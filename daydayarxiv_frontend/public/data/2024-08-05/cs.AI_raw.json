[
  {
    "arxiv_id": "2408.02865v1",
    "title": "VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge",
    "authors": [
      "Zihan Li",
      "Diping Song",
      "Zefeng Yang",
      "Deming Wang",
      "Fei Li",
      "Xiulan Zhang",
      "Paul E. Kinahan",
      "Yu Qiao"
    ],
    "abstract": "The need for improved diagnostic methods in ophthalmology is acute,\nespecially in the less developed regions with limited access to specialists and\nadvanced equipment. Therefore, we introduce VisionUnite, a novel\nvision-language foundation model for ophthalmology enhanced with clinical\nknowledge. VisionUnite has been pretrained on an extensive dataset comprising\n1.24 million image-text pairs, and further refined using our proposed MMFundus\ndataset, which includes 296,379 high-quality fundus image-text pairs and\n889,137 simulated doctor-patient dialogue instances. Our experiments indicate\nthat VisionUnite outperforms existing generative foundation models such as\nGPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable\nto junior ophthalmologists. VisionUnite performs well in various clinical\nscenarios including open-ended multi-disease diagnosis, clinical explanation,\nand patient interaction, making it a highly versatile tool for initial\nophthalmic disease screening. VisionUnite can also serve as an educational aid\nfor junior ophthalmologists, accelerating their acquisition of knowledge\nregarding both common and rare ophthalmic conditions. VisionUnite represents a\nsignificant advancement in ophthalmology, with broad implications for\ndiagnostics, medical education, and understanding of disease mechanisms.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02865v1",
    "published_date": "2024-08-05 23:31:07 UTC",
    "updated_date": "2024-08-05 23:31:07 UTC"
  },
  {
    "arxiv_id": "2408.02862v1",
    "title": "On The Stability of Moral Preferences: A Problem with Computational Elicitation Methods",
    "authors": [
      "Kyle Boerstler",
      "Vijay Keswani",
      "Lok Chan",
      "Jana Schaich Borg",
      "Vincent Conitzer",
      "Hoda Heidari",
      "Walter Sinnott-Armstrong"
    ],
    "abstract": "Preference elicitation frameworks feature heavily in the research on\nparticipatory ethical AI tools and provide a viable mechanism to enquire and\nincorporate the moral values of various stakeholders. As part of the\nelicitation process, surveys about moral preferences, opinions, and judgments\nare typically administered only once to each participant. This methodological\npractice is reasonable if participants' responses are stable over time such\nthat, all other relevant factors being held constant, their responses today\nwill be the same as their responses to the same questions at a later time.\nHowever, we do not know how often that is the case. It is possible that\nparticipants' true moral preferences change, are subject to temporary moods or\nwhims, or are influenced by environmental factors we don't track. If\nparticipants' moral responses are unstable in such ways, it would raise\nimportant methodological and theoretical issues for how participants' true\nmoral preferences, opinions, and judgments can be ascertained. We address this\npossibility here by asking the same survey participants the same moral\nquestions about which patient should receive a kidney when only one is\navailable ten times in ten different sessions over two weeks, varying only\npresentation order across sessions. We measured how often participants gave\ndifferent responses to simple (Study One) and more complicated (Study Two)\nrepeated scenarios. On average, the fraction of times participants changed\ntheir responses to controversial scenarios was around 10-18% across studies,\nand this instability is observed to have positive associations with response\ntime and decision-making difficulty. We discuss the implications of these\nresults for the efficacy of moral preference elicitation, highlighting the role\nof response instability in causing value misalignment between stakeholders and\nAI tools trained on their moral judgments.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "To appear in AIES 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.02862v1",
    "published_date": "2024-08-05 23:20:47 UTC",
    "updated_date": "2024-08-05 23:20:47 UTC"
  },
  {
    "arxiv_id": "2408.02859v1",
    "title": "Multistain Pretraining for Slide Representation Learning in Pathology",
    "authors": [
      "Guillaume Jaume",
      "Anurag Vaidya",
      "Andrew Zhang",
      "Andrew H. Song",
      "Richard J. Chen",
      "Sharifa Sahai",
      "Dandan Mo",
      "Emilio Madrigal",
      "Long Phi Le",
      "Faisal Mahmood"
    ],
    "abstract": "Developing self-supervised learning (SSL) models that can learn universal and\ntransferable representations of H&E gigapixel whole-slide images (WSIs) is\nbecoming increasingly valuable in computational pathology. These models hold\nthe potential to advance critical tasks such as few-shot classification, slide\nretrieval, and patient stratification. Existing approaches for slide\nrepresentation learning extend the principles of SSL from small images (e.g.,\n224 x 224 patches) to entire slides, usually by aligning two different\naugmentations (or views) of the slide. Yet the resulting representation remains\nconstrained by the limited clinical and biological diversity of the views.\nInstead, we postulate that slides stained with multiple markers, such as\nimmunohistochemistry, can be used as different views to form a rich\ntask-agnostic training signal. To this end, we introduce Madeleine, a\nmultimodal pretraining strategy for slide representation learning. Madeleine is\ntrained with a dual global-local cross-stain alignment objective on large\ncohorts of breast cancer samples (N=4,211 WSIs across five stains) and kidney\ntransplant samples (N=12,070 WSIs across four stains). We demonstrate the\nquality of slide representations learned by Madeleine on various downstream\nevaluations, ranging from morphological and molecular classification to\nprognostic prediction, comprising 21 tasks using 7,299 WSIs from multiple\nmedical centers. Code is available at https://github.com/mahmoodlab/MADELEINE.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "ECCV'24",
    "pdf_url": "http://arxiv.org/pdf/2408.02859v1",
    "published_date": "2024-08-05 22:59:50 UTC",
    "updated_date": "2024-08-05 22:59:50 UTC"
  },
  {
    "arxiv_id": "2408.02835v3",
    "title": "Training a multilayer dynamical spintronic network with standard machine learning tools to perform time series classification",
    "authors": [
      "Erwan Plouet",
      "Dédalo Sanz-Hernández",
      "Aymeric Vecchiola",
      "Julie Grollier",
      "Frank Mizrahi"
    ],
    "abstract": "The ability to process time-series at low energy cost is critical for many\napplications. Recurrent neural network, which can perform such tasks, are\ncomputationally expensive when implementing in software on conventional\ncomputers. Here we propose to implement a recurrent neural network in hardware\nusing spintronic oscillators as dynamical neurons. Using numerical simulations,\nwe build a multi-layer network and demonstrate that we can use backpropagation\nthrough time (BPTT) and standard machine learning tools to train this network.\nLeveraging the transient dynamics of the spintronic oscillators, we solve the\nsequential digits classification task with $89.83\\pm2.91~\\%$ accuracy, as good\nas the equivalent software network. We devise guidelines on how to choose the\ntime constant of the oscillators as well as hyper-parameters of the network to\nadapt to different input time scales.",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.mes-hall",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.dis-nn",
    "comment": "7 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.02835v3",
    "published_date": "2024-08-05 21:12:12 UTC",
    "updated_date": "2025-03-04 13:41:49 UTC"
  },
  {
    "arxiv_id": "2408.05241v4",
    "title": "Large Model Strategic Thinking, Small Model Efficiency: Transferring Theory of Mind in Large Language Models",
    "authors": [
      "Nunzio Lore",
      "Sepehr Ilami",
      "Babak Heydari"
    ],
    "abstract": "As the performance of larger, newer Large Language Models continues to\nimprove for strategic Theory of Mind (ToM) tasks, the demand for these\nstate-of-the-art models increases commensurately. However, their deployment is\ncostly both in terms of processing power and time. In this paper, we\ninvestigate the feasibility of creating smaller, highly-performing specialized\nalgorithms by way of fine-tuning. To do this, we first present a large\npre-trained model with 20 unique scenarios that combine different social\ncontexts with games of varying social dilemmas, record its answers, and use\nthem for Q&A fine-tuning on a smaller model of the same family. Our focus is on\nin-context game-theoretic decision-making, the same domain within which human\ninteraction occurs and that requires both a theory of mind (or a semblance\nthereof) and an understanding of social dynamics. The smaller model is\ntherefore trained not just on the answers provided, but also on the motivations\nprovided by the larger model, which should contain advice and guidelines to\nnavigate both strategic dilemmas and social cues. We find that the fine-tuned\nsmaller language model consistently bridged the gap in performance between the\nsmaller pre-trained version of the model and its larger relative and that its\nimprovements extended in areas and contexts beyond the ones provided in the\ntraining examples, including on out-of-sample scenarios that include completely\ndifferent game structures. On average for all games, through fine-tuning, the\nsmaller model showed a 46% improvement measured as alignment towards the\nbehavior of the larger model, with 100% representing indistinguishable\nbehavior. When presented with out-of-sample social contexts and games, the\nfine-tuned model still displays remarkable levels of alignment, reaching an\nimprovement of 18% and 28% respectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.ET",
      "cs.GT"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.05241v4",
    "published_date": "2024-08-05 20:49:48 UTC",
    "updated_date": "2024-10-30 18:37:57 UTC"
  },
  {
    "arxiv_id": "2408.02825v2",
    "title": "The Impact of Environment Configurations on the Stability of AI-Enabled Systems",
    "authors": [
      "Musfiqur Rahman",
      "SayedHassan Khatoonabadi",
      "Ahmad Abdellatif",
      "Haya Samaana",
      "Emad Shihab"
    ],
    "abstract": "Nowadays, software systems tend to include Artificial Intelligence (AI)\ncomponents. Changes in the operational environment have been known to\nnegatively impact the stability of AI-enabled software systems by causing\nunintended changes in behavior. However, how an environment configuration\nimpacts the behavior of such systems has yet to be explored. Understanding and\nquantifying the degree of instability caused by different environment settings\ncan help practitioners decide the best environment configuration for the most\nstable AI systems. To achieve this goal, we performed experiments with eight\ndifferent combinations of three key environment variables (operating system,\nPython version, and CPU architecture) on $30$ open-source AI-enabled systems\nusing the Travis CI platform. We determine the existence and the degree of\ninstability introduced by each configuration using three metrics: the output of\nan AI component of the system (model performance), the time required to build\nand run the system (processing time), and the cost associated with building and\nrunning the system (expense). Our results indicate that changes in environment\nconfigurations lead to instability across all three metrics; however, it is\nobserved more frequently with respect to processing time and expense rather\nthan model performance. For example, between Linux and MacOS, instability is\nobserved in 23\\%, 96.67\\%, and 100\\% of the studied projects in model\nperformance, processing time, and expense, respectively. Our findings\nunderscore the importance of identifying the optimal combination of\nconfiguration settings to mitigate drops in model performance and reduce the\nprocessing time and expense before deploying an AI-enabled system.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication at the International Conference on\n  Evaluation and Assessment in Software Engineering (EASE 2025)",
    "pdf_url": "http://arxiv.org/pdf/2408.02825v2",
    "published_date": "2024-08-05 20:47:14 UTC",
    "updated_date": "2025-04-17 14:52:17 UTC"
  },
  {
    "arxiv_id": "2408.02811v1",
    "title": "Development of REGAI: Rubric Enabled Generative Artificial Intelligence",
    "authors": [
      "Zach Johnson",
      "Jeremy Straub"
    ],
    "abstract": "This paper presents and evaluates a new retrieval augmented generation (RAG)\nand large language model (LLM)-based artificial intelligence (AI) technique:\nrubric enabled generative artificial intelligence (REGAI). REGAI uses rubrics,\nwhich can be created manually or automatically by the system, to enhance the\nperformance of LLMs for evaluation purposes. REGAI improves on the performance\nof both classical LLMs and RAG-based LLM techniques. This paper describes\nREGAI, presents data regarding its performance and discusses several possible\napplication areas for the technology.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02811v1",
    "published_date": "2024-08-05 20:21:54 UTC",
    "updated_date": "2024-08-05 20:21:54 UTC"
  },
  {
    "arxiv_id": "2408.03350v3",
    "title": "miniCTX: Neural Theorem Proving with (Long-)Contexts",
    "authors": [
      "Jiewen Hu",
      "Thomas Zhu",
      "Sean Welleck"
    ],
    "abstract": "Real-world formal theorem proving often depends on a wealth of context,\nincluding definitions, lemmas, comments, file structure, and other information.\nWe introduce miniCTX, which tests a model's ability to prove formal\nmathematical theorems that depend on new context that is not seen during\ntraining. miniCTX contains theorems sourced from real Lean projects and\ntextbooks, each associated with a context that can span tens of thousands of\ntokens. Models are tasked with proving a theorem given access to code from the\ntheorem's repository, which contains context that is needed for the proof. As a\nbaseline for miniCTX, we tested fine-tuning and prompting methods that\ncondition theorem proving on preceding context. Both approaches substantially\noutperform traditional methods that rely solely on state information. We found\nthat this ability to use context is not captured by previous benchmarks such as\nminiF2F. Alongside miniCTX, we offer ntp-toolkit for automatically extracting\nand annotating theorem proving data, making it easy to add new projects into\nminiCTX to ensure that contexts are not seen during training. miniCTX offers a\nchallenging and realistic evaluation of neural theorem provers.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Project page: https://cmu-l3.github.io/minictx",
    "pdf_url": "http://arxiv.org/pdf/2408.03350v3",
    "published_date": "2024-08-05 20:19:18 UTC",
    "updated_date": "2025-03-04 00:10:22 UTC"
  },
  {
    "arxiv_id": "2408.04660v3",
    "title": "XMainframe: A Large Language Model for Mainframe Modernization",
    "authors": [
      "Anh T. V. Dau",
      "Hieu Trung Dao",
      "Anh Tuan Nguyen",
      "Hieu Trung Tran",
      "Phong X. Nguyen",
      "Nghi D. Q. Bui"
    ],
    "abstract": "Mainframe operating systems, despite their inception in the 1940s, continue\nto support critical sectors like finance and government. However, these systems\nare often viewed as outdated, requiring extensive maintenance and\nmodernization. Addressing this challenge necessitates innovative tools that can\nunderstand and interact with legacy codebases. To this end, we introduce\nXMainframe, a state-of-the-art large language model (LLM) specifically designed\nwith knowledge of mainframe legacy systems and COBOL codebases. Our solution\ninvolves the creation of an extensive data collection pipeline to produce\nhigh-quality training datasets, enhancing XMainframe's performance in this\nspecialized domain. Additionally, we present MainframeBench, a comprehensive\nbenchmark for assessing mainframe knowledge, including multiple-choice\nquestions, question answering, and COBOL code summarization. Our empirical\nevaluations demonstrate that XMainframe consistently outperforms existing\nstate-of-the-art LLMs across these tasks. Specifically, XMainframe achieves 30%\nhigher accuracy than DeepSeek-Coder on multiple-choice questions, doubles the\nBLEU score of Mixtral-Instruct 8x7B on question answering, and scores six times\nhigher than GPT-3.5 on COBOL summarization. Our work highlights the potential\nof XMainframe to drive significant advancements in managing and modernizing\nlegacy systems, thereby enhancing productivity and saving time for software\ndevelopers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04660v3",
    "published_date": "2024-08-05 20:01:10 UTC",
    "updated_date": "2024-08-26 09:37:46 UTC"
  },
  {
    "arxiv_id": "2408.02798v1",
    "title": "Examining Gender and Power on Wikipedia Through Face and Politeness",
    "authors": [
      "Adil Soubki",
      "Shyne Choi",
      "Owen Rambow"
    ],
    "abstract": "We propose a framework for analyzing discourse by combining two\ninterdependent concepts from sociolinguistic theory: face acts and politeness.\nWhile politeness has robust existing tools and data, face acts are less\nresourced. We introduce a new corpus created by annotating Wikipedia talk pages\nwith face acts and we use this to train a face act tagger. We then employ our\nframework to study how face and politeness interact with gender and power in\ndiscussions between Wikipedia editors. Among other findings, we observe that\nfemale Wikipedians are not only more polite, which is consistent with prior\nstudies, but that this difference corresponds with significantly more language\ndirected at humbling aspects of their own face. Interestingly, the distinction\nnearly vanishes once limiting to editors with administrative power.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02798v1",
    "published_date": "2024-08-05 19:28:58 UTC",
    "updated_date": "2024-08-05 19:28:58 UTC"
  },
  {
    "arxiv_id": "2408.02666v2",
    "title": "Self-Taught Evaluators",
    "authors": [
      "Tianlu Wang",
      "Ilia Kulikov",
      "Olga Golovneva",
      "Ping Yu",
      "Weizhe Yuan",
      "Jane Dwivedi-Yu",
      "Richard Yuanzhe Pang",
      "Maryam Fazel-Zarandi",
      "Jason Weston",
      "Xian Li"
    ],
    "abstract": "Model-based evaluation is at the heart of successful model development -- as\na reward model for training, and as a replacement for human evaluation. To\ntrain such evaluators, the standard approach is to collect a large amount of\nhuman preference judgments over model responses, which is costly and the data\nbecomes stale as models improve. In this work, we present an approach that aims\nto im-prove evaluators without human annotations, using synthetic training data\nonly. Starting from unlabeled instructions, our iterative self-improvement\nscheme generates contrasting model outputs and trains an LLM-as-a-Judge to\nproduce reasoning traces and final judgments, repeating this training at each\nnew iteration using the improved predictions. Without any labeled preference\ndata, our Self-Taught Evaluator can improve a strong LLM (Llama3-70B-Instruct)\nfrom 75.4 to 88.3 (88.7 with majority vote) on RewardBench. This outperforms\ncommonly used LLM judges such as GPT-4 and matches the performance of the\ntop-performing reward models trained with labeled examples.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02666v2",
    "published_date": "2024-08-05 17:57:02 UTC",
    "updated_date": "2024-08-08 17:09:58 UTC"
  },
  {
    "arxiv_id": "2408.02651v1",
    "title": "Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?",
    "authors": [
      "Mohammad Bahrami Karkevandi",
      "Nishant Vishwamitra",
      "Peyman Najafirad"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nnatural language tasks, but their safety and morality remain contentious due to\ntheir training on internet text corpora. To address these concerns, alignment\ntechniques have been developed to improve the public usability and safety of\nLLMs. Yet, the potential for generating harmful content through these models\nseems to persist. This paper explores the concept of jailbreaking\nLLMs-reversing their alignment through adversarial triggers. Previous methods,\nsuch as soft embedding prompts, manually crafted prompts, and gradient-based\nautomatic prompts, have had limited success on black-box models due to their\nrequirements for model access and for producing a low variety of manually\ncrafted prompts, making them susceptible to being blocked. This paper\nintroduces a novel approach using reinforcement learning to optimize\nadversarial triggers, requiring only inference API access to the target model\nand a small surrogate model. Our method, which leverages a BERTScore-based\nreward function, enhances the transferability and effectiveness of adversarial\ntriggers on new black-box models. We demonstrate that this approach improves\nthe performance of adversarial triggers on a previously untested language\nmodel.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to AI4CYBER - KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.02651v1",
    "published_date": "2024-08-05 17:27:29 UTC",
    "updated_date": "2024-08-05 17:27:29 UTC"
  },
  {
    "arxiv_id": "2408.05239v1",
    "title": "The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development",
    "authors": [
      "Joshua Morriss",
      "Tod Brindle",
      "Jessica Bah Rösman",
      "Daniel Reibsamen",
      "Andreas Enz"
    ],
    "abstract": "Systematic literature reviews are the highest quality of evidence in\nresearch. However, the review process is hindered by significant resource and\ndata constraints. The Literature Review Network (LRN) is the first of its kind\nexplainable AI platform adhering to PRISMA 2020 standards, designed to automate\nthe entire literature review process. LRN was evaluated in the domain of\nsurgical glove practices using 3 search strings developed by experts to query\nPubMed. A non-expert trained all LRN models. Performance was benchmarked\nagainst an expert manual review. Explainability and performance metrics\nassessed LRN's ability to replicate the experts' review. Concordance was\nmeasured with the Jaccard index and confusion matrices. Researchers were\nblinded to the other's results until study completion. Overlapping studies were\nintegrated into an LRN-generated systematic review. LRN models demonstrated\nsuperior classification accuracy without expert training, achieving 84.78% and\n85.71% accuracy. The highest performance model achieved high interrater\nreliability (k = 0.4953) and explainability metrics, linking 'reduce',\n'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%\nof the relevant literature despite diverging from the non-expert's judgments (k\n= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN\noutperformed the manual review (19,920 minutes over 11 months), reducing the\nentire process to 288.6 minutes over 5 days. This study demonstrates that\nexplainable AI does not require expert training to successfully conduct\nPRISMA-compliant systematic literature reviews like an expert. LRN summarized\nthe results of surgical glove studies and identified themes that were nearly\nidentical to the clinical researchers' findings. Explainable AI can accurately\nexpedite our understanding of clinical practices, potentially revolutionizing\nhealthcare research.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.DL",
    "comment": "12 pages, 4 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.05239v1",
    "published_date": "2024-08-05 17:25:16 UTC",
    "updated_date": "2024-08-05 17:25:16 UTC"
  },
  {
    "arxiv_id": "2408.07705v1",
    "title": "Enhancing Supply Chain Visibility with Knowledge Graphs and Large Language Models",
    "authors": [
      "Sara AlMahri",
      "Liming Xu",
      "Alexandra Brintrup"
    ],
    "abstract": "In today's globalized economy, comprehensive supply chain visibility is\ncrucial for effective risk management. Achieving visibility remains a\nsignificant challenge due to limited information sharing among supply chain\npartners. This paper presents a novel framework leveraging Knowledge Graphs\n(KGs) and Large Language Models (LLMs) to enhance supply chain visibility\nwithout relying on direct stakeholder information sharing. Our zero-shot,\nLLM-driven approach automates the extraction of supply chain information from\ndiverse public sources and constructs KGs to capture complex interdependencies\nbetween supply chain entities. We employ zero-shot prompting for Named Entity\nRecognition (NER) and Relation Extraction (RE) tasks, eliminating the need for\nextensive domain-specific training. We validate the framework with a case study\non electric vehicle supply chains, focusing on tracking critical minerals for\nbattery manufacturing. Results show significant improvements in supply chain\nmapping, extending visibility beyond tier-2 suppliers. The framework reveals\ncritical dependencies and alternative sourcing options, enhancing risk\nmanagement and strategic planning. With high accuracy in NER and RE tasks, it\nprovides an effective tool for understanding complex, multi-tiered supply\nnetworks. This research offers a scalable, flexible method for constructing\ndomain-specific supply chain KGs, addressing longstanding challenges in\nvisibility and paving the way for advancements in digital supply chain\nsurveillance.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07705v1",
    "published_date": "2024-08-05 17:11:29 UTC",
    "updated_date": "2024-08-05 17:11:29 UTC"
  },
  {
    "arxiv_id": "2408.02632v2",
    "title": "SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models",
    "authors": [
      "Muxi Diao",
      "Rumei Li",
      "Shiyang Liu",
      "Guogang Liao",
      "Jingang Wang",
      "Xunliang Cai",
      "Weiran Xu"
    ],
    "abstract": "As large language models (LLMs) continue to advance in capability and\ninfluence, ensuring their security and preventing harmful outputs has become\ncrucial. A promising approach to address these concerns involves training\nmodels to automatically generate adversarial prompts for red teaming. However,\nthe evolving subtlety of vulnerabilities in LLMs challenges the effectiveness\nof current adversarial methods, which struggle to specifically target and\nexplore the weaknesses of these models. To tackle these challenges, we\nintroduce the $\\mathbf{S}\\text{elf-}\\mathbf{E}\\text{volving\n}\\mathbf{A}\\text{dversarial }\\mathbf{S}\\text{afety }\\mathbf{(SEAS)}$\noptimization framework, which enhances security by leveraging data generated by\nthe model itself. SEAS operates through three iterative stages: Initialization,\nAttack, and Adversarial Optimization, refining both the Red Team and Target\nmodels to improve robustness and safety. This framework reduces reliance on\nmanual testing and significantly enhances the security capabilities of LLMs.\nOur contributions include a novel adversarial framework, a comprehensive safety\ndataset, and after three iterations, the Target model achieves a security level\ncomparable to GPT-4, while the Red Team model shows a marked increase in attack\nsuccess rate (ASR) against advanced models. Our code and datasets are released\nat https://SEAS-LLM.github.io/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02632v2",
    "published_date": "2024-08-05 16:55:06 UTC",
    "updated_date": "2024-12-23 05:44:30 UTC"
  },
  {
    "arxiv_id": "2408.02622v1",
    "title": "Language Model Can Listen While Speaking",
    "authors": [
      "Ziyang Ma",
      "Yakun Song",
      "Chenpeng Du",
      "Jian Cong",
      "Zhuo Chen",
      "Yuping Wang",
      "Yuxuan Wang",
      "Xie Chen"
    ],
    "abstract": "Dialogue serves as the most natural manner of human-computer interaction\n(HCI). Recent advancements in speech language models (SLM) have significantly\nenhanced speech-based conversational AI. However, these models are limited to\nturn-based conversation, lacking the ability to interact with humans in\nreal-time spoken scenarios, for example, being interrupted when the generated\ncontent is not satisfactory. To address these limitations, we explore full\nduplex modeling (FDM) in interactive speech language models (iSLM), focusing on\nenhancing real-time interaction and, more explicitly, exploring the\nquintessential ability of interruption. We introduce a novel model design,\nnamely listening-while-speaking language model (LSLM), an end-to-end system\nequipped with both listening and speaking channels. Our LSLM employs a\ntoken-based decoder-only TTS for speech generation and a streaming\nself-supervised learning (SSL) encoder for real-time audio input. LSLM fuses\nboth channels for autoregressive generation and detects turn-taking in real\ntime. Three fusion strategies -- early fusion, middle fusion, and late fusion\n-- are explored, with middle fusion achieving an optimal balance between speech\ngeneration and real-time interaction. Two experimental settings, command-based\nFDM and voice-based FDM, demonstrate LSLM's robustness to noise and sensitivity\nto diverse instructions. Our results highlight LSLM's capability to achieve\nduplex communication with minimal impact on existing systems. This study aims\nto advance the development of interactive speech dialogue systems, enhancing\ntheir applicability in real-world contexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Demo can be found at https://ddlbojack.github.io/LSLM",
    "pdf_url": "http://arxiv.org/pdf/2408.02622v1",
    "published_date": "2024-08-05 16:47:22 UTC",
    "updated_date": "2024-08-05 16:47:22 UTC"
  },
  {
    "arxiv_id": "2408.02606v1",
    "title": "Backward explanations via redefinition of predicates",
    "authors": [
      "Léo Saulières",
      "Martin C. Cooper",
      "Florence Dupin de Saint Cyr"
    ],
    "abstract": "History eXplanation based on Predicates (HXP), studies the behavior of a\nReinforcement Learning (RL) agent in a sequence of agent's interactions with\nthe environment (a history), through the prism of an arbitrary predicate. To\nthis end, an action importance score is computed for each action in the\nhistory. The explanation consists in displaying the most important actions to\nthe user. As the calculation of an action's importance is #W[1]-hard, it is\nnecessary for long histories to approximate the scores, at the expense of their\nquality. We therefore propose a new HXP method, called Backward-HXP, to provide\nexplanations for these histories without having to approximate scores.\nExperiments show the ability of B-HXP to summarise long histories.",
    "categories": [
      "cs.AI",
      "cs.CC",
      "I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02606v1",
    "published_date": "2024-08-05 16:31:38 UTC",
    "updated_date": "2024-08-05 16:31:38 UTC"
  },
  {
    "arxiv_id": "2408.02599v2",
    "title": "Progressively Label Enhancement for Large Language Model Alignment",
    "authors": [
      "Biao Liu",
      "Ning Xu",
      "Xin Geng"
    ],
    "abstract": "Large Language Models (LLM) alignment aims to prevent models from producing\ncontent that misaligns with human expectations, which can lead to ethical and\nlegal concerns. In the last few years, Reinforcement Learning from Human\nFeedback (RLHF) has been the most prominent method for achieving alignment. Due\nto challenges in stability and scalability with RLHF stages, which arise from\nthe complex interactions between multiple models, researchers are exploring\nalternative methods to achieve effects comparable to those of RLHF. However,\nthese methods often rely on large high-quality datasets. Despite some methods\nconsidering the generation of additional data to expand datasets, they often\ntreat model training and data generation as separate and static processes,\noverlooking the fact that these processes are highly interdependent, leading to\ninefficient utilization of the generated data. To deal with this problem, we\npropose PLE, i.e., Progressively Label Enhancement for LLM Alignment, a\nframework that dynamically adjusts the model's training process based on the\nevolving quality of the generated data. Specifically, we prompt the model to\ngenerate responses for both the original query and the query guided by a set of\ncarefully designed principles, and then utilize a dynamic threshold to\ndetermine the appropriate training approach for both responses based on their\ncorresponding reward scores. Experimental results demonstrate the effectiveness\nof PLE compared to existing LLM alignment methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02599v2",
    "published_date": "2024-08-05 16:21:17 UTC",
    "updated_date": "2024-10-09 07:31:18 UTC"
  },
  {
    "arxiv_id": "2408.02595v1",
    "title": "Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection",
    "authors": [
      "Sajal Aggarwal",
      "Ananya Pandey",
      "Dinesh Kumar Vishwakarma"
    ],
    "abstract": "Sarcasm is a type of irony, characterized by an inherent mismatch between the\nliteral interpretation and the intended connotation. Though sarcasm detection\nin text has been extensively studied, there are situations in which textual\ninput alone might be insufficient to perceive sarcasm. The inclusion of\nadditional contextual cues, such as images, is essential to recognize sarcasm\nin social media data effectively. This study presents a novel framework for\nmultimodal sarcasm detection that can process input triplets. Two components of\nthese triplets comprise the input text and its associated image, as provided in\nthe datasets. Additionally, a supplementary modality is introduced in the form\nof descriptive image captions. The motivation behind incorporating this visual\nsemantic representation is to more accurately capture the discrepancies between\nthe textual and visual content, which are fundamental to the sarcasm detection\ntask. The primary contributions of this study are: (1) a robust textual feature\nextraction branch that utilizes a cross-lingual language model; (2) a visual\nfeature extraction branch that incorporates a self-regulated residual ConvNet\nintegrated with a lightweight spatially aware attention module; (3) an\nadditional modality in the form of image captions generated using an\nencoder-decoder architecture capable of reading text embedded in images; (4)\ndistinct attention modules to effectively identify the incongruities between\nthe text and two levels of image representations; (5) multi-level cross-domain\nsemantic incongruity representation achieved through feature fusion. Compared\nwith cutting-edge baselines, the proposed model achieves the best accuracy of\n92.89% and 64.48%, respectively, on the Twitter multimodal sarcasm and\nMultiBully datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02595v1",
    "published_date": "2024-08-05 16:07:31 UTC",
    "updated_date": "2024-08-05 16:07:31 UTC"
  },
  {
    "arxiv_id": "2408.02584v1",
    "title": "Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization",
    "authors": [
      "Ankan Mullick",
      "Sombit Bose",
      "Rounak Saha",
      "Ayan Kumar Bhowmick",
      "Aditya Vempaty",
      "Pawan Goyal",
      "Niloy Ganguly",
      "Prasenjit Dey",
      "Ravi Kokku"
    ],
    "abstract": "The ever-increasing volume of digital information necessitates efficient\nmethods for users to extract key insights from lengthy documents. Aspect-based\nsummarization offers a targeted approach, generating summaries focused on\nspecific aspects within a document. Despite advancements in aspect-based\nsummarization research, there is a continuous quest for improved model\nperformance. Given that large language models (LLMs) have demonstrated the\npotential to revolutionize diverse tasks within natural language processing,\nparticularly in the problem of summarization, this paper explores the potential\nof fine-tuning LLMs for the aspect-based summarization task. We evaluate the\nimpact of fine-tuning open-source foundation LLMs, including Llama2, Mistral,\nGemma and Aya, on a publicly available domain-specific aspect based summary\ndataset. We hypothesize that this approach will enable these models to\neffectively identify and extract aspect-related information, leading to\nsuperior quality aspect-based summaries compared to the state-of-the-art. We\nestablish a comprehensive evaluation framework to compare the performance of\nfine-tuned LLMs against competing aspect-based summarization methods and\nvanilla counterparts of the fine-tuned LLMs. Our work contributes to the field\nof aspect-based summarization by demonstrating the efficacy of fine-tuning LLMs\nfor generating high-quality aspect-based summaries. Furthermore, it opens doors\nfor further exploration of using LLMs for targeted information extraction tasks\nacross various NLP domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02584v1",
    "published_date": "2024-08-05 16:00:21 UTC",
    "updated_date": "2024-08-05 16:00:21 UTC"
  },
  {
    "arxiv_id": "2408.02582v1",
    "title": "Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition",
    "authors": [
      "Jaeyoung Kim",
      "Han Lu",
      "Soheil Khorram",
      "Anshuman Tripathi",
      "Qian Zhang",
      "Hasim Sak"
    ],
    "abstract": "Modern automatic speech recognition (ASR) systems are typically trained on\nmore than tens of thousands hours of speech data, which is one of the main\nfactors for their great success. However, the distribution of such data is\ntypically biased towards common accents or typical speech patterns. As a\nresult, those systems often poorly perform on atypical accented speech. In this\npaper, we present accent clustering and mining schemes for fair speech\nrecognition systems which can perform equally well on under-represented\naccented speech. For accent recognition, we applied three schemes to overcome\nlimited size of supervised accent data: supervised or unsupervised\npre-training, distributionally robust optimization (DRO) and unsupervised\nclustering. Three schemes can significantly improve the accent recognition\nmodel especially for unbalanced and small accented speech. Fine-tuning ASR on\nthe mined Indian accent speech using the proposed supervised or unsupervised\nclustering schemes showed 10.0% and 5.3% relative improvements compared to\nfine-tuning on the randomly sampled speech, respectively.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02582v1",
    "published_date": "2024-08-05 16:00:07 UTC",
    "updated_date": "2024-08-05 16:00:07 UTC"
  },
  {
    "arxiv_id": "2408.10248v1",
    "title": "Target-Dependent Multimodal Sentiment Analysis Via Employing Visual-to Emotional-Caption Translation Network using Visual-Caption Pairs",
    "authors": [
      "Ananya Pandey",
      "Dinesh Kumar Vishwakarma"
    ],
    "abstract": "The natural language processing and multimedia field has seen a notable surge\nin interest in multimodal sentiment recognition. Hence, this study aims to\nemploy Target-Dependent Multimodal Sentiment Analysis (TDMSA) to identify the\nlevel of sentiment associated with every target (aspect) stated within a\nmultimodal post consisting of a visual-caption pair. Despite the recent\nadvancements in multimodal sentiment recognition, there has been a lack of\nexplicit incorporation of emotional clues from the visual modality,\nspecifically those pertaining to facial expressions. The challenge at hand is\nto proficiently obtain visual and emotional clues and subsequently synchronise\nthem with the textual content. In light of this fact, this study presents a\nnovel approach called the Visual-to-Emotional-Caption Translation Network\n(VECTN) technique. The primary objective of this strategy is to effectively\nacquire visual sentiment clues by analysing facial expressions. Additionally,\nit effectively aligns and blends the obtained emotional clues with the target\nattribute of the caption mode. The experimental findings demonstrate that our\nmethodology is capable of producing ground-breaking outcomes when applied to\ntwo publicly accessible multimodal Twitter datasets, namely, Twitter-2015 and\nTwitter-2017. The experimental results show that the suggested model achieves\nan accuracy of 81.23% and a macro-F1 of 80.61% on the Twitter-15 dataset, while\n77.42% and 75.19% on the Twitter-17 dataset, respectively. The observed\nimprovement in performance reveals that our model is better than others when it\ncomes to collecting target-level sentiment in multimodal data using the\nexpressions of the face.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10248v1",
    "published_date": "2024-08-05 15:56:55 UTC",
    "updated_date": "2024-08-05 15:56:55 UTC"
  },
  {
    "arxiv_id": "2408.10247v1",
    "title": "MetaEnzyme: Meta Pan-Enzyme Learning for Task-Adaptive Redesign",
    "authors": [
      "Jiangbin Zheng",
      "Han Zhang",
      "Qianqing Xu",
      "An-Ping Zeng",
      "Stan Z. Li"
    ],
    "abstract": "Enzyme design plays a crucial role in both industrial production and biology.\nHowever, this field faces challenges due to the lack of comprehensive\nbenchmarks and the complexity of enzyme design tasks, leading to a dearth of\nsystematic research. Consequently, computational enzyme design is relatively\noverlooked within the broader protein domain and remains in its early stages.\nIn this work, we address these challenges by introducing MetaEnzyme, a staged\nand unified enzyme design framework. We begin by employing a cross-modal\nstructure-to-sequence transformation architecture, as the feature-driven\nstarting point to obtain initial robust protein representation. Subsequently,\nwe leverage domain adaptive techniques to generalize specific enzyme design\ntasks under low-resource conditions. MetaEnzyme focuses on three fundamental\nlow-resource enzyme redesign tasks: functional design (FuncDesign), mutation\ndesign (MutDesign), and sequence generation design (SeqDesign). Through novel\nunified paradigm and enhanced representation capabilities, MetaEnzyme\ndemonstrates adaptability to diverse enzyme design tasks, yielding outstanding\nresults. Wet lab experiments further validate these findings, reinforcing the\nefficacy of the redesign process.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "Accepted to ACM Multimedia 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10247v1",
    "published_date": "2024-08-05 15:48:39 UTC",
    "updated_date": "2024-08-05 15:48:39 UTC"
  },
  {
    "arxiv_id": "2408.02571v1",
    "title": "Contrastive Learning-based Multi Modal Architecture for Emoticon Prediction by Employing Image-Text Pairs",
    "authors": [
      "Ananya Pandey",
      "Dinesh Kumar Vishwakarma"
    ],
    "abstract": "The emoticons are symbolic representations that generally accompany the\ntextual content to visually enhance or summarize the true intention of a\nwritten message. Although widely utilized in the realm of social media, the\ncore semantics of these emoticons have not been extensively explored based on\nmultiple modalities. Incorporating textual and visual information within a\nsingle message develops an advanced way of conveying information. Hence, this\nresearch aims to analyze the relationship among sentences, visuals, and\nemoticons. For an orderly exposition, this paper initially provides a detailed\nexamination of the various techniques for extracting multimodal features,\nemphasizing the pros and cons of each method. Through conducting a\ncomprehensive examination of several multimodal algorithms, with specific\nemphasis on the fusion approaches, we have proposed a novel contrastive\nlearning based multimodal architecture. The proposed model employs the joint\ntraining of dual-branch encoder along with the contrastive learning to\naccurately map text and images into a common latent space. Our key finding is\nthat by integrating the principle of contrastive learning with that of the\nother two branches yields superior results. The experimental results\ndemonstrate that our suggested methodology surpasses existing multimodal\napproaches in terms of accuracy and robustness. The proposed model attained an\naccuracy of 91% and an MCC-score of 90% while assessing emoticons using the\nMultimodal-Twitter Emoticon dataset acquired from Twitter. We provide evidence\nthat deep features acquired by contrastive learning are more efficient,\nsuggesting that the proposed fusion technique also possesses strong\ngeneralisation capabilities for recognising emoticons across several modes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02571v1",
    "published_date": "2024-08-05 15:45:59 UTC",
    "updated_date": "2024-08-05 15:45:59 UTC"
  },
  {
    "arxiv_id": "2408.10246v1",
    "title": "VyAnG-Net: A Novel Multi-Modal Sarcasm Recognition Model by Uncovering Visual, Acoustic and Glossary Features",
    "authors": [
      "Ananya Pandey",
      "Dinesh Kumar Vishwakarma"
    ],
    "abstract": "Various linguistic and non-linguistic clues, such as excessive emphasis on a\nword, a shift in the tone of voice, or an awkward expression, frequently convey\nsarcasm. The computer vision problem of sarcasm recognition in conversation\naims to identify hidden sarcastic, criticizing, and metaphorical information\nembedded in everyday dialogue. Prior, sarcasm recognition has focused mainly on\ntext. Still, it is critical to consider all textual information, audio stream,\nfacial expression, and body position for reliable sarcasm identification.\nHence, we propose a novel approach that combines a lightweight depth attention\nmodule with a self-regulated ConvNet to concentrate on the most crucial\nfeatures of visual data and an attentional tokenizer based strategy to extract\nthe most critical context-specific information from the textual data. The\nfollowing is a list of the key contributions that our experimentation has made\nin response to performing the task of Multi-modal Sarcasm Recognition: an\nattentional tokenizer branch to get beneficial features from the glossary\ncontent provided by the subtitles; a visual branch for acquiring the most\nprominent features from the video frames; an utterance-level feature extraction\nfrom acoustic content and a multi-headed attention based feature fusion branch\nto blend features obtained from multiple modalities. Extensive testing on one\nof the benchmark video datasets, MUSTaRD, yielded an accuracy of 79.86% for\nspeaker dependent and 76.94% for speaker independent configuration\ndemonstrating that our approach is superior to the existing methods. We have\nalso conducted a cross-dataset analysis to test the adaptability of VyAnG-Net\nwith unseen samples of another dataset MUStARD++.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10246v1",
    "published_date": "2024-08-05 15:36:52 UTC",
    "updated_date": "2024-08-05 15:36:52 UTC"
  },
  {
    "arxiv_id": "2408.02559v1",
    "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information",
    "authors": [
      "Yauwai Yim",
      "Chunkit Chan",
      "Tianyu Shi",
      "Zheye Deng",
      "Wei Fan",
      "Tianshi Zheng",
      "Yangqiu Song"
    ],
    "abstract": "Large language models (LLMs) have shown success in handling simple games with\nimperfect information and enabling multi-agent coordination, but their ability\nto facilitate practical collaboration against other agents in complex,\nimperfect information environments, especially in a non-English environment,\nstill needs to be explored. This study investigates the applicability of\nknowledge acquired by open-source and API-based LLMs to sophisticated\ntext-based games requiring agent collaboration under imperfect information,\ncomparing their performance to established baselines using other types of\nagents. We propose a Theory of Mind (ToM) planning technique that allows LLM\nagents to adapt their strategy against various adversaries using only game\nrules, current state, and historical context as input. An external tool was\nincorporated to mitigate the challenge of dynamic and extensive action spaces\nin this card game. Our results show that although a performance gap exists\nbetween current LLMs and state-of-the-art reinforcement learning (RL) models,\nLLMs demonstrate ToM capabilities in this game setting. It consistently\nimproves their performance against opposing agents, suggesting their ability to\nunderstand the actions of allies and adversaries and establish collaboration\nwith allies. To encourage further research and understanding, we have made our\ncodebase openly accessible.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02559v1",
    "published_date": "2024-08-05 15:36:46 UTC",
    "updated_date": "2024-08-05 15:36:46 UTC"
  },
  {
    "arxiv_id": "2408.02555v3",
    "title": "MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization",
    "authors": [
      "Yiwen Chen",
      "Yikai Wang",
      "Yihao Luo",
      "Zhengyi Wang",
      "Zilong Chen",
      "Jun Zhu",
      "Chi Zhang",
      "Guosheng Lin"
    ],
    "abstract": "Meshes are the de facto 3D representation in the industry but are\nlabor-intensive to produce. Recently, a line of research has focused on\nautoregressively generating meshes. This approach processes meshes into a\nsequence composed of vertices and then generates them vertex by vertex, similar\nto how a language model generates text. These methods have achieved some\nsuccess but still struggle to generate complex meshes. One primary reason for\nthis limitation is their inefficient tokenization methods. To address this\nissue, we introduce MeshAnything V2, an advanced mesh generation model designed\nto create Artist-Created Meshes that align precisely with specified shapes. A\nkey innovation behind MeshAnything V2 is our novel Adjacent Mesh Tokenization\n(AMT) method. Unlike traditional approaches that represent each face using\nthree vertices, AMT optimizes this by employing a single vertex wherever\nfeasible, effectively reducing the token sequence length by about half on\naverage. This not only streamlines the tokenization process but also results in\nmore compact and well-structured sequences, enhancing the efficiency of mesh\ngeneration. With these improvements, MeshAnything V2 effectively doubles the\nface limit compared to previous models, delivering superior performance without\nincreasing computational costs. We will make our code and models publicly\navailable. Project Page: https://buaacyw.github.io/meshanything-v2/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://buaacyw.github.io/meshanything-v2/ Github:\n  https://github.com/buaacyw/MeshAnythingV2",
    "pdf_url": "http://arxiv.org/pdf/2408.02555v3",
    "published_date": "2024-08-05 15:33:45 UTC",
    "updated_date": "2024-12-01 14:34:01 UTC"
  },
  {
    "arxiv_id": "2408.02547v1",
    "title": "The Role of Functional Muscle Networks in Improving Hand Gesture Perception for Human-Machine Interfaces",
    "authors": [
      "Costanza Armanini",
      "Tuka Alhanai",
      "Farah E. Shamout",
      "S. Farokh Atashzar"
    ],
    "abstract": "Developing accurate hand gesture perception models is critical for various\nrobotic applications, enabling effective communication between humans and\nmachines and directly impacting neurorobotics and interactive robots. Recently,\nsurface electromyography (sEMG) has been explored for its rich informational\ncontext and accessibility when combined with advanced machine learning\napproaches and wearable systems. The literature presents numerous approaches to\nboost performance while ensuring robustness for neurorobots using sEMG, often\nresulting in models requiring high processing power, large datasets, and less\nscalable solutions. This paper addresses this challenge by proposing the\ndecoding of muscle synchronization rather than individual muscle activation. We\nstudy coherence-based functional muscle networks as the core of our perception\nmodel, proposing that functional synchronization between muscles and the\ngraph-based network of muscle connectivity encode contextual information about\nintended hand gestures. This can be decoded using shallow machine learning\napproaches without the need for deep temporal networks. Our technique could\nimpact myoelectric control of neurorobots by reducing computational burdens and\nenhancing efficiency. The approach is benchmarked on the Ninapro database,\nwhich contains 12 EMG signals from 40 subjects performing 17 hand gestures. It\nachieves an accuracy of 85.1%, demonstrating improved performance compared to\nexisting methods while requiring much less computational power. The results\nsupport the hypothesis that a coherence-based functional muscle network encodes\ncritical information related to gesture execution, significantly enhancing hand\ngesture perception with potential applications for neurorobotic systems and\ninteractive machines.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02547v1",
    "published_date": "2024-08-05 15:17:34 UTC",
    "updated_date": "2024-08-05 15:17:34 UTC"
  },
  {
    "arxiv_id": "2408.02545v1",
    "title": "RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation",
    "authors": [
      "Daniel Fleischer",
      "Moshe Berchansky",
      "Moshe Wasserblat",
      "Peter Izsak"
    ],
    "abstract": "Implementing Retrieval-Augmented Generation (RAG) systems is inherently\ncomplex, requiring deep understanding of data, use cases, and intricate design\ndecisions. Additionally, evaluating these systems presents significant\nchallenges, necessitating assessment of both retrieval accuracy and generative\nquality through a multi-faceted approach. We introduce RAG Foundry, an\nopen-source framework for augmenting large language models for RAG use cases.\nRAG Foundry integrates data creation, training, inference and evaluation into a\nsingle workflow, facilitating the creation of data-augmented datasets for\ntraining and evaluating large language models in RAG settings. This integration\nenables rapid prototyping and experimentation with various RAG techniques,\nallowing users to easily generate datasets and train RAG models using internal\nor specialized knowledge sources. We demonstrate the framework effectiveness by\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\nconfigurations, showcasing consistent improvements across three\nknowledge-intensive datasets. Code is released as open-source in\nhttps://github.com/IntelLabs/RAGFoundry.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.02545v1",
    "published_date": "2024-08-05 15:16:24 UTC",
    "updated_date": "2024-08-05 15:16:24 UTC"
  },
  {
    "arxiv_id": "2408.02529v2",
    "title": "Explaining Reinforcement Learning: A Counterfactual Shapley Values Approach",
    "authors": [
      "Yiwei Shi",
      "Qi Zhang",
      "Kevin McAreavey",
      "Weiru Liu"
    ],
    "abstract": "This paper introduces a novel approach Counterfactual Shapley Values (CSV),\nwhich enhances explainability in reinforcement learning (RL) by integrating\ncounterfactual analysis with Shapley Values. The approach aims to quantify and\ncompare the contributions of different state dimensions to various action\nchoices. To more accurately analyze these impacts, we introduce new\ncharacteristic value functions, the ``Counterfactual Difference Characteristic\nValue\" and the ``Average Counterfactual Difference Characteristic Value.\" These\nfunctions help calculate the Shapley values to evaluate the differences in\ncontributions between optimal and non-optimal actions. Experiments across\nseveral RL domains, such as GridWorld, FrozenLake, and Taxi, demonstrate the\neffectiveness of the CSV method. The results show that this method not only\nimproves transparency in complex RL systems but also quantifies the differences\nacross various decisions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02529v2",
    "published_date": "2024-08-05 14:49:12 UTC",
    "updated_date": "2024-08-06 07:32:02 UTC"
  },
  {
    "arxiv_id": "2408.02525v1",
    "title": "Single-tap Latency Reduction with Single- or Double- tap Prediction",
    "authors": [
      "Naoto Nishida",
      "Kaori Ikematsu",
      "Junichi Sato",
      "Shota Yamanaka",
      "Kota Tsubouchi"
    ],
    "abstract": "Touch surfaces are widely utilized for smartphones, tablet PCs, and laptops\n(touchpad), and single and double taps are the most basic and common operations\non them. The detection of single or double taps causes the single-tap latency\nproblem, which creates a bottleneck in terms of the sensitivity of touch\ninputs. To reduce the single-tap latency, we propose a novel\nmachine-learning-based tap prediction method called PredicTaps. Our method\npredicts whether a detected tap is a single tap or the first contact of a\ndouble tap without having to wait for the hundreds of milliseconds\nconventionally required. We present three evaluations and one user evaluation\nthat demonstrate its broad applicability and usability for various tap\nsituations on two form factors (touchpad and smartphone). The results showed\nPredicTaps reduces the single-tap latency from 150-500 ms to 12 ms on laptops\nand to 17.6 ms on smartphones without reducing usability.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02525v1",
    "published_date": "2024-08-05 14:46:04 UTC",
    "updated_date": "2024-08-05 14:46:04 UTC"
  },
  {
    "arxiv_id": "2408.04658v1",
    "title": "Winning Amazon KDD Cup'24",
    "authors": [
      "Chris Deotte",
      "Ivan Sorokin",
      "Ahmet Erdem",
      "Benedikt Schifferer",
      "Gilberto Titericz Jr",
      "Simon Jegou"
    ],
    "abstract": "This paper describes the winning solution of all 5 tasks for the Amazon KDD\nCup 2024 Multi Task Online Shopping Challenge for LLMs. The challenge was to\nbuild a useful assistant, answering questions in the domain of online shopping.\nThe competition contained 57 diverse tasks, covering 5 different task types\n(e.g. multiple choice) and across 4 different tracks (e.g. multi-lingual). Our\nsolution is a single model per track. We fine-tune Qwen2-72B-Instruct on our\nown training dataset. As the competition released only 96 example questions, we\ndeveloped our own training dataset by processing multiple public datasets or\nusing Large Language Models for data augmentation and synthetic data\ngeneration. We apply wise-ft to account for distribution shifts and ensemble\nmultiple LoRA adapters in one model. We employed Logits Processors to constrain\nthe model output on relevant tokens for the tasks. AWQ 4-bit Quantization and\nvLLM are used during inference to predict the test dataset in the time\nconstraints of 20 to 140 minutes depending on the track. Our solution achieved\nthe first place in each individual track and is the first place overall of\nAmazons KDD Cup 2024.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04658v1",
    "published_date": "2024-08-05 14:40:04 UTC",
    "updated_date": "2024-08-05 14:40:04 UTC"
  },
  {
    "arxiv_id": "2408.02714v1",
    "title": "MDM: Advancing Multi-Domain Distribution Matching for Automatic Modulation Recognition Dataset Synthesis",
    "authors": [
      "Dongwei Xu",
      "Jiajun Chen",
      "Yao Lu",
      "Tianhao Xia",
      "Qi Xuan",
      "Wei Wang",
      "Yun Lin",
      "Xiaoniu Yang"
    ],
    "abstract": "Recently, deep learning technology has been successfully introduced into\nAutomatic Modulation Recognition (AMR) tasks. However, the success of deep\nlearning is all attributed to the training on large-scale datasets. Such a\nlarge amount of data brings huge pressure on storage, transmission and model\ntraining. In order to solve the problem of large amount of data, some\nresearchers put forward the method of data distillation, which aims to compress\nlarge training data into smaller synthetic datasets to maintain its\nperformance. While numerous data distillation techniques have been developed\nwithin the realm of image processing, the unique characteristics of signals set\nthem apart. Signals exhibit distinct features across various domains,\nnecessitating specialized approaches for their analysis and processing. To this\nend, a novel dataset distillation method--Multi-domain Distribution Matching\n(MDM) is proposed. MDM employs the Discrete Fourier Transform (DFT) to\ntranslate timedomain signals into the frequency domain, and then uses a model\nto compute distribution matching losses between the synthetic and real\ndatasets, considering both the time and frequency domains. Ultimately, these\ntwo losses are integrated to update the synthetic dataset. We conduct extensive\nexperiments on three AMR datasets. Experimental results show that, compared\nwith baseline methods, our method achieves better performance under the same\ncompression ratio. Furthermore, we conduct crossarchitecture generalization\nexperiments on several models, and the experimental results show that our\nsynthetic datasets can generalize well on other unseen models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02714v1",
    "published_date": "2024-08-05 14:16:54 UTC",
    "updated_date": "2024-08-05 14:16:54 UTC"
  },
  {
    "arxiv_id": "2408.02487v3",
    "title": "LiCoEval: Evaluating LLMs on License Compliance in Code Generation",
    "authors": [
      "Weiwei Xu",
      "Kai Gao",
      "Hao He",
      "Minghui Zhou"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have revolutionized code\ngeneration, leading to widespread adoption of AI coding tools by developers.\nHowever, LLMs can generate license-protected code without providing the\nnecessary license information, leading to potential intellectual property\nviolations during software production. This paper addresses the critical, yet\nunderexplored, issue of license compliance in LLM-generated code by\nestablishing a benchmark to evaluate the ability of LLMs to provide accurate\nlicense information for their generated code. To establish this benchmark, we\nconduct an empirical study to identify a reasonable standard for \"striking\nsimilarity\" that excludes the possibility of independent creation, indicating a\ncopy relationship between the LLM output and certain open-source code. Based on\nthis standard, we propose LiCoEval, to evaluate the license compliance\ncapabilities of LLMs, i.e., the ability to provide accurate license or\ncopyright information when they generate code with striking similarity to\nalready existing copyrighted code. Using LiCoEval, we evaluate 14 popular LLMs,\nfinding that even top-performing LLMs produce a non-negligible proportion\n(0.88% to 2.01%) of code strikingly similar to existing open-source\nimplementations. Notably, most LLMs fail to provide accurate license\ninformation, particularly for code under copyleft licenses. These findings\nunderscore the urgent need to enhance LLM compliance capabilities in code\ngeneration tasks. Our study provides a foundation for future research and\ndevelopment to improve license compliance in AI-assisted software development,\ncontributing to both the protection of open-source software copyrights and the\nmitigation of legal risks for LLM users.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "The 47th International Conference on Software Engineering(ICSE 2025)",
    "pdf_url": "http://arxiv.org/pdf/2408.02487v3",
    "published_date": "2024-08-05 14:09:30 UTC",
    "updated_date": "2025-02-25 08:58:05 UTC"
  },
  {
    "arxiv_id": "2408.02713v1",
    "title": "A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality",
    "authors": [
      "Zheng Han",
      "Qi Dou"
    ],
    "abstract": "Augmented Reality (AR) holds the potential to revolutionize surgical\nprocedures by allowing surgeons to visualize critical structures within the\npatient's body. This is achieved through superimposing preoperative organ\nmodels onto the actual anatomy. Challenges arise from dynamic deformations of\norgans during surgery, making preoperative models inadequate for faithfully\nrepresenting intraoperative anatomy. To enable reliable navigation in augmented\nsurgery, modeling of intraoperative deformation to obtain an accurate alignment\nof the preoperative organ model with the intraoperative anatomy is\nindispensable. Despite the existence of various methods proposed to model\nintraoperative organ deformation, there are still few literature reviews that\nsystematically categorize and summarize these approaches. This review aims to\nfill this gap by providing a comprehensive and technical-oriented overview of\nmodeling methods for intraoperative organ deformation in augmented reality in\nsurgery. Through a systematic search and screening process, 112 closely\nrelevant papers were included in this review. By presenting the current status\nof organ deformation modeling methods and their clinical applications, this\nreview seeks to enhance the understanding of organ deformation modeling in\nAR-guided surgery, and discuss the potential topics for future advancements.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "cs.HC",
      "eess.IV"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02713v1",
    "published_date": "2024-08-05 14:03:17 UTC",
    "updated_date": "2024-08-05 14:03:17 UTC"
  },
  {
    "arxiv_id": "2408.02479v2",
    "title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future",
    "authors": [
      "Haolin Jin",
      "Linghan Huang",
      "Haipeng Cai",
      "Jun Yan",
      "Bo Li",
      "Huaming Chen"
    ],
    "abstract": "With the rise of large language models (LLMs), researchers are increasingly\nexploring their applications in var ious vertical domains, such as software\nengineering. LLMs have achieved remarkable success in areas including code\ngeneration and vulnerability detection. However, they also exhibit numerous\nlimitations and shortcomings. LLM-based agents, a novel tech nology with the\npotential for Artificial General Intelligence (AGI), combine LLMs as the core\nfor decision-making and action-taking, addressing some of the inherent\nlimitations of LLMs such as lack of autonomy and self-improvement. Despite\nnumerous studies and surveys exploring the possibility of using LLMs in\nsoftware engineering, it lacks a clear distinction between LLMs and LLM based\nagents. It is still in its early stage for a unified standard and benchmarking\nto qualify an LLM solution as an LLM-based agent in its domain. In this survey,\nwe broadly investigate the current practice and solutions for LLMs and\nLLM-based agents for software engineering. In particular we summarise six key\ntopics: requirement engineering, code generation, autonomous decision-making,\nsoftware design, test generation, and software maintenance. We review and\ndifferentiate the work of LLMs and LLM-based agents from these six topics,\nexamining their differences and similarities in tasks, benchmarks, and\nevaluation metrics. Finally, we discuss the models and benchmarks used,\nproviding a comprehensive analysis of their applications and effectiveness in\nsoftware engineering. We anticipate this work will shed some lights on pushing\nthe boundaries of LLM-based agents in software engineering for future research.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02479v2",
    "published_date": "2024-08-05 14:01:15 UTC",
    "updated_date": "2025-04-13 09:42:30 UTC"
  },
  {
    "arxiv_id": "2408.02712v1",
    "title": "Automatic Voice Identification after Speech Resynthesis using PPG",
    "authors": [
      "Thibault Gaudier",
      "Marie Tahon",
      "Anthony Larcher",
      "Yannick Estève"
    ],
    "abstract": "Speech resynthesis is a generic task for which we want to synthesize audio\nwith another audio as input, which finds applications for media monitors and\njournalists.Among different tasks addressed by speech resynthesis, voice\nconversion preserves the linguistic information while modifying the identity of\nthe speaker, and speech edition preserves the identity of the speaker but some\nwords are modified.In both cases, we need to disentangle speaker and phonetic\ncontents in intermediate representations.Phonetic PosteriorGrams (PPG) are a\nframe-level probabilistic representation of phonemes, and are usually\nconsidered speaker-independent.This paper presents a PPG-based speech\nresynthesis system.A perceptive evaluation assesses that it produces correct\naudio quality.Then, we demonstrate that an automatic speaker verification model\nis not able to recover the source speaker after re-synthesis with PPG, even\nwhen the model is trained on synthetic data.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.NE",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02712v1",
    "published_date": "2024-08-05 13:59:40 UTC",
    "updated_date": "2024-08-05 13:59:40 UTC"
  },
  {
    "arxiv_id": "2408.07080v1",
    "title": "DisCoM-KD: Cross-Modal Knowledge Distillation via Disentanglement Representation and Adversarial Learning",
    "authors": [
      "Dino Ienco",
      "Cassio Fraga Dantas"
    ],
    "abstract": "Cross-modal knowledge distillation (CMKD) refers to the scenario in which a\nlearning framework must handle training and test data that exhibit a modality\nmismatch, more precisely, training and test data do not cover the same set of\ndata modalities. Traditional approaches for CMKD are based on a teacher/student\nparadigm where a teacher is trained on multi-modal data with the aim to\nsuccessively distill knowledge from a multi-modal teacher to a single-modal\nstudent. Despite the widespread adoption of such paradigm, recent research has\nhighlighted its inherent limitations in the context of cross-modal knowledge\ntransfer.Taking a step beyond the teacher/student paradigm, here we introduce a\nnew framework for cross-modal knowledge distillation, named DisCoM-KD\n(Disentanglement-learning based Cross-Modal Knowledge Distillation), that\nexplicitly models different types of per-modality information with the aim to\ntransfer knowledge from multi-modal data to a single-modal classifier. To this\nend, DisCoM-KD effectively combines disentanglement representation learning\nwith adversarial domain adaptation to simultaneously extract, foreach modality,\ndomain-invariant, domain-informative and domain-irrelevant features according\nto a specific downstream task. Unlike the traditional teacher/student paradigm,\nour framework simultaneously learns all single-modal classifiers, eliminating\nthe need to learn each student model separately as well as the teacher\nclassifier. We evaluated DisCoM-KD on three standard multi-modal benchmarks and\ncompared its behaviourwith recent SOTA knowledge distillation frameworks. The\nfindings clearly demonstrate the effectiveness of DisCoM-KD over competitors\nconsidering mismatch scenarios involving both overlapping and non-overlapping\nmodalities. These results offer insights to reconsider the traditional paradigm\nfor distilling information from multi-modal data to single-modal neural\nnetworks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07080v1",
    "published_date": "2024-08-05 13:44:15 UTC",
    "updated_date": "2024-08-05 13:44:15 UTC"
  },
  {
    "arxiv_id": "2408.02462v1",
    "title": "An investigation into the causes of race bias in AI-based cine CMR segmentation",
    "authors": [
      "Tiarna Lee",
      "Esther Puyol-Anton",
      "Bram Ruijsink",
      "Sebastien Roujol",
      "Theodore Barfoot",
      "Shaheim Ogbomo-Harmitt",
      "Miaojing Shi",
      "Andrew P. King"
    ],
    "abstract": "Artificial intelligence (AI) methods are being used increasingly for the\nautomated segmentation of cine cardiac magnetic resonance (CMR) imaging.\nHowever, these methods have been shown to be subject to race bias, i.e. they\nexhibit different levels of performance for different races depending on the\n(im)balance of the data used to train the AI model. In this paper we\ninvestigate the source of this bias, seeking to understand its root cause(s) so\nthat it can be effectively mitigated. We perform a series of classification and\nsegmentation experiments on short-axis cine CMR images acquired from Black and\nWhite subjects from the UK Biobank and apply AI interpretability methods to\nunderstand the results. In the classification experiments, we found that race\ncan be predicted with high accuracy from the images alone, but less accurately\nfrom ground truth segmentations, suggesting that the distributional shift\nbetween races, which is often the cause of AI bias, is mostly image-based\nrather than segmentation-based. The interpretability methods showed that most\nattention in the classification models was focused on non-heart regions, such\nas subcutaneous fat. Cropping the images tightly around the heart reduced\nclassification accuracy to around chance level. Similarly, race can be\npredicted from the latent representations of a biased segmentation model,\nsuggesting that race information is encoded in the model. Cropping images\ntightly around the heart reduced but did not eliminate segmentation bias. We\nalso investigate the influence of possible confounders on the bias observed.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02462v1",
    "published_date": "2024-08-05 13:40:33 UTC",
    "updated_date": "2024-08-05 13:40:33 UTC"
  },
  {
    "arxiv_id": "2408.11826v1",
    "title": "Generative Organizational Behavior Simulation using Large Language Model based Autonomous Agents: A Holacracy Perspective",
    "authors": [
      "Chen Zhu",
      "Yihang Cheng",
      "Jingshuai Zhang",
      "Yusheng Qiu",
      "Sitao Xia",
      "Hengshu Zhu"
    ],
    "abstract": "In this paper, we present the technical details and periodic findings of our\nproject, CareerAgent, which aims to build a generative simulation framework for\na Holacracy organization using Large Language Model-based Autonomous Agents.\nSpecifically, the simulation framework includes three phases: construction,\nexecution, and evaluation, and it incorporates basic characteristics of\nindividuals, organizations, tasks, and meetings. Through our simulation, we\nobtained several interesting findings. At the organizational level, an increase\nin the average values of management competence and functional competence can\nreduce overall members' stress levels, but it negatively impacts deeper\norganizational performance measures such as average task completion. At the\nindividual level, both competences can improve members' work performance. From\nthe analysis of social networks, we found that highly competent members\nselectively participate in certain tasks and take on more responsibilities.\nOver time, small sub-communities form around these highly competent members\nwithin the holacracy. These findings contribute theoretically to the study of\norganizational science and provide practical insights for managers to\nunderstand the organization dynamics.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11826v1",
    "published_date": "2024-08-05 13:39:03 UTC",
    "updated_date": "2024-08-05 13:39:03 UTC"
  },
  {
    "arxiv_id": "2408.02456v1",
    "title": "Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach",
    "authors": [
      "Wanxu Wei",
      "Yitong Song",
      "Bin Yao"
    ],
    "abstract": "Knowledge graphs (KGs) play a vital role in enhancing search results and\nrecommendation systems. With the rapid increase in the size of the KGs, they\nare becoming inaccuracy and incomplete. This problem can be solved by the\nknowledge graph completion methods, of which graph attention network\n(GAT)-based methods stand out since their superior performance. However,\nexisting GAT-based knowledge graph completion methods often suffer from\noverfitting issues when dealing with heterogeneous knowledge graphs, primarily\ndue to the unbalanced number of samples. Additionally, these methods\ndemonstrate poor performance in predicting the tail (head) entity that shares\nthe same relation and head (tail) entity with others. To solve these problems,\nwe propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH\nincorporates two separate attention network modules that work synergistically\nto predict the missing entities. We also introduce novel encoding and feature\ntransformation approaches, enabling the robust performance of GATH in scenarios\nwith imbalanced samples. Comprehensive experiments are conducted to evaluate\nthe GATH's performance. Compared with the existing SOTA GAT-based model on\nHits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the\nFB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02456v1",
    "published_date": "2024-08-05 13:28:51 UTC",
    "updated_date": "2024-08-05 13:28:51 UTC"
  },
  {
    "arxiv_id": "2408.05237v1",
    "title": "Biomimetic Machine Learning approach for prediction of mechanical properties of Additive Friction Stir Deposited Aluminum alloys based walled structures",
    "authors": [
      "Akshansh Mishra"
    ],
    "abstract": "This study presents a novel approach to predicting mechanical properties of\nAdditive Friction Stir Deposited (AFSD) aluminum alloy walled structures using\nbiomimetic machine learning. The research combines numerical modeling of the\nAFSD process with genetic algorithm-optimized machine learning models to\npredict von Mises stress and logarithmic strain. Finite element analysis was\nemployed to simulate the AFSD process for five aluminum alloys: AA2024, AA5083,\nAA5086, AA7075, and AA6061, capturing complex thermal and mechanical\ninteractions. A dataset of 200 samples was generated from these simulations.\nSubsequently, Decision Tree (DT) and Random Forest (RF) regression models,\noptimized using genetic algorithms, were developed to predict key mechanical\nproperties. The GA-RF model demonstrated superior performance in predicting\nboth von Mises stress (R square = 0.9676) and logarithmic strain (R square =\n0.7201). This innovative approach provides a powerful tool for understanding\nand optimizing the AFSD process across multiple aluminum alloys, offering\ninsights into material behavior under various process parameters.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 14 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.05237v1",
    "published_date": "2024-08-05 13:27:54 UTC",
    "updated_date": "2024-08-05 13:27:54 UTC"
  },
  {
    "arxiv_id": "2408.02711v1",
    "title": "Text Conditioned Symbolic Drumbeat Generation using Latent Diffusion Models",
    "authors": [
      "Pushkar Jajoria",
      "James McDermott"
    ],
    "abstract": "This study introduces a text-conditioned approach to generating drumbeats\nwith Latent Diffusion Models (LDMs). It uses informative conditioning text\nextracted from training data filenames. By pretraining a text and drumbeat\nencoder through contrastive learning within a multimodal network, aligned\nfollowing CLIP, we align the modalities of text and music closely.\nAdditionally, we examine an alternative text encoder based on multihot text\nencodings. Inspired by musics multi-resolution nature, we propose a novel LSTM\nvariant, MultiResolutionLSTM, designed to operate at various resolutions\nindependently. In common with recent LDMs in the image space, it speeds up the\ngeneration process by running diffusion in a latent space provided by a\npretrained unconditional autoencoder. We demonstrate the originality and\nvariety of the generated drumbeats by measuring distance (both over binary\npianorolls and in the latent space) versus the training dataset and among the\ngenerated drumbeats. We also assess the generated drumbeats through a listening\ntest focused on questions of quality, aptness for the prompt text, and novelty.\nWe show that the generated drumbeats are novel and apt to the prompt text, and\ncomparable in quality to those created by human musicians.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02711v1",
    "published_date": "2024-08-05 13:23:05 UTC",
    "updated_date": "2024-08-05 13:23:05 UTC"
  },
  {
    "arxiv_id": "2408.02439v1",
    "title": "Long Input Benchmark for Russian Analysis",
    "authors": [
      "Igor Churin",
      "Murat Apishev",
      "Maria Tikhonova",
      "Denis Shevelev",
      "Aydar Bulatov",
      "Yuri Kuratov",
      "Sergej Averkiev",
      "Alena Fenogenova"
    ],
    "abstract": "Recent advancements in Natural Language Processing (NLP) have fostered the\ndevelopment of Large Language Models (LLMs) that can solve an immense variety\nof tasks. One of the key aspects of their application is their ability to work\nwith long text documents and to process long sequences of tokens. This has\ncreated a demand for proper evaluation of long-context understanding. To\naddress this need for the Russian language, we propose LIBRA (Long Input\nBenchmark for Russian Analysis), which comprises 21 adapted datasets to study\nthe LLM's abilities to understand long texts thoroughly. The tests are divided\ninto four complexity groups and allow the evaluation of models across various\ncontext lengths ranging from 4k up to 128k tokens. We provide the open-source\ndatasets, codebase, and public leaderboard for LIBRA to guide forthcoming\nresearch.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02439v1",
    "published_date": "2024-08-05 12:59:35 UTC",
    "updated_date": "2024-08-05 12:59:35 UTC"
  },
  {
    "arxiv_id": "2408.02709v1",
    "title": "Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns",
    "authors": [
      "Chi Him Ng"
    ],
    "abstract": "This study analyzes hybrid AI systems' design patterns and their\neffectiveness in clinical decision-making using the boxology framework. It\ncategorizes and copares various architectures combining machine learning and\nrule-based reasoning to provide insights into their structural foundations and\nhealthcare applications. Addressing two main questions, how to categorize these\nsystems againts established design patterns and how to extract insights through\ncomparative analysis, the study uses design patterns from software engineering\nto understand and optimize healthcare AI systems. Boxology helps identify\ncommonalities and create reusable solutions, enhancing these systems'\nscalability, reliability, and performance. Five primary architectures are\nexamined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and\nweaknesses, highlighting the need for tailored approaches in clinical tasks.\nREML excels in high-accuracy prediction for datasets with limited data; MLRB in\nhandling large datasets and complex data integration; RBML in explainability\nand trustworthiness; RMLT in managing high-dimensional data; and PERML, though\nlimited in analysis, shows promise in urgent care scenarios. The study\nintroduces four new patterns, creates five abstract categorization patterns,\nand refines those five further to specific systems. These contributions enhance\nBoxlogy's taxonomical organization and offer novel approaches to integrating\nexpert knowledge with machine learning. Boxology's structured, modular apporach\noffers significant advantages in developing and analyzing hybrid AI systems,\nrevealing commonalities, and promoting reusable solutions. In conclusion, this\nstudy underscores hybrid AI systems' crucial role in advancing healthcare and\nBoxology's potential to drive further innovation in AI integration, ultimately\nimproving clinical decision support and patient outcomes.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02709v1",
    "published_date": "2024-08-05 12:53:04 UTC",
    "updated_date": "2024-08-05 12:53:04 UTC"
  },
  {
    "arxiv_id": "2408.02412v1",
    "title": "PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy",
    "authors": [
      "Rachmad Vidya Wicaksana Putra",
      "Muhammad Abdullah Hanif",
      "Muhammad Shafique"
    ],
    "abstract": "Convolutional Neural Networks (CNNs), a prominent type of Deep Neural\nNetworks (DNNs), have emerged as a state-of-the-art solution for solving\nmachine learning tasks. To improve the performance and energy efficiency of CNN\ninference, the employment of specialized hardware accelerators is prevalent.\nHowever, CNN accelerators still face performance- and energy-efficiency\nchallenges due to high off-chip memory (DRAM) access latency and energy, which\nare especially crucial for latency- and energy-constrained embedded\napplications. Moreover, different DRAM architectures have different profiles of\naccess latency and energy, thus making it challenging to optimize them for high\nperformance and energy-efficient CNN accelerators. To address this, we present\nPENDRAM, a novel design space exploration methodology that enables\nhigh-performance and energy-efficient CNN acceleration through a generalized\nDRAM data mapping policy. Specifically, it explores the impact of different\nDRAM data mapping policies and DRAM architectures across different CNN\npartitioning and scheduling schemes on the DRAM access latency and energy, then\nidentifies the pareto-optimal design choices. The experimental results show\nthat our DRAM data mapping policy improves the energy-delay-product of DRAM\naccesses in the CNN accelerator over other mapping policies by up to 96%. In\nthis manner, our PENDRAM methodology offers high-performance and\nenergy-efficient CNN acceleration under any given DRAM architectures for\ndiverse embedded AI applications.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AR",
    "comment": "11 pages, 15 figures, 2 tables. arXiv admin note: substantial text\n  overlap with arXiv:2004.10341",
    "pdf_url": "http://arxiv.org/pdf/2408.02412v1",
    "published_date": "2024-08-05 12:11:09 UTC",
    "updated_date": "2024-08-05 12:11:09 UTC"
  },
  {
    "arxiv_id": "2408.02408v2",
    "title": "Multi-weather Cross-view Geo-localization Using Denoising Diffusion Models",
    "authors": [
      "Tongtong Feng",
      "Qing Li",
      "Xin Wang",
      "Mingzi Wang",
      "Guangyao Li",
      "Wenwu Zhu"
    ],
    "abstract": "Cross-view geo-localization in GNSS-denied environments aims to determine an\nunknown location by matching drone-view images with the correct geo-tagged\nsatellite-view images from a large gallery. Recent research shows that learning\ndiscriminative image representations under specific weather conditions can\nsignificantly enhance performance. However, the frequent occurrence of unseen\nextreme weather conditions hinders progress. This paper introduces MCGF, a\nMulti-weather Cross-view Geo-localization Framework designed to dynamically\nadapt to unseen weather conditions. MCGF establishes a joint optimization\nbetween image restoration and geo-localization using denoising diffusion\nmodels. For image restoration, MCGF incorporates a shared encoder and a\nlightweight restoration module to help the backbone eliminate weather-specific\ninformation. For geo-localization, MCGF uses EVA-02 as a backbone for feature\nextraction, with cross-entropy loss for training and cosine distance for\ntesting. Extensive experiments on University160k-WX demonstrate that MCGF\nachieves competitive results for geo-localization in varying weather\nconditions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM MM24 workshop",
    "pdf_url": "http://arxiv.org/pdf/2408.02408v2",
    "published_date": "2024-08-05 12:09:38 UTC",
    "updated_date": "2024-08-28 02:53:22 UTC"
  },
  {
    "arxiv_id": "2408.02707v1",
    "title": "SnapE -- Training Snapshot Ensembles of Link Prediction Models",
    "authors": [
      "Ali Shaban",
      "Heiko Paulheim"
    ],
    "abstract": "Snapshot ensembles have been widely used in various fields of prediction.\nThey allow for training an ensemble of prediction models at the cost of\ntraining a single one. They are known to yield more robust predictions by\ncreating a set of diverse base models. In this paper, we introduce an approach\nto transfer the idea of snapshot ensembles to link prediction models in\nknowledge graphs. Moreover, since link prediction in knowledge graphs is a\nsetup without explicit negative examples, we propose a novel training loop that\niteratively creates negative examples using previous snapshot models. An\nevaluation with four base models across four datasets shows that this approach\nconstantly outperforms the single model approach, while keeping the training\ntime constant.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at International Semantic Web Conference (ISWC) 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.02707v1",
    "published_date": "2024-08-05 12:02:10 UTC",
    "updated_date": "2024-08-05 12:02:10 UTC"
  },
  {
    "arxiv_id": "2408.02402v3",
    "title": "Enhancing AI-based Generation of Software Exploits with Contextual Information",
    "authors": [
      "Pietro Liguori",
      "Cristina Improta",
      "Roberto Natella",
      "Bojan Cukic",
      "Domenico Cotroneo"
    ],
    "abstract": "This practical experience report explores Neural Machine Translation (NMT)\nmodels' capability to generate offensive security code from natural language\n(NL) descriptions, highlighting the significance of contextual understanding\nand its impact on model performance. Our study employs a dataset comprising\nreal shellcodes to evaluate the models across various scenarios, including\nmissing information, necessary context, and unnecessary context. The\nexperiments are designed to assess the models' resilience against incomplete\ndescriptions, their proficiency in leveraging context for enhanced accuracy,\nand their ability to discern irrelevant information. The findings reveal that\nthe introduction of contextual data significantly improves performance.\nHowever, the benefits of additional context diminish beyond a certain point,\nindicating an optimal level of contextual information for model training.\nMoreover, the models demonstrate an ability to filter out unnecessary context,\nmaintaining high levels of accuracy in the generation of offensive security\ncode. This study paves the way for future research on optimizing context use in\nAI-driven code generation, particularly for applications requiring a high\ndegree of technical precision such as the generation of offensive code.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication at The 35th IEEE International Symposium on\n  Software Reliability Engineering",
    "pdf_url": "http://arxiv.org/pdf/2408.02402v3",
    "published_date": "2024-08-05 11:52:34 UTC",
    "updated_date": "2024-09-06 12:51:35 UTC"
  },
  {
    "arxiv_id": "2408.04655v2",
    "title": "Strong and weak alignment of large language models with human values",
    "authors": [
      "Mehdi Khamassi",
      "Marceau Nahon",
      "Raja Chatila"
    ],
    "abstract": "Minimizing negative impacts of Artificial Intelligent (AI) systems on human\nsocieties without human supervision requires them to be able to align with\nhuman values. However, most current work only addresses this issue from a\ntechnical point of view, e.g., improving current methods relying on\nreinforcement learning from human feedback, neglecting what it means and is\nrequired for alignment to occur. Here, we propose to distinguish strong and\nweak value alignment. Strong alignment requires cognitive abilities (either\nhuman-like or different from humans) such as understanding and reasoning about\nagents' intentions and their ability to causally produce desired effects. We\nargue that this is required for AI systems like large language models (LLMs) to\nbe able to recognize situations presenting a risk that human values may be\nflouted. To illustrate this distinction, we present a series of prompts showing\nChatGPT's, Gemini's and Copilot's failures to recognize some of these\nsituations. We moreover analyze word embeddings to show that the nearest\nneighbors of some human values in LLMs differ from humans' semantic\nrepresentations. We then propose a new thought experiment that we call \"the\nChinese room with a word transition dictionary\", in extension of John Searle's\nfamous proposal. We finally mention current promising research directions\ntowards a weak alignment, which could produce statistically satisfying answers\nin a number of common situations, however so far without ensuring any truth\nvalue.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication in Scientific Reports, special issue on AI\n  aligment",
    "pdf_url": "http://arxiv.org/pdf/2408.04655v2",
    "published_date": "2024-08-05 11:27:51 UTC",
    "updated_date": "2024-08-12 13:20:36 UTC"
  },
  {
    "arxiv_id": "2408.02380v1",
    "title": "Perfect Information Monte Carlo with Postponing Reasoning",
    "authors": [
      "Jérôme Arjonilla",
      "Abdallah Saffidine",
      "Tristan Cazenave"
    ],
    "abstract": "Imperfect information games, such as Bridge and Skat, present challenges due\nto state-space explosion and hidden information, posing formidable obstacles\nfor search algorithms. Determinization-based algorithms offer a resolution by\nsampling hidden information and solving the game in a perfect information\nsetting, facilitating rapid and effective action estimation. However,\ntransitioning to perfect information introduces challenges, notably one called\nstrategy fusion.This research introduces `Extended Perfect Information Monte\nCarlo' (EPIMC), an online algorithm inspired by the state-of-the-art\ndeterminization-based approach Perfect Information Monte Carlo (PIMC). EPIMC\nenhances the capabilities of PIMC by postponing the perfect information\nresolution, reducing alleviating issues related to strategy fusion. However,\nthe decision to postpone the leaf evaluator introduces novel considerations,\nsuch as the interplay between prior levels of reasoning and the newly deferred\nresolution. In our empirical analysis, we investigate the performance of EPIMC\nacross a range of games, with a particular focus on those characterized by\nvarying degrees of strategy fusion. Our results demonstrate notable performance\nenhancements, particularly in games where strategy fusion significantly impacts\ngameplay. Furthermore, our research contributes to the theoretical foundation\nof determinization-based algorithms addressing challenges associated with\nstrategy fusion.%, thereby enhancing our understanding of these algorithms\nwithin the context of imperfect information game scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in IEEE Conference on Games (CoG) 2024 + Appendix",
    "pdf_url": "http://arxiv.org/pdf/2408.02380v1",
    "published_date": "2024-08-05 11:12:48 UTC",
    "updated_date": "2024-08-05 11:12:48 UTC"
  },
  {
    "arxiv_id": "2408.02377v1",
    "title": "A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models",
    "authors": [
      "Vanni Zavarella",
      "Juan Carlos Gamero-Salinas",
      "Sergio Consoli"
    ],
    "abstract": "Knowledge graphs (KGs) have been successfully applied to the analysis of\ncomplex scientific and technological domains, with automatic KG generation\nmethods typically building upon relation extraction models capturing\nfine-grained relations between domain entities in text. While these relations\nare fully applicable across scientific areas, existing models are trained on\nfew domain-specific datasets such as SciERC and do not perform well on new\ntarget domains. In this paper, we experiment with leveraging in-context\nlearning capabilities of Large Language Models to perform schema-constrained\ndata annotation, collecting in-domain training instances for a\nTransformer-based relation extraction model deployed on titles and abstracts of\nresearch papers in the Architecture, Construction, Engineering and Operations\n(AECO) domain. By assessing the performance gain with respect to a baseline\nDeep Learning architecture trained on off-domain data, we show that by using a\nfew-shot learning strategy with structured prompts and only minimal expert\nannotation the presented approach can potentially support domain adaptation of\na science KG generation model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02377v1",
    "published_date": "2024-08-05 11:06:36 UTC",
    "updated_date": "2024-08-05 11:06:36 UTC"
  },
  {
    "arxiv_id": "2408.02373v2",
    "title": "Operationalizing Contextual Integrity in Privacy-Conscious Assistants",
    "authors": [
      "Sahra Ghalebikesabi",
      "Eugene Bagdasaryan",
      "Ren Yi",
      "Itay Yona",
      "Ilia Shumailov",
      "Aneesh Pappu",
      "Chongyang Shi",
      "Laura Weidinger",
      "Robert Stanforth",
      "Leonard Berrada",
      "Pushmeet Kohli",
      "Po-Sen Huang",
      "Borja Balle"
    ],
    "abstract": "Advanced AI assistants combine frontier LLMs and tool access to autonomously\nperform complex tasks on behalf of users. While the helpfulness of such\nassistants can increase dramatically with access to user information including\nemails and documents, this raises privacy concerns about assistants sharing\ninappropriate information with third parties without user supervision. To steer\ninformation-sharing assistants to behave in accordance with privacy\nexpectations, we propose to operationalize contextual integrity (CI), a\nframework that equates privacy with the appropriate flow of information in a\ngiven context. In particular, we design and evaluate a number of strategies to\nsteer assistants' information-sharing actions to be CI compliant. Our\nevaluation is based on a novel form filling benchmark composed of human\nannotations of common webform applications, and it reveals that prompting\nfrontier LLMs to perform CI-based reasoning yields strong results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02373v2",
    "published_date": "2024-08-05 10:53:51 UTC",
    "updated_date": "2024-09-13 13:09:41 UTC"
  },
  {
    "arxiv_id": "2408.02706v1",
    "title": "Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability",
    "authors": [
      "Masoud Muhammed Hassan"
    ],
    "abstract": "Because of its strong predictive skills, deep learning has emerged as an\nessential tool in many industries, including healthcare. Traditional deep\nlearning models, on the other hand, frequently lack interpretability and omit\nto take prediction uncertainty into account two crucial components of clinical\ndecision making. In order to produce explainable and uncertainty aware\npredictions, this study presents a novel framework called Bayesian Kolmogorov\nArnold Networks (BKANs), which combines the expressive capacity of Kolmogorov\nArnold Networks with Bayesian inference. We employ BKANs on two medical\ndatasets, which are widely used benchmarks for assessing machine learning\nmodels in medical diagnostics: the Pima Indians Diabetes dataset and the\nCleveland Heart Disease dataset. Our method provides useful insights into\nprediction confidence and decision boundaries and outperforms traditional deep\nlearning models in terms of prediction accuracy. Moreover, BKANs' capacity to\nrepresent aleatoric and epistemic uncertainty guarantees doctors receive more\nsolid and trustworthy decision support. Our Bayesian strategy improves the\ninterpretability of the model and considerably minimises overfitting, which is\nimportant for tiny and imbalanced medical datasets, according to experimental\nresults. We present possible expansions to further use BKANs in more\ncomplicated multimodal datasets and address the significance of these\ndiscoveries for future research in building reliable AI systems for healthcare.\nThis work paves the way for a new paradigm in deep learning model deployment in\nvital sectors where transparency and reliability are crucial.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02706v1",
    "published_date": "2024-08-05 10:38:34 UTC",
    "updated_date": "2024-08-05 10:38:34 UTC"
  },
  {
    "arxiv_id": "2408.02705v1",
    "title": "PSNE: Efficient Spectral Sparsification Algorithms for Scaling Network Embedding",
    "authors": [
      "Longlong Lin",
      "Yunfeng Yu",
      "Zihao Wang",
      "Zeli Wang",
      "Yuying Zhao",
      "Jin Zhao",
      "Tao Jia"
    ],
    "abstract": "Network embedding has numerous practical applications and has received\nextensive attention in graph learning, which aims at mapping vertices into a\nlow-dimensional and continuous dense vector space by preserving the underlying\nstructural properties of the graph. Many network embedding methods have been\nproposed, among which factorization of the Personalized PageRank (PPR for\nshort) matrix has been empirically and theoretically well supported recently.\nHowever, several fundamental issues cannot be addressed. (1) Existing methods\ninvoke a seminal Local Push subroutine to approximate \\textit{a single} row or\ncolumn of the PPR matrix. Thus, they have to execute $n$ ($n$ is the number of\nnodes) Local Push subroutines to obtain a provable PPR matrix, resulting in\nprohibitively high computational costs for large $n$. (2) The PPR matrix has\nlimited power in capturing the structural similarity between vertices, leading\nto performance degradation. To overcome these dilemmas, we propose PSNE, an\nefficient spectral s\\textbf{P}arsification method for \\textbf{S}caling\n\\textbf{N}etwork \\textbf{E}mbedding, which can fast obtain the embedding\nvectors that retain strong structural similarities. Specifically, PSNE first\ndesigns a matrix polynomial sparser to accelerate the calculation of the PPR\nmatrix, which has a theoretical guarantee in terms of the Frobenius norm.\nSubsequently, PSNE proposes a simple but effective multiple-perspective\nstrategy to enhance further the representation power of the obtained\napproximate PPR matrix. Finally, PSNE applies a randomized singular value\ndecomposition algorithm on the sparse and multiple-perspective PPR matrix to\nget the target embedding vectors. Experimental evaluation of real-world and\nsynthetic datasets shows that our solutions are indeed more efficient,\neffective, and scalable compared with ten competitors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02705v1",
    "published_date": "2024-08-05 10:38:30 UTC",
    "updated_date": "2024-08-05 10:38:30 UTC"
  },
  {
    "arxiv_id": "2408.07704v1",
    "title": "Empathic Responding for Digital Interpersonal Emotion Regulation via Content Recommendation",
    "authors": [
      "Akriti Verma",
      "Shama Islam",
      "Valeh Moghaddam",
      "Adnan Anwar",
      "Sharon Horwood"
    ],
    "abstract": "Interpersonal communication plays a key role in managing people's emotions,\nespecially on digital platforms. Studies have shown that people use social\nmedia and consume online content to regulate their emotions and find support\nfor rest and recovery. However, these platforms are not designed for emotion\nregulation, which limits their effectiveness in this regard. To address this\nissue, we propose an approach to enhance Interpersonal Emotion Regulation (IER)\non online platforms through content recommendation. The objective is to empower\nusers to regulate their emotions while actively or passively engaging in online\nplatforms by crafting media content that aligns with IER strategies,\nparticularly empathic responding. The proposed recommendation system is\nexpected to blend system-initiated and user-initiated emotion regulation,\npaving the way for real-time IER practices on digital media platforms. To\nassess the efficacy of this approach, a mixed-method research design is used,\nincluding the analysis of text-based social media data and a user survey.\nDigital applications has served as facilitators in this process, given the\nwidespread recognition of digital media applications for Digital Emotion\nRegulation (DER). The study collects 37.5K instances of user posts and\ninteractions on Reddit over a year to design a Contextual Multi-Armed Bandits\n(CMAB) based recommendation system using features from user activity and\npreferences. The experimentation shows that the empathic recommendations\ngenerated by the proposed recommendation system are preferred by users over\nwidely accepted ER strategies such as distraction and avoidance.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07704v1",
    "published_date": "2024-08-05 10:27:28 UTC",
    "updated_date": "2024-08-05 10:27:28 UTC"
  },
  {
    "arxiv_id": "2408.10243v2",
    "title": "TrIM, Triangular Input Movement Systolic Array for Convolutional Neural Networks: Architecture and Hardware Implementation",
    "authors": [
      "Cristian Sestito",
      "Shady Agwa",
      "Themis Prodromakis"
    ],
    "abstract": "Modern hardware architectures for Convolutional Neural Networks (CNNs), other\nthan targeting high performance, aim at dissipating limited energy. Reducing\nthe data movement cost between the computing cores and the memory is a way to\nmitigate the energy consumption. Systolic arrays are suitable architectures to\nachieve this objective: they use multiple processing elements that communicate\neach other to maximize data utilization, based on proper dataflows like the\nweight stationary and row stationary. Motivated by this, we have proposed TrIM,\nan innovative dataflow based on a triangular movement of inputs, and capable to\nreduce the number of memory accesses by one order of magnitude when compared to\nstate-of-the-art systolic arrays. In this paper, we present a TrIM-based\nhardware architecture for CNNs. As a showcase, the accelerator is implemented\nonto a Field Programmable Gate Array (FPGA) to execute the VGG-16 and AlexNet\nCNNs. The architecture achieves a peak throughput of 453.6 Giga Operations per\nSecond, outperforming a state-of-the-art row stationary systolic array up to\n~3x in terms of memory accesses, and being up to ~11.9x more energy-efficient\nthan other FPGA accelerators.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AR",
    "comment": "This work has been accepted by IEEE TCAS-I for publication",
    "pdf_url": "http://arxiv.org/pdf/2408.10243v2",
    "published_date": "2024-08-05 10:18:00 UTC",
    "updated_date": "2025-01-14 11:23:05 UTC"
  },
  {
    "arxiv_id": "2408.02361v2",
    "title": "Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding",
    "authors": [
      "Renato Vukovic",
      "David Arps",
      "Carel van Niekerk",
      "Benjamin Matthias Ruppik",
      "Hsien-Chin Lin",
      "Michael Heck",
      "Milica Gašić"
    ],
    "abstract": "State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to appear at SIGDIAL 2024. 9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.02361v2",
    "published_date": "2024-08-05 10:10:01 UTC",
    "updated_date": "2025-03-07 11:12:17 UTC"
  },
  {
    "arxiv_id": "2408.02357v1",
    "title": "On the consistent reasoning paradox of intelligence and optimal trust in AI: The power of 'I don't know'",
    "authors": [
      "Alexander Bastounis",
      "Paolo Campodonico",
      "Mihaela van der Schaar",
      "Ben Adcock",
      "Anders C. Hansen"
    ],
    "abstract": "We introduce the Consistent Reasoning Paradox (CRP). Consistent reasoning,\nwhich lies at the core of human intelligence, is the ability to handle tasks\nthat are equivalent, yet described by different sentences ('Tell me the time!'\nand 'What is the time?'). The CRP asserts that consistent reasoning implies\nfallibility -- in particular, human-like intelligence in AI necessarily comes\nwith human-like fallibility. Specifically, it states that there are problems,\ne.g. in basic arithmetic, where any AI that always answers and strives to mimic\nhuman intelligence by reasoning consistently will hallucinate (produce wrong,\nyet plausible answers) infinitely often. The paradox is that there exists a\nnon-consistently reasoning AI (which therefore cannot be on the level of human\nintelligence) that will be correct on the same set of problems. The CRP also\nshows that detecting these hallucinations, even in a probabilistic sense, is\nstrictly harder than solving the original problems, and that there are problems\nthat an AI may answer correctly, but it cannot provide a correct logical\nexplanation for how it arrived at the answer. Therefore, the CRP implies that\nany trustworthy AI (i.e., an AI that never answers incorrectly) that also\nreasons consistently must be able to say 'I don't know'. Moreover, this can\nonly be done by implicitly computing a new concept that we introduce, termed\nthe 'I don't know' function -- something currently lacking in modern AI. In\nview of these insights, the CRP also provides a glimpse into the behaviour of\nArtificial General Intelligence (AGI). An AGI cannot be 'almost sure', nor can\nit always explain itself, and therefore to be trustworthy it must be able to\nsay 'I don't know'.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.OC",
      "math.PR"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages and 50 pages of supplementary material, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.02357v1",
    "published_date": "2024-08-05 10:06:53 UTC",
    "updated_date": "2024-08-05 10:06:53 UTC"
  },
  {
    "arxiv_id": "2408.02349v4",
    "title": "Toward Cost-efficient Adaptive Clinical Trials in Knee Osteoarthritis with Reinforcement Learning",
    "authors": [
      "Khanh Nguyen",
      "Huy Hoang Nguyen",
      "Egor Panfilov",
      "Aleksei Tiulpin"
    ],
    "abstract": "Osteoarthritis (OA) is the most common musculoskeletal disease, with knee OA\n(KOA) being one of the leading causes of disability and a significant economic\nburden. Predicting KOA progression is crucial for improving patient outcomes,\noptimizing healthcare resources, studying the disease, and developing new\ntreatments. The latter application particularly requires one to understand the\ndisease progression in order to collect the most informative data at the right\ntime. Existing methods, however, are limited by their static nature and their\nfocus on individual joints, leading to suboptimal predictive performance and\ndownstream utility. Our study proposes a new method that allows to dynamically\nmonitor patients rather than individual joints with KOA using a novel Active\nSensing (AS) approach powered by Reinforcement Learning (RL). Our key idea is\nto directly optimize for the downstream task by training an agent that\nmaximizes informative data collection while minimizing overall costs. Our\nRL-based method leverages a specially designed reward function to monitor\ndisease progression across multiple body parts, employs multimodal deep\nlearning, and requires no human input during testing. Extensive numerical\nexperiments demonstrate that our approach outperforms current state-of-the-art\nmodels, paving the way for the next generation of KOA trials.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02349v4",
    "published_date": "2024-08-05 09:54:08 UTC",
    "updated_date": "2025-04-08 12:10:27 UTC"
  },
  {
    "arxiv_id": "2408.11825v1",
    "title": "Strategic AI adoption in SMEs: A Prescriptive Framework",
    "authors": [
      "Atif Hussain",
      "Rana Rizwan"
    ],
    "abstract": "Artificial Intelligence (AI) is increasingly acknowledged as a vital\ncomponent for the advancement and competitiveness of modern organizations,\nincluding small and medium enterprises (SMEs). However, the adoption of AI\ntechnologies in SMEs faces significant barriers, primarily related to cost,\nlack of technical skills, and employee acceptance. This study proposes a\ncomprehensive, phased framework designed to facilitate the effective adoption\nof AI in SMEs by systematically addressing these barriers. The framework begins\nwith raising awareness and securing commitment from leadership, followed by the\nadoption of low-cost, general-purpose AI tools to build technical competence\nand foster a positive attitude towards AI. As familiarity with AI technologies\nincreases, the framework advocates for the integration of task-specific AI\ntools to enhance efficiency and productivity. Subsequently, it guides\norganizations towards the in-house development of generative AI tools,\nproviding greater customization and control. Finally, the framework addresses\nthe development of discriminative AI models to meet highly specific and\nprecision-oriented tasks. By providing a structured and incremental approach,\nthis framework ensures that SMEs can navigate the complexities of AI\nintegration effectively, driving innovation, efficiency, and competitive\nadvantage. This study contributes to the field by offering a practical,\nprescriptive framework tailored to the unique needs of SMEs, facilitating the\nsuccessful adoption of AI technologies and positioning these organizations for\nsustained growth in a competitive landscape.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11825v1",
    "published_date": "2024-08-05 09:49:37 UTC",
    "updated_date": "2024-08-05 09:49:37 UTC"
  },
  {
    "arxiv_id": "2408.02704v1",
    "title": "Spatial-temporal Graph Convolutional Networks with Diversified Transformation for Dynamic Graph Representation Learning",
    "authors": [
      "Ling Wang",
      "Yixiang Huang",
      "Hao Wu"
    ],
    "abstract": "Dynamic graphs (DG) are often used to describe evolving interactions between\nnodes in real-world applications. Temporal patterns are a natural feature of\nDGs and are also key to representation learning. However, existing dynamic GCN\nmodels are mostly composed of static GCNs and sequence modules, which results\nin the separation of spatiotemporal information and cannot effectively capture\ncomplex temporal patterns in DGs. To address this problem, this study proposes\na spatial-temporal graph convolutional networks with diversified transformation\n(STGCNDT), which includes three aspects: a) constructing a unified graph tensor\nconvolutional network (GTCN) using tensor M-products without the need to\nrepresent spatiotemporal information separately; b) introducing three\ntransformation schemes in GTCN to model complex temporal patterns to aggregate\ntemporal information; and c) constructing an ensemble of diversified\ntransformation schemes to obtain higher representation capabilities. Empirical\nstudies on four DGs that appear in communication networks show that the\nproposed STGCNDT significantly outperforms state-of-the-art models in solving\nlink weight estimation tasks due to the diversified transformations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 papges, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2408.02704v1",
    "published_date": "2024-08-05 09:40:47 UTC",
    "updated_date": "2024-08-05 09:40:47 UTC"
  },
  {
    "arxiv_id": "2408.04653v1",
    "title": "Batching BPE Tokenization Merges",
    "authors": [
      "Alexander P. Morgan"
    ],
    "abstract": "The Byte Pair Encoding algorithm can be safely batched to merge hundreds of\npairs of tokens at a time when building up a tokenizer's vocabulary. This\ntechnique combined with reducing the memory footprint of text used in\nvocabulary training make it feasible to train a high quality tokenizer on a\nbasic laptop. This paper presents BatchBPE, an open-source pure Python\nimplementation of these concepts, with the goal of making experimenting with\nnew tokenization strategies more accessible especially in compute- and\nmemory-constrained contexts. BatchBPE's usefulness and malleability are\ndemonstrated through the training of several token vocabularies to explore the\nbatch merging process and experiment with preprocessing a stop word list and\nignoring the least common text chunks in a dataset. Resultant encoded lengths\nof texts are used as a basic evaluation metric.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 5 figures, 1 code block",
    "pdf_url": "http://arxiv.org/pdf/2408.04653v1",
    "published_date": "2024-08-05 09:37:21 UTC",
    "updated_date": "2024-08-05 09:37:21 UTC"
  },
  {
    "arxiv_id": "2408.02337v1",
    "title": "Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction",
    "authors": [
      "Albert Sawczyn",
      "Katsiaryna Viarenich",
      "Konrad Wojtasik",
      "Aleksandra Domogała",
      "Marcin Oleksy",
      "Maciej Piasecki",
      "Tomasz Kajdanowicz"
    ],
    "abstract": "Advancements in AI and natural language processing have revolutionized\nmachine-human language interactions, with question answering (QA) systems\nplaying a pivotal role. The knowledge base question answering (KBQA) task,\nutilizing structured knowledge graphs (KG), allows for handling extensive\nknowledge-intensive questions. However, a significant gap exists in KBQA\ndatasets, especially for low-resource languages. Many existing construction\npipelines for these datasets are outdated and inefficient in human labor, and\nmodern assisting tools like Large Language Models (LLM) are not utilized to\nreduce the workload. To address this, we have designed and implemented a\nmodern, semi-automated approach for creating datasets, encompassing tasks such\nas KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),\ntailored explicitly for low-resource environments. We executed this pipeline\nand introduced the PUGG dataset, the first Polish KBQA dataset, and novel\ndatasets for MRC and IR. Additionally, we provide a comprehensive\nimplementation, insightful findings, detailed statistics, and evaluation of\nbaseline models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for ACL 2024 (findings)",
    "pdf_url": "http://arxiv.org/pdf/2408.02337v1",
    "published_date": "2024-08-05 09:23:49 UTC",
    "updated_date": "2024-08-05 09:23:49 UTC"
  },
  {
    "arxiv_id": "2408.05235v1",
    "title": "SLO-aware GPU Frequency Scaling for Energy Efficient LLM Inference Serving",
    "authors": [
      "Andreas Kosmas Kakolyris",
      "Dimosthenis Masouros",
      "Petros Vavaroutsos",
      "Sotirios Xydis",
      "Dimitrios Soudris"
    ],
    "abstract": "As Large Language Models (LLMs) gain traction, their reliance on power-hungry\nGPUs places ever-increasing energy demands, raising environmental and monetary\nconcerns. Inference dominates LLM workloads, presenting a critical challenge\nfor providers: minimizing energy costs under Service-Level Objectives (SLOs)\nthat ensure optimal user experience. In this paper, we present\n\\textit{throttLL'eM}, a framework that reduces energy consumption while meeting\nSLOs through the use of instance and GPU frequency scaling.\n\\textit{throttLL'eM} features mechanisms that project future KV cache usage and\nbatch size. Leveraging a Machine-Learning (ML) model that receives these\nprojections as inputs, \\textit{throttLL'eM} manages performance at the\niteration level to satisfy SLOs with reduced frequencies and instance sizes. We\nshow that the proposed ML model achieves $R^2$ scores greater than 0.97 and\nmiss-predicts performance by less than 1 iteration per second on average.\nExperimental results on LLM inference traces show that \\textit{throttLL'eM}\nachieves up to 43.8\\% lower energy consumption and an energy efficiency\nimprovement of at least $1.71\\times$ under SLOs, when compared to NVIDIA's\nTriton server.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05235v1",
    "published_date": "2024-08-05 09:07:06 UTC",
    "updated_date": "2024-08-05 09:07:06 UTC"
  },
  {
    "arxiv_id": "2408.02295v3",
    "title": "Generalized Gaussian Temporal Difference Error for Uncertainty-aware Reinforcement Learning",
    "authors": [
      "Seyeon Kim",
      "Joonhun Lee",
      "Namhoon Cho",
      "Sungjun Han",
      "Wooseop Hwang"
    ],
    "abstract": "Conventional uncertainty-aware temporal difference (TD) learning often\nassumes a zero-mean Gaussian distribution for TD errors, leading to inaccurate\nerror representations and compromised uncertainty estimation. We introduce a\nnovel framework for generalized Gaussian error modeling in deep reinforcement\nlearning to enhance the flexibility of error distribution modeling by\nincorporating additional higher-order moment, particularly kurtosis, thereby\nimproving the estimation and mitigation of data-dependent aleatoric\nuncertainty. We examine the influence of the shape parameter of the generalized\nGaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form\nexpression that demonstrates an inverse relationship between uncertainty and\nthe shape parameter. Additionally, we propose a theoretically grounded\nweighting scheme to address epistemic uncertainty by fully leveraging the GGD.\nWe refine batch inverse variance weighting with bias reduction and kurtosis\nconsiderations, enhancing robustness. Experiments with policy gradient\nalgorithms demonstrate significant performance gains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.PR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02295v3",
    "published_date": "2024-08-05 08:12:25 UTC",
    "updated_date": "2025-02-03 06:14:18 UTC"
  },
  {
    "arxiv_id": "2408.02288v3",
    "title": "Spin glass model of in-context learning",
    "authors": [
      "Yuhao Li",
      "Ruoran Bai",
      "Haiping Huang"
    ],
    "abstract": "Large language models show a surprising in-context learning ability -- being\nable to use a prompt to form a prediction for a query, yet without additional\ntraining, in stark contrast to old-fashioned supervised learning. Providing a\nmechanistic interpretation and linking the empirical phenomenon to physics are\nthus challenging and remain unsolved. We study a simple yet expressive\ntransformer with linear attention and map this structure to a spin glass model\nwith real-valued spins, where the couplings and fields explain the intrinsic\ndisorder in data. The spin glass model explains how the weight parameters\ninteract with each other during pre-training, and further clarifies why an\nunseen function can be predicted by providing only a prompt yet without further\ntraining. Our theory reveals that for single-instance learning, increasing the\ntask diversity leads to the emergence of in-context learning, by allowing the\nBoltzmann distribution to converge to a unique correct solution of weight\nparameters. Therefore the pre-trained transformer displays a prediction power\nin a novel prompt setting. The proposed analytically tractable model thus\noffers a promising avenue for thinking about how to interpret many intriguing\nbut puzzling properties of large language models.",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cond-mat.dis-nn",
    "comment": "16 pages, 4+6 figures, revised version to the journal",
    "pdf_url": "http://arxiv.org/pdf/2408.02288v3",
    "published_date": "2024-08-05 07:54:01 UTC",
    "updated_date": "2025-04-18 08:16:22 UTC"
  },
  {
    "arxiv_id": "2408.02280v1",
    "title": "Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and Cost",
    "authors": [
      "Jannis Maier",
      "Felix Möller",
      "Lennart Purucker"
    ],
    "abstract": "Automated Machine Learning (AutoML) significantly simplifies the deployment\nof machine learning models by automating tasks from data preprocessing to model\nselection to ensembling. AutoML systems for tabular data often employ post hoc\nensembling, where multiple models are combined to improve predictive accuracy.\nThis typically results in longer inference times, a major limitation in\npractical deployments. Addressing this, we introduce a hardware-aware ensemble\nselection approach that integrates inference time into post hoc ensembling. By\nleveraging an existing framework for ensemble selection with quality diversity\noptimization, our method evaluates ensemble candidates for their predictive\naccuracy and hardware efficiency. This dual focus allows for a balanced\nconsideration of accuracy and operational efficiency. Thus, our approach\nenables practitioners to choose from a Pareto front of accurate and efficient\nensembles. Our evaluation using 83 classification datasets shows that our\napproach sustains competitive accuracy and can significantly improve ensembles'\noperational efficiency. The results of this study provide a foundation for\nextending these principles to additional hardware constraints, setting the\nstage for the development of more resource-efficient AutoML systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at Third International Conference on Automated Machine\n  Learning (AutoML 2024), Workshop Track; for code, see\n  https://github.com/Atraxus/HA-ES",
    "pdf_url": "http://arxiv.org/pdf/2408.02280v1",
    "published_date": "2024-08-05 07:30:18 UTC",
    "updated_date": "2024-08-05 07:30:18 UTC"
  },
  {
    "arxiv_id": "2408.02279v1",
    "title": "DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting",
    "authors": [
      "Ruixin Ding",
      "Yuqi Chen",
      "Yu-Ting Lan",
      "Wei Zhang"
    ],
    "abstract": "Long-term time series forecasting (LTSF) has been widely applied in finance,\ntraffic prediction, and other domains. Recently, patch-based transformers have\nemerged as a promising approach, segmenting data into sub-level patches that\nserve as input tokens. However, existing methods mostly rely on predetermined\npatch lengths, necessitating expert knowledge and posing challenges in\ncapturing diverse characteristics across various scales. Moreover, time series\ndata exhibit diverse variations and fluctuations across different temporal\nscales, which traditional approaches struggle to model effectively. In this\npaper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm\nto capture diverse receptive fields and sparse patterns of time series data. In\norder to build hierarchical receptive fields, we develop a multi-scale\nTransformer model, coupled with multi-scale sequence extraction, capable of\ncapturing multi-resolution features. Additionally, we introduce a group-aware\nrotary position encoding technique to enhance intra- and inter-group position\nawareness among representations across different temporal scales. Our proposed\nmodel, named DRFormer, is evaluated on various real-world datasets, and\nexperimental results demonstrate its superiority compared to existing methods.\nOur code is available at: https://github.com/ruixindingECNU/DRFormer.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02279v1",
    "published_date": "2024-08-05 07:26:47 UTC",
    "updated_date": "2024-08-05 07:26:47 UTC"
  },
  {
    "arxiv_id": "2408.02275v1",
    "title": "Geometric Algebra Meets Large Language Models: Instruction-Based Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes",
    "authors": [
      "Dimitris Angelis",
      "Prodromos Kolyvakis",
      "Manos Kamarianakis",
      "George Papagiannakis"
    ],
    "abstract": "This paper introduces a novel integration of Large Language Models (LLMs)\nwith Conformal Geometric Algebra (CGA) to revolutionize controllable 3D scene\nediting, particularly for object repositioning tasks, which traditionally\nrequires intricate manual processes and specialized expertise. These\nconventional methods typically suffer from reliance on large training datasets\nor lack a formalized language for precise edits. Utilizing CGA as a robust\nformal language, our system, shenlong, precisely models spatial transformations\nnecessary for accurate object repositioning. Leveraging the zero-shot learning\ncapabilities of pre-trained LLMs, shenlong translates natural language\ninstructions into CGA operations which are then applied to the scene,\nfacilitating exact spatial transformations within 3D scenes without the need\nfor specialized pre-training. Implemented in a realistic simulation\nenvironment, shenlong ensures compatibility with existing graphics pipelines.\nTo accurately assess the impact of CGA, we benchmark against robust Euclidean\nSpace baselines, evaluating both latency and accuracy. Comparative performance\nevaluations indicate that shenlong significantly reduces LLM response times by\n16% and boosts success rates by 9.6% on average compared to the traditional\nmethods. Notably, shenlong achieves a 100% perfect success rate in common\npractical queries, a benchmark where other systems fall short. These\nadvancements underscore shenlong's potential to democratize 3D scene editing,\nenhancing accessibility and fostering innovation across sectors such as\neducation, digital entertainment, and virtual reality.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.02275v1",
    "published_date": "2024-08-05 07:10:40 UTC",
    "updated_date": "2024-08-05 07:10:40 UTC"
  },
  {
    "arxiv_id": "2408.11824v3",
    "title": "AppAgent v2: Advanced Agent for Flexible Mobile Interactions",
    "authors": [
      "Yanda Li",
      "Chi Zhang",
      "Wanqi Yang",
      "Bin Fu",
      "Pei Cheng",
      "Xin Chen",
      "Ling Chen",
      "Yunchao Wei"
    ],
    "abstract": "With the advancement of Multimodal Large Language Models (MLLM), LLM-driven\nvisual agents are increasingly impacting software interfaces, particularly\nthose with graphical user interfaces. This work introduces a novel LLM-based\nmultimodal agent framework for mobile devices. This framework, capable of\nnavigating mobile devices, emulates human-like interactions. Our agent\nconstructs a flexible action space that enhances adaptability across various\napplications including parser, text and vision descriptions. The agent operates\nthrough two main phases: exploration and deployment. During the exploration\nphase, functionalities of user interface elements are documented either through\nagent-driven or manual explorations into a customized structured knowledge\nbase. In the deployment phase, RAG technology enables efficient retrieval and\nupdate from this knowledge base, thereby empowering the agent to perform tasks\neffectively and accurately. This includes performing complex, multi-step\noperations across various applications, thereby demonstrating the framework's\nadaptability and precision in handling customized task workflows. Our\nexperimental results across various benchmarks demonstrate the framework's\nsuperior performance, confirming its effectiveness in real-world scenarios. Our\ncode will be open source soon.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11824v3",
    "published_date": "2024-08-05 06:31:39 UTC",
    "updated_date": "2024-10-10 06:33:20 UTC"
  },
  {
    "arxiv_id": "2408.02247v5",
    "title": "Contrastive Learning and Abstract Concepts: The Case of Natural Numbers",
    "authors": [
      "Daniel N. Nissani"
    ],
    "abstract": "Contrastive Learning (CL) has been successfully applied to classification and\nother downstream tasks related to concrete concepts, such as objects contained\nin the ImageNet dataset. No attempts seem to have been made so far in applying\nthis promising scheme to more abstract entities. A prominent example of these\ncould be the concept of (discrete) Quantity. CL can be frequently interpreted\nas a self-supervised scheme guided by some profound and ubiquitous conservation\nprinciple (e.g. conservation of identity in object classification tasks). In\nthis introductory work we apply a suitable conservation principle to the\nsemi-abstract concept of natural numbers by which discrete quantities can be\nestimated or predicted. We experimentally show, by means of a toy problem, that\ncontrastive learning can be trained to count at a glance with high accuracy\nboth at human as well as at super-human ranges.. We compare this with the\nresults of a trained-to-count at a glance supervised learning (SL) neural\nnetwork scheme of similar architecture. We show that both schemes exhibit\nsimilar good performance on baseline experiments, where the distributions of\nthe training and testing stages are equal. Importantly, we demonstrate that in\nsome generalization scenarios, where training and testing distributions differ,\nCL boasts more robust and much better error performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02247v5",
    "published_date": "2024-08-05 05:41:16 UTC",
    "updated_date": "2024-09-11 14:21:29 UTC"
  },
  {
    "arxiv_id": "2408.02244v1",
    "title": "Evaluating Vision-Language Models for Zero-Shot Detection, Classification, and Association of Motorcycles, Passengers, and Helmets",
    "authors": [
      "Lucas Choi",
      "Ross Greer"
    ],
    "abstract": "Motorcycle accidents pose significant risks, particularly when riders and\npassengers do not wear helmets. This study evaluates the efficacy of an\nadvanced vision-language foundation model, OWLv2, in detecting and classifying\nvarious helmet-wearing statuses of motorcycle occupants using video data. We\nextend the dataset provided by the CVPR AI City Challenge and employ a cascaded\nmodel approach for detection and classification tasks, integrating OWLv2 and\nCNN models. The results highlight the potential of zero-shot learning to\naddress challenges arising from incomplete and biased training datasets,\ndemonstrating the usage of such models in detecting motorcycles, helmet usage,\nand occupant positions under varied conditions. We have achieved an average\nprecision of 0.5324 for helmet detection and provided precision-recall curves\ndetailing the detection and classification performance. Despite limitations\nsuch as low-resolution data and poor visibility, our research shows promising\nadvancements in automated vehicle safety and traffic safety enforcement\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02244v1",
    "published_date": "2024-08-05 05:30:36 UTC",
    "updated_date": "2024-08-05 05:30:36 UTC"
  },
  {
    "arxiv_id": "2408.02233v1",
    "title": "A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method for Legal Charge Prediction",
    "authors": [
      "Jingyun Sun",
      "Chi Wei",
      "Yang Li"
    ],
    "abstract": "Legal charge prediction, an essential task in legal AI, seeks to assign\naccurate charge labels to case descriptions, attracting significant recent\ninterest. Existing methods primarily employ diverse neural network structures\nfor modeling case descriptions directly, failing to effectively leverage\nmulti-source external knowledge. We propose a prompt learning framework-based\nmethod that simultaneously leverages multi-source heterogeneous external\nknowledge from a legal knowledge base, a conversational LLM, and related legal\narticles. Specifically, we match knowledge snippets in case descriptions via\nthe legal knowledge base and encapsulate them into the input through a hard\nprompt template. Additionally, we retrieve legal articles related to a given\ncase description through contrastive learning, and then obtain factual elements\nwithin the case description through a conversational LLM. We fuse the embedding\nvectors of soft prompt tokens with the encoding vector of factual elements to\nachieve knowledge-enhanced model forward inference. Experimental results show\nthat our method achieved state-of-the-art results on CAIL-2018, the largest\nlegal charge prediction dataset, and our method has lower data dependency. Case\nstudies also demonstrate our method's strong interpretability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.02233v1",
    "published_date": "2024-08-05 04:53:17 UTC",
    "updated_date": "2024-08-05 04:53:17 UTC"
  },
  {
    "arxiv_id": "2408.02232v4",
    "title": "SpecRover: Code Intent Extraction via LLMs",
    "authors": [
      "Haifeng Ruan",
      "Yuntong Zhang",
      "Abhik Roychoudhury"
    ],
    "abstract": "Autonomous program improvement typically involves automatically producing bug\nfixes and feature additions. Such program improvement can be accomplished by a\ncombination of large language model (LLM) and program analysis capabilities, in\nthe form of an LLM agent. Since program repair or program improvement typically\nrequires a specification of intended behavior - specification inference can be\nuseful for producing high quality program patches. In this work, we examine\nefficient and low-cost workflows for iterative specification inference within\nan LLM agent. Given a GitHub issue to be resolved in a software project, our\ngoal is to conduct iterative code search accompanied by specification inference\n- thereby inferring intent from both the project structure and behavior. The\nintent thus captured is examined by a reviewer agent with the goal of vetting\nthe patches as well as providing a measure of confidence in the vetted patches.\nOur approach SpecRover (AutoCodeRover-v2) is built on the open-source LLM agent\nAutoCodeRover. In an evaluation on the full SWE-Bench consisting of 2294 GitHub\nissues, it shows more than 50% improvement in efficacy over AutoCodeRover.\nCompared to the open-source agents available, our work shows modest cost ($0.65\nper issue) in resolving an average GitHub issue in SWE-Bench lite. The\nproduction of explanation by SpecRover allows for a better \"signal\" to be given\nto the developer, on when the suggested patches can be accepted with\nconfidence. SpecRover also seeks to demonstrate the continued importance of\nspecification inference in automated program repair, even as program repair\ntechnologies enter the LLM era.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Haifeng Ruan and Yuntong Zhang contributed equally to this work. To\n  appear in ICSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.02232v4",
    "published_date": "2024-08-05 04:53:01 UTC",
    "updated_date": "2024-12-11 11:18:54 UTC"
  },
  {
    "arxiv_id": "2408.02213v1",
    "title": "Is Large Language Model Good at Database Knob Tuning? A Comprehensive Experimental Evaluation",
    "authors": [
      "Yiyan Li",
      "Haoyang Li",
      "Zhao Pu",
      "Jing Zhang",
      "Xinyi Zhang",
      "Tao Ji",
      "Luming Sun",
      "Cuiping Li",
      "Hong Chen"
    ],
    "abstract": "Knob tuning plays a crucial role in optimizing databases by adjusting knobs\nto enhance database performance. However, traditional tuning methods often\nfollow a Try-Collect-Adjust approach, proving inefficient and\ndatabase-specific. Moreover, these methods are often opaque, making it\nchallenging for DBAs to grasp the underlying decision-making process.\n  The emergence of large language models (LLMs) like GPT-4 and Claude-3 has\nexcelled in complex natural language tasks, yet their potential in database\nknob tuning remains largely unexplored. This study harnesses LLMs as\nexperienced DBAs for knob-tuning tasks with carefully designed prompts. We\nidentify three key subtasks in the tuning system: knob pruning, model\ninitialization, and knob recommendation, proposing LLM-driven solutions to\nreplace conventional methods for each subtask.\n  We conduct extensive experiments to compare LLM-driven approaches against\ntraditional methods across the subtasks to evaluate LLMs' efficacy in the knob\ntuning domain. Furthermore, we explore the adaptability of LLM-based solutions\nin diverse evaluation settings, encompassing new benchmarks, database engines,\nand hardware environments. Our findings reveal that LLMs not only match or\nsurpass traditional methods but also exhibit notable interpretability by\ngenerating responses in a coherent ``chain-of-thought'' manner. We further\nobserve that LLMs exhibit remarkable generalizability through simple\nadjustments in prompts, eliminating the necessity for additional training or\nextensive code modifications.\n  Drawing insights from our experimental findings, we identify several\nopportunities for future research aimed at advancing the utilization of LLMs in\nthe realm of database management.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02213v1",
    "published_date": "2024-08-05 03:26:01 UTC",
    "updated_date": "2024-08-05 03:26:01 UTC"
  },
  {
    "arxiv_id": "2408.02207v1",
    "title": "MARCO: A Memory-Augmented Reinforcement Framework for Combinatorial Optimization",
    "authors": [
      "Andoni I. Garmendia",
      "Quentin Cappart",
      "Josu Ceberio",
      "Alexander Mendiburu"
    ],
    "abstract": "Neural Combinatorial Optimization (NCO) is an emerging domain where deep\nlearning techniques are employed to address combinatorial optimization problems\nas a standalone solver. Despite their potential, existing NCO methods often\nsuffer from inefficient search space exploration, frequently leading to local\noptima entrapment or redundant exploration of previously visited states. This\npaper introduces a versatile framework, referred to as Memory-Augmented\nReinforcement for Combinatorial Optimization (MARCO), that can be used to\nenhance both constructive and improvement methods in NCO through an innovative\nmemory module. MARCO stores data collected throughout the optimization\ntrajectory and retrieves contextually relevant information at each state. This\nway, the search is guided by two competing criteria: making the best decision\nin terms of the quality of the solution and avoiding revisiting already\nexplored solutions. This approach promotes a more efficient use of the\navailable optimization budget. Moreover, thanks to the parallel nature of NCO\nmodels, several search threads can run simultaneously, all sharing the same\nmemory module, enabling an efficient collaborative exploration. Empirical\nevaluations, carried out on the maximum cut, maximum independent set and\ntravelling salesman problems, reveal that the memory module effectively\nincreases the exploration, enabling the model to discover diverse,\nhigher-quality solutions. MARCO achieves good performance in a low\ncomputational cost, establishing a promising new direction in the field of NCO.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.02207v1",
    "published_date": "2024-08-05 03:15:21 UTC",
    "updated_date": "2024-08-05 03:15:21 UTC"
  },
  {
    "arxiv_id": "2408.02205v4",
    "title": "Swiss Cheese Model for AI Safety: A Taxonomy and Reference Architecture for Multi-Layered Guardrails of Foundation Model Based Agents",
    "authors": [
      "Md Shamsujjoha",
      "Qinghua Lu",
      "Dehai Zhao",
      "Liming Zhu"
    ],
    "abstract": "Foundation Model (FM)-based agents are revolutionizing application\ndevelopment across various domains. However, their rapidly growing capabilities\nand autonomy have raised significant concerns about AI safety. Researchers are\nexploring better ways to design guardrails to ensure that the runtime behavior\nof FM-based agents remains within specific boundaries. Nevertheless, designing\neffective runtime guardrails is challenging due to the agents' autonomous and\nnon-deterministic behavior. The involvement of multiple pipeline stages and\nagent artifacts, such as goals, plans, tools, at runtime further complicates\nthese issues. Addressing these challenges at runtime requires multi-layered\nguardrails that operate effectively at various levels of the agent\narchitecture. Therefore, in this paper, based on the results of a systematic\nliterature review, we present a comprehensive taxonomy of runtime guardrails\nfor FM-based agents to identify the key quality attributes for guardrails and\ndesign dimensions. Inspired by the Swiss Cheese Model, we also propose a\nreference architecture for designing multi-layered runtime guardrails for\nFM-based agents, which includes three dimensions: quality attributes,\npipelines, and artifacts. The proposed taxonomy and reference architecture\nprovide concrete and robust guidance for researchers and practitioners to build\nAI-safety-by-design from a software architecture perspective.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.02205v4",
    "published_date": "2024-08-05 03:08:51 UTC",
    "updated_date": "2025-01-27 00:48:51 UTC"
  },
  {
    "arxiv_id": "2408.10240v1",
    "title": "AltCanvas: A Tile-Based Image Editor with Generative AI for Blind or Visually Impaired People",
    "authors": [
      "Seonghee Lee",
      "Maho Kohga",
      "Steve Landau",
      "Sile O'Modhrain",
      "Hari Subramonyam"
    ],
    "abstract": "People with visual impairments often struggle to create content that relies\nheavily on visual elements, particularly when conveying spatial and structural\ninformation. Existing accessible drawing tools, which construct images line by\nline, are suitable for simple tasks like math but not for more expressive\nartwork. On the other hand, emerging generative AI-based text-to-image tools\ncan produce expressive illustrations from descriptions in natural language, but\nthey lack precise control over image composition and properties. To address\nthis gap, our work integrates generative AI with a constructive approach that\nprovides users with enhanced control and editing capabilities. Our system,\nAltCanvas, features a tile-based interface enabling users to construct visual\nscenes incrementally, with each tile representing an object within the scene.\nUsers can add, edit, move, and arrange objects while receiving speech and audio\nfeedback. Once completed, the scene can be rendered as a color illustration or\nas a vector for tactile graphic generation. Involving 14 blind or low-vision\nusers in design and evaluation, we found that participants effectively used the\nAltCanvas workflow to create illustrations.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10240v1",
    "published_date": "2024-08-05 01:47:36 UTC",
    "updated_date": "2024-08-05 01:47:36 UTC"
  },
  {
    "arxiv_id": "2408.10239v1",
    "title": "A Conceptual Framework for Ethical Evaluation of Machine Learning Systems",
    "authors": [
      "Neha R. Gupta",
      "Jessica Hullman",
      "Hari Subramonyam"
    ],
    "abstract": "Research in Responsible AI has developed a range of principles and practices\nto ensure that machine learning systems are used in a manner that is ethical\nand aligned with human values. However, a critical yet often neglected aspect\nof ethical ML is the ethical implications that appear when designing\nevaluations of ML systems. For instance, teams may have to balance a trade-off\nbetween highly informative tests to ensure downstream product safety, with\npotential fairness harms inherent to the implemented testing procedures. We\nconceptualize ethics-related concerns in standard ML evaluation techniques.\nSpecifically, we present a utility framework, characterizing the key trade-off\nin ethical evaluation as balancing information gain against potential ethical\nharms. The framework is then a tool for characterizing challenges teams face,\nand systematically disentangling competing considerations that teams seek to\nbalance. Differentiating between different types of issues encountered in\nevaluation allows us to highlight best practices from analogous domains, such\nas clinical trials and automotive crash testing, which navigate these issues in\nways that can offer inspiration to improve evaluation processes in ML. Our\nanalysis underscores the critical need for development teams to deliberately\nassess and manage ethical complexities that arise during the evaluation of ML\nsystems, and for the industry to move towards designing institutional policies\nto support ethical evaluations.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10239v1",
    "published_date": "2024-08-05 01:06:49 UTC",
    "updated_date": "2024-08-05 01:06:49 UTC"
  },
  {
    "arxiv_id": "2408.11058v1",
    "title": "LLM Agents Improve Semantic Code Search",
    "authors": [
      "Sarthak Jain",
      "Aditya Dora",
      "Ka Seng Sam",
      "Prabhat Singh"
    ],
    "abstract": "Code Search is a key task that many programmers often have to perform while\ndeveloping solutions to problems. Current methodologies suffer from an\ninability to perform accurately on prompts that contain some ambiguity or ones\nthat require additional context relative to a code-base. We introduce the\napproach of using Retrieval Augmented Generation (RAG) powered agents to inject\ninformation into user prompts allowing for better inputs into embedding models.\nBy utilizing RAG, agents enhance user queries with relevant details from GitHub\nrepositories, making them more informative and contextually aligned.\nAdditionally, we introduce a multi-stream ensemble approach which when paired\nwith agentic workflow can obtain improved retrieval accuracy, which we deploy\non application called repo-rift.com. Experimental results on the CodeSearchNet\ndataset demonstrate that RepoRift significantly outperforms existing methods,\nachieving an 78.2% success rate at Success@10 and a 34.6% success rate at\nSuccess@1. This research presents a substantial advancement in semantic code\nsearch, highlighting the potential of agentic LLMs and RAG to enhance code\nretrieval systems.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages, 1 Figure",
    "pdf_url": "http://arxiv.org/pdf/2408.11058v1",
    "published_date": "2024-08-05 00:43:56 UTC",
    "updated_date": "2024-08-05 00:43:56 UTC"
  }
]