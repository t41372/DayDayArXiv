{
  "date": "2024-08-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-05 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的安全性、LLM（Large Language Models）的应用扩展、医疗诊断创新，以及 AI 在强化学习和知识图谱中的优化；重点包括 LLM 安全框架 SEAS 和眼科视觉语言模型 VisionUnite，这些文章展示了 AI 在实际应用中的潜力；有名的学者如 Vincent Conitzer 参与的道德偏好稳定性研究，也值得关注。\n\n### 重点论文讨论\n\n**1. VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge（眼科视觉语言基础模型：增强临床知识）**  \n这篇论文提出 VisionUnite，一种基于 1.24 百万图像文本对预训练的眼科视觉语言模型，通过 MMFundus 数据集进一步优化，能在多病诊断和患者互动中超越 GPT-4V 和 Gemini Pro，其主要贡献是提升初级眼科诊断准确性，并可作为教育工具，适用于资源有限的地区。\n\n**2. On The Stability of Moral Preferences: A Problem with Computational Elicitation Methods（道德偏好稳定性：计算抽取方法的挑战）**  \n作者包括知名学者 Vincent Conitzer，该研究通过重复调查发现道德偏好不稳定（10-18% 的响应变化），这对 AI 伦理工具的设计有重要启示；主要发现是响应不稳定性可能导致 AI 与利益相关者价值失调，强调需改进偏好抽取方法。\n\n**3. Multistain Pretraining for Slide Representation Learning in Pathology（多染色预训练用于病理学幻灯片表示学习）**  \n论文引入 Madeleine 框架，使用多标记染色作为训练信号，处理乳腺癌和肾移植样本；其关键贡献是提升自监督学习在病理任务中的性能，如分类和预后预测，代码已在 GitHub 公开。\n\n**4. Self-Taught Evaluators（自学习评估器）**  \n这项工作提出无需人类标注的自迭代框架，训练 LLM 评估模型；主要发现是，通过合成数据，模型在 RewardBench 上从 75.4% 提升到 88.3%，超越 GPT-4，在 AI 评估领域提供高效替代方案。\n\n**5. SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models（SEAS：自演化对抗安全优化框架）**  \n论文开发 SEAS 框架，通过迭代优化提升 LLM 安全性；其核心贡献是生成更强的对抗样本，目标模型达到 GPT-4 水平，同时红队模型攻击成功率显著提高，代码已开源。\n\n**6. Large Model Strategic Thinking, Small Model Efficiency: Transferring Theory of Mind in Large Language Models（大模型战略思维，小模型效率：LLM 中的理论思维转移）**  \n研究通过微调小模型转移大模型的理论思维能力；主要发现是，小模型在游戏决策上平均改善 46%，并在未见场景中保持 18-28% 的对齐，展示了 LLM 知识迁移的潜力。\n\n**7. Language Model Can Listen While Speaking（语言模型可边听边说）**  \n论文提出 LSLM 模型，支持实时语音交互和中断；其创新在于融合流式编码器和解码器，实现双向通信，实验显示在噪声环境中鲁棒性强，演示视频已发布。\n\n**8. miniCTX: Neural Theorem Proving with (Long-)Contexts（miniCTX：使用长上下文的神经定理证明）**  \n这项工作构建 miniCTX 基准，测试模型在长上下文下的定理证明能力；主要贡献是通过微调和提示方法提升性能，远超传统方法，并提供工具提取新数据。\n\n**9. XMainframe: A Large Language Model for Mainframe Modernization（XMainframe：用于主frame现代化的 LLM）**  \n论文开发 XMainframe 模型，针对 COBOL 代码优化；其关键发现是，在多任务上超越 DeepSeek-Coder 和 GPT-3.5，提升主frame系统维护效率。\n\n### 其他相关论文快速掠过\n其余论文多聚焦技术细节，以下简要提及：\n- **Enhancing Supply Chain Visibility with Knowledge Graphs and Large Language Models（使用知识图谱和 LLM 提升供应链可见性）**：提出框架从公开数据提取供应链信息，提高风险管理。\n- **Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition（聚类和挖掘口音语音以实现包容性语音识别）**：改善语音识别公平性，通过聚类提升对印度口音的处理。\n- **MARCO: A Memory-Augmented Reinforcement Framework for Combinatorial Optimization（MARCO：增强记忆的强化框架用于组合优化）**：引入记忆模块提升探索效率，在最大割等问题上表现优异。\n- **Swiss Cheese Model for AI Safety（AI 安全的瑞士奶酪模型）**：提出多层守卫参考架构，强调 AI 安全设计。\n- 其他如几何代数在 3D 编辑中的应用、强化学习不确定性建模等，贡献在于特定领域优化，但非核心热点，故从简。\n\n今天的 arXiv 更新展示了 AI 在安全和实际应用中的进展，感兴趣的读者可关注 LLM 相关论文进行深入阅读！",
  "papers": [
    {
      "arxiv_id": "2408.02865v1",
      "title": "VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Li",
        "Diping Song",
        "Zefeng Yang",
        "Deming Wang",
        "Fei Li",
        "Xiulan Zhang",
        "Paul E. Kinahan",
        "Yu Qiao"
      ],
      "abstract": "The need for improved diagnostic methods in ophthalmology is acute,\nespecially in the less developed regions with limited access to specialists and\nadvanced equipment. Therefore, we introduce VisionUnite, a novel\nvision-language foundation model for ophthalmology enhanced with clinical\nknowledge. VisionUnite has been pretrained on an extensive dataset comprising\n1.24 million image-text pairs, and further refined using our proposed MMFundus\ndataset, which includes 296,379 high-quality fundus image-text pairs and\n889,137 simulated doctor-patient dialogue instances. Our experiments indicate\nthat VisionUnite outperforms existing generative foundation models such as\nGPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable\nto junior ophthalmologists. VisionUnite performs well in various clinical\nscenarios including open-ended multi-disease diagnosis, clinical explanation,\nand patient interaction, making it a highly versatile tool for initial\nophthalmic disease screening. VisionUnite can also serve as an educational aid\nfor junior ophthalmologists, accelerating their acquisition of knowledge\nregarding both common and rare ophthalmic conditions. VisionUnite represents a\nsignificant advancement in ophthalmology, with broad implications for\ndiagnostics, medical education, and understanding of disease mechanisms.",
      "tldr_zh": "该研究引入了 VisionUnite，一种增强临床知识的视觉-语言基础模型，旨在改善眼科诊断，尤其适用于资源有限的地区。模型在1.24百万图像-文本对数据集上预训练，并通过MMFundus数据集（包括29.6万高质量眼底图像-文本对和88.9万模拟医生-患者对话实例）进一步微调。实验结果显示，VisionUnite 优于 GPT-4V 和 Gemini Pro，其诊断能力可与初级眼科医生相当，并在开放式多疾病诊断、临床解释和患者互动等场景中表现出色。该模型不仅可作为初级眼科筛查工具，还能加速医生的知识获取，并对眼科诊断、医疗教育和疾病机制理解产生广泛影响。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02865v1",
      "published_date": "2024-08-05 23:31:07 UTC",
      "updated_date": "2024-08-05 23:31:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:54:51.534946"
    },
    {
      "arxiv_id": "2408.02862v1",
      "title": "On The Stability of Moral Preferences: A Problem with Computational Elicitation Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Kyle Boerstler",
        "Vijay Keswani",
        "Lok Chan",
        "Jana Schaich Borg",
        "Vincent Conitzer",
        "Hoda Heidari",
        "Walter Sinnott-Armstrong"
      ],
      "abstract": "Preference elicitation frameworks feature heavily in the research on\nparticipatory ethical AI tools and provide a viable mechanism to enquire and\nincorporate the moral values of various stakeholders. As part of the\nelicitation process, surveys about moral preferences, opinions, and judgments\nare typically administered only once to each participant. This methodological\npractice is reasonable if participants' responses are stable over time such\nthat, all other relevant factors being held constant, their responses today\nwill be the same as their responses to the same questions at a later time.\nHowever, we do not know how often that is the case. It is possible that\nparticipants' true moral preferences change, are subject to temporary moods or\nwhims, or are influenced by environmental factors we don't track. If\nparticipants' moral responses are unstable in such ways, it would raise\nimportant methodological and theoretical issues for how participants' true\nmoral preferences, opinions, and judgments can be ascertained. We address this\npossibility here by asking the same survey participants the same moral\nquestions about which patient should receive a kidney when only one is\navailable ten times in ten different sessions over two weeks, varying only\npresentation order across sessions. We measured how often participants gave\ndifferent responses to simple (Study One) and more complicated (Study Two)\nrepeated scenarios. On average, the fraction of times participants changed\ntheir responses to controversial scenarios was around 10-18% across studies,\nand this instability is observed to have positive associations with response\ntime and decision-making difficulty. We discuss the implications of these\nresults for the efficacy of moral preference elicitation, highlighting the role\nof response instability in causing value misalignment between stakeholders and\nAI tools trained on their moral judgments.",
      "tldr_zh": "本研究质疑了道德偏好elicitation（偏好提取）方法在参与式AI工具中的稳定性，指出传统调查通常只进行一次，假设参与者的moral preferences（道德偏好）是稳定的。研究者通过两个实验（Study One 和 Study Two）重复向参与者提问相同的肾移植道德场景问题，共10次，观察响应变化。结果显示，参与者对争议性场景的响应不稳定，平均变化率为10-18%，且与响应时间和决策难度正相关。这些发现突显了道德偏好elicitation的有效性问题，可能导致利益相关者和基于其判断训练的AI工具之间出现价值misalignment（价值不匹配）。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "To appear in AIES 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.02862v1",
      "published_date": "2024-08-05 23:20:47 UTC",
      "updated_date": "2024-08-05 23:20:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:55:01.815831"
    },
    {
      "arxiv_id": "2408.02859v1",
      "title": "Multistain Pretraining for Slide Representation Learning in Pathology",
      "title_zh": "翻译失败",
      "authors": [
        "Guillaume Jaume",
        "Anurag Vaidya",
        "Andrew Zhang",
        "Andrew H. Song",
        "Richard J. Chen",
        "Sharifa Sahai",
        "Dandan Mo",
        "Emilio Madrigal",
        "Long Phi Le",
        "Faisal Mahmood"
      ],
      "abstract": "Developing self-supervised learning (SSL) models that can learn universal and\ntransferable representations of H&E gigapixel whole-slide images (WSIs) is\nbecoming increasingly valuable in computational pathology. These models hold\nthe potential to advance critical tasks such as few-shot classification, slide\nretrieval, and patient stratification. Existing approaches for slide\nrepresentation learning extend the principles of SSL from small images (e.g.,\n224 x 224 patches) to entire slides, usually by aligning two different\naugmentations (or views) of the slide. Yet the resulting representation remains\nconstrained by the limited clinical and biological diversity of the views.\nInstead, we postulate that slides stained with multiple markers, such as\nimmunohistochemistry, can be used as different views to form a rich\ntask-agnostic training signal. To this end, we introduce Madeleine, a\nmultimodal pretraining strategy for slide representation learning. Madeleine is\ntrained with a dual global-local cross-stain alignment objective on large\ncohorts of breast cancer samples (N=4,211 WSIs across five stains) and kidney\ntransplant samples (N=12,070 WSIs across four stains). We demonstrate the\nquality of slide representations learned by Madeleine on various downstream\nevaluations, ranging from morphological and molecular classification to\nprognostic prediction, comprising 21 tasks using 7,299 WSIs from multiple\nmedical centers. Code is available at https://github.com/mahmoodlab/MADELEINE.",
      "tldr_zh": "该论文探讨了在病理学中开发自监督学习 (SSL) 模型，以学习 H&E 显微镜下全滑片图像 (WSIs) 的通用和可转移表示，从而支持少样本分类、滑片检索和患者分层等任务。作者提出 Madeleine，一种多模态预训练策略，通过使用多种染色（如免疫组织化学）作为不同视图，并采用双重全局-局部跨染色对齐目标，在大型队列（包括 4,211 张乳腺癌 WSIs 和 12,070 张肾移植 WSIs）上进行训练。实验结果显示，Madeleine 在 21 个下游任务上表现出色，包括形态学和分子分类以及预后预测，涉及 7,299 张 WSIs，从而提升了计算病理学的表示学习能力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "ECCV'24",
      "pdf_url": "http://arxiv.org/pdf/2408.02859v1",
      "published_date": "2024-08-05 22:59:50 UTC",
      "updated_date": "2024-08-05 22:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:55:16.394950"
    },
    {
      "arxiv_id": "2408.02835v3",
      "title": "Training a multilayer dynamical spintronic network with standard machine learning tools to perform time series classification",
      "title_zh": "翻译失败",
      "authors": [
        "Erwan Plouet",
        "Dédalo Sanz-Hernández",
        "Aymeric Vecchiola",
        "Julie Grollier",
        "Frank Mizrahi"
      ],
      "abstract": "The ability to process time-series at low energy cost is critical for many\napplications. Recurrent neural network, which can perform such tasks, are\ncomputationally expensive when implementing in software on conventional\ncomputers. Here we propose to implement a recurrent neural network in hardware\nusing spintronic oscillators as dynamical neurons. Using numerical simulations,\nwe build a multi-layer network and demonstrate that we can use backpropagation\nthrough time (BPTT) and standard machine learning tools to train this network.\nLeveraging the transient dynamics of the spintronic oscillators, we solve the\nsequential digits classification task with $89.83\\pm2.91~\\%$ accuracy, as good\nas the equivalent software network. We devise guidelines on how to choose the\ntime constant of the oscillators as well as hyper-parameters of the network to\nadapt to different input time scales.",
      "tldr_zh": "本研究提出了一种硬件实现的多层动态自旋电子网络(spintronic network)，利用自旋电子振荡器(spintronic oscillators)作为动态神经元，以低能量成本处理时间序列分类任务。研究通过数值模拟构建多层网络，并采用反向传播通过时间(Backpropagation Through Time, BPTT)和标准机器学习工具进行训练。结果显示，该网络在顺序数字分类任务上达到了89.83±2.91%的准确率，与等效软件网络相当，并提供了选择振荡器时间常数和网络超参数的指导，以适应不同输入时间尺度。",
      "categories": [
        "cond-mat.dis-nn",
        "cond-mat.mes-hall",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.dis-nn",
      "comment": "7 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.02835v3",
      "published_date": "2024-08-05 21:12:12 UTC",
      "updated_date": "2025-03-04 13:41:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:55:26.447590"
    },
    {
      "arxiv_id": "2408.05241v4",
      "title": "Large Model Strategic Thinking, Small Model Efficiency: Transferring Theory of Mind in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nunzio Lore",
        "Sepehr Ilami",
        "Babak Heydari"
      ],
      "abstract": "As the performance of larger, newer Large Language Models continues to\nimprove for strategic Theory of Mind (ToM) tasks, the demand for these\nstate-of-the-art models increases commensurately. However, their deployment is\ncostly both in terms of processing power and time. In this paper, we\ninvestigate the feasibility of creating smaller, highly-performing specialized\nalgorithms by way of fine-tuning. To do this, we first present a large\npre-trained model with 20 unique scenarios that combine different social\ncontexts with games of varying social dilemmas, record its answers, and use\nthem for Q&A fine-tuning on a smaller model of the same family. Our focus is on\nin-context game-theoretic decision-making, the same domain within which human\ninteraction occurs and that requires both a theory of mind (or a semblance\nthereof) and an understanding of social dynamics. The smaller model is\ntherefore trained not just on the answers provided, but also on the motivations\nprovided by the larger model, which should contain advice and guidelines to\nnavigate both strategic dilemmas and social cues. We find that the fine-tuned\nsmaller language model consistently bridged the gap in performance between the\nsmaller pre-trained version of the model and its larger relative and that its\nimprovements extended in areas and contexts beyond the ones provided in the\ntraining examples, including on out-of-sample scenarios that include completely\ndifferent game structures. On average for all games, through fine-tuning, the\nsmaller model showed a 46% improvement measured as alignment towards the\nbehavior of the larger model, with 100% representing indistinguishable\nbehavior. When presented with out-of-sample social contexts and games, the\nfine-tuned model still displays remarkable levels of alignment, reaching an\nimprovement of 18% and 28% respectively.",
      "tldr_zh": "本研究探讨了如何将大型语言模型（Large Language Models, LLMs）在战略性 Theory of Mind (ToM) 任务中的思考能力转移到小型模型上，以提升效率并降低部署成本。研究方法包括使用一个大型预训练模型在20个结合社会背景和博弈论场景中生成答案和动机，然后通过 Q&A fine-tuning 对小型模型进行训练，使其不仅学习答案，还掌握战略决策指导。结果显示，fine-tuned 的小型模型在性能上与大型模型的差距缩小，平均改善46%，并在训练外的社会背景和游戏场景中表现出18%至28%的泛化提升，为高效的AI决策系统提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "cs.GT"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.05241v4",
      "published_date": "2024-08-05 20:49:48 UTC",
      "updated_date": "2024-10-30 18:37:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:55:38.099128"
    },
    {
      "arxiv_id": "2408.02825v2",
      "title": "The Impact of Environment Configurations on the Stability of AI-Enabled Systems",
      "title_zh": "环境配置对 AI 启用系统稳定性的影响",
      "authors": [
        "Musfiqur Rahman",
        "SayedHassan Khatoonabadi",
        "Ahmad Abdellatif",
        "Haya Samaana",
        "Emad Shihab"
      ],
      "abstract": "Nowadays, software systems tend to include Artificial Intelligence (AI)\ncomponents. Changes in the operational environment have been known to\nnegatively impact the stability of AI-enabled software systems by causing\nunintended changes in behavior. However, how an environment configuration\nimpacts the behavior of such systems has yet to be explored. Understanding and\nquantifying the degree of instability caused by different environment settings\ncan help practitioners decide the best environment configuration for the most\nstable AI systems. To achieve this goal, we performed experiments with eight\ndifferent combinations of three key environment variables (operating system,\nPython version, and CPU architecture) on $30$ open-source AI-enabled systems\nusing the Travis CI platform. We determine the existence and the degree of\ninstability introduced by each configuration using three metrics: the output of\nan AI component of the system (model performance), the time required to build\nand run the system (processing time), and the cost associated with building and\nrunning the system (expense). Our results indicate that changes in environment\nconfigurations lead to instability across all three metrics; however, it is\nobserved more frequently with respect to processing time and expense rather\nthan model performance. For example, between Linux and MacOS, instability is\nobserved in 23\\%, 96.67\\%, and 100\\% of the studied projects in model\nperformance, processing time, and expense, respectively. Our findings\nunderscore the importance of identifying the optimal combination of\nconfiguration settings to mitigate drops in model performance and reduce the\nprocessing time and expense before deploying an AI-enabled system.",
      "tldr_zh": "本文研究了环境配置对 AI-enabled systems 稳定性的影响，旨在量化不同配置（如操作系统、Python 版本和 CPU 架构）对系统行为的不稳定性。研究通过在 Travis CI 平台上实验八种环境变量组合，对 30 个开源 AI 系统使用三个指标（模型性能、处理时间和成本）进行评估。结果表明，环境变化导致所有指标的不稳定性，但处理时间和成本受影响更频繁，例如 Linux 和 MacOS 之间，模型性能不稳定率仅 23%，而处理时间和成本分别达 96.67% 和 100%。这些发现强调了在部署 AI-enabled systems 前，选择最佳配置组合以减少性能下降和降低资源消耗的重要性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication at the International Conference on\n  Evaluation and Assessment in Software Engineering (EASE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2408.02825v2",
      "published_date": "2024-08-05 20:47:14 UTC",
      "updated_date": "2025-04-17 14:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:55:50.854800"
    },
    {
      "arxiv_id": "2408.02811v1",
      "title": "Development of REGAI: Rubric Enabled Generative Artificial Intelligence",
      "title_zh": "REGAI 的开发：基于评分标准的生成式人工智能",
      "authors": [
        "Zach Johnson",
        "Jeremy Straub"
      ],
      "abstract": "This paper presents and evaluates a new retrieval augmented generation (RAG)\nand large language model (LLM)-based artificial intelligence (AI) technique:\nrubric enabled generative artificial intelligence (REGAI). REGAI uses rubrics,\nwhich can be created manually or automatically by the system, to enhance the\nperformance of LLMs for evaluation purposes. REGAI improves on the performance\nof both classical LLMs and RAG-based LLM techniques. This paper describes\nREGAI, presents data regarding its performance and discusses several possible\napplication areas for the technology.",
      "tldr_zh": "本文开发了 REGAI，一种基于检索增强生成 (RAG) 和大型语言模型 (LLM) 的生成式 AI 技术，通过手动或自动创建的评分标准 (rubrics) 来提升 LLM 在评估任务中的性能。相比传统 LLM 和 RAG-based LLM，REGAI 展示了更好的表现，并提供了相关性能数据支持。论文还讨论了 REGAI 在教育、评估和其它领域的潜在应用前景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02811v1",
      "published_date": "2024-08-05 20:21:54 UTC",
      "updated_date": "2024-08-05 20:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:56:01.921904"
    },
    {
      "arxiv_id": "2408.03350v3",
      "title": "miniCTX: Neural Theorem Proving with (Long-)Contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Jiewen Hu",
        "Thomas Zhu",
        "Sean Welleck"
      ],
      "abstract": "Real-world formal theorem proving often depends on a wealth of context,\nincluding definitions, lemmas, comments, file structure, and other information.\nWe introduce miniCTX, which tests a model's ability to prove formal\nmathematical theorems that depend on new context that is not seen during\ntraining. miniCTX contains theorems sourced from real Lean projects and\ntextbooks, each associated with a context that can span tens of thousands of\ntokens. Models are tasked with proving a theorem given access to code from the\ntheorem's repository, which contains context that is needed for the proof. As a\nbaseline for miniCTX, we tested fine-tuning and prompting methods that\ncondition theorem proving on preceding context. Both approaches substantially\noutperform traditional methods that rely solely on state information. We found\nthat this ability to use context is not captured by previous benchmarks such as\nminiF2F. Alongside miniCTX, we offer ntp-toolkit for automatically extracting\nand annotating theorem proving data, making it easy to add new projects into\nminiCTX to ensure that contexts are not seen during training. miniCTX offers a\nchallenging and realistic evaluation of neural theorem provers.",
      "tldr_zh": "该论文引入了 miniCTX 基准测试，用于评估神经定理证明模型处理未见训练的长上下文能力，包括定义、引理、注释和文件结构等。miniCTX 收集了来自真实 Lean 项目和教科书的定理，每个定理关联数万 tokens 的上下文，模型需利用仓库代码进行证明。实验结果显示，基于上下文的微调和提示方法显著优于传统仅依赖状态信息的做法，并在之前基准如 miniF2F 中未被充分覆盖。同时，论文提供了 ntp-toolkit 工具，用于自动提取和标注定理证明数据，便于扩展新项目以确保测试的真实性和挑战性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Project page: https://cmu-l3.github.io/minictx",
      "pdf_url": "http://arxiv.org/pdf/2408.03350v3",
      "published_date": "2024-08-05 20:19:18 UTC",
      "updated_date": "2025-03-04 00:10:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:56:15.424701"
    },
    {
      "arxiv_id": "2408.04660v3",
      "title": "XMainframe: A Large Language Model for Mainframe Modernization",
      "title_zh": "XMainframe：一种用于主机现代化的巨型语言模型",
      "authors": [
        "Anh T. V. Dau",
        "Hieu Trung Dao",
        "Anh Tuan Nguyen",
        "Hieu Trung Tran",
        "Phong X. Nguyen",
        "Nghi D. Q. Bui"
      ],
      "abstract": "Mainframe operating systems, despite their inception in the 1940s, continue\nto support critical sectors like finance and government. However, these systems\nare often viewed as outdated, requiring extensive maintenance and\nmodernization. Addressing this challenge necessitates innovative tools that can\nunderstand and interact with legacy codebases. To this end, we introduce\nXMainframe, a state-of-the-art large language model (LLM) specifically designed\nwith knowledge of mainframe legacy systems and COBOL codebases. Our solution\ninvolves the creation of an extensive data collection pipeline to produce\nhigh-quality training datasets, enhancing XMainframe's performance in this\nspecialized domain. Additionally, we present MainframeBench, a comprehensive\nbenchmark for assessing mainframe knowledge, including multiple-choice\nquestions, question answering, and COBOL code summarization. Our empirical\nevaluations demonstrate that XMainframe consistently outperforms existing\nstate-of-the-art LLMs across these tasks. Specifically, XMainframe achieves 30%\nhigher accuracy than DeepSeek-Coder on multiple-choice questions, doubles the\nBLEU score of Mixtral-Instruct 8x7B on question answering, and scores six times\nhigher than GPT-3.5 on COBOL summarization. Our work highlights the potential\nof XMainframe to drive significant advancements in managing and modernizing\nlegacy systems, thereby enhancing productivity and saving time for software\ndevelopers.",
      "tldr_zh": "本研究介绍了 XMainframe，一种专门针对主机系统现代化的先进大型语言模型 (LLM)，它整合了主机遗留系统和 COBOL 代码库的知识，以解决这些过时系统的维护挑战。研究团队构建了一个全面的数据收集管道来生成高质量训练数据集，并开发了 MainframeBench 基准，用于评估主机知识，包括多项选择题、问答和 COBOL 代码总结。实验结果显示，XMainframe 在多项选择题上比 DeepSeek-Coder 准确率高 30%，在问答任务中 BLEU 分数是 Mixtral-Instruct 8x7B 的两倍，并在 COBOL 总结上比 GPT-3.5 高六倍，从而显著提升了遗留系统管理和开发者的生产力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04660v3",
      "published_date": "2024-08-05 20:01:10 UTC",
      "updated_date": "2024-08-26 09:37:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:56:26.599745"
    },
    {
      "arxiv_id": "2408.02798v1",
      "title": "Examining Gender and Power on Wikipedia Through Face and Politeness",
      "title_zh": "翻译失败",
      "authors": [
        "Adil Soubki",
        "Shyne Choi",
        "Owen Rambow"
      ],
      "abstract": "We propose a framework for analyzing discourse by combining two\ninterdependent concepts from sociolinguistic theory: face acts and politeness.\nWhile politeness has robust existing tools and data, face acts are less\nresourced. We introduce a new corpus created by annotating Wikipedia talk pages\nwith face acts and we use this to train a face act tagger. We then employ our\nframework to study how face and politeness interact with gender and power in\ndiscussions between Wikipedia editors. Among other findings, we observe that\nfemale Wikipedians are not only more polite, which is consistent with prior\nstudies, but that this difference corresponds with significantly more language\ndirected at humbling aspects of their own face. Interestingly, the distinction\nnearly vanishes once limiting to editors with administrative power.",
      "tldr_zh": "这篇论文提出一个框架，将社会语言学理论中的face acts和politeness相结合，用于分析Wikipedia讨论中的性别和权力动态。他们创建了一个新语料库，通过标注Wikipedia讨论页上的face acts来训练一个face act tagger。研究发现，女性Wikipedians不仅更礼貌，而且更频繁使用针对自身面子的谦卑语言；然而，这种性别差异在限于有行政权力的编辑时几乎消失。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02798v1",
      "published_date": "2024-08-05 19:28:58 UTC",
      "updated_date": "2024-08-05 19:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:56:39.379503"
    },
    {
      "arxiv_id": "2408.02666v2",
      "title": "Self-Taught Evaluators",
      "title_zh": "翻译失败",
      "authors": [
        "Tianlu Wang",
        "Ilia Kulikov",
        "Olga Golovneva",
        "Ping Yu",
        "Weizhe Yuan",
        "Jane Dwivedi-Yu",
        "Richard Yuanzhe Pang",
        "Maryam Fazel-Zarandi",
        "Jason Weston",
        "Xian Li"
      ],
      "abstract": "Model-based evaluation is at the heart of successful model development -- as\na reward model for training, and as a replacement for human evaluation. To\ntrain such evaluators, the standard approach is to collect a large amount of\nhuman preference judgments over model responses, which is costly and the data\nbecomes stale as models improve. In this work, we present an approach that aims\nto im-prove evaluators without human annotations, using synthetic training data\nonly. Starting from unlabeled instructions, our iterative self-improvement\nscheme generates contrasting model outputs and trains an LLM-as-a-Judge to\nproduce reasoning traces and final judgments, repeating this training at each\nnew iteration using the improved predictions. Without any labeled preference\ndata, our Self-Taught Evaluator can improve a strong LLM (Llama3-70B-Instruct)\nfrom 75.4 to 88.3 (88.7 with majority vote) on RewardBench. This outperforms\ncommonly used LLM judges such as GPT-4 and matches the performance of the\ntop-performing reward models trained with labeled examples.",
      "tldr_zh": "本文提出 Self-Taught Evaluators，一种无需人类标注的模型评估方法，通过迭代自提升方案从无标签指令生成对比模型输出，并训练 LLM-as-a-Judge 来产生推理轨迹和最终判断。 该方法重复使用改进的预测进行训练，实现模型性能的持续提升。实验结果显示，在 RewardBench 上，Self-Taught Evaluator 将 Llama3-70B-Instruct 的性能从 75.4 提升到 88.3（多数投票下达 88.7），超过了 GPT-4 等常用 LLM 判断器，并与使用标注数据训练的顶级奖励模型相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02666v2",
      "published_date": "2024-08-05 17:57:02 UTC",
      "updated_date": "2024-08-08 17:09:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:56:52.636961"
    },
    {
      "arxiv_id": "2408.02651v1",
      "title": "Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Bahrami Karkevandi",
        "Nishant Vishwamitra",
        "Peyman Najafirad"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nnatural language tasks, but their safety and morality remain contentious due to\ntheir training on internet text corpora. To address these concerns, alignment\ntechniques have been developed to improve the public usability and safety of\nLLMs. Yet, the potential for generating harmful content through these models\nseems to persist. This paper explores the concept of jailbreaking\nLLMs-reversing their alignment through adversarial triggers. Previous methods,\nsuch as soft embedding prompts, manually crafted prompts, and gradient-based\nautomatic prompts, have had limited success on black-box models due to their\nrequirements for model access and for producing a low variety of manually\ncrafted prompts, making them susceptible to being blocked. This paper\nintroduces a novel approach using reinforcement learning to optimize\nadversarial triggers, requiring only inference API access to the target model\nand a small surrogate model. Our method, which leverages a BERTScore-based\nreward function, enhances the transferability and effectiveness of adversarial\ntriggers on new black-box models. We demonstrate that this approach improves\nthe performance of adversarial triggers on a previously untested language\nmodel.",
      "tldr_zh": "这篇论文探讨了强化学习（Reinforcement Learning）是否能逆转对齐的大型语言模型（LLMs）的安全机制，从而揭示其潜在危险，如通过对抗触发器（adversarial triggers）生成有害内容。现有方法（如软嵌入提示和手动提示）因需模型访问或易被阻塞而效果有限，论文提出一种新方法：利用强化学习优化触发器，仅需目标模型的推理 API 和一个小代理模型，并采用 BERTScore-based 奖励函数来提升触发器的可转移性和有效性。实验结果表明，该方法显著提高了对抗触发器在新黑箱模型上的性能，证明了强化学习在 jailbreaking LLMs 方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to AI4CYBER - KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.02651v1",
      "published_date": "2024-08-05 17:27:29 UTC",
      "updated_date": "2024-08-05 17:27:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:57:05.324958"
    },
    {
      "arxiv_id": "2408.05239v1",
      "title": "The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Morriss",
        "Tod Brindle",
        "Jessica Bah Rösman",
        "Daniel Reibsamen",
        "Andreas Enz"
      ],
      "abstract": "Systematic literature reviews are the highest quality of evidence in\nresearch. However, the review process is hindered by significant resource and\ndata constraints. The Literature Review Network (LRN) is the first of its kind\nexplainable AI platform adhering to PRISMA 2020 standards, designed to automate\nthe entire literature review process. LRN was evaluated in the domain of\nsurgical glove practices using 3 search strings developed by experts to query\nPubMed. A non-expert trained all LRN models. Performance was benchmarked\nagainst an expert manual review. Explainability and performance metrics\nassessed LRN's ability to replicate the experts' review. Concordance was\nmeasured with the Jaccard index and confusion matrices. Researchers were\nblinded to the other's results until study completion. Overlapping studies were\nintegrated into an LRN-generated systematic review. LRN models demonstrated\nsuperior classification accuracy without expert training, achieving 84.78% and\n85.71% accuracy. The highest performance model achieved high interrater\nreliability (k = 0.4953) and explainability metrics, linking 'reduce',\n'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%\nof the relevant literature despite diverging from the non-expert's judgments (k\n= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN\noutperformed the manual review (19,920 minutes over 11 months), reducing the\nentire process to 288.6 minutes over 5 days. This study demonstrates that\nexplainable AI does not require expert training to successfully conduct\nPRISMA-compliant systematic literature reviews like an expert. LRN summarized\nthe results of surgical glove studies and identified themes that were nearly\nidentical to the clinical researchers' findings. Explainable AI can accurately\nexpedite our understanding of clinical practices, potentially revolutionizing\nhealthcare research.",
      "tldr_zh": "本研究引入了 Literature Review Network (LRN)，一个可解释的 AI 平台，旨在自动化系统文献综述、荟萃分析和方法开发过程，严格遵守 PRISMA 2020 标准，从而克服传统文献审查的资源和数据限制。LRN 在手术手套实践领域进行评估，使用专家开发的搜索字符串查询 PubMed，并由非专家训练模型，与专家手动审查进行基准测试。结果显示，LRN 模型在分类准确率上达到 84.78% 和 85.71%，并通过 Jaccard index 和混淆矩阵证明了高一致性和可解释性，例如将关键词如 'reduce'、'accident' 和 'sharp' 与 'double-gloving' 关联。总体而言，LRN 将文献审查时间从专家的 11 个月（19,920 分钟）缩短至 5 天（288.6 分钟），证明 explainable AI 无需专家训练即可高效进行高质量文献综述，并加速医疗研究的创新。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.DL",
      "comment": "12 pages, 4 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.05239v1",
      "published_date": "2024-08-05 17:25:16 UTC",
      "updated_date": "2024-08-05 17:25:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:57:17.848860"
    },
    {
      "arxiv_id": "2408.07705v1",
      "title": "Enhancing Supply Chain Visibility with Knowledge Graphs and Large Language Models",
      "title_zh": "使用知识图谱和大语言模型增强供应链可见性",
      "authors": [
        "Sara AlMahri",
        "Liming Xu",
        "Alexandra Brintrup"
      ],
      "abstract": "In today's globalized economy, comprehensive supply chain visibility is\ncrucial for effective risk management. Achieving visibility remains a\nsignificant challenge due to limited information sharing among supply chain\npartners. This paper presents a novel framework leveraging Knowledge Graphs\n(KGs) and Large Language Models (LLMs) to enhance supply chain visibility\nwithout relying on direct stakeholder information sharing. Our zero-shot,\nLLM-driven approach automates the extraction of supply chain information from\ndiverse public sources and constructs KGs to capture complex interdependencies\nbetween supply chain entities. We employ zero-shot prompting for Named Entity\nRecognition (NER) and Relation Extraction (RE) tasks, eliminating the need for\nextensive domain-specific training. We validate the framework with a case study\non electric vehicle supply chains, focusing on tracking critical minerals for\nbattery manufacturing. Results show significant improvements in supply chain\nmapping, extending visibility beyond tier-2 suppliers. The framework reveals\ncritical dependencies and alternative sourcing options, enhancing risk\nmanagement and strategic planning. With high accuracy in NER and RE tasks, it\nprovides an effective tool for understanding complex, multi-tiered supply\nnetworks. This research offers a scalable, flexible method for constructing\ndomain-specific supply chain KGs, addressing longstanding challenges in\nvisibility and paving the way for advancements in digital supply chain\nsurveillance.",
      "tldr_zh": "本文提出一个新框架，利用 Knowledge Graphs (KGs) 和 Large Language Models (LLMs)，来提升供应链可见性，而不依赖直接利益相关者信息共享。该框架采用 zero-shot prompting 进行 Named Entity Recognition (NER) 和 Relation Extraction (RE)，从公共来源自动提取信息并构建 KGs，以捕捉供应链实体间的复杂相互依赖。通过电动汽车供应链案例研究，框架成功追踪电池制造的关键矿物，并将可见性扩展到 tier-2 供应商以外。结果显示，NER 和 RE 任务准确率高，提升了风险管理和战略规划，并为构建可扩展的领域特定供应链 KGs 提供了有效工具。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07705v1",
      "published_date": "2024-08-05 17:11:29 UTC",
      "updated_date": "2024-08-05 17:11:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:57:29.890922"
    },
    {
      "arxiv_id": "2408.02632v2",
      "title": "SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Muxi Diao",
        "Rumei Li",
        "Shiyang Liu",
        "Guogang Liao",
        "Jingang Wang",
        "Xunliang Cai",
        "Weiran Xu"
      ],
      "abstract": "As large language models (LLMs) continue to advance in capability and\ninfluence, ensuring their security and preventing harmful outputs has become\ncrucial. A promising approach to address these concerns involves training\nmodels to automatically generate adversarial prompts for red teaming. However,\nthe evolving subtlety of vulnerabilities in LLMs challenges the effectiveness\nof current adversarial methods, which struggle to specifically target and\nexplore the weaknesses of these models. To tackle these challenges, we\nintroduce the $\\mathbf{S}\\text{elf-}\\mathbf{E}\\text{volving\n}\\mathbf{A}\\text{dversarial }\\mathbf{S}\\text{afety }\\mathbf{(SEAS)}$\noptimization framework, which enhances security by leveraging data generated by\nthe model itself. SEAS operates through three iterative stages: Initialization,\nAttack, and Adversarial Optimization, refining both the Red Team and Target\nmodels to improve robustness and safety. This framework reduces reliance on\nmanual testing and significantly enhances the security capabilities of LLMs.\nOur contributions include a novel adversarial framework, a comprehensive safety\ndataset, and after three iterations, the Target model achieves a security level\ncomparable to GPT-4, while the Red Team model shows a marked increase in attack\nsuccess rate (ASR) against advanced models. Our code and datasets are released\nat https://SEAS-LLM.github.io/.",
      "tldr_zh": "该研究提出SEAS框架，即Self-Evolving Adversarial Safety Optimization，用于提升大型语言模型(LLMs)的安全性和防范有害输出。SEAS通过模型自身生成数据，采用三个迭代阶段——Initialization、Attack和Adversarial Optimization——来优化Red Team模型（生成对抗提示）和Target模型，从而针对LLMs的弱点进行精确探索和强化。实验结果显示，经过三次迭代，Target模型的安全水平达到与GPT-4相当的水平，同时Red Team模型的攻击成功率(ASR)显著提升；此外，该框架还贡献了一个全面的安全数据集，并减少了对手动测试的依赖。代码和数据集已开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02632v2",
      "published_date": "2024-08-05 16:55:06 UTC",
      "updated_date": "2024-12-23 05:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:57:40.053676"
    },
    {
      "arxiv_id": "2408.02622v1",
      "title": "Language Model Can Listen While Speaking",
      "title_zh": "语言模型能够边说边听",
      "authors": [
        "Ziyang Ma",
        "Yakun Song",
        "Chenpeng Du",
        "Jian Cong",
        "Zhuo Chen",
        "Yuping Wang",
        "Yuxuan Wang",
        "Xie Chen"
      ],
      "abstract": "Dialogue serves as the most natural manner of human-computer interaction\n(HCI). Recent advancements in speech language models (SLM) have significantly\nenhanced speech-based conversational AI. However, these models are limited to\nturn-based conversation, lacking the ability to interact with humans in\nreal-time spoken scenarios, for example, being interrupted when the generated\ncontent is not satisfactory. To address these limitations, we explore full\nduplex modeling (FDM) in interactive speech language models (iSLM), focusing on\nenhancing real-time interaction and, more explicitly, exploring the\nquintessential ability of interruption. We introduce a novel model design,\nnamely listening-while-speaking language model (LSLM), an end-to-end system\nequipped with both listening and speaking channels. Our LSLM employs a\ntoken-based decoder-only TTS for speech generation and a streaming\nself-supervised learning (SSL) encoder for real-time audio input. LSLM fuses\nboth channels for autoregressive generation and detects turn-taking in real\ntime. Three fusion strategies -- early fusion, middle fusion, and late fusion\n-- are explored, with middle fusion achieving an optimal balance between speech\ngeneration and real-time interaction. Two experimental settings, command-based\nFDM and voice-based FDM, demonstrate LSLM's robustness to noise and sensitivity\nto diverse instructions. Our results highlight LSLM's capability to achieve\nduplex communication with minimal impact on existing systems. This study aims\nto advance the development of interactive speech dialogue systems, enhancing\ntheir applicability in real-world contexts.",
      "tldr_zh": "本研究针对现有语音语言模型（SLM）在对话交互中的局限性，如仅支持轮流对话且无法处理实时中断，提出了一种全双工建模（FDM）的交互式语音语言模型（iSLM），即listening-while-speaking language model (LSLM)。LSLM 采用端到端的系统设计，包括基于 token 的解码器 TTS 用于语音生成，以及流式自监督学习（SSL）编码器用于实时音频输入，并通过 early fusion、middle fusion 和 late fusion 策略融合双通道信息，其中 middle fusion 实现了最佳平衡。实验在基于命令和语音的 FDM 设置中验证了 LSLM 的鲁棒性、对噪声的抵抗力和对指令的敏感性，最终实现了高效的双工通信，并为实时交互式语音对话系统的实际应用奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Demo can be found at https://ddlbojack.github.io/LSLM",
      "pdf_url": "http://arxiv.org/pdf/2408.02622v1",
      "published_date": "2024-08-05 16:47:22 UTC",
      "updated_date": "2024-08-05 16:47:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:57:52.607600"
    },
    {
      "arxiv_id": "2408.02606v1",
      "title": "Backward explanations via redefinition of predicates",
      "title_zh": "翻译失败",
      "authors": [
        "Léo Saulières",
        "Martin C. Cooper",
        "Florence Dupin de Saint Cyr"
      ],
      "abstract": "History eXplanation based on Predicates (HXP), studies the behavior of a\nReinforcement Learning (RL) agent in a sequence of agent's interactions with\nthe environment (a history), through the prism of an arbitrary predicate. To\nthis end, an action importance score is computed for each action in the\nhistory. The explanation consists in displaying the most important actions to\nthe user. As the calculation of an action's importance is #W[1]-hard, it is\nnecessary for long histories to approximate the scores, at the expense of their\nquality. We therefore propose a new HXP method, called Backward-HXP, to provide\nexplanations for these histories without having to approximate scores.\nExperiments show the ability of B-HXP to summarise long histories.",
      "tldr_zh": "本论文针对强化学习 (RL) 代理的行为解释，扩展了 History eXplanation based on Predicates (HXP) 方法，通过计算动作重要性分数来分析代理在历史序列中的关键动作，但该计算被证明是 #W[1]-hard 的，需依赖近似处理。论文提出新方法 Backward-HXP，通过重新定义谓词 (redefinition of predicates) 实现后向解释，避免了分数近似，从而为长历史序列提供精确总结。实验结果表明，Backward-HXP 有效总结了长历史，提升了解释的质量和可靠性。",
      "categories": [
        "cs.AI",
        "cs.CC",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02606v1",
      "published_date": "2024-08-05 16:31:38 UTC",
      "updated_date": "2024-08-05 16:31:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:58:03.993095"
    },
    {
      "arxiv_id": "2408.02599v2",
      "title": "Progressively Label Enhancement for Large Language Model Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Biao Liu",
        "Ning Xu",
        "Xin Geng"
      ],
      "abstract": "Large Language Models (LLM) alignment aims to prevent models from producing\ncontent that misaligns with human expectations, which can lead to ethical and\nlegal concerns. In the last few years, Reinforcement Learning from Human\nFeedback (RLHF) has been the most prominent method for achieving alignment. Due\nto challenges in stability and scalability with RLHF stages, which arise from\nthe complex interactions between multiple models, researchers are exploring\nalternative methods to achieve effects comparable to those of RLHF. However,\nthese methods often rely on large high-quality datasets. Despite some methods\nconsidering the generation of additional data to expand datasets, they often\ntreat model training and data generation as separate and static processes,\noverlooking the fact that these processes are highly interdependent, leading to\ninefficient utilization of the generated data. To deal with this problem, we\npropose PLE, i.e., Progressively Label Enhancement for LLM Alignment, a\nframework that dynamically adjusts the model's training process based on the\nevolving quality of the generated data. Specifically, we prompt the model to\ngenerate responses for both the original query and the query guided by a set of\ncarefully designed principles, and then utilize a dynamic threshold to\ndetermine the appropriate training approach for both responses based on their\ncorresponding reward scores. Experimental results demonstrate the effectiveness\nof PLE compared to existing LLM alignment methods.",
      "tldr_zh": "大型语言模型 (LLM) 的对齐旨在防止模型输出不符合人类期望的内容，但传统方法如 Reinforcement Learning from Human Feedback (RLHF) 面临稳定性和可扩展性挑战。论文提出 PLE（Progressively Label Enhancement）框架，通过动态调整训练过程来优化数据生成和利用效率。具体而言，PLE 提示模型为原始查询和基于设计原则的查询生成响应，并利用动态阈值根据奖励分数决定训练策略。实验结果显示，PLE 比现有 LLM 对齐方法更有效。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02599v2",
      "published_date": "2024-08-05 16:21:17 UTC",
      "updated_date": "2024-10-09 07:31:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:58:16.630386"
    },
    {
      "arxiv_id": "2408.02595v1",
      "title": "Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Sajal Aggarwal",
        "Ananya Pandey",
        "Dinesh Kumar Vishwakarma"
      ],
      "abstract": "Sarcasm is a type of irony, characterized by an inherent mismatch between the\nliteral interpretation and the intended connotation. Though sarcasm detection\nin text has been extensively studied, there are situations in which textual\ninput alone might be insufficient to perceive sarcasm. The inclusion of\nadditional contextual cues, such as images, is essential to recognize sarcasm\nin social media data effectively. This study presents a novel framework for\nmultimodal sarcasm detection that can process input triplets. Two components of\nthese triplets comprise the input text and its associated image, as provided in\nthe datasets. Additionally, a supplementary modality is introduced in the form\nof descriptive image captions. The motivation behind incorporating this visual\nsemantic representation is to more accurately capture the discrepancies between\nthe textual and visual content, which are fundamental to the sarcasm detection\ntask. The primary contributions of this study are: (1) a robust textual feature\nextraction branch that utilizes a cross-lingual language model; (2) a visual\nfeature extraction branch that incorporates a self-regulated residual ConvNet\nintegrated with a lightweight spatially aware attention module; (3) an\nadditional modality in the form of image captions generated using an\nencoder-decoder architecture capable of reading text embedded in images; (4)\ndistinct attention modules to effectively identify the incongruities between\nthe text and two levels of image representations; (5) multi-level cross-domain\nsemantic incongruity representation achieved through feature fusion. Compared\nwith cutting-edge baselines, the proposed model achieves the best accuracy of\n92.89% and 64.48%, respectively, on the Twitter multimodal sarcasm and\nMultiBully datasets.",
      "tldr_zh": "这篇论文提出了一种新框架，用于多模态讽刺检测（Multimodal Sarcasm Detection），通过整合文本、图像和生成的图像标题来捕捉跨模态语义不一致（cross-modal semantic incongruity）。框架的核心组件包括基于跨语言语言模型（cross-lingual language model）的文本特征提取分支，以及结合自调节残差 ConvNet 和轻量级空间注意力模块（spatially aware attention module）的视觉特征提取分支。论文的主要贡献是引入图像标题作为额外模态、使用编码器-解码器架构生成标题，并通过 distinct attention modules 实现多级跨域语义不一致表示（multi-level cross-domain semantic incongruity representation）。实验结果显示，该模型在 Twitter multimodal sarcasm 数据集上达到 92.89% 的准确率，在 MultiBully 数据集上达到 64.48%，优于现有基线。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02595v1",
      "published_date": "2024-08-05 16:07:31 UTC",
      "updated_date": "2024-08-05 16:07:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:58:32.214914"
    },
    {
      "arxiv_id": "2408.02584v1",
      "title": "Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization",
      "title_zh": "利用 LLMs 的强大能力：一种微调方法用于高质量的",
      "authors": [
        "Ankan Mullick",
        "Sombit Bose",
        "Rounak Saha",
        "Ayan Kumar Bhowmick",
        "Aditya Vempaty",
        "Pawan Goyal",
        "Niloy Ganguly",
        "Prasenjit Dey",
        "Ravi Kokku"
      ],
      "abstract": "The ever-increasing volume of digital information necessitates efficient\nmethods for users to extract key insights from lengthy documents. Aspect-based\nsummarization offers a targeted approach, generating summaries focused on\nspecific aspects within a document. Despite advancements in aspect-based\nsummarization research, there is a continuous quest for improved model\nperformance. Given that large language models (LLMs) have demonstrated the\npotential to revolutionize diverse tasks within natural language processing,\nparticularly in the problem of summarization, this paper explores the potential\nof fine-tuning LLMs for the aspect-based summarization task. We evaluate the\nimpact of fine-tuning open-source foundation LLMs, including Llama2, Mistral,\nGemma and Aya, on a publicly available domain-specific aspect based summary\ndataset. We hypothesize that this approach will enable these models to\neffectively identify and extract aspect-related information, leading to\nsuperior quality aspect-based summaries compared to the state-of-the-art. We\nestablish a comprehensive evaluation framework to compare the performance of\nfine-tuned LLMs against competing aspect-based summarization methods and\nvanilla counterparts of the fine-tuned LLMs. Our work contributes to the field\nof aspect-based summarization by demonstrating the efficacy of fine-tuning LLMs\nfor generating high-quality aspect-based summaries. Furthermore, it opens doors\nfor further exploration of using LLMs for targeted information extraction tasks\nacross various NLP domains.",
      "tldr_zh": "这篇论文探讨了通过微调大型语言模型（LLMs）来提升基于方面的摘要（Aspect-Based Summarization）质量的方法，旨在帮助用户从长文档中高效提取特定方面的关键洞见。研究者使用了开源LLMs（如Llama2、Mistral、Gemma和Aya）在公开数据集上进行微调，假设这能使模型更有效地识别和提取方面相关信息。实验结果显示，微调后的LLMs在全面评估框架中比现有方法和未微调模型表现更优，为NLP领域的信息提取任务提供了新探索方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02584v1",
      "published_date": "2024-08-05 16:00:21 UTC",
      "updated_date": "2024-08-05 16:00:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:58:40.970230"
    },
    {
      "arxiv_id": "2408.02582v1",
      "title": "Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition",
      "title_zh": "带口音语音的聚类和挖掘：用于包容性和公平的语音识别",
      "authors": [
        "Jaeyoung Kim",
        "Han Lu",
        "Soheil Khorram",
        "Anshuman Tripathi",
        "Qian Zhang",
        "Hasim Sak"
      ],
      "abstract": "Modern automatic speech recognition (ASR) systems are typically trained on\nmore than tens of thousands hours of speech data, which is one of the main\nfactors for their great success. However, the distribution of such data is\ntypically biased towards common accents or typical speech patterns. As a\nresult, those systems often poorly perform on atypical accented speech. In this\npaper, we present accent clustering and mining schemes for fair speech\nrecognition systems which can perform equally well on under-represented\naccented speech. For accent recognition, we applied three schemes to overcome\nlimited size of supervised accent data: supervised or unsupervised\npre-training, distributionally robust optimization (DRO) and unsupervised\nclustering. Three schemes can significantly improve the accent recognition\nmodel especially for unbalanced and small accented speech. Fine-tuning ASR on\nthe mined Indian accent speech using the proposed supervised or unsupervised\nclustering schemes showed 10.0% and 5.3% relative improvements compared to\nfine-tuning on the randomly sampled speech, respectively.",
      "tldr_zh": "本研究针对现代自动语音识别（ASR）系统因训练数据偏向常见口音而导致对非典型口音识别性能较差的问题，提出了口音聚类和挖掘方案，以实现更具包容性和公平性的语音识别。方案包括监督或无监督预训练、分布鲁棒优化（DRO）和无监督聚类三种方法，这些方法显著提升了口音识别模型的表现，尤其在不平衡和小样本数据上。实验结果显示，在使用这些方案对印度口音语音进行微调后，ASR 系统的性能分别比随机采样微调提高了 10.0% 和 5.3% 的相对改善。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02582v1",
      "published_date": "2024-08-05 16:00:07 UTC",
      "updated_date": "2024-08-05 16:00:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:58:55.451377"
    },
    {
      "arxiv_id": "2408.10248v1",
      "title": "Target-Dependent Multimodal Sentiment Analysis Via Employing Visual-to Emotional-Caption Translation Network using Visual-Caption Pairs",
      "title_zh": "翻译失败",
      "authors": [
        "Ananya Pandey",
        "Dinesh Kumar Vishwakarma"
      ],
      "abstract": "The natural language processing and multimedia field has seen a notable surge\nin interest in multimodal sentiment recognition. Hence, this study aims to\nemploy Target-Dependent Multimodal Sentiment Analysis (TDMSA) to identify the\nlevel of sentiment associated with every target (aspect) stated within a\nmultimodal post consisting of a visual-caption pair. Despite the recent\nadvancements in multimodal sentiment recognition, there has been a lack of\nexplicit incorporation of emotional clues from the visual modality,\nspecifically those pertaining to facial expressions. The challenge at hand is\nto proficiently obtain visual and emotional clues and subsequently synchronise\nthem with the textual content. In light of this fact, this study presents a\nnovel approach called the Visual-to-Emotional-Caption Translation Network\n(VECTN) technique. The primary objective of this strategy is to effectively\nacquire visual sentiment clues by analysing facial expressions. Additionally,\nit effectively aligns and blends the obtained emotional clues with the target\nattribute of the caption mode. The experimental findings demonstrate that our\nmethodology is capable of producing ground-breaking outcomes when applied to\ntwo publicly accessible multimodal Twitter datasets, namely, Twitter-2015 and\nTwitter-2017. The experimental results show that the suggested model achieves\nan accuracy of 81.23% and a macro-F1 of 80.61% on the Twitter-15 dataset, while\n77.42% and 75.19% on the Twitter-17 dataset, respectively. The observed\nimprovement in performance reveals that our model is better than others when it\ncomes to collecting target-level sentiment in multimodal data using the\nexpressions of the face.",
      "tldr_zh": "本研究针对Target-Dependent Multimodal Sentiment Analysis (TDMSA)，提出了一种新方法Visual-to-Emotional-Caption Translation Network (VECTN)，通过分析视觉模态中的面部表情来提取情感线索，并将其与标题文本的目标属性对齐和融合，从而提升多模态帖子（如视觉-标题对）中目标级情感识别的准确性。该方法解决了现有模型在同步视觉情感线索和文本内容方面的不足，在Twitter-2015和Twitter-2017数据集上分别实现了81.23%的准确率和80.61%的macro-F1，以及77.42%和75.19%的相应指标。实验结果表明，VECTN在利用面部表情进行multimodal sentiment analysis时，显著优于其他基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10248v1",
      "published_date": "2024-08-05 15:56:55 UTC",
      "updated_date": "2024-08-05 15:56:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:59:06.098785"
    },
    {
      "arxiv_id": "2408.10247v1",
      "title": "MetaEnzyme: Meta Pan-Enzyme Learning for Task-Adaptive Redesign",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangbin Zheng",
        "Han Zhang",
        "Qianqing Xu",
        "An-Ping Zeng",
        "Stan Z. Li"
      ],
      "abstract": "Enzyme design plays a crucial role in both industrial production and biology.\nHowever, this field faces challenges due to the lack of comprehensive\nbenchmarks and the complexity of enzyme design tasks, leading to a dearth of\nsystematic research. Consequently, computational enzyme design is relatively\noverlooked within the broader protein domain and remains in its early stages.\nIn this work, we address these challenges by introducing MetaEnzyme, a staged\nand unified enzyme design framework. We begin by employing a cross-modal\nstructure-to-sequence transformation architecture, as the feature-driven\nstarting point to obtain initial robust protein representation. Subsequently,\nwe leverage domain adaptive techniques to generalize specific enzyme design\ntasks under low-resource conditions. MetaEnzyme focuses on three fundamental\nlow-resource enzyme redesign tasks: functional design (FuncDesign), mutation\ndesign (MutDesign), and sequence generation design (SeqDesign). Through novel\nunified paradigm and enhanced representation capabilities, MetaEnzyme\ndemonstrates adaptability to diverse enzyme design tasks, yielding outstanding\nresults. Wet lab experiments further validate these findings, reinforcing the\nefficacy of the redesign process.",
      "tldr_zh": "本研究针对酶设计领域的基准缺失和任务复杂性问题，提出MetaEnzyme框架，这是一种元泛酶学习方法，支持任务自适应重设计。框架首先采用跨模态structure-to-sequence转换架构获取鲁棒的蛋白质表示，然后通过domain adaptive techniques在低资源条件下泛化三个关键任务：FuncDesign（功能设计）、MutDesign（突变设计）和SeqDesign（序列生成设计）。实验结果显示，MetaEnzyme在多样酶设计任务上表现出色，并经湿实验室实验验证其重设计过程的有效性。",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "Accepted to ACM Multimedia 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10247v1",
      "published_date": "2024-08-05 15:48:39 UTC",
      "updated_date": "2024-08-05 15:48:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:59:17.986196"
    },
    {
      "arxiv_id": "2408.02571v1",
      "title": "Contrastive Learning-based Multi Modal Architecture for Emoticon Prediction by Employing Image-Text Pairs",
      "title_zh": "翻译失败",
      "authors": [
        "Ananya Pandey",
        "Dinesh Kumar Vishwakarma"
      ],
      "abstract": "The emoticons are symbolic representations that generally accompany the\ntextual content to visually enhance or summarize the true intention of a\nwritten message. Although widely utilized in the realm of social media, the\ncore semantics of these emoticons have not been extensively explored based on\nmultiple modalities. Incorporating textual and visual information within a\nsingle message develops an advanced way of conveying information. Hence, this\nresearch aims to analyze the relationship among sentences, visuals, and\nemoticons. For an orderly exposition, this paper initially provides a detailed\nexamination of the various techniques for extracting multimodal features,\nemphasizing the pros and cons of each method. Through conducting a\ncomprehensive examination of several multimodal algorithms, with specific\nemphasis on the fusion approaches, we have proposed a novel contrastive\nlearning based multimodal architecture. The proposed model employs the joint\ntraining of dual-branch encoder along with the contrastive learning to\naccurately map text and images into a common latent space. Our key finding is\nthat by integrating the principle of contrastive learning with that of the\nother two branches yields superior results. The experimental results\ndemonstrate that our suggested methodology surpasses existing multimodal\napproaches in terms of accuracy and robustness. The proposed model attained an\naccuracy of 91% and an MCC-score of 90% while assessing emoticons using the\nMultimodal-Twitter Emoticon dataset acquired from Twitter. We provide evidence\nthat deep features acquired by contrastive learning are more efficient,\nsuggesting that the proposed fusion technique also possesses strong\ngeneralisation capabilities for recognising emoticons across several modes.",
      "tldr_zh": "该研究探讨了表情符号（emoticons）在社交媒体中的语义，通过整合文本和图像的多模态信息来预测表情符号。论文提出了一种基于对比学习（contrastive learning）的多模态架构，使用双分支编码器（dual-branch encoder）将文本和图像映射到共同的潜在空间，并通过联合训练提升模型性能。实验结果显示，该方法在 Multimodal-Twitter Emoticon 数据集上达到了 91% 的准确率和 90% 的 MCC 分数，比现有多模态方法更准确、鲁棒，并证明了对比学习在特征提取和泛化能力上的优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02571v1",
      "published_date": "2024-08-05 15:45:59 UTC",
      "updated_date": "2024-08-05 15:45:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:59:30.880718"
    },
    {
      "arxiv_id": "2408.10246v1",
      "title": "VyAnG-Net: A Novel Multi-Modal Sarcasm Recognition Model by Uncovering Visual, Acoustic and Glossary Features",
      "title_zh": "翻译失败",
      "authors": [
        "Ananya Pandey",
        "Dinesh Kumar Vishwakarma"
      ],
      "abstract": "Various linguistic and non-linguistic clues, such as excessive emphasis on a\nword, a shift in the tone of voice, or an awkward expression, frequently convey\nsarcasm. The computer vision problem of sarcasm recognition in conversation\naims to identify hidden sarcastic, criticizing, and metaphorical information\nembedded in everyday dialogue. Prior, sarcasm recognition has focused mainly on\ntext. Still, it is critical to consider all textual information, audio stream,\nfacial expression, and body position for reliable sarcasm identification.\nHence, we propose a novel approach that combines a lightweight depth attention\nmodule with a self-regulated ConvNet to concentrate on the most crucial\nfeatures of visual data and an attentional tokenizer based strategy to extract\nthe most critical context-specific information from the textual data. The\nfollowing is a list of the key contributions that our experimentation has made\nin response to performing the task of Multi-modal Sarcasm Recognition: an\nattentional tokenizer branch to get beneficial features from the glossary\ncontent provided by the subtitles; a visual branch for acquiring the most\nprominent features from the video frames; an utterance-level feature extraction\nfrom acoustic content and a multi-headed attention based feature fusion branch\nto blend features obtained from multiple modalities. Extensive testing on one\nof the benchmark video datasets, MUSTaRD, yielded an accuracy of 79.86% for\nspeaker dependent and 76.94% for speaker independent configuration\ndemonstrating that our approach is superior to the existing methods. We have\nalso conducted a cross-dataset analysis to test the adaptability of VyAnG-Net\nwith unseen samples of another dataset MUStARD++.",
      "tldr_zh": "该论文提出了 VyAnG-Net，一种新型的多模态讽刺识别模型，通过整合视觉、声学和文本特征（如 facial expression 和 body position）来识别对话中的隐藏讽刺信息。模型采用轻量级深度注意力模块与自调节 ConvNet 处理视觉数据，注意力 tokenizer 提取文本关键特征，并结合utterance-level 声学特征提取和多头注意力机制进行特征融合。实验结果显示，在 MUSTaRD 数据集上，VyAnG-Net 在说话者相关配置下达到 79.86% 的准确率，在说话者独立配置下达到 76.94%，优于现有方法，并通过跨数据集分析验证了其在 MUStARD++ 上的适应性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10246v1",
      "published_date": "2024-08-05 15:36:52 UTC",
      "updated_date": "2024-08-05 15:36:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:59:42.999138"
    },
    {
      "arxiv_id": "2408.02559v1",
      "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information",
      "title_zh": "翻译失败",
      "authors": [
        "Yauwai Yim",
        "Chunkit Chan",
        "Tianyu Shi",
        "Zheye Deng",
        "Wei Fan",
        "Tianshi Zheng",
        "Yangqiu Song"
      ],
      "abstract": "Large language models (LLMs) have shown success in handling simple games with\nimperfect information and enabling multi-agent coordination, but their ability\nto facilitate practical collaboration against other agents in complex,\nimperfect information environments, especially in a non-English environment,\nstill needs to be explored. This study investigates the applicability of\nknowledge acquired by open-source and API-based LLMs to sophisticated\ntext-based games requiring agent collaboration under imperfect information,\ncomparing their performance to established baselines using other types of\nagents. We propose a Theory of Mind (ToM) planning technique that allows LLM\nagents to adapt their strategy against various adversaries using only game\nrules, current state, and historical context as input. An external tool was\nincorporated to mitigate the challenge of dynamic and extensive action spaces\nin this card game. Our results show that although a performance gap exists\nbetween current LLMs and state-of-the-art reinforcement learning (RL) models,\nLLMs demonstrate ToM capabilities in this game setting. It consistently\nimproves their performance against opposing agents, suggesting their ability to\nunderstand the actions of allies and adversaries and establish collaboration\nwith allies. To encourage further research and understanding, we have made our\ncodebase openly accessible.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 代理在不完美信息的多玩家合作游戏 Guandan 中的性能，并提出了一种基于 Theory of Mind (ToM) 的规划技术，以帮助 LLMs 代理适应策略，仅依赖游戏规则、当前状态和历史上下文。研究通过比较开源和 API 基于的 LLMs 与其他代理基线，引入外部工具来处理动态行动空间的问题。结果显示，虽然 LLMs 的表现仍落后于最先进的 reinforcement learning (RL) 模型，但它们展示了 ToM 能力，能有效改善对抗对手的表现并与盟友建立合作。最后，研究开源了代码，以促进进一步探索。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02559v1",
      "published_date": "2024-08-05 15:36:46 UTC",
      "updated_date": "2024-08-05 15:36:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T12:59:54.868180"
    },
    {
      "arxiv_id": "2408.02555v3",
      "title": "MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwen Chen",
        "Yikai Wang",
        "Yihao Luo",
        "Zhengyi Wang",
        "Zilong Chen",
        "Jun Zhu",
        "Chi Zhang",
        "Guosheng Lin"
      ],
      "abstract": "Meshes are the de facto 3D representation in the industry but are\nlabor-intensive to produce. Recently, a line of research has focused on\nautoregressively generating meshes. This approach processes meshes into a\nsequence composed of vertices and then generates them vertex by vertex, similar\nto how a language model generates text. These methods have achieved some\nsuccess but still struggle to generate complex meshes. One primary reason for\nthis limitation is their inefficient tokenization methods. To address this\nissue, we introduce MeshAnything V2, an advanced mesh generation model designed\nto create Artist-Created Meshes that align precisely with specified shapes. A\nkey innovation behind MeshAnything V2 is our novel Adjacent Mesh Tokenization\n(AMT) method. Unlike traditional approaches that represent each face using\nthree vertices, AMT optimizes this by employing a single vertex wherever\nfeasible, effectively reducing the token sequence length by about half on\naverage. This not only streamlines the tokenization process but also results in\nmore compact and well-structured sequences, enhancing the efficiency of mesh\ngeneration. With these improvements, MeshAnything V2 effectively doubles the\nface limit compared to previous models, delivering superior performance without\nincreasing computational costs. We will make our code and models publicly\navailable. Project Page: https://buaacyw.github.io/meshanything-v2/",
      "tldr_zh": "该论文提出MeshAnything V2，一种先进的网格生成模型，旨在高效创建与指定形状精确对齐的Artist-Created Meshes，以解决现有自动回归网格生成方法的低效tokenization问题。核心创新是Adjacent Mesh Tokenization (AMT)方法，该方法通过在可能时使用单个顶点表示每个面，将标记序列长度平均减少一半，从而提升生成效率。结果表明，MeshAnything V2将面限制提高了一倍，同时不增加计算成本，并计划公开代码和模型以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://buaacyw.github.io/meshanything-v2/ Github:\n  https://github.com/buaacyw/MeshAnythingV2",
      "pdf_url": "http://arxiv.org/pdf/2408.02555v3",
      "published_date": "2024-08-05 15:33:45 UTC",
      "updated_date": "2024-12-01 14:34:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:00:06.623852"
    },
    {
      "arxiv_id": "2408.02547v1",
      "title": "The Role of Functional Muscle Networks in Improving Hand Gesture Perception for Human-Machine Interfaces",
      "title_zh": "功能性肌肉网络在提升人机界面手势感知中的作用",
      "authors": [
        "Costanza Armanini",
        "Tuka Alhanai",
        "Farah E. Shamout",
        "S. Farokh Atashzar"
      ],
      "abstract": "Developing accurate hand gesture perception models is critical for various\nrobotic applications, enabling effective communication between humans and\nmachines and directly impacting neurorobotics and interactive robots. Recently,\nsurface electromyography (sEMG) has been explored for its rich informational\ncontext and accessibility when combined with advanced machine learning\napproaches and wearable systems. The literature presents numerous approaches to\nboost performance while ensuring robustness for neurorobots using sEMG, often\nresulting in models requiring high processing power, large datasets, and less\nscalable solutions. This paper addresses this challenge by proposing the\ndecoding of muscle synchronization rather than individual muscle activation. We\nstudy coherence-based functional muscle networks as the core of our perception\nmodel, proposing that functional synchronization between muscles and the\ngraph-based network of muscle connectivity encode contextual information about\nintended hand gestures. This can be decoded using shallow machine learning\napproaches without the need for deep temporal networks. Our technique could\nimpact myoelectric control of neurorobots by reducing computational burdens and\nenhancing efficiency. The approach is benchmarked on the Ninapro database,\nwhich contains 12 EMG signals from 40 subjects performing 17 hand gestures. It\nachieves an accuracy of 85.1%, demonstrating improved performance compared to\nexisting methods while requiring much less computational power. The results\nsupport the hypothesis that a coherence-based functional muscle network encodes\ncritical information related to gesture execution, significantly enhancing hand\ngesture perception with potential applications for neurorobotic systems and\ninteractive machines.",
      "tldr_zh": "本论文探讨了功能肌肉网络（functional muscle networks）在提升手势感知模型方面的作用，以改善人机接口，特别是神经机器人和交互机器人应用。研究提出一种基于相干性（coherence-based）的功能肌肉网络方法，通过解码肌肉同步性而非单个肌肉激活，使用浅层机器学习（shallow machine learning）来编码手势信息，从而减少计算负担并提高效率。在 Ninapro 数据库上测试，该方法在 40 名受试者执行 17 个手势时，准确率达到 85.1%，优于现有方法，并证明功能肌肉网络能有效捕捉手势相关关键信息。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02547v1",
      "published_date": "2024-08-05 15:17:34 UTC",
      "updated_date": "2024-08-05 15:17:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:00:18.020795"
    },
    {
      "arxiv_id": "2408.02545v1",
      "title": "RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Fleischer",
        "Moshe Berchansky",
        "Moshe Wasserblat",
        "Peter Izsak"
      ],
      "abstract": "Implementing Retrieval-Augmented Generation (RAG) systems is inherently\ncomplex, requiring deep understanding of data, use cases, and intricate design\ndecisions. Additionally, evaluating these systems presents significant\nchallenges, necessitating assessment of both retrieval accuracy and generative\nquality through a multi-faceted approach. We introduce RAG Foundry, an\nopen-source framework for augmenting large language models for RAG use cases.\nRAG Foundry integrates data creation, training, inference and evaluation into a\nsingle workflow, facilitating the creation of data-augmented datasets for\ntraining and evaluating large language models in RAG settings. This integration\nenables rapid prototyping and experimentation with various RAG techniques,\nallowing users to easily generate datasets and train RAG models using internal\nor specialized knowledge sources. We demonstrate the framework effectiveness by\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\nconfigurations, showcasing consistent improvements across three\nknowledge-intensive datasets. Code is released as open-source in\nhttps://github.com/IntelLabs/RAGFoundry.",
      "tldr_zh": "该研究指出，实现 Retrieval-Augmented Generation (RAG) 系统面临复杂挑战，包括设计决策和评估检索准确性与生成质量的问题。为解决这些问题，论文引入了开源框架 RAG Foundry，它整合数据创建、训练、推理和评估的工作流，支持快速原型设计和使用内部知识来源生成数据增强数据集。通过该框架增强和微调 Llama-3 和 Phi-3 模型，实验在三个知识密集型数据集上实现了持续性能改进。代码已在 https://github.com/IntelLabs/RAGFoundry 开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.02545v1",
      "published_date": "2024-08-05 15:16:24 UTC",
      "updated_date": "2024-08-05 15:16:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:00:31.539895"
    },
    {
      "arxiv_id": "2408.02529v2",
      "title": "Explaining Reinforcement Learning: A Counterfactual Shapley Values Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwei Shi",
        "Qi Zhang",
        "Kevin McAreavey",
        "Weiru Liu"
      ],
      "abstract": "This paper introduces a novel approach Counterfactual Shapley Values (CSV),\nwhich enhances explainability in reinforcement learning (RL) by integrating\ncounterfactual analysis with Shapley Values. The approach aims to quantify and\ncompare the contributions of different state dimensions to various action\nchoices. To more accurately analyze these impacts, we introduce new\ncharacteristic value functions, the ``Counterfactual Difference Characteristic\nValue\" and the ``Average Counterfactual Difference Characteristic Value.\" These\nfunctions help calculate the Shapley values to evaluate the differences in\ncontributions between optimal and non-optimal actions. Experiments across\nseveral RL domains, such as GridWorld, FrozenLake, and Taxi, demonstrate the\neffectiveness of the CSV method. The results show that this method not only\nimproves transparency in complex RL systems but also quantifies the differences\nacross various decisions.",
      "tldr_zh": "这篇论文提出了 Counterfactual Shapley Values (CSV) 方法，通过整合反事实分析和 Shapley Values 来提升强化学习 (RL) 的可解释性，旨在量化不同状态维度对各种动作选择的影响。该方法引入了新的特征值函数，包括 \"Counterfactual Difference Characteristic Value\" 和 \"Average Counterfactual Difference Characteristic Value\"，用于计算 Shapley Values 并评估最优动作与非最优动作之间的贡献差异。在 GridWorld、FrozenLake 和 Taxi 等 RL 领域进行的实验证明，CSV 方法显著提高了复杂 RL 系统的透明度，并有效量化了决策差异。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02529v2",
      "published_date": "2024-08-05 14:49:12 UTC",
      "updated_date": "2024-08-06 07:32:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:00:42.045704"
    },
    {
      "arxiv_id": "2408.02525v1",
      "title": "Single-tap Latency Reduction with Single- or Double- tap Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Naoto Nishida",
        "Kaori Ikematsu",
        "Junichi Sato",
        "Shota Yamanaka",
        "Kota Tsubouchi"
      ],
      "abstract": "Touch surfaces are widely utilized for smartphones, tablet PCs, and laptops\n(touchpad), and single and double taps are the most basic and common operations\non them. The detection of single or double taps causes the single-tap latency\nproblem, which creates a bottleneck in terms of the sensitivity of touch\ninputs. To reduce the single-tap latency, we propose a novel\nmachine-learning-based tap prediction method called PredicTaps. Our method\npredicts whether a detected tap is a single tap or the first contact of a\ndouble tap without having to wait for the hundreds of milliseconds\nconventionally required. We present three evaluations and one user evaluation\nthat demonstrate its broad applicability and usability for various tap\nsituations on two form factors (touchpad and smartphone). The results showed\nPredicTaps reduces the single-tap latency from 150-500 ms to 12 ms on laptops\nand to 17.6 ms on smartphones without reducing usability.",
      "tldr_zh": "本研究针对触控设备（如智能手机和触控板）上的单击延迟问题，提出了一种基于机器学习的点击预测方法PredicTaps。PredicTaps能够实时预测一个点击是单击还是双击的第一次点击，从而避免传统数百毫秒的等待时间。实验结果显示，该方法将单击延迟从150-500毫秒减少到12毫秒（触控板）和17.6毫秒（智能手机），并通过多个评估证明了其在各种场景下的适用性和可用性而不降低用户体验。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02525v1",
      "published_date": "2024-08-05 14:46:04 UTC",
      "updated_date": "2024-08-05 14:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:00:55.313783"
    },
    {
      "arxiv_id": "2408.04658v1",
      "title": "Winning Amazon KDD Cup'24",
      "title_zh": "翻译失败",
      "authors": [
        "Chris Deotte",
        "Ivan Sorokin",
        "Ahmet Erdem",
        "Benedikt Schifferer",
        "Gilberto Titericz Jr",
        "Simon Jegou"
      ],
      "abstract": "This paper describes the winning solution of all 5 tasks for the Amazon KDD\nCup 2024 Multi Task Online Shopping Challenge for LLMs. The challenge was to\nbuild a useful assistant, answering questions in the domain of online shopping.\nThe competition contained 57 diverse tasks, covering 5 different task types\n(e.g. multiple choice) and across 4 different tracks (e.g. multi-lingual). Our\nsolution is a single model per track. We fine-tune Qwen2-72B-Instruct on our\nown training dataset. As the competition released only 96 example questions, we\ndeveloped our own training dataset by processing multiple public datasets or\nusing Large Language Models for data augmentation and synthetic data\ngeneration. We apply wise-ft to account for distribution shifts and ensemble\nmultiple LoRA adapters in one model. We employed Logits Processors to constrain\nthe model output on relevant tokens for the tasks. AWQ 4-bit Quantization and\nvLLM are used during inference to predict the test dataset in the time\nconstraints of 20 to 140 minutes depending on the track. Our solution achieved\nthe first place in each individual track and is the first place overall of\nAmazons KDD Cup 2024.",
      "tldr_zh": "这篇论文介绍了在 Amazon KDD Cup 2024 多任务在线购物挑战中赢得所有 5 个任务的获胜解决方案，该挑战涉及构建一个基于 LLMs 的在线购物助手，处理 57 个多样化任务（涵盖 5 种任务类型和 4 个轨道）。研究团队通过微调 Qwen2-72B-Instruct 模型，并使用自定义训练数据集（包括处理公共数据集、LLMs 数据增强和合成数据生成）来实现每个轨道的单一模型，同时应用 wise-ft 处理分布偏移、集成多个 LoRA adapters、Logits Processors 约束输出，以及 AWQ 4-bit Quantization 和 vLLM 优化推理过程。最终，该方案在所有 4 个轨道上均获得第一名，并在整体比赛中排名第一，展示了其在多语言和多任务环境中的高效性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04658v1",
      "published_date": "2024-08-05 14:40:04 UTC",
      "updated_date": "2024-08-05 14:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:01:09.195946"
    },
    {
      "arxiv_id": "2408.02714v1",
      "title": "MDM: Advancing Multi-Domain Distribution Matching for Automatic Modulation Recognition Dataset Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Dongwei Xu",
        "Jiajun Chen",
        "Yao Lu",
        "Tianhao Xia",
        "Qi Xuan",
        "Wei Wang",
        "Yun Lin",
        "Xiaoniu Yang"
      ],
      "abstract": "Recently, deep learning technology has been successfully introduced into\nAutomatic Modulation Recognition (AMR) tasks. However, the success of deep\nlearning is all attributed to the training on large-scale datasets. Such a\nlarge amount of data brings huge pressure on storage, transmission and model\ntraining. In order to solve the problem of large amount of data, some\nresearchers put forward the method of data distillation, which aims to compress\nlarge training data into smaller synthetic datasets to maintain its\nperformance. While numerous data distillation techniques have been developed\nwithin the realm of image processing, the unique characteristics of signals set\nthem apart. Signals exhibit distinct features across various domains,\nnecessitating specialized approaches for their analysis and processing. To this\nend, a novel dataset distillation method--Multi-domain Distribution Matching\n(MDM) is proposed. MDM employs the Discrete Fourier Transform (DFT) to\ntranslate timedomain signals into the frequency domain, and then uses a model\nto compute distribution matching losses between the synthetic and real\ndatasets, considering both the time and frequency domains. Ultimately, these\ntwo losses are integrated to update the synthetic dataset. We conduct extensive\nexperiments on three AMR datasets. Experimental results show that, compared\nwith baseline methods, our method achieves better performance under the same\ncompression ratio. Furthermore, we conduct crossarchitecture generalization\nexperiments on several models, and the experimental results show that our\nsynthetic datasets can generalize well on other unseen models.",
      "tldr_zh": "该论文针对 Automatic Modulation Recognition (AMR) 任务中深度学习模型依赖大量数据带来的存储和训练压力，提出了一种新型数据集蒸馏方法——Multi-domain Distribution Matching (MDM)。MDM 通过 Discrete Fourier Transform (DFT) 将时域信号转换为频域，并计算合成数据集与真实数据集在时域和频域的分布匹配损失，然后整合这些损失来优化合成数据集。实验结果显示，在三个 AMR 数据集上，MDM 在相同压缩比下比基线方法表现出色，并证明了其合成数据集在跨架构泛化实验中具有良好的适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02714v1",
      "published_date": "2024-08-05 14:16:54 UTC",
      "updated_date": "2024-08-05 14:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:01:19.641134"
    },
    {
      "arxiv_id": "2408.02487v3",
      "title": "LiCoEval: Evaluating LLMs on License Compliance in Code Generation",
      "title_zh": "LiCoEval：评估 LLMs 在代码生成中的许可证合规性",
      "authors": [
        "Weiwei Xu",
        "Kai Gao",
        "Hao He",
        "Minghui Zhou"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have revolutionized code\ngeneration, leading to widespread adoption of AI coding tools by developers.\nHowever, LLMs can generate license-protected code without providing the\nnecessary license information, leading to potential intellectual property\nviolations during software production. This paper addresses the critical, yet\nunderexplored, issue of license compliance in LLM-generated code by\nestablishing a benchmark to evaluate the ability of LLMs to provide accurate\nlicense information for their generated code. To establish this benchmark, we\nconduct an empirical study to identify a reasonable standard for \"striking\nsimilarity\" that excludes the possibility of independent creation, indicating a\ncopy relationship between the LLM output and certain open-source code. Based on\nthis standard, we propose LiCoEval, to evaluate the license compliance\ncapabilities of LLMs, i.e., the ability to provide accurate license or\ncopyright information when they generate code with striking similarity to\nalready existing copyrighted code. Using LiCoEval, we evaluate 14 popular LLMs,\nfinding that even top-performing LLMs produce a non-negligible proportion\n(0.88% to 2.01%) of code strikingly similar to existing open-source\nimplementations. Notably, most LLMs fail to provide accurate license\ninformation, particularly for code under copyleft licenses. These findings\nunderscore the urgent need to enhance LLM compliance capabilities in code\ngeneration tasks. Our study provides a foundation for future research and\ndevelopment to improve license compliance in AI-assisted software development,\ncontributing to both the protection of open-source software copyrights and the\nmitigation of legal risks for LLM users.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在代码生成中可能违反许可证合规性的问题，提出LiCoEval基准来评估LLMs生成高度相似（striking similarity）代码时提供准确许可证信息的能力。研究者通过实证分析定义了striking similarity的标准，并评估了14个流行LLMs，发现这些模型生成与现有开源代码高度相似的代码比例为0.88%至2.01%，且大多数LLMs尤其在copyleft licenses下无法正确提供许可证信息。这些发现强调了提升LLMs合规性的迫切需求，并为未来AI辅助软件开发提供基础，以保护开源版权并降低法律风险。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "The 47th International Conference on Software Engineering(ICSE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2408.02487v3",
      "published_date": "2024-08-05 14:09:30 UTC",
      "updated_date": "2025-02-25 08:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:01:30.840123"
    },
    {
      "arxiv_id": "2408.02713v1",
      "title": "A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Han",
        "Qi Dou"
      ],
      "abstract": "Augmented Reality (AR) holds the potential to revolutionize surgical\nprocedures by allowing surgeons to visualize critical structures within the\npatient's body. This is achieved through superimposing preoperative organ\nmodels onto the actual anatomy. Challenges arise from dynamic deformations of\norgans during surgery, making preoperative models inadequate for faithfully\nrepresenting intraoperative anatomy. To enable reliable navigation in augmented\nsurgery, modeling of intraoperative deformation to obtain an accurate alignment\nof the preoperative organ model with the intraoperative anatomy is\nindispensable. Despite the existence of various methods proposed to model\nintraoperative organ deformation, there are still few literature reviews that\nsystematically categorize and summarize these approaches. This review aims to\nfill this gap by providing a comprehensive and technical-oriented overview of\nmodeling methods for intraoperative organ deformation in augmented reality in\nsurgery. Through a systematic search and screening process, 112 closely\nrelevant papers were included in this review. By presenting the current status\nof organ deformation modeling methods and their clinical applications, this\nreview seeks to enhance the understanding of organ deformation modeling in\nAR-guided surgery, and discuss the potential topics for future advancements.",
      "tldr_zh": "这篇综述探讨了增强现实(Augmented Reality, AR)用于手术导航时，器官变形建模的方法，以解决器官在手术中的动态变形导致术前模型不准确的问题。作者通过系统搜索和筛选112篇相关论文，对现有建模方法进行了全面的技术导向分类和总结，包括其临床应用。综述旨在提升对器官变形建模的理解，并讨论未来AR引导手术的潜在研究方向。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "cs.HC",
        "eess.IV"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02713v1",
      "published_date": "2024-08-05 14:03:17 UTC",
      "updated_date": "2024-08-05 14:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:01:43.595830"
    },
    {
      "arxiv_id": "2408.02479v2",
      "title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future",
      "title_zh": "翻译失败",
      "authors": [
        "Haolin Jin",
        "Linghan Huang",
        "Haipeng Cai",
        "Jun Yan",
        "Bo Li",
        "Huaming Chen"
      ],
      "abstract": "With the rise of large language models (LLMs), researchers are increasingly\nexploring their applications in var ious vertical domains, such as software\nengineering. LLMs have achieved remarkable success in areas including code\ngeneration and vulnerability detection. However, they also exhibit numerous\nlimitations and shortcomings. LLM-based agents, a novel tech nology with the\npotential for Artificial General Intelligence (AGI), combine LLMs as the core\nfor decision-making and action-taking, addressing some of the inherent\nlimitations of LLMs such as lack of autonomy and self-improvement. Despite\nnumerous studies and surveys exploring the possibility of using LLMs in\nsoftware engineering, it lacks a clear distinction between LLMs and LLM based\nagents. It is still in its early stage for a unified standard and benchmarking\nto qualify an LLM solution as an LLM-based agent in its domain. In this survey,\nwe broadly investigate the current practice and solutions for LLMs and\nLLM-based agents for software engineering. In particular we summarise six key\ntopics: requirement engineering, code generation, autonomous decision-making,\nsoftware design, test generation, and software maintenance. We review and\ndifferentiate the work of LLMs and LLM-based agents from these six topics,\nexamining their differences and similarities in tasks, benchmarks, and\nevaluation metrics. Finally, we discuss the models and benchmarks used,\nproviding a comprehensive analysis of their applications and effectiveness in\nsoftware engineering. We anticipate this work will shed some lights on pushing\nthe boundaries of LLM-based agents in software engineering for future research.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型 (LLMs) 在软件工程中的应用及其向基于 LLMs 的智能体 (LLM-based agents) 的演变，强调了 LLMs 的局限性（如缺乏自治性和自我改进）以及 LLM-based agents 在决策和行动方面的潜力，以实现人工智能通用智能 (AGI)。论文总结了六个关键主题，包括需求工程、代码生成、自治决策、软件设计、测试生成和软件维护，并比较了 LLMs 和 LLM-based agents 在任务、基准和评估指标上的差异和相似性。最终，通过分析当前实践和模型有效性，该研究指出了挑战并为推动 LLM-based agents 在软件工程领域的未来发展提供了指导。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02479v2",
      "published_date": "2024-08-05 14:01:15 UTC",
      "updated_date": "2025-04-13 09:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:01:56.380052"
    },
    {
      "arxiv_id": "2408.02712v1",
      "title": "Automatic Voice Identification after Speech Resynthesis using PPG",
      "title_zh": "翻译失败",
      "authors": [
        "Thibault Gaudier",
        "Marie Tahon",
        "Anthony Larcher",
        "Yannick Estève"
      ],
      "abstract": "Speech resynthesis is a generic task for which we want to synthesize audio\nwith another audio as input, which finds applications for media monitors and\njournalists.Among different tasks addressed by speech resynthesis, voice\nconversion preserves the linguistic information while modifying the identity of\nthe speaker, and speech edition preserves the identity of the speaker but some\nwords are modified.In both cases, we need to disentangle speaker and phonetic\ncontents in intermediate representations.Phonetic PosteriorGrams (PPG) are a\nframe-level probabilistic representation of phonemes, and are usually\nconsidered speaker-independent.This paper presents a PPG-based speech\nresynthesis system.A perceptive evaluation assesses that it produces correct\naudio quality.Then, we demonstrate that an automatic speaker verification model\nis not able to recover the source speaker after re-synthesis with PPG, even\nwhen the model is trained on synthetic data.",
      "tldr_zh": "这篇论文提出了一种基于 Phonetic PosteriorGrams (PPG) 的演讲重合成系统，用于语音转换和语音编辑任务，其中语音转换保留语言信息但修改说话者身份，而语音编辑保留说话者身份但修改特定单词。系统通过在中间表示中分离说话者和语音内容，确保重合成音频的质量，并通过主观评估证明其音频输出正确。实验结果显示，即使使用在合成数据上训练的自动说话者验证模型，也无法从重合成音频中恢复源说话者身份，从而增强了隐私保护在演讲重合成中的应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.NE",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02712v1",
      "published_date": "2024-08-05 13:59:40 UTC",
      "updated_date": "2024-08-05 13:59:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:02:06.122002"
    },
    {
      "arxiv_id": "2408.07080v1",
      "title": "DisCoM-KD: Cross-Modal Knowledge Distillation via Disentanglement Representation and Adversarial Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dino Ienco",
        "Cassio Fraga Dantas"
      ],
      "abstract": "Cross-modal knowledge distillation (CMKD) refers to the scenario in which a\nlearning framework must handle training and test data that exhibit a modality\nmismatch, more precisely, training and test data do not cover the same set of\ndata modalities. Traditional approaches for CMKD are based on a teacher/student\nparadigm where a teacher is trained on multi-modal data with the aim to\nsuccessively distill knowledge from a multi-modal teacher to a single-modal\nstudent. Despite the widespread adoption of such paradigm, recent research has\nhighlighted its inherent limitations in the context of cross-modal knowledge\ntransfer.Taking a step beyond the teacher/student paradigm, here we introduce a\nnew framework for cross-modal knowledge distillation, named DisCoM-KD\n(Disentanglement-learning based Cross-Modal Knowledge Distillation), that\nexplicitly models different types of per-modality information with the aim to\ntransfer knowledge from multi-modal data to a single-modal classifier. To this\nend, DisCoM-KD effectively combines disentanglement representation learning\nwith adversarial domain adaptation to simultaneously extract, foreach modality,\ndomain-invariant, domain-informative and domain-irrelevant features according\nto a specific downstream task. Unlike the traditional teacher/student paradigm,\nour framework simultaneously learns all single-modal classifiers, eliminating\nthe need to learn each student model separately as well as the teacher\nclassifier. We evaluated DisCoM-KD on three standard multi-modal benchmarks and\ncompared its behaviourwith recent SOTA knowledge distillation frameworks. The\nfindings clearly demonstrate the effectiveness of DisCoM-KD over competitors\nconsidering mismatch scenarios involving both overlapping and non-overlapping\nmodalities. These results offer insights to reconsider the traditional paradigm\nfor distilling information from multi-modal data to single-modal neural\nnetworks.",
      "tldr_zh": "该论文提出了一种新的跨模态知识蒸馏（Cross-Modal Knowledge Distillation）框架，名为 DisCoM-KD，通过 disentanglement representation learning 和 adversarial learning 技术，从多模态数据中提取每个模态的 domain-invariant、domain-informative 和 domain-irrelevant 特征，从而实现向单模态分类器的知识转移。不同于传统的 teacher/student 范式，DisCoM-KD 同时学习所有单模态分类器，避免了单独训练教师模型或学生模型的需要。在三个标准多模态基准上的实验结果显示，该框架在模态匹配和不匹配场景中均优于现有 SOTA 方法，为跨模态知识转移提供了新的见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07080v1",
      "published_date": "2024-08-05 13:44:15 UTC",
      "updated_date": "2024-08-05 13:44:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:02:19.281128"
    },
    {
      "arxiv_id": "2408.02462v1",
      "title": "An investigation into the causes of race bias in AI-based cine CMR segmentation",
      "title_zh": "对基于AI的",
      "authors": [
        "Tiarna Lee",
        "Esther Puyol-Anton",
        "Bram Ruijsink",
        "Sebastien Roujol",
        "Theodore Barfoot",
        "Shaheim Ogbomo-Harmitt",
        "Miaojing Shi",
        "Andrew P. King"
      ],
      "abstract": "Artificial intelligence (AI) methods are being used increasingly for the\nautomated segmentation of cine cardiac magnetic resonance (CMR) imaging.\nHowever, these methods have been shown to be subject to race bias, i.e. they\nexhibit different levels of performance for different races depending on the\n(im)balance of the data used to train the AI model. In this paper we\ninvestigate the source of this bias, seeking to understand its root cause(s) so\nthat it can be effectively mitigated. We perform a series of classification and\nsegmentation experiments on short-axis cine CMR images acquired from Black and\nWhite subjects from the UK Biobank and apply AI interpretability methods to\nunderstand the results. In the classification experiments, we found that race\ncan be predicted with high accuracy from the images alone, but less accurately\nfrom ground truth segmentations, suggesting that the distributional shift\nbetween races, which is often the cause of AI bias, is mostly image-based\nrather than segmentation-based. The interpretability methods showed that most\nattention in the classification models was focused on non-heart regions, such\nas subcutaneous fat. Cropping the images tightly around the heart reduced\nclassification accuracy to around chance level. Similarly, race can be\npredicted from the latent representations of a biased segmentation model,\nsuggesting that race information is encoded in the model. Cropping images\ntightly around the heart reduced but did not eliminate segmentation bias. We\nalso investigate the influence of possible confounders on the bias observed.",
      "tldr_zh": "本研究调查了AI在cine CMR（心脏磁共振成像）图像分割中存在的种族偏见原因，重点分析训练数据不平衡如何导致不同种族的性能差异。研究者通过分类和分割实验，使用UK Biobank的黑人和白人图像数据，并应用AI可解释性方法，发现种族信息主要源于图像整体分布（如非心脏区域如皮下脂肪），而非分割结果本身。实验显示，紧切图像围绕心脏区域可将种族分类准确率降至接近随机水平，但分割模型的偏见虽减弱却未完全消除。总体而言，该工作揭示了偏见的根源，并为通过图像处理和模型优化来缓解AI偏见提供了见解。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02462v1",
      "published_date": "2024-08-05 13:40:33 UTC",
      "updated_date": "2024-08-05 13:40:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:02:30.626749"
    },
    {
      "arxiv_id": "2408.11826v1",
      "title": "Generative Organizational Behavior Simulation using Large Language Model based Autonomous Agents: A Holacracy Perspective",
      "title_zh": "基于大型语言模型的自治代理的生成式组织行为模拟：Holacracy 视角",
      "authors": [
        "Chen Zhu",
        "Yihang Cheng",
        "Jingshuai Zhang",
        "Yusheng Qiu",
        "Sitao Xia",
        "Hengshu Zhu"
      ],
      "abstract": "In this paper, we present the technical details and periodic findings of our\nproject, CareerAgent, which aims to build a generative simulation framework for\na Holacracy organization using Large Language Model-based Autonomous Agents.\nSpecifically, the simulation framework includes three phases: construction,\nexecution, and evaluation, and it incorporates basic characteristics of\nindividuals, organizations, tasks, and meetings. Through our simulation, we\nobtained several interesting findings. At the organizational level, an increase\nin the average values of management competence and functional competence can\nreduce overall members' stress levels, but it negatively impacts deeper\norganizational performance measures such as average task completion. At the\nindividual level, both competences can improve members' work performance. From\nthe analysis of social networks, we found that highly competent members\nselectively participate in certain tasks and take on more responsibilities.\nOver time, small sub-communities form around these highly competent members\nwithin the holacracy. These findings contribute theoretically to the study of\norganizational science and provide practical insights for managers to\nunderstand the organization dynamics.",
      "tldr_zh": "本文提出 CareerAgent 项目，使用 Large Language Model-based Autonomous Agents 构建一个 Holacracy 组织的生成模拟框架，该框架包括构建、执行和评估三个阶段，并整合个体、组织、任务和会议的基本特性。模拟结果显示，在组织层面，提高平均管理能力和功能能力可降低成员压力，但会负面影响任务完成等绩效指标；在个人层面，这两种能力能提升工作绩效。社会网络分析发现，高能力成员倾向于选择性参与任务并承担更多责任，导致小社区围绕他们形成。这些发现为组织科学理论提供贡献，并为管理者理解组织动态提供实际洞见。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11826v1",
      "published_date": "2024-08-05 13:39:03 UTC",
      "updated_date": "2024-08-05 13:39:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:02:43.516659"
    },
    {
      "arxiv_id": "2408.02456v1",
      "title": "Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Wanxu Wei",
        "Yitong Song",
        "Bin Yao"
      ],
      "abstract": "Knowledge graphs (KGs) play a vital role in enhancing search results and\nrecommendation systems. With the rapid increase in the size of the KGs, they\nare becoming inaccuracy and incomplete. This problem can be solved by the\nknowledge graph completion methods, of which graph attention network\n(GAT)-based methods stand out since their superior performance. However,\nexisting GAT-based knowledge graph completion methods often suffer from\noverfitting issues when dealing with heterogeneous knowledge graphs, primarily\ndue to the unbalanced number of samples. Additionally, these methods\ndemonstrate poor performance in predicting the tail (head) entity that shares\nthe same relation and head (tail) entity with others. To solve these problems,\nwe propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH\nincorporates two separate attention network modules that work synergistically\nto predict the missing entities. We also introduce novel encoding and feature\ntransformation approaches, enabling the robust performance of GATH in scenarios\nwith imbalanced samples. Comprehensive experiments are conducted to evaluate\nthe GATH's performance. Compared with the existing SOTA GAT-based model on\nHits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the\nFB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively.",
      "tldr_zh": "该研究针对异构知识图谱 (KGs) 的补全问题，指出现有基于图注意力网络 (GAT) 方法易受样本不平衡导致的过拟合影响，并在预测共享相同关系的尾实体或头实体时表现欠佳。作者提出了一种新型方法 GATH，它整合了两个协同工作的注意力网络模块，以及创新的编码和特征转换技术，以提升模型在不平衡样本场景下的鲁棒性。通过在 FB15K-237 和 WN18RR 数据集上的实验，GATH 相比现有最先进 GAT 模型，使 Hits@10 和 MRR 指标分别提高了 5.2% 和 5.2% 以及 4.5% 和 14.6%。这项工作为异构 KGs 补全提供了更有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02456v1",
      "published_date": "2024-08-05 13:28:51 UTC",
      "updated_date": "2024-08-05 13:28:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:02:59.171598"
    },
    {
      "arxiv_id": "2408.05237v1",
      "title": "Biomimetic Machine Learning approach for prediction of mechanical properties of Additive Friction Stir Deposited Aluminum alloys based walled structures",
      "title_zh": "翻译失败",
      "authors": [
        "Akshansh Mishra"
      ],
      "abstract": "This study presents a novel approach to predicting mechanical properties of\nAdditive Friction Stir Deposited (AFSD) aluminum alloy walled structures using\nbiomimetic machine learning. The research combines numerical modeling of the\nAFSD process with genetic algorithm-optimized machine learning models to\npredict von Mises stress and logarithmic strain. Finite element analysis was\nemployed to simulate the AFSD process for five aluminum alloys: AA2024, AA5083,\nAA5086, AA7075, and AA6061, capturing complex thermal and mechanical\ninteractions. A dataset of 200 samples was generated from these simulations.\nSubsequently, Decision Tree (DT) and Random Forest (RF) regression models,\noptimized using genetic algorithms, were developed to predict key mechanical\nproperties. The GA-RF model demonstrated superior performance in predicting\nboth von Mises stress (R square = 0.9676) and logarithmic strain (R square =\n0.7201). This innovative approach provides a powerful tool for understanding\nand optimizing the AFSD process across multiple aluminum alloys, offering\ninsights into material behavior under various process parameters.",
      "tldr_zh": "本研究提出了一种基于生物启发式机器学习（Biomimetic Machine Learning）的创新方法，用于预测 Additive Friction Stir Deposited (AFSD) 铝合金壁结构的机械性能。研究结合了 AFSD 过程的数值建模和有限元分析，模拟了五种铝合金（AA2024, AA5083, AA5086, AA7075, AA6061）的热力和机械相互作用，生成 200 个样本数据集，并使用遗传算法优化 Decision Tree (DT) 和 Random Forest (RF) 回归模型。结果显示，GA-RF 模型在预测 von Mises stress (R square = 0.9676) 和 logarithmic strain (R square = 0.7201) 方面表现出色，为理解和优化 AFSD 过程提供有力工具，揭示了材料在不同参数下的行为。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 14 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.05237v1",
      "published_date": "2024-08-05 13:27:54 UTC",
      "updated_date": "2024-08-05 13:27:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:03:09.898205"
    },
    {
      "arxiv_id": "2408.02711v1",
      "title": "Text Conditioned Symbolic Drumbeat Generation using Latent Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pushkar Jajoria",
        "James McDermott"
      ],
      "abstract": "This study introduces a text-conditioned approach to generating drumbeats\nwith Latent Diffusion Models (LDMs). It uses informative conditioning text\nextracted from training data filenames. By pretraining a text and drumbeat\nencoder through contrastive learning within a multimodal network, aligned\nfollowing CLIP, we align the modalities of text and music closely.\nAdditionally, we examine an alternative text encoder based on multihot text\nencodings. Inspired by musics multi-resolution nature, we propose a novel LSTM\nvariant, MultiResolutionLSTM, designed to operate at various resolutions\nindependently. In common with recent LDMs in the image space, it speeds up the\ngeneration process by running diffusion in a latent space provided by a\npretrained unconditional autoencoder. We demonstrate the originality and\nvariety of the generated drumbeats by measuring distance (both over binary\npianorolls and in the latent space) versus the training dataset and among the\ngenerated drumbeats. We also assess the generated drumbeats through a listening\ntest focused on questions of quality, aptness for the prompt text, and novelty.\nWe show that the generated drumbeats are novel and apt to the prompt text, and\ncomparable in quality to those created by human musicians.",
      "tldr_zh": "本研究提出了一种基于文本条件化的方法，使用 Latent Diffusion Models (LDMs) 生成符号化鼓点，通过从训练数据文件名中提取的信息性文本作为条件。研究采用对比学习在多模态网络中预训练文本和鼓点编码器，并借鉴 CLIP 的对齐方式来紧密整合文本和音乐模态，同时引入了新颖的 MultiResolutionLSTM 变体，以处理音乐的多分辨率特性并加速潜在空间中的扩散生成。实验结果显示，生成的鼓点在二进制钢琴卷和潜在空间中表现出较高的原创性和多样性，且通过听力测试验证，其质量与提示文本的匹配度均可与人类音乐家创作相媲美。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02711v1",
      "published_date": "2024-08-05 13:23:05 UTC",
      "updated_date": "2024-08-05 13:23:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:03:21.884056"
    },
    {
      "arxiv_id": "2408.02439v1",
      "title": "Long Input Benchmark for Russian Analysis",
      "title_zh": "俄语分析的长输入基准",
      "authors": [
        "Igor Churin",
        "Murat Apishev",
        "Maria Tikhonova",
        "Denis Shevelev",
        "Aydar Bulatov",
        "Yuri Kuratov",
        "Sergej Averkiev",
        "Alena Fenogenova"
      ],
      "abstract": "Recent advancements in Natural Language Processing (NLP) have fostered the\ndevelopment of Large Language Models (LLMs) that can solve an immense variety\nof tasks. One of the key aspects of their application is their ability to work\nwith long text documents and to process long sequences of tokens. This has\ncreated a demand for proper evaluation of long-context understanding. To\naddress this need for the Russian language, we propose LIBRA (Long Input\nBenchmark for Russian Analysis), which comprises 21 adapted datasets to study\nthe LLM's abilities to understand long texts thoroughly. The tests are divided\ninto four complexity groups and allow the evaluation of models across various\ncontext lengths ranging from 4k up to 128k tokens. We provide the open-source\ndatasets, codebase, and public leaderboard for LIBRA to guide forthcoming\nresearch.",
      "tldr_zh": "本研究针对自然语言处理（NLP）中大型语言模型（LLMs）的长文本理解能力，提出了一种名为 LIBRA 的基准，用于俄罗斯语言的评估。LIBRA 包含 21 个适配数据集，分为四个复杂性组，涵盖从 4k 到 128k 标记的上下文长度，从而全面测试模型在处理长序列时的表现。该基准提供开源数据集、代码库和公共排行榜，以推动后续研究的进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02439v1",
      "published_date": "2024-08-05 12:59:35 UTC",
      "updated_date": "2024-08-05 12:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:03:32.099558"
    },
    {
      "arxiv_id": "2408.02709v1",
      "title": "Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns",
      "title_zh": "增强医疗学习和推理系统：基于 Boxology 的设计模式比较分析",
      "authors": [
        "Chi Him Ng"
      ],
      "abstract": "This study analyzes hybrid AI systems' design patterns and their\neffectiveness in clinical decision-making using the boxology framework. It\ncategorizes and copares various architectures combining machine learning and\nrule-based reasoning to provide insights into their structural foundations and\nhealthcare applications. Addressing two main questions, how to categorize these\nsystems againts established design patterns and how to extract insights through\ncomparative analysis, the study uses design patterns from software engineering\nto understand and optimize healthcare AI systems. Boxology helps identify\ncommonalities and create reusable solutions, enhancing these systems'\nscalability, reliability, and performance. Five primary architectures are\nexamined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and\nweaknesses, highlighting the need for tailored approaches in clinical tasks.\nREML excels in high-accuracy prediction for datasets with limited data; MLRB in\nhandling large datasets and complex data integration; RBML in explainability\nand trustworthiness; RMLT in managing high-dimensional data; and PERML, though\nlimited in analysis, shows promise in urgent care scenarios. The study\nintroduces four new patterns, creates five abstract categorization patterns,\nand refines those five further to specific systems. These contributions enhance\nBoxlogy's taxonomical organization and offer novel approaches to integrating\nexpert knowledge with machine learning. Boxology's structured, modular apporach\noffers significant advantages in developing and analyzing hybrid AI systems,\nrevealing commonalities, and promoting reusable solutions. In conclusion, this\nstudy underscores hybrid AI systems' crucial role in advancing healthcare and\nBoxology's potential to drive further innovation in AI integration, ultimately\nimproving clinical decision support and patient outcomes.",
      "tldr_zh": "这项研究使用 boxology 框架对混合 AI 系统的设计模式进行比较分析，评估其在临床决策中的有效性，并分类五种主要架构：REML、MLRB、RBML、RMLT 和 PERML，每种架构在处理数据、解释性和可靠性方面各有优势，如 REML 适合数据有限的预测任务。研究回答了系统分类和洞见提取的关键问题，引入四个新模式并创建五个抽象分类模式，进一步优化了 boxology 的分类组织。总体而言，这些贡献促进了混合 AI 系统的可扩展性和性能，提升了医疗领域的决策支持和患者结果。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02709v1",
      "published_date": "2024-08-05 12:53:04 UTC",
      "updated_date": "2024-08-05 12:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:03:55.623585"
    },
    {
      "arxiv_id": "2408.02412v1",
      "title": "PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy",
      "title_zh": "PENDRAM：通过通用 DRAM 数据映射策略实现深度神经网络的高性能和节能处理",
      "authors": [
        "Rachmad Vidya Wicaksana Putra",
        "Muhammad Abdullah Hanif",
        "Muhammad Shafique"
      ],
      "abstract": "Convolutional Neural Networks (CNNs), a prominent type of Deep Neural\nNetworks (DNNs), have emerged as a state-of-the-art solution for solving\nmachine learning tasks. To improve the performance and energy efficiency of CNN\ninference, the employment of specialized hardware accelerators is prevalent.\nHowever, CNN accelerators still face performance- and energy-efficiency\nchallenges due to high off-chip memory (DRAM) access latency and energy, which\nare especially crucial for latency- and energy-constrained embedded\napplications. Moreover, different DRAM architectures have different profiles of\naccess latency and energy, thus making it challenging to optimize them for high\nperformance and energy-efficient CNN accelerators. To address this, we present\nPENDRAM, a novel design space exploration methodology that enables\nhigh-performance and energy-efficient CNN acceleration through a generalized\nDRAM data mapping policy. Specifically, it explores the impact of different\nDRAM data mapping policies and DRAM architectures across different CNN\npartitioning and scheduling schemes on the DRAM access latency and energy, then\nidentifies the pareto-optimal design choices. The experimental results show\nthat our DRAM data mapping policy improves the energy-delay-product of DRAM\naccesses in the CNN accelerator over other mapping policies by up to 96%. In\nthis manner, our PENDRAM methodology offers high-performance and\nenergy-efficient CNN acceleration under any given DRAM architectures for\ndiverse embedded AI applications.",
      "tldr_zh": "该研究提出 PENDRAM，一种通过通用 DRAM 数据映射策略来提升深度神经网络 (DNNs) 处理性能和能效的设计空间探索方法，针对 CNN 加速器中 DRAM 访问延迟和能耗的挑战。PENDRAM 评估不同 DRAM 架构、数据映射策略以及 CNN 分区和调度方案对访问延迟和能耗的影响，并识别 Pareto 最优设计选择。实验结果表明，该策略可将 CNN 加速器的 DRAM 访问能量-延迟乘积改善高达 96%，为嵌入式 AI 应用提供高性能和能效优化。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AR",
      "comment": "11 pages, 15 figures, 2 tables. arXiv admin note: substantial text\n  overlap with arXiv:2004.10341",
      "pdf_url": "http://arxiv.org/pdf/2408.02412v1",
      "published_date": "2024-08-05 12:11:09 UTC",
      "updated_date": "2024-08-05 12:11:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:04:07.775615"
    },
    {
      "arxiv_id": "2408.02408v2",
      "title": "Multi-weather Cross-view Geo-localization Using Denoising Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tongtong Feng",
        "Qing Li",
        "Xin Wang",
        "Mingzi Wang",
        "Guangyao Li",
        "Wenwu Zhu"
      ],
      "abstract": "Cross-view geo-localization in GNSS-denied environments aims to determine an\nunknown location by matching drone-view images with the correct geo-tagged\nsatellite-view images from a large gallery. Recent research shows that learning\ndiscriminative image representations under specific weather conditions can\nsignificantly enhance performance. However, the frequent occurrence of unseen\nextreme weather conditions hinders progress. This paper introduces MCGF, a\nMulti-weather Cross-view Geo-localization Framework designed to dynamically\nadapt to unseen weather conditions. MCGF establishes a joint optimization\nbetween image restoration and geo-localization using denoising diffusion\nmodels. For image restoration, MCGF incorporates a shared encoder and a\nlightweight restoration module to help the backbone eliminate weather-specific\ninformation. For geo-localization, MCGF uses EVA-02 as a backbone for feature\nextraction, with cross-entropy loss for training and cosine distance for\ntesting. Extensive experiments on University160k-WX demonstrate that MCGF\nachieves competitive results for geo-localization in varying weather\nconditions.",
      "tldr_zh": "该论文针对GNSS-denied环境中跨视角地理定位问题，提出MCGF框架，利用Denoising Diffusion Models动态适应未见过的极端天气条件。MCGF通过联合优化图像恢复和地理定位模块，包括一个共享编码器及轻量级恢复模块来去除天气特定信息，并以EVA-02作为骨干网络进行特征提取，使用cross-entropy loss训练和cosine distance测试。实验在University160k-WX数据集上显示，MCGF在多种天气条件下实现了与现有方法竞争性的性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MM24 workshop",
      "pdf_url": "http://arxiv.org/pdf/2408.02408v2",
      "published_date": "2024-08-05 12:09:38 UTC",
      "updated_date": "2024-08-28 02:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:04:11.074063"
    },
    {
      "arxiv_id": "2408.02707v1",
      "title": "SnapE -- Training Snapshot Ensembles of Link Prediction Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Shaban",
        "Heiko Paulheim"
      ],
      "abstract": "Snapshot ensembles have been widely used in various fields of prediction.\nThey allow for training an ensemble of prediction models at the cost of\ntraining a single one. They are known to yield more robust predictions by\ncreating a set of diverse base models. In this paper, we introduce an approach\nto transfer the idea of snapshot ensembles to link prediction models in\nknowledge graphs. Moreover, since link prediction in knowledge graphs is a\nsetup without explicit negative examples, we propose a novel training loop that\niteratively creates negative examples using previous snapshot models. An\nevaluation with four base models across four datasets shows that this approach\nconstantly outperforms the single model approach, while keeping the training\ntime constant.",
      "tldr_zh": "本论文提出 SnapE 方法，将 Snapshot Ensembles 应用于知识图谱的链接预测模型中，允许以训练单个模型的成本创建一组多样化的模型集合，从而提升预测的鲁棒性。由于链接预测缺乏显式负例，研究引入了一种新颖的训练循环，使用之前的快照模型迭代生成负例。实验在四个基准模型和四个数据集上显示，SnapE 方法比单一模型方法显著提升性能，同时保持训练时间不变。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at International Semantic Web Conference (ISWC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.02707v1",
      "published_date": "2024-08-05 12:02:10 UTC",
      "updated_date": "2024-08-05 12:02:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:04:20.799049"
    },
    {
      "arxiv_id": "2408.02402v3",
      "title": "Enhancing AI-based Generation of Software Exploits with Contextual Information",
      "title_zh": "翻译失败",
      "authors": [
        "Pietro Liguori",
        "Cristina Improta",
        "Roberto Natella",
        "Bojan Cukic",
        "Domenico Cotroneo"
      ],
      "abstract": "This practical experience report explores Neural Machine Translation (NMT)\nmodels' capability to generate offensive security code from natural language\n(NL) descriptions, highlighting the significance of contextual understanding\nand its impact on model performance. Our study employs a dataset comprising\nreal shellcodes to evaluate the models across various scenarios, including\nmissing information, necessary context, and unnecessary context. The\nexperiments are designed to assess the models' resilience against incomplete\ndescriptions, their proficiency in leveraging context for enhanced accuracy,\nand their ability to discern irrelevant information. The findings reveal that\nthe introduction of contextual data significantly improves performance.\nHowever, the benefits of additional context diminish beyond a certain point,\nindicating an optimal level of contextual information for model training.\nMoreover, the models demonstrate an ability to filter out unnecessary context,\nmaintaining high levels of accuracy in the generation of offensive security\ncode. This study paves the way for future research on optimizing context use in\nAI-driven code generation, particularly for applications requiring a high\ndegree of technical precision such as the generation of offensive code.",
      "tldr_zh": "这篇实证报告探讨了 Neural Machine Translation (NMT) 模型从自然语言描述生成攻击性安全代码的能力，并强调了上下文理解对模型性能的关键影响。研究使用包含真实 shellcodes 的数据集，评估了模型在缺少信息、必要上下文和不必要上下文等场景下的表现，结果显示添加适当上下文显著提升了生成准确性，但超过最佳水平后收益递减。模型还展现出过滤不相关信息的能力，为优化 AI 驱动代码生成提供指导，特别是针对高精度需求的攻击性代码应用。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication at The 35th IEEE International Symposium on\n  Software Reliability Engineering",
      "pdf_url": "http://arxiv.org/pdf/2408.02402v3",
      "published_date": "2024-08-05 11:52:34 UTC",
      "updated_date": "2024-09-06 12:51:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:04:36.399131"
    },
    {
      "arxiv_id": "2408.04655v2",
      "title": "Strong and weak alignment of large language models with human values",
      "title_zh": "大型语言模型与人类价值观的强对齐和弱对齐",
      "authors": [
        "Mehdi Khamassi",
        "Marceau Nahon",
        "Raja Chatila"
      ],
      "abstract": "Minimizing negative impacts of Artificial Intelligent (AI) systems on human\nsocieties without human supervision requires them to be able to align with\nhuman values. However, most current work only addresses this issue from a\ntechnical point of view, e.g., improving current methods relying on\nreinforcement learning from human feedback, neglecting what it means and is\nrequired for alignment to occur. Here, we propose to distinguish strong and\nweak value alignment. Strong alignment requires cognitive abilities (either\nhuman-like or different from humans) such as understanding and reasoning about\nagents' intentions and their ability to causally produce desired effects. We\nargue that this is required for AI systems like large language models (LLMs) to\nbe able to recognize situations presenting a risk that human values may be\nflouted. To illustrate this distinction, we present a series of prompts showing\nChatGPT's, Gemini's and Copilot's failures to recognize some of these\nsituations. We moreover analyze word embeddings to show that the nearest\nneighbors of some human values in LLMs differ from humans' semantic\nrepresentations. We then propose a new thought experiment that we call \"the\nChinese room with a word transition dictionary\", in extension of John Searle's\nfamous proposal. We finally mention current promising research directions\ntowards a weak alignment, which could produce statistically satisfying answers\nin a number of common situations, however so far without ensuring any truth\nvalue.",
      "tldr_zh": "本文提出区分大型语言模型(LLMs)与人类价值观的强对齐和弱对齐：强对齐要求AI具备理解意图、推理因果关系等认知能力，以识别潜在风险；弱对齐则仅在常见情境下提供统计上满意的答案，但不确保真实性。通过测试ChatGPT、Gemini和Copilot的提示响应以及分析词嵌入，论文揭示了现有LLMs在识别价值观风险方面的失败。论文还引入了一个扩展John Searle's思想实验——“Chinese room with a word transition dictionary”，并建议未来研究方向以推进弱对齐的进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication in Scientific Reports, special issue on AI\n  aligment",
      "pdf_url": "http://arxiv.org/pdf/2408.04655v2",
      "published_date": "2024-08-05 11:27:51 UTC",
      "updated_date": "2024-08-12 13:20:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:04:45.946107"
    },
    {
      "arxiv_id": "2408.02380v1",
      "title": "Perfect Information Monte Carlo with Postponing Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jérôme Arjonilla",
        "Abdallah Saffidine",
        "Tristan Cazenave"
      ],
      "abstract": "Imperfect information games, such as Bridge and Skat, present challenges due\nto state-space explosion and hidden information, posing formidable obstacles\nfor search algorithms. Determinization-based algorithms offer a resolution by\nsampling hidden information and solving the game in a perfect information\nsetting, facilitating rapid and effective action estimation. However,\ntransitioning to perfect information introduces challenges, notably one called\nstrategy fusion.This research introduces `Extended Perfect Information Monte\nCarlo' (EPIMC), an online algorithm inspired by the state-of-the-art\ndeterminization-based approach Perfect Information Monte Carlo (PIMC). EPIMC\nenhances the capabilities of PIMC by postponing the perfect information\nresolution, reducing alleviating issues related to strategy fusion. However,\nthe decision to postpone the leaf evaluator introduces novel considerations,\nsuch as the interplay between prior levels of reasoning and the newly deferred\nresolution. In our empirical analysis, we investigate the performance of EPIMC\nacross a range of games, with a particular focus on those characterized by\nvarying degrees of strategy fusion. Our results demonstrate notable performance\nenhancements, particularly in games where strategy fusion significantly impacts\ngameplay. Furthermore, our research contributes to the theoretical foundation\nof determinization-based algorithms addressing challenges associated with\nstrategy fusion.%, thereby enhancing our understanding of these algorithms\nwithin the context of imperfect information game scenarios.",
      "tldr_zh": "该研究针对不完美信息游戏（如 Bridge 和 Skat）的挑战，包括状态空间爆炸和隐藏信息问题，提出了一种名为“Extended Perfect Information Monte Carlo”（EPIMC）的在线算法。该算法基于现有的“Perfect Information Monte Carlo”（PIMC），通过推迟完美信息解析来缓解 strategy fusion 的影响，从而提升行动估计的准确性。实验结果显示，EPIMC 在各种游戏中表现出显著性能提升，尤其在 strategy fusion 影响明显的场景中，并为 determinization-based 算法提供了新的理论基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in IEEE Conference on Games (CoG) 2024 + Appendix",
      "pdf_url": "http://arxiv.org/pdf/2408.02380v1",
      "published_date": "2024-08-05 11:12:48 UTC",
      "updated_date": "2024-08-05 11:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:04:58.820677"
    },
    {
      "arxiv_id": "2408.02377v1",
      "title": "A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Vanni Zavarella",
        "Juan Carlos Gamero-Salinas",
        "Sergio Consoli"
      ],
      "abstract": "Knowledge graphs (KGs) have been successfully applied to the analysis of\ncomplex scientific and technological domains, with automatic KG generation\nmethods typically building upon relation extraction models capturing\nfine-grained relations between domain entities in text. While these relations\nare fully applicable across scientific areas, existing models are trained on\nfew domain-specific datasets such as SciERC and do not perform well on new\ntarget domains. In this paper, we experiment with leveraging in-context\nlearning capabilities of Large Language Models to perform schema-constrained\ndata annotation, collecting in-domain training instances for a\nTransformer-based relation extraction model deployed on titles and abstracts of\nresearch papers in the Architecture, Construction, Engineering and Operations\n(AECO) domain. By assessing the performance gain with respect to a baseline\nDeep Learning architecture trained on off-domain data, we show that by using a\nfew-shot learning strategy with structured prompts and only minimal expert\nannotation the presented approach can potentially support domain adaptation of\na science KG generation model.",
      "tldr_zh": "本研究提出了一种基于大语言模型的少样本（few-shot）学习方法，用于关系提取模型的领域适应问题。该方法利用大语言模型的 in-context learning 能力，通过 schema-constrained 数据标注，收集特定领域的训练实例，例如建筑、施工、工程和运营（AECO）领域的论文标题和摘要。实验结果显示，与基于 off-domain 数据的基线深度学习模型相比，该方法仅需最小专家标注和结构化提示，就能显著提升 Transformer-based 关系提取模型的性能，从而支持知识图谱（KGs）生成模型在新领域的适应。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02377v1",
      "published_date": "2024-08-05 11:06:36 UTC",
      "updated_date": "2024-08-05 11:06:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:05:10.354955"
    },
    {
      "arxiv_id": "2408.02373v2",
      "title": "Operationalizing Contextual Integrity in Privacy-Conscious Assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Sahra Ghalebikesabi",
        "Eugene Bagdasaryan",
        "Ren Yi",
        "Itay Yona",
        "Ilia Shumailov",
        "Aneesh Pappu",
        "Chongyang Shi",
        "Laura Weidinger",
        "Robert Stanforth",
        "Leonard Berrada",
        "Pushmeet Kohli",
        "Po-Sen Huang",
        "Borja Balle"
      ],
      "abstract": "Advanced AI assistants combine frontier LLMs and tool access to autonomously\nperform complex tasks on behalf of users. While the helpfulness of such\nassistants can increase dramatically with access to user information including\nemails and documents, this raises privacy concerns about assistants sharing\ninappropriate information with third parties without user supervision. To steer\ninformation-sharing assistants to behave in accordance with privacy\nexpectations, we propose to operationalize contextual integrity (CI), a\nframework that equates privacy with the appropriate flow of information in a\ngiven context. In particular, we design and evaluate a number of strategies to\nsteer assistants' information-sharing actions to be CI compliant. Our\nevaluation is based on a novel form filling benchmark composed of human\nannotations of common webform applications, and it reveals that prompting\nfrontier LLMs to perform CI-based reasoning yields strong results.",
      "tldr_zh": "这篇论文探讨了AI助手在使用前沿LLMs和工具访问用户信息（如邮件和文档）时可能不当分享信息导致的隐私问题，提出通过操作化Contextual Integrity (CI)框架来指导助手的分享行为，确保信息在特定上下文中的适当流动。研究设计并评估了多种策略，包括提示LLMs进行CI-based推理，以符合用户隐私期望。实验基于一个新型表单填写基准（由人类注解的常见网络表单应用组成）进行，结果显示这种方法显著提升了助手的隐私合规性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02373v2",
      "published_date": "2024-08-05 10:53:51 UTC",
      "updated_date": "2024-09-13 13:09:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:05:32.802030"
    },
    {
      "arxiv_id": "2408.02706v1",
      "title": "Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Masoud Muhammed Hassan"
      ],
      "abstract": "Because of its strong predictive skills, deep learning has emerged as an\nessential tool in many industries, including healthcare. Traditional deep\nlearning models, on the other hand, frequently lack interpretability and omit\nto take prediction uncertainty into account two crucial components of clinical\ndecision making. In order to produce explainable and uncertainty aware\npredictions, this study presents a novel framework called Bayesian Kolmogorov\nArnold Networks (BKANs), which combines the expressive capacity of Kolmogorov\nArnold Networks with Bayesian inference. We employ BKANs on two medical\ndatasets, which are widely used benchmarks for assessing machine learning\nmodels in medical diagnostics: the Pima Indians Diabetes dataset and the\nCleveland Heart Disease dataset. Our method provides useful insights into\nprediction confidence and decision boundaries and outperforms traditional deep\nlearning models in terms of prediction accuracy. Moreover, BKANs' capacity to\nrepresent aleatoric and epistemic uncertainty guarantees doctors receive more\nsolid and trustworthy decision support. Our Bayesian strategy improves the\ninterpretability of the model and considerably minimises overfitting, which is\nimportant for tiny and imbalanced medical datasets, according to experimental\nresults. We present possible expansions to further use BKANs in more\ncomplicated multimodal datasets and address the significance of these\ndiscoveries for future research in building reliable AI systems for healthcare.\nThis work paves the way for a new paradigm in deep learning model deployment in\nvital sectors where transparency and reliability are crucial.",
      "tldr_zh": "本研究提出了一种新型框架Bayesian Kolmogorov Arnold Networks (BKANs)，将Kolmogorov Arnold Networks的表达能力与Bayesian inference相结合，提升深度学习模型的预测准确性和可解释性，以解决传统模型在医疗决策中的不确定性问题。该框架在Pima Indians Diabetes dataset和Cleveland Heart Disease dataset上进行了测试，结果显示BKANs在准确率上超越传统模型，并能有效处理aleatoric and epistemic uncertainty，提供预测信心和决策边界洞见。实验还证明，该方法显著减少了过拟合，尤其适用于小型和不平衡的医疗数据集，并为未来在复杂多模态数据集上的应用和可靠AI系统的发展奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02706v1",
      "published_date": "2024-08-05 10:38:34 UTC",
      "updated_date": "2024-08-05 10:38:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:05:35.130879"
    },
    {
      "arxiv_id": "2408.02705v1",
      "title": "PSNE: Efficient Spectral Sparsification Algorithms for Scaling Network Embedding",
      "title_zh": "PSNE: 高效光谱稀疏",
      "authors": [
        "Longlong Lin",
        "Yunfeng Yu",
        "Zihao Wang",
        "Zeli Wang",
        "Yuying Zhao",
        "Jin Zhao",
        "Tao Jia"
      ],
      "abstract": "Network embedding has numerous practical applications and has received\nextensive attention in graph learning, which aims at mapping vertices into a\nlow-dimensional and continuous dense vector space by preserving the underlying\nstructural properties of the graph. Many network embedding methods have been\nproposed, among which factorization of the Personalized PageRank (PPR for\nshort) matrix has been empirically and theoretically well supported recently.\nHowever, several fundamental issues cannot be addressed. (1) Existing methods\ninvoke a seminal Local Push subroutine to approximate \\textit{a single} row or\ncolumn of the PPR matrix. Thus, they have to execute $n$ ($n$ is the number of\nnodes) Local Push subroutines to obtain a provable PPR matrix, resulting in\nprohibitively high computational costs for large $n$. (2) The PPR matrix has\nlimited power in capturing the structural similarity between vertices, leading\nto performance degradation. To overcome these dilemmas, we propose PSNE, an\nefficient spectral s\\textbf{P}arsification method for \\textbf{S}caling\n\\textbf{N}etwork \\textbf{E}mbedding, which can fast obtain the embedding\nvectors that retain strong structural similarities. Specifically, PSNE first\ndesigns a matrix polynomial sparser to accelerate the calculation of the PPR\nmatrix, which has a theoretical guarantee in terms of the Frobenius norm.\nSubsequently, PSNE proposes a simple but effective multiple-perspective\nstrategy to enhance further the representation power of the obtained\napproximate PPR matrix. Finally, PSNE applies a randomized singular value\ndecomposition algorithm on the sparse and multiple-perspective PPR matrix to\nget the target embedding vectors. Experimental evaluation of real-world and\nsynthetic datasets shows that our solutions are indeed more efficient,\neffective, and scalable compared with ten competitors.",
      "tldr_zh": "该论文提出 PSNE，一种高效的谱稀疏化算法，用于扩展网络嵌入（Network Embedding），旨在解决现有基于 Personalized PageRank (PPR) 矩阵的方法在计算成本高和结构相似性捕获不足的问题。PSNE 首先设计了矩阵多项式稀疏器来加速 PPR 矩阵计算，并提供 Frobenius 范数理论保证；随后引入多视角策略增强矩阵表示能力，并应用随机奇异值分解 (randomized SVD) 算法获取嵌入向量。实验结果显示，PSNE 在真实和合成数据集上比其他十种竞争方法更高效、有效和可扩展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02705v1",
      "published_date": "2024-08-05 10:38:30 UTC",
      "updated_date": "2024-08-05 10:38:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:05:46.565917"
    },
    {
      "arxiv_id": "2408.07704v1",
      "title": "Empathic Responding for Digital Interpersonal Emotion Regulation via Content Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Akriti Verma",
        "Shama Islam",
        "Valeh Moghaddam",
        "Adnan Anwar",
        "Sharon Horwood"
      ],
      "abstract": "Interpersonal communication plays a key role in managing people's emotions,\nespecially on digital platforms. Studies have shown that people use social\nmedia and consume online content to regulate their emotions and find support\nfor rest and recovery. However, these platforms are not designed for emotion\nregulation, which limits their effectiveness in this regard. To address this\nissue, we propose an approach to enhance Interpersonal Emotion Regulation (IER)\non online platforms through content recommendation. The objective is to empower\nusers to regulate their emotions while actively or passively engaging in online\nplatforms by crafting media content that aligns with IER strategies,\nparticularly empathic responding. The proposed recommendation system is\nexpected to blend system-initiated and user-initiated emotion regulation,\npaving the way for real-time IER practices on digital media platforms. To\nassess the efficacy of this approach, a mixed-method research design is used,\nincluding the analysis of text-based social media data and a user survey.\nDigital applications has served as facilitators in this process, given the\nwidespread recognition of digital media applications for Digital Emotion\nRegulation (DER). The study collects 37.5K instances of user posts and\ninteractions on Reddit over a year to design a Contextual Multi-Armed Bandits\n(CMAB) based recommendation system using features from user activity and\npreferences. The experimentation shows that the empathic recommendations\ngenerated by the proposed recommendation system are preferred by users over\nwidely accepted ER strategies such as distraction and avoidance.",
      "tldr_zh": "该研究探讨了通过内容推荐增强数字平台上的Interpersonal Emotion Regulation (IER)，特别强调移情响应（empathic responding）以帮助用户管理情绪。论文提出了一种基于Contextual Multi-Armed Bandits (CMAB)的推荐系统，利用用户帖子和互动数据（如Reddit的37.5K实例）来生成与IER策略相匹配的媒体内容，支持系统和用户发起的实时情绪调节。实验结果显示，这种移情推荐比传统的ER策略（如distraction和avoidance）更受用户青睐，从而提升了数字平台在情绪支持方面的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07704v1",
      "published_date": "2024-08-05 10:27:28 UTC",
      "updated_date": "2024-08-05 10:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:05:58.205615"
    },
    {
      "arxiv_id": "2408.10243v2",
      "title": "TrIM, Triangular Input Movement Systolic Array for Convolutional Neural Networks: Architecture and Hardware Implementation",
      "title_zh": "翻译失败",
      "authors": [
        "Cristian Sestito",
        "Shady Agwa",
        "Themis Prodromakis"
      ],
      "abstract": "Modern hardware architectures for Convolutional Neural Networks (CNNs), other\nthan targeting high performance, aim at dissipating limited energy. Reducing\nthe data movement cost between the computing cores and the memory is a way to\nmitigate the energy consumption. Systolic arrays are suitable architectures to\nachieve this objective: they use multiple processing elements that communicate\neach other to maximize data utilization, based on proper dataflows like the\nweight stationary and row stationary. Motivated by this, we have proposed TrIM,\nan innovative dataflow based on a triangular movement of inputs, and capable to\nreduce the number of memory accesses by one order of magnitude when compared to\nstate-of-the-art systolic arrays. In this paper, we present a TrIM-based\nhardware architecture for CNNs. As a showcase, the accelerator is implemented\nonto a Field Programmable Gate Array (FPGA) to execute the VGG-16 and AlexNet\nCNNs. The architecture achieves a peak throughput of 453.6 Giga Operations per\nSecond, outperforming a state-of-the-art row stationary systolic array up to\n~3x in terms of memory accesses, and being up to ~11.9x more energy-efficient\nthan other FPGA accelerators.",
      "tldr_zh": "本研究提出了一种名为 TrIM 的三角形输入运动数据流，用于 Convolutional Neural Networks (CNNs) 的 Systolic arrays 架构，旨在通过减少内存访问来降低能量消耗，与传统的 weight stationary 和 row stationary 数据流相比，可将内存访问减少一个数量级。论文详细呈现了基于 TrIM 的硬件架构，并在 Field Programmable Gate Array (FPGA) 上实现，成功执行 VGG-16 和 AlexNet 模型。实验结果显示，该架构实现了 453.6 Giga Operations per Second 的峰值吞吐量，比 state-of-the-art row stationary Systolic array 减少约 3 倍内存访问，并比其他 FPGA 加速器提高约 11.9 倍的能量效率。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AR",
      "comment": "This work has been accepted by IEEE TCAS-I for publication",
      "pdf_url": "http://arxiv.org/pdf/2408.10243v2",
      "published_date": "2024-08-05 10:18:00 UTC",
      "updated_date": "2025-01-14 11:23:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:06:11.456893"
    },
    {
      "arxiv_id": "2408.02361v2",
      "title": "Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding",
      "title_zh": "基于约束链式思维解码的对话本体关系提取",
      "authors": [
        "Renato Vukovic",
        "David Arps",
        "Carel van Niekerk",
        "Benjamin Matthias Ruppik",
        "Hsien-Chin Lin",
        "Michael Heck",
        "Milica Gašić"
      ],
      "abstract": "State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.",
      "tldr_zh": "该论文针对任务导向对话系统的本体（ontologies）关系提取问题，提出了一种基于约束 Chain-of-Thought (CoT) 解码机制的扩展方法，以提升转移学习（transfer learning）设置下的泛化能力。该方法在 large language models (LLMs) 的解码过程中生成多个分支，并通过置信度阈值选择关系，同时约束解码到本体术语和关系以减少幻觉（hallucination）风险。在两个常用数据集上的实验表明，该方法显著提高了源微调和 one-shot 提示的 LLM 在目标本体上的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to appear at SIGDIAL 2024. 9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.02361v2",
      "published_date": "2024-08-05 10:10:01 UTC",
      "updated_date": "2025-03-07 11:12:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:06:33.332608"
    },
    {
      "arxiv_id": "2408.02357v1",
      "title": "On the consistent reasoning paradox of intelligence and optimal trust in AI: The power of 'I don't know'",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Bastounis",
        "Paolo Campodonico",
        "Mihaela van der Schaar",
        "Ben Adcock",
        "Anders C. Hansen"
      ],
      "abstract": "We introduce the Consistent Reasoning Paradox (CRP). Consistent reasoning,\nwhich lies at the core of human intelligence, is the ability to handle tasks\nthat are equivalent, yet described by different sentences ('Tell me the time!'\nand 'What is the time?'). The CRP asserts that consistent reasoning implies\nfallibility -- in particular, human-like intelligence in AI necessarily comes\nwith human-like fallibility. Specifically, it states that there are problems,\ne.g. in basic arithmetic, where any AI that always answers and strives to mimic\nhuman intelligence by reasoning consistently will hallucinate (produce wrong,\nyet plausible answers) infinitely often. The paradox is that there exists a\nnon-consistently reasoning AI (which therefore cannot be on the level of human\nintelligence) that will be correct on the same set of problems. The CRP also\nshows that detecting these hallucinations, even in a probabilistic sense, is\nstrictly harder than solving the original problems, and that there are problems\nthat an AI may answer correctly, but it cannot provide a correct logical\nexplanation for how it arrived at the answer. Therefore, the CRP implies that\nany trustworthy AI (i.e., an AI that never answers incorrectly) that also\nreasons consistently must be able to say 'I don't know'. Moreover, this can\nonly be done by implicitly computing a new concept that we introduce, termed\nthe 'I don't know' function -- something currently lacking in modern AI. In\nview of these insights, the CRP also provides a glimpse into the behaviour of\nArtificial General Intelligence (AGI). An AGI cannot be 'almost sure', nor can\nit always explain itself, and therefore to be trustworthy it must be able to\nsay 'I don't know'.",
      "tldr_zh": "该论文引入了Consistent Reasoning Paradox (CRP)，指出一致性推理（人类智能的核心能力）会导致AI在处理等价但表述不同的任务时不可避免地产生hallucinations（错误却 plausible 的答案）。CRP 证明了任何追求一致性推理的AI会无限频繁地出错，而一个不一致性推理的AI可能在相同问题上更准确；此外，检测这些hallucinations比解决问题更困难，且AI可能正确回答却无法提供正确逻辑解释。论文强调，可信任的AI必须能够说“I don't know”，这需要实现一个新概念“I don't know” function，从而为Artificial General Intelligence (AGI)的发展提供关键洞见，即AGI不能总是自信或自我解释。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC",
        "math.PR"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages and 50 pages of supplementary material, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.02357v1",
      "published_date": "2024-08-05 10:06:53 UTC",
      "updated_date": "2024-08-05 10:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:06:45.541875"
    },
    {
      "arxiv_id": "2408.02349v4",
      "title": "Toward Cost-efficient Adaptive Clinical Trials in Knee Osteoarthritis with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Khanh Nguyen",
        "Huy Hoang Nguyen",
        "Egor Panfilov",
        "Aleksei Tiulpin"
      ],
      "abstract": "Osteoarthritis (OA) is the most common musculoskeletal disease, with knee OA\n(KOA) being one of the leading causes of disability and a significant economic\nburden. Predicting KOA progression is crucial for improving patient outcomes,\noptimizing healthcare resources, studying the disease, and developing new\ntreatments. The latter application particularly requires one to understand the\ndisease progression in order to collect the most informative data at the right\ntime. Existing methods, however, are limited by their static nature and their\nfocus on individual joints, leading to suboptimal predictive performance and\ndownstream utility. Our study proposes a new method that allows to dynamically\nmonitor patients rather than individual joints with KOA using a novel Active\nSensing (AS) approach powered by Reinforcement Learning (RL). Our key idea is\nto directly optimize for the downstream task by training an agent that\nmaximizes informative data collection while minimizing overall costs. Our\nRL-based method leverages a specially designed reward function to monitor\ndisease progression across multiple body parts, employs multimodal deep\nlearning, and requires no human input during testing. Extensive numerical\nexperiments demonstrate that our approach outperforms current state-of-the-art\nmodels, paving the way for the next generation of KOA trials.",
      "tldr_zh": "本文针对膝关节骨关节炎（KOA）的预测挑战，提出了一种基于强化学习（RL）的Active Sensing (AS) 方法，以动态监控患者整体而非单个关节，从而最大化信息数据收集并最小化临床试验成本。关键创新包括设计特定奖励函数、多模态深度学习技术，以及无需人为输入的自动化过程。该方法通过广泛的数值实验证明了其优于现有模型的表现，为下一代KOA临床试验提供更高效、可扩展的框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02349v4",
      "published_date": "2024-08-05 09:54:08 UTC",
      "updated_date": "2025-04-08 12:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:06:46.652265"
    },
    {
      "arxiv_id": "2408.11825v1",
      "title": "Strategic AI adoption in SMEs: A Prescriptive Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Atif Hussain",
        "Rana Rizwan"
      ],
      "abstract": "Artificial Intelligence (AI) is increasingly acknowledged as a vital\ncomponent for the advancement and competitiveness of modern organizations,\nincluding small and medium enterprises (SMEs). However, the adoption of AI\ntechnologies in SMEs faces significant barriers, primarily related to cost,\nlack of technical skills, and employee acceptance. This study proposes a\ncomprehensive, phased framework designed to facilitate the effective adoption\nof AI in SMEs by systematically addressing these barriers. The framework begins\nwith raising awareness and securing commitment from leadership, followed by the\nadoption of low-cost, general-purpose AI tools to build technical competence\nand foster a positive attitude towards AI. As familiarity with AI technologies\nincreases, the framework advocates for the integration of task-specific AI\ntools to enhance efficiency and productivity. Subsequently, it guides\norganizations towards the in-house development of generative AI tools,\nproviding greater customization and control. Finally, the framework addresses\nthe development of discriminative AI models to meet highly specific and\nprecision-oriented tasks. By providing a structured and incremental approach,\nthis framework ensures that SMEs can navigate the complexities of AI\nintegration effectively, driving innovation, efficiency, and competitive\nadvantage. This study contributes to the field by offering a practical,\nprescriptive framework tailored to the unique needs of SMEs, facilitating the\nsuccessful adoption of AI technologies and positioning these organizations for\nsustained growth in a competitive landscape.",
      "tldr_zh": "这篇论文提出一个针对小微企业（SMEs）的处方框架（Prescriptive Framework），旨在系统解决 AI 采用中的成本、技术技能缺失和员工接受度障碍。框架采用分阶段方法，从提升领导层意识并引入低成本通用 AI 工具开始，逐步推进到整合任务特定 AI 工具、内部开发生成式 AI 工具，以及开发判别式 AI 模型，以提高效率和生产力。该框架为 SMEs 提供结构化的指导，促进 AI 整合，推动创新和竞争优势。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11825v1",
      "published_date": "2024-08-05 09:49:37 UTC",
      "updated_date": "2024-08-05 09:49:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:07:00.016057"
    },
    {
      "arxiv_id": "2408.02704v1",
      "title": "Spatial-temporal Graph Convolutional Networks with Diversified Transformation for Dynamic Graph Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ling Wang",
        "Yixiang Huang",
        "Hao Wu"
      ],
      "abstract": "Dynamic graphs (DG) are often used to describe evolving interactions between\nnodes in real-world applications. Temporal patterns are a natural feature of\nDGs and are also key to representation learning. However, existing dynamic GCN\nmodels are mostly composed of static GCNs and sequence modules, which results\nin the separation of spatiotemporal information and cannot effectively capture\ncomplex temporal patterns in DGs. To address this problem, this study proposes\na spatial-temporal graph convolutional networks with diversified transformation\n(STGCNDT), which includes three aspects: a) constructing a unified graph tensor\nconvolutional network (GTCN) using tensor M-products without the need to\nrepresent spatiotemporal information separately; b) introducing three\ntransformation schemes in GTCN to model complex temporal patterns to aggregate\ntemporal information; and c) constructing an ensemble of diversified\ntransformation schemes to obtain higher representation capabilities. Empirical\nstudies on four DGs that appear in communication networks show that the\nproposed STGCNDT significantly outperforms state-of-the-art models in solving\nlink weight estimation tasks due to the diversified transformations.",
      "tldr_zh": "这篇论文针对动态图 (Dynamic Graphs) 中时空信息分离问题，提出了一种空间-时间图卷积网络 STGCNDT，用于改进动态图表示学习。STGCNDT 通过构建统一的图张量卷积网络 (GTCN) 基于张量 M-products 来整合时空信息，并引入三种转换方案来建模复杂时间模式，同时构建多种方案的集成以提升表示能力。在四个通信网络的动态图上进行实证研究，结果显示 STGCNDT 在链接权重估计任务中显著优于现有模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 papges, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2408.02704v1",
      "published_date": "2024-08-05 09:40:47 UTC",
      "updated_date": "2024-08-05 09:40:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:07:23.623177"
    },
    {
      "arxiv_id": "2408.04653v1",
      "title": "Batching BPE Tokenization Merges",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander P. Morgan"
      ],
      "abstract": "The Byte Pair Encoding algorithm can be safely batched to merge hundreds of\npairs of tokens at a time when building up a tokenizer's vocabulary. This\ntechnique combined with reducing the memory footprint of text used in\nvocabulary training make it feasible to train a high quality tokenizer on a\nbasic laptop. This paper presents BatchBPE, an open-source pure Python\nimplementation of these concepts, with the goal of making experimenting with\nnew tokenization strategies more accessible especially in compute- and\nmemory-constrained contexts. BatchBPE's usefulness and malleability are\ndemonstrated through the training of several token vocabularies to explore the\nbatch merging process and experiment with preprocessing a stop word list and\nignoring the least common text chunks in a dataset. Resultant encoded lengths\nof texts are used as a basic evaluation metric.",
      "tldr_zh": "该论文提出了一种批量处理 Byte Pair Encoding (BPE) 算法的方法，能够安全地同时合并数百对令牌，从而在构建分词器词汇表时显著提高效率并减少内存占用，使其在基本笔记本电脑上训练高质量分词器成为可能。作者开发了开源纯 Python 实现 BatchBPE，旨在简化在计算和内存受限环境中的新分词策略实验，并通过预处理停用词列表和忽略数据集中最不常见的文本块来展示其灵活性。实验结果使用文本编码长度作为评估指标，证明了 BatchBPE 在优化词汇训练方面的实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 5 figures, 1 code block",
      "pdf_url": "http://arxiv.org/pdf/2408.04653v1",
      "published_date": "2024-08-05 09:37:21 UTC",
      "updated_date": "2024-08-05 09:37:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:07:23.911049"
    },
    {
      "arxiv_id": "2408.02337v1",
      "title": "Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction",
      "title_zh": "翻译失败",
      "authors": [
        "Albert Sawczyn",
        "Katsiaryna Viarenich",
        "Konrad Wojtasik",
        "Aleksandra Domogała",
        "Marcin Oleksy",
        "Maciej Piasecki",
        "Tomasz Kajdanowicz"
      ],
      "abstract": "Advancements in AI and natural language processing have revolutionized\nmachine-human language interactions, with question answering (QA) systems\nplaying a pivotal role. The knowledge base question answering (KBQA) task,\nutilizing structured knowledge graphs (KG), allows for handling extensive\nknowledge-intensive questions. However, a significant gap exists in KBQA\ndatasets, especially for low-resource languages. Many existing construction\npipelines for these datasets are outdated and inefficient in human labor, and\nmodern assisting tools like Large Language Models (LLM) are not utilized to\nreduce the workload. To address this, we have designed and implemented a\nmodern, semi-automated approach for creating datasets, encompassing tasks such\nas KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),\ntailored explicitly for low-resource environments. We executed this pipeline\nand introduced the PUGG dataset, the first Polish KBQA dataset, and novel\ndatasets for MRC and IR. Additionally, we provide a comprehensive\nimplementation, insightful findings, detailed statistics, and evaluation of\nbaseline models.",
      "tldr_zh": "该研究针对低资源语言的知识库问答 (KBQA) 数据集建设问题，提出了一种现代半自动化的方法，利用大型语言模型 (LLM) 等工具来优化数据集构建过程，从而减少人力工作量。该方法适用于 KBQA、机器阅读理解 (MRC) 和信息检索 (IR) 等任务，特别针对如波兰语这样的低资源环境。研究团队成功创建了 PUGG 数据集，这是首个波兰语 KBQA 数据集，以及相应的 MRC 和 IR 数据集，并提供了全面实现细节、统计分析和基线模型评估结果。总的来说，这一方法填补了现有数据集管道的不足，提升了效率和可扩展性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for ACL 2024 (findings)",
      "pdf_url": "http://arxiv.org/pdf/2408.02337v1",
      "published_date": "2024-08-05 09:23:49 UTC",
      "updated_date": "2024-08-05 09:23:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:07:35.642835"
    },
    {
      "arxiv_id": "2408.05235v1",
      "title": "SLO-aware GPU Frequency Scaling for Energy Efficient LLM Inference Serving",
      "title_zh": "SLO 感知的 GPU 频率缩放，用于能效高效的 LLM 推理服务",
      "authors": [
        "Andreas Kosmas Kakolyris",
        "Dimosthenis Masouros",
        "Petros Vavaroutsos",
        "Sotirios Xydis",
        "Dimitrios Soudris"
      ],
      "abstract": "As Large Language Models (LLMs) gain traction, their reliance on power-hungry\nGPUs places ever-increasing energy demands, raising environmental and monetary\nconcerns. Inference dominates LLM workloads, presenting a critical challenge\nfor providers: minimizing energy costs under Service-Level Objectives (SLOs)\nthat ensure optimal user experience. In this paper, we present\n\\textit{throttLL'eM}, a framework that reduces energy consumption while meeting\nSLOs through the use of instance and GPU frequency scaling.\n\\textit{throttLL'eM} features mechanisms that project future KV cache usage and\nbatch size. Leveraging a Machine-Learning (ML) model that receives these\nprojections as inputs, \\textit{throttLL'eM} manages performance at the\niteration level to satisfy SLOs with reduced frequencies and instance sizes. We\nshow that the proposed ML model achieves $R^2$ scores greater than 0.97 and\nmiss-predicts performance by less than 1 iteration per second on average.\nExperimental results on LLM inference traces show that \\textit{throttLL'eM}\nachieves up to 43.8\\% lower energy consumption and an energy efficiency\nimprovement of at least $1.71\\times$ under SLOs, when compared to NVIDIA's\nTriton server.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)推理服务中的高能源消耗问题，提出了一种SLO-aware GPU频率缩放框架\\textit{throttLL'eM}，旨在在满足Service-Level Objectives (SLOs)的前提下降低能源使用。框架通过预测未来KV cache使用和批量大小，并利用一个Machine-Learning (ML)模型在迭代级别动态调整GPU频率和实例大小，实现高效性能管理。该ML模型的R²分数超过0.97，平均预测误差小于1个迭代每秒；实验结果显示，与NVIDIA的Triton服务器相比，\\textit{throttLL'eM}可降低能源消耗高达43.8%，并至少提高1.71倍的能源效率。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05235v1",
      "published_date": "2024-08-05 09:07:06 UTC",
      "updated_date": "2024-08-05 09:07:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:07:47.843849"
    },
    {
      "arxiv_id": "2408.02295v3",
      "title": "Generalized Gaussian Temporal Difference Error for Uncertainty-aware Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Seyeon Kim",
        "Joonhun Lee",
        "Namhoon Cho",
        "Sungjun Han",
        "Wooseop Hwang"
      ],
      "abstract": "Conventional uncertainty-aware temporal difference (TD) learning often\nassumes a zero-mean Gaussian distribution for TD errors, leading to inaccurate\nerror representations and compromised uncertainty estimation. We introduce a\nnovel framework for generalized Gaussian error modeling in deep reinforcement\nlearning to enhance the flexibility of error distribution modeling by\nincorporating additional higher-order moment, particularly kurtosis, thereby\nimproving the estimation and mitigation of data-dependent aleatoric\nuncertainty. We examine the influence of the shape parameter of the generalized\nGaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form\nexpression that demonstrates an inverse relationship between uncertainty and\nthe shape parameter. Additionally, we propose a theoretically grounded\nweighting scheme to address epistemic uncertainty by fully leveraging the GGD.\nWe refine batch inverse variance weighting with bias reduction and kurtosis\nconsiderations, enhancing robustness. Experiments with policy gradient\nalgorithms demonstrate significant performance gains.",
      "tldr_zh": "该研究指出，传统不确定性感知 Temporal Difference (TD) 学习假设 TD 错误服从零均值高斯分布，导致错误表示不准确和不确定性估计不足。为解决此问题，研究引入了一个新框架，使用 Generalized Gaussian Distribution (GGD) 建模 TD 错误，通过融入峰度 (kurtosis) 等更高阶矩，提高 aleatoric 不确定性的估计和缓解，并证明了不确定性与 GGD 形状参数呈反比关系。研究还提出一个基于 GGD 的加权方案，以处理 epistemic 不确定性，并通过偏差减少和峰度考虑优化批次逆方差加权。实验在策略梯度算法上显示，该方法显著提升了性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.PR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02295v3",
      "published_date": "2024-08-05 08:12:25 UTC",
      "updated_date": "2025-02-03 06:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:08:02.613876"
    },
    {
      "arxiv_id": "2408.02288v3",
      "title": "Spin glass model of in-context learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Li",
        "Ruoran Bai",
        "Haiping Huang"
      ],
      "abstract": "Large language models show a surprising in-context learning ability -- being\nable to use a prompt to form a prediction for a query, yet without additional\ntraining, in stark contrast to old-fashioned supervised learning. Providing a\nmechanistic interpretation and linking the empirical phenomenon to physics are\nthus challenging and remain unsolved. We study a simple yet expressive\ntransformer with linear attention and map this structure to a spin glass model\nwith real-valued spins, where the couplings and fields explain the intrinsic\ndisorder in data. The spin glass model explains how the weight parameters\ninteract with each other during pre-training, and further clarifies why an\nunseen function can be predicted by providing only a prompt yet without further\ntraining. Our theory reveals that for single-instance learning, increasing the\ntask diversity leads to the emergence of in-context learning, by allowing the\nBoltzmann distribution to converge to a unique correct solution of weight\nparameters. Therefore the pre-trained transformer displays a prediction power\nin a novel prompt setting. The proposed analytically tractable model thus\noffers a promising avenue for thinking about how to interpret many intriguing\nbut puzzling properties of large language models.",
      "tldr_zh": "本文提出了一种 spin glass model 来解释大语言模型的 in-context learning 能力，即模型能通过提示进行预测，而无需额外训练。作者将一个简单 transformer 模型与线性注意力结构映射到 spin glass model 中，其中耦合和场解释了数据中的内在无序，并阐明了权重参数在预训练期间的互动机制。研究发现，增加任务多样性可使 Boltzmann distribution 收敛到唯一正确权重参数解，从而在新型提示设置中实现预测能力。该模型为解析大语言模型的诸多谜题属性提供了一个有前景的理论框架。",
      "categories": [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cond-mat.dis-nn",
      "comment": "16 pages, 4+6 figures, revised version to the journal",
      "pdf_url": "http://arxiv.org/pdf/2408.02288v3",
      "published_date": "2024-08-05 07:54:01 UTC",
      "updated_date": "2025-04-18 08:16:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:08:14.467292"
    },
    {
      "arxiv_id": "2408.02280v1",
      "title": "Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and Cost",
      "title_zh": "翻译失败",
      "authors": [
        "Jannis Maier",
        "Felix Möller",
        "Lennart Purucker"
      ],
      "abstract": "Automated Machine Learning (AutoML) significantly simplifies the deployment\nof machine learning models by automating tasks from data preprocessing to model\nselection to ensembling. AutoML systems for tabular data often employ post hoc\nensembling, where multiple models are combined to improve predictive accuracy.\nThis typically results in longer inference times, a major limitation in\npractical deployments. Addressing this, we introduce a hardware-aware ensemble\nselection approach that integrates inference time into post hoc ensembling. By\nleveraging an existing framework for ensemble selection with quality diversity\noptimization, our method evaluates ensemble candidates for their predictive\naccuracy and hardware efficiency. This dual focus allows for a balanced\nconsideration of accuracy and operational efficiency. Thus, our approach\nenables practitioners to choose from a Pareto front of accurate and efficient\nensembles. Our evaluation using 83 classification datasets shows that our\napproach sustains competitive accuracy and can significantly improve ensembles'\noperational efficiency. The results of this study provide a foundation for\nextending these principles to additional hardware constraints, setting the\nstage for the development of more resource-efficient AutoML systems.",
      "tldr_zh": "该研究针对 Automated Machine Learning (AutoML) 在处理表格数据时，后验集成（post hoc ensembling）导致推理时间过长的难题，提出了一种硬件感知的集成选择方法，以平衡预测准确性和操作成本。方法通过整合质量多样性优化框架，评估集成候选的准确性与硬件效率，从而生成 Pareto front 的集成选项，供从业者选择最优权衡方案。在83个分类数据集的实验中，该方法保持了竞争性预测准确率，同时显著提升了操作效率，为扩展到更多硬件约束的资源高效AutoML系统提供了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Third International Conference on Automated Machine\n  Learning (AutoML 2024), Workshop Track; for code, see\n  https://github.com/Atraxus/HA-ES",
      "pdf_url": "http://arxiv.org/pdf/2408.02280v1",
      "published_date": "2024-08-05 07:30:18 UTC",
      "updated_date": "2024-08-05 07:30:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:08:24.178847"
    },
    {
      "arxiv_id": "2408.02279v1",
      "title": "DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Ruixin Ding",
        "Yuqi Chen",
        "Yu-Ting Lan",
        "Wei Zhang"
      ],
      "abstract": "Long-term time series forecasting (LTSF) has been widely applied in finance,\ntraffic prediction, and other domains. Recently, patch-based transformers have\nemerged as a promising approach, segmenting data into sub-level patches that\nserve as input tokens. However, existing methods mostly rely on predetermined\npatch lengths, necessitating expert knowledge and posing challenges in\ncapturing diverse characteristics across various scales. Moreover, time series\ndata exhibit diverse variations and fluctuations across different temporal\nscales, which traditional approaches struggle to model effectively. In this\npaper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm\nto capture diverse receptive fields and sparse patterns of time series data. In\norder to build hierarchical receptive fields, we develop a multi-scale\nTransformer model, coupled with multi-scale sequence extraction, capable of\ncapturing multi-resolution features. Additionally, we introduce a group-aware\nrotary position encoding technique to enhance intra- and inter-group position\nawareness among representations across different temporal scales. Our proposed\nmodel, named DRFormer, is evaluated on various real-world datasets, and\nexperimental results demonstrate its superiority compared to existing methods.\nOur code is available at: https://github.com/ruixindingECNU/DRFormer.",
      "tldr_zh": "该论文提出 DRFormer，一种多尺度 Transformer 模型，用于长期时间序列预测（LTSF），通过动态 tokenizer 和动态稀疏学习算法捕捉时间序列数据的多样化感受野和稀疏模式，以克服现有方法依赖固定 patch 长度的局限性。模型还结合多尺度序列提取和 group-aware rotary position encoding 技术，构建层次化感受野并提升不同时间尺度间的表示感知。实验结果显示，DRFormer 在各种真实数据集上表现出优于现有方法的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02279v1",
      "published_date": "2024-08-05 07:26:47 UTC",
      "updated_date": "2024-08-05 07:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:08:35.284958"
    },
    {
      "arxiv_id": "2408.02275v1",
      "title": "Geometric Algebra Meets Large Language Models: Instruction-Based Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes",
      "title_zh": "翻译失败",
      "authors": [
        "Dimitris Angelis",
        "Prodromos Kolyvakis",
        "Manos Kamarianakis",
        "George Papagiannakis"
      ],
      "abstract": "This paper introduces a novel integration of Large Language Models (LLMs)\nwith Conformal Geometric Algebra (CGA) to revolutionize controllable 3D scene\nediting, particularly for object repositioning tasks, which traditionally\nrequires intricate manual processes and specialized expertise. These\nconventional methods typically suffer from reliance on large training datasets\nor lack a formalized language for precise edits. Utilizing CGA as a robust\nformal language, our system, shenlong, precisely models spatial transformations\nnecessary for accurate object repositioning. Leveraging the zero-shot learning\ncapabilities of pre-trained LLMs, shenlong translates natural language\ninstructions into CGA operations which are then applied to the scene,\nfacilitating exact spatial transformations within 3D scenes without the need\nfor specialized pre-training. Implemented in a realistic simulation\nenvironment, shenlong ensures compatibility with existing graphics pipelines.\nTo accurately assess the impact of CGA, we benchmark against robust Euclidean\nSpace baselines, evaluating both latency and accuracy. Comparative performance\nevaluations indicate that shenlong significantly reduces LLM response times by\n16% and boosts success rates by 9.6% on average compared to the traditional\nmethods. Notably, shenlong achieves a 100% perfect success rate in common\npractical queries, a benchmark where other systems fall short. These\nadvancements underscore shenlong's potential to democratize 3D scene editing,\nenhancing accessibility and fostering innovation across sectors such as\neducation, digital entertainment, and virtual reality.",
      "tldr_zh": "本论文提出了一种将 Large Language Models (LLMs) 与 Conformal Geometric Algebra (CGA) 整合的创新系统，名为 shenlong，用于实现基于自然语言指令的可控 3D 场景编辑，特别是对象重新定位任务，避免了传统方法对大规模训练数据集的依赖。系统利用 LLMs 的零样本学习能力，将指令转化为精确的 CGA 操作，从而在无需专门预训练的情况下，实现 3D 场景中的空间变换，并与现有图形管道兼容。实验结果显示，shenlong 相较于 Euclidean Space 基线，减少了 LLM 响应时间 16% 并提高了成功率 9.6%，在常见查询中达到 100% 完美成功率，这有助于 democratize 3D 编辑技术，推动教育、数字娱乐和虚拟现实领域的创新。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.02275v1",
      "published_date": "2024-08-05 07:10:40 UTC",
      "updated_date": "2024-08-05 07:10:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:08:49.338028"
    },
    {
      "arxiv_id": "2408.11824v3",
      "title": "AppAgent v2: Advanced Agent for Flexible Mobile Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Yanda Li",
        "Chi Zhang",
        "Wanqi Yang",
        "Bin Fu",
        "Pei Cheng",
        "Xin Chen",
        "Ling Chen",
        "Yunchao Wei"
      ],
      "abstract": "With the advancement of Multimodal Large Language Models (MLLM), LLM-driven\nvisual agents are increasingly impacting software interfaces, particularly\nthose with graphical user interfaces. This work introduces a novel LLM-based\nmultimodal agent framework for mobile devices. This framework, capable of\nnavigating mobile devices, emulates human-like interactions. Our agent\nconstructs a flexible action space that enhances adaptability across various\napplications including parser, text and vision descriptions. The agent operates\nthrough two main phases: exploration and deployment. During the exploration\nphase, functionalities of user interface elements are documented either through\nagent-driven or manual explorations into a customized structured knowledge\nbase. In the deployment phase, RAG technology enables efficient retrieval and\nupdate from this knowledge base, thereby empowering the agent to perform tasks\neffectively and accurately. This includes performing complex, multi-step\noperations across various applications, thereby demonstrating the framework's\nadaptability and precision in handling customized task workflows. Our\nexperimental results across various benchmarks demonstrate the framework's\nsuperior performance, confirming its effectiveness in real-world scenarios. Our\ncode will be open source soon.",
      "tldr_zh": "本研究提出AppAgent v2，一种基于Multimodal Large Language Models (MLLM)的多模态代理框架，用于实现灵活的移动设备交互。该框架构建可适应各种应用的action space，通过exploration阶段记录UI元素功能到structured knowledge base，以及deployment阶段利用RAG technology进行高效检索和更新，从而模拟人类-like操作并执行复杂多步任务。实验结果显示，该框架在多个基准上表现出色，证明了其在真实场景中的精确性和适用性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11824v3",
      "published_date": "2024-08-05 06:31:39 UTC",
      "updated_date": "2024-10-10 06:33:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:09:01.551192"
    },
    {
      "arxiv_id": "2408.02247v5",
      "title": "Contrastive Learning and Abstract Concepts: The Case of Natural Numbers",
      "title_zh": "对比学习与抽象概念：以自然数为例",
      "authors": [
        "Daniel N. Nissani"
      ],
      "abstract": "Contrastive Learning (CL) has been successfully applied to classification and\nother downstream tasks related to concrete concepts, such as objects contained\nin the ImageNet dataset. No attempts seem to have been made so far in applying\nthis promising scheme to more abstract entities. A prominent example of these\ncould be the concept of (discrete) Quantity. CL can be frequently interpreted\nas a self-supervised scheme guided by some profound and ubiquitous conservation\nprinciple (e.g. conservation of identity in object classification tasks). In\nthis introductory work we apply a suitable conservation principle to the\nsemi-abstract concept of natural numbers by which discrete quantities can be\nestimated or predicted. We experimentally show, by means of a toy problem, that\ncontrastive learning can be trained to count at a glance with high accuracy\nboth at human as well as at super-human ranges.. We compare this with the\nresults of a trained-to-count at a glance supervised learning (SL) neural\nnetwork scheme of similar architecture. We show that both schemes exhibit\nsimilar good performance on baseline experiments, where the distributions of\nthe training and testing stages are equal. Importantly, we demonstrate that in\nsome generalization scenarios, where training and testing distributions differ,\nCL boasts more robust and much better error performance.",
      "tldr_zh": "本研究首次将对比学习（Contrastive Learning, CL）应用于抽象概念，特别是自然数，旨在通过守恒原则指导的自监督学习来估计或预测离散数量。研究者设计了一个玩具问题实验，训练CL模型实现快速高精度计数，并在人类和超人类范围内表现出色。相比于类似架构的监督学习（Supervised Learning, SL）神经网络，CL在训练和测试分布相同的基准实验中表现相当，但在分布不同的泛化场景中，CL显示出更强的鲁棒性和更好的错误性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02247v5",
      "published_date": "2024-08-05 05:41:16 UTC",
      "updated_date": "2024-09-11 14:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:09:13.816912"
    },
    {
      "arxiv_id": "2408.02244v1",
      "title": "Evaluating Vision-Language Models for Zero-Shot Detection, Classification, and Association of Motorcycles, Passengers, and Helmets",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Choi",
        "Ross Greer"
      ],
      "abstract": "Motorcycle accidents pose significant risks, particularly when riders and\npassengers do not wear helmets. This study evaluates the efficacy of an\nadvanced vision-language foundation model, OWLv2, in detecting and classifying\nvarious helmet-wearing statuses of motorcycle occupants using video data. We\nextend the dataset provided by the CVPR AI City Challenge and employ a cascaded\nmodel approach for detection and classification tasks, integrating OWLv2 and\nCNN models. The results highlight the potential of zero-shot learning to\naddress challenges arising from incomplete and biased training datasets,\ndemonstrating the usage of such models in detecting motorcycles, helmet usage,\nand occupant positions under varied conditions. We have achieved an average\nprecision of 0.5324 for helmet detection and provided precision-recall curves\ndetailing the detection and classification performance. Despite limitations\nsuch as low-resolution data and poor visibility, our research shows promising\nadvancements in automated vehicle safety and traffic safety enforcement\nsystems.",
      "tldr_zh": "本研究评估了视觉语言模型 OWLv2 在零样本（zero-shot）条件下，对摩托车、乘客和头盔的检测、分类及关联能力的效能，针对摩托车事故风险（如未戴头盔）提出解决方案。研究扩展了 CVPR AI City Challenge 的数据集，并采用级联模型（OWLv2 与 CNN 结合）来处理视频数据中的检测和分类任务。结果显示，OWLv2 在各种条件下实现了 0.5324 的平均精度，并提供了精确-召回曲线，证明了零样本学习在应对不完整或偏差数据集时的潜力。尽管存在低分辨率和可见性挑战，该方法为自动车辆安全和交通执法系统带来了显著进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02244v1",
      "published_date": "2024-08-05 05:30:36 UTC",
      "updated_date": "2024-08-05 05:30:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:09:26.430045"
    },
    {
      "arxiv_id": "2408.02233v1",
      "title": "A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method for Legal Charge Prediction",
      "title_zh": "一种多源异构知识注入的提示学习方法，用于法律指控预测",
      "authors": [
        "Jingyun Sun",
        "Chi Wei",
        "Yang Li"
      ],
      "abstract": "Legal charge prediction, an essential task in legal AI, seeks to assign\naccurate charge labels to case descriptions, attracting significant recent\ninterest. Existing methods primarily employ diverse neural network structures\nfor modeling case descriptions directly, failing to effectively leverage\nmulti-source external knowledge. We propose a prompt learning framework-based\nmethod that simultaneously leverages multi-source heterogeneous external\nknowledge from a legal knowledge base, a conversational LLM, and related legal\narticles. Specifically, we match knowledge snippets in case descriptions via\nthe legal knowledge base and encapsulate them into the input through a hard\nprompt template. Additionally, we retrieve legal articles related to a given\ncase description through contrastive learning, and then obtain factual elements\nwithin the case description through a conversational LLM. We fuse the embedding\nvectors of soft prompt tokens with the encoding vector of factual elements to\nachieve knowledge-enhanced model forward inference. Experimental results show\nthat our method achieved state-of-the-art results on CAIL-2018, the largest\nlegal charge prediction dataset, and our method has lower data dependency. Case\nstudies also demonstrate our method's strong interpretability.",
      "tldr_zh": "该研究提出了一种基于提示学习（prompt learning）的框架方法，用于法律指控预测任务，通过注入多源异构外部知识（来自法律知识库、对话式 LLM 和相关法律文章）来提升模型性能。具体方法包括：通过法律知识基匹配并封装知识片段到硬提示模板中、利用对比学习（contrastive learning）检索相关法律文章、并通过对话式 LLM 提取事实元素，然后融合软提示嵌入向量以实现知识增强的推理。实验结果显示，该方法在 CAIL-2018 数据集上取得了最先进（state-of-the-art）的性能，同时具有较低的数据依赖性和强解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.02233v1",
      "published_date": "2024-08-05 04:53:17 UTC",
      "updated_date": "2024-08-05 04:53:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:09:37.905907"
    },
    {
      "arxiv_id": "2408.02232v4",
      "title": "SpecRover: Code Intent Extraction via LLMs",
      "title_zh": "SpecRover：通过大语言模型的代码意图提取",
      "authors": [
        "Haifeng Ruan",
        "Yuntong Zhang",
        "Abhik Roychoudhury"
      ],
      "abstract": "Autonomous program improvement typically involves automatically producing bug\nfixes and feature additions. Such program improvement can be accomplished by a\ncombination of large language model (LLM) and program analysis capabilities, in\nthe form of an LLM agent. Since program repair or program improvement typically\nrequires a specification of intended behavior - specification inference can be\nuseful for producing high quality program patches. In this work, we examine\nefficient and low-cost workflows for iterative specification inference within\nan LLM agent. Given a GitHub issue to be resolved in a software project, our\ngoal is to conduct iterative code search accompanied by specification inference\n- thereby inferring intent from both the project structure and behavior. The\nintent thus captured is examined by a reviewer agent with the goal of vetting\nthe patches as well as providing a measure of confidence in the vetted patches.\nOur approach SpecRover (AutoCodeRover-v2) is built on the open-source LLM agent\nAutoCodeRover. In an evaluation on the full SWE-Bench consisting of 2294 GitHub\nissues, it shows more than 50% improvement in efficacy over AutoCodeRover.\nCompared to the open-source agents available, our work shows modest cost ($0.65\nper issue) in resolving an average GitHub issue in SWE-Bench lite. The\nproduction of explanation by SpecRover allows for a better \"signal\" to be given\nto the developer, on when the suggested patches can be accepted with\nconfidence. SpecRover also seeks to demonstrate the continued importance of\nspecification inference in automated program repair, even as program repair\ntechnologies enter the LLM era.",
      "tldr_zh": "本研究提出SpecRover（AutoCodeRover-v2），一种基于LLMs的框架，用于通过迭代代码搜索和specification inference提取代码意图，从而实现自动程序修复和改进。该方法结合LLM代理和审查者代理，从GitHub问题中推断项目结构与行为意图，并生成可审核的补丁，以提升补丁置信度。在SWE-Bench的2294个GitHub问题评估中，SpecRover比AutoCodeRover效能提升超过50%，且每问题成本仅0.65美元。该框架强调了specification inference在LLM时代自动程序修复中的持续重要性，提供更可靠的开发者决策支持。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Haifeng Ruan and Yuntong Zhang contributed equally to this work. To\n  appear in ICSE 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.02232v4",
      "published_date": "2024-08-05 04:53:01 UTC",
      "updated_date": "2024-12-11 11:18:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:09:50.536752"
    },
    {
      "arxiv_id": "2408.02213v1",
      "title": "Is Large Language Model Good at Database Knob Tuning? A Comprehensive Experimental Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyan Li",
        "Haoyang Li",
        "Zhao Pu",
        "Jing Zhang",
        "Xinyi Zhang",
        "Tao Ji",
        "Luming Sun",
        "Cuiping Li",
        "Hong Chen"
      ],
      "abstract": "Knob tuning plays a crucial role in optimizing databases by adjusting knobs\nto enhance database performance. However, traditional tuning methods often\nfollow a Try-Collect-Adjust approach, proving inefficient and\ndatabase-specific. Moreover, these methods are often opaque, making it\nchallenging for DBAs to grasp the underlying decision-making process.\n  The emergence of large language models (LLMs) like GPT-4 and Claude-3 has\nexcelled in complex natural language tasks, yet their potential in database\nknob tuning remains largely unexplored. This study harnesses LLMs as\nexperienced DBAs for knob-tuning tasks with carefully designed prompts. We\nidentify three key subtasks in the tuning system: knob pruning, model\ninitialization, and knob recommendation, proposing LLM-driven solutions to\nreplace conventional methods for each subtask.\n  We conduct extensive experiments to compare LLM-driven approaches against\ntraditional methods across the subtasks to evaluate LLMs' efficacy in the knob\ntuning domain. Furthermore, we explore the adaptability of LLM-based solutions\nin diverse evaluation settings, encompassing new benchmarks, database engines,\nand hardware environments. Our findings reveal that LLMs not only match or\nsurpass traditional methods but also exhibit notable interpretability by\ngenerating responses in a coherent ``chain-of-thought'' manner. We further\nobserve that LLMs exhibit remarkable generalizability through simple\nadjustments in prompts, eliminating the necessity for additional training or\nextensive code modifications.\n  Drawing insights from our experimental findings, we identify several\nopportunities for future research aimed at advancing the utilization of LLMs in\nthe realm of database management.",
      "tldr_zh": "这篇论文评估了大型语言模型（LLMs，如 GPT-4 和 Claude-3）在数据库 knob tuning 中的性能，旨在解决传统方法的低效、不透明和数据库特定问题。研究者提出 LLMs 驱动的解决方案，包括 knob pruning、model initialization 和 knob recommendation 等子任务，通过精心设计的 prompts 替换传统方法。实验结果显示，LLMs 不仅能匹配或超越传统方法，还提供更好的 interpretability  via chain-of-thought 响应，并展示出优秀的 generalizability，仅需简单 prompt 调整即可适应新基准、数据库引擎和硬件环境。论文最后指出了未来利用 LLMs 提升数据库管理的潜在研究机会。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02213v1",
      "published_date": "2024-08-05 03:26:01 UTC",
      "updated_date": "2024-08-05 03:26:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:10:02.943725"
    },
    {
      "arxiv_id": "2408.02207v1",
      "title": "MARCO: A Memory-Augmented Reinforcement Framework for Combinatorial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Andoni I. Garmendia",
        "Quentin Cappart",
        "Josu Ceberio",
        "Alexander Mendiburu"
      ],
      "abstract": "Neural Combinatorial Optimization (NCO) is an emerging domain where deep\nlearning techniques are employed to address combinatorial optimization problems\nas a standalone solver. Despite their potential, existing NCO methods often\nsuffer from inefficient search space exploration, frequently leading to local\noptima entrapment or redundant exploration of previously visited states. This\npaper introduces a versatile framework, referred to as Memory-Augmented\nReinforcement for Combinatorial Optimization (MARCO), that can be used to\nenhance both constructive and improvement methods in NCO through an innovative\nmemory module. MARCO stores data collected throughout the optimization\ntrajectory and retrieves contextually relevant information at each state. This\nway, the search is guided by two competing criteria: making the best decision\nin terms of the quality of the solution and avoiding revisiting already\nexplored solutions. This approach promotes a more efficient use of the\navailable optimization budget. Moreover, thanks to the parallel nature of NCO\nmodels, several search threads can run simultaneously, all sharing the same\nmemory module, enabling an efficient collaborative exploration. Empirical\nevaluations, carried out on the maximum cut, maximum independent set and\ntravelling salesman problems, reveal that the memory module effectively\nincreases the exploration, enabling the model to discover diverse,\nhigher-quality solutions. MARCO achieves good performance in a low\ncomputational cost, establishing a promising new direction in the field of NCO.",
      "tldr_zh": "这篇论文提出了 MARCO，一种记忆增强的强化框架，用于提升 Neural Combinatorial Optimization (NCO) 在组合优化问题中的搜索效率，解决现有方法容易陷入局部最优或重复探索的难题。MARCO 通过一个创新的记忆模块存储优化轨迹数据，并在每个状态下检索相关信息，指导搜索同时考虑解决方案质量和避免重复探索，并支持多线程并行协作。实验在 maximum cut、maximum independent set 和 travelling salesman problems 上显示，MARCO 显著提高了解决方案的质量和多样性，同时在低计算成本下实现了出色性能，为 NCO 领域开辟了新方向。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02207v1",
      "published_date": "2024-08-05 03:15:21 UTC",
      "updated_date": "2024-08-05 03:15:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:10:14.567967"
    },
    {
      "arxiv_id": "2408.02205v4",
      "title": "Swiss Cheese Model for AI Safety: A Taxonomy and Reference Architecture for Multi-Layered Guardrails of Foundation Model Based Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Md Shamsujjoha",
        "Qinghua Lu",
        "Dehai Zhao",
        "Liming Zhu"
      ],
      "abstract": "Foundation Model (FM)-based agents are revolutionizing application\ndevelopment across various domains. However, their rapidly growing capabilities\nand autonomy have raised significant concerns about AI safety. Researchers are\nexploring better ways to design guardrails to ensure that the runtime behavior\nof FM-based agents remains within specific boundaries. Nevertheless, designing\neffective runtime guardrails is challenging due to the agents' autonomous and\nnon-deterministic behavior. The involvement of multiple pipeline stages and\nagent artifacts, such as goals, plans, tools, at runtime further complicates\nthese issues. Addressing these challenges at runtime requires multi-layered\nguardrails that operate effectively at various levels of the agent\narchitecture. Therefore, in this paper, based on the results of a systematic\nliterature review, we present a comprehensive taxonomy of runtime guardrails\nfor FM-based agents to identify the key quality attributes for guardrails and\ndesign dimensions. Inspired by the Swiss Cheese Model, we also propose a\nreference architecture for designing multi-layered runtime guardrails for\nFM-based agents, which includes three dimensions: quality attributes,\npipelines, and artifacts. The proposed taxonomy and reference architecture\nprovide concrete and robust guidance for researchers and practitioners to build\nAI-safety-by-design from a software architecture perspective.",
      "tldr_zh": "这篇论文针对 Foundation Model (FM)-based agents 的快速发展和自主性引发的 AI 安全担忧，提出一个基于系统文献综述的运行时守卫机制分类法(taxonomy)，以识别关键质量属性和设计维度。受 Swiss Cheese Model 启发，他们设计了一个参考架构，包括质量属性、管道和工件的三个维度，用于构建多层守卫机制，确保代理行为的边界控制。总体上，该 taxonomy 和参考架构为研究者和从业者提供实用指导，从软件架构视角实现 AI 安全设计。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.02205v4",
      "published_date": "2024-08-05 03:08:51 UTC",
      "updated_date": "2025-01-27 00:48:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:10:26.364748"
    },
    {
      "arxiv_id": "2408.10240v1",
      "title": "AltCanvas: A Tile-Based Image Editor with Generative AI for Blind or Visually Impaired People",
      "title_zh": "AltCanvas：一种基于平铺的图像编辑器，结合生成式人工智能，用于盲人或视力受损人士",
      "authors": [
        "Seonghee Lee",
        "Maho Kohga",
        "Steve Landau",
        "Sile O'Modhrain",
        "Hari Subramonyam"
      ],
      "abstract": "People with visual impairments often struggle to create content that relies\nheavily on visual elements, particularly when conveying spatial and structural\ninformation. Existing accessible drawing tools, which construct images line by\nline, are suitable for simple tasks like math but not for more expressive\nartwork. On the other hand, emerging generative AI-based text-to-image tools\ncan produce expressive illustrations from descriptions in natural language, but\nthey lack precise control over image composition and properties. To address\nthis gap, our work integrates generative AI with a constructive approach that\nprovides users with enhanced control and editing capabilities. Our system,\nAltCanvas, features a tile-based interface enabling users to construct visual\nscenes incrementally, with each tile representing an object within the scene.\nUsers can add, edit, move, and arrange objects while receiving speech and audio\nfeedback. Once completed, the scene can be rendered as a color illustration or\nas a vector for tactile graphic generation. Involving 14 blind or low-vision\nusers in design and evaluation, we found that participants effectively used the\nAltCanvas workflow to create illustrations.",
      "tldr_zh": "本研究针对视觉障碍者创建依赖空间和结构信息的视觉内容时面临的挑战，提出AltCanvas系统，该系统结合Generative AI和基于平铺的编辑界面，允许用户逐步添加、编辑和排列场景中的对象，并通过语音和音频反馈提供辅助。AltCanvas支持将完成的场景渲染为彩色插图或向量图形，用于触觉图形生成，从而增强用户对图像组成的精确控制。与现有工具相比，该系统解决了表达性艺术创作的局限性。用户研究涉及14名盲人或低视力参与者，结果显示他们能有效使用AltCanvas创建插图。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10240v1",
      "published_date": "2024-08-05 01:47:36 UTC",
      "updated_date": "2024-08-05 01:47:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:10:39.182202"
    },
    {
      "arxiv_id": "2408.10239v1",
      "title": "A Conceptual Framework for Ethical Evaluation of Machine Learning Systems",
      "title_zh": "机器学习系统伦理评估的概念框架",
      "authors": [
        "Neha R. Gupta",
        "Jessica Hullman",
        "Hari Subramonyam"
      ],
      "abstract": "Research in Responsible AI has developed a range of principles and practices\nto ensure that machine learning systems are used in a manner that is ethical\nand aligned with human values. However, a critical yet often neglected aspect\nof ethical ML is the ethical implications that appear when designing\nevaluations of ML systems. For instance, teams may have to balance a trade-off\nbetween highly informative tests to ensure downstream product safety, with\npotential fairness harms inherent to the implemented testing procedures. We\nconceptualize ethics-related concerns in standard ML evaluation techniques.\nSpecifically, we present a utility framework, characterizing the key trade-off\nin ethical evaluation as balancing information gain against potential ethical\nharms. The framework is then a tool for characterizing challenges teams face,\nand systematically disentangling competing considerations that teams seek to\nbalance. Differentiating between different types of issues encountered in\nevaluation allows us to highlight best practices from analogous domains, such\nas clinical trials and automotive crash testing, which navigate these issues in\nways that can offer inspiration to improve evaluation processes in ML. Our\nanalysis underscores the critical need for development teams to deliberately\nassess and manage ethical complexities that arise during the evaluation of ML\nsystems, and for the industry to move towards designing institutional policies\nto support ethical evaluations.",
      "tldr_zh": "本研究提出一个概念框架，用于评估机器学习 (ML) 系统的伦理问题，强调在设计评估时需平衡信息获取与潜在伦理危害，如公平性损害。框架将关键权衡定义为最大化信息增益同时最小化伦理风险，并通过系统分析帮助团队识别和处理评估中的竞争考虑。作者借鉴临床试验和汽车碰撞测试等领域的经验，建议最佳实践，以指导ML评估过程；最终呼吁开发团队主动评估伦理复杂性，并推动行业制定相关政策以确保更负责任的ML系统开发。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10239v1",
      "published_date": "2024-08-05 01:06:49 UTC",
      "updated_date": "2024-08-05 01:06:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:10:49.270226"
    },
    {
      "arxiv_id": "2408.11058v1",
      "title": "LLM Agents Improve Semantic Code Search",
      "title_zh": "LLM 代理改进语义代码搜索",
      "authors": [
        "Sarthak Jain",
        "Aditya Dora",
        "Ka Seng Sam",
        "Prabhat Singh"
      ],
      "abstract": "Code Search is a key task that many programmers often have to perform while\ndeveloping solutions to problems. Current methodologies suffer from an\ninability to perform accurately on prompts that contain some ambiguity or ones\nthat require additional context relative to a code-base. We introduce the\napproach of using Retrieval Augmented Generation (RAG) powered agents to inject\ninformation into user prompts allowing for better inputs into embedding models.\nBy utilizing RAG, agents enhance user queries with relevant details from GitHub\nrepositories, making them more informative and contextually aligned.\nAdditionally, we introduce a multi-stream ensemble approach which when paired\nwith agentic workflow can obtain improved retrieval accuracy, which we deploy\non application called repo-rift.com. Experimental results on the CodeSearchNet\ndataset demonstrate that RepoRift significantly outperforms existing methods,\nachieving an 78.2% success rate at Success@10 and a 34.6% success rate at\nSuccess@1. This research presents a substantial advancement in semantic code\nsearch, highlighting the potential of agentic LLMs and RAG to enhance code\nretrieval systems.",
      "tldr_zh": "该研究针对代码搜索任务中现有方法处理模糊提示或上下文依赖问题的不足，提出使用LLM代理结合Retrieval Augmented Generation (RAG)技术来增强用户查询。具体而言，代理从GitHub仓库中注入相关信息，并引入多流集成(multi-stream ensemble)方法，提高检索准确性，该系统部署在名为repo-rift.com的应用上。在CodeSearchNet数据集上的实验显示，RepoRift在Success@10上达到78.2%、Success@1上达到34.6%的成功率，显著优于现有方法，展示了代理LLM和RAG在语义代码搜索领域的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 1 Figure",
      "pdf_url": "http://arxiv.org/pdf/2408.11058v1",
      "published_date": "2024-08-05 00:43:56 UTC",
      "updated_date": "2024-08-05 00:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:11:12.951945"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 81,
  "processed_papers_count": 81,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T13:11:34.677796"
}