[
  {
    "arxiv_id": "2405.16381v2",
    "title": "Trivialized Momentum Facilitates Diffusion Generative Modeling on Lie Groups",
    "authors": [
      "Yuchen Zhu",
      "Tianrong Chen",
      "Lingkai Kong",
      "Evangelos A. Theodorou",
      "Molei Tao"
    ],
    "abstract": "The generative modeling of data on manifolds is an important task, for which\ndiffusion models in flat spaces typically need nontrivial adaptations. This\narticle demonstrates how a technique called `trivialization' can transfer the\neffectiveness of diffusion models in Euclidean spaces to Lie groups. In\nparticular, an auxiliary momentum variable was algorithmically introduced to\nhelp transport the position variable between data distribution and a fixed,\neasy-to-sample distribution. Normally, this would incur further difficulty for\nmanifold data because momentum lives in a space that changes with the position.\nHowever, our trivialization technique creates a new momentum variable that\nstays in a simple fixed vector space. This design, together with a manifold\npreserving integrator, simplifies implementation and avoids inaccuracies\ncreated by approximations such as projections to tangent space and manifold,\nwhich were typically used in prior work, hence facilitating generation with\nhigh-fidelity and efficiency. The resulting method achieves state-of-the-art\nperformance on protein and RNA torsion angle generation and sophisticated torus\ndatasets. We also, arguably for the first time, tackle the generation of data\non high-dimensional Special Orthogonal and Unitary groups, the latter essential\nfor quantum problems. Code is available at\nhttps://github.com/yuchen-zhu-zyc/TDM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.16381v2",
    "published_date": "2024-05-25 23:53:07 UTC",
    "updated_date": "2025-02-12 00:48:57 UTC"
  },
  {
    "arxiv_id": "2405.16368v2",
    "title": "Qsco: A Quantum Scoring Module for Open-set Supervised Anomaly Detection",
    "authors": [
      "Yifeng Peng",
      "Xinyi Li",
      "Zhiding Liang",
      "Ying Wang"
    ],
    "abstract": "Open set anomaly detection (OSAD) is a crucial task that aims to identify\nabnormal patterns or behaviors in data sets, especially when the anomalies\nobserved during training do not represent all possible classes of anomalies.\nThe recent advances in quantum computing in handling complex data structures\nand improving machine learning models herald a paradigm shift in anomaly\ndetection methodologies. This study proposes a Quantum Scoring Module (Qsco),\nembedding quantum variational circuits into neural networks to enhance the\nmodel's processing capabilities in handling uncertainty and unlabeled data.\nExtensive experiments conducted across eight real-world anomaly detection\ndatasets demonstrate our model's superior performance in detecting anomalies\nacross varied settings and reveal that integrating quantum simulators does not\nresult in prohibitive time complexities. Our study validates the feasibility of\nquantum-enhanced anomaly detection methods in practical applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI-25)",
    "pdf_url": "http://arxiv.org/pdf/2405.16368v2",
    "published_date": "2024-05-25 22:37:43 UTC",
    "updated_date": "2024-12-16 18:11:07 UTC"
  },
  {
    "arxiv_id": "2405.16363v2",
    "title": "LLMs for User Interest Exploration in Large-scale Recommendation Systems",
    "authors": [
      "Jianling Wang",
      "Haokai Lu",
      "Yifan Liu",
      "He Ma",
      "Yueqi Wang",
      "Yang Gu",
      "Shuzhou Zhang",
      "Ningren Han",
      "Shuchao Bi",
      "Lexi Baugher",
      "Ed Chi",
      "Minmin Chen"
    ],
    "abstract": "Traditional recommendation systems are subject to a strong feedback loop by\nlearning from and reinforcing past user-item interactions, which in turn limits\nthe discovery of novel user interests. To address this, we introduce a hybrid\nhierarchical framework combining Large Language Models (LLMs) and classic\nrecommendation models for user interest exploration. The framework controls the\ninterfacing between the LLMs and the classic recommendation models through\n\"interest clusters\", the granularity of which can be explicitly determined by\nalgorithm designers. It recommends the next novel interests by first\nrepresenting \"interest clusters\" using language, and employs a fine-tuned LLM\nto generate novel interest descriptions that are strictly within these\npredefined clusters. At the low level, it grounds these generated interests to\nan item-level policy by restricting classic recommendation models, in this case\na transformer-based sequence recommender to return items that fall within the\nnovel clusters generated at the high level. We showcase the efficacy of this\napproach on an industrial-scale commercial platform serving billions of users.\nLive experiments show a significant increase in both exploration of novel\ninterests and overall user enjoyment of the platform.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16363v2",
    "published_date": "2024-05-25 21:57:36 UTC",
    "updated_date": "2024-06-07 18:06:20 UTC"
  },
  {
    "arxiv_id": "2405.16355v1",
    "title": "Navigating AI Fallibility: Examining People's Reactions and Perceptions of AI after Encountering Personality Misrepresentations",
    "authors": [
      "Qiaosi Wang",
      "Chidimma L. Anyi",
      "Vedant Das Swain",
      "Ashok K. Goel"
    ],
    "abstract": "Many hyper-personalized AI systems profile people's characteristics (e.g.,\npersonality traits) to provide personalized recommendations. These systems are\nincreasingly used to facilitate interactions among people, such as providing\nteammate recommendations. Despite improved accuracy, such systems are not\nimmune to errors when making inferences about people's most personal traits.\nThese errors manifested as AI misrepresentations. However, the repercussions of\nsuch AI misrepresentations are unclear, especially on people's reactions and\nperceptions of the AI. We present two studies to examine how people react and\nperceive the AI after encountering personality misrepresentations in\nAI-facilitated team matching in a higher education context. Through\nsemi-structured interviews (n=20) and a survey experiment (n=198), we pinpoint\nhow people's existing and newly acquired AI knowledge could shape their\nperceptions and reactions of the AI after encountering AI misrepresentations.\nSpecifically, we identified three rationales that people adopted through\nknowledge acquired from AI (mis)representations: AI works like a machine,\nhuman, and/or magic. These rationales are highly connected to people's\nreactions of over-trusting, rationalizing, and forgiving of AI\nmisrepresentations. Finally, we found that people's existing AI knowledge,\ni.e., AI literacy, could moderate people's changes in their trust in AI after\nencountering AI misrepresentations, but not changes in people's social\nperceptions of AI. We discuss the role of people's AI knowledge when facing AI\nfallibility and implications for designing responsible mitigation and repair\nstrategies.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.HC",
    "comment": "37 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.16355v1",
    "published_date": "2024-05-25 21:27:15 UTC",
    "updated_date": "2024-05-25 21:27:15 UTC"
  },
  {
    "arxiv_id": "2405.16350v3",
    "title": "A Second-Order Perspective on Model Compositionality and Incremental Learning",
    "authors": [
      "Angelo Porrello",
      "Lorenzo Bonicelli",
      "Pietro Buzzega",
      "Monica Millunzi",
      "Simone Calderara",
      "Rita Cucchiara"
    ],
    "abstract": "The fine-tuning of deep pre-trained models has revealed compositional\nproperties, with multiple specialized modules that can be arbitrarily composed\ninto a single, multi-task model. However, identifying the conditions that\npromote compositionality remains an open issue, with recent efforts\nconcentrating mainly on linearized networks. We conduct a theoretical study\nthat attempts to demystify compositionality in standard non-linear networks\nthrough the second-order Taylor approximation of the loss function. The\nproposed formulation highlights the importance of staying within the\npre-training basin to achieve composable modules. Moreover, it provides the\nbasis for two dual incremental training algorithms: the one from the\nperspective of multiple models trained individually, while the other aims to\noptimize the composed model as a whole. We probe their application in\nincremental classification tasks and highlight some valuable skills. In fact,\nthe pool of incrementally learned modules not only supports the creation of an\neffective multi-task model but also enables unlearning and specialization in\ncertain tasks. Code available at https://github.com/aimagelab/mammoth.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICLR 2025 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2405.16350v3",
    "published_date": "2024-05-25 20:56:54 UTC",
    "updated_date": "2025-02-28 19:08:43 UTC"
  },
  {
    "arxiv_id": "2405.16337v3",
    "title": "Learning to Reason via Program Generation, Emulation, and Search",
    "authors": [
      "Nathaniel Weir",
      "Muhammad Khalifa",
      "Linlu Qiu",
      "Orion Weller",
      "Peter Clark"
    ],
    "abstract": "Program synthesis with language models (LMs) has unlocked a large set of\nreasoning abilities; code-tuned LMs have proven adept at generating programs\nthat solve a wide variety of algorithmic symbolic manipulation tasks (e.g. word\nconcatenation). However, not all reasoning tasks are easily expressible as\ncode, e.g. tasks involving commonsense reasoning, moral decision-making, and\nsarcasm understanding. Our goal is to extend an LM's program synthesis skills\nto such tasks and evaluate the results via pseudo-programs, namely Python\nprograms where some leaf function calls are left undefined. To that end, we\npropose, Code Generation and Emulated EXecution (CoGEX). CoGEX works by (1)\ntraining LMs to generate pseudo-programs, (2) teaching them to emulate their\ngenerated program's execution, including those leaf functions, allowing the\nLM's knowledge to fill in the execution gaps; and (3) using them to search over\nmany programs to find an optimal one. To adapt the CoGEX model to a new task,\nwe introduce a method for performing program search to find a single program\nwhose pseudo-execution yields optimal performance when applied to all the\ninstances of a given dataset. We show that our approach yields large\nimprovements compared to standard in-context learning approaches on a battery\nof tasks, both algorithmic and soft reasoning. This result thus demonstrates\nthat code synthesis can be applied to a much broader class of problems than\npreviously considered. Our released dataset, fine-tuned models, and\nimplementation can be found at \\url{https://github.com/nweir127/CoGEX}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024 camera ready",
    "pdf_url": "http://arxiv.org/pdf/2405.16337v3",
    "published_date": "2024-05-25 19:40:50 UTC",
    "updated_date": "2024-11-03 22:44:20 UTC"
  },
  {
    "arxiv_id": "2405.16334v4",
    "title": "Devil's Advocate: Anticipatory Reflection for LLM Agents",
    "authors": [
      "Haoyu Wang",
      "Tao Li",
      "Zhiwei Deng",
      "Dan Roth",
      "Yang Li"
    ],
    "abstract": "In this work, we introduce a novel approach that equips LLM agents with\nintrospection, enhancing consistency and adaptability in solving complex tasks.\nOur approach prompts LLM agents to decompose a given task into manageable\nsubtasks (i.e., to make a plan), and to continuously introspect upon the\nsuitability and results of their actions. %; and when necessary, to explore\n``the road not taken.'' We implement a three-fold introspective intervention:\n1) anticipatory reflection on potential failures and alternative remedy before\naction execution, 2) post-action alignment with subtask objectives and\nbacktracking with remedy to ensure utmost effort in plan execution, and 3)\ncomprehensive review upon plan completion for future strategy refinement. By\ndeploying and experimenting with this methodology -- a zero-shot approach --\nwithin WebArena for practical tasks in web environments, our agent demonstrates\nsuperior performance with a success rate of 23.5% over existing zero-shot\nmethods by 3.5%. The experimental results suggest that our introspection-driven\napproach not only enhances the agent's ability to navigate unanticipated\nchallenges through a robust mechanism of plan execution, but also improves\nefficiency by reducing the number of trials and plan revisions by 45% needed to\nachieve a task.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.16334v4",
    "published_date": "2024-05-25 19:20:15 UTC",
    "updated_date": "2024-06-20 19:41:48 UTC"
  },
  {
    "arxiv_id": "2405.16325v3",
    "title": "SLoPe: Double-Pruned Sparse Plus Lazy Low-Rank Adapter Pretraining of LLMs",
    "authors": [
      "Mohammad Mozaffari",
      "Amir Yazdanbakhsh",
      "Zhao Zhang",
      "Maryam Mehri Dehnavi"
    ],
    "abstract": "We propose SLoPe, a Double-Pruned Sparse Plus Lazy Low-rank Adapter\nPretraining method for LLMs that improves the accuracy of sparse LLMs while\naccelerating their pretraining and inference and reducing their memory\nfootprint. Sparse pretraining of LLMs reduces the accuracy of the model, to\novercome this, prior work uses dense models during fine-tuning. SLoPe improves\nthe accuracy of sparsely pretrained models by adding low-rank adapters in the\nfinal 1% iterations of pretraining without adding significant overheads to the\nmodel pretraining and inference. In addition, SLoPe uses a double-pruned\nbackward pass formulation that prunes the transposed weight matrix using N:M\nsparsity structures to enable an accelerated sparse backward pass. SLoPe\naccelerates the training and inference of models with billions of parameters up\nto $1.25\\times$ and $1.54\\times$ respectively (OPT-33B and OPT-66B) while\nreducing their memory usage by up to $0.63\\times$ and $0.61\\times$ for training\nand inference respectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2405.16325v3",
    "published_date": "2024-05-25 18:43:05 UTC",
    "updated_date": "2025-01-25 22:24:04 UTC"
  },
  {
    "arxiv_id": "2405.17497v1",
    "title": "Secure Hierarchical Federated Learning in Vehicular Networks Using Dynamic Client Selection and Anomaly Detection",
    "authors": [
      "M. Saeid HaghighiFard",
      "Sinem Coleri"
    ],
    "abstract": "Hierarchical Federated Learning (HFL) faces the significant challenge of\nadversarial or unreliable vehicles in vehicular networks, which can compromise\nthe model's integrity through misleading updates. Addressing this, our study\nintroduces a novel framework that integrates dynamic vehicle selection and\nrobust anomaly detection mechanisms, aiming to optimize participant selection\nand mitigate risks associated with malicious contributions. Our approach\ninvolves a comprehensive vehicle reliability assessment, considering historical\naccuracy, contribution frequency, and anomaly records. An anomaly detection\nalgorithm is utilized to identify anomalous behavior by analyzing the cosine\nsimilarity of local or model parameters during the federated learning (FL)\nprocess. These anomaly records are then registered and combined with past\nperformance for accuracy and contribution frequency to identify the most\nsuitable vehicles for each learning round. Dynamic client selection and anomaly\ndetection algorithms are deployed at different levels, including cluster heads\n(CHs), cluster members (CMs), and the Evolving Packet Core (EPC), to detect and\nfilter out spurious updates. Through simulation-based performance evaluation,\nour proposed algorithm demonstrates remarkable resilience even under intense\nattack conditions. Even in the worst-case scenarios, it achieves convergence\ntimes at $63$\\% as effective as those in scenarios without any attacks.\nConversely, in scenarios without utilizing our proposed algorithm, there is a\nhigh likelihood of non-convergence in the FL process.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17497v1",
    "published_date": "2024-05-25 18:31:20 UTC",
    "updated_date": "2024-05-25 18:31:20 UTC"
  },
  {
    "arxiv_id": "2405.16312v2",
    "title": "Time-SSM: Simplifying and Unifying State Space Models for Time Series Forecasting",
    "authors": [
      "Jiaxi Hu",
      "Disen Lan",
      "Ziyu Zhou",
      "Qingsong Wen",
      "Yuxuan Liang"
    ],
    "abstract": "State Space Models (SSMs) have emerged as a potent tool in sequence modeling\ntasks in recent years. These models approximate continuous systems using a set\nof basis functions and discretize them to handle input data, making them\nwell-suited for modeling time series data collected at specific frequencies\nfrom continuous systems. Despite its potential, the application of SSMs in time\nseries forecasting remains underexplored, with most existing models treating\nSSMs as a black box for capturing temporal or channel dependencies. To address\nthis gap, this paper proposes a novel theoretical framework termed Dynamic\nSpectral Operator, offering more intuitive and general guidance on applying\nSSMs to time series data. Building upon our theory, we introduce Time-SSM, a\nnovel SSM-based foundation model with only one-seventh of the parameters\ncompared to Mamba. Various experiments validate both our theoretical framework\nand the superior performance of Time-SSM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2402.11463",
    "pdf_url": "http://arxiv.org/pdf/2405.16312v2",
    "published_date": "2024-05-25 17:42:40 UTC",
    "updated_date": "2024-07-14 14:40:20 UTC"
  },
  {
    "arxiv_id": "2405.16310v1",
    "title": "An Empirical Exploration of Trust Dynamics in LLM Supply Chains",
    "authors": [
      "Agathe Balayn",
      "Mireia Yurrita",
      "Fanny Rancourt",
      "Fabio Casati",
      "Ujwal Gadiraju"
    ],
    "abstract": "With the widespread proliferation of AI systems, trust in AI is an important\nand timely topic to navigate. Researchers so far have largely employed a myopic\nview of this relationship. In particular, a limited number of relevant trustors\n(e.g., end-users) and trustees (i.e., AI systems) have been considered, and\nempirical explorations have remained in laboratory settings, potentially\noverlooking factors that impact human-AI relationships in the real world. In\nthis paper, we argue for broadening the scope of studies addressing `trust in\nAI' by accounting for the complex and dynamic supply chains that AI systems\nresult from. AI supply chains entail various technical artifacts that diverse\nindividuals, organizations, and stakeholders interact with, in a variety of\nways. We present insights from an in-situ, empirical study of LLM supply\nchains. Our work reveals additional types of trustors and trustees and new\nfactors impacting their trust relationships. These relationships were found to\nbe central to the development and adoption of LLMs, but they can also be the\nterrain for uncalibrated trust and reliance on untrustworthy LLMs. Based on\nthese findings, we discuss the implications for research on `trust in AI'. We\nhighlight new research opportunities and challenges concerning the appropriate\nstudy of inter-actor relationships across the supply chain and the development\nof calibrated trust and meaningful reliance behaviors. We also question the\nmeaning of building trust in the LLM supply chain.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Paper accepted at the TREW workshop co-located with CHI'24",
    "pdf_url": "http://arxiv.org/pdf/2405.16310v1",
    "published_date": "2024-05-25 17:37:56 UTC",
    "updated_date": "2024-05-25 17:37:56 UTC"
  },
  {
    "arxiv_id": "2405.20773v2",
    "title": "Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Character",
    "authors": [
      "Siyuan Ma",
      "Weidi Luo",
      "Yu Wang",
      "Xiaogeng Liu"
    ],
    "abstract": "With the advent and widespread deployment of Multimodal Large Language Models\n(MLLMs), ensuring their safety has become increasingly critical. To achieve\nthis objective, it requires us to proactively discover the vulnerability of\nMLLMs by exploring the attack methods. Thus, structure-based jailbreak attacks,\nwhere harmful semantic content is embedded within images, have been proposed to\nmislead the models. However, previous structure-based jailbreak methods mainly\nfocus on transforming the format of malicious queries, such as converting\nharmful content into images through typography, which lacks sufficient\njailbreak effectiveness and generalizability. To address these limitations, we\nfirst introduce the concept of \"Role-play\" into MLLM jailbreak attacks and\npropose a novel and effective method called Visual Role-play (VRP).\nSpecifically, VRP leverages Large Language Models to generate detailed\ndescriptions of high-risk characters and create corresponding images based on\nthe descriptions. When paired with benign role-play instruction texts, these\nhigh-risk character images effectively mislead MLLMs into generating malicious\nresponses by enacting characters with negative attributes. We further extend\nour VRP method into a universal setup to demonstrate its generalizability.\nExtensive experiments on popular benchmarks show that VRP outperforms the\nstrongest baseline, Query relevant and FigStep, by an average Attack Success\nRate (ASR) margin of 14.3% across all models.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.20773v2",
    "published_date": "2024-05-25 17:17:18 UTC",
    "updated_date": "2024-06-12 07:13:48 UTC"
  },
  {
    "arxiv_id": "2405.16304v2",
    "title": "Federated Unsupervised Domain Generalization using Global and Local Alignment of Gradients",
    "authors": [
      "Farhad Pourpanah",
      "Mahdiyar Molahasani",
      "Milad Soltany",
      "Michael Greenspan",
      "Ali Etemad"
    ],
    "abstract": "We address the problem of federated domain generalization in an unsupervised\nsetting for the first time. We first theoretically establish a connection\nbetween domain shift and alignment of gradients in unsupervised federated\nlearning and show that aligning the gradients at both client and server levels\ncan facilitate the generalization of the model to new (target) domains.\nBuilding on this insight, we propose a novel method named FedGaLA, which\nperforms gradient alignment at the client level to encourage clients to learn\ndomain-invariant features, as well as global gradient alignment at the server\nto obtain a more generalized aggregated model. To empirically evaluate our\nmethod, we perform various experiments on four commonly used multi-domain\ndatasets, PACS, OfficeHome, DomainNet, and TerraInc. The results demonstrate\nthe effectiveness of our method which outperforms comparable baselines.\nAblation and sensitivity studies demonstrate the impact of different components\nand parameters in our approach. The source code is available at:\nhttps://github.com/MahdiyarMM/FedGaLA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to AAAI 2025, 16 pages, 3 figure",
    "pdf_url": "http://arxiv.org/pdf/2405.16304v2",
    "published_date": "2024-05-25 17:12:54 UTC",
    "updated_date": "2025-01-02 23:28:10 UTC"
  },
  {
    "arxiv_id": "2407.13059v2",
    "title": "Prioritizing High-Consequence Biological Capabilities in Evaluations of Artificial Intelligence Models",
    "authors": [
      "Jaspreet Pannu",
      "Doni Bloomfield",
      "Alex Zhu",
      "Robert MacKnight",
      "Gabe Gomes",
      "Anita Cicero",
      "Thomas V. Inglesby"
    ],
    "abstract": "As a result of rapidly accelerating AI capabilities, over the past year,\nnational governments and multinational bodies have announced efforts to address\nsafety, security and ethics issues related to AI models. One high priority\namong these efforts is the mitigation of misuse of AI models. Many biologists\nhave for decades sought to reduce the risks of scientific research that could\nlead, through accident or misuse, to high-consequence disease outbreaks.\nScientists have carefully considered what types of life sciences research have\nthe potential for both benefit and risk (dual-use), especially as scientific\nadvances have accelerated our ability to engineer organisms and create novel\nvariants of pathogens. Here we describe how previous experience and study by\nscientists and policy professionals of dual-use capabilities in the life\nsciences can inform risk evaluations of AI models with biological capabilities.\nWe argue that AI model evaluations should prioritize addressing\nhigh-consequence risks (those that could cause large-scale harm to the public,\nsuch as pandemics), and that these risks should be evaluated prior to model\ndeployment so as to allow potential biosafety and/or biosecurity measures.\nScientists' experience with identifying and mitigating dual-use biological\nrisks can help inform new approaches to evaluating biological AI models.\nIdentifying which AI capabilities post the greatest biosecurity and biosafety\nconcerns is necessary in order to establish targeted AI safety evaluation\nmethods, secure these tools against accident and misuse, and avoid impeding\nimmense potential benefits.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CY",
    "comment": "9 pages, 1 figure, 3 tables, 1 box",
    "pdf_url": "http://arxiv.org/pdf/2407.13059v2",
    "published_date": "2024-05-25 16:29:17 UTC",
    "updated_date": "2024-07-23 01:08:25 UTC"
  },
  {
    "arxiv_id": "2405.16282v5",
    "title": "Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models",
    "authors": [
      "Abhishek Kumar",
      "Robert Morabito",
      "Sanzhar Umbet",
      "Jad Kabbara",
      "Ali Emami"
    ],
    "abstract": "As the use of Large Language Models (LLMs) becomes more widespread,\nunderstanding their self-evaluation of confidence in generated responses\nbecomes increasingly important as it is integral to the reliability of the\noutput of these models. We introduce the concept of Confidence-Probability\nAlignment, that connects an LLM's internal confidence, quantified by token\nprobabilities, to the confidence conveyed in the model's response when\nexplicitly asked about its certainty. Using various datasets and prompting\ntechniques that encourage model introspection, we probe the alignment between\nmodels' internal and expressed confidence. These techniques encompass using\nstructured evaluation scales to rate confidence, including answer options when\nprompting, and eliciting the model's confidence level for outputs it does not\nrecognize as its own. Notably, among the models analyzed, OpenAI's GPT-4 showed\nthe strongest confidence-probability alignment, with an average Spearman's\n$\\hat{\\rho}$ of 0.42, across a wide range of tasks. Our work contributes to the\nongoing efforts to facilitate risk assessment in the application of LLMs and to\nfurther our understanding of model trustworthiness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages (excluding references), accepted to ACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2405.16282v5",
    "published_date": "2024-05-25 15:42:04 UTC",
    "updated_date": "2024-06-15 22:18:06 UTC"
  },
  {
    "arxiv_id": "2406.00033v1",
    "title": "Retrieval-Augmented Conversational Recommendation with Prompt-based Semi-Structured Natural Language State Tracking",
    "authors": [
      "Sara Kemper",
      "Justin Cui",
      "Kai Dicarlantonio",
      "Kathy Lin",
      "Danjie Tang",
      "Anton Korikov",
      "Scott Sanner"
    ],
    "abstract": "Conversational recommendation (ConvRec) systems must understand rich and\ndiverse natural language (NL) expressions of user preferences and intents,\noften communicated in an indirect manner (e.g., \"I'm watching my weight\"). Such\ncomplex utterances make retrieving relevant items challenging, especially if\nonly using often incomplete or out-of-date metadata. Fortunately, many domains\nfeature rich item reviews that cover standard metadata categories and offer\ncomplex opinions that might match a user's interests (e.g., \"classy joint for a\ndate\"). However, only recently have large language models (LLMs) let us unlock\nthe commonsense connections between user preference utterances and complex\nlanguage in user-generated reviews. Further, LLMs enable novel paradigms for\nsemi-structured dialogue state tracking, complex intent and preference\nunderstanding, and generating recommendations, explanations, and question\nanswers. We thus introduce a novel technology RA-Rec, a Retrieval-Augmented,\nLLM-driven dialogue state tracking system for ConvRec, showcased with a video,\nopen source GitHub repository, and interactive Google Colab notebook.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00033v1",
    "published_date": "2024-05-25 15:41:26 UTC",
    "updated_date": "2024-05-25 15:41:26 UTC"
  },
  {
    "arxiv_id": "2405.16279v2",
    "title": "AI-Assisted Detector Design for the EIC (AID(2)E)",
    "authors": [
      "M. Diefenthaler",
      "C. Fanelli",
      "L. O. Gerlach",
      "W. Guan",
      "T. Horn",
      "A. Jentsch",
      "M. Lin",
      "K. Nagai",
      "H. Nayak",
      "C. Pecar",
      "K. Suresh",
      "A. Vossen",
      "T. Wang",
      "T. Wenaus"
    ],
    "abstract": "Artificial Intelligence is poised to transform the design of complex,\nlarge-scale detectors like the ePIC at the future Electron Ion Collider.\nFeaturing a central detector with additional detecting systems in the far\nforward and far backward regions, the ePIC experiment incorporates numerous\ndesign parameters and objectives, including performance, physics reach, and\ncost, constrained by mechanical and geometric limits. This project aims to\ndevelop a scalable, distributed AI-assisted detector design for the EIC\n(AID(2)E), employing state-of-the-art multiobjective optimization to tackle\ncomplex designs. Supported by the ePIC software stack and using Geant4\nsimulations, our approach benefits from transparent parameterization and\nadvanced AI features. The workflow leverages the PanDA and iDDS systems, used\nin major experiments such as ATLAS at CERN LHC, the Rubin Observatory, and\nsPHENIX at RHIC, to manage the compute intensive demands of ePIC detector\nsimulations. Tailored enhancements to the PanDA system focus on usability,\nscalability, automation, and monitoring. Ultimately, this project aims to\nestablish a robust design capability, apply a distributed AI-assisted workflow\nto the ePIC detector, and extend its applications to the design of the second\ndetector (Detector-2) in the EIC, as well as to calibration and alignment\ntasks. Additionally, we are developing advanced data science tools to\nefficiently navigate the complex, multidimensional trade-offs identified\nthrough this optimization process.",
    "categories": [
      "physics.ins-det",
      "cs.AI"
    ],
    "primary_category": "physics.ins-det",
    "comment": "11 pages, 4 figures, AI4EIC 2023 proceeding",
    "pdf_url": "http://arxiv.org/pdf/2405.16279v2",
    "published_date": "2024-05-25 15:33:44 UTC",
    "updated_date": "2024-05-28 16:31:59 UTC"
  },
  {
    "arxiv_id": "2405.16277v3",
    "title": "Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge",
    "authors": [
      "Brendan Park",
      "Madeline Janecek",
      "Naser Ezzati-Jivan",
      "Yifeng Li",
      "Ali Emami"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable success in tasks\nlike the Winograd Schema Challenge (WSC), showcasing advanced textual\ncommon-sense reasoning. However, applying this reasoning to multimodal domains,\nwhere understanding text and images together is essential, remains a\nsubstantial challenge. To address this, we introduce WinoVis, a novel dataset\nspecifically designed to probe text-to-image models on pronoun disambiguation\nwithin multimodal contexts. Utilizing GPT-4 for prompt generation and Diffusion\nAttentive Attribution Maps (DAAM) for heatmap analysis, we propose a novel\nevaluation framework that isolates the models' ability in pronoun\ndisambiguation from other visual processing challenges. Evaluation of\nsuccessive model versions reveals that, despite incremental advancements,\nStable Diffusion 2.0 achieves a precision of 56.7% on WinoVis, only marginally\nsurpassing random guessing. Further error analysis identifies important areas\nfor future research aimed at advancing text-to-image models in their ability to\ninterpret and interact with the complex visual world.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages (excluding references), accepted to ACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2405.16277v3",
    "published_date": "2024-05-25 15:28:22 UTC",
    "updated_date": "2024-06-03 16:42:55 UTC"
  },
  {
    "arxiv_id": "2405.16263v1",
    "title": "Assessing Image Inpainting via Re-Inpainting Self-Consistency Evaluation",
    "authors": [
      "Tianyi Chen",
      "Jianfu Zhang",
      "Yan Hong",
      "Yiyi Zhang",
      "Liqing Zhang"
    ],
    "abstract": "Image inpainting, the task of reconstructing missing segments in corrupted\nimages using available data, faces challenges in ensuring consistency and\nfidelity, especially under information-scarce conditions. Traditional\nevaluation methods, heavily dependent on the existence of unmasked reference\nimages, inherently favor certain inpainting outcomes, introducing biases.\nAddressing this issue, we introduce an innovative evaluation paradigm that\nutilizes a self-supervised metric based on multiple re-inpainting passes. This\napproach, diverging from conventional reliance on direct comparisons in pixel\nor feature space with original images, emphasizes the principle of\nself-consistency to enable the exploration of various viable inpainting\nsolutions, effectively reducing biases. Our extensive experiments across\nnumerous benchmarks validate the alignment of our evaluation method with human\njudgment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16263v1",
    "published_date": "2024-05-25 15:05:08 UTC",
    "updated_date": "2024-05-25 15:05:08 UTC"
  },
  {
    "arxiv_id": "2405.16259v1",
    "title": "Front-propagation Algorithm: Explainable AI Technique for Extracting Linear Function Approximations from Neural Networks",
    "authors": [
      "Javier Viaña"
    ],
    "abstract": "This paper introduces the front-propagation algorithm, a novel eXplainable AI\n(XAI) technique designed to elucidate the decision-making logic of deep neural\nnetworks. Unlike other popular explainability algorithms such as Integrated\nGradients or Shapley Values, the proposed algorithm is able to extract an\naccurate and consistent linear function explanation of the network in a single\nforward pass of the trained model. This nuance sets apart the time complexity\nof the front-propagation as it could be running real-time and in parallel with\ndeployed models. We packaged this algorithm in a software called\n$\\texttt{front-prop}$ and we demonstrate its efficacy in providing accurate\nlinear functions with three different neural network architectures trained on\npublicly available benchmark datasets.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "68T07"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 6 figures. Accepted for publication in: Barnabas Bede,\n  Kelly Cohen, and Vladik Kreinovich (eds.), Proceedings of the NAFIPS\n  International Conference on Fuzzy Systems, Soft Computing, and Explainable\n  AI. NAFIPS'2024, South Padre Island, Texas, May 27-29, 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16259v1",
    "published_date": "2024-05-25 14:50:23 UTC",
    "updated_date": "2024-05-25 14:50:23 UTC"
  },
  {
    "arxiv_id": "2405.16258v1",
    "title": "USD: Unsupervised Soft Contrastive Learning for Fault Detection in Multivariate Time Series",
    "authors": [
      "Hong Liu",
      "Xiuxiu Qiu",
      "Yiming Shi",
      "Zelin Zang"
    ],
    "abstract": "Unsupervised fault detection in multivariate time series is critical for\nmaintaining the integrity and efficiency of complex systems, with current\nmethodologies largely focusing on statistical and machine learning techniques.\nHowever, these approaches often rest on the assumption that data distributions\nconform to Gaussian models, overlooking the diversity of patterns that can\nmanifest in both normal and abnormal states, thereby diminishing discriminative\nperformance. Our innovation addresses this limitation by introducing a\ncombination of data augmentation and soft contrastive learning, specifically\ndesigned to capture the multifaceted nature of state behaviors more accurately.\nThe data augmentation process enriches the dataset with varied representations\nof normal states, while soft contrastive learning fine-tunes the model's\nsensitivity to the subtle differences between normal and abnormal patterns,\nenabling it to recognize a broader spectrum of anomalies. This dual strategy\nsignificantly boosts the model's ability to distinguish between normal and\nabnormal states, leading to a marked improvement in fault detection performance\nacross multiple datasets and settings, thereby setting a new benchmark for\nunsupervised fault detection in complex systems. The code of our method is\navailable at \\url{https://github.com/zangzelin/code_USD.git}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 7 figures, under review",
    "pdf_url": "http://arxiv.org/pdf/2405.16258v1",
    "published_date": "2024-05-25 14:48:04 UTC",
    "updated_date": "2024-05-25 14:48:04 UTC"
  },
  {
    "arxiv_id": "2405.16256v2",
    "title": "HETHUB: A Distributed Training System with Heterogeneous Cluster for Large-Scale Models",
    "authors": [
      "Si Xu",
      "Zixiao Huang",
      "Yan Zeng",
      "Shengen Yan",
      "Xuefei Ning",
      "Quanlu Zhang",
      "Haolin Ye",
      "Sipei Gu",
      "Chunsheng Shui",
      "Zhezheng Lin",
      "Hao Zhang",
      "Sheng Wang",
      "Guohao Dai",
      "Yu Wang"
    ],
    "abstract": "Training large-scale models relies on a vast number of computing resources.\nFor example, training the GPT-4 model (1.8 trillion parameters) requires 25000\nA100 GPUs . It is a challenge to build a large-scale cluster with one type of\nGPU-accelerator. Using multiple types of GPU-accelerators to construct a\nlarge-scale cluster is an effective way to solve the problem of insufficient\nhomogeneous GPU-accelerators. However, the existing distributed training\nsystems for large-scale models only support homogeneous GPU-accelerators, not\nsupport heterogeneous GPU-accelerators. To address the problem, this paper\nproposes a distributed training system with hybrid parallelism, HETHUB, for\nlarge-scale models, which supports heterogeneous cluster, including AMD, Nvidia\nGPU and other types of GPU-accelerators . It introduces a distributed unified\ncommunicator to realize the communication between heterogeneous\nGPU-accelerators, a distributed performance predictor, and an automatic\nparallel planner to develop and train models efficiently with heterogeneous\nGPU-accelerators. Compared to the distributed training system with homogeneous\nGPU-accelerators, our system can support six combinations of heterogeneous\nGPU-accelerators. We train the Llama-140B model on a heterogeneous cluster with\n768 GPU-accelerators(128 AMD and 640 GPU-accelerator A). The experiment results\nshow that the optimal performance of our system in the heterogeneous cluster\nhas achieved up to 97.49% of the theoretical upper bound performance.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16256v2",
    "published_date": "2024-05-25 14:36:35 UTC",
    "updated_date": "2024-08-09 02:38:07 UTC"
  },
  {
    "arxiv_id": "2405.16247v4",
    "title": "AutoManual: Constructing Instruction Manuals by LLM Agents via Interactive Environmental Learning",
    "authors": [
      "Minghao Chen",
      "Yihang Li",
      "Yanting Yang",
      "Shiyu Yu",
      "Binbin Lin",
      "Xiaofei He"
    ],
    "abstract": "Large Language Models (LLM) based agents have shown promise in autonomously\ncompleting tasks across various domains, e.g., robotics, games, and web\nnavigation. However, these agents typically require elaborate design and expert\nprompts to solve tasks in specific domains, which limits their adaptability. We\nintroduce AutoManual, a framework enabling LLM agents to autonomously build\ntheir understanding through interaction and adapt to new environments.\nAutoManual categorizes environmental knowledge into diverse rules and optimizes\nthem in an online fashion by two agents: 1) The Planner codes actionable plans\nbased on current rules for interacting with the environment. 2) The Builder\nupdates the rules through a well-structured rule system that facilitates online\nrule management and essential detail retention. To mitigate hallucinations in\nmanaging rules, we introduce a *case-conditioned prompting* strategy for the\nBuilder. Finally, the Formulator agent compiles these rules into a\ncomprehensive manual. The self-generated manual can not only improve the\nadaptability but also guide the planning of smaller LLMs while being\nhuman-readable. Given only one simple demonstration, AutoManual significantly\nimproves task success rates, achieving 97.4\\% with GPT-4-turbo and 86.2\\% with\nGPT-3.5-turbo on ALFWorld benchmark tasks. The code is available at\nhttps://github.com/minghchen/automanual.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16247v4",
    "published_date": "2024-05-25 14:11:44 UTC",
    "updated_date": "2024-11-10 12:54:35 UTC"
  },
  {
    "arxiv_id": "2405.16241v1",
    "title": "FastQuery: Communication-efficient Embedding Table Query for Private LLM Inference",
    "authors": [
      "Chenqi Lin",
      "Tianshi Xu",
      "Zebin Yang",
      "Runsheng Wang",
      "Ru Huang",
      "Meng Li"
    ],
    "abstract": "With the fast evolution of large language models (LLMs), privacy concerns\nwith user queries arise as they may contain sensitive information. Private\ninference based on homomorphic encryption (HE) has been proposed to protect\nuser query privacy. However, a private embedding table query has to be\nformulated as a HE-based matrix-vector multiplication problem and suffers from\nenormous computation and communication overhead. We observe the overhead mainly\ncomes from the neglect of 1) the one-hot nature of user queries and 2) the\nrobustness of the embedding table to low bit-width quantization noise. Hence,\nin this paper, we propose a private embedding table query optimization\nframework, dubbed FastQuery. FastQuery features a communication-aware embedding\ntable quantization algorithm and a one-hot-aware dense packing algorithm to\nsimultaneously reduce both the computation and communication costs. Compared to\nprior-art HE-based frameworks, e.g., Cheetah, Iron, and Bumblebee, FastQuery\nachieves more than $4.3\\times$, $2.7\\times$, $1.3\\times$ latency reduction,\nrespectively and more than $75.7\\times$, $60.2\\times$, $20.2\\times$\ncommunication reduction, respectively, on both LLAMA-7B and LLAMA-30B.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "6 pages, DAC2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16241v1",
    "published_date": "2024-05-25 13:58:45 UTC",
    "updated_date": "2024-05-25 13:58:45 UTC"
  },
  {
    "arxiv_id": "2405.16237v1",
    "title": "N-BVH: Neural ray queries with bounding volume hierarchies",
    "authors": [
      "Philippe Weier",
      "Alexander Rath",
      "Élie Michel",
      "Iliyan Georgiev",
      "Philipp Slusallek",
      "Tamy Boubekeur"
    ],
    "abstract": "Neural representations have shown spectacular ability to compress complex\nsignals in a fraction of the raw data size. In 3D computer graphics, the bulk\nof a scene's memory usage is due to polygons and textures, making them ideal\ncandidates for neural compression. Here, the main challenge lies in finding\ngood trade-offs between efficient compression and cheap inference while\nminimizing training time. In the context of rendering, we adopt a ray-centric\napproach to this problem and devise N-BVH, a neural compression architecture\ndesigned to answer arbitrary ray queries in 3D. Our compact model is learned\nfrom the input geometry and substituted for it whenever a ray intersection is\nqueried by a path-tracing engine. While prior neural compression methods have\nfocused on point queries, ours proposes neural ray queries that integrate\nseamlessly into standard ray-tracing pipelines. At the core of our method, we\nemploy an adaptive BVH-driven probing scheme to optimize the parameters of a\nmulti-resolution hash grid, focusing its neural capacity on the sparse 3D\noccupancy swept by the original surfaces. As a result, our N-BVH can serve\naccurate ray queries from a representation that is more than an order of\nmagnitude more compact, providing faithful approximations of visibility, depth,\nand appearance attributes. The flexibility of our method allows us to combine\nand overlap neural and non-neural entities within the same 3D scene and extends\nto appearance level of detail.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.16237v1",
    "published_date": "2024-05-25 13:54:34 UTC",
    "updated_date": "2024-05-25 13:54:34 UTC"
  },
  {
    "arxiv_id": "2405.16225v2",
    "title": "Local Causal Structure Learning in the Presence of Latent Variables",
    "authors": [
      "Feng Xie",
      "Zheng Li",
      "Peng Wu",
      "Yan Zeng",
      "Chunchen Liu",
      "Zhi Geng"
    ],
    "abstract": "Discovering causal relationships from observational data, particularly in the\npresence of latent variables, poses a challenging problem. While current local\nstructure learning methods have proven effective and efficient when the focus\nlies solely on the local relationships of a target variable, they operate under\nthe assumption of causal sufficiency. This assumption implies that all the\ncommon causes of the measured variables are observed, leaving no room for\nlatent variables. Such a premise can be easily violated in various real-world\napplications, resulting in inaccurate structures that may adversely impact\ndownstream tasks. In light of this, our paper delves into the primary\ninvestigation of locally identifying potential parents and children of a target\nfrom observational data that may include latent variables. Specifically, we\nharness the causal information from m-separation and V-structures to derive\ntheoretical consistency results, effectively bridging the gap between global\nand local structure learning. Together with the newly developed stop rules, we\npresent a principled method for determining whether a variable is a direct\ncause or effect of a target. Further, we theoretically demonstrate the\ncorrectness of our approach under the standard causal Markov and faithfulness\nconditions, with infinite samples. Experimental results on both synthetic and\nreal-world data validate the effectiveness and efficiency of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16225v2",
    "published_date": "2024-05-25 13:31:05 UTC",
    "updated_date": "2024-06-06 07:44:36 UTC"
  },
  {
    "arxiv_id": "2405.16224v1",
    "title": "Negative as Positive: Enhancing Out-of-distribution Generalization for Graph Contrastive Learning",
    "authors": [
      "Zixu Wang",
      "Bingbing Xu",
      "Yige Yuan",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "abstract": "Graph contrastive learning (GCL), standing as the dominant paradigm in the\nrealm of graph pre-training, has yielded considerable progress. Nonetheless,\nits capacity for out-of-distribution (OOD) generalization has been relatively\nunderexplored. In this work, we point out that the traditional optimization of\nInfoNCE in GCL restricts the cross-domain pairs only to be negative samples,\nwhich inevitably enlarges the distribution gap between different domains. This\nviolates the requirement of domain invariance under OOD scenario and\nconsequently impairs the model's OOD generalization performance. To address\nthis issue, we propose a novel strategy \"Negative as Positive\", where the most\nsemantically similar cross-domain negative pairs are treated as positive during\nGCL. Our experimental results, spanning a wide array of datasets, confirm that\nthis method substantially improves the OOD generalization performance of GCL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 5 figures, In Proceedings of the 47th International ACM\n  SIGIR Conference on Research and Development in Information Retrieval (SIGIR\n  '24), July 14-18, 2024, Washington, DC, USA",
    "pdf_url": "http://arxiv.org/pdf/2405.16224v1",
    "published_date": "2024-05-25 13:29:31 UTC",
    "updated_date": "2024-05-25 13:29:31 UTC"
  },
  {
    "arxiv_id": "2405.20771v3",
    "title": "Towards Black-Box Membership Inference Attack for Diffusion Models",
    "authors": [
      "Jingwei Li",
      "Jing Dong",
      "Tianxing He",
      "Jingzhao Zhang"
    ],
    "abstract": "Given the rising popularity of AI-generated art and the associated copyright\nconcerns, identifying whether an artwork was used to train a diffusion model is\nan important research topic. The work approaches this problem from the\nmembership inference attack (MIA) perspective. We first identify the limitation\nof applying existing MIA methods for proprietary diffusion models: the required\naccess of internal U-nets. To address the above problem, we introduce a novel\nmembership inference attack method that uses only the image-to-image variation\nAPI and operates without access to the model's internal U-net. Our method is\nbased on the intuition that the model can more easily obtain an unbiased noise\nprediction estimate for images from the training set. By applying the API\nmultiple times to the target image, averaging the outputs, and comparing the\nresult to the original image, our approach can classify whether a sample was\npart of the training set. We validate our method using DDIM and Stable\nDiffusion setups and further extend both our approach and existing algorithms\nto the Diffusion Transformer architecture. Our experimental results\nconsistently outperform previous methods.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.20771v3",
    "published_date": "2024-05-25 12:47:58 UTC",
    "updated_date": "2024-11-27 03:48:21 UTC"
  },
  {
    "arxiv_id": "2405.16205v1",
    "title": "GeneAgent: Self-verification Language Agent for Gene Set Knowledge Discovery using Domain Databases",
    "authors": [
      "Zhizheng Wang",
      "Qiao Jin",
      "Chih-Hsuan Wei",
      "Shubo Tian",
      "Po-Ting Lai",
      "Qingqing Zhu",
      "Chi-Ping Day",
      "Christina Ross",
      "Zhiyong Lu"
    ],
    "abstract": "Gene set knowledge discovery is essential for advancing human functional\ngenomics. Recent studies have shown promising performance by harnessing the\npower of Large Language Models (LLMs) on this task. Nonetheless, their results\nare subject to several limitations common in LLMs such as hallucinations. In\nresponse, we present GeneAgent, a first-of-its-kind language agent featuring\nself-verification capability. It autonomously interacts with various biological\ndatabases and leverages relevant domain knowledge to improve accuracy and\nreduce hallucination occurrences. Benchmarking on 1,106 gene sets from\ndifferent sources, GeneAgent consistently outperforms standard GPT-4 by a\nsignificant margin. Moreover, a detailed manual review confirms the\neffectiveness of the self-verification module in minimizing hallucinations and\ngenerating more reliable analytical narratives. To demonstrate its practical\nutility, we apply GeneAgent to seven novel gene sets derived from mouse B2905\nmelanoma cell lines, with expert evaluations showing that GeneAgent offers\nnovel insights into gene functions and subsequently expedites knowledge\ndiscovery.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages with 10 figures and/or tables",
    "pdf_url": "http://arxiv.org/pdf/2405.16205v1",
    "published_date": "2024-05-25 12:35:15 UTC",
    "updated_date": "2024-05-25 12:35:15 UTC"
  },
  {
    "arxiv_id": "2405.16204v2",
    "title": "VOODOO XP: Expressive One-Shot Head Reenactment for VR Telepresence",
    "authors": [
      "Phong Tran",
      "Egor Zakharov",
      "Long-Nhat Ho",
      "Liwen Hu",
      "Adilbek Karmanov",
      "Aviral Agarwal",
      "McLean Goldwhite",
      "Ariana Bermudez Venegas",
      "Anh Tuan Tran",
      "Hao Li"
    ],
    "abstract": "We introduce VOODOO XP: a 3D-aware one-shot head reenactment method that can\ngenerate highly expressive facial expressions from any input driver video and a\nsingle 2D portrait. Our solution is real-time, view-consistent, and can be\ninstantly used without calibration or fine-tuning. We demonstrate our solution\non a monocular video setting and an end-to-end VR telepresence system for\ntwo-way communication. Compared to 2D head reenactment methods, 3D-aware\napproaches aim to preserve the identity of the subject and ensure\nview-consistent facial geometry for novel camera poses, which makes them\nsuitable for immersive applications. While various facial disentanglement\ntechniques have been introduced, cutting-edge 3D-aware neural reenactment\ntechniques still lack expressiveness and fail to reproduce complex and\nfine-scale facial expressions. We present a novel cross-reenactment\narchitecture that directly transfers the driver's facial expressions to\ntransformer blocks of the input source's 3D lifting module. We show that highly\neffective disentanglement is possible using an innovative multi-stage\nself-supervision approach, which is based on a coarse-to-fine strategy,\ncombined with an explicit face neutralization and 3D lifted frontalization\nduring its initial training stage. We further integrate our novel head\nreenactment solution into an accessible high-fidelity VR telepresence system,\nwhere any person can instantly build a personalized neural head avatar from any\nphoto and bring it to life using the headset. We demonstrate state-of-the-art\nperformance in terms of expressiveness and likeness preservation on a large set\nof diverse subjects and capture conditions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16204v2",
    "published_date": "2024-05-25 12:33:40 UTC",
    "updated_date": "2024-05-28 09:22:34 UTC"
  },
  {
    "arxiv_id": "2405.16195v3",
    "title": "Adaptive $Q$-Network: On-the-fly Target Selection for Deep Reinforcement Learning",
    "authors": [
      "Théo Vincent",
      "Fabian Wahren",
      "Jan Peters",
      "Boris Belousov",
      "Carlo D'Eramo"
    ],
    "abstract": "Deep Reinforcement Learning (RL) is well known for being highly sensitive to\nhyperparameters, requiring practitioners substantial efforts to optimize them\nfor the problem at hand. This also limits the applicability of RL in real-world\nscenarios. In recent years, the field of automated Reinforcement Learning\n(AutoRL) has grown in popularity by trying to address this issue. However,\nthese approaches typically hinge on additional samples to select\nwell-performing hyperparameters, hindering sample-efficiency and practicality.\nFurthermore, most AutoRL methods are heavily based on already existing AutoML\nmethods, which were originally developed neglecting the additional challenges\ninherent to RL due to its non-stationarities. In this work, we propose a new\napproach for AutoRL, called Adaptive $Q$-Network (AdaQN), that is tailored to\nRL to take into account the non-stationarity of the optimization procedure\nwithout requiring additional samples. AdaQN learns several $Q$-functions, each\none trained with different hyperparameters, which are updated online using the\n$Q$-function with the smallest approximation error as a shared target. Our\nselection scheme simultaneously handles different hyperparameters while coping\nwith the non-stationarity induced by the RL optimization procedure and being\northogonal to any critic-based RL algorithm. We demonstrate that AdaQN is\ntheoretically sound and empirically validate it in MuJoCo control problems and\nAtari $2600$ games, showing benefits in sample-efficiency, overall performance,\nrobustness to stochasticity and training stability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR https://iclr.cc/virtual/2025/poster/28508",
    "pdf_url": "http://arxiv.org/pdf/2405.16195v3",
    "published_date": "2024-05-25 11:57:43 UTC",
    "updated_date": "2025-03-03 11:39:53 UTC"
  },
  {
    "arxiv_id": "2405.16194v4",
    "title": "Diffusion-Reward Adversarial Imitation Learning",
    "authors": [
      "Chun-Mao Lai",
      "Hsiang-Chun Wang",
      "Ping-Chun Hsieh",
      "Yu-Chiang Frank Wang",
      "Min-Hung Chen",
      "Shao-Hua Sun"
    ],
    "abstract": "Imitation learning aims to learn a policy from observing expert\ndemonstrations without access to reward signals from environments. Generative\nadversarial imitation learning (GAIL) formulates imitation learning as\nadversarial learning, employing a generator policy learning to imitate expert\nbehaviors and discriminator learning to distinguish the expert demonstrations\nfrom agent trajectories. Despite its encouraging results, GAIL training is\noften brittle and unstable. Inspired by the recent dominance of diffusion\nmodels in generative modeling, we propose Diffusion-Reward Adversarial\nImitation Learning (DRAIL), which integrates a diffusion model into GAIL,\naiming to yield more robust and smoother rewards for policy learning.\nSpecifically, we propose a diffusion discriminative classifier to construct an\nenhanced discriminator, and design diffusion rewards based on the classifier's\noutput for policy learning. Extensive experiments are conducted in navigation,\nmanipulation, and locomotion, verifying DRAIL's effectiveness compared to prior\nimitation learning methods. Moreover, additional experimental results\ndemonstrate the generalizability and data efficiency of DRAIL. Visualized\nlearned reward functions of GAIL and DRAIL suggest that DRAIL can produce more\nrobust and smoother rewards. Project page:\nhttps://nturobotlearninglab.github.io/DRAIL/",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024. Project page:\n  https://nturobotlearninglab.github.io/DRAIL/",
    "pdf_url": "http://arxiv.org/pdf/2405.16194v4",
    "published_date": "2024-05-25 11:53:23 UTC",
    "updated_date": "2024-11-26 02:47:01 UTC"
  },
  {
    "arxiv_id": "2405.16191v1",
    "title": "Rocket Landing Control with Grid Fins and Path-following using MPC",
    "authors": [
      "Junhao Yu",
      "Jiarun Wei"
    ],
    "abstract": "In this project, we attempt to optimize a landing trajectory of a rocket. The\ngoal is to minimize the total fuel consumption during the landing process using\ndifferent techniques. Once the optimal and feasible trajectory is generated\nusing batch approach, we attempt to follow the path using a Model Predictive\nControl (MPC) based algorithm, called Trajectory Optimizing Path following\nEstimation from Demonstration (TOPED), in order to generalize to similar\ninitial states and models, where we introduce a novel cost function for the MPC\nto solve. We further show that TOPED can follow a demonstration trajectory well\nin practice under model mismatch and different initial states.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16191v1",
    "published_date": "2024-05-25 11:42:29 UTC",
    "updated_date": "2024-05-25 11:42:29 UTC"
  },
  {
    "arxiv_id": "2405.16185v1",
    "title": "Differentiable Cluster Graph Neural Network",
    "authors": [
      "Yanfei Dong",
      "Mohammed Haroon Dupty",
      "Lambert Deng",
      "Zhuanghua Liu",
      "Yong Liang Goh",
      "Wee Sun Lee"
    ],
    "abstract": "Graph Neural Networks often struggle with long-range information propagation\nand in the presence of heterophilous neighborhoods. We address both challenges\nwith a unified framework that incorporates a clustering inductive bias into the\nmessage passing mechanism, using additional cluster-nodes. Central to our\napproach is the formulation of an optimal transport based implicit clustering\nobjective function. However, the algorithm for solving the implicit objective\nfunction needs to be differentiable to enable end-to-end learning of the GNN.\nTo facilitate this, we adopt an entropy regularized objective function and\npropose an iterative optimization process, alternating between solving for the\ncluster assignments and updating the node/cluster-node embeddings. Notably, our\nderived closed-form optimization steps are themselves simple yet elegant\nmessage passing steps operating seamlessly on a bipartite graph of nodes and\ncluster-nodes. Our clustering-based approach can effectively capture both local\nand global information, demonstrated by extensive experiments on both\nheterophilous and homophilous datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16185v1",
    "published_date": "2024-05-25 11:23:39 UTC",
    "updated_date": "2024-05-25 11:23:39 UTC"
  },
  {
    "arxiv_id": "2405.16184v1",
    "title": "Safe Deep Model-Based Reinforcement Learning with Lyapunov Functions",
    "authors": [
      "Harry Zhang"
    ],
    "abstract": "Model-based Reinforcement Learning (MBRL) has shown many desirable properties\nfor intelligent control tasks. However, satisfying safety and stability\nconstraints during training and rollout remains an open question. We propose a\nnew Model-based RL framework to enable efficient policy learning with unknown\ndynamics based on learning model predictive control (LMPC) framework with\nmathematically provable guarantees of stability. We introduce and explore a\nnovel method for adding safety constraints for model-based RL during training\nand policy learning. The new stability-augmented framework consists of a\nneural-network-based learner that learns to construct a Lyapunov function, and\na model-based RL agent to consistently complete the tasks while satisfying\nuser-specified constraints given only sub-optimal demonstrations and\nsparse-cost feedback. We demonstrate the capability of the proposed framework\nthrough simulated experiments.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16184v1",
    "published_date": "2024-05-25 11:21:12 UTC",
    "updated_date": "2024-05-25 11:21:12 UTC"
  },
  {
    "arxiv_id": "2405.16183v1",
    "title": "Graph Neural PDE Solvers with Conservation and Similarity-Equivariance",
    "authors": [
      "Masanobu Horie",
      "Naoto Mitsume"
    ],
    "abstract": "Utilizing machine learning to address partial differential equations (PDEs)\npresents significant challenges due to the diversity of spatial domains and\ntheir corresponding state configurations, which complicates the task of\nencompassing all potential scenarios through data-driven methodologies alone.\nMoreover, there are legitimate concerns regarding the generalization and\nreliability of such approaches, as they often overlook inherent physical\nconstraints. In response to these challenges, this study introduces a novel\nmachine-learning architecture that is highly generalizable and adheres to\nconservation laws and physical symmetries, thereby ensuring greater\nreliability. The foundation of this architecture is graph neural networks\n(GNNs), which are adept at accommodating a variety of shapes and forms.\nAdditionally, we explore the parallels between GNNs and traditional numerical\nsolvers, facilitating a seamless integration of conservative principles and\nsymmetries into machine learning models. Our findings from experiments\ndemonstrate that the model's inclusion of physical laws significantly enhances\nits generalizability, i.e., no significant accuracy degradation for unseen\nspatial domains while other models degrade. The code is available at\nhttps://github.com/yellowshippo/fluxgnn-icml2024.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16183v1",
    "published_date": "2024-05-25 11:18:27 UTC",
    "updated_date": "2024-05-25 11:18:27 UTC"
  },
  {
    "arxiv_id": "2405.16164v3",
    "title": "Acquiring Better Load Estimates by Combining Anomaly and Change Point Detection in Power Grid Time-series Measurements",
    "authors": [
      "Roel Bouman",
      "Linda Schmeitz",
      "Luco Buise",
      "Jacco Heres",
      "Yuliya Shapovalova",
      "Tom Heskes"
    ],
    "abstract": "In this paper we present novel methodology for automatic anomaly and switch\nevent filtering to improve load estimation in power grid systems. By leveraging\nunsupervised methods with supervised optimization, our approach prioritizes\ninterpretability while ensuring robust and generalizable performance on unseen\ndata. Through experimentation, a combination of binary segmentation for change\npoint detection and statistical process control for anomaly detection emerges\nas the most effective strategy, specifically when ensembled in a novel\nsequential manner. Results indicate the clear wasted potential when filtering\nis not applied. The automatic load estimation is also fairly accurate, with\napproximately 90% of estimates falling within a 10% error margin, with only a\nsingle significant failure in both the minimum and maximum load estimates\nacross 60 measurements in the test set. Our methodology's interpretability\nmakes it particularly suitable for critical infrastructure planning, thereby\nenhancing decision-making processes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "All code can be found at: https://github.com/RoelBouman/StormPhase2",
    "pdf_url": "http://arxiv.org/pdf/2405.16164v3",
    "published_date": "2024-05-25 10:15:51 UTC",
    "updated_date": "2024-10-23 14:24:50 UTC"
  },
  {
    "arxiv_id": "2405.16153v4",
    "title": "DefSent+: Improving sentence embeddings of language models by projecting definition sentences into a quasi-isotropic or isotropic vector space of unlimited dictionary entries",
    "authors": [
      "Xiaodong Liu"
    ],
    "abstract": "This paper presents a significant improvement on the previous conference\npaper known as DefSent. The prior study seeks to improve sentence embeddings of\nlanguage models by projecting definition sentences into the vector space of\ndictionary entries. We discover that this approach is not fully explored due to\nthe methodological limitation of using word embeddings of language models to\nrepresent dictionary entries. This leads to two hindrances. First, dictionary\nentries are constrained by the single-word vocabulary, and thus cannot be fully\nexploited. Second, semantic representations of language models are known to be\nanisotropic, but pre-processing word embeddings for DefSent is not allowed\nbecause its weight is frozen during training and tied to the prediction layer.\nIn this paper, we propose a novel method to progressively build entry\nembeddings not subject to the limitations. As a result, definition sentences\ncan be projected into a quasi-isotropic or isotropic vector space of unlimited\ndictionary entries, so that sentence embeddings of noticeably better quality\nare attainable. We abbreviate our approach as DefSent+ (a plus version of\nDefSent), involving the following strengths: 1) the task performance on\nmeasuring sentence similarities is significantly improved compared to DefSent;\n2) when DefSent+ is used to further train data-augmented models like SIMCSE,\nSNCSE, and SynCSE, state-of-the-art performance on measuring sentence\nsimilarities can be achieved among the approaches without using manually\nlabeled datasets; 3) DefSent+ is also competitive in feature-based transfer for\nNLP downstream tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16153v4",
    "published_date": "2024-05-25 09:43:38 UTC",
    "updated_date": "2024-09-29 05:38:24 UTC"
  },
  {
    "arxiv_id": "2405.16144v1",
    "title": "GreenCOD: A Green Camouflaged Object Detection Method",
    "authors": [
      "Hong-Shuo Chen",
      "Yao Zhu",
      "Suya You",
      "Azad M. Madni",
      "C. -C. Jay Kuo"
    ],
    "abstract": "We introduce GreenCOD, a green method for detecting camouflaged objects,\ndistinct in its avoidance of backpropagation techniques. GreenCOD leverages\ngradient boosting and deep features extracted from pre-trained Deep Neural\nNetworks (DNNs). Traditional camouflaged object detection (COD) approaches\noften rely on complex deep neural network architectures, seeking performance\nimprovements through backpropagation-based fine-tuning. However, such methods\nare typically computationally demanding and exhibit only marginal performance\nvariations across different models. This raises the question of whether\neffective training can be achieved without backpropagation. Addressing this,\nour work proposes a new paradigm that utilizes gradient boosting for COD. This\napproach significantly simplifies the model design, resulting in a system that\nrequires fewer parameters and operations and maintains high performance\ncompared to state-of-the-art deep learning models. Remarkably, our models are\ntrained without backpropagation and achieve the best performance with fewer\nthan 20G Multiply-Accumulate Operations (MACs). This new, more efficient\nparadigm opens avenues for further exploration in green, backpropagation-free\nmodel training.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16144v1",
    "published_date": "2024-05-25 09:25:27 UTC",
    "updated_date": "2024-05-25 09:25:27 UTC"
  },
  {
    "arxiv_id": "2405.16141v4",
    "title": "AIGB: Generative Auto-bidding via Conditional Diffusion Modeling",
    "authors": [
      "Jiayan Guo",
      "Yusen Huo",
      "Zhilin Zhang",
      "Tianyu Wang",
      "Chuan Yu",
      "Jian Xu",
      "Yan Zhang",
      "Bo Zheng"
    ],
    "abstract": "Auto-bidding plays a crucial role in facilitating online advertising by\nautomatically providing bids for advertisers. Reinforcement learning (RL) has\ngained popularity for auto-bidding. However, most current RL auto-bidding\nmethods are modeled through the Markovian Decision Process (MDP), which assumes\nthe Markovian state transition. This assumption restricts the ability to\nperform in long horizon scenarios and makes the model unstable when dealing\nwith highly random online advertising environments. To tackle this issue, this\npaper introduces AI-Generated Bidding (AIGB), a novel paradigm for auto-bidding\nthrough generative modeling. In this paradigm, we propose DiffBid, a\nconditional diffusion modeling approach for bid generation. DiffBid directly\nmodels the correlation between the return and the entire trajectory,\neffectively avoiding error propagation across time steps in long horizons.\nAdditionally, DiffBid offers a versatile approach for generating trajectories\nthat maximize given targets while adhering to specific constraints. Extensive\nexperiments conducted on the real-world dataset and online A/B test on Alibaba\nadvertising platform demonstrate the effectiveness of DiffBid, achieving 2.81%\nincrease in GMV and 3.36% increase in ROI.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16141v4",
    "published_date": "2024-05-25 09:21:43 UTC",
    "updated_date": "2024-10-08 07:02:01 UTC"
  },
  {
    "arxiv_id": "2405.16136v1",
    "title": "C3LLM: Conditional Multimodal Content Generation Using Large Language Models",
    "authors": [
      "Zixuan Wang",
      "Qinkai Duan",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "abstract": "We introduce C3LLM (Conditioned-on-Three-Modalities Large Language Models), a\nnovel framework combining three tasks of video-to-audio, audio-to-text, and\ntext-to-audio together. C3LLM adapts the Large Language Model (LLM) structure\nas a bridge for aligning different modalities, synthesizing the given\nconditional information, and making multimodal generation in a discrete manner.\nOur contributions are as follows. First, we adapt a hierarchical structure for\naudio generation tasks with pre-trained audio codebooks. Specifically, we train\nthe LLM to generate audio semantic tokens from the given conditions, and\nfurther use a non-autoregressive transformer to generate different levels of\nacoustic tokens in layers to better enhance the fidelity of the generated\naudio. Second, based on the intuition that LLMs were originally designed for\ndiscrete tasks with the next-word prediction method, we use the discrete\nrepresentation for audio generation and compress their semantic meanings into\nacoustic tokens, similar to adding \"acoustic vocabulary\" to LLM. Third, our\nmethod combines the previous tasks of audio understanding, video-to-audio\ngeneration, and text-to-audio generation together into one unified model,\nproviding more versatility in an end-to-end fashion. Our C3LLM achieves\nimproved results through various automated evaluation metrics, providing better\nsemantic alignment compared to previous methods.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16136v1",
    "published_date": "2024-05-25 09:10:12 UTC",
    "updated_date": "2024-05-25 09:10:12 UTC"
  },
  {
    "arxiv_id": "2405.16133v3",
    "title": "Uncovering LLM-Generated Code: A Zero-Shot Synthetic Code Detector via Code Rewriting",
    "authors": [
      "Tong Ye",
      "Yangkai Du",
      "Tengfei Ma",
      "Lingfei Wu",
      "Xuhong Zhang",
      "Shouling Ji",
      "Wenhai Wang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in\ngenerating code. However, the misuse of LLM-generated (synthetic) code has\nraised concerns in both educational and industrial contexts, underscoring the\nurgent need for synthetic code detectors. Existing methods for detecting\nsynthetic content are primarily designed for general text and struggle with\ncode due to the unique grammatical structure of programming languages and the\npresence of numerous ''low-entropy'' tokens. Building on this, our work\nproposes a novel zero-shot synthetic code detector based on the similarity\nbetween the original code and its LLM-rewritten variants. Our method is based\non the observation that differences between LLM-rewritten and original code\ntend to be smaller when the original code is synthetic. We utilize\nself-supervised contrastive learning to train a code similarity model and\nevaluate our approach on two synthetic code detection benchmarks. Our results\ndemonstrate a significant improvement over existing SOTA synthetic content\ndetectors, with AUROC scores increasing by 20.5% on the APPS benchmark and\n29.1% on the MBPP benchmark.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by AAAI 2025; previously submitted to EMNLP 2023",
    "pdf_url": "http://arxiv.org/pdf/2405.16133v3",
    "published_date": "2024-05-25 08:57:28 UTC",
    "updated_date": "2024-12-16 15:42:38 UTC"
  },
  {
    "arxiv_id": "2405.16128v1",
    "title": "How Well Do Deep Learning Models Capture Human Concepts? The Case of the Typicality Effect",
    "authors": [
      "Siddhartha K. Vemuri",
      "Raj Sanjay Shah",
      "Sashank Varma"
    ],
    "abstract": "How well do representations learned by ML models align with those of humans?\nHere, we consider concept representations learned by deep learning models and\nevaluate whether they show a fundamental behavioral signature of human\nconcepts, the typicality effect. This is the finding that people judge some\ninstances (e.g., robin) of a category (e.g., Bird) to be more typical than\nothers (e.g., penguin). Recent research looking for human-like typicality\neffects in language and vision models has focused on models of a single\nmodality, tested only a small number of concepts, and found only modest\ncorrelations with human typicality ratings. The current study expands this\nbehavioral evaluation of models by considering a broader range of language (N =\n8) and vision (N = 10) model architectures. It also evaluates whether the\ncombined typicality predictions of vision + language model pairs, as well as a\nmultimodal CLIP-based model, are better aligned with human typicality judgments\nthan those of models of either modality alone. Finally, it evaluates the models\nacross a broader range of concepts (N = 27) than prior studies. There were\nthree important findings. First, language models better align with human\ntypicality judgments than vision models. Second, combined language and vision\nmodels (e.g., AlexNet + MiniLM) better predict the human typicality data than\nthe best-performing language model (i.e., MiniLM) or vision model (i.e.,\nViT-Huge) alone. Third, multimodal models (i.e., CLIP ViT) show promise for\nexplaining human typicality judgments. These results advance the\nstate-of-the-art in aligning the conceptual representations of ML models and\nhumans. A methodological contribution is the creation of a new image set for\ntesting the conceptual alignment of vision models.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear at CogSci 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16128v1",
    "published_date": "2024-05-25 08:38:30 UTC",
    "updated_date": "2024-05-25 08:38:30 UTC"
  },
  {
    "arxiv_id": "2405.16123v1",
    "title": "Retro-prob: Retrosynthetic Planning Based on a Probabilistic Model",
    "authors": [
      "Chengyang Tian",
      "Yangpeng Zhang",
      "Yang Liu"
    ],
    "abstract": "Retrosynthesis is a fundamental but challenging task in organic chemistry,\nwith broad applications in fields such as drug design and synthesis. Given a\ntarget molecule, the goal of retrosynthesis is to find out a series of\nreactions which could be assembled into a synthetic route which starts from\npurchasable molecules and ends at the target molecule. The uncertainty of\nreactions used in retrosynthetic planning, which is caused by hallucinations of\nbackward models, has recently been noticed. In this paper we propose a succinct\nprobabilistic model to describe such uncertainty. Based on the model, we\npropose a new retrosynthesis planning algorithm called retro-prob to maximize\nthe successful synthesis probability of target molecules, which acquires high\nefficiency by utilizing the chain rule of derivatives. Experiments on the\nParoutes benchmark show that retro-prob outperforms previous algorithms, retro*\nand retro-fallback, both in speed and in the quality of synthesis plans.",
    "categories": [
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16123v1",
    "published_date": "2024-05-25 08:23:40 UTC",
    "updated_date": "2024-05-25 08:23:40 UTC"
  },
  {
    "arxiv_id": "2405.16122v2",
    "title": "Prompt Optimization with EASE? Efficient Ordering-aware Automated Selection of Exemplars",
    "authors": [
      "Zhaoxuan Wu",
      "Xiaoqiang Lin",
      "Zhongxiang Dai",
      "Wenyang Hu",
      "Yao Shu",
      "See-Kiong Ng",
      "Patrick Jaillet",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "Large language models (LLMs) have shown impressive capabilities in real-world\napplications. The capability of in-context learning (ICL) allows us to adapt an\nLLM to downstream tasks by including input-label exemplars in the prompt\nwithout model fine-tuning. However, the quality of these exemplars in the\nprompt greatly impacts performance, highlighting the need for an effective\nautomated exemplar selection method. Recent studies have explored\nretrieval-based approaches to select exemplars tailored to individual test\nqueries, which can be undesirable due to extra test-time computation and an\nincreased risk of data exposure. Moreover, existing methods fail to adequately\naccount for the impact of exemplar ordering on the performance. On the other\nhand, the impact of the instruction, another essential component in the prompt\ngiven to the LLM, is often overlooked in existing exemplar selection methods.\nTo address these challenges, we propose a novel method named EASE, which\nleverages the hidden embedding from a pre-trained language model to represent\nordered sets of exemplars and uses a neural bandit algorithm to optimize the\nsets of exemplars while accounting for exemplar ordering. Our EASE can\nefficiently find an ordered set of exemplars that performs well for all test\nqueries from a given task, thereby eliminating test-time computation.\nImportantly, EASE can be readily extended to jointly optimize both the\nexemplars and the instruction. Through extensive empirical evaluations\n(including novel tasks), we demonstrate the superiority of EASE over existing\nmethods, and reveal practical insights about the impact of exemplar selection\non ICL, which may be of independent interest. Our code is available at\nhttps://github.com/ZhaoxuanWu/EASE-Prompt-Optimization.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 1 figure, 35 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.16122v2",
    "published_date": "2024-05-25 08:23:05 UTC",
    "updated_date": "2024-10-29 11:17:44 UTC"
  },
  {
    "arxiv_id": "2405.16114v1",
    "title": "Multi-scale Quaternion CNN and BiGRU with Cross Self-attention Feature Fusion for Fault Diagnosis of Bearing",
    "authors": [
      "Huanbai Liu",
      "Fanlong Zhang",
      "Yin Tan",
      "Lian Huang",
      "Yan Li",
      "Guoheng Huang",
      "Shenghong Luo",
      "An Zeng"
    ],
    "abstract": "In recent years, deep learning has led to significant advances in bearing\nfault diagnosis (FD). Most techniques aim to achieve greater accuracy. However,\nthey are sensitive to noise and lack robustness, resulting in insufficient\ndomain adaptation and anti-noise ability. The comparison of studies reveals\nthat giving equal attention to all features does not differentiate their\nsignificance. In this work, we propose a novel FD model by integrating\nmulti-scale quaternion convolutional neural network (MQCNN), bidirectional\ngated recurrent unit (BiGRU), and cross self-attention feature fusion (CSAFF).\nWe have developed innovative designs in two modules, namely MQCNN and CSAFF.\nFirstly, MQCNN applies quaternion convolution to multi-scale architecture for\nthe first time, aiming to extract the rich hidden features of the original\nsignal from multiple scales. Then, the extracted multi-scale information is\ninput into CSAFF for feature fusion, where CSAFF innovatively incorporates\ncross self-attention mechanism to enhance discriminative interaction\nrepresentation within features. Finally, BiGRU captures temporal dependencies\nwhile a softmax layer is employed for fault classification, achieving accurate\nFD. To assess the efficacy of our approach, we experiment on three public\ndatasets (CWRU, MFPT, and Ottawa) and compare it with other excellent methods.\nThe results confirm its state-of-the-art, which the average accuracies can\nachieve up to 99.99%, 100%, and 99.21% on CWRU, MFPT, and Ottawa datasets.\nMoreover, we perform practical tests and ablation experiments to validate the\nefficacy and robustness of the proposed approach. Code is available at\nhttps://github.com/mubai011/MQCCAF.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16114v1",
    "published_date": "2024-05-25 07:55:02 UTC",
    "updated_date": "2024-05-25 07:55:02 UTC"
  },
  {
    "arxiv_id": "2406.01604v2",
    "title": "An Empirical Study of Excitation and Aggregation Design Adaptions in CLIP4Clip for Video-Text Retrieval",
    "authors": [
      "Xiaolun Jing",
      "Genke Yang",
      "Jian Chu"
    ],
    "abstract": "CLIP4Clip model transferred from the CLIP has been the de-factor standard to\nsolve the video clip retrieval task from frame-level input, triggering the\nsurge of CLIP4Clip-based models in the video-text retrieval domain. In this\nwork, we rethink the inherent limitation of widely-used mean pooling operation\nin the frame features aggregation and investigate the adaptions of excitation\nand aggregation design for discriminative video representation generation. We\npresent a novel excitationand-aggregation design, including (1) The excitation\nmodule is available for capturing non-mutuallyexclusive relationships among\nframe features and achieving frame-wise features recalibration, and (2) The\naggregation module is applied to learn exclusiveness used for frame\nrepresentations aggregation. Similarly, we employ the cascade of sequential\nmodule and aggregation design to generate discriminative video representation\nin the sequential type. Besides, we adopt the excitation design in the tight\ntype to obtain representative frame features for multi-modal interaction. The\nproposed modules are evaluated on three benchmark datasets of MSR-VTT,\nActivityNet and DiDeMo, achieving MSR-VTT (43.9 R@1), ActivityNet (44.1 R@1)\nand DiDeMo (31.0 R@1). They outperform the CLIP4Clip results by +1.2% (+0.5%),\n+4.5% (+1.9%) and +9.5% (+2.7%) relative (absolute) improvements, demonstrating\nthe superiority of our proposed excitation and aggregation designs. We hope our\nwork will serve as an alternative for frame representations aggregation and\nfacilitate future research.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.IR",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.01604v2",
    "published_date": "2024-05-25 07:45:10 UTC",
    "updated_date": "2024-06-08 05:49:24 UTC"
  },
  {
    "arxiv_id": "2405.16105v1",
    "title": "MambaLLIE: Implicit Retinex-Aware Low Light Enhancement with Global-then-Local State Space",
    "authors": [
      "Jiangwei Weng",
      "Zhiqiang Yan",
      "Ying Tai",
      "Jianjun Qian",
      "Jian Yang",
      "Jun Li"
    ],
    "abstract": "Recent advances in low light image enhancement have been dominated by\nRetinex-based learning framework, leveraging convolutional neural networks\n(CNNs) and Transformers. However, the vanilla Retinex theory primarily\naddresses global illumination degradation and neglects local issues such as\nnoise and blur in dark conditions. Moreover, CNNs and Transformers struggle to\ncapture global degradation due to their limited receptive fields. While state\nspace models (SSMs) have shown promise in the long-sequence modeling, they face\nchallenges in combining local invariants and global context in visual data. In\nthis paper, we introduce MambaLLIE, an implicit Retinex-aware low light\nenhancer featuring a global-then-local state space design. We first propose a\nLocal-Enhanced State Space Module (LESSM) that incorporates an augmented local\nbias within a 2D selective scan mechanism, enhancing the original SSMs by\npreserving local 2D dependency. Additionally, an Implicit Retinex-aware\nSelective Kernel module (IRSK) dynamically selects features using\nspatially-varying operations, adapting to varying inputs through an adaptive\nkernel selection process. Our Global-then-Local State Space Block (GLSSB)\nintegrates LESSM and IRSK with LayerNorm as its core. This design enables\nMambaLLIE to achieve comprehensive global long-range modeling and flexible\nlocal feature aggregation. Extensive experiments demonstrate that MambaLLIE\nsignificantly outperforms state-of-the-art CNN and Transformer-based methods.\nProject Page: https://mamballie.github.io/anon/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16105v1",
    "published_date": "2024-05-25 07:31:49 UTC",
    "updated_date": "2024-05-25 07:31:49 UTC"
  },
  {
    "arxiv_id": "2406.00032v2",
    "title": "Paths of A Million People: Extracting Life Trajectories from Wikipedia",
    "authors": [
      "Ying Zhang",
      "Xiaofeng Li",
      "Zhaoyang Liu",
      "Haipeng Zhang"
    ],
    "abstract": "The life trajectories of notable people have been studied to pinpoint the\ntimes and places of significant events such as birth, death, education,\nmarriage, competition, work, speeches, scientific discoveries, artistic\nachievements, and battles. Understanding how these individuals interact with\nothers provides valuable insights for broader research into human dynamics.\nHowever, the scarcity of trajectory data in terms of volume, density, and\ninter-person interactions, limits relevant studies from being comprehensive and\ninteractive. We mine millions of biography pages from Wikipedia and tackle the\ngeneralization problem stemming from the variety and heterogeneity of the\ntrajectory descriptions. Our ensemble model COSMOS, which combines the idea of\nsemi-supervised learning and contrastive learning, achieves an F1 score of\n85.95%. For this task, we also create a hand-curated dataset,\nWikiLifeTrajectory, consisting of 8,852 (person, time, location) triplets as\nground truth. Besides, we perform an empirical analysis on the trajectories of\n8,272 historians to demonstrate the validity of the extracted results. To\nfacilitate the research on trajectory extractions and help the analytical\nstudies to construct grand narratives, we make our code, the million-level\nextracted trajectories, and the WikiLifeTrajectory dataset publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICWSM 2025. 15 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.00032v2",
    "published_date": "2024-05-25 06:57:33 UTC",
    "updated_date": "2024-07-21 06:52:40 UTC"
  },
  {
    "arxiv_id": "2405.16082v1",
    "title": "Uncertainty Measurement of Deep Learning System based on the Convex Hull of Training Sets",
    "authors": [
      "Hyekyoung Hwang",
      "Jitae Shin"
    ],
    "abstract": "Deep Learning (DL) has made remarkable achievements in computer vision and\nadopted in safety critical domains such as medical imaging or autonomous drive.\nThus, it is necessary to understand the uncertainty of the model to effectively\nreduce accidents and losses due to misjudgment of the Deep Neural Networks\n(DNN). This can start by efficiently selecting data that could potentially\nmalfunction to the model. Traditionally, data collection and labeling have been\ndone manually, but recently test data selection methods have emerged that focus\non capturing samples that are not relevant to what the model had been learned.\nThey're selected based on the activation pattern of neurons in DNN, entropy\nminimization based on softmax output of the DL. However, these methods cannot\nquantitatively analyze the extent to which unseen samples are extrapolated from\nthe training data. Therefore, we propose To-hull Uncertainty and Closure Ratio,\nwhich measures an uncertainty of trained model based on the convex hull of\ntraining data. It can observe the positional relation between the convex hull\nof the learned data and an unseen sample and infer how extrapolate the sample\nis from the convex hull. To evaluate the proposed method, we conduct empirical\nstudies on popular datasets and DNN models, compared to state-of-the art test\nselection metrics. As a result of the experiment, the proposed To-hull\nUncertainty is effective in finding samples with unusual patterns (e.g.\nadversarial attack) compared to the existing test selection metric.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.16082v1",
    "published_date": "2024-05-25 06:25:24 UTC",
    "updated_date": "2024-05-25 06:25:24 UTC"
  },
  {
    "arxiv_id": "2405.16075v2",
    "title": "Continuous Temporal Domain Generalization",
    "authors": [
      "Zekun Cai",
      "Guangji Bai",
      "Renhe Jiang",
      "Xuan Song",
      "Liang Zhao"
    ],
    "abstract": "Temporal Domain Generalization (TDG) addresses the challenge of training\npredictive models under temporally varying data distributions. Traditional TDG\napproaches typically focus on domain data collected at fixed, discrete time\nintervals, which limits their capability to capture the inherent dynamics\nwithin continuous-evolving and irregularly-observed temporal domains. To\novercome this, this work formalizes the concept of Continuous Temporal Domain\nGeneralization (CTDG), where domain data are derived from continuous times and\nare collected at arbitrary times. CTDG tackles critical challenges including:\n1) Characterizing the continuous dynamics of both data and models, 2) Learning\ncomplex high-dimensional nonlinear dynamics, and 3) Optimizing and controlling\nthe generalization across continuous temporal domains. To address them, we\npropose a Koopman operator-driven continuous temporal domain generalization\n(Koodos) framework. We formulate the problem within a continuous dynamic system\nand leverage the Koopman theory to learn the underlying dynamics; the framework\nis further enhanced with a comprehensive optimization strategy equipped with\nanalysis and control driven by prior knowledge of the dynamics patterns.\nExtensive experiments demonstrate the effectiveness and efficiency of our\napproach. The code can be found at: https://github.com/Zekun-Cai/Koodos.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16075v2",
    "published_date": "2024-05-25 05:52:04 UTC",
    "updated_date": "2024-10-29 09:32:52 UTC"
  },
  {
    "arxiv_id": "2405.16072v4",
    "title": "SynthAI: A Multi Agent Generative AI Framework for Automated Modular HLS Design Generation",
    "authors": [
      "Seyed Arash Sheikholeslam",
      "Andre Ivanov"
    ],
    "abstract": "In this paper, we introduce SynthAI, a new method for the automated creation\nof High-Level Synthesis (HLS) designs. SynthAI integrates ReAct agents,\nChain-of-Thought (CoT) prompting, web search technologies, and the\nRetrieval-Augmented Generation (RAG) framework within a structured decision\ngraph. This innovative approach enables the systematic decomposition of complex\nhardware design tasks into multiple stages and smaller, manageable modules. As\na result, SynthAI produces synthesizable designs that closely adhere to\nuser-specified design objectives and functional requirements. We further\nvalidate the capabilities of SynthAI through several case studies, highlighting\nits proficiency in generating complex, multi-module logic designs from a single\ninitial prompt. The SynthAI code is provided via the following repo:\n\\url{https://github.com/sarashs/FPGA_AGI}",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This work is in progress and we will be updating it",
    "pdf_url": "http://arxiv.org/pdf/2405.16072v4",
    "published_date": "2024-05-25 05:45:55 UTC",
    "updated_date": "2024-09-23 14:38:16 UTC"
  },
  {
    "arxiv_id": "2405.17492v2",
    "title": "StatWhy: Formal Verification Tool for Statistical Hypothesis Testing Programs",
    "authors": [
      "Yusuke Kawamoto",
      "Kentaro Kobayashi",
      "Kohei Suenaga"
    ],
    "abstract": "Statistical methods have been widely misused and misinterpreted in various\nscientific fields, raising significant concerns about the integrity of\nscientific research. To mitigate this problem, we propose a new method for\nformally specifying and automatically verifying the correctness of statistical\nprograms. In this method, programmers are required to annotate the source code\nof the statistical programs with the requirements for these methods. Through\nthis annotation, they are reminded to check the requirements for statistical\nmethods, including those that cannot be formally verified, such as the\ndistribution of the unknown true population. Our software tool StatWhy\nautomatically checks whether programmers have properly specified the\nrequirements for the statistical methods, thereby identifying any missing\nrequirements that need to be addressed. This tool is implemented using the Why3\nplatform to verify the correctness of OCaml programs that conduct statistical\nhypothesis testing. We demonstrate how StatWhy can be used to avoid common\nerrors in various popular statistical hypothesis testing programs.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17492v2",
    "published_date": "2024-05-25 05:07:33 UTC",
    "updated_date": "2024-11-01 16:16:45 UTC"
  },
  {
    "arxiv_id": "2405.16051v1",
    "title": "A Bi-Objective Approach to Last-Mile Delivery Routing Considering Driver Preferences",
    "authors": [
      "Juan Pablo Mesa",
      "Alejandro Montoya",
      "Raul Ramos-Pollán",
      "Mauricio Toro"
    ],
    "abstract": "The Multi-Objective Vehicle Routing Problem (MOVRP) is a complex optimization\nproblem in the transportation and logistics industry. This paper proposes a\nnovel approach to the MOVRP that aims to create routes that consider drivers'\nand operators' decisions and preferences. We evaluate two approaches to address\nthis objective: visually attractive route planning and data mining of\nhistorical driver behavior to plan similar routes. Using a real-world dataset\nprovided by Amazon, we demonstrate that data mining of historical patterns is\nmore effective than visual attractiveness metrics found in the literature.\nFurthermore, we propose a bi-objective problem to balance the similarity of\nroutes to historical routes and minimize routing costs. We propose a two-stage\nGRASP algorithm with heuristic box splitting to solve this problem. The\nproposed algorithm aims to approximate the Pareto front and to present routes\nthat cover a wide range of the objective function space. The results\ndemonstrate that our approach can generate a small number of non-dominated\nsolutions per instance, which can help decision-makers to identify trade-offs\nbetween routing costs and drivers' preferences. Our approach has the potential\nto enhance the last-mile delivery operations of logistics companies by\nbalancing these conflicting objectives.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16051v1",
    "published_date": "2024-05-25 04:25:00 UTC",
    "updated_date": "2024-05-25 04:25:00 UTC"
  },
  {
    "arxiv_id": "2405.16041v3",
    "title": "Explainable Molecular Property Prediction: Aligning Chemical Concepts with Predictions via Language Models",
    "authors": [
      "Zhenzhong Wang",
      "Zehui Lin",
      "Wanyu Lin",
      "Ming Yang",
      "Minggang Zeng",
      "Kay Chen Tan"
    ],
    "abstract": "Providing explainable molecular property predictions is critical for many\nscientific domains, such as drug discovery and material science. Though\ntransformer-based language models have shown great potential in accurate\nmolecular property prediction, they neither provide chemically meaningful\nexplanations nor faithfully reveal the molecular structure-property\nrelationships. In this work, we develop a framework for explainable molecular\nproperty prediction based on language models, dubbed as Lamole, which can\nprovide chemical concepts-aligned explanations. We take a string-based\nmolecular representation -- Group SELFIES -- as input tokens to pretrain and\nfine-tune our Lamole, as it provides chemically meaningful semantics. By\ndisentangling the information flows of Lamole, we propose combining\nself-attention weights and gradients for better quantification of each\nchemically meaningful substructure's impact on the model's output. To make the\nexplanations more faithfully respect the structure-property relationship, we\nthen carefully craft a marginal loss to explicitly optimize the explanations to\nbe able to align with the chemists' annotations. We bridge the manifold\nhypothesis with the elaborated marginal loss to prove that the loss can align\nthe explanations with the tangent space of the data manifold, leading to\nconcept-aligned explanations. Experimental results over six mutagenicity\ndatasets and one hepatotoxicity dataset demonstrate Lamole can achieve\ncomparable classification accuracy and boost the explanation accuracy by up to\n14.3%, being the state-of-the-art in explainable molecular property prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16041v3",
    "published_date": "2024-05-25 03:27:04 UTC",
    "updated_date": "2024-10-02 03:52:50 UTC"
  },
  {
    "arxiv_id": "2405.17489v1",
    "title": "On the Inflation of KNN-Shapley Value",
    "authors": [
      "Ziao Yang",
      "Han Yue",
      "Jian Chen",
      "Hongfu Liu"
    ],
    "abstract": "Shapley value-based data valuation methods, originating from cooperative game\ntheory, quantify the usefulness of each individual sample by considering its\ncontribution to all possible training subsets. Despite their extensive\napplications, these methods encounter the challenge of value inflation - while\nsamples with negative Shapley values are detrimental, some with positive values\ncan also be harmful. This challenge prompts two fundamental questions: the\nsuitability of zero as a threshold for distinguishing detrimental from\nbeneficial samples and the determination of an appropriate threshold. To\naddress these questions, we focus on KNN-Shapley and propose Calibrated\nKNN-Shapley (CKNN-Shapley), which calibrates zero as the threshold to\ndistinguish detrimental samples from beneficial ones by mitigating the negative\neffects of small-sized training subsets. Through extensive experiments, we\ndemonstrate the effectiveness of CKNN-Shapley in alleviating data valuation\ninflation, detecting detrimental samples, and assessing data quality. We also\nextend our approach beyond conventional classification settings, applying it to\ndiverse and practical scenarios such as learning with mislabeled data, online\nlearning with stream data, and active learning for label annotation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17489v1",
    "published_date": "2024-05-25 03:26:33 UTC",
    "updated_date": "2024-05-25 03:26:33 UTC"
  },
  {
    "arxiv_id": "2405.16039v2",
    "title": "MoEUT: Mixture-of-Experts Universal Transformers",
    "authors": [
      "Róbert Csordás",
      "Kazuki Irie",
      "Jürgen Schmidhuber",
      "Christopher Potts",
      "Christopher D. Manning"
    ],
    "abstract": "Previous work on Universal Transformers (UTs) has demonstrated the importance\nof parameter sharing across layers. By allowing recurrence in depth, UTs have\nadvantages over standard Transformers in learning compositional\ngeneralizations, but layer-sharing comes with a practical limitation of\nparameter-compute ratio: it drastically reduces the parameter count compared to\nthe non-shared model with the same dimensionality. Naively scaling up the layer\nsize to compensate for the loss of parameters makes its computational resource\nrequirements prohibitive. In practice, no previous work has succeeded in\nproposing a shared-layer Transformer design that is competitive in parameter\ncount-dominated tasks such as language modeling. Here we propose MoEUT\n(pronounced \"moot\"), an effective mixture-of-experts (MoE)-based shared-layer\nTransformer architecture, which combines several recent advances in MoEs for\nboth feedforward and attention layers of standard Transformers together with\nnovel layer-normalization and grouping schemes that are specific and crucial to\nUTs. The resulting UT model, for the first time, slightly outperforms standard\nTransformers on language modeling tasks such as BLiMP and PIQA, while using\nsignificantly less compute and memory.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.16039v2",
    "published_date": "2024-05-25 03:24:32 UTC",
    "updated_date": "2024-10-13 04:46:00 UTC"
  },
  {
    "arxiv_id": "2405.16003v2",
    "title": "Disentangling Heterogeneous Knowledge Concept Embedding for Cognitive Diagnosis on Untested Knowledge",
    "authors": [
      "Miao Zhang",
      "Ziming Wang",
      "Runtian Xing",
      "Kui Xiao",
      "Zhifei Li",
      "Yan Zhang",
      "Chang Tang"
    ],
    "abstract": "Cognitive diagnosis is a fundamental and critical task in learning\nassessment, which aims to infer students' proficiency on knowledge concepts\nfrom their response logs. Current works assume each knowledge concept will\ncertainly be tested and covered by multiple exercises. However, whether online\nor offline courses, it's hardly feasible to completely cover all knowledge\nconcepts in several exercises. Restricted tests lead to undiscovered knowledge\ndeficits, especially untested knowledge concepts(UKCs). In this paper, we\npropose a novel framework for Cognitive Diagnosis called Disentangling\nHeterogeneous Knowledge Cognitive Diagnosis(DisKCD) on untested knowledge.\nSpecifically, we leverage course grades, exercise questions, and learning\nresources to learn the potential representations of students, exercises, and\nknowledge concepts. In particular, knowledge concepts are disentangled into\ntested and untested based on the limiting actual exercises. We construct a\nheterogeneous relation graph network via students, exercises, tested knowledge\nconcepts(TKCs), and UKCs. Then, through a hierarchical heterogeneous\nmessage-passing mechanism, the fine-grained relations are incorporated into the\nembeddings of the entities. Finally, the embeddings will be applied to multiple\nexisting cognitive diagnosis models to infer students' proficiency on UKCs.\nExperimental results on real-world datasets show that the proposed model can\neffectively improve the performance of the task of diagnosing students'\nproficiency on UKCs. Our code is available at\nhttps://github.com/Hubuers/DisKCD.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.16003v2",
    "published_date": "2024-05-25 01:49:54 UTC",
    "updated_date": "2024-10-18 02:57:01 UTC"
  },
  {
    "arxiv_id": "2405.16000v1",
    "title": "Carnatic Raga Identification System using Rigorous Time-Delay Neural Network",
    "authors": [
      "Sanjay Natesan",
      "Homayoon Beigi"
    ],
    "abstract": "Large scale machine learning-based Raga identification continues to be a\nnontrivial issue in the computational aspects behind Carnatic music. Each raga\nconsists of many unique and intrinsic melodic patterns that can be used to\neasily identify them from others. These ragas can also then be used to cluster\nsongs within the same raga, as well as identify songs in other closely related\nragas. In this case, the input sound is analyzed using a combination of steps\nincluding using a Discrete Fourier transformation and using Triangular\nFiltering to create custom bins of possible notes, extracting features from the\npresence of particular notes or lack thereof. Using a combination of Neural\nNetworks including 1D Convolutional Neural Networks conventionally known as\nTime-Delay Neural Networks) and Long Short-Term Memory (LSTM), which are a form\nof Recurrent Neural Networks, the backbone of the classification strategy to\nbuild the model can be created. In addition, to help with variations in shruti,\na long-time attention-based mechanism will be implemented to determine the\nrelative changes in frequency rather than the absolute differences. This will\nprovide a much more meaningful data point when training audio clips in\ndifferent shrutis. To evaluate the accuracy of the classifier, a dataset of 676\nrecordings is used. The songs are distributed across the list of ragas. The\ngoal of this program is to be able to effectively and efficiently label a much\nwider range of audio clips in more shrutis, ragas, and with more background\nnoise.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "7 pages, 2 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.16000v1",
    "published_date": "2024-05-25 01:31:58 UTC",
    "updated_date": "2024-05-25 01:31:58 UTC"
  },
  {
    "arxiv_id": "2405.15994v2",
    "title": "Verified Safe Reinforcement Learning for Neural Network Dynamic Models",
    "authors": [
      "Junlin Wu",
      "Huan Zhang",
      "Yevgeniy Vorobeychik"
    ],
    "abstract": "Learning reliably safe autonomous control is one of the core problems in\ntrustworthy autonomy. However, training a controller that can be formally\nverified to be safe remains a major challenge. We introduce a novel approach\nfor learning verified safe control policies in nonlinear neural dynamical\nsystems while maximizing overall performance. Our approach aims to achieve\nsafety in the sense of finite-horizon reachability proofs, and is comprised of\nthree key parts. The first is a novel curriculum learning scheme that\niteratively increases the verified safe horizon. The second leverages the\niterative nature of gradient-based learning to leverage incremental\nverification, reusing information from prior verification runs. Finally, we\nlearn multiple verified initial-state-dependent controllers, an idea that is\nespecially valuable for more complex domains where learning a single universal\nverified safe controller is extremely challenging. Our experiments on five safe\ncontrol problems demonstrate that our trained controllers can achieve verified\nsafety over horizons that are as much as an order of magnitude longer than\nstate-of-the-art baselines, while maintaining high reward, as well as a perfect\nsafety record over entire episodes. Our code is available at\nhttps://github.com/jlwu002/VSRL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15994v2",
    "published_date": "2024-05-25 00:35:39 UTC",
    "updated_date": "2024-11-16 04:21:50 UTC"
  },
  {
    "arxiv_id": "2405.15991v2",
    "title": "Rényi Neural Processes",
    "authors": [
      "Xuesong Wang",
      "He Zhao",
      "Edwin V. Bonilla"
    ],
    "abstract": "Neural Processes (NPs) are deep probabilistic models that represent\nstochastic processes by conditioning their prior distributions on a set of\ncontext points. Despite their obvious advantages in uncertainty estimation for\ncomplex distributions, NPs enforce parameterization coupling between the\nconditional prior model and the posterior model, thereby risking introducing a\nmisspecified prior distribution. We hereby revisit the NP objectives and\npropose R\\'enyi Neural Processes (RNP) to ameliorate the impacts of prior\nmisspecification by optimizing an alternative posterior that achieves better\nmarginal likelihood. More specifically, by replacing the standard KL divergence\nwith the R\\'enyi divergence between the model posterior and the true posterior,\nwe scale the density ratio $\\frac{p}{q}$ by the power of (1-$\\alpha$) in the\ndivergence gradients with respect to the posterior. This hyper parameter\n$\\alpha$ allows us to dampen the effects of the misspecified prior for the\nposterior update, which has been shown to effectively avoid oversmoothed\npredictions and improve the expressiveness of the posterior model. Our\nextensive experiments show consistent log-likelihood improvements over\nstate-of-the-art NP family models which adopt both the variational inference or\nmaximum likelihood estimation objectives. We validate the effectiveness of our\napproach across multiple benchmarks including regression and image inpainting\ntasks, and show significant performance improvements of RNPs in real-world\nregression problems where the underlying prior model is misspecifed.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15991v2",
    "published_date": "2024-05-25 00:14:55 UTC",
    "updated_date": "2024-10-03 09:33:43 UTC"
  },
  {
    "arxiv_id": "2405.15988v1",
    "title": "Transductive Confidence Machine and its application to Medical Data Sets",
    "authors": [
      "David Lindsay"
    ],
    "abstract": "The Transductive Confidence Machine Nearest Neighbours (TCMNN) algorithm and\na supporting, simple user interface was developed. Different settings of the\nTCMNN algorithms' parameters were tested on medical data sets, in addition to\nthe use of different Minkowski metrics and polynomial kernels. The effect of\nincreasing the number of nearest neighbours and marking results with\nsignificance was also investigated. SVM implementation of the Transductive\nConfidence Machine was compared with Nearest Neighbours implementation. The\napplication of neural networks was investigated as a useful comparison to the\ntransductive algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "160 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.15988v1",
    "published_date": "2024-05-25 00:02:15 UTC",
    "updated_date": "2024-05-25 00:02:15 UTC"
  }
]