{
  "date": "2024-08-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-22 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、图像生成、医疗应用和强化学习等领域，其中 LLM 在医疗诊断和自动驾驶中的创新应用（如 RuleAlign 和 Can LLMs Understand Social Norms）特别引人注目，展示了 LLM 的实际潜力；此外，xGen-VideoSyn-1 在高质量视频生成方面的突破，以及 MultiMed 在多模态医疗理解上的进展，也值得关注。\n\n下面，我将挑选并简要讨论几篇重要的、具有话题度的论文，先从 LLM 和医疗相关的高影响力文章入手，然后快速概述其他领域的亮点。对于较无聊或次要的论文（如一些基础方法改进或小规模实验），我将简略掠过，只列标题和核心要点，以控制篇幅。\n\n### 重点论文讨论\n\n**1. RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment（RuleAlign: 使用诊断规则对齐提升大型语言模型的医疗诊断能力）**  \n   这篇论文提出 RuleAlign 框架，利用偏好学习和医疗对话数据集来对齐 LLM 与诊断规则，显著提升了 LLM 在医疗诊断中的性能。主要贡献是通过规则对齐和偏好学习，使 LLM 能更准确地模拟医生诊断过程，并在实验中展示了在实际医疗任务中的鲁棒性，潜在影响包括改进 AI 辅助诊断的可靠性和效率。\n\n**2. Can LLMs Understand Social Norms in Autonomous Driving Games?（大型语言模型能否理解自动驾驶游戏中的社会规范？）**  \n   作者探索了 LLM 在自动驾驶场景中的社会规范推理能力，引入 LLM 作为智能代理参与马尔科夫游戏。主要发现是 LLM 能处理动态环境并演化出保守的驾驶策略（如避免碰撞），这为自动驾驶系统的安全性和可解释性提供了新视角，突显 LLM 在多代理系统中的潜力。\n\n**3. MultiMed: Massively Multimodal and Multitask Medical Understanding（MultiMed: 海量多模态和多任务医疗理解）**  \n   这篇论文由 Paul Pu Liang 等作者提出，构建了一个包含 2.56 百万样本的基准数据集，覆盖多种医疗模态（如报告、图像和基因数据）。主要贡献是开发了一个多模态多任务模型，提升了医疗预测的泛化能力，并在实验中展示了跨模态协同关系的优势，对于医疗 AI 的全面应用具有重要启发。\n\n**4. SLM Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination Detection（小语言模型遇上大语言模型：平衡延迟、可解释性和一致性以检测幻觉）**  \n   论文引入一个框架，使用小语言模型（SLM）进行初步幻觉检测，并用 LLM 生成解释。主要发现是通过提示技巧优化了实时检测的效率和准确性，这对 LLM 在实际应用中的幻觉问题提供了实用解决方案。\n\n**5. xGen-VideoSyn-1: High-fidelity Text-to-Video Synthesis with Compressed Representations（xGen-VideoSyn-1: 使用压缩表示的高保真文本到视频合成）**  \n   作者提出一个基于扩散模型的框架，能生成长达 14 秒的 720p 视频。主要贡献是引入视频变分自动编码器和分段策略，显著降低了计算成本，并在实验中超越了现有文本到视频模型，对于视频生成和数字孪生应用有重要意义。\n\n**6. Rethinking Training for De-biasing Text-to-Image Generation: Unlocking the Potential of Stable Diffusion（重新思考文本到图像生成的去偏置训练：释放 Stable Diffusion 的潜力）**  \n   这篇论文探索了 Stable Diffusion 在图像生成中的偏置问题，提出“弱引导”方法来减少偏置而不需额外训练。主要发现是该方法能有效生成更公平的图像，同时保持语义完整性，对于 AI 生成内容的伦理应用提供了新路径。\n\n**7. SQL-GEN: Bridging the Dialect Gap for Text-to-SQL Via Synthetic Data And Model Merging（SQL-GEN: 通过合成数据和模型合并桥接 SQL 方言鸿沟）**  \n   论文提出 SQL-GEN 框架，使用合成数据生成不同 SQL 方言的训练数据，并通过混合专家模型融合方言知识。主要贡献是提升了跨方言的文本到 SQL 性能，实验显示准确率提升高达 20%，这对数据库查询自动化有实际价值。\n\n**8. Multi-tool Integration Application for Math Reasoning Using Large Language Model（使用大型语言模型的多工具集成应用进行数学推理）**  \n   作者开发了一个多工具框架，结合数学计算和代码生成工具提升 LLM 的数学推理能力。主要发现是通过工具协同（如 CoT 和自一致性），在基准测试中显著提高了准确率，对于复杂数学任务的 AI 支持具有潜力。\n\n其他论文中，如涉及图神经网络的（如 When In-memory Computing Meets Spiking Neural Networks）和图像处理的（如 Generating Realistic X-ray Scattering Images），也有一些创新，但影响力相对有限，我将快速掠过：\n\n- **TReX: Reusing Vision Transformer's Attention for Efficient Xbar-based Computing（TReX: 为高效 Xbar 计算重用视觉 Transformer 的注意力）**  \n  贡献：提出注意力重用框架，提升视觉 Transformer 的能效，实验显示在图像任务中减少了计算开销。\n\n- **BankTweak: Adversarial Attack against Multi-Object Trackers（BankTweak: 针对多目标跟踪器的对抗攻击）**  \n  发现：通过操纵特征库诱发跟踪错误，提升了攻击的鲁棒性。\n\n- **From Radiologist Report to Image Label（从放射科报告到图像标签）**  \n  贡献：使用 LDA 和神经网络从报告中生成图像标签，提高了正交影像分类的准确性。\n\n剩余论文（如一些基础基准或小实验，如第11、17、19篇）多为方法改进或特定领域应用，我仅列出标题和简要核心点，以节省篇幅：\n- **Assessing Modality Bias in Video Question Answering（评估视频问答中的模态偏差）**：引入模态重要性分数，改进多模态模型的偏差检测。\n- **Visual Verity in AI-Generated Imagery（AI 生成图像中的视觉真实性）**：开发新指标评估图像质量，提升了生成模型的真实性。\n- **Learning Valid Dual Bounds in Constraint Programming（在约束编程中学习有效双边界）**：提出自监督学习方法，提升约束求解效率。\n- **AlphaFolding: 4D Diffusion for Dynamic Protein Structure Prediction（AlphaFolding: 用于动态蛋白结构预测的 4D 扩散）**：整合物理属性提升蛋白预测准确性。\n\n总之，今天的论文突显了 AI 在医疗和生成领域的进展，LLM 的应用尤其值得关注。未来几天，arXiv 可能继续聚焦这些热门主题，读者可根据自身兴趣优先查看相关论文！",
  "papers": [
    {
      "arxiv_id": "2408.12767v1",
      "title": "When In-memory Computing Meets Spiking Neural Networks -- A Perspective on Device-Circuit-System-and-Algorithm Co-design",
      "title_zh": "当内存计算遇上脉冲神经网络——对设备-电路-系统-算法联合设计的视角",
      "authors": [
        "Abhishek Moitra",
        "Abhiroop Bhattacharjee",
        "Yuhang Li",
        "Youngeun Kim",
        "Priyadarshini Panda"
      ],
      "abstract": "This review explores the intersection of bio-plausible artificial\nintelligence in the form of Spiking Neural Networks (SNNs) with the analog\nIn-Memory Computing (IMC) domain, highlighting their collective potential for\nlow-power edge computing environments. Through detailed investigation at the\ndevice, circuit, and system levels, we highlight the pivotal synergies between\nSNNs and IMC architectures. Additionally, we emphasize the critical need for\ncomprehensive system-level analyses, considering the inter-dependencies between\nalgorithms, devices, circuit & system parameters, crucial for optimal\nperformance. An in-depth analysis leads to identification of key system-level\nbottlenecks arising from device limitations which can be addressed using\nSNN-specific algorithm-hardware co-design techniques. This review underscores\nthe imperative for holistic device to system design space co-exploration,\nhighlighting the critical aspects of hardware and algorithm research endeavors\nfor low-power neuromorphic solutions.",
      "tldr_zh": "这篇评论探讨了 Spiking Neural Networks (SNNs) 与 In-Memory Computing (IMC) 的交汇点，强调它们在低功耗边缘计算环境中的协同潜力。作者通过设备、电路和系统级别的详细调查，突出了 SNNs 和 IMC 架构之间的关键协同作用，并强调了系统级分析的必要性，以考虑算法、设备、电路和系统参数的相互依赖。分析识别出设备限制导致的系统级瓶颈，并提出通过 SNN 特定的算法-硬件联合设计技术来解决这些问题。该研究呼吁进行从设备到系统的整体设计空间联合探索，以推动低功耗神经形态解决方案的发展。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "19 Pages, 13 Figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12767v1",
      "published_date": "2024-08-22 23:45:40 UTC",
      "updated_date": "2024-08-22 23:45:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:41:59.030787"
    },
    {
      "arxiv_id": "2408.12763v2",
      "title": "Assessing Modality Bias in Video Question Answering Benchmarks with Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jean Park",
        "Kuk Jin Jang",
        "Basam Alasaly",
        "Sriharsha Mopidevi",
        "Andrew Zolensky",
        "Eric Eaton",
        "Insup Lee",
        "Kevin Johnson"
      ],
      "abstract": "Multimodal large language models (MLLMs) can simultaneously process visual,\ntextual, and auditory data, capturing insights that complement human analysis.\nHowever, existing video question-answering (VidQA) benchmarks and datasets\noften exhibit a bias toward a single modality, despite the goal of requiring\nadvanced reasoning skills that integrate diverse modalities to answer the\nqueries. In this work, we introduce the modality importance score (MIS) to\nidentify such bias. It is designed to assess which modality embeds the\nnecessary information to answer the question. Additionally, we propose an\ninnovative method using state-of-the-art MLLMs to estimate the modality\nimportance, which can serve as a proxy for human judgments of modality\nperception. With this MIS, we demonstrate the presence of unimodal bias and the\nscarcity of genuinely multimodal questions in existing datasets. We further\nvalidate the modality importance score with multiple ablation studies to\nevaluate the performance of MLLMs on permuted feature sets. Our results\nindicate that current models do not effectively integrate information due to\nmodality imbalance in existing datasets. Our proposed MLLM-derived MIS can\nguide the curation of modality-balanced datasets that advance multimodal\nlearning and enhance MLLMs' capabilities to understand and utilize synergistic\nrelations across modalities.",
      "tldr_zh": "这篇论文评估了现有视频问答（VidQA）基准中的模态偏置问题，使用Multimodal Large Language Models (MLLMs)提出模态重要性分数（Modality Importance Score, MIS）来识别哪个模态包含回答问题所需的信息。研究通过MLLMs估计MIS，并进行消融研究，证明了现有数据集存在显著的单模态偏置，导致真正多模态问题的稀缺。结果显示，当前模型因模态不平衡而无法有效整合信息，而MIS可指导创建模态平衡数据集，提升MLLMs的多模态学习能力和跨模态协同理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12763v2",
      "published_date": "2024-08-22 23:32:42 UTC",
      "updated_date": "2024-12-19 19:37:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:42:11.119070"
    },
    {
      "arxiv_id": "2408.12762v2",
      "title": "Visual Verity in AI-Generated Imagery: Computational Metrics and Human-Centric Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Memoona Aziz",
        "Umair Rehman",
        "Syed Ali Safi",
        "Amir Zaib Abbasi"
      ],
      "abstract": "The rapid advancements in AI technologies have revolutionized the production\nof graphical content across various sectors, including entertainment,\nadvertising, and e-commerce. These developments have spurred the need for\nrobust evaluation methods to assess the quality and realism of AI-generated\nimages. To address this, we conducted three studies. First, we introduced and\nvalidated a questionnaire called Visual Verity, which measures photorealism,\nimage quality, and text-image alignment. Second, we applied this questionnaire\nto assess images from AI models (DALL-E2, DALL-E3, GLIDE, Stable Diffusion) and\ncamera-generated images, revealing that camera-generated images excelled in\nphotorealism and text-image alignment, while AI models led in image quality. We\nalso analyzed statistical properties, finding that camera-generated images\nscored lower in hue, saturation, and brightness. Third, we evaluated\ncomputational metrics' alignment with human judgments, identifying MS-SSIM and\nCLIP as the most consistent with human assessments. Additionally, we proposed\nthe Neural Feature Similarity Score (NFSS) for assessing image quality. Our\nfindings highlight the need for refining computational metrics to better\ncapture human visual perception, thereby enhancing AI-generated content\nevaluation.",
      "tldr_zh": "这篇论文探讨了AI生成图像的评估方法，引入了Visual Verity问卷来衡量photorealism、image quality和text-image alignment。该问卷应用于评估DALL-E2、DALL-E3、GLIDE、Stable Diffusion等AI模型生成的图像与相机图像，结果显示相机图像在photorealism和text-image alignment上更出色，而AI图像在image quality上领先；此外，统计分析发现相机图像在hue、saturation和brightness方面得分较低。论文还评估了computational metrics的可靠性，发现MS-SSIM和CLIP最符合人类判断，并提出了Neural Feature Similarity Score (NFSS)作为新的图像质量评估工具，强调需要优化这些指标以更好地捕捉人类视觉感知。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12762v2",
      "published_date": "2024-08-22 23:29:07 UTC",
      "updated_date": "2024-09-01 17:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:42:23.463180"
    },
    {
      "arxiv_id": "2408.12748v1",
      "title": "SLM Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Mengya Hu",
        "Rui Xu",
        "Deren Lei",
        "Yaxi Li",
        "Mingyu Wang",
        "Emily Ching",
        "Eslam Kamal",
        "Alex Deng"
      ],
      "abstract": "Large language models (LLMs) are highly capable but face latency challenges\nin real-time applications, such as conducting online hallucination detection.\nTo overcome this issue, we propose a novel framework that leverages a small\nlanguage model (SLM) classifier for initial detection, followed by a LLM as\nconstrained reasoner to generate detailed explanations for detected\nhallucinated content. This study optimizes the real-time interpretable\nhallucination detection by introducing effective prompting techniques that\nalign LLM-generated explanations with SLM decisions. Empirical experiment\nresults demonstrate its effectiveness, thereby enhancing the overall user\nexperience.",
      "tldr_zh": "该研究提出了一种结合小语言模型(SLM)和大语言模型(LLM)的框架，用于平衡幻觉检测中的延迟、可解释性和一致性。框架中，SLM作为初始检测器快速识别潜在幻觉，而LLM作为受限推理器生成详细解释，并通过有效的提示技术确保解释与SLM决策一致。实验结果证明，该方法在实时应用中有效提升了检测性能和用户体验。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint under review",
      "pdf_url": "http://arxiv.org/pdf/2408.12748v1",
      "published_date": "2024-08-22 22:13:13 UTC",
      "updated_date": "2024-08-22 22:13:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:42:32.208614"
    },
    {
      "arxiv_id": "2408.12742v1",
      "title": "TReX- Reusing Vision Transformer's Attention for Efficient Xbar-based Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Moitra",
        "Abhiroop Bhattacharjee",
        "Youngeun Kim",
        "Priyadarshini Panda"
      ],
      "abstract": "Due to the high computation overhead of Vision Transformers (ViTs), In-memory\nComputing architectures are being researched towards energy-efficient\ndeployment in edge-computing scenarios. Prior works have proposed efficient\nalgorithm-hardware co-design and IMC-architectural improvements to improve the\nenergy-efficiency of IMC-implemented ViTs. However, all prior works have\nneglected the overhead and co-depencence of attention blocks on the\naccuracy-energy-delay-area of IMC-implemented ViTs. To this end, we propose\nTReX- an attention-reuse-driven ViT optimization framework that effectively\nperforms attention reuse in ViT models to achieve optimal\naccuracy-energy-delay-area tradeoffs. TReX optimally chooses the transformer\nencoders for attention reuse to achieve near iso-accuracy performance while\nmeeting the user-specified delay requirement. Based on our analysis on the\nImagenet-1k dataset, we find that TReX achieves 2.3x (2.19x) EDAP reduction and\n1.86x (1.79x) TOPS/mm2 improvement with ~1% accuracy drop in case of DeiT-S\n(LV-ViT-S) ViT models. Additionally, TReX achieves high accuracy at high EDAP\nreduction compared to state-of-the-art token pruning and weight sharing\napproaches. On NLP tasks such as CoLA, TReX leads to 2% higher non-ideal\naccuracy compared to baseline at 1.6x lower EDAP.",
      "tldr_zh": "该研究提出 TReX 框架，通过重用 Vision Transformers (ViTs) 的注意力机制，优化基于 Xbar 的 In-memory Computing (IMC) 架构，以降低 ViTs 的计算开销并实现最佳的准确性-能量-延迟-面积 (EDAP) 权衡。TReX 算法通过选择性地重用 transformer 编码器，确保在满足用户指定的延迟要求下，保持近乎相同的准确性。实验结果显示，在 Imagenet-1k 数据集上，TReX 使 DeiT-S 和 LV-ViT-S 模型的 EDAP 分别减少 2.3x 和 2.19x，TOPS/mm2 改善 1.86x 和 1.79x，同时准确性仅下降约 1%；在 NLP 任务如 CoLA 上，TReX 比基线方法提高 2% 非理想准确性，并实现 1.6x EDAP 降低。",
      "categories": [
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.12742v1",
      "published_date": "2024-08-22 21:51:38 UTC",
      "updated_date": "2024-08-22 21:51:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:42:48.596873"
    },
    {
      "arxiv_id": "2408.12734v1",
      "title": "Towards measuring fairness in speech recognition: Fair-Speech dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Irina-Elena Veliche",
        "Zhuangqun Huang",
        "Vineeth Ayyat Kochaniyan",
        "Fuchun Peng",
        "Ozlem Kalinli",
        "Michael L. Seltzer"
      ],
      "abstract": "The current public datasets for speech recognition (ASR) tend not to focus\nspecifically on the fairness aspect, such as performance across different\ndemographic groups. This paper introduces a novel dataset, Fair-Speech, a\npublicly released corpus to help researchers evaluate their ASR models for\naccuracy across a diverse set of self-reported demographic information, such as\nage, gender, ethnicity, geographic variation and whether the participants\nconsider themselves native English speakers. Our dataset includes approximately\n26.5K utterances in recorded speech by 593 people in the United States, who\nwere paid to record and submit audios of themselves saying voice commands. We\nalso provide ASR baselines, including on models trained on transcribed and\nuntranscribed social media videos and open source models.",
      "tldr_zh": "本论文针对语音识别（ASR）模型在不同人口统计学群体（如年龄、性别、种族、地域差异和英语母语者）上的公平性问题，引入了 Fair-Speech 数据集，以帮助评估模型的准确性。该数据集包含约 26.5K 条语音记录，由 593 名美国参与者录制提交，涵盖多样化的自报人口统计信息。论文还提供了 ASR 基准模型，包括在转录和未转录社交媒体视频上训练的模型，以及开源模型，作为评估工具。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.SD",
        "eess.AS",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12734v1",
      "published_date": "2024-08-22 20:55:17 UTC",
      "updated_date": "2024-08-22 20:55:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:42:57.956813"
    },
    {
      "arxiv_id": "2408.12733v2",
      "title": "SQL-GEN: Bridging the Dialect Gap for Text-to-SQL Via Synthetic Data And Model Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadreza Pourreza",
        "Ruoxi Sun",
        "Hailong Li",
        "Lesly Miculicich",
        "Tomas Pfister",
        "Sercan O. Arik"
      ],
      "abstract": "Recent advances in Text-to-SQL have largely focused on the SQLite dialect,\nneglecting the diverse landscape of SQL dialects like BigQuery and PostgreSQL.\nThis limitation is due to the diversity in SQL syntaxes and functions, along\nwith the high cost of collecting and curating SQL-specific training data. To\naddress this, we introduce SQL-GEN, a framework for generating high-quality\nsynthetic training data for any SQL dialect, guided by readily available\ndialect-specific tutorials. SQL-GEN significantly improves cross-dialect\nText-to-SQL performance, boosting execution accuracy by up to 20\\% over\nexisting methods. This performance gain narrows the gap with models trained on\nlarge-scale human-annotated data. Furthermore, combining synthetic data from\nSQL-GEN with human-annotated data yields additional improvements of up to\n5.6\\%. To unify multi-dialect capabilities within a single model, we propose a\nnovel Mixture-of-Experts (MoE) initialization that leverages the shared\nknowledge across dialects. Our approach merges self-attention layers from\ndialect-specific models and initializes expert gates using dialect-specific\nkeywords. This leads to a versatile model optimized for multiple SQL dialects,\noutperforming single-dialect models and significantly enhancing overall\nperformance.",
      "tldr_zh": "本文提出 SQL-GEN 框架，通过利用方言特定教程生成高质量的 synthetic data，来桥接 Text-to-SQL 在不同 SQL 方言（如 BigQuery 和 PostgreSQL）间的差距，解决了数据收集成本高的问题。实验显示，SQL-GEN 显著提升了跨方言性能，执行准确率提高高达 20%，并与人工标注数据结合可进一步提升 5.6%。此外，该框架引入 Mixture-of-Experts (MoE) 初始化方法，合并自注意力层并使用方言特定关键词优化专家门控，构建一个多方言统一的模型，整体性能超越单方言模型。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12733v2",
      "published_date": "2024-08-22 20:50:48 UTC",
      "updated_date": "2024-10-02 18:19:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:43:10.895147"
    },
    {
      "arxiv_id": "2408.12727v1",
      "title": "BankTweak: Adversarial Attack against Multi-Object Trackers by Manipulating Feature Banks",
      "title_zh": "翻译失败",
      "authors": [
        "Woojin Shin",
        "Donghwa Kang",
        "Daejin Choi",
        "Brent Kang",
        "Jinkyu Lee",
        "Hyeongboo Baek"
      ],
      "abstract": "Multi-object tracking (MOT) aims to construct moving trajectories for\nobjects, and modern multi-object trackers mainly utilize the\ntracking-by-detection methodology. Initial approaches to MOT attacks primarily\naimed to degrade the detection quality of the frames under attack, thereby\nreducing accuracy only in those specific frames, highlighting a lack of\n\\textit{efficiency}. To improve efficiency, recent advancements manipulate\nobject positions to cause persistent identity (ID) switches during the\nassociation phase, even after the attack ends within a few frames. However,\nthese position-manipulating attacks have inherent limitations, as they can be\neasily counteracted by adjusting distance-related parameters in the association\nphase, revealing a lack of \\textit{robustness}. In this paper, we present\n\\textsf{BankTweak}, a novel adversarial attack designed for MOT trackers, which\nfeatures efficiency and robustness. \\textsf{BankTweak} focuses on the feature\nextractor in the association phase and reveals vulnerability in the Hungarian\nmatching method used by feature-based MOT systems. Exploiting the\nvulnerability, \\textsf{BankTweak} induces persistent ID switches (addressing\n\\textit{efficiency}) even after the attack ends by strategically injecting\naltered features into the feature banks without modifying object positions\n(addressing \\textit{robustness}). To demonstrate the applicability, we apply\n\\textsf{BankTweak} to three multi-object trackers (DeepSORT, StrongSORT, and\nMOTDT) with one-stage, two-stage, anchor-free, and transformer detectors.\nExtensive experiments on the MOT17 and MOT20 datasets show that our method\nsubstantially surpasses existing attacks, exposing the vulnerability of the\ntracking-by-detection framework to \\textsf{BankTweak}.",
      "tldr_zh": "本文提出 BankTweak，一种针对 Multi-Object Trackers (MOT) 的新型对抗攻击方法，通过操纵 Feature Banks 来诱导持久的 ID 切换，从而提升攻击的效率和鲁棒性。不同于传统攻击，BankTweak 利用特征提取器和 Hungarian Matching 的漏洞，仅注入修改后的特征而不改变对象位置，确保攻击效果持续存在。实验在 MOT17 和 MOT20 数据集上应用该方法于 DeepSORT、StrongSORT 和 MOTDT 等跟踪器，结果显示 BankTweak 显著优于现有攻击，暴露了跟踪-by-detection 框架的潜在脆弱性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12727v1",
      "published_date": "2024-08-22 20:35:46 UTC",
      "updated_date": "2024-08-22 20:35:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:43:22.318402"
    },
    {
      "arxiv_id": "2408.12720v1",
      "title": "Generating Realistic X-ray Scattering Images Using Stable Diffusion and Human-in-the-loop Annotations",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuowen Zhao",
        "Xiaoya Chong",
        "Tanny Chavez",
        "Alexander Hexemer"
      ],
      "abstract": "We fine-tuned a foundational stable diffusion model using X-ray scattering\nimages and their corresponding descriptions to generate new scientific images\nfrom given prompts. However, some of the generated images exhibit significant\nunrealistic artifacts, commonly known as \"hallucinations\". To address this\nissue, we trained various computer vision models on a dataset composed of 60%\nhuman-approved generated images and 40% experimental images to detect\nunrealistic images. The classified images were then reviewed and corrected by\nhuman experts, and subsequently used to further refine the classifiers in next\nrounds of training and inference. Our evaluations demonstrate the feasibility\nof generating high-fidelity, domain-specific images using a fine-tuned\ndiffusion model. We anticipate that generative AI will play a crucial role in\nenhancing data augmentation and driving the development of digital twins in\nscientific research facilities.",
      "tldr_zh": "本文研究利用 Stable Diffusion 模型微调生成 X-ray scattering 图像，并结合 Human-in-the-loop Annotations 来处理生成图像中的 hallucinations（不现实伪影）。他们训练计算机视觉模型，使用60%人类批准的生成图像和40%实验图像来检测不现实图像，并通过人类专家审查和迭代修正进一步优化模型。实验评估证明了该方法的可行性，能够产生高保真度的领域特定图像，并预见生成式 AI 将在数据增强和数字孪生技术中发挥关键作用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12720v1",
      "published_date": "2024-08-22 20:23:04 UTC",
      "updated_date": "2024-08-22 20:23:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:43:44.617773"
    },
    {
      "arxiv_id": "2408.13284v1",
      "title": "From Radiologist Report to Image Label: Assessing Latent Dirichlet Allocation in Training Neural Networks for Orthopedic Radiograph Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Olczak",
        "Max Gordon"
      ],
      "abstract": "Background: Radiography (X-rays) is the dominant modality in orthopedics, and\nimproving the interpretation of radiographs is clinically relevant. Machine\nlearning (ML) has revolutionized data analysis and has been applied to\nmedicine, with some success, in the form of natural language processing (NLP)\nand artificial neural networks (ANN). Latent Dirichlet allocation (LDA) is an\nNLP method that automatically categorizes documents into topics. Successfully\napplying ML to orthopedic radiography could enable the creation of\ncomputer-aided decision systems for use in the clinic. We studied how an\nautomated ML pipeline could classify orthopedic trauma radiographs from\nradiologist reports. Methods: Wrist and ankle radiographs from Danderyd\nHospital in Sweden taken between 2002 and 2015, with radiologist reports. LDA\nwas used to create image labels for radiographs from the radiologist reports.\nRadiographs and labels were used to train an image recognition ANN. The ANN\noutcomes were manually reviewed to get an accurate estimate of the method's\nutility and accuracy. Results: Image Labels generated via LDA could\nsuccessfully train the ANN. The ANN reached an accuracy between 91% and 60%\ncompared to a gold standard, depending on the label. Conclusions: We found that\nLDA was unsuited to label orthopedic radiographs from reports with high\naccuracy. However, despite this, the ANN could learn to detect some features in\nradiographs with high accuracy. The study also illustrates how ML and ANN can\nbe applied to medical research.",
      "tldr_zh": "本研究评估了Latent Dirichlet Allocation (LDA) 在从放射科报告生成图像标签并训练神经网络以分类骨科X光片中的应用，旨在提升X光解读的临床价值。研究使用LDA从瑞典Danderyd医院2002-2015年手腕和踝关节X光报告中自动创建标签，然后训练图像识别artificial neural networks (ANN)进行分类。结果显示，ANN的准确率在60%至91%之间，取决于标签，尽管LDA在高精度标签生成方面表现不佳。该方法证明了机器学习 (ML) 和ANN在医疗研究中的潜力，特别是检测某些X光特征。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This article is an abridged version of a 2016 master's thesis at the\n  Karolinska Institute. The original is available upon request",
      "pdf_url": "http://arxiv.org/pdf/2408.13284v1",
      "published_date": "2024-08-22 19:47:25 UTC",
      "updated_date": "2024-08-22 19:47:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:43:46.277745"
    },
    {
      "arxiv_id": "2408.12695v1",
      "title": "Learning Valid Dual Bounds in Constraint Programming: Boosted Lagrangian Decomposition with Self-Supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Swann Bessa",
        "Darius Dabert",
        "Max Bourgeat",
        "Louis-Martin Rousseau",
        "Quentin Cappart"
      ],
      "abstract": "Lagrangian decomposition (LD) is a relaxation method that provides a dual\nbound for constrained optimization problems by decomposing them into more\nmanageable sub-problems. This bound can be used in branch-and-bound algorithms\nto prune the search space effectively. In brief, a vector of Lagrangian\nmultipliers is associated with each sub-problem, and an iterative procedure\n(e.g., a sub-gradient optimization) adjusts these multipliers to find the\ntightest bound. Initially applied to integer programming, Lagrangian\ndecomposition also had success in constraint programming due to its versatility\nand the fact that global constraints provide natural sub-problems. However, the\nnon-linear and combinatorial nature of sub-problems in constraint programming\nmakes it computationally intensive to optimize the Lagrangian multipliers with\nsub-gradient methods at each node of the tree search. This currently limits the\npracticality of LD as a general bounding mechanism for constraint programming.\nTo address this challenge, we propose a self-supervised learning approach that\nleverages neural networks to generate multipliers directly, yielding tight\nbounds. This approach significantly reduces the number of sub-gradient\noptimization steps required, enhancing the pruning efficiency and reducing the\nexecution time of constraint programming solvers. This contribution is one of\nthe few that leverage learning to enhance bounding mechanisms on the dual side,\na critical element in the design of combinatorial solvers. To our knowledge,\nthis work presents the first generic method for learning valid dual bounds in\nconstraint programming.",
      "tldr_zh": "本研究针对约束编程（Constraint Programming）中Lagrangian Decomposition (LD)的计算密集问题，提出了一种基于自监督学习(Self-Supervised Learning)的增强方法，使用神经网络直接生成Lagrangian multipliers，以快速获得紧的双重边界。相比传统子梯度优化，该方法显著减少了优化步骤，提高了分支定界算法的修剪效率和求解器执行时间。实验结果表明，此创新方法是首个通用的学习有效双重边界技术，为提升组合优化求解器的性能奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12695v1",
      "published_date": "2024-08-22 19:26:29 UTC",
      "updated_date": "2024-08-22 19:26:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:43:58.886736"
    },
    {
      "arxiv_id": "2408.12692v2",
      "title": "Rethinking Training for De-biasing Text-to-Image Generation: Unlocking the Potential of Stable Diffusion",
      "title_zh": "重新思考用于去偏置文本到图像生成的训练：释放",
      "authors": [
        "Eunji Kim",
        "Siwon Kim",
        "Minjun Park",
        "Rahim Entezari",
        "Sungroh Yoon"
      ],
      "abstract": "Recent advancements in text-to-image models, such as Stable Diffusion, show\nsignificant demographic biases. Existing de-biasing techniques rely heavily on\nadditional training, which imposes high computational costs and risks of\ncompromising core image generation functionality. This hinders them from being\nwidely adopted to real-world applications. In this paper, we explore Stable\nDiffusion's overlooked potential to reduce bias without requiring additional\ntraining. Through our analysis, we uncover that initial noises associated with\nminority attributes form \"minority regions\" rather than scattered. We view\nthese \"minority regions\" as opportunities in SD to reduce bias. To unlock the\npotential, we propose a novel de-biasing method called 'weak guidance,'\ncarefully designed to guide a random noise to the minority regions without\ncompromising semantic integrity. Through analysis and experiments on various\nversions of SD, we demonstrate that our proposed approach effectively reduces\nbias without additional training, achieving both efficiency and preservation of\ncore image generation functionality.",
      "tldr_zh": "本研究重新审视了文本到图像生成模型如 Stable Diffusion 的去偏见（de-biasing）训练，指出现有方法依赖额外训练导致高计算成本和核心功能损害的问题。论文通过分析发现，初始噪声与少数属性形成的“minority regions”可作为减少偏见的潜在机会，并提出“weak guidance”方法，该方法通过引导随机噪声到这些区域，同时保持语义完整性。实验在各种 Stable Diffusion 版本上验证了该方法的有效性，实现偏见减少、计算效率提升和图像生成功能的完整保留。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages; First two authors contributed equally; Accepted at CVPR\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2408.12692v2",
      "published_date": "2024-08-22 19:12:52 UTC",
      "updated_date": "2025-03-27 07:52:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:44:11.453054"
    },
    {
      "arxiv_id": "2408.12682v1",
      "title": "MultiMed: Massively Multimodal and Multitask Medical Understanding",
      "title_zh": "MultiMed：大规模多模态和多任务医疗理解",
      "authors": [
        "Shentong Mo",
        "Paul Pu Liang"
      ],
      "abstract": "Biomedical data is inherently multimodal, consisting of electronic health\nrecords, medical imaging, digital pathology, genome sequencing, wearable\nsensors, and more. The application of artificial intelligence tools to these\nmultifaceted sensing technologies has the potential to revolutionize the\nprognosis, diagnosis, and management of human health and disease. However,\ncurrent approaches to biomedical AI typically only train and evaluate with one\nor a small set of medical modalities and tasks. This limitation hampers the\ndevelopment of comprehensive tools that can leverage the rich interconnected\ninformation across many heterogeneous biomedical sensors. To address this\nchallenge, we present MultiMed, a benchmark designed to evaluate and enable\nlarge-scale learning across a wide spectrum of medical modalities and tasks.\nMultiMed consists of 2.56 million samples across ten medical modalities such as\nmedical reports, pathology, genomics, and protein data, and is structured into\neleven challenging tasks, including disease prognosis, protein structure\nprediction, and medical question answering. Using MultiMed, we conduct\ncomprehensive experiments benchmarking state-of-the-art unimodal, multimodal,\nand multitask models. Our analysis highlights the advantages of training\nlarge-scale medical models across many related modalities and tasks. Moreover,\nMultiMed enables studies of generalization across related medical concepts,\nrobustness to real-world noisy data and distribution shifts, and novel modality\ncombinations to improve prediction performance. MultiMed will be publicly\navailable and regularly updated and welcomes inputs from the community.",
      "tldr_zh": "该研究提出 MultiMed 基准，用于评估和实现大规模跨模态和多任务学习，旨在解决生物医学 AI 仅限于单一或少数 medical modalities 和任务的局限性。MultiMed 包含 2.56 百万样本，覆盖十种医学模态（如 medical reports、pathology、genomics 和 protein data）以及 11 个挑战性任务，包括 disease prognosis、protein structure prediction 和 medical question answering。通过全面实验，比较了 unimodal、multimodal 和 multitask 模型，结果显示跨多种相关模态和任务训练大型医学模型能显著提升泛化能力、鲁棒性以及预测性能。MultiMed 将作为公开数据集定期更新，欢迎社区参与和扩展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12682v1",
      "published_date": "2024-08-22 18:41:36 UTC",
      "updated_date": "2024-08-22 18:41:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:44:24.729604"
    },
    {
      "arxiv_id": "2408.12680v2",
      "title": "Can LLMs Understand Social Norms in Autonomous Driving Games?",
      "title_zh": "LLMs 是否能理解自动驾驶游戏中的社会规范？",
      "authors": [
        "Boxuan Wang",
        "Haonan Duan",
        "Yanhao Feng",
        "Xu Chen",
        "Yongjie Fu",
        "Zhaobin Mo",
        "Xuan Di"
      ],
      "abstract": "Social norm is defined as a shared standard of acceptable behavior in a\nsociety. The emergence of social norms fosters coordination among agents\nwithout any hard-coded rules, which is crucial for the large-scale deployment\nof AVs in an intelligent transportation system. This paper explores the\napplication of LLMs in understanding and modeling social norms in autonomous\ndriving games. We introduce LLMs into autonomous driving games as intelligent\nagents who make decisions according to text prompts. These agents are referred\nto as LLM-based agents. Our framework involves LLM-based agents playing Markov\ngames in a multi-agent system (MAS), allowing us to investigate the emergence\nof social norms among individual agents. We aim to identify social norms by\ndesigning prompts and utilizing LLMs on textual information related to the\nenvironment setup and the observations of LLM-based agents. Using the OpenAI\nChat API powered by GPT-4.0, we conduct experiments to simulate interactions\nand evaluate the performance of LLM-based agents in two driving scenarios:\nunsignalized intersection and highway platoon. The results show that LLM-based\nagents can handle dynamically changing environments in Markov games, and social\nnorms evolve among LLM-based agents in both scenarios. In the intersection\ngame, LLM-based agents tend to adopt a conservative driving policy when facing\na potential car crash. The advantage of LLM-based agents in games lies in their\nstrong operability and analyzability, which facilitate experimental design.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）在自动驾驶游戏中理解和建模社会规范（social norms）的能力，这些规范是促进代理协调的关键因素，而无需硬编码规则。研究引入LLMs作为智能代理（LLM-based agents），让它们在多代理系统（MAS）的Markov games中根据文本提示做出决策，并通过设计提示和GPT-4.0进行实验，模拟无信号灯十字路口和高高速公路车队场景。结果表明，LLM-based agents能适应动态环境，社会规范在代理间演化，如在十字路口游戏中采用保守驾驶策略以避免碰撞，且这种方法提升了实验的可操作性和可分析性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12680v2",
      "published_date": "2024-08-22 18:39:00 UTC",
      "updated_date": "2024-09-01 05:24:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:44:37.350647"
    },
    {
      "arxiv_id": "2408.12673v3",
      "title": "Enhancing Transferability of Adversarial Attacks with GE-AdvGAN+: A Comprehensive Framework for Gradient Editing",
      "title_zh": "通过 GE-AdvGAN",
      "authors": [
        "Zhibo Jin",
        "Jiayu Zhang",
        "Zhiyu Zhu",
        "Chenyu Zhang",
        "Jiahao Huang",
        "Jianlong Zhou",
        "Fang Chen"
      ],
      "abstract": "Transferable adversarial attacks pose significant threats to deep neural\nnetworks, particularly in black-box scenarios where internal model information\nis inaccessible. Studying adversarial attack methods helps advance the\nperformance of defense mechanisms and explore model vulnerabilities. These\nmethods can uncover and exploit weaknesses in models, promoting the development\nof more robust architectures. However, current methods for transferable attacks\noften come with substantial computational costs, limiting their deployment and\napplication, especially in edge computing scenarios. Adversarial generative\nmodels, such as Generative Adversarial Networks (GANs), are characterized by\ntheir ability to generate samples without the need for retraining after an\ninitial training phase. GE-AdvGAN, a recent method for transferable adversarial\nattacks, is based on this principle. In this paper, we propose a novel general\nframework for gradient editing-based transferable attacks, named GE-AdvGAN+,\nwhich integrates nearly all mainstream attack methods to enhance\ntransferability while significantly reducing computational resource\nconsumption. Our experiments demonstrate the compatibility and effectiveness of\nour framework. Compared to the baseline AdvGAN, our best-performing method,\nGE-AdvGAN++, achieves an average ASR improvement of 47.8. Additionally, it\nsurpasses the latest competing algorithm, GE-AdvGAN, with an average ASR\nincrease of 5.9. The framework also exhibits enhanced computational efficiency,\nachieving 2217.7 FPS, outperforming traditional methods such as BIM and\nMI-FGSM. The implementation code for our GE-AdvGAN+ framework is available at\nhttps://github.com/GEAdvGANP",
      "tldr_zh": "本研究针对可转移对抗攻击在黑盒场景下的计算成本高问题，提出了一种基于梯度编辑的通用框架 GE-AdvGAN+，该框架整合了几乎所有主流攻击方法，如 GANs，提升攻击的可转移性并显著降低资源消耗。GE-AdvGAN+ 通过优化梯度编辑机制，避免了反复训练的需求，从而提高了整体效率。实验结果显示，与 AdvGAN 相比，GE-AdvGAN++ 平均 ASR 提升了 47.8%，并比 GE-AdvGAN 提高了 5.9%；此外，该框架的计算效率达到 2217.7 FPS，优于传统方法如 BIM 和 MI-FGSM。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12673v3",
      "published_date": "2024-08-22 18:26:31 UTC",
      "updated_date": "2024-09-20 11:07:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:44:49.321707"
    },
    {
      "arxiv_id": "2408.12670v1",
      "title": "Leveraging Information Consistency in Frequency and Spatial Domain for Adversarial Attacks",
      "title_zh": "利用频率域和空间域的信息一致性进行对抗攻击",
      "authors": [
        "Zhibo Jin",
        "Jiayu Zhang",
        "Zhiyu Zhu",
        "Xinyi Wang",
        "Yiyun Huang",
        "Huaming Chen"
      ],
      "abstract": "Adversarial examples are a key method to exploit deep neural networks. Using\ngradient information, such examples can be generated in an efficient way\nwithout altering the victim model. Recent frequency domain transformation has\nfurther enhanced the transferability of such adversarial examples, such as\nspectrum simulation attack. In this work, we investigate the effectiveness of\nfrequency domain-based attacks, aligning with similar findings in the spatial\ndomain. Furthermore, such consistency between the frequency and spatial domains\nprovides insights into how gradient-based adversarial attacks induce\nperturbations across different domains, which is yet to be explored. Hence, we\npropose a simple, effective, and scalable gradient-based adversarial attack\nalgorithm leveraging the information consistency in both frequency and spatial\ndomains. We evaluate the algorithm for its effectiveness against different\nmodels. Extensive experiments demonstrate that our algorithm achieves\nstate-of-the-art results compared to other gradient-based algorithms. Our code\nis available at: https://github.com/LMBTough/FSA.",
      "tldr_zh": "本研究探讨了对抗攻击(adversarial attacks)中频域(frequency domain)和空间域(spatial domain)信息一致性的作用，以提升攻击的有效性和可转移性。作者提出了一种简单、有效且可扩展的梯度-based 攻击算法，通过整合频域和空间域的梯度信息，优化对抗样本的生成过程。实验结果显示，该算法在多种模型上比其他梯度-based 算法取得了最先进(state-of-the-art)的性能，并提供了开源代码以供验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by PRICAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12670v1",
      "published_date": "2024-08-22 18:24:08 UTC",
      "updated_date": "2024-08-22 18:24:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:44:57.855875"
    },
    {
      "arxiv_id": "2408.12666v2",
      "title": "Benchmarking Counterfactual Interpretability in Deep Learning Models for Time Series Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwen Kan",
        "Shahbaz Rezaei",
        "Xin Liu"
      ],
      "abstract": "The popularity of deep learning methods in the time series domain boosts\ninterest in interpretability studies, including counterfactual (CF) methods. CF\nmethods identify minimal changes in instances to alter the model predictions.\nDespite extensive research, no existing work benchmarks CF methods in the time\nseries domain. Additionally, the results reported in the literature are\ninconclusive due to the limited number of datasets and inadequate metrics. In\nthis work, we redesign quantitative metrics to accurately capture desirable\ncharacteristics in CFs. We specifically redesign the metrics for sparsity and\nplausibility and introduce a new metric for consistency. Combined with\nvalidity, generation time, and proximity, we form a comprehensive metric set.\nWe systematically benchmark 6 different CF methods on 20 univariate datasets\nand 10 multivariate datasets with 3 different classifiers. Results indicate\nthat the performance of CF methods varies across metrics and among different\nmodels. Finally, we provide case studies and a guideline for practical usage.",
      "tldr_zh": "本研究针对深度学习模型在时间序列分类中的 Counterfactual (CF) 可解释性方法进行了首次系统基准测试，旨在解决现有研究中数据集和指标不足的问题。作者重新设计了 sparsity 和 plausibility 指标，并引入新的 consistency 指标，与 validity、generation time 和 proximity 一起形成一个全面的指标集。随后，在 20 个单变量数据集和 10 个多变量数据集上，使用 3 个不同分类器对 6 个 CF 方法进行了基准测试，结果显示这些方法的性能在不同指标和模型之间存在显著差异。最后，通过案例研究和实用指南，为 CF 方法的应用提供了指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 27 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12666v2",
      "published_date": "2024-08-22 18:17:26 UTC",
      "updated_date": "2024-10-10 02:52:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:45:11.538728"
    },
    {
      "arxiv_id": "2408.12664v2",
      "title": "Multilevel Interpretability Of Artificial Neural Networks: Leveraging Framework And Methods From Neuroscience",
      "title_zh": "翻译失败",
      "authors": [
        "Zhonghao He",
        "Jascha Achterberg",
        "Katie Collins",
        "Kevin Nejad",
        "Danyal Akarca",
        "Yinzhu Yang",
        "Wes Gurnee",
        "Ilia Sucholutsky",
        "Yuhan Tang",
        "Rebeca Ianov",
        "George Ogden",
        "Chole Li",
        "Kai Sandbrink",
        "Stephen Casper",
        "Anna Ivanova",
        "Grace W. Lindsay"
      ],
      "abstract": "As deep learning systems are scaled up to many billions of parameters,\nrelating their internal structure to external behaviors becomes very\nchallenging. Although daunting, this problem is not new: Neuroscientists and\ncognitive scientists have accumulated decades of experience analyzing a\nparticularly complex system - the brain. In this work, we argue that\ninterpreting both biological and artificial neural systems requires analyzing\nthose systems at multiple levels of analysis, with different analytic tools for\neach level. We first lay out a joint grand challenge among scientists who study\nthe brain and who study artificial neural networks: understanding how\ndistributed neural mechanisms give rise to complex cognition and behavior. We\nthen present a series of analytical tools that can be used to analyze\nbiological and artificial neural systems, organizing those tools according to\nMarr's three levels of analysis: computation/behavior,\nalgorithm/representation, and implementation. Overall, the multilevel\ninterpretability framework provides a principled way to tackle neural system\ncomplexity; links structure, computation, and behavior; clarifies assumptions\nand research priorities at each level; and paves the way toward a unified\neffort for understanding intelligent systems, may they be biological or\nartificial.",
      "tldr_zh": "本研究探讨了深度学习系统的复杂性问题，提出将神经科学和认知科学的框架应用于人工神经网络的多层次解释方法，以理解分布式神经机制如何产生复杂认知和行为。作者强调采用 Marr 的三个分析层次——computation/behavior（计算/行为）、algorithm/representation（算法/表示）和implementation（实现）——来组织分析工具，从而处理生物和人工神经系统的相似挑战。该框架不仅链接了结构、计算和行为，还澄清了各层次的假设和研究优先级，推动了生物与人工智能系统的统一研究努力。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12664v2",
      "published_date": "2024-08-22 18:17:20 UTC",
      "updated_date": "2024-08-26 02:35:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:45:32.166805"
    },
    {
      "arxiv_id": "2408.12659v1",
      "title": "Disentangled Structural and Featural Representation for Task-Agnostic Graph Valuation",
      "title_zh": "针对任务无关图估值的解耦结构和特征表示",
      "authors": [
        "Ali Falahati",
        "Mohammad Mohammadi Amiri"
      ],
      "abstract": "With the emergence of data marketplaces, the demand for methods to assess the\nvalue of data has increased significantly. While numerous techniques have been\nproposed for this purpose, none have specifically addressed graphs as the main\ndata modality. Graphs are widely used across various fields, ranging from\nchemical molecules to social networks. In this study, we break down graphs into\ntwo main components: structural and featural, and we focus on evaluating data\nwithout relying on specific task-related metrics, making it applicable in\npractical scenarios where validation requirements may be lacking. We introduce\na novel framework called blind message passing, which aligns the seller's and\nbuyer's graphs using a shared node permutation based on graph matching. This\nallows us to utilize the graph Wasserstein distance to quantify the differences\nin the structural distribution of graph datasets, called the structural\ndisparities. We then consider featural aspects of buyers' and sellers' graphs\nfor data valuation and capture their statistical similarities and differences,\nreferred to as relevance and diversity, respectively. Our approach ensures that\nbuyers and sellers remain unaware of each other's datasets. Our experiments on\nreal datasets demonstrate the effectiveness of our approach in capturing the\nrelevance, diversity, and structural disparities of seller data for buyers,\nparticularly in graph-based data valuation scenarios.",
      "tldr_zh": "该论文提出了一种 task-agnostic 的图数据估值方法，将图分解为结构（structural）和特征（featural）组件，以评估数据市场中的图数据价值，而不依赖特定任务指标。论文引入了 blind message passing 框架，通过基于图匹配的节点排列对齐买卖双方的图，并利用 graph Wasserstein distance 量化结构差异，同时评估特征方面的相关性（relevance）和多样性（diversity），确保数据隐私。实验结果显示，该方法在真实数据集上有效捕捉了卖家数据的相关性、多样性和结构差异，适用于图数据估值场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12659v1",
      "published_date": "2024-08-22 18:05:41 UTC",
      "updated_date": "2024-08-22 18:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:45:35.467866"
    },
    {
      "arxiv_id": "2408.12658v2",
      "title": "Hierarchical Generative Modeling of Melodic Vocal Contours in Hindustani Classical Music",
      "title_zh": "翻译失败",
      "authors": [
        "Nithya Shikarpur",
        "Krishna Maneesha Dendukuri",
        "Yusong Wu",
        "Antoine Caillon",
        "Cheng-Zhi Anna Huang"
      ],
      "abstract": "Hindustani music is a performance-driven oral tradition that exhibits the\nrendition of rich melodic patterns. In this paper, we focus on generative\nmodeling of singers' vocal melodies extracted from audio recordings, as the\nvoice is musically prominent within the tradition. Prior generative work in\nHindustani music models melodies as coarse discrete symbols which fails to\ncapture the rich expressive melodic intricacies of singing. Thus, we propose to\nuse a finely quantized pitch contour, as an intermediate representation for\nhierarchical audio modeling. We propose GaMaDHaNi, a modular two-level\nhierarchy, consisting of a generative model on pitch contours, and a pitch\ncontour to audio synthesis model. We compare our approach to non-hierarchical\naudio models and hierarchical models that use a self-supervised intermediate\nrepresentation, through a listening test and qualitative analysis. We also\nevaluate audio model's ability to faithfully represent the pitch contour input\nusing Pearson correlation coefficient. By using pitch contours as an\nintermediate representation, we show that our model may be better equipped to\nlisten and respond to musicians in a human-AI collaborative setting by\nhighlighting two potential interaction use cases (1) primed generation, and (2)\ncoarse pitch conditioning.",
      "tldr_zh": "本研究针对 Hindustani Classical Music 中的歌手声线旋律建模问题，提出使用精细量化化的 pitch contour 作为中间表示，以捕捉演唱中的丰富表达细节。研究引入 GaMaDHaNi 框架，一个模块化的两级层次结构，包括 pitch contour 生成模型和音高轮廓到音频合成的模型。相比非层次音频模型和使用自监督中间表示的层次模型，通过听力测试、定性分析以及 Pearson correlation coefficient 评估，结果显示该方法在忠实再现旋律方面表现出色。最终，该框架增强了模型在人机协作中的潜力，支持 primed generation 和 coarse pitch conditioning 等交互应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at International Society for Music Information Retrieval\n  (ISMIR) 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12658v2",
      "published_date": "2024-08-22 18:04:29 UTC",
      "updated_date": "2024-08-26 13:02:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:45:48.771682"
    },
    {
      "arxiv_id": "2408.12598v3",
      "title": "ND-SDF: Learning Normal Deflection Fields for High-Fidelity Indoor Reconstruction",
      "title_zh": "ND-SDF：学习法线偏转场以实现高保真室内",
      "authors": [
        "Ziyu Tang",
        "Weicai Ye",
        "Yifan Wang",
        "Di Huang",
        "Hujun Bao",
        "Tong He",
        "Guofeng Zhang"
      ],
      "abstract": "Neural implicit reconstruction via volume rendering has demonstrated its\neffectiveness in recovering dense 3D surfaces. However, it is non-trivial to\nsimultaneously recover meticulous geometry and preserve smoothness across\nregions with differing characteristics. To address this issue, previous methods\ntypically employ geometric priors, which are often constrained by the\nperformance of the prior models. In this paper, we propose ND-SDF, which learns\na Normal Deflection field to represent the angular deviation between the scene\nnormal and the prior normal. Unlike previous methods that uniformly apply\ngeometric priors on all samples, introducing significant bias in accuracy, our\nproposed normal deflection field dynamically learns and adapts the utilization\nof samples based on their specific characteristics, thereby improving both the\naccuracy and effectiveness of the model. Our method not only obtains smooth\nweakly textured regions such as walls and floors but also preserves the\ngeometric details of complex structures. In addition, we introduce a novel ray\nsampling strategy based on the deflection angle to facilitate the unbiased\nrendering process, which significantly improves the quality and accuracy of\nintricate surfaces, especially on thin structures. Consistent improvements on\nvarious challenging datasets demonstrate the superiority of our method.",
      "tldr_zh": "本文提出 ND-SDF 方法，通过学习 Normal Deflection field 来表示场景法线与先验法线之间的角度偏差，从而提升神经隐式重建（neural implicit reconstruction via volume rendering）的精度和平滑性。该方法动态适应样本特性，避免了传统几何先验（geometric priors）的偏差，确保弱纹理区域如墙壁和地板保持平滑，同时保留复杂结构的几何细节。此外，ND-SDF 引入基于偏转角度的射线采样策略，显著提高了薄结构等复杂表面的重建质量，并在各种挑战数据集上表现出一致的改进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12598v3",
      "published_date": "2024-08-22 17:59:01 UTC",
      "updated_date": "2025-04-08 15:24:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:46:02.682973"
    },
    {
      "arxiv_id": "2408.12591v2",
      "title": "Differentiable Logic Programming for Distant Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Akihiro Takemura",
        "Katsumi Inoue"
      ],
      "abstract": "We introduce a new method for integrating neural networks with logic\nprogramming in Neural-Symbolic AI (NeSy), aimed at learning with distant\nsupervision, in which direct labels are unavailable. Unlike prior methods, our\napproach does not depend on symbolic solvers for reasoning about missing\nlabels. Instead, it evaluates logical implications and constraints in a\ndifferentiable manner by embedding both neural network outputs and logic\nprograms into matrices. This method facilitates more efficient learning under\ndistant supervision. We evaluated our approach against existing methods while\nmaintaining a constant volume of training data. The findings indicate that our\nmethod not only matches or exceeds the accuracy of other methods across various\ntasks but also speeds up the learning process. These results highlight the\npotential of our approach to enhance both accuracy and learning efficiency in\nNeSy applications.",
      "tldr_zh": "这篇论文提出了一种可微分逻辑编程方法，用于 Neural-Symbolic AI (NeSy) 中的远监督学习，以处理缺乏直接标签的数据。该方法不依赖于符号求解器，而是通过将神经网络输出和逻辑程序嵌入矩阵中，以可微分方式评估逻辑含义和约束，从而提升学习效率。实验结果表明，该方法在保持训练数据不变的情况下，准确率匹配或超过现有方法，并显著加速了学习过程。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Updated Figure 1 and fixed the overlapping caption issue. 11 pages\n  including the appendix. To be published in ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12591v2",
      "published_date": "2024-08-22 17:55:52 UTC",
      "updated_date": "2024-08-25 06:40:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:46:13.692839"
    },
    {
      "arxiv_id": "2408.12590v2",
      "title": "xGen-VideoSyn-1: High-fidelity Text-to-Video Synthesis with Compressed Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Can Qin",
        "Congying Xia",
        "Krithika Ramakrishnan",
        "Michael Ryoo",
        "Lifu Tu",
        "Yihao Feng",
        "Manli Shu",
        "Honglu Zhou",
        "Anas Awadalla",
        "Jun Wang",
        "Senthil Purushwalkam",
        "Le Xue",
        "Yingbo Zhou",
        "Huan Wang",
        "Silvio Savarese",
        "Juan Carlos Niebles",
        "Zeyuan Chen",
        "Ran Xu",
        "Caiming Xiong"
      ],
      "abstract": "We present xGen-VideoSyn-1, a text-to-video (T2V) generation model capable of\nproducing realistic scenes from textual descriptions. Building on recent\nadvancements, such as OpenAI's Sora, we explore the latent diffusion model\n(LDM) architecture and introduce a video variational autoencoder (VidVAE).\nVidVAE compresses video data both spatially and temporally, significantly\nreducing the length of visual tokens and the computational demands associated\nwith generating long-sequence videos. To further address the computational\ncosts, we propose a divide-and-merge strategy that maintains temporal\nconsistency across video segments. Our Diffusion Transformer (DiT) model\nincorporates spatial and temporal self-attention layers, enabling robust\ngeneralization across different timeframes and aspect ratios. We have devised a\ndata processing pipeline from the very beginning and collected over 13M\nhigh-quality video-text pairs. The pipeline includes multiple steps such as\nclipping, text detection, motion estimation, aesthetics scoring, and dense\ncaptioning based on our in-house video-LLM model. Training the VidVAE and DiT\nmodels required approximately 40 and 642 H100 days, respectively. Our model\nsupports over 14-second 720p video generation in an end-to-end way and\ndemonstrates competitive performance against state-of-the-art T2V models.",
      "tldr_zh": "我们提出了xGen-VideoSyn-1，一种高保真文本到视频(T2V)生成模型，基于Latent Diffusion Model (LDM)架构，引入Video Variational Autoencoder (VidVAE)来实现空间和时间压缩，显著降低长序列视频的计算需求。模型采用divide-and-merge策略和Diffusion Transformer (DiT)模型，结合空间及时间自注意力层，确保视频段的temporal consistency。研究团队构建了一个数据处理管道，收集了超过13M高质量视频-文本对，并通过约40和642 H100天的训练，使xGen-VideoSyn-1支持端到端生成超过14秒的720p视频，并在性能上与最先进T2V模型竞争。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV24 AI4VA",
      "pdf_url": "http://arxiv.org/pdf/2408.12590v2",
      "published_date": "2024-08-22 17:55:22 UTC",
      "updated_date": "2024-08-31 05:12:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:46:28.168362"
    },
    {
      "arxiv_id": "2408.12638v1",
      "title": "AI-driven Transformer Model for Fault Prediction in Non-Linear Dynamic Automotive System",
      "title_zh": "AI驱动的Transformer模型用于非线性动态汽车系统的故障预测",
      "authors": [
        "Priyanka Kumar"
      ],
      "abstract": "Fault detection in automotive engine systems is one of the most promising\nresearch areas. Several works have been done in the field of model-based fault\ndiagnosis. Many researchers have discovered more advanced statistical methods\nand algorithms for better fault detection on any automotive dynamic engine\nsystem. The gas turbines/diesel engines produce highly complex and huge data\nwhich are highly non-linear. So, researchers should come up with an automated\nsystem that is more resilient and robust enough to handle this huge, complex\ndata in highly non-linear dynamic automotive systems. Here, I present an\nAI-based fault classification and prediction model in the diesel engine that\ncan be applied to any highly non-linear dynamic automotive system. The main\ncontribution of this paper is the AI-based Transformer fault classification and\nprediction model in the diesel engine concerning the worldwide harmonic light\nvehicle test procedure (WLTP) driving cycle. This model used 27 input\ndimensions, 64 hidden dimensions with 2 layers, and 9 heads to create a\nclassifier with 12 output heads (one for fault-free data and 11 different fault\ntypes). This model was trained on the UTSA Arc High-Performance Compute (HPC)\ncluster with 5 NVIDIA V100 GPUs, 40-core CPUs, and 384GB RAM and achieved 70.01\n% accuracy on a held test set.",
      "tldr_zh": "这篇论文提出了一种AI驱动的Transformer模型，用于高度非线性动态汽车系统的故障预测和分类，针对柴油引擎的复杂数据问题。模型的主要贡献是基于全球统一轻型车辆测试程序(WLTP)驾驶周期，设计了一个包含27输入维度、64隐藏维度、2层和9头的Transformer结构，能够识别12种输出类别（包括无故障和11种故障类型）。在UTSA Arc High-Performance Compute (HPC)集群上训练，使用5个NVIDIA V100 GPUs，该模型在测试集上实现了70.01%的准确率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12638v1",
      "published_date": "2024-08-22 17:53:32 UTC",
      "updated_date": "2024-08-22 17:53:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:46:37.968104"
    },
    {
      "arxiv_id": "2408.12637v1",
      "title": "Building and better understanding vision-language models: insights and future directions",
      "title_zh": "构建和更好地理解视觉语言模型：见解和未来方向",
      "authors": [
        "Hugo Laurençon",
        "Andrés Marafioti",
        "Victor Sanh",
        "Léo Tronchon"
      ],
      "abstract": "The field of vision-language models (VLMs), which take images and texts as\ninputs and output texts, is rapidly evolving and has yet to reach consensus on\nseveral key aspects of the development pipeline, including data, architecture,\nand training methods. This paper can be seen as a tutorial for building a VLM.\nWe begin by providing a comprehensive overview of the current state-of-the-art\napproaches, highlighting the strengths and weaknesses of each, addressing the\nmajor challenges in the field, and suggesting promising research directions for\nunderexplored areas. We then walk through the practical steps to build\nIdefics3-8B, a powerful VLM that significantly outperforms its predecessor\nIdefics2-8B, while being trained efficiently, exclusively on open datasets, and\nusing a straightforward pipeline. These steps include the creation of Docmatix,\na dataset for improving document understanding capabilities, which is 240 times\nlarger than previously available datasets. We release the model along with the\ndatasets created for its training.",
      "tldr_zh": "这篇论文概述了视觉语言模型 (VLMs) 的构建管道，包括数据、架构和训练方法，并讨论了当前领域的主要挑战、优势与弱点，同时提出未来研究方向。作者提供了一个实用教程，详细说明了构建 Idefics3-8B 的步骤，该模型在性能上显著优于其前身 Idefics2-8B，同时采用高效训练方法并仅使用开源数据集。论文还介绍了创建 Docmatix 数据集来提升文档理解能力，该数据集比之前可用数据集大 240 倍，并公开发布了模型及其训练数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12637v1",
      "published_date": "2024-08-22 17:47:24 UTC",
      "updated_date": "2024-08-22 17:47:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:46:52.337891"
    },
    {
      "arxiv_id": "2408.12581v1",
      "title": "Identifying the Best Arm in the Presence of Global Environment Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Phurinut Srisawad",
        "Juergen Branke",
        "Long Tran-Thanh"
      ],
      "abstract": "This paper formulates a new Best-Arm Identification problem in the\nnon-stationary stochastic bandits setting, where the means of all arms are\nshifted in the same way due to a global influence of the environment. The aim\nis to identify the unique best arm across environmental change given a fixed\ntotal budget. While this setting can be regarded as a special case of\nAdversarial Bandits or Corrupted Bandits, we demonstrate that existing\nsolutions tailored to those settings do not fully utilise the nature of this\nglobal influence, and thus, do not work well in practice (despite their\ntheoretical guarantees). To overcome this issue, in this paper we develop a\nnovel selection policy that is consistent and robust in dealing with global\nenvironmental shifts. We then propose an allocation policy, LinLUCB, which\nexploits information about global shifts across all arms in each environment.\nEmpirical tests depict a significant improvement in our policies against other\nexisting methods.",
      "tldr_zh": "本论文提出了一种新的 Best-Arm Identification 问题，针对非-stationary stochastic bandits 设置，其中所有 arms 的均值因全局环境影响而统一偏移，目标是在固定总预算下识别唯一的最佳 arm。不同于 Adversarial Bandits 或 Corrupted Bandits 的现有解决方案，该研究开发了一个鲁棒且一致的 selection policy，以及一个利用全局偏移信息的 allocation policy LinLUCB，以更好地处理环境变化。实证测试结果显示，该方法相较于现有方法实现了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Extended version of the paper accepted at the 27th European\n  Conference on Artificial Intelligence (ECAI 2024); Paper ID: M1125",
      "pdf_url": "http://arxiv.org/pdf/2408.12581v1",
      "published_date": "2024-08-22 17:47:01 UTC",
      "updated_date": "2024-08-22 17:47:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:47:01.551901"
    },
    {
      "arxiv_id": "2408.12579v1",
      "title": "RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohan Wang",
        "Xiaoyan Yang",
        "Yuqi Zhu",
        "Yue Shen",
        "Jian Wang",
        "Peng Wei",
        "Lei Liang",
        "Jinjie Gu",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "Large Language Models (LLMs) like GPT-4, MedPaLM-2, and Med-Gemini achieve\nperformance competitively with human experts across various medical benchmarks.\nHowever, they still face challenges in making professional diagnoses akin to\nphysicians, particularly in efficiently gathering patient information and\nreasoning the final diagnosis. To this end, we introduce the RuleAlign\nframework, designed to align LLMs with specific diagnostic rules. We develop a\nmedical dialogue dataset comprising rule-based communications between patients\nand physicians and design an alignment learning approach through preference\nlearning. Experimental results demonstrate the effectiveness of the proposed\napproach. We hope that our work can serve as an inspiration for exploring the\npotential of LLMs as AI physicians.",
      "tldr_zh": "大语言模型 (LLMs) 如 GPT-4 和 MedPaLM-2 在医疗基准上已接近人类专家水平，但仍面临高效收集患者信息和推理诊断的挑战。为解决此问题，本文提出 RuleAlign 框架，通过开发一个包含基于规则的患者-医生对话的医疗数据集，并采用偏好学习 (preference learning) 的对齐学习方法，使 LLMs 更好地遵守诊断规则。实验结果验证了该框架的有效性，并为探索 LLMs 作为 AI 医生的潜力提供了新灵感。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Ongoing work",
      "pdf_url": "http://arxiv.org/pdf/2408.12579v1",
      "published_date": "2024-08-22 17:44:40 UTC",
      "updated_date": "2024-08-22 17:44:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:47:13.858614"
    },
    {
      "arxiv_id": "2408.12578v2",
      "title": "A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language",
      "title_zh": "翻译失败",
      "authors": [
        "Ekdeep Singh Lubana",
        "Kyogo Kawaguchi",
        "Robert P. Dick",
        "Hidenori Tanaka"
      ],
      "abstract": "Increase in data, size, or compute can lead to sudden learning of specific\ncapabilities by a neural network -- a phenomenon often called \"emergence''.\nBeyond scientific understanding, establishing the causal factors underlying\nsuch emergent capabilities is crucial to enable risk regulation frameworks for\nAI. In this work, we seek inspiration from study of emergent properties in\nother fields and propose a phenomenological definition for the concept in the\ncontext of neural networks. Our definition implicates the acquisition of\ngeneral structures underlying the data-generating process as a cause of sudden\nperformance growth for specific, narrower tasks. We empirically investigate\nthis definition by proposing an experimental system grounded in a\ncontext-sensitive formal language and find that Transformers trained to perform\ntasks on top of strings from this language indeed exhibit emergent\ncapabilities. Specifically, we show that once the language's underlying grammar\nand context-sensitivity inducing structures are learned by the model,\nperformance on narrower tasks suddenly begins to improve. We then analogize our\nnetwork's learning dynamics with the process of percolation on a bipartite\ngraph, establishing a formal phase transition model that predicts the shift in\nthe point of emergence observed in our experiments when changing the data\nstructure. Overall, our experimental and theoretical frameworks yield a step\ntowards better defining, characterizing, and predicting emergence in neural\nnetworks.",
      "tldr_zh": "这篇论文探讨了神经网络中emergence现象，即数据、规模或计算增加导致特定能力突然出现，并提出一个现象学定义，将其归因于模型获取数据生成过程的通用结构。研究者通过训练Transformers处理一个上下文敏感formal language的实验系统，观察到一旦模型学习了语言的底层语法和context-sensitivity结构，特定任务的性能就会突然提升。作者将网络的学习动态类比为双部图上的percolation过程，建立一个正式的相变模型，以预测emergence的转变点。总体上，这为定义、表征和预测神经网络中的emergence提供了新的理论和实验框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2408.12578v2",
      "published_date": "2024-08-22 17:44:22 UTC",
      "updated_date": "2024-09-07 20:10:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:47:25.882953"
    },
    {
      "arxiv_id": "2408.12575v2",
      "title": "Enhanced Parking Perception by Multi-Task Fisheye Cross-view Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Antonyo Musabini",
        "Ivan Novikov",
        "Sana Soula",
        "Christel Leonet",
        "Lihao Wang",
        "Rachid Benmokhtar",
        "Fabian Burger",
        "Thomas Boulay",
        "Xavier Perrotton"
      ],
      "abstract": "Current parking area perception algorithms primarily focus on detecting\nvacant slots within a limited range, relying on error-prone homographic\nprojection for both labeling and inference. However, recent advancements in\nAdvanced Driver Assistance System (ADAS) require interaction with end-users\nthrough comprehensive and intelligent Human-Machine Interfaces (HMIs). These\ninterfaces should present a complete perception of the parking area going from\ndistinguishing vacant slots' entry lines to the orientation of other parked\nvehicles. This paper introduces Multi-Task Fisheye Cross View Transformers (MT\nF-CVT), which leverages features from a four-camera fisheye Surround-view\nCamera System (SVCS) with multihead attentions to create a detailed Bird-Eye\nView (BEV) grid feature map. Features are processed by both a segmentation\ndecoder and a Polygon-Yolo based object detection decoder for parking slots and\nvehicles. Trained on data labeled using LiDAR, MT F-CVT positions objects\nwithin a 25m x 25m real open-road scenes with an average error of only 20 cm.\nOur larger model achieves an F-1 score of 0.89. Moreover the smaller model\noperates at 16 fps on an Nvidia Jetson Orin embedded board, with similar\ndetection results to the larger one. MT F-CVT demonstrates robust\ngeneralization capability across different vehicles and camera rig\nconfigurations. A demo video from an unseen vehicle and camera rig is available\nat: https://streamable.com/jjw54x.",
      "tldr_zh": "本文提出 Multi-Task Fisheye Cross-view Transformers (MT F-CVT)，一种增强停车感知的多任务框架，利用四个鱼眼相机组成的环视系统（SVCS）和多头注意力机制，生成详细的 Bird-Eye View (BEV) 网格特征图，并结合分割解码器和基于 Polygon-Yolo 的物体检测解码器，实现对停车位和车辆的精确识别。相比传统依赖同源投影的算法，MT F-CVT 在用 LiDAR 标注的数据上训练，能在 25m x 25m 真实场景中将物体定位平均误差控制在 20 cm，并达到 F-1 score 0.89。实验显示，较小模型在 Nvidia Jetson Orin 嵌入式板上以 16 fps 运行，且在不同车辆和相机配置下表现出强劲的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper is a preprint of a paper submitted to the 26th Irish\n  Machine Vision and Image Processing Conference (IMVIP 2024). If accepted, the\n  copy of record will be available at IET Digital Library",
      "pdf_url": "http://arxiv.org/pdf/2408.12575v2",
      "published_date": "2024-08-22 17:42:16 UTC",
      "updated_date": "2024-09-30 13:30:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:47:40.525939"
    },
    {
      "arxiv_id": "2408.12574v4",
      "title": "MuMA-ToM: Multi-modal Multi-Agent Theory of Mind",
      "title_zh": "MuMA-ToM：多模态多智能体心智理论",
      "authors": [
        "Haojun Shi",
        "Suyu Ye",
        "Xinyu Fang",
        "Chuanyang Jin",
        "Leyla Isik",
        "Yen-Ling Kuo",
        "Tianmin Shu"
      ],
      "abstract": "Understanding people's social interactions in complex real-world scenarios\noften relies on intricate mental reasoning. To truly understand how and why\npeople interact with one another, we must infer the underlying mental states\nthat give rise to the social interactions, i.e., Theory of Mind reasoning in\nmulti-agent interactions. Additionally, social interactions are often\nmulti-modal -- we can watch people's actions, hear their conversations, and/or\nread about their past behaviors. For AI systems to successfully and safely\ninteract with people in real-world environments, they also need to understand\npeople's mental states as well as their inferences about each other's mental\nstates based on multi-modal information about their interactions. For this, we\nintroduce MuMA-ToM, a Multi-modal Multi-Agent Theory of Mind benchmark.\nMuMA-ToM is the first multi-modal Theory of Mind benchmark that evaluates\nmental reasoning in embodied multi-agent interactions. In MuMA-ToM, we provide\nvideo and text descriptions of people's multi-modal behavior in realistic\nhousehold environments. Based on the context, we then ask questions about\npeople's goals, beliefs, and beliefs about others' goals. We validated MuMA-ToM\nin a human experiment and provided a human baseline. We also proposed a novel\nmulti-modal, multi-agent ToM model, LIMP (Language model-based Inverse\nMulti-agent Planning). Our experimental results show that LIMP significantly\noutperforms state-of-the-art methods, including large multi-modal models (e.g.,\nGPT-4o, Gemini-1.5 Pro) and a recent multi-modal ToM model, BIP-ALM.",
      "tldr_zh": "该研究探讨了多智能体 Theory of Mind (ToM) 推理，以理解人们在复杂现实场景中的社会互动，强调基于多模态信息（如视频和文本）推断目标、信念及对他人信念。论文引入 MuMA-ToM，这是一个首创的多模态多智能体 ToM 基准，通过提供现实家庭环境中的行为描述和相关问题来评估心理推理，并提供了人类实验基线。为此，研究提出了一种新模型 LIMP (Language model-based Inverse Multi-agent Planning)，实验结果显示 LIMP 显著优于现有方法，包括 GPT-4o、Gemini-1.5 Pro 和 BIP-ALM 等大型模型。总的来说，该工作为 AI 系统在真实环境中理解和安全互动奠定了基础。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI-25 (Oral). Project website:\n  https://scai.cs.jhu.edu/projects/MuMA-ToM/ Code:\n  https://github.com/SCAI-JHU/MuMA-ToM",
      "pdf_url": "http://arxiv.org/pdf/2408.12574v4",
      "published_date": "2024-08-22 17:41:45 UTC",
      "updated_date": "2025-01-23 16:31:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:47:50.665944"
    },
    {
      "arxiv_id": "2408.12568v2",
      "title": "Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune CNNs and Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Sayed Mohammad Vakilzadeh Hatefi",
        "Maximilian Dreyer",
        "Reduan Achtibat",
        "Thomas Wiegand",
        "Wojciech Samek",
        "Sebastian Lapuschkin"
      ],
      "abstract": "To solve ever more complex problems, Deep Neural Networks are scaled to\nbillions of parameters, leading to huge computational costs. An effective\napproach to reduce computational requirements and increase efficiency is to\nprune unnecessary components of these often over-parameterized networks.\nPrevious work has shown that attribution methods from the field of eXplainable\nAI serve as effective means to extract and prune the least relevant network\ncomponents in a few-shot fashion. We extend the current state by proposing to\nexplicitly optimize hyperparameters of attribution methods for the task of\npruning, and further include transformer-based networks in our analysis. Our\napproach yields higher model compression rates of large transformer- and\nconvolutional architectures (VGG, ResNet, ViT) compared to previous works,\nwhile still attaining high performance on ImageNet classification tasks. Here,\nour experiments indicate that transformers have a higher degree of\nover-parameterization compared to convolutional neural networks. Code is\navailable at https://github.com/erfanhatefi/Pruning-by-eXplaining-in-PyTorch.",
      "tldr_zh": "这篇论文重新审视了基于解释的神经网络修剪方法，提出通过优化 attribution methods 的超参数来高效修剪 CNNs 和 Transformers，从而减少模型参数并降低计算成本。研究扩展了先前工作，将该方法应用于 VGG、ResNet 和 ViT 等架构，实现了比之前更高的模型压缩率，同时在 ImageNet 分类任务上保持高性能。实验发现，Transformers 相比 CNNs 具有更高的过参数化程度，为更有效的模型优化提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted as a workshop paper at ECCV 2024, 26 pages (11 pages\n  manuscript, 3 pages references, 12 pages appendix)",
      "pdf_url": "http://arxiv.org/pdf/2408.12568v2",
      "published_date": "2024-08-22 17:35:18 UTC",
      "updated_date": "2024-10-23 17:53:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:48:02.799964"
    },
    {
      "arxiv_id": "2408.12561v2",
      "title": "ssProp: Energy-Efficient Training for Convolutional Neural Networks with Scheduled Sparse Back Propagation",
      "title_zh": "翻译失败",
      "authors": [
        "Lujia Zhong",
        "Shuo Huang",
        "Yonggang Shi"
      ],
      "abstract": "Recently, deep learning has made remarkable strides, especially with\ngenerative modeling, such as large language models and probabilistic diffusion\nmodels. However, training these models often involves significant computational\nresources, requiring billions of petaFLOPs. This high resource consumption\nresults in substantial energy usage and a large carbon footprint, raising\ncritical environmental concerns. Back-propagation (BP) is a major source of\ncomputational expense during training deep learning models. To advance research\non energy-efficient training and allow for sparse learning on any machine and\ndevice, we propose a general, energy-efficient convolution module that can be\nseamlessly integrated into any deep learning architecture. Specifically, we\nintroduce channel-wise sparsity with additional gradient selection schedulers\nduring backward based on the assumption that BP is often dense and inefficient,\nwhich can lead to over-fitting and high computational consumption. Our\nexperiments demonstrate that our approach reduces 40\\% computations while\npotentially improving model performance, validated on image classification and\ngeneration tasks. This reduction can lead to significant energy savings and a\nlower carbon footprint during the research and development phases of\nlarge-scale AI systems. Additionally, our method mitigates over-fitting in a\nmanner distinct from Dropout, allowing it to be combined with Dropout to\nfurther enhance model performance and reduce computational resource usage.\nExtensive experiments validate that our method generalizes to a variety of\ndatasets and tasks and is compatible with a wide range of deep learning\narchitectures and modules. Code is publicly available at\nhttps://github.com/lujiazho/ssProp.",
      "tldr_zh": "本文提出ssProp，一种用于卷积神经网络(CNNs)的能源高效训练方法，通过Scheduled Sparse Back Propagation引入通道级稀疏性和梯度选择调度器，在反向传播(BP)过程中减少计算消耗。实验结果显示，该方法可降低40%的计算量，同时改善模型性能，并在图像分类和生成任务上缓解过拟合，与Dropout结合可进一步提升效果。ssProp兼容多种数据集、任务和架构，并有助于减少AI系统的能源使用和碳足迹，代码已在GitHub开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI24 Workshop: Scalable and Efficient Artificial\n  Intelligence Systems",
      "pdf_url": "http://arxiv.org/pdf/2408.12561v2",
      "published_date": "2024-08-22 17:22:59 UTC",
      "updated_date": "2024-12-29 19:45:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:48:15.459582"
    },
    {
      "arxiv_id": "2408.12560v1",
      "title": "Data Quality Antipatterns for Software Analytics",
      "title_zh": "软件分析的数据质量反模式",
      "authors": [
        "Aaditya Bhatia",
        "Dayi Lin",
        "Gopi Krishnan Rajbahadur",
        "Bram Adams",
        "Ahmed E. Hassan"
      ],
      "abstract": "Background: Data quality is vital in software analytics, particularly for\nmachine learning (ML) applications like software defect prediction (SDP).\nDespite the widespread use of ML in software engineering, the effect of data\nquality antipatterns on these models remains underexplored.\n  Objective: This study develops a taxonomy of ML-specific data quality\nantipatterns and assesses their impact on software analytics models'\nperformance and interpretation.\n  Methods: We identified eight types and 14 sub-types of ML-specific data\nquality antipatterns through a literature review. We conducted experiments to\ndetermine the prevalence of these antipatterns in SDP data (RQ1), assess how\ncleaning order affects model performance (RQ2), evaluate the impact of\nantipattern removal on performance (RQ3), and examine the consistency of\ninterpretation from models built with different antipatterns (RQ4).\n  Results: In our SDP case study, we identified nine antipatterns. Over 90% of\nthese overlapped at both row and column levels, complicating cleaning\nprioritization and risking excessive data removal. The order of cleaning\nsignificantly impacts ML model performance, with neural networks being more\nresilient to cleaning order changes than simpler models like logistic\nregression. Antipatterns such as Tailed Distributions and Class Overlap show a\nstatistically significant correlation with performance metrics when other\nantipatterns are cleaned. Models built with different antipatterns showed\nmoderate consistency in interpretation results.\n  Conclusion: The cleaning order of different antipatterns impacts ML model\nperformance. Five antipatterns have a statistically significant correlation\nwith model performance when others are cleaned. Additionally, model\ninterpretation is moderately affected by different data quality antipatterns.",
      "tldr_zh": "本研究探讨了数据质量反模式（Data Quality Antipatterns）对软件分析（Software Analytics）中机器学习（ML）模型的影响，特别是软件缺陷预测（SDP）。研究者通过文献回顾识别了八种类型和14个子类型的ML特定数据质量反模式，并通过实验评估这些反模式在SDP数据中的流行性（RQ1）、清理顺序对模型性能的影响（RQ2）、移除反模式后的性能变化（RQ3），以及模型解释的一致性（RQ4）。结果显示，在SDP案例中发现九种反模式，其中超过90%在行和列级别重叠，清理顺序显著影响模型性能（如神经网络比逻辑回归更耐受），且Tailed Distributions和Class Overlap等反模式与性能指标有显著相关性。总之，该研究强调了数据质量反模式的清理优先级对ML模型性能和解释的影响，提供指导以提升软件分析的可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12560v1",
      "published_date": "2024-08-22 17:21:09 UTC",
      "updated_date": "2024-08-22 17:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:48:28.528950"
    },
    {
      "arxiv_id": "2408.12549v3",
      "title": "Modeling Time-Variant Responses of Optical Compressors with Selective State Space Models",
      "title_zh": "利用选择性状态空间模型建",
      "authors": [
        "Riccardo Simionato",
        "Stefano Fasciani"
      ],
      "abstract": "This paper presents a method for modeling optical dynamic range compressors\nusing deep neural networks with Selective State Space models. The proposed\napproach surpasses previous methods based on recurrent layers by employing a\nSelective State Space block to encode the input audio. It features a refined\ntechnique integrating Feature-wise Linear Modulation and Gated Linear Units to\nadjust the network dynamically, conditioning the compression's attack and\nrelease phases according to external parameters. The proposed architecture is\nwell-suited for low-latency and real-time applications, crucial in live audio\nprocessing. The method has been validated on the analog optical compressors\nTubeTech CL 1B and Teletronix LA-2A, which possess distinct characteristics.\nEvaluation is performed using quantitative metrics and subjective listening\ntests, comparing the proposed method with other state-of-the-art models.\nResults show that our black-box modeling methods outperform all others,\nachieving accurate emulation of the compression process for both seen and\nunseen settings during training. We further show a correlation between this\naccuracy and the sampling density of the control parameters in the dataset and\nidentify settings with fast attack and slow release as the most challenging to\nemulate.",
      "tldr_zh": "本文提出了一种使用 Selective State Space 模型的深度神经网络方法，来建模光学动态范围压缩器的时变响应，该方法优于基于循环层的先前技术，并通过整合 Feature-wise Linear Modulation 和 Gated Linear Units 动态调整网络以适应压缩的 attack 和 release 阶段。实验在 TubeTech CL 1B 和 Teletronix LA-2A 压缩器上进行，使用定量指标和主观听力测试，结果显示该方法在已知和未知设置下均实现了更高的仿真准确率。研究还发现，控制参数的采样密度与仿真性能相关，而快速 attack 和缓慢 release 的设置是最具挑战性的。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Journal of the Audio Engineering Society",
      "pdf_url": "http://arxiv.org/pdf/2408.12549v3",
      "published_date": "2024-08-22 17:03:08 UTC",
      "updated_date": "2025-01-16 14:26:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:48:39.952944"
    },
    {
      "arxiv_id": "2408.12534v1",
      "title": "Automatic Organ and Pan-cancer Segmentation in Abdomen CT: the FLARE 2023 Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Ma",
        "Yao Zhang",
        "Song Gu",
        "Cheng Ge",
        "Ershuai Wang",
        "Qin Zhou",
        "Ziyan Huang",
        "Pengju Lyu",
        "Jian He",
        "Bo Wang"
      ],
      "abstract": "Organ and cancer segmentation in abdomen Computed Tomography (CT) scans is\nthe prerequisite for precise cancer diagnosis and treatment. Most existing\nbenchmarks and algorithms are tailored to specific cancer types, limiting their\nability to provide comprehensive cancer analysis. This work presents the first\ninternational competition on abdominal organ and pan-cancer segmentation by\nproviding a large-scale and diverse dataset, including 4650 CT scans with\nvarious cancer types from over 40 medical centers. The winning team established\na new state-of-the-art with a deep learning-based cascaded framework, achieving\naverage Dice Similarity Coefficient scores of 92.3% for organs and 64.9% for\nlesions on the hidden multi-national testing set. The dataset and code of top\nteams are publicly available, offering a benchmark platform to drive further\ninnovations https://codalab.lisn.upsaclay.fr/competitions/12239.",
      "tldr_zh": "这项研究介绍了FLARE 2023挑战赛，这是首个专注于腹部CT扫描中器官和全癌症分割的国际比赛，旨在解决现有基准算法针对特定癌症类型的局限性。该比赛提供了大规模数据集，包括4650个CT扫描，涵盖各种癌症类型，来自40多个医疗中心。获胜团队采用基于深度学习的级联框架，实现了器官分割的平均Dice Similarity Coefficient为92.3%，病变分割为64.9%，建立了新的state-of-the-art。该数据集和顶级团队的代码已公开可用，作为推动进一步创新的基准平台。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "MICCAI 2024 FLARE Challenge Summary",
      "pdf_url": "http://arxiv.org/pdf/2408.12534v1",
      "published_date": "2024-08-22 16:38:45 UTC",
      "updated_date": "2024-08-22 16:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:48:52.504859"
    },
    {
      "arxiv_id": "2408.12525v1",
      "title": "PCGRL+: Scaling, Control and Generalization in Reinforcement Learning Level Generators",
      "title_zh": "翻译失败",
      "authors": [
        "Sam Earle",
        "Zehua Jiang",
        "Julian Togelius"
      ],
      "abstract": "Procedural Content Generation via Reinforcement Learning (PCGRL) has been\nintroduced as a means by which controllable designer agents can be trained\nbased only on a set of computable metrics acting as a proxy for the level's\nquality and key characteristics. While PCGRL offers a unique set of affordances\nfor game designers, it is constrained by the compute-intensive process of\ntraining RL agents, and has so far been limited to generating relatively small\nlevels. To address this issue of scale, we implement several PCGRL environments\nin Jax so that all aspects of learning and simulation happen in parallel on the\nGPU, resulting in faster environment simulation; removing the CPU-GPU transfer\nof information bottleneck during RL training; and ultimately resulting in\nsignificantly improved training speed. We replicate several key results from\nprior works in this new framework, letting models train for much longer than\npreviously studied, and evaluating their behavior after 1 billion timesteps.\nAiming for greater control for human designers, we introduce randomized level\nsizes and frozen \"pinpoints\" of pivotal game tiles as further ways of\ncountering overfitting. To test the generalization ability of learned\ngenerators, we evaluate models on large, out-of-distribution map sizes, and\nfind that partial observation sizes learn more robust design strategies.",
      "tldr_zh": "本文提出 PCGRL+ 方法，以解决 Procedural Content Generation via Reinforcement Learning (PCGRL) 在生成游戏关卡时的计算密集和规模限制问题。通过在 Jax 上实现环境模拟，使学习和模拟在 GPU 上并行进行，大幅提升训练速度，并允许模型训练至1 billion timesteps。作者引入随机化关卡大小和固定关键点（pinpoints）来增强设计师控制并防止过拟合；实验结果显示，部分观察大小的模型在更大、出分布地图上表现出更强的泛化能力和鲁棒设计策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 7 figures, 6 tables. Published at IEEE Conference on Games,\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12525v1",
      "published_date": "2024-08-22 16:30:24 UTC",
      "updated_date": "2024-08-22 16:30:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:49:03.525769"
    },
    {
      "arxiv_id": "2408.12519v1",
      "title": "Advanced atom-level representations for protein flexibility prediction utilizing graph neural networks",
      "title_zh": "先进的原子级别表示用于蛋白质柔性预测，利用图神经网络",
      "authors": [
        "Sina Sarparast",
        "Aldo Zaimi",
        "Maximilian Ebert",
        "Michael-Rock Goldsmith"
      ],
      "abstract": "Protein dynamics play a crucial role in many biological processes and drug\ninteractions. However, measuring, and simulating protein dynamics is\nchallenging and time-consuming. While machine learning holds promise in\ndeciphering the determinants of protein dynamics from structural information,\nmost existing methods for protein representation learning operate at the\nresidue level, ignoring the finer details of atomic interactions. In this work,\nwe propose for the first time to use graph neural networks (GNNs) to learn\nprotein representations at the atomic level and predict B-factors from protein\n3D structures. The B-factor reflects the atomic displacement of atoms in\nproteins, and can serve as a surrogate for protein flexibility. We compared\ndifferent GNN architectures to assess their performance. The Meta-GNN model\nachieves a correlation coefficient of 0.71 on a large and diverse test set of\nover 4k proteins (17M atoms) from the Protein Data Bank (PDB), outperforming\nprevious methods by a large margin. Our work demonstrates the potential of\nrepresentations learned by GNNs for protein flexibility prediction and other\nrelated tasks.",
      "tldr_zh": "本文首次提出使用 graph neural networks (GNNs) 在原子水平学习蛋白质表示，从而从蛋白质 3D 结构预测 B-factors，并以此作为蛋白质柔性的代理指标，以解决现有方法忽略原子细节的局限性。研究比较了不同 GNN 架构，其中 Meta-GNN 模型在 Protein Data Bank (PDB) 的超过 4k 蛋白（17M 原子）的测试集上达到了 0.71 的相关系数，远超之前方法。总体而言，这展示了 GNNs 在蛋白质动力学预测和其他相关任务中的巨大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12519v1",
      "published_date": "2024-08-22 16:15:13 UTC",
      "updated_date": "2024-08-22 16:15:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:49:16.194542"
    },
    {
      "arxiv_id": "2408.12503v2",
      "title": "The Russian-focused embedders' exploration: ruMTEB benchmark and Russian embedding model design",
      "title_zh": "以俄语为重点的嵌入模型探索：ruMTEB 基准和俄语嵌入模型设计",
      "authors": [
        "Artem Snegirev",
        "Maria Tikhonova",
        "Anna Maksimova",
        "Alena Fenogenova",
        "Alexander Abramov"
      ],
      "abstract": "Embedding models play a crucial role in Natural Language Processing (NLP) by\ncreating text embeddings used in various tasks such as information retrieval\nand assessing semantic text similarity. This paper focuses on research related\nto embedding models in the Russian language. It introduces a new\nRussian-focused embedding model called ru-en-RoSBERTa and the ruMTEB benchmark,\nthe Russian version extending the Massive Text Embedding Benchmark (MTEB). Our\nbenchmark includes seven categories of tasks, such as semantic textual\nsimilarity, text classification, reranking, and retrieval.The research also\nassesses a representative set of Russian and multilingual models on the\nproposed benchmark. The findings indicate that the new model achieves results\nthat are on par with state-of-the-art models in Russian. We release the model\nru-en-RoSBERTa, and the ruMTEB framework comes with open-source code,\nintegration into the original framework and a public leaderboard.",
      "tldr_zh": "本文探讨了俄语嵌入模型在 NLP 中的应用，引入了新的 ru-en-RoSBERTa 模型和 ruMTEB 基准，后者是 Massive Text Embedding Benchmark (MTEB) 的俄语扩展，包括语义文本相似度、文本分类、重新排序和检索等七类任务。研究评估了多种俄语和多语言模型，结果显示 ru-en-RoSBERTa 的性能与最先进模型相当。作者发布了该模型、开源代码、框架整合以及公共排行榜，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "to appear in NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.12503v2",
      "published_date": "2024-08-22 15:53:23 UTC",
      "updated_date": "2025-02-03 12:53:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:49:27.799777"
    },
    {
      "arxiv_id": "2408.12496v1",
      "title": "MEDCO: Medical Education Copilots Based on A Multi-Agent Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Wei",
        "Jianing Qiu",
        "Haibao Yu",
        "Wu Yuan"
      ],
      "abstract": "Large language models (LLMs) have had a significant impact on diverse\nresearch domains, including medicine and healthcare. However, the potential of\nLLMs as copilots in medical education remains underexplored. Current\nAI-assisted educational tools are limited by their solitary learning approach\nand inability to simulate the multi-disciplinary and interactive nature of\nactual medical training. To address these limitations, we propose MEDCO\n(Medical EDucation COpilots), a novel multi-agent-based copilot system\nspecially developed to emulate real-world medical training environments. MEDCO\nincorporates three primary agents: an agentic patient, an expert doctor, and a\nradiologist, facilitating a multi-modal and interactive learning environment.\nOur framework emphasizes the learning of proficient question-asking skills,\nmulti-disciplinary collaboration, and peer discussions between students. Our\nexperiments show that simulated virtual students who underwent training with\nMEDCO not only achieved substantial performance enhancements comparable to\nthose of advanced models, but also demonstrated human-like learning behaviors\nand improvements, coupled with an increase in the number of learning samples.\nThis work contributes to medical education by introducing a copilot that\nimplements an interactive and collaborative learning approach. It also provides\nvaluable insights into the effectiveness of AI-integrated training paradigms.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)在医疗教育中的潜力，提出MEDCO（Medical Education Copilots），一个基于多智能体框架的辅助系统，以模拟真实的多学科互动训练环境。MEDCO包括患者代理、专家医生代理和放射科医生代理，支持多模态互动、提问技能训练、多学科协作以及学生间讨论。实验结果显示，使用MEDCO训练的虚拟学生性能显著提升，与高级模型相当，并展现出类似人类的学习行为，同时增加了学习样本。该框架为医疗教育引入交互式协作范式，并提供AI集成训练的有效性见解。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12496v1",
      "published_date": "2024-08-22 15:41:58 UTC",
      "updated_date": "2024-08-22 15:41:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:49:39.159892"
    },
    {
      "arxiv_id": "2408.12494v2",
      "title": "GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models",
      "title_zh": "GenderCARE：用于评估和减少大语言模型中性别偏见的全面框架",
      "authors": [
        "Kunsheng Tang",
        "Wenbo Zhou",
        "Jie Zhang",
        "Aishan Liu",
        "Gelei Deng",
        "Shuai Li",
        "Peigui Qi",
        "Weiming Zhang",
        "Tianwei Zhang",
        "Nenghai Yu"
      ],
      "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in\nnatural language generation, but they have also been observed to magnify\nsocietal biases, particularly those related to gender. In response to this\nissue, several benchmarks have been proposed to assess gender bias in LLMs.\nHowever, these benchmarks often lack practical flexibility or inadvertently\nintroduce biases. To address these shortcomings, we introduce GenderCARE, a\ncomprehensive framework that encompasses innovative Criteria, bias Assessment,\nReduction techniques, and Evaluation metrics for quantifying and mitigating\ngender bias in LLMs. To begin, we establish pioneering criteria for gender\nequality benchmarks, spanning dimensions such as inclusivity, diversity,\nexplainability, objectivity, robustness, and realisticity. Guided by these\ncriteria, we construct GenderPair, a novel pair-based benchmark designed to\nassess gender bias in LLMs comprehensively. Our benchmark provides standardized\nand realistic evaluations, including previously overlooked gender groups such\nas transgender and non-binary individuals. Furthermore, we develop effective\ndebiasing techniques that incorporate counterfactual data augmentation and\nspecialized fine-tuning strategies to reduce gender bias in LLMs without\ncompromising their overall performance. Extensive experiments demonstrate a\nsignificant reduction in various gender bias benchmarks, with reductions\npeaking at over 90% and averaging above 35% across 17 different LLMs.\nImportantly, these reductions come with minimal variability in mainstream\nlanguage tasks, remaining below 2%. By offering a realistic assessment and\ntailored reduction of gender biases, we hope that our GenderCARE can represent\na significant step towards achieving fairness and equity in LLMs. More details\nare available at https://github.com/kstanghere/GenderCARE-ccs24.",
      "tldr_zh": "该研究提出 GenderCARE 框架，用于全面评估和减少大型语言模型 (LLMs) 中的性别偏见，解决现有基准的灵活性和偏见引入问题。框架包括创新标准（如包容性、多样性和客观性）、新型 GenderPair 基准（覆盖跨性别和非二元群体）、反事实数据增强和专门微调技术，以量化并缓解偏见。实验在 17 个 LLMs 上显示，性别偏见平均减少 35%、最高超过 90%，同时主流语言任务性能变化小于 2%，为实现 LLMs 的公平性提供了重要进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACM CCS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12494v2",
      "published_date": "2024-08-22 15:35:46 UTC",
      "updated_date": "2025-02-23 05:10:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:49:51.002232"
    },
    {
      "arxiv_id": "2408.12491v2",
      "title": "AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines",
      "title_zh": "翻译失败",
      "authors": [
        "Douwe J. Spaanderman",
        "Matthew Marzetti",
        "Xinyi Wan",
        "Andrew F. Scarsbrook",
        "Philip Robinson",
        "Edwin H. G. Oei",
        "Jacob J. Visser",
        "Robert Hemke",
        "Kirsten van Langevelde",
        "David F. Hanff",
        "Geert J. L. H. van Leenders",
        "Cornelis Verhoef",
        "Dirk J. Gruühagen",
        "Wiro J. Niessen",
        "Stefan Klein",
        "Martijn P. A. Starmans"
      ],
      "abstract": "Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging\nlesions with variable clinical behaviours and treatment approaches. This\nsystematic review provides an overview of Artificial Intelligence (AI) methods\nusing radiological imaging for diagnosis and prognosis of these tumours,\nhighlighting challenges in clinical translation, and evaluating study alignment\nwith the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI\ninternational consensus guidelines for trustworthy and deployable AI to promote\nthe clinical translation of AI methods. The review covered literature from\nseveral bibliographic databases, including papers published before 17/07/2024.\nOriginal research in peer-reviewed journals focused on radiology-based AI for\ndiagnosing or prognosing primary STBT was included. Exclusion criteria were\nanimal, cadaveric, or laboratory studies, and non-English papers. Abstracts\nwere screened by two of three independent reviewers for eligibility. Eligible\npapers were assessed against guidelines by one of three independent reviewers.\nThe search identified 15,015 abstracts, from which 325 articles were included\nfor evaluation. Most studies performed moderately on CLAIM, averaging a score\nof 28.9$\\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\\pm$2.1 out\nof 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,\nindicating significant room for improvement. Future efforts by AI developers\nshould focus on design (e.g. define unmet clinical need, intended clinical\nsetting and how AI would be integrated in clinical workflow), development (e.g.\nbuild on previous work, explainability), evaluation (e.g. evaluating and\naddressing biases, evaluating AI against best practices), and data\nreproducibility and availability (making documented code and data publicly\navailable). Following these recommendations could improve clinical translation\nof AI methods.",
      "tldr_zh": "本系统综述评估了使用放射学图像的AI方法在诊断和预后软组织和骨肿瘤（STBT）中的应用，涵盖了截至2024年7月17日的文献，共筛选出15,015篇摘要并最终纳入325篇研究。研究发现，大多数论文在CLAIM指南中得分中等（平均28.9±7.5/53），但在FUTURE-AI指南中表现较差（平均5.1±2.1/30），表明这些AI工具仍处于概念验证阶段，临床翻译面临挑战。作者推荐AI开发者重点改进设计（如定义临床需求）、开发（如增强解释性）、评估（如处理偏差）和数据再现性，以促进AI方法的可靠部署和实际应用。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 6 figures, 8 supplementary figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12491v2",
      "published_date": "2024-08-22 15:31:48 UTC",
      "updated_date": "2025-03-31 13:58:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:50:03.207705"
    },
    {
      "arxiv_id": "2408.12483v1",
      "title": "Not All Samples Should Be Utilized Equally: Towards Understanding and Improving Dataset Distillation",
      "title_zh": "并非所有样本都应被平等利用：朝向理解和改进数据集蒸馏",
      "authors": [
        "Shaobo Wang",
        "Yantai Yang",
        "Qilong Wang",
        "Kaixin Li",
        "Linfeng Zhang",
        "Junchi Yan"
      ],
      "abstract": "Dataset Distillation (DD) aims to synthesize a small dataset capable of\nperforming comparably to the original dataset. Despite the success of numerous\nDD methods, theoretical exploration of this area remains unaddressed. In this\npaper, we take an initial step towards understanding various matching-based DD\nmethods from the perspective of sample difficulty. We begin by empirically\nexamining sample difficulty, measured by gradient norm, and observe that\ndifferent matching-based methods roughly correspond to specific difficulty\ntendencies. We then extend the neural scaling laws of data pruning to DD to\ntheoretically explain these matching-based methods. Our findings suggest that\nprioritizing the synthesis of easier samples from the original dataset can\nenhance the quality of distilled datasets, especially in low IPC\n(image-per-class) settings. Based on our empirical observations and theoretical\nanalysis, we introduce the Sample Difficulty Correction (SDC) approach,\ndesigned to predominantly generate easier samples to achieve higher dataset\nquality. Our SDC can be seamlessly integrated into existing methods as a plugin\nwith minimal code adjustments. Experimental results demonstrate that adding SDC\ngenerates higher-quality distilled datasets across 7 distillation methods and 6\ndatasets.",
      "tldr_zh": "本论文探讨了Dataset Distillation (DD) 的样本难度问题，通过测量梯度范数（gradient norm）观察不同匹配-based 方法的难度倾向，并扩展神经缩放定律（neural scaling laws）进行理论解释。研究发现，优先合成更容易的样本可显著提升蒸馏数据集质量，尤其在低IPC（image-per-class）设置中。作者提出Sample Difficulty Correction (SDC) 方法，作为插件无缝整合到现有DD方法中，实验结果显示，在7种蒸馏方法和6个数据集上，SDC 生成了更高质量的蒸馏数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12483v1",
      "published_date": "2024-08-22 15:20:32 UTC",
      "updated_date": "2024-08-22 15:20:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:50:15.952954"
    },
    {
      "arxiv_id": "2408.12476v3",
      "title": "Predicting Solar Energy Generation with Machine Learning based on AQI and Weather Features",
      "title_zh": "基于 AQI 和天气特征的机器学习太阳能发电预测",
      "authors": [
        "Arjun Shah",
        "Varun Viswanath",
        "Kashish Gandhi",
        "Nilesh Madhukar Patil"
      ],
      "abstract": "This paper addresses the pressing need for an accurate solar energy\nprediction model, which is crucial for efficient grid integration. We explore\nthe influence of the Air Quality Index and weather features on solar energy\ngeneration, employing advanced Machine Learning and Deep Learning techniques.\nOur methodology uses time series modeling and makes novel use of power\ntransform normalization and zero-inflated modeling. Various Machine Learning\nalgorithms and Conv2D Long Short-Term Memory model based Deep Learning models\nare applied to these transformations for precise predictions. Results\nunderscore the effectiveness of our approach, demonstrating enhanced prediction\naccuracy with Air Quality Index and weather features. We achieved a 0.9691\n$R^2$ Score, 0.18 MAE, 0.10 RMSE with Conv2D Long Short-Term Memory model,\nshowcasing the power transform technique's innovation in enhancing time series\nforecasting for solar energy generation. Such results help our research\ncontribute valuable insights to the synergy between Air Quality Index, weather\nfeatures, and Deep Learning techniques for solar energy prediction.",
      "tldr_zh": "这篇论文针对太阳能生成预测的需求，使用 Machine Learning 和 Deep Learning 技术，探讨了 AQI 和天气特征的影响，以提升电网整合效率。方法包括时间序列建模、功率变换归一化和零膨胀建模，并应用各种算法如 Conv2D Long Short-Term Memory 模型进行精确预测。结果显示，该方法显著提高了准确性，取得了 R² Score 0.9691、MAE 0.18 和 RMSE 0.10 的表现，突显了功率变换技术在太阳能预测中的创新贡献。该研究为 AQI、天气特征与 Deep Learning 协同作用提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AISD2024 : Second International Workshop on Artificial\n  Intelligence: Empowering Sustainable Development",
      "pdf_url": "http://arxiv.org/pdf/2408.12476v3",
      "published_date": "2024-08-22 15:13:44 UTC",
      "updated_date": "2024-10-03 20:29:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:50:27.653870"
    },
    {
      "arxiv_id": "2408.12466v1",
      "title": "WCEbleedGen: A wireless capsule endoscopy dataset and its benchmarking for automatic bleeding classification, detection, and segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Palak Handa",
        "Manas Dhir",
        "Amirreza Mahbod",
        "Florian Schwarzhans",
        "Ramona Woitek",
        "Nidhi Goel",
        "Deepak Gunjan"
      ],
      "abstract": "Computer-based analysis of Wireless Capsule Endoscopy (WCE) is crucial.\nHowever, a medically annotated WCE dataset for training and evaluation of\nautomatic classification, detection, and segmentation of bleeding and\nnon-bleeding frames is currently lacking. The present work focused on\ndevelopment of a medically annotated WCE dataset called WCEbleedGen for\nautomatic classification, detection, and segmentation of bleeding and\nnon-bleeding frames. It comprises 2,618 WCE bleeding and non-bleeding frames\nwhich were collected from various internet resources and existing WCE datasets.\nA comprehensive benchmarking and evaluation of the developed dataset was done\nusing nine classification-based, three detection-based, and three\nsegmentation-based deep learning models. The dataset is of high-quality, is\nclass-balanced and contains single and multiple bleeding sites. Overall, our\nstandard benchmark results show that Visual Geometric Group (VGG) 19, You Only\nLook Once version 8 nano (YOLOv8n), and Link network (Linknet) performed best\nin automatic classification, detection, and segmentation-based evaluations,\nrespectively. Automatic bleeding diagnosis is crucial for WCE video\ninterpretations. This diverse dataset will aid in developing of real-time,\nmulti-task learning-based innovative solutions for automatic bleeding diagnosis\nin WCE. The dataset and code are publicly available at\nhttps://zenodo.org/records/10156571 and\nhttps://github.com/misahub2023/Benchmarking-Codes-of-the-WCEBleedGen-dataset.",
      "tldr_zh": "本文开发了WCEbleedGen，这是一个医学标注的无创胶囊内窥镜（WCE）数据集，包含2,618张出血和非出血帧，用于支持出血帧的自动分类、检测和分割任务。该数据集从各种互联网资源和现有数据集收集而成，并进行了全面基准测试，使用九个分类模型（如VGG19）、三个检测模型（如YOLOv8n）和三个分割模型（如Linknet），结果显示VGG19、YOLOv8n和Linknet分别在分类、检测和分割任务中表现出色。WCEbleedGen的数据质量高、类别平衡且包含单多出血位点，有助于推进实时、多任务学习的自动出血诊断解决方案；数据集和代码已公开可用于https://zenodo.org/records/10156571和https://github.com/misahub2023/Benchmarking-Codes-of-the-WCEBleedGen-dataset。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12466v1",
      "published_date": "2024-08-22 15:06:50 UTC",
      "updated_date": "2024-08-22 15:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:50:40.979126"
    },
    {
      "arxiv_id": "2408.12454v3",
      "title": "Relaxed Rotational Equivariance via $G$-Biases in Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqiang Wu",
        "Yingjie Liu",
        "Licheng Sun",
        "Jian Yang",
        "Hanlin Dong",
        "Shing-Ho J. Lin",
        "Xuan Tang",
        "Jinpeng Mi",
        "Bo Jin",
        "Xian Wei"
      ],
      "abstract": "Group Equivariant Convolution (GConv) can capture rotational equivariance\nfrom original data. It assumes uniform and strict rotational equivariance\nacross all features as the transformations under the specific group. However,\nthe presentation or distribution of real-world data rarely conforms to strict\nrotational equivariance, commonly referred to as Rotational Symmetry-Breaking\n(RSB) in the system or dataset, making GConv unable to adapt effectively to\nthis phenomenon. Motivated by this, we propose a simple but highly effective\nmethod to address this problem, which utilizes a set of learnable biases called\n$G$-Biases under the group order to break strict group constraints and then\nachieve a Relaxed Rotational Equivariant Convolution (RREConv). To validate the\nefficiency of RREConv, we conduct extensive ablation experiments on the\ndiscrete rotational group $\\mathcal{C}_n$. Experiments demonstrate that the\nproposed RREConv-based methods achieve excellent performance compared to\nexisting GConv-based methods in both classification and 2D object detection\ntasks on the natural image datasets.",
      "tldr_zh": "该论文针对Group Equivariant Convolution (GConv) 在视觉任务中假设严格旋转等变的局限性，指出现实数据常出现Rotational Symmetry-Breaking (RSB)，导致GConv适应性不足。作者提出一种简单有效的方法，使用可学习的$G$-Biases 在群约束下打破严格等变性，从而实现Relaxed Rotational Equivariant Convolution (RREConv)。实验在离散旋转群$\\mathcal{C}_n$上进行，结果显示RREConv在自然图像数据集的分类和2D对象检测任务中，比现有GConv方法表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12454v3",
      "published_date": "2024-08-22 14:52:53 UTC",
      "updated_date": "2025-01-14 15:35:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:50:51.159455"
    },
    {
      "arxiv_id": "2408.12443v1",
      "title": "A Riemannian Approach for Spatiotemporal Analysis and Generation of 4D Tree-shaped Structures",
      "title_zh": "翻译失败",
      "authors": [
        "Tahmina Khanam",
        "Hamid Laga",
        "Mohammed Bennamoun",
        "Guanjin Wang",
        "Ferdous Sohel",
        "Farid Boussaid",
        "Guan Wang",
        "Anuj Srivastava"
      ],
      "abstract": "We propose the first comprehensive approach for modeling and analyzing the\nspatiotemporal shape variability in tree-like 4D objects, i.e., 3D objects\nwhose shapes bend, stretch, and change in their branching structure over time\nas they deform, grow, and interact with their environment. Our key contribution\nis the representation of tree-like 3D shapes using Square Root Velocity\nFunction Trees (SRVFT). By solving the spatial registration in the SRVFT space,\nwhich is equipped with an L2 metric, 4D tree-shaped structures become\ntime-parameterized trajectories in this space. This reduces the problem of\nmodeling and analyzing 4D tree-like shapes to that of modeling and analyzing\nelastic trajectories in the SRVFT space, where elasticity refers to time\nwarping. In this paper, we propose a novel mathematical representation of the\nshape space of such trajectories, a Riemannian metric on that space, and\ncomputational tools for fast and accurate spatiotemporal registration and\ngeodesics computation between 4D tree-shaped structures. Leveraging these\nbuilding blocks, we develop a full framework for modelling the spatiotemporal\nvariability using statistical models and generating novel 4D tree-like\nstructures from a set of exemplars. We demonstrate and validate the proposed\nframework using real 4D plant data.",
      "tldr_zh": "本文提出了一种全面方法，用于建模和分析树状4D对象的时空形状变异性，包括弯曲、伸展和分支结构的变化。核心贡献是使用Square Root Velocity Function Trees (SRVFT)表示树状3D形状，并通过在SRVFT空间的L2度量下进行时空注册，将问题简化为建模弹性轨迹，同时引入Riemannian度量和计算工具以支持注册、测地线计算和统计建模。实验结果显示，该框架能有效生成新4D树状结构，并在真实4D植物数据上得到验证。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12443v1",
      "published_date": "2024-08-22 14:39:30 UTC",
      "updated_date": "2024-08-22 14:39:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:51:04.018580"
    },
    {
      "arxiv_id": "2409.00061v1",
      "title": "Enhancing Natural Language Inference Performance with Knowledge Graph for COVID-19 Automated Fact-Checking in Indonesian Language",
      "title_zh": "翻译失败",
      "authors": [
        "Arief Purnama Muharram",
        "Ayu Purwarianti"
      ],
      "abstract": "Automated fact-checking is a key strategy to overcome the spread of COVID-19\nmisinformation on the internet. These systems typically leverage deep learning\napproaches through Natural Language Inference (NLI) to verify the truthfulness\nof information based on supporting evidence. However, one challenge that arises\nin deep learning is performance stagnation due to a lack of knowledge during\ntraining. This study proposes using a Knowledge Graph (KG) as external\nknowledge to enhance NLI performance for automated COVID-19 fact-checking in\nthe Indonesian language. The proposed model architecture comprises three\nmodules: a fact module, an NLI module, and a classifier module. The fact module\nprocesses information from the KG, while the NLI module handles semantic\nrelationships between the given premise and hypothesis. The representation\nvectors from both modules are concatenated and fed into the classifier module\nto produce the final result. The model was trained using the generated\nIndonesian COVID-19 fact-checking dataset and the COVID-19 KG Bahasa Indonesia.\nOur study demonstrates that incorporating KGs can significantly improve NLI\nperformance in fact-checking, achieving the best accuracy of 0,8616. This\nsuggests that KGs are a valuable component for enhancing NLI performance in\nautomated fact-checking.",
      "tldr_zh": "本研究针对COVID-19 misinformation的传播，提出了一种使用Knowledge Graph (KG)增强Natural Language Inference (NLI)性能的自动事实检查框架，专注于印尼语环境。该框架包括三个模块：fact module处理KG中的信息、NLI module分析前提和假设的语义关系，以及classifier module合并向量进行最终分类。模型在生成的印尼语COVID-19事实检查数据集和COVID-19 KG Bahasa Indonesia上训练，实现了0.8616的最高准确率，证明KG能显著提升NLI在事实检查中的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00061v1",
      "published_date": "2024-08-22 14:27:47 UTC",
      "updated_date": "2024-08-22 14:27:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:51:24.977806"
    },
    {
      "arxiv_id": "2408.12426v1",
      "title": "Enhanced Infield Agriculture with Interpretable Machine Learning Approaches for Crop Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Sudi Murindanyi",
        "Joyce Nakatumba-Nabende",
        "Rahman Sanya",
        "Rose Nakibuule",
        "Andrew Katumba"
      ],
      "abstract": "The increasing popularity of Artificial Intelligence in recent years has led\nto a surge in interest in image classification, especially in the agricultural\nsector. With the help of Computer Vision, Machine Learning, and Deep Learning,\nthe sector has undergone a significant transformation, leading to the\ndevelopment of new techniques for crop classification in the field. Despite the\nextensive research on various image classification techniques, most have\nlimitations such as low accuracy, limited use of data, and a lack of reporting\nmodel size and prediction. The most significant limitation of all is the need\nfor model explainability. This research evaluates four different approaches for\ncrop classification, namely traditional ML with handcrafted feature extraction\nmethods like SIFT, ORB, and Color Histogram; Custom Designed CNN and\nestablished DL architecture like AlexNet; transfer learning on five models\npre-trained using ImageNet such as EfficientNetV2, ResNet152V2, Xception,\nInception-ResNetV2, MobileNetV3; and cutting-edge foundation models like YOLOv8\nand DINOv2, a self-supervised Vision Transformer Model. All models performed\nwell, but Xception outperformed all of them in terms of generalization,\nachieving 98% accuracy on the test data, with a model size of 80.03 MB and a\nprediction time of 0.0633 seconds. A key aspect of this research was the\napplication of Explainable AI to provide the explainability of all the models.\nThis journal presents the explainability of Xception model with LIME, SHAP, and\nGradCAM, ensuring transparency and trustworthiness in the models' predictions.\nThis study highlights the importance of selecting the right model according to\ntask-specific needs. It also underscores the important role of explainability\nin deploying AI in agriculture, providing insightful information to help\nenhance AI-driven crop management strategies.",
      "tldr_zh": "这篇论文评估了多种机器学习方法用于农业作物分类，旨在解决传统模型的准确率低、可解释性差等问题。研究比较了四类方法，包括传统 ML 的手工特征提取（如 SIFT, ORB 和 Color Histogram）、自定义 CNN 和 AlexNet、基于 ImageNet 的迁移学习模型（如 EfficientNetV2, ResNet152V2, Xception 等），以及前沿模型（如 YOLOv8 和 DINOv2）。Xception 模型表现出色，实现了 98% 测试准确率、模型大小 80.03 MB 和预测时间 0.0633 秒；同时，通过 Explainable AI 工具如 LIME, SHAP 和 GradCAM，对其预测过程进行了解释，以提升模型的透明度和可靠性。该研究强调了根据任务需求选择合适模型的重要性，并为 AI 驱动的农业作物管理策略提供了宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12426v1",
      "published_date": "2024-08-22 14:20:34 UTC",
      "updated_date": "2024-08-22 14:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:51:29.600943"
    },
    {
      "arxiv_id": "2408.12423v1",
      "title": "Multi-Knowledge Fusion Network for Time Series Representation Learning",
      "title_zh": "多知识融合网络用于时序表示学习",
      "authors": [
        "Sagar Srinivas Sakhinana",
        "Shivam Gupta",
        "Krishna Sai Sudhir Aripirala",
        "Venkataramana Runkana"
      ],
      "abstract": "Forecasting the behaviour of complex dynamical systems such as interconnected\nsensor networks characterized by high-dimensional multivariate time series(MTS)\nis of paramount importance for making informed decisions and planning for the\nfuture in a broad spectrum of applications. Graph forecasting networks(GFNs)\nare well-suited for forecasting MTS data that exhibit spatio-temporal\ndependencies. However, most prior works of GFN-based methods on MTS forecasting\nrely on domain-expertise to model the nonlinear dynamics of the system, but\nneglect the potential to leverage the inherent relational-structural\ndependencies among time series variables underlying MTS data. On the other\nhand, contemporary works attempt to infer the relational structure of the\ncomplex dependencies between the variables and simultaneously learn the\nnonlinear dynamics of the interconnected system but neglect the possibility of\nincorporating domain-specific prior knowledge to improve forecast accuracy. To\nthis end, we propose a hybrid architecture that combines explicit prior\nknowledge with implicit knowledge of the relational structure within the MTS\ndata. It jointly learns intra-series temporal dependencies and inter-series\nspatial dependencies by encoding time-conditioned structural spatio-temporal\ninductive biases to provide more accurate and reliable forecasts. It also\nmodels the time-varying uncertainty of the multi-horizon forecasts to support\ndecision-making by providing estimates of prediction uncertainty. The proposed\narchitecture has shown promising results on multiple benchmark datasets and\noutperforms state-of-the-art forecasting methods by a significant margin. We\nreport and discuss the ablation studies to validate our forecasting\narchitecture.",
      "tldr_zh": "该论文提出了一种Multi-Knowledge Fusion Network，用于多变量时间序列(MTS)表示学习，旨在解决现有图预测网络(GFNs)方法在建模非线性动态时忽略变量间关系结构或先验知识的问题。该框架将显式领域先验知识与隐式关系结构相结合，通过编码时间条件化的结构时空归纳偏差，共同学习序列内的时序依赖和序列间的空间依赖，同时模型化多horizon预测的不确定性以支持决策。在多个基准数据集上，该方法显著优于现有预测技术，并通过消融研究验证了其架构的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted at ML4IoT Workshop, International Conference on\n  Learning Representations(ICLR) 2023",
      "pdf_url": "http://arxiv.org/pdf/2408.12423v1",
      "published_date": "2024-08-22 14:18:16 UTC",
      "updated_date": "2024-08-22 14:18:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:51:39.407474"
    },
    {
      "arxiv_id": "2408.12420v1",
      "title": "Dataset | Mindset = Explainable AI | Interpretable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Caesar Wu",
        "Rajkumar Buyya",
        "Yuan Fang Li",
        "Pascal Bouvry"
      ],
      "abstract": "We often use \"explainable\" Artificial Intelligence (XAI)\" and \"interpretable\nAI (IAI)\" interchangeably when we apply various XAI tools for a given dataset\nto explain the reasons that underpin machine learning (ML) outputs. However,\nthese notions can sometimes be confusing because interpretation often has a\nsubjective connotation, while explanations lean towards objective facts. We\nargue that XAI is a subset of IAI. The concept of IAI is beyond the sphere of a\ndataset. It includes the domain of a mindset. At the core of this ambiguity is\nthe duality of reasons, in which we can reason either outwards or inwards. When\ndirected outwards, we want the reasons to make sense through the laws of\nnature. When turned inwards, we want the reasons to be happy, guided by the\nlaws of the heart. While XAI and IAI share reason as the common notion for the\ngoal of transparency, clarity, fairness, reliability, and accountability in the\ncontext of ethical AI and trustworthy AI (TAI), their differences lie in that\nXAI emphasizes the post-hoc analysis of a dataset, and IAI requires a priori\nmindset of abstraction. This hypothesis can be proved by empirical experiments\nbased on an open dataset and harnessed by High-Performance Computing (HPC). The\ndemarcation of XAI and IAI is indispensable because it would be impossible to\ndetermine regulatory policies for many AI applications, especially in\nhealthcare, human resources, banking, and finance. We aim to clarify these\nnotions and lay the foundation of XAI, IAI, EAI, and TAI for many practitioners\nand policymakers in future AI applications and research.",
      "tldr_zh": "本论文探讨了 Explainable AI (XAI) 与 Interpretable AI (IAI) 的概念差异，作者认为 XAI 是 IAI 的子集，前者侧重于事后数据集分析以提供客观解释，而后者强调先验心智抽象和主观解读。论文通过基于开放数据集的经验实验和 High-Performance Computing (HPC) 技术，证明了这种内外向推理的双重性，并论证 XAI 与 IAI 虽均追求透明、公平和 Trustworthy AI (TAI)，但 IAI 更涉及心智领域。最终，该研究旨在澄清这些概念，为 AI 应用（如医疗、金融）的监管政策奠定基础，并指导未来从业者和政策制定者。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12420v1",
      "published_date": "2024-08-22 14:12:53 UTC",
      "updated_date": "2024-08-22 14:12:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:51:51.649857"
    },
    {
      "arxiv_id": "2408.12419v3",
      "title": "AlphaFolding: 4D Diffusion for Dynamic Protein Structure Prediction with Reference and Motion Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Kaihui Cheng",
        "Ce Liu",
        "Qingkun Su",
        "Jun Wang",
        "Liwei Zhang",
        "Yining Tang",
        "Yao Yao",
        "Siyu Zhu",
        "Yuan Qi"
      ],
      "abstract": "Protein structure prediction is pivotal for understanding the\nstructure-function relationship of proteins, advancing biological research, and\nfacilitating pharmaceutical development and experimental design. While deep\nlearning methods and the expanded availability of experimental 3D protein\nstructures have accelerated structure prediction, the dynamic nature of protein\nstructures has received limited attention. This study introduces an innovative\n4D diffusion model incorporating molecular dynamics (MD) simulation data to\nlearn dynamic protein structures. Our approach is distinguished by the\nfollowing components: (1) a unified diffusion model capable of generating\ndynamic protein structures, including both the backbone and side chains,\nutilizing atomic grouping and side-chain dihedral angle predictions; (2) a\nreference network that enhances structural consistency by integrating the\nlatent embeddings of the initial 3D protein structures; and (3) a motion\nalignment module aimed at improving temporal structural coherence across\nmultiple time steps. To our knowledge, this is the first diffusion-based model\naimed at predicting protein trajectories across multiple time steps\nsimultaneously. Validation on benchmark datasets demonstrates that our model\nexhibits high accuracy in predicting dynamic 3D structures of proteins\ncontaining up to 256 amino acids over 32 time steps, effectively capturing both\nlocal flexibility in stable states and significant conformational changes. URL:\nhttps://fudan-generative-vision.github.io/AlphaFolding/#/",
      "tldr_zh": "这篇论文提出了 AlphaFolding，一种创新的 4D diffusion model，用于预测动态蛋白结构，通过整合 molecular dynamics (MD) 模拟数据来解决传统方法对蛋白动态性关注不足的问题。该模型的关键组件包括统一的扩散模型（支持主链和侧链的原子分组及二面角预测）、reference network（增强初始 3D 结构的一致性），以及 motion alignment module（提高多个时间步骤的 temporal 结构连贯性）。作为首个基于扩散的模型，它能同时预测蛋白质轨迹；在基准数据集上的验证显示，该方法准确预测多达 256 个氨基酸的蛋白在 32 个时间步骤内的动态 3D 结构，有效捕捉局部灵活性和重大构象变化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12419v3",
      "published_date": "2024-08-22 14:12:50 UTC",
      "updated_date": "2024-12-25 15:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:52:05.476911"
    },
    {
      "arxiv_id": "2408.12418v1",
      "title": "CODE: Confident Ordinary Differential Editing",
      "title_zh": "CODE：自信的常微分编辑",
      "authors": [
        "Bastien van Delft",
        "Tommaso Martorella",
        "Alexandre Alahi"
      ],
      "abstract": "Conditioning image generation facilitates seamless editing and the creation\nof photorealistic images. However, conditioning on noisy or Out-of-Distribution\n(OoD) images poses significant challenges, particularly in balancing fidelity\nto the input and realism of the output. We introduce Confident Ordinary\nDifferential Editing (CODE), a novel approach for image synthesis that\neffectively handles OoD guidance images. Utilizing a diffusion model as a\ngenerative prior, CODE enhances images through score-based updates along the\nprobability-flow Ordinary Differential Equation (ODE) trajectory. This method\nrequires no task-specific training, no handcrafted modules, and no assumptions\nregarding the corruptions affecting the conditioning image. Our method is\ncompatible with any diffusion model. Positioned at the intersection of\nconditional image generation and blind image restoration, CODE operates in a\nfully blind manner, relying solely on a pre-trained generative model. Our\nmethod introduces an alternative approach to blind restoration: instead of\ntargeting a specific ground truth image based on assumptions about the\nunderlying corruption, CODE aims to increase the likelihood of the input image\nwhile maintaining fidelity. This results in the most probable in-distribution\nimage around the input. Our contributions are twofold. First, CODE introduces a\nnovel editing method based on ODE, providing enhanced control, realism, and\nfidelity compared to its SDE-based counterpart. Second, we introduce a\nconfidence interval-based clipping method, which improves CODE's effectiveness\nby allowing it to disregard certain pixels or information, thus enhancing the\nrestoration process in a blind manner. Experimental results demonstrate CODE's\neffectiveness over existing methods, particularly in scenarios involving severe\ndegradation or OoD inputs.",
      "tldr_zh": "本研究提出了一种名为 Confident Ordinary Differential Editing (CODE) 的新方法，用于处理噪声或 Out-of-Distribution (OoD) 图像的条件图像生成问题。CODE 利用扩散模型作为生成先验，通过基于分数的更新沿着概率流 Ordinary Differential Equation (ODE) 轨迹来增强图像，实现图像的保真度和真实性平衡，而无需任务特定训练或对腐败的假设。创新点包括引入基于置信区间的剪切机制，以忽略某些像素信息提升盲恢复效果；实验结果表明，CODE 在严重退化或 OoD 输入场景中比现有方法表现出更高的控制、真实性和性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12418v1",
      "published_date": "2024-08-22 14:12:20 UTC",
      "updated_date": "2024-08-22 14:12:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:52:27.495243"
    },
    {
      "arxiv_id": "2408.12634v1",
      "title": "Joint Hypergraph Rewiring and Memory-Augmented Forecasting Techniques in Digital Twin Technology",
      "title_zh": "翻译失败",
      "authors": [
        "Sagar Srinivas Sakhinana",
        "Krishna Sai Sudhir Aripirala",
        "Shivam Gupta",
        "Venkataramana Runkana"
      ],
      "abstract": "Digital Twin technology creates virtual replicas of physical objects,\nprocesses, or systems by replicating their properties, data, and behaviors.\nThis advanced technology offers a range of intelligent functionalities, such as\nmodeling, simulation, and data-driven decision-making, that facilitate design\noptimization, performance estimation, and monitoring operations. Forecasting\nplays a pivotal role in Digital Twin technology, as it enables the prediction\nof future outcomes, supports informed decision-making, minimizes risks, driving\nimprovements in efficiency, productivity, and cost reduction. Recently, Digital\nTwin technology has leveraged Graph forecasting techniques in large-scale\ncomplex sensor networks to enable accurate forecasting and simulation of\ndiverse scenarios, fostering proactive and data-driven decision making.\nHowever, existing Graph forecasting techniques lack scalability for many\nreal-world applications. They have limited ability to adapt to non-stationary\nenvironments, retain past knowledge, lack a mechanism to capture the higher\norder spatio-temporal dynamics, and estimate uncertainty in model predictions.\nTo surmount the challenges, we introduce a hybrid architecture that enhances\nthe hypergraph representation learning backbone by incorporating fast\nadaptation to new patterns and memory-based retrieval of past knowledge. This\nbalance aims to improve the slowly-learned backbone and achieve better\nperformance in adapting to recent changes. In addition, it models the\ntime-varying uncertainty of multi-horizon forecasts, providing estimates of\nprediction uncertainty. Our forecasting architecture has been validated through\nablation studies and has demonstrated promising results across multiple\nbenchmark datasets, surpassing state-ofthe-art forecasting methods by a\nsignificant margin.",
      "tldr_zh": "这篇论文针对 Digital Twin 技术中的预测挑战，提出了一种结合超图重连（Hypergraph Rewiring）和记忆增强（Memory-Augmented）技术的混合架构，以解决现有图预测方法在可扩展性、适应非平稳环境、知识保留以及捕捉高阶时空动态方面的不足。该架构通过快速适应新模式、基于记忆的知识检索和不确定性估计，增强了超图表示学习骨干网络，从而实现更准确的多 horizons 预测。实验结果显示，该方法在多个基准数据集上显著超越了现有状态-of-the-art 预测技术，证明了其在促进数据驱动决策方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted at AI for Digital Twins and Cyber-Physical\n  Applications Workshop, International Joint Conferences on Artificial\n  Intelligence(IJCAI-23). arXiv admin note: text overlap with arXiv:2408.12409",
      "pdf_url": "http://arxiv.org/pdf/2408.12634v1",
      "published_date": "2024-08-22 14:08:45 UTC",
      "updated_date": "2024-08-22 14:08:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:52:28.653004"
    },
    {
      "arxiv_id": "2408.12413v3",
      "title": "Dynamic PDB: A New Dataset and a SE(3) Model Extension by Integrating Dynamic Behaviors and Physical Properties in Protein Structures",
      "title_zh": "Dynamic PDB",
      "authors": [
        "Ce Liu",
        "Jun Wang",
        "Zhiqiang Cai",
        "Yingxu Wang",
        "Huizhen Kuang",
        "Kaihui Cheng",
        "Liwei Zhang",
        "Qingkun Su",
        "Yining Tang",
        "Fenglei Cao",
        "Limei Han",
        "Siyu Zhu",
        "Yuan Qi"
      ],
      "abstract": "Despite significant progress in static protein structure collection and\nprediction, the dynamic behavior of proteins, one of their most vital\ncharacteristics, has been largely overlooked in prior research. This oversight\ncan be attributed to the limited availability, diversity, and heterogeneity of\ndynamic protein datasets. To address this gap, we propose to enhance existing\nprestigious static 3D protein structural databases, such as the Protein Data\nBank (PDB), by integrating dynamic data and additional physical properties.\nSpecifically, we introduce a large-scale dataset, Dynamic PDB, encompassing\napproximately 12.6K proteins, each subjected to all-atom molecular dynamics\n(MD) simulations lasting 1 microsecond to capture conformational changes.\nFurthermore, we provide a comprehensive suite of physical properties, including\natomic velocities and forces, potential and kinetic energies of proteins, and\nthe temperature of the simulation environment, recorded at 1 picosecond\nintervals throughout the simulations. For benchmarking purposes, we evaluate\nstate-of-the-art methods on the proposed dataset for the task of trajectory\nprediction. To demonstrate the value of integrating richer physical properties\nin the study of protein dynamics and related model design, we base our approach\non the SE(3) diffusion model and incorporate these physical properties into the\ntrajectory prediction process. Preliminary results indicate that this\nstraightforward extension of the SE(3) model yields improved accuracy, as\nmeasured by MAE and RMSD, when the proposed physical properties are taken into\nconsideration. https://fudan-generative-vision.github.io/dynamicPDB/ .",
      "tldr_zh": "本研究针对蛋白质动态行为在现有研究中的忽视，提出一个新数据集Dynamic PDB，该数据集基于Protein Data Bank (PDB)扩展，包含约12.6K蛋白质的1微秒分子动力学(MD)模拟数据，并整合了原子速度、力、势能、动能和模拟温度等物理属性，每1皮秒记录一次。为评估其价值，研究者扩展了SE(3)扩散模型，将这些物理属性融入轨迹预测任务中，实验结果显示扩展模型在MAE和RMSD指标上比基线方法准确性有所提升。",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12413v3",
      "published_date": "2024-08-22 14:06:01 UTC",
      "updated_date": "2024-09-18 10:53:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:52:40.858897"
    },
    {
      "arxiv_id": "2408.12409v1",
      "title": "Multi-Source Knowledge-Based Hybrid Neural Framework for Time Series Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sagar Srinivas Sakhinana",
        "Krishna Sai Sudhir Aripirala",
        "Shivam Gupta",
        "Venkataramana Runkana"
      ],
      "abstract": "Accurately predicting the behavior of complex dynamical systems,\ncharacterized by high-dimensional multivariate time series(MTS) in\ninterconnected sensor networks, is crucial for informed decision-making in\nvarious applications to minimize risk. While graph forecasting networks(GFNs)\nare ideal for forecasting MTS data that exhibit spatio-temporal dependencies,\nprior works rely solely on the domain-specific knowledge of time-series\nvariables inter-relationships to model the nonlinear dynamics, neglecting\ninherent relational structural dependencies among the variables within the MTS\ndata. In contrast, contemporary works infer relational structures from MTS data\nbut neglect domain-specific knowledge. The proposed hybrid architecture\naddresses these limitations by combining both domain-specific knowledge and\nimplicit knowledge of the relational structure underlying the MTS data using\nKnowledge-Based Compositional Generalization. The hybrid architecture shows\npromising results on multiple benchmark datasets, outperforming\nstate-of-the-art forecasting methods. Additionally, the architecture models the\ntime varying uncertainty of multi-horizon forecasts.",
      "tldr_zh": "该论文针对复杂动态系统的多变量时间序列(MTS)预测问题，提出了一种基于多源知识的混合神经框架，以解决现有方法忽略领域特定知识或隐含关系结构的问题。该框架结合领域特定知识和从MTS数据中推断的隐含关系结构，使用Knowledge-Based Compositional Generalization来建模非线性动态和时空依赖性。在多个基准数据集上，该方法优于最先进的时间序列预测模型，并能够处理多 horizons 预测的时间变化不确定性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper is accepted at Knowledge-Based Compositional Generalization\n  Workshop, International Joint Conferences on Artificial\n  Intelligence(IJCAI-23)",
      "pdf_url": "http://arxiv.org/pdf/2408.12409v1",
      "published_date": "2024-08-22 13:58:55 UTC",
      "updated_date": "2024-08-22 13:58:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:52:52.196587"
    },
    {
      "arxiv_id": "2408.12400v1",
      "title": "Multi-Style Facial Sketch Synthesis through Masked Generative Modeling",
      "title_zh": "基于掩码生成建模的多风格面部素描合成",
      "authors": [
        "Bowen Sun",
        "Guo Lu",
        "Shibao Zheng"
      ],
      "abstract": "The facial sketch synthesis (FSS) model, capable of generating sketch\nportraits from given facial photographs, holds profound implications across\nmultiple domains, encompassing cross-modal face recognition, entertainment,\nart, media, among others. However, the production of high-quality sketches\nremains a formidable task, primarily due to the challenges and flaws associated\nwith three key factors: (1) the scarcity of artist-drawn data, (2) the\nconstraints imposed by limited style types, and (3) the deficiencies of\nprocessing input information in existing models. To address these difficulties,\nwe propose a lightweight end-to-end synthesis model that efficiently converts\nimages to corresponding multi-stylized sketches, obviating the necessity for\nany supplementary inputs (\\eg, 3D geometry). In this study, we overcome the\nissue of data insufficiency by incorporating semi-supervised learning into the\ntraining process. Additionally, we employ a feature extraction module and style\nembeddings to proficiently steer the generative transformer during the\niterative prediction of masked image tokens, thus achieving a continuous\nstylized output that retains facial features accurately in sketches. The\nextensive experiments demonstrate that our method consistently outperforms\nprevious algorithms across multiple benchmarks, exhibiting a discernible\ndisparity.",
      "tldr_zh": "本文提出一种基于 Masked Generative Modeling 的多样式面部草图合成（Facial Sketch Synthesis, FSS）模型，能够将面部照片高效转换为高质量的多样式草图，解决数据稀缺、样式类型有限以及现有模型处理输入信息不足的挑战。该模型采用轻量级端到端架构，通过半监督学习缓解数据不足问题，并利用特征提取模块和样式嵌入来引导生成式 Transformer 在迭代预测 masked 图像 tokens 时实现连续样式输出，同时准确保留面部特征。无需额外输入（如 3D 几何），该方法在多个基准测试中显著优于现有算法，展示了出色的性能优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12400v1",
      "published_date": "2024-08-22 13:45:04 UTC",
      "updated_date": "2024-08-22 13:45:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:53:04.278586"
    },
    {
      "arxiv_id": "2408.12632v1",
      "title": "Generative Diffusion Model-based Downscaling of Observed Sea Surface Height over Kuroshio Extension since 2000",
      "title_zh": "翻译失败",
      "authors": [
        "Qiuchang Han",
        "Xingliang Jiang",
        "Yang Zhao",
        "Xudong Wang",
        "Zhijin Li",
        "Renhe Zhang"
      ],
      "abstract": "Satellite altimetry has been widely utilized to monitor global sea surface\ndynamics, enabling investigation of upper ocean variability from basin-scale to\nlocalized eddy ranges. However, the sparse spatial resolution of observational\naltimetry limits our understanding of oceanic submesoscale variability,\nprevalent at horizontal scales below 0.25o resolution. Here, we introduce a\nstate-of-the-art generative diffusion model to train high-resolution sea\nsurface height (SSH) reanalysis data and demonstrate its advantage in\nobservational SSH downscaling over the eddy-rich Kuroshio Extension region. The\ndiffusion-based model effectively downscales raw satellite-interpolated data\nfrom 0.25o resolution to 1/16o, corresponding to approximately 12-km\nwavelength. This model outperforms other high-resolution reanalysis datasets\nand neural network-based methods. Also, it successfully reproduces the spatial\npatterns and power spectra of satellite along-track observations. Our\ndiffusion-based results indicate that eddy kinetic energy at horizontal scales\nless than 250 km has intensified significantly since 2004 in the Kuroshio\nExtension region. These findings underscore the great potential of deep\nlearning in reconstructing satellite altimetry and enhancing our understanding\nof ocean dynamics at eddy scales.",
      "tldr_zh": "该研究利用生成扩散模型(generative diffusion model)对卫星高度计观测的海面高度(Sea Surface Height, SSH)数据进行下采样，针对黑潮延伸区(Kuroshio Extension)从2000年以来进行高分辨率重建，将原始0.25°分辨率提升至1/16°（约12公里）。该模型在训练中使用高分辨率SSH再分析数据，比其他再分析数据集和神经网络方法表现出色，并成功再现了卫星沿轨观测的空间模式和功率谱。结果显示，自2004年起，该区域小于250公里的水平尺度涡动能(eddy kinetic energy)显著增强，突显了深度学习在提升海洋动态理解方面的潜力。",
      "categories": [
        "physics.ao-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "28 pages, 7 figures, and 1 table",
      "pdf_url": "http://arxiv.org/pdf/2408.12632v1",
      "published_date": "2024-08-22 13:26:19 UTC",
      "updated_date": "2024-08-22 13:26:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:53:19.530495"
    },
    {
      "arxiv_id": "2408.12373v2",
      "title": "Cell-ontology guided transcriptome foundation model",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Yuan",
        "Zhihao Zhan",
        "Zuobai Zhang",
        "Manqi Zhou",
        "Jianan Zhao",
        "Boyu Han",
        "Yue Li",
        "Jian Tang"
      ],
      "abstract": "Transcriptome foundation models TFMs hold great promises of deciphering the\ntranscriptomic language that dictate diverse cell functions by self-supervised\nlearning on large-scale single-cell gene expression data, and ultimately\nunraveling the complex mechanisms of human diseases. However, current TFMs\ntreat cells as independent samples and ignore the taxonomic relationships\nbetween cell types, which are available in cell ontology graphs. We argue that\neffectively leveraging this ontology information during the TFM pre-training\ncan improve learning biologically meaningful gene co-expression patterns while\npreserving TFM as a general purpose foundation model for downstream zero-shot\nand fine-tuning tasks. To this end, we present single cell, Cell-ontology\nguided TFM scCello. We introduce cell-type coherence loss and ontology\nalignment loss, which are minimized along with the masked gene expression\nprediction loss during the pre-training. The novel loss component guide scCello\nto learn the cell-type-specific representation and the structural relation\nbetween cell types from the cell ontology graph, respectively. We pre-trained\nscCello on 22 million cells from CellxGene database leveraging their cell-type\nlabels mapped to the cell ontology graph from Open Biological and Biomedical\nOntology Foundry. Our TFM demonstrates competitive generalization and\ntransferability performance over the existing TFMs on biologically important\ntasks including identifying novel cell types of unseen cells, prediction of\ncell-type-specific marker genes, and cancer drug responses.",
      "tldr_zh": "本研究提出了一种基于细胞本体（cell ontology）的转录组基础模型（Transcriptome foundation models, TFMs）——scCello，以解决现有TFMs忽略细胞类型间分类关系的局限性。scCello在预训练过程中引入cell-type coherence loss和ontology alignment loss，与masked gene expression prediction loss结合，引导模型学习细胞类型特异性表示和细胞类型间的结构关系，并在CellxGene数据库的2200万细胞数据上进行训练。实验结果显示，scCello在零样本和微调任务中表现出色，包括识别新细胞类型、预测细胞类型特异性标记基因（marker genes）和癌症药物反应，展现出比现有TFMs更强的泛化性和可转移性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024 as Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2408.12373v2",
      "published_date": "2024-08-22 13:15:49 UTC",
      "updated_date": "2025-02-28 17:36:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:53:39.642758"
    },
    {
      "arxiv_id": "2408.12369v2",
      "title": "RoundTable: Leveraging Dynamic Schema and Contextual Autocomplete for Enhanced Query Precision in Tabular Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Pratyush Kumar",
        "Kuber Vijaykumar Bellad",
        "Bharat Vadlamudi",
        "Aman Chadha"
      ],
      "abstract": "With advancements in Large Language Models (LLMs), a major use case that has\nemerged is querying databases in plain English, translating user questions into\nexecutable database queries, which has improved significantly. However,\nreal-world datasets often feature a vast array of attributes and complex\nvalues, complicating the LLMs task of accurately identifying relevant columns\nor values from natural language queries. Traditional methods cannot fully relay\nthe datasets size and complexity to the LLM. To address these challenges, we\npropose a novel framework that leverages Full-Text Search (FTS) on the input\ntable. This approach not only enables precise detection of specific values and\ncolumns but also narrows the search space for language models, thereby\nenhancing query accuracy. Additionally, it supports a custom auto-complete\nfeature that suggests queries based on the data in the table. This integration\nsignificantly refines the interaction between the user and complex datasets,\noffering a sophisticated solution to the limitations faced by current table\nquerying capabilities. This work is accompanied by an application for both Mac\nand Windows platforms, which readers can try out themselves on their own data.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 在表格问题回答中的挑战，提出 RoundTable 框架，以解决真实数据集的庞大属性和复杂值导致的查询不准问题。该框架利用 Full-Text Search (FTS) 在输入表上进行精确检测和列值识别，同时整合 Dynamic Schema 和 Contextual Autocomplete 功能，缩小语言模型的搜索空间并提供基于数据的查询建议。实验结果显示，该方法显著提升了查询精确度，并通过附带的 Mac 和 Windows 应用，用户可以直接在自身数据上体验交互改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12369v2",
      "published_date": "2024-08-22 13:13:06 UTC",
      "updated_date": "2024-08-23 08:11:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:53:40.256850"
    },
    {
      "arxiv_id": "2408.12364v1",
      "title": "SAM-SP: Self-Prompting Makes SAM Great Again",
      "title_zh": "SAM-SP：自提示使",
      "authors": [
        "Chunpeng Zhou",
        "Kangjie Ning",
        "Qianqian Shen",
        "Sheng Zhou",
        "Zhi Yu",
        "Haishuai Wang"
      ],
      "abstract": "The recently introduced Segment Anything Model (SAM), a Visual Foundation\nModel (VFM), has demonstrated impressive capabilities in zero-shot segmentation\ntasks across diverse natural image datasets. Despite its success, SAM\nencounters noticeably performance degradation when applied to specific domains,\nsuch as medical images. Current efforts to address this issue have involved\nfine-tuning strategies, intended to bolster the generalizability of the vanilla\nSAM. However, these approaches still predominantly necessitate the utilization\nof domain specific expert-level prompts during the evaluation phase, which\nseverely constrains the model's practicality.\n  To overcome this limitation, we introduce a novel self-prompting based\nfine-tuning approach, called SAM-SP, tailored for extending the vanilla SAM\nmodel. Specifically, SAM-SP leverages the output from the previous iteration of\nthe model itself as prompts to guide subsequent iteration of the model. This\nself-prompting module endeavors to learn how to generate useful prompts\nautonomously and alleviates the dependence on expert prompts during the\nevaluation phase, significantly broadening SAM's applicability. Additionally,\nwe integrate a self-distillation module to enhance the self-prompting process\nfurther. Extensive experiments across various domain specific datasets validate\nthe effectiveness of the proposed SAM-SP. Our SAM-SP not only alleviates the\nreliance on expert prompts but also exhibits superior segmentation performance\ncomparing to the state-of-the-art task-specific segmentation approaches, the\nvanilla SAM, and SAM-based approaches.",
      "tldr_zh": "该研究针对 Segment Anything Model (SAM) 在特定领域（如医疗图像）上的性能下降问题，提出了一种新型自提示(self-prompting)微调方法，名为 SAM-SP。SAM-SP 通过利用模型自身的前一迭代输出作为提示来指导后续迭代，从而自主学习生成有用提示，并减少了对专家级提示的依赖。同时，该方法整合了自蒸馏(self-distillation)模块，进一步提升自提示过程的效率。实验在多个领域特定数据集上验证了 SAM-SP 的有效性，其分割性能优于现有任务特定方法、原始 SAM 模型以及其他 SAM 基于方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2408.12364v1",
      "published_date": "2024-08-22 13:03:05 UTC",
      "updated_date": "2024-08-22 13:03:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:53:52.379489"
    },
    {
      "arxiv_id": "2408.12355v1",
      "title": "Class-balanced Open-set Semi-supervised Object Detection for Medical Images",
      "title_zh": "翻译失败",
      "authors": [
        "Zhanyun Lu",
        "Renshu Gu",
        "Huimin Cheng",
        "Siyu Pang",
        "Mingyu Xu",
        "Peifang Xu",
        "Yaqi Wang",
        "Yuichiro Kinoshita",
        "Juan Ye",
        "Gangyong Jia",
        "Qing Wu"
      ],
      "abstract": "Medical image datasets in the real world are often unlabeled and imbalanced,\nand Semi-Supervised Object Detection (SSOD) can utilize unlabeled data to\nimprove an object detector. However, existing approaches predominantly assumed\nthat the unlabeled data and test data do not contain out-of-distribution (OOD)\nclasses. The few open-set semi-supervised object detection methods have two\nweaknesses: first, the class imbalance is not considered; second, the OOD\ninstances are distinguished and simply discarded during pseudo-labeling. In\nthis paper, we consider the open-set semi-supervised object detection problem\nwhich leverages unlabeled data that contain OOD classes to improve object\ndetection for medical images. Our study incorporates two key innovations:\nCategory Control Embed (CCE) and out-of-distribution Detection Fusion\nClassifier (OODFC). CCE is designed to tackle dataset imbalance by constructing\na Foreground information Library, while OODFC tackles open-set challenges by\nintegrating the ``unknown'' information into basic pseudo-labels. Our method\noutperforms the state-of-the-art SSOD performance, achieving a 4.25 mAP\nimprovement on the public Parasite dataset.",
      "tldr_zh": "该论文针对医疗图像的无标签和不平衡数据集，提出了一种 Class-balanced Open-set Semi-supervised Object Detection (SSOD) 方法，以利用包含 out-of-distribution (OOD) 类的无标签数据来提升物体检测性能。创新点包括 Category Control Embed (CCE)，通过构建 Foreground information Library 来处理类别不平衡问题，以及 out-of-distribution Detection Fusion Classifier (OODFC)，将“unknown”信息整合到伪标签中以应对开放集挑战。该方法在公共 Parasite 数据集上实现了 4.25 mAP 的性能提升，超过了现有最先进 SSOD 模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12355v1",
      "published_date": "2024-08-22 12:54:15 UTC",
      "updated_date": "2024-08-22 12:54:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:54:04.409291"
    },
    {
      "arxiv_id": "2408.12337v1",
      "title": "Fine-tuning Smaller Language Models for Question Answering over Financial Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Karmvir Singh Phogat",
        "Sai Akhil Puranam",
        "Sridhar Dasaratha",
        "Chetan Harsha",
        "Shashishekar Ramakrishna"
      ],
      "abstract": "Recent research has shown that smaller language models can acquire\nsubstantial reasoning abilities when fine-tuned with reasoning exemplars\ncrafted by a significantly larger teacher model. We explore this paradigm for\nthe financial domain, focusing on the challenge of answering questions that\nrequire multi-hop numerical reasoning over financial texts. We assess the\nperformance of several smaller models that have been fine-tuned to generate\nprograms that encode the required financial reasoning and calculations. Our\nfindings demonstrate that these fine-tuned smaller models approach the\nperformance of the teacher model.\n  To provide a granular analysis of model performance, we propose an approach\nto investigate the specific student model capabilities that are enhanced by\nfine-tuning. Our empirical analysis indicates that fine-tuning refines the\nstudent models ability to express and apply the required financial concepts\nalong with adapting the entity extraction for the specific data format. In\naddition, we hypothesize and demonstrate that comparable financial reasoning\ncapability can be induced using relatively smaller datasets.",
      "tldr_zh": "本文研究了通过微调较小语言模型来处理金融文档中的问答任务，特别针对需要多跳数值推理的问题。方法涉及使用较大教师模型创建的推理示例来微调这些模型，使其生成编码财务推理和计算的程序。结果显示，微调后的较小模型性能接近教师模型；此外，细粒度分析表明，这种微调增强了模型表达和应用财务概念的能力，并证明使用较小数据集即可诱导相似的财务推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12337v1",
      "published_date": "2024-08-22 12:23:29 UTC",
      "updated_date": "2024-08-22 12:23:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:54:19.917370"
    },
    {
      "arxiv_id": "2408.12334v2",
      "title": "Boosting Graph Neural Network Expressivity with Learnable Lanczos Constraints",
      "title_zh": "通过可学习的 Lanczos 约束提升图神经网络的表达能力",
      "authors": [
        "Niloofar Azizi",
        "Nils Kriege",
        "Horst Bischof"
      ],
      "abstract": "Graph Neural Networks (GNNs) excel in handling graph-structured data but\noften underperform in link prediction tasks compared to classical methods,\nmainly due to the limitations of the commonly used message-passing principle.\nNotably, their ability to distinguish non-isomorphic graphs is limited by the\n1-dimensional Weisfeiler-Lehman test. Our study presents a novel method to\nenhance the expressivity of GNNs by embedding induced subgraphs into the graph\nLaplacian matrix's eigenbasis. We introduce a Learnable Lanczos algorithm with\nLinear Constraints (LLwLC), proposing two novel subgraph extraction strategies:\nencoding vertex-deleted subgraphs and applying Neumann eigenvalue constraints.\nFor the former, we demonstrate the ability to distinguish graphs that are\nindistinguishable by 2-WL, while maintaining efficient time complexity. The\nlatter focuses on link representations enabling differentiation between\n$k$-regular graphs and node automorphism, a vital aspect for link prediction\ntasks. Our approach results in an extremely lightweight architecture, reducing\nthe need for extensive training datasets. Empirically, our method improves\nperformance in challenging link prediction tasks across benchmark datasets,\nestablishing its practical utility and supporting our theoretical findings.\nNotably, LLwLC achieves 20x and 10x speedup by only requiring 5% and 10% data\nfrom the PubMed and OGBL-Vessel datasets while comparing to the\nstate-of-the-art.",
      "tldr_zh": "本文针对Graph Neural Networks (GNNs)在链接预测任务中的表现不足，提出了一种提升其表达能力的方法，即Learnable Lanczos algorithm with Linear Constraints (LLwLC)。该方法通过嵌入诱导子图到图Laplacian矩阵的特征基，并引入编码顶点删除子图和Neumann特征值约束两种策略，使GNNs能够区分2-WL测试无法区分的图，同时保持高效时间复杂度。实验结果显示，LLwLC在基准数据集上显著提升链接预测性能，仅需PubMed和OGBL-Vessel数据集的5%和10%数据，即实现20倍和10倍的速度加速，并与最先进方法相当。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12334v2",
      "published_date": "2024-08-22 12:22:00 UTC",
      "updated_date": "2025-02-14 22:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:54:30.410095"
    },
    {
      "arxiv_id": "2408.12333v3",
      "title": "GRATR: Zero-Shot Evidence Graph Retrieval-Augmented Trustworthiness Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Ying Zhu",
        "Shengchang Li",
        "Ziqian Kong",
        "Qiang Yang",
        "Peilan Xu"
      ],
      "abstract": "Trustworthiness reasoning aims to enable agents in multiplayer games with\nincomplete information to identify potential allies and adversaries, thereby\nenhancing decision-making. In this paper, we introduce the graph\nretrieval-augmented trustworthiness reasoning (GRATR) framework, which\nretrieves observable evidence from the game environment to inform\ndecision-making by large language models (LLMs) without requiring additional\ntraining, making it a zero-shot approach. Within the GRATR framework, agents\nfirst observe the actions of other players and evaluate the resulting shifts in\ninter-player trust, constructing a corresponding trustworthiness graph. During\ndecision-making, the agent performs multi-hop retrieval to evaluate\ntrustworthiness toward a specific target, where evidence chains are retrieved\nfrom multiple trusted sources to form a comprehensive assessment. Experiments\nin the multiplayer game \\emph{Werewolf} demonstrate that GRATR outperforms the\nalternatives, improving reasoning accuracy by 50.5\\% and reducing hallucination\nby 30.6\\% compared to the baseline method. Additionally, when tested on a\ndataset of Twitter tweets during the U.S. election period, GRATR surpasses the\nbaseline method by 10.4\\% in accuracy, highlighting its potential in real-world\napplications such as intent analysis.",
      "tldr_zh": "本文提出 GRATR 框架，这是一种零样本（Zero-Shot）证据图检索增强的信任度推理方法，旨在帮助多人游戏中的代理通过检索游戏环境中的可观察证据来识别盟友和对手，从而提升决策质量。框架的核心包括构建信任度图（trustworthiness graph）和进行多跳检索（multi-hop retrieval），以从多个可信来源形成全面的信任评估。实验结果显示，在 Werewolf 游戏中，GRATR 比基线方法提高了 50.5% 的推理准确率并减少了 30.6% 的幻觉；在 Twitter 数据集上，准确率提升了 10.4%，证明了其在真实世界应用如意图分析中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12333v3",
      "published_date": "2024-08-22 12:21:22 UTC",
      "updated_date": "2025-01-27 09:18:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:54:43.940975"
    },
    {
      "arxiv_id": "2408.12326v1",
      "title": "Interactive DualChecker for Mitigating Hallucinations in Distilling Large Language Models",
      "title_zh": "互动式 DualChecker 用于缓解大语言模型知识蒸馏中的幻觉",
      "authors": [
        "Meiyun Wang",
        "Masahiro Suzuki",
        "Hiroki Sakaji",
        "Kiyoshi Izumi"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities\nacross various machine learning (ML) tasks. Given the high costs of creating\nannotated datasets for supervised learning, LLMs offer a valuable alternative\nby enabling effective few-shot in-context learning. However, these models can\nproduce hallucinations, particularly in domains with incomplete knowledge.\nAdditionally, current methods for knowledge distillation using LLMs often\nstruggle to enhance the effectiveness of both teacher and student models. To\naddress these challenges, we introduce DualChecker, an innovative framework\ndesigned to mitigate hallucinations and improve the performance of both teacher\nand student models during knowledge distillation. DualChecker employs\nContextAligner to ensure that the context provided by teacher models aligns\nwith human labeling standards. It also features a dynamic checker system that\nenhances model interaction: one component re-prompts teacher models with more\ndetailed content when they show low confidence, and another identifies\nborderline cases from student models to refine the teaching templates. This\ninteractive process promotes continuous improvement and effective knowledge\ntransfer between the models. We evaluate DualChecker using a green innovation\ntextual dataset that includes binary, multiclass, and token classification\ntasks. The experimental results show that DualChecker significantly outperforms\nexisting state-of-the-art methods, achieving up to a 17% improvement in F1\nscore for teacher models and 10% for student models. Notably, student models\nfine-tuned with LLM predictions perform comparably to those fine-tuned with\nactual data, even in a challenging domain. We make all datasets, models, and\ncode from this research publicly available.",
      "tldr_zh": "本研究针对Large Language Models (LLMs) 在知识蒸馏过程中产生的幻觉问题，提出了一种创新框架Interactive DualChecker，以提升教师和学生模型的性能。DualChecker 包括ContextAligner 组件，确保教师模型的上下文与人类标注标准一致，并采用动态检查器系统：一个通过重新提示教师模型以更多细节来处理低信心输出，另一个识别学生模型的边界案例并优化教学模板，从而实现模型间互动和知识转移。在绿色创新文本数据集上的实验显示，DualChecker 比现有方法提高教师模型的F1分数17%和学生模型的10%，且使用LLM预测微调的学生模型性能可媲美实际数据微调版本，所有数据集、模型和代码已公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12326v1",
      "published_date": "2024-08-22 12:04:04 UTC",
      "updated_date": "2024-08-22 12:04:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:54:52.678242"
    },
    {
      "arxiv_id": "2408.12320v3",
      "title": "TensorOpera Router: A Multi-Model Router for Efficient LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Dimitris Stripelis",
        "Zijian Hu",
        "Jipeng Zhang",
        "Zhaozhuo Xu",
        "Alay Dilipbhai Shah",
        "Han Jin",
        "Yuhang Yao",
        "Salman Avestimehr",
        "Chaoyang He"
      ],
      "abstract": "With the rapid growth of Large Language Models (LLMs) across various domains,\nnumerous new LLMs have emerged, each possessing domain-specific expertise. This\nproliferation has highlighted the need for quick, high-quality, and\ncost-effective LLM query response methods. Yet, no single LLM exists to\nefficiently balance this trilemma. Some models are powerful but extremely\ncostly, while others are fast and inexpensive but qualitatively inferior. To\naddress this challenge, we present TO-Router, a non-monolithic LLM querying\nsystem that seamlessly integrates various LLM experts into a single query\ninterface and dynamically routes incoming queries to the most high-performant\nexpert based on query's requirements. Through extensive experiments, we\ndemonstrate that when compared to standalone expert models, TO-Router improves\nquery efficiency by up to 40\\%, and leads to significant cost reductions of up\nto 30%, while maintaining or enhancing model performance by up to 10%.",
      "tldr_zh": "该论文介绍了TensorOpera Router (TO-Router)，一种多模型路由系统，旨在解决Large Language Models (LLMs) 在查询响应中面临的性能、速度和成本平衡难题。该系统将各种领域专长LLM整合到一个查询接口中，并根据查询需求动态路由到最合适的专家模型。通过广泛实验，TO-Router相比独立模型提高了查询效率达40%、降低了成本达30%，同时保持或提升了模型性能达10%。这项创新为高效的LLM推理提供了实用框架。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2; I.5"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.12320v3",
      "published_date": "2024-08-22 11:57:07 UTC",
      "updated_date": "2024-10-23 18:11:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:55:03.637494"
    },
    {
      "arxiv_id": "2408.12315v1",
      "title": "Large Language Models Are Self-Taught Reasoners: Enhancing LLM Applications via Tailored Problem-Solving Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Tzu-iunn Ong",
        "Taeyoon Kwon",
        "Jinyoung Yeo"
      ],
      "abstract": "Guiding large language models with a selected set of human-authored\ndemonstrations is a common practice for improving LLM applications. However,\nhuman effort can be costly, especially in specialized domains (e.g., clinical\ndiagnosis), and does not guarantee optimal performance due to the potential\ndiscrepancy of target skills between selected demonstrations and real test\ninstances. Motivated by these, this paper explores the automatic creation of\ncustomized demonstrations, whose target skills align with the given target\ninstance. We present SELF-TAUGHT, a problem-solving framework, which\nfacilitates demonstrations that are \"tailored\" to the target problem and\n\"filtered\" for better quality (i.e., correctness) in a zero-shot manner. In 15\ntasks of multiple-choice questions of diverse domains and the diagnosis of\nAlzheimer's disease (AD) with real-world patients, SELF-TAUGHT achieves\nsuperior performance to strong baselines (e.g., Few-shot CoT, Plan-and-Solve,\nAuto-CoT). We conduct comprehensive analyses on SELF-TAUGHT, including its\ngeneralizability to existing prompting methods and different LLMs, the quality\nof its intermediate generation, and more.",
      "tldr_zh": "该论文探讨了如何通过自动创建定制问题解决演示来提升 Large Language Models (LLMs) 的应用，以减少对人工演示的依赖。作者提出 SELF-TAUGHT 框架，该框架在零-shot 方式下生成针对目标实例的“定制”和“过滤”演示，确保演示的质量和相关性。在 15 个多选题任务以及 Alzheimer 疾病诊断等真实场景中，SELF-TAUGHT 表现优于基线方法如 Few-shot CoT 和 Auto-CoT，并通过全面分析验证了其泛化性及中间生成质量。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "preprint / under review",
      "pdf_url": "http://arxiv.org/pdf/2408.12315v1",
      "published_date": "2024-08-22 11:41:35 UTC",
      "updated_date": "2024-08-22 11:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:55:16.901442"
    },
    {
      "arxiv_id": "2408.12308v3",
      "title": "Deep Learning with CNNs: A Compact Holistic Tutorial with Focus on Supervised Regression (Preprint)",
      "title_zh": "翻译失败",
      "authors": [
        "Yansel Gonzalez Tejeda",
        "Helmut A. Mayer"
      ],
      "abstract": "In this tutorial, we present a compact and holistic discussion of Deep\nLearning with a focus on Convolutional Neural Networks (CNNs) and supervised\nregression. While there are numerous books and articles on the individual\ntopics we cover, comprehensive and detailed tutorials that address Deep\nLearning from a foundational yet rigorous and accessible perspective are rare.\nMost resources on CNNs are either too advanced, focusing on cutting-edge\narchitectures, or too narrow, addressing only specific applications like image\nclassification.This tutorial not only summarizes the most relevant concepts but\nalso provides an in-depth exploration of each, offering a complete yet agile\nset of ideas. Moreover, we highlight the powerful synergy between learning\ntheory, statistic, and machine learning, which together underpin the Deep\nLearning and CNN frameworks. We aim for this tutorial to serve as an optimal\nresource for students, professors, and anyone interested in understanding the\nfoundations of Deep Learning. Upon acceptance we will provide an accompanying\nrepository under\n\\href{https://github.com/neoglez/deep-learning-tutorial}{https://github.com/neoglez/deep-learning-tutorial}\n  Keywords: Tutorial, Deep Learning, Convolutional Neural Networks, Machine\nLearning.",
      "tldr_zh": "本教程提供了一个全面且基础的深度学习讨论，焦点在于 Convolutional Neural Networks (CNNs) 和 Supervised Regression，旨在填补现有资源过于高级或狭隘的空白。作者总结了关键概念并进行深入探索，强调学习理论、统计学和 Machine Learning 的协同作用，使其适合学生、教授和对基础知识感兴趣的读者。教程还附带一个 GitHub 仓库（https://github.com/neoglez/deep-learning-tutorial），作为配套资源以增强可访问性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to the journal Machine Learning and Knowledge Extraction",
      "pdf_url": "http://arxiv.org/pdf/2408.12308v3",
      "published_date": "2024-08-22 11:34:34 UTC",
      "updated_date": "2024-11-12 11:45:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:55:27.950439"
    },
    {
      "arxiv_id": "2408.12305v2",
      "title": "Tipta uzmanlik sinavinda (tus) buyuk dil modelleri insanlardan daha mi basarili?",
      "title_zh": "翻译失败",
      "authors": [
        "Yesim Aygul",
        "Muge Olucoglu",
        "Adil Alpkocak"
      ],
      "abstract": "The potential of artificial intelligence in medical education and assessment\nhas been made evident by recent developments in natural language processing and\nartificial intelligence. Medical questions can now be successfully answered by\nartificial intelligence algorithms. It can help medical practitioners. This\nstudy evaluates the performance of three different artificial intelligence\nmodels in answering Turkish medical questions in the 2021 1st Term Medical\nSpecialization Examination (MSE). MSE consists of a total of 240 questions\nacross clinical (CMST) and basic (BMST) medical sciences. According to the\nresults in CMST, it was concluded that Gemini correctly answered 82 questions,\nChatGPT-4 answered 105 questions and ChatGPT-4o answered 117 questions. In\nBMST, Gemini and ChatGPT-4 answered 93 questions and ChatGPT-4o answered 107\nquestions correctly according to the answer key. ChatGPT-4o outperformed the\ncandidate with the highest scores of 113 and 106 according to CMST and BMST\nrespectively. This study highlights the importance of the potential of\nartificial intelligence in medical education and assessment. It demonstrates\nthat advanced models can achieve high accuracy and contextual understanding,\ndemonstrating their potential role in medical education and evaluation.",
      "tldr_zh": "本研究评估了大型语言模型（Large Language Models）在2021年第一学期土耳其医学专业考试（MSE）中的表现，比较了Gemini、ChatGPT-4和ChatGPT-4o在临床医学科学测试（CMST）和基础医学科学测试（BMST）上的表现。结果显示，在CMST中，ChatGPT-4o正确回答117题，超过了最高考生分数；在BMST中，ChatGPT-4o正确回答107题，也优于人类表现。研究证明了AI模型的高准确性和上下文理解能力，突出了其在医学教育和评估中的潜在应用价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, in Turkish language, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12305v2",
      "published_date": "2024-08-22 11:25:08 UTC",
      "updated_date": "2024-08-27 06:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:55:41.392725"
    },
    {
      "arxiv_id": "2408.12304v1",
      "title": "OPTDTALS: Approximate Logic Synthesis via Optimal Decision Trees Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Hu",
        "Shaowei Cai"
      ],
      "abstract": "The growing interest in Explainable Artificial Intelligence (XAI) motivates\npromising studies of computing optimal Interpretable Machine Learning models,\nespecially decision trees. Such models generally provide optimality in compact\nsize or empirical accuracy. Recent works focus on improving efficiency due to\nthe natural scalability issue. The application of such models to practical\nproblems is quite limited. As an emerging problem in circuit design,\nApproximate Logic Synthesis (ALS) aims to reduce circuit complexity by\nsacrificing correctness. Recently, multiple heuristic machine learning methods\nhave been applied in ALS, which learns approximated circuits from samples of\ninput-output pairs.\n  In this paper, we propose a new ALS methodology realizing the approximation\nvia learning optimal decision trees in empirical accuracy. Compared to previous\nheuristic ALS methods, the guarantee of optimality achieves a more controllable\ntrade-off between circuit complexity and accuracy. Experimental results show\nclear improvements in our methodology in the quality of approximated designs\n(circuit complexity and accuracy) compared to the state-of-the-art approaches.",
      "tldr_zh": "该论文提出OPTDTALS，一种通过Optimal Decision Trees方法实现Approximate Logic Synthesis (ALS)的新方法，旨在通过学习经验准确性最优的决策树来平衡电路复杂度和准确性。相比传统的启发式机器学习方法，该方法提供更可控的权衡，确保了近似电路的可靠性。实验结果表明，OPTDTALS在电路复杂度和准确性方面比现有最先进方法有显著改善，为Explainable Artificial Intelligence (XAI)在电路设计中的应用提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12304v1",
      "published_date": "2024-08-22 11:23:58 UTC",
      "updated_date": "2024-08-22 11:23:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:55:52.835179"
    },
    {
      "arxiv_id": "2408.12293v1",
      "title": "AT-SNN: Adaptive Tokens for Vision Transformer on Spiking Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Donghwa Kang",
        "Youngmoon Lee",
        "Eun-Kyu Lee",
        "Brent Kang",
        "Jinkyu Lee",
        "Hyeongboo Baek"
      ],
      "abstract": "In the training and inference of spiking neural networks (SNNs), direct\ntraining and lightweight computation methods have been orthogonally developed,\naimed at reducing power consumption. However, only a limited number of\napproaches have applied these two mechanisms simultaneously and failed to fully\nleverage the advantages of SNN-based vision transformers (ViTs) since they were\noriginally designed for convolutional neural networks (CNNs). In this paper, we\npropose AT-SNN designed to dynamically adjust the number of tokens processed\nduring inference in SNN-based ViTs with direct training, wherein power\nconsumption is proportional to the number of tokens. We first demonstrate the\napplicability of adaptive computation time (ACT), previously limited to RNNs\nand ViTs, to SNN-based ViTs, enhancing it to discard less informative spatial\ntokens selectively. Also, we propose a new token-merge mechanism that relies on\nthe similarity of tokens, which further reduces the number of tokens while\nenhancing accuracy. We implement AT-SNN to Spikformer and show the\neffectiveness of AT-SNN in achieving high energy efficiency and accuracy\ncompared to state-of-the-art approaches on the image classification tasks,\nCIFAR10, CIFAR-100, and TinyImageNet. For example, our approach uses up to\n42.4% fewer tokens than the existing best-performing method on CIFAR-100, while\nconserving higher accuracy.",
      "tldr_zh": "该论文提出AT-SNN框架，用于在基于SNN（Spiking Neural Network）的Vision Transformer (ViTs)中动态调整推理过程中的token数量，以降低功耗。AT-SNN首先扩展了Adaptive Computation Time (ACT)机制，使其适用于SNN-based ViTs，从而选择性地丢弃不重要的空间token；同时引入一种基于token相似性的新token-merge机制，进一步减少token数量并提升准确率。在图像分类任务如CIFAR-10、CIFAR-100和TinyImageNet上，AT-SNN在Spikformer模型上实现了比现有最佳方法高能效表现，例如在CIFAR-100上减少42.4%的token同时保持更高准确率。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.12293v1",
      "published_date": "2024-08-22 11:06:18 UTC",
      "updated_date": "2024-08-22 11:06:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:56:05.236943"
    },
    {
      "arxiv_id": "2408.12292v1",
      "title": "Towards Deconfounded Image-Text Matching with Causal Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhui Li",
        "Xinqi Su",
        "Dan Song",
        "Lanjun Wang",
        "Kun Zhang",
        "An-An Liu"
      ],
      "abstract": "Prior image-text matching methods have shown remarkable performance on many\nbenchmark datasets, but most of them overlook the bias in the dataset, which\nexists in intra-modal and inter-modal, and tend to learn the spurious\ncorrelations that extremely degrade the generalization ability of the model.\nFurthermore, these methods often incorporate biased external knowledge from\nlarge-scale datasets as prior knowledge into image-text matching model, which\nis inevitable to force model further learn biased associations. To address\nabove limitations, this paper firstly utilizes Structural Causal Models (SCMs)\nto illustrate how intra- and inter-modal confounders damage the image-text\nmatching. Then, we employ backdoor adjustment to propose an innovative\nDeconfounded Causal Inference Network (DCIN) for image-text matching task. DCIN\n(1) decomposes the intra- and inter-modal confounders and incorporates them\ninto the encoding stage of visual and textual features, effectively eliminating\nthe spurious correlations during image-text matching, and (2) uses causal\ninference to mitigate biases of external knowledge. Consequently, the model can\nlearn causality instead of spurious correlations caused by dataset bias.\nExtensive experiments on two well-known benchmark datasets, i.e., Flickr30K and\nMSCOCO, demonstrate the superiority of our proposed method.",
      "tldr_zh": "现有图像-文本匹配方法忽略了数据集中的 intra-modal 和 inter-modal 偏置，导致模型学习虚假相关性并降低泛化能力，同时引入外部知识的偏置。本文首先利用 Structural Causal Models (SCMs) 分析这些混杂因素如何损害匹配任务，然后提出 Deconfounded Causal Inference Network (DCIN)，通过 backdoor adjustment 分解混杂因素并整合到视觉和文本特征编码阶段，以消除虚假相关性，并使用因果推断缓解外部知识偏置。结果显示，DCIN 使模型学习真正的因果关系而非虚假关联。在 Flickr30K 和 MSCOCO 数据集上的实验证明了该方法的优越性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ACM MM",
      "pdf_url": "http://arxiv.org/pdf/2408.12292v1",
      "published_date": "2024-08-22 11:04:28 UTC",
      "updated_date": "2024-08-22 11:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:56:18.113691"
    },
    {
      "arxiv_id": "2408.12279v1",
      "title": "Developing vocal system impaired patient-aimed voice quality assessment approach using ASR representation-included multiple features",
      "title_zh": "翻译失败",
      "authors": [
        "Shaoxiang Dang",
        "Tetsuya Matsumoto",
        "Yoshinori Takeuchi",
        "Takashi Tsuboi",
        "Yasuhiro Tanaka",
        "Daisuke Nakatsubo",
        "Satoshi Maesawa",
        "Ryuta Saito",
        "Masahisa Katsuno",
        "Hiroaki Kudo"
      ],
      "abstract": "The potential of deep learning in clinical speech processing is immense, yet\nthe hurdles of limited and imbalanced clinical data samples loom large. This\narticle addresses these challenges by showcasing the utilization of automatic\nspeech recognition and self-supervised learning representations, pre-trained on\nextensive datasets of normal speech. This innovative approach aims to estimate\nvoice quality of patients with impaired vocal systems. Experiments involve\nchecks on PVQD dataset, covering various causes of vocal system damage in\nEnglish, and a Japanese dataset focusing on patients with Parkinson's disease\nbefore and after undergoing subthalamic nucleus deep brain stimulation\n(STN-DBS) surgery. The results on PVQD reveal a notable correlation (>0.8 on\nPCC) and an extraordinary accuracy (<0.5 on MSE) in predicting Grade, Breathy,\nand Asthenic indicators. Meanwhile, progress has been achieved in predicting\nthe voice quality of patients in the context of STN-DBS.",
      "tldr_zh": "这篇论文提出了一种针对声音系统受损患者的语音质量评估方法，利用自动语音识别 (ASR) 和自监督学习表示，这些表示基于大量正常语音数据集进行预训练，以解决临床数据有限和不平衡的挑战。实验在 PVQD 数据集（涵盖英语声音损伤原因）和一个日语数据集（针对帕金森病患者在亚丘脑深部刺激手术 STN-DBS 前后）上进行。结果显示，该方法在预测 Grade、Breathy 和 Asthenic 指标时，相关性超过 0.8 (PCC)，均方误差小于 0.5 (MSE)，并在 STN-DBS 语境中取得了显著进展。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12279v1",
      "published_date": "2024-08-22 10:22:53 UTC",
      "updated_date": "2024-08-22 10:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:56:30.185028"
    },
    {
      "arxiv_id": "2408.12270v1",
      "title": "Variance reduction of diffusion model's gradients with Taylor approximation-based control variate",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Jeha",
        "Will Grathwohl",
        "Michael Riis Andersen",
        "Carl Henrik Ek",
        "Jes Frellsen"
      ],
      "abstract": "Score-based models, trained with denoising score matching, are remarkably\neffective in generating high dimensional data. However, the high variance of\ntheir training objective hinders optimisation. We attempt to reduce it with a\ncontrol variate, derived via a $k$-th order Taylor expansion on the training\nobjective and its gradient. We prove an equivalence between the two and\ndemonstrate empirically the effectiveness of our approach on a low dimensional\nproblem setting; and study its effect on larger problems.",
      "tldr_zh": "这篇论文针对 score-based models 在通过 denoising score matching 训练时梯度方差过高的优化问题，提出了一种基于 k-th order Taylor expansion 的 control variate 方法，以降低训练目标的方差。作者证明了该方法在训练目标及其梯度之间存在等价性，从而提升了模型的优化效率。通过实验验证，该方法在低维问题上显示出显著效果，并进一步探讨了其在大规模问题中的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, ICML Structured Probabilistic Inference & Generative\n  Modeling 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12270v1",
      "published_date": "2024-08-22 10:08:34 UTC",
      "updated_date": "2024-08-22 10:08:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:56:40.964411"
    },
    {
      "arxiv_id": "2408.12263v1",
      "title": "Toward the Evaluation of Large Language Models Considering Score Variance across Instruction Templates",
      "title_zh": "翻译失败",
      "authors": [
        "Yusuke Sakai",
        "Adam Nohejl",
        "Jiangnan Hang",
        "Hidetaka Kamigaito",
        "Taro Watanabe"
      ],
      "abstract": "The natural language understanding (NLU) performance of large language models\n(LLMs) has been evaluated across various tasks and datasets. The existing\nevaluation methods, however, do not take into account the variance in scores\ndue to differences in prompts, which leads to unfair evaluation and comparison\nof NLU performance. Moreover, evaluation designed for specific prompts is\ninappropriate for instruction tuning, which aims to perform well with any\nprompt. It is therefore necessary to find a way to measure NLU performance in a\nfair manner, considering score variance between different instruction\ntemplates. In this study, we provide English and Japanese cross-lingual\ndatasets for evaluating the NLU performance of LLMs, which include multiple\ninstruction templates for fair evaluation of each task, along with regular\nexpressions to constrain the output format. Furthermore, we propose the Sharpe\nscore as an evaluation metric that takes into account the variance in scores\nbetween templates. Comprehensive analysis of English and Japanese LLMs reveals\nthat the high variance among templates has a significant impact on the fair\nevaluation of LLMs.",
      "tldr_zh": "该研究指出，现有的自然语言理解 (NLU) 评估方法忽略了提示 (prompts) 差异导致的分数方差，从而造成对大型语言模型 (LLMs) 的不公平评估。作者提供了英文和日文跨语言数据集，包括多种指令模板和正则表达式，以约束输出格式并实现公平评估。针对此问题，他们提出了 Sharpe score 作为新指标，用于衡量模板间分数方差的影响。实验分析显示，这种方差对英文和日文 LLMs 的评估有显著影响，从而强调了改进评估方法的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12263v1",
      "published_date": "2024-08-22 10:00:20 UTC",
      "updated_date": "2024-08-22 10:00:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:56:51.931477"
    },
    {
      "arxiv_id": "2408.12259v2",
      "title": "How Safe is Your Safety Metric? Automatic Concatenation Tests for Metric Reliability",
      "title_zh": "翻译失败",
      "authors": [
        "Ora Nova Fandina",
        "Leshem Choshen",
        "Eitan Farchi",
        "George Kour",
        "Yotam Perlitz",
        "Orna Raz"
      ],
      "abstract": "Consider a scenario where a harmfulness evaluation metric intended to filter\nunsafe responses from a Large Language Model. When applied to individual\nharmful prompt-response pairs, it correctly flags them as unsafe by assigning a\nhigh-risk score. Yet, if those same pairs are concatenated, the metrics\ndecision unexpectedly reverses - labelling the combined content as safe with a\nlow score, allowing the harmful text to bypass the filter. We found that\nmultiple safety metrics, including advanced metrics such as GPT-based judges,\nexhibit this non-safe behaviour. Moreover, they show a strong sensitivity to\ninput order: responses are often classified as safe if safe content appears\nfirst, regardless of any harmful content that follows, and vice versa. These\nfindings underscore the importance of evaluating the safety of safety metrics,\nthat is, the reliability of their output scores. To address this, we developed\ngeneral, automatic, concatenation-based tests to assess key properties of these\nmetrics. When applied in a model safety scenario, the tests revealed\nsignificant inconsistencies in harmfulness evaluations.",
      "tldr_zh": "这篇论文揭示了安全指标（safety metrics）的潜在缺陷：尽管这些指标能正确识别单个有害提示，但当内容被连接时，它们可能错误地将有害文本标记为安全，尤其对输入顺序高度敏感，如安全内容先出现即被视为安全。研究发现，包括基于 GPT 的高级指标（GPT-based judges）在内的多种安全指标均存在此问题，突显了评估指标可靠性的必要性。为解决此问题，作者开发了通用的自动连接测试（automatic concatenation tests），用于检查这些指标的关键属性。在模型安全场景中，这些测试暴露了显著的评估不一致性，从而为改进安全评估提供了重要洞见。",
      "categories": [
        "cs.AI",
        "68T50"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12259v2",
      "published_date": "2024-08-22 09:57:57 UTC",
      "updated_date": "2025-02-12 19:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:57:05.553938"
    },
    {
      "arxiv_id": "2408.12254v1",
      "title": "A Language-agnostic Model of Child Language Acquisition",
      "title_zh": "翻译失败",
      "authors": [
        "Louis Mahon",
        "Omri Abend",
        "Uri Berger",
        "Katherine Demuth",
        "Mark Johnson",
        "Mark Steedman"
      ],
      "abstract": "This work reimplements a recent semantic bootstrapping child-language\nacquisition model, which was originally designed for English, and trains it to\nlearn a new language: Hebrew. The model learns from pairs of utterances and\nlogical forms as meaning representations, and acquires both syntax and word\nmeanings simultaneously. The results show that the model mostly transfers to\nHebrew, but that a number of factors, including the richer morphology in\nHebrew, makes the learning slower and less robust. This suggests that a clear\ndirection for future work is to enable the model to leverage the similarities\nbetween different word forms.",
      "tldr_zh": "本研究重新实现了语义引导(semantic bootstrapping)模型，用于儿童语言习得(child-language acquisition)，并将其从英语扩展到Hebrew。模型通过从话语和逻辑形式(logical forms)对学习，同步获取语法和单词含义。结果显示，该模型在Hebrew上基本可转移，但Hebrew更丰富的形态学(morphology)导致学习速度更慢且稳定性较差，这表明未来应开发模型来利用不同词形式之间的相似性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12254v1",
      "published_date": "2024-08-22 09:48:06 UTC",
      "updated_date": "2024-08-22 09:48:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:57:15.906142"
    },
    {
      "arxiv_id": "2408.12250v1",
      "title": "Can Artificial Intelligence Embody Moral Values?",
      "title_zh": "人工智能能够体现道德价值吗？",
      "authors": [
        "Torben Swoboda",
        "Lode Lauwaert"
      ],
      "abstract": "The neutrality thesis holds that technology cannot be laden with values. This\nlong-standing view has faced critiques, but much of the argumentation against\nneutrality has focused on traditional, non-smart technologies like bridges and\nrazors. In contrast, AI is a smart technology increasingly used in high-stakes\ndomains like healthcare, finance, and policing, where its decisions can cause\nmoral harm. In this paper, we argue that artificial intelligence, particularly\nartificial agents that autonomously make decisions to pursue their goals,\nchallenge the neutrality thesis. Our central claim is that the computational\nmodels underlying artificial agents can integrate representations of moral\nvalues such as fairness, honesty and avoiding harm. We provide a conceptual\nframework discussing the neutrality thesis, values, and AI. Moreover, we\nexamine two approaches to designing computational models of morality,\nartificial conscience and ethical prompting, and present empirical evidence\nfrom text-based game environments that artificial agents with such models\nexhibit more ethical behavior compared to agents without these models. The\nfindings support that AI can embody moral values, which contradicts the claim\nthat all technologies are necessarily value-neutral.",
      "tldr_zh": "本论文挑战中立论（neutrality thesis），即技术本身无法承载道德价值观，特别针对AI这种智能技术在医疗、金融和执法等高风险领域可能导致道德伤害。作者提出AI代理的计算模型可以整合道德价值观的表示，如公平、诚实和避免伤害，并通过概念框架分析了AI与价值观的关系。论文考察了两种方法——artificial conscience和ethical prompting，并在文本游戏环境中提供实证证据，显示配备这些模型的AI代理表现出更道德的行为，从而证明AI能体现道德价值观，反驳了技术必然中立的观点。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12250v1",
      "published_date": "2024-08-22 09:39:16 UTC",
      "updated_date": "2024-08-22 09:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:57:28.342806"
    },
    {
      "arxiv_id": "2408.12249v1",
      "title": "LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Aishik Nagar",
        "Viktor Schlegel",
        "Thanh-Tung Nguyen",
        "Hao Li",
        "Yuping Wu",
        "Kuluhan Binici",
        "Stefan Winkler"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly adopted for applications in\nhealthcare, reaching the performance of domain experts on tasks such as\nquestion answering and document summarisation. Despite their success on these\ntasks, it is unclear how well LLMs perform on tasks that are traditionally\npursued in the biomedical domain, such as structured information extration. To\nbreach this gap, in this paper, we systematically benchmark LLM performance in\nMedical Classification and Named Entity Recognition (NER) tasks. We aim to\ndisentangle the contribution of different factors to the performance,\nparticularly the impact of LLMs' task knowledge and reasoning capabilities,\ntheir (parametric) domain knowledge, and addition of external knowledge. To\nthis end we evaluate various open LLMs -- including BioMistral and Llama-2\nmodels -- on a diverse set of biomedical datasets, using standard prompting,\nChain-of-Thought (CoT) and Self-Consistency based reasoning as well as\nRetrieval-Augmented Generation (RAG) with PubMed and Wikipedia corpora.\nCounter-intuitively, our results reveal that standard prompting consistently\noutperforms more complex techniques across both tasks, laying bare the\nlimitations in the current application of CoT, self-consistency and RAG in the\nbiomedical domain. Our findings suggest that advanced prompting methods\ndeveloped for knowledge- or reasoning-intensive tasks, such as CoT or RAG, are\nnot easily portable to biomedical tasks where precise structured outputs are\nrequired. This highlights the need for more effective integration of external\nknowledge and reasoning mechanisms in LLMs to enhance their performance in\nreal-world biomedical applications.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 在生物医学信息提取任务（如分类和命名实体识别 (NER)）上的性能，挑战了 LLMs 作为零样本推理器的假设。研究者使用标准提示、Chain-of-Thought (CoT)、Self-Consistency 和 Retrieval-Augmented Generation (RAG) 等方法，对 BioMistral 和 Llama-2 等模型在多种生物医学数据集上进行基准测试。结果显示，标准提示在这些任务中 consistently 优于更复杂的技巧，揭示了 CoT、Self-Consistency 和 RAG 在生物医学领域的局限性。论文强调，需要更有效的外部知识整合和推理机制，以提升 LLMs 在真实生物医学应用的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.12249v1",
      "published_date": "2024-08-22 09:37:40 UTC",
      "updated_date": "2024-08-22 09:37:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:57:42.194578"
    },
    {
      "arxiv_id": "2408.12247v2",
      "title": "Enhanced Fine-Tuning of Lightweight Domain-Specific Q&A Model Based on Large Language Models",
      "title_zh": "基于大型语言模型的轻量级领域特定问答模型增强微",
      "authors": [
        "Shenglin Zhang",
        "Pengtian Zhu",
        "Minghua Ma",
        "Jiagang Wang",
        "Yongqian Sun",
        "Dongwen Li",
        "Jingyu Wang",
        "Qianying Guo",
        "Xiaolei Hua",
        "Lin Zhu",
        "Dan Pei"
      ],
      "abstract": "Large language models (LLMs) excel at general question-answering (Q&A) but\noften fall short in specialized domains due to a lack of domain-specific\nknowledge. Commercial companies face the dual challenges of privacy protection\nand resource constraints when involving LLMs for fine-tuning. This paper\npropose a novel framework, Self-Evolution, designed to address these issues by\nleveraging lightweight open-source LLMs through multiple iterative fine-tuning\nrounds. To enhance the efficiency of iterative fine-tuning, Self-Evolution\nemploy a strategy that filters and reinforces the knowledge with higher value\nduring the iterative process. We employed Self-Evolution on Qwen1.5-7B-Chat\nusing 4,000 documents containing rich domain knowledge from China Mobile,\nachieving a performance score 174% higher on domain-specific question-answering\nevaluations than Qwen1.5-7B-Chat and even 22% higher than Qwen1.5-72B-Chat.\nSelf-Evolution has been deployed in China Mobile's daily operation and\nmaintenance for 117 days, and it improves the efficiency of locating alarms,\nfixing problems, and finding related reports, with an average efficiency\nimprovement of over 18.6%. In addition, we release Self-Evolution framework\ncode in https://github.com/Zero-Pointer/Self-Evolution.",
      "tldr_zh": "本文提出 Self-Evolution 框架，利用轻量级开源 LLMs 通过多次迭代微调，解决大语言模型在领域特定 Q&A 中的知识不足问题，同时兼顾隐私保护和资源限制。框架采用过滤和强化高价值知识的策略，以提高微调效率。在实验中，使用中国移动的4000份文档对 Qwen1.5-7B-Chat 进行微调，性能比原模型提升174%，并超过 Qwen1.5-72B-Chat 22%。此外，该框架已在实际运维中部署117天，平均效率提升18.6%，并开源代码（https://github.com/Zero-Pointer/Self-Evolution）。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12247v2",
      "published_date": "2024-08-22 09:36:15 UTC",
      "updated_date": "2024-08-23 01:25:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:57:54.957104"
    },
    {
      "arxiv_id": "2408.12237v1",
      "title": "Weight Scope Alignment: A Frustratingly Easy Method for Model Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Yichu Xu",
        "Xin-Chun Li",
        "Le Gan",
        "De-Chuan Zhan"
      ],
      "abstract": "Merging models becomes a fundamental procedure in some applications that\nconsider model efficiency and robustness. The training randomness or Non-I.I.D.\ndata poses a huge challenge for averaging-based model fusion. Previous research\nefforts focus on element-wise regularization or neural permutations to enhance\nmodel averaging while overlooking weight scope variations among models, which\ncan significantly affect merging effectiveness. In this paper, we reveal\nvariations in weight scope under different training conditions, shedding light\non its influence on model merging. Fortunately, the parameters in each layer\nbasically follow the Gaussian distribution, which inspires a novel and simple\nregularization approach named Weight Scope Alignment (WSA). It contains two key\ncomponents: 1) leveraging a target weight scope to guide the model training\nprocess for ensuring weight scope matching in the subsequent model merging. 2)\nfusing the weight scope of two or more models into a unified one for\nmulti-stage model fusion. We extend the WSA regularization to two different\nscenarios, including Mode Connectivity and Federated Learning. Abundant\nexperimental studies validate the effectiveness of our approach.",
      "tldr_zh": "本研究揭示了模型合并中权重范围（weight scope）差异对效果的影响，这是现有方法（如元素级正则化和神经排列）常忽略的关键问题，尤其在训练随机性和Non-I.I.D.数据环境下。作者提出了一种简单有效的Weight Scope Alignment (WSA)方法，利用参数的Gaussian distribution特性，通过目标权重范围指导训练和多模型融合，确保权重范围匹配。WSA扩展应用于Mode Connectivity和Federated Learning场景，大量实验验证了其显著提升模型合并的效率和鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12237v1",
      "published_date": "2024-08-22 09:13:27 UTC",
      "updated_date": "2024-08-22 09:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:58:17.608384"
    },
    {
      "arxiv_id": "2408.12236v1",
      "title": "MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for Dynamic Medical Image Generation in Virtual Simulated Patient",
      "title_zh": "翻译失败",
      "authors": [
        "Yanzeng Li",
        "Cheng Zeng",
        "Jinchao Zhang",
        "Jie Zhou",
        "Lei Zou"
      ],
      "abstract": "Medical education relies heavily on Simulated Patients (SPs) to provide a\nsafe environment for students to practice clinical skills, including medical\nimage analysis. However, the high cost of recruiting qualified SPs and the lack\nof diverse medical imaging datasets have presented significant challenges. To\naddress these issues, this paper introduces MedDiT, a novel\nknowledge-controlled conversational framework that can dynamically generate\nplausible medical images aligned with simulated patient symptoms, enabling\ndiverse diagnostic skill training. Specifically, MedDiT integrates various\npatient Knowledge Graphs (KGs), which describe the attributes and symptoms of\npatients, to dynamically prompt Large Language Models' (LLMs) behavior and\ncontrol the patient characteristics, mitigating hallucination during medical\nconversation. Additionally, a well-tuned Diffusion Transformer (DiT) model is\nincorporated to generate medical images according to the specified patient\nattributes in the KG. In this paper, we present the capabilities of MedDiT\nthrough a practical demonstration, showcasing its ability to act in diverse\nsimulated patient cases and generate the corresponding medical images. This can\nprovide an abundant and interactive learning experience for students, advancing\nmedical education by offering an immersive simulation platform for future\nhealthcare professionals. The work sheds light on the feasibility of\nincorporating advanced technologies like LLM, KG, and DiT in education\napplications, highlighting their potential to address the challenges faced in\nsimulated patient-based medical education.",
      "tldr_zh": "本论文提出MedDiT框架，这是一个知识控制的对话系统，用于在虚拟模拟患者环境中动态生成与患者症状相符的医疗图像，从而解决医疗教育中模拟患者成本高和图像数据集多样性不足的问题。MedDiT整合患者知识图谱(KGs)来提示和控制大语言模型(LLMs)的行为，减少对话中的幻觉，并结合微调的Diffusion Transformer(DiT)模型根据患者属性生成高质量医疗图像。通过实际演示，该框架展示了在多种模拟患者案例中的有效性，提供丰富的互动学习体验。该工作突显了LLMs、KGs和DiT在医疗教育中的潜力，推动了沉浸式模拟平台的创新发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12236v1",
      "published_date": "2024-08-22 09:10:29 UTC",
      "updated_date": "2024-08-22 09:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:58:22.792893"
    },
    {
      "arxiv_id": "2408.12226v1",
      "title": "EvalYaks: Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts",
      "title_zh": "EvalYaks：指令微调数据集和 LoRA 微调模型，用于 CEFR B2 口语评估转录",
      "authors": [
        "Nicy Scaria",
        "Silvester John Joseph Kennedy",
        "Thomas Latinovich",
        "Deepak Subramani"
      ],
      "abstract": "Relying on human experts to evaluate CEFR speaking assessments in an\ne-learning environment creates scalability challenges, as it limits how quickly\nand widely assessments can be conducted. We aim to automate the evaluation of\nCEFR B2 English speaking assessments in e-learning environments from\nconversation transcripts. First, we evaluate the capability of leading open\nsource and commercial Large Language Models (LLMs) to score a candidate's\nperformance across various criteria in the CEFR B2 speaking exam in both global\nand India-specific contexts. Next, we create a new expert-validated,\nCEFR-aligned synthetic conversational dataset with transcripts that are rated\nat different assessment scores. In addition, new instruction-tuned datasets are\ndeveloped from the English Vocabulary Profile (up to CEFR B2 level) and the\nCEFR-SP WikiAuto datasets. Finally, using these new datasets, we perform\nparameter efficient instruction tuning of Mistral Instruct 7B v0.2 to develop a\nfamily of models called EvalYaks. Four models in this family are for assessing\nthe four sections of the CEFR B2 speaking exam, one for identifying the CEFR\nlevel of vocabulary and generating level-specific vocabulary, and another for\ndetecting the CEFR level of text and generating level-specific text. EvalYaks\nachieved an average acceptable accuracy of 96%, a degree of variation of 0.35\nlevels, and performed 3 times better than the next best model. This\ndemonstrates that a 7B parameter LLM instruction tuned with high-quality\nCEFR-aligned assessment data can effectively evaluate and score CEFR B2 English\nspeaking assessments, offering a promising solution for scalable, automated\nlanguage proficiency evaluation.",
      "tldr_zh": "该研究针对 CEFR B2 英语口语评估在 e-learning 环境中的可扩展性挑战，提出自动化评分系统 EvalYaks，通过评估领先的 LLMs（Large Language Models）并创建新的专家验证的合成对话数据集来实现。研究开发了基于 English Vocabulary Profile 和 CEFR-SP WikiAuto 的指令微调数据集，并使用 LoRA 微调技术对 Mistral Instruct 7B v0.2 进行参数高效优化，生成 EvalYaks 模型家族，用于评估口语考试四个部分、识别词汇级别及生成级别特定文本。结果显示，EvalYaks 模型实现了 96% 的平均可接受准确率和 0.35 级别的变异度，比最佳基线模型高出 3 倍，证明了高质量 CEFR 对齐数据在自动化语言能力评估中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12226v1",
      "published_date": "2024-08-22 08:57:31 UTC",
      "updated_date": "2024-08-22 08:57:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:58:44.842119"
    },
    {
      "arxiv_id": "2408.12214v2",
      "title": "Bridging Large Language Models and Optimization: A Unified Framework for Text-attributed Combinatorial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Xia Jiang",
        "Yaoxin Wu",
        "Yuan Wang",
        "Yingqian Zhang"
      ],
      "abstract": "To advance capabilities of large language models (LLMs) in solving\ncombinatorial optimization problems (COPs), this paper presents the\nLanguage-based Neural COP Solver (LNCS), a novel framework that is unified for\nthe end-to-end resolution of diverse text-attributed COPs. LNCS leverages LLMs\nto encode problem instances into a unified semantic space, and integrates their\nembeddings with a Transformer-based solution generator to produce high-quality\nsolutions. By training the solution generator with conflict-free multi-task\nreinforcement learning, LNCS effectively enhances LLM performance in tackling\nCOPs of varying types and sizes, achieving state-of-the-art results across\ndiverse problems. Extensive experiments validate the effectiveness and\ngeneralizability of the LNCS, highlighting its potential as a unified and\npractical framework for real-world COP applications.",
      "tldr_zh": "本研究提出了一种统一的框架Language-based Neural COP Solver (LNCS)，旨在将Large Language Models (LLMs)与组合优化问题(COPs)整合，处理各种文本属性的COPs。LNCS使用LLMs将问题实例编码到统一语义空间，并结合Transformer-based解决方案生成器来产生高质量解决方案。通过无冲突的多任务强化学习训练，该框架显著提升了LLMs在不同类型和规模COPs上的性能，并在多项实验中实现了state-of-the-art结果。实验验证了LNCS的有效性和泛化性，为实际COPs应用提供了一个实用框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12214v2",
      "published_date": "2024-08-22 08:42:44 UTC",
      "updated_date": "2024-12-15 09:20:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:58:42.692957"
    },
    {
      "arxiv_id": "2408.12212v2",
      "title": "Relational decomposition for program synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Céline Hocquette",
        "Andrew Cropper"
      ],
      "abstract": "We introduce a relational approach to program synthesis. The key idea is to\ndecompose synthesis tasks into simpler relational synthesis subtasks.\nSpecifically, our representation decomposes a training input-output example\ninto sets of input and output facts respectively. We then learn relations\nbetween the input and output facts. We demonstrate our approach using an\noff-the-shelf inductive logic programming (ILP) system on four challenging\nsynthesis datasets. Our results show that (i) our representation can outperform\na standard one, and (ii) an off-the-shelf ILP system with our representation\ncan outperform domain-specific approaches.",
      "tldr_zh": "本论文提出了一种关系分解方法，用于程序合成，通过将训练的输入-输出示例分解成输入事实集和输出事实集，并学习它们之间的关系。该方法利用现成的归纳逻辑编程 (ILP) 系统在四个具有挑战性的合成数据集上进行测试。结果表明，这种关系表示方式优于标准方法，且结合 ILP 系统的表现超过了领域特定方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12212v2",
      "published_date": "2024-08-22 08:41:52 UTC",
      "updated_date": "2025-02-06 14:58:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:58:54.723914"
    },
    {
      "arxiv_id": "2408.12198v1",
      "title": "Two-level deep domain decomposition method",
      "title_zh": "两级深度域分解方法",
      "authors": [
        "Victorita Dolean",
        "Serge Gratton",
        "Alexander Heinlein",
        "Valentin Mercier"
      ],
      "abstract": "This study presents a two-level Deep Domain Decomposition Method (Deep-DDM)\naugmented with a coarse-level network for solving boundary value problems using\nphysics-informed neural networks (PINNs). The addition of the coarse level\nnetwork improves scalability and convergence rates compared to the single level\nmethod. Tested on a Poisson equation with Dirichlet boundary conditions, the\ntwo-level deep DDM demonstrates superior performance, maintaining efficient\nconvergence regardless of the number of subdomains. This advance provides a\nmore scalable and effective approach to solving complex partial differential\nequations with machine learning.",
      "tldr_zh": "本研究提出了一种两级深度域分解方法（Two-level Deep-DDM），它在物理信息神经网络（PINNs）的基础上添加了粗级网络，以提升边界值问题的求解可扩展性和收敛率。该方法通过域分解技术处理复杂偏微分方程，无论子域数量如何，都能保持高效收敛，在 Dirichlet 边界条件的 Poisson 方程测试中表现出优越性能。总体而言，这为使用机器学习解决复杂偏微分方程提供了更具可扩展性和有效性的新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint proceeding format",
      "pdf_url": "http://arxiv.org/pdf/2408.12198v1",
      "published_date": "2024-08-22 08:20:39 UTC",
      "updated_date": "2024-08-22 08:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:59:17.647249"
    },
    {
      "arxiv_id": "2408.12188v1",
      "title": "Reasoning Factual Knowledge in Structured Data with Large Language Models",
      "title_zh": "使用大语言模型推理结构化数据中的事实知识",
      "authors": [
        "Sirui Huang",
        "Yanggan Gu",
        "Xuming Hu",
        "Zhonghao Li",
        "Qing Li",
        "Guandong Xu"
      ],
      "abstract": "Large language models (LLMs) have made remarkable progress in various natural\nlanguage processing tasks as a benefit of their capability to comprehend and\nreason with factual knowledge. However, a significant amount of factual\nknowledge is stored in structured data, which possesses unique characteristics\nthat differ from the unstructured texts used for pretraining. This difference\ncan introduce imperceptible inference parameter deviations, posing challenges\nfor LLMs in effectively utilizing and reasoning with structured data to\naccurately infer factual knowledge. To this end, we propose a benchmark named\nStructFact, to evaluate the structural reasoning capabilities of LLMs in\ninferring factual knowledge. StructFact comprises 8,340 factual questions\nencompassing various tasks, domains, timelines, and regions. This benchmark\nallows us to investigate the capability of LLMs across five factual tasks\nderived from the unique characteristics of structural facts. Extensive\nexperiments on a set of LLMs with different training strategies reveal the\nlimitations of current LLMs in inferring factual knowledge from structured\ndata. We present this benchmark as a compass to navigate the strengths and\nweaknesses of LLMs in reasoning with structured data for knowledge-sensitive\ntasks, and to encourage advancements in related real-world applications. Please\nfind our code at https://github.com/EganGu/StructFact.",
      "tldr_zh": "本研究探讨了大语言模型(LLMs)在处理结构化数据时推理事实知识的挑战，因为结构化数据与预训练的非结构化文本存在差异，导致推理偏差。该论文提出StructFact基准，用于评估LLMs的结构化推理能力，该基准包含8340个事实问题，覆盖多种任务、领域、时间线和地区，并涉及五个从结构化事实特性派生的任务。通过广泛实验，揭示了当前LLMs在结构化数据推理中的局限性，并以此基准作为指南，推动LLMs在知识敏感任务中的改进和实际应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12188v1",
      "published_date": "2024-08-22 08:05:09 UTC",
      "updated_date": "2024-08-22 08:05:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:59:20.066817"
    },
    {
      "arxiv_id": "2408.12187v1",
      "title": "A Safe and Efficient Self-evolving Algorithm for Decision-making and Control of Autonomous Driving Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Yang",
        "Liwen Wang",
        "Yanjun Huang",
        "Hong Chen"
      ],
      "abstract": "Autonomous vehicles with a self-evolving ability are expected to cope with\nunknown scenarios in the real-world environment. Take advantage of trial and\nerror mechanism, reinforcement learning is able to self evolve by learning the\noptimal policy, and it is particularly well suitable for solving\ndecision-making problems. However, reinforcement learning suffers from safety\nissues and low learning efficiency, especially in the continuous action space.\nTherefore, the motivation of this paper is to address the above problem by\nproposing a hybrid Mechanism-Experience-Learning augmented approach.\nSpecifically, to realize the efficient self-evolution, the driving tendency by\nanalogy with human driving experience is proposed to reduce the search space of\nthe autonomous driving problem, while the constrained optimization problem\nbased on a mechanistic model is designed to ensure safety during the\nself-evolving process. Experimental results show that the proposed method is\ncapable of generating safe and reasonable actions in various complex scenarios,\nimproving the performance of the autonomous driving system. Compared to\nconventional reinforcement learning, the safety and efficiency of the proposed\nalgorithm are greatly improved. The training process is collision-free, and the\ntraining time is equivalent to less than 10 minutes in the real world.",
      "tldr_zh": "该论文提出了一种安全高效的自演化算法，用于自动驾驶系统的决策和控制，旨在解决强化学习(reinforcement learning)在连续动作空间中存在的安全问题和低学习效率问题。算法采用混合机制-经验-学习方法，通过模拟人类驾驶经验的驾驶倾向(driving tendency)来缩小搜索空间，并设计基于机制模型(mechanistic model)的约束优化(constrained optimization)问题，确保自演化过程的安全性。实验结果表明，该方法在各种复杂场景中生成安全合理的动作，显著提升了自动驾驶系统的性能，与传统强化学习相比，训练过程无碰撞，且训练时间相当于现实世界的不到10分钟。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12187v1",
      "published_date": "2024-08-22 08:05:03 UTC",
      "updated_date": "2024-08-22 08:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:59:31.122202"
    },
    {
      "arxiv_id": "2408.12185v1",
      "title": "Rank and Align: Towards Effective Source-free Graph Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Junyu Luo",
        "Zhiping Xiao",
        "Yifan Wang",
        "Xiao Luo",
        "Jingyang Yuan",
        "Wei Ju",
        "Langechuan Liu",
        "Ming Zhang"
      ],
      "abstract": "Graph neural networks (GNNs) have achieved impressive performance in graph\ndomain adaptation. However, extensive source graphs could be unavailable in\nreal-world scenarios due to privacy and storage concerns. To this end, we\ninvestigate an underexplored yet practical problem of source-free graph domain\nadaptation, which transfers knowledge from source models instead of source\ngraphs to a target domain. To solve this problem, we introduce a novel\nGNN-based approach called Rank and Align (RNA), which ranks graph similarities\nwith spectral seriation for robust semantics learning, and aligns inharmonic\ngraphs with harmonic graphs which close to the source domain for subgraph\nextraction. In particular, to overcome label scarcity, we employ the spectral\nseriation algorithm to infer the robust pairwise rankings, which can guide\nsemantic learning using a similarity learning objective. To depict distribution\nshifts, we utilize spectral clustering and the silhouette coefficient to detect\nharmonic graphs, which the source model can easily classify. To reduce\npotential domain discrepancy, we extract domain-invariant subgraphs from\ninharmonic graphs by an adversarial edge sampling process, which guides the\ninvariant learning of GNNs. Extensive experiments on several benchmark datasets\ndemonstrate the effectiveness of our proposed RNA.",
      "tldr_zh": "这篇论文探讨了源-free 图域适配问题，提出了一种名为 Rank and Align (RNA) 的 GNN-based 方法，以从源模型而不是源图中转移知识。RNA 通过谱序列算法（spectral seriation）推断鲁棒的成对排名，指导语义学习，并利用谱聚类和轮廓系数检测和谐图，从不和谐图中通过对抗性边采样提取域不变子图，从而减少分布偏移。实验结果表明，该方法在多个基准数据集上表现出色，有效提升了源-free 场景下的图域适配性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in IJCAI2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12185v1",
      "published_date": "2024-08-22 08:00:50 UTC",
      "updated_date": "2024-08-22 08:00:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:59:44.755910"
    },
    {
      "arxiv_id": "2408.12184v1",
      "title": "Randomness control and reproducibility study of random forest algorithm in R and Python",
      "title_zh": "翻译失败",
      "authors": [
        "Louisa Camadini",
        "Yanis Bouzid",
        "Maeva Merlet",
        "Léopold Carron"
      ],
      "abstract": "When it comes to the safety of cosmetic products, compliance with regulatory\nstandards is crucialto guarantee consumer protection against the risks of skin\nirritation. Toxicologists must thereforebe fully conversant with all risks.\nThis applies not only to their day-to-day work, but also to allthe algorithms\nthey integrate into their routines. Recognizing this, ensuring the\nreproducibility ofalgorithms becomes one of the most crucial aspects to\naddress.However, how can we prove the robustness of an algorithm such as the\nrandom forest, that reliesheavily on randomness? In this report, we will\ndiscuss the strategy of integrating random forest intoocular tolerance\nassessment for toxicologists.We will compare four packages: randomForest and\nRanger (R packages), adapted in Python via theSKRanger package, and the widely\nused Scikit-Learn with the RandomForestClassifier() function.Our goal is to\ninvestigate the parameters and sources of randomness affecting the outcomes\nofRandom Forest algorithms.By setting comparable parameters and using the same\nPseudo-Random Number Generator (PRNG),we expect to reproduce results\nconsistently across the various available implementations of therandom forest\nalgorithm. Nevertheless, this exploration will unveil hidden layers of\nrandomness andguide our understanding of the critical parameters necessary to\nensure reproducibility across all fourimplementations of the random forest\nalgorithm.",
      "tldr_zh": "本研究探讨了随机森林算法在 R 和 Python 中的随机性控制和再现性问题，特别是在化妆品安全领域用于眼部耐受性评估的毒理学应用中。论文比较了四个实现版本，包括 R 中的 randomForest 和 Ranger，以及通过 SKRanger 移植到 Python 的版本和 Scikit-Learn 的 RandomForestClassifier，通过设置相同参数和 Pseudo-Random Number Generator (PRNG) 来调查影响结果的随机性来源。结果显示，这种方法有助于揭示隐藏的随机性层，并识别关键参数，以确保随机森林算法在不同实现中的一致再现性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12184v1",
      "published_date": "2024-08-22 07:59:49 UTC",
      "updated_date": "2024-08-22 07:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:59:55.599000"
    },
    {
      "arxiv_id": "2408.12159v1",
      "title": "Search-Based LLMs for Code Optimization",
      "title_zh": "基于搜索的LLMs用于代码优化",
      "authors": [
        "Shuzheng Gao",
        "Cuiyun Gao",
        "Wenchao Gu",
        "Michael Lyu"
      ],
      "abstract": "The code written by developers usually suffers from efficiency problems and\ncontain various performance bugs. These inefficiencies necessitate the research\nof automated refactoring methods for code optimization. Early research in code\noptimization employs rule-based methods and focuses on specific inefficiency\nissues, which are labor-intensive and suffer from the low coverage issue.\nRecent work regards the task as a sequence generation problem, and resorts to\ndeep learning (DL) techniques such as large language models (LLMs). These\nmethods typically prompt LLMs to directly generate optimized code. Although\nthese methods show state-of-the-art performance, such one-step generation\nparadigm is hard to achieve an optimal solution. First, complex optimization\nmethods such as combinatorial ones are hard to be captured by LLMs. Second, the\none-step generation paradigm poses challenge in precisely infusing the\nknowledge required for effective code optimization within LLMs, resulting in\nunder-optimized code.To address these problems, we propose to model this task\nfrom the search perspective, and propose a search-based LLMs framework named\nSBLLM that enables iterative refinement and discovery of improved optimization\nmethods. SBLLM synergistically integrate LLMs with evolutionary search and\nconsists of three key components: 1) an execution-based representative sample\nselection part that evaluates the fitness of each existing optimized code and\nprioritizes promising ones to pilot the generation of improved code; 2) an\nadaptive optimization pattern retrieval part that infuses targeted optimization\npatterns into the model for guiding LLMs towards rectifying and progressively\nenhancing their optimization methods; and 3) a genetic operator-inspired\nchain-of-thought prompting part that aids LLMs in combining different\noptimization methods and generating improved optimization methods.",
      "tldr_zh": "本研究针对开发者代码中的效率问题和性能bug，提出了一种基于搜索视角的框架Search-Based LLMs (SBLLM)，将大型语言模型(LLMs)与进化搜索相结合，实现代码优化的迭代改进。SBLLM 包括三个关键组件：执行-based 代表样本选择用于评估和优先优化代码、自适应优化模式检索注入针对性知识，以及遗传操作符启发的链式思维提示帮助LLMs 结合多种优化方法生成改进方案。该框架解决了现有直接生成方法的局限性，如难以捕捉复杂优化和精确知识注入，从而提升代码优化的整体效果。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by 2025 IEEE/ACM 47th International Conference on Software\n  Engineering (ICSE'25)",
      "pdf_url": "http://arxiv.org/pdf/2408.12159v1",
      "published_date": "2024-08-22 06:59:46 UTC",
      "updated_date": "2024-08-22 06:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:00:09.304222"
    },
    {
      "arxiv_id": "2408.12157v1",
      "title": "Implicit Sentiment Analysis Based on Chain of Thought Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihua Duan",
        "Jialin Wang"
      ],
      "abstract": "Implicit Sentiment Analysis (ISA) is a crucial research area in natural\nlanguage processing. Inspired by the idea of large language model Chain of\nThought (CoT), this paper introduces a Sentiment Analysis of Thinking (SAoT)\nframework. The framework first analyzes the implicit aspects and opinions in\nthe text using common sense and thinking chain capabilities. Then, it reflects\non the process of implicit sentiment analysis and finally deduces the polarity\nof sentiment. The model is evaluated on the SemEval 2014 dataset, consisting of\n1120 restaurant reviews and 638 laptop reviews. The experimental results\ndemonstrate that the utilization of the ERNIE-Bot-4+SAoT model yields a notable\nperformance improvement. Specifically, on the restaurant dataset, the F1 score\nreaches 75.27, accompanied by an ISA score of 66.29. Similarly, on the computer\ndataset, the F1 score achieves 76.50, while the ISA score amounts to 73.46.\nComparatively, the ERNIE-Bot-4+SAoT model surpasses the BERTAsp + SCAPt\nbaseline by an average margin of 47.99%.",
      "tldr_zh": "这篇论文提出了一种基于Chain of Thought (CoT)启发的框架——Sentiment Analysis of Thinking (SAoT)，用于处理Implicit Sentiment Analysis (ISA)，通过利用常见感和思考链来分析文本中的隐式方面和意见，并进行反思以推断情感极性。SAoT框架首先识别隐式元素，然后逐步推理，最终得出情感 polarity。实验在SemEval 2014数据集上进行，使用ERNIE-Bot-4+SAoT模型，在餐厅评论中获得F1 score 75.27和ISA score 66.29，在笔记本评论中分别达到76.50和73.46，与BERTAsp + SCAPt基线相比平均提高了47.99%。这项工作展示了CoT在ISA中的有效性，提升了情感分析的准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12157v1",
      "published_date": "2024-08-22 06:55:29 UTC",
      "updated_date": "2024-08-22 06:55:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:00:20.325053"
    },
    {
      "arxiv_id": "2408.12151v2",
      "title": "A Tighter Complexity Analysis of SparseGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "In this work, we improved the analysis of the running time of SparseGPT\n[Frantar, Alistarh ICML 2023] from $O(d^{3})$ to $O(d^{\\omega} + d^{2+a+o(1)} +\nd^{1+\\omega(1,1,a)-a})$ for any $a \\in [0, 1]$, where $\\omega$ is the exponent\nof matrix multiplication. In particular, for the current $\\omega \\approx 2.371$\n[Alman, Duan, Williams, Xu, Xu, Zhou 2024], our running time boils down to\n$O(d^{2.53})$. This running time is due to the analysis of the lazy update\nbehavior in iterative maintenance problems such as [Deng, Song, Weinstein 2022;\nBrand, Song, Zhou ICML 2024].",
      "tldr_zh": "该论文对 SparseGPT 的复杂度分析进行了改进，将其运行时间从 O(d^3) 优化到 O(d^ω + d^{2+a+o(1)} + d^{1+ω(1,1,a)-a})，其中 a ∈ [0,1]，并以矩阵乘法指数 ω 为基础。针对当前的 ω ≈ 2.371，这一优化使运行时间简化为 O(d^{2.53})，显著提升了算法效率。改进基于对迭代维护问题中 lazy update behavior 的深入分析，并参考了相关工作如 [Deng, Song, Weinstein 2022; Brand, Song, Zhou ICML 2024]。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12151v2",
      "published_date": "2024-08-22 06:40:32 UTC",
      "updated_date": "2024-10-18 03:36:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:00:34.482831"
    },
    {
      "arxiv_id": "2408.12150v1",
      "title": "DeepHQ: Learned Hierarchical Quantizer for Progressive Deep Image Coding",
      "title_zh": "翻译失败",
      "authors": [
        "Jooyoung Lee",
        "Se Yoon Jeong",
        "Munchurl Kim"
      ],
      "abstract": "Unlike fixed- or variable-rate image coding, progressive image coding (PIC)\naims to compress various qualities of images into a single bitstream,\nincreasing the versatility of bitstream utilization and providing high\ncompression efficiency compared to simulcast compression. Research on neural\nnetwork (NN)-based PIC is in its early stages, mainly focusing on applying\nvarying quantization step sizes to the transformed latent representations in a\nhierarchical manner. These approaches are designed to compress only the\nprogressively added information as the quality improves, considering that a\nwider quantization interval for lower-quality compression includes multiple\nnarrower sub-intervals for higher-quality compression. However, the existing\nmethods are based on handcrafted quantization hierarchies, resulting in\nsub-optimal compression efficiency. In this paper, we propose an NN-based\nprogressive coding method that firstly utilizes learned quantization step sizes\nvia learning for each quantization layer. We also incorporate selective\ncompression with which only the essential representation components are\ncompressed for each quantization layer. We demonstrate that our method achieves\nsignificantly higher coding efficiency than the existing approaches with\ndecreased decoding time and reduced model size.",
      "tldr_zh": "本文提出 DeepHQ，一种基于学习的层次量化器，用于 Progressive Image Coding (PIC)，旨在通过优化量化步长来提升图像压缩效率。不同于现有依赖手工设计的量化层次方法，DeepHQ 采用学习得到的量化步长以及选择性压缩，仅针对每个量化层处理必要的表示组件。实验结果表明，该方法显著提高了编码效率，同时减少了解码时间和模型大小。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12150v1",
      "published_date": "2024-08-22 06:32:53 UTC",
      "updated_date": "2024-08-22 06:32:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:00:45.207126"
    },
    {
      "arxiv_id": "2408.12148v1",
      "title": "Multi-tool Integration Application for Math Reasoning Using Large Language Model",
      "title_zh": "使用大型语言模型的多工具集成数学推理应用",
      "authors": [
        "Zhihua Duan",
        "Jialin Wang"
      ],
      "abstract": "Mathematical reasoning is an important research direction in the field of\nartificial intelligence. This article proposes a novel multi tool application\nframework for mathematical reasoning, aiming to achieve more comprehensive and\naccurate mathematical reasoning by utilizing the collaborative effect of large\nlanguage models (LLMs) and multiple external tools. Firstly, use a Math Tool to\nperform basic mathematical calculations during the inference process through\ninteraction with LLM. Secondly, Code Tool can generate code fragments that\ncomply with syntax rules and execute them, providing support for complex\nmathematical problems. Then, through the iterative reasoning of the CoT Tool,\nthe logical coherence and accuracy of mathematical reasoning are enhanced.\nUltimately, by using self consistency tools to select the final answer based on\ndifferent parameters, the consistency and reliability of reasoning are\nimproved. Through the synergistic effect of these tools, the framework has\nachieved significant performance improvement in mathematical reasoning tasks.\nWe conducted experiments on the NumGLUE Task 4 test set, which includes 220\nmathematical reasoning fill in the blank questions. The experimental results\nshowed that, based on Math Tool, Code Tool, and CoT Tool, in Task 4 task,our\nmethod achieved an accuracy of 89.09,compared with the GPT3+FewShot baseline,\nFew Shot+ERNIE-4.0+self consistency improved by 49.09%, and compared with\nfine-tuning the Fine tuning baseline, Few Shot+ERNIE-4.0+self consistency\nimproved by 52.29%",
      "tldr_zh": "该论文提出了一种多工具集成框架，用于利用 Large Language Model (LLMs) 进行数学推理，通过 Math Tool、Code Tool、CoT Tool 和自一致性工具的协同作用，提升推理的全面性和准确性。框架中，Math Tool 通过与 LLM 交互执行基本计算，Code Tool 生成并运行符合语法规则的代码片段处理复杂问题，CoT Tool 进行迭代推理以增强逻辑连贯性，而自一致性工具则基于不同参数选择最终答案以提高可靠性。在 NumGLUE Task 4 测试集（包括220个数学推理填空题）上，实验结果显示该方法准确率达到89.09%，较GPT3+FewShot基线提升49.09%，较Fine-tuning基线提升52.29%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12148v1",
      "published_date": "2024-08-22 06:27:10 UTC",
      "updated_date": "2024-08-22 06:27:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:00:57.274905"
    },
    {
      "arxiv_id": "2408.12142v2",
      "title": "MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents",
      "title_zh": "MDD-5k：一种通过神经符号 LLM ",
      "authors": [
        "Congchi Yin",
        "Feng Li",
        "Shu Zhang",
        "Zike Wang",
        "Jun Shao",
        "Piji Li",
        "Jianhua Chen",
        "Xun Jiang"
      ],
      "abstract": "The clinical diagnosis of most mental disorders primarily relies on the\nconversations between psychiatrist and patient. The creation of such diagnostic\nconversation datasets is promising to boost the AI mental healthcare community.\nHowever, directly collecting the conversations in real diagnosis scenarios is\nnear impossible due to stringent privacy and ethical considerations. To address\nthis issue, we seek to synthesize diagnostic conversation by exploiting\nanonymized patient cases that are easier to access. Specifically, we design a\nneuro-symbolic multi-agent framework for synthesizing the diagnostic\nconversation of mental disorders with large language models. It takes patient\ncase as input and is capable of generating multiple diverse conversations with\none single patient case. The framework basically involves the interaction\nbetween a doctor agent and a patient agent, and generates conversations under\nsymbolic control via a dynamic diagnosis tree. By applying the proposed\nframework, we develop the largest Chinese mental disorders diagnosis dataset\nMDD-5k. This dataset is built upon 1000 real, anonymized patient cases by\ncooperating with Shanghai Mental Health Center and comprises 5000 high-quality\nlong conversations with diagnosis results and treatment opinions as labels. To\nthe best of our knowledge, it's also the first labeled dataset for Chinese\nmental disorders diagnosis. Human evaluation demonstrates the proposed MDD-5k\ndataset successfully simulates human-like diagnostic process of mental\ndisorders.",
      "tldr_zh": "该研究提出了一种神经符号多智能体框架，利用大型语言模型（LLM）代理从匿名患者案例合成精神障碍诊断对话，以解决真实数据收集的隐私和伦理挑战。该框架通过医生代理和患者代理的交互，以及动态诊断树进行符号控制，生成多样化的诊断对话，从而构建了MDD-5k数据集——一个基于1000个真实匿名案例的5000条高质量中文对话数据集，包括诊断结果和治疗意见标签。作为首个带标签的中文精神障碍诊断数据集，人类评估显示它成功模拟了真实的诊断过程。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by the 39th Annual AAAI Conference on Artificial\n  Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2408.12142v2",
      "published_date": "2024-08-22 05:59:47 UTC",
      "updated_date": "2024-12-26 06:39:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:01:08.335424"
    },
    {
      "arxiv_id": "2408.12139v2",
      "title": "DRExplainer: Quantifiable Interpretability in Drug Response Prediction with Directed Graph Convolutional Network",
      "title_zh": "DRExplainer：基于有向图卷积网络的药物反应预测可量化可解释性",
      "authors": [
        "Haoyuan Shi",
        "Tao Xu",
        "Xiaodi Li",
        "Qian Gao",
        "Zhiwei Xiong",
        "Junfeng Xia",
        "Zhenyu Yue"
      ],
      "abstract": "Predicting the response of a cancer cell line to a therapeutic drug is\npivotal for personalized medicine. Despite numerous deep learning methods that\nhave been developed for drug response prediction, integrating diverse\ninformation about biological entities and predicting the directional response\nremain major challenges. Here, we propose a novel interpretable predictive\nmodel, DRExplainer, which leverages a directed graph convolutional network to\nenhance the prediction in a directed bipartite network framework. DRExplainer\nconstructs a directed bipartite network integrating multi-omics profiles of\ncell lines, the chemical structure of drugs and known drug response to achieve\ndirected prediction. Then, DRExplainer identifies the most relevant subgraph to\neach prediction in this directed bipartite network by learning a mask,\nfacilitating critical medical decision-making. Additionally, we introduce a\nquantifiable method for model interpretability that leverages a ground truth\nbenchmark dataset curated from biological features. In computational\nexperiments, DRExplainer outperforms state-of-the-art predictive methods and\nanother graph-based explanation method under the same experimental setting.\nFinally, the case studies further validate the interpretability and the\neffectiveness of DRExplainer in predictive novel drug response. Our code is\navailable at: https://github.com/vshy-dream/DRExplainer.",
      "tldr_zh": "该论文提出 DRExplainer，一种基于 directed graph convolutional network 的可解释预测模型，用于预测癌症细胞系对治疗药物的响应，支持个性化医学。DRExplainer 通过构建一个 directed bipartite network，整合细胞系的多组学数据、药物化学结构和已知响应，并通过学习 mask 来识别每个预测的最相关子图，从而提升模型的可量化解释性和医疗决策支持。实验结果表明，该模型在计算实验中优于现有预测方法，并在案例研究中验证了其在预测新型药物响应方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12139v2",
      "published_date": "2024-08-22 05:45:48 UTC",
      "updated_date": "2025-03-28 02:50:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:01:20.414173"
    },
    {
      "arxiv_id": "2408.12133v2",
      "title": "Self-Supervised Representation Learning for Geospatial Objects: A Survey",
      "title_zh": "自监督表示学习在地理空间对象中的应用：一个综述",
      "authors": [
        "Yile Chen",
        "Weiming Huang",
        "Kaiqi Zhao",
        "Yue Jiang",
        "Gao Cong"
      ],
      "abstract": "The proliferation of various data sources in urban and territorial\nenvironments has significantly facilitated the development of geospatial\nartificial intelligence (GeoAI) across a wide range of geospatial applications.\nHowever, geospatial data, which is inherently linked to geospatial objects,\noften exhibits data heterogeneity that necessitates specialized fusion and\nrepresentation strategies while simultaneously being inherently sparse in\nlabels for downstream tasks. Consequently, there is a growing demand for\ntechniques that can effectively leverage geospatial data without heavy reliance\non task-specific labels and model designs. This need aligns with the principles\nof self-supervised learning (SSL), which has garnered increasing attention for\nits ability to learn effective and generalizable representations directly from\ndata without extensive labeled supervision. This paper presents a comprehensive\nand up-to-date survey of SSL techniques specifically applied to or developed\nfor geospatial objects in three primary vector geometric types: Point,\nPolyline, and Polygon. We systematically categorize various SSL techniques into\npredictive and contrastive methods, and analyze their adaptation to different\ndata types for representation learning across various downstream tasks.\nFurthermore, we examine the emerging trends in SSL for geospatial objects,\nparticularly the gradual advancements towards geospatial foundation models.\nFinally, we discuss key challenges in current research and outline promising\ndirections for future investigation. By offering a structured analysis of\nexisting studies, this paper aims to inspire continued progress in integrating\nSSL with geospatial objects, and the development of geospatial foundation\nmodels in a longer term.",
      "tldr_zh": "这篇论文对Self-Supervised Representation Learning (SSL) 在地理空间对象上的应用进行了全面调查，旨在解决地理空间数据（geospatial data）的异质性和标签稀缺问题。论文将SSL技术分为预测和对比方法，并分析其在Point、Polyline和Polygon三种主要几何类型上的适应性，以支持各种下游任务的表示学习。同时，该研究探讨了SSL在地理空间对象中的新兴趋势，如向geospatial foundation models的进展，并指出了当前挑战和未来研究方向，例如整合SSL以构建更通用的地理空间模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12133v2",
      "published_date": "2024-08-22 05:28:22 UTC",
      "updated_date": "2025-04-25 06:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:01:32.774800"
    },
    {
      "arxiv_id": "2408.12130v3",
      "title": "S-EPOA: Overcoming the Indistinguishability of Segments with Skill-Driven Preference-Based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ni Mu",
        "Yao Luan",
        "Yiqin Yang",
        "Bo Xu",
        "Qing-shan Jia"
      ],
      "abstract": "Preference-based reinforcement learning (PbRL) stands out by utilizing human\npreferences as a direct reward signal, eliminating the need for intricate\nreward engineering. However, despite its potential, traditional PbRL methods\nare often constrained by the indistinguishability of segments, which impedes\nthe learning process. In this paper, we introduce Skill-Enhanced Preference\nOptimization Algorithm (S-EPOA), which addresses the segment\nindistinguishability issue by integrating skill mechanisms into the preference\nlearning framework. Specifically, we first conduct the unsupervised pretraining\nto learn useful skills. Then, we propose a novel query selection mechanism to\nbalance the information gain and distinguishability over the learned skill\nspace. Experimental results on a range of tasks, including robotic manipulation\nand locomotion, demonstrate that S-EPOA significantly outperforms conventional\nPbRL methods in terms of both robustness and learning efficiency. The results\nhighlight the effectiveness of skill-driven learning in overcoming the\nchallenges posed by segment indistinguishability.",
      "tldr_zh": "该论文提出 S-EPOA（Skill-Enhanced Preference Optimization Algorithm），一种技能驱动的 Preference-Based Reinforcement Learning (PbRL) 方法，用于解决传统 PbRL 中段落不可区分性（indistinguishability of segments）的问题，从而提升学习过程的效率。S-EPOA 首先通过无监督预训练学习有用的技能，然后引入一个新型查询选择机制，在技能空间中平衡信息增益和可区分性。实验结果显示，在机器人操作和运动任务上，S-EPOA 显著优于传统 PbRL 方法，提高了鲁棒性和学习效率，突出了技能驱动学习在克服该挑战方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.12130v3",
      "published_date": "2024-08-22 04:54:25 UTC",
      "updated_date": "2025-05-13 14:30:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:01:44.875795"
    },
    {
      "arxiv_id": "2408.12129v1",
      "title": "Deep Analysis of Time Series Data for Smart Grid Startup Strategies: A Transformer-LSTM-PSO Model Approach",
      "title_zh": "智能电网启动策略的时间序列数据深度分析：一种 Transformer-LSTM-PSO 模型方法",
      "authors": [
        "Zecheng Zhang"
      ],
      "abstract": "Grid startup, an integral component of the power system, holds strategic\nimportance for ensuring the reliability and efficiency of the electrical grid.\nHowever, current methodologies for in-depth analysis and precise prediction of\ngrid startup scenarios are inadequate. To address these challenges, we propose\na novel method based on the Transformer-LSTM-PSO model. This model uniquely\ncombines the Transformer's self-attention mechanism, LSTM's temporal modeling\ncapabilities, and the parameter tuning features of the particle swarm\noptimization algorithm. It is designed to more effectively capture the complex\ntemporal relationships in grid startup schemes. Our experiments demonstrate\nsignificant improvements, with our model achieving lower RMSE and MAE values\nacross multiple datasets compared to existing benchmarks, particularly in the\nNYISO Electric Market dataset where the RMSE was reduced by approximately 15%\nand the MAE by 20% compared to conventional models. Our main contribution is\nthe development of a Transformer-LSTM-PSO model that significantly enhances the\naccuracy and efficiency of smart grid startup predictions. The application of\nthe Transformer-LSTM-PSO model represents a significant advancement in smart\ngrid predictive analytics, concurrently fostering the development of more\nreliable and intelligent grid management systems.",
      "tldr_zh": "该研究针对电网启动策略的深度分析问题，提出了一种基于 Transformer-LSTM-PSO 模型的新方法，以更好地捕捉时间序列数据中的复杂时间关系。该模型结合了 Transformer's 自注意力机制、LSTM 的时间建模能力，以及 PSO（粒子群优化算法）的参数调优功能。实验结果显示，该模型在多个数据集上表现出色，尤其在 NYISO Electric Market 数据集上，RMSE 降低了约 15%，MAE 降低了 20%，相比传统模型显著提升预测准确性。主要贡献在于开发了这一高效模型，推动了智能电网管理的可靠性和智能化发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "46 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.12129v1",
      "published_date": "2024-08-22 04:52:02 UTC",
      "updated_date": "2024-08-22 04:52:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:01:56.841717"
    },
    {
      "arxiv_id": "2408.12128v1",
      "title": "Diffusion-Based Visual Art Creation: A Survey and New Perspectives",
      "title_zh": "基于扩散的视觉艺术创作：一个综述和新视角",
      "authors": [
        "Bingyuan Wang",
        "Qifeng Chen",
        "Zeyu Wang"
      ],
      "abstract": "The integration of generative AI in visual art has revolutionized not only\nhow visual content is created but also how AI interacts with and reflects the\nunderlying domain knowledge. This survey explores the emerging realm of\ndiffusion-based visual art creation, examining its development from both\nartistic and technical perspectives. We structure the survey into three phases,\ndata feature and framework identification, detailed analyses using a structured\ncoding process, and open-ended prospective outlooks. Our findings reveal how\nartistic requirements are transformed into technical challenges and highlight\nthe design and application of diffusion-based methods within visual art\ncreation. We also provide insights into future directions from technical and\nsynergistic perspectives, suggesting that the confluence of generative AI and\nart has shifted the creative paradigm and opened up new possibilities. By\nsummarizing the development and trends of this emerging interdisciplinary area,\nwe aim to shed light on the mechanisms through which AI systems emulate and\npossibly, enhance human capacities in artistic perception and creativity.",
      "tldr_zh": "这篇调查综述了基于扩散的视觉艺术创建（Diffusion-Based Visual Art Creation），探讨了生成式 AI 如何变革视觉内容创作及其与领域知识的互动。论文从艺术和技术角度，将内容结构化为三个阶段：数据特征和框架识别、详细分析（使用结构化编码过程），以及开放性展望。研究发现，艺术需求转化为技术挑战，并突出了扩散方法的设计和应用，从而提升了 AI 在视觉艺术中的表现。最终，论文提出未来技术和社会协同方向，强调 AI 系统可能模仿并增强人类的艺术感知和创造力。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12128v1",
      "published_date": "2024-08-22 04:49:50 UTC",
      "updated_date": "2024-08-22 04:49:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:02:09.879977"
    },
    {
      "arxiv_id": "2408.12125v1",
      "title": "AutoTest: Evolutionary Code Solution Selection with Test Cases",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihua Duan",
        "Jialin Wang"
      ],
      "abstract": "With the development of code generation techniques, selecting the correct\ncode solution from multiple candidate solutions has become a crucial task. This\nstudy proposes AutoTest, a novel technique that combines automated test case\ngeneration with code solution execution to optimize the selection process using\nan evolutionary genetic algorithm. Firstly, AutoTest utilizes large pre-trained\nlanguage models such as codegen-16B, code-davinci-002, and incoder-6B to\nprovide code solutions and their corresponding test cases. Then, by executing\nthe code solutions and evaluating their performance on the test cases, a\nconsensus set is formed. Fine-grained ranking is achieved through the\nselection, mutation, and crossover mechanisms based on the evolutionary genetic\nalgorithm, with the adjustment of alpha and beta parameters. Finally, the best\ncode solution is chosen. AutoTest demonstrates significant performance\nimprovements on the HumanEval benchmark test. The HumanEval dataset consists of\n164 programming problems, and AutoTest achieves approximately a 10% improvement\nover the baseline method in terms of pass@1 score.",
      "tldr_zh": "这篇论文提出了AutoTest，一种结合自动测试用例生成和代码执行的技术，使用evolutionary genetic algorithm优化从多个候选代码解决方案中选择正确的过程。AutoTest首先利用大型预训练语言模型（如codegen-16B、code-davinci-002和incoder-6B）生成代码解决方案及其测试用例，然后通过执行代码、形成共识集，并应用选育、变异和交叉机制（结合alpha和beta参数调整）进行细粒度排名。在HumanEval基准测试中，AutoTest在164个编程问题上实现了约10%的pass@1分数提升，显著优于基线方法。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12125v1",
      "published_date": "2024-08-22 04:38:41 UTC",
      "updated_date": "2024-08-22 04:38:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:02:31.331010"
    },
    {
      "arxiv_id": "2408.12121v1",
      "title": "Emotion-Agent: Unsupervised Deep Reinforcement Learning with Distribution-Prototype Reward for Continuous Emotional EEG Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihao Zhou",
        "Qile Liu",
        "Jiyuan Wang",
        "Zhen Liang"
      ],
      "abstract": "Continuous electroencephalography (EEG) signals are widely used in affective\nbrain-computer interface (aBCI) applications. However, not all continuously\ncollected EEG signals are relevant or meaningful to the task at hand (e.g.,\nwondering thoughts). On the other hand, manually labeling the relevant parts is\nnearly impossible due to varying engagement patterns across different tasks and\nindividuals. Therefore, effectively and efficiently identifying the important\nparts from continuous EEG recordings is crucial for downstream BCI tasks, as it\ndirectly impacts the accuracy and reliability of the results. In this paper, we\npropose a novel unsupervised deep reinforcement learning framework, called\nEmotion-Agent, to automatically identify relevant and informative emotional\nmoments from continuous EEG signals. Specifically, Emotion-Agent involves\nunsupervised deep reinforcement learning combined with a heuristic algorithm.\nWe first use the heuristic algorithm to perform an initial global search and\nform prototype representations of the EEG signals, which facilitates the\nefficient exploration of the signal space and identify potential regions of\ninterest. Then, we design distribution-prototype reward functions to estimate\nthe interactions between samples and prototypes, ensuring that the identified\nparts are both relevant and representative of the underlying emotional states.\nEmotion-Agent is trained using Proximal Policy Optimization (PPO) to achieve\nstable and efficient convergence. Our experiments compare the performance with\nand without Emotion-Agent. The results demonstrate that selecting relevant and\ninformative emotional parts before inputting them into downstream tasks\nenhances the accuracy and reliability of aBCI applications.",
      "tldr_zh": "这篇论文提出了 Emotion-Agent，一种无监督深度强化学习框架，用于从连续 EEG 信号中自动识别相关的情感时刻，以解决情感脑机接口 (aBCI) 应用中信号相关性问题。框架结合启发式算法进行初始全局搜索生成原型表示，并设计 distribution-prototype reward 函数来评估样本与原型的交互，同时使用 Proximal Policy Optimization (PPO) 实现稳定训练。实验结果表明，使用 Emotion-Agent 选择相关部分后，能显著提升下游 aBCI 任务的准确性和可靠性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 4 figures, 4 tables, submitted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.12121v1",
      "published_date": "2024-08-22 04:29:25 UTC",
      "updated_date": "2024-08-22 04:29:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:02:33.627943"
    },
    {
      "arxiv_id": "2408.12119v1",
      "title": "Understanding Data Reconstruction Leakage in Federated Learning from a Theoretical Perspective",
      "title_zh": "从理论视角理解联邦学习中的数据重建泄露",
      "authors": [
        "Zifan Wang",
        "Binghui Zhang",
        "Meng Pang",
        "Yuan Hong",
        "Binghui Wang"
      ],
      "abstract": "Federated learning (FL) is an emerging collaborative learning paradigm that\naims to protect data privacy. Unfortunately, recent works show FL algorithms\nare vulnerable to the serious data reconstruction attacks. However, existing\nworks lack a theoretical foundation on to what extent the devices' data can be\nreconstructed and the effectiveness of these attacks cannot be compared fairly\ndue to their unstable performance. To address this deficiency, we propose a\ntheoretical framework to understand data reconstruction attacks to FL. Our\nframework involves bounding the data reconstruction error and an attack's error\nbound reflects its inherent attack effectiveness. Under the framework, we can\ntheoretically compare the effectiveness of existing attacks. For instance, our\nresults on multiple datasets validate that the iDLG attack inherently\noutperforms the DLG attack.",
      "tldr_zh": "这篇论文从理论视角探讨了联邦学习(FL)中数据重建泄露的问题，强调现有攻击缺乏理论基础导致其有效性难以比较。研究提出一个理论框架，通过量化数据重建错误的边界来评估攻击的固有有效性，从而实现对不同攻击的公平比较。例如，在多个数据集上，实验结果验证了iDLG攻击比DLG攻击更具优势，为提升FL的数据隐私保护提供了重要指导。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12119v1",
      "published_date": "2024-08-22 04:20:48 UTC",
      "updated_date": "2024-08-22 04:20:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:02:44.643958"
    },
    {
      "arxiv_id": "2408.12116v2",
      "title": "Geolocation Representation from Large Language Models are Generic Enhancers for Spatio-Temporal Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Junlin He",
        "Tong Nie",
        "Wei Ma"
      ],
      "abstract": "In the geospatial domain, universal representation models are significantly\nless prevalent than their extensive use in natural language processing and\ncomputer vision. This discrepancy arises primarily from the high costs\nassociated with the input of existing representation models, which often\nrequire street views and mobility data. To address this, we develop a novel,\ntraining-free method that leverages large language models (LLMs) and auxiliary\nmap data from OpenStreetMap to derive geolocation representations (LLMGeovec).\nLLMGeovec can represent the geographic semantics of city, country, and global\nscales, which acts as a generic enhancer for spatio-temporal learning.\nSpecifically, by direct feature concatenation, we introduce a simple yet\neffective paradigm for enhancing multiple spatio-temporal tasks including\ngeographic prediction (GP), long-term time series forecasting (LTSF), and\ngraph-based spatio-temporal forecasting (GSTF). LLMGeovec can seamlessly\nintegrate into a wide spectrum of spatio-temporal learning models, providing\nimmediate enhancements. Experimental results demonstrate that LLMGeovec\nachieves global coverage and significantly boosts the performance of leading\nGP, LTSF, and GSTF models. Our codes are available at\n\\url{https://github.com/Umaruchain/LLMGeovec}.",
      "tldr_zh": "该研究指出，地理空间领域缺乏通用表示模型，主要因现有模型依赖昂贵的街景和移动数据。为此，提出了一种无需训练的创新方法，利用大型语言模型（LLMs）和OpenStreetMap的辅助地图数据，生成地理位置表示（LLMGeovec），以捕捉城市、国家和全球规模的地理语义。LLMGeovec作为通用增强器，通过直接特征连接，提升多种时空学习任务，包括地理预测（GP）、长期时间序列预测（LTSF）和基于图的时空预测（GSTF）。实验结果显示，LLMGeovec实现了全球覆盖，并显著提高了领先模型的性能，为时空学习提供了即时增强支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAAI25 main track",
      "pdf_url": "http://arxiv.org/pdf/2408.12116v2",
      "published_date": "2024-08-22 04:05:02 UTC",
      "updated_date": "2024-12-18 03:23:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:03:00.689530"
    },
    {
      "arxiv_id": "2408.12113v1",
      "title": "Risk Analysis in Customer Relationship Management via Quantile Region Convolutional Neural Network-Long Short-Term Memory and Cross-Attention Mechanism",
      "title_zh": "客户关系管理中的风险",
      "authors": [
        "Yaowen Huang",
        "Jun Der Leu",
        "Baoli Lu",
        "Yan Zhou"
      ],
      "abstract": "Risk analysis is an important business decision support task in customer\nrelationship management (CRM), involving the identification of potential risks\nor challenges that may affect customer satisfaction, retention rates, and\noverall business performance. To enhance risk analysis in CRM, this paper\ncombines the advantages of quantile region convolutional neural network-long\nshort-term memory (QRCNN-LSTM) and cross-attention mechanisms for modeling. The\nQRCNN-LSTM model combines sequence modeling with deep learning architectures\ncommonly used in natural language processing tasks, enabling the capture of\nboth local and global dependencies in sequence data. The cross-attention\nmechanism enhances interactions between different input data parts, allowing\nthe model to focus on specific areas or features relevant to CRM risk analysis.\nBy applying QRCNN-LSTM and cross-attention mechanisms to CRM risk analysis,\nempirical evidence demonstrates that this approach can effectively identify\npotential risks and provide data-driven support for business decisions.",
      "tldr_zh": "该研究针对客户关系管理(CRM)中的风险分析，提出了一种结合 Quantile Region Convolutional Neural Network-Long Short-Term Memory (QRCNN-LSTM) 和 Cross-Attention Mechanism 的方法，以识别潜在风险并支持业务决策。QRCNN-LSTM 模型整合了序列建模和深度学习架构，能够捕捉序列数据的局部和全局依赖关系，而 Cross-Attention Mechanism 则增强了不同输入数据部分之间的交互，允许模型重点关注与风险相关的关键特征。通过实证实验，该方法在 CRM 风险分析中表现出色，有效提升了风险识别的准确性和数据驱动决策的支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "44 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.12113v1",
      "published_date": "2024-08-22 03:55:28 UTC",
      "updated_date": "2024-08-22 03:55:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:03:08.807663"
    },
    {
      "arxiv_id": "2408.12112v3",
      "title": "Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards",
      "title_zh": "翻译失败",
      "authors": [
        "Shresth Verma",
        "Niclas Boehmer",
        "Lingkai Kong",
        "Milind Tambe"
      ],
      "abstract": "LLMs are increasingly used to design reward functions based on human\npreferences in Reinforcement Learning (RL). We focus on LLM-designed rewards\nfor Restless Multi-Armed Bandits, a framework for allocating limited resources\namong agents. In applications such as public health, this approach empowers\ngrassroots health workers to tailor automated allocation decisions to community\nneeds. In the presence of multiple agents, altering the reward function based\non human preferences can impact subpopulations very differently, leading to\ncomplex tradeoffs and a multi-objective resource allocation problem. We are the\nfirst to present a principled method termed Social Choice Language Model for\ndealing with these tradeoffs for LLM-designed rewards for multiagent planners\nin general and restless bandits in particular. The novel part of our model is a\ntransparent and configurable selection component, called an adjudicator,\nexternal to the LLM that controls complex tradeoffs via a user-selected social\nwelfare function. Our experiments demonstrate that our model reliably selects\nmore effective, aligned, and balanced reward functions compared to purely\nLLM-based approaches.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型 (LLMs) 设计强化学习 (Reinforcement Learning) 中奖励函数的策略，特别针对 Restless Multi-Armed Bandits 框架，用于多代理资源分配场景，如公共卫生中的社区需求定制。作者首次提出 Social Choice Language Model，这是一种新颖方法，通过一个外部的、可配置的 adjudicator 和用户选择的 social welfare function 来透明处理奖励函数调整带来的子群体权衡问题。实验结果显示，该模型比纯 LLM 方法更可靠地选择出有效、对齐和平衡的奖励函数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12112v3",
      "published_date": "2024-08-22 03:54:08 UTC",
      "updated_date": "2025-01-16 08:44:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:03:23.401821"
    },
    {
      "arxiv_id": "2408.12097v1",
      "title": "Extraction of Research Objectives, Machine Learning Model Names, and Dataset Names from Academic Papers and Analysis of Their Interrelationships Using LLM and Network Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "S. Nishio",
        "H. Nonaka",
        "N. Tsuchiya",
        "A. Migita",
        "Y. Banno",
        "T. Hayashi",
        "H. Sakaji",
        "T. Sakumoto",
        "K. Watabe"
      ],
      "abstract": "Machine learning is widely utilized across various industries. Identifying\nthe appropriate machine learning models and datasets for specific tasks is\ncrucial for the effective industrial application of machine learning. However,\nthis requires expertise in both machine learning and the relevant domain,\nleading to a high learning cost. Therefore, research focused on extracting\ncombinations of tasks, machine learning models, and datasets from academic\npapers is critically important, as it can facilitate the automatic\nrecommendation of suitable methods. Conventional information extraction methods\nfrom academic papers have been limited to identifying machine learning models\nand other entities as named entities. To address this issue, this study\nproposes a methodology extracting tasks, machine learning methods, and dataset\nnames from scientific papers and analyzing the relationships between these\ninformation by using LLM, embedding model, and network clustering. The proposed\nmethod's expression extraction performance, when using Llama3, achieves an\nF-score exceeding 0.8 across various categories, confirming its practical\nutility. Benchmarking results on financial domain papers have demonstrated the\neffectiveness of this method, providing insights into the use of the latest\ndatasets, including those related to ESG (Environmental, Social, and\nGovernance) data.",
      "tldr_zh": "本研究提出了一种从学术论文中提取研究目标、机器学习模型名称和数据集名称的方法，并使用LLM（如Llama3）、嵌入模型和网络聚类分析这些元素之间的关系，以促进机器学习任务的自动推荐。相比传统命名实体识别方法，该方法能够更全面地处理任务、模型和数据集的互连，提升了机器学习在工业应用中的可访问性。实验结果显示，使用Llama3的提取性能F-score超过0.8，并在金融领域基准测试中证明了其有效性，提供了对最新数据集（如ESG数据）的宝贵洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12097v1",
      "published_date": "2024-08-22 03:10:52 UTC",
      "updated_date": "2024-08-22 03:10:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:03:45.336124"
    },
    {
      "arxiv_id": "2408.12095v2",
      "title": "uMedSum: A Unified Framework for Advancing Medical Abstractive Summarization",
      "title_zh": "uMedSum：用于推进医学抽象式摘要生成的统一框架",
      "authors": [
        "Aishik Nagar",
        "Yutong Liu",
        "Andy T. Liu",
        "Viktor Schlegel",
        "Vijay Prakash Dwivedi",
        "Arun-Kumar Kaliya-Perumal",
        "Guna Pratheep Kalanchiam",
        "Yili Tang",
        "Robby T. Tan"
      ],
      "abstract": "Medical abstractive summarization faces the challenge of balancing\nfaithfulness and informativeness. Current methods often sacrifice key\ninformation for faithfulness or introduce confabulations when prioritizing\ninformativeness. While recent advancements in techniques like in-context\nlearning (ICL) and fine-tuning have improved medical summarization, they often\noverlook crucial aspects such as faithfulness and informativeness without\nconsidering advanced methods like model reasoning and self-improvement.\nMoreover, the field lacks a unified benchmark, hindering systematic evaluation\ndue to varied metrics and datasets. This paper addresses these gaps by\npresenting a comprehensive benchmark of six advanced abstractive summarization\nmethods across three diverse datasets using five standardized metrics. Building\non these findings, we propose uMedSum, a modular hybrid summarization framework\nthat introduces novel approaches for sequential confabulation removal followed\nby key missing information addition, ensuring both faithfulness and\ninformativeness. Our work improves upon previous GPT-4-based state-of-the-art\n(SOTA) medical summarization methods, significantly outperforming them in both\nquantitative metrics and qualitative domain expert evaluations. Notably, we\nachieve an average relative performance improvement of 11.8% in reference-free\nmetrics over the previous SOTA. Doctors prefer uMedSum's summaries 6 times more\nthan previous SOTA in difficult cases where there are chances of confabulations\nor missing information. These results highlight uMedSum's effectiveness and\ngeneralizability across various datasets and metrics, marking a significant\nadvancement in medical summarization.",
      "tldr_zh": "该论文指出现有医疗摘要化总结方法在平衡忠实性和信息性方面存在挑战，常因忽略模型推理和自我改进而牺牲关键信息或引入虚构。作者建立了统一基准，在三个数据集上评估六种高级摘要化总结方法，使用五种标准化指标，以系统化评估。uMedSum 框架通过模块化设计，引入顺序移除虚构信息和添加关键缺失信息的创新方法，显著超越 GPT-4-based SOTA，在无参考指标上平均提升 11.8%，并在医生评估中被偏好 6 倍以上，标志着医疗总结领域的重大进步。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.12095v2",
      "published_date": "2024-08-22 03:08:49 UTC",
      "updated_date": "2024-08-26 02:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:03:46.129575"
    },
    {
      "arxiv_id": "2408.12086v1",
      "title": "Unlocking Attributes' Contribution to Successful Camouflage: A Combined Textual and VisualAnalysis Strategy",
      "title_zh": "揭示属性对成功伪装的贡献：一种结合文本和视觉分析策略",
      "authors": [
        "Hong Zhang",
        "Yixuan Lyu",
        "Qian Yu",
        "Hanyang Liu",
        "Huimin Ma",
        "Ding Yuan",
        "Yifan Yang"
      ],
      "abstract": "In the domain of Camouflaged Object Segmentation (COS), despite continuous\nimprovements in segmentation performance, the underlying mechanisms of\neffective camouflage remain poorly understood, akin to a black box. To address\nthis gap, we present the first comprehensive study to examine the impact of\ncamouflage attributes on the effectiveness of camouflage patterns, offering a\nquantitative framework for the evaluation of camouflage designs. To support\nthis analysis, we have compiled the first dataset comprising descriptions of\ncamouflaged objects and their attribute contributions, termed COD-Text And\nX-attributions (COD-TAX). Moreover, drawing inspiration from the hierarchical\nprocess by which humans process information: from high-level textual\ndescriptions of overarching scenarios, through mid-level summaries of local\nareas, to low-level pixel data for detailed analysis. We have developed a\nrobust framework that combines textual and visual information for the task of\nCOS, named Attribution CUe Modeling with Eye-fixation Network (ACUMEN). ACUMEN\ndemonstrates superior performance, outperforming nine leading methods across\nthree widely-used datasets. We conclude by highlighting key insights derived\nfrom the attributes identified in our study. Code:\nhttps://github.com/lyu-yx/ACUMEN.",
      "tldr_zh": "本文首次针对 Camouflaged Object Segmentation (COS) 的黑箱问题，开展了首个全面研究，探讨伪装属性的影响，并提出一个定量评估框架。研究者编译了新的 COD-Text And X-attributions (COD-TAX) 数据集，并开发了 Attribution CUe Modeling with Eye-fixation Network (ACUMEN) 框架，该框架结合文本和视觉信息，模仿人类的层次化处理过程（从高层场景描述到低层像素分析）。实验结果显示，ACUMEN 在三个常用数据集上超越了九种领先方法，并揭示了伪装属性的关键洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12086v1",
      "published_date": "2024-08-22 02:51:21 UTC",
      "updated_date": "2024-08-22 02:51:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:03:58.145717"
    },
    {
      "arxiv_id": "2408.12080v1",
      "title": "Exploring the Feasibility of Automated Data Standardization using Large Language Models for Seamless Positioning",
      "title_zh": "探讨使用大语言模型实现自动化数据标准化的可行性，以支持无缝定位",
      "authors": [
        "Max J. L. Lee",
        "Ju Lin",
        "Li-Ta Hsu"
      ],
      "abstract": "We propose a feasibility study for real-time automated data standardization\nleveraging Large Language Models (LLMs) to enhance seamless positioning systems\nin IoT environments. By integrating and standardizing heterogeneous sensor data\nfrom smartphones, IoT devices, and dedicated systems such as Ultra-Wideband\n(UWB), our study ensures data compatibility and improves positioning accuracy\nusing the Extended Kalman Filter (EKF). The core components include the\nIntelligent Data Standardization Module (IDSM), which employs a fine-tuned LLM\nto convert varied sensor data into a standardized format, and the\nTransformation Rule Generation Module (TRGM), which automates the creation of\ntransformation rules and scripts for ongoing data standardization. Evaluated in\nreal-time environments, our study demonstrates adaptability and scalability,\nenhancing operational efficiency and accuracy in seamless navigation. This\nstudy underscores the potential of advanced LLMs in overcoming sensor data\nintegration complexities, paving the way for more scalable and precise IoT\nnavigation solutions.",
      "tldr_zh": "本研究探讨了使用大型语言模型(LLMs)进行实时自动化数据标准化的可行性，以提升IoT环境中的无缝定位系统。核心方法包括智能数据标准化模块(IDSM)，通过微调LLMs将来自智能手机、IoT设备和Ultra-Wideband(UWB)等异构传感器数据转换为标准化格式，以及转换规则生成模块(TRGM)，用于自动化生成转换规则和脚本，并结合扩展卡尔曼滤波器(EKF)提高定位准确性。在实时环境中评估显示，该方法显著提升了操作效率和适应性，证明了LLMs在克服传感器数据整合复杂性方面的潜力，为更可扩展的IoT导航解决方案铺平道路。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted at IPIN 2024. To be published in IEEE Xplore",
      "pdf_url": "http://arxiv.org/pdf/2408.12080v1",
      "published_date": "2024-08-22 02:40:21 UTC",
      "updated_date": "2024-08-22 02:40:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:04:21.606898"
    },
    {
      "arxiv_id": "2408.12079v1",
      "title": "High-Quality Data Augmentation for Low-Resource NMT: Combining a Translation Memory, a GAN Generator, and Filtering",
      "title_zh": "高质量数据增强用于低资源 NMT：结合翻译记忆库、GAN 生成器和过滤",
      "authors": [
        "Hengjie Liu",
        "Ruibo Hou",
        "Yves Lepage"
      ],
      "abstract": "Back translation, as a technique for extending a dataset, is widely used by\nresearchers in low-resource language translation tasks. It typically translates\nfrom the target to the source language to ensure high-quality translation\nresults. This paper proposes a novel way of utilizing a monolingual corpus on\nthe source side to assist Neural Machine Translation (NMT) in low-resource\nsettings. We realize this concept by employing a Generative Adversarial Network\n(GAN), which augments the training data for the discriminator while mitigating\nthe interference of low-quality synthetic monolingual translations with the\ngenerator. Additionally, this paper integrates Translation Memory (TM) with\nNMT, increasing the amount of data available to the generator. Moreover, we\npropose a novel procedure to filter the synthetic sentence pairs during the\naugmentation process, ensuring the high quality of the data.",
      "tldr_zh": "该论文针对低资源神经机器翻译 (NMT) 的数据不足问题，提出了一种高质量数据扩充方法，通过结合 Translation Memory (TM)、Generative Adversarial Network (GAN) 生成器和过滤机制，利用源语言单语语料库辅助翻译训练。GAN 生成器负责扩充数据，同时减少低质量合成翻译对模型的干扰；TM 被整合以增加生成器可用数据量；此外，论文引入了一个新颖的过滤过程，确保合成句对的高质量，从而提升整体翻译性能。该方法为低资源翻译任务提供了一个创新的框架，潜在地改善模型的准确性和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12079v1",
      "published_date": "2024-08-22 02:35:47 UTC",
      "updated_date": "2024-08-22 02:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:04:33.377948"
    },
    {
      "arxiv_id": "2408.12076v1",
      "title": "ConflictBank: A Benchmark for Evaluating the Influence of Knowledge Conflicts in LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaochen Su",
        "Jun Zhang",
        "Xiaoye Qu",
        "Tong Zhu",
        "Yanshu Li",
        "Jiashuo Sun",
        "Juntao Li",
        "Min Zhang",
        "Yu Cheng"
      ],
      "abstract": "Large language models (LLMs) have achieved impressive advancements across\nnumerous disciplines, yet the critical issue of knowledge conflicts, a major\nsource of hallucinations, has rarely been studied. Only a few research explored\nthe conflicts between the inherent knowledge of LLMs and the retrieved\ncontextual knowledge. However, a thorough assessment of knowledge conflict in\nLLMs is still missing. Motivated by this research gap, we present ConflictBank,\nthe first comprehensive benchmark developed to systematically evaluate\nknowledge conflicts from three aspects: (i) conflicts encountered in retrieved\nknowledge, (ii) conflicts within the models' encoded knowledge, and (iii) the\ninterplay between these conflict forms. Our investigation delves into four\nmodel families and twelve LLM instances, meticulously analyzing conflicts\nstemming from misinformation, temporal discrepancies, and semantic divergences.\nBased on our proposed novel construction framework, we create 7,453,853\nclaim-evidence pairs and 553,117 QA pairs. We present numerous findings on\nmodel scale, conflict causes, and conflict types. We hope our ConflictBank\nbenchmark will help the community better understand model behavior in conflicts\nand develop more reliable LLMs.",
      "tldr_zh": "该论文提出了ConflictBank，这是一个全面的基准，用于评估大型语言模型(LLM)中知识冲突的影响，这些冲突是模型幻觉的主要来源。ConflictBank从三个方面系统评估冲突：检索知识中的冲突、模型编码知识中的冲突，以及两者之间的互动，并分析了由错误信息、时间差异和语义分歧引起的问题。通过一个新颖的构建框架，该基准生成了7,453,853个claim-evidence对和553,117个QA对，并在四个模型家族和十二个LLM实例上进行了深入调查。研究揭示了模型规模、冲突原因和类型之间的关键发现，并旨在帮助社区提升LLM的可靠性和行为理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2408.12076v1",
      "published_date": "2024-08-22 02:33:13 UTC",
      "updated_date": "2024-08-22 02:33:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:04:35.410393"
    },
    {
      "arxiv_id": "2408.12067v2",
      "title": "Distributed Noncoherent Joint Transmission Based on Multi-Agent Reinforcement Learning for Dense Small Cell MISO Systems",
      "title_zh": "基于多智能体强化学习的分布式",
      "authors": [
        "Shaozhuang Bai",
        "Zhenzhen Gao",
        "Xuewen Liao"
      ],
      "abstract": "We consider a dense small cell (DSC) network where multi-antenna small cell\nbase stations (SBSs) transmit data to single-antenna users over a shared\nfrequency band. To enhance capacity, a state-of-the-art technique known as\nnoncoherent joint transmission (JT) is applied, enabling users to receive data\nfrom multiple coordinated SBSs. However, the sum rate maximization problem with\nnoncoherent JT is inherently nonconvex and NP-hard. While existing\noptimization-based noncoherent JT algorithms can provide near-optimal\nperformance, they require global channel state information (CSI) and multiple\niterations, which makes them difficult to be implemeted in DSC networks.To\novercome these challenges, we first prove that the optimal beamforming\nstructure is the same for both the power minimization problem and the sum rate\nmaximization problem, and then mathematically derive the optimal beamforming\nstructure for both problems by solving the power minimization problem.The\noptimal beamforming structure can effectively reduces the variable\ndimensions.By exploiting the optimal beamforming structure, we propose a deep\ndeterministic policy gradient-based distributed noncoherent JT scheme to\nmaximize the system sum rate.In the proposed scheme, each SBS utilizes global\ninformation for training and uses local CSI to determine beamforming vectors.\nSimulation results demonstrate that the proposed scheme achieves comparable\nperformance with considerably lower computational complexity and information\noverhead compared to centralized iterative optimization-based techniques,\nmaking it more attractive for practical deployment.",
      "tldr_zh": "该论文研究了密集小蜂窝（Dense Small Cell）MISO系统中的非相干联合传输（Noncoherent Joint Transmission），旨在通过多智能体强化学习（Multi-Agent Reinforcement Learning）最大化系统总速率。作者首先证明了功率最小化问题和总速率最大化问题的优化波束形成结构相同，并通过数学推导获得最优结构，以减少变量维度。随后，提出了一种基于深度确定性策略梯度（DDPG）的分布式非相干JT方案，其中每个小蜂窝基站（SBS）使用全局信息训练但仅依赖本地信道状态信息（CSI）来确定波束形成向量。模拟结果显示，该方案与集中式迭代优化技术相比，性能相当，但计算复杂度和信息开销显著降低，更适合实际部署。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "After thorough discussions with my co-authors, we have identified\n  certain issues with the paper that cannot be resolved through revisions. As a\n  result, we have collectively decided to complete withdraw the paper from\n  arXiv",
      "pdf_url": "http://arxiv.org/pdf/2408.12067v2",
      "published_date": "2024-08-22 02:11:14 UTC",
      "updated_date": "2024-09-11 04:06:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:04:47.040456"
    },
    {
      "arxiv_id": "2408.12065v1",
      "title": "Transformers As Approximations of Solomonoff Induction",
      "title_zh": "翻译失败",
      "authors": [
        "Nathan Young",
        "Michael Witbrock"
      ],
      "abstract": "Solomonoff Induction is an optimal-in-the-limit unbounded algorithm for\nsequence prediction, representing a Bayesian mixture of every computable\nprobability distribution and performing close to optimally in predicting any\ncomputable sequence.\n  Being an optimal form of computational sequence prediction, it seems\nplausible that it may be used as a model against which other methods of\nsequence prediction might be compared.\n  We put forth and explore the hypothesis that Transformer models - the basis\nof Large Language Models - approximate Solomonoff Induction better than any\nother extant sequence prediction method. We explore evidence for and against\nthis hypothesis, give alternate hypotheses that take this evidence into\naccount, and outline next steps for modelling Transformers and other kinds of\nAI in this way.",
      "tldr_zh": "本文假设 Transformers 模型（作为大型语言模型的基础）比其他现有序列预测方法更好地近似 Solomonoff Induction，一种极限最优的序列预测算法，它基于所有可计算概率分布的 Bayesian 混合体。作者探讨了支持和反对这一假设的证据，包括对 Transformers 在序列预测中的表现进行比较，并提出了替代假设以整合这些证据。该研究为未来建模 Transformers 和其他 AI 系统提供了下一步方向，帮助评估其在计算序列预测中的效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12065v1",
      "published_date": "2024-08-22 02:05:44 UTC",
      "updated_date": "2024-08-22 02:05:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:05:07.741844"
    },
    {
      "arxiv_id": "2408.12063v1",
      "title": "A Deconfounding Approach to Climate Model Bias Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Wentao Gao",
        "Jiuyong Li",
        "Debo Cheng",
        "Lin Liu",
        "Jixue Liu",
        "Thuc Duy Le",
        "Xiaojing Du",
        "Xiongren Chen",
        "Yanchang Zhao",
        "Yun Chen"
      ],
      "abstract": "Global Climate Models (GCMs) are crucial for predicting future climate\nchanges by simulating the Earth systems. However, GCM outputs exhibit\nsystematic biases due to model uncertainties, parameterization simplifications,\nand inadequate representation of complex climate phenomena. Traditional bias\ncorrection methods, which rely on historical observation data and statistical\ntechniques, often neglect unobserved confounders, leading to biased results.\nThis paper proposes a novel bias correction approach to utilize both GCM and\nobservational data to learn a factor model that captures multi-cause latent\nconfounders. Inspired by recent advances in causality based time series\ndeconfounding, our method first constructs a factor model to learn latent\nconfounders from historical data and then applies them to enhance the bias\ncorrection process using advanced time series forecasting models. The\nexperimental results demonstrate significant improvements in the accuracy of\nprecipitation outputs. By addressing unobserved confounders, our approach\noffers a robust and theoretically grounded solution for climate model bias\ncorrection.",
      "tldr_zh": "本研究针对全球气候模型（GCMs）的系统偏差问题，提出了一种新型去混杂偏差校正方法，该方法利用GCM输出和观测数据学习因子模型，以捕捉多因子的潜在混杂因素（latent confounders）。受因果性时间序列去混杂（causality based time series deconfounding）技术的启发，该方法先从历史数据中提取混杂因素，然后将其整合到高级时间序列预测模型（time series forecasting models）中进行偏差校正。实验结果显示，该方法显著提高了降水输出的准确性，为气候模型偏差校正提供了稳健且理论基础坚实的解决方案。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "physics.ao-ph"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12063v1",
      "published_date": "2024-08-22 01:53:35 UTC",
      "updated_date": "2024-08-22 01:53:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:05:18.016064"
    },
    {
      "arxiv_id": "2408.12062v2",
      "title": "Enhancing Sampling Protocol for Point Cloud Classification Against Corruptions",
      "title_zh": "增强点云分类采样协议以对抗损坏",
      "authors": [
        "Chongshou Li",
        "Pin Tang",
        "Xinke Li",
        "Yuheng Liu",
        "Tianrui Li"
      ],
      "abstract": "Established sampling protocols for 3D point cloud learning, such as Farthest\nPoint Sampling (FPS) and Fixed Sample Size (FSS), have long been relied upon.\nHowever, real-world data often suffer from corruptions, such as sensor noise,\nwhich violates the benign data assumption in current protocols. As a result,\nthese protocols are highly vulnerable to noise, posing significant safety risks\nin critical applications like autonomous driving. To address these issues, we\npropose an enhanced point cloud sampling protocol, PointSP, designed to improve\nrobustness against point cloud corruptions. PointSP incorporates key point\nreweighting to mitigate outlier sensitivity and ensure the selection of\nrepresentative points. It also introduces a local-global balanced downsampling\nstrategy, which allows for scalable and adaptive sampling while maintaining\ngeometric consistency. Additionally, a lightweight tangent plane interpolation\nmethod is used to preserve local geometry while enhancing the density of the\npoint cloud. Unlike learning-based approaches that require additional model\ntraining, PointSP is architecture-agnostic, requiring no extra learning or\nmodification to the network. This enables seamless integration into existing\npipelines. Extensive experiments on synthetic and real-world corrupted datasets\nshow that PointSP significantly improves the robustness and accuracy of point\ncloud classification, outperforming state-of-the-art methods across multiple\nbenchmarks.",
      "tldr_zh": "本研究针对现有点云学习采样协议如 FPS (Farthest Point Sampling) 和 FSS (Fixed Sample Size) 在面对现实世界噪声（如传感器噪声）时的脆弱性问题，提出了一种增强型协议 PointSP，以提升点云分类的鲁棒性。PointSP 包括关键点 reweighting 以减少异常点敏感性、local-global balanced downsampling strategy 以实现可扩展的自适应采样并保持几何一致性，以及 lightweight tangent plane interpolation 以保留局部几何并增强点云密度。该方法无需额外模型训练或网络修改，具备架构无关性，便于无缝集成到现有管道中。实验结果显示，PointSP 在合成和真实世界腐败数据集上显著提高了点云分类的准确性和鲁棒性，超越了最先进方法的多项基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12062v2",
      "published_date": "2024-08-22 01:48:31 UTC",
      "updated_date": "2025-02-03 08:43:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:05:25.928952"
    },
    {
      "arxiv_id": "2408.12060v2",
      "title": "Evidence-backed Fact Checking using RAG and Few-Shot In-Context Learning with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ronit Singhal",
        "Pransh Patwa",
        "Parth Patwa",
        "Aman Chadha",
        "Amitava Das"
      ],
      "abstract": "Given the widespread dissemination of misinformation on social media,\nimplementing fact-checking mechanisms for online claims is essential. Manually\nverifying every claim is very challenging, underscoring the need for an\nautomated fact-checking system. This paper presents our system designed to\naddress this issue. We utilize the Averitec dataset (Schlichtkrull et al.,\n2023) to assess the performance of our fact-checking system. In addition to\nveracity prediction, our system provides supporting evidence, which is\nextracted from the dataset. We develop a Retrieve and Generate (RAG) pipeline\nto extract relevant evidence sentences from a knowledge base, which are then\ninputted along with the claim into a large language model (LLM) for\nclassification. We also evaluate the few-shot In-Context Learning (ICL)\ncapabilities of multiple LLMs. Our system achieves an 'Averitec' score of 0.33,\nwhich is a 22% absolute improvement over the baseline. Our Code is publicly\navailable on\nhttps://github.com/ronit-singhal/evidence-backed-fact-checking-using-rag-and-few-shot-in-context-learning-with-llms.",
      "tldr_zh": "这篇论文提出了一种基于 Retrieve and Generate (RAG) 管道和 Few-Shot In-Context Learning with LLMs 的证据支持事实检查系统，用于应对社交媒体上误信息传播的问题。系统利用 Averitec 数据集从知识库中提取相关证据句子，并将其与声明输入到大型语言模型 (LLM) 中进行真实性分类，同时评估多个 LLM 的 Few-Shot ICL 能力。实验结果显示，该系统在 Averitec 得分上达到 0.33，比基线模型提高了 22%。代码已在 GitHub 上公开，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in The Seventh FEVER Workshop at EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12060v2",
      "published_date": "2024-08-22 01:42:34 UTC",
      "updated_date": "2024-10-04 19:31:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:05:35.142545"
    },
    {
      "arxiv_id": "2408.12056v2",
      "title": "Enhancing Automated Program Repair with Solution Design",
      "title_zh": "通过解决方案设计增强自动化程序修复",
      "authors": [
        "Jiuang Zhao",
        "Donghao Yang",
        "Li Zhang",
        "Xiaoli Lian",
        "Zitian Yang",
        "Fang Liu"
      ],
      "abstract": "Automatic Program Repair (APR) endeavors to autonomously rectify issues\nwithin specific projects, which generally encompasses three categories of\ntasks: bug resolution, new feature development, and feature enhancement.\nDespite extensive research proposing various methodologies, their efficacy in\naddressing real issues remains unsatisfactory. It's worth noting that,\ntypically, engineers have design rationales (DR) on solution-planed solutions\nand a set of underlying reasons-before they start patching code. In open-source\nprojects, these DRs are frequently captured in issue logs through project\nmanagement tools like Jira. This raises a compelling question: How can we\nleverage DR scattered across the issue logs to efficiently enhance APR? To\ninvestigate this premise, we introduce DRCodePilot, an approach designed to\naugment GPT-4-Turbo's APR capabilities by incorporating DR into the prompt\ninstruction. Furthermore, given GPT-4's constraints in fully grasping the\nbroader project context and occasional shortcomings in generating precise\nidentifiers, we have devised a feedback-based self-reflective framework, in\nwhich we prompt GPT-4 to reconsider and refine its outputs by referencing a\nprovided patch and suggested identifiers. We have established a benchmark\ncomprising 938 issue-patch pairs sourced from two open-source repositories\nhosted on GitHub and Jira. Our experimental results are impressive: DRCodePilot\nachieves a full-match ratio that is a remarkable 4.7x higher than when GPT-4 is\nutilized directly. Additionally, the CodeBLEU scores also exhibit promising\nenhancements. Moreover, our findings reveal that the standalone application of\nDR can yield promising increase in the full-match ratio across CodeLlama,\nGPT-3.5, and GPT-4 within our benchmark suite. We believe that our DRCodePilot\ninitiative heralds a novel human-in-the-loop avenue for advancing the field of\nAPR.",
      "tldr_zh": "本文研究了如何利用设计理由 (Design Rationales, DR) 来自问题日志来提升 Automated Program Repair (APR) 的效果，针对 bug 修复、新功能开发和功能增强等任务。论文提出 DRCodePilot 方法，通过将 DR 整合到 GPT-4-Turbo 的提示指令中，并采用反馈-based self-reflective 框架，让模型重新审视并优化输出。实验在包含 938 个 issue-patch 对的基准数据集上显示，DRCodePilot 的 full-match ratio 比直接使用 GPT-4 高出 4.7 倍，CodeBLEU 分数也显著提升；此外，单独应用 DR 可提高 CodeLlama、GPT-3.5 和 GPT-4 的修复准确率。该工作为 APR 领域引入人类参与的新途径，提供更高效的自主修复机制。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "*These authors contributed equally to this work. {\\dag}Corresponding\n  author. Will appear in ase'24",
      "pdf_url": "http://arxiv.org/pdf/2408.12056v2",
      "published_date": "2024-08-22 01:13:02 UTC",
      "updated_date": "2024-09-22 03:16:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:05:48.362747"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 119,
  "processed_papers_count": 119,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T18:06:15.015544"
}