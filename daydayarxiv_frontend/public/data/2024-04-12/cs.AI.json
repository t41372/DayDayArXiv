{
  "date": "2024-04-12",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-12 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 79 篇论文，主要聚焦 AI 和机器学习的创新应用，如大语言模型（LLM）的偏见与安全强化、强化学习在自主驾驶和机器人领域的进展，以及计算机视觉的多模态处理；令人印象深刻的是 LLM 在医疗和机器人任务中的潜力，以及著名会议如 ICLR 和 NeurIPS 的相关工作。\n\n### 重点论文讨论\n我将优先选取话题度高、创新性强或涉及著名学者的论文进行详细讨论，并将相关主题归类。其他论文将简要掠过，以控制篇幅。\n\n#### 大语言模型（LLM）的偏见、安全与应用\n这些论文探讨了 LLM 的鲁棒性、偏见和实际应用，体现了 AI 领域的热门话题。\n- **The Generation Gap: Exploring Age Bias in the Value Systems of Large Language Models**（《代际鸿沟：探索大语言模型价值体系中的年龄偏见》）  \n  这篇论文由 Rada Mihalcea 等学者主导，分析了 LLM 在不同年龄组的价值偏见，主要贡献是通过世界价值调查数据揭示 LLM 倾向于年轻群体，并提出融入年龄身份信息的方法以缓解偏差，发现这种偏见在某些类别（如社会价值观）更明显。\n- **Is ChatGPT Transforming Academics' Writing Style?**（《ChatGPT 是否在改变学术写作风格？》）  \n  作者 Mingmeng Geng 和 Roberto Trotta 使用百万 arXiv 论文分析 LLM 对学术摘要的影响，主要发现 ChatGPT 风格的写作在计算机科学领域占比约 35%，并讨论了其对学术写作的积极和消极影响。\n- **RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs**（《RLHF 解析：基于人类反馈的强化学习在大语言模型中的关键分析》）  \n  这篇论文审视了基于人类反馈的强化学习（RLHF）在 LLM 中的局限性，主要贡献是分析奖励模型的假设和问题，提供理论框架以改进 RLHF 的泛化性和鲁棒性。\n- **FLoRA: Enhancing Vision-Language Models with Parameter-Efficient Federated Learning**（《FLoRA：通过参数高效的联邦学习增强视觉语言模型》）  \n  相关于多模态 LLM，该论文提出联邦学习框架来优化视觉语言模型训练，主要发现这种方法在保持隐私的前提下，提高了模型效率，并减少了计算资源需求。\n\n这些 LLM 相关工作突出了 AI 安全和偏见问题，具有实际应用潜力，如在医疗和教育领域的部署。\n\n#### 强化学习在机器人和自主驾驶中的创新\n强化学习论文较多，我挑选了几个有实际影响的。\n- **Hindsight PRIORs for Reward Learning from Human Preferences**（《基于后见先知奖励学习的偏好建模》）  \n  作者 Mudit Verma 和 Katherine Metcalf 提出了一种信用分配策略，用于从人类偏好中学习奖励函数，主要贡献是改善了强化学习的策略性能，在 MetaWorld 和 DMC 任务中提升了 15-20% 的奖励恢复率。\n- **Vehicle-to-Vehicle Charging: Model, Complexity, and Heuristics**（《车辆间充电：模型、复杂性和启发式方法》）  \n  这篇论文由 Soummya Kar 和 Sridhar Tayur 等知名学者撰写，针对电动车辆充电建模 NP-Complete 问题，主要发现启发式算法 R-V2VC 能高效解决实际规模问题，并在 IEEE 会议中被接受。\n- **Enhancing Autonomous Vehicle Training with Language Model Integration and Critical Scenario Generation**（《通过语言模型集成和关键场景生成增强自主车辆训练》）  \n  作者团队包括 Yiannis Demiris，提出 CRITICAL 框架，将 LLM 用于生成关键驾驶场景，主要贡献是提升了强化学习的训练效率和安全性，在 HighwayEnv 模拟中表现出色。\n- **Differentiable and Stable Long-Range Tracking of Multiple Posterior Modes**（《可微和稳定的多后验模式长期跟踪》）  \n  作者 Ali Younis 和 Erik Sudderth 开发了基于混合密度粒子滤波的跟踪方法，主要发现这种方法在机器人定位任务中提高了准确性和鲁棒性。\n\n这些论文展示了强化学习在真实世界应用的潜力，尤其在自主驾驶和机器人领域，相关工作如 IROS 会议论文值得关注。\n\n#### 计算机视觉和图像处理进展\n视觉相关论文创新性强，我挑选了几个代表。\n- **BERT-LSH: Reducing Absolute Compute For Attention**（《BERT-LSH：减少注意力机制的计算量》）  \n  作者 Zezheng Li 和 Kingston Yip 提出 LSH 机制优化 BERT 注意力，主要贡献是显著降低计算需求，同时在预训练和微调任务中提升了性能。\n- **Semantic Approach to Quantifying the Consistency of Diffusion Model Image Generation**（《扩散模型图像生成的语义一致性量化方法》）  \n  作者 Brinnae Bent 使用 CLIP 分数量化扩散模型的一致性，主要发现 Stable Diffusion XL 在语义一致性上优于其他模型，并在 CVPR 研讨会中被接受。\n- **PnLCalib: Sports Field Registration via Points and Lines Optimization**（《PnLCalib：通过点线优化的体育场注册》）  \n  这篇论文在 ICLR 背景下优化了体育视频校准，主要贡献是提出点线优化框架，提升了多视角相机校准的准确性。\n\n这些工作在图像处理和多模态融合上取得了进展，适用于实际场景如体育分析。\n\n### 其他论文简要掠过\n剩余论文涉及领域广泛，如神经网络优化（第18、22）、数据生成（第49）、图神经网络（第55）等，但许多较为理论化或小众，我仅快速总结：例如，第11 论文讨论了 AI 训练基础设施的挑战，第25 提出 SNN 在控制系统中的能效框架，第38 探索了强化学习在森林防火中的应用。这些论文虽有贡献，如第38 在防火策略上提供了新方法，但整体影响力较小，建议感兴趣读者查阅具体摘要。\n\n总之，今天的 arXiv 更新突显了 AI 领域的动态发展，LLM 和强化学习的创新值得持续关注。如果您有特定兴趣领域，欢迎深入探索这些论文！",
  "papers": [
    {
      "arxiv_id": "2404.08850v2",
      "title": "Assessing Economic Viability: A Comparative Analysis of Total Cost of Ownership for Domain-Adapted Large Language Models versus State-of-the-art Counterparts in Chip Design Coding Assistance",
      "title_zh": "评估经济可行性：领域",
      "authors": [
        "Amit Sharma",
        "Teodor-Dumitru Ene",
        "Kishor Kunal",
        "Mingjie Liu",
        "Zafar Hasan",
        "Haoxing Ren"
      ],
      "abstract": "This paper presents a comparative analysis of total cost of ownership (TCO)\nand performance between domain-adapted large language models (LLM) and\nstate-of-the-art (SoTA) LLMs , with a particular emphasis on tasks related to\ncoding assistance for chip design. We examine the TCO and performance metrics\nof a domain-adaptive LLM, ChipNeMo, against two leading LLMs, Claude 3 Opus and\nChatGPT-4 Turbo, to assess their efficacy in chip design coding generation.\nThrough a detailed evaluation of the accuracy of the model, training\nmethodologies, and operational expenditures, this study aims to provide\nstakeholders with critical information to select the most economically viable\nand performance-efficient solutions for their specific needs. Our results\nunderscore the benefits of employing domain-adapted models, such as ChipNeMo,\nthat demonstrate improved performance at significantly reduced costs compared\nto their general-purpose counterparts. In particular, we reveal the potential\nof domain-adapted LLMs to decrease TCO by approximately 90%-95%, with the cost\nadvantages becoming increasingly evident as the deployment scale expands. With\nexpansion of deployment, the cost benefits of ChipNeMo become more pronounced,\nmaking domain-adaptive LLMs an attractive option for organizations with\nsubstantial coding needs supported by LLMs",
      "tldr_zh": "本研究比较了领域适应的大型语言模型（LLM），如 ChipNeMo，与最先进（SoTA）模型如 Claude 3 Opus 和 ChatGPT-4 Turbo，在芯片设计编码辅助任务中的总拥有成本（TCO）和性能差异。研究通过评估模型准确性、训练方法以及运营支出，提供决策者选择经济可行解决方案的关键信息。结果显示，ChipNeMo 等领域适应模型在保持或提升性能的同时，可将 TCO 降低约 90%-95%，且在大规模部署场景下，其成本优势更为显著，使其成为高需求组织的首选选项。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Paper accepted in IEEE-ACM conference: 2024 IEEE LLM-Aided Design\n  Workshop (LAD)",
      "pdf_url": "http://arxiv.org/pdf/2404.08850v2",
      "published_date": "2024-04-12 23:37:56 UTC",
      "updated_date": "2024-05-28 17:11:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:48:35.585651"
    },
    {
      "arxiv_id": "2404.08844v2",
      "title": "Multi-fingered Robotic Hand Grasping in Cluttered Environments through Hand-object Contact Semantic Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Zhang",
        "Kaixin Bai",
        "Guowen Huang",
        "Zhenshan Bing",
        "Zhaopeng Chen",
        "Alois Knoll",
        "Jianwei Zhang"
      ],
      "abstract": "The deep learning models has significantly advanced dexterous manipulation\ntechniques for multi-fingered hand grasping. However, the contact\ninformation-guided grasping in cluttered environments remains largely\nunderexplored. To address this gap, we have developed a method for generating\nmulti-fingered hand grasp samples in cluttered settings through contact\nsemantic map. We introduce a contact semantic conditional variational\nautoencoder network (CoSe-CVAE) for creating comprehensive contact semantic map\nfrom object point cloud. We utilize grasp detection method to estimate hand\ngrasp poses from the contact semantic map. Finally, an unified grasp evaluation\nmodel is designed to assess grasp quality and collision probability,\nsubstantially improving the reliability of identifying optimal grasps in\ncluttered scenarios. Our grasp generation method has demonstrated remarkable\nsuccess, outperforming state-of-the-art methods by at least 4.65% with 81.0%\naverage grasping success rate in real-world single-object environment and 75.3%\ngrasping success rate in cluttered scenes. We also proposed the multi-modal\nmulti-fingered grasping dataset generation method. Our multi-fingered hand\ngrasping dataset outperforms previous datasets in scene diversity, modality\ndiversity. The dataset, code and supplementary materials can be found at\nhttps://sites.google.com/view/ffh-cluttered-grasping.",
      "tldr_zh": "这篇论文针对多指机器人手在杂乱环境中的抓取问题，提出了一种基于手-物体接触语义映射的方法，以解决深度学习模型在接触信息引导方面的不足。核心技术包括CoSe-CVAE网络，用于从物体点云生成全面的接触语义映射，随后通过抓取检测估计手抓取姿势，并设计统一的抓取评估模型来评估抓取质量和碰撞概率。实验结果显示，该方法在真实世界环境中实现81.0%的单物体抓取成功率和75.3%的杂乱场景成功率，比现有方法至少提高4.65%。此外，论文还引入了一个在场景和模态多样性上优于现有数据集的多模态多指抓取数据集，并提供了相关资源。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.08844v2",
      "published_date": "2024-04-12 23:11:36 UTC",
      "updated_date": "2024-09-22 11:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:48:50.345007"
    },
    {
      "arxiv_id": "2404.08837v2",
      "title": "Vehicle-to-Vehicle Charging: Model, Complexity, and Heuristics",
      "title_zh": "车辆间充电：模型、复杂度和启发式方法",
      "authors": [
        "Cláudio Gomes",
        "João Paulo Fernandes",
        "Gabriel Falcao",
        "Soummya Kar",
        "Sridhar Tayur"
      ],
      "abstract": "The rapid adoption of Electric Vehicles (EVs) poses challenges for\nelectricity grids to accommodate or mitigate peak demand. Vehicle-to-Vehicle\nCharging (V2VC) has been recently adopted by popular EVs, posing new\nopportunities and challenges to the management and operation of EVs. We present\na novel V2VC model that allows decision-makers to take V2VC into account when\noptimizing their EV operations. We show that optimizing V2VC is NP-Complete and\nfind that even small problem instances are computationally challenging. We\npropose R-V2VC, a heuristic that takes advantage of the resulting totally\nunimodular constraint matrix to efficiently solve problems of realistic sizes.\nOur results demonstrate that R-V2VC presents a linear growth in the solution\ntime as the problem size increases, while achieving solutions of optimal or\nnear-optimal quality. R-V2VC can be used for real-world operations and to study\nwhat-if scenarios when evaluating the costs and benefits of V2VC.",
      "tldr_zh": "该论文提出一个新的Vehicle-to-Vehicle Charging (V2VC) 模型，用于帮助决策者在优化Electric Vehicles (EVs) 操作时考虑V2VC，从而缓解电网峰值需求挑战。研究证明，优化V2VC是一个NP-Complete问题，且即使小型实例也计算复杂，因此开发了启发式算法R-V2VC，利用全非模约束矩阵实现高效求解。实验结果显示，R-V2VC的求解时间随问题规模线性增长，同时获得最优或近似最优解，可应用于实际EV管理和评估V2VC的成本与益处。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 6 figures, and 3 tables. This work has been submitted to the\n  IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2404.08837v2",
      "published_date": "2024-04-12 22:46:37 UTC",
      "updated_date": "2024-10-14 14:05:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:48:59.183218"
    },
    {
      "arxiv_id": "2404.08836v1",
      "title": "BERT-LSH: Reducing Absolute Compute For Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Zezheng Li",
        "Kingston Yip"
      ],
      "abstract": "This study introduces a novel BERT-LSH model that incorporates Locality\nSensitive Hashing (LSH) to approximate the attention mechanism in the BERT\narchitecture. We examine the computational efficiency and performance of this\nmodel compared to a standard baseline BERT model. Our findings reveal that\nBERT-LSH significantly reduces computational demand for the self-attention\nlayer while unexpectedly outperforming the baseline model in pretraining and\nfine-tuning tasks. These results suggest that the LSH-based attention mechanism\nnot only offers computational advantages but also may enhance the model's\nability to generalize from its training data. For more information, visit our\nGitHub repository: https://github.com/leo4life2/algoml-final",
      "tldr_zh": "本研究提出了一种名为 BERT-LSH 的模型，通过 Locality Sensitive Hashing (LSH) 来近似 BERT 架构中的注意力机制，从而显著减少自注意力层的计算需求。实验结果显示，与标准 BERT 基线模型相比，BERT-LSH 在预训练和微调任务中不仅降低了计算量，还意外地提升了性能表现。总体而言，这种 LSH-based 注意力机制不仅提供了计算优势，还可能增强模型的泛化能力，为高效的Transformer模型优化提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.08836v1",
      "published_date": "2024-04-12 22:35:00 UTC",
      "updated_date": "2024-04-12 22:35:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:49:11.290790"
    },
    {
      "arxiv_id": "2405.02316v1",
      "title": "A Cloud-Edge Framework for Energy-Efficient Event-Driven Control: An Integration of Online Supervised Learning, Spiking Neural Networks and Local Plasticity Rules",
      "title_zh": "翻译失败",
      "authors": [
        "Reza Ahmadvand",
        "Sarah Safura Sharif",
        "Yaser Mike Banad"
      ],
      "abstract": "This paper presents a novel cloud-edge framework for addressing computational\nand energy constraints in complex control systems. Our approach centers around\na learning-based controller using Spiking Neural Networks (SNN) on physical\nplants. By integrating a biologically plausible learning method with local\nplasticity rules, we harness the efficiency, scalability, and low latency of\nSNNs. This design replicates control signals from a cloud-based controller\ndirectly on the plant, reducing the need for constant plant-cloud\ncommunication. The plant updates weights only when errors surpass predefined\nthresholds, ensuring efficiency and robustness in various conditions. Applied\nto linear workbench systems and satellite rendezvous scenarios, including\nobstacle avoidance, our architecture dramatically lowers normalized tracking\nerror by 96% with increased network size. The event-driven nature of SNNs\nminimizes energy consumption, utilizing only about 111 nJ (0.3% of conventional\ncomputing requirements). The results demonstrate the system's adjustment to\nchanging work environments and its efficient use of computational and energy\nresources, with a moderate increase in energy consumption of 27.2% and 37% for\nstatic and dynamic obstacles, respectively, compared to non-obstacle scenarios.",
      "tldr_zh": "本论文提出了一种云边框架，用于解决复杂控制系统的计算和能源约束问题，通过整合在线监督学习(Online Supervised Learning)、Spiking Neural Networks (SNN) 和本地可塑性规则(Local Plasticity Rules)，实现高效的事件驱动控制。框架在物理设备上复制云端控制信号，仅在错误超过阈值时更新权重，从而减少设备-云通信并提升鲁棒性。实验结果显示，在线性工作台系统和卫星交会场景（包括避障）中，该框架将归一化跟踪错误降低96%，SNN的能源消耗仅为111 nJ（占常规计算的0.3%），并在动态环境中表现出色，尽管避障时能源消耗分别增加27.2%和37%。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "13 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.02316v1",
      "published_date": "2024-04-12 22:34:17 UTC",
      "updated_date": "2024-04-12 22:34:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:49:23.586811"
    },
    {
      "arxiv_id": "2404.08828v1",
      "title": "Hindsight PRIORs for Reward Learning from Human Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Mudit Verma",
        "Katherine Metcalf"
      ],
      "abstract": "Preference based Reinforcement Learning (PbRL) removes the need to hand\nspecify a reward function by learning a reward from preference feedback over\npolicy behaviors. Current approaches to PbRL do not address the credit\nassignment problem inherent in determining which parts of a behavior most\ncontributed to a preference, which result in data intensive approaches and\nsubpar reward functions. We address such limitations by introducing a credit\nassignment strategy (Hindsight PRIOR) that uses a world model to approximate\nstate importance within a trajectory and then guides rewards to be proportional\nto state importance through an auxiliary predicted return redistribution\nobjective. Incorporating state importance into reward learning improves the\nspeed of policy learning, overall policy performance, and reward recovery on\nboth locomotion and manipulation tasks. For example, Hindsight PRIOR recovers\non average significantly (p<0.05) more reward on MetaWorld (20%) and DMC (15%).\nThe performance gains and our ablations demonstrate the benefits even a simple\ncredit assignment strategy can have on reward learning and that state\nimportance in forward dynamics prediction is a strong proxy for a state's\ncontribution to a preference decision. Code repository can be found at\nhttps://github.com/apple/ml-rlhf-hindsight-prior.",
      "tldr_zh": "该论文提出了一种名为 Hindsight PRIOR 的信用分配策略，用于基于偏好强化学习 (PbRL)，旨在解决传统方法在确定行为贡献时存在的信用分配问题。该策略利用世界模型评估轨迹中状态的重要性，并通过辅助预测回报重新分配目标，使奖励与状态重要性成比例，从而提升奖励学习效率。实验结果显示，Hindsight PRIOR 在运动和操作任务上显著提高了政策学习速度和整体性能，例如在 MetaWorld 上奖励恢复提高了 20%，在 DMC 上提高了 15%，证明了状态重要性在偏好决策中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "International Conference on Learning Representations, 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08828v1",
      "published_date": "2024-04-12 21:59:42 UTC",
      "updated_date": "2024-04-12 21:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:49:34.889546"
    },
    {
      "arxiv_id": "2404.08825v2",
      "title": "Inverse Kinematics for Neuro-Robotic Grasping with Humanoid Embodied Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jan-Gerrit Habekost",
        "Connor Gäde",
        "Philipp Allgeuer",
        "Stefan Wermter"
      ],
      "abstract": "This paper introduces a novel zero-shot motion planning method that allows\nusers to quickly design smooth robot motions in Cartesian space. A B\\'ezier\ncurve-based Cartesian plan is transformed into a joint space trajectory by our\nneuro-inspired inverse kinematics (IK) method CycleIK, for which we enable\nplatform independence by scaling it to arbitrary robot designs. The motion\nplanner is evaluated on the physical hardware of the two humanoid robots NICO\nand NICOL in a human-in-the-loop grasping scenario. Our method is deployed with\nan embodied agent that is a large language model (LLM) at its core. We\ngeneralize the embodied agent, that was introduced for NICOL, to also embody\nNICO. The agent can execute a discrete set of physical actions and allows the\nuser to verbally instruct various different robots. We contribute a grasping\nprimitive to its action space that allows for precise manipulation of household\nobjects. The updated CycleIK method is compared to popular numerical IK solvers\nand state-of-the-art neural IK methods in simulation and is shown to be\ncompetitive with or outperform all evaluated methods when the algorithm runtime\nis very short. The grasping primitive is evaluated on both NICOL and NICO\nrobots with a reported grasp success of 72% to 82% for each robot,\nrespectively.",
      "tldr_zh": "这篇论文提出了一种零样本运动规划方法，使用 B\\'ezier 曲线结合神经启发式逆运动学方法 CycleIK，将笛卡尔空间的平滑机器人运动转换为关节空间轨迹，并扩展到任意机器人设计以实现平台独立性。研究将该方法整合到一个以大型语言模型 (LLM) 为核心的具身代理中，允许用户通过语音指令控制 NICO 和 NICOL 人形机器人执行抓取任务，并新增了一个抓取原语以实现精确操作家居物体。实验结果显示，CycleIK 在模拟中优于传统数值 IK 求解器和最先进神经 IK 方法，尤其在短运行时间内，且在实际硬件测试中，抓取成功率分别达到 72% (NICO) 和 82% (NICOL)。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Published at IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08825v2",
      "published_date": "2024-04-12 21:42:34 UTC",
      "updated_date": "2024-11-06 21:13:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:49:49.077581"
    },
    {
      "arxiv_id": "2404.10534v2",
      "title": "Into the Fog: Evaluating Robustness of Multiple Object Tracking",
      "title_zh": "进入雾中：评估多目标跟踪的鲁棒性",
      "authors": [
        "Nadezda Kirillova",
        "M. Jehanzeb Mirza",
        "Horst Bischof",
        "Horst Possegger"
      ],
      "abstract": "State-of-the-art Multiple Object Tracking (MOT) approaches have shown\nremarkable performance when trained and evaluated on current benchmarks.\nHowever, these benchmarks primarily consist of clear weather scenarios,\noverlooking adverse atmospheric conditions such as fog, haze, smoke and dust.\nAs a result, the robustness of trackers against these challenging conditions\nremains underexplored. To address this gap, we introduce physics-based\nvolumetric fog simulation method for arbitrary MOT datasets, utilizing\nframe-by-frame monocular depth estimation and a fog formation optical model. We\nenhance our simulation by rendering both homogeneous and heterogeneous fog and\npropose to use the dark channel prior method to estimate atmospheric light,\nshowing promising results even in night and indoor scenes. We present the\nleading benchmark MOTChallenge (third release) augmented with fog (smoke for\nindoor scenes) of various intensities and conduct a comprehensive evaluation of\nMOT methods, revealing their limitations under fog and fog-like challenges.",
      "tldr_zh": "本研究评估了多目标跟踪 (MOT) 方法在不利天气条件下的鲁棒性，指出现有基准主要针对晴朗场景，而忽略了雾、烟尘等挑战。论文提出了一种基于物理的体积雾模拟方法，利用单目深度估计 (monocular depth estimation) 和雾形成光学模型 (fog formation optical model)，并通过暗通道先验方法 (dark channel prior) 估计 atmospheric light，以生成均匀和非均匀雾。最终，他们增强了 MOTChallenge 基准数据集，添加各种强度的雾或烟，并对多种 MOT 方法进行全面评估，揭示了这些方法在雾类条件下的显著局限性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10534v2",
      "published_date": "2024-04-12 21:41:50 UTC",
      "updated_date": "2024-11-13 14:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:49:59.938980"
    },
    {
      "arxiv_id": "2404.10789v1",
      "title": "PASA: Attack Agnostic Unsupervised Adversarial Detection using Prediction & Attribution Sensitivity Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Dipkamal Bhusal",
        "Md Tanvirul Alam",
        "Monish K. Veerabhadran",
        "Michael Clifford",
        "Sara Rampazzi",
        "Nidhi Rastogi"
      ],
      "abstract": "Deep neural networks for classification are vulnerable to adversarial\nattacks, where small perturbations to input samples lead to incorrect\npredictions. This susceptibility, combined with the black-box nature of such\nnetworks, limits their adoption in critical applications like autonomous\ndriving. Feature-attribution-based explanation methods provide relevance of\ninput features for model predictions on input samples, thus explaining model\ndecisions. However, we observe that both model predictions and feature\nattributions for input samples are sensitive to noise. We develop a practical\nmethod for this characteristic of model prediction and feature attribution to\ndetect adversarial samples. Our method, PASA, requires the computation of two\ntest statistics using model prediction and feature attribution and can reliably\ndetect adversarial samples using thresholds learned from benign samples. We\nvalidate our lightweight approach by evaluating the performance of PASA on\nvarying strengths of FGSM, PGD, BIM, and CW attacks on multiple image and\nnon-image datasets. On average, we outperform state-of-the-art statistical\nunsupervised adversarial detectors on CIFAR-10 and ImageNet by 14\\% and 35\\%\nROC-AUC scores, respectively. Moreover, our approach demonstrates competitive\nperformance even when an adversary is aware of the defense mechanism.",
      "tldr_zh": "该研究提出PASA，一种无监督的攻击无关对抗样本检测方法，通过分析模型预测和特征归因（feature attribution）的敏感性来识别对抗攻击。PASA计算两个测试统计量，并利用从良性样本学得的阈值来检测异常样本，在多种数据集上表现出色。实验结果显示，PASA在CIFAR-10和ImageNet数据集上分别比现有统计无监督检测器提高14%和35%的ROC-AUC分数，且即使攻击者知晓防御机制，性能仍保持竞争力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "9th IEEE European Symposium on Security and Privacy",
      "pdf_url": "http://arxiv.org/pdf/2404.10789v1",
      "published_date": "2024-04-12 21:22:21 UTC",
      "updated_date": "2024-04-12 21:22:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:50:09.992202"
    },
    {
      "arxiv_id": "2404.08814v2",
      "title": "E3: Ensemble of Expert Embedders for Adapting Synthetic Image Detectors to New Generators Using Limited Data",
      "title_zh": "翻译失败",
      "authors": [
        "Aref Azizpour",
        "Tai D. Nguyen",
        "Manil Shrestha",
        "Kaidi Xu",
        "Edward Kim",
        "Matthew C. Stamm"
      ],
      "abstract": "As generative AI progresses rapidly, new synthetic image generators continue\nto emerge at a swift pace. Traditional detection methods face two main\nchallenges in adapting to these generators: the forensic traces of synthetic\nimages from new techniques can vastly differ from those learned during\ntraining, and access to data for these new generators is often limited. To\naddress these issues, we introduce the Ensemble of Expert Embedders (E3), a\nnovel continual learning framework for updating synthetic image detectors. E3\nenables the accurate detection of images from newly emerged generators using\nminimal training data. Our approach does this by first employing transfer\nlearning to develop a suite of expert embedders, each specializing in the\nforensic traces of a specific generator. Then, all embeddings are jointly\nanalyzed by an Expert Knowledge Fusion Network to produce accurate and reliable\ndetection decisions. Our experiments demonstrate that E3 outperforms existing\ncontinual learning methods, including those developed specifically for\nsynthetic image detection.",
      "tldr_zh": "这篇论文提出了 E3 框架，即 Ensemble of Expert Embedders，用于适应新合成图像生成器的检测器，解决传统方法在面对新生成器取证痕迹差异和数据有限时的挑战。E3 通过 transfer learning 开发一组专家嵌入器，每个专注于特定生成器的图像特征，然后利用 Expert Knowledge Fusion Network 联合分析这些嵌入以做出准确的检测决策。该框架实现了使用最小训练数据检测新生成器图像的核心目标，并在实验中优于现有持续学习方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 4 figures, To be published in CVPRWMF24",
      "pdf_url": "http://arxiv.org/pdf/2404.08814v2",
      "published_date": "2024-04-12 21:14:20 UTC",
      "updated_date": "2024-04-16 14:17:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:50:22.839811"
    },
    {
      "arxiv_id": "2404.08811v2",
      "title": "Reducing the Barriers to Entry for Foundation Model Training",
      "title_zh": "翻译失败",
      "authors": [
        "Paolo Faraboschi",
        "Ellis Giles",
        "Justin Hotard",
        "Konstanty Owczarek",
        "Andrew Wheeler"
      ],
      "abstract": "The world has recently witnessed an unprecedented acceleration in demands for\nMachine Learning and Artificial Intelligence applications. This spike in demand\nhas imposed tremendous strain on the underlying technology stack in supply\nchain, GPU-accelerated hardware, software, datacenter power density, and energy\nconsumption. If left on the current technological trajectory, future demands\nshow insurmountable spending trends, further limiting market players, stifling\ninnovation, and widening the technology gap. To address these challenges, we\npropose a fundamental change in the AI training infrastructure throughout the\ntechnology ecosystem. The changes require advancements in supercomputing and\nnovel AI training approaches, from high-end software to low-level hardware,\nmicroprocessor, and chip design, while advancing the energy efficiency required\nby a sustainable infrastructure. This paper presents the analytical framework\nthat quantitatively highlights the challenges and points to the opportunities\nto reduce the barriers to entry for training large language models.",
      "tldr_zh": "这篇论文讨论了机器学习和人工智能（AI）应用需求的激增，对供应链、GPU-accelerated hardware、软件、数据中心功率密度和能源消耗造成的巨大压力。如果延续当前趋势，将导致支出激增、市场参与者减少、创新受阻和技术差距扩大。为应对这些挑战，论文提出通过变革AI训练基础设施，包括超级计算（supercomputing）和新型AI训练方法，从高端软件到低级硬件及芯片设计，同时提升能源效率。论文提供了一个分析框架，量化这些问题并指出机会，以降低训练基础模型（Foundation Model）的进入壁垒，促进更广泛的创新和发展。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08811v2",
      "published_date": "2024-04-12 20:58:25 UTC",
      "updated_date": "2024-10-14 17:03:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:50:35.601070"
    },
    {
      "arxiv_id": "2404.14418v1",
      "title": "Mitigating Cascading Effects in Large Adversarial Graph Environments",
      "title_zh": "翻译失败",
      "authors": [
        "James D. Cunningham",
        "Conrad S. Tucker"
      ],
      "abstract": "A significant amount of society's infrastructure can be modeled using graph\nstructures, from electric and communication grids, to traffic networks, to\nsocial networks. Each of these domains are also susceptible to the cascading\nspread of negative impacts, whether this be overloaded devices in the power\ngrid or the reach of a social media post containing misinformation. The\npotential harm of a cascade is compounded when considering a malicious attack\nby an adversary that is intended to maximize the cascading impact. However, by\nexploiting knowledge of the cascading dynamics, targets with the largest\ncascading impact can be preemptively prioritized for defense, and the damage an\nadversary can inflict can be mitigated. While game theory provides tools for\nfinding an optimal preemptive defense strategy, existing methods struggle to\nscale to the context of large graph environments because of the combinatorial\nexplosion of possible actions that occurs when the attacker and defender can\neach choose multiple targets in the graph simultaneously. The proposed method\nenables a data-driven deep learning approach that uses multi-node\nrepresentation learning and counterfactual data augmentation to generalize to\nthe full combinatorial action space by training on a variety of small\nrestricted subsets of the action space. We demonstrate through experiments that\nthe proposed method is capable of identifying defense strategies that are less\nexploitable than SOTA methods for large graphs, while still being able to\nproduce strategies near the Nash equilibrium for small-scale scenarios for\nwhich it can be computed. Moreover, the proposed method demonstrates superior\nprediction accuracy on a validation set of unseen cascades compared to other\ndeep learning approaches.",
      "tldr_zh": "这篇论文针对大型对抗图环境（如电网或社会网络）中的级联效应提出缓解策略，旨在防御恶意攻击放大负面影响，如信息传播或系统过载。作者采用数据驱动的深度学习方法，包括多节点表示学习和反事实数据增强，通过在小规模子集上训练来泛化到完整的组合行动空间，从而克服现有游戏理论方法的扩展性问题。实验结果表明，该方法能识别出比SOTA方法更不易被利用的防御策略，并在小规模场景中接近Nash equilibrium；此外，它在预测未见级联上的准确率superior于其他深度学习方法。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.SI",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.14418v1",
      "published_date": "2024-04-12 20:23:02 UTC",
      "updated_date": "2024-04-12 20:23:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:50:48.747989"
    },
    {
      "arxiv_id": "2404.08799v1",
      "title": "Semantic Approach to Quantifying the Consistency of Diffusion Model Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Brinnae Bent"
      ],
      "abstract": "In this study, we identify the need for an interpretable, quantitative score\nof the repeatability, or consistency, of image generation in diffusion models.\nWe propose a semantic approach, using a pairwise mean CLIP (Contrastive\nLanguage-Image Pretraining) score as our semantic consistency score. We applied\nthis metric to compare two state-of-the-art open-source image generation\ndiffusion models, Stable Diffusion XL and PixArt-{\\alpha}, and we found\nstatistically significant differences between the semantic consistency scores\nfor the models. Agreement between the Semantic Consistency Score selected model\nand aggregated human annotations was 94%. We also explored the consistency of\nSDXL and a LoRA-fine-tuned version of SDXL and found that the fine-tuned model\nhad significantly higher semantic consistency in generated images. The Semantic\nConsistency Score proposed here offers a measure of image generation alignment,\nfacilitating the evaluation of model architectures for specific tasks and\naiding in informed decision-making regarding model selection.",
      "tldr_zh": "本研究针对扩散模型图像生成的重复性（consistency）问题，提出了一种语义方法，使用成对的均值 CLIP 评分作为语义一致性分数，以提供可解释的量化指标。实验比较了 Stable Diffusion XL 和 PixArt-α 模型，发现二者在语义一致性上存在统计显著差异，且该分数与人类标注的同意率达 94%。此外，研究还发现，SDXL 的 LoRA 微调版本在生成图像的一致性上显著提升。该方法有助于评估模型架构的图像生成对齐度，支持任务特定决策和模型选择。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to 2024 CVPR 3rd Explainable AI for Computer Vision (XAI4CV)\n  Workshop",
      "pdf_url": "http://arxiv.org/pdf/2404.08799v1",
      "published_date": "2024-04-12 20:16:03 UTC",
      "updated_date": "2024-04-12 20:16:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:50:59.289369"
    },
    {
      "arxiv_id": "2404.10788v1",
      "title": "The Path To Autonomous Cyber Defense",
      "title_zh": "通往自主网络防御的路径",
      "authors": [
        "Sean Oesch",
        "Phillipe Austria",
        "Amul Chaulagain",
        "Brian Weber",
        "Cory Watson",
        "Matthew Dixson",
        "Amir Sadovnik"
      ],
      "abstract": "Defenders are overwhelmed by the number and scale of attacks against their\nnetworks.This problem will only be exacerbated as attackers leverage artificial\nintelligence to automate their workflows. We propose a path to autonomous cyber\nagents able to augment defenders by automating critical steps in the cyber\ndefense life cycle.",
      "tldr_zh": "网络防御者正面临着大量攻击的数量和规模所带来的巨大压力，而攻击者利用 artificial intelligence 自动化工作流程会进一步加剧这一问题。  \n本文提出一条通往自主网络代理的路径，这些代理能够增强防御者的能力，通过自动化网络防御生命周期中的关键步骤。  \n这一方法旨在帮助防御者应对自动化威胁，提高整体网络安全效率。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10788v1",
      "published_date": "2024-04-12 19:51:45 UTC",
      "updated_date": "2024-04-12 19:51:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:51:11.197494"
    },
    {
      "arxiv_id": "2404.08791v2",
      "title": "Expectation Alignment: Handling Reward Misspecification in the Presence of Expectation Mismatch",
      "title_zh": "翻译失败",
      "authors": [
        "Malek Mechergui",
        "Sarath Sreedharan"
      ],
      "abstract": "Detecting and handling misspecified objectives, such as reward functions, has\nbeen widely recognized as one of the central challenges within the domain of\nArtificial Intelligence (AI) safety research. However, even with the\nrecognition of the importance of this problem, we are unaware of any works that\nattempt to provide a clear definition for what constitutes (a) misspecified\nobjectives and (b) successfully resolving such misspecifications. In this work,\nwe use the theory of mind, i.e., the human user's beliefs about the AI agent,\nas a basis to develop a formal explanatory framework called Expectation\nAlignment (EAL) to understand the objective misspecification and its causes.\nOur EAL framework not only acts as an explanatory framework for existing works\nbut also provides us with concrete insights into the limitations of existing\nmethods to handle reward misspecification and novel solution strategies. We use\nthese insights to propose a new interactive algorithm that uses the specified\nreward to infer potential user expectations about the system behavior. We show\nhow one can efficiently implement this algorithm by mapping the inference\nproblem into linear programs. We evaluate our method on a set of standard\nMarkov Decision Process (MDP) benchmarks.",
      "tldr_zh": "本文提出Expectation Alignment (EAL)框架，利用theory of mind（人类对AI代理的信念）来正式定义和解释reward misspecification问题及其成因。EAL框架不仅分析了现有方法的局限性，还提供新见解，并引入一个交互式算法，通过指定的奖励函数推断用户对系统行为的期望，并将其映射到线性程序中进行高效实现。在标准Markov Decision Process (MDP)基准上评估显示，该方法有效处理了期望不匹配问题，提升了AI安全目标的处理能力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08791v2",
      "published_date": "2024-04-12 19:43:37 UTC",
      "updated_date": "2024-10-31 02:34:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:51:24.760854"
    },
    {
      "arxiv_id": "2404.08789v1",
      "title": "Differentiable and Stable Long-Range Tracking of Multiple Posterior Modes",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Younis",
        "Erik Sudderth"
      ],
      "abstract": "Particle filters flexibly represent multiple posterior modes\nnonparametrically, via a collection of weighted samples, but have classically\nbeen applied to tracking problems with known dynamics and observation\nlikelihoods. Such generative models may be inaccurate or unavailable for\nhigh-dimensional observations like images. We instead leverage training data to\ndiscriminatively learn particle-based representations of uncertainty in latent\nobject states, conditioned on arbitrary observations via deep neural network\nencoders. While prior discriminative particle filters have used heuristic\nrelaxations of discrete particle resampling, or biased learning by truncating\ngradients at resampling steps, we achieve unbiased and low-variance gradient\nestimates by representing posteriors as continuous mixture densities. Our\ntheory and experiments expose dramatic failures of existing\nreparameterization-based estimators for mixture gradients, an issue we address\nvia an importance-sampling gradient estimator. Unlike standard recurrent neural\nnetworks, our mixture density particle filter represents multimodal uncertainty\nin continuous latent states, improving accuracy and robustness. On a range of\nchallenging tracking and robot localization problems, our approach achieves\ndramatic improvements in accuracy, while also showing much greater stability\nacross multiple training runs.",
      "tldr_zh": "该论文提出了一种可微且稳定的长程多后验模式（posterior modes）跟踪方法，通过判别学习和深度神经网络编码器，利用训练数据来表示基于粒子的不确定性（particle filters），以处理高维观测如图像的挑战。不同于以往的启发式松弛或偏置学习，该方法将后验表示为连续混合密度（mixture densities），并采用重要性采样梯度估计器（importance-sampling gradient estimator）来实现无偏低方差梯度估计，从而避免了现有重参数化估计器（reparameterization-based estimators）的失败。实验结果显示，该方法在各种跟踪和机器人定位任务上显著提高了准确性和鲁棒性，并展现出更稳定的训练性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Neurips 2023",
      "pdf_url": "http://arxiv.org/pdf/2404.08789v1",
      "published_date": "2024-04-12 19:33:52 UTC",
      "updated_date": "2024-04-12 19:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:51:37.457989"
    },
    {
      "arxiv_id": "2404.19675v1",
      "title": "Deep Learning for Educational Data Science",
      "title_zh": "翻译失败",
      "authors": [
        "Juan D. Pinto",
        "Luc Paquette"
      ],
      "abstract": "With the ever-growing presence of deep artificial neural networks in every\nfacet of modern life, a growing body of researchers in educational data science\n-- a field consisting of various interrelated research communities -- have\nturned their attention to leveraging these powerful algorithms within the\ndomain of education. Use cases range from advanced knowledge tracing models\nthat can leverage open-ended student essays or snippets of code to automatic\naffect and behavior detectors that can identify when a student is frustrated or\naimlessly trying to solve problems unproductively -- and much more. This\nchapter provides a brief introduction to deep learning, describes some of its\nadvantages and limitations, presents a survey of its many uses in education,\nand discusses how it may further come to shape the field of educational data\nscience.",
      "tldr_zh": "这篇论文探讨了深度学习在教育数据科学领域的应用，介绍了深度学习的原理、优势（如处理复杂数据的能力）和局限性（如数据需求高）。论文调研了深度学习的多项教育用例，包括先进的知识追踪模型（能分析学生作文或代码）和自动情感行为检测（如识别学生沮丧或无效问题解决）。最终，它讨论了深度学习如何进一步影响教育数据科学，推动更智能化的教育工具发展。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "18 pages. To be published in Trust and Inclusion in AI-Mediated\n  Education: Where Human Learning Meets Learning Machines by Springer\n  International",
      "pdf_url": "http://arxiv.org/pdf/2404.19675v1",
      "published_date": "2024-04-12 19:17:14 UTC",
      "updated_date": "2024-04-12 19:17:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:51:47.382958"
    },
    {
      "arxiv_id": "2404.08786v4",
      "title": "NeuroLGP-SM: Scalable Surrogate-Assisted Neuroevolution for Deep Neural Networks",
      "title_zh": "NeuroLGP-SM：用于深度神经网络的可扩展代理辅助神经进化",
      "authors": [
        "Fergal Stapleton",
        "Edgar Galván"
      ],
      "abstract": "Evolutionary Algorithms (EAs) play a crucial role in the architectural\nconfiguration and training of Artificial Deep Neural Networks (DNNs), a process\nknown as neuroevolution. However, neuroevolution is hindered by its inherent\ncomputational expense, requiring multiple generations, a large population, and\nnumerous epochs. The most computationally intensive aspect lies in evaluating\nthe fitness function of a single candidate solution. To address this challenge,\nwe employ Surrogate-assisted EAs (SAEAs). While a few SAEAs approaches have\nbeen proposed in neuroevolution, none have been applied to truly large DNNs due\nto issues like intractable information usage. In this work, drawing inspiration\nfrom Genetic Programming semantics, we use phenotypic distance vectors,\noutputted from DNNs, alongside Kriging Partial Least Squares (KPLS), an\napproach that is effective in handling these large vectors, making them\nsuitable for search. Our proposed approach, named Neuro-Linear Genetic\nProgramming surrogate model (NeuroLGP-SM), efficiently and accurately estimates\nDNN fitness without the need for complete evaluations. NeuroLGP-SM demonstrates\ncompetitive or superior results compared to 12 other methods, including\nNeuroLGP without SM, convolutional neural networks, support vector machines,\nand autoencoders. Additionally, it is worth noting that NeuroLGP-SM is 25% more\nenergy-efficient than its NeuroLGP counterpart. This efficiency advantage adds\nto the overall appeal of our proposed NeuroLGP-SM in optimising the\nconfiguration of large DNNs.",
      "tldr_zh": "该研究针对神经演化（neuroevolution）中评估深度神经网络（DNNs）的适应度函数计算开销大的问题，提出了一种可扩展的代理辅助进化算法（SAEAs）方法，名为 NeuroLGP-SM。方法借鉴遗传编程语义，使用表型距离向量和 Kriging Partial Least Squares (KPLS) 来高效处理大型向量，从而无需完整评估即可准确估计 DNN 的适应度。与其他 12 种方法相比，NeuroLGP-SM 表现出竞争性或优越性能，且比 NeuroLGP 节省 25% 的能源，显著提升了大型 DNN 配置优化的效率。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "published in IEEE Congress on Evolutionary Computation (CEC) (CEC\n  2024), Yokohama, Japan, 8 pages, 5 figures, 2 tables (EDIT: added DOI)",
      "pdf_url": "http://arxiv.org/pdf/2404.08786v4",
      "published_date": "2024-04-12 19:15:38 UTC",
      "updated_date": "2024-09-16 13:48:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:52:00.179076"
    },
    {
      "arxiv_id": "2404.08760v4",
      "title": "The Generation Gap: Exploring Age Bias in the Value Systems of Large Language Models",
      "title_zh": "代沟：探索大型语言模型价值系统中的年龄偏见",
      "authors": [
        "Siyang Liu",
        "Trish Maturi",
        "Bowen Yi",
        "Siqi Shen",
        "Rada Mihalcea"
      ],
      "abstract": "We explore the alignment of values in Large Language Models (LLMs) with\nspecific age groups, leveraging data from the World Value Survey across\nthirteen categories. Through a diverse set of prompts tailored to ensure\nresponse robustness, we find a general inclination of LLM values towards\nyounger demographics, especially when compared to the US population. Although a\ngeneral inclination can be observed, we also found that this inclination toward\nyounger groups can be different across different value categories.\nAdditionally, we explore the impact of incorporating age identity information\nin prompts and observe challenges in mitigating value discrepancies with\ndifferent age cohorts. Our findings highlight the age bias in LLMs and provide\ninsights for future work. Materials for our analysis are available at \\url{\nhttps://github.com/MichiganNLP/Age-Bias-In-LLMs}",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 的价值系统与不同年龄群体的对齐问题，使用 World Value Survey 的数据覆盖十三类价值观，通过多样化提示确保响应鲁棒性。结果显示，LLMs 的价值倾向于年轻群体，尤其是与美国人口相比，这种偏见在不同价值类别中表现不一。研究进一步测试了在提示中加入年龄身份信息的影响，但发现无法有效缓解与各年龄群体的价值差异，并为未来缓解年龄偏见的工作提供了宝贵见解和分析资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.08760v4",
      "published_date": "2024-04-12 18:36:20 UTC",
      "updated_date": "2024-10-15 09:10:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:52:12.035785"
    },
    {
      "arxiv_id": "2404.08755v1",
      "title": "Training a Vision Language Model as Smartphone Assistant",
      "title_zh": "将视觉语言模型训练为智能手机助手",
      "authors": [
        "Nicolai Dorka",
        "Janusz Marecki",
        "Ammar Anwar"
      ],
      "abstract": "Addressing the challenge of a digital assistant capable of executing a wide\narray of user tasks, our research focuses on the realm of instruction-based\nmobile device control. We leverage recent advancements in large language models\n(LLMs) and present a visual language model (VLM) that can fulfill diverse tasks\non mobile devices. Our model functions by interacting solely with the user\ninterface (UI). It uses the visual input from the device screen and mimics\nhuman-like interactions, encompassing gestures such as tapping and swiping.\nThis generality in the input and output space allows our agent to interact with\nany application on the device. Unlike previous methods, our model operates not\nonly on a single screen image but on vision-language sentences created from\nsequences of past screenshots along with corresponding actions. Evaluating our\nmethod on the challenging Android in the Wild benchmark demonstrates its\npromising efficacy and potential.",
      "tldr_zh": "这篇论文提出了一种训练视觉语言模型(VLM)作为智能手机助手的框架，旨在处理基于指令的移动设备控制任务，利用大型语言模型(LLMs)的最新进展。模型通过设备屏幕的视觉输入和序列截图生成的视觉-语言句子来模仿人类交互，如点击和滑动，从而适用于任何应用程序。不同于以往仅处理单一屏幕图像的方法，该框架强调序列数据以提升任务泛化能力。在Android in the Wild基准上的评估结果显示，该方法表现出色，具有显著的实际应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024 workshop on Generative Models for Decision Making",
      "pdf_url": "http://arxiv.org/pdf/2404.08755v1",
      "published_date": "2024-04-12 18:28:44 UTC",
      "updated_date": "2024-04-12 18:28:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:52:25.184887"
    },
    {
      "arxiv_id": "2404.08747v1",
      "title": "Observation-specific explanations through scattered data approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Valentina Ghidini",
        "Michael Multerer",
        "Jacopo Quizi",
        "Rohan Sen"
      ],
      "abstract": "This work introduces the definition of observation-specific explanations to\nassign a score to each data point proportional to its importance in the\ndefinition of the prediction process. Such explanations involve the\nidentification of the most influential observations for the black-box model of\ninterest. The proposed method involves estimating these explanations by\nconstructing a surrogate model through scattered data approximation utilizing\nthe orthogonal matching pursuit algorithm. The proposed approach is validated\non both simulated and real-world datasets.",
      "tldr_zh": "该论文引入了observation-specific explanations的概念，用于为每个数据点分配一个分数，以反映其在预测过程中的重要性，从而识别对black-box model最有影响的观察。方法通过scattered data approximation和orthogonal matching pursuit algorithm构建surrogate model来估算这些解释。实验在模拟和真实数据集上验证了该方法的有效性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08747v1",
      "published_date": "2024-04-12 18:20:26 UTC",
      "updated_date": "2024-04-12 18:20:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:52:36.681735"
    },
    {
      "arxiv_id": "2404.08634v2",
      "title": "Inheritune: Training Smaller Yet More Attentive Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sunny Sanyal",
        "Ravid Shwartz-Ziv",
        "Alexandros G. Dimakis",
        "Sujay Sanghavi"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable performance across\nvarious natural language processing tasks, primarily due to the transformer\narchitecture and its self-attention mechanism. However, we observe that in\nstandard decoder-style LLMs, attention matrices degenerate to single-column for\ndeeper layers. Layers in this state are unable to learn anything meaningful and\nmostly redundant; we refer to these as lazy layers. The goal of this paper is\nto train smaller models by eliminating this structural inefficiency without\ncompromising performance.\n  Motivated by this observation, we propose Inheritune, a simple yet effective\ntraining recipe for developing smaller, high-performing language models.\nSmaller models trained with Inheritune, inherit early transformer layers from a\nlarger pre-trained model, then retrain and progressively expand until they\nmatch or exceed the performance of the larger model. We demonstrate that\nInheritune enables the training of various sizes of GPT-2 models on datasets\nlike OpenWebText-9B and FineWeb_edu. Models trained with Inheritune, despite\nhaving significantly fewer layers, match or even surpass the performance of\ntheir larger counterparts. For instance, our 16-layer GPT-2 medium variant\nachieves comparable performance to the standard 24-layer GPT-2 medium model.\nCode is available at https://github.com/sanyalsunny111/LLM-Inheritune.",
      "tldr_zh": "这篇论文观察到标准 Large Language Models (LLMs) 中的自注意力(self-attention)机制在深层退化，导致“lazy layers”无法有效学习，从而造成结构性低效。作者提出 Inheritune 方法，通过从更大预训练模型继承早期 transformer 层，然后重新训练并逐步扩展，来训练更小却性能更强的模型。该方法在 OpenWebText-9B 和 FineWeb_edu 数据集上验证，显示训练的 16 层 GPT-2 medium 模型可与标准 24 层模型匹敌或超越，显著提高了模型效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 13 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.08634v2",
      "published_date": "2024-04-12 17:53:34 UTC",
      "updated_date": "2024-10-04 05:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:52:52.042839"
    },
    {
      "arxiv_id": "2404.08630v1",
      "title": "A Conceptual Framework for Conversational Search and Recommendation: Conceptualizing Agent-Human Interactions During the Conversational Search Process",
      "title_zh": "翻译失败",
      "authors": [
        "Leif Azzopardi",
        "Mateusz Dubiel",
        "Martin Halvey",
        "Jeffery Dalton"
      ],
      "abstract": "The conversational search task aims to enable a user to resolve information\nneeds via natural language dialogue with an agent. In this paper, we aim to\ndevelop a conceptual framework of the actions and intents of users and agents\nexplaining how these actions enable the user to explore the search space and\nresolve their information need. We outline the different actions and intents,\nbefore discussing key decision points in the conversation where the agent needs\nto decide how to steer the conversational search process to a successful and/or\nsatisfactory conclusion. Essentially, this paper provides a conceptualization\nof the conversational search process between an agent and user, which provides\na framework and a starting point for research, development and evaluation of\nconversational search agents.",
      "tldr_zh": "该论文提出一个概念框架，用于理解对话式搜索(Conversational Search)中的用户和代理互动，旨在解释这些互动如何帮助用户探索搜索空间并解决信息需求。框架详细概述了用户和代理的动作(actions)和意图(intents)，并讨论了对话过程中的关键决策点，例如代理如何引导对话以实现成功或满意的结果。通过这种概念化，该框架为对话式搜索代理的研究、开发和评估提供了一个基础和起点。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08630v1",
      "published_date": "2024-04-12 17:48:18 UTC",
      "updated_date": "2024-04-12 17:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:53:02.095642"
    },
    {
      "arxiv_id": "2404.08627v2",
      "title": "Is ChatGPT Transforming Academics' Writing Style?",
      "title_zh": "翻译失败",
      "authors": [
        "Mingmeng Geng",
        "Roberto Trotta"
      ],
      "abstract": "Based on one million arXiv papers submitted from May 2018 to January 2024, we\nassess the textual density of ChatGPT's writing style in their abstracts\nthrough a statistical analysis of word frequency changes. Our model is\ncalibrated and validated on a mixture of real abstracts and ChatGPT-modified\nabstracts (simulated data) after a careful noise analysis. The words used for\nestimation are not fixed but adaptive, including those with decreasing\nfrequency. We find that large language models (LLMs), represented by ChatGPT,\nare having an increasing impact on arXiv abstracts, especially in the field of\ncomputer science, where the fraction of LLM-style abstracts is estimated to be\napproximately 35%, if we take the responses of GPT-3.5 to one simple prompt,\n\"revise the following sentences\", as a baseline. We conclude with an analysis\nof both positive and negative aspects of the penetration of LLMs into\nacademics' writing style.",
      "tldr_zh": "本研究基于2018年5月至2024年1月的100万篇arXiv论文，通过统计词频变化分析ChatGPT写作风格在摘要中的影响，采用自适应词语模型并在真实和模拟数据上校准验证。结果显示，大语言模型（LLMs）如ChatGPT对arXiv摘要的影响日益显著，尤其在计算机科学领域，估计约35%的摘要受LLMs影响，以GPT-3.5对“revise the following sentences”提示的响应为基准。论文进一步讨论了LLMs渗透学术写作的积极（如提升效率）和消极（如潜在的非原创性）方面，为评估AI在学术领域的角色提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.08627v2",
      "published_date": "2024-04-12 17:41:05 UTC",
      "updated_date": "2024-11-08 18:56:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:53:15.010869"
    },
    {
      "arxiv_id": "2404.08611v2",
      "title": "Automatic Quantification of Serial PET/CT Images for Pediatric Hodgkin Lymphoma Patients Using a Longitudinally-Aware Segmentation Network",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Tie",
        "Muheon Shin",
        "Changhee Lee",
        "Scott B. Perlman",
        "Zachary Huemann",
        "Amy J. Weisman",
        "Sharon M. Castellino",
        "Kara M. Kelly",
        "Kathleen M. McCarten",
        "Adina L. Alazraki",
        "Junjie Hu",
        "Steve Y. Cho",
        "Tyler J. Bradshaw"
      ],
      "abstract": "$\\textbf{Purpose}$: Automatic quantification of longitudinal changes in PET\nscans for lymphoma patients has proven challenging, as residual disease in\ninterim-therapy scans is often subtle and difficult to detect. Our goal was to\ndevelop a longitudinally-aware segmentation network (LAS-Net) that can quantify\nserial PET/CT images for pediatric Hodgkin lymphoma patients.\n$\\textbf{Materials and Methods}$: This retrospective study included baseline\n(PET1) and interim (PET2) PET/CT images from 297 patients enrolled in two\nChildren's Oncology Group clinical trials (AHOD1331 and AHOD0831). LAS-Net\nincorporates longitudinal cross-attention, allowing relevant features from PET1\nto inform the analysis of PET2. Model performance was evaluated using Dice\ncoefficients for PET1 and detection F1 scores for PET2. Additionally, we\nextracted and compared quantitative PET metrics, including metabolic tumor\nvolume (MTV) and total lesion glycolysis (TLG) in PET1, as well as qPET and\n$\\Delta$SUVmax in PET2, against physician measurements. We quantified their\nagreement using Spearman's $\\rho$ correlations and employed bootstrap\nresampling for statistical analysis. $\\textbf{Results}$: LAS-Net detected\nresidual lymphoma in PET2 with an F1 score of 0.606 (precision/recall:\n0.615/0.600), outperforming all comparator methods (P<0.01). For baseline\nsegmentation, LAS-Net achieved a mean Dice score of 0.772. In PET\nquantification, LAS-Net's measurements of qPET, $\\Delta$SUVmax, MTV and TLG\nwere strongly correlated with physician measurements, with Spearman's $\\rho$ of\n0.78, 0.80, 0.93 and 0.96, respectively. The performance remained high, with a\nslight decrease, in an external testing cohort. $\\textbf{Conclusion}$: LAS-Net\ndemonstrated significant improvements in quantifying PET metrics across serial\nscans, highlighting the value of longitudinal awareness in evaluating\nmulti-time-point imaging datasets.",
      "tldr_zh": "本研究开发了纵向感知分割网络（LAS-Net），旨在自动量化儿童霍奇金淋巴瘤患者连续 PET/CT 图像中的纵向变化，特别是检测中期扫描的残留病变。LAS-Net 通过纵向交叉注意力机制整合基线（PET1）和中期（PET2）图像特征，并使用 Dice 系数和 F1 分数等指标评估模型性能，同时与医生测量比较量化指标如 MTV、TLG、qPET 和 ΔSUVmax。结果显示，LAS-Net 在 PET2 残留淋巴瘤检测上 F1 分数达 0.606（精确率/召回率：0.615/0.600），优于其他方法，且量化指标与医生测量高度相关，Spearman's ρ 分别为 0.78、0.80、0.93 和 0.96。在外部测试队列中性能保持稳定。该框架突出了纵向感知在多时间点图像评估中的重要价值，为临床量化提供可靠工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "cs.CV",
      "comment": "There are 6 figures and 4 tables in the main text. The supplementary\n  material is appended to the main text",
      "pdf_url": "http://arxiv.org/pdf/2404.08611v2",
      "published_date": "2024-04-12 17:20:57 UTC",
      "updated_date": "2024-10-01 00:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:53:28.123107"
    },
    {
      "arxiv_id": "2404.08727v1",
      "title": "Can LLMs substitute SQL? Comparing Resource Utilization of Querying LLMs versus Traditional Relational Databases",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Zhang",
        "Khatoon Khedri",
        "Reza Rawassizadeh"
      ],
      "abstract": "Large Language Models (LLMs) can automate or substitute different types of\ntasks in the software engineering process. This study evaluates the resource\nutilization and accuracy of LLM in interpreting and executing natural language\nqueries against traditional SQL within relational database management systems.\nWe empirically examine the resource utilization and accuracy of nine LLMs\nvarying from 7 to 34 Billion parameters, including Llama2 7B, Llama2 13B,\nMistral, Mixtral, Optimus-7B, SUS-chat-34B, platypus-yi-34b,\nNeuralHermes-2.5-Mistral-7B and Starling-LM-7B-alpha, using a small transaction\ndataset. Our findings indicate that using LLMs for database queries incurs\nsignificant energy overhead (even small and quantized models), making it an\nenvironmentally unfriendly approach. Therefore, we advise against replacing\nrelational databases with LLMs due to their substantial resource utilization.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 是否能取代传统 SQL 在数据库查询中的作用，重点比较了资源利用率和准确性。研究通过实证测试 9 个不同规模的 LLMs（如 Llama2 7B、Mistral 和 SUS-chat-34B），使用一个小事务数据集进行自然语言查询实验。结果显示，LLMs 即使是小型量化模型也带来显著能源开销，导致环境影响较大，因此不推荐用 LLMs 替换关系数据库。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "68-04",
        "H.2.m"
      ],
      "primary_category": "cs.DB",
      "comment": "13 pages, 2 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.08727v1",
      "published_date": "2024-04-12 16:44:28 UTC",
      "updated_date": "2024-04-12 16:44:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:53:38.463300"
    },
    {
      "arxiv_id": "2404.08590v2",
      "title": "Vision-Aware Text Features in Referring Image Segmentation: From Object Understanding to Context Understanding",
      "title_zh": "视觉感知文本特征在指称图像分割中的应用：从对象理解到上下文理解",
      "authors": [
        "Hai Nguyen-Truong",
        "E-Ro Nguyen",
        "Tuan-Anh Vu",
        "Minh-Triet Tran",
        "Binh-Son Hua",
        "Sai-Kit Yeung"
      ],
      "abstract": "Referring image segmentation is a challenging task that involves generating\npixel-wise segmentation masks based on natural language descriptions. The\ncomplexity of this task increases with the intricacy of the sentences provided.\nExisting methods have relied mostly on visual features to generate the\nsegmentation masks while treating text features as supporting components.\nHowever, this under-utilization of text understanding limits the model's\ncapability to fully comprehend the given expressions. In this work, we propose\na novel framework that specifically emphasizes object and context comprehension\ninspired by human cognitive processes through Vision-Aware Text Features.\nFirstly, we introduce a CLIP Prior module to localize the main object of\ninterest and embed the object heatmap into the query initialization process.\nSecondly, we propose a combination of two components: Contextual Multimodal\nDecoder and Meaning Consistency Constraint, to further enhance the coherent and\nconsistent interpretation of language cues with the contextual understanding\nobtained from the image. Our method achieves significant performance\nimprovements on three benchmark datasets RefCOCO, RefCOCO+ and G-Ref. Project\npage: \\url{https://vatex.hkustvgd.com/}.",
      "tldr_zh": "本文针对 Referring Image Segmentation 任务，提出了一种新框架，利用 Vision-Aware Text Features 来提升文本理解从对象到上下文的认知过程。框架首先引入 CLIP Prior module 来定位主要对象并将对象热图嵌入查询初始化过程，其次结合 Contextual Multimodal Decoder 和 Meaning Consistency Constraint，确保语言提示与图像上下文的连贯解释。相比现有方法，该方法更充分地利用文本特征，改善了模型对复杂句子的处理能力。实验在 RefCOCO, RefCOCO+ 和 G-Ref 数据集上实现了显著性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper is accepted in WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.08590v2",
      "published_date": "2024-04-12 16:38:48 UTC",
      "updated_date": "2024-11-04 05:43:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:53:51.076606"
    },
    {
      "arxiv_id": "2404.08589v1",
      "title": "Enhancing Visual Question Answering through Question-Driven Image Captions as Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Övgü Özdemir",
        "Erdem Akagündüz"
      ],
      "abstract": "Visual question answering (VQA) is known as an AI-complete task as it\nrequires understanding, reasoning, and inferring about the vision and the\nlanguage content. Over the past few years, numerous neural architectures have\nbeen suggested for the VQA problem. However, achieving success in zero-shot VQA\nremains a challenge due to its requirement for advanced generalization and\nreasoning skills. This study explores the impact of incorporating image\ncaptioning as an intermediary process within the VQA pipeline. Specifically, we\nexplore the efficacy of utilizing image captions instead of images and\nleveraging large language models (LLMs) to establish a zero-shot setting. Since\nimage captioning is the most crucial step in this process, we compare the\nimpact of state-of-the-art image captioning models on VQA performance across\nvarious question types in terms of structure and semantics. We propose a\nstraightforward and efficient question-driven image captioning approach within\nthis pipeline to transfer contextual information into the question-answering\n(QA) model. This method involves extracting keywords from the question,\ngenerating a caption for each image-question pair using the keywords, and\nincorporating the question-driven caption into the LLM prompt. We evaluate the\nefficacy of using general-purpose and question-driven image captions in the VQA\npipeline. Our study highlights the potential of employing image captions and\nharnessing the capabilities of LLMs to achieve competitive performance on GQA\nunder the zero-shot setting. Our code is available at\n\\url{https://github.com/ovguyo/captions-in-VQA}.",
      "tldr_zh": "这篇论文探讨了通过问题驱动的图像描述作为提示来提升视觉问答（VQA）性能的方法，特别是针对零样本（zero-shot）设置的挑战。研究者提出了一种管道，将图像描述作为中间过程，使用大型语言模型（LLMs）进行问答，并比较了不同图像描述模型对各种问题类型的影响。具体而言，该方法从问题中提取关键词，生成针对图像-问题对的描述，并将其整合到LLMs提示中。实验结果显示，这种问答驱动的图像描述在GQA数据集上实现了竞争性的零样本性能，证明了其在提升VQA泛化性和推理能力方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The paper has been accepted for presentation at CVPR 2024 Workshop on\n  Prompting in Vision",
      "pdf_url": "http://arxiv.org/pdf/2404.08589v1",
      "published_date": "2024-04-12 16:35:23 UTC",
      "updated_date": "2024-04-12 16:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:54:01.983772"
    },
    {
      "arxiv_id": "2404.08726v1",
      "title": "An Integrated Toolbox for Creating Neuromorphic Edge Applications",
      "title_zh": "用于创建神经形态边缘应用的集成工具箱",
      "authors": [
        "Lars Niedermeier",
        "Jeffrey L. Krichmar"
      ],
      "abstract": "Spiking Neural Networks (SNNs) and neuromorphic models are more efficient and\nhave more biological realism than the activation functions typically used in\ndeep neural networks, transformer models and generative AI. SNNs have local\nlearning rules, are able to learn on small data sets, and can adapt through\nneuromodulation. Although research has shown their advantages, there are still\nfew compelling practical applications, especially at the edge where sensors and\nactuators need to be processed in a timely fashion. One reason for this might\nbe that SNNs are much more challenging to understand, build, and operate due to\ntheir intrinsic properties. For instance, the mathematical foundation involves\ndifferential equations rather than basic activation functions. To address these\nchallenges, we have developed CARLsim++. It is an integrated toolbox that\nenables fast and easy creation of neuromorphic applications. It encapsulates\nthe mathematical intrinsics and low-level C++ programming by providing a\ngraphical user interface for users who do not have a background in software\nengineering but still want to create neuromorphic models. Developers can easily\nconfigure inputs and outputs to devices and robots. These can be accurately\nsimulated before deploying on physical devices. CARLsim++ can lead to rapid\ndevelopment of neuromorphic applications for simulation or edge processing.",
      "tldr_zh": "本研究强调了Spiking Neural Networks (SNNs) 和neuromorphic models的优点，包括比传统深度神经网络更高效、更具生物真实性，以及本地学习规则和小数据集适应能力，但它们在边缘计算应用中面临理解和构建的挑战，如涉及微分方程。针对这些问题，论文开发了CARLsim++，一个集成工具箱，提供图形用户界面，让非软件工程背景的用户能轻松创建neuromorphic模型，并配置输入输出到设备和机器人。CARLsim++支持准确模拟后部署到物理设备，有助于加速neuromorphic应用的开发，用于边缘处理和模拟场景。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "8 pages, 5 figures, NICE 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08726v1",
      "published_date": "2024-04-12 16:34:55 UTC",
      "updated_date": "2024-04-12 16:34:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:54:14.004365"
    },
    {
      "arxiv_id": "2404.08582v1",
      "title": "FashionFail: Addressing Failure Cases in Fashion Object Detection and Segmentation",
      "title_zh": "FashionFail: 解决时尚物体检测和分割中的失败案例",
      "authors": [
        "Riza Velioglu",
        "Robin Chan",
        "Barbara Hammer"
      ],
      "abstract": "In the realm of fashion object detection and segmentation for online shopping\nimages, existing state-of-the-art fashion parsing models encounter limitations,\nparticularly when exposed to non-model-worn apparel and close-up shots. To\naddress these failures, we introduce FashionFail; a new fashion dataset with\ne-commerce images for object detection and segmentation. The dataset is\nefficiently curated using our novel annotation tool that leverages recent\nfoundation models. The primary objective of FashionFail is to serve as a test\nbed for evaluating the robustness of models. Our analysis reveals the\nshortcomings of leading models, such as Attribute-Mask R-CNN and Fashionformer.\nAdditionally, we propose a baseline approach using naive data augmentation to\nmitigate common failure cases and improve model robustness. Through this work,\nwe aim to inspire and support further research in fashion item detection and\nsegmentation for industrial applications. The dataset, annotation tool, code,\nand models are available at \\url{https://rizavelioglu.github.io/fashionfail/}.",
      "tldr_zh": "本文针对时尚物体检测和分割中的失败案例（如非模特穿戴服装和特写镜头），引入了新数据集FashionFail，用于电商图像的object detection和segmentation。数据集通过一个基于foundation models的创新标注工具高效创建，旨在作为测试平台评估模型鲁棒性。分析显示，领先模型如Attribute-Mask R-CNN和Fashionformer存在显著缺点，因此作者提出使用简单的数据augmentation作为基线方法，以缓解常见问题并提升模型性能。该工作旨在推动时尚物品检测在工业应用的进一步研究，并公开了数据集、工具、代码和模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "to be published in 2024 International Joint Conference on Neural\n  Networks (IJCNN)",
      "pdf_url": "http://arxiv.org/pdf/2404.08582v1",
      "published_date": "2024-04-12 16:28:30 UTC",
      "updated_date": "2024-04-12 16:28:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:54:27.724968"
    },
    {
      "arxiv_id": "2404.08579v1",
      "title": "Small Models Are (Still) Effective Cross-Domain Argument Extractors",
      "title_zh": "翻译失败",
      "authors": [
        "William Gantt",
        "Aaron Steven White"
      ],
      "abstract": "Effective ontology transfer has been a major goal of recent work on event\nargument extraction (EAE). Two methods in particular -- question answering (QA)\nand template infilling (TI) -- have emerged as promising approaches to this\nproblem. However, detailed explorations of these techniques' ability to\nactually enable this transfer are lacking. In this work, we provide such a\nstudy, exploring zero-shot transfer using both techniques on six major EAE\ndatasets at both the sentence and document levels. Further, we challenge the\ngrowing reliance on LLMs for zero-shot extraction, showing that vastly smaller\nmodels trained on an appropriate source ontology can yield zero-shot\nperformance superior to that of GPT-3.5 or GPT-4.",
      "tldr_zh": "本研究探讨了问答(QA)和模板填充(TI)方法在事件参数提取(EAE)中的本体转移能力，通过在六个主要EAE数据集上进行零样本转移实验，涵盖句子和文档级别。结果显示，这些方法在使用小模型时表现出色，即使在适当的源本体上训练后，小模型的零样本性能也能超过大型语言模型(LLMs)如GPT-3.5或GPT-4。该发现挑战了LLMs在EAE任务中的主导地位，并证明小模型在跨领域参数提取中依然高效且实用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL Rolling Review Short Paper",
      "pdf_url": "http://arxiv.org/pdf/2404.08579v1",
      "published_date": "2024-04-12 16:23:41 UTC",
      "updated_date": "2024-04-12 16:23:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:54:39.978682"
    },
    {
      "arxiv_id": "2404.08570v1",
      "title": "Enhancing Autonomous Vehicle Training with Language Model Integration and Critical Scenario Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hanlin Tian",
        "Kethan Reddy",
        "Yuxiang Feng",
        "Mohammed Quddus",
        "Yiannis Demiris",
        "Panagiotis Angeloudis"
      ],
      "abstract": "This paper introduces CRITICAL, a novel closed-loop framework for autonomous\nvehicle (AV) training and testing. CRITICAL stands out for its ability to\ngenerate diverse scenarios, focusing on critical driving situations that target\nspecific learning and performance gaps identified in the Reinforcement Learning\n(RL) agent. The framework achieves this by integrating real-world traffic\ndynamics, driving behavior analysis, surrogate safety measures, and an optional\nLarge Language Model (LLM) component. It is proven that the establishment of a\nclosed feedback loop between the data generation pipeline and the training\nprocess can enhance the learning rate during training, elevate overall system\nperformance, and augment safety resilience. Our evaluations, conducted using\nthe Proximal Policy Optimization (PPO) and the HighwayEnv simulation\nenvironment, demonstrate noticeable performance improvements with the\nintegration of critical case generation and LLM analysis, indicating CRITICAL's\npotential to improve the robustness of AV systems and streamline the generation\nof critical scenarios. This ultimately serves to hasten the development of AV\nagents, expand the general scope of RL training, and ameliorate validation\nefforts for AV safety.",
      "tldr_zh": "本论文提出了一种名为 CRITICAL 的新型闭环框架，用于增强自动驾驶车辆 (AV) 训练和测试，通过生成针对 Reinforcement Learning (RL) 代理特定学习和性能缺口的关键驾驶场景来提升多样性。框架整合了真实交通动态、驾驶行为分析、代理安全措施以及可选的 Large Language Model (LLM) 组件，建立反馈循环以提高学习率、系统性能和安全韧性。在使用 Proximal Policy Optimization (PPO) 和 HighwayEnv 模拟环境的评估中，CRITICAL 展示了显著的性能改善，从而提升了 AV 系统的鲁棒性、加速代理开发并优化了安全验证过程。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.08570v1",
      "published_date": "2024-04-12 16:13:10 UTC",
      "updated_date": "2024-04-12 16:13:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:54:54.974315"
    },
    {
      "arxiv_id": "2404.08561v2",
      "title": "IDD-X: A Multi-View Dataset for Ego-relative Important Object Localization and Explanation in Dense and Unstructured Traffic",
      "title_zh": "翻译失败",
      "authors": [
        "Chirag Parikh",
        "Rohit Saluja",
        "C. V. Jawahar",
        "Ravi Kiran Sarvadevabhatla"
      ],
      "abstract": "Intelligent vehicle systems require a deep understanding of the interplay\nbetween road conditions, surrounding entities, and the ego vehicle's driving\nbehavior for safe and efficient navigation. This is particularly critical in\ndeveloping countries where traffic situations are often dense and unstructured\nwith heterogeneous road occupants. Existing datasets, predominantly geared\ntowards structured and sparse traffic scenarios, fall short of capturing the\ncomplexity of driving in such environments. To fill this gap, we present IDD-X,\na large-scale dual-view driving video dataset. With 697K bounding boxes, 9K\nimportant object tracks, and 1-12 objects per video, IDD-X offers comprehensive\nego-relative annotations for multiple important road objects covering 10\ncategories and 19 explanation label categories. The dataset also incorporates\nrearview information to provide a more complete representation of the driving\nenvironment. We also introduce custom-designed deep networks aimed at multiple\nimportant object localization and per-object explanation prediction. Overall,\nour dataset and introduced prediction models form the foundation for studying\nhow road conditions and surrounding entities affect driving behavior in complex\ntraffic situations.",
      "tldr_zh": "本研究引入了 IDD-X，这是一个大规模双视图驾驶视频数据集，针对发展中国家密集和无结构交通场景，填补了现有数据集在复杂环境下的不足。IDD-X 包含 697K bounding boxes、9K important object tracks 和每视频 1-12 对象，提供 ego-relative 注释，覆盖 10 个对象类别和 19 个 explanation label 类别，并整合后视信息以全面表示驾驶环境。该数据集还配以自定义深度网络，用于多个 important object localization 和每个对象的解释预测，最终为研究道路条件与周围实体对驾驶行为的影响奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICRA 2024; Project page: https://idd-x.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2404.08561v2",
      "published_date": "2024-04-12 16:00:03 UTC",
      "updated_date": "2024-04-23 19:19:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:55:04.299488"
    },
    {
      "arxiv_id": "2404.08555v2",
      "title": "RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs",
      "title_zh": "RLHF 解析：人类反馈强化学习在大语言模型中的批判性分析",
      "authors": [
        "Shreyas Chaudhari",
        "Pranjal Aggarwal",
        "Vishvak Murahari",
        "Tanmay Rajpurohit",
        "Ashwin Kalyan",
        "Karthik Narasimhan",
        "Ameet Deshpande",
        "Bruno Castro da Silva"
      ],
      "abstract": "State-of-the-art large language models (LLMs) have become indispensable tools\nfor various tasks. However, training LLMs to serve as effective assistants for\nhumans requires careful consideration. A promising approach is reinforcement\nlearning from human feedback (RLHF), which leverages human feedback to update\nthe model in accordance with human preferences and mitigate issues like\ntoxicity and hallucinations. Yet, an understanding of RLHF for LLMs is largely\nentangled with initial design choices that popularized the method and current\nresearch focuses on augmenting those choices rather than fundamentally\nimproving the framework. In this paper, we analyze RLHF through the lens of\nreinforcement learning principles to develop an understanding of its\nfundamentals, dedicating substantial focus to the core component of RLHF -- the\nreward model. Our study investigates modeling choices, caveats of function\napproximation, and their implications on RLHF training algorithms, highlighting\nthe underlying assumptions made about the expressivity of reward. Our analysis\nimproves the understanding of the role of reward models and methods for their\ntraining, concurrently revealing limitations of the current methodology. We\ncharacterize these limitations, including incorrect generalization, model\nmisspecification, and the sparsity of feedback, along with their impact on the\nperformance of a language model. The discussion and analysis are substantiated\nby a categorical review of current literature, serving as a reference for\nresearchers and practitioners to understand the challenges of RLHF and build\nupon existing efforts.",
      "tldr_zh": "本论文对 RLHF（Reinforcement Learning from Human Feedback）在 LLMs（Large Language Models）中的应用进行了批判性分析，通过强化学习原则审视其基础，特别是 reward model 的核心作用。研究探讨了建模选择、函数逼近的潜在问题及其对 RLHF 训练算法的影响，揭示了 reward model 表达性的隐含假设。分析结果突出了 RLHF 的局限性，包括不正确的泛化、模型错误指定和反馈稀疏性，这些因素可能损害语言模型的性能，并通过文献回顾为研究者提供改进建议。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08555v2",
      "published_date": "2024-04-12 15:54:15 UTC",
      "updated_date": "2024-04-16 00:22:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:55:16.079213"
    },
    {
      "arxiv_id": "2404.16054v2",
      "title": "LlamaTouch: A Faithful and Scalable Testbed for Mobile UI Task Automation",
      "title_zh": "LlamaTouch：一个可靠且可扩展的移动UI任务自动化测试平台",
      "authors": [
        "Li Zhang",
        "Shihe Wang",
        "Xianqing Jia",
        "Zhihan Zheng",
        "Yunhe Yan",
        "Longxi Gao",
        "Yuanchun Li",
        "Mengwei Xu"
      ],
      "abstract": "The emergent large language/multimodal models facilitate the evolution of\nmobile agents, especially in mobile UI task automation. However, existing\nevaluation approaches, which rely on human validation or established datasets\nto compare agent-predicted actions with predefined action sequences, are\nunscalable and unfaithful. To overcome these limitations, this paper presents\nLlamaTouch, a testbed for on-device mobile UI task execution and faithful,\nscalable task evaluation. By observing that the task execution process only\ntransfers UI states, LlamaTouch employs a novel evaluation approach that only\nassesses whether an agent traverses all manually annotated, essential\napplication/system states. LlamaTouch comprises three key techniques: (1)\nOn-device task execution that enables mobile agents to interact with realistic\nmobile environments for task execution. (2) Fine-grained UI component\nannotation that merges pixel-level screenshots and textual screen hierarchies\nto explicitly identify and precisely annotate essential UI components with a\nrich set of designed annotation primitives. (3) A multi-level application state\nmatching algorithm that utilizes exact and fuzzy matching to accurately detect\ncritical information in each screen, even with unpredictable UI layout/content\ndynamics. LlamaTouch currently incorporates four mobile agents and 496 tasks,\nencompassing both tasks in the widely-used datasets and our self-constructed\nones to cover more diverse mobile applications. Evaluation results demonstrate\nLlamaTouch's high faithfulness of evaluation in real-world mobile environments\nand its better scalability than human validation. LlamaTouch also enables easy\ntask annotation and integration of new mobile agents. Code and dataset are\npublicly available at https://github.com/LlamaTouch/LlamaTouch.",
      "tldr_zh": "这篇论文介绍了 LlamaTouch，一个可信且可扩展的测试平台，用于评估移动 UI 任务自动化的代理性能，以解决现有方法依赖人工验证或预定义数据集的局限性。LlamaTouch 采用创新评估方法，通过 on-device task execution、细粒度 UI 组件 annotation 和多级 application state matching algorithm，确保代理是否正确遍历所有必要 UI 状态，即使面对动态布局。实验结果显示，该平台在真实移动环境中提供高保真评估，比人工验证更具可扩展性，并支持易于任务标注和集成新代理，代码和数据集已在 GitHub 上公开。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at ACM UIST 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.16054v2",
      "published_date": "2024-04-12 15:39:09 UTC",
      "updated_date": "2024-08-02 13:49:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:55:29.443789"
    },
    {
      "arxiv_id": "2404.08544v2",
      "title": "Analyzing Decades-Long Environmental Changes in Namibia Using Archival Aerial Photography and Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Girmaw Abebe Tadesse",
        "Caleb Robinson",
        "Gilles Quentin Hacheme",
        "Akram Zaytar",
        "Rahul Dodhia",
        "Tsering Wangyal Shawa",
        "Juan M. Lavista Ferres",
        "Emmanuel H. Kreike"
      ],
      "abstract": "This study explores object detection in historical aerial photographs of\nNamibia to identify long-term environmental changes. Specifically, we aim to\nidentify key objects -- Waterholes, Omuti homesteads, and Big trees -- around\nOshikango in Namibia using sub-meter gray-scale aerial imagery from 1943 and\n1972. In this work, we propose a workflow for analyzing historical aerial\nimagery using a deep semantic segmentation model on sparse hand-labels. To this\nend, we employ a number of strategies including class-weighting,\npseudo-labeling and empirical p-value-based filtering to balance skewed and\nsparse representations of objects in the ground truth data. Results demonstrate\nthe benefits of these different training strategies resulting in an average\n$F_1=0.661$ and $F_1=0.755$ over the three objects of interest for the 1943 and\n1972 imagery, respectively. We also identified that the average size of\nWaterhole and Big trees increased while the average size of Omuti homesteads\ndecreased between 1943 and 1972 reflecting some of the local effects of the\nmassive post-Second World War economic, agricultural, demographic, and\nenvironmental changes. This work also highlights the untapped potential of\nhistorical aerial photographs in understanding long-term environmental changes\nbeyond Namibia (and Africa). With the lack of adequate satellite technology in\nthe past, archival aerial photography offers a great alternative to uncover\ndecades-long environmental changes.",
      "tldr_zh": "这篇论文使用历史航拍照片和深度学习分析纳米比亚的环境变化，焦点是识别 Oshikango 地区的 Waterholes、Omuti homesteads 和 Big trees，在 1943 和 1972 年的灰度图像上进行对象检测。研究提出一个基于深度语义分割模型的工作流程，结合 class-weighting、pseudo-labeling 和 empirical p-value-based filtering 等策略，以处理数据中的不平衡和稀疏问题，结果显示 1943 年的平均 F1 分数为 0.661，1972 年为 0.755。论文发现 Waterholes 和 Big trees 的平均大小增加，而 Omuti homesteads 的平均大小减少，反映了二战后当地经济、农业、人口和环境变化的影响，并强调历史航拍照片作为卫星技术的替代方案，在全球范围内理解长期环境变化的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08544v2",
      "published_date": "2024-04-12 15:37:53 UTC",
      "updated_date": "2024-04-21 10:24:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:55:43.075860"
    },
    {
      "arxiv_id": "2404.08543v1",
      "title": "Memory Traces: Are Transformers Tulving Machines?",
      "title_zh": "记忆痕迹：Transformers 是 Tulving 机器吗？",
      "authors": [
        "Jean-Marie Chauvet"
      ],
      "abstract": "Memory traces--changes in the memory system that result from the perception\nand encoding of an event--were measured in pioneering studies by Endel Tulving\nand Michael J. Watkins in 1975. These and further experiments informed the\nmaturation of Tulving's memory model, from the GAPS (General Abstract\nProcessing System} to the SPI (Serial-Parallel Independent) model. Having\ncurrent top of the line LLMs revisit the original Tulving-Watkins tests may\nhelp in assessing whether foundation models completely instantiate or not this\nclass of psychological models.",
      "tldr_zh": "该论文探讨了Transformer模型是否类似于Tulving的记忆系统，焦点在于记忆痕迹（memory traces）——即事件感知和编码对记忆系统产生的变化。作者回顾了Endel Tulving和Michael J. Watkins在1975年的开创性研究，这些实验推动了Tulving记忆模型从GAPS（General Abstract Processing System）到SPI（Serial-Parallel Independent）的演进。论文建议通过让当前顶级LLMs（Large Language Models）重新测试这些实验，来评估Transformer模型是否完全实例化了此类心理模型，从而深化AI与人类记忆机制的比较分析。",
      "categories": [
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 1 figure and 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.08543v1",
      "published_date": "2024-04-12 15:37:35 UTC",
      "updated_date": "2024-04-12 15:37:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:55:52.666368"
    },
    {
      "arxiv_id": "2404.08523v1",
      "title": "Advancing Forest Fire Prevention: Deep Reinforcement Learning for Effective Firebreak Placement",
      "title_zh": "推进森林火灾预防：深度强化学习用于有效的防火隔离带放置",
      "authors": [
        "Lucas Murray",
        "Tatiana Castillo",
        "Jaime Carrasco",
        "Andrés Weintraub",
        "Richard Weber",
        "Isaac Martín de Diego",
        "José Ramón González",
        "Jordi García-Gonzalo"
      ],
      "abstract": "Over the past decades, the increase in both frequency and intensity of\nlarge-scale wildfires due to climate change has emerged as a significant\nnatural threat. The pressing need to design resilient landscapes capable of\nwithstanding such disasters has become paramount, requiring the development of\nadvanced decision-support tools. Existing methodologies, including Mixed\nInteger Programming, Stochastic Optimization, and Network Theory, have proven\neffective but are hindered by computational demands, limiting their\napplicability.\n  In response to this challenge, we propose using artificial intelligence\ntechniques, specifically Deep Reinforcement Learning, to address the complex\nproblem of firebreak placement in the landscape. We employ value-function based\napproaches like Deep Q-Learning, Double Deep Q-Learning, and Dueling Double\nDeep Q-Learning. Utilizing the Cell2Fire fire spread simulator combined with\nConvolutional Neural Networks, we have successfully implemented a computational\nagent capable of learning firebreak locations within a forest environment,\nachieving good results.\n  Furthermore, we incorporate a pre-training loop, initially teaching our agent\nto mimic a heuristic-based algorithm and observe that it consistently exceeds\nthe performance of these solutions. Our findings underscore the immense\npotential of Deep Reinforcement Learning for operational research challenges,\nespecially in fire prevention. Our approach demonstrates convergence with\nhighly favorable results in problem instances as large as 40 x 40 cells,\nmarking a significant milestone in applying Reinforcement Learning to this\ncritical issue.\n  To the best of our knowledge, this study represents a pioneering effort in\nusing Reinforcement Learning to address the aforementioned problem, offering\npromising perspectives in fire prevention and landscape management",
      "tldr_zh": "这篇论文针对气候变化导致的野火频率和强度增加问题，提出使用 Deep Reinforcement Learning 来优化防火带放置，从而提升森林防火策略的效率。方法包括采用 Deep Q-Learning、Double Deep Q-Learning 和 Dueling Double Deep Q-Learning 等算法，结合 Cell2Fire 火势传播模拟器和 Convolutional Neural Networks，让代理通过预训练循环模仿并超越启发式算法。实验结果显示，该框架在 40x40 细胞规模的实例上取得了显著改善，准确率和性能优于传统方法，如混合整数规划，为防火预防和景观管理提供了创新性解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.08523v1",
      "published_date": "2024-04-12 15:10:57 UTC",
      "updated_date": "2024-04-12 15:10:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:56:05.040717"
    },
    {
      "arxiv_id": "2404.08517v1",
      "title": "Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path Forward",
      "title_zh": "LLMs 的在线安全分析：一个基准、一个评估以及一条前进路径",
      "authors": [
        "Xuan Xie",
        "Jiayang Song",
        "Zhehua Zhou",
        "Yuheng Huang",
        "Da Song",
        "Lei Ma"
      ],
      "abstract": "While Large Language Models (LLMs) have seen widespread applications across\nnumerous fields, their limited interpretability poses concerns regarding their\nsafe operations from multiple aspects, e.g., truthfulness, robustness, and\nfairness. Recent research has started developing quality assurance methods for\nLLMs, introducing techniques such as offline detector-based or uncertainty\nestimation methods. However, these approaches predominantly concentrate on\npost-generation analysis, leaving the online safety analysis for LLMs during\nthe generation phase an unexplored area. To bridge this gap, we conduct in this\nwork a comprehensive evaluation of the effectiveness of existing online safety\nanalysis methods on LLMs. We begin with a pilot study that validates the\nfeasibility of detecting unsafe outputs in the early generation process.\nFollowing this, we establish the first publicly available benchmark of online\nsafety analysis for LLMs, including a broad spectrum of methods, models, tasks,\ndatasets, and evaluation metrics. Utilizing this benchmark, we extensively\nanalyze the performance of state-of-the-art online safety analysis methods on\nboth open-source and closed-source LLMs. This analysis reveals the strengths\nand weaknesses of individual methods and offers valuable insights into\nselecting the most appropriate method based on specific application scenarios\nand task requirements. Furthermore, we also explore the potential of using\nhybridization methods, i.e., combining multiple methods to derive a collective\nsafety conclusion, to enhance the efficacy of online safety analysis for LLMs.\nOur findings indicate a promising direction for the development of innovative\nand trustworthy quality assurance methodologies for LLMs, facilitating their\nreliable deployments across diverse domains.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)的在线安全分析问题，评估了生成过程中的安全风险，如真实性、鲁棒性和公平性。研究者建立了首个公开基准，包括多种方法、模型、任务、数据集和评估指标，并通过实验分析了现有方法的性能，揭示了它们的优势和劣势。结果表明，结合多种方法的混合策略（如集体安全结论）可显著提升分析效能，为开发可信赖的LLMs质量保障方法提供了重要路径。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08517v1",
      "published_date": "2024-04-12 14:55:16 UTC",
      "updated_date": "2024-04-12 14:55:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:56:16.350360"
    },
    {
      "arxiv_id": "2404.08513v1",
      "title": "Adversarial Imitation Learning via Boosting",
      "title_zh": "通过 Boosting 的对抗模仿学习",
      "authors": [
        "Jonathan D. Chang",
        "Dhruv Sreenivas",
        "Yingbing Huang",
        "Kianté Brantley",
        "Wen Sun"
      ],
      "abstract": "Adversarial imitation learning (AIL) has stood out as a dominant framework\nacross various imitation learning (IL) applications, with Discriminator Actor\nCritic (DAC) (Kostrikov et al.,, 2019) demonstrating the effectiveness of\noff-policy learning algorithms in improving sample efficiency and scalability\nto higher-dimensional observations. Despite DAC's empirical success, the\noriginal AIL objective is on-policy and DAC's ad-hoc application of off-policy\ntraining does not guarantee successful imitation (Kostrikov et al., 2019;\n2020). Follow-up work such as ValueDICE (Kostrikov et al., 2020) tackles this\nissue by deriving a fully off-policy AIL objective. Instead in this work, we\ndevelop a novel and principled AIL algorithm via the framework of boosting.\nLike boosting, our new algorithm, AILBoost, maintains an ensemble of properly\nweighted weak learners (i.e., policies) and trains a discriminator that\nwitnesses the maximum discrepancy between the distributions of the ensemble and\nthe expert policy. We maintain a weighted replay buffer to represent the\nstate-action distribution induced by the ensemble, allowing us to train\ndiscriminators using the entire data collected so far. In the weighted replay\nbuffer, the contribution of the data from older policies are properly\ndiscounted with the weight computed based on the boosting framework.\nEmpirically, we evaluate our algorithm on both controller state-based and\npixel-based environments from the DeepMind Control Suite. AILBoost outperforms\nDAC on both types of environments, demonstrating the benefit of properly\nweighting replay buffer data for off-policy training. On state-based\nenvironments, DAC outperforms ValueDICE and IQ-Learn (Gary et al., 2021),\nachieving competitive performance with as little as one expert trajectory.",
      "tldr_zh": "本研究针对Adversarial Imitation Learning (AIL)的off-policy训练问题，提出了一种新算法AILBoost，通过boosting框架来优化模仿学习。AILBoost维护一个权重化的弱学习者集合（policies），并训练鉴别器以检测集合和专家策略之间的最大差异，同时使用weighted replay buffer来存储和折扣旧数据，从而实现高效的off-policy训练。实验结果显示，在DeepMind Control Suite的基于状态和像素的环境中，AILBoost超越了DAC，并在基于状态的环境中仅需一个专家轨迹就实现了与ValueDICE和IQ-Learn相当的性能，证明了正确权重化重放缓冲区的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 7 figures, 4 tables, 3 algorithms, ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08513v1",
      "published_date": "2024-04-12 14:53:36 UTC",
      "updated_date": "2024-04-12 14:53:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:56:29.680565"
    },
    {
      "arxiv_id": "2404.08511v1",
      "title": "Leveraging Multi-AI Agents for Cross-Domain Knowledge Discovery",
      "title_zh": "利用多AI代理进行跨领域知识发现",
      "authors": [
        "Shiva Aryal",
        "Tuyen Do",
        "Bisesh Heyojoo",
        "Sandeep Chataut",
        "Bichar Dip Shrestha Gurung",
        "Venkataramana Gadhamshetty",
        "Etienne Gnimpieba"
      ],
      "abstract": "In the rapidly evolving field of artificial intelligence, the ability to\nharness and integrate knowledge across various domains stands as a paramount\nchallenge and opportunity. This study introduces a novel approach to\ncross-domain knowledge discovery through the deployment of multi-AI agents,\neach specialized in distinct knowledge domains. These AI agents, designed to\nfunction as domain-specific experts, collaborate in a unified framework to\nsynthesize and provide comprehensive insights that transcend the limitations of\nsingle-domain expertise. By facilitating seamless interaction among these\nagents, our platform aims to leverage the unique strengths and perspectives of\neach, thereby enhancing the process of knowledge discovery and decision-making.\nWe present a comparative analysis of the different multi-agent workflow\nscenarios evaluating their performance in terms of efficiency, accuracy, and\nthe breadth of knowledge integration. Through a series of experiments involving\ncomplex, interdisciplinary queries, our findings demonstrate the superior\ncapability of domain specific multi-AI agent system in identifying and bridging\nknowledge gaps. This research not only underscores the significance of\ncollaborative AI in driving innovation but also sets the stage for future\nadvancements in AI-driven, cross-disciplinary research and application. Our\nmethods were evaluated on a small pilot data and it showed a trend we expected,\nif we increase the amount of data we custom train the agents, the trend is\nexpected to be more smooth.",
      "tldr_zh": "这篇论文提出了一种利用 Multi-AI Agents 的方法，实现跨领域知识发现，这些代理作为领域专家在统一框架中协作，提供超越单一领域限制的综合洞见。研究通过比较不同多代理工作流场景，评估了效率、准确性和知识整合广度，并在复杂跨学科查询的实验中证明，该系统在识别和桥接知识差距方面表现出色。结果显示，这种协作AI方法能驱动创新，并为未来AI驱动的跨学科研究铺平道路；虽然在小规模试点数据上验证了预期趋势，但作者预期通过增加数据和自定义训练，性能将进一步提升。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08511v1",
      "published_date": "2024-04-12 14:50:41 UTC",
      "updated_date": "2024-04-12 14:50:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:56:43.524612"
    },
    {
      "arxiv_id": "2404.08501v1",
      "title": "Analyzing and Overcoming Local Optima in Complex Multi-Objective Optimization by Decomposition-Based Evolutionary Algorithms",
      "title_zh": "基于分解进化算法分析和克服复杂多目标优化中的局部最优",
      "authors": [
        "Ting Dong",
        "Haoxin Wang",
        "Hengxi Zhang",
        "Wenbo Ding"
      ],
      "abstract": "When addressing the challenge of complex multi-objective optimization\nproblems, particularly those with non-convex and non-uniform Pareto fronts,\nDecomposition-based Multi-Objective Evolutionary Algorithms (MOEADs) often\nconverge to local optima, thereby limiting solution diversity. Despite its\nsignificance, this issue has received limited theoretical exploration. Through\na comprehensive geometric analysis, we identify that the traditional method of\nReference Point (RP) selection fundamentally contributes to this challenge. In\nresponse, we introduce an innovative RP selection strategy, the Weight\nVector-Guided and Gaussian-Hybrid method, designed to overcome the local optima\nissue. This approach employs a novel RP type that aligns with weight vector\ndirections and integrates a Gaussian distribution to combine three distinct RP\ncategories. Our research comprises two main experimental components: an\nablation study involving 14 algorithms within the MOEADs framework, spanning\nfrom 2014 to 2022, to validate our theoretical framework, and a series of\nempirical tests to evaluate the effectiveness of our proposed method against\nboth traditional and cutting-edge alternatives. Results demonstrate that our\nmethod achieves remarkable improvements in both population diversity and\nconvergence.",
      "tldr_zh": "该论文分析了基于分解的多目标进化算法(MOEADs)在处理非凸、非均匀Pareto前沿的复杂多目标优化问题时，容易收敛到局部最优从而降低解决方案多样性的问题，并通过几何分析确定了传统Reference Point (RP)选择方法是主要原因。作者提出了一种创新的RP选择策略，即Weight Vector-Guided and Gaussian-Hybrid方法，该策略与权重向量对齐并整合高斯分布来结合三种不同RP类别，以克服局部最优挑战。实验结果显示，通过对14个MOEADs算法的消融研究和实证测试，该方法显著提升了种群多样性和收敛性能。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08501v1",
      "published_date": "2024-04-12 14:29:45 UTC",
      "updated_date": "2024-04-12 14:29:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:56:55.900659"
    },
    {
      "arxiv_id": "2404.08495v3",
      "title": "Dataset Reset Policy Optimization for RLHF",
      "title_zh": "针对 RLHF 的数据集重置策略优化",
      "authors": [
        "Jonathan D. Chang",
        "Wenhao Zhan",
        "Owen Oertell",
        "Kianté Brantley",
        "Dipendra Misra",
        "Jason D. Lee",
        "Wen Sun"
      ],
      "abstract": "Reinforcement Learning (RL) from Human Preference-based feedback is a popular\nparadigm for fine-tuning generative models, which has produced impressive\nmodels such as GPT-4 and Claude3 Opus. This framework often consists of two\nsteps: learning a reward model from an offline preference dataset followed by\nrunning online RL to optimize the learned reward model. In this work,\nleveraging the idea of reset, we propose a new RLHF algorithm with provable\nguarantees. Motivated by the fact that offline preference dataset provides\ninformative states (i.e., data that is preferred by the labelers), our new\nalgorithm, Dataset Reset Policy Optimization (DR-PO), integrates the existing\noffline preference dataset into the online policy training procedure via\ndataset reset: it directly resets the policy optimizer to the states in the\noffline dataset, instead of always starting from the initial state\ndistribution. In theory, we show that DR-PO learns to perform at least as good\nas any policy that is covered by the offline dataset under general function\napproximation with finite sample complexity. In experiments, we demonstrate\nthat on both the TL;DR summarization and the Anthropic Helpful Harmful (HH)\ndataset, the generation from DR-PO is better than that from Proximal Policy\nOptimization (PPO) and Direction Preference Optimization (DPO), under the\nmetric of GPT4 win-rate. Code for this work can be found at\nhttps://github.com/Cornell-RL/drpo.",
      "tldr_zh": "该论文针对强化学习从人类偏好反馈（RLHF）提出了一种新算法 Dataset Reset Policy Optimization (DR-PO)，旨在通过整合离线偏好数据集来优化在线策略训练。DR-PO 的核心创新是将策略优化器直接重置到数据集中的信息状态，而不是总是从初始状态分布开始，从而提升训练效率和性能。在理论上，该算法在一般函数逼近下具有有限样本复杂度的保证，能学习至少与数据集覆盖的政策一样出色；实验结果显示，在 TL;DR 总结和 Anthropic Helpful Harmful (HH) 数据集上，DR-PO 的生成输出优于 Proximal Policy Optimization (PPO) 和 Direction Preference Optimization (DPO)，根据 GPT4 win-rate 指标评估。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 6 tables, 3 Figures, 3 Algorithms",
      "pdf_url": "http://arxiv.org/pdf/2404.08495v3",
      "published_date": "2024-04-12 14:25:49 UTC",
      "updated_date": "2024-04-16 17:36:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:57:07.837898"
    },
    {
      "arxiv_id": "2404.08491v1",
      "title": "Mitigating Language-Level Performance Disparity in mPLMs via Teacher Language Selection and Cross-lingual Self-Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhe Zhao",
        "Zefan Cai",
        "Shuzheng Si",
        "Liang Chen",
        "Yufeng He",
        "Kaikai An",
        "Baobao Chang"
      ],
      "abstract": "Large-scale multilingual Pretrained Language Models (mPLMs) yield impressive\nperformance on cross-language tasks, yet significant performance disparities\nexist across different languages within the same mPLM. Previous studies\nendeavored to narrow these disparities by supervise fine-tuning the mPLMs with\nmultilingual data. However, obtaining labeled multilingual data is\ntime-consuming, and fine-tuning mPLM with limited labeled multilingual data\nmerely encapsulates the knowledge specific to the labeled data. Therefore, we\nintroduce ALSACE to leverage the learned knowledge from the well-performing\nlanguages to guide under-performing ones within the same mPLM, eliminating the\nneed for additional labeled multilingual data. Experiments show that ALSACE\neffectively mitigates language-level performance disparity across various mPLMs\nwhile showing the competitive performance on different multilingual NLU tasks,\nranging from full resource to limited resource settings. The code for our\napproach is available at https://github.com/pkunlp-icler/ALSACE.",
      "tldr_zh": "这项研究针对大规模多语言预训练语言模型 (mPLMs) 在不同语言间的性能差异问题，提出了 ALSACE 方法，通过教师语言选择和跨语言自蒸馏 (Cross-lingual Self-Distillation) 利用高性能语言的知识指导低性能语言，从而避免了额外标注多语言数据的需求。ALSACE 无需监督微调即可有效减少语言级性能差距，并在各种多语言自然语言理解 (NLU) 任务中表现出竞争性表现，从资源充足到资源有限的场景均适用。该方法为提升 mPLMs 的跨语言鲁棒性提供了新途径，并已在开源代码中实现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08491v1",
      "published_date": "2024-04-12 14:19:16 UTC",
      "updated_date": "2024-04-12 14:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:57:18.540759"
    },
    {
      "arxiv_id": "2404.08476v1",
      "title": "Combining Statistical Depth and Fermat Distance for Uncertainty Quantification",
      "title_zh": "翻译失败",
      "authors": [
        "Hai-Vy Nguyen",
        "Fabrice Gamboa",
        "Reda Chhaibi",
        "Sixin Zhang",
        "Serge Gratton",
        "Thierry Giaccone"
      ],
      "abstract": "We measure the Out-of-domain uncertainty in the prediction of Neural Networks\nusing a statistical notion called ``Lens Depth'' (LD) combined with Fermat\nDistance, which is able to capture precisely the ``depth'' of a point with\nrespect to a distribution in feature space, without any assumption about the\nform of distribution. Our method has no trainable parameter. The method is\napplicable to any classification model as it is applied directly in feature\nspace at test time and does not intervene in training process. As such, it does\nnot impact the performance of the original model. The proposed method gives\nexcellent qualitative result on toy datasets and can give competitive or better\nuncertainty estimation on standard deep learning datasets compared to strong\nbaseline methods.",
      "tldr_zh": "本文提出了一种结合统计深度(Lens Depth)和Fermat Distance的方法，用于量化神经网络预测中的Out-of-domain不确定性。该方法无需任何训练参数，直接在特征空间测试时应用，不影响原模型的性能，且适用于任何分类模型。实验结果显示，该方法在玩具数据集上提供优秀的定性结果，并在标准深度学习数据集上与强基线方法相比具有竞争性或更好的不确定性估计。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.PR",
        "stat.AP"
      ],
      "primary_category": "stat.ML",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.08476v1",
      "published_date": "2024-04-12 13:54:21 UTC",
      "updated_date": "2024-04-12 13:54:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:57:29.952671"
    },
    {
      "arxiv_id": "2404.08461v2",
      "title": "OTTER: Effortless Label Distribution Adaptation of Zero-shot Models",
      "title_zh": "翻译失败",
      "authors": [
        "Changho Shin",
        "Jitian Zhao",
        "Sonia Cromp",
        "Harit Vishwakarma",
        "Frederic Sala"
      ],
      "abstract": "Popular zero-shot models suffer due to artifacts inherited from pretraining.\nOne particularly detrimental issue, caused by unbalanced web-scale pretraining\ndata, is mismatched label distribution. Existing approaches that seek to repair\nthe label distribution are not suitable in zero-shot settings, as they have\nmismatching requirements, such as needing access to labeled downstream task\ndata or knowledge of the true label balance in the pretraining distribution. We\nsidestep these challenges and introduce a simple and lightweight approach to\nadjust pretrained model predictions via optimal transport. Our technique\nrequires only an estimate of the label distribution of a downstream task.\nTheoretically, we characterize the improvement produced by our procedure under\ncertain mild conditions and provide bounds on the error caused by\nmisspecification. Empirically, we validate our method in a wide array of\nzero-shot image and text classification tasks, improving accuracy by 4.8% and\n15.9% on average, and beating baselines like prior matching -- often by\nsignificant margins -- in 17 out of 21 datasets.",
      "tldr_zh": "本论文提出OTTER，一种简单轻量的方法，用于适应零样本模型（zero-shot models）的标签分布不匹配问题，通过optimal transport调整预训练模型的预测，仅需下游任务的标签分布估计，而无需标记数据或预训练分布知识。理论上，该方法在特定条件下可改善模型性能，并提供错误界限。实验结果显示，在多种零样本图像和文本分类任务中，OTTER平均提高了4.8%和15.9%的准确率，并在21个数据集中的17个上显著超过了基线方法，如prior matching。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08461v2",
      "published_date": "2024-04-12 13:18:47 UTC",
      "updated_date": "2024-10-30 11:40:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:57:42.917307"
    },
    {
      "arxiv_id": "2404.08721v1",
      "title": "Beyond One-Size-Fits-All: Adapting Counterfactual Explanations to User Objectives",
      "title_zh": "翻译失败",
      "authors": [
        "Orfeas Menis Mastromichalakis",
        "Jason Liartis",
        "Giorgos Stamou"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) has emerged as a critical area of\nresearch aimed at enhancing the transparency and interpretability of AI\nsystems. Counterfactual Explanations (CFEs) offer valuable insights into the\ndecision-making processes of machine learning algorithms by exploring\nalternative scenarios where certain factors differ. Despite the growing\npopularity of CFEs in the XAI community, existing literature often overlooks\nthe diverse needs and objectives of users across different applications and\ndomains, leading to a lack of tailored explanations that adequately address the\ndifferent use cases. In this paper, we advocate for a nuanced understanding of\nCFEs, recognizing the variability in desired properties based on user\nobjectives and target applications. We identify three primary user objectives\nand explore the desired characteristics of CFEs in each case. By addressing\nthese differences, we aim to design more effective and tailored explanations\nthat meet the specific needs of users, thereby enhancing collaboration with AI\nsystems.",
      "tldr_zh": "本论文探讨了 Explainable Artificial Intelligence (XAI) 中的 Counterfactual Explanations (CFEs)，指出现有方法忽略了用户在不同应用领域的多样化目标，导致解释不充分。作者主张根据用户需求调整 CFEs，识别了三种主要用户目标，并分析了每种目标下期望的解释特性。最终，该方法旨在设计更具针对性的解释，提升用户与 AI 系统的协作效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08721v1",
      "published_date": "2024-04-12 13:11:55 UTC",
      "updated_date": "2024-04-12 13:11:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:57:54.144137"
    },
    {
      "arxiv_id": "2404.08458v2",
      "title": "On the Independence Assumption in Neurosymbolic Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Emile van Krieken",
        "Pasquale Minervini",
        "Edoardo M. Ponti",
        "Antonio Vergari"
      ],
      "abstract": "State-of-the-art neurosymbolic learning systems use probabilistic reasoning\nto guide neural networks towards predictions that conform to logical\nconstraints over symbols. Many such systems assume that the probabilities of\nthe considered symbols are conditionally independent given the input to\nsimplify learning and reasoning. We study and criticise this assumption,\nhighlighting how it can hinder optimisation and prevent uncertainty\nquantification. We prove that loss functions bias conditionally independent\nneural networks to become overconfident in their predictions. As a result, they\nare unable to represent uncertainty over multiple valid options. Furthermore,\nwe prove that these loss functions are difficult to optimise: they are\nnon-convex, and their minima are usually highly disconnected. Our theoretical\nanalysis gives the foundation for replacing the conditional independence\nassumption and designing more expressive neurosymbolic probabilistic models.",
      "tldr_zh": "本论文探讨了神经符号学习（neurosymbolic learning）中条件独立假设（conditional independence）的局限性，该假设假设符号概率在给定输入时相互独立，以简化概率推理和学习过程。作者证明，这种假设会导致损失函数使神经网络过度自信，无法准确量化不确定性，从而忽略多个有效选项的可能性。此外，论文分析了这些损失函数的非凸性和最小值的高度不连续性，证明它们难以优化，并为取代该假设并开发更具表现力的神经符号概率模型提供了理论基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08458v2",
      "published_date": "2024-04-12 13:09:48 UTC",
      "updated_date": "2024-06-07 15:10:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:58:05.784698"
    },
    {
      "arxiv_id": "2404.08434v2",
      "title": "An improved tabular data generator with VAE-GMM integration",
      "title_zh": "翻译失败",
      "authors": [
        "Patricia A. Apellániz",
        "Juan Parras",
        "Santiago Zazo"
      ],
      "abstract": "The rising use of machine learning in various fields requires robust methods\nto create synthetic tabular data. Data should preserve key characteristics\nwhile addressing data scarcity challenges. Current approaches based on\nGenerative Adversarial Networks, such as the state-of-the-art CTGAN model,\nstruggle with the complex structures inherent in tabular data. These data often\ncontain both continuous and discrete features with non-Gaussian distributions.\nTherefore, we propose a novel Variational Autoencoder (VAE)-based model that\naddresses these limitations. Inspired by the TVAE model, our approach\nincorporates a Bayesian Gaussian Mixture model (BGM) within the VAE\narchitecture. This avoids the limitations imposed by assuming a strictly\nGaussian latent space, allowing for a more accurate representation of the\nunderlying data distribution during data generation. Furthermore, our model\noffers enhanced flexibility by allowing the use of various differentiable\ndistributions for individual features, making it possible to handle both\ncontinuous and discrete data types. We thoroughly validate our model on three\nreal-world datasets with mixed data types, including two medically relevant\nones, based on their resemblance and utility. This evaluation demonstrates\nsignificant outperformance against CTGAN and TVAE, establishing its potential\nas a valuable tool for generating synthetic tabular data in various domains,\nparticularly in healthcare.",
      "tldr_zh": "该研究针对机器学习中合成表格数据生成的问题，提出了一种改进的模型，通过整合 Variational Autoencoder (VAE) 和 Bayesian Gaussian Mixture model (BGM)，以更好地处理表格数据中的连续、离散特征及非高斯分布。该模型避免了传统VAE的严格高斯潜空间假设，并支持多种可微分分布，增强了灵活性。在三个真实数据集（包括医疗相关数据）上的验证中，该模型显著优于CTGAN和TVAE，展示了更高的数据相似性和实用性，为医疗等领域的数据生成提供了一个有价值的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.08434v2",
      "published_date": "2024-04-12 12:31:06 UTC",
      "updated_date": "2024-11-14 09:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:58:18.458021"
    },
    {
      "arxiv_id": "2404.08424v3",
      "title": "Comparing Apples to Oranges: LLM-powered Multimodal Intention Prediction in an Object Categorization Task",
      "title_zh": "翻译失败",
      "authors": [
        "Hassan Ali",
        "Philipp Allgeuer",
        "Stefan Wermter"
      ],
      "abstract": "Human intention-based systems enable robots to perceive and interpret user\nactions to interact with humans and adapt to their behavior proactively.\nTherefore, intention prediction is pivotal in creating a natural interaction\nwith social robots in human-designed environments. In this paper, we examine\nusing Large Language Models (LLMs) to infer human intention in a collaborative\nobject categorization task with a physical robot. We propose a novel multimodal\napproach that integrates user non-verbal cues, like hand gestures, body poses,\nand facial expressions, with environment states and user verbal cues to predict\nuser intentions in a hierarchical architecture. Our evaluation of five LLMs\nshows the potential for reasoning about verbal and non-verbal user cues,\nleveraging their context-understanding and real-world knowledge to support\nintention prediction while collaborating on a task with a social robot. Video:\nhttps://youtu.be/tBJHfAuzohI",
      "tldr_zh": "本研究探讨了使用大型语言模型(LLMs)来推断人类意图，旨在提升社交机器人与人类在物体分类任务中的协作互动。该方法采用多模态(multi-modal)整合策略，将用户非语言线索（如手势、body poses和facial expressions）与环境状态和verbal cues结合，在分层架构中进行意图预测。评估五个LLMs的结果显示，这些模型能有效利用上下文理解和真实世界知识，提升意图预测的准确性，从而为自然的人机互动提供支持。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "I.2.9; I.2.7; I.2.8"
      ],
      "primary_category": "cs.RO",
      "comment": "Published in the Proceedings of the 16th International Conference on\n  Social Robotics (ICSR) 2024,15 pages,5 figures,2 tables; work was co-funded\n  by Horizon Europe project TERAIS under Grant agreement number 101079338",
      "pdf_url": "http://arxiv.org/pdf/2404.08424v3",
      "published_date": "2024-04-12 12:15:14 UTC",
      "updated_date": "2025-04-08 10:48:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:58:29.762048"
    },
    {
      "arxiv_id": "2404.08417v2",
      "title": "AdapterSwap: Continuous Training of LLMs with Data Removal and Access-Control Guarantees",
      "title_zh": "Adapter",
      "authors": [
        "William Fleshman",
        "Aleem Khan",
        "Marc Marone",
        "Benjamin Van Durme"
      ],
      "abstract": "Large language models (LLMs) are increasingly capable of completing knowledge\nintensive tasks by recalling information from a static pretraining corpus. Here\nwe are concerned with LLMs in the context of evolving data requirements. For\ninstance: batches of new data that are introduced periodically; subsets of data\nwith user-based access controls; or requirements on dynamic removal of\ndocuments with guarantees that associated knowledge cannot be recalled. We wish\nto satisfy these requirements while at the same time ensuring a model does not\nforget old information when new data becomes available. To address these\nissues, we introduce AdapterSwap, a training and inference scheme that\norganizes knowledge from a data collection into a set of low-rank adapters,\nwhich are dynamically composed during inference. Our experiments demonstrate\nAdapterSwap's ability to support efficient continual learning, while also\nenabling organizations to have fine-grained control over data access and\ndeletion.",
      "tldr_zh": "这篇论文介绍了 AdapterSwap，一种针对大型语言模型 (LLMs) 的持续训练方案，旨在处理动态数据需求，如定期引入新数据、用户-based 访问控制，以及文档移除后确保相关知识不可召回，同时防止模型遗忘旧信息。AdapterSwap 通过将知识组织成一组低秩适配器 (low-rank adapters)，并在推理时动态组合这些适配器，实现高效的持续学习。实验结果表明，该方法支持细粒度的数据访问和删除控制，为 LLMs 在演变数据环境中的应用提供了可靠保障。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "In Proceedings of the Conference on Applied Machine Learning in\n  Information Security, 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08417v2",
      "published_date": "2024-04-12 12:06:02 UTC",
      "updated_date": "2025-02-09 21:25:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:58:42.525921"
    },
    {
      "arxiv_id": "2404.08414v1",
      "title": "Evolutionary Preference Sampling for Pareto Set Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Rongguang Ye",
        "Longcan Chen",
        "Jinyuan Zhang",
        "Hisao Ishibuchi"
      ],
      "abstract": "Recently, Pareto Set Learning (PSL) has been proposed for learning the entire\nPareto set using a neural network. PSL employs preference vectors to scalarize\nmultiple objectives, facilitating the learning of mappings from preference\nvectors to specific Pareto optimal solutions. Previous PSL methods have shown\ntheir effectiveness in solving artificial multi-objective optimization problems\n(MOPs) with uniform preference vector sampling. The quality of the learned\nPareto set is influenced by the sampling strategy of the preference vector, and\nthe sampling of the preference vector needs to be decided based on the Pareto\nfront shape. However, a fixed preference sampling strategy cannot\nsimultaneously adapt the Pareto front of multiple MOPs. To address this\nlimitation, this paper proposes an Evolutionary Preference Sampling (EPS)\nstrategy to efficiently sample preference vectors. Inspired by evolutionary\nalgorithms, we consider preference sampling as an evolutionary process to\ngenerate preference vectors for neural network training. We integrate the EPS\nstrategy into five advanced PSL methods. Extensive experiments demonstrate that\nour proposed method has a faster convergence speed than baseline algorithms on\n7 testing problems. Our implementation is available at\nhttps://github.com/rG223/EPS.",
      "tldr_zh": "该论文针对 Pareto Set Learning (PSL) 方法提出了一种 Evolutionary Preference Sampling (EPS) 策略，以优化偏好向量的采样过程。EPS 受进化算法启发，将偏好向量采样视为进化过程，从而更好地适应多目标优化问题 (MOPs) 的 Pareto 前沿形状，并将其整合到五个先进的 PSL 方法中。实验结果显示，该策略在 7 个测试问题上比基线算法具有更快的收敛速度，为高效学习 Pareto 集提供了新途径。开源实现可访问 https://github.com/rG223/EPS。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Genetic and Evolutionary Computation Conference (GECCO '24)",
      "pdf_url": "http://arxiv.org/pdf/2404.08414v1",
      "published_date": "2024-04-12 11:58:13 UTC",
      "updated_date": "2024-04-12 11:58:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:58:54.684133"
    },
    {
      "arxiv_id": "2404.08412v2",
      "title": "PiRD: Physics-informed Residual Diffusion for Flow Field Reconstruction",
      "title_zh": "PiRD：基于物理信息的残差扩散用于流场重建",
      "authors": [
        "Siming Shan",
        "Pengkai Wang",
        "Song Chen",
        "Jiaxu Liu",
        "Chao Xu",
        "Shengze Cai"
      ],
      "abstract": "The use of machine learning in fluid dynamics is becoming more common to\nexpedite the computation when solving forward and inverse problems of partial\ndifferential equations. Yet, a notable challenge with existing convolutional\nneural network (CNN)-based methods for data fidelity enhancement is their\nreliance on specific low-fidelity data patterns and distributions during the\ntraining phase. In addition, the CNN-based method essentially treats the flow\nreconstruction task as a computer vision task that prioritizes the element-wise\nprecision which lacks a physical and mathematical explanation. This dependence\ncan dramatically affect the models' effectiveness in real-world scenarios,\nespecially when the low-fidelity input deviates from the training data or\ncontains noise not accounted for during training. The introduction of diffusion\nmodels in this context shows promise for improving performance and\ngeneralizability. Unlike direct mapping from a specific low-fidelity to a\nhigh-fidelity distribution, diffusion models learn to transition from any\nlow-fidelity distribution towards a high-fidelity one. Our proposed model -\nPhysics-informed Residual Diffusion, demonstrates the capability to elevate the\nquality of data from both standard low-fidelity inputs, to low-fidelity inputs\nwith injected Gaussian noise, and randomly collected samples. By integrating\nphysics-based insights into the objective function, it further refines the\naccuracy and the fidelity of the inferred high-quality data. Experimental\nresults have shown that our approach can effectively reconstruct high-quality\noutcomes for two-dimensional turbulent flows from a range of low-fidelity input\nconditions without requiring retraining.",
      "tldr_zh": "该论文针对流体力学中机器学习方法的局限性，提出了一种新模型Physics-informed Residual Diffusion (PiRD)，旨在解决现有CNN-based方法依赖特定低保真数据模式并缺乏物理解释的问题。PiRD利用扩散模型从任何低保真分布（如带Gaussian噪声的输入）过渡到高保真分布，并通过整合物理洞见到目标函数，提升重建的准确性和泛化性。实验结果显示，该方法无需重新训练即可有效重建二维湍流的高质量流场，从多种低保真输入条件下表现出色。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.08412v2",
      "published_date": "2024-04-12 11:45:51 UTC",
      "updated_date": "2024-05-09 15:30:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:59:06.068395"
    },
    {
      "arxiv_id": "2404.08408v1",
      "title": "Seismic First Break Picking in a Higher Dimension Using Deep Graph Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongtao Wang",
        "Li Long",
        "Jiangshe Zhang",
        "Xiaoli Wei",
        "Chunxia Zhang",
        "Zhenbo Guo"
      ],
      "abstract": "Contemporary automatic first break (FB) picking methods typically analyze 1D\nsignals, 2D source gathers, or 3D source-receiver gathers. Utilizing\nhigher-dimensional data, such as 2D or 3D, incorporates global features,\nimproving the stability of local picking. Despite the benefits,\nhigh-dimensional data requires structured input and increases computational\ndemands. Addressing this, we propose a novel approach using deep graph learning\ncalled DGL-FB, constructing a large graph to efficiently extract information.\nIn this graph, each seismic trace is represented as a node, connected by edges\nthat reflect similarities. To manage the size of the graph, we develop a\nsubgraph sampling technique to streamline model training and inference. Our\nproposed framework, DGL-FB, leverages deep graph learning for FB picking. It\nencodes subgraphs into global features using a deep graph encoder.\nSubsequently, the encoded global features are combined with local node signals\nand fed into a ResUNet-based 1D segmentation network for FB detection. Field\nsurvey evaluations of DGL-FB show superior accuracy and stability compared to a\n2D U-Net-based benchmark method.",
      "tldr_zh": "本文提出了一种名为DGL-FB的深度图学习方法，用于处理地震首次破裂（First Break）选取问题，通过利用更高维度数据（如2D或3D）整合全局特征来提升选取的稳定性和准确性。该框架构建一个大型图结构，其中每个地震示踪作为节点，边反映相似性，并采用子图采样技术简化训练和推理过程；随后，使用深度图编码器提取全局特征，并结合本地节点信号输入基于ResUNet的1D分割网络进行检测。与2D U-Net基准方法相比，DGL-FB在实地调查中表现出显著更高的准确性和稳定性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08408v1",
      "published_date": "2024-04-12 11:36:24 UTC",
      "updated_date": "2024-04-12 11:36:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:59:19.268245"
    },
    {
      "arxiv_id": "2404.08404v2",
      "title": "A Complexity Map of Probabilistic Reasoning for Neurosymbolic Classification Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Arthur Ledaguenel",
        "Céline Hudelot",
        "Mostepha Khouadjia"
      ],
      "abstract": "Neurosymbolic artificial intelligence is a growing field of research aiming\nto combine neural network learning capabilities with the reasoning abilities of\nsymbolic systems. Informed multi-label classification is a sub-field of\nneurosymbolic AI which studies how to leverage prior knowledge to improve\nneural classification systems. Recently, a family of neurosymbolic techniques\nfor informed classification based on probabilistic reasoning has gained\nsignificant traction. Unfortunately, depending on the language used to\nrepresent prior knowledge, solving certain probabilistic reasoning problems can\nbecome prohibitively hard when the number of classes increases. Therefore, the\nasymptotic complexity of probabilistic reasoning is of cardinal importance to\nassess the scalability of such techniques. In this paper, we develop a unified\nformalism for four probabilistic reasoning problems. Then, we compile several\nknown and new tractability results into a single complexity map of\nprobabilistic reasoning. We build on top of this complexity map to characterize\nthe domains of scalability of several techniques. We hope this work will help\nneurosymbolic AI practitioners navigate the scalability landscape of\nprobabilistic neurosymbolic techniques.",
      "tldr_zh": "本研究探讨了神经符号 AI (Neurosymbolic AI) 中概率推理的复杂性问题，特别是针对 informed multi-label classification 技术的可扩展性挑战。论文开发了一个统一的正式框架来处理四种概率推理问题，并编译了一个综合的复杂性地图，涵盖已知和新的可处理性结果。通过这个复杂性地图，作者表征了多种技术的可扩展性领域，帮助神经符号 AI 从业者评估和导航概率推理的规模化难题。",
      "categories": [
        "cs.AI",
        "cs.CC",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "36 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.08404v2",
      "published_date": "2024-04-12 11:31:37 UTC",
      "updated_date": "2025-01-23 09:52:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:59:30.679128"
    },
    {
      "arxiv_id": "2407.00743v1",
      "title": "AIMDiT: Modality Augmentation and Interaction via Multimodal Dimension Transformation for Emotion Recognition in Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Sheng Wu",
        "Jiaxing Liu",
        "Longbiao Wang",
        "Dongxiao He",
        "Xiaobao Wang",
        "Jianwu Dang"
      ],
      "abstract": "Emotion Recognition in Conversations (ERC) is a popular task in natural\nlanguage processing, which aims to recognize the emotional state of the speaker\nin conversations. While current research primarily emphasizes contextual\nmodeling, there exists a dearth of investigation into effective multimodal\nfusion methods. We propose a novel framework called AIMDiT to solve the problem\nof multimodal fusion of deep features. Specifically, we design a Modality\nAugmentation Network which performs rich representation learning through\ndimension transformation of different modalities and parameter-efficient\ninception block. On the other hand, the Modality Interaction Network performs\ninteraction fusion of extracted inter-modal features and intra-modal features.\nExperiments conducted using our AIMDiT framework on the public benchmark\ndataset MELD reveal 2.34% and 2.87% improvements in terms of the Acc-7 and w-F1\nmetrics compared to the state-of-the-art (SOTA) models.",
      "tldr_zh": "本文针对对话中的情感识别(ERC)问题，提出了一种新型框架AIMDiT，以解决多模态融合方法的不足。AIMDiT包括Modality Augmentation Network，通过多模态维度变换和参数高效的inception block进行丰富的表示学习，以及Modality Interaction Network来融合提取的模态间和模态内特征。实验在公共基准数据集MELD上进行，结果显示AIMDiT在Acc-7和w-F1指标上分别比最先进(SOTA)模型提高了2.34%和2.87%。这项工作为ERC的多模态处理提供了更有效的解决方案。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00743v1",
      "published_date": "2024-04-12 11:31:18 UTC",
      "updated_date": "2024-04-12 11:31:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:59:43.996594"
    },
    {
      "arxiv_id": "2404.08401v4",
      "title": "PnLCalib: Sports Field Registration via Points and Lines Optimization",
      "title_zh": "PnLCalib：通过点和线优化的体育场地配准",
      "authors": [
        "Marc Gutiérrez-Pérez",
        "Antonio Agudo"
      ],
      "abstract": "Camera calibration in broadcast sports videos presents numerous challenges\nfor accurate sports field registration due to multiple camera angles, varying\ncamera parameters, and frequent occlusions of the field. Traditional\nsearch-based methods depend on initial camera pose estimates, which can\nstruggle in non-standard positions and dynamic environments. In response, we\npropose an optimization-based calibration pipeline that leverages a 3D soccer\nfield model and a predefined set of keypoints to overcome these limitations.\nOur method also introduces a novel refinement module that improves initial\ncalibration by using detected field lines in a non-linear optimization process.\nThis approach outperforms existing techniques in both multi-view and\nsingle-view 3D camera calibration tasks, while maintaining competitive\nperformance in homography estimation. Extensive experimentation on real-world\nsoccer datasets, including SoccerNet-Calibration, WorldCup 2014, and\nTS-WorldCup, highlights the robustness and accuracy of our method across\ndiverse broadcast scenarios. Our approach offers significant improvements in\ncamera calibration precision and reliability.",
      "tldr_zh": "本研究提出PnLCalib，一种基于Points and Lines Optimization的优化框架，用于解决广播体育视频中相机校准的挑战，如多个相机角度、参数变化和场地遮挡问题。该方法利用3D足球场模型和预定义关键点进行初始校准，并引入一个新颖的精炼模块，通过检测的场线进行非线性优化，提升校准精度。在多视图和单视图3D camera calibration任务中，PnLCalib优于现有技术，同时在homography estimation中保持竞争性能；实验在SoccerNet-Calibration、WorldCup 2014和TS-WorldCup数据集上验证了其鲁棒性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2; I.4; I.5"
      ],
      "primary_category": "cs.CV",
      "comment": "Extended version of \"No Bells, Just Whistles: Sports Field\n  Registration Leveraging Geometric Properties\"",
      "pdf_url": "http://arxiv.org/pdf/2404.08401v4",
      "published_date": "2024-04-12 11:15:15 UTC",
      "updated_date": "2024-10-24 14:41:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T23:59:54.851853"
    },
    {
      "arxiv_id": "2404.08398v1",
      "title": "Multi-Agent eXperimenter (MAX)",
      "title_zh": "翻译失败",
      "authors": [
        "Önder Gürcan"
      ],
      "abstract": "We present a novel multi-agent simulator named Multi-Agent eXperimenter (MAX)\nthat is designed to simulate blockchain experiments involving large numbers of\nagents of different types acting in one or several environments. The\narchitecture of MAX is highly modular, enabling easy addition of new models.",
      "tldr_zh": "我们提出了一种新型多智能体模拟器 Multi-Agent eXperimenter (MAX)，旨在模拟区块链实验中大量不同类型 agents 的行为，这些 agents 在一个或多个环境中互动。MAX 采用高度模块化的架构，便于用户轻松添加新模型。这种设计为区块链实验的模拟提供了灵活性和扩展性，提升了实验效率和可适应性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.MA",
      "comment": "3 pages, no figures",
      "pdf_url": "http://arxiv.org/pdf/2404.08398v1",
      "published_date": "2024-04-12 11:07:10 UTC",
      "updated_date": "2024-04-12 11:07:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:00:05.769898"
    },
    {
      "arxiv_id": "2404.08382v2",
      "title": "Look at the Text: Instruction-Tuned Language Models are More Robust Multiple Choice Selectors than You Think",
      "title_zh": "翻译失败",
      "authors": [
        "Xinpeng Wang",
        "Chengzhi Hu",
        "Bolei Ma",
        "Paul Röttger",
        "Barbara Plank"
      ],
      "abstract": "Multiple choice questions (MCQs) are commonly used to evaluate the\ncapabilities of large language models (LLMs). One common way to evaluate the\nmodel response is to rank the candidate answers based on the log probability of\nthe first token prediction. An alternative way is to examine the text output.\nPrior work has shown that first token probabilities lack robustness to changes\nin MCQ phrasing, and that first token probabilities do not match text answers\nfor instruction-tuned models. Therefore, in this paper, we investigate the\nrobustness of text answers. We show that the text answers are more robust to\nquestion perturbations than the first token probabilities, when the first token\nanswers mismatch the text answers. The difference in robustness increases as\nthe mismatch rate becomes greater. As the mismatch reaches over 50\\%, the text\nanswer is more robust to option order changes than the debiased first token\nprobabilities using state-of-the-art debiasing methods such as PriDe. Our\nfindings provide further evidence for the benefits of text answer evaluation\nover first token probability evaluation.",
      "tldr_zh": "这篇论文探讨了指令调整语言模型在多选题 (MCQs) 评估中的鲁棒性，比较了文本答案与基于第一个 token 概率的评估方法。研究发现，当第一个 token 答案与文本答案不匹配时，文本答案对问题扰动更具鲁棒性，且这种差异随着不匹配率增加而放大。特别地，当不匹配率超过 50%，文本答案比使用先进去偏置方法（如 PriDe）的概率评估更能抵抗选项顺序变化，为优先采用文本答案评估提供了有力证据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08382v2",
      "published_date": "2024-04-12 10:36:15 UTC",
      "updated_date": "2024-08-20 08:07:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:00:19.545090"
    },
    {
      "arxiv_id": "2404.08376v1",
      "title": "Graph data augmentation with Gromow-Wasserstein Barycenters",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Ponti"
      ],
      "abstract": "Graphs are ubiquitous in various fields, and deep learning methods have been\nsuccessful applied in graph classification tasks. However, building large and\ndiverse graph datasets for training can be expensive. While augmentation\ntechniques exist for structured data like images or numerical data, the\naugmentation of graph data remains challenging. This is primarily due to the\ncomplex and non-Euclidean nature of graph data. In this paper, it has been\nproposed a novel augmentation strategy for graphs that operates in a\nnon-Euclidean space. This approach leverages graphon estimation, which models\nthe generative mechanism of networks sequences. Computational results\ndemonstrate the effectiveness of the proposed augmentation framework in\nimproving the performance of graph classification models. Additionally, using a\nnon-Euclidean distance, specifically the Gromow-Wasserstein distance, results\nin better approximations of the graphon. This framework also provides a means\nto validate different graphon estimation approaches, particularly in real-world\nscenarios where the true graphon is unknown.",
      "tldr_zh": "该论文针对图数据增强的挑战提出了一种新颖策略，该策略在非欧空间中操作，以解决图数据的复杂性和生成机制建模问题。方法利用图on估计来模拟网络序列的生成过程，并结合Gromov-Wasserstein距离实现更好的图on近似，从而生成多样化的增强数据。实验结果表明，该框架显著提高了图分类模型的性能，并在真实场景中为验证不同图on估计方法提供了有效手段。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.08376v1",
      "published_date": "2024-04-12 10:22:55 UTC",
      "updated_date": "2024-04-12 10:22:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:00:31.940080"
    },
    {
      "arxiv_id": "2404.08361v2",
      "title": "Large-Scale Multi-Domain Recommendation: an Automatic Domain Feature Extraction and Personalized Integration Framework",
      "title_zh": "大规模多域推荐：自动域特征提取和个性化集成框架",
      "authors": [
        "Dongbo Xi",
        "Zhen Chen",
        "Yuexian Wang",
        "He Cui",
        "Chong Peng",
        "Fuzhen Zhuang",
        "Peng Yan"
      ],
      "abstract": "Feed recommendation is currently the mainstream mode for many real-world\napplications (e.g., TikTok, Dianping), it is usually necessary to model and\npredict user interests in multiple scenarios (domains) within and even outside\nthe application. Multi-domain learning is a typical solution in this regard.\nWhile considerable efforts have been made in this regard, there are still two\nlong-standing challenges: (1) Accurately depicting the differences among\ndomains using domain features is crucial for enhancing the performance of each\ndomain. However, manually designing domain features and models for numerous\ndomains can be a laborious task. (2) Users typically have limited impressions\nin only a few domains. Extracting features automatically from other domains and\nleveraging them to improve the predictive capabilities of each domain has\nconsistently posed a challenging problem. In this paper, we propose an\nAutomatic Domain Feature Extraction and Personalized Integration (DFEI)\nframework for the large-scale multi-domain recommendation. The framework\nautomatically transforms the behavior of each individual user into an\naggregation of all user behaviors within the domain, which serves as the domain\nfeatures. Unlike offline feature engineering methods, the extracted domain\nfeatures are higher-order representations and directly related to the target\nlabel. Besides, by personalized integration of domain features from other\ndomains for each user and the innovation in the training mode, the DFEI\nframework can yield more accurate conversion identification. Experimental\nresults on both public and industrial datasets, consisting of over 20 domains,\nclearly demonstrate that the proposed framework achieves significantly better\nperformance compared with SOTA baselines. Furthermore, we have released the\nsource code of the proposed framework at https://github.com/xidongbo/DFEI.",
      "tldr_zh": "该论文针对大规模多域推荐系统，解决了手动设计域特征的繁琐性和从其他域提取特征以提升用户预测能力的难题。DFEI框架自动将每个用户的行为聚合为域特征，这些特征是高阶表示，直接与目标标签相关，并通过个性化整合其他域的特征以及创新训练模式，提高转换识别准确性。在超过20个域的公共和工业数据集上，DFEI显著优于SOTA baselines，并开源了框架代码。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.08361v2",
      "published_date": "2024-04-12 09:57:17 UTC",
      "updated_date": "2024-04-15 01:50:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:00:45.357843"
    },
    {
      "arxiv_id": "2404.08359v1",
      "title": "Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Juraj Vladika",
        "Florian Matthes"
      ],
      "abstract": "In today's digital world, seeking answers to health questions on the Internet\nis a common practice. However, existing question answering (QA) systems often\nrely on using pre-selected and annotated evidence documents, thus making them\ninadequate for addressing novel questions. Our study focuses on the open-domain\nQA setting, where the key challenge is to first uncover relevant evidence in\nlarge knowledge bases. By utilizing the common retrieve-then-read QA pipeline\nand PubMed as a trustworthy collection of medical research documents, we answer\nhealth questions from three diverse datasets. We modify different retrieval\nsettings to observe their influence on the QA pipeline's performance, including\nthe number of retrieved documents, sentence selection process, the publication\nyear of articles, and their number of citations. Our results reveal that\ncutting down on the amount of retrieved documents and favoring more recent and\nhighly cited documents can improve the final macro F1 score up to 10%. We\ndiscuss the results, highlight interesting examples, and outline challenges for\nfuture research, like managing evidence disagreement and crafting user-friendly\nexplanations.",
      "tldr_zh": "本文研究了如何通过可靠且时间感知的证据检索来提升健康问答（QA）系统的性能，针对开放域 QA 设置中从大型知识库（如 PubMed）中检索相关证据的挑战。作者采用 retrieve-then-read QA pipeline，并测试了多种检索设置，包括减少检索文档数量、优先选择较新出版和高引用文章，结果显示这些优化可将宏 F1 分数提高高达 10%。此外，论文讨论了实际案例，并指出了未来研究方向，如处理证据分歧和开发用户友好解释。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2404.08359v1",
      "published_date": "2024-04-12 09:56:12 UTC",
      "updated_date": "2024-04-12 09:56:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:00:57.555979"
    },
    {
      "arxiv_id": "2405.01440v1",
      "title": "A Review of Reward Functions for Reinforcement Learning in the context of Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Abouelazm",
        "Jonas Michel",
        "J. Marius Zoellner"
      ],
      "abstract": "Reinforcement learning has emerged as an important approach for autonomous\ndriving. A reward function is used in reinforcement learning to establish the\nlearned skill objectives and guide the agent toward the optimal policy. Since\nautonomous driving is a complex domain with partly conflicting objectives with\nvarying degrees of priority, developing a suitable reward function represents a\nfundamental challenge. This paper aims to highlight the gap in such function\ndesign by assessing different proposed formulations in the literature and\ndividing individual objectives into Safety, Comfort, Progress, and Traffic\nRules compliance categories. Additionally, the limitations of the reviewed\nreward functions are discussed, such as objectives aggregation and indifference\nto driving context. Furthermore, the reward categories are frequently\ninadequately formulated and lack standardization. This paper concludes by\nproposing future research that potentially addresses the observed shortcomings\nin rewards, including a reward validation framework and structured rewards that\nare context-aware and able to resolve conflicts.",
      "tldr_zh": "这篇论文回顾了在自动驾驶（Autonomous Driving）背景下，Reinforcement Learning 中的奖励函数（Reward Functions）的设计挑战，强调了处理复杂且部分冲突目标的重要性。论文评估了文献中各种奖励函数的方案，并将目标分类为 Safety、Comfort、Progress 和 Traffic Rules compliance 等类别，同时讨论了这些函数的局限性，如目标聚合问题、对驾驶环境的 indifference 以及缺乏标准化。最终，论文提出未来研究方向，包括开发奖励验证框架和上下文感知的结构化奖励，以解决现有不足并提升强化学习的应用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at \"Interaction-driven Behavior Prediction and Planning for\n  Autonomous Vehicles\" workshop in 35th IEEE Intelligent Vehicles Symposium (IV\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.01440v1",
      "published_date": "2024-04-12 08:32:54 UTC",
      "updated_date": "2024-04-12 08:32:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:01:09.467402"
    },
    {
      "arxiv_id": "2404.08322v1",
      "title": "BOND: Bootstrapping From-Scratch Name Disambiguation with Multi-task Promoting",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqing Cheng",
        "Bo Chen",
        "Fanjin Zhang",
        "Jie Tang"
      ],
      "abstract": "From-scratch name disambiguation is an essential task for establishing a\nreliable foundation for academic platforms. It involves partitioning documents\nauthored by identically named individuals into groups representing distinct\nreal-life experts. Canonically, the process is divided into two decoupled\ntasks: locally estimating the pairwise similarities between documents followed\nby globally grouping these documents into appropriate clusters. However, such a\ndecoupled approach often inhibits optimal information exchange between these\nintertwined tasks. Therefore, we present BOND, which bootstraps the local and\nglobal informative signals to promote each other in an end-to-end regime.\nSpecifically, BOND harnesses local pairwise similarities to drive global\nclustering, subsequently generating pseudo-clustering labels. These global\nsignals further refine local pairwise characterizations. The experimental\nresults establish BOND's superiority, outperforming other advanced baselines by\na substantial margin. Moreover, an enhanced version, BOND+, incorporating\nensemble and post-match techniques, rivals the top methods in the WhoIsWho\ncompetition.",
      "tldr_zh": "该论文提出BOND框架，用于从零开始的name disambiguation任务，该任务旨在将相同姓名的文档分组为代表不同真实专家的聚类。BOND通过多任务促进机制，在端-to-end模式下引导local pairwise similarities和global clustering相互提升：先利用本地成对相似度驱动全局聚类生成伪聚类标签，然后用这些标签优化本地特征。实验结果显示，BOND显著优于高级基线方法，而增强版BOND+结合集成和后匹配技术，在WhoIsWho竞赛中与顶级方法相当。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "H.3.7; H.3.3"
      ],
      "primary_category": "cs.SI",
      "comment": "TheWebConf 2024 (WWW '24)",
      "pdf_url": "http://arxiv.org/pdf/2404.08322v1",
      "published_date": "2024-04-12 08:28:52 UTC",
      "updated_date": "2024-04-12 08:28:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:01:20.207836"
    },
    {
      "arxiv_id": "2404.08313v1",
      "title": "The Integration of Semantic and Structural Knowledge in Knowledge Graph Entity Typing",
      "title_zh": "翻译失败",
      "authors": [
        "Muzhi Li",
        "Minda Hu",
        "Irwin King",
        "Ho-fung Leung"
      ],
      "abstract": "The Knowledge Graph Entity Typing (KGET) task aims to predict missing type\nannotations for entities in knowledge graphs. Recent works only utilize the\n\\textit{\\textbf{structural knowledge}} in the local neighborhood of entities,\ndisregarding \\textit{\\textbf{semantic knowledge}} in the textual\nrepresentations of entities, relations, and types that are also crucial for\ntype inference. Additionally, we observe that the interaction between semantic\nand structural knowledge can be utilized to address the false-negative problem.\nIn this paper, we propose a novel \\textbf{\\underline{S}}emantic and\n\\textbf{\\underline{S}}tructure-aware KG \\textbf{\\underline{E}}ntity\n\\textbf{\\underline{T}}yping~{(SSET)} framework, which is composed of three\nmodules. First, the \\textit{Semantic Knowledge Encoding} module encodes factual\nknowledge in the KG with a Masked Entity Typing task. Then, the\n\\textit{Structural Knowledge Aggregation} module aggregates knowledge from the\nmulti-hop neighborhood of entities to infer missing types. Finally, the\n\\textit{Unsupervised Type Re-ranking} module utilizes the inference results\nfrom the two models above to generate type predictions that are robust to\nfalse-negative samples. Extensive experiments show that SSET significantly\noutperforms existing state-of-the-art methods.",
      "tldr_zh": "这篇论文针对Knowledge Graph Entity Typing (KGET)任务，提出了一种整合语义知识和结构知识的方法，以解决现有模型忽略实体、关系和类型文本表示的问题，并利用二者交互来处理false-negative问题。论文引入了SSET框架，包括三个模块：Semantic Knowledge Encoding（通过Masked Entity Typing任务编码KG中的事实知识）、Structural Knowledge Aggregation（从实体的多跳邻居中聚合知识推断缺失类型），以及Unsupervised Type Re-ranking（基于前两模块的结果生成对假阴性鲁棒的类型预测）。实验结果表明，SSET框架显著优于现有最先进方法，提升了实体类型预测的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in NAACL2024 main",
      "pdf_url": "http://arxiv.org/pdf/2404.08313v1",
      "published_date": "2024-04-12 08:17:44 UTC",
      "updated_date": "2024-04-12 08:17:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:01:34.098726"
    },
    {
      "arxiv_id": "2406.11865v1",
      "title": "Artificial Intelligence in Everyday Life 2.0: Educating University Students from Different Majors",
      "title_zh": "人工智能在日常生活 2.0：教育不同专业的大学学生",
      "authors": [
        "Maria Kasinidou",
        "Styliani Kleanthous",
        "Matteo Busso",
        "Marcelo Rodas",
        "Jahna Otterbacher",
        "Fausto Giunchiglia"
      ],
      "abstract": "With the surge in data-centric AI and its increasing capabilities, AI\napplications have become a part of our everyday lives. However,\nmisunderstandings regarding their capabilities, limitations, and associated\nadvantages and disadvantages are widespread. Consequently, in the university\nsetting, there is a crucial need to educate not only computer science majors\nbut also students from various disciplines about AI. In this experience report,\nwe present an overview of an introductory course that we offered to students\ncoming from different majors. Moreover, we discuss the assignments and quizzes\nof the course, which provided students with a firsthand experience of AI\nprocesses and insights into their learning patterns. Additionally, we provide a\nsummary of the course evaluation, as well as students' performance. Finally, we\npresent insights gained from teaching this course and elaborate on our future\nplans.",
      "tldr_zh": "这篇论文探讨了 AI 在日常生活中的误解问题，强调大学教育需针对计算机 science 及其他专业学生进行 AI 知识普及。该研究报告了一个入门课程的设计，包括作业和测验，让学生亲身参与 AI 过程并洞察其学习模式。课程评估总结了学生表现和教学insights，并提出了未来改进计划。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "7 pages, ITiCSE conference",
      "pdf_url": "http://arxiv.org/pdf/2406.11865v1",
      "published_date": "2024-04-12 08:10:42 UTC",
      "updated_date": "2024-04-12 08:10:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:01:44.285855"
    },
    {
      "arxiv_id": "2404.08309v1",
      "title": "Subtoxic Questions: Dive Into Attitude Change of LLM's Response in Jailbreak Attempts",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Zhang",
        "Zixuan Zhao",
        "Jiaqi Huang",
        "Jingyu Hua",
        "Sheng Zhong"
      ],
      "abstract": "As Large Language Models (LLMs) of Prompt Jailbreaking are getting more and\nmore attention, it is of great significance to raise a generalized research\nparadigm to evaluate attack strengths and a basic model to conduct subtler\nexperiments. In this paper, we propose a novel approach by focusing on a set of\ntarget questions that are inherently more sensitive to jailbreak prompts,\naiming to circumvent the limitations posed by enhanced LLM security. Through\ndesigning and analyzing these sensitive questions, this paper reveals a more\neffective method of identifying vulnerabilities in LLMs, thereby contributing\nto the advancement of LLM security. This research not only challenges existing\njailbreaking methodologies but also fortifies LLMs against potential exploits.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）的提示越狱（Prompt Jailbreaking）问题，提出一种新方法，通过设计一组对越狱提示更敏感的目标问题，来评估攻击强度并进行更细致的实验，从而绕过增强LLM安全限制。研究揭示，这种聚焦敏感问题的策略能更有效地识别LLMs的漏洞，并挑战现有越狱方法。最终，该工作有助于提升LLMs的安全性，为模型防护提供重要贡献。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "4 pages, 2 figures. This paper was submitted to The 7th Deep Learning\n  Security and Privacy Workshop (DLSP 2024) and was accepted as extended\n  abstract, see https://dlsp2024.ieee-security.org/",
      "pdf_url": "http://arxiv.org/pdf/2404.08309v1",
      "published_date": "2024-04-12 08:08:44 UTC",
      "updated_date": "2024-04-12 08:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:01:55.835140"
    },
    {
      "arxiv_id": "2404.08295v1",
      "title": "Study of Emotion Concept Formation by Integrating Vision, Physiology, and Word Information using Multilayered Multimodal Latent Dirichlet Allocation",
      "title_zh": "翻译失败",
      "authors": [
        "Kazuki Tsurumaki",
        "Chie Hieida",
        "Kazuki Miyazawa"
      ],
      "abstract": "How are emotions formed? Through extensive debate and the promulgation of\ndiverse theories , the theory of constructed emotion has become prevalent in\nrecent research on emotions. According to this theory, an emotion concept\nrefers to a category formed by interoceptive and exteroceptive information\nassociated with a specific emotion. An emotion concept stores past experiences\nas knowledge and can predict unobserved information from acquired information.\nTherefore, in this study, we attempted to model the formation of emotion\nconcepts using a constructionist approach from the perspective of the\nconstructed emotion theory. Particularly, we constructed a model using\nmultilayered multimodal latent Dirichlet allocation , which is a probabilistic\ngenerative model. We then trained the model for each subject using vision,\nphysiology, and word information obtained from multiple people who experienced\ndifferent visual emotion-evoking stimuli. To evaluate the model, we verified\nwhether the formed categories matched human subjectivity and determined whether\nunobserved information could be predicted via categories. The verification\nresults exceeded chance level, suggesting that emotion concept formation can be\nexplained by the proposed model.",
      "tldr_zh": "本研究基于 constructed emotion theory，探讨了情绪概念的形成过程，通过整合视觉、生理和词汇信息来模拟个体对情绪刺激的响应。研究采用 Multilayered Multimodal Latent Dirichlet Allocation 模型作为概率生成框架，对多位受试者的数据进行训练，形成与 interoceptive and exteroceptive information 相关的类别。实验结果表明，该模型能准确匹配人类主观性并预测未观察信息，超过了随机水平，从而为情绪概念的建构主义解释提供了实证支持。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.RO",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been submitted to the IEEE for possible publication. We\n  would like to thank Professor Takayuki Nagai for useful discussions",
      "pdf_url": "http://arxiv.org/pdf/2404.08295v1",
      "published_date": "2024-04-12 07:34:46 UTC",
      "updated_date": "2024-04-12 07:34:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:02:08.717719"
    },
    {
      "arxiv_id": "2404.08285v2",
      "title": "A Survey of Neural Network Robustness Assessment in Image Recognition",
      "title_zh": "神经网络稳健性评估在图像识别中的调查",
      "authors": [
        "Jie Wang",
        "Jun Ai",
        "Minyan Lu",
        "Haoran Su",
        "Dan Yu",
        "Yutao Zhang",
        "Junda Zhu",
        "Jingyu Liu"
      ],
      "abstract": "In recent years, there has been significant attention given to the robustness\nassessment of neural networks. Robustness plays a critical role in ensuring\nreliable operation of artificial intelligence (AI) systems in complex and\nuncertain environments. Deep learning's robustness problem is particularly\nsignificant, highlighted by the discovery of adversarial attacks on image\nclassification models. Researchers have dedicated efforts to evaluate\nrobustness in diverse perturbation conditions for image recognition tasks.\nRobustness assessment encompasses two main techniques: robustness verification/\ncertification for deliberate adversarial attacks and robustness testing for\nrandom data corruptions. In this survey, we present a detailed examination of\nboth adversarial robustness (AR) and corruption robustness (CR) in neural\nnetwork assessment. Analyzing current research papers and standards, we provide\nan extensive overview of robustness assessment in image recognition. Three\nessential aspects are analyzed: concepts, metrics, and assessment methods. We\ninvestigate the perturbation metrics and range representations used to measure\nthe degree of perturbations on images, as well as the robustness metrics\nspecifically for the robustness conditions of classification models. The\nstrengths and limitations of the existing methods are also discussed, and some\npotential directions for future research are provided.",
      "tldr_zh": "这篇调查论文审视了神经网络在图像识别任务中的鲁棒性评估，强调了鲁棒性在确保AI系统可靠性的关键作用，特别是面对对抗攻击和数据腐败。论文详细分析了对抗鲁棒性(AR)和腐败鲁棒性(CR)两种主要技术，包括概念、指标（如扰动指标和鲁棒性指标）以及评估方法，并讨论了现有方法的优势、局限性。最终，论文为未来研究提供了潜在方向，以提升神经网络的整体鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CV",
      "comment": "Corrected typos and grammatical errors in Section 5",
      "pdf_url": "http://arxiv.org/pdf/2404.08285v2",
      "published_date": "2024-04-12 07:19:16 UTC",
      "updated_date": "2024-04-15 10:50:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:02:19.891007"
    },
    {
      "arxiv_id": "2404.08263v2",
      "title": "Relational Prompt-based Pre-trained Language Models for Social Event Detection",
      "title_zh": "基于关系提示的预训练语言模型用于社会事件检测",
      "authors": [
        "Pu Li",
        "Xiaoyan Yu",
        "Hao Peng",
        "Yantuan Xian",
        "Linqin Wang",
        "Li Sun",
        "Jingyun Zhang",
        "Philip S. Yu"
      ],
      "abstract": "Social Event Detection (SED) aims to identify significant events from social\nstreams, and has a wide application ranging from public opinion analysis to\nrisk management. In recent years, Graph Neural Network (GNN) based solutions\nhave achieved state-of-the-art performance. However, GNN-based methods often\nstruggle with missing and noisy edges between messages, affecting the quality\nof learned message embedding. Moreover, these methods statically initialize\nnode embedding before training, which, in turn, limits the ability to learn\nfrom message texts and relations simultaneously. In this paper, we approach\nsocial event detection from a new perspective based on Pre-trained Language\nModels (PLMs), and present RPLM_SED (Relational prompt-based Pre-trained\nLanguage Models for Social Event Detection). We first propose a new pairwise\nmessage modeling strategy to construct social messages into message pairs with\nmulti-relational sequences. Secondly, a new multi-relational prompt-based\npairwise message learning mechanism is proposed to learn more comprehensive\nmessage representation from message pairs with multi-relational prompts using\nPLMs. Thirdly, we design a new clustering constraint to optimize the encoding\nprocess by enhancing intra-cluster compactness and inter-cluster dispersion,\nmaking the message representation more distinguishable. We evaluate the\nRPLM_SED on three real-world datasets, demonstrating that the RPLM_SED model\nachieves state-of-the-art performance in offline, online, low-resource, and\nlong-tail distribution scenarios for social event detection tasks.",
      "tldr_zh": "该论文针对 Social Event Detection (SED) 任务，提出了一种基于 Pre-trained Language Models (PLMs) 的新方法 RPLM_SED，以解决 Graph Neural Network (GNN) 方法中消息嵌入质量受缺失和噪声边影响的问题，以及静态节点初始化限制。RPLM_SED 包括三个关键创新：pairwise message modeling 策略将社交消息构建为带有多关系序列的消息对；多关系提示-based 的消息学习机制使用 PLMs 从消息对中提取更全面的表示；以及 clustering constraint 通过增强 intra-cluster compactness 和 inter-cluster dispersion 来优化编码过程，提高消息区分度。在三个真实数据集上的实验表明，RPLM_SED 在离线、在线、低资源和长尾分布场景中实现了 state-of-the-art 性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACM TOIS",
      "pdf_url": "http://arxiv.org/pdf/2404.08263v2",
      "published_date": "2024-04-12 06:23:07 UTC",
      "updated_date": "2024-09-10 09:14:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:02:33.715972"
    },
    {
      "arxiv_id": "2404.08262v3",
      "title": "Pretraining and Updates of Domain-Specific LLM: A Case Study in the Japanese Business Domain",
      "title_zh": "特定领域LLM的预训练和更新：",
      "authors": [
        "Kosuke Takahashi",
        "Takahiro Omi",
        "Kosuke Arima",
        "Tatsuya Ishigaki"
      ],
      "abstract": "The development of Large Language Models (LLMs) in various languages has been\nadvancing, but the combination of non-English languages with domain-specific\ncontexts remains underexplored. This paper presents our findings from training\nand evaluating a Japanese business domain-specific LLM designed to better\nunderstand business-related documents, such as the news on current affairs,\ntechnical reports, and patents. Additionally, LLMs in this domain require\nregular updates to incorporate the most recent knowledge. Therefore, we also\nreport our findings from the first experiments and evaluations involving\nupdates to this LLM using the latest article data, which is an important\nproblem setting that has not been addressed in previous research. From our\nexperiments on a newly created benchmark dataset for question answering in the\ntarget domain, we found that (1) our pretrained model improves QA accuracy\nwithout losing general knowledge, and (2) a proper mixture of the latest and\nolder texts in the training data for the update is necessary. Our pretrained\nmodel and business domain benchmark are publicly available to support further\nstudies.",
      "tldr_zh": "本研究探讨了在日语商业领域训练特定LLM（Large Language Models）的过程，包括预训练和更新策略，以更好地处理商业相关文档如新闻、技术报告和专利。研究者创建了一个新基准数据集进行问答实验，发现预训练模型提高了QA准确率，同时保留了一般知识，且更新训练数据时需要适当混合最新和旧文本，以优化性能。该工作首次解决了LLM在非英语领域的更新问题，并公开了预训练模型和基准数据集，以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at PACLIC 38",
      "pdf_url": "http://arxiv.org/pdf/2404.08262v3",
      "published_date": "2024-04-12 06:21:48 UTC",
      "updated_date": "2024-11-06 16:19:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:02:47.098151"
    },
    {
      "arxiv_id": "2404.08242v1",
      "title": "RLEMMO: Evolutionary Multimodal Optimization Assisted By Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongqiao Lian",
        "Zeyuan Ma",
        "Hongshu Guo",
        "Ting Huang",
        "Yue-Jiao Gong"
      ],
      "abstract": "Solving multimodal optimization problems (MMOP) requires finding all optimal\nsolutions, which is challenging in limited function evaluations. Although\nexisting works strike the balance of exploration and exploitation through\nhand-crafted adaptive strategies, they require certain expert knowledge, hence\ninflexible to deal with MMOP with different properties. In this paper, we\npropose RLEMMO, a Meta-Black-Box Optimization framework, which maintains a\npopulation of solutions and incorporates a reinforcement learning agent for\nflexibly adjusting individual-level searching strategies to match the\nup-to-date optimization status, hence boosting the search performance on MMOP.\nConcretely, we encode landscape properties and evolution path information into\neach individual and then leverage attention networks to advance population\ninformation sharing. With a novel reward mechanism that encourages both quality\nand diversity, RLEMMO can be effectively trained using a policy gradient\nalgorithm. The experimental results on the CEC2013 MMOP benchmark underscore\nthe competitive optimization performance of RLEMMO against several strong\nbaselines.",
      "tldr_zh": "本研究针对多模态优化问题（MMOP），提出了一种名为 RLEMMO 的 Meta-Black-Box Optimization 框架，利用 Deep Reinforcement Learning 辅助进化优化，以克服现有方法依赖专家知识的不灵活性。RLEMMO 通过维护解决方案种群、编码景观属性和进化路径信息，并使用注意力网络实现种群信息共享，同时采用一个鼓励质量和多样性的奖励机制，以及策略梯度算法进行训练，从而灵活调整个体级搜索策略。实验结果在 CEC2013 MMOP 基准上显示，RLEMMO 与多个强基线相比表现出竞争力的优化性能，提升了探索和利用的平衡。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted as full paper at GECCO 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08242v1",
      "published_date": "2024-04-12 05:02:49 UTC",
      "updated_date": "2024-04-12 05:02:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:02:59.552716"
    },
    {
      "arxiv_id": "2404.08239v1",
      "title": "Auto-configuring Exploration-Exploitation Tradeoff in Evolutionary Computation via Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyuan Ma",
        "Jiacheng Chen",
        "Hongshu Guo",
        "Yining Ma",
        "Yue-Jiao Gong"
      ],
      "abstract": "Evolutionary computation (EC) algorithms, renowned as powerful black-box\noptimizers, leverage a group of individuals to cooperatively search for the\noptimum. The exploration-exploitation tradeoff (EET) plays a crucial role in\nEC, which, however, has traditionally been governed by manually designed rules.\nIn this paper, we propose a deep reinforcement learning-based framework that\nautonomously configures and adapts the EET throughout the EC search process.\nThe framework allows different individuals of the population to selectively\nattend to the global and local exemplars based on the current search state,\nmaximizing the cooperative search outcome. Our proposed framework is\ncharacterized by its simplicity, effectiveness, and generalizability, with the\npotential to enhance numerous existing EC algorithms. To validate its\ncapabilities, we apply our framework to several representative EC algorithms\nand conduct extensive experiments on the augmented CEC2021 benchmark. The\nresults demonstrate significant improvements in the performance of the backbone\nalgorithms, as well as favorable generalization across diverse problem classes,\ndimensions, and population sizes. Additionally, we provide an in-depth analysis\nof the EET issue by interpreting the learned behaviors of EC.",
      "tldr_zh": "本研究提出了一种基于深度强化学习的框架，用于自动配置和适应进化计算（EC）中的探索-利用权衡（EET），以优化种群个体的合作搜索。框架允许个体根据当前搜索状态选择关注全局或本地样本，从而实现简单、有效且可泛化的增强效果。在增强的 CEC2021 基准实验中，该框架显著提高了多种 EC 算法的性能，并在不同问题类别、维度和种群规模上表现出色，同时通过深入分析解释了 EET 的行为。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted as a full paper at GECCO 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.08239v1",
      "published_date": "2024-04-12 04:48:32 UTC",
      "updated_date": "2024-04-12 04:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:03:12.253722"
    },
    {
      "arxiv_id": "2404.08237v1",
      "title": "IFViT: Interpretable Fixed-Length Representation for Fingerprint Matching via Vision Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhang Qiu",
        "Honghui Chen",
        "Xingbo Dong",
        "Zheng Lin",
        "Iman Yi Liao",
        "Massimo Tistarelli",
        "Zhe Jin"
      ],
      "abstract": "Determining dense feature points on fingerprints used in constructing deep\nfixed-length representations for accurate matching, particularly at the pixel\nlevel, is of significant interest. To explore the interpretability of\nfingerprint matching, we propose a multi-stage interpretable fingerprint\nmatching network, namely Interpretable Fixed-length Representation for\nFingerprint Matching via Vision Transformer (IFViT), which consists of two\nprimary modules. The first module, an interpretable dense registration module,\nestablishes a Vision Transformer (ViT)-based Siamese Network to capture\nlong-range dependencies and the global context in fingerprint pairs. It\nprovides interpretable dense pixel-wise correspondences of feature points for\nfingerprint alignment and enhances the interpretability in the subsequent\nmatching stage. The second module takes into account both local and global\nrepresentations of the aligned fingerprint pair to achieve an interpretable\nfixed-length representation extraction and matching. It employs the ViTs\ntrained in the first module with the additional fully connected layer and\nretrains them to simultaneously produce the discriminative fixed-length\nrepresentation and interpretable dense pixel-wise correspondences of feature\npoints. Extensive experimental results on diverse publicly available\nfingerprint databases demonstrate that the proposed framework not only exhibits\nsuperior performance on dense registration and matching but also significantly\npromotes the interpretability in deep fixed-length representations-based\nfingerprint matching.",
      "tldr_zh": "本研究提出IFViT框架，这是一种基于Vision Transformer (ViT)的可解释指纹匹配网络，旨在通过多阶段处理提升指纹匹配的准确性和解释性。框架包括两个模块：第一个是可解释的密集注册模块，使用ViT-based Siamese Network捕捉指纹对的长程依赖和全局上下文，提供密集像素级对应关系以实现指纹对齐；第二个模块则在对齐基础上提取局部和全局表示，并通过添加全连接层重新训练，以生成判别性的固定长度表示和可解释对应关系。实验在多个公开指纹数据库上显示，IFViT在密集注册和匹配方面表现出色，并显著提高了深度固定长度表示的解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ready to submit to IEEE Transactions on Information Forensics and\n  Security (TIFS)",
      "pdf_url": "http://arxiv.org/pdf/2404.08237v1",
      "published_date": "2024-04-12 04:44:11 UTC",
      "updated_date": "2024-04-12 04:44:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:03:23.218799"
    },
    {
      "arxiv_id": "2404.08233v2",
      "title": "Generalized Population-Based Training for Hyperparameter Optimization in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Bai",
        "Ran Cheng"
      ],
      "abstract": "Hyperparameter optimization plays a key role in the machine learning domain.\nIts significance is especially pronounced in reinforcement learning (RL), where\nagents continuously interact with and adapt to their environments, requiring\ndynamic adjustments in their learning trajectories. To cater to this\ndynamicity, the Population-Based Training (PBT) was introduced, leveraging the\ncollective intelligence of a population of agents learning simultaneously.\nHowever, PBT tends to favor high-performing agents, potentially neglecting the\nexplorative potential of agents on the brink of significant advancements. To\nmitigate the limitations of PBT, we present the Generalized Population-Based\nTraining (GPBT), a refined framework designed for enhanced granularity and\nflexibility in hyperparameter adaptation. Complementing GPBT, we further\nintroduce Pairwise Learning (PL). Instead of merely focusing on elite agents,\nPL employs a comprehensive pairwise strategy to identify performance\ndifferentials and provide holistic guidance to underperforming agents. By\nintegrating the capabilities of GPBT and PL, our approach significantly\nimproves upon traditional PBT in terms of adaptability and computational\nefficiency. Rigorous empirical evaluations across a range of RL benchmarks\nconfirm that our approach consistently outperforms not only the conventional\nPBT but also its Bayesian-optimized variant.",
      "tldr_zh": "该论文针对强化学习(Reinforcement Learning, RL)中的超参数优化问题，提出了一种改进的Generalized Population-Based Training (GPBT)框架，以提升适应性和灵活性，解决传统Population-Based Training (PBT)偏好高性能代理而忽略探索潜力的局限。GPBT结合了Pairwise Learning (PL)方法，通过成对策略分析性能差异并为表现不佳的代理提供全面指导，从而提高整体计算效率。实验结果显示，该方法在多种RL基准测试中显著优于传统PBT及其Bayesian-optimized变体，证明了其在动态学习环境中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "IEEE Transactions on Emerging Topics in Computational Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2404.08233v2",
      "published_date": "2024-04-12 04:23:20 UTC",
      "updated_date": "2024-04-23 03:28:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:03:34.857728"
    },
    {
      "arxiv_id": "2404.08224v2",
      "title": "HCL-MTSAD: Hierarchical Contrastive Consistency Learning for Accurate Detection of Industrial Multivariate Time Series Anomalies",
      "title_zh": "翻译失败",
      "authors": [
        "Haili Sun",
        "Yan Huang",
        "Lansheng Han",
        "Cai Fu",
        "Chunjie Zhou"
      ],
      "abstract": "Multivariate Time Series (MTS) anomaly detection focuses on pinpointing\nsamples that diverge from standard operational patterns, which is crucial for\nensuring the safety and security of industrial applications. The primary\nchallenge in this domain is to develop representations capable of discerning\nanomalies effectively. The prevalent methods for anomaly detection in the\nliterature are predominantly reconstruction-based and predictive in nature.\nHowever, they typically concentrate on a single-dimensional instance level,\nthereby not fully harnessing the complex associations inherent in industrial\nMTS. To address this issue, we propose a novel self-supervised hierarchical\ncontrastive consistency learning method for detecting anomalies in MTS, named\nHCL-MTSAD. It innovatively leverages data consistency at multiple levels\ninherent in industrial MTS, systematically capturing consistent associations\nacross four latent levels-measurement, sample, channel, and process. By\ndeveloping a multi-layer contrastive loss, HCL-MTSAD can extensively mine data\nconsistency and spatio-temporal association, resulting in more informative\nrepresentations. Subsequently, an anomaly discrimination module, grounded in\nself-supervised hierarchical contrastive learning, is designed to detect\ntimestamp-level anomalies by calculating multi-scale data consistency.\nExtensive experiments conducted on six diverse MTS datasets retrieved from real\ncyber-physical systems and server machines, in comparison with 20 baselines,\nindicate that HCL-MTSAD's anomaly detection capability outperforms the\nstate-of-the-art benchmark models by an average of 1.8\\% in terms of F1 score.",
      "tldr_zh": "这篇论文针对工业多变量时间序列 (Multivariate Time Series, MTS) 异常检测问题，提出了一种新型自监督方法HCL-MTSAD，以捕捉MTS中measurement、sample、channel和process等多个层面的数据一致性和时空关联。HCL-MTSAD通过多层对比损失 (multi-layer contrastive loss) 进行分层对比一致性学习，生成更具信息性的表示，并设计了一个基于自监督学习的异常鉴别模块来计算多尺度数据一致性，从而实现时间戳级别的精确异常检测。在六个真实工业数据集上的实验中，与20个基线模型相比，HCL-MTSAD在F1分数上平均提高了1.8%，显著提升了异常检测性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.IT",
        "cs.SY",
        "eess.SY",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is a manuscript that is still in the process of revision,\n  including Table 1, Figure 2, problem definition in section III.B and method\n  description proposed in section IV. In addition, the submitter has not been\n  authorized by the first author and other co-authors to post the paper to\n  arXiv",
      "pdf_url": "http://arxiv.org/pdf/2404.08224v2",
      "published_date": "2024-04-12 03:39:33 UTC",
      "updated_date": "2024-04-18 04:15:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:03:47.572897"
    },
    {
      "arxiv_id": "2404.08189v1",
      "title": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Patrice Béchard",
        "Orlando Marquez Ayala"
      ],
      "abstract": "A common and fundamental limitation of Generative AI (GenAI) is its\npropensity to hallucinate. While large language models (LLM) have taken the\nworld by storm, without eliminating or at least reducing hallucinations,\nreal-world GenAI systems may face challenges in user adoption. In the process\nof deploying an enterprise application that produces workflows based on natural\nlanguage requirements, we devised a system leveraging Retrieval Augmented\nGeneration (RAG) to greatly improve the quality of the structured output that\nrepresents such workflows. Thanks to our implementation of RAG, our proposed\nsystem significantly reduces hallucinations in the output and improves the\ngeneralization of our LLM in out-of-domain settings. In addition, we show that\nusing a small, well-trained retriever encoder can reduce the size of the\naccompanying LLM, thereby making deployments of LLM-based systems less\nresource-intensive.",
      "tldr_zh": "该论文探讨了生成式 AI (GenAI) 中幻觉 (hallucination) 问题的根本限制，特别是大型语言模型 (LLM) 在实际应用中的挑战。研究提出了一种基于 Retrieval Augmented Generation (RAG) 的系统，用于生成基于自然语言需求的结构化工作流程，从而显著减少输出中的幻觉并提升 LLM 在领域外场景的泛化能力。此外，通过采用小型、训练良好的检索器编码器，该系统降低了 LLM 的规模，使部署更高效且资源密集度更低。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "To be presented at NAACL 2024. 11 pages and 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.08189v1",
      "published_date": "2024-04-12 01:42:09 UTC",
      "updated_date": "2024-04-12 01:42:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:03:58.144310"
    },
    {
      "arxiv_id": "2404.15182v1",
      "title": "FLoRA: Enhancing Vision-Language Models with Parameter-Efficient Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Duy Phuong Nguyen",
        "J. Pablo Munoz",
        "Ali Jannesari"
      ],
      "abstract": "In the rapidly evolving field of artificial intelligence, multimodal models,\ne.g., integrating vision and language into visual-language models (VLMs), have\nbecome pivotal for many applications, ranging from image captioning to\nmultimodal search engines. Among these models, the Contrastive Language-Image\nPre-training (CLIP) model has demonstrated remarkable performance in\nunderstanding and generating nuanced relationships between text and images.\nHowever, the conventional training of such models often requires centralized\naggregation of vast datasets, posing significant privacy and data governance\nchallenges. To address these concerns, this paper proposes a novel approach\nthat leverages Federated Learning and parameter-efficient adapters, i.e.,\nLow-Rank Adaptation (LoRA), to train VLMs. This methodology preserves data\nprivacy by training models across decentralized data sources and ensures model\nadaptability and efficiency through LoRA's parameter-efficient fine-tuning. Our\napproach accelerates training time by up to 34.72 times and requires 2.47 times\nless memory usage than full fine-tuning.",
      "tldr_zh": "该论文提出 FLoRA 方法，通过结合 Parameter-Efficient Federated Learning 和 Low-Rank Adaptation (LoRA)，来增强 Vision-Language Models (VLMs) 的训练过程。FLoRA 利用分布式数据源进行模型训练，从而解决传统集中式训练中的数据隐私和治理挑战。相比全微调，该方法可将训练时间加速高达 34.72 倍，并减少 2.47 倍的内存使用，为高效且隐私友好的多模态模型开发提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.15182v1",
      "published_date": "2024-04-12 00:36:43 UTC",
      "updated_date": "2024-04-12 00:36:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:04:10.099267"
    },
    {
      "arxiv_id": "2404.08164v2",
      "title": "Language Model Prompt Selection via Simulation Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Haoting Zhang",
        "Jinghai He",
        "Rhonda Righter",
        "Zeyu Zheng"
      ],
      "abstract": "With the advancement in generative language models, the selection of prompts\nhas gained significant attention in recent years. A prompt is an instruction or\ndescription provided by the user, serving as a guide for the generative\nlanguage model in content generation. Despite existing methods for prompt\nselection that are based on human labor, we consider facilitating this\nselection through simulation optimization, aiming to maximize a pre-defined\nscore for the selected prompt. Specifically, we propose a two-stage framework.\nIn the first stage, we determine a feasible set of prompts in sufficient\nnumbers, where each prompt is represented by a moderate-dimensional vector. In\nthe subsequent stage for evaluation and selection, we construct a surrogate\nmodel of the score regarding the moderate-dimensional vectors that represent\nthe prompts. We propose sequentially selecting the prompt for evaluation based\non this constructed surrogate model. We prove the consistency of the sequential\nevaluation procedure in our framework. We also conduct numerical experiments to\ndemonstrate the efficacy of our proposed framework, providing practical\ninstructions for implementation.",
      "tldr_zh": "该研究探讨了通过模拟优化(Simulation Optimization)来选择语言模型的提示(Prompt)，以最大化预定义的分数，从而减少对人工依赖。框架分为两个阶段：首先生成足够数量的可行提示集，每个提示用中等维度的向量表示；其次构建一个代理模型(Surrogate Model)来评估这些向量，并基于此模型顺序选择提示进行评估。作者证明了这一顺序评估过程的一致性(Consistency)，并通过数值实验验证了框架的有效性，提供实际实施指导。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08164v2",
      "published_date": "2024-04-12 00:03:56 UTC",
      "updated_date": "2024-05-20 02:34:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:04:21.957790"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 79,
  "processed_papers_count": 79,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T00:04:46.306503"
}