{
  "date": "2024-01-16",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-16 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 和机器学习的创新应用，包括大型语言模型（LLMs）的鲁棒性、多模态模型的进展、强化学习在复杂任务中的优化，以及图像处理和医疗诊断的实际改进。其中，Ida Momennejad 的记忆与规划论文（Memory, Space, and Planning）令人印象深刻，探讨了认知映射在 AI 规划中的作用，而 Yining Hong 的 MultiPLY 论文则展示了多模态 LLM 在 3D 环境中的潜力。其他值得关注的是涉及 LLMs 鲁棒性的工作，以及在医疗 AI 中的公平性讨论，这些论文可能引发更广泛的学术和伦理话题。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊那些重要、相关且有话题度的（如 AI 生成、强化学习和医疗应用），其他次要论文快速掠过。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### 重点 AI 生成和多模态模型\n- **MultiPLY: A Multisensory Object-Centric Embodied Large Language Model in 3D World（中文：多感官物体中心嵌入式大型语言模型在 3D 世界中）**  \n  Yining Hong 等人的论文提出 MultiPLY，一种多模态 LLM，能处理视觉、音频、触觉和热感数据，实现物体交互和任务分解。主要贡献是通过多感官数据生成和强化学习，提升 AI 在 3D 环境中的感知和规划能力，实验在多种任务上表现出色。\n\n- **MMToM-QA: Multimodal Theory of Mind Question Answering（中文：多模态理论心智问答）**  \n  Chuanyang Jin 等的研究开发了 MMToM-QA 基准和 BIP-ALM 方法，用于多模态理论心智推理。关键发现是，BIP-ALM 通过贝叶斯逆规划和语言模型融合，提高了 LLM 在多模态任务中的表现，远超基线模型，在人类认知模拟方面有潜力。\n\n- **Fixed Point Diffusion Models（中文：固定点扩散模型）**  \n  Xingjian Bai 和 Luke Melas-Kyriazi 的工作引入固定点扩散模型，优化图像生成过程。贡献在于减少参数和内存使用，同时提高生成质量，实验在 ImageNet 等数据集上超越 DiT 模型，适用于高效生成任务。\n\n- **EgoGen: An Egocentric Synthetic Data Generator（中文：自我中心合成数据生成器）**  \n  这篇论文提出 EgoGen，用于生成自我中心视角数据，支持无人机和机器人应用。核心是结合人类运动合成模型和强化学习，生成高质量数据，提升视觉任务性能。\n\n### 强化学习和优化方向\n- **REValueD: Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes（中文：因子化马尔可夫决策过程的正则化集成价值分解）**  \n  David Ireland 和 Giovanni Montana 的研究针对高维离散动作空间的强化学习，提出 REValueD 算法。发现通过集成批评家和正则化损失，显著减少偏差并提升性能，在 DeepMind Control Suite 上优于基线。\n\n- **Learning from Sparse Offline Datasets via Conservative Density Estimation（中文：通过保守密度估计从稀疏离线数据集学习）**  \n  这篇论文引入 CDE 方法，用于离线强化学习。贡献在于解决分布外推错误，实验在 D4RL 基准上超越现有方法，尤其在稀疏奖励任务中表现出色。\n\n- **AgentMixer: Multi-Agent Correlated Policy Factorization（中文：多代理相关策略因子化）**  \n  该工作提出 AgentMixer，提升多代理强化学习的协调性。关键发现是通过相关均衡和注意力机制，实现高效策略融合，实验在多种基准上优于 SOTA 方法。\n\n### 医疗和图像处理应用\n- **Hidden flaws behind expert-level accuracy of multimodal GPT-4 vision in medicine（中文：多模态 GPT-4 视觉在医疗中的专家级准确性背后的隐藏缺陷）**  \n  这篇论文分析 GPT-4V 在医疗图像任务中的理性解释问题。发现尽管多选准确率高，但图像理解和推理存在缺陷，强调需进一步评估 LLM 在临床中的鲁棒性。\n\n- **Fairness Concerns in App Reviews: A Study on AI-based Mobile Apps（中文：AI 移动应用评论中的公平性担忧）**  \n  研究揭示 AI 应用评论中的公平问题，提出检测模型。贡献在于使用机器学习识别公平性类型，提升 AI 应用的伦理设计。\n\n其他论文，如水动力学优化（Water-Based Metaheuristics）和特定领域如交通预测（MA2GCN），虽有技术贡献但相对次要，我仅快速提到：这些工作探索了元启发式算法和交通数据建模，但影响力有限，适合专业领域应用。\n\n总之，今天的论文突显 AI 模型的鲁棒性和实际应用潜力，LLMs 和多模态方向尤其值得跟踪。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2401.08887v1",
      "title": "NOTSOFAR-1 Challenge: New Datasets, Baseline, and Tasks for Distant Meeting Transcription",
      "title_zh": "翻译失败",
      "authors": [
        "Alon Vinnikov",
        "Amir Ivry",
        "Aviv Hurvitz",
        "Igor Abramovski",
        "Sharon Koubi",
        "Ilya Gurvich",
        "Shai Pe`er",
        "Xiong Xiao",
        "Benjamin Martinez Elizalde",
        "Naoyuki Kanda",
        "Xiaofei Wang",
        "Shalev Shaer",
        "Stav Yagev",
        "Yossi Asher",
        "Sunit Sivasankaran",
        "Yifan Gong",
        "Min Tang",
        "Huaming Wang",
        "Eyal Krupka"
      ],
      "abstract": "We introduce the first Natural Office Talkers in Settings of Far-field Audio\nRecordings (``NOTSOFAR-1'') Challenge alongside datasets and baseline system.\nThe challenge focuses on distant speaker diarization and automatic speech\nrecognition (DASR) in far-field meeting scenarios, with single-channel and\nknown-geometry multi-channel tracks, and serves as a launch platform for two\nnew datasets: First, a benchmarking dataset of 315 meetings, averaging 6\nminutes each, capturing a broad spectrum of real-world acoustic conditions and\nconversational dynamics. It is recorded across 30 conference rooms, featuring\n4-8 attendees and a total of 35 unique speakers. Second, a 1000-hour simulated\ntraining dataset, synthesized with enhanced authenticity for real-world\ngeneralization, incorporating 15,000 real acoustic transfer functions. The\ntasks focus on single-device DASR, where multi-channel devices always share the\nsame known geometry. This is aligned with common setups in actual conference\nrooms, and avoids technical complexities associated with multi-device tasks. It\nalso allows for the development of geometry-specific solutions. The NOTSOFAR-1\nChallenge aims to advance research in the field of distant conversational\nspeech recognition, providing key resources to unlock the potential of\ndata-driven methods, which we believe are currently constrained by the absence\nof comprehensive high-quality training and benchmarking datasets.",
      "tldr_zh": "我们引入了 NOTSOFAR-1 Challenge，这是一个针对远场会议转录的新挑战赛，提供了两个数据集和基线系统，焦点在于远场说话人识别和自动语音识别（DASR），包括单通道和已知几何多通道轨道。第一个数据集是一个由 315 个会议组成的基准数据集，每个会议平均 6 分钟，记录于 30 个会议室，涉及 4-8 名参与者和 35 个独特说话人，覆盖广泛的真实世界声学条件和对话动态。第二个数据集是一个 1000 小时的模拟训练数据集，使用 15,000 个真实声学传输函数合成，以提升模型的真实世界泛化能力。该挑战赛旨在通过这些资源推动数据驱动方法的远场对话语音识别研究，解决当前高质量训练和基准数据集缺失的问题。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2401.08887v1",
      "published_date": "2024-01-16 23:50:26 UTC",
      "updated_date": "2024-01-16 23:50:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:04:07.830556"
    },
    {
      "arxiv_id": "2401.08879v2",
      "title": "Contribution Functions for Quantitative Bipolar Argumentation Graphs: A Principle-based Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Timotheus Kampik",
        "Nico Potyka",
        "Xiang Yin",
        "Kristijonas Čyras",
        "Francesca Toni"
      ],
      "abstract": "We present a principle-based analysis of contribution functions for\nquantitative bipolar argumentation graphs that quantify the contribution of one\nargument to another. The introduced principles formalise the intuitions\nunderlying different contribution functions as well as expectations one would\nhave regarding the behaviour of contribution functions in general. As none of\nthe covered contribution functions satisfies all principles, our analysis can\nserve as a tool that enables the selection of the most suitable function based\non the requirements of a given use case.",
      "tldr_zh": "这篇论文对量化双极论点图（Quantitative Bipolar Argumentation Graphs）中的贡献函数（Contribution Functions）进行了基于原则的分析，这些函数用于量化一个论点对另一个论点的贡献。论文引入了一系列原则，以形式化不同贡献函数背后的直觉以及对这些函数一般行为的期望。分析结果表明，没有任何一种贡献函数能满足所有原则，从而为根据特定用例需求选择最合适的函数提供了实用工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08879v2",
      "published_date": "2024-01-16 23:27:42 UTC",
      "updated_date": "2024-06-13 22:07:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:04:16.284704"
    },
    {
      "arxiv_id": "2401.08875v2",
      "title": "DCRMTA: Unbiased Causal Representation for Multi-touch Attribution",
      "title_zh": "DCRMTA：多触点归因的无偏因果表示",
      "authors": [
        "Jiaming Tang"
      ],
      "abstract": "Multi-touch attribution (MTA) currently plays a pivotal role in achieving a\nfair estimation of the contributions of each advertising touchpoint to-wards\nconversion behavior, deeply influencing budget allocation and advertising\nrecommenda-tion. Previous works attempted to eliminate the bias caused by user\npreferences to achieve the unbiased assumption of the conversion model. The\nmulti-model collaboration method is not ef-ficient, and the complete\nelimination of user in-fluence also eliminates the causal effect of user\nfeatures on conversion, resulting in limited per-formance of the conversion\nmodel. This paper re-defines the causal effect of user features on con-versions\nand proposes a novel end-to-end ap-proach, Deep Causal Representation for MTA\n(DCRMTA). Our model focuses on extracting causa features between conversions\nand users while eliminating confounding variables. Fur-thermore, extensive\nexperiments demonstrate DCRMTA's superior performance in converting prediction\nacross varying data distributions, while also effectively attributing value\nacross dif-ferent advertising channels.",
      "tldr_zh": "本文提出 DCRMTA，一种端到端方法，用于多触点归因 (Multi-touch Attribution, MTA)，旨在通过重新定义用户特征对转化的因果效应，实现无偏的因果表示，同时提取转换和用户之间的因果特征并消除混杂变量 (confounding variables)。这解决了现有方法在消除用户偏好偏差时效率低下且忽略用户特征因果效应的局限性。实验结果表明，DCRMTA 在不同数据分布下的转换预测性能优越，并在不同广告渠道的归因方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.08875v2",
      "published_date": "2024-01-16 23:16:18 UTC",
      "updated_date": "2024-02-05 08:43:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:04:30.080944"
    },
    {
      "arxiv_id": "2401.08863v1",
      "title": "Robust Localization of Key Fob Using Channel Impulse Response of Ultra Wide Band Sensors for Keyless Entry Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Abhiram Kolli",
        "Filippo Casamassima",
        "Horst Possegger",
        "Horst Bischof"
      ],
      "abstract": "Using neural networks for localization of key fob within and surrounding a\ncar as a security feature for keyless entry is fast emerging. In this paper we\nstudy: 1) the performance of pre-computed features of neural networks based UWB\n(ultra wide band) localization classification forming the baseline of our\nexperiments. 2) Investigate the inherent robustness of various neural networks;\ntherefore, we include the study of robustness of the adversarial examples\nwithout any adversarial training in this work. 3) Propose a multi-head\nself-supervised neural network architecture which outperforms the baseline\nneural networks without any adversarial training. The model's performance\nimproved by 67% at certain ranges of adversarial magnitude for fast gradient\nsign method and 37% each for basic iterative method and projected gradient\ndescent method.",
      "tldr_zh": "这篇论文研究了使用UWB（Ultra Wide Band）传感器的通道脉冲响应来实现钥匙遥控器（key fob）的鲁棒定位，以提升无钥匙进入系统的安全性。作者首先评估了基于预计算特征的神经网络定位分类作为基线，并调查了各种神经网络对对抗样本（adversarial examples）的固有鲁棒性，而不依赖对抗训练。最终，他们提出了一种多头自监督神经网络架构，该架构在没有对抗训练的情况下，显著提升了性能：在fast gradient sign method下的某些对抗幅度提升67%，以及在basic iterative method和projected gradient descent method下各提升37%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08863v1",
      "published_date": "2024-01-16 22:35:14 UTC",
      "updated_date": "2024-01-16 22:35:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:04:42.600340"
    },
    {
      "arxiv_id": "2401.08850v2",
      "title": "REValueD: Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes",
      "title_zh": "翻译失败",
      "authors": [
        "David Ireland",
        "Giovanni Montana"
      ],
      "abstract": "Discrete-action reinforcement learning algorithms often falter in tasks with\nhigh-dimensional discrete action spaces due to the vast number of possible\nactions. A recent advancement leverages value-decomposition, a concept from\nmulti-agent reinforcement learning, to tackle this challenge. This study delves\ndeep into the effects of this value-decomposition, revealing that whilst it\ncurtails the over-estimation bias inherent to Q-learning algorithms, it\namplifies target variance. To counteract this, we present an ensemble of\ncritics to mitigate target variance. Moreover, we introduce a regularisation\nloss that helps to mitigate the effects that exploratory actions in one\ndimension can have on the value of optimal actions in other dimensions. Our\nnovel algorithm, REValueD, tested on discretised versions of the DeepMind\nControl Suite tasks, showcases superior performance, especially in the\nchallenging humanoid and dog tasks. We further dissect the factors influencing\nREValueD's performance, evaluating the significance of the regularisation loss\nand the scalability of REValueD with increasing sub-actions per dimension.",
      "tldr_zh": "这篇论文针对高维离散动作空间中的强化学习问题，分析了 value-decomposition 方法如何减少 Q-learning 的过估计偏差，但同时增加了目标方差。作者提出 REValueD 算法，通过 ensemble of critics 缓解目标方差，并引入 regularisation loss 来减少一个维度探索动作对其他维度最优动作价值的影响。在 DeepMind Control Suite 的离散化任务上，REValueD 展现出卓越性能，尤其在 humanoid 和 dog 任务中。最后，论文评估了 regularisation loss 的重要性和算法的可扩展性，随着每个维度子动作数量的增加。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR camera ready version",
      "pdf_url": "http://arxiv.org/pdf/2401.08850v2",
      "published_date": "2024-01-16 21:47:23 UTC",
      "updated_date": "2024-03-08 10:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:04:54.801041"
    },
    {
      "arxiv_id": "2401.09491v2",
      "title": "Memory, Space, and Planning: Multiscale Predictive Representations",
      "title_zh": "记忆、空间和规划：多尺度预测表征",
      "authors": [
        "Ida Momennejad"
      ],
      "abstract": "Memory is inherently entangled with prediction and planning. Flexible\nbehavior in biological and artificial agents depends on the interplay of\nlearning from the past and predicting the future in ever-changing environments.\nThis chapter reviews computational, behavioral, and neural evidence suggesting\nthese processes rely on learning the relational structure of experiences, known\nas cognitive maps, and draws two key takeaways. First, that these memory\nstructures are organized as multiscale, compact predictive representations in\nhippocampal and prefrontal cortex, or PFC, hierarchies. Second, we argue that\nsuch predictive memory structures are crucial to the complementary functions of\nthe hippocampus and PFC, both for enabling a recall of detailed and coherent\npast episodes as well as generalizing experiences at varying scales for\nefficient prediction and planning. These insights advance our understanding of\nmemory and planning mechanisms in the brain and hold significant implications\nfor advancing artificial intelligence systems.",
      "tldr_zh": "本论文探讨记忆、预测和规划之间的相互关联，回顾了计算、行为和神经证据，强调这些过程依赖于学习经验的关联结构，即 cognitive maps。关键发现是，这些记忆结构在 hippocampal 和 prefrontal cortex (PFC) 的层次中组织为 multiscale predictive representations，能够支持详细回忆过去事件并在不同尺度上泛化经验，以实现高效的预测和规划。该研究深化了对大脑记忆机制的理解，并为推进人工智能系统提供了重要启示。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To be published as a chapter in an edited volume by Oxford University\n  Press (Editors: Sara Aronowitz and Lynn Nadel)",
      "pdf_url": "http://arxiv.org/pdf/2401.09491v2",
      "published_date": "2024-01-16 21:46:43 UTC",
      "updated_date": "2024-02-19 21:01:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:05:04.918009"
    },
    {
      "arxiv_id": "2401.08819v2",
      "title": "Learning from Sparse Offline Datasets via Conservative Density Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhepeng Cen",
        "Zuxin Liu",
        "Zitong Wang",
        "Yihang Yao",
        "Henry Lam",
        "Ding Zhao"
      ],
      "abstract": "Offline reinforcement learning (RL) offers a promising direction for learning\npolicies from pre-collected datasets without requiring further interactions\nwith the environment. However, existing methods struggle to handle\nout-of-distribution (OOD) extrapolation errors, especially in sparse reward or\nscarce data settings. In this paper, we propose a novel training algorithm\ncalled Conservative Density Estimation (CDE), which addresses this challenge by\nexplicitly imposing constraints on the state-action occupancy stationary\ndistribution. CDE overcomes the limitations of existing approaches, such as the\nstationary distribution correction method, by addressing the support mismatch\nissue in marginal importance sampling. Our method achieves state-of-the-art\nperformance on the D4RL benchmark. Notably, CDE consistently outperforms\nbaselines in challenging tasks with sparse rewards or insufficient data,\ndemonstrating the advantages of our approach in addressing the extrapolation\nerror problem in offline RL.",
      "tldr_zh": "本论文探讨了离线强化学习（Offline RL）从稀疏数据集学习策略的问题，提出了一种名为Conservative Density Estimation (CDE)的新训练算法，以显式约束状态-动作占用平稳分布，解决现有方法在分布外（OOD）外推错误中的支持不匹配问题。CDE 通过改进边缘重要性采样，克服了传统平稳分布修正方法的局限性，在D4RL基准测试中实现了最先进性能。实验结果显示，CDE在稀疏奖励或数据不足的任务中持续优于基线模型，证明了其在处理Offline RL外推错误方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.08819v2",
      "published_date": "2024-01-16 20:42:15 UTC",
      "updated_date": "2024-03-11 14:43:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:05:17.218872"
    },
    {
      "arxiv_id": "2401.08815v1",
      "title": "Adversarial Supervision Makes Layout-to-Image Diffusion Models Thrive",
      "title_zh": "对抗监督使布局到图像扩散模型蓬勃发展",
      "authors": [
        "Yumeng Li",
        "Margret Keuper",
        "Dan Zhang",
        "Anna Khoreva"
      ],
      "abstract": "Despite the recent advances in large-scale diffusion models, little progress\nhas been made on the layout-to-image (L2I) synthesis task. Current L2I models\neither suffer from poor editability via text or weak alignment between the\ngenerated image and the input layout. This limits their usability in practice.\nTo mitigate this, we propose to integrate adversarial supervision into the\nconventional training pipeline of L2I diffusion models (ALDM). Specifically, we\nemploy a segmentation-based discriminator which provides explicit feedback to\nthe diffusion generator on the pixel-level alignment between the denoised image\nand the input layout. To encourage consistent adherence to the input layout\nover the sampling steps, we further introduce the multistep unrolling strategy.\nInstead of looking at a single timestep, we unroll a few steps recursively to\nimitate the inference process, and ask the discriminator to assess the\nalignment of denoised images with the layout over a certain time window. Our\nexperiments show that ALDM enables layout faithfulness of the generated images,\nwhile allowing broad editability via text prompts. Moreover, we showcase its\nusefulness for practical applications: by synthesizing target distribution\nsamples via text control, we improve domain generalization of semantic\nsegmentation models by a large margin (~12 mIoU points).",
      "tldr_zh": "这篇论文针对 layout-to-image (L2I) 扩散模型的文本编辑性差和图像布局对齐弱等问题，提出了 ALDM 方法，通过整合 adversarial supervision 来提升模型性能。具体而言，ALDM 采用基于分割的判别器提供像素级反馈，以及 multistep unrolling 策略来确保采样过程中的布局一致性。实验结果显示，该方法显著提高了生成图像的布局忠实度和文本编辑灵活性，并通过合成目标分布样本，大幅提升了语义分割模型的领域泛化能力，mIoU 指标改善约 12 点。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICLR 2024. Project page:\n  https://yumengli007.github.io/ALDM/ and code:\n  https://github.com/boschresearch/ALDM",
      "pdf_url": "http://arxiv.org/pdf/2401.08815v1",
      "published_date": "2024-01-16 20:31:46 UTC",
      "updated_date": "2024-01-16 20:31:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:05:30.724641"
    },
    {
      "arxiv_id": "2401.09489v1",
      "title": "PUPAE: Intuitive and Actionable Explanations for Time Series Anomalies",
      "title_zh": "PUPAE：时间序列异常的直观且可",
      "authors": [
        "Audrey Der",
        "Chin-Chia Michael Yeh",
        "Yan Zheng",
        "Junpeng Wang",
        "Zhongfang Zhuang",
        "Liang Wang",
        "Wei Zhang",
        "Eamonn J. Keogh"
      ],
      "abstract": "In recent years there has been significant progress in time series anomaly\ndetection. However, after detecting an (perhaps tentative) anomaly, can we\nexplain it? Such explanations would be useful to triage anomalies. For example,\nin an oil refinery, should we respond to an anomaly by dispatching a hydraulic\nengineer, or an intern to replace the battery on a sensor? There have been some\nparallel efforts to explain anomalies, however many proposed techniques produce\nexplanations that are indirect, and often seem more complex than the anomaly\nthey seek to explain. Our review of the literature/checklists/user-manuals used\nby frontline practitioners in various domains reveals an interesting\nnear-universal commonality. Most practitioners discuss, explain and report\nanomalies in the following format: The anomaly would be like normal data A, if\nnot for the corruption B. The reader will appreciate that is a type of\ncounterfactual explanation. In this work we introduce a domain agnostic\ncounterfactual explanation technique to produce explanations for time series\nanomalies. As we will show, our method can produce both visual and text-based\nexplanations that are objectively correct, intuitive and in many circumstances,\ndirectly actionable.",
      "tldr_zh": "这篇论文针对时间序列异常检测的进展，强调了异常解释的实际需求，例如在工业场景中快速判断响应措施。作者发现现有解释方法往往间接且复杂，而从业者常用一种反事实(counterfactual)格式：\"异常就像正常数据A，如果没有干扰B\"。论文引入PUPAE，一种通用的counterfactual explanation技术，能生成客观正确、直观且可操作的视觉和文本解释，从而帮助用户更有效地处理异常。实验结果显示，该方法在各种领域具有普适性，提升了异常处理的效率和可行动性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 Page Manuscript, 1 Page Supplementary (Supplement not published in\n  conference proceedings.)",
      "pdf_url": "http://arxiv.org/pdf/2401.09489v1",
      "published_date": "2024-01-16 20:13:46 UTC",
      "updated_date": "2024-01-16 20:13:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:05:40.958843"
    },
    {
      "arxiv_id": "2401.08577v1",
      "title": "MultiPLY: A Multisensory Object-Centric Embodied Large Language Model in 3D World",
      "title_zh": "翻译失败",
      "authors": [
        "Yining Hong",
        "Zishuo Zheng",
        "Peihao Chen",
        "Yian Wang",
        "Junyan Li",
        "Chuang Gan"
      ],
      "abstract": "Human beings possess the capability to multiply a melange of multisensory\ncues while actively exploring and interacting with the 3D world. Current\nmulti-modal large language models, however, passively absorb sensory data as\ninputs, lacking the capacity to actively interact with the objects in the 3D\nenvironment and dynamically collect their multisensory information. To usher in\nthe study of this area, we propose MultiPLY, a multisensory embodied large\nlanguage model that could incorporate multisensory interactive data, including\nvisual, audio, tactile, and thermal information into large language models,\nthereby establishing the correlation among words, actions, and percepts. To\nthis end, we first collect Multisensory Universe, a large-scale multisensory\ninteraction dataset comprising 500k data by deploying an LLM-powered embodied\nagent to engage with the 3D environment. To perform instruction tuning with\npre-trained LLM on such generated data, we first encode the 3D scene as\nabstracted object-centric representations and then introduce action tokens\ndenoting that the embodied agent takes certain actions within the environment,\nas well as state tokens that represent the multisensory state observations of\nthe agent at each time step. In the inference time, MultiPLY could generate\naction tokens, instructing the agent to take the action in the environment and\nobtain the next multisensory state observation. The observation is then\nappended back to the LLM via state tokens to generate subsequent text or action\ntokens. We demonstrate that MultiPLY outperforms baselines by a large margin\nthrough a diverse set of embodied tasks involving object retrieval, tool use,\nmultisensory captioning, and task decomposition.",
      "tldr_zh": "本文提出MultiPLY，一种多感官的具身LLM（Large Language Model），旨在让模型在3D世界中主动互动并整合视觉、音频、触觉和热感信息，建立词语、动作和感知之间的关联，以克服现有多模态LLM被动吸收数据的局限性。为此，研究团队收集了Multisensory Universe数据集，包含50万互动数据，并通过对象中心表示、动作token和状态token进行指令微调。实验结果表明，MultiPLY在物体检索、工具使用、多感官描述和任务分解等任务中大幅优于基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://vis-www.cs.umass.edu/multiply",
      "pdf_url": "http://arxiv.org/pdf/2401.08577v1",
      "published_date": "2024-01-16 18:59:45 UTC",
      "updated_date": "2024-01-16 18:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:05:53.623576"
    },
    {
      "arxiv_id": "2401.08743v2",
      "title": "MMToM-QA: Multimodal Theory of Mind Question Answering",
      "title_zh": "MMToM-QA：多模态心智理论问答",
      "authors": [
        "Chuanyang Jin",
        "Yutong Wu",
        "Jing Cao",
        "Jiannan Xiang",
        "Yen-Ling Kuo",
        "Zhiting Hu",
        "Tomer Ullman",
        "Antonio Torralba",
        "Joshua B. Tenenbaum",
        "Tianmin Shu"
      ],
      "abstract": "Theory of Mind (ToM), the ability to understand people's mental states, is an\nessential ingredient for developing machines with human-level social\nintelligence. Recent machine learning models, particularly large language\nmodels, seem to show some aspects of ToM understanding. However, existing ToM\nbenchmarks use unimodal datasets - either video or text. Human ToM, on the\nother hand, is more than video or text understanding. People can flexibly\nreason about another person's mind based on conceptual representations (e.g.,\ngoals, beliefs, plans) extracted from any available data. To address this, we\nintroduce a multimodal Theory of Mind question answering (MMToM-QA) benchmark.\nMMToM-QA comprehensively evaluates machine ToM both on multimodal data and on\ndifferent kinds of unimodal data about a person's activity in a household\nenvironment. To engineer multimodal ToM capacity, we propose a novel method,\nBIP-ALM (Bayesian Inverse Planning Accelerated by Language Models). BIP-ALM\nextracts unified representations from multimodal data and utilizes language\nmodels for scalable Bayesian inverse planning. We conducted a systematic\ncomparison of human performance, BIP-ALM, and state-of-the-art models,\nincluding GPT-4. The experiments demonstrate that large language models and\nlarge multimodal models still lack robust ToM capacity. BIP-ALM, on the other\nhand, shows promising results, by leveraging the power of both model-based\nmental inference and language models.",
      "tldr_zh": "该论文引入了 MMToM-QA 基准，用于全面评估机器的 Theory of Mind (ToM) 能力，即理解他人心理状态的关键社会智能要素，该基准涵盖多模态数据（如视频和文本）以及单模态数据，在家庭环境场景中测试机器对人类目标、信念和计划的推理。论文提出了一种新方法 BIP-ALM (Bayesian Inverse Planning Accelerated by Language Models)，它从多模态数据中提取统一表示，并结合 Language Models 进行可扩展的 Bayesian 逆向规划，以增强 ToM 推理。实验比较了人类、BIP-ALM 和如 GPT-4 的先进模型，结果表明大型语言模型和多模态模型在 ToM 方面缺乏稳健性，而 BIP-ALM 显示出显著的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ACL 2024. 26 pages, 11 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.08743v2",
      "published_date": "2024-01-16 18:59:24 UTC",
      "updated_date": "2024-06-15 10:13:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:06:08.631590"
    },
    {
      "arxiv_id": "2401.08741v1",
      "title": "Fixed Point Diffusion Models",
      "title_zh": "固定点扩散模型",
      "authors": [
        "Xingjian Bai",
        "Luke Melas-Kyriazi"
      ],
      "abstract": "We introduce the Fixed Point Diffusion Model (FPDM), a novel approach to\nimage generation that integrates the concept of fixed point solving into the\nframework of diffusion-based generative modeling. Our approach embeds an\nimplicit fixed point solving layer into the denoising network of a diffusion\nmodel, transforming the diffusion process into a sequence of closely-related\nfixed point problems. Combined with a new stochastic training method, this\napproach significantly reduces model size, reduces memory usage, and\naccelerates training. Moreover, it enables the development of two new\ntechniques to improve sampling efficiency: reallocating computation across\ntimesteps and reusing fixed point solutions between timesteps. We conduct\nextensive experiments with state-of-the-art models on ImageNet, FFHQ,\nCelebA-HQ, and LSUN-Church, demonstrating substantial improvements in\nperformance and efficiency. Compared to the state-of-the-art DiT model, FPDM\ncontains 87% fewer parameters, consumes 60% less memory during training, and\nimproves image generation quality in situations where sampling computation or\ntime is limited. Our code and pretrained models are available at\nhttps://lukemelas.github.io/fixed-point-diffusion-models.",
      "tldr_zh": "本研究提出Fixed Point Diffusion Models (FPDM)，一种将固定点求解概念融入扩散模型框架的新型图像生成方法，通过在去噪网络中嵌入隐式固定点求解层，将扩散过程转化为一系列相关联的固定点问题，并结合新的随机训练方法，显著减少模型参数、内存使用并加速训练。FPDM还引入两种新技巧——跨时间步重新分配计算和重用固定点解决方案——以提升采样效率。在ImageNet、FFHQ、CelebA-HQ和LSUN-Church数据集上的实验显示，与最先进DiT模型相比，FPDM参数减少87%、训练内存使用降低60%，并在计算或时间受限情况下改善图像生成质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page:\n  https://lukemelas.github.io/fixed-point-diffusion-models",
      "pdf_url": "http://arxiv.org/pdf/2401.08741v1",
      "published_date": "2024-01-16 18:55:54 UTC",
      "updated_date": "2024-01-16 18:55:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:06:19.786140"
    },
    {
      "arxiv_id": "2401.08739v2",
      "title": "EgoGen: An Egocentric Synthetic Data Generator",
      "title_zh": "翻译失败",
      "authors": [
        "Gen Li",
        "Kaifeng Zhao",
        "Siwei Zhang",
        "Xiaozhong Lyu",
        "Mihai Dusmanu",
        "Yan Zhang",
        "Marc Pollefeys",
        "Siyu Tang"
      ],
      "abstract": "Understanding the world in first-person view is fundamental in Augmented\nReality (AR). This immersive perspective brings dramatic visual changes and\nunique challenges compared to third-person views. Synthetic data has empowered\nthird-person-view vision models, but its application to embodied egocentric\nperception tasks remains largely unexplored. A critical challenge lies in\nsimulating natural human movements and behaviors that effectively steer the\nembodied cameras to capture a faithful egocentric representation of the 3D\nworld. To address this challenge, we introduce EgoGen, a new synthetic data\ngenerator that can produce accurate and rich ground-truth training data for\negocentric perception tasks. At the heart of EgoGen is a novel human motion\nsynthesis model that directly leverages egocentric visual inputs of a virtual\nhuman to sense the 3D environment. Combined with collision-avoiding motion\nprimitives and a two-stage reinforcement learning approach, our motion\nsynthesis model offers a closed-loop solution where the embodied perception and\nmovement of the virtual human are seamlessly coupled. Compared to previous\nworks, our model eliminates the need for a pre-defined global path, and is\ndirectly applicable to dynamic environments. Combined with our easy-to-use and\nscalable data generation pipeline, we demonstrate EgoGen's efficacy in three\ntasks: mapping and localization for head-mounted cameras, egocentric camera\ntracking, and human mesh recovery from egocentric views. EgoGen will be fully\nopen-sourced, offering a practical solution for creating realistic egocentric\ntraining data and aiming to serve as a useful tool for egocentric computer\nvision research. Refer to our project page: https://ego-gen.github.io/.",
      "tldr_zh": "这篇论文介绍了 EgoGen，一种专为第一人称视角（egocentric）合成数据生成器，旨在解决增强现实（AR）中视觉变化和挑战的问题。EgoGen 的核心是新型人类运动合成模型，通过利用 egocentric 视觉输入、collision-avoiding motion primitives 和两阶段 reinforcement learning，提供一个闭环解决方案，实现对动态环境的精确感知，而无需预定义全局路径。在映射和定位（mapping and localization）、egocentric 相机跟踪以及人体网格恢复（human mesh recovery）等任务上，EgoGen 显著提升了训练数据的准确性和丰富性，并计划完全开源以推动 egocentric 计算机视觉研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2024 (Oral). 23 pages, 17 figures. Project page:\n  https://ego-gen.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2401.08739v2",
      "published_date": "2024-01-16 18:55:22 UTC",
      "updated_date": "2024-04-11 16:35:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:06:32.220253"
    },
    {
      "arxiv_id": "2401.08567v1",
      "title": "Connect, Collapse, Corrupt: Learning Cross-Modal Tasks with Uni-Modal Data",
      "title_zh": "Connect, Collapse, Corrupt：使用单模态数据学习跨模态任务",
      "authors": [
        "Yuhui Zhang",
        "Elaine Sui",
        "Serena Yeung-Levy"
      ],
      "abstract": "Building cross-modal applications is challenging due to limited paired\nmulti-modal data. Recent works have shown that leveraging a pre-trained\nmulti-modal contrastive representation space enables cross-modal tasks to be\nlearned from uni-modal data. This is based on the assumption that contrastive\noptimization makes embeddings from different modalities interchangeable.\nHowever, this assumption is under-explored due to the poorly understood\ngeometry of the multi-modal contrastive space, where a modality gap exists. In\nour study, we provide a theoretical explanation of this space's geometry and\nintroduce a three-step method, $C^3$ (Connect, Collapse, Corrupt), to bridge\nthe modality gap, enhancing the interchangeability of embeddings. Our $C^3$\nmethod significantly improves cross-modal learning from uni-modal data,\nachieving state-of-the-art results on zero-shot image / audio / video\ncaptioning and text-to-image generation.",
      "tldr_zh": "本论文探讨了在配对多模态数据有限的情况下，如何从 uni-modal data 中学习 cross-modal tasks。作者提供了多模态对比空间几何的理论解释，揭示了模态间模ality gap的存在，并引入了三步方法 $C^3$ (Connect, Collapse, Corrupt) 来桥接这一差距，提高嵌入的可互换性。该方法显著提升了跨模态学习性能，在零样本图像/音频/视频字幕和文本到图像生成任务上达到了最先进的结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.08567v1",
      "published_date": "2024-01-16 18:52:27 UTC",
      "updated_date": "2024-01-16 18:52:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:06:44.761375"
    },
    {
      "arxiv_id": "2401.08552v2",
      "title": "Explaining Time Series via Contrastive and Locally Sparse Perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Zichuan Liu",
        "Yingying Zhang",
        "Tianchun Wang",
        "Zefan Wang",
        "Dongsheng Luo",
        "Mengnan Du",
        "Min Wu",
        "Yi Wang",
        "Chunlin Chen",
        "Lunting Fan",
        "Qingsong Wen"
      ],
      "abstract": "Explaining multivariate time series is a compound challenge, as it requires\nidentifying important locations in the time series and matching complex\ntemporal patterns. Although previous saliency-based methods addressed the\nchallenges, their perturbation may not alleviate the distribution shift issue,\nwhich is inevitable especially in heterogeneous samples. We present ContraLSP,\na locally sparse model that introduces counterfactual samples to build\nuninformative perturbations but keeps distribution using contrastive learning.\nFurthermore, we incorporate sample-specific sparse gates to generate more\nbinary-skewed and smooth masks, which easily integrate temporal trends and\nselect the salient features parsimoniously. Empirical studies on both synthetic\nand real-world datasets show that ContraLSP outperforms state-of-the-art\nmodels, demonstrating a substantial improvement in explanation quality for time\nseries data. The source code is available at\n\\url{https://github.com/zichuan-liu/ContraLSP}.",
      "tldr_zh": "本论文针对解释多元时间序列的挑战，提出了一种名为ContraLSP的局部稀疏模型，通过引入反事实样本和对比学习（contrastive learning）构建无信息扰动，同时保持数据分布，以缓解分布偏移问题。模型还整合样本特定的稀疏门控（sparse gates），生成更二值化且平滑的掩码，便于捕捉时间趋势并选择显著特征。实验结果显示，ContraLSP在合成和真实数据集上优于现有模型，在时间序列解释质量方面实现了显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by International Conference on Learning Representations\n  (ICLR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.08552v2",
      "published_date": "2024-01-16 18:27:37 UTC",
      "updated_date": "2024-01-29 04:44:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:06:54.552998"
    },
    {
      "arxiv_id": "2401.08534v4",
      "title": "DiConStruct: Causal Concept-based Explanations through Black-Box Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Ricardo Moreira",
        "Jacopo Bono",
        "Mário Cardoso",
        "Pedro Saleiro",
        "Mário A. T. Figueiredo",
        "Pedro Bizarro"
      ],
      "abstract": "Model interpretability plays a central role in human-AI decision-making\nsystems. Ideally, explanations should be expressed using human-interpretable\nsemantic concepts. Moreover, the causal relations between these concepts should\nbe captured by the explainer to allow for reasoning about the explanations.\nLastly, explanation methods should be efficient and not compromise the\nperformance of the predictive task. Despite the rapid advances in AI\nexplainability in recent years, as far as we know to date, no method fulfills\nthese three properties. Indeed, mainstream methods for local concept\nexplainability do not produce causal explanations and incur a trade-off between\nexplainability and prediction performance. We present DiConStruct, an\nexplanation method that is both concept-based and causal, with the goal of\ncreating more interpretable local explanations in the form of structural causal\nmodels and concept attributions. Our explainer works as a distillation model to\nany black-box machine learning model by approximating its predictions while\nproducing the respective explanations. Because of this, DiConStruct generates\nexplanations efficiently while not impacting the black-box prediction task. We\nvalidate our method on an image dataset and a tabular dataset, showing that\nDiConStruct approximates the black-box models with higher fidelity than other\nconcept explainability baselines, while providing explanations that include the\ncausal relations between the concepts.",
      "tldr_zh": "该论文提出DiConStruct，一种基于概念的因果解释方法，通过black-box distillation技术来生成可解释的局部解释。DiConStruct作为蒸馏模型，近似黑盒机器学习模型的预测，同时构建structural causal models和concept attributions，以捕捉概念间的因果关系，同时保持高效性和预测性能不变。与现有方法相比，该方法在图像和表格数据集上实现了更高的保真度，并成功提供了包括因果关系的解释，从而提升了AI模型的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Conference on Causal Learning and Reasoning (CLeaR 2024,\n  https://www.cclear.cc/2024). To be published at Proceedings of Machine\n  Learning Research (PMLR)",
      "pdf_url": "http://arxiv.org/pdf/2401.08534v4",
      "published_date": "2024-01-16 17:54:02 UTC",
      "updated_date": "2024-01-26 14:48:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:07:07.268937"
    },
    {
      "arxiv_id": "2401.08527v1",
      "title": "MICA: Towards Explainable Skin Lesion Diagnosis via Multi-Level Image-Concept Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yequan Bie",
        "Luyang Luo",
        "Hao Chen"
      ],
      "abstract": "Black-box deep learning approaches have showcased significant potential in\nthe realm of medical image analysis. However, the stringent trustworthiness\nrequirements intrinsic to the medical field have catalyzed research into the\nutilization of Explainable Artificial Intelligence (XAI), with a particular\nfocus on concept-based methods. Existing concept-based methods predominantly\napply concept annotations from a single perspective (e.g., global level),\nneglecting the nuanced semantic relationships between sub-regions and concepts\nembedded within medical images. This leads to underutilization of the valuable\nmedical information and may cause models to fall short in harmoniously\nbalancing interpretability and performance when employing inherently\ninterpretable architectures such as Concept Bottlenecks. To mitigate these\nshortcomings, we propose a multi-modal explainable disease diagnosis framework\nthat meticulously aligns medical images and clinical-related concepts\nsemantically at multiple strata, encompassing the image level, token level, and\nconcept level. Moreover, our method allows for model intervention and offers\nboth textual and visual explanations in terms of human-interpretable concepts.\nExperimental results on three skin image datasets demonstrate that our method,\nwhile preserving model interpretability, attains high performance and label\nefficiency for concept detection and disease diagnosis.",
      "tldr_zh": "本文提出 MICA 框架，旨在提升皮肤病变诊断的可解释性，通过多层次图像-概念对齐（包括图像水平、token 水平和概念水平）来弥合现有 Explainable Artificial Intelligence (XAI) 方法的不足，这些方法往往忽略医疗图像中子区域与概念的语义关系。MICA 采用多模态框架，支持模型干预，并提供基于人类可解释概念的文本和视觉解释，以平衡模型的性能和可解释性。在三个皮肤图像数据集上的实验结果显示，该方法在保持 Concept Bottlenecks 等可解释架构的同时，实现了高性能和标签效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08527v1",
      "published_date": "2024-01-16 17:45:01 UTC",
      "updated_date": "2024-01-16 17:45:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:07:20.281774"
    },
    {
      "arxiv_id": "2401.08525v1",
      "title": "GATS: Gather-Attend-Scatter",
      "title_zh": "翻译失败",
      "authors": [
        "Konrad Zolna",
        "Serkan Cabi",
        "Yutian Chen",
        "Eric Lau",
        "Claudio Fantacci",
        "Jurgis Pasukonis",
        "Jost Tobias Springenberg",
        "Sergio Gomez Colmenarejo"
      ],
      "abstract": "As the AI community increasingly adopts large-scale models, it is crucial to\ndevelop general and flexible tools to integrate them. We introduce\nGather-Attend-Scatter (GATS), a novel module that enables seamless combination\nof pretrained foundation models, both trainable and frozen, into larger\nmultimodal networks. GATS empowers AI systems to process and generate\ninformation across multiple modalities at different rates. In contrast to\ntraditional fine-tuning, GATS allows for the original component models to\nremain frozen, avoiding the risk of them losing important knowledge acquired\nduring the pretraining phase. We demonstrate the utility and versatility of\nGATS with a few experiments across games, robotics, and multimodal input-output\nsystems.",
      "tldr_zh": "本研究提出了一种名为 Gather-Attend-Scatter (GATS) 的新模块，用于无缝整合预训练基础模型（无论是否可训练）到更大的多模态网络中。GATS 允许 AI 系统以不同速率处理和生成多种模态信息，同时保持原始模型冻结，从而避免传统微调过程中可能丢失预训练知识的风险。通过实验在游戏、机器人和多模态输入输出系统中，展示了 GATS 的效用和多功能性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08525v1",
      "published_date": "2024-01-16 17:43:42 UTC",
      "updated_date": "2024-01-16 17:43:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:07:31.563840"
    },
    {
      "arxiv_id": "2401.08517v3",
      "title": "Supporting Student Decisions on Learning Recommendations: An LLM-Based Chatbot with Knowledge Graph Contextualization for Conversational Explainability and Mentoring",
      "title_zh": "翻译失败",
      "authors": [
        "Hasan Abu-Rasheed",
        "Mohamad Hussam Abdulsalam",
        "Christian Weber",
        "Madjid Fathi"
      ],
      "abstract": "Student commitment towards a learning recommendation is not separable from\ntheir understanding of the reasons it was recommended to them; and their\nability to modify it based on that understanding. Among explainability\napproaches, chatbots offer the potential to engage the student in a\nconversation, similar to a discussion with a peer or a mentor. The capabilities\nof chatbots, however, are still not sufficient to replace a human mentor,\ndespite the advancements of generative AI (GenAI) and large language models\n(LLM). Therefore, we propose an approach to utilize chatbots as mediators of\nthe conversation and sources of limited and controlled generation of\nexplanations, to harvest the potential of LLMs while reducing their potential\nrisks at the same time. The proposed LLM-based chatbot supports students in\nunderstanding learning-paths recommendations. We use a knowledge graph (KG) as\na human-curated source of information, to regulate the LLM's output through\ndefining its prompt's context. A group chat approach is developed to connect\nstudents with human mentors, either on demand or in cases that exceed the\nchatbot's pre-defined tasks. We evaluate the chatbot with a user study, to\nprovide a proof-of-concept and highlight the potential requirements and\nlimitations of utilizing chatbots in conversational explainability.",
      "tldr_zh": "该论文提出了一种基于 Large Language Models (LLM) 的聊天机器人系统，用于帮助学生理解和修改学习路径推荐，从而提升他们的决策承诺和修改能力。系统通过知识图谱 (KG) 作为人类策划的信息源，来定义 LLM 提示的上下文，确保输出可控并减少风险，同时采用群聊机制连接学生与人类导师以处理超出机器人任务的场景。通过用户研究，该方法证明了其在对话式解释和指导中的概念可行性，并突出了潜在的要求和限制。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08517v3",
      "published_date": "2024-01-16 17:31:35 UTC",
      "updated_date": "2024-01-24 09:55:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:07:43.937861"
    },
    {
      "arxiv_id": "2401.08505v4",
      "title": "Harnessing Orthogonality to Train Low-Rank Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Coquelin",
        "Katharina Flügel",
        "Marie Weiel",
        "Nicholas Kiefer",
        "Charlotte Debus",
        "Achim Streit",
        "Markus Götz"
      ],
      "abstract": "This study explores the learning dynamics of neural networks by analyzing the\nsingular value decomposition (SVD) of their weights throughout training. Our\ninvestigation reveals that an orthogonal basis within each multidimensional\nweight's SVD representation stabilizes during training. Building upon this, we\nintroduce Orthogonality-Informed Adaptive Low-Rank (OIALR) training, a novel\ntraining method exploiting the intrinsic orthogonality of neural networks.\nOIALR seamlessly integrates into existing training workflows with minimal\naccuracy loss, as demonstrated by benchmarking on various datasets and\nwell-established network architectures. With appropriate hyperparameter tuning,\nOIALR can surpass conventional training setups, including those of\nstate-of-the-art models.",
      "tldr_zh": "这篇论文通过分析神经网络权重在训练过程中的奇异值分解 (SVD)，发现每个多维权重的 SVD 表示中存在一个稳定的正交基。基于此，他们提出了一种新颖的 Orthogonality-Informed Adaptive Low-Rank (OIALR) 训练方法，利用神经网络的内在正交性，以最小准确性损失无缝集成到现有训练流程中。实验在各种数据集和网络架构上进行基准测试，结果显示，通过适当的超参数调整，OIALR 能超越传统训练设置，甚至优于最先进模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08505v4",
      "published_date": "2024-01-16 17:07:22 UTC",
      "updated_date": "2024-07-10 06:59:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:07:55.581766"
    },
    {
      "arxiv_id": "2401.08478v2",
      "title": "Solving Continual Offline Reinforcement Learning with Decision Transformer",
      "title_zh": "利用 Decision Transformer 解决持续离线强化学习",
      "authors": [
        "Kaixin Huang",
        "Li Shen",
        "Chen Zhao",
        "Chun Yuan",
        "Dacheng Tao"
      ],
      "abstract": "Continuous offline reinforcement learning (CORL) combines continuous and\noffline reinforcement learning, enabling agents to learn multiple tasks from\nstatic datasets without forgetting prior tasks. However, CORL faces challenges\nin balancing stability and plasticity. Existing methods, employing Actor-Critic\nstructures and experience replay (ER), suffer from distribution shifts, low\nefficiency, and weak knowledge-sharing. We aim to investigate whether Decision\nTransformer (DT), another offline RL paradigm, can serve as a more suitable\noffline continuous learner to address these issues. We first compare AC-based\noffline algorithms with DT in the CORL framework. DT offers advantages in\nlearning efficiency, distribution shift mitigation, and zero-shot\ngeneralization but exacerbates the forgetting problem during supervised\nparameter updates. We introduce multi-head DT (MH-DT) and low-rank adaptation\nDT (LoRA-DT) to mitigate DT's forgetting problem. MH-DT stores task-specific\nknowledge using multiple heads, facilitating knowledge sharing with common\ncomponents. It employs distillation and selective rehearsal to enhance current\ntask learning when a replay buffer is available. In buffer-unavailable\nscenarios, LoRA-DT merges less influential weights and fine-tunes DT's decisive\nMLP layer to adapt to the current task. Extensive experiments on MoJuCo and\nMeta-World benchmarks demonstrate that our methods outperform SOTA CORL\nbaselines and showcase enhanced learning capabilities and superior memory\nefficiency.",
      "tldr_zh": "该研究针对连续离线强化学习（CORL）面临的稳定性和可塑性平衡挑战，提出使用 Decision Transformer (DT) 作为替代框架，以解决现有 Actor-Critic 方法的分布偏移、低效率和知识共享不足问题。作者引入 multi-head DT (MH-DT) 和 low-rank adaptation DT (LoRA-DT) 来缓解 DT 在监督参数更新中的遗忘问题，其中 MH-DT 通过多个头存储任务特定知识并结合蒸馏和选择性回放，而 LoRA-DT 在无回放缓冲区场景下微调关键层以适应新任务。在 MoJuCo 和 Meta-World 基准上的广泛实验表明，这些方法优于现有 SOTA CORL 基准，提升了学习能力和内存效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.08478v2",
      "published_date": "2024-01-16 16:28:32 UTC",
      "updated_date": "2024-04-07 11:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:08:10.629719"
    },
    {
      "arxiv_id": "2401.08461v1",
      "title": "Decentralised Emergence of Robust and Adaptive Linguistic Conventions in Populations of Autonomous Agents Grounded in Continuous Worlds",
      "title_zh": "翻译失败",
      "authors": [
        "Jérôme Botoko Ekila",
        "Jens Nevens",
        "Lara Verheyen",
        "Katrien Beuls",
        "Paul Van Eecke"
      ],
      "abstract": "This paper introduces a methodology through which a population of autonomous\nagents can establish a linguistic convention that enables them to refer to\narbitrary entities that they observe in their environment. The linguistic\nconvention emerges in a decentralised manner through local communicative\ninteractions between pairs of agents drawn from the population. The convention\nconsists of symbolic labels (word forms) associated to concept representations\n(word meanings) that are grounded in a continuous feature space. The concept\nrepresentations of each agent are individually constructed yet compatible on a\ncommunicative level. Through a range of experiments, we show (i) that the\nmethodology enables a population to converge on a communicatively effective,\ncoherent and human-interpretable linguistic convention, (ii) that it is\nnaturally robust against sensor defects in individual agents, (iii) that it can\neffectively deal with noisy observations, uncalibrated sensors and\nheteromorphic populations, (iv) that the method is adequate for continual\nlearning, and (v) that the convention self-adapts to changes in the environment\nand communicative needs of the agents.",
      "tldr_zh": "本论文提出了一种方法，让一群自治 agents（autonomous agents）通过去中心化（decentralised）的本地通信互动，在连续世界（continuous worlds）中自发形成鲁棒且适应的语言约定（linguistic conventions），以指代环境中的任意实体。语言约定由符号标签（symbolic labels）和基于连续特征空间的概念表示（concept representations）组成，每个 agents 的表示独立但在通信层面兼容。该方法经实验验证，能实现有效的语言收敛、人类可解释性，并对传感器缺陷、噪声观察、非校准传感器和异形群组（heteromorphic populations）具有自然鲁棒性，同时支持持续学习（continual learning）和环境变化的自适应。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08461v1",
      "published_date": "2024-01-16 16:11:35 UTC",
      "updated_date": "2024-01-16 16:11:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:08:24.758541"
    },
    {
      "arxiv_id": "2401.08460v1",
      "title": "Reinforcement Learning for Conversational Question Answering over Knowledge Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Mi Wu"
      ],
      "abstract": "Conversational question answering (ConvQA) over law knowledge bases (KBs)\ninvolves answering multi-turn natural language questions about law and hope to\nfind answers in the law knowledge base. Despite many methods have been\nproposed. Existing law knowledge base ConvQA model assume that the input\nquestion is clear and can perfectly reflect user's intention. However, in real\nworld, the input questions are noisy and inexplict. This makes the model hard\nto find the correct answer in the law knowledge bases. In this paper, we try to\nuse reinforcement learning to solve this problem. The reinforcement learning\nagent can automatically learn how to find the answer based on the input\nquestion and the conversation history, even when the input question is\ninexplicit. We test the proposed method on several real world datasets and the\nresults show the effectivenss of the proposed model.",
      "tldr_zh": "本论文针对知识图谱上的对话式问答(ConvQA)，特别是在法律知识库中，处理多轮自然语言问题时输入问题模糊不清的问题。作者提出使用强化学习(Reinforcement Learning)代理，该代理能基于输入问题和对话历史自动学习并定位正确答案，从而提升模型在噪声数据下的鲁棒性。实验结果显示，该方法在多个真实数据集上表现出色，证明了其有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08460v1",
      "published_date": "2024-01-16 16:09:56 UTC",
      "updated_date": "2024-01-16 16:09:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:08:33.497684"
    },
    {
      "arxiv_id": "2401.08458v1",
      "title": "Security and Privacy Issues and Solutions in Federated Learning for Digital Healthcare",
      "title_zh": "联邦学习在数字医疗中的安全和隐私问题及解决方案",
      "authors": [
        "Hyejun Jeong",
        "Tai-Myoung Chung"
      ],
      "abstract": "The advent of Federated Learning has enabled the creation of a\nhigh-performing model as if it had been trained on a considerable amount of\ndata. A multitude of participants and a server cooperatively train a model\nwithout the need for data disclosure or collection. The healthcare industry,\nwhere security and privacy are paramount, can substantially benefit from this\nnew learning paradigm, as data collection is no longer feasible due to\nstringent data policies. Nonetheless, unaddressed challenges and insufficient\nattack mitigation are hampering its adoption. Attack surfaces differ from\ntraditional centralized learning in that the server and clients communicate\nbetween each round of training. In this paper, we thus present vulnerabilities,\nattacks, and defenses based on the widened attack surfaces, as well as suggest\npromising new research directions toward a more robust FL.",
      "tldr_zh": "这篇论文探讨了Federated Learning在数字医疗领域的安全和隐私挑战，强调其通过多参与者和服务器合作训练模型，而无需数据共享，从而符合严格的数据政策。作者分析了FL中独特的攻击面扩展，包括服务器与客户端间的通信引发的漏洞和攻击，并提出了相应的防御策略。最终，论文建议了新的研究方向，以增强FL的稳健性，促进其在医疗行业的可靠应用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08458v1",
      "published_date": "2024-01-16 16:07:53 UTC",
      "updated_date": "2024-01-16 16:07:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:08:45.085676"
    },
    {
      "arxiv_id": "2401.08728v3",
      "title": "AgentMixer: Multi-Agent Correlated Policy Factorization",
      "title_zh": "AgentMixer: 多智能体相关策略因子分解",
      "authors": [
        "Zhiyuan Li",
        "Wenshuai Zhao",
        "Lijun Wu",
        "Joni Pajarinen"
      ],
      "abstract": "In multi-agent reinforcement learning, centralized training with\ndecentralized execution (CTDE) methods typically assume that agents make\ndecisions based on their local observations independently, which may not lead\nto a correlated joint policy with coordination. Coordination can be explicitly\nencouraged during training and individual policies can be trained to imitate\nthe correlated joint policy. However, this may lead to an \\textit{asymmetric\nlearning failure} due to the observation mismatch between the joint and\nindividual policies. Inspired by the concept of correlated equilibrium, we\nintroduce a \\textit{strategy modification} called AgentMixer that allows agents\nto correlate their policies. AgentMixer combines individual partially\nobservable policies into a joint fully observable policy non-linearly. To\nenable decentralized execution, we introduce\n\\textit{Individual-Global-Consistency} to guarantee mode consistency during\njoint training of the centralized and decentralized policies and prove that\nAgentMixer converges to an $\\epsilon$-approximate Correlated Equilibrium. In\nthe Multi-Agent MuJoCo, SMAC-v2, Matrix Game, and Predator-Prey benchmarks,\nAgentMixer outperforms or matches state-of-the-art methods.",
      "tldr_zh": "该论文解决了多智能体强化学习(MARL)中 Centralized Training with Decentralized Execution (CTDE) 方法的局限性，即代理独立决策可能导致缺乏协调的联合策略，并可能引发不对称学习失败。作者提出 AgentMixer，一种策略修改方法，通过非线性地将个体部分可观察策略组合成联合完全可观察策略，实现代理策略的关联。引入 Individual-Global-Consistency 机制确保集中式和分散式策略在训练中的模式一致性，并证明 AgentMixer 收敛到 ε-approximate Correlated Equilibrium。在 Multi-Agent MuJoCo、SMAC-v2、Matrix Game 和 Predator-Prey 基准测试中，AgentMixer 的性能优于或匹配最先进方法。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08728v3",
      "published_date": "2024-01-16 15:32:41 UTC",
      "updated_date": "2024-12-13 11:12:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:08:57.326860"
    },
    {
      "arxiv_id": "2401.08429v1",
      "title": "Machine Translation with Large Language Models: Prompt Engineering for Persian, English, and Russian Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Nooshin Pourkamali",
        "Shler Ebrahim Sharifi"
      ],
      "abstract": "Generative large language models (LLMs) have demonstrated exceptional\nproficiency in various natural language processing (NLP) tasks, including\nmachine translation, question answering, text summarization, and natural\nlanguage understanding.\n  To further enhance the performance of LLMs in machine translation, we\nconducted an investigation into two popular prompting methods and their\ncombination, focusing on cross-language combinations of Persian, English, and\nRussian. We employed n-shot feeding and tailored prompting frameworks. Our\nfindings indicate that multilingual LLMs like PaLM exhibit human-like machine\ntranslation outputs, enabling superior fine-tuning of desired translation\nnuances in accordance with style guidelines and linguistic considerations.\nThese models also excel in processing and applying prompts. However, the choice\nof language model, machine translation task, and the specific source and target\nlanguages necessitate certain considerations when adopting prompting frameworks\nand utilizing n-shot in-context learning.\n  Furthermore, we identified errors and limitations inherent in popular LLMs as\nmachine translation tools and categorized them based on various linguistic\nmetrics. This typology of errors provides valuable insights for utilizing LLMs\neffectively and offers methods for designing prompts for in-context learning.\nOur report aims to contribute to the advancement of machine translation with\nLLMs by improving both the accuracy and reliability of evaluation metrics.",
      "tldr_zh": "本文研究了如何通过提示工程（Prompt Engineering）提升大型语言模型（LLMs）在机器翻译中的性能，重点测试了波斯语（Persian）、英语（English）和俄语（Russian）的跨语言组合，使用 n-shot feeding 和定制提示框架。结果显示，多语言 LLMs 如 PaLM 可以产生类似人类的翻译输出，并根据风格和语言考虑进行微调，但模型选择、任务类型和源目标语言会影响效果。论文还识别并分类了 LLMs 在翻译中的错误和限制，并提出改进 in-context learning 提示设计的方法，以提升翻译的准确性和可靠性评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "ACM-class: I.2.2",
        "I.2.2"
      ],
      "primary_category": "cs.CL",
      "comment": "34 pages, 46 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.08429v1",
      "published_date": "2024-01-16 15:16:34 UTC",
      "updated_date": "2024-01-16 15:16:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:09:10.079245"
    },
    {
      "arxiv_id": "2401.08425v1",
      "title": "U-DIADS-Bib: a full and few-shot pixel-precise dataset for document layout analysis of ancient manuscripts",
      "title_zh": "U-DIADS-Bib：一个全量与少样本的像素级精确数据集，用于古代手稿",
      "authors": [
        "Silvia Zottin",
        "Axel De Nardin",
        "Emanuela Colombi",
        "Claudio Piciarelli",
        "Filippo Pavan",
        "Gian Luca Foresti"
      ],
      "abstract": "Document Layout Analysis, which is the task of identifying different semantic\nregions inside of a document page, is a subject of great interest for both\ncomputer scientists and humanities scholars as it represents a fundamental step\ntowards further analysis tasks for the former and a powerful tool to improve\nand facilitate the study of the documents for the latter. However, many of the\nworks currently present in the literature, especially when it comes to the\navailable datasets, fail to meet the needs of both worlds and, in particular,\ntend to lean towards the needs and common practices of the computer science\nside, leading to resources that are not representative of the humanities real\nneeds. For this reason, the present paper introduces U-DIADS-Bib, a novel,\npixel-precise, non-overlapping and noiseless document layout analysis dataset\ndeveloped in close collaboration between specialists in the fields of computer\nvision and humanities. Furthermore, we propose a novel, computer-aided,\nsegmentation pipeline in order to alleviate the burden represented by the\ntime-consuming process of manual annotation, necessary for the generation of\nthe ground truth segmentation maps. Finally, we present a standardized few-shot\nversion of the dataset (U-DIADS-BibFS), with the aim of encouraging the\ndevelopment of models and solutions able to address this task with as few\nsamples as possible, which would allow for more effective use in a real-world\nscenario, where collecting a large number of segmentations is not always\nfeasible.",
      "tldr_zh": "本文介绍了 U-DIADS-Bib，这是一个像素-precise、非重叠、无噪声的文档布局分析数据集，针对古籍手稿开发，由计算机视觉和人文专家合作创建，以更好地满足计算机科学和人文研究的实际需求。研究者提出了一种计算机辅助的分割管道，旨在减轻手动标注的繁重工作，提高 ground truth 分割图的生成效率。同时，论文呈现了 U-DIADS-Bib 的少样本（few-shot）版本，鼓励开发少样本学习模型，从而在数据有限的真实场景中实现更有效的文档布局分析。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Neural Comput & Applic (2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.08425v1",
      "published_date": "2024-01-16 15:11:18 UTC",
      "updated_date": "2024-01-16 15:11:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:09:21.877106"
    },
    {
      "arxiv_id": "2402.08611v1",
      "title": "A Cost-Sensitive Transformer Model for Prognostics Under Highly Imbalanced Industrial Data",
      "title_zh": "一种成本敏感的Transformer模型，用于高度不平衡工业数据下的预后分析",
      "authors": [
        "Ali Beikmohammadi",
        "Mohammad Hosein Hamian",
        "Neda Khoeyniha",
        "Tony Lindgren",
        "Olof Steinert",
        "Sindri Magnússon"
      ],
      "abstract": "The rapid influx of data-driven models into the industrial sector has been\nfacilitated by the proliferation of sensor technology, enabling the collection\nof vast quantities of data. However, leveraging these models for failure\ndetection and prognosis poses significant challenges, including issues like\nmissing values and class imbalances. Moreover, the cost sensitivity associated\nwith industrial operations further complicates the application of conventional\nmodels in this context. This paper introduces a novel cost-sensitive\ntransformer model developed as part of a systematic workflow, which also\nintegrates a hybrid resampler and a regression-based imputer. After subjecting\nour approach to rigorous testing using the APS failure dataset from Scania\ntrucks and the SECOM dataset, we observed a substantial enhancement in\nperformance compared to state-of-the-art methods. Moreover, we conduct an\nablation study to analyze the contributions of different components in our\nproposed method. Our findings highlight the potential of our method in\naddressing the unique challenges of failure prediction in industrial settings,\nthereby contributing to enhanced reliability and efficiency in industrial\noperations.",
      "tldr_zh": "这篇论文针对工业数据中的缺失值、类别不平衡和成本敏感性等问题，提出了一种新型成本敏感 Transformer 模型，作为系统工作流程的一部分。该模型整合了 hybrid resampler 和 regression-based imputer，以提升故障预测的准确性。在使用 Scania 卡车 APS 故障数据集和 SECOM 数据集进行测试后，该方法比现有最先进方法性能显著提升，并通过 ablation study 分析了不同组件的贡献。该研究为工业环境下的故障预测提供了更可靠且高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08611v1",
      "published_date": "2024-01-16 15:09:53 UTC",
      "updated_date": "2024-01-16 15:09:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:09:33.930551"
    },
    {
      "arxiv_id": "2401.08405v3",
      "title": "Interrogating AI: Characterizing Emergent Playful Interactions with ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Ronagh Nikghalb",
        "Jinghui Cheng"
      ],
      "abstract": "In an era of AI's growing capabilities and influences, recent advancements\nare reshaping HCI and CSCW's view of AI. Playful interactions emerged as an\nimportant way for users to make sense of the ever-changing AI technologies, yet\nremained underexamined. We target this gap by investigating playful\ninteractions exhibited by users of a popular AI technology, ChatGPT. Through a\nthematic analysis of 372 user-generated posts on the ChatGPT subreddit, we\nfound that more than half (54\\%) of user discourse revolved around playful\ninteractions. The analysis further allowed us to construct a preliminary\nframework to describe these interactions, categorizing them into six types:\nreflecting, jesting, imitating, challenging, tricking, and contriving; each\nincluded sub-categories. This study contributes to HCI and CSCW by identifying\nthe diverse ways users engage in playful interactions with AI. It examines how\nthese interactions can help users understand AI's agency, shape human-AI\nrelationships, and provide insights for designing AI systems.",
      "tldr_zh": "该研究探讨了用户与 ChatGPT 的新兴玩耍互动（playful interactions），通过分析 372 条 ChatGPT subreddit 用户帖子，发现超过半数（54%）的讨论涉及此类互动。研究采用 thematic analysis 构建了一个初步框架，将玩耍互动分为六类：reflecting、jesting、imitating、challenging、tricking 和 contriving，每个类别包含子类别。论文为 HCI 和 CSCW 领域贡献了新见解，展示了这些互动如何帮助用户理解 AI 的 agency、塑造人-AI 关系，并为 AI 系统设计提供指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to CSCW 2025; 23 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.08405v3",
      "published_date": "2024-01-16 14:44:13 UTC",
      "updated_date": "2024-10-15 02:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:09:44.868572"
    },
    {
      "arxiv_id": "2401.08396v4",
      "title": "Hidden flaws behind expert-level accuracy of multimodal GPT-4 vision in medicine",
      "title_zh": "多模态 GPT-4 视觉在医学中专家级准确率背后的隐藏缺陷",
      "authors": [
        "Qiao Jin",
        "Fangyuan Chen",
        "Yiliang Zhou",
        "Ziyang Xu",
        "Justin M. Cheung",
        "Robert Chen",
        "Ronald M. Summers",
        "Justin F. Rousseau",
        "Peiyun Ni",
        "Marc J Landsman",
        "Sally L. Baxter",
        "Subhi J. Al'Aref",
        "Yijia Li",
        "Alex Chen",
        "Josef A. Brejt",
        "Michael F. Chiang",
        "Yifan Peng",
        "Zhiyong Lu"
      ],
      "abstract": "Recent studies indicate that Generative Pre-trained Transformer 4 with Vision\n(GPT-4V) outperforms human physicians in medical challenge tasks. However,\nthese evaluations primarily focused on the accuracy of multi-choice questions\nalone. Our study extends the current scope by conducting a comprehensive\nanalysis of GPT-4V's rationales of image comprehension, recall of medical\nknowledge, and step-by-step multimodal reasoning when solving New England\nJournal of Medicine (NEJM) Image Challenges - an imaging quiz designed to test\nthe knowledge and diagnostic capabilities of medical professionals. Evaluation\nresults confirmed that GPT-4V performs comparatively to human physicians\nregarding multi-choice accuracy (81.6% vs. 77.8%). GPT-4V also performs well in\ncases where physicians incorrectly answer, with over 78% accuracy. However, we\ndiscovered that GPT-4V frequently presents flawed rationales in cases where it\nmakes the correct final choices (35.5%), most prominent in image comprehension\n(27.2%). Regardless of GPT-4V's high accuracy in multi-choice questions, our\nfindings emphasize the necessity for further in-depth evaluations of its\nrationales before integrating such multimodal AI models into clinical\nworkflows.",
      "tldr_zh": "本研究对多模态GPT-4V在医学领域的性能进行了全面评估，不仅考察多选题准确率，还分析了其图像理解、医疗知识回忆和逐步多模态推理过程，使用NEJM Image Challenges作为测试基准。结果显示，GPT-4V的多选题准确率（81.6%）与人类医生（77.8%）相当，甚至在医生错误情况下仍有78%的准确率。然而，GPT-4V在正确答案时经常出现推理缺陷，占比达35.5%，其中图像理解问题最为突出（27.2%）。研究强调，尽管GPT-4V表现出专家级准确率，但需进行更深入的推理评估，以确保其在临床工作流程中的安全性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08396v4",
      "published_date": "2024-01-16 14:41:20 UTC",
      "updated_date": "2024-08-31 23:51:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:09:58.691720"
    },
    {
      "arxiv_id": "2401.08397v2",
      "title": "A Micro Architectural Events Aware Real-Time Embedded System Fault Injector",
      "title_zh": "翻译失败",
      "authors": [
        "Enrico Magliano",
        "Alessio Carpegna",
        "Alessadro Savino",
        "Stefano Di Carlo"
      ],
      "abstract": "In contemporary times, the increasing complexity of the system poses\nsignificant challenges to the reliability, trustworthiness, and security of the\nSACRES. Key issues include the susceptibility to phenomena such as\ninstantaneous voltage spikes, electromagnetic interference, neutron strikes,\nand out-of-range temperatures. These factors can induce switch state changes in\ntransistors, resulting in bit-flipping, soft errors, and transient corruption\nof stored data in memory. The occurrence of soft errors, in turn, may lead to\nsystem faults that can propel the system into a hazardous state. Particularly\nin critical sectors like automotive, avionics, or aerospace, such malfunctions\ncan have real-world implications, potentially causing harm to individuals.\n  This paper introduces a novel fault injector designed to facilitate the\nmonitoring, aggregation, and examination of micro-architectural events. This is\nachieved by harnessing the microprocessor's PMU and the debugging interface,\nspecifically focusing on ensuring the repeatability of fault injections. The\nfault injection methodology targets bit-flipping within the memory system,\naffecting CPU registers and RAM. The outcomes of these fault injections enable\na thorough analysis of the impact of soft errors and establish a robust\ncorrelation between the identified faults and the essential timing\npredictability demanded by SACRES.",
      "tldr_zh": "本文针对实时嵌入式系统(SACRES)面临的软错误问题，如电压尖峰和电磁干扰导致的bit-flipping，提出了一种新型故障注入器。该注入器利用微处理器的PMU和调试接口，监控并聚合微架构事件，确保故障注入的可重复性，并针对CPU寄存器和RAM进行内存系统bit-flipping模拟。实验结果显示，该方法能有效分析软错误对系统的影响，并建立故障与时序可预测性之间的稳健相关性，从而提升关键领域如汽车和航空系统的可靠性和安全性。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08397v2",
      "published_date": "2024-01-16 14:41:20 UTC",
      "updated_date": "2024-06-11 08:44:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:10:12.733960"
    },
    {
      "arxiv_id": "2401.08727v2",
      "title": "MA2GCN: Multi Adjacency relationship Attention Graph Convolutional Networks for Traffic Prediction using Trajectory data",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengke Sun",
        "Yuliang Ma"
      ],
      "abstract": "The problem of traffic congestion not only causes a large amount of economic\nlosses, but also seriously endangers the urban environment. Predicting traffic\ncongestion has important practical significance. So far, most studies have been\nbased on historical data from sensors placed on different roads to predict\nfuture traffic flow and speed, to analyze the traffic congestion conditions of\na certain road segment. However, due to the fixed position of sensors, it is\ndifficult to mine new information. On the other hand, vehicle trajectory data\nis more flexible and can extract traffic information as needed. Therefore, we\nproposed a new traffic congestion prediction model - Multi Adjacency\nrelationship Attention Graph Convolutional Networks(MA2GCN). This model\ntransformed vehicle trajectory data into graph structured data in grid form,\nand proposed a vehicle entry and exit matrix based on the mobility between\ndifferent grids. At the same time, in order to improve the performance of the\nmodel, this paper also built a new adaptive adjacency matrix generation method\nand adjacency matrix attention module. This model mainly used gated temporal\nconvolution and graph convolution to extract temporal and spatial information,\nrespectively. Compared with multiple baselines, our model achieved the best\nperformance on Shanghai taxi GPS trajectory dataset. The code is available at\nhttps://github.com/zachysun/Taxi_Traffic_Benchmark.",
      "tldr_zh": "这篇论文针对交通拥堵预测问题，提出了一种新模型 MA2GCN，利用车辆轨迹数据来构建网格形式的图结构数据，并引入车辆进出矩阵来捕捉交通流动。模型采用了自适应邻接矩阵生成方法和邻接矩阵注意力模块，以提升性能，同时使用门控时间卷积提取时间信息和 Graph Convolutional Networks 提取空间信息。与多个基线模型相比，MA2GCN 在上海出租车 GPS 轨迹数据集上取得了最佳预测效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08727v2",
      "published_date": "2024-01-16 14:22:44 UTC",
      "updated_date": "2024-01-18 05:25:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:10:24.678826"
    },
    {
      "arxiv_id": "2401.08386v1",
      "title": "Deep Learning-based Group Causal Inference in Multivariate Time-series",
      "title_zh": "翻译失败",
      "authors": [
        "Wasim Ahmad",
        "Maha Shadaydeh",
        "Joachim Denzler"
      ],
      "abstract": "Causal inference in a nonlinear system of multivariate timeseries is\ninstrumental in disentangling the intricate web of relationships among\nvariables, enabling us to make more accurate predictions and gain deeper\ninsights into real-world complex systems. Causality methods typically identify\nthe causal structure of a multivariate system by considering the cause-effect\nrelationship of each pair of variables while ignoring the collective effect of\na group of variables or interactions involving more than two-time series\nvariables. In this work, we test model invariance by group-level interventions\non the trained deep networks to infer causal direction in groups of variables,\nsuch as climate and ecosystem, brain networks, etc. Extensive testing with\nsynthetic and real-world time series data shows a significant improvement of\nour method over other applied group causality methods and provides us insights\ninto real-world time series. The code for our method can be found\nat:https://github.com/wasimahmadpk/gCause.",
      "tldr_zh": "该论文探讨了基于深度学习（deep learning）的组级因果推断（group causal inference），旨在处理多变量时间序列（multivariate time-series）中变量间的复杂交互关系。传统方法仅关注变量对的因果关系，而本研究通过在训练好的深度网络上进行组级干预测试模型不变性，从而推断变量组的因果方向。实验结果显示，该方法在合成和真实世界数据（如气候生态系统和脑网络）上比其他组因果方法显著提升性能，提供更深入的真实世界洞见。代码已开源，可在 GitHub 上获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in AAAI24 (AI4TS)",
      "pdf_url": "http://arxiv.org/pdf/2401.08386v1",
      "published_date": "2024-01-16 14:19:28 UTC",
      "updated_date": "2024-01-16 14:19:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:10:36.455595"
    },
    {
      "arxiv_id": "2401.08383v2",
      "title": "Exploiting Inter-Layer Expert Affinity for Accelerating Mixture-of-Experts Model Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Jinghan Yao",
        "Quentin Anthony",
        "Aamir Shafi",
        "Hari Subramoni",
        "Dhabaleswar K.",
        "Panda"
      ],
      "abstract": "In large language models like the Generative Pre-trained Transformer, the\nMixture of Experts paradigm has emerged as a powerful technique for enhancing\nmodel expressiveness and accuracy. However, deploying GPT MoE models for\nparallel inference on distributed systems presents significant challenges,\nprimarily due to the extensive Alltoall communication required for expert\nrouting and aggregation. This communication bottleneck exacerbates the already\ncomplex computational landscape, hindering the efficient utilization of\nhigh-performance computing resources. In this paper, we propose a lightweight\noptimization technique called ExFlow, to largely accelerate the inference of\nthese MoE models. We take a new perspective on alleviating the communication\noverhead by exploiting the inter-layer expert affinity. Unlike previous\nmethods, our solution can be directly applied to pre-trained MoE models without\nany fine-tuning or accuracy degradation. By proposing a context-coherent expert\nparallelism on distributed systems, our design only uses one Alltoall\ncommunication to deliver the same functionality while previous methods all\nrequire two Alltoalls. By carefully examining the conditional probability in\ntokens' routing across multiple layers, we proved that pre-trained GPT MoE\nmodels implicitly exhibit a strong inter-layer expert affinity. We then design\nan efficient integer programming model to capture such features and show that\nby properly placing the experts on corresponding GPUs, we can reduce up to 67%\ncross-GPU routing latency. Our solution beats the cutting-edge MoE\nimplementations with experts from 8 to 64, with up to 2.2x improvement in\ninference throughput. We further provide a detailed study of how the model\nimplicitly acquires this expert affinity at the very early training stage and\nhow this affinity evolves and stabilizes during training.",
      "tldr_zh": "该论文针对Mixture of Experts (MoE)模型在分布式系统上的推理效率问题，提出了一种轻量级优化技术ExFlow，通过利用层间专家亲和性(inter-layer expert affinity)来减少Alltoall通信开销。ExFlow采用context-coherent expert parallelism设计，仅需一个Alltoall通信即可实现传统方法的全部功能，同时通过整数规划模型优化专家在GPU上的放置，降低高达67%的跨GPU路由延迟。实验证明，该方法可直接应用于预训练GPT MoE模型，无需微调或准确性损失，并在专家数量从8到64的场景下，实现推理吞吐量高达2.2倍的提升。研究进一步探讨了模型在早期训练阶段如何获得这种专家亲和性，以及其在训练过程中的演变和稳定。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08383v2",
      "published_date": "2024-01-16 14:16:47 UTC",
      "updated_date": "2024-01-17 03:37:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:10:52.945889"
    },
    {
      "arxiv_id": "2401.08376v1",
      "title": "KADEL: Knowledge-Aware Denoising Learning for Commit Message Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Tao",
        "Yucheng Zhou",
        "Yanlin Wang",
        "Hongyu Zhang",
        "Haofen Wang",
        "Wenqiang Zhang"
      ],
      "abstract": "Commit messages are natural language descriptions of code changes, which are\nimportant for software evolution such as code understanding and maintenance.\nHowever, previous methods are trained on the entire dataset without considering\nthe fact that a portion of commit messages adhere to good practice (i.e.,\ngood-practice commits), while the rest do not. On the basis of our empirical\nstudy, we discover that training on good-practice commits significantly\ncontributes to the commit message generation. Motivated by this finding, we\npropose a novel knowledge-aware denoising learning method called KADEL.\nConsidering that good-practice commits constitute only a small proportion of\nthe dataset, we align the remaining training samples with these good-practice\ncommits. To achieve this, we propose a model that learns the commit knowledge\nby training on good-practice commits. This knowledge model enables\nsupplementing more information for training samples that do not conform to good\npractice. However, since the supplementary information may contain noise or\nprediction errors, we propose a dynamic denoising training method. This method\ncomposes a distribution-aware confidence function and a dynamic distribution\nlist, which enhances the effectiveness of the training process. Experimental\nresults on the whole MCMD dataset demonstrate that our method overall achieves\nstate-of-the-art performance compared with previous methods. Our source code\nand data are available at https://github.com/DeepSoftwareAnalytics/KADEL",
      "tldr_zh": "这篇论文提出 KADEL，一种知识感知去噪学习（Knowledge-Aware Denoising Learning）方法，用于生成高质量的提交消息（Commit Message Generation），以提升软件演化的代码理解和维护。研究发现，通过在良好实践提交（good-practice commits）上训练模型，可以显著改善生成效果，因此 KADEL 使用一个知识模型来为非良好实践样本补充信息，同时引入动态去噪训练方法，包括分布感知置信函数（distribution-aware confidence function）和动态分布列表，以减少噪声干扰。实验在 MCMD 数据集上表明，KADEL 比现有方法实现了最先进性能，并提供了源代码和数据以供复现。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to ACM Transactions on Software Engineering and Methodology\n  2024 (TOSEM'24)",
      "pdf_url": "http://arxiv.org/pdf/2401.08376v1",
      "published_date": "2024-01-16 14:07:48 UTC",
      "updated_date": "2024-01-16 14:07:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:11:02.655893"
    },
    {
      "arxiv_id": "2401.12988v2",
      "title": "Few-Shot Learning for Mental Disorder Detection: A Continuous Multi-Prompt Engineering Approach with Medical Knowledge Injection",
      "title_zh": "少样本学习用于精神障碍检测：一种连续多提示工程方法结合医疗知识注入",
      "authors": [
        "Haoxin Liu",
        "Wenli Zhang",
        "Jiaheng Xie",
        "Buomsoo Kim",
        "Zhu Zhang",
        "Yidong Chai",
        "Sudha Ram"
      ],
      "abstract": "This study harnesses state-of-the-art AI technology for detecting mental\ndisorders through user-generated textual content. Existing studies typically\nrely on fully supervised machine learning, which presents challenges such as\nthe labor-intensive manual process of annotating extensive training data for\neach research problem and the need to design specialized deep learning\narchitectures for each task. We propose a novel method to address these\nchallenges by leveraging large language models and continuous multi-prompt\nengineering, which offers two key advantages: (1) developing personalized\nprompts that capture each user's unique characteristics and (2) integrating\nstructured medical knowledge into prompts to provide context for disease\ndetection and facilitate predictive modeling. We evaluate our method using\nthree widely prevalent mental disorders as research cases. Our method\nsignificantly outperforms existing methods, including feature engineering,\narchitecture engineering, and discrete prompt engineering. Meanwhile, our\napproach demonstrates success in few-shot learning, i.e., requiring only a\nminimal number of training examples. Moreover, our method can be generalized to\nother rare mental disorder detection tasks with few positive labels. In\naddition to its technical contributions, our method has the potential to\nenhance the well-being of individuals with mental disorders and offer a\ncost-effective, accessible alternative for stakeholders beyond traditional\nmental disorder screening methods.",
      "tldr_zh": "本研究提出了一种基于Few-Shot Learning的精神障碍检测方法，利用大型语言模型和Continuous Multi-Prompt Engineering，结合医疗知识注入，解决传统监督学习中数据标注 laborious 和架构设计的问题。该方法通过开发个性化提示捕捉用户独特特征，并整合结构化医疗知识，提升检测的准确性和上下文理解。在三种常见精神障碍的实验中，该方法显著优于现有方法如特征工程和离散提示工程，仅需少量训练样本即可实现高效检测，并可泛化到罕见障碍，具有提升患者福祉和提供成本有效筛查的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "K.5",
        "I.2.7; H.4.m"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12988v2",
      "published_date": "2024-01-16 13:54:43 UTC",
      "updated_date": "2025-03-14 01:34:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:11:14.681966"
    },
    {
      "arxiv_id": "2402.01669v2",
      "title": "Improved Performances and Motivation in Intelligent Tutoring Systems: Combining Machine Learning and Learner Choice",
      "title_zh": "智能辅导系统中的性能和动机改进：结合机器学习与学习者选择",
      "authors": [
        "Benjamin Clément",
        "Hélène Sauzéon",
        "Didier Roy",
        "Pierre-Yves Oudeyer"
      ],
      "abstract": "Large class sizes challenge personalized learning in schools, prompting the\nuse of educational technologies such as intelligent tutoring systems. To\naddress this, we present an AI-driven personalization system, called ZPDES,\nbased on the Learning Progress Hypothesis - modeling curiosity-driven learning\n- and multi-armed bandit techniques. It sequences exercises that maximize\nlearning progress for each student. While previous studies demonstrated its\nefficacy in enhancing learning compared to hand-made curricula, its impact on\nstudent motivation remained unexplored. Furthermore, ZPDES previously lacked\nfeatures allowing student choice, a limitation in agency that conflicts with\nits foundation on models of curiosity-driven learning. This study investigates\nhow integrating choice, as a gamification element unrelated to exercise\ndifficulty, affects both learning outcomes and motivation. We conducted an\nextensive field study (265 7-8 years old children, RCT design), comparing ZPDES\nwith and without choice against a hand-designed curriculum. Results show that\nZPDES improves both learning performance and the learning experience. Moreover\nadding choice to ZPDES enhances intrinsic motivation and further strengthens\nits learning benefits. In contrast, incorporating choice into a fixed, linear\ncurriculum negatively impacts learning outcomes. These findings highlight that\nthe intrinsic motivation elicited by choice (gamification) is beneficial only\nwhen paired with an adaptive personalized learning system. This insight is\ncritical as gamified features become increasingly prevalent in educational\ntechnologies.",
      "tldr_zh": "这篇论文介绍了 ZPDES 系统，一种基于 Learning Progress Hypothesis 和 multi-armed bandit 技术的智能辅导系统，用于个性化学习序列以最大化学生的学习进步。研究通过大规模实地实验（涉及 265 名 7-8 岁儿童的随机对照试验）比较了 ZPDES 系统（有无学生选择功能）与固定课程，结果显示 ZPDES 显著提升了学习表现和体验，而添加 gamification 元素如学生选择进一步增强了内在动机和学习益处。论文强调，gamification 只有在自适应个性化系统中才有效，否则可能在固定课程中降低学习成果。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "I.2.1; I.2.6"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01669v2",
      "published_date": "2024-01-16 13:41:00 UTC",
      "updated_date": "2025-03-05 08:23:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:11:25.151549"
    },
    {
      "arxiv_id": "2401.08358v1",
      "title": "Hallucination Detection and Hallucination Mitigation: An Investigation",
      "title_zh": "翻译失败",
      "authors": [
        "Junliang Luo",
        "Tianyu Li",
        "Di Wu",
        "Michael Jenkin",
        "Steve Liu",
        "Gregory Dudek"
      ],
      "abstract": "Large language models (LLMs), including ChatGPT, Bard, and Llama, have\nachieved remarkable successes over the last two years in a range of different\napplications. In spite of these successes, there exist concerns that limit the\nwide application of LLMs. A key problem is the problem of hallucination.\nHallucination refers to the fact that in addition to correct responses, LLMs\ncan also generate seemingly correct but factually incorrect responses. This\nreport aims to present a comprehensive review of the current literature on both\nhallucination detection and hallucination mitigation. We hope that this report\ncan serve as a good reference for both engineers and researchers who are\ninterested in LLMs and applying them to real world tasks.",
      "tldr_zh": "这篇论文调查了大型语言模型(LLMs)如ChatGPT、Bard和Llama的幻觉(hallucination)问题，即模型可能生成看似正确但事实错误的响应。作者通过对现有文献的全面回顾，探讨了hallucination detection（幻觉检测）和hallucination mitigation（幻觉缓解）的关键方法和技术。报告旨在为工程师和研究人员提供参考，帮助他们在实际任务中更有效地应用LLMs，以减少幻觉带来的风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08358v1",
      "published_date": "2024-01-16 13:36:07 UTC",
      "updated_date": "2024-01-16 13:36:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:11:35.527783"
    },
    {
      "arxiv_id": "2401.08330v2",
      "title": "Boosting Gradient Ascent for Continuous DR-submodular Maximization",
      "title_zh": "翻译失败",
      "authors": [
        "Qixin Zhang",
        "Zongqi Wan",
        "Zengde Deng",
        "Zaiyi Chen",
        "Xiaoming Sun",
        "Jialin Zhang",
        "Yu Yang"
      ],
      "abstract": "Projected Gradient Ascent (PGA) is the most commonly used optimization scheme\nin machine learning and operations research areas. Nevertheless, numerous\nstudies and examples have shown that the PGA methods may fail to achieve the\ntight approximation ratio for continuous DR-submodular maximization problems.\nTo address this challenge, we present a boosting technique in this paper, which\ncan efficiently improve the approximation guarantee of the standard PGA to\n\\emph{optimal} with only small modifications on the objective function. The\nfundamental idea of our boosting technique is to exploit non-oblivious search\nto derive a novel auxiliary function $F$, whose stationary points are excellent\napproximations to the global maximum of the original DR-submodular objective\n$f$. Specifically, when $f$ is monotone and $\\gamma$-weakly DR-submodular, we\npropose an auxiliary function $F$ whose stationary points can provide a better\n$(1-e^{-\\gamma})$-approximation than the\n$(\\gamma^2/(1+\\gamma^2))$-approximation guaranteed by the stationary points of\n$f$ itself. Similarly, for the non-monotone case, we devise another auxiliary\nfunction $F$ whose stationary points can achieve an optimal\n$\\frac{1-\\min_{\\boldsymbol{x}\\in\\mathcal{C}}\\|\\boldsymbol{x}\\|_{\\infty}}{4}$-approximation\nguarantee where $\\mathcal{C}$ is a convex constraint set. In contrast, the\nstationary points of the original non-monotone DR-submodular function can be\narbitrarily bad~\\citep{chen2023continuous}. Furthermore, we demonstrate the\nscalability of our boosting technique on four problems. In all of these four\nproblems, our resulting variants of boosting PGA algorithm beat the previous\nstandard PGA in several aspects such as approximation ratio and efficiency.\nFinally, we corroborate our theoretical findings with numerical experiments,\nwhich demonstrate the effectiveness of our boosting PGA methods.",
      "tldr_zh": "这篇论文针对连续 DR-submodular 最大化问题，提出了一种 boosting 技术，以提升 Projected Gradient Ascent (PGA) 的逼近保证，通过对目标函数进行小修改并利用 non-oblivious search 创建辅助函数 F，使其静止点更好地逼近原函数的全局最大。对于单调的 γ-weakly DR-submodular 函数，该方法提供 (1-e^{-γ}) 的逼近比，优于原函数的 (γ^2/(1+γ^2))；对于非单调情况，则达到最优的 \\frac{1-\\min_{\\boldsymbol{x}\\in\\mathcal{C}}\\|\\boldsymbol{x}\\|_{\\infty}}{4} 逼近比。实验在四个问题上验证了该技术的可扩展性和效率提升，并通过数值实验证实了其实际有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "74 pages, 6 figures and 9 tables. An extended version of Stochastic\n  Continuous Submodular Maximization: Boosting via Non-oblivious Function (ICML\n  2022)",
      "pdf_url": "http://arxiv.org/pdf/2401.08330v2",
      "published_date": "2024-01-16 12:49:10 UTC",
      "updated_date": "2024-07-24 08:13:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:11:50.956262"
    },
    {
      "arxiv_id": "2401.08326v3",
      "title": "RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning",
      "title_zh": "RoTBench：用于评估大型语言模型在工具学习中鲁棒性的多层次基准",
      "authors": [
        "Junjie Ye",
        "Yilong Wu",
        "Songyang Gao",
        "Caishuang Huang",
        "Sixian Li",
        "Guanyu Li",
        "Xiaoran Fan",
        "Qi Zhang",
        "Tao Gui",
        "Xuanjing Huang"
      ],
      "abstract": "Tool learning has generated widespread interest as a vital means of\ninteraction between Large Language Models (LLMs) and the physical world.\nCurrent research predominantly emphasizes LLMs' capacity to utilize tools in\nwell-structured environments while overlooking their stability when confronted\nwith the inevitable noise of the real world. To bridge this gap, we introduce\nRoTBench, a multi-level benchmark for evaluating the robustness of LLMs in tool\nlearning. Specifically, we establish five external environments, each featuring\nvarying levels of noise (i.e., Clean, Slight, Medium, Heavy, and Union),\nproviding an in-depth analysis of the model's resilience across three critical\nphases: tool selection, parameter identification, and content filling.\nExperiments involving six widely-used models underscore the urgent necessity\nfor enhancing the robustness of LLMs in tool learning. For instance, the\nperformance of GPT-4 even drops significantly from 80.00 to 58.10 when there is\nno substantial change in manual accuracy. More surprisingly, the noise\ncorrection capability inherent in the GPT family paradoxically impedes its\nadaptability in the face of mild noise. In light of these findings, we propose\nRoTTuning, a strategy that enriches the diversity of training environments to\nbolster the robustness of LLMs in tool learning. The code and data are\navailable at https://github.com/Junjie-Ye/RoTBench.",
      "tldr_zh": "该论文引入了 RoTBench，一种多级基准，用于评估大型语言模型 (LLMs) 在工具学习中的鲁棒性，旨在解决现有研究忽略真实世界噪声对模型稳定性的影响。RoTBench 构建了五个外部环境（Clean、Slight、Medium、Heavy 和 Union），并分析模型在工具选择、参数识别和内容填充等三个关键阶段的弹性。实验结果显示，六种常用模型如 GPT-4 的性能在噪声环境下显著下降（例如从 80.00 降至 58.10），并揭示 GPT 家族的噪声修正能力反而在轻微噪声下阻碍了适应性。为此，论文提出 RoTTuning 策略，通过丰富训练环境的多样性来提升 LLMs 在工具学习的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Main conference",
      "pdf_url": "http://arxiv.org/pdf/2401.08326v3",
      "published_date": "2024-01-16 12:45:15 UTC",
      "updated_date": "2024-09-21 08:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:12:02.049882"
    },
    {
      "arxiv_id": "2403.12058v1",
      "title": "Water-Based Metaheuristics: How Water Dynamics Can Help Us to Solve NP-Hard Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Fernando Rubio",
        "Ismael Rodríguez"
      ],
      "abstract": "Many water-based optimization metaheuristics have been introduced during the\nlast decade, both for combinatorial and for continuous optimization. Despite\nthe strong similarities of these methods in terms of their underlying natural\nmetaphors (most of them emulate, in some way or another, how drops\ncollaboratively form paths down to the sea), in general the resulting\nalgorithms are quite different in terms of their searching approach or their\nsolution construction approach. For instance, each entity may represent a\nsolution by itself or, alternatively, entities may construct solutions by\nmodifying the landscape while moving. A researcher or practitioner could assume\nthat the degree of similarity between two water-based metaheuristics heavily\ndepends on the similarity of the natural water mechanics they emulate, but this\nis not the case. In order to bring some clarity to this mosaic of apparently\nrelated metaheuristics, in this paper we introduce them, explain their\nmechanics, and highlight their differences.",
      "tldr_zh": "这篇论文探讨了基于水的元启发式算法（water-based metaheuristics），这些算法通过模仿水动力学（如水滴协作形成路径）来解决 NP-Hard 问题，包括组合优化和连续优化。尽管这些算法共享相似的自然隐喻，但它们在搜索方法或解决方案构建方式上存在显著差异，例如实体可能独立代表解决方案或通过修改景观来构建。论文对这些算法进行了介绍、机制解释，并突出了它们的差异，以帮助研究者和从业者更好地理解这一领域。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "68T20",
        "I.2"
      ],
      "primary_category": "cs.NE",
      "comment": "14 pages, 0 figures, published in journal Complexity, 2019",
      "pdf_url": "http://arxiv.org/pdf/2403.12058v1",
      "published_date": "2024-01-16 11:39:42 UTC",
      "updated_date": "2024-01-16 11:39:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:12:16.368963"
    },
    {
      "arxiv_id": "2401.08273v3",
      "title": "Large Language Models are Null-Shot Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Pittawat Taveekitworachai",
        "Febri Abdullah",
        "Ruck Thawonmas"
      ],
      "abstract": "This paper presents null-shot prompting. Null-shot prompting exploits\nhallucination in large language models (LLMs) by instructing LLMs to utilize\ninformation from the \"Examples\" section that never exists within the provided\ncontext to perform a task. While reducing hallucination is crucial and\nnon-negligible for daily and critical uses of LLMs, we propose that in the\ncurrent landscape in which these LLMs still hallucinate, it is possible, in\nfact, to exploit hallucination to increase performance in performing tasks\ncompared to standard zero-shot prompting. Experiments with eight LLMs show\nimprovements in performance across the majority of eight datasets, including\nreading comprehension, arithmetic reasoning, and closed-book question\nanswering. The observed inconsistency in increased relative performance across\nthe LLMs also potentially indicates a different degree of inherent\nhallucination in each model. These differences show that it is possible to\nutilize null-shot prompting as a way to detect degrees of hallucination in LLMs\nusing existing benchmarking datasets. We also perform ablation studies,\nincluding experimenting with a modified version of null-shot prompting that\nincorporates ideas from zero-shot chain-of-thought prompting, which shows\ndifferent trends of results.",
      "tldr_zh": "本论文提出了一种名为 null-shot prompting 的新方法，利用大型语言模型 (LLMs) 的 hallucination 特性，通过指令模型使用不存在的“Examples”部分信息来执行任务，从而提升性能。相比标准 zero-shot prompting，该方法在八个数据集（包括阅读理解、算术推理和闭卷问答）上的实验显示，大多数 LLMs 的表现有所改善，并揭示了不同模型间 hallucination 程度的差异。论文进一步通过消融研究，包括结合 zero-shot chain-of-thought 的变体，探讨了这种方法的潜力，并建议其可作为检测 LLMs hallucination 程度的工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages; v2: added Gemini Pro results, error analysis, and a\n  discussion on confabulation; v3: see its extended version, an EMNLP 2024\n  paper, at https://aclanthology.org/2024.emnlp-main.740/",
      "pdf_url": "http://arxiv.org/pdf/2401.08273v3",
      "published_date": "2024-01-16 10:53:11 UTC",
      "updated_date": "2024-11-16 04:23:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:12:27.508684"
    },
    {
      "arxiv_id": "2401.08268v2",
      "title": "An Explainable Proxy Model for Multiabel Audio Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Théo Mariotte",
        "Antonio Almudévar",
        "Marie Tahon",
        "Alfonso Ortega"
      ],
      "abstract": "Audio signal segmentation is a key task for automatic audio indexing. It\nconsists of detecting the boundaries of class-homogeneous segments in the\nsignal. In many applications, explainable AI is a vital process for\ntransparency of decision-making with machine learning. In this paper, we\npropose an explainable multilabel segmentation model that solves speech\nactivity (SAD), music (MD), noise (ND), and overlapped speech detection (OSD)\nsimultaneously. This proxy uses the non-negative matrix factorization (NMF) to\nmap the embedding used for the segmentation to the frequency domain.\nExperiments conducted on two datasets show similar performances as the\npre-trained black box model while showing strong explainability features.\nSpecifically, the frequency bins used for the decision can be easily identified\nat both the segment level (local explanations) and global level (class\nprototypes).",
      "tldr_zh": "这篇论文提出了一种可解释的多标签音频分割代理模型，用于同时检测语音活动 (SAD)、音乐 (MD)、噪声 (ND) 和重叠语音 (OSD)，以提升机器学习决策的透明性。模型采用非负矩阵分解 (NMF) 将用于分割的嵌入映射到频域，从而实现对决策过程的解释。实验在两个数据集上显示，该模型的性能与预训练黑盒模型相当，并能轻松识别频率 bin 在段级 (局部解释) 和全局级 (类原型) 的作用。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.08268v2",
      "published_date": "2024-01-16 10:41:33 UTC",
      "updated_date": "2024-01-17 13:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:12:41.134831"
    },
    {
      "arxiv_id": "2401.08261v2",
      "title": "Probabilistically Robust Watermarking of Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Mikhail Pautov",
        "Nikita Bogdanov",
        "Stanislav Pyatkin",
        "Oleg Rogov",
        "Ivan Oseledets"
      ],
      "abstract": "As deep learning (DL) models are widely and effectively used in Machine\nLearning as a Service (MLaaS) platforms, there is a rapidly growing interest in\nDL watermarking techniques that can be used to confirm the ownership of a\nparticular model. Unfortunately, these methods usually produce watermarks\nsusceptible to model stealing attacks. In our research, we introduce a novel\ntrigger set-based watermarking approach that demonstrates resilience against\nfunctionality stealing attacks, particularly those involving extraction and\ndistillation. Our approach does not require additional model training and can\nbe applied to any model architecture. The key idea of our method is to compute\nthe trigger set, which is transferable between the source model and the set of\nproxy models with a high probability. In our experimental study, we show that\nif the probability of the set being transferable is reasonably high, it can be\neffectively used for ownership verification of the stolen model. We evaluate\nour method on multiple benchmarks and show that our approach outperforms\ncurrent state-of-the-art watermarking techniques in all considered experimental\nsetups.",
      "tldr_zh": "该论文提出了一种概率鲁棒的神经网络 watermarking 方法，用于确认深度学习模型在 Machine Learning as a Service (MLaaS) 平台上的所有权，并抵抗功能窃取攻击如模型提取和蒸馏。该方法基于一个可转移的 trigger set，不需要额外模型训练，且适用于任何架构。通过计算 trigger set 在源模型和代理模型之间的高概率转移性，实现了有效的所有权验证。实验结果显示，该方法在多个基准上优于现有最先进的技术，显著提升了 watermarking 的鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08261v2",
      "published_date": "2024-01-16 10:32:13 UTC",
      "updated_date": "2024-09-18 16:50:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:12:52.344818"
    },
    {
      "arxiv_id": "2401.08255v1",
      "title": "A Generative Adversarial Attack for Multilingual Text Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Tom Roth",
        "Inigo Jauregi Unanue",
        "Alsharif Abuadbba",
        "Massimo Piccardi"
      ],
      "abstract": "Current adversarial attack algorithms, where an adversary changes a text to\nfool a victim model, have been repeatedly shown to be effective against text\nclassifiers. These attacks, however, generally assume that the victim model is\nmonolingual and cannot be used to target multilingual victim models, a\nsignificant limitation given the increased use of these models. For this\nreason, in this work we propose an approach to fine-tune a multilingual\nparaphrase model with an adversarial objective so that it becomes able to\ngenerate effective adversarial examples against multilingual classifiers. The\ntraining objective incorporates a set of pre-trained models to ensure text\nquality and language consistency of the generated text. In addition, all the\nmodels are suitably connected to the generator by vocabulary-mapping matrices,\nallowing for full end-to-end differentiability of the overall training\npipeline. The experimental validation over two multilingual datasets and five\nlanguages has shown the effectiveness of the proposed approach compared to\nexisting baselines, particularly in terms of query efficiency. We also provide\na detailed analysis of the generated attacks and discuss limitations and\nopportunities for future research.",
      "tldr_zh": "本研究针对现有对抗攻击算法无法有效攻击多语种文本分类器的问题，提出了一种生成式对抗攻击方法，通过微调多语种改写模型并采用对抗目标，生成针对多语种分类器的有效对抗样本。训练过程整合预训练模型来确保生成的文本质量和语言一致性，并使用词汇映射矩阵实现端到端可微训练，从而提高整体效率。在两个多语种数据集和五种语言的实验中，该方法在查询效率上优于现有基线，并通过详细分析讨论了生成的攻击样本的特性以及未来研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI-24 Workshop on Artificial Intelligence for Cyber Security (AICS)",
      "pdf_url": "http://arxiv.org/pdf/2401.08255v1",
      "published_date": "2024-01-16 10:14:27 UTC",
      "updated_date": "2024-01-16 10:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:13:04.088733"
    },
    {
      "arxiv_id": "2401.08221v1",
      "title": "Towards Causal Relationship in Indefinite Data: Baseline Model and New Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Chen",
        "Xinyu Yang",
        "Keqing Du"
      ],
      "abstract": "Integrating deep learning and causal discovery has encouraged us to spot that\nlearning causal structures and representations in dialogue and video is full of\nchallenges. We defined These data forms as \"Indefinite Data\", characterized by\nmulti-structure data and multi-value representations. Unlike existing adaptable\ndata forms, Indefinite Data still faces gaps in datasets and methods. To\naddress the dataset gap, we release two high-quality datasets - Causalogue and\nCausaction, containing text dialogue samples and video action samples with\ncausal annotations respectively. Moreover, the method gap arises from the\ncoexistence of multi-structure data and multi-value representations, breaking\nthe assumptions of all current methods and rendering them infeasible on\nIndefinite Data. To this end, we propose a probabilistic framework as a\nbaseline, incorporating three designed highlights for this gap: 1) establishing\nCausation Condition of representations using the independence of noise terms\nunder non-fixed causal structures, 2) treating causal strength as a latent\nvariable and measuring the reconstruction loss in the correlation space, and 3)\nestimating the effects of latent confounders. These highpoints make the\nprobabilistic model capable of overcoming challenges brought by the coexistence\nof multi-structure data and multi-value representations and pave the way for\nthe extension of latent confounders. Comprehensive experiments have evaluated\nbaseline results of causal structures, causal representations, and confounding\ndisentanglement.",
      "tldr_zh": "这篇论文针对“Indefinite Data”（如对话和视频）中因果结构和表示的学习挑战，定义了其多结构数据和多值表示的特点，并发布了两个高质量数据集：Causalogue（文本对话样本）和 Causaction（视频动作样本），这些数据集包含了因果标注以填补数据缺口。作者提出一个概率框架作为基线模型，突出的三个设计亮点包括：1）使用噪声项独立性建立表示的因果条件，2）将因果强度视为潜变量并在相关空间测量重构损失，3）估计潜变量混淆因素，从而处理多结构数据和多值表示的共存问题。实验结果全面评估了该框架在因果 structures、causal representations 和 confounding disentanglement 方面的基线性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "If you are interested in the two new datasets, pls contact us by\n  email",
      "pdf_url": "http://arxiv.org/pdf/2401.08221v1",
      "published_date": "2024-01-16 09:15:43 UTC",
      "updated_date": "2024-01-16 09:15:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:13:18.245725"
    },
    {
      "arxiv_id": "2402.03337v1",
      "title": "Reinforcement-learning robotic sailboats: simulator and preliminary results",
      "title_zh": "翻译失败",
      "authors": [
        "Eduardo Charles Vasconcellos",
        "Ronald M Sampaio",
        "André P D Araújo",
        "Esteban Walter Gonzales Clua",
        "Philippe Preux",
        "Raphael Guerra",
        "Luiz M G Gonçalves",
        "Luis Martí",
        "Hernan Lira",
        "Nayat Sanchez-Pi"
      ],
      "abstract": "This work focuses on the main challenges and problems in developing a virtual\noceanic environment reproducing real experiments using Unmanned Surface\nVehicles (USV) digital twins. We introduce the key features for building\nvirtual worlds, considering using Reinforcement Learning (RL) agents for\nautonomous navigation and control. With this in mind, the main problems concern\nthe definition of the simulation equations (physics and mathematics), their\neffective implementation, and how to include strategies for simulated control\nand perception (sensors) to be used with RL. We present the modeling,\nimplementation steps, and challenges required to create a functional digital\ntwin based on a real robotic sailing vessel. The application is immediate for\ndeveloping navigation algorithms based on RL to be applied on real boats.",
      "tldr_zh": "该论文探讨了开发虚拟海洋环境以模拟真实无人水面车辆 (USV) 实验的关键挑战，聚焦于使用 Reinforcement Learning (RL) 代理实现自主导航和控制。研究者详细介绍了模拟方程的建模和实施步骤，包括物理、数学模型以及整合传感器策略的感知系统，以创建基于真实机器人帆船的数字孪生。初步结果表明，这种方法为开发可应用于真实船只的 RL 基于导航算法提供了坚实基础，并突出了潜在的技术难题。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03337v1",
      "published_date": "2024-01-16 09:04:05 UTC",
      "updated_date": "2024-01-16 09:04:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:13:27.886545"
    },
    {
      "arxiv_id": "2401.08721v1",
      "title": "A Telerehabilitation System for the Selection, Evaluation and Remote Management of Therapies",
      "title_zh": "一种用于疗法选择、评估和远程管理的远程康复系统",
      "authors": [
        "David Anton",
        "Idoia Berges",
        "Jesús Bermúdez",
        "Alfredo Goñi",
        "Arantza Illarramendi"
      ],
      "abstract": "Telerehabilitation systems that support physical therapy sessions anywhere\ncan help save healthcare costs while also improving the quality of life of the\nusers that need rehabilitation. The main contribution of this paper is to\npresent, as a whole, all the features supported by the innovative Kinect-based\nTelerehabilitation System (KiReS). In addition to the functionalities provided\nby current systems, it handles two new ones that could be incorporated into\nthem, in order to give a step forward towards a new generation of\ntelerehabilitation systems. The knowledge extraction functionality handles\nknowledge about the physical therapy record of patients and treatment protocols\ndescribed in an ontology, named TRHONT, to select the adequate exercises for\nthe rehabilitation of patients. The teleimmersion functionality provides a\nconvenient, effective and user-friendly experience when performing the\ntelerehabilitation, through a two-way real-time multimedia communication. The\nontology contains about 2300 classes and 100 properties, and the system allows\na reliable transmission of Kinect video depth, audio and skeleton data, being\nable to adapt to various network conditions. Moreover, the system has been\ntested with patients who suffered from shoulder disorders or total hip\nreplacement.",
      "tldr_zh": "本文提出一个创新的 Kinect-based Telerehabilitation System (KiReS)，旨在通过远程支持物理疗程来降低医疗成本并提升患者生活质量。系统整合了知识提取功能，利用 TRHONT 本体（包含约2300个类和100个属性）来分析患者康复记录并选择合适的锻炼，同时提供远程沉浸功能，支持双向实时多媒体通信，包括Kinect视频深度、音频和骨骼数据的可靠传输。测试结果显示，该系统适应各种网络条件，并在肩部疾病和髋关节置换患者中表现出有效性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08721v1",
      "published_date": "2024-01-16 08:35:36 UTC",
      "updated_date": "2024-01-16 08:35:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:13:40.110828"
    },
    {
      "arxiv_id": "2401.08194v1",
      "title": "End-to-End Optimized Image Compression with the Frequency-Oriented Transform",
      "title_zh": "翻译失败",
      "authors": [
        "Yuefeng Zhang",
        "Kai Lin"
      ],
      "abstract": "Image compression constitutes a significant challenge amidst the era of\ninformation explosion. Recent studies employing deep learning methods have\ndemonstrated the superior performance of learning-based image compression\nmethods over traditional codecs. However, an inherent challenge associated with\nthese methods lies in their lack of interpretability. Following an analysis of\nthe varying degrees of compression degradation across different frequency\nbands, we propose the end-to-end optimized image compression model facilitated\nby the frequency-oriented transform. The proposed end-to-end image compression\nmodel consists of four components: spatial sampling, frequency-oriented\ntransform, entropy estimation, and frequency-aware fusion. The\nfrequency-oriented transform separates the original image signal into distinct\nfrequency bands, aligning with the human-interpretable concept. Leveraging the\nnon-overlapping hypothesis, the model enables scalable coding through the\nselective transmission of arbitrary frequency components. Extensive experiments\nare conducted to demonstrate that our model outperforms all traditional codecs\nincluding next-generation standard H.266/VVC on MS-SSIM metric. Moreover,\nvisual analysis tasks (i.e., object detection and semantic segmentation) are\nconducted to verify the proposed compression method could preserve semantic\nfidelity besides signal-level precision.",
      "tldr_zh": "这篇论文针对图像压缩的挑战，提出了一种端到端优化的模型，利用 frequency-oriented transform 来分析和处理不同频率带的压缩退化问题。模型由 spatial sampling、frequency-oriented transform、entropy estimation 和 frequency-aware fusion 四个组件组成，通过非重叠假设实现可伸缩编码，并允许选择性传输频率组件。实验结果表明，该模型在 MS-SSIM 指标上优于传统编解码器如 H.266/VVC，并在视觉任务（如物体检测和语义分割）中有效保留语义保真度，而不仅仅是信号级精度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, accepted by MVAP",
      "pdf_url": "http://arxiv.org/pdf/2401.08194v1",
      "published_date": "2024-01-16 08:16:10 UTC",
      "updated_date": "2024-01-16 08:16:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:13:54.016632"
    },
    {
      "arxiv_id": "2401.08189v4",
      "title": "PRewrite: Prompt Rewriting with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Weize Kong",
        "Spurthi Amba Hombaiah",
        "Mingyang Zhang",
        "Qiaozhu Mei",
        "Michael Bendersky"
      ],
      "abstract": "Prompt engineering is critical for the development of LLM-based applications.\nHowever, it is usually done manually in a \"trial and error\" fashion that can be\ntime consuming, ineffective, and sub-optimal. Even for the prompts which\nseemingly work well, there is always a lingering question: can the prompts be\nmade better with further modifications?\n  To address these problems, we investigate automated prompt engineering in\nthis paper. Specifically, we propose PRewrite, an automated method to rewrite\nan under-optimized prompt to a more effective prompt. We instantiate the prompt\nrewriter using a LLM. The rewriter LLM is trained using reinforcement learning\nto optimize the performance on a given downstream task. We conduct experiments\non diverse benchmark datasets, which demonstrates the effectiveness of\nPRewrite.",
      "tldr_zh": "论文指出，手动提示工程（Prompt engineering）在开发LLM-based应用时往往采用试错方式，耗时且可能不理想，难以进一步优化。针对这些问题，研究提出PRewrite，一种自动化提示重写方法，使用LLM作为重写器，并通过强化学习（Reinforcement Learning）训练以提升下游任务的性能。在多样基准数据集上的实验证明了PRewrite的有效性，能够显著改善提示质量。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08189v4",
      "published_date": "2024-01-16 08:04:50 UTC",
      "updated_date": "2024-06-10 13:46:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:14:03.092978"
    },
    {
      "arxiv_id": "2401.08185v1",
      "title": "DPAFNet:Dual Path Attention Fusion Network for Single Image Deraining",
      "title_zh": "翻译失败",
      "authors": [
        "Bingcai Wei"
      ],
      "abstract": "Rainy weather will have a significant impact on the regular operation of the\nimaging system. Based on this premise, image rain removal has always been a\npopular branch of low-level visual tasks, especially methods using deep neural\nnetworks. However, most neural networks are but-branched, such as only using\nconvolutional neural networks or Transformers, which is unfavourable for the\nmultidimensional fusion of image features. In order to solve this problem, this\npaper proposes a dual-branch attention fusion network. Firstly, a two-branch\nnetwork structure is proposed. Secondly, an attention fusion module is proposed\nto selectively fuse the features extracted by the two branches rather than\nsimply adding them. Finally, complete ablation experiments and sufficient\ncomparison experiments prove the rationality and effectiveness of the proposed\nmethod.",
      "tldr_zh": "这篇论文针对雨天对成像系统的负面影响，提出了一种名为 DPAFNet 的双分支注意力融合网络，用于单图像去雨任务。DPAFNet 包括一个双分支网络结构，用于提取图像特征，以及一个注意力融合模块，能够选择性地融合两个分支的特征，而不是简单相加，从而实现多维特征融合。实验结果通过完整的消融实验和比较实验证明，该方法比传统单分支网络（如基于 convolutional neural networks 或 Transformers 的方法）更有效，提升了图像去雨的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08185v1",
      "published_date": "2024-01-16 08:01:09 UTC",
      "updated_date": "2024-01-16 08:01:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:14:15.915770"
    },
    {
      "arxiv_id": "2401.08138v1",
      "title": "LLMs for Test Input Generation for Semantic Caches",
      "title_zh": "翻译失败",
      "authors": [
        "Zafaryab Rasool",
        "Scott Barnett",
        "David Willie",
        "Stefanus Kurniawan",
        "Sherwin Balugo",
        "Srikanth Thudumu",
        "Mohamed Abdelrazek"
      ],
      "abstract": "Large language models (LLMs) enable state-of-the-art semantic capabilities to\nbe added to software systems such as semantic search of unstructured documents\nand text generation. However, these models are computationally expensive. At\nscale, the cost of serving thousands of users increases massively affecting\nalso user experience. To address this problem, semantic caches are used to\ncheck for answers to similar queries (that may have been phrased differently)\nwithout hitting the LLM service. Due to the nature of these semantic cache\ntechniques that rely on query embeddings, there is a high chance of errors\nimpacting user confidence in the system. Adopting semantic cache techniques\nusually requires testing the effectiveness of a semantic cache (accurate cache\nhits and misses) which requires a labelled test set of similar queries and\nresponses which is often unavailable. In this paper, we present VaryGen, an\napproach for using LLMs for test input generation that produces similar\nquestions from unstructured text documents. Our novel approach uses the\nreasoning capabilities of LLMs to 1) adapt queries to the domain, 2) synthesise\nsubtle variations to queries, and 3) evaluate the synthesised test dataset. We\nevaluated our approach in the domain of a student question and answer system by\nqualitatively analysing 100 generated queries and result pairs, and conducting\nan empirical case study with an open source semantic cache. Our results show\nthat query pairs satisfy human expectations of similarity and our generated\ndata demonstrates failure cases of a semantic cache. Additionally, we also\nevaluate our approach on Qasper dataset. This work is an important first step\ninto test input generation for semantic applications and presents\nconsiderations for practitioners when calibrating a semantic cache.",
      "tldr_zh": "本研究提出 VaryGen，一种利用 Large Language Models (LLMs) 生成测试输入的方法，旨在评估语义缓存的准确性（包括缓存命中和失误），解决标记测试数据集缺失的问题。VaryGen 借助 LLMs 的推理能力，实现在特定领域适应查询、合成细微查询变异，以及评估生成的测试数据集。实验结果显示，在学生问答系统上对 100 个查询对进行定性分析，以及在开源语义缓存和 Qasper 数据集上的实证研究中，生成的查询对符合人类对相似性的期望，并成功揭示了语义缓存的失败案例，为语义应用的测试和缓存校准提供重要指导。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted in International Conference on AI Engineering Software\n  Engineering (CAIN 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.08138v1",
      "published_date": "2024-01-16 06:16:33 UTC",
      "updated_date": "2024-01-16 06:16:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:14:31.141789"
    },
    {
      "arxiv_id": "2401.08121v1",
      "title": "CycLight: learning traffic signal cooperation with a cycle-level strategy",
      "title_zh": "CycLight：采用周期级策略学习交通信号合作",
      "authors": [
        "Gengyue Han",
        "Xiaohan Liu",
        "Xianyue Peng",
        "Hao Wang",
        "Yu Han"
      ],
      "abstract": "This study introduces CycLight, a novel cycle-level deep reinforcement\nlearning (RL) approach for network-level adaptive traffic signal control\n(NATSC) systems. Unlike most traditional RL-based traffic controllers that\nfocus on step-by-step decision making, CycLight adopts a cycle-level strategy,\noptimizing cycle length and splits simultaneously using Parameterized Deep\nQ-Networks (PDQN) algorithm. This cycle-level approach effectively reduces the\ncomputational burden associated with frequent data communication, meanwhile\nenhancing the practicality and safety of real-world applications. A\ndecentralized framework is formulated for multi-agent cooperation, while\nattention mechanism is integrated to accurately assess the impact of the\nsurroundings on the current intersection. CycLight is tested in a large\nsynthetic traffic grid using the microscopic traffic simulation tool, SUMO.\nExperimental results not only demonstrate the superiority of CycLight over\nother state-of-the-art approaches but also showcase its robustness against\ninformation transmission delays.",
      "tldr_zh": "本研究提出CycLight，一种基于cycle-level深度强化学习（RL）的创新方法，用于网络级自适应交通信号控制（NATSC），它通过Parameterized Deep Q-Networks (PDQN)算法同时优化周期长度和信号分配，从而减少计算负担并提升实际应用的安全性。CycLight采用分散式多代理合作框架，并整合注意力机制来评估周边环境对当前路口的影响。实验在SUMO模拟工具的大型合成交通网格中进行，结果显示CycLight优于现有先进方法，并在信息传输延迟方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08121v1",
      "published_date": "2024-01-16 05:28:12 UTC",
      "updated_date": "2024-01-16 05:28:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:14:40.298898"
    },
    {
      "arxiv_id": "2401.08117v1",
      "title": "E2HQV: High-Quality Video Generation from Event Camera via Theory-Inspired Model-Aided Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Qiang Qu",
        "Yiran Shen",
        "Xiaoming Chen",
        "Yuk Ying Chung",
        "Tongliang Liu"
      ],
      "abstract": "The bio-inspired event cameras or dynamic vision sensors are capable of\nasynchronously capturing per-pixel brightness changes (called event-streams) in\nhigh temporal resolution and high dynamic range. However, the non-structural\nspatial-temporal event-streams make it challenging for providing intuitive\nvisualization with rich semantic information for human vision. It calls for\nevents-to-video (E2V) solutions which take event-streams as input and generate\nhigh quality video frames for intuitive visualization. However, current\nsolutions are predominantly data-driven without considering the prior knowledge\nof the underlying statistics relating event-streams and video frames. It highly\nrelies on the non-linearity and generalization capability of the deep neural\nnetworks, thus, is struggling on reconstructing detailed textures when the\nscenes are complex. In this work, we propose \\textbf{E2HQV}, a novel E2V\nparadigm designed to produce high-quality video frames from events. This\napproach leverages a model-aided deep learning framework, underpinned by a\ntheory-inspired E2V model, which is meticulously derived from the fundamental\nimaging principles of event cameras. To deal with the issue of state-reset in\nthe recurrent components of E2HQV, we also design a temporal shift embedding\nmodule to further improve the quality of the video frames. Comprehensive\nevaluations on the real world event camera datasets validate our approach, with\nE2HQV, notably outperforming state-of-the-art approaches, e.g., surpassing the\nsecond best by over 40\\% for some evaluation metrics.",
      "tldr_zh": "该研究针对事件相机（event cameras）捕获的事件流（event-streams）难以直观可视化的挑战，提出了一种新型 E2V（events-to-video）框架 E2HQV，利用理论驱动的模型辅助深度学习方法来生成高质量视频帧。E2HQV 基于事件相机成像原理构建的理论启发模型，并引入 temporal shift embedding 模块来解决循环组件中的状态重置问题，从而提升视频帧的细节重建和质量。在真实数据集上的全面评估中，E2HQV 显著优于现有方法，例如某些指标超过了第二佳方法 40% 以上。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in AAAI2024",
      "pdf_url": "http://arxiv.org/pdf/2401.08117v1",
      "published_date": "2024-01-16 05:10:50 UTC",
      "updated_date": "2024-01-16 05:10:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:14:52.165745"
    },
    {
      "arxiv_id": "2401.08115v2",
      "title": "No-Clean-Reference Image Super-Resolution: Application to Electron Microscopy",
      "title_zh": "无清洁参考图像超",
      "authors": [
        "Mohammad Khateri",
        "Morteza Ghahremani",
        "Alejandra Sierra",
        "Jussi Tohka"
      ],
      "abstract": "The inability to acquire clean high-resolution (HR) electron microscopy (EM)\nimages over a large brain tissue volume hampers many neuroscience studies. To\naddress this challenge, we propose a deep-learning-based image super-resolution\n(SR) approach to computationally reconstruct clean HR 3D-EM with a large field\nof view (FoV) from noisy low-resolution (LR) acquisition. Our contributions are\nI) Investigating training with no-clean references for $\\ell_2$ and $\\ell_1$\nloss functions; II) Introducing a novel network architecture, named EMSR, for\nenhancing the resolution of LR EM images while reducing inherent noise; and,\nIII) Comparing different training strategies including using acquired LR and HR\nimage pairs, i.e., real pairs with no-clean references contaminated with real\ncorruptions, the pairs of synthetic LR and acquired HR, as well as acquired LR\nand denoised HR pairs. Experiments with nine brain datasets showed that\ntraining with real pairs can produce high-quality super-resolved results,\ndemonstrating the feasibility of training with non-clean references for both\nloss functions. Additionally, comparable results were observed, both visually\nand numerically, when employing denoised and noisy references for training.\nMoreover, utilizing the network trained with synthetically generated LR images\nfrom HR counterparts proved effective in yielding satisfactory SR results, even\nin certain cases, outperforming training with real pairs. The proposed SR\nnetwork was compared quantitatively and qualitatively with several established\nSR techniques, showcasing either the superiority or competitiveness of the\nproposed method in mitigating noise while recovering fine details.",
      "tldr_zh": "该论文针对电子显微镜（Electron Microscopy）图像中无法获取干净高分辨率（HR）图像的问题，提出了一种基于深度学习的图像超分辨率（Image Super-Resolution）方法，用于从噪声低分辨率（LR）图像重建高质量的3D-EM图像。研究的主要贡献包括：调查在无清洁参考条件下使用\\(\\ell_2\\)和\\(\\ell_1\\)损失函数进行训练、引入新型网络架构EMSR以增强图像分辨率并减少噪声，以及比较多种训练策略如实际LR-HR图像对、合成LR与实际HR图像对等。实验在九个大脑数据集上表明，使用实际图像对训练能产生高品质超分辨率结果，且EMSR网络在减少噪声和恢复细节方面优于或与现有技术相当。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 12 figures, and 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.08115v2",
      "published_date": "2024-01-16 05:05:08 UTC",
      "updated_date": "2024-01-26 11:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:15:08.241899"
    },
    {
      "arxiv_id": "2401.08105v1",
      "title": "Hardware Acceleration for Real-Time Wildfire Detection Onboard Drone Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Austin Briley",
        "Fatemeh Afghah"
      ],
      "abstract": "Early wildfire detection in remote and forest areas is crucial for minimizing\ndevastation and preserving ecosystems. Autonomous drones offer agile access to\nremote, challenging terrains, equipped with advanced imaging technology that\ndelivers both high-temporal and detailed spatial resolution, making them\nvaluable assets in the early detection and monitoring of wildfires. However,\nthe limited computation and battery resources of Unmanned Aerial Vehicles\n(UAVs) pose significant challenges in implementing robust and efficient image\nclassification models. Current works in this domain often operate offline,\nemphasizing the need for solutions that can perform inference in real time,\ngiven the constraints of UAVs. To address these challenges, this paper aims to\ndevelop a real-time image classification and fire segmentation model. It\npresents a comprehensive investigation into hardware acceleration using the\nJetson Nano P3450 and the implications of TensorRT, NVIDIA's high-performance\ndeep-learning inference library, on fire classification accuracy and speed. The\nstudy includes implementations of Quantization Aware Training (QAT), Automatic\nMixed Precision (AMP), and post-training mechanisms, comparing them against the\nlatest baselines for fire segmentation and classification. All experiments\nutilize the FLAME dataset - an image dataset collected by low-altitude drones\nduring a prescribed forest fire. This work contributes to the ongoing efforts\nto enable real-time, on-board wildfire detection capabilities for UAVs,\naddressing speed and the computational and energy constraints of these crucial\nmonitoring systems. The results show a 13% increase in classification speed\ncompared to similar models without hardware optimization. Comparatively, loss\nand accuracy are within 1.225% of the original values.",
      "tldr_zh": "该论文针对无人机（UAVs）在偏远地区实时野火检测的计算和电池资源限制问题，开发了一个图像分类和火势分割模型。研究利用 Jetson Nano P3450 硬件加速器和 TensorRT 库，结合 Quantization Aware Training (QAT)、Automatic Mixed Precision (AMP) 等优化技术，对 FLAME 数据集进行实验。结果显示，分类速度比未优化模型提高了 13%，同时准确率和损失仅相差 1.225%。这项工作为 UAVs 的实时板载野火检测提供了高效、可行的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 7 figures, NETROBOTICS conference submission",
      "pdf_url": "http://arxiv.org/pdf/2401.08105v1",
      "published_date": "2024-01-16 04:16:46 UTC",
      "updated_date": "2024-01-16 04:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:15:18.686811"
    },
    {
      "arxiv_id": "2401.08103v5",
      "title": "Resolving Ethics Trade-offs in Implementing Responsible AI",
      "title_zh": "翻译失败",
      "authors": [
        "Conrad Sanderson",
        "Emma Schleiger",
        "David Douglas",
        "Petra Kuhnert",
        "Qinghua Lu"
      ],
      "abstract": "While the operationalisation of high-level AI ethics principles into\npractical AI/ML systems has made progress, there is still a theory-practice gap\nin managing tensions between the underlying AI ethics aspects. We cover five\napproaches for addressing the tensions via trade-offs, ranging from rudimentary\nto complex. The approaches differ in the types of considered context, scope,\nmethods for measuring contexts, and degree of justification. None of the\napproaches is likely to be appropriate for all organisations, systems, or\napplications. To address this, we propose a framework which consists of: (i)\nproactive identification of tensions, (ii) prioritisation and weighting of\nethics aspects, (iii) justification and documentation of trade-off decisions.\nThe proposed framework aims to facilitate the implementation of well-rounded\nAI/ML systems that are appropriate for potential regulatory requirements.",
      "tldr_zh": "本研究探讨了在将 AI 伦理原则应用于实际 AI/ML 系统时存在的理论与实践差距，特别是如何管理伦理方面的张力与权衡。论文总结了五种处理这些权衡的方法，从简单到复杂，这些方法在考虑的上下文、范围、测量方式和正当性上存在差异。针对不同情境的需求，作者提出一个框架，包括主动识别张力、优先级排序和加权伦理方面、以及证明和记录权衡决策，以促进开发全面、符合潜在监管要求的 AI/ML 系统。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "68T01",
        "K.4.1; I.2.m; C.4"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08103v5",
      "published_date": "2024-01-16 04:14:23 UTC",
      "updated_date": "2024-12-24 12:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:15:30.642926"
    },
    {
      "arxiv_id": "2401.12986v2",
      "title": "Crowdsourced Adaptive Surveys",
      "title_zh": "众包自适应调查",
      "authors": [
        "Yamil Velez"
      ],
      "abstract": "Public opinion surveys are vital for informing democratic decision-making,\nbut responding to rapidly evolving information environments and measuring\nbeliefs within niche communities can be challenging for traditional survey\nmethods. This paper introduces a crowdsourced adaptive survey methodology\n(CSAS) that unites advances in natural language processing and adaptive\nalgorithms to generate question banks that evolve with user input. The CSAS\nmethod converts open-ended text provided by participants into survey items and\napplies a multi-armed bandit algorithm to determine which questions should be\nprioritized in the survey. The method's adaptive nature allows for the\nexploration of new survey questions, while imposing minimal costs in survey\nlength. Applications in the domains of Latino information environments,\nnational issue importance, and local politics showcase CSAS's ability to\nidentify topics that might otherwise escape the notice of survey researchers. I\nconclude by highlighting CSAS's potential to bridge conceptual gaps between\nresearchers and participants in survey research.",
      "tldr_zh": "这篇论文介绍了 CSAS（Crowdsourced Adaptive Surveys）方法，一种结合 natural language processing 和自适应算法的众包调查技术，用于应对传统调查在快速变化信息环境和利基社区信念测量中的挑战。CSAS 通过将参与者提供的开放文本转化为调查问题，并应用 multi-armed bandit algorithm 来动态优先选择问题，从而实现调查的适应性和高效性，同时不增加调查长度。在拉丁裔信息环境、国家问题重要性和本地政治等领域的应用中，该方法成功识别了研究者可能忽略的关键话题。最终，CSAS 有潜力桥接研究者和参与者之间的概念差距，提升公共意见调查的包容性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "stat.AP"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.12986v2",
      "published_date": "2024-01-16 04:05:25 UTC",
      "updated_date": "2024-12-06 19:42:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:15:41.615932"
    },
    {
      "arxiv_id": "2401.08100v1",
      "title": "KTVIC: A Vietnamese Image Captioning Dataset on the Life Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Anh-Cuong Pham",
        "Van-Quang Nguyen",
        "Thi-Hong Vuong",
        "Quang-Thuy Ha"
      ],
      "abstract": "Image captioning is a crucial task with applications in a wide range of\ndomains, including healthcare and education. Despite extensive research on\nEnglish image captioning datasets, the availability of such datasets for\nVietnamese remains limited, with only two existing datasets. In this study, we\nintroduce KTVIC, a comprehensive Vietnamese Image Captioning dataset focused on\nthe life domain, covering a wide range of daily activities. This dataset\ncomprises 4,327 images and 21,635 Vietnamese captions, serving as a valuable\nresource for advancing image captioning in the Vietnamese language. We conduct\nexperiments using various deep neural networks as the baselines on our dataset,\nevaluating them using the standard image captioning metrics, including BLEU,\nMETEOR, CIDEr, and ROUGE. Our findings underscore the effectiveness of the\nproposed dataset and its potential contributions to the field of image\ncaptioning in the Vietnamese context.",
      "tldr_zh": "本文介绍了 KTVIC，这是一个针对越南语的图像描述数据集，专注于日常生活领域，包括 4,327 张图像和 21,635 个越南语描述，以填补现有资源的不足。作者使用各种深度神经网络作为基线模型，并通过 BLEU、METEOR、CIDEr 和 ROUGE 等标准指标进行评估，证明了该数据集的有效性。该研究为推进越南语图像描述技术提供了宝贵资源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08100v1",
      "published_date": "2024-01-16 04:01:49 UTC",
      "updated_date": "2024-01-16 04:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:15:53.306015"
    },
    {
      "arxiv_id": "2401.08099v1",
      "title": "Inpainting Normal Maps for Lightstage data",
      "title_zh": "翻译失败",
      "authors": [
        "Hancheng Zuo",
        "Bernard Tiddeman"
      ],
      "abstract": "This study introduces a novel method for inpainting normal maps using a\ngenerative adversarial network (GAN). Normal maps, often derived from a\nlightstage, are crucial in performance capture but can have obscured areas due\nto movement (e.g., by arms, hair, or props). Inpainting fills these missing\nareas with plausible data. Our approach extends previous general image\ninpainting techniques, employing a bow tie-like generator network and a\ndiscriminator network, with alternating training phases. The generator aims to\nsynthesize images aligning with the ground truth and deceive the discriminator,\nwhich differentiates between real and processed images. Periodically, the\ndiscriminator undergoes retraining to enhance its ability to identify processed\nimages. Importantly, our method adapts to the unique characteristics of normal\nmap data, necessitating modifications to the loss function. We utilize a cosine\nloss instead of mean squared error loss for generator training. Limited\ntraining data availability, even with synthetic datasets, demands significant\naugmentation, considering the specific nature of the input data. This includes\nappropriate image flipping and in-plane rotations to accurately alter normal\nvectors. Throughout training, we monitored key metrics such as average loss,\nStructural Similarity Index Measure (SSIM), and Peak Signal-to-Noise Ratio\n(PSNR) for the generator, along with average loss and accuracy for the\ndiscriminator. Our findings suggest that the proposed model effectively\ngenerates high-quality, realistic inpainted normal maps, suitable for\nperformance capture applications. These results establish a foundation for\nfuture research, potentially involving more advanced networks and comparisons\nwith inpainting of source images used to create the normal maps.",
      "tldr_zh": "这篇论文提出了一种新方法，使用生成对抗网络 (GAN) 来修复 Lightstage 数据中的 normal maps，针对运动（如手臂或头发）导致的遮挡区域进行 plausible 数据填充。方法扩展了传统图像修复技术，采用 bow tie-like generator 网络和 discriminator 网络进行交替训练，并将损失函数改为 cosine loss 以适应 normal map 的特性，同时通过图像翻转和 in-plane rotations 等数据增强处理训练数据不足的问题。实验监控了平均损失、Structural Similarity Index Measure (SSIM) 和 Peak Signal-to-Noise Ratio (PSNR) 等指标，结果显示模型能有效生成高质量的修复 normal maps，适用于性能捕捉应用，并为未来研究奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "I.2.6; I.4.5"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 4 figures, CGVC Conference, The Eurographics Association",
      "pdf_url": "http://arxiv.org/pdf/2401.08099v1",
      "published_date": "2024-01-16 03:59:07 UTC",
      "updated_date": "2024-01-16 03:59:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:16:06.480671"
    },
    {
      "arxiv_id": "2401.08097v4",
      "title": "Fairness Concerns in App Reviews: A Study on AI-based Mobile Apps",
      "title_zh": "应用评论中的公平性担忧：关于基于AI的移动应用的一项研究",
      "authors": [
        "Ali Rezaei Nasab",
        "Maedeh Dashti",
        "Mojtaba Shahin",
        "Mansooreh Zahedi",
        "Hourieh Khalajzadeh",
        "Chetan Arora",
        "Peng Liang"
      ],
      "abstract": "Fairness is one of the socio-technical concerns that must be addressed in\nsoftware systems. Considering the popularity of mobile software applications\n(apps) among a wide range of individuals worldwide, mobile apps with unfair\nbehaviors and outcomes can affect a significant proportion of the global\npopulation, potentially more than any other type of software system. Users\nexpress a wide range of socio-technical concerns in mobile app reviews. This\nresearch aims to investigate fairness concerns raised in mobile app reviews.\nOur research focuses on AI-based mobile app reviews as the chance of unfair\nbehaviors and outcomes in AI-based mobile apps may be higher than in\nnon-AI-based apps. To this end, we first manually constructed a ground-truth\ndataset, including 1,132 fairness and 1,473 non-fairness reviews. Leveraging\nthe ground-truth dataset, we developed and evaluated a set of machine learning\nand deep learning models that distinguish fairness reviews from non-fairness\nreviews. Our experiments show that our best-performing model can detect\nfairness reviews with a precision of 94%. We then applied the best-performing\nmodel on approximately 9.5M reviews collected from 108 AI-based apps and\nidentified around 92K fairness reviews. Next, applying the K-means clustering\ntechnique to the 92K fairness reviews, followed by manual analysis, led to the\nidentification of six distinct types of fairness concerns (e.g., 'receiving\ndifferent quality of features and services in different platforms and devices'\nand 'lack of transparency and fairness in dealing with user-generated\ncontent'). Finally, the manual analysis of 2,248 app owners' responses to the\nfairness reviews identified six root causes (e.g., 'copyright issues') that app\nowners report to justify fairness concerns.",
      "tldr_zh": "这篇论文研究了AI-based移动应用评论中的公平性问题，强调了不公平行为对全球用户的潜在影响。研究者手动构建了一个包含1,132个公平性和1,473个非公平性评论的ground-truth数据集，并开发了machine learning和deep learning模型，其中最佳模型的precision达到94%。他们将该模型应用于约9.5M条AI-based应用评论，识别出约92K条公平性评论，并通过K-means clustering和手动分析，分类出六种公平性问题类型（如不同平台服务质量差异和内容处理透明度不足）。最终，分析了2,248条应用所有者的回应，揭示了六种公平性问题的根因，例如版权issues。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.SE",
      "comment": "Preprint accepted for publication in ACM Transactions on Software\n  Engineering and Methodology (TOSEM), 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.08097v4",
      "published_date": "2024-01-16 03:43:33 UTC",
      "updated_date": "2024-07-31 14:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:16:22.645933"
    },
    {
      "arxiv_id": "2401.08095v4",
      "title": "DurFlex-EVC: Duration-Flexible Emotional Voice Conversion Leveraging Discrete Representations without Text Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Hyung-Seok Oh",
        "Sang-Hoon Lee",
        "Deok-Hyeon Cho",
        "Seong-Whan Lee"
      ],
      "abstract": "Emotional voice conversion (EVC) involves modifying various acoustic\ncharacteristics, such as pitch and spectral envelope, to match a desired\nemotional state while preserving the speaker's identity. Existing EVC methods\noften rely on text transcriptions or time-alignment information and struggle to\nhandle varying speech durations effectively. In this paper, we propose\nDurFlex-EVC, a duration-flexible EVC framework that operates without the need\nfor text or alignment information. We introduce a unit aligner that models\ncontextual information by aligning speech with discrete units representing\ncontent, eliminating the need for text or speech-text alignment. Additionally,\nwe design a style autoencoder that effectively disentangles content and\nemotional style, allowing precise manipulation of the emotional characteristics\nof the speech. We further enhance emotional expressiveness through a\nhierarchical stylize encoder that applies the target emotional style at\nmultiple hierarchical levels, refining the stylization process to improve the\nnaturalness and expressiveness of the converted speech. Experimental results\nfrom subjective and objective evaluations demonstrate that our approach\noutperforms baseline models, effectively handling duration variability and\nenhancing emotional expressiveness in the converted speech.",
      "tldr_zh": "本研究提出DurFlex-EVC，一种无需文本对齐的Duration-Flexible情感语音转换(EVC)框架，旨在解决现有方法依赖文本或时间对齐信息且处理语音时长变化困难的问题。该框架引入unit aligner来通过离散单位对齐语音与内容信息建模，以及style autoencoder来分离内容和情感风格，实现对情感特性的精确操控；此外，hierarchical stylize encoder在多层次应用目标情感风格，提升转换语音的自然性和表现力。实验结果显示，DurFlex-EVC在主观和客观评估中优于基线模型，能够有效处理时长变异并增强情感表达。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "15 pages, 11 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.08095v4",
      "published_date": "2024-01-16 03:39:35 UTC",
      "updated_date": "2025-01-21 02:51:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:16:32.509819"
    },
    {
      "arxiv_id": "2401.08092v2",
      "title": "A Survey of Resource-efficient LLM and Multimodal Foundation Models",
      "title_zh": "资源高效 LLM 和多模态基础模型的综述",
      "authors": [
        "Mengwei Xu",
        "Wangsong Yin",
        "Dongqi Cai",
        "Rongjie Yi",
        "Daliang Xu",
        "Qipeng Wang",
        "Bingyang Wu",
        "Yihao Zhao",
        "Chen Yang",
        "Shihe Wang",
        "Qiyang Zhang",
        "Zhenyan Lu",
        "Li Zhang",
        "Shangguang Wang",
        "Yuanchun Li",
        "Yunxin Liu",
        "Xin Jin",
        "Xuanzhe Liu"
      ],
      "abstract": "Large foundation models, including large language models (LLMs), vision\ntransformers (ViTs), diffusion, and LLM-based multimodal models, are\nrevolutionizing the entire machine learning lifecycle, from training to\ndeployment. However, the substantial advancements in versatility and\nperformance these models offer come at a significant cost in terms of hardware\nresources. To support the growth of these large models in a scalable and\nenvironmentally sustainable way, there has been a considerable focus on\ndeveloping resource-efficient strategies. This survey delves into the critical\nimportance of such research, examining both algorithmic and systemic aspects.\nIt offers a comprehensive analysis and valuable insights gleaned from existing\nliterature, encompassing a broad array of topics from cutting-edge model\narchitectures and training/serving algorithms to practical system designs and\nimplementations. The goal of this survey is to provide an overarching\nunderstanding of how current approaches are tackling the resource challenges\nposed by large foundation models and to potentially inspire future\nbreakthroughs in this field.",
      "tldr_zh": "这篇调查探讨了资源高效的大型语言模型（LLM）和多模态基础模型（如vision transformers (ViTs)和扩散模型）的关键挑战与策略，强调这些模型在提升通用性和性能的同时带来的硬件资源消耗问题。调查全面分析了现有文献中的算法和系统方面，包括创新模型架构、训练/服务算法以及实际系统设计与实现。最终目标是提供整体性理解，支持模型的可扩展性和环境可持续性，并启发未来领域的突破。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08092v2",
      "published_date": "2024-01-16 03:35:26 UTC",
      "updated_date": "2024-09-23 07:37:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:16:44.064953"
    },
    {
      "arxiv_id": "2401.08089v1",
      "title": "A Study on Training and Developing Large Language Models for Behavior Tree Generation",
      "title_zh": "关于训练和发展大型语言模型用于行为树生成的研究",
      "authors": [
        "Fu Li",
        "Xueying Wang",
        "Bin Li",
        "Yunlong Wu",
        "Yanzhen Wang",
        "Xiaodong Yi"
      ],
      "abstract": "This paper presents an innovative exploration of the application potential of\nlarge language models (LLM) in addressing the challenging task of automatically\ngenerating behavior trees (BTs) for complex tasks. The conventional manual BT\ngeneration method is inefficient and heavily reliant on domain expertise. On\nthe other hand, existing automatic BT generation technologies encounter\nbottlenecks related to task complexity, model adaptability, and reliability. In\norder to overcome these challenges, we propose a novel methodology that\nleverages the robust representation and reasoning abilities of LLMs. The core\ncontribution of this paper lies in the design of a BT generation framework\nbased on LLM, which encompasses the entire process, from data synthesis and\nmodel training to application developing and data verification. Synthetic data\nis introduced to train the BT generation model (BTGen model), enhancing its\nunderstanding and adaptability to various complex tasks, thereby significantly\nimproving its overall performance. In order to ensure the effectiveness and\nexecutability of the generated BTs, we emphasize the importance of data\nverification and introduce a multilevel verification strategy. Additionally, we\nexplore a range of agent design and development schemes with LLM as the central\nelement. We hope that the work in this paper may provide a reference for the\nresearchers who are interested in BT generation based on LLMs.",
      "tldr_zh": "这篇论文探讨了利用大型语言模型 (LLM) 来自动生成行为树 (BTs) 的潜力，以解决传统手动方法效率低下和依赖专家的问题，以及现有自动技术在任务复杂性、适应性和可靠性方面的瓶颈。论文提出了一种基于 LLM 的 BT 生成框架，包括数据合成、模型训练 (BTGen 模型)、应用开发和多级验证策略，通过合成数据增强模型对复杂任务的理解和适应性。实验结果显示，该框架显著提高了 BTs 的生成性能和可执行性，并探索了以 LLM 为核心的代理设计方案，为未来相关研究提供参考。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08089v1",
      "published_date": "2024-01-16 03:28:29 UTC",
      "updated_date": "2024-01-16 03:28:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:16:56.662012"
    },
    {
      "arxiv_id": "2401.08077v1",
      "title": "Transformer-based approach for Ethereum Price Prediction Using Crosscurrency correlation and Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Singh",
        "Mayur Bhat"
      ],
      "abstract": "The research delves into the capabilities of a transformer-based neural\nnetwork for Ethereum cryptocurrency price forecasting. The experiment runs\naround the hypothesis that cryptocurrency prices are strongly correlated with\nother cryptocurrencies and the sentiments around the cryptocurrency. The model\nemploys a transformer architecture for several setups from single-feature\nscenarios to complex configurations incorporating volume, sentiment, and\ncorrelated cryptocurrency prices. Despite a smaller dataset and less complex\narchitecture, the transformer model surpasses ANN and MLP counterparts on some\nparameters. The conclusion presents a hypothesis on the illusion of causality\nin cryptocurrency price movements driven by sentiments.",
      "tldr_zh": "本研究提出了一种基于 Transformer 的方法，用于预测以太坊价格，假设价格受跨货币相关性（Crosscurrency correlation）和情感分析（Sentiment Analysis）的影响。模型采用了从单一特征到复杂配置的多种设置，包括整合交易量、情感和相关加密货币价格。实验结果显示，尽管数据集较小，该 Transformer 模型在某些参数上超过了 ANN 和 MLP 模型。最终，研究假设情感驱动的价格波动可能存在因果错觉（illusion of causality）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.PR"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.08077v1",
      "published_date": "2024-01-16 03:03:39 UTC",
      "updated_date": "2024-01-16 03:03:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:17:09.399769"
    },
    {
      "arxiv_id": "2401.08066v1",
      "title": "Achieve Fairness without Demographics for Dermatological Disease Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Ching-Hao Chiu",
        "Yu-Jen Chen",
        "Yawen Wu",
        "Yiyu Shi",
        "Tsung-Yi Ho"
      ],
      "abstract": "In medical image diagnosis, fairness has become increasingly crucial. Without\nbias mitigation, deploying unfair AI would harm the interests of the\nunderprivileged population and potentially tear society apart. Recent research\naddresses prediction biases in deep learning models concerning demographic\ngroups (e.g., gender, age, and race) by utilizing demographic (sensitive\nattribute) information during training. However, many sensitive attributes\nnaturally exist in dermatological disease images. If the trained model only\ntargets fairness for a specific attribute, it remains unfair for other\nattributes. Moreover, training a model that can accommodate multiple sensitive\nattributes is impractical due to privacy concerns. To overcome this, we propose\na method enabling fair predictions for sensitive attributes during the testing\nphase without using such information during training. Inspired by prior work\nhighlighting the impact of feature entanglement on fairness, we enhance the\nmodel features by capturing the features related to the sensitive and target\nattributes and regularizing the feature entanglement between corresponding\nclasses. This ensures that the model can only classify based on the features\nrelated to the target attribute without relying on features associated with\nsensitive attributes, thereby improving fairness and accuracy. Additionally, we\nuse disease masks from the Segment Anything Model (SAM) to enhance the quality\nof the learned feature. Experimental results demonstrate that the proposed\nmethod can improve fairness in classification compared to state-of-the-art\nmethods in two dermatological disease datasets.",
      "tldr_zh": "该论文针对皮肤病诊断中的公平性问题，提出了一种无需使用人口统计信息（如性别、年龄、种族）的方法，以避免训练过程中的隐私风险和潜在偏见。研究方法通过捕获与敏感属性和目标属性相关的特征，并正则化feature entanglement，确保模型仅依赖目标特征进行分类，同时利用Segment Anything Model (SAM)的疾病掩码来提升特征质量，从而提高预测的公平性和准确性。实验结果显示，在两个皮肤病数据集上，该方法比现有最先进方法显著改善了分类公平性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08066v1",
      "published_date": "2024-01-16 02:49:52 UTC",
      "updated_date": "2024-01-16 02:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:17:21.196994"
    },
    {
      "arxiv_id": "2401.10286v3",
      "title": "Code-Based English Models Surprising Performance on Chinese QA Pair Extraction Task",
      "title_zh": "翻译失败",
      "authors": [
        "Linghan Zheng",
        "Hui Liu",
        "Xiaojun Lin",
        "Jiayuan Dong",
        "Yue Sheng",
        "Gang Shi",
        "Zhiwei Liu",
        "Hongwei Chen"
      ],
      "abstract": "In previous studies, code-based models have consistently outperformed\ntext-based models in reasoning-intensive scenarios. When generating our\nknowledge base for Retrieval-Augmented Generation (RAG), we observed that\ncode-based models also perform exceptionally well in Chinese QA Pair Extraction\ntask. Further, our experiments and the metrics we designed discovered that\ncode-based models containing a certain amount of Chinese data achieve even\nbetter performance. Additionally, the capabilities of code-based English models\nin specified Chinese tasks offer a distinct perspective for discussion on the\nphilosophical \"Chinese Room\" thought experiment.",
      "tldr_zh": "该研究发现，基于代码的英语模型（code-based English models）在中文QA对提取（Chinese QA Pair Extraction）任务上表现出乎预期的优异性能，优于传统的文本-based模型，尤其在推理密集型场景中。研究者通过实验和设计的指标评估了这些模型，并观察到包含一定量中文数据的代码-based模型能进一步提升表现，这为构建RAG（Retrieval-Augmented Generation）知识库提供了新见解。此外，这一发现为哲学上的“Chinese Room”思想实验提供了独特视角，探讨了模型理解和语言处理的能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10286v3",
      "published_date": "2024-01-16 02:11:35 UTC",
      "updated_date": "2024-03-11 01:23:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:17:30.939022"
    },
    {
      "arxiv_id": "2401.08046v1",
      "title": "Enhancing Robustness of LLM-Synthetic Text Detectors for Academic Writing: A Comprehensive Analysis",
      "title_zh": "增强 LLM 合成文本检测器的鲁棒性：针对学术写作的全面分析",
      "authors": [
        "Zhicheng Dou",
        "Yuchen Guo",
        "Ching-Chun Chang",
        "Huy H. Nguyen",
        "Isao Echizen"
      ],
      "abstract": "The emergence of large language models (LLMs), such as Generative Pre-trained\nTransformer 4 (GPT-4) used by ChatGPT, has profoundly impacted the academic and\nbroader community. While these models offer numerous advantages in terms of\nrevolutionizing work and study methods, they have also garnered significant\nattention due to their potential negative consequences. One example is\ngenerating academic reports or papers with little to no human contribution.\nConsequently, researchers have focused on developing detectors to address the\nmisuse of LLMs. However, most existing methods prioritize achieving higher\naccuracy on restricted datasets, neglecting the crucial aspect of\ngeneralizability. This limitation hinders their practical application in\nreal-life scenarios where reliability is paramount. In this paper, we present a\ncomprehensive analysis of the impact of prompts on the text generated by LLMs\nand highlight the potential lack of robustness in one of the current\nstate-of-the-art GPT detectors. To mitigate these issues concerning the misuse\nof LLMs in academic writing, we propose a reference-based Siamese detector\nnamed Synthetic-Siamese which takes a pair of texts, one as the inquiry and the\nother as the reference. Our method effectively addresses the lack of robustness\nof previous detectors (OpenAI detector and DetectGPT) and significantly\nimproves the baseline performances in realistic academic writing scenarios by\napproximately 67% to 95%.",
      "tldr_zh": "该研究分析了大型语言模型 (LLMs) 如 GPT-4 在学术写作中的滥用问题，指出现有检测器（如 OpenAI detector 和 DetectGPT）虽追求高准确率，但缺乏泛化性和鲁棒性，特别是在现实场景中。论文首先考察了提示对 LLM 生成文本的影响，然后提出了一种基于参考的 Siamese 检测器 Synthetic-Siamese，该方法使用一对文本（查询和参考）来提升检测可靠性。实验结果显示，Synthetic-Siamese 在实际学术写作场景中将基线性能提高了约 67% 到 95%，为更有效的 LLM 滥用检测提供了解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.08046v1",
      "published_date": "2024-01-16 01:58:36 UTC",
      "updated_date": "2024-01-16 01:58:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:17:44.448697"
    },
    {
      "arxiv_id": "2401.08025v2",
      "title": "Self-Imagine: Effective Unimodal Reasoning with Multimodal Models using Self-Imagination",
      "title_zh": "Self-Imagine：使用自我想象的多模态模型进行有效单模态推理",
      "authors": [
        "Syeda Nahida Akter",
        "Aman Madaan",
        "Sangwu Lee",
        "Yiming Yang",
        "Eric Nyberg"
      ],
      "abstract": "The potential of Vision-Language Models (VLMs) often remains underutilized in\nhandling complex text-based problems, particularly when these problems could\nbenefit from visual representation. Resonating with humans' ability to solve\ncomplex text-based problems by (1) creating a visual diagram from the problem\nand (2) deducing what steps they need to take to solve it, we propose\nSelf-Imagine. We leverage a single Vision-Language Model (VLM) to generate a\nstructured representation of the question using HTML, then render the HTML as\nan image, and finally use the same VLM to answer the question using both the\nquestion and the image. Our approach does not require any additional training\ndata or training. We evaluate our approach on three mathematics tasks and nine\ngeneral-purpose reasoning tasks using state-of-the-art (LLAVA-1.5 and GEMINI\nPRO) VLMs. Our approach boosts the performance of LLAVA-1.5 and GEMINI PRO on\nall math tasks (on average GSM8K: +3.1%; ASDIV: +3.2%; SVAMP: +6.9%) and the\nmajority of the general-purpose reasoning tasks by 3.2% to 6.0% on average.",
      "tldr_zh": "这篇论文提出Self-Imagine方法，利用Vision-Language Models (VLMs) 通过自我生成视觉表示来提升处理复杂文本问题的能力。具体而言，该方法使用单个VLM生成问题的HTML结构化表示，将其渲染为图像，然后结合图像和问题进行推理，无需额外训练数据或模型微调。在三个数学任务（如GSM8K、ASDIV和SVAMP）和九个通用推理任务上，实验结果显示LLAVA-1.5和GEMINI PRO的性能平均提升3.1%至6.9%，证明了该方法的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 9 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.08025v2",
      "published_date": "2024-01-16 00:46:29 UTC",
      "updated_date": "2024-02-21 22:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:17:57.182988"
    },
    {
      "arxiv_id": "2401.08715v1",
      "title": "Selecting Subsets of Source Data for Transfer Learning with Applications in Metal Additive Manufacturing",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Tang",
        "M. Rahmani Dehaghani",
        "Pouyan Sajadi",
        "G. Gary Wang"
      ],
      "abstract": "Considering data insufficiency in metal additive manufacturing (AM), transfer\nlearning (TL) has been adopted to extract knowledge from source domains (e.g.,\ncompleted printings) to improve the modeling performance in target domains\n(e.g., new printings). Current applications use all accessible source data\ndirectly in TL with no regard to the similarity between source and target data.\nThis paper proposes a systematic method to find appropriate subsets of source\ndata based on similarities between the source and target datasets for a given\nset of limited target domain data. Such similarity is characterized by the\nspatial and model distance metrics. A Pareto frontier-based source data\nselection method is developed, where the source data located on the Pareto\nfrontier defined by two similarity distance metrics are selected iteratively.\nThe method is integrated into an instance-based TL method (decision tree\nregression model) and a model-based TL method (fine-tuned artificial neural\nnetwork). Both models are then tested on several regression tasks in metal AM.\nComparison results demonstrate that 1) the source data selection method is\ngeneral and supports integration with various TL methods and distance metrics,\n2) compared with using all source data, the proposed method can find a small\nsubset of source data from the same domain with better TL performance in metal\nAM regression tasks involving different processes and machines, and 3) when\nmultiple source domains exist, the source data selection method could find the\nsubset from one source domain to obtain comparable or better TL performance\nthan the model constructed using data from all source domains.",
      "tldr_zh": "这篇论文针对金属增材制造(AM)中的数据不足问题，提出了一种系统方法，通过空间和模型距离指标评估源数据与目标数据的相似性，并使用Pareto前沿方法迭代选择合适的源数据子集，以优化转移学习(TL)性能。该方法整合到基于实例的TL（如决策树回归模型）和基于模型的TL（如微调人工神经网络）中，并在金属AM的回归任务上进行测试。结果表明，该方法通用且灵活，能从源数据中筛选出更小的子集，实现比使用全部源数据更好的TL性能，尤其在涉及多个源域时。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.08715v1",
      "published_date": "2024-01-16 00:14:37 UTC",
      "updated_date": "2024-01-16 00:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T22:18:09.273029"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 70,
  "processed_papers_count": 70,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T22:18:33.278022"
}