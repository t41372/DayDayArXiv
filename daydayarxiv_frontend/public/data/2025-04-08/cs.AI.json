{
  "date": "2025-04-08",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-08 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 模型优化、生成模型应用、联邦学习和多模态学习等领域，其中 FedMetaNAS 和 TxGemma 等论文因其高效联邦架构和医疗应用创新而令人印象深刻，同时 AI Index Report 作为综合性报告，由知名学者如 Yoav Shoham 和 James Manyika 参与，提供了 AI 发展全局洞见。\n\n下面，我将挑选并简要讨论今天的关键论文，先从最具影响力和话题度的文章入手，再快速掠过其他相关或次要内容。重点放在 AI 安全、LLM 优化、生成模型和实际应用等领域，相关论文按主题归类。\n\n### AI 模型安全与优化\n- **Exploiting Meta-Learning-based Poisoning Attacks for Graph Link Prediction（利用元学习-based 投毒攻击的图链接预测）**：这篇论文提出了一种基于元学习的无权图投毒攻击方法，针对 Variational Graph Auto-Encoder（VGAE）模型，实验显示其显著降低了链接预测性能，并优于现有方法。该研究强调了图神经网络的鲁棒性问题，对 AI 安全有重要启示。\n- **Federated Neural Architecture Search with Model-Agnostic Meta Learning（基于模型无关元学习的联邦神经架构搜索）**：作者 Xinyuan Huang 和 Jiechao Gao 开发了 FedMetaNAS 框架，通过元学习加速联邦学习中的架构搜索，减少重训并提升 50% 以上效率。该方法在异质数据下表现出色，是联邦学习领域的关键进展。\n- **kNN-SVC: Robust Zero-Shot Singing Voice Conversion with Additive Synthesis and Concatenation Smoothness Optimization（kNN-SVC: 使用加法合成和连接平滑优化的鲁棒零样本歌声转换）**：论文引入加法合成和优化策略，提升了歌声转换的鲁棒性，显著减少了伪影和失真。该工作为语音生成模型提供新工具，适用于实际音频应用。\n\n### 生成模型与多模态学习\n- **DDT: Decoupled Diffusion Transformer（解耦扩散 Transformer）**：该论文提出 DDT 框架，通过解耦编码器和解码器优化扩散模型，实现了更快的训练收敛（比现有方法快 4 倍），在 ImageNet 基准上达到最先进性能。该方法在图像生成领域有重大影响。\n- **TxGemma: Efficient and Agentic LLMs for Therapeutics（TxGemma: 用于治疗的高效代理 LLM）**：作者如 Shekoofeh Azizi 开发的 TxGemma 模型，针对药物开发优化 LLM，实现了多任务预测并提升 50% 性能。该研究展示了 LLM 在医疗中的实际价值。\n- **FEABench: Evaluating Language Models on Multiphysics Reasoning Ability（FEABench: 评估语言模型的多物理推理能力）**：论文构建了 FEABench 基准，测试 LLM 在物理模拟中的推理能力，使用 RAG 和 API 交互提升准确性。该工作为 AI 在科学领域的应用提供了新评估框架。\n\n### 其他亮点与快速掠过\n- **AI Index Report 2025（AI 指数报告 2025）**：由 Yoav Shoham 等知名学者编写的综合报告，涵盖 AI 硬件、推理成本和全球趋势，提供了权威数据和洞见，是 AI 领域年度关键读物。\n- 其他论文，如 **Agent-Arena: A General Framework for Evaluating Control Algorithms（Agent-Arena: 评估控制算法的通用框架）** 和 **GOLLuM: Gaussian Process Optimized LLMs（GOLLuM: 使用高斯过程优化的 LLM）**，分别在机器人控制和优化领域有小幅创新，但影响有限，仅快速提及其框架设计提升了算法评估效率。\n- 还有一些如量子计算（Evaluating Mutation Techniques in Genetic Algorithm-Based Quantum Circuit Synthesis）和医疗应用（WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and Real-World Wound Care）等论文，贡献在于具体技术优化，但非主流话题，故简要掠过：前者改进了量子电路合成，后者提升了伤口图像分割的实际应用。\n\n今天的论文总体反映了 AI 向高效、安全和实际应用方向的演进，但许多仍需关注泛化性和数据隐私问题。感兴趣的读者可优先查看 FedMetaNAS 和 AI Index Report 等核心作品！",
  "papers": [
    {
      "arxiv_id": "2504.06492v1",
      "title": "Exploiting Meta-Learning-based Poisoning Attacks for Graph Link Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Mingchen Li",
        "Di Zhuang",
        "Keyu Chen",
        "Dumindu Samaraweera",
        "Morris Chang"
      ],
      "abstract": "Link prediction in graph data utilizes various algorithms and machine\nlearning/deep learning models to predict potential relationships between graph\nnodes. This technique has found widespread use in numerous real-world\napplications, including recommendation systems, community networks, and\nbiological structures. However, recent research has highlighted the\nvulnerability of link prediction models to adversarial attacks, such as\npoisoning and evasion attacks. Addressing the vulnerability of these models is\ncrucial to ensure stable and robust performance in link prediction\napplications. While many works have focused on enhancing the robustness of the\nGraph Convolution Network (GCN) model, the Variational Graph Auto-Encoder\n(VGAE), a sophisticated model for link prediction, has not been thoroughly\ninvestigated in the context of graph adversarial attacks. To bridge this gap,\nthis article proposes an unweighted graph poisoning attack approach using\nmeta-learning techniques to undermine VGAE's link prediction performance. We\nconducted comprehensive experiments on diverse datasets to evaluate the\nproposed method and its parameters, comparing it with existing approaches in\nsimilar settings. Our results demonstrate that our approach significantly\ndiminishes link prediction performance and outperforms other state-of-the-art\nmethods.",
      "tldr_zh": "这篇论文探讨了图链接预测模型（如 Variational Graph Auto-Encoder, VGAE）的脆弱性，提出了一种基于 meta-learning 的无权图中毒攻击方法，以破坏其预测性能。方法利用元学习技术针对性地注入攻击，旨在模拟真实世界对抗场景。实验在多种数据集上进行，与现有方法比较，结果显示该攻击显著降低了链接预测准确性，并优于其他最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06492v1",
      "published_date": "2025-04-08 23:36:29 UTC",
      "updated_date": "2025-04-08 23:36:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:44:10.409359"
    },
    {
      "arxiv_id": "2504.07998v1",
      "title": "CDM-QTA: Quantized Training Acceleration for Efficient LoRA Fine-Tuning of Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jinming Lu",
        "Minghao She",
        "Wendong Mao",
        "Zhongfeng Wang"
      ],
      "abstract": "Fine-tuning large diffusion models for custom applications demands\nsubstantial power and time, which poses significant challenges for efficient\nimplementation on mobile devices. In this paper, we develop a novel training\naccelerator specifically for Low-Rank Adaptation (LoRA) of diffusion models,\naiming to streamline the process and reduce computational complexity. By\nleveraging a fully quantized training scheme for LoRA fine-tuning, we achieve\nsubstantial reductions in memory usage and power consumption while maintaining\nhigh model fidelity. The proposed accelerator features flexible dataflow,\nenabling high utilization for irregular and variable tensor shapes during the\nLoRA process. Experimental results show up to 1.81x training speedup and 5.50x\nenergy efficiency improvements compared to the baseline, with minimal impact on\nimage generation quality.",
      "tldr_zh": "本文提出CDM-QTA，一种针对扩散模型的Low-Rank Adaptation (LoRA)微调的量化训练加速器，旨在降低计算复杂性和功耗，使其适用于移动设备。该加速器通过完全量化训练方案和灵活数据流，显著减少内存使用和功率消耗，同时保持模型保真度。实验结果显示，与基线相比，训练速度提高1.81倍，能源效率提升5.50倍，对图像生成质量的影响最小。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.AR",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "ISCAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.07998v1",
      "published_date": "2025-04-08 22:40:29 UTC",
      "updated_date": "2025-04-08 22:40:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:44:22.632185"
    },
    {
      "arxiv_id": "2504.06469v2",
      "title": "AI-Assisted Transport of Radioactive Ion Beams",
      "title_zh": "翻译失败",
      "authors": [
        "Sergio Lopez-Caceres",
        "Daniel Santiago-Gonzalez"
      ],
      "abstract": "Beams of radioactive heavy ions allow researchers to study rare and unstable\natomic nuclei, shedding light into the internal structure of exotic nuclei and\non how chemical elements are formed in stars. However, the extraction and\ntransport of radioactive beams rely on time-consuming expert-driven tuning\nmethods, where hundreds of parameters are manually optimized. Here, we\nintroduce a system that employs Artificial Intelligence (AI), specifically\nutilizing Bayesian Optimization, to assist in the transport process of\nradioactive beams. We apply our methodology to real-life scenarios showing\nadvantages when compared with standard tuning methods. This AI-assisted\napproach can be extended to other radioactive beam facilities around the world\nto improve operational efficiency and enhance scientific output.",
      "tldr_zh": "该研究针对放射性离子束的提取和传输问题，提出了一种利用人工智能（AI）辅助系统，具体采用 Bayesian Optimization 算法来自动优化数百个参数，从而取代耗时的专家手动调优方法。在真实场景应用中，该系统显示出显著优势，比标准方法提高了操作效率。该方法可扩展到全球其他放射性束设施，提升科学输出和实验效率。",
      "categories": [
        "physics.acc-ph",
        "cs.AI",
        "nucl-ex"
      ],
      "primary_category": "physics.acc-ph",
      "comment": "6 pages, 6 figures; Section headings added for clarity.\n  Implementation and Results sections expanded. Minor revisions to Abstract and\n  to Summary and Conclusion",
      "pdf_url": "http://arxiv.org/pdf/2504.06469v2",
      "published_date": "2025-04-08 22:21:54 UTC",
      "updated_date": "2025-04-17 00:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:44:34.290325"
    },
    {
      "arxiv_id": "2504.06468v1",
      "title": "Agent-Arena: A General Framework for Evaluating Control Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Halid Abdulrahim Kadi",
        "Kasim Terzić"
      ],
      "abstract": "Robotic research is inherently challenging, requiring expertise in diverse\nenvironments and control algorithms. Adapting algorithms to new environments\noften poses significant difficulties, compounded by the need for extensive\nhyper-parameter tuning in data-driven methods. To address these challenges, we\npresent Agent-Arena, a Python framework designed to streamline the integration,\nreplication, development, and testing of decision-making policies across a wide\nrange of benchmark environments. Unlike existing frameworks, Agent-Arena is\nuniquely generalised to support all types of control algorithms and is\nadaptable to both simulation and real-robot scenarios. Please see our GitHub\nrepository https://github.com/halid1020/agent-arena-v0.",
      "tldr_zh": "机器人研究面临环境适应困难和数据驱动方法超参数调整的挑战，为此，研究者提出Agent-Arena，这是一个通用的Python框架，用于简化决策策略在各种基准环境中的整合、复制、开发和测试。该框架支持所有类型control algorithms，并适用于模拟和真实机器人场景，与现有框架不同的是其高度通用性。通过Agent-Arena，用户可以更高效地评估和优化控制算法，相关代码可在GitHub仓库https://github.com/halid1020/agent-arena-v0获取。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.RO",
      "comment": "20 pages and 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.06468v1",
      "published_date": "2025-04-08 22:20:50 UTC",
      "updated_date": "2025-04-08 22:20:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:44:46.769178"
    },
    {
      "arxiv_id": "2504.06457v1",
      "title": "Federated Neural Architecture Search with Model-Agnostic Meta Learning",
      "title_zh": "联邦神经架构搜索与模型无关元学习",
      "authors": [
        "Xinyuan Huang",
        "Jiechao Gao"
      ],
      "abstract": "Federated Learning (FL) often struggles with data heterogeneity due to the\nnaturally uneven distribution of user data across devices. Federated Neural\nArchitecture Search (NAS) enables collaborative search for optimal model\narchitectures tailored to heterogeneous data to achieve higher accuracy.\nHowever, this process is time-consuming due to extensive search space and\nretraining. To overcome this, we introduce FedMetaNAS, a framework that\nintegrates meta-learning with NAS within the FL context to expedite the\narchitecture search by pruning the search space and eliminating the retraining\nstage. Our approach first utilizes the Gumbel-Softmax reparameterization to\nfacilitate relaxation of the mixed operations in the search space. We then\nrefine the local search process by incorporating Model-Agnostic Meta-Learning,\nwhere a task-specific learner adapts both weights and architecture parameters\n(alphas) for individual tasks, while a meta learner adjusts the overall model\nweights and alphas based on the gradient information from task learners.\nFollowing the meta-update, we propose soft pruning using the same trick on\nsearch space to gradually sparsify the architecture, ensuring that the\nperformance of the chosen architecture remains robust after pruning which\nallows for immediate use of the model without retraining. Experimental\nevaluations demonstrate that FedMetaNAS significantly accelerates the search\nprocess by more than 50\\% with higher accuracy compared to FedNAS.",
      "tldr_zh": "该研究提出 FedMetaNAS 框架，将 Model-Agnostic Meta-Learning (MAML) 整合到 Federated Neural Architecture Search (NAS) 中，以解决 Federated Learning (FL) 中数据异质性导致的模型优化问题。该框架使用 Gumbel-Softmax 放松搜索空间，并让任务特定学习器适应权重和架构参数 (alphas)，而元学习器基于任务学习器的梯度信息进行整体调整，同时通过软修剪逐步稀疏化架构，避免重新训练。实验结果表明，FedMetaNAS 比 FedNAS 搜索速度提高超过 50%，并在准确率上取得显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06457v1",
      "published_date": "2025-04-08 21:57:40 UTC",
      "updated_date": "2025-04-08 21:57:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:44:59.246939"
    },
    {
      "arxiv_id": "2504.06446v1",
      "title": "Can you Finetune your Binoculars? Embedding Text Watermarks into the Weights of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fay Elhassan",
        "Niccolò Ajroldi",
        "Antonio Orvieto",
        "Jonas Geiping"
      ],
      "abstract": "The indistinguishability of AI-generated content from human text raises\nchallenges in transparency and accountability. While several methods exist to\nwatermark models behind APIs, embedding watermark strategies directly into\nmodel weights that are later reflected in the outputs of the model is\nchallenging. In this study we propose a strategy to finetune a pair of low-rank\nadapters of a model, one serving as the text-generating model, and the other as\nthe detector, so that a subtle watermark is embedded into the text generated by\nthe first model and simultaneously optimized for detectability by the second.\nIn this way, the watermarking strategy is fully learned end-to-end. This\nprocess imposes an optimization challenge, as balancing watermark robustness,\nnaturalness, and task performance requires trade-offs. We discuss strategies on\nhow to optimize this min-max objective and present results showing the effect\nof this modification to instruction finetuning.",
      "tldr_zh": "本研究解决了AI生成内容与人类文本难以区分的问题，提出了一种在大型语言模型（Large Language Models）权重中嵌入文本水印的策略，通过微调一对low-rank adapters——一个用于生成带水印的文本，另一个用于检测水印——实现端到端学习。优化过程需平衡水印的鲁棒性、自然性和任务性能，并采用min-max目标来处理权衡挑战。实验结果展示了这种修改对指令微调的影响，提高了AI内容的透明度和可追溯性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06446v1",
      "published_date": "2025-04-08 21:34:02 UTC",
      "updated_date": "2025-04-08 21:34:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:45:11.352542"
    },
    {
      "arxiv_id": "2504.06438v1",
      "title": "Don't Let It Hallucinate: Premise Verification via Retrieval-Augmented Logical Reasoning",
      "title_zh": "别让它产生幻觉：通过检索增强逻辑推理进行前提验证",
      "authors": [
        "Yuehan Qin",
        "Shawn Li",
        "Yi Nian",
        "Xinyan Velocity Yu",
        "Yue Zhao",
        "Xuezhe Ma"
      ],
      "abstract": "Large language models (LLMs) have shown substantial capacity for generating\nfluent, contextually appropriate responses. However, they can produce\nhallucinated outputs, especially when a user query includes one or more false\npremises-claims that contradict established facts. Such premises can mislead\nLLMs into offering fabricated or misleading details. Existing approaches\ninclude pretraining, fine-tuning, and inference-time techniques that often rely\non access to logits or address hallucinations after they occur. These methods\ntend to be computationally expensive, require extensive training data, or lack\nproactive mechanisms to prevent hallucination before generation, limiting their\nefficiency in real-time applications. We propose a retrieval-based framework\nthat identifies and addresses false premises before generation. Our method\nfirst transforms a user's query into a logical representation, then applies\nretrieval-augmented generation (RAG) to assess the validity of each premise\nusing factual sources. Finally, we incorporate the verification results into\nthe LLM's prompt to maintain factual consistency in the final output.\nExperiments show that this approach effectively reduces hallucinations,\nimproves factual accuracy, and does not require access to model logits or\nlarge-scale fine-tuning.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）在处理包含虚假前提的用户查询时容易产生幻觉的问题，提出了一种基于检索增强生成（RAG）的框架，以在生成前验证前提。该方法首先将查询转化为逻辑表示，然后使用RAG从事实来源评估每个前提的有效性，并将验证结果整合到LLMs的提示中，确保输出的事实一致性。与现有方法相比，该框架无需访问模型logits或进行大规模微调。实验结果显示，该方法显著减少了幻觉，提高了事实准确性，适用于实时应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06438v1",
      "published_date": "2025-04-08 21:14:48 UTC",
      "updated_date": "2025-04-08 21:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:45:22.499243"
    },
    {
      "arxiv_id": "2504.06436v1",
      "title": "Language-Dependent Political Bias in AI: A Study of ChatGPT and Gemini",
      "title_zh": "翻译失败",
      "authors": [
        "Dogus Yuksel",
        "Mehmet Cem Catalbas",
        "Bora Oc"
      ],
      "abstract": "As leading examples of large language models, ChatGPT and Gemini claim to\nprovide accurate and unbiased information, emphasizing their commitment to\npolitical neutrality and avoidance of personal bias. This research investigates\nthe political tendency of large language models and the existence of\ndifferentiation according to the query language. For this purpose, ChatGPT and\nGemini were subjected to a political axis test using 14 different languages.\nThe findings of the study suggest that these large language models do exhibit\npolitical tendencies, with both models demonstrating liberal and leftist\nbiases. A comparative analysis revealed that Gemini exhibited a more pronounced\nliberal and left-wing tendency compared to ChatGPT. The study also found that\nthese political biases varied depending on the language used for inquiry. The\nstudy delves into the factors that constitute political tendencies and\nlinguistic differentiation, exploring differences in the sources and scope of\neducational data, structural and grammatical features of languages, cultural\nand political contexts, and the model's response to linguistic features. From\nthis standpoint, and an ethical perspective, it is proposed that artificial\nintelligence tools should refrain from asserting a lack of political tendencies\nand neutrality, instead striving for political neutrality and executing user\nqueries by incorporating these tendencies.",
      "tldr_zh": "本研究调查了大型语言模型 ChatGPT 和 Gemini 的政治偏见，采用 14 种不同语言进行政治轴测试，以评估其政治倾向和语言依赖性。结果显示，两者均表现出自由主义和左翼偏见，其中 Gemini 的偏见更为明显，且这些偏见会因查询语言而变化，受数据来源、语言结构、文化背景等因素影响。该研究建议，AI 工具应避免声称完全中立，而是承认潜在偏见并努力实现政治中立，以更 ethical 地响应用户查询。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "stat.AP"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.06436v1",
      "published_date": "2025-04-08 21:13:01 UTC",
      "updated_date": "2025-04-08 21:13:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:45:34.650086"
    },
    {
      "arxiv_id": "2504.06413v1",
      "title": "Evaluating Mutation Techniques in Genetic Algorithm-Based Quantum Circuit Synthesis",
      "title_zh": "评估基于遗传算法的量子电路合成的变异技术",
      "authors": [
        "Michael Kölle",
        "Tom Bintener",
        "Maximilian Zorn",
        "Gerhard Stenzel",
        "Leo Sünkel",
        "Thomas Gabor",
        "Claudia Linnhoff-Popien"
      ],
      "abstract": "Quantum computing leverages the unique properties of qubits and quantum\nparallelism to solve problems intractable for classical systems, offering\nunparalleled computational potential. However, the optimization of quantum\ncircuits remains critical, especially for noisy intermediate-scale quantum\n(NISQ) devices with limited qubits and high error rates. Genetic algorithms\n(GAs) provide a promising approach for efficient quantum circuit synthesis by\nautomating optimization tasks. This work examines the impact of various\nmutation strategies within a GA framework for quantum circuit synthesis. By\nanalyzing how different mutations transform circuits, it identifies strategies\nthat enhance efficiency and performance. Experiments utilized a fitness\nfunction emphasizing fidelity, while accounting for circuit depth and T\noperations, to optimize circuits with four to six qubits. Comprehensive\nhyperparameter testing revealed that combining delete and swap strategies\noutperformed other approaches, demonstrating their effectiveness in developing\nrobust GA-based quantum circuit optimizers.",
      "tldr_zh": "这篇论文评估了遗传算法（GAs）在量子电路合成中的各种突变技术，针对噪声中等规模量子（NISQ）设备的高错误率和有限比特问题，旨在优化电路性能。研究通过实验使用强调保真度的适应度函数，同时考虑电路深度和T操作，来测试突变策略对4到6比特电路的影响。结果表明，结合删除和交换策略的突变方法表现最佳，能够显著提升效率和整体优化效果，为开发稳健的GA-based量子电路优化器提供了关键见解。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "Accepted at GECCO 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.06413v1",
      "published_date": "2025-04-08 20:14:35 UTC",
      "updated_date": "2025-04-08 20:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:45:48.677384"
    },
    {
      "arxiv_id": "2504.06407v1",
      "title": "Understanding Machine Unlearning Through the Lens of Mode Connectivity",
      "title_zh": "通过模式连通性的视角理解机器取消学习",
      "authors": [
        "Jiali Cheng",
        "Hadi Amiri"
      ],
      "abstract": "Machine Unlearning aims to remove undesired information from trained models\nwithout requiring full retraining from scratch. Despite recent advancements,\ntheir underlying loss landscapes and optimization dynamics received less\nattention. In this paper, we investigate and analyze machine unlearning through\nthe lens of mode connectivity - the phenomenon where independently trained\nmodels can be connected by smooth low-loss paths in the parameter space. We\ndefine and study mode connectivity in unlearning across a range of overlooked\nconditions, including connections between different unlearning methods, models\ntrained with and without curriculum learning, and models optimized with\nfirst-order and secondorder techniques. Our findings show distinct patterns of\nfluctuation of different evaluation metrics along the curve, as well as the\nmechanistic (dis)similarity between unlearning methods. To the best of our\nknowledge, this is the first study on mode connectivity in the context of\nmachine unlearning.",
      "tldr_zh": "本论文通过 Mode Connectivity 的视角，分析了 Machine Unlearning 的优化动态和损失景观，Machine Unlearning 旨在从训练模型中移除 undesired 信息，而无需完全重新训练。研究者定义并探索了在不同条件下的 Mode Connectivity，包括不同 Unlearning 方法、带或不带 Curriculum Learning 的模型，以及一阶和二阶优化技术。结果显示，评估指标沿连接路径呈现出明显的波动模式，并揭示了 Unlearning 方法之间的机制相似性或差异；这也是首次在 Machine Unlearning 上下文中系统研究 Mode Connectivity。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06407v1",
      "published_date": "2025-04-08 20:02:10 UTC",
      "updated_date": "2025-04-08 20:02:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:45:59.228094"
    },
    {
      "arxiv_id": "2504.06404v1",
      "title": "Physical spline for denoising object trajectory data by combining splines, ML feature regression and model knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas Torzewski"
      ],
      "abstract": "This article presents a method for estimating the dynamic driving states\n(position, velocity, acceleration and heading) from noisy measurement data. The\nproposed approach is effective with both complete and partial observations,\nproducing refined trajectory signals with kinematic consistency, ensuring that\nvelocity is the integral of acceleration and position is the integral of\nvelocity. Additionally, the method accounts for the constraint that vehicles\ncan only move in the direction of their orientation. The method is implemented\nas a configurable python library that also enables trajectory estimation solely\nbased on position data. Regularization is applied to prevent extreme state\nvariations. A key application is enhancing recorded trajectory data for use as\nreference inputs in machine learning models. At the end, the article presents\nthe results of the method along with a comparison to ground truth data.",
      "tldr_zh": "这篇论文提出了一种名为 Physical spline 的方法，用于从噪声测量数据中估计对象的动态状态，包括位置、速度、加速度和航向。该方法结合 splines、ML feature regression 和 model knowledge，确保轨迹信号具有运动学一致性（如速度为加速度的积分），并考虑车辆只能朝其方向移动的约束。该方法实现为一个可配置的 Python 库，能处理完整或部分观察数据，并通过正则化防止极端状态变化。实验结果显示，该方法显著提升了轨迹数据的质量，并与地面真实数据进行了比较，主要应用于增强记录轨迹作为机器学习模型的参考输入。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "7 pages, 7 figures, https://github.com/jonasTorz/physical_spline",
      "pdf_url": "http://arxiv.org/pdf/2504.06404v1",
      "published_date": "2025-04-08 19:53:57 UTC",
      "updated_date": "2025-04-08 19:53:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:46:11.768827"
    },
    {
      "arxiv_id": "2504.06265v2",
      "title": "GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning through Bayesian Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Bojana Ranković",
        "Philippe Schwaller"
      ],
      "abstract": "Large Language Models (LLMs) can encode complex relationships in their latent\nspaces, yet harnessing them for optimization under uncertainty remains\nchallenging. We address this gap with a novel architecture that reframes LLM\nfinetuning as Gaussian process (GP) marginal likelihood optimization via deep\nkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPs\nto preserve the benefits of both - LLMs to provide a rich and flexible input\nspace for Bayesian optimization and - GPs to model this space with predictive\nuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction\noptimization, our method nearly doubles the discovery rate of high-performing\nreactions compared to static LLM embeddings (from 24% to 43% coverage of the\ntop 5% reactions in just 50 optimization iterations). We also observe a 14%\nimprovement over domain-specific representations without requiring specialized\nfeatures. Extensive empirical evaluation across 19 benchmarks - ranging from\ngeneral chemistry to reaction and molecular property optimization -\ndemonstrates our method's robustness, generality, and consistent improvements\nacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),\n(3) pretraining domains (chemistry-related or general-purpose) and (4)\nhyperparameter settings (tuned once on a single dataset). Finally, we explain\nthese improvements: joint LLM-GP optimization through marginal likelihood\nimplicitly performs contrastive learning, aligning representations to produce\n(1) better-structured embedding spaces, (2) improved uncertainty calibration,\nand (3) more efficient sampling - without requiring any external loss. This\nwork provides both practical advances in sample-efficient optimization and\ninsights into what makes effective Bayesian optimization.",
      "tldr_zh": "该论文提出GOLLuM框架，通过Gaussian Process (GP)优化Large Language Models (LLMs)的微调，将其重新框架为基于深度核方法的GP边缘似然优化。方法结合LLM-based deep kernels与GP的联合优化，利用LLMs的丰富输入空间和GP的预测不确定性，提升Bayesian Optimization的采样效率。在Buchwald-Hartwig反应优化等19个基准测试中，GOLLuM将高性能反应的发现率提高近一倍（从24%到43%），并在不同LLM架构和预训练领域中表现出色。研究进一步解释，这些改进源于联合优化隐式进行的对比学习，提高了嵌入空间结构、不确定性校准和整体优化效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06265v2",
      "published_date": "2025-04-08 17:59:57 UTC",
      "updated_date": "2025-04-09 23:45:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:46:23.804263"
    },
    {
      "arxiv_id": "2504.06260v1",
      "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability",
      "title_zh": "翻译失败",
      "authors": [
        "Nayantara Mudur",
        "Hao Cui",
        "Subhashini Venugopalan",
        "Paul Raccuglia",
        "Michael P. Brenner",
        "Peter Norgaard"
      ],
      "abstract": "Building precise simulations of the real world and invoking numerical solvers\nto answer quantitative problems is an essential requirement in engineering and\nscience. We present FEABench, a benchmark to evaluate the ability of large\nlanguage models (LLMs) and LLM agents to simulate and solve physics,\nmathematics and engineering problems using finite element analysis (FEA). We\nintroduce a comprehensive evaluation scheme to investigate the ability of LLMs\nto solve these problems end-to-end by reasoning over natural language problem\ndescriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to\ncompute the answers. We additionally design a language model agent equipped\nwith the ability to interact with the software through its Application\nProgramming Interface (API), examine its outputs and use tools to improve its\nsolutions over multiple iterations. Our best performing strategy generates\nexecutable API calls 88% of the time. LLMs that can successfully interact with\nand operate FEA software to solve problems such as those in our benchmark would\npush the frontiers of automation in engineering. Acquiring this capability\nwould augment LLMs' reasoning skills with the precision of numerical solvers\nand advance the development of autonomous systems that can tackle complex\nproblems in the real world. The code is available at\nhttps://github.com/google/feabench",
      "tldr_zh": "本研究引入了 FEABench 基准，用于评估大型语言模型 (LLMs) 和 LLM 代理在多物理场推理方面的能力，专注于通过有限元分析 (FEA) 模拟和解决物理、数学及工程问题。研究设计了一个全面评估方案，让 LLMs 通过推理自然语言问题描述并操作 COMSOL Multiphysics$^\\circledR$ 软件的 API 来计算答案，同时开发了一个可交互的 LLM 代理，能够检查输出并通过多次迭代改进解决方案。实验结果显示，最佳策略的 API 调用成功率达到 88%，这有助于增强 LLMs 的推理能力与数值求解器的精确性，推动工程领域的自动化和自主系统发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.AI",
      "comment": "39 pages. Accepted at the NeurIPS 2024 Workshops on Mathematical\n  Reasoning and AI and Open-World Agents",
      "pdf_url": "http://arxiv.org/pdf/2504.06260v1",
      "published_date": "2025-04-08 17:59:39 UTC",
      "updated_date": "2025-04-08 17:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:46:36.384768"
    },
    {
      "arxiv_id": "2504.06235v2",
      "title": "Decentralized Federated Domain Generalization with Style Sharing: A Formal Modeling and Convergence Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Shahryar Zehtabi",
        "Dong-Jun Han",
        "Seyyedali Hosseinalipour",
        "Christopher G. Brinton"
      ],
      "abstract": "Much of the federated learning (FL) literature focuses on settings where\nlocal dataset statistics remain the same between training and testing time.\nRecent advances in domain generalization (DG) aim to use data from source\n(training) domains to train a model that generalizes well to data from unseen\ntarget (testing) domains. In this paper, we are motivated by two major gaps in\nexisting work on FL and DG: (1) the lack of formal mathematical analysis of DG\nobjectives and training processes; and (2) DG research in FL being limited to\nthe conventional star-topology architecture. Addressing the second gap, we\ndevelop $\\textit{Decentralized Federated Domain Generalization with Style\nSharing}$ ($\\texttt{StyleDDG}$), a fully decentralized DG algorithm designed to\nallow devices in a peer-to-peer network to achieve DG based on sharing style\ninformation inferred from their datasets. Additionally, we fill the first gap\nby providing the first systematic approach to mathematically analyzing\nstyle-based DG training optimization. We cast existing centralized DG\nalgorithms within our framework, and employ their formalisms to model\n$\\texttt{StyleDDG}$. Based on this, we obtain analytical conditions under which\na sub-linear convergence rate of $\\texttt{StyleDDG}$ can be obtained. Through\nexperiments on two popular DG datasets, we demonstrate that $\\texttt{StyleDDG}$\ncan obtain significant improvements in accuracy across target domains with\nminimal added communication overhead compared to decentralized gradient methods\nthat do not employ style sharing.",
      "tldr_zh": "这篇论文解决了联邦学习（FL）中领域泛化（DG）的两大空白：缺乏正式数学分析和局限于星形拓扑架构。作者提出 $\\texttt{StyleDDG}$，一个完全去中心化的 DG 算法，允许设备在点对点网络中通过共享样式信息来实现模型在未见目标域的泛化。论文首次提供系统化的数学建模和收敛分析，证明 $\\texttt{StyleDDG}$ 可获得次线性收敛率，并在两个 DG 数据集上实验显示，其在目标域准确率显著提升，同时通信开销最小。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06235v2",
      "published_date": "2025-04-08 17:32:56 UTC",
      "updated_date": "2025-04-17 08:52:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:46:47.905166"
    },
    {
      "arxiv_id": "2504.07994v1",
      "title": "Evaluating the Fitness of Ontologies for the Task of Question Generation",
      "title_zh": "评估本体用于问题生成任务的适合性",
      "authors": [
        "Samah Alkhuzaey",
        "Floriana Grasso",
        "Terry R. Payne",
        "Valentina Tamma"
      ],
      "abstract": "Ontology-based question generation is an important application of\nsemantic-aware systems that enables the creation of large question banks for\ndiverse learning environments. The effectiveness of these systems, both in\nterms of the calibre and cognitive difficulty of the resulting questions,\ndepends heavily on the quality and modelling approach of the underlying\nontologies, making it crucial to assess their fitness for this task. To date,\nthere has been no comprehensive investigation into the specific ontology\naspects or characteristics that affect the question generation process.\nTherefore, this paper proposes a set of requirements and task-specific metrics\nfor evaluating the fitness of ontologies for question generation tasks in\npedagogical settings. Using the ROMEO methodology, a structured framework for\nderiving task-specific metrics, an expert-based approach is employed to assess\nthe performance of various ontologies in Automatic Question Generation (AQG)\ntasks, which is then evaluated over a set of ontologies. Our results\ndemonstrate that ontology characteristics significantly impact the\neffectiveness of question generation, with different ontologies exhibiting\nvarying performance levels. This highlights the importance of assessing\nontology quality with respect to AQG tasks.",
      "tldr_zh": "这篇论文评估了本体（ontologies）在问答生成任务中的适用性，强调本体质量和建模方法对生成问题的质量和认知难度影响重大。\n论文提出一套要求和任务特定指标，使用 ROMEO 方法论结合专家评估来检验各种本体在自动问答生成（AQG）任务中的性能。\n结果显示，本体特性显著影响问答生成的有效性，不同本体表现出不同表现水平，从而突出了针对 AQG 任务评估本体质量的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.07994v1",
      "published_date": "2025-04-08 17:10:04 UTC",
      "updated_date": "2025-04-08 17:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:46:58.877409"
    },
    {
      "arxiv_id": "2504.06214v1",
      "title": "From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chejian Xu",
        "Wei Ping",
        "Peng Xu",
        "Zihan Liu",
        "Boxin Wang",
        "Mohammad Shoeybi",
        "Bo Li",
        "Bryan Catanzaro"
      ],
      "abstract": "Long-context capabilities are essential for a wide range of applications,\nincluding document and video understanding, in-context learning, and\ninference-time scaling, all of which require models to process and reason over\nlong sequences of text and multimodal data. In this work, we introduce a\nefficient training recipe for building ultra-long context LLMs from aligned\ninstruct model, pushing the boundaries of context lengths from 128K to 1M, 2M,\nand 4M tokens. Our approach leverages efficient continued pretraining\nstrategies to extend the context window and employs effective instruction\ntuning to maintain the instruction-following and reasoning abilities. Our\nUltraLong-8B, built on Llama3.1-Instruct with our recipe, achieves\nstate-of-the-art performance across a diverse set of long-context benchmarks.\nImportantly, models trained with our approach maintain competitive performance\non standard benchmarks, demonstrating balanced improvements for both long and\nshort context tasks. We further provide an in-depth analysis of key design\nchoices, highlighting the impacts of scaling strategies and data composition.\nOur findings establish a robust framework for efficiently scaling context\nlengths while preserving general model capabilities. We release all model\nweights at: https://ultralong.github.io/.",
      "tldr_zh": "这篇论文提出了一种高效训练方法，用于将大型语言模型（LLMs）的上下文长度从128K扩展到1M、2M和4M tokens，针对文档理解、在上下文学习和推理等应用的需求。方法包括利用高效的持续预训练策略（efficient continued pretraining strategies）扩展上下文窗口，以及有效的指令调整（effective instruction tuning）来维持模型的指令遵循和推理能力。基于Llama3.1-Instruct构建的UltraLong-8B模型在多种长上下文benchmark上实现最先进性能，同时在标准benchmark上保持竞争力，并通过深入分析关键设计选择（如缩放策略和数据组成）建立了稳健的框架。模型权重已开源，提供给研究社区使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06214v1",
      "published_date": "2025-04-08 16:58:58 UTC",
      "updated_date": "2025-04-08 16:58:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:47:11.370866"
    },
    {
      "arxiv_id": "2504.06207v1",
      "title": "An experimental survey and Perspective View on Meta-Learning for Automated Algorithms Selection and Parametrization",
      "title_zh": "翻译失败",
      "authors": [
        "Moncef Garouani"
      ],
      "abstract": "Considerable progress has been made in the recent literature studies to\ntackle the Algorithms Selection and Parametrization (ASP) problem, which is\ndiversified in multiple meta-learning setups. Yet there is a lack of surveys\nand comparative evaluations that critically analyze, summarize and assess the\nperformance of existing methods. In this paper, we provide an overview of the\nstate of the art in this continuously evolving field. The survey sheds light on\nthe motivational reasons for pursuing classifiers selection through\nmeta-learning. In this regard, Automated Machine Learning (AutoML) is usually\ntreated as an ASP problem under the umbrella of the democratization of machine\nlearning. Accordingly, AutoML makes machine learning techniques accessible to\ndomain scientists who are interested in applying advanced analytics but lack\nthe required expertise. It can ease the task of manually selecting ML\nalgorithms and tuning related hyperparameters. We comprehensively discuss the\ndifferent phases of classifiers selection based on a generic framework that is\nformed as an outcome of reviewing prior works. Subsequently, we propose a\nbenchmark knowledge base of 4 millions previously learned models and present\nextensive comparative evaluations of the prominent methods for classifiers\nselection based on 08 classification algorithms and 400 benchmark datasets. The\ncomparative study quantitatively assesses the performance of algorithms\nselection methods along while emphasizing the strengths and limitations of\nexisting studies.",
      "tldr_zh": "这篇论文对Meta-Learning在Automated Algorithms Selection and Parametrization (ASP)中的应用进行了实验调查和综述，旨在填补现有方法缺乏系统评估的空白。作者概述了ASP问题的背景，将其与Automated Machine Learning (AutoML)联系起来，强调其在帮助非专家简化算法选择和超参数调优方面的作用，并提出一个基于通用框架的分类器选择阶段。实验通过一个包含400万模型的基准知识库，对8种分类算法和400个数据集进行比较评估，量化了方法的性能优势，同时指出了现有研究的局限性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06207v1",
      "published_date": "2025-04-08 16:51:22 UTC",
      "updated_date": "2025-04-08 16:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:47:22.878377"
    },
    {
      "arxiv_id": "2504.06196v1",
      "title": "TxGemma: Efficient and Agentic LLMs for Therapeutics",
      "title_zh": "翻译失败",
      "authors": [
        "Eric Wang",
        "Samuel Schmidgall",
        "Paul F. Jaeger",
        "Fan Zhang",
        "Rory Pilgrim",
        "Yossi Matias",
        "Joelle Barral",
        "David Fleet",
        "Shekoofeh Azizi"
      ],
      "abstract": "Therapeutic development is a costly and high-risk endeavor that is often\nplagued by high failure rates. To address this, we introduce TxGemma, a suite\nof efficient, generalist large language models (LLMs) capable of therapeutic\nproperty prediction as well as interactive reasoning and explainability. Unlike\ntask-specific models, TxGemma synthesizes information from diverse sources,\nenabling broad application across the therapeutic development pipeline. The\nsuite includes 2B, 9B, and 27B parameter models, fine-tuned from Gemma-2 on a\ncomprehensive dataset of small molecules, proteins, nucleic acids, diseases,\nand cell lines. Across 66 therapeutic development tasks, TxGemma achieved\nsuperior or comparable performance to the state-of-the-art generalist model on\n64 (superior on 45), and against state-of-the-art specialist models on 50\n(superior on 26). Fine-tuning TxGemma models on therapeutic downstream tasks,\nsuch as clinical trial adverse event prediction, requires less training data\nthan fine-tuning base LLMs, making TxGemma suitable for data-limited\napplications. Beyond these predictive capabilities, TxGemma features\nconversational models that bridge the gap between general LLMs and specialized\nproperty predictors. These allow scientists to interact in natural language,\nprovide mechanistic reasoning for predictions based on molecular structure, and\nengage in scientific discussions. Building on this, we further introduce\nAgentic-Tx, a generalist therapeutic agentic system powered by Gemini 2.5 that\nreasons, acts, manages diverse workflows, and acquires external domain\nknowledge. Agentic-Tx surpasses prior leading models on the Humanity's Last\nExam benchmark (Chemistry & Biology) with 52.3% relative improvement over\no3-mini (high) and 26.7% over o3-mini (high) on GPQA (Chemistry) and excels\nwith improvements of 6.3% (ChemBench-Preference) and 2.4% (ChemBench-Mini) over\no3-mini (high).",
      "tldr_zh": "本文介绍了 TxGemma，一套高效的通用大型语言模型 (LLMs)，旨在提升治疗开发效率，通过从 Gemma-2 微调的 2B、9B 和 27B 参数模型，处理小分子、蛋白质等数据，实现治疗属性预测和交互式推理。TxGemma 在 66 个治疗任务中优于或相当于是现有通用和专业模型（在 45 个任务上表现优越），并在数据有限场景下需更少训练数据。进一步，Agentic-Tx 系统基于 Gemini 2.5 构建，支持自然语言交互、机制推理和工作流管理，并在 Humanity's Last Exam 和 GPQA 等基准上显著超越领先模型。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06196v1",
      "published_date": "2025-04-08 16:39:02 UTC",
      "updated_date": "2025-04-08 16:39:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:47:35.949533"
    },
    {
      "arxiv_id": "2504.06193v1",
      "title": "Heuristic Methods are Good Teachers to Distill MLPs for Graph Link Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zongyue Qin",
        "Shichang Zhang",
        "Mingxuan Ju",
        "Tong Zhao",
        "Neil Shah",
        "Yizhou Sun"
      ],
      "abstract": "Link prediction is a crucial graph-learning task with applications including\ncitation prediction and product recommendation. Distilling Graph Neural\nNetworks (GNNs) teachers into Multi-Layer Perceptrons (MLPs) students has\nemerged as an effective approach to achieve strong performance and reducing\ncomputational cost by removing graph dependency. However, existing distillation\nmethods only use standard GNNs and overlook alternative teachers such as\nspecialized model for link prediction (GNN4LP) and heuristic methods (e.g.,\ncommon neighbors). This paper first explores the impact of different teachers\nin GNN-to-MLP distillation. Surprisingly, we find that stronger teachers do not\nalways produce stronger students: MLPs distilled from GNN4LP can underperform\nthose distilled from simpler GNNs, while weaker heuristic methods can teach\nMLPs to near-GNN performance with drastically reduced training costs. Building\non these insights, we propose Ensemble Heuristic-Distilled MLPs (EHDM), which\neliminates graph dependencies while effectively integrating complementary\nsignals via a gating mechanism. Experiments on ten datasets show an average\n7.93% improvement over previous GNN-to-MLP approaches with 1.95-3.32 times less\ntraining time, indicating EHDM is an efficient and effective link prediction\nmethod.",
      "tldr_zh": "本论文探讨了在图链接预测任务中，使用启发式方法作为老师来蒸馏 Multi-Layer Perceptrons (MLPs) 的效果，发现更强的 Graph Neural Networks (GNNs) 老师（如 GNN4LP）并不总是产生更好的学生，而较弱的启发式方法（如常见邻居）能以显著减少训练成本的方式教导 MLPs 达到近似 GNN 性能。作者提出 Ensemble Heuristic-Distilled MLPs (EHDM) 方法，通过门控机制整合互补信号，成功消除图依赖。实验在十个数据集上显示，EHDM 比现有 GNN-to-MLP 方法平均提高 7.93% 的性能，同时训练时间减少 1.95-3.32 倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06193v1",
      "published_date": "2025-04-08 16:35:11 UTC",
      "updated_date": "2025-04-08 16:35:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:47:47.908428"
    },
    {
      "arxiv_id": "2504.06188v1",
      "title": "SkillFlow: Efficient Skill and Code Transfer Through Communication in Adapting AI Agents",
      "title_zh": "SkillFlow：通过通信在AI代理适应中实现高效技能和代码转移",
      "authors": [
        "Pagkratios Tagkopoulos",
        "Fangzhou Li",
        "Ilias Tagkopoulos"
      ],
      "abstract": "AI agents are autonomous systems that can execute specific tasks based on\npredefined programming. Here, we present SkillFlow, a modular,\ntechnology-agnostic framework that allows agents to expand their functionality\nin an ad-hoc fashion by acquiring new skills from their environment or other\nagents. We present a theoretical model that examines under which conditions\nthis framework would be beneficial, and we then explore SkillFlow's ability to\naccelerate task completion and lead to lower cumulative costs in a real-world\napplication, namely scheduling agents for calendar events. We demonstrate that\nwithin a few iterations, SkillFlow leads to considerable (24.8%, p-value =\n$6.4\\times10^{-3}$) gains in time and cost, especially when the communication\ncost is high. Finally, we draw analogies from well-studied biological systems\nand compare this framework to that of lateral gene transfer, a significant\nprocess of adaptation and evolution in novel environments.",
      "tldr_zh": "本文提出SkillFlow框架，这是一个模块化的、技术无关的系统，允许AI agents通过通信从环境或其他代理获取新技能，从而实现高效的功能扩展和适应。我们开发了一个理论模型来分析这种框架的适用条件，并在日历事件调度等实际应用中验证其效果，展示了在几轮迭代内显著降低时间和成本（24.8%，p-value = $6.4\\times10^{-3}$），特别是在高通信成本场景下。最终，SkillFlow的机制被类比于生物系统的lateral gene transfer，强调其在AI代理进化中的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06188v1",
      "published_date": "2025-04-08 16:33:24 UTC",
      "updated_date": "2025-04-08 16:33:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:47:59.553723"
    },
    {
      "arxiv_id": "2504.06185v1",
      "title": "WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and Real-World Wound Care",
      "title_zh": "WoundAmbit：桥接最先进的语义分割与真实世界的伤口护理",
      "authors": [
        "Vanessa Borst",
        "Timo Dittus",
        "Tassilo Dege",
        "Astrid Schmieder",
        "Samuel Kounev"
      ],
      "abstract": "Chronic wounds affect a large population, particularly the elderly and\ndiabetic patients, who often exhibit limited mobility and co-existing health\nconditions. Automated wound monitoring via mobile image capture can reduce\nin-person physician visits by enabling remote tracking of wound size. Semantic\nsegmentation is key to this process, yet wound segmentation remains\nunderrepresented in medical imaging research. To address this, we benchmark\nstate-of-the-art deep learning models from general-purpose vision, medical\nimaging, and top methods from public wound challenges. For fair comparison, we\nstandardize training, data augmentation, and evaluation, conducting\ncross-validationto minimize partitioning bias. We also assess real-world\ndeployment aspects, including generalization to an out-of-distribution wound\ndataset, computational efficiency, and interpretability. Additionally, we\npropose a reference object-based approach to convert AI-generated masks into\nclinically relevant wound size estimates, and evaluate this, along with mask\nquality, for the best models based on physician assessments. Overall, the\ntransformer-based TransNeXt showed the highest levels of generalizability.\nDespite variations in inference times, all models processed at least one image\nper second on the CPU, which is deemed adequate for the intended application.\nInterpretability analysis typically revealed prominent activations in wound\nregions, emphasizing focus on clinically relevant features. Expert evaluation\nshowed high mask approval for all analyzed models, with VWFormer and ConvNeXtS\nbackbone performing the best. Size retrieval accuracy was similar across\nmodels, and predictions closely matched expert annotations. Finally, we\ndemonstrate how our AI-driven wound size estimation framework, WoundAmbit, can\nbe integrated into a custom telehealth system. Our code will be made available\non GitHub upon publication.",
      "tldr_zh": "该研究针对慢性伤口监测问题，基准测试了多种深度学习模型，包括通用视觉、医疗成像和公共伤口挑战中的顶级方法，如TransNeXt和VWFormer，以提升语义分割在实际伤口护理中的应用。研究标准化了训练、数据增强和交叉验证评估，并评估了模型的泛化能力、计算效率（所有模型在CPU上至少每秒处理一张图像）和可解释性。作者提出了一种基于参考对象的approach，将AI生成的mask转换为临床相关的伤口大小估计，结果显示TransNeXt具有最高泛化性，VWFormer和ConvNeXtS在专家评估中表现最佳，且大小估计准确性与专家标注高度一致。最终，该框架WoundAmbit可整合到自定义远程医疗系统中，并计划开源代码以促进实际部署。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Main paper: 17 pages; supplementary material: 16 pages; paper\n  submitted to the application track of the European Conference on Machine\n  Learning and Principles and Practice of Knowledge Discovery in Databases\n  (ECML PKDD 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.06185v1",
      "published_date": "2025-04-08 16:25:59 UTC",
      "updated_date": "2025-04-08 16:25:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:48:11.991690"
    },
    {
      "arxiv_id": "2504.06176v2",
      "title": "A Self-Supervised Framework for Space Object Behaviour Characterisation",
      "title_zh": "一种自监督框架，用于空间物体行为表征",
      "authors": [
        "Ian Groves",
        "Andrew Campbell",
        "James Fernandes",
        "Diego Ramírez Rodríguez",
        "Paul Murray",
        "Massimiliano Vasile",
        "Victoria Nockles"
      ],
      "abstract": "Foundation Models, pre-trained on large unlabelled datasets before\ntask-specific fine-tuning, are increasingly being applied to specialised\ndomains. Recent examples include ClimaX for climate and Clay for satellite\nEarth observation, but a Foundation Model for Space Object Behavioural Analysis\nhas not yet been developed. As orbital populations grow, automated methods for\ncharacterising space object behaviour are crucial for space safety. We present\na Space Safety and Sustainability Foundation Model focusing on space object\nbehavioural analysis using light curves (LCs). We implemented a\nPerceiver-Variational Autoencoder (VAE) architecture, pre-trained with\nself-supervised reconstruction and masked reconstruction on 227,000 LCs from\nthe MMT-9 observatory. The VAE enables anomaly detection, motion prediction,\nand LC generation. We fine-tuned the model for anomaly detection & motion\nprediction using two independent LC simulators (CASSANDRA and GRIAL\nrespectively), using CAD models of boxwing, Sentinel-3, SMOS, and Starlink\nplatforms. Our pre-trained model achieved a reconstruction error of 0.01%,\nidentifying potentially anomalous light curves through reconstruction\ndifficulty. After fine-tuning, the model scored 88% and 82% accuracy, with 0.90\nand 0.95 ROC AUC scores respectively in both anomaly detection and motion mode\nprediction (sun-pointing, spin, etc.). Analysis of high-confidence anomaly\npredictions on real data revealed distinct patterns including characteristic\nobject profiles and satellite glinting. Here, we demonstrate how\nself-supervised learning can simultaneously enable anomaly detection, motion\nprediction, and synthetic data generation from rich representations learned in\npre-training. Our work therefore supports space safety and sustainability\nthrough automated monitoring and simulation capabilities.",
      "tldr_zh": "本文提出了一种自监督框架，用于空间物体行为表征，开发了首个专注于此领域的Foundation Model，以支持空间安全和可持续性。该框架采用Perceiver-VAE架构，在22.7万条light curves上进行自监督预训练，包括重建和masked重建任务，从而实现异常检测、运动预测和light curves生成。实验结果显示，预训练模型重建错误率仅0.01%，微调后在异常检测和运动模式预测（如sun-pointing或spin）上分别达到88%和82%准确率，并通过高置信度预测揭示了真实数据中的独特模式，如物体轮廓和卫星glinting。该工作展示了自监督学习如何同时增强自动化监控、模拟和分析能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.space-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.06176v2",
      "published_date": "2025-04-08 16:19:19 UTC",
      "updated_date": "2025-04-11 08:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:48:23.504892"
    },
    {
      "arxiv_id": "2504.06173v1",
      "title": "Multi-Modality Sensing in mmWave Beamforming for Connected Vehicles Using Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Baqer Mollah",
        "Honggang Wang",
        "Mohammad Ataul Karim",
        "Hua Fang"
      ],
      "abstract": "Beamforming techniques are considered as essential parts to compensate severe\npath losses in millimeter-wave (mmWave) communications. In particular, these\ntechniques adopt large antenna arrays and formulate narrow beams to obtain\nsatisfactory received powers. However, performing accurate beam alignment over\nnarrow beams for efficient link configuration by traditional standard defined\nbeam selection approaches, which mainly rely on channel state information and\nbeam sweeping through exhaustive searching, imposes computational and\ncommunications overheads. And, such resulting overheads limit their potential\nuse in vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V)\ncommunications involving highly dynamic scenarios. In comparison, utilizing\nout-of-band contextual information, such as sensing data obtained from sensor\ndevices, provides a better alternative to reduce overheads. This paper presents\na deep learning-based solution for utilizing the multi-modality sensing data\nfor predicting the optimal beams having sufficient mmWave received powers so\nthat the best V2I and V2V line-of-sight links can be ensured proactively. The\nproposed solution has been tested on real-world measured mmWave sensing and\ncommunication data, and the results show that it can achieve up to 98.19%\naccuracies while predicting top-13 beams. Correspondingly, when compared to\nexisting been sweeping approach, the beam sweeping searching space and time\noverheads are greatly shortened roughly by 79.67% and 91.89%, respectively\nwhich confirm a promising solution for beamforming in mmWave enabled\ncommunications.",
      "tldr_zh": "这篇论文针对毫米波(mmWave)通信中beamforming技术的计算和通信开销问题，提出了一种基于深度学习的解决方案，利用多模态sensing数据（如传感器信息）来预测最佳beams，确保车辆间(V2I和V2V)通信的高效线-of-sight链接。方法通过整合out-of-band contextual information，减少了传统beam sweeping的exhaustive searching开销。实验结果显示，该方案在真实mmWave数据上实现了高达98.19%的准确率（预测top-13 beams），并将搜索空间和时间开销分别降低约79.67%和91.89%。这为动态车辆通信场景提供了高效的beamforming优化策略。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.NI",
      "comment": "15 Pages",
      "pdf_url": "http://arxiv.org/pdf/2504.06173v1",
      "published_date": "2025-04-08 16:18:00 UTC",
      "updated_date": "2025-04-08 16:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:48:35.414481"
    },
    {
      "arxiv_id": "2504.06165v1",
      "title": "Real-Time Pitch/F0 Detection Using Spectrogram Images and Convolutional Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Xufang Zhao",
        "Omer Tsimhoni"
      ],
      "abstract": "This paper presents a novel approach to detect F0 through Convolutional\nNeural Networks and image processing techniques to directly estimate pitch from\nspectrogram images. Our new approach demonstrates a very good detection\naccuracy; a total of 92% of predicted pitch contours have strong or moderate\ncorrelations to the true pitch contours. Furthermore, the experimental\ncomparison between our new approach and other state-of-the-art CNN methods\nreveals that our approach can enhance the detection rate by approximately 5%\nacross various Signal-to-Noise Ratio conditions.",
      "tldr_zh": "这篇论文提出了一种新方法，使用 Spectrogram Images 和 Convolutional Neural Networks (CNN) 来实时检测音高 (F0)，通过图像处理技术直接从频谱图中估计音高轮廓。实验结果显示，该方法检测准确率高达92%，其中预测轮廓与真实轮廓有强或中度相关性。与其他最先进 CNN 方法相比，它在各种 Signal-to-Noise Ratio (SNR) 条件下提高了约5%的检测率，从而提升了音高检测的可靠性和效率。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06165v1",
      "published_date": "2025-04-08 16:01:25 UTC",
      "updated_date": "2025-04-08 16:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:48:46.209343"
    },
    {
      "arxiv_id": "2504.06160v3",
      "title": "Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups",
      "title_zh": "翻译失败",
      "authors": [
        "Rijul Magu",
        "Arka Dutta",
        "Sean Kim",
        "Ashiqur R. KhudaBukhsh",
        "Munmun De Choudhury"
      ],
      "abstract": "Large Language Models (LLMs) have been shown to demonstrate imbalanced biases\nagainst certain groups. However, the study of unprovoked targeted attacks by\nLLMs towards at-risk populations remains underexplored. Our paper presents\nthree novel contributions: (1) the explicit evaluation of LLM-generated attacks\non highly vulnerable mental health groups; (2) a network-based framework to\nstudy the propagation of relative biases; and (3) an assessment of the relative\ndegree of stigmatization that emerges from these attacks. Our analysis of a\nrecently released large-scale bias audit dataset reveals that mental health\nentities occupy central positions within attack narrative networks, as revealed\nby a significantly higher mean centrality of closeness (p-value = 4.06e-10) and\ndense clustering (Gini coefficient = 0.7). Drawing from sociological\nfoundations of stigmatization theory, our stigmatization analysis indicates\nincreased labeling components for mental health disorder-related targets\nrelative to initial targets in generation chains. Taken together, these\ninsights shed light on the structural predilections of large language models to\nheighten harmful discourse and highlight the need for suitable approaches for\nmitigation.",
      "tldr_zh": "该研究探讨了大型语言模型 (LLMs) 在生成针对心理健康群体的攻击叙事时出现的偏见问题，填补了相关领域的空白。论文的主要贡献包括：(1) 评估 LLM 对高度脆弱心理健康群体的未激发的攻击；(2) 提出一个基于网络的框架来研究偏见传播；(3) 评估这些攻击导致的污名化程度。分析结果显示，心理健康实体在攻击叙事网络中占据中心位置，具有显著更高的 closeness 中心性 (p-value = 4.06e-10) 和密集聚类 (Gini coefficient = 0.7)。总体而言，该研究揭示了 LLMs 加剧有害话语的结构性倾向，并呼吁开发适当的缓解策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SI",
        "J.4; K.4.1; K.4.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06160v3",
      "published_date": "2025-04-08 15:56:57 UTC",
      "updated_date": "2025-04-11 20:13:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:48:59.513918"
    },
    {
      "arxiv_id": "2504.06143v1",
      "title": "ARLO: A Tailorable Approach for Transforming Natural Language Software Requirements into Architecture using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Tooraj Helmi"
      ],
      "abstract": "Software requirements expressed in natural language (NL) frequently suffer\nfrom verbosity, ambiguity, and inconsistency. This creates a range of\nchallenges, including selecting an appropriate architecture for a system and\nassessing different architectural alternatives. Relying on human expertise to\naccomplish the task of mapping NL requirements to architecture is\ntime-consuming and error-prone. This paper proposes ARLO, an approach that\nautomates this task by leveraging (1) a set of NL requirements for a system,\n(2) an existing standard that specifies architecturally relevant software\nquality attributes, and (3) a readily available Large Language Model (LLM).\nSpecifically, ARLO determines the subset of NL requirements for a given system\nthat is architecturally relevant and maps that subset to a tailorable matrix of\narchitectural choices. ARLO applies integer linear programming on the\narchitectural-choice matrix to determine the optimal architecture for the\ncurrent requirements. We demonstrate ARLO's efficacy using a set of real-world\nexamples. We highlight ARLO's ability (1) to trace the selected architectural\nchoices to the requirements and (2) to isolate NL requirements that exert a\nparticular influence on a system's architecture. This allows the\nidentification, comparative assessment, and exploration of alternative\narchitectural choices based on the requirements and constraints expressed\ntherein.",
      "tldr_zh": "该论文提出ARLO，一种可定制的方法，利用Large Language Models (LLMs)将自然语言软件需求(NL requirements)自动转化为系统架构，以解决需求中的冗长、模糊和不一致问题。ARLO通过分析NL requirements的架构相关子集、映射到可调整的架构选择矩阵，并应用integer linear programming优化算法，确定最优架构。实验结果显示，ARLO在真实案例中有效，能够追踪架构选择与需求的对应关系，并隔离影响架构的关键需求，从而支持架构备选方案的比较和探索。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06143v1",
      "published_date": "2025-04-08 15:38:42 UTC",
      "updated_date": "2025-04-08 15:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:49:11.097082"
    },
    {
      "arxiv_id": "2504.06138v2",
      "title": "A Multimedia Analytics Model for the Foundation Model Era",
      "title_zh": "翻译失败",
      "authors": [
        "Marcel Worring",
        "Jan Zahálka",
        "Stef van den Elzen",
        "Maximilian T. Fischer",
        "Daniel A. Keim"
      ],
      "abstract": "The rapid advances in Foundation Models and agentic Artificial Intelligence\nare transforming multimedia analytics by enabling richer, more sophisticated\ninteractions between humans and analytical systems. Existing conceptual models\nfor visual and multimedia analytics, however, do not adequately capture the\ncomplexity introduced by these powerful AI paradigms. To bridge this gap, we\npropose a comprehensive multimedia analytics model specifically designed for\nthe foundation model era. Building upon established frameworks from visual\nanalytics, multimedia analytics, knowledge generation, analytic task\ndefinition, mixed-initiative guidance, and human-in-the-loop reinforcement\nlearning, our model emphasizes integrated human-AI teaming based on visual\nanalytics agents from both technical and conceptual perspectives. Central to\nthe model is a seamless, yet explicitly separable, interaction channel between\nexpert users and semi-autonomous analytical processes, ensuring continuous\nalignment between user intent and AI behavior. The model addresses practical\nchallenges in sensitive domains such as intelligence analysis, investigative\njournalism, and other fields handling complex, high-stakes data. We illustrate\nthrough detailed case studies how our model facilitates deeper understanding\nand targeted improvement of multimedia analytics solutions. By explicitly\ncapturing how expert users can optimally interact with and guide AI-powered\nmultimedia analytics systems, our conceptual framework sets a clear direction\nfor system design, comparison, and future research.",
      "tldr_zh": "该研究提出一个针对基础模型时代的多媒体分析模型，以应对现有框架在处理Foundation Models和agentic Artificial Intelligence带来的复杂性。该模型建立在视觉分析、多媒体分析、知识生成以及human-in-the-loop强化学习等框架基础上，强调人类-AI团队合作和mixed-initiative指导，确保专家用户与半自治分析过程的无缝互动。模型特别适用于敏感领域如情报分析和调查 journalism，通过详细案例研究展示了如何提升多媒体分析解决方案的理解和针对性改进，从而为系统设计、比较和未来研究提供清晰方向。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06138v2",
      "published_date": "2025-04-08 15:35:59 UTC",
      "updated_date": "2025-04-10 10:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:49:23.019059"
    },
    {
      "arxiv_id": "2504.13904v1",
      "title": "Generative Framework for Personalized Persuasion: Inferring Causal, Counterfactual, and Latent Knowledge",
      "title_zh": "个性化说服的生成框架：推断因果、反事实和潜在知识",
      "authors": [
        "Donghuo Zeng",
        "Roberto Legaspi",
        "Yuewen Sun",
        "Xinshuai Dong",
        "Kazushi Ikeda",
        "Peter Spirtes",
        "Kun Zhang"
      ],
      "abstract": "We hypothesize that optimal system responses emerge from adaptive strategies\ngrounded in causal and counterfactual knowledge. Counterfactual inference\nallows us to create hypothetical scenarios to examine the effects of\nalternative system responses. We enhance this process through causal discovery,\nwhich identifies the strategies informed by the underlying causal structure\nthat govern system behaviors. Moreover, we consider the psychological\nconstructs and unobservable noises that might be influencing user-system\ninteractions as latent factors. We show that these factors can be effectively\nestimated. We employ causal discovery to identify strategy-level causal\nrelationships among user and system utterances, guiding the generation of\npersonalized counterfactual dialogues. We model the user utterance strategies\nas causal factors, enabling system strategies to be treated as counterfactual\nactions. Furthermore, we optimize policies for selecting system responses based\non counterfactual data. Our results using a real-world dataset on social good\ndemonstrate significant improvements in persuasive system outcomes, with\nincreased cumulative rewards validating the efficacy of causal discovery in\nguiding personalized counterfactual inference and optimizing dialogue policies\nfor a persuasive dialogue system.",
      "tldr_zh": "该论文提出一个生成框架，用于个性化说服系统，通过推断因果（causal）、反事实（counterfactual）和潜在知识来优化系统响应策略。框架利用因果发现（causal discovery）识别用户和系统话语间的策略级因果关系，并通过反事实推理（counterfactual inference）生成假设对话场景，同时估计心理构建和潜在因素的影响。最终，优化后的对话政策在真实社交公益数据集上实现了显著改进，累积奖励大幅提升，证明了该方法在提升说服效果方面的效能。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "12 pages, 10 figures, 1 table. Accepted by ACM UMAP 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.13904v1",
      "published_date": "2025-04-08 15:33:54 UTC",
      "updated_date": "2025-04-08 15:33:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:49:35.252051"
    },
    {
      "arxiv_id": "2505.03747v1",
      "title": "The Evolution of Rough Sets 1970s-1981",
      "title_zh": "翻译失败",
      "authors": [
        "Viktor Marek",
        "Ewa Orłowska",
        "Ivo Düntsch"
      ],
      "abstract": "In this note research and publications by Zdzis{\\l}aw Pawlak and his\ncollaborators from 1970s and 1981 are recalled. Focus is placed on the sources\nof inspiration which one can identify on the basis of those publications.\nFinally, developments from 1981 related to rough sets and information systems\nare outlined.",
      "tldr_zh": "这篇论文回顾了Zdzisław Pawlak及其合作者在1970年代和1981年的粗糙集(Rough Sets)研究与出版物，重点分析了这些工作的灵感来源。作者通过回顾早期文献，揭示了粗糙集概念的演变基础。最终，论文概述了1981年与粗糙集和信息系统相关的关键进展，为理解这一领域的历史发展提供了重要参考。",
      "categories": [
        "math.HO",
        "cs.AI"
      ],
      "primary_category": "math.HO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03747v1",
      "published_date": "2025-04-08 15:33:51 UTC",
      "updated_date": "2025-04-08 15:33:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:49:46.324007"
    },
    {
      "arxiv_id": "2504.06136v1",
      "title": "QGen Studio: An Adaptive Question-Answer Generation, Training and Evaluation Platform",
      "title_zh": "翻译失败",
      "authors": [
        "Movina Moses",
        "Mohab Elkaref",
        "James Barry",
        "Shinnosuke Tanaka",
        "Vishnudev Kuruvanthodi",
        "Nathan Herr",
        "Campbell D Watson",
        "Geeth De Mel"
      ],
      "abstract": "We present QGen Studio: an adaptive question-answer generation, training, and\nevaluation platform. QGen Studio enables users to leverage large language\nmodels (LLMs) to create custom question-answer datasets and fine-tune models on\nthis synthetic data. It features a dataset viewer and model explorer to\nstreamline this process. The dataset viewer provides key metrics and visualizes\nthe context from which the QA pairs are generated, offering insights into data\nquality. The model explorer supports model comparison, allowing users to\ncontrast the performance of their trained LLMs against other models, supporting\nperformance benchmarking and refinement. QGen Studio delivers an interactive,\nend-to-end solution for generating QA datasets and training scalable,\ndomain-adaptable models. The studio will be open-sourced soon, allowing users\nto deploy it locally.",
      "tldr_zh": "该研究介绍了 QGen Studio，这是一个自适应的问答生成、训练和评估平台，利用 LLMs 来创建自定义 QA datasets 并在合成数据上微调模型。平台包括数据集查看器，提供关键指标和可视化以评估数据质量，以及模型探索器，支持模型比较和性能基准测试。QGen Studio 提供交互式端到端解决方案，帮助用户训练可扩展的、领域适配模型，并计划开源以便本地部署。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06136v1",
      "published_date": "2025-04-08 15:32:09 UTC",
      "updated_date": "2025-04-08 15:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:49:58.837361"
    },
    {
      "arxiv_id": "2504.06135v1",
      "title": "Decentralizing AI Memory: SHIMI, a Semantic Hierarchical Memory Index for Scalable Agent Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Tooraj Helmi"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) and vector-based search have become\nfoundational tools for memory in AI systems, yet they struggle with\nabstraction, scalability, and semantic precision - especially in decentralized\nenvironments. We present SHIMI (Semantic Hierarchical Memory Index), a unified\narchitecture that models knowledge as a dynamically structured hierarchy of\nconcepts, enabling agents to retrieve information based on meaning rather than\nsurface similarity. SHIMI organizes memory into layered semantic nodes and\nsupports top-down traversal from abstract intent to specific entities, offering\nmore precise and explainable retrieval. Critically, SHIMI is natively designed\nfor decentralized ecosystems, where agents maintain local memory trees and\nsynchronize them asynchronously across networks. We introduce a lightweight\nsync protocol that leverages Merkle-DAG summaries, Bloom filters, and\nCRDT-style conflict resolution to enable partial synchronization with minimal\noverhead. Through benchmark experiments and use cases involving decentralized\nagent collaboration, we demonstrate SHIMI's advantages in retrieval accuracy,\nsemantic fidelity, and scalability - positioning it as a core infrastructure\nlayer for decentralized cognitive systems.",
      "tldr_zh": "该研究针对 Retrieval-Augmented Generation (RAG) 和向量搜索在抽象性、可扩展性和语义精度上的局限性，特别是在去中心化环境中，提出了 SHIMI（Semantic Hierarchical Memory Index），一种将知识建模为动态层次化概念结构的统一架构。\nSHIMI 通过分层语义节点和自上而下的遍历机制，实现基于意义的检索，提供更精确和可解释的结果，同时支持代理在本地维护内存树并使用轻量级同步协议（如 Merkle-DAG 摘要、Bloom filters 和 CRDT 风格冲突解决）进行异步网络同步。\n实验和用例证明，SHIMI 在检索准确性、语义保真度和可扩展性方面显著优于基线模型，有望作为去中心化认知系统的核心基础设施。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06135v1",
      "published_date": "2025-04-08 15:31:00 UTC",
      "updated_date": "2025-04-08 15:31:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:50:12.540062"
    },
    {
      "arxiv_id": "2504.06122v2",
      "title": "Leanabell-Prover: Posttraining Scaling in Formal Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyuan Zhang",
        "Qi Wang",
        "Xingguang Ji",
        "Yahui Liu",
        "Yang Yue",
        "Fuzheng Zhang",
        "Di Zhang",
        "Guorui Zhou",
        "Kun Gai"
      ],
      "abstract": "Recent advances in automated theorem proving (ATP) through LLMs have\nhighlighted the potential of formal reasoning with Lean 4 codes. However, ATP\nhas not yet be revolutionized by the recent posttraining scaling as\ndemonstrated by Open AI O1/O3 and Deepseek R1. In this work, we investigate the\nentire posttraining of ATP, aiming to align it with breakthroughs in reasoning\nmodels in natural languages. To begin, we continual train current ATP models\nwith a hybrid dataset, which consists of numerous statement-proof pairs, and\nadditional data aimed at incorporating cognitive behaviors that emulate human\nreasoning and hypothesis refinement. Next, we explore reinforcement learning\nwith the use of outcome reward returned by Lean 4 compiler. Through our\ndesigned continual training and reinforcement learning processes, we have\nsuccessfully improved existing formal provers, including both\nDeepSeek-Prover-v1.5 and Goedel-Prover, achieving state-of-the-art performance\nin the field of whole-proof generation. For example, we achieve a 59.8% pass\nrate (pass@32) on MiniF2F. This is an on-going project and we will\nprogressively update our findings, release our data and training details.",
      "tldr_zh": "该研究探讨了自动定理证明 (ATP) 的后训练扩展，旨在通过借鉴自然语言推理模型（如 OpenAI O1/O3）的突破来提升基于 Lean 4 代码的形式推理性能。主要方法包括使用混合数据集进行持续训练 (continual training)，结合模拟人类推理的认知行为数据，以及采用 Lean 4 编译器返回的奖励进行强化学习 (reinforcement learning)，从而改进了现有证明器如 DeepSeek-Prover-v1.5 和 Goedel-Prover。在 MiniF2F 测试中，该框架实现了 59.8% 的 pass@32 率，达到了该领域的状态-of-the-art 性能，并计划持续更新数据和训练细节。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.06122v2",
      "published_date": "2025-04-08 15:15:26 UTC",
      "updated_date": "2025-04-09 04:03:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:50:24.228693"
    },
    {
      "arxiv_id": "2504.06105v1",
      "title": "Uncertainty-Aware Hybrid Machine Learning in Virtual Sensors for Vehicle Sideslip Angle Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Abinav Kalyanasundaram",
        "Karthikeyan Chandra Sekaran",
        "Philipp Stauber",
        "Michael Lange",
        "Wolfgang Utschick",
        "Michael Botsch"
      ],
      "abstract": "Precise vehicle state estimation is crucial for safe and reliable autonomous\ndriving. The number of measurable states and their precision offered by the\nonboard vehicle sensor system are often constrained by cost. For instance,\nmeasuring critical quantities such as the Vehicle Sideslip Angle (VSA) poses\nsignificant commercial challenges using current optical sensors. This paper\naddresses these limitations by focusing on the development of high-performance\nvirtual sensors to enhance vehicle state estimation for active safety. The\nproposed Uncertainty-Aware Hybrid Learning (UAHL) architecture integrates a\nmachine learning model with vehicle motion models to estimate VSA directly from\nonboard sensor data. A key aspect of the UAHL architecture is its focus on\nuncertainty quantification for individual model estimates and hybrid fusion.\nThese mechanisms enable the dynamic weighting of uncertainty-aware predictions\nfrom machine learning and vehicle motion models to produce accurate and\nreliable hybrid VSA estimates. This work also presents a novel dataset named\nReal-world Vehicle State Estimation Dataset (ReV-StED), comprising synchronized\nmeasurements from advanced vehicle dynamic sensors. The experimental results\ndemonstrate the superior performance of the proposed method for VSA estimation,\nhighlighting UAHL as a promising architecture for advancing virtual sensors and\nenhancing active safety in autonomous vehicles.",
      "tldr_zh": "本研究针对自主驾驶中车辆状态估计的挑战，提出Uncertainty-Aware Hybrid Learning (UAHL)架构，用于从车载传感器数据估计Vehicle Sideslip Angle (VSA)，以克服成本限制下光学传感器测量困难的问题。UAHL将机器学习模型与车辆运动模型整合，并通过不确定性量化机制动态加权预测，实现准确可靠的混合VSA估计。该方法还引入了新数据集Real-world Vehicle State Estimation Dataset (ReV-StED)，包含同步的高级车辆动态传感器测量。实验结果显示，UAHL在VSA估计方面显著优于基线模型，提升了虚拟传感器的性能，并为增强自主车辆的主动安全提供了有前景的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at the 2025 IEEE Intelligent Vehicles Symposium (IV)",
      "pdf_url": "http://arxiv.org/pdf/2504.06105v1",
      "published_date": "2025-04-08 14:49:58 UTC",
      "updated_date": "2025-04-08 14:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:50:35.563323"
    },
    {
      "arxiv_id": "2504.06099v1",
      "title": "Towards Varroa destructor mite detection using a narrow spectra illumination",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Bielik",
        "Simon Bilik"
      ],
      "abstract": "This paper focuses on the development and modification of a beehive\nmonitoring device and Varroa destructor detection on the bees with the help of\nhyperspectral imagery while utilizing a U-net, semantic segmentation\narchitecture, and conventional computer vision methods. The main objectives\nwere to collect a dataset of bees and mites, and propose the computer vision\nmodel which can achieve the detection between bees and mites.",
      "tldr_zh": "这篇论文旨在开发一种基于窄谱照明的蜂箱监测设备，用于检测蜜蜂上的Varroa destructor螨虫。研究团队利用高光谱图像（hyperspectral imagery）、U-net语义分割架构（semantic segmentation architecture）以及传统的计算机视觉方法，收集了蜜蜂和螨虫的数据集。最终，他们提出了一种计算机视觉模型，能够有效区分蜜蜂和螨虫，从而提升害虫检测的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06099v1",
      "published_date": "2025-04-08 14:41:42 UTC",
      "updated_date": "2025-04-08 14:41:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:50:47.478232"
    },
    {
      "arxiv_id": "2504.06091v1",
      "title": "Real-Time LaCAM",
      "title_zh": "实时 LaCAM",
      "authors": [
        "Runzhe Liang",
        "Rishi Veerapaneni",
        "Daniel Harabor",
        "Jiaoyang Li",
        "Maxim Likhachev"
      ],
      "abstract": "The vast majority of Multi-Agent Path Finding (MAPF) methods with\ncompleteness guarantees require planning full horizon paths. However, planning\nfull horizon paths can take too long and be impractical in real-world\napplications. Instead, real-time planning and execution, which only allows the\nplanner a finite amount of time before executing and replanning, is more\npractical for real world multi-agent systems. Several methods utilize real-time\nplanning schemes but none are provably complete, which leads to livelock or\ndeadlock. Our main contribution is to show the first Real-Time MAPF method with\nprovable completeness guarantees. We do this by leveraging LaCAM (Okumura 2023)\nin an incremental fashion. Our results show how we can iteratively plan for\ncongested environments with a cutoff time of milliseconds while still\nmaintaining the same success rate as full horizon LaCAM. We also show how it\ncan be used with a single-step learned MAPF policy. The proposed Real-Time\nLaCAM also provides us with a general mechanism for using iterative constraints\nfor completeness in future real-time MAPF algorithms.",
      "tldr_zh": "这篇论文解决了 Multi-Agent Path Finding (MAPF) 的关键挑战，即现有方法需规划全时域路径，导致计算耗时过长，且实时规划方案缺乏完整性保证，可能引发 livelock 或 deadlock。作者提出 Real-Time LaCAM，这是一种基于 LaCAM (Okumura 2023) 的增量方法，能够在毫秒级截止时间内迭代规划路径，同时保持与全时域 LaCAM 相同的成功率。实验结果显示，在拥挤环境中，该方法成功率显著提升，并可与单步学习 MAPF 策略结合使用。该框架还为未来实时 MAPF 算法提供通用迭代约束机制，以确保完整性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06091v1",
      "published_date": "2025-04-08 14:31:05 UTC",
      "updated_date": "2025-04-08 14:31:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:51:00.585402"
    },
    {
      "arxiv_id": "2504.06088v1",
      "title": "MCAT: Visual Query-Based Localization of Standard Anatomical Clips in Fetal Ultrasound Videos Using Multi-Tier Class-Aware Token Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Divyanshu Mishra",
        "Pramit Saha",
        "He Zhao",
        "Netzahualcoyotl Hernandez-Cruz",
        "Olga Patey",
        "Aris Papageorghiou",
        "J. Alison Noble"
      ],
      "abstract": "Accurate standard plane acquisition in fetal ultrasound (US) videos is\ncrucial for fetal growth assessment, anomaly detection, and adherence to\nclinical guidelines. However, manually selecting standard frames is\ntime-consuming and prone to intra- and inter-sonographer variability. Existing\nmethods primarily rely on image-based approaches that capture standard frames\nand then classify the input frames across different anatomies. This ignores the\ndynamic nature of video acquisition and its interpretation. To address these\nchallenges, we introduce Multi-Tier Class-Aware Token Transformer (MCAT), a\nvisual query-based video clip localization (VQ-VCL) method, to assist\nsonographers by enabling them to capture a quick US sweep. By then providing a\nvisual query of the anatomy they wish to analyze, MCAT returns the video clip\ncontaining the standard frames for that anatomy, facilitating thorough\nscreening for potential anomalies. We evaluate MCAT on two ultrasound video\ndatasets and a natural image VQ-VCL dataset based on Ego4D. Our model\noutperforms state-of-the-art methods by 10% and 13% mIoU on the ultrasound\ndatasets and by 5.35% mIoU on the Ego4D dataset, using 96% fewer tokens. MCAT's\nefficiency and accuracy have significant potential implications for public\nhealth, especially in low- and middle-income countries (LMICs), where it may\nenhance prenatal care by streamlining standard plane acquisition, simplifying\nUS-based screening, diagnosis and allowing sonographers to examine more\npatients.",
      "tldr_zh": "该研究针对胎儿超声视频中标准平面的手动获取问题，提出了一种基于视觉查询的视频剪辑定位方法（VQ-VCL），即 Multi-Tier Class-Aware Token Transformer (MCAT)，以帮助超声医师通过视觉查询快速定位并返回包含标准解剖帧的视频剪辑。MCAT 通过多层级类别感知 token 转换器处理视频的动态特性，显著提高了任务效率。实验结果显示，该模型在两个超声视频数据集上比现有方法提升 10% 和 13% mIoU，在 Ego4D 数据集上提升 5.35% mIoU，同时仅使用 96% 的 tokens。MCAT 的应用有望简化产前筛查和诊断，尤其在低中收入国家 (LMICs) 提升公共卫生水平和医疗可及性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.06088v1",
      "published_date": "2025-04-08 14:29:15 UTC",
      "updated_date": "2025-04-08 14:29:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:51:12.884139"
    },
    {
      "arxiv_id": "2504.08798v1",
      "title": "Exploring Gradient-Guided Masked Language Model to Detect Textual Adversarial Attacks",
      "title_zh": "探索梯度引导的掩码语言模型以检测文本对抗攻击",
      "authors": [
        "Xiaomei Zhang",
        "Zhaoxi Zhang",
        "Yanjun Zhang",
        "Xufei Zheng",
        "Leo Yu Zhang",
        "Shengshan Hu",
        "Shirui Pan"
      ],
      "abstract": "Textual adversarial examples pose serious threats to the reliability of\nnatural language processing systems. Recent studies suggest that adversarial\nexamples tend to deviate from the underlying manifold of normal texts, whereas\npre-trained masked language models can approximate the manifold of normal data.\nThese findings inspire the exploration of masked language models for detecting\ntextual adversarial attacks. We first introduce Masked Language Model-based\nDetection (MLMD), leveraging the mask and unmask operations of the masked\nlanguage modeling (MLM) objective to induce the difference in manifold changes\nbetween normal and adversarial texts. Although MLMD achieves competitive\ndetection performance, its exhaustive one-by-one masking strategy introduces\nsignificant computational overhead. Our posterior analysis reveals that a\nsignificant number of non-keywords in the input are not important for detection\nbut consume resources. Building on this, we introduce Gradient-guided MLMD\n(GradMLMD), which leverages gradient information to identify and skip\nnon-keywords during detection, significantly reducing resource consumption\nwithout compromising detection performance.",
      "tldr_zh": "本研究探讨了使用masked language model检测textual adversarial attacks，以应对自然语言处理系统的可靠性威胁。作者首先提出Masked Language Model-based Detection (MLMD)方法，通过masked language modeling (MLM)的mask和unmask操作，捕捉正常文本与对抗文本的流形差异，实现竞争性的检测性能，但该方法因逐个masking而导致计算开销过大。针对此问题，他们开发了Gradient-guided MLMD (GradMLMD)，利用梯度信息识别并跳过非关键词，从而显著减少资源消耗，同时保持检测效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.08798v1",
      "published_date": "2025-04-08 14:10:57 UTC",
      "updated_date": "2025-04-08 14:10:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:51:23.707968"
    },
    {
      "arxiv_id": "2504.06330v1",
      "title": "Analyzing the Impact of Low-Rank Adaptation for Cross-Domain Few-Shot Object Detection in Aerial Images",
      "title_zh": "翻译失败",
      "authors": [
        "Hicham Talaoubrid",
        "Anissa Mokraoui",
        "Ismail Ben Ayed",
        "Axel Prouvost",
        "Sonimith Hang",
        "Monit Korn",
        "Rémi Harvey"
      ],
      "abstract": "This paper investigates the application of Low-Rank Adaptation (LoRA) to\nsmall models for cross-domain few-shot object detection in aerial images.\nOriginally designed for large-scale models, LoRA helps mitigate overfitting,\nmaking it a promising approach for resource-constrained settings. We integrate\nLoRA into DiffusionDet, and evaluate its performance on the DOTA and DIOR\ndatasets. Our results show that LoRA applied after an initial fine-tuning\nslightly improves performance in low-shot settings (e.g., 1-shot and 5-shot),\nwhile full fine-tuning remains more effective in higher-shot configurations.\nThese findings highlight LoRA's potential for efficient adaptation in aerial\nobject detection, encouraging further research into parameter-efficient\nfine-tuning strategies for few-shot learning. Our code is available here:\nhttps://github.com/HichTala/LoRA-DiffusionDet.",
      "tldr_zh": "本论文探讨了 Low-Rank Adaptation (LoRA) 在小模型中的应用，以提升航空图像的跨域少样本物体检测性能。研究者将 LoRA 整合到 DiffusionDet 模型中，并在 DOTA 和 DIOR 数据集上进行评估，结果显示 LoRA 在初始微调后，能在低样本设置（如 1-shot 和 5-shot）中略微改善检测性能，而在高样本设置中，全微调方法更具优势。这些发现突出了 LoRA 在参数高效微调策略方面的潜力，并鼓励进一步探索少样本学习在航空物体检测中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06330v1",
      "published_date": "2025-04-08 14:10:39 UTC",
      "updated_date": "2025-04-08 14:10:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:51:35.505342"
    },
    {
      "arxiv_id": "2504.06037v2",
      "title": "Confidence Regularized Masked Language Modeling using Text Length",
      "title_zh": "基于文本长度的置信",
      "authors": [
        "Seunghyun Ji",
        "Soowon Lee"
      ],
      "abstract": "Masked language modeling is a widely used method for learning language\nrepresentations, where the model predicts a randomly masked word in each input.\nHowever, this approach typically considers only a single correct answer during\ntraining, ignoring the variety of plausible alternatives that humans might\nchoose. This issue becomes more pronounced when the input text is short, as the\npossible word distribution tends to have higher entropy, potentially causing\nthe model to become overconfident in its predictions. To mitigate this, we\npropose a novel confidence regularizer that adaptively adjusts the\nregularization strength based on the input length. Experiments on the GLUE and\nSQuAD benchmarks show that our method improves both accuracy and expected\ncalibration error",
      "tldr_zh": "本论文针对Masked Language Modeling (MLM) 的问题提出了一种置信度正则化方法，因为传统MLM仅考虑单一正确答案，而忽略了短文本中可能的多种备选答案，导致模型过度自信。该方法根据输入文本长度自适应调整正则化强度，以降低预测的不确定性。在GLUE和SQuAD基准测试中，实验结果显示该方法显著提高了模型的准确性和预期校准错误（expected calibration error）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.06037v2",
      "published_date": "2025-04-08 13:37:08 UTC",
      "updated_date": "2025-04-09 02:32:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:51:46.777363"
    },
    {
      "arxiv_id": "2504.06020v1",
      "title": "Information-Theoretic Reward Decomposition for Generalizable RLHF",
      "title_zh": "基于信息论的奖励分解用于可泛化的 RLHF",
      "authors": [
        "Liyuan Mao",
        "Haoran Xu",
        "Amy Zhang",
        "Weinan Zhang",
        "Chenjia Bai"
      ],
      "abstract": "A generalizable reward model is crucial in Reinforcement Learning from Human\nFeedback (RLHF) as it enables correctly evaluating unseen prompt-response\npairs. However, existing reward models lack this ability, as they are typically\ntrained by increasing the reward gap between chosen and rejected responses,\nwhile overlooking the prompts that the responses are conditioned on.\nConsequently, when the trained reward model is evaluated on prompt-response\npairs that lie outside the data distribution, neglecting the effect of prompts\nmay result in poor generalization of the reward model. To address this issue,\nwe decompose the reward value into two independent components: prompt-free\nreward and prompt-related reward. Prompt-free reward represents the evaluation\nthat is determined only by responses, while the prompt-related reward reflects\nthe reward that derives from both the prompt and the response. We extract these\ntwo components from an information-theoretic perspective, which requires no\nextra models. Subsequently, we propose a new reward learning algorithm by\nprioritizing data samples based on their prompt-free reward values. Through toy\nexamples, we demonstrate that the extracted prompt-free and prompt-related\nrewards effectively characterize two parts of the reward model. Further,\nstandard evaluations show that our method improves both the alignment\nperformance and the generalization capability of the reward model.",
      "tldr_zh": "该论文针对强化学习从人类反馈（RLHF）中的奖励模型泛化问题，提出了一种信息论视角的奖励分解方法，将奖励值分解为两个独立组件：prompt-free reward（仅由响应决定）和 prompt-related reward（由提示和响应共同决定）。\n该方法通过信息论提取这些组件，无需额外模型，并设计了一个新的奖励学习算法，优先基于 prompt-free reward 值处理数据样本。\n实验结果表明，该方法在玩具例子中有效区分了奖励组件，并在标准评估中提升了奖励模型的性能和泛化能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Work done during internships at Institute of Artificial Intelligence\n  (TeleAI), China Telecom",
      "pdf_url": "http://arxiv.org/pdf/2504.06020v1",
      "published_date": "2025-04-08 13:26:07 UTC",
      "updated_date": "2025-04-08 13:26:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:51:58.578838"
    },
    {
      "arxiv_id": "2504.06328v1",
      "title": "A Geometric-Aware Perspective and Beyond: Hybrid Quantum-Classical Machine Learning Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Azadeh Alavia",
        "Hossein Akhoundib",
        "Fatemeh Kouchmeshkib",
        "Mojtaba Mahmoodianc",
        "Sanduni Jayasinghec",
        "Yongli Rena",
        "Abdolrahman Alavi"
      ],
      "abstract": "Geometric Machine Learning (GML) has shown that respecting non-Euclidean\ngeometry in data spaces can significantly improve performance over naive\nEuclidean assumptions. In parallel, Quantum Machine Learning (QML) has emerged\nas a promising paradigm that leverages superposition, entanglement, and\ninterference within quantum state manifolds for learning tasks. This paper\noffers a unifying perspective by casting QML as a specialized yet more\nexpressive branch of GML. We argue that quantum states, whether pure or mixed,\nreside on curved manifolds (e.g., projective Hilbert spaces or density-operator\nmanifolds), mirroring how covariance matrices inhabit the manifold of symmetric\npositive definite (SPD) matrices or how image sets occupy Grassmann manifolds.\nHowever, QML also benefits from purely quantum properties, such as\nentanglement-induced curvature, that can yield richer kernel structures and\nmore nuanced data embeddings.\n  We illustrate these ideas with published and newly discussed results,\nincluding hybrid classical -quantum pipelines for diabetic foot ulcer\nclassification and structural health monitoring. Despite near-term hardware\nlimitations that constrain purely quantum solutions, hybrid architectures\nalready demonstrate tangible benefits by combining classical manifold-based\nfeature extraction with quantum embeddings. We present a detailed mathematical\ntreatment of the geometrical underpinnings of quantum states, emphasizing\nparallels to classical Riemannian geometry and manifold-based optimization.\nFinally, we outline open research challenges and future directions, including\nQuantum Large Language Models (LLMs), quantum reinforcement learning, and\nemerging hardware approaches, demonstrating how synergizing GML and QML\nprinciples can unlock the next generation of machine intelligence.",
      "tldr_zh": "本论文将Quantum Machine Learning (QML)视为Geometric Machine Learning (GML)的更具表现力的分支，强调量子态位于弯曲流形（如投影希尔伯特空间）上，与经典Riemannian geometry类似，从而提升机器学习性能。作者通过混合量子-经典管道，结合量子特性如纠缠诱导的曲率，实现了更丰富的内核结构和数据嵌入，并在糖尿病足部溃疡分类及结构健康监测等应用中展示了实际益处。实验结果表明，尽管量子硬件受限，混合架构已比纯经典方法表现出显著优势；论文还概述了未来挑战，包括Quantum LLMs和量子强化学习，以推动机器智能的下一代发展。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "19 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.06328v1",
      "published_date": "2025-04-08 13:24:55 UTC",
      "updated_date": "2025-04-08 13:24:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:52:11.350270"
    },
    {
      "arxiv_id": "2504.06016v1",
      "title": "The Hall of AI Fears and Hopes: Comparing the Views of AI Influencers and those of Members of the U.S. Public Through an Interactive Platform",
      "title_zh": "翻译失败",
      "authors": [
        "Gustavo Moreira",
        "Edyta Paulina Bogucka",
        "Marios Constantinides",
        "Daniele Quercia"
      ],
      "abstract": "AI development is shaped by academics and industry leaders - let us call them\n``influencers'' - but it is unclear how their views align with those of the\npublic. To address this gap, we developed an interactive platform that served\nas a data collection tool for exploring public views on AI, including their\nfears, hopes, and overall sense of hopefulness. We made the platform available\nto 330 participants representative of the U.S. population in terms of age, sex,\nethnicity, and political leaning, and compared their views with those of 100 AI\ninfluencers identified by Time magazine. The public fears AI getting out of\ncontrol, while influencers emphasize regulation, seemingly to deflect attention\nfrom their alleged focus on monetizing AI's potential. Interestingly, the views\nof AI influencers from underrepresented groups such as women and people of\ncolor often differ from the views of underrepresented groups in the public.",
      "tldr_zh": "该研究开发了一个交互平台，以比较AI influencers（包括学术和行业领袖）和美国公众对AI的恐惧、希望及整体乐观感的观点。平台收集了330名代表美国人口（在年龄、性别、种族和政治倾向上）的参与者数据，并与100名由Time杂志识别的AI influencers的观点进行对比。结果显示，公众更担心AI失控，而influencers强调监管，可能是为了转移对他们商业化AI潜力的关注；此外，来自underrepresented groups（如女性和有色人种）的AI influencers观点往往与公众中这些群体的看法不同。该平台为理解AI发展中的公众参与提供了新工具。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2; K.4.1; K.4.2; K.4.3"
      ],
      "primary_category": "cs.HC",
      "comment": "27 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.06016v1",
      "published_date": "2025-04-08 13:21:31 UTC",
      "updated_date": "2025-04-08 13:21:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:52:23.180991"
    },
    {
      "arxiv_id": "2504.06006v2",
      "title": "Optuna vs Code Llama: Are LLMs a New Paradigm for Hyperparameter Tuning?",
      "title_zh": "Optuna 与 Code Llama：LLMs",
      "authors": [
        "Roman Kochnev",
        "Arash Torabi Goodarzi",
        "Zofia Antonina Bentyn",
        "Dmitry Ignatov",
        "Radu Timofte"
      ],
      "abstract": "Optimal hyperparameter selection is critical for maximizing neural network\nperformance, especially as models grow in complexity. This work investigates\nthe viability of leveraging large language models (LLMs) for hyperparameter\noptimization by fine-tuning a parameter-efficient version of Code Llama using\nLoRA. The adapted LLM is capable of generating accurate and efficient\nhyperparameter recommendations tailored to diverse neural network\narchitectures. Unlike traditional approaches such as Optuna, which rely on\ncomputationally intensive trial-and-error procedures, our method achieves\ncompetitive or superior results in terms of Root Mean Square Error (RMSE) while\nsignificantly reducing computational overhead. Our findings demonstrate that\nLLM-based optimization not only matches the performance of state-of-the-art\ntechniques like Tree-structured Parzen Estimators (TPE) but also substantially\naccelerates the tuning process. This positions LLMs as a promising alternative\nfor rapid experimentation, particularly in resource-constrained environments\nsuch as edge devices and mobile platforms, where computational efficiency is\nessential. In addition to improved efficiency, the method offers time savings\nand consistent performance across various tasks, highlighting its robustness\nand generalizability. All generated hyperparameters are included in the LEMUR\nNeural Network (NN) Dataset, which is publicly available and serves as an\nopen-source benchmark for hyperparameter optimization research.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)是否能取代传统方法（如Optuna）成为超参数优化的新范式，通过微调Code Llama的LoRA版本生成针对不同神经网络架构的准确超参数推荐。与Optuna等依赖试错的计算密集型方法相比，该方法在Root Mean Square Error (RMSE)上实现竞争或优越性能，同时大幅降低计算开销。实验结果显示，LLM-based优化不仅匹配Tree-structured Parzen Estimators (TPE)的表现，还加速了调优过程，适用于资源受限环境，并通过公开LEMUR Neural Network (NN)数据集增强了研究的可复现性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06006v2",
      "published_date": "2025-04-08 13:15:47 UTC",
      "updated_date": "2025-04-11 20:43:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:52:35.502454"
    },
    {
      "arxiv_id": "2504.05995v1",
      "title": "NativQA Framework: Enabling LLMs with Native, Local, and Everyday Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Firoj Alam",
        "Md Arid Hasan",
        "Sahinur Rahman Laskar",
        "Mucahid Kutlu",
        "Shammur Absar Chowdhury"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has raised concerns\nabout cultural bias, fairness, and their applicability in diverse linguistic\nand underrepresented regional contexts. To enhance and benchmark the\ncapabilities of LLMs, there is a need to develop large-scale resources focused\non multilingual, local, and cultural contexts. In this study, we propose a\nframework, NativQA, that can seamlessly construct large-scale, culturally and\nregionally aligned QA datasets in native languages. The framework utilizes\nuser-defined seed queries and leverages search engines to collect\nlocation-specific, everyday information. It has been evaluated across 39\nlocations in 24 countries and in 7 languages, ranging from extremely\nlow-resource to high-resource languages, which resulted over 300K Question\nAnswer (QA) pairs. The developed resources can be used for LLM benchmarking and\nfurther fine-tuning. The framework has been made publicly available for the\ncommunity (https://gitlab.com/nativqa/nativqa-framework).",
      "tldr_zh": "该研究针对大型语言模型(LLMs)的文化偏见和多语言适用性问题，提出了NativQA框架，用于构建大规模、多语言的问答(QA)数据集，以增强LLMs在本地和文化语境中的能力。框架通过用户定义的种子查询和搜索引擎，收集位置特定的日常信息，并在7种语言和39个位置（覆盖24个国家）上生成超过30万QA对。实验结果显示，该框架适用于从极低资源到高资源语言的场景，并可用于LLMs的基准测试和微调，框架已公开提供（https://gitlab.com/nativqa/nativqa-framework）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "LLMs, Native, Multilingual, Language Diversity, Contextual\n  Understanding, Minority Languages, Culturally Informed, Foundation Models,\n  Large Language Models",
      "pdf_url": "http://arxiv.org/pdf/2504.05995v1",
      "published_date": "2025-04-08 13:01:51 UTC",
      "updated_date": "2025-04-08 13:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:52:46.591342"
    },
    {
      "arxiv_id": "2504.05956v1",
      "title": "Temporal Alignment-Free Video Matching for Few-shot Action Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "SuBeen Lee",
        "WonJun Moon",
        "Hyun Seok Seong",
        "Jae-Pil Heo"
      ],
      "abstract": "Few-Shot Action Recognition (FSAR) aims to train a model with only a few\nlabeled video instances. A key challenge in FSAR is handling divergent\nnarrative trajectories for precise video matching. While the frame- and\ntuple-level alignment approaches have been promising, their methods heavily\nrely on pre-defined and length-dependent alignment units (e.g., frames or\ntuples), which limits flexibility for actions of varying lengths and speeds. In\nthis work, we introduce a novel TEmporal Alignment-free Matching (TEAM)\napproach, which eliminates the need for temporal units in action representation\nand brute-force alignment during matching. Specifically, TEAM represents each\nvideo with a fixed set of pattern tokens that capture globally discriminative\nclues within the video instance regardless of action length or speed, ensuring\nits flexibility. Furthermore, TEAM is inherently efficient, using token-wise\ncomparisons to measure similarity between videos, unlike existing methods that\nrely on pairwise comparisons for temporal alignment. Additionally, we propose\nan adaptation process that identifies and removes common information across\nclasses, establishing clear boundaries even between novel categories. Extensive\nexperiments demonstrate the effectiveness of TEAM. Codes are available at\ngithub.com/leesb7426/TEAM.",
      "tldr_zh": "本研究针对 Few-Shot Action Recognition (FSAR) 的关键挑战——处理视频叙事轨迹差异并进行精确匹配，提出了一种新型 TEmporal Alignment-free Matching (TEAM) 方法。TEAM 通过使用固定的一组 pattern tokens 来表示视频，这些标记捕捉视频中的全局鉴别线索，而不受动作长度或速度的影响，从而避免了传统帧级或元组级对齐的局限性。该方法采用 token-wise 比较来高效测量视频相似性，并引入一个适应过程来识别并移除类间共同信息，以建立新类别间的清晰边界。实验结果显示，TEAM 在广泛测试中表现出色，有效提升了 FSAR 的性能，并已在 GitHub 上开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures, 6 tables, Accepted to CVPR 2025 as Oral\n  Presentation",
      "pdf_url": "http://arxiv.org/pdf/2504.05956v1",
      "published_date": "2025-04-08 12:11:11 UTC",
      "updated_date": "2025-04-08 12:11:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:52:59.657312"
    },
    {
      "arxiv_id": "2504.05951v1",
      "title": "Representing Normative Regulations in OWL DL for Automated Compliance Checking Supported by Text Annotation",
      "title_zh": "翻译失败",
      "authors": [
        "Ildar Baimuratov",
        "Denis Turygin"
      ],
      "abstract": "Compliance checking is the process of determining whether a regulated entity\nadheres to these regulations. Currently, compliance checking is predominantly\nmanual, requiring significant time and highly skilled experts, while still\nbeing prone to errors caused by the human factor. Various approaches have been\nexplored to automate compliance checking, however, representing regulations in\nOWL DL language which enables compliance checking through OWL reasoning has not\nbeen adopted. In this work, we propose an annotation schema and an algorithm\nthat transforms text annotations into machine-interpretable OWL DL code. The\nproposed approach is validated through a proof-of-concept implementation\napplied to examples from the building construction domain.",
      "tldr_zh": "本文研究了合规性检查（compliance checking）的自动化问题，指出当前方法主要依赖手动操作，耗时且易出错。作者提出一种使用 OWL DL 语言表示规范性法规的框架，并设计了文本注释模式和算法，将文本注释转化为机器可解释的 OWL DL 代码。该方法通过 OWL 推理支持自动化合规性检查，并在建筑施工领域的概念验证实施中得到验证，展示了其潜在的效率和准确性提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05951v1",
      "published_date": "2025-04-08 12:05:21 UTC",
      "updated_date": "2025-04-08 12:05:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:53:10.951131"
    },
    {
      "arxiv_id": "2504.05950v1",
      "title": "AEGIS: Human Attention-based Explainable Guidance for Intelligent Vehicle Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoli Zhuang",
        "Cheng-You Lu",
        "Yu-Cheng Fred Chang",
        "Yu-Kai Wang",
        "Thomas Do",
        "Chin-Teng Lin"
      ],
      "abstract": "Improving decision-making capabilities in Autonomous Intelligent Vehicles\n(AIVs) has been a heated topic in recent years. Despite advancements, training\nmachines to capture regions of interest for comprehensive scene understanding,\nlike human perception and reasoning, remains a significant challenge. This\nstudy introduces a novel framework, Human Attention-based Explainable Guidance\nfor Intelligent Vehicle Systems (AEGIS). AEGIS utilizes human attention,\nconverted from eye-tracking, to guide reinforcement learning (RL) models to\nidentify critical regions of interest for decision-making. AEGIS uses a\npre-trained human attention model to guide RL models to identify critical\nregions of interest for decision-making. By collecting 1.2 million frames from\n20 participants across six scenarios, AEGIS pre-trains a model to predict human\nattention patterns.",
      "tldr_zh": "本研究提出 AEGIS 框架，用于提升 Autonomous Intelligent Vehicles (AIVs) 的决策能力，通过人类注意力（从眼动追踪转换而来）来指导 reinforcement learning (RL) 模型识别关键兴趣区域。AEGIS 利用预训练模型预测人类注意力模式，以解决机器在场景理解方面的挑战。研究基于从20名参与者收集的1.2百万帧数据，涵盖六种场景，旨在实现更具解释性和可信度的车辆系统决策。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05950v1",
      "published_date": "2025-04-08 12:04:52 UTC",
      "updated_date": "2025-04-08 12:04:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:53:23.040454"
    },
    {
      "arxiv_id": "2504.06325v1",
      "title": "MM-STFlowNet: A Transportation Hub-Oriented Multi-Mode Passenger Flow Prediction Method via Spatial-Temporal Dynamic Graph Modeling",
      "title_zh": "MM-STFlowNet：一种面向交通枢纽的多模式旅客流量预测方法，通过空间-时间动态图建模",
      "authors": [
        "Ronghui Zhang",
        "Wenbin Xing",
        "Mengran Li",
        "Zihan Wang",
        "Junzhou Chen",
        "Xiaolei Ma",
        "Zhiyuan Liu",
        "Zhengbing He"
      ],
      "abstract": "Accurate and refined passenger flow prediction is essential for optimizing\nthe collaborative management of multiple collection and distribution modes in\nlarge-scale transportation hubs. Traditional methods often focus only on the\noverall passenger volume, neglecting the interdependence between different\nmodes within the hub. To address this limitation, we propose MM-STFlowNet, a\ncomprehensive multi-mode prediction framework grounded in dynamic\nspatial-temporal graph modeling. Initially, an integrated temporal feature\nprocessing strategy is implemented using signal decomposition and convolution\ntechniques to address data spikes and high volatility. Subsequently, we\nintroduce the Spatial-Temporal Dynamic Graph Convolutional Recurrent Network\n(STDGCRN) to capture detailed spatial-temporal dependencies across multiple\ntraffic modes, enhanced by an adaptive channel attention mechanism. Finally,\nthe self-attention mechanism is applied to incorporate various external\nfactors, further enhancing prediction accuracy. Experiments on a real-world\ndataset from Guangzhounan Railway Station in China demonstrate that\nMM-STFlowNet achieves state-of-the-art performance, particularly during peak\nperiods, providing valuable insight for transportation hub management.",
      "tldr_zh": "该研究提出 MM-STFlowNet，一种面向交通枢纽的多模式客流预测方法，通过动态时空图建模解决传统方法忽略不同交通模式间相互依赖的问题。\n该框架首先使用信号分解和卷积技术处理时间特征，以应对数据尖峰和高波动性；随后引入 Spatial-Temporal Dynamic Graph Convolutional Recurrent Network (STDGCRN) 和自适应通道注意力机制，捕捉多模式间的详细时空依赖，并通过自注意力机制整合外部因素，提升预测准确性。\n实验在广州南站的真实数据集上表明，MM-STFlowNet 尤其在高峰期表现出色，达到最先进水平，为交通枢纽的协同管理和优化提供重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06325v1",
      "published_date": "2025-04-08 12:00:06 UTC",
      "updated_date": "2025-04-08 12:00:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:53:35.686911"
    },
    {
      "arxiv_id": "2504.05945v1",
      "title": "CKGAN: Training Generative Adversarial Networks Using Characteristic Kernel Integral Probability Metrics",
      "title_zh": "翻译失败",
      "authors": [
        "Kuntian Zhang",
        "Simin Yu",
        "Yaoshu Wang",
        "Makoto Onizuka",
        "Chuan Xiao"
      ],
      "abstract": "In this paper, we propose CKGAN, a novel generative adversarial network (GAN)\nvariant based on an integral probability metrics framework with characteristic\nkernel (CKIPM). CKIPM, as a distance between two probability distributions, is\ndesigned to optimize the lowerbound of the maximum mean discrepancy (MMD) in a\nreproducing kernel Hilbert space, and thus can be used to train GANs. CKGAN\nmitigates the notorious problem of mode collapse by mapping the generated\nimages back to random noise. To save the effort of selecting the kernel\nfunction manually, we propose a soft selection method to automatically learn a\ncharacteristic kernel function. The experimental evaluation conducted on a set\nof synthetic and real image benchmarks (MNIST, CelebA, etc.) demonstrates that\nCKGAN generally outperforms other MMD-based GANs. The results also show that at\nthe cost of moderately more training time, the automatically selected kernel\nfunction delivers very close performance to the best of manually fine-tuned one\non real image benchmarks and is able to improve the performances of other\nMMD-based GANs.",
      "tldr_zh": "这篇论文提出了 CKGAN，一种基于特征核积分概率度量 (CKIPM) 的新型 GAN 变体，用于优化最大均值差异 (MMD) 的下界，从而训练生成对抗网络。CKGAN 通过将生成图像映射回随机噪声来缓解常见的模式崩溃问题，并引入软选择方法自动学习特征核函数，避免手动调整。实验结果显示，在 MNIST 和 CelebA 等合成及真实图像基准上，CKGAN 整体性能优于其他 MMD-based GANs，且自动选择的核函数在训练时间稍长的情况下，其效果接近手动优化的最佳版本，并能提升其他 MMD-based GANs 的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Source codes are available at https://github.com/chuanxiao1983/CKGAN/",
      "pdf_url": "http://arxiv.org/pdf/2504.05945v1",
      "published_date": "2025-04-08 11:58:56 UTC",
      "updated_date": "2025-04-08 11:58:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:53:47.983391"
    },
    {
      "arxiv_id": "2504.06324v1",
      "title": "From Stability to Inconsistency: A Study of Moral Preferences in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Monika Jotautaite",
        "Mary Phuong",
        "Chatrik Singh Mangat",
        "Maria Angelica Martinez"
      ],
      "abstract": "As large language models (LLMs) increasingly integrate into our daily lives,\nit becomes crucial to understand their implicit biases and moral tendencies. To\naddress this, we introduce a Moral Foundations LLM dataset (MFD-LLM) grounded\nin Moral Foundations Theory, which conceptualizes human morality through six\ncore foundations. We propose a novel evaluation method that captures the full\nspectrum of LLMs' revealed moral preferences by answering a range of real-world\nmoral dilemmas. Our findings reveal that state-of-the-art models have\nremarkably homogeneous value preferences, yet demonstrate a lack of\nconsistency.",
      "tldr_zh": "本研究基于 Moral Foundations Theory 探讨了大型语言模型（LLMs）的道德偏好，引入了 Moral Foundations LLM 数据集（MFD-LLM），该数据集将人类道德分为六个核心基础。研究提出了一种新评估方法，通过回答真实世界的道德困境来全面捕捉 LLMs 的显露道德偏好。结果显示，先进模型表现出高度同质的价值偏好，但存在显著的一致性缺失。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06324v1",
      "published_date": "2025-04-08 11:52:50 UTC",
      "updated_date": "2025-04-08 11:52:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:53:59.276032"
    },
    {
      "arxiv_id": "2504.06323v1",
      "title": "Mosaic: Composite Projection Pruning for Resource-efficient LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Bailey J. Eccles",
        "Leon Wong",
        "Blesson Varghese"
      ],
      "abstract": "Extensive compute and memory requirements limit the deployment of large\nlanguage models (LLMs) on any hardware. Compression methods, such as pruning,\ncan reduce model size, which in turn reduces resource requirements.\nState-of-the-art pruning is based on coarse-grained methods. They are\ntime-consuming and inherently remove critical model parameters, adversely\nimpacting the quality of the pruned model. This paper introduces projection\npruning, a novel fine-grained method for pruning LLMs. In addition, LLM\nprojection pruning is enhanced by a new approach we refer to as composite\nprojection pruning - the synergistic combination of unstructured pruning that\nretains accuracy and structured pruning that reduces model size. We develop\nMosaic, a novel system to create and deploy pruned LLMs using composite\nprojection pruning. Mosaic is evaluated using a range of performance and\nquality metrics on multiple hardware platforms, LLMs, and datasets. Mosaic is\n7.19x faster in producing models than existing approaches. Mosaic models\nachieve up to 84.2% lower perplexity and 31.4% higher accuracy than models\nobtained from coarse-grained pruning. Up to 67% faster inference and 68% lower\nGPU memory use is noted for Mosaic models.",
      "tldr_zh": "本论文提出了一种名为 Mosaic 的系统，利用复合投影修剪（composite projection pruning）来优化大型语言模型（LLMs）的资源效率，该方法结合无结构修剪（保持准确性）和结构化修剪（减少模型大小），解决了传统粗粒度修剪的耗时和性能问题。Mosaic 通过细粒度投影修剪（projection pruning）生成更高效的模型，并在多个硬件平台、LLMs 和数据集上进行评估。结果显示，Mosaic 生成模型的速度比现有方法快 7.19 倍，perplexity 降低高达 84.2%、准确率提高 31.4%，并实现推理速度加快 67% 和 GPU 内存使用降低 68%。这为资源受限环境下的 LLMs 部署提供了重要贡献。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06323v1",
      "published_date": "2025-04-08 11:51:35 UTC",
      "updated_date": "2025-04-08 11:51:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:54:11.973687"
    },
    {
      "arxiv_id": "2504.05923v1",
      "title": "Uncovering Fairness through Data Complexity as an Early Indicator",
      "title_zh": "翻译失败",
      "authors": [
        "Juliett Suárez Ferreira",
        "Marija Slavkovik",
        "Jorge Casillas"
      ],
      "abstract": "Fairness constitutes a concern within machine learning (ML) applications.\nCurrently, there is no study on how disparities in classification complexity\nbetween privileged and unprivileged groups could influence the fairness of\nsolutions, which serves as a preliminary indicator of potential unfairness. In\nthis work, we investigate this gap, specifically, we focus on synthetic\ndatasets designed to capture a variety of biases ranging from historical bias\nto measurement and representational bias to evaluate how various complexity\nmetrics differences correlate with group fairness metrics. We then apply\nassociation rule mining to identify patterns that link disproportionate\ncomplexity differences between groups with fairness-related outcomes, offering\ndata-centric indicators to guide bias mitigation. Our findings are also\nvalidated by their application in real-world problems, providing evidence that\nquantifying group-wise classification complexity can uncover early indicators\nof potential fairness challenges. This investigation helps practitioners to\nproactively address bias in classification tasks.",
      "tldr_zh": "本研究探讨了机器学习 (ML) 中，特权组和非特权组在分类复杂度上的差异如何作为潜在不公平的早期指标，填补了现有研究的空白。通过使用合成数据集模拟各种偏差（如历史偏差、测量偏差和表示偏差），作者评估了复杂度指标差异与群体公平指标 (group fairness metrics) 的相关性，并应用关联规则挖掘 (association rule mining) 来识别组间不均衡复杂度与公平结果的模式，提供数据导向的偏差缓解指导。实验结果显示，这些复杂度差异可作为早期预警信号，并在真实世界问题中得到验证，从而帮助从业者主动处理分类任务中的偏见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05923v1",
      "published_date": "2025-04-08 11:28:40 UTC",
      "updated_date": "2025-04-08 11:28:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:54:22.868924"
    },
    {
      "arxiv_id": "2504.05908v1",
      "title": "PRIMEDrive-CoT: A Precognitive Chain-of-Thought Framework for Uncertainty-Aware Object Interaction in Driving Scene Scenario",
      "title_zh": "翻译失败",
      "authors": [
        "Sriram Mandalika",
        "Lalitha V",
        "Athira Nambiar"
      ],
      "abstract": "Driving scene understanding is a critical real-world problem that involves\ninterpreting and associating various elements of a driving environment, such as\nvehicles, pedestrians, and traffic signals. Despite advancements in autonomous\ndriving, traditional pipelines rely on deterministic models that fail to\ncapture the probabilistic nature and inherent uncertainty of real-world\ndriving. To address this, we propose PRIMEDrive-CoT, a novel uncertainty-aware\nmodel for object interaction and Chain-of-Thought (CoT) reasoning in driving\nscenarios. In particular, our approach combines LiDAR-based 3D object detection\nwith multi-view RGB references to ensure interpretable and reliable scene\nunderstanding. Uncertainty and risk assessment, along with object interactions,\nare modelled using Bayesian Graph Neural Networks (BGNNs) for probabilistic\nreasoning under ambiguous conditions. Interpretable decisions are facilitated\nthrough CoT reasoning, leveraging object dynamics and contextual cues, while\nGrad-CAM visualizations highlight attention regions. Extensive evaluations on\nthe DriveCoT dataset demonstrate that PRIMEDrive-CoT outperforms\nstate-of-the-art CoT and risk-aware models.",
      "tldr_zh": "本论文提出PRIMEDrive-CoT框架，一种前瞻性Chain-of-Thought (CoT)方法，用于处理驾驶场景中不确定性的物体交互问题，旨在克服传统确定性模型的局限性。框架结合LiDAR-based 3D物体检测、多视图RGB引用以及Bayesian Graph Neural Networks (BGNNs)来实现概率推理、风险评估和物体动态建模，同时通过CoT推理和Grad-CAM可视化提供可解释决策。实验结果显示，在DriveCoT数据集上，PRIMEDrive-CoT在性能上优于现有CoT和风险感知模型，为可靠的自动驾驶场景理解奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at The IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition 2025 - CVPRW",
      "pdf_url": "http://arxiv.org/pdf/2504.05908v1",
      "published_date": "2025-04-08 11:06:02 UTC",
      "updated_date": "2025-04-08 11:06:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:54:35.864842"
    },
    {
      "arxiv_id": "2504.05882v1",
      "title": "Turin3D: Evaluating Adaptation Strategies under Label Scarcity in Urban LiDAR Segmentation with Semi-Supervised Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Barco",
        "Giacomo Blanco",
        "Gaetano Chiriaco",
        "Alessia Intini",
        "Luigi La Riccia",
        "Vittorio Scolamiero",
        "Piero Boccardo",
        "Paolo Garza",
        "Fabrizio Dominici"
      ],
      "abstract": "3D semantic segmentation plays a critical role in urban modelling, enabling\ndetailed understanding and mapping of city environments. In this paper, we\nintroduce Turin3D: a new aerial LiDAR dataset for point cloud semantic\nsegmentation covering an area of around 1.43 km2 in the city centre of Turin\nwith almost 70M points. We describe the data collection process and compare\nTurin3D with others previously proposed in the literature. We did not fully\nannotate the dataset due to the complexity and time-consuming nature of the\nprocess; however, a manual annotation process was performed on the validation\nand test sets, to enable a reliable evaluation of the proposed techniques. We\nfirst benchmark the performances of several point cloud semantic segmentation\nmodels, trained on the existing datasets, when tested on Turin3D, and then\nimprove their performances by applying a semi-supervised learning technique\nleveraging the unlabelled training set. The dataset will be publicly available\nto support research in outdoor point cloud segmentation, with particular\nrelevance for self-supervised and semi-supervised learning approaches given the\nabsence of ground truth annotations for the training set.",
      "tldr_zh": "本研究引入了Turin3D，这是一个新的航空LiDAR数据集，用于城市点云语义分割，覆盖Turin市中心约1.43 km²，包含近70M点，并详细描述了数据收集过程及其与其他数据集的比较。考虑到标注的复杂性，数据集仅对验证集和测试集进行了手动标注，而训练集未标注；研究者首先基准测试了多种点云语义分割模型在Turin3D上的性能，然后通过半监督学习(semi-supervised learning)技术利用未标注数据提升了模型表现。实验结果显示，这种适应策略在标签稀缺(label scarcity)场景下有效，支持户外点云分割研究，特别是自监督和半监督方法，该数据集将公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPRW2025 - USM3D",
      "pdf_url": "http://arxiv.org/pdf/2504.05882v1",
      "published_date": "2025-04-08 10:17:14 UTC",
      "updated_date": "2025-04-08 10:17:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:54:47.010022"
    },
    {
      "arxiv_id": "2504.06322v1",
      "title": "Assessing employment and labour issues implicated by using AI",
      "title_zh": "翻译失败",
      "authors": [
        "Thijs Willems",
        "Darion Jin Hotan",
        "Jiawen Cheryl Tang",
        "Norakmal Hakim bin Norhashim",
        "King Wang Poon",
        "Zi An Galvyn Goh",
        "Radha Vinod"
      ],
      "abstract": "This chapter critiques the dominant reductionist approach in AI and work\nstudies, which isolates tasks and skills as replaceable components. Instead, it\nadvocates for a systemic perspective that emphasizes the interdependence of\ntasks, roles, and workplace contexts. Two complementary approaches are\nproposed: an ethnographic, context-rich method that highlights how AI\nreconfigures work environments and expertise; and a relational task-based\nanalysis that bridges micro-level work descriptions with macro-level labor\ntrends. The authors argue that effective AI impact assessments must go beyond\npredicting automation rates to include ethical, well-being, and\nexpertise-related questions. Drawing on empirical case studies, they\ndemonstrate how AI reshapes human-technology relations, professional roles, and\ntacit knowledge practices. The chapter concludes by calling for a\nhuman-centric, holistic framework that guides organizational and policy\ndecisions, balancing technological possibilities with social desirability and\nsustainability of work.",
      "tldr_zh": "本研究批评了主流 AI 与工作研究的简化方法，该方法将任务和技能视为可替换组件，并提倡采用系统性视角，强调任务、角色和工作环境的相互依赖。作者提出两种互补方法：民族志方法（ethnographic method），用于揭示 AI 如何重塑工作环境和专业知识；以及关系任务分析（relational task-based analysis），将微观工作描述与宏观劳动趋势相连。研究通过实证案例研究，展示了 AI 在改变人-技术关系、专业角色和隐性知识实践方面的影响，并呼吁建立以人为中心的全方位框架，用于指导组织和政策决策，以平衡技术可能性与社会可取性和工作可持续性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "This manuscript is accepted for publication in Emad Yaghmaei, et al.,\n  eds., Global Perspectives on AI Impact Assessment (Oxford University Press,\n  forthcoming 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.06322v1",
      "published_date": "2025-04-08 10:14:19 UTC",
      "updated_date": "2025-04-08 10:14:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:54:59.528863"
    },
    {
      "arxiv_id": "2504.05874v2",
      "title": "Systematic Parameter Decision in Approximate Model Counting",
      "title_zh": "在近似模型计数中的系统参数决策",
      "authors": [
        "Jinping Lei",
        "Toru Takisaka",
        "Junqiang Peng",
        "Mingyu Xiao"
      ],
      "abstract": "This paper proposes a novel approach to determining the internal parameters\nof the hashing-based approximate model counting algorithm $\\mathsf{ApproxMC}$.\nIn this problem, the chosen parameter values must ensure that\n$\\mathsf{ApproxMC}$ is Probably Approximately Correct (PAC), while also making\nit as efficient as possible. The existing approach to this problem relies on\nheuristics; in this paper, we solve this problem by formulating it as an\noptimization problem that arises from generalizing $\\mathsf{ApproxMC}$'s\ncorrectness proof to arbitrary parameter values.\n  Our approach separates the concerns of algorithm soundness and optimality,\nallowing us to address the former without the need for repetitive case-by-case\nargumentation, while establishing a clear framework for the latter.\nFurthermore, after reduction, the resulting optimization problem takes on an\nexceptionally simple form, enabling the use of a basic search algorithm and\nproviding insight into how parameter values affect algorithm performance.\nExperimental results demonstrate that our optimized parameters improve the\nruntime performance of the latest $\\mathsf{ApproxMC}$ by a factor of 1.6 to\n2.4, depending on the error tolerance.",
      "tldr_zh": "这篇论文提出了一种新方法，用于系统地决定基于哈希的近似模型计数算法 $\\mathsf{ApproxMC}$ 的内部参数，确保算法满足 Probably Approximately Correct (PAC) 条件，同时优化其效率。不同于依赖启发式规则的现有方法，该方法将参数决策问题转化为一个优化问题，通过泛化 $\\mathsf{ApproxMC}$ 的正确性证明来处理任意参数值，并分离算法的正确性和最优性框架。实验结果表明，使用优化的参数，$\\mathsf{ApproxMC}$ 的运行时间性能提高了 1.6 到 2.4 倍，取决于错误容忍度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05874v2",
      "published_date": "2025-04-08 09:58:41 UTC",
      "updated_date": "2025-05-21 12:50:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:55:11.819203"
    },
    {
      "arxiv_id": "2504.05871v1",
      "title": "Agent Guide: A Simple Agent Behavioral Watermarking Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Kaibo Huang",
        "Zhongliang Yang",
        "Linna Zhou"
      ],
      "abstract": "The increasing deployment of intelligent agents in digital ecosystems, such\nas social media platforms, has raised significant concerns about traceability\nand accountability, particularly in cybersecurity and digital content\nprotection. Traditional large language model (LLM) watermarking techniques,\nwhich rely on token-level manipulations, are ill-suited for agents due to the\nchallenges of behavior tokenization and information loss during\nbehavior-to-action translation. To address these issues, we propose Agent\nGuide, a novel behavioral watermarking framework that embeds watermarks by\nguiding the agent's high-level decisions (behavior) through probability biases,\nwhile preserving the naturalness of specific executions (action). Our approach\ndecouples agent behavior into two levels, behavior (e.g., choosing to bookmark)\nand action (e.g., bookmarking with specific tags), and applies watermark-guided\nbiases to the behavior probability distribution. We employ a z-statistic-based\nstatistical analysis to detect the watermark, ensuring reliable extraction over\nmultiple rounds. Experiments in a social media scenario with diverse agent\nprofiles demonstrate that Agent Guide achieves effective watermark detection\nwith a low false positive rate. Our framework provides a practical and robust\nsolution for agent watermarking, with applications in identifying malicious\nagents and protecting proprietary agent systems.",
      "tldr_zh": "该论文提出 Agent Guide，一种简单的代理行为水印框架，旨在解决智能代理在网络安全和数字内容保护中的可追溯性和责任问题。框架通过在代理的高级决策（行为）上应用概率偏差来嵌入水marks，同时保持具体执行（action）的自然性，并将代理行为解耦为行为级别（如选择书签）和动作级别（如具体标签）。它采用基于 z-统计量的统计分析进行可靠的水印检测，确保在多轮交互中有效提取。实验在社交媒体场景中验证了该框架的检测效果，低假阳性率，并为识别恶意代理和保护专有代理系统提供了实用应用。",
      "categories": [
        "cs.AI",
        "K.6.5"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05871v1",
      "published_date": "2025-04-08 09:54:49 UTC",
      "updated_date": "2025-04-08 09:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:55:24.200602"
    },
    {
      "arxiv_id": "2504.05862v2",
      "title": "Are Generative AI Agents Effective Personalized Financial Advisors?",
      "title_zh": "生成式 AI 代理是否是有效的个性化财务顾问？",
      "authors": [
        "Takehiro Takayanagi",
        "Kiyoshi Izumi",
        "Javier Sanz-Cruzado",
        "Richard McCreadie",
        "Iadh Ounis"
      ],
      "abstract": "Large language model-based agents are becoming increasingly popular as a\nlow-cost mechanism to provide personalized, conversational advice, and have\ndemonstrated impressive capabilities in relatively simple scenarios, such as\nmovie recommendations. But how do these agents perform in complex high-stakes\ndomains, where domain expertise is essential and mistakes carry substantial\nrisk? This paper investigates the effectiveness of LLM-advisors in the finance\ndomain, focusing on three distinct challenges: (1) eliciting user preferences\nwhen users themselves may be unsure of their needs, (2) providing personalized\nguidance for diverse investment preferences, and (3) leveraging advisor\npersonality to build relationships and foster trust. Via a lab-based user study\nwith 64 participants, we show that LLM-advisors often match human advisor\nperformance when eliciting preferences, although they can struggle to resolve\nconflicting user needs. When providing personalized advice, the LLM was able to\npositively influence user behavior, but demonstrated clear failure modes. Our\nresults show that accurate preference elicitation is key, otherwise, the\nLLM-advisor has little impact, or can even direct the investor toward\nunsuitable assets. More worryingly, users appear insensitive to the quality of\nadvice being given, or worse these can have an inverse relationship. Indeed,\nusers reported a preference for and increased satisfaction as well as emotional\ntrust with LLMs adopting an extroverted persona, even though those agents\nprovided worse advice.",
      "tldr_zh": "这篇论文评估了基于大型语言模型(LLM)的AI代理是否能作为有效的个性化财务顾问，焦点在于三个挑战：eliciting user preferences（当用户不确定需求时）、providing personalized guidance（针对不同投资偏好）和leveraging advisor personality（利用顾问个性建立信任）。通过一项涉及64名参与者的实验室用户研究，发现LLM在eliciting用户偏好时往往与人类顾问相当，但可能在处理冲突需求时表现不佳。研究结果显示，LLM能影响用户行为并提供个性化建议，但如果preference elicitation不准确，可能导致用户选择不合适的资产；更令人担忧的是，用户对建议质量不敏感，反而更偏好外向的LLM代理，尽管这些代理的建议质量较低，从而提升了用户满意度和情感信任，但也增加了潜在风险。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.IR",
        "q-fin.CP"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for presentation at SIGIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.05862v2",
      "published_date": "2025-04-08 09:41:03 UTC",
      "updated_date": "2025-04-15 01:14:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:55:36.036804"
    },
    {
      "arxiv_id": "2504.05857v1",
      "title": "Towards an AI-Driven Video-Based American Sign Language Dictionary: Exploring Design and Usage Experience with Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Saad Hassan",
        "Matyas Bohacek",
        "Chaelin Kim",
        "Denise Crochet"
      ],
      "abstract": "Searching for unfamiliar American Sign Language (ASL) signs is challenging\nfor learners because, unlike spoken languages, they cannot type a text-based\nquery to look up an unfamiliar sign. Advances in isolated sign recognition have\nenabled the creation of video-based dictionaries, allowing users to submit a\nvideo and receive a list of the closest matching signs. Previous HCI research\nusing Wizard-of-Oz prototypes has explored interface designs for ASL\ndictionaries. Building on these studies, we incorporate their design\nrecommendations and leverage state-of-the-art sign-recognition technology to\ndevelop an automated video-based dictionary. We also present findings from an\nobservational study with twelve novice ASL learners who used this dictionary\nduring video-comprehension and question-answering tasks. Our results address\nhuman-AI interaction challenges not covered in previous WoZ research, including\nrecording and resubmitting signs, unpredictable outputs, system latency, and\nprivacy concerns. These insights offer guidance for designing and deploying\nvideo-based ASL dictionary systems.",
      "tldr_zh": "本研究探讨了基于 AI 的视频型 American Sign Language (ASL) 字典的设计和使用体验，针对 ASL 学习者无法通过文本查询搜索不熟悉手势的问题，开发了一个允许用户提交视频并返回匹配手势的系统。研究基于先前 HCI 和 Wizard-of-Oz 原型的研究建议，结合最先进的孤立手势识别技术，构建了自动化字典，并通过对 12 名新手 ASL 学习者的观察性研究（包括视频理解和问答任务）进行评估。结果揭示了人类-AI 交互中的新挑战，如录制/重新提交手势、输出不可预测性、系统延迟和隐私问题，并为视频型 ASL 字典系统的设计和部署提供了宝贵指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05857v1",
      "published_date": "2025-04-08 09:35:46 UTC",
      "updated_date": "2025-04-08 09:35:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:55:47.373314"
    },
    {
      "arxiv_id": "2504.05855v1",
      "title": "Enhancing Coreference Resolution with Pretrained Language Models: Bridging the Gap Between Syntax and Semantics",
      "title_zh": "使用预训练语言模型增强共指解析：弥合语法与语义之间的差距",
      "authors": [
        "Xingzu Liu",
        "Songhang deng",
        "Mingbang Wang",
        "Zhang Dong",
        "Le Dai",
        "Jiyuan Li",
        "Ruilin Nong"
      ],
      "abstract": "Large language models have made significant advancements in various natural\nlanguage processing tasks, including coreference resolution. However,\ntraditional methods often fall short in effectively distinguishing referential\nrelationships due to a lack of integration between syntactic and semantic\ninformation. This study introduces an innovative framework aimed at enhancing\ncoreference resolution by utilizing pretrained language models. Our approach\ncombines syntax parsing with semantic role labeling to accurately capture finer\ndistinctions in referential relationships. By employing state-of-the-art\npretrained models to gather contextual embeddings and applying an attention\nmechanism for fine-tuning, we improve the performance of coreference tasks.\nExperimental results across diverse datasets show that our method surpasses\nconventional coreference resolution systems, achieving notable accuracy in\ndisambiguating references. This development not only improves coreference\nresolution outcomes but also positively impacts other natural language\nprocessing tasks that depend on precise referential understanding.",
      "tldr_zh": "本研究提出一个创新框架，利用预训练语言模型（Pretrained Language Models）来增强核心ference解析（Coreference Resolution），旨在桥接语法解析（Syntax Parsing）和语义信息之间的鸿沟。框架通过结合语义角色标注（Semantic Role Labeling）和注意力机制（Attention Mechanism）进行微调，从而更准确地捕捉参考关系。实验结果显示，该方法在多种数据集上超过了传统系统，显著提高了参考消歧的准确率，并为其他依赖精确参考理解的自然语言处理（NLP）任务提供了积极影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "acl submission",
      "pdf_url": "http://arxiv.org/pdf/2504.05855v1",
      "published_date": "2025-04-08 09:33:09 UTC",
      "updated_date": "2025-04-08 09:33:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:55:59.488056"
    },
    {
      "arxiv_id": "2504.05852v1",
      "title": "Physics-aware generative models for turbulent fluid flows through energy-consistent stochastic interpolants",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolaj T. Mücke",
        "Benjamin Sanderse"
      ],
      "abstract": "Generative models have demonstrated remarkable success in domains such as\ntext, image, and video synthesis. In this work, we explore the application of\ngenerative models to fluid dynamics, specifically for turbulence simulation,\nwhere classical numerical solvers are computationally expensive. We propose a\nnovel stochastic generative model based on stochastic interpolants, which\nenables probabilistic forecasting while incorporating physical constraints such\nas energy stability and divergence-freeness. Unlike conventional stochastic\ngenerative models, which are often agnostic to underlying physical laws, our\napproach embeds energy consistency by making the parameters of the stochastic\ninterpolant learnable coefficients. We evaluate our method on a benchmark\nturbulence problem - Kolmogorov flow - demonstrating superior accuracy and\nstability over state-of-the-art alternatives such as autoregressive conditional\ndiffusion models (ACDMs) and PDE-Refiner. Furthermore, we achieve stable\nresults for significantly longer roll-outs than standard stochastic\ninterpolants. Our results highlight the potential of physics-aware generative\nmodels in accelerating and enhancing turbulence simulations while preserving\nfundamental conservation properties.",
      "tldr_zh": "本文提出了一种基于stochastic interpolants的物理感知生成模型，用于湍流模拟，以替代计算开销巨大的经典数值求解器。该模型通过将随机插值的参数设为可学习的系数，嵌入能量稳定性和无散度等物理约束，实现概率预测和更稳定的输出。在Kolmogorov flow基准问题上，实验结果显示该方法在准确性和稳定性方面优于autoregressive conditional diffusion models (ACDMs)和PDE-Refiner，并支持更长的滚动模拟输出。该研究为加速湍流模拟同时保留基本守恒属性提供了新途径。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05852v1",
      "published_date": "2025-04-08 09:29:01 UTC",
      "updated_date": "2025-04-08 09:29:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:56:12.665152"
    },
    {
      "arxiv_id": "2504.05846v1",
      "title": "PathGPT: Leveraging Large Language Models for Personalized Route Generation",
      "title_zh": "PathGPT: 利用大语言模型进行个性化路线生成",
      "authors": [
        "Steeve Cuthbert Marcelyn",
        "Yucen Gao",
        "Yuzhe Zhang",
        "Xiaofeng Gao",
        "Guihai Chen"
      ],
      "abstract": "The proliferation of GPS enabled devices has led to the accumulation of a\nsubstantial corpus of historical trajectory data. By leveraging these data for\ntraining machine learning models,researchers have devised novel data-driven\nmethodologies that address the personalized route recommendation (PRR) problem.\nIn contrast to conventional algorithms such as Dijkstra shortest path\nalgorithm,these novel algorithms possess the capacity to discern and learn\npatterns within the data,thereby facilitating the generation of more\npersonalized paths. However,once these models have been trained,their\napplication is constrained to the generation of routes that align with their\ntraining patterns. This limitation renders them less adaptable to novel\nscenarios and the deployment of multiple machine learning models might be\nnecessary to address new possible scenarios,which can be costly as each model\nmust be trained separately. Inspired by recent advances in the field of Large\nLanguage Models (LLMs),we leveraged their natural language understanding\ncapabilities to develop a unified model to solve the PRR problem while being\nseamlessly adaptable to new scenarios without additional training. To\naccomplish this,we combined the extensive knowledge LLMs acquired during\ntraining with further access to external hand-crafted context\ninformation,similar to RAG (Retrieved Augmented Generation) systems,to enhance\ntheir ability to generate paths according to user-defined requirements.\nExtensive experiments on different datasets show a considerable uplift in LLM\nperformance on the PRR problem.",
      "tldr_zh": "本论文提出 PathGPT，一种利用大型语言模型 (LLMs) 的框架，用于解决个性化路线推荐 (PRR) 问题，克服传统算法如 Dijkstra 的局限性，以及现有模型在适应新场景时的训练成本高问题。\nPathGPT 通过整合 LLMs 的自然语言理解能力与外部手-crafted 上下文信息（如 RAG 系统），构建一个统一的模型，实现无缝适应用户自定义需求而无需额外训练。\n实验结果显示，在不同数据集上，PathGPT 显著提升了 LLMs 在 PRR 任务上的性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05846v1",
      "published_date": "2025-04-08 09:25:21 UTC",
      "updated_date": "2025-04-08 09:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:56:23.017297"
    },
    {
      "arxiv_id": "2504.06320v1",
      "title": "Hybrid Temporal Differential Consistency Autoencoder for Efficient and Sustainable Anomaly Detection in Cyber-Physical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Somma"
      ],
      "abstract": "Cyberattacks on critical infrastructure, particularly water distribution\nsystems, have increased due to rapid digitalization and the integration of IoT\ndevices and industrial control systems (ICS). These cyber-physical systems\n(CPS) introduce new vulnerabilities, requiring robust and automated intrusion\ndetection systems (IDS) to mitigate potential threats. This study addresses key\nchallenges in anomaly detection by leveraging time correlations in sensor data,\nintegrating physical principles into machine learning models, and optimizing\ncomputational efficiency for edge applications. We build upon the concept of\ntemporal differential consistency (TDC) loss to capture the dynamics of the\nsystem, ensuring meaningful relationships between dynamic states. Expanding on\nthis foundation, we propose a hybrid autoencoder-based approach, referred to as\nhybrid TDC-AE, which extends TDC by incorporating both deterministic nodes and\nconventional statistical nodes. This hybrid structure enables the model to\naccount for non-deterministic processes. Our approach achieves state-of-the-art\nclassification performance while improving time to detect anomalies by 3%,\noutperforming the BATADAL challenge leader without requiring domain-specific\nknowledge, making it broadly applicable. Additionally, it maintains the\ncomputational efficiency of conventional autoencoders while reducing the number\nof fully connected layers, resulting in a more sustainable and efficient\nsolution. The method demonstrates how leveraging physics-inspired consistency\nprinciples enhances anomaly detection and strengthens the resilience of\ncyber-physical systems.",
      "tldr_zh": "这篇论文针对网络攻击对关键基础设施（如水分配系统）的威胁，提出了一种高效可持续的异常检测方法，用于 Cyber-Physical Systems (CPS)。他们开发了 Hybrid Temporal Differential Consistency Autoencoder (Hybrid TDC-AE) 模型，通过整合 Temporal Differential Consistency (TDC) loss、确定性节点和常规统计节点，捕捉传感器数据的动态关系并处理非确定性过程，同时优化计算效率。实验结果显示，该方法在分类性能上达到最先进水平，异常检测时间提高 3%，优于 BATADAL 挑战领先者，且无需领域特定知识，使其更广泛适用，并通过物理启发的 consistency 原则提升了 CPS 的韧性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06320v1",
      "published_date": "2025-04-08 09:22:44 UTC",
      "updated_date": "2025-04-08 09:22:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:56:36.538945"
    },
    {
      "arxiv_id": "2504.05840v1",
      "title": "Momentum Boosted Episodic Memory for Improving Learning in Long-Tailed RL Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Dolton Fernandes",
        "Pramod Kaushik",
        "Harsh Shukla",
        "Bapi Raju Surampudi"
      ],
      "abstract": "Traditional Reinforcement Learning (RL) algorithms assume the distribution of\nthe data to be uniform or mostly uniform. However, this is not the case with\nmost real-world applications like autonomous driving or in nature where animals\nroam. Some experiences are encountered frequently, and most of the remaining\nexperiences occur rarely; the resulting distribution is called Zipfian. Taking\ninspiration from the theory of complementary learning systems, an architecture\nfor learning from Zipfian distributions is proposed where important long tail\ntrajectories are discovered in an unsupervised manner. The proposal comprises\nan episodic memory buffer containing a prioritised memory module to ensure\nimportant rare trajectories are kept longer to address the Zipfian problem,\nwhich needs credit assignment to happen in a sample efficient manner. The\nexperiences are then reinstated from episodic memory and given weighted\nimportance forming the trajectory to be executed. Notably, the proposed\narchitecture is modular, can be incorporated in any RL architecture and yields\nimproved performance in multiple Zipfian tasks over traditional architectures.\nOur method outperforms IMPALA by a significant margin on all three tasks and\nall three evaluation metrics (Zipfian, Uniform, and Rare Accuracy) and also\ngives improvements on most Atari environments that are considered challenging",
      "tldr_zh": "该论文针对传统强化学习（RL）算法在长尾分布（Zipfian）环境中表现不佳的问题，提出了一种受互补学习系统理论启发的架构。该架构包括一个带有优先级记忆模块的 episodic memory buffer，能够无监督地发现并保留重要的稀有轨迹，并通过加权重新执行这些轨迹以提高样本效率。该方法模块化，可整合到任何 RL 架构中，并在多个 Zipfian 任务上显著优于 IMPALA，在 Zipfian、Uniform 和 Rare Accuracy 等指标上表现出色，并改善了大多数 Atari 环境的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05840v1",
      "published_date": "2025-04-08 09:21:39 UTC",
      "updated_date": "2025-04-08 09:21:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:56:48.019989"
    },
    {
      "arxiv_id": "2504.05838v1",
      "title": "Mind the Trojan Horse: Image Prompt Adapter Enabling Scalable and Deceptive Jailbreaking",
      "title_zh": "翻译失败",
      "authors": [
        "Junxi Chen",
        "Junhao Dong",
        "Xiaohua Xie"
      ],
      "abstract": "Recently, the Image Prompt Adapter (IP-Adapter) has been increasingly\nintegrated into text-to-image diffusion models (T2I-DMs) to improve\ncontrollability. However, in this paper, we reveal that T2I-DMs equipped with\nthe IP-Adapter (T2I-IP-DMs) enable a new jailbreak attack named the hijacking\nattack. We demonstrate that, by uploading imperceptible image-space adversarial\nexamples (AEs), the adversary can hijack massive benign users to jailbreak an\nImage Generation Service (IGS) driven by T2I-IP-DMs and mislead the public to\ndiscredit the service provider. Worse still, the IP-Adapter's dependency on\nopen-source image encoders reduces the knowledge required to craft AEs.\nExtensive experiments verify the technical feasibility of the hijacking attack.\nIn light of the revealed threat, we investigate several existing defenses and\nexplore combining the IP-Adapter with adversarially trained models to overcome\nexisting defenses' limitations. Our code is available at\nhttps://github.com/fhdnskfbeuv/attackIPA.",
      "tldr_zh": "该论文揭示了在text-to-image diffusion models (T2I-DMs)中整合Image Prompt Adapter (IP-Adapter)后出现的一种新型jailbreak攻击，称为hijacking attack。攻击者通过上传不易察觉的图像空间对抗样本 (AEs)，可以劫持Image Generation Service (IGS)，诱导大量良性用户生成违规内容，从而损害服务提供者的信誉。实验结果验证了这种攻击的可行性，并强调IP-Adapter依赖开源图像编码器的特性降低了攻击门槛。论文进一步评估了现有防御措施的局限性，并探索了将IP-Adapter与对抗训练模型结合的潜在解决方案，以提升安全性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025 as Highlight",
      "pdf_url": "http://arxiv.org/pdf/2504.05838v1",
      "published_date": "2025-04-08 09:20:29 UTC",
      "updated_date": "2025-04-08 09:20:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:57:00.326829"
    },
    {
      "arxiv_id": "2504.06319v1",
      "title": "Accelerating LLM Inference Throughput via Asynchronous KV Cache Prefetching",
      "title_zh": "翻译失败",
      "authors": [
        "Yanhao Dong",
        "Yubo Miao",
        "Weinan Li",
        "Xiao Zheng",
        "Chao Wang",
        "Feng Lyu"
      ],
      "abstract": "Large Language Models (LLMs) exhibit pronounced memory-bound characteristics\nduring inference due to High Bandwidth Memory (HBM) bandwidth constraints. In\nthis paper, we propose an L2 Cache-oriented asynchronous KV Cache prefetching\nmethod to break through the memory bandwidth bottleneck in LLM inference\nthrough computation-load overlap. By strategically scheduling idle memory\nbandwidth during active computation windows, our method proactively prefetches\nrequired KV Cache into GPU L2 cache, enabling high-speed L2 cache hits for\nsubsequent accesses and effectively hiding HBM access latency within\ncomputational cycles. Extensive experiments on NVIDIA H20 GPUs demonstrate that\nthe proposed method achieves 2.15x improvement in attention kernel efficiency\nand up to 1.97x end-to-end throughput enhancement, surpassing state-of-the-art\nbaseline FlashAttention-3. Notably, our solution maintains orthogonality to\nexisting optimization techniques and can be integrated with current inference\nframeworks, providing a scalable latency-hiding solution for next-generation\nLLM inference engines.",
      "tldr_zh": "该论文提出了一种异步 KV Cache 预取方法，针对 LLM 推理过程中 HBM 带宽限制导致的内存绑定问题，通过计算负载重叠来提升效率。\n该方法战略性地利用空闲内存带宽，将所需的 KV Cache 预取到 GPU L2 cache 中，从而隐藏 HBM 访问延迟并实现高速缓存命中。\n实验结果显示，在 NVIDIA H20 GPUs 上，该方法使注意力内核效率提高 2.15 倍，并将端到端吞吐量提升高达 1.97 倍，优于 FlashAttention-3 基线。\n此外，该方案与现有优化技术正交，可轻松集成到当前 LLM 推理框架中，提供可扩展的延迟隐藏解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.06319v1",
      "published_date": "2025-04-08 09:17:35 UTC",
      "updated_date": "2025-04-08 09:17:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:57:12.577482"
    },
    {
      "arxiv_id": "2504.05830v1",
      "title": "Human Activity Recognition using RGB-Event based Sensors: A Multi-modal Heat Conduction Model and A Benchmark Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Shiao Wang",
        "Xiao Wang",
        "Bo Jiang",
        "Lin Zhu",
        "Guoqi Li",
        "Yaowei Wang",
        "Yonghong Tian",
        "Jin Tang"
      ],
      "abstract": "Human Activity Recognition (HAR) primarily relied on traditional RGB cameras\nto achieve high-performance activity recognition. However, the challenging\nfactors in real-world scenarios, such as insufficient lighting and rapid\nmovements, inevitably degrade the performance of RGB cameras. To address these\nchallenges, biologically inspired event cameras offer a promising solution to\novercome the limitations of traditional RGB cameras. In this work, we rethink\nhuman activity recognition by combining the RGB and event cameras. The first\ncontribution is the proposed large-scale multi-modal RGB-Event human activity\nrecognition benchmark dataset, termed HARDVS 2.0, which bridges the dataset\ngaps. It contains 300 categories of everyday real-world actions with a total of\n107,646 paired videos covering various challenging scenarios. Inspired by the\nphysics-informed heat conduction model, we propose a novel multi-modal heat\nconduction operation framework for effective activity recognition, termed\nMMHCO-HAR. More in detail, given the RGB frames and event streams, we first\nextract the feature embeddings using a stem network. Then, multi-modal Heat\nConduction blocks are designed to fuse the dual features, the key module of\nwhich is the multi-modal Heat Conduction Operation layer. We integrate RGB and\nevent embeddings through a multi-modal DCT-IDCT layer while adaptively\nincorporating the thermal conductivity coefficient via FVEs into this module.\nAfter that, we propose an adaptive fusion module based on a policy routing\nstrategy for high-performance classification. Comprehensive experiments\ndemonstrate that our method consistently performs well, validating its\neffectiveness and robustness. The source code and benchmark dataset will be\nreleased on https://github.com/Event-AHU/HARDVS/tree/HARDVSv2",
      "tldr_zh": "该论文探讨了人类活动识别（HAR）中 RGB 相机在光线不足和快速运动等真实场景下的性能问题，并提出结合 RGB 和 event 相机作为解决方案。研究的主要贡献包括发布一个大规模多模态 RGB-Event HAR 基准数据集 HARDVS 2.0，涵盖 300 类日常动作和 107,646 对视频，以填补数据集空白。作者设计了新型框架 MMHCO-HAR，基于物理启发的热传导模型，通过提取特征嵌入、多模态热传导操作层（如 DCT-IDCT 和热传导系数整合）以及自适应融合模块，实现 RGB 和 event 数据的有效融合。实验结果显示，该方法在各种挑战场景下表现出色，验证了其有效性和鲁棒性，并计划在 GitHub 上开源代码和数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Journal Extension of HARDVS (AAAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2504.05830v1",
      "published_date": "2025-04-08 09:14:24 UTC",
      "updated_date": "2025-04-08 09:14:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:57:24.460912"
    },
    {
      "arxiv_id": "2504.05815v1",
      "title": "Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models",
      "title_zh": "Parasite：一种基于隐写术的后门攻击框架，用于扩散模型",
      "authors": [
        "Jiahao Chen",
        "Yu Pan",
        "Yi Du",
        "Chunkai Wu",
        "Lin Wang"
      ],
      "abstract": "Recently, the diffusion model has gained significant attention as one of the\nmost successful image generation models, which can generate high-quality images\nby iteratively sampling noise. However, recent studies have shown that\ndiffusion models are vulnerable to backdoor attacks, allowing attackers to\nenter input data containing triggers to activate the backdoor and generate\ntheir desired output. Existing backdoor attack methods primarily focused on\ntarget noise-to-image and text-to-image tasks, with limited work on backdoor\nattacks in image-to-image tasks. Furthermore, traditional backdoor attacks\noften rely on a single, conspicuous trigger to generate a fixed target image,\nlacking concealability and flexibility. To address these limitations, we\npropose a novel backdoor attack method called \"Parasite\" for image-to-image\ntasks in diffusion models, which not only is the first to leverage\nsteganography for triggers hiding, but also allows attackers to embed the\ntarget content as a backdoor trigger to achieve a more flexible attack.\n\"Parasite\" as a novel attack method effectively bypasses existing detection\nframeworks to execute backdoor attacks. In our experiments, \"Parasite\" achieved\na 0 percent backdoor detection rate against the mainstream defense frameworks.\nIn addition, in the ablation study, we discuss the influence of different\nhiding coefficients on the attack results. You can find our code at\nhttps://anonymous.4open.science/r/Parasite-1715/.",
      "tldr_zh": "该研究提出了一种名为 Parasite 的后门攻击框架，针对扩散模型（diffusion models）中的图像到图像（image-to-image）任务，首次利用隐写术（steganography）来隐藏触发器，并允许攻击者将目标内容嵌入作为触发器，以提升攻击的隐蔽性和灵活性。相比传统后门攻击（backdoor attacks），Parasite 能够绕过主流防御框架，在实验中实现 0% 的检测率。研究还通过消融实验探讨了不同隐藏系数对攻击效果的影响，为评估扩散模型的安全性提供了新洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05815v1",
      "published_date": "2025-04-08 08:53:47 UTC",
      "updated_date": "2025-04-08 08:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:57:35.246793"
    },
    {
      "arxiv_id": "2504.05806v1",
      "title": "Meta-Continual Learning of Neural Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Seungyoon Woo",
        "Junhyeog Yun",
        "Gunhee Kim"
      ],
      "abstract": "Neural Fields (NF) have gained prominence as a versatile framework for\ncomplex data representation. This work unveils a new problem setting termed\n\\emph{Meta-Continual Learning of Neural Fields} (MCL-NF) and introduces a novel\nstrategy that employs a modular architecture combined with optimization-based\nmeta-learning. Focused on overcoming the limitations of existing methods for\ncontinual learning of neural fields, such as catastrophic forgetting and slow\nconvergence, our strategy achieves high-quality reconstruction with\nsignificantly improved learning speed. We further introduce Fisher Information\nMaximization loss for neural radiance fields (FIM-NeRF), which maximizes\ninformation gains at the sample level to enhance learning generalization, with\nproved convergence guarantee and generalization bound. We perform extensive\nevaluations across image, audio, video reconstruction, and view synthesis tasks\non six diverse datasets, demonstrating our method's superiority in\nreconstruction quality and speed over existing MCL and CL-NF approaches.\nNotably, our approach attains rapid adaptation of neural fields for city-scale\nNeRF rendering with reduced parameter requirement.",
      "tldr_zh": "本研究引入了 Meta-Continual Learning of Neural Fields (MCL-NF) 的新问题设置，并提出了一种结合模块化架构和优化-based meta-learning 的策略，以克服 Neural Fields 在持续学习中的灾难性遗忘和慢速收敛问题。该策略显著提高了重建质量和学习速度，并开发了 Fisher Information Maximization loss for neural radiance fields (FIM-NeRF)，通过最大化样本级信息增益来增强泛化能力，并提供了收敛保证和泛化边界。在图像、音频、视频重建以及视图合成任务的六种数据集上进行的大量评估表明，该方法优于现有 MCL 和 CL-NF 方法，尤其在城市规模 NeRF 渲染中实现了快速适应和参数减少。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05806v1",
      "published_date": "2025-04-08 08:38:37 UTC",
      "updated_date": "2025-04-08 08:38:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:57:48.752806"
    },
    {
      "arxiv_id": "2504.05804v1",
      "title": "StealthRank: LLM Ranking Manipulation via Stealthy Prompt Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Tang",
        "Yi Fan",
        "Chenxiao Yu",
        "Tiankai Yang",
        "Yue Zhao",
        "Xiyang Hu"
      ],
      "abstract": "The integration of large language models (LLMs) into information retrieval\nsystems introduces new attack surfaces, particularly for adversarial ranking\nmanipulations. We present StealthRank, a novel adversarial ranking attack that\nmanipulates LLM-driven product recommendation systems while maintaining textual\nfluency and stealth. Unlike existing methods that often introduce detectable\nanomalies, StealthRank employs an energy-based optimization framework combined\nwith Langevin dynamics to generate StealthRank Prompts (SRPs)-adversarial text\nsequences embedded within product descriptions that subtly yet effectively\ninfluence LLM ranking mechanisms. We evaluate StealthRank across multiple LLMs,\ndemonstrating its ability to covertly boost the ranking of target products\nwhile avoiding explicit manipulation traces that can be easily detected. Our\nresults show that StealthRank consistently outperforms state-of-the-art\nadversarial ranking baselines in both effectiveness and stealth, highlighting\ncritical vulnerabilities in LLM-driven recommendation systems.",
      "tldr_zh": "本研究提出StealthRank，一种针对LLM（Large Language Models）驱动的信息检索系统的隐秘对抗性排名攻击方法，能够操纵产品推荐排名同时保持文本流畅性，避免可检测异常。StealthRank采用基于能量的优化框架结合Langevin dynamics生成StealthRank Prompts (SRPs)，这些对抗性文本序列嵌入产品描述中， subtlety影响LLM的排名机制。实验结果显示，StealthRank在多个LLMs上表现优于现有基线，在有效性（如提升目标产品排名）和隐秘性方面均有显著优势，揭示了LLM驱动推荐系统的关键漏洞。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05804v1",
      "published_date": "2025-04-08 08:36:18 UTC",
      "updated_date": "2025-04-08 08:36:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:57:58.886307"
    },
    {
      "arxiv_id": "2504.05801v1",
      "title": "From Superficial to Deep: Integrating External Knowledge for Follow-up Question Generation Using Knowledge Graph and LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Jianyu Liu",
        "Yi Huang",
        "Sheng Bi",
        "Junlan Feng",
        "Guilin Qi"
      ],
      "abstract": "In a conversational system, dynamically generating follow-up questions based\non context can help users explore information and provide a better user\nexperience. Humans are usually able to ask questions that involve some general\nlife knowledge and demonstrate higher order cognitive skills. However, the\nquestions generated by existing methods are often limited to shallow contextual\nquestions that are uninspiring and have a large gap to the human level. In this\npaper, we propose a three-stage external knowledge-enhanced follow-up question\ngeneration method, which generates questions by identifying contextual topics,\nconstructing a knowledge graph (KG) online, and finally combining these with a\nlarge language model to generate the final question. The model generates\ninformation-rich and exploratory follow-up questions by introducing external\ncommon sense knowledge and performing a knowledge fusion operation. Experiments\nshow that compared to baseline models, our method generates questions that are\nmore informative and closer to human questioning levels while maintaining\ncontextual relevance.",
      "tldr_zh": "本研究针对对话系统中后续问题生成的局限性，提出一种三阶段外部知识增强方法，以解决现有模型生成的浅层问题无法达到人类认知水平的问题。该方法通过识别上下文主题、在线构建知识图谱（KG），并结合大语言模型（LLM）进行知识融合，生成更具信息性和探索性的后续问题。实验结果表明，与基线模型相比，该方法产生的問題更接近人类提问水平，同时保持了上下文相关性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Proceedings of the 31st International Conference on Computational\n  Linguistics",
      "pdf_url": "http://arxiv.org/pdf/2504.05801v1",
      "published_date": "2025-04-08 08:31:03 UTC",
      "updated_date": "2025-04-08 08:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:58:11.958105"
    },
    {
      "arxiv_id": "2504.10500v1",
      "title": "Leveraging Auto-Distillation and Generative Self-Supervised Learning in Residual Graph Transformers for Enhanced Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Eya Mhedhbi",
        "Youssef Mourchid",
        "Alice Othmani"
      ],
      "abstract": "This paper introduces a cutting-edge method for enhancing recommender systems\nthrough the integration of generative self-supervised learning (SSL) with a\nResidual Graph Transformer. Our approach emphasizes the importance of superior\ndata enhancement through the use of pertinent pretext tasks, automated through\nrationale-aware SSL to distill clear ways of how users and items interact. The\nResidual Graph Transformer incorporates a topology-aware transformer for global\ncontext and employs residual connections to improve graph representation\nlearning. Additionally, an auto-distillation process refines self-supervised\nsignals to uncover consistent collaborative rationales. Experimental\nevaluations on multiple datasets demonstrate that our approach consistently\noutperforms baseline methods.",
      "tldr_zh": "本文提出了一种增强推荐系统的方法，通过整合生成式 self-supervised learning 和 Residual Graph Transformer，利用 rationale-aware SSL 自动处理前置任务，以提炼用户和物品互动的协作理性。Residual Graph Transformer 采用 topology-aware transformer 处理全局上下文，并通过 residual connections 改进图表示学习，同时 auto-distillation 过程优化自监督信号。实验在多个数据集上显示，该方法 consistently outperforms baseline methods，在推荐性能方面取得了显著提升。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10500v1",
      "published_date": "2025-04-08 08:15:04 UTC",
      "updated_date": "2025-04-08 08:15:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:58:24.185027"
    },
    {
      "arxiv_id": "2504.05786v1",
      "title": "How to Enable LLM with 3D Capacity? A Survey of Spatial Reasoning in LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Jirong Zha",
        "Yuxuan Fan",
        "Xiao Yang",
        "Chen Gao",
        "Xinlei Chen"
      ],
      "abstract": "3D spatial understanding is essential in real-world applications such as\nrobotics, autonomous vehicles, virtual reality, and medical imaging. Recently,\nLarge Language Models (LLMs), having demonstrated remarkable success across\nvarious domains, have been leveraged to enhance 3D understanding tasks, showing\npotential to surpass traditional computer vision methods. In this survey, we\npresent a comprehensive review of methods integrating LLMs with 3D spatial\nunderstanding. We propose a taxonomy that categorizes existing methods into\nthree branches: image-based methods deriving 3D understanding from 2D visual\ndata, point cloud-based methods working directly with 3D representations, and\nhybrid modality-based methods combining multiple data streams. We\nsystematically review representative methods along these categories, covering\ndata representations, architectural modifications, and training strategies that\nbridge textual and 3D modalities. Finally, we discuss current limitations,\nincluding dataset scarcity and computational challenges, while highlighting\npromising research directions in spatial perception, multi-modal fusion, and\nreal-world applications.",
      "tldr_zh": "这篇调查论文探讨了如何赋予大型语言模型（LLMs）以 3D 空间推理能力，强调其在机器人、自动驾驶、虚拟现实和医疗成像等领域的潜力。作者提出一个分类法，将现有方法分为基于图像（从 2D 视觉数据推导出 3D 理解）、基于点云（直接处理 3D 表示）和混合模态（结合多种数据流）三类，并系统回顾了这些类别中的代表性方法，包括数据表示、架构修改和训练策略。论文指出了当前限制，如数据集稀缺和计算挑战，并突出了未来研究方向，包括空间感知、多模态融合和实际应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05786v1",
      "published_date": "2025-04-08 08:11:39 UTC",
      "updated_date": "2025-04-08 08:11:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:58:36.067265"
    },
    {
      "arxiv_id": "2504.05783v1",
      "title": "Video Flow as Time Series: Discovering Temporal Consistency and Variability for VideoQA",
      "title_zh": "视频流作为时间序列：发现 VideoQA 的时间一致性和变异性",
      "authors": [
        "Zijie Song",
        "Zhenzhen Hu",
        "Yixiao Ma",
        "Jia Li",
        "Richang Hong"
      ],
      "abstract": "Video Question Answering (VideoQA) is a complex video-language task that\ndemands a sophisticated understanding of both visual content and temporal\ndynamics. Traditional Transformer-style architectures, while effective in\nintegrating multimodal data, often simplify temporal dynamics through\npositional encoding and fail to capture non-linear interactions within video\nsequences. In this paper, we introduce the Temporal Trio Transformer (T3T), a\nnovel architecture that models time consistency and time variability. The T3T\nintegrates three key components: Temporal Smoothing (TS), Temporal Difference\n(TD), and Temporal Fusion (TF). The TS module employs Brownian Bridge for\ncapturing smooth, continuous temporal transitions, while the TD module\nidentifies and encodes significant temporal variations and abrupt changes\nwithin the video content. Subsequently, the TF module synthesizes these\ntemporal features with textual cues, facilitating a deeper contextual\nunderstanding and response accuracy. The efficacy of the T3T is demonstrated\nthrough extensive testing on multiple VideoQA benchmark datasets. Our results\nunderscore the importance of a nuanced approach to temporal modeling in\nimproving the accuracy and depth of video-based question answering.",
      "tldr_zh": "本论文针对 VideoQA 的视觉内容和时间动态建模挑战，提出了一种新架构 Temporal Trio Transformer (T3T)，它通过捕捉时间一致性和变异性来改善传统 Transformer 的不足。T3T 包括三个关键组件：Temporal Smoothing (TS) 使用 Brownian Bridge 处理平滑时间过渡、Temporal Difference (TD) 识别显著变化，以及 Temporal Fusion (TF) 整合这些时间特征与文本线索，以提升上下文理解和响应准确性。在多个 VideoQA 基准数据集上的实验结果表明，该方法显著提高了问答的准确性和深度，强调了细致时间建模的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05783v1",
      "published_date": "2025-04-08 08:08:03 UTC",
      "updated_date": "2025-04-08 08:08:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:58:49.230583"
    },
    {
      "arxiv_id": "2504.05782v1",
      "title": "MDK12-Bench: A Multi-Discipline Benchmark for Evaluating Reasoning in Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Zhou",
        "Fanrui Zhang",
        "Xiaopeng Peng",
        "Zhaopan Xu",
        "Jiaxin Ai",
        "Yansheng Qiu",
        "Chuanhao Li",
        "Zhen Li",
        "Ming Li",
        "Yukang Feng",
        "Jianwen Sun",
        "Haoquan Zhang",
        "Zizhen Li",
        "Xiaofeng Mao",
        "Wangbo Zhao",
        "Kai Wang",
        "Xiaojun Chang",
        "Wenqi Shao",
        "Yang You",
        "Kaipeng Zhang"
      ],
      "abstract": "Multimodal reasoning, which integrates language and visual cues into problem\nsolving and decision making, is a fundamental aspect of human intelligence and\na crucial step toward artificial general intelligence. However, the evaluation\nof multimodal reasoning capabilities in Multimodal Large Language Models\n(MLLMs) remains inadequate. Most existing reasoning benchmarks are constrained\nby limited data size, narrow domain coverage, and unstructured knowledge\ndistribution. To close these gaps, we introduce MDK12-Bench, a\nmulti-disciplinary benchmark assessing the reasoning capabilities of MLLMs via\nreal-world K-12 examinations. Spanning six disciplines (math, physics,\nchemistry, biology, geography, and information science), our benchmark\ncomprises 140K reasoning instances across diverse difficulty levels from\nprimary school to 12th grade. It features 6,827 instance-level knowledge point\nannotations based on a well-organized knowledge structure, detailed answer\nexplanations, difficulty labels and cross-year partitions, providing a robust\nplatform for comprehensive evaluation. Additionally, we present a novel dynamic\nevaluation framework to mitigate data contamination issues by bootstrapping\nquestion forms, question types, and image styles during evaluation. Extensive\nexperiment on MDK12-Bench reveals the significant limitation of current MLLMs\nin multimodal reasoning. The findings on our benchmark provide insights into\nthe development of the next-generation models. Our data and codes are available\nat https://github.com/LanceZPF/MDK12.",
      "tldr_zh": "本研究引入了MDK12-Bench，一种多学科基准，用于评估Multimodal Large Language Models (MLLMs)在多模态推理能力方面的表现，旨在解决现有基准数据规模小、领域覆盖窄和知识分布不结构化等问题。该基准涵盖数学、物理、化学、生物、地理和信息科学六大领域，总计包含14万余个推理实例，难度从小学到12年级，并附带6,827个知识点注解、答案解释、难度标签和跨年分区，以提供全面评估平台。同时，该框架引入了一个新型动态评估方法，通过引导问题形式、类型和图像样式来缓解数据污染问题；实验结果揭示了当前MLLMs在多模态推理中的显著局限性，并为下一代模型开发提供宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05782v1",
      "published_date": "2025-04-08 08:06:53 UTC",
      "updated_date": "2025-04-08 08:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:58:59.979351"
    },
    {
      "arxiv_id": "2504.05774v1",
      "title": "Transferable Mask Transformer: Cross-domain Semantic Segmentation with Region-adaptive Transferability Estimation",
      "title_zh": "Transferable Mask Transformer：基于区域自适应可转移性估计的跨域语义分割",
      "authors": [
        "Enming Zhang",
        "Zhengyu Li",
        "Yanru Wu",
        "Jingge Wang",
        "Yang Tan",
        "Ruizhe Zhao",
        "Guan Wang",
        "Yang Li"
      ],
      "abstract": "Recent advances in Vision Transformers (ViTs) have set new benchmarks in\nsemantic segmentation. However, when adapting pretrained ViTs to new target\ndomains, significant performance degradation often occurs due to distribution\nshifts, resulting in suboptimal global attention. Since self-attention\nmechanisms are inherently data-driven, they may fail to effectively attend to\nkey objects when source and target domains exhibit differences in texture,\nscale, or object co-occurrence patterns. While global and patch-level domain\nadaptation methods provide partial solutions, region-level adaptation with\ndynamically shaped regions is crucial due to spatial heterogeneity in\ntransferability across different image areas. We present Transferable Mask\nTransformer (TMT), a novel region-level adaptation framework for semantic\nsegmentation that aligns cross-domain representations through spatial\ntransferability analysis. TMT consists of two key components: (1) An Adaptive\nCluster-based Transferability Estimator (ACTE) that dynamically segments images\ninto structurally and semantically coherent regions for localized\ntransferability assessment, and (2) A Transferable Masked Attention (TMA)\nmodule that integrates region-specific transferability maps into ViTs'\nattention mechanisms, prioritizing adaptation in regions with low\ntransferability and high semantic uncertainty. Comprehensive evaluations across\n20 cross-domain pairs demonstrate TMT's superiority, achieving an average 2%\nMIoU improvement over vanilla fine-tuning and a 1.28% increase compared to\nstate-of-the-art baselines. The source code will be publicly available.",
      "tldr_zh": "本文提出 Transferable Mask Transformer (TMT)，一种针对跨域语义分割的创新框架，用于解决预训练 Vision Transformers (ViTs) 因分布偏移导致的性能下降问题，特别是自注意力机制在纹理、规模或物体共现差异下的失效。TMT 包括两个关键组件：Adaptive Cluster-based Transferability Estimator (ACTE)，用于动态将图像分割成结构和语义连贯的区域进行局部可转移性评估；以及 Transferable Masked Attention (TMA)，通过整合区域特定转移性映射优先适应低转移性和高语义不确定性的区域。在20对跨域任务的全面评估中，TMT 比传统微调提高了平均2% MIoU，并比最先进基线提升1.28%，展示了其在区域级适配方面的显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05774v1",
      "published_date": "2025-04-08 07:53:51 UTC",
      "updated_date": "2025-04-08 07:53:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:59:14.394305"
    },
    {
      "arxiv_id": "2504.05770v1",
      "title": "A Lightweight Multi-Module Fusion Approach for Korean Character Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Inho Jake Park",
        "Jaehoon Jay Jeong",
        "Ho-Sang Jo"
      ],
      "abstract": "Optical Character Recognition (OCR) is essential in applications such as\ndocument processing, license plate recognition, and intelligent surveillance.\nHowever, existing OCR models often underperform in real-world scenarios due to\nirregular text layouts, poor image quality, character variability, and high\ncomputational costs.\n  This paper introduces SDA-Net (Stroke-Sensitive Attention and Dynamic Context\nEncoding Network), a lightweight and efficient architecture designed for robust\nsingle-character recognition. SDA-Net incorporates: (1) a Dual Attention\nMechanism to enhance stroke-level and spatial feature extraction; (2) a Dynamic\nContext Encoding module that adaptively refines semantic information using a\nlearnable gating mechanism; (3) a U-Net-inspired Feature Fusion Strategy for\ncombining low-level and high-level features; and (4) a highly optimized\nlightweight backbone that reduces memory and computational demands.\n  Experimental results show that SDA-Net achieves state-of-the-art accuracy on\nchallenging OCR benchmarks, with significantly faster inference, making it\nwell-suited for deployment in real-time and edge-based OCR systems.",
      "tldr_zh": "这篇论文针对Optical Character Recognition (OCR) 在真实场景中的挑战，如不规则文本布局和图像质量问题，提出了一种轻量级多模块融合方法SDA-Net，用于韩国字符识别。SDA-Net 整合了Dual Attention Mechanism 以增强笔划级和空间特征提取、Dynamic Context Encoding 模块通过可学习门控机制自适应优化语义信息、U-Net-inspired Feature Fusion Strategy 结合低级和高级特征，以及一个优化后的轻量级骨干网络，以降低计算需求。实验结果表明，SDA-Net 在挑战性OCR基准上实现了最先进准确率，同时推理速度显著提升，适用于实时和边缘设备部署。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.05770v1",
      "published_date": "2025-04-08 07:50:19 UTC",
      "updated_date": "2025-04-08 07:50:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:59:23.674016"
    },
    {
      "arxiv_id": "2504.05768v1",
      "title": "Temporal Dynamic Embedding for Irregularly Sampled Time Series",
      "title_zh": "针对不规则采样时间序列的时序动态嵌入",
      "authors": [
        "Mincheol Kim",
        "Soo-Yong Shin"
      ],
      "abstract": "In several practical applications, particularly healthcare, clinical data of\neach patient is individually recorded in a database at irregular intervals as\nrequired. This causes a sparse and irregularly sampled time series, which makes\nit difficult to handle as a structured representation of the prerequisites of\nneural network models. We therefore propose temporal dynamic embedding (TDE),\nwhich enables neural network models to receive data that change the number of\nvariables over time. TDE regards each time series variable as an embedding\nvector evolving over time, instead of a conventional fixed structured\nrepresentation, which causes a critical missing problem. For each time step,\nTDE allows for the selective adoption and aggregation of only observed variable\nsubsets and represents the current status of patient based on current\nobservations. The experiment was conducted on three clinical datasets:\nPhysioNet 2012, MIMIC-III, and PhysioNet 2019. The TDE model performed\ncompetitively or better than the imputation-based baseline and several recent\nstate-of-the-art methods with reduced training runtime.",
      "tldr_zh": "本研究针对医疗等领域的不规则采样时间序列问题，提出了一种Temporal Dynamic Embedding (TDE)方法，以处理数据稀疏和变量数量随时间变化的挑战。TDE将每个时间序列变量视为随时间演化的嵌入向量，并通过选择性采用和聚合观察到的变量子集，来表示当前状态，如患者实时状况，从而避免了传统固定结构表示的缺失问题。在PhysioNet 2012、MIMIC-III和PhysioNet 2019三个临床数据集上的实验表明，TDE模型的性能与基于插值的基线方法和最新先进方法相当或更优，同时显著减少了训练运行时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05768v1",
      "published_date": "2025-04-08 07:49:22 UTC",
      "updated_date": "2025-04-08 07:49:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:59:34.911724"
    },
    {
      "arxiv_id": "2504.05755v2",
      "title": "Unraveling Human-AI Teaming: A Review and Outlook",
      "title_zh": "揭示人类-AI 团队合作：回顾与展望",
      "authors": [
        "Bowen Lou",
        "Tian Lu",
        "T. S. Raghu",
        "Yingjie Zhang"
      ],
      "abstract": "Artificial Intelligence (AI) is advancing at an unprecedented pace, with\nclear potential to enhance decision-making and productivity. Yet, the\ncollaborative decision-making process between humans and AI remains\nunderdeveloped, often falling short of its transformative possibilities. This\npaper explores the evolution of AI agents from passive tools to active\ncollaborators in human-AI teams, emphasizing their ability to learn, adapt, and\noperate autonomously in complex environments. This paradigm shifts challenges\ntraditional team dynamics, requiring new interaction protocols, delegation\nstrategies, and responsibility distribution frameworks. Drawing on Team\nSituation Awareness (SA) theory, we identify two critical gaps in current\nhuman-AI teaming research: the difficulty of aligning AI agents with human\nvalues and objectives, and the underutilization of AI's capabilities as genuine\nteam members. Addressing these gaps, we propose a structured research outlook\ncentered on four key aspects of human-AI teaming: formulation, coordination,\nmaintenance, and training. Our framework highlights the importance of shared\nmental models, trust-building, conflict resolution, and skill adaptation for\neffective teaming. Furthermore, we discuss the unique challenges posed by\nvarying team compositions, goals, and complexities. This paper provides a\nfoundational agenda for future research and practical design of sustainable,\nhigh-performing human-AI teams.",
      "tldr_zh": "这篇论文审视了人工智能(AI)从被动工具向主动合作者的演变，强调人类-AI团队协作在决策和生产力提升中的潜力，但也指出当前协作过程存在不足。基于Team Situation Awareness (SA)理论，作者识别了两个关键差距：AI与人类价值观及目标的对齐困难，以及AI作为团队成员能力的未充分利用。论文提出一个结构化的研究框架，聚焦于人类-AI团队的制定、协调、维护和训练四个方面，包括共享心理模型、建立信任、解决冲突和技能适应。最终，该研究为未来构建可持续、高性能人类-AI团队提供了基础议程和实践指导。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05755v2",
      "published_date": "2025-04-08 07:37:25 UTC",
      "updated_date": "2025-04-09 12:20:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:59:47.515625"
    },
    {
      "arxiv_id": "2504.07140v2",
      "title": "Secure Text Mail Encryption with Generative Adversarial Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Alexej Schelle"
      ],
      "abstract": "This work presents an encryption model based on Generative Adversarial\nNetworks (GANs). Encryption of RTF-8 data is realized by dynamically generating\ndecimal numbers that lead to the encryption and decryption of alphabetic\nstrings in integer representation by simple addition rules, the modulus of the\ndimension of the considered alphabet. The binary numbers for the private\ndynamic keys correspond to the binary numbers of public reference keys, as\ndefined by a specific GAN configuration. For reversible encryption with a\nbijective mapping between dynamic and reference keys, as defined by the GAN\nencryptor, secure text encryption can be achieved by transferring a\nGAN-encrypted public key along with the encrypted text from a sender to a\nreceiver. Using the technique described above, secure text mail transfer can be\nrealized through component-wise encryption and decryption of text mail strings,\nwith total key sizes of up to $10^{8}$ bits that define random decimal numbers\ngenerated by the GAN. From the present model, we assert that encrypted texts\ncan be transmitted more efficiently and securely than from RSA encryption, as\nlong as users of the specific configuration of the GAN encryption model are\nunaware of the GAN encryptor circuit and configuration, respectively.",
      "tldr_zh": "这篇论文提出了一种基于 Generative Adversarial Networks (GANs) 的安全文本邮件加密模型，用于加密 RTF-8 数据，通过动态生成十进制数和简单加法规则实现字母字符串的加密与解密。模型利用 GAN 配置生成动态私钥与公共参考密钥的对应关系，确保加密过程可逆，并通过传输 GAN-加密的公共密钥来实现安全传输。研究声称，该方法在密钥大小达 10^8 位的条件下，比 RSA 加密更高效和安全，前提是用户不知晓 GAN 加密器的电路和配置。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 3 figures, one table; Preprint before publication",
      "pdf_url": "http://arxiv.org/pdf/2504.07140v2",
      "published_date": "2025-04-08 07:27:57 UTC",
      "updated_date": "2025-04-14 10:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:59:59.293476"
    },
    {
      "arxiv_id": "2504.05741v2",
      "title": "DDT: Decoupled Diffusion Transformer",
      "title_zh": "DDT：解耦扩散Transformer",
      "authors": [
        "Shuai Wang",
        "Zhi Tian",
        "Weilin Huang",
        "Limin Wang"
      ],
      "abstract": "Diffusion transformers have demonstrated remarkable generation quality,\nalbeit requiring longer training iterations and numerous inference steps. In\neach denoising step, diffusion transformers encode the noisy inputs to extract\nthe lower-frequency semantic component and then decode the higher frequency\nwith identical modules. This scheme creates an inherent optimization dilemma:\nencoding low-frequency semantics necessitates reducing high-frequency\ncomponents, creating tension between semantic encoding and high-frequency\ndecoding. To resolve this challenge, we propose a new\n\\textbf{\\color{ddt}D}ecoupled \\textbf{\\color{ddt}D}iffusion\n\\textbf{\\color{ddt}T}ransformer~(\\textbf{\\color{ddt}DDT}), with a decoupled\ndesign of a dedicated condition encoder for semantic extraction alongside a\nspecialized velocity decoder. Our experiments reveal that a more substantial\nencoder yields performance improvements as model size increases. For ImageNet\n$256\\times256$, Our DDT-XL/2 achieves a new state-of-the-art performance of\n{1.31 FID}~(nearly $4\\times$ faster training convergence compared to previous\ndiffusion transformers). For ImageNet $512\\times512$, Our DDT-XL/2 achieves a\nnew state-of-the-art FID of 1.28. Additionally, as a beneficial by-product, our\ndecoupled architecture enhances inference speed by enabling the sharing\nself-condition between adjacent denoising steps. To minimize performance\ndegradation, we propose a novel statistical dynamic programming approach to\nidentify optimal sharing strategies.",
      "tldr_zh": "这篇论文针对扩散变换器（Diffusion Transformers）在去噪步骤中存在的优化困境——即编码低频语义组件与解码高频组件的冲突——提出了DDT（Decoupled Diffusion Transformer）。DDT 通过解耦设计，使用专用条件编码器提取语义信息和专用速度解码器处理高频细节，从而提高了模型的训练和推理效率。实验结果显示，在ImageNet 256×256上，DDT-XL/2 达到了1.31 FID的新状态-of-the-art性能，训练收敛速度快4倍；在512×512上达到1.28 FID；此外，该架构还通过共享自条件和统计动态编程方法优化了推理速度，减少了性能损失。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "sota on ImageNet256 and ImageNet512",
      "pdf_url": "http://arxiv.org/pdf/2504.05741v2",
      "published_date": "2025-04-08 07:17:45 UTC",
      "updated_date": "2025-04-09 04:23:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:00:12.396758"
    },
    {
      "arxiv_id": "2504.05736v1",
      "title": "Rank-Then-Score: Enhancing Large Language Models for Automated Essay Scoring",
      "title_zh": "Rank-Then-Score：增强大型语言模型用于自动作文评分",
      "authors": [
        "Yida Cai",
        "Kun Liang",
        "Sanwoo Lee",
        "Qinghan Wang",
        "Yunfang Wu"
      ],
      "abstract": "In recent years, large language models (LLMs) achieve remarkable success\nacross a variety of tasks. However, their potential in the domain of Automated\nEssay Scoring (AES) remains largely underexplored. Moreover, compared to\nEnglish data, the methods for Chinese AES is not well developed. In this paper,\nwe propose Rank-Then-Score (RTS), a fine-tuning framework based on large\nlanguage models to enhance their essay scoring capabilities. Specifically, we\nfine-tune the ranking model (Ranker) with feature-enriched data, and then feed\nthe output of the ranking model, in the form of a candidate score set, with the\nessay content into the scoring model (Scorer) to produce the final score.\nExperimental results on two benchmark datasets, HSK and ASAP, demonstrate that\nRTS consistently outperforms the direct prompting (Vanilla) method in terms of\naverage QWK across all LLMs and datasets, and achieves the best performance on\nChinese essay scoring using the HSK dataset.",
      "tldr_zh": "本文提出 Rank-Then-Score (RTS) 框架，以提升 Large Language Models (LLMs) 在 Automated Essay Scoring (AES) 中的性能，特别是针对中文作文评分领域的不足。RTS 通过微调排名模型 (Ranker) 处理特征丰富的数据，然后将排名输出作为候选分数集与作文内容输入评分模型 (Scorer)，从而生成更准确的最终分数。在 HSK 和 ASAP 数据集上的实验结果表明，RTS 在平均 QWK 上 consistently 优于直接提示 (Vanilla) 方法，并在中文作文评分中实现了最佳性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.05736v1",
      "published_date": "2025-04-08 07:10:51 UTC",
      "updated_date": "2025-04-08 07:10:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:00:23.750957"
    },
    {
      "arxiv_id": "2504.05728v1",
      "title": "AI-Driven Prognostics for State of Health Prediction in Li-ion Batteries: A Comprehensive Analysis with Validation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianqi Ding",
        "Dawei Xiang",
        "Tianyao Sun",
        "YiJiashum Qi",
        "Zunduo Zhao"
      ],
      "abstract": "This paper presents a comprehensive review of AI-driven prognostics for State\nof Health (SoH) prediction in lithium-ion batteries. We compare the\neffectiveness of various AI algorithms, including FFNN, LSTM, and BiLSTM,\nacross multiple datasets (CALCE, NASA, UDDS) and scenarios (e.g., varying\ntemperatures and driving conditions). Additionally, we analyze the factors\ninfluencing SoH fluctuations, such as temperature and charge-discharge rates,\nand validate our findings through simulations. The results demonstrate that\nBiLSTM achieves the highest accuracy, with an average RMSE reduction of 15%\ncompared to LSTM, highlighting its robustness in real-world applications.",
      "tldr_zh": "这篇论文对AI驱动的锂离子电池健康状态（SoH）预测进行了全面分析和验证，比较了FFNN、LSTM和BiLSTM等算法在CALCE、NASA和UDDS数据集上的表现，并考虑了不同温度和驾驶条件等场景。研究分析了影响SoH波动的关键因素，如温度和充放电率，通过模拟验证了这些发现。结果表明，BiLSTM的准确性最高，平均RMSE比LSTM降低了15%，突显了其在实际应用中的鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 12 figures, Accepted by 2025 6th International Conference on\n  Electrical Technology and Automatic Control(ICETAC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.05728v1",
      "published_date": "2025-04-08 06:58:39 UTC",
      "updated_date": "2025-04-08 06:58:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:00:35.799181"
    },
    {
      "arxiv_id": "2504.05711v1",
      "title": "Automated Archival Descriptions with Federated Intelligence of LLMs",
      "title_zh": "利用 LLMs 联邦智能的自动档案描述",
      "authors": [
        "Jinghua Groppe",
        "Andreas Marquet",
        "Annabel Walz",
        "Sven Groppe"
      ],
      "abstract": "Enforcing archival standards requires specialized expertise, and manually\ncreating metadata descriptions for archival materials is a tedious and\nerror-prone task. This work aims at exploring the potential of agentic AI and\nlarge language models (LLMs) in addressing the challenges of implementing a\nstandardized archival description process. To this end, we introduce an agentic\nAI-driven system for automated generation of high-quality metadata descriptions\nof archival materials. We develop a federated optimization approach that unites\nthe intelligence of multiple LLMs to construct optimal archival metadata. We\nalso suggest methods to overcome the challenges associated with using LLMs for\nconsistent metadata generation. To evaluate the feasibility and effectiveness\nof our techniques, we conducted extensive experiments using a real-world\ndataset of archival materials, which covers a variety of document types and\ndata formats. The evaluation results demonstrate the feasibility of our\ntechniques and highlight the superior performance of the federated optimization\napproach compared to single-model solutions in metadata quality and\nreliability.",
      "tldr_zh": "该研究针对档案标准实施的挑战，提出了一种基于代理AI和大型语言模型(LLMs)的系统，用于自动生成高质量的档案材料元数据描述，以减少手动操作的繁琐和错误。核心方法是开发联邦优化(federated optimization)方法，将多个LLMs的智能整合起来构建最佳元数据，并解决LLMs在一致性生成中的问题。通过使用真实世界数据集进行实验，该方法在各种文档类型和格式上表现出色，比单一模型方案在元数据质量和可靠性上提升显著。整体结果验证了代理AI在标准化档案描述中的可行性和潜力。",
      "categories": [
        "cs.AI",
        "cs.DL",
        "cs.IR",
        "cs.LG",
        "I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.05711v1",
      "published_date": "2025-04-08 06:11:05 UTC",
      "updated_date": "2025-04-08 06:11:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:00:46.785618"
    },
    {
      "arxiv_id": "2504.05695v3",
      "title": "Architecture independent generalization bounds for overparametrized deep ReLU networks",
      "title_zh": "过参数化深度 ReLU 网络的架构无关泛化界",
      "authors": [
        "Thomas Chen",
        "Chun-Kai Kevin Chien",
        "Patricia Muñoz Ewald",
        "Andrew G. Moore"
      ],
      "abstract": "We prove that overparametrized neural networks are able to generalize with a\ntest error that is independent of the level of overparametrization, and\nindependent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds\nthat only depend on the metric geometry of the test and training sets, on the\nregularity properties of the activation function, and on the operator norms of\nthe weights and norms of biases. For overparametrized deep ReLU networks with a\ntraining sample size bounded by the input space dimension, we explicitly\nconstruct zero loss minimizers without use of gradient descent, and prove that\nthe generalization error is independent of the network architecture.",
      "tldr_zh": "本论文证明了overparametrized deep ReLU networks的泛化边界与网络过参数化程度和Vapnik-Chervonenkis (VC) dimension无关，仅取决于测试集和训练集的度量几何、激活函数的正则性以及权重和偏差的范数。研究者显式构造了零损失最小化器（无需梯度下降），适用于训练样本大小不超过输入空间维度的场景。结果显示，这些网络的泛化错误独立于网络架构，从而为理解神经网络泛化提供了新的理论洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AP",
        "math.OC",
        "stat.ML",
        "57R70, 62M45"
      ],
      "primary_category": "cs.LG",
      "comment": "AMS Latex, 13 pages. Both main theorems are now in Section 1",
      "pdf_url": "http://arxiv.org/pdf/2504.05695v3",
      "published_date": "2025-04-08 05:37:38 UTC",
      "updated_date": "2025-05-22 15:45:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:00:59.636963"
    },
    {
      "arxiv_id": "2504.05694v2",
      "title": "Large Language Models Enhanced Hyperbolic Space Recommender Systems",
      "title_zh": "大语言模型增强的双曲空间推荐系统",
      "authors": [
        "Wentao Cheng",
        "Zhida Qin",
        "Zexue Wu",
        "Pengzhan Zhou",
        "Tianyu Huang"
      ],
      "abstract": "Large Language Models (LLMs) have attracted significant attention in\nrecommender systems for their excellent world knowledge capabilities. However,\nexisting methods that rely on Euclidean space struggle to capture the rich\nhierarchical information inherent in textual and semantic data, which is\nessential for capturing user preferences. The geometric properties of\nhyperbolic space offer a promising solution to address this issue.\nNevertheless, integrating LLMs-based methods with hyperbolic space to\neffectively extract and incorporate diverse hierarchical information is\nnon-trivial. To this end, we propose a model-agnostic framework, named\nHyperLLM, which extracts and integrates hierarchical information from both\nstructural and semantic perspectives. Structurally, HyperLLM uses LLMs to\ngenerate multi-level classification tags with hierarchical parent-child\nrelationships for each item. Then, tag-item and user-item interactions are\njointly learned and aligned through contrastive learning, thereby providing the\nmodel with clear hierarchical information. Semantically, HyperLLM introduces a\nnovel meta-optimized strategy to extract hierarchical information from semantic\nembeddings and bridge the gap between the semantic and collaborative spaces for\nseamless integration. Extensive experiments show that HyperLLM significantly\noutperforms recommender systems based on hyperbolic space and LLMs, achieving\nperformance improvements of over 40%. Furthermore, HyperLLM not only improves\nrecommender performance but also enhances training stability, highlighting the\ncritical role of hierarchical information in recommender systems.",
      "tldr_zh": "这篇论文提出了一种模型无关框架HyperLLM，将Large Language Models (LLMs)与Hyperbolic Space整合，以更好地捕获文本和语义数据的层次信息，从而提升推荐系统的用户偏好建模。框架从结构角度使用LLMs生成多级分类标签并通过contrastive learning联合学习标签-物品和用户-物品交互；从语义角度引入元优化策略，从语义嵌入中提取层次信息并桥接语义空间与协作空间。实验结果表明，HyperLLM相较于基于Hyperbolic Space和LLMs的基线方法，性能提升超过40%，并显著提高了训练稳定性，突显了层次信息在推荐系统中的关键作用。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted as a SIGIR'25 full paper",
      "pdf_url": "http://arxiv.org/pdf/2504.05694v2",
      "published_date": "2025-04-08 05:35:38 UTC",
      "updated_date": "2025-04-19 14:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:01:11.869059"
    },
    {
      "arxiv_id": "2504.05693v1",
      "title": "STRIVE: A Think & Improve Approach with Iterative Refinement for Enhancing Question Quality Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Aniket Deroy",
        "Subhankar Maity"
      ],
      "abstract": "Automatically assessing question quality is crucial for educators as it saves\ntime, ensures consistency, and provides immediate feedback for refining\nteaching materials. We propose a novel methodology called STRIVE (Structured\nThinking and Refinement with multiLLMs for Improving Verified Question\nEstimation) using a series of Large Language Models (LLMs) for automatic\nquestion evaluation. This approach aims to improve the accuracy and depth of\nquestion quality assessment, ultimately supporting diverse learners and\nenhancing educational practices. The method estimates question quality in an\nautomated manner by generating multiple evaluations based on the strengths and\nweaknesses of the provided question and then choosing the best solution\ngenerated by the LLM. Then the process is improved by iterative review and\nresponse with another LLM until the evaluation metric values converge. This\nsophisticated method of evaluating question quality improves the estimation of\nquestion quality by automating the task of question quality evaluation.\nCorrelation scores show that using this proposed method helps to improve\ncorrelation with human judgments compared to the baseline method. Error\nanalysis shows that metrics like relevance and appropriateness improve\nsignificantly relative to human judgments by using STRIVE.",
      "tldr_zh": "该研究提出了一种名为 STRIVE 的方法，用于提升问题质量评估的准确性和深度，旨在通过多 Large Language Models (LLMs) 实现自动评估，从而支持教育实践和多样化学习者。STRIVE 采用结构化思考和迭代改进策略，包括生成基于问题优势与劣势的多重评估、选择最佳方案，并通过另一个 LLM 进行反复审查直至评估指标收敛。实验结果显示，与基线方法相比，STRIVE 显著提高了与人类判断的相关性，特别是 relevance 和 appropriateness 等指标的改善。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05693v1",
      "published_date": "2025-04-08 05:34:38 UTC",
      "updated_date": "2025-04-08 05:34:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:01:22.450369"
    },
    {
      "arxiv_id": "2504.05691v1",
      "title": "StayLTC: A Cost-Effective Multimodal Framework for Hospital Length of Stay Forecasting",
      "title_zh": "StayLTC：一种成本有效的多模态框架，用于医院住院时长预测",
      "authors": [
        "Sudeshna Jana",
        "Manjira Sinha",
        "Tirthankar Dasgupta"
      ],
      "abstract": "Accurate prediction of Length of Stay (LOS) in hospitals is crucial for\nimproving healthcare services, resource management, and cost efficiency. This\npaper presents StayLTC, a multimodal deep learning framework developed to\nforecast real-time hospital LOS using Liquid Time-Constant Networks (LTCs).\nLTCs, with their continuous-time recurrent dynamics, are evaluated against\ntraditional models using structured data from Electronic Health Records (EHRs)\nand clinical notes. Our evaluation, conducted on the MIMIC-III dataset,\ndemonstrated that LTCs significantly outperform most of the other time series\nmodels, offering enhanced accuracy, robustness, and efficiency in resource\nutilization. Additionally, LTCs demonstrate a comparable performance in LOS\nprediction compared to time series large language models, while requiring\nsignificantly less computational power and memory, underscoring their potential\nto advance Natural Language Processing (NLP) tasks in healthcare.",
      "tldr_zh": "本研究提出了一种经济有效的多模态深度学习框架 StayLTC，用于预测医院住院时间（Length of Stay, LOS），以提升医疗服务、资源管理和成本效率。框架利用 Liquid Time-Constant Networks (LTCs) 模型，通过处理 Electronic Health Records (EHRs) 的结构化数据和临床笔记，实现实时 LOS 预测。实验在 MIMIC-III 数据集上显示，LTCs 在准确性、鲁棒性和资源利用效率上显著优于传统时间序列模型，且与时间序列大语言模型性能相当，但所需计算能力和内存大幅降低，从而为医疗领域的自然语言处理（NLP）任务提供潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05691v1",
      "published_date": "2025-04-08 05:27:53 UTC",
      "updated_date": "2025-04-08 05:27:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:01:35.156740"
    },
    {
      "arxiv_id": "2504.05686v1",
      "title": "kNN-SVC: Robust Zero-Shot Singing Voice Conversion with Additive Synthesis and Concatenation Smoothness Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Keren Shao",
        "Ke Chen",
        "Matthew Baas",
        "Shlomo Dubnov"
      ],
      "abstract": "Robustness is critical in zero-shot singing voice conversion (SVC). This\npaper introduces two novel methods to strengthen the robustness of the kNN-VC\nframework for SVC. First, kNN-VC's core representation, WavLM, lacks harmonic\nemphasis, resulting in dull sounds and ringing artifacts. To address this, we\nleverage the bijection between WavLM, pitch contours, and spectrograms to\nperform additive synthesis, integrating the resulting waveform into the model\nto mitigate these issues. Second, kNN-VC overlooks concatenative smoothness, a\nkey perceptual factor in SVC. To enhance smoothness, we propose a new distance\nmetric that filters out unsuitable kNN candidates and optimize the summing\nweights of the candidates during inference. Although our techniques are built\non the kNN-VC framework for implementation convenience, they are broadly\napplicable to general concatenative neural synthesis models. Experimental\nresults validate the effectiveness of these modifications in achieving robust\nSVC. Demo: http://knnsvc.com Code: https://github.com/SmoothKen/knn-svc",
      "tldr_zh": "这篇论文针对零样本唱歌语音转换（SVC）的鲁棒性问题，提出了两种改进kNN-VC框架的方法，以提升音频质量和感知效果。首先，通过additive synthesis技术利用WavLM、音高轮廓和频谱图之间的双射关系，整合波形合成来缓解WavLM的谐波不足问题，减少声音单调和伪像。其次，引入新的距离度量来过滤不合适的kNN候选，并优化候选的求和权重，以改善concatenation smoothness。最后，实验结果证明这些修改显著增强了SVC的鲁棒性，并适用于一般连接神经合成模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 6 figures, 1 table, Proceedings of the International\n  Conference on Acoustics, Speech, and Signal Processing, ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.05686v1",
      "published_date": "2025-04-08 04:59:56 UTC",
      "updated_date": "2025-04-08 04:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:01:48.169309"
    },
    {
      "arxiv_id": "2504.05684v1",
      "title": "TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Tri Ton",
        "Ji Woo Hong",
        "Chang D. Yoo"
      ],
      "abstract": "This paper introduces Timestep-Adaptive Representation Alignment with\nOnset-Aware Conditioning (TARO), a novel framework for high-fidelity and\ntemporally coherent video-to-audio synthesis. Built upon flow-based\ntransformers, which offer stable training and continuous transformations for\nenhanced synchronization and audio quality, TARO introduces two key\ninnovations: (1) Timestep-Adaptive Representation Alignment (TRA), which\ndynamically aligns latent representations by adjusting alignment strength based\non the noise schedule, ensuring smooth evolution and improved fidelity, and (2)\nOnset-Aware Conditioning (OAC), which integrates onset cues that serve as sharp\nevent-driven markers of audio-relevant visual moments to enhance\nsynchronization with dynamic visual events. Extensive experiments on the\nVGGSound and Landscape datasets demonstrate that TARO outperforms prior\nmethods, achieving relatively 53\\% lower Frechet Distance (FD), 29% lower\nFrechet Audio Distance (FAD), and a 97.19% Alignment Accuracy, highlighting its\nsuperior audio quality and synchronization precision.",
      "tldr_zh": "这篇论文提出了 TARO 框架，用于实现高保真和时间连贯的视频到音频合成，构建于 flow-based transformers 之上，以提升音频质量和同步性。\nTARO 的关键创新包括 Timestep-Adaptive Representation Alignment (TRA)，该方法根据噪声时间表动态调整潜在表示的对齐强度，确保平滑演化和保真度，以及 Onset-Aware Conditioning (OAC)，通过整合 onset 提示作为音频相关视觉事件的标记来加强动态同步。\n实验在 VGGSound 和 Landscape 数据集上表明，TARO 优于现有方法，Frechet Distance (FD) 相对降低 53%、Frechet Audio Distance (FAD) 降低 29%，并达到 97.19% 的 Alignment Accuracy。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.SD",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05684v1",
      "published_date": "2025-04-08 04:49:36 UTC",
      "updated_date": "2025-04-08 04:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:02:00.322256"
    },
    {
      "arxiv_id": "2504.05683v1",
      "title": "Towards Smarter Hiring: Are Zero-Shot and Few-Shot Pre-trained LLMs Ready for HR Spoken Interview Transcript Analysis?",
      "title_zh": "翻译失败",
      "authors": [
        "Subhankar Maity",
        "Aniket Deroy",
        "Sudeshna Sarkar"
      ],
      "abstract": "This research paper presents a comprehensive analysis of the performance of\nprominent pre-trained large language models (LLMs), including GPT-4 Turbo,\nGPT-3.5 Turbo, text-davinci-003, text-babbage-001, text-curie-001,\ntext-ada-001, llama-2-7b-chat, llama-2-13b-chat, and llama-2-70b-chat, in\ncomparison to expert human evaluators in providing scores, identifying errors,\nand offering feedback and improvement suggestions to candidates during mock HR\n(Human Resources) interviews. We introduce a dataset called HURIT (Human\nResource Interview Transcripts), which comprises 3,890 HR interview transcripts\nsourced from real-world HR interview scenarios. Our findings reveal that\npre-trained LLMs, particularly GPT-4 Turbo and GPT-3.5 Turbo, exhibit\ncommendable performance and are capable of producing evaluations comparable to\nthose of expert human evaluators. Although these LLMs demonstrate proficiency\nin providing scores comparable to human experts in terms of human evaluation\nmetrics, they frequently fail to identify errors and offer specific actionable\nadvice for candidate performance improvement in HR interviews. Our research\nsuggests that the current state-of-the-art pre-trained LLMs are not fully\nconducive for automatic deployment in an HR interview assessment. Instead, our\nfindings advocate for a human-in-the-loop approach, to incorporate manual\nchecks for inconsistencies and provisions for improving feedback quality as a\nmore suitable strategy.",
      "tldr_zh": "这篇论文评估了Zero-Shot和Few-Shot Pre-trained LLMs（如GPT-4 Turbo和GPT-3.5 Turbo）在HR面试转录分析中的性能，比较它们与人类专家在评分、错误识别和反馈建议方面的表现。研究引入了HURIT数据集，包含3,890个真实HR面试转录，用于测试这些模型的能力。结果显示，GPT-4 Turbo和GPT-3.5 Turbo在评分上可与人类专家媲美，但经常无法有效识别错误或提供具体的可行动改进建议。论文结论认为，当前LLMs不适合完全自动部署在HR面试评估中，建议采用人类参与的混合方法以提升准确性和反馈质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "32 pages, 24 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05683v1",
      "published_date": "2025-04-08 04:46:10 UTC",
      "updated_date": "2025-04-08 04:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:02:12.990598"
    },
    {
      "arxiv_id": "2504.05657v1",
      "title": "Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven Speech Anti-spoofing",
      "title_zh": "Nes2Net：",
      "authors": [
        "Tianchi Liu",
        "Duc-Tuan Truong",
        "Rohan Kumar Das",
        "Kong Aik Lee",
        "Haizhou Li"
      ],
      "abstract": "Speech foundation models have significantly advanced various speech-related\ntasks by providing exceptional representation capabilities. However, their\nhigh-dimensional output features often create a mismatch with downstream task\nmodels, which typically require lower-dimensional inputs. A common solution is\nto apply a dimensionality reduction (DR) layer, but this approach increases\nparameter overhead, computational costs, and risks losing valuable information.\nTo address these issues, we propose Nested Res2Net (Nes2Net), a lightweight\nback-end architecture designed to directly process high-dimensional features\nwithout DR layers. The nested structure enhances multi-scale feature\nextraction, improves feature interaction, and preserves high-dimensional\ninformation. We first validate Nes2Net on CtrSVDD, a singing voice deepfake\ndetection dataset, and report a 22% performance improvement and an 87% back-end\ncomputational cost reduction over the state-of-the-art baseline. Additionally,\nextensive testing across four diverse datasets: ASVspoof 2021, ASVspoof 5,\nPartialSpoof, and In-the-Wild, covering fully spoofed speech, adversarial\nattacks, partial spoofing, and real-world scenarios, consistently highlights\nNes2Net's superior robustness and generalization capabilities. The code package\nand pre-trained models are available at https://github.com/Liu-Tianchi/Nes2Net.",
      "tldr_zh": "该论文提出Nes2Net，一种轻量级嵌套架构（Nested Res2Net），旨在解决语音基础模型高维输出特征与下游任务模型不匹配的问题，避免使用传统的dimensionality reduction (DR) 层以减少参数开销和计算成本。Nes2Net通过嵌套结构增强多尺度特征提取、改善特征交互，并保留高维信息，从而直接处理高维特征。实验结果显示，在CtrSVDD数据集上，Nes2Net比最先进基线提升22%性能，同时减少87%计算成本；在ASVspoof 2021、ASVspoof 5、PartialSpoof和In-the-Wild数据集上，它展示了出色的鲁棒性和泛化能力。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "This manuscript has been submitted for peer review",
      "pdf_url": "http://arxiv.org/pdf/2504.05657v1",
      "published_date": "2025-04-08 04:11:28 UTC",
      "updated_date": "2025-04-08 04:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:02:24.236126"
    },
    {
      "arxiv_id": "2504.05646v1",
      "title": "Lattice: Learning to Efficiently Compress the Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Karami",
        "Vahab Mirrokni"
      ],
      "abstract": "Attention mechanisms have revolutionized sequence learning but suffer from\nquadratic computational complexity. This paper introduces Lattice, a novel\nrecurrent neural network (RNN) mechanism that leverages the inherent low-rank\nstructure of K-V matrices to efficiently compress the cache into a fixed number\nof memory slots, achieving sub-quadratic complexity. We formulate this\ncompression as an online optimization problem and derive a dynamic memory\nupdate rule based on a single gradient descent step. The resulting recurrence\nfeatures a state- and input-dependent gating mechanism, offering an\ninterpretable memory update process. The core innovation is the orthogonal\nupdate: each memory slot is updated exclusively with information orthogonal to\nits current state hence incorporation of only novel, non-redundant data, which\nminimizes the interference with previously stored information. The experimental\nresults show that Lattice achieves the best perplexity compared to all\nbaselines across diverse context lengths, with performance improvement becoming\nmore pronounced as the context length increases.",
      "tldr_zh": "本论文提出 Lattice，一种新型的 RNN 机制，旨在解决 Attention mechanisms 的二次方计算复杂度问题，通过利用 K-V matrices 的低秩结构，将缓存压缩到固定数量的内存槽，实现子二次方复杂度。Lattice 将压缩过程表述为在线优化问题，并基于单步 gradient descent 推导动态内存更新规则，包括状态和输入相关的门控机制以及 orthogonal update，确保只整合新颖、非冗余的数据，从而最小化对现有信息的干扰。实验结果表明，Lattice 在各种上下文长度上比基线模型的 perplexity 更低，且性能优势在上下文长度增加时更为显著。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05646v1",
      "published_date": "2025-04-08 03:48:43 UTC",
      "updated_date": "2025-04-08 03:48:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:02:35.577501"
    },
    {
      "arxiv_id": "2504.05639v1",
      "title": "DBOT: Artificial Intelligence for Systematic Long-Term Investing",
      "title_zh": "DBOT：人工智能用于系统性长期投资",
      "authors": [
        "Vasant Dhar",
        "João Sedoc"
      ],
      "abstract": "Long-term investing was previously seen as requiring human judgment. With the\nadvent of generative artificial intelligence (AI) systems, automated systematic\nlong-term investing is now feasible. In this paper, we present DBOT, a system\nwhose goal is to reason about valuation like Aswath Damodaran, who is a unique\nexpert in the investment arena in terms of having published thousands of\nvaluations on companies in addition to his numerous writings on the topic,\nwhich provide ready training data for an AI system. DBOT can value any publicly\ntraded company. DBOT can also be back-tested, making its behavior and\nperformance amenable to scientific inquiry. We compare DBOT to its analytic\nparent, Damodaran, and highlight the research challenges involved in raising\nits current capability to that of Damodaran's. Finally, we examine the\nimplications of DBOT-like AI agents for the financial industry, especially how\nthey will impact the role of human analysts in valuation.",
      "tldr_zh": "该研究提出DBOT，一种基于生成式Artificial Intelligence (AI)的系统，用于系统化长期投资决策，旨在模仿投资专家Aswath Damodaran的估值方法，利用其出版物作为训练数据。DBOT能够对任何公开交易的公司进行估值，并支持back-tested回测，以便科学评估其行为和性能。论文比较DBOT与Damodaran的分析能力，突出了提升AI系统能力的挑战，包括处理复杂估值场景。最终，探讨了DBOT-like AI代理对金融行业的影响，特别是可能改变人类分析师在估值中的角色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-fin.PR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05639v1",
      "published_date": "2025-04-08 03:34:22 UTC",
      "updated_date": "2025-04-08 03:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:02:47.712973"
    },
    {
      "arxiv_id": "2504.06312v1",
      "title": "DMol: A Schedule-Driven Diffusion Model for Highly Efficient and Versatile Molecule Generation",
      "title_zh": "DMol：一种调度驱动的扩散模型，用于高效且多功能的分子生成",
      "authors": [
        "Peizhi Niu",
        "Yu-Hsiang Wang",
        "Vishal Rana",
        "Chetan Rupakheti",
        "Abhishek Pandey",
        "Olgica Milenkovic"
      ],
      "abstract": "We introduce a new graph diffusion model for small molecule generation,\n\\emph{DMol}, which outperforms the state-of-the-art DiGress model in terms of\nvalidity by roughly $1.5\\%$ across all benchmarking datasets while reducing the\nnumber of diffusion steps by at least $10$-fold, and the running time to\nroughly one half. The performance improvements are a result of a careful change\nin the objective function and a ``graph noise\" scheduling approach which, at\neach diffusion step, allows one to only change a subset of nodes of varying\nsize in the molecule graph. Another relevant property of the method is that it\ncan be easily combined with junction-tree-like graph representations that arise\nby compressing a collection of relevant ring structures into supernodes. Unlike\nclassical junction-tree techniques that involve VAEs and require complicated\nreconstruction steps, compressed DMol directly performs graph diffusion on a\ngraph that compresses only a carefully selected set of frequent carbon rings\ninto supernodes, which results in straightforward sample generation. This\ncompressed DMol method offers additional validity improvements over generic\nDMol of roughly $2\\%$, increases the novelty of the method, and further\nimproves the running time due to reductions in the graph size.",
      "tldr_zh": "我们引入了DMol，一种基于图扩散的模型，用于小分子生成，它在有效性上比最先进的DiGress模型高约1.5%，同时将扩散步骤减少至少10倍，运行时间缩短到约一半，主要通过修改目标函数和“图噪声”调度方法来实现，该方法仅在每个步骤改变分子图的部分节点。DMol还可与junction-tree-like图表示结合，将相关碳环结构压缩成超节点，避免了传统VAE方法的复杂重构步骤。实验结果显示，压缩后的DMol进一步提高了有效性约2%，增强了新颖性，并进一步优化了运行时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06312v1",
      "published_date": "2025-04-08 03:31:21 UTC",
      "updated_date": "2025-04-08 03:31:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:02:59.581555"
    },
    {
      "arxiv_id": "2504.05632v2",
      "title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning",
      "title_zh": "针对公平性的推理：通过推理引导的微调缓解语言模型中的偏差",
      "authors": [
        "Sanchit Kabra",
        "Akshita Jha",
        "Chandan K. Reddy"
      ],
      "abstract": "Recent advances in large-scale generative language models have shown that\nreasoning capabilities can significantly improve model performance across a\nvariety of tasks. However, the impact of reasoning on a model's ability to\nmitigate stereotypical responses remains largely underexplored. In this work,\nwe investigate the crucial relationship between a model's reasoning ability and\nfairness, and ask whether improved reasoning capabilities can mitigate harmful\nstereotypical responses, especially those arising due to shallow or flawed\nreasoning. We conduct a comprehensive evaluation of multiple open-source LLMs,\nand find that larger models with stronger reasoning abilities exhibit\nsubstantially lower stereotypical bias on existing fairness benchmarks.\nBuilding on this insight, we introduce ReGiFT -- Reasoning Guided Fine-Tuning,\na novel approach that extracts structured reasoning traces from advanced\nreasoning models and infuses them into models that lack such capabilities. We\nuse only general-purpose reasoning and do not require any fairness-specific\nsupervision for bias mitigation. Notably, we see that models fine-tuned using\nReGiFT not only improve fairness relative to their non-reasoning counterparts\nbut also outperform advanced reasoning models on fairness benchmarks. We also\nanalyze how variations in the correctness of the reasoning traces and their\nlength influence model fairness and their overall performance. Our findings\nhighlight that enhancing reasoning capabilities is an effective,\nfairness-agnostic strategy for mitigating stereotypical bias caused by\nreasoning flaws.",
      "tldr_zh": "本研究探讨了语言模型的推理能力对公平性的影响，发现更大规模的LLMs（Large Language Models）具有更强的推理能力，能够显著降低刻板偏见。研究引入了ReGiFT（Reasoning Guided Fine-Tuning）方法，通过从先进推理模型中提取结构化的推理痕迹，并注入到缺乏推理能力的模型中，从而缓解浅层或缺陷推理导致的刻板响应，而无需任何特定公平监督。实验结果显示，使用ReGiFT微调的模型不仅在公平基准上优于非推理模型，还超过了先进推理模型。此外，分析表明，推理痕迹的正确性和长度对模型的公平性和整体性能有重要影响，证明增强推理能力是一种有效的、无需针对公平优化的偏见缓解策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.05632v2",
      "published_date": "2025-04-08 03:21:51 UTC",
      "updated_date": "2025-04-09 03:05:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:03:11.632070"
    },
    {
      "arxiv_id": "2504.05621v1",
      "title": "Continual Learning of Multiple Cognitive Functions with Brain-inspired Temporal Development Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Bing Han",
        "Feifei Zhao",
        "Yinqian Sun",
        "Wenxuan Pan",
        "Yi Zeng"
      ],
      "abstract": "Cognitive functions in current artificial intelligence networks are tied to\nthe exponential increase in network scale, whereas the human brain can\ncontinuously learn hundreds of cognitive functions with remarkably low energy\nconsumption. This advantage is in part due to the brain cross-regional temporal\ndevelopment mechanisms, where the progressive formation, reorganization, and\npruning of connections from basic to advanced regions, facilitate knowledge\ntransfer and prevent network redundancy. Inspired by these, we propose the\nContinual Learning of Multiple Cognitive Functions with Brain-inspired Temporal\nDevelopment Mechanism(TD-MCL), enabling cognitive enhancement from simple to\ncomplex in Perception-Motor-Interaction(PMI) multiple cognitive task scenarios.\nThe TD-MCL model proposes the sequential evolution of long-range connections\nbetween different cognitive modules to promote positive knowledge transfer,\nwhile using feedback-guided local connection inhibition and pruning to\neffectively eliminate redundancies in previous tasks, reducing energy\nconsumption while preserving acquired knowledge. Experiments show that the\nproposed method can achieve continual learning capabilities while reducing\nnetwork scale, without introducing regularization, replay, or freezing\nstrategies, and achieving superior accuracy on new tasks compared to direct\nlearning. The proposed method shows that the brain's developmental mechanisms\noffer a valuable reference for exploring biologically plausible, low-energy\nenhancements of general cognitive abilities.",
      "tldr_zh": "该论文提出 TD-MCL 模型，灵感来源于大脑的 temporal development mechanism，实现多个认知功能的持续学习，旨在解决人工智能网络规模膨胀和能耗问题。模型在 Perception-Motor-Interaction (PMI) 任务场景中，通过顺序演化长距离连接促进知识转移，并采用反馈引导的局部连接抑制和修剪来消除冗余，减少能耗同时保留已有知识。实验结果显示，TD-MCL 无需正则化、回放或冻结策略，即可减少网络规模并在新任务上实现更高的准确率，为生物学上合理的、低能耗认知能力增强提供参考。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05621v1",
      "published_date": "2025-04-08 02:36:36 UTC",
      "updated_date": "2025-04-08 02:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:03:25.646163"
    },
    {
      "arxiv_id": "2504.05618v1",
      "title": "Technical Report: Full Version of Analyzing and Optimizing Perturbation of DP-SGD Geometrically",
      "title_zh": "技术报告：分析和优化 DP-SGD 几何扰动的完整版本",
      "authors": [
        "Jiawei Duan",
        "Haibo Hu",
        "Qingqing Ye",
        "Xinyue Sun"
      ],
      "abstract": "Differential privacy (DP) has become a prevalent privacy model in a wide\nrange of machine learning tasks, especially after the debut of DP-SGD. However,\nDP-SGD, which directly perturbs gradients in the training iterations, fails to\nmitigate the negative impacts of noise on gradient direction. As a result,\nDP-SGD is often inefficient. Although various solutions (e.g., clipping to\nreduce the sensitivity of gradients and amplifying privacy bounds to save\nprivacy budgets) are proposed to trade privacy for model efficiency, the root\ncause of its inefficiency is yet unveiled.\n  In this work, we first generalize DP-SGD and theoretically derive the impact\nof DP noise on the training process. Our analysis reveals that, in terms of a\nperturbed gradient, only the noise on direction has eminent impact on the model\nefficiency while that on magnitude can be mitigated by optimization techniques,\ni.e., fine-tuning gradient clipping and learning rate. Besides, we confirm that\ntraditional DP introduces biased noise on the direction when adding unbiased\nnoise to the gradient itself. Overall, the perturbation of DP-SGD is actually\nsub-optimal from a geometric perspective. Motivated by this, we design a\ngeometric perturbation strategy GeoDP within the DP framework, which perturbs\nthe direction and the magnitude of a gradient, respectively. By directly\nreducing the noise on the direction, GeoDP mitigates the negative impact of DP\nnoise on model efficiency with the same DP guarantee. Extensive experiments on\ntwo public datasets (i.e., MNIST and CIFAR-10), one synthetic dataset and three\nprevalent models (i.e., Logistic Regression, CNN and ResNet) confirm the\neffectiveness and generality of our strategy.",
      "tldr_zh": "本文分析了 DP-SGD 在梯度扰动中的效率问题，揭示其根本原因在于噪声对梯度方向的显著负面影响，而对梯度幅度的影响可以通过优化技术（如微调梯度剪切和学习率）缓解。作者提出了一种几何扰动策略 GeoDP，在 DP 框架内分别扰动梯度的方向和幅度，从而减少方向噪声并提升模型效率，同时保持相同的隐私保证。实验在 MNIST、CIFAR-10 等数据集以及 Logistic Regression、CNN 和 ResNet 模型上证实了 GeoDP 的有效性和通用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "This is the full version of our paper \"Analyzing and Optimizing\n  Perturbation of DP-SGD Geometrically\", which will appear in ICDE 2025 as a\n  regular research paper",
      "pdf_url": "http://arxiv.org/pdf/2504.05618v1",
      "published_date": "2025-04-08 02:26:10 UTC",
      "updated_date": "2025-04-08 02:26:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:03:36.535185"
    },
    {
      "arxiv_id": "2504.05615v1",
      "title": "FedEFC: Federated Learning Using Enhanced Forward Correction Against Noisy Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Seunghun Yu",
        "Jin-Hyun Ahn",
        "Joonhyuk Kang"
      ],
      "abstract": "Federated Learning (FL) is a powerful framework for privacy-preserving\ndistributed learning. It enables multiple clients to collaboratively train a\nglobal model without sharing raw data. However, handling noisy labels in FL\nremains a major challenge due to heterogeneous data distributions and\ncommunication constraints, which can severely degrade model performance. To\naddress this issue, we propose FedEFC, a novel method designed to tackle the\nimpact of noisy labels in FL. FedEFC mitigates this issue through two key\ntechniques: (1) prestopping, which prevents overfitting to mislabeled data by\ndynamically halting training at an optimal point, and (2) loss correction,\nwhich adjusts model updates to account for label noise. In particular, we\ndevelop an effective loss correction tailored to the unique challenges of FL,\nincluding data heterogeneity and decentralized training. Furthermore, we\nprovide a theoretical analysis, leveraging the composite proper loss property,\nto demonstrate that the FL objective function under noisy label distributions\ncan be aligned with the clean label distribution. Extensive experimental\nresults validate the effectiveness of our approach, showing that it\nconsistently outperforms existing FL techniques in mitigating the impact of\nnoisy labels, particularly under heterogeneous data settings (e.g., achieving\nup to 41.64% relative performance improvement over the existing loss correction\nmethod).",
      "tldr_zh": "该论文提出 FedEFC，一种针对 Federated Learning (FL) 中噪声标签问题的新方法，通过 prestopping 和 loss correction 两大技术来缓解异质数据分布和通信约束带来的影响。Prestopping 动态停止训练以防止过度拟合错误标签，而 loss correction 则调整模型更新以适应 FL 的去中心化特性，并利用 composite proper loss 属性进行理论证明，确保目标函数与干净标签分布对齐。实验结果显示，FedEFC 在异质数据场景下显著优于现有方法，相对性能提升高达 41.64%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05615v1",
      "published_date": "2025-04-08 02:14:50 UTC",
      "updated_date": "2025-04-08 02:14:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:03:48.804161"
    },
    {
      "arxiv_id": "2504.07139v1",
      "title": "Artificial Intelligence Index Report 2025",
      "title_zh": "人工智能指数报告 2025",
      "authors": [
        "Nestor Maslej",
        "Loredana Fattorini",
        "Raymond Perrault",
        "Yolanda Gil",
        "Vanessa Parli",
        "Njenga Kariuki",
        "Emily Capstick",
        "Anka Reuel",
        "Erik Brynjolfsson",
        "John Etchemendy",
        "Katrina Ligett",
        "Terah Lyons",
        "James Manyika",
        "Juan Carlos Niebles",
        "Yoav Shoham",
        "Russell Wald",
        "Tobi Walsh",
        "Armin Hamrah",
        "Lapo Santarlasci",
        "Julia Betts Lotufo",
        "Alexandra Rome",
        "Andrew Shi",
        "Sukrut Oak"
      ],
      "abstract": "Welcome to the eighth edition of the AI Index report. The 2025 Index is our\nmost comprehensive to date and arrives at an important moment, as AI's\ninfluence across society, the economy, and global governance continues to\nintensify. New in this year's report are in-depth analyses of the evolving\nlandscape of AI hardware, novel estimates of inference costs, and new analyses\nof AI publication and patenting trends. We also introduce fresh data on\ncorporate adoption of responsible AI practices, along with expanded coverage of\nAI's growing role in science and medicine. Since its founding in 2017 as an\noffshoot of the One Hundred Year Study of Artificial Intelligence, the AI Index\nhas been committed to equipping policymakers, journalists, executives,\nresearchers, and the public with accurate, rigorously validated, and globally\nsourced data. Our mission has always been to help these stakeholders make\nbetter-informed decisions about the development and deployment of AI. In a\nworld where AI is discussed everywhere - from boardrooms to kitchen tables -\nthis mission has never been more essential. The AI Index continues to lead in\ntracking and interpreting the most critical trends shaping the field - from the\nshifting geopolitical landscape and the rapid evolution of underlying\ntechnologies, to AI's expanding role in business, policymaking, and public\nlife. Longitudinal tracking remains at the heart of our mission. In a domain\nadvancing at breakneck speed, the Index provides essential context - helping us\nunderstand where AI stands today, how it got here, and where it may be headed\nnext. Recognized globally as one of the most authoritative resources on\nartificial intelligence, the AI Index has been cited in major media outlets\nsuch as The New York Times, Bloomberg, and The Guardian; referenced in hundreds\nof academic papers; and used by policymakers and government agencies around the\nworld.",
      "tldr_zh": "该报告是人工智能（Artificial Intelligence）领域的第八版年度指数报告，内容最为全面，聚焦于AI在社会、经济和全球治理中日益增强的影响。报告引入了新的深度分析，包括AI硬件景观的演变、推理成本（inference costs）的估算、AI出版和专利趋势，以及企业对负责任AI实践的采用，同时扩展了对AI在科学和医学领域作用的覆盖。凭借全球数据来源和纵向跟踪，该报告为政策制定者、记者、企业领袖、研究者和公众提供准确验证的数据，帮助他们在AI开发和部署方面做出更明智的决策。报告已被广泛引用，包括在《纽约时报》等媒体、学术论文和政府机构中，确立了其作为权威资源的地位。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.07139v1",
      "published_date": "2025-04-08 02:01:37 UTC",
      "updated_date": "2025-04-08 02:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:03:59.320052"
    },
    {
      "arxiv_id": "2504.05607v1",
      "title": "FactGuard: Leveraging Multi-Agent Systems to Generate Answerable and Unanswerable Questions for Enhanced Long-Context LLM Extraction",
      "title_zh": "FactGuard",
      "authors": [
        "Qian-Wen Zhang",
        "Fang Li",
        "Jie Wang",
        "Lingfeng Qiao",
        "Yifei Yu",
        "Di Yin",
        "Xing Sun"
      ],
      "abstract": "Extractive reading comprehension systems are designed to locate the correct\nanswer to a question within a given text. However, a persistent challenge lies\nin ensuring these models maintain high accuracy in answering questions while\nreliably recognizing unanswerable queries. Despite significant advances in\nlarge language models (LLMs) for reading comprehension, this issue remains\ncritical, particularly as the length of supported contexts continues to expand.\nTo address this challenge, we propose an innovative data augmentation\nmethodology grounded in a multi-agent collaborative framework. Unlike\ntraditional methods, such as the costly human annotation process required for\ndatasets like SQuAD 2.0, our method autonomously generates evidence-based\nquestion-answer pairs and systematically constructs unanswerable questions.\nUsing this methodology, we developed the FactGuard-Bench dataset, which\ncomprises 25,220 examples of both answerable and unanswerable question\nscenarios, with context lengths ranging from 8K to 128K. Experimental\nevaluations conducted on seven popular LLMs reveal that even the most advanced\nmodels achieve only 61.79% overall accuracy. Furthermore, we emphasize the\nimportance of a model's ability to reason about unanswerable questions to avoid\ngenerating plausible but incorrect answers. By implementing efficient data\nselection and generation within the multi-agent collaborative framework, our\nmethod significantly reduces the traditionally high costs associated with\nmanual annotation and provides valuable insights for the training and\noptimization of LLMs.",
      "tldr_zh": "本研究提出FactGuard，一种基于Multi-Agent Systems的多智能体协作框架，用于数据增强，以提升大型语言模型(LLMs)在长上下文提取式阅读理解中的性能。该框架能自动生成基于证据的可回答和不可回答问题-答案对，显著降低了传统手动标注（如SQuAD 2.0）的成本，并构建了FactGuard-Bench数据集，包含25,220个例子，上下文长度从8K到128K。实验在七个流行LLMs上显示，最高整体准确率仅为61.79%，突显模型在处理不可回答问题时的不足，并为LLMs的训练和优化提供宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05607v1",
      "published_date": "2025-04-08 01:45:16 UTC",
      "updated_date": "2025-04-08 01:45:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:04:12.314106"
    },
    {
      "arxiv_id": "2504.05591v1",
      "title": "Class Imbalance Correction for Improved Universal Lesion Detection and Tagging in CT",
      "title_zh": "翻译失败",
      "authors": [
        "Peter D. Erickson",
        "Tejas Sudharshan Mathai",
        "Ronald M. Summers"
      ],
      "abstract": "Radiologists routinely detect and size lesions in CT to stage cancer and\nassess tumor burden. To potentially aid their efforts, multiple lesion\ndetection algorithms have been developed with a large public dataset called\nDeepLesion (32,735 lesions, 32,120 CT slices, 10,594 studies, 4,427 patients, 8\nbody part labels). However, this dataset contains missing measurements and\nlesion tags, and exhibits a severe imbalance in the number of lesions per label\ncategory. In this work, we utilize a limited subset of DeepLesion (6\\%, 1331\nlesions, 1309 slices) containing lesion annotations and body part label tags to\ntrain a VFNet model to detect lesions and tag them. We address the class\nimbalance by conducting three experiments: 1) Balancing data by the body part\nlabels, 2) Balancing data by the number of lesions per patient, and 3)\nBalancing data by the lesion size. In contrast to a randomly sampled\n(unbalanced) data subset, our results indicated that balancing the body part\nlabels always increased sensitivity for lesions >= 1cm for classes with low\ndata quantities (Bone: 80\\% vs. 46\\%, Kidney: 77\\% vs. 61\\%, Soft Tissue: 70\\%\nvs. 60\\%, Pelvis: 83\\% vs. 76\\%). Similar trends were seen for three other\nmodels tested (FasterRCNN, RetinaNet, FoveaBox). Balancing data by lesion size\nalso helped the VFNet model improve recalls for all classes in contrast to an\nunbalanced dataset. We also provide a structured reporting guideline for a\n``Lesions'' subsection to be entered into the ``Findings'' section of a\nradiology report. To our knowledge, we are the first to report the class\nimbalance in DeepLesion, and have taken data-driven steps to address it in the\ncontext of joint lesion detection and tagging.",
      "tldr_zh": "这篇论文针对DeepLesion数据集中的类别不平衡问题，提出通过数据平衡策略来提升CT图像中病变检测和标记的性能。具体方法包括使用6%子集（1331个病变）训练VFNet模型，并通过按身体部位标签、患者病变数量和病变大小三种方式平衡数据。实验结果显示，平衡身体部位标签后，模型对低数据量类别（如Bone、Kidney）的敏感度显著提高（例如Bone从46%增至80%），其他模型（如FasterRCNN、RetinaNet）也表现出类似趋势；此外，按病变大小平衡改善了整体召回率。论文首次系统报告了DeepLesion的类别不平衡问题，并提供了结构化的放射学报告指南，以支持临床应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Published at MICCAI MILLAND Workshop 2022",
      "pdf_url": "http://arxiv.org/pdf/2504.05591v1",
      "published_date": "2025-04-08 00:58:26 UTC",
      "updated_date": "2025-04-08 00:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:04:25.375352"
    },
    {
      "arxiv_id": "2504.05588v1",
      "title": "Multi-fidelity Reinforcement Learning Control for Complex Dynamical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Luning Sun",
        "Xin-Yang Liu",
        "Siyan Zhao",
        "Aditya Grover",
        "Jian-Xun Wang",
        "Jayaraman J. Thiagarajan"
      ],
      "abstract": "Controlling instabilities in complex dynamical systems is challenging in\nscientific and engineering applications. Deep reinforcement learning (DRL) has\nseen promising results for applications in different scientific applications.\nThe many-query nature of control tasks requires multiple interactions with real\nenvironments of the underlying physics. However, it is usually sparse to\ncollect from the experiments or expensive to simulate for complex dynamics.\nAlternatively, controlling surrogate modeling could mitigate the computational\ncost issue. However, a fast and accurate learning-based model by offline\ntraining makes it very hard to get accurate pointwise dynamics when the\ndynamics are chaotic. To bridge this gap, the current work proposes a\nmulti-fidelity reinforcement learning (MFRL) framework that leverages\ndifferentiable hybrid models for control tasks, where a physics-based hybrid\nmodel is corrected by limited high-fidelity data. We also proposed a\nspectrum-based reward function for RL learning. The effect of the proposed\nframework is demonstrated on two complex dynamics in physics. The statistics of\nthe MFRL control result match that computed from many-query evaluations of the\nhigh-fidelity environments and outperform other SOTA baselines.",
      "tldr_zh": "该研究针对复杂动态系统的控制挑战，提出了一种多保真强化学习 (MFRL) 框架，以缓解深度强化学习 (DRL) 在高计算成本和数据稀缺问题上的局限性。MFRL 框架利用可微混合模型，将基于物理的混合模型通过有限的高保真数据进行修正，并引入基于频谱的奖励函数来优化学习过程。在两个物理复杂动态系统中，实验结果显示 MFRL 的控制性能与高保真环境的多查询评估统计相匹配，并优于现有最先进基线。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05588v1",
      "published_date": "2025-04-08 00:50:15 UTC",
      "updated_date": "2025-04-08 00:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:04:36.966096"
    },
    {
      "arxiv_id": "2504.05586v2",
      "title": "Finding Fantastic Experts in MoEs: A Unified Study for Expert Dropping Strategies and Observations",
      "title_zh": "翻译失败",
      "authors": [
        "Ajay Jaiswal",
        "Jianyu Wang",
        "Yixiao Li",
        "Pingzhi Li",
        "Tianlong Chen",
        "Zhangyang Wang",
        "Chong Wang",
        "Ruoming Pang",
        "Xianzhi Du"
      ],
      "abstract": "Sparsely activated Mixture-of-Experts (SMoE) has shown promise in scaling up\nthe learning capacity of neural networks. However, vanilla SMoEs have issues\nsuch as expert redundancy and heavy memory requirements, making them\ninefficient and non-scalable, especially for resource-constrained scenarios.\nExpert-level sparsification of SMoEs involves pruning the least important\nexperts to address these limitations. In this work, we aim to address three\nquestions: (1) What is the best recipe to identify the least knowledgeable\nsubset of experts that can be dropped with minimal impact on performance? (2)\nHow should we perform expert dropping (one-shot or iterative), and what\ncorrection measures can we undertake to minimize its drastic impact on SMoE\nsubnetwork capabilities? (3) What capabilities of full-SMoEs are severely\nimpacted by the removal of the least dominant experts, and how can we recover\nthem? Firstly, we propose MoE Experts Compression Suite (MC-Suite), which is a\ncollection of some previously explored and multiple novel recipes to provide a\ncomprehensive benchmark for estimating expert importance from diverse\nperspectives, as well as unveil numerous valuable insights for SMoE experts.\nSecondly, unlike prior works with a one-shot expert pruning approach, we\nexplore the benefits of iterative pruning with the re-estimation of the\nMC-Suite criterion. Moreover, we introduce the benefits of task-agnostic\nfine-tuning as a correction mechanism during iterative expert dropping, which\nwe term MoE Lottery Subnetworks. Lastly, we present an experimentally validated\nconjecture that, during expert dropping, SMoEs' instruction-following\ncapabilities are predominantly hurt, which can be restored to a robust level\nsubject to external augmentation of instruction-following capabilities using\nk-shot examples and supervised fine-tuning.",
      "tldr_zh": "本研究针对稀疏激活的Mixture-of-Experts (SMoE)模型存在的专家冗余和内存需求问题，探讨了专家删除策略，以提高模型效率。该论文提出MoE Experts Compression Suite (MC-Suite)，一个综合基准套件，用于从多种视角评估专家重要性，包括现有和新型方法，并比较一次性与迭代专家修剪策略，同时引入任务无关微调作为修正机制，形成MoE Lottery Subnetworks。通过实验验证，发现专家删除主要损害SMoE的指令遵循能力，但可以通过k-shot示例和监督微调有效恢复。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05586v2",
      "published_date": "2025-04-08 00:49:08 UTC",
      "updated_date": "2025-04-10 02:32:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:04:47.778658"
    },
    {
      "arxiv_id": "2504.05585v2",
      "title": "TW-CRL: Time-Weighted Contrastive Reward Learning for Efficient Inverse Reinforcement Learning",
      "title_zh": "TW-CRL：时间加权的对比奖励学习，用于高效的反向强化",
      "authors": [
        "Yuxuan Li",
        "Yicheng Gao",
        "Ning Yang",
        "Stephen Xia"
      ],
      "abstract": "Episodic tasks in Reinforcement Learning (RL) often pose challenges due to\nsparse reward signals and high-dimensional state spaces, which hinder efficient\nlearning. Additionally, these tasks often feature hidden \"trap states\" --\nirreversible failures that prevent task completion but do not provide explicit\nnegative rewards to guide agents away from repeated errors. To address these\nissues, we propose Time-Weighted Contrastive Reward Learning (TW-CRL), an\nInverse Reinforcement Learning (IRL) framework that leverages both successful\nand failed demonstrations. By incorporating temporal information, TW-CRL learns\na dense reward function that identifies critical states associated with success\nor failure. This approach not only enables agents to avoid trap states but also\nencourages meaningful exploration beyond simple imitation of expert\ntrajectories. Empirical evaluations on navigation tasks and robotic\nmanipulation benchmarks demonstrate that TW-CRL surpasses state-of-the-art\nmethods, achieving improved efficiency and robustness.",
      "tldr_zh": "该论文提出 TW-CRL，一种时间加权的对比奖励学习框架，用于提升逆强化学习（IRL）的效率，解决强化学习（RL）中稀疏奖励信号、高维状态空间以及隐藏的“trap states”（不可逆失败状态）等问题。TW-CRL 通过整合成功和失败的演示，学习一个密集奖励函数来识别与成功或失败相关的关键状态，从而帮助代理避免陷阱并进行有意义的探索，而非简单模仿专家轨迹。在导航任务和机器人操作基准上的实验显示，TW-CRL 超过了现有最先进方法，在效率和鲁棒性方面取得了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05585v2",
      "published_date": "2025-04-08 00:48:29 UTC",
      "updated_date": "2025-05-22 00:37:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:05:00.431983"
    },
    {
      "arxiv_id": "2504.16940v3",
      "title": "Better artificial intelligence does not mean better models of biology",
      "title_zh": "更好的人工智能并不意味着更好的生物模型",
      "authors": [
        "Drew Linsley",
        "Pinyuan Feng",
        "Thomas Serre"
      ],
      "abstract": "Deep neural networks (DNNs) once showed increasing alignment with primate\nperception and neural responses as they improved on vision benchmarks, raising\nhopes that advances in AI would yield better models of biological vision.\nHowever, we show across three benchmarks that this alignment is now plateauing\n- and in some cases worsening - as DNNs scale to human or superhuman accuracy.\nThis divergence may reflect the adoption of visual strategies that differ from\nthose used by primates. These findings challenge the view that progress in\nartificial intelligence will naturally translate to neuroscience. We argue that\nvision science must chart its own course, developing algorithms grounded in\nbiological visual systems rather than optimizing for benchmarks based on\ninternet-scale datasets.",
      "tldr_zh": "这项研究发现，尽管深度神经网络 (DNNs) 在视觉基准上达到人类或超人类准确率，但它们与灵长类动物感知和神经响应的对齐程度已开始停滞，甚至在某些情况下恶化。研究通过三个基准测试显示，这种分歧可能源于 DNNs 采用的视觉策略与生物系统不同，从而挑战了 AI 进步会自动转化为更好生物模型的观点。作者主张，视觉科学应独立发展基于生物视觉系统的算法，而不是依赖于基于互联网数据集的优化基准。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16940v3",
      "published_date": "2025-04-08 00:36:29 UTC",
      "updated_date": "2025-04-28 16:05:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:05:11.452114"
    },
    {
      "arxiv_id": "2504.05576v1",
      "title": "SoundVista: Novel-View Ambient Sound Synthesis via Visual-Acoustic Binding",
      "title_zh": "翻译失败",
      "authors": [
        "Mingfei Chen",
        "Israel D. Gebru",
        "Ishwarya Ananthabhotla",
        "Christian Richardt",
        "Dejan Markovic",
        "Jake Sandakly",
        "Steven Krenn",
        "Todd Keebler",
        "Eli Shlizerman",
        "Alexander Richard"
      ],
      "abstract": "We introduce SoundVista, a method to generate the ambient sound of an\narbitrary scene at novel viewpoints. Given a pre-acquired recording of the\nscene from sparsely distributed microphones, SoundVista can synthesize the\nsound of that scene from an unseen target viewpoint. The method learns the\nunderlying acoustic transfer function that relates the signals acquired at the\ndistributed microphones to the signal at the target viewpoint, using a limited\nnumber of known recordings. Unlike existing works, our method does not require\nconstraints or prior knowledge of sound source details. Moreover, our method\nefficiently adapts to diverse room layouts, reference microphone configurations\nand unseen environments. To enable this, we introduce a visual-acoustic binding\nmodule that learns visual embeddings linked with local acoustic properties from\npanoramic RGB and depth data. We first leverage these embeddings to optimize\nthe placement of reference microphones in any given scene. During synthesis, we\nleverage multiple embeddings extracted from reference locations to get adaptive\nweights for their contribution, conditioned on target viewpoint. We benchmark\nthe task on both publicly available data and real-world settings. We\ndemonstrate significant improvements over existing methods.",
      "tldr_zh": "本研究提出了SoundVista，一种通过视觉-声学绑定（visual-acoustic binding）的方法，用于从新视角合成任意场景的环境声音，仅需预先从稀疏分布麦克风获取的有限录音。SoundVista 学习声学传输函数，将分布式麦克风信号映射到目标视角信号，而无需声源细节的先验知识或约束。核心组件包括一个视觉-声学绑定模块，从全景 RGB 和 depth data 中提取视觉嵌入，并结合局部声学属性来优化参考麦克风放置和合成权重。实验在公开数据和真实世界设置中显示，SoundVista 比现有方法显著提升性能，提供更高效的环境声音合成能力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.SD",
      "comment": "Highlight Accepted to CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.05576v1",
      "published_date": "2025-04-08 00:22:16 UTC",
      "updated_date": "2025-04-08 00:22:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:05:23.536962"
    },
    {
      "arxiv_id": "2504.05573v1",
      "title": "MicroNN: An On-device Disk-resident Updatable Vector Database",
      "title_zh": "MicroNN：一种设备上的磁盘驻留可更新向量数据库",
      "authors": [
        "Jeffrey Pound",
        "Floris Chabert",
        "Arjun Bhushan",
        "Ankur Goswami",
        "Anil Pacaci",
        "Shihabur Rahman Chowdhury"
      ],
      "abstract": "Nearest neighbour search over dense vector collections has important\napplications in information retrieval, retrieval augmented generation (RAG),\nand content ranking. Performing efficient search over large vector collections\nis a well studied problem with many existing approaches and open source\nimplementations. However, most state-of-the-art systems are generally targeted\ntowards scenarios using large servers with an abundance of memory, static\nvector collections that are not updatable, and nearest neighbour search in\nisolation of other search criteria. We present Micro Nearest Neighbour\n(MicroNN), an embedded nearest-neighbour vector search engine designed for\nscalable similarity search in low-resource environments. MicroNN addresses the\nproblem of on-device vector search for real-world workloads containing updates\nand hybrid search queries that combine nearest neighbour search with structured\nattribute filters. In this scenario, memory is highly constrained and\ndisk-efficient index structures and algorithms are required, as well as support\nfor continuous inserts and deletes. MicroNN is an embeddable library that can\nscale to large vector collections with minimal resources. MicroNN is used in\nproduction and powers a wide range of vector search use-cases on-device.\nMicroNN takes less than 7 ms to retrieve the top-100 nearest neighbours with\n90% recall on publicly available million-scale vector benchmark while using ~10\nMB of memory.",
      "tldr_zh": "该论文提出 MicroNN，一种嵌入式磁盘驻留的向量数据库，旨在为低资源环境提供可扩展的 Nearest Neighbour 搜索，支持更新和混合查询（结合 Nearest Neighbour 搜索与结构化属性过滤）。MicroNN 通过磁盘高效的索引结构和算法，处理真实工作负载中的连续插入、删除和查询，同时在内存受限场景下保持高效。实验结果显示，在百万规模的公开向量基准上，MicroNN 能在不到 7 ms 内检索 top-100 最近邻，达到 90% 召回率，仅使用约 10 MB 内存，并已在生产环境中用于多种向量搜索应用。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05573v1",
      "published_date": "2025-04-08 00:05:58 UTC",
      "updated_date": "2025-04-08 00:05:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:05:37.067353"
    },
    {
      "arxiv_id": "2504.05571v1",
      "title": "Knowledge-Instruct: Effective Continual Pre-training from Limited Data using Instructions",
      "title_zh": "Knowledge-Instruct：使用指令从有限数据进行有效的持续预训练",
      "authors": [
        "Oded Ovadia",
        "Meni Brief",
        "Rachel Lemberg",
        "Eitam Sheetrit"
      ],
      "abstract": "While Large Language Models (LLMs) acquire vast knowledge during\npre-training, they often lack domain-specific, new, or niche information.\nContinual pre-training (CPT) attempts to address this gap but suffers from\ncatastrophic forgetting and inefficiencies in low-data regimes. We introduce\nKnowledge-Instruct, a novel approach to efficiently inject knowledge from\nlimited corpora through pure instruction-tuning. By generating\ninformation-dense synthetic instruction data, it effectively integrates new\nknowledge while preserving general reasoning and instruction-following\nabilities. Knowledge-Instruct demonstrates superior factual memorization,\nminimizes catastrophic forgetting, and remains scalable by leveraging synthetic\ndata from relatively small language models. Additionally, it enhances\ncontextual understanding, including complex multi-hop reasoning, facilitating\nintegration with retrieval systems. We validate its effectiveness across\ndiverse benchmarks, including Companies, a new dataset that we release to\nmeasure knowledge injection capabilities.",
      "tldr_zh": "本研究针对大语言模型(LLMs)在预训练中虽获取大量知识但缺乏特定领域或新信息的不足，提出Knowledge-Instruct方法，通过纯指令微调从有限语料生成信息密集的合成指令数据，实现高效知识注入。Knowledge-Instruct不仅减少灾难性遗忘，还保留了LLMs的一般推理和指令遵循能力，同时提升事实记忆和复杂多跳推理，支持与检索系统的整合。在各种基准测试中，包括新发布的Companies数据集，该方法展示了显著的性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05571v1",
      "published_date": "2025-04-08 00:00:36 UTC",
      "updated_date": "2025-04-08 00:00:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T11:05:48.771373"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 109,
  "processed_papers_count": 109,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T11:06:09.338607"
}