[
  {
    "arxiv_id": "2507.17988v1",
    "title": "Synthesis of timeline-based planning strategies avoiding determinization",
    "authors": [
      "Dario Della Monica",
      "Angelo Montanari",
      "Pietro Sala"
    ],
    "abstract": "Qualitative timeline-based planning models domains as sets of independent, but\n  interacting, components whose behaviors over time, the timelines, are governed\n  by sets of qualitative temporal constraints (ordering relations), called\n  synchronization rules.\n  Its plan-existence problem has been shown to be PSPACE-complete; in\n  particular, PSPACE-membership has been proved via reduction to the\n  nonemptiness problem for nondeterministic finite automata.\n  However, nondeterministic automata cannot be directly used to synthesize\n  planning strategies as a costly determinization step is needed.\n  In this paper, we identify a fragment of qualitative timeline-based planning\n  whose plan-existence problem can be directly mapped into the nonemptiness\n  problem of deterministic finite automata, which can then\n  synthesize strategies.\n  In addition, we identify a maximal subset of Allen's relations that fits into\n  such a deterministic fragment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2410.22757",
    "pdf_url": "https://arxiv.org/pdf/2507.17988v1",
    "published_date": "2025-07-23 23:39:04 UTC",
    "updated_date": "2025-07-23 23:39:04 UTC"
  },
  {
    "arxiv_id": "2507.19543v1",
    "title": "Agent WARPP: Workflow Adherence via Runtime Parallel Personalization",
    "authors": [
      "Maria Emilia Mazzolenis",
      "Ruirui Zhang"
    ],
    "abstract": "Large language models (LLMs) are increasingly applied in task-oriented dialogue (TOD) systems but often struggle with long, conditional workflows that involve external tool calls and depend on user-specific information. We present Workflow Adherence via Runtime Parallel Personalization, or WARPP, a training-free, modular framework that combines multi-agent orchestration with runtime personalization to improve workflow adherence in LLM-based systems. By dynamically pruning conditional branches based on user attributes, the framework reduces reasoning overhead and narrows tool selection at runtime. WARPP deploys a parallelized architecture where a dedicated Personalizer agent operates alongside modular, domain-specific agents to dynamically tailor execution paths in real time. The framework is evaluated across five representative user intents of varying complexity within three domains: banking, flights, and healthcare. Our evaluation leverages synthetic datasets and LLM-powered simulated users to test scenarios with conditional dependencies. Our results demonstrate that WARPP outperforms both the non-personalized method and the ReAct baseline, achieving increasingly larger gains in parameter fidelity and tool accuracy as intent complexity grows, while also reducing average token usage, without any additional training.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the ICML 2025 Workshop on Multi-Agent Systems in the Era of Foundation Models: Opportunities, Challenges, and Futures. Code repo: https://github.com/emiliamazzo/WARPP/",
    "pdf_url": "https://arxiv.org/pdf/2507.19543v1",
    "published_date": "2025-07-23 23:27:49 UTC",
    "updated_date": "2025-07-23 23:27:49 UTC"
  },
  {
    "arxiv_id": "2507.17985v3",
    "title": "How K-12 Educators Use AI: LLM-Assisted Qualitative Analysis at Scale",
    "authors": [
      "Alex Liu",
      "Lief Esbenshade",
      "Shawon Sarkar",
      "Victor Tian",
      "Zachary Zhang",
      "Kevin He",
      "Min Sun"
    ],
    "abstract": "This study investigates how K-12 educators use generative AI tools in real-world instructional contexts and how large language models (LLMs) can support scalable qualitative analysis of these interactions. Drawing on over 13,000 unscripted educator-AI conversations from an open-access platform, we examine educators' use of AI for lesson planning, differentiation, assessment, and pedagogical reflection. Methodologically, we introduce a replicable, LLM-assisted qualitative analysis pipeline that supports inductive theme discovery, codebook development, and large-scale annotation while preserving researcher control over conceptual synthesis. Empirically, the findings surface concrete patterns in how educators prompt, adapt, and evaluate AI-generated suggestions as part of their instructional reasoning. This work demonstrates the feasibility of combining LLM support with qualitative rigor to analyze complex educator behaviors at scale and inform the design of AI-powered educational tools.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17985v3",
    "published_date": "2025-07-23 23:23:38 UTC",
    "updated_date": "2025-12-15 21:32:56 UTC"
  },
  {
    "arxiv_id": "2507.17984v3",
    "title": "Machine Unlearning of Traffic State Estimation and Prediction",
    "authors": [
      "Xin Wang",
      "R. Tyrrell Rockafellar",
      "Xuegang",
      "Ban"
    ],
    "abstract": "Data-driven traffic state estimation and prediction (TSEP) relies heavily on data sources that contain sensitive information. While the abundance of data has fueled significant breakthroughs, particularly in machine learning-based methods, it also raises concerns regarding privacy, cybersecurity, and data freshness. These issues can erode public trust in intelligent transportation systems. Recently, regulations have introduced the \"right to be forgotten\", allowing users to request the removal of their private data from models. As machine learning models can remember old data, simply removing it from back-end databases is insufficient in such systems. To address these challenges, this study introduces a novel learning paradigm for TSEP-Machine Unlearning TSEP-which enables a trained TSEP model to selectively forget privacy-sensitive, poisoned, or outdated data. By empowering models to \"unlearn,\" we aim to enhance the trustworthiness and reliability of data-driven traffic TSEP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17984v3",
    "published_date": "2025-07-23 23:23:18 UTC",
    "updated_date": "2025-11-27 04:02:38 UTC"
  },
  {
    "arxiv_id": "2507.17978v2",
    "title": "MeAJOR Corpus: A Multi-Source Dataset for Phishing Email Detection",
    "authors": [
      "Paulo Mendes",
      "Eva Maia",
      "Isabel Praça"
    ],
    "abstract": "Phishing emails continue to pose a significant threat to cybersecurity by exploiting human vulnerabilities through deceptive content and malicious payloads. While Machine Learning (ML) models are effective at detecting phishing threats, their performance largely relies on the quality and diversity of the training data. This paper presents MeAJOR (Merged email Assets from Joint Open-source Repositories) Corpus, a novel, multi-source phishing email dataset designed to overcome critical limitations in existing resources. It integrates 135894 samples representing a broad number of phishing tactics and legitimate emails, with a wide spectrum of engineered features. We evaluated the dataset's utility for phishing detection research through systematic experiments with four classification models (RF, XGB, MLP, and CNN) across multiple feature configurations. Results highlight the dataset's effectiveness, achieving 98.34% F1 with XGB. By integrating broad features from multiple categories, our dataset provides a reusable and consistent resource, while addressing common challenges like class imbalance, generalisability and reproducibility.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages, 2 tables, WI-IAT 2025 conference",
    "pdf_url": "https://arxiv.org/pdf/2507.17978v2",
    "published_date": "2025-07-23 22:57:08 UTC",
    "updated_date": "2025-11-06 16:20:31 UTC"
  },
  {
    "arxiv_id": "2507.17977v1",
    "title": "Improving the Computational Efficiency and Explainability of GeoAggregator",
    "authors": [
      "Rui Deng",
      "Ziqi Li",
      "Mingshu Wang"
    ],
    "abstract": "Accurate modeling and explaining geospatial tabular data (GTD) are critical for understanding geospatial phenomena and their underlying processes. Recent work has proposed a novel transformer-based deep learning model named GeoAggregator (GA) for this purpose, and has demonstrated that it outperforms other statistical and machine learning approaches. In this short paper, we further improve GA by 1) developing an optimized pipeline that accelerates the dataloading process and streamlines the forward pass of GA to achieve better computational efficiency; and 2) incorporating a model ensembling strategy and a post-hoc model explanation function based on the GeoShapley framework to enhance model explainability. We validate the functionality and efficiency of the proposed strategies by applying the improved GA model to synthetic datasets. Experimental results show that our implementation improves the prediction accuracy and inference speed of GA compared to the original implementation. Moreover, explanation experiments indicate that GA can effectively captures the inherent spatial effects in the designed synthetic dataset. The complete pipeline has been made publicly available for community use (https://github.com/ruid7181/GA-sklearn).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "4 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.17977v1",
    "published_date": "2025-07-23 22:51:09 UTC",
    "updated_date": "2025-07-23 22:51:09 UTC"
  },
  {
    "arxiv_id": "2507.17974v3",
    "title": "Natural Language Processing for Tigrinya: Current State and Future Directions",
    "authors": [
      "Fitsum Gaim",
      "Jong C. Park"
    ],
    "abstract": "Despite being spoken by millions of people, Tigrinya remains severely underrepresented in Natural Language Processing (NLP) research. This work presents a comprehensive survey of NLP research for Tigrinya, analyzing over 50 studies from 2011 to 2025. We systematically review the current state of computational resources, models, and applications across fifteen downstream tasks, including morphological processing, part-of-speech tagging, named entity recognition, machine translation, question-answering, speech recognition, and synthesis. Our analysis reveals a clear trajectory from foundational, rule-based systems to modern neural architectures, with progress consistently driven by milestones in resource creation. We identify key challenges rooted in Tigrinya's morphological properties and resource scarcity, and highlight promising research directions, including morphology-aware modeling, cross-lingual transfer, and community-centered resource development. This work serves both as a reference for researchers and as a roadmap for advancing Tigrinya NLP. An anthology of surveyed studies and resources is publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17974v3",
    "published_date": "2025-07-23 22:45:30 UTC",
    "updated_date": "2025-12-30 19:22:48 UTC"
  },
  {
    "arxiv_id": "2507.17958v2",
    "title": "VIBE: Video-Input Brain Encoder for fMRI Response Modeling",
    "authors": [
      "Daniel Carlström Schad",
      "Shrey Dixit",
      "Janis Keck",
      "Viktor Studenyak",
      "Aleksandr Shpilevoi",
      "Andrej Bicanski"
    ],
    "abstract": "We present VIBE, a two-stage Transformer that fuses multi-modal video, audio, and text features to predict fMRI activity. Representations from open-source models (Qwen2.5, BEATs, Whisper, SlowFast, V-JEPA) are merged by a modality-fusion transformer and temporally decoded by a prediction transformer with rotary embeddings. Trained on 65 hours of movie data from the CNeuroMod dataset and ensembled across 20 seeds, VIBE attains mean parcel-wise Pearson correlations of 0.3225 on in-distribution Friends S07 and 0.2125 on six out-of-distribution films. An earlier iteration of the same architecture obtained 0.3198 and 0.2096, respectively, winning Phase-1 and placing second overall in the Algonauts 2025 Challenge.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17958v2",
    "published_date": "2025-07-23 22:02:56 UTC",
    "updated_date": "2025-07-25 01:14:19 UTC"
  },
  {
    "arxiv_id": "2507.17951v1",
    "title": "Are LLM Belief Updates Consistent with Bayes' Theorem?",
    "authors": [
      "Sohaib Imran",
      "Ihor Kendiukhov",
      "Matthew Broerman",
      "Aditya Thomas",
      "Riccardo Campanella",
      "Rob Lamb",
      "Peter M. Atkinson"
    ],
    "abstract": "Do larger and more capable language models learn to update their \"beliefs\" about propositions more consistently with Bayes' theorem when presented with evidence in-context? To test this, we formulate a Bayesian Coherence Coefficient (BCC) metric and generate a dataset with which to measure the BCC. We measure BCC for multiple pre-trained-only language models across five model families, comparing against the number of model parameters, the amount of training data, and model scores on common benchmarks. Our results provide evidence for our hypothesis that larger and more capable pre-trained language models assign credences that are more coherent with Bayes' theorem. These results have important implications for our understanding and governance of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at the ICML 2025 Workshop on Assessing World Models",
    "pdf_url": "https://arxiv.org/pdf/2507.17951v1",
    "published_date": "2025-07-23 21:46:37 UTC",
    "updated_date": "2025-07-23 21:46:37 UTC"
  },
  {
    "arxiv_id": "2507.17948v2",
    "title": "VERIRAG: A Post-Retrieval Auditing of Scientific Study Summaries",
    "authors": [
      "Shubham Mohole",
      "Hongjun Choi",
      "Shusen Liu",
      "Christine Klymko",
      "Shashank Kushwaha",
      "Derek Shi",
      "Wesam Sakla",
      "Sainyam Galhotra",
      "Ruben Glatt"
    ],
    "abstract": "Can democratized information gatekeepers and community note writers effectively decide what scientific information to amplify? Lacking domain expertise, such gatekeepers rely on automated reasoning agents that use RAG to ground evidence to cited sources. But such standard RAG systems validate summaries via semantic grounding and suffer from \"methodological blindness,\" treating all cited evidence as equally valid regardless of rigor. To address this, we introduce VERIRAG, a post-retrieval auditing framework that shifts the task from classification to methodological vulnerability detection. Using private Small Language Models (SLMs), VERIRAG audits source papers against the Veritable taxonomy of statistical rigor. We contribute: (1) a benchmark of 1,730 summaries with realistic, non-obvious perturbations modeled after retracted papers; (2) the auditable Veritable taxonomy; and (3) an operational system that improves Macro F1 by at least 19 points over baselines using GPT-based SLMs, a result that replicates across MISTRAL and Gemma architectures. Given the complexity of detecting non-obvious flaws, we view VERIRAG as a \"vulnerability-detection copilot,\" providing structured audit trails for human editors. In our experiments, individual human testers found over 80% of the generated audit trails useful for decision-making. We plan to release the dataset and code to support responsible science advocacy.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17948v2",
    "published_date": "2025-07-23 21:32:50 UTC",
    "updated_date": "2025-12-05 00:40:28 UTC"
  },
  {
    "arxiv_id": "2507.17944v1",
    "title": "Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text",
    "authors": [
      "Hulayyil Alshammari",
      "Praveen Rao"
    ],
    "abstract": "Large language models (LLMs) have rapidly transformed the creation of written materials. LLMs have led to questions about writing integrity, thereby driving the creation of artificial intelligence (AI) detection technologies. Adversarial attacks, such as standard and humanized paraphrasing, inhibit detectors' ability to detect machine-generated text. Previous studies have mainly focused on ChatGPT and other well-known LLMs and have shown varying accuracy across detectors. However, there is a clear gap in the literature about DeepSeek, a recently published LLM. Therefore, in this work, we investigate whether six generally accessible AI detection tools -- AI Text Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, and GPTZero -- can consistently recognize text generated by DeepSeek. The detectors were exposed to the aforementioned adversarial attacks. We also considered DeepSeek as a detector by performing few-shot prompting and chain-of-thought reasoning (CoT) for classifying AI and human-written text. We collected 49 human-authored question-answer pairs from before the LLM era and generated matching responses using DeepSeek-v3, producing 49 AI-generated samples. Then, we applied adversarial techniques such as paraphrasing and humanizing to add 196 more samples. These were used to challenge detector robustness and assess accuracy impact. While QuillBot and Copyleaks showed near-perfect performance on original and paraphrased DeepSeek text, others -- particularly AI Text Classifier and GPT-2 -- showed inconsistent results. The most effective attack was humanization, reducing accuracy to 71% for Copyleaks, 58% for QuillBot, and 52% for GPTZero. Few-shot and CoT prompting showed high accuracy, with the best five-shot result misclassifying only one of 49 samples (AI recall 96%, human recall 100%).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17944v1",
    "published_date": "2025-07-23 21:26:33 UTC",
    "updated_date": "2025-07-23 21:26:33 UTC"
  },
  {
    "arxiv_id": "2507.17942v1",
    "title": "Minimax Data Sanitization with Distortion Constraint and Adversarial Inference",
    "authors": [
      "Amirarsalan Moatazedian",
      "Yauhen Yakimenka",
      "Rémi A. Chou",
      "Jörg Kliewer"
    ],
    "abstract": "We study a privacy-preserving data-sharing setting where a privatizer transforms private data into a sanitized version observed by an authorized reconstructor and two unauthorized adversaries, each with access to side information correlated with the private data.\n  The reconstructor is evaluated under a distortion function, while each adversary is evaluated using a separate loss function. The privatizer ensures the reconstructor distortion remains below a fixed threshold while maximizing the minimum loss across the two adversaries. This two-adversary setting models cases where individual users cannot reconstruct the data accurately, but their combined side information enables estimation within the distortion threshold. The privatizer maximizes individual loss while permitting accurate reconstruction only through collaboration. This echoes secret-sharing principles, but with lossy rather than perfect recovery. We frame this as a constrained data-driven minimax optimization problem and propose a data-driven training procedure that alternately updates the privatizer, reconstructor, and adversaries. We also analyze the Gaussian and binary cases as special scenarios where optimal solutions can be obtained. These theoretical optimal results are benchmarks for evaluating the proposed minimax training approach.",
    "categories": [
      "cs.IT",
      "cs.AI"
    ],
    "primary_category": "cs.IT",
    "comment": "Accepted to IEEE ITW 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.17942v1",
    "published_date": "2025-07-23 21:22:35 UTC",
    "updated_date": "2025-07-23 21:22:35 UTC"
  },
  {
    "arxiv_id": "2508.03715v1",
    "title": "Detection of Autonomic Dysreflexia in Individuals With Spinal Cord Injury Using Multimodal Wearable Sensors",
    "authors": [
      "Bertram Fuchs",
      "Mehdi Ejtehadi",
      "Ana Cisnal",
      "Jürgen Pannek",
      "Anke Scheel-Sailer",
      "Robert Riener",
      "Inge Eriks-Hoogland",
      "Diego Paez-Granados"
    ],
    "abstract": "Autonomic Dysreflexia (AD) is a potentially life-threatening condition characterized by sudden, severe blood pressure (BP) spikes in individuals with spinal cord injury (SCI). Early, accurate detection is essential to prevent cardiovascular complications, yet current monitoring methods are either invasive or rely on subjective symptom reporting, limiting applicability in daily file. This study presents a non-invasive, explainable machine learning framework for detecting AD using multimodal wearable sensors. Data were collected from 27 individuals with chronic SCI during urodynamic studies, including electrocardiography (ECG), photoplethysmography (PPG), bioimpedance (BioZ), temperature, respiratory rate (RR), and heart rate (HR), across three commercial devices. Objective AD labels were derived from synchronized cuff-based BP measurements. Following signal preprocessing and feature extraction, BorutaSHAP was used for robust feature selection, and SHAP values for explainability. We trained modality- and device-specific weak learners and aggregated them using a stacked ensemble meta-model. Cross-validation was stratified by participants to ensure generalizability. HR- and ECG-derived features were identified as the most informative, particularly those capturing rhythm morphology and variability. The Nearest Centroid ensemble yielded the highest performance (Macro F1 = 0.77+/-0.03), significantly outperforming baseline models. Among modalities, HR achieved the highest area under the curve (AUC = 0.93), followed by ECG (0.88) and PPG (0.86). RR and temperature features contributed less to overall accuracy, consistent with missing data and low specificity. The model proved robust to sensor dropout and aligned well with clinical AD events. These results represent an important step toward personalized, real-time monitoring for individuals with SCI.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.03715v1",
    "published_date": "2025-07-23 21:18:23 UTC",
    "updated_date": "2025-07-23 21:18:23 UTC"
  },
  {
    "arxiv_id": "2507.17937v3",
    "title": "Bob's Confetti: Phonetic Memorization Attacks in Music and Video Generation",
    "authors": [
      "Jaechul Roh",
      "Zachary Novack",
      "Yuefeng Peng",
      "Niloofar Mireshghallah",
      "Taylor Berg-Kirkpatrick",
      "Amir Houmansadr"
    ],
    "abstract": "Generative AI systems for music and video commonly use text-based filters to prevent the regurgitation of copyrighted material. We expose a fundamental flaw in this approach by introducing Adversarial PhoneTic Prompting (APT), a novel attack that bypasses these safeguards by exploiting phonetic memorization. The APT attack replaces iconic lyrics with homophonic but semantically unrelated alternatives (e.g., \"mom's spaghetti\" becomes \"Bob's confetti\"), preserving acoustic structure while altering meaning; we identify high-fidelity phonetic matches using CMU pronouncing dictionary. We demonstrate that leading Lyrics-to-Song (L2S) models like SUNO and YuE regenerate songs with striking melodic and rhythmic similarity to their copyrighted originals when prompted with these altered lyrics. More surprisingly, this vulnerability extends across modalities. When prompted with phonetically modified lyrics from a song, a Text-to-Video (T2V) model like Veo 3 reconstructs visual scenes from the original music video-including specific settings and character archetypes-despite the absence of any visual cues in the prompt. Our findings reveal that models memorize deep, structural patterns tied to acoustics, not just verbatim text. This phonetic-to-visual leakage represents a critical vulnerability in transcript-conditioned generative models, rendering simple copyright filters ineffective and raising urgent concerns about the secure deployment of multimodal AI systems. Demo examples are available at our project page (https://jrohsc.github.io/music_attack/).",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17937v3",
    "published_date": "2025-07-23 21:11:47 UTC",
    "updated_date": "2025-10-29 17:29:43 UTC"
  },
  {
    "arxiv_id": "2507.17927v1",
    "title": "SMARTAPS: Tool-augmented LLMs for Operations Management",
    "authors": [
      "Timothy Tin Long Yu",
      "Mahdi Mostajabdaveh",
      "Jabo Serge Byusa",
      "Rindra Ramamonjison",
      "Giuseppe Carenini",
      "Kun Mao",
      "Zirui Zhou",
      "Yong Zhang"
    ],
    "abstract": "Large language models (LLMs) present intriguing opportunities to enhance user interaction with traditional algorithms and tools in real-world applications. An advanced planning system (APS) is a sophisticated software that leverages optimization to help operations planners create, interpret, and modify an operational plan. While highly beneficial, many customers are priced out of using an APS due to the ongoing costs of consultants responsible for customization and maintenance. To address the need for a more accessible APS expressed by supply chain planners, we present SmartAPS, a conversational system built on a tool-augmented LLM. Our system provides operations planners with an intuitive natural language chat interface, allowing them to query information, perform counterfactual reasoning, receive recommendations, and execute scenario analysis to better manage their operation. A short video demonstrating the system has been released: https://youtu.be/KtIrJjlDbyw",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "https://aaai.org/conference/aaai/aaai-25/bridge-ai-orms/",
    "pdf_url": "https://arxiv.org/pdf/2507.17927v1",
    "published_date": "2025-07-23 20:53:40 UTC",
    "updated_date": "2025-07-23 20:53:40 UTC"
  },
  {
    "arxiv_id": "2507.17924v1",
    "title": "UrbanPulse: A Cross-City Deep Learning Framework for Ultra-Fine-Grained Population Transfer Prediction",
    "authors": [
      "Hongrong Yang",
      "Markus Schlaepfer"
    ],
    "abstract": "Accurate population flow prediction is essential for urban planning, transportation management, and public health. Yet existing methods face key limitations: traditional models rely on static spatial assumptions, deep learning models struggle with cross-city generalization, and Large Language Models (LLMs) incur high computational costs while failing to capture spatial structure. Moreover, many approaches sacrifice resolution by clustering Points of Interest (POIs) or restricting coverage to subregions, limiting their utility for city-wide analytics. We introduce UrbanPulse, a scalable deep learning framework that delivers ultra-fine-grained, city-wide OD flow predictions by treating each POI as an individual node. It combines a temporal graph convolutional encoder with a transformer-based decoder to model multi-scale spatiotemporal dependencies. To ensure robust generalization across urban contexts, UrbanPulse employs a three-stage transfer learning strategy: pretraining on large-scale urban graphs, cold-start adaptation, and reinforcement learning fine-tuning.Evaluated on over 103 million cleaned GPS records from three metropolitan areas in California, UrbanPulse achieves state-of-the-art accuracy and scalability. Through efficient transfer learning, UrbanPulse takes a key step toward making high-resolution, AI-powered urban forecasting deployable in practice across diverse cities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17924v1",
    "published_date": "2025-07-23 20:44:25 UTC",
    "updated_date": "2025-07-23 20:44:25 UTC"
  },
  {
    "arxiv_id": "2507.17922v1",
    "title": "From Seed to Harvest: Augmenting Human Creativity with AI for Red-teaming Text-to-Image Models",
    "authors": [
      "Jessica Quaye",
      "Charvi Rastogi",
      "Alicia Parrish",
      "Oana Inel",
      "Minsuk Kahng",
      "Lora Aroyo",
      "Vijay Janapa Reddi"
    ],
    "abstract": "Text-to-image (T2I) models have become prevalent across numerous applications, making their robust evaluation against adversarial attacks a critical priority. Continuous access to new and challenging adversarial prompts across diverse domains is essential for stress-testing these models for resilience against novel attacks from multiple vectors. Current techniques for generating such prompts are either entirely authored by humans or synthetically generated. On the one hand, datasets of human-crafted adversarial prompts are often too small in size and imbalanced in their cultural and contextual representation. On the other hand, datasets of synthetically-generated prompts achieve scale, but typically lack the realistic nuances and creative adversarial strategies found in human-crafted prompts. To combine the strengths of both human and machine approaches, we propose Seed2Harvest, a hybrid red-teaming method for guided expansion of culturally diverse, human-crafted adversarial prompt seeds. The resulting prompts preserve the characteristics and attack patterns of human prompts while maintaining comparable average attack success rates (0.31 NudeNet, 0.36 SD NSFW, 0.12 Q16). Our expanded dataset achieves substantially higher diversity with 535 unique geographic locations and a Shannon entropy of 7.48, compared to 58 locations and 5.28 entropy in the original dataset. Our work demonstrates the importance of human-machine collaboration in leveraging human creativity and machine computational capacity to achieve comprehensive, scalable red-teaming for continuous T2I model safety evaluation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17922v1",
    "published_date": "2025-07-23 20:39:14 UTC",
    "updated_date": "2025-07-23 20:39:14 UTC"
  },
  {
    "arxiv_id": "2507.17907v1",
    "title": "Deep learning-aided inverse design of porous metamaterials",
    "authors": [
      "Phu Thien Nguyen",
      "Yousef Heider",
      "Dennis M. Kochmann",
      "Fadi Aldakheel"
    ],
    "abstract": "The ultimate aim of the study is to explore the inverse design of porous metamaterials using a deep learning-based generative framework. Specifically, we develop a property-variational autoencoder (pVAE), a variational autoencoder (VAE) augmented with a regressor, to generate structured metamaterials with tailored hydraulic properties, such as porosity and permeability. While this work uses the lattice Boltzmann method (LBM) to generate intrinsic permeability tensor data for limited porous microstructures, a convolutional neural network (CNN) is trained using a bottom-up approach to predict effective hydraulic properties. This significantly reduces the computational cost compared to direct LBM simulations. The pVAE framework is trained on two datasets: a synthetic dataset of artificial porous microstructures and CT-scan images of volume elements from real open-cell foams. The encoder-decoder architecture of the VAE captures key microstructural features, mapping them into a compact and interpretable latent space for efficient structure-property exploration. The study provides a detailed analysis and interpretation of the latent space, demonstrating its role in structure-property mapping, interpolation, and inverse design. This approach facilitates the generation of new metamaterials with desired properties. The datasets and codes used in this study will be made open-access to support further research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages, 29 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.17907v1",
    "published_date": "2025-07-23 20:07:53 UTC",
    "updated_date": "2025-07-23 20:07:53 UTC"
  },
  {
    "arxiv_id": "2508.03714v1",
    "title": "\"Think First, Verify Always\": Training Humans to Face AI Risks",
    "authors": [
      "Yuksel Aydin"
    ],
    "abstract": "Artificial intelligence enables unprecedented attacks on human cognition, yet cybersecurity remains predominantly device-centric. This paper introduces the \"Think First, Verify Always\" (TFVA) protocol, which repositions humans as 'Firewall Zero', the first line of defense against AI-enabled threats. The protocol is grounded in five operational principles: Awareness, Integrity, Judgment, Ethical Responsibility, and Transparency (AIJET). A randomized controlled trial (n=151) demonstrated that a minimal 3-minute intervention produced statistically significant improvements in cognitive security task performance, with participants showing an absolute +7.87% gains compared to controls. These results suggest that brief, principles-based training can rapidly enhance human resilience against AI-driven cognitive manipulation. We recommend that GenAI platforms embed \"Think First, Verify Always\" as a standard prompt, replacing passive warnings with actionable protocols to enhance trustworthy and ethical AI use. By bridging the gap between technical cybersecurity and human factors, the TFVA protocol establishes human-empowered security as a vital component of trustworthy AI systems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.03714v1",
    "published_date": "2025-07-23 19:59:08 UTC",
    "updated_date": "2025-07-23 19:59:08 UTC"
  },
  {
    "arxiv_id": "2507.17896v1",
    "title": "VeriMinder: Mitigating Analytical Vulnerabilities in NL2SQL",
    "authors": [
      "Shubham Mohole",
      "Sainyam Galhotra"
    ],
    "abstract": "Application systems using natural language interfaces to databases (NLIDBs) have democratized data analysis. This positive development has also brought forth an urgent challenge to help users who might use these systems without a background in statistical analysis to formulate bias-free analytical questions. Although significant research has focused on text-to-SQL generation accuracy, addressing cognitive biases in analytical questions remains underexplored. We present VeriMinder, https://veriminder.ai, an interactive system for detecting and mitigating such analytical vulnerabilities. Our approach introduces three key innovations: (1) a contextual semantic mapping framework for biases relevant to specific analysis contexts (2) an analytical framework that operationalizes the Hard-to-Vary principle and guides users in systematic data analysis (3) an optimized LLM-powered system that generates high-quality, task-specific prompts using a structured process involving multiple candidates, critic feedback, and self-reflection.\n  User testing confirms the merits of our approach. In direct user experience evaluation, 82.5% participants reported positively impacting the quality of the analysis. In comparative evaluation, VeriMinder scored significantly higher than alternative approaches, at least 20% better when considered for metrics of the analysis's concreteness, comprehensiveness, and accuracy. Our system, implemented as a web application, is set to help users avoid \"wrong question\" vulnerability during data analysis. VeriMinder code base with prompts, https://reproducibility.link/veriminder, is available as an MIT-licensed open-source software to facilitate further research and adoption within the community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17896v1",
    "published_date": "2025-07-23 19:48:12 UTC",
    "updated_date": "2025-07-23 19:48:12 UTC"
  },
  {
    "arxiv_id": "2507.17893v2",
    "title": "Action-List Reinforcement Learning Syndrome Decoding for Binary Linear Block Codes",
    "authors": [
      "Milad Taghipour",
      "Bane Vasic"
    ],
    "abstract": "This paper explores the application of reinforcement learning techniques to enhance the performance of decoding of linear block codes based on flipping bits and finding optimal decisions. We describe the methodology for mapping the iterative decoding process into Markov Decision Processes (MDPs) and propose different methods to reduce the number of states in the MDP. A truncated MDP is proposed to reduce the number of states in the MDP by learning a Hamming ball with a specified radius around codewords. We then propose a general scheme for reinforcement learning based decoders applicable to any class of codes to improve the performance of decoders. We call this scheme an action-list decoding. We design an action-list decoder based on the Deep-Q network values that substantially enhance performance. We also get benefit of automorphism group of code to further improve the code performance. Additionally, we propose a feedback-based method to exploit and enhance the performance of existing high-performing decoders by applying reinforcement learning algorithms after the existing decoders. These approaches effectively reduces the complexity of the reinforcement learning block. Finally, we present experimental results for the Low-Density Parity Check (LDPC) codes over the Binary Symmetric Channel (BSC) to demonstrate the efficiency of the proposed methods.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17893v2",
    "published_date": "2025-07-23 19:42:51 UTC",
    "updated_date": "2025-07-28 05:46:06 UTC"
  },
  {
    "arxiv_id": "2507.17874v1",
    "title": "I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis",
    "authors": [
      "SaiBarath Sundar",
      "Pranav Satheesan",
      "Udayaadithya Avadhanam"
    ],
    "abstract": "Recent advances in agentic systems for data analysis have emphasized automation of insight generation through multi-agent frameworks, and orchestration layers. While these systems effectively manage tasks like query translation, data transformation, and visualization, they often overlook the structured reasoning process underlying analytical thinking. Reasoning large language models (LLMs) used for multi-step problem solving are trained as general-purpose problem solvers. As a result, their reasoning or thinking steps do not adhere to fixed processes for specific tasks. Real-world data analysis requires a consistent cognitive workflow: interpreting vague goals, grounding them in contextual knowledge, constructing abstract plans, and adapting execution based on intermediate outcomes. We introduce I2I-STRADA (Information-to-Insight via Structured Reasoning Agent for Data Analysis), an agentic architecture designed to formalize this reasoning process. I2I-STRADA focuses on modeling how analysis unfolds via modular sub-tasks that reflect the cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench benchmarks show that I2I-STRADA outperforms prior systems in planning coherence and insight alignment, highlighting the importance of structured cognitive workflows in agent design for data analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17874v1",
    "published_date": "2025-07-23 18:58:42 UTC",
    "updated_date": "2025-07-23 18:58:42 UTC"
  },
  {
    "arxiv_id": "2507.17860v4",
    "title": "Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis",
    "authors": [
      "Ko Watanabe",
      "Stanislav Frolov",
      "Aya Hassan",
      "David Dembinsky",
      "Adriano Lucieri",
      "Andreas Dengel"
    ],
    "abstract": "Recent advances in deep learning and on-device inference could transform routine screening for skin cancers. Along with the anticipated benefits of this technology, potential dangers arise from unforeseen and inherent biases. A significant obstacle is building evaluation datasets that accurately reflect key demographics, including sex, age, and race, as well as other underrepresented groups. To address this, we train a state-of-the-art generative model to generate synthetic data in a controllable manner to assess the fairness of publicly available skin cancer classifiers. To evaluate whether synthetic images can be used as a fairness testing dataset, we prepare a real-image dataset (MILK10K) as a benchmark and compare the True Positive Rate result of three models (DeepGuide, MelaNet, and SkinLesionDensnet). As a result, the classification tendencies observed in each model when tested on real and generated images showed similar patterns across different attribute data sets. We confirm that highly realistic synthetic images facilitate model fairness verification.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17860v4",
    "published_date": "2025-07-23 18:33:27 UTC",
    "updated_date": "2025-12-22 10:41:08 UTC"
  },
  {
    "arxiv_id": "2507.17853v1",
    "title": "Detail++: Training-Free Detail Enhancer for Text-to-Image Diffusion Models",
    "authors": [
      "Lifeng Chen",
      "Jiner Wang",
      "Zihao Pan",
      "Beier Zhu",
      "Xiaofeng Yang",
      "Chi Zhang"
    ],
    "abstract": "Recent advances in text-to-image (T2I) generation have led to impressive visual results. However, these models still face significant challenges when handling complex prompt, particularly those involving multiple subjects with distinct attributes. Inspired by the human drawing process, which first outlines the composition and then incrementally adds details, we propose Detail++, a training-free framework that introduces a novel Progressive Detail Injection (PDI) strategy to address this limitation. Specifically, we decompose a complex prompt into a sequence of simplified sub-prompts, guiding the generation process in stages. This staged generation leverages the inherent layout-controlling capacity of self-attention to first ensure global composition, followed by precise refinement. To achieve accurate binding between attributes and corresponding subjects, we exploit cross-attention mechanisms and further introduce a Centroid Alignment Loss at test time to reduce binding noise and enhance attribute consistency. Extensive experiments on T2I-CompBench and a newly constructed style composition benchmark demonstrate that Detail++ significantly outperforms existing methods, particularly in scenarios involving multiple objects and complex stylistic conditions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17853v1",
    "published_date": "2025-07-23 18:20:46 UTC",
    "updated_date": "2025-07-23 18:20:46 UTC"
  },
  {
    "arxiv_id": "2507.17850v1",
    "title": "Performance Evaluation and Threat Mitigation in Large-scale 5G Core Deployment",
    "authors": [
      "Rodrigo Moreira",
      "Larissa F. Rodrigues Moreira",
      "Flávio de Oliveira Silva"
    ],
    "abstract": "The deployment of large-scale software-based 5G core functions presents significant challenges due to their reliance on optimized and intelligent resource provisioning for their services. Many studies have focused on analyzing the impact of resource allocation for complex deployments using mathematical models, queue theories, or even Artificial Intelligence (AI). This paper elucidates the effects of chaotic workloads, generated by Distributed Denial of Service (DDoS) on different Network Functions (NFs) on User Equipment registration performance. Our findings highlight the necessity of diverse resource profiles to ensure Service-Level Agreement (SLA) compliance in large-scale 5G core deployments. Additionally, our analysis of packet capture approaches demonstrates the potential of kernel-based monitoring for scalable security threat defense. Finally, our empirical evaluation provides insights into the effective deployment of 5G NFs in complex scenarios.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17850v1",
    "published_date": "2025-07-23 18:17:26 UTC",
    "updated_date": "2025-07-23 18:17:26 UTC"
  },
  {
    "arxiv_id": "2507.17844v1",
    "title": "SV3.3B: A Sports Video Understanding Model for Action Recognition",
    "authors": [
      "Sai Varun Kodathala",
      "Yashwanth Reddy Vutukoori",
      "Rakesh Vunnam"
    ],
    "abstract": "This paper addresses the challenge of automated sports video analysis, which has traditionally been limited by computationally intensive models requiring server-side processing and lacking fine-grained understanding of athletic movements. Current approaches struggle to capture the nuanced biomechanical transitions essential for meaningful sports analysis, often missing critical phases like preparation, execution, and follow-through that occur within seconds. To address these limitations, we introduce SV3.3B, a lightweight 3.3B parameter video understanding model that combines novel temporal motion difference sampling with self-supervised learning for efficient on-device deployment. Our approach employs a DWT-VGG16-LDA based keyframe extraction mechanism that intelligently identifies the 16 most representative frames from sports sequences, followed by a V-DWT-JEPA2 encoder pretrained through mask-denoising objectives and an LLM decoder fine-tuned for sports action description generation. Evaluated on a subset of the NSVA basketball dataset, SV3.3B achieves superior performance across both traditional text generation metrics and sports-specific evaluation criteria, outperforming larger closed-source models including GPT-4o variants while maintaining significantly lower computational requirements. Our model demonstrates exceptional capability in generating technically detailed and analytically rich sports descriptions, achieving 29.2% improvement over GPT-4o in ground truth validation metrics, with substantial improvements in information density, action complexity, and measurement precision metrics essential for comprehensive athletic analysis. Model Available at https://huggingface.co/sportsvision/SV3.3B.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 6 figures, 4 tables. Submitted to AIxSET 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.17844v1",
    "published_date": "2025-07-23 18:11:39 UTC",
    "updated_date": "2025-07-23 18:11:39 UTC"
  },
  {
    "arxiv_id": "2507.17748v2",
    "title": "Large Learning Rates Simultaneously Achieve Robustness to Spurious Correlations and Compressibility",
    "authors": [
      "Melih Barsbey",
      "Lucas Prieto",
      "Stefanos Zafeiriou",
      "Tolga Birdal"
    ],
    "abstract": "Robustness and resource-efficiency are two highly desirable properties for modern machine learning models. However, achieving them jointly remains a challenge. In this paper, we identify high learning rates as a facilitator for simultaneously achieving robustness to spurious correlations and network compressibility. We demonstrate that large learning rates also produce desirable representation properties such as invariant feature utilization, class separation, and activation sparsity. Our findings indicate that large learning rates compare favorably to other hyperparameters and regularization methods, in consistently satisfying these properties in tandem. In addition to demonstrating the positive effect of large learning rates across diverse spurious correlation datasets, models, and optimizers, we also present strong evidence that the previously documented success of large learning rates in standard classification tasks is related to addressing hidden/rare spurious correlations in the training dataset. Our investigation of the mechanisms underlying this phenomenon reveals the importance of confident mispredictions of bias-conflicting samples under large learning rates.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICCV 2025, 25 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.17748v2",
    "published_date": "2025-07-23 17:59:02 UTC",
    "updated_date": "2025-08-05 15:46:33 UTC"
  },
  {
    "arxiv_id": "2507.17747v2",
    "title": "Pretraining on the Test Set Is No Longer All You Need: A Debate-Driven Approach to QA Benchmarks",
    "authors": [
      "Linbo Cao",
      "Jinman Zhao"
    ],
    "abstract": "As frontier language models increasingly saturate standard QA benchmarks, concerns about data contamination, memorization, and escalating dataset creation costs persist. We propose a debate-driven evaluation paradigm that transforms any existing QA dataset into structured adversarial debates--where one model is given the official answer to defend, and another constructs and defends an alternative answer--adjudicated by a judge model blind to the correct solution. By forcing multi-round argumentation, this approach substantially increases difficulty while penalizing shallow memorization, yet reuses QA items to reduce curation overhead. We make two main contributions: (1) an evaluation pipeline to systematically convert QA tasks into debate-based assessments, and (2) a public benchmark that demonstrates our paradigm's effectiveness on a subset of MMLU-Pro questions, complete with standardized protocols and reference models. Empirical results validate the robustness of the method and its effectiveness against data contamination--a Llama 3.1 model fine-tuned on test questions showed dramatic accuracy improvements (50% -> 82%) but performed worse in debates. Results also show that even weaker judges can reliably differentiate stronger debaters, highlighting how debate-based evaluation can scale to future, more capable systems while maintaining a fraction of the cost of creating new benchmarks. Overall, our framework underscores that \"pretraining on the test set is no longer all you need,\" offering a sustainable path for measuring the genuine reasoning ability of advanced language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 7 figures. Accepted to COLM 2025. Code available at: github.com/l6cao/Debate-Driven-Evaluation",
    "pdf_url": "https://arxiv.org/pdf/2507.17747v2",
    "published_date": "2025-07-23 17:58:14 UTC",
    "updated_date": "2025-08-08 01:56:30 UTC"
  },
  {
    "arxiv_id": "2507.17746v2",
    "title": "Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains",
    "authors": [
      "Anisha Gunjal",
      "Anthony Wang",
      "Elaine Lau",
      "Vaskar Nath",
      "Yunzhong He",
      "Bing Liu",
      "Sean Hendryx"
    ],
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for complex reasoning tasks with clear correctness signals such as math and coding. However, extending it to real-world reasoning tasks is challenging, as evaluation depends on nuanced, multi-criteria judgments rather than binary correctness. Instance-specific rubrics have recently been used in evaluation benchmarks to capture such judgments, but their potential as reward signals for on-policy post-training remains underexplored. We introduce $\\textbf{Rubrics as Rewards}$ (RaR), an on-policy reinforcement learning method that extends RLVR beyond verifiable domains by using rubric-based feedback. Across both medical and science domains, we evaluate multiple strategies for aggregating rubric feedback into rewards. The best RaR variant achieves relative improvements of up to $31\\%$ on HealthBench and $7\\%$ on GPQA-Diamond over popular LLM-as-judge baselines that rely on direct Likert-based rewards. These results demonstrate that RaR-trained policies adapt well to diverse evaluation formats, performing strongly on both rubric-based and multiple-choice tasks. Moreover, we find that using rubrics as structured reward signals yields better alignment for smaller judges and reduces performance variance across judge scales.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "preprint",
    "pdf_url": "https://arxiv.org/pdf/2507.17746v2",
    "published_date": "2025-07-23 17:57:55 UTC",
    "updated_date": "2025-10-03 01:55:55 UTC"
  },
  {
    "arxiv_id": "2507.17745v3",
    "title": "Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention",
    "authors": [
      "Yiwen Chen",
      "Zhihao Li",
      "Yikai Wang",
      "Hu Zhang",
      "Qin Li",
      "Chi Zhang",
      "Guosheng Lin"
    ],
    "abstract": "Recent advances in sparse voxel representations have significantly improved the quality of 3D content generation, enabling high-resolution modeling with fine-grained geometry. However, existing frameworks suffer from severe computational inefficiencies due to the quadratic complexity of attention mechanisms in their two-stage diffusion pipelines. In this work, we propose Ultra3D, an efficient 3D generation framework that significantly accelerates sparse voxel modeling without compromising quality. Our method leverages the compact VecSet representation to efficiently generate a coarse object layout in the first stage, reducing token count and accelerating voxel coordinate prediction. To refine per-voxel latent features in the second stage, we introduce Part Attention, a geometry-aware localized attention mechanism that restricts attention computation within semantically consistent part regions. This design preserves structural continuity while avoiding unnecessary global attention, achieving up to 6.7x speed-up in latent generation. To support this mechanism, we construct a scalable part annotation pipeline that converts raw meshes into part-labeled sparse voxels. Extensive experiments demonstrate that Ultra3D supports high-resolution 3D generation at 1024 resolution and achieves state-of-the-art performance in both visual fidelity and user preference.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://buaacyw.github.io/ultra3d/",
    "pdf_url": "https://arxiv.org/pdf/2507.17745v3",
    "published_date": "2025-07-23 17:57:16 UTC",
    "updated_date": "2025-07-31 15:39:27 UTC"
  },
  {
    "arxiv_id": "2507.17744v1",
    "title": "Yume: An Interactive World Generation Model",
    "authors": [
      "Xiaofeng Mao",
      "Shaoheng Lin",
      "Zhen Li",
      "Chuanhao Li",
      "Wenshuo Peng",
      "Tong He",
      "Jiangmiao Pang",
      "Mingmin Chi",
      "Yu Qiao",
      "Kaipeng Zhang"
    ],
    "abstract": "Yume aims to use images, text, or videos to create an interactive, realistic, and dynamic world, which allows exploration and control using peripheral devices or neural signals. In this report, we present a preview version of \\method, which creates a dynamic world from an input image and allows exploration of the world using keyboard actions. To achieve this high-fidelity and interactive video world generation, we introduce a well-designed framework, which consists of four main components, including camera motion quantization, video generation architecture, advanced sampler, and model acceleration. First, we quantize camera motions for stable training and user-friendly interaction using keyboard inputs. Then, we introduce the Masked Video Diffusion Transformer~(MVDT) with a memory module for infinite video generation in an autoregressive manner. After that, training-free Anti-Artifact Mechanism (AAM) and Time Travel Sampling based on Stochastic Differential Equations (TTS-SDE) are introduced to the sampler for better visual quality and more precise control. Moreover, we investigate model acceleration by synergistic optimization of adversarial distillation and caching mechanisms. We use the high-quality world exploration dataset \\sekai to train \\method, and it achieves remarkable results in diverse scenes and applications. All data, codebase, and model weights are available on https://github.com/stdstu12/YUME. Yume will update monthly to achieve its original goal. Project page: https://stdstu12.github.io/YUME-Project/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17744v1",
    "published_date": "2025-07-23 17:57:09 UTC",
    "updated_date": "2025-07-23 17:57:09 UTC"
  },
  {
    "arxiv_id": "2507.17731v1",
    "title": "Flow Matching Meets Biology and Life Science: A Survey",
    "authors": [
      "Zihao Li",
      "Zhichen Zeng",
      "Xiao Lin",
      "Feihao Fang",
      "Yanru Qu",
      "Zhe Xu",
      "Zhining Liu",
      "Xuying Ning",
      "Tianxin Wei",
      "Ge Liu",
      "Hanghang Tong",
      "Jingrui He"
    ],
    "abstract": "Over the past decade, advances in generative modeling, such as generative adversarial networks, masked autoencoders, and diffusion models, have significantly transformed biological research and discovery, enabling breakthroughs in molecule design, protein generation, drug discovery, and beyond. At the same time, biological applications have served as valuable testbeds for evaluating the capabilities of generative models. Recently, flow matching has emerged as a powerful and efficient alternative to diffusion-based generative modeling, with growing interest in its application to problems in biology and life sciences. This paper presents the first comprehensive survey of recent developments in flow matching and its applications in biological domains. We begin by systematically reviewing the foundations and variants of flow matching, and then categorize its applications into three major areas: biological sequence modeling, molecule generation and design, and peptide and protein generation. For each, we provide an in-depth review of recent progress. We also summarize commonly used datasets and software tools, and conclude with a discussion of potential future directions. The corresponding curated resources are available at https://github.com/Violet24K/Awesome-Flow-Matching-Meets-Biology.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint, 27 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.17731v1",
    "published_date": "2025-07-23 17:44:29 UTC",
    "updated_date": "2025-07-23 17:44:29 UTC"
  },
  {
    "arxiv_id": "2507.17730v1",
    "title": "Online Submission and Evaluation System Design for Competition Operations",
    "authors": [
      "Zhe Chen",
      "Daniel Harabor",
      "Ryan Hechnenberger",
      "Nathan R. Sturtevant"
    ],
    "abstract": "Research communities have developed benchmark datasets across domains to compare the performance of algorithms and techniques However, tracking the progress in these research areas is not easy, as publications appear in different venues at the same time, and many of them claim to represent the state-of-the-art. To address this, research communities often organise periodic competitions to evaluate the performance of various algorithms and techniques, thereby tracking advancements in the field. However, these competitions pose a significant operational burden. The organisers must manage and evaluate a large volume of submissions. Furthermore, participants typically develop their solutions in diverse environments, leading to compatibility issues during the evaluation of their submissions. This paper presents an online competition system that automates the submission and evaluation process for a competition. The competition system allows organisers to manage large numbers of submissions efficiently, utilising isolated environments to evaluate submissions. This system has already been used successfully for several competitions, including the Grid-Based Pathfinding Competition and the League of Robot Runners competition.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This work was presented at the Workshop on the International Planning Competition (WIPC 2024)",
    "pdf_url": "https://arxiv.org/pdf/2507.17730v1",
    "published_date": "2025-07-23 17:44:10 UTC",
    "updated_date": "2025-07-23 17:44:10 UTC"
  },
  {
    "arxiv_id": "2507.17725v2",
    "title": "On the Interaction of Compressibility and Adversarial Robustness",
    "authors": [
      "Melih Barsbey",
      "Antônio H. Ribeiro",
      "Umut Şimşekli",
      "Tolga Birdal"
    ],
    "abstract": "Modern neural networks are expected to simultaneously satisfy a host of desirable properties: accurate fitting to training data, generalization to unseen inputs, parameter and computational efficiency, and robustness to adversarial perturbations. While compressibility and robustness have each been studied extensively, a unified understanding of their interaction still remains elusive. In this work, we develop a principled framework to analyze how different forms of compressibility - such as neuron-level sparsity and spectral compressibility - affect adversarial robustness. We show that these forms of compression can induce a small number of highly sensitive directions in the representation space, which adversaries can exploit to construct effective perturbations. Our analysis yields a simple yet instructive robustness bound, revealing how neuron and spectral compressibility impact $L_\\infty$ and $L_2$ robustness via their effects on the learned representations. Crucially, the vulnerabilities we identify arise irrespective of how compression is achieved - whether via regularization, architectural bias, or implicit learning dynamics. Through empirical evaluations across synthetic and realistic tasks, we confirm our theoretical predictions, and further demonstrate that these vulnerabilities persist under adversarial training and transfer learning, and contribute to the emergence of universal adversarial perturbations. Our findings show a fundamental tension between structured compressibility and robustness, and suggest new pathways for designing models that are both efficient and secure.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17725v2",
    "published_date": "2025-07-23 17:35:48 UTC",
    "updated_date": "2025-10-16 18:00:46 UTC"
  },
  {
    "arxiv_id": "2507.17718v1",
    "title": "AI Telephone Surveying: Automating Quantitative Data Collection with an AI Interviewer",
    "authors": [
      "Danny D. Leybzon",
      "Shreyas Tirumala",
      "Nishant Jain",
      "Summer Gillen",
      "Michael Jackson",
      "Cameron McPhee",
      "Jennifer Schmidt"
    ],
    "abstract": "With the rise of voice-enabled artificial intelligence (AI) systems, quantitative survey researchers have access to a new data-collection mode: AI telephone surveying. By using AI to conduct phone interviews, researchers can scale quantitative studies while balancing the dual goals of human-like interactivity and methodological rigor. Unlike earlier efforts that used interactive voice response (IVR) technology to automate these surveys, voice AI enables a more natural and adaptive respondent experience as it is more robust to interruptions, corrections, and other idiosyncrasies of human speech.\n  We built and tested an AI system to conduct quantitative surveys based on large language models (LLM), automatic speech recognition (ASR), and speech synthesis technologies. The system was specifically designed for quantitative research, and strictly adhered to research best practices like question order randomization, answer order randomization, and exact wording.\n  To validate the system's effectiveness, we deployed it to conduct two pilot surveys with the SSRS Opinion Panel and followed-up with a separate human-administered survey to assess respondent experiences. We measured three key metrics: the survey completion rates, break-off rates, and respondent satisfaction scores. Our results suggest that shorter instruments and more responsive AI interviewers may contribute to improvements across all three metrics studied.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17718v1",
    "published_date": "2025-07-23 17:30:14 UTC",
    "updated_date": "2025-07-23 17:30:14 UTC"
  },
  {
    "arxiv_id": "2507.17717v2",
    "title": "From Feedback to Checklists: Grounded Evaluation of AI-Generated Clinical Notes",
    "authors": [
      "Karen Zhou",
      "John Giorgi",
      "Pranav Mani",
      "Peng Xu",
      "Davis Liang",
      "Chenhao Tan"
    ],
    "abstract": "AI-generated clinical notes are increasingly used in healthcare, but evaluating their quality remains a challenge due to high subjectivity and limited scalability of expert review. Existing automated metrics often fail to align with real-world physician preferences. To address this, we propose a pipeline that systematically distills real user feedback into structured checklists for note evaluation. These checklists are designed to be interpretable, grounded in human feedback, and enforceable by LLM-based evaluators. Using deidentified data from over 21,000 clinical encounters (prepared in accordance with the HIPAA safe harbor standard) from a deployed AI medical scribe system, we show that our feedback-derived checklist outperforms a baseline approach in our offline evaluations in coverage, diversity, and predictive power for human ratings. Extensive experiments confirm the checklist's robustness to quality-degrading perturbations, significant alignment with clinician preferences, and practical value as an evaluation methodology. In offline research settings, our checklist offers a practical tool for flagging notes that may fall short of our defined quality standards.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2025 Industry Track",
    "pdf_url": "https://arxiv.org/pdf/2507.17717v2",
    "published_date": "2025-07-23 17:28:31 UTC",
    "updated_date": "2025-10-09 03:45:01 UTC"
  },
  {
    "arxiv_id": "2507.17699v1",
    "title": "Thinking Isn't an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations",
    "authors": [
      "Zhao Song",
      "Song Yue",
      "Jiahao Zhang"
    ],
    "abstract": "Large Reasoning Models (LRMs) have become a central focus in today's large language model (LLM) research, where models are designed to output a step-by-step thinking process before arriving at a final answer to handle complex reasoning tasks. Despite their promise, recent empirical studies (e.g., [Shojaee et al., 2025] from Apple) suggest that this thinking process may not actually enhance reasoning ability, where LLMs without explicit reasoning actually outperform LRMs on tasks with low or high complexity. In this work, we revisit these findings and investigate whether the limitations of LRMs persist when tool augmentations are introduced. We incorporate two types of tools, Python interpreters and scratchpads, and evaluate three representative LLMs and their LRM counterparts on Apple's benchmark reasoning puzzles. Our results show that, with proper tool use, LRMs consistently outperform their non-reasoning counterparts across all levels of task complexity. These findings challenge the recent narrative that reasoning is an illusion and highlight the potential of tool-augmented LRMs for solving complex problems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17699v1",
    "published_date": "2025-07-23 17:04:20 UTC",
    "updated_date": "2025-07-23 17:04:20 UTC"
  },
  {
    "arxiv_id": "2507.17695v2",
    "title": "Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks",
    "authors": [
      "Ilias Chatzistefanidis",
      "Navid Nikaein"
    ],
    "abstract": "Large Language Model (LLM)-based autonomous agents are expected to play a vital role in the evolution of 6G networks, by empowering real-time decision-making related to management and service provisioning to end-users. This shift facilitates the transition from a specialized intelligence approach, where artificial intelligence (AI) algorithms handle isolated tasks, to artificial general intelligence (AGI)-driven networks, where agents possess broader reasoning capabilities and can manage diverse network functions. In this paper, we introduce a novel agentic paradigm that combines LLMs with real-time optimization algorithms towards Trustworthy AI, defined as symbiotic agents. Optimizers at the LLM's input-level provide bounded uncertainty steering for numerically precise tasks, whereas output-level optimizers supervised by the LLM enable adaptive real-time control. We design and implement two novel agent types including: (i) Radio Access Network optimizers, and (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We further propose an end-to-end architecture for AGI networks and evaluate it on a 5G testbed capturing channel fluctuations from moving vehicles. Results show that symbiotic agents reduce decision errors fivefold compared to standalone LLM-based agents, while smaller language models (SLM) achieve similar accuracy with a 99.9% reduction in GPU resource overhead and in near-real-time loops of 82 ms. A multi-agent demonstration for collaborative RAN on the real-world testbed highlights significant flexibility in service-level agreement and resource allocation, reducing RAN over-utilization by approximately 44%. Drawing on our findings and open-source implementations, we introduce the symbiotic paradigm as the foundation for next-generation, AGI-driven networks-systems designed to remain adaptable, efficient, and trustworthy even as LLMs advance.",
    "categories": [
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to Computer Networks AI for 6G",
    "pdf_url": "https://arxiv.org/pdf/2507.17695v2",
    "published_date": "2025-07-23 17:01:23 UTC",
    "updated_date": "2025-09-03 09:49:56 UTC"
  },
  {
    "arxiv_id": "2507.17691v1",
    "title": "CASCADE: LLM-Powered JavaScript Deobfuscator at Google",
    "authors": [
      "Shan Jiang",
      "Pranoy Kovuri",
      "David Tao",
      "Zhixun Tan"
    ],
    "abstract": "Software obfuscation, particularly prevalent in JavaScript, hinders code comprehension and analysis, posing significant challenges to software testing, static analysis, and malware detection. This paper introduces CASCADE, a novel hybrid approach that integrates the advanced coding capabilities of Gemini with the deterministic transformation capabilities of a compiler Intermediate Representation (IR), specifically JavaScript IR (JSIR). By employing Gemini to identify critical prelude functions, the foundational components underlying the most prevalent obfuscation techniques, and leveraging JSIR for subsequent code transformations, CASCADE effectively recovers semantic elements like original strings and API names, and reveals original program behaviors. This method overcomes limitations of existing static and dynamic deobfuscation techniques, eliminating hundreds to thousands of hardcoded rules while achieving reliability and flexibility. CASCADE is already deployed in Google's production environment, demonstrating substantial improvements in JavaScript deobfuscation efficiency and reducing reverse engineering efforts.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17691v1",
    "published_date": "2025-07-23 16:57:32 UTC",
    "updated_date": "2025-07-23 16:57:32 UTC"
  },
  {
    "arxiv_id": "2507.17680v1",
    "title": "Simulating multiple human perspectives in socio-ecological systems using large language models",
    "authors": [
      "Yongchao Zeng",
      "Calum Brown",
      "Ioannis Kyriakou",
      "Ronja Hotz",
      "Mark Rounsevell"
    ],
    "abstract": "Understanding socio-ecological systems requires insights from diverse stakeholder perspectives, which are often hard to access. To enable alternative, simulation-based exploration of different stakeholder perspectives, we develop the HoPeS (Human-Oriented Perspective Shifting) modelling framework. HoPeS employs agents powered by large language models (LLMs) to represent various stakeholders; users can step into the agent roles to experience perspectival differences. A simulation protocol serves as a \"scaffold\" to streamline multiple perspective-taking simulations, supporting users in reflecting on, transitioning between, and integrating across perspectives. A prototype system is developed to demonstrate HoPeS in the context of institutional dynamics and land use change, enabling both narrative-driven and numerical experiments. In an illustrative experiment, a user successively adopts the perspectives of a system observer and a researcher - a role that analyses data from the embedded land use model to inform evidence-based decision-making for other LLM agents representing various institutions. Despite the user's effort to recommend technically sound policies, discrepancies persist between the policy recommendation and implementation due to stakeholders' competing advocacies, mirroring real-world misalignment between researcher and policymaker perspectives. The user's reflection highlights the subjective feelings of frustration and disappointment as a researcher, especially due to the challenge of maintaining political neutrality while attempting to gain political influence. Despite this, the user exhibits high motivation to experiment with alternative narrative framing strategies, suggesting the system's potential in exploring different perspectives. Further system and protocol refinement are likely to enable new forms of interdisciplinary collaboration in socio-ecological simulations.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17680v1",
    "published_date": "2025-07-23 16:42:51 UTC",
    "updated_date": "2025-07-23 16:42:51 UTC"
  },
  {
    "arxiv_id": "2507.17668v2",
    "title": "How Should We Meta-Learn Reinforcement Learning Algorithms?",
    "authors": [
      "Alexander David Goldie",
      "Zilin Wang",
      "Jaron Cohen",
      "Jakob Nicolaus Foerster",
      "Shimon Whiteson"
    ],
    "abstract": "The process of meta-learning algorithms from data, instead of relying on manual design, is growing in popularity as a paradigm for improving the performance of machine learning systems. Meta-learning shows particular promise for reinforcement learning (RL), where algorithms are often adapted from supervised or unsupervised learning despite their suboptimality for RL. However, until now there has been a severe lack of comparison between different meta-learning algorithms, such as using evolution to optimise over black-box functions or LLMs to propose code. In this paper, we carry out this empirical comparison of the different approaches when applied to a range of meta-learned algorithms which target different parts of the RL pipeline. In addition to meta-train and meta-test performance, we also investigate factors including the interpretability, sample cost and train time for each meta-learning algorithm. Based on these findings, we propose several guidelines for meta-learning new RL algorithms which will help ensure that future learned algorithms are as performant as possible.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted paper at Reinforcement Learning Conference (RLC) 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.17668v2",
    "published_date": "2025-07-23 16:31:38 UTC",
    "updated_date": "2025-09-10 12:25:27 UTC"
  },
  {
    "arxiv_id": "2507.17616v1",
    "title": "Vision Transformer attention alignment with human visual perception in aesthetic object evaluation",
    "authors": [
      "Miguel Carrasco",
      "César González-Martín",
      "José Aranda",
      "Luis Oliveros"
    ],
    "abstract": "Visual attention mechanisms play a crucial role in human perception and aesthetic evaluation. Recent advances in Vision Transformers (ViTs) have demonstrated remarkable capabilities in computer vision tasks, yet their alignment with human visual attention patterns remains underexplored, particularly in aesthetic contexts. This study investigates the correlation between human visual attention and ViT attention mechanisms when evaluating handcrafted objects. We conducted an eye-tracking experiment with 30 participants (9 female, 21 male, mean age 24.6 years) who viewed 20 artisanal objects comprising basketry bags and ginger jars. Using a Pupil Labs eye-tracker, we recorded gaze patterns and generated heat maps representing human visual attention. Simultaneously, we analyzed the same objects using a pre-trained ViT model with DINO (Self-DIstillation with NO Labels), extracting attention maps from each of the 12 attention heads. We compared human and ViT attention distributions using Kullback-Leibler divergence across varying Gaussian parameters (sigma=0.1 to 3.0). Statistical analysis revealed optimal correlation at sigma=2.4 +-0.03, with attention head #12 showing the strongest alignment with human visual patterns. Significant differences were found between attention heads, with heads #7 and #9 demonstrating the greatest divergence from human attention (p< 0.05, Tukey HSD test). Results indicate that while ViTs exhibit more global attention patterns compared to human focal attention, certain attention heads can approximate human visual behavior, particularly for specific object features like buckles in basketry items. These findings suggest potential applications of ViT attention mechanisms in product design and aesthetic evaluation, while highlighting fundamental differences in attention strategies between human perception and current AI models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "25 pages, 15 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.17616v1",
    "published_date": "2025-07-23 15:47:34 UTC",
    "updated_date": "2025-07-23 15:47:34 UTC"
  },
  {
    "arxiv_id": "2507.17596v2",
    "title": "PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving",
    "authors": [
      "Maciej K. Wozniak",
      "Lianhang Liu",
      "Yixi Cai",
      "Patric Jensfelt"
    ],
    "abstract": "While end-to-end autonomous driving models show promising results, their practical deployment is often hindered by large model sizes, a reliance on expensive LiDAR sensors and computationally intensive BEV feature representations. This limits their scalability, especially for mass-market vehicles equipped only with cameras. To address these challenges, we propose PRIX (Plan from Raw Pixels). Our novel and efficient end-to-end driving architecture operates using only camera data, without explicit BEV representation and forgoing the need for LiDAR. PRIX leverages a visual feature extractor coupled with a generative planning head to predict safe trajectories from raw pixel inputs directly. A core component of our architecture is the Context-aware Recalibration Transformer (CaRT), a novel module designed to effectively enhance multi-level visual features for more robust planning. We demonstrate through comprehensive experiments that PRIX achieves state-of-the-art performance on the NavSim and nuScenes benchmarks, matching the capabilities of larger, multimodal diffusion planners while being significantly more efficient in terms of inference speed and model size, making it a practical solution for real-world deployment. Our work is open-source and the code will be at https://maxiuw.github.io/prix.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "under review",
    "pdf_url": "https://arxiv.org/pdf/2507.17596v2",
    "published_date": "2025-07-23 15:28:23 UTC",
    "updated_date": "2025-07-24 11:04:42 UTC"
  },
  {
    "arxiv_id": "2507.17580v1",
    "title": "Enhancing Quantum Federated Learning with Fisher Information-Based Optimization",
    "authors": [
      "Amandeep Singh Bhatia",
      "Sabre Kais"
    ],
    "abstract": "Federated Learning (FL) has become increasingly popular across different sectors, offering a way for clients to work together to train a global model without sharing sensitive data. It involves multiple rounds of communication between the global model and participating clients, which introduces several challenges like high communication costs, heterogeneous client data, prolonged processing times, and increased vulnerability to privacy threats. In recent years, the convergence of federated learning and parameterized quantum circuits has sparked significant research interest, with promising implications for fields such as healthcare and finance. By enabling decentralized training of quantum models, it allows clients or institutions to collaboratively enhance model performance and outcomes while preserving data privacy. Recognizing that Fisher information can quantify the amount of information that a quantum state carries under parameter changes, thereby providing insight into its geometric and statistical properties. We intend to leverage this property to address the aforementioned challenges. In this work, we propose a Quantum Federated Learning (QFL) algorithm that makes use of the Fisher information computed on local client models, with data distributed across heterogeneous partitions. This approach identifies the critical parameters that significantly influence the quantum model's performance, ensuring they are preserved during the aggregation process. Our research assessed the effectiveness and feasibility of QFL by comparing its performance against other variants, and exploring the benefits of incorporating Fisher information in QFL settings. Experimental results on ADNI and MNIST datasets demonstrate the effectiveness of our approach in achieving better performance and robustness against the quantum federated averaging method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.ET",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17580v1",
    "published_date": "2025-07-23 15:14:53 UTC",
    "updated_date": "2025-07-23 15:14:53 UTC"
  },
  {
    "arxiv_id": "2507.21147v1",
    "title": "Advancing Wildfire Risk Prediction via Morphology-Aware Curriculum Contrastive Learning",
    "authors": [
      "Fabrizio Lo Scudo",
      "Alessio De Rango",
      "Luca Furnari",
      "Alfonso Senatore",
      "Donato D'Ambrosio",
      "Giuseppe Mendicino",
      "Gianluigi Greco"
    ],
    "abstract": "Wildfires significantly impact natural ecosystems and human health, leading to biodiversity loss, increased hydrogeological risks, and elevated emissions of toxic substances. Climate change exacerbates these effects, particularly in regions with rising temperatures and prolonged dry periods, such as the Mediterranean. This requires the development of advanced risk management strategies that utilize state-of-the-art technologies. However, in this context, the data show a bias toward an imbalanced setting, where the incidence of wildfire events is significantly lower than typical situations. This imbalance, coupled with the inherent complexity of high-dimensional spatio-temporal data, poses significant challenges for training deep learning architectures. Moreover, since precise wildfire predictions depend mainly on weather data, finding a way to reduce computational costs to enable more frequent updates using the latest weather forecasts would be beneficial. This paper investigates how adopting a contrastive framework can address these challenges through enhanced latent representations for the patch's dynamic features. We thus introduce a new morphology-based curriculum contrastive learning that mitigates issues associated with diverse regional characteristics and enables the use of smaller patch sizes without compromising performance. An experimental analysis is performed to validate the effectiveness of the proposed modeling strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear in the Proceedings of ECAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.21147v1",
    "published_date": "2025-07-23 14:23:45 UTC",
    "updated_date": "2025-07-23 14:23:45 UTC"
  },
  {
    "arxiv_id": "2507.17539v1",
    "title": "Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning",
    "authors": [
      "Xinyao Liu",
      "Diping Song"
    ],
    "abstract": "Multimodal large language models (MLLMs) demonstrate significant potential in the field of medical diagnosis. However, they face critical challenges in specialized domains such as ophthalmology, particularly the fragmentation of annotation granularity and inconsistencies in clinical reasoning logic, which hinder precise cross-modal understanding. This paper introduces FundusExpert, an ophthalmology-specific MLLM with integrated positioning-diagnosis reasoning capabilities, along with FundusGen, a dataset constructed through the intelligent Fundus-Engine system. Fundus-Engine automates localization and leverages MLLM-based semantic expansion to integrate global disease classification, local object detection, and fine-grained feature analysis within a single fundus image. Additionally, by constructing a clinically aligned cognitive chain, it guides the model to generate interpretable reasoning paths. FundusExpert, fine-tuned with instruction data from FundusGen, achieves the best performance in ophthalmic question-answering tasks, surpassing the average accuracy of the 40B MedRegA by 26.6%. It also excels in zero-shot report generation tasks, achieving a clinical consistency of 77.0%, significantly outperforming GPT-4o's 47.6%. Furthermore, we reveal a scaling law between data quality and model capability ($L \\propto N^{0.068}$), demonstrating that the cognitive alignment annotations in FundusGen enhance data utilization efficiency. By integrating region-level localization with diagnostic reasoning chains, our work develops a scalable, clinically-aligned MLLM and explores a pathway toward bridging the visual-language gap in specific MLLMs. Our project can be found at https://github.com/MeteorElf/FundusExpert.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17539v1",
    "published_date": "2025-07-23 14:19:30 UTC",
    "updated_date": "2025-07-23 14:19:30 UTC"
  },
  {
    "arxiv_id": "2507.17534v1",
    "title": "Federated Majorize-Minimization: Beyond Parameter Aggregation",
    "authors": [
      "Aymeric Dieuleveut",
      "Gersende Fort",
      "Mahmoud Hegazy",
      "Hoi-To Wai"
    ],
    "abstract": "This paper proposes a unified approach for designing stochastic optimization algorithms that robustly scale to the federated learning setting. Our work studies a class of Majorize-Minimization (MM) problems, which possesses a linearly parameterized family of majorizing surrogate functions. This framework encompasses (proximal) gradient-based algorithms for (regularized) smooth objectives, the Expectation Maximization algorithm, and many problems seen as variational surrogate MM. We show that our framework motivates a unifying algorithm called Stochastic Approximation Stochastic Surrogate MM (\\SSMM), which includes previous stochastic MM procedures as special instances. We then extend \\SSMM\\ to the federated setting, while taking into consideration common bottlenecks such as data heterogeneity, partial participation, and communication constraints; this yields \\QSMM. The originality of \\QSMM\\ is to learn locally and then aggregate information characterizing the \\textit{surrogate majorizing function}, contrary to classical algorithms which learn and aggregate the \\textit{original parameter}. Finally, to showcase the flexibility of this methodology beyond our theoretical setting, we use it to design an algorithm for computing optimal transport maps in the federated setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17534v1",
    "published_date": "2025-07-23 14:13:19 UTC",
    "updated_date": "2025-07-23 14:13:19 UTC"
  },
  {
    "arxiv_id": "2507.17526v1",
    "title": "Integrating Physics-Based and Data-Driven Approaches for Probabilistic Building Energy Modeling",
    "authors": [
      "Leandro Von Krannichfeldt",
      "Kristina Orehounig",
      "Olga Fink"
    ],
    "abstract": "Building energy modeling is a key tool for optimizing the performance of building energy systems. Historically, a wide spectrum of methods has been explored -- ranging from conventional physics-based models to purely data-driven techniques. Recently, hybrid approaches that combine the strengths of both paradigms have gained attention. These include strategies such as learning surrogates for physics-based models, modeling residuals between simulated and observed data, fine-tuning surrogates with real-world measurements, using physics-based outputs as additional inputs for data-driven models, and integrating the physics-based output into the loss function the data-driven model. Despite this progress, two significant research gaps remain. First, most hybrid methods focus on deterministic modeling, often neglecting the inherent uncertainties caused by factors like weather fluctuations and occupant behavior. Second, there has been little systematic comparison within a probabilistic modeling framework. This study addresses these gaps by evaluating five representative hybrid approaches for probabilistic building energy modeling, focusing on quantile predictions of building thermodynamics in a real-world case study. Our results highlight two main findings. First, the performance of hybrid approaches varies across different building room types, but residual learning with a Feedforward Neural Network performs best on average. Notably, the residual approach is the only model that produces physically intuitive predictions when applied to out-of-distribution test data. Second, Quantile Conformal Prediction is an effective procedure for calibrating quantile predictions in case of indoor temperature modeling.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17526v1",
    "published_date": "2025-07-23 14:07:33 UTC",
    "updated_date": "2025-07-23 14:07:33 UTC"
  },
  {
    "arxiv_id": "2507.17518v1",
    "title": "Enabling Cyber Security Education through Digital Twins and Generative AI",
    "authors": [
      "Vita Santa Barletta",
      "Vito Bavaro",
      "Miriana Calvano",
      "Antonio Curci",
      "Antonio Piccinno",
      "Davide Pio Posa"
    ],
    "abstract": "Digital Twins (DTs) are gaining prominence in cybersecurity for their ability to replicate complex IT (Information Technology), OT (Operational Technology), and IoT (Internet of Things) infrastructures, allowing for real time monitoring, threat analysis, and system simulation. This study investigates how integrating DTs with penetration testing tools and Large Language Models (LLMs) can enhance cybersecurity education and operational readiness. By simulating realistic cyber environments, this approach offers a practical, interactive framework for exploring vulnerabilities and defensive strategies. At the core of this research is the Red Team Knife (RTK), a custom penetration testing toolkit aligned with the Cyber Kill Chain model. RTK is designed to guide learners through key phases of cyberattacks, including reconnaissance, exploitation, and response within a DT powered ecosystem. The incorporation of Large Language Models (LLMs) further enriches the experience by providing intelligent, real-time feedback, natural language threat explanations, and adaptive learning support during training exercises. This combined DT LLM framework is currently being piloted in academic settings to develop hands on skills in vulnerability assessment, threat detection, and security operations. Initial findings suggest that the integration significantly improves the effectiveness and relevance of cybersecurity training, bridging the gap between theoretical knowledge and real-world application. Ultimately, the research demonstrates how DTs and LLMs together can transform cybersecurity education to meet evolving industry demands.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17518v1",
    "published_date": "2025-07-23 13:55:35 UTC",
    "updated_date": "2025-07-23 13:55:35 UTC"
  },
  {
    "arxiv_id": "2507.21146v1",
    "title": "Towards Unifying Quantitative Security Benchmarking for Multi Agent Systems",
    "authors": [
      "Gauri Sharma",
      "Vidhi Kulkarni",
      "Miles King",
      "Ken Huang"
    ],
    "abstract": "Evolving AI systems increasingly deploy multi-agent architectures where autonomous agents collaborate, share information, and delegate tasks through developing protocols. This connectivity, while powerful, introduces novel security risks. One such risk is a cascading risk: a breach in one agent can cascade through the system, compromising others by exploiting inter-agent trust. In tandem with OWASP's initiative for an Agentic AI Vulnerability Scoring System we define an attack vector, Agent Cascading Injection, analogous to Agent Impact Chain and Blast Radius, operating across networks of agents. In an ACI attack, a malicious input or tool exploit injected at one agent leads to cascading compromises and amplified downstream effects across agents that trust its outputs. We formalize this attack with an adversarial goal equation and key variables (compromised agent, injected exploit, polluted observations, etc.), capturing how a localized vulnerability can escalate into system-wide failure. We then analyze ACI's properties -- propagation chains, amplification factors, and inter-agent compound effects -- and map these to OWASP's emerging Agentic AI risk categories (e.g. Impact Chain and Orchestration Exploits). Finally, we argue that ACI highlights a critical need for quantitative benchmarking frameworks to evaluate the security of agent-to-agent communication protocols. We outline a methodology for stress-testing multi-agent systems (using architectures such as Google's A2A and Anthropic's MCP) against cascading trust failures, developing upon groundwork for measurable, standardized agent-to-agent security evaluation. Our work provides the necessary apparatus for engineers to benchmark system resilience, make data-driven architectural trade-offs, and develop robust defenses against a new generation of agentic threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "9 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.21146v1",
    "published_date": "2025-07-23 13:51:28 UTC",
    "updated_date": "2025-07-23 13:51:28 UTC"
  },
  {
    "arxiv_id": "2507.17514v2",
    "title": "TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment",
    "authors": [
      "Athanasios Davvetas",
      "Xenia Ziouvelou",
      "Ypatia Dami",
      "Alexios Kaponis",
      "Konstantina Giouvanopoulou",
      "Michael Papademas"
    ],
    "abstract": "This paper introduces the TAI Scan Tool, a RAG-based TAI self-assessment tool with minimalistic input. The current version of the tool supports the legal TAI assessment, with a particular emphasis on facilitating compliance with the AI Act. It involves a two-step approach with a pre-screening and an assessment phase. The assessment output of the system includes insight regarding the risk-level of the AI system according to the AI Act, while at the same time retrieving relevant articles to aid with compliance and notify on their obligations. Our qualitative evaluation using use-case scenarios yields promising results, correctly predicting risk levels while retrieving relevant articles across three distinct semantic groups. Furthermore, interpretation of results shows that the tool's reasoning relies on comparison with the setting of high-risk systems, a behaviour attributed to their deployment requiring careful consideration, and therefore frequently presented within the AI Act.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 1 figure, 4 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.17514v2",
    "published_date": "2025-07-23 13:51:23 UTC",
    "updated_date": "2025-09-17 11:19:18 UTC"
  },
  {
    "arxiv_id": "2507.17513v2",
    "title": "HOTA: Hamiltonian framework for Optimal Transport Advection",
    "authors": [
      "Nazar Buzun",
      "Daniil Shlenskii",
      "Maxim Bobrin",
      "Dmitry V. Dylov"
    ],
    "abstract": "Optimal transport (OT) has become a natural framework for guiding the probability flows. Yet, the majority of recent generative models assume trivial geometry (e.g., Euclidean) and rely on strong density-estimation assumptions, yielding trajectories that do not respect the true principles of optimality in the underlying manifold. We present Hamiltonian Optimal Transport Advection (HOTA), a Hamilton-Jacobi-Bellman based method that tackles the dual dynamical OT problem explicitly through Kantorovich potentials, enabling efficient and scalable trajectory optimization. Our approach effectively evades the need for explicit density modeling, performing even when the cost functionals are non-smooth. Empirically, HOTA outperforms all baselines in standard benchmarks, as well as in custom datasets with non-differentiable costs, both in terms of feasibility and optimality.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17513v2",
    "published_date": "2025-07-23 13:51:06 UTC",
    "updated_date": "2025-09-20 21:07:37 UTC"
  },
  {
    "arxiv_id": "2507.17512v1",
    "title": "Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning",
    "authors": [
      "Yu Li",
      "Zhuoshi Pan",
      "Honglin Lin",
      "Mengyuan Sun",
      "Conghui He",
      "Lijun Wu"
    ],
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the reasoning capabilities of LLMs. Existing research has predominantly concentrated on isolated reasoning domains such as mathematical problem-solving, coding tasks, or logical reasoning. However, real world reasoning scenarios inherently demand an integrated application of multiple cognitive skills. Despite this, the interplay among these reasoning skills under reinforcement learning remains poorly understood. To bridge this gap, we present a systematic investigation of multi-domain reasoning within the RLVR framework, explicitly focusing on three primary domains: mathematical reasoning, code generation, and logical puzzle solving. We conduct a comprehensive study comprising four key components: (1) Leveraging the GRPO algorithm and the Qwen-2.5-7B model family, our study thoroughly evaluates the models' in-domain improvements and cross-domain generalization capabilities when trained on single-domain datasets. (2) Additionally, we examine the intricate interactions including mutual enhancements and conflicts that emerge during combined cross-domain training. (3) To further understand the influence of SFT on RL, we also analyze and compare performance differences between base and instruct models under identical RL configurations. (4) Furthermore, we delve into critical RL training details, systematically exploring the impacts of curriculum learning strategies, variations in reward design, and language-specific factors. Through extensive experiments, our results offer significant insights into the dynamics governing domain interactions, revealing key factors influencing both specialized and generalizable reasoning performance. These findings provide valuable guidance for optimizing RL methodologies to foster comprehensive, multi-domain reasoning capabilities in LLMs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "27 pages, 24 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.17512v1",
    "published_date": "2025-07-23 13:51:04 UTC",
    "updated_date": "2025-07-23 13:51:04 UTC"
  },
  {
    "arxiv_id": "2507.17494v3",
    "title": "To Trust or Not to Trust: On Calibration in ML-based Resource Allocation for Wireless Networks",
    "authors": [
      "Rashika Raina",
      "Nidhi Simmons",
      "David E. Simmons",
      "Michel Daoud Yacoub",
      "Trung Q. Duong"
    ],
    "abstract": "In next-generation communications and networks, machine learning (ML) models are expected to deliver not only accurate predictions but also well-calibrated confidence scores that reflect the true likelihood of correct decisions. This paper studies the calibration performance of an ML-based outage predictor within a single-user, multi-resource allocation framework. We first establish key theoretical properties of this system's outage probability (OP) under perfect calibration. Importantly, we show that as the number of resources grows, the OP of a perfectly calibrated predictor approaches the expected output conditioned on it being below the classification threshold. In contrast, when only one resource is available, the system's OP equals the model's overall expected output. We then derive the OP conditions for a perfectly calibrated predictor. These findings guide the choice of the classification threshold to achieve a desired OP, helping system designers meet specific reliability requirements. We also demonstrate that post-processing calibration cannot improve the system's minimum achievable OP, as it does not introduce new information about future channel states. Additionally, we show that well-calibrated models are part of a broader class of predictors that necessarily improve OP. In particular, we establish a monotonicity condition that the accuracy-confidence function must satisfy for such improvement to occur. To demonstrate these theoretical properties, we conduct a rigorous simulation-based analysis using post-processing calibration techniques: Platt scaling and isotonic regression. As part of this framework, the predictor is trained using an outage loss function specifically designed for this system. Furthermore, this analysis is performed on Rayleigh fading channels with temporal correlation captured by Clarke's 2D model, which accounts for receiver mobility.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17494v3",
    "published_date": "2025-07-23 13:23:43 UTC",
    "updated_date": "2025-11-19 21:12:27 UTC"
  },
  {
    "arxiv_id": "2507.17493v1",
    "title": "Automated Hybrid Grounding Using Structural and Data-Driven Heuristics",
    "authors": [
      "Alexander Beiser",
      "Markus Hecher",
      "Stefan Woltran"
    ],
    "abstract": "The grounding bottleneck poses one of the key challenges that hinders the widespread adoption of Answer Set Programming in industry. Hybrid Grounding is a step in alleviating the bottleneck by combining the strength of standard bottom-up grounding with recently proposed techniques where rule bodies are decoupled during grounding. However, it has remained unclear when hybrid grounding shall use body-decoupled grounding and when to use standard bottom-up grounding. In this paper, we address this issue by developing automated hybrid grounding: we introduce a splitting algorithm based on data-structural heuristics that detects when to use body-decoupled grounding and when standard grounding is beneficial. We base our heuristics on the structure of rules and an estimation procedure that incorporates the data of the instance. The experiments conducted on our prototypical implementation demonstrate promising results, which show an improvement on hard-to-ground scenarios, whereas on hard-to-solve instances we approach state-of-the-art performance.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17493v1",
    "published_date": "2025-07-23 13:19:02 UTC",
    "updated_date": "2025-07-23 13:19:02 UTC"
  },
  {
    "arxiv_id": "2507.17487v2",
    "title": "CQE under Epistemic Dependencies: Algorithms and Experiments (extended version)",
    "authors": [
      "Lorenzo Marconi",
      "Flavia Ricci",
      "Riccardo Rosati"
    ],
    "abstract": "We investigate Controlled Query Evaluation (CQE) over ontologies, where information disclosure is regulated by epistemic dependencies (EDs), a family of logical rules recently proposed for the CQE framework. In particular, we combine EDs with the notion of optimal GA censors, i.e. maximal sets of ground atoms that are entailed by the ontology and can be safely revealed. We focus on answering Boolean unions of conjunctive queries (BUCQs) with respect to the intersection of all optimal GA censors - an approach that has been shown in other contexts to ensure strong security guarantees with favorable computational behavior. First, we characterize the security of this intersection-based approach and identify a class of EDs (namely, full EDs) for which it remains safe. Then, for a subclass of EDs and for DL-Lite_R ontologies, we show that answering BUCQs in the above CQE semantics is in AC^0 in data complexity by presenting a suitable, detailed first-order rewriting algorithm. Finally, we report on experiments conducted in two different evaluation scenarios, showing the practical feasibility of our rewriting function.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of paper accepted at the 24th International Semantic Web Conference (ISWC 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.17487v2",
    "published_date": "2025-07-23 13:10:33 UTC",
    "updated_date": "2025-07-28 16:42:27 UTC"
  },
  {
    "arxiv_id": "2507.17486v1",
    "title": "Unsupervised anomaly detection using Bayesian flow networks: application to brain FDG PET in the context of Alzheimer's disease",
    "authors": [
      "Hugues Roy",
      "Reuben Dorent",
      "Ninon Burgos"
    ],
    "abstract": "Unsupervised anomaly detection (UAD) plays a crucial role in neuroimaging for identifying deviations from healthy subject data and thus facilitating the diagnosis of neurological disorders. In this work, we focus on Bayesian flow networks (BFNs), a novel class of generative models, which have not yet been applied to medical imaging or anomaly detection. BFNs combine the strength of diffusion frameworks and Bayesian inference. We introduce AnoBFN, an extension of BFNs for UAD, designed to: i) perform conditional image generation under high levels of spatially correlated noise, and ii) preserve subject specificity by incorporating a recursive feedback from the input image throughout the generative process. We evaluate AnoBFN on the challenging task of Alzheimer's disease-related anomaly detection in FDG PET images. Our approach outperforms other state-of-the-art methods based on VAEs (beta-VAE), GANs (f-AnoGAN), and diffusion models (AnoDDPM), demonstrating its effectiveness at detecting anomalies while reducing false positive rates.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17486v1",
    "published_date": "2025-07-23 13:09:57 UTC",
    "updated_date": "2025-07-23 13:09:57 UTC"
  },
  {
    "arxiv_id": "2507.17482v1",
    "title": "LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning",
    "authors": [
      "Luca Salvatore Lorello",
      "Nikolaos Manginas",
      "Marco Lippi",
      "Stefano Melacci"
    ],
    "abstract": "Neuro-symbolic artificial intelligence aims to combine neural architectures with symbolic approaches that can represent knowledge in a human-interpretable formalism. Continual learning concerns with agents that expand their knowledge over time, improving their skills while avoiding to forget previously learned concepts. Most of the existing approaches for neuro-symbolic artificial intelligence are applied to static scenarios only, and the challenging setting where reasoning along the temporal dimension is necessary has been seldom explored. In this work we introduce LTLZinc, a benchmarking framework that can be used to generate datasets covering a variety of different problems, against which neuro-symbolic and continual learning methods can be evaluated along the temporal and constraint-driven dimensions. Our framework generates expressive temporal reasoning and continual learning tasks from a linear temporal logic specification over MiniZinc constraints, and arbitrary image classification datasets. Fine-grained annotations allow multiple neural and neuro-symbolic training settings on the same generated datasets. Experiments on six neuro-symbolic sequence classification and four class-continual learning tasks generated by LTLZinc, demonstrate the challenging nature of temporal learning and reasoning, and highlight limitations of current state-of-the-art methods. We release the LTLZinc generator and ten ready-to-use tasks to the neuro-symbolic and continual learning communities, in the hope of fostering research towards unified temporal learning and reasoning frameworks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17482v1",
    "published_date": "2025-07-23 13:04:13 UTC",
    "updated_date": "2025-07-23 13:04:13 UTC"
  },
  {
    "arxiv_id": "2507.17477v1",
    "title": "An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models",
    "authors": [
      "Haoran Sun",
      "Zekun Zhang",
      "Shaoning Zeng"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable progress in instruction following and general-purpose reasoning. However, achieving high-quality alignment with human intent and safety norms without human annotations remains a fundamental challenge. In this work, we propose an Uncertainty-Driven Adaptive Self-Alignment (UDASA) framework designed to improve LLM alignment in a fully automated manner. UDASA first generates multiple responses for each input and quantifies output uncertainty across three dimensions: semantics, factuality, and value alignment. Based on these uncertainty scores, the framework constructs preference pairs and categorizes training samples into three stages, conservative, moderate, and exploratory, according to their uncertainty difference. The model is then optimized progressively across these stages. In addition, we conduct a series of preliminary studies to validate the core design assumptions and provide strong empirical motivation for the proposed framework. Experimental results show that UDASA outperforms existing alignment methods across multiple tasks, including harmlessness, helpfulness, truthfulness, and controlled sentiment generation, significantly improving model performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17477v1",
    "published_date": "2025-07-23 13:00:00 UTC",
    "updated_date": "2025-07-23 13:00:00 UTC"
  },
  {
    "arxiv_id": "2507.17476v1",
    "title": "MultiNRC: A Challenging and Native Multilingual Reasoning Evaluation Benchmark for LLMs",
    "authors": [
      "Alexander R. Fabbri",
      "Diego Mares",
      "Jorge Flores",
      "Meher Mankikar",
      "Ernesto Hernandez",
      "Dean Lee",
      "Bing Liu",
      "Chen Xing"
    ],
    "abstract": "Although recent Large Language Models (LLMs) have shown rapid improvement on reasoning benchmarks in English, the evaluation of such LLMs' multilingual reasoning capability across diverse languages and cultural contexts remains limited. Existing multilingual reasoning benchmarks are typically constructed by translating existing English reasoning benchmarks, biasing these benchmarks towards reasoning problems with context in English language/cultures. In this work, we introduce the Multilingual Native Reasoning Challenge (MultiNRC), a benchmark designed to assess LLMs on more than 1,000 native, linguistic and culturally grounded reasoning questions written by native speakers in French, Spanish, and Chinese. MultiNRC covers four core reasoning categories: language-specific linguistic reasoning, wordplay & riddles, cultural/tradition reasoning, and math reasoning with cultural relevance. For cultural/tradition reasoning and math reasoning with cultural relevance, we also provide English equivalent translations of the multilingual questions by manual translation from native speakers fluent in English. This set of English equivalents can provide a direct comparison of LLM reasoning capacity in other languages vs. English on the same reasoning questions. We systematically evaluate current 14 leading LLMs covering most LLM families on MultiNRC and its English equivalent set. The results show that (1) current LLMs are still not good at native multilingual reasoning, with none scoring above 50% on MultiNRC; (2) LLMs exhibit distinct strengths and weaknesses in handling linguistic, cultural, and logical reasoning tasks; (3) Most models perform substantially better in math reasoning in English compared to in original languages (+10%), indicating persistent challenges with culturally grounded knowledge.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17476v1",
    "published_date": "2025-07-23 12:56:31 UTC",
    "updated_date": "2025-07-23 12:56:31 UTC"
  },
  {
    "arxiv_id": "2507.17472v1",
    "title": "BGM-HAN: A Hierarchical Attention Network for Accurate and Fair Decision Assessment on Semi-Structured Profiles",
    "authors": [
      "Junhua Liu",
      "Roy Ka-Wei Lee",
      "Kwan Hui Lim"
    ],
    "abstract": "Human decision-making in high-stakes domains often relies on expertise and heuristics, but is vulnerable to hard-to-detect cognitive biases that threaten fairness and long-term outcomes. This work presents a novel approach to enhancing complex decision-making workflows through the integration of hierarchical learning alongside various enhancements. Focusing on university admissions as a representative high-stakes domain, we propose BGM-HAN, an enhanced Byte-Pair Encoded, Gated Multi-head Hierarchical Attention Network, designed to effectively model semi-structured applicant data. BGM-HAN captures multi-level representations that are crucial for nuanced assessment, improving both interpretability and predictive performance. Experimental results on real admissions data demonstrate that our proposed model significantly outperforms both state-of-the-art baselines from traditional machine learning to large language models, offering a promising framework for augmenting decision-making in domains where structure, context, and fairness matter. Source code is available at: https://github.com/junhua/bgm-han.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ASONAM 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.17472v1",
    "published_date": "2025-07-23 12:52:38 UTC",
    "updated_date": "2025-07-23 12:52:38 UTC"
  },
  {
    "arxiv_id": "2507.17470v1",
    "title": "Demonstration of Efficient Predictive Surrogates for Large-scale Quantum Processors",
    "authors": [
      "Wei-You Liao",
      "Yuxuan Du",
      "Xinbiao Wang",
      "Tian-Ci Tian",
      "Yong Luo",
      "Bo Du",
      "Dacheng Tao",
      "He-Liang Huang"
    ],
    "abstract": "The ongoing development of quantum processors is driving breakthroughs in scientific discovery. Despite this progress, the formidable cost of fabricating large-scale quantum processors means they will remain rare for the foreseeable future, limiting their widespread application. To address this bottleneck, we introduce the concept of predictive surrogates, which are classical learning models designed to emulate the mean-value behavior of a given quantum processor with provably computational efficiency. In particular, we propose two predictive surrogates that can substantially reduce the need for quantum processor access in diverse practical scenarios. To demonstrate their potential in advancing digital quantum simulation, we use these surrogates to emulate a quantum processor with up to 20 programmable superconducting qubits, enabling efficient pre-training of variational quantum eigensolvers for families of transverse-field Ising models and identification of non-equilibrium Floquet symmetry-protected topological phases. Experimental results reveal that the predictive surrogates not only reduce measurement overhead by orders of magnitude, but can also surpass the performance of conventional, quantum-resource-intensive approaches. Collectively, these findings establish predictive surrogates as a practical pathway to broadening the impact of advanced quantum processors.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "53 pages, 15 figures, comments are welcome",
    "pdf_url": "https://arxiv.org/pdf/2507.17470v1",
    "published_date": "2025-07-23 12:51:03 UTC",
    "updated_date": "2025-07-23 12:51:03 UTC"
  },
  {
    "arxiv_id": "2507.17467v1",
    "title": "Probing Vision-Language Understanding through the Visual Entailment Task: promises and pitfalls",
    "authors": [
      "Elena Pitta",
      "Tom Kouwenhoven",
      "Tessa Verhoef"
    ],
    "abstract": "This study investigates the extent to which the Visual Entailment (VE) task serves as a reliable probe of vision-language understanding in multimodal language models, using the LLaMA 3.2 11B Vision model as a test case. Beyond reporting performance metrics, we aim to interpret what these results reveal about the underlying possibilities and limitations of the VE task. We conduct a series of experiments across zero-shot, few-shot, and fine-tuning settings, exploring how factors such as prompt design, the number and order of in-context examples and access to visual information might affect VE performance. To further probe the reasoning processes of the model, we used explanation-based evaluations. Results indicate that three-shot inference outperforms the zero-shot baselines. However, additional examples introduce more noise than they provide benefits. Additionally, the order of the labels in the prompt is a critical factor that influences the predictions. In the absence of visual information, the model has a strong tendency to hallucinate and imagine content, raising questions about the model's over-reliance on linguistic priors. Fine-tuning yields strong results, achieving an accuracy of 83.3% on the e-SNLI-VE dataset and outperforming the state-of-the-art OFA-X model. Additionally, the explanation evaluation demonstrates that the fine-tuned model provides semantically meaningful explanations similar to those of humans, with a BERTScore F1-score of 89.2%. We do, however, find comparable BERTScore results in experiments with limited vision, questioning the visual grounding of this task. Overall, our results highlight both the utility and limitations of VE as a diagnostic task for vision-language understanding and point to directions for refining multimodal evaluation methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "LUHME: 2nd Workshop on Language Understanding in the Human-Machine Era",
    "pdf_url": "https://arxiv.org/pdf/2507.17467v1",
    "published_date": "2025-07-23 12:46:51 UTC",
    "updated_date": "2025-07-23 12:46:51 UTC"
  },
  {
    "arxiv_id": "2507.22925v1",
    "title": "Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents",
    "authors": [
      "Haoran Sun",
      "Shaoning Zeng"
    ],
    "abstract": "Long-term memory is one of the key factors influencing the reasoning capabilities of Large Language Model Agents (LLM Agents). Incorporating a memory mechanism that effectively integrates past interactions can significantly enhance decision-making and contextual coherence of LLM Agents. While recent works have made progress in memory storage and retrieval, such as encoding memory into dense vectors for similarity-based search or organizing knowledge in the form of graph, these approaches often fall short in structured memory organization and efficient retrieval. To address these limitations, we propose a Hierarchical Memory (H-MEM) architecture for LLM Agents that organizes and updates memory in a multi-level fashion based on the degree of semantic abstraction. Each memory vector is embedded with a positional index encoding pointing to its semantically related sub-memories in the next layer. During the reasoning phase, an index-based routing mechanism enables efficient, layer-by-layer retrieval without performing exhaustive similarity computations. We evaluate our method on five task settings from the LoCoMo dataset. Experimental results show that our approach consistently outperforms five baseline methods, demonstrating its effectiveness in long-term dialogue scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22925v1",
    "published_date": "2025-07-23 12:45:44 UTC",
    "updated_date": "2025-07-23 12:45:44 UTC"
  },
  {
    "arxiv_id": "2507.17448v1",
    "title": "Reasoning-Driven Retrosynthesis Prediction with Large Language Models via Reinforcement Learning",
    "authors": [
      "Situo Zhang",
      "Hanqi Li",
      "Lu Chen",
      "Zihan Zhao",
      "Xuanze Lin",
      "Zichen Zhu",
      "Bo Chen",
      "Xin Chen",
      "Kai Yu"
    ],
    "abstract": "Retrosynthesis planning, essential in organic synthesis and drug discovery, has greatly benefited from recent AI-driven advancements. Nevertheless, existing methods frequently face limitations in both applicability and explainability. Traditional graph-based and sequence-to-sequence models often lack generalized chemical knowledge, leading to predictions that are neither consistently accurate nor easily explainable. To address these challenges, we introduce RetroDFM-R, a reasoning-based large language model (LLM) designed specifically for chemical retrosynthesis. Leveraging large-scale reinforcement learning guided by chemically verifiable rewards, RetroDFM-R significantly enhances prediction accuracy and explainability. Comprehensive evaluations demonstrate that RetroDFM-R significantly outperforms state-of-the-art methods, achieving a top-1 accuracy of 65.0% on the USPTO-50K benchmark. Double-blind human assessments further validate the chemical plausibility and practical utility of RetroDFM-R's predictions. RetroDFM-R also accurately predicts multistep retrosynthetic routes reported in the literature for both real-world drug molecules and perovskite materials. Crucially, the model's explicit reasoning process provides human-interpretable insights, thereby enhancing trust and practical value in real-world retrosynthesis applications.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "cs.CE",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2507.17448v1",
    "published_date": "2025-07-23 12:13:06 UTC",
    "updated_date": "2025-07-23 12:13:06 UTC"
  },
  {
    "arxiv_id": "2507.17445v1",
    "title": "IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception",
    "authors": [
      "Haichuan Li",
      "Changda Tian",
      "Panos Trahanias",
      "Tomi Westerlund"
    ],
    "abstract": "Detecting diverse objects within complex indoor 3D point clouds presents significant challenges for robotic perception, particularly with varied object shapes, clutter, and the co-existence of static and dynamic elements where traditional bounding box methods falter. To address these limitations, we propose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoor mobile robots.\n  In a BEV method, a 3D scene is projected into a 2D BEV grid which handles naturally occlusions and provides a consistent top-down view aiding to distinguish static obstacles from dynamic agents. The obtained 2D BEV results is directly usable to downstream robotic tasks like navigation, motion prediction, and planning. Our architecture utilizes an axis compact encoder and a window-based backbone to extract rich spatial features from this BEV map. A query-based decoder head then employs learned object queries to concurrently predict object classes and instance masks in the BEV space. This mask-centric formulation effectively captures the footprint of both static and dynamic objects regardless of their shape, offering a robust alternative to bounding box regression. We demonstrate the effectiveness of IndoorBEV on a custom indoor dataset featuring diverse object classes including static objects\n  and dynamic elements like robots and miscellaneous items, showcasing its potential for robust indoor scene understanding.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17445v1",
    "published_date": "2025-07-23 12:07:21 UTC",
    "updated_date": "2025-07-23 12:07:21 UTC"
  },
  {
    "arxiv_id": "2507.17442v3",
    "title": "Confident RAG: Enhancing the Performance of LLMs for Mathematics Question Answering through Multi-Embedding and Confidence Scoring",
    "authors": [
      "Shiting Chen",
      "Zijian Zhao",
      "Jinsong Chen"
    ],
    "abstract": "Large Language Models (LLMs) hold significant promise for mathematics education, yet they often struggle with complex mathematical reasoning. While Retrieval-Augmented Generation (RAG) mitigates these issues by grounding LLMs in external knowledge, its effectiveness remains unstable, heavily dependent on the choice of a single embedding model. Moving beyond static RAG workflows, we draw on agentic workflow patterns, a paradigm that introduces structured task decomposition and collaboration to enhance system performance. We propose and examine two novel approaches that combine the benefits of multiple embedding models. While our Mixture-Embedding RAG approach (fusing retrieved documents) shows limited gains, our Confident RAG method (generating multiple answers and selecting the one with the highest confidence score) demonstrates significant improvement. Experimental results show that Confident RAG achieved average accuracy improvements of approximately 10% over vanilla LLMs and 5% over vanilla RAG. The consistent results across different LLMs and embedding models indicate that Confident RAG is an efficient plug-and-play solution for trustworthy mathematical AI assistants. Finally, we discuss how this work lays the groundwork for deploying Agentic RAG systems in educational settings, where autonomous planning and iterative refinement can be built upon our robust retrieval foundation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17442v3",
    "published_date": "2025-07-23 12:03:54 UTC",
    "updated_date": "2025-11-30 16:05:05 UTC"
  },
  {
    "arxiv_id": "2507.17433v1",
    "title": "Fair Compromises in Participatory Budgeting: a Multi-Agent Deep Reinforcement Learning Approach",
    "authors": [
      "Hugh Adams",
      "Srijoni Majumdar",
      "Evangelos Pournaras"
    ],
    "abstract": "Participatory budgeting is a method of collectively understanding and addressing spending priorities where citizens vote on how a budget is spent, it is regularly run to improve the fairness of the distribution of public funds. Participatory budgeting requires voters to make decisions on projects which can lead to ``choice overload\". A multi-agent reinforcement learning approach to decision support can make decision making easier for voters by identifying voting strategies that increase the winning proportion of their vote. This novel approach can also support policymakers by highlighting aspects of election design that enable fair compromise on projects. This paper presents a novel, ethically aligned approach to decision support using multi-agent deep reinforcement learning modelling. This paper introduces a novel use of a branching neural network architecture to overcome scalability challenges of multi-agent reinforcement learning in a decentralized way. Fair compromises are found through optimising voter actions towards greater representation of voter preferences in the winning set. Experimental evaluation with real-world participatory budgeting data reveals a pattern in fair compromise: that it is achievable through projects with smaller cost.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17433v1",
    "published_date": "2025-07-23 11:46:13 UTC",
    "updated_date": "2025-07-23 11:46:13 UTC"
  },
  {
    "arxiv_id": "2507.17418v1",
    "title": "Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning",
    "authors": [
      "Joobin Jin",
      "Seokjun Hong",
      "Gyeongseon Baek",
      "Yeeun Kim",
      "Byeongjoon Noh"
    ],
    "abstract": "Precise modeling of microscopic vehicle trajectories is critical for traffic behavior analysis and autonomous driving systems. We propose Ctx2TrajGen, a context-aware trajectory generation framework that synthesizes realistic urban driving behaviors using GAIL. Leveraging PPO and WGAN-GP, our model addresses nonlinear interdependencies and training instability inherent in microscopic settings. By explicitly conditioning on surrounding vehicles and road geometry, Ctx2TrajGen generates interaction-aware trajectories aligned with real-world context. Experiments on the drone-captured DRIFT dataset demonstrate superior performance over existing methods in terms of realism, behavioral diversity, and contextual fidelity, offering a robust solution to data scarcity and domain shift without simulation.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17418v1",
    "published_date": "2025-07-23 11:21:27 UTC",
    "updated_date": "2025-07-23 11:21:27 UTC"
  },
  {
    "arxiv_id": "2507.17412v2",
    "title": "Content-based 3D Image Retrieval and a ColBERT-inspired Re-ranking for Tumor Flagging and Staging",
    "authors": [
      "Farnaz Khun Jush",
      "Steffen Vogler",
      "Matthias Lenga"
    ],
    "abstract": "The increasing volume of medical images poses challenges for radiologists in retrieving relevant cases. Content-based image retrieval (CBIR) systems offer potential for efficient access to similar cases, yet lack standardized evaluation and comprehensive studies. Building on prior studies for tumor characterization via CBIR, this study advances CBIR research for volumetric medical images through three key contributions: (1) a framework eliminating reliance on pre-segmented data and organ-specific datasets, aligning with large and unstructured image archiving systems, i.e. PACS in clinical practice; (2) introduction of C-MIR, a novel volumetric re-ranking method adapting ColBERT's contextualized late interaction mechanism for 3D medical imaging; (3) comprehensive evaluation across four tumor sites using three feature extractors and three database configurations. Our evaluations highlight the significant advantages of C-MIR. We demonstrate the successful adaptation of the late interaction principle to volumetric medical images, enabling effective context-aware re-ranking. A key finding is C-MIR's ability to effectively localize the region of interest, eliminating the need for pre-segmentation of datasets and offering a computationally efficient alternative to systems relying on expensive data enrichment steps. C-MIR demonstrates promising improvements in tumor flagging, achieving improved performance, particularly for colon and lung tumors (p<0.05). C-MIR also shows potential for improving tumor staging, warranting further exploration of its capabilities. Ultimately, our work seeks to bridge the gap between advanced retrieval techniques and their practical applications in healthcare, paving the way for improved diagnostic processes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17412v2",
    "published_date": "2025-07-23 11:12:52 UTC",
    "updated_date": "2025-08-25 14:03:41 UTC"
  },
  {
    "arxiv_id": "2507.17399v1",
    "title": "Millions of $\\text{GeAR}$-s: Extending GraphRAG to Millions of Documents",
    "authors": [
      "Zhili Shen",
      "Chenxin Diao",
      "Pascual Merita",
      "Pavlos Vougiouklis",
      "Jeff Z. Pan"
    ],
    "abstract": "Recent studies have explored graph-based approaches to retrieval-augmented generation, leveraging structured or semi-structured information -- such as entities and their relations extracted from documents -- to enhance retrieval. However, these methods are typically designed to address specific tasks, such as multi-hop question answering and query-focused summarisation, and therefore, there is limited evidence of their general applicability across broader datasets. In this paper, we aim to adapt a state-of-the-art graph-based RAG solution: $\\text{GeAR}$ and explore its performance and limitations on the SIGIR 2025 LiveRAG Challenge.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by SIGIR 2025 LiveRAG Challenge Program",
    "pdf_url": "https://arxiv.org/pdf/2507.17399v1",
    "published_date": "2025-07-23 10:54:24 UTC",
    "updated_date": "2025-07-23 10:54:24 UTC"
  },
  {
    "arxiv_id": "2507.17394v1",
    "title": "HiProbe-VAD: Video Anomaly Detection via Hidden States Probing in Tuning-Free Multimodal LLMs",
    "authors": [
      "Zhaolin Cai",
      "Fan Li",
      "Ziwei Zheng",
      "Yanjun Qin"
    ],
    "abstract": "Video Anomaly Detection (VAD) aims to identify and locate deviations from normal patterns in video sequences. Traditional methods often struggle with substantial computational demands and a reliance on extensive labeled datasets, thereby restricting their practical applicability. To address these constraints, we propose HiProbe-VAD, a novel framework that leverages pre-trained Multimodal Large Language Models (MLLMs) for VAD without requiring fine-tuning. In this paper, we discover that the intermediate hidden states of MLLMs contain information-rich representations, exhibiting higher sensitivity and linear separability for anomalies compared to the output layer. To capitalize on this, we propose a Dynamic Layer Saliency Probing (DLSP) mechanism that intelligently identifies and extracts the most informative hidden states from the optimal intermediate layer during the MLLMs reasoning. Then a lightweight anomaly scorer and temporal localization module efficiently detects anomalies using these extracted hidden states and finally generate explanations. Experiments on the UCF-Crime and XD-Violence datasets demonstrate that HiProbe-VAD outperforms existing training-free and most traditional approaches. Furthermore, our framework exhibits remarkable cross-model generalization capabilities in different MLLMs without any tuning, unlocking the potential of pre-trained MLLMs for video anomaly detection and paving the way for more practical and scalable solutions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM MM 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.17394v1",
    "published_date": "2025-07-23 10:41:46 UTC",
    "updated_date": "2025-07-23 10:41:46 UTC"
  },
  {
    "arxiv_id": "2507.17389v1",
    "title": "Investigating Training Data Detection in AI Coders",
    "authors": [
      "Tianlin Li",
      "Yunxiang Wei",
      "Zhiming Li",
      "Aishan Liu",
      "Qing Guo",
      "Xianglong Liu",
      "Dongning Sun",
      "Yang Liu"
    ],
    "abstract": "Recent advances in code large language models (CodeLLMs) have made them indispensable tools in modern software engineering. However, these models occasionally produce outputs that contain proprietary or sensitive code snippets, raising concerns about potential non-compliant use of training data, and posing risks to privacy and intellectual property. To ensure responsible and compliant deployment of CodeLLMs, training data detection (TDD) has become a critical task. While recent TDD methods have shown promise in natural language settings, their effectiveness on code data remains largely underexplored. This gap is particularly important given code's structured syntax and distinct similarity criteria compared to natural language. To address this, we conduct a comprehensive empirical study of seven state-of-the-art TDD methods on source code data, evaluating their performance across eight CodeLLMs. To support this evaluation, we introduce CodeSnitch, a function-level benchmark dataset comprising 9,000 code samples in three programming languages, each explicitly labeled as either included or excluded from CodeLLM training. Beyond evaluation on the original CodeSnitch, we design targeted mutation strategies to test the robustness of TDD methods under three distinct settings. These mutation strategies are grounded in the well-established Type-1 to Type-4 code clone detection taxonomy. Our study provides a systematic assessment of current TDD techniques for code and offers insights to guide the development of more effective and robust detection methods in the future.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17389v1",
    "published_date": "2025-07-23 10:34:22 UTC",
    "updated_date": "2025-07-23 10:34:22 UTC"
  },
  {
    "arxiv_id": "2507.17791v1",
    "title": "Helix 1.0: An Open-Source Framework for Reproducible and Interpretable Machine Learning on Tabular Scientific Data",
    "authors": [
      "Eduardo Aguilar-Bejarano",
      "Daniel Lea",
      "Karthikeyan Sivakumar",
      "Jimiama M. Mase",
      "Reza Omidvar",
      "Ruizhe Li",
      "Troy Kettle",
      "James Mitchell-White",
      "Morgan R Alexander",
      "David A Winkler",
      "Grazziela Figueredo"
    ],
    "abstract": "Helix is an open-source, extensible, Python-based software framework to facilitate reproducible and interpretable machine learning workflows for tabular data. It addresses the growing need for transparent experimental data analytics provenance, ensuring that the entire analytical process -- including decisions around data transformation and methodological choices -- is documented, accessible, reproducible, and comprehensible to relevant stakeholders. The platform comprises modules for standardised data preprocessing, visualisation, machine learning model training, evaluation, interpretation, results inspection, and model prediction for unseen data. To further empower researchers without formal training in data science to derive meaningful and actionable insights, Helix features a user-friendly interface that enables the design of computational experiments, inspection of outcomes, including a novel interpretation approach to machine learning decisions using linguistic terms all within an integrated environment. Released under the MIT licence, Helix is accessible via GitHub and PyPI, supporting community-driven development and promoting adherence to the FAIR principles.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.17791v1",
    "published_date": "2025-07-23 10:33:35 UTC",
    "updated_date": "2025-07-23 10:33:35 UTC"
  },
  {
    "arxiv_id": "2507.17373v1",
    "title": "SFUOD: Source-Free Unknown Object Detection",
    "authors": [
      "Keon-Hee Park",
      "Seun-An Choe",
      "Gyeong-Moon Park"
    ],
    "abstract": "Source-free object detection adapts a detector pre-trained on a source domain to an unlabeled target domain without requiring access to labeled source data. While this setting is practical as it eliminates the need for the source dataset during domain adaptation, it operates under the restrictive assumption that only pre-defined objects from the source domain exist in the target domain. This closed-set setting prevents the detector from detecting undefined objects. To ease this assumption, we propose Source-Free Unknown Object Detection (SFUOD), a novel scenario which enables the detector to not only recognize known objects but also detect undefined objects as unknown objects. To this end, we propose CollaPAUL (Collaborative tuning and Principal Axis-based Unknown Labeling), a novel framework for SFUOD. Collaborative tuning enhances knowledge adaptation by integrating target-dependent knowledge from the auxiliary encoder with source-dependent knowledge from the pre-trained detector through a cross-domain attention mechanism. Additionally, principal axes-based unknown labeling assigns pseudo-labels to unknown objects by estimating objectness via principal axes projection and confidence scores from model predictions. The proposed CollaPAUL achieves state-of-the-art performances on SFUOD benchmarks, and extensive experiments validate its effectiveness.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been accepted by ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.17373v1",
    "published_date": "2025-07-23 10:16:25 UTC",
    "updated_date": "2025-07-23 10:16:25 UTC"
  },
  {
    "arxiv_id": "2507.17365v2",
    "title": "DynaSearcher: Dynamic Knowledge Graph Augmented Search Agent via Multi-Reward Reinforcement Learning",
    "authors": [
      "Chuzhan Hao",
      "Wenfeng Feng",
      "Yuewei Zhang",
      "Hao Wang"
    ],
    "abstract": "Multi-step agentic retrieval systems based on large language models (LLMs) have demonstrated remarkable performance in complex information search tasks. However, these systems still face significant challenges in practical applications, particularly in generating factually inconsistent intermediate queries and inefficient search trajectories, which can lead to reasoning deviations or redundant computations. To address these issues, we propose DynaSearcher, an innovative search agent enhanced by dynamic knowledge graphs and multi-reward reinforcement learning (RL). Specifically, our system leverages knowledge graphs as external structured knowledge to guide the search process by explicitly modeling entity relationships, thereby ensuring factual consistency in intermediate queries and mitigating biases from irrelevant information. Furthermore, we employ a multi-reward RL framework for fine-grained control over training objectives such as retrieval accuracy, efficiency, and response quality. This framework promotes the generation of high-quality intermediate queries and comprehensive final answers, while discouraging unnecessary exploration and minimizing information omissions or redundancy. Experimental results demonstrate that our approach achieves state-of-the-art answer accuracy on six multi-hop question answering datasets, matching frontier LLMs while using only small-scale models and limited computational resources. Furthermore, our approach demonstrates strong generalization and robustness across diverse retrieval environments and larger-scale models, highlighting its broad applicability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 3 figures, 8 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.17365v2",
    "published_date": "2025-07-23 09:58:31 UTC",
    "updated_date": "2025-10-15 06:36:54 UTC"
  },
  {
    "arxiv_id": "2507.17788v1",
    "title": "Adaptive Repetition for Mitigating Position Bias in LLM-Based Ranking",
    "authors": [
      "Ali Vardasbi",
      "Gustavo Penha",
      "Claudia Hauff",
      "Hugues Bouchard"
    ],
    "abstract": "When using LLMs to rank items based on given criteria, or evaluate answers, the order of candidate items can influence the model's final decision. This sensitivity to item positioning in a LLM's prompt is known as position bias. Prior research shows that this bias exists even in large models, though its severity varies across models and tasks. In addition to position bias, LLMs also exhibit varying degrees of low repetition consistency, where repeating the LLM call with the same candidate ordering can lead to different rankings. To address both inconsistencies, a common approach is to prompt the model multiple times with different candidate orderings and aggregate the results via majority voting. However, this repetition strategy, significantly increases computational costs. Extending prior findings, we observe that both the direction -- favoring either the earlier or later candidate in the prompt -- and magnitude of position bias across instances vary substantially, even within a single dataset. This observation highlights the need for a per-instance mitigation strategy. To this end, we introduce a dynamic early-stopping method that adaptively determines the number of repetitions required for each instance. Evaluating our approach across three LLMs of varying sizes and on two tasks, namely re-ranking and alignment, we demonstrate that transitioning to a dynamic repetition strategy reduces the number of LLM calls by an average of 81%, while preserving the accuracy. Furthermore, we propose a confidence-based adaptation to our early-stopping method, reducing LLM calls by an average of 87% compared to static repetition, with only a slight accuracy trade-off relative to our original early-stopping method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17788v1",
    "published_date": "2025-07-23 09:54:44 UTC",
    "updated_date": "2025-07-23 09:54:44 UTC"
  },
  {
    "arxiv_id": "2507.17787v1",
    "title": "Hyperbolic Deep Learning for Foundation Models: A Survey",
    "authors": [
      "Neil He",
      "Hiren Madhu",
      "Ngoc Bui",
      "Menglin Yang",
      "Rex Ying"
    ],
    "abstract": "Foundation models pre-trained on massive datasets, including large language models (LLMs), vision-language models (VLMs), and large multimodal models, have demonstrated remarkable success in diverse downstream tasks. However, recent studies have shown fundamental limitations of these models: (1) limited representational capacity, (2) lower adaptability, and (3) diminishing scalability. These shortcomings raise a critical question: is Euclidean geometry truly the optimal inductive bias for all foundation models, or could incorporating alternative geometric spaces enable models to better align with the intrinsic structure of real-world data and improve reasoning processes? Hyperbolic spaces, a class of non-Euclidean manifolds characterized by exponential volume growth with respect to distance, offer a mathematically grounded solution. These spaces enable low-distortion embeddings of hierarchical structures (e.g., trees, taxonomies) and power-law distributions with substantially fewer dimensions compared to Euclidean counterparts. Recent advances have leveraged these properties to enhance foundation models, including improving LLMs' complex reasoning ability, VLMs' zero-shot generalization, and cross-modal semantic alignment, while maintaining parameter efficiency. This paper provides a comprehensive review of hyperbolic neural networks and their recent development for foundation models. We further outline key challenges and research directions to advance the field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 Pages, SIGKDD 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.17787v1",
    "published_date": "2025-07-23 09:50:17 UTC",
    "updated_date": "2025-07-23 09:50:17 UTC"
  },
  {
    "arxiv_id": "2507.17347v3",
    "title": "Swin-TUNA : A Novel PEFT Approach for Accurate Food Image Segmentation",
    "authors": [
      "Haotian Chen",
      "Zhiyong Xiao"
    ],
    "abstract": "In the field of food image processing, efficient semantic segmentation techniques are crucial for industrial applications. However, existing large-scale Transformer-based models (such as FoodSAM) face challenges in meeting practical deploymentrequirements due to their massive parameter counts and high computational resource demands. This paper introduces TUNable Adapter module (Swin-TUNA), a Parameter Efficient Fine-Tuning (PEFT) method that integrates multiscale trainable adapters into the Swin Transformer architecture, achieving high-performance food image segmentation by updating only 4% of the parameters. The core innovation of Swin-TUNA lies in its hierarchical feature adaptation mechanism: it designs separable convolutions in depth and dimensional mappings of varying scales to address the differences in features between shallow and deep networks, combined with a dynamic balancing strategy for tasks-agnostic and task-specific features. Experiments demonstrate that this method achieves mIoU of 50.56% and 74.94% on the FoodSeg103 and UECFoodPix Complete datasets, respectively, surpassing the fully parameterized FoodSAM model while reducing the parameter count by 98.7% (to only 8.13M). Furthermore, Swin-TUNA exhibits faster convergence and stronger generalization capabilities in low-data scenarios, providing an efficient solution for assembling lightweight food image.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "After discussion among the authors, some parts of the paper are deemed inappropriate and will be revised and resubmitted",
    "pdf_url": "https://arxiv.org/pdf/2507.17347v3",
    "published_date": "2025-07-23 09:28:25 UTC",
    "updated_date": "2025-07-28 08:44:20 UTC"
  },
  {
    "arxiv_id": "2507.17334v1",
    "title": "Temporal Point-Supervised Signal Reconstruction: A Human-Annotation-Free Framework for Weak Moving Target Detection",
    "authors": [
      "Weihua Gao",
      "Chunxu Ren",
      "Wenlong Niu",
      "Xiaodong Peng"
    ],
    "abstract": "In low-altitude surveillance and early warning systems, detecting weak moving targets remains a significant challenge due to low signal energy, small spatial extent, and complex background clutter. Existing methods struggle with extracting robust features and suffer from the lack of reliable annotations. To address these limitations, we propose a novel Temporal Point-Supervised (TPS) framework that enables high-performance detection of weak targets without any manual annotations.Instead of conventional frame-based detection, our framework reformulates the task as a pixel-wise temporal signal modeling problem, where weak targets manifest as short-duration pulse-like responses. A Temporal Signal Reconstruction Network (TSRNet) is developed under the TPS paradigm to reconstruct these transient signals.TSRNet adopts an encoder-decoder architecture and integrates a Dynamic Multi-Scale Attention (DMSAttention) module to enhance its sensitivity to diverse temporal patterns. Additionally, a graph-based trajectory mining strategy is employed to suppress false alarms and ensure temporal consistency.Extensive experiments on a purpose-built low-SNR dataset demonstrate that our framework outperforms state-of-the-art methods while requiring no human annotations. It achieves strong detection performance and operates at over 1000 FPS, underscoring its potential for real-time deployment in practical scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17334v1",
    "published_date": "2025-07-23 09:02:09 UTC",
    "updated_date": "2025-07-23 09:02:09 UTC"
  },
  {
    "arxiv_id": "2507.17311v3",
    "title": "A Self-Evolving AI Agent System for Climate Science",
    "authors": [
      "Zijie Guo",
      "Jiong Wang",
      "Fenghua Ling",
      "Wangxu Wei",
      "Xiaoyu Yue",
      "Zhe Jiang",
      "Wanghan Xu",
      "Jing-Jia Luo",
      "Lijing Cheng",
      "Yoo-Geun Ham",
      "Fengfei Song",
      "Pierre Gentine",
      "Toshio Yamagata",
      "Ben Fei",
      "Wenlong Zhang",
      "Xinyu Gu",
      "Chao Li",
      "Yaqiang Wang",
      "Tao Chen",
      "Wanli Ouyang",
      "Bowen Zhou",
      "Lei Bai"
    ],
    "abstract": "Scientific progress in Earth science depends on integrating data across the planet's interconnected spheres. However, the accelerating volume and fragmentation of multi-sphere knowledge and data have surpassed human analytical capacity. This creates a major bottleneck for discovery, especially in climate science. To address this challenge, we introduce EarthLink, the first self-evolving AI agent system designed as an interactive \"copilot\" for Earth scientists. Through natural language interaction, EarthLink automates the entire research workflow by integrating planning, code execution, data analysis, and physical reasoning into a unified process that directly addresses this limitation. Beyond efficiency, it exhibits human-like cross-disciplinary analytical ability and achieves proficiency comparable to a junior researcher in expert evaluations on core large-scale climate tasks, including model-observation comparison and climate change understanding. When tasked with an open scientific problem, specifically the discovery of precursors of the Atlantic Niño, EarthLink autonomously developed a research strategy, identified sources of predictability, verified its hypotheses with available data, and proposed a physically consistent mechanism. These emerging capabilities enable a new human-AI research paradigm. Scientists can focus on value and result judgments, while AI systems handle complex data analysis and knowledge integration. This accelerates the pace and breadth of discovery in Earth sciences. The system is accessible at our website https://earthlink.intern-ai.org.cn.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17311v3",
    "published_date": "2025-07-23 08:29:25 UTC",
    "updated_date": "2025-11-03 09:17:56 UTC"
  },
  {
    "arxiv_id": "2507.17309v1",
    "title": "Confounded Causal Imitation Learning with Instrumental Variables",
    "authors": [
      "Yan Zeng",
      "Shenglan Nie",
      "Feng Xie",
      "Libo Huang",
      "Peng Wu",
      "Zhi Geng"
    ],
    "abstract": "Imitation learning from demonstrations usually suffers from the confounding effects of unmeasured variables (i.e., unmeasured confounders) on the states and actions. If ignoring them, a biased estimation of the policy would be entailed. To break up this confounding gap, in this paper, we take the best of the strong power of instrumental variables (IV) and propose a Confounded Causal Imitation Learning (C2L) model. This model accommodates confounders that influence actions across multiple timesteps, rather than being restricted to immediate temporal dependencies. We develop a two-stage imitation learning framework for valid IV identification and policy optimization. In particular, in the first stage, we construct a testing criterion based on the defined pseudo-variable, with which we achieve identifying a valid IV for the C2L models. Such a criterion entails the sufficient and necessary identifiability conditions for IV validity. In the second stage, with the identified IV, we propose two candidate policy learning approaches: one is based on a simulator, while the other is offline. Extensive experiments verified the effectiveness of identifying the valid IV as well as learning the policy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.17309v1",
    "published_date": "2025-07-23 08:23:34 UTC",
    "updated_date": "2025-07-23 08:23:34 UTC"
  },
  {
    "arxiv_id": "2507.17307v4",
    "title": "R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning",
    "authors": [
      "Zhuokun Chen",
      "Zeren Chen",
      "Jiahao He",
      "Lu Sheng",
      "Mingkui Tan",
      "Jianfei Cai",
      "Bohan Zhuang"
    ],
    "abstract": "Chain-of-thought (CoT) enhances the problem-solving ability of large language models (LLMs) but incurs substantial inference cost due to long autoregressive trajectories. Existing acceleration strategies either shorten traces via early stopping or compression, or adopt speculative decoding with a smaller model. However, speculative decoding provides limited gains when model agreement is low and rigidly enforces token-level consistency, overlooking the observation that some smaller models, when correct, produce significantly more concise reasoning traces that could reduce inference length. We introduce R-Stitch, a training-free hybrid decoding framework that leverages token-level entropy as an uncertainty proxy to delegate computation between a small language model (SLM) and an LLM. Our analysis shows that high-entropy tokens are more likely to induce errors, motivating an entropy-guided routing strategy that lets the SLM efficiently handle low-entropy tokens while delegating uncertain ones to the LLM, thereby avoiding full rollbacks and preserving answer quality. We further extend this design with R-Stitch$^{+}$, which learns an adaptive routing policy to adjust the token budget dynamically beyond fixed thresholds. By jointly reducing per-token decoding complexity and the number of generated tokens, our method achieves substantial acceleration with negligible accuracy loss. Concretely, it attains peak speedups of 3.00$\\times$ on DeepSeek-R1-Distill-Qwen-7B, 3.85$\\times$ on 14B, and 4.10$\\times$ on QWQ-32B while maintaining accuracy comparable to full LLM decoding. Moreover, it naturally enables adaptive efficiency--accuracy trade-offs that can be tailored to diverse computational budgets without retraining.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17307v4",
    "published_date": "2025-07-23 08:14:36 UTC",
    "updated_date": "2025-09-26 10:55:36 UTC"
  },
  {
    "arxiv_id": "2507.17303v2",
    "title": "A Versatile Pathology Co-pilot via Reasoning Enhanced Multimodal Large Language Model",
    "authors": [
      "Zhe Xu",
      "Ziyi Liu",
      "Junlin Hou",
      "Jiabo Ma",
      "Cheng Jin",
      "Yihui Wang",
      "Zhixuan Chen",
      "Zhengyu Zhang",
      "Fuxiang Huang",
      "Zhengrui Guo",
      "Fengtao Zhou",
      "Yingxue Xu",
      "Xi Wang",
      "Ronald Cheong Kin Chan",
      "Li Liang",
      "Hao Chen"
    ],
    "abstract": "Multimodal large language models (MLLMs) have emerged as powerful tools for computational pathology, offering unprecedented opportunities to integrate pathological images with language context for comprehensive diagnostic analysis. These models hold particular promise for automating complex tasks that traditionally require expert interpretation of pathologists. However, current MLLM approaches in pathology demonstrate significantly constrained reasoning capabilities, primarily due to their reliance on expensive chain-of-thought annotations. Additionally, existing methods remain limited to simplex application of visual question answering (VQA) at the region-of-interest (ROI) level, failing to address the full spectrum of diagnostic needs such as ROI classification, detection, segmentation, whole-slide-image (WSI) classification and VQA in clinical practice. In this study, we present SmartPath-R1, a versatile MLLM capable of simultaneously addressing both ROI-level and WSI-level tasks while demonstrating robust pathological reasoning capability. Our framework combines scale-dependent supervised fine-tuning and task-aware reinforcement fine-tuning, which circumvents the requirement for chain-of-thought supervision by leveraging the intrinsic knowledge within MLLM. Furthermore, SmartPath-R1 integrates multiscale and multitask analysis through a mixture-of-experts mechanism, enabling dynamic processing for diverse tasks. We curate a large-scale dataset comprising 2.3M ROI samples and 188K WSI samples for training and evaluation. Extensive experiments across 72 tasks validate the effectiveness and superiority of the proposed approach. This work represents a significant step toward developing versatile, reasoning-enhanced AI systems for precision pathology.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17303v2",
    "published_date": "2025-07-23 08:09:42 UTC",
    "updated_date": "2025-08-19 08:51:01 UTC"
  },
  {
    "arxiv_id": "2507.21142v1",
    "title": "Privacy Artifact ConnecTor (PACT): Embedding Enterprise Artifacts for Compliance AI Agents",
    "authors": [
      "Chenhao Fang",
      "Yanqing Peng",
      "Rajeev Rao",
      "Matt Sarmiento",
      "Wendy Summer",
      "Arya Pudota",
      "Alex Goncalves",
      "Jordi Mola",
      "Hervé Robert"
    ],
    "abstract": "Enterprise environments contain a heterogeneous, rapidly growing collection of internal artifacts related to code, data, and many different tools. Critical information for assessing privacy risk and ensuring regulatory compliance is often embedded across these varied resources, each with their own arcane discovery and extraction techniques. Therefore, large-scale privacy compliance in adherence to governmental regulations requires systems to discern the interconnected nature of diverse artifacts in a common, shared universe.\n  We present Privacy Artifact ConnecT or (PACT), an embeddings-driven graph that links millions of artifacts spanning multiple artifact types generated by a variety of teams and projects. Powered by the state-of-the-art DRAGON embedding model, PACT uses a contrastive learning objective with light fine-tuning to link artifacts via their textual components such as raw metadata, ownership specifics, and compliance context. Experimental results show that PACT's fine-tuned model improves recall@1 from 18% to 53%, the query match rate from 9.6% to 69.7% when paired with a baseline AI agent, and the hitrate@1 from 25.7% to 44.9% for candidate selection in a standard recommender system.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21142v1",
    "published_date": "2025-07-23 08:00:20 UTC",
    "updated_date": "2025-07-23 08:00:20 UTC"
  },
  {
    "arxiv_id": "2507.17297v1",
    "title": "On Temporal Guidance and Iterative Refinement in Audio Source Separation",
    "authors": [
      "Tobias Morocutti",
      "Jonathan Greif",
      "Paul Primus",
      "Florian Schmid",
      "Gerhard Widmer"
    ],
    "abstract": "Spatial semantic segmentation of sound scenes (S5) involves the accurate identification of active sound classes and the precise separation of their sources from complex acoustic mixtures. Conventional systems rely on a two-stage pipeline - audio tagging followed by label-conditioned source separation - but are often constrained by the absence of fine-grained temporal information critical for effective separation. In this work, we address this limitation by introducing a novel approach for S5 that enhances the synergy between the event detection and source separation stages. Our key contributions are threefold. First, we fine-tune a pre-trained Transformer to detect active sound classes. Second, we utilize a separate instance of this fine-tuned Transformer to perform sound event detection (SED), providing the separation module with detailed, time-varying guidance. Third, we implement an iterative refinement mechanism that progressively enhances separation quality by recursively reusing the separator's output from previous iterations. These advancements lead to significant improvements in both audio tagging and source separation performance, as demonstrated by our system's second-place finish in Task 4 of the DCASE Challenge 2025. Our implementation and model checkpoints are available in our GitHub repository: https://github.com/theMoro/dcase25task4 .",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17297v1",
    "published_date": "2025-07-23 07:58:28 UTC",
    "updated_date": "2025-07-23 07:58:28 UTC"
  },
  {
    "arxiv_id": "2507.21141v1",
    "title": "The Geometry of Harmfulness in LLMs through Subconcept Probing",
    "authors": [
      "McNair Shah",
      "Saleena Angeline",
      "Adhitya Rajendra Kumar",
      "Naitik Chheda",
      "Kevin Zhu",
      "Vasu Sharma",
      "Sean O'Brien",
      "Will Cai"
    ],
    "abstract": "Recent advances in large language models (LLMs) have intensified the need to understand and reliably curb their harmful behaviours. We introduce a multidimensional framework for probing and steering harmful content in model internals. For each of 55 distinct harmfulness subconcepts (e.g., racial hate, employment scams, weapons), we learn a linear probe, yielding 55 interpretable directions in activation space. Collectively, these directions span a harmfulness subspace that we show is strikingly low-rank. We then test ablation of the entire subspace from model internals, as well as steering and ablation in the subspace's dominant direction. We find that dominant direction steering allows for near elimination of harmfulness with a low decrease in utility. Our findings advance the emerging view that concept subspaces provide a scalable lens on LLM behaviour and offer practical tools for the community to audit and harden future generations of language models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.21141v1",
    "published_date": "2025-07-23 07:56:05 UTC",
    "updated_date": "2025-07-23 07:56:05 UTC"
  },
  {
    "arxiv_id": "2507.17291v2",
    "title": "Integrating Belief Domains into Probabilistic Logic Programs",
    "authors": [
      "Damiano Azzolini",
      "Fabrizio Riguzzi",
      "Theresa Swift"
    ],
    "abstract": "Probabilistic Logic Programming (PLP) under the Distribution Semantics is a leading approach to practical reasoning under uncertainty. An advantage of the Distribution Semantics is its suitability for implementation as a Prolog or Python library, available through two well-maintained implementations, namely ProbLog and cplint/PITA. However, current formulations of the Distribution Semantics use point-probabilities, making it difficult to express epistemic uncertainty, such as arises from, for example, hierarchical classifications from computer vision models. Belief functions generalize probability measures as non-additive capacities, and address epistemic uncertainty via interval probabilities. This paper introduces interval-based Capacity Logic Programs based on an extension of the Distribution Semantics to include belief functions, and describes properties of the new framework that make it amenable to practical applications.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "Under consideration in Theory and Practice of Logic Programming (TPLP)",
    "pdf_url": "https://arxiv.org/pdf/2507.17291v2",
    "published_date": "2025-07-23 07:52:09 UTC",
    "updated_date": "2025-09-23 16:15:07 UTC"
  },
  {
    "arxiv_id": "2507.17289v3",
    "title": "Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments",
    "authors": [
      "Shitong Zhu",
      "Chenhao Fang",
      "Derek Larson",
      "Neel Reddy Pochareddy",
      "Rajeev Rao",
      "Sophie Zeng",
      "Yanqing Peng",
      "Wendy Summer",
      "Alex Goncalves",
      "Arya Pudota",
      "Hervé Robert"
    ],
    "abstract": "This paper presents Compliance Brain Assistant (CBA), a conversational, agentic AI assistant designed to boost the efficiency of daily compliance tasks for personnel in enterprise environments. To strike a good balance between response quality and latency, we design a user query router that can intelligently choose between (i) FastTrack mode: to handle simple requests that only need additional relevant context retrieved from knowledge corpora; and (ii) FullAgentic mode: to handle complicated requests that need composite actions and tool invocations to proactively discover context across various compliance artifacts, and/or involving other APIs/models for accommodating requests. A typical example would be to start with a user query, use its description to find a specific entity and then use the entity's information to query other APIs for curating and enriching the final AI response.\n  Our experimental evaluations compared CBA against an out-of-the-box LLM on various real-world privacy/compliance-related queries targeting various personas. We found that CBA substantially improved upon the vanilla LLM's performance on metrics such as average keyword match rate (83.7% vs. 41.7%) and LLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full routing-based design against the `fast-track only` and `full-agentic` modes and found that it had a better average match-rate and pass-rate while keeping the run-time approximately the same. This finding validated our hypothesis that the routing mechanism leads to a good trade-off between the two worlds.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17289v3",
    "published_date": "2025-07-23 07:51:10 UTC",
    "updated_date": "2025-07-26 21:24:32 UTC"
  },
  {
    "arxiv_id": "2508.00880v1",
    "title": "Reproducibility of Machine Learning-Based Fault Detection and Diagnosis for HVAC Systems in Buildings: An Empirical Study",
    "authors": [
      "Adil Mukhtar",
      "Michael Hadwiger",
      "Franz Wotawa",
      "Gerald Schweiger"
    ],
    "abstract": "Reproducibility is a cornerstone of scientific research, enabling independent verification and validation of empirical findings. The topic gained prominence in fields such as psychology and medicine, where concerns about non - replicable results sparked ongoing discussions about research practices. In recent years, the fast-growing field of Machine Learning (ML) has become part of this discourse, as it faces similar concerns about transparency and reliability. Some reproducibility issues in ML research are shared with other fields, such as limited access to data and missing methodological details. In addition, ML introduces specific challenges, including inherent nondeterminism and computational constraints. While reproducibility issues are increasingly recognized by the ML community and its major conferences, less is known about how these challenges manifest in applied disciplines. This paper contributes to closing this gap by analyzing the transparency and reproducibility standards of ML applications in building energy systems. The results indicate that nearly all articles are not reproducible due to insufficient disclosure across key dimensions of reproducibility. 72% of the articles do not specify whether the dataset used is public, proprietary, or commercially available. Only two papers share a link to their code - one of which was broken. Two-thirds of the publications were authored exclusively by academic researchers, yet no significant differences in reproducibility were observed compared to publications with industry-affiliated authors. These findings highlight the need for targeted interventions, including reproducibility guidelines, training for researchers, and policies by journals and conferences that promote transparency and reproducibility.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.00880v1",
    "published_date": "2025-07-23 07:35:58 UTC",
    "updated_date": "2025-07-23 07:35:58 UTC"
  },
  {
    "arxiv_id": "2507.17273v1",
    "title": "Leveraging Knowledge Graphs and LLM Reasoning to Identify Operational Bottlenecks for Warehouse Planning Assistance",
    "authors": [
      "Rishi Parekh",
      "Saisubramaniam Gopalakrishnan",
      "Zishan Ahmad",
      "Anirudh Deodhar"
    ],
    "abstract": "Analyzing large, complex output datasets from Discrete Event Simulations (DES) of warehouse operations to identify bottlenecks and inefficiencies is a critical yet challenging task, often demanding significant manual effort or specialized analytical tools. Our framework integrates Knowledge Graphs (KGs) and Large Language Model (LLM)-based agents to analyze complex Discrete Event Simulation (DES) output data from warehouse operations. It transforms raw DES data into a semantically rich KG, capturing relationships between simulation events and entities. An LLM-based agent uses iterative reasoning, generating interdependent sub-questions. For each sub-question, it creates Cypher queries for KG interaction, extracts information, and self-reflects to correct errors. This adaptive, iterative, and self-correcting process identifies operational issues mimicking human analysis. Our DES approach for warehouse bottleneck identification, tested with equipment breakdowns and process irregularities, outperforms baseline methods. For operational questions, it achieves near-perfect pass rates in pinpointing inefficiencies. For complex investigative questions, we demonstrate its superior diagnostic ability to uncover subtle, interconnected issues. This work bridges simulation modeling and AI (KG+LLM), offering a more intuitive method for actionable insights, reducing time-to-insight, and enabling automated warehouse inefficiency evaluation and diagnosis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.17273v1",
    "published_date": "2025-07-23 07:18:55 UTC",
    "updated_date": "2025-07-23 07:18:55 UTC"
  },
  {
    "arxiv_id": "2507.17264v1",
    "title": "Understanding Prompt Programming Tasks and Questions",
    "authors": [
      "Jenny T. Liang",
      "Chenyang Yang",
      "Agnia Sergeyuk",
      "Travis D. Breaux",
      "Brad A. Myers"
    ],
    "abstract": "Prompting foundation models (FMs) like large language models (LLMs) have enabled new AI-powered software features (e.g., text summarization) that previously were only possible by fine-tuning FMs. Now, developers are embedding prompts in software, known as prompt programs. The process of prompt programming requires the developer to make many changes to their prompt. Yet, the questions developers ask to update their prompt is unknown, despite the answers to these questions affecting how developers plan their changes. With the growing number of research and commercial prompt programming tools, it is unclear whether prompt programmers' needs are being adequately addressed. We address these challenges by developing a taxonomy of 25 tasks prompt programmers do and 51 questions they ask, measuring the importance of each task and question. We interview 16 prompt programmers, observe 8 developers make prompt changes, and survey 50 developers. We then compare the taxonomy with 48 research and commercial tools. We find that prompt programming is not well-supported: all tasks are done manually, and 16 of the 51 questions -- including a majority of the most important ones -- remain unanswered. Based on this, we outline important opportunities for prompt programming tools.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17264v1",
    "published_date": "2025-07-23 07:01:44 UTC",
    "updated_date": "2025-07-23 07:01:44 UTC"
  },
  {
    "arxiv_id": "2507.17258v1",
    "title": "Students' Feedback Requests and Interactions with the SCRIPT Chatbot: Do They Get What They Ask For?",
    "authors": [
      "Andreas Scholl",
      "Natalie Kiesler"
    ],
    "abstract": "Building on prior research on Generative AI (GenAI) and related tools for programming education, we developed SCRIPT, a chatbot based on ChatGPT-4o-mini, to support novice learners. SCRIPT allows for open-ended interactions and structured guidance through predefined prompts. We evaluated the tool via an experiment with 136 students from an introductory programming course at a large German university and analyzed how students interacted with SCRIPT while solving programming tasks with a focus on their feedback preferences. The results reveal that students' feedback requests seem to follow a specific sequence. Moreover, the chatbot responses aligned well with students' requested feedback types (in 75%), and it adhered to the system prompt constraints. These insights inform the design of GenAI-based learning support systems and highlight challenges in balancing guidance and flexibility in AI-assisted tools.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at PPIG 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.17258v1",
    "published_date": "2025-07-23 06:56:26 UTC",
    "updated_date": "2025-07-23 06:56:26 UTC"
  },
  {
    "arxiv_id": "2507.17257v1",
    "title": "Agent Identity Evals: Measuring Agentic Identity",
    "authors": [
      "Elija Perrier",
      "Michael Timothy Bennett"
    ],
    "abstract": "Central to agentic capability and trustworthiness of language model agents (LMAs) is the extent they maintain stable, reliable, identity over time. However, LMAs inherit pathologies from large language models (LLMs) (statelessness, stochasticity, sensitivity to prompts and linguistically-intermediation) which can undermine their identifiability, continuity, persistence and consistency. This attrition of identity can erode their reliability, trustworthiness and utility by interfering with their agentic capabilities such as reasoning, planning and action. To address these challenges, we introduce \\textit{agent identity evals} (AIE), a rigorous, statistically-driven, empirical framework for measuring the degree to which an LMA system exhibit and maintain their agentic identity over time, including their capabilities, properties and ability to recover from state perturbations. AIE comprises a set of novel metrics which can integrate with other measures of performance, capability and agentic robustness to assist in the design of optimal LMA infrastructure and scaffolding such as memory and tools. We set out formal definitions and methods that can be applied at each stage of the LMA life-cycle, and worked examples of how to apply them.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17257v1",
    "published_date": "2025-07-23 06:56:15 UTC",
    "updated_date": "2025-07-23 06:56:15 UTC"
  },
  {
    "arxiv_id": "2507.17248v2",
    "title": "Reality Proxy: Fluid Interactions with Real-World Objects in MR via Abstract Representations",
    "authors": [
      "Xiaoan Liu",
      "Difan Jia",
      "Xianhao Carton Liu",
      "Mar Gonzalez-Franco",
      "Chen Zhu-Tian"
    ],
    "abstract": "Interacting with real-world objects in Mixed Reality (MR) often proves difficult when they are crowded, distant, or partially occluded, hindering straightforward selection and manipulation. We observe that these difficulties stem from performing interaction directly on physical objects, where input is tightly coupled to their physical constraints. Our key insight is to decouple interaction from these constraints by introducing proxies-abstract representations of real-world objects. We embody this concept in Reality Proxy, a system that seamlessly shifts interaction targets from physical objects to their proxies during selection. Beyond facilitating basic selection, Reality Proxy uses AI to enrich proxies with semantic attributes and hierarchical spatial relationships of their corresponding physical objects, enabling novel and previously cumbersome interactions in MR - such as skimming, attribute-based filtering, navigating nested groups, and complex multi object selections - all without requiring new gestures or menu systems. We demonstrate Reality Proxy's versatility across diverse scenarios, including office information retrieval, large-scale spatial navigation, and multi-drone control. An expert evaluation suggests the system's utility and usability, suggesting that proxy-based abstractions offer a powerful and generalizable interaction paradigm for future MR systems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.HC",
    "comment": "16 pages, 9 figures. Accepted for publication in UIST'25 (The 38th Annual ACM Symposium on User Interface Software and Technology), Busan, Republic of Korea, 28 Sep - 1 Oct 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.17248v2",
    "published_date": "2025-07-23 06:34:58 UTC",
    "updated_date": "2025-07-24 07:13:36 UTC"
  },
  {
    "arxiv_id": "2507.17245v1",
    "title": "DistrAttention: An Efficient and Flexible Self-Attention Mechanism on Modern GPUs",
    "authors": [
      "Haolin Jin",
      "Mengbai Xiao",
      "Yuan Yuan",
      "Xiao Zhang",
      "Dongxiao Yu",
      "Guanghui Zhang",
      "Haoliang Wang"
    ],
    "abstract": "The Transformer architecture has revolutionized deep learning, delivering the state-of-the-art performance in areas such as natural language processing, computer vision, and time series prediction. However, its core component, self-attention, has the quadratic time complexity relative to input sequence length, which hinders the scalability of Transformers. The exsiting approaches on optimizing self-attention either discard full-contextual information or lack of flexibility. In this work, we design DistrAttention, an effcient and flexible self-attention mechanism with the full context. DistrAttention achieves this by grouping data on the embedding dimensionality, usually referred to as $d$. We realize DistrAttention with a lightweight sampling and fusion method that exploits locality-sensitive hashing to group similar data. A block-wise grouping framework is further designed to limit the errors introduced by locality sensitive hashing. By optimizing the selection of block sizes, DistrAttention could be easily integrated with FlashAttention-2, gaining high-performance on modern GPUs. We evaluate DistrAttention with extensive experiments. The results show that our method is 37% faster than FlashAttention-2 on calculating self-attention. In ViT inference, DistrAttention is the fastest and the most accurate among approximate self-attention mechanisms. In Llama3-1B, DistrAttention still achieves the lowest inference time with only 1% accuray loss.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17245v1",
    "published_date": "2025-07-23 06:29:38 UTC",
    "updated_date": "2025-07-23 06:29:38 UTC"
  },
  {
    "arxiv_id": "2507.17241v1",
    "title": "Eco-Friendly AI: Unleashing Data Power for Green Federated Learning",
    "authors": [
      "Mattia Sabella",
      "Monica Vitali"
    ],
    "abstract": "The widespread adoption of Artificial Intelligence (AI) and Machine Learning (ML) comes with a significant environmental impact, particularly in terms of energy consumption and carbon emissions. This pressing issue highlights the need for innovative solutions to mitigate AI's ecological footprint. One of the key factors influencing the energy consumption of ML model training is the size of the training dataset. ML models are often trained on vast amounts of data continuously generated by sensors and devices distributed across multiple locations. To reduce data transmission costs and enhance privacy, Federated Learning (FL) enables model training without the need to move or share raw data. While FL offers these advantages, it also introduces challenges due to the heterogeneity of data sources (related to volume and quality), computational node capabilities, and environmental impact.\n  This paper contributes to the advancement of Green AI by proposing a data-centric approach to Green Federated Learning. Specifically, we focus on reducing FL's environmental impact by minimizing the volume of training data. Our methodology involves the analysis of the characteristics of federated datasets, the selecting of an optimal subset of data based on quality metrics, and the choice of the federated nodes with the lowest environmental impact. We develop a comprehensive methodology that examines the influence of data-centric factors, such as data quality and volume, on FL training performance and carbon emissions. Building on these insights, we introduce an interactive recommendation system that optimizes FL configurations through data reduction, minimizing environmental impact during training. Applying this methodology to time series classification has demonstrated promising results in reducing the environmental impact of FL tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17241v1",
    "published_date": "2025-07-23 06:18:15 UTC",
    "updated_date": "2025-07-23 06:18:15 UTC"
  },
  {
    "arxiv_id": "2507.17232v2",
    "title": "A Highly Clean Recipe Dataset with Ingredient States Annotation for State Probing Task",
    "authors": [
      "Mashiro Toyooka",
      "Kiyoharu Aizawa",
      "Yoko Yamakata"
    ],
    "abstract": "Large Language Models (LLMs) are trained on a vast amount of procedural texts, but they do not directly observe real-world phenomena. In the context of cooking recipes, this poses a challenge, as intermediate states of ingredients are often omitted, making it difficult for models to track ingredient states and understand recipes accurately. In this paper, we apply state probing, a method for evaluating a language model's understanding of the world, to the domain of cooking. We propose a new task and dataset for evaluating how well LLMs can recognize intermediate ingredient states during cooking procedures. We first construct a new Japanese recipe dataset with clear and accurate annotations of ingredient state changes, collected from well-structured and controlled recipe texts. Using this dataset, we design three novel tasks to evaluate whether LLMs can track ingredient state transitions and identify ingredients present at intermediate steps. Our experiments with widely used LLMs, such as Llama3.1-70B and Qwen2.5-72B, show that learning ingredient state knowledge improves their understanding of cooking processes, achieving performance comparable to commercial LLMs. The dataset are publicly available at: https://huggingface.co/datasets/mashi6n/nhkrecipe-100-anno-1",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MM",
    "comment": "Accepted to ACM Multimedia 2025. The dataset are publicly available at: https://huggingface.co/datasets/mashi6n/nhkrecipe-100-anno-1",
    "pdf_url": "https://arxiv.org/pdf/2507.17232v2",
    "published_date": "2025-07-23 05:56:20 UTC",
    "updated_date": "2025-08-28 15:15:18 UTC"
  },
  {
    "arxiv_id": "2507.17228v2",
    "title": "P3SL: Personalized Privacy-Preserving Split Learning on Heterogeneous Edge Devices",
    "authors": [
      "Wei Fan",
      "JinYi Yoon",
      "Xiaochang Li",
      "Huajie Shao",
      "Bo Ji"
    ],
    "abstract": "Split Learning (SL) is an emerging privacy-preserving machine learning technique that enables resource constrained edge devices to participate in model training by partitioning a model into client-side and server-side sub-models. While SL reduces computational overhead on edge devices, it encounters significant challenges in heterogeneous environments where devices vary in computing resources, communication capabilities, environmental conditions, and privacy requirements. Although recent studies have explored heterogeneous SL frameworks that optimize split points for devices with varying resource constraints, they often neglect personalized privacy requirements and local model customization under varying environmental conditions. To address these limitations, we propose P3SL, a Personalized Privacy-Preserving Split Learning framework designed for heterogeneous, resource-constrained edge device systems. The key contributions of this work are twofold. First, we design a personalized sequential split learning pipeline that allows each client to achieve customized privacy protection and maintain personalized local models tailored to their computational resources, environmental conditions, and privacy needs. Second, we adopt a bi-level optimization technique that empowers clients to determine their own optimal personalized split points without sharing private sensitive information (i.e., computational resources, environmental conditions, privacy requirements) with the server. This approach balances energy consumption and privacy leakage risks while maintaining high model accuracy. We implement and evaluate P3SL on a testbed consisting of 7 devices including 4 Jetson Nano P3450 devices, 2 Raspberry Pis, and 1 laptop, using diverse model architectures and datasets under varying environmental conditions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as invited paper in The 34th International Conference on Computer Communications and Networks (ICCCN 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.17228v2",
    "published_date": "2025-07-23 05:50:33 UTC",
    "updated_date": "2025-08-05 02:08:01 UTC"
  },
  {
    "arxiv_id": "2507.17224v3",
    "title": "HuiduRep: A Robust Self-Supervised Framework for Learning Neural Representations from Extracellular Recordings",
    "authors": [
      "Feng Cao",
      "Zishuo Feng",
      "Jicong Zhang",
      "Wei Shi"
    ],
    "abstract": "Extracellular recordings are transient voltage fluctuations in the vicinity of neurons, serving as a fundamental modality in neuroscience for decoding brain activity at single-neuron resolution. Spike sorting, the process of attributing each detected spike to its corresponding neuron, is a pivotal step in brain sensing pipelines. However, it remains challenging under low signal-to-noise ratio (SNR), electrode drift and cross-session variability. In this paper, we propose HuiduRep, a robust self-supervised representation learning framework that extracts discriminative and generalizable features from extracellular recordings. By integrating contrastive learning with a denoising autoencoder, HuiduRep learns latent representations that are robust to noise and drift. With HuiduRep, we develop a spike sorting pipeline that clusters spike representations without ground truth labels. Experiments on hybrid and real-world datasets demonstrate that HuiduRep achieves strong robustness. Furthermore, the pipeline outperforms state-of-the-art tools such as KiloSort4 and MountainSort5. These findings demonstrate the potential of self-supervised spike representation learning as a foundational tool for robust and generalizable processing of extracellular recordings. Code is available at: https://github.com/IgarashiAkatuki/HuiduRep",
    "categories": [
      "eess.SP",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "eess.SP",
    "comment": "10 pages, 3 figures, 6 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.17224v3",
    "published_date": "2025-07-23 05:45:38 UTC",
    "updated_date": "2026-01-12 01:58:06 UTC"
  },
  {
    "arxiv_id": "2507.17216v1",
    "title": "The Pluralistic Moral Gap: Understanding Judgment and Value Differences between Humans and Large Language Models",
    "authors": [
      "Giuseppe Russo",
      "Debora Nozza",
      "Paul Röttger",
      "Dirk Hovy"
    ],
    "abstract": "People increasingly rely on Large Language Models (LLMs) for moral advice, which may influence humans' decisions. Yet, little is known about how closely LLMs align with human moral judgments. To address this, we introduce the Moral Dilemma Dataset, a benchmark of 1,618 real-world moral dilemmas paired with a distribution of human moral judgments consisting of a binary evaluation and a free-text rationale. We treat this problem as a pluralistic distributional alignment task, comparing the distributions of LLM and human judgments across dilemmas. We find that models reproduce human judgments only under high consensus; alignment deteriorates sharply when human disagreement increases. In parallel, using a 60-value taxonomy built from 3,783 value expressions extracted from rationales, we show that LLMs rely on a narrower set of moral values than humans. These findings reveal a pluralistic moral gap: a mismatch in both the distribution and diversity of values expressed. To close this gap, we introduce Dynamic Moral Profiling (DMP), a Dirichlet-based sampling method that conditions model outputs on human-derived value profiles. DMP improves alignment by 64.3% and enhances value diversity, offering a step toward more pluralistic and human-aligned moral guidance from LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.17216v1",
    "published_date": "2025-07-23 05:26:17 UTC",
    "updated_date": "2025-07-23 05:26:17 UTC"
  },
  {
    "arxiv_id": "2507.17214v1",
    "title": "Our Cars Can Talk: How IoT Brings AI to Vehicles",
    "authors": [
      "Amod Kant Agrawal"
    ],
    "abstract": "Bringing AI to vehicles and enabling them as sensing platforms is key to transforming maintenance from reactive to proactive. Now is the time to integrate AI copilots that speak both languages: machine and driver. This article offers a conceptual and technical perspective intended to spark interdisciplinary dialogue and guide future research and development in intelligent vehicle systems, predictive maintenance, and AI-powered user interaction.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.NI",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "3 pages, 1 figure; To appear in IEEE Computer (Nov 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.17214v1",
    "published_date": "2025-07-23 05:12:04 UTC",
    "updated_date": "2025-07-23 05:12:04 UTC"
  },
  {
    "arxiv_id": "2507.17202v1",
    "title": "DesignLab: Designing Slides Through Iterative Detection and Correction",
    "authors": [
      "Jooyeol Yun",
      "Heng Wang",
      "Yotaro Shimose",
      "Jaegul Choo",
      "Shingo Takamatsu"
    ],
    "abstract": "Designing high-quality presentation slides can be challenging for non-experts due to the complexity involved in navigating various design choices. Numerous automated tools can suggest layouts and color schemes, yet often lack the ability to refine their own output, which is a key aspect in real-world workflows. We propose DesignLab, which separates the design process into two roles, the design reviewer, who identifies design-related issues, and the design contributor who corrects them. This decomposition enables an iterative loop where the reviewer continuously detects issues and the contributor corrects them, allowing a draft to be further polished with each iteration, reaching qualities that were unattainable. We fine-tune large language models for these roles and simulate intermediate drafts by introducing controlled perturbations, enabling the design reviewer learn design errors and the contributor learn how to fix them. Our experiments show that DesignLab outperforms existing design-generation methods, including a commercial tool, by embracing the iterative nature of designing which can result in polished, professional slides.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "https://yeolj00.github.io/personal-projects/designlab",
    "pdf_url": "https://arxiv.org/pdf/2507.17202v1",
    "published_date": "2025-07-23 04:49:48 UTC",
    "updated_date": "2025-07-23 04:49:48 UTC"
  },
  {
    "arxiv_id": "2507.17194v1",
    "title": "Dispatch-Aware Deep Neural Network for Optimal Transmission Switching: Toward Real-Time and Feasibility Guaranteed Operation",
    "authors": [
      "Minsoo Kim",
      "Jip Kim"
    ],
    "abstract": "Optimal transmission switching (OTS) improves optimal power flow (OPF) by selectively opening transmission lines, but its mixed-integer formulation increases computational complexity, especially on large grids. To deal with this, we propose a dispatch-aware deep neural network (DA-DNN) that accelerates DC-OTS without relying on pre-solved labels. DA-DNN predicts line states and passes them through a differentiable DC-OPF layer, using the resulting generation cost as the loss function so that all physical network constraints are enforced throughout training and inference. In addition, we adopt a customized weight-bias initialization that keeps every forward pass feasible from the first iteration, which allows stable learning on large grids. Once trained, the proposed DA-DNN produces a provably feasible topology and dispatch pair in the same time as solving the DCOPF, whereas conventional mixed-integer solvers become intractable. As a result, the proposed method successfully captures the economic advantages of OTS while maintaining scalability.",
    "categories": [
      "eess.SY",
      "cs.AI"
    ],
    "primary_category": "eess.SY",
    "comment": "5 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.17194v1",
    "published_date": "2025-07-23 04:39:29 UTC",
    "updated_date": "2025-07-23 04:39:29 UTC"
  },
  {
    "arxiv_id": "2507.17188v1",
    "title": "LLM Meets the Sky: Heuristic Multi-Agent Reinforcement Learning for Secure Heterogeneous UAV Networks",
    "authors": [
      "Lijie Zheng",
      "Ji He",
      "Shih Yu Chang",
      "Yulong Shen",
      "Dusit Niyato"
    ],
    "abstract": "This work tackles the physical layer security (PLS) problem of maximizing the secrecy rate in heterogeneous UAV networks (HetUAVNs) under propulsion energy constraints. Unlike prior studies that assume uniform UAV capabilities or overlook energy-security trade-offs, we consider a realistic scenario where UAVs with diverse payloads and computation resources collaborate to serve ground terminals in the presence of eavesdroppers. To manage the complex coupling between UAV motion and communication, we propose a hierarchical optimization framework. The inner layer uses a semidefinite relaxation (SDR)-based S2DC algorithm combining penalty functions and difference-of-convex (d.c.) programming to solve the secrecy precoding problem with fixed UAV positions. The outer layer introduces a Large Language Model (LLM)-guided heuristic multi-agent reinforcement learning approach (LLM-HeMARL) for trajectory optimization. LLM-HeMARL efficiently incorporates expert heuristics policy generated by the LLM, enabling UAVs to learn energy-aware, security-driven trajectories without the inference overhead of real-time LLM calls. The simulation results show that our method outperforms existing baselines in secrecy rate and energy efficiency, with consistent robustness across varying UAV swarm sizes and random seeds.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.NI",
    "comment": "Submitted to IEEE Transactions on Mobile Computing",
    "pdf_url": "https://arxiv.org/pdf/2507.17188v1",
    "published_date": "2025-07-23 04:22:57 UTC",
    "updated_date": "2025-07-23 04:22:57 UTC"
  },
  {
    "arxiv_id": "2507.17185v1",
    "title": "Asymmetric Lesion Detection with Geometric Patterns and CNN-SVM Classification",
    "authors": [
      "M. A. Rasel",
      "Sameem Abdul Kareem",
      "Zhenli Kwan",
      "Nik Aimee Azizah Faheem",
      "Winn Hui Han",
      "Rebecca Kai Jan Choong",
      "Shin Shen Yong",
      "Unaizah Obaidellah"
    ],
    "abstract": "In dermoscopic images, which allow visualization of surface skin structures not visible to the naked eye, lesion shape offers vital insights into skin diseases. In clinically practiced methods, asymmetric lesion shape is one of the criteria for diagnosing melanoma. Initially, we labeled data for a non-annotated dataset with symmetrical information based on clinical assessments. Subsequently, we propose a supporting technique, a supervised learning image processing algorithm, to analyze the geometrical pattern of lesion shape, aiding non-experts in understanding the criteria of an asymmetric lesion. We then utilize a pre-trained convolutional neural network (CNN) to extract shape, color, and texture features from dermoscopic images for training a multiclass support vector machine (SVM) classifier, outperforming state-of-the-art methods from the literature. In the geometry-based experiment, we achieved a 99.00% detection rate for dermatological asymmetric lesions. In the CNN-based experiment, the best performance is found with 94% Kappa Score, 95% Macro F1-score, and 97% Weighted F1-score for classifying lesion shapes (Asymmetric, Half-Symmetric, and Symmetric).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted version. Published in Computers in Biology and Medicine, Volume 179, 2024. DOI: 10.1016/j.compbiomed.2024.108851",
    "pdf_url": "https://arxiv.org/pdf/2507.17185v1",
    "published_date": "2025-07-23 04:17:57 UTC",
    "updated_date": "2025-07-23 04:17:57 UTC"
  },
  {
    "arxiv_id": "2507.17183v1",
    "title": "Regret Minimization in Population Network Games: Vanishing Heterogeneity and Convergence to Equilibria",
    "authors": [
      "Die Hu",
      "Shuyue Hu",
      "Chunjiang Mu",
      "Shiqi Fan",
      "Chen Chu",
      "Jinzhuo Liu",
      "Zhen Wang"
    ],
    "abstract": "Understanding and predicting the behavior of large-scale multi-agents in games remains a fundamental challenge in multi-agent systems. This paper examines the role of heterogeneity in equilibrium formation by analyzing how smooth regret-matching drives a large number of heterogeneous agents with diverse initial policies toward unified behavior. By modeling the system state as a probability distribution of regrets and analyzing its evolution through the continuity equation, we uncover a key phenomenon in diverse multi-agent settings: the variance of the regret distribution diminishes over time, leading to the disappearance of heterogeneity and the emergence of consensus among agents. This universal result enables us to prove convergence to quantal response equilibria in both competitive and cooperative multi-agent settings. Our work advances the theoretical understanding of multi-agent learning and offers a novel perspective on equilibrium selection in diverse game-theoretic scenarios.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17183v1",
    "published_date": "2025-07-23 04:13:56 UTC",
    "updated_date": "2025-07-23 04:13:56 UTC"
  },
  {
    "arxiv_id": "2507.17178v3",
    "title": "SKA-Bench: A Fine-Grained Benchmark for Evaluating Structured Knowledge Understanding of LLMs",
    "authors": [
      "Zhiqiang Liu",
      "Enpei Niu",
      "Yin Hua",
      "Mengshu Sun",
      "Lei Liang",
      "Huajun Chen",
      "Wen Zhang"
    ],
    "abstract": "Although large language models (LLMs) have made significant progress in understanding Structured Knowledge (SK) like KG and Table, existing evaluations for SK understanding are non-rigorous (i.e., lacking evaluations of specific capabilities) and focus on a single type of SK. Therefore, we aim to propose a more comprehensive and rigorous structured knowledge understanding benchmark to diagnose the shortcomings of LLMs. In this paper, we introduce SKA-Bench, a Structured Knowledge Augmented QA Benchmark that encompasses four widely used structured knowledge forms: KG, Table, KG+Text, and Table+Text. We utilize a three-stage pipeline to construct SKA-Bench instances, which includes a question, an answer, positive knowledge units, and noisy knowledge units. To evaluate the SK understanding capabilities of LLMs in a fine-grained manner, we expand the instances into four fundamental ability testbeds: Noise Robustness, Order Insensitivity, Information Integration, and Negative Rejection. Empirical evaluations on 8 representative LLMs, including the advanced DeepSeek-R1, indicate that existing LLMs still face significant challenges in understanding structured knowledge, and their performance is influenced by factors such as the amount of noise, the order of knowledge units, and hallucination phenomenon. Our dataset and code are available at https://github.com/zjukg/SKA-Bench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.17178v3",
    "published_date": "2025-07-23 03:52:24 UTC",
    "updated_date": "2025-08-29 06:52:20 UTC"
  },
  {
    "arxiv_id": "2507.17168v1",
    "title": "Improving LLMs' Generalized Reasoning Abilities by Graph Problems",
    "authors": [
      "Qifan Zhang",
      "Nuo Chen",
      "Zehua Li",
      "Miao Peng",
      "Jing Tang",
      "Jia Li"
    ],
    "abstract": "Large Language Models (LLMs) have made remarkable strides in reasoning tasks, yet their performance often falters on novel and complex problems. Domain-specific continued pretraining (CPT) methods, such as those tailored for mathematical reasoning, have shown promise but lack transferability to broader reasoning tasks. In this work, we pioneer the use of Graph Problem Reasoning (GPR) to enhance the general reasoning capabilities of LLMs. GPR tasks, spanning pathfinding, network analysis, numerical computation, and topological reasoning, require sophisticated logical and relational reasoning, making them ideal for teaching diverse reasoning patterns. To achieve this, we introduce GraphPile, the first large-scale corpus specifically designed for CPT using GPR data. Spanning 10.9 billion tokens across 23 graph tasks, the dataset includes chain-of-thought, program-of-thought, trace of execution, and real-world graph data. Using GraphPile, we train GraphMind on popular base models Llama 3 and 3.1, as well as Gemma 2, achieving up to 4.9 percent higher accuracy in mathematical reasoning and up to 21.2 percent improvement in non-mathematical reasoning tasks such as logical and commonsense reasoning. By being the first to harness GPR for enhancing reasoning patterns and introducing the first dataset of its kind, our work bridges the gap between domain-specific pretraining and universal reasoning capabilities, advancing the adaptability and robustness of LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "COLM2025",
    "pdf_url": "https://arxiv.org/pdf/2507.17168v1",
    "published_date": "2025-07-23 03:19:57 UTC",
    "updated_date": "2025-07-23 03:19:57 UTC"
  },
  {
    "arxiv_id": "2507.17161v1",
    "title": "Tabular Diffusion based Actionable Counterfactual Explanations for Network Intrusion Detection",
    "authors": [
      "Vinura Galwaduge",
      "Jagath Samarabandu"
    ],
    "abstract": "Modern network intrusion detection systems (NIDS) frequently utilize the predictive power of complex deep learning models. However, the \"black-box\" nature of such deep learning methods adds a layer of opaqueness that hinders the proper understanding of detection decisions, trust in the decisions and prevent timely countermeasures against such attacks. Explainable AI (XAI) methods provide a solution to this problem by providing insights into the causes of the predictions. The majority of the existing XAI methods provide explanations which are not convenient to convert into actionable countermeasures. In this work, we propose a novel diffusion-based counterfactual explanation framework that can provide actionable explanations for network intrusion attacks. We evaluated our proposed algorithm against several other publicly available counterfactual explanation algorithms on 3 modern network intrusion datasets. To the best of our knowledge, this work also presents the first comparative analysis of existing counterfactual explanation algorithms within the context of network intrusion detection systems. Our proposed method provide minimal, diverse counterfactual explanations out of the tested counterfactual explanation algorithms in a more efficient manner by reducing the time to generate explanations. We also demonstrate how counterfactual explanations can provide actionable explanations by summarizing them to create a set of global rules. These rules are actionable not only at instance level but also at the global level for intrusion attacks. These global counterfactual rules show the ability to effectively filter out incoming attack queries which is crucial for efficient intrusion detection and defense mechanisms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17161v1",
    "published_date": "2025-07-23 02:53:58 UTC",
    "updated_date": "2025-07-23 02:53:58 UTC"
  },
  {
    "arxiv_id": "2507.17152v1",
    "title": "JAM: Keypoint-Guided Joint Prediction after Classification-Aware Marginal Proposal for Multi-Agent Interaction",
    "authors": [
      "Fangze Lin",
      "Ying He",
      "Fei Yu",
      "Hong Zhang"
    ],
    "abstract": "Predicting the future motion of road participants is a critical task in autonomous driving. In this work, we address the challenge of low-quality generation of low-probability modes in multi-agent joint prediction. To tackle this issue, we propose a two-stage multi-agent interactive prediction framework named \\textit{keypoint-guided joint prediction after classification-aware marginal proposal} (JAM). The first stage is modeled as a marginal prediction process, which classifies queries by trajectory type to encourage the model to learn all categories of trajectories, providing comprehensive mode information for the joint prediction module. The second stage is modeled as a joint prediction process, which takes the scene context and the marginal proposals from the first stage as inputs to learn the final joint distribution. We explicitly introduce key waypoints to guide the joint prediction module in better capturing and leveraging the critical information from the initial predicted trajectories. We conduct extensive experiments on the real-world Waymo Open Motion Dataset interactive prediction benchmark. The results show that our approach achieves competitive performance. In particular, in the framework comparison experiments, the proposed JAM outperforms other prediction frameworks and achieves state-of-the-art performance in interactive trajectory prediction. The code is available at https://github.com/LinFunster/JAM to facilitate future research.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "IROS 2025 Accepted",
    "pdf_url": "https://arxiv.org/pdf/2507.17152v1",
    "published_date": "2025-07-23 02:35:04 UTC",
    "updated_date": "2025-07-23 02:35:04 UTC"
  },
  {
    "arxiv_id": "2507.17149v1",
    "title": "ScSAM: Debiasing Morphology and Distributional Variability in Subcellular Semantic Segmentation",
    "authors": [
      "Bo Fang",
      "Jianan Fan",
      "Dongnan Liu",
      "Hang Chang",
      "Gerald J. Shami",
      "Filip Braet",
      "Weidong Cai"
    ],
    "abstract": "The significant morphological and distributional variability among subcellular components poses a long-standing challenge for learning-based organelle segmentation models, significantly increasing the risk of biased feature learning. Existing methods often rely on single mapping relationships, overlooking feature diversity and thereby inducing biased training. Although the Segment Anything Model (SAM) provides rich feature representations, its application to subcellular scenarios is hindered by two key challenges: (1) The variability in subcellular morphology and distribution creates gaps in the label space, leading the model to learn spurious or biased features. (2) SAM focuses on global contextual understanding and often ignores fine-grained spatial details, making it challenging to capture subtle structural alterations and cope with skewed data distributions. To address these challenges, we introduce ScSAM, a method that enhances feature robustness by fusing pre-trained SAM with Masked Autoencoder (MAE)-guided cellular prior knowledge to alleviate training bias from data imbalance. Specifically, we design a feature alignment and fusion module to align pre-trained embeddings to the same feature space and efficiently combine different representations. Moreover, we present a cosine similarity matrix-based class prompt encoder to activate class-specific features to recognize subcellular categories. Extensive experiments on diverse subcellular image datasets demonstrate that ScSAM outperforms state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by 28th European Conference on Artificial Intelligence (ECAI)",
    "pdf_url": "https://arxiv.org/pdf/2507.17149v1",
    "published_date": "2025-07-23 02:28:43 UTC",
    "updated_date": "2025-07-23 02:28:43 UTC"
  },
  {
    "arxiv_id": "2507.17141v1",
    "title": "Towards Human-level Intelligence via Human-like Whole-Body Manipulation",
    "authors": [
      "Guang Gao",
      "Jianan Wang",
      "Jinbo Zuo",
      "Junnan Jiang",
      "Jingfan Zhang",
      "Xianwen Zeng",
      "Yuejiang Zhu",
      "Lianyang Ma",
      "Ke Chen",
      "Minhua Sheng",
      "Ruirui Zhang",
      "Zhaohui An"
    ],
    "abstract": "Building general-purpose intelligent robots has long been a fundamental goal of robotics. A promising approach is to mirror the evolutionary trajectory of humans: learning through continuous interaction with the environment, with early progress driven by the imitation of human behaviors. Achieving this goal presents three core challenges: (1) designing safe robotic hardware with human-level physical capabilities; (2) developing an intuitive and scalable whole-body teleoperation interface for data collection; and (3) creating algorithms capable of learning whole-body visuomotor policies from human demonstrations. To address these challenges in a unified framework, we propose Astribot Suite, a robot learning suite for whole-body manipulation aimed at general daily tasks across diverse environments. We demonstrate the effectiveness of our system on a wide range of activities that require whole-body coordination, extensive reachability, human-level dexterity, and agility. Our results show that Astribot's cohesive integration of embodiment, teleoperation interface, and learning pipeline marks a significant step towards real-world, general-purpose whole-body robotic manipulation, laying the groundwork for the next generation of intelligent robots.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17141v1",
    "published_date": "2025-07-23 02:23:41 UTC",
    "updated_date": "2025-07-23 02:23:41 UTC"
  },
  {
    "arxiv_id": "2507.17135v1",
    "title": "SADA: Stability-guided Adaptive Diffusion Acceleration",
    "authors": [
      "Ting Jiang",
      "Yixiao Wang",
      "Hancheng Ye",
      "Zishan Shao",
      "Jingwei Sun",
      "Jingyang Zhang",
      "Zekai Chen",
      "Jianyi Zhang",
      "Yiran Chen",
      "Hai Li"
    ],
    "abstract": "Diffusion models have achieved remarkable success in generative tasks but suffer from high computational costs due to their iterative sampling process and quadratic attention costs. Existing training-free acceleration strategies that reduce per-step computation cost, while effectively reducing sampling time, demonstrate low faithfulness compared to the original baseline. We hypothesize that this fidelity gap arises because (a) different prompts correspond to varying denoising trajectory, and (b) such methods do not consider the underlying ODE formulation and its numerical solution. In this paper, we propose Stability-guided Adaptive Diffusion Acceleration (SADA), a novel paradigm that unifies step-wise and token-wise sparsity decisions via a single stability criterion to accelerate sampling of ODE-based generative models (Diffusion and Flow-matching). For (a), SADA adaptively allocates sparsity based on the sampling trajectory. For (b), SADA introduces principled approximation schemes that leverage the precise gradient information from the numerical ODE solver. Comprehensive evaluations on SD-2, SDXL, and Flux using both EDM and DPM++ solvers reveal consistent $\\ge 1.8\\times$ speedups with minimal fidelity degradation (LPIPS $\\leq 0.10$ and FID $\\leq 4.5$) compared to unmodified baselines, significantly outperforming prior methods. Moreover, SADA adapts seamlessly to other pipelines and modalities: It accelerates ControlNet without any modifications and speeds up MusicLDM by $1.8\\times$ with $\\sim 0.01$ spectrogram LPIPS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted and published by ICML 2025. Code is available at: https://github.com/Ting-Justin-Jiang/sada-icml",
    "pdf_url": "https://arxiv.org/pdf/2507.17135v1",
    "published_date": "2025-07-23 02:15:45 UTC",
    "updated_date": "2025-07-23 02:15:45 UTC"
  },
  {
    "arxiv_id": "2507.17134v1",
    "title": "Resilient Multi-Agent Negotiation for Medical Supply Chains:Integrating LLMs and Blockchain for Transparent Coordination",
    "authors": [
      "Mariam ALMutairi",
      "Hyungmin Kim"
    ],
    "abstract": "Global health emergencies, such as the COVID-19 pandemic, have exposed critical weaknesses in traditional medical supply chains, including inefficiencies in resource allocation, lack of transparency, and poor adaptability to dynamic disruptions. This paper presents a novel hybrid framework that integrates blockchain technology with a decentralized, large language model (LLM) powered multi-agent negotiation system to enhance the resilience and accountability of medical supply chains during crises. In this system, autonomous agents-representing manufacturers, distributors, and healthcare institutions-engage in structured, context-aware negotiation and decision-making processes facilitated by LLMs, enabling rapid and ethical allocation of scarce medical resources. The off-chain agent layer supports adaptive reasoning and local decision-making, while the on-chain blockchain layer ensures immutable, transparent, and auditable enforcement of decisions via smart contracts. The framework also incorporates a formal cross-layer communication protocol to bridge decentralized negotiation with institutional enforcement. A simulation environment emulating pandemic scenarios evaluates the system's performance, demonstrating improvements in negotiation efficiency, fairness of allocation, supply chain responsiveness, and auditability. This research contributes an innovative approach that synergizes blockchain trust guarantees with the adaptive intelligence of LLM-driven agents, providing a robust and scalable solution for critical supply chain coordination under uncertainty.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "11 pages, 6 figure",
    "pdf_url": "https://arxiv.org/pdf/2507.17134v1",
    "published_date": "2025-07-23 02:14:42 UTC",
    "updated_date": "2025-07-23 02:14:42 UTC"
  },
  {
    "arxiv_id": "2507.17131v2",
    "title": "Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance",
    "authors": [
      "Yufei He",
      "Ruoyu Li",
      "Alex Chen",
      "Yue Liu",
      "Yulin Chen",
      "Yuan Sui",
      "Cheng Chen",
      "Yi Zhu",
      "Luca Luo",
      "Frank Yang",
      "Bryan Hooi"
    ],
    "abstract": "Large language model (LLM) agents often struggle in environments where rules and required domain knowledge frequently change, such as regulatory compliance and user risk screening. Current approaches, like offline fine-tuning and standard prompting, are insufficient because they cannot effectively adapt to new knowledge during actual operation. To address this limitation, we propose the Adaptive Reflective Interactive Agent (ARIA), an LLM agent framework designed specifically to continuously learn updated domain knowledge at test time. ARIA assesses its own uncertainty through structured self-dialogue, proactively identifying knowledge gaps and requesting targeted explanations or corrections from human experts. It then systematically updates an internal, timestamped knowledge repository with provided human guidance, detecting and resolving conflicting or outdated knowledge through comparisons and clarification queries. We evaluate ARIA on the realistic customer due diligence name screening task on TikTok Pay, alongside publicly available dynamic knowledge tasks. Results demonstrate significant improvements in adaptability and accuracy compared to baselines using standard offline fine-tuning and existing self-improving agents. ARIA is deployed within TikTok Pay serving over 150 million monthly active users, confirming its practicality and effectiveness for operational use in rapidly evolving environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.17131v2",
    "published_date": "2025-07-23 02:12:32 UTC",
    "updated_date": "2025-10-10 06:52:01 UTC"
  },
  {
    "arxiv_id": "2507.17120v1",
    "title": "BucketServe: Bucket-Based Dynamic Batching for Smart and Efficient LLM Inference Serving",
    "authors": [
      "Wanyi Zheng",
      "Minxian Xu",
      "Shengye Song",
      "Kejiang Ye"
    ],
    "abstract": "Large language models (LLMs) have become increasingly popular in various areas, traditional business gradually shifting from rule-based systems to LLM-based solutions. However, the inference of LLMs is resource-intensive or latency-sensitive, posing significant challenges for serving systems. Existing LLM serving systems often use static or continuous batching strategies, which can lead to inefficient GPU memory utilization and increased latency, especially under heterogeneous workloads. These methods may also struggle to adapt to dynamic workload fluctuations, resulting in suboptimal throughput and potential service level objective (SLO) violations. In this paper, we introduce BucketServe, a bucket-based dynamic batching framework designed to optimize LLM inference performance. By grouping requests into size-homogeneous buckets based on sequence length, BucketServe minimizes padding overhead and optimizes GPU memory usage through real-time batch size adjustments preventing out-of-memory (OOM) errors. It introduces adaptive bucket splitting/merging and priority-aware scheduling to mitigate resource fragmentation and ensure SLO compliance. Experiment shows that BucketServe significantly outperforms UELLM in throughput, achieving up to 3.58x improvement. It can also handle 1.93x more request load under the SLO attainment of 80% compared with DistServe and demonstrates 1.975x higher system load capacity compared to the UELLM.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "9 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.17120v1",
    "published_date": "2025-07-23 01:51:48 UTC",
    "updated_date": "2025-07-23 01:51:48 UTC"
  },
  {
    "arxiv_id": "2508.00879v1",
    "title": "GNN-ASE: Graph-Based Anomaly Detection and Severity Estimation in Three-Phase Induction Machines",
    "authors": [
      "Moutaz Bellah Bentrad",
      "Adel Ghoggal",
      "Tahar Bahi",
      "Abderaouf Bahi"
    ],
    "abstract": "The diagnosis of induction machines has traditionally relied on model-based methods that require the development of complex dynamic models, making them difficult to implement and computationally expensive. To overcome these limitations, this paper proposes a model-free approach using Graph Neural Networks (GNNs) for fault diagnosis in induction machines. The focus is on detecting multiple fault types -- including eccentricity, bearing defects, and broken rotor bars -- under varying severity levels and load conditions. Unlike traditional approaches, raw current and vibration signals are used as direct inputs, eliminating the need for signal preprocessing or manual feature extraction. The proposed GNN-ASE model automatically learns and extracts relevant features from raw inputs, leveraging the graph structure to capture complex relationships between signal types and fault patterns. It is evaluated for both individual fault detection and multi-class classification of combined fault conditions. Experimental results demonstrate the effectiveness of the proposed model, achieving 92.5\\% accuracy for eccentricity defects, 91.2\\% for bearing faults, and 93.1\\% for broken rotor bar detection. These findings highlight the model's robustness and generalization capability across different operational scenarios. The proposed GNN-based framework offers a lightweight yet powerful solution that simplifies implementation while maintaining high diagnostic performance. It stands as a promising alternative to conventional model-based diagnostic techniques for real-world induction machine monitoring and predictive maintenance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.00879v1",
    "published_date": "2025-07-23 01:50:07 UTC",
    "updated_date": "2025-07-23 01:50:07 UTC"
  },
  {
    "arxiv_id": "2507.17118v1",
    "title": "HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study",
    "authors": [
      "Mandar Pitale",
      "Jelena Frtunikj",
      "Abhinaw Priyadershi",
      "Vasu Singh",
      "Maria Spence"
    ],
    "abstract": "AI has become integral to safety-critical areas like autonomous driving systems (ADS) and robotics. The architecture of recent autonomous systems are trending toward end-to-end (E2E) monolithic architectures such as large language models (LLMs) and vision language models (VLMs). In this paper, we review different architectural solutions and then evaluate the efficacy of common safety analyses such as failure modes and effect analysis (FMEA) and fault tree analysis (FTA). We show how these techniques can be improved for the intricate nature of the foundational models, particularly in how they form and utilize latent representations. We introduce HySAFE-AI, Hybrid Safety Architectural Analysis Framework for AI Systems, a hybrid framework that adapts traditional methods to evaluate the safety of AI systems. Lastly, we offer hints of future work and suggestions to guide the evolution of future AI safety standards.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.17118v1",
    "published_date": "2025-07-23 01:41:51 UTC",
    "updated_date": "2025-07-23 01:41:51 UTC"
  },
  {
    "arxiv_id": "2507.17107v2",
    "title": "Reinforcement Learning Fine-Tunes a Sparse Subnetwork in Large Language Models",
    "authors": [
      "Andrii Balashov"
    ],
    "abstract": "Reinforcement learning (RL) is a key post-pretraining step for aligning large language models (LLMs) with complex tasks and human preferences. While it is often assumed that RL fine-tuning requires updating most of a model's parameters, we challenge this assumption with a surprising finding: RL fine-tuning consistently modifies only a small subnetwork (typically 5-30% of weights), leaving most parameters unchanged. We call this phenomenon RL-induced parameter update sparsity. It arises naturally, without any sparsity constraints or parameter-efficient tuning, and appears across multiple RL algorithms (e.g., PPO, DPO, SimPO, PRIME) and model families (e.g., OpenAI, Meta, and open-source LLMs). Moreover, the subnetworks updated by RL show substantial overlap across different seeds, datasets, and algorithms-far exceeding chance-suggesting a partially transferable structure in the pretrained model. We show that fine-tuning only this sparse subnetwork recovers full model performance and yields parameters nearly identical to the fully fine-tuned model. Our analysis suggests this sparsity emerges because RL operates near the model's original distribution, requiring only targeted changes. KL penalties, gradient clipping, and on-policy dynamics have limited effect on the sparsity pattern. These findings shed new light on how RL adapts models: not by shifting all weights, but by focusing training on a small, consistently updated subnetwork. This insight enables more efficient RL methods and reframes sparsity through the lens of the lottery ticket hypothesis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The manuscript has been withdrawn due to significant overlap in methodology and results with a prior work (arXiv:2505.11711) that we were not aware of at the time of submission. To maintain academic integrity and avoid redundancy in the literature, we have chosen to withdraw this version",
    "pdf_url": "https://arxiv.org/pdf/2507.17107v2",
    "published_date": "2025-07-23 01:02:17 UTC",
    "updated_date": "2025-07-28 18:29:13 UTC"
  },
  {
    "arxiv_id": "2507.17780v1",
    "title": "In Reverie Together: Ten Years of Mathematical Discovery with a Machine Collaborator",
    "authors": [
      "Randy Davila",
      "Boris Brimkov",
      "Ryan Pepper"
    ],
    "abstract": "We present four open conjectures in graph theory generated by the automated conjecturing system \\texttt{TxGraffiti}. Each conjecture is concise, grounded in natural graph invariants, and empirically validated across hundreds of graphs. Despite extensive effort, these statements remain unresolved--defying both proof and counterexample. They are not only mathematical challenges but creative expressions--born of symbolic pattern recognition and mathematician-defined heuristics, refined through years of human dialogue, and now offered back to the community as collaborative artifacts. These conjectures invite not only formal proof, but also reflection on how machines can evoke wonder, spark curiosity, and contribute to the raw material of discovery. By highlighting these problems, we aim to inspire both human mathematicians and AI systems to engage with them--not only to solve them, but to reflect on what it means when machines participate meaningfully in the creative process of mathematical thought.",
    "categories": [
      "cs.DM",
      "cs.AI",
      "math.CO"
    ],
    "primary_category": "cs.DM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.17780v1",
    "published_date": "2025-07-23 00:49:32 UTC",
    "updated_date": "2025-07-23 00:49:32 UTC"
  },
  {
    "arxiv_id": "2507.17099v1",
    "title": "Weather-Aware AI Systems versus Route-Optimization AI: A Comprehensive Analysis of AI Applications in Transportation Productivity",
    "authors": [
      "Tatsuru Kikuchi"
    ],
    "abstract": "While recent research demonstrates that AI route-optimization systems improve taxi driver productivity by 14\\%, this study reveals that such findings capture only a fraction of AI's potential in transportation. We examine comprehensive weather-aware AI systems that integrate deep learning meteorological prediction with machine learning positioning optimization, comparing their performance against traditional operations and route-only AI approaches. Using simulation data from 10,000 taxi operations across varied weather conditions, we find that weather-aware AI systems increase driver revenue by 107.3\\%, compared to 14\\% improvements from route-optimization alone. Weather prediction contributes the largest individual productivity gain, with strong correlations between meteorological conditions and demand ($r=0.575$). Economic analysis reveals annual earnings increases of 13.8 million yen per driver, with rapid payback periods and superior return on investment. These findings suggest that current AI literature significantly underestimates AI's transformative potential by focusing narrowly on routing algorithms, while weather intelligence represents an untapped \\$8.9 billion market opportunity. Our results indicate that future AI implementations should adopt comprehensive approaches that address multiple operational challenges simultaneously rather than optimizing isolated functions.",
    "categories": [
      "econ.GN",
      "cs.AI"
    ],
    "primary_category": "econ.GN",
    "comment": "41 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.17099v1",
    "published_date": "2025-07-23 00:30:09 UTC",
    "updated_date": "2025-07-23 00:30:09 UTC"
  }
]