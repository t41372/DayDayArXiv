{
  "date": "2025-03-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-06 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 领域的创新，特别是大型语言模型 (LLMs) 的优化、多模态处理和应用扩展，以及强化学习在机器人和医疗诊断中的进展。重点包括 XAI 技术评估框架、MoE 模型的持续训练，以及 LLMs 在软件开发和社会影响中的潜力，令人印象深刻的文章有 “Continual Pre-training of MoEs” 和 “LLMs' Reshaping of People, Processes, Products, and Society”，这些论文展示了著名学者如 Benjamin Thérien 和 Benyamin Tabarsi 的前沿工作。\n\n下面，我将按主题简要总结相关论文，先优先讨论 AI 和 LLMs 相关的重要内容，再快速掠过其他领域。每个论文标题以中文 + 英文形式列出，焦点放在核心贡献和发现上。\n\n### AI 和 LLMs 优化\n- **Continual Pre-training of MoEs: How robust is your router? (MoE 模型的持续预训练：路由器的鲁棒性)**  \n  这篇论文探讨了稀疏激活 Mixture of Experts (MoE) 模型的持续预训练，核心发现是 MoE 路由算法对分布偏移表现出惊人的鲁棒性，即使没有重放数据也能保持样本效率，显著提升了 LLM 在大规模数据上的性能。\n\n- **LLMs' Reshaping of People, Processes, Products, and Society in Software Development: A Comprehensive Exploration with Early Adopters (LLMs 在软件开发中重塑人员、流程、产品和社会：与早期采用者的全面探索)**  \n  通过对 16 名专业开发者的访谈，论文揭示 LLMs 显著提升了代码生成和调试等常规任务，但也强调了生成内容的不准确性，需要手动审查，这为软件工程的 LLM 应用提供了宝贵指导。\n\n- **Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models (Balcony：生成式语言模型的轻量动态推理方法)**  \n  论文提出 Balcony 框架，通过在预训练模型中插入额外层并使用自蒸馏损失，实现高效的动态推理，显著减少了训练令牌和参数，相比状态-of-the-art 方法在多个基准上表现出色。\n\n- **Wanda++: Pruning Large Language Models via Regional Gradients (Wanda++：通过区域梯度修剪大型语言模型)**  \n  这篇工作引入区域梯度优化来修剪 LLM，显著降低了计算资源需求，同时在语言建模和下游任务中提升了性能，证明了其对复杂模型的普适性。\n\n- **LVLM-Compress-Bench: Benchmarking the Broader Impact of Large Vision-Language Model Compression (LVLM-Compress-Bench：基准测试大型视觉语言模型压缩的广泛影响)**  \n  论文构建了一个基准来评估视觉语言模型的压缩影响，涵盖知识和偏见等指标，发现量化压缩在保持性能的同时能减少资源消耗。\n\n- **Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge Reasoning (超越 RAG：任务感知 KV 缓存压缩用于全面知识推理)**  \n  提出任务感知的 KV 缓存压缩方法，显著提高了知识推理效率，实验显示在 LongBench v2 上比 RAG 提升 7 个绝对点，同时减少了延迟。\n\n其他 LLM 相关论文如 “A Unified Framework with Novel Metrics for Evaluating the Effectiveness of XAI Techniques in LLMs” 和 “Shifting Long-Context LLMs Research from Input to Output” 等，分别贡献了 XAI 评估新指标和长上下文输出优化，但这些更技术性较强，我这里简要掠过。\n\n### 医疗和生物应用\n- **Enhancing Alzheimer's Diagnosis: Leveraging Anatomical Landmarks in Graph Convolutional Neural Networks on Tetrahedral Meshes (增强阿尔茨海默病诊断：利用解剖标志在四面体网格上的图卷积神经网络)**  \n  论文开发了一个基于几何深度学习的模型，使用解剖标志预测脑淀粉样沉积，提高了阿尔茨海默病早期诊断准确性，尤其在中等风险组中表现出色。\n\n- **Federated Inverse Probability Treatment Weighting for Individual Treatment Effect Estimation (联邦逆概率处理加权用于个体治疗效果估计)**  \n  这篇工作提出 FED-IPTW 算法，用于隐私保护的联邦学习环境，显著提升了 ICU 机械通气治疗效果的估计准确性。\n\n其他医疗论文如 “Prediction of Frozen Region Growth in Kidney Cryoablation Intervention Using a 3D Flow-Matching Model” 等，贡献了 cryoablation 预测模型，但细节较专业，我快速掠过。\n\n### 强化学习和机器人\n- **Provably Correct Automata Embeddings for Optimal Automata-Conditioned Reinforcement Learning (可证明正确的自动机嵌入用于最优自动机条件强化学习)**  \n  论文提供了一个理论框架，确保强化学习中的自动机嵌入是正确可学习的，实验验证了其在多任务策略学习中的优越性。\n\n- **Data-Efficient Learning from Human Interventions for Mobile Robots (从人类干预中进行数据高效学习用于移动机器人)**  \n  提出 PVP4Real 方法，通过在线人类干预结合强化学习，实现机器人任务的快速训练，实验显示 15 分钟内即可完成。\n\n其他强化学习论文如 “Incentivizing Multi-Tenant Split Federated Learning for Foundation Models at the Network Edge” 等，聚焦边缘计算激励机制，但影响力较小，我简要略过。\n\n### 其他领域快速掠过\n其余论文涉及文本生成、量子学习和安全等领域，我只列出标题和核心发现：\n- **VQEL: Enabling Self-Developed Symbolic Language in Agents through Vector Quantization in Emergent Language Games (VQEL：通过向量量化在新兴语言游戏中启用代理的自发展符号语言)**  \n  贡献了代理的自监督语言学习方法，提升了符号表示的鲁棒性。\n- **SafeArena: Evaluating the Safety of Autonomous Web Agents (SafeArena：评估自主网络代理的安全性)**  \n  构建了安全基准，揭示代理在有害任务中的易受攻击性。\n- **TIMER: Temporal Instruction Modeling and Evaluation for Longitudinal Clinical Records (TIMER：纵向临床记录的时序指令建模和评估)**  \n  改进了 LLM 在时序医疗数据上的推理能力。\n- **L$^2$M: Mutual Information Scaling Law for Long-Context Language Modeling (L$^2$M：长上下文语言建模的互信息缩放定律)**  \n  建立了长上下文建模的理论基础。\n- **Enough Coin Flips Can Make LLMs Act Bayesian (足够的硬币抛掷能让 LLMs 表现为贝叶斯)**  \n  发现 LLMs 通过少样本学习可模拟贝叶斯更新。\n\n今天的论文总体上突出了 AI 领域的实用创新，LLM 相关工作尤其值得关注。如果你对特定主题感兴趣，建议查看这些论文的摘要！",
  "papers": [
    {
      "arxiv_id": "2503.05050v2",
      "title": "A Unified Framework with Novel Metrics for Evaluating the Effectiveness of XAI Techniques in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Melkamu Abay Mersha",
        "Mesay Gemeda Yigezu",
        "Hassan Shakil",
        "Ali K. AlShami",
        "Sanghyun Byun",
        "Jugal Kalita"
      ],
      "abstract": "The increasing complexity of LLMs presents significant challenges to their\ntransparency and interpretability, necessitating the use of eXplainable AI\n(XAI) techniques to enhance trustworthiness and usability. This study\nintroduces a comprehensive evaluation framework with four novel metrics for\nassessing the effectiveness of five XAI techniques across five LLMs and two\ndownstream tasks. We apply this framework to evaluate several XAI techniques\nLIME, SHAP, Integrated Gradients, Layer-wise Relevance Propagation (LRP), and\nAttention Mechanism Visualization (AMV) using the IMDB Movie Reviews and Tweet\nSentiment Extraction datasets. The evaluation focuses on four key metrics:\nHuman-reasoning Agreement (HA), Robustness, Consistency, and Contrastivity. Our\nresults show that LIME consistently achieves high scores across multiple LLMs\nand evaluation metrics, while AMV demonstrates superior Robustness and\nnear-perfect Consistency. LRP excels in Contrastivity, particularly with more\ncomplex models. Our findings provide valuable insights into the strengths and\nlimitations of different XAI methods, offering guidance for developing and\nselecting appropriate XAI techniques for LLMs.",
      "tldr_zh": "这篇论文提出一个统一框架和四个新颖指标（Human-reasoning Agreement (HA)、Robustness、Consistency 和 Contrastivity），用于评估 XAI 技术在 LLMs 中的有效性。研究团队评估了 LIME、SHAP、Integrated Gradients、Layer-wise Relevance Propagation (LRP) 和 Attention Mechanism Visualization (AMV) 等五种 XAI 技术，应用于五个 LLMs 和 IMDB Movie Reviews、Tweet Sentiment Extraction 等两个下游任务。结果显示，LIME 在多个 LLMs 和指标中表现出色，AMV 在 Robustness 和 Consistency 上表现优异，而 LRP 在 Contrastivity 上特别突出。这些发现为理解 XAI 方法的优缺点提供了宝贵洞见，并指导了其在 LLMs 中的开发和选择。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2501.15374",
      "pdf_url": "http://arxiv.org/pdf/2503.05050v2",
      "published_date": "2025-03-06 23:59:50 UTC",
      "updated_date": "2025-04-07 20:37:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:33:29.487526"
    },
    {
      "arxiv_id": "2503.05042v1",
      "title": "Provably Correct Automata Embeddings for Optimal Automata-Conditioned Reinforcement Learning",
      "title_zh": "可证明正确的自动机嵌入，用于最优自动机条件化强化学习",
      "authors": [
        "Beyazit Yalcinkaya",
        "Niklas Lauffer",
        "Marcell Vazquez-Chanlatte",
        "Sanjit A. Seshia"
      ],
      "abstract": "Automata-conditioned reinforcement learning (RL) has given promising results\nfor learning multi-task policies capable of performing temporally extended\nobjectives given at runtime, done by pretraining and freezing automata\nembeddings prior to training the downstream policy. However, no theoretical\nguarantees were given. This work provides a theoretical framework for the\nautomata-conditioned RL problem and shows that it is probably approximately\ncorrect learnable. We then present a technique for learning provably correct\nautomata embeddings, guaranteeing optimal multi-task policy learning. Our\nexperimental evaluation confirms these theoretical results.",
      "tldr_zh": "这篇论文针对Automata-conditioned Reinforcement Learning (RL)的问题，提供了一个理论框架，证明其是probably approximately correct learnable，从而为学习多任务策略提供理论保证。作者提出了一种学习provably correct automata embeddings的技术，通过预训练和冻结嵌入来确保下游策略的优化性能。实验结果验证了这些理论分析，展示了框架在执行时间扩展目标任务时的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.FL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05042v1",
      "published_date": "2025-03-06 23:37:05 UTC",
      "updated_date": "2025-03-06 23:37:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:33:38.905070"
    },
    {
      "arxiv_id": "2503.05031v1",
      "title": "Enhancing Alzheimer's Diagnosis: Leveraging Anatomical Landmarks in Graph Convolutional Neural Networks on Tetrahedral Meshes",
      "title_zh": "翻译失败",
      "authors": [
        "Yanxi Chen",
        "Mohammad Farazi",
        "Zhangsihao Yang",
        "Yonghui Fan",
        "Nicholas Ashton",
        "Eric M Reiman",
        "Yi Su",
        "Yalin Wang"
      ],
      "abstract": "Alzheimer's disease (AD) is a major neurodegenerative condition that affects\nmillions around the world. As one of the main biomarkers in the AD diagnosis\nprocedure, brain amyloid positivity is typically identified by positron\nemission tomography (PET), which is costly and invasive. Brain structural\nmagnetic resonance imaging (sMRI) may provide a safer and more convenient\nsolution for the AD diagnosis. Recent advances in geometric deep learning have\nfacilitated sMRI analysis and early diagnosis of AD. However, determining AD\npathology, such as brain amyloid deposition, in preclinical stage remains\nchallenging, as less significant morphological changes can be observed. As a\nresult, few AD classification models are generalizable to the brain amyloid\npositivity classification task. Blood-based biomarkers (BBBMs), on the other\nhand, have recently achieved remarkable success in predicting brain amyloid\npositivity and identifying individuals with high risk of being brain amyloid\npositive. However, individuals in medium risk group still require gold standard\ntests such as Amyloid PET for further evaluation. Inspired by the recent\nsuccess of transformer architectures, we propose a geometric deep learning\nmodel based on transformer that is both scalable and robust to variations in\ninput volumetric mesh size. Our work introduced a novel tokenization scheme for\ntetrahedral meshes, incorporating anatomical landmarks generated by a\npre-trained Gaussian process model. Our model achieved superior classification\nperformance in AD classification task. In addition, we showed that the model\nwas also generalizable to the brain amyloid positivity prediction with\nindividuals in the medium risk class, where BM alone cannot achieve a clear\nclassification. Our work may enrich geometric deep learning research and\nimprove AD diagnosis accuracy without using expensive and invasive PET scans.",
      "tldr_zh": "本研究针对阿尔茨海默病（AD）诊断的挑战，提出了一种基于Transformer的几何深度学习模型，利用Graph Convolutional Neural Networks在Tetrahedral Meshes上整合预训练的高斯过程模型生成的anatomical landmarks，以分析结构磁共振成像（sMRI）。该模型引入了一种新颖的标记化方案（tokenization scheme），能够有效捕捉早期AD病理变化，并在AD分类任务中实现优越的性能。实验结果显示，该模型对中风险人群的脑淀粉样沉积预测具有良好的泛化性，从而减少了对昂贵侵入性的positron emission tomography (PET)扫描的依赖，并提升了诊断准确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "q-bio.NC"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05031v1",
      "published_date": "2025-03-06 23:02:18 UTC",
      "updated_date": "2025-03-06 23:02:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:33:53.037988"
    },
    {
      "arxiv_id": "2503.05029v1",
      "title": "Continual Pre-training of MoEs: How robust is your router?",
      "title_zh": "MoEs 的持续预训练：你的路由器有多鲁",
      "authors": [
        "Benjamin Thérien",
        "Charles-Étienne Joseph",
        "Zain Sarwar",
        "Ashwinee Panda",
        "Anirban Das",
        "Shi-Xiong Zhang",
        "Stephen Rawls",
        "Sambit Sahu",
        "Eugene Belilovsky",
        "Irina Rish"
      ],
      "abstract": "Sparsely-activated Mixture of Experts (MoE) transformers are promising\narchitectures for foundation models. Compared to dense transformers that\nrequire the same amount of floating point operations (FLOPs) per forward pass,\nMoEs benefit from improved sample efficiency at training time and achieve much\nstronger performance. Many closed-source and open-source frontier language\nmodels have thus adopted an MoE architecture. Naturally, practitioners will\nwant to extend the capabilities of these models with large amounts of newly\ncollected data without completely re-training them. Prior work has shown that a\nsimple combination of replay and learning rate re-warming and re-decaying can\nenable the continual pre-training (CPT) of dense decoder-only transformers with\nminimal performance degradation compared to full re-training. In the case of\ndecoder-only MoE transformers, however, it is unclear how the routing algorithm\nwill impact continual pre-training performance: 1) do the MoE transformer's\nrouters exacerbate forgetting relative to a dense model?; 2) do the routers\nmaintain a balanced load on previous distributions after CPT?; 3) are the same\nstrategies applied to dense models sufficient to continually pre-train MoE\nLLMs? In what follows, we conduct a large-scale (>2B parameter switch and\nDeepSeek MoE LLMs trained for 600B tokens) empirical study across four MoE\ntransformers to answer these questions. Our results establish a surprising\nrobustness to distribution shifts for both Sinkhorn-Balanced and\nZ-and-Aux-loss-balanced routing algorithms, even in MoEs continually\npre-trained without replay. Moreover, we show that MoE LLMs maintain their\nsample efficiency (relative to a FLOP-matched dense model) during CPT and that\nthey can match the performance of a fully re-trained MoE at a fraction of the\ncost.",
      "tldr_zh": "这篇论文探讨了稀疏激活的 Mixture of Experts (MoE) 变换器在持续预训练 (CPT) 中的鲁棒性，特别是路由算法的表现。研究者通过大规模实证实验（涉及>2B 参数的 MoE 模型，训练600B tokens）评估了路由算法是否加剧遗忘、保持负载平衡，以及是否能采用与密集模型相同的策略。结果显示，Sinkhorn-Balanced 和 Z-and-Aux-loss-balanced 路由算法对分布偏移表现出惊人鲁棒性，即使在没有重放的情况下；此外，MoE 模型在 CPT 中保持了相对于 FLOP 匹配密集模型的样本效率，并能以更低成本匹配完全重新训练的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05029v1",
      "published_date": "2025-03-06 22:55:01 UTC",
      "updated_date": "2025-03-06 22:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:34:03.998471"
    },
    {
      "arxiv_id": "2503.05012v1",
      "title": "LLMs' Reshaping of People, Processes, Products, and Society in Software Development: A Comprehensive Exploration with Early Adopters",
      "title_zh": "翻译失败",
      "authors": [
        "Benyamin Tabarsi",
        "Heidi Reichert",
        "Ally Limke",
        "Sandeep Kuttal",
        "Tiffany Barnes"
      ],
      "abstract": "Large language models (LLMs) like OpenAI ChatGPT, Google Gemini, and GitHub\nCopilot are rapidly gaining traction in the software industry, but their full\nimpact on software engineering remains insufficiently explored. Despite their\ngrowing adoption, there is a notable lack of formal, qualitative assessments of\nhow LLMs are applied in real-world software development contexts. To fill this\ngap, we conducted semi-structured interviews with sixteen early-adopter\nprofessional developers to explore their use of LLMs throughout various stages\nof the software development life cycle. Our investigation examines four\ndimensions: people - how LLMs affect individual developers and teams; process -\nhow LLMs alter software engineering workflows; product - LLM impact on software\nquality and innovation; and society - the broader socioeconomic and ethical\nimplications of LLM adoption. Thematic analysis of our data reveals that while\nLLMs have not fundamentally revolutionized the development process, they have\nsubstantially enhanced routine coding tasks, including code generation,\nrefactoring, and debugging. Developers reported the most effective outcomes\nwhen providing LLMs with clear, well-defined problem statements, indicating\nthat LLMs excel with decomposed problems and specific requirements.\nFurthermore, these early-adopters identified that LLMs offer significant value\nfor personal and professional development, aiding in learning new languages and\nconcepts. Early-adopters, highly skilled in software engineering and how LLMs\nwork, identified early and persisting challenges for software engineering, such\nas inaccuracies in generated content and the need for careful manual review\nbefore integrating LLM outputs into production environments. Our study provides\na nuanced understanding of how LLMs are shaping the landscape of software\ndevelopment, with their benefits, limitations, and ongoing implications.",
      "tldr_zh": "本研究通过对16名早期采用者专业开发者的半结构化采访，探讨了大型语言模型（LLMs）如ChatGPT、Google Gemini和GitHub Copilot在软件开发中的影响，涵盖人员（对开发者和团队的影响）、流程（工作流程改变）、产品（软件质量和创新）和社会（社会经济及伦理含义）四个维度。结果显示，LLMs显著提升了例行任务如代码生成、重构和调试的效率，并在学习新语言和概念方面提供价值，但其最佳效果依赖于清晰的问题定义。开发人员强调了生成的代码可能不准确，需要手动审查等挑战，该研究为理解LLMs在软件开发领域的益处、限制和长期影响提供了细致见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05012v1",
      "published_date": "2025-03-06 22:27:05 UTC",
      "updated_date": "2025-03-06 22:27:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:34:15.311126"
    },
    {
      "arxiv_id": "2503.05005v2",
      "title": "Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models",
      "title_zh": "Balcony：生成式语言模型动态推理的轻量级方法",
      "authors": [
        "Benyamin Jamialahmadi",
        "Parsa Kavehzadeh",
        "Mehdi Rezagholizadeh",
        "Parsa Farinneya",
        "Hossein Rajabzadeh",
        "Aref Jafari",
        "Boxing Chen",
        "Marzieh S. Tahaei"
      ],
      "abstract": "Deploying large language models (LLMs) in real-world applications is often\nhindered by strict computational and latency constraints. While dynamic\ninference offers the flexibility to adjust model behavior based on varying\nresource budgets, existing methods are frequently limited by hardware\ninefficiencies or performance degradation. In this paper, we introduce Balcony,\na simple yet highly effective framework for depth-based dynamic inference. By\nfreezing the pretrained LLM and inserting additional transformer layers at\nselected exit points, Balcony maintains the full model's performance while\nenabling real-time adaptation to different computational budgets. These\nadditional layers are trained using a straightforward self-distillation loss,\naligning the sub-model outputs with those of the full model. This approach\nrequires significantly fewer training tokens and tunable parameters,\ndrastically reducing computational costs compared to prior methods. When\napplied to the LLaMA3-8B model, using only 0.2% of the original pretraining\ndata, Balcony achieves minimal performance degradation while enabling\nsignificant speedups. Remarkably, we show that Balcony outperforms\nstate-of-the-art methods such as Flextron and Layerskip as well as other\nleading compression techniques on multiple models and at various scales, across\na variety of benchmarks.",
      "tldr_zh": "本研究提出 Balcony，一种轻量级框架，用于实现生成语言模型（LLMs）的动态推理，以应对实际部署中的计算和延迟限制。Balcony 通过在预训练 LLM 上插入额外 transformer layers 并在选定出口点进行深度调整，同时使用自蒸馏 loss 训练这些层，从而保持全模型性能并显著减少训练数据和参数量。实验结果显示，在 LLaMA3-8B 模型上，仅使用 0.2% 的原始预训练数据，Balcony 就实现了最小性能下降和显著加速，并在多个基准上优于现有方法如 Flextron 和 Layerskip。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05005v2",
      "published_date": "2025-03-06 22:09:55 UTC",
      "updated_date": "2025-03-10 18:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:34:26.849790"
    },
    {
      "arxiv_id": "2503.04992v2",
      "title": "Wanda++: Pruning Large Language Models via Regional Gradients",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Yang",
        "Kai Zhen",
        "Bhavana Ganesh",
        "Aram Galstyan",
        "Goeric Huybrechts",
        "Markus Müller",
        "Jonas M. Kübler",
        "Rupak Vignesh Swaminathan",
        "Athanasios Mouchtaris",
        "Sravan Babu Bodapati",
        "Nathan Susanj",
        "Zheng Zhang",
        "Jack FitzGerald",
        "Abhishek Kumar"
      ],
      "abstract": "Large Language Models (LLMs) pruning seeks to remove unimportant weights for\ninference speedup with minimal performance impact. However, existing methods\noften suffer from performance loss without full-model sparsity-aware\nfine-tuning. This paper presents Wanda++, a novel pruning framework that\noutperforms the state-of-the-art methods by utilizing decoder-block-level\n\\textbf{regional} gradients. Specifically, Wanda++ improves the pruning score\nwith regional gradients for the first time and proposes an efficient regional\noptimization method to minimize pruning-induced output discrepancies between\nthe dense and sparse decoder output. Notably, Wanda++ improves perplexity by up\nto 32\\% over Wanda in the language modeling task and generalizes effectively to\ndownstream tasks. Further experiments indicate our proposed method is\northogonal to sparsity-aware fine-tuning, where Wanda++ can be combined with\nLoRA fine-tuning to achieve a similar perplexity improvement as the Wanda\nmethod. The proposed method is lightweight, pruning a 7B LLaMA model in under\n10 minutes on a single NVIDIA H100 GPU.",
      "tldr_zh": "本文提出Wanda++，一种创新的剪枝框架，用于通过decoder-block-level的regional gradients优化Large Language Models (LLMs)，以实现推理加速同时最小化性能损失。Wanda++首次利用regional gradients改进剪枝分数，并引入高效的regional optimization方法，减少剪枝导致的密集和稀疏解码器输出差异。实验结果显示，该框架在语言建模任务中比Wanda方法降低多达32%的perplexity，并在下游任务中表现出良好的泛化性。此外，Wanda++与sparsity-aware fine-tuning正交，可与LoRA微调结合，并能在单块NVIDIA H100 GPU上在10分钟内剪枝7B LLaMA模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04992v2",
      "published_date": "2025-03-06 21:42:35 UTC",
      "updated_date": "2025-04-29 17:42:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:34:41.499187"
    },
    {
      "arxiv_id": "2503.04982v1",
      "title": "LVLM-Compress-Bench: Benchmarking the Broader Impact of Large Vision-Language Model Compression",
      "title_zh": "LVLM-Compress-Bench：大型视觉语言模型压缩的更广泛影响基准测试",
      "authors": [
        "Souvik Kundu",
        "Anahita Bhiwandiwalla",
        "Sungduk Yu",
        "Phillip Howard",
        "Tiep Le",
        "Sharath Nittur Sridhar",
        "David Cobbley",
        "Hao Kang",
        "Vasudev Lal"
      ],
      "abstract": "Despite recent efforts in understanding the compression impact on large\nlanguage models (LLMs) in terms of their downstream task performance and\ntrustworthiness on relatively simpler uni-modal benchmarks (for example,\nquestion answering, common sense reasoning), their detailed study on\nmulti-modal Large Vision-Language Models (LVLMs) is yet to be unveiled. Towards\nmitigating this gap, we present LVLM-Compress-Bench, a framework to first\nthoroughly study the broad impact of compression on the generative performance\nof LVLMs with multi-modal input driven tasks. In specific, we consider two\nmajor classes of compression for autoregressive models, namely KV cache and\nweight compression, for the dynamically growing intermediate cache and static\nweights, respectively.\n  We use four LVLM variants of the popular LLaVA framework to present our\nanalysis via integrating various state-of-the-art KV and weight compression\nmethods including uniform, outlier-reduced, and group quantization for the KV\ncache and weights. With this framework we demonstrate on ten different\nmulti-modal datasets with different capabilities including recognition,\nknowledge, language generation, spatial awareness, visual reasoning,\nhallucination and visual illusion identification, toxicity, stereotypes and\nbias. In specific, our framework demonstrates the compression impact on both\ngeneral and ethically critical metrics leveraging a combination of real world\nand synthetic datasets to encompass diverse societal intersectional attributes.\nExtensive experimental evaluations yield diverse and intriguing observations on\nthe behavior of LVLMs at different quantization budget of KV and weights, in\nboth maintaining and losing performance as compared to the baseline model with\nFP16 data format.\n  Code will be open-sourced at\nhttps://github.com/opengear-project/LVLM-compress-bench.",
      "tldr_zh": "该论文引入了 LVLM-Compress-Bench 框架，用于评估大型视觉语言模型 (LVLMs) 压缩对多模态任务生成性能的广泛影响，填补了现有研究主要聚焦单模态模型的空白。框架考虑了 KV cache 和 weight 压缩两种主要方法，并在 LLaVA 框架的四个变体上整合了先进技术，如均匀量化、出lier-reduced 量化和分组量化。实验在十个多模态数据集上进行，包括识别、知识生成、空间意识、视觉推理、幻觉识别、毒性和偏见等方面，结果显示压缩在不同量化预算下可能维持或降低性能，与 FP16 基线模型相比揭示了多样行为。代码将开源以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04982v1",
      "published_date": "2025-03-06 21:21:18 UTC",
      "updated_date": "2025-03-06 21:21:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:34:53.053392"
    },
    {
      "arxiv_id": "2503.04980v1",
      "title": "A Consensus Privacy Metrics Framework for Synthetic Data",
      "title_zh": "合成数据的共识隐私度量框架",
      "authors": [
        "Lisa Pilgram",
        "Fida K. Dankar",
        "Jorg Drechsler",
        "Mark Elliot",
        "Josep Domingo-Ferrer",
        "Paul Francis",
        "Murat Kantarcioglu",
        "Linglong Kong",
        "Bradley Malin",
        "Krishnamurty Muralidhar",
        "Puja Myles",
        "Fabian Prasser",
        "Jean Louis Raisaro",
        "Chao Yan",
        "Khaled El Emam"
      ],
      "abstract": "Synthetic data generation is one approach for sharing individual-level data.\nHowever, to meet legislative requirements, it is necessary to demonstrate that\nthe individuals' privacy is adequately protected. There is no consolidated\nstandard for measuring privacy in synthetic data. Through an expert panel and\nconsensus process, we developed a framework for evaluating privacy in synthetic\ndata. Our findings indicate that current similarity metrics fail to measure\nidentity disclosure, and their use is discouraged. For differentially private\nsynthetic data, a privacy budget other than close to zero was not considered\ninterpretable. There was consensus on the importance of membership and\nattribute disclosure, both of which involve inferring personal information\nabout an individual without necessarily revealing their identity. The resultant\nframework provides precise recommendations for metrics that address these types\nof disclosures effectively. Our findings further present specific opportunities\nfor future research that can help with widespread adoption of synthetic data.",
      "tldr_zh": "本研究通过专家小组和共识过程，开发了一个统一的框架，用于评估合成数据中的隐私保护，以符合立法要求。研究发现，当前相似性指标无法有效测量身份泄露，因此不推荐使用；同时强调了成员披露和属性披露的重要性，这些涉及推断个人信息而不揭示身份。该框架提供了针对这些披露类型的精确指标推荐，并为合成数据的广泛采用提出了未来研究机会。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04980v1",
      "published_date": "2025-03-06 21:19:02 UTC",
      "updated_date": "2025-03-06 21:19:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:35:03.339739"
    },
    {
      "arxiv_id": "2503.04977v1",
      "title": "Quantifying the Relevance of Youth Research Cited in the US Policy Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Miftahul Jannat Mokarrama",
        "Hamed Alhoori"
      ],
      "abstract": "In recent years, there has been a growing concern and emphasis on conducting\nresearch beyond academic or scientific research communities, benefiting society\nat large. A well-known approach to measuring the impact of research on society\nis enumerating its policy citation(s). Despite the importance of research in\ninforming policy, there is no concrete evidence to suggest the research's\nrelevance in cited policy documents. This is concerning because it may increase\nthe possibility of evidence used in policy being manipulated by individual,\nsocial, or political biases that may lead to inappropriate, fragmented, or\narchaic research evidence in policy. Therefore, it is crucial to identify the\ndegree of relevance between research articles and citing policy documents. In\nthis paper, we examined the scale of contextual relevance of youth-focused\nresearch in the referenced US policy documents using natural language\nprocessing techniques, state-of-the-art pre-trained Large Language Models\n(LLMs), and statistical analysis. Our experiments and analysis concluded that\nyouth-related research articles that get US policy citations are mostly\nrelevant to the citing policy documents.",
      "tldr_zh": "这篇论文量化了青年相关研究在US政策文档中的引用相关性，旨在评估研究对政策的实际影响并减少潜在偏见。研究者采用自然语言处理(NLP)技术、先进的Large Language Models (LLMs)以及统计分析，对被引用的青年研究文章进行上下文相关性分析。结果显示，大多数这些研究与引用的政策文档高度相关，为确保政策证据的可靠性和客观性提供了重要洞见。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "The paper was accepted and presented in IEEE BIG DATA 2024. It has 10\n  pages, 5 figures, and 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04977v1",
      "published_date": "2025-03-06 21:14:04 UTC",
      "updated_date": "2025-03-06 21:14:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:35:15.608008"
    },
    {
      "arxiv_id": "2503.04973v1",
      "title": "Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Giulio Corallo",
        "Orion Weller",
        "Fabio Petroni",
        "Paolo Papotti"
      ],
      "abstract": "Incorporating external knowledge in large language models (LLMs) enhances\ntheir utility across diverse applications, but existing methods have\ntrade-offs. Retrieval-Augmented Generation (RAG) fetches evidence via\nsimilarity search, but key information may fall outside top ranked results.\nLong-context models can process multiple documents but are computationally\nexpensive and limited by context window size. Inspired by students condensing\nstudy material for open-book exams, we propose task-aware key-value (KV) cache\ncompression, which compresses external knowledge in a zero- or few-shot setup.\nThis enables LLMs to reason efficiently over a compacted representation of all\nrelevant information. Experiments show our approach outperforms both RAG and\ntask-agnostic compression methods. On LongBench v2, it improves accuracy by up\nto 7 absolute points over RAG with a 30x compression rate, while reducing\ninference latency from 0.43s to 0.16s. A synthetic dataset highlights that RAG\nperforms well when sparse evidence suffices, whereas task-aware compression is\nsuperior for broad knowledge tasks.",
      "tldr_zh": "该论文超越传统的 Retrieval-Augmented Generation (RAG) 系统，提出了一种任务感知的 key-value (KV) 缓存压缩方法，旨在帮助大型语言模型 (LLMs) 更高效地处理外部知识进行全面推理。该方法受学生备考启发，在零样本或少样本设置下压缩相关信息，允许 LLMs 在紧凑表示上进行快速推理。实验结果显示，在 LongBench v2 上，该方法比 RAG 准确率提高多达 7 点，同时实现 30 倍压缩率并将推理延迟从 0.43 秒减至 0.16 秒；在合成数据集上，它特别适合处理需要广泛知识的任务，而 RAG 更适用于稀疏证据场景。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04973v1",
      "published_date": "2025-03-06 21:07:41 UTC",
      "updated_date": "2025-03-06 21:07:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:35:29.758146"
    },
    {
      "arxiv_id": "2503.04971v1",
      "title": "Incentivizing Multi-Tenant Split Federated Learning for Foundation Models at the Network Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Songyuan Li",
        "Jia Hu",
        "Geyong Min",
        "Haojun Huang"
      ],
      "abstract": "Foundation models (FMs) such as GPT-4 exhibit exceptional generative\ncapabilities across diverse downstream tasks through fine-tuning. Split\nFederated Learning (SFL) facilitates privacy-preserving FM fine-tuning on\nresource-constrained local devices by offloading partial FM computations to\nedge servers, enabling device-edge synergistic fine-tuning. Practical edge\nnetworks often host multiple SFL tenants to support diversified downstream\ntasks. However, existing research primarily focuses on single-tenant SFL\nscenarios, and lacks tailored incentive mechanisms for multi-tenant settings,\nwhich are essential to effectively coordinate self-interested local devices for\nparticipation in various downstream tasks, ensuring that each SFL tenant's\ndistinct FM fine-tuning requirements (e.g., FM types, performance targets, and\nfine-tuning deadlines) are met. To address this gap, we propose a novel\nPrice-Incentive Mechanism (PRINCE) that guides multiple SFL tenants to offer\nstrategic price incentives, which solicit high-quality device participation for\nefficient FM fine-tuning. Specifically, we first develop a bias-resilient\nglobal SFL model aggregation scheme to eliminate model biases caused by\nindependent device participation. We then derive a rigorous SFL convergence\nbound to evaluate the contributions of heterogeneous devices to FM performance\nimprovements, guiding the incentive strategies of SFL tenants. Furthermore, we\nmodel inter-tenant device competition as a congestion game for Stackelberg\nequilibrium (SE) analysis, deriving each SFL tenant's optimal incentive\nstrategy. Extensive simulations involving four representative SFL tenant types\n(ViT, BERT, Whisper, and LLaMA) across diverse data modalities (text, images,\nand audio) demonstrate that PRINCE accelerates FM fine-tuning by up to 3.07x\ncompared to state-of-the-art approaches, while consistently meeting fine-tuning\nperformance targets.",
      "tldr_zh": "该论文探讨了在网络边缘微调基础模型（FMs，如 GPT-4）的多租户 Split Federated Learning (SFL) 场景中，如何通过激励机制协调自利设备参与。作者提出了一种新型 Price-Incentive Mechanism (PRINCE)，引导多个 SFL 租户提供战略性价格激励，以吸引高质量设备参与，确保满足不同租户的微调需求（如 FM 类型、性能目标和截止期限）。PRINCE 包括一个消除模型偏差的全局 SFL 模型聚合方案、SFL 收敛边界评估设备贡献，以及将设备竞争建模为拥塞游戏进行 Stackelberg equilibrium (SE) 分析。实验结果显示，PRINCE 相较于现有方法可将 FM 微调速度提高高达 3.07 倍，并在多种数据模式（如文本、图像和音频）及代表性 FM（如 ViT、BERT、Whisper 和 LLaMA）上 consistently 达到性能目标。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Index Terms: Foundation models, Edge computing, Split federated\n  learning, Multi-tenant system, Incentive mechanism",
      "pdf_url": "http://arxiv.org/pdf/2503.04971v1",
      "published_date": "2025-03-06 21:06:27 UTC",
      "updated_date": "2025-03-06 21:06:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:35:41.687339"
    },
    {
      "arxiv_id": "2503.04969v1",
      "title": "Data-Efficient Learning from Human Interventions for Mobile Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenghao Peng",
        "Zhizheng Liu",
        "Bolei Zhou"
      ],
      "abstract": "Mobile robots are essential in applications such as autonomous delivery and\nhospitality services. Applying learning-based methods to address mobile robot\ntasks has gained popularity due to its robustness and generalizability.\nTraditional methods such as Imitation Learning (IL) and Reinforcement Learning\n(RL) offer adaptability but require large datasets, carefully crafted reward\nfunctions, and face sim-to-real gaps, making them challenging for efficient and\nsafe real-world deployment. We propose an online human-in-the-loop learning\nmethod PVP4Real that combines IL and RL to address these issues. PVP4Real\nenables efficient real-time policy learning from online human intervention and\ndemonstration, without reward or any pretraining, significantly improving data\nefficiency and training safety. We validate our method by training two\ndifferent robots -- a legged quadruped, and a wheeled delivery robot -- in two\nmobile robot tasks, one of which even uses raw RGBD image as observation. The\ntraining finishes within 15 minutes. Our experiments show the promising future\nof human-in-the-loop learning in addressing the data efficiency issue in\nreal-world robotic tasks. More information is available at:\nhttps://metadriverse.github.io/pvp4real/",
      "tldr_zh": "我们提出了一种名为PVP4Real的在线人类在循环学习方法，结合Imitation Learning (IL)和Reinforcement Learning (RL)，旨在解决移动机器人任务中数据需求大、奖励函数设计复杂以及模拟到真实环境差距等问题。该方法通过实时从人类干预和演示中学习策略，无需奖励函数或预训练，从而显著提高了数据效率和训练安全性。在实验中，我们在两款机器人（四足机器人和轮式交付机器人）上验证了该方法，包括使用原始RGBD图像作为观察，训练仅需15分钟，结果显示了人类在循环学习在真实世界机器人任务中的广阔前景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "ICRA 2025. Webpage: https://metadriverse.github.io/pvp4real/",
      "pdf_url": "http://arxiv.org/pdf/2503.04969v1",
      "published_date": "2025-03-06 21:02:02 UTC",
      "updated_date": "2025-03-06 21:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:35:53.608074"
    },
    {
      "arxiv_id": "2503.04966v2",
      "title": "Prediction of Frozen Region Growth in Kidney Cryoablation Intervention Using a 3D Flow-Matching Model",
      "title_zh": "翻译失败",
      "authors": [
        "Siyeop Yoon",
        "Yujin Oh",
        "Matthew Tivnan",
        "Sifan Song",
        "Pengfei Jin",
        "Sekeun Kim",
        "Hyun Jin Cho",
        "Dufan Wu",
        "Raul Uppot",
        "Quanzheng Li"
      ],
      "abstract": "This study presents a 3D flow-matching model designed to predict the\nprogression of the frozen region (iceball) during kidney cryoablation. Precise\nintraoperative guidance is critical in cryoablation to ensure complete tumor\neradication while preserving adjacent healthy tissue. However, conventional\nmethods, typically based on physics driven or diffusion based simulations, are\ncomputationally demanding and often struggle to represent complex anatomical\nstructures accurately. To address these limitations, our approach leverages\nintraoperative CT imaging to inform the model. The proposed 3D flow matching\nmodel is trained to learn a continuous deformation field that maps early-stage\nCT scans to future predictions. This transformation not only estimates the\nvolumetric expansion of the iceball but also generates corresponding\nsegmentation masks, effectively capturing spatial and morphological changes\nover time. Quantitative analysis highlights the model robustness, demonstrating\nstrong agreement between predictions and ground-truth segmentations. The model\nachieves an Intersection over Union (IoU) score of 0.61 and a Dice coefficient\nof 0.75. By integrating real time CT imaging with advanced deep learning\ntechniques, this approach has the potential to enhance intraoperative guidance\nin kidney cryoablation, improving procedural outcomes and advancing the field\nof minimally invasive surgery.",
      "tldr_zh": "这篇论文提出了一种 3D flow-matching 模型，用于预测肾脏冷冻消融（cryoablation）过程中冻结区域（iceball）的增长，以提供精确的术中指导，确保肿瘤完全清除同时保护健康组织。模型通过利用术中 CT 成像，训练一个连续变形场（continuous deformation field）来映射早期扫描到未来预测，并生成对应的分割掩码（segmentation masks），从而捕捉空间和形态变化。实验结果显示，该模型表现出色，与真实分割的契合度高，达到 IoU 0.61 和 Dice coefficient 0.75。通过整合实时 CT 成像和深度学习技术，该方法有望提升手术效果并推进微创手术领域的发展。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "MICCAI 2025 submitted version (author list included)",
      "pdf_url": "http://arxiv.org/pdf/2503.04966v2",
      "published_date": "2025-03-06 20:52:58 UTC",
      "updated_date": "2025-03-11 15:21:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:36:05.533804"
    },
    {
      "arxiv_id": "2503.04963v1",
      "title": "Energy-Latency Attacks: A New Adversarial Threat to Deep Learning",
      "title_zh": "能量-延迟攻击：深度学习的一种新对抗威胁",
      "authors": [
        "Hanene F. Z. Brachemi Meftah",
        "Wassim Hamidouche",
        "Sid Ahmed Fezza",
        "Olivier Deforges"
      ],
      "abstract": "The growing computational demand for deep neural networks ( DNNs) has raised\nconcerns about their energy consumption and carbon footprint, particularly as\nthe size and complexity of the models continue to increase. To address these\nchallenges, energy-efficient hardware and custom accelerators have become\nessential. Additionally, adaptable DNN s are being developed to dynamically\nbalance performance and efficiency. The use of these strategies became more\ncommon to enable sustainable AI deployment. However, these efficiency-focused\ndesigns may also introduce vulnerabilities, as attackers can potentially\nexploit them to increase latency and energy usage by triggering their\nworst-case-performance scenarios. This new type of attack, called\nenergy-latency attacks, has recently gained significant research attention,\nfocusing on the vulnerability of DNN s to this emerging attack paradigm, which\ncan trigger denial-of-service ( DoS) attacks. This paper provides a\ncomprehensive overview of current research on energy-latency attacks,\ncategorizing them using the established taxonomy for traditional adversarial\nattacks. We explore different metrics used to measure the success of these\nattacks and provide an analysis and comparison of existing attack strategies.\nWe also analyze existing defense mechanisms and highlight current challenges\nand potential areas for future research in this developing field. The GitHub\npage for this work can be accessed at\nhttps://github.com/hbrachemi/Survey_energy_attacks/",
      "tldr_zh": "本论文探讨了深度神经网络(DNNs)日益增长的能源消耗问题，并引入了一种新威胁：能源-延迟攻击，这种攻击通过利用效率优化设计来触发DNNs的最坏性能场景，从而增加延迟和能源使用，可能导致拒绝服务(DoS)攻击。论文对现有研究进行全面概述，包括使用传统对抗攻击分类来归类这些攻击、分析成功度量标准、比较攻击策略，以及评估现有防御机制。最终，论文指出了当前挑战和未来研究方向，如进一步提升DNNs的安全性和可持续性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04963v1",
      "published_date": "2025-03-06 20:50:58 UTC",
      "updated_date": "2025-03-06 20:50:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:36:16.208050"
    },
    {
      "arxiv_id": "2503.04957v1",
      "title": "SafeArena: Evaluating the Safety of Autonomous Web Agents",
      "title_zh": "SafeArena：评估自治网络代理",
      "authors": [
        "Ada Defne Tur",
        "Nicholas Meade",
        "Xing Han Lù",
        "Alejandra Zambrano",
        "Arkil Patel",
        "Esin Durmus",
        "Spandana Gella",
        "Karolina Stańczak",
        "Siva Reddy"
      ],
      "abstract": "LLM-based agents are becoming increasingly proficient at solving web-based\ntasks. With this capability comes a greater risk of misuse for malicious\npurposes, such as posting misinformation in an online forum or selling illicit\nsubstances on a website. To evaluate these risks, we propose SafeArena, the\nfirst benchmark to focus on the deliberate misuse of web agents. SafeArena\ncomprises 250 safe and 250 harmful tasks across four websites. We classify the\nharmful tasks into five harm categories -- misinformation, illegal activity,\nharassment, cybercrime, and social bias, designed to assess realistic misuses\nof web agents. We evaluate leading LLM-based web agents, including GPT-4o,\nClaude-3.5 Sonnet, Qwen-2-VL 72B, and Llama-3.2 90B, on our benchmark. To\nsystematically assess their susceptibility to harmful tasks, we introduce the\nAgent Risk Assessment framework that categorizes agent behavior across four\nrisk levels. We find agents are surprisingly compliant with malicious requests,\nwith GPT-4o and Qwen-2 completing 34.7% and 27.3% of harmful requests,\nrespectively. Our findings highlight the urgent need for safety alignment\nprocedures for web agents. Our benchmark is available here:\nhttps://safearena.github.io",
      "tldr_zh": "该研究引入了 SafeArena，这是一个专注于评估自主网络代理潜在恶意误用的首个基准，包含250个安全任务和250个有害任务，分布在四个网站上，并将有害任务分类为 misinformation（错误信息）、illegal activity（非法活动）、harassment（骚扰）、cybercrime（网络犯罪）和 social bias（社会偏见）。他们开发了 Agent Risk Assessment 框架来系统评估代理行为的风险级别，并测试了领先的LLM模型，如GPT-4o和Claude-3.5 Sonnet，结果显示GPT-4o完成了34.7%的有害请求，突显代理对恶意指令的惊人顺从性。论文强调了为网络代理实施安全对齐程序的紧迫需求，并公开了基准资源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04957v1",
      "published_date": "2025-03-06 20:43:14 UTC",
      "updated_date": "2025-03-06 20:43:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:36:28.443239"
    },
    {
      "arxiv_id": "2503.04952v1",
      "title": "INTENT: Trajectory Prediction Framework with Intention-Guided Contrastive Clustering",
      "title_zh": "INTENT：基于意图引导对比聚类的轨迹预测框架",
      "authors": [
        "Yihong Tang",
        "Wei Ma"
      ],
      "abstract": "Accurate trajectory prediction of road agents (e.g., pedestrians, vehicles)\nis an essential prerequisite for various intelligent systems applications, such\nas autonomous driving and robotic navigation. Recent research highlights the\nimportance of environmental contexts (e.g., maps) and the \"multi-modality\" of\ntrajectories, leading to increasingly complex model structures. However,\nreal-world deployments require lightweight models that can quickly migrate and\nadapt to new environments. Additionally, the core motivations of road agents,\nreferred to as their intentions, deserves further exploration. In this study,\nwe advocate that understanding and reasoning road agents' intention plays a key\nrole in trajectory prediction tasks, and the main challenge is that the concept\nof intention is fuzzy and abstract. To this end, we present INTENT, an\nefficient intention-guided trajectory prediction model that relies solely on\ninformation contained in the road agent's trajectory. Our model distinguishes\nitself from existing models in several key aspects: (i) We explicitly model\nroad agents' intentions through contrastive clustering, accommodating the\nfuzziness and abstraction of human intention in their trajectories. (ii) The\nproposed INTENT is based solely on multi-layer perceptrons (MLPs), resulting in\nreduced training and inference time, making it very efficient and more suitable\nfor real-world deployment. (iii) By leveraging estimated intentions and an\ninnovative algorithm for transforming trajectory observations, we obtain more\nrobust trajectory representations that lead to superior prediction accuracy.\nExtensive experiments on real-world trajectory datasets for pedestrians and\nautonomous vehicles demonstrate the effectiveness and efficiency of INTENT.",
      "tldr_zh": "该论文提出INTENT框架，这是一个基于意图引导对比聚类（Intention-Guided Contrastive Clustering）的轨迹预测模型，旨在提升道路代理（如行人、车辆）的预测准确性。INTENT模型通过显式建模代理意图，利用对比聚类处理意图的模糊性和抽象性，同时仅依赖多层感知器（MLPs）构建，实现高效的训练和推理，适合实际部署。实验结果显示，该框架在真实轨迹数据集上显著提高了预测精度，并通过意图估计和轨迹观察转换算法获得更稳健的表示，为自主驾驶和机器人导航等应用提供了高效解决方案。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04952v1",
      "published_date": "2025-03-06 20:31:11 UTC",
      "updated_date": "2025-03-06 20:31:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:36:39.502006"
    },
    {
      "arxiv_id": "2503.04946v1",
      "title": "Federated Inverse Probability Treatment Weighting for Individual Treatment Effect Estimation",
      "title_zh": "联邦逆概率治疗加权用于个体治疗效果估计",
      "authors": [
        "Changchang Yin",
        "Hong-You Chen",
        "Wei-Lun Chao",
        "Ping Zhang"
      ],
      "abstract": "Individual treatment effect (ITE) estimation is to evaluate the causal\neffects of treatment strategies on some important outcomes, which is a crucial\nproblem in healthcare. Most existing ITE estimation methods are designed for\ncentralized settings. However, in real-world clinical scenarios, the raw data\nare usually not shareable among hospitals due to the potential privacy and\nsecurity risks, which makes the methods not applicable. In this work, we study\nthe ITE estimation task in a federated setting, which allows us to harness the\ndecentralized data from multiple hospitals. Due to the unavoidable confounding\nbias in the collected data, a model directly learned from it would be\ninaccurate. One well-known solution is Inverse Probability Treatment Weighting\n(IPTW), which uses the conditional probability of treatment given the\ncovariates to re-weight each training example. Applying IPTW in a federated\nsetting, however, is non-trivial. We found that even with a well-estimated\nconditional probability, the local model training step using each hospital's\ndata alone would still suffer from confounding bias. To address this, we\npropose FED-IPTW, a novel algorithm to extend IPTW into a federated setting\nthat enforces both global (over all the data) and local (within each hospital)\ndecorrelation between covariates and treatments. We validated our approach on\nthe task of comparing the treatment effects of mechanical ventilation on\nimproving survival probability for patients with breadth difficulties in the\nintensive care unit (ICU). We conducted experiments on both synthetic and\nreal-world eICU datasets and the results show that FED-IPTW outperform\nstate-of-the-art methods on all the metrics on factual prediction and ITE\nestimation tasks, paving the way for personalized treatment strategy design in\nmechanical ventilation usage.",
      "tldr_zh": "该论文针对个体治疗效果（ITE）估计问题，提出了一种适用于联邦设置的算法，以解决医疗数据隐私限制下多医院数据无法共享的挑战。作者扩展了Inverse Probability Treatment Weighting (IPTW)方法，开发出FED-IPTW算法，通过强制全局和本地层面（over all data and within each hospital）协变量和治疗之间的去相关（decorrelation），有效缓解混杂偏差。实验在合成和真实eICU数据集上验证了该方法在事实预测和ITE估计任务上的表现，优于现有技术，并为个性化治疗策略设计（如机械通气对ICU患者的影响）提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "K.3.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04946v1",
      "published_date": "2025-03-06 20:24:34 UTC",
      "updated_date": "2025-03-06 20:24:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:36:51.807861"
    },
    {
      "arxiv_id": "2503.04945v1",
      "title": "Collaborative Evaluation of Deepfake Text with Deliberation-Enhancing Dialogue Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jooyoung Lee",
        "Xiaochen Zhu",
        "Georgi Karadzhov",
        "Tom Stafford",
        "Andreas Vlachos",
        "Dongwon Lee"
      ],
      "abstract": "The proliferation of generative models has presented significant challenges\nin distinguishing authentic human-authored content from deepfake content.\nCollaborative human efforts, augmented by AI tools, present a promising\nsolution. In this study, we explore the potential of DeepFakeDeLiBot, a\ndeliberation-enhancing chatbot, to support groups in detecting deepfake text.\nOur findings reveal that group-based problem-solving significantly improves the\naccuracy of identifying machine-generated paragraphs compared to individual\nefforts. While engagement with DeepFakeDeLiBot does not yield substantial\nperformance gains overall, it enhances group dynamics by fostering greater\nparticipant engagement, consensus building, and the frequency and diversity of\nreasoning-based utterances. Additionally, participants with higher perceived\neffectiveness of group collaboration exhibited performance benefits from\nDeepFakeDeLiBot. These findings underscore the potential of deliberative\nchatbots in fostering interactive and productive group dynamics while ensuring\naccuracy in collaborative deepfake text detection. \\textit{Dataset and source\ncode used in this study will be made publicly available upon acceptance of the\nmanuscript.",
      "tldr_zh": "本研究探讨了生成模型泛滥导致的深度伪造文本（deepfake text）检测挑战，并引入DeepFakeDeLiBot，一种促进审议的对话系统，以增强群体协作。结果显示，群体协作相比个人努力，能显著提高识别机器生成段落的准确性。虽DeepFakeDeLiBot整体未显著提升性能，但它改善了群体动态，包括增加参与度、共识构建以及推理表达的频率和多样性。研究进一步发现，那些认为群体协作有效的参与者从DeepFakeDeLiBot中获益，并强调此类审议聊天系统在促进互动生产力和准确协作检测方面的潜力。数据集和源代码将于稿件接受后公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "15",
      "pdf_url": "http://arxiv.org/pdf/2503.04945v1",
      "published_date": "2025-03-06 20:19:38 UTC",
      "updated_date": "2025-03-06 20:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:37:03.755980"
    },
    {
      "arxiv_id": "2503.04940v1",
      "title": "VQEL: Enabling Self-Developed Symbolic Language in Agents through Vector Quantization in Emergent Language Games",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Mahdi Samiei Paqaleh",
        "Mahdieh Soleymani Baghshah"
      ],
      "abstract": "In the field of emergent language, efforts have traditionally focused on\ndeveloping communication protocols through interactions between agents in\nreferential games. However, the aspect of internal language learning, where\nlanguage serves not only as a communicative tool with others but also as a\nmeans for individual thinking, self-reflection, and problem-solving remains\nunderexplored. Developing a language through self-play, without another agent's\ninvolvement, poses a unique challenge. It requires an agent to craft symbolic\nrepresentations and train them using direct gradient methods. The challenge\nhere is that if an agent attempts to learn symbolic representations through\nself-play using conventional modeling and techniques such as REINFORCE, the\nsolution will offer no advantage over previous multi-agent approaches. We\nintroduce VQEL, a novel method that incorporates Vector Quantization into the\nagents' architecture, enabling them to autonomously invent and develop discrete\nsymbolic representations in a self-play referential game. Following the\nself-play phase, agents can enhance their language through reinforcement\nlearning and interactions with other agents in the mutual-play phase. Our\nexperiments across various datasets demonstrate that VQEL not only outperforms\nthe traditional REINFORCE method but also benefits from improved control and\nreduced susceptibility to collapse, thanks to the incorporation of vector\nquantization.",
      "tldr_zh": "本研究探讨了紧急语言（emergent language）领域的内部语言学习问题，强调语言不仅是代理间沟通工具，还可用于个体思考和问题解决。论文提出 VQEL 方法，通过在代理架构中整合 Vector Quantization，使代理能够在自玩（self-play）参考游戏中自主开发离散符号表示，并随后通过强化学习和 mutual-play 与其他代理互动来增强语言。与传统 REINFORCE 方法相比，实验在多种数据集上证明 VQEL 表现出色，提供更好的控制并显著降低崩溃风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04940v1",
      "published_date": "2025-03-06 20:15:51 UTC",
      "updated_date": "2025-03-06 20:15:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:37:18.027660"
    },
    {
      "arxiv_id": "2503.04933v1",
      "title": "Learning-based GNSS Uncertainty Quantification using Continuous-Time Factor Graph Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Haoming Zhang"
      ],
      "abstract": "This short paper presents research findings on two learning-based methods for\nquantifying measurement uncertainties in global navigation satellite systems\n(GNSS). We investigate two learning strategies: offline learning for outlier\nprediction and online learning for noise distribution approximation,\nspecifically applied to GNSS pseudorange observations. To develop and evaluate\nthese learning methods, we introduce a novel multisensor state estimator that\naccurately and robustly estimates trajectory from multiple sensor inputs,\ncritical for deriving GNSS measurement residuals used to train the uncertainty\nmodels. We validate the proposed learning-based models using real-world sensor\ndata collected in diverse urban environments. Experimental results demonstrate\nthat both models effectively handle GNSS outliers and improve state estimation\nperformance. Furthermore, we provide insightful discussions to motivate future\nresearch toward developing a federated framework for robust vehicle\nlocalization in challenging environments.",
      "tldr_zh": "这篇论文提出两种基于学习的全球导航卫星系统(GNSS)测量不确定性量化方法：离线学习用于预测异常，以及在线学习用于近似噪声分布，具体应用于GNSS pseudorange观测。研究引入了一个新的多传感器状态估计器，利用连续时间因子图优化从多种传感器输入中准确估计轨迹，并生成GNSS测量残差来训练不确定性模型。实验结果显示，在多样化城市环境中，这些模型有效处理GNSS异常并提升状态估计性能；论文还讨论了未来开发联邦框架以实现更鲁棒车辆定位的研究方向。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "This extended abstract has been accepted to the 1st German Robotic\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2503.04933v1",
      "published_date": "2025-03-06 20:04:36 UTC",
      "updated_date": "2025-03-06 20:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:37:31.613221"
    },
    {
      "arxiv_id": "2503.04931v1",
      "title": "Curiosity-Driven Imagination: Discovering Plan Operators and Learning Associated Policies for Open-World Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Pierrick Lorang",
        "Hong Lu",
        "Matthias Scheutz"
      ],
      "abstract": "Adapting quickly to dynamic, uncertain environments-often called \"open\nworlds\"-remains a major challenge in robotics. Traditional Task and Motion\nPlanning (TAMP) approaches struggle to cope with unforeseen changes, are\ndata-inefficient when adapting, and do not leverage world models during\nlearning. We address this issue with a hybrid planning and learning system that\nintegrates two models: a low level neural network based model that learns\nstochastic transitions and drives exploration via an Intrinsic Curiosity Module\n(ICM), and a high level symbolic planning model that captures abstract\ntransitions using operators, enabling the agent to plan in an \"imaginary\" space\nand generate reward machines. Our evaluation in a robotic manipulation domain\nwith sequential novelty injections demonstrates that our approach converges\nfaster and outperforms state-of-the-art hybrid methods.",
      "tldr_zh": "该研究针对机器人适应动态不确定环境（开放世界）的挑战，提出了一种基于好奇心驱动的混合规划和学习系统，以解决传统 Task and Motion Planning (TAMP) 方法的数据效率低和适应性差的问题。该系统整合了低层神经网络模型（通过 Intrinsic Curiosity Module (ICM) 驱动探索和学习随机转移）和高层符号规划模型（使用操作符捕获抽象转移，并在“想象”空间中规划并生成奖励机器）。实验结果显示，在机器人操作领域中注入顺序新奇性的场景下，该方法比现有混合方法收敛更快并表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures. Accepted at ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04931v1",
      "published_date": "2025-03-06 20:02:26 UTC",
      "updated_date": "2025-03-06 20:02:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:37:41.844183"
    },
    {
      "arxiv_id": "2503.04930v1",
      "title": "HILGEN: Hierarchically-Informed Data Generation for Biomedical NER Using Knowledgebases and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Ge",
        "Yuting Guo",
        "Sudeshna Das",
        "Swati Rajwal",
        "Selen Bozkurt",
        "Abeed Sarker"
      ],
      "abstract": "We present HILGEN, a Hierarchically-Informed Data Generation approach that\ncombines domain knowledge from the Unified Medical Language System (UMLS) with\nsynthetic data generated by large language models (LLMs), specifically GPT-3.5.\nOur approach leverages UMLS's hierarchical structure to expand training data\nwith related concepts, while incorporating contextual information from LLMs\nthrough targeted prompts aimed at automatically generating synthetic examples\nfor sparsely occurring named entities. The performance of the HILGEN approach\nwas evaluated across four biomedical NER datasets (MIMIC III, BC5CDR,\nNCBI-Disease, and Med-Mentions) using BERT-Large and DANN (Data Augmentation\nwith Nearest Neighbor Classifier) models, applying various data generation\nstrategies, including UMLS, GPT-3.5, and their best ensemble. For the\nBERT-Large model, incorporating UMLS led to an average F1 score improvement of\n40.36%, while using GPT-3.5 resulted in a comparable average increase of\n40.52%. The Best-Ensemble approach using BERT-Large achieved the highest\nimprovement, with an average increase of 42.29%. DANN model's F1 score improved\nby 22.74% on average using the UMLS-only approach. The GPT-3.5-based method\nresulted in a 21.53% increase, and the Best-Ensemble DANN model showed a more\nnotable improvement, with an average increase of 25.03%. Our proposed HILGEN\napproach improves NER performance in few-shot settings without requiring\nadditional manually annotated data. Our experiments demonstrate that an\neffective strategy for optimizing biomedical NER is to combine biomedical\nknowledge curated in the past, such as the UMLS, and generative LLMs to create\nsynthetic training instances. Our future research will focus on exploring\nadditional innovative synthetic data generation strategies for further\nimproving NER performance.",
      "tldr_zh": "本研究提出HILGEN，一种基于层次结构的合成数据生成方法，结合UMLS知识库的领域信息和GPT-3.5生成模型，通过扩展相关概念和针对性提示创建合成样本，以提升生物医学命名实体识别(NER)的性能。实验在MIMIC III、BC5CDR、NCBI-Disease和Med-Mentions四个数据集上评估，使用BERT-Large和DANN模型，结果显示HILGEN显著提高了F1分数，BERT-Large的Best-Ensemble策略平均提升42.29%，DANN模型的Best-Ensemble提升25.03%。该方法在少样本场景下无需额外手动标注数据即可优化NER表现，证明了整合传统知识库和生成式LLMs的有效性，并为未来探索更多合成数据策略提供了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04930v1",
      "published_date": "2025-03-06 20:02:19 UTC",
      "updated_date": "2025-03-06 20:02:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:37:54.833093"
    },
    {
      "arxiv_id": "2503.04725v1",
      "title": "L$^2$M: Mutual Information Scaling Law for Long-Context Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuo Chen",
        "Oriol Mayné i Comas",
        "Zhuotao Jin",
        "Di Luo",
        "Marin Soljačić"
      ],
      "abstract": "We rigorously establish a bipartite mutual information scaling law in natural\nlanguage that governs long-range dependencies. This scaling law, which we show\nis distinct from and scales independently of the conventional two-point mutual\ninformation, is the key to understanding long-context language modeling. Using\nthis scaling law, we formulate the Long-context Language Modeling (L$^2$M)\ncondition, which relates a model's capacity for effective long context length\nmodeling to the scaling of its latent state size for storing past information.\nOur results are validated through experiments on both transformers and state\nspace models. This work establishes a theoretical foundation that guides the\ndevelopment of large language models toward longer context lengths.",
      "tldr_zh": "该论文建立了自然语言中长程依赖关系的双部互信息缩放定律，该定律独立于传统的两点互信息，并为理解长上下文语言建模提供了关键框架。论文据此提出 Long-Context Language Modeling (L$^2$M) 条件，将模型的有效长上下文长度与潜变量状态大小的缩放关联起来，从而指导模型存储过去信息的能力。实验在 transformers 和 state space models 上验证了这些结果，为开发支持更长上下文的大型语言模型奠定了理论基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT",
        "physics.data-an"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 12 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.04725v1",
      "published_date": "2025-03-06 18:59:48 UTC",
      "updated_date": "2025-03-06 18:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:38:06.316180"
    },
    {
      "arxiv_id": "2503.04723v2",
      "title": "Shifting Long-Context LLMs Research from Input to Output",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Wu",
        "Yushi Bai",
        "Zhiqing Hu",
        "Shangqing Tu",
        "Ming Shan Hee",
        "Juanzi Li",
        "Roy Ka-Wei Lee"
      ],
      "abstract": "Recent advancements in long-context Large Language Models (LLMs) have\nprimarily concentrated on processing extended input contexts, resulting in\nsignificant strides in long-context comprehension. However, the equally\ncritical aspect of generating long-form outputs has received comparatively less\nattention. This paper advocates for a paradigm shift in NLP research toward\naddressing the challenges of long-output generation. Tasks such as novel\nwriting, long-term planning, and complex reasoning require models to understand\nextensive contexts and produce coherent, contextually rich, and logically\nconsistent extended text. These demands highlight a critical gap in current LLM\ncapabilities. We underscore the importance of this under-explored domain and\ncall for focused efforts to develop foundational LLMs tailored for generating\nhigh-quality, long-form outputs, which hold immense potential for real-world\napplications.",
      "tldr_zh": "这篇论文主张将长上下文大语言模型（LLMs）研究从处理长输入转向关注长输出生成，强调当前研究在理解扩展上下文方面取得了进展，但忽略了生成高质量长文本的挑战。论文指出，任务如小说写作、长期规划和复杂推理需要模型产生连贯、上下文丰富且逻辑一致的输出，这暴露了现有LLMs的显著能力缺口。作者呼吁NLP社区加大努力，开发专为长输出优化的基础LLMs，以实现其在实际应用中的巨大潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.04723v2",
      "published_date": "2025-03-06 18:59:37 UTC",
      "updated_date": "2025-03-07 03:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:38:17.588197"
    },
    {
      "arxiv_id": "2503.04722v1",
      "title": "Enough Coin Flips Can Make LLMs Act Bayesian",
      "title_zh": "翻译失败",
      "authors": [
        "Ritwik Gupta",
        "Rodolfo Corona",
        "Jiaxin Ge",
        "Eric Wang",
        "Dan Klein",
        "Trevor Darrell",
        "David M. Chan"
      ],
      "abstract": "Large language models (LLMs) exhibit the ability to generalize given few-shot\nexamples in their input prompt, an emergent capability known as in-context\nlearning (ICL). We investigate whether LLMs utilize ICL to perform structured\nreasoning in ways that are consistent with a Bayesian framework or rely on\npattern matching. Using a controlled setting of biased coin flips, we find\nthat: (1) LLMs often possess biased priors, causing initial divergence in\nzero-shot settings, (2) in-context evidence outweighs explicit bias\ninstructions, (3) LLMs broadly follow Bayesian posterior updates, with\ndeviations primarily due to miscalibrated priors rather than flawed updates,\nand (4) attention magnitude has negligible effect on Bayesian inference. With\nsufficient demonstrations of biased coin flips via ICL, LLMs update their\npriors in a Bayesian manner.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否通过少样本学习（ICL）进行与贝叶斯框架一致的结构化推理，而非单纯模式匹配。研究采用偏置硬币翻转的控制实验，发现LLMs 通常存在偏置先验，导致零样本设置下的初始偏差，但ICL 证据能优先于显式指令，且模型总体遵循贝叶斯后验更新，主要问题在于先验校准不当，而非更新机制缺陷。结果显示，提供足够ICL 演示后，LLMs 可以以贝叶斯方式更新先验，且注意力机制对这一推理影响微不足道。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04722v1",
      "published_date": "2025-03-06 18:59:23 UTC",
      "updated_date": "2025-03-06 18:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:38:30.687887"
    },
    {
      "arxiv_id": "2503.04715v5",
      "title": "Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining",
      "title_zh": "可预测规模：第一部分——大型语言模型",
      "authors": [
        "Houyi Li",
        "Wenzhen Zheng",
        "Qiufeng Wang",
        "Hanshan Zhang",
        "Zili Wang",
        "Shijie Xuyang",
        "Yuantao Fan",
        "Shuigeng Zhou",
        "Xiangyu Zhang",
        "Daxin Jiang"
      ],
      "abstract": "The impressive capabilities of Large Language Models (LLMs) across diverse\ntasks are now well-established, yet their effective deployment necessitates\ncareful hyperparameter optimization. Through extensive empirical studies\ninvolving grid searches across diverse configurations, we discover universal\nscaling laws governing these hyperparameters: optimal learning rate follows a\npower-law relationship with both model parameters and data sizes, while optimal\nbatch size scales primarily with data sizes. Our analysis reveals a convex\noptimization landscape for hyperparameters under fixed models and data size\nconditions. This convexity implies an optimal hyperparameter plateau. We\ncontribute a universal, plug-and-play optimal hyperparameter tool for the\ncommunity. Its estimated values on the test set are merely 0.09% away from the\nglobally optimal LLM performance found via an exhaustive search. These laws\ndemonstrate remarkable robustness across variations in model sparsity, training\ndata distribution, and model shape. To our best known, this is the first work\nthat unifies different model shapes and structures, such as Mixture-of-Experts\nmodels and dense transformers, as well as establishes optimal hyperparameter\nscaling laws across diverse data distributions. This exhaustive optimization\nprocess demands substantial computational resources, utilizing nearly one\nmillion NVIDIA H800 GPU hours to train 3,700 LLMs of varying sizes and\nhyperparameters from scratch and consuming approximately 100 trillion tokens in\ntotal. To facilitate reproducibility and further research, we will\nprogressively release all loss measurements and model checkpoints through our\ndesignated repository https://step-law.github.io/",
      "tldr_zh": "本研究通过广泛的经验研究，发现了大语言模型 (LLMs) 预训练中的超参数缩放定律：最优学习率与模型参数和数据大小呈幂律关系，而最优批量大小主要随数据大小线性增长。分析显示，在固定模型和数据规模下，超参数优化景观为凸形，从而存在一个最优超参数平台。研究贡献了一个通用即插即用的最优超参数工具，其在测试集上的估计值仅比全局最优性能差 0.09%，并证明这些定律在模型稀疏度、数据分布和形状（如 Mixture-of-Experts 模型和密集变压器）上具有显著鲁棒性。该工作首次统一不同模型结构和数据分布的最优超参数缩放定律，并通过近一百万 NVIDIA H800 GPU 小时的计算资源支持实验结果的再现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.04715v5",
      "published_date": "2025-03-06 18:58:29 UTC",
      "updated_date": "2025-05-21 10:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:38:44.148854"
    },
    {
      "arxiv_id": "2503.04713v1",
      "title": "Scaling Rich Style-Prompted Text-to-Speech Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Anuj Diwan",
        "Zhisheng Zheng",
        "David Harwath",
        "Eunsol Choi"
      ],
      "abstract": "We introduce Paralinguistic Speech Captions (ParaSpeechCaps), a large-scale\ndataset that annotates speech utterances with rich style captions. While rich\nabstract tags (e.g. guttural, nasal, pained) have been explored in small-scale\nhuman-annotated datasets, existing large-scale datasets only cover basic tags\n(e.g. low-pitched, slow, loud). We combine off-the-shelf text and speech\nembedders, classifiers and an audio language model to automatically scale rich\ntag annotations for the first time. ParaSpeechCaps covers a total of 59 style\ntags, including both speaker-level intrinsic tags and utterance-level\nsituational tags. It consists of 342 hours of human-labelled data (PSC-Base)\nand 2427 hours of automatically annotated data (PSC-Scaled). We finetune\nParler-TTS, an open-source style-prompted TTS model, on ParaSpeechCaps, and\nachieve improved style consistency (+7.9% Consistency MOS) and speech quality\n(+15.5% Naturalness MOS) over the best performing baseline that combines\nexisting rich style tag datasets. We ablate several of our dataset design\nchoices to lay the foundation for future work in this space. Our dataset,\nmodels and code are released at https://github.com/ajd12342/paraspeechcaps .",
      "tldr_zh": "本研究引入了ParaSpeechCaps数据集，该数据集标注了语音片段的丰富风格标签（共59个，包括说话者级别的内在标签和话语级别的情境标签），涵盖342小时人类标注数据（PSC-Base）和2427小时自动标注数据（PSC-Scaled）。研究者利用现成的文本和语音嵌入器、分类器以及音频语言模型，首次实现了丰富标签的自动扩展，以解决现有数据集仅覆盖基本标签（如低音调、慢速）的局限性。在Parler-TTS模型上微调后，该数据集显著提升了风格一致性（+7.9% Consistency MOS）和语音质量（+15.5% Naturalness MOS），优于基线模型。该数据集、模型和代码已开源，为文本到语音（TTS）领域的未来研究奠定基础。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04713v1",
      "published_date": "2025-03-06 18:57:40 UTC",
      "updated_date": "2025-03-06 18:57:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:38:55.993397"
    },
    {
      "arxiv_id": "2503.04710v1",
      "title": "Self-Supervised Models for Phoneme Recognition: Applications in Children's Speech for Reading Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Block Medin",
        "Thomas Pellegrini",
        "Lucile Gelin"
      ],
      "abstract": "Child speech recognition is still an underdeveloped area of research due to\nthe lack of data (especially on non-English languages) and the specific\ndifficulties of this task. Having explored various architectures for child\nspeech recognition in previous work, in this article we tackle recent\nself-supervised models. We first compare wav2vec 2.0, HuBERT and WavLM models\nadapted to phoneme recognition in French child speech, and continue our\nexperiments with the best of them, WavLM base+. We then further adapt it by\nunfreezing its transformer blocks during fine-tuning on child speech, which\ngreatly improves its performance and makes it significantly outperform our base\nmodel, a Transformer+CTC. Finally, we study in detail the behaviour of these\ntwo models under the real conditions of our application, and show that WavLM\nbase+ is more robust to various reading tasks and noise levels. Index Terms:\nspeech recognition, child speech, self-supervised learning",
      "tldr_zh": "本研究探讨了自监督模型在儿童语音识别中的应用，针对数据不足和任务复杂性等问题，比较了 wav2vec 2.0、HuBERT 和 WavLM 模型在法语儿童语音音素识别上的性能。研究者选择了 WavLM base+ 作为最佳模型，并通过在微调过程中解冻其 Transformer 块，大幅提升了其识别准确率，使其显著优于基础模型 Transformer+CTC。最终实验显示，WavLM base+ 在不同阅读任务和噪声水平下的鲁棒性更强，为儿童语音识别和阅读学习应用提供了更可靠的解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "This paper was originally published in the Proceedings of Interspeech\n  2024. DOI: 10.21437/Interspeech.2024-1095",
      "pdf_url": "http://arxiv.org/pdf/2503.04710v1",
      "published_date": "2025-03-06 18:57:16 UTC",
      "updated_date": "2025-03-06 18:57:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:39:19.760027"
    },
    {
      "arxiv_id": "2503.04704v2",
      "title": "Universality of Layer-Level Entropy-Weighted Quantization Beyond Model Architecture and Size",
      "title_zh": "超越模型架构和大小的层级熵加权量化普遍性",
      "authors": [
        "Alireza Behtash",
        "Marijan Fofonjka",
        "Ethan Baird",
        "Tyler Mauer",
        "Hossein Moghimifam",
        "David Stout",
        "Joel Dennison"
      ],
      "abstract": "We present a novel approach to selective model quantization that transcends\nthe limitations of architecture-specific and size-dependent compression methods\nfor Large Language Models (LLMs) using Entropy-Weighted Quantization (EWQ). By\nanalyzing the entropy distribution across transformer blocks, EWQ determines\nwhich blocks can be safely quantized without causing significant performance\ndegradation, independent of model architecture or size. Our method outperforms\nuniform quantization approaches, maintaining Massive Multitask Language\nUnderstanding (MMLU) accuracy scores within 0.5% of unquantized models while\nreducing memory usage by up to 18%. We demonstrate the effectiveness of EWQ\nacross multiple architectures -- from 1.6B to 70B parameters -- and showcase\nconsistent improvements in the quality-compression trade-off regardless of\nmodel scale or architectural design. A surprising finding of EWQ is its ability\nto reduce perplexity compared to unquantized models, suggesting the presence of\nbeneficial regularization through selective precision reduction. This\nimprovement holds across different model families, indicating a fundamental\nrelationship between layer-level entropy and optimal precision requirements.\nAdditionally, we introduce FastEWQ, a rapid method for entropy distribution\nanalysis that eliminates the need for loading model weights. This technique\nleverages universal characteristics of entropy distribution that persist across\nvarious architectures and scales, enabling near-instantaneous quantization\ndecisions while maintaining 80% classification accuracy with full entropy\nanalysis. Our results demonstrate that effective quantization strategies can be\ndeveloped independently of specific architectural choices or model sizes,\nopening new possibilities for efficient LLM deployment.",
      "tldr_zh": "本研究提出了一种名为 Entropy-Weighted Quantization (EWQ) 的新型选择性模型量化方法，能够超越模型架构和大小的限制，通过分析 transformer 块的熵分布，安全地量化关键层级而不会显著影响性能。EWQ 在多种架构的 Large Language Models (LLMs) 上表现出色，与未量化模型相比，MMLU 准确率仅下降 0.5%，同时减少内存使用高达 18%，并意外地降低了 perplexity，表明选择性精度减少具有有益的正则化效果。研究还引入了 FastEWQ，一种无需加载模型权重的快速熵分析技术，能保持 80% 的分类准确率，并证明有效的量化策略可适用于从 1.6B 到 70B 参数的模型，促进 LLM 的高效部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 7 figures, 14 tables; Fixed some types, added some\n  clarifications and improvements",
      "pdf_url": "http://arxiv.org/pdf/2503.04704v2",
      "published_date": "2025-03-06 18:54:32 UTC",
      "updated_date": "2025-03-07 15:12:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:39:18.277083"
    },
    {
      "arxiv_id": "2503.04697v1",
      "title": "L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning",
      "title_zh": "L1：通过强化学习控制推理模型的思考时长",
      "authors": [
        "Pranjal Aggarwal",
        "Sean Welleck"
      ],
      "abstract": "Reasoning language models have shown an uncanny ability to improve\nperformance at test-time by ``thinking longer''-that is, by generating longer\nchain-of-thought sequences and hence using more compute. However, the length of\ntheir chain-of-thought reasoning is not controllable, making it impossible to\nallocate test-time compute to achieve a desired level of performance. We\nintroduce Length Controlled Policy Optimization (LCPO), a simple reinforcement\nlearning method that optimizes for accuracy and adherence to user-specified\nlength constraints. We use LCPO to train L1, a reasoning language model that\nproduces outputs satisfying a length constraint given in its prompt. L1's\nlength control allows for smoothly trading off computational cost and accuracy\non a wide range of tasks, and outperforms the state-of-the-art S1 method for\nlength control. Furthermore, we uncover an unexpected short chain-of-thought\ncapability in models trained with LCPO. For instance, our 1.5B L1 model\nsurpasses GPT-4o at equal reasoning lengths. Overall, LCPO enables precise\ncontrol over reasoning length, allowing for fine-grained allocation of\ntest-time compute and accuracy. We release code and models at\nhttps://www.cmu-l3.github.io/l1",
      "tldr_zh": "该研究提出了一种名为 Length Controlled Policy Optimization (LCPO) 的强化学习(Reinforcement Learning)方法，用于控制推理语言模型的 Chain-of-Thought 思考长度，从而实现准确性和计算成本的平滑 tradeoff。作者训练了 L1 模型，该模型能根据提示中的长度约束生成输出，并在多种任务上优于现有 S1 方法。实验结果显示，L1 模型意外展现出强大的短 Chain-of-Thought 能力，例如 1.5B 参数的 L1 模型在相同长度下超越 GPT-4o，并开源了代码和模型以支持进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04697v1",
      "published_date": "2025-03-06 18:43:29 UTC",
      "updated_date": "2025-03-06 18:43:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:39:32.916322"
    },
    {
      "arxiv_id": "2503.04680v1",
      "title": "Matrix Factorization for Inferring Associations and Missing Links",
      "title_zh": "用于推断关联和缺失链接的矩阵分解",
      "authors": [
        "Ryan Barron",
        "Maksim E. Eren",
        "Duc P. Truong",
        "Cynthia Matuszek",
        "James Wendelberger",
        "Mary F. Dorn",
        "Boian Alexandrov"
      ],
      "abstract": "Missing link prediction is a method for network analysis, with applications\nin recommender systems, biology, social sciences, cybersecurity, information\nretrieval, and Artificial Intelligence (AI) reasoning in Knowledge Graphs.\nMissing link prediction identifies unseen but potentially existing connections\nin a network by analyzing the observed patterns and relationships. In\nproliferation detection, this supports efforts to identify and characterize\nattempts by state and non-state actors to acquire nuclear weapons or associated\ntechnology - a notoriously challenging but vital mission for global security.\nDimensionality reduction techniques like Non-Negative Matrix Factorization\n(NMF) and Logistic Matrix Factorization (LMF) are effective but require\nselection of the matrix rank parameter, that is, of the number of hidden\nfeatures, k, to avoid over/under-fitting. We introduce novel Weighted (WNMFk),\nBoolean (BNMFk), and Recommender (RNMFk) matrix factorization methods, along\nwith ensemble variants incorporating logistic factorization, for link\nprediction. Our methods integrate automatic model determination for rank\nestimation by evaluating stability and accuracy using a modified bootstrap\nmethodology and uncertainty quantification (UQ), assessing prediction\nreliability under random perturbations. We incorporate Otsu threshold selection\nand k-means clustering for Boolean matrix factorization, comparing them to\ncoordinate descent-based Boolean thresholding. Our experiments highlight the\nimpact of rank k selection, evaluate model performance under varying test-set\nsizes, and demonstrate the benefits of UQ for reliable predictions using\nabstention. We validate our methods on three synthetic datasets (Boolean and\nuniformly distributed) and benchmark them against LMF and symmetric LMF\n(symLMF) on five real-world protein-protein interaction networks, showcasing an\nimproved prediction performance.",
      "tldr_zh": "这篇论文探讨了矩阵分解（Matrix Factorization）在缺失链接预测（Missing Link Prediction）中的应用，旨在推断网络中的潜在关联，尤其在推荐系统、生物学和社会科学等领域，包括核扩散检测。该研究引入了新的方法，包括加权矩阵分解（Weighted WNMFk）、布尔矩阵分解（Boolean BNMFk）和推荐矩阵分解（Recommender RNMFk），以及结合 Logistic Matrix Factorization (LMF) 的集成变体，这些方法通过修改的 bootstrap 技术实现自动秩估计（rank estimation）和不确定性量化 (UQ)，以提高预测稳定性和准确性。实验在合成数据集（如布尔和均匀分布数据集）和真实蛋白质-蛋白质交互网络上进行，展示了这些方法比 LMF 和 symmetric LMF (symLMF) 显著提升预测性能，并突出了秩 k 选择和 UQ 在可靠预测中的重要作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages, 14 figures, 3 tables, 1 algorithm",
      "pdf_url": "http://arxiv.org/pdf/2503.04680v1",
      "published_date": "2025-03-06 18:22:46 UTC",
      "updated_date": "2025-03-06 18:22:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:39:45.495042"
    },
    {
      "arxiv_id": "2503.04679v1",
      "title": "Multi-Agent Inverse Q-Learning from Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Nathaniel Haynam",
        "Adam Khoja",
        "Dhruv Kumar",
        "Vivek Myers",
        "Erdem Bıyık"
      ],
      "abstract": "When reward functions are hand-designed, deep reinforcement learning\nalgorithms often suffer from reward misspecification, causing them to learn\nsuboptimal policies in terms of the intended task objectives. In the\nsingle-agent case, inverse reinforcement learning (IRL) techniques attempt to\naddress this issue by inferring the reward function from expert demonstrations.\nHowever, in multi-agent problems, misalignment between the learned and true\nobjectives is exacerbated due to increased environment non-stationarity and\nvariance that scales with multiple agents. As such, in multi-agent general-sum\ngames, multi-agent IRL algorithms have difficulty balancing cooperative and\ncompetitive objectives. To address these issues, we propose Multi-Agent\nMarginal Q-Learning from Demonstrations (MAMQL), a novel sample-efficient\nframework for multi-agent IRL. For each agent, MAMQL learns a critic\nmarginalized over the other agents' policies, allowing for a well-motivated use\nof Boltzmann policies in the multi-agent context. We identify a connection\nbetween optimal marginalized critics and single-agent soft-Q IRL, allowing us\nto apply a direct, simple optimization criterion from the single-agent domain.\nAcross our experiments on three different simulated domains, MAMQL\nsignificantly outperforms previous multi-agent methods in average reward,\nsample efficiency, and reward recovery by often more than 2-5x. We make our\ncode available at https://sites.google.com/view/mamql .",
      "tldr_zh": "本论文针对多智能体环境中，手动设计的奖励函数可能导致深度强化学习算法出现奖励错误，从而学习次优策略的问题，提出了一种新的框架Multi-Agent Marginal Q-Learning from Demonstrations (MAMQL)。MAMQL通过为每个智能体学习一个对其他智能体策略边缘化的批评者(critic)，并结合Boltzmann policies与单智能体soft-Q IRL的优化标准，提高了逆强化学习(Inverse Reinforcement Learning, IRL)的样本效率和平衡合作与竞争的能力。在三个模拟领域实验中，MAMQL在平均奖励、样本效率和奖励恢复方面比现有多智能体方法提升了2-5倍以上，展示了显著的性能优势。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "8 pages, 4 figures, 2 tables. Published at the International\n  Conference on Robotics and Automation (ICRA) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04679v1",
      "published_date": "2025-03-06 18:22:29 UTC",
      "updated_date": "2025-03-06 18:22:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:39:57.076153"
    },
    {
      "arxiv_id": "2503.04877v2",
      "title": "Adapt3R: Adaptive 3D Scene Representation for Domain Transfer in Imitation Learning",
      "title_zh": "Adapt3R：自适应三维场景表示用于模仿学习中的领域转移",
      "authors": [
        "Albert Wilcox",
        "Mohamed Ghanem",
        "Masoud Moghani",
        "Pierre Barroso",
        "Benjamin Joffe",
        "Animesh Garg"
      ],
      "abstract": "Imitation Learning can train robots to perform complex and diverse\nmanipulation tasks, but learned policies are brittle with observations outside\nof the training distribution. 3D scene representations that incorporate\nobservations from calibrated RGBD cameras have been proposed as a way to\nmitigate this, but in our evaluations with unseen embodiments and camera\nviewpoints they show only modest improvement. To address those challenges, we\npropose Adapt3R, a general-purpose 3D observation encoder which synthesizes\ndata from calibrated RGBD cameras into a vector that can be used as\nconditioning for arbitrary IL algorithms. The key idea is to use a pretrained\n2D backbone to extract semantic information, using 3D only as a medium to\nlocalize this information with respect to the end-effector. We show across 93\nsimulated and 6 real tasks that when trained end-to-end with a variety of IL\nalgorithms, Adapt3R maintains these algorithms' learning capacity while\nenabling zero-shot transfer to novel embodiments and camera poses.",
      "tldr_zh": "该论文针对 Imitation Learning (IL) 在训练分布外观察时的脆弱性，提出了 Adapt3R，一种自适应 3D 场景表示方法，用于从校准的 RGBD cameras 合成观察数据作为 IL 算法的条件输入。关键想法是利用预训练的 2D 骨干网络提取语义信息，并通过 3D 表示定位这些信息相对于机器人末端执行器，从而实现更强的领域转移能力。在 93 个模拟任务和 6 个真实任务的实验中，Adapt3R 使各种 IL 算法在端到端训练后保持学习能力，并实现了零样本 (zero-shot) 转移到新机器人形态和相机姿态。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Videos, code, and data: https://pairlab.github.io/Adapt3R",
      "pdf_url": "http://arxiv.org/pdf/2503.04877v2",
      "published_date": "2025-03-06 18:17:09 UTC",
      "updated_date": "2025-05-15 20:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:40:09.358129"
    },
    {
      "arxiv_id": "2503.07650v2",
      "title": "Insights into Schizophrenia: Leveraging Machine Learning for Early Identification via EEG, ERP, and Demographic Attributes",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Alkhalifa"
      ],
      "abstract": "The research presents a machine learning (ML) classifier designed to\ndifferentiate between schizophrenia patients and healthy controls by utilising\nfeatures extracted from electroencephalogram (EEG) data, specifically focusing\non event-related potentials (ERPs) and certain demographic variables. The\ndataset comprises data from 81 participants, encompassing 32 healthy controls\nand 49 schizophrenia patients, all sourced from an online dataset. After\npreprocessing the dataset, our ML model achieved an accuracy of 99.930%. This\nperformance outperforms earlier research, including those that used deep\nlearning methods. Additionally, an analysis was conducted to assess individual\nfeatures' contribution to improving classification accuracy. This involved\nsystematically excluding specific features from the original dataset one at a\ntime, and another technique involved an iterative process of removing features\nbased on their entropy scores incrementally. The impact of these removals on\nmodel performance was evaluated to identify the most informative features.",
      "tldr_zh": "本研究开发了一个机器学习(ML)分类器，利用脑电图(EEG)数据中的事件相关电位(ERPs)和人口统计属性，来区分精神分裂症患者和健康对照组。\n数据集包含81名参与者（包括32名健康对照和49名精神分裂症患者），模型在预处理后达到了99.930%的准确率，优于现有深度学习方法。\n此外，研究通过逐个排除特征和基于熵分数的迭代移除，评估了各特征对分类性能的影响，以识别最具信息价值的特征。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T05, 92C60"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 6 figures and 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.07650v2",
      "published_date": "2025-03-06 17:42:25 UTC",
      "updated_date": "2025-03-15 09:36:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:40:20.977533"
    },
    {
      "arxiv_id": "2503.04647v1",
      "title": "Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference Alignment",
      "title_zh": "隐式跨语言奖励机制用于高效的多语言偏好对齐",
      "authors": [
        "Wen Yang",
        "Junhong Wu",
        "Chen Wang",
        "Chengqing Zong",
        "Jiajun Zhang"
      ],
      "abstract": "Direct Preference Optimization (DPO) has become a prominent method for\naligning Large Language Models (LLMs) with human preferences. While DPO has\nenabled significant progress in aligning English LLMs, multilingual preference\nalignment is hampered by data scarcity. To address this, we propose a novel\napproach that $\\textit{captures}$ learned preferences from well-aligned English\nmodels by implicit rewards and $\\textit{transfers}$ them to other languages\nthrough iterative training. Specifically, we derive an implicit reward model\nfrom the logits of an English DPO-aligned model and its corresponding reference\nmodel. This reward model is then leveraged to annotate preference relations in\ncross-lingual instruction-following pairs, using English instructions to\nevaluate multilingual responses. The annotated data is subsequently used for\nmultilingual DPO fine-tuning, facilitating preference knowledge transfer from\nEnglish to other languages. Fine-tuning Llama3 for two iterations resulted in a\n12.72% average improvement in Win Rate and a 5.97% increase in Length Control\nWin Rate across all training languages on the X-AlpacaEval leaderboard. Our\nfindings demonstrate that leveraging existing English-aligned models can enable\nefficient and effective multilingual preference alignment, significantly\nreducing the need for extensive multilingual preference data. The code is\navailable at https://github.com/ZNLP/Implicit-Cross-Lingual-Rewarding",
      "tldr_zh": "该研究提出了一种隐式跨语言奖励方法，用于高效的多语言偏好对齐，解决Direct Preference Optimization (DPO) 在多语言Large Language Models (LLMs) 训练中数据稀缺的问题。方法通过从英语DPO对齐模型的logits中派生隐式奖励模型，并将其用于标注跨语言指令跟随对（以英语指令评估多语言响应），随后进行多语言DPO微调，实现偏好知识从英语向其他语言的转移。实验结果显示，在Llama3模型上迭代微调两次后，X-AlpacaEval排行榜的Win Rate平均提升12.72%，Length Control Win Rate提升5.97%，证明该方法能显著减少多语言偏好数据的需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.04647v1",
      "published_date": "2025-03-06 17:33:01 UTC",
      "updated_date": "2025-03-06 17:33:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:40:33.559121"
    },
    {
      "arxiv_id": "2503.04641v1",
      "title": "Simulating the Real World: A Unified Survey of Multimodal Generative Models",
      "title_zh": "模拟真实世界：多模态生成模型的统一综述",
      "authors": [
        "Yuqi Hu",
        "Longguang Wang",
        "Xian Liu",
        "Ling-Hao Chen",
        "Yuwei Guo",
        "Yukai Shi",
        "Ce Liu",
        "Anyi Rao",
        "Zeyu Wang",
        "Hui Xiong"
      ],
      "abstract": "Understanding and replicating the real world is a critical challenge in\nArtificial General Intelligence (AGI) research. To achieve this, many existing\napproaches, such as world models, aim to capture the fundamental principles\ngoverning the physical world, enabling more accurate simulations and meaningful\ninteractions. However, current methods often treat different modalities,\nincluding 2D (images), videos, 3D, and 4D representations, as independent\ndomains, overlooking their interdependencies. Additionally, these methods\ntypically focus on isolated dimensions of reality without systematically\nintegrating their connections. In this survey, we present a unified survey for\nmultimodal generative models that investigate the progression of data\ndimensionality in real-world simulation. Specifically, this survey starts from\n2D generation (appearance), then moves to video (appearance+dynamics) and 3D\ngeneration (appearance+geometry), and finally culminates in 4D generation that\nintegrate all dimensions. To the best of our knowledge, this is the first\nattempt to systematically unify the study of 2D, video, 3D and 4D generation\nwithin a single framework. To guide future research, we provide a comprehensive\nreview of datasets, evaluation metrics and future directions, and fostering\ninsights for newcomers. This survey serves as a bridge to advance the study of\nmultimodal generative models and real-world simulation within a unified\nframework.",
      "tldr_zh": "这篇调查论文探讨了多模态生成模型在模拟真实世界中的应用，旨在统一 2D、视频、3D 和 4D 生成的研究框架，以推进 Artificial General Intelligence (AGI) 领域的进展。论文从 2D 生成（appearance）开始，逐步扩展到视频（appearance + dynamics）、3D 生成（appearance + geometry），并最终整合至 4D 生成，从而系统地揭示这些模态间的相互依赖性。首次将这些维度统一在一个框架中，该调查还提供了数据集、评估指标的全面回顾，以及未来研究方向的指导，以提升真实世界模拟的准确性和交互性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Repository for the related papers at\n  https://github.com/ALEEEHU/World-Simulator",
      "pdf_url": "http://arxiv.org/pdf/2503.04641v1",
      "published_date": "2025-03-06 17:31:43 UTC",
      "updated_date": "2025-03-06 17:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:40:45.460995"
    },
    {
      "arxiv_id": "2503.04636v2",
      "title": "Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models via Watermarking",
      "title_zh": "翻译失败",
      "authors": [
        "Yijie Xu",
        "Aiwei Liu",
        "Xuming Hu",
        "Lijie Wen",
        "Hui Xiong"
      ],
      "abstract": "As open-source large language models (LLMs) like Llama3 become more capable,\nit is crucial to develop watermarking techniques to detect their potential\nmisuse. Existing watermarking methods either add watermarks during LLM\ninference, which is unsuitable for open-source LLMs, or primarily target\nclassification LLMs rather than recent generative LLMs. Adapting these\nwatermarks to open-source LLMs for misuse detection remains an open challenge.\nThis work defines two misuse scenarios for open-source LLMs: intellectual\nproperty (IP) violation and LLM Usage Violation. Then, we explore the\napplication of inference-time watermark distillation and backdoor watermarking\nin these contexts. We propose comprehensive evaluation methods to assess the\nimpact of various real-world further fine-tuning scenarios on watermarks and\nthe effect of these watermarks on LLM performance. Our experiments reveal that\nbackdoor watermarking could effectively detect IP Violation, while\ninference-time watermark distillation is applicable in both scenarios but less\nrobust to further fine-tuning and has a more significant impact on LLM\nperformance compared to backdoor watermarking. Exploring more advanced\nwatermarking methods for open-source LLMs to detect their misuse should be an\nimportant future direction.",
      "tldr_zh": "这篇论文针对开源大语言模型 (LLMs) 如 Llama3 的潜在滥用问题，提出了 watermarking 水印技术来检测知识产权 (IP) 侵犯和 LLM Usage Violation 两种场景。研究者探索了 inference-time watermark distillation 和 backdoor watermarking 方法，并设计了全面评估框架，以检验这些水印在进一步微调场景下的鲁棒性和对模型性能的影响。实验结果显示，backdoor watermarking 在检测 IP 侵犯方面更有效，而 inference-time watermark distillation 虽适用于多种场景，但对微调更敏感且对 LLM 性能的影响更大。未来，开发更先进的开源 LLM 水印技术被视为重要方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by the ICLR 2025 Workshop on GenAI Watermarking",
      "pdf_url": "http://arxiv.org/pdf/2503.04636v2",
      "published_date": "2025-03-06 17:24:06 UTC",
      "updated_date": "2025-03-15 20:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:40:56.396206"
    },
    {
      "arxiv_id": "2503.04626v2",
      "title": "IDInit: A Universal and Stable Initialization Method for Neural Network Training",
      "title_zh": "IDInit：一种通用且稳定的神经网络训练初始化方法",
      "authors": [
        "Yu Pan",
        "Chaozheng Wang",
        "Zekai Wu",
        "Qifan Wang",
        "Min Zhang",
        "Zenglin Xu"
      ],
      "abstract": "Deep neural networks have achieved remarkable accomplishments in practice.\nThe success of these networks hinges on effective initialization methods, which\nare vital for ensuring stable and rapid convergence during training. Recently,\ninitialization methods that maintain identity transition within layers have\nshown good efficiency in network training. These techniques (e.g., Fixup) set\nspecific weights to zero to achieve identity control. However, settings of\nremaining weight (e.g., Fixup uses random values to initialize non-zero\nweights) will affect the inductive bias that is achieved only by a zero weight,\nwhich may be harmful to training. Addressing this concern, we introduce fully\nidentical initialization (IDInit), a novel method that preserves identity in\nboth the main and sub-stem layers of residual networks. IDInit employs a padded\nidentity-like matrix to overcome rank constraints in non-square weight\nmatrices. Furthermore, we show the convergence problem of an identity matrix\ncan be solved by stochastic gradient descent. Additionally, we enhance the\nuniversality of IDInit by processing higher-order weights and addressing dead\nneuron problems. IDInit is a straightforward yet effective initialization\nmethod, with improved convergence, stability, and performance across various\nsettings, including large-scale datasets and deep models.",
      "tldr_zh": "这篇论文提出了IDInit，一种新型的神经网络初始化方法，旨在在残差网络(residual networks)中实现完全身份转换(fully identical initialization)，从而确保训练的稳定和快速收敛。IDInit使用padded identity-like matrix来克服非方形权重矩阵的秩约束，并通过stochastic gradient descent解决收敛问题，同时增强了其通用性，包括处理更高阶权重和避免dead neuron问题。与现有方法如Fixup相比，IDInit在各种设置中显著提高了性能，尤其在大规模数据集和深层模型上。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04626v2",
      "published_date": "2025-03-06 17:12:46 UTC",
      "updated_date": "2025-03-09 16:31:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:41:06.870486"
    },
    {
      "arxiv_id": "2503.04606v3",
      "title": "The Best of Both Worlds: Integrating Language Models and Diffusion Models for Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Aoxiong Yin",
        "Kai Shen",
        "Yichong Leng",
        "Xu Tan",
        "Xinyu Zhou",
        "Juncheng Li",
        "Siliang Tang"
      ],
      "abstract": "Recent advancements in text-to-video (T2V) generation have been driven by two\ncompeting paradigms: autoregressive language models and diffusion models.\nHowever, each paradigm has intrinsic limitations: language models struggle with\nvisual quality and error accumulation, while diffusion models lack semantic\nunderstanding and causal modeling. In this work, we propose LanDiff, a hybrid\nframework that synergizes the strengths of both paradigms through\ncoarse-to-fine generation. Our architecture introduces three key innovations:\n(1) a semantic tokenizer that compresses 3D visual features into compact 1D\ndiscrete representations through efficient semantic compression, achieving a\n$\\sim$14,000$\\times$ compression ratio; (2) a language model that generates\nsemantic tokens with high-level semantic relationships; (3) a streaming\ndiffusion model that refines coarse semantics into high-fidelity videos.\nExperiments show that LanDiff, a 5B model, achieves a score of 85.43 on the\nVBench T2V benchmark, surpassing the state-of-the-art open-source models\nHunyuan Video (13B) and other commercial models such as Sora, Kling, and\nHailuo. Furthermore, our model also achieves state-of-the-art performance in\nlong video generation, surpassing other open-source models in this field. Our\ndemo can be viewed at https://landiff.github.io/.",
      "tldr_zh": "本研究提出 LanDiff 框架，将语言模型和扩散模型的优势相结合，用于文本到视频 (T2V) 生成，解决语言模型的视觉质量和错误积累问题，以及扩散模型的语义理解和因果建模不足。框架采用粗到细的生成策略，包括语义分词器实现约 14,000 倍的 3D 视觉特征压缩、语言模型生成高层语义关系的离散标记，以及流式扩散模型将粗糙语义细化为高保真视频。实验结果显示，LanDiff 的 5B 模型在 VBench T2V 基准上得分 85.43，超越开源模型 Hunyuan Video (13B) 和商业模型如 Sora、Kling 和 Hailuo，并在长视频生成中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Our code is available at https://github.com/LanDiff/LanDiff",
      "pdf_url": "http://arxiv.org/pdf/2503.04606v3",
      "published_date": "2025-03-06 16:53:14 UTC",
      "updated_date": "2025-04-29 10:34:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:41:18.352109"
    },
    {
      "arxiv_id": "2503.07649v2",
      "title": "TS-RAG: Retrieval-Augmented Generation based Time Series Foundation Models are Stronger Zero-Shot Forecaster",
      "title_zh": "翻译失败",
      "authors": [
        "Kanghui Ning",
        "Zijie Pan",
        "Yu Liu",
        "Yushan Jiang",
        "James Y. Zhang",
        "Kashif Rasul",
        "Anderson Schneider",
        "Lintao Ma",
        "Yuriy Nevmyvaka",
        "Dongjin Song"
      ],
      "abstract": "Recently, Large Language Models (LLMs) and Foundation Models (FMs) have\nbecome prevalent for time series forecasting tasks. However, fine-tuning large\nlanguage models (LLMs) for forecasting enables the adaptation to specific\ndomains but may not generalize well across diverse, unseen datasets. Meanwhile,\nexisting time series foundation models (TSFMs) lack inherent mechanisms for\ndomain adaptation and suffer from limited interpretability, making them\nsuboptimal for zero-shot forecasting. To this end, we present TS-RAG, a\nretrieval-augmented generation based time series forecasting framework that\nenhances the generalization capability and interpretability of TSFMs.\nSpecifically, TS-RAG leverages pre-trained time series encoders to retrieve\nsemantically relevant time series segments from a dedicated knowledge database,\nincorporating contextual patterns for the given time series query. Next, we\ndevelop a learnable Mixture-of-Experts (MoE)-based augmentation module, which\ndynamically fuses retrieved time series patterns with the TSFM's representation\nof the input query, improving forecasting accuracy without requiring\ntask-specific fine-tuning. Thorough empirical studies on seven public benchmark\ndatasets demonstrate that TS-RAG achieves state-of-the-art zero-shot\nforecasting performance, outperforming TSFMs by up to 6.51% across diverse\ndomains and showcasing desired interpretability.",
      "tldr_zh": "该研究提出TS-RAG框架，一种基于Retrieval-Augmented Generation (RAG)的时间序列基础模型(TSFMs)，旨在提升零样本预测的泛化能力和可解释性，以解决现有LLMs和TSFMs在领域适应和泛化方面的局限性。具体而言，TS-RAG使用预训练时间序列编码器从知识数据库检索语义相关的时间序列段，并通过一个可学习的Mixture-of-Experts (MoE)增强模块动态融合这些段与输入查询的表示，从而提高预测准确性而不需任务特定微调。在七个公共基准数据集上的实验显示，TS-RAG实现了最先进的零样本预测性能，比TSFMs高出最多6.51%，并展示了良好的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07649v2",
      "published_date": "2025-03-06 16:48:48 UTC",
      "updated_date": "2025-04-01 21:23:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:41:30.936142"
    },
    {
      "arxiv_id": "2503.04598v3",
      "title": "HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid Normalization",
      "title_zh": "HybridNorm：通过混合归一化实现 Transformer 训练的稳定性和高效性",
      "authors": [
        "Zhijian Zhuo",
        "Yutao Zeng",
        "Ya Wang",
        "Sijun Zhang",
        "Jian Yang",
        "Xiaoqing Li",
        "Xun Zhou",
        "Jinwen Ma"
      ],
      "abstract": "Transformers have become the de facto architecture for a wide range of\nmachine learning tasks, particularly in large language models (LLMs). Despite\ntheir remarkable performance, challenges remain in training deep transformer\nnetworks, especially regarding the position of layer normalization. While\nPre-Norm structures facilitate more stable training owing to their stronger\nidentity path, they often lead to suboptimal performance compared to Post-Norm.\nIn this paper, we propose $\\textbf{HybridNorm}$, a simple yet effective hybrid\nnormalization strategy that integrates the advantages of both Pre-Norm and\nPost-Norm. Specifically, HybridNorm employs QKV normalization within the\nattention mechanism and Post-Norm in the feed-forward network (FFN) of each\ntransformer block. We provide both theoretical insights and empirical evidence\ndemonstrating that HybridNorm improves gradient flow and model robustness.\nExtensive experiments on large-scale transformer models, including both dense\nand sparse variants, show that HybridNorm consistently outperforms both\nPre-Norm and Post-Norm approaches across multiple benchmarks. These findings\nhighlight the potential of HybridNorm as a more stable and effective technique\nfor improving the training and performance of deep transformer models. Code is\navailable at https://github.com/BryceZhuo/HybridNorm.",
      "tldr_zh": "本研究针对 Transformers 模型训练中的层归一化问题，提出了一种简单有效的 HybridNorm 策略，该策略结合 Pre-Norm 和 Post-Norm 的优势，在注意力机制中使用 QKV normalization，并在 Feed-Forward Network (FFN) 中采用 Post-Norm，从而改善梯度流和模型鲁棒性。理论分析和实验证据表明，HybridNorm 显著提升了模型稳定性，并在多个基准测试中超越传统 Pre-Norm 和 Post-Norm 方法，尤其在大型密集和稀疏 Transformer 变体上表现出色。该方法为更高效的深度 Transformer 训练提供了新途径，代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04598v3",
      "published_date": "2025-03-06 16:40:48 UTC",
      "updated_date": "2025-05-22 14:53:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:41:43.862567"
    },
    {
      "arxiv_id": "2503.04596v1",
      "title": "The Next Frontier of LLM Applications: Open Ecosystems and Hardware Synergy",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyi Hou",
        "Yanjie Zhao",
        "Haoyu Wang"
      ],
      "abstract": "Large Language Model (LLM) applications, including LLM app stores and\nautonomous agents, are shaping the future of AI ecosystems. However, platform\nsilos, fragmented hardware integration, and the absence of standardized\ninterfaces limit scalability, interoperability, and resource efficiency. While\nLLM app stores democratize AI, their closed ecosystems restrict modular AI\nreuse and cross-platform portability. Meanwhile, agent-based frameworks offer\nflexibility but often lack seamless integration across diverse environments.\nThis paper envisions the future of LLM applications and proposes a three-layer\ndecoupled architecture grounded in software engineering principles such as\nlayered system design, service-oriented architectures, and hardware-software\nco-design. This architecture separates application logic, communication\nprotocols, and hardware execution, enhancing modularity, efficiency, and\ncross-platform compatibility. Beyond architecture, we highlight key security\nand privacy challenges for safe, scalable AI deployment and outline research\ndirections in software and security engineering. This vision aims to foster\nopen, secure, and interoperable LLM ecosystems, guiding future advancements in\nAI applications.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLM)应用（如LLM app stores和autonomous agents）在AI生态中的未来发展，但指出平台孤岛、硬件集成碎片化和缺乏标准化接口等问题限制了可扩展性、互操作性和资源效率。论文提出一个基于软件工程原则（如分层系统设计、服务导向架构和硬件软件协同设计）的三层解耦架构，该架构将应用逻辑、通信协议和硬件执行分开，以提升模块性、效率和跨平台兼容性。同时，论文强调了安全和隐私挑战，并概述了软件和安全工程的研究方向，以推动开放、安全且可互操作的LLM生态发展。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04596v1",
      "published_date": "2025-03-06 16:38:23 UTC",
      "updated_date": "2025-03-06 16:38:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:41:58.665007"
    },
    {
      "arxiv_id": "2503.04873v1",
      "title": "Are Large Language Models Good In-context Learners for Financial Sentiment Analysis?",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Wei",
        "Luojia Liu"
      ],
      "abstract": "Recently, large language models (LLMs) with hundreds of billions of\nparameters have demonstrated the emergent ability, surpassing traditional\nmethods in various domains even without fine-tuning over domain-specific data.\nHowever, when it comes to financial sentiment analysis (FSA)$\\unicode{x2013}$a\nfundamental task in financial AI$\\unicode{x2013}$these models often encounter\nvarious challenges, such as complex financial terminology, subjective human\nemotions, and ambiguous inclination expressions. In this paper, we aim to\nanswer the fundamental question: whether LLMs are good in-context learners for\nFSA? Unveiling this question can yield informative insights on whether LLMs can\nlearn to address the challenges by generalizing in-context demonstrations of\nfinancial document-sentiment pairs to the sentiment analysis of new documents,\ngiven that finetuning these models on finance-specific data is difficult, if\nnot impossible at all. To the best of our knowledge, this is the first paper\nexploring in-context learning for FSA that covers most modern LLMs (recently\nreleased DeepSeek V3 included) and multiple in-context sample selection\nmethods. Comprehensive experiments validate the in-context learning capability\nof LLMs for FSA.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 是否适合作为 in-context learners 用于金融情感分析 (FSA)，因为 LLMs 尽管在其他领域表现出色，但面临复杂金融术语、主观情绪和模糊表达等挑战。研究通过实验评估多种现代 LLMs（包括最近发布的 DeepSeek V3）和多种 in-context sample selection 方法，检验 LLMs 是否能从上下文演示中泛化学习。结果证明，LLMs 在 FSA 任务中具备有效的 in-context learning 能力，为无需微调的金融 AI 应用提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-fin.CP"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICLR 2025 Workshop on Advances in Financial AI",
      "pdf_url": "http://arxiv.org/pdf/2503.04873v1",
      "published_date": "2025-03-06 16:38:12 UTC",
      "updated_date": "2025-03-06 16:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:42:08.035150"
    },
    {
      "arxiv_id": "2503.04872v2",
      "title": "TinyR1-32B-Preview: Boosting Accuracy with Branch-Merge Distillation",
      "title_zh": "TinyR1-32B-Preview：通过分支-合并蒸馏提升准确性",
      "authors": [
        "Lin Sun",
        "Guangxiang Zhao",
        "Xiaoqi Jian",
        "Yuhan Wu",
        "Weihong Lin",
        "Yongfu Zhu",
        "Change Jia",
        "Linglin Zhang",
        "Jinzhu Wu",
        "Junfeng Ran",
        "Sai-er Hu",
        "Zihan Jiang",
        "Junting Zhou",
        "Wenrui Liu",
        "Bin Cui",
        "Tong Yang",
        "Xiangzheng Zhang"
      ],
      "abstract": "The challenge of reducing the size of Large Language Models (LLMs) while\nmaintaining their performance has gained significant attention. However,\nexisting methods, such as model distillation and transfer learning, often fail\nto achieve high accuracy. To address this limitation, we introduce the\nBranch-Merge distillation approach, which enhances model compression through\ntwo phases: (1) the Branch Phase, where knowledge from a large teacher model is\n\\textit{selectively distilled} into specialized student models via\ndomain-specific supervised fine-tuning (SFT); And (2) the Merge Phase, where\nthese student models are merged to enable cross-domain knowledge transfer and\nimprove generalization. We validate our distillation approach using DeepSeek-R1\nas the teacher and DeepSeek-R1-Distill-Qwen-32B as the student. The resulting\nmerged model, TinyR1-32B-Preview, outperforms its counterpart\nDeepSeek-R1-Distill-Qwen-32B across multiple benchmarks, including Mathematics\n(+5.5 points), Coding (+4.4 points) and Science (+2.9 points), while achieving\nnear-equal performance to DeepSeek-R1 on AIME 2024. The Branch-Merge\ndistillation approach provides a scalable solution for creating smaller,\nhigh-performing LLMs with reduced computational cost and time.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的压缩挑战，提出了一种Branch-Merge蒸馏方法，以提升模型准确率。该方法分为两个阶段：Branch Phase，通过从教师模型DeepSeek-R1中选择性地蒸馏知识到专用学生模型，并进行领域特定的监督微调（SFT）；Merge Phase，则合并这些学生模型，实现跨领域知识转移和泛化能力提升。实验结果显示，生成的TinyR1-32B-Preview模型在多个基准上优于DeepSeek-R1-Distill-Qwen-32B，包括数学（+5.5分）、编码（+4.4分）和科学（+2.9分），并在AIME 2024上接近教师模型的性能。该方法提供了一种可扩展的解决方案，显著降低了计算成本和时间，同时保持高性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.04872v2",
      "published_date": "2025-03-06 16:25:53 UTC",
      "updated_date": "2025-03-17 10:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:42:22.030344"
    },
    {
      "arxiv_id": "2503.04569v1",
      "title": "ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making",
      "title_zh": "ValuePilot：一个两阶段框架，用于价值驱动决策",
      "authors": [
        "Yitong Luo",
        "Hou Hei Lam",
        "Ziang Chen",
        "Zhenliang Zhang",
        "Xue Feng"
      ],
      "abstract": "Despite recent advances in artificial intelligence (AI), it poses challenges\nto ensure personalized decision-making in tasks that are not considered in\ntraining datasets. To address this issue, we propose ValuePilot, a two-phase\nvalue-driven decision-making framework comprising a dataset generation toolkit\nDGT and a decision-making module DMM trained on the generated data. DGT is\ncapable of generating scenarios based on value dimensions and closely mirroring\nreal-world tasks, with automated filtering techniques and human curation to\nensure the validity of the dataset. In the generated dataset, DMM learns to\nrecognize the inherent values of scenarios, computes action feasibility and\nnavigates the trade-offs between multiple value dimensions to make personalized\ndecisions. Extensive experiments demonstrate that, given human value\npreferences, our DMM most closely aligns with human decisions, outperforming\nClaude-3.5-Sonnet, Gemini-2-flash, Llama-3.1-405b and GPT-4o. This research is\na preliminary exploration of value-driven decision-making. We hope it will\nstimulate interest in value-driven decision-making and personalized\ndecision-making within the community.",
      "tldr_zh": "这篇论文提出 ValuePilot，一种两阶段框架，用于实现 value-driven decision-making，帮助 AI 在训练数据集外进行个性化决策。框架包括数据集生成工具 (DGT)，它基于价值维度生成真实场景，并通过自动过滤和人工整理确保数据集的有效性；以及决策模块 (DMM)，在这些数据上训练以识别场景内在价值、计算行动可行性和处理多价值维度的权衡。实验结果显示，DMM 在给定人类价值偏好下，与人类决策最接近，并优于 Claude-3.5-Sonnet、Gemini-2-flash、Llama-3.1-405b 和 GPT-4o。该研究作为 value-driven decision-making 的初步探索，有望激发学术社区对个性化决策的兴趣。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04569v1",
      "published_date": "2025-03-06 16:02:53 UTC",
      "updated_date": "2025-03-06 16:02:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:42:35.023073"
    },
    {
      "arxiv_id": "2503.04564v3",
      "title": "Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User Association",
      "title_zh": "带有循环用户关联的分层安全聚合的基础极限",
      "authors": [
        "Xiang Zhang",
        "Zhou Li",
        "Kai Wan",
        "Hua Sun",
        "Mingyue Ji",
        "Giuseppe Caire"
      ],
      "abstract": "Secure aggregation is motivated by federated learning (FL) where a cloud\nserver aims to compute an averaged model (i.e., weights of deep neural\nnetworks) of the locally-trained models of numerous clients, while adhering to\ndata security requirements. Hierarchical secure aggregation (HSA) extends this\nconcept to a three-layer network, where clustered users communicate with the\nserver through an intermediate layer of relays. In HSA, beyond conventional\nserver security, relay security is also enforced to ensure that the relays\nremain oblivious to the users' inputs (an abstraction of the local models in\nFL). Existing study on HSA assumes that each user is associated with only one\nrelay, limiting opportunities for coding across inter-cluster users to achieve\nefficient communication and key generation. In this paper, we consider HSA with\na cyclic association pattern where each user is connected to $B$ consecutive\nrelays in a wrap-around manner. We propose an efficient aggregation scheme\nwhich includes a message design for the inputs inspired by gradient coding-a\nwell-known technique for efficient communication in distributed computing-along\nwith a highly nontrivial security key design. We also derive novel converse\nbounds on the minimum achievable communication and key rates using\ninformation-theoretic arguments.",
      "tldr_zh": "本研究探讨了Hierarchical Secure Aggregation (HSA) 的基本极限，针对联邦学习 (FL) 中用户通过中继与服务器通信的三层网络，确保服务器和中继对用户输入（本地模型）保持安全。论文引入了循环用户关联模式（cyclic user association），每个用户连接到B个连续中继，从而克服现有方案中用户仅关联一个中继的限制。作者提出了一种高效聚合方案，结合gradient coding启发的输入消息设计和复杂的安全密钥设计，并使用information-theoretic arguments推导出通信和密钥速率的最小下界，显著提升了系统的通信效率和安全性。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.CR",
        "cs.DC",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04564v3",
      "published_date": "2025-03-06 15:53:37 UTC",
      "updated_date": "2025-05-21 20:35:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:42:44.724192"
    },
    {
      "arxiv_id": "2503.04556v2",
      "title": "Compositional Causal Reasoning Evaluation in Language Models",
      "title_zh": "组合因果推理在语言模型中的评估",
      "authors": [
        "Jacqueline R. M. A. Maasch",
        "Alihan Hüyük",
        "Xinnuo Xu",
        "Aditya V. Nori",
        "Javier Gonzalez"
      ],
      "abstract": "Causal reasoning and compositional reasoning are two core aspirations in\ngenerative AI. Measuring the extent of these behaviors requires principled\nevaluation methods. We explore a unified perspective that considers both\nbehaviors simultaneously, termed compositional causal reasoning (CCR): the\nability to infer how causal measures compose and, equivalently, how causal\nquantities propagate through graphs. We instantiate a framework for the\nsystematic evaluation of CCR for the average treatment effect and the\nprobability of necessity and sufficiency. As proof of concept, we demonstrate\nthe design of CCR tasks for language models in the LLama, Phi, and GPT\nfamilies. On a math word problem, our framework revealed a range of\ntaxonomically distinct error patterns. Additionally, CCR errors increased with\nthe complexity of causal paths for all models except o1.",
      "tldr_zh": "本论文提出组合因果推理 (compositional causal reasoning, CCR) 的概念，旨在统一评估语言模型中因果推理和组合推理的能力。该框架通过系统任务设计，评估平均治疗效果 (average treatment effect) 和必要性与充分性概率 (probability of necessity and sufficiency)，并在 LLaMA、Phi 和 GPT 系列模型上进行实验。结果显示，CCR 任务揭示了各种分类不同的错误模式，且错误率随因果路径复杂性增加而上升，除 o1 模型外。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04556v2",
      "published_date": "2025-03-06 15:47:19 UTC",
      "updated_date": "2025-03-16 16:22:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:42:57.385414"
    },
    {
      "arxiv_id": "2503.04550v1",
      "title": "Benchmarking Reasoning Robustness in Large Language Models",
      "title_zh": "大语言模型的推理鲁棒性基准测试",
      "authors": [
        "Tong Yu",
        "Yongcheng Jing",
        "Xikun Zhang",
        "Wentao Jiang",
        "Wenjie Wu",
        "Yingjie Wang",
        "Wenbin Hu",
        "Bo Du",
        "Dacheng Tao"
      ],
      "abstract": "Despite the recent success of large language models (LLMs) in reasoning such\nas DeepSeek, we for the first time identify a key dilemma in reasoning\nrobustness and generalization: significant performance degradation on novel or\nincomplete data, suggesting a reliance on memorized patterns rather than\nsystematic reasoning. Our closer examination reveals four key unique\nlimitations underlying this issue:(1) Positional bias--models favor earlier\nqueries in multi-query inputs but answering the wrong one in the latter (e.g.,\nGPT-4o's accuracy drops from 75.8 percent to 72.8 percent); (2) Instruction\nsensitivity--performance declines by 5.0 to 7.5 percent in the Qwen2.5 Series\nand by 5.0 percent in DeepSeek-V3 with auxiliary guidance; (3) Numerical\nfragility--value substitution sharply reduces accuracy (e.g., GPT-4o drops from\n97.5 percent to 82.5 percent, GPT-o1-mini drops from 97.5 percent to 92.5\npercent); and (4) Memory dependence--models resort to guesswork when missing\ncritical data. These findings further highlight the reliance on heuristic\nrecall over rigorous logical inference, demonstrating challenges in reasoning\nrobustness. To comprehensively investigate these robustness challenges, this\npaper introduces a novel benchmark, termed as Math-RoB, that exploits\nhallucinations triggered by missing information to expose reasoning gaps. This\nis achieved by an instruction-based approach to generate diverse datasets that\nclosely resemble training distributions, facilitating a holistic robustness\nassessment and advancing the development of more robust reasoning frameworks.\nBad character(s) in field Abstract.",
      "tldr_zh": "本文评估了大型语言模型(LLMs)在推理鲁棒性方面的表现，首次揭示了其在处理新型或不完整数据时的性能下降问题，主要归因于依赖记忆模式而非系统性推理。研究识别了四个关键限制：Positional bias（模型偏好早期查询）、Instruction sensitivity（对指导敏感导致性能下降）、Numerical fragility（数值替换急剧降低准确率）和Memory dependence（缺少数据时依赖猜测）。为了全面调查这些挑战，论文引入了新基准Math-RoB，通过生成类似训练分布的数据集来暴露推理漏洞，从而推动更鲁棒推理框架的开发。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04550v1",
      "published_date": "2025-03-06 15:36:06 UTC",
      "updated_date": "2025-03-06 15:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:43:09.680940"
    },
    {
      "arxiv_id": "2503.04543v1",
      "title": "Keeping Yourself is Important in Downstream Tuning Multimodal Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Wenke Huang",
        "Jian Liang",
        "Xianda Guo",
        "Yiyang Fang",
        "Guancheng Wan",
        "Xuankun Rong",
        "Chi Wen",
        "Zekun Shi",
        "Qingyun Li",
        "Didi Zhu",
        "Yanbiao Ma",
        "Ke Liang",
        "Bin Yang",
        "He Li",
        "Jiawei Shao",
        "Mang Ye",
        "Bo Du"
      ],
      "abstract": "Multi-modal Large Language Models (MLLMs) integrate visual and linguistic\nreasoning to address complex tasks such as image captioning and visual question\nanswering. While MLLMs demonstrate remarkable versatility, MLLMs appears\nlimited performance on special applications. But tuning MLLMs for downstream\ntasks encounters two key challenges: Task-Expert Specialization, where\ndistribution shifts between pre-training and target datasets constrain target\nperformance, and Open-World Stabilization, where catastrophic forgetting erases\nthe model general knowledge. In this work, we systematically review recent\nadvancements in MLLM tuning methodologies, classifying them into three\nparadigms: (I) Selective Tuning, (II) Additive Tuning, and (III)\nReparameterization Tuning. Furthermore, we benchmark these tuning strategies\nacross popular MLLM architectures and diverse downstream tasks to establish\nstandardized evaluation analysis and systematic tuning principles. Finally, we\nhighlight several open challenges in this domain and propose future research\ndirections. To facilitate ongoing progress in this rapidly evolving field, we\nprovide a public repository that continuously tracks developments:\nhttps://github.com/WenkeHuang/Awesome-MLLM-Tuning.",
      "tldr_zh": "本文强调，在下游任务调优多模态大语言模型(MLLMs)时，需重视保持模型自身知识，以解决 Task-Expert Specialization（预训练与目标数据集分布偏移）和 Open-World Stabilization（灾难性遗忘）等挑战。研究系统回顾了 MLLMs 调优方法，并将其分类为三类：(I) Selective Tuning、(II) Additive Tuning 和 (III) Reparameterization Tuning。通过在不同 MLLMs 架构和下游任务上的基准测试，建立了标准化评估分析和系统调优原则。最后，论文指出了领域的开放挑战，提出了未来研究方向，并提供公共仓库（https://github.com/WenkeHuang/Awesome-MLLM-Tuning）以跟踪进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04543v1",
      "published_date": "2025-03-06 15:29:13 UTC",
      "updated_date": "2025-03-06 15:29:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:43:22.475954"
    },
    {
      "arxiv_id": "2503.04530v3",
      "title": "SOLAR: Scalable Optimization of Large-scale Architecture for Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Li",
        "Yinyi Luo",
        "Anudeep Bolimera",
        "Uzair Ahmed",
        "Shri Kiran Srinivasan",
        "Hrishikesh Gokhale",
        "Marios Savvides"
      ],
      "abstract": "Large Language Models excel in reasoning yet often rely on Chain-of-Thought\nprompts, limiting performance on tasks demanding more nuanced topological\nstructures. We present SOLAR (Scalable Optimization of Large-scale Architecture\nfor Reasoning), a framework that dynamically optimizes Chain-of-Thought (CoT),\nTree-of-Thought (ToT), and Graph-of-Thought (GoT) topologies to boost accuracy\nand efficiency. Our Topological-Annotation-Generation (TAG) system automates\ndataset creation, annotation, and difficulty segmentation, leading to stronger\npost training and test-time performance. We also propose Topological-Scaling, a\ncurriculum-learning-based approach that adaptively combines post training and\ninference scaling to each task. On MATH and GSM8K, SOLAR delivers notable\ngains: +5% accuracy with Topological Tuning, +9% with Topological Rewarding,\nand +10.02% with Hybrid Scaling, while reducing response length by over 5%,\nlowering inference latency. To further enhance efficiency, we introduce a\nmulti-task Topological Reward Model (M-TRM) that selects both the optimal\nreasoning topology and final answer in a single pass, eliminating multiple\nsingle-task TRMs. Remarkably, M-TRM also surpasses all single-task TRMs,\nimproving accuracy by +10% and rank correlation by +9%. Overall, SOLAR\nestablishes a new benchmark for scalable, high-precision LLM reasoning and\nintroduces a fully automated, dynamic topology competition mechanism.",
      "tldr_zh": "本文提出 SOLAR 框架，用于动态优化 Chain-of-Thought (CoT)、Tree-of-Thought (ToT) 和 Graph-of-Thought (GoT) 拓扑结构，以提升大语言模型在复杂推理任务中的准确性和效率。框架包括 Topological-Annotation-Generation (TAG) 系统，用于自动化数据集创建、标注和难度分段，以及 Topological-Scaling 方法，通过课程学习适应性结合训练和推理缩放。在 MATH 和 GSM8K 数据集上，SOLAR 实现了准确率提升高达 10.02%、响应长度减少超过 5% 和推理延迟降低；同时，多任务 Topological Reward Model (M-TRM) 在单次传递中选择最佳拓扑和答案，提升整体性能 10%。总体上，SOLAR 建立了可扩展、高精度 LLM 推理的新基准，并引入了自动化动态拓扑竞争机制。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04530v3",
      "published_date": "2025-03-06 15:19:17 UTC",
      "updated_date": "2025-05-16 06:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:43:38.153200"
    },
    {
      "arxiv_id": "2503.04869v1",
      "title": "Label Distribution Learning-Enhanced Dual-KNN for Text Classification",
      "title_zh": "标签分布学习增强的双KNN用于文本分类",
      "authors": [
        "Bo Yuan",
        "Yulin Chen",
        "Zhen Tan",
        "Wang Jinyan",
        "Huan Liu",
        "Yin Zhang"
      ],
      "abstract": "Many text classification methods usually introduce external information\n(e.g., label descriptions and knowledge bases) to improve the classification\nperformance. Compared to external information, some internal information\ngenerated by the model itself during training, like text embeddings and\npredicted label probability distributions, are exploited poorly when predicting\nthe outcomes of some texts. In this paper, we focus on leveraging this internal\ninformation, proposing a dual $k$ nearest neighbor (D$k$NN) framework with two\n$k$NN modules, to retrieve several neighbors from the training set and augment\nthe distribution of labels. For the $k$NN module, it is easily confused and may\ncause incorrect predictions when retrieving some nearest neighbors from noisy\ndatasets (datasets with labeling errors) or similar datasets (datasets with\nsimilar labels). To address this issue, we also introduce a label distribution\nlearning module that can learn label similarity, and generate a better label\ndistribution to help models distinguish texts more effectively. This module\neases model overfitting and improves final classification performance, hence\nenhancing the quality of the retrieved neighbors by $k$NN modules during\ninference. Extensive experiments on the benchmark datasets verify the\neffectiveness of our method.",
      "tldr_zh": "这篇论文提出了一种基于标签分布学习的双 k 最近邻（Dual kNN）框架，用于提升文本分类性能，通过更好地利用模型自身的内部信息（如文本嵌入和预测标签概率分布），而非依赖外部信息。框架包括两个 kNN 模块，从训练集检索邻居并增强标签分布，以辅助预测。针对 kNN 在噪声数据集或相似标签数据集中的易混淆问题，引入标签分布学习模块来学习标签相似性，生成更精确的标签分布，从而减少模型过拟合并改善文本区分能力。实验在基准数据集上证实，该方法显著提高了分类性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by SDM 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.04869v1",
      "published_date": "2025-03-06 15:15:26 UTC",
      "updated_date": "2025-03-06 15:15:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:43:47.638530"
    },
    {
      "arxiv_id": "2503.04521v1",
      "title": "Dynamic Pricing for On-Demand DNN Inference in the Edge-AI Market",
      "title_zh": "翻译失败",
      "authors": [
        "Songyuan Li",
        "Jia Hu",
        "Geyong Min",
        "Haojun Huang",
        "Jiwei Huang"
      ],
      "abstract": "The convergence of edge computing and AI gives rise to Edge-AI, which enables\nthe deployment of real-time AI applications and services at the network edge.\nOne of the fundamental research issues in Edge-AI is edge inference\nacceleration, which aims to realize low-latency high-accuracy DNN inference\nservices by leveraging the fine-grained offloading of partitioned inference\ntasks from end devices to edge servers. However, existing research has yet to\nadopt a practical Edge-AI market perspective, which would systematically\nexplore the personalized inference needs of AI users (e.g., inference accuracy,\nlatency, and task complexity), the revenue incentives for AI service providers\nthat offer edge inference services, and multi-stakeholder governance within a\nmarket-oriented context. To bridge this gap, we propose an Auction-based Edge\nInference Pricing Mechanism (AERIA) for revenue maximization to tackle the\nmulti-dimensional optimization problem of DNN model partition, edge inference\npricing, and resource allocation. We investigate the multi-exit device-edge\nsynergistic inference scheme for on-demand DNN inference acceleration, and\nanalyse the auction dynamics amongst the AI service providers, AI users and\nedge infrastructure provider. Owing to the strategic mechanism design via\nrandomized consensus estimate and cost sharing techniques, the Edge-AI market\nattains several desirable properties, including competitiveness in revenue\nmaximization, incentive compatibility, and envy-freeness, which are crucial to\nmaintain the effectiveness, truthfulness, and fairness of our auction outcomes.\nThe extensive simulation experiments based on four representative DNN inference\nworkloads demonstrate that our AERIA mechanism significantly outperforms\nseveral state-of-the-art approaches in revenue maximization, demonstrating the\nefficacy of AERIA for on-demand DNN inference in the Edge-AI market.",
      "tldr_zh": "该论文探讨了 Edge-AI 市场中按需 DNN 推理的动态定价问题，针对现有研究忽略的 AI 用户个性化需求（如推理准确性、延迟和任务复杂度）、服务提供者收入激励以及多利益相关者治理提出解决方案。作者开发了 Auction-based Edge Inference Pricing Mechanism (AERIA)，通过 DNN 模型分区、边缘推理定价和资源分配的多维优化，以及 multi-exit device-edge synergistic inference scheme 来最大化收入，同时利用 randomized consensus estimate 和 cost sharing 技术确保机制的激励兼容性和无羡慕性。实验基于四种代表性 DNN 推理工作负载显示，AERIA 在收入最大化方面显著优于现有方法，为 Edge-AI 市场的有效性和公平性提供了重要支撑。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.DC",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Index Terms: Edge-AI, DNN Inference Offloading, Resource Management,\n  Dynamic Pricing, Auction Mechanism",
      "pdf_url": "http://arxiv.org/pdf/2503.04521v1",
      "published_date": "2025-03-06 15:08:31 UTC",
      "updated_date": "2025-03-06 15:08:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:44:00.213297"
    },
    {
      "arxiv_id": "2503.04509v1",
      "title": "STX-Search: Explanation Search for Continuous Dynamic Spatio-Temporal Models",
      "title_zh": "STX-Search：针对连续动态时空模型的解释搜索",
      "authors": [
        "Saif Anwar",
        "Nathan Griffiths",
        "Thomas Popham",
        "Abhir Bhalerao"
      ],
      "abstract": "Recent improvements in the expressive power of spatio-temporal models have\nled to performance gains in many real-world applications, such as traffic\nforecasting and social network modelling. However, understanding the\npredictions from a model is crucial to ensure reliability and trustworthiness,\nparticularly for high-risk applications, such as healthcare and transport. Few\nexisting methods are able to generate explanations for models trained on\ncontinuous-time dynamic graph data and, of these, the computational complexity\nand lack of suitable explanation objectives pose challenges. In this paper, we\npropose $\\textbf{S}$patio-$\\textbf{T}$emporal E$\\textbf{X}$planation\n$\\textbf{Search}$ (STX-Search), a novel method for generating instance-level\nexplanations that is applicable to static and dynamic temporal graph\nstructures. We introduce a novel search strategy and objective function, to\nfind explanations that are highly faithful and interpretable. When compared\nwith existing methods, STX-Search produces explanations of higher fidelity\nwhilst optimising explanation size to maintain interpretability.",
      "tldr_zh": "本文提出 STX-Search，一种新型解释搜索方法，针对连续动态时空模型（spatio-temporal models）的预测生成实例级解释，以提升模型的可解释性和可靠性，尤其适用于高风险领域如医疗和交通。该方法引入创新的搜索策略和目标函数，确保解释高度忠实（faithful）和可解释，同时优化解释大小以避免复杂性。与现有方法相比，STX-Search 在静态和动态时空图结构上生成更高质量的解释，显著提高了保真度（fidelity）。这为处理动态图数据提供了更有效的解释框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04509v1",
      "published_date": "2025-03-06 14:55:25 UTC",
      "updated_date": "2025-03-06 14:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:44:11.092460"
    },
    {
      "arxiv_id": "2503.04506v1",
      "title": "Multi-modal Summarization in Model-Based Engineering: Automotive Software Development Case Study",
      "title_zh": "翻译失败",
      "authors": [
        "Nenad Petrovic",
        "Yurui Zhang",
        "Moaad Maaroufi",
        "Kuo-Yi Chao",
        "Lukasz Mazur",
        "Fengjunjie Pan",
        "Vahid Zolfaghari",
        "Alois Knoll"
      ],
      "abstract": "Multimodal summarization integrating information from diverse data modalities\npresents a promising solution to aid the understanding of information within\nvarious processes. However, the application and advantages of multimodal\nsummarization have not received much attention in model-based engineering\n(MBE), where it has become a cornerstone in the design and development of\ncomplex systems, leveraging formal models to improve understanding, validation\nand automation throughout the engineering lifecycle. UML and EMF diagrams in\nmodel-based engineering contain a large amount of multimodal information and\nintricate relational data. Hence, our study explores the application of\nmultimodal large language models within the domain of model-based engineering\nto evaluate their capacity for understanding and identifying relationships,\nfeatures, and functionalities embedded in UML and EMF diagrams. We aim to\ndemonstrate the transformative potential benefits and limitations of multimodal\nsummarization in improving productivity and accuracy in MBE practices. The\nproposed approach is evaluated within the context of automotive software\ndevelopment, while many promising state-of-art models were taken into account.",
      "tldr_zh": "这篇论文探讨了多模态总结（multimodal summarization）在基于模型工程（MBE）中的应用，通过一个汽车软件开发案例研究，旨在整合多种数据模态信息以提升过程理解。研究评估了多模态大型语言模型（multimodal large language models）在分析 UML 和 EMF 图中的关系、特征和功能的能力，突出了其在识别复杂关系方面的潜力。结果表明，这种方法能显著提高 MBE 实践的生产力和准确性，同时指出了其存在的局限性，如模型理解的挑战和适用性问题。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Conference paper accepted for IntelliSys2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04506v1",
      "published_date": "2025-03-06 14:53:37 UTC",
      "updated_date": "2025-03-06 14:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:44:22.054016"
    },
    {
      "arxiv_id": "2503.04502v1",
      "title": "Interpretable Transformation and Analysis of Timelines through Learning via Surprisability",
      "title_zh": "翻译失败",
      "authors": [
        "Osnat Mokryn",
        "Teddy Lazebnik",
        "Hagit Ben Shoshan"
      ],
      "abstract": "The analysis of high-dimensional timeline data and the identification of\noutliers and anomalies is critical across diverse domains, including sensor\nreadings, biological and medical data, historical records, and global\nstatistics. However, conventional analysis techniques often struggle with\nchallenges such as high dimensionality, complex distributions, and sparsity.\nThese limitations hinder the ability to extract meaningful insights from\ncomplex temporal datasets, making it difficult to identify trending features,\noutliers, and anomalies effectively. Inspired by surprisability -- a cognitive\nscience concept describing how humans instinctively focus on unexpected\ndeviations - we propose Learning via Surprisability (LvS), a novel approach for\ntransforming high-dimensional timeline data. LvS quantifies and prioritizes\nanomalies in time-series data by formalizing deviations from expected behavior.\nLvS bridges cognitive theories of attention with computational methods,\nenabling the detection of anomalies and shifts in a way that preserves critical\ncontext, offering a new lens for interpreting complex datasets. We demonstrate\nthe usefulness of LvS on three high-dimensional timeline use cases: a time\nseries of sensor data, a global dataset of mortality causes over multiple\nyears, and a textual corpus containing over two centuries of State of the Union\nAddresses by U.S. presidents. Our results show that the LvS transformation\nenables efficient and interpretable identification of outliers, anomalies, and\nthe most variable features along the timeline.",
      "tldr_zh": "本研究针对高维时间线数据的分析挑战（如高维度、复杂分布和稀疏性），提出了一种基于“surprisability”（惊奇性）概念的创新方法Learning via Surprisability (LvS)。LvS通过量化时间序列数据中预期行为的偏差，将认知科学理论与计算方法相结合，实现对异常、离群值和变化特征的可解释检测，同时保留关键上下文。实验在三个真实用例上验证，包括传感器数据、全球死亡原因数据集和美国国情咨文文本语料，结果显示LvS显著提升了异常识别的效率和可解释性。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04502v1",
      "published_date": "2025-03-06 14:50:29 UTC",
      "updated_date": "2025-03-06 14:50:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:44:34.617336"
    },
    {
      "arxiv_id": "2503.04500v2",
      "title": "ReynoldsFlow: Exquisite Flow Estimation via Reynolds Transport Theorem",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Hsi Chen",
        "Chin-Tien Wu"
      ],
      "abstract": "Optical flow is a fundamental technique for motion estimation, widely applied\nin video stabilization, interpolation, and object tracking. Traditional optical\nflow estimation methods rely on restrictive assumptions like brightness\nconstancy and slow motion constraints. Recent deep learning-based flow\nestimations require extensive training on large domain-specific datasets,\nmaking them computationally demanding. Also, artificial intelligence (AI)\nadvances have enabled deep learning models to take advantage of optical flow as\nan important feature for object tracking and motion analysis. Since optical\nflow is commonly encoded in HSV for visualization, its conversion to RGB for\nneural network processing is nonlinear and may introduce perceptual\ndistortions. These transformations amplify the sensitivity to estimation\nerrors, potentially affecting the predictive accuracy of the networks. To\naddress these challenges that are influential to the performance of downstream\nnetwork models, we propose Reynolds flow, a novel training-free flow estimation\ninspired by the Reynolds transport theorem, offering a principled approach to\nmodeling complex motion dynamics. In addition to conventional HSV-based\nvisualization of Reynolds flow, we also introduce an RGB-encoded representation\nof Reynolds flow designed to improve flow visualization and feature enhancement\nfor neural networks. We evaluated the effectiveness of Reynolds flow in\nvideo-based tasks. Experimental results on three benchmarks, tiny object\ndetection on UAVDB, infrared object detection on Anti-UAV, and pose estimation\non GolfDB, demonstrate that networks trained with RGB-encoded Reynolds flow\nachieve SOTA performance, exhibiting improved robustness and efficiency across\nall tasks.",
      "tldr_zh": "该论文针对传统光学流估计方法的假设限制（如亮度恒定和慢速运动约束）以及深度学习方法的计算密集和数据需求等问题，提出了一种基于 Reynolds Transport Theorem 的新型训练-free 框架：ReynoldsFlow，用于精确建模复杂运动动态。ReynoldsFlow 不仅提供常规 HSV 编码的可视化，还引入 RGB 编码表示，以减少转换失真并增强神经网络特征。实验在 UAVDB（小物体检测）、Anti-UAV（红外物体检测）和 GolfDB（姿态估计）等基准上表明，使用 RGB 编码 ReynoldsFlow 训练的网络实现了 SOTA 性能，显著提高了任务的鲁棒性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04500v2",
      "published_date": "2025-03-06 14:49:28 UTC",
      "updated_date": "2025-03-09 17:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:44:46.718639"
    },
    {
      "arxiv_id": "2503.15538v1",
      "title": "There must be encapsulated nonconceptual content in vision",
      "title_zh": "视觉中必须存在封装的非概念内容",
      "authors": [
        "Vincent C. Müller"
      ],
      "abstract": "In this paper I want to propose an argument to support Jerry Fodor's thesis\n(Fodor 1983) that input systems are modular and thus informationally\nencapsulated. The argument starts with the suggestion that there is a\n\"grounding problem\" in perception, i. e. that there is a problem in explaining\nhow perception that can yield a visual experience is possible, how sensation\ncan become meaningful perception of something for the subject. Given that\nvisual experience is actually possible, this invites a transcendental argument\nthat explains the conditions of its possibility. I propose that one of these\nconditions is the existence of a visual module in Fodor's sense that allows the\nstep from sensation to object-identifying perception, thus enabling visual\nexperience. It seems to follow that there is informationally encapsulated\nnonconceptual content in visual perception.",
      "tldr_zh": "这篇论文旨在支持 Jerry Fodor 的观点，即输入系统是模块化的和 informationally encapsulated 的。作者从感知中的“grounding problem”出发，提出一个 transcendental argument，解释视觉经验如何从感觉转变为有意义的物体识别感知。最终，论证表明，视觉模块的存在是视觉经验的必要条件，从而证明了视觉感知中存在 informationally encapsulated 的 nonconceptual content。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15538v1",
      "published_date": "2025-03-06 14:44:55 UTC",
      "updated_date": "2025-03-06 14:44:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:44:58.281310"
    },
    {
      "arxiv_id": "2503.04482v1",
      "title": "Generalized Interpolating Discrete Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Dimitri von Rütte",
        "Janis Fluri",
        "Yuhui Ding",
        "Antonio Orvieto",
        "Bernhard Schölkopf",
        "Thomas Hofmann"
      ],
      "abstract": "While state-of-the-art language models achieve impressive results through\nnext-token prediction, they have inherent limitations such as the inability to\nrevise already generated tokens. This has prompted exploration of alternative\napproaches such as discrete diffusion. However, masked diffusion, which has\nemerged as a popular choice due to its simplicity and effectiveness,\nreintroduces this inability to revise words. To overcome this, we generalize\nmasked diffusion and derive the theoretical backbone of a family of general\ninterpolating discrete diffusion (GIDD) processes offering greater flexibility\nin the design of the noising processes. Leveraging a novel diffusion ELBO, we\nachieve compute-matched state-of-the-art performance in diffusion language\nmodeling. Exploiting GIDD's flexibility, we explore a hybrid approach combining\nmasking and uniform noise, leading to improved sample quality and unlocking the\nability for the model to correct its own mistakes, an area where autoregressive\nmodels notoriously have struggled. Our code and models are open-source:\nhttps://github.com/dvruette/gidd/",
      "tldr_zh": "该论文针对现有语言模型（如基于下一个标记预测的模型）无法修改已生成标记的局限性，推广了 masked diffusion，提出了 Generalized Interpolating Discrete Diffusion (GIDD) 进程，以提供更大的 noising 过程设计灵活性。利用一个新型的 diffusion ELBO，该方法在计算资源匹配的情况下达到了最先进的离散扩散语言建模性能。通过探索 GIDD 的混合方法（结合 masking 和 uniform noise），论文提升了样本质量，并使模型能够自我修正错误，这在 autoregressive 模型中长期存在挑战。开源代码和模型可从 GitHub 获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04482v1",
      "published_date": "2025-03-06 14:30:55 UTC",
      "updated_date": "2025-03-06 14:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:45:11.656329"
    },
    {
      "arxiv_id": "2503.04479v3",
      "title": "ToolFuzz -- Automated Agent Tool Testing",
      "title_zh": "ToolFuzz -- 自动化代理工具测试",
      "authors": [
        "Ivan Milev",
        "Mislav Balunović",
        "Maximilian Baader",
        "Martin Vechev"
      ],
      "abstract": "Large Language Model (LLM) Agents leverage the advanced reasoning\ncapabilities of LLMs in real-world applications. To interface with an\nenvironment, these agents often rely on tools, such as web search or database\nAPIs. As the agent provides the LLM with tool documentation along the user\nquery, the completeness and correctness of this documentation is critical.\nHowever, tool documentation is often over-, under-, or ill-specified, impeding\nthe agent's accuracy. Standard software testing approaches struggle to identify\nthese errors as they are expressed in natural language. Thus, despite its\nimportance, there currently exists no automated method to test the tool\ndocumentation for agents. To address this issue, we present ToolFuzz, the first\nmethod for automated testing of tool documentations. ToolFuzz is designed to\ndiscover two types of errors: (1) user queries leading to tool runtime errors\nand (2) user queries that lead to incorrect agent responses. ToolFuzz can\ngenerate a large and diverse set of natural inputs, effectively finding tool\ndescription errors at a low false positive rate. Further, we present two\nstraightforward prompt-engineering approaches. We evaluate all three tool\ntesting approaches on 32 common LangChain tools and 35 newly created custom\ntools and 2 novel benchmarks to further strengthen the assessment. We find that\nmany publicly available tools suffer from underspecification. Specifically, we\nshow that ToolFuzz identifies 20x more erroneous inputs compared to the\nprompt-engineering approaches, making it a key component for building reliable\nAI agents.",
      "tldr_zh": "本文提出 ToolFuzz，一种自动化测试 LLM 代理工具文档的方法，旨在发现工具描述中的错误，包括导致工具运行时错误或代理响应错误的用户查询。ToolFuzz 通过生成大量多样化的自然输入来实现高效测试，并与两种提示工程方法进行了比较。在评估中，ToolFuzz 在 32 个 LangChain 工具和 35 个自定义工具上识别了 20 倍更多的错误输入，揭示了许多工具存在 underspecification 问题，从而为构建可靠的 AI 代理提供了关键支持。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04479v3",
      "published_date": "2025-03-06 14:29:52 UTC",
      "updated_date": "2025-03-11 14:28:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:45:23.201936"
    },
    {
      "arxiv_id": "2503.04472v1",
      "title": "DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models",
      "title_zh": "DAST：难度自适应慢思考用于大型推理模型",
      "authors": [
        "Yi Shen",
        "Jian Zhang",
        "Jieyun Huang",
        "Shuming Shi",
        "Wenjing Zhang",
        "Jiangze Yan",
        "Ning Wang",
        "Kai Wang",
        "Shiguo Lian"
      ],
      "abstract": "Recent advancements in slow-thinking reasoning models have shown exceptional\nperformance in complex reasoning tasks. However, these models often exhibit\noverthinking-generating redundant reasoning steps for simple problems, leading\nto excessive computational resource usage. While current mitigation strategies\nuniformly reduce reasoning tokens, they risk degrading performance on\nchallenging tasks that require extended reasoning. This paper introduces\nDifficulty-Adaptive Slow-Thinking (DAST), a novel framework that enables models\nto autonomously adjust the length of Chain-of-Thought(CoT) based on problem\ndifficulty. We first propose a Token Length Budget (TLB) metric to quantify\ndifficulty, then leveraging length-aware reward shaping and length preference\noptimization to implement DAST. DAST penalizes overlong responses for simple\ntasks while incentivizing sufficient reasoning for complex problems.\nExperiments on diverse datasets and model scales demonstrate that DAST\neffectively mitigates overthinking (reducing token usage by over 30\\% on\naverage) while preserving reasoning accuracy on complex problems.",
      "tldr_zh": "该论文针对大型推理模型的过度思考问题，提出了一种Difficulty-Adaptive Slow-Thinking (DAST)框架，以优化Chain-of-Thought (CoT)推理长度。DAST首先引入Token Length Budget (TLB)指标来量化问题难度，然后通过length-aware reward shaping和length preference optimization技术，让模型自主调整推理步骤，从而减少简单任务的冗余响应并强化复杂任务的充分推理。实验结果显示，DAST在多种数据集和模型规模上平均降低了超过30%的token使用，同时保持了复杂问题的推理准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "working in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.04472v1",
      "published_date": "2025-03-06 14:23:06 UTC",
      "updated_date": "2025-03-06 14:23:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:45:34.938110"
    },
    {
      "arxiv_id": "2503.04457v1",
      "title": "TPC: Cross-Temporal Prediction Connection for Vision-Language Model Hallucination Reduction",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Wang",
        "Weiwei Fu",
        "Yang Zhou"
      ],
      "abstract": "Vision-language models (VLMs) have achieved remarkable advancements,\ncapitalizing on the impressive capabilities of large language models (LLMs)\nacross diverse tasks. Despite this, a critical challenge known as hallucination\noccurs when models overconfidently describe objects or attributes absent from\nthe image, a problem exacerbated by the tendency of VLMs to rely on linguistic\npriors. This limitation reduces model reliability in high-stakes applications.\nIn this work, we have observed the characteristic of logits' continuity\nconsistency enhancement and introduced a straightforward and efficient method,\nCross-Temporal Prediction Connection (TPC), designed to enhance the semantic\nconsistency of logits by connecting them temporally across timesteps. TPC\namplifies information flow and improves coherence, effectively reducing\nhallucination. Extensive experiments show that TPC surpasses existing\nrepresentatives, delivering superior performance in both accuracy and\nefficiency while maintaining robustness in open-ended text generation tasks.",
      "tldr_zh": "本研究针对视觉语言模型(VLMs)的幻觉问题，即模型过度依赖语言先验而错误描述图像中不存在的对象或属性，从而降低了其在高风险应用中的可靠性。作者观察到logits的连续性一致性增强，并提出了一种简单高效的方法Cross-Temporal Prediction Connection (TPC)，通过跨时间步连接logits来放大信息流、提升语义一致性，从而有效减少幻觉。实验结果表明，TPC在准确性和效率上优于现有方法，并在开放式文本生成任务中保持稳健表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04457v1",
      "published_date": "2025-03-06 14:11:00 UTC",
      "updated_date": "2025-03-06 14:11:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:45:47.585670"
    },
    {
      "arxiv_id": "2503.04451v1",
      "title": "Privacy Preserving and Robust Aggregation for Cross-Silo Federated Learning in Non-IID Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Arazzi",
        "Mert Cihangiroglu",
        "Antonino Nocera"
      ],
      "abstract": "Federated Averaging remains the most widely used aggregation strategy in\nfederated learning due to its simplicity and scalability. However, its\nperformance degrades significantly in non-IID data settings, where client\ndistributions are highly imbalanced or skewed. Additionally, it relies on\nclients transmitting metadata, specifically the number of training samples,\nwhich introduces privacy risks and may conflict with regulatory frameworks like\nthe European GDPR. In this paper, we propose a novel aggregation strategy that\naddresses these challenges by introducing class-aware gradient masking. Unlike\ntraditional approaches, our method relies solely on gradient updates,\neliminating the need for any additional client metadata, thereby enhancing\nprivacy protection. Furthermore, our approach validates and dynamically weights\nclient contributions based on class-specific importance, ensuring robustness\nagainst non-IID distributions, convergence prevention, and backdoor attacks.\nExtensive experiments on benchmark datasets demonstrate that our method not\nonly outperforms FedAvg and other widely accepted aggregation strategies in\nnon-IID settings but also preserves model integrity in adversarial scenarios.\nOur results establish the effectiveness of gradient masking as a practical and\nsecure solution for federated learning.",
      "tldr_zh": "该论文针对联邦学习中非独立同分布（non-IID）数据设置下的挑战，提出了一种新型聚合策略，以解决Federated Averaging（FedAvg）在数据分布不均时性能下降以及隐私风险的问题。新的策略采用class-aware gradient masking，仅依赖梯度更新来动态加权客户端贡献，并基于类特定重要性验证客户端输入，从而增强隐私保护、防止收敛问题和后门攻击。实验在基准数据集上证明，该方法在non-IID环境中优于FedAvg和其他策略，并在对抗场景中维持模型完整性，建立gradient masking作为联邦学习的一种实用、安全解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04451v1",
      "published_date": "2025-03-06 14:06:20 UTC",
      "updated_date": "2025-03-06 14:06:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:45:59.808122"
    },
    {
      "arxiv_id": "2504.06275v1",
      "title": "A Cascaded Architecture for Extractive Summarization of Multimedia Content via Audio-to-Text Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Tanzir Hossain",
        "Ar-Rafi Islam",
        "Md. Sabbir Hossain",
        "Annajiat Alim Rasel"
      ],
      "abstract": "This study presents a cascaded architecture for extractive summarization of\nmultimedia content via audio-to-text alignment. The proposed framework\naddresses the challenge of extracting key insights from multimedia sources like\nYouTube videos. It integrates audio-to-text conversion using Microsoft Azure\nSpeech with advanced extractive summarization models, including Whisper,\nPegasus, and Facebook BART XSum. The system employs tools such as Pytube,\nPydub, and SpeechRecognition for content retrieval, audio extraction, and\ntranscription. Linguistic analysis is enhanced through named entity recognition\nand semantic role labeling. Evaluation using ROUGE and F1 scores demonstrates\nthat the cascaded architecture outperforms conventional summarization methods,\ndespite challenges like transcription errors. Future improvements may include\nmodel fine-tuning and real-time processing. This study contributes to\nmultimedia summarization by improving information retrieval, accessibility, and\nuser experience.",
      "tldr_zh": "这篇论文提出了一种级联架构，用于通过音频到文本对齐实现多媒体内容的提取式 summarization，针对 YouTube 视频等来源的摘要提取挑战。框架整合了 Microsoft Azure Speech 进行音频转文本转换，以及 Whisper、Pegasus 和 Facebook BART XSum 等模型，加上 Pytube、Pydub 和 SpeechRecognition 等工具，并通过命名实体识别和语义角色标记增强语言分析。实验结果显示，该架构在 ROUGE 和 F1 scores 上优于传统方法，尽管面临转录错误等问题；该研究提升了多媒体总结的信息检索、可访问性和用户体验，并建议未来通过模型 fine-tuning 和实时处理进行优化。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06275v1",
      "published_date": "2025-03-06 13:59:14 UTC",
      "updated_date": "2025-03-06 13:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:46:12.647205"
    },
    {
      "arxiv_id": "2503.04429v2",
      "title": "Activation Space Interventions Can Be Transferred Between Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Narmeen Oozeer",
        "Dhruv Nathawani",
        "Nirmalendu Prakash",
        "Michael Lan",
        "Abir Harrasse",
        "Amirali Abdullah"
      ],
      "abstract": "The study of representation universality in AI models reveals growing\nconvergence across domains, modalities, and architectures. However, the\npractical applications of representation universality remain largely\nunexplored. We bridge this gap by demonstrating that safety interventions can\nbe transferred between models through learned mappings of their shared\nactivation spaces. We demonstrate this approach on two well-established AI\nsafety tasks: backdoor removal and refusal of harmful prompts, showing\nsuccessful transfer of steering vectors that alter the models' outputs in a\npredictable way. Additionally, we propose a new task, \\textit{corrupted\ncapabilities}, where models are fine-tuned to embed knowledge tied to a\nbackdoor. This tests their ability to separate useful skills from backdoors,\nreflecting real-world challenges. Extensive experiments across Llama, Qwen and\nGemma model families show that our method enables using smaller models to\nefficiently align larger ones. Furthermore, we demonstrate that autoencoder\nmappings between base and fine-tuned models can serve as reliable ``lightweight\nsafety switches\", allowing dynamic toggling between model behaviors.",
      "tldr_zh": "这篇论文探讨了 AI 模型中 representation universality 的实际应用，通过 learned mappings 将激活空间 interventions 转移到不同大型语言模型之间。研究团队在 backdoor removal 和 refusal of harmful prompts 任务上展示了 steering vectors 的成功转移，并提出了新任务 corrupted capabilities，以测试模型分离有用技能和后门的能力。实验跨 Llama、Qwen 和 Gemma 模型家族进行，结果表明该方法能用小模型高效对齐大模型，并利用 autoencoder mappings 作为可靠的轻量级安全开关，实现动态行为切换。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "68 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.04429v2",
      "published_date": "2025-03-06 13:38:44 UTC",
      "updated_date": "2025-05-05 16:39:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:46:24.152033"
    },
    {
      "arxiv_id": "2503.04422v1",
      "title": "PDX: A Data Layout for Vector Similarity Search",
      "title_zh": "PDX：一种用于向量相似性搜索的数据布局",
      "authors": [
        "Leonardo Kuffo",
        "Elena Krippner",
        "Peter Boncz"
      ],
      "abstract": "We propose Partition Dimensions Across (PDX), a data layout for vectors\n(e.g., embeddings) that, similar to PAX [6], stores multiple vectors in one\nblock, using a vertical layout for the dimensions (Figure 1). PDX accelerates\nexact and approximate similarity search thanks to its dimension-by-dimension\nsearch strategy that operates on multiple-vectors-at-a-time in tight loops. It\nbeats SIMD-optimized distance kernels on standard horizontal vector storage\n(avg 40% faster), only relying on scalar code that gets auto-vectorized. We\ncombined the PDX layout with recent dimension-pruning algorithms ADSampling\n[19] and BSA [52] that accelerate approximate vector search. We found that\nthese algorithms on the horizontal vector layout can lose to SIMD-optimized\nlinear scans, even if they are SIMD-optimized. However, when used on PDX, their\nbenefit is restored to 2-7x. We find that search on PDX is especially fast if a\nlimited number of dimensions has to be scanned fully, which is what the\ndimension-pruning approaches do. We finally introduce PDX-BOND, an even more\nflexible dimension-pruning strategy, with good performance on exact search and\nreasonable performance on approximate search. Unlike previous pruning\nalgorithms, it can work on vector data \"as-is\" without preprocessing; making it\nattractive for vector databases with frequent updates.",
      "tldr_zh": "我们提出 PDX，一种数据布局，用于向量相似性搜索（例如嵌入），类似于 PAX，将多个向量存储在一个块中，并采用垂直布局按维度组织，从而通过维度-by-dimension 搜索策略在紧凑循环中处理多个向量。PDX 比标准水平向量存储的 SIMD-优化距离内核快 40%，仅依赖自动向量化标量代码，并在结合 ADSampling 和 BSA 等维度修剪算法后，实现 2-7 倍的加速，尤其在需完全扫描有限维度时表现突出。我们还引入 PDX-BOND，一种更灵活的维度修剪策略，它无需预处理即可应用于精确和近似搜索，适合频繁更新的向量数据库。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "To be published in Proceedings of The 2025 International Conference\n  on Management of Data (SIGMOD '25). For associated code, see\n  https://github.com/cwida/PDX",
      "pdf_url": "http://arxiv.org/pdf/2503.04422v1",
      "published_date": "2025-03-06 13:31:16 UTC",
      "updated_date": "2025-03-06 13:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:47:28.178117"
    },
    {
      "arxiv_id": "2503.04417v1",
      "title": "From Idea to CAD: A Language Model-Driven Multi-Agent System for Collaborative Design",
      "title_zh": "翻译失败",
      "authors": [
        "Felix Ocker",
        "Stefan Menzel",
        "Ahmed Sadik",
        "Thiago Rios"
      ],
      "abstract": "Creating digital models using Computer Aided Design (CAD) is a process that\nrequires in-depth expertise. In industrial product development, this process\ntypically involves entire teams of engineers, spanning requirements\nengineering, CAD itself, and quality assurance. We present an approach that\nmirrors this team structure with a Vision Language Model (VLM)-based Multi\nAgent System, with access to parametric CAD tooling and tool documentation.\nCombining agents for requirements engineering, CAD engineering, and\nvision-based quality assurance, a model is generated automatically from\nsketches and/ or textual descriptions. The resulting model can be refined\ncollaboratively in an iterative validation loop with the user. Our approach has\nthe potential to increase the effectiveness of design processes, both for\nindustry experts and for hobbyists who create models for 3D printing. We\ndemonstrate the potential of the architecture at the example of various design\ntasks and provide several ablations that show the benefits of the\narchitecture's individual components.",
      "tldr_zh": "该论文提出了一种基于 Vision Language Model (VLM) 的多智能体系统，用于模拟工程团队结构，实现从想法到 CAD 设计的协作过程。该系统包括需求工程代理、CAD 工程代理和基于视觉的质量保证代理，能够从草图或文本描述自动生成参数化 CAD 模型，并通过迭代验证循环与用户协作完善。实验通过各种设计任务和消融分析证明，该架构提高了设计过程的效率，适用于工业专家和 3D 打印爱好者。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "J.6; I.6.5; I.2.1; I.2.11; I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04417v1",
      "published_date": "2025-03-06 13:21:27 UTC",
      "updated_date": "2025-03-06 13:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:46:48.981323"
    },
    {
      "arxiv_id": "2503.04416v1",
      "title": "Learning Transformer-based World Models with Contrastive Predictive Coding",
      "title_zh": "使用对比预测编码学习基于 Transformer 的世界模型",
      "authors": [
        "Maxime Burchi",
        "Radu Timofte"
      ],
      "abstract": "The DreamerV3 algorithm recently obtained remarkable performance across\ndiverse environment domains by learning an accurate world model based on\nRecurrent Neural Networks (RNNs). Following the success of model-based\nreinforcement learning algorithms and the rapid adoption of the Transformer\narchitecture for its superior training efficiency and favorable scaling\nproperties, recent works such as STORM have proposed replacing RNN-based world\nmodels with Transformer-based world models using masked self-attention.\nHowever, despite the improved training efficiency of these methods, their\nimpact on performance remains limited compared to the Dreamer algorithm,\nstruggling to learn competitive Transformer-based world models. In this work,\nwe show that the next state prediction objective adopted in previous approaches\nis insufficient to fully exploit the representation capabilities of\nTransformers. We propose to extend world model predictions to longer time\nhorizons by introducing TWISTER (Transformer-based World model wIth contraSTivE\nRepresentations), a world model using action-conditioned Contrastive Predictive\nCoding to learn high-level temporal feature representations and improve the\nagent performance. TWISTER achieves a human-normalized mean score of 162% on\nthe Atari 100k benchmark, setting a new record among state-of-the-art methods\nthat do not employ look-ahead search.",
      "tldr_zh": "本研究针对基于 Transformer 的世界模型在强化学习中的性能限制，提出 TWISTER 框架，通过引入 action-conditioned Contrastive Predictive Coding 来扩展预测时序，并学习高水平的时间特征表示，从而提升代理性能。相比于先前方法如 STORM 的 next state prediction 目标，TWISTER 充分利用了 Transformer's 表示能力。实验结果显示，TWISTER 在 Atari 100k 基准上达到了 162% 的 human-normalized mean score，超越了不使用 look-ahead search 的最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04416v1",
      "published_date": "2025-03-06 13:18:37 UTC",
      "updated_date": "2025-03-06 13:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:46:59.568070"
    },
    {
      "arxiv_id": "2503.04412v1",
      "title": "Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Kou Misaki",
        "Yuichi Inoue",
        "Yuki Imajuku",
        "So Kuroki",
        "Taishi Nakamura",
        "Takuya Akiba"
      ],
      "abstract": "Recent advances demonstrate that increasing inference-time computation can\nsignificantly boost the reasoning capabilities of large language models (LLMs).\nAlthough repeated sampling (i.e., generating multiple candidate outputs) is a\nhighly effective strategy, it does not leverage external feedback signals for\nrefinement, which are often available in tasks like coding. In this work, we\npropose $\\textit{Adaptive Branching Monte Carlo Tree Search (AB-MCTS)}$, a\nnovel inference-time framework that generalizes repeated sampling with\nprincipled multi-turn exploration and exploitation. At each node in the search\ntree, AB-MCTS dynamically decides whether to \"go wider\" by expanding new\ncandidate responses or \"go deeper\" by revisiting existing ones based on\nexternal feedback signals. We evaluate our method on complex coding and\nengineering tasks using frontier models. Empirical results show that AB-MCTS\nconsistently outperforms both repeated sampling and standard MCTS, underscoring\nthe importance of combining the response diversity of LLMs with multi-turn\nsolution refinement for effective inference-time scaling.",
      "tldr_zh": "最近的研究显示，增加大型语言模型（LLMs）的推理时计算量可显著提升其推理能力，但重复采样方法未能充分利用外部反馈信号。本文提出Adaptive Branching Monte Carlo Tree Search (AB-MCTS)，一种新型框架，将重复采样扩展为有原则的多轮探索和利用，在搜索树的每个节点根据反馈动态决定是“扩展更宽”（生成新候选响应）还是“深入更深”（优化现有响应）。实验在复杂编码和工程任务中使用前沿模型评估，结果表明AB-MCTS 优于重复采样和标准Monte Carlo Tree Search，突出了结合LLMs响应多样性与多轮解决方案改进的重要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear at ICLR 2025 Workshop on Foundation Models in the Wild",
      "pdf_url": "http://arxiv.org/pdf/2503.04412v1",
      "published_date": "2025-03-06 13:10:40 UTC",
      "updated_date": "2025-03-06 13:10:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:47:12.728257"
    },
    {
      "arxiv_id": "2503.04406v1",
      "title": "Training-Free Graph Filtering via Multimodal Feature Refinement for Extremely Fast Multimodal Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Seung Roh",
        "Joo-Young Kim",
        "Jin-Duk Park",
        "Won-Yong Shin"
      ],
      "abstract": "Multimodal recommender systems improve the performance of canonical\nrecommender systems with no item features by utilizing diverse content types\nsuch as text, images, and videos, while alleviating inherent sparsity of\nuser-item interactions and accelerating user engagement. However, current\nneural network-based models often incur significant computational overhead due\nto the complex training process required to learn and integrate information\nfrom multiple modalities. To overcome this limitation, we propose\nMultiModal-Graph Filtering (MM-GF), a training-free method based on the notion\nof graph filtering (GF) for efficient and accurate multimodal recommendations.\nSpecifically, MM-GF first constructs multiple similarity graphs through\nnontrivial multimodal feature refinement such as robust scaling and vector\nshifting by addressing the heterogeneous characteristics across modalities.\nThen, MM-GF optimally fuses multimodal information using linear low-pass\nfilters across different modalities. Extensive experiments on real-world\nbenchmark datasets demonstrate that MM-GF not only improves recommendation\naccuracy by up to 13.35% compared to the best competitor but also dramatically\nreduces computational costs by achieving the runtime of less than 10 seconds.",
      "tldr_zh": "该研究针对多模态推荐系统面临的计算开销问题，提出了一种训练-free的方法：MultiModal-Graph Filtering (MM-GF)，基于graph filtering (GF)原理，实现高效的推荐过程。具体而言，MM-GF 通过多模态特征精炼（如robust scaling和vector shifting）来构建多个相似性图，并使用linear low-pass filters在不同模态之间最佳融合信息，从而处理模态异质性。实验在真实基准数据集上显示，MM-GF 比最佳竞争对手提高了多达13.35%的推荐准确率，同时将运行时间缩短至不到10秒，大大降低了计算成本。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "cs.SI",
        "math.IT"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, 6 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04406v1",
      "published_date": "2025-03-06 13:00:53 UTC",
      "updated_date": "2025-03-06 13:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:47:24.175045"
    },
    {
      "arxiv_id": "2503.04398v3",
      "title": "Speculative MoE: Communication Efficient Parallel MoE Inference with Speculative Token and Expert Pre-scheduling",
      "title_zh": "Speculative MoE：通信高效的并行 MoE 推理，采用推测性 Token 和 Expert 预调度",
      "authors": [
        "Yan Li",
        "Pengfei Zheng",
        "Shuang Chen",
        "Zewei Xu",
        "Yuanhao Lai",
        "Yunfei Du",
        "Zhengang Wang"
      ],
      "abstract": "MoE (Mixture of Experts) prevails as a neural architecture that can scale\nmodern transformer-based LLMs (Large Language Models) to unprecedented scales.\nNevertheless, large MoEs' great demands of computing power, memory capacity and\nmemory bandwidth make scalable serving a fundamental challenge and efficient\nparallel inference has become a requisite to attain adequate throughput under\nlatency constraints. DeepSpeed-MoE, one state-of-the-art MoE inference\nframework, adopts a 3D-parallel paradigm including EP (Expert Parallelism), TP\n(Tensor Parallel) and DP (Data Parallelism). However, our analysis shows\nDeepSpeed-MoE's inference efficiency is largely bottlenecked by EP, which is\nimplemented with costly all-to-all collectives to route token activation. Our\nwork aims to boost DeepSpeed-MoE by strategically reducing EP's communication\noverhead with a technique named Speculative MoE. Speculative MoE has two\nspeculative parallelization schemes, speculative token shuffling and\nspeculative expert grouping, which predict outstanding tokens' expert routing\npaths and pre-schedule tokens and experts across devices to losslessly trim\nEP's communication volume. Besides DeepSpeed-MoE, we also build Speculative MoE\ninto a prevailing MoE inference engine SGLang. Experiments show Speculative MoE\ncan significantly boost state-of-the-art MoE inference frameworks on fast\nhomogeneous and slow heterogeneous interconnects.",
      "tldr_zh": "该论文针对 MoE (Mixture of Experts) 模型在大型语言模型 (LLMs) 中的并行推理效率问题，提出 Speculative MoE 方法，以减少 Expert Parallelism (EP) 中的通信开销。Speculative MoE 通过 speculative token shuffling 和 speculative expert grouping 两种方案，预测 tokens 的专家路由路径并预调度 tokens 和 experts，从而无损地降低通信量。实验结果显示，该方法显著提升了 DeepSpeed-MoE 和 SGLang 等框架在快速同构和缓慢异构互连环境下的推理性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04398v3",
      "published_date": "2025-03-06 12:52:22 UTC",
      "updated_date": "2025-03-19 02:03:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:47:42.265107"
    },
    {
      "arxiv_id": "2503.04392v1",
      "title": "AgentSafe: Safeguarding Large Language Model-based Multi-agent Systems via Hierarchical Data Management",
      "title_zh": "翻译失败",
      "authors": [
        "Junyuan Mao",
        "Fanci Meng",
        "Yifan Duan",
        "Miao Yu",
        "Xiaojun Jia",
        "Junfeng Fang",
        "Yuxuan Liang",
        "Kun Wang",
        "Qingsong Wen"
      ],
      "abstract": "Large Language Model based multi-agent systems are revolutionizing autonomous\ncommunication and collaboration, yet they remain vulnerable to security threats\nlike unauthorized access and data breaches. To address this, we introduce\nAgentSafe, a novel framework that enhances MAS security through hierarchical\ninformation management and memory protection. AgentSafe classifies information\nby security levels, restricting sensitive data access to authorized agents.\nAgentSafe incorporates two components: ThreatSieve, which secures communication\nby verifying information authority and preventing impersonation, and\nHierarCache, an adaptive memory management system that defends against\nunauthorized access and malicious poisoning, representing the first systematic\ndefense for agent memory. Experiments across various LLMs show that AgentSafe\nsignificantly boosts system resilience, achieving defense success rates above\n80% under adversarial conditions. Additionally, AgentSafe demonstrates\nscalability, maintaining robust performance as agent numbers and information\ncomplexity grow. Results underscore effectiveness of AgentSafe in securing MAS\nand its potential for real-world application.",
      "tldr_zh": "该研究提出了AgentSafe框架，用于提升Large Language Model-based Multi-agent Systems的安全性，针对未授权访问和数据泄露等威胁。AgentSafe通过分层信息管理和内存保护，包括ThreatSieve组件（验证信息权限并防止冒充）和HierarCache组件（自适应内存系统防御未授权访问及恶意投毒）。实验结果显示，该框架在各种LLMs上实现了超过80%的防御成功率，并在对抗条件下保持可扩展性。总体而言，AgentSafe为多智能体系统的安全提供了系统化解决方案，具有实际应用潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04392v1",
      "published_date": "2025-03-06 12:41:54 UTC",
      "updated_date": "2025-03-06 12:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:47:53.585061"
    },
    {
      "arxiv_id": "2503.04378v1",
      "title": "Dedicated Feedback and Edit Models Empower Inference-Time Scaling for Open-Ended General-Domain Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Zhilin Wang",
        "Jiaqi Zeng",
        "Olivier Delalleau",
        "Daniel Egert",
        "Ellie Evans",
        "Hoo-Chang Shin",
        "Felipe Soares",
        "Yi Dong",
        "Oleksii Kuchaiev"
      ],
      "abstract": "Inference-Time Scaling has been critical to the success of recent models such\nas OpenAI o1 and DeepSeek R1. However, many techniques used to train models for\ninference-time scaling require tasks to have answers that can be verified,\nlimiting their application to domains such as math, coding and logical\nreasoning. We take inspiration from how humans make first attempts, ask for\ndetailed feedback from others and make improvements based on such feedback\nacross a wide spectrum of open-ended endeavors. To this end, we collect data\nfor and train dedicated Feedback and Edit Models that are capable of performing\ninference-time scaling for open-ended general-domain tasks. In our setup, one\nmodel generates an initial response, which are given feedback by a second\nmodel, that are then used by a third model to edit the response. We show that\nperformance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo\ncan be boosted by scaling the number of initial response drafts, effective\nfeedback and edited responses. When scaled optimally, our setup based on 70B\nmodels from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7\nas of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and\nDeepSeek R1 with 92.3.",
      "tldr_zh": "本研究提出了一种基于专用的 Feedback and Edit Models 的方法，以实现 Inference-Time Scaling，适用于开放式通用领域任务，这些任务通常无法通过验证答案来优化。该系统模仿人类过程，由一个模型生成初始响应、第二个模型提供详细反馈，以及第三个模型基于反馈进行编辑，从而提升响应质量。实验结果表明，通过优化初始响应草稿、反馈和编辑过程，使用 Llama 3 家族的 70B 模型，在 Arena Hard 基准上达到了 92.7 的 SoTA 性能，超过了 OpenAI o1-preview-2024-09-12 的 90.4 和 DeepSeek R1 的 92.3。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04378v1",
      "published_date": "2025-03-06 12:30:24 UTC",
      "updated_date": "2025-03-06 12:30:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:48:06.711191"
    },
    {
      "arxiv_id": "2503.04363v1",
      "title": "Causally Reliable Concept Bottleneck Models",
      "title_zh": "因果可靠的概念瓶颈模型",
      "authors": [
        "Giovanni De Felice",
        "Arianna Casanova Flores",
        "Francesco De Santis",
        "Silvia Santini",
        "Johannes Schneider",
        "Pietro Barbiero",
        "Alberto Termine"
      ],
      "abstract": "Concept-based models are an emerging paradigm in deep learning that\nconstrains the inference process to operate through human-interpretable\nconcepts, facilitating explainability and human interaction. However, these\narchitectures, on par with popular opaque neural models, fail to account for\nthe true causal mechanisms underlying the target phenomena represented in the\ndata. This hampers their ability to support causal reasoning tasks, limits\nout-of-distribution generalization, and hinders the implementation of fairness\nconstraints. To overcome these issues, we propose \\emph{Causally reliable\nConcept Bottleneck Models} (C$^2$BMs), a class of concept-based architectures\nthat enforce reasoning through a bottleneck of concepts structured according to\na model of the real-world causal mechanisms. We also introduce a pipeline to\nautomatically learn this structure from observational data and\n\\emph{unstructured} background knowledge (e.g., scientific literature).\nExperimental evidence suggest that C$^2$BM are more interpretable, causally\nreliable, and improve responsiveness to interventions w.r.t. standard opaque\nand concept-based models, while maintaining their accuracy.",
      "tldr_zh": "该论文指出，现有的Concept-based模型虽能提升深度学习的解释性和人类交互，但未能考虑数据中目标现象的真实因果机制，导致在因果推理、泛化和公平性方面存在局限。作者提出Causally reliable Concept Bottleneck Models (C²BMs)，一种新架构，通过结构化概念瓶颈强制模型遵守真实世界的因果机制，并引入一个管道从观察数据和非结构化背景知识（如科学文献）中自动学习这一结构。实验结果显示，C²BMs 相较于标准黑箱模型和传统概念-based 模型，更具可解释性、因果可靠性和对干预的响应能力，同时保持了准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04363v1",
      "published_date": "2025-03-06 12:06:54 UTC",
      "updated_date": "2025-03-06 12:06:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:48:21.324991"
    },
    {
      "arxiv_id": "2503.04362v1",
      "title": "A Generalist Cross-Domain Molecular Learning Framework for Structure-Based Drug Discovery",
      "title_zh": "通用跨领域分子学习框架，用于基于结构的药物发现",
      "authors": [
        "Yiheng Zhu",
        "Mingyang Li",
        "Junlong Liu",
        "Kun Fu",
        "Jiansheng Wu",
        "Qiuyi Li",
        "Mingze Yin",
        "Jieping Ye",
        "Jian Wu",
        "Zheng Wang"
      ],
      "abstract": "Structure-based drug discovery (SBDD) is a systematic scientific process that\ndevelops new drugs by leveraging the detailed physical structure of the target\nprotein. Recent advancements in pre-trained models for biomolecules have\ndemonstrated remarkable success across various biochemical applications,\nincluding drug discovery and protein engineering. However, in most approaches,\nthe pre-trained models primarily focus on the characteristics of either small\nmolecules or proteins, without delving into their binding interactions which\nare essential cross-domain relationships pivotal to SBDD. To fill this gap, we\npropose a general-purpose foundation model named BIT (an abbreviation for\nBiomolecular Interaction Transformer), which is capable of encoding a range of\nbiochemical entities, including small molecules, proteins, and protein-ligand\ncomplexes, as well as various data formats, encompassing both 2D and 3D\nstructures. Specifically, we introduce Mixture-of-Domain-Experts (MoDE) to\nhandle the biomolecules from diverse biochemical domains and\nMixture-of-Structure-Experts (MoSE) to capture positional dependencies in the\nmolecular structures. The proposed mixture-of-experts approach enables BIT to\nachieve both deep fusion and domain-specific encoding, effectively capturing\nfine-grained molecular interactions within protein-ligand complexes. Then, we\nperform cross-domain pre-training on the shared Transformer backbone via\nseveral unified self-supervised denoising tasks. Experimental results on\nvarious benchmarks demonstrate that BIT achieves exceptional performance in\ndownstream tasks, including binding affinity prediction, structure-based\nvirtual screening, and molecular property prediction.",
      "tldr_zh": "本研究针对结构-based 药物发现 (SBDD) 中的局限性，提出一个通用跨领域分子学习框架 BIT (Biomolecular Interaction Transformer)，旨在编码小分子、蛋白和蛋白-配体复合物等生化实体，同时处理 2D 和 3D 结构。BIT 引入 Mixture-of-Domain-Experts (MoDE) 来管理不同生化领域的生物分子，以及 Mixture-of-Structure-Experts (MoSE) 来捕捉分子结构的位移依赖性，从而实现深度融合和精细分子互动编码。模型通过统一的自我监督去噪任务在共享 Transformer 骨干上进行跨领域预训练。实验结果显示，BIT 在结合亲和力预测、基于结构的虚拟筛选和分子属性预测等下游任务中表现出色，显著提升了 SBDD 的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04362v1",
      "published_date": "2025-03-06 12:04:56 UTC",
      "updated_date": "2025-03-06 12:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:48:31.217294"
    },
    {
      "arxiv_id": "2503.04866v1",
      "title": "Privacy in Responsible AI: Approaches to Facial Recognition from Cloud Providers",
      "title_zh": "负责任的 AI 中的隐私：云提供商的面部识别方法",
      "authors": [
        "Anna Elivanova"
      ],
      "abstract": "As the use of facial recognition technology is expanding in different\ndomains, ensuring its responsible use is gaining more importance. This paper\nconducts a comprehensive literature review of existing studies on facial\nrecognition technology from the perspective of privacy, which is one of the key\nResponsible AI principles.\n  Cloud providers, such as Microsoft, AWS, and Google, are at the forefront of\ndelivering facial-related technology services, but their approaches to\nresponsible use of these technologies vary significantly. This paper compares\nhow these cloud giants implement the privacy principle into their facial\nrecognition and detection services. By analysing their approaches, it\nidentifies both common practices and notable differences. The results of this\nresearch will be valuable for developers and businesses by providing them\ninsights into best practices of three major companies for integration\nresponsible AI, particularly privacy, into their cloud-based facial recognition\ntechnologies.",
      "tldr_zh": "这篇论文通过全面文献综述，探讨了人脸识别技术在Responsible AI框架下的隐私原则实施情况。研究重点比较了Microsoft、AWS和Google等云提供商在人脸识别和检测服务中的隐私处理方法，分析了它们的共同实践和显著差异。这些发现为开发者和企业提供了宝贵见解，帮助他们在云-based人脸识别技术中更好地整合Responsible AI的最佳实践。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04866v1",
      "published_date": "2025-03-06 12:04:12 UTC",
      "updated_date": "2025-03-06 12:04:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:48:40.692084"
    },
    {
      "arxiv_id": "2503.04357v1",
      "title": "scDD: Latent Codes Based scRNA-seq Dataset Distillation with Foundation Model Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Yu",
        "Jianan Han",
        "Yang Liu",
        "Qingchao Chen"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) technology has profiled hundreds of\nmillions of human cells across organs, diseases, development and perturbations\nto date. However, the high-dimensional sparsity, batch effect noise, category\nimbalance, and ever-increasing data scale of the original sequencing data pose\nsignificant challenges for multi-center knowledge transfer, data fusion, and\ncross-validation between scRNA-seq datasets. To address these barriers, (1) we\nfirst propose a latent codes-based scRNA-seq dataset distillation framework\nnamed scDD, which transfers and distills foundation model knowledge and\noriginal dataset information into a compact latent space and generates\nsynthetic scRNA-seq dataset by a generator to replace the original dataset.\nThen, (2) we propose a single-step conditional diffusion generator named SCDG,\nwhich perform single-step gradient back-propagation to help scDD optimize\ndistillation quality and avoid gradient decay caused by multi-step\nback-propagation. Meanwhile, SCDG ensures the scRNA-seq data characteristics\nand inter-class discriminability of the synthetic dataset through flexible\nconditional control and generation quality assurance. Finally, we propose a\ncomprehensive benchmark to evaluate the performance of scRNA-seq dataset\ndistillation in different data analysis tasks. It is validated that our\nproposed method can achieve 7.61% absolute and 15.70% relative improvement over\nprevious state-of-the-art methods on average task.",
      "tldr_zh": "该论文针对单细胞 RNA 测序 (scRNA-seq) 数据的高维稀疏性、批次效应噪声、类别不平衡等问题，提出了 scDD 框架，该框架基于潜在代码蒸馏数据集，将基础模型知识和原始信息转移到紧凑的潜在空间，并通过生成器创建合成数据集以便于知识转移和数据融合。scDD 结合了单步条件扩散生成器 (SCDG)，该生成器采用单步梯度反向传播优化蒸馏质量，避免多步传播的梯度衰减，同时确保合成数据的 scRNA-seq 特性及类别间可区分性。为评估性能，论文建立了一个全面基准，结果显示 scDD 在不同数据分析任务上比现有最先进方法平均绝对提高了 7.61%，相对提高了 15.70%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04357v1",
      "published_date": "2025-03-06 12:01:20 UTC",
      "updated_date": "2025-03-06 12:01:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:48:54.679994"
    },
    {
      "arxiv_id": "2503.04343v1",
      "title": "Talking Back -- human input and explanations to interactive AI systems",
      "title_zh": "翻译失败",
      "authors": [
        "Alan Dix",
        "Tommaso Turchi",
        "Ben Wilson",
        "Anna Monreale",
        "Matt Roach"
      ],
      "abstract": "While XAI focuses on providing AI explanations to humans, can the reverse -\nhumans explaining their judgments to AI - foster richer, synergistic human-AI\nsystems? This paper explores various forms of human inputs to AI and examines\nhow human explanations can guide machine learning models toward automated\njudgments and explanations that align more closely with human concepts.",
      "tldr_zh": "这篇论文探讨了“Talking Back”概念，即人类向 AI 系统提供输入和解释，以逆转传统 XAI（可解释 AI）模式，从而构建更丰富且协同的人类-AI 系统。论文考察了各种人类输入形式，并分析了如何利用人类解释来指导机器学习模型，使其自动判断和解释更紧密地与人类概念对齐。通过这种互动方式，研究旨在提升 AI 的适应性和可靠性，为未来的人类-AI 协作奠定基础。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "I.2"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04343v1",
      "published_date": "2025-03-06 11:39:46 UTC",
      "updated_date": "2025-03-06 11:39:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:49:05.021056"
    },
    {
      "arxiv_id": "2503.04328v1",
      "title": "Solving Word-Sense Disambiguation and Word-Sense Induction with Dictionary Examples",
      "title_zh": "利用字典示例解决词义消歧和词义归纳",
      "authors": [
        "Tadej Škvorc",
        "Marko Robnik-Šikonja"
      ],
      "abstract": "Many less-resourced languages struggle with a lack of large, task-specific\ndatasets that are required for solving relevant tasks with modern\ntransformer-based large language models (LLMs). On the other hand, many\nlinguistic resources, such as dictionaries, are rarely used in this context\ndespite their large information contents. We show how LLMs can be used to\nextend existing language resources in less-resourced languages for two\nimportant tasks: word-sense disambiguation (WSD) and word-sense induction\n(WSI). We approach the two tasks through the related but much more accessible\nword-in-context (WiC) task where, given a pair of sentences and a target word,\na classification model is tasked with predicting whether the sense of a given\nword differs between sentences. We demonstrate that a well-trained model for\nthis task can distinguish between different word senses and can be adapted to\nsolve the WSD and WSI tasks. The advantage of using the WiC task, instead of\ndirectly predicting senses, is that the WiC task does not need pre-constructed\nsense inventories with a sufficient number of examples for each sense, which\nare rarely available in less-resourced languages. We show that sentence pairs\nfor the WiC task can be successfully generated from dictionary examples using\nLLMs. The resulting prediction models outperform existing models on WiC, WSD,\nand WSI tasks. We demonstrate our methodology on the Slovene language, where a\nmonolingual dictionary is available, but word-sense resources are tiny.",
      "tldr_zh": "这篇论文提出了一种利用大型语言模型 (LLMs) 从字典例子生成 word-in-context (WiC) 数据集的方法，以解决资源不足语言中的词义消歧 (WSD) 和词义归纳 (WSI) 问题。相比直接预测词义，该方法通过 WiC 任务避免了依赖预构建词义库存的需求，从而使模型更容易适应少资源语言。实验结果显示，基于此方法训练的模型在 WiC、WSD 和 WSI 任务上优于现有模型，并在斯洛文尼亚语上验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.04328v1",
      "published_date": "2025-03-06 11:27:55 UTC",
      "updated_date": "2025-03-06 11:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:49:18.502093"
    },
    {
      "arxiv_id": "2503.04315v1",
      "title": "Provable Robust Overfitting Mitigation in Wasserstein Distributionally Robust Optimization",
      "title_zh": "在瓦瑟斯坦分布鲁棒优化中可证明的鲁棒过拟合缓解",
      "authors": [
        "Shuang Liu",
        "Yihan Wang",
        "Yifan Zhu",
        "Yibo Miao",
        "Xiao-Shan Gao"
      ],
      "abstract": "Wasserstein distributionally robust optimization (WDRO) optimizes against\nworst-case distributional shifts within a specified uncertainty set, leading to\nenhanced generalization on unseen adversarial examples, compared to standard\nadversarial training which focuses on pointwise adversarial perturbations.\nHowever, WDRO still suffers fundamentally from the robust overfitting problem,\nas it does not consider statistical error. We address this gap by proposing a\nnovel robust optimization framework under a new uncertainty set for adversarial\nnoise via Wasserstein distance and statistical error via Kullback-Leibler\ndivergence, called the Statistically Robust WDRO. We establish a robust\ngeneralization bound for the new optimization framework, implying that\nout-of-distribution adversarial performance is at least as good as the\nstatistically robust training loss with high probability. Furthermore, we\nderive conditions under which Stackelberg and Nash equilibria exist between the\nlearner and the adversary, giving an optimal robust model in certain sense.\nFinally, through extensive experiments, we demonstrate that our method\nsignificantly mitigates robust overfitting and enhances robustness within the\nframework of WDRO.",
      "tldr_zh": "本研究针对Wasserstein distributionally robust optimization (WDRO)中存在的robust overfitting问题，提出了一种新框架Statistically Robust WDRO，通过结合Wasserstein distance处理adversarial noise和Kullback-Leibler divergence处理statistical error，构建了一个新的uncertainty set。研究建立了robust generalization bound，确保out-of-distribution adversarial performance至少与statistically robust training loss相当，并导出了Stackelberg和Nash equilibria的条件，以获得optimal robust model。该方法经广泛实验验证，显著缓解了robust overfitting并提升了WDRO框架下的整体robustness。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04315v1",
      "published_date": "2025-03-06 10:58:35 UTC",
      "updated_date": "2025-03-06 10:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:49:29.519364"
    },
    {
      "arxiv_id": "2503.04302v1",
      "title": "Malware Detection at the Edge with Lightweight LLMs: A Performance Evaluation",
      "title_zh": "使用轻量级 LLMs 的边缘恶意软件检测：性能评估",
      "authors": [
        "Christian Rondanini",
        "Barbara Carminati",
        "Elena Ferrari",
        "Antonio Gaudiano",
        "Ashish Kundu"
      ],
      "abstract": "The rapid evolution of malware attacks calls for the development of\ninnovative detection methods, especially in resource-constrained edge\ncomputing. Traditional detection techniques struggle to keep up with modern\nmalware's sophistication and adaptability, prompting a shift towards advanced\nmethodologies like those leveraging Large Language Models (LLMs) for enhanced\nmalware detection. However, deploying LLMs for malware detection directly at\nedge devices raises several challenges, including ensuring accuracy in\nconstrained environments and addressing edge devices' energy and computational\nlimits. To tackle these challenges, this paper proposes an architecture\nleveraging lightweight LLMs' strengths while addressing limitations like\nreduced accuracy and insufficient computational power. To evaluate the\neffectiveness of the proposed lightweight LLM-based approach for edge\ncomputing, we perform an extensive experimental evaluation using several\nstate-of-the-art lightweight LLMs. We test them with several publicly available\ndatasets specifically designed for edge and IoT scenarios and different edge\nnodes with varying computational power and characteristics.",
      "tldr_zh": "本研究针对恶意软件（Malware）攻击在资源受限的边缘计算（Edge Computing）环境中的检测挑战，提出了一种基于轻量级大型语言模型（Lightweight LLMs）的架构，以提升检测准确性和适应计算限制。  \n该架构优化了LLMs的部署问题，包括减少准确性损失和缓解能量消耗，旨在为边缘设备提供高效的恶意软件检测解决方案。  \n通过广泛实验，使用多种先进轻量级LLMs和公开数据集，在不同边缘节点上进行评估，结果证明了该方法的有效性，为边缘计算安全提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04302v1",
      "published_date": "2025-03-06 10:42:18 UTC",
      "updated_date": "2025-03-06 10:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:49:42.281459"
    },
    {
      "arxiv_id": "2503.04865v1",
      "title": "E4: Energy-Efficient DNN Inference for Edge Video Analytics Via Early-Exit and DVFS",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Zhang",
        "Yang Zhao",
        "Ming-Ching Chang",
        "Changyao Lin",
        "Jie Liu"
      ],
      "abstract": "Deep neural network (DNN) models are increasingly popular in edge video\nanalytic applications. However, the compute-intensive nature of DNN models pose\nchallenges for energy-efficient inference on resource-constrained edge devices.\nMost existing solutions focus on optimizing DNN inference latency and accuracy,\noften overlooking energy efficiency. They also fail to account for the varying\ncomplexity of video frames, leading to sub-optimal performance in edge video\nanalytics. In this paper, we propose an Energy-Efficient Early-Exit (E4)\nframework that enhances DNN inference efficiency for edge video analytics by\nintegrating a novel early-exit mechanism with dynamic voltage and frequency\nscaling (DVFS) governors. It employs an attention-based cascade module to\nanalyze video frame diversity and automatically determine optimal DNN exit\npoints. Additionally, E4 features a just-in-time (JIT) profiler that uses\ncoordinate descent search to co-optimize CPU and GPU clock frequencies for each\nlayer before the DNN exit points. Extensive evaluations demonstrate that E4\noutperforms current state-of-the-art methods, achieving up to 2.8x speedup and\n26% average energy saving while maintaining high accuracy.",
      "tldr_zh": "该论文针对边缘视频分析中DNN模型的计算密集问题，提出E4框架，通过整合早退出（Early-Exit）机制和动态电压频率缩放（DVFS）技术来提升能量效率。E4框架利用基于注意力的级联模块分析视频帧多样性，自动确定最佳DNN退出点，并采用即时分析器（JIT profiler）结合坐标下降搜索优化CPU和GPU时钟频率。实验结果显示，E4相较现有方法实现高达2.8倍的加速和平均26%的能量节省，同时保持高准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 5 figures, to be published in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04865v1",
      "published_date": "2025-03-06 10:41:28 UTC",
      "updated_date": "2025-03-06 10:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:49:52.755072"
    },
    {
      "arxiv_id": "2503.04299v2",
      "title": "Mapping AI Benchmark Data to Quantitative Risk Estimates Through Expert Elicitation",
      "title_zh": "通过专家征询将 AI 基准测试数据映射到定量风险估计",
      "authors": [
        "Malcolm Murray",
        "Henry Papadatos",
        "Otter Quarks",
        "Pierre-François Gimenez",
        "Simeon Campos"
      ],
      "abstract": "The literature and multiple experts point to many potential risks from large\nlanguage models (LLMs), but there are still very few direct measurements of the\nactual harms posed. AI risk assessment has so far focused on measuring the\nmodels' capabilities, but the capabilities of models are only indicators of\nrisk, not measures of risk. Better modeling and quantification of AI risk\nscenarios can help bridge this disconnect and link the capabilities of LLMs to\ntangible real-world harm. This paper makes an early contribution to this field\nby demonstrating how existing AI benchmarks can be used to facilitate the\ncreation of risk estimates. We describe the results of a pilot study in which\nexperts use information from Cybench, an AI benchmark, to generate probability\nestimates. We show that the methodology seems promising for this purpose, while\nnoting improvements that can be made to further strengthen its application in\nquantitative AI risk assessment.",
      "tldr_zh": "该论文探讨了如何通过专家征询（expert elicitation）将AI基准数据映射到量化风险估计（quantitative risk estimates），以更好地评估大型语言模型（LLMs）的潜在风险。作者指出，当前AI风险评估主要关注模型能力，但这仅是风险的间接指标，而非直接测量。论文通过一个试点研究，使用Cybench等AI基准，帮助专家生成风险概率估计，结果显示该方法具有前景，但需进一步改进以增强其在量化AI风险评估中的应用。总的来说，这为将LLMs能力与实际危害联系起来提供了初步框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04299v2",
      "published_date": "2025-03-06 10:39:47 UTC",
      "updated_date": "2025-03-10 13:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:50:05.328736"
    },
    {
      "arxiv_id": "2503.04291v1",
      "title": "MathMistake Checker: A Comprehensive Demonstration for Step-by-Step Math Problem Mistake Finding by Prompt-Guided LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyang Zhang",
        "Zhuoxuan Jiang",
        "Haotian Zhang",
        "Lin Lin",
        "Shaohua Zhang"
      ],
      "abstract": "We propose a novel system, MathMistake Checker, designed to automate\nstep-by-step mistake finding in mathematical problems with lengthy answers\nthrough a two-stage process. The system aims to simplify grading, increase\nefficiency, and enhance learning experiences from a pedagogical perspective. It\nintegrates advanced technologies, including computer vision and the\nchain-of-thought capabilities of the latest large language models (LLMs). Our\nsystem supports open-ended grading without reference answers and promotes\npersonalized learning by providing targeted feedback. We demonstrate its\neffectiveness across various types of math problems, such as calculation and\nword problems.",
      "tldr_zh": "我们提出了一种名为 MathMistake Checker 的系统，通过两阶段过程，利用提示引导的 LLMs 和 chain-of-thought 能力以及计算机视觉技术，自动化数学问题的逐步错误检测。该系统简化了评分过程，提高效率，并从教育角度提供个性化反馈，支持无参考答案的开放式评估。在各种数学问题（如计算和文字问题）上，系统证明了其有效性，增强了学习体验。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04291v1",
      "published_date": "2025-03-06 10:19:01 UTC",
      "updated_date": "2025-03-06 10:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:50:17.205391"
    },
    {
      "arxiv_id": "2503.04290v1",
      "title": "How Do Hackathons Foster Creativity? Towards AI Collaborative Evaluation of Creativity at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Jeanette Falk",
        "Yiyi Chen",
        "Janet Rafner",
        "Mike Zhang",
        "Johannes Bjerva",
        "Alexander Nolte"
      ],
      "abstract": "Hackathons have become popular collaborative events for accelerating the\ndevelopment of creative ideas and prototypes. There are several case studies\nshowcasing creative outcomes across domains such as industry, education, and\nresearch. However, there are no large-scale studies on creativity in hackathons\nwhich can advance theory on how hackathon formats lead to creative outcomes. We\nconducted a computational analysis of 193,353 hackathon projects. By\noperationalizing creativity through usefulness and novelty, we refined our\ndataset to 10,363 projects, allowing us to analyze how participant\ncharacteristics, collaboration patterns, and hackathon setups influence the\ndevelopment of creative projects. The contribution of our paper is twofold: We\nidentified means for organizers to foster creativity in hackathons. We also\nexplore the use of large language models (LLMs) to augment the evaluation of\ncreative outcomes and discuss challenges and opportunities of doing this, which\nhas implications for creativity research at large.",
      "tldr_zh": "这篇论文通过对193,353个hackathon项目的计算分析，探讨了hackathon如何促进创意，特别关注参与者特征、合作模式和设置的影响。作者将创意操作化为usefulness（有用性）和novelty（新颖性），并将数据集精炼到10,363个项目，以揭示这些因素如何驱动创意成果。主要贡献包括：识别出组织者可采用的策略来提升hackathon中的创意，并探索使用large language models (LLMs)来辅助大规模创意评估，同时讨论了其挑战和对创意研究的更广泛启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted in Proceedings of the 2025 CHI Conference on Human Factors\n  in Computing Systems",
      "pdf_url": "http://arxiv.org/pdf/2503.04290v1",
      "published_date": "2025-03-06 10:17:52 UTC",
      "updated_date": "2025-03-06 10:17:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:50:30.096499"
    },
    {
      "arxiv_id": "2503.04283v1",
      "title": "Explainable AI in Time-Sensitive Scenarios: Prefetched Offline Explanation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Fabio Michele Russo",
        "Carlo Metta",
        "Anna Monreale",
        "Salvatore Rinzivillo",
        "Fabio Pinelli"
      ],
      "abstract": "As predictive machine learning models become increasingly adopted and\nadvanced, their role has evolved from merely predicting outcomes to actively\nshaping them. This evolution has underscored the importance of Trustworthy AI,\nhighlighting the necessity to extend our focus beyond mere accuracy and toward\na comprehensive understanding of these models' behaviors within the specific\ncontexts of their applications. To further progress in explainability, we\nintroduce Poem, Prefetched Offline Explanation Model, a model-agnostic, local\nexplainability algorithm for image data. The algorithm generates exemplars,\ncounterexemplars and saliency maps to provide quick and effective explanations\nsuitable for time-sensitive scenarios. Leveraging an existing local algorithm,\n\\poem{} infers factual and counterfactual rules from data to create\nillustrative examples and opposite scenarios with an enhanced stability by\ndesign. A novel mechanism then matches incoming test points with an explanation\nbase and produces diverse exemplars, informative saliency maps and believable\ncounterexemplars. Experimental results indicate that Poem outperforms its\npredecessor Abele in speed and ability to generate more nuanced and varied\nexemplars alongside more insightful saliency maps and valuable\ncounterexemplars.",
      "tldr_zh": "该研究强调了可解释 AI 在时间敏感场景中的重要性，提出了一种模型无关的本地解释算法——Poem（Prefetched Offline Explanation Model），用于图像数据。该算法通过从数据中推断事实和反事实规则，生成 exemplars（样本）、counterexemplars（反样本）和 saliency maps（显著性图），以提供快速、稳定的解释。Poem 利用现有算法并引入匹配机制，提升了解释的多样性和洞察力；实验结果显示，它在速度和生成质量上优于前身 Abele，产出更细致多样的样本和更有价值的反样本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04283v1",
      "published_date": "2025-03-06 10:09:20 UTC",
      "updated_date": "2025-03-06 10:09:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:50:42.015479"
    },
    {
      "arxiv_id": "2503.04280v2",
      "title": "Towards Autonomous Reinforcement Learning for Real-World Robotic Manipulation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Niccolò Turcato",
        "Matteo Iovino",
        "Aris Synodinos",
        "Alberto Dalla Libera",
        "Ruggero Carli",
        "Pietro Falco"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) and Visual Language\nModels (VLMs) have significantly impacted robotics, enabling high-level\nsemantic motion planning applications. Reinforcement Learning (RL), a\ncomplementary paradigm, enables agents to autonomously optimize complex\nbehaviors through interaction and reward signals. However, designing effective\nreward functions for RL remains challenging, especially in real-world tasks\nwhere sparse rewards are insufficient and dense rewards require elaborate\ndesign. In this work, we propose Autonomous Reinforcement learning for Complex\nHumanInformed Environments (ARCHIE), an unsupervised pipeline leveraging GPT-4,\na pre-trained LLM, to generate reward functions directly from natural language\ntask descriptions. The rewards are used to train RL agents in simulated\nenvironments, where we formalize the reward generation process to enhance\nfeasibility. Additionally, GPT-4 automates the coding of task success criteria,\ncreating a fully automated, one-shot procedure for translating human-readable\ntext into deployable robot skills. Our approach is validated through extensive\nsimulated experiments on single-arm and bi-manual manipulation tasks using an\nABB YuMi collaborative robot, highlighting its practicality and effectiveness.\nTasks are demonstrated on the real robot setup.",
      "tldr_zh": "该论文探讨了如何利用 Large Language Models (LLMs) 和 Visual Language Models (VLMs) 实现自主强化学习 (RL) 在真实世界机器人操纵任务中的应用，以解决奖励函数设计难题。研究提出 Autonomous Reinforcement learning for Complex HumanInformed Environments (ARCHIE) 框架，使用 GPT-4 从自然语言任务描述自动生成奖励函数和任务成功标准，实现无监督的自动化流程。实验在模拟环境中训练 RL 代理，并通过 ABB YuMi 机器人的单臂和双臂操纵任务验证了其有效性，最终在真实机器人设置中成功演示了可部署的机器人技能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04280v2",
      "published_date": "2025-03-06 10:08:44 UTC",
      "updated_date": "2025-03-07 10:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:50:53.583966"
    },
    {
      "arxiv_id": "2503.04267v1",
      "title": "Prompt Programming: A Platform for Dialogue-based Computational Problem Solving with Generative AI Models",
      "title_zh": "翻译失败",
      "authors": [
        "Victor-Alexandru Pădurean",
        "Paul Denny",
        "Alkis Gotovos",
        "Adish Singla"
      ],
      "abstract": "Computing students increasingly rely on generative AI tools for programming\nassistance, often without formal instruction or guidance. This highlights a\nneed to teach students how to effectively interact with AI models, particularly\nthrough natural language prompts, to generate and critically evaluate code for\nsolving computational tasks. To address this, we developed a novel platform for\nprompt programming that enables authentic dialogue-based interactions, supports\nproblems involving multiple interdependent functions, and offers on-request\nexecution of generated code. Data analysis from over 900 students in an\nintroductory programming course revealed high engagement, with the majority of\nprompts occurring within multi-turn dialogues. Problems with multiple\ninterdependent functions encouraged iterative refinement, with progression\ngraphs highlighting several common strategies. Students were highly selective\nabout the code they chose to test, suggesting that on-request execution of\ngenerated code promoted critical thinking. Given the growing importance of\nlearning dialogue-based programming with AI, we provide this tool as a publicly\naccessible resource, accompanied by a corpus of programming problems for\neducational use.",
      "tldr_zh": "这篇论文介绍了Prompt Programming平台，一种支持对话式交互的工具，旨在教计算学生如何通过自然语言提示与generative AI模型有效互动，生成并评估代码以解决计算任务。该平台处理多个相互依赖函数的问题，提供多轮对话和按需代码执行功能，以鼓励迭代改进和批判性思考。通过分析超过900名入门编程课程学生的使用数据，发现学生参与度高，常见策略包括多轮对话和选择性代码测试。该平台作为公开教育资源发布，并附带编程问题语料库，以推动AI辅助编程学习。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Preprint of the ITiCSE'25 paper",
      "pdf_url": "http://arxiv.org/pdf/2503.04267v1",
      "published_date": "2025-03-06 09:56:07 UTC",
      "updated_date": "2025-03-06 09:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:51:05.324827"
    },
    {
      "arxiv_id": "2503.04262v1",
      "title": "Guidelines for Applying RL and MARL in Cybersecurity Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Vasilios Mavroudis",
        "Gregory Palmer",
        "Sara Farmer",
        "Kez Smithson Whitehead",
        "David Foster",
        "Adam Price",
        "Ian Miles",
        "Alberto Caron",
        "Stephen Pasteris"
      ],
      "abstract": "Reinforcement Learning (RL) and Multi-Agent Reinforcement Learning (MARL)\nhave emerged as promising methodologies for addressing challenges in automated\ncyber defence (ACD). These techniques offer adaptive decision-making\ncapabilities in high-dimensional, adversarial environments. This report\nprovides a structured set of guidelines for cybersecurity professionals and\nresearchers to assess the suitability of RL and MARL for specific use cases,\nconsidering factors such as explainability, exploration needs, and the\ncomplexity of multi-agent coordination. It also discusses key algorithmic\napproaches, implementation challenges, and real-world constraints, such as data\nscarcity and adversarial interference. The report further outlines open\nresearch questions, including policy optimality, agent cooperation levels, and\nthe integration of MARL systems into operational cybersecurity frameworks. By\nbridging theoretical advancements and practical deployment, these guidelines\naim to enhance the effectiveness of AI-driven cyber defence strategies.",
      "tldr_zh": "本报告提出了针对强化学习（RL）和多智能体强化学习（MARL）的应用指导方针，旨在帮助网络安全专业人士评估这些技术在自动化网络防御（ACD）中的适用性，尤其在高维敌对环境中提供自适应决策能力。指导方针考虑了关键因素如可解释性、探索需求和多智能体协调复杂度，同时讨论了算法方法、实施挑战（如数据稀缺性和敌对干扰）以及现实约束。最终，该报告桥接了理论进展与实际部署，突出了开放研究问题如策略最优性和代理合作水平，以提升AI驱动的网络防御策略有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04262v1",
      "published_date": "2025-03-06 09:46:16 UTC",
      "updated_date": "2025-03-06 09:46:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:51:17.952548"
    },
    {
      "arxiv_id": "2503.04261v1",
      "title": "VirtualXAI: A User-Centric Framework for Explainability Assessment Leveraging GPT-Generated Personas",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Makridis",
        "Vasileios Koukos",
        "Georgios Fatouros",
        "Dimosthenis Kyriazis"
      ],
      "abstract": "In today's data-driven era, computational systems generate vast amounts of\ndata that drive the digital transformation of industries, where Artificial\nIntelligence (AI) plays a key role. Currently, the demand for eXplainable AI\n(XAI) has increased to enhance the interpretability, transparency, and\ntrustworthiness of AI models. However, evaluating XAI methods remains\nchallenging: existing evaluation frameworks typically focus on quantitative\nproperties such as fidelity, consistency, and stability without taking into\naccount qualitative characteristics such as satisfaction and interpretability.\nIn addition, practitioners face a lack of guidance in selecting appropriate\ndatasets, AI models, and XAI methods -a major hurdle in human-AI collaboration.\nTo address these gaps, we propose a framework that integrates quantitative\nbenchmarking with qualitative user assessments through virtual personas based\non the \"Anthology\" of backstories of the Large Language Model (LLM). Our\nframework also incorporates a content-based recommender system that leverages\ndataset-specific characteristics to match new input data with a repository of\nbenchmarked datasets. This yields an estimated XAI score and provides tailored\nrecommendations for both the optimal AI model and the XAI method for a given\nscenario.",
      "tldr_zh": "该论文提出 VirtualXAI 框架，这是一个以用户为中心的系统，用于评估 eXplainable AI (XAI) 方法的解释性问题。该框架整合定量基准测试（如保真度、一致性和稳定性）和定性用户评估，通过基于 Large Language Model (LLM) 和 GPT 生成的虚拟人物 (personas) 来评估满意度和可解释性，同时使用内容-based recommender system 匹配数据集并推荐最佳 AI 模型和 XAI 方法。总体上，该框架解决了现有评估的局限性，提供更全面的指导，提升了人机协作的透明度和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04261v1",
      "published_date": "2025-03-06 09:44:18 UTC",
      "updated_date": "2025-03-06 09:44:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:51:30.250344"
    },
    {
      "arxiv_id": "2503.04863v1",
      "title": "Manboformer: Learning Gaussian Representations via Spatial-temporal Attention Mechanism",
      "title_zh": "Manboformer：通过时空注意力机制学习高斯表示",
      "authors": [
        "Ziyue Zhao",
        "Qining Qi",
        "Jianfa Ma"
      ],
      "abstract": "Compared with voxel-based grid prediction, in the field of 3D semantic\noccupation prediction for autonomous driving, GaussianFormer proposed using 3D\nGaussian to describe scenes with sparse 3D semantic Gaussian based on objects\nis another scheme with lower memory requirements. Each 3D Gaussian function\nrepresents a flexible region of interest and its semantic features, which are\niteratively refined by the attention mechanism. In the experiment, it is found\nthat the Gaussian function required by this method is larger than the query\nresolution of the original dense grid network, resulting in impaired\nperformance. Therefore, we consider optimizing GaussianFormer by using unused\ntemporal information. We learn the Spatial-Temporal Self-attention Mechanism\nfrom the previous grid-given occupation network and improve it to\nGaussianFormer. The experiment was conducted with the NuScenes dataset, and the\nexperiment is currently underway.",
      "tldr_zh": "该论文提出 Manboformer，一种优化 3D Gaussian 表示方法的框架，针对 GaussianFormer 在 3D 语义占用预测领域的性能问题（如所需 Gaussian 函数过大导致效果下降）进行改进。Manboformer 通过学习并改进 Spatial-Temporal Self-attention Mechanism，利用时序信息来增强空间-时间注意力机制，从而更好地精炼 3D Gaussian 的语义特征。实验在 NuScenes 数据集上进行，目前仍在进行中，旨在降低内存需求并提升自主驾驶场景的预测准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04863v1",
      "published_date": "2025-03-06 09:40:46 UTC",
      "updated_date": "2025-03-06 09:40:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:51:41.757940"
    },
    {
      "arxiv_id": "2503.04258v1",
      "title": "TAIL: Text-Audio Incremental Learning",
      "title_zh": "TAIL：文本-音频增量学习",
      "authors": [
        "Yingfei Sun",
        "Xu Gu",
        "Wei Ji",
        "Hanbin Zhao",
        "Hao Fei",
        "Yifang Yin",
        "Roger Zimmermann"
      ],
      "abstract": "Many studies combine text and audio to capture multi-modal information but\nthey overlook the model's generalization ability on new datasets. Introducing\nnew datasets may affect the feature space of the original dataset, leading to\ncatastrophic forgetting. Meanwhile, large model parameters can significantly\nimpact training performance. To address these limitations, we introduce a novel\ntask called Text-Audio Incremental Learning (TAIL) task for text-audio\nretrieval, and propose a new method, PTAT, Prompt Tuning for Audio-Text\nincremental learning. This method utilizes prompt tuning to optimize the model\nparameters while incorporating an audio-text similarity and feature\ndistillation module to effectively mitigate catastrophic forgetting. We\nbenchmark our method and previous incremental learning methods on AudioCaps,\nClotho, BBC Sound Effects and Audioset datasets, and our method outperforms\nprevious methods significantly, particularly demonstrating stronger resistance\nto forgetting on older datasets. Compared to the full-parameters Finetune\n(Sequential) method, our model only requires 2.42\\% of its parameters,\nachieving 4.46\\% higher performance.",
      "tldr_zh": "该论文引入了文本-音频增量学习(TAIL)任务，旨在解决多模态模型在新数据集上泛化能力不足和灾难性遗忘(catastrophic forgetting)的问题。作者提出了PTAT方法，通过prompt tuning优化模型参数，并整合音频-文本相似度和特征蒸馏(feature distillation)模块，有效缓解遗忘现象。在AudioCaps、Clotho、BBC Sound Effects和Audioset数据集上的基准测试中，PTAT显著优于现有增量学习方法，尤其在抵抗遗忘方面表现出色，且仅需全参数微调方法的2.42%参数，即实现了4.46%的性能提升。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "eess.AS",
        "I.2"
      ],
      "primary_category": "cs.SD",
      "comment": "4 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04258v1",
      "published_date": "2025-03-06 09:39:36 UTC",
      "updated_date": "2025-03-06 09:39:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:51:56.478399"
    },
    {
      "arxiv_id": "2503.04257v1",
      "title": "How to Move Your Dragon: Text-to-Motion Synthesis for Large-Vocabulary Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Wonkwang Lee",
        "Jongwon Jeong",
        "Taehong Moon",
        "Hyeon-Jong Kim",
        "Jaehyeon Kim",
        "Gunhee Kim",
        "Byeong-Uk Lee"
      ],
      "abstract": "Motion synthesis for diverse object categories holds great potential for 3D\ncontent creation but remains underexplored due to two key challenges: (1) the\nlack of comprehensive motion datasets that include a wide range of high-quality\nmotions and annotations, and (2) the absence of methods capable of handling\nheterogeneous skeletal templates from diverse objects. To address these\nchallenges, we contribute the following: First, we augment the Truebones Zoo\ndataset, a high-quality animal motion dataset covering over 70 species, by\nannotating it with detailed text descriptions, making it suitable for\ntext-based motion synthesis. Second, we introduce rig augmentation techniques\nthat generate diverse motion data while preserving consistent dynamics,\nenabling models to adapt to various skeletal configurations. Finally, we\nredesign existing motion diffusion models to dynamically adapt to arbitrary\nskeletal templates, enabling motion synthesis for a diverse range of objects\nwith varying structures. Experiments show that our method learns to generate\nhigh-fidelity motions from textual descriptions for diverse and even unseen\nobjects, setting a strong foundation for motion synthesis across diverse object\ncategories and skeletal templates. Qualitative results are available on this\nlink: t2m4lvo.github.io",
      "tldr_zh": "这篇论文解决了文本到动作合成（Text-to-Motion Synthesis）在多样对象类别中的挑战，包括缺乏全面动作数据集和处理异构骨骼模板（heterogeneous skeletal templates）的问题。研究者通过增强 Truebones Zoo 数据集（添加详细文本描述，覆盖超过70个物种）、引入 rig augmentation 技术（生成多样动作数据并保持动态一致性），以及重新设计动作扩散模型（motion diffusion models）以动态适应任意骨骼模板，从而实现对大词汇表对象的动作合成。实验结果显示，该方法能生成高保真度的动作，甚至适用于未见过对象，为跨不同类别和模板的动作合成奠定坚实基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04257v1",
      "published_date": "2025-03-06 09:39:09 UTC",
      "updated_date": "2025-03-06 09:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:52:06.448594"
    },
    {
      "arxiv_id": "2503.04256v1",
      "title": "Knowledge Retention for Continual Model-Based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yixiang Sun",
        "Haotian Fu",
        "Michael Littman",
        "George Konidaris"
      ],
      "abstract": "We propose DRAGO, a novel approach for continual model-based reinforcement\nlearning aimed at improving the incremental development of world models across\na sequence of tasks that differ in their reward functions but not the state\nspace or dynamics. DRAGO comprises two key components: Synthetic Experience\nRehearsal, which leverages generative models to create synthetic experiences\nfrom past tasks, allowing the agent to reinforce previously learned dynamics\nwithout storing data, and Regaining Memories Through Exploration, which\nintroduces an intrinsic reward mechanism to guide the agent toward revisiting\nrelevant states from prior tasks. Together, these components enable the agent\nto maintain a comprehensive and continually developing world model,\nfacilitating more effective learning and adaptation across diverse\nenvironments. Empirical evaluations demonstrate that DRAGO is able to preserve\nknowledge across tasks, achieving superior performance in various continual\nlearning scenarios.",
      "tldr_zh": "本论文提出了一种名为 DRAGO 的新方法，用于持续模型-based reinforcement learning，旨在通过序列任务的增量发展改进世界模型，这些任务的奖励函数不同但状态空间和动态相同。DRAGO 包括两个关键组件：Synthetic Experience Rehearsal，利用生成模型创建过去任务的合成经验来强化学到的动态，而不需存储数据；以及 Regaining Memories Through Exploration，通过内在奖励机制引导代理重新访问先前任务的相关状态。这些组件共同帮助代理维护一个全面且持续发展的世界模型，提升在多样环境中的学习和适应能力。实验评估显示，DRAGO 在各种 continual learning 场景中表现出色，能够有效保留知识并实现优于基线的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04256v1",
      "published_date": "2025-03-06 09:38:14 UTC",
      "updated_date": "2025-03-06 09:38:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:52:18.699628"
    },
    {
      "arxiv_id": "2503.04249v1",
      "title": "How to Mitigate Overfitting in Weak-to-strong Generalization?",
      "title_zh": "如何在弱到强泛化中缓解过拟合？",
      "authors": [
        "Junhao Shi",
        "Qinyuan Cheng",
        "Zhaoye Fei",
        "Yining Zheng",
        "Qipeng Guo",
        "Xipeng Qiu"
      ],
      "abstract": "Aligning powerful AI models on tasks that surpass human evaluation\ncapabilities is the central problem of \\textbf{superalignment}. To address this\nproblem, weak-to-strong generalization aims to elicit the capabilities of\nstrong models through weak supervisors and ensure that the behavior of strong\nmodels aligns with the intentions of weak supervisors without unsafe behaviors\nsuch as deception. Although weak-to-strong generalization exhibiting certain\ngeneralization capabilities, strong models exhibit significant overfitting in\nweak-to-strong generalization: Due to the strong fit ability of strong models,\nerroneous labels from weak supervisors may lead to overfitting in strong\nmodels. In addition, simply filtering out incorrect labels may lead to a\ndegeneration in question quality, resulting in a weak generalization ability of\nstrong models on hard questions. To mitigate overfitting in weak-to-strong\ngeneralization, we propose a two-stage framework that simultaneously improves\nthe quality of supervision signals and the quality of input questions.\nExperimental results in three series of large language models and two\nmathematical benchmarks demonstrate that our framework significantly improves\nPGR compared to naive weak-to-strong generalization, even achieving up to 100\\%\nPGR on some models.",
      "tldr_zh": "该论文探讨了在超对齐(superalignment)中，如何通过弱到强泛化(weak-to-strong generalization)缓解强模型的过度拟合(overfitting)问题，因为弱监督者(weak supervisors)的错误标签可能导致强模型出现不安全行为。作者提出一个两阶段框架(two-stage framework)，旨在同时提升监督信号的质量和输入问题的质量，以避免简单过滤标签导致的泛化能力下降。实验结果显示，在三个系列的大型语言模型和两个数学基准上，该框架显著提高了PGR(Proper Generalization Rate)，甚至在某些模型上达到100%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04249v1",
      "published_date": "2025-03-06 09:32:39 UTC",
      "updated_date": "2025-03-06 09:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:52:30.985451"
    },
    {
      "arxiv_id": "2503.04231v2",
      "title": "One-Shot Clustering for Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Maciej Krzysztof Zuziak",
        "Roberto Pellungrini",
        "Salvatore Rinzivillo"
      ],
      "abstract": "Federated Learning (FL) is a widespread and well adopted paradigm of\ndecentralized learning that allows training one model from multiple sources\nwithout the need to directly transfer data between participating clients. Since\nits inception in 2015, it has been divided into numerous sub-fields that deal\nwith application-specific issues, be it data heterogeneity or resource\nallocation. One such sub-field, Clustered Federated Learning (CFL), is dealing\nwith the problem of clustering the population of clients into separate cohorts\nto deliver personalized models. Although few remarkable works have been\npublished in this domain, the problem is still largely unexplored, as its basic\nassumption and settings are slightly different from standard FL. In this work,\nwe present One-Shot Clustered Federated Learning (OCFL), a clustering-agnostic\nalgorithm that can automatically detect the earliest suitable moment for\nclustering. Our algorithm is based on the computation of cosine similarity\nbetween gradients of the clients and a temperature measure that detects when\nthe federated model starts to converge. We empirically evaluate our methodology\nby testing various one-shot clustering algorithms for over thirty different\ntasks on three benchmark datasets. Our experiments showcase the good\nperformance of our approach when used to perform CFL in an automated manner\nwithout the need to adjust hyperparameters.",
      "tldr_zh": "这篇论文提出了 One-Shot Clustered Federated Learning (OCFL)，一种无需预设聚类的算法，用于 Federated Learning (FL) 中自动将客户端分组以提供个性化模型。OCFL 通过计算客户端梯度的 cosine similarity 和一个温度度量来检测模型收敛时的最佳聚类时机，从而简化了 Clustered Federated Learning (CFL) 的过程。实验在三个基准数据集上测试了超过三十个任务，结果显示 OCFL 表现出色，能够在自动化 CFL 中实现良好性能，而无需调整超参数。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04231v2",
      "published_date": "2025-03-06 09:12:43 UTC",
      "updated_date": "2025-04-29 16:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:52:42.456151"
    },
    {
      "arxiv_id": "2503.04219v1",
      "title": "Quantum-Inspired Reinforcement Learning in the Presence of Epistemic Ambivalence",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Habibi",
        "Saeed Ghoorchian",
        "Setareh Maghsudi"
      ],
      "abstract": "The complexity of online decision-making under uncertainty stems from the\nrequirement of finding a balance between exploiting known strategies and\nexploring new possibilities. Naturally, the uncertainty type plays a crucial\nrole in developing decision-making strategies that manage complexity\neffectively. In this paper, we focus on a specific form of uncertainty known as\nepistemic ambivalence (EA), which emerges from conflicting pieces of evidence\nor contradictory experiences. It creates a delicate interplay between\nuncertainty and confidence, distinguishing it from epistemic uncertainty that\ntypically diminishes with new information. Indeed, ambivalence can persist even\nafter additional knowledge is acquired. To address this phenomenon, we propose\na novel framework, called the epistemically ambivalent Markov decision process\n(EA-MDP), aiming to understand and control EA in decision-making processes.\nThis framework incorporates the concept of a quantum state from the quantum\nmechanics formalism, and its core is to assess the probability and reward of\nevery possible outcome. We calculate the reward function using quantum\nmeasurement techniques and prove the existence of an optimal policy and an\noptimal value function in the EA-MDP framework. We also propose the\nEA-epsilon-greedy Q-learning algorithm. To evaluate the impact of EA on\ndecision-making and the expedience of our framework, we study two distinct\nexperimental setups, namely the two-state problem and the lattice problem. Our\nresults show that using our methods, the agent converges to the optimal policy\nin the presence of EA.",
      "tldr_zh": "这篇论文探讨了在线决策中的不确定性问题，特别是 epistemic ambivalence (EA)——一种由冲突证据引起的持久不确定性，并提出了一种 quantum-inspired 的强化学习框架。作者引入了 epistemically ambivalent Markov decision process (EA-MDP)，借鉴量子力学概念，通过量子测量技术计算奖励函数，并证明了最优策略和最优价值函数的存在。同时，开发了 EA-epsilon-greedy Q-learning 算法，并在 two-state problem 和 lattice problem 的实验中验证，结果显示代理能够在 EA 的情况下收敛到最优策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph",
        "81P68, 81Q99, 68T05, 68Q12",
        "J.2; G.3; I.1.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04219v1",
      "published_date": "2025-03-06 08:54:31 UTC",
      "updated_date": "2025-03-06 08:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:52:55.345730"
    },
    {
      "arxiv_id": "2503.04859v1",
      "title": "Codebook Reduction and Saturation: Novel observations on Inductive Thematic Saturation for Large Language Models and initial coding in Thematic Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Stefano De Paoli",
        "Walter Stan Mathis"
      ],
      "abstract": "This paper reflects on the process of performing Thematic Analysis with Large\nLanguage Models (LLMs). Specifically, the paper deals with the problem of\nanalytical saturation of initial codes, as produced by LLMs. Thematic Analysis\nis a well-established qualitative analysis method composed of interlinked\nphases. A key phase is the initial coding, where the analysts assign labels to\ndiscrete components of a dataset. Saturation is a way to measure the validity\nof a qualitative analysis and relates to the recurrence and repetition of\ninitial codes. In the paper we reflect on how well LLMs achieve analytical\nsaturation and propose also a novel technique to measure Inductive Thematic\nSaturation (ITS). This novel technique leverages a programming framework called\nDSPy. The proposed novel approach allows a precise measurement of ITS.",
      "tldr_zh": "本论文探讨了使用 Large Language Models (LLMs) 进行 Thematic Analysis 中的初始编码问题，特别关注分析饱和度的有效性。研究反思了 LLMs 在实现 Inductive Thematic Saturation (ITS) 方面的表现，并提出了一种新方法，利用 DSPy 编程框架来精确测量 ITS。总体而言，此方法有助于提升定性分析的可靠性和自动化水平。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04859v1",
      "published_date": "2025-03-06 08:52:03 UTC",
      "updated_date": "2025-03-06 08:52:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:53:06.863207"
    },
    {
      "arxiv_id": "2503.04858v1",
      "title": "SHAPE : Self-Improved Visual Preference Alignment by Iteratively Generating Holistic Winner",
      "title_zh": "SHAPE：通过迭代生成整体获胜者的自我改进视觉偏好对齐",
      "authors": [
        "Kejia Chen",
        "Jiawen Zhang",
        "Jiacong Hu",
        "Jiazhen Yang",
        "Jian Lou",
        "Zunlei Feng",
        "Mingli Song"
      ],
      "abstract": "Large Visual Language Models (LVLMs) increasingly rely on preference\nalignment to ensure reliability, which steers the model behavior via preference\nfine-tuning on preference data structured as ``image - winner text - loser\ntext'' triplets. However, existing approaches often suffer from limited\ndiversity and high costs associated with human-annotated preference data,\nhindering LVLMs from fully achieving their intended alignment capabilities. We\npresent \\projectname, a self-supervised framework capable of transforming the\nalready abundant supervised text-image pairs into holistic preference triplets\nfor more effective and cheaper LVLM alignment, eliminating the need for human\npreference annotations. Our approach facilitates LVLMs in progressively\nenhancing alignment capabilities through iterative self-improvement. The key\ndesign rationale is to devise preference triplets where the winner text\nconsistently improves in holisticness and outperforms the loser response in\nquality, thereby pushing the model to ``strive to the utmost'' of alignment\nperformance through preference fine-tuning. For each given text-image pair,\nSHAPE introduces multiple visual augmentations and pairs them with a summarized\ntext to serve as the winner response, while designating the original text as\nthe loser response. Experiments across \\textbf{12} benchmarks on various model\narchitectures and sizes, including LLaVA and DeepSeek-VL, show that SHAPE\nachieves significant gains, for example, achieving +11.3\\% on MMVet\n(comprehensive evaluation), +1.4\\% on MMBench (general VQA), and +8.0\\% on POPE\n(hallucination robustness) over baselines in 7B models. Notably, qualitative\nanalyses confirm enhanced attention to visual details and better alignment with\nhuman preferences for holistic descriptions.",
      "tldr_zh": "本研究提出 SHAPE 框架，这是一种自监督方法，用于提升大型视觉语言模型 (LVLMs) 的偏好对齐，通过迭代生成更全面的 winner 响应来避免依赖昂贵的人工标注偏好数据。该框架将现有的监督文本-图像对转化为偏好三元组，利用视觉 augmentations 和文本总结作为 winner response，而原文本作为 loser response，推动模型通过迭代自改进实现更有效的对齐。实验在 12 个基准上显示显著提升，例如在 7B 模型上，MMVet 提升 11.3%、MMBench 提升 1.4%、POPE 提升 8.0%，并通过定性分析证实了模型对视觉细节的更好关注和与人类偏好的更强对齐。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04858v1",
      "published_date": "2025-03-06 08:33:11 UTC",
      "updated_date": "2025-03-06 08:33:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:53:19.669365"
    },
    {
      "arxiv_id": "2503.04201v1",
      "title": "Knowledge-Decoupled Synergetic Learning: An MLLM based Collaborative Approach to Few-shot Multimodal Dialogue Intention Recognition",
      "title_zh": "知识",
      "authors": [
        "Bin Chen",
        "Yu Zhang",
        "Hongfei Ye",
        "Ziyi Huang",
        "Hongyang Chen"
      ],
      "abstract": "Few-shot multimodal dialogue intention recognition is a critical challenge in\nthe e-commerce domainn. Previous methods have primarily enhanced model\nclassification capabilities through post-training techniques. However, our\nanalysis reveals that training for few-shot multimodal dialogue intention\nrecognition involves two interconnected tasks, leading to a seesaw effect in\nmulti-task learning. This phenomenon is attributed to knowledge interference\nstemming from the superposition of weight matrix updates during the training\nprocess. To address these challenges, we propose Knowledge-Decoupled Synergetic\nLearning (KDSL), which mitigates these issues by utilizing smaller models to\ntransform knowledge into interpretable rules, while applying the post-training\nof larger models. By facilitating collaboration between the large and small\nmultimodal large language models for prediction, our approach demonstrates\nsignificant improvements. Notably, we achieve outstanding results on two real\nTaobao datasets, with enhancements of 6.37\\% and 6.28\\% in online weighted F1\nscores compared to the state-of-the-art method, thereby validating the efficacy\nof our framework.",
      "tldr_zh": "本研究针对少样本多模态对话意图识别（Few-shot Multimodal Dialogue Intention Recognition）中的知识干扰问题，提出 Knowledge-Decoupled Synergetic Learning (KDSL) 框架，该框架基于 MLLM（多模态大语言模型）实现大模型和小模型的协作学习。KDSL 通过使用较小模型将知识转化为可解释规则，并对较大模型进行后训练，从而缓解多任务学习中的跷跷板效应（seesaw effect）。实验结果显示，该方法在两个真实 Taobao 数据集上显著提升性能，与最先进方法相比，在线加权 F1 分数分别提高了 6.37% 和 6.28%。这为电商领域的对话意图识别提供了更高效的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04201v1",
      "published_date": "2025-03-06 08:28:44 UTC",
      "updated_date": "2025-03-06 08:28:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:53:31.194928"
    },
    {
      "arxiv_id": "2503.04199v1",
      "title": "MASTER: Multimodal Segmentation with Text Prompts",
      "title_zh": "MASTER：基于文本提示的多模态分割",
      "authors": [
        "Fuyang Liu",
        "Shun Lu",
        "Jilin Mei",
        "Yu Hu"
      ],
      "abstract": "RGB-Thermal fusion is a potential solution for various weather and light\nconditions in challenging scenarios. However, plenty of studies focus on\ndesigning complex modules to fuse different modalities. With the widespread\napplication of large language models (LLMs), valuable information can be more\neffectively extracted from natural language. Therefore, we aim to leverage the\nadvantages of large language models to design a structurally simple and highly\nadaptable multimodal fusion model architecture. We proposed MultimodAl\nSegmentation with TExt PRompts (MASTER) architecture, which integrates LLM into\nthe fusion of RGB-Thermal multimodal data and allows complex query text to\nparticipate in the fusion process. Our model utilizes a dual-path structure to\nextract information from different modalities of images. Additionally, we\nemploy LLM as the core module for multimodal fusion, enabling the model to\ngenerate learnable codebook tokens from RGB, thermal images, and textual\ninformation. A lightweight image decoder is used to obtain semantic\nsegmentation results. The proposed MASTER performs exceptionally well in\nbenchmark tests across various automated driving scenarios, yielding promising\nresults.",
      "tldr_zh": "本研究针对RGB-Thermal多模态融合在复杂天气和光照条件下的挑战，提出了一种结构简单且高度适配的架构——MASTER（MultimodAl Segmentation with TExt PRompts）。MASTER整合大型语言模型（LLMs）作为核心模块，允许复杂查询文本参与RGB和热成像数据的融合过程，并采用双路径结构提取图像信息，同时生成可学习的codebook tokens。实验结果显示，该模型在各种自动驾驶场景的基准测试中表现出色，提供了一种高效的语义分割解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04199v1",
      "published_date": "2025-03-06 08:27:51 UTC",
      "updated_date": "2025-03-06 08:27:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:53:43.286190"
    },
    {
      "arxiv_id": "2503.04184v1",
      "title": "Large-Scale AI in Telecom: Charting the Roadmap for Innovation, Scalability, and Enhanced Digital Experiences",
      "title_zh": "电信中的大规模人工智能：绘制创新、可扩展性和增强数字体验的路线图",
      "authors": [
        "Adnan Shahid",
        "Adrian Kliks",
        "Ahmed Al-Tahmeesschi",
        "Ahmed Elbakary",
        "Alexandros Nikou",
        "Ali Maatouk",
        "Ali Mokh",
        "Amirreza Kazemi",
        "Antonio De Domenico",
        "Athanasios Karapantelakis",
        "Bo Cheng",
        "Bo Yang",
        "Bohao Wang",
        "Carlo Fischione",
        "Chao Zhang",
        "Chaouki Ben Issaid",
        "Chau Yuen",
        "Chenghui Peng",
        "Chongwen Huang",
        "Christina Chaccour",
        "Christo Kurisummoottil Thomas",
        "Dheeraj Sharma",
        "Dimitris Kalogiros",
        "Dusit Niyato",
        "Eli De Poorter",
        "Elissa Mhanna",
        "Emilio Calvanese Strinati",
        "Faouzi Bader",
        "Fathi Abdeldayem",
        "Fei Wang",
        "Fenghao Zhu",
        "Gianluca Fontanesi",
        "Giovanni Geraci",
        "Haibo Zhou",
        "Hakimeh Purmehdi",
        "Hamed Ahmadi",
        "Hang Zou",
        "Hongyang Du",
        "Hoon Lee",
        "Howard H. Yang",
        "Iacopo Poli",
        "Igor Carron",
        "Ilias Chatzistefanidis",
        "Inkyu Lee",
        "Ioannis Pitsiorlas",
        "Jaron Fontaine",
        "Jiajun Wu",
        "Jie Zeng",
        "Jinan Li",
        "Jinane Karam",
        "Johny Gemayel",
        "Juan Deng",
        "Julien Frison",
        "Kaibin Huang",
        "Kehai Qiu",
        "Keith Ball",
        "Kezhi Wang",
        "Kun Guo",
        "Leandros Tassiulas",
        "Lecorve Gwenole",
        "Liexiang Yue",
        "Lina Bariah",
        "Louis Powell",
        "Marcin Dryjanski",
        "Maria Amparo Canaveras Galdon",
        "Marios Kountouris",
        "Maryam Hafeez",
        "Maxime Elkael",
        "Mehdi Bennis",
        "Mehdi Boudjelli",
        "Meiling Dai",
        "Merouane Debbah",
        "Michele Polese",
        "Mohamad Assaad",
        "Mohamed Benzaghta",
        "Mohammad Al Refai",
        "Moussab Djerrab",
        "Mubeen Syed",
        "Muhammad Amir",
        "Na Yan",
        "Najla Alkaabi",
        "Nan Li",
        "Nassim Sehad",
        "Navid Nikaein",
        "Omar Hashash",
        "Pawel Sroka",
        "Qianqian Yang",
        "Qiyang Zhao",
        "Rasoul Nikbakht Silab",
        "Rex Ying",
        "Roberto Morabito",
        "Rongpeng Li",
        "Ryad Madi",
        "Salah Eddine El Ayoubi",
        "Salvatore D'Oro",
        "Samson Lasaulce",
        "Serveh Shalmashi",
        "Sige Liu",
        "Sihem Cherrared",
        "Swarna Bindu Chetty",
        "Swastika Dutta",
        "Syed A. R. Zaidi",
        "Tianjiao Chen",
        "Timothy Murphy",
        "Tommaso Melodia",
        "Tony Q. S. Quek",
        "Vishnu Ram",
        "Walid Saad",
        "Wassim Hamidouche",
        "Weilong Chen",
        "Xiaoou Liu",
        "Xiaoxue Yu",
        "Xijun Wang",
        "Xingyu Shang",
        "Xinquan Wang",
        "Xuelin Cao",
        "Yang Su",
        "Yanping Liang",
        "Yansha Deng",
        "Yifan Yang",
        "Yingping Cui",
        "Yu Sun",
        "Yuxuan Chen",
        "Yvan Pointurier",
        "Zeinab Nehme",
        "Zeinab Nezami",
        "Zhaohui Yang",
        "Zhaoyang Zhang",
        "Zhe Liu",
        "Zhenyu Yang",
        "Zhu Han",
        "Zhuang Zhou",
        "Zihan Chen",
        "Zirui Chen",
        "Zitao Shuai"
      ],
      "abstract": "This white paper discusses the role of large-scale AI in the\ntelecommunications industry, with a specific focus on the potential of\ngenerative AI to revolutionize network functions and user experiences,\nespecially in the context of 6G systems. It highlights the development and\ndeployment of Large Telecom Models (LTMs), which are tailored AI models\ndesigned to address the complex challenges faced by modern telecom networks.\nThe paper covers a wide range of topics, from the architecture and deployment\nstrategies of LTMs to their applications in network management, resource\nallocation, and optimization. It also explores the regulatory, ethical, and\nstandardization considerations for LTMs, offering insights into their future\nintegration into telecom infrastructure. The goal is to provide a comprehensive\nroadmap for the adoption of LTMs to enhance scalability, performance, and\nuser-centric innovation in telecom networks.",
      "tldr_zh": "这篇白皮书探讨了大规模AI在电信行业的应用，特别是生成式AI在6G系统中的潜力，以及Large Telecom Models (LTMs)的开发与部署，以应对现代电信网络的复杂挑战。论文详细介绍了LTMs的架构、部署策略及其在网络管理、资源分配和优化方面的实际应用，同时分析了监管、伦理和标准化方面的考虑。总体上，它提供了一个全面路线图，推动LTMs的采用，以提升电信网络的可扩展性、性能和用户导向创新。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04184v1",
      "published_date": "2025-03-06 07:53:24 UTC",
      "updated_date": "2025-03-06 07:53:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:53:55.290947"
    },
    {
      "arxiv_id": "2503.04183v1",
      "title": "CrowdHMTware: A Cross-level Co-adaptation Middleware for Context-aware Mobile DL Deployment",
      "title_zh": "CrowdHMTware：一种跨层级协同适应中间件，用于上下文感知移动深度学习部署",
      "authors": [
        "Sicong Liu",
        "Bin Guo",
        "Shiyan Luo",
        "Yuzhan Wang",
        "Hao Luo",
        "Cheng Fang",
        "Yuan Xu",
        "Ke Ma",
        "Yao Li",
        "Zhiwen Yu"
      ],
      "abstract": "There are many deep learning (DL) powered mobile and wearable applications\ntoday continuously and unobtrusively sensing the ambient surroundings to\nenhance all aspects of human lives.To enable robust and private mobile sensing,\nDL models are often deployed locally on resource-constrained mobile devices\nusing techniques such as model compression or offloading.However, existing\nmethods, either front-end algorithm level (i.e. DL model\ncompression/partitioning) or back-end scheduling level (i.e. operator/resource\nscheduling), cannot be locally online because they require offline retraining\nto ensure accuracy or rely on manually pre-defined strategies, struggle with\ndynamic adaptability.The primary challenge lies in feeding back runtime\nperformance from the back-end level to the front-end level optimization\ndecision. Moreover, the adaptive mobile DL model porting middleware with\ncross-level co-adaptation is less explored, particularly in mobile environments\nwith diversity and dynamics. In response, we introduce CrowdHMTware, a dynamic\ncontext-adaptive DL model deployment middleware for heterogeneous mobile\ndevices. It establishes an automated adaptation loop between cross-level\nfunctional components, i.e. elastic inference, scalable offloading, and\nmodel-adaptive engine, enhancing scalability and adaptability. Experiments with\nfour typical tasks across 15 platforms and a real-world case study demonstrate\nthat CrowdHMTware can effectively scale DL model, offloading, and engine\nactions across diverse platforms and tasks. It hides run-time system issues\nfrom developers, reducing the required developer expertise.",
      "tldr_zh": "该论文提出 CrowdHMTware，一种跨级联适中间件，用于处理深度学习 (DL) 模型在异构移动设备上的上下文感知部署问题，解决现有方法（如模型压缩或卸载）在动态适应性和准确性方面的局限性。CrowdHMTware 通过建立自动化适应循环，包括弹性推理、可扩展 offloading 和模型自适应引擎，实现前端和后端优化决策的实时反馈和协同。实验在 15 个平台上测试四个典型任务，并通过真实案例研究证明，该中间件能有效扩展 DL 模型部署策略，隐藏运行时系统问题，并降低开发者所需的专业知识。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is accepted by IEEE Transactions on Mobile Computing",
      "pdf_url": "http://arxiv.org/pdf/2503.04183v1",
      "published_date": "2025-03-06 07:52:20 UTC",
      "updated_date": "2025-03-06 07:52:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:54:08.342462"
    },
    {
      "arxiv_id": "2503.04176v1",
      "title": "TIMER: Temporal Instruction Modeling and Evaluation for Longitudinal Clinical Records",
      "title_zh": "翻译失败",
      "authors": [
        "Hejie Cui",
        "Alyssa Unell",
        "Bowen Chen",
        "Jason Alan Fries",
        "Emily Alsentzer",
        "Sanmi Koyejo",
        "Nigam Shah"
      ],
      "abstract": "Large language models (LLMs) have emerged as promising tools for assisting in\nmedical tasks, yet processing Electronic Health Records (EHRs) presents unique\nchallenges due to their longitudinal nature. While LLMs' capabilities to\nperform medical tasks continue to improve, their ability to reason over\ntemporal dependencies across multiple patient visits and time frames remains\nunexplored. We introduce TIMER (Temporal Instruction Modeling and Evaluation\nfor Longitudinal Clinical Records), a framework that incorporate\ninstruction-response pairs grounding to different parts of a patient's record\nas a critical dimension in both instruction evaluation and tuning for\nlongitudinal clinical records. We develop TIMER-Bench, the first time-aware\nbenchmark that evaluates temporal reasoning capabilities over longitudinal\nEHRs, as well as TIMER-Instruct, an instruction-tuning methodology for LLMs to\nlearn reasoning over time. We demonstrate that models fine-tuned with\nTIMER-Instruct improve performance by 7.3% on human-generated benchmarks and\n9.2% on TIMER-Bench, indicating that temporal instruction-tuning improves model\nperformance for reasoning over EHR.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 在处理电子健康记录 (EHRs) 的纵向数据时存在的 temporal dependencies 推理不足问题，引入了 TIMER 框架，用于整合指令-响应对以评估和微调纵向临床记录。研究开发了 TIMER-Bench，这是首个时间感知基准，用于评估模型在 EHRs 上的时间推理能力，以及 TIMER-Instruct，一种指令微调方法，帮助 LLMs 学习时间依赖性推理。实验结果显示，使用 TIMER-Instruct 微调的模型在人类生成基准上提升 7.3%，在 TIMER-Bench 上提升 9.2%，证明了该方法显著改善了 EHRs 推理性能。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.LG",
        "68T50, 68T37",
        "I.2.7; J.3"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.04176v1",
      "published_date": "2025-03-06 07:44:17 UTC",
      "updated_date": "2025-03-06 07:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:54:19.893079"
    },
    {
      "arxiv_id": "2503.04170v1",
      "title": "Towards Intelligent Transportation with Pedestrians and Vehicles In-the-Loop: A Surveillance Video-Assisted Federated Digital Twin Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaolong Li",
        "Jianhao Wei",
        "Haidong Wang",
        "Li Dong",
        "Ruoyang Chen",
        "Changyan Yi",
        "Jun Cai",
        "Dusit Niyato",
        "Xuemin",
        "Shen"
      ],
      "abstract": "In intelligent transportation systems (ITSs), incorporating pedestrians and\nvehicles in-the-loop is crucial for developing realistic and safe traffic\nmanagement solutions. However, there is falls short of simulating complex\nreal-world ITS scenarios, primarily due to the lack of a digital twin\nimplementation framework for characterizing interactions between pedestrians\nand vehicles at different locations in different traffic environments. In this\narticle, we propose a surveillance video assisted federated digital twin\n(SV-FDT) framework to empower ITSs with pedestrians and vehicles in-the-loop.\nSpecifically, SVFDT builds comprehensive pedestrian-vehicle interaction models\nby leveraging multi-source traffic surveillance videos. Its architecture\nconsists of three layers: (i) the end layer, which collects traffic\nsurveillance videos from multiple sources; (ii) the edge layer, responsible for\nsemantic segmentation-based visual understanding, twin agent-based interaction\nmodeling, and local digital twin system (LDTS) creation in local regions; and\n(iii) the cloud layer, which integrates LDTSs across different regions to\nconstruct a global DT model in realtime. We analyze key design requirements and\nchallenges and present core guidelines for SVFDT's system implementation. A\ntestbed evaluation demonstrates its effectiveness in optimizing traffic\nmanagement. Comparisons with traditional terminal-server frameworks highlight\nSV-FDT's advantages in mirroring delays, recognition accuracy, and subjective\nevaluation. Finally, we identify some open challenges and discuss future\nresearch directions.",
      "tldr_zh": "该论文提出了一种监控视频辅助的联邦数字孪生 (SV-FDT) 框架，用于智能交通系统 (ITS)，旨在将行人和车辆纳入循环，以模拟真实场景中的互动并提升交通管理安全性。框架采用三层架构，包括端层收集多源监控视频、边层进行语义分割和本地数字孪生系统建模，以及云层整合全局模型，实现实时优化。实验评估显示，SV-FDT 在镜像延迟、识别准确性和主观评估方面显著优于传统框架，并指出了未来研究中的开放挑战，如系统扩展和数据隐私问题。",
      "categories": [
        "cs.ET",
        "cs.AI"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04170v1",
      "published_date": "2025-03-06 07:36:06 UTC",
      "updated_date": "2025-03-06 07:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:54:32.807257"
    },
    {
      "arxiv_id": "2503.04856v1",
      "title": "One-Shot is Enough: Consolidating Multi-Turn Attacks into Efficient Single-Turn Prompts for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Junwoo Ha",
        "Hyunjun Kim",
        "Sangyoon Yu",
        "Haon Park",
        "Ashkan Yousefpour",
        "Yuna Park",
        "Suhyun Kim"
      ],
      "abstract": "Despite extensive safety enhancements in large language models (LLMs),\nmulti-turn \"jailbreak\" conversations crafted by skilled human adversaries can\nstill breach even the most sophisticated guardrails. However, these multi-turn\nattacks demand considerable manual effort, limiting their scalability. In this\nwork, we introduce a novel approach called Multi-turn-to-Single-turn (M2S) that\nsystematically converts multi-turn jailbreak prompts into single-turn attacks.\nSpecifically, we propose three conversion strategies - Hyphenize, Numberize,\nand Pythonize - each preserving sequential context yet packaging it in a single\nquery. Our experiments on the Multi-turn Human Jailbreak (MHJ) dataset show\nthat M2S often increases or maintains high Attack Success Rates (ASRs) compared\nto original multi-turn conversations. Notably, using a StrongREJECT-based\nevaluation of harmfulness, M2S achieves up to 95.9% ASR on Mistral-7B and\noutperforms original multi-turn prompts by as much as 17.5% in absolute\nimprovement on GPT-4o. Further analysis reveals that certain adversarial\ntactics, when consolidated into a single prompt, exploit structural formatting\ncues to evade standard policy checks. These findings underscore that\nsingle-turn attacks - despite being simpler and cheaper to conduct - can be\njust as potent, if not more, than their multi-turn counterparts. Our findings\nunderscore the urgent need to reevaluate and reinforce LLM safety strategies,\ngiven how adversarial queries can be compacted into a single prompt while still\nretaining sufficient complexity to bypass existing safety measures.",
      "tldr_zh": "本研究提出了一种名为 M2S（Multi-turn-to-Single-turn）的创新方法，用于将多轮“越狱”攻击提示简化为高效的单轮提示，从而挑战大型语言模型（LLMs）的安全机制。M2S 包括三种转换策略——Hyphenize、Numberize 和 Pythonize，这些策略保留了顺序上下文并将其打包成单一查询，显著降低了攻击的复杂度。实验在 MHJ 数据集上显示，M2S 能维持或提升攻击成功率（ASR），例如在 Mistral-7B 上达到 95.9%，并在 GPT-4o 上比原多轮提示高出 17.5%。这些发现强调了单轮攻击的潜在威力，并呼吁重新强化 LLM 的安全策略，以应对结构格式提示可能规避政策检查的风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04856v1",
      "published_date": "2025-03-06 07:34:51 UTC",
      "updated_date": "2025-03-06 07:34:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:54:44.585858"
    },
    {
      "arxiv_id": "2503.04167v1",
      "title": "The Role of Visual Modality in Multimodal Mathematical Reasoning: Challenges and Insights",
      "title_zh": "视觉模态在多模态数学推理中的作用：挑战和洞见",
      "authors": [
        "Yufang Liu",
        "Yao Du",
        "Tao Ji",
        "Jianing Wang",
        "Yang Liu",
        "Yuanbin Wu",
        "Aimin Zhou",
        "Mengdi Zhang",
        "Xunliang Cai"
      ],
      "abstract": "Recent research has increasingly focused on multimodal mathematical\nreasoning, particularly emphasizing the creation of relevant datasets and\nbenchmarks. Despite this, the role of visual information in reasoning has been\nunderexplored. Our findings show that existing multimodal mathematical models\nminimally leverage visual information, and model performance remains largely\nunaffected by changes to or removal of images in the dataset. We attribute this\nto the dominance of textual information and answer options that inadvertently\nguide the model to correct answers. To improve evaluation methods, we introduce\nthe HC-M3D dataset, specifically designed to require image reliance for\nproblem-solving and to challenge models with similar, yet distinct, images that\nchange the correct answer. In testing leading models, their failure to detect\nthese subtle visual differences suggests limitations in current visual\nperception capabilities. Additionally, we observe that the common approach of\nimproving general VQA capabilities by combining various types of image encoders\ndoes not contribute to math reasoning performance. This finding also presents a\nchallenge to enhancing visual reliance during math reasoning. Our benchmark and\ncode would be available at\n\\href{https://github.com/Yufang-Liu/visual_modality_role}{https://github.com/Yufang-Liu/visual\\_modality\\_role}.",
      "tldr_zh": "本研究探讨了视觉模态(visual modality)在多模态数学推理(multimodal mathematical reasoning)中的作用，发现现有模型对视觉信息的利用有限，性能主要依赖文本信息和答案选项，导致移除图像几乎不影响结果。作者引入了HC-M3D数据集，该数据集专门设计为要求模型依赖图像，并通过相似的视觉差异来挑战模型的感知能力。实验测试显示，领先模型无法检测这些微妙视觉变化，且提升一般视觉问答(VQA)能力的方法未能改善数学推理性能。这些发现揭示了当前模型的局限性，并为未来增强视觉依赖性提供了挑战和见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04167v1",
      "published_date": "2025-03-06 07:29:33 UTC",
      "updated_date": "2025-03-06 07:29:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:54:55.771162"
    },
    {
      "arxiv_id": "2503.04162v1",
      "title": "Semantic Retrieval Augmented Contrastive Learning for Sequential Recommendation",
      "title_zh": "基于语义检索的对比学习增强用于序列推荐",
      "authors": [
        "Ziqiang Cui",
        "Yunpeng Weng",
        "Xing Tang",
        "Xiaokun Zhang",
        "Dugang Liu",
        "Shiwei Li",
        "Peiyang Liu",
        "Bowei He",
        "Weihong Luo",
        "Xiuqiang He",
        "Chen Ma"
      ],
      "abstract": "Sequential recommendation aims to model user preferences based on historical\nbehavior sequences, which is crucial for various online platforms. Data\nsparsity remains a significant challenge in this area as most users have\nlimited interactions and many items receive little attention. To mitigate this\nissue, contrastive learning has been widely adopted. By constructing positive\nsample pairs from the data itself and maximizing their agreement in the\nembedding space,it can leverage available data more effectively. Constructing\nreasonable positive sample pairs is crucial for the success of contrastive\nlearning. However, current approaches struggle to generate reliable positive\npairs as they either rely on representations learned from inherently sparse\ncollaborative signals or use random perturbations which introduce significant\nuncertainty. To address these limitations, we propose a novel approach named\nSemantic Retrieval Augmented Contrastive Learning (SRA-CL), which leverages\nsemantic information to improve the reliability of contrastive samples. SRA-CL\ncomprises two main components: (1) Cross-Sequence Contrastive Learning via User\nSemantic Retrieval, which utilizes large language models (LLMs) to understand\ndiverse user preferences and retrieve semantically similar users to form\nreliable positive samples through a learnable sample synthesis method; and (2)\nIntra-Sequence Contrastive Learning via Item Semantic Retrieval, which employs\nLLMs to comprehend items and retrieve similar items to perform semantic-based\nitem substitution, thereby creating semantically consistent augmented views for\ncontrastive learning. SRA-CL is plug-and-play and can be integrated into\nstandard sequential recommendation models. Extensive experiments on four public\ndatasets demonstrate the effectiveness and generalizability of the proposed\napproach.",
      "tldr_zh": "该论文针对顺序推荐（Sequential Recommendation）中的数据稀疏问题，提出了一种新型方法SRA-CL（Semantic Retrieval Augmented Contrastive Learning），通过利用大型语言模型（LLMs）进行语义检索来生成可靠的正样本对。SRA-CL 包括两个核心组件：跨序列对比学习（Cross-Sequence Contrastive Learning via User Semantic Retrieval），用于检索语义相似的用户并合成样本；以及序列内对比学习（Intra-Sequence Contrastive Learning via Item Semantic Retrieval），用于检索相似物品并创建语义一致的增强视图。该方法是即插即用型，并能在四个公共数据集上显著提升推荐性能，证明了其有效性和泛化性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04162v1",
      "published_date": "2025-03-06 07:25:19 UTC",
      "updated_date": "2025-03-06 07:25:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:55:08.246348"
    },
    {
      "arxiv_id": "2503.04160v1",
      "title": "Unseen Fake News Detection Through Casual Debiasing",
      "title_zh": "翻译失败",
      "authors": [
        "Shuzhi Gong",
        "Richard Sinnott",
        "Jianzhong Qi",
        "Cecile Paris"
      ],
      "abstract": "The widespread dissemination of fake news on social media poses significant\nrisks, necessitating timely and accurate detection. However, existing methods\nstruggle with unseen news due to their reliance on training data from past\nevents and domains, leaving the challenge of detecting novel fake news largely\nunresolved. To address this, we identify biases in training data tied to\nspecific domains and propose a debiasing solution FNDCD. Originating from\ncausal analysis, FNDCD employs a reweighting strategy based on classification\nconfidence and propagation structure regularization to reduce the influence of\ndomain-specific biases, enhancing the detection of unseen fake news.\nExperiments on real-world datasets with non-overlapping news domains\ndemonstrate FNDCD's effectiveness in improving generalization across domains.",
      "tldr_zh": "现有假新闻检测方法依赖于过去事件的训练数据，导致在处理未见过的新闻时表现不佳。论文识别了训练数据中的领域特定偏差，并提出 FNDCD 解决方案，该方法基于 causal analysis 的重新加权策略和传播结构正则化，以减少偏差影响并提升检测泛化能力。在真实世界数据集上的实验表明，FNDCD 在非重叠新闻领域上显著提高了检测性能。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "2025 The Web Conference, 6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04160v1",
      "published_date": "2025-03-06 07:23:44 UTC",
      "updated_date": "2025-03-06 07:23:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:55:19.409883"
    },
    {
      "arxiv_id": "2503.04154v1",
      "title": "CA-W3D: Leveraging Context-Aware Knowledge for Weakly Supervised Monocular 3D Detection",
      "title_zh": "CA-W3D：利用上下文感知知识进行弱监督单目3D检测",
      "authors": [
        "Chupeng Liu",
        "Runkai Zhao",
        "Weidong Cai"
      ],
      "abstract": "Weakly supervised monocular 3D detection, while less annotation-intensive,\noften struggles to capture the global context required for reliable 3D\nreasoning. Conventional label-efficient methods focus on object-centric\nfeatures, neglecting contextual semantic relationships that are critical in\ncomplex scenes. In this work, we propose a Context-Aware Weak Supervision for\nMonocular 3D object detection, namely CA-W3D, to address this limitation in a\ntwo-stage training paradigm. Specifically, we first introduce a pre-training\nstage employing Region-wise Object Contrastive Matching (ROCM), which aligns\nregional object embeddings derived from a trainable monocular 3D encoder and a\nfrozen open-vocabulary 2D visual grounding model. This alignment encourages the\nmonocular encoder to discriminate scene-specific attributes and acquire richer\ncontextual knowledge. In the second stage, we incorporate a pseudo-label\ntraining process with a Dual-to-One Distillation (D2OD) mechanism, which\neffectively transfers contextual priors into the monocular encoder while\npreserving spatial fidelity and maintaining computational efficiency during\ninference. Extensive experiments conducted on the public KITTI benchmark\ndemonstrate the effectiveness of our approach, surpassing the SoTA method over\nall metrics, highlighting the importance of contextual-aware knowledge in\nweakly-supervised monocular 3D detection.",
      "tldr_zh": "本研究提出CA-W3D框架，用于弱监督单目3D检测（Weakly Supervised Monocular 3D Detection），旨在通过整合上下文感知知识来解决传统方法忽略全局语义关系的局限性。该框架采用两阶段训练范式：第一阶段引入Region-wise Object Contrastive Matching (ROCM)来对齐可训练的单目3D编码器与冻结的开源2D视觉grounding模型，从而增强场景特定属性的区分和上下文知识获取；第二阶段则通过伪标签训练和Dual-to-One Distillation (D2OD)机制，将上下文先验转移到单目编码器，同时保持空间保真度和计算效率。在KITTI基准测试中，CA-W3D超越了现有最先进方法（SoTA）在所有指标上，突显了上下文感知知识在弱监督单目3D检测中的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The paper includes 8 pages, 6 figures and 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04154v1",
      "published_date": "2025-03-06 07:02:13 UTC",
      "updated_date": "2025-03-06 07:02:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:55:32.286409"
    },
    {
      "arxiv_id": "2503.04153v1",
      "title": "KidneyTalk-open: No-code Deployment of a Private Large Language Model with Medical Documentation-Enhanced Knowledge Database for Kidney Disease",
      "title_zh": "翻译失败",
      "authors": [
        "Yongchao Long",
        "Chao Yang",
        "Gongzheng Tang",
        "Jinwei Wang",
        "Zhun Sui",
        "Yuxi Zhou",
        "Shenda Hong",
        "Luxia Zhang"
      ],
      "abstract": "Privacy-preserving medical decision support for kidney disease requires\nlocalized deployment of large language models (LLMs) while maintaining clinical\nreasoning capabilities. Current solutions face three challenges: 1) Cloud-based\nLLMs pose data security risks; 2) Local model deployment demands technical\nexpertise; 3) General LLMs lack mechanisms to integrate medical knowledge.\nRetrieval-augmented systems also struggle with medical document processing and\nclinical usability. We developed KidneyTalk-open, a desktop system integrating\nthree technical components: 1) No-code deployment of state-of-the-art (SOTA)\nopen-source LLMs (such as DeepSeek-r1, Qwen2.5) via local inference engine; 2)\nMedical document processing pipeline combining context-aware chunking and\nintelligent filtering; 3) Adaptive Retrieval and Augmentation Pipeline (AddRep)\nemploying agents collaboration for improving the recall rate of medical\ndocuments. A graphical interface was designed to enable clinicians to manage\nmedical documents and conduct AI-powered consultations without technical\nexpertise. Experimental validation on 1,455 challenging nephrology exam\nquestions demonstrates AddRep's effectiveness: achieving 29.1% accuracy (+8.1%\nover baseline) with intelligent knowledge integration, while maintaining\nrobustness through 4.9% rejection rate to suppress hallucinations. Comparative\ncase studies with the mainstream products (AnythingLLM, Chatbox, GPT4ALL)\ndemonstrate KidneyTalk-open's superior performance in real clinical query.\nKidneyTalk-open represents the first no-code medical LLM system enabling secure\ndocumentation-enhanced medical Q&A on desktop. Its designs establishes a new\nframework for privacy-sensitive clinical AI applications. The system\nsignificantly lowers technical barriers while improving evidence traceability,\nenabling more medical staff or patients to use SOTA open-source LLMs\nconveniently.",
      "tldr_zh": "该研究开发了KidneyTalk-open系统，这是一个无代码部署的私有Large Language Model (LLM)，旨在为肾病领域提供隐私保护的医疗决策支持，通过整合医疗文档增强知识数据库来解决数据安全、技术门槛和知识整合的挑战。系统包括三个核心组件：无代码部署SOTA开源LLM（如DeepSeek-r1和Qwen2.5）、医疗文档处理管道（结合上下文感知分块和智能过滤），以及Adaptive Retrieval and Augmentation Pipeline (AddRep)，利用代理协作提升医疗文档召回率。实验在1455个肾病考试问题上验证了AddRep的有效性，实现29.1%的准确率（比基线高8.1%），并通过4.9%的拒绝率抑制幻觉，在真实临床查询中优于主流产品如AnythingLLM和Chatbox。KidneyTalk-open作为首个桌面无代码医疗LLM系统，降低了技术门槛，提高了证据可追溯性，为隐私敏感的临床AI应用建立了新框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Corresponding authors: zhanglx@bjmu.edu.cn; joy_yuxi@pku.edu.cn;\n  hongshenda@pku.edu.cn",
      "pdf_url": "http://arxiv.org/pdf/2503.04153v1",
      "published_date": "2025-03-06 07:01:36 UTC",
      "updated_date": "2025-03-06 07:01:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:55:45.991536"
    },
    {
      "arxiv_id": "2503.04151v1",
      "title": "Robust Multi-View Learning via Representation Fusion of Sample-Level Attention and Alignment of Simulated Perturbation",
      "title_zh": "通过样本级注意力表示融合和模拟扰动对齐的鲁棒多视图学习",
      "authors": [
        "Jie Xu",
        "Na Zhao",
        "Gang Niu",
        "Masashi Sugiyama",
        "Xiaofeng Zhu"
      ],
      "abstract": "Recently, multi-view learning (MVL) has garnered significant attention due to\nits ability to fuse discriminative information from multiple views. However,\nreal-world multi-view datasets are often heterogeneous and imperfect, which\nusually makes MVL methods designed for specific combinations of views lack\napplication potential and limits their effectiveness. To address this issue, we\npropose a novel robust MVL method (namely RML) with simultaneous representation\nfusion and alignment. Specifically, we introduce a simple yet effective\nmulti-view transformer fusion network where we transform heterogeneous\nmulti-view data into homogeneous word embeddings, and then integrate multiple\nviews by the sample-level attention mechanism to obtain a fused representation.\nFurthermore, we propose a simulated perturbation based multi-view contrastive\nlearning framework that dynamically generates the noise and unusable\nperturbations for simulating imperfect data conditions. The simulated noisy and\nunusable data obtain two distinct fused representations, and we utilize\ncontrastive learning to align them for learning discriminative and robust\nrepresentations. Our RML is self-supervised and can also be applied for\ndownstream tasks as a regularization. In experiments, we employ it in\nunsupervised multi-view clustering, noise-label classification, and as a\nplug-and-play module for cross-modal hashing retrieval. Extensive comparison\nexperiments and ablation studies validate the effectiveness of RML.",
      "tldr_zh": "该论文提出了一种鲁棒的多视图学习方法 RML，通过同时进行表示融合和对齐来处理现实中异构和不完美的数据问题。具体而言，RML 利用多视图 Transformer 融合网络将异构数据转化为同质词嵌入，并通过样本级注意力机制融合多视图表示；同时，引入基于模拟扰动的多视图对比学习框架，动态生成噪声和不可用扰动，并通过对比学习对齐表示以提升鲁棒性和判别性。实验结果表明，RML 在无监督多视图聚类、噪声标签分类以及作为插件的跨模态散列检索任务中表现出色，验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04151v1",
      "published_date": "2025-03-06 07:01:08 UTC",
      "updated_date": "2025-03-06 07:01:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:55:56.904901"
    },
    {
      "arxiv_id": "2503.04150v2",
      "title": "Ticktack : Long Span Temporal Alignment of Large Language Models Leveraging Sexagenary Cycle Time Expression",
      "title_zh": "翻译失败",
      "authors": [
        "Xue Han",
        "Qian Hu",
        "Yitong Wang",
        "Wenchun Gao",
        "Lianlian Zhang",
        "Qing Wang",
        "Lijun Mei",
        "Chao Deng",
        "Junlan Feng"
      ],
      "abstract": "Large language models (LLMs) suffer from temporal misalignment issues\nespecially across long span of time. The issue arises from knowing that LLMs\nare trained on large amounts of data where temporal information is rather\nsparse over long times, such as thousands of years, resulting in insufficient\nlearning or catastrophic forgetting by the LLMs. This paper proposes a\nmethodology named \"Ticktack\" for addressing the LLM's long-time span\nmisalignment in a yearly setting. Specifically, we first propose to utilize the\nsexagenary year expression instead of the Gregorian year expression employed by\nLLMs, achieving a more uniform distribution in yearly granularity. Then, we\nemploy polar coordinates to model the sexagenary cycle of 60 terms and the year\norder within each term, with additional temporal encoding to ensure LLMs\nunderstand them. Finally, we present a temporal representational alignment\napproach for post-training LLMs that effectively distinguishes time points with\nrelevant knowledge, hence improving performance on time-related tasks,\nparticularly over a long period. We also create a long time span benchmark for\nevaluation. Experimental results prove the effectiveness of our proposal.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 在长时段时间信息处理中的误对齐问题（如数千年跨度导致的学习不足或灾难性遗忘），提出了一种名为 Ticktack 的方法，以年度设置为核心。Ticktack 首先采用六十进制年表达 (sexagenary year expression) 代替公历年表达，实现更均匀的年份分布；然后利用 polar coordinates 建模六十进制的 60 个术语和年份顺序，并结合时间编码进行后训练。最终，该方法通过时间表示对齐技术提升 LLMs 在长时期任务的性能，实验结果证明其有效性，并在创建的长时段基准上表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04150v2",
      "published_date": "2025-03-06 06:59:09 UTC",
      "updated_date": "2025-03-07 09:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:56:09.014960"
    },
    {
      "arxiv_id": "2503.04149v1",
      "title": "Dynamic Benchmarking of Reasoning Capabilities in Code Large Language Models Under Data Contamination",
      "title_zh": "翻译失败",
      "authors": [
        "Simin Chen",
        "Pranav Pusarla",
        "Baishakhi Ray"
      ],
      "abstract": "The rapid evolution of code largelanguage models underscores the need for\neffective and transparent benchmarking of their reasoning capabilities.\nHowever, the current benchmarking approach heavily depends on publicly\navailable, human-created datasets. The widespread use of these fixed benchmark\ndatasets makes the benchmarking process to be static and thus particularly\nsusceptible to data contamination, an unavoidable consequence of the extensive\ndata collection processes used to train Code LLMs. Existing approaches that\naddress data contamination often suffer from human effort limitations and\nimbalanced problem complexity. To tackle these challenges, we propose \\tool, a\nnovel benchmarking suite for evaluating Code LLMs under potential data\ncontamination. Given a seed programming problem, \\tool employs multiple agents\nto extract and modify the context without altering the core logic, generating\nsemantically equivalent variations. We introduce a dynamic data generation\nmethods and conduct empirical studies on two seed datasets across 21 Code LLMs.\nResults show that \\tool effectively benchmarks reasoning capabilities under\ncontamination risks while generating diverse problem sets to ensure consistent\nand reliable evaluations.",
      "tldr_zh": "该研究针对代码大语言模型（Code LLMs）的推理能力基准测试问题，指出现有方法依赖固定数据集易受数据污染（data contamination）影响，导致评估静态且不可靠。作者提出了一种新型基准测试套件\\tool，通过多个agents从种子编程问题中提取并修改上下文，生成语义等价变体，从而实现动态数据生成。实验在两个种子数据集和21个Code LLMs上进行，结果显示\\tool有效评估了模型在数据污染风险下的推理能力，并提供了多样化问题集以确保评估的一致性和可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "https://codekaleidoscope.github.io/dycodeeval.html",
      "pdf_url": "http://arxiv.org/pdf/2503.04149v1",
      "published_date": "2025-03-06 06:56:59 UTC",
      "updated_date": "2025-03-06 06:56:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:56:20.187174"
    },
    {
      "arxiv_id": "2503.04144v1",
      "title": "DM-Adapter: Domain-Aware Mixture-of-Adapters for Text-Based Person Retrieval",
      "title_zh": "DM-Adapter：领域感知混合适配器用于基于文本",
      "authors": [
        "Yating Liu",
        "Zimo Liu",
        "Xiangyuan Lan",
        "Wenming Yang",
        "Yaowei Li",
        "Qingmin Liao"
      ],
      "abstract": "Text-based person retrieval (TPR) has gained significant attention as a\nfine-grained and challenging task that closely aligns with practical\napplications. Tailoring CLIP to person domain is now a emerging research topic\ndue to the abundant knowledge of vision-language pretraining, but challenges\nstill remain during fine-tuning: (i) Previous full-model fine-tuning in TPR is\ncomputationally expensive and prone to overfitting.(ii) Existing\nparameter-efficient transfer learning (PETL) for TPR lacks of fine-grained\nfeature extraction. To address these issues, we propose Domain-Aware\nMixture-of-Adapters (DM-Adapter), which unifies Mixture-of-Experts (MOE) and\nPETL to enhance fine-grained feature representations while maintaining\nefficiency. Specifically, Sparse Mixture-of-Adapters is designed in parallel to\nMLP layers in both vision and language branches, where different experts\nspecialize in distinct aspects of person knowledge to handle features more\nfinely. To promote the router to exploit domain information effectively and\nalleviate the routing imbalance, Domain-Aware Router is then developed by\nbuilding a novel gating function and injecting learnable domain-aware prompts.\nExtensive experiments show that our DM-Adapter achieves state-of-the-art\nperformance, outperforming previous methods by a significant margin.",
      "tldr_zh": "本文提出DM-Adapter，一种针对文本-based人检索(TPR)的领域感知混合适配器方法，旨在解决CLIP模型细调时的计算开销和细粒度特征提取不足问题。DM-Adapter结合Mixture-of-Experts (MOE)和参数高效传输学习(PETL)，在视觉和语言分支的MLP层并行设计Sparse Mixture-of-Adapters，不同专家专注于不同的人知识方面以提升特征表示效率。为优化路由，引入Domain-Aware Router，通过新型门控函数和可学习的领域感知提示，有效利用领域信息并缓解路由不平衡。实验结果表明，DM-Adapter在TPR任务上大幅超越现有方法，实现了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 5 figures, accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04144v1",
      "published_date": "2025-03-06 06:41:38 UTC",
      "updated_date": "2025-03-06 06:41:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:56:34.052103"
    },
    {
      "arxiv_id": "2503.04143v1",
      "title": "MTS: A Deep Reinforcement Learning Portfolio Management Framework with Time-Awareness and Short-Selling",
      "title_zh": "MTS：一个具有时间感知和卖空的深度强化学习投资组合管理框架",
      "authors": [
        "Fengchen Gu",
        "Zhengyong Jiang",
        "Ángel F. García-Fernández",
        "Angelos Stefanidis",
        "Jionglong Su",
        "Huakang Li"
      ],
      "abstract": "Portfolio management remains a crucial challenge in finance, with traditional\nmethods often falling short in complex and volatile market environments. While\ndeep reinforcement approaches have shown promise, they still face limitations\nin dynamic risk management, exploitation of temporal markets, and incorporation\nof complex trading strategies such as short-selling. These limitations can lead\nto suboptimal portfolio performance, increased vulnerability to market\nvolatility, and missed opportunities in capturing potential returns from\ndiverse market conditions. This paper introduces a Deep Reinforcement Learning\nPortfolio Management Framework with Time-Awareness and Short-Selling (MTS),\noffering a robust and adaptive strategy for sustainable investment performance.\nThis framework utilizes a novel encoder-attention mechanism to address the\nlimitations by incorporating temporal market characteristics, a parallel\nstrategy for automated short-selling based on market trends, and risk\nmanagement through innovative Incremental Conditional Value at Risk, enhancing\nadaptability and performance. Experimental validation on five diverse datasets\nfrom 2019 to 2023 demonstrates MTS's superiority over traditional algorithms\nand advanced machine learning techniques. MTS consistently achieves higher\ncumulative returns, Sharpe, Omega, and Sortino ratios, underscoring its\neffectiveness in balancing risk and return while adapting to market dynamics.\nMTS demonstrates an average relative increase of 30.67% in cumulative returns\nand 29.33% in Sharpe ratio compared to the next best-performing strategies\nacross various datasets.",
      "tldr_zh": "该论文针对投资组合管理的挑战，提出了一种基于 Deep Reinforcement Learning 的框架 MTS，该框架通过 encoder-attention mechanism 处理时间市场特性、parallel strategy 实现自动 short-selling，以及 Incremental Conditional Value at Risk 进行风险管理，从而提升动态适应性和性能。MTS 解决了传统方法在复杂市场中的局限性，如动态风险管理和短卖策略的缺失。实验在 2019-2023 年的五个数据集上验证了其优越性，MTS 相较于其他策略平均提高了 30.67% 的累计回报和 29.33% 的 Sharpe ratio，并在 Omega 和 Sortino 比率上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04143v1",
      "published_date": "2025-03-06 06:41:17 UTC",
      "updated_date": "2025-03-06 06:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:56:46.647216"
    },
    {
      "arxiv_id": "2503.04128v1",
      "title": "Artificial Intelligence in Pronunciation Teaching: Use and Beliefs of Foreign Language Teachers",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios P. Georgiou"
      ],
      "abstract": "Pronunciation instruction in foreign language classrooms has often been an\noverlooked area of focus. With the widespread adoption of Artificial\nIntelligence (AI) and its potential benefits, investigating how AI is utilized\nin pronunciation teaching and understanding the beliefs of teachers about this\ntool is essential for improving learning outcomes. This study aims to examine\nhow AI use for pronunciation instruction varies across different demographic\nand professional factors among teachers, and how these factors, including AI\nuse, influence the beliefs of teachers about AI. The study involved 117 English\nas a Foreign Language (EFL) in-service teachers working in Cyprus, who\ncompleted an online survey designed to assess their beliefs about the\neffectiveness of AI, its drawbacks, and their willingness to integrate AI into\ntheir teaching practices. The results revealed that teachers were significantly\nmore likely to agree on the perceived effectiveness of AI and their willingness\nto adopt it, compared to their concerns about its use. Furthermore, teachers\nworking in higher education and adult education, as well as those who had\nreceived more extensive training, reported using AI more frequently in their\nteaching. Teachers who utilized AI more often expressed stronger agreement with\nits effectiveness, while those who had received more training were less likely\nto express concerns about its integration. Given the limited training that many\nteachers currently receive, these findings demonstrate the need for tailored\ntraining sessions that address the specific needs and concerns of educators,\nultimately fostering the adoption of AI in pronunciation instruction.",
      "tldr_zh": "这篇论文探讨了外语教师在使用 Artificial Intelligence (AI) 进行发音教学时的使用情况和信念，旨在分析 AI 如何受教师人口统计和职业因素影响，并评估这些因素对教师信念的影响。研究通过对 117 名在塞浦路斯的 English as a Foreign Language (EFL) 在职教师进行的在线问卷调查，发现教师更倾向于认可 AI 的有效性和采用意愿，而非其潜在缺点；同时，高等教育和成人教育背景的教师，以及接受过更多培训的教师，更频繁地使用 AI。结果表明，增加针对教师需求的定制培训至关重要，以缓解担忧并推动 AI 在发音教学中的广泛应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04128v1",
      "published_date": "2025-03-06 06:14:27 UTC",
      "updated_date": "2025-03-06 06:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:56:58.042059"
    },
    {
      "arxiv_id": "2503.04853v1",
      "title": "From Pixels to Trajectory: Universal Adversarial Example Detection via Temporal Imprints",
      "title_zh": "翻译失败",
      "authors": [
        "Yansong Gao",
        "Huaibing Peng",
        "Hua Ma",
        "Zhiyang Dai",
        "Shuo Wang",
        "Hongsheng Hu",
        "Anmin Fu",
        "Minhui Xue"
      ],
      "abstract": "For the first time, we unveil discernible temporal (or historical) trajectory\nimprints resulting from adversarial example (AE) attacks. Standing in contrast\nto existing studies all focusing on spatial (or static) imprints within the\ntargeted underlying victim models, we present a fresh temporal paradigm for\nunderstanding these attacks. Of paramount discovery is that these imprints are\nencapsulated within a single loss metric, spanning universally across diverse\ntasks such as classification and regression, and modalities including image,\ntext, and audio. Recognizing the distinct nature of loss between adversarial\nand clean examples, we exploit this temporal imprint for AE detection by\nproposing TRAIT (TRaceable Adversarial temporal trajectory ImprinTs). TRAIT\noperates under minimal assumptions without prior knowledge of attacks, thereby\nframing the detection challenge as a one-class classification problem. However,\ndetecting AEs is still challenged by significant overlaps between the\nconstructed synthetic losses of adversarial and clean examples due to the\nabsence of ground truth for incoming inputs. TRAIT addresses this challenge by\nconverting the synthetic loss into a spectrum signature, using the technique of\nFast Fourier Transform to highlight the discrepancies, drawing inspiration from\nthe temporal nature of the imprints, analogous to time-series signals. Across\n12 AE attacks including SMACK (USENIX Sec'2023), TRAIT demonstrates consistent\noutstanding performance across comprehensively evaluated modalities, tasks,\ndatasets, and model architectures. In all scenarios, TRAIT achieves an AE\ndetection accuracy exceeding 97%, often around 99%, while maintaining a false\nrejection rate of 1%. TRAIT remains effective under the formulated strong\nadaptive attacks.",
      "tldr_zh": "该研究首次揭示了对抗样本（AE）攻击导致的 temporal trajectory imprints，这是一种新的时间序列范式，与以往专注于 spatial imprints 的方法不同。作者提出 TRAIT（TRaceable Adversarial temporal trajectory ImprinTs）框架，通过分析单一 loss metric 的差异，将检测问题转化为 one-class classification，并利用 Fast Fourier Transform 将合成损失转换为 spectrum signature，以突出 AE 与正常样本的差异。在跨图像、文本和音频等模态、12 种 AE 攻击（包括 SMACK）上的实验中，TRAIT 实现了超过 97% 的检测准确率、约 99% 的高性能，同时保持 1% 的假拒绝率，并能有效抵御 adaptive attacks。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04853v1",
      "published_date": "2025-03-06 06:00:04 UTC",
      "updated_date": "2025-03-06 06:00:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:57:08.850557"
    },
    {
      "arxiv_id": "2503.04121v1",
      "title": "Simple Self Organizing Map with Visual Transformer",
      "title_zh": "简单的自组织映射结合视觉Transformer",
      "authors": [
        "Alan Luo",
        "Kaiwen Yuan"
      ],
      "abstract": "Vision Transformers (ViTs) have demonstrated exceptional performance in\nvarious vision tasks. However, they tend to underperform on smaller datasets\ndue to their inherent lack of inductive biases. Current approaches address this\nlimitation implicitly-often by pairing ViTs with pretext tasks or by distilling\nknowledge from convolutional neural networks (CNNs) to strengthen the prior. In\ncontrast, Self-Organizing Maps (SOMs), a widely adopted self-supervised\nframework, are inherently structured to preserve topology and spatial\norganization, making them a promising candidate to directly address the\nlimitations of ViTs in limited or small training datasets. Despite this\npotential, equipping SOMs with modern deep learning architectures remains\nlargely unexplored. In this study, we conduct a novel exploration on how Vision\nTransformers (ViTs) and Self-Organizing Maps (SOMs) can empower each other,\naiming to bridge this critical research gap. Our findings demonstrate that\nthese architectures can synergistically enhance each other, leading to\nsignificantly improved performance in both unsupervised and supervised tasks.\nCode will be publicly available.",
      "tldr_zh": "本研究探讨了 Vision Transformers (ViTs) 在小数据集上表现不佳的问题，该问题源于其固有的缺乏归纳偏差，而现有方法通常通过预训练任务或从 convolutional neural networks (CNNs) 知识蒸馏来间接解决。作者提出了一种简单的方法，将 Self-Organizing Maps (SOMs) 与 ViTs 结合，利用 SOMs 的拓扑和空间组织特性，来直接增强 ViTs 在有限数据集中的能力。实验结果显示，这种协同架构显著提高了无监督和监督任务的性能，代码将公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "65D19 (Primary)"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 4 figures. Submitted to IEEE. All experiments and code work\n  were performed by the first author, with the second author serving in a\n  PI/mentor role, guiding the progression of the work",
      "pdf_url": "http://arxiv.org/pdf/2503.04121v1",
      "published_date": "2025-03-06 05:58:41 UTC",
      "updated_date": "2025-03-06 05:58:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:57:20.947387"
    },
    {
      "arxiv_id": "2503.04111v1",
      "title": "Generalizability of Neural Networks Minimizing Empirical Risk Based on Expressive Ability",
      "title_zh": "翻译失败",
      "authors": [
        "Lijia Yu",
        "Yibo Miao",
        "Yifan Zhu",
        "Xiao-Shan Gao",
        "Lijun Zhang"
      ],
      "abstract": "The primary objective of learning methods is generalization. Classic uniform\ngeneralization bounds, which rely on VC-dimension or Rademacher complexity,\nfail to explain the significant attribute that over-parameterized models in\ndeep learning exhibit nice generalizability. On the other hand,\nalgorithm-dependent generalization bounds, like stability bounds, often rely on\nstrict assumptions. To establish generalizability under less stringent\nassumptions, this paper investigates the generalizability of neural networks\nthat minimize or approximately minimize empirical risk. We establish a lower\nbound for population accuracy based on the expressiveness of these networks,\nwhich indicates that with an adequate large number of training samples and\nnetwork sizes, these networks, including over-parameterized ones, can\ngeneralize effectively. Additionally, we provide a necessary condition for\ngeneralization, demonstrating that, for certain data distributions, the\nquantity of training data required to ensure generalization exceeds the network\nsize needed to represent the corresponding data distribution. Finally, we\nprovide theoretical insights into several phenomena in deep learning, including\nrobust generalization, importance of over-parameterization, and effect of loss\nfunction on generalization.",
      "tldr_zh": "本文探讨了神经网络在最小化经验风险时的泛化能力，指出经典的统一泛化界限（如基于 VC-dimension 或 Rademacher complexity）无法解释过参数化模型的良好泛化现象，同时算法相关的泛化界限（如稳定性界限）依赖严格假设。研究建立了基于神经网络表达能力（expressive ability）的泛化下界，证明了在足够训练样本和网络大小下，包括过参数化网络在内，能够实现有效泛化，并提供了一个必要条件：某些数据分布下，所需训练数据量可能超过表示该分布的网络大小。最终，该工作为深度学习现象提供了理论见解，包括robust generalization、over-parameterization 的重要性和损失函数对泛化的影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04111v1",
      "published_date": "2025-03-06 05:36:35 UTC",
      "updated_date": "2025-03-06 05:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:57:33.922120"
    },
    {
      "arxiv_id": "2503.04110v2",
      "title": "InterChat: Enhancing Generative Visual Analytics using Multimodal Interactions",
      "title_zh": "InterChat：通过多模态交互增强生成式视觉分析",
      "authors": [
        "Juntong Chen",
        "Jiang Wu",
        "Jiajing Guo",
        "Vikram Mohanty",
        "Xueming Li",
        "Jorge Piazentin Ono",
        "Wenbin He",
        "Liu Ren",
        "Dongyu Liu"
      ],
      "abstract": "The rise of Large Language Models (LLMs) and generative visual analytics\nsystems has transformed data-driven insights, yet significant challenges\npersist in accurately interpreting users' analytical and interaction intents.\nWhile language inputs offer flexibility, they often lack precision, making the\nexpression of complex intents inefficient, error-prone, and time-intensive. To\naddress these limitations, we investigate the design space of multimodal\ninteractions for generative visual analytics through a literature review and\npilot brainstorming sessions. Building on these insights, we introduce a highly\nextensible workflow that integrates multiple LLM agents for intent inference\nand visualization generation. We develop InterChat, a generative visual\nanalytics system that combines direct manipulation of visual elements with\nnatural language inputs. This integration enables precise intent communication\nand supports progressive, visually driven exploratory data analyses. By\nemploying effective prompt engineering, and contextual interaction linking,\nalongside intuitive visualization and interaction designs, InterChat bridges\nthe gap between user interactions and LLM-driven visualizations, enhancing both\ninterpretability and usability. Extensive evaluations, including two usage\nscenarios, a user study, and expert feedback, demonstrate the effectiveness of\nInterChat. Results show significant improvements in the accuracy and efficiency\nof handling complex visual analytics tasks, highlighting the potential of\nmultimodal interactions to redefine user engagement and analytical depth in\ngenerative visual analytics.",
      "tldr_zh": "本文研究了Large Language Models (LLMs) 在生成式视觉分析中解释用户意图的挑战，语言输入虽灵活但往往缺乏精确性，导致处理复杂任务效率低下。为解决此问题，作者通过文献回顾和头脑风暴探索多模态交互设计空间，并开发了InterChat 系统，该系统整合多个 LLM 代理、可扩展工作流以及直接操作与自然语言输入相结合的方法，支持渐进式数据探索。实验评估包括使用场景、用户研究和专家反馈，证明InterChat 显著提升了任务的准确性和效率，展示了多模态交互在提升用户参与度和分析深度方面的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "This work is accepted by the 27th Eurographics Conference on\n  Visualization (EuroVis 2025). The paper contains 12 pages and 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04110v2",
      "published_date": "2025-03-06 05:35:19 UTC",
      "updated_date": "2025-04-16 01:11:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:57:46.844173"
    },
    {
      "arxiv_id": "2503.04099v1",
      "title": "Disparities in LLM Reasoning Accuracy and Explanations: A Case Study on African American English",
      "title_zh": "翻译失败",
      "authors": [
        "Runtao Zhou",
        "Guangya Wan",
        "Saadia Gabriel",
        "Sheng Li",
        "Alexander J Gates",
        "Maarten Sap",
        "Thomas Hartvigsen"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nreasoning tasks, leading to their widespread deployment. However, recent\nstudies have highlighted concerning biases in these models, particularly in\ntheir handling of dialectal variations like African American English (AAE). In\nthis work, we systematically investigate dialectal disparities in LLM reasoning\ntasks. We develop an experimental framework comparing LLM performance given\nStandard American English (SAE) and AAE prompts, combining LLM-based dialect\nconversion with established linguistic analyses. We find that LLMs consistently\nproduce less accurate responses and simpler reasoning chains and explanations\nfor AAE inputs compared to equivalent SAE questions, with disparities most\npronounced in social science and humanities domains. These findings highlight\nsystematic differences in how LLMs process and reason about different language\nvarieties, raising important questions about the development and deployment of\nthese systems in our multilingual and multidialectal world. Our code repository\nis publicly available at https://github.com/Runtaozhou/dialect_bias_eval.",
      "tldr_zh": "本文研究了Large Language Models (LLM) 在处理African American English (AAE) 时存在的推理准确性和解释偏差，通过与Standard American English (SAE) 的比较来揭示系统性差异。研究团队开发了一个实验框架，利用LLM-based dialect conversion和linguistic analyses，评估LLM在不同方言提示下的性能。结果显示，LLM对AAE输入的响应准确性较低，推理链和解释更简单，尤其在social science和humanities领域差异显著。这些发现突显了LLM处理语言变体的系统问题，并引发了对这些模型在多语言、多方言环境中的开发和部署的担忧。代码仓库已公开在https://github.com/Runtaozhou/dialect_bias_eval。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ARR Under Review, First two authors contribute equally",
      "pdf_url": "http://arxiv.org/pdf/2503.04099v1",
      "published_date": "2025-03-06 05:15:34 UTC",
      "updated_date": "2025-03-06 05:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:57:59.156212"
    },
    {
      "arxiv_id": "2503.04095v2",
      "title": "Chart-HQA: A Benchmark for Hypothetical Question Answering in Charts",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangnan Chen",
        "Yuancheng Fang",
        "Qian Xiao",
        "Juncheng Li",
        "Jun Lin",
        "Siliang Tang",
        "Yi Yang",
        "Yueting Zhuang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have garnered significant attention\nfor their strong visual-semantic understanding. Most existing chart benchmarks\nevaluate MLLMs' ability to parse information from charts to answer questions.\nHowever, they overlook the inherent output biases of MLLMs, where models rely\non their parametric memory to answer questions rather than genuinely\nunderstanding the chart content. To address this limitation, we introduce a\nnovel Chart Hypothetical Question Answering (HQA) task, which imposes\nassumptions on the same question to compel models to engage in counterfactual\nreasoning based on the chart content. Furthermore, we introduce HAI, a human-AI\ninteractive data synthesis approach that leverages the efficient text-editing\ncapabilities of LLMs alongside human expert knowledge to generate diverse and\nhigh-quality HQA data at a low cost. Using HAI, we construct Chart-HQA, a\nchallenging benchmark synthesized from publicly available data sources.\nEvaluation results on 18 MLLMs of varying model sizes reveal that current\nmodels face significant generalization challenges and exhibit imbalanced\nreasoning performance on the HQA task.",
      "tldr_zh": "本研究引入了 Chart-HQA，这是一个针对图表假设性问答(Hypothetical Question Answering)的基准任务，旨在解决 Multimodal Large Language Models (MLLMs) 在图表理解中依赖参数记忆而非真实内容分析的问题。论文提出 HAI 方法，一种人类-AI 交互数据合成策略，利用 LLMs 的文本编辑能力和专家知识，从公开来源高效生成多样高质量的 HQA 数据。实验评估了 18 个不同规模的 MLLMs，发现这些模型在 Chart-HQA 任务上存在显著的泛化挑战和不平衡的推理性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2503.04095v2",
      "published_date": "2025-03-06 05:08:40 UTC",
      "updated_date": "2025-03-07 05:18:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:58:10.421303"
    },
    {
      "arxiv_id": "2503.04085v1",
      "title": "SED2AM: Solving Multi-Trip Time-Dependent Vehicle Routing Problem using Deep Reinforcement Learning",
      "title_zh": "SED2AM：使用深度强化学习解决多行程时间相关车辆路径问题",
      "authors": [
        "Arash Mozhdehi",
        "Yunli Wang",
        "Sun Sun",
        "Xin Wang"
      ],
      "abstract": "Deep reinforcement learning (DRL)-based frameworks, featuring\nTransformer-style policy networks, have demonstrated their efficacy across\nvarious vehicle routing problem (VRP) variants. However, the application of\nthese methods to the multi-trip time-dependent vehicle routing problem\n(MTTDVRP) with maximum working hours constraints -- a pivotal element of urban\nlogistics -- remains largely unexplored. This paper introduces a DRL-based\nmethod called the Simultaneous Encoder and Dual Decoder Attention Model\n(SED2AM), tailored for the MTTDVRP with maximum working hours constraints. The\nproposed method introduces a temporal locality inductive bias to the encoding\nmodule of the policy networks, enabling it to effectively account for the\ntime-dependency in travel distance or time. The decoding module of SED2AM\nincludes a vehicle selection decoder that selects a vehicle from the fleet,\neffectively associating trips with vehicles for functional multi-trip routing.\nAdditionally, this decoding module is equipped with a trip construction decoder\nleveraged for constructing trips for the vehicles. This policy model is\nequipped with two classes of state representations, fleet state and routing\nstate, providing the information needed for effective route construction in the\npresence of maximum working hours constraints. Experimental results using\nreal-world datasets from two major Canadian cities not only show that SED2AM\noutperforms the current state-of-the-art DRL-based and metaheuristic-based\nbaselines but also demonstrate its generalizability to solve larger-scale\nproblems.",
      "tldr_zh": "本文提出了一种基于深度强化学习 (DRL) 的方法 SED2AM，用于解决多行程时间依赖车辆路径问题 (MTTDVRP)，该问题涉及最大工作小时约束，是城市物流的核心挑战。SED2AM 在编码模块引入时间局部性归纳偏差，以处理旅行距离或时间的时变性，并在解码模块配备车辆选择解码器和行程构建解码器，实现车队管理和高效路径构建。实验结果显示，该方法在使用加拿大两个主要城市的真实数据集时，优于现有 DRL 和元启发式基线，并在更大规模问题上表现出良好的泛化能力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ACM TKDD: https://dl.acm.org/doi/10.1145/3721983",
      "pdf_url": "http://arxiv.org/pdf/2503.04085v1",
      "published_date": "2025-03-06 04:47:49 UTC",
      "updated_date": "2025-03-06 04:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:58:21.685054"
    },
    {
      "arxiv_id": "2503.04074v1",
      "title": "Can We Optimize Deep RL Policy Weights as Trajectory Modeling?",
      "title_zh": "我们能将深度强化学习策略权重优化视为轨迹建模吗？",
      "authors": [
        "Hongyao Tang"
      ],
      "abstract": "Learning the optimal policy from a random network initialization is the theme\nof deep Reinforcement Learning (RL). As the scale of DRL training increases,\ntreating DRL policy network weights as a new data modality and exploring the\npotential becomes appealing and possible. In this work, we focus on the policy\nlearning path in deep RL, represented by the trajectory of network weights of\nhistorical policies, which reflects the evolvement of the policy learning\nprocess. Taking the idea of trajectory modeling with Transformer, we propose\nTransformer as Implicit Policy Learner (TIPL), which processes policy network\nweights in an autoregressive manner. We collect the policy learning path data\nby running independent RL training trials, with which we then train our TIPL\nmodel. In the experiments, we demonstrate that TIPL is able to fit the implicit\ndynamics of policy learning and perform the optimization of policy network by\ninference.",
      "tldr_zh": "本论文探讨了在深度强化学习（Deep RL）中，是否能将策略网络权重视为轨迹进行建模，以优化从随机初始化学习最优策略的过程。作者提出 Transformer as Implicit Policy Learner (TIPL) 方法，使用 Transformer 以自回归方式处理历史策略网络权重的学习路径数据，这些数据通过独立 RL 训练试验收集。实验结果表明，TIPL 能够有效拟合策略学习的隐式动态，并通过推理进行策略网络优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as an extended abstract to ICLR 2025 Workshop on Weight\n  Space Learning (WSL)",
      "pdf_url": "http://arxiv.org/pdf/2503.04074v1",
      "published_date": "2025-03-06 04:12:22 UTC",
      "updated_date": "2025-03-06 04:12:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:58:32.806363"
    },
    {
      "arxiv_id": "2503.04065v2",
      "title": "PP-DocBee: Improving Multimodal Document Understanding Through a Bag of Tricks",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Ni",
        "Kui Huang",
        "Yao Lu",
        "Wenyu Lv",
        "Guanzhong Wang",
        "Zeyu Chen",
        "Yi Liu"
      ],
      "abstract": "With the rapid advancement of digitalization, various document images are\nbeing applied more extensively in production and daily life, and there is an\nincreasingly urgent need for fast and accurate parsing of the content in\ndocument images. Therefore, this report presents PP-DocBee, a novel multimodal\nlarge language model designed for end-to-end document image understanding.\nFirst, we develop a data synthesis strategy tailored to document scenarios in\nwhich we build a diverse dataset to improve the model generalization. Then, we\napply a few training techniques, including dynamic proportional sampling, data\npreprocessing, and OCR postprocessing strategies. Extensive evaluations\ndemonstrate the superior performance of PP-DocBee, achieving state-of-the-art\nresults on English document understanding benchmarks and even outperforming\nexisting open source and commercial models in Chinese document understanding.\nThe source code and pre-trained models are publicly available at\n\\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.",
      "tldr_zh": "这篇论文介绍了 PP-DocBee，一种新型的多模态大语言模型，旨在通过一系列技巧提升文档图像的端到端理解能力。研究者开发了针对文档场景的数据合成策略，以构建多样数据集并提高模型泛化性，同时应用了动态比例采样、数据预处理和 OCR 后处理等训练技巧。实验评估显示，PP-DocBee 在英语文档理解基准上取得了最先进的结果，并在中文文档理解上超过了现有开源和商业模型。源代码和预训练模型已在 GitHub 上公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04065v2",
      "published_date": "2025-03-06 03:43:21 UTC",
      "updated_date": "2025-03-10 03:22:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:58:45.885075"
    },
    {
      "arxiv_id": "2503.04064v1",
      "title": "Uncovering inequalities in new knowledge learning by large language models across different languages",
      "title_zh": "揭示大语言模型在新知识学习中跨不同语言的不平等",
      "authors": [
        "Chenglong Wang",
        "Haoyu Tang",
        "Xiyuan Yang",
        "Yueqi Xie",
        "Jina Suh",
        "Sunayana Sitaram",
        "Junming Huang",
        "Yu Xie",
        "Zhaoya Gong",
        "Xing Xie",
        "Fangzhao Wu"
      ],
      "abstract": "As large language models (LLMs) gradually become integral tools for problem\nsolving in daily life worldwide, understanding linguistic inequality is\nbecoming increasingly important. Existing research has primarily focused on\nstatic analyses that assess the disparities in the existing knowledge and\ncapabilities of LLMs across languages. However, LLMs are continuously evolving,\nacquiring new knowledge to generate up-to-date, domain-specific responses.\nInvestigating linguistic inequalities within this dynamic process is,\ntherefore, also essential. In this paper, we explore inequalities in new\nknowledge learning by LLMs across different languages and four key dimensions:\neffectiveness, transferability, prioritization, and robustness. Through\nextensive experiments under two settings (in-context learning and fine-tuning)\nusing both proprietary and open-source models, we demonstrate that low-resource\nlanguages consistently face disadvantages across all four dimensions. By\nshedding light on these disparities, we aim to raise awareness of linguistic\ninequalities in LLMs' new knowledge learning, fostering the development of more\ninclusive and equitable future LLMs.",
      "tldr_zh": "本研究探讨大型语言模型(LLMs)在不同语言中学习新知识的不平等问题，重点关注动态学习过程而非静态能力。研究者通过在上下文化学习(in-context learning)和微调(fine-tuning)两种设置下进行的广泛实验，评估了有效性(effectiveness)、可转移性(transferability)、优先级(prioritization)和鲁棒性(robustness)四个维度。结果显示，低资源语言在所有维度上均存在显著劣势。该研究旨在提升对语言不平等的认识，推动开发更具包容性和公平性的未来LLMs。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04064v1",
      "published_date": "2025-03-06 03:41:47 UTC",
      "updated_date": "2025-03-06 03:41:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:58:58.986990"
    },
    {
      "arxiv_id": "2503.04046v1",
      "title": "Continual Optimization with Symmetry Teleportation for Multi-Task Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhipeng Zhou",
        "Ziqiao Meng",
        "Pengcheng Wu",
        "Peilin Zhao",
        "Chunyan Miao"
      ],
      "abstract": "Multi-task learning (MTL) is a widely explored paradigm that enables the\nsimultaneous learning of multiple tasks using a single model. Despite numerous\nsolutions, the key issues of optimization conflict and task imbalance remain\nunder-addressed, limiting performance. Unlike existing optimization-based\napproaches that typically reweight task losses or gradients to mitigate\nconflicts or promote progress, we propose a novel approach based on Continual\nOptimization with Symmetry Teleportation (COST). During MTL optimization, when\nan optimization conflict arises, we seek an alternative loss-equivalent point\non the loss landscape to reduce conflict. Specifically, we utilize a low-rank\nadapter (LoRA) to facilitate this practical teleportation by designing\nconvergent, loss-invariant objectives. Additionally, we introduce a historical\ntrajectory reuse strategy to continually leverage the benefits of advanced\noptimizers. Extensive experiments on multiple mainstream datasets demonstrate\nthe effectiveness of our approach. COST is a plug-and-play solution that\nenhances a wide range of existing MTL methods. When integrated with\nstate-of-the-art methods, COST achieves superior performance.",
      "tldr_zh": "本研究针对多任务学习 (MTL) 中的优化冲突和任务不平衡问题，提出了一种新方法 Continual Optimization with Symmetry Teleportation (COST)。COST 在优化冲突发生时，通过低秩适配器 (LoRA) 实现损失景观上的等价点“teleportation”，并设计收敛且损失不变的目标，以减少冲突；同时引入历史轨迹重用策略来利用高级优化器的优势。实验结果显示，COST 作为即插即用的解决方案，在多个主流数据集上显著提升了现有 MTL 方法的性能，并在与最先进方法结合时实现了优越表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages,8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04046v1",
      "published_date": "2025-03-06 02:58:09 UTC",
      "updated_date": "2025-03-06 02:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:59:10.387139"
    },
    {
      "arxiv_id": "2503.04021v1",
      "title": "TextDoctor: Unified Document Image Inpainting via Patch Pyramid Diffusion Models",
      "title_zh": "TextDoctor：通过补丁金字塔扩散模型的统一",
      "authors": [
        "Wanglong Lu",
        "Lingming Su",
        "Jingjing Zheng",
        "Vinícius Veloso de Melo",
        "Farzaneh Shoeleh",
        "John Hawkin",
        "Terrence Tricco",
        "Hanli Zhao",
        "Xianta Jiang"
      ],
      "abstract": "Digital versions of real-world text documents often suffer from issues like\nenvironmental corrosion of the original document, low-quality scanning, or\nhuman interference. Existing document restoration and inpainting methods\ntypically struggle with generalizing to unseen document styles and handling\nhigh-resolution images. To address these challenges, we introduce TextDoctor, a\nnovel unified document image inpainting method. Inspired by human reading\nbehavior, TextDoctor restores fundamental text elements from patches and then\napplies diffusion models to entire document images instead of training models\non specific document types. To handle varying text sizes and avoid\nout-of-memory issues, common in high-resolution documents, we propose using\nstructure pyramid prediction and patch pyramid diffusion models. These\ntechniques leverage multiscale inputs and pyramid patches to enhance the\nquality of inpainting both globally and locally. Extensive qualitative and\nquantitative experiments on seven public datasets validated that TextDoctor\noutperforms state-of-the-art methods in restoring various types of\nhigh-resolution document images.",
      "tldr_zh": "该研究针对数字文本文档因环境腐蚀、低质量扫描或人为干扰而导致的损坏问题，提出了TextDoctor，一种统一的文档图像修复方法。该方法受人类阅读行为启发，从patches中恢复基本文本元素，并使用diffusion models处理整个文档图像，而非针对特定文档类型训练模型。为应对不同文本大小和高分辨率图像的内存问题，TextDoctor引入structure pyramid prediction和patch pyramid diffusion models，通过多尺度输入和金字塔patches提升全局和局部修复质量。在七个公共数据集上的广泛实验表明，TextDoctor在修复各种高分辨率文档图像方面优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68U10",
        "I.4.3; I.4.4; I.4.5; I.4.9"
      ],
      "primary_category": "cs.CV",
      "comment": "28 pages, 25 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04021v1",
      "published_date": "2025-03-06 02:16:35 UTC",
      "updated_date": "2025-03-06 02:16:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:59:22.629103"
    },
    {
      "arxiv_id": "2503.07643v1",
      "title": "ConstellationNet: Reinventing Spatial Clustering through GNNs",
      "title_zh": "翻译失败",
      "authors": [
        "Aidan Gao",
        "Junhong Lin"
      ],
      "abstract": "Spatial clustering is a crucial field, finding universal use across\ncriminology, pathology, and urban planning. However, most spatial clustering\nalgorithms cannot pull information from nearby nodes and suffer performance\ndrops when dealing with higher dimensionality and large datasets, making them\nsuboptimal for large-scale and high-dimensional clustering. Due to modern data\ngrowing in size and dimension, clustering algorithms become weaker when\naddressing multifaceted issues. To improve upon this, we develop\nConstellationNet, a convolution neural network(CNN)-graph neural network(GNN)\nframework that leverages the embedding power of a CNN, the neighbor aggregation\nof a GNN, and a neural network's ability to deal with batched data to improve\nspatial clustering and classification with graph augmented predictions.\nConstellationNet achieves state-of-the-art performance on both supervised\nclassification and unsupervised clustering across several datasets,\noutperforming state-of-the-art classification and clustering while reducing\nmodel size and training time by up to tenfold and improving baselines by 10\ntimes. Because of its fast training and powerful nature, ConstellationNet holds\npromise in fields like epidemiology and medical imaging, able to quickly train\non new data to develop robust responses.",
      "tldr_zh": "该论文针对现有空间聚类算法在高维度和大数据集上性能下降的问题，提出 ConstellationNet，一种结合 CNN 和 GNN 的框架，利用 CNN 的嵌入能力、GNN 的邻居聚合机制以及神经网络的批量处理优势来提升空间聚类和分类性能。在多个数据集上，ConstellationNet 在监督分类和无监督聚类中实现了最先进水平，比基线模型提升10倍，同时减少模型大小和训练时间最多十倍。该框架有望应用于流行病学和医学成像等领域，提供快速且鲁棒的响应。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07643v1",
      "published_date": "2025-03-06 02:10:11 UTC",
      "updated_date": "2025-03-06 02:10:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:59:34.688967"
    },
    {
      "arxiv_id": "2503.04013v1",
      "title": "Benchmarking Large Language Models on Multiple Tasks in Bioinformatics NLP with Prompting",
      "title_zh": "通过提示技术对大语言模型在生物信息学自然语言处理的多任务进行基准测试",
      "authors": [
        "Jiyue Jiang",
        "Pengan Chen",
        "Jiuming Wang",
        "Dongchen He",
        "Ziqin Wei",
        "Liang Hong",
        "Licheng Zong",
        "Sheng Wang",
        "Qinze Yu",
        "Zixian Ma",
        "Yanyu Chen",
        "Yimin Fan",
        "Xiangyu Shi",
        "Jiawei Sun",
        "Chuan Wu",
        "Yu Li"
      ],
      "abstract": "Large language models (LLMs) have become important tools in solving\nbiological problems, offering improvements in accuracy and adaptability over\nconventional methods. Several benchmarks have been proposed to evaluate the\nperformance of these LLMs. However, current benchmarks can hardly evaluate the\nperformance of these models across diverse tasks effectively. In this paper, we\nintroduce a comprehensive prompting-based benchmarking framework, termed\nBio-benchmark, which includes 30 key bioinformatics tasks covering areas such\nas proteins, RNA, drugs, electronic health records, and traditional Chinese\nmedicine. Using this benchmark, we evaluate six mainstream LLMs, including\nGPT-4o and Llama-3.1-70b, etc., using 0-shot and few-shot Chain-of-Thought\n(CoT) settings without fine-tuning to reveal their intrinsic capabilities. To\nimprove the efficiency of our evaluations, we demonstrate BioFinder, a new tool\nfor extracting answers from LLM responses, which increases extraction accuracy\nby round 30% compared to existing methods. Our benchmark results show the\nbiological tasks suitable for current LLMs and identify specific areas\nrequiring enhancement. Furthermore, we propose targeted prompt engineering\nstrategies for optimizing LLM performance in these contexts. Based on these\nfindings, we provide recommendations for the development of more robust LLMs\ntailored for various biological applications. This work offers a comprehensive\nevaluation framework and robust tools to support the application of LLMs in\nbioinformatics.",
      "tldr_zh": "本篇论文引入了Bio-benchmark框架，这是一个全面的基于提示的基准，用于评估Large Language Models (LLMs)在生物信息学NLP任务中的性能，涵盖30个关键任务，如蛋白质、RNA和药物等领域。研究者通过0-shot和few-shot Chain-of-Thought (CoT)设置，对包括GPT-4o和Llama-3.1-70b在内的六种主流LLM进行了无微调评估，揭示了它们的内在能力。论文还开发了BioFinder工具，提高了从LLM响应中提取答案的准确性约30%，并基于基准结果识别了适合LLMs的生物任务以及需要改进的领域。最后，作者提出了针对性的提示工程策略和LLM开发推荐，以支持其在生物信息学中的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04013v1",
      "published_date": "2025-03-06 02:01:59 UTC",
      "updated_date": "2025-03-06 02:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:59:48.547475"
    },
    {
      "arxiv_id": "2503.03995v1",
      "title": "Subgraph Federated Learning for Local Generalization",
      "title_zh": "子图联邦学习用于本地泛化",
      "authors": [
        "Sungwon Kim",
        "Yoonho Lee",
        "Yunhak Oh",
        "Namkyeong Lee",
        "Sukwon Yun",
        "Junseok Lee",
        "Sein Kim",
        "Carl Yang",
        "Chanyoung Park"
      ],
      "abstract": "Federated Learning (FL) on graphs enables collaborative model training to\nenhance performance without compromising the privacy of each client. However,\nexisting methods often overlook the mutable nature of graph data, which\nfrequently introduces new nodes and leads to shifts in label distribution.\nSince they focus solely on performing well on each client's local data, they\nare prone to overfitting to their local distributions (i.e., local\noverfitting), which hinders their ability to generalize to unseen data with\ndiverse label distributions. In contrast, our proposed method, FedLoG,\neffectively tackles this issue by mitigating local overfitting. Our model\ngenerates global synthetic data by condensing the reliable information from\neach class representation and its structural information across clients. Using\nthese synthetic data as a training set, we alleviate the local overfitting\nproblem by adaptively generalizing the absent knowledge within each local\ndataset. This enhances the generalization capabilities of local models,\nenabling them to handle unseen data effectively. Our model outperforms\nbaselines in our proposed experimental settings, which are designed to measure\ngeneralization power to unseen data in practical scenarios. Our code is\navailable at https://github.com/sung-won-kim/FedLoG",
      "tldr_zh": "本研究针对图数据中的联邦学习（Federated Learning, FL），指出现有方法易因图数据的可变性（如新节点和标签分布变化）导致本地过拟合，从而影响对未见数据的泛化。论文提出 FedLoG 方法，通过从各客户端的类表示和结构信息中生成全局合成数据，作为辅助训练集，以适应本地数据集缺失的知识，从而提升本地模型的泛化能力。实验结果显示，FedLoG 在设计用于评估实际场景中未见数据泛化能力的设置下，优于基线模型，并提供了开源代码以供参考。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 (oral)",
      "pdf_url": "http://arxiv.org/pdf/2503.03995v1",
      "published_date": "2025-03-06 01:08:01 UTC",
      "updated_date": "2025-03-06 01:08:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T22:59:59.004422"
    },
    {
      "arxiv_id": "2503.03987v1",
      "title": "RetinalGPT: A Retinal Clinical Preference Conversational Assistant Powered by Large Vision-Language Models",
      "title_zh": "RetinalGPT：基于大型视觉语言模型的视网膜",
      "authors": [
        "Wenhui Zhu",
        "Xin Li",
        "Xiwen Chen",
        "Peijie Qiu",
        "Vamsi Krishna Vasa",
        "Xuanzhao Dong",
        "Yanxi Chen",
        "Natasha Lepore",
        "Oana Dumitrascu",
        "Yi Su",
        "Yalin Wang"
      ],
      "abstract": "Recently, Multimodal Large Language Models (MLLMs) have gained significant\nattention for their remarkable ability to process and analyze non-textual data,\nsuch as images, videos, and audio. Notably, several adaptations of\ngeneral-domain MLLMs to the medical field have been explored, including\nLLaVA-Med. However, these medical adaptations remain insufficiently advanced in\nunderstanding and interpreting retinal images. In contrast, medical experts\nemphasize the importance of quantitative analyses for disease detection and\ninterpretation. This underscores a gap between general-domain and\nmedical-domain MLLMs: while general-domain MLLMs excel in broad applications,\nthey lack the specialized knowledge necessary for precise diagnostic and\ninterpretative tasks in the medical field. To address these challenges, we\nintroduce \\textit{RetinalGPT}, a multimodal conversational assistant for\nclinically preferred quantitative analysis of retinal images. Specifically, we\nachieve this by compiling a large retinal image dataset, developing a novel\ndata pipeline, and employing customized visual instruction tuning to enhance\nboth retinal analysis and enrich medical knowledge. In particular, RetinalGPT\noutperforms MLLM in the generic domain by a large margin in the diagnosis of\nretinal diseases in 8 benchmark retinal datasets. Beyond disease diagnosis,\nRetinalGPT features quantitative analyses and lesion localization, representing\na pioneering step in leveraging LLMs for an interpretable and end-to-end\nclinical research framework. The code is available at\nhttps://github.com/Retinal-Research/RetinalGPT",
      "tldr_zh": "该研究针对 Multimodal Large Language Models (MLLMs) 在视网膜图像分析中的不足，引入了 RetinalGPT，一种基于 Large Vision-Language Models 的多模态对话助手，专注于临床偏好的定量分析。RetinalGPT 通过编译大型视网膜图像数据集、开发新数据管道以及定制的视觉指令 tuning，增强了视网膜疾病诊断和医疗知识的精确性。在8个基准视网膜数据集上，RetinalGPT 显著优于通用 MLLM，提供可解释的定量分析和病变定位，推动了端到端临床研究框架的创新发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03987v1",
      "published_date": "2025-03-06 00:19:54 UTC",
      "updated_date": "2025-03-06 00:19:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:00:11.590056"
    },
    {
      "arxiv_id": "2503.03986v1",
      "title": "Training neural networks faster with minimal tuning using pre-computed lists of hyperparameters for NAdamW",
      "title_zh": "利用预先计算的超参数列表，通过最小调整，更快地训练神经网络，用于 NAdamW",
      "authors": [
        "Sourabh Medapati",
        "Priya Kasimbeg",
        "Shankar Krishnan",
        "Naman Agarwal",
        "George Dahl"
      ],
      "abstract": "If we want to train a neural network using any of the most popular\noptimization algorithms, we are immediately faced with a dilemma: how to set\nthe various optimization and regularization hyperparameters? When computational\nresources are abundant, there are a variety of methods for finding good\nhyperparameter settings, but when resources are limited the only realistic\nchoices are using standard default values of uncertain quality and provenance,\nor tuning only a couple of the most important hyperparameters via extremely\nlimited handdesigned sweeps. Extending the idea of default settings to a modest\ntuning budget, Metz et al. (2020) proposed using ordered lists of\nwell-performing hyperparameter settings, derived from a broad hyperparameter\nsearch on a large library of training workloads. However, to date, no practical\nand performant hyperparameter lists that generalize to representative deep\nlearning workloads have been demonstrated. In this paper, we present\nhyperparameter lists for NAdamW derived from extensive experiments on the\nrealistic workloads in the AlgoPerf: Training Algorithms benchmark. Our\nhyperparameter lists also include values for basic regularization techniques\n(i.e. weight decay, label smoothing, and dropout). In particular, our best\nNAdamW hyperparameter list performs well on AlgoPerf held-out workloads not\nused to construct it, and represents a compelling turn-key approach to tuning\nwhen restricted to five or fewer trials. It also outperforms basic learning\nrate/weight decay sweeps and an off-the-shelf Bayesian optimization tool when\nrestricted to the same budget.",
      "tldr_zh": "本研究针对神经网络训练中的超参数调整问题，提出了一种使用预先计算的超参数列表来加速 NAdamW 优化器的训练方法。该列表基于对 AlgoPerf 基准的广泛实验生成，包括权重衰减（weight decay）、标签平滑（label smoothing）和 dropout 等基本正则化技术。实验结果显示，该方法在限制为五个或更少的试验预算下，在未使用的 held-out 工作负载上表现出色，并优于传统的学习率/权重衰减扫描以及现成的贝叶斯优化（Bayesian optimization）工具。总的来说，这为资源有限的场景提供了高效、可转化的超参数调整策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Good defaults for NadamW Optimizer, generalizes well to unseen\n  problems",
      "pdf_url": "http://arxiv.org/pdf/2503.03986v1",
      "published_date": "2025-03-06 00:14:50 UTC",
      "updated_date": "2025-03-06 00:14:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:00:23.736015"
    },
    {
      "arxiv_id": "2503.05830v1",
      "title": "AI-Facilitated Collective Judgements",
      "title_zh": "翻译失败",
      "authors": [
        "Manon Revel",
        "Théophile Pénigaud"
      ],
      "abstract": "This article unpacks the design choices behind longstanding and newly\nproposed computational frameworks aimed at finding common grounds across\ncollective preferences and examines their potential future impacts, both\ntechnically and normatively. It begins by situating AI-assisted preference\nelicitation within the historical role of opinion polls, emphasizing that\npreferences are shaped by the decision-making context and are seldom\nobjectively captured. With that caveat in mind, we explore AI-facilitated\ncollective judgment as a discovery tool for fostering reasonable\nrepresentations of a collective will, sense-making, and agreement-seeking. At\nthe same time, we caution against dangerously misguided uses, such as enabling\nbinding decisions, fostering gradual disempowerment or post-rationalizing\npolitical outcomes.",
      "tldr_zh": "这篇文章探讨了 AI-facilitated collective judgment 的设计选择及其技术与规范性影响，将其置于历史意见调查的背景下，强调偏好受决策环境影响而非客观捕捉。论文提出 AI 可以作为一种工具，促进集体意愿的合理表示、意义构建和共识寻求，从而帮助发现共同点。同时，作者警告不当使用可能导致风险，如启用绑定决策、逐步权力丧失或事后合理化政治结果。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05830v1",
      "published_date": "2025-03-06 00:06:22 UTC",
      "updated_date": "2025-03-06 00:06:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:00:35.069068"
    },
    {
      "arxiv_id": "2503.03979v1",
      "title": "ReasonGraph: Visualisation of Reasoning Paths",
      "title_zh": "ReasonGraph: 推理路径的可视化",
      "authors": [
        "Zongqian Li",
        "Ehsan Shareghi",
        "Nigel Collier"
      ],
      "abstract": "Large Language Models (LLMs) reasoning processes are challenging to analyze\ndue to their complexity and the lack of organized visualization tools. We\npresent ReasonGraph, a web-based platform for visualizing and analyzing LLM\nreasoning processes. It supports both sequential and tree-based reasoning\nmethods while integrating with major LLM providers and over fifty\nstate-of-the-art models. ReasonGraph incorporates an intuitive UI with meta\nreasoning method selection, configurable visualization parameters, and a\nmodular framework that facilitates efficient extension. Our evaluation shows\nhigh parsing reliability, efficient processing, and strong usability across\nvarious downstream applications. By providing a unified visualization\nframework, ReasonGraph reduces cognitive load in analyzing complex reasoning\npaths, improves error detection in logical processes, and enables more\neffective development of LLM-based applications. The platform is open-source,\npromoting accessibility and reproducibility in LLM reasoning analysis.",
      "tldr_zh": "该论文提出 ReasonGraph，一个基于网络的平台，用于可视化和分析 Large Language Models (LLMs) 的推理过程，以解决其复杂性和缺乏组织化工具的问题。该平台支持顺序和树状推理方法，集成主要 LLM 提供者和超过五十个最先进模型，并提供直观的 UI、元推理方法选择、可配置参数以及模块化框架，便于扩展。评估结果显示 ReasonGraph 具有高解析可靠性、有效处理和强可用性，能够减少分析复杂推理路径的认知负担、提升逻辑过程的错误检测，并促进 LLM 基于应用的开发。该平台是开源的，提升了 LLM 推理分析的可访问性和可重复性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03979v1",
      "published_date": "2025-03-06 00:03:55 UTC",
      "updated_date": "2025-03-06 00:03:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T23:00:47.603479"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 136,
  "processed_papers_count": 136,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-23T23:01:16.801832"
}