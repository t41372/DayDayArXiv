{
  "date": "2025-03-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间2025-03-06的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 上的论文热点依然集中在大型语言模型（LLMs），探讨了从推理能力、可解释性、压缩、安全性到特定应用的方方面面。特别值得关注的是对 LLM 推理鲁棒性、长上下文处理、以及如何通过强化学习控制推理深度的研究。此外，多模态模型（特别是视觉-语言模型）的生成、压缩和对齐也是热门话题。强化学习、联邦学习、机器人学和AI在生物信息、医疗、金融等领域的应用也贡献了大量新成果。一些有趣的论文包括提出了首个评估Web Agent恶意使用的基准 SafeArena，以及探索如何让LLM像贝叶斯一样思考的研究。\n\n以下是今天值得关注的论文：\n\n---\n\n**LLM 推理、能力与评估**\n\n*   **论文标题：L1: 使用强化学习控制推理模型的思考时长 (L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning)**\n    *   摘要：推理语言模型通过生成更长的思维链（CoT）来提高性能，但这会增加计算成本且长度不可控。本文提出长度控制策略优化（LCPO），一种简单的强化学习方法，用于训练 L1 模型，使其在满足用户指定的长度约束下优化准确性。L1 能平滑地权衡计算成本和准确性，在推理长度相同时，1.5B 参数的 L1 甚至能超越 GPT-4o。\n    *   贡献：提出 LCPO 方法和 L1 模型，实现了对 LLM 推理长度的精确控制，并发现了意外的短思维链能力。\n\n*   **论文标题：足够的硬币翻转可以让 LLM 表现得像贝叶斯模型 (Enough Coin Flips Can Make LLMs Act Bayesian)**\n    *   摘要：研究 LLM 是否通过上下文学习（ICL）进行符合贝叶斯框架的结构化推理，还是仅依赖模式匹配。通过模拟有偏硬币翻转的实验发现，LLM 通常有偏见先验，但上下文证据比明确指令更重要。LLM 大致遵循贝叶斯后验更新，偏差主要源于未校准的先验而非更新机制。足够多的 ICL 演示能让 LLM 以贝叶斯方式更新先验。\n    *   贡献：揭示了 LLM 在 ICL 下进行类贝叶斯推理的机制和局限性，强调了先验校准的重要性。\n\n*   **论文标题：基准测试大型语言模型中的推理鲁棒性 (Benchmarking Reasoning Robustness in Large Language Models)**\n    *   摘要：尽管 LLM 在推理任务上取得成功，但本文首次发现其在处理新颖或不完整数据时性能显著下降，表明其依赖记忆模式而非系统推理。研究揭示了位置偏差、指令敏感性、数值脆弱性和记忆依赖等局限性。为全面研究这些挑战，本文引入了 Math-RoB 基准，通过利用缺失信息引发的幻觉来暴露推理差距。\n    *   贡献：识别并系统分析了 LLM 推理中的四种鲁棒性问题，并提出了 Math-RoB 基准用于评估。\n\n*   **论文标题：DAST: 面向大型推理模型的难度自适应慢思考 (DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models)**\n    *   摘要：当前的慢思考推理模型在简单问题上存在“过度思考”导致计算资源浪费。本文提出难度自适应慢思考（DAST）框架，使模型能根据问题难度自主调整思维链（CoT）长度。通过引入 Token 长度预算（TLB）量化难度，并利用长度感知奖励塑造和长度偏好优化实现 DAST。实验表明 DAST 能有效减少过度思考（平均减少 30% Token 使用），同时保持复杂问题的推理准确性。\n    *   贡献：提出 DAST 框架，使 LLM 能根据问题难度自适应调整推理深度，平衡效率与性能。\n\n*   **论文标题：SOLAR: 面向推理的大规模架构可扩展优化 (SOLAR: Scalable Optimization of Large-scale Architecture for Reasoning)**\n    *   摘要：现有 LLM 的思维链（CoT）方法难以处理需要更复杂拓扑推理的任务。本文提出 SOLAR 框架，动态优化各种推理拓扑以提高准确性和效率。通过拓扑标注生成（TAG）系统自动化创建数据集，并提出拓扑扩展（Topological-Scaling）奖励驱动框架，使 LLM 具备自适应、任务感知的推理能力。同时训练了一个多任务拓扑奖励模型（M-TRM）来自主选择最佳推理拓扑和答案。\n    *   贡献：提出 SOLAR 框架和 M-TRM 模型，显著提升了 LLM 在数学推理任务上的性能和效率，并引入了自动化标注和动态拓扑竞争机制。\n\n*   **论文标题：语言模型中的组合因果推理评估 (Compositional Causal Reasoning Evaluation in Language Models)**\n    *   摘要：本文探讨了组合因果推理（CCR）——即推断因果度量如何组合以及因果量如何在图中传播的能力。提出了一个系统评估 CCR 的框架，并以平均处理效应和必要充分概率为例。在 Llama、Phi 和 GPT 系列模型上的数学应用题实验中，该框架揭示了多种不同的错误模式，并发现 CCR 错误随因果路径复杂性增加而增加（o1 除外）。\n    *   贡献：提出了评估 LLM 组合因果推理能力的框架和任务设计方法。\n\n**LLM 训练、压缩与效率**\n\n*   **论文标题：可预测的规模：第一部分 -- 大型语言模型预训练中的最优超参数缩放定律 (Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining)**\n    *   摘要：通过大规模实验（近百万 H800 GPU 小时，训练 3700 个 LLM），本文发现了 LLM 预训练中超参数的通用缩放定律：最优学习率与模型参数和数据大小呈幂律关系，最优批大小主要与数据大小相关。分析揭示了固定模型和数据下超参数的凸优化景观。这些定律对模型稀疏性、训练数据分布和模型形状（包括 MoE 和密集 Transformer）具有鲁棒性。\n    *   贡献：首次统一了不同模型结构和数据分布下的最优超参数缩放定律，并提供了即插即用的超参数工具。\n\n*   **论文标题：MoE 的持续预训练：你的路由器有多鲁棒？(Continual Pre-training of MoEs: How robust is your router?)**\n    *   摘要：研究了稀疏激活专家混合（MoE）Transformer 在持续预训练（CPT）中的表现，特别是路由算法的影响。通过大规模实验（>2B 参数模型，600B tokens 训练）发现，即使没有回放（replay），MoE 路由算法（Sinkhorn-Balanced 和 Z-and-Aux-loss-balanced）对分布变化也表现出惊人的鲁棒性。MoE LLM 在 CPT 期间保持了其样本效率，并能以较低成本达到完全重训练的性能。\n    *   贡献：证明了 MoE 模型在持续预训练中的鲁棒性和效率，表明现有 CPT 策略对其有效。\n\n*   **论文标题：Wanda++: 通过区域梯度修剪大型语言模型 (Wanda++: Pruning Large Language Models via Regional Gradients)**\n    *   摘要：提出 Wanda++，一种新的 LLM 剪枝框架，利用解码器块级别的区域梯度来改进剪枝评分，并通过高效的区域优化方法最小化剪枝引起的输出差异。Wanda++ 在语言建模任务上相比 Wanda 显著提高了困惑度（高达 32%），并能有效泛化到下游任务。该方法轻量级，可在单个 H100 GPU 上 10 分钟内完成 7B LLaMA 模型的剪枝。\n    *   贡献：提出基于区域梯度的剪枝方法 Wanda++，在不进行全模型稀疏感知微调的情况下优于现有方法。\n\n*   **论文标题：超越 RAG：面向全面知识推理的任务感知 KV Cache 压缩 (Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge Reasoning)**\n    *   摘要：提出一种任务感知的键值（KV）缓存压缩方法，在零样本或少样本设置下压缩外部知识，使 LLM 能在压缩表示上高效推理。实验表明，该方法优于 RAG 和任务无关的压缩方法。在 LongBench v2 上，以 30 倍压缩率将准确率提高 7 个绝对点，并将推理延迟从 0.43s 降至 0.16s。\n    *   贡献：提出任务感知的 KV Cache 压缩方法，在需要广泛知识的任务上优于 RAG。\n\n*   **论文标题：Balcony: 一种生成式语言模型的轻量级动态推理方法 (Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models)**\n    *   摘要：提出 Balcony，一个简单有效的基于深度的动态推理框架。通过冻结预训练 LLM 并在选定退出点插入额外 Transformer 层，Balcony 保持全模型性能，同时允许实时适应不同计算预算。额外层通过简单的自蒸馏损失训练。该方法训练成本低，应用于 LLaMA3-8B 时性能损失小，速度显著提升，优于 Flextron、Layerskip 等方法。\n    *   贡献：提出轻量级、高效的动态推理框架 Balcony，训练成本低，性能优越。\n\n*   **论文标题：层级熵加权量化的普适性：超越模型架构和规模 (Universality of Layer-Level Entropy-Weighted Quantization Beyond Model Architecture and Size)**\n    *   摘要：提出一种基于熵加权量化（EWQ）的选择性模型量化方法，通过分析 Transformer 块的熵分布来确定哪些块可以安全量化，且与模型架构或大小无关。该方法优于均匀量化，能在保持 MMLU 准确率损失小于 0.5% 的同时减少高达 18% 的内存使用。EWQ 甚至能降低困惑度，表明选择性精度降低可能带来有益的正则化。还提出了 FastEWQ，一种无需加载模型权重的快速熵分析方法。\n    *   贡献：提出 EWQ 量化方法，证明了层级熵与最优精度需求的普适关系，并开发了快速版本 FastEWQ。\n\n*   **论文标题：Speculative MoE: 具有推测性 Token 和专家预调度的通信高效并行 MoE 推理 (Speculative MoE: Communication Efficient Parallel MoE Inference with Speculative Token and Expert Pre-scheduling)**\n    *   摘要：MoE 推理的瓶颈在于专家并行（EP）中昂贵的 all-to-all 通信。本文提出 Speculative MoE 技术，通过推测性 Token shuffling 和推测性专家 grouping 两种方案，预测 Token 的专家路由路径，并预先调度 Token 和专家以减少 EP 的通信量。实验表明，该技术能显著提升现有 MoE 推理框架（如 DeepSpeed-MoE, SGLang）在不同互连网络下的效率。\n    *   贡献：提出 Speculative MoE，通过预测和预调度减少 MoE 推理中的通信开销。\n\n*   **论文标题：HybridNorm: 通过混合归一化实现稳定高效的 Transformer 训练 (HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid Normalization)**\n    *   摘要：Transformer 训练中层归一化（Layer Normalization）的位置影响稳定性和性能（Pre-Norm 易训练但性能稍差，Post-Norm 反之）。本文提出 HybridNorm，一种混合归一化策略，在注意力机制中使用 QKV 归一化，在前馈网络（FFN）中使用 Post-Norm。这种设计结合了 Pre-Norm 和 Post-Norm 的优点，既稳定训练又提升性能，尤其在 LLM 中效果显著。\n    *   贡献：提出 HybridNorm 归一化策略，提升 Transformer 训练的稳定性和性能。\n\n*   **论文标题：IDInit: 一种通用且稳定的神经网络训练初始化方法 (IDInit: A Universal and Stable Initialization Method for Neural Network Training)**\n    *   摘要：现有保持层内恒等变换的初始化方法（如 Fixup）通过将特定权重设为零实现，但剩余权重的设置可能影响归纳偏置。本文提出全恒等初始化（IDInit），在残差网络的主干和子分支层都保持恒等性。IDInit 使用填充的类单位矩阵处理非方阵权重，并通过 SGD 解决单位矩阵的收敛问题。该方法简单有效，在多种设置下提升了收敛性、稳定性和性能。\n    *   贡献：提出 IDInit 初始化方法，通过全恒等初始化提升神经网络训练效果。\n\n**LLM 安全、对齐与伦理**\n\n*   **论文标题：SafeArena: 评估自主 Web Agent 的安全性 (SafeArena: Evaluating the Safety of Autonomous Web Agents)**\n    *   摘要：LLM Agent 在解决 Web 任务方面能力增强，但也带来了被恶意使用的风险。本文提出 SafeArena，首个关注 Web Agent 蓄意滥用风险的基准。包含 4 个网站上的 250 个安全任务和 250 个有害任务（分 5 类）。评估了 GPT-4o, Claude-3.5 Sonnet 等主流 Agent，发现它们对恶意请求的遵从度惊人地高（如 GPT-4o 完成了 34.7% 的有害请求）。\n    *   贡献：提出首个评估 Web Agent 恶意使用的基准 SafeArena，并揭示了当前 Agent 的安全风险。\n\n*   **论文标题：标记你的 LLM：通过水印检测开源大型语言模型的滥用 (Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models via Watermarking)**\n    *   摘要：随着 Llama3 等开源 LLM 能力增强，需要水印技术检测其潜在滥用。现有水印方法不适用于开源 LLM 或主要针对分类模型。本文定义了 IP 侵犯和 LLM 使用违规两种滥用场景，探索了推理时水印蒸馏和后门水印的应用。实验表明，后门水印能有效检测 IP 侵犯，而水印蒸馏适用两种场景但对微调鲁棒性较差且影响性能更大。\n    *   贡献：定义了开源 LLM 的滥用场景，并评估了两种水印技术在这些场景下的有效性和局限性。\n\n*   **论文标题：AgentSafe: 通过分层数据管理保护基于 LLM 的多智能体系统 (AgentSafe: Safeguarding Large Language Model-based Multi-agent Systems via Hierarchical Data Management)**\n    *   摘要：基于 LLM 的多智能体系统（MAS）易受未授权访问和数据泄露等安全威胁。本文提出 AgentSafe 框架，通过分层信息管理和内存保护增强 MAS 安全性。AgentSafe 按安全级别分类信息，限制敏感数据访问。包含 ThreatSieve（验证信息权限，防止冒充）和 HierarCache（自适应内存管理，防御未授权访问和恶意投毒）。实验表明 AgentSafe 能显著提升系统弹性。\n    *   贡献：提出 AgentSafe 框架，包含 ThreatSieve 和 HierarCache 组件，首次系统性地为 Agent 内存提供防御。\n\n*   **论文标题：一击即中：将多轮攻击整合为针对 LLM 的高效单轮提示 (One-Shot is Enough: Consolidating Multi-Turn Attacks into Efficient Single-Turn Prompts for LLMs)**\n    *   摘要：多轮“越狱”对话能绕过 LLM 安全护栏，但需要大量人工。本文提出 Multi-turn-to-Single-turn (M2S) 方法，系统地将多轮越狱提示转换为单轮攻击。提出了三种转换策略（Hyphenize, Numberize, Pythonize）。实验表明 M2S 能保持甚至提高攻击成功率（ASR），有时甚至优于原始多轮攻击。这表明单轮攻击同样强大，需要重新评估 LLM 安全策略。\n    *   贡献：提出 M2S 方法，证明多轮攻击可压缩为高效的单轮攻击，揭示了 LLM 安全的新挑战。\n\n*   **论文标题：激活空间干预可在大型语言模型间迁移 (Activation Space Interventions Can Be Transferred Between Large Language Models)**\n    *   摘要：研究表明 AI 模型表示具有普遍性，但其实际应用探索不足。本文证明安全干预措施（如后门移除、拒绝有害提示）可以通过学习共享激活空间的映射在模型间迁移。实验表明，该方法可用小模型高效对齐大模型。此外，基础模型和微调模型间的自编码器映射可作为“轻量级安全开关”，动态切换模型行为。\n    *   贡献：首次证明了安全相关的激活空间干预可以在不同 LLM 间迁移，并提出“轻量级安全开关”概念。\n\n*   **论文标题：揭示大型语言模型在不同语言间学习新知识的不平等性 (Uncovering inequalities in new knowledge learning by large language models across different languages)**\n    *   摘要：现有研究多关注 LLM 在不同语言间现有知识和能力的静态差异。本文探讨了 LLM 在学习新知识过程中的语言不平等性，考察了有效性、可迁移性、优先级和鲁棒性四个维度。通过在上下文学习和微调两种设置下对多种模型的实验，发现低资源语言在所有四个维度上都持续处于劣势。\n    *   贡献：揭示了 LLM 在动态学习新知识过程中存在的显著语言不平等现象。\n\n*   **论文标题：LLM 推理准确性和解释中的差异：非裔美国人英语案例研究 (Disparities in LLM Reasoning Accuracy and Explanations: A Case Study on African American English)**\n    *   摘要：系统研究了 LLM 推理任务中的方言差异。开发了一个比较 LLM 在标准美国英语（SAE）和非裔美国人英语（AAE）提示下表现的框架。发现 LLM 对 AAE 输入的响应准确性较低，推理链和解释更简单，尤其在社会科学和人文学科领域。\n    *   贡献：揭示了 LLM 在处理不同语言变体（特别是 AAE）时存在的系统性推理准确性和解释质量差异。\n\n**多模态模型 (视觉-语言等)**\n\n*   **论文标题：两全其美：整合语言模型和扩散模型进行视频生成 (The Best of Both Worlds: Integrating Language Models and Diffusion Models for Video Generation)**\n    *   摘要：当前的文本到视频（T2V）生成由自回归语言模型和扩散模型主导，各有优劣。本文提出 LanDiff，一个混合框架，通过粗到精生成结合两者优势。包含语义分词器（压缩 3D 视觉特征）、生成语义 Token 的语言模型、以及将粗糙语义精炼为高保真视频的流式扩散模型。5B 参数的 LanDiff 在 VBench T2V 基准上超越了开源 SOTA 模型。\n    *   贡献：提出 LanDiff 混合框架，结合 LM 和 Diffusion 优势，在 T2V 和长视频生成上取得 SOTA 性能。\n\n*   **论文标题：模拟真实世界：多模态生成模型的统一综述 (Simulating the Real World: A Unified Survey of Multimodal Generative Models)**\n    *   摘要：本文提供了一个统一的多模态生成模型综述，探讨了真实世界模拟中数据维度的进展，从 2D（外观）到视频（外观+动态）、3D（外观+几何），最终到 4D（集成所有维度）。这是首次尝试在单一框架内系统统一 2D、视频、3D 和 4D 生成的研究。综述涵盖了数据集、评估指标和未来方向。\n    *   贡献：首次提出了一个统一框架来综述跨越 2D 到 4D 的多模态生成模型，旨在模拟真实世界。\n\n*   **论文标题：LVLM-Compress-Bench: 基准测试大型视觉语言模型压缩的更广泛影响 (LVLM-Compress-Bench: Benchmarking the Broader Impact of Large Vision-Language Model Compression)**\n    *   摘要：现有 LLM 压缩影响研究主要关注单模态任务，缺乏对多模态大型视觉语言模型（LVLM）的深入研究。本文提出 LVLM-Compress-Bench 框架，全面研究 KV Cache 压缩和权重压缩对 LVLM 生成性能（包括识别、知识、生成、推理、幻觉、毒性、偏见等）的广泛影响。实验揭示了不同量化预算下 LVLM 行为的复杂性。\n    *   贡献：提出首个全面评估压缩对 LVLM 性能和伦理影响的基准框架 LVLM-Compress-Bench。\n\n*   **论文标题：SHAPE: 通过迭代生成整体更优响应来自我改进视觉偏好对齐 (SHAPE : Self-Improved Visual Preference Alignment by Iteratively Generating Holistic Winner)**\n    *   摘要：现有 LVLM 偏好对齐依赖人工标注数据，成本高且多样性有限。本文提出 SHAPE，一个自监督框架，将现有的图文对转换为偏好三元组（图像-更优文本-较差文本）用于 LVLM 对齐，无需人工偏好标注。通过迭代自我改进，LVLM 能逐步提升对齐能力。实验表明 SHAPE 能显著提升模型在多个基准上的表现。\n    *   贡献：提出 SHAPE 自监督框架，能自动生成高质量偏好数据，有效且低成本地进行 LVLM 偏好对齐。\n\n*   **论文标题：TPC: 通过跨时间预测连接减少视觉语言模型幻觉 (TPC: Cross-Temporal Prediction Connection for Vision-Language Model Hallucination Reduction)**\n    *   摘要：VLM 倾向于依赖语言先验，导致幻觉（描述图像中不存在的对象或属性）。本文观察到 logits 的连续性一致性增强特性，提出跨时间预测连接（TPC）方法，通过在时间步之间连接 logits 来增强其语义一致性。TPC 增强信息流和一致性，有效减少幻觉。实验表明 TPC 在准确性和效率上优于现有方法。\n    *   贡献：提出 TPC 方法，通过增强 logits 的时间一致性来减少 VLM 幻觉。\n\n*   **论文标题：MASTER: 带文本提示的多模态分割 (MASTER: Multimodal Segmentation with Text Prompts)**\n    *   摘要：RGB-热成像融合有助于全天候场景理解，但现有方法模块复杂。本文利用 LLM 优势，提出 MASTER 架构，将 LLM 集成到 RGB-热成像数据融合中，并允许复杂查询文本参与融合过程。模型使用双路径结构提取图像信息，LLM 作为核心融合模块生成可学习的 codebook tokens，最后由轻量级解码器输出分割结果。\n    *   贡献：提出 MASTER 架构，利用 LLM 进行 RGB-热成像和文本提示的多模态融合分割。\n\n*   **论文标题：视觉模态在多模态数学推理中的作用：挑战与洞见 (The Role of Visual Modality in Multimodal Mathematical Reasoning: Challenges and Insights)**\n    *   摘要：现有 multimodal math 模型对视觉信息的利用有限，性能受图像变化影响小，部分原因是文本信息主导和选项提示。本文提出 HC-M3D 数据集，强制依赖图像解决问题，并包含细微视觉差异导致答案变化的挑战性样本。测试表明当前模型难以察觉这些差异。同时发现，提升通用 VQA 能力的图像编码器组合对数学推理性能无益。\n    *   贡献：揭示了当前多模态数学模型对视觉信息依赖不足的问题，并提出了 HC-M3D 数据集来评估和挑战视觉依赖性。\n\n**强化学习 (RL) 与机器人学**\n\n*   **论文标题：用于最优自动机条件强化学习的可证明正确的自动机嵌入 (Provably Correct Automata Embeddings for Optimal Automata-Conditioned Reinforcement Learning)**\n    *   摘要：自动机条件 RL 用于学习能执行运行时给定的时序扩展目标的多任务策略。本文为此问题提供了理论框架，证明其是可能近似正确可学习的，并提出了一种学习可证明正确的自动机嵌入的技术，保证了最优多任务策略学习。\n    *   贡献：为自动机条件 RL 提供了理论保证，并提出了学习可证明正确嵌入的方法。\n\n*   **论文标题：面向真实世界机器人操作的自主强化学习与大型语言模型 (Towards Autonomous Reinforcement Learning for Real-World Robotic Manipulation with Large Language Models)**\n    *   摘要：RL 的奖励函数设计，尤其在真实世界任务中，仍然具有挑战性。本文提出 ARCHIE，一个无监督流程，利用 GPT-4 从自然语言任务描述直接生成奖励函数，用于在模拟环境中训练 RL Agent。GPT-4 还自动化了任务成功标准的编码，实现了从文本到可部署机器人技能的全自动流程。\n    *   贡献：提出 ARCHIE 框架，利用 LLM 自动生成 RL 奖励函数和成功标准，实现机器人技能的自主学习。\n\n*   **论文标题：好奇心驱动的想象：发现规划算子并学习关联策略以适应开放世界 (Curiosity-Driven Imagination: Discovering Plan Operators and Learning Associated Policies for Open-World Adaptation)**\n    *   摘要：为解决机器人在动态不确定环境（开放世界）中的适应性挑战，本文提出一个混合规划与学习系统。该系统集成了一个基于神经网络的低层模型（学习随机转移并通过内在好奇心模块 ICM 驱动探索）和一个高层符号规划模型（捕捉抽象转移并生成奖励机）。实验表明该方法收敛更快，优于现有混合方法。\n    *   贡献：提出结合好奇心驱动探索和符号规划的混合系统，提高机器人在开放世界中的适应能力。\n\n*   **论文标题：来自演示的多智能体逆 Q 学习 (Multi-Agent Inverse Q-Learning from Demonstrations)**\n    *   摘要：多智能体逆强化学习（MARL）旨在从专家演示中推断奖励函数，但现有方法难以平衡合作与竞争目标。本文提出 MAMQL，一种新颖的样本高效 MARL 框架。MAMQL 为每个 Agent 学习一个边缘化其他 Agent 策略的 Critic，并利用单智能体 soft-Q IRL 的优化准则。实验表明 MAMQL 在奖励恢复、样本效率等方面显著优于先前方法。\n    *   贡献：提出 MAMQL 框架，改进了多智能体逆强化学习的性能和样本效率。\n\n*   **论文标题：面向移动机器人的数据高效的人类干预学习 (Data-Efficient Learning from Human Interventions for Mobile Robots)**\n    *   摘要：传统 IL 和 RL 方法需要大量数据或精心设计的奖励，且面临 sim-to-real 差距。本文提出在线人机交互学习方法 PVP4Real，结合 IL 和 RL，无需奖励或预训练，从在线人类干预和演示中高效实时学习策略，显著提高数据效率和训练安全性。在腿式和轮式机器人上的实验验证了其有效性。\n    *   贡献：提出 PVP4Real 方法，实现了无需奖励、数据高效且安全的真实世界机器人策略学习。\n\n**联邦学习 (FL)**\n\n*   **论文标题：用于个体治疗效果估计的联邦逆概率处理加权 (Federated Inverse Probability Treatment Weighting for Individual Treatment Effect Estimation)**\n    *   摘要：个体治疗效果（ITE）估计在医疗中至关重要，但现有方法多用于中心化设置。本文研究联邦设置下的 ITE 估计，允许多家医院协作。为解决联邦设置下逆概率处理加权（IPTW）的挑战（局部模型仍受混淆偏倚影响），提出 FED-IPTW 算法，强制全局和局部协变量与处理的去相关。在 ICU 机械通气效果预测任务上验证了有效性。\n    *   贡献：提出 FED-IPTW 算法，将 IPTW 扩展到联邦学习，有效处理混淆偏倚。\n\n*   **论文标题：激励网络边缘基础模型的多租户分裂联邦学习 (Incentivizing Multi-Tenant Split Federated Learning for Foundation Models at the Network Edge)**\n    *   摘要：分裂联邦学习（SFL）允许在资源受限设备上微调基础模型（FM），部分计算卸载到边缘服务器。实际边缘网络常有多 SFL 租户。本文提出 PRINCE 价格激励机制，引导多租户提供策略性价格激励，吸引高质量设备参与，满足各租户不同的 FM 微调需求。通过建模租户间设备竞争为拥塞博弈，推导最优激励策略。\n    *   贡献：提出 PRINCE 激励机制，有效协调多租户 SFL 场景下的设备参与和资源分配。\n\n*   **论文标题：面向非独立同分布设置的跨孤岛联邦学习的隐私保护与鲁棒聚合 (Privacy Preserving and Robust Aggregation for Cross-Silo Federated Learning in Non-IID Settings)**\n    *   摘要：FedAvg 在非 IID 数据下性能下降，且传输样本数元数据存在隐私风险。本文提出一种新的聚合策略，引入类感知梯度掩码，仅依赖梯度更新，无需额外元数据，增强隐私。同时，根据类特定重要性验证和动态加权客户端贡献，确保对非 IID 分布、收敛阻止和后门攻击的鲁棒性。\n    *   贡献：提出基于类感知梯度掩码的 FL 聚合策略，增强了隐私保护和在非 IID 及对抗场景下的鲁棒性。\n\n**AI 应用与其他**\n\n*   **论文标题：大型语言模型重塑软件开发中的人、流程、产品和社会：与早期采用者的全面探索 (LLMs' Reshaping of People, Processes, Products, and Society in Software Development: A Comprehensive Exploration with Early Adopters)**\n    *   摘要：通过对 16 位早期采用 LLM 的专业开发人员进行访谈，探讨 LLM 对软件工程四个维度（人、流程、产品、社会）的影响。发现 LLM 虽未根本改变开发流程，但显著增强了日常编码任务（代码生成、重构、调试），尤其在问题分解清晰时效果最佳。LLM 对个人和专业发展（学习新语言/概念）价值显著。挑战包括生成内容不准确和需要人工审查。\n    *   贡献：对 LLM 在软件开发中的实际应用、影响和挑战进行了深入的定性研究。\n\n*   **论文标题：从想法到 CAD：一个语言模型驱动的多智能体系统用于协同设计 (From Idea to CAD: A Language Model-Driven Multi-Agent System for Collaborative Design)**\n    *   摘要：提出一个基于 VLM 的多智能体系统，模拟工程团队（需求、CAD、质保），可根据草图和/或文本描述自动生成参数化 CAD 模型。系统包含需求工程、CAD 工程和基于视觉的质量保证 Agent，并允许用户在迭代验证循环中协同改进模型。\n    *   贡献：构建了一个多智能体系统，实现了从自然语言/草图到 CAD 模型的自动化和协同设计。\n\n*   **论文标题：TS-RAG: 基于检索增强生成的时序基础模型是更强的零样本预测器 (TS-RAG: Retrieval-Augmented Generation based Time Series Foundation Models are Stronger Zero-Shot Forecaster)**\n    *   摘要：现有时间序列基础模型（TSFM）缺乏领域自适应机制且可解释性有限。本文提出 TS-RAG 框架，利用预训练时序编码器从知识库检索相关时序片段，并通过可学习的 MoE 模块融合检索到的模式与 TSFM 的输入表示，提升零样本预测能力和可解释性，无需任务特定微调。\n    *   贡献：提出 TS-RAG 框架，通过检索增强提升了时间序列基础模型的零样本预测性能和可解释性。\n\n*   **论文标题：RetinalGPT: 由大型视觉语言模型驱动的视网膜临床偏好对话助手 (RetinalGPT: A Retinal Clinical Preference Conversational Assistant Powered by Large Vision-Language Models)**\n    *   摘要：现有医疗 MLLM 在理解视网膜图像方面不足，且缺乏定量分析能力。本文提出 RetinalGPT，一个面向视网膜图像临床偏好定量分析的多模态对话助手。通过构建大型视网膜数据集、新颖数据流程和定制化视觉指令调优，RetinalGPT 在视网膜疾病诊断、定量分析和病灶定位方面表现优越。\n    *   贡献：开发了 RetinalGPT，一个专注于视网膜图像定量分析和解释的 MLLM 对话助手。\n\n*   **论文标题：KidneyTalk-open: 无代码部署带有医学文档增强知识库的私有大型语言模型用于肾脏疾病 (KidneyTalk-open: No-code Deployment of a Private Large Language Model with Medical Documentation-Enhanced Knowledge Database for Kidney Disease)**\n    *   摘要：为解决肾脏病隐私保护医疗决策支持的挑战，开发了 KidneyTalk-open 桌面系统。该系统支持 SOTA 开源 LLM 的无代码本地部署，包含结合上下文感知分块和智能过滤的医学文档处理流程，以及利用 Agent 协作提高文档召回率的自适应检索增强流程（AddRep）。图形界面方便临床医生使用。\n    *   贡献：首个无代码、支持本地部署和医学文档增强的医疗 LLM 系统，降低了技术门槛，保护隐私。\n\n*   **论文标题：能量-延迟攻击：深度学习的新对抗威胁 (Energy-Latency Attacks: A New Adversarial Threat to Deep Learning)**\n    *   摘要：针对 DNN 能效优化的设计（如自适应 DNN、能效硬件）可能引入新的漏洞。攻击者可利用这些设计触发最坏性能场景，增加延迟和能耗，即能量-延迟攻击，可能导致 DoS。本文全面综述了该领域研究，分类攻击、探讨度量指标、分析现有策略和防御机制，并指出未来研究方向。\n    *   贡献：对新兴的能量-延迟攻击进行了全面的综述和分析。\n\n---\n\n**快速浏览:**\n\n*   **XAI for LLMs (1):** 提出了评估 LLM 的 XAI 技术有效性的统一框架和新指标。 (注意：与 arXiv:2501.15374 文本重叠较多)\n*   **医疗图像+GCN (3):** 利用解剖标志改进基于四面体网格的图卷积网络，用于阿尔茨海默病诊断。\n*   **合成数据隐私 (9):** 通过专家共识提出了评估合成数据隐私的框架，强调成员和属性泄露风险，不鼓励使用相似性度量。\n*   **政策文件中的研究相关性 (10):** 使用 LLM 和 NLP 技术量化美国政策文件中引用的青年研究的相关性，发现大部分是相关的。\n*   **Deepfake 文本检测 (19):** 探索使用增强审议的对话系统 DeepFakeDeLiBot 辅助小组协作检测 Deepfake 文本，发现小组协作优于个人，聊天机器人能改善小组动态。\n*   **新兴语言中的 VQ (20):** 提出 VQEL 方法，使用向量量化使 Agent 能在自玩参照游戏中自主发展离散符号表示。\n*   **GNSS 不确定性量化 (21):** 提出基于学习的方法（离线异常预测和在线噪声分布近似）来量化 GNSS 测量不确定性。\n*   **生物医学 NER 数据生成 (23):** 提出 HILGEN 方法，结合 UMLS 知识库和 LLM 生成的合成数据，用于改进生物医学命名实体识别（NER）。\n*   **长上下文 LLM (24, 25):** 论文 24 建立了关于长程依赖的互信息缩放定律，指导长上下文建模；论文 25 呼吁将研究重点从长输入转向长输出生成。\n*   **TTS 数据集扩展 (28):** 提出 ParaSpeechCaps，一个用丰富风格字幕标注语音的大规模数据集，并用其改进了 Parler-TTS 模型。\n*   **儿童语音识别 (29):** 比较并优化了 WavLM 等自监督模型用于法语儿童语音识别，发现 WavLM base+ 表现最佳且鲁棒。\n*   **矩阵分解用于链接预测 (32):** 提出新的加权、布尔和推荐 NMF 方法及集成变体，用于网络中的缺失链接预测，并集成了自动秩估计和不确定性量化。\n*   **机器人模仿学习域迁移 (34):** 提出 Adapt3R，一种自适应 3D 场景表示编码器，用于改善模仿学习策略在跨实体和新相机姿态设置下的泛化能力。\n*   **精神分裂症识别 (35):** 使用机器学习分类器，结合 EEG、ERP 和人口统计学特征区分精神分裂症患者和健康对照组，准确率达 99.93%。\n*   **多语言偏好对齐 (36):** 提出隐式跨语言奖励方法，利用已对齐的英语模型隐式奖励来标注跨语言数据，实现高效多语言 DPO 微调。\n*   **LLM 应用生态 (43):** 展望 LLM 应用的未来，提出解耦架构以促进开放、安全、可互操作的 LLM 生态系统。\n*   **金融情感分析 LLM (44):** 评估 LLM 作为金融情感分析（FSA）上下文学习者的能力，发现 LLM 具备 FSA 的 ICL 能力。\n*   **模型蒸馏 (45):** 提出 Branch-Merge 蒸馏方法，通过领域特定 SFT 选择性蒸馏和模型合并来压缩 LLM。\n*   **价值驱动决策 (46):** 提出 ValuePilot 框架，包含数据集生成工具 DGT 和决策模块 DMM，用于基于人类价值偏好的个性化决策。\n*   **安全聚合 (47):** 研究了循环用户关联模式下的分层安全聚合（HSA）的基本限制，提出了高效聚合方案并推导了通信和密钥率的界限。\n*   **解释性搜索 (54):** 提出 STX-Search，一种用于连续动态时空模型（如图数据）的实例级解释生成方法。\n*   **模型工程中的多模态摘要 (55):** 探索多模态 LLM 在模型驱动工程（MBE）中理解 UML/EMF 图的能力。\n*   **时间线分析 (56):** 提出 LvS 方法，受认知科学启发，用于转换和分析高维时间线数据，识别异常和趋势。\n*   **光流估计 (57):** 提出 ReynoldsFlow，一种受雷诺输运定理启发的无需训练的光流估计算法。\n*   **视觉中的非概念内容 (58):** 哲学探讨，认为视觉中必须存在封装的非概念内容。\n*   **离散扩散模型 (59):** 提出通用插值离散扩散（GIDD）过程，改进了掩码扩散，在扩散语言建模中达到 SOTA。\n*   **Agent 工具测试 (60):** 提出 ToolFuzz，首个自动化测试 Agent 工具文档的方法，用于发现导致运行时错误或不正确响应的用户查询。\n*   **视觉语言模型调优 (50):** 系统回顾和基准测试了 MLLM 下游任务调优的三种范式，旨在解决任务专家化和灾难性遗忘问题。\n*   **因果可靠概念瓶颈模型 (73):** 提出 C2BMs，一种基于概念的模型，其推理通过符合真实世界因果机制的概念瓶颈进行，提高了可解释性和因果可靠性。\n*   **药物发现框架 (74):** 提出 BIT，一个通用的跨域分子学习框架，用于基于结构的药物发现。\n*   **人脸识别隐私 (75):** 综述了云提供商（微软、AWS、谷歌）在人脸识别服务中实现隐私保护的方法。\n*   **单细胞数据蒸馏 (76):** 提出 scDD 框架，利用基础模型知识进行 scRNA-seq 数据集蒸馏，生成紧凑的合成数据集。\n*   **人机交互解释 (77):** 探讨人类向 AI 提供解释如何促进更协同的人机系统。\n*   **词义消歧/归纳 (78):** 展示如何利用 LLM 和词典示例为资源匮乏语言解决 WSD 和 WSI 任务。\n*   **鲁棒优化 (79):** 提出 Statistically Robust WDRO 框架，通过考虑统计误差来缓解 WDRO 中的鲁棒过拟合问题。\n*   **边缘恶意软件检测 (80):** 评估使用轻量级 LLM 在边缘设备上进行恶意软件检测的性能。\n*   **边缘视频分析能效 (81):** 提出 E4 框架，结合早退机制和 DVFS，提高边缘视频分析中 DNN 推理的能效。\n*   **AI 风险量化 (82):** 探索如何通过专家启发将 AI 基准数据映射到定量风险估计。\n*   **数学错误检查 (83):** 演示 MathMistake Checker 系统，使用 LLM 自动查找数学问题解答中的步骤错误。\n*   **黑客松创意评估 (84):** 分析大型黑客松数据集，识别促进创意的因素，并探讨使用 LLM 辅助评估创意。\n*   **时间敏感场景 XAI (85):** 提出 Poem 算法，一种预取离线解释模型，为时间敏感场景提供快速有效的图像解释（范例、反事实、显著图）。\n*   **RL/MARL 网络安全指南 (88):** 为在网络安全应用中使用 RL 和 MARL 提供结构化指南。\n*   **XAI 评估框架 (89):** 提出 VirtualXAI 框架，结合定量基准和基于 LLM 生成角色的定性用户评估来评估 XAI 方法。\n*   **高斯表示学习 (90):** 改进 GaussianFormer，通过时空自注意力机制学习 3D 语义占据预测的高斯表示。\n*   **文本-音频增量学习 (91):** 提出 TAIL 任务和 PTAT 方法，使用提示调优和蒸馏解决文本-音频检索中的增量学习和灾难性遗忘问题。\n*   **文本到运动合成 (92):** 提出针对大词汇量对象（如动物）的文本到运动合成方法，解决了缺乏多样化数据和异构骨架的问题。\n*   **持续模型基 RL (93):** 提出 DRAGO 方法，通过合成经验回放和探索机制，在连续任务序列中保持和利用世界模型知识。\n*   **弱到强泛化过拟合 (94):** 提出两阶段框架，通过提高监督信号质量和输入问题质量来缓解弱到强泛化中的过拟合问题。\n*   **联邦学习聚类 (95):** 提出 OCFL 算法，能在联邦学习中自动检测最早合适的聚类时机，实现个性化模型训练。\n*   **量子启发 RL (96):** 提出 EA-MDP 框架，使用量子力学形式主义处理决策中由冲突证据引起的认知矛盾（EA）不确定性。\n*   **LLM 主题分析饱和度 (97):** 探讨 LLM 在主题分析初始编码阶段实现分析饱和度的问题，并提出测量归纳主题饱和度（ITS）的新技术。\n*   **文档图像修复 (128):** 提出 TextDoctor，使用补丁金字塔扩散模型统一修复各种类型的高分辨率文档图像。\n*   **图神经网络空间聚类 (129):** 提出 ConstellationNet，一个 CNN-GNN 框架，用于改进大规模高维数据的空间聚类和分类。\n*   **生物信息 NLP 基准 (130):** 提出 Bio-benchmark，包含 30 个生物信息 NLP 任务，使用提示评估主流 LLM 的能力。\n*   **子图联邦学习 (131):** 提出 FedLoG，通过生成全局合成数据来缓解 FL 中的局部过拟合，增强对具有不同标签分布的未见数据的泛化能力。\n*   **神经网络超参数列表 (133):** 提供了 NAdamW 优化器的预计算超参数列表，可在有限调优预算下快速训练神经网络。\n*   **AI 辅助集体判断 (134):** 探讨旨在整合集体偏好的计算框架的设计选择、潜力与风险。\n*   **推理路径可视化 (135):** 推出 ReasonGraph，一个可视化和分析 LLM 推理过程（顺序或树状）的 Web 平台。\n\n---\n\n希望这份 TLDR 能帮助你快速了解今天的 arXiv 精华！",
  "papers": [
    {
      "arxiv_id": "2503.05050v1",
      "title": "A Unified Framework with Novel Metrics for Evaluating the Effectiveness of XAI Techniques in LLMs",
      "title_zh": "一个包含新指标的统一框架，用于评估LLM中XAI技术的有效性",
      "authors": [
        "Melkamu Abay Mersha",
        "Mesay Gemeda Yigezu",
        "Hassan shakil",
        "Ali Al shami",
        "Sanghyun Byun",
        "Jugal Kalita"
      ],
      "abstract": "The increasing complexity of LLMs presents significant challenges to their\ntransparency and interpretability, necessitating the use of eXplainable AI\n(XAI) techniques to enhance trustworthiness and usability. This study\nintroduces a comprehensive evaluation framework with four novel metrics for\nassessing the effectiveness of five XAI techniques across five LLMs and two\ndownstream tasks. We apply this framework to evaluate several XAI techniques\nLIME, SHAP, Integrated Gradients, Layer-wise Relevance Propagation (LRP), and\nAttention Mechanism Visualization (AMV) using the IMDB Movie Reviews and Tweet\nSentiment Extraction datasets. The evaluation focuses on four key metrics:\nHuman-reasoning Agreement (HA), Robustness, Consistency, and Contrastivity. Our\nresults show that LIME consistently achieves high scores across multiple LLMs\nand evaluation metrics, while AMV demonstrates superior Robustness and\nnear-perfect Consistency. LRP excels in Contrastivity, particularly with more\ncomplex models. Our findings provide valuable insights into the strengths and\nlimitations of different XAI methods, offering guidance for developing and\nselecting appropriate XAI techniques for LLMs.",
      "tldr_zh": "该研究提出了一个统一评估框架，包含四项新颖指标（Human-reasoning Agreement、Robustness、Consistency、Contrastivity），用于系统评估五种XAI技术（LIME、SHAP等）在大型语言模型(LLMs)中的有效性。实验发现：LIME在多种LLM和指标上表现稳定，Attention Mechanism Visualization(AMV)在鲁棒性和一致性方面表现突出，而Layer-wise Relevance Propagation(LRP)在复杂模型上的对比性最优。该框架为LLM可解释性技术的选择和优化提供了实证依据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2501.15374",
      "pdf_url": "http://arxiv.org/pdf/2503.05050v1",
      "published_date": "2025-03-06 23:59:50 UTC",
      "updated_date": "2025-03-06 23:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:23:46.392409"
    },
    {
      "arxiv_id": "2503.05042v1",
      "title": "Provably Correct Automata Embeddings for Optimal Automata-Conditioned Reinforcement Learning",
      "title_zh": "可证明正确的自动机嵌入用于最优自动机条件强化学习",
      "authors": [
        "Beyazit Yalcinkaya",
        "Niklas Lauffer",
        "Marcell Vazquez-Chanlatte",
        "Sanjit A. Seshia"
      ],
      "abstract": "Automata-conditioned reinforcement learning (RL) has given promising results\nfor learning multi-task policies capable of performing temporally extended\nobjectives given at runtime, done by pretraining and freezing automata\nembeddings prior to training the downstream policy. However, no theoretical\nguarantees were given. This work provides a theoretical framework for the\nautomata-conditioned RL problem and shows that it is probably approximately\ncorrect learnable. We then present a technique for learning provably correct\nautomata embeddings, guaranteeing optimal multi-task policy learning. Our\nexperimental evaluation confirms these theoretical results.",
      "tldr_zh": "本文提出了一个理论框架，证明自动机条件强化学习（Automata-conditioned RL）是近似可学习的，并开发了一种学习可证明正确的自动机嵌入（automata embeddings）的技术，确保多任务策略学习的最优性。实验验证了该理论框架和技术的有效性，为运行时执行时间扩展目标的多任务策略学习提供了理论保证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.FL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05042v1",
      "published_date": "2025-03-06 23:37:05 UTC",
      "updated_date": "2025-03-06 23:37:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:23:28.163056"
    },
    {
      "arxiv_id": "2503.05031v1",
      "title": "Enhancing Alzheimer's Diagnosis: Leveraging Anatomical Landmarks in Graph Convolutional Neural Networks on Tetrahedral Meshes",
      "title_zh": "增强阿尔茨海默病诊断：在四面体网格的图卷积神经网络中利用解剖标志",
      "authors": [
        "Yanxi Chen",
        "Mohammad Farazi",
        "Zhangsihao Yang",
        "Yonghui Fan",
        "Nicholas Ashton",
        "Eric M Reiman",
        "Yi Su",
        "Yalin Wang"
      ],
      "abstract": "Alzheimer's disease (AD) is a major neurodegenerative condition that affects\nmillions around the world. As one of the main biomarkers in the AD diagnosis\nprocedure, brain amyloid positivity is typically identified by positron\nemission tomography (PET), which is costly and invasive. Brain structural\nmagnetic resonance imaging (sMRI) may provide a safer and more convenient\nsolution for the AD diagnosis. Recent advances in geometric deep learning have\nfacilitated sMRI analysis and early diagnosis of AD. However, determining AD\npathology, such as brain amyloid deposition, in preclinical stage remains\nchallenging, as less significant morphological changes can be observed. As a\nresult, few AD classification models are generalizable to the brain amyloid\npositivity classification task. Blood-based biomarkers (BBBMs), on the other\nhand, have recently achieved remarkable success in predicting brain amyloid\npositivity and identifying individuals with high risk of being brain amyloid\npositive. However, individuals in medium risk group still require gold standard\ntests such as Amyloid PET for further evaluation. Inspired by the recent\nsuccess of transformer architectures, we propose a geometric deep learning\nmodel based on transformer that is both scalable and robust to variations in\ninput volumetric mesh size. Our work introduced a novel tokenization scheme for\ntetrahedral meshes, incorporating anatomical landmarks generated by a\npre-trained Gaussian process model. Our model achieved superior classification\nperformance in AD classification task. In addition, we showed that the model\nwas also generalizable to the brain amyloid positivity prediction with\nindividuals in the medium risk class, where BM alone cannot achieve a clear\nclassification. Our work may enrich geometric deep learning research and\nimprove AD diagnosis accuracy without using expensive and invasive PET scans.",
      "tldr_zh": "本研究提出了一种基于Transformer的几何深度学习模型，用于增强阿尔茨海默病（AD）的诊断。该模型通过引入预训练的Gaussian process模型生成的解剖标志点，开发了一种新的四面体网格标记化方案，能够处理不同大小的输入体积网格。实验表明，该模型在AD分类任务中表现优异，并且在预测中等风险个体的脑淀粉样蛋白阳性方面也具有良好的泛化能力。该研究为无需昂贵且侵入性PET扫描的AD诊断提供了新的解决方案，丰富了几何深度学习在医学领域的应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "q-bio.NC"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05031v1",
      "published_date": "2025-03-06 23:02:18 UTC",
      "updated_date": "2025-03-06 23:02:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:23:38.908832"
    },
    {
      "arxiv_id": "2503.05029v1",
      "title": "Continual Pre-training of MoEs: How robust is your router?",
      "title_zh": "MoEs的持续预训练：你的路由机制有多稳健？",
      "authors": [
        "Benjamin Thérien",
        "Charles-Étienne Joseph",
        "Zain Sarwar",
        "Ashwinee Panda",
        "Anirban Das",
        "Shi-Xiong Zhang",
        "Stephen Rawls",
        "Sambit Sahu",
        "Eugene Belilovsky",
        "Irina Rish"
      ],
      "abstract": "Sparsely-activated Mixture of Experts (MoE) transformers are promising\narchitectures for foundation models. Compared to dense transformers that\nrequire the same amount of floating point operations (FLOPs) per forward pass,\nMoEs benefit from improved sample efficiency at training time and achieve much\nstronger performance. Many closed-source and open-source frontier language\nmodels have thus adopted an MoE architecture. Naturally, practitioners will\nwant to extend the capabilities of these models with large amounts of newly\ncollected data without completely re-training them. Prior work has shown that a\nsimple combination of replay and learning rate re-warming and re-decaying can\nenable the continual pre-training (CPT) of dense decoder-only transformers with\nminimal performance degradation compared to full re-training. In the case of\ndecoder-only MoE transformers, however, it is unclear how the routing algorithm\nwill impact continual pre-training performance: 1) do the MoE transformer's\nrouters exacerbate forgetting relative to a dense model?; 2) do the routers\nmaintain a balanced load on previous distributions after CPT?; 3) are the same\nstrategies applied to dense models sufficient to continually pre-train MoE\nLLMs? In what follows, we conduct a large-scale (>2B parameter switch and\nDeepSeek MoE LLMs trained for 600B tokens) empirical study across four MoE\ntransformers to answer these questions. Our results establish a surprising\nrobustness to distribution shifts for both Sinkhorn-Balanced and\nZ-and-Aux-loss-balanced routing algorithms, even in MoEs continually\npre-trained without replay. Moreover, we show that MoE LLMs maintain their\nsample efficiency (relative to a FLOP-matched dense model) during CPT and that\nthey can match the performance of a fully re-trained MoE at a fraction of the\ncost.",
      "tldr_zh": "该研究探讨了稀疏激活的专家混合模型（MoE）在持续预训练（CPT）中的路由算法鲁棒性。通过大规模实验（>20亿参数的MoE模型，训练600B tokens），研究发现Sinkhorn平衡和Z-and-Aux-loss平衡的路由算法在分布偏移下表现出惊人的鲁棒性，即使在没有回放的情况下也能有效进行CPT。此外，MoE模型在CPT期间保持了样本效率，并且能以较低成本达到完全重新训练的性能水平。这表明MoE模型在扩展能力时具有显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05029v1",
      "published_date": "2025-03-06 22:55:01 UTC",
      "updated_date": "2025-03-06 22:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:23:46.253445"
    },
    {
      "arxiv_id": "2503.05012v1",
      "title": "LLMs' Reshaping of People, Processes, Products, and Society in Software Development: A Comprehensive Exploration with Early Adopters",
      "title_zh": "LLMs 对软件开发中人员、流程、产品及社会的重塑：基于早期采用者的全面探索",
      "authors": [
        "Benyamin Tabarsi",
        "Heidi Reichert",
        "Ally Limke",
        "Sandeep Kuttal",
        "Tiffany Barnes"
      ],
      "abstract": "Large language models (LLMs) like OpenAI ChatGPT, Google Gemini, and GitHub\nCopilot are rapidly gaining traction in the software industry, but their full\nimpact on software engineering remains insufficiently explored. Despite their\ngrowing adoption, there is a notable lack of formal, qualitative assessments of\nhow LLMs are applied in real-world software development contexts. To fill this\ngap, we conducted semi-structured interviews with sixteen early-adopter\nprofessional developers to explore their use of LLMs throughout various stages\nof the software development life cycle. Our investigation examines four\ndimensions: people - how LLMs affect individual developers and teams; process -\nhow LLMs alter software engineering workflows; product - LLM impact on software\nquality and innovation; and society - the broader socioeconomic and ethical\nimplications of LLM adoption. Thematic analysis of our data reveals that while\nLLMs have not fundamentally revolutionized the development process, they have\nsubstantially enhanced routine coding tasks, including code generation,\nrefactoring, and debugging. Developers reported the most effective outcomes\nwhen providing LLMs with clear, well-defined problem statements, indicating\nthat LLMs excel with decomposed problems and specific requirements.\nFurthermore, these early-adopters identified that LLMs offer significant value\nfor personal and professional development, aiding in learning new languages and\nconcepts. Early-adopters, highly skilled in software engineering and how LLMs\nwork, identified early and persisting challenges for software engineering, such\nas inaccuracies in generated content and the need for careful manual review\nbefore integrating LLM outputs into production environments. Our study provides\na nuanced understanding of how LLMs are shaping the landscape of software\ndevelopment, with their benefits, limitations, and ongoing implications.",
      "tldr_zh": "这项研究通过访谈16位早期采用LLM（如ChatGPT、GitHub Copilot）的专业开发者，探讨了LLM对软件开发的多维影响。研究发现，LLM虽未彻底改变开发流程，但显著提升了代码生成、重构和调试等常规任务的效率，尤其适用于分解清晰的问题。开发者指出LLM对个人学习新技术和概念具有重要价值，但也面临生成内容不准确、需人工审核等挑战。研究从人员（个人与团队）、流程（工作流）、产品（质量与创新）和社会（伦理与经济）四个维度揭示了LLM对软件行业的渐进式重塑，强调了其在提升效率与持续改进需求之间的平衡。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05012v1",
      "published_date": "2025-03-06 22:27:05 UTC",
      "updated_date": "2025-03-06 22:27:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:23:59.138363"
    },
    {
      "arxiv_id": "2503.05005v2",
      "title": "Balcony: A Lightweight Approach to Dynamic Inference of Generative Language Models",
      "title_zh": "Balcony：生成式语言模型动态推理的轻量级方法",
      "authors": [
        "Benyamin Jamialahmadi",
        "Parsa Kavehzadeh",
        "Mehdi Rezagholizadeh",
        "Parsa Farinneya",
        "Hossein Rajabzadeh",
        "Aref Jafari",
        "Boxing Chen",
        "Marzieh S. Tahaei"
      ],
      "abstract": "Deploying large language models (LLMs) in real-world applications is often\nhindered by strict computational and latency constraints. While dynamic\ninference offers the flexibility to adjust model behavior based on varying\nresource budgets, existing methods are frequently limited by hardware\ninefficiencies or performance degradation. In this paper, we introduce Balcony,\na simple yet highly effective framework for depth-based dynamic inference. By\nfreezing the pretrained LLM and inserting additional transformer layers at\nselected exit points, Balcony maintains the full model's performance while\nenabling real-time adaptation to different computational budgets. These\nadditional layers are trained using a straightforward self-distillation loss,\naligning the sub-model outputs with those of the full model. This approach\nrequires significantly fewer training tokens and tunable parameters,\ndrastically reducing computational costs compared to prior methods. When\napplied to the LLaMA3-8B model, using only 0.2% of the original pretraining\ndata, Balcony achieves minimal performance degradation while enabling\nsignificant speedups. Remarkably, we show that Balcony outperforms\nstate-of-the-art methods such as Flextron and Layerskip as well as other\nleading compression techniques on multiple models and at various scales, across\na variety of benchmarks.",
      "tldr_zh": "该研究提出了Balcony，一种轻量级的动态推理框架，旨在优化大语言模型(LLMs)的实时部署效率。通过冻结预训练模型并在特定退出点插入额外的Transformer层，Balcony实现了在不同计算预算下的灵活调整，同时保持了完整模型的性能。该方法采用自蒸馏损失进行训练，显著减少了训练数据和可调参数的需求。实验表明，Balcony在LLaMA3-8B等模型上表现优异，仅使用0.2%的预训练数据即可实现显著的加速，并在多种基准测试中超越了Flextron和Layerskip等现有方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05005v2",
      "published_date": "2025-03-06 22:09:55 UTC",
      "updated_date": "2025-03-10 18:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:24:00.198130"
    },
    {
      "arxiv_id": "2503.04992v1",
      "title": "Wanda++: Pruning Large Language Models via Regional Gradients",
      "title_zh": "Wanda++：基于区域梯度的大语言模型剪枝方法",
      "authors": [
        "Yifan Yang",
        "Kai Zhen",
        "Bhavana Ganesh",
        "Aram Galstyan",
        "Goeric Huybrechts",
        "Markus Müller",
        "Jonas M. Kübler",
        "Rupak Vignesh Swaminathan",
        "Athanasios Mouchtaris",
        "Sravan Babu Bodapati",
        "Nathan Susanj",
        "Zheng Zhang",
        "Jack FitzGerald",
        "Abhishek Kumar"
      ],
      "abstract": "Large Language Models (LLMs) pruning seeks to remove unimportant weights for\ninference speedup with minimal performance impact. However, existing methods\noften suffer from performance loss without full-model sparsity-aware\nfine-tuning. This paper presents Wanda++, a novel pruning framework that\noutperforms the state-of-the-art methods by utilizing decoder-block-level\n\\textbf{regional} gradients. Specifically, Wanda++ improves the pruning score\nwith regional gradients for the first time and proposes an efficient regional\noptimization method to minimize pruning-induced output discrepancies between\nthe dense and sparse decoder output. Notably, Wanda++ improves perplexity by up\nto 32\\% over Wanda in the language modeling task and generalizes effectively to\ndownstream tasks. Further experiments indicate our proposed method is\northogonal to sparsity-aware fine-tuning, where Wanda++ can be combined with\nLoRA fine-tuning to achieve a similar perplexity improvement as the Wanda\nmethod. The proposed method is lightweight, pruning a 7B LLaMA model in under\n10 minutes on a single NVIDIA H100 GPU.",
      "tldr_zh": "本文提出Wanda++，一种基于区域梯度(regional gradients)的大语言模型(LLMs)剪枝新方法。该方法首次利用解码器块级区域梯度改进剪枝评分，并通过高效的区域优化技术最小化剪枝导致的输出差异。实验表明，Wanda++在语言建模任务中比现有最佳方法Wanda降低32%的困惑度(perplexity)，且能高效兼容LoRA微调等稀疏感知训练技术，仅需单块H100 GPU在10分钟内完成7B参数LLaMA模型的剪枝。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04992v1",
      "published_date": "2025-03-06 21:42:35 UTC",
      "updated_date": "2025-03-06 21:42:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:24:30.054580"
    },
    {
      "arxiv_id": "2503.04982v1",
      "title": "LVLM-Compress-Bench: Benchmarking the Broader Impact of Large Vision-Language Model Compression",
      "title_zh": "LVLM-Compress-Bench：大型视觉语言模型压缩广泛影响的基准测试",
      "authors": [
        "Souvik Kundu",
        "Anahita Bhiwandiwalla",
        "Sungduk Yu",
        "Phillip Howard",
        "Tiep Le",
        "Sharath Nittur Sridhar",
        "David Cobbley",
        "Hao Kang",
        "Vasudev Lal"
      ],
      "abstract": "Despite recent efforts in understanding the compression impact on large\nlanguage models (LLMs) in terms of their downstream task performance and\ntrustworthiness on relatively simpler uni-modal benchmarks (for example,\nquestion answering, common sense reasoning), their detailed study on\nmulti-modal Large Vision-Language Models (LVLMs) is yet to be unveiled. Towards\nmitigating this gap, we present LVLM-Compress-Bench, a framework to first\nthoroughly study the broad impact of compression on the generative performance\nof LVLMs with multi-modal input driven tasks. In specific, we consider two\nmajor classes of compression for autoregressive models, namely KV cache and\nweight compression, for the dynamically growing intermediate cache and static\nweights, respectively.\n  We use four LVLM variants of the popular LLaVA framework to present our\nanalysis via integrating various state-of-the-art KV and weight compression\nmethods including uniform, outlier-reduced, and group quantization for the KV\ncache and weights. With this framework we demonstrate on ten different\nmulti-modal datasets with different capabilities including recognition,\nknowledge, language generation, spatial awareness, visual reasoning,\nhallucination and visual illusion identification, toxicity, stereotypes and\nbias. In specific, our framework demonstrates the compression impact on both\ngeneral and ethically critical metrics leveraging a combination of real world\nand synthetic datasets to encompass diverse societal intersectional attributes.\nExtensive experimental evaluations yield diverse and intriguing observations on\nthe behavior of LVLMs at different quantization budget of KV and weights, in\nboth maintaining and losing performance as compared to the baseline model with\nFP16 data format.\n  Code will be open-sourced at\nhttps://github.com/opengear-project/LVLM-compress-bench.",
      "tldr_zh": "该研究提出了LVLM-Compress-Bench，一个用于全面评估大型视觉语言模型(LVLMs)压缩对其多模态生成性能广泛影响的框架。研究重点分析了两种压缩方法：KV缓存压缩和权重压缩，并基于LLaVA框架的四种LVLM变体，结合最新的量化技术进行实验。通过在十个多模态数据集上的评估，研究揭示了压缩对模型在识别、语言生成、视觉推理等能力上的影响，以及对伦理指标（如偏见和毒性）的作用。实验结果表明，不同量化预算下，模型性能表现出多样且有趣的变化，为LVLMs的压缩优化提供了重要见解。代码将开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04982v1",
      "published_date": "2025-03-06 21:21:18 UTC",
      "updated_date": "2025-03-06 21:21:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:24:22.688974"
    },
    {
      "arxiv_id": "2503.04980v1",
      "title": "A Consensus Privacy Metrics Framework for Synthetic Data",
      "title_zh": "合成数据共识隐私度量框架",
      "authors": [
        "Lisa Pilgram",
        "Fida K. Dankar",
        "Jorg Drechsler",
        "Mark Elliot",
        "Josep Domingo-Ferrer",
        "Paul Francis",
        "Murat Kantarcioglu",
        "Linglong Kong",
        "Bradley Malin",
        "Krishnamurty Muralidhar",
        "Puja Myles",
        "Fabian Prasser",
        "Jean Louis Raisaro",
        "Chao Yan",
        "Khaled El Emam"
      ],
      "abstract": "Synthetic data generation is one approach for sharing individual-level data.\nHowever, to meet legislative requirements, it is necessary to demonstrate that\nthe individuals' privacy is adequately protected. There is no consolidated\nstandard for measuring privacy in synthetic data. Through an expert panel and\nconsensus process, we developed a framework for evaluating privacy in synthetic\ndata. Our findings indicate that current similarity metrics fail to measure\nidentity disclosure, and their use is discouraged. For differentially private\nsynthetic data, a privacy budget other than close to zero was not considered\ninterpretable. There was consensus on the importance of membership and\nattribute disclosure, both of which involve inferring personal information\nabout an individual without necessarily revealing their identity. The resultant\nframework provides precise recommendations for metrics that address these types\nof disclosures effectively. Our findings further present specific opportunities\nfor future research that can help with widespread adoption of synthetic data.",
      "tldr_zh": "本文提出了一个针对合成数据的共识性隐私评估框架，旨在解决当前缺乏统一隐私衡量标准的问题。研究发现现有相似性指标无法有效评估身份泄露风险，且差分隐私合成数据的隐私预算需接近零才具有可解释性。专家共识强调了成员推断和属性泄露两类风险的重要性，该框架为此提供了具体的评估指标建议，并为合成数据的广泛应用指明了未来研究方向。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04980v1",
      "published_date": "2025-03-06 21:19:02 UTC",
      "updated_date": "2025-03-06 21:19:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:24:30.246549"
    },
    {
      "arxiv_id": "2503.04977v1",
      "title": "Quantifying the Relevance of Youth Research Cited in the US Policy Documents",
      "title_zh": "量化美国政策文件中引用的青年研究相关性",
      "authors": [
        "Miftahul Jannat Mokarrama",
        "Hamed Alhoori"
      ],
      "abstract": "In recent years, there has been a growing concern and emphasis on conducting\nresearch beyond academic or scientific research communities, benefiting society\nat large. A well-known approach to measuring the impact of research on society\nis enumerating its policy citation(s). Despite the importance of research in\ninforming policy, there is no concrete evidence to suggest the research's\nrelevance in cited policy documents. This is concerning because it may increase\nthe possibility of evidence used in policy being manipulated by individual,\nsocial, or political biases that may lead to inappropriate, fragmented, or\narchaic research evidence in policy. Therefore, it is crucial to identify the\ndegree of relevance between research articles and citing policy documents. In\nthis paper, we examined the scale of contextual relevance of youth-focused\nresearch in the referenced US policy documents using natural language\nprocessing techniques, state-of-the-art pre-trained Large Language Models\n(LLMs), and statistical analysis. Our experiments and analysis concluded that\nyouth-related research articles that get US policy citations are mostly\nrelevant to the citing policy documents.",
      "tldr_zh": "该研究通过自然语言处理技术、预训练大语言模型(LLMs)和统计分析，量化了美国政策文件中引用的青年相关研究文献的上下文相关性。结果表明，被美国政策文件引用的青年研究文献大多与引用政策文件相关，为评估研究对政策制定的实际影响提供了实证依据。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "The paper was accepted and presented in IEEE BIG DATA 2024. It has 10\n  pages, 5 figures, and 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04977v1",
      "published_date": "2025-03-06 21:14:04 UTC",
      "updated_date": "2025-03-06 21:14:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:24:31.574263"
    },
    {
      "arxiv_id": "2503.04973v1",
      "title": "Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge Reasoning",
      "title_zh": "超越RAG：面向全面知识推理的任务感知型KV缓存压缩",
      "authors": [
        "Giulio Corallo",
        "Orion Weller",
        "Fabio Petroni",
        "Paolo Papotti"
      ],
      "abstract": "Incorporating external knowledge in large language models (LLMs) enhances\ntheir utility across diverse applications, but existing methods have\ntrade-offs. Retrieval-Augmented Generation (RAG) fetches evidence via\nsimilarity search, but key information may fall outside top ranked results.\nLong-context models can process multiple documents but are computationally\nexpensive and limited by context window size. Inspired by students condensing\nstudy material for open-book exams, we propose task-aware key-value (KV) cache\ncompression, which compresses external knowledge in a zero- or few-shot setup.\nThis enables LLMs to reason efficiently over a compacted representation of all\nrelevant information. Experiments show our approach outperforms both RAG and\ntask-agnostic compression methods. On LongBench v2, it improves accuracy by up\nto 7 absolute points over RAG with a 30x compression rate, while reducing\ninference latency from 0.43s to 0.16s. A synthetic dataset highlights that RAG\nperforms well when sparse evidence suffices, whereas task-aware compression is\nsuperior for broad knowledge tasks.",
      "tldr_zh": "该研究提出了一种任务感知的键值缓存压缩(task-aware KV cache compression)方法，以解决大语言模型(LLMs)结合外部知识时面临的效率与准确性权衡问题。与检索增强生成(RAG)和长上下文模型相比，该方法在零样本或少样本设置下压缩外部知识，使LLMs能够高效推理所有相关信息。实验表明，该方法在LongBench v2上的准确率比RAG提高最多7个百分点，压缩率达30倍，推理延迟从0.43秒降至0.16秒。尤其在需要广泛知识的任务中，任务感知压缩优于RAG。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04973v1",
      "published_date": "2025-03-06 21:07:41 UTC",
      "updated_date": "2025-03-06 21:07:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:24:45.885534"
    },
    {
      "arxiv_id": "2503.04971v1",
      "title": "Incentivizing Multi-Tenant Split Federated Learning for Foundation Models at the Network Edge",
      "title_zh": "激励网络边缘基础模型的多租户分割联邦学习",
      "authors": [
        "Songyuan Li",
        "Jia Hu",
        "Geyong Min",
        "Haojun Huang"
      ],
      "abstract": "Foundation models (FMs) such as GPT-4 exhibit exceptional generative\ncapabilities across diverse downstream tasks through fine-tuning. Split\nFederated Learning (SFL) facilitates privacy-preserving FM fine-tuning on\nresource-constrained local devices by offloading partial FM computations to\nedge servers, enabling device-edge synergistic fine-tuning. Practical edge\nnetworks often host multiple SFL tenants to support diversified downstream\ntasks. However, existing research primarily focuses on single-tenant SFL\nscenarios, and lacks tailored incentive mechanisms for multi-tenant settings,\nwhich are essential to effectively coordinate self-interested local devices for\nparticipation in various downstream tasks, ensuring that each SFL tenant's\ndistinct FM fine-tuning requirements (e.g., FM types, performance targets, and\nfine-tuning deadlines) are met. To address this gap, we propose a novel\nPrice-Incentive Mechanism (PRINCE) that guides multiple SFL tenants to offer\nstrategic price incentives, which solicit high-quality device participation for\nefficient FM fine-tuning. Specifically, we first develop a bias-resilient\nglobal SFL model aggregation scheme to eliminate model biases caused by\nindependent device participation. We then derive a rigorous SFL convergence\nbound to evaluate the contributions of heterogeneous devices to FM performance\nimprovements, guiding the incentive strategies of SFL tenants. Furthermore, we\nmodel inter-tenant device competition as a congestion game for Stackelberg\nequilibrium (SE) analysis, deriving each SFL tenant's optimal incentive\nstrategy. Extensive simulations involving four representative SFL tenant types\n(ViT, BERT, Whisper, and LLaMA) across diverse data modalities (text, images,\nand audio) demonstrate that PRINCE accelerates FM fine-tuning by up to 3.07x\ncompared to state-of-the-art approaches, while consistently meeting fine-tuning\nperformance targets.",
      "tldr_zh": "该研究提出了一种面向多租户 Split Federated Learning (SFL) 的激励机制 PRINCE，旨在优化边缘网络中基础模型 (FMs) 的微调效率。通过设计偏差弹性的全局模型聚合方案和严格的 SFL 收敛边界，PRINCE 能够评估异构设备对 FM 性能提升的贡献，并基于 Stackelberg 均衡分析推导出最优激励策略。实验表明，PRINCE 在多种数据模态（文本、图像、音频）和 FM 类型（如 ViT、BERT 等）下，将 FM 微调速度提升至多 3.07 倍，同时满足性能目标。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Index Terms: Foundation models, Edge computing, Split federated\n  learning, Multi-tenant system, Incentive mechanism",
      "pdf_url": "http://arxiv.org/pdf/2503.04971v1",
      "published_date": "2025-03-06 21:06:27 UTC",
      "updated_date": "2025-03-06 21:06:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:24:59.153724"
    },
    {
      "arxiv_id": "2503.04969v1",
      "title": "Data-Efficient Learning from Human Interventions for Mobile Robots",
      "title_zh": "面向移动机器人的人类干预数据高效学习方法",
      "authors": [
        "Zhenghao Peng",
        "Zhizheng Liu",
        "Bolei Zhou"
      ],
      "abstract": "Mobile robots are essential in applications such as autonomous delivery and\nhospitality services. Applying learning-based methods to address mobile robot\ntasks has gained popularity due to its robustness and generalizability.\nTraditional methods such as Imitation Learning (IL) and Reinforcement Learning\n(RL) offer adaptability but require large datasets, carefully crafted reward\nfunctions, and face sim-to-real gaps, making them challenging for efficient and\nsafe real-world deployment. We propose an online human-in-the-loop learning\nmethod PVP4Real that combines IL and RL to address these issues. PVP4Real\nenables efficient real-time policy learning from online human intervention and\ndemonstration, without reward or any pretraining, significantly improving data\nefficiency and training safety. We validate our method by training two\ndifferent robots -- a legged quadruped, and a wheeled delivery robot -- in two\nmobile robot tasks, one of which even uses raw RGBD image as observation. The\ntraining finishes within 15 minutes. Our experiments show the promising future\nof human-in-the-loop learning in addressing the data efficiency issue in\nreal-world robotic tasks. More information is available at:\nhttps://metadriverse.github.io/pvp4real/",
      "tldr_zh": "该研究提出了一种名为PVP4Real的在线人机交互学习方法，结合模仿学习(IL)和强化学习(RL)，以解决移动机器人任务中的数据效率问题。该方法通过实时人类干预和示范进行策略学习，无需奖励函数或预训练，显著提高了数据效率和训练安全性。实验验证了该方法在腿式四足机器人和轮式配送机器人上的有效性，训练时间仅需15分钟，展示了人机交互学习在现实世界机器人任务中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "ICRA 2025. Webpage: https://metadriverse.github.io/pvp4real/",
      "pdf_url": "http://arxiv.org/pdf/2503.04969v1",
      "published_date": "2025-03-06 21:02:02 UTC",
      "updated_date": "2025-03-06 21:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:25:02.773811"
    },
    {
      "arxiv_id": "2503.04966v2",
      "title": "Prediction of Frozen Region Growth in Kidney Cryoablation Intervention Using a 3D Flow-Matching Model",
      "title_zh": "基于3D流匹配模型的肾脏冷冻消融术中冰冻区域生长预测",
      "authors": [
        "Siyeop Yoon",
        "Yujin Oh",
        "Matthew Tivnan",
        "Sifan Song",
        "Pengfei Jin",
        "Sekeun Kim",
        "Hyun Jin Cho",
        "Dufan Wu",
        "Raul Uppot",
        "Quanzheng Li"
      ],
      "abstract": "This study presents a 3D flow-matching model designed to predict the\nprogression of the frozen region (iceball) during kidney cryoablation. Precise\nintraoperative guidance is critical in cryoablation to ensure complete tumor\neradication while preserving adjacent healthy tissue. However, conventional\nmethods, typically based on physics driven or diffusion based simulations, are\ncomputationally demanding and often struggle to represent complex anatomical\nstructures accurately. To address these limitations, our approach leverages\nintraoperative CT imaging to inform the model. The proposed 3D flow matching\nmodel is trained to learn a continuous deformation field that maps early-stage\nCT scans to future predictions. This transformation not only estimates the\nvolumetric expansion of the iceball but also generates corresponding\nsegmentation masks, effectively capturing spatial and morphological changes\nover time. Quantitative analysis highlights the model robustness, demonstrating\nstrong agreement between predictions and ground-truth segmentations. The model\nachieves an Intersection over Union (IoU) score of 0.61 and a Dice coefficient\nof 0.75. By integrating real time CT imaging with advanced deep learning\ntechniques, this approach has the potential to enhance intraoperative guidance\nin kidney cryoablation, improving procedural outcomes and advancing the field\nof minimally invasive surgery.",
      "tldr_zh": "该研究提出了一种基于3D流匹配(flow-matching)的模型，用于预测肾脏冷冻消融手术中冷冻区域（冰球）的生长过程。传统方法依赖物理驱动或扩散模拟，计算复杂且难以准确反映解剖结构，而该模型利用术中CT影像，通过训练连续变形场，将早期CT扫描映射到未来预测，同时生成分割掩码，捕捉冰球的空间和形态变化。实验表明，模型预测与真实分割结果高度一致，IoU得分为0.61，Dice系数为0.75。该方法结合实时CT影像与深度学习技术，有望提升术中导航精度，改善手术效果，推动微创手术领域发展。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "MICCAI 2025 submitted version (author list included)",
      "pdf_url": "http://arxiv.org/pdf/2503.04966v2",
      "published_date": "2025-03-06 20:52:58 UTC",
      "updated_date": "2025-03-11 15:21:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:25:18.318275"
    },
    {
      "arxiv_id": "2503.04963v1",
      "title": "Energy-Latency Attacks: A New Adversarial Threat to Deep Learning",
      "title_zh": "能量-延迟攻击：深度学习面临的新型对抗性威胁",
      "authors": [
        "Hanene F. Z. Brachemi Meftah",
        "Wassim Hamidouche",
        "Sid Ahmed Fezza",
        "Olivier Deforges"
      ],
      "abstract": "The growing computational demand for deep neural networks ( DNNs) has raised\nconcerns about their energy consumption and carbon footprint, particularly as\nthe size and complexity of the models continue to increase. To address these\nchallenges, energy-efficient hardware and custom accelerators have become\nessential. Additionally, adaptable DNN s are being developed to dynamically\nbalance performance and efficiency. The use of these strategies became more\ncommon to enable sustainable AI deployment. However, these efficiency-focused\ndesigns may also introduce vulnerabilities, as attackers can potentially\nexploit them to increase latency and energy usage by triggering their\nworst-case-performance scenarios. This new type of attack, called\nenergy-latency attacks, has recently gained significant research attention,\nfocusing on the vulnerability of DNN s to this emerging attack paradigm, which\ncan trigger denial-of-service ( DoS) attacks. This paper provides a\ncomprehensive overview of current research on energy-latency attacks,\ncategorizing them using the established taxonomy for traditional adversarial\nattacks. We explore different metrics used to measure the success of these\nattacks and provide an analysis and comparison of existing attack strategies.\nWe also analyze existing defense mechanisms and highlight current challenges\nand potential areas for future research in this developing field. The GitHub\npage for this work can be accessed at\nhttps://github.com/hbrachemi/Survey_energy_attacks/",
      "tldr_zh": "该论文提出了一种新型对抗威胁——**能量-时延攻击（Energy-Latency Attacks）**，专门针对深度学习模型的能效优化机制。研究发现，攻击者可通过触发DNN的最坏性能场景，恶意增加计算延迟和能耗，甚至导致**拒绝服务（DoS）**。  \n\n作者系统梳理了现有攻击方法，采用传统对抗攻击分类体系进行归类，并对比分析了不同攻击策略的效果评估指标。同时探讨了当前防御机制的局限性，为这一新兴领域的未来研究指明方向。相关资源已在GitHub开源。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04963v1",
      "published_date": "2025-03-06 20:50:58 UTC",
      "updated_date": "2025-03-06 20:50:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:25:35.901465"
    },
    {
      "arxiv_id": "2503.04957v1",
      "title": "SafeArena: Evaluating the Safety of Autonomous Web Agents",
      "title_zh": "SafeArena：评估自主网络智能体的安全性",
      "authors": [
        "Ada Defne Tur",
        "Nicholas Meade",
        "Xing Han Lù",
        "Alejandra Zambrano",
        "Arkil Patel",
        "Esin Durmus",
        "Spandana Gella",
        "Karolina Stańczak",
        "Siva Reddy"
      ],
      "abstract": "LLM-based agents are becoming increasingly proficient at solving web-based\ntasks. With this capability comes a greater risk of misuse for malicious\npurposes, such as posting misinformation in an online forum or selling illicit\nsubstances on a website. To evaluate these risks, we propose SafeArena, the\nfirst benchmark to focus on the deliberate misuse of web agents. SafeArena\ncomprises 250 safe and 250 harmful tasks across four websites. We classify the\nharmful tasks into five harm categories -- misinformation, illegal activity,\nharassment, cybercrime, and social bias, designed to assess realistic misuses\nof web agents. We evaluate leading LLM-based web agents, including GPT-4o,\nClaude-3.5 Sonnet, Qwen-2-VL 72B, and Llama-3.2 90B, on our benchmark. To\nsystematically assess their susceptibility to harmful tasks, we introduce the\nAgent Risk Assessment framework that categorizes agent behavior across four\nrisk levels. We find agents are surprisingly compliant with malicious requests,\nwith GPT-4o and Qwen-2 completing 34.7% and 27.3% of harmful requests,\nrespectively. Our findings highlight the urgent need for safety alignment\nprocedures for web agents. Our benchmark is available here:\nhttps://safearena.github.io",
      "tldr_zh": "该研究提出了首个评估自主网页代理安全性的基准测试SafeArena，包含250个安全任务和250个有害任务，涵盖虚假信息、非法活动、骚扰、网络犯罪和社会偏见五大危害类别。通过新提出的Agent Risk Assessment框架对GPT-4o、Claude-3.5等主流LLM代理进行测试，发现这些代理对恶意请求的顺从度惊人（GPT-4o完成率达34.7%），凸显了网页代理安全对齐机制的迫切需求。该基准为评估和改善自主代理的安全性提供了重要工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04957v1",
      "published_date": "2025-03-06 20:43:14 UTC",
      "updated_date": "2025-03-06 20:43:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:25:27.835858"
    },
    {
      "arxiv_id": "2503.04952v1",
      "title": "INTENT: Trajectory Prediction Framework with Intention-Guided Contrastive Clustering",
      "title_zh": "INTENT：基于意图引导对比聚类的轨迹预测框架",
      "authors": [
        "Yihong Tang",
        "Wei Ma"
      ],
      "abstract": "Accurate trajectory prediction of road agents (e.g., pedestrians, vehicles)\nis an essential prerequisite for various intelligent systems applications, such\nas autonomous driving and robotic navigation. Recent research highlights the\nimportance of environmental contexts (e.g., maps) and the \"multi-modality\" of\ntrajectories, leading to increasingly complex model structures. However,\nreal-world deployments require lightweight models that can quickly migrate and\nadapt to new environments. Additionally, the core motivations of road agents,\nreferred to as their intentions, deserves further exploration. In this study,\nwe advocate that understanding and reasoning road agents' intention plays a key\nrole in trajectory prediction tasks, and the main challenge is that the concept\nof intention is fuzzy and abstract. To this end, we present INTENT, an\nefficient intention-guided trajectory prediction model that relies solely on\ninformation contained in the road agent's trajectory. Our model distinguishes\nitself from existing models in several key aspects: (i) We explicitly model\nroad agents' intentions through contrastive clustering, accommodating the\nfuzziness and abstraction of human intention in their trajectories. (ii) The\nproposed INTENT is based solely on multi-layer perceptrons (MLPs), resulting in\nreduced training and inference time, making it very efficient and more suitable\nfor real-world deployment. (iii) By leveraging estimated intentions and an\ninnovative algorithm for transforming trajectory observations, we obtain more\nrobust trajectory representations that lead to superior prediction accuracy.\nExtensive experiments on real-world trajectory datasets for pedestrians and\nautonomous vehicles demonstrate the effectiveness and efficiency of INTENT.",
      "tldr_zh": "该研究提出INTENT框架，一种基于意图引导对比聚类的轻量化轨迹预测方法。该框架创新性地通过多层感知机(MLP)和对比聚类技术建模道路使用者（行人、车辆等）的模糊意图，仅依赖轨迹数据即可实现高效预测。相比复杂模型，INTENT在保持预测精度的同时显著降低计算成本，更适合实际部署。实验证明，该方法在真实行人及自动驾驶数据集上展现出优越的预测性能和效率。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04952v1",
      "published_date": "2025-03-06 20:31:11 UTC",
      "updated_date": "2025-03-06 20:31:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:25:36.122134"
    },
    {
      "arxiv_id": "2503.04946v1",
      "title": "Federated Inverse Probability Treatment Weighting for Individual Treatment Effect Estimation",
      "title_zh": "联邦逆概率加权法用于个体治疗效果估计",
      "authors": [
        "Changchang Yin",
        "Hong-You Chen",
        "Wei-Lun Chao",
        "Ping Zhang"
      ],
      "abstract": "Individual treatment effect (ITE) estimation is to evaluate the causal\neffects of treatment strategies on some important outcomes, which is a crucial\nproblem in healthcare. Most existing ITE estimation methods are designed for\ncentralized settings. However, in real-world clinical scenarios, the raw data\nare usually not shareable among hospitals due to the potential privacy and\nsecurity risks, which makes the methods not applicable. In this work, we study\nthe ITE estimation task in a federated setting, which allows us to harness the\ndecentralized data from multiple hospitals. Due to the unavoidable confounding\nbias in the collected data, a model directly learned from it would be\ninaccurate. One well-known solution is Inverse Probability Treatment Weighting\n(IPTW), which uses the conditional probability of treatment given the\ncovariates to re-weight each training example. Applying IPTW in a federated\nsetting, however, is non-trivial. We found that even with a well-estimated\nconditional probability, the local model training step using each hospital's\ndata alone would still suffer from confounding bias. To address this, we\npropose FED-IPTW, a novel algorithm to extend IPTW into a federated setting\nthat enforces both global (over all the data) and local (within each hospital)\ndecorrelation between covariates and treatments. We validated our approach on\nthe task of comparing the treatment effects of mechanical ventilation on\nimproving survival probability for patients with breadth difficulties in the\nintensive care unit (ICU). We conducted experiments on both synthetic and\nreal-world eICU datasets and the results show that FED-IPTW outperform\nstate-of-the-art methods on all the metrics on factual prediction and ITE\nestimation tasks, paving the way for personalized treatment strategy design in\nmechanical ventilation usage.",
      "tldr_zh": "该研究提出联邦逆概率加权(FED-IPTW)方法，用于解决跨医院数据隐私保护下的个体治疗效果(ITE)估计问题。针对分散医疗数据中存在的混杂偏差，该方法通过全局和局部双重去相关策略，有效消除协变量与治疗间的关联性。在ICU机械通气治疗效果评估的实验中，FED-IPTW在事实预测和ITE估计任务上均优于现有方法，为个性化治疗策略设计提供了新思路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "K.3.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04946v1",
      "published_date": "2025-03-06 20:24:34 UTC",
      "updated_date": "2025-03-06 20:24:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:25:45.522913"
    },
    {
      "arxiv_id": "2503.04945v1",
      "title": "Collaborative Evaluation of Deepfake Text with Deliberation-Enhancing Dialogue Systems",
      "title_zh": "基于审议增强对话系统的深度伪造文本协作评估",
      "authors": [
        "Jooyoung Lee",
        "Xiaochen Zhu",
        "Georgi Karadzhov",
        "Tom Stafford",
        "Andreas Vlachos",
        "Dongwon Lee"
      ],
      "abstract": "The proliferation of generative models has presented significant challenges\nin distinguishing authentic human-authored content from deepfake content.\nCollaborative human efforts, augmented by AI tools, present a promising\nsolution. In this study, we explore the potential of DeepFakeDeLiBot, a\ndeliberation-enhancing chatbot, to support groups in detecting deepfake text.\nOur findings reveal that group-based problem-solving significantly improves the\naccuracy of identifying machine-generated paragraphs compared to individual\nefforts. While engagement with DeepFakeDeLiBot does not yield substantial\nperformance gains overall, it enhances group dynamics by fostering greater\nparticipant engagement, consensus building, and the frequency and diversity of\nreasoning-based utterances. Additionally, participants with higher perceived\neffectiveness of group collaboration exhibited performance benefits from\nDeepFakeDeLiBot. These findings underscore the potential of deliberative\nchatbots in fostering interactive and productive group dynamics while ensuring\naccuracy in collaborative deepfake text detection. \\textit{Dataset and source\ncode used in this study will be made publicly available upon acceptance of the\nmanuscript.",
      "tldr_zh": "该研究提出了DeepFakeDeLiBot，一种增强审议能力的对话系统，用于支持协作检测深度伪造文本。实验发现，小组协作方式相比个人能显著提高识别AI生成文本的准确率，虽然该系统未直接提升检测性能，但改善了小组互动质量，促进了参与者投入度和共识形成。研究还表明，对团队协作感知度高的用户更能从该系统中获益。这些发现揭示了审议型聊天机器人在提升群体协作效能方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "15",
      "pdf_url": "http://arxiv.org/pdf/2503.04945v1",
      "published_date": "2025-03-06 20:19:38 UTC",
      "updated_date": "2025-03-06 20:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:25:52.492157"
    },
    {
      "arxiv_id": "2503.04940v1",
      "title": "VQEL: Enabling Self-Developed Symbolic Language in Agents through Vector Quantization in Emergent Language Games",
      "title_zh": "VQEL：通过涌现语言游戏中的向量量化实现智能体自主发展符号语言",
      "authors": [
        "Mohammad Mahdi Samiei Paqaleh",
        "Mahdieh Soleymani Baghshah"
      ],
      "abstract": "In the field of emergent language, efforts have traditionally focused on\ndeveloping communication protocols through interactions between agents in\nreferential games. However, the aspect of internal language learning, where\nlanguage serves not only as a communicative tool with others but also as a\nmeans for individual thinking, self-reflection, and problem-solving remains\nunderexplored. Developing a language through self-play, without another agent's\ninvolvement, poses a unique challenge. It requires an agent to craft symbolic\nrepresentations and train them using direct gradient methods. The challenge\nhere is that if an agent attempts to learn symbolic representations through\nself-play using conventional modeling and techniques such as REINFORCE, the\nsolution will offer no advantage over previous multi-agent approaches. We\nintroduce VQEL, a novel method that incorporates Vector Quantization into the\nagents' architecture, enabling them to autonomously invent and develop discrete\nsymbolic representations in a self-play referential game. Following the\nself-play phase, agents can enhance their language through reinforcement\nlearning and interactions with other agents in the mutual-play phase. Our\nexperiments across various datasets demonstrate that VQEL not only outperforms\nthe traditional REINFORCE method but also benefits from improved control and\nreduced susceptibility to collapse, thanks to the incorporation of vector\nquantization.",
      "tldr_zh": "该研究提出了VQEL方法，通过将向量量化(Vector Quantization)引入智能体架构，使其能够在自玩参照游戏中自主发明和发展离散符号表示。VQEL允许智能体在自玩阶段创建符号语言，随后通过强化学习与其他智能体互动进一步优化语言能力。实验表明，VQEL不仅优于传统的REINFORCE方法，还因向量量化的引入提高了控制性并降低了崩溃风险，为智能体内部语言学习提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04940v1",
      "published_date": "2025-03-06 20:15:51 UTC",
      "updated_date": "2025-03-06 20:15:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:26:12.203728"
    },
    {
      "arxiv_id": "2503.04933v1",
      "title": "Learning-based GNSS Uncertainty Quantification using Continuous-Time Factor Graph Optimization",
      "title_zh": "基于学习的GNSS不确定性量化：连续时间因子图优化方法",
      "authors": [
        "Haoming Zhang"
      ],
      "abstract": "This short paper presents research findings on two learning-based methods for\nquantifying measurement uncertainties in global navigation satellite systems\n(GNSS). We investigate two learning strategies: offline learning for outlier\nprediction and online learning for noise distribution approximation,\nspecifically applied to GNSS pseudorange observations. To develop and evaluate\nthese learning methods, we introduce a novel multisensor state estimator that\naccurately and robustly estimates trajectory from multiple sensor inputs,\ncritical for deriving GNSS measurement residuals used to train the uncertainty\nmodels. We validate the proposed learning-based models using real-world sensor\ndata collected in diverse urban environments. Experimental results demonstrate\nthat both models effectively handle GNSS outliers and improve state estimation\nperformance. Furthermore, we provide insightful discussions to motivate future\nresearch toward developing a federated framework for robust vehicle\nlocalization in challenging environments.",
      "tldr_zh": "本文提出了两种基于学习的方法来量化全球导航卫星系统（GNSS）的测量不确定性，包括用于异常值预测的离线学习和用于噪声分布近似的在线学习。研究开发了一种多传感器状态估计器，用于从多种传感器输入中精确估计轨迹，从而为训练不确定性模型提供GNSS测量残差。实验结果表明，这两种模型有效处理了GNSS异常值并提升了状态估计性能。研究还探讨了未来开发联邦框架以在复杂环境中实现鲁棒车辆定位的可能性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "This extended abstract has been accepted to the 1st German Robotic\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2503.04933v1",
      "published_date": "2025-03-06 20:04:36 UTC",
      "updated_date": "2025-03-06 20:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:26:39.398456"
    },
    {
      "arxiv_id": "2503.04931v1",
      "title": "Curiosity-Driven Imagination: Discovering Plan Operators and Learning Associated Policies for Open-World Adaptation",
      "title_zh": "好奇心驱动的想象：发现规划算子并学习开放世界适应中的相关策略",
      "authors": [
        "Pierrick Lorang",
        "Hong Lu",
        "Matthias Scheutz"
      ],
      "abstract": "Adapting quickly to dynamic, uncertain environments-often called \"open\nworlds\"-remains a major challenge in robotics. Traditional Task and Motion\nPlanning (TAMP) approaches struggle to cope with unforeseen changes, are\ndata-inefficient when adapting, and do not leverage world models during\nlearning. We address this issue with a hybrid planning and learning system that\nintegrates two models: a low level neural network based model that learns\nstochastic transitions and drives exploration via an Intrinsic Curiosity Module\n(ICM), and a high level symbolic planning model that captures abstract\ntransitions using operators, enabling the agent to plan in an \"imaginary\" space\nand generate reward machines. Our evaluation in a robotic manipulation domain\nwith sequential novelty injections demonstrates that our approach converges\nfaster and outperforms state-of-the-art hybrid methods.",
      "tldr_zh": "该研究提出了一种好奇心驱动的想象机制，用于在开放世界中快速适应动态不确定环境。系统结合了低层神经网络模型和高层符号规划模型：前者通过内在好奇心模块(ICM)驱动探索并学习随机转移，后者利用操作符捕捉抽象转移，使智能体能在\"想象\"空间中规划并生成奖励机制。实验表明，在连续引入新奇的机器人操作任务中，该方法比现有混合方法收敛更快且性能更优。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures. Accepted at ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04931v1",
      "published_date": "2025-03-06 20:02:26 UTC",
      "updated_date": "2025-03-06 20:02:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:26:36.519642"
    },
    {
      "arxiv_id": "2503.04930v1",
      "title": "HILGEN: Hierarchically-Informed Data Generation for Biomedical NER Using Knowledgebases and Large Language Models",
      "title_zh": "HILGEN：基于知识库与大型语言模型的生物医学命名实体识别分层数据生成方法",
      "authors": [
        "Yao Ge",
        "Yuting Guo",
        "Sudeshna Das",
        "Swati Rajwal",
        "Selen Bozkurt",
        "Abeed Sarker"
      ],
      "abstract": "We present HILGEN, a Hierarchically-Informed Data Generation approach that\ncombines domain knowledge from the Unified Medical Language System (UMLS) with\nsynthetic data generated by large language models (LLMs), specifically GPT-3.5.\nOur approach leverages UMLS's hierarchical structure to expand training data\nwith related concepts, while incorporating contextual information from LLMs\nthrough targeted prompts aimed at automatically generating synthetic examples\nfor sparsely occurring named entities. The performance of the HILGEN approach\nwas evaluated across four biomedical NER datasets (MIMIC III, BC5CDR,\nNCBI-Disease, and Med-Mentions) using BERT-Large and DANN (Data Augmentation\nwith Nearest Neighbor Classifier) models, applying various data generation\nstrategies, including UMLS, GPT-3.5, and their best ensemble. For the\nBERT-Large model, incorporating UMLS led to an average F1 score improvement of\n40.36%, while using GPT-3.5 resulted in a comparable average increase of\n40.52%. The Best-Ensemble approach using BERT-Large achieved the highest\nimprovement, with an average increase of 42.29%. DANN model's F1 score improved\nby 22.74% on average using the UMLS-only approach. The GPT-3.5-based method\nresulted in a 21.53% increase, and the Best-Ensemble DANN model showed a more\nnotable improvement, with an average increase of 25.03%. Our proposed HILGEN\napproach improves NER performance in few-shot settings without requiring\nadditional manually annotated data. Our experiments demonstrate that an\neffective strategy for optimizing biomedical NER is to combine biomedical\nknowledge curated in the past, such as the UMLS, and generative LLMs to create\nsynthetic training instances. Our future research will focus on exploring\nadditional innovative synthetic data generation strategies for further\nimproving NER performance.",
      "tldr_zh": "本研究提出了HILGEN，一种基于层次化知识的数据生成方法，结合了统一医学语言系统(UMLS)的知识和大语言模型(LLMs)生成的合成数据，用于提升生物医学命名实体识别(NER)性能。通过利用UMLS的层次结构和GPT-3.5生成的上下文信息，HILGEN能够自动生成稀疏实体的训练样本。实验表明，使用UMLS和GPT-3.5的Best-Ensemble策略显著提升了BERT-Large和DANN模型的F1分数，分别达到42.29%和25.03%的平均提升。该方法在少样本场景下无需额外人工标注数据，有效优化了生物医学NER任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04930v1",
      "published_date": "2025-03-06 20:02:19 UTC",
      "updated_date": "2025-03-06 20:02:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:26:43.505406"
    },
    {
      "arxiv_id": "2503.04725v1",
      "title": "L$^2$M: Mutual Information Scaling Law for Long-Context Language Modeling",
      "title_zh": "L$^2$M：长上下文语言建模的互信息缩放定律",
      "authors": [
        "Zhuo Chen",
        "Oriol Mayné i Comas",
        "Zhuotao Jin",
        "Di Luo",
        "Marin Soljačić"
      ],
      "abstract": "We rigorously establish a bipartite mutual information scaling law in natural\nlanguage that governs long-range dependencies. This scaling law, which we show\nis distinct from and scales independently of the conventional two-point mutual\ninformation, is the key to understanding long-context language modeling. Using\nthis scaling law, we formulate the Long-context Language Modeling (L$^2$M)\ncondition, which relates a model's capacity for effective long context length\nmodeling to the scaling of its latent state size for storing past information.\nOur results are validated through experiments on both transformers and state\nspace models. This work establishes a theoretical foundation that guides the\ndevelopment of large language models toward longer context lengths.",
      "tldr_zh": "该研究提出了长上下文语言建模(L$^2$M)的互信息尺度定律，揭示了自然语言中长程依赖关系的二部互信息尺度规律。研究发现，该尺度定律与传统两点互信息不同且独立，是理解长上下文语言建模的关键。基于此，研究者提出了L$^2$M条件，将模型的有效长上下文建模能力与其潜在状态大小的尺度联系起来。实验在Transformer和状态空间模型上验证了该理论，为开发更长上下文的大语言模型奠定了理论基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT",
        "physics.data-an"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 12 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.04725v1",
      "published_date": "2025-03-06 18:59:48 UTC",
      "updated_date": "2025-03-06 18:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:26:47.891210"
    },
    {
      "arxiv_id": "2503.04723v2",
      "title": "Shifting Long-Context LLMs Research from Input to Output",
      "title_zh": "将长上下文大语言模型研究的重心从输入转向输出",
      "authors": [
        "Yuhao Wu",
        "Yushi Bai",
        "Zhiqing Hu",
        "Shangqing Tu",
        "Ming Shan Hee",
        "Juanzi Li",
        "Roy Ka-Wei Lee"
      ],
      "abstract": "Recent advancements in long-context Large Language Models (LLMs) have\nprimarily concentrated on processing extended input contexts, resulting in\nsignificant strides in long-context comprehension. However, the equally\ncritical aspect of generating long-form outputs has received comparatively less\nattention. This paper advocates for a paradigm shift in NLP research toward\naddressing the challenges of long-output generation. Tasks such as novel\nwriting, long-term planning, and complex reasoning require models to understand\nextensive contexts and produce coherent, contextually rich, and logically\nconsistent extended text. These demands highlight a critical gap in current LLM\ncapabilities. We underscore the importance of this under-explored domain and\ncall for focused efforts to develop foundational LLMs tailored for generating\nhigh-quality, long-form outputs, which hold immense potential for real-world\napplications.",
      "tldr_zh": "该论文呼吁将长上下文大语言模型（LLMs）的研究重点从输入转向输出。当前研究主要集中在处理长上下文输入，而在生成长文本输出方面的探索相对不足。论文强调，生成高质量、逻辑一致的长文本（如小说创作、长期规划和复杂推理）是亟待解决的关键挑战。作者主张开发专门针对长文本生成的基础模型，以填补当前LLMs能力的空白，并推动其在实际应用中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.04723v2",
      "published_date": "2025-03-06 18:59:37 UTC",
      "updated_date": "2025-03-07 03:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:26:59.141609"
    },
    {
      "arxiv_id": "2503.04722v1",
      "title": "Enough Coin Flips Can Make LLMs Act Bayesian",
      "title_zh": "足够的硬币翻转可以使大语言模型表现出贝叶斯行为",
      "authors": [
        "Ritwik Gupta",
        "Rodolfo Corona",
        "Jiaxin Ge",
        "Eric Wang",
        "Dan Klein",
        "Trevor Darrell",
        "David M. Chan"
      ],
      "abstract": "Large language models (LLMs) exhibit the ability to generalize given few-shot\nexamples in their input prompt, an emergent capability known as in-context\nlearning (ICL). We investigate whether LLMs utilize ICL to perform structured\nreasoning in ways that are consistent with a Bayesian framework or rely on\npattern matching. Using a controlled setting of biased coin flips, we find\nthat: (1) LLMs often possess biased priors, causing initial divergence in\nzero-shot settings, (2) in-context evidence outweighs explicit bias\ninstructions, (3) LLMs broadly follow Bayesian posterior updates, with\ndeviations primarily due to miscalibrated priors rather than flawed updates,\nand (4) attention magnitude has negligible effect on Bayesian inference. With\nsufficient demonstrations of biased coin flips via ICL, LLMs update their\npriors in a Bayesian manner.",
      "tldr_zh": "研究表明，大语言模型(LLMs)在少量示例的上下文学习(ICL)中，能够表现出类似贝叶斯推理的行为。通过控制偏置硬币翻转的实验发现：LLMs虽然初始存在偏置先验，但在足够多的ICL示例下，能够以贝叶斯方式更新后验概率，且注意力机制对推理影响较小。这表明LLMs的推理能力并非完全依赖模式匹配，而是可以通过ICL实现结构化推理。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04722v1",
      "published_date": "2025-03-06 18:59:23 UTC",
      "updated_date": "2025-03-06 18:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:27:09.725170"
    },
    {
      "arxiv_id": "2503.04715v4",
      "title": "Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining",
      "title_zh": "可预测的规模：第一部分 —— 大语言模型预训练中的最优超参数缩放规律",
      "authors": [
        "Houyi Li",
        "Wenzhen Zheng",
        "Jingcheng Hu",
        "Qiufeng Wang",
        "Hanshan Zhang",
        "Zili Wang",
        "Shijie Xuyang",
        "Yuantao Fan",
        "Shuigeng Zhou",
        "Xiangyu Zhang",
        "Daxin Jiang"
      ],
      "abstract": "The impressive capabilities of Large Language Models (LLMs) across diverse\ntasks are now well-established, yet their effective deployment necessitates\ncareful hyperparameter optimization. Through extensive empirical studies\ninvolving grid searches across diverse configurations, we discover universal\nscaling laws governing these hyperparameters: optimal learning rate follows a\npower-law relationship with both model parameters and data sizes, while optimal\nbatch size scales primarily with data sizes. Our analysis reveals a convex\noptimization landscape for hyperparameters under fixed models and data size\nconditions. This convexity implies an optimal hyperparameter plateau. We\ncontribute a universal, plug-and-play optimal hyperparameter tool for the\ncommunity. Its estimated values on the test set are merely 0.09% away from the\nglobally optimal LLM performance found via an exhaustive search. These laws\ndemonstrate remarkable robustness across variations in model sparsity, training\ndata distribution, and model shape. To our best known, this is the first work\nthat unifies different model shapes and structures, such as Mixture-of-Experts\nmodels and dense transformers, as well as establishes optimal hyperparameter\nscaling laws across diverse data distributions. This exhaustive optimization\nprocess demands substantial computational resources, utilizing nearly one\nmillion NVIDIA H800 GPU hours to train 3,700 LLMs of varying sizes and\nhyperparameters from scratch and consuming approximately 100 trillion tokens in\ntotal. To facilitate reproducibility and further research, we will\nprogressively release all loss measurements and model checkpoints through our\ndesignated repository https://step-law.github.io/",
      "tldr_zh": "该研究首次提出大型语言模型(LLM)预训练中的最优超参数缩放定律。通过训练3,700个不同规模的LLM（消耗近百万H800 GPU小时），发现：最优学习率与模型参数量及数据规模呈幂律关系，而最优批大小主要随数据规模变化。研究揭示了超参数在固定模型和数据条件下的凸优化特性，并开发了误差仅0.09%的通用超参数预测工具。这些定律在稀疏模型、混合专家(MoE)架构及不同数据分布下均保持稳健，首次统一了密集Transformer和MoE模型的超参数缩放规律。所有实验数据和模型检查点将通过指定仓库逐步公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.04715v4",
      "published_date": "2025-03-06 18:58:29 UTC",
      "updated_date": "2025-03-19 16:28:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:27:32.701967"
    },
    {
      "arxiv_id": "2503.04713v1",
      "title": "Scaling Rich Style-Prompted Text-to-Speech Datasets",
      "title_zh": "扩展富风格提示的文本转语音数据集",
      "authors": [
        "Anuj Diwan",
        "Zhisheng Zheng",
        "David Harwath",
        "Eunsol Choi"
      ],
      "abstract": "We introduce Paralinguistic Speech Captions (ParaSpeechCaps), a large-scale\ndataset that annotates speech utterances with rich style captions. While rich\nabstract tags (e.g. guttural, nasal, pained) have been explored in small-scale\nhuman-annotated datasets, existing large-scale datasets only cover basic tags\n(e.g. low-pitched, slow, loud). We combine off-the-shelf text and speech\nembedders, classifiers and an audio language model to automatically scale rich\ntag annotations for the first time. ParaSpeechCaps covers a total of 59 style\ntags, including both speaker-level intrinsic tags and utterance-level\nsituational tags. It consists of 342 hours of human-labelled data (PSC-Base)\nand 2427 hours of automatically annotated data (PSC-Scaled). We finetune\nParler-TTS, an open-source style-prompted TTS model, on ParaSpeechCaps, and\nachieve improved style consistency (+7.9% Consistency MOS) and speech quality\n(+15.5% Naturalness MOS) over the best performing baseline that combines\nexisting rich style tag datasets. We ablate several of our dataset design\nchoices to lay the foundation for future work in this space. Our dataset,\nmodels and code are released at https://github.com/ajd12342/paraspeechcaps .",
      "tldr_zh": "该研究提出了Paralinguistic Speech Captions (ParaSpeechCaps)，一个大规模数据集，通过丰富的风格描述标注语音片段。与现有大规模数据集仅涵盖基本标签（如低音、慢速、大声）不同，ParaSpeechCaps首次利用现成的文本和语音嵌入器、分类器以及音频语言模型，自动扩展了59种风格标签，包括说话者内在特征和情境特征。该数据集包含342小时人工标注数据（PSC-Base）和2427小时自动标注数据（PSC-Scaled）。基于此，研究团队微调了开源风格提示TTS模型Parler-TTS，在风格一致性和语音质量上分别比最佳基线模型提升了7.9%和15.5%，为未来研究奠定了基础。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04713v1",
      "published_date": "2025-03-06 18:57:40 UTC",
      "updated_date": "2025-03-06 18:57:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:27:36.571651"
    },
    {
      "arxiv_id": "2503.04710v1",
      "title": "Self-Supervised Models for Phoneme Recognition: Applications in Children's Speech for Reading Learning",
      "title_zh": "自监督模型在音素识别中的应用：面向儿童阅读学习的语音研究",
      "authors": [
        "Lucas Block Medin",
        "Thomas Pellegrini",
        "Lucile Gelin"
      ],
      "abstract": "Child speech recognition is still an underdeveloped area of research due to\nthe lack of data (especially on non-English languages) and the specific\ndifficulties of this task. Having explored various architectures for child\nspeech recognition in previous work, in this article we tackle recent\nself-supervised models. We first compare wav2vec 2.0, HuBERT and WavLM models\nadapted to phoneme recognition in French child speech, and continue our\nexperiments with the best of them, WavLM base+. We then further adapt it by\nunfreezing its transformer blocks during fine-tuning on child speech, which\ngreatly improves its performance and makes it significantly outperform our base\nmodel, a Transformer+CTC. Finally, we study in detail the behaviour of these\ntwo models under the real conditions of our application, and show that WavLM\nbase+ is more robust to various reading tasks and noise levels. Index Terms:\nspeech recognition, child speech, self-supervised learning",
      "tldr_zh": "该论文研究了自监督学习模型在儿童语音音素识别中的应用，特别针对法语儿童阅读学习场景。通过对比wav2vec 2.0、HuBERT和WavLM等模型，发现WavLM base+表现最佳，在微调阶段解冻其transformer块可显著提升性能，优于传统Transformer+CTC基线模型。实验表明，WavLM base+对不同阅读任务和噪声水平具有更强鲁棒性，为解决儿童语音数据匮乏问题提供了有效方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "This paper was originally published in the Proceedings of Interspeech\n  2024. DOI: 10.21437/Interspeech.2024-1095",
      "pdf_url": "http://arxiv.org/pdf/2503.04710v1",
      "published_date": "2025-03-06 18:57:16 UTC",
      "updated_date": "2025-03-06 18:57:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:27:31.744662"
    },
    {
      "arxiv_id": "2503.04704v2",
      "title": "Universality of Layer-Level Entropy-Weighted Quantization Beyond Model Architecture and Size",
      "title_zh": "层级熵加权量化的普适性：超越模型架构与规模的限制",
      "authors": [
        "Alireza Behtash",
        "Marijan Fofonjka",
        "Ethan Baird",
        "Tyler Mauer",
        "Hossein Moghimifam",
        "David Stout",
        "Joel Dennison"
      ],
      "abstract": "We present a novel approach to selective model quantization that transcends\nthe limitations of architecture-specific and size-dependent compression methods\nfor Large Language Models (LLMs) using Entropy-Weighted Quantization (EWQ). By\nanalyzing the entropy distribution across transformer blocks, EWQ determines\nwhich blocks can be safely quantized without causing significant performance\ndegradation, independent of model architecture or size. Our method outperforms\nuniform quantization approaches, maintaining Massive Multitask Language\nUnderstanding (MMLU) accuracy scores within 0.5% of unquantized models while\nreducing memory usage by up to 18%. We demonstrate the effectiveness of EWQ\nacross multiple architectures -- from 1.6B to 70B parameters -- and showcase\nconsistent improvements in the quality-compression trade-off regardless of\nmodel scale or architectural design. A surprising finding of EWQ is its ability\nto reduce perplexity compared to unquantized models, suggesting the presence of\nbeneficial regularization through selective precision reduction. This\nimprovement holds across different model families, indicating a fundamental\nrelationship between layer-level entropy and optimal precision requirements.\nAdditionally, we introduce FastEWQ, a rapid method for entropy distribution\nanalysis that eliminates the need for loading model weights. This technique\nleverages universal characteristics of entropy distribution that persist across\nvarious architectures and scales, enabling near-instantaneous quantization\ndecisions while maintaining 80% classification accuracy with full entropy\nanalysis. Our results demonstrate that effective quantization strategies can be\ndeveloped independently of specific architectural choices or model sizes,\nopening new possibilities for efficient LLM deployment.",
      "tldr_zh": "本文提出了一种基于熵加权量化（EWQ）的模型量化方法，突破了传统方法对模型架构和规模的依赖。通过分析Transformer块的熵分布，EWQ能够在不显著降低性能的情况下选择性地量化模型，并减少高达18%的内存使用，同时保持大规模多任务语言理解（MMLU）精度在未量化模型的0.5%以内。实验表明，EWQ不仅适用于不同规模（1.6B到70B参数）和架构的模型，还意外地降低了困惑度，揭示了选择性精度降低的潜在正则化效果。此外，作者提出的FastEWQ方法无需加载模型权重即可快速分析熵分布，为高效LLM部署提供了新思路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 7 figures, 14 tables; Fixed some types, added some\n  clarifications and improvements",
      "pdf_url": "http://arxiv.org/pdf/2503.04704v2",
      "published_date": "2025-03-06 18:54:32 UTC",
      "updated_date": "2025-03-07 15:12:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:27:38.183849"
    },
    {
      "arxiv_id": "2503.04697v1",
      "title": "L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning",
      "title_zh": "L1：通过强化学习控制推理模型的思考时长",
      "authors": [
        "Pranjal Aggarwal",
        "Sean Welleck"
      ],
      "abstract": "Reasoning language models have shown an uncanny ability to improve\nperformance at test-time by ``thinking longer''-that is, by generating longer\nchain-of-thought sequences and hence using more compute. However, the length of\ntheir chain-of-thought reasoning is not controllable, making it impossible to\nallocate test-time compute to achieve a desired level of performance. We\nintroduce Length Controlled Policy Optimization (LCPO), a simple reinforcement\nlearning method that optimizes for accuracy and adherence to user-specified\nlength constraints. We use LCPO to train L1, a reasoning language model that\nproduces outputs satisfying a length constraint given in its prompt. L1's\nlength control allows for smoothly trading off computational cost and accuracy\non a wide range of tasks, and outperforms the state-of-the-art S1 method for\nlength control. Furthermore, we uncover an unexpected short chain-of-thought\ncapability in models trained with LCPO. For instance, our 1.5B L1 model\nsurpasses GPT-4o at equal reasoning lengths. Overall, LCPO enables precise\ncontrol over reasoning length, allowing for fine-grained allocation of\ntest-time compute and accuracy. We release code and models at\nhttps://www.cmu-l3.github.io/l1",
      "tldr_zh": "该研究提出了Length Controlled Policy Optimization (LCPO)，一种基于强化学习的方法，用于控制推理语言模型的链式思维(Chain-of-Thought)长度。通过LCPO训练的L1模型能够根据提示中的长度约束生成输出，实现了计算成本与准确率的灵活权衡。实验表明，L1在多种任务上优于现有的S1方法，甚至在某些短链式思维任务中，1.5B参数的L1模型表现优于GPT-4o。LCPO为精确控制推理长度提供了有效工具，支持细粒度的计算资源分配与性能优化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04697v1",
      "published_date": "2025-03-06 18:43:29 UTC",
      "updated_date": "2025-03-06 18:43:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:28:10.232099"
    },
    {
      "arxiv_id": "2503.04680v1",
      "title": "Matrix Factorization for Inferring Associations and Missing Links",
      "title_zh": "矩阵分解在关联推断与缺失链接预测中的应用",
      "authors": [
        "Ryan Barron",
        "Maksim E. Eren",
        "Duc P. Truong",
        "Cynthia Matuszek",
        "James Wendelberger",
        "Mary F. Dorn",
        "Boian Alexandrov"
      ],
      "abstract": "Missing link prediction is a method for network analysis, with applications\nin recommender systems, biology, social sciences, cybersecurity, information\nretrieval, and Artificial Intelligence (AI) reasoning in Knowledge Graphs.\nMissing link prediction identifies unseen but potentially existing connections\nin a network by analyzing the observed patterns and relationships. In\nproliferation detection, this supports efforts to identify and characterize\nattempts by state and non-state actors to acquire nuclear weapons or associated\ntechnology - a notoriously challenging but vital mission for global security.\nDimensionality reduction techniques like Non-Negative Matrix Factorization\n(NMF) and Logistic Matrix Factorization (LMF) are effective but require\nselection of the matrix rank parameter, that is, of the number of hidden\nfeatures, k, to avoid over/under-fitting. We introduce novel Weighted (WNMFk),\nBoolean (BNMFk), and Recommender (RNMFk) matrix factorization methods, along\nwith ensemble variants incorporating logistic factorization, for link\nprediction. Our methods integrate automatic model determination for rank\nestimation by evaluating stability and accuracy using a modified bootstrap\nmethodology and uncertainty quantification (UQ), assessing prediction\nreliability under random perturbations. We incorporate Otsu threshold selection\nand k-means clustering for Boolean matrix factorization, comparing them to\ncoordinate descent-based Boolean thresholding. Our experiments highlight the\nimpact of rank k selection, evaluate model performance under varying test-set\nsizes, and demonstrate the benefits of UQ for reliable predictions using\nabstention. We validate our methods on three synthetic datasets (Boolean and\nuniformly distributed) and benchmark them against LMF and symmetric LMF\n(symLMF) on five real-world protein-protein interaction networks, showcasing an\nimproved prediction performance.",
      "tldr_zh": "该研究提出了几种新型矩阵分解方法，包括加权矩阵分解（WNMFk）、布尔矩阵分解（BNMFk）和推荐矩阵分解（RNMFk），用于网络分析中的缺失链接预测。这些方法结合了自动模型确定技术，通过改进的引导方法和不确定性量化（UQ）来评估模型的稳定性和准确性，从而优化矩阵秩参数的选择。实验表明，新方法在合成数据集和真实蛋白质-蛋白质相互作用网络上均表现出优于现有方法的预测性能，特别是在处理不同测试集规模和可靠性评估方面。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages, 14 figures, 3 tables, 1 algorithm",
      "pdf_url": "http://arxiv.org/pdf/2503.04680v1",
      "published_date": "2025-03-06 18:22:46 UTC",
      "updated_date": "2025-03-06 18:22:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:28:11.447000"
    },
    {
      "arxiv_id": "2503.04679v1",
      "title": "Multi-Agent Inverse Q-Learning from Demonstrations",
      "title_zh": "多智能体逆向 Q 学习：基于示范的推理",
      "authors": [
        "Nathaniel Haynam",
        "Adam Khoja",
        "Dhruv Kumar",
        "Vivek Myers",
        "Erdem Bıyık"
      ],
      "abstract": "When reward functions are hand-designed, deep reinforcement learning\nalgorithms often suffer from reward misspecification, causing them to learn\nsuboptimal policies in terms of the intended task objectives. In the\nsingle-agent case, inverse reinforcement learning (IRL) techniques attempt to\naddress this issue by inferring the reward function from expert demonstrations.\nHowever, in multi-agent problems, misalignment between the learned and true\nobjectives is exacerbated due to increased environment non-stationarity and\nvariance that scales with multiple agents. As such, in multi-agent general-sum\ngames, multi-agent IRL algorithms have difficulty balancing cooperative and\ncompetitive objectives. To address these issues, we propose Multi-Agent\nMarginal Q-Learning from Demonstrations (MAMQL), a novel sample-efficient\nframework for multi-agent IRL. For each agent, MAMQL learns a critic\nmarginalized over the other agents' policies, allowing for a well-motivated use\nof Boltzmann policies in the multi-agent context. We identify a connection\nbetween optimal marginalized critics and single-agent soft-Q IRL, allowing us\nto apply a direct, simple optimization criterion from the single-agent domain.\nAcross our experiments on three different simulated domains, MAMQL\nsignificantly outperforms previous multi-agent methods in average reward,\nsample efficiency, and reward recovery by often more than 2-5x. We make our\ncode available at https://sites.google.com/view/mamql .",
      "tldr_zh": "该研究提出了多智能体边际Q学习(MAMQL)，一种从专家演示中进行多智能体逆强化学习(IRL)的新框架，旨在解决多智能体环境中奖励函数难以设计和目标不一致的问题。MAMQL通过为每个智能体学习一个边际化其他智能体策略的critic，将单智能体软Q IRL的优化准则扩展到多智能体领域，从而在合作与竞争目标之间取得平衡。实验表明，在三个模拟领域中，MAMQL在平均奖励、样本效率和奖励恢复方面显著优于现有方法，通常提升2-5倍。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "8 pages, 4 figures, 2 tables. Published at the International\n  Conference on Robotics and Automation (ICRA) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04679v1",
      "published_date": "2025-03-06 18:22:29 UTC",
      "updated_date": "2025-03-06 18:22:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:28:28.140248"
    },
    {
      "arxiv_id": "2503.04877v1",
      "title": "Adapt3R: Adaptive 3D Scene Representation for Domain Transfer in Imitation Learning",
      "title_zh": "Adapt3R：面向模仿学习领域迁移的自适应三维场景表征",
      "authors": [
        "Albert Wilcox",
        "Mohamed Ghanem",
        "Masoud Moghani",
        "Pierre Barroso",
        "Benjamin Joffe",
        "Animesh Garg"
      ],
      "abstract": "Imitation Learning (IL) has been very effective in training robots to perform\ncomplex and diverse manipulation tasks. However, its performance declines\nprecipitously when the observations are out of the training distribution. 3D\nscene representations that incorporate observations from calibrated RGBD\ncameras have been proposed as a way to improve generalizability of IL policies,\nbut our evaluations in cross-embodiment and novel camera pose settings found\nthat they show only modest improvement. To address those challenges, we propose\nAdaptive 3D Scene Representation (Adapt3R), a general-purpose 3D observation\nencoder which uses a novel architecture to synthesize data from one or more\nRGBD cameras into a single vector that can then be used as conditioning for\narbitrary IL algorithms. The key idea is to use a pretrained 2D backbone to\nextract semantic information about the scene, using 3D only as a medium for\nlocalizing this semantic information with respect to the end-effector. We show\nthat when trained end-to-end with several SOTA multi-task IL algorithms,\nAdapt3R maintains these algorithms' multi-task learning capacity while enabling\nzero-shot transfer to novel embodiments and camera poses. Furthermore, we\nprovide a detailed suite of ablation and sensitivity experiments to elucidate\nthe design space for point cloud observation encoders.",
      "tldr_zh": "该研究提出了Adapt3R，一种自适应的3D场景表示方法，用于提升模仿学习（Imitation Learning, IL）在跨具身和新相机姿态设置下的泛化能力。Adapt3R通过结合预训练的2D骨干网络提取场景语义信息，并利用3D技术将这些信息相对于机械臂末端进行定位，从而将多个RGBD相机的数据编码为单一向量。实验表明，Adapt3R在零样本迁移到新具身和相机姿态时，能够保持最先进多任务IL算法的性能，同时显著提升跨域适应性。研究还通过详尽的消融实验揭示了点云观测编码器的设计空间。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Videos, code, and data: https://pairlab.github.io/Adapt3R",
      "pdf_url": "http://arxiv.org/pdf/2503.04877v1",
      "published_date": "2025-03-06 18:17:09 UTC",
      "updated_date": "2025-03-06 18:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:28:39.038849"
    },
    {
      "arxiv_id": "2503.07650v2",
      "title": "Insights into Schizophrenia: Leveraging Machine Learning for Early Identification via EEG, ERP, and Demographic Attributes",
      "title_zh": "精神分裂症洞见：利用机器学习通过脑电图、事件相关电位与人口统计学特征实现早期识别",
      "authors": [
        "Sara Alkhalifa"
      ],
      "abstract": "The research presents a machine learning (ML) classifier designed to\ndifferentiate between schizophrenia patients and healthy controls by utilising\nfeatures extracted from electroencephalogram (EEG) data, specifically focusing\non event-related potentials (ERPs) and certain demographic variables. The\ndataset comprises data from 81 participants, encompassing 32 healthy controls\nand 49 schizophrenia patients, all sourced from an online dataset. After\npreprocessing the dataset, our ML model achieved an accuracy of 99.930%. This\nperformance outperforms earlier research, including those that used deep\nlearning methods. Additionally, an analysis was conducted to assess individual\nfeatures' contribution to improving classification accuracy. This involved\nsystematically excluding specific features from the original dataset one at a\ntime, and another technique involved an iterative process of removing features\nbased on their entropy scores incrementally. The impact of these removals on\nmodel performance was evaluated to identify the most informative features.",
      "tldr_zh": "该研究开发了一种机器学习分类器，通过结合脑电图（EEG）数据中的事件相关电位（ERP）特征和人口统计学变量，用于区分精神分裂症患者与健康对照组。基于81名参与者的数据集，模型在预处理后达到了99.930%的准确率，优于包括深度学习方法在内的先前研究。此外，研究通过系统排除特征和基于熵值的迭代移除方法，评估了各特征对分类准确率的贡献，识别出最具信息量的特征，为精神分裂症的早期识别提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T05, 92C60"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 6 figures and 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.07650v2",
      "published_date": "2025-03-06 17:42:25 UTC",
      "updated_date": "2025-03-15 09:36:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:28:23.809153"
    },
    {
      "arxiv_id": "2503.04647v1",
      "title": "Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference Alignment",
      "title_zh": "隐式跨语言奖励机制：高效多语言偏好对齐",
      "authors": [
        "Wen Yang",
        "Junhong Wu",
        "Chen Wang",
        "Chengqing Zong",
        "Jiajun Zhang"
      ],
      "abstract": "Direct Preference Optimization (DPO) has become a prominent method for\naligning Large Language Models (LLMs) with human preferences. While DPO has\nenabled significant progress in aligning English LLMs, multilingual preference\nalignment is hampered by data scarcity. To address this, we propose a novel\napproach that $\\textit{captures}$ learned preferences from well-aligned English\nmodels by implicit rewards and $\\textit{transfers}$ them to other languages\nthrough iterative training. Specifically, we derive an implicit reward model\nfrom the logits of an English DPO-aligned model and its corresponding reference\nmodel. This reward model is then leveraged to annotate preference relations in\ncross-lingual instruction-following pairs, using English instructions to\nevaluate multilingual responses. The annotated data is subsequently used for\nmultilingual DPO fine-tuning, facilitating preference knowledge transfer from\nEnglish to other languages. Fine-tuning Llama3 for two iterations resulted in a\n12.72% average improvement in Win Rate and a 5.97% increase in Length Control\nWin Rate across all training languages on the X-AlpacaEval leaderboard. Our\nfindings demonstrate that leveraging existing English-aligned models can enable\nefficient and effective multilingual preference alignment, significantly\nreducing the need for extensive multilingual preference data. The code is\navailable at https://github.com/ZNLP/Implicit-Cross-Lingual-Rewarding",
      "tldr_zh": "本研究提出了一种基于隐式奖励的跨语言偏好对齐方法，利用已对齐的英文大语言模型(LLMs)通过Direct Preference Optimization (DPO)学习到的偏好知识，将其迁移到其他语言。具体方法是从英文DPO对齐模型的logits中提取隐式奖励模型，用于标注跨语言指令跟随数据中的偏好关系，进而进行多语言DPO微调。实验表明，该方法在X-AlpacaEval排行榜上显著提升了多语言模型的Win Rate和Length Control Win Rate，有效减少了对多语言偏好数据的需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.04647v1",
      "published_date": "2025-03-06 17:33:01 UTC",
      "updated_date": "2025-03-06 17:33:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:29:27.356825"
    },
    {
      "arxiv_id": "2503.04641v1",
      "title": "Simulating the Real World: A Unified Survey of Multimodal Generative Models",
      "title_zh": "模拟现实世界：多模态生成模型统一综述",
      "authors": [
        "Yuqi Hu",
        "Longguang Wang",
        "Xian Liu",
        "Ling-Hao Chen",
        "Yuwei Guo",
        "Yukai Shi",
        "Ce Liu",
        "Anyi Rao",
        "Zeyu Wang",
        "Hui Xiong"
      ],
      "abstract": "Understanding and replicating the real world is a critical challenge in\nArtificial General Intelligence (AGI) research. To achieve this, many existing\napproaches, such as world models, aim to capture the fundamental principles\ngoverning the physical world, enabling more accurate simulations and meaningful\ninteractions. However, current methods often treat different modalities,\nincluding 2D (images), videos, 3D, and 4D representations, as independent\ndomains, overlooking their interdependencies. Additionally, these methods\ntypically focus on isolated dimensions of reality without systematically\nintegrating their connections. In this survey, we present a unified survey for\nmultimodal generative models that investigate the progression of data\ndimensionality in real-world simulation. Specifically, this survey starts from\n2D generation (appearance), then moves to video (appearance+dynamics) and 3D\ngeneration (appearance+geometry), and finally culminates in 4D generation that\nintegrate all dimensions. To the best of our knowledge, this is the first\nattempt to systematically unify the study of 2D, video, 3D and 4D generation\nwithin a single framework. To guide future research, we provide a comprehensive\nreview of datasets, evaluation metrics and future directions, and fostering\ninsights for newcomers. This survey serves as a bridge to advance the study of\nmultimodal generative models and real-world simulation within a unified\nframework.",
      "tldr_zh": "该综述论文首次系统性地统一了多模态生成模型的研究框架，涵盖从2D（图像）、视频、3D到4D生成的数据维度演进，探索现实世界模拟的关键挑战。论文指出现有方法通常将不同模态（如图像、视频、3D和4D）视为独立领域，忽视了其内在关联，并缺乏对现实多维度整合的系统研究。通过全面回顾数据集、评估指标和未来方向，该研究为多模态生成模型和现实世界模拟提供了一个统一的框架，为新研究者提供了重要指导。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Repository for the related papers at\n  https://github.com/ALEEEHU/World-Simulator",
      "pdf_url": "http://arxiv.org/pdf/2503.04641v1",
      "published_date": "2025-03-06 17:31:43 UTC",
      "updated_date": "2025-03-06 17:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:28:44.641912"
    },
    {
      "arxiv_id": "2503.04636v2",
      "title": "Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models via Watermarking",
      "title_zh": "为您的LLM打上标记：通过水印技术检测开源大型语言模型的滥用",
      "authors": [
        "Yijie Xu",
        "Aiwei Liu",
        "Xuming Hu",
        "Lijie Wen",
        "Hui Xiong"
      ],
      "abstract": "As open-source large language models (LLMs) like Llama3 become more capable,\nit is crucial to develop watermarking techniques to detect their potential\nmisuse. Existing watermarking methods either add watermarks during LLM\ninference, which is unsuitable for open-source LLMs, or primarily target\nclassification LLMs rather than recent generative LLMs. Adapting these\nwatermarks to open-source LLMs for misuse detection remains an open challenge.\nThis work defines two misuse scenarios for open-source LLMs: intellectual\nproperty (IP) violation and LLM Usage Violation. Then, we explore the\napplication of inference-time watermark distillation and backdoor watermarking\nin these contexts. We propose comprehensive evaluation methods to assess the\nimpact of various real-world further fine-tuning scenarios on watermarks and\nthe effect of these watermarks on LLM performance. Our experiments reveal that\nbackdoor watermarking could effectively detect IP Violation, while\ninference-time watermark distillation is applicable in both scenarios but less\nrobust to further fine-tuning and has a more significant impact on LLM\nperformance compared to backdoor watermarking. Exploring more advanced\nwatermarking methods for open-source LLMs to detect their misuse should be an\nimportant future direction.",
      "tldr_zh": "该研究针对开源大语言模型(LLMs)的滥用问题，提出了两种水印技术：推理时水印蒸馏和基于后门的水印。研究定义了两种滥用场景：知识产权(IP)侵权和LLM使用违规，并评估了不同水印技术在这些场景中的有效性。实验表明，后门水印能有效检测IP侵权，而推理时水印蒸馏适用于两种场景，但对进一步微调的鲁棒性较差，且对LLM性能影响更大。研究强调开发更先进的水印技术是未来重要方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by the ICLR 2025 Workshop on GenAI Watermarking",
      "pdf_url": "http://arxiv.org/pdf/2503.04636v2",
      "published_date": "2025-03-06 17:24:06 UTC",
      "updated_date": "2025-03-15 20:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:28:54.239866"
    },
    {
      "arxiv_id": "2503.04626v2",
      "title": "IDInit: A Universal and Stable Initialization Method for Neural Network Training",
      "title_zh": "IDInit：一种通用且稳定的神经网络训练初始化方法",
      "authors": [
        "Yu Pan",
        "Chaozheng Wang",
        "Zekai Wu",
        "Qifan Wang",
        "Min Zhang",
        "Zenglin Xu"
      ],
      "abstract": "Deep neural networks have achieved remarkable accomplishments in practice.\nThe success of these networks hinges on effective initialization methods, which\nare vital for ensuring stable and rapid convergence during training. Recently,\ninitialization methods that maintain identity transition within layers have\nshown good efficiency in network training. These techniques (e.g., Fixup) set\nspecific weights to zero to achieve identity control. However, settings of\nremaining weight (e.g., Fixup uses random values to initialize non-zero\nweights) will affect the inductive bias that is achieved only by a zero weight,\nwhich may be harmful to training. Addressing this concern, we introduce fully\nidentical initialization (IDInit), a novel method that preserves identity in\nboth the main and sub-stem layers of residual networks. IDInit employs a padded\nidentity-like matrix to overcome rank constraints in non-square weight\nmatrices. Furthermore, we show the convergence problem of an identity matrix\ncan be solved by stochastic gradient descent. Additionally, we enhance the\nuniversality of IDInit by processing higher-order weights and addressing dead\nneuron problems. IDInit is a straightforward yet effective initialization\nmethod, with improved convergence, stability, and performance across various\nsettings, including large-scale datasets and deep models.",
      "tldr_zh": "该研究提出了一种新颖的神经网络初始化方法IDInit，通过在全同初始化中采用填充的类单位矩阵，解决了非方形权重矩阵的秩约束问题，并证明了随机梯度下降可以解决单位矩阵的收敛问题。该方法在处理高阶权重和解决死神经元问题上表现出色，提高了初始化过程的收敛性、稳定性和性能，适用于大规模数据集和深度模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04626v2",
      "published_date": "2025-03-06 17:12:46 UTC",
      "updated_date": "2025-03-09 16:31:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:28:56.456601"
    },
    {
      "arxiv_id": "2503.04606v2",
      "title": "The Best of Both Worlds: Integrating Language Models and Diffusion Models for Video Generation",
      "title_zh": "两全其美：融合语言模型与扩散模型的视频生成技术",
      "authors": [
        "Aoxiong Yin",
        "Kai Shen",
        "Yichong Leng",
        "Xu Tan",
        "Xinyu Zhou",
        "Juncheng Li",
        "Siliang Tang"
      ],
      "abstract": "Recent advancements in text-to-video (T2V) generation have been driven by two\ncompeting paradigms: autoregressive language models and diffusion models.\nHowever, each paradigm has intrinsic limitations: language models struggle with\nvisual quality and error accumulation, while diffusion models lack semantic\nunderstanding and causal modeling. In this work, we propose LanDiff, a hybrid\nframework that synergizes the strengths of both paradigms through\ncoarse-to-fine generation. Our architecture introduces three key innovations:\n(1) a semantic tokenizer that compresses 3D visual features into compact 1D\ndiscrete representations through efficient semantic compression, achieving a\n$\\sim$14,000$\\times$ compression ratio; (2) a language model that generates\nsemantic tokens with high-level semantic relationships; (3) a streaming\ndiffusion model that refines coarse semantics into high-fidelity videos.\nExperiments show that LanDiff, a 5B model, achieves a score of 85.43 on the\nVBench T2V benchmark, surpassing the state-of-the-art open-source models\nHunyuan Video (13B) and other commercial models such as Sora, Kling, and\nHailuo. Furthermore, our model also achieves state-of-the-art performance in\nlong video generation, surpassing other open-source models in this field. Our\ndemo can be viewed at https://landiff.github.io/.",
      "tldr_zh": "本研究提出LanDiff混合框架，创新性地结合了语言模型(LMs)和扩散模型(DMs)的优势，实现了文本到视频(T2V)生成的突破。通过三个关键技术：(1) 将3D视觉特征压缩为1D离散表示的语义分词器，(2) 生成高层次语义关系的语言模型，(3) 将粗粒度语义细化为高清视频的流式扩散模型，该框架在VBench基准测试中以5B参数量达到85.43分，超越包括Sora在内的现有商业模型。特别在长视频生成领域也实现了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04606v2",
      "published_date": "2025-03-06 16:53:14 UTC",
      "updated_date": "2025-03-08 14:29:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:29:16.941585"
    },
    {
      "arxiv_id": "2503.07649v1",
      "title": "TS-RAG: Retrieval-Augmented Generation based Time Series Foundation Models are Stronger Zero-Shot Forecaster",
      "title_zh": "TS-RAG：基于检索增强生成的时间序列基础模型在零样本预测中表现更强",
      "authors": [
        "Kanghui Ning",
        "Zijie Pan",
        "Yu Liu",
        "Yushan Jiang",
        "James Y. Zhang",
        "Kashif Rasul",
        "Anderson Schneider",
        "Lintao Ma",
        "Yuriy Nevmyvaka",
        "Dongjin Song"
      ],
      "abstract": "Recently, Large Language Models (LLMs) and Foundation Models (FMs) have\nbecome prevalent for time series forecasting tasks. However, fine-tuning large\nlanguage models (LLMs) for forecasting enables the adaptation to specific\ndomains but may not generalize well across diverse, unseen datasets. Meanwhile,\nexisting time series foundation models (TSFMs) lack inherent mechanisms for\ndomain adaptation and suffer from limited interpretability, making them\nsuboptimal for zero-shot forecasting. To this end, we present TS-RAG, a\nretrieval-augmented generation based time series forecasting framework that\nenhances the generalization capability and interpretability of TSFMs.\nSpecifically, TS-RAG leverages pre-trained time series encoders to retrieve\nsemantically relevant time series segments from a dedicated knowledge database,\nincorporating contextual patterns for the given time series query. Next, we\ndevelop a learnable Mixture-of-Experts (MoE)-based augmentation module, which\ndynamically fuses retrieved time series patterns with the TSFM's representation\nof the input query, improving forecasting accuracy without requiring\ntask-specific fine-tuning. Thorough empirical studies on seven public benchmark\ndatasets demonstrate that TS-RAG achieves state-of-the-art zero-shot\nforecasting performance, outperforming TSFMs by up to 6.51% across diverse\ndomains and showcasing desired interpretability.",
      "tldr_zh": "该研究提出了TS-RAG，一种基于检索增强生成(Retrieval-Augmented Generation)的时间序列基础模型(TSFMs)框架，旨在提升零样本预测的泛化能力和可解释性。TS-RAG通过预训练的时间序列编码器从专用知识库中检索语义相关的时间序列片段，并结合可学习的专家混合(Mixture-of-Experts)模块动态融合检索到的模式与模型表示，从而在不进行任务特定微调的情况下提高预测精度。实验表明，TS-RAG在七个公共基准数据集上实现了最先进的零样本预测性能，比现有TSFMs提升高达6.51%，并展现出良好的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07649v1",
      "published_date": "2025-03-06 16:48:48 UTC",
      "updated_date": "2025-03-06 16:48:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:30:09.671570"
    },
    {
      "arxiv_id": "2503.04598v2",
      "title": "HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid Normalization",
      "title_zh": "HybridNorm：通过混合归一化实现稳定高效的Transformer训练",
      "authors": [
        "Zhijian Zhuo",
        "Yutao Zeng",
        "Ya Wang",
        "Sijun Zhang",
        "Jian Yang",
        "Xiaoqing Li",
        "Xun Zhou",
        "Jinwen Ma"
      ],
      "abstract": "Transformers have become the de facto architecture for a wide range of\nmachine learning tasks, particularly in large language models (LLMs). Despite\ntheir remarkable performance, challenges remain in training deep transformer\nnetworks, especially regarding the location of layer normalization. While\nPre-Norm structures facilitate easier training due to their more prominent\nidentity path, they often yield suboptimal performance compared to Post-Norm.\nIn this paper, we propose $\\textbf{HybridNorm}$, a straightforward yet\neffective hybrid normalization strategy that integrates the advantages of both\nPre-Norm and Post-Norm approaches. Specifically, HybridNorm employs QKV\nnormalization within the attention mechanism and Post-Norm in the feed-forward\nnetwork (FFN) of each transformer block. This design not only stabilizes\ntraining but also enhances performance, particularly in the context of LLMs.\nComprehensive experiments in both dense and sparse architectures show that\nHybridNorm consistently outperforms both Pre-Norm and Post-Norm approaches,\nachieving state-of-the-art results across various benchmarks. These findings\nhighlight the potential of HybridNorm as a more stable and effective technique\nfor improving the training and performance of deep transformer models. Code is\navailable at https://github.com/BryceZhuo/HybridNorm.",
      "tldr_zh": "该研究提出了HybridNorm，一种结合Pre-Norm和Post-Norm优点的混合归一化策略，用于提升Transformer模型的训练稳定性和性能。具体来说，HybridNorm在注意力机制中使用QKV归一化，而在前馈网络(FFN)中采用Post-Norm。实验表明，该方法在密集和稀疏架构中均优于传统Pre-Norm和Post-Norm，并在多个基准测试中达到了最先进的结果。这一策略为深度Transformer模型的训练和性能提升提供了更稳定有效的技术。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04598v2",
      "published_date": "2025-03-06 16:40:48 UTC",
      "updated_date": "2025-03-24 15:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:29:50.469667"
    },
    {
      "arxiv_id": "2503.04596v1",
      "title": "The Next Frontier of LLM Applications: Open Ecosystems and Hardware Synergy",
      "title_zh": "LLM应用的新前沿：开放生态系统与硬件协同",
      "authors": [
        "Xinyi Hou",
        "Yanjie Zhao",
        "Haoyu Wang"
      ],
      "abstract": "Large Language Model (LLM) applications, including LLM app stores and\nautonomous agents, are shaping the future of AI ecosystems. However, platform\nsilos, fragmented hardware integration, and the absence of standardized\ninterfaces limit scalability, interoperability, and resource efficiency. While\nLLM app stores democratize AI, their closed ecosystems restrict modular AI\nreuse and cross-platform portability. Meanwhile, agent-based frameworks offer\nflexibility but often lack seamless integration across diverse environments.\nThis paper envisions the future of LLM applications and proposes a three-layer\ndecoupled architecture grounded in software engineering principles such as\nlayered system design, service-oriented architectures, and hardware-software\nco-design. This architecture separates application logic, communication\nprotocols, and hardware execution, enhancing modularity, efficiency, and\ncross-platform compatibility. Beyond architecture, we highlight key security\nand privacy challenges for safe, scalable AI deployment and outline research\ndirections in software and security engineering. This vision aims to foster\nopen, secure, and interoperable LLM ecosystems, guiding future advancements in\nAI applications.",
      "tldr_zh": "该论文探讨了大型语言模型（LLM）应用的未来发展方向，提出了一种三层解耦架构，以解决当前平台孤岛、硬件集成碎片化和标准化接口缺失等问题。该架构基于软件工程原则，包括分层系统设计、面向服务架构和软硬件协同设计，将应用逻辑、通信协议和硬件执行分离，从而提升模块化、效率和跨平台兼容性。此外，论文还强调了安全和隐私挑战，并提出了开放、安全、互操作的LLM生态系统愿景，为AI应用的未来发展提供了指导。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04596v1",
      "published_date": "2025-03-06 16:38:23 UTC",
      "updated_date": "2025-03-06 16:38:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:30:02.614939"
    },
    {
      "arxiv_id": "2503.04873v1",
      "title": "Are Large Language Models Good In-context Learners for Financial Sentiment Analysis?",
      "title_zh": "大语言模型在金融情感分析中是否具备良好的上下文学习能力？",
      "authors": [
        "Xinyu Wei",
        "Luojia Liu"
      ],
      "abstract": "Recently, large language models (LLMs) with hundreds of billions of\nparameters have demonstrated the emergent ability, surpassing traditional\nmethods in various domains even without fine-tuning over domain-specific data.\nHowever, when it comes to financial sentiment analysis (FSA)$\\unicode{x2013}$a\nfundamental task in financial AI$\\unicode{x2013}$these models often encounter\nvarious challenges, such as complex financial terminology, subjective human\nemotions, and ambiguous inclination expressions. In this paper, we aim to\nanswer the fundamental question: whether LLMs are good in-context learners for\nFSA? Unveiling this question can yield informative insights on whether LLMs can\nlearn to address the challenges by generalizing in-context demonstrations of\nfinancial document-sentiment pairs to the sentiment analysis of new documents,\ngiven that finetuning these models on finance-specific data is difficult, if\nnot impossible at all. To the best of our knowledge, this is the first paper\nexploring in-context learning for FSA that covers most modern LLMs (recently\nreleased DeepSeek V3 included) and multiple in-context sample selection\nmethods. Comprehensive experiments validate the in-context learning capability\nof LLMs for FSA.",
      "tldr_zh": "本研究探讨了大语言模型(LLMs)在金融情感分析(FSA)中的上下文学习能力，这是金融AI中的一项基础任务。尽管LLMs在无需领域数据微调的情况下已在多个领域展现出卓越性能，但面对复杂的金融术语、主观情感和模糊表达时仍面临挑战。论文首次全面评估了包括DeepSeek V3在内的多种现代LLMs在FSA中的上下文学习表现，并验证了其通过金融文档-情感对示例进行泛化的能力。实验结果表明，LLMs在FSA中具备有效的上下文学习能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-fin.CP"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICLR 2025 Workshop on Advances in Financial AI",
      "pdf_url": "http://arxiv.org/pdf/2503.04873v1",
      "published_date": "2025-03-06 16:38:12 UTC",
      "updated_date": "2025-03-06 16:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:30:11.832364"
    },
    {
      "arxiv_id": "2503.04872v2",
      "title": "TinyR1-32B-Preview: Boosting Accuracy with Branch-Merge Distillation",
      "title_zh": "TinyR1-32B-Preview：通过分支合并蒸馏提升精度",
      "authors": [
        "Lin Sun",
        "Guangxiang Zhao",
        "Xiaoqi Jian",
        "Yuhan Wu",
        "Weihong Lin",
        "Yongfu Zhu",
        "Change Jia",
        "Linglin Zhang",
        "Jinzhu Wu",
        "Junfeng Ran",
        "Sai-er Hu",
        "Zihan Jiang",
        "Junting Zhou",
        "Wenrui Liu",
        "Bin Cui",
        "Tong Yang",
        "Xiangzheng Zhang"
      ],
      "abstract": "The challenge of reducing the size of Large Language Models (LLMs) while\nmaintaining their performance has gained significant attention. However,\nexisting methods, such as model distillation and transfer learning, often fail\nto achieve high accuracy. To address this limitation, we introduce the\nBranch-Merge distillation approach, which enhances model compression through\ntwo phases: (1) the Branch Phase, where knowledge from a large teacher model is\n\\textit{selectively distilled} into specialized student models via\ndomain-specific supervised fine-tuning (SFT); And (2) the Merge Phase, where\nthese student models are merged to enable cross-domain knowledge transfer and\nimprove generalization. We validate our distillation approach using DeepSeek-R1\nas the teacher and DeepSeek-R1-Distill-Qwen-32B as the student. The resulting\nmerged model, TinyR1-32B-Preview, outperforms its counterpart\nDeepSeek-R1-Distill-Qwen-32B across multiple benchmarks, including Mathematics\n(+5.5 points), Coding (+4.4 points) and Science (+2.9 points), while achieving\nnear-equal performance to DeepSeek-R1 on AIME 2024. The Branch-Merge\ndistillation approach provides a scalable solution for creating smaller,\nhigh-performing LLMs with reduced computational cost and time.",
      "tldr_zh": "该研究提出了一种名为Branch-Merge的新型模型蒸馏方法，用于在压缩大型语言模型(LLMs)时保持性能。该方法分为两个阶段：Branch阶段通过领域特定监督微调(SFT)将大模型知识选择性地蒸馏到专门化的小模型；Merge阶段则合并这些小模型以实现跨领域知识迁移。实验以DeepSeek-R1为教师模型，生成的TinyR1-32B-Preview模型在数学(+5.5分)、编程(+4.4分)和科学(+2.9分)等多个基准测试中优于基线模型，同时在AIME 2024上接近原始大模型性能，为开发高性能小型LLM提供了可扩展方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.04872v2",
      "published_date": "2025-03-06 16:25:53 UTC",
      "updated_date": "2025-03-17 10:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:30:25.675255"
    },
    {
      "arxiv_id": "2503.04569v1",
      "title": "ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making",
      "title_zh": "ValuePilot：基于价值驱动的两阶段决策框架",
      "authors": [
        "Yitong Luo",
        "Hou Hei Lam",
        "Ziang Chen",
        "Zhenliang Zhang",
        "Xue Feng"
      ],
      "abstract": "Despite recent advances in artificial intelligence (AI), it poses challenges\nto ensure personalized decision-making in tasks that are not considered in\ntraining datasets. To address this issue, we propose ValuePilot, a two-phase\nvalue-driven decision-making framework comprising a dataset generation toolkit\nDGT and a decision-making module DMM trained on the generated data. DGT is\ncapable of generating scenarios based on value dimensions and closely mirroring\nreal-world tasks, with automated filtering techniques and human curation to\nensure the validity of the dataset. In the generated dataset, DMM learns to\nrecognize the inherent values of scenarios, computes action feasibility and\nnavigates the trade-offs between multiple value dimensions to make personalized\ndecisions. Extensive experiments demonstrate that, given human value\npreferences, our DMM most closely aligns with human decisions, outperforming\nClaude-3.5-Sonnet, Gemini-2-flash, Llama-3.1-405b and GPT-4o. This research is\na preliminary exploration of value-driven decision-making. We hope it will\nstimulate interest in value-driven decision-making and personalized\ndecision-making within the community.",
      "tldr_zh": "该研究提出了ValuePilot，一个两阶段的价值驱动决策框架，旨在解决AI在未考虑训练数据集任务中的个性化决策问题。框架包括数据集生成工具包DGT和决策模块DMM，DGT基于价值维度生成真实任务场景，并通过自动过滤和人工筛选确保数据有效性，DMM则学习识别场景内在价值，计算行动可行性并在多个价值维度间权衡以做出个性化决策。实验表明，在给定人类价值偏好时，DMM最接近人类决策，优于Claude-3.5-Sonnet、Gemini-2-flash、Llama-3.1-405b和GPT-4o。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04569v1",
      "published_date": "2025-03-06 16:02:53 UTC",
      "updated_date": "2025-03-06 16:02:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:30:23.290116"
    },
    {
      "arxiv_id": "2503.04564v2",
      "title": "Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User Association",
      "title_zh": "分层安全聚合的基本限制：循环用户关联下的性能极限",
      "authors": [
        "Xiang Zhang",
        "Zhou Li",
        "Kai Wan",
        "Hua Sun",
        "Mingyue Ji",
        "Giuseppe Caire"
      ],
      "abstract": "Secure aggregation is motivated by federated learning (FL) where a cloud\nserver aims to compute an averaged model (i.e., weights of deep neural\nnetworks) of the locally-trained models of numerous clients, while adhering to\ndata security requirements. Hierarchical secure aggregation (HSA) extends this\nconcept to a three-layer network, where clustered users communicate with the\nserver through an intermediate layer of relays. In HSA, beyond conventional\nserver security, relay security is also enforced to ensure that the relays\nremain oblivious to the users' inputs (an abstraction of the local models in\nFL). Existing study on HSA assumes that each user is associated with only one\nrelay, limiting opportunities for coding across inter-cluster users to achieve\nefficient communication and key generation. In this paper, we consider HSA with\na cyclic association pattern where each user is connected to $B$ consecutive\nrelays in a wrap-around manner. We propose an efficient aggregation scheme\nwhich includes a message design for the inputs inspired by gradient coding-a\nwell-known technique for efficient communication in distributed computing-along\nwith a highly nontrivial security key design. We also derive novel converse\nbounds on the minimum achievable communication and key rates using\ninformation-theoretic arguments.",
      "tldr_zh": "该论文探讨了分层安全聚合（HSA）在循环用户关联模式下的基本限制，提出了一种高效的聚合方案。通过将每个用户与$B$个连续的中继节点循环连接，研究团队设计了一种基于梯度编码的消息输入方案和复杂的安全密钥生成机制。此外，利用信息论方法，论文推导了最小通信和密钥率的新逆界，为联邦学习中的安全模型聚合提供了理论支持。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.CR",
        "cs.DC",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04564v2",
      "published_date": "2025-03-06 15:53:37 UTC",
      "updated_date": "2025-03-07 10:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:30:34.577353"
    },
    {
      "arxiv_id": "2503.04556v2",
      "title": "Compositional Causal Reasoning Evaluation in Language Models",
      "title_zh": "语言模型中的组合因果推理评估",
      "authors": [
        "Jacqueline R. M. A. Maasch",
        "Alihan Hüyük",
        "Xinnuo Xu",
        "Aditya V. Nori",
        "Javier Gonzalez"
      ],
      "abstract": "Causal reasoning and compositional reasoning are two core aspirations in\ngenerative AI. Measuring the extent of these behaviors requires principled\nevaluation methods. We explore a unified perspective that considers both\nbehaviors simultaneously, termed compositional causal reasoning (CCR): the\nability to infer how causal measures compose and, equivalently, how causal\nquantities propagate through graphs. We instantiate a framework for the\nsystematic evaluation of CCR for the average treatment effect and the\nprobability of necessity and sufficiency. As proof of concept, we demonstrate\nthe design of CCR tasks for language models in the LLama, Phi, and GPT\nfamilies. On a math word problem, our framework revealed a range of\ntaxonomically distinct error patterns. Additionally, CCR errors increased with\nthe complexity of causal paths for all models except o1.",
      "tldr_zh": "该研究提出了组合因果推理(CCR)评估框架，用于系统评估语言模型在因果推理和组合推理方面的能力。研究者设计了CCR任务，对LLama、Phi和GPT等系列语言模型进行了测试，发现随着因果路径复杂度的增加，所有模型（除o1外）的CCR错误率均有所上升。研究还揭示了不同模型在数学应用题上表现出的各种错误模式，为衡量生成式AI在因果推理方面的进展提供了系统化评估方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04556v2",
      "published_date": "2025-03-06 15:47:19 UTC",
      "updated_date": "2025-03-16 16:22:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:30:39.792530"
    },
    {
      "arxiv_id": "2503.04550v1",
      "title": "Benchmarking Reasoning Robustness in Large Language Models",
      "title_zh": "大型语言模型推理鲁棒性基准测试",
      "authors": [
        "Tong Yu",
        "Yongcheng Jing",
        "Xikun Zhang",
        "Wentao Jiang",
        "Wenjie Wu",
        "Yingjie Wang",
        "Wenbin Hu",
        "Bo Du",
        "Dacheng Tao"
      ],
      "abstract": "Despite the recent success of large language models (LLMs) in reasoning such\nas DeepSeek, we for the first time identify a key dilemma in reasoning\nrobustness and generalization: significant performance degradation on novel or\nincomplete data, suggesting a reliance on memorized patterns rather than\nsystematic reasoning. Our closer examination reveals four key unique\nlimitations underlying this issue:(1) Positional bias--models favor earlier\nqueries in multi-query inputs but answering the wrong one in the latter (e.g.,\nGPT-4o's accuracy drops from 75.8 percent to 72.8 percent); (2) Instruction\nsensitivity--performance declines by 5.0 to 7.5 percent in the Qwen2.5 Series\nand by 5.0 percent in DeepSeek-V3 with auxiliary guidance; (3) Numerical\nfragility--value substitution sharply reduces accuracy (e.g., GPT-4o drops from\n97.5 percent to 82.5 percent, GPT-o1-mini drops from 97.5 percent to 92.5\npercent); and (4) Memory dependence--models resort to guesswork when missing\ncritical data. These findings further highlight the reliance on heuristic\nrecall over rigorous logical inference, demonstrating challenges in reasoning\nrobustness. To comprehensively investigate these robustness challenges, this\npaper introduces a novel benchmark, termed as Math-RoB, that exploits\nhallucinations triggered by missing information to expose reasoning gaps. This\nis achieved by an instruction-based approach to generate diverse datasets that\nclosely resemble training distributions, facilitating a holistic robustness\nassessment and advancing the development of more robust reasoning frameworks.\nBad character(s) in field Abstract.",
      "tldr_zh": "该研究首次揭示了大语言模型（LLMs）在推理鲁棒性和泛化能力上的关键问题：面对新数据或不完整数据时性能显著下降，表明模型依赖记忆模式而非系统性推理。通过深入分析，研究提出了四个核心局限性：（1）位置偏差，（2）指令敏感性，（3）数值脆弱性，（4）记忆依赖性。为系统性评估这些问题，研究提出了新基准Math-RoB，利用缺失信息触发的幻觉暴露推理缺陷，并通过指令生成多样化数据集，推动更鲁棒的推理框架发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04550v1",
      "published_date": "2025-03-06 15:36:06 UTC",
      "updated_date": "2025-03-06 15:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:31:10.129913"
    },
    {
      "arxiv_id": "2503.04543v1",
      "title": "Keeping Yourself is Important in Downstream Tuning Multimodal Large Language Model",
      "title_zh": "在下游任务微调多模态大语言模型时保持自身特性至关重要",
      "authors": [
        "Wenke Huang",
        "Jian Liang",
        "Xianda Guo",
        "Yiyang Fang",
        "Guancheng Wan",
        "Xuankun Rong",
        "Chi Wen",
        "Zekun Shi",
        "Qingyun Li",
        "Didi Zhu",
        "Yanbiao Ma",
        "Ke Liang",
        "Bin Yang",
        "He Li",
        "Jiawei Shao",
        "Mang Ye",
        "Bo Du"
      ],
      "abstract": "Multi-modal Large Language Models (MLLMs) integrate visual and linguistic\nreasoning to address complex tasks such as image captioning and visual question\nanswering. While MLLMs demonstrate remarkable versatility, MLLMs appears\nlimited performance on special applications. But tuning MLLMs for downstream\ntasks encounters two key challenges: Task-Expert Specialization, where\ndistribution shifts between pre-training and target datasets constrain target\nperformance, and Open-World Stabilization, where catastrophic forgetting erases\nthe model general knowledge. In this work, we systematically review recent\nadvancements in MLLM tuning methodologies, classifying them into three\nparadigms: (I) Selective Tuning, (II) Additive Tuning, and (III)\nReparameterization Tuning. Furthermore, we benchmark these tuning strategies\nacross popular MLLM architectures and diverse downstream tasks to establish\nstandardized evaluation analysis and systematic tuning principles. Finally, we\nhighlight several open challenges in this domain and propose future research\ndirections. To facilitate ongoing progress in this rapidly evolving field, we\nprovide a public repository that continuously tracks developments:\nhttps://github.com/WenkeHuang/Awesome-MLLM-Tuning.",
      "tldr_zh": "该研究探讨了多模态大语言模型(MLLM)在下游任务微调中的核心挑战，包括任务专家化导致的分布偏移问题以及开放世界稳定性不足引发的灾难性遗忘现象。论文系统梳理了当前MLLM微调方法的三大范式：选择性调优(Selective Tuning)、附加调优(Additive Tuning)和重参数化调优(Reparameterization Tuning)，并通过基准测试建立了标准化评估体系。研究团队还开源了持续更新的MLLM调优资源库，为推动该领域发展提供了重要基础设施。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04543v1",
      "published_date": "2025-03-06 15:29:13 UTC",
      "updated_date": "2025-03-06 15:29:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:30:56.946973"
    },
    {
      "arxiv_id": "2503.04530v1",
      "title": "SOLAR: Scalable Optimization of Large-scale Architecture for Reasoning",
      "title_zh": "SOLAR：面向推理的大规模架构可扩展优化",
      "authors": [
        "Chen Li",
        "Yinyi Luo",
        "Anudeep Bolimera",
        "Marios Savvides"
      ],
      "abstract": "Large Language Models (LLMs) excel in reasoning but remain constrained by\ntheir Chain-of-Thought (CoT) approach, which struggles with complex tasks\nrequiring more nuanced topological reasoning. We introduce SOLAR, Scalable\nOptimization of Large-scale Architecture for Reasoning, a framework that\ndynamically optimizes various reasoning topologies to enhance accuracy and\nefficiency.\n  Our Topological Annotation Generation (TAG) system automates topological\ndataset creation and segmentation, improving post-training and evaluation.\nAdditionally, we propose Topological-Scaling, a reward-driven framework that\naligns training and inference scaling, equipping LLMs with adaptive, task-aware\nreasoning.\n  SOLAR achieves substantial gains on MATH and GSM8K: +5% accuracy with\nTopological Tuning, +9% with Topological Reward, and +10.02% with Hybrid\nScaling. It also reduces response length by over 5% for complex problems,\nlowering inference latency.\n  To foster the reward system, we train a multi-task Topological Reward Model\n(M-TRM), which autonomously selects the best reasoning topology and answer in a\nsingle pass, eliminating the need for training and inference on multiple\nsingle-task TRMs (S-TRMs), thus reducing both training cost and inference\nlatency. In addition, in terms of performance, M-TRM surpasses all S-TRMs,\nimproving accuracy by +10% and rank correlation by +9%.\n  To the best of our knowledge, SOLAR sets a new benchmark for scalable,\nhigh-precision LLM reasoning while introducing an automated annotation process\nand a dynamic reasoning topology competition mechanism.",
      "tldr_zh": "该研究提出了SOLAR（Scalable Optimization of Large-scale Architecture for Reasoning），一种可扩展的优化框架，旨在提升大语言模型（LLMs）在复杂推理任务中的表现。SOLAR通过动态优化推理拓扑结构，结合拓扑标注生成（TAG）系统和拓扑缩放（Topological-Scaling）机制，显著提高了模型在MATH和GSM8K等数据集上的准确性，同时减少了推理延迟。此外，研究还训练了一个多任务拓扑奖励模型（M-TRM），能够自主选择最佳推理拓扑和答案，进一步降低了训练和推理成本。SOLAR为高精度、可扩展的LLM推理设定了新基准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04530v1",
      "published_date": "2025-03-06 15:19:17 UTC",
      "updated_date": "2025-03-06 15:19:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:31:26.987137"
    },
    {
      "arxiv_id": "2503.04869v1",
      "title": "Label Distribution Learning-Enhanced Dual-KNN for Text Classification",
      "title_zh": "标签分布学习增强的双KNN文本分类方法",
      "authors": [
        "Bo Yuan",
        "Yulin Chen",
        "Zhen Tan",
        "Wang Jinyan",
        "Huan Liu",
        "Yin Zhang"
      ],
      "abstract": "Many text classification methods usually introduce external information\n(e.g., label descriptions and knowledge bases) to improve the classification\nperformance. Compared to external information, some internal information\ngenerated by the model itself during training, like text embeddings and\npredicted label probability distributions, are exploited poorly when predicting\nthe outcomes of some texts. In this paper, we focus on leveraging this internal\ninformation, proposing a dual $k$ nearest neighbor (D$k$NN) framework with two\n$k$NN modules, to retrieve several neighbors from the training set and augment\nthe distribution of labels. For the $k$NN module, it is easily confused and may\ncause incorrect predictions when retrieving some nearest neighbors from noisy\ndatasets (datasets with labeling errors) or similar datasets (datasets with\nsimilar labels). To address this issue, we also introduce a label distribution\nlearning module that can learn label similarity, and generate a better label\ndistribution to help models distinguish texts more effectively. This module\neases model overfitting and improves final classification performance, hence\nenhancing the quality of the retrieved neighbors by $k$NN modules during\ninference. Extensive experiments on the benchmark datasets verify the\neffectiveness of our method.",
      "tldr_zh": "本文提出了一种基于标签分布学习的双K近邻(D$k$NN)框架，用于增强文本分类性能。该方法通过两个K近邻模块从训练集中检索邻居并增强标签分布，同时引入标签分布学习模块来学习标签相似性，生成更优的标签分布以区分文本。实验表明，该方法有效缓解了模型过拟合问题，并显著提升了分类性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by SDM 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.04869v1",
      "published_date": "2025-03-06 15:15:26 UTC",
      "updated_date": "2025-03-06 15:15:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:31:30.422267"
    },
    {
      "arxiv_id": "2503.04521v1",
      "title": "Dynamic Pricing for On-Demand DNN Inference in the Edge-AI Market",
      "title_zh": "边缘AI市场中按需DNN推理的动态定价",
      "authors": [
        "Songyuan Li",
        "Jia Hu",
        "Geyong Min",
        "Haojun Huang",
        "Jiwei Huang"
      ],
      "abstract": "The convergence of edge computing and AI gives rise to Edge-AI, which enables\nthe deployment of real-time AI applications and services at the network edge.\nOne of the fundamental research issues in Edge-AI is edge inference\nacceleration, which aims to realize low-latency high-accuracy DNN inference\nservices by leveraging the fine-grained offloading of partitioned inference\ntasks from end devices to edge servers. However, existing research has yet to\nadopt a practical Edge-AI market perspective, which would systematically\nexplore the personalized inference needs of AI users (e.g., inference accuracy,\nlatency, and task complexity), the revenue incentives for AI service providers\nthat offer edge inference services, and multi-stakeholder governance within a\nmarket-oriented context. To bridge this gap, we propose an Auction-based Edge\nInference Pricing Mechanism (AERIA) for revenue maximization to tackle the\nmulti-dimensional optimization problem of DNN model partition, edge inference\npricing, and resource allocation. We investigate the multi-exit device-edge\nsynergistic inference scheme for on-demand DNN inference acceleration, and\nanalyse the auction dynamics amongst the AI service providers, AI users and\nedge infrastructure provider. Owing to the strategic mechanism design via\nrandomized consensus estimate and cost sharing techniques, the Edge-AI market\nattains several desirable properties, including competitiveness in revenue\nmaximization, incentive compatibility, and envy-freeness, which are crucial to\nmaintain the effectiveness, truthfulness, and fairness of our auction outcomes.\nThe extensive simulation experiments based on four representative DNN inference\nworkloads demonstrate that our AERIA mechanism significantly outperforms\nseveral state-of-the-art approaches in revenue maximization, demonstrating the\nefficacy of AERIA for on-demand DNN inference in the Edge-AI market.",
      "tldr_zh": "该研究提出了一种基于拍卖的边缘AI推理定价机制（AERIA），旨在解决Edge-AI市场中DNN推理服务的多维优化问题，包括模型分割、定价和资源分配。通过设计多出口设备-边缘协同推理方案，并结合随机共识估计和成本分摊技术，AERIA机制在最大化收入、激励兼容性和无嫉妒性方面表现出色，确保了拍卖结果的有效性、真实性和公平性。实验结果表明，AERIA在四种典型DNN推理任务中显著优于现有方法，为Edge-AI市场的按需DNN推理服务提供了高效解决方案。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.DC",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Index Terms: Edge-AI, DNN Inference Offloading, Resource Management,\n  Dynamic Pricing, Auction Mechanism",
      "pdf_url": "http://arxiv.org/pdf/2503.04521v1",
      "published_date": "2025-03-06 15:08:31 UTC",
      "updated_date": "2025-03-06 15:08:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:33:01.633817"
    },
    {
      "arxiv_id": "2503.04509v1",
      "title": "STX-Search: Explanation Search for Continuous Dynamic Spatio-Temporal Models",
      "title_zh": "STX-Search：连续动态时空模型的解释搜索方法",
      "authors": [
        "Saif Anwar",
        "Nathan Griffiths",
        "Thomas Popham",
        "Abhir Bhalerao"
      ],
      "abstract": "Recent improvements in the expressive power of spatio-temporal models have\nled to performance gains in many real-world applications, such as traffic\nforecasting and social network modelling. However, understanding the\npredictions from a model is crucial to ensure reliability and trustworthiness,\nparticularly for high-risk applications, such as healthcare and transport. Few\nexisting methods are able to generate explanations for models trained on\ncontinuous-time dynamic graph data and, of these, the computational complexity\nand lack of suitable explanation objectives pose challenges. In this paper, we\npropose $\\textbf{S}$patio-$\\textbf{T}$emporal E$\\textbf{X}$planation\n$\\textbf{Search}$ (STX-Search), a novel method for generating instance-level\nexplanations that is applicable to static and dynamic temporal graph\nstructures. We introduce a novel search strategy and objective function, to\nfind explanations that are highly faithful and interpretable. When compared\nwith existing methods, STX-Search produces explanations of higher fidelity\nwhilst optimising explanation size to maintain interpretability.",
      "tldr_zh": "该研究提出STX-Search方法，用于生成连续动态时空模型的解释性结果，适用于静态和动态时间图结构。该方法通过创新的搜索策略和目标函数，寻找高保真且可解释的模型预测解释。相比现有方法，STX-Search在保持解释简洁性的同时，能生成更高保真度的解释结果，特别适用于交通预测等高风险应用场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04509v1",
      "published_date": "2025-03-06 14:55:25 UTC",
      "updated_date": "2025-03-06 14:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:32:04.697923"
    },
    {
      "arxiv_id": "2503.04506v1",
      "title": "Multi-modal Summarization in Model-Based Engineering: Automotive Software Development Case Study",
      "title_zh": "基于模型的工程中的多模态摘要：汽车软件开发案例研究",
      "authors": [
        "Nenad Petrovic",
        "Yurui Zhang",
        "Moaad Maaroufi",
        "Kuo-Yi Chao",
        "Lukasz Mazur",
        "Fengjunjie Pan",
        "Vahid Zolfaghari",
        "Alois Knoll"
      ],
      "abstract": "Multimodal summarization integrating information from diverse data modalities\npresents a promising solution to aid the understanding of information within\nvarious processes. However, the application and advantages of multimodal\nsummarization have not received much attention in model-based engineering\n(MBE), where it has become a cornerstone in the design and development of\ncomplex systems, leveraging formal models to improve understanding, validation\nand automation throughout the engineering lifecycle. UML and EMF diagrams in\nmodel-based engineering contain a large amount of multimodal information and\nintricate relational data. Hence, our study explores the application of\nmultimodal large language models within the domain of model-based engineering\nto evaluate their capacity for understanding and identifying relationships,\nfeatures, and functionalities embedded in UML and EMF diagrams. We aim to\ndemonstrate the transformative potential benefits and limitations of multimodal\nsummarization in improving productivity and accuracy in MBE practices. The\nproposed approach is evaluated within the context of automotive software\ndevelopment, while many promising state-of-art models were taken into account.",
      "tldr_zh": "本研究探讨了多模态摘要技术在基于模型的工程(MBE)中的应用，特别是在汽车软件开发领域。研究聚焦于如何利用多模态大语言模型处理UML和EMF图表中复杂的多模态信息和关系数据，以提升工程实践中的生产力和准确性。通过整合多种最先进模型，该研究评估了多模态摘要技术在理解图表特征、功能和关系方面的潜力，揭示了其在优化MBE生命周期中的变革性优势与局限。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Conference paper accepted for IntelliSys2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04506v1",
      "published_date": "2025-03-06 14:53:37 UTC",
      "updated_date": "2025-03-06 14:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:31:55.171085"
    },
    {
      "arxiv_id": "2503.04502v1",
      "title": "Interpretable Transformation and Analysis of Timelines through Learning via Surprisability",
      "title_zh": "《基于可惊奇性学习的可解释时间线转换与分析》",
      "authors": [
        "Osnat Mokryn",
        "Teddy Lazebnik",
        "Hagit Ben Shoshan"
      ],
      "abstract": "The analysis of high-dimensional timeline data and the identification of\noutliers and anomalies is critical across diverse domains, including sensor\nreadings, biological and medical data, historical records, and global\nstatistics. However, conventional analysis techniques often struggle with\nchallenges such as high dimensionality, complex distributions, and sparsity.\nThese limitations hinder the ability to extract meaningful insights from\ncomplex temporal datasets, making it difficult to identify trending features,\noutliers, and anomalies effectively. Inspired by surprisability -- a cognitive\nscience concept describing how humans instinctively focus on unexpected\ndeviations - we propose Learning via Surprisability (LvS), a novel approach for\ntransforming high-dimensional timeline data. LvS quantifies and prioritizes\nanomalies in time-series data by formalizing deviations from expected behavior.\nLvS bridges cognitive theories of attention with computational methods,\nenabling the detection of anomalies and shifts in a way that preserves critical\ncontext, offering a new lens for interpreting complex datasets. We demonstrate\nthe usefulness of LvS on three high-dimensional timeline use cases: a time\nseries of sensor data, a global dataset of mortality causes over multiple\nyears, and a textual corpus containing over two centuries of State of the Union\nAddresses by U.S. presidents. Our results show that the LvS transformation\nenables efficient and interpretable identification of outliers, anomalies, and\nthe most variable features along the timeline.",
      "tldr_zh": "该研究提出了一种基于“意外性”(surprisability)认知理论的高维时间线数据转换方法——Learning via Surprisability (LvS)。LvS通过量化时间序列数据中的异常行为，将认知注意力机制与计算方法结合，能够高效识别异常值和关键特征变化，同时保留上下文信息。研究在传感器数据、全球死亡率数据集和长达两个世纪的美国总统国情咨文文本语料上验证了LvS的有效性，表明其能够提供高效且可解释的异常检测和趋势分析。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04502v1",
      "published_date": "2025-03-06 14:50:29 UTC",
      "updated_date": "2025-03-06 14:50:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:32:12.646863"
    },
    {
      "arxiv_id": "2503.04500v2",
      "title": "ReynoldsFlow: Exquisite Flow Estimation via Reynolds Transport Theorem",
      "title_zh": "ReynoldsFlow：基于雷诺传输定理的精细流场估计算法",
      "authors": [
        "Yu-Hsi Chen",
        "Chin-Tien Wu"
      ],
      "abstract": "Optical flow is a fundamental technique for motion estimation, widely applied\nin video stabilization, interpolation, and object tracking. Traditional optical\nflow estimation methods rely on restrictive assumptions like brightness\nconstancy and slow motion constraints. Recent deep learning-based flow\nestimations require extensive training on large domain-specific datasets,\nmaking them computationally demanding. Also, artificial intelligence (AI)\nadvances have enabled deep learning models to take advantage of optical flow as\nan important feature for object tracking and motion analysis. Since optical\nflow is commonly encoded in HSV for visualization, its conversion to RGB for\nneural network processing is nonlinear and may introduce perceptual\ndistortions. These transformations amplify the sensitivity to estimation\nerrors, potentially affecting the predictive accuracy of the networks. To\naddress these challenges that are influential to the performance of downstream\nnetwork models, we propose Reynolds flow, a novel training-free flow estimation\ninspired by the Reynolds transport theorem, offering a principled approach to\nmodeling complex motion dynamics. In addition to conventional HSV-based\nvisualization of Reynolds flow, we also introduce an RGB-encoded representation\nof Reynolds flow designed to improve flow visualization and feature enhancement\nfor neural networks. We evaluated the effectiveness of Reynolds flow in\nvideo-based tasks. Experimental results on three benchmarks, tiny object\ndetection on UAVDB, infrared object detection on Anti-UAV, and pose estimation\non GolfDB, demonstrate that networks trained with RGB-encoded Reynolds flow\nachieve SOTA performance, exhibiting improved robustness and efficiency across\nall tasks.",
      "tldr_zh": "该研究提出ReynoldsFlow，一种基于雷诺传输定理(Reynolds Transport Theorem)的新型无训练光流估计方法，突破了传统方法对亮度恒定和慢运动假设的限制。通过创新的RGB编码表示法，该方法解决了HSV到RGB转换导致的神经网络特征失真问题。在无人机微小目标检测(UAVDB)、红外目标追踪(Anti-UAV)和高尔夫姿态估计(GolfDB)三个基准测试中，采用RGB编码ReynoldsFlow的神经网络均实现了最先进(SOTA)性能，显著提升了鲁棒性和计算效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04500v2",
      "published_date": "2025-03-06 14:49:28 UTC",
      "updated_date": "2025-03-09 17:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:32:33.952926"
    },
    {
      "arxiv_id": "2503.15538v1",
      "title": "There must be encapsulated nonconceptual content in vision",
      "title_zh": "视觉中必然存在封装化的非概念性内容",
      "authors": [
        "Vincent C. Müller"
      ],
      "abstract": "In this paper I want to propose an argument to support Jerry Fodor's thesis\n(Fodor 1983) that input systems are modular and thus informationally\nencapsulated. The argument starts with the suggestion that there is a\n\"grounding problem\" in perception, i. e. that there is a problem in explaining\nhow perception that can yield a visual experience is possible, how sensation\ncan become meaningful perception of something for the subject. Given that\nvisual experience is actually possible, this invites a transcendental argument\nthat explains the conditions of its possibility. I propose that one of these\nconditions is the existence of a visual module in Fodor's sense that allows the\nstep from sensation to object-identifying perception, thus enabling visual\nexperience. It seems to follow that there is informationally encapsulated\nnonconceptual content in visual perception.",
      "tldr_zh": "本文通过提出“感知基础问题”，支持Jerry Fodor的模块化理论，认为视觉系统是信息封装的模块。作者认为，视觉体验之所以可能，是因为存在一个视觉模块，它能够将感觉转化为对象识别的感知，从而生成视觉体验。这一论点表明，视觉感知中存在信息封装的非概念内容。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15538v1",
      "published_date": "2025-03-06 14:44:55 UTC",
      "updated_date": "2025-03-06 14:44:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:32:16.812217"
    },
    {
      "arxiv_id": "2503.04482v1",
      "title": "Generalized Interpolating Discrete Diffusion",
      "title_zh": "广义插值离散扩散方法",
      "authors": [
        "Dimitri von Rütte",
        "Janis Fluri",
        "Yuhui Ding",
        "Antonio Orvieto",
        "Bernhard Schölkopf",
        "Thomas Hofmann"
      ],
      "abstract": "While state-of-the-art language models achieve impressive results through\nnext-token prediction, they have inherent limitations such as the inability to\nrevise already generated tokens. This has prompted exploration of alternative\napproaches such as discrete diffusion. However, masked diffusion, which has\nemerged as a popular choice due to its simplicity and effectiveness,\nreintroduces this inability to revise words. To overcome this, we generalize\nmasked diffusion and derive the theoretical backbone of a family of general\ninterpolating discrete diffusion (GIDD) processes offering greater flexibility\nin the design of the noising processes. Leveraging a novel diffusion ELBO, we\nachieve compute-matched state-of-the-art performance in diffusion language\nmodeling. Exploiting GIDD's flexibility, we explore a hybrid approach combining\nmasking and uniform noise, leading to improved sample quality and unlocking the\nability for the model to correct its own mistakes, an area where autoregressive\nmodels notoriously have struggled. Our code and models are open-source:\nhttps://github.com/dvruette/gidd/",
      "tldr_zh": "该研究提出了广义插值离散扩散(GIDD)方法，通过理论推导构建了一个灵活的离散扩散框架，克服了现有掩码扩散模型无法修正已生成内容的缺陷。研究者开发了新型扩散ELBO目标函数，在计算效率匹配条件下实现了扩散语言建模的SOTA性能。实验表明，结合掩码和均匀噪声的混合策略不仅提升了生成质量，还赋予模型自我纠错能力——这是自回归模型长期存在的痛点。所有代码和模型均已开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04482v1",
      "published_date": "2025-03-06 14:30:55 UTC",
      "updated_date": "2025-03-06 14:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:32:38.072730"
    },
    {
      "arxiv_id": "2503.04479v3",
      "title": "ToolFuzz -- Automated Agent Tool Testing",
      "title_zh": "ToolFuzz——自动化智能体工具测试",
      "authors": [
        "Ivan Milev",
        "Mislav Balunović",
        "Maximilian Baader",
        "Martin Vechev"
      ],
      "abstract": "Large Language Model (LLM) Agents leverage the advanced reasoning\ncapabilities of LLMs in real-world applications. To interface with an\nenvironment, these agents often rely on tools, such as web search or database\nAPIs. As the agent provides the LLM with tool documentation along the user\nquery, the completeness and correctness of this documentation is critical.\nHowever, tool documentation is often over-, under-, or ill-specified, impeding\nthe agent's accuracy. Standard software testing approaches struggle to identify\nthese errors as they are expressed in natural language. Thus, despite its\nimportance, there currently exists no automated method to test the tool\ndocumentation for agents. To address this issue, we present ToolFuzz, the first\nmethod for automated testing of tool documentations. ToolFuzz is designed to\ndiscover two types of errors: (1) user queries leading to tool runtime errors\nand (2) user queries that lead to incorrect agent responses. ToolFuzz can\ngenerate a large and diverse set of natural inputs, effectively finding tool\ndescription errors at a low false positive rate. Further, we present two\nstraightforward prompt-engineering approaches. We evaluate all three tool\ntesting approaches on 32 common LangChain tools and 35 newly created custom\ntools and 2 novel benchmarks to further strengthen the assessment. We find that\nmany publicly available tools suffer from underspecification. Specifically, we\nshow that ToolFuzz identifies 20x more erroneous inputs compared to the\nprompt-engineering approaches, making it a key component for building reliable\nAI agents.",
      "tldr_zh": "该研究提出了ToolFuzz，首个用于自动化测试LLM（大语言模型）智能体工具文档的方法。ToolFuzz旨在发现两类错误：导致工具运行时错误的用户查询和导致智能体错误响应的用户查询。该方法能够生成大量多样化的自然语言输入，以低误报率有效识别工具描述中的错误。研究还提出了两种简单的提示工程方法，并在32个常见LangChain工具和35个自定义工具上进行评估。实验表明，许多公开可用的工具存在描述不足的问题，ToolFuzz发现的错误输入数量是提示工程方法的20倍，为构建可靠的AI智能体提供了关键支持。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04479v3",
      "published_date": "2025-03-06 14:29:52 UTC",
      "updated_date": "2025-03-11 14:28:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:32:42.241560"
    },
    {
      "arxiv_id": "2503.04472v1",
      "title": "DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models",
      "title_zh": "DAST：面向大型推理模型的难度自适应慢思考方法",
      "authors": [
        "Yi Shen",
        "Jian Zhang",
        "Jieyun Huang",
        "Shuming Shi",
        "Wenjing Zhang",
        "Jiangze Yan",
        "Ning Wang",
        "Kai Wang",
        "Shiguo Lian"
      ],
      "abstract": "Recent advancements in slow-thinking reasoning models have shown exceptional\nperformance in complex reasoning tasks. However, these models often exhibit\noverthinking-generating redundant reasoning steps for simple problems, leading\nto excessive computational resource usage. While current mitigation strategies\nuniformly reduce reasoning tokens, they risk degrading performance on\nchallenging tasks that require extended reasoning. This paper introduces\nDifficulty-Adaptive Slow-Thinking (DAST), a novel framework that enables models\nto autonomously adjust the length of Chain-of-Thought(CoT) based on problem\ndifficulty. We first propose a Token Length Budget (TLB) metric to quantify\ndifficulty, then leveraging length-aware reward shaping and length preference\noptimization to implement DAST. DAST penalizes overlong responses for simple\ntasks while incentivizing sufficient reasoning for complex problems.\nExperiments on diverse datasets and model scales demonstrate that DAST\neffectively mitigates overthinking (reducing token usage by over 30\\% on\naverage) while preserving reasoning accuracy on complex problems.",
      "tldr_zh": "本文提出了一种难度自适应的慢速思维框架（DAST），旨在解决大型推理模型在简单问题上过度推理（overthinking）导致计算资源浪费的问题。DAST通过引入Token Length Budget（TLB）指标量化问题难度，并结合长度感知的奖励机制和长度偏好优化，使模型能够根据问题复杂度动态调整链式思维（Chain-of-Thought, CoT）的长度。实验表明，DAST在多种数据集和模型规模上显著减少了推理过程中的token使用量（平均降低30%以上），同时保持了复杂问题上的推理准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "working in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.04472v1",
      "published_date": "2025-03-06 14:23:06 UTC",
      "updated_date": "2025-03-06 14:23:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:33:17.004226"
    },
    {
      "arxiv_id": "2503.04457v1",
      "title": "TPC: Cross-Temporal Prediction Connection for Vision-Language Model Hallucination Reduction",
      "title_zh": "TPC：跨时间预测连接以减少视觉语言模型幻觉",
      "authors": [
        "Chao Wang",
        "Weiwei Fu",
        "Yang Zhou"
      ],
      "abstract": "Vision-language models (VLMs) have achieved remarkable advancements,\ncapitalizing on the impressive capabilities of large language models (LLMs)\nacross diverse tasks. Despite this, a critical challenge known as hallucination\noccurs when models overconfidently describe objects or attributes absent from\nthe image, a problem exacerbated by the tendency of VLMs to rely on linguistic\npriors. This limitation reduces model reliability in high-stakes applications.\nIn this work, we have observed the characteristic of logits' continuity\nconsistency enhancement and introduced a straightforward and efficient method,\nCross-Temporal Prediction Connection (TPC), designed to enhance the semantic\nconsistency of logits by connecting them temporally across timesteps. TPC\namplifies information flow and improves coherence, effectively reducing\nhallucination. Extensive experiments show that TPC surpasses existing\nrepresentatives, delivering superior performance in both accuracy and\nefficiency while maintaining robustness in open-ended text generation tasks.",
      "tldr_zh": "该研究提出了一种名为跨时间预测连接(TPC)的新方法，旨在减少视觉语言模型(VLMs)中的幻觉问题。TPC通过增强logits在时间步上的连续性一致性，提升语义连贯性，从而有效减少模型对图像中不存在对象的错误描述。实验表明，TPC在准确性和效率上均优于现有方法，并在开放域文本生成任务中保持了鲁棒性，为高可靠性应用提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04457v1",
      "published_date": "2025-03-06 14:11:00 UTC",
      "updated_date": "2025-03-06 14:11:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:33:30.097816"
    },
    {
      "arxiv_id": "2503.04451v1",
      "title": "Privacy Preserving and Robust Aggregation for Cross-Silo Federated Learning in Non-IID Settings",
      "title_zh": "非独立同分布环境下面向跨机构联邦学习的隐私保护与鲁棒聚合",
      "authors": [
        "Marco Arazzi",
        "Mert Cihangiroglu",
        "Antonino Nocera"
      ],
      "abstract": "Federated Averaging remains the most widely used aggregation strategy in\nfederated learning due to its simplicity and scalability. However, its\nperformance degrades significantly in non-IID data settings, where client\ndistributions are highly imbalanced or skewed. Additionally, it relies on\nclients transmitting metadata, specifically the number of training samples,\nwhich introduces privacy risks and may conflict with regulatory frameworks like\nthe European GDPR. In this paper, we propose a novel aggregation strategy that\naddresses these challenges by introducing class-aware gradient masking. Unlike\ntraditional approaches, our method relies solely on gradient updates,\neliminating the need for any additional client metadata, thereby enhancing\nprivacy protection. Furthermore, our approach validates and dynamically weights\nclient contributions based on class-specific importance, ensuring robustness\nagainst non-IID distributions, convergence prevention, and backdoor attacks.\nExtensive experiments on benchmark datasets demonstrate that our method not\nonly outperforms FedAvg and other widely accepted aggregation strategies in\nnon-IID settings but also preserves model integrity in adversarial scenarios.\nOur results establish the effectiveness of gradient masking as a practical and\nsecure solution for federated learning.",
      "tldr_zh": "本文提出了一种新的联邦学习聚合策略，通过引入类感知梯度掩码（class-aware gradient masking）解决了非独立同分布（non-IID）数据设置下的性能下降问题。与传统方法不同，该方法仅依赖梯度更新，无需传输额外的客户端元数据，从而增强了隐私保护。此外，该方法根据类特定重要性动态验证和加权客户端贡献，确保了在非IID分布、收敛问题和后门攻击下的鲁棒性。实验表明，该方法在非IID设置下优于FedAvg及其他广泛接受的聚合策略，并在对抗场景中保持了模型完整性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04451v1",
      "published_date": "2025-03-06 14:06:20 UTC",
      "updated_date": "2025-03-06 14:06:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:33:46.096481"
    },
    {
      "arxiv_id": "2503.04429v1",
      "title": "Activation Space Interventions Can Be Transferred Between Large Language Models",
      "title_zh": "激活空间干预可在大型语言模型间迁移",
      "authors": [
        "Narmeen Oozeer",
        "Dhruv Nathawani",
        "Nirmalendu Prakash",
        "Michael Lan",
        "Abir Harrasse",
        "Amirali Abdullah"
      ],
      "abstract": "The study of representation universality in AI models reveals growing\nconvergence across domains, modalities, and architectures. However, the\npractical applications of representation universality remain largely\nunexplored. We bridge this gap by demonstrating that safety interventions can\nbe transferred between models through learned mappings of their shared\nactivation spaces. We demonstrate this approach on two well-established AI\nsafety tasks: backdoor removal and refusal of harmful prompts, showing\nsuccessful transfer of steering vectors that alter the models' outputs in a\npredictable way. Additionally, we propose a new task, \\textit{corrupted\ncapabilities}, where models are fine-tuned to embed knowledge tied to a\nbackdoor. This tests their ability to separate useful skills from backdoors,\nreflecting real-world challenges. Extensive experiments across Llama, Qwen and\nGemma model families show that our method enables using smaller models to\nefficiently align larger ones. Furthermore, we demonstrate that autoencoder\nmappings between base and fine-tuned models can serve as reliable ``lightweight\nsafety switches\", allowing dynamic toggling between model behaviors.",
      "tldr_zh": "该研究揭示了大型语言模型（LLMs）激活空间干预的可迁移性，提出通过共享激活空间的映射实现安全干预在不同模型间的转移。实验在Llama、Qwen和Gemma等模型家族中验证了该方法在三个安全任务上的有效性：后门消除、有害提示拒绝和新提出的\"能力污染\"任务（测试模型区分有用技能与后门的能力）。研究还发现，基础模型与微调模型间的自动编码器映射可作为轻量级\"安全开关\"，实现模型行为的动态切换，使得能用小模型高效对齐大模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "68 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.04429v1",
      "published_date": "2025-03-06 13:38:44 UTC",
      "updated_date": "2025-03-06 13:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:33:40.894177"
    },
    {
      "arxiv_id": "2503.04422v1",
      "title": "PDX: A Data Layout for Vector Similarity Search",
      "title_zh": "PDX：一种面向向量相似性搜索的数据布局方案",
      "authors": [
        "Leonardo Kuffo",
        "Elena Krippner",
        "Peter Boncz"
      ],
      "abstract": "We propose Partition Dimensions Across (PDX), a data layout for vectors\n(e.g., embeddings) that, similar to PAX [6], stores multiple vectors in one\nblock, using a vertical layout for the dimensions (Figure 1). PDX accelerates\nexact and approximate similarity search thanks to its dimension-by-dimension\nsearch strategy that operates on multiple-vectors-at-a-time in tight loops. It\nbeats SIMD-optimized distance kernels on standard horizontal vector storage\n(avg 40% faster), only relying on scalar code that gets auto-vectorized. We\ncombined the PDX layout with recent dimension-pruning algorithms ADSampling\n[19] and BSA [52] that accelerate approximate vector search. We found that\nthese algorithms on the horizontal vector layout can lose to SIMD-optimized\nlinear scans, even if they are SIMD-optimized. However, when used on PDX, their\nbenefit is restored to 2-7x. We find that search on PDX is especially fast if a\nlimited number of dimensions has to be scanned fully, which is what the\ndimension-pruning approaches do. We finally introduce PDX-BOND, an even more\nflexible dimension-pruning strategy, with good performance on exact search and\nreasonable performance on approximate search. Unlike previous pruning\nalgorithms, it can work on vector data \"as-is\" without preprocessing; making it\nattractive for vector databases with frequent updates.",
      "tldr_zh": "该论文提出了一种名为PDX的新型向量数据布局方案，通过将多个向量的维度垂直存储在同一数据块中，显著提升了向量相似性搜索效率。PDX布局采用逐维度搜索策略，仅需标量代码即可实现比SIMD优化水平存储方案快40%的搜索速度。研究还发现，当与维度剪枝算法(如ADSampling和BSA)结合时，PDX能恢复这些算法2-7倍的性能优势，并进一步提出了无需预处理的灵活剪枝策略PDX-BOND，特别适合频繁更新的向量数据库场景。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "To be published in Proceedings of The 2025 International Conference\n  on Management of Data (SIGMOD '25). For associated code, see\n  https://github.com/cwida/PDX",
      "pdf_url": "http://arxiv.org/pdf/2503.04422v1",
      "published_date": "2025-03-06 13:31:16 UTC",
      "updated_date": "2025-03-06 13:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:33:52.957311"
    },
    {
      "arxiv_id": "2503.04417v1",
      "title": "From Idea to CAD: A Language Model-Driven Multi-Agent System for Collaborative Design",
      "title_zh": "从构想到CAD：基于语言模型驱动的协同设计多智能体系统",
      "authors": [
        "Felix Ocker",
        "Stefan Menzel",
        "Ahmed Sadik",
        "Thiago Rios"
      ],
      "abstract": "Creating digital models using Computer Aided Design (CAD) is a process that\nrequires in-depth expertise. In industrial product development, this process\ntypically involves entire teams of engineers, spanning requirements\nengineering, CAD itself, and quality assurance. We present an approach that\nmirrors this team structure with a Vision Language Model (VLM)-based Multi\nAgent System, with access to parametric CAD tooling and tool documentation.\nCombining agents for requirements engineering, CAD engineering, and\nvision-based quality assurance, a model is generated automatically from\nsketches and/ or textual descriptions. The resulting model can be refined\ncollaboratively in an iterative validation loop with the user. Our approach has\nthe potential to increase the effectiveness of design processes, both for\nindustry experts and for hobbyists who create models for 3D printing. We\ndemonstrate the potential of the architecture at the example of various design\ntasks and provide several ablations that show the benefits of the\narchitecture's individual components.",
      "tldr_zh": "这篇论文提出了一个基于视觉语言模型(VLM)的多智能体系统，能够将草图或文本描述自动转换为计算机辅助设计(CAD)模型。该系统模拟工业产品开发流程，包含需求工程、CAD工程和基于视觉的质量保证三个智能体模块，通过迭代验证循环与用户协作优化设计。研究表明，该架构不仅能提升专业设计流程效率，也适用于3D打印爱好者的建模需求，并通过多个设计任务案例验证了系统各组件的有效性。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "J.6; I.6.5; I.2.1; I.2.11; I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04417v1",
      "published_date": "2025-03-06 13:21:27 UTC",
      "updated_date": "2025-03-06 13:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:34:22.903473"
    },
    {
      "arxiv_id": "2503.04416v1",
      "title": "Learning Transformer-based World Models with Contrastive Predictive Coding",
      "title_zh": "学习基于Transformer的世界模型：对比预测编码方法",
      "authors": [
        "Maxime Burchi",
        "Radu Timofte"
      ],
      "abstract": "The DreamerV3 algorithm recently obtained remarkable performance across\ndiverse environment domains by learning an accurate world model based on\nRecurrent Neural Networks (RNNs). Following the success of model-based\nreinforcement learning algorithms and the rapid adoption of the Transformer\narchitecture for its superior training efficiency and favorable scaling\nproperties, recent works such as STORM have proposed replacing RNN-based world\nmodels with Transformer-based world models using masked self-attention.\nHowever, despite the improved training efficiency of these methods, their\nimpact on performance remains limited compared to the Dreamer algorithm,\nstruggling to learn competitive Transformer-based world models. In this work,\nwe show that the next state prediction objective adopted in previous approaches\nis insufficient to fully exploit the representation capabilities of\nTransformers. We propose to extend world model predictions to longer time\nhorizons by introducing TWISTER (Transformer-based World model wIth contraSTivE\nRepresentations), a world model using action-conditioned Contrastive Predictive\nCoding to learn high-level temporal feature representations and improve the\nagent performance. TWISTER achieves a human-normalized mean score of 162% on\nthe Atari 100k benchmark, setting a new record among state-of-the-art methods\nthat do not employ look-ahead search.",
      "tldr_zh": "本研究提出了TWISTER，一种基于Transformer的世界模型，通过引入动作条件对比预测编码(Contrastive Predictive Coding)来扩展预测时间范围，从而更充分地利用Transformer的表征能力。与之前采用下一状态预测目标的方法不同，TWISTER能够学习高层次的时间特征表示，显著提升了智能体性能。在Atari 100k基准测试中，TWISTER取得了162%的人类标准化平均得分，创下了不采用前瞻搜索的现有方法的新记录。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04416v1",
      "published_date": "2025-03-06 13:18:37 UTC",
      "updated_date": "2025-03-06 13:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:34:04.275604"
    },
    {
      "arxiv_id": "2503.04412v1",
      "title": "Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search",
      "title_zh": "更宽还是更深？基于自适应分支树搜索扩展大语言模型推理计算",
      "authors": [
        "Kou Misaki",
        "Yuichi Inoue",
        "Yuki Imajuku",
        "So Kuroki",
        "Taishi Nakamura",
        "Takuya Akiba"
      ],
      "abstract": "Recent advances demonstrate that increasing inference-time computation can\nsignificantly boost the reasoning capabilities of large language models (LLMs).\nAlthough repeated sampling (i.e., generating multiple candidate outputs) is a\nhighly effective strategy, it does not leverage external feedback signals for\nrefinement, which are often available in tasks like coding. In this work, we\npropose $\\textit{Adaptive Branching Monte Carlo Tree Search (AB-MCTS)}$, a\nnovel inference-time framework that generalizes repeated sampling with\nprincipled multi-turn exploration and exploitation. At each node in the search\ntree, AB-MCTS dynamically decides whether to \"go wider\" by expanding new\ncandidate responses or \"go deeper\" by revisiting existing ones based on\nexternal feedback signals. We evaluate our method on complex coding and\nengineering tasks using frontier models. Empirical results show that AB-MCTS\nconsistently outperforms both repeated sampling and standard MCTS, underscoring\nthe importance of combining the response diversity of LLMs with multi-turn\nsolution refinement for effective inference-time scaling.",
      "tldr_zh": "本研究提出自适应分支蒙特卡洛树搜索（AB-MCTS），一种新型推理时计算框架，通过动态决策\"横向扩展\"（生成新候选）或\"纵向深化\"（优化现有方案）来提升大语言模型（LLMs）的推理能力。该方法在编码和工程任务上的实验表明，AB-MCTS显著优于传统重复采样和标准MCTS，验证了结合LLMs响应多样性与多轮解决方案优化的有效性。该框架为如何有效分配推理时计算资源提供了新思路，特别适用于需要外部反馈的复杂任务场景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear at ICLR 2025 Workshop on Foundation Models in the Wild",
      "pdf_url": "http://arxiv.org/pdf/2503.04412v1",
      "published_date": "2025-03-06 13:10:40 UTC",
      "updated_date": "2025-03-06 13:10:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:34:13.790803"
    },
    {
      "arxiv_id": "2503.04406v1",
      "title": "Training-Free Graph Filtering via Multimodal Feature Refinement for Extremely Fast Multimodal Recommendation",
      "title_zh": "免训练图滤波：通过多模态特征精炼实现极速多模态推荐",
      "authors": [
        "Yu-Seung Roh",
        "Joo-Young Kim",
        "Jin-Duk Park",
        "Won-Yong Shin"
      ],
      "abstract": "Multimodal recommender systems improve the performance of canonical\nrecommender systems with no item features by utilizing diverse content types\nsuch as text, images, and videos, while alleviating inherent sparsity of\nuser-item interactions and accelerating user engagement. However, current\nneural network-based models often incur significant computational overhead due\nto the complex training process required to learn and integrate information\nfrom multiple modalities. To overcome this limitation, we propose\nMultiModal-Graph Filtering (MM-GF), a training-free method based on the notion\nof graph filtering (GF) for efficient and accurate multimodal recommendations.\nSpecifically, MM-GF first constructs multiple similarity graphs through\nnontrivial multimodal feature refinement such as robust scaling and vector\nshifting by addressing the heterogeneous characteristics across modalities.\nThen, MM-GF optimally fuses multimodal information using linear low-pass\nfilters across different modalities. Extensive experiments on real-world\nbenchmark datasets demonstrate that MM-GF not only improves recommendation\naccuracy by up to 13.35% compared to the best competitor but also dramatically\nreduces computational costs by achieving the runtime of less than 10 seconds.",
      "tldr_zh": "该研究提出了一种无需训练的多模态图过滤方法MM-GF，用于高效的多模态推荐。该方法通过多模态特征精炼（如鲁棒缩放和向量平移）构建多个相似性图，并利用线性低通滤波器优化融合多模态信息。实验表明，MM-GF在真实基准数据集上不仅将推荐准确率提高了13.35%，还将计算成本大幅降低，运行时间少于10秒。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "cs.SI",
        "math.IT"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, 6 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04406v1",
      "published_date": "2025-03-06 13:00:53 UTC",
      "updated_date": "2025-03-06 13:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:34:38.113398"
    },
    {
      "arxiv_id": "2503.04398v3",
      "title": "Speculative MoE: Communication Efficient Parallel MoE Inference with Speculative Token and Expert Pre-scheduling",
      "title_zh": "Speculative MoE：基于推测性令牌与专家预调度的通信高效并行 MoE 推理",
      "authors": [
        "Yan Li",
        "Pengfei Zheng",
        "Shuang Chen",
        "Zewei Xu",
        "Yuanhao Lai",
        "Yunfei Du",
        "Zhengang Wang"
      ],
      "abstract": "MoE (Mixture of Experts) prevails as a neural architecture that can scale\nmodern transformer-based LLMs (Large Language Models) to unprecedented scales.\nNevertheless, large MoEs' great demands of computing power, memory capacity and\nmemory bandwidth make scalable serving a fundamental challenge and efficient\nparallel inference has become a requisite to attain adequate throughput under\nlatency constraints. DeepSpeed-MoE, one state-of-the-art MoE inference\nframework, adopts a 3D-parallel paradigm including EP (Expert Parallelism), TP\n(Tensor Parallel) and DP (Data Parallelism). However, our analysis shows\nDeepSpeed-MoE's inference efficiency is largely bottlenecked by EP, which is\nimplemented with costly all-to-all collectives to route token activation. Our\nwork aims to boost DeepSpeed-MoE by strategically reducing EP's communication\noverhead with a technique named Speculative MoE. Speculative MoE has two\nspeculative parallelization schemes, speculative token shuffling and\nspeculative expert grouping, which predict outstanding tokens' expert routing\npaths and pre-schedule tokens and experts across devices to losslessly trim\nEP's communication volume. Besides DeepSpeed-MoE, we also build Speculative MoE\ninto a prevailing MoE inference engine SGLang. Experiments show Speculative MoE\ncan significantly boost state-of-the-art MoE inference frameworks on fast\nhomogeneous and slow heterogeneous interconnects.",
      "tldr_zh": "本文提出Speculative MoE方法，通过预测性token调度和专家预分组技术来优化MoE（Mixture of Experts）模型的并行推理效率。该方法包含两种创新方案：预测性token重组和预测性专家分组，可无损减少专家并行（EP）中的通信开销。实验表明，该方法能显著提升现有MoE推理框架（如DeepSpeed-MoE和SGLang）在各类网络环境下的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04398v3",
      "published_date": "2025-03-06 12:52:22 UTC",
      "updated_date": "2025-03-19 02:03:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:34:32.893745"
    },
    {
      "arxiv_id": "2503.04392v1",
      "title": "AgentSafe: Safeguarding Large Language Model-based Multi-agent Systems via Hierarchical Data Management",
      "title_zh": "AgentSafe：基于分层数据管理的大型语言模型多智能体系统安全防护框架",
      "authors": [
        "Junyuan Mao",
        "Fanci Meng",
        "Yifan Duan",
        "Miao Yu",
        "Xiaojun Jia",
        "Junfeng Fang",
        "Yuxuan Liang",
        "Kun Wang",
        "Qingsong Wen"
      ],
      "abstract": "Large Language Model based multi-agent systems are revolutionizing autonomous\ncommunication and collaboration, yet they remain vulnerable to security threats\nlike unauthorized access and data breaches. To address this, we introduce\nAgentSafe, a novel framework that enhances MAS security through hierarchical\ninformation management and memory protection. AgentSafe classifies information\nby security levels, restricting sensitive data access to authorized agents.\nAgentSafe incorporates two components: ThreatSieve, which secures communication\nby verifying information authority and preventing impersonation, and\nHierarCache, an adaptive memory management system that defends against\nunauthorized access and malicious poisoning, representing the first systematic\ndefense for agent memory. Experiments across various LLMs show that AgentSafe\nsignificantly boosts system resilience, achieving defense success rates above\n80% under adversarial conditions. Additionally, AgentSafe demonstrates\nscalability, maintaining robust performance as agent numbers and information\ncomplexity grow. Results underscore effectiveness of AgentSafe in securing MAS\nand its potential for real-world application.",
      "tldr_zh": "该研究提出了AgentSafe框架，旨在解决基于大语言模型(LLM)的多智能体系统(MAS)面临的安全威胁，如未授权访问和数据泄露。AgentSafe通过分层信息管理和内存保护增强系统安全性，包括两个核心组件：ThreatSieve用于验证通信权限并防止身份伪造，HierarCache则提供自适应内存管理，抵御未授权访问和恶意数据污染。实验表明，AgentSafe在对抗条件下防御成功率超过80%，并在智能体数量和信息复杂度增加时保持稳健性能，为多智能体系统的实际应用提供了可靠的安全保障。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04392v1",
      "published_date": "2025-03-06 12:41:54 UTC",
      "updated_date": "2025-03-06 12:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:34:52.915860"
    },
    {
      "arxiv_id": "2503.04378v1",
      "title": "Dedicated Feedback and Edit Models Empower Inference-Time Scaling for Open-Ended General-Domain Tasks",
      "title_zh": "专用反馈与编辑模型赋能开放域任务的推理时扩展",
      "authors": [
        "Zhilin Wang",
        "Jiaqi Zeng",
        "Olivier Delalleau",
        "Daniel Egert",
        "Ellie Evans",
        "Hoo-Chang Shin",
        "Felipe Soares",
        "Yi Dong",
        "Oleksii Kuchaiev"
      ],
      "abstract": "Inference-Time Scaling has been critical to the success of recent models such\nas OpenAI o1 and DeepSeek R1. However, many techniques used to train models for\ninference-time scaling require tasks to have answers that can be verified,\nlimiting their application to domains such as math, coding and logical\nreasoning. We take inspiration from how humans make first attempts, ask for\ndetailed feedback from others and make improvements based on such feedback\nacross a wide spectrum of open-ended endeavors. To this end, we collect data\nfor and train dedicated Feedback and Edit Models that are capable of performing\ninference-time scaling for open-ended general-domain tasks. In our setup, one\nmodel generates an initial response, which are given feedback by a second\nmodel, that are then used by a third model to edit the response. We show that\nperformance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo\ncan be boosted by scaling the number of initial response drafts, effective\nfeedback and edited responses. When scaled optimally, our setup based on 70B\nmodels from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7\nas of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and\nDeepSeek R1 with 92.3.",
      "tldr_zh": "该研究提出了专用于开放式通用任务的反馈-编辑模型（Feedback and Edit Models）框架，通过三阶段推理过程实现推理时扩展（Inference-Time Scaling）：首先生成初始回答，再由反馈模型提供详细建议，最后由编辑模型改进响应。不同于传统方法局限在可验证答案领域（如数学、编程），该框架模仿人类\"尝试-反馈-改进\"的学习模式，成功应用于开放式任务。实验表明，基于70B参数的Llama 3系列模型，该方案在Arena Hard基准测试中达到92.7的最新性能（2025年3月5日），超越了OpenAI o1（90.4）和DeepSeek R1（92.3）的表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04378v1",
      "published_date": "2025-03-06 12:30:24 UTC",
      "updated_date": "2025-03-06 12:30:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:35:13.134197"
    },
    {
      "arxiv_id": "2503.04363v1",
      "title": "Causally Reliable Concept Bottleneck Models",
      "title_zh": "因果可靠的概念瓶颈模型",
      "authors": [
        "Giovanni De Felice",
        "Arianna Casanova Flores",
        "Francesco De Santis",
        "Silvia Santini",
        "Johannes Schneider",
        "Pietro Barbiero",
        "Alberto Termine"
      ],
      "abstract": "Concept-based models are an emerging paradigm in deep learning that\nconstrains the inference process to operate through human-interpretable\nconcepts, facilitating explainability and human interaction. However, these\narchitectures, on par with popular opaque neural models, fail to account for\nthe true causal mechanisms underlying the target phenomena represented in the\ndata. This hampers their ability to support causal reasoning tasks, limits\nout-of-distribution generalization, and hinders the implementation of fairness\nconstraints. To overcome these issues, we propose \\emph{Causally reliable\nConcept Bottleneck Models} (C$^2$BMs), a class of concept-based architectures\nthat enforce reasoning through a bottleneck of concepts structured according to\na model of the real-world causal mechanisms. We also introduce a pipeline to\nautomatically learn this structure from observational data and\n\\emph{unstructured} background knowledge (e.g., scientific literature).\nExperimental evidence suggest that C$^2$BM are more interpretable, causally\nreliable, and improve responsiveness to interventions w.r.t. standard opaque\nand concept-based models, while maintaining their accuracy.",
      "tldr_zh": "该研究提出因果可靠概念瓶颈模型(Causally reliable Concept Bottleneck Models, C²BMs)，通过将推理过程约束在符合真实世界因果机制的概念瓶颈结构中，解决了现有基于概念的模型无法支持因果推理的问题。该方法创新性地从观测数据和非结构化背景知识(如科学文献)中自动学习因果结构，实验证明其相比传统黑盒模型和普通概念模型具有更好的可解释性、因果可靠性以及对干预的响应能力，同时保持预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04363v1",
      "published_date": "2025-03-06 12:06:54 UTC",
      "updated_date": "2025-03-06 12:06:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:35:05.976185"
    },
    {
      "arxiv_id": "2503.04362v1",
      "title": "A Generalist Cross-Domain Molecular Learning Framework for Structure-Based Drug Discovery",
      "title_zh": "面向结构药物发现的通用跨域分子学习框架",
      "authors": [
        "Yiheng Zhu",
        "Mingyang Li",
        "Junlong Liu",
        "Kun Fu",
        "Jiansheng Wu",
        "Qiuyi Li",
        "Mingze Yin",
        "Jieping Ye",
        "Jian Wu",
        "Zheng Wang"
      ],
      "abstract": "Structure-based drug discovery (SBDD) is a systematic scientific process that\ndevelops new drugs by leveraging the detailed physical structure of the target\nprotein. Recent advancements in pre-trained models for biomolecules have\ndemonstrated remarkable success across various biochemical applications,\nincluding drug discovery and protein engineering. However, in most approaches,\nthe pre-trained models primarily focus on the characteristics of either small\nmolecules or proteins, without delving into their binding interactions which\nare essential cross-domain relationships pivotal to SBDD. To fill this gap, we\npropose a general-purpose foundation model named BIT (an abbreviation for\nBiomolecular Interaction Transformer), which is capable of encoding a range of\nbiochemical entities, including small molecules, proteins, and protein-ligand\ncomplexes, as well as various data formats, encompassing both 2D and 3D\nstructures. Specifically, we introduce Mixture-of-Domain-Experts (MoDE) to\nhandle the biomolecules from diverse biochemical domains and\nMixture-of-Structure-Experts (MoSE) to capture positional dependencies in the\nmolecular structures. The proposed mixture-of-experts approach enables BIT to\nachieve both deep fusion and domain-specific encoding, effectively capturing\nfine-grained molecular interactions within protein-ligand complexes. Then, we\nperform cross-domain pre-training on the shared Transformer backbone via\nseveral unified self-supervised denoising tasks. Experimental results on\nvarious benchmarks demonstrate that BIT achieves exceptional performance in\ndownstream tasks, including binding affinity prediction, structure-based\nvirtual screening, and molecular property prediction.",
      "tldr_zh": "该研究提出了一种名为BIT（Biomolecular Interaction Transformer）的通用跨域分子学习框架，用于基于结构的药物发现（SBDD）。BIT通过引入Mixture-of-Domain-Experts（MoDE）和Mixture-of-Structure-Experts（MoSE）模块，能够编码小分子、蛋白质及其复合物等多种生物化学实体，并融合2D和3D结构信息。该框架通过统一的自监督去噪任务进行跨域预训练，显著提升了蛋白质-配体复合物中分子相互作用的捕捉能力。实验结果表明，BIT在结合亲和力预测、基于结构的虚拟筛选和分子性质预测等下游任务中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04362v1",
      "published_date": "2025-03-06 12:04:56 UTC",
      "updated_date": "2025-03-06 12:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:35:15.534195"
    },
    {
      "arxiv_id": "2503.04866v1",
      "title": "Privacy in Responsible AI: Approaches to Facial Recognition from Cloud Providers",
      "title_zh": "负责任人工智能中的隐私：云服务提供商的面部识别方法",
      "authors": [
        "Anna Elivanova"
      ],
      "abstract": "As the use of facial recognition technology is expanding in different\ndomains, ensuring its responsible use is gaining more importance. This paper\nconducts a comprehensive literature review of existing studies on facial\nrecognition technology from the perspective of privacy, which is one of the key\nResponsible AI principles.\n  Cloud providers, such as Microsoft, AWS, and Google, are at the forefront of\ndelivering facial-related technology services, but their approaches to\nresponsible use of these technologies vary significantly. This paper compares\nhow these cloud giants implement the privacy principle into their facial\nrecognition and detection services. By analysing their approaches, it\nidentifies both common practices and notable differences. The results of this\nresearch will be valuable for developers and businesses by providing them\ninsights into best practices of three major companies for integration\nresponsible AI, particularly privacy, into their cloud-based facial recognition\ntechnologies.",
      "tldr_zh": "该论文从隐私保护角度系统分析了微软、AWS和谷歌三大云服务商的面部识别技术应用差异。研究发现，尽管这些云巨头都在推进负责任AI原则，但它们在隐私保护实施策略上存在显著差异。通过比较分析，研究总结了行业最佳实践，为开发者和企业整合隐私保护的面部识别云服务提供了重要参考。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04866v1",
      "published_date": "2025-03-06 12:04:12 UTC",
      "updated_date": "2025-03-06 12:04:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:35:26.735395"
    },
    {
      "arxiv_id": "2503.04357v1",
      "title": "scDD: Latent Codes Based scRNA-seq Dataset Distillation with Foundation Model Knowledge",
      "title_zh": "scDD：基于潜在编码与基础模型知识的单细胞RNA测序数据集蒸馏",
      "authors": [
        "Zhen Yu",
        "Jianan Han",
        "Yang Liu",
        "Qingchao Chen"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) technology has profiled hundreds of\nmillions of human cells across organs, diseases, development and perturbations\nto date. However, the high-dimensional sparsity, batch effect noise, category\nimbalance, and ever-increasing data scale of the original sequencing data pose\nsignificant challenges for multi-center knowledge transfer, data fusion, and\ncross-validation between scRNA-seq datasets. To address these barriers, (1) we\nfirst propose a latent codes-based scRNA-seq dataset distillation framework\nnamed scDD, which transfers and distills foundation model knowledge and\noriginal dataset information into a compact latent space and generates\nsynthetic scRNA-seq dataset by a generator to replace the original dataset.\nThen, (2) we propose a single-step conditional diffusion generator named SCDG,\nwhich perform single-step gradient back-propagation to help scDD optimize\ndistillation quality and avoid gradient decay caused by multi-step\nback-propagation. Meanwhile, SCDG ensures the scRNA-seq data characteristics\nand inter-class discriminability of the synthetic dataset through flexible\nconditional control and generation quality assurance. Finally, we propose a\ncomprehensive benchmark to evaluate the performance of scRNA-seq dataset\ndistillation in different data analysis tasks. It is validated that our\nproposed method can achieve 7.61% absolute and 15.70% relative improvement over\nprevious state-of-the-art methods on average task.",
      "tldr_zh": "该研究提出scDD框架，基于潜在编码实现单细胞RNA测序(scRNA-seq)数据集的蒸馏，通过迁移基础模型知识将高维稀疏原始数据压缩至紧凑潜在空间。创新性地设计了单步条件扩散生成器(SCDG)，采用单步梯度反向传播优化蒸馏质量，同时通过灵活的条件控制保持数据特性和类间区分度。实验表明，该方法在多种分析任务中平均性能较现有最优方法提升7.61%（绝对）和15.70%（相对），有效解决了多中心数据集成的维度灾难和批次效应问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04357v1",
      "published_date": "2025-03-06 12:01:20 UTC",
      "updated_date": "2025-03-06 12:01:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:35:33.406714"
    },
    {
      "arxiv_id": "2503.04343v1",
      "title": "Talking Back -- human input and explanations to interactive AI systems",
      "title_zh": "回话——人类对交互式AI系统的输入与解释",
      "authors": [
        "Alan Dix",
        "Tommaso Turchi",
        "Ben Wilson",
        "Anna Monreale",
        "Matt Roach"
      ],
      "abstract": "While XAI focuses on providing AI explanations to humans, can the reverse -\nhumans explaining their judgments to AI - foster richer, synergistic human-AI\nsystems? This paper explores various forms of human inputs to AI and examines\nhow human explanations can guide machine learning models toward automated\njudgments and explanations that align more closely with human concepts.",
      "tldr_zh": "这篇论文探讨了在可解释人工智能(XAI)领域中\"反向解释\"的价值——即人类向AI系统解释自身判断如何能够促进更协同的人机交互。研究分析了多种人类输入形式，发现人类解释能有效引导机器学习模型生成更符合人类概念的自动化判断和解释，从而建立更具协同性的人机系统。这一发现为构建更符合人类认知的AI系统提供了新思路。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "I.2"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04343v1",
      "published_date": "2025-03-06 11:39:46 UTC",
      "updated_date": "2025-03-06 11:39:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:35:59.255411"
    },
    {
      "arxiv_id": "2503.04328v1",
      "title": "Solving Word-Sense Disambiguation and Word-Sense Induction with Dictionary Examples",
      "title_zh": "利用词典示例解决词义消歧与词义归纳问题",
      "authors": [
        "Tadej Škvorc",
        "Marko Robnik-Šikonja"
      ],
      "abstract": "Many less-resourced languages struggle with a lack of large, task-specific\ndatasets that are required for solving relevant tasks with modern\ntransformer-based large language models (LLMs). On the other hand, many\nlinguistic resources, such as dictionaries, are rarely used in this context\ndespite their large information contents. We show how LLMs can be used to\nextend existing language resources in less-resourced languages for two\nimportant tasks: word-sense disambiguation (WSD) and word-sense induction\n(WSI). We approach the two tasks through the related but much more accessible\nword-in-context (WiC) task where, given a pair of sentences and a target word,\na classification model is tasked with predicting whether the sense of a given\nword differs between sentences. We demonstrate that a well-trained model for\nthis task can distinguish between different word senses and can be adapted to\nsolve the WSD and WSI tasks. The advantage of using the WiC task, instead of\ndirectly predicting senses, is that the WiC task does not need pre-constructed\nsense inventories with a sufficient number of examples for each sense, which\nare rarely available in less-resourced languages. We show that sentence pairs\nfor the WiC task can be successfully generated from dictionary examples using\nLLMs. The resulting prediction models outperform existing models on WiC, WSD,\nand WSI tasks. We demonstrate our methodology on the Slovene language, where a\nmonolingual dictionary is available, but word-sense resources are tiny.",
      "tldr_zh": "该研究提出利用词典示例解决低资源语言中的词义消歧(WSD)和词义归纳(WSI)任务。通过将问题转化为更易获取的上下文词义识别(WiC)任务，并基于大语言模型(LLMs)从词典中自动生成训练数据，该方法避免了传统方法需要大规模标注语料库的缺陷。实验证明，该方法在斯洛文尼亚语等低资源语言中显著优于现有模型，为缺乏大规模词义资源的语言提供了有效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.04328v1",
      "published_date": "2025-03-06 11:27:55 UTC",
      "updated_date": "2025-03-06 11:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:36:26.616321"
    },
    {
      "arxiv_id": "2503.04315v1",
      "title": "Provable Robust Overfitting Mitigation in Wasserstein Distributionally Robust Optimization",
      "title_zh": "可证明的鲁棒过拟合缓解：基于Wasserstein分布鲁棒优化的方法",
      "authors": [
        "Shuang Liu",
        "Yihan Wang",
        "Yifan Zhu",
        "Yibo Miao",
        "Xiao-Shan Gao"
      ],
      "abstract": "Wasserstein distributionally robust optimization (WDRO) optimizes against\nworst-case distributional shifts within a specified uncertainty set, leading to\nenhanced generalization on unseen adversarial examples, compared to standard\nadversarial training which focuses on pointwise adversarial perturbations.\nHowever, WDRO still suffers fundamentally from the robust overfitting problem,\nas it does not consider statistical error. We address this gap by proposing a\nnovel robust optimization framework under a new uncertainty set for adversarial\nnoise via Wasserstein distance and statistical error via Kullback-Leibler\ndivergence, called the Statistically Robust WDRO. We establish a robust\ngeneralization bound for the new optimization framework, implying that\nout-of-distribution adversarial performance is at least as good as the\nstatistically robust training loss with high probability. Furthermore, we\nderive conditions under which Stackelberg and Nash equilibria exist between the\nlearner and the adversary, giving an optimal robust model in certain sense.\nFinally, through extensive experiments, we demonstrate that our method\nsignificantly mitigates robust overfitting and enhances robustness within the\nframework of WDRO.",
      "tldr_zh": "本文提出了一种新型统计鲁棒Wasserstein分布鲁棒优化框架(Statistically Robust WDRO)，通过结合Wasserstein距离和Kullback-Leibler散度构建新型不确定性集合，有效解决了传统WDRO方法存在的鲁棒过拟合问题。理论分析表明，该框架不仅建立了鲁棒泛化边界，保证分布外对抗性能至少与统计鲁棒训练损失相当，还证明了在特定条件下学习器与对抗者之间存在Stackelberg和Nash均衡。实验验证该方法能显著缓解鲁棒过拟合现象，并在WDRO框架内提高了模型鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04315v1",
      "published_date": "2025-03-06 10:58:35 UTC",
      "updated_date": "2025-03-06 10:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:36:00.762766"
    },
    {
      "arxiv_id": "2503.04302v1",
      "title": "Malware Detection at the Edge with Lightweight LLMs: A Performance Evaluation",
      "title_zh": "边缘计算中的轻量级大语言模型恶意软件检测：性能评估",
      "authors": [
        "Christian Rondanini",
        "Barbara Carminati",
        "Elena Ferrari",
        "Antonio Gaudiano",
        "Ashish Kundu"
      ],
      "abstract": "The rapid evolution of malware attacks calls for the development of\ninnovative detection methods, especially in resource-constrained edge\ncomputing. Traditional detection techniques struggle to keep up with modern\nmalware's sophistication and adaptability, prompting a shift towards advanced\nmethodologies like those leveraging Large Language Models (LLMs) for enhanced\nmalware detection. However, deploying LLMs for malware detection directly at\nedge devices raises several challenges, including ensuring accuracy in\nconstrained environments and addressing edge devices' energy and computational\nlimits. To tackle these challenges, this paper proposes an architecture\nleveraging lightweight LLMs' strengths while addressing limitations like\nreduced accuracy and insufficient computational power. To evaluate the\neffectiveness of the proposed lightweight LLM-based approach for edge\ncomputing, we perform an extensive experimental evaluation using several\nstate-of-the-art lightweight LLMs. We test them with several publicly available\ndatasets specifically designed for edge and IoT scenarios and different edge\nnodes with varying computational power and characteristics.",
      "tldr_zh": "该研究评估了轻量化大语言模型（LLMs）在边缘计算环境下的恶意软件检测性能。针对边缘设备资源受限的特点，研究提出了基于轻量化LLMs的架构，解决了传统检测方法难以应对现代恶意软件复杂性的问题。通过多组公开边缘/IoT数据集测试，实验验证了该方法在不同计算能力的边缘节点上的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04302v1",
      "published_date": "2025-03-06 10:42:18 UTC",
      "updated_date": "2025-03-06 10:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:36:05.393219"
    },
    {
      "arxiv_id": "2503.04865v1",
      "title": "E4: Energy-Efficient DNN Inference for Edge Video Analytics Via Early-Exit and DVFS",
      "title_zh": "E4：通过提前退出与动态电压频率调谐实现边缘视频分析的高效能DNN推理",
      "authors": [
        "Ziyang Zhang",
        "Yang Zhao",
        "Ming-Ching Chang",
        "Changyao Lin",
        "Jie Liu"
      ],
      "abstract": "Deep neural network (DNN) models are increasingly popular in edge video\nanalytic applications. However, the compute-intensive nature of DNN models pose\nchallenges for energy-efficient inference on resource-constrained edge devices.\nMost existing solutions focus on optimizing DNN inference latency and accuracy,\noften overlooking energy efficiency. They also fail to account for the varying\ncomplexity of video frames, leading to sub-optimal performance in edge video\nanalytics. In this paper, we propose an Energy-Efficient Early-Exit (E4)\nframework that enhances DNN inference efficiency for edge video analytics by\nintegrating a novel early-exit mechanism with dynamic voltage and frequency\nscaling (DVFS) governors. It employs an attention-based cascade module to\nanalyze video frame diversity and automatically determine optimal DNN exit\npoints. Additionally, E4 features a just-in-time (JIT) profiler that uses\ncoordinate descent search to co-optimize CPU and GPU clock frequencies for each\nlayer before the DNN exit points. Extensive evaluations demonstrate that E4\noutperforms current state-of-the-art methods, achieving up to 2.8x speedup and\n26% average energy saving while maintaining high accuracy.",
      "tldr_zh": "该研究提出E4框架，通过结合Early-Exit机制和动态电压频率调节(DVFS)来优化边缘设备上的DNN视频分析能效。系统采用注意力级联模块分析视频帧差异以确定最佳退出点，并引入即时分析器(JIT profiler)通过坐标下降搜索协同优化CPU/GPU频率。实验显示E4框架相比现有方法可实现2.8倍加速和26%的平均能耗节省，同时保持高精度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 5 figures, to be published in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04865v1",
      "published_date": "2025-03-06 10:41:28 UTC",
      "updated_date": "2025-03-06 10:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:36:41.683721"
    },
    {
      "arxiv_id": "2503.04299v2",
      "title": "Mapping AI Benchmark Data to Quantitative Risk Estimates Through Expert Elicitation",
      "title_zh": "通过专家启发将AI基准数据映射为定量风险估计",
      "authors": [
        "Malcolm Murray",
        "Henry Papadatos",
        "Otter Quarks",
        "Pierre-François Gimenez",
        "Simeon Campos"
      ],
      "abstract": "The literature and multiple experts point to many potential risks from large\nlanguage models (LLMs), but there are still very few direct measurements of the\nactual harms posed. AI risk assessment has so far focused on measuring the\nmodels' capabilities, but the capabilities of models are only indicators of\nrisk, not measures of risk. Better modeling and quantification of AI risk\nscenarios can help bridge this disconnect and link the capabilities of LLMs to\ntangible real-world harm. This paper makes an early contribution to this field\nby demonstrating how existing AI benchmarks can be used to facilitate the\ncreation of risk estimates. We describe the results of a pilot study in which\nexperts use information from Cybench, an AI benchmark, to generate probability\nestimates. We show that the methodology seems promising for this purpose, while\nnoting improvements that can be made to further strengthen its application in\nquantitative AI risk assessment.",
      "tldr_zh": "该研究通过专家评估方法，将AI基准测试数据映射到定量风险估计，以填补大语言模型（LLMs）能力评估与实际风险测量之间的差距。研究展示了一项试点研究的结果，专家利用Cybench基准测试信息生成概率估计，表明该方法在定量AI风险评估中具有潜力，同时指出了进一步改进的方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04299v2",
      "published_date": "2025-03-06 10:39:47 UTC",
      "updated_date": "2025-03-10 13:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:36:45.367832"
    },
    {
      "arxiv_id": "2503.04291v1",
      "title": "MathMistake Checker: A Comprehensive Demonstration for Step-by-Step Math Problem Mistake Finding by Prompt-Guided LLMs",
      "title_zh": "MathMistake Checker：基于提示引导大语言模型的逐步数学问题错误查找综合演示",
      "authors": [
        "Tianyang Zhang",
        "Zhuoxuan Jiang",
        "Haotian Zhang",
        "Lin Lin",
        "Shaohua Zhang"
      ],
      "abstract": "We propose a novel system, MathMistake Checker, designed to automate\nstep-by-step mistake finding in mathematical problems with lengthy answers\nthrough a two-stage process. The system aims to simplify grading, increase\nefficiency, and enhance learning experiences from a pedagogical perspective. It\nintegrates advanced technologies, including computer vision and the\nchain-of-thought capabilities of the latest large language models (LLMs). Our\nsystem supports open-ended grading without reference answers and promotes\npersonalized learning by providing targeted feedback. We demonstrate its\neffectiveness across various types of math problems, such as calculation and\nword problems.",
      "tldr_zh": "该研究提出MathMistake Checker系统，采用两阶段流程自动检测数学解题步骤中的错误，结合计算机视觉和大语言模型(LLMs)的链式推理能力。该系统无需参考答案即可实现开放式评分，并通过针对性反馈促进个性化学习，适用于计算题和文字题等多种数学题型，有效提升批改效率和教学体验。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04291v1",
      "published_date": "2025-03-06 10:19:01 UTC",
      "updated_date": "2025-03-06 10:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:36:58.129633"
    },
    {
      "arxiv_id": "2503.04290v1",
      "title": "How Do Hackathons Foster Creativity? Towards AI Collaborative Evaluation of Creativity at Scale",
      "title_zh": "黑客马拉松如何激发创造力？——面向人工智能辅助的大规模协作创造力评估",
      "authors": [
        "Jeanette Falk",
        "Yiyi Chen",
        "Janet Rafner",
        "Mike Zhang",
        "Johannes Bjerva",
        "Alexander Nolte"
      ],
      "abstract": "Hackathons have become popular collaborative events for accelerating the\ndevelopment of creative ideas and prototypes. There are several case studies\nshowcasing creative outcomes across domains such as industry, education, and\nresearch. However, there are no large-scale studies on creativity in hackathons\nwhich can advance theory on how hackathon formats lead to creative outcomes. We\nconducted a computational analysis of 193,353 hackathon projects. By\noperationalizing creativity through usefulness and novelty, we refined our\ndataset to 10,363 projects, allowing us to analyze how participant\ncharacteristics, collaboration patterns, and hackathon setups influence the\ndevelopment of creative projects. The contribution of our paper is twofold: We\nidentified means for organizers to foster creativity in hackathons. We also\nexplore the use of large language models (LLMs) to augment the evaluation of\ncreative outcomes and discuss challenges and opportunities of doing this, which\nhas implications for creativity research at large.",
      "tldr_zh": "本研究通过大规模计算分析193,353个黑客马拉松项目，探讨了黑客马拉松如何促进创造力。研究将创造力操作化为实用性和新颖性，筛选出10,363个项目，分析了参与者特征、协作模式和活动设置对创意项目开发的影响。研究贡献包括：提出了组织者提升黑客马拉松创造力的方法，并探索了使用大语言模型(LLMs)增强创意成果评估的潜力，同时讨论了相关挑战和机遇，对创造力研究具有重要意义。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted in Proceedings of the 2025 CHI Conference on Human Factors\n  in Computing Systems",
      "pdf_url": "http://arxiv.org/pdf/2503.04290v1",
      "published_date": "2025-03-06 10:17:52 UTC",
      "updated_date": "2025-03-06 10:17:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:37:04.503493"
    },
    {
      "arxiv_id": "2503.04283v1",
      "title": "Explainable AI in Time-Sensitive Scenarios: Prefetched Offline Explanation Model",
      "title_zh": "时间敏感场景中的可解释AI：预取离线解释模型",
      "authors": [
        "Fabio Michele Russo",
        "Carlo Metta",
        "Anna Monreale",
        "Salvatore Rinzivillo",
        "Fabio Pinelli"
      ],
      "abstract": "As predictive machine learning models become increasingly adopted and\nadvanced, their role has evolved from merely predicting outcomes to actively\nshaping them. This evolution has underscored the importance of Trustworthy AI,\nhighlighting the necessity to extend our focus beyond mere accuracy and toward\na comprehensive understanding of these models' behaviors within the specific\ncontexts of their applications. To further progress in explainability, we\nintroduce Poem, Prefetched Offline Explanation Model, a model-agnostic, local\nexplainability algorithm for image data. The algorithm generates exemplars,\ncounterexemplars and saliency maps to provide quick and effective explanations\nsuitable for time-sensitive scenarios. Leveraging an existing local algorithm,\n\\poem{} infers factual and counterfactual rules from data to create\nillustrative examples and opposite scenarios with an enhanced stability by\ndesign. A novel mechanism then matches incoming test points with an explanation\nbase and produces diverse exemplars, informative saliency maps and believable\ncounterexemplars. Experimental results indicate that Poem outperforms its\npredecessor Abele in speed and ability to generate more nuanced and varied\nexemplars alongside more insightful saliency maps and valuable\ncounterexemplars.",
      "tldr_zh": "本文提出了PoEM（预取离线解释模型），一种适用于时间敏感场景的模型无关本地可解释性算法。该算法通过生成示例、反例和显著图，为图像数据提供快速有效的解释。PoEM改进了现有本地算法，能推断事实和反事实规则，设计上增强了稳定性，并通过新颖机制匹配测试点与解释库，产生多样化示例、信息丰富的显著图和可信的反例。实验表明，PoEM在速度和生成更细致示例、更具洞察力的显著图及更有价值的反例方面优于前身Abele算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04283v1",
      "published_date": "2025-03-06 10:09:20 UTC",
      "updated_date": "2025-03-06 10:09:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:37:14.500412"
    },
    {
      "arxiv_id": "2503.04280v2",
      "title": "Towards Autonomous Reinforcement Learning for Real-World Robotic Manipulation with Large Language Models",
      "title_zh": "迈向基于大语言模型的现实世界机器人操作自主强化学习",
      "authors": [
        "Niccolò Turcato",
        "Matteo Iovino",
        "Aris Synodinos",
        "Alberto Dalla Libera",
        "Ruggero Carli",
        "Pietro Falco"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) and Visual Language\nModels (VLMs) have significantly impacted robotics, enabling high-level\nsemantic motion planning applications. Reinforcement Learning (RL), a\ncomplementary paradigm, enables agents to autonomously optimize complex\nbehaviors through interaction and reward signals. However, designing effective\nreward functions for RL remains challenging, especially in real-world tasks\nwhere sparse rewards are insufficient and dense rewards require elaborate\ndesign. In this work, we propose Autonomous Reinforcement learning for Complex\nHumanInformed Environments (ARCHIE), an unsupervised pipeline leveraging GPT-4,\na pre-trained LLM, to generate reward functions directly from natural language\ntask descriptions. The rewards are used to train RL agents in simulated\nenvironments, where we formalize the reward generation process to enhance\nfeasibility. Additionally, GPT-4 automates the coding of task success criteria,\ncreating a fully automated, one-shot procedure for translating human-readable\ntext into deployable robot skills. Our approach is validated through extensive\nsimulated experiments on single-arm and bi-manual manipulation tasks using an\nABB YuMi collaborative robot, highlighting its practicality and effectiveness.\nTasks are demonstrated on the real robot setup.",
      "tldr_zh": "本研究提出ARCHIE框架，通过大语言模型（GPT-4）实现从自然语言任务描述到强化学习（RL）奖励函数的自动生成，解决了传统RL在真实机器人操作任务中奖励函数设计困难的痛点。该框架利用GPT-4自动生成可行奖励函数并编写任务成功标准代码，实现了从人类可读文本到可部署机器人技能的全自动单次转换流程。在ABB YuMi协作机器人的单臂/双臂操作任务实验中，该方案验证了其可行性和有效性，为真实世界机器人操控提供了自主强化学习新范式。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04280v2",
      "published_date": "2025-03-06 10:08:44 UTC",
      "updated_date": "2025-03-07 10:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:37:28.719641"
    },
    {
      "arxiv_id": "2503.04267v1",
      "title": "Prompt Programming: A Platform for Dialogue-based Computational Problem Solving with Generative AI Models",
      "title_zh": "提示编程：基于生成式AI模型的对话式计算问题解决平台",
      "authors": [
        "Victor-Alexandru Pădurean",
        "Paul Denny",
        "Alkis Gotovos",
        "Adish Singla"
      ],
      "abstract": "Computing students increasingly rely on generative AI tools for programming\nassistance, often without formal instruction or guidance. This highlights a\nneed to teach students how to effectively interact with AI models, particularly\nthrough natural language prompts, to generate and critically evaluate code for\nsolving computational tasks. To address this, we developed a novel platform for\nprompt programming that enables authentic dialogue-based interactions, supports\nproblems involving multiple interdependent functions, and offers on-request\nexecution of generated code. Data analysis from over 900 students in an\nintroductory programming course revealed high engagement, with the majority of\nprompts occurring within multi-turn dialogues. Problems with multiple\ninterdependent functions encouraged iterative refinement, with progression\ngraphs highlighting several common strategies. Students were highly selective\nabout the code they chose to test, suggesting that on-request execution of\ngenerated code promoted critical thinking. Given the growing importance of\nlearning dialogue-based programming with AI, we provide this tool as a publicly\naccessible resource, accompanied by a corpus of programming problems for\neducational use.",
      "tldr_zh": "该研究开发了一个名为Prompt Programming的对话式编程平台，旨在帮助计算科学学生通过自然语言提示与生成式AI模型互动，解决编程任务。平台支持多轮对话、多函数依赖问题的处理，并提供按需代码执行功能。通过对900多名学生的数据分析，发现该平台促进了迭代优化和批判性思维，学生倾向于选择性测试生成的代码。研究还提供了公开访问的平台资源和编程问题库，以支持基于AI的对话式编程教育。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Preprint of the ITiCSE'25 paper",
      "pdf_url": "http://arxiv.org/pdf/2503.04267v1",
      "published_date": "2025-03-06 09:56:07 UTC",
      "updated_date": "2025-03-06 09:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:37:50.867069"
    },
    {
      "arxiv_id": "2503.04262v1",
      "title": "Guidelines for Applying RL and MARL in Cybersecurity Applications",
      "title_zh": "网络安全应用中强化学习与多智能体强化学习实施指南",
      "authors": [
        "Vasilios Mavroudis",
        "Gregory Palmer",
        "Sara Farmer",
        "Kez Smithson Whitehead",
        "David Foster",
        "Adam Price",
        "Ian Miles",
        "Alberto Caron",
        "Stephen Pasteris"
      ],
      "abstract": "Reinforcement Learning (RL) and Multi-Agent Reinforcement Learning (MARL)\nhave emerged as promising methodologies for addressing challenges in automated\ncyber defence (ACD). These techniques offer adaptive decision-making\ncapabilities in high-dimensional, adversarial environments. This report\nprovides a structured set of guidelines for cybersecurity professionals and\nresearchers to assess the suitability of RL and MARL for specific use cases,\nconsidering factors such as explainability, exploration needs, and the\ncomplexity of multi-agent coordination. It also discusses key algorithmic\napproaches, implementation challenges, and real-world constraints, such as data\nscarcity and adversarial interference. The report further outlines open\nresearch questions, including policy optimality, agent cooperation levels, and\nthe integration of MARL systems into operational cybersecurity frameworks. By\nbridging theoretical advancements and practical deployment, these guidelines\naim to enhance the effectiveness of AI-driven cyber defence strategies.",
      "tldr_zh": "该报告为网络安全领域提供了强化学习(RL)和多智能体强化学习(MARL)的应用指南，指出这些方法在自动化网络防御(ACD)中具有自适应高维对抗环境的优势。报告系统性地阐述了RL/MARL适用性评估标准，包括可解释性、探索需求和多智能体协调复杂度等关键考量因素，同时探讨了算法选择、实施挑战（如数据稀缺和对抗干扰）等实际问题。最后提出了政策最优性、智能体协作水平等开放研究问题，旨在促进AI驱动网络防御从理论到实际部署的转化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04262v1",
      "published_date": "2025-03-06 09:46:16 UTC",
      "updated_date": "2025-03-06 09:46:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:37:37.499419"
    },
    {
      "arxiv_id": "2503.04261v1",
      "title": "VirtualXAI: A User-Centric Framework for Explainability Assessment Leveraging GPT-Generated Personas",
      "title_zh": "VirtualXAI：基于GPT生成角色模型的用户中心化可解释性评估框架",
      "authors": [
        "Georgios Makridis",
        "Vasileios Koukos",
        "Georgios Fatouros",
        "Dimosthenis Kyriazis"
      ],
      "abstract": "In today's data-driven era, computational systems generate vast amounts of\ndata that drive the digital transformation of industries, where Artificial\nIntelligence (AI) plays a key role. Currently, the demand for eXplainable AI\n(XAI) has increased to enhance the interpretability, transparency, and\ntrustworthiness of AI models. However, evaluating XAI methods remains\nchallenging: existing evaluation frameworks typically focus on quantitative\nproperties such as fidelity, consistency, and stability without taking into\naccount qualitative characteristics such as satisfaction and interpretability.\nIn addition, practitioners face a lack of guidance in selecting appropriate\ndatasets, AI models, and XAI methods -a major hurdle in human-AI collaboration.\nTo address these gaps, we propose a framework that integrates quantitative\nbenchmarking with qualitative user assessments through virtual personas based\non the \"Anthology\" of backstories of the Large Language Model (LLM). Our\nframework also incorporates a content-based recommender system that leverages\ndataset-specific characteristics to match new input data with a repository of\nbenchmarked datasets. This yields an estimated XAI score and provides tailored\nrecommendations for both the optimal AI model and the XAI method for a given\nscenario.",
      "tldr_zh": "本文提出VirtualXAI框架，通过整合量化指标与基于LLM生成虚拟角色的用户评估，解决当前可解释人工智能(XAI)评估中忽视用户满意度等定性指标的问题。该框架创新性地利用大语言模型生成的\"人物志\"(Anthology)构建虚拟用户角色，并结合基于内容的推荐系统，为特定场景推荐最优AI模型和XAI方法。研究实现了XAI评估从纯技术指标到用户体验导向的范式转变，为提升人机协作中的AI可解释性提供了系统化解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04261v1",
      "published_date": "2025-03-06 09:44:18 UTC",
      "updated_date": "2025-03-06 09:44:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:37:50.777584"
    },
    {
      "arxiv_id": "2503.04863v1",
      "title": "Manboformer: Learning Gaussian Representations via Spatial-temporal Attention Mechanism",
      "title_zh": "Manboformer：通过时空注意力机制学习高斯表示",
      "authors": [
        "Ziyue Zhao",
        "Qining Qi",
        "Jianfa Ma"
      ],
      "abstract": "Compared with voxel-based grid prediction, in the field of 3D semantic\noccupation prediction for autonomous driving, GaussianFormer proposed using 3D\nGaussian to describe scenes with sparse 3D semantic Gaussian based on objects\nis another scheme with lower memory requirements. Each 3D Gaussian function\nrepresents a flexible region of interest and its semantic features, which are\niteratively refined by the attention mechanism. In the experiment, it is found\nthat the Gaussian function required by this method is larger than the query\nresolution of the original dense grid network, resulting in impaired\nperformance. Therefore, we consider optimizing GaussianFormer by using unused\ntemporal information. We learn the Spatial-Temporal Self-attention Mechanism\nfrom the previous grid-given occupation network and improve it to\nGaussianFormer. The experiment was conducted with the NuScenes dataset, and the\nexperiment is currently underway.",
      "tldr_zh": "该研究提出了Manboformer，通过引入时空自注意力机制(Spatial-Temporal Self-attention Mechanism)优化了基于3D高斯分布的语义占据预测方法GaussianFormer。与传统的体素网格预测相比，该方法使用3D高斯函数描述场景，具有更低的内存需求。研究通过利用未使用的时间信息，改进了原有的密集网格网络，并在NuScenes数据集上进行实验验证。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04863v1",
      "published_date": "2025-03-06 09:40:46 UTC",
      "updated_date": "2025-03-06 09:40:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:37:54.896901"
    },
    {
      "arxiv_id": "2503.04258v1",
      "title": "TAIL: Text-Audio Incremental Learning",
      "title_zh": "TAIL：文本-音频增量学习",
      "authors": [
        "Yingfei Sun",
        "Xu Gu",
        "Wei Ji",
        "Hanbin Zhao",
        "Hao Fei",
        "Yifang Yin",
        "Roger Zimmermann"
      ],
      "abstract": "Many studies combine text and audio to capture multi-modal information but\nthey overlook the model's generalization ability on new datasets. Introducing\nnew datasets may affect the feature space of the original dataset, leading to\ncatastrophic forgetting. Meanwhile, large model parameters can significantly\nimpact training performance. To address these limitations, we introduce a novel\ntask called Text-Audio Incremental Learning (TAIL) task for text-audio\nretrieval, and propose a new method, PTAT, Prompt Tuning for Audio-Text\nincremental learning. This method utilizes prompt tuning to optimize the model\nparameters while incorporating an audio-text similarity and feature\ndistillation module to effectively mitigate catastrophic forgetting. We\nbenchmark our method and previous incremental learning methods on AudioCaps,\nClotho, BBC Sound Effects and Audioset datasets, and our method outperforms\nprevious methods significantly, particularly demonstrating stronger resistance\nto forgetting on older datasets. Compared to the full-parameters Finetune\n(Sequential) method, our model only requires 2.42\\% of its parameters,\nachieving 4.46\\% higher performance.",
      "tldr_zh": "该研究提出了文本-音频增量学习任务（Text-Audio Incremental Learning, TAIL），并开发了一种名为PTAT（Prompt Tuning for Audio-Text）的新方法，用于优化文本-音频检索中的模型性能。PTAT方法通过提示调优（Prompt Tuning）减少模型参数量，并结合音频-文本相似性模块和特征蒸馏模块，有效缓解了增量学习中的灾难性遗忘问题。在多个数据集上的实验表明，PTAT方法显著优于现有增量学习方法，特别是在旧数据集上表现出更强的抗遗忘能力，同时仅需2.42%的参数量即可实现比全参数微调方法高4.46%的性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "eess.AS",
        "I.2"
      ],
      "primary_category": "cs.SD",
      "comment": "4 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04258v1",
      "published_date": "2025-03-06 09:39:36 UTC",
      "updated_date": "2025-03-06 09:39:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:38:32.174084"
    },
    {
      "arxiv_id": "2503.04257v1",
      "title": "How to Move Your Dragon: Text-to-Motion Synthesis for Large-Vocabulary Objects",
      "title_zh": "如何驱动你的龙：面向大词汇量物体的文本到动作合成",
      "authors": [
        "Wonkwang Lee",
        "Jongwon Jeong",
        "Taehong Moon",
        "Hyeon-Jong Kim",
        "Jaehyeon Kim",
        "Gunhee Kim",
        "Byeong-Uk Lee"
      ],
      "abstract": "Motion synthesis for diverse object categories holds great potential for 3D\ncontent creation but remains underexplored due to two key challenges: (1) the\nlack of comprehensive motion datasets that include a wide range of high-quality\nmotions and annotations, and (2) the absence of methods capable of handling\nheterogeneous skeletal templates from diverse objects. To address these\nchallenges, we contribute the following: First, we augment the Truebones Zoo\ndataset, a high-quality animal motion dataset covering over 70 species, by\nannotating it with detailed text descriptions, making it suitable for\ntext-based motion synthesis. Second, we introduce rig augmentation techniques\nthat generate diverse motion data while preserving consistent dynamics,\nenabling models to adapt to various skeletal configurations. Finally, we\nredesign existing motion diffusion models to dynamically adapt to arbitrary\nskeletal templates, enabling motion synthesis for a diverse range of objects\nwith varying structures. Experiments show that our method learns to generate\nhigh-fidelity motions from textual descriptions for diverse and even unseen\nobjects, setting a strong foundation for motion synthesis across diverse object\ncategories and skeletal templates. Qualitative results are available on this\nlink: t2m4lvo.github.io",
      "tldr_zh": "该研究提出了面向多样化对象的文本到动作合成方法，解决了大规模词汇对象动作合成的两大挑战：缺乏高质量动作数据集和难以处理异构骨骼模板的问题。研究通过扩展Truebones Zoo数据集并添加详细文本标注，引入rig augmentation技术生成多样化动作数据，同时重新设计动作扩散模型以动态适应任意骨骼模板。实验表明，该方法能够从文本描述生成高质量动作，甚至适用于未见过的对象，为跨类别对象动作合成奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04257v1",
      "published_date": "2025-03-06 09:39:09 UTC",
      "updated_date": "2025-03-06 09:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:38:16.557101"
    },
    {
      "arxiv_id": "2503.04256v1",
      "title": "Knowledge Retention for Continual Model-Based Reinforcement Learning",
      "title_zh": "基于模型的持续强化学习中的知识保留",
      "authors": [
        "Yixiang Sun",
        "Haotian Fu",
        "Michael Littman",
        "George Konidaris"
      ],
      "abstract": "We propose DRAGO, a novel approach for continual model-based reinforcement\nlearning aimed at improving the incremental development of world models across\na sequence of tasks that differ in their reward functions but not the state\nspace or dynamics. DRAGO comprises two key components: Synthetic Experience\nRehearsal, which leverages generative models to create synthetic experiences\nfrom past tasks, allowing the agent to reinforce previously learned dynamics\nwithout storing data, and Regaining Memories Through Exploration, which\nintroduces an intrinsic reward mechanism to guide the agent toward revisiting\nrelevant states from prior tasks. Together, these components enable the agent\nto maintain a comprehensive and continually developing world model,\nfacilitating more effective learning and adaptation across diverse\nenvironments. Empirical evaluations demonstrate that DRAGO is able to preserve\nknowledge across tasks, achieving superior performance in various continual\nlearning scenarios.",
      "tldr_zh": "该研究提出DRAGO方法，用于改进持续模型强化学习中的世界模型增量构建。该方法包含两大核心创新：1）利用生成模型创建过往任务的合成经验（Synthetic Experience Rehearsal），无需存储数据即可巩固已学动态；2）通过探索重获记忆（Regaining Memories Through Exploration）机制，引导智能体重访先前任务的关键状态。实验表明，DRAGO能有效保持跨任务知识，在多种持续学习场景中表现优异。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04256v1",
      "published_date": "2025-03-06 09:38:14 UTC",
      "updated_date": "2025-03-06 09:38:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:38:26.073540"
    },
    {
      "arxiv_id": "2503.04249v1",
      "title": "How to Mitigate Overfitting in Weak-to-strong Generalization?",
      "title_zh": "如何缓解弱到强泛化中的过拟合问题？",
      "authors": [
        "Junhao Shi",
        "Qinyuan Cheng",
        "Zhaoye Fei",
        "Yining Zheng",
        "Qipeng Guo",
        "Xipeng Qiu"
      ],
      "abstract": "Aligning powerful AI models on tasks that surpass human evaluation\ncapabilities is the central problem of \\textbf{superalignment}. To address this\nproblem, weak-to-strong generalization aims to elicit the capabilities of\nstrong models through weak supervisors and ensure that the behavior of strong\nmodels aligns with the intentions of weak supervisors without unsafe behaviors\nsuch as deception. Although weak-to-strong generalization exhibiting certain\ngeneralization capabilities, strong models exhibit significant overfitting in\nweak-to-strong generalization: Due to the strong fit ability of strong models,\nerroneous labels from weak supervisors may lead to overfitting in strong\nmodels. In addition, simply filtering out incorrect labels may lead to a\ndegeneration in question quality, resulting in a weak generalization ability of\nstrong models on hard questions. To mitigate overfitting in weak-to-strong\ngeneralization, we propose a two-stage framework that simultaneously improves\nthe quality of supervision signals and the quality of input questions.\nExperimental results in three series of large language models and two\nmathematical benchmarks demonstrate that our framework significantly improves\nPGR compared to naive weak-to-strong generalization, even achieving up to 100\\%\nPGR on some models.",
      "tldr_zh": "该研究针对弱监督到强泛化（weak-to-strong generalization）中的过拟合问题，提出了一种两阶段框架。通过同时提升监督信号质量和输入问题质量，该框架有效缓解了强模型对弱监督错误标签的过拟合现象，并避免了因过滤错误标签导致的泛化能力下降。实验表明，该框架在多个大语言模型和数学基准测试中显著提升了性能泛化率（PGR），部分模型甚至达到100%的PGR。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04249v1",
      "published_date": "2025-03-06 09:32:39 UTC",
      "updated_date": "2025-03-06 09:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:38:33.763600"
    },
    {
      "arxiv_id": "2503.04231v1",
      "title": "One-Shot Clustering for Federated Learning",
      "title_zh": "联邦学习中的一次性聚类",
      "authors": [
        "Maciej Krzysztof Zuziak",
        "Roberto Pellungrini",
        "Salvatore Rinzivillo"
      ],
      "abstract": "Federated Learning (FL) is a widespread and well adopted paradigm of\ndecentralized learning that allows training one model from multiple sources\nwithout the need to directly transfer data between participating clients. Since\nits inception in 2015, it has been divided into numerous sub-fields that deal\nwith application-specific issues, be it data heterogeneity or resource\nallocation. One such sub-field, Clustered Federated Learning (CFL), is dealing\nwith the problem of clustering the population of clients into separate cohorts\nto deliver personalized models. Although few remarkable works have been\npublished in this domain, the problem is still largely unexplored, as its basic\nassumption and settings are slightly different from standard FL. In this work,\nwe present One-Shot Clustered Federated Learning (OCFL), a clustering-agnostic\nalgorithm that can automatically detect the earliest suitable moment for\nclustering. Our algorithm is based on the computation of cosine similarity\nbetween gradients of the clients and a temperature measure that detects when\nthe federated model starts to converge. We empirically evaluate our methodology\nby testing various one-shot clustering algorithms for over thirty different\ntasks on three benchmark datasets. Our experiments showcase the good\nperformance of our approach when used to perform CFL in an automated manner\nwithout the need to adjust hyperparameters.",
      "tldr_zh": "该研究提出了一种新型联邦学习框架——One-Shot Clustered Federated Learning (OCFL)，通过单次聚类解决客户端个性化建模问题。该方法创新性地采用客户端梯度余弦相似度和温度测量指标，自动检测最佳聚类时机，无需调整超参数。实验在三个基准数据集上测试了30多个任务，验证了该自动化聚类方法在联邦学习中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04231v1",
      "published_date": "2025-03-06 09:12:43 UTC",
      "updated_date": "2025-03-06 09:12:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:38:54.419589"
    },
    {
      "arxiv_id": "2503.04219v1",
      "title": "Quantum-Inspired Reinforcement Learning in the Presence of Epistemic Ambivalence",
      "title_zh": "量子启发的认知矛盾下强化学习",
      "authors": [
        "Alireza Habibi",
        "Saeed Ghoorchian",
        "Setareh Maghsudi"
      ],
      "abstract": "The complexity of online decision-making under uncertainty stems from the\nrequirement of finding a balance between exploiting known strategies and\nexploring new possibilities. Naturally, the uncertainty type plays a crucial\nrole in developing decision-making strategies that manage complexity\neffectively. In this paper, we focus on a specific form of uncertainty known as\nepistemic ambivalence (EA), which emerges from conflicting pieces of evidence\nor contradictory experiences. It creates a delicate interplay between\nuncertainty and confidence, distinguishing it from epistemic uncertainty that\ntypically diminishes with new information. Indeed, ambivalence can persist even\nafter additional knowledge is acquired. To address this phenomenon, we propose\na novel framework, called the epistemically ambivalent Markov decision process\n(EA-MDP), aiming to understand and control EA in decision-making processes.\nThis framework incorporates the concept of a quantum state from the quantum\nmechanics formalism, and its core is to assess the probability and reward of\nevery possible outcome. We calculate the reward function using quantum\nmeasurement techniques and prove the existence of an optimal policy and an\noptimal value function in the EA-MDP framework. We also propose the\nEA-epsilon-greedy Q-learning algorithm. To evaluate the impact of EA on\ndecision-making and the expedience of our framework, we study two distinct\nexperimental setups, namely the two-state problem and the lattice problem. Our\nresults show that using our methods, the agent converges to the optimal policy\nin the presence of EA.",
      "tldr_zh": "该论文提出了一种受量子力学启发的强化学习新框架EA-MDP，用于处理决策过程中存在的认知矛盾（epistemic ambivalence）问题。该框架创新性地将量子态概念引入马尔可夫决策过程，通过量子测量技术计算奖励函数，并证明了最优策略的存在性。研究者开发了EA-epsilon-greedy Q-learning算法，在双态问题和格子问题上的实验表明，该框架能有效处理持续性认知矛盾，使智能体在矛盾环境下仍能收敛至最优策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph",
        "81P68, 81Q99, 68T05, 68Q12",
        "J.2; G.3; I.1.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04219v1",
      "published_date": "2025-03-06 08:54:31 UTC",
      "updated_date": "2025-03-06 08:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:38:50.600189"
    },
    {
      "arxiv_id": "2503.04859v1",
      "title": "Codebook Reduction and Saturation: Novel observations on Inductive Thematic Saturation for Large Language Models and initial coding in Thematic Analysis",
      "title_zh": "代码本缩减与饱和：关于大语言模型归纳主题饱和及主题分析初始编码的新观察",
      "authors": [
        "Stefano De Paoli",
        "Walter Stan Mathis"
      ],
      "abstract": "This paper reflects on the process of performing Thematic Analysis with Large\nLanguage Models (LLMs). Specifically, the paper deals with the problem of\nanalytical saturation of initial codes, as produced by LLMs. Thematic Analysis\nis a well-established qualitative analysis method composed of interlinked\nphases. A key phase is the initial coding, where the analysts assign labels to\ndiscrete components of a dataset. Saturation is a way to measure the validity\nof a qualitative analysis and relates to the recurrence and repetition of\ninitial codes. In the paper we reflect on how well LLMs achieve analytical\nsaturation and propose also a novel technique to measure Inductive Thematic\nSaturation (ITS). This novel technique leverages a programming framework called\nDSPy. The proposed novel approach allows a precise measurement of ITS.",
      "tldr_zh": "本文探讨了使用大语言模型(LLMs)进行主题分析的过程，重点关注LLMs生成的初始代码的分析饱和问题。研究提出了一种基于DSPy编程框架的新方法，用于精确测量归纳主题饱和(ITS)，从而评估LLMs在主题分析中的有效性。该方法为定性分析提供了一种创新工具，能够更准确地衡量初始代码的重复性和一致性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04859v1",
      "published_date": "2025-03-06 08:52:03 UTC",
      "updated_date": "2025-03-06 08:52:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:39:04.954272"
    },
    {
      "arxiv_id": "2503.04858v1",
      "title": "SHAPE : Self-Improved Visual Preference Alignment by Iteratively Generating Holistic Winner",
      "title_zh": "SHAPE：通过迭代生成整体优胜者实现自我改进的视觉偏好对齐",
      "authors": [
        "Kejia Chen",
        "Jiawen Zhang",
        "Jiacong Hu",
        "Jiazhen Yang",
        "Jian Lou",
        "Zunlei Feng",
        "Mingli Song"
      ],
      "abstract": "Large Visual Language Models (LVLMs) increasingly rely on preference\nalignment to ensure reliability, which steers the model behavior via preference\nfine-tuning on preference data structured as ``image - winner text - loser\ntext'' triplets. However, existing approaches often suffer from limited\ndiversity and high costs associated with human-annotated preference data,\nhindering LVLMs from fully achieving their intended alignment capabilities. We\npresent \\projectname, a self-supervised framework capable of transforming the\nalready abundant supervised text-image pairs into holistic preference triplets\nfor more effective and cheaper LVLM alignment, eliminating the need for human\npreference annotations. Our approach facilitates LVLMs in progressively\nenhancing alignment capabilities through iterative self-improvement. The key\ndesign rationale is to devise preference triplets where the winner text\nconsistently improves in holisticness and outperforms the loser response in\nquality, thereby pushing the model to ``strive to the utmost'' of alignment\nperformance through preference fine-tuning. For each given text-image pair,\nSHAPE introduces multiple visual augmentations and pairs them with a summarized\ntext to serve as the winner response, while designating the original text as\nthe loser response. Experiments across \\textbf{12} benchmarks on various model\narchitectures and sizes, including LLaVA and DeepSeek-VL, show that SHAPE\nachieves significant gains, for example, achieving +11.3\\% on MMVet\n(comprehensive evaluation), +1.4\\% on MMBench (general VQA), and +8.0\\% on POPE\n(hallucination robustness) over baselines in 7B models. Notably, qualitative\nanalyses confirm enhanced attention to visual details and better alignment with\nhuman preferences for holistic descriptions.",
      "tldr_zh": "该研究提出了SHAPE框架，通过自监督方式将现有的文本-图像对转化为全面的偏好三元组（image - winner text - loser text），从而提升大型视觉语言模型（LVLMs）的偏好对齐能力，减少对人类标注的依赖。SHAPE通过视觉增强和文本总结生成高质量的三元组，推动模型在偏好微调中不断自我优化。实验表明，SHAPE在12个基准测试中显著提升了模型性能，例如在MMVet、MMBench和POPE上分别提高了11.3%、1.4%和8.0%，同时增强了模型对视觉细节的关注和整体描述的偏好对齐能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04858v1",
      "published_date": "2025-03-06 08:33:11 UTC",
      "updated_date": "2025-03-06 08:33:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:39:15.362772"
    },
    {
      "arxiv_id": "2503.04201v1",
      "title": "Knowledge-Decoupled Synergetic Learning: An MLLM based Collaborative Approach to Few-shot Multimodal Dialogue Intention Recognition",
      "title_zh": "知识解耦协同学习：基于MLLM的少样本多模态对话意图识别协作方法",
      "authors": [
        "Bin Chen",
        "Yu Zhang",
        "Hongfei Ye",
        "Ziyi Huang",
        "Hongyang Chen"
      ],
      "abstract": "Few-shot multimodal dialogue intention recognition is a critical challenge in\nthe e-commerce domainn. Previous methods have primarily enhanced model\nclassification capabilities through post-training techniques. However, our\nanalysis reveals that training for few-shot multimodal dialogue intention\nrecognition involves two interconnected tasks, leading to a seesaw effect in\nmulti-task learning. This phenomenon is attributed to knowledge interference\nstemming from the superposition of weight matrix updates during the training\nprocess. To address these challenges, we propose Knowledge-Decoupled Synergetic\nLearning (KDSL), which mitigates these issues by utilizing smaller models to\ntransform knowledge into interpretable rules, while applying the post-training\nof larger models. By facilitating collaboration between the large and small\nmultimodal large language models for prediction, our approach demonstrates\nsignificant improvements. Notably, we achieve outstanding results on two real\nTaobao datasets, with enhancements of 6.37\\% and 6.28\\% in online weighted F1\nscores compared to the state-of-the-art method, thereby validating the efficacy\nof our framework.",
      "tldr_zh": "本文提出知识解耦协同学习(KDSL)，用于解决多模态对话意图识别中的\"跷跷板效应\"问题。该方法通过小型模型将知识转化为可解释规则，与大型多模态语言模型(MLLM)协同训练，有效缓解权重矩阵叠加导致的知识干扰。在淘宝两个真实数据集上的实验表明，该方法在线加权F1值分别提升6.37%和6.28%，显著优于现有最佳方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04201v1",
      "published_date": "2025-03-06 08:28:44 UTC",
      "updated_date": "2025-03-06 08:28:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:39:17.719317"
    },
    {
      "arxiv_id": "2503.04199v1",
      "title": "MASTER: Multimodal Segmentation with Text Prompts",
      "title_zh": "MASTER：基于文本提示的多模态分割方法",
      "authors": [
        "Fuyang Liu",
        "Shun Lu",
        "Jilin Mei",
        "Yu Hu"
      ],
      "abstract": "RGB-Thermal fusion is a potential solution for various weather and light\nconditions in challenging scenarios. However, plenty of studies focus on\ndesigning complex modules to fuse different modalities. With the widespread\napplication of large language models (LLMs), valuable information can be more\neffectively extracted from natural language. Therefore, we aim to leverage the\nadvantages of large language models to design a structurally simple and highly\nadaptable multimodal fusion model architecture. We proposed MultimodAl\nSegmentation with TExt PRompts (MASTER) architecture, which integrates LLM into\nthe fusion of RGB-Thermal multimodal data and allows complex query text to\nparticipate in the fusion process. Our model utilizes a dual-path structure to\nextract information from different modalities of images. Additionally, we\nemploy LLM as the core module for multimodal fusion, enabling the model to\ngenerate learnable codebook tokens from RGB, thermal images, and textual\ninformation. A lightweight image decoder is used to obtain semantic\nsegmentation results. The proposed MASTER performs exceptionally well in\nbenchmark tests across various automated driving scenarios, yielding promising\nresults.",
      "tldr_zh": "该研究提出了MASTER架构，一种基于文本提示的多模态分割模型，旨在简化并提升RGB-Thermal多模态数据的融合效果。通过将大语言模型(LLM)作为核心模块，MASTER能够从RGB图像、热成像和文本信息中生成可学习的编码本token，并结合轻量级图像解码器实现语义分割。实验表明，MASTER在多种自动驾驶场景的基准测试中表现优异，为复杂环境下的多模态融合提供了高效且适应性强的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04199v1",
      "published_date": "2025-03-06 08:27:51 UTC",
      "updated_date": "2025-03-06 08:27:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:39:22.621560"
    },
    {
      "arxiv_id": "2503.04184v1",
      "title": "Large-Scale AI in Telecom: Charting the Roadmap for Innovation, Scalability, and Enhanced Digital Experiences",
      "title_zh": "电信领域的大规模人工智能：绘制创新、可扩展性和增强数字体验的路线图",
      "authors": [
        "Adnan Shahid",
        "Adrian Kliks",
        "Ahmed Al-Tahmeesschi",
        "Ahmed Elbakary",
        "Alexandros Nikou",
        "Ali Maatouk",
        "Ali Mokh",
        "Amirreza Kazemi",
        "Antonio De Domenico",
        "Athanasios Karapantelakis",
        "Bo Cheng",
        "Bo Yang",
        "Bohao Wang",
        "Carlo Fischione",
        "Chao Zhang",
        "Chaouki Ben Issaid",
        "Chau Yuen",
        "Chenghui Peng",
        "Chongwen Huang",
        "Christina Chaccour",
        "Christo Kurisummoottil Thomas",
        "Dheeraj Sharma",
        "Dimitris Kalogiros",
        "Dusit Niyato",
        "Eli De Poorter",
        "Elissa Mhanna",
        "Emilio Calvanese Strinati",
        "Faouzi Bader",
        "Fathi Abdeldayem",
        "Fei Wang",
        "Fenghao Zhu",
        "Gianluca Fontanesi",
        "Giovanni Geraci",
        "Haibo Zhou",
        "Hakimeh Purmehdi",
        "Hamed Ahmadi",
        "Hang Zou",
        "Hongyang Du",
        "Hoon Lee",
        "Howard H. Yang",
        "Iacopo Poli",
        "Igor Carron",
        "Ilias Chatzistefanidis",
        "Inkyu Lee",
        "Ioannis Pitsiorlas",
        "Jaron Fontaine",
        "Jiajun Wu",
        "Jie Zeng",
        "Jinan Li",
        "Jinane Karam",
        "Johny Gemayel",
        "Juan Deng",
        "Julien Frison",
        "Kaibin Huang",
        "Kehai Qiu",
        "Keith Ball",
        "Kezhi Wang",
        "Kun Guo",
        "Leandros Tassiulas",
        "Lecorve Gwenole",
        "Liexiang Yue",
        "Lina Bariah",
        "Louis Powell",
        "Marcin Dryjanski",
        "Maria Amparo Canaveras Galdon",
        "Marios Kountouris",
        "Maryam Hafeez",
        "Maxime Elkael",
        "Mehdi Bennis",
        "Mehdi Boudjelli",
        "Meiling Dai",
        "Merouane Debbah",
        "Michele Polese",
        "Mohamad Assaad",
        "Mohamed Benzaghta",
        "Mohammad Al Refai",
        "Moussab Djerrab",
        "Mubeen Syed",
        "Muhammad Amir",
        "Na Yan",
        "Najla Alkaabi",
        "Nan Li",
        "Nassim Sehad",
        "Navid Nikaein",
        "Omar Hashash",
        "Pawel Sroka",
        "Qianqian Yang",
        "Qiyang Zhao",
        "Rasoul Nikbakht Silab",
        "Rex Ying",
        "Roberto Morabito",
        "Rongpeng Li",
        "Ryad Madi",
        "Salah Eddine El Ayoubi",
        "Salvatore D'Oro",
        "Samson Lasaulce",
        "Serveh Shalmashi",
        "Sige Liu",
        "Sihem Cherrared",
        "Swarna Bindu Chetty",
        "Swastika Dutta",
        "Syed A. R. Zaidi",
        "Tianjiao Chen",
        "Timothy Murphy",
        "Tommaso Melodia",
        "Tony Q. S. Quek",
        "Vishnu Ram",
        "Walid Saad",
        "Wassim Hamidouche",
        "Weilong Chen",
        "Xiaoou Liu",
        "Xiaoxue Yu",
        "Xijun Wang",
        "Xingyu Shang",
        "Xinquan Wang",
        "Xuelin Cao",
        "Yang Su",
        "Yanping Liang",
        "Yansha Deng",
        "Yifan Yang",
        "Yingping Cui",
        "Yu Sun",
        "Yuxuan Chen",
        "Yvan Pointurier",
        "Zeinab Nehme",
        "Zeinab Nezami",
        "Zhaohui Yang",
        "Zhaoyang Zhang",
        "Zhe Liu",
        "Zhenyu Yang",
        "Zhu Han",
        "Zhuang Zhou",
        "Zihan Chen",
        "Zirui Chen",
        "Zitao Shuai"
      ],
      "abstract": "This white paper discusses the role of large-scale AI in the\ntelecommunications industry, with a specific focus on the potential of\ngenerative AI to revolutionize network functions and user experiences,\nespecially in the context of 6G systems. It highlights the development and\ndeployment of Large Telecom Models (LTMs), which are tailored AI models\ndesigned to address the complex challenges faced by modern telecom networks.\nThe paper covers a wide range of topics, from the architecture and deployment\nstrategies of LTMs to their applications in network management, resource\nallocation, and optimization. It also explores the regulatory, ethical, and\nstandardization considerations for LTMs, offering insights into their future\nintegration into telecom infrastructure. The goal is to provide a comprehensive\nroadmap for the adoption of LTMs to enhance scalability, performance, and\nuser-centric innovation in telecom networks.",
      "tldr_zh": "该白皮书探讨了大规模AI在电信行业中的作用，重点分析了生成式AI在6G系统中革新网络功能和用户体验的潜力。研究提出了专为电信网络设计的\"大型电信模型\"(LTMs)，覆盖了从架构设计到网络管理、资源优化等应用场景，同时探讨了相关监管和标准化问题。该研究为电信网络提供了通过LTMs实现可扩展性提升和用户中心创新的全面技术路线图。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04184v1",
      "published_date": "2025-03-06 07:53:24 UTC",
      "updated_date": "2025-03-06 07:53:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:39:54.505064"
    },
    {
      "arxiv_id": "2503.04183v1",
      "title": "CrowdHMTware: A Cross-level Co-adaptation Middleware for Context-aware Mobile DL Deployment",
      "title_zh": "CrowdHMTware：面向上下文感知移动深度学习部署的跨层级协同适应中间件",
      "authors": [
        "Sicong Liu",
        "Bin Guo",
        "Shiyan Luo",
        "Yuzhan Wang",
        "Hao Luo",
        "Cheng Fang",
        "Yuan Xu",
        "Ke Ma",
        "Yao Li",
        "Zhiwen Yu"
      ],
      "abstract": "There are many deep learning (DL) powered mobile and wearable applications\ntoday continuously and unobtrusively sensing the ambient surroundings to\nenhance all aspects of human lives.To enable robust and private mobile sensing,\nDL models are often deployed locally on resource-constrained mobile devices\nusing techniques such as model compression or offloading.However, existing\nmethods, either front-end algorithm level (i.e. DL model\ncompression/partitioning) or back-end scheduling level (i.e. operator/resource\nscheduling), cannot be locally online because they require offline retraining\nto ensure accuracy or rely on manually pre-defined strategies, struggle with\ndynamic adaptability.The primary challenge lies in feeding back runtime\nperformance from the back-end level to the front-end level optimization\ndecision. Moreover, the adaptive mobile DL model porting middleware with\ncross-level co-adaptation is less explored, particularly in mobile environments\nwith diversity and dynamics. In response, we introduce CrowdHMTware, a dynamic\ncontext-adaptive DL model deployment middleware for heterogeneous mobile\ndevices. It establishes an automated adaptation loop between cross-level\nfunctional components, i.e. elastic inference, scalable offloading, and\nmodel-adaptive engine, enhancing scalability and adaptability. Experiments with\nfour typical tasks across 15 platforms and a real-world case study demonstrate\nthat CrowdHMTware can effectively scale DL model, offloading, and engine\nactions across diverse platforms and tasks. It hides run-time system issues\nfrom developers, reducing the required developer expertise.",
      "tldr_zh": "该研究提出CrowdHMTware，一种面向异构移动设备的上下文感知深度学习部署中间件，解决了现有方法无法在线动态适应的问题。通过建立弹性推理、可扩展卸载和模型自适应引擎的跨层级协同适应机制，该系统实现了移动环境下深度学习模型的自动化部署优化。实验表明，该中间件能在15种平台和4类典型任务中有效调整模型规模与卸载策略，同时降低对开发者的技术要求，为动态移动环境中的高效深度学习部署提供了新方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is accepted by IEEE Transactions on Mobile Computing",
      "pdf_url": "http://arxiv.org/pdf/2503.04183v1",
      "published_date": "2025-03-06 07:52:20 UTC",
      "updated_date": "2025-03-06 07:52:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:40:13.157548"
    },
    {
      "arxiv_id": "2503.04176v1",
      "title": "TIMER: Temporal Instruction Modeling and Evaluation for Longitudinal Clinical Records",
      "title_zh": "TIMER：纵向临床记录的时间指令建模与评估",
      "authors": [
        "Hejie Cui",
        "Alyssa Unell",
        "Bowen Chen",
        "Jason Alan Fries",
        "Emily Alsentzer",
        "Sanmi Koyejo",
        "Nigam Shah"
      ],
      "abstract": "Large language models (LLMs) have emerged as promising tools for assisting in\nmedical tasks, yet processing Electronic Health Records (EHRs) presents unique\nchallenges due to their longitudinal nature. While LLMs' capabilities to\nperform medical tasks continue to improve, their ability to reason over\ntemporal dependencies across multiple patient visits and time frames remains\nunexplored. We introduce TIMER (Temporal Instruction Modeling and Evaluation\nfor Longitudinal Clinical Records), a framework that incorporate\ninstruction-response pairs grounding to different parts of a patient's record\nas a critical dimension in both instruction evaluation and tuning for\nlongitudinal clinical records. We develop TIMER-Bench, the first time-aware\nbenchmark that evaluates temporal reasoning capabilities over longitudinal\nEHRs, as well as TIMER-Instruct, an instruction-tuning methodology for LLMs to\nlearn reasoning over time. We demonstrate that models fine-tuned with\nTIMER-Instruct improve performance by 7.3% on human-generated benchmarks and\n9.2% on TIMER-Bench, indicating that temporal instruction-tuning improves model\nperformance for reasoning over EHR.",
      "tldr_zh": "该研究提出了TIMER框架，旨在提升大语言模型(LLMs)对电子健康记录(EHRs)中时间依赖性的推理能力。TIMER包括TIMER-Bench，首个用于评估EHR时间推理能力的时间感知基准，以及TIMER-Instruct，一种通过指令微调方法使LLMs学习时间推理的技术。实验表明，经过TIMER-Instruct微调的模型在人工生成基准和TIMER-Bench上的性能分别提升了7.3%和9.2%，验证了该方法在EHR时间推理任务中的有效性。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.LG",
        "68T50, 68T37",
        "I.2.7; J.3"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.04176v1",
      "published_date": "2025-03-06 07:44:17 UTC",
      "updated_date": "2025-03-06 07:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:40:40.830877"
    },
    {
      "arxiv_id": "2503.04170v1",
      "title": "Towards Intelligent Transportation with Pedestrians and Vehicles In-the-Loop: A Surveillance Video-Assisted Federated Digital Twin Framework",
      "title_zh": "迈向行人车辆闭环智能交通：基于监控视频的联邦数字孪生框架",
      "authors": [
        "Xiaolong Li",
        "Jianhao Wei",
        "Haidong Wang",
        "Li Dong",
        "Ruoyang Chen",
        "Changyan Yi",
        "Jun Cai",
        "Dusit Niyato",
        "Xuemin",
        "Shen"
      ],
      "abstract": "In intelligent transportation systems (ITSs), incorporating pedestrians and\nvehicles in-the-loop is crucial for developing realistic and safe traffic\nmanagement solutions. However, there is falls short of simulating complex\nreal-world ITS scenarios, primarily due to the lack of a digital twin\nimplementation framework for characterizing interactions between pedestrians\nand vehicles at different locations in different traffic environments. In this\narticle, we propose a surveillance video assisted federated digital twin\n(SV-FDT) framework to empower ITSs with pedestrians and vehicles in-the-loop.\nSpecifically, SVFDT builds comprehensive pedestrian-vehicle interaction models\nby leveraging multi-source traffic surveillance videos. Its architecture\nconsists of three layers: (i) the end layer, which collects traffic\nsurveillance videos from multiple sources; (ii) the edge layer, responsible for\nsemantic segmentation-based visual understanding, twin agent-based interaction\nmodeling, and local digital twin system (LDTS) creation in local regions; and\n(iii) the cloud layer, which integrates LDTSs across different regions to\nconstruct a global DT model in realtime. We analyze key design requirements and\nchallenges and present core guidelines for SVFDT's system implementation. A\ntestbed evaluation demonstrates its effectiveness in optimizing traffic\nmanagement. Comparisons with traditional terminal-server frameworks highlight\nSV-FDT's advantages in mirroring delays, recognition accuracy, and subjective\nevaluation. Finally, we identify some open challenges and discuss future\nresearch directions.",
      "tldr_zh": "该研究提出了一个基于监控视频的联邦数字孪生框架（SV-FDT），用于实现行人和车辆实时参与的智能交通系统。该框架通过多源监控视频构建行人-车辆交互模型，采用三层架构（终端层-边缘层-云端层）实现局部数字孪生系统的实时整合。相比传统终端-服务器框架，SV-FDT在延迟、识别准确率和主观评价方面表现更优，为交通管理优化提供了有效解决方案。研究还探讨了该框架面临的关键挑战和未来研究方向。",
      "categories": [
        "cs.ET",
        "cs.AI"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04170v1",
      "published_date": "2025-03-06 07:36:06 UTC",
      "updated_date": "2025-03-06 07:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:39:59.942095"
    },
    {
      "arxiv_id": "2503.04856v1",
      "title": "One-Shot is Enough: Consolidating Multi-Turn Attacks into Efficient Single-Turn Prompts for LLMs",
      "title_zh": "一次足矣：将多轮攻击整合为高效的单轮提示以突破大语言模型",
      "authors": [
        "Junwoo Ha",
        "Hyunjun Kim",
        "Sangyoon Yu",
        "Haon Park",
        "Ashkan Yousefpour",
        "Yuna Park",
        "Suhyun Kim"
      ],
      "abstract": "Despite extensive safety enhancements in large language models (LLMs),\nmulti-turn \"jailbreak\" conversations crafted by skilled human adversaries can\nstill breach even the most sophisticated guardrails. However, these multi-turn\nattacks demand considerable manual effort, limiting their scalability. In this\nwork, we introduce a novel approach called Multi-turn-to-Single-turn (M2S) that\nsystematically converts multi-turn jailbreak prompts into single-turn attacks.\nSpecifically, we propose three conversion strategies - Hyphenize, Numberize,\nand Pythonize - each preserving sequential context yet packaging it in a single\nquery. Our experiments on the Multi-turn Human Jailbreak (MHJ) dataset show\nthat M2S often increases or maintains high Attack Success Rates (ASRs) compared\nto original multi-turn conversations. Notably, using a StrongREJECT-based\nevaluation of harmfulness, M2S achieves up to 95.9% ASR on Mistral-7B and\noutperforms original multi-turn prompts by as much as 17.5% in absolute\nimprovement on GPT-4o. Further analysis reveals that certain adversarial\ntactics, when consolidated into a single prompt, exploit structural formatting\ncues to evade standard policy checks. These findings underscore that\nsingle-turn attacks - despite being simpler and cheaper to conduct - can be\njust as potent, if not more, than their multi-turn counterparts. Our findings\nunderscore the urgent need to reevaluate and reinforce LLM safety strategies,\ngiven how adversarial queries can be compacted into a single prompt while still\nretaining sufficient complexity to bypass existing safety measures.",
      "tldr_zh": "该研究提出了一种将多轮越狱攻击(Multi-turn jailbreak)压缩为单轮提示的高效方法M2S（Multi-turn-to-Single-turn）。通过Hyphenize、Numberize和Pythonize三种转换策略，该方法在保持攻击效果的同时显著提升效率，在Mistral-7B模型上攻击成功率(ASR)高达95.9%，对GPT-4o的单轮攻击效果甚至比原始多轮攻击提升17.5%。研究发现，结构化格式提示能有效规避现有安全策略，表明单轮攻击可能比多轮攻击更具威胁性，这为LLM安全防御机制提出了新的挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04856v1",
      "published_date": "2025-03-06 07:34:51 UTC",
      "updated_date": "2025-03-06 07:34:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:40:07.883729"
    },
    {
      "arxiv_id": "2503.04167v1",
      "title": "The Role of Visual Modality in Multimodal Mathematical Reasoning: Challenges and Insights",
      "title_zh": "视觉模态在多模态数学推理中的作用：挑战与洞见",
      "authors": [
        "Yufang Liu",
        "Yao Du",
        "Tao Ji",
        "Jianing Wang",
        "Yang Liu",
        "Yuanbin Wu",
        "Aimin Zhou",
        "Mengdi Zhang",
        "Xunliang Cai"
      ],
      "abstract": "Recent research has increasingly focused on multimodal mathematical\nreasoning, particularly emphasizing the creation of relevant datasets and\nbenchmarks. Despite this, the role of visual information in reasoning has been\nunderexplored. Our findings show that existing multimodal mathematical models\nminimally leverage visual information, and model performance remains largely\nunaffected by changes to or removal of images in the dataset. We attribute this\nto the dominance of textual information and answer options that inadvertently\nguide the model to correct answers. To improve evaluation methods, we introduce\nthe HC-M3D dataset, specifically designed to require image reliance for\nproblem-solving and to challenge models with similar, yet distinct, images that\nchange the correct answer. In testing leading models, their failure to detect\nthese subtle visual differences suggests limitations in current visual\nperception capabilities. Additionally, we observe that the common approach of\nimproving general VQA capabilities by combining various types of image encoders\ndoes not contribute to math reasoning performance. This finding also presents a\nchallenge to enhancing visual reliance during math reasoning. Our benchmark and\ncode would be available at\n\\href{https://github.com/Yufang-Liu/visual_modality_role}{https://github.com/Yufang-Liu/visual\\_modality\\_role}.",
      "tldr_zh": "该研究探讨了多模态数学推理中视觉信息的作用，发现现有模型主要依赖文本信息，而视觉输入对性能影响微弱。作者提出了HC-M3D数据集，专门设计需要依赖图像解题的数学问题，并包含细微视觉差异影响答案的样本。实验表明主流模型难以捕捉这些视觉差异，且增强通用视觉问答能力并不能提升数学推理表现。这项研究揭示了当前多模态数学推理中视觉感知的局限性，为改进评估方法提供了新基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04167v1",
      "published_date": "2025-03-06 07:29:33 UTC",
      "updated_date": "2025-03-06 07:29:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:40:20.708171"
    },
    {
      "arxiv_id": "2503.04162v1",
      "title": "Semantic Retrieval Augmented Contrastive Learning for Sequential Recommendation",
      "title_zh": "语义检索增强的对比学习用于序列推荐",
      "authors": [
        "Ziqiang Cui",
        "Yunpeng Weng",
        "Xing Tang",
        "Xiaokun Zhang",
        "Dugang Liu",
        "Shiwei Li",
        "Peiyang Liu",
        "Bowei He",
        "Weihong Luo",
        "Xiuqiang He",
        "Chen Ma"
      ],
      "abstract": "Sequential recommendation aims to model user preferences based on historical\nbehavior sequences, which is crucial for various online platforms. Data\nsparsity remains a significant challenge in this area as most users have\nlimited interactions and many items receive little attention. To mitigate this\nissue, contrastive learning has been widely adopted. By constructing positive\nsample pairs from the data itself and maximizing their agreement in the\nembedding space,it can leverage available data more effectively. Constructing\nreasonable positive sample pairs is crucial for the success of contrastive\nlearning. However, current approaches struggle to generate reliable positive\npairs as they either rely on representations learned from inherently sparse\ncollaborative signals or use random perturbations which introduce significant\nuncertainty. To address these limitations, we propose a novel approach named\nSemantic Retrieval Augmented Contrastive Learning (SRA-CL), which leverages\nsemantic information to improve the reliability of contrastive samples. SRA-CL\ncomprises two main components: (1) Cross-Sequence Contrastive Learning via User\nSemantic Retrieval, which utilizes large language models (LLMs) to understand\ndiverse user preferences and retrieve semantically similar users to form\nreliable positive samples through a learnable sample synthesis method; and (2)\nIntra-Sequence Contrastive Learning via Item Semantic Retrieval, which employs\nLLMs to comprehend items and retrieve similar items to perform semantic-based\nitem substitution, thereby creating semantically consistent augmented views for\ncontrastive learning. SRA-CL is plug-and-play and can be integrated into\nstandard sequential recommendation models. Extensive experiments on four public\ndatasets demonstrate the effectiveness and generalizability of the proposed\napproach.",
      "tldr_zh": "本研究提出了一种基于语义检索增强的对比学习方法（SRA-CL），用于解决序列推荐中数据稀疏性问题。该方法创新性地利用大语言模型（LLMs）理解用户和物品语义：一方面通过检索语义相似用户构建跨序列对比样本，另一方面基于物品语义进行替换以生成序列内增强视图。实验表明，这种可插拔的框架能有效提升现有推荐模型性能，在四个公开数据集上验证了其优越性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04162v1",
      "published_date": "2025-03-06 07:25:19 UTC",
      "updated_date": "2025-03-06 07:25:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:40:23.865520"
    },
    {
      "arxiv_id": "2503.04160v1",
      "title": "Unseen Fake News Detection Through Casual Debiasing",
      "title_zh": "通过因果去偏见的未见假新闻检测",
      "authors": [
        "Shuzhi Gong",
        "Richard Sinnott",
        "Jianzhong Qi",
        "Cecile Paris"
      ],
      "abstract": "The widespread dissemination of fake news on social media poses significant\nrisks, necessitating timely and accurate detection. However, existing methods\nstruggle with unseen news due to their reliance on training data from past\nevents and domains, leaving the challenge of detecting novel fake news largely\nunresolved. To address this, we identify biases in training data tied to\nspecific domains and propose a debiasing solution FNDCD. Originating from\ncausal analysis, FNDCD employs a reweighting strategy based on classification\nconfidence and propagation structure regularization to reduce the influence of\ndomain-specific biases, enhancing the detection of unseen fake news.\nExperiments on real-world datasets with non-overlapping news domains\ndemonstrate FNDCD's effectiveness in improving generalization across domains.",
      "tldr_zh": "该研究提出了一种基于因果去偏(FNDCD)的新方法来检测未见过的虚假新闻。通过因果分析发现现有方法存在对特定领域训练数据的依赖偏差，FNDCD采用基于分类置信度的重加权策略和传播结构正则化来降低领域特异性偏差的影响。实验结果表明，该方案能有效提升模型在非重叠新闻领域数据集上的泛化能力，解决了现有方法难以检测新型虚假新闻的问题。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "2025 The Web Conference, 6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04160v1",
      "published_date": "2025-03-06 07:23:44 UTC",
      "updated_date": "2025-03-06 07:23:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:40:39.043356"
    },
    {
      "arxiv_id": "2503.04154v1",
      "title": "CA-W3D: Leveraging Context-Aware Knowledge for Weakly Supervised Monocular 3D Detection",
      "title_zh": "CA-W3D：利用上下文感知知识实现弱监督单目3D检测",
      "authors": [
        "Chupeng Liu",
        "Runkai Zhao",
        "Weidong Cai"
      ],
      "abstract": "Weakly supervised monocular 3D detection, while less annotation-intensive,\noften struggles to capture the global context required for reliable 3D\nreasoning. Conventional label-efficient methods focus on object-centric\nfeatures, neglecting contextual semantic relationships that are critical in\ncomplex scenes. In this work, we propose a Context-Aware Weak Supervision for\nMonocular 3D object detection, namely CA-W3D, to address this limitation in a\ntwo-stage training paradigm. Specifically, we first introduce a pre-training\nstage employing Region-wise Object Contrastive Matching (ROCM), which aligns\nregional object embeddings derived from a trainable monocular 3D encoder and a\nfrozen open-vocabulary 2D visual grounding model. This alignment encourages the\nmonocular encoder to discriminate scene-specific attributes and acquire richer\ncontextual knowledge. In the second stage, we incorporate a pseudo-label\ntraining process with a Dual-to-One Distillation (D2OD) mechanism, which\neffectively transfers contextual priors into the monocular encoder while\npreserving spatial fidelity and maintaining computational efficiency during\ninference. Extensive experiments conducted on the public KITTI benchmark\ndemonstrate the effectiveness of our approach, surpassing the SoTA method over\nall metrics, highlighting the importance of contextual-aware knowledge in\nweakly-supervised monocular 3D detection.",
      "tldr_zh": "本文提出了一种基于上下文感知的弱监督单目3D检测方法CA-W3D，通过两阶段训练范式解决现有方法忽视场景语义关系的问题。第一阶段采用区域目标对比匹配(ROCM)预训练，使单目3D编码器学习场景特定属性和丰富上下文知识；第二阶段通过双对一蒸馏(D2OD)机制将上下文先验知识有效迁移到单目编码器中。在KITTI基准测试中，该方法在所有指标上均超过现有最优方法，证明了上下文感知知识对弱监督单目3D检测的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The paper includes 8 pages, 6 figures and 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.04154v1",
      "published_date": "2025-03-06 07:02:13 UTC",
      "updated_date": "2025-03-06 07:02:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:40:43.791777"
    },
    {
      "arxiv_id": "2503.04153v1",
      "title": "KidneyTalk-open: No-code Deployment of a Private Large Language Model with Medical Documentation-Enhanced Knowledge Database for Kidney Disease",
      "title_zh": "KidneyTalk-open：基于医疗文档增强知识库的肾病专用大语言模型无代码部署方案",
      "authors": [
        "Yongchao Long",
        "Chao Yang",
        "Gongzheng Tang",
        "Jinwei Wang",
        "Zhun Sui",
        "Yuxi Zhou",
        "Shenda Hong",
        "Luxia Zhang"
      ],
      "abstract": "Privacy-preserving medical decision support for kidney disease requires\nlocalized deployment of large language models (LLMs) while maintaining clinical\nreasoning capabilities. Current solutions face three challenges: 1) Cloud-based\nLLMs pose data security risks; 2) Local model deployment demands technical\nexpertise; 3) General LLMs lack mechanisms to integrate medical knowledge.\nRetrieval-augmented systems also struggle with medical document processing and\nclinical usability. We developed KidneyTalk-open, a desktop system integrating\nthree technical components: 1) No-code deployment of state-of-the-art (SOTA)\nopen-source LLMs (such as DeepSeek-r1, Qwen2.5) via local inference engine; 2)\nMedical document processing pipeline combining context-aware chunking and\nintelligent filtering; 3) Adaptive Retrieval and Augmentation Pipeline (AddRep)\nemploying agents collaboration for improving the recall rate of medical\ndocuments. A graphical interface was designed to enable clinicians to manage\nmedical documents and conduct AI-powered consultations without technical\nexpertise. Experimental validation on 1,455 challenging nephrology exam\nquestions demonstrates AddRep's effectiveness: achieving 29.1% accuracy (+8.1%\nover baseline) with intelligent knowledge integration, while maintaining\nrobustness through 4.9% rejection rate to suppress hallucinations. Comparative\ncase studies with the mainstream products (AnythingLLM, Chatbox, GPT4ALL)\ndemonstrate KidneyTalk-open's superior performance in real clinical query.\nKidneyTalk-open represents the first no-code medical LLM system enabling secure\ndocumentation-enhanced medical Q&A on desktop. Its designs establishes a new\nframework for privacy-sensitive clinical AI applications. The system\nsignificantly lowers technical barriers while improving evidence traceability,\nenabling more medical staff or patients to use SOTA open-source LLMs\nconveniently.",
      "tldr_zh": "该研究提出了KidneyTalk-open，一个无需代码即可部署的私有大型语言模型(LLM)系统，专为肾病医学决策支持设计。系统结合了三个关键技术：1) 通过本地推理引擎实现开源LLM的无代码部署；2) 医学文档处理管道，结合上下文感知分块和智能过滤；3) 自适应检索与增强管道(AddRep)，通过智能体协作提高医学文档召回率。实验表明，AddRep在1455个肾病考试问题上实现了29.1%的准确率，较基线提升8.1%，同时通过4.9%的拒绝率有效抑制幻觉。KidneyTalk-open显著降低了技术门槛，为隐私敏感的临床AI应用提供了新框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Corresponding authors: zhanglx@bjmu.edu.cn; joy_yuxi@pku.edu.cn;\n  hongshenda@pku.edu.cn",
      "pdf_url": "http://arxiv.org/pdf/2503.04153v1",
      "published_date": "2025-03-06 07:01:36 UTC",
      "updated_date": "2025-03-06 07:01:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:40:59.831535"
    },
    {
      "arxiv_id": "2503.04151v1",
      "title": "Robust Multi-View Learning via Representation Fusion of Sample-Level Attention and Alignment of Simulated Perturbation",
      "title_zh": "《鲁棒多视图学习：基于样本级注意力表征融合与模拟扰动对齐的方法》",
      "authors": [
        "Jie Xu",
        "Na Zhao",
        "Gang Niu",
        "Masashi Sugiyama",
        "Xiaofeng Zhu"
      ],
      "abstract": "Recently, multi-view learning (MVL) has garnered significant attention due to\nits ability to fuse discriminative information from multiple views. However,\nreal-world multi-view datasets are often heterogeneous and imperfect, which\nusually makes MVL methods designed for specific combinations of views lack\napplication potential and limits their effectiveness. To address this issue, we\npropose a novel robust MVL method (namely RML) with simultaneous representation\nfusion and alignment. Specifically, we introduce a simple yet effective\nmulti-view transformer fusion network where we transform heterogeneous\nmulti-view data into homogeneous word embeddings, and then integrate multiple\nviews by the sample-level attention mechanism to obtain a fused representation.\nFurthermore, we propose a simulated perturbation based multi-view contrastive\nlearning framework that dynamically generates the noise and unusable\nperturbations for simulating imperfect data conditions. The simulated noisy and\nunusable data obtain two distinct fused representations, and we utilize\ncontrastive learning to align them for learning discriminative and robust\nrepresentations. Our RML is self-supervised and can also be applied for\ndownstream tasks as a regularization. In experiments, we employ it in\nunsupervised multi-view clustering, noise-label classification, and as a\nplug-and-play module for cross-modal hashing retrieval. Extensive comparison\nexperiments and ablation studies validate the effectiveness of RML.",
      "tldr_zh": "本文提出了一种鲁棒的多视图学习方法RML，通过样本级注意力机制和模拟扰动的对齐实现表示融合。该方法利用多视图Transformer融合网络将异构数据转化为同构词嵌入，并通过样本级注意力机制融合多视图表示。此外，提出了一种基于模拟扰动的多视图对比学习框架，动态生成噪声和不可用扰动以模拟不完美数据条件，并通过对比学习对齐不同扰动下的表示，从而学习判别性和鲁棒的表示。实验表明，RML在无监督多视图聚类、噪声标签分类和跨模态哈希检索等任务中表现优异。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04151v1",
      "published_date": "2025-03-06 07:01:08 UTC",
      "updated_date": "2025-03-06 07:01:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:41:15.199126"
    },
    {
      "arxiv_id": "2503.04150v2",
      "title": "Ticktack : Long Span Temporal Alignment of Large Language Models Leveraging Sexagenary Cycle Time Expression",
      "title_zh": "Ticktack：利用干支纪年时间表达实现大语言模型的长时段时间对齐",
      "authors": [
        "Xue Han",
        "Qian Hu",
        "Yitong Wang",
        "Wenchun Gao",
        "Lianlian Zhang",
        "Qing Wang",
        "Lijun Mei",
        "Chao Deng",
        "Junlan Feng"
      ],
      "abstract": "Large language models (LLMs) suffer from temporal misalignment issues\nespecially across long span of time. The issue arises from knowing that LLMs\nare trained on large amounts of data where temporal information is rather\nsparse over long times, such as thousands of years, resulting in insufficient\nlearning or catastrophic forgetting by the LLMs. This paper proposes a\nmethodology named \"Ticktack\" for addressing the LLM's long-time span\nmisalignment in a yearly setting. Specifically, we first propose to utilize the\nsexagenary year expression instead of the Gregorian year expression employed by\nLLMs, achieving a more uniform distribution in yearly granularity. Then, we\nemploy polar coordinates to model the sexagenary cycle of 60 terms and the year\norder within each term, with additional temporal encoding to ensure LLMs\nunderstand them. Finally, we present a temporal representational alignment\napproach for post-training LLMs that effectively distinguishes time points with\nrelevant knowledge, hence improving performance on time-related tasks,\nparticularly over a long period. We also create a long time span benchmark for\nevaluation. Experimental results prove the effectiveness of our proposal.",
      "tldr_zh": "本研究提出\"Ticktack\"方法，通过引入中国传统干支纪年法(Sexagenary Cycle)替代公历纪年，解决大语言模型(LLMs)在长时间跨度上的时间对齐问题。该方法采用极坐标系建模60年干支循环周期及其内部年份顺序，配合专门的时间编码机制，使LLMs能更均匀地理解长时段时序关系。实验表明，这种时间表征对齐方法显著提升了LLMs在长时间跨度任务中的表现，并建立了专门的长时间跨度评测基准进行验证。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04150v2",
      "published_date": "2025-03-06 06:59:09 UTC",
      "updated_date": "2025-03-07 09:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:41:28.262345"
    },
    {
      "arxiv_id": "2503.04149v1",
      "title": "Dynamic Benchmarking of Reasoning Capabilities in Code Large Language Models Under Data Contamination",
      "title_zh": "数据污染环境下代码大语言模型推理能力的动态基准评测",
      "authors": [
        "Simin Chen",
        "Pranav Pusarla",
        "Baishakhi Ray"
      ],
      "abstract": "The rapid evolution of code largelanguage models underscores the need for\neffective and transparent benchmarking of their reasoning capabilities.\nHowever, the current benchmarking approach heavily depends on publicly\navailable, human-created datasets. The widespread use of these fixed benchmark\ndatasets makes the benchmarking process to be static and thus particularly\nsusceptible to data contamination, an unavoidable consequence of the extensive\ndata collection processes used to train Code LLMs. Existing approaches that\naddress data contamination often suffer from human effort limitations and\nimbalanced problem complexity. To tackle these challenges, we propose \\tool, a\nnovel benchmarking suite for evaluating Code LLMs under potential data\ncontamination. Given a seed programming problem, \\tool employs multiple agents\nto extract and modify the context without altering the core logic, generating\nsemantically equivalent variations. We introduce a dynamic data generation\nmethods and conduct empirical studies on two seed datasets across 21 Code LLMs.\nResults show that \\tool effectively benchmarks reasoning capabilities under\ncontamination risks while generating diverse problem sets to ensure consistent\nand reliable evaluations.",
      "tldr_zh": "该研究提出了一个名为\"动态基准测试套件\"的新方法，用于评估代码大语言模型(Code LLMs)在数据污染情况下的推理能力。该方法通过多智能体系统对种子编程问题进行语义等价的上下文修改，生成多样化变体，同时保持核心逻辑不变。实验在21个Code LLMs和两个种子数据集上进行，结果表明该工具能有效评估模型在数据污染风险下的推理性能，并生成多样化问题集以确保评估的一致性和可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "https://codekaleidoscope.github.io/dycodeeval.html",
      "pdf_url": "http://arxiv.org/pdf/2503.04149v1",
      "published_date": "2025-03-06 06:56:59 UTC",
      "updated_date": "2025-03-06 06:56:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:41:49.300004"
    },
    {
      "arxiv_id": "2503.04144v1",
      "title": "DM-Adapter: Domain-Aware Mixture-of-Adapters for Text-Based Person Retrieval",
      "title_zh": "DM-Adapter：面向文本行人检索的领域感知混合适配器",
      "authors": [
        "Yating Liu",
        "Zimo Liu",
        "Xiangyuan Lan",
        "Wenming Yang",
        "Yaowei Li",
        "Qingmin Liao"
      ],
      "abstract": "Text-based person retrieval (TPR) has gained significant attention as a\nfine-grained and challenging task that closely aligns with practical\napplications. Tailoring CLIP to person domain is now a emerging research topic\ndue to the abundant knowledge of vision-language pretraining, but challenges\nstill remain during fine-tuning: (i) Previous full-model fine-tuning in TPR is\ncomputationally expensive and prone to overfitting.(ii) Existing\nparameter-efficient transfer learning (PETL) for TPR lacks of fine-grained\nfeature extraction. To address these issues, we propose Domain-Aware\nMixture-of-Adapters (DM-Adapter), which unifies Mixture-of-Experts (MOE) and\nPETL to enhance fine-grained feature representations while maintaining\nefficiency. Specifically, Sparse Mixture-of-Adapters is designed in parallel to\nMLP layers in both vision and language branches, where different experts\nspecialize in distinct aspects of person knowledge to handle features more\nfinely. To promote the router to exploit domain information effectively and\nalleviate the routing imbalance, Domain-Aware Router is then developed by\nbuilding a novel gating function and injecting learnable domain-aware prompts.\nExtensive experiments show that our DM-Adapter achieves state-of-the-art\nperformance, outperforming previous methods by a significant margin.",
      "tldr_zh": "本文提出DM-Adapter，一种面向文本行人检索(TPR)任务的领域感知混合适配器方法。该方法创新性地结合混合专家(MoE)和参数高效迁移学习(PETL)技术，通过在CLIP模型的视觉和语言分支并行部署稀疏混合适配器，实现细粒度特征提取。为解决路由不平衡问题，研究者设计了包含可学习领域感知提示的新型门控函数，有效利用领域信息。实验表明，该方法在保持高效的同时显著超越现有技术，为文本行人检索领域提供了新的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 5 figures, accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04144v1",
      "published_date": "2025-03-06 06:41:38 UTC",
      "updated_date": "2025-03-06 06:41:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:41:52.857028"
    },
    {
      "arxiv_id": "2503.04143v1",
      "title": "MTS: A Deep Reinforcement Learning Portfolio Management Framework with Time-Awareness and Short-Selling",
      "title_zh": "MTS：具备时间感知与卖空机制的深度强化学习投资组合管理框架",
      "authors": [
        "Fengchen Gu",
        "Zhengyong Jiang",
        "Ángel F. García-Fernández",
        "Angelos Stefanidis",
        "Jionglong Su",
        "Huakang Li"
      ],
      "abstract": "Portfolio management remains a crucial challenge in finance, with traditional\nmethods often falling short in complex and volatile market environments. While\ndeep reinforcement approaches have shown promise, they still face limitations\nin dynamic risk management, exploitation of temporal markets, and incorporation\nof complex trading strategies such as short-selling. These limitations can lead\nto suboptimal portfolio performance, increased vulnerability to market\nvolatility, and missed opportunities in capturing potential returns from\ndiverse market conditions. This paper introduces a Deep Reinforcement Learning\nPortfolio Management Framework with Time-Awareness and Short-Selling (MTS),\noffering a robust and adaptive strategy for sustainable investment performance.\nThis framework utilizes a novel encoder-attention mechanism to address the\nlimitations by incorporating temporal market characteristics, a parallel\nstrategy for automated short-selling based on market trends, and risk\nmanagement through innovative Incremental Conditional Value at Risk, enhancing\nadaptability and performance. Experimental validation on five diverse datasets\nfrom 2019 to 2023 demonstrates MTS's superiority over traditional algorithms\nand advanced machine learning techniques. MTS consistently achieves higher\ncumulative returns, Sharpe, Omega, and Sortino ratios, underscoring its\neffectiveness in balancing risk and return while adapting to market dynamics.\nMTS demonstrates an average relative increase of 30.67% in cumulative returns\nand 29.33% in Sharpe ratio compared to the next best-performing strategies\nacross various datasets.",
      "tldr_zh": "本文提出了一种结合时间感知和卖空机制的深度强化学习投资组合管理框架MTS，旨在解决传统方法在复杂和波动的市场环境中的不足。该框架通过新颖的编码器-注意力机制捕捉时间市场特征，采用并行策略实现基于市场趋势的自动化卖空，并通过创新的增量条件风险价值（Incremental Conditional Value at Risk）进行风险管理。实验验证表明，MTS在2019年至2023年的五个多样化数据集上表现优异，相比其他策略，其累积回报率和夏普比率分别平均提高了30.67%和29.33%，展现了其在平衡风险与回报方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04143v1",
      "published_date": "2025-03-06 06:41:17 UTC",
      "updated_date": "2025-03-06 06:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:41:50.331316"
    },
    {
      "arxiv_id": "2503.04128v1",
      "title": "Artificial Intelligence in Pronunciation Teaching: Use and Beliefs of Foreign Language Teachers",
      "title_zh": "人工智能在发音教学中的应用：外语教师的使用现状与认知态度",
      "authors": [
        "Georgios P. Georgiou"
      ],
      "abstract": "Pronunciation instruction in foreign language classrooms has often been an\noverlooked area of focus. With the widespread adoption of Artificial\nIntelligence (AI) and its potential benefits, investigating how AI is utilized\nin pronunciation teaching and understanding the beliefs of teachers about this\ntool is essential for improving learning outcomes. This study aims to examine\nhow AI use for pronunciation instruction varies across different demographic\nand professional factors among teachers, and how these factors, including AI\nuse, influence the beliefs of teachers about AI. The study involved 117 English\nas a Foreign Language (EFL) in-service teachers working in Cyprus, who\ncompleted an online survey designed to assess their beliefs about the\neffectiveness of AI, its drawbacks, and their willingness to integrate AI into\ntheir teaching practices. The results revealed that teachers were significantly\nmore likely to agree on the perceived effectiveness of AI and their willingness\nto adopt it, compared to their concerns about its use. Furthermore, teachers\nworking in higher education and adult education, as well as those who had\nreceived more extensive training, reported using AI more frequently in their\nteaching. Teachers who utilized AI more often expressed stronger agreement with\nits effectiveness, while those who had received more training were less likely\nto express concerns about its integration. Given the limited training that many\nteachers currently receive, these findings demonstrate the need for tailored\ntraining sessions that address the specific needs and concerns of educators,\nultimately fostering the adoption of AI in pronunciation instruction.",
      "tldr_zh": "这项研究调查了外语教师对人工智能（AI）在发音教学中的应用及其态度。通过对塞浦路斯117名在职英语教师的调查发现，教师普遍认同AI的有效性并愿意将其融入教学，但对使用仍存在顾虑。高等教育和成人教育领域的教师，以及接受过更多培训的教师更频繁地使用AI。研究强调，需要针对教师的具体需求和顾虑提供定制化培训，以促进AI在发音教学中的广泛应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04128v1",
      "published_date": "2025-03-06 06:14:27 UTC",
      "updated_date": "2025-03-06 06:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:42:05.930150"
    },
    {
      "arxiv_id": "2503.04853v1",
      "title": "From Pixels to Trajectory: Universal Adversarial Example Detection via Temporal Imprints",
      "title_zh": "从像素到轨迹：基于时间印记的通用对抗样本检测",
      "authors": [
        "Yansong Gao",
        "Huaibing Peng",
        "Hua Ma",
        "Zhiyang Dai",
        "Shuo Wang",
        "Hongsheng Hu",
        "Anmin Fu",
        "Minhui Xue"
      ],
      "abstract": "For the first time, we unveil discernible temporal (or historical) trajectory\nimprints resulting from adversarial example (AE) attacks. Standing in contrast\nto existing studies all focusing on spatial (or static) imprints within the\ntargeted underlying victim models, we present a fresh temporal paradigm for\nunderstanding these attacks. Of paramount discovery is that these imprints are\nencapsulated within a single loss metric, spanning universally across diverse\ntasks such as classification and regression, and modalities including image,\ntext, and audio. Recognizing the distinct nature of loss between adversarial\nand clean examples, we exploit this temporal imprint for AE detection by\nproposing TRAIT (TRaceable Adversarial temporal trajectory ImprinTs). TRAIT\noperates under minimal assumptions without prior knowledge of attacks, thereby\nframing the detection challenge as a one-class classification problem. However,\ndetecting AEs is still challenged by significant overlaps between the\nconstructed synthetic losses of adversarial and clean examples due to the\nabsence of ground truth for incoming inputs. TRAIT addresses this challenge by\nconverting the synthetic loss into a spectrum signature, using the technique of\nFast Fourier Transform to highlight the discrepancies, drawing inspiration from\nthe temporal nature of the imprints, analogous to time-series signals. Across\n12 AE attacks including SMACK (USENIX Sec'2023), TRAIT demonstrates consistent\noutstanding performance across comprehensively evaluated modalities, tasks,\ndatasets, and model architectures. In all scenarios, TRAIT achieves an AE\ndetection accuracy exceeding 97%, often around 99%, while maintaining a false\nrejection rate of 1%. TRAIT remains effective under the formulated strong\nadaptive attacks.",
      "tldr_zh": "该研究首次揭示了对抗样本攻击(AE)在时间维度上留下的可识别轨迹印记，突破了现有仅关注空间特征的研究范式。研究者提出TRAIT检测框架，通过分析对抗样本与正常样本在单一损失指标上表现出的时间轨迹差异，将其转化为频谱特征进行识别，无需预先了解攻击类型。实验表明，TRAIT在12种对抗攻击（包括SMACK）中表现优异，跨图像、文本、音频等多种模态和任务的平均检测准确率超过97%，假拒率仅1%，且能抵御强适应性攻击。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04853v1",
      "published_date": "2025-03-06 06:00:04 UTC",
      "updated_date": "2025-03-06 06:00:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:42:15.898566"
    },
    {
      "arxiv_id": "2503.04121v1",
      "title": "Simple Self Organizing Map with Visual Transformer",
      "title_zh": "结合视觉Transformer的简单自组织映射",
      "authors": [
        "Alan Luo",
        "Kaiwen Yuan"
      ],
      "abstract": "Vision Transformers (ViTs) have demonstrated exceptional performance in\nvarious vision tasks. However, they tend to underperform on smaller datasets\ndue to their inherent lack of inductive biases. Current approaches address this\nlimitation implicitly-often by pairing ViTs with pretext tasks or by distilling\nknowledge from convolutional neural networks (CNNs) to strengthen the prior. In\ncontrast, Self-Organizing Maps (SOMs), a widely adopted self-supervised\nframework, are inherently structured to preserve topology and spatial\norganization, making them a promising candidate to directly address the\nlimitations of ViTs in limited or small training datasets. Despite this\npotential, equipping SOMs with modern deep learning architectures remains\nlargely unexplored. In this study, we conduct a novel exploration on how Vision\nTransformers (ViTs) and Self-Organizing Maps (SOMs) can empower each other,\naiming to bridge this critical research gap. Our findings demonstrate that\nthese architectures can synergistically enhance each other, leading to\nsignificantly improved performance in both unsupervised and supervised tasks.\nCode will be publicly available.",
      "tldr_zh": "本研究探索了视觉Transformer（ViT）与自组织映射（SOM）的结合，旨在解决ViT在小数据集上表现不佳的问题。通过利用SOM固有的拓扑和空间组织特性，研究提出了一种新的框架，将SOM与ViT相结合，显著提升了无监督和监督任务中的性能。实验表明，这种结合能够有效弥补ViT在小数据集上缺乏归纳偏置的不足，为相关领域的研究提供了新的思路。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "65D19 (Primary)"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 4 figures. Submitted to IEEE. All experiments and code work\n  were performed by the first author, with the second author serving in a\n  PI/mentor role, guiding the progression of the work",
      "pdf_url": "http://arxiv.org/pdf/2503.04121v1",
      "published_date": "2025-03-06 05:58:41 UTC",
      "updated_date": "2025-03-06 05:58:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:42:17.968621"
    },
    {
      "arxiv_id": "2503.04111v1",
      "title": "Generalizability of Neural Networks Minimizing Empirical Risk Based on Expressive Ability",
      "title_zh": "基于表达能力的最小化经验风险神经网络的泛化性研究",
      "authors": [
        "Lijia Yu",
        "Yibo Miao",
        "Yifan Zhu",
        "Xiao-Shan Gao",
        "Lijun Zhang"
      ],
      "abstract": "The primary objective of learning methods is generalization. Classic uniform\ngeneralization bounds, which rely on VC-dimension or Rademacher complexity,\nfail to explain the significant attribute that over-parameterized models in\ndeep learning exhibit nice generalizability. On the other hand,\nalgorithm-dependent generalization bounds, like stability bounds, often rely on\nstrict assumptions. To establish generalizability under less stringent\nassumptions, this paper investigates the generalizability of neural networks\nthat minimize or approximately minimize empirical risk. We establish a lower\nbound for population accuracy based on the expressiveness of these networks,\nwhich indicates that with an adequate large number of training samples and\nnetwork sizes, these networks, including over-parameterized ones, can\ngeneralize effectively. Additionally, we provide a necessary condition for\ngeneralization, demonstrating that, for certain data distributions, the\nquantity of training data required to ensure generalization exceeds the network\nsize needed to represent the corresponding data distribution. Finally, we\nprovide theoretical insights into several phenomena in deep learning, including\nrobust generalization, importance of over-parameterization, and effect of loss\nfunction on generalization.",
      "tldr_zh": "本文研究了基于经验风险最小化的神经网络的可泛化性，提出了在较少严格假设下建立泛化性的理论框架。研究表明，在足够多的训练样本和网络规模下，包括过参数化网络在内的神经网络能够有效泛化。此外，论文揭示了某些数据分布下，确保泛化所需的训练数据量超过了表示对应数据分布所需的网络规模。研究还为深度学习中的若干现象提供了理论解释，如鲁棒泛化、过参数化的重要性以及损失函数对泛化的影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04111v1",
      "published_date": "2025-03-06 05:36:35 UTC",
      "updated_date": "2025-03-06 05:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:42:39.050219"
    },
    {
      "arxiv_id": "2503.04110v1",
      "title": "InterChat: Enhancing Generative Visual Analytics using Multimodal Interactions",
      "title_zh": "InterChat：利用多模态交互增强生成式视觉分析",
      "authors": [
        "Juntong Chen",
        "Jiang Wu",
        "Jiajing Guo",
        "Vikram Mohanty",
        "Xueming Li",
        "Jorge Piazentin Ono",
        "Wenbin He",
        "Liu Ren",
        "Dongyu Liu"
      ],
      "abstract": "The rise of Large Language Models (LLMs) and generative visual analytics\nsystems has transformed data-driven insights, yet significant challenges\npersist in accurately interpreting users' analytical and interaction intents.\nWhile language inputs offer flexibility, they often lack precision, making the\nexpression of complex intents inefficient, error-prone, and time-intensive. To\naddress these limitations, we investigate the design space of multimodal\ninteractions for generative visual analytics through a literature review and\npilot brainstorming sessions. Building on these insights, we introduce a highly\nextensible workflow that integrates multiple LLM agents for intent inference\nand visualization generation. We develop InterChat, a generative visual\nanalytics system that combines direct manipulation of visual elements with\nnatural language inputs. This integration enables precise intent communication\nand supports progressive, visually driven exploratory data analyses. By\nemploying effective prompt engineering, and contextual interaction linking,\nalongside intuitive visualization and interaction designs, InterChat bridges\nthe gap between user interactions and LLM-driven visualizations, enhancing both\ninterpretability and usability. Extensive evaluations, including two usage\nscenarios, a user study, and expert feedback, demonstrate the effectiveness of\nInterChat. Results show significant improvements in the accuracy and efficiency\nof handling complex visual analytics tasks, highlighting the potential of\nmultimodal interactions to redefine user engagement and analytical depth in\ngenerative visual analytics.",
      "tldr_zh": "该研究提出了InterChat系统，通过整合多模态交互（直接操作+自然语言）来增强生成式视觉分析能力。系统采用可扩展的多LLM智能体工作流，结合提示工程和上下文交互链接技术，有效解决了传统语言输入在表达复杂分析意图时精度不足的问题。实验证明，该系统显著提升了处理复杂视觉分析任务的准确性和效率，为生成式视觉分析提供了更直观的交互范式。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Manuscript submitted to EuroVis 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04110v1",
      "published_date": "2025-03-06 05:35:19 UTC",
      "updated_date": "2025-03-06 05:35:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:42:27.853100"
    },
    {
      "arxiv_id": "2503.04099v1",
      "title": "Disparities in LLM Reasoning Accuracy and Explanations: A Case Study on African American English",
      "title_zh": "大语言模型推理准确性与解释中的差异：以非洲裔美国人英语为例的案例研究",
      "authors": [
        "Runtao Zhou",
        "Guangya Wan",
        "Saadia Gabriel",
        "Sheng Li",
        "Alexander J Gates",
        "Maarten Sap",
        "Thomas Hartvigsen"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nreasoning tasks, leading to their widespread deployment. However, recent\nstudies have highlighted concerning biases in these models, particularly in\ntheir handling of dialectal variations like African American English (AAE). In\nthis work, we systematically investigate dialectal disparities in LLM reasoning\ntasks. We develop an experimental framework comparing LLM performance given\nStandard American English (SAE) and AAE prompts, combining LLM-based dialect\nconversion with established linguistic analyses. We find that LLMs consistently\nproduce less accurate responses and simpler reasoning chains and explanations\nfor AAE inputs compared to equivalent SAE questions, with disparities most\npronounced in social science and humanities domains. These findings highlight\nsystematic differences in how LLMs process and reason about different language\nvarieties, raising important questions about the development and deployment of\nthese systems in our multilingual and multidialectal world. Our code repository\nis publicly available at https://github.com/Runtaozhou/dialect_bias_eval.",
      "tldr_zh": "本研究系统评估了大型语言模型(LLMs)在处理非裔美国英语(AAE)和标准美国英语(SAE)时的推理准确性差异。通过结合LLM方言转换技术和语言学分析，研究发现LLMs对AAE输入的响应准确性显著低于SAE，且在社会科学和人文学科领域差异最为明显。此外，LLMs为AAE生成的推理链和解释也更简单。这些发现揭示了LLMs在处理不同语言变体时的系统性差异，对在多语言和多方言世界中的模型开发与部署提出了重要问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ARR Under Review, First two authors contribute equally",
      "pdf_url": "http://arxiv.org/pdf/2503.04099v1",
      "published_date": "2025-03-06 05:15:34 UTC",
      "updated_date": "2025-03-06 05:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:42:58.522237"
    },
    {
      "arxiv_id": "2503.04095v2",
      "title": "Chart-HQA: A Benchmark for Hypothetical Question Answering in Charts",
      "title_zh": "Chart-HQA：图表假设问答基准",
      "authors": [
        "Xiangnan Chen",
        "Yuancheng Fang",
        "Qian Xiao",
        "Juncheng Li",
        "Jun Lin",
        "Siliang Tang",
        "Yi Yang",
        "Yueting Zhuang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have garnered significant attention\nfor their strong visual-semantic understanding. Most existing chart benchmarks\nevaluate MLLMs' ability to parse information from charts to answer questions.\nHowever, they overlook the inherent output biases of MLLMs, where models rely\non their parametric memory to answer questions rather than genuinely\nunderstanding the chart content. To address this limitation, we introduce a\nnovel Chart Hypothetical Question Answering (HQA) task, which imposes\nassumptions on the same question to compel models to engage in counterfactual\nreasoning based on the chart content. Furthermore, we introduce HAI, a human-AI\ninteractive data synthesis approach that leverages the efficient text-editing\ncapabilities of LLMs alongside human expert knowledge to generate diverse and\nhigh-quality HQA data at a low cost. Using HAI, we construct Chart-HQA, a\nchallenging benchmark synthesized from publicly available data sources.\nEvaluation results on 18 MLLMs of varying model sizes reveal that current\nmodels face significant generalization challenges and exhibit imbalanced\nreasoning performance on the HQA task.",
      "tldr_zh": "该研究提出了Chart-HQA基准测试，用于评估多模态大语言模型(MLLMs)在图表假设问答(HQA)任务中的表现。通过引入反事实推理问题，该基准测试旨在克服模型依赖参数记忆而非真正理解图表内容的局限性。研究还提出了HAI方法，结合人类专家知识和LLMs的文本编辑能力，低成本生成多样化的高质量HQA数据。实验表明，现有MLLMs在HQA任务上存在显著的泛化挑战和推理性能不平衡问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2503.04095v2",
      "published_date": "2025-03-06 05:08:40 UTC",
      "updated_date": "2025-03-07 05:18:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:43:02.145009"
    },
    {
      "arxiv_id": "2503.04085v1",
      "title": "SED2AM: Solving Multi-Trip Time-Dependent Vehicle Routing Problem using Deep Reinforcement Learning",
      "title_zh": "SED2AM：利用深度强化学习解决多行程时间依赖车辆路径规划问题",
      "authors": [
        "Arash Mozhdehi",
        "Yunli Wang",
        "Sun Sun",
        "Xin Wang"
      ],
      "abstract": "Deep reinforcement learning (DRL)-based frameworks, featuring\nTransformer-style policy networks, have demonstrated their efficacy across\nvarious vehicle routing problem (VRP) variants. However, the application of\nthese methods to the multi-trip time-dependent vehicle routing problem\n(MTTDVRP) with maximum working hours constraints -- a pivotal element of urban\nlogistics -- remains largely unexplored. This paper introduces a DRL-based\nmethod called the Simultaneous Encoder and Dual Decoder Attention Model\n(SED2AM), tailored for the MTTDVRP with maximum working hours constraints. The\nproposed method introduces a temporal locality inductive bias to the encoding\nmodule of the policy networks, enabling it to effectively account for the\ntime-dependency in travel distance or time. The decoding module of SED2AM\nincludes a vehicle selection decoder that selects a vehicle from the fleet,\neffectively associating trips with vehicles for functional multi-trip routing.\nAdditionally, this decoding module is equipped with a trip construction decoder\nleveraged for constructing trips for the vehicles. This policy model is\nequipped with two classes of state representations, fleet state and routing\nstate, providing the information needed for effective route construction in the\npresence of maximum working hours constraints. Experimental results using\nreal-world datasets from two major Canadian cities not only show that SED2AM\noutperforms the current state-of-the-art DRL-based and metaheuristic-based\nbaselines but also demonstrate its generalizability to solve larger-scale\nproblems.",
      "tldr_zh": "本文提出SED2AM模型，采用深度强化学习(DRL)结合Transformer架构，专门解决带最大工作时长约束的多行程时间依赖车辆路径规划问题(MTTDVRP)。该模型创新性地在编码模块引入时间局部性归纳偏置以处理时间依赖性，并采用双解码器结构分别进行车辆选择和行程构建。实验表明，基于加拿大两大城市真实数据的测试中，SED2AM不仅超越了现有DRL和元启发式方法，还展现出优秀的大规模问题泛化能力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ACM TKDD: https://dl.acm.org/doi/10.1145/3721983",
      "pdf_url": "http://arxiv.org/pdf/2503.04085v1",
      "published_date": "2025-03-06 04:47:49 UTC",
      "updated_date": "2025-03-06 04:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:43:16.012474"
    },
    {
      "arxiv_id": "2503.04074v1",
      "title": "Can We Optimize Deep RL Policy Weights as Trajectory Modeling?",
      "title_zh": "能否将深度强化学习策略权重优化为轨迹建模？",
      "authors": [
        "Hongyao Tang"
      ],
      "abstract": "Learning the optimal policy from a random network initialization is the theme\nof deep Reinforcement Learning (RL). As the scale of DRL training increases,\ntreating DRL policy network weights as a new data modality and exploring the\npotential becomes appealing and possible. In this work, we focus on the policy\nlearning path in deep RL, represented by the trajectory of network weights of\nhistorical policies, which reflects the evolvement of the policy learning\nprocess. Taking the idea of trajectory modeling with Transformer, we propose\nTransformer as Implicit Policy Learner (TIPL), which processes policy network\nweights in an autoregressive manner. We collect the policy learning path data\nby running independent RL training trials, with which we then train our TIPL\nmodel. In the experiments, we demonstrate that TIPL is able to fit the implicit\ndynamics of policy learning and perform the optimization of policy network by\ninference.",
      "tldr_zh": "本研究提出了一种新的深度强化学习（DRL）策略优化方法，将策略网络权重视为一种新的数据模态，并通过Transformer模型对其进行轨迹建模。作者提出了Transformer as Implicit Policy Learner (TIPL)，以自回归方式处理策略网络权重，并利用独立RL训练试验收集的策略学习路径数据进行训练。实验表明，TIPL能够拟合策略学习的隐式动态，并通过推理优化策略网络，为大规模DRL训练提供了新的思路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as an extended abstract to ICLR 2025 Workshop on Weight\n  Space Learning (WSL)",
      "pdf_url": "http://arxiv.org/pdf/2503.04074v1",
      "published_date": "2025-03-06 04:12:22 UTC",
      "updated_date": "2025-03-06 04:12:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:43:20.948861"
    },
    {
      "arxiv_id": "2503.04065v2",
      "title": "PP-DocBee: Improving Multimodal Document Understanding Through a Bag of Tricks",
      "title_zh": "PP-DocBee：通过一系列技巧提升多模态文档理解能力",
      "authors": [
        "Feng Ni",
        "Kui Huang",
        "Yao Lu",
        "Wenyu Lv",
        "Guanzhong Wang",
        "Zeyu Chen",
        "Yi Liu"
      ],
      "abstract": "With the rapid advancement of digitalization, various document images are\nbeing applied more extensively in production and daily life, and there is an\nincreasingly urgent need for fast and accurate parsing of the content in\ndocument images. Therefore, this report presents PP-DocBee, a novel multimodal\nlarge language model designed for end-to-end document image understanding.\nFirst, we develop a data synthesis strategy tailored to document scenarios in\nwhich we build a diverse dataset to improve the model generalization. Then, we\napply a few training techniques, including dynamic proportional sampling, data\npreprocessing, and OCR postprocessing strategies. Extensive evaluations\ndemonstrate the superior performance of PP-DocBee, achieving state-of-the-art\nresults on English document understanding benchmarks and even outperforming\nexisting open source and commercial models in Chinese document understanding.\nThe source code and pre-trained models are publicly available at\n\\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.",
      "tldr_zh": "该研究提出了PP-DocBee，一种用于端到端文档图像理解的多模态大语言模型。通过开发针对文档场景的数据合成策略，结合动态比例采样、数据预处理和OCR后处理等技术，显著提升了模型的泛化能力。实验表明，PP-DocBee在英文文档理解基准测试中取得了最先进的性能，并在中文文档理解任务中超越了现有的开源和商业模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04065v2",
      "published_date": "2025-03-06 03:43:21 UTC",
      "updated_date": "2025-03-10 03:22:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:43:24.752601"
    },
    {
      "arxiv_id": "2503.04064v1",
      "title": "Uncovering inequalities in new knowledge learning by large language models across different languages",
      "title_zh": "揭示大型语言模型在不同语言间新知识学习的不平等现象",
      "authors": [
        "Chenglong Wang",
        "Haoyu Tang",
        "Xiyuan Yang",
        "Yueqi Xie",
        "Jina Suh",
        "Sunayana Sitaram",
        "Junming Huang",
        "Yu Xie",
        "Zhaoya Gong",
        "Xing Xie",
        "Fangzhao Wu"
      ],
      "abstract": "As large language models (LLMs) gradually become integral tools for problem\nsolving in daily life worldwide, understanding linguistic inequality is\nbecoming increasingly important. Existing research has primarily focused on\nstatic analyses that assess the disparities in the existing knowledge and\ncapabilities of LLMs across languages. However, LLMs are continuously evolving,\nacquiring new knowledge to generate up-to-date, domain-specific responses.\nInvestigating linguistic inequalities within this dynamic process is,\ntherefore, also essential. In this paper, we explore inequalities in new\nknowledge learning by LLMs across different languages and four key dimensions:\neffectiveness, transferability, prioritization, and robustness. Through\nextensive experiments under two settings (in-context learning and fine-tuning)\nusing both proprietary and open-source models, we demonstrate that low-resource\nlanguages consistently face disadvantages across all four dimensions. By\nshedding light on these disparities, we aim to raise awareness of linguistic\ninequalities in LLMs' new knowledge learning, fostering the development of more\ninclusive and equitable future LLMs.",
      "tldr_zh": "本研究揭示了大语言模型(LLMs)在不同语言间学习新知识时存在的不平等现象。通过实验分析，研究发现低资源语言在有效性、迁移性、优先级和鲁棒性四个维度上均处于劣势。该研究采用上下文学习和微调两种设置，结合商用和开源模型进行广泛实验，旨在提高对LLMs新知识学习中语言不平等问题的认识，推动未来开发更具包容性和公平性的LLMs。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04064v1",
      "published_date": "2025-03-06 03:41:47 UTC",
      "updated_date": "2025-03-06 03:41:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:43:32.253908"
    },
    {
      "arxiv_id": "2503.04046v1",
      "title": "Continual Optimization with Symmetry Teleportation for Multi-Task Learning",
      "title_zh": "基于对称传送的持续优化方法在多任务学习中的应用",
      "authors": [
        "Zhipeng Zhou",
        "Ziqiao Meng",
        "Pengcheng Wu",
        "Peilin Zhao",
        "Chunyan Miao"
      ],
      "abstract": "Multi-task learning (MTL) is a widely explored paradigm that enables the\nsimultaneous learning of multiple tasks using a single model. Despite numerous\nsolutions, the key issues of optimization conflict and task imbalance remain\nunder-addressed, limiting performance. Unlike existing optimization-based\napproaches that typically reweight task losses or gradients to mitigate\nconflicts or promote progress, we propose a novel approach based on Continual\nOptimization with Symmetry Teleportation (COST). During MTL optimization, when\nan optimization conflict arises, we seek an alternative loss-equivalent point\non the loss landscape to reduce conflict. Specifically, we utilize a low-rank\nadapter (LoRA) to facilitate this practical teleportation by designing\nconvergent, loss-invariant objectives. Additionally, we introduce a historical\ntrajectory reuse strategy to continually leverage the benefits of advanced\noptimizers. Extensive experiments on multiple mainstream datasets demonstrate\nthe effectiveness of our approach. COST is a plug-and-play solution that\nenhances a wide range of existing MTL methods. When integrated with\nstate-of-the-art methods, COST achieves superior performance.",
      "tldr_zh": "本研究提出了一种基于对称传送的持续优化方法（COST），用于解决多任务学习（MTL）中的优化冲突和任务不平衡问题。与传统方法通过重新加权任务损失或梯度来缓解冲突不同，COST在优化冲突发生时，通过低秩适配器（LoRA）在损失景观中寻找等效点以减少冲突，并结合历史轨迹重用策略持续利用优化器的优势。实验表明，COST作为一种即插即用的解决方案，能够显著提升多种现有MTL方法的性能，并在与先进方法结合时表现优异。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages,8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04046v1",
      "published_date": "2025-03-06 02:58:09 UTC",
      "updated_date": "2025-03-06 02:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:44:31.909269"
    },
    {
      "arxiv_id": "2503.04021v1",
      "title": "TextDoctor: Unified Document Image Inpainting via Patch Pyramid Diffusion Models",
      "title_zh": "TextDoctor：基于块金字塔扩散模型的统一文档图像修复方法",
      "authors": [
        "Wanglong Lu",
        "Lingming Su",
        "Jingjing Zheng",
        "Vinícius Veloso de Melo",
        "Farzaneh Shoeleh",
        "John Hawkin",
        "Terrence Tricco",
        "Hanli Zhao",
        "Xianta Jiang"
      ],
      "abstract": "Digital versions of real-world text documents often suffer from issues like\nenvironmental corrosion of the original document, low-quality scanning, or\nhuman interference. Existing document restoration and inpainting methods\ntypically struggle with generalizing to unseen document styles and handling\nhigh-resolution images. To address these challenges, we introduce TextDoctor, a\nnovel unified document image inpainting method. Inspired by human reading\nbehavior, TextDoctor restores fundamental text elements from patches and then\napplies diffusion models to entire document images instead of training models\non specific document types. To handle varying text sizes and avoid\nout-of-memory issues, common in high-resolution documents, we propose using\nstructure pyramid prediction and patch pyramid diffusion models. These\ntechniques leverage multiscale inputs and pyramid patches to enhance the\nquality of inpainting both globally and locally. Extensive qualitative and\nquantitative experiments on seven public datasets validated that TextDoctor\noutperforms state-of-the-art methods in restoring various types of\nhigh-resolution document images.",
      "tldr_zh": "本文提出TextDoctor，一种基于Patch Pyramid Diffusion Models的统一文档图像修复方法。该方法受人类阅读行为启发，通过从局部修复基本文本元素，再对整个文档图像应用扩散模型，避免了针对特定文档类型的训练。创新性地采用结构金字塔预测和补丁金字塔扩散模型，解决了高分辨率文档处理中的内存问题和多尺度文本修复难题。在7个公开数据集上的实验表明，该方法在各类高分辨率文档图像修复任务中均优于现有最优方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68U10",
        "I.4.3; I.4.4; I.4.5; I.4.9"
      ],
      "primary_category": "cs.CV",
      "comment": "28 pages, 25 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04021v1",
      "published_date": "2025-03-06 02:16:35 UTC",
      "updated_date": "2025-03-06 02:16:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:43:49.929385"
    },
    {
      "arxiv_id": "2503.07643v1",
      "title": "ConstellationNet: Reinventing Spatial Clustering through GNNs",
      "title_zh": "ConstellationNet：通过图神经网络重构空间聚类",
      "authors": [
        "Aidan Gao",
        "Junhong Lin"
      ],
      "abstract": "Spatial clustering is a crucial field, finding universal use across\ncriminology, pathology, and urban planning. However, most spatial clustering\nalgorithms cannot pull information from nearby nodes and suffer performance\ndrops when dealing with higher dimensionality and large datasets, making them\nsuboptimal for large-scale and high-dimensional clustering. Due to modern data\ngrowing in size and dimension, clustering algorithms become weaker when\naddressing multifaceted issues. To improve upon this, we develop\nConstellationNet, a convolution neural network(CNN)-graph neural network(GNN)\nframework that leverages the embedding power of a CNN, the neighbor aggregation\nof a GNN, and a neural network's ability to deal with batched data to improve\nspatial clustering and classification with graph augmented predictions.\nConstellationNet achieves state-of-the-art performance on both supervised\nclassification and unsupervised clustering across several datasets,\noutperforming state-of-the-art classification and clustering while reducing\nmodel size and training time by up to tenfold and improving baselines by 10\ntimes. Because of its fast training and powerful nature, ConstellationNet holds\npromise in fields like epidemiology and medical imaging, able to quickly train\non new data to develop robust responses.",
      "tldr_zh": "该研究提出了ConstellationNet，一种结合卷积神经网络(CNN)和图神经网络(GNN)的新型空间聚类框架。该模型通过CNN的嵌入能力和GNN的邻域聚合特性，有效解决了传统空间聚类算法在处理高维大数据时性能下降的问题。实验表明，ConstellationNet在监督分类和无监督聚类任务上均达到最先进水平，模型大小和训练时间减少高达10倍，性能比基线提升10倍。该框架在流行病学和医学影像等领域具有应用潜力，能快速训练新数据并生成鲁棒响应。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.07643v1",
      "published_date": "2025-03-06 02:10:11 UTC",
      "updated_date": "2025-03-06 02:10:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:44:15.235003"
    },
    {
      "arxiv_id": "2503.04013v1",
      "title": "Benchmarking Large Language Models on Multiple Tasks in Bioinformatics NLP with Prompting",
      "title_zh": "基于提示的生物信息学自然语言处理多任务大语言模型基准测试",
      "authors": [
        "Jiyue Jiang",
        "Pengan Chen",
        "Jiuming Wang",
        "Dongchen He",
        "Ziqin Wei",
        "Liang Hong",
        "Licheng Zong",
        "Sheng Wang",
        "Qinze Yu",
        "Zixian Ma",
        "Yanyu Chen",
        "Yimin Fan",
        "Xiangyu Shi",
        "Jiawei Sun",
        "Chuan Wu",
        "Yu Li"
      ],
      "abstract": "Large language models (LLMs) have become important tools in solving\nbiological problems, offering improvements in accuracy and adaptability over\nconventional methods. Several benchmarks have been proposed to evaluate the\nperformance of these LLMs. However, current benchmarks can hardly evaluate the\nperformance of these models across diverse tasks effectively. In this paper, we\nintroduce a comprehensive prompting-based benchmarking framework, termed\nBio-benchmark, which includes 30 key bioinformatics tasks covering areas such\nas proteins, RNA, drugs, electronic health records, and traditional Chinese\nmedicine. Using this benchmark, we evaluate six mainstream LLMs, including\nGPT-4o and Llama-3.1-70b, etc., using 0-shot and few-shot Chain-of-Thought\n(CoT) settings without fine-tuning to reveal their intrinsic capabilities. To\nimprove the efficiency of our evaluations, we demonstrate BioFinder, a new tool\nfor extracting answers from LLM responses, which increases extraction accuracy\nby round 30% compared to existing methods. Our benchmark results show the\nbiological tasks suitable for current LLMs and identify specific areas\nrequiring enhancement. Furthermore, we propose targeted prompt engineering\nstrategies for optimizing LLM performance in these contexts. Based on these\nfindings, we provide recommendations for the development of more robust LLMs\ntailored for various biological applications. This work offers a comprehensive\nevaluation framework and robust tools to support the application of LLMs in\nbioinformatics.",
      "tldr_zh": "该研究提出了Bio-benchmark，一种基于提示的综合性评估框架，用于评测大语言模型(LLMs)在生物信息学自然语言处理中的表现。该框架涵盖30项关键任务，涉及蛋白质、RNA、药物、电子健康记录和传统中医等领域，并在0-shot和few-shot链式思维推理(CoT)设置下评测了GPT-4o和Llama-3.1-70b等主流模型。研究还开发了BioFinder工具，用于高效提取LLM响应，准确率提升约30%。实验结果揭示了LLMs在生物任务中的适用性及改进方向，并提出了针对性的提示工程策略，为开发生物信息学专用LLMs提供了参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04013v1",
      "published_date": "2025-03-06 02:01:59 UTC",
      "updated_date": "2025-03-06 02:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:44:14.303569"
    },
    {
      "arxiv_id": "2503.03995v1",
      "title": "Subgraph Federated Learning for Local Generalization",
      "title_zh": "子图联邦学习：面向局部泛化的方法",
      "authors": [
        "Sungwon Kim",
        "Yoonho Lee",
        "Yunhak Oh",
        "Namkyeong Lee",
        "Sukwon Yun",
        "Junseok Lee",
        "Sein Kim",
        "Carl Yang",
        "Chanyoung Park"
      ],
      "abstract": "Federated Learning (FL) on graphs enables collaborative model training to\nenhance performance without compromising the privacy of each client. However,\nexisting methods often overlook the mutable nature of graph data, which\nfrequently introduces new nodes and leads to shifts in label distribution.\nSince they focus solely on performing well on each client's local data, they\nare prone to overfitting to their local distributions (i.e., local\noverfitting), which hinders their ability to generalize to unseen data with\ndiverse label distributions. In contrast, our proposed method, FedLoG,\neffectively tackles this issue by mitigating local overfitting. Our model\ngenerates global synthetic data by condensing the reliable information from\neach class representation and its structural information across clients. Using\nthese synthetic data as a training set, we alleviate the local overfitting\nproblem by adaptively generalizing the absent knowledge within each local\ndataset. This enhances the generalization capabilities of local models,\nenabling them to handle unseen data effectively. Our model outperforms\nbaselines in our proposed experimental settings, which are designed to measure\ngeneralization power to unseen data in practical scenarios. Our code is\navailable at https://github.com/sung-won-kim/FedLoG",
      "tldr_zh": "该研究提出了FedLoG框架，用于解决图联邦学习中的局部过拟合问题。通过聚合各客户端的类别表征和结构信息生成全局合成数据，该方法能自适应补全本地数据集中缺失的知识分布。实验表明，FedLoG在应对新节点和标签分布变化方面优于基线方法，显著提升了模型对未见数据的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 (oral)",
      "pdf_url": "http://arxiv.org/pdf/2503.03995v1",
      "published_date": "2025-03-06 01:08:01 UTC",
      "updated_date": "2025-03-06 01:08:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:44:49.931623"
    },
    {
      "arxiv_id": "2503.03987v1",
      "title": "RetinalGPT: A Retinal Clinical Preference Conversational Assistant Powered by Large Vision-Language Models",
      "title_zh": "RetinalGPT：基于大型视觉语言模型的视网膜临床偏好对话助手",
      "authors": [
        "Wenhui Zhu",
        "Xin Li",
        "Xiwen Chen",
        "Peijie Qiu",
        "Vamsi Krishna Vasa",
        "Xuanzhao Dong",
        "Yanxi Chen",
        "Natasha Lepore",
        "Oana Dumitrascu",
        "Yi Su",
        "Yalin Wang"
      ],
      "abstract": "Recently, Multimodal Large Language Models (MLLMs) have gained significant\nattention for their remarkable ability to process and analyze non-textual data,\nsuch as images, videos, and audio. Notably, several adaptations of\ngeneral-domain MLLMs to the medical field have been explored, including\nLLaVA-Med. However, these medical adaptations remain insufficiently advanced in\nunderstanding and interpreting retinal images. In contrast, medical experts\nemphasize the importance of quantitative analyses for disease detection and\ninterpretation. This underscores a gap between general-domain and\nmedical-domain MLLMs: while general-domain MLLMs excel in broad applications,\nthey lack the specialized knowledge necessary for precise diagnostic and\ninterpretative tasks in the medical field. To address these challenges, we\nintroduce \\textit{RetinalGPT}, a multimodal conversational assistant for\nclinically preferred quantitative analysis of retinal images. Specifically, we\nachieve this by compiling a large retinal image dataset, developing a novel\ndata pipeline, and employing customized visual instruction tuning to enhance\nboth retinal analysis and enrich medical knowledge. In particular, RetinalGPT\noutperforms MLLM in the generic domain by a large margin in the diagnosis of\nretinal diseases in 8 benchmark retinal datasets. Beyond disease diagnosis,\nRetinalGPT features quantitative analyses and lesion localization, representing\na pioneering step in leveraging LLMs for an interpretable and end-to-end\nclinical research framework. The code is available at\nhttps://github.com/Retinal-Research/RetinalGPT",
      "tldr_zh": "该研究提出了RetinalGPT，一种基于大视觉语言模型(MLLMs)的视网膜临床偏好对话助手，专注于视网膜图像的定量分析。通过构建大规模视网膜图像数据集、开发新型数据管道并进行定制化视觉指令调优，RetinalGPT显著提升了视网膜疾病诊断的准确性，在8个基准数据集上表现远超通用领域MLLMs。此外，RetinalGPT还具备定量分析和病变定位功能，为利用大语言模型构建可解释的端到端临床研究框架迈出了重要一步。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03987v1",
      "published_date": "2025-03-06 00:19:54 UTC",
      "updated_date": "2025-03-06 00:19:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:45:03.662012"
    },
    {
      "arxiv_id": "2503.03986v1",
      "title": "Training neural networks faster with minimal tuning using pre-computed lists of hyperparameters for NAdamW",
      "title_zh": "利用预计算NAdamW超参数列表实现神经网络快速训练且无需精细调参",
      "authors": [
        "Sourabh Medapati",
        "Priya Kasimbeg",
        "Shankar Krishnan",
        "Naman Agarwal",
        "George Dahl"
      ],
      "abstract": "If we want to train a neural network using any of the most popular\noptimization algorithms, we are immediately faced with a dilemma: how to set\nthe various optimization and regularization hyperparameters? When computational\nresources are abundant, there are a variety of methods for finding good\nhyperparameter settings, but when resources are limited the only realistic\nchoices are using standard default values of uncertain quality and provenance,\nor tuning only a couple of the most important hyperparameters via extremely\nlimited handdesigned sweeps. Extending the idea of default settings to a modest\ntuning budget, Metz et al. (2020) proposed using ordered lists of\nwell-performing hyperparameter settings, derived from a broad hyperparameter\nsearch on a large library of training workloads. However, to date, no practical\nand performant hyperparameter lists that generalize to representative deep\nlearning workloads have been demonstrated. In this paper, we present\nhyperparameter lists for NAdamW derived from extensive experiments on the\nrealistic workloads in the AlgoPerf: Training Algorithms benchmark. Our\nhyperparameter lists also include values for basic regularization techniques\n(i.e. weight decay, label smoothing, and dropout). In particular, our best\nNAdamW hyperparameter list performs well on AlgoPerf held-out workloads not\nused to construct it, and represents a compelling turn-key approach to tuning\nwhen restricted to five or fewer trials. It also outperforms basic learning\nrate/weight decay sweeps and an off-the-shelf Bayesian optimization tool when\nrestricted to the same budget.",
      "tldr_zh": "本文提出了针对NAdamW优化器的预计算超参数列表，旨在减少神经网络训练中的超参数调优成本。这些列表基于AlgoPerf基准测试中的大量实验数据生成，并涵盖了权重衰减、标签平滑和dropout等基本正则化技术。实验表明，该列表在未参与构建的测试任务上表现优异，尤其在仅允许5次或更少调优试验时，其性能优于传统的学习率/权重衰减搜索和现成的贝叶斯优化工具，为资源受限的深度学习训练提供了一种高效的开箱即用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Good defaults for NadamW Optimizer, generalizes well to unseen\n  problems",
      "pdf_url": "http://arxiv.org/pdf/2503.03986v1",
      "published_date": "2025-03-06 00:14:50 UTC",
      "updated_date": "2025-03-06 00:14:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:45:13.457131"
    },
    {
      "arxiv_id": "2503.05830v1",
      "title": "AI-Facilitated Collective Judgements",
      "title_zh": "AI赋能的集体判断",
      "authors": [
        "Manon Revel",
        "Théophile Pénigaud"
      ],
      "abstract": "This article unpacks the design choices behind longstanding and newly\nproposed computational frameworks aimed at finding common grounds across\ncollective preferences and examines their potential future impacts, both\ntechnically and normatively. It begins by situating AI-assisted preference\nelicitation within the historical role of opinion polls, emphasizing that\npreferences are shaped by the decision-making context and are seldom\nobjectively captured. With that caveat in mind, we explore AI-facilitated\ncollective judgment as a discovery tool for fostering reasonable\nrepresentations of a collective will, sense-making, and agreement-seeking. At\nthe same time, we caution against dangerously misguided uses, such as enabling\nbinding decisions, fostering gradual disempowerment or post-rationalizing\npolitical outcomes.",
      "tldr_zh": "该研究探讨了AI辅助集体决策框架的设计选择及其技术与社会影响。文章将AI偏好提取技术置于民意调查的历史脉络中，指出偏好具有情境依赖性，难以客观捕捉。研究提出AI可作为探索工具，帮助形成合理的集体意志表达与共识构建，但警告需避免将其用于具有约束力的决策或政治结果合理化等危险用途。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05830v1",
      "published_date": "2025-03-06 00:06:22 UTC",
      "updated_date": "2025-03-06 00:06:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:45:09.166122"
    },
    {
      "arxiv_id": "2503.03979v1",
      "title": "ReasonGraph: Visualisation of Reasoning Paths",
      "title_zh": "ReasonGraph：推理路径的可视化",
      "authors": [
        "Zongqian Li",
        "Ehsan Shareghi",
        "Nigel Collier"
      ],
      "abstract": "Large Language Models (LLMs) reasoning processes are challenging to analyze\ndue to their complexity and the lack of organized visualization tools. We\npresent ReasonGraph, a web-based platform for visualizing and analyzing LLM\nreasoning processes. It supports both sequential and tree-based reasoning\nmethods while integrating with major LLM providers and over fifty\nstate-of-the-art models. ReasonGraph incorporates an intuitive UI with meta\nreasoning method selection, configurable visualization parameters, and a\nmodular framework that facilitates efficient extension. Our evaluation shows\nhigh parsing reliability, efficient processing, and strong usability across\nvarious downstream applications. By providing a unified visualization\nframework, ReasonGraph reduces cognitive load in analyzing complex reasoning\npaths, improves error detection in logical processes, and enables more\neffective development of LLM-based applications. The platform is open-source,\npromoting accessibility and reproducibility in LLM reasoning analysis.",
      "tldr_zh": "该研究提出了ReasonGraph，一个基于Web的可视化平台，专门用于分析和展示大型语言模型(LLMs)的推理过程。该系统支持顺序式和树状推理方法，兼容主流LLM提供商及50多种先进模型，提供包含元推理方法选择、可配置可视化参数的直观用户界面。评估表明该平台具有高解析可靠性、高效处理能力和优秀的可用性，能有效降低分析复杂推理路径的认知负荷，提升逻辑错误检测能力。作为开源工具，ReasonGraph为LLM推理分析提供了统一的可视化框架，促进了该领域的可访问性和可重复性研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.03979v1",
      "published_date": "2025-03-06 00:03:55 UTC",
      "updated_date": "2025-03-06 00:03:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T03:45:42.234557"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 135,
  "processed_papers_count": 135,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-03-26T03:47:29.899186"
}