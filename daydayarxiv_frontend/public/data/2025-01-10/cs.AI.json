{
  "date": "2025-01-10",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-10 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化、多模态处理、生物医疗应用和语音图像技术等领域，其中令人印象深刻的是多模态大型语言模型（如 MinMo）的创新应用，以及 AI 伦理和生物信息学领域的进展；有名的学者如 Antonio Torralba 和 Tianming Liu 等参与的论文值得关注。\n\n以下是今天更新的关键论文摘要，我将优先讨论那些创新性强、可能有话题度的文章（如 AI 模型和医疗应用），并快速掠过一些技术优化或较次要的论文。每个条目包括论文标题（中文 + 英文）、主要贡献和发现，保留核心学术术语。\n\n### 1. **多模态大型语言模型的创新（Multi-Modal LLMs）**\n   - **MinMo: A Multimodal Large Language Model for Seamless Voice Interaction**（中文：MinMo：一种用于无缝语音交互的多模态大型语言模型）  \n     主要贡献：提出 MinMo 框架，通过多阶段训练（如语音到文本、文本到语音等）处理语音任务，结合视觉和语言信息。发现：在语音理解和生成 benchmark 上，MinMo 实现实时全双工交互，并在情感和方言控制上表现出色，适用于复杂语音应用。\n   - **VideoRAG: Retrieval-Augmented Generation over Video Corpus**（中文：VideoRAG：基于视频语料的检索增强生成）  \n     主要贡献：开发 VideoRAG 框架，使用 Large Video Language Models (LVLMs) 动态检索视频并生成响应。发现：显著提升视频理解和生成性能，适用于多模态任务，如视频问答。\n\n### 2. **AI 伦理和治理（AI Ethics and Governance）**\n   - **A Capability Approach to AI Ethics**（中文：一种能力方法论用于 AI 伦理）  \n     主要贡献：使用能力方法论框架定义 AI 伦理规范，并应用于医疗 AI 工具的设计。发现：该方法能清晰评估 AI 的公平性和可解释性，提高工具在医疗领域的可靠性。\n   - **Supervision policies can shape long-term risk management in general-purpose AI models**（中文：监督策略如何塑造通用 AI 模型的长期风险管理）  \n     主要贡献：提出模拟框架分析 AI 监督策略（如优先级和多样性策略）。发现：优先策略可减少高影响风险，但可能忽略系统性问题，强调 AI 风险监督的权衡。\n\n### 3. **生物医疗和健康应用（Bioinformatics and Health）**\n   - **BioAgents: Democratizing Bioinformatics Analysis with Multi-Agent Systems**（中文：BioAgents：使用多代理系统实现生物信息分析的民主化）  \n     主要贡献：构建基于小语言模型的 BioAgents 系统，支持本地化分析和个性化数据。发现：在基因组任务上与人类专家性能相当，有望简化生物信息学工作流程。\n   - **AI-Driven Diabetic Retinopathy Screening: Multicentric Validation of AIDRSS in India**（中文：AI 驱动的糖尿病视网膜病变筛查：AIDRSS 在印度的多中心验证）  \n     主要贡献：开发 AIDRSS 系统，使用深度学习检测视网膜病变。发现：在印度数据集上，敏感性达 92%，准确识别可参考病变，提高了资源有限地区的筛查效率。\n   - **Polarized Patterns of Language Toxicity and Sentiment of Debunking Posts on Social Media**（中文：社交媒体辟谣帖子的语言毒性和情感极化模式）  \n     主要贡献：分析辟谣帖子的毒性和情感模式。发现：Twitter 放大 partisanship 差异，Reddit 毒性更高，交互可降低毒性，提供社交平台治理洞见。\n\n### 4. **语音和图像处理（Speech and Image Processing）**\n   - **TTS-Transducer: End-to-End Speech Synthesis with Neural Transducer**（中文：TTS-Transducer：使用神经转录器的端到端语音合成）  \n     主要贡献：引入 TTS-Transducer 架构，结合神经转录器和音频编解码器，避免显式时长预测。发现：在语音生成任务上，性能优于传统 TTS 系统，实现更高效的单步多码预测。\n   - **UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping**（中文：UV-Attack：使用动态-NeRF 的 UV 映射进行物理世界的人检测对抗攻击）  \n     主要贡献：提出 UV-Attack 框架，利用动态 Neural Radiance Fields (NeRF) 生成鲁棒对抗纹理。发现：在 YOLOv8 上，攻击成功率达 49.5%，揭示了人检测系统的漏洞。\n   - **xLSTM-SENet: xLSTM for Single-Channel Speech Enhancement**（中文：xLSTM-SENet：用于单通道语音增强的 xLSTM）  \n     主要贡献：开发 xLSTM-SENet 系统，优化语音增强架构。发现：在 VoiceBank+DEMAND 数据集上，性能优于 Mamba 和 Conformer 模型，提供更高效的实时增强。\n\n### 5. **其他值得注意的论文（Other Notable Papers）**\n   - **Diffusion Models for Smarter UAVs: Decision-Making and Modeling**（中文：扩散模型用于更智能的无人机：决策和建模）  \n     主要贡献：将扩散模型与强化学习结合，提升无人机决策。发现：显著改善实时优化和建模准确性，适用于复杂通信场景。\n   - **TransPlace: Transferable Circuit Global Placement via Graph Neural Network**（中文：TransPlace：通过图神经网络实现可转移的电路全局布局）  \n     主要贡献：使用 Graph Neural Network (GNN) 优化电路布局。发现：加速布局过程，减少拥塞和时延，适用于大规模芯片设计。\n   - 其他如 \"Aggregating Low Rank Adapters in Federated Fine-tuning\"（中文：联邦微调中聚合低秩适配器）和 \"Model Alignment Search\"（中文：模型对齐搜索）等论文涉及联邦学习和模型解释，但这些更技术导向，我这里快速掠过：它们分别优化了联邦微调的聚合方法和模型行为解释，提供了一些效率改进，但影响力较局限。\n\n今天的 arXiv 更新突显了 AI 在多模态和医疗领域的潜力，但也暴露了伦理和鲁棒性挑战。感兴趣的读者可关注 LLM 和生物应用论文，探索实际创新。如果有特定主题，建议直接查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2501.06389v1",
      "title": "Kolmogorov-Arnold networks for metal surface defect classification",
      "title_zh": "Kolmogorov-Arnold 网络用于金属表面缺陷分类",
      "authors": [
        "Maciej Krzywda",
        "Mariusz Wermiński",
        "Szymon Łukasik",
        "Amir H. Gandomi"
      ],
      "abstract": "This paper presents the application of Kolmogorov-Arnold Networks (KAN) in\nclassifying metal surface defects. Specifically, steel surfaces are analyzed to\ndetect defects such as cracks, inclusions, patches, pitted surfaces, and\nscratches. Drawing on the Kolmogorov-Arnold theorem, KAN provides a novel\napproach compared to conventional multilayer perceptrons (MLPs), facilitating\nmore efficient function approximation by utilizing spline functions. The\nresults show that KAN networks can achieve better accuracy than convolutional\nneural networks (CNNs) with fewer parameters, resulting in faster convergence\nand improved performance in image classification.",
      "tldr_zh": "这篇论文探讨了 Kolmogorov-Arnold Networks (KAN) 在金属表面缺陷分类中的应用，针对钢材表面的 cracks、inclusions、patches、pitted surfaces 和 scratches 等缺陷进行检测。KAN 基于 Kolmogorov-Arnold 定理，通过利用样条函数实现更有效的函数逼近，与传统多层感知器 (MLPs) 相比，提供了一种更高效的替代方案。实验结果表明，KAN 比卷积神经网络 (CNNs) 实现了更高的准确率，同时参数更少、收敛更快，提升了图像分类性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06389v1",
      "published_date": "2025-01-10 23:58:30 UTC",
      "updated_date": "2025-01-10 23:58:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:07:59.318162"
    },
    {
      "arxiv_id": "2501.06382v3",
      "title": "Dynamics of Spontaneous Topic Changes in Next Token Prediction with Self-Attention",
      "title_zh": "自注意力机制中下一个标记预测的自发主题变化动态",
      "authors": [
        "Mumin Jia",
        "Jairo Diaz-Rodriguez"
      ],
      "abstract": "Human cognition is punctuated by abrupt, spontaneous shifts between\ntopics-driven by emotional, contextual, or associative cues-a phenomenon known\nas spontaneous thought in neuroscience. In contrast, self-attention based\nmodels depend on structured patterns over their inputs to predict each next\ntoken, lacking spontaneity. Motivated by this distinction, we characterize\nspontaneous topic changes in self-attention architectures, revealing both their\nsimilarities and their divergences from spontaneous human thought. First, we\nestablish theoretical results under a simplified, single-layer self-attention\nmodel with suitable conditions by defining the topic as a set of Token Priority\nGraphs (TPGs). Specifically, we demonstrate that (1) the model maintains the\npriority order of tokens related to the input topic, (2) a spontaneous topic\nchange can occur only if lower-priority tokens outnumber all higher-priority\ntokens of the input topic, and (3) unlike human cognition, the longer context\nlength or the more ambiguous input topic reduces the likelihood of spontaneous\nchange. Second, we empirically validate that these dynamics persist in modern,\nstate-of-the-art LLMs, underscoring a fundamental disparity between human\ncognition and AI behaviour in the context of spontaneous topic changes. To the\nbest of our knowledge, no prior work has explored these questions with a focus\nas closely aligned to human thought.",
      "tldr_zh": "本研究探讨了自注意力(self-attention)模型在下一个 token 预测中的自发主题切换动态，并将其与人类认知中的自发思维进行比较。论文首先在简化单层自注意力模型中定义主题为 Token Priority Graphs (TPGs)，理论证明了模型会保持输入主题 token 的优先顺序，且自发切换仅在低优先级 token 数量超过高优先级 token 时发生，同时指出与人类不同，更长的上下文或更模糊的输入会降低切换可能性。其次，通过实证实验验证这些动态在现代大型语言模型(LLMs)中持续存在，突显了人类认知和 AI 行为在自发主题切换方面的根本差异。该工作首次密切关注人类思维，提供对 AI 模型行为的深入洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06382v3",
      "published_date": "2025-01-10 23:18:23 UTC",
      "updated_date": "2025-05-02 02:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:08:12.667522"
    },
    {
      "arxiv_id": "2501.06370v2",
      "title": "Towards a Probabilistic Framework for Analyzing and Improving LLM-Enabled Software",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Manuel Baldonado",
        "Flavia Bonomo-Braberman",
        "Víctor Adrián Braberman"
      ],
      "abstract": "Ensuring the reliability and verifiability of large language model\n(LLM)-enabled systems remains a significant challenge in software engineering.\nWe propose a probabilistic framework for systematically analyzing and improving\nthese systems by modeling and refining distributions over clusters of\nsemantically equivalent outputs. This framework facilitates the evaluation and\niterative improvement of Transference Models--key software components that\nutilize LLMs to transform inputs into outputs for downstream tasks. To\nillustrate its utility, we apply the framework to the autoformalization\nproblem, where natural language documentation is transformed into formal\nprogram specifications. Our case illustrates how distribution-aware analysis\nenables the identification of weaknesses and guides focused alignment\nimprovements, resulting in more reliable and interpretable outputs. This\nprincipled approach offers a foundation for addressing critical challenges in\nthe development of robust LLM-enabled systems.",
      "tldr_zh": "这篇论文提出一个概率框架，用于系统分析和改进LLM-enabled软件系统，通过建模和细化语义等价输出簇的分布，以提升系统可靠性与可验证性。该框架专注于评估和迭代改进Transference Models，这些模型利用LLM将输入转换为下游任务输出。作为示例，应用于autoformalization问题，即将自然语言文档转化为正式程序规范，从而识别系统弱点并指导针对性对齐改进。最终，这为开发更稳健的LLM-enabled系统提供了坚实基础。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.5; D.2.4; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06370v2",
      "published_date": "2025-01-10 22:42:06 UTC",
      "updated_date": "2025-04-13 21:33:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:08:23.168114"
    },
    {
      "arxiv_id": "2501.07601v5",
      "title": "Real-Time Decision-Making for Digital Twin in Additive Manufacturing with Model Predictive Control using Time-Series Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yi-Ping Chen",
        "Vispi Karkaria",
        "Ying-Kuan Tsai",
        "Faith Rolark",
        "Daniel Quispe",
        "Robert X. Gao",
        "Jian Cao",
        "Wei Chen"
      ],
      "abstract": "Digital Twin -- a virtual replica of a physical system enabling real-time\nmonitoring, model updating, prediction, and decision-making -- combined with\nrecent advances in machine learning, offers new opportunities for proactive\ncontrol strategies in autonomous manufacturing. However, achieving real-time\ndecision-making with Digital Twins requires efficient optimization driven by\naccurate predictions of highly nonlinear manufacturing systems. This paper\npresents a simultaneous multi-step Model Predictive Control (MPC) framework for\nreal-time decision-making, using a multivariate deep neural network, named\nTime-Series Dense Encoder (TiDE), as the surrogate model. Unlike conventional\nMPC models which only provide one-step ahead prediction, TiDE is capable of\npredicting future states within the prediction horizon in one shot\n(multi-step), significantly accelerating the MPC. Using Directed Energy\nDeposition (DED) additive manufacturing as a case study, we demonstrate the\neffectiveness of the proposed MPC in achieving melt pool temperature tracking\nto ensure part quality, while reducing porosity defects by regulating laser\npower to maintain melt pool depth constraints. In this work, we first show that\nTiDE is capable of accurately predicting melt pool temperature and depth.\nSecond, we demonstrate that the proposed MPC achieves precise temperature\ntracking while satisfying melt pool depth constraints within a targeted\ndilution range (10\\%-30\\%), reducing potential porosity defects. Compared to\nPID controller, the MPC results in smoother and less fluctuating laser power\nprofiles with competitive or superior melt pool temperature control\nperformance. This demonstrates the MPC's proactive control capabilities,\nleveraging time-series prediction and real-time optimization, positioning it as\na powerful tool for future Digital Twin applications and real-time process\noptimization in manufacturing.",
      "tldr_zh": "本研究提出了一种基于模型预测控制（MPC）的实时决策框架，用于数字孪生（Digital Twin）在增材制造中的应用，该框架利用Time-Series Dense Encoder (TiDE)神经网络作为代理模型，实现多步预测以加速优化过程。不同于传统MPC的单步预测，TiDE能一次性预测未来状态，从而提升了对高度非线性制造系统的控制效率。以Directed Energy Deposition (DED)增材制造为例，实验证明该MPC框架能精确跟踪熔池温度，同时满足熔池深度约束（10%-30%的稀释范围），从而减少孔隙缺陷。相比PID控制器，该方法提供更平滑的激光功率配置文件，并实现竞争或优越的温度控制性能，为数字孪生在自主制造中的实时优化提供强大工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07601v5",
      "published_date": "2025-01-10 22:31:53 UTC",
      "updated_date": "2025-04-11 04:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:08:36.070137"
    },
    {
      "arxiv_id": "2501.06365v1",
      "title": "Gender-Neutral Large Language Models for Medical Applications: Reducing Bias in PubMed Abstracts",
      "title_zh": "翻译失败",
      "authors": [
        "Elizabeth Schaefer",
        "Kirk Roberts"
      ],
      "abstract": "This paper presents a pipeline for mitigating gender bias in large language\nmodels (LLMs) used in medical literature by neutralizing gendered occupational\npronouns. A dataset of 379,000 PubMed abstracts from 1965-1980 was processed to\nidentify and modify pronouns tied to professions. We developed a BERT-based\nmodel, ``Modern Occupational Bias Elimination with Refined Training,'' or\n``MOBERT,'' trained on these neutralized abstracts, and compared its\nperformance with ``1965Bert,'' trained on the original dataset. MOBERT achieved\na 70\\% inclusive replacement rate, while 1965Bert reached only 4\\%. A further\nanalysis of MOBERT revealed that pronoun replacement accuracy correlated with\nthe frequency of occupational terms in the training data. We propose expanding\nthe dataset and refining the pipeline to improve performance and ensure more\nequitable language modeling in medical applications.",
      "tldr_zh": "本文提出一个管道，用于减少大型语言模型 (LLMs) 在医疗文献中的性别偏见，通过中和性别化的职业代词，并处理了 1965-1980 年的 379,000 个 PubMed 摘要。研究开发了基于 BERT 的 MOBERT 模型（Modern Occupational Bias Elimination with Refined Training），训练于这些修改后的摘要，并与基线模型 1965Bert 相比，MOBERT 的包容性替换率达到 70%，远高于 1965Bert 的 4%。分析发现，代词替换准确率与训练数据中职业术语的频率密切相关。作者建议扩展数据集并优化管道，以提升医疗应用中的语言模型公平性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06365v1",
      "published_date": "2025-01-10 22:07:56 UTC",
      "updated_date": "2025-01-10 22:07:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:08:48.682620"
    },
    {
      "arxiv_id": "2501.06356v1",
      "title": "Ultrasound Image Synthesis Using Generative AI for Lung Ultrasound Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Cheng Chou",
        "Gary Y. Li",
        "Li Chen",
        "Mohsen Zahiri",
        "Naveen Balaraju",
        "Shubham Patil",
        "Bryson Hicks",
        "Nikolai Schnittke",
        "David O. Kessler",
        "Jeffrey Shupp",
        "Maria Parker",
        "Cristiana Baloescu",
        "Christopher Moore",
        "Cynthia Gregory",
        "Kenton Gregory",
        "Balasundar Raju",
        "Jochen Kruecker",
        "Alvin Chen"
      ],
      "abstract": "Developing reliable healthcare AI models requires training with\nrepresentative and diverse data. In imbalanced datasets, model performance\ntends to plateau on the more prevalent classes while remaining low on less\ncommon cases. To overcome this limitation, we propose DiffUltra, the first\ngenerative AI technique capable of synthesizing realistic Lung Ultrasound (LUS)\nimages with extensive lesion variability. Specifically, we condition the\ngenerative AI by the introduced Lesion-anatomy Bank, which captures the\nlesion's structural and positional properties from real patient data to guide\nthe image synthesis.We demonstrate that DiffUltra improves consolidation\ndetection by 5.6% in AP compared to the models trained solely on real patient\ndata. More importantly, DiffUltra increases data diversity and prevalence of\nrare cases, leading to a 25% AP improvement in detecting rare instances such as\nlarge lung consolidations, which make up only 10% of the dataset.",
      "tldr_zh": "该研究提出了一种名为 DiffUltra 的生成式 AI 技术，用于合成真实肺超声 (LUS) 图像，以解决医疗 AI 在不平衡数据集中的问题，即模型对常见类别性能停滞，而对罕见病例检测能力不足。DiffUltra 通过引入 Lesion-anatomy Bank 来指导图像合成，该银行从真实患者数据中提取病变的结构和位置属性，从而增加图像的多样性和罕见病例的 prevalence。实验结果显示，与仅使用真实数据训练的模型相比，DiffUltra 使肺部固化检测的 Average Precision (AP) 提高了 5.6%，并对罕见实例如大型肺固化实现了 25% 的 AP 提升。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by ISBI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.06356v1",
      "published_date": "2025-01-10 21:32:50 UTC",
      "updated_date": "2025-01-10 21:32:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:09:00.140496"
    },
    {
      "arxiv_id": "2501.06339v1",
      "title": "On The Statistical Complexity of Offline Decision-Making",
      "title_zh": "翻译失败",
      "authors": [
        "Thanh Nguyen-Tang",
        "Raman Arora"
      ],
      "abstract": "We study the statistical complexity of offline decision-making with function\napproximation, establishing (near) minimax-optimal rates for stochastic\ncontextual bandits and Markov decision processes. The performance limits are\ncaptured by the pseudo-dimension of the (value) function class and a new\ncharacterization of the behavior policy that \\emph{strictly} subsumes all the\nprevious notions of data coverage in the offline decision-making literature. In\naddition, we seek to understand the benefits of using offline data in online\ndecision-making and show nearly minimax-optimal rates in a wide range of\nregimes.",
      "tldr_zh": "这篇论文探讨了离线决策的统计复杂性，使用函数逼近建立了随机上下文盗贼(stochastic contextual bandits)和Markov决策过程(Markov decision processes)的近似最优率。论文的核心贡献包括以伪维度(pseudo-dimension)衡量性能限制，并引入一种新的行为策略表征，该表征严格包含了之前所有离线决策文献中的数据覆盖概念。此外，研究展示了使用离线数据在在线决策中的益处，并提供了广泛情境下的近似最优率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv version for the ICML'24 paper",
      "pdf_url": "http://arxiv.org/pdf/2501.06339v1",
      "published_date": "2025-01-10 20:45:23 UTC",
      "updated_date": "2025-01-10 20:45:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:09:11.545864"
    },
    {
      "arxiv_id": "2501.06332v1",
      "title": "Aggregating Low Rank Adapters in Federated Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Evelyn Trautmann",
        "Ian Hales",
        "Martin F. Volk"
      ],
      "abstract": "Fine-tuning large language models requires high computational and memory\nresources, and is therefore associated with significant costs. When training on\nfederated datasets, an increased communication effort is also needed. For this\nreason, parameter-efficient methods (PEFT) are becoming increasingly important.\nIn this context, very good results have already been achieved by fine-tuning\nwith low-rank adaptation methods (LoRA). The application of LoRA methods in\nFederated Learning, and especially the aggregation of adaptation matrices, is a\ncurrent research field. In this article, we propose a novel aggregation method\nand compare it with different existing aggregation methods of low rank adapters\ntrained in a federated fine-tuning of large machine learning models and\nevaluate their performance with respect to selected GLUE benchmark datasets.",
      "tldr_zh": "该论文探讨了微调大型语言模型在联邦学习中的高计算和通信资源消耗问题，强调了参数高效方法(PEFT)的重要性，特别是Low-Rank Adaptation(LoRA)的应用。作者提出了一种新颖的LoRA适配矩阵聚合方法，并与其他现有聚合方法进行了比较。实验结果显示，该方法在联邦微调大型模型时，使用选定的GLUE基准数据集，展现了良好的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "presented at conference\n  https://flta-conference.org/flta-2024-detailed-program/",
      "pdf_url": "http://arxiv.org/pdf/2501.06332v1",
      "published_date": "2025-01-10 20:24:33 UTC",
      "updated_date": "2025-01-10 20:24:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:09:23.209643"
    },
    {
      "arxiv_id": "2501.06322v1",
      "title": "Multi-Agent Collaboration Mechanisms: A Survey of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Khanh-Tung Tran",
        "Dung Dao",
        "Minh-Duong Nguyen",
        "Quoc-Viet Pham",
        "Barry O'Sullivan",
        "Hoang D. Nguyen"
      ],
      "abstract": "With recent advances in Large Language Models (LLMs), Agentic AI has become\nphenomenal in real-world applications, moving toward multiple LLM-based agents\nto perceive, learn, reason, and act collaboratively. These LLM-based\nMulti-Agent Systems (MASs) enable groups of intelligent agents to coordinate\nand solve complex tasks collectively at scale, transitioning from isolated\nmodels to collaboration-centric approaches. This work provides an extensive\nsurvey of the collaborative aspect of MASs and introduces an extensible\nframework to guide future research. Our framework characterizes collaboration\nmechanisms based on key dimensions: actors (agents involved), types (e.g.,\ncooperation, competition, or coopetition), structures (e.g., peer-to-peer,\ncentralized, or distributed), strategies (e.g., role-based or model-based), and\ncoordination protocols. Through a review of existing methodologies, our\nfindings serve as a foundation for demystifying and advancing LLM-based MASs\ntoward more intelligent and collaborative solutions for complex, real-world use\ncases. In addition, various applications of MASs across diverse domains,\nincluding 5G/6G networks, Industry 5.0, question answering, and social and\ncultural settings, are also investigated, demonstrating their wider adoption\nand broader impacts. Finally, we identify key lessons learned, open challenges,\nand potential research directions of MASs towards artificial collective\nintelligence.",
      "tldr_zh": "这篇论文对大型语言模型（LLMs）在多智能体系统（MASs）中的协作机制进行了全面调查，强调了LLMs如何从孤立模型转向协作性方法，以共同感知、学习、推理和行动。论文引入了一个可扩展框架，基于关键维度如参与者（actors）、类型（e.g., 合作、竞争或coopetition）、结构（e.g., 点对点、中央化或分布式）、策略（e.g., 基于角色的或模型-based）和协调协议，指导未来MASs研究。调查还探讨了MASs在5G/6G网络、Industry 5.0、问答系统和社会文化领域的应用，并总结了关键教训、开放挑战及向人工集体智能发展的潜在方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06322v1",
      "published_date": "2025-01-10 19:56:50 UTC",
      "updated_date": "2025-01-10 19:56:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:09:35.801828"
    },
    {
      "arxiv_id": "2501.06320v1",
      "title": "TTS-Transducer: End-to-End Speech Synthesis with Neural Transducer",
      "title_zh": "翻译失败",
      "authors": [
        "Vladimir Bataev",
        "Subhankar Ghosh",
        "Vitaly Lavrukhin",
        "Jason Li"
      ],
      "abstract": "This work introduces TTS-Transducer - a novel architecture for\ntext-to-speech, leveraging the strengths of audio codec models and neural\ntransducers. Transducers, renowned for their superior quality and robustness in\nspeech recognition, are employed to learn monotonic alignments and allow for\navoiding using explicit duration predictors. Neural audio codecs efficiently\ncompress audio into discrete codes, revealing the possibility of applying text\nmodeling approaches to speech generation. However, the complexity of predicting\nmultiple tokens per frame from several codebooks, as necessitated by audio\ncodec models with residual quantizers, poses a significant challenge. The\nproposed system first uses a transducer architecture to learn monotonic\nalignments between tokenized text and speech codec tokens for the first\ncodebook. Next, a non-autoregressive Transformer predicts the remaining codes\nusing the alignment extracted from transducer loss. The proposed system is\ntrained end-to-end. We show that TTS-Transducer is a competitive and robust\nalternative to contemporary TTS systems.",
      "tldr_zh": "本文提出了一种新型端到端文本到语音（TTS）架构，名为 TTS-Transducer，它结合了神经转录器（neural transducers）和音频编解码器模型的优势，以实现高效的语音合成。系统首先使用转录器学习文本和语音编解码令牌之间的单调对齐（monotonic alignments），从而避免依赖显式持续时间预测器。接着，通过非自回归 Transformer 基于从转录器损失中提取的对齐来预测剩余代码，实现端到端训练。结果显示，TTS-Transducer 在质量和稳健性方面可作为当代 TTS 系统的竞争性替代方案。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted by ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.06320v1",
      "published_date": "2025-01-10 19:50:32 UTC",
      "updated_date": "2025-01-10 19:50:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:09:48.608936"
    },
    {
      "arxiv_id": "2501.06317v1",
      "title": "Understanding How Paper Writers Use AI-Generated Captions in Figure Caption Writing",
      "title_zh": "翻译失败",
      "authors": [
        "Ho Yin",
        "Ng",
        "Ting-Yao Hsu",
        "Jiyoo Min",
        "Sungchul Kim",
        "Ryan A. Rossi",
        "Tong Yu",
        "Hyunggu Jung",
        "Ting-Hao 'Kenneth' Huang"
      ],
      "abstract": "Figures and their captions play a key role in scientific publications.\nHowever, despite their importance, many captions in published papers are poorly\ncrafted, largely due to a lack of attention by paper authors. While prior AI\nresearch has explored caption generation, it has mainly focused on\nreader-centered use cases, where users evaluate generated captions rather than\nactively integrating them into their writing. This paper addresses this gap by\ninvestigating how paper authors incorporate AI-generated captions into their\nwriting process through a user study involving 18 participants. Each\nparticipant rewrote captions for two figures from their own recently published\nwork, using captions generated by state-of-the-art AI models as a resource. By\nanalyzing video recordings of the writing process through interaction analysis,\nwe observed that participants often began by copying and refining AI-generated\ncaptions. Paper writers favored longer, detail-rich captions that integrated\ntextual and visual elements but found current AI models less effective for\ncomplex figures. These findings highlight the nuanced and diverse nature of\nfigure caption composition, revealing design opportunities for AI systems to\nbetter support the challenges of academic writing.",
      "tldr_zh": "本文研究了论文作者如何在写作过程中整合AI-generated captions（AI 生成的图表标题），以解决现有研究中忽略的作者视角问题。通过一项涉及18名参与者的用户研究，作者分析了参与者使用AI模型重写自身已发表论文图表标题的视频记录。结果发现，参与者通常从复制并改进AI-generated captions开始，更倾向于创建更长、细节丰富的标题以整合文本和视觉元素，但当前AI模型在处理复杂图表时效果较差。这些发现突出了图表标题编写的多样性，并为设计更有效的AI系统以支持学术写作挑战提供了宝贵机会。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "This paper will appear at AAAI 2025 Workshop (2nd AI4Research\n  Workshop: Towards a Knowledge-grounded Scientific Research Lifecycle)",
      "pdf_url": "http://arxiv.org/pdf/2501.06317v1",
      "published_date": "2025-01-10 19:39:06 UTC",
      "updated_date": "2025-01-10 19:39:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:10:01.101941"
    },
    {
      "arxiv_id": "2501.06314v1",
      "title": "BioAgents: Democratizing Bioinformatics Analysis with Multi-Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Nikita Mehandru",
        "Amanda K. Hall",
        "Olesya Melnichenko",
        "Yulia Dubinina",
        "Daniel Tsirulnikov",
        "David Bamman",
        "Ahmed Alaa",
        "Scott Saponas",
        "Venkat S. Malladi"
      ],
      "abstract": "Creating end-to-end bioinformatics workflows requires diverse domain\nexpertise, which poses challenges for both junior and senior researchers as it\ndemands a deep understanding of both genomics concepts and computational\ntechniques. While large language models (LLMs) provide some assistance, they\noften fall short in providing the nuanced guidance needed to execute complex\nbioinformatics tasks, and require expensive computing resources to achieve high\nperformance. We thus propose a multi-agent system built on small language\nmodels, fine-tuned on bioinformatics data, and enhanced with retrieval\naugmented generation (RAG). Our system, BioAgents, enables local operation and\npersonalization using proprietary data. We observe performance comparable to\nhuman experts on conceptual genomics tasks, and suggest next steps to enhance\ncode generation capabilities.",
      "tldr_zh": "本研究提出 BioAgents，一种基于 multi-agent systems 的框架，旨在解决生物信息学分析中对领域专业知识和计算资源的需求问题。BioAgents 利用小语言模型（fine-tuned on bioinformatics data）和检索增强生成（RAG）技术，支持本地操作和个性化，以提供更细致的指导。实验结果显示，该系统在概念性基因组任务上表现出与人类专家相当的性能，并建议未来步骤来提升代码生成能力。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06314v1",
      "published_date": "2025-01-10 19:30:59 UTC",
      "updated_date": "2025-01-10 19:30:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:10:11.884897"
    },
    {
      "arxiv_id": "2501.06293v1",
      "title": "LensNet: Enhancing Real-time Microlensing Event Discovery with Recurrent Neural Networks in the Korea Microlensing Telescope Network",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Viaña",
        "Kyu-Ha Hwang",
        "Zoë de Beurs",
        "Jennifer C. Yee",
        "Andrew Vanderburg",
        "Michael D. Albrow",
        "Sun-Ju Chung",
        "Andrew Gould",
        "Cheongho Han",
        "Youn Kil Jung",
        "Yoon-Hyun Ryu",
        "In-Gu Shin",
        "Yossi Shvartzvald",
        "Hongjing Yang",
        "Weicheng Zang",
        "Sang-Mok Cha",
        "Dong-Jin Kim",
        "Seung-Lee Kim",
        "Chung-Uk Lee",
        "Dong-Joo Lee",
        "Yongseok Lee",
        "Byeong-Gon Park",
        "Richard W. Pogge"
      ],
      "abstract": "Traditional microlensing event vetting methods require highly trained human\nexperts, and the process is both complex and time-consuming. This reliance on\nmanual inspection often leads to inefficiencies and constrains the ability to\nscale for widespread exoplanet detection, ultimately hindering discovery rates.\nTo address the limits of traditional microlensing event vetting, we have\ndeveloped LensNet, a machine learning pipeline specifically designed to\ndistinguish legitimate microlensing events from false positives caused by\ninstrumental artifacts, such as pixel bleed trails and diffraction spikes. Our\nsystem operates in conjunction with a preliminary algorithm that detects\nincreasing trends in flux. These flagged instances are then passed to LensNet\nfor further classification, allowing for timely alerts and follow-up\nobservations. Tailored for the multi-observatory setup of the Korea\nMicrolensing Telescope Network (KMTNet) and trained on a rich dataset of\nmanually classified events, LensNet is optimized for early detection and\nwarning of microlensing occurrences, enabling astronomers to organize follow-up\nobservations promptly. The internal model of the pipeline employs a\nmulti-branch Recurrent Neural Network (RNN) architecture that evaluates\ntime-series flux data with contextual information, including sky background,\nthe full width at half maximum of the target star, flux errors, PSF quality\nflags, and air mass for each observation. We demonstrate a classification\naccuracy above 87.5%, and anticipate further improvements as we expand our\ntraining set and continue to refine the algorithm.",
      "tldr_zh": "本研究针对传统微引力透镜事件检查依赖专家手动操作的低效问题，开发了 LensNet，一种机器学习管道，用于 Korea Microlensing Telescope Network (KMTNet) 的实时事件发现。LensNet 结合初步通量趋势检测算法，并采用多分支 Recurrent Neural Networks (RNN) 架构，评估时间序列通量数据以及上下文信息（如天空背景、目标星的 FWHM 和 PSF 质量），以区分真实事件和仪器伪影。实验结果显示，LensNet 的分类准确率超过 87.5%，有助于及时发出警报并组织后续观察，并预计通过扩展训练集进一步提升性能。",
      "categories": [
        "astro-ph.IM",
        "astro-ph.EP",
        "astro-ph.GA",
        "cs.AI",
        "85-08",
        "J.2"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "23 pages, 13 figures, Accepted for publication in the The\n  Astronomical Journal",
      "pdf_url": "http://arxiv.org/pdf/2501.06293v1",
      "published_date": "2025-01-10 19:00:01 UTC",
      "updated_date": "2025-01-10 19:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:10:24.615692"
    },
    {
      "arxiv_id": "2501.06286v1",
      "title": "Bactrainus: Optimizing Large Language Models for Multi-hop Complex Question Answering Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Iman Barati",
        "Arash Ghafouri",
        "Behrouz Minaei-Bidgoli"
      ],
      "abstract": "In recent years, the use of large language models (LLMs) has significantly\nincreased, and these models have demonstrated remarkable performance in a\nvariety of general language tasks. However, the evaluation of their performance\nin domain-specific tasks, particularly those requiring deep natural language\nunderstanding, has received less attention. In this research, we evaluate the\nability of large language models in performing domain-specific tasks, focusing\non the multi-hop question answering (MHQA) problem using the HotpotQA dataset.\nThis task, due to its requirement for reasoning and combining information from\nmultiple textual sources, serves as a challenging benchmark for assessing the\nlanguage comprehension capabilities of these models. To tackle this problem, we\nhave designed a two-stage selector-reader architecture, where each stage\nutilizes an independent LLM. In addition, methods such as Chain of Thought\n(CoT) and question decomposition have been employed to investigate their impact\non improving the model's performance. The results of the study show that the\nintegration of large language models with these techniques can lead to up to a\n4% improvement in F1 score for finding answers, providing evidence of the\nmodels' ability to handle domain-specific tasks and their understanding of\ncomplex language.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在领域特定任务中的性能，特别针对多跳问答（MHQA）问题，使用HotpotQA数据集作为基准，该任务需要从多个文本来源进行推理和信息整合。研究设计了一个两阶段的selector-reader架构，每个阶段采用独立的LLM，并结合Chain of Thought (CoT)和问题分解技术来优化模型表现。结果显示，这些方法使F1分数提高了最多4%，证明了LLMs在处理复杂语言理解和领域特定任务方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06286v1",
      "published_date": "2025-01-10 18:44:06 UTC",
      "updated_date": "2025-01-10 18:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:10:35.266081"
    },
    {
      "arxiv_id": "2501.06164v4",
      "title": "Model Alignment Search",
      "title_zh": "翻译失败",
      "authors": [
        "Satchel Grant"
      ],
      "abstract": "When can we say that two neural systems are the same? The answer to this\nquestion is goal-dependent, and it is often addressed through correlative\nmethods such as Representational Similarity Analysis (RSA) and Centered Kernel\nAlignment (CKA). We find ourselves chiefly interested in the relationship\nbetween representations and behavior, asking ourselves how we can isolate\nspecific functional aspects of representational similarity to relate our\nmeasures to behavior -- avoiding cause vs. correlation pitfalls in the process.\nIn this work, we introduce Model Alignment Search (MAS), a method for causally\nexploring distributed representational similarity as it relates to behavior.\nThe method learns invertible linear transformations that find an aligned\nsubspace between two distributed networks' representations where functional\ninformation can be isolated and manipulated. We first show that the method can\nbe used to transfer values of specific causal variables -- such as the number\nof items in a counting task -- between networks with different training seeds\nand different architectures. We then explore open questions in number cognition\nby comparing different types of numeric representations in models trained on\nstructurally different tasks, we explore differences between MAS and\npreexisting functional similarity methods, and lastly, we introduce a\ncounterfactual latent auxiliary loss that helps shape functionally relevant\nalignments even in cases where we do not have causal access to one of the two\nmodels for training.",
      "tldr_zh": "本文探讨了神经系统表示与行为关系的因果探索问题，引入了 Model Alignment Search (MAS) 方法，该方法通过学习可逆线性变换来找到两个分布式网络表示之间的对齐子空间，从而隔离和操纵功能信息。MAS 能够转移特定因果变量，如计数任务中的物品数量，在不同训练种子和架构的网络之间进行操作。作者进一步使用 MAS 比较不同数字表示和任务训练的模型，探索数字认知问题，并引入反事实潜在辅助损失（counterfactual latent auxiliary loss）来优化功能对齐，即使在无法访问其中一个模型时。实验结果验证了 MAS 在功能相似性分析（如与 Representational Similarity Analysis (RSA) 和 Centered Kernel Alignment (CKA) 的比较）中的优势，为相关领域提供了新工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06164v4",
      "published_date": "2025-01-10 18:39:29 UTC",
      "updated_date": "2025-04-24 02:13:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:10:48.800952"
    },
    {
      "arxiv_id": "2501.06146v2",
      "title": "xLSTM-SENet: xLSTM for Single-Channel Speech Enhancement",
      "title_zh": "xLSTM-SENet：xLSTM",
      "authors": [
        "Nikolai Lund Kühne",
        "Jan Østergaard",
        "Jesper Jensen",
        "Zheng-Hua Tan"
      ],
      "abstract": "While attention-based architectures, such as Conformers, excel in speech\nenhancement, they face challenges such as scalability with respect to input\nsequence length. In contrast, the recently proposed Extended Long Short-Term\nMemory (xLSTM) architecture offers linear scalability. However, xLSTM-based\nmodels remain unexplored for speech enhancement. This paper introduces\nxLSTM-SENet, the first xLSTM-based single-channel speech enhancement system. A\ncomparative analysis reveals that xLSTM-and notably, even LSTM-can match or\noutperform state-of-the-art Mamba- and Conformer-based systems across various\nmodel sizes in speech enhancement on the VoiceBank+Demand dataset. Through\nablation studies, we identify key architectural design choices such as\nexponential gating and bidirectionality contributing to its effectiveness. Our\nbest xLSTM-based model, xLSTM-SENet2, outperforms state-of-the-art Mamba- and\nConformer-based systems of similar complexity on the Voicebank+DEMAND dataset.",
      "tldr_zh": "本研究引入xLSTM-SENet，这是首个基于扩展长短时记忆网络(xLSTM)的单通道语音增强系统，以解决注意力机制模型如Conformers在处理长序列时的可扩展性挑战。实验比较显示，xLSTM（甚至LSTM）在VoiceBank+Demand数据集上能与或超越最先进的Mamba和Conformer系统，特别是在不同模型规模下。消融研究识别出指数门控和双向性等关键设计选择为其性能提升做出了贡献，而xLSTM-SENet2在类似复杂度的模型中实现了最佳表现。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at INTERSPEECH 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.06146v2",
      "published_date": "2025-01-10 18:10:06 UTC",
      "updated_date": "2025-05-20 08:28:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:11:00.320065"
    },
    {
      "arxiv_id": "2501.06143v3",
      "title": "Multilingual Performance of a Multimodal Artificial Intelligence System on Multisubject Physics Concept Inventories",
      "title_zh": "翻译失败",
      "authors": [
        "Gerd Kortemeyer",
        "Marina Babayeva",
        "Giulia Polverini",
        "Ralf Widenhorn",
        "Bor Gregorcic"
      ],
      "abstract": "We investigate the multilingual and multimodal performance of a large\nlanguage model-based artificial intelligence (AI) system, GPT-4o, using a\ndiverse set of physics concept inventories spanning multiple languages and\nsubject categories. The inventories, sourced from the PhysPort website, cover\nclassical physics topics such as mechanics, electromagnetism, optics, and\nthermodynamics, as well as relativity, quantum mechanics, astronomy,\nmathematics, and laboratory skills. Unlike previous text-only studies, we\nuploaded the inventories as images to reflect what a student would see on\npaper, thereby assessing the system's multimodal functionality. Our results\nindicate variation in performance across subjects, with laboratory skills\nstanding out as the weakest. We also observe differences across languages, with\nEnglish and European languages showing the strongest performance. Notably, the\nrelative difficulty of an inventory item is largely independent of the language\nof the survey. When comparing AI results to existing literature on student\nperformance, we find that the AI system outperforms average post-instruction\nundergraduate students in all subject categories except laboratory skills.\nFurthermore, the AI performs worse on items requiring visual interpretation of\nimages than on those that are purely text-based. While our exploratory findings\nshow GPT-4o's potential usefulness in physics education, they highlight the\ncritical need for instructors to foster students' ability to critically\nevaluate AI outputs, adapt curricula thoughtfully in response to AI\nadvancements, and address equity concerns associated with AI integration.",
      "tldr_zh": "本研究评估了大型语言模型AI系统GPT-4o在多语言和多模态环境下的表现，使用PhysPort网站提供的物理概念库存，这些库存涵盖力学、电磁学、光学、热力学、相对论、量子力学、天文学、数学和实验室技能，并以图像形式上传以测试多模态功能。结果显示，GPT-4o在英语和欧洲语言中表现最佳，但实验室技能是最弱领域，且项目难度与语言无关。AI系统在所有科目中均优于平均后指令本科生表现，但处理需要视觉解释的图像项目时表现较差。该研究强调了GPT-4o在物理教育中的潜力，同时呼吁教师培养学生批判性评估AI输出、调整课程并关注公平性问题。",
      "categories": [
        "physics.ed-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ed-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06143v3",
      "published_date": "2025-01-10 18:08:07 UTC",
      "updated_date": "2025-05-12 12:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:11:12.457017"
    },
    {
      "arxiv_id": "2501.06141v2",
      "title": "Emergent Symbol-like Number Variables in Artificial Neural Networks",
      "title_zh": "人工神经网络中涌现的类似符号的数字变量",
      "authors": [
        "Satchel Grant",
        "Noah D. Goodman",
        "James L. McClelland"
      ],
      "abstract": "What types of numeric representations emerge in neural systems? What would a\nsatisfying answer to this question look like? In this work, we interpret Neural\nNetwork (NN) solutions to sequence based counting tasks through a variety of\nlenses. We seek to understand how well we can understand NNs through the lens\nof interpretable Symbolic Algorithms (SAs), where SAs are defined by precise,\nabstract, mutable variables used to perform computations. We use GRUs, LSTMs,\nand Transformers trained using Next Token Prediction (NTP) on numeric tasks\nwhere the solutions to the tasks depend on numeric information only latent in\nthe task structure. We show through multiple causal and theoretical methods\nthat we can interpret NN's raw activity through the lens of simplified SAs when\nwe frame the neural activity in terms of interpretable subspaces rather than\nindividual neurons. Depending on the analysis, however, these interpretations\ncan be graded, existing on a continuum, highlighting the philosophical question\nof what it means to \"interpret\" neural activity, and motivating us to introduce\nAlignment Functions to add flexibility to the existing Distributed Alignment\nSearch (DAS) method. Through our specific analyses we show the importance of\ncausal interventions for NN interpretability; we show that recurrent models\ndevelop graded, symbol-like number variables within their neural activity; we\nintroduce a generalization of DAS to frame NN activity in terms of linear\nfunctions of interpretable variables; and we show that Transformers must use\nanti-Markovian solutions -- solutions that avoid using cumulative, Markovian\nhidden states -- in the absence of sufficient attention layers. We use our\nresults to encourage interpreting NNs at the level of neural subspaces through\nthe lens of SAs.",
      "tldr_zh": "本研究探讨了数字表示在神经网络（NNs）中的涌现形式，通过多种视角分析 NNs 在序列计数任务中的解决方案。研究者使用 GRUs、LSTMs 和 Transformers 模型，通过 Next Token Prediction (NTP) 训练，并采用因果干预和理论方法，将 NNs 的神经活动解读为可解释子空间，而非单个神经元，从而与 Symbolic Algorithms (SAs) 进行比较。关键发现包括：循环模型在神经活动中发展出 graded、symbol-like 数字变量；Transformers 在注意力层不足时采用 anti-Markovian 解决方案；并引入 Alignment Functions 来扩展 Distributed Alignment Search (DAS) 方法，以增强 NNs 的可解释性。总体上，该工作鼓励从 SAs 的角度，通过神经子空间来解读 NNs，提供更灵活的神经网络解释框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06141v2",
      "published_date": "2025-01-10 18:03:46 UTC",
      "updated_date": "2025-04-24 02:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:11:40.739864"
    },
    {
      "arxiv_id": "2501.06137v1",
      "title": "Supervision policies can shape long-term risk management in general-purpose AI models",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Cebrian",
        "Emilia Gomez",
        "David Fernandez Llorca"
      ],
      "abstract": "The rapid proliferation and deployment of General-Purpose AI (GPAI) models,\nincluding large language models (LLMs), present unprecedented challenges for AI\nsupervisory entities. We hypothesize that these entities will need to navigate\nan emergent ecosystem of risk and incident reporting, likely to exceed their\nsupervision capacity. To investigate this, we develop a simulation framework\nparameterized by features extracted from the diverse landscape of risk,\nincident, or hazard reporting ecosystems, including community-driven platforms,\ncrowdsourcing initiatives, and expert assessments. We evaluate four supervision\npolicies: non-prioritized (first-come, first-served), random selection,\npriority-based (addressing the highest-priority risks first), and\ndiversity-prioritized (balancing high-priority risks with comprehensive\ncoverage across risk types). Our results indicate that while priority-based and\ndiversity-prioritized policies are more effective at mitigating high-impact\nrisks, particularly those identified by experts, they may inadvertently neglect\nsystemic issues reported by the broader community. This oversight can create\nfeedback loops that amplify certain types of reporting while discouraging\nothers, leading to a skewed perception of the overall risk landscape. We\nvalidate our simulation results with several real-world datasets, including one\nwith over a million ChatGPT interactions, of which more than 150,000\nconversations were identified as risky. This validation underscores the complex\ntrade-offs inherent in AI risk supervision and highlights how the choice of\nrisk management policies can shape the future landscape of AI risks across\ndiverse GPAI models used in society.",
      "tldr_zh": "这篇论文探讨了监督策略如何影响通用 AI (GPAI) 模型的长期风险管理，特别是在处理风险和事件报告生态系统的挑战中。研究者开发了一个模拟框架，使用从社区驱动平台、众包和专家评估等来源提取的参数，来评估四种策略：非优先（先到先得）、随机选择、基于优先级和多样性优先。结果表明，优先级和多样性优先策略更有效地缓解高影响风险，但可能忽略社区报告的系统性问题，从而形成反馈循环并扭曲整体风险景观。该研究通过超过一百万的 ChatGPT 交互数据集验证了这些权衡，强调了选择适当监督策略对塑造 AI 风险管理的重要性。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06137v1",
      "published_date": "2025-01-10 17:52:34 UTC",
      "updated_date": "2025-01-10 17:52:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:11:36.799855"
    },
    {
      "arxiv_id": "2501.06132v1",
      "title": "CoDriveVLM: VLM-Enhanced Urban Cooperative Dispatching and Motion Planning for Future Autonomous Mobility on Demand Systems",
      "title_zh": "CoDriveVLM：VLM 增强的城市合作调度和运动规划，用于未来自治按需移动系统",
      "authors": [
        "Haichao Liu",
        "Ruoyu Yao",
        "Wenru Liu",
        "Zhenmin Huang",
        "Shaojie Shen",
        "Jun Ma"
      ],
      "abstract": "The increasing demand for flexible and efficient urban transportation\nsolutions has spotlighted the limitations of traditional Demand Responsive\nTransport (DRT) systems, particularly in accommodating diverse passenger needs\nand dynamic urban environments. Autonomous Mobility-on-Demand (AMoD) systems\nhave emerged as a promising alternative, leveraging connected and autonomous\nvehicles (CAVs) to provide responsive and adaptable services. However, existing\nmethods primarily focus on either vehicle scheduling or path planning, which\noften simplify complex urban layouts and neglect the necessity for simultaneous\ncoordination and mutual avoidance among CAVs. This oversimplification poses\nsignificant challenges to the deployment of AMoD systems in real-world\nscenarios. To address these gaps, we propose CoDriveVLM, a novel framework that\nintegrates high-fidelity simultaneous dispatching and cooperative motion\nplanning for future AMoD systems. Our method harnesses Vision-Language Models\n(VLMs) to enhance multi-modality information processing, and this enables\ncomprehensive dispatching and collision risk evaluation. The VLM-enhanced CAV\ndispatching coordinator is introduced to effectively manage complex and\nunforeseen AMoD conditions, thus supporting efficient scheduling\ndecision-making. Furthermore, we propose a scalable decentralized cooperative\nmotion planning method via consensus alternating direction method of\nmultipliers (ADMM) focusing on collision risk evaluation and decentralized\ntrajectory optimization. Simulation results demonstrate the feasibility and\nrobustness of CoDriveVLM in various traffic conditions, showcasing its\npotential to significantly improve the fidelity and effectiveness of AMoD\nsystems in future urban transportation networks. The code is available at\nhttps://github.com/henryhcliu/CoDriveVLM.git.",
      "tldr_zh": "该研究针对传统 Demand Responsive Transport (DRT) 系统的局限性，提出 CoDriveVLM 框架，以增强 Autonomous Mobility on Demand (AMoD) 系统的调度和运动规划能力。框架利用 Vision-Language Models (VLMs) 处理多模态信息，实现高保真同时调度和合作运动规划，包括 VLM-增强的 Connected and Autonomous Vehicles (CAVs) 调度协调器，以及基于 consensus Alternating Direction Method of Multipliers (ADMM) 的去中心化轨迹优化方法，以评估碰撞风险并优化车辆路径。模拟结果显示，CoDriveVLM 在各种交通条件下表现出色，可显著提高 AMoD 系统的保真度和有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06132v1",
      "published_date": "2025-01-10 17:44:57 UTC",
      "updated_date": "2025-01-10 17:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:11:49.166914"
    },
    {
      "arxiv_id": "2501.06129v1",
      "title": "Contextual ASR Error Handling with LLMs Augmentation for Goal-Oriented Conversational AI",
      "title_zh": "翻译失败",
      "authors": [
        "Yuya Asano",
        "Sabit Hassan",
        "Paras Sharma",
        "Anthony Sicilia",
        "Katherine Atwell",
        "Diane Litman",
        "Malihe Alikhani"
      ],
      "abstract": "General-purpose automatic speech recognition (ASR) systems do not always\nperform well in goal-oriented dialogue. Existing ASR correction methods rely on\nprior user data or named entities. We extend correction to tasks that have no\nprior user data and exhibit linguistic flexibility such as lexical and\nsyntactic variations. We propose a novel context augmentation with a large\nlanguage model and a ranking strategy that incorporates contextual information\nfrom the dialogue states of a goal-oriented conversational AI and its tasks.\nOur method ranks (1) n-best ASR hypotheses by their lexical and semantic\nsimilarity with context and (2) context by phonetic correspondence with ASR\nhypotheses. Evaluated in home improvement and cooking domains with real-world\nusers, our method improves recall and F1 of correction by 34% and 16%,\nrespectively, while maintaining precision and false positive rate. Users rated\n.8-1 point (out of 5) higher when our correction method worked properly, with\nno decrease due to false positives.",
      "tldr_zh": "该论文针对通用自动语音识别（ASR）系统在目标导向对话AI中的表现不佳问题，提出了一种使用大型语言模型（LLMs）进行上下文增强的纠错方法，以处理无先验用户数据且语言灵活的任务。方法包括一个排名策略：基于对话状态的上下文信息，对n-best ASR假设进行词汇和语义相似度排名，并对上下文进行语音对应排名。实验在家居改进和烹饪领域中显示，该方法将纠错的召回率和F1分数分别提高了34%和16%，同时保持精度和假阳性率，用户满意度也提升了0.8-1分（满分5分）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to COLING 2025 Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2501.06129v1",
      "published_date": "2025-01-10 17:35:06 UTC",
      "updated_date": "2025-01-10 17:35:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:12:00.704757"
    },
    {
      "arxiv_id": "2501.06283v1",
      "title": "Dafny as Verification-Aware Intermediate Language for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Chen Li",
        "Stefan Zetzsche",
        "Siva Somayyajula"
      ],
      "abstract": "Using large language models (LLMs) to generate source code from natural\nlanguage prompts is a popular and promising idea with a wide range of\napplications. One of its limitations is that the generated code can be faulty\nat times, often in a subtle way, despite being presented to the user as\ncorrect. In this paper, we explore ways in which formal methods can assist with\nincreasing the quality of code generated by an LLM. Instead of emitting code in\na target language directly, we propose that the user guides the LLM to first\ngenerate an opaque intermediate representation, in the verification-aware\nlanguage Dafny, that can be automatically validated for correctness against\nagreed on specifications. The correct Dafny program is then compiled to the\ntarget language and returned to the user. All user-system interactions\nthroughout the procedure occur via natural language; Dafny code is never\nexposed. We describe our current prototype and report on its performance on the\nHumanEval Python code generation benchmarks.",
      "tldr_zh": "该研究探讨了利用形式化方法提升大型语言模型(LLMs)从自然语言提示生成代码的质量问题，旨在解决生成的代码可能存在的细微错误。论文提出将Dafny作为验证感知的中间语言，让LLMs先生成Dafny程序进行自动正确性验证，然后编译为目标语言，整个过程通过自然语言交互，用户无需接触Dafny代码。主要贡献包括构建了一个原型，并在HumanEval Python代码生成基准上评估其性能，展示了提高代码可靠性的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LO",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06283v1",
      "published_date": "2025-01-10 17:23:14 UTC",
      "updated_date": "2025-01-10 17:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:12:12.710959"
    },
    {
      "arxiv_id": "2501.06117v2",
      "title": "Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Fabian David Schmidt",
        "Ivan Vulić",
        "Goran Glavaš",
        "David Ifeoluwa Adelani"
      ],
      "abstract": "Spoken language understanding (SLU) is indispensable for half of all living\nlanguages that lack a formal writing system, since these languages cannot pair\nautomatic speech recognition (ASR) with language models to benefit from\nlanguage technology. Even if low-resource languages possess a writing system,\nASR for these languages remains unreliable due to limited bimodal speech and\ntext training data. Better SLU can strengthen the robustness of massively\nmultilingual ASR by levering language semantics to disambiguate utterances via\ncontext or exploiting semantic similarities across languages. However, the\nevaluation of multilingual SLU remains limited to shallow tasks such as intent\nclassification or language identification. To address this, we present\nFleurs-SLU, a multilingual SLU benchmark that encompasses (i) 692 hours of\nspeech for topical utterance classification in 102 languages and (ii)\nmultiple-choice question answering through listening comprehension spanning 944\nhours of speech across 92 languages. We extensively evaluate both end-to-end\nspeech classification models and cascaded systems that combine speech-to-text\ntranscription with subsequent classification by large language models on\nFleurs-SLU. Our results show that cascaded systems exhibit greater robustness\nin multilingual SLU tasks, though speech encoders can achieve competitive\nperformance in topical speech classification when appropriately pre-trained. We\nfurther find a strong correlation between robust multilingual ASR, effective\nspeech-to-text translation, and strong multilingual SLU, highlighting the\nmutual benefits between acoustic and semantic speech representations.",
      "tldr_zh": "本研究提出 Fleurs-SLU，这是一个大规模多语言基准数据集，用于评估 Spoken Language Understanding (SLU)，旨在解决低资源语言在自动语音识别 (ASR) 方面的局限性，并通过语义增强 ASR 的鲁棒性。该数据集包括 692 小时语音用于 102 种语言的主题分类任务，以及 944 小时语音用于 92 种语言的听力理解多选题。实验评估了端到端语音分类模型和级联系统（结合 ASR 和 Large Language Models），结果显示级联系统在多语言 SLU 任务中更具鲁棒性，而适当预训练的语音编码器在主题分类中可实现竞争性能；此外，研究发现 ASR、语音到文本翻译与 SLU 之间存在强相关性，相互促进语义和声学表示的提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06117v2",
      "published_date": "2025-01-10 17:15:38 UTC",
      "updated_date": "2025-02-19 06:23:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:12:24.314759"
    },
    {
      "arxiv_id": "2501.06099v1",
      "title": "Explaining Deep Learning-based Anomaly Detection in Energy Consumption Data by Focusing on Contextually Relevant Data",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Noorchenarboo",
        "Katarina Grolinger"
      ],
      "abstract": "Detecting anomalies in energy consumption data is crucial for identifying\nenergy waste, equipment malfunction, and overall, for ensuring efficient energy\nmanagement. Machine learning, and specifically deep learning approaches, have\nbeen greatly successful in anomaly detection; however, they are black-box\napproaches that do not provide transparency or explanations. SHAP and its\nvariants have been proposed to explain these models, but they suffer from high\ncomputational complexity (SHAP) or instability and inconsistency (e.g., Kernel\nSHAP). To address these challenges, this paper proposes an explainability\napproach for anomalies in energy consumption data that focuses on\ncontext-relevant information. The proposed approach leverages existing\nexplainability techniques, focusing on SHAP variants, together with global\nfeature importance and weighted cosine similarity to select background dataset\nbased on the context of each anomaly point. By focusing on the context and most\nrelevant features, this approach mitigates the instability of explainability\nalgorithms. Experimental results across 10 different machine learning models,\nfive datasets, and five XAI techniques, demonstrate that our method reduces the\nvariability of explanations providing consistent explanations. Statistical\nanalyses confirm the robustness of our approach, showing an average reduction\nin variability of approximately 38% across multiple datasets.",
      "tldr_zh": "该研究针对深度学习在能源消耗数据异常检测中的黑盒问题，提出了一种聚焦上下文相关信息的解释方法，以解决 SHAP 和其变体（如 Kernel SHAP）的高计算复杂性和不稳定性。方法结合全局特征重要性（global feature importance）和加权余弦相似性（weighted cosine similarity），通过选择基于异常点的背景数据集来增强解释的稳定性，并在多种 XAI 技术中应用。实验结果显示，在 10 个机器学习模型、5 个数据集和 5 个 XAI 技术上，该方法平均减少解释变异性约 38%，从而提供更一致可靠的异常解释。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06099v1",
      "published_date": "2025-01-10 16:53:48 UTC",
      "updated_date": "2025-01-10 16:53:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:14:29.716162"
    },
    {
      "arxiv_id": "2501.06089v2",
      "title": "Towards Developing Socially Compliant Automated Vehicles: Advances, Expert Insights, and A Conceptual Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Yongqi Dong",
        "Bart van Arem",
        "Haneen Farah"
      ],
      "abstract": "Automated Vehicles (AVs) hold promise for revolutionizing transportation by\nimproving road safety, traffic efficiency, and overall mobility. Despite the\nsteady advancement in high-level AVs in recent years, the transition to full\nautomation entails a period of mixed traffic, where AVs of varying automation\nlevels coexist with human-driven vehicles (HDVs). Making AVs socially compliant\nand understood by human drivers is expected to improve the safety and\nefficiency of mixed traffic. Thus, ensuring AVs' compatibility with HDVs and\nsocial acceptance is crucial for their successful and seamless integration into\nmixed traffic. However, research in this critical area of developing Socially\nCompliant AVs (SCAVs) remains sparse. This study carries out the first\ncomprehensive scoping review to assess the current state of the art in\ndeveloping SCAVs, identifying key concepts, methodological approaches, and\nresearch gaps. An informal expert interview was also conducted to discuss the\nliterature review results and identify critical research gaps and expectations\ntowards SCAVs. Based on the scoping review and expert interview input, a\nconceptual framework is proposed for the development of SCAVs. The conceptual\nframework is evaluated using an online survey targeting researchers,\ntechnicians, policymakers, and other relevant professionals worldwide. The\nsurvey results provide valuable validation and insights, affirming the\nsignificance of the proposed conceptual framework in tackling the challenges of\nintegrating AVs into mixed-traffic environments. Additionally, future research\nperspectives and suggestions are discussed, contributing to the research and\ndevelopment agenda of SCAVs.",
      "tldr_zh": "这篇论文探讨了开发社会兼容自动车辆(SCAVs)的进展，以提升混合交通中自动车辆(AVs)和人类驾驶车辆(HDVs)共存的安全与效率。研究通过首次全面范围审查(scoping review)评估了当前状态，识别关键概念、方法和研究空白，并结合专家访谈提出一个概念框架，用于指导SCAVs的开发。该框架经在线调查验证，获得了研究人员、技术人员和政策制定者等专业人士的认可，并提供了未来研究视角和建议，以推动AVs的顺利集成。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "58 pages, 13 figures, accepted by the Journal of Communications in\n  Transportation Research",
      "pdf_url": "http://arxiv.org/pdf/2501.06089v2",
      "published_date": "2025-01-10 16:39:01 UTC",
      "updated_date": "2025-04-14 04:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:12:49.024072"
    },
    {
      "arxiv_id": "2501.06086v1",
      "title": "All AI Models are Wrong, but Some are Optimal",
      "title_zh": "所有 AI 模型都是错误的，但有些是最佳的",
      "authors": [
        "Akhil S Anand",
        "Shambhuraj Sawant",
        "Dirk Reinhardt",
        "Sebastien Gros"
      ],
      "abstract": "AI models that predict the future behavior of a system (a.k.a. predictive AI\nmodels) are central to intelligent decision-making. However, decision-making\nusing predictive AI models often results in suboptimal performance. This is\nprimarily because AI models are typically constructed to best fit the data, and\nhence to predict the most likely future rather than to enable high-performance\ndecision-making. The hope that such prediction enables high-performance\ndecisions is neither guaranteed in theory nor established in practice. In fact,\nthere is increasing empirical evidence that predictive models must be tailored\nto decision-making objectives for performance. In this paper, we establish\nformal (necessary and sufficient) conditions that a predictive model (AI-based\nor not) must satisfy for a decision-making policy established using that model\nto be optimal. We then discuss their implications for building predictive AI\nmodels for sequential decision-making.",
      "tldr_zh": "该论文指出，预测性 AI 模型通常优化数据拟合以预测最可能的结果，但这往往导致决策性能次优，因为它们并非专门针对决策目标设计。作者建立了正式的必要和充分条件，这些条件是任何预测模型（包括 AI 模型）必须满足的，以便基于该模型的决策策略实现最优性能。通过理论分析，论文强调预测模型需针对决策目标进行调整，并讨论了这些条件对构建用于 sequential decision-making 的预测 AI 模型的影响。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06086v1",
      "published_date": "2025-01-10 16:34:19 UTC",
      "updated_date": "2025-01-10 16:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:14:59.798017"
    },
    {
      "arxiv_id": "2501.06080v1",
      "title": "Scale-up Unlearnable Examples Learning with High-Performance Computing",
      "title_zh": "利用高性能计算扩展不可学习样本学习",
      "authors": [
        "Yanfan Zhu",
        "Issac Lyngaas",
        "Murali Gopalakrishnan Meena",
        "Mary Ellen I. Koran",
        "Bradley Malin",
        "Daniel Moyer",
        "Shunxing Bao",
        "Anuj Kapadia",
        "Xiao Wang",
        "Bennett Landman",
        "Yuankai Huo"
      ],
      "abstract": "Recent advancements in AI models are structured to retain user interactions,\nwhich could inadvertently include sensitive healthcare data. In the healthcare\nfield, particularly when radiologists use AI-driven diagnostic tools hosted on\nonline platforms, there is a risk that medical imaging data may be repurposed\nfor future AI training without explicit consent, spotlighting critical privacy\nand intellectual property concerns around healthcare data usage. Addressing\nthese privacy challenges, a novel approach known as Unlearnable Examples (UEs)\nhas been introduced, aiming to make data unlearnable to deep learning models. A\nprominent method within this area, called Unlearnable Clustering (UC), has\nshown improved UE performance with larger batch sizes but was previously\nlimited by computational resources. To push the boundaries of UE performance\nwith theoretically unlimited resources, we scaled up UC learning across various\ndatasets using Distributed Data Parallel (DDP) training on the Summit\nsupercomputer. Our goal was to examine UE efficacy at high-performance\ncomputing (HPC) levels to prevent unauthorized learning and enhance data\nsecurity, particularly exploring the impact of batch size on UE's\nunlearnability. Utilizing the robust computational capabilities of the Summit,\nextensive experiments were conducted on diverse datasets such as Pets,\nMedMNist, Flowers, and Flowers102. Our findings reveal that both overly large\nand overly small batch sizes can lead to performance instability and affect\naccuracy. However, the relationship between batch size and unlearnability\nvaried across datasets, highlighting the necessity for tailored batch size\nstrategies to achieve optimal data protection. Our results underscore the\ncritical role of selecting appropriate batch sizes based on the specific\ncharacteristics of each dataset to prevent learning and ensure data security in\ndeep learning applications.",
      "tldr_zh": "本文研究了使用高性能计算 (HPC) 来扩展 Unlearnable Examples (UEs) 的学习，旨在解决AI模型可能未经授权使用敏感医疗数据的问题，特别是通过 Unlearnable Clustering (UC) 方法使数据无法被深度学习模型学习。研究者利用 Distributed Data Parallel (DDP) 在 Summit 超级计算机上进行大规模训练，实验涉及Pets、MedMNist、Flowers和Flowers102等数据集。结果表明，批处理大小对UE的unlearnability影响显著：过大或过小均可能导致性能不稳定，不同数据集需采用定制策略以优化数据保护和安全性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06080v1",
      "published_date": "2025-01-10 16:15:23 UTC",
      "updated_date": "2025-01-10 16:15:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:13:13.054804"
    },
    {
      "arxiv_id": "2501.06078v1",
      "title": "Explaining k-Nearest Neighbors: Abductive and Counterfactual Explanations",
      "title_zh": "解释 k-最近邻：溯因和反事实解释",
      "authors": [
        "Pablo Barceló",
        "Alexander Kozachinskiy",
        "Miguel Romero Orth",
        "Bernardo Subercaseaux",
        "José Verschae"
      ],
      "abstract": "Despite the wide use of $k$-Nearest Neighbors as classification models, their\nexplainability properties remain poorly understood from a theoretical\nperspective. While nearest neighbors classifiers offer interpretability from a\n\"data perspective\", in which the classification of an input vector $\\bar{x}$ is\nexplained by identifying the vectors $\\bar{v}_1, \\ldots, \\bar{v}_k$ in the\ntraining set that determine the classification of $\\bar{x}$, we argue that such\nexplanations can be impractical in high-dimensional applications, where each\nvector has hundreds or thousands of features and it is not clear what their\nrelative importance is. Hence, we focus on understanding nearest neighbor\nclassifications through a \"feature perspective\", in which the goal is to\nidentify how the values of the features in $\\bar{x}$ affect its classification.\nConcretely, we study abductive explanations such as \"minimum sufficient\nreasons\", which correspond to sets of features in $\\bar{x}$ that are enough to\nguarantee its classification, and \"counterfactual explanations\" based on the\nminimum distance feature changes one would have to perform in $\\bar{x}$ to\nchange its classification. We present a detailed landscape of positive and\nnegative complexity results for counterfactual and abductive explanations,\ndistinguishing between discrete and continuous feature spaces, and considering\nthe impact of the choice of distance function involved. Finally, we show that\ndespite some negative complexity results, Integer Quadratic Programming and SAT\nsolving allow for computing explanations in practice.",
      "tldr_zh": "这篇论文探讨了 k-Nearest Neighbors (k-NN) 分类器的解释性问题，指出传统从“数据视角”解释（如基于最近邻样本）在高维空间中不实用，转而采用“特征视角”来分析特征值对分类的影响。研究重点是 abductive explanations（如 minimum sufficient reasons，即一组特征足以保证分类）和 counterfactual explanations（如最小特征变化来改变分类）。论文分析了这些解释的复杂性，包括正负结果，区分离散和连续特征空间，并考虑距离函数的影响；尽管存在计算挑战，但通过 Integer Quadratic Programming 和 SAT solving 可以实际实现这些解释。总的来说，该工作为提升 k-NN 模型的可解释性提供了理论框架和实用方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06078v1",
      "published_date": "2025-01-10 16:14:35 UTC",
      "updated_date": "2025-01-10 16:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:15:17.219151"
    },
    {
      "arxiv_id": "2501.06066v3",
      "title": "Distilling Calibration via Conformalized Credal Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayi Huang",
        "Sangwoo Park",
        "Nicola Paoletti",
        "Osvaldo Simeone"
      ],
      "abstract": "Deploying artificial intelligence (AI) models on edge devices involves a\ndelicate balance between meeting stringent complexity constraints, such as\nlimited memory and energy resources, and ensuring reliable performance in\nsensitive decision-making tasks. One way to enhance reliability is through\nuncertainty quantification via Bayesian inference. This approach, however,\ntypically necessitates maintaining and running multiple models in an ensemble,\nwhich may exceed the computational limits of edge devices. This paper\nintroduces a low-complexity methodology to address this challenge by distilling\ncalibration information from a more complex model. In an offline phase,\npredictive probabilities generated by a high-complexity cloud-based model are\nleveraged to determine a threshold based on the typical divergence between the\ncloud and edge models. At run time, this threshold is used to construct credal\nsets -- ranges of predictive probabilities that are guaranteed, with a\nuser-selected confidence level, to include the predictions of the cloud model.\nThe credal sets are obtained through thresholding of a divergence measure in\nthe simplex of predictive probabilities. Experiments on visual and language\ntasks demonstrate that the proposed approach, termed Conformalized Distillation\nfor Credal Inference (CD-CI), significantly improves calibration performance\ncompared to low-complexity Bayesian methods, such as Laplace approximation,\nmaking it a practical and efficient solution for edge AI deployments.",
      "tldr_zh": "该论文提出了一种低复杂度方法，Distilling Calibration via Conformalized Credal Inference（CD-CI），旨在解决边缘设备AI部署中复杂性限制与可靠性能的平衡问题，特别是通过Bayesian推理进行不确定性量化时面临的计算挑战。方法在离线阶段利用云端复杂模型的预测概率确定一个阈值，基于云端和边缘模型的差异度量来构建credal sets，这些sets以用户选择的置信水平保证包含云端预测。实验结果显示，CD-CI在视觉和语言任务上显著提升校准性能，比传统低复杂度Bayesian方法如Laplace approximation更高效，从而为边缘AI部署提供实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2501.06066v3",
      "published_date": "2025-01-10 15:57:23 UTC",
      "updated_date": "2025-05-01 13:04:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:13:36.988312"
    },
    {
      "arxiv_id": "2501.06282v1",
      "title": "MinMo: A Multimodal Large Language Model for Seamless Voice Interaction",
      "title_zh": "MinMo：用于无缝语音交互的多模态大型语言模型",
      "authors": [
        "Qian Chen",
        "Yafeng Chen",
        "Yanni Chen",
        "Mengzhe Chen",
        "Yingda Chen",
        "Chong Deng",
        "Zhihao Du",
        "Ruize Gao",
        "Changfeng Gao",
        "Zhifu Gao",
        "Yabin Li",
        "Xiang Lv",
        "Jiaqing Liu",
        "Haoneng Luo",
        "Bin Ma",
        "Chongjia Ni",
        "Xian Shi",
        "Jialong Tang",
        "Hui Wang",
        "Hao Wang",
        "Wen Wang",
        "Yuxuan Wang",
        "Yunlan Xu",
        "Fan Yu",
        "Zhijie Yan",
        "Yexin Yang",
        "Baosong Yang",
        "Xian Yang",
        "Guanrou Yang",
        "Tianyu Zhao",
        "Qinglin Zhang",
        "Shiliang Zhang",
        "Nan Zhao",
        "Pei Zhang",
        "Chong Zhang",
        "Jinren Zhou"
      ],
      "abstract": "Recent advancements in large language models (LLMs) and multimodal\nspeech-text models have laid the groundwork for seamless voice interactions,\nenabling real-time, natural, and human-like conversations. Previous models for\nvoice interactions are categorized as native and aligned. Native models\nintegrate speech and text processing in one framework but struggle with issues\nlike differing sequence lengths and insufficient pre-training. Aligned models\nmaintain text LLM capabilities but are often limited by small datasets and a\nnarrow focus on speech tasks. In this work, we introduce MinMo, a Multimodal\nLarge Language Model with approximately 8B parameters for seamless voice\ninteraction. We address the main limitations of prior aligned multimodal\nmodels. We train MinMo through multiple stages of speech-to-text alignment,\ntext-to-speech alignment, speech-to-speech alignment, and duplex interaction\nalignment, on 1.4 million hours of diverse speech data and a broad range of\nspeech tasks. After the multi-stage training, MinMo achieves state-of-the-art\nperformance across various benchmarks for voice comprehension and generation\nwhile maintaining the capabilities of text LLMs, and also facilitates\nfull-duplex conversation, that is, simultaneous two-way communication between\nthe user and the system. Moreover, we propose a novel and simple voice decoder\nthat outperforms prior models in voice generation. The enhanced\ninstruction-following capabilities of MinMo supports controlling speech\ngeneration based on user instructions, with various nuances including emotions,\ndialects, and speaking rates, and mimicking specific voices. For MinMo, the\nspeech-to-text latency is approximately 100ms, full-duplex latency is\napproximately 600ms in theory and 800ms in practice. The MinMo project web page\nis https://funaudiollm.github.io/minmo, and the code and models will be\nreleased soon.",
      "tldr_zh": "本研究引入了MinMo，一种约8B参数的多模态Large Language Model（LLM），旨在实现无缝语音交互，解决现有native和aligned模型的局限性，如序列长度差异和数据集规模问题。通过多阶段训练，包括speech-to-text alignment、text-to-speech alignment、speech-to-speech alignment和duplex interaction alignment，使用1.4百万小时的多样化语音数据，MinMo在语音理解和生成基准上达到了state-of-the-art（SOTA）性能，同时保留了文本LLM的能力，并支持全双工对话。创新点包括一个新型简单的语音解码器，提升了语音生成质量，并允许根据用户指令控制语音细节，如情绪、方言和语速，以及模仿特定声音。实验显示，MinMo的speech-to-text延迟约为100ms，全双工延迟理论上600ms、实际800ms，为实时自然语音交互提供了高效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress. Authors are listed in alphabetical order by family\n  name",
      "pdf_url": "http://arxiv.org/pdf/2501.06282v1",
      "published_date": "2025-01-10 15:55:27 UTC",
      "updated_date": "2025-01-10 15:55:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:13:48.770132"
    },
    {
      "arxiv_id": "2501.06051v1",
      "title": "Benchmarking Rotary Position Embeddings for Automatic Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Shucong Zhang",
        "Titouan Parcollet",
        "Rogier van Dalen",
        "Sourav Bhattacharya"
      ],
      "abstract": "Rotary Position Embedding (RoPE) encodes relative and absolute positional\ninformation in Transformer-based models through rotation matrices applied to\ninput vectors within sequences. While RoPE has demonstrated superior\nperformance compared to other positional embedding technologies in natural\nlanguage processing tasks, its effectiveness in speech processing applications\nremains understudied. In this work, we conduct a comprehensive evaluation of\nRoPE across diverse automatic speech recognition (ASR) tasks. Our experimental\nresults demonstrate that for ASR tasks, RoPE consistently achieves lower error\nrates compared to the currently widely used relative positional embedding. To\nfacilitate further research, we release the implementation and all experimental\nrecipes through the SpeechBrain toolkit.",
      "tldr_zh": "本文研究评估了 Rotary Position Embedding (RoPE) 在 Automatic Speech Recognition (ASR) 任务中的性能，RoPE 通过旋转矩阵在 Transformer 模型中编码序列的相对和绝对位置信息，并在自然语言处理任务中已证明优于其他技术。作者进行了全面实验，比较 RoPE 与传统相对位置嵌入，结果显示 RoPE 在各种 ASR 任务中实现了更低的错误率。研究还通过 SpeechBrain 工具包发布了实现代码和实验配方，以促进后续研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06051v1",
      "published_date": "2025-01-10 15:30:46 UTC",
      "updated_date": "2025-01-10 15:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:15:27.769176"
    },
    {
      "arxiv_id": "2501.06039v1",
      "title": "AI-powered virtual tissues from spatial proteomics for clinical diagnostics and biomedical discovery",
      "title_zh": "基于空间蛋白质组学的 AI 驱动虚拟组织，用于临床诊断和生物医学发现",
      "authors": [
        "Johann Wenckstern",
        "Eeshaan Jain",
        "Kiril Vasilev",
        "Matteo Pariset",
        "Andreas Wicki",
        "Gabriele Gut",
        "Charlotte Bunne"
      ],
      "abstract": "Spatial proteomics technologies have transformed our understanding of complex\ntissue architectures by enabling simultaneous analysis of multiple molecular\nmarkers and their spatial organization. The high dimensionality of these data,\nvarying marker combinations across experiments and heterogeneous study designs\npose unique challenges for computational analysis. Here, we present Virtual\nTissues (VirTues), a foundation model framework for biological tissues that\noperates across the molecular, cellular and tissue scale. VirTues introduces\ninnovations in transformer architecture design, including a novel tokenization\nscheme that captures both spatial and marker dimensions, and attention\nmechanisms that scale to high-dimensional multiplex data while maintaining\ninterpretability. Trained on diverse cancer and non-cancer tissue datasets,\nVirTues demonstrates strong generalization capabilities without task-specific\nfine-tuning, enabling cross-study analysis and novel marker integration. As a\ngeneralist model, VirTues outperforms existing approaches across clinical\ndiagnostics, biological discovery and patient case retrieval tasks, while\nproviding insights into tissue function and disease mechanisms.",
      "tldr_zh": "本研究提出 VirTues，一种基于 AI 的基础模型框架，利用 Spatial proteomics 数据构建虚拟组织模型，以支持临床诊断和生物医学发现。该框架创新性地设计了 transformer 架构，包括一种捕捉空间和标记维度的 tokenization 方案，以及可扩展到高维多重数据的注意力机制，从而处理数据高维度和异质性的挑战。VirTues 在多样化癌症和非癌症组织数据集上训练后，无需任务特定微调就展现出强大泛化能力，在临床诊断、生物发现和患者案例检索任务中优于现有方法，并为组织功能和疾病机制提供可解释性洞见。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "23 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06039v1",
      "published_date": "2025-01-10 15:17:27 UTC",
      "updated_date": "2025-01-10 15:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:15:40.101063"
    },
    {
      "arxiv_id": "2501.06025v1",
      "title": "How to Tune a Multilingual Encoder Model for Germanic Languages: A Study of PEFT, Full Fine-Tuning, and Language Adapters",
      "title_zh": "翻译失败",
      "authors": [
        "Romina Oji",
        "Jenny Kunz"
      ],
      "abstract": "This paper investigates the optimal use of the multilingual encoder model\nmDeBERTa for tasks in three Germanic languages -- German, Swedish, and\nIcelandic -- representing varying levels of presence and likely data quality in\nmDeBERTas pre-training data. We compare full fine-tuning with the\nparameter-efficient fine-tuning (PEFT) methods LoRA and Pfeiffer bottleneck\nadapters, finding that PEFT is more effective for the higher-resource language,\nGerman. However, results for Swedish and Icelandic are less consistent. We also\nobserve differences between tasks: While PEFT tends to work better for question\nanswering, full fine-tuning is preferable for named entity recognition.\nInspired by previous research on modular approaches that combine task and\nlanguage adapters, we evaluate the impact of adding PEFT modules trained on\nunstructured text, finding that this approach is not beneficial.",
      "tldr_zh": "这篇论文研究了如何优化多语言编码器模型 mDeBERTa，以适应德语、瑞典语和冰岛语等日耳曼语言的特定任务，通过比较 full fine-tuning、PEFT 方法（如 LoRA 和 Pfeiffer bottleneck adapters）的效果。结果显示，PEFT 在资源丰富的德语任务中更具优势，但对瑞典语和冰岛语的表现不一致；此外，PEFT 在问答任务中优于 full fine-tuning，而后者在命名实体识别任务中更佳。论文还评估了添加基于无结构文本训练的 PEFT 模块，但发现这种 modular 方式并未带来显著益处。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NoDaLiDa Baltic-HLT 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2501.06025v1",
      "published_date": "2025-01-10 15:01:51 UTC",
      "updated_date": "2025-01-10 15:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:15:52.582991"
    },
    {
      "arxiv_id": "2501.06019v3",
      "title": "BRIGHT: A globally distributed multimodal building damage assessment dataset with very-high-resolution for all-weather disaster response",
      "title_zh": "翻译失败",
      "authors": [
        "Hongruixuan Chen",
        "Jian Song",
        "Olivier Dietrich",
        "Clifford Broni-Bediako",
        "Weihao Xuan",
        "Junjue Wang",
        "Xinlei Shao",
        "Yimin Wei",
        "Junshi Xia",
        "Cuiling Lan",
        "Konrad Schindler",
        "Naoto Yokoya"
      ],
      "abstract": "Disaster events occur around the world and cause significant damage to human\nlife and property. Earth observation (EO) data enables rapid and comprehensive\nbuilding damage assessment (BDA), an essential capability in the aftermath of a\ndisaster to reduce human casualties and to inform disaster relief efforts.\nRecent research focuses on the development of AI models to achieve accurate\nmapping of unseen disaster events, mostly using optical EO data. However,\nsolutions based on optical data are limited to clear skies and daylight hours,\npreventing a prompt response to disasters. Integrating multimodal (MM) EO data,\nparticularly the combination of optical and SAR imagery, makes it possible to\nprovide all-weather, day-and-night disaster responses. Despite this potential,\nthe development of robust multimodal AI models has been constrained by the lack\nof suitable benchmark datasets. In this paper, we present a BDA dataset using\nveRy-hIGH-resoluTion optical and SAR imagery (BRIGHT) to support AI-based\nall-weather disaster response. To the best of our knowledge, BRIGHT is the\nfirst open-access, globally distributed, event-diverse MM dataset specifically\ncurated to support AI-based disaster response. It covers five types of natural\ndisasters and two types of man-made disasters across 14 regions worldwide, with\na particular focus on developing countries where external assistance is most\nneeded. The optical and SAR imagery in BRIGHT, with a spatial resolution\nbetween 0.3-1 meters, provides detailed representations of individual\nbuildings, making it ideal for precise BDA. In our experiments, we have tested\nseven advanced AI models trained with our BRIGHT to validate the\ntransferability and robustness. The dataset and code are available at\nhttps://github.com/ChenHongruixuan/BRIGHT. BRIGHT also serves as the official\ndataset for the 2025 IEEE GRSS Data Fusion Contest.",
      "tldr_zh": "本研究介绍了BRIGHT数据集，这是一个全球分布的多模态(MM)建筑损伤评估(BDA)数据集，利用高分辨率(0.3-1米)光学和SAR图像，支持全天候灾害响应。BRIGHT覆盖五种自然灾害和两种人为灾害，涉及14个地区的多样化事件，特别是发展中国家，以克服传统光学EO数据受限于晴天和白天的局限性。通过实验验证，七个先进AI模型在BRIGHT上训练显示出良好的鲁棒性和可转移性；数据集及其代码已开源，并作为2025 IEEE GRSS Data Fusion Contest的官方资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06019v3",
      "published_date": "2025-01-10 14:57:18 UTC",
      "updated_date": "2025-04-18 12:07:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:16:04.775190"
    },
    {
      "arxiv_id": "2501.05989v1",
      "title": "Addressing speaker gender bias in large scale speech translation systems",
      "title_zh": "解决大规模语音翻译系统中的说话者性别偏见",
      "authors": [
        "Shubham Bansal",
        "Vikas Joshi",
        "Harveen Chadha",
        "Rupeshkumar Mehta",
        "Jinyu Li"
      ],
      "abstract": "This study addresses the issue of speaker gender bias in Speech Translation\n(ST) systems, which can lead to offensive and inaccurate translations. The\nmasculine bias often found in large-scale ST systems is typically perpetuated\nthrough training data derived from Machine Translation (MT) systems. Our\napproach involves two key steps. First, we employ Large Language Models (LLMs)\nto rectify translations based on the speaker's gender in a cost-effective\nmanner. Second, we fine-tune the ST model with the corrected data, enabling the\nmodel to generate gender-specific translations directly from audio cues,\nwithout the need for explicit gender input. Additionally, we propose a\nthree-mode fine-tuned model for scenarios where the speaker's gender is either\npredefined or should not be inferred from speech cues. We demonstrate a 70%\nimprovement in translations for female speakers compared to our baseline and\nother large-scale ST systems, such as Seamless M4T and Canary, on the MuST-SHE\ntest set.",
      "tldr_zh": "这篇论文针对大规模语音翻译（ST）系统中的说话者性别偏见问题进行研究，该偏见往往源于机器翻译（MT）系统的训练数据，导致翻译不准确或冒犯性。研究方法包括两步：首先，使用大型语言模型（LLMs）以成本有效的方式修正基于说话者性别的翻译；其次，通过修正数据微调 ST 模型，使其能从音频线索直接生成性别特定翻译，而无需显式输入性别。论文还提出一个三模式微调模型，适用于说话者性别预定义或不从语音线索推断的场景。实验结果显示，在 MuST-SHE 测试集上，与基线系统如 Seamless M4T 和 Canary 相比，女说话者的翻译准确率提高了 70%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05989v1",
      "published_date": "2025-01-10 14:20:46 UTC",
      "updated_date": "2025-01-10 14:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:16:17.426708"
    },
    {
      "arxiv_id": "2501.05962v1",
      "title": "Effective faking of verbal deception detection with target-aligned adversarial attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Bennett Kleinberg",
        "Riccardo Loconte",
        "Bruno Verschuere"
      ],
      "abstract": "Background: Deception detection through analysing language is a promising\navenue using both human judgments and automated machine learning judgments. For\nboth forms of credibility assessment, automated adversarial attacks that\nrewrite deceptive statements to appear truthful pose a serious threat. Methods:\nWe used a dataset of 243 truthful and 262 fabricated autobiographical stories\nin a deception detection task for humans and machine learning models. A large\nlanguage model was tasked to rewrite deceptive statements so that they appear\ntruthful. In Study 1, humans who made a deception judgment or used the\ndetailedness heuristic and two machine learning models (a fine-tuned language\nmodel and a simple n-gram model) judged original or adversarial modifications\nof deceptive statements. In Study 2, we manipulated the target alignment of the\nmodifications, i.e. tailoring the attack to whether the statements would be\nassessed by humans or computer models. Results: When adversarial modifications\nwere aligned with their target, human (d=-0.07 and d=-0.04) and machine\njudgments (51% accuracy) dropped to the chance level. When the attack was not\naligned with the target, both human heuristics judgments (d=0.30 and d=0.36)\nand machine learning predictions (63-78%) were significantly better than\nchance. Conclusions: Easily accessible language models can effectively help\nanyone fake deception detection efforts both by humans and machine learning\nmodels. Robustness against adversarial modifications for humans and machines\ndepends on that target alignment. We close with suggestions on advancing\ndeception research with adversarial attack designs.",
      "tldr_zh": "该研究探讨了通过目标对齐的对抗攻击（adversarial attacks）来伪造语言欺骗检测（deception detection）的有效性，使用大语言模型（large language model）重写欺骗性语句，使其看起来真实。研究基于一个包含真实和编造故事的数据集，进行了两项实验：Study 1 测试人类和机器模型对原始或修改语句的判断，Study 2 操纵攻击的目标对齐（针对人类或机器）。结果显示，当攻击与目标对齐时，人类判断（d=-0.07 和 d=-0.04）和机器准确率（51%）降至随机水平；反之，判断显著优于随机水平（人类 d=0.30 和 d=0.36，机器 63-78%）。该工作强调了大语言模型在欺骗检测中的潜在威胁，并建议通过对抗攻击设计来提升人类和机器的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2501.05962v1",
      "published_date": "2025-01-10 13:42:40 UTC",
      "updated_date": "2025-01-10 13:42:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:16:29.135913"
    },
    {
      "arxiv_id": "2501.05932v1",
      "title": "DiffuSETS: 12-lead ECG Generation Conditioned on Clinical Text Reports and Patient-Specific Information",
      "title_zh": "Diffu",
      "authors": [
        "Yongfan Lai",
        "Jiabo Chen",
        "Deyun Zhang",
        "Yue Wang",
        "Shijia Geng",
        "Hongyan Li",
        "Shenda Hong"
      ],
      "abstract": "Heart disease remains a significant threat to human health. As a non-invasive\ndiagnostic tool, the electrocardiogram (ECG) is one of the most widely used\nmethods for cardiac screening. However, the scarcity of high-quality ECG data,\ndriven by privacy concerns and limited medical resources, creates a pressing\nneed for effective ECG signal generation. Existing approaches for generating\nECG signals typically rely on small training datasets, lack comprehensive\nevaluation frameworks, and overlook potential applications beyond data\naugmentation. To address these challenges, we propose DiffuSETS, a novel\nframework capable of generating ECG signals with high semantic alignment and\nfidelity. DiffuSETS accepts various modalities of clinical text reports and\npatient-specific information as inputs, enabling the creation of clinically\nmeaningful ECG signals. Additionally, to address the lack of standardized\nevaluation in ECG generation, we introduce a comprehensive benchmarking\nmethodology to assess the effectiveness of generative models in this domain.\nOur model achieve excellent results in tests, proving its superiority in the\ntask of ECG generation. Furthermore, we showcase its potential to mitigate data\nscarcity while exploring novel applications in cardiology education and medical\nknowledge discovery, highlighting the broader impact of our work.",
      "tldr_zh": "该研究针对ECG数据稀缺的问题，提出DiffuSETS框架，使用扩散模型生成12-lead ECG信号，该框架以临床文本报告和患者特定信息作为条件输入，确保生成的ECG信号具有高语义对齐和保真度。同时，研究引入了一个全面的基准测试方法来评估ECG生成模型的有效性。实验结果显示，DiffuSETS在测试中表现出色，不仅缓解了数据稀缺问题，还为心脏病学教育和医疗知识发现提供了新应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05932v1",
      "published_date": "2025-01-10 12:55:34 UTC",
      "updated_date": "2025-01-10 12:55:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:16:39.899841"
    },
    {
      "arxiv_id": "2501.05928v1",
      "title": "Towards Backdoor Stealthiness in Model Parameter Space",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyun Xu",
        "Zhuoran Liu",
        "Stefanos Koffas",
        "Stjepan Picek"
      ],
      "abstract": "Recent research on backdoor stealthiness focuses mainly on indistinguishable\ntriggers in input space and inseparable backdoor representations in feature\nspace, aiming to circumvent backdoor defenses that examine these respective\nspaces. However, existing backdoor attacks are typically designed to resist a\nspecific type of backdoor defense without considering the diverse range of\ndefense mechanisms. Based on this observation, we pose a natural question: Are\ncurrent backdoor attacks truly a real-world threat when facing diverse\npractical defenses?\n  To answer this question, we examine 12 common backdoor attacks that focus on\ninput-space or feature-space stealthiness and 17 diverse representative\ndefenses. Surprisingly, we reveal a critical blind spot: Backdoor attacks\ndesigned to be stealthy in input and feature spaces can be mitigated by\nexamining backdoored models in parameter space. To investigate the underlying\ncauses behind this common vulnerability, we study the characteristics of\nbackdoor attacks in the parameter space. Notably, we find that input- and\nfeature-space attacks introduce prominent backdoor-related neurons in parameter\nspace, which are not thoroughly considered by current backdoor attacks. Taking\ncomprehensive stealthiness into account, we propose a novel supply-chain attack\ncalled Grond. Grond limits the parameter changes by a simple yet effective\nmodule, Adversarial Backdoor Injection (ABI), which adaptively increases the\nparameter-space stealthiness during the backdoor injection. Extensive\nexperiments demonstrate that Grond outperforms all 12 backdoor attacks against\nstate-of-the-art (including adaptive) defenses on CIFAR-10, GTSRB, and a subset\nof ImageNet. In addition, we show that ABI consistently improves the\neffectiveness of common backdoor attacks.",
      "tldr_zh": "本研究探讨了后门攻击（backdoor attacks）的隐蔽性，指出现有攻击虽在输入空间和特征空间（input space and feature space）上设计隐蔽，但易被参数空间（parameter space）防御检测。通过评估12种常见攻击和17种代表性防御，发现这些攻击在参数空间暴露了显著的后门相关神经元（backdoor-related neurons），从而削弱其真实威胁。作者提出了一种新型供应链攻击Grond，利用Adversarial Backdoor Injection (ABI)模块来适配地限制参数变化，提升整体隐蔽性。实验结果显示，Grond在CIFAR-10、GTSRB和ImageNet子集上优于12种基线攻击，并有效对抗最先进防御，同时ABI模块还能增强其他后门攻击的性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05928v1",
      "published_date": "2025-01-10 12:49:12 UTC",
      "updated_date": "2025-01-10 12:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:16:52.493948"
    },
    {
      "arxiv_id": "2501.05921v1",
      "title": "The New Anticipatory Governance Culture for Innovation: Regulatory Foresight, Regulatory Experimentation and Regulatory Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Deirdre Ahern"
      ],
      "abstract": "With the rapid pace of technological innovation, traditional methods of\npolicy formation and legislating are becoming conspicuously anachronistic. The\nneed for regulatory choices to be made to counter the deadening effect of\nregulatory lag is more important to developing markets and fostering growth\nthan achieving one off regulatory perfection. This article advances scholarship\non innovation policy and the regulation of technological innovation in the\nEuropean Union. It does so by considering what building an agile yet robust\nanticipatory governance regulatory culture involves. It systematically\nexcavates a variety of tools and elements that are being put into use in\ninventive ways and argues that these need to be more cohesively and\nsystemically integrated into the regulatory toolbox. Approaches covered include\nstrategic foresight, the critical embrace of iterative policy development and\nregulatory learning in the face of uncertainty and the embrace of bottom up\napproaches to cocreation of policy such as Policy Labs and the testing and\nregulatory learning through pilot regulation and experimentation. The growing\nuse of regulatory sandboxes as an EU policy tool to boost innovation and\nnavigate regulatory complexity as seen in the EU AI Act is also probed",
      "tldr_zh": "这篇论文探讨了技术创新的快速步伐如何使传统政策和立法方法变得过时，并强调通过监管选择应对监管滞后（regulatory lag）以促进市场发展和增长。论文推进了欧盟创新政策和科技监管的学术研究，提出构建敏捷而稳健的预见性治理（anticipatory governance）监管文化。关键方法包括战略预见（strategic foresight）、迭代政策发展、监管学习（regulatory learning）、以及自下而上的政策共同创建工具，如 Policy Labs 和试点监管实验（regulatory experimentation）。论文还分析了监管沙盒（regulatory sandboxes）在欧盟 AI Act 中的应用，主张这些工具需更系统地整合，以提升创新和处理监管复杂性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05921v1",
      "published_date": "2025-01-10 12:26:38 UTC",
      "updated_date": "2025-01-10 12:26:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:17:04.497567"
    },
    {
      "arxiv_id": "2502.03469v1",
      "title": "A Capability Approach to AI Ethics",
      "title_zh": "翻译失败",
      "authors": [
        "Emanuele Ratti",
        "Mark Graves"
      ],
      "abstract": "We propose a conceptualization and implementation of AI ethics via the\ncapability approach. We aim to show that conceptualizing AI ethics through the\ncapability approach has two main advantages for AI ethics as a discipline.\nFirst, it helps clarify the ethical dimension of AI tools. Second, it provides\nguidance to implementing ethical considerations within the design of AI tools.\nWe illustrate these advantages in the context of AI tools in medicine, by\nshowing how ethics-based auditing of AI tools in medicine can greatly benefit\nfrom our capability-based approach.",
      "tldr_zh": "本论文提出使用 capability approach 来概念化和实施 AI 伦理，这有助于 AI 伦理学科的两个主要优势：一是明确 AI 工具的伦理维度，二是指导在 AI 工具设计中融入伦理考虑。作者通过医疗 AI 工具的案例说明，这种方法能显著提升基于伦理的审计过程。整体框架为开发更负责任的 AI 系统提供了实用指导。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03469v1",
      "published_date": "2025-01-10 12:08:21 UTC",
      "updated_date": "2025-01-10 12:08:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:17:15.745708"
    },
    {
      "arxiv_id": "2501.05891v2",
      "title": "Affordably Fine-tuned LLMs Provide Better Answers to Course-specific MCQs",
      "title_zh": "翻译失败",
      "authors": [
        "Bianca Raimondi",
        "Saverio Giallorenzo",
        "Maurizio Gabbrielli"
      ],
      "abstract": "In education, the capability of generating human-like text of Large Language\nModels (LLMs) inspired work on how they can increase the efficiency of learning\nand teaching. We study the affordability of these models for educators and\nstudents by investigating how LLMs answer multiple-choice questions (MCQs) with\nrespect to hardware constraints and refinement techniques. We explore this\nspace by using generic pre-trained LLMs (the 7B, 13B, and 70B variants of\nLLaMA-2) to answer 162 undergraduate-level MCQs from a course on Programming\nLanguages (PL) -- the MCQ dataset is a contribution of this work, which we make\npublicly available. Specifically, we dissect how different factors, such as\nusing readily-available material -- (parts of) the course's textbook -- for\nfine-tuning and quantisation (to decrease resource usage) can change the\naccuracy of the responses. The main takeaway is that smaller textbook-based\nfine-tuned models outperform generic larger ones (whose pre-training requires\nconspicuous resources), making the usage of LLMs for answering MCQs resource-\nand material-wise affordable.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在教育中的应用，特别是如何通过经济高效的方式回答课程特定多选题(MCQs)。研究者使用LLaMA-2的7B、13B和70B变体测试了162个本科编程语言课程MCQs数据集（该数据集作为新贡献公开可用），并通过fine-tuning（使用课程教材部分）和quantisation技术来优化模型性能。结果显示，较小的fine-tuned模型在准确性上超过了更大的通用模型，从而证明了这种方法在硬件资源和材料方面更具可负担性，为教育场景中的LLMs应用提供了实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The 40th ACM/SIGAPP Symposium On Applied Computing",
      "pdf_url": "http://arxiv.org/pdf/2501.05891v2",
      "published_date": "2025-01-10 11:44:35 UTC",
      "updated_date": "2025-03-05 09:18:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:17:29.415836"
    },
    {
      "arxiv_id": "2501.05885v1",
      "title": "EDNet: Edge-Optimized Small Target Detection in UAV Imagery -- Faster Context Attention, Better Feature Fusion, and Hardware Acceleration",
      "title_zh": "翻译失败",
      "authors": [
        "Zhifan Song",
        "Yuan Zhang",
        "Abd Al Rahman M. Abu Ebayyeh"
      ],
      "abstract": "Detecting small targets in drone imagery is challenging due to low\nresolution, complex backgrounds, and dynamic scenes. We propose EDNet, a novel\nedge-target detection framework built on an enhanced YOLOv10 architecture,\noptimized for real-time applications without post-processing. EDNet\nincorporates an XSmall detection head and a Cross Concat strategy to improve\nfeature fusion and multi-scale context awareness for detecting tiny targets in\ndiverse environments. Our unique C2f-FCA block employs Faster Context Attention\nto enhance feature extraction while reducing computational complexity. The WIoU\nloss function is employed for improved bounding box regression. With seven\nmodel sizes ranging from Tiny to XL, EDNet accommodates various deployment\nenvironments, enabling local real-time inference and ensuring data privacy.\nNotably, EDNet achieves up to a 5.6% gain in mAP@50 with significantly fewer\nparameters. On an iPhone 12, EDNet variants operate at speeds ranging from 16\nto 55 FPS, providing a scalable and efficient solution for edge-based object\ndetection in challenging drone imagery. The source code and pre-trained models\nare available at: https://github.com/zsniko/EDNet.",
      "tldr_zh": "该研究针对无人机图像中小目标检测的挑战（如低分辨率、复杂背景和动态场景），提出了 EDNet 框架，该框架基于增强的 YOLOv10 架构，优化了实时应用并省去了后处理。EDNet 引入 XSmall 检测头、Cross Concat 策略和 C2f-FCA 块（利用 Faster Context Attention 提升特征提取效率）、WIoU 损失函数，以改善特征融合、多尺度上下文感知和边界框回归，同时降低计算复杂度。实验结果显示，EDNet 在 mAP@50 上比基线提升 5.6%，参数更少，并在 iPhone 12 上实现 16-55 FPS 的实时推理，提供可扩展的边缘优化解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in 21st IEEE International Conference on Ubiquitous\n  Intelligence and Computing (UIC 2024)\n  https://www.ieee-smart-world.org/2024/uic",
      "pdf_url": "http://arxiv.org/pdf/2501.05885v1",
      "published_date": "2025-01-10 11:37:50 UTC",
      "updated_date": "2025-01-10 11:37:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:17:41.515361"
    },
    {
      "arxiv_id": "2501.05882v1",
      "title": "Solving nonograms using Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "José María Buades Rubio",
        "Antoni Jaume-i-Capó",
        "David López González",
        "Gabriel Moyà Alcover"
      ],
      "abstract": "Nonograms are logic puzzles in which cells in a grid must be colored or left\nblank according to the numbers that are located in its headers. In this study,\nwe analyze different techniques to solve this type of logical problem using an\nHeuristic Algorithm, Genetic Algorithm, and Heuristic Algorithm with Neural\nNetwork. Furthermore, we generate a public dataset to train the neural\nnetworks. We published this dataset and the code of the algorithms. Combination\nof the heuristic algorithm with a neural network obtained the best results.\nFrom state of the art review, no previous works used neural network to solve\nnonograms, nor combined a network with other algorithms to accelerate the\nresolution process.",
      "tldr_zh": "这篇论文探讨了使用 Neural Networks 等方法解决 Nonograms 逻辑谜题，具体分析了 Heuristic Algorithm、Genetic Algorithm 和 Heuristic Algorithm 与 Neural Network 结合的三种技术。研究者生成并公开了一个公共数据集，用于训练 Neural Networks，并分享了相关算法代码。结果表明，Heuristic Algorithm 与 Neural Network 的结合表现最佳，且这是首次将 Neural Networks 应用于 Nonograms 的解决或与其他算法结合以加速过程。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05882v1",
      "published_date": "2025-01-10 11:34:22 UTC",
      "updated_date": "2025-01-10 11:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:17:53.474006"
    },
    {
      "arxiv_id": "2501.05874v2",
      "title": "VideoRAG: Retrieval-Augmented Generation over Video Corpus",
      "title_zh": "VideoRAG：视频语料库上的检索增强生成",
      "authors": [
        "Soyeong Jeong",
        "Kangsan Kim",
        "Jinheon Baek",
        "Sung Ju Hwang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) is a powerful strategy for improving the\nfactual accuracy of models by retrieving external knowledge relevant to queries\nand incorporating it into the generation process. However, existing approaches\nprimarily focus on text, with some recent advancements considering images, and\nthey largely overlook videos, a rich source of multimodal knowledge capable of\nrepresenting contextual details more effectively than any other modality. While\nvery recent studies explore the use of videos in response generation, they\neither predefine query-associated videos without retrieval or convert videos\ninto textual descriptions losing multimodal richness. To tackle these, we\nintroduce VideoRAG, a framework that not only dynamically retrieves videos\nbased on their relevance with queries but also utilizes both visual and textual\ninformation. The operation of VideoRAG is powered by recent Large Video\nLanguage Models (LVLMs), which enable the direct processing of video content to\nrepresent it for retrieval and the seamless integration of retrieved videos\njointly with queries for response generation. Also, inspired by that the\ncontext size of LVLMs may not be sufficient to process all frames in extremely\nlong videos and not all frames are equally important, we introduce a video\nframe selection mechanism to extract the most informative subset of frames,\nalong with a strategy to extract textual information from videos (as it can aid\nthe understanding of video content) when their subtitles are not available. We\nexperimentally validate the effectiveness of VideoRAG, showcasing that it is\nsuperior to relevant baselines. Code is available at\nhttps://github.com/starsuzi/VideoRAG.",
      "tldr_zh": "该论文提出VideoRAG框架，以扩展Retrieval-Augmented Generation (RAG)至视频语料库，解决现有方法忽略视频多模态特性的问题。VideoRAG动态检索与查询相关的视频，并利用Large Video Language Models (LVLMs)处理视觉和文本信息，包括视频帧选择机制来提取最重要的帧子集，以及从视频中提取文本信息策略。实验结果显示，VideoRAG在响应生成任务中优于基线模型，提升了事实准确性和上下文理解能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05874v2",
      "published_date": "2025-01-10 11:17:15 UTC",
      "updated_date": "2025-03-04 07:29:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:18:04.694882"
    },
    {
      "arxiv_id": "2501.05845v1",
      "title": "Annealing Machine-assisted Learning of Graph Neural Network for Combinatorial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Pablo Loyola",
        "Kento Hasegawa",
        "Andres Hoyos-Idobro",
        "Kazuo Ono",
        "Toyotaro Suzumura",
        "Yu Hirate",
        "Masanao Yamaoka"
      ],
      "abstract": "While Annealing Machines (AM) have shown increasing capabilities in solving\ncomplex combinatorial problems, positioning themselves as a more immediate\nalternative to the expected advances of future fully quantum solutions, there\nare still scaling limitations. In parallel, Graph Neural Networks (GNN) have\nbeen recently adapted to solve combinatorial problems, showing competitive\nresults and potentially high scalability due to their distributed nature. We\npropose a merging approach that aims at retaining both the accuracy exhibited\nby AMs and the representational flexibility and scalability of GNNs. Our model\nconsiders a compression step, followed by a supervised interaction where\npartial solutions obtained from the AM are used to guide local GNNs from where\nnode feature representations are obtained and combined to initialize an\nadditional GNN-based solver that handles the original graph's target problem.\nIntuitively, the AM can solve the combinatorial problem indirectly by infusing\nits knowledge into the GNN. Experiments on canonical optimization problems show\nthat the idea is feasible, effectively allowing the AM to solve size problems\nbeyond its original limits.",
      "tldr_zh": "本论文提出了一种将Annealing Machines (AM) 与Graph Neural Networks (GNN) 相结合的方法，用于解决组合优化问题，旨在融合AM的高准确性和GNN的可伸缩性，以克服AM的规模限制。方法包括一个压缩步骤和监督交互过程，其中AM的部分解决方案用于指导本地GNN提取节点特征表示，随后这些表示被整合到一个额外的GNN求解器中，以处理原始图的问题，从而实现AM知识向GNN的间接注入。实验在经典优化问题上验证了这一方法的有效性，证明它能使AM处理超出其原始规模限制的问题。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Second Workshop on Machine Learning with New Compute Paradigms at\n  NeurIPS 2024 (MLNCP 2024)",
      "pdf_url": "http://arxiv.org/pdf/2501.05845v1",
      "published_date": "2025-01-10 10:36:46 UTC",
      "updated_date": "2025-01-10 10:36:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:18:16.793955"
    },
    {
      "arxiv_id": "2501.05826v2",
      "title": "AI-Driven Diabetic Retinopathy Screening: Multicentric Validation of AIDRSS in India",
      "title_zh": "AI驱动的糖尿病视网膜病变筛查：AIDRSS 在印度的多中心验证",
      "authors": [
        "Amit Kr Dey",
        "Pradeep Walia",
        "Girish Somvanshi",
        "Abrar Ali",
        "Sagarnil Das",
        "Pallabi Paul",
        "Minakhi Ghosh"
      ],
      "abstract": "Purpose: Diabetic retinopathy (DR) is a major cause of vision loss,\nparticularly in India, where access to retina specialists is limited in rural\nareas. This study aims to evaluate the Artificial Intelligence-based Diabetic\nRetinopathy Screening System (AIDRSS) for DR detection and prevalence\nassessment, addressing the growing need for scalable, automated screening\nsolutions in resource-limited settings.\n  Approach: A multicentric, cross-sectional study was conducted in Kolkata,\nIndia, involving 5,029 participants and 10,058 macula-centric retinal fundus\nimages. The AIDRSS employed a deep learning algorithm with 50 million trainable\nparameters, integrated with Contrast Limited Adaptive Histogram Equalization\n(CLAHE) preprocessing for enhanced image quality. DR was graded using the\nInternational Clinical Diabetic Retinopathy (ICDR) Scale, categorizing disease\ninto five stages (DR0 to DR4). Statistical metrics including sensitivity,\nspecificity, and prevalence rates were evaluated against expert retina\nspecialist assessments.\n  Results: The prevalence of DR in the general population was 13.7%, rising to\n38.2% among individuals with elevated random blood glucose levels. The AIDRSS\nachieved an overall sensitivity of 92%, specificity of 88%, and 100%\nsensitivity for detecting referable DR (DR3 and DR4). These results demonstrate\nthe system's robust performance in accurately identifying and grading DR in a\ndiverse population.\n  Conclusions: AIDRSS provides a reliable, scalable solution for early DR\ndetection in resource-constrained environments. Its integration of advanced AI\ntechniques ensures high diagnostic accuracy, with potential to significantly\nreduce the burden of diabetes-related vision loss in underserved regions.",
      "tldr_zh": "本研究评估了AIDRSS（Artificial Intelligence-based Diabetic Retinopathy Screening System）在印度的多中心验证，用于糖尿病视网膜病变（DR）筛查，旨在解决农村地区缺乏视网膜专家的问题。研究采用深度学习算法（5000万参数）和CLAHE预处理，对5029名参与者的10058张视网膜图像进行分析，并使用ICDR Scale对DR进行分级（DR0至DR4）。结果显示，DR总体流行率为13.7%，高血糖人群中升至38.2%，AIDRSS的敏感性达92%、特异性88%，并对可转诊DR（DR3和DR4）实现100%敏感性。该系统提供可靠、可扩展的AI解决方案，有助于在资源有限环境中早期检测DR并减少视力损失风险。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "22 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.05826v2",
      "published_date": "2025-01-10 10:03:56 UTC",
      "updated_date": "2025-01-13 08:56:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:18:30.077762"
    },
    {
      "arxiv_id": "2501.05819v1",
      "title": "Diffusion Models for Smarter UAVs: Decision-Making and Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yousef Emami",
        "Hao Zhou",
        "Luis Almeida",
        "Kai Li"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly adopted in modern\ncommunication networks. However, challenges in decision-making and digital\nmodeling continue to impede their rapid advancement. Reinforcement Learning\n(RL) algorithms face limitations such as low sample efficiency and limited data\nversatility, further magnified in UAV communication scenarios. Moreover,\nDigital Twin (DT) modeling introduces substantial decision-making and data\nmanagement complexities. RL models, often integrated into DT frameworks,\nrequire extensive training data to achieve accurate predictions. In contrast to\ntraditional approaches that focus on class boundaries, Diffusion Models (DMs),\na new class of generative AI, learn the underlying probability distribution\nfrom the training data and can generate trustworthy new patterns based on this\nlearned distribution. This paper explores the integration of DMs with RL and DT\nto effectively address these challenges. By combining the data generation\ncapabilities of DMs with the decision-making framework of RL and the modeling\naccuracy of DT, the integration improves the adaptability and real-time\nperformance of UAV communication. Moreover, the study shows how DMs can\nalleviate data scarcity, improve policy networks, and optimize dynamic\nmodeling, providing a robust solution for complex UAV communication scenarios.",
      "tldr_zh": "这篇论文探讨了使用Diffusion Models (DMs)来提升无人驾驶飞机 (UAVs) 在通信网络中的决策和建模能力，旨在解决强化学习 (RL) 的低样本效率和数据局限性，以及Digital Twin (DT) 的决策复杂性问题。通过将DMs的生成数据能力与RL的决策框架和DT的建模精度相结合，论文显著改善了UAVs的适应性和实时性能。研究结果显示，这种整合方法能缓解数据稀缺问题、优化策略网络，并为复杂UAV通信场景提供可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "53-01",
        "C.2; I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.05819v1",
      "published_date": "2025-01-10 09:59:16 UTC",
      "updated_date": "2025-01-10 09:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:18:41.132841"
    },
    {
      "arxiv_id": "2501.05808v1",
      "title": "Real-Time Integrated Dispatching and Idle Fleet Steering with Deep Reinforcement Learning for A Meal Delivery Platform",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyi Cheng",
        "Shadi Sharif Azadeh"
      ],
      "abstract": "To achieve high service quality and profitability, meal delivery platforms\nlike Uber Eats and Grubhub must strategically operate their fleets to ensure\ntimely deliveries for current orders while mitigating the consequential impacts\nof suboptimal decisions that leads to courier understaffing in the future. This\nstudy set out to solve the real-time order dispatching and idle courier\nsteering problems for a meal delivery platform by proposing a reinforcement\nlearning (RL)-based strategic dual-control framework. To address the inherent\nsequential nature of these problems, we model both order dispatching and\ncourier steering as Markov Decision Processes. Trained via a deep reinforcement\nlearning (DRL) framework, we obtain strategic policies by leveraging the\nexplicitly predicted demands as part of the inputs. In our dual-control\nframework, the dispatching and steering policies are iteratively trained in an\nintegrated manner. These forward-looking policies can be executed in real-time\nand provide decisions while jointly considering the impacts on local and\nnetwork levels. To enhance dispatching fairness, we propose convolutional deep\nQ networks to construct fair courier embeddings. To simultaneously rebalance\nthe supply and demand within the service network, we propose to utilize\nmean-field approximated supply-demand knowledge to reallocate idle couriers at\nthe local level. Utilizing the policies generated by the RL-based strategic\ndual-control framework, we find the delivery efficiency and fairness of\nworkload distribution among couriers have been improved, and under-supplied\nconditions have been alleviated within the service network. Our study sheds\nlight on designing an RL-based framework to enable forward-looking real-time\noperations for meal delivery platforms and other on-demand services.",
      "tldr_zh": "这篇论文提出了一种基于 Deep Reinforcement Learning (DRL) 的双重控制框架，用于餐食配送平台的实时订单调度和闲置配送员引导，以确保及时交付并缓解未来供需不平衡问题。该框架将订单调度和配送员引导建模为 Markov Decision Processes (MDP)，并通过迭代训练集成策略，利用预测需求作为输入，同时引入卷积深度 Q 网络构建公平的配送员嵌入，并采用均值场逼近 (mean-field approximated) 的供需知识重新分配闲置配送员。实验结果显示，该方法显著提高了配送效率、工作负载分布的公平性，并缓解了服务网络中的供需短缺问题。该研究为餐食配送平台和其他按需服务设计前瞻性的实时操作框架提供了重要见解。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05808v1",
      "published_date": "2025-01-10 09:15:40 UTC",
      "updated_date": "2025-01-10 09:15:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:18:54.151310"
    },
    {
      "arxiv_id": "2501.05803v3",
      "title": "Test-time Alignment of Diffusion Models without Reward Over-optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Sunwoo Kim",
        "Minkyu Kim",
        "Dongmin Park"
      ],
      "abstract": "Diffusion models excel in generative tasks, but aligning them with specific\nobjectives while maintaining their versatility remains challenging. Existing\nfine-tuning methods often suffer from reward over-optimization, while\napproximate guidance approaches fail to optimize target rewards effectively.\nAddressing these limitations, we propose a training-free, test-time method\nbased on Sequential Monte Carlo (SMC) to sample from the reward-aligned target\ndistribution. Our approach, tailored for diffusion sampling and incorporating\ntempering techniques, achieves comparable or superior target rewards to\nfine-tuning methods while preserving diversity and cross-reward generalization.\nWe demonstrate its effectiveness in single-reward optimization, multi-objective\nscenarios, and online black-box optimization. This work offers a robust\nsolution for aligning diffusion models with diverse downstream objectives\nwithout compromising their general capabilities. Code is available at\nhttps://github.com/krafton-ai/DAS.",
      "tldr_zh": "该论文针对 Diffusion models 在生成任务中的对齐挑战，提出了一种无需训练的测试时方法，以避免奖励过度优化（reward over-optimization）。该方法利用 Sequential Monte Carlo (SMC) 结合 tempering 技术，从奖励对齐的目标分布中采样，实现高效的优化。实验结果显示，该方法在单奖励优化、多目标场景和在线黑盒优化中，取得了与 fine-tuning 方法相当或更好的目标奖励，同时保持了模型的多样性和跨奖励泛化能力。该工作为 Diffusion models 与多样下游目标对齐提供了稳健的解决方案，而不牺牲其一般能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 (Spotlight). The Thirteenth International Conference on\n  Learning Representations. 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05803v3",
      "published_date": "2025-01-10 09:10:30 UTC",
      "updated_date": "2025-04-17 12:23:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:19:05.211763"
    },
    {
      "arxiv_id": "2501.05795v3",
      "title": "Robust Counterfactual Explanations under Model Multiplicity Using Multi-Objective Optimization",
      "title_zh": "在模型多样性下使用多目标优化的鲁棒反事实解释",
      "authors": [
        "Keita Kinjo"
      ],
      "abstract": "In recent years, explainability in machine learning has gained importance. In\nthis context, counterfactual explanation (CE), which is an explanation method\nthat uses examples, has attracted attention. However, it has been pointed out\nthat CE is not robust when there are multiple machine-learning models with\nsimilar accuracy. These problems are important when using machine learning to\nmake safe decisions. In this paper, we propose robust CEs that introduce a new\nviewpoint -- Pareto improvement -- and a method that uses multi-objective\noptimization to generate it. To evaluate the proposed method, we conducted\nexperiments using both simulated and real data. The results demonstrate that\nthe proposed method is both robust and practical. This study highlights the\npotential of ensuring robustness in decision-making by applying the concept of\nsocial welfare. We believe that this research can serve as a valuable\nfoundation for various fields, including explainability in machine learning,\ndecision-making, and action planning based on machine learning.",
      "tldr_zh": "该论文针对机器学习模型多样性（Model Multiplicity）下 Counterfactual Explanation (CE) 的鲁棒性问题，提出了一种新方法，通过引入 Pareto improvement 的视角并使用 Multi-Objective Optimization 生成鲁棒的 CE。实验使用模拟和真实数据验证了该方法的鲁棒性和实用性，展示了其在确保决策安全方面的潜力。该研究为解释性机器学习、决策和基于机器学习的行动规划等领域提供了重要基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.05795v3",
      "published_date": "2025-01-10 08:57:50 UTC",
      "updated_date": "2025-02-03 06:07:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:19:16.159781"
    },
    {
      "arxiv_id": "2501.05790v1",
      "title": "Understanding Impact of Human Feedback via Influence Functions",
      "title_zh": "通过影响函数理解人类反馈的影响",
      "authors": [
        "Taywon Min",
        "Haeone Lee",
        "Hanho Ryu",
        "Yongchan Kwon",
        "Kimin Lee"
      ],
      "abstract": "In Reinforcement Learning from Human Feedback (RLHF), it is crucial to learn\nsuitable reward models from human feedback to align large language models\n(LLMs) with human intentions. However, human feedback can often be noisy,\ninconsistent, or biased, especially when evaluating complex responses. Such\nfeedback can lead to misaligned reward signals, potentially causing unintended\nside effects during the RLHF process. To address these challenges, we explore\nthe use of influence functions to measure the impact of human feedback on the\nperformance of reward models. We propose a compute-efficient approximation\nmethod that enables the application of influence functions to LLM-based reward\nmodels and large-scale preference datasets. In our experiments, we demonstrate\ntwo key applications of influence functions: (1) detecting common forms of\nlabeler bias in human feedback datasets and (2) guiding labelers to refine\ntheir strategies to align more closely with expert feedback. By quantifying the\nimpact of human feedback on reward models, we believe that influence functions\ncan enhance feedback interpretability and contribute to scalable oversight in\nRLHF, helping labelers provide more accurate and consistent feedback. Source\ncode is available at https://github.com/mintaywon/IF_RLHF",
      "tldr_zh": "这篇论文探讨了在强化学习从人类反馈（RLHF）中，使用 influence functions 来评估人类反馈对奖励模型性能的影响，以解决反馈的噪声、不一致性和偏差问题。作者提出了一种计算高效的近似方法，适用于大型语言模型（LLMs）-based 奖励模型和大规模偏好数据集。实验结果显示，该方法能有效检测标签偏差并指导标签者优化策略，使反馈更接近专家水平，从而提升 RLHF 的可解释性和可扩展监督。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Source code: https://github.com/mintaywon/IF_RLHF",
      "pdf_url": "http://arxiv.org/pdf/2501.05790v1",
      "published_date": "2025-01-10 08:50:38 UTC",
      "updated_date": "2025-01-10 08:50:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:19:28.414107"
    },
    {
      "arxiv_id": "2501.05783v1",
      "title": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Yanjie Li",
        "Wenxuan Zhang",
        "Kaisheng Liang",
        "Bin Xiao"
      ],
      "abstract": "In recent research, adversarial attacks on person detectors using patches or\nstatic 3D model-based texture modifications have struggled with low success\nrates due to the flexible nature of human movement. Modeling the 3D\ndeformations caused by various actions has been a major challenge. Fortunately,\nadvancements in Neural Radiance Fields (NeRF) for dynamic human modeling offer\nnew possibilities. In this paper, we introduce UV-Attack, a groundbreaking\napproach that achieves high success rates even with extensive and unseen human\nactions. We address the challenge above by leveraging dynamic-NeRF-based UV\nmapping. UV-Attack can generate human images across diverse actions and\nviewpoints, and even create novel actions by sampling from the SMPL parameter\nspace. While dynamic NeRF models are capable of modeling human bodies,\nmodifying clothing textures is challenging because they are embedded in neural\nnetwork parameters. To tackle this, UV-Attack generates UV maps instead of RGB\nimages and modifies the texture stacks. This approach enables real-time texture\nedits and makes the attack more practical. We also propose a novel Expectation\nover Pose Transformation loss (EoPT) to improve the evasion success rate on\nunseen poses and views. Our experiments show that UV-Attack achieves a 92.75%\nattack success rate against the FastRCNN model across varied poses in dynamic\nvideo settings, significantly outperforming the state-of-the-art AdvCamou\nattack, which only had a 28.50% ASR. Moreover, we achieve 49.5% ASR on the\nlatest YOLOv8 detector in black-box settings. This work highlights the\npotential of dynamic NeRF-based UV mapping for creating more effective\nadversarial attacks on person detectors, addressing key challenges in modeling\nhuman movement and texture modification.",
      "tldr_zh": "该研究提出 UV-Attack，一种基于 dynamic-NeRF 的 UV 映射方法，用于物理世界对抗攻击人检测器，以应对现有方法在处理人类动作灵活性时的低成功率。UV-Attack 通过生成动态人类图像、修改 UV 地图而非直接纹理堆栈，实现实时编辑，并引入 Expectation over Pose Transformation loss (EoPT) 来提升对未见姿势和视角的攻击效果。实验结果显示，在动态视频设置中，UV-Attack 对 FastRCNN 的攻击成功率达到 92.75%，显著优于 AdvCamou 的 28.50%；在黑盒设置下，对 YOLOv8 的成功率达 49.5%，证明了其在建模人类运动和纹理修改方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 22 figures, submitted to ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05783v1",
      "published_date": "2025-01-10 08:33:31 UTC",
      "updated_date": "2025-01-10 08:33:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:19:42.288905"
    },
    {
      "arxiv_id": "2501.06274v2",
      "title": "Polarized Patterns of Language Toxicity and Sentiment of Debunking Posts on Social Media",
      "title_zh": "翻译失败",
      "authors": [
        "Wentao Xu",
        "Wenlu Fan",
        "Shiqian Lu",
        "Tenghao Li",
        "Bin Wang"
      ],
      "abstract": "The rise of misinformation and fake news in online political discourse poses\nsignificant challenges to democratic processes and public engagement. While\ndebunking efforts aim to counteract misinformation and foster fact-based\ndialogue, these discussions often involve language toxicity and emotional\npolarization. We examined over 86 million debunking tweets and more than 4\nmillion Reddit debunking comments to investigate the relationship between\nlanguage toxicity, pessimism, and social polarization in debunking efforts.\nFocusing on discussions of the 2016 and 2020 U.S. presidential elections and\nthe QAnon conspiracy theory, our analysis reveals three key findings: (1)\nperipheral participants (1-degree users) play a disproportionate role in\nshaping toxic discourse, driven by lower community accountability and emotional\nexpression; (2) platform mechanisms significantly influence polarization, with\nTwitter amplifying partisan differences and Reddit fostering higher overall\ntoxicity due to its structured, community-driven interactions; and (3) a\nnegative correlation exists between language toxicity and pessimism, with\nincreased interaction reducing toxicity, especially on Reddit. We show that\nplatform architecture affects informational complexity of user interactions,\nwith Twitter promoting concentrated, uniform discourse and Reddit encouraging\ndiverse, complex communication. Our findings highlight the importance of user\nengagement patterns, platform dynamics, and emotional expressions in shaping\npolarization in debunking discourse. This study offers insights for\npolicymakers and platform designers to mitigate harmful effects and promote\nhealthier online discussions, with implications for understanding\nmisinformation, hate speech, and political polarization in digital\nenvironments.",
      "tldr_zh": "本文研究了社交媒体上辟谣帖子的语言毒性、悲观主义与社会极化的模式，通过分析超过8600万条Twitter推文和400万条Reddit评论，聚焦2016和2020年美国总统选举以及QAnon阴谋论。关键发现包括：外围参与者（1-degree users）在塑造有毒话语中发挥不成比例的作用，Twitter放大了党派差异而Reddit因其社区驱动互动导致更高毒性，以及语言毒性与悲观主义呈负相关，增加互动可显著降低毒性。研究强调平台架构（如Twitter的统一话语和Reddit的多样沟通）影响用户互动的信息复杂性，并为政策制定者和平台设计师提供见解，以缓解误信息、仇恨言论和政治极化的有害影响。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06274v2",
      "published_date": "2025-01-10 08:00:58 UTC",
      "updated_date": "2025-01-31 16:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:19:53.416917"
    },
    {
      "arxiv_id": "2501.05768v1",
      "title": "Halal or Not: Knowledge Graph Completion for Predicting Cultural Appropriateness of Daily Products",
      "title_zh": "翻译失败",
      "authors": [
        "Van Thuy Hoang",
        "Tien-Bach-Thanh Do",
        "Jinho Seo",
        "Seung Charlie Kim",
        "Luong Vuong Nguyen",
        "Duong Nguyen Minh Huy",
        "Hyeon-Ju Jeon",
        "O-Joun Lee"
      ],
      "abstract": "The growing demand for halal cosmetic products has exposed significant\nchallenges, especially in Muslim-majority countries. Recently, various machine\nlearning-based strategies, e.g., image-based methods, have shown remarkable\nsuccess in predicting the halal status of cosmetics. However, these methods\nmainly focus on analyzing the discrete and specific ingredients within separate\ncosmetics, which ignore the high-order and complex relations between cosmetics\nand ingredients. To address this problem, we propose a halal cosmetic\nrecommendation framework, namely HaCKG, that leverages a knowledge graph of\ncosmetics and their ingredients to explicitly model and capture the\nrelationships between cosmetics and their components. By representing cosmetics\nand ingredients as entities within the knowledge graph, HaCKG effectively\nlearns the high-order and complex relations between entities, offering a robust\nmethod for predicting halal status. Specifically, we first construct a cosmetic\nknowledge graph representing the relations between various cosmetics,\ningredients, and their properties. We then propose a pre-trained relational\ngraph attention network model with residual connections to learn the structural\nrelation between entities in the knowledge graph. The pre-trained model is then\nfine-tuned on downstream cosmetic data to predict halal status. Extensive\nexperiments on the cosmetic dataset over halal prediction tasks demonstrate the\nsuperiority of our model over state-of-the-art baselines.",
      "tldr_zh": "该研究针对清真化妆品预测的需求，提出HaCKG框架，利用Knowledge Graph来捕捉化妆品及其成分之间的高阶复杂关系，以提升文化适宜性预测准确性。框架首先构建化妆品知识图谱，将化妆品和成分作为实体来表示关系，然后采用预训练的关系图注意力网络(Relational Graph Attention Network)模型，结合残差连接进行实体关系的学习，并通过微调来预测清真状态。实验结果显示，在化妆品数据集上的清真预测任务中，HaCKG模型优于现有基线方法，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.05768v1",
      "published_date": "2025-01-10 07:56:30 UTC",
      "updated_date": "2025-01-10 07:56:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:20:04.004674"
    },
    {
      "arxiv_id": "2501.05767v3",
      "title": "Migician: Revealing the Magic of Free-Form Multi-Image Grounding in Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "You Li",
        "Heyu Huang",
        "Chi Chen",
        "Kaiyu Huang",
        "Chao Huang",
        "Zonghao Guo",
        "Zhiyuan Liu",
        "Jinan Xu",
        "Yuhua Li",
        "Ruixuan Li",
        "Maosong Sun"
      ],
      "abstract": "The recent advancement of Multimodal Large Language Models (MLLMs) has\nsignificantly improved their fine-grained perception of single images and\ngeneral comprehension across multiple images. However, existing MLLMs still\nface challenges in achieving precise grounding in complex multi-image\nscenarios. To address this, we first explore a Chain-of-Thought (CoT) framework\nthat integrates single-image grounding with multi-image comprehension. While\npartially effective, it remains unstable and struggles to capture abstract\nvisual information due to its non-end-to-end nature. Therefore, we introduce\nMigician, the first multi-image grounding model capable of performing free-form\nand accurate grounding across multiple images. To support this, we present the\nMGrounding-630k dataset, which comprises data for several multi-image grounding\ntasks derived from existing datasets, along with newly generated free-form\ngrounding instruction-following data. Furthermore, we propose MIG-Bench, a\ncomprehensive benchmark specifically designed for evaluating multi-image\ngrounding capabilities. Experimental results demonstrate that our model\nachieves significantly superior multi-image grounding capabilities,\noutperforming the best existing MLLMs by 24.94% and even surpassing much larger\n70B models. Our code, model, dataset, and benchmark are fully open-sourced at\nhttps://migician-vg.github.io/.",
      "tldr_zh": "该研究揭示了 Multimodal Large Language Models (MLLMs) 在多图像场景中精确 grounding 的挑战，并引入了 Migician，这是一个首个支持自由形式多图像 grounding 的模型，通过整合 Chain-of-Thought (CoT) 框架实现端到端的改进。研究者构建了 MGrounding-630k 数据集，提供多图像 grounding 任务数据，以及 MIG-Bench 基准，用于全面评估模型性能。实验结果显示，Migician 比现有最佳 MLLMs 提升了 24.94%，甚至超过了 70B 级模型的性能，所有资源均已开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.05767v3",
      "published_date": "2025-01-10 07:56:23 UTC",
      "updated_date": "2025-02-18 02:40:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:20:17.206549"
    },
    {
      "arxiv_id": "2501.05765v2",
      "title": "Deontic Temporal Logic for Formal Verification of AI Ethics",
      "title_zh": "翻译失败",
      "authors": [
        "Priya T. V.",
        "Shrisha Rao"
      ],
      "abstract": "Ensuring ethical behavior in Artificial Intelligence (AI) systems amidst\ntheir increasing ubiquity and influence is a major concern the world over. The\nuse of formal methods in AI ethics is a possible crucial approach for\nspecifying and verifying the ethical behavior of AI systems. This paper\nproposes a formalization based on deontic logic to define and evaluate the\nethical behavior of AI systems, focusing on system-level specifications,\ncontributing to this important goal. It introduces axioms and theorems to\ncapture ethical requirements related to fairness and explainability. The\nformalization incorporates temporal operators to reason about the ethical\nbehavior of AI systems over time. The authors evaluate the effectiveness of\nthis formalization by assessing the ethics of the real-world COMPAS and loan\nprediction AI systems. Various ethical properties of the COMPAS and loan\nprediction systems are encoded using deontic logical formulas, allowing the use\nof an automated theorem prover to verify whether these systems satisfy the\ndefined properties. The formal verification reveals that both systems fail to\nfulfill certain key ethical properties related to fairness and\nnon-discrimination, demonstrating the effectiveness of the proposed\nformalization in identifying potential ethical issues in real-world AI\napplications.",
      "tldr_zh": "本论文提出了一种基于 deontic logic 的形式化方法，用于指定和验证 AI 系统的伦理行为，旨在通过系统级规范来确保公平性和 explainability 等要求。作者引入了公理、定理以及 temporal operators，以处理 AI 系统在时间维度上的伦理动态。论文通过对真实世界 AI 系统如 COMPAS 和贷款预测系统进行编码和自动定理证明，揭示这些系统未能满足关键的公平性和非歧视性属性。总体而言，此方法证明了 deontic temporal logic 在识别 AI 伦理问题方面的有效性，为 AI 伦理验证提供了坚实基础。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "I.2.m; F.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05765v2",
      "published_date": "2025-01-10 07:48:40 UTC",
      "updated_date": "2025-05-14 16:47:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:20:27.500724"
    },
    {
      "arxiv_id": "2501.05752v1",
      "title": "Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sungjae Lee",
        "Hyejin Park",
        "Jaechang Kim",
        "Jungseul Ok"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have shown remarkable\npotential in various complex tasks requiring multi-step reasoning methods like\ntree search to explore diverse reasoning paths. However, existing methods often\nsuffer from computational inefficiency and redundancy. First, they overlook the\ndiversity of task difficulties, leading to unnecessarily extensive searches\neven for easy tasks. Second, they neglect the semantics of reasoning paths,\nresulting in redundant exploration of semantically identical paths. To address\nthese limitations, we propose Semantic Exploration with Adaptive Gating (SEAG),\na computationally efficient method. SEAG employs an adaptive gating mechanism\nthat dynamically decides whether to conduct a tree search, based on the\nconfidence level of answers from a preceding simple reasoning method.\nFurthermore, its tree-based exploration consolidates semantically identical\nreasoning steps, reducing redundant explorations while maintaining or even\nimproving accuracy. Our extensive experiments demonstrate that SEAG\nsignificantly improves accuracy by 4.3% on average while requiring only 31% of\ncomputational costs compared to existing tree search-based methods on complex\nreasoning benchmarks including GSM8K and ARC with diverse language models such\nas Llama2, Llama3, and Mistral.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在多步推理任务中的计算效率问题，提出了Semantic Exploration with Adaptive Gating (SEAG)方法，以解决现有树搜索方法忽略任务难度差异和语义冗余的问题。SEAG采用自适应门控机制，根据简单推理的置信度动态决定是否进行树搜索，同时通过合并语义相同的推理步骤减少冗余探索。实验结果显示，在GSM8K和ARC等基准上，SEAG平均准确率提高4.3%，而计算成本仅为现有方法的31%，适用于Llama2、Llama3和Mistral等模型。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05752v1",
      "published_date": "2025-01-10 07:02:43 UTC",
      "updated_date": "2025-01-10 07:02:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:22:33.848856"
    },
    {
      "arxiv_id": "2505.09616v1",
      "title": "SpecWav-Attack: Leveraging Spectrogram Resizing and Wav2Vec 2.0 for Attacking Anonymized Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqi Li",
        "Yuanzhong Zheng",
        "Zhongtian Guo",
        "Yaoxuan Wang",
        "Jianjun Yin",
        "Haojun Fei"
      ],
      "abstract": "This paper presents SpecWav-Attack, an adversarial model for detecting\nspeakers in anonymized speech. It leverages Wav2Vec2 for feature extraction and\nincorporates spectrogram resizing and incremental training for improved\nperformance. Evaluated on librispeech-dev and librispeech-test, SpecWav-Attack\noutperforms conventional attacks, revealing vulnerabilities in anonymized\nspeech systems and emphasizing the need for stronger defenses, benchmarked\nagainst the ICASSP 2025 Attacker Challenge.",
      "tldr_zh": "这篇论文提出了SpecWav-Attack，一种对抗模型，用于检测匿名语音中的说话者，旨在揭示语音匿名系统的安全漏洞。\n该模型利用Wav2Vec 2.0进行特征提取，并结合spectrogram resizing和incremental training来提升攻击性能。\n在librispeech-dev和librispeech-test数据集上，SpecWav-Attack超过了传统攻击方法，强调了加强匿名语音防御的必要性，并与ICASSP 2025 Attacker Challenge基准进行了比较。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "I.2.0"
      ],
      "primary_category": "cs.SD",
      "comment": "2 pages,3 figures,1 chart",
      "pdf_url": "http://arxiv.org/pdf/2505.09616v1",
      "published_date": "2025-01-10 06:18:41 UTC",
      "updated_date": "2025-01-10 06:18:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:20:52.604274"
    },
    {
      "arxiv_id": "2501.05730v1",
      "title": "Element-wise Attention Is All You Need",
      "title_zh": "翻译失败",
      "authors": [
        "Guoxin Feng"
      ],
      "abstract": "The self-attention (SA) mechanism has demonstrated superior performance\nacross various domains, yet it suffers from substantial complexity during both\ntraining and inference. The next-generation architecture, aiming at retaining\nthe competitive performance of SA while achieving low-cost inference and\nefficient long-sequence training, primarily focuses on three approaches: linear\nattention, linear RNNs, and state space models. Although these approaches\nachieve reduced complexity than SA, they all have built-in performance\ndegradation factors, such as diminished “spikiness” and compression of\nhistorical information. In contrast to these approaches, we propose a novel\nelement-wise attention mechanism, which uses the element-wise squared Euclidean\ndistance, instead of the dot product operation, to compute similarity and\napproximates the quadratic complexity term $\\exp(q_{ic}k_{jc})$ with a Taylor\npolynomial. This design achieves remarkable efficiency: during training, the\nelement-wise attention has a complexity of $\\mathcal{O}(tLD)$, making\nlong-sequence training both computationally and memory efficient, where $L$ is\nthe sequence length, $D$ is the feature dimension, and $t$ is the highest order\nof the polynomial; during inference, it can be reformulated as recurrent neural\nnetworks, achieving a inference complexity of $\\mathcal{O}(tD)$. Furthermore,\nthe element-wise attention circumvents the performance degradation factors\npresent in these approaches and achieves performance comparable to SA in both\ncausal and non-causal forms.",
      "tldr_zh": "这篇论文针对自注意力（self-attention, SA）机制在训练和推理中存在的较高复杂度问题，提出了一种新型的 element-wise attention 机制，以实现高效处理。新的机制使用元素-wise squared Euclidean distance 计算相似性，并通过 Taylor polynomial 近似 exp(q_ic k_jc) 项，从而将训练复杂度降至 O(tLD)，推理复杂度降至 O(tD)，并可重构为 recurrent neural networks (RNN)。与线性注意力、线性 RNN 和状态空间模型等现有方法相比，element-wise attention 避免了性能退化因素，如“spikiness”减弱和历史信息压缩，并在因果和非因果形式上实现了与 SA 相当的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05730v1",
      "published_date": "2025-01-10 05:54:04 UTC",
      "updated_date": "2025-01-10 05:54:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:21:04.734558"
    },
    {
      "arxiv_id": "2501.05729v2",
      "title": "ExPO: Explainable Phonetic Trait-Oriented Network for Speaker Verification",
      "title_zh": "ExPO：用于说话人验证的可解释语音特性导向网络",
      "authors": [
        "Yi Ma",
        "Shuai Wang",
        "Tianchi Liu",
        "Haizhou Li"
      ],
      "abstract": "In speaker verification, we use computational method to verify if an\nutterance matches the identity of an enrolled speaker. This task is similar to\nthe manual task of forensic voice comparison, where linguistic analysis is\ncombined with auditory measurements to compare and evaluate voice samples.\nDespite much success, we have yet to develop a speaker verification system that\noffers explainable results comparable to those from manual forensic voice\ncomparison. A novel approach, Explainable Phonetic Trait-Oriented (ExPO)\nnetwork, is proposed in this paper to introduce the speaker's phonetic trait\nwhich describes the speaker's characteristics at the phonetic level, resembling\nwhat forensic comparison does. ExPO not only generates utterance-level speaker\nembeddings but also allows for fine-grained analysis and visualization of\nphonetic traits, offering an explainable speaker verification process.\nFurthermore, we investigate phonetic traits from within-speaker and\nbetween-speaker variation perspectives to determine which trait is most\neffective for speaker verification, marking an important step towards\nexplainable speaker verification. Our code is available at\nhttps://github.com/mmmmayi/ExPO.",
      "tldr_zh": "本论文提出ExPO（Explainable Phonetic Trait-Oriented）网络，用于说话人验证（speaker verification），旨在提供类似于法医语音比较的可解释结果。ExPO通过引入说话人的语音特征（phonetic traits）来生成utterance-level speaker embeddings，并支持细粒度分析和可视化，从而实现对语音特性的透明解读。该方法从说话人内部和之间变异角度调查语音特征的有效性，展示了其在提升说话人验证准确性和可解释性方面的潜力。开源代码可从指定仓库获取。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by IEEE Signal Processing Letters",
      "pdf_url": "http://arxiv.org/pdf/2501.05729v2",
      "published_date": "2025-01-10 05:53:37 UTC",
      "updated_date": "2025-01-14 07:28:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:21:15.868631"
    },
    {
      "arxiv_id": "2501.05727v1",
      "title": "Enabling Scalable Oversight via Self-Evolving Critic",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyang Tang",
        "Ziniu Li",
        "Zhenyang Xiao",
        "Tian Ding",
        "Ruoyu Sun",
        "Benyou Wang",
        "Dayiheng Liu",
        "Fei Huang",
        "Tianyu Liu",
        "Bowen Yu",
        "Junyang Lin"
      ],
      "abstract": "Despite their remarkable performance, the development of Large Language\nModels (LLMs) faces a critical challenge in scalable oversight: providing\neffective feedback for tasks where human evaluation is difficult or where LLMs\noutperform humans. While there is growing interest in using LLMs for critique,\ncurrent approaches still rely on human annotations or more powerful models,\nleaving the issue of enhancing critique capabilities without external\nsupervision unresolved. We introduce SCRIT (Self-evolving CRITic), a framework\nthat enables genuine self-evolution of critique abilities. Technically, SCRIT\nself-improves by training on synthetic data, generated by a contrastive-based\nself-critic that uses reference solutions for step-by-step critique, and a\nself-validation mechanism that ensures critique quality through correction\noutcomes. Implemented with Qwen2.5-72B-Instruct, one of the most powerful LLMs,\nSCRIT achieves up to a 10.3\\% improvement on critique-correction and error\nidentification benchmarks. Our analysis reveals that SCRIT's performance scales\npositively with data and model size, outperforms alternative approaches, and\nbenefits critically from its self-validation component.",
      "tldr_zh": "这篇论文提出 SCRIT（Self-evolving CRITic）框架，以解决 Large Language Models (LLMs) 在可扩展监督方面的挑战，即在人类评估困难或 LLMs 超过人类能力的任务中提供有效反馈。SCRIT 通过在合成数据上训练、利用基于对比的自我批评器（生成步步批评参考解决方案）和自我验证机制（通过修正结果确保质量）来实现批评能力的真正自我进化。实验结果显示，使用 Qwen2.5-72B-Instruct 模型的 SCRIT 在批评-修正和错误识别基准上改善高达 10.3%，并证明其性能随数据和模型大小正向扩展，同时依赖自我验证组件的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05727v1",
      "published_date": "2025-01-10 05:51:52 UTC",
      "updated_date": "2025-01-10 05:51:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:22:45.167829"
    },
    {
      "arxiv_id": "2501.05717v1",
      "title": "Zero-shot Shark Tracking and Biometrics from Aerial Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Chinmay K Lalgudi",
        "Mark E Leone",
        "Jaden V Clark",
        "Sergio Madrigal-Mora",
        "Mario Espinoza"
      ],
      "abstract": "The recent widespread adoption of drones for studying marine animals provides\nopportunities for deriving biological information from aerial imagery. The\nlarge scale of imagery data acquired from drones is well suited for machine\nlearning (ML) analysis. Development of ML models for analyzing marine animal\naerial imagery has followed the classical paradigm of training, testing, and\ndeploying a new model for each dataset, requiring significant time, human\neffort, and ML expertise. We introduce Frame Level ALIgment and tRacking\n(FLAIR), which leverages the video understanding of Segment Anything Model 2\n(SAM2) and the vision-language capabilities of Contrastive Language-Image\nPre-training (CLIP). FLAIR takes a drone video as input and outputs\nsegmentation masks of the species of interest across the video. Notably, FLAIR\nleverages a zero-shot approach, eliminating the need for labeled data, training\na new model, or fine-tuning an existing model to generalize to other species.\nWith a dataset of 18,000 drone images of Pacific nurse sharks, we trained\nstate-of-the-art object detection models to compare against FLAIR. We show that\nFLAIR massively outperforms these object detectors and performs competitively\nagainst two human-in-the-loop methods for prompting SAM2, achieving a Dice\nscore of 0.81. FLAIR readily generalizes to other shark species without\nadditional human effort and can be combined with novel heuristics to\nautomatically extract relevant information including length and tailbeat\nfrequency. FLAIR has significant potential to accelerate aerial imagery\nanalysis workflows, requiring markedly less human effort and expertise than\ntraditional machine learning workflows, while achieving superior accuracy. By\nreducing the effort required for aerial imagery analysis, FLAIR allows\nscientists to spend more time interpreting results and deriving insights about\nmarine ecosystems.",
      "tldr_zh": "本研究提出FLAIR框架，利用Segment Anything Model 2 (SAM2)的视频理解能力和Contrastive Language-Image Pre-training (CLIP)的视觉语言能力，实现无人机空中图像中鲨鱼的零样本跟踪和生物测量。FLAIR无需标注数据或模型训练，即可泛化到不同鲨鱼物种，并自动提取信息如长度和尾beat频率。实验结果显示，FLAIR在18,000张Pacific nurse sharks图像数据集上远超传统物体检测模型，Dice score达0.81，并显著减少人力努力，从而加速海洋生态研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05717v1",
      "published_date": "2025-01-10 05:29:09 UTC",
      "updated_date": "2025-01-10 05:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:22:56.526312"
    },
    {
      "arxiv_id": "2501.05714v2",
      "title": "How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Huang",
        "Yang Deng",
        "Wenqiang Lei",
        "Jiancheng Lv",
        "Tat-Seng Chua",
        "Jimmy Xiangji Huang"
      ],
      "abstract": "With the advancement of large language models (LLMs), intelligent models have\nevolved from mere tools to autonomous agents with their own goals and\nstrategies for cooperating with humans. This evolution has birthed a novel\nparadigm in NLP, i.e., human-model cooperation, that has yielded remarkable\nprogress in numerous NLP tasks in recent years. In this paper, we take the\nfirst step to present a thorough review of human-model cooperation, exploring\nits principles, formalizations, and open challenges. In particular, we\nintroduce a new taxonomy that provides a unified perspective to summarize\nexisting approaches. Also, we discuss potential frontier areas and their\ncorresponding challenges. We regard our work as an entry point, paving the way\nfor more breakthrough research in this regard.",
      "tldr_zh": "这篇论文对人类与 NLP 模型的有效合作进行首次全面综述，随着 LLMs 的发展，模型从简单工具演变为具有自身目标和策略的自治代理。作者引入了一个新的 taxonomy，提供统一视角来总结现有方法，并探讨了合作的原则、形式化和开放挑战。研究强调，这种合作范式已在众多 NLP 任务中取得显著进展，并指出了潜在的前沿领域及其挑战，为未来突破性研究铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "V2: Only minor edits were made to the main text, and we've added more\n  supplementary materials",
      "pdf_url": "http://arxiv.org/pdf/2501.05714v2",
      "published_date": "2025-01-10 05:15:14 UTC",
      "updated_date": "2025-04-20 02:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:23:09.266185"
    },
    {
      "arxiv_id": "2501.05707v2",
      "title": "Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains",
      "title_zh": "多智能体微调：使用多样化推理链的自提升",
      "authors": [
        "Vighnesh Subramaniam",
        "Yilun Du",
        "Joshua B. Tenenbaum",
        "Antonio Torralba",
        "Shuang Li",
        "Igor Mordatch"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable performance in recent\nyears but are fundamentally limited by the underlying training data. To improve\nmodels beyond the training data, recent works have explored how LLMs can be\nused to generate synthetic data for autonomous self-improvement. However,\nsuccessive steps of self-improvement can reach a point of diminishing returns.\nIn this work, we propose a complementary approach towards self-improvement\nwhere finetuning is applied to a multiagent society of language models. A group\nof language models, all starting from the same base model, are independently\nspecialized by updating each one using data generated through multiagent\ninteractions among the models. By training each model on independent sets of\ndata, we illustrate how this approach enables specialization across models and\ndiversification over the set of models. As a result, our overall system is able\nto preserve diverse reasoning chains and autonomously improve over many more\nrounds of fine-tuning than single-agent self-improvement methods. We\nquantitatively illustrate the efficacy of the approach across a wide suite of\nreasoning tasks.",
      "tldr_zh": "本文提出一种多智能体 finetuning 方法，用于提升大语言模型 (LLMs) 的自主自我改进，通过模型间的交互生成数据，避免传统方法中的 diminishing returns。多个从相同基模型开始的语言模型独立更新，每个模型使用独立数据集训练，从而实现模型间的专业化和 diverse reasoning chains 的保留。与单智能体方法相比，该方法支持更多轮 finetuning，并在广泛的推理任务上展示了显著的效能提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025; 22 pages, 13 figures, 7 tables; Project page at\n  https://llm-multiagent-ft.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2501.05707v2",
      "published_date": "2025-01-10 04:35:46 UTC",
      "updated_date": "2025-03-03 18:58:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:23:21.356634"
    },
    {
      "arxiv_id": "2501.10421v1",
      "title": "CodEv: An Automated Grading Framework Leveraging Large Language Models for Consistent and Constructive Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "En-Qi Tseng",
        "Pei-Cing Huang",
        "Chan Hsu",
        "Peng-Yi Wu",
        "Chan-Tung Ku",
        "Yihuang Kang"
      ],
      "abstract": "Grading programming assignments is crucial for guiding students to improve\ntheir programming skills and coding styles. This study presents an automated\ngrading framework, CodEv, which leverages Large Language Models (LLMs) to\nprovide consistent and constructive feedback. We incorporate Chain of Thought\n(CoT) prompting techniques to enhance the reasoning capabilities of LLMs and\nensure that the grading is aligned with human evaluation. Our framework also\nintegrates LLM ensembles to improve the accuracy and consistency of scores,\nalong with agreement tests to deliver reliable feedback and code review\ncomments. The results demonstrate that the framework can yield grading results\ncomparable to human evaluators, by using smaller LLMs. Evaluation and\nconsistency tests of the LLMs further validate our approach, confirming the\nreliability of the generated scores and feedback.",
      "tldr_zh": "这篇论文介绍了CodEv框架，一种利用Large Language Models (LLMs)实现编程作业自动评分的方法，旨在提供一致且建设性的反馈。框架采用Chain of Thought (CoT)提示技术提升LLMs的推理能力，并整合LLM ensembles和agreement tests，以确保评分准确性和可靠性。实验结果表明，CodEv使用较小的LLMs即可产生与人类评估相媲美的结果，并通过一致性测试验证了其可靠性和有效性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10421v1",
      "published_date": "2025-01-10 03:09:46 UTC",
      "updated_date": "2025-01-10 03:09:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:23:33.193762"
    },
    {
      "arxiv_id": "2501.05680v1",
      "title": "EXION: Exploiting Inter- and Intra-Iteration Output Sparsity for Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehoon Heo",
        "Adiwena Putra",
        "Jieon Yoon",
        "Sungwoong Yune",
        "Hangyeol Lee",
        "Ji-Hoon Kim",
        "Joo-Young Kim"
      ],
      "abstract": "Over the past few years, diffusion models have emerged as novel AI solutions,\ngenerating diverse multi-modal outputs from text prompts. Despite their\ncapabilities, they face challenges in computing, such as excessive latency and\nenergy consumption due to their iterative architecture. Although prior works\nspecialized in transformer acceleration can be applied, the iterative nature of\ndiffusion models remains unresolved. In this paper, we present EXION, the first\nSW-HW co-designed diffusion accelerator that solves the computation challenges\nby exploiting the unique inter- and intra-iteration output sparsity in\ndiffusion models. To this end, we propose two SW-level optimizations. First, we\nintroduce the FFN-Reuse algorithm that identifies and skips redundant\ncomputations in FFN layers across different iterations (inter-iteration\nsparsity). Second, we use a modified eager prediction method that employs\ntwo-step leading-one detection to accurately predict the attention score,\nskipping unnecessary computations within an iteration (intra-iteration\nsparsity). We also introduce a novel data compaction mechanism named ConMerge,\nwhich can enhance HW utilization by condensing and merging sparse matrices into\ncompact forms. Finally, it has a dedicated HW architecture that supports the\nabove sparsity-inducing algorithms, translating high output sparsity into\nimproved energy efficiency and performance. To verify the feasibility of the\nEXION, we first demonstrate that it has no impact on accuracy in various types\nof multi-modal diffusion models. We then instantiate EXION in both server- and\nedge-level settings and compare its performance against GPUs with similar\nspecifications. Our evaluation shows that EXION achieves dramatic improvements\nin performance and energy efficiency by 3.2-379.3x and 45.1-3067.6x compared to\na server GPU and by 42.6-1090.9x and 196.9-4668.2x compared to an edge GPU.",
      "tldr_zh": "该论文提出 EXION，一种软件-硬件（SW-HW）协同设计的加速器，针对扩散模型（diffusion models）的迭代架构问题，利用 inter-iteration 和 intra-iteration 输出稀疏性来减少计算延迟和能耗。具体方法包括 FFN-Reuse 算法跳过不同迭代中的冗余计算，以及修改的 eager prediction 方法通过两步 leading-one detection 预测注意力分数以避免内部不必要运算，同时引入 ConMerge 数据压缩机制优化硬件利用率。实验结果显示，EXION 在多模态扩散模型中不影响准确性，并在服务器和边缘设置下，相比类似规格的 GPU，实现性能提升 3.2-379.3x 和 42.6-1090.9x，以及能量效率提升 45.1-3067.6x 和 196.9-4668.2x。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "To appear in 2025 IEEE International Symposium on High-Performance\n  Computer Architecture (HPCA 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.05680v1",
      "published_date": "2025-01-10 03:07:28 UTC",
      "updated_date": "2025-01-10 03:07:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:23:46.347479"
    },
    {
      "arxiv_id": "2501.05675v4",
      "title": "Synergizing Large Language Models and Task-specific Models for Time Series Anomaly Detection",
      "title_zh": "大语言模型与任务特定模型的协同用于时间序列异常检测",
      "authors": [
        "Feiyi Chen",
        "Leilei Zhang",
        "Guansong Pang",
        "Roger Zimmermann",
        "Shuiguang Deng"
      ],
      "abstract": "In anomaly detection, methods based on large language models (LLMs) can\nincorporate expert knowledge by reading professional document, while\ntask-specific small models excel at extracting normal data patterns and\ndetecting value fluctuations from training data of target applications.\nInspired by the human nervous system, where the brain stores expert knowledge\nand the peripheral nervous system and spinal cord handle specific tasks like\nwithdrawal and knee-jerk reflexes, we propose CoLLaTe, a framework designed to\nfacilitate collaboration between LLMs and task-specific models, leveraging the\nstrengths of both models for anomaly detection.\n  In particular, we first formulate the collaboration process and identify two\nkey challenges in the collaboration:\n  (1) the misalignment between the expression domains of the LLMs and\ntask-specific small models, and (2) error accumulation arising from the\npredictions of both models.\n  To address these challenges, we then introduce two key components in CoLLaTe:\na model alignment module and a collaborative loss function. Through theoretical\nanalysis and experimental validation, we demonstrate that these components\neffectively mitigate the identified challenges and achieve better performance\nthan both LLM-based and task-specific models.",
      "tldr_zh": "本论文提出 CoLLaTe 框架，旨在将 Large Language Models (LLMs) 与任务特定小模型相结合，用于时间序列异常检测，借鉴人类神经系统的灵感来发挥二者优势：LLMs 提供专家知识，而小模型擅长提取数据模式。框架重点解决两个挑战，包括模型表达域不对齐和预测错误积累，通过引入模型对齐模块和协作损失函数来优化协作过程。实验结果显示，CoLLaTe 在性能上优于纯 LLM 或任务特定模型的独立方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05675v4",
      "published_date": "2025-01-10 02:57:08 UTC",
      "updated_date": "2025-05-06 07:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:23:56.791871"
    },
    {
      "arxiv_id": "2501.05673v1",
      "title": "Network Diffuser for Placing-Scheduling Service Function Chains with Inverse Demonstration",
      "title_zh": "翻译失败",
      "authors": [
        "Zuyuan Zhang",
        "Vaneet Aggarwal",
        "Tian Lan"
      ],
      "abstract": "Network services are increasingly managed by considering chained-up virtual\nnetwork functions and relevant traffic flows, known as the Service Function\nChains (SFCs). To deal with sequential arrivals of SFCs in an online fashion,\nwe must consider two closely-coupled problems - an SFC placement problem that\nmaps SFCs to servers/links in the network and an SFC scheduling problem that\ndetermines when each SFC is executed. Solving the whole SFC problem targeting\nthese two optimizations jointly is extremely challenging. In this paper, we\npropose a novel network diffuser using conditional generative modeling for this\nSFC placing-scheduling optimization. Recent advances in generative AI and\ndiffusion models have made it possible to generate high-quality images/videos\nand decision trajectories from language description. We formulate the SFC\noptimization as a problem of generating a state sequence for planning and\nperform graph diffusion on the state trajectories to enable extraction of SFC\ndecisions, with SFC optimization constraints and objectives as conditions. To\naddress the lack of demonstration data due to NP-hardness and exponential\nproblem space of the SFC optimization, we also propose a novel and somewhat\nmaverick approach -- Rather than solving instances of this difficult\noptimization, we start with randomly-generated solutions as input, and then\ndetermine appropriate SFC optimization problems that render these solutions\nfeasible. This inverse demonstration enables us to obtain sufficient expert\ndemonstrations, i.e., problem-solution pairs, through further optimization. In\nour numerical evaluations, the proposed network diffuser outperforms learning\nand heuristic baselines, by $\\sim$20\\% improvement in SFC reward and $\\sim$50\\%\nreduction in SFC waiting time and blocking rate.",
      "tldr_zh": "这篇论文提出了一种名为 Network Diffuser 的框架，利用条件生成模型和扩散模型来联合优化 Service Function Chains (SFCs) 的放置（映射到网络服务器/链接）和调度（执行时机）问题，以处理在线 SFCs 到达场景。创新点包括将 SFC 优化问题转化为状态序列生成任务，并采用 Inverse Demonstration 方法，从随机解决方案反向生成合适的优化问题，从而获得足够的专家演示数据。实验结果显示，该框架相较于学习和启发式基线，实现了约20%的 SFC 奖励提升，以及约50%的等待时间和阻塞率降低。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted to IEEE INFOCOM 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05673v1",
      "published_date": "2025-01-10 02:51:58 UTC",
      "updated_date": "2025-01-10 02:51:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:24:09.119275"
    },
    {
      "arxiv_id": "2501.05667v2",
      "title": "TransPlace: Transferable Circuit Global Placement via Graph Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yunbo Hou",
        "Haoran Ye",
        "Shuwen Yang",
        "Yingxue Zhang",
        "Siyuan Xu",
        "Guojie Song"
      ],
      "abstract": "Global placement, a critical step in designing the physical layout of\ncomputer chips, is essential to optimize chip performance. Prior global\nplacement methods optimize each circuit design individually from scratch. Their\nneglect of transferable knowledge limits solution efficiency and chip\nperformance as circuit complexity drastically increases. This study presents\nTransPlace, a global placement framework that learns to place millions of\nmixed-size cells in continuous space. TransPlace introduces i) Netlist Graph to\nefficiently model netlist topology, ii) Cell-flow and relative position\nencoding to learn SE(2)-invariant representation, iii) a tailored graph neural\nnetwork architecture for informed parameterization of placement knowledge, and\niv) a two-stage strategy for coarse-to-fine placement. Compared to\nstate-of-the-art placement methods, TransPlace-trained on a few high-quality\nplacements-can place unseen circuits with 1.2x speedup while reducing\ncongestion by 30%, timing by 9%, and wirelength by 5%.",
      "tldr_zh": "本文提出 TransPlace 框架，利用 Graph Neural Network 实现电路全局放置的知识转移，旨在解决现有方法忽略可转移知识导致效率低下的问题。该框架引入 Netlist Graph 建模网表拓扑、Cell-flow 和相对位置编码学习 SE(2)-invariant 表示，以及两阶段粗到细的放置策略，以高效处理数百万混合大小单元的连续空间放置。与现有方法相比，TransPlace 在少量高质量放置上训练后，能以1.2倍速度放置未见电路，同时减少拥塞30%、时序9%和线长5%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05667v2",
      "published_date": "2025-01-10 02:33:15 UTC",
      "updated_date": "2025-03-26 03:19:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:24:21.859911"
    },
    {
      "arxiv_id": "2501.05663v1",
      "title": "Learning to Measure Quantum Neural Networks",
      "title_zh": "学习测量量子神经网络",
      "authors": [
        "Samuel Yen-Chi Chen",
        "Huan-Hsin Tseng",
        "Hsin-Yi Lin",
        "Shinjae Yoo"
      ],
      "abstract": "The rapid progress in quantum computing (QC) and machine learning (ML) has\nattracted growing attention, prompting extensive research into quantum machine\nlearning (QML) algorithms to solve diverse and complex problems. Designing\nhigh-performance QML models demands expert-level proficiency, which remains a\nsignificant obstacle to the broader adoption of QML. A few major hurdles\ninclude crafting effective data encoding techniques and parameterized quantum\ncircuits, both of which are crucial to the performance of QML models.\nAdditionally, the measurement phase is frequently overlooked-most current QML\nmodels rely on pre-defined measurement protocols that often fail to account for\nthe specific problem being addressed. We introduce a novel approach that makes\nthe observable of the quantum system-specifically, the Hermitian\nmatrix-learnable. Our method features an end-to-end differentiable learning\nframework, where the parameterized observable is trained alongside the ordinary\nquantum circuit parameters simultaneously. Using numerical simulations, we show\nthat the proposed method can identify observables for variational quantum\ncircuits that lead to improved outcomes, such as higher classification\naccuracy, thereby boosting the overall performance of QML models.",
      "tldr_zh": "该论文探讨了量子机器学习（QML）模型的设计挑战，特别是数据编码、参数化量子电路和测量阶段的难题。作者提出了一种新颖方法，使量子系统的可观测量（Hermitian matrix）可学习，通过端到端的可微学习框架，同时训练参数化可观测量和量子电路参数。实验结果显示，该方法在变分量子电路（variational quantum circuits）上识别出更有效的可观测量，提升了分类准确率，从而显著提高了QML模型的整体性能。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "quant-ph",
      "comment": "Accepted by ICASSP 2025 Workshop: Quantum Machine Learning in Signal\n  Processing and Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2501.05663v1",
      "published_date": "2025-01-10 02:28:19 UTC",
      "updated_date": "2025-01-10 02:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:24:32.512099"
    },
    {
      "arxiv_id": "2501.05662v2",
      "title": "Cascaded Self-Evaluation Augmented Training for Lightweight Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Zheqi Lv",
        "Wenkai Wang",
        "Jiawei Wang",
        "Shengyu Zhang",
        "Fei Wu"
      ],
      "abstract": "Efficient Multimodal Large Language Models (EMLLMs) can improve performance\nthrough Chain-of-Thought (CoT) reasoning, but they have poor self-evaluation\ncapabilities during the CoT reasoning process. This is due to their tendency to\nsimplify the reasoning process and the degradation of self-evaluation ability\nduring downstream task fine-tuning. To address this, we intuitively propose\n\\textit{Self-Evaluation Augmented Training (SEAT)}, which uses more powerful\nEMLLMs to evaluate CoT reasoning data. The evaluation data is then used to\ntrain EMLLMs. However, due to the difficulties EMLLMs face with processing long\ntoken input-output sequences, and the degradation of self-evaluation ability as\na basis for CoT reasoning, the SEAT method is not fully adapted. Therefore, we\nfurther propose \\textit{Cascaded Self-Evaluation Augmented Training\n(Cas-SEAT)}, which converts long prompts into cascaded short prompts, each\nfocusing on a specific task. Additionally, we mix CoT reasoning and\nself-evaluation data to preserve its CoT reasoning ability while enhancing the\nself-evaluation capability of EMLLMs. We also conduct \\textit{Double-level Data\nFiltering (DDF)}, which includes source data filtering and labeled data\nfiltering, using both manual selection and MLLMs for filtering. Cas-SEAT and\nDDF work together to improve the performance of EMLLMs. Experiments show that\nCas-SEAT achieves an average improvement of 22.16% across multiple datasets,\nand DDF significantly reduces the resource consumption of training",
      "tldr_zh": "本研究针对 Efficient Multimodal Large Language Models (EMLLMs) 在 Chain-of-Thought (CoT) 推理过程中自评估能力不足的问题，提出了 Self-Evaluation Augmented Training (SEAT) 方法，使用更强大的模型来评估和训练推理数据。进一步优化为 Cascaded Self-Evaluation Augmented Training (Cas-SEAT)，该方法将长提示分解为级联短提示，并混合 CoT 推理和自评估数据，以提升自评估能力同时保持推理性能；同时，引入 Double-level Data Filtering (DDF) 通过手动和 MLLMs 过滤源数据和标记数据，提高数据质量。实验结果显示，Cas-SEAT 在多个数据集上平均提升了 22.16% 的性能，并显著减少了训练资源消耗。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05662v2",
      "published_date": "2025-01-10 02:28:04 UTC",
      "updated_date": "2025-03-16 02:28:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:24:46.654828"
    },
    {
      "arxiv_id": "2501.06271v1",
      "title": "Large Language Models for Bioinformatics",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Ruan",
        "Yanjun Lyu",
        "Jing Zhang",
        "Jiazhang Cai",
        "Peng Shu",
        "Yang Ge",
        "Yao Lu",
        "Shang Gao",
        "Yue Wang",
        "Peilong Wang",
        "Lin Zhao",
        "Tao Wang",
        "Yufang Liu",
        "Luyang Fang",
        "Ziyu Liu",
        "Zhengliang Liu",
        "Yiwei Li",
        "Zihao Wu",
        "Junhao Chen",
        "Hanqi Jiang",
        "Yi Pan",
        "Zhenyuan Yang",
        "Jingyuan Chen",
        "Shizhe Liang",
        "Wei Zhang",
        "Terry Ma",
        "Yuan Dou",
        "Jianli Zhang",
        "Xinyu Gong",
        "Qi Gan",
        "Yusong Zou",
        "Zebang Chen",
        "Yuanxin Qian",
        "Shuo Yu",
        "Jin Lu",
        "Kenan Song",
        "Xianqiao Wang",
        "Andrea Sikora",
        "Gang Li",
        "Xiang Li",
        "Quanzheng Li",
        "Yingfeng Wang",
        "Lu Zhang",
        "Yohannes Abate",
        "Lifang He",
        "Wenxuan Zhong",
        "Rongjie Liu",
        "Chao Huang",
        "Wei Liu",
        "Ye Shen",
        "Ping Ma",
        "Hongtu Zhu",
        "Yajun Yan",
        "Dajiang Zhu",
        "Tianming Liu"
      ],
      "abstract": "With the rapid advancements in large language model (LLM) technology and the\nemergence of bioinformatics-specific language models (BioLMs), there is a\ngrowing need for a comprehensive analysis of the current landscape,\ncomputational characteristics, and diverse applications. This survey aims to\naddress this need by providing a thorough review of BioLMs, focusing on their\nevolution, classification, and distinguishing features, alongside a detailed\nexamination of training methodologies, datasets, and evaluation frameworks. We\nexplore the wide-ranging applications of BioLMs in critical areas such as\ndisease diagnosis, drug discovery, and vaccine development, highlighting their\nimpact and transformative potential in bioinformatics. We identify key\nchallenges and limitations inherent in BioLMs, including data privacy and\nsecurity concerns, interpretability issues, biases in training data and model\noutputs, and domain adaptation complexities. Finally, we highlight emerging\ntrends and future directions, offering valuable insights to guide researchers\nand clinicians toward advancing BioLMs for increasingly sophisticated\nbiological and clinical applications.",
      "tldr_zh": "这篇综述论文探讨了大型语言模型(LLM)和生物信息学特定语言模型(BioLMs)在生物信息学领域的应用现状，包括模型的演变、分类、特点、训练方法、数据集以及评估框架。论文详细分析了BioLMs在疾病诊断、药物发现和疫苗开发等关键领域的广泛应用及其潜在变革性影响，同时指出了数据隐私、安全、解释性、偏见和领域适应等方面的挑战和限制。最终，论文强调了BioLMs的未来趋势，如持续优化和更复杂的生物临床应用，以指导研究者和临床人员进一步发展。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "q-bio.QM",
      "comment": "64 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2501.06271v1",
      "published_date": "2025-01-10 01:43:05 UTC",
      "updated_date": "2025-01-10 01:43:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:26:56.096528"
    },
    {
      "arxiv_id": "2501.05647v2",
      "title": "Collaboration of Large Language Models and Small Recommendation Models for Device-Cloud Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Zheqi Lv",
        "Tianyu Zhan",
        "Wenjie Wang",
        "Xinyu Lin",
        "Shengyu Zhang",
        "Wenqiao Zhang",
        "Jiwei Li",
        "Kun Kuang",
        "Fei Wu"
      ],
      "abstract": "Large Language Models (LLMs) for Recommendation (LLM4Rec) is a promising\nresearch direction that has demonstrated exceptional performance in this field.\nHowever, its inability to capture real-time user preferences greatly limits the\npractical application of LLM4Rec because (i) LLMs are costly to train and infer\nfrequently, and (ii) LLMs struggle to access real-time data (its large number\nof parameters poses an obstacle to deployment on devices). Fortunately, small\nrecommendation models (SRMs) can effectively supplement these shortcomings of\nLLM4Rec diagrams by consuming minimal resources for frequent training and\ninference, and by conveniently accessing real-time data on devices.\n  In light of this, we designed the Device-Cloud LLM-SRM Collaborative\nRecommendation Framework (LSC4Rec) under a device-cloud collaboration setting.\nLSC4Rec aims to integrate the advantages of both LLMs and SRMs, as well as the\nbenefits of cloud and edge computing, achieving a complementary synergy. We\nenhance the practicability of LSC4Rec by designing three strategies:\ncollaborative training, collaborative inference, and intelligent request.\nDuring training, LLM generates candidate lists to enhance the ranking ability\nof SRM in collaborative scenarios and enables SRM to update adaptively to\ncapture real-time user interests. During inference, LLM and SRM are deployed on\nthe cloud and on the device, respectively. LLM generates candidate lists and\ninitial ranking results based on user behavior, and SRM get reranking results\nbased on the candidate list, with final results integrating both LLM's and\nSRM's scores. The device determines whether a new candidate list is needed by\ncomparing the consistency of the LLM's and SRM's sorted lists. Our\ncomprehensive and extensive experimental analysis validates the effectiveness\nof each strategy in LSC4Rec.",
      "tldr_zh": "该论文提出 Device-Cloud LLM-SRM Collaborative Recommendation Framework (LSC4Rec)，旨在整合 Large Language Models (LLMs) 和 Small Recommendation Models (SRMs) 的优势，解决 LLM4Rec 在捕获实时用户偏好方面的局限性，通过设备-云协作实现高效推荐。框架包括三个关键策略：协作训练（LLM 生成候选列表提升 SRM 的排名能力，并适应实时用户兴趣）、协作推理（LLM 在云端生成初始结果，SRM 在设备端重新排名，并整合最终输出）、以及智能请求（设备通过比较排序一致性决定是否请求新列表）。实验结果证明了这些策略的有效性，提升了推荐系统的实用性和性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.IR",
      "comment": "Published on KDD'25: Proceedings of the ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05647v2",
      "published_date": "2025-01-10 01:27:12 UTC",
      "updated_date": "2025-02-25 13:10:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:25:09.477191"
    },
    {
      "arxiv_id": "2501.05646v1",
      "title": "Efficient Representations for High-Cardinality Categorical Variables in Machine Learning",
      "title_zh": "机器学习中高基数分类变量的高效表示",
      "authors": [
        "Zixuan Liang"
      ],
      "abstract": "High\\-cardinality categorical variables pose significant challenges in\nmachine learning, particularly in terms of computational efficiency and model\ninterpretability. Traditional one\\-hot encoding often results in\nhigh\\-dimensional sparse feature spaces, increasing the risk of overfitting and\nreducing scalability. This paper introduces novel encoding techniques,\nincluding means encoding, low\\-rank encoding, and multinomial logistic\nregression encoding, to address these challenges. These methods leverage\nsufficient representations to generate compact and informative embeddings of\ncategorical data. We conduct rigorous theoretical analyses and empirical\nvalidations on diverse datasets, demonstrating significant improvements in\nmodel performance and computational efficiency compared to baseline methods.\nThe proposed techniques are particularly effective in domains requiring\nscalable solutions for large datasets, paving the way for more robust and\nefficient applications in machine learning.",
      "tldr_zh": "本论文针对高基数分类变量在机器学习中的挑战，包括计算效率和模型可解释性问题，提出了新型编码技术：means encoding、low-rank encoding 和 multinomial logistic regression encoding。这些方法利用充分表示生成紧凑且信息丰富的嵌入，以避免传统 one-hot encoding 导致的高维稀疏特征空间和过拟合风险。通过理论分析和实证验证，实验结果显示这些技术在多样数据集上显著提高了模型性能和计算效率，尤其适用于处理大规模数据的场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "2025 International Conference on Advanced Machine Learning and Data\n  Science (AMLDS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.05646v1",
      "published_date": "2025-01-10 01:25:01 UTC",
      "updated_date": "2025-01-10 01:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:25:21.059704"
    },
    {
      "arxiv_id": "2501.05643v1",
      "title": "Iconicity in Large Language Models",
      "title_zh": "大型语言模型中的象似性",
      "authors": [
        "Anna Marklová",
        "Jiří Milička",
        "Leonid Ryvkin",
        "Ľudmila Lacková Bennet",
        "Libuše Kormaníková"
      ],
      "abstract": "Lexical iconicity, a direct relation between a word's meaning and its form,\nis an important aspect of every natural language, most commonly manifesting\nthrough sound-meaning associations. Since Large language models' (LLMs') access\nto both meaning and sound of text is only mediated (meaning through textual\ncontext, sound through written representation, further complicated by\ntokenization), we might expect that the encoding of iconicity in LLMs would be\neither insufficient or significantly different from human processing. This\nstudy addresses this hypothesis by having GPT-4 generate highly iconic\npseudowords in artificial languages. To verify that these words actually carry\niconicity, we had their meanings guessed by Czech and German participants\n(n=672) and subsequently by LLM-based participants (generated by GPT-4 and\nClaude 3.5 Sonnet). The results revealed that humans can guess the meanings of\npseudowords in the generated iconic language more accurately than words in\ndistant natural languages and that LLM-based participants are even more\nsuccessful than humans in this task. This core finding is accompanied by\nseveral additional analyses concerning the universality of the generated\nlanguage and the cues that both human and LLM-based participants utilize.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 中词汇象征性 (lexical iconicity) 的编码方式，即词语形式与意义直接关联的问题，并假设 LLMs 可能无法像人类一样有效处理此特性。研究方法包括使用 GPT-4 生成高度象征性的伪词 (pseudowords) 在人工语言中，然后让捷克和德国人类参与者 (n=672) 以及 LLM-based 参与者 (由 GPT-4 和 Claude 3.5 Sonnet 生成) 猜测这些词的意义。结果显示，人类在猜测生成语言的伪词时比自然语言更准确，而 LLM-based 参与者甚至比人类更成功。该研究还分析了生成语言的普遍性和人类与 LLM 参与者使用的线索，为理解 LLMs 在处理象征性方面的能力提供了新洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Supplementary information: https://osf.io/ywjrk/",
      "pdf_url": "http://arxiv.org/pdf/2501.05643v1",
      "published_date": "2025-01-10 01:00:05 UTC",
      "updated_date": "2025-01-10 01:00:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:27:26.395962"
    },
    {
      "arxiv_id": "2501.05629v1",
      "title": "The Impact of Model Scaling on Seen and Unseen Language Performance",
      "title_zh": "模型缩放对已见和未见语言性能的影响",
      "authors": [
        "Rhitabrat Pokharel",
        "Sina Bagheri Nezhad",
        "Ameeta Agrawal",
        "Suresh Singh"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs), particularly those\ntrained on multilingual corpora, has intensified the need for a deeper\nunderstanding of their performance across a diverse range of languages and\nmodel sizes. Our research addresses this critical need by studying the\nperformance and scaling behavior of multilingual LLMs in text classification\nand machine translation tasks across 204 languages. We systematically examine\nboth seen and unseen languages across three model families of varying sizes in\nzero-shot and few-shot settings. Our findings show significant differences in\nscaling behavior between zero-shot and two-shot scenarios, with striking\ndisparities in performance between seen and unseen languages. Model scale has\nlittle effect on zero-shot performance, which remains mostly flat. However, in\ntwo-shot settings, larger models show clear linear improvements in multilingual\ntext classification. For translation tasks, however, only the instruction-tuned\nmodel showed clear benefits from scaling. Our analysis also suggests that\noverall resource levels, not just the proportions of pretraining languages, are\nbetter predictors of model performance, shedding light on what drives\nmultilingual LLM effectiveness.",
      "tldr_zh": "本文研究了大型语言模型（LLMs）在不同规模下的性能表现，针对204种已见和未见语言，在zero-shot和few-shot设置下评估文本分类和机器翻译任务。结果显示，zero-shot场景中模型规模对性能影响有限，而few-shot场景中大模型在多语言文本分类中表现出线性改善；翻译任务仅指令微调模型从规模扩展中获益。总体分析表明，总资源水平比预训练语言比例更能预测LLMs的效能，为多语言模型优化提供重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at SEAS Workshop at AAAI25",
      "pdf_url": "http://arxiv.org/pdf/2501.05629v1",
      "published_date": "2025-01-10 00:10:21 UTC",
      "updated_date": "2025-01-10 00:10:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:27:30.722186"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 76,
  "processed_papers_count": 76,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T22:27:50.623184"
}