[
  {
    "arxiv_id": "2509.02896v2",
    "title": "Cut Costs, Not Accuracy: LLM-Powered Data Processing with Guarantees",
    "authors": [
      "Sepanta Zeighami",
      "Shreya Shankar",
      "Aditya Parameswaran"
    ],
    "abstract": "Large Language Models (LLMs) are being increasingly used as a building block in data systems to process large text datasets. To do so, LLM model providers offer multiple LLMs with different sizes, spanning various cost-quality trade-offs when processing text at scale. Top-of-the-line LLMs (e.g., GPT-4o, Claude Sonnet) operate with high accuracy but are prohibitively expensive when processing many records. To avoid high costs, more affordable but lower quality LLMs (e.g., GPT-4o-mini, Claude Haiku) can be used to process records, but we need to ensure that the overall accuracy does not deviate substantially from that of the top-of-the-line LLMs. The model cascade framework provides a blueprint to manage this trade-off, by using the confidence of LLMs in their output (e.g., log-probabilities) to decide on which records to use the affordable LLM. However, existing solutions following this framework provide only marginal cost savings and weak theoretical guarantees because of poor estimation of the quality of the affordable LLM's outputs. We present BARGAIN, a method that judiciously uses affordable LLMs in data processing to significantly reduce cost while providing strong theoretical guarantees on the solution quality. BARGAIN employs a novel adaptive sampling strategy and statistical estimation procedure that uses data and task characteristics and builds on recent statistical tools to make accurate estimations with tight theoretical guarantees. Variants of BARGAIN can support guarantees on accuracy, precision, or recall of the output. Experimental results across 8 real-world datasets show that BARGAIN reduces cost, on average, by up to 86% more than state-of-the-art, while providing stronger theoretical guarantees on accuracy of output, with similar gains when guaranteeing a desired level of precision or recall.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "To appear in SIGMOD'26",
    "pdf_url": "https://arxiv.org/pdf/2509.02896v2",
    "published_date": "2025-09-02 23:41:50 UTC",
    "updated_date": "2025-09-12 16:30:38 UTC"
  },
  {
    "arxiv_id": "2509.02890v2",
    "title": "Grocery to General Merchandise: A Cross-Pollination Recommender using LLMs and Real-Time Cart Context",
    "authors": [
      "Akshay Kekuda",
      "Murali Mohana Krishna Dandu",
      "Rimita Lahiri",
      "Shiqin Cai",
      "Sinduja Subramaniam",
      "Evren Korpeoglu",
      "Kannan Achan"
    ],
    "abstract": "Modern e-commerce platforms strive to enhance customer experience by providing timely and contextually relevant recommendations. However, recommending general merchandise to customers focused on grocery shopping -- such as pairing milk with a milk frother -- remains a critical yet under-explored challenge. This paper introduces a cross-pollination (XP) framework, a novel approach that bridges grocery and general merchandise cross-category recommendations by leveraging multi-source product associations and real-time cart context. Our solution employs a two-stage framework: (1) A candidate generation mechanism that uses co-purchase market basket analysis and LLM-based approach to identify novel item-item associations; and (2) a transformer-based ranker that leverages the real-time sequential cart context and optimizes for engagement signals such as add-to-carts. Offline analysis and online A/B tests show an increase of 36\\% add-to-cart rate with LLM-based retrieval on the item page, and 15\\% lift in add-to-cart using cart context-based ranker on the cart page. Our work contributes practical techniques for cross-category recommendations and broader insights for e-commerce systems.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted at RecSys 2025 EARL Workshop on Evaluating and Applying Recommender Systems with Large Language Models",
    "pdf_url": "https://arxiv.org/pdf/2509.02890v2",
    "published_date": "2025-09-02 23:28:34 UTC",
    "updated_date": "2025-09-29 13:23:57 UTC"
  },
  {
    "arxiv_id": "2509.03550v1",
    "title": "Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method",
    "authors": [
      "Tonghe Li",
      "Jixin Liu",
      "Weili Zeng",
      "Hao Jiang"
    ],
    "abstract": "In the context of continuously rising global air traffic, efficient and safe Conflict Detection and Resolution (CD&R) is paramount for air traffic management. Although Deep Reinforcement Learning (DRL) offers a promising pathway for CD&R automation, existing approaches commonly suffer from a \"unimodal bias\" in their policies. This leads to a critical lack of decision-making flexibility when confronted with complex and dynamic constraints, often resulting in \"decision deadlocks.\" To overcome this limitation, this paper pioneers the integration of diffusion probabilistic models into the safety-critical task of CD&R, proposing a novel autonomous conflict resolution framework named Diffusion-AC. Diverging from conventional methods that converge to a single optimal solution, our framework models its policy as a reverse denoising process guided by a value function, enabling it to generate a rich, high-quality, and multimodal action distribution. This core architecture is complemented by a Density-Progressive Safety Curriculum (DPSC), a training mechanism that ensures stable and efficient learning as the agent progresses from sparse to high-density traffic environments. Extensive simulation experiments demonstrate that the proposed method significantly outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the most challenging high-density scenarios, Diffusion-AC not only maintains a high success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions (NMACs) by approximately 59% compared to the next-best-performing baseline, significantly enhancing the system's safety margin. This performance leap stems from its unique multimodal decision-making capability, which allows the agent to flexibly switch to effective alternative maneuvers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "59 pages,13 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.03550v1",
    "published_date": "2025-09-02 23:17:46 UTC",
    "updated_date": "2025-09-02 23:17:46 UTC"
  },
  {
    "arxiv_id": "2509.02864v1",
    "title": "A-SEA3L-QA: A Fully Automated Self-Evolving, Adversarial Workflow for Arabic Long-Context Question-Answer Generation",
    "authors": [
      "Kesen Wang",
      "Daulet Toibazar",
      "Pedro J. Moreno"
    ],
    "abstract": "We present an end-to-end, self-evolving adversarial workflow for long-context Question-Answer (QA) Generation in Arabic. By orchestrating multiple specialized LVLMs: a question generator, an evaluator, and a swarm of answer generators, our system iteratively refines its own performance without any human intervention. Starting from raw, multi-page Arabic documents across diverse domains, the question generator produces fine-grained, context-aware queries to be tackled by the answer generator swarm, and the evaluator assesses and feeds back quality metrics. This closed-loop cycle enables continuous learning: low-confidence outputs trigger automated re-generation and model updates, progressively enhancing question difficulty and relevance. Moreover, we set the quality metrics as a tunable hyperparameter, enabling question generation at controllable and customizable difficulty levels. We release AraLongBench, a large-scale Arabic benchmark of single- and multi-page challenges spanning hundreds of pages, and demonstrate that our self-evolving workflow substantially outperform static pipelines, markedly boosting the long-context comprehension capabilities of leading Arabic Large Vision Language Models (LVLMs). Lastly, we also meticulously architect a fully automated agentic workflow for long-context Arabic document collection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02864v1",
    "published_date": "2025-09-02 22:21:55 UTC",
    "updated_date": "2025-09-02 22:21:55 UTC"
  },
  {
    "arxiv_id": "2509.02863v1",
    "title": "Enhancing Machine Learning for Imbalanced Medical Data: A Quantum-Inspired Approach to Synthetic Oversampling (QI-SMOTE)",
    "authors": [
      "Vikas Kashtriya",
      "Pardeep Singh"
    ],
    "abstract": "Class imbalance remains a critical challenge in machine learning (ML), particularly in the medical domain, where underrepresented minority classes lead to biased models and reduced predictive performance. This study introduces Quantum-Inspired SMOTE (QI-SMOTE), a novel data augmentation technique that enhances the performance of ML classifiers, including Random Forest (RF), Support Vector Machine (SVM), Logistic Regression (LR), k-Nearest Neighbors (KNN), Gradient Boosting (GB), and Neural Networks, by leveraging quantum principles such as quantum evolution and layered entanglement. Unlike conventional oversampling methods, QI-SMOTE generates synthetic instances that preserve complex data structures, improving model generalization and classification accuracy. We validate QI-SMOTE on the MIMIC-III and MIMIC-IV datasets, using mortality detection as a benchmark task due to their clinical significance and inherent class imbalance. We compare our method against traditional oversampling techniques, including Borderline-SMOTE, ADASYN, SMOTE-ENN, SMOTE-TOMEK, and SVM-SMOTE, using key performance metrics such as Accuracy, F1-score, G-Mean, and AUC-ROC. The results demonstrate that QI-SMOTE significantly improves the effectiveness of ensemble methods (RF, GB, ADA), kernel-based models (SVM), and deep learning approaches by producing more informative and balanced training data. By integrating quantum-inspired transformations into the ML pipeline, QI-SMOTE not only mitigates class imbalance but also enhances the robustness and reliability of predictive models in medical diagnostics and decision-making. This study highlights the potential of quantum-inspired resampling techniques in advancing state-of-the-art ML methodologies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02863v1",
    "published_date": "2025-09-02 22:20:46 UTC",
    "updated_date": "2025-09-02 22:20:46 UTC"
  },
  {
    "arxiv_id": "2509.02853v3",
    "title": "The Architecture of AI Transformation: Four Strategic Patterns and an Emerging Frontier",
    "authors": [
      "Diana A. Wolfe",
      "Alice Choe",
      "Fergus Kidd"
    ],
    "abstract": "Despite extensive investment in artificial intelligence, 95% of enterprises report no measurable profit impact from AI deployments (MIT, 2025). In this theoretical paper, we argue that this gap reflects paradigmatic lock-in that channels AI into incremental optimization rather than structural transformation. Using a cross-case analysis, we propose a 2x2 framework that reconceptualizes AI strategy along two independent dimensions: the degree of transformation achieved (incremental to transformational) and the treatment of human contribution (reduced to amplified). The framework surfaces four patterns now dominant in practice: individual augmentation, process automation, workforce substitution, and a less deployed frontier of collaborative intelligence. Evidence shows that the first three dimensions reinforce legacy work models and yield localized gains without durable value capture. Realizing collaborative intelligence requires three mechanisms: complementarity (pairing distinct human and machine strengths), co-evolution (mutual adaptation through interaction), and boundary-setting (human determination of ethical and strategic parameters). Complementarity and boundary-setting are observable in regulated and high-stakes domains; co-evolution is largely absent, which helps explain limited system-level impact. Our findings in a case study analysis illustrated that advancing toward collaborative intelligence requires material restructuring of roles, governance, and data architecture rather than additional tools. The framework reframes AI transformation as an organizational design challenge: moving from optimizing the division of labor between humans and machines to architecting their convergence, with implications for operating models, workforce development, and the future of work.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "59 pages, 2 tables, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.02853v3",
    "published_date": "2025-09-02 21:57:58 UTC",
    "updated_date": "2025-09-12 02:23:53 UTC"
  },
  {
    "arxiv_id": "2509.02844v4",
    "title": "Conformal Prediction for Time-series Forecasting with Change Points",
    "authors": [
      "Sophia Sun",
      "Rose Yu"
    ],
    "abstract": "Conformal prediction has been explored as a general and efficient way to provide uncertainty quantification for time series. However, current methods struggle to handle time series data with change points - sudden shifts in the underlying data-generating process. In this paper, we propose a novel Conformal Prediction for Time-series with Change points (CPTC) algorithm, addressing this gap by integrating a model to predict the underlying state with online conformal prediction to model uncertainties in non-stationary time series. We prove CPTC's validity and improved adaptivity in the time series setting under minimum assumptions, and demonstrate CPTC's practical effectiveness on 6 synthetic and real-world datasets, showing improved validity and adaptivity compared to state-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02844v4",
    "published_date": "2025-09-02 21:26:53 UTC",
    "updated_date": "2025-12-01 08:47:15 UTC"
  },
  {
    "arxiv_id": "2509.02837v1",
    "title": "HF-RAG: Hierarchical Fusion-based RAG with Multiple Sources and Rankers",
    "authors": [
      "Payel Santra",
      "Madhusudan Ghosh",
      "Debasis Ganguly",
      "Partha Basuchowdhuri",
      "Sudip Kumar Naskar"
    ],
    "abstract": "Leveraging both labeled (input-output associations) and unlabeled data (wider contextual grounding) may provide complementary benefits in retrieval augmented generation (RAG). However, effectively combining evidence from these heterogeneous sources is challenging as the respective similarity scores are not inter-comparable. Additionally, aggregating beliefs from the outputs of multiple rankers can improve the effectiveness of RAG. Our proposed method first aggregates the top-documents from a number of IR models using a standard rank fusion technique for each source (labeled and unlabeled). Next, we standardize the retrieval score distributions within each source by applying z-score transformation before merging the top-retrieved documents from the two sources. We evaluate our approach on the fact verification task, demonstrating that it consistently improves over the best-performing individual ranker or source and also shows better out-of-domain generalization.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02837v1",
    "published_date": "2025-09-02 21:03:40 UTC",
    "updated_date": "2025-09-02 21:03:40 UTC"
  },
  {
    "arxiv_id": "2509.02834v1",
    "title": "Clustering Discourses: Racial Biases in Short Stories about Women Generated by Large Language Models",
    "authors": [
      "Gustavo Bonil",
      "João Gondim",
      "Marina dos Santos",
      "Simone Hashiguti",
      "Helena Maia",
      "Nadia Silva",
      "Helio Pedrini",
      "Sandra Avila"
    ],
    "abstract": "This study investigates how large language models, in particular LLaMA 3.2-3B, construct narratives about Black and white women in short stories generated in Portuguese. From 2100 texts, we applied computational methods to group semantically similar stories, allowing a selection for qualitative analysis. Three main discursive representations emerge: social overcoming, ancestral mythification and subjective self-realization. The analysis uncovers how grammatically coherent, seemingly neutral texts materialize a crystallized, colonially structured framing of the female body, reinforcing historical inequalities. The study proposes an integrated approach, that combines machine learning techniques with qualitative, manual discourse analysis.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 3 figures. Accepted at STIL @ BRACIS 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02834v1",
    "published_date": "2025-09-02 21:01:02 UTC",
    "updated_date": "2025-09-02 21:01:02 UTC"
  },
  {
    "arxiv_id": "2509.02826v1",
    "title": "Ensemble Learning for Healthcare: A Comparative Analysis of Hybrid Voting and Ensemble Stacking in Obesity Risk Prediction",
    "authors": [
      "Towhidul Islam",
      "Md Sumon Ali"
    ],
    "abstract": "Obesity is a critical global health issue driven by dietary, physiological, and environmental factors, and is strongly associated with chronic diseases such as diabetes, cardiovascular disorders, and cancer. Machine learning has emerged as a promising approach for early obesity risk prediction, yet a comparative evaluation of ensemble techniques -- particularly hybrid majority voting and ensemble stacking -- remains limited. This study aims to compare hybrid majority voting and ensemble stacking methods for obesity risk prediction, identifying which approach delivers higher accuracy and efficiency. The analysis seeks to highlight the complementary strengths of these ensemble techniques in guiding better predictive model selection for healthcare applications. Two datasets were utilized to evaluate three ensemble models: Majority Hard Voting, Weighted Hard Voting, and Stacking (with a Multi-Layer Perceptron as meta-classifier). A pool of nine Machine Learning (ML) algorithms, evaluated across a total of 50 hyperparameter configurations, was analyzed to identify the top three models to serve as base learners for the ensemble methods. Preprocessing steps involved dataset balancing, and outlier detection, and model performance was evaluated using Accuracy and F1-Score. On Dataset-1, weighted hard voting and stacking achieved nearly identical performance (Accuracy: 0.920304, F1: 0.920070), outperforming majority hard voting. On Dataset-2, stacking demonstrated superior results (Accuracy: 0.989837, F1: 0.989825) compared to majority hard voting (Accuracy: 0.981707, F1: 0.981675) and weighted hard voting, which showed the lowest performance. The findings confirm that ensemble stacking provides stronger predictive capability, particularly for complex data distributions, while hybrid majority voting remains a robust alternative.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "stat.CO"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 3 figures, 16 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.02826v1",
    "published_date": "2025-09-02 20:44:52 UTC",
    "updated_date": "2025-09-02 20:44:52 UTC"
  },
  {
    "arxiv_id": "2509.02808v1",
    "title": "Improving the Resilience of Quadrotors in Underground Environments by Combining Learning-based and Safety Controllers",
    "authors": [
      "Isaac Ronald Ward",
      "Mark Paral",
      "Kristopher Riordan",
      "Mykel J. Kochenderfer"
    ],
    "abstract": "Autonomously controlling quadrotors in large-scale subterranean environments is applicable to many areas such as environmental surveying, mining operations, and search and rescue. Learning-based controllers represent an appealing approach to autonomy, but are known to not generalize well to `out-of-distribution' environments not encountered during training. In this work, we train a normalizing flow-based prior over the environment, which provides a measure of how far out-of-distribution the quadrotor is at any given time. We use this measure as a runtime monitor, allowing us to switch between a learning-based controller and a safe controller when we are sufficiently out-of-distribution. Our methods are benchmarked on a point-to-point navigation task in a simulated 3D cave environment based on real-world point cloud data from the DARPA Subterranean Challenge Final Event Dataset. Our experimental results show that our combined controller simultaneously possesses the liveness of the learning-based controller (completing the task quickly) and the safety of the safety controller (avoiding collision).",
    "categories": [
      "cs.RO",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted and awarded best paper at the 11th International Conference on Control, Decision and Information Technologies (CoDIT 2025 - https://codit2025.org/)",
    "pdf_url": "https://arxiv.org/pdf/2509.02808v1",
    "published_date": "2025-09-02 20:22:54 UTC",
    "updated_date": "2025-09-02 20:22:54 UTC"
  },
  {
    "arxiv_id": "2509.02794v1",
    "title": "Learning General Policies From Examples",
    "authors": [
      "Blai Bonet",
      "Hector Geffner"
    ],
    "abstract": "Combinatorial methods for learning general policies that solve large collections of planning problems have been recently developed. One of their strengths, in relation to deep learning approaches, is that the resulting policies can be understood and shown to be correct. A weakness is that the methods do not scale up and learn only from small training instances and feature pools that contain a few hundreds of states and features at most. In this work, we propose a new symbolic method for learning policies based on the generalization of sampled plans that ensures structural termination and hence acyclicity. The proposed learning approach is not based on SAT/ASP, as previous symbolic methods, but on a hitting set algorithm that can effectively handle problems with millions of states, and pools with hundreds of thousands of features. The formal properties of the approach are analyzed, and its scalability is tested on a number of benchmarks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02794v1",
    "published_date": "2025-09-02 19:56:08 UTC",
    "updated_date": "2025-09-02 19:56:08 UTC"
  },
  {
    "arxiv_id": "2509.02785v2",
    "title": "DrDiff: Dynamic Routing Diffusion with Hierarchical Attention for Breaking the Efficiency-Quality Trade-off",
    "authors": [
      "Jusheng Zhang",
      "Yijia Fan",
      "Kaitong Cai",
      "Zimeng Huang",
      "Xiaofei Sun",
      "Jian Wang",
      "Chengpei Tang",
      "Keze Wang"
    ],
    "abstract": "This paper introduces DrDiff, a novel framework for long-text generation that overcomes the efficiency-quality trade-off through three core technologies. First, we design a dynamic expert scheduling mechanism that intelligently allocates computational resources during the diffusion process based on text complexity, enabling more efficient handling of text generation tasks of varying difficulty. Second, we introduce a Hierarchical Sparse Attention (HSA) mechanism that adaptively adjusts attention patterns according to a variety of input lengths, reducing computational complexity from O($n^2$) to O($n$) while maintaining model performance. Finally, we propose a soft absorption guidance optimization strategy that combines with DPM-solver++ to reduce diffusion steps, significantly improving generation speed. Comprehensive experiments on various long-text generation benchmarks demonstrate the superiority of our DrDiff over the existing SOTA methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted 2025 EMNLP (MainConference)",
    "pdf_url": "https://arxiv.org/pdf/2509.02785v2",
    "published_date": "2025-09-02 19:38:49 UTC",
    "updated_date": "2025-10-12 20:19:21 UTC"
  },
  {
    "arxiv_id": "2509.02783v2",
    "title": "The Transparent Earth: A Multimodal Foundation Model for the Earth's Subsurface",
    "authors": [
      "Arnab Mazumder",
      "Javier E. Santos",
      "Noah Hobbs",
      "Mohamed Mehana",
      "Daniel O'Malley"
    ],
    "abstract": "We present the Transparent Earth, a transformer-based architecture for reconstructing subsurface properties from heterogeneous datasets that vary in sparsity, resolution, and modality, where each modality represents a distinct type of observation (e.g., stress angle, mantle temperature, tectonic plate type). The model incorporates positional encodings of observations together with modality encodings, derived from a text embedding model applied to a description of each modality. This design enables the model to scale to an arbitrary number of modalities, making it straightforward to add new ones not considered in the initial design. We currently include eight modalities spanning directional angles, categorical classes, and continuous properties such as temperature and thickness. These capabilities support in-context learning, enabling the model to generate predictions either with no inputs or with an arbitrary number of additional observations from any subset of modalities. On validation data, this reduces errors in predicting stress angle by more than a factor of three. The proposed architecture is scalable and demonstrates improved performance with increased parameters. Together, these advances make the Transparent Earth an initial foundation model for the Earth's subsurface that ultimately aims to predict any subsurface property anywhere on Earth.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.geo-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the Neurips 2025 AI4Science Workshop",
    "pdf_url": "https://arxiv.org/pdf/2509.02783v2",
    "published_date": "2025-09-02 19:37:12 UTC",
    "updated_date": "2025-09-23 16:43:24 UTC"
  },
  {
    "arxiv_id": "2509.02782v1",
    "title": "Key Principles in Cross-Domain Hyper-Heuristic Performance",
    "authors": [
      "Václav Sobotka",
      "Lucas Kletzander",
      "Nysret Musliu",
      "Hana Rudová"
    ],
    "abstract": "Cross-domain selection hyper-heuristics aim to distill decades of research on problem-specific heuristic search algorithms into adaptable general-purpose search strategies. In this respect, existing selection hyper-heuristics primarily focus on an adaptive selection of low-level heuristics (LLHs) from a predefined set. In contrast, we concentrate on the composition of this set and its strategic transformations. We systematically analyze transformations based on three key principles: solution acceptance, LLH repetitions, and perturbation intensity, i.e., the proportion of a solution affected by a perturbative LLH. We demonstrate the raw effects of our transformations on a trivial unbiased random selection mechanism. With an appropriately constructed transformation, this trivial method outperforms all available state-of-the-art hyper-heuristics on three challenging real-world domains and finds 11 new best-known solutions. The same method is competitive with the winner of the CHeSC competition, commonly used as the standard cross-domain benchmark. Moreover, we accompany several recent hyper-heuristics with such strategic transformations. Using this approach, we outperform the current state-of-the-art methods on both the CHeSC benchmark and real-world domains while often simplifying their designs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02782v1",
    "published_date": "2025-09-02 19:36:28 UTC",
    "updated_date": "2025-09-02 19:36:28 UTC"
  },
  {
    "arxiv_id": "2509.02761v4",
    "title": "Plan Verification for LLM-Based Embodied Task Completion Agents",
    "authors": [
      "Ananth Hariharan",
      "Vardhan Dongre",
      "Dilek Hakkani-Tür",
      "Gokhan Tur"
    ],
    "abstract": "Large language model (LLM) based task plans and corresponding human demonstrations for embodied AI may be noisy, with unnecessary actions, redundant navigation, and logical errors that reduce policy quality. We propose an iterative verification framework in which a Judge LLM critiques action sequences and a Planner LLM applies the revisions, yielding progressively cleaner and more spatially coherent trajectories. Unlike rule-based approaches, our method relies on natural language prompting, enabling broad generalization across error types including irrelevant actions, contradictions, and missing steps. On a set of manually annotated actions from the TEACh embodied AI dataset, our framework achieves up to 90% recall and 100% precision across four state-of-the-art LLMs (GPT o4-mini, DeepSeek-R1, Gemini 2.5, LLaMA 4 Scout). The refinement loop converges quickly, with 96.5% of sequences requiring at most three iterations, while improving both temporal efficiency and spatial action organization. Crucially, the method preserves human error-recovery patterns rather than collapsing them, supporting future work on robust corrective behavior. By establishing plan verification as a reliable LLM capability for spatial planning and action refinement, we provide a scalable path to higher-quality training data for imitation learning in embodied AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02761v4",
    "published_date": "2025-09-02 19:06:56 UTC",
    "updated_date": "2025-12-31 18:31:30 UTC"
  },
  {
    "arxiv_id": "2509.02758v2",
    "title": "An Ontology-Based Approach to Optimizing Geometry Problem Sets for Skill Development",
    "authors": [
      "Michael Bouzinier",
      "Sergey Trifonov",
      "Matthew Chen",
      "Tarun Venkatesh",
      "Lielle Rifkin"
    ],
    "abstract": "Euclidean geometry has historically played a central role in cultivating logical reasoning and abstract thinking within mathematics education, but has experienced waning emphasis in recent curricula. The resurgence of interest, driven by advances in artificial intelligence and educational technology, has highlighted geometry's potential to develop essential cognitive skills and inspired new approaches to automated problem solving and proof verification. This article presents an ontology-based framework for annotating and optimizing geometry problem sets, originally developed in the 1990s. The ontology systematically classifies geometric problems, solutions, and associated skills into interlinked facts, objects, and methods, supporting granular tracking of student abilities and facilitating curriculum design. The core concept of 'solution graphs'--directed acyclic graphs encoding multiple solution pathways and skill dependencies--enables alignment of problem selection with instructional objectives. We hypothesize that this framework also points toward automated solution validation via semantic parsing. We contend that our approach addresses longstanding challenges in representing dynamic, procedurally complex mathematical knowledge, paving the way for adaptive, feedback-rich educational tools. Our methodology offers a scalable, adaptable foundation for future advances in intelligent geometry education and automated reasoning.",
    "categories": [
      "math.HO",
      "cs.AI"
    ],
    "primary_category": "math.HO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02758v2",
    "published_date": "2025-09-02 19:04:45 UTC",
    "updated_date": "2025-11-16 18:32:39 UTC"
  },
  {
    "arxiv_id": "2509.02754v1",
    "title": "Do LLM Modules Generalize? A Study on Motion Generation for Autonomous Driving",
    "authors": [
      "Mingyi Wang",
      "Jingke Wang",
      "Tengju Ye",
      "Junbo Chen",
      "Kaicheng Yu"
    ],
    "abstract": "Recent breakthroughs in large language models (LLMs) have not only advanced natural language processing but also inspired their application in domains with structurally similar problems--most notably, autonomous driving motion generation. Both domains involve autoregressive sequence modeling, token-based representations, and context-aware decision making, making the transfer of LLM components a natural and increasingly common practice. However, despite promising early attempts, a systematic understanding of which LLM modules are truly transferable remains lacking. In this paper, we present a comprehensive evaluation of five key LLM modules--tokenizer design, positional embedding, pre-training paradigms, post-training strategies, and test-time computation--within the context of motion generation for autonomous driving. Through extensive experiments on the Waymo Sim Agents benchmark, we demonstrate that, when appropriately adapted, these modules can significantly improve performance for autonomous driving motion generation. In addition, we identify which techniques can be effectively transferred, analyze the potential reasons for the failure of others, and discuss the specific adaptations needed for autonomous driving scenarios. We evaluate our method on the Sim Agents task and achieve competitive results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "CoRL 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02754v1",
    "published_date": "2025-09-02 19:02:49 UTC",
    "updated_date": "2025-09-02 19:02:49 UTC"
  },
  {
    "arxiv_id": "2509.02751v1",
    "title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics",
    "authors": [
      "Matthew Russo",
      "Tim Kraska"
    ],
    "abstract": "With advances in large language models (LLMs), researchers are creating new systems that can perform AI-driven analytics over large unstructured datasets. Recent work has explored executing such analytics queries using semantic operators -- a declarative set of AI-powered data transformations with natural language specifications. However, even when optimized, these operators can be expensive to execute on millions of records and their iterator execution semantics make them ill-suited for interactive data analytics tasks. In another line of work, Deep Research systems have demonstrated an ability to answer natural language question(s) over large datasets. These systems use one or more LLM agent(s) to plan their execution, process the dataset(s), and iteratively refine their answer. However, these systems do not explicitly optimize their query plans which can lead to poor plan execution. In order for AI-driven analytics to excel, we need a runtime which combines the optimized execution of semantic operators with the flexibility and more dynamic execution of Deep Research systems. As a first step towards this vision, we build a prototype which enables Deep Research agents to write and execute optimized semantic operator programs. We evaluate our prototype and demonstrate that it can outperform a handcrafted semantic operator program and open Deep Research systems on two basic queries. Compared to a standard open Deep Research agent, our prototype achieves up to 1.95x better F1-score. Furthermore, even if we give the agent access to semantic operators as tools, our prototype still achieves cost and runtime savings of up to 76.8% and 72.7% thanks to its optimized execution.",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 2 figures, submitted to CIDR'26",
    "pdf_url": "https://arxiv.org/pdf/2509.02751v1",
    "published_date": "2025-09-02 18:59:15 UTC",
    "updated_date": "2025-09-02 18:59:15 UTC"
  },
  {
    "arxiv_id": "2509.02746v1",
    "title": "Mentality: A Mamba-based Approach towards Foundation Models for EEG",
    "authors": [
      "Saarang Panchavati",
      "Corey Arnold",
      "William Speier"
    ],
    "abstract": "This work explores the potential of foundation models, specifically a Mamba-based selective state space model, for enhancing EEG analysis in neurological disorder diagnosis. EEG, crucial for diagnosing conditions like epilepsy, presents significant challenges due to its noisy, high-dimensional, and nonlinear nature. Traditional machine learning methods have made advances in automating EEG analysis but often fail to capture its complex spatio-temporal dynamics. Recent advances in deep learning, particularly in sequence modeling, offer new avenues for creating more generalized and expressive models capable of handling such complexities. By training a Mamba-based model on a large dataset containing seizure and non-seizure EEG recordings through a self-supervised reconstruction task followed by a seizure detection task, we demonstrate the model's effectiveness, achieving an AUROC of 0.72 on a held-out test set. This approach marks a significant step toward developing large-scale, clinically applicable foundation models for EEG data analysis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02746v1",
    "published_date": "2025-09-02 18:47:38 UTC",
    "updated_date": "2025-09-02 18:47:38 UTC"
  },
  {
    "arxiv_id": "2509.02722v2",
    "title": "Planning with Reasoning using Vision Language World Model",
    "authors": [
      "Delong Chen",
      "Theo Moutakanni",
      "Willy Chung",
      "Yejin Bang",
      "Ziwei Ji",
      "Allen Bolourchi",
      "Pascale Fung"
    ],
    "abstract": "Effective planning requires strong world models, but high-level world models that can understand and reason about actions with semantic and temporal abstraction remain largely underdeveloped. We introduce the Vision Language World Model (VLWM), a foundation model trained for language-based world modeling on natural videos. Given visual observations, the VLWM first infers the overall goal achievements then predicts a trajectory composed of interleaved actions and world state changes. Those targets are extracted by iterative LLM Self-Refine conditioned on compressed future observations represented by Tree of Captions. The VLWM learns both an action policy and a dynamics model, which respectively facilitates reactive system-1 plan decoding and reflective system-2 planning via cost minimization. The cost evaluates the semantic distance between the hypothetical future states given by VLWM roll-outs and the expected goal state, and is measured by a critic model that we trained in a self-supervised manner. The VLWM achieves state-of-the-art Visual Planning for Assistance (VPA) performance on both benchmark evaluations and our proposed PlannerArena human evaluations, where system-2 improves the Elo score by +27% upon system-1. The VLWM models also outperforms strong VLM baselines on RoboVQA and WorldPrediction benchmark.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02722v2",
    "published_date": "2025-09-02 18:18:57 UTC",
    "updated_date": "2025-09-06 21:02:02 UTC"
  },
  {
    "arxiv_id": "2509.02718v3",
    "title": "Efficient Training-Free Online Routing for High-Volume Multi-LLM Serving",
    "authors": [
      "Fangzhou Wu",
      "Sandeep Silwal"
    ],
    "abstract": "Increasing demand for Large Language Models (LLMs) services imposes substantial deployment and computation costs on providers. LLM routing offers a cost-efficient solution by directing queries to the optimal LLM based on model and query features. However, existing works primarily focus on offline scenarios and struggle to adapt to online settings with high query volume and constrained token budgets. In this work, we introduce the first training-free algorithm for online routing scenarios. Our algorithm leverages approximate nearest neighbor search to efficiently estimate query features and performs a one-time optimization over a small set of initial queries to learn a routing strategy that guides future routing. We provide theoretical guarantees demonstrating that our algorithm achieves a competitive ratio of $1 - o(1)$ under natural assumptions, which is further validated by extensive experiments across 3 benchmark datasets and 8 baselines, showing an average improvement of 3.55$\\times$ in overall performance, 1.85$\\times$ in cost efficiency, and nearly 4.25$\\times$ in throughput. Our code is available at https://github.com/fzwark/PORT.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02718v3",
    "published_date": "2025-09-02 18:15:03 UTC",
    "updated_date": "2025-12-12 21:16:29 UTC"
  },
  {
    "arxiv_id": "2509.02661v2",
    "title": "The Future of Artificial Intelligence and the Mathematical and Physical Sciences (AI+MPS)",
    "authors": [
      "Andrew Ferguson",
      "Marisa LaFleur",
      "Lars Ruthotto",
      "Jesse Thaler",
      "Yuan-Sen Ting",
      "Pratyush Tiwary",
      "Soledad Villar",
      "E. Paulo Alves",
      "Jeremy Avigad",
      "Simon Billinge",
      "Camille Bilodeau",
      "Keith Brown",
      "Emmanuel Candes",
      "Arghya Chattopadhyay",
      "Bingqing Cheng",
      "Jonathan Clausen",
      "Connor Coley",
      "Andrew Connolly",
      "Fred Daum",
      "Sijia Dong",
      "Chrisy Xiyu Du",
      "Cora Dvorkin",
      "Cristiano Fanelli",
      "Eric B. Ford",
      "Luis Manuel Frutos",
      "Nicolás García Trillos",
      "Cecilia Garraffo",
      "Robert Ghrist",
      "Rafael Gomez-Bombarelli",
      "Gianluca Guadagni",
      "Sreelekha Guggilam",
      "Sergei Gukov",
      "Juan B. Gutiérrez",
      "Salman Habib",
      "Johannes Hachmann",
      "Boris Hanin",
      "Philip Harris",
      "Murray Holland",
      "Elizabeth Holm",
      "Hsin-Yuan Huang",
      "Shih-Chieh Hsu",
      "Nick Jackson",
      "Olexandr Isayev",
      "Heng Ji",
      "Aggelos Katsaggelos",
      "Jeremy Kepner",
      "Yannis Kevrekidis",
      "Michelle Kuchera",
      "J. Nathan Kutz",
      "Branislava Lalic",
      "Ann Lee",
      "Matt LeBlanc",
      "Josiah Lim",
      "Rebecca Lindsey",
      "Yongmin Liu",
      "Peter Y. Lu",
      "Sudhir Malik",
      "Vuk Mandic",
      "Vidya Manian",
      "Emeka P. Mazi",
      "Pankaj Mehta",
      "Peter Melchior",
      "Brice Ménard",
      "Jennifer Ngadiuba",
      "Stella Offner",
      "Elsa Olivetti",
      "Shyue Ping Ong",
      "Christopher Rackauckas",
      "Philippe Rigollet",
      "Chad Risko",
      "Philip Romero",
      "Grant Rotskoff",
      "Brett Savoie",
      "Uros Seljak",
      "David Shih",
      "Gary Shiu",
      "Dima Shlyakhtenko",
      "Eva Silverstein",
      "Taylor Sparks",
      "Thomas Strohmer",
      "Christopher Stubbs",
      "Stephen Thomas",
      "Suriyanarayanan Vaikuntanathan",
      "Rene Vidal",
      "Francisco Villaescusa-Navarro",
      "Gregory Voth",
      "Benjamin Wandelt",
      "Rachel Ward",
      "Melanie Weber",
      "Risa Wechsler",
      "Stephen Whitelam",
      "Olaf Wiest",
      "Mike Williams",
      "Zhuoran Yang",
      "Yaroslava G. Yingling",
      "Bin Yu",
      "Shuwen Yue",
      "Ann Zabludoff",
      "Huimin Zhao",
      "Tong Zhang"
    ],
    "abstract": "This community paper developed out of the NSF Workshop on the Future of Artificial Intelligence (AI) and the Mathematical and Physics Sciences (MPS), which was held in March 2025 with the goal of understanding how the MPS domains (Astronomy, Chemistry, Materials Research, Mathematical Sciences, and Physics) can best capitalize on, and contribute to, the future of AI. We present here a summary and snapshot of the MPS community's perspective, as of Spring/Summer 2025, in a rapidly developing field. The link between AI and MPS is becoming increasingly inextricable; now is a crucial moment to strengthen the link between AI and Science by pursuing a strategy that proactively and thoughtfully leverages the potential of AI for scientific discovery and optimizes opportunities to impact the development of AI by applying concepts from fundamental science. To achieve this, we propose activities and strategic priorities that: (1) enable AI+MPS research in both directions; (2) build up an interdisciplinary community of AI+MPS researchers; and (3) foster education and workforce development in AI for MPS researchers and students. We conclude with a summary of suggested priorities for funding agencies, educational institutions, and individual researchers to help position the MPS community to be a leader in, and take full advantage of, the transformative potential of AI+MPS.",
    "categories": [
      "cs.AI",
      "astro-ph.IM",
      "cond-mat.mtrl-sci",
      "cs.LG",
      "physics.data-an",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "Community Paper from the NSF Future of AI+MPS Workshop, Cambridge, Massachusetts, March 24-26, 2025, supported by NSF Award Number 2512945; v2: minor clarifications",
    "pdf_url": "https://arxiv.org/pdf/2509.02661v2",
    "published_date": "2025-09-02 18:00:00 UTC",
    "updated_date": "2025-10-02 07:33:15 UTC"
  },
  {
    "arxiv_id": "2509.03548v1",
    "title": "Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models",
    "authors": [
      "João P. Arroyo",
      "João G. Rodrigues",
      "Daniel Lawand",
      "Denis D. Mauá",
      "Junkyu Lee",
      "Radu Marinescu",
      "Alex Gray",
      "Eduardo R. Laurentino",
      "Fabio G. Cozman"
    ],
    "abstract": "We investigate partially identifiable queries in a class of causal models. We focus on acyclic Structural Causal Models that are quasi-Markovian (that is, each endogenous variable is connected with at most one exogenous confounder). We look into scenarios where endogenous variables are observed (and a distribution over them is known), while exogenous variables are not fully specified. This leads to a representation that is in essence a Bayesian network where the distribution of root variables is not uniquely determined. In such circumstances, it may not be possible to precisely compute a probability value of interest. We thus study the computation of tight probability bounds, a problem that has been solved by multilinear programming in general, and by linear programming when a single confounded component is intervened upon. We present a new algorithm to simplify the construction of such programs by exploiting input probabilities over endogenous variables. For scenarios with a single intervention, we apply column generation to compute a probability bound through a sequence of auxiliary linear integer programs, thus showing that a representation with polynomial cardinality for exogenous variables is possible. Experiments show column generation techniques to be superior to existing methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the Causal Abstractions and Representations (CAR) workshop of the 41st Conference on Uncertainty in Artificial Intelligence (UAI 2025)",
    "pdf_url": "https://arxiv.org/pdf/2509.03548v1",
    "published_date": "2025-09-02 17:51:34 UTC",
    "updated_date": "2025-09-02 17:51:34 UTC"
  },
  {
    "arxiv_id": "2509.02555v1",
    "title": "Surrogate Benchmarks for Model Merging Optimization",
    "authors": [
      "Rio Akizuki",
      "Yuya Kudo",
      "Nozomu Yoshinari",
      "Yoichi Hirose",
      "Toshiyuki Nishimoto",
      "Kento Uchida",
      "Shinichi Shirakawa"
    ],
    "abstract": "Model merging techniques aim to integrate the abilities of multiple models into a single model. Most model merging techniques have hyperparameters, and their setting affects the performance of the merged model. Because several existing works show that tuning hyperparameters in model merging can enhance the merging outcome, developing hyperparameter optimization algorithms for model merging is a promising direction. However, its optimization process is computationally expensive, particularly in merging LLMs. In this work, we develop surrogate benchmarks for optimization of the merging hyperparameters to realize algorithm development and performance comparison at low cost. We define two search spaces and collect data samples to construct surrogate models to predict the performance of a merged model from a hyperparameter. We demonstrate that our benchmarks can predict the performance of merged models well and simulate optimization algorithm behaviors.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "AutoML 2025 Non-Archival Content Track",
    "pdf_url": "https://arxiv.org/pdf/2509.02555v1",
    "published_date": "2025-09-02 17:51:03 UTC",
    "updated_date": "2025-09-02 17:51:03 UTC"
  },
  {
    "arxiv_id": "2509.02547v3",
    "title": "The Landscape of Agentic Reinforcement Learning for LLMs: A Survey",
    "authors": [
      "Guibin Zhang",
      "Hejia Geng",
      "Xiaohang Yu",
      "Zhenfei Yin",
      "Zaibin Zhang",
      "Zelin Tan",
      "Heng Zhou",
      "Zhongzhi Li",
      "Xiangyuan Xue",
      "Yijiang Li",
      "Yifan Zhou",
      "Yang Chen",
      "Chen Zhang",
      "Yutao Fan",
      "Zihu Wang",
      "Songtao Huang",
      "Francisco Piedrahita-Velez",
      "Yue Liao",
      "Hongru Wang",
      "Mengyue Yang",
      "Heng Ji",
      "Jun Wang",
      "Shuicheng Yan",
      "Philip Torr",
      "Lei Bai"
    ],
    "abstract": "The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm shift from conventional reinforcement learning applied to large language models (LLM RL), reframing LLMs from passive sequence generators into autonomous, decision-making agents embedded in complex, dynamic worlds. This survey formalizes this conceptual shift by contrasting the degenerate single-step Markov Decision Processes (MDPs) of LLM-RL with the temporally extended, partially observable Markov decision processes (POMDPs) that define Agentic RL. Building on this foundation, we propose a comprehensive twofold taxonomy: one organized around core agentic capabilities, including planning, tool use, memory, reasoning, self-improvement, and perception, and the other around their applications across diverse task domains. Central to our thesis is that reinforcement learning serves as the critical mechanism for transforming these capabilities from static, heuristic modules into adaptive, robust agentic behavior. To support and accelerate future research, we consolidate the landscape of open-source environments, benchmarks, and frameworks into a practical compendium. By synthesizing over five hundred recent works, this survey charts the contours of this rapidly evolving field and highlights the opportunities and challenges that will shape the development of scalable, general-purpose AI agents.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02547v3",
    "published_date": "2025-09-02 17:46:26 UTC",
    "updated_date": "2025-11-08 05:55:03 UTC"
  },
  {
    "arxiv_id": "2509.02544v2",
    "title": "UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning",
    "authors": [
      "Haoming Wang",
      "Haoyang Zou",
      "Huatong Song",
      "Jiazhan Feng",
      "Junjie Fang",
      "Junting Lu",
      "Longxiang Liu",
      "Qinyu Luo",
      "Shihao Liang",
      "Shijue Huang",
      "Wanjun Zhong",
      "Yining Ye",
      "Yujia Qin",
      "Yuwen Xiong",
      "Yuxin Song",
      "Zhiyong Wu",
      "Aoyan Li",
      "Bo Li",
      "Chen Dun",
      "Chong Liu",
      "Daoguang Zan",
      "Fuxing Leng",
      "Hanbin Wang",
      "Hao Yu",
      "Haobin Chen",
      "Hongyi Guo",
      "Jing Su",
      "Jingjia Huang",
      "Kai Shen",
      "Kaiyu Shi",
      "Lin Yan",
      "Peiyao Zhao",
      "Pengfei Liu",
      "Qinghao Ye",
      "Renjie Zheng",
      "Shulin Xin",
      "Wayne Xin Zhao",
      "Wen Heng",
      "Wenhao Huang",
      "Wenqian Wang",
      "Xiaobo Qin",
      "Yi Lin",
      "Youbin Wu",
      "Zehui Chen",
      "Zihao Wang",
      "Baoquan Zhong",
      "Xinchun Zhang",
      "Xujing Li",
      "Yuanfan Li",
      "Zhongkai Zhao",
      "Chengquan Jiang",
      "Faming Wu",
      "Haotian Zhou",
      "Jinlin Pang",
      "Li Han",
      "Qi Liu",
      "Qianli Ma",
      "Siyao Liu",
      "Songhua Cai",
      "Wenqi Fu",
      "Xin Liu",
      "Yaohui Wang",
      "Zhi Zhang",
      "Bo Zhou",
      "Guoliang Li",
      "Jiajun Shi",
      "Jiale Yang",
      "Jie Tang",
      "Li Li",
      "Qihua Han",
      "Taoran Lu",
      "Woyu Lin",
      "Xiaokang Tong",
      "Xinyao Li",
      "Yichi Zhang",
      "Yu Miao",
      "Zhengxuan Jiang",
      "Zili Li",
      "Ziyuan Zhao",
      "Chenxin Li",
      "Dehua Ma",
      "Feng Lin",
      "Ge Zhang",
      "Haihua Yang",
      "Hangyu Guo",
      "Hongda Zhu",
      "Jiaheng Liu",
      "Junda Du",
      "Kai Cai",
      "Kuanye Li",
      "Lichen Yuan",
      "Meilan Han",
      "Minchao Wang",
      "Shuyue Guo",
      "Tianhao Cheng",
      "Xiaobo Ma",
      "Xiaojun Xiao",
      "Xiaolong Huang",
      "Xinjie Chen",
      "Yidi Du",
      "Yilin Chen",
      "Yiwen Wang",
      "Zhaojian Li",
      "Zhenzhu Yang",
      "Zhiyuan Zeng",
      "Chaolin Jin",
      "Chen Li",
      "Hao Chen",
      "Haoli Chen",
      "Jian Chen",
      "Qinghao Zhao",
      "Guang Shi"
    ],
    "abstract": "The development of autonomous agents for graphical user interfaces (GUIs) presents major challenges in artificial intelligence. While recent advances in native agent models have shown promise by unifying perception, reasoning, action, and memory through end-to-end learning, open problems remain in data scalability, multi-turn reinforcement learning (RL), the limitations of GUI-only operation, and environment stability. In this technical report, we present UI-TARS-2, a native GUI-centered agent model that addresses these challenges through a systematic training methodology: a data flywheel for scalable data generation, a stabilized multi-turn RL framework, a hybrid GUI environment that integrates file systems and terminals, and a unified sandbox platform for large-scale rollouts. Empirical evaluation demonstrates that UI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5. On GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on WindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines such as Claude and OpenAI agents. In game environments, it attains a mean normalized score of 59.8 across a 15-game suite-roughly 60% of human-level performance-and remains competitive with frontier proprietary models (e.g., OpenAI o3) on LMGame-Bench. Additionally, the model can generalize to long-horizon information-seeking tasks and software engineering benchmarks, highlighting its robustness across diverse agent tasks. Detailed analyses of training dynamics further provide insights into achieving stability and efficiency in large-scale agent RL. These results underscore UI-TARS-2's potential to advance the state of GUI agents and exhibit strong generalization to real-world interactive scenarios.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02544v2",
    "published_date": "2025-09-02 17:44:45 UTC",
    "updated_date": "2025-09-05 14:59:27 UTC"
  },
  {
    "arxiv_id": "2509.02530v1",
    "title": "Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots",
    "authors": [
      "Minghuan Liu",
      "Zhengbang Zhu",
      "Xiaoshen Han",
      "Peng Hu",
      "Haotong Lin",
      "Xinyao Li",
      "Jingxiao Chen",
      "Jiafeng Xu",
      "Yichu Yang",
      "Yunfeng Lin",
      "Xinghang Li",
      "Yong Yu",
      "Weinan Zhang",
      "Tao Kong",
      "Bingyi Kang"
    ],
    "abstract": "Modern robotic manipulation primarily relies on visual observations in a 2D color space for skill learning but suffers from poor generalization. In contrast, humans, living in a 3D world, depend more on physical properties-such as distance, size, and shape-than on texture when interacting with objects. Since such 3D geometric information can be acquired from widely available depth cameras, it appears feasible to endow robots with similar perceptual capabilities. Our pilot study found that using depth cameras for manipulation is challenging, primarily due to their limited accuracy and susceptibility to various types of noise. In this work, we propose Camera Depth Models (CDMs) as a simple plugin on daily-use depth cameras, which take RGB images and raw depth signals as input and output denoised, accurate metric depth. To achieve this, we develop a neural data engine that generates high-quality paired data from simulation by modeling a depth camera's noise pattern. Our results show that CDMs achieve nearly simulation-level accuracy in depth prediction, effectively bridging the sim-to-real gap for manipulation tasks. Notably, our experiments demonstrate, for the first time, that a policy trained on raw simulated depth, without the need for adding noise or real-world fine-tuning, generalizes seamlessly to real-world robots on two challenging long-horizon tasks involving articulated, reflective, and slender objects, with little to no performance degradation. We hope our findings will inspire future research in utilizing simulation data and 3D information in general robot policies.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "32 pages, 18 figures, project page: https://manipulation-as-in-simulation.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2509.02530v1",
    "published_date": "2025-09-02 17:29:38 UTC",
    "updated_date": "2025-09-02 17:29:38 UTC"
  },
  {
    "arxiv_id": "2509.02521v2",
    "title": "FLM-Audio: Natural Monologues Improves Native Full-Duplex Chatbots via Dual Training",
    "authors": [
      "Yiqun Yao",
      "Xiang Li",
      "Xin Jiang",
      "Xuezhi Fang",
      "Naitong Yu",
      "Wenjia Ma",
      "Aixin Sun",
      "Yequan Wang"
    ],
    "abstract": "Full-duplex dialog models aim to listen and speak simultaneously, delivering rapid responses to dynamic user input. Among different solutions to full duplexity, a native solution merges multiple channels in each time step, achieving the lowest latency. However, prevailing designs break down the textual monologue sentences for word-level alignment with audio streams, which degrades language modeling abilities. To help address this issue, we introduce natural monologues, which are composed by continuous sentences and waiting intervals, mimicking humanoid cognitive behavior in dialogs. We find a proper training paradigm to be critical for semantically aligning natural monologues with audio. To this end, we develop a dual training paradigm that alternates the position of the monologues, either leading or trailing the audio, across different training stages. A combination of our natural monologue and dual training strategy is applied in developing FLM-Audio, our 7B spoken dialog chatbot with native full-duplexity. As confirmed by experimental results, FLM-Audio achieves superior response qualities and chatting experiences while requiring significantly less training data.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02521v2",
    "published_date": "2025-09-02 17:18:49 UTC",
    "updated_date": "2025-09-11 13:07:17 UTC"
  },
  {
    "arxiv_id": "2509.02515v1",
    "title": "Contemporary Agent Technology: LLM-Driven Advancements vs Classic Multi-Agent Systems",
    "authors": [
      "Costin Bădică",
      "Amelia Bădică",
      "Maria Ganzha",
      "Mirjana Ivanović",
      "Marcin Paprzycki",
      "Dan Selişteanu",
      "Zofia Wrona"
    ],
    "abstract": "This contribution provides our comprehensive reflection on the contemporary agent technology, with a particular focus on the advancements driven by Large Language Models (LLM) vs classic Multi-Agent Systems (MAS). It delves into the models, approaches, and characteristics that define these new systems. The paper emphasizes the critical analysis of how the recent developments relate to the foundational MAS, as articulated in the core academic literature. Finally, it identifies key challenges and promising future directions in this rapidly evolving domain.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "The paper has 33 pages and it contains 1 figure and 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.02515v1",
    "published_date": "2025-09-02 17:07:58 UTC",
    "updated_date": "2025-09-02 17:07:58 UTC"
  },
  {
    "arxiv_id": "2509.02510v1",
    "title": "Top-H Decoding: Adapting the Creativity and Coherence with Bounded Entropy in Text Generation",
    "authors": [
      "Erfan Baghaei Potraghloo",
      "Seyedarmin Azizi",
      "Souvik Kundu",
      "Massoud Pedram"
    ],
    "abstract": "Large language models (LLMs), despite their impressive performance across a wide range of tasks, often struggle to balance two competing objectives in open-ended text generation: fostering diversity and creativity while preserving logical coherence. Existing truncated sampling techniques, including temperature scaling, top-\\$p\\$ (nucleus) sampling, and min-\\$p\\$ sampling, aim to manage this trade-off. However, they exhibit limitations, particularly in the effective incorporation of the confidence of the model into the corresponding sampling strategy. For example, min-\\$p\\$ sampling relies on a single top token as a heuristic for confidence, eventually underutilizing the information of the probability distribution. Toward effective incorporation of the confidence of the model, in this paper, we present **top-H** decoding. We first establish the theoretical foundation of the interplay between creativity and coherence in truncated sampling by formulating an **entropy-constrained minimum divergence** problem. We then prove this minimization problem to be equivalent to an **entropy-constrained mass maximization** (ECMM) problem, which is NP-hard. Finally, we present top-H decoding, a computationally efficient greedy algorithm to solve the ECMM problem. Extensive empirical evaluations demonstrate that top-H outperforms the state-of-the-art (SoTA) alternative of min-\\$p\\$ sampling by up to **25.63%** on creative writing benchmarks, while maintaining robustness on question-answering datasets such as GPQA, GSM8K, and MT-Bench. Additionally, an *LLM-as-judge* evaluation confirms that top-H indeed produces coherent outputs even at higher temperatures, where creativity is especially critical. In summary, top-H advances SoTA in open-ended text generation and can be *easily integrated* into creative writing applications. The code is available at https://github.com/ErfanBaghaei/Top-H-Decoding.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02510v1",
    "published_date": "2025-09-02 17:02:29 UTC",
    "updated_date": "2025-09-02 17:02:29 UTC"
  },
  {
    "arxiv_id": "2509.02499v3",
    "title": "MoSEs: Uncertainty-Aware AI-Generated Text Detection via Mixture of Stylistics Experts with Conditional Thresholds",
    "authors": [
      "Junxi Wu",
      "Jinpeng Wang",
      "Zheng Liu",
      "Bin Chen",
      "Dongjian Hu",
      "Hao Wu",
      "Shu-Tao Xia"
    ],
    "abstract": "The rapid advancement of large language models has intensified public concerns about the potential misuse. Therefore, it is important to build trustworthy AI-generated text detection systems. Existing methods neglect stylistic modeling and mostly rely on static thresholds, which greatly limits the detection performance. In this paper, we propose the Mixture of Stylistic Experts (MoSEs) framework that enables stylistics-aware uncertainty quantification through conditional threshold estimation. MoSEs contain three core components, namely, the Stylistics Reference Repository (SRR), the Stylistics-Aware Router (SAR), and the Conditional Threshold Estimator (CTE). For input text, SRR can activate the appropriate reference data in SRR and provide them to CTE. Subsequently, CTE jointly models the linguistic statistical properties and semantic features to dynamically determine the optimal threshold. With a discrimination score, MoSEs yields prediction labels with the corresponding confidence level. Our framework achieves an average improvement 11.34% in detection performance compared to baselines. More inspiringly, MoSEs shows a more evident improvement 39.15% in the low-resource case. Our code is available at https://github.com/creator-xi/MoSEs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02499v3",
    "published_date": "2025-09-02 16:51:43 UTC",
    "updated_date": "2025-09-08 02:08:49 UTC"
  },
  {
    "arxiv_id": "2509.02495v1",
    "title": "Probabilistically stable revision and comparative probability: a representation theorem and applications",
    "authors": [
      "Krzysztof Mierzewski"
    ],
    "abstract": "The stability rule for belief, advocated by Leitgeb [Annals of Pure and Applied Logic 164, 2013], is a rule for rational acceptance that captures categorical belief in terms of $\\textit{probabilistically stable propositions}$: propositions to which the agent assigns resiliently high credence. The stability rule generates a class of $\\textit{probabilistically stable belief revision}$ operators, which capture the dynamics of belief that result from an agent updating their credences through Bayesian conditioning while complying with the stability rule for their all-or-nothing beliefs. In this paper, we prove a representation theorem that yields a complete characterisation of such probabilistically stable revision operators and provides a `qualitative' selection function semantics for the (non-monotonic) logic of probabilistically stable belief revision. Drawing on the theory of comparative probability orders, this result gives necessary and sufficient conditions for a selection function to be representable as a strongest-stable-set operator on a finite probability space. The resulting logic of probabilistically stable belief revision exhibits strong monotonicity properties while failing the AGM belief revision postulates and satisfying only very weak forms of case reasoning. In showing the main theorem, we prove two results of independent interest to the theory of comparative probability: the first provides necessary and sufficient conditions for the joint representation of a pair of (respectively, strict and non-strict) comparative probability orders. The second result provides a method for axiomatising the logic of ratio comparisons of the form ``event $A$ is at least $k$ times more likely than event $B$''. In addition to these measurement-theoretic applications, we point out two applications of our main result to the theory of simple voting games and to revealed preference theory.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "econ.TH",
      "math.PR"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02495v1",
    "published_date": "2025-09-02 16:42:47 UTC",
    "updated_date": "2025-09-02 16:42:47 UTC"
  },
  {
    "arxiv_id": "2509.02494v1",
    "title": "GridMind: LLMs-Powered Agents for Power System Analysis and Operations",
    "authors": [
      "Hongwei Jin",
      "Kibaek Kim",
      "Jonghwan Kwon"
    ],
    "abstract": "The complexity of traditional power system analysis workflows presents significant barriers to efficient decision-making in modern electric grids. This paper presents GridMind, a multi-agent AI system that integrates Large Language Models (LLMs) with deterministic engineering solvers to enable conversational scientific computing for power system analysis. The system employs specialized agents coordinating AC Optimal Power Flow and N-1 contingency analysis through natural language interfaces while maintaining numerical precision via function calls. GridMind addresses workflow integration, knowledge accessibility, context preservation, and expert decision-support augmentation. Experimental evaluation on IEEE test cases demonstrates that the proposed agentic framework consistently delivers correct solutions across all tested language models, with smaller LLMs achieving comparable analytical accuracy with reduced computational latency. This work establishes agentic AI as a viable paradigm for scientific computing, demonstrating how conversational interfaces can enhance accessibility while preserving numerical rigor essential for critical engineering applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 9 figures, 2 tables. Work under review",
    "pdf_url": "https://arxiv.org/pdf/2509.02494v1",
    "published_date": "2025-09-02 16:42:18 UTC",
    "updated_date": "2025-09-02 16:42:18 UTC"
  },
  {
    "arxiv_id": "2509.02480v1",
    "title": "MLP-Offload: Multi-Level, Multi-Path Offloading for LLM Pre-training to Break the GPU Memory Wall",
    "authors": [
      "Avinash Maurya",
      "M. Mustafa Rafique",
      "Franck Cappello",
      "Bogdan Nicolae"
    ],
    "abstract": "Training LLMs larger than the aggregated memory of multiple GPUs is increasingly necessary due to the faster growth of LLM sizes compared to GPU memory. To this end, multi-tier host memory or disk offloading techniques are proposed by state of art. Despite advanced asynchronous multi-tier read/write strategies, such offloading strategies result in significant I/O overheads in the critical path of training, resulting in slower iterations. To this end, we propose MLP-Offload, a novel multi-level, multi-path offloading engine specifically designed for optimizing LLM training on resource-constrained setups by mitigating I/O bottlenecks. We make several key observations that drive the design of MLP-Offload, such as I/O overheads during the update dominate the iteration time; I/O bandwidth of the third-level remote storage tier remains unutilized; and, contention due to concurrent offloading amplifies I/O bottlenecks. Driven by these insights, we design and implement MLP-Offload to offload the optimizer states across multiple tiers in a cache-efficient and concurrency-controlled fashion to mitigate I/O bottlenecks during the backward and update phases. Evaluations on models up to 280B parameters shows that MLP-Offload achieves 2.5$\\times$ faster iterations compared to the state-of-the-art LLM training runtimes.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "SC'25: The International Conference for High Performance Computing, Networking, Storage and Analysis",
    "pdf_url": "https://arxiv.org/pdf/2509.02480v1",
    "published_date": "2025-09-02 16:30:49 UTC",
    "updated_date": "2025-09-02 16:30:49 UTC"
  },
  {
    "arxiv_id": "2509.04507v1",
    "title": "From Silent Signals to Natural Language: A Dual-Stage Transformer-LLM Approach",
    "authors": [
      "Nithyashree Sivasubramaniam"
    ],
    "abstract": "Silent Speech Interfaces (SSIs) have gained attention for their ability to generate intelligible speech from non-acoustic signals. While significant progress has been made in advancing speech generation pipelines, limited work has addressed the recognition and downstream processing of synthesized speech, which often suffers from phonetic ambiguity and noise. To overcome these challenges, we propose an enhanced automatic speech recognition framework that combines a transformer-based acoustic model with a large language model (LLM) for post-processing. The transformer captures full utterance context, while the LLM ensures linguistic consistency. Experimental results show a 16% relative and 6% absolute reduction in word error rate (WER) over a 36% baseline, demonstrating substantial improvements in intelligibility for silent speech interfaces.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.04507v1",
    "published_date": "2025-09-02 16:13:29 UTC",
    "updated_date": "2025-09-02 16:13:29 UTC"
  },
  {
    "arxiv_id": "2509.02458v1",
    "title": "Generative Sequential Notification Optimization via Multi-Objective Decision Transformers",
    "authors": [
      "Borja Ocejo",
      "Ruofan Wang",
      "Ke Liu",
      "Rohit K. Patra",
      "Haotian Shen",
      "David Liu",
      "Yiwen Yuan",
      "Gokulraj Mohanasundaram",
      "Fedor Borisyuk",
      "Prakruthi Prabhakar"
    ],
    "abstract": "Notifications are an important communication channel for delivering timely and relevant information. Optimizing their delivery involves addressing complex sequential decision-making challenges under constraints such as message utility and user fatigue. Offline reinforcement learning (RL) methods, such as Conservative Q-Learning (CQL), have been applied to this problem but face practical challenges at scale, including instability, sensitivity to distribution shifts, limited reproducibility, and difficulties with explainability in high-dimensional recommendation settings. We present a Decision Transformer (DT) based framework that reframes policy learning as return-conditioned supervised learning, improving robustness, scalability, and modeling flexibility. Our contributions include a real-world comparison with CQL, a multi-reward design suitable for non-episodic tasks, a quantile regression approach to return-to-go conditioning, and a production-ready system with circular buffer-based sequence processing for near-real-time inference. Extensive offline and online experiments in a deployed notification system show that our approach improves notification utility and overall session activity while minimizing user fatigue. Compared to a multi-objective CQL-based agent, the DT-based approach achieved a +0.72% increase in sessions for notification decision-making at LinkedIn by making notification recommendation more relevant.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02458v1",
    "published_date": "2025-09-02 16:09:02 UTC",
    "updated_date": "2025-09-02 16:09:02 UTC"
  },
  {
    "arxiv_id": "2509.02452v2",
    "title": "Do LLMs Adhere to Label Definitions? Examining Their Receptivity to External Label Definitions",
    "authors": [
      "Seyedali Mohammadi",
      "Bhaskara Hanuma Vedula",
      "Hemank Lamba",
      "Edward Raff",
      "Ponnurangam Kumaraguru",
      "Francis Ferraro",
      "Manas Gaur"
    ],
    "abstract": "Do LLMs genuinely incorporate external definitions, or do they primarily rely on their parametric knowledge? To address these questions, we conduct controlled experiments across multiple explanation benchmark datasets (general and domain-specific) and label definition conditions, including expert-curated, LLM-generated, perturbed, and swapped definitions. Our results reveal that while explicit label definitions can enhance accuracy and explainability, their integration into an LLM's task-solving processes is neither guaranteed nor consistent, suggesting reliance on internalized representations in many cases. Models often default to their internal representations, particularly in general tasks, whereas domain-specific tasks benefit more from explicit definitions. These findings underscore the need for a deeper understanding of how LLMs process external knowledge alongside their pre-existing capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2025 (Main Conference)",
    "pdf_url": "https://arxiv.org/pdf/2509.02452v2",
    "published_date": "2025-09-02 16:01:47 UTC",
    "updated_date": "2025-09-28 22:44:37 UTC"
  },
  {
    "arxiv_id": "2509.10511v1",
    "title": "LogGuardQ: A Cognitive-Enhanced Reinforcement Learning Framework for Cybersecurity Anomaly Detection in Security Logs",
    "authors": [
      "Umberto Gonçalves de Sousa"
    ],
    "abstract": "Reinforcement learning (RL) has transformed sequential decision-making, but traditional algorithms like Deep Q-Networks (DQNs) and Proximal Policy Optimization (PPO) often struggle with efficient exploration, stability, and adaptability in dynamic environments. This study presents LogGuardQ (Adaptive Log Guard with Cognitive enhancement), a novel framework that integrates a dual-memory system inspired by human cognition and adaptive exploration strategies driven by temperature decay and curiosity. Evaluated on a dataset of 1,000,000 simulated access logs with 47.9% anomalies over 20,000 episodes, LogGuardQ achieves a 96.0% detection rate (versus 93.0% for DQN and 47.1% for PPO), with precision of 0.4776, recall of 0.9996, and an F1-score of 0.6450. The mean reward is 20.34 \\pm 44.63 across all episodes (versus 18.80 \\pm 43.98 for DQN and -0.17 \\pm 23.79 for PPO), with an average of 5.0 steps per episode (constant across models). Graphical analyses, including learning curves smoothed with a Savgol filter (window=501, polynomial=2), variance trends, action distributions, and cumulative detections, demonstrate LogGuardQ's superior stability and efficiency. Statistical tests (Mann-Whitney U) confirm significant performance advantages (e.g., p = 0.0002 vs. DQN with negligible effect size, p < 0.0001 vs. PPO with medium effect size, and p < 0.0001 for DQN vs. PPO with small effect size). By bridging cognitive science and RL, LogGuardQ offers a scalable approach to adaptive learning in uncertain environments, with potential applications in cybersecurity, intrusion detection, and decision-making under uncertainty.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.10511v1",
    "published_date": "2025-09-02 15:51:53 UTC",
    "updated_date": "2025-09-02 15:51:53 UTC"
  },
  {
    "arxiv_id": "2509.02444v2",
    "title": "AppCopilot: Toward General, Accurate, Long-Horizon, and Efficient Mobile Agent",
    "authors": [
      "Jingru Fan",
      "Yufan Dang",
      "Jingyao Wu",
      "Huatao Li",
      "Runde Yang",
      "Xiyuan Yang",
      "Yuheng Wang",
      "Chen Qian"
    ],
    "abstract": "With the raid evolution of large language models and multimodal models, the mobile-agent landscape has proliferated without converging on the fundamental challenges. This paper identifies four core problems that should be solved for mobile agents to deliver practical, scalable impact: (1) generalization across tasks, APPs, and devices; (2) accuracy, specifically precise on-screen interaction and click targeting; (3) long-horizon capability for sustained, multi-step goals; and (4) efficiency, specifically high-performance runtime on resource-constrained devices. We present AppCopilot, a multimodal, multi-agent, general-purpose mobile agent that operates across applications. AppCopilot operationalizes this position through an end-to-end pipeline spanning data collection, training, finetuning, efficient inference, and PC/mobile application. At the model layer, it integrates multimodal foundation models with robust Chinese-English support. At the reasoning and control layer, it combines chain-of-thought reasoning, hierarchical task planning and decomposition, and multi-agent collaboration. At the execution layer, it enables experiential adaptation, voice interaction, function calling, cross-APP and cross-device orchestration, and comprehensive mobile APP support. The system design incorporates profiling-driven optimization for latency and memory across heterogeneous hardware. Empirically, AppCopilot achieves significant improvements on four dimensions: stronger generalization, higher precision of on screen actions, more reliable long horizon task completion, and faster, more resource efficient runtime. By articulating a cohesive position and a reference architecture that closes the loop from data collection, training to finetuning and efficient inference, this paper offers a concrete roadmap for general purpose mobile agent and provides actionable guidance.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Project at https://github.com/OpenBMB/AppCopilot",
    "pdf_url": "https://arxiv.org/pdf/2509.02444v2",
    "published_date": "2025-09-02 15:48:21 UTC",
    "updated_date": "2025-10-17 00:57:58 UTC"
  },
  {
    "arxiv_id": "2509.02419v1",
    "title": "From Noisy Labels to Intrinsic Structure: A Geometric-Structural Dual-Guided Framework for Noise-Robust Medical Image Segmentation",
    "authors": [
      "Tao Wang",
      "Zhenxuan Zhang",
      "Yuanbo Zhou",
      "Xinlin Zhang",
      "Yuanbin Chen",
      "Tao Tan",
      "Guang Yang",
      "Tong Tong"
    ],
    "abstract": "The effectiveness of convolutional neural networks in medical image segmentation relies on large-scale, high-quality annotations, which are costly and time-consuming to obtain. Even expert-labeled datasets inevitably contain noise arising from subjectivity and coarse delineations, which disrupt feature learning and adversely impact model performance. To address these challenges, this study propose a Geometric-Structural Dual-Guided Network (GSD-Net), which integrates geometric and structural cues to improve robustness against noisy annotations. It incorporates a Geometric Distance-Aware module that dynamically adjusts pixel-level weights using geometric features, thereby strengthening supervision in reliable regions while suppressing noise. A Structure-Guided Label Refinement module further refines labels with structural priors, and a Knowledge Transfer module enriches supervision and improves sensitivity to local details. To comprehensively assess its effectiveness, we evaluated GSD-Net on six publicly available datasets: four containing three types of simulated label noise, and two with multi-expert annotations that reflect real-world subjectivity and labeling inconsistencies. Experimental results demonstrate that GSD-Net achieves state-of-the-art performance under noisy annotations, achieving improvements of 2.52% on Kvasir, 22.76% on Shenzhen, 8.87% on BU-SUC, and 4.59% on BraTS2020 under SR simulated noise. The codes of this study are available at https://github.com/ortonwang/GSD-Net.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02419v1",
    "published_date": "2025-09-02 15:23:59 UTC",
    "updated_date": "2025-09-02 15:23:59 UTC"
  },
  {
    "arxiv_id": "2509.02411v1",
    "title": "A Survey: Towards Privacy and Security in Mobile Large Language Models",
    "authors": [
      "Honghui Xu",
      "Kaiyang Li",
      "Wei Chen",
      "Danyang Zheng",
      "Zhiyuan Li",
      "Zhipeng Cai"
    ],
    "abstract": "Mobile Large Language Models (LLMs) are revolutionizing diverse fields such as healthcare, finance, and education with their ability to perform advanced natural language processing tasks on-the-go. However, the deployment of these models in mobile and edge environments introduces significant challenges related to privacy and security due to their resource-intensive nature and the sensitivity of the data they process. This survey provides a comprehensive overview of privacy and security issues associated with mobile LLMs, systematically categorizing existing solutions such as differential privacy, federated learning, and prompt encryption. Furthermore, we analyze vulnerabilities unique to mobile LLMs, including adversarial attacks, membership inference, and side-channel attacks, offering an in-depth comparison of their effectiveness and limitations. Despite recent advancements, mobile LLMs face unique hurdles in achieving robust security while maintaining efficiency in resource-constrained environments. To bridge this gap, we propose potential applications, discuss open challenges, and suggest future research directions, paving the way for the development of trustworthy, privacy-compliant, and scalable mobile LLM systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02411v1",
    "published_date": "2025-09-02 15:19:57 UTC",
    "updated_date": "2025-09-02 15:19:57 UTC"
  },
  {
    "arxiv_id": "2509.02655v1",
    "title": "BioBlue: Notable runaway-optimiser-like LLM failure modes on biologically and economically aligned AI safety benchmarks for LLMs with simplified observation format",
    "authors": [
      "Roland Pihlakas",
      "Sruthi Kuriakose"
    ],
    "abstract": "Relatively many past AI safety discussions have centered around the dangers of unbounded utility maximisation by RL agents, illustrated by scenarios like the \"paperclip maximiser\" or by specification gaming in general. Unbounded maximisation is problematic for many reasons. We wanted to verify whether these RL runaway optimisation problems are still relevant with LLMs as well. Turns out, strangely, this is indeed clearly the case. The problem is not that the LLMs just lose context or become incoherent. The problem is that in various scenarios, LLMs lose context in very specific ways, which systematically resemble runaway optimisers in the following distinct ways: 1) Ignoring homeostatic targets and \"defaulting\" to unbounded maximisation instead. 2) It is equally concerning that the \"default\" meant also reverting back to single-objective optimisation. Our findings also suggest that long-running scenarios are important. Systematic failures emerge after periods of initially successful behaviour. In some trials the LLMs were successful until the end. This means, while current LLMs do conceptually grasp biological and economic alignment, they exhibit randomly triggered problematic behavioural tendencies under sustained long-running conditions, particularly involving multiple or competing objectives. Once they flip, they usually do not recover. Even though LLMs look multi-objective and bounded on the surface, the underlying mechanisms seem to be actually still biased towards being single-objective and unbounded.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "13 pages, 8 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.02655v1",
    "published_date": "2025-09-02 15:13:14 UTC",
    "updated_date": "2025-09-02 15:13:14 UTC"
  },
  {
    "arxiv_id": "2509.02401v1",
    "title": "Towards Agents That Know When They Don't Know: Uncertainty as a Control Signal for Structured Reasoning",
    "authors": [
      "Josefa Lia Stoisser",
      "Marc Boubnovski Martell",
      "Lawrence Phillips",
      "Gianluca Mazzoni",
      "Lea Mørch Harder",
      "Philip Torr",
      "Jesper Ferkinghoff-Borg",
      "Kaspar Martens",
      "Julien Fauqueur"
    ],
    "abstract": "Large language model (LLM) agents are increasingly deployed in structured biomedical data environments, yet they often produce fluent but overconfident outputs when reasoning over complex multi-table data. We introduce an uncertainty-aware agent for query-conditioned multi-table summarization that leverages two complementary signals: (i) retrieval uncertainty--entropy over multiple table-selection rollouts--and (ii) summary uncertainty--combining self-consistency and perplexity. Summary uncertainty is incorporated into reinforcement learning (RL) with Group Relative Policy Optimization (GRPO), while both retrieval and summary uncertainty guide inference-time filtering and support the construction of higher-quality synthetic datasets.\n  On multi-omics benchmarks, our approach improves factuality and calibration, nearly tripling correct and useful claims per summary (3.0\\(\\rightarrow\\)8.4 internal; 3.6\\(\\rightarrow\\)9.9 cancer multi-omics) and substantially improving downstream survival prediction (C-index 0.32\\(\\rightarrow\\)0.63). These results demonstrate that uncertainty can serve as a control signal--enabling agents to abstain, communicate confidence, and become more reliable tools for complex structured-data environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02401v1",
    "published_date": "2025-09-02 15:12:10 UTC",
    "updated_date": "2025-09-02 15:12:10 UTC"
  },
  {
    "arxiv_id": "2509.02387v1",
    "title": "Real-time ML-based Defense Against Malicious Payload in Reconfigurable Embedded Systems",
    "authors": [
      "Rye Stahle-Smith",
      "Rasha Karakchi"
    ],
    "abstract": "The growing use of FPGAs in reconfigurable systems introducessecurity risks through malicious bitstreams that could cause denial-of-service (DoS), data leakage, or covert attacks. We investigated chip-level hardware malicious payload in embedded systems and proposed a supervised machine learning method to detect malicious bitstreams via static byte-level features. Our approach diverges from existing methods by analyzing bitstreams directly at the binary level, enabling real-time detection without requiring access to source code or netlists. Bitstreams were sourced from state-of-the-art (SOTA) benchmarks and re-engineered to target the Xilinx PYNQ-Z1 FPGA Development Board. Our dataset included 122 samples of benign and malicious configurations. The data were vectorized using byte frequency analysis, compressed using TSVD, and balanced using SMOTE to address class imbalance. The evaluated classifiers demonstrated that Random Forest achieved a macro F1-score of 0.97, underscoring the viability of real-time Trojan detection on resource-constrained systems. The final model was serialized and successfully deployed via PYNQ to enable integrated bitstream analysis.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "This paper is submitted at Supercomputing (SC'25)",
    "pdf_url": "https://arxiv.org/pdf/2509.02387v1",
    "published_date": "2025-09-02 14:52:43 UTC",
    "updated_date": "2025-09-02 14:52:43 UTC"
  },
  {
    "arxiv_id": "2509.02372v2",
    "title": "Scam2Prompt: A Scalable Framework for Auditing Malicious Scam Endpoints in Production LLMs",
    "authors": [
      "Zhiyang Chen",
      "Tara Saba",
      "Xun Deng",
      "Xujie Si",
      "Fan Long"
    ],
    "abstract": "Large Language Models (LLMs) have become critical to modern software development, but their reliance on uncurated web-scale datasets for training introduces a significant security risk: the absorption and reproduction of malicious content. To systematically evaluate this risk, we introduce Scam2Prompt, a scalable automated auditing framework that identifies the underlying intent of a scam site and then synthesizes innocuous, developer-style prompts that mirror this intent, allowing us to test whether an LLM will generate malicious code in response to these innocuous prompts. In a large-scale study of four production LLMs (GPT-4o, GPT-4o-mini, Llama-4-Scout, and DeepSeek-V3), we found that Scam2Prompt's innocuous prompts triggered malicious URL generation in 4.24% of cases. To test the persistence of this security risk, we constructed Innoc2Scam-bench, a benchmark of 1,559 innocuous prompts that consistently elicited malicious code from all four initial LLMs. When applied to seven additional production LLMs released in 2025, we found the vulnerability is not only present but severe, with malicious code generation rates ranging from 12.7% to 43.8%. Furthermore, existing safety measures like state-of-the-art guardrails proved insufficient to prevent this behavior, with an overall detection rate of less than 0.3%.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02372v2",
    "published_date": "2025-09-02 14:39:25 UTC",
    "updated_date": "2025-10-02 20:58:03 UTC"
  },
  {
    "arxiv_id": "2509.02369v1",
    "title": "Guidance and Control Neural Network Acceleration using Memristors",
    "authors": [
      "Zacharia A. Rudge",
      "Dario Izzo",
      "Moritz Fieback",
      "Anteneh Gebregiorgis",
      "Said Hamdioui",
      "Dominik Dold"
    ],
    "abstract": "In recent years, the space community has been exploring the possibilities of Artificial Intelligence (AI), specifically Artificial Neural Networks (ANNs), for a variety of on board applications. However, this development is limited by the restricted energy budget of smallsats and cubesats as well as radiation concerns plaguing modern chips. This necessitates research into neural network accelerators capable of meeting these requirements whilst satisfying the compute and performance needs of the application. This paper explores the use of Phase-Change Memory (PCM) and Resistive Random-Access Memory (RRAM) memristors for on-board in-memory computing AI acceleration in space applications. A guidance and control neural network (G\\&CNET) accelerated using memristors is simulated in a variety of scenarios and with both device types to evaluate the performance of memristor-based accelerators, considering device non-idealities such as noise and conductance drift. We show that the memristive accelerator is able to learn the expert actions, though challenges remain with the impact of noise on accuracy. We also show that re-training after degradation is able to restore performance to nominal levels. This study provides a foundation for future research into memristor-based AI accelerators for space, highlighting their potential and the need for further investigation.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.AR",
    "comment": "4 pages, SPAICE 2024 conference",
    "pdf_url": "https://arxiv.org/pdf/2509.02369v1",
    "published_date": "2025-09-02 14:33:00 UTC",
    "updated_date": "2025-09-02 14:33:00 UTC"
  },
  {
    "arxiv_id": "2509.04506v1",
    "title": "Memristor-Based Neural Network Accelerators for Space Applications: Enhancing Performance with Temporal Averaging and SIRENs",
    "authors": [
      "Zacharia A. Rudge",
      "Dominik Dold",
      "Moritz Fieback",
      "Dario Izzo",
      "Said Hamdioui"
    ],
    "abstract": "Memristors are an emerging technology that enables artificial intelligence (AI) accelerators with high energy efficiency and radiation robustness -- properties that are vital for the deployment of AI on-board spacecraft. However, space applications require reliable and precise computations, while memristive devices suffer from non-idealities, such as device variability, conductance drifts, and device faults. Thus, porting neural networks (NNs) to memristive devices often faces the challenge of severe performance degradation. In this work, we show in simulations that memristor-based NNs achieve competitive performance levels on on-board tasks, such as navigation \\& control and geodesy of asteroids. Through bit-slicing, temporal averaging of NN layers, and periodic activation functions, we improve initial results from around $0.07$ to $0.01$ and $0.3$ to $0.007$ for both tasks using RRAM devices, coming close to state-of-the-art levels ($0.003-0.005$ and $0.003$, respectively). Our results demonstrate the potential of memristors for on-board space applications, and we are convinced that future technology and NN improvements will further close the performance gap to fully unlock the benefits of memristors.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "eess.SY",
    "comment": "21 pages, IAA acta astronautica. arXiv admin note: text overlap with arXiv:2509.02369",
    "pdf_url": "https://arxiv.org/pdf/2509.04506v1",
    "published_date": "2025-09-02 14:30:50 UTC",
    "updated_date": "2025-09-02 14:30:50 UTC"
  },
  {
    "arxiv_id": "2509.02360v2",
    "title": "When Agents go Astray: Course-Correcting SWE Agents with PRMs",
    "authors": [
      "Shubham Gandhi",
      "Jason Tsay",
      "Jatin Ganhotra",
      "Kiran Kate",
      "Yara Rizk"
    ],
    "abstract": "Large Language Model (LLM) agents are increasingly deployed for complex, multi-step software engineering (SWE) tasks. However, their trajectories often contain costly inefficiencies, such as redundant exploration, looping, and failure to terminate once a solution is reached. Prior work has largely treated these errors in a post-hoc manner, diagnosing failures only after execution. In this paper, we introduce SWE-PRM, an inference-time Process Reward Model (PRM) that intervenes during execution to detect and course-correct trajectory-level errors. Our PRM design leverages a taxonomy of common inefficiencies and delivers lightweight, interpretable feedback without modifying the underlying policy. On SWE-bench Verified, closed-source PRMs improve resolution from 40.0% to 50.6% (+10.6 p.p.), with the largest gains on medium and hard tasks. Among feedback strategies, taxonomy-guided PRMs outperform unguided or explicit action-prescriptive variants, increasing success rate while reducing trajectory length. These benefits come at an acceptable added inference cost of as low as $0.2, making PRMs a practical and scalable mechanism for improving SWE agents' reliability and efficiency.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02360v2",
    "published_date": "2025-09-02 14:23:15 UTC",
    "updated_date": "2025-10-21 08:41:38 UTC"
  },
  {
    "arxiv_id": "2509.05346v2",
    "title": "Benchmarking Large Language Models for Personalized Guidance in AI-Enhanced Learning",
    "authors": [
      "Bo Yuan",
      "Jiazi Hu"
    ],
    "abstract": "While Large Language Models (LLMs) are increasingly envisioned as intelligent assistants for personalized learning, systematic head-to-head evaluations in authentic learning scenarios remain scarce. This study presents an empirical comparison of three state-of-the-art LLMs on a tutoring task simulating a realistic learning setting. Using a dataset containing a student's responses to ten mixed-format questions with correctness labels, each model was asked to (i) analyze the quiz to identify underlying knowledge components, (ii) infer the student's mastery profile, and (iii) generate targeted guidance for improvement. To mitigate subjectivity and evaluator bias, Gemini was employed as a virtual judge to perform pairwise comparisons across multiple dimensions: accuracy, clarity, actionability, and appropriateness. Results analyzed via the Bradley-Terry model reveal that GPT-4o is generally preferred, producing feedback that is more informative and better structured than its counterparts, whereas DeepSeek-V3 and GLM-4.5 demonstrate intermittent strengths but lower consistency. These findings highlight the feasibility of deploying LLMs as advanced teaching assistants for individualized support and provide methodological insights for subsequent empirical research on LLM-driven personalized learning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.05346v2",
    "published_date": "2025-09-02 14:21:59 UTC",
    "updated_date": "2025-10-22 13:08:29 UTC"
  },
  {
    "arxiv_id": "2509.02351v2",
    "title": "Ordinal Adaptive Correction: A Data-Centric Approach to Ordinal Image Classification with Noisy Labels",
    "authors": [
      "Alireza Sedighi Moghaddam",
      "Mohammad Reza Mohammadi"
    ],
    "abstract": "Labeled data is a fundamental component in training supervised deep learning models for computer vision tasks. However, the labeling process, especially for ordinal image classification where class boundaries are often ambiguous, is prone to error and noise. Such label noise can significantly degrade the performance and reliability of machine learning models. This paper addresses the problem of detecting and correcting label noise in ordinal image classification tasks. To this end, a novel data-centric method called ORDinal Adaptive Correction (ORDAC) is proposed for adaptive correction of noisy labels. The proposed approach leverages the capabilities of Label Distribution Learning (LDL) to model the inherent ambiguity and uncertainty present in ordinal labels. During training, ORDAC dynamically adjusts the mean and standard deviation of the label distribution for each sample. Rather than discarding potentially noisy samples, this approach aims to correct them and make optimal use of the entire training dataset. The effectiveness of the proposed method is evaluated on benchmark datasets for age estimation (Adience) and disease severity detection (Diabetic Retinopathy) under various asymmetric Gaussian noise scenarios. Results show that ORDAC and its extended versions (ORDAC_C and ORDAC_R) lead to significant improvements in model performance. For instance, on the Adience dataset with 40% noise, ORDAC_R reduced the mean absolute error from 0.86 to 0.62 and increased the recall metric from 0.37 to 0.49. The method also demonstrated its effectiveness in correcting intrinsic noise present in the original datasets. This research indicates that adaptive label correction using label distributions is an effective strategy to enhance the robustness and accuracy of ordinal classification models in the presence of noisy data.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures, 5 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.02351v2",
    "published_date": "2025-09-02 14:17:16 UTC",
    "updated_date": "2025-12-29 15:03:06 UTC"
  },
  {
    "arxiv_id": "2509.02350v1",
    "title": "Implicit Reasoning in Large Language Models: A Comprehensive Survey",
    "authors": [
      "Jindong Li",
      "Yali Fu",
      "Li Fan",
      "Jiahong Liu",
      "Yao Shu",
      "Chengwei Qin",
      "Menglin Yang",
      "Irwin King",
      "Rex Ying"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong generalization across a wide range of tasks. Reasoning with LLMs is central to solving multi-step problems and complex decision-making. To support efficient reasoning, recent studies have shifted attention from explicit chain-of-thought prompting toward implicit reasoning, where reasoning occurs silently via latent structures without emitting intermediate textual steps. Implicit reasoning brings advantages such as lower generation cost, faster inference, and better alignment with internal computation. Although prior surveys have discussed latent representations in the context of reasoning, a dedicated and mechanism-level examination of how reasoning unfolds internally within LLMs remains absent. This survey fills that gap by introducing a taxonomy centered on execution paradigms, shifting the focus from representational forms to computational strategies. We organize existing methods into three execution paradigms based on \\textbf{\\textit{how and where internal computation unfolds}}: latent optimization, signal-guided control, and layer-recurrent execution. We also review structural, behavioral and representation-based evidence that supports the presence of implicit reasoning in LLMs. We further provide a structured overview of the evaluation metrics and benchmarks used in existing works to assess the effectiveness and reliability of implicit reasoning. We maintain a continuously updated project at: https://github.com/digailab/awesome-llm-implicit-reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02350v1",
    "published_date": "2025-09-02 14:16:02 UTC",
    "updated_date": "2025-09-02 14:16:02 UTC"
  },
  {
    "arxiv_id": "2509.02349v2",
    "title": "AudioCodecBench: A Comprehensive Benchmark for Audio Codec Evaluation",
    "authors": [
      "Lu Wang",
      "Hao Chen",
      "Siyu Wu",
      "Zhiyue Wu",
      "Hao Zhou",
      "Chengfeng Zhang",
      "Ting Wang",
      "Haodi Zhang"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have been widely applied in speech and music. This tendency has led to a focus on audio tokenization for Large Models (LMs). Unlike semantic-only text tokens, audio tokens must both capture global semantic content and preserve fine-grained acoustic details. Moreover, they provide a discrete method for speech and music that can be effectively integrated into MLLMs. However, existing research is unsuitable in the definitions of semantic tokens and acoustic tokens. In addition, the evaluation of different codecs typically concentrates on specific domains or tasks, such as reconstruction or Automatic Speech Recognition (ASR) task, which prevents fair and comprehensive comparisons. To address these problems, this paper provides suitable definitions for semantic and acoustic tokens and introduces a systematic evaluation framework. This framework allows for a comprehensive assessment of codecs' capabilities which evaluate across four dimensions: audio reconstruction metric, codebook index (ID) stability, decoder-only transformer perplexity, and performance on downstream probe tasks. Our results show the correctness of the provided suitable definitions and the correlation among reconstruction metrics, codebook ID stability, downstream probe tasks and perplexity.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02349v2",
    "published_date": "2025-09-02 14:15:22 UTC",
    "updated_date": "2025-09-04 14:25:57 UTC"
  },
  {
    "arxiv_id": "2509.02341v1",
    "title": "RDIT: Residual-based Diffusion Implicit Models for Probabilistic Time Series Forecasting",
    "authors": [
      "Chih-Yu Lai",
      "Yu-Chien Ning",
      "Duane S. Boning"
    ],
    "abstract": "Probabilistic Time Series Forecasting (PTSF) plays a critical role in domains requiring accurate and uncertainty-aware predictions for decision-making. However, existing methods offer suboptimal distribution modeling and suffer from a mismatch between training and evaluation metrics. Surprisingly, we found that augmenting a strong point estimator with a zero-mean Gaussian, whose standard deviation matches its training error, can yield state-of-the-art performance in PTSF. In this work, we propose RDIT, a plug-and-play framework that combines point estimation and residual-based conditional diffusion with a bidirectional Mamba network. We theoretically prove that the Continuous Ranked Probability Score (CRPS) can be minimized by adjusting to an optimal standard deviation and then derive algorithms to achieve distribution matching. Evaluations on eight multivariate datasets across varied forecasting horizons demonstrate that RDIT achieves lower CRPS, rapid inference, and improved coverage compared to strong baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02341v1",
    "published_date": "2025-09-02 14:06:29 UTC",
    "updated_date": "2025-09-02 14:06:29 UTC"
  },
  {
    "arxiv_id": "2509.02340v1",
    "title": "Explainability-Driven Dimensionality Reduction for Hyperspectral Imaging",
    "authors": [
      "Salma Haidar",
      "José Oramas"
    ],
    "abstract": "Hyperspectral imaging (HSI) provides rich spectral information for precise material classification and analysis; however, its high dimensionality introduces a computational burden and redundancy, making dimensionality reduction essential. We present an exploratory study into the application of post-hoc explainability methods in a model--driven framework for band selection, which reduces the spectral dimension while preserving predictive performance. A trained classifier is probed with explanations to quantify each band's contribution to its decisions. We then perform deletion--insertion evaluations, recording confidence changes as ranked bands are removed or reintroduced, and aggregate these signals into influence scores. Selecting the highest--influence bands yields compact spectral subsets that maintain accuracy and improve efficiency. Experiments on two public benchmarks (Pavia University and Salinas) demonstrate that classifiers trained on as few as 30 selected bands match or exceed full--spectrum baselines while reducing computational requirements. The resulting subsets align with physically meaningful, highly discriminative wavelength regions, indicating that model--aligned, explanation-guided band selection is a principled route to effective dimensionality reduction for HSI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02340v1",
    "published_date": "2025-09-02 14:06:10 UTC",
    "updated_date": "2025-09-02 14:06:10 UTC"
  },
  {
    "arxiv_id": "2509.02333v2",
    "title": "DCPO: Dynamic Clipping Policy Optimization",
    "authors": [
      "Shihui Yang",
      "Chengfeng Dou",
      "Peidong Guo",
      "Kai Lu",
      "Qiang Ju",
      "Fei Deng",
      "Rihui Xin"
    ],
    "abstract": "Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a promising framework for enhancing the reasoning capabilities of large language models. However, existing approaches such as GRPO often suffer from zero gradients. This problem arises primarily due to fixed clipping bounds for token-level probability ratios and the standardization of identical rewards, which can lead to ineffective gradient updates and underutilization of generated responses. In this work, we propose Dynamic Clipping Policy Optimization(DCPO), which introduces a dynamic clipping strategy that adaptively adjusts clipping bounds based on token-specific prior probabilities to enhance token-level exploration, and a smooth advantage standardization technique that standardizes rewards across cumulative training steps to improve the response-level effective utilization of generated responses. DCPO achieved state-of-the-art performance on four benchmarks based on four different models. In particular, DCPO achieved an Avg@1 of 46.7 under greedy decoding and an Avg@32 of 38.8 under 32 times sampling on the AIME24 benchmark, surpassing DAPO (36.7/31.6), GRPO (36.7/32.1) and GSPO (40.0/34.9) on the Qwen2.5-Math-7B model. On the AIME25 benchmark based on Qwen2.5-14B, DCPO achieves a performance of (23.3/19.0), surpassing GRPO (13.3/10.5), DAPO (20.0/15.3) and GSPO (16.7/9.9). Furthermore, DCPO achieved an average 28% improvement in the nonzero advantage over GRPO in four models, doubled the training efficiency over DAPO, and significantly reduced the token clipping ratio by an order of magnitude compared to both GRPO and DAPO, while achieving superior performance. These results highlight DCPO's effectiveness in leveraging generated data more efficiently for reinforcement learning in large language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02333v2",
    "published_date": "2025-09-02 14:01:07 UTC",
    "updated_date": "2025-09-08 14:50:44 UTC"
  },
  {
    "arxiv_id": "2509.02330v1",
    "title": "ReCode: Improving LLM-based Code Repair with Fine-Grained Retrieval-Augmented Generation",
    "authors": [
      "Yicong Zhao",
      "Shisong Chen",
      "Jiacheng Zhang",
      "Zhixu Li"
    ],
    "abstract": "Recent advances in large language models (LLMs) have demonstrated impressive capabilities in code-related tasks, such as code generation and automated program repair. Despite their promising performance, most existing approaches for code repair suffer from high training costs or computationally expensive inference. Retrieval-augmented generation (RAG), with its efficient in-context learning paradigm, offers a more scalable alternative. However, conventional retrieval strategies, which are often based on holistic code-text embeddings, fail to capture the structural intricacies of code, resulting in suboptimal retrieval quality. To address the above limitations, we propose ReCode, a fine-grained retrieval-augmented in-context learning framework designed for accurate and efficient code repair. Specifically, ReCode introduces two key innovations: (1) an algorithm-aware retrieval strategy that narrows the search space using preliminary algorithm type predictions; and (2) a modular dual-encoder architecture that separately processes code and textual inputs, enabling fine-grained semantic matching between input and retrieved contexts. Furthermore, we propose RACodeBench, a new benchmark constructed from real-world user-submitted buggy code, which addresses the limitations of synthetic benchmarks and supports realistic evaluation. Experimental results on RACodeBench and competitive programming datasets demonstrate that ReCode achieves higher repair accuracy with significantly reduced inference cost, highlighting its practical value for real-world code repair scenarios.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by CIKM 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02330v1",
    "published_date": "2025-09-02 13:58:48 UTC",
    "updated_date": "2025-09-02 13:58:48 UTC"
  },
  {
    "arxiv_id": "2509.04505v1",
    "title": "The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management",
    "authors": [
      "Somtochukwu Azie",
      "Yiping Meng"
    ],
    "abstract": "The integration of Artificial Intelligence (AI) into construction project management (CPM) is accelerating, with Large Language Models (LLMs) emerging as accessible decision-support tools. This study aims to critically evaluate the ethical viability and reliability of LLMs when applied to the ethically sensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods research design was employed, involving the quantitative performance testing of two leading LLMs against twelve real-world ethical scenarios using a novel Ethical Decision Support Assessment Checklist (EDSAC), and qualitative analysis of semi-structured interviews with 12 industry experts to capture professional perceptions. The findings reveal that while LLMs demonstrate adequate performance in structured domains such as legal compliance, they exhibit significant deficiencies in handling contextual nuance, ensuring accountability, and providing transparent reasoning. Stakeholders expressed considerable reservations regarding the autonomous use of AI for ethical judgments, strongly advocating for robust human-in-the-loop oversight. To our knowledge, this is one of the first studies to empirically test the ethical reasoning of LLMs within the construction domain. It introduces the EDSAC framework as a replicable methodology and provides actionable recommendations, emphasising that LLMs are currently best positioned as decision-support aids rather than autonomous ethical agents.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "16 Pages",
    "pdf_url": "https://arxiv.org/pdf/2509.04505v1",
    "published_date": "2025-09-02 13:50:36 UTC",
    "updated_date": "2025-09-02 13:50:36 UTC"
  },
  {
    "arxiv_id": "2509.02308v1",
    "title": "Exploring Diffusion Models for Generative Forecasting of Financial Charts",
    "authors": [
      "Taegyeong Lee",
      "Jiwon Park",
      "Kyunga Bang",
      "Seunghyun Hwang",
      "Ung-Jin Jang"
    ],
    "abstract": "Recent advances in generative models have enabled significant progress in tasks such as generating and editing images from text, as well as creating videos from text prompts, and these methods are being applied across various fields. However, in the financial domain, there may still be a reliance on time-series data and a continued focus on transformer models, rather than on diverse applications of generative models. In this paper, we propose a novel approach that leverages text-to-image model by treating time-series data as a single image pattern, thereby enabling the prediction of stock price trends. Unlike prior methods that focus on learning and classifying chart patterns using architectures such as ResNet or ViT, we experiment with generating the next chart image from the current chart image and an instruction prompt using diffusion models. Furthermore, we introduce a simple method for evaluating the generated chart image against ground truth image. We highlight the potential of leveraging text-to-image generative models in the financial domain, and our findings motivate further research to address the current limitations and expand their applicability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02308v1",
    "published_date": "2025-09-02 13:31:10 UTC",
    "updated_date": "2025-09-02 13:31:10 UTC"
  },
  {
    "arxiv_id": "2509.06988v1",
    "title": "Frustratingly Easy Feature Reconstruction for Out-of-Distribution Detection",
    "authors": [
      "Yingsheng Wang",
      "Shuo Lu",
      "Jian Liang",
      "Aihua Zheng",
      "Ran He"
    ],
    "abstract": "Out-of-distribution (OOD) detection helps models identify data outside the training categories, crucial for security applications. While feature-based post-hoc methods address this by evaluating data differences in the feature space without changing network parameters, they often require access to training data, which may not be suitable for some data privacy scenarios. This may not be suitable in scenarios where data privacy protection is a concern. In this paper, we propose a simple yet effective post-hoc method, termed Classifier-based Feature Reconstruction (ClaFR), from the perspective of subspace projection. It first performs an orthogonal decomposition of the classifier's weights to extract the class-known subspace, then maps the original data features into this subspace to obtain new data representations. Subsequently, the OOD score is determined by calculating the feature reconstruction error of the data within the subspace. Compared to existing OOD detection algorithms, our method does not require access to training data while achieving leading performance on multiple OOD benchmarks. Our code is released at https://github.com/Aie0923/ClaFR.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to PRCV2025",
    "pdf_url": "https://arxiv.org/pdf/2509.06988v1",
    "published_date": "2025-09-02 13:24:40 UTC",
    "updated_date": "2025-09-02 13:24:40 UTC"
  },
  {
    "arxiv_id": "2509.02297v1",
    "title": "Re-evaluating LLM-based Heuristic Search: A Case Study on the 3D Packing Problem",
    "authors": [
      "Guorui Quan",
      "Mingfei Sun",
      "Manuel López-Ibáñez"
    ],
    "abstract": "The art of heuristic design has traditionally been a human pursuit. While Large Language Models (LLMs) can generate code for search heuristics, their application has largely been confined to adjusting simple functions within human-crafted frameworks, leaving their capacity for broader innovation an open question. To investigate this, we tasked an LLM with building a complete solver for the constrained 3D Packing Problem. Direct code generation quickly proved fragile, prompting us to introduce two supports: constraint scaffolding--prewritten constraint-checking code--and iterative self-correction--additional refinement cycles to repair bugs and produce a viable initial population. Notably, even within a vast search space in a greedy process, the LLM concentrated its efforts almost exclusively on refining the scoring function. This suggests that the emphasis on scoring functions in prior work may reflect not a principled strategy, but rather a natural limitation of LLM capabilities. The resulting heuristic was comparable to a human-designed greedy algorithm, and when its scoring function was integrated into a human-crafted metaheuristic, its performance rivaled established solvers, though its effectiveness waned as constraints tightened. Our findings highlight two major barriers to automated heuristic design with current LLMs: the engineering required to mitigate their fragility in complex reasoning tasks, and the influence of pretrained biases, which can prematurely narrow the search for novel solutions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02297v1",
    "published_date": "2025-09-02 13:18:47 UTC",
    "updated_date": "2025-09-02 13:18:47 UTC"
  },
  {
    "arxiv_id": "2509.02278v1",
    "title": "Think2Sing: Orchestrating Structured Motion Subtitles for Singing-Driven 3D Head Animation",
    "authors": [
      "Zikai Huang",
      "Yihan Zhou",
      "Xuemiao Xu",
      "Cheng Xu",
      "Xiaofen Xing",
      "Jing Qin",
      "Shengfeng He"
    ],
    "abstract": "Singing-driven 3D head animation is a challenging yet promising task with applications in virtual avatars, entertainment, and education. Unlike speech, singing involves richer emotional nuance, dynamic prosody, and lyric-based semantics, requiring the synthesis of fine-grained, temporally coherent facial motion. Existing speech-driven approaches often produce oversimplified, emotionally flat, and semantically inconsistent results, which are insufficient for singing animation. To address this, we propose Think2Sing, a diffusion-based framework that leverages pretrained large language models to generate semantically coherent and temporally consistent 3D head animations, conditioned on both lyrics and acoustics. A key innovation is the introduction of motion subtitles, an auxiliary semantic representation derived through a novel Singing Chain-of-Thought reasoning process combined with acoustic-guided retrieval. These subtitles contain precise timestamps and region-specific motion descriptions, serving as interpretable motion priors. We frame the task as a motion intensity prediction problem, enabling finer control over facial regions and improving the modeling of expressive motion. To support this, we create a multimodal singing dataset with synchronized video, acoustic descriptors, and motion subtitles, enabling diverse and expressive motion learning. Extensive experiments show that Think2Sing outperforms state-of-the-art methods in realism, expressiveness, and emotional fidelity, while also offering flexible, user-controllable animation editing.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02278v1",
    "published_date": "2025-09-02 12:59:27 UTC",
    "updated_date": "2025-09-02 12:59:27 UTC"
  },
  {
    "arxiv_id": "2509.10510v2",
    "title": "FireGNN: Neuro-Symbolic Graph Neural Networks with Trainable Fuzzy Rules for Interpretable Medical Image Classification",
    "authors": [
      "Prajit Sengupta",
      "Islem Rekik"
    ],
    "abstract": "Medical image classification requires not only high predictive performance but also interpretability to ensure clinical trust and adoption. Graph Neural Networks (GNNs) offer a powerful framework for modeling relational structures within datasets; however, standard GNNs often operate as black boxes, limiting transparency and usability, particularly in clinical settings. In this work, we present an interpretable graph-based learning framework named FireGNN that integrates trainable fuzzy rules into GNNs for medical image classification. These rules embed topological descriptors - node degree, clustering coefficient, and label agreement - using learnable thresholds and sharpness parameters to enable intrinsic symbolic reasoning. Additionally, we explore auxiliary self-supervised tasks (e.g., homophily prediction, similarity entropy) as a benchmark to evaluate the contribution of topological learning. Our fuzzy-rule-enhanced model achieves strong performance across five MedMNIST benchmarks and the synthetic dataset MorphoMNIST, while also generating interpretable rule-based explanations. To our knowledge, this is the first integration of trainable fuzzy rules within a GNN. Source Code: https://github.com/basiralab/FireGNN",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted at NeurIPS 2025 Conference (Workshop Track), San Diego, USA",
    "pdf_url": "https://arxiv.org/pdf/2509.10510v2",
    "published_date": "2025-09-02 12:57:54 UTC",
    "updated_date": "2025-10-09 10:43:33 UTC"
  },
  {
    "arxiv_id": "2509.02276v1",
    "title": "Rewarding Explainability in Drug Repurposing with Knowledge Graphs",
    "authors": [
      "Susana Nunes",
      "Samy Badreddine",
      "Catia Pesquita"
    ],
    "abstract": "Knowledge graphs (KGs) are powerful tools for modelling complex, multi-relational data and supporting hypothesis generation, particularly in applications like drug repurposing. However, for predictive methods to gain acceptance as credible scientific tools, they must ensure not only accuracy but also the capacity to offer meaningful scientific explanations. This paper presents a novel approach REx, for generating scientific explanations based in link prediction in knowledge graphs. It employs reward and policy mechanisms that consider desirable properties of scientific explanation to guide a reinforcement learning agent in the identification of explanatory paths within a KG. The approach further enriches explanatory paths with domain-specific ontologies, ensuring that the explanations are both insightful and grounded in established biomedical knowledge. We evaluate our approach in drug repurposing using three popular knowledge graph benchmarks. The results clearly demonstrate its ability to generate explanations that validate predictive insights against biomedical knowledge and that outperform the state-of-the-art approaches in predictive performance, establishing REx as a relevant contribution to advance AI-driven scientific discovery.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 4 figures, accepted at conference IJCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02276v1",
    "published_date": "2025-09-02 12:55:35 UTC",
    "updated_date": "2025-09-02 12:55:35 UTC"
  },
  {
    "arxiv_id": "2509.02274v1",
    "title": "Look: AI at Work! -- Analysing Key Aspects of AI-support at the Work Place",
    "authors": [
      "Stefan Schiffer",
      "Anna Milena Rothermel",
      "Alexander Ferrein",
      "Astrid Rosenthal-von der Pütten"
    ],
    "abstract": "In this paper we present an analysis of technological and psychological factors of applying artificial intelligence (AI) at the work place. We do so for a number of twelve application cases in the context of a project where AI is integrated at work places and in work systems of the future. From a technological point of view we mainly look at the areas of AI that the applications are concerned with. This allows to formulate recommendations in terms of what to look at in developing an AI application and what to pay attention to with regards to building AI literacy with different stakeholders using the system. This includes the importance of high-quality data for training learning-based systems as well as the integration of human expertise, especially with knowledge-based systems. In terms of the psychological factors we derive research questions to investigate in the development of AI supported work systems and to consider in future work, mainly concerned with topics such as acceptance, openness, and trust in an AI system.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "10 pages, accepted at the German Conference on Artificial Intelligence KI 2024 Workshop \"HuMaIn\"",
    "pdf_url": "https://arxiv.org/pdf/2509.02274v1",
    "published_date": "2025-09-02 12:51:23 UTC",
    "updated_date": "2025-09-02 12:51:23 UTC"
  },
  {
    "arxiv_id": "2509.02271v1",
    "title": "VariAntNet: Learning Decentralized Control of Multi-Agent Systems",
    "authors": [
      "Yigal Koifman",
      "Erez Koifman",
      "Eran Iceland",
      "Ariel Barel",
      "Alfred M. Bruckstein"
    ],
    "abstract": "A simple multi-agent system can be effectively utilized in disaster response applications, such as firefighting. Such a swarm is required to operate in complex environments with limited local sensing and no reliable inter-agent communication or centralized control. These simple robotic agents, also known as Ant Robots, are defined as anonymous agents that possess limited sensing capabilities, lack a shared coordinate system, and do not communicate explicitly with one another. A key challenge for simple swarms lies in maintaining cohesion and avoiding fragmentation despite limited-range sensing. Recent advances in machine learning offer effective solutions to some of the classical decentralized control challenges. We propose VariAntNet, a deep learning-based decentralized control model designed to facilitate agent swarming and collaborative task execution. VariAntNet includes geometric features extraction from unordered, variable-sized local observations. It incorporates a neural network architecture trained with a novel, differentiable, multi-objective, mathematically justified loss function that promotes swarm cohesiveness by utilizing the properties of the visibility graph Laplacian matrix. VariAntNet is demonstrated on the fundamental multi-agent gathering task, where agents with bearing-only and limited-range sensing must gather at some location. VariAntNet significantly outperforms an existing analytical solution, achieving more than double the convergence rate while maintaining high swarm connectivity across varying swarm sizes. While the analytical solution guarantees cohesion, it is often too slow in practice. In time-critical scenarios, such as emergency response operations where lives are at risk, slower analytical methods are impractical and justify the loss of some agents within the swarm. This paper presents and analyzes this trade-off in detail.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02271v1",
    "published_date": "2025-09-02 12:48:15 UTC",
    "updated_date": "2025-09-02 12:48:15 UTC"
  },
  {
    "arxiv_id": "2509.02258v1",
    "title": "An Epidemiological Knowledge Graph extracted from the World Health Organization's Disease Outbreak News",
    "authors": [
      "Sergio Consoli",
      "Pietro Coletti",
      "Peter V. Markov",
      "Lia Orfei",
      "Indaco Biazzo",
      "Lea Schuh",
      "Nicolas Stefanovitch",
      "Lorenzo Bertolini",
      "Mario Ceresa",
      "Nikolaos I. Stilianakis"
    ],
    "abstract": "The rapid evolution of artificial intelligence (AI), together with the increased availability of social media and news for epidemiological surveillance, are marking a pivotal moment in epidemiology and public health research. Leveraging the power of generative AI, we use an ensemble approach which incorporates multiple Large Language Models (LLMs) to extract valuable actionable epidemiological information from the World Health Organization (WHO) Disease Outbreak News (DONs). DONs is a collection of regular reports on global outbreaks curated by the WHO and the adopted decision-making processes to respond to them. The extracted information is made available in a daily-updated dataset and a knowledge graph, referred to as eKG, derived to provide a nuanced representation of the public health domain knowledge. We provide an overview of this new dataset and describe the structure of eKG, along with the services and tools used to access and utilize the data that we are building on top. These innovative data resources open altogether new opportunities for epidemiological research, and the analysis and surveillance of disease outbreaks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.02258v1",
    "published_date": "2025-09-02 12:34:31 UTC",
    "updated_date": "2025-09-02 12:34:31 UTC"
  },
  {
    "arxiv_id": "2509.02650v1",
    "title": "Can Media Act as a Soft Regulator of Safe AI Development? A Game Theoretical Analysis",
    "authors": [
      "Henrique Correia da Fonseca",
      "António Fernandes",
      "Zhao Song",
      "Theodor Cimpeanu",
      "Nataliya Balabanova",
      "Adeela Bashir",
      "Paolo Bova",
      "Alessio Buscemi",
      "Alessandro Di Stefano",
      "Manh Hong Duong",
      "Elias Fernandez Domingos",
      "Ndidi Bianca Ogbo",
      "Simon T. Powers",
      "Daniele Proverbio",
      "Zia Ush Shamszaman",
      "Fernando P. Santos",
      "The Anh Han",
      "Marcus Krellner"
    ],
    "abstract": "When developers of artificial intelligence (AI) products need to decide between profit and safety for the users, they likely choose profit. Untrustworthy AI technology must come packaged with tangible negative consequences. Here, we envisage those consequences as the loss of reputation caused by media coverage of their misdeeds, disseminated to the public. We explore whether media coverage has the potential to push AI creators into the production of safe products, enabling widespread adoption of AI technology. We created artificial populations of self-interested creators and users and studied them through the lens of evolutionary game theory. Our results reveal that media is indeed able to foster cooperation between creators and users, but not always. Cooperation does not evolve if the quality of the information provided by the media is not reliable enough, or if the costs of either accessing media or ensuring safety are too high. By shaping public perception and holding developers accountable, media emerges as a powerful soft regulator -- guiding AI safety even in the absence of formal government oversight.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "q-bio.PE"
    ],
    "primary_category": "cs.AI",
    "comment": "10 Pages, 7 Figures, accepted in the ALIFE 2025 Conference",
    "pdf_url": "https://arxiv.org/pdf/2509.02650v1",
    "published_date": "2025-09-02 12:13:34 UTC",
    "updated_date": "2025-09-02 12:13:34 UTC"
  },
  {
    "arxiv_id": "2509.02241v1",
    "title": "LLMs for LLMs: A Structured Prompting Methodology for Long Legal Documents",
    "authors": [
      "Strahinja Klem",
      "Noura Al Moubayed"
    ],
    "abstract": "The rise of Large Language Models (LLMs) has had a profoundly transformative effect on a number of fields and domains. However, their uptake in Law has proven more challenging due to the important issues of reliability and transparency. In this study, we present a structured prompting methodology as a viable alternative to the often expensive fine-tuning, with the capability of tacking long legal documents from the CUAD dataset on the task of information retrieval. Each document is first split into chunks via a system of chunking and augmentation, addressing the long document problem. Then, alongside an engineered prompt, the input is fed into QWEN-2 to produce a set of answers for each question. Finally, we tackle the resulting candidate selection problem with the introduction of the Distribution-based Localisation and Inverse Cardinality Weighting heuristics. This approach leverages a general purpose model to promote long term scalability, prompt engineering to increase reliability and the two heuristic strategies to reduce the impact of the black box effect. Whilst our model performs up to 9\\% better than the previously presented method, reaching state-of-the-art performance, it also highlights the limiting factor of current automatic evaluation metrics for question answering, serving as a call to action for future research. However, the chief aim of this work is to underscore the potential of structured prompt engineering as a useful, yet under-explored, tool in ensuring accountability and responsibility of AI in the legal domain, and beyond.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, 6 figures, 4 tables,",
    "pdf_url": "https://arxiv.org/pdf/2509.02241v1",
    "published_date": "2025-09-02 12:09:49 UTC",
    "updated_date": "2025-09-02 12:09:49 UTC"
  },
  {
    "arxiv_id": "2509.02237v1",
    "title": "Autoencoder-based non-intrusive model order reduction in continuum mechanics",
    "authors": [
      "Jannick Kehls",
      "Ellen Kuhl",
      "Tim Brepols",
      "Kevin Linka",
      "Hagen Holthusen"
    ],
    "abstract": "We propose a non-intrusive, Autoencoder-based framework for reduced-order modeling in continuum mechanics. Our method integrates three stages: (i) an unsupervised Autoencoder compresses high-dimensional finite element solutions into a compact latent space, (ii) a supervised regression network maps problem parameters to latent codes, and (iii) an end-to-end surrogate reconstructs full-field solutions directly from input parameters.\n  To overcome limitations of existing approaches, we propose two key extensions: a force-augmented variant that jointly predicts displacement fields and reaction forces at Neumann boundaries, and a multi-field architecture that enables coupled field predictions, such as in thermo-mechanical systems. The framework is validated on nonlinear benchmark problems involving heterogeneous composites, anisotropic elasticity with geometric variation, and thermo-mechanical coupling. Across all cases, it achieves accurate reconstructions of high-fidelity solutions while remaining fully non-intrusive.\n  These results highlight the potential of combining deep learning with dimensionality reduction to build efficient and extensible surrogate models. Our publicly available implementation provides a foundation for integrating data-driven model order reduction into uncertainty quantification, optimization, and digital twin applications.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02237v1",
    "published_date": "2025-09-02 12:05:00 UTC",
    "updated_date": "2025-09-02 12:05:00 UTC"
  },
  {
    "arxiv_id": "2509.02227v1",
    "title": "Application Of Large Language Models For The Extraction Of Information From Particle Accelerator Technical Documentation",
    "authors": [
      "Qing Dai",
      "Rasmus Ischebeck",
      "Maruisz Sapinski",
      "Adam Grycner"
    ],
    "abstract": "The large set of technical documentation of legacy accelerator systems, coupled with the retirement of experienced personnel, underscores the urgent need for efficient methods to preserve and transfer specialized knowledge. This paper explores the application of large language models (LLMs), to automate and enhance the extraction of information from particle accelerator technical documents. By exploiting LLMs, we aim to address the challenges of knowledge retention, enabling the retrieval of domain expertise embedded in legacy documentation. We present initial results of adapting LLMs to this specialized domain. Our evaluation demonstrates the effectiveness of LLMs in extracting, summarizing, and organizing knowledge, significantly reducing the risk of losing valuable insights as personnel retire. Furthermore, we discuss the limitations of current LLMs, such as interpretability and handling of rare domain-specific terms, and propose strategies for improvement. This work highlights the potential of LLMs to play a pivotal role in preserving institutional knowledge and ensuring continuity in highly specialized fields.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "physics.acc-ph"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02227v1",
    "published_date": "2025-09-02 11:45:01 UTC",
    "updated_date": "2025-09-02 11:45:01 UTC"
  },
  {
    "arxiv_id": "2509.02220v1",
    "title": "Towards Multi-Aspect Diversification of News Recommendations Using Neuro-Symbolic AI for Individual and Societal Benefit",
    "authors": [
      "Markus Reiter-Haas",
      "Elisabeth Lex"
    ],
    "abstract": "News recommendations are complex, with diversity playing a vital role. So far, existing literature predominantly focuses on specific aspects of news diversity, such as viewpoints. In this paper, we introduce multi-aspect diversification in four distinct recommendation modes and outline the nuanced challenges in diversifying lists, sequences, summaries, and interactions. Our proposed research direction combines symbolic and subsymbolic artificial intelligence, leveraging both knowledge graphs and rule learning. We plan to evaluate our models using user studies to not only capture behavior but also their perceived experience. Our vision to balance news consumption points to other positive effects for users (e.g., increased serendipity) and society (e.g., decreased polarization).",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted at INRA 2025: 13th International Workshop on News Recommendation and Analytics in Conjunction with ACM RecSys 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02220v1",
    "published_date": "2025-09-02 11:40:52 UTC",
    "updated_date": "2025-09-02 11:40:52 UTC"
  },
  {
    "arxiv_id": "2509.02217v1",
    "title": "ST-Hyper: Learning High-Order Dependencies Across Multiple Spatial-Temporal Scales for Multivariate Time Series Forecasting",
    "authors": [
      "Binqing Wu",
      "Jianlong Huang",
      "Zongjiang Shang",
      "Ling Chen"
    ],
    "abstract": "In multivariate time series (MTS) forecasting, many deep learning based methods have been proposed for modeling dependencies at multiple spatial (inter-variate) or temporal (intra-variate) scales. However, existing methods may fail to model dependencies across multiple spatial-temporal scales (ST-scales, i.e., scales that jointly consider spatial and temporal scopes). In this work, we propose ST-Hyper to model the high-order dependencies across multiple ST-scales through adaptive hypergraph modeling. Specifically, we introduce a Spatial-Temporal Pyramid Modeling (STPM) module to extract features at multiple ST-scales. Furthermore, we introduce an Adaptive Hypergraph Modeling (AHM) module that learns a sparse hypergraph to capture robust high-order dependencies among features. In addition, we interact with these features through tri-phase hypergraph propagation, which can comprehensively capture multi-scale spatial-temporal dynamics. Experimental results on six real-world MTS datasets demonstrate that ST-Hyper achieves the state-of-the-art performance, outperforming the best baselines with an average MAE reduction of 3.8\\% and 6.8\\% for long-term and short-term forecasting, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by CIKM 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02217v1",
    "published_date": "2025-09-02 11:37:08 UTC",
    "updated_date": "2025-09-02 11:37:08 UTC"
  },
  {
    "arxiv_id": "2509.02208v1",
    "title": "Baichuan-M2: Scaling Medical Capability with Large Verifier System",
    "authors": [
      "Baichuan-M2 Team",
      ":",
      "Chengfeng Dou",
      "Chong Liu",
      "Fan Yang",
      "Fei Li",
      "Jiyuan Jia",
      "Mingyang Chen",
      "Qiang Ju",
      "Shuai Wang",
      "Shunya Dang",
      "Tianpeng Li",
      "Xiangrong Zeng",
      "Yijie Zhou",
      "Chenzheng Zhu",
      "Da Pan",
      "Fei Deng",
      "Guangwei Ai",
      "Guosheng Dong",
      "Hongda Zhang",
      "Jinyang Tai",
      "Jixiang Hong",
      "Kai Lu",
      "Linzhuang Sun",
      "Peidong Guo",
      "Qian Ma",
      "Rihui Xin",
      "Shihui Yang",
      "Shusen Zhang",
      "Yichuan Mo",
      "Zheng Liang",
      "Zhishou Zhang",
      "Hengfu Cui",
      "Zuyi Zhu",
      "Xiaochuan Wang"
    ],
    "abstract": "As large language models (LLMs) advance in conversational and reasoning capabilities, their practical application in healthcare has become a critical research focus. However, there is a notable gap between the performance of medical LLMs on static benchmarks such as USMLE and their utility in real-world clinical decision-making. This discrepancy arises because traditional exams fail to capture the dynamic, interactive nature of medical consultations. To address this challenge, we introduce a novel dynamic verification framework that moves beyond static answer verifier, establishing a large-scale, high-fidelity interactive reinforcement learning system. Our framework comprises two key components: a Patient Simulator that creates realistic clinical environments using de-identified medical records, and a Clinical Rubrics Generator that dynamically produces multi-dimensional evaluation metrics. Building on this foundation, we develop Baichuan-M2, a 32B-parameter medical augmented reasoning model trained through a multi-stage reinforcement learning strategy with an improved Group Relative Policy Optimization (GRPO) algorithm. Evaluated on HealthBench, Baichuan-M2 outperforms all other open-source models and most advanced closed-source counterparts, achieving a score above 32 on the challenging HealthBench Hard benchmark-previously exceeded only by GPT-5. Our work demonstrates that robust dynamic verifier system is essential for aligning LLM capabilities with practical clinical applications, establishing a new Pareto front in the performance-parameter trade-off for medical AI deployment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Baichuan-M2 Technical Report",
    "pdf_url": "https://arxiv.org/pdf/2509.02208v1",
    "published_date": "2025-09-02 11:23:35 UTC",
    "updated_date": "2025-09-02 11:23:35 UTC"
  },
  {
    "arxiv_id": "2509.02196v4",
    "title": "Beyond Ensembles: Simulating All-Atom Protein Dynamics in a Learned Latent Space",
    "authors": [
      "Aditya Sengar",
      "Jiying Zhang",
      "Pierre Vandergheynst",
      "Patrick Barth"
    ],
    "abstract": "Simulating the long-timescale dynamics of biomolecules is a central challenge in computational science. While enhanced sampling methods can accelerate these simulations, they rely on pre-defined collective variables that are often difficult to identify, restricting their ability to model complex switching mechanisms between metastable states. A recent generative model, LD-FPG, demonstrated that this problem could be bypassed by learning to sample the static equilibrium ensemble as all-atom deformations from a reference structure, establishing a powerful method for all-atom ensemble generation. However, while this approach successfully captures a system's probable conformations, it does not model the temporal evolution between them. We introduce the Graph Latent Dynamics Propagator (GLDP), a modular component for simulating dynamics within the learned latent space of LD-FPG. We then compare three classes of propagators: (i) score-guided Langevin dynamics, (ii) Koopman-based linear operators, and (iii) autoregressive neural networks. Within a unified encoder-propagator-decoder framework, we evaluate long-horizon stability, backbone and side-chain ensemble fidelity, and temporal kinetics via TICA. Benchmarks on systems ranging from small peptides to mixed-topology proteins and large GPCRs reveal that autoregressive neural networks deliver the most robust long rollouts and coherent physical timescales; score-guided Langevin best recovers side-chain thermodynamics when the score is well learned; and Koopman provides an interpretable, lightweight baseline that tends to damp fluctuations. These results clarify the trade-offs among propagators and offer practical guidance for latent-space simulators of all-atom protein dynamics.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02196v4",
    "published_date": "2025-09-02 11:09:06 UTC",
    "updated_date": "2025-11-27 18:33:23 UTC"
  },
  {
    "arxiv_id": "2509.06987v1",
    "title": "FusWay: Multimodal hybrid fusion approach. Application to Railway Defect Detection",
    "authors": [
      "Alexey Zhukov",
      "Jenny Benois-Pineau",
      "Amira Youssef",
      "Akka Zemmari",
      "Mohamed Mosbah",
      "Virginie Taillandier"
    ],
    "abstract": "Multimodal fusion is a multimedia technique that has become popular in the wide range of tasks where image information is accompanied by a signal/audio. The latter may not convey highly semantic information, such as speech or music, but some measures such as audio signal recorded by mics in the goal to detect rail structure elements or defects. While classical detection approaches such as You Only Look Once (YOLO) family detectors can be efficiently deployed for defect detection on the image modality, the single modality approaches remain limited. They yield an overdetection in case of the appearance similar to normal structural elements. The paper proposes a new multimodal fusion architecture built on the basis of domain rules with YOLO and Vision transformer backbones. It integrates YOLOv8n for rapid object detection with a Vision Transformer (ViT) to combine feature maps extracted from multiple layers (7, 16, and 19) and synthesised audio representations for two defect classes: rail Rupture and Surface defect. Fusion is performed between audio and image. Experimental evaluation on a real-world railway dataset demonstrates that our multimodal fusion improves precision and overall accuracy by 0.2 points compared to the vision-only approach. Student's unpaired t-test also confirms statistical significance of differences in the mean accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06987v1",
    "published_date": "2025-09-02 10:45:51 UTC",
    "updated_date": "2025-09-02 10:45:51 UTC"
  },
  {
    "arxiv_id": "2509.02175v2",
    "title": "Understanding Space Is Rocket Science -- Only Top Reasoning Models Can Solve Spatial Understanding Tasks",
    "authors": [
      "Nils Hoehing",
      "Mayug Maniparambil",
      "Ellen Rushe",
      "Noel E. O'Connor",
      "Anthony Ventresque"
    ],
    "abstract": "We propose RocketScience, an open-source contrastive VLM benchmark that tests for spatial relation understanding. It is comprised of entirely new real-world image-text pairs covering mostly relative spatial understanding and the order of objects. The benchmark is designed to be very easy for humans and hard for the current generation of VLMs, and this is empirically verified. Our results show a striking lack of spatial relation understanding in open source and frontier commercial VLMs and a surprisingly high performance of reasoning models. Additionally, we perform a disentanglement analysis to separate the contributions of object localization and spatial reasoning in chain-of-thought-based models and find that the performance on the benchmark is bottlenecked by spatial reasoning and not object localization capabilities. We release the dataset with a CC-BY-4.0 license and make the evaluation code available at: https://github.com/nilshoehing/rocketscience",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02175v2",
    "published_date": "2025-09-02 10:32:58 UTC",
    "updated_date": "2025-09-04 16:38:44 UTC"
  },
  {
    "arxiv_id": "2509.02170v2",
    "title": "Avoidance Decoding for Diverse Multi-Branch Story Generation",
    "authors": [
      "Kyeongman Park",
      "Nakyeong Yang",
      "Kyomin Jung"
    ],
    "abstract": "Large Language Models (LLMs) often generate repetitive and monotonous outputs, especially in tasks like story generation, due to limited creative diversity when given the same input prompt. To address this challenge, we propose a novel decoding strategy, Avoidance Decoding, that modifies token logits by penalizing similarity to previously generated outputs, thereby encouraging more diverse multi-branch stories. This penalty adaptively balances two similarity measures: (1) Concept-level Similarity Penalty, which is prioritized in early stages to diversify initial story concepts, and (2) Narrative-level Similarity Penalty, which is increasingly emphasized later to ensure natural yet diverse plot development. Notably, our method achieves up to 2.6 times higher output diversity and reduces repetition by an average of 30% compared to strong baselines, while effectively mitigating text degeneration. Furthermore, we reveal that our method activates a broader range of neurons, demonstrating that it leverages the model's intrinsic creativity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02170v2",
    "published_date": "2025-09-02 10:22:46 UTC",
    "updated_date": "2025-09-03 10:39:50 UTC"
  },
  {
    "arxiv_id": "2509.02163v1",
    "title": "Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety",
    "authors": [
      "Wenxiao Zhang",
      "Xiangrui Kong",
      "Conan Dewitt",
      "Thomas Bräunl",
      "Jin B. Hong"
    ],
    "abstract": "Integrating large language models (LLMs) into robotic systems has revolutionised embodied artificial intelligence, enabling advanced decision-making and adaptability. However, ensuring reliability, encompassing both security against adversarial attacks and safety in complex environments, remains a critical challenge. To address this, we propose a unified framework that mitigates prompt injection attacks while enforcing operational safety through robust validation mechanisms. Our approach combines prompt assembling, state management, and safety validation, evaluated using both performance and security metrics. Experiments show a 30.8% improvement under injection attacks and up to a 325% improvement in complex environment settings under adversarial conditions compared to baseline scenarios. This work bridges the gap between safety and security in LLM-based robotic systems, offering actionable insights for deploying reliable LLM-integrated mobile robots in real-world settings. The framework is open-sourced with simulation and physical deployment demos at https://llmeyesim.vercel.app/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02163v1",
    "published_date": "2025-09-02 10:14:28 UTC",
    "updated_date": "2025-09-02 10:14:28 UTC"
  },
  {
    "arxiv_id": "2509.02160v2",
    "title": "Meta-Pretraining for Zero-Shot Cross-Lingual Named Entity Recognition in Low-Resource Philippine Languages",
    "authors": [
      "David Demitri Africa",
      "Suchir Salhan",
      "Yuval Weiss",
      "Paula Buttery",
      "Richard Diehl Martinez"
    ],
    "abstract": "Named-entity recognition (NER) in low-resource languages is usually tackled by finetuning very large multilingual LMs, an option that is often infeasible in memory- or latency-constrained settings. We ask whether small decoder LMs can be pretrained so that they adapt quickly and transfer zero-shot to languages unseen during pretraining. To this end we replace part of the autoregressive objective with first-order model-agnostic meta-learning (MAML). Tagalog and Cebuano are typologically similar yet structurally different in their actor/non-actor voice systems, and hence serve as a challenging test-bed. Across four model sizes (11 M - 570 M) MAML lifts zero-shot micro-F1 by 2-6 pp under head-only tuning and 1-3 pp after full tuning, while cutting convergence time by up to 8%. Gains are largest for single-token person entities that co-occur with Tagalog case particles si/ni, highlighting the importance of surface anchors.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted (poster) to 5th Workshop on Multilingual Representation Learning at EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02160v2",
    "published_date": "2025-09-02 10:09:51 UTC",
    "updated_date": "2025-10-04 10:54:49 UTC"
  },
  {
    "arxiv_id": "2509.02154v1",
    "title": "Conditional-$t^3$VAE: Equitable Latent Space Allocation for Fair Generation",
    "authors": [
      "Aymene Mohammed Bouayed",
      "Samuel Deslauriers-Gauthier",
      "Adrian Iaccovelli",
      "David Naccache"
    ],
    "abstract": "Variational Autoencoders (VAEs) with global priors mirror the training set's class frequency in latent space, underrepresenting tail classes and reducing generative fairness on imbalanced datasets. While $t^3$VAE improves robustness via heavy-tailed Student's t-distribution priors, it still allocates latent volume proportionally to the class frequency.In this work, we address this issue by explicitly enforcing equitable latent space allocation across classes. To this end, we propose Conditional-$t^3$VAE, which defines a per-class \\mbox{Student's t} joint prior over latent and output variables, preventing dominance by majority classes. Our model is optimized using a closed-form objective derived from the $γ$-power divergence. Moreover, for class-balanced generation, we derive an equal-weight latent mixture of Student's t-distributions. On SVHN-LT, CIFAR100-LT, and CelebA, Conditional-$t^3$VAE consistently achieves lower FID scores than both $t^3$VAE and Gaussian-based VAE baselines, particularly under severe class imbalance. In per-class F1 evaluations, Conditional-$t^3$VAE also outperforms the conditional Gaussian VAE across all highly imbalanced settings. While Gaussian-based models remain competitive under mild imbalance ratio ($ρ\\lesssim 3$), our approach substantially improves generative fairness and diversity in more extreme regimes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02154v1",
    "published_date": "2025-09-02 10:03:10 UTC",
    "updated_date": "2025-09-02 10:03:10 UTC"
  },
  {
    "arxiv_id": "2509.02144v1",
    "title": "A Theoretical Framework of the Processes of Change in Psychotherapy Delivered by Artificial Agents",
    "authors": [
      "Arthur Bran Herbener",
      "Malene Flensborg Damholdt"
    ],
    "abstract": "The question of whether artificial agents (e.g., chatbots and social robots) can replace human therapists has received notable attention following the recent launch of large language models. However, little is known about the processes of change in psychotherapy delivered by artificial agents. To facilitate hypothesis development and stimulate scientific debate, the present article offers the first theoretical framework of the processes of change in psychotherapy delivered by artificial agents. The theoretical framework rests upon a conceptual analysis of what active ingredients may be inherently linked to the presence of human therapists. We propose that human therapists' ontological status as human beings and sociocultural status as socially sanctioned healthcare professionals play crucial roles in promoting treatment outcomes. In the absence of the ontological and sociocultural status of human therapists, we propose what we coin the genuineness gap and credibility gap can emerge and undermine key processes of change in psychotherapy. Based on these propositions, we propose avenues for scientific investigations and practical applications aimed at leveraging the strengths of artificial agents and human therapists respectively. We also highlight the intricate agentic nature of artificial agents and discuss how this complicates endeavors to establish universally applicable propositions regarding the processes of change in these interventions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Submitted on 19 March 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02144v1",
    "published_date": "2025-09-02 09:45:40 UTC",
    "updated_date": "2025-09-02 09:45:40 UTC"
  },
  {
    "arxiv_id": "2509.02134v1",
    "title": "Learning Social Heuristics for Human-Aware Path Planning",
    "authors": [
      "Andrea Eirale",
      "Matteo Leonetti",
      "Marcello Chiaberge"
    ],
    "abstract": "Social robotic navigation has been at the center of numerous studies in recent years. Most of the research has focused on driving the robotic agent along obstacle-free trajectories, respecting social distances from humans, and predicting their movements to optimize navigation. However, in order to really be socially accepted, the robots must be able to attain certain social norms that cannot arise from conventional navigation, but require a dedicated learning process. We propose Heuristic Planning with Learned Social Value (HPLSV), a method to learn a value function encapsulating the cost of social navigation, and use it as an additional heuristic in heuristic-search path planning. In this preliminary work, we apply the methodology to the common social scenario of joining a queue of people, with the intention of generalizing to further human activities.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02134v1",
    "published_date": "2025-09-02 09:36:11 UTC",
    "updated_date": "2025-09-02 09:36:11 UTC"
  },
  {
    "arxiv_id": "2509.02113v1",
    "title": "HiGraph: A Large-Scale Hierarchical Graph Dataset for Malware Analysis",
    "authors": [
      "Han Chen",
      "Hanchen Wang",
      "Hongmei Chen",
      "Ying Zhang",
      "Lu Qin",
      "Wenjie Zhang"
    ],
    "abstract": "The advancement of graph-based malware analysis is critically limited by the absence of large-scale datasets that capture the inherent hierarchical structure of software. Existing methods often oversimplify programs into single level graphs, failing to model the crucial semantic relationship between high-level functional interactions and low-level instruction logic. To bridge this gap, we introduce \\dataset, the largest public hierarchical graph dataset for malware analysis, comprising over \\textbf{200M} Control Flow Graphs (CFGs) nested within \\textbf{595K} Function Call Graphs (FCGs). This two-level representation preserves structural semantics essential for building robust detectors resilient to code obfuscation and malware evolution. We demonstrate HiGraph's utility through a large-scale analysis that reveals distinct structural properties of benign and malicious software, establishing it as a foundational benchmark for the community. The dataset and tools are publicly available at https://higraph.org.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02113v1",
    "published_date": "2025-09-02 09:10:52 UTC",
    "updated_date": "2025-09-02 09:10:52 UTC"
  },
  {
    "arxiv_id": "2509.02101v1",
    "title": "SALAD -- Semantics-Aware Logical Anomaly Detection",
    "authors": [
      "Matic Fučka",
      "Vitjan Zavrtanik",
      "Danijel Skočaj"
    ],
    "abstract": "Recent surface anomaly detection methods excel at identifying structural anomalies, such as dents and scratches, but struggle with logical anomalies, such as irregular or missing object components. The best-performing logical anomaly detection approaches rely on aggregated pretrained features or handcrafted descriptors (most often derived from composition maps), which discard spatial and semantic information, leading to suboptimal performance. We propose SALAD, a semantics-aware discriminative logical anomaly detection method that incorporates a newly proposed composition branch to explicitly model the distribution of object composition maps, consequently learning important semantic relationships. Additionally, we introduce a novel procedure for extracting composition maps that requires no hand-made labels or category-specific information, in contrast to previous methods. By effectively modelling the composition map distribution, SALAD significantly improves upon state-of-the-art methods on the standard benchmark for logical anomaly detection, MVTec LOCO, achieving an impressive image-level AUROC of 96.1%. Code: https://github.com/MaticFuc/SALAD",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02101v1",
    "published_date": "2025-09-02 08:58:39 UTC",
    "updated_date": "2025-09-02 08:58:39 UTC"
  },
  {
    "arxiv_id": "2509.02097v4",
    "title": "JudgeAgent: Beyond Static Benchmarks for Knowledge-Driven and Dynamic LLM Evaluation",
    "authors": [
      "Zhichao Shi",
      "Xuhui Jiang",
      "Chengjin Xu",
      "Cangli Yao",
      "Shengjia Ma",
      "Yinghan Shen",
      "Zixuan Li",
      "Jian Guo",
      "Yuanzhuo Wang"
    ],
    "abstract": "Current evaluation methods for large language models (LLMs) primarily rely on static benchmarks, presenting two major challenges: limited knowledge coverage and fixed difficulties that mismatch with the evaluated LLMs. These limitations lead to superficial assessments of LLM knowledge, thereby impeding the targeted model optimizations. To bridge this gap, we propose JudgeAgent, a knowledge-driven and dynamic evaluation framework for LLMs. To address the challenge of limited knowledge coverage, JudgeAgent leverages LLM agents equipped with context graphs to traverse knowledge structures systematically for question generation. Furthermore, to mitigate data contamination and difficulty mismatch, it adopts a difficulty-adaptive and multi-turn interview mechanism. Thereby, JudgeAgent can achieve comprehensive evaluations and facilitate more effective improvement of LLMs. Empirical results demonstrate that JudgeAgent enables more comprehensive evaluations and facilitates effective model iterations, highlighting the potential of this knowledge-driven and dynamic evaluation paradigm. The source code is available on https://github.com/DataArcTech/JudgeAgent.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02097v4",
    "published_date": "2025-09-02 08:52:16 UTC",
    "updated_date": "2026-01-15 04:01:33 UTC"
  },
  {
    "arxiv_id": "2509.02093v2",
    "title": "Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization",
    "authors": [
      "Juhyeon Lee",
      "Wonduk Seo",
      "Hyunjin An",
      "Seunghyun Lee",
      "Yi Bu"
    ],
    "abstract": "Automatic prompt optimization has recently emerged as a strategy for improving the quality of prompts used in Large Language Models (LLMs), with the goal of generating more accurate and useful responses. However, most prior work focuses on direct prompt refinement or model fine-tuning, overlooking the potential of leveraging LLMs' inherent reasoning capability to learn from contrasting examples. In this paper, we present Contrastive Reasoning Prompt Optimization (CRPO), a novel framework that formulates prompt optimization as a retrieval-augmented reasoning process. Our approach retrieves top k reference prompt-response pairs from the HelpSteer2 dataset, an open source collection where each response is annotated for helpfulness, correctness, coherence, complexity, and verbosity, and constructs two complementary optimization paradigms: (1) tiered contrastive reasoning, where the LLM compares high-, medium-, and low-quality exemplars (both prompts and responses) to refine its own generation through reflective reasoning, and (2) multi-metric contrastive reasoning, where the LLM analyzes the best exemplars along each evaluation dimension and integrates their strengths into an optimized prompt. By explicitly contrasting high and low quality exemplars, CRPO enables the model to deduce why certain prompts succeed while others fail, thereby achieving more robust and interpretable optimization. Experimental results on the HelpSteer2 benchmark demonstrate that CRPO significantly outperforms baselines. Our findings highlight the promise of contrastive, retrieval-augmented reasoning for advancing automatic prompt optimization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2509.02093v2",
    "published_date": "2025-09-02 08:45:29 UTC",
    "updated_date": "2025-10-03 13:39:44 UTC"
  },
  {
    "arxiv_id": "2509.02089v1",
    "title": "AGI as Second Being: The Structural-Generative Ontology of Intelligence",
    "authors": [
      "Maijunxian Wang",
      "Ran Ji"
    ],
    "abstract": "Artificial intelligence is often measured by the range of tasks it can perform. Yet wide ability without depth remains only an imitation. This paper proposes a Structural-Generative Ontology of Intelligence: true intelligence exists only when a system can generate new structures, coordinate them into reasons, and sustain its identity over time. These three conditions -- generativity, coordination, and sustaining -- define the depth that underlies real intelligence. Current AI systems, however broad in function, remain surface simulations because they lack this depth. Breadth is not the source of intelligence but the growth that follows from depth. If future systems were to meet these conditions, they would no longer be mere tools, but could be seen as a possible Second Being, standing alongside yet distinct from human existence.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02089v1",
    "published_date": "2025-09-02 08:38:52 UTC",
    "updated_date": "2025-09-02 08:38:52 UTC"
  },
  {
    "arxiv_id": "2509.02076v1",
    "title": "Forecasting Future DDoS Attacks Using Long Short Term Memory (LSTM) Model",
    "authors": [
      "Kong Mun Yeen",
      "Rafidah Md Noor",
      "Wahidah Md Shah",
      "Aslinda Hassan",
      "Muhammad Umair Munir"
    ],
    "abstract": "This paper forecasts future Distributed Denial of Service (DDoS) attacks using deep learning models. Although several studies address forecasting DDoS attacks, they remain relatively limited compared to detection-focused research. By studying the current trends and forecasting based on newer and updated datasets, mitigation plans against the attacks can be planned and formulated. The methodology used in this research work conforms to the Cross Industry Standard Process for Data Mining (CRISP-DM) model.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "18 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.02076v1",
    "published_date": "2025-09-02 08:26:51 UTC",
    "updated_date": "2025-09-02 08:26:51 UTC"
  },
  {
    "arxiv_id": "2509.02075v1",
    "title": "How Instruction-Tuning Imparts Length Control: A Cross-Lingual Mechanistic Analysis",
    "authors": [
      "Elisabetta Rocchetti",
      "Alfio Ferrara"
    ],
    "abstract": "Adhering to explicit length constraints, such as generating text with a precise word count, remains a significant challenge for Large Language Models (LLMs). This study aims at investigating the differences between foundation models and their instruction-tuned counterparts, on length-controlled text generation in English and Italian. We analyze both performance and internal component contributions using Cumulative Weighted Attribution, a metric derived from Direct Logit Attribution. Our findings reveal that instruction-tuning substantially improves length control, primarily by specializing components in deeper model layers. Specifically, attention heads in later layers of IT models show increasingly positive contributions, particularly in English. In Italian, while attention contributions are more attenuated, final-layer MLPs exhibit a stronger positive role, suggesting a compensatory mechanism. These results indicate that instruction-tuning reconfigures later layers for task adherence, with component-level strategies potentially adapting to linguistic context.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02075v1",
    "published_date": "2025-09-02 08:26:18 UTC",
    "updated_date": "2025-09-02 08:26:18 UTC"
  },
  {
    "arxiv_id": "2509.02055v2",
    "title": "Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance",
    "authors": [
      "Yang Zhang",
      "Chenwei Wang",
      "Ouyang Lu",
      "Yuan Zhao",
      "Yunfei Ge",
      "Zhenglong Sun",
      "Xiu Li",
      "Chi Zhang",
      "Chenjia Bai",
      "Xuelong Li"
    ],
    "abstract": "Vision-Language-Action (VLA) models pre-trained on large, diverse datasets show remarkable potential for general-purpose robotic manipulation. However, a primary bottleneck remains in adapting these models to downstream tasks, especially when the robot's embodiment or the task itself differs from the pre-training data. This discrepancy leads to a significant mismatch in action distributions, demanding extensive data and compute for effective fine-tuning. To address this challenge, we introduce \\textbf{Align-Then-stEer (\\texttt{ATE})}, a novel, data-efficient, and plug-and-play adaptation framework. \\texttt{ATE} first aligns disparate action spaces by constructing a unified latent space, where a variational autoencoder constrained by reverse KL divergence embeds adaptation actions into modes of the pre-training action latent distribution. Subsequently, it steers the diffusion- or flow-based VLA's generation process during fine-tuning via a guidance mechanism that pushes the model's output distribution towards the target domain. We conduct extensive experiments on cross-embodiment and cross-task manipulation in both simulation and real world. Compared to direct fine-tuning of representative VLAs, our method improves the average multi-task success rate by up to \\textbf{9.8\\%} in simulation and achieves a striking \\textbf{32\\% success rate gain} in a real-world cross-embodiment setting. Our work presents a general and lightweight solution that greatly enhances the practicality of deploying VLA models to new robotic platforms and tasks.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "The first three authors contributed equally",
    "pdf_url": "https://arxiv.org/pdf/2509.02055v2",
    "published_date": "2025-09-02 07:51:59 UTC",
    "updated_date": "2025-09-05 06:24:50 UTC"
  },
  {
    "arxiv_id": "2509.02053v1",
    "title": "Generative KI für TA",
    "authors": [
      "Wolfgang Eppler",
      "Reinhard Heil"
    ],
    "abstract": "Many scientists use generative AI in their scientific work. People working in technology assessment (TA) are no exception. TA's approach to generative AI is twofold: on the one hand, generative AI is used for TA work, and on the other hand, generative AI is the subject of TA research. After briefly outlining the phenomenon of generative AI and formulating requirements for its use in TA, the following article discusses in detail the structural causes of the problems associated with it. Although generative AI is constantly being further developed, the structurally induced risks remain. The article concludes with proposed solutions and brief notes on their feasibility, as well as some examples of the use of generative AI in TA work.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Written in German. To appear in Proceedings of NTA11 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.02053v1",
    "published_date": "2025-09-02 07:47:14 UTC",
    "updated_date": "2025-09-02 07:47:14 UTC"
  },
  {
    "arxiv_id": "2509.02048v1",
    "title": "Privacy-Utility Trade-off in Data Publication: A Bilevel Optimization Framework with Curvature-Guided Perturbation",
    "authors": [
      "Yi Yin",
      "Guangquan Zhang",
      "Hua Zuo",
      "Jie Lu"
    ],
    "abstract": "Machine learning models require datasets for effective training, but directly sharing raw data poses significant privacy risk such as membership inference attacks (MIA). To mitigate the risk, privacy-preserving techniques such as data perturbation, generalization, and synthetic data generation are commonly utilized. However, these methods often degrade data accuracy, specificity, and diversity, limiting the performance of downstream tasks and thus reducing data utility. Therefore, striking an optimal balance between privacy preservation and data utility remains a critical challenge.\n  To address this issue, we introduce a novel bilevel optimization framework for the publication of private datasets, where the upper-level task focuses on data utility and the lower-level task focuses on data privacy. In the upper-level task, a discriminator guides the generation process to ensure that perturbed latent variables are mapped to high-quality samples, maintaining fidelity for downstream tasks. In the lower-level task, our framework employs local extrinsic curvature on the data manifold as a quantitative measure of individual vulnerability to MIA, providing a geometric foundation for targeted privacy protection. By perturbing samples toward low-curvature regions, our method effectively suppresses distinctive feature combinations that are vulnerable to MIA. Through alternating optimization of both objectives, we achieve a synergistic balance between privacy and utility. Extensive experimental evaluations demonstrate that our method not only enhances resistance to MIA in downstream tasks but also surpasses existing methods in terms of sample quality and diversity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02048v1",
    "published_date": "2025-09-02 07:44:21 UTC",
    "updated_date": "2025-09-02 07:44:21 UTC"
  },
  {
    "arxiv_id": "2509.02046v2",
    "title": "Fantastic Pretraining Optimizers and Where to Find Them",
    "authors": [
      "Kaiyue Wen",
      "David Hall",
      "Tengyu Ma",
      "Percy Liang"
    ],
    "abstract": "AdamW has long been the dominant optimizer in language model pretraining, despite numerous claims that alternative optimizers offer 1.4 to 2x speedup. We posit that two methodological shortcomings have obscured fair comparisons and hindered practical adoption: (i) unequal hyperparameter tuning and (ii) limited or misleading evaluation setups. To address these two issues, we conduct a systematic study of ten deep learning optimizers across four model scales (0.1B-1.2B parameters) and data-to-model ratios (1-8x the Chinchilla optimum). We find that fair and informative comparisons require rigorous hyperparameter tuning and evaluations across a range of model scales and data-to-model ratios, performed at the end of training. First, optimal hyperparameters for one optimizer may be suboptimal for another, making blind hyperparameter transfer unfair. Second, the actual speedup of many proposed optimizers over well-tuned baselines is lower than claimed and decreases with model size to only 1.1x for 1.2B parameter models. Thirdly, comparing intermediate checkpoints before reaching the target training budgets can be misleading, as rankings between two optimizers can flip during training due to learning rate decay. Through our thorough investigation, we find that all the fastest optimizers such as Muon and Soap, use matrices as preconditioners -- multiplying gradients with matrices rather than entry-wise scalars. However, the speedup of matrix-based optimizers is inversely proportional to model scale, decreasing from 1.4x over AdamW for 0.1B parameter models to merely 1.1x for 1.2B parameter models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "108 pages, 8 figures, reproducible runs available at https://wandb.ai/marin-community/optimizer-scaling",
    "pdf_url": "https://arxiv.org/pdf/2509.02046v2",
    "published_date": "2025-09-02 07:43:22 UTC",
    "updated_date": "2025-09-04 19:22:04 UTC"
  },
  {
    "arxiv_id": "2509.02036v1",
    "title": "DeepSeek performs better than other Large Language Models in Dental Cases",
    "authors": [
      "Hexian Zhang",
      "Xinyu Yan",
      "Yanqi Yang",
      "Lijian Jin",
      "Ping Yang",
      "Junwen Wang"
    ],
    "abstract": "Large language models (LLMs) hold transformative potential in healthcare, yet their capacity to interpret longitudinal patient narratives remains inadequately explored. Dentistry, with its rich repository of structured clinical data, presents a unique opportunity to rigorously assess LLMs' reasoning abilities. While several commercial LLMs already exist, DeepSeek, a model that gained significant attention earlier this year, has also joined the competition. This study evaluated four state-of-the-art LLMs (GPT-4o, Gemini 2.0 Flash, Copilot, and DeepSeek V3) on their ability to analyze longitudinal dental case vignettes through open-ended clinical tasks. Using 34 standardized longitudinal periodontal cases (comprising 258 question-answer pairs), we assessed model performance via automated metrics and blinded evaluations by licensed dentists. DeepSeek emerged as the top performer, demonstrating superior faithfulness (median score = 0.528 vs. 0.367-0.457) and higher expert ratings (median = 4.5/5 vs. 4.0/5), without significantly compromising readability. Our study positions DeepSeek as the leading LLM for case analysis, endorses its integration as an adjunct tool in both medical education and research, and highlights its potential as a domain-specific agent.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Abstract word count: 171; Total word count: 3130; Total number of tables: 2; Total number of figures: 3; Number of references: 32",
    "pdf_url": "https://arxiv.org/pdf/2509.02036v1",
    "published_date": "2025-09-02 07:26:20 UTC",
    "updated_date": "2025-09-02 07:26:20 UTC"
  },
  {
    "arxiv_id": "2509.02031v1",
    "title": "Synesthesia of Machines (SoM)-Based Task-Driven MIMO System for Image Transmission",
    "authors": [
      "Sijiang Li",
      "Rongqing Zhang",
      "Xiang Cheng",
      "Jian Tang"
    ],
    "abstract": "To support cooperative perception (CP) of networked mobile agents in dynamic scenarios, the efficient and robust transmission of sensory data is a critical challenge. Deep learning-based joint source-channel coding (JSCC) has demonstrated promising results for image transmission under adverse channel conditions, outperforming traditional rule-based codecs. While recent works have explored to combine JSCC with the widely adopted multiple-input multiple-output (MIMO) technology, these approaches are still limited to the discrete-time analog transmission (DTAT) model and simple tasks. Given the limited performance of existing MIMO JSCC schemes in supporting complex CP tasks for networked mobile agents with digital MIMO communication systems, this paper presents a Synesthesia of Machines (SoM)-based task-driven MIMO system for image transmission, referred to as SoM-MIMO. By leveraging the structural properties of the feature pyramid for perceptual tasks and the channel properties of the closed-loop MIMO communication system, SoM-MIMO enables efficient and robust digital MIMO transmission of images. Experimental results have shown that compared with two JSCC baseline schemes, our approach achieves average mAP improvements of 6.30 and 10.48 across all SNR levels, while maintaining identical communication overhead.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02031v1",
    "published_date": "2025-09-02 07:19:02 UTC",
    "updated_date": "2025-09-02 07:19:02 UTC"
  },
  {
    "arxiv_id": "2509.02029v1",
    "title": "Fake & Square: Training Self-Supervised Vision Transformers with Synthetic Data and Synthetic Hard Negatives",
    "authors": [
      "Nikolaos Giakoumoglou",
      "Andreas Floros",
      "Kleanthis Marios Papadopoulos",
      "Tania Stathaki"
    ],
    "abstract": "This paper does not introduce a new method per se. Instead, we build on existing self-supervised learning approaches for vision, drawing inspiration from the adage \"fake it till you make it\". While contrastive self-supervised learning has achieved remarkable success, it typically relies on vast amounts of real-world data and carefully curated hard negatives. To explore alternatives to these requirements, we investigate two forms of \"faking it\" in vision transformers. First, we study the potential of generative models for unsupervised representation learning, leveraging synthetic data to augment sample diversity. Second, we examine the feasibility of generating synthetic hard negatives in the representation space, creating diverse and challenging contrasts. Our framework - dubbed Syn2Co - combines both approaches and evaluates whether synthetically enhanced training can lead to more robust and transferable visual representations on DeiT-S and Swin-T architectures. Our findings highlight the promise and limitations of synthetic data in self-supervised learning, offering insights for future work in this direction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICCV 2025 Workshop LIMIT",
    "pdf_url": "https://arxiv.org/pdf/2509.02029v1",
    "published_date": "2025-09-02 07:17:46 UTC",
    "updated_date": "2025-09-02 07:17:46 UTC"
  },
  {
    "arxiv_id": "2509.02024v1",
    "title": "Unsupervised Training of Vision Transformers with Synthetic Negatives",
    "authors": [
      "Nikolaos Giakoumoglou",
      "Andreas Floros",
      "Kleanthis Marios Papadopoulos",
      "Tania Stathaki"
    ],
    "abstract": "This paper does not introduce a novel method per se. Instead, we address the neglected potential of hard negative samples in self-supervised learning. Previous works explored synthetic hard negatives but rarely in the context of vision transformers. We build on this observation and integrate synthetic hard negatives to improve vision transformer representation learning. This simple yet effective technique notably improves the discriminative power of learned representations. Our experiments show performance improvements for both DeiT-S and Swin-T architectures.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025 Workshop VisCon",
    "pdf_url": "https://arxiv.org/pdf/2509.02024v1",
    "published_date": "2025-09-02 07:14:21 UTC",
    "updated_date": "2025-09-02 07:14:21 UTC"
  },
  {
    "arxiv_id": "2509.02642v1",
    "title": "BioMD: All-atom Generative Model for Biomolecular Dynamics Simulation",
    "authors": [
      "Bin Feng",
      "Jiying Zhang",
      "Xinni Zhang",
      "Zijing Liu",
      "Yu Li"
    ],
    "abstract": "Molecular dynamics (MD) simulations are essential tools in computational chemistry and drug discovery, offering crucial insights into dynamic molecular behavior. However, their utility is significantly limited by substantial computational costs, which severely restrict accessible timescales for many biologically relevant processes. Despite the encouraging performance of existing machine learning (ML) methods, they struggle to generate extended biomolecular system trajectories, primarily due to the lack of MD datasets and the large computational demands of modeling long historical trajectories. Here, we introduce BioMD, the first all-atom generative model to simulate long-timescale protein-ligand dynamics using a hierarchical framework of forecasting and interpolation. We demonstrate the effectiveness and versatility of BioMD on the DD-13M (ligand unbinding) and MISATO datasets. For both datasets, BioMD generates highly realistic conformations, showing high physical plausibility and low reconstruction errors. Besides, BioMD successfully generates ligand unbinding paths for 97.1% of the protein-ligand systems within ten attempts, demonstrating its ability to explore critical unbinding pathways. Collectively, these results establish BioMD as a tool for simulating complex biomolecular processes, offering broad applicability for computational chemistry and drug discovery.",
    "categories": [
      "physics.chem-ph",
      "cs.AI"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02642v1",
    "published_date": "2025-09-02 07:12:50 UTC",
    "updated_date": "2025-09-02 07:12:50 UTC"
  },
  {
    "arxiv_id": "2509.04504v1",
    "title": "Behavioral Fingerprinting of Large Language Models",
    "authors": [
      "Zehua Pei",
      "Hui-Ling Zhen",
      "Ying Zhang",
      "Zhiyuan Yang",
      "Xing Li",
      "Xianzhi Yu",
      "Mingxuan Yuan",
      "Bei Yu"
    ],
    "abstract": "Current benchmarks for Large Language Models (LLMs) primarily focus on performance metrics, often failing to capture the nuanced behavioral characteristics that differentiate them. This paper introduces a novel ``Behavioral Fingerprinting'' framework designed to move beyond traditional evaluation by creating a multi-faceted profile of a model's intrinsic cognitive and interactive styles. Using a curated \\textit{Diagnostic Prompt Suite} and an innovative, automated evaluation pipeline where a powerful LLM acts as an impartial judge, we analyze eighteen models across capability tiers. Our results reveal a critical divergence in the LLM landscape: while core capabilities like abstract and causal reasoning are converging among top models, alignment-related behaviors such as sycophancy and semantic robustness vary dramatically. We further document a cross-model default persona clustering (ISTJ/ESTJ) that likely reflects common alignment incentives. Taken together, this suggests that a model's interactive nature is not an emergent property of its scale or reasoning power, but a direct consequence of specific, and highly variable, developer alignment strategies. Our framework provides a reproducible and scalable methodology for uncovering these deep behavioral differences. Project: https://github.com/JarvisPei/Behavioral-Fingerprinting",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to 1st Open Conference on AI Agents for Science (agents4science 2025)",
    "pdf_url": "https://arxiv.org/pdf/2509.04504v1",
    "published_date": "2025-09-02 07:03:20 UTC",
    "updated_date": "2025-09-02 07:03:20 UTC"
  },
  {
    "arxiv_id": "2509.02017v1",
    "title": "Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs",
    "authors": [
      "Yuhao Wang",
      "Junwei Pan",
      "Xinhang Li",
      "Maolin Wang",
      "Yuan Wang",
      "Yue Liu",
      "Dapeng Liu",
      "Jie Jiang",
      "Xiangyu Zhao"
    ],
    "abstract": "Sequential recommendation (SR) aims to capture users' dynamic interests and sequential patterns based on their historical interactions. Recently, the powerful capabilities of large language models (LLMs) have driven their adoption in SR. However, we identify two critical challenges in existing LLM-based SR methods: 1) embedding collapse when incorporating pre-trained collaborative embeddings and 2) catastrophic forgetting of quantized embeddings when utilizing semantic IDs. These issues dampen the model scalability and lead to suboptimal recommendation performance. Therefore, based on LLMs like Llama3-8B-instruct, we introduce a novel SR framework named MME-SID, which integrates multimodal embeddings and quantized embeddings to mitigate embedding collapse. Additionally, we propose a Multimodal Residual Quantized Variational Autoencoder (MM-RQ-VAE) with maximum mean discrepancy as the reconstruction loss and contrastive learning for alignment, which effectively preserve intra-modal distance information and capture inter-modal correlations, respectively. To further alleviate catastrophic forgetting, we initialize the model with the trained multimodal code embeddings. Finally, we fine-tune the LLM efficiently using LoRA in a multimodal frequency-aware fusion manner. Extensive experiments on three public datasets validate the superior performance of MME-SID thanks to its capability to mitigate embedding collapse and catastrophic forgetting. The implementation code and datasets are publicly available for reproduction: https://github.com/Applied-Machine-Learning-Lab/MME-SID.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "CIKM 2025 Full Research Paper",
    "pdf_url": "https://arxiv.org/pdf/2509.02017v1",
    "published_date": "2025-09-02 07:02:29 UTC",
    "updated_date": "2025-09-02 07:02:29 UTC"
  },
  {
    "arxiv_id": "2509.02007v1",
    "title": "mFARM: Towards Multi-Faceted Fairness Assessment based on HARMs in Clinical Decision Support",
    "authors": [
      "Shreyash Adappanavar",
      "Krithi Shailya",
      "Gokul S Krishnan",
      "Sriraam Natarajan",
      "Balaraman Ravindran"
    ],
    "abstract": "The deployment of Large Language Models (LLMs) in high-stakes medical settings poses a critical AI alignment challenge, as models can inherit and amplify societal biases, leading to significant disparities. Existing fairness evaluation methods fall short in these contexts as they typically use simplistic metrics that overlook the multi-dimensional nature of medical harms. This also promotes models that are fair only because they are clinically inert, defaulting to safe but potentially inaccurate outputs. To address this gap, our contributions are mainly two-fold: first, we construct two large-scale, controlled benchmarks (ED-Triage and Opioid Analgesic Recommendation) from MIMIC-IV, comprising over 50,000 prompts with twelve race x gender variants and three context tiers. Second, we propose a multi-metric framework - Multi-faceted Fairness Assessment based on hARMs ($mFARM$) to audit fairness for three distinct dimensions of disparity (Allocational, Stability, and Latent) and aggregate them into an $mFARM$ score. We also present an aggregated Fairness-Accuracy Balance (FAB) score to benchmark and observe trade-offs between fairness and prediction accuracy. We empirically evaluate four open-source LLMs (Mistral-7B, BioMistral-7B, Qwen-2.5-7B, Bio-LLaMA3-8B) and their finetuned versions under quantization and context variations. Our findings showcase that the proposed $mFARM$ metrics capture subtle biases more effectively under various settings. We find that most models maintain robust performance in terms of $mFARM$ score across varying levels of quantization but deteriorate significantly when the context is reduced. Our benchmarks and evaluation code are publicly released to enhance research in aligned AI for healthcare.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02007v1",
    "published_date": "2025-09-02 06:47:57 UTC",
    "updated_date": "2025-09-02 06:47:57 UTC"
  },
  {
    "arxiv_id": "2509.01997v1",
    "title": "ACA-Net: Future Graph Learning for Logistical Demand-Supply Forecasting",
    "authors": [
      "Jiacheng Shi",
      "Haibin Wei",
      "Jiang Wang",
      "Xiaowei Xu",
      "Longzhi Du",
      "Taixu Jiang"
    ],
    "abstract": "Logistical demand-supply forecasting that evaluates the alignment between projected supply and anticipated demand, is essential for the efficiency and quality of on-demand food delivery platforms and serves as a key indicator for scheduling decisions. Future order distribution information, which reflects the distribution of orders in on-demand food delivery, is crucial for the performance of logistical demand-supply forecasting. Current studies utilize spatial-temporal analysis methods to model future order distribution information from serious time slices. However, learning future order distribution in online delivery platform is a time-series-insensitive problem with strong randomness. These approaches often struggle to effectively capture this information while remaining efficient. This paper proposes an innovative spatiotemporal learning model that utilizes only two graphs (ongoing and global) to learn future order distribution information, achieving superior performance compared to traditional spatial-temporal long-series methods. The main contributions are as follows: (1) The introduction of ongoing and global graphs in logistical demand-supply pressure forecasting compared to traditional long time series significantly enhances forecasting performance. (2) An innovative graph learning network framework using adaptive future graph learning and innovative cross attention mechanism (ACA-Net) is proposed to extract future order distribution information, effectively learning a robust future graph that substantially improves logistical demand-supply pressure forecasting outcomes. (3) The effectiveness of the proposed method is validated in real-world production environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, DASFAA2025 conference full paper",
    "pdf_url": "https://arxiv.org/pdf/2509.01997v1",
    "published_date": "2025-09-02 06:20:41 UTC",
    "updated_date": "2025-09-02 06:20:41 UTC"
  },
  {
    "arxiv_id": "2509.01986v2",
    "title": "Draw-In-Mind: Rebalancing Designer-Painter Roles in Unified Multimodal Models Benefits Image Editing",
    "authors": [
      "Ziyun Zeng",
      "Junhao Zhang",
      "Wei Li",
      "Mike Zheng Shou"
    ],
    "abstract": "In recent years, integrating multimodal understanding and generation into a single unified model has emerged as a promising paradigm. While this approach achieves strong results in text-to-image (T2I) generation, it still struggles with precise image editing. We attribute this limitation to an imbalanced division of responsibilities. The understanding module primarily functions as a translator that encodes user instructions into semantic conditions, while the generation module must simultaneously act as designer and painter, inferring the original layout, identifying the target editing region, and rendering the new content. This imbalance is counterintuitive because the understanding module is typically trained with several times more data on complex reasoning tasks than the generation module. To address this issue, we introduce Draw-In-Mind (DIM), a dataset comprising two complementary subsets: (i) DIM-T2I, containing 14M long-context image-text pairs to enhance complex instruction comprehension; and (ii) DIM-Edit, consisting of 233K chain-of-thought imaginations generated by GPT-4o, serving as explicit design blueprints for image edits. We connect a frozen Qwen2.5-VL-3B with a trainable SANA1.5-1.6B via a lightweight two-layer MLP, and train it on the proposed DIM dataset, resulting in DIM-4.6B-T2I/Edit. Despite its modest parameter scale, DIM-4.6B-Edit achieves SOTA or competitive performance on the ImgEdit and GEdit-Bench benchmarks, outperforming much larger models such as UniWorld-V1 and Step1X-Edit. These findings demonstrate that explicitly assigning the design responsibility to the understanding module provides significant benefits for image editing. Our dataset and models are available at https://github.com/showlab/DIM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Tech Report",
    "pdf_url": "https://arxiv.org/pdf/2509.01986v2",
    "published_date": "2025-09-02 06:06:52 UTC",
    "updated_date": "2025-09-26 06:30:36 UTC"
  },
  {
    "arxiv_id": "2509.10509v1",
    "title": "The Anti-Ouroboros Effect: Emergent Resilience in Large Language Models from Recursive Selective Feedback",
    "authors": [
      "Sai Teja Reddy Adapala"
    ],
    "abstract": "The stability of recursively trained large language models (LLMs) is a foundational problem for AI safety. Prevailing theory predicts model collapse, a progressive degradation when models are trained on their own output. We challenge this narrative by introducing a selective feedback mechanism. Contrary to expectation, instead of merely slowing decay, our experiments provide strong evidence that this pressure reverses it, inducing a statistically significant performance improvement in a Gemma 2B model on a complex summarization task. We name this phenomenon the Anti-Ouroboros Effect. We contrast this with a foundational experiment using a simple classifier, where the theoretical degenerative loop was validated, highlighting the unique dynamics of high-dimensional models. Our findings establish that systemic resilience can be an emergent property of LLMs under simple selection pressure, suggesting a powerful and scalable principle for developing safer and more robust AI systems. Across five generations, a quality-filtered condition improved by 6.6% in ROUGE-L F1 score, whereas an unfiltered control degraded by 3.5% and a random-filter control degraded by 4.2%",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 3 figures, 2 tables. Code is available at: https://github.com/imsaitejareddy/ouroboros-effect-experiment",
    "pdf_url": "https://arxiv.org/pdf/2509.10509v1",
    "published_date": "2025-09-02 05:46:28 UTC",
    "updated_date": "2025-09-02 05:46:28 UTC"
  },
  {
    "arxiv_id": "2509.10508v1",
    "title": "CAR-BRAINet: Sub-6GHz Aided Spatial Adaptive Beam Prediction with Multi Head Attention for Heterogeneous Vehicular Networks",
    "authors": [
      "Aathira G Menon",
      "Prabu Krishnan",
      "Shyam Lal"
    ],
    "abstract": "Heterogeneous Vehicular Networks (HetVNets) play a key role by stacking different communication technologies such as sub-6GHz, mm-wave and DSRC to meet diverse connectivity needs of 5G/B5G vehicular networks. HetVNet helps address the humongous user demands-but maintaining a steady connection in a highly mobile, real-world conditions remain a challenge. Though there has been ample of studies on beam prediction models a dedicated solution for HetVNets is sparsely explored. Hence, it is the need of the hour to develop a reliable beam prediction solution, specifically for HetVNets. This paper introduces a lightweight deep learning-based solution termed-\"CAR-BRAINet\" which consists of convolutional neural networks with a powerful multi-head attention (MHA) mechanism. Existing literature on beam prediction is largely studied under a limited, idealised vehicular scenario, often overlooking the real-time complexities and intricacies of vehicular networks. Therefore, this study aims to mimic the complexities of a real-time driving scenario by incorporating key factors such as prominent MAC protocols-3GPP-C-V2X and IEEE 802.11BD, the effect of Doppler shifts under high velocity and varying distance and SNR levels into three high-quality dynamic datasets pertaining to urban, rural and highway vehicular networks. CAR-BRAINet performs effectively across all the vehicular scenarios, demonstrating precise beam prediction with minimal beam overhead and a steady improvement of 17.9422% on the spectral efficiency over the existing methods. Thus, this study justifies the effectiveness of CAR-BRAINet in complex HetVNets, offering promising performance without relying on the location angle and antenna dimensions of the mobile users, and thereby reducing the redundant sensor-latency.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.NI",
    "comment": "10 pages, 10 figures, 6 tables, (to be published)",
    "pdf_url": "https://arxiv.org/pdf/2509.10508v1",
    "published_date": "2025-09-02 05:17:23 UTC",
    "updated_date": "2025-09-02 05:17:23 UTC"
  },
  {
    "arxiv_id": "2509.01964v1",
    "title": "2D Gaussian Splatting with Semantic Alignment for Image Inpainting",
    "authors": [
      "Hongyu Li",
      "Chaofeng Chen",
      "Xiaoming Li",
      "Guangming Lu"
    ],
    "abstract": "Gaussian Splatting (GS), a recent technique for converting discrete points into continuous spatial representations, has shown promising results in 3D scene modeling and 2D image super-resolution. In this paper, we explore its untapped potential for image inpainting, which demands both locally coherent pixel synthesis and globally consistent semantic restoration. We propose the first image inpainting framework based on 2D Gaussian Splatting, which encodes incomplete images into a continuous field of 2D Gaussian splat coefficients and reconstructs the final image via a differentiable rasterization process. The continuous rendering paradigm of GS inherently promotes pixel-level coherence in the inpainted results. To improve efficiency and scalability, we introduce a patch-wise rasterization strategy that reduces memory overhead and accelerates inference. For global semantic consistency, we incorporate features from a pretrained DINO model. We observe that DINO's global features are naturally robust to small missing regions and can be effectively adapted to guide semantic alignment in large-mask scenarios, ensuring that the inpainted content remains contextually consistent with the surrounding scene. Extensive experiments on standard benchmarks demonstrate that our method achieves competitive performance in both quantitative metrics and perceptual quality, establishing a new direction for applying Gaussian Splatting to 2D image processing.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01964v1",
    "published_date": "2025-09-02 05:12:52 UTC",
    "updated_date": "2025-09-02 05:12:52 UTC"
  },
  {
    "arxiv_id": "2509.01959v1",
    "title": "Structure-aware Contrastive Learning for Diagram Understanding of Multimodal Models",
    "authors": [
      "Hiroshi Sasaki"
    ],
    "abstract": "Multimodal models, such as the Contrastive Language-Image Pre-training (CLIP) model, have demonstrated remarkable success in aligning visual and linguistic representations. However, these models exhibit limitations when applied to specialised visual domains, such as diagrams, which encode structured, symbolic information distinct from that of natural imagery.\n  In this paper, we introduce a novel training paradigm explicitly designed to enhance the comprehension of diagrammatic images within vision-language models. Our approach uses ``hard'' samples for our proposed contrastive learning that incorporates two specialised loss functions that leverage the inherent structural properties of diagrams. By integrating these objectives into model training, our method enables models to develop a more structured and semantically coherent understanding of diagrammatic content.\n  We empirically validate our approach on a benchmark dataset of flowcharts, as a representative class of diagrammatic imagery, demonstrating substantial improvements over standard CLIP and conventional hard negative CLIP learning paradigms for both image-text matching and visual question answering tasks. Our findings underscore the significance of tailored training strategies for specialised tasks and contribute to advancing diagrammatic understanding within the broader landscape of vision-language integration.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.01959v1",
    "published_date": "2025-09-02 05:02:23 UTC",
    "updated_date": "2025-09-02 05:02:23 UTC"
  },
  {
    "arxiv_id": "2509.04502v1",
    "title": "VaccineRAG: Boosting Multimodal Large Language Models' Immunity to Harmful RAG Samples",
    "authors": [
      "Qixin Sun",
      "Ziqin Wang",
      "Hengyuan Zhao",
      "Yilin Li",
      "Kaiyou Song",
      "Linjiang Huang",
      "Xiaolin Hu",
      "Qingpei Guo",
      "Si Liu"
    ],
    "abstract": "Retrieval Augmented Generation enhances the response accuracy of Large Language Models (LLMs) by integrating retrieval and generation modules with external knowledge, demonstrating particular strength in real-time queries and Visual Question Answering tasks. However, the effectiveness of RAG is frequently hindered by the precision of the retriever: many retrieved samples fed into the generation phase are irrelevant or misleading, posing a critical bottleneck to LLMs' performance. To address this challenge, we introduce VaccineRAG, a novel Chain-of-Thought-based retrieval-augmented generation dataset. On one hand, VaccineRAG employs a benchmark to evaluate models using data with varying positive/negative sample ratios, systematically exposing inherent weaknesses in current LLMs. On the other hand, it enhances models' sample-discrimination capabilities by prompting LLMs to generate explicit Chain-of-Thought (CoT) analysis for each sample before producing final answers. Furthermore, to enhance the model's ability to learn long-sequence complex CoT content, we propose Partial-GRPO. By modeling the outputs of LLMs as multiple components rather than a single whole, our model can make more informed preference selections for complex sequences, thereby enhancing its capacity to learn complex CoT. Comprehensive evaluations and ablation studies on VaccineRAG validate the effectiveness of the proposed scheme. The code and dataset will be publicly released soon.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.04502v1",
    "published_date": "2025-09-02 04:49:51 UTC",
    "updated_date": "2025-09-02 04:49:51 UTC"
  },
  {
    "arxiv_id": "2509.01943v1",
    "title": "A Continuous Encoding-Based Representation for Efficient Multi-Fidelity Multi-Objective Neural Architecture Search",
    "authors": [
      "Zhao Wei",
      "Chin Chun Ooi",
      "Yew-Soon Ong"
    ],
    "abstract": "Neural architecture search (NAS) is an attractive approach to automate the design of optimized architectures but is constrained by high computational budget, especially when optimizing for multiple, important conflicting objectives. To address this, an adaptive Co-Kriging-assisted multi-fidelity multi-objective NAS algorithm is proposed to further reduce the computational cost of NAS by incorporating a clustering-based local multi-fidelity infill sampling strategy, enabling efficient exploration of the search space for faster convergence. This algorithm is further accelerated by the use of a novel continuous encoding method to represent the connections of nodes in each cell within a generalized cell-based U-Net backbone, thereby decreasing the search dimension (number of variables). Results indicate that the proposed NAS algorithm outperforms previously published state-of-the-art methods under limited computational budget on three numerical benchmarks, a 2D Darcy flow regression problem and a CHASE_DB1 biomedical image segmentation problem. The proposed method is subsequently used to create a wind velocity regression model with application in urban modelling, with the found model able to achieve good prediction with less computational complexity. Further analysis revealed that the NAS algorithm independently identified principles undergirding superior U-Net architectures in other literature, such as the importance of allowing each cell to incorporate information from prior cells.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01943v1",
    "published_date": "2025-09-02 04:31:02 UTC",
    "updated_date": "2025-09-02 04:31:02 UTC"
  },
  {
    "arxiv_id": "2509.01938v3",
    "title": "EigenBench: A Comparative Behavioral Measure of Value Alignment",
    "authors": [
      "Jonathn Chang",
      "Leonhard Piff",
      "Suvadip Sana",
      "Jasmine X. Li",
      "Lionel Levine"
    ],
    "abstract": "Aligning AI with human values is a pressing unsolved problem. To address the lack of quantitative metrics for value alignment, we propose EigenBench: a black-box method for comparatively benchmarking language models' values. Given an ensemble of models, a constitution describing a value system, and a dataset of scenarios, our method returns a vector of scores quantifying each model's alignment to the given constitution. To produce these scores, each model judges the outputs of other models across many scenarios, and these judgments are aggregated with EigenTrust (Kamvar et al., 2003), yielding scores that reflect a weighted consensus judgment of the whole ensemble. EigenBench uses no ground truth labels, as it is designed to quantify subjective traits for which reasonable judges may disagree on the correct label. Hence, to validate our method, we collect human judgments on the same ensemble of models and show that EigenBench's judgments align closely with those of human evaluators. We further demonstrate that EigenBench can recover model rankings on the GPQA benchmark without access to objective labels, supporting its viability as a framework for evaluating subjective values for which no ground truths exist.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01938v3",
    "published_date": "2025-09-02 04:14:26 UTC",
    "updated_date": "2025-09-26 01:58:19 UTC"
  },
  {
    "arxiv_id": "2509.04501v2",
    "title": "Understanding Reinforcement Learning for Model Training, and future directions with GRAPE",
    "authors": [
      "Rohit Patel"
    ],
    "abstract": "This paper provides a self-contained, from-scratch, exposition of key algorithms for instruction tuning of models: SFT, Rejection Sampling, REINFORCE, Trust Region Policy Optimization (TRPO), Proximal Policy Optimization (PPO), Group Relative Policy Optimization (GRPO), and Direct Preference Optimization (DPO). Explanations of these algorithms often assume prior knowledge, lack critical details, and/or are overly generalized and complex. Here, each method is discussed and developed step by step using simplified and explicit notation focused on LLMs, aiming to eliminate ambiguity and provide a clear and intuitive understanding of the concepts. By minimizing detours into the broader RL literature and connecting concepts to LLMs, we eliminate superfluous abstractions and reduce cognitive overhead. Following this exposition, we provide a literature review of new techniques and approaches beyond those detailed. Finally, new ideas for research and exploration in the form of GRAPE (Generalized Relative Advantage Policy Evolution) are presented.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "35 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2509.04501v2",
    "published_date": "2025-09-02 03:59:40 UTC",
    "updated_date": "2025-10-21 15:29:40 UTC"
  },
  {
    "arxiv_id": "2509.01920v3",
    "title": "Dynamic Speculative Agent Planning",
    "authors": [
      "Yilin Guan",
      "Qingfeng Lan",
      "Sun Fei",
      "Dujian Ding",
      "Devang Acharya",
      "Chi Wang",
      "William Yang Wang",
      "Wenyue Hua"
    ],
    "abstract": "Despite their remarkable success in complex tasks propelling widespread adoption, large language-model-based agents still face critical deployment challenges due to prohibitive latency and inference costs. While recent work has explored various methods to accelerate inference, existing approaches suffer from significant limitations: they either fail to preserve performance fidelity, require extensive offline training of router modules, or incur excessive operational costs. Moreover, they provide minimal user control over the tradeoff between acceleration and other performance metrics. To address these gaps, we introduce Dynamic Speculative Planning (DSP), an asynchronous online reinforcement learning framework that provides lossless acceleration with substantially reduced costs without requiring additional pre-deployment preparation. DSP explicitly optimizes a joint objective balancing end-to-end latency against dollar cost, allowing practitioners to adjust a single parameter that steers the system toward faster responses, cheaper operation, or any point along this continuum. Experiments on two standard agent benchmarks demonstrate that DSP achieves comparable efficiency to the fastest lossless acceleration method while reducing total cost by 30% and unnecessary cost up to 60%. Our code and data are available through https://github.com/guanyilin428/Dynamic-Speculative-Planning.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 11 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.01920v3",
    "published_date": "2025-09-02 03:34:36 UTC",
    "updated_date": "2025-09-21 01:40:25 UTC"
  },
  {
    "arxiv_id": "2509.06986v1",
    "title": "CellPainTR: Generalizable Representation Learning for Cross-Dataset Cell Painting Analysis",
    "authors": [
      "Cedric Caruzzo",
      "Jong Chul Ye"
    ],
    "abstract": "Large-scale biological discovery requires integrating massive, heterogeneous datasets like those from the JUMP Cell Painting consortium, but technical batch effects and a lack of generalizable models remain critical roadblocks. To address this, we introduce CellPainTR, a Transformer-based architecture designed to learn foundational representations of cellular morphology that are robust to batch effects. Unlike traditional methods that require retraining on new data, CellPainTR's design, featuring source-specific context tokens, allows for effective out-of-distribution (OOD) generalization to entirely unseen datasets without fine-tuning. We validate CellPainTR on the large-scale JUMP dataset, where it outperforms established methods like ComBat and Harmony in both batch integration and biological signal preservation. Critically, we demonstrate its robustness through a challenging OOD task on the unseen Bray et al. dataset, where it maintains high performance despite significant domain and feature shifts. Our work represents a significant step towards creating truly foundational models for image-based profiling, enabling more reliable and scalable cross-study biological analysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 4 figures. Code available at: https://github.com/CellPainTR/CellPainTR",
    "pdf_url": "https://arxiv.org/pdf/2509.06986v1",
    "published_date": "2025-09-02 03:30:07 UTC",
    "updated_date": "2025-09-02 03:30:07 UTC"
  },
  {
    "arxiv_id": "2509.03353v1",
    "title": "Fair Resource Allocation for Fleet Intelligence",
    "authors": [
      "Oguzhan Baser",
      "Kaan Kale",
      "Po-han Li",
      "Sandeep Chinchali"
    ],
    "abstract": "Resource allocation is crucial for the performance optimization of cloud-assisted multi-agent intelligence. Traditional methods often overlook agents' diverse computational capabilities and complex operating environments, leading to inefficient and unfair resource distribution. To address this, we open-sourced Fair-Synergy, an algorithmic framework that utilizes the concave relationship between the agents' accuracy and the system resources to ensure fair resource allocation across fleet intelligence. We extend traditional allocation approaches to encompass a multidimensional machine learning utility landscape defined by model parameters, training data volume, and task complexity. We evaluate Fair-Synergy with advanced vision and language models such as BERT, VGG16, MobileNet, and ResNets on datasets including MNIST, CIFAR-10, CIFAR-100, BDD, and GLUE. We demonstrate that Fair-Synergy outperforms standard benchmarks by up to 25% in multi-agent inference and 11% in multi-agent learning settings. Also, we explore how the level of fairness affects the least advantaged, most advantaged, and average agents, providing insights for equitable fleet intelligence.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted for presentation at the 2025 IEEE Global Communications Conference (GLOBECOM 2025)",
    "pdf_url": "https://arxiv.org/pdf/2509.03353v1",
    "published_date": "2025-09-02 03:20:41 UTC",
    "updated_date": "2025-09-02 03:20:41 UTC"
  },
  {
    "arxiv_id": "2509.01914v1",
    "title": "How Real Is AI Tutoring? Comparing Simulated and Human Dialogues in One-on-One Instruction",
    "authors": [
      "Ruijia Li",
      "Yuan-Hao Jiang",
      "Jiatong Wang",
      "Bo Jiang"
    ],
    "abstract": "Heuristic and scaffolded teacher-student dialogues are widely regarded as critical for fostering students' higher-order thinking and deep learning. However, large language models (LLMs) currently face challenges in generating pedagogically rich interactions. This study systematically investigates the structural and behavioral differences between AI-simulated and authentic human tutoring dialogues. We conducted a quantitative comparison using an Initiation-Response-Feedback (IRF) coding scheme and Epistemic Network Analysis (ENA). The results show that human dialogues are significantly superior to their AI counterparts in utterance length, as well as in questioning (I-Q) and general feedback (F-F) behaviors. More importantly, ENA results reveal a fundamental divergence in interactional patterns: human dialogues are more cognitively guided and diverse, centered around a \"question-factual response-feedback\" teaching loop that clearly reflects pedagogical guidance and student-driven thinking; in contrast, simulated dialogues exhibit a pattern of structural simplification and behavioral convergence, revolving around an \"explanation-simplistic response\" loop that is essentially a simple information transfer between the teacher and student. These findings illuminate key limitations in current AI-generated tutoring and provide empirical guidance for designing and evaluating more pedagogically effective generative educational dialogue systems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Proceedings of the 33rd International Conference on Computers in Education (ICCE 2025). Asia-Pacific Society for Computers in Education",
    "pdf_url": "https://arxiv.org/pdf/2509.01914v1",
    "published_date": "2025-09-02 03:18:39 UTC",
    "updated_date": "2025-09-02 03:18:39 UTC"
  },
  {
    "arxiv_id": "2509.01910v2",
    "title": "Towards Interpretable Geo-localization: a Concept-Aware Global Image-GPS Alignment Framework",
    "authors": [
      "Furong Jia",
      "Lanxin Liu",
      "Ce Hou",
      "Fan Zhang",
      "Xinyan Liu",
      "Yu Liu"
    ],
    "abstract": "Worldwide geo-localization involves determining the exact geographic location of images captured globally, typically guided by geographic cues such as climate, landmarks, and architectural styles. Despite advancements in geo-localization models like GeoCLIP, which leverages images and location alignment via contrastive learning for accurate predictions, the interpretability of these models remains insufficiently explored. Current concept-based interpretability methods fail to align effectively with Geo-alignment image-location embedding objectives, resulting in suboptimal interpretability and performance. To address this gap, we propose a novel framework integrating global geo-localization with concept bottlenecks. Our method inserts a Concept-Aware Alignment Module that jointly projects image and location embeddings onto a shared bank of geographic concepts (e.g., tropical climate, mountain, cathedral) and minimizes a concept-level loss, enhancing alignment in a concept-specific subspace and enabling robust interpretability. To our knowledge, this is the first work to introduce interpretability into geo-localization. Extensive experiments demonstrate that our approach surpasses GeoCLIP in geo-localization accuracy and boosts performance across diverse geospatial prediction tasks, revealing richer semantic insights into geographic decision-making processes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01910v2",
    "published_date": "2025-09-02 03:07:26 UTC",
    "updated_date": "2025-09-05 10:42:33 UTC"
  },
  {
    "arxiv_id": "2509.01909v7",
    "title": "Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models",
    "authors": [
      "Ranjie Duan",
      "Jiexi Liu",
      "Xiaojun Jia",
      "Shiji Zhao",
      "Ruoxi Cheng",
      "Fengxiang Wang",
      "Cheng Wei",
      "Yong Xie",
      "Chang Liu",
      "Defeng Li",
      "Yinpeng Dong",
      "Yichi Zhang",
      "Yuefeng Chen",
      "Chongwen Wang",
      "Xingjun Ma",
      "Xingxing Wei",
      "Yang Liu",
      "Hang Su",
      "Jun Zhu",
      "Xinfeng Li",
      "Yitong Sun",
      "Jie Zhang",
      "Jinzhao Hu",
      "Sha Xu",
      "Wenchao Yang",
      "Yitong Yang",
      "Xingyao Zhang",
      "Yingshui Tan",
      "Jialing Tao",
      "Hui Xue"
    ],
    "abstract": "Large language models (LLMs) typically deploy safety mechanisms to prevent harmful content generation. Most current approaches focus narrowly on risks posed by malicious actors, often framing risks as adversarial events and relying on defensive refusals. However, in real-world settings, risks also come from non-malicious users seeking help while under psychological distress (e.g., self-harm intentions). In such cases, the model's response can strongly influence the user's next actions. Simple refusals may lead them to repeat, escalate, or move to unsafe platforms, creating worse outcomes. We introduce Constructive Safety Alignment (CSA), a human-centric paradigm that protects against malicious misuse while actively guiding vulnerable users toward safe and helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic anticipation of user reactions, fine-grained risk boundary discovery, and interpretable reasoning control, turning safety into a trust-building process. Oy1 achieves state-of-the-art safety among open models while retaining high general capabilities. On our Constructive Benchmark, it shows strong constructive engagement, close to GPT-5, and unmatched robustness on the Strata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from refusal-first to guidance-first safety, CSA redefines the model-user relationship, aiming for systems that are not just safe, but meaningfully helpful. We release Oy1, code, and the benchmark to support responsible, user-centered AI.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "Technical Report Code & Model weights available: https://github.com/Alibaba-AAIG/Oyster",
    "pdf_url": "https://arxiv.org/pdf/2509.01909v7",
    "published_date": "2025-09-02 03:04:27 UTC",
    "updated_date": "2025-10-14 07:33:00 UTC"
  },
  {
    "arxiv_id": "2509.01903v1",
    "title": "VISP: Volatility Informed Stochastic Projection for Adaptive Regularization",
    "authors": [
      "Tanvir Islam"
    ],
    "abstract": "We propose VISP: Volatility Informed Stochastic Projection, an adaptive regularization method that leverages gradient volatility to guide stochastic noise injection in deep neural networks. Unlike conventional techniques that apply uniform noise or fixed dropout rates, VISP dynamically computes volatility from gradient statistics and uses it to scale a stochastic projection matrix. This mechanism selectively regularizes inputs and hidden nodes that exhibit higher gradient volatility while preserving stable representations, thereby mitigating overfitting. Extensive experiments on MNIST, CIFAR-10, and SVHN demonstrate that VISP consistently improves generalization performance over baseline models and fixed-noise alternatives. In addition, detailed analyses of the evolution of volatility, the spectral properties of the projection matrix, and activation distributions reveal that VISP not only stabilizes the internal dynamics of the network but also fosters a more robust feature representation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01903v1",
    "published_date": "2025-09-02 02:51:23 UTC",
    "updated_date": "2025-09-02 02:51:23 UTC"
  },
  {
    "arxiv_id": "2509.03545v1",
    "title": "A software security review on Uganda's Mobile Money Services: Dr. Jim Spire's tweets sentiment analysis",
    "authors": [
      "Nsengiyumva Wilberforce"
    ],
    "abstract": "The proliferation of mobile money in Uganda has been a cornerstone of financial inclusion, yet its security mechanisms remain a critical concern. This study investigates a significant public response to perceived security failures: the #StopAirtelThefty Twitter campaign of August 2025 Sparked by an incident publicized by Dr. Jim Spire Ssentongo where a phone thief accessed a victim's account, withdrew funds, and procured a loan, the campaign revealed deep seated public anxiety over the safety of mobile money. This research employs qualitative analysis to systematically examine the complaints raised during this campaign, extracting key themes related to security vulnerabilities and user dissatisfaction. By synthesizing these public sentiments, the paper provides crucial insights into the specific security gaps experienced by users and situates these findings within the larger framework of Uganda's mobile money regulatory and operational environment. The study concludes with implications for providers, policymakers, and the future of secure digital finance in Uganda.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CY",
    "comment": "16 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.03545v1",
    "published_date": "2025-09-02 02:48:28 UTC",
    "updated_date": "2025-09-02 02:48:28 UTC"
  },
  {
    "arxiv_id": "2509.01885v1",
    "title": "Extracting OPQRST in Electronic Health Records using Large Language Models with Reasoning",
    "authors": [
      "Zhimeng Luo",
      "Abhibha Gupta",
      "Adam Frisch",
      "Daqing He"
    ],
    "abstract": "The extraction of critical patient information from Electronic Health Records (EHRs) poses significant challenges due to the complexity and unstructured nature of the data. Traditional machine learning approaches often fail to capture pertinent details efficiently, making it difficult for clinicians to utilize these tools effectively in patient care. This paper introduces a novel approach to extracting the OPQRST assessment from EHRs by leveraging the capabilities of Large Language Models (LLMs). We propose to reframe the task from sequence labeling to text generation, enabling the models to provide reasoning steps that mimic a physician's cognitive processes. This approach enhances interpretability and adapts to the limited availability of labeled data in healthcare settings. Furthermore, we address the challenge of evaluating the accuracy of machine-generated text in clinical contexts by proposing a modification to traditional Named Entity Recognition (NER) metrics. This includes the integration of semantic similarity measures, such as the BERT Score, to assess the alignment between generated text and the clinical intent of the original records. Our contributions demonstrate a significant advancement in the use of AI in healthcare, offering a scalable solution that improves the accuracy and usability of information extraction from EHRs, thereby aiding clinicians in making more informed decisions and enhancing patient care outcomes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01885v1",
    "published_date": "2025-09-02 02:21:02 UTC",
    "updated_date": "2025-09-02 02:21:02 UTC"
  },
  {
    "arxiv_id": "2509.01882v2",
    "title": "HydroVision: Predicting Optically Active Parameters in Surface Water Using Computer Vision",
    "authors": [
      "Shubham Laxmikant Deshmukh",
      "Matthew Wilchek",
      "Feras A. Batarseh"
    ],
    "abstract": "Ongoing advancements in computer vision, particularly in pattern recognition and scene classification, have enabled new applications in environmental monitoring. Deep learning now offers non-contact methods for assessing water quality and detecting contamination, both critical for disaster response and public health protection. This work introduces HydroVision, a deep learning-based scene classification framework that estimates optically active water quality parameters including Chlorophyll-Alpha, Chlorophylls, Colored Dissolved Organic Matter (CDOM), Phycocyanins, Suspended Sediments, and Turbidity from standard Red-Green-Blue (RGB) images of surface water. HydroVision supports early detection of contamination trends and strengthens monitoring by regulatory agencies during external environmental stressors, industrial activities, and force majeure events. The model is trained on more than 500,000 seasonally varied images collected from the United States Geological Survey Hydrologic Imagery Visualization and Information System between 2022 and 2024. This approach leverages widely available RGB imagery as a scalable, cost-effective alternative to traditional multispectral and hyperspectral remote sensing. Four state-of-the-art convolutional neural networks (VGG-16, ResNet50, MobileNetV2, DenseNet121) and a Vision Transformer are evaluated through transfer learning to identify the best-performing architecture. DenseNet121 achieves the highest validation performance, with an R2 score of 0.89 in predicting CDOM, demonstrating the framework's promise for real-world water quality monitoring across diverse conditions. While the current model is optimized for well-lit imagery, future work will focus on improving robustness under low-light and obstructed scenarios to expand its operational utility.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper is under peer review for IEEE Journal of Oceanic Engineering",
    "pdf_url": "https://arxiv.org/pdf/2509.01882v2",
    "published_date": "2025-09-02 02:12:52 UTC",
    "updated_date": "2025-09-03 13:00:31 UTC"
  },
  {
    "arxiv_id": "2509.01874v1",
    "title": "Preserving Bilinear Weight Spectra with a Signed and Shrunk Quadratic Activation Function",
    "authors": [
      "Jason Abohwo",
      "Thomas Mosen"
    ],
    "abstract": "Understanding the inner workings of machine learning models is critical for ensuring their reliability and robustness. Whilst many techniques in mechanistic interpretability focus on activation driven analyses, being able to derive meaningful features directly from the weights of a neural network would provide greater guarantees and more computational efficiency. Existing techniques for analyzing model features through weights suffer from drawbacks such as reduced performance and data inefficiency. In this paper, we introduce Signed Quadratic Shrink (SQS), an activation function designed to allow Gated Linear Units (GLUs) to learn interpretable features without these drawbacks. Our experimental results show that SQS achieves performance competitive with state-of-the-art activation functions whilst enabling weight-based interpretability",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01874v1",
    "published_date": "2025-09-02 01:42:39 UTC",
    "updated_date": "2025-09-02 01:42:39 UTC"
  },
  {
    "arxiv_id": "2509.01873v1",
    "title": "Doctoral Thesis: Geometric Deep Learning For Camera Pose Prediction, Registration, Depth Estimation, and 3D Reconstruction",
    "authors": [
      "Xueyang Kang"
    ],
    "abstract": "Modern deep learning developments create new opportunities for 3D mapping technology, scene reconstruction pipelines, and virtual reality development. Despite advances in 3D deep learning technology, direct training of deep learning models on 3D data faces challenges due to the high dimensionality inherent in 3D data and the scarcity of labeled datasets. Structure-from-motion (SfM) and Simultaneous Localization and Mapping (SLAM) exhibit robust performance when applied to structured indoor environments but often struggle with ambiguous features in unstructured environments. These techniques often struggle to generate detailed geometric representations effective for downstream tasks such as rendering and semantic analysis. Current limitations require the development of 3D representation methods that combine traditional geometric techniques with deep learning capabilities to generate robust geometry-aware deep learning models.\n  The dissertation provides solutions to the fundamental challenges in 3D vision by developing geometric deep learning methods tailored for essential tasks such as camera pose estimation, point cloud registration, depth prediction, and 3D reconstruction. The integration of geometric priors or constraints, such as including depth information, surface normals, and equivariance into deep learning models, enhances both the accuracy and robustness of geometric representations. This study systematically investigates key components of 3D vision, including camera pose estimation, point cloud registration, depth estimation, and high-fidelity 3D reconstruction, demonstrating their effectiveness across real-world applications such as digital cultural heritage preservation and immersive VR/AR environments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "175 pages, 66 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.01873v1",
    "published_date": "2025-09-02 01:35:44 UTC",
    "updated_date": "2025-09-02 01:35:44 UTC"
  },
  {
    "arxiv_id": "2511.16617v1",
    "title": "Generative AI for Enhanced Wildfire Detection: Bridging the Synthetic-Real Domain Gap",
    "authors": [
      "Satyam Gaba"
    ],
    "abstract": "The early detection of wildfires is a critical environmental challenge, with timely identification of smoke plumes being key to mitigating large-scale damage. While deep neural networks have proven highly effective for localization tasks, the scarcity of large, annotated datasets for smoke detection limits their potential. In response, we leverage generative AI techniques to address this data limitation by synthesizing a comprehensive, annotated smoke dataset. We then explore unsupervised domain adaptation methods for smoke plume segmentation, analyzing their effectiveness in closing the gap between synthetic and real-world data. To further refine performance, we integrate advanced generative approaches such as style transfer, Generative Adversarial Networks (GANs), and image matting. These methods aim to enhance the realism of synthetic data and bridge the domain disparity, paving the way for more accurate and scalable wildfire detection models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 16 figures",
    "pdf_url": "https://arxiv.org/pdf/2511.16617v1",
    "published_date": "2025-09-02 00:40:55 UTC",
    "updated_date": "2025-09-02 00:40:55 UTC"
  },
  {
    "arxiv_id": "2509.04500v1",
    "title": "Context Engineering for Trustworthiness: Rescorla Wagner Steering Under Mixed and Inappropriate Contexts",
    "authors": [
      "Rushi Wang",
      "Jiateng Liu",
      "Cheng Qian",
      "Yifan Shen",
      "Yanzhou Pan",
      "Zhaozhuo Xu",
      "Ahmed Abbasi",
      "Heng Ji",
      "Denghui Zhang"
    ],
    "abstract": "Incorporating external context can significantly enhance the response quality of Large Language Models (LLMs). However, real-world contexts often mix relevant information with disproportionate inappropriate content, posing reliability risks. How do LLMs process and prioritize mixed context? To study this, we introduce the Poisoned Context Testbed, pairing queries with real-world contexts containing relevant and inappropriate content. Inspired by associative learning in animals, we adapt the Rescorla-Wagner (RW) model from neuroscience to quantify how competing contextual signals influence LLM outputs. Our adapted model reveals a consistent behavioral pattern: LLMs exhibit a strong tendency to incorporate information that is less prevalent in the context. This susceptibility is harmful in real-world settings, where small amounts of inappropriate content can substantially degrade response quality. Empirical evaluations on our testbed further confirm this vulnerability. To tackle this, we introduce RW-Steering, a two-stage finetuning-based approach that enables the model to internally identify and ignore inappropriate signals. Unlike prior methods that rely on extensive supervision across diverse context mixtures, RW-Steering generalizes robustly across varying proportions of inappropriate content. Experiments show that our best fine-tuned model improves response quality by 39.8% and reverses the undesirable behavior curve, establishing RW-Steering as a robust, generalizable context engineering solution for improving LLM safety in real-world use.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "36 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.04500v1",
    "published_date": "2025-09-02 00:40:34 UTC",
    "updated_date": "2025-09-02 00:40:34 UTC"
  },
  {
    "arxiv_id": "2511.16619v1",
    "title": "Improving Long-Tailed Object Detection with Balanced Group Softmax and Metric Learning",
    "authors": [
      "Satyam Gaba"
    ],
    "abstract": "Object detection has been widely explored for class-balanced datasets such as COCO. However, real-world scenarios introduce the challenge of long-tailed distributions, where numerous categories contain only a few instances. This inherent class imbalance biases detection models towards the more frequent classes, degrading performance on rare categories. In this paper, we tackle the problem of long-tailed 2D object detection using the LVISv1 dataset, which consists of 1,203 categories and 164,000 images. We employ a two-stage Faster R-CNN architecture and propose enhancements to the Balanced Group Softmax (BAGS) framework to mitigate class imbalance. Our approach achieves a new state-of-the-art performance with a mean Average Precision (mAP) of 24.5%, surpassing the previous benchmark of 24.0%.\n  Additionally, we hypothesize that tail class features may form smaller, denser clusters within the feature space of head classes, making classification challenging for regression-based classifiers. To address this issue, we explore metric learning to produce feature embeddings that are both well-separated across classes and tightly clustered within each class. For inference, we utilize a k-Nearest Neighbors (k-NN) approach to improve classification performance, particularly for rare classes. Our results demonstrate the effectiveness of these methods in advancing long-tailed object detection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 7 figures, International Conference on Semantic Computing",
    "pdf_url": "https://arxiv.org/pdf/2511.16619v1",
    "published_date": "2025-09-02 00:38:13 UTC",
    "updated_date": "2025-09-02 00:38:13 UTC"
  },
  {
    "arxiv_id": "2509.04499v1",
    "title": "DeepTRACE: Auditing Deep Research AI Systems for Tracking Reliability Across Citations and Evidence",
    "authors": [
      "Pranav Narayanan Venkit",
      "Philippe Laban",
      "Yilun Zhou",
      "Kung-Hsiang Huang",
      "Yixin Mao",
      "Chien-Sheng Wu"
    ],
    "abstract": "Generative search engines and deep research LLM agents promise trustworthy, source-grounded synthesis, yet users regularly encounter overconfidence, weak sourcing, and confusing citation practices. We introduce DeepTRACE, a novel sociotechnically grounded audit framework that turns prior community-identified failure cases into eight measurable dimensions spanning answer text, sources, and citations. DeepTRACE uses statement-level analysis (decomposition, confidence scoring) and builds citation and factual-support matrices to audit how systems reason with and attribute evidence end-to-end. Using automated extraction pipelines for popular public models (e.g., GPT-4.5/5, You.com, Perplexity, Copilot/Bing, Gemini) and an LLM-judge with validated agreement to human raters, we evaluate both web-search engines and deep-research configurations. Our findings show that generative search engines and deep research agents frequently produce one-sided, highly confident responses on debate queries and include large fractions of statements unsupported by their own listed sources. Deep-research configurations reduce overconfidence and can attain high citation thoroughness, but they remain highly one-sided on debate queries and still exhibit large fractions of unsupported statements, with citation accuracy ranging from 40--80% across systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: text overlap with arXiv:2410.22349",
    "pdf_url": "https://arxiv.org/pdf/2509.04499v1",
    "published_date": "2025-09-02 00:32:38 UTC",
    "updated_date": "2025-09-02 00:32:38 UTC"
  },
  {
    "arxiv_id": "2509.01845v2",
    "title": "Community-Centered Spatial Intelligence for Climate Adaptation at Nova Scotia's Eastern Shore",
    "authors": [
      "Gabriel Spadon",
      "Oladapo Oyebode",
      "Camilo M. Botero",
      "Tushar Sharma",
      "Floris Goerlandt",
      "Ronald Pelot"
    ],
    "abstract": "This paper presents an overview of a human-centered initiative aimed at strengthening climate resilience along Nova Scotia's Eastern Shore. This region, a collection of rural villages with deep ties to the sea, faces existential threats from climate change that endanger its way of life. Our project moves beyond a purely technical response, weaving together expertise from Computer Science, Industrial Engineering, and Coastal Geography to co-create tools with the community. By integrating generational knowledge of residents, particularly elders, through the Eastern Shore Citizen Science Coastal Monitoring Network, this project aims to collaborate in building a living digital archive. This effort is hosted under Dalhousie University's Transforming Climate Action (TCA) initiative, specifically through its Transformative Adaptations to Social-Ecological Climate Change Trajectories (TranSECT) and TCA Artificial Intelligence (TCA-AI) projects. This work is driven by a collaboration model in which student teams work directly with residents. We present a detailed project timeline and a replicable model for how technology can support traditional communities, enabling them to navigate climate transformation more effectively.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01845v2",
    "published_date": "2025-09-02 00:06:17 UTC",
    "updated_date": "2025-10-08 14:10:18 UTC"
  }
]