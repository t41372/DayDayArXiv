[
  {
    "arxiv_id": "2504.12299v1",
    "title": "Adapting a World Model for Trajectory Following in a 3D Game",
    "authors": [
      "Marko Tot",
      "Shu Ishida",
      "Abdelhak Lemkhenter",
      "David Bignell",
      "Pallavi Choudhury",
      "Chris Lovett",
      "Luis França",
      "Matheus Ribeiro Furtado de Mendonça",
      "Tarun Gupta",
      "Darren Gehring",
      "Sam Devlin",
      "Sergio Valcarcel Macua",
      "Raluca Georgescu"
    ],
    "abstract": "Imitation learning is a powerful tool for training agents by leveraging\nexpert knowledge, and being able to replicate a given trajectory is an integral\npart of it. In complex environments, like modern 3D video games, distribution\nshift and stochasticity necessitate robust approaches beyond simple action\nreplay. In this study, we apply Inverse Dynamics Models (IDM) with different\nencoders and policy heads to trajectory following in a modern 3D video game --\nBleeding Edge. Additionally, we investigate several future alignment strategies\nthat address the distribution shift caused by the aleatoric uncertainty and\nimperfections of the agent. We measure both the trajectory deviation distance\nand the first significant deviation point between the reference and the agent's\ntrajectory and show that the optimal configuration depends on the chosen\nsetting. Our results show that in a diverse data setting, a GPT-style policy\nhead with an encoder trained from scratch performs the best, DINOv2 encoder\nwith the GPT-style policy head gives the best results in the low data regime,\nand both GPT-style and MLP-style policy heads had comparable results when\npre-trained on a diverse setting and fine-tuned for a specific behaviour\nsetting.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12299v1",
    "published_date": "2025-04-16 17:59:54 UTC",
    "updated_date": "2025-04-16 17:59:54 UTC"
  },
  {
    "arxiv_id": "2504.12292v1",
    "title": "SHeaP: Self-Supervised Head Geometry Predictor Learned via 2D Gaussians",
    "authors": [
      "Liam Schoneveld",
      "Zhe Chen",
      "Davide Davoli",
      "Jiapeng Tang",
      "Saimon Terazawa",
      "Ko Nishino",
      "Matthias Nießner"
    ],
    "abstract": "Accurate, real-time 3D reconstruction of human heads from monocular images\nand videos underlies numerous visual applications. As 3D ground truth data is\nhard to come by at scale, previous methods have sought to learn from abundant\n2D videos in a self-supervised manner. Typically, this involves the use of\ndifferentiable mesh rendering, which is effective but faces limitations. To\nimprove on this, we propose SHeaP (Self-supervised Head Geometry Predictor\nLearned via 2D Gaussians). Given a source image, we predict a 3DMM mesh and a\nset of Gaussians that are rigged to this mesh. We then reanimate this rigged\nhead avatar to match a target frame, and backpropagate photometric losses to\nboth the 3DMM and Gaussian prediction networks. We find that using Gaussians\nfor rendering substantially improves the effectiveness of this self-supervised\napproach. Training solely on 2D data, our method surpasses existing\nself-supervised approaches in geometric evaluations on the NoW benchmark for\nneutral faces and a new benchmark for non-neutral expressions. Our method also\nproduces highly expressive meshes, outperforming state-of-the-art in emotion\nclassification.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "For video demonstrations and additional materials please see\n  https://nlml.github.io/sheap/",
    "pdf_url": "http://arxiv.org/pdf/2504.12292v1",
    "published_date": "2025-04-16 17:55:02 UTC",
    "updated_date": "2025-04-16 17:55:02 UTC"
  },
  {
    "arxiv_id": "2504.12284v1",
    "title": "How Do I Do That? Synthesizing 3D Hand Motion and Contacts for Everyday Interactions",
    "authors": [
      "Aditya Prakash",
      "Benjamin Lundell",
      "Dmitry Andreychuk",
      "David Forsyth",
      "Saurabh Gupta",
      "Harpreet Sawhney"
    ],
    "abstract": "We tackle the novel problem of predicting 3D hand motion and contact maps (or\nInteraction Trajectories) given a single RGB view, action text, and a 3D\ncontact point on the object as input. Our approach consists of (1) Interaction\nCodebook: a VQVAE model to learn a latent codebook of hand poses and contact\npoints, effectively tokenizing interaction trajectories, (2) Interaction\nPredictor: a transformer-decoder module to predict the interaction trajectory\nfrom test time inputs by using an indexer module to retrieve a latent\naffordance from the learned codebook. To train our model, we develop a data\nengine that extracts 3D hand poses and contact trajectories from the diverse\nHoloAssist dataset. We evaluate our model on a benchmark that is 2.5-10X larger\nthan existing works, in terms of diversity of objects and interactions\nobserved, and test for generalization of the model across object categories,\naction categories, tasks, and scenes. Experimental results show the\neffectiveness of our approach over transformer & diffusion baselines across all\nsettings.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025, Project page:\n  https://ap229997.github.io/projects/latentact",
    "pdf_url": "http://arxiv.org/pdf/2504.12284v1",
    "published_date": "2025-04-16 17:48:12 UTC",
    "updated_date": "2025-04-16 17:48:12 UTC"
  },
  {
    "arxiv_id": "2504.12268v1",
    "title": "HLS-Eval: A Benchmark and Framework for Evaluating LLMs on High-Level Synthesis Design Tasks",
    "authors": [
      "Stefan Abi-Karam",
      "Cong Hao"
    ],
    "abstract": "The rapid scaling of large language model (LLM) training and inference has\ndriven their adoption in semiconductor design across academia and industry.\nWhile most prior work evaluates LLMs on hardware description language (HDL)\ntasks, particularly Verilog, designers are increasingly using high-level\nsynthesis (HLS) to build domain-specific accelerators and complex hardware\nsystems. However, benchmarks and tooling to comprehensively evaluate LLMs for\nHLS design tasks remain scarce.\n  To address this, we introduce HLS-Eval, the first complete benchmark and\nevaluation framework for LLM-driven HLS design. HLS-Eval targets two core\ntasks: (1) generating HLS code from natural language descriptions, and (2)\nperforming HLS-specific code edits to optimize performance and hardware\nefficiency. The benchmark includes 94 unique designs drawn from standard HLS\nbenchmarks and novel sources. Each case is prepared via a semi-automated flow\nthat produces a natural language description and a paired testbench for\nC-simulation and synthesis validation, ensuring each task is \"LLM-ready.\"\n  Beyond the benchmark, HLS-Eval offers a modular Python framework for\nautomated, parallel evaluation of both local and hosted LLMs. It includes a\nparallel evaluation engine, direct HLS tool integration, and abstractions for\nto support different LLM interaction paradigms, enabling rapid prototyping of\nnew benchmarks, tasks, and LLM methods.\n  We demonstrate HLS-Eval through baseline evaluations of open-source LLMs on\nVitis HLS, measuring outputs across four key metrics - parseability,\ncompilability, runnability, and synthesizability - reflecting the iterative HLS\ndesign cycle. We also report pass@k metrics, establishing clear baselines and\nreusable infrastructure for the broader LLM-for-hardware community.\n  All benchmarks, framework code, and results are open-sourced at\nhttps://github.com/stefanpie/hls-eval.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12268v1",
    "published_date": "2025-04-16 17:30:36 UTC",
    "updated_date": "2025-04-16 17:30:36 UTC"
  },
  {
    "arxiv_id": "2504.12262v1",
    "title": "SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via Scalable Conditioned Neural Fields",
    "authors": [
      "David Keetae Park",
      "Xihaier Luo",
      "Guang Zhao",
      "Seungjun Lee",
      "Miruna Oprescu",
      "Shinjae Yoo"
    ],
    "abstract": "Spatiotemporal learning is challenging due to the intricate interplay between\nspatial and temporal dependencies, the high dimensionality of the data, and\nscalability constraints. These challenges are further amplified in scientific\ndomains, where data is often irregularly distributed (e.g., missing values from\nsensor failures) and high-volume (e.g., high-fidelity simulations), posing\nadditional computational and modeling difficulties. In this paper, we present\nSCENT, a novel framework for scalable and continuity-informed spatiotemporal\nrepresentation learning. SCENT unifies interpolation, reconstruction, and\nforecasting within a single architecture. Built on a transformer-based\nencoder-processor-decoder backbone, SCENT introduces learnable queries to\nenhance generalization and a query-wise cross-attention mechanism to\neffectively capture multi-scale dependencies. To ensure scalability in both\ndata size and model complexity, we incorporate a sparse attention mechanism,\nenabling flexible output representations and efficient evaluation at arbitrary\nresolutions. We validate SCENT through extensive simulations and real-world\nexperiments, demonstrating state-of-the-art performance across multiple\nchallenging tasks while achieving superior scalability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 5 main figures, 3 tables, under review",
    "pdf_url": "http://arxiv.org/pdf/2504.12262v1",
    "published_date": "2025-04-16 17:17:31 UTC",
    "updated_date": "2025-04-16 17:17:31 UTC"
  },
  {
    "arxiv_id": "2504.12256v1",
    "title": "FLIP Reasoning Challenge",
    "authors": [
      "Andreas Plesner",
      "Turlan Kuzhagaliyev",
      "Roger Wattenhofer"
    ],
    "abstract": "Over the past years, advances in artificial intelligence (AI) have\ndemonstrated how AI can solve many perception and generation tasks, such as\nimage classification and text writing, yet reasoning remains a challenge. This\npaper introduces the FLIP dataset, a benchmark for evaluating AI reasoning\ncapabilities based on human verification tasks on the Idena blockchain. FLIP\nchallenges present users with two orderings of 4 images, requiring them to\nidentify the logically coherent one. By emphasizing sequential reasoning,\nvisual storytelling, and common sense, FLIP provides a unique testbed for\nmultimodal AI systems. Our experiments evaluate state-of-the-art models,\nleveraging both vision-language models (VLMs) and large language models (LLMs).\nResults reveal that even the best open-sourced and closed-sourced models\nachieve maximum accuracies of 75.5% and 77.9%, respectively, in zero-shot\nsettings, compared to human performance of 95.3%. Captioning models aid\nreasoning models by providing text descriptions of images, yielding better\nresults than when using the raw images directly, 69.6% vs. 75.2% for Gemini 1.5\nPro. Combining the predictions from 15 models in an ensemble increases the\naccuracy to 85.2%. These findings highlight the limitations of existing\nreasoning models and the need for robust multimodal benchmarks like FLIP. The\nfull codebase and dataset will be available at\nhttps://github.com/aplesner/FLIP-Reasoning-Challenge.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at First Workshop on Open Science for Foundation Models at\n  ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.12256v1",
    "published_date": "2025-04-16 17:07:16 UTC",
    "updated_date": "2025-04-16 17:07:16 UTC"
  },
  {
    "arxiv_id": "2504.12254v1",
    "title": "Advancing Arabic Speech Recognition Through Large-Scale Weakly Supervised Learning",
    "authors": [
      "Mahmoud Salhab",
      "Marwan Elghitany",
      "Shameed Sait",
      "Syed Sibghat Ullah",
      "Mohammad Abusheikh",
      "Hasan Abusheikh"
    ],
    "abstract": "Automatic speech recognition (ASR) is crucial for human-machine interaction\nin diverse applications like conversational agents, industrial robotics, call\ncenter automation, and automated subtitling. However, developing\nhigh-performance ASR models remains challenging, particularly for low-resource\nlanguages like Arabic, due to the scarcity of large, labeled speech datasets,\nwhich are costly and labor-intensive to produce. In this work, we employ weakly\nsupervised learning to train an Arabic ASR model using the Conformer\narchitecture. Our model is trained from scratch on 15,000 hours of weakly\nannotated speech data covering both Modern Standard Arabic (MSA) and Dialectal\nArabic (DA), eliminating the need for costly manual transcriptions. Despite the\nabsence of human-verified labels, our approach attains state-of-the-art (SOTA)\nperformance, exceeding all previous efforts in the field of Arabic ASR on the\nstandard benchmarks. By demonstrating the effectiveness of weak supervision as\na scalable, cost-efficient alternative to traditional supervised approaches,\npaving the way for improved ASR systems in low resource settings.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12254v1",
    "published_date": "2025-04-16 17:05:14 UTC",
    "updated_date": "2025-04-16 17:05:14 UTC"
  },
  {
    "arxiv_id": "2504.12215v1",
    "title": "Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware Post-Processing",
    "authors": [
      "Ilkin Sevgi Isler",
      "David Mohaisen",
      "Curtis Lisle",
      "Damla Turgut",
      "Ulas Bagci"
    ],
    "abstract": "Reliable tumor segmentation in thoracic computed tomography (CT) remains\nchallenging due to boundary ambiguity, class imbalance, and anatomical\nvariability. We propose an uncertainty-guided, coarse-to-fine segmentation\nframework that combines full-volume tumor localization with refined\nregion-of-interest (ROI) segmentation, enhanced by anatomically aware\npost-processing. The first-stage model generates a coarse prediction, followed\nby anatomically informed filtering based on lung overlap, proximity to lung\nsurfaces, and component size. The resulting ROIs are segmented by a\nsecond-stage model trained with uncertainty-aware loss functions to improve\naccuracy and boundary calibration in ambiguous regions. Experiments on private\nand public datasets demonstrate improvements in Dice and Hausdorff scores, with\nfewer false positives and enhanced spatial interpretability. These results\nhighlight the value of combining uncertainty modeling and anatomical priors in\ncascaded segmentation pipelines for robust and clinically meaningful tumor\ndelineation. On the Orlando dataset, our framework improved Swin UNETR Dice\nfrom 0.4690 to 0.6447. Reduction in spurious components was strongly correlated\nwith segmentation gains, underscoring the value of anatomically informed\npost-processing.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 2 figures, to appear in IEEE ADSCA 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.12215v1",
    "published_date": "2025-04-16 16:08:38 UTC",
    "updated_date": "2025-04-16 16:08:38 UTC"
  },
  {
    "arxiv_id": "2504.12210v1",
    "title": "Communication Optimization for Decentralized Learning atop Bandwidth-limited Edge Networks",
    "authors": [
      "Tingyang Sun",
      "Tuan Nguyen",
      "Ting He"
    ],
    "abstract": "Decentralized federated learning (DFL) is a promising machine learning\nparadigm for bringing artificial intelligence (AI) capabilities to the network\nedge. Running DFL on top of edge networks, however, faces severe performance\nchallenges due to the extensive parameter exchanges between agents. Most\nexisting solutions for these challenges were based on simplistic communication\nmodels, which cannot capture the case of learning over a multi-hop\nbandwidth-limited network. In this work, we address this problem by jointly\ndesigning the communication scheme for the overlay network formed by the agents\nand the mixing matrix that controls the communication demands between the\nagents. By carefully analyzing the properties of our problem, we cast each\ndesign problem into a tractable optimization and develop an efficient algorithm\nwith guaranteed performance. Our evaluations based on real topology and data\nshow that the proposed algorithm can reduce the total training time by over\n$80\\%$ compared to the baseline without sacrificing accuracy, while\nsignificantly improving the computational efficiency over the state of the art.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "arXiv admin note: text overlap with arXiv:2408.04705",
    "pdf_url": "http://arxiv.org/pdf/2504.12210v1",
    "published_date": "2025-04-16 15:56:57 UTC",
    "updated_date": "2025-04-16 15:56:57 UTC"
  },
  {
    "arxiv_id": "2504.12192v1",
    "title": "From Requirements to Architecture: Semi-Automatically Generating Software Architectures",
    "authors": [
      "Tobias Eisenreich"
    ],
    "abstract": "To support junior and senior architects, I propose developing a new\narchitecture creation method that leverages LLMs' evolving capabilities to\nsupport the architect. This method involves the architect's close collaboration\nwith LLM-fueled tooling over the whole process. The architect is guided through\nDomain Model creation, Use Case specification, architectural decisions, and\narchitecture evaluation. While the architect can take complete control of the\nprocess and the results, and use the tooling as a building set, they can follow\nthe intended process for maximum tooling support. The preliminary results\nsuggest the feasibility of this process and indicate major time savings for the\narchitect.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.2"
    ],
    "primary_category": "cs.SE",
    "comment": "to be published in EMISA 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.12192v1",
    "published_date": "2025-04-16 15:46:56 UTC",
    "updated_date": "2025-04-16 15:46:56 UTC"
  },
  {
    "arxiv_id": "2504.12187v1",
    "title": "What Do Large Language Models Know? Tacit Knowledge as a Potential Causal-Explanatory Structure",
    "authors": [
      "Céline Budding"
    ],
    "abstract": "It is sometimes assumed that Large Language Models (LLMs) know language, or\nfor example that they know that Paris is the capital of France. But what -- if\nanything -- do LLMs actually know? In this paper, I argue that LLMs can acquire\ntacit knowledge as defined by Martin Davies (1990). Whereas Davies himself\ndenies that neural networks can acquire tacit knowledge, I demonstrate that\ncertain architectural features of LLMs satisfy the constraints of semantic\ndescription, syntactic structure, and causal systematicity. Thus, tacit\nknowledge may serve as a conceptual framework for describing, explaining, and\nintervening on LLMs and their behavior.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication in Philosophy of Science",
    "pdf_url": "http://arxiv.org/pdf/2504.12187v1",
    "published_date": "2025-04-16 15:42:33 UTC",
    "updated_date": "2025-04-16 15:42:33 UTC"
  },
  {
    "arxiv_id": "2504.12185v1",
    "title": "SALAD: Improving Robustness and Generalization through Contrastive Learning with Structure-Aware and LLM-Driven Augmented Data",
    "authors": [
      "Suyoung Bae",
      "Hyojun Kim",
      "YunSeok Choi",
      "Jee-Hyong Lee"
    ],
    "abstract": "In various natural language processing (NLP) tasks, fine-tuning Pre-trained\nLanguage Models (PLMs) often leads to the issue of spurious correlations, which\nnegatively impacts performance, particularly when dealing with\nout-of-distribution data. To address this problem, we propose SALAD}(Structure\nAware and LLM-driven Augmented Data), a novel approach designed to enhance\nmodel robustness and generalization by generating structure-aware and\ncounterfactually augmented data for contrastive learning. Our method leverages\na tagging-based approach to generate structure-aware positive samples and\nutilizes large language models (LLMs) to generate counterfactual negative\nsamples with diverse sentence patterns. By applying contrastive learning, SALAD\nenables the model to focus on learning the structural relationships between key\nsentence components while minimizing reliance on spurious correlations. We\nvalidate our approach through experiments on three tasks: Sentiment\nClassification, Sexism Detection, and Natural Language Inference. The results\ndemonstrate that SALAD not only improves model robustness and performance\nacross different environments but also enhances generalization to\nout-of-distribution datasets and cross-domain scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 main. 15 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.12185v1",
    "published_date": "2025-04-16 15:40:10 UTC",
    "updated_date": "2025-04-16 15:40:10 UTC"
  },
  {
    "arxiv_id": "2504.12180v1",
    "title": "Trusting CHATGPT: how minor tweaks in the prompts lead to major differences in sentiment classification",
    "authors": [
      "Jaime E. Cuellar",
      "Oscar Moreno-Martinez",
      "Paula Sofia Torres-Rodriguez",
      "Jaime Andres Pavlich-Mariscal",
      "Andres Felipe Mican-Castiblanco",
      "Juan Guillermo Torres-Hurtado"
    ],
    "abstract": "One fundamental question for the social sciences today is: how much can we\ntrust highly complex predictive models like ChatGPT? This study tests the\nhypothesis that subtle changes in the structure of prompts do not produce\nsignificant variations in the classification results of sentiment polarity\nanalysis generated by the Large Language Model GPT-4o mini. Using a dataset of\n100.000 comments in Spanish on four Latin American presidents, the model\nclassified the comments as positive, negative, or neutral on 10 occasions,\nvarying the prompts slightly each time. The experimental methodology included\nexploratory and confirmatory analyses to identify significant discrepancies\namong classifications.\n  The results reveal that even minor modifications to prompts such as lexical,\nsyntactic, or modal changes, or even their lack of structure impact the\nclassifications. In certain cases, the model produced inconsistent responses,\nsuch as mixing categories, providing unsolicited explanations, or using\nlanguages other than Spanish. Statistical analysis using Chi-square tests\nconfirmed significant differences in most comparisons between prompts, except\nin one case where linguistic structures were highly similar.\n  These findings challenge the robustness and trust of Large Language Models\nfor classification tasks, highlighting their vulnerability to variations in\ninstructions. Moreover, it was evident that the lack of structured grammar in\nprompts increases the frequency of hallucinations. The discussion underscores\nthat trust in Large Language Models is based not only on technical performance\nbut also on the social and institutional relationships underpinning their use.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "in Spanish language",
    "pdf_url": "http://arxiv.org/pdf/2504.12180v1",
    "published_date": "2025-04-16 15:37:09 UTC",
    "updated_date": "2025-04-16 15:37:09 UTC"
  },
  {
    "arxiv_id": "2504.12177v1",
    "title": "Mapping Controversies Using Artificial Intelligence: An Analysis of the Hamas-Israel Conflict on YouTube",
    "authors": [
      "Victor Manuel Hernandez Lopez",
      "Jaime E. Cuellar"
    ],
    "abstract": "This article analyzes the Hamas-Israel controversy through 253,925\nSpanish-language YouTube comments posted between October 2023 and January 2024,\nfollowing the October 7 attack that escalated the conflict. Adopting an\ninterdisciplinary approach, the study combines the analysis of controversies\nfrom Science and Technology Studies (STS) with advanced computational\nmethodologies, specifically Natural Language Processing (NLP) using the BERT\n(Bidirectional Encoder Representations from Transformers) model. Using this\napproach, the comments were automatically classified into seven categories,\nreflecting pro-Palestinian, pro-Israeli, anti- Palestinian, anti-Israeli\npositions, among others. The results show a predominance of pro- Palestinian\ncomments, although pro-Israeli and anti-Palestinian comments received more\n\"likes.\" This study also applies the agenda-setting theory to demonstrate how\nmedia coverage significantly influences public perception, observing a notable\nshift in public opinion, transitioning from a pro- Palestinian stance to a more\ncritical position towards Israel. This work highlights the importance of\ncombining social science perspectives with technological tools in the analysis\nof controversies, presenting a methodological innovation by integrating\ncomputational analysis with critical social theories to address complex public\nopinion phenomena and media narratives.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "in Spanish language",
    "pdf_url": "http://arxiv.org/pdf/2504.12177v1",
    "published_date": "2025-04-16 15:27:57 UTC",
    "updated_date": "2025-04-16 15:27:57 UTC"
  },
  {
    "arxiv_id": "2504.12172v1",
    "title": "Poem Meter Classification of Recited Arabic Poetry: Integrating High-Resource Systems for a Low-Resource Task",
    "authors": [
      "Maged S. Al-Shaibani",
      "Zaid Alyafeai",
      "Irfan Ahmad"
    ],
    "abstract": "Arabic poetry is an essential and integral part of Arabic language and\nculture. It has been used by the Arabs to spot lights on their major events\nsuch as depicting brutal battles and conflicts. They also used it, as in many\nother languages, for various purposes such as romance, pride, lamentation, etc.\nArabic poetry has received major attention from linguistics over the decades.\nOne of the main characteristics of Arabic poetry is its special rhythmic\nstructure as opposed to prose. This structure is referred to as a meter.\nMeters, along with other poetic characteristics, are intensively studied in an\nArabic linguistic field called \"\\textit{Aroud}\". Identifying these meters for a\nverse is a lengthy and complicated process. It also requires technical\nknowledge in \\textit{Aruod}. For recited poetry, it adds an extra layer of\nprocessing. Developing systems for automatic identification of poem meters for\nrecited poems need large amounts of labelled data. In this study, we propose a\nstate-of-the-art framework to identify the poem meters of recited Arabic\npoetry, where we integrate two separate high-resource systems to perform the\nlow-resource task. To ensure generalization of our proposed architecture, we\npublish a benchmark for this task for future research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12172v1",
    "published_date": "2025-04-16 15:25:45 UTC",
    "updated_date": "2025-04-16 15:25:45 UTC"
  },
  {
    "arxiv_id": "2504.12151v1",
    "title": "Towards Explainable Fusion and Balanced Learning in Multimodal Sentiment Analysis",
    "authors": [
      "Miaosen Luo",
      "Yuncheng Jiang",
      "Sijie Mai"
    ],
    "abstract": "Multimodal Sentiment Analysis (MSA) faces two critical challenges: the lack\nof interpretability in the decision logic of multimodal fusion and modality\nimbalance caused by disparities in inter-modal information density. To address\nthese issues, we propose KAN-MCP, a novel framework that integrates the\ninterpretability of Kolmogorov-Arnold Networks (KAN) with the robustness of the\nMultimodal Clean Pareto (MCPareto) framework. First, KAN leverages its\nunivariate function decomposition to achieve transparent analysis of\ncross-modal interactions. This structural design allows direct inspection of\nfeature transformations without relying on external interpretation tools,\nthereby ensuring both high expressiveness and interpretability. Second, the\nproposed MCPareto enhances robustness by addressing modality imbalance and\nnoise interference. Specifically, we introduce the Dimensionality Reduction and\nDenoising Modal Information Bottleneck (DRD-MIB) method, which jointly denoises\nand reduces feature dimensionality. This approach provides KAN with\ndiscriminative low-dimensional inputs to reduce the modeling complexity of KAN\nwhile preserving critical sentiment-related information. Furthermore, MCPareto\ndynamically balances gradient contributions across modalities using the\npurified features output by DRD-MIB, ensuring lossless transmission of\nauxiliary signals and effectively alleviating modality imbalance. This synergy\nof interpretability and robustness not only achieves superior performance on\nbenchmark datasets such as CMU-MOSI, CMU-MOSEI, and CH-SIMS v2 but also offers\nan intuitive visualization interface through KAN's interpretable architecture.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12151v1",
    "published_date": "2025-04-16 15:00:06 UTC",
    "updated_date": "2025-04-16 15:00:06 UTC"
  },
  {
    "arxiv_id": "2504.12143v1",
    "title": "ARCeR: an Agentic RAG for the Automated Definition of Cyber Ranges",
    "authors": [
      "Matteo Lupinacci",
      "Francesco Blefari",
      "Francesco Romeo",
      "Francesco Aurelio Pironti",
      "Angelo Furfaro"
    ],
    "abstract": "The growing and evolving landscape of cybersecurity threats necessitates the\ndevelopment of supporting tools and platforms that allow for the creation of\nrealistic IT environments operating within virtual, controlled settings as\nCyber Ranges (CRs). CRs can be exploited for analyzing vulnerabilities and\nexperimenting with the effectiveness of devised countermeasures, as well as\nserving as training environments for building cyber security skills and\nabilities for IT operators. This paper proposes ARCeR as an innovative solution\nfor the automatic generation and deployment of CRs, starting from user-provided\ndescriptions in a natural language. ARCeR relies on the Agentic RAG paradigm,\nwhich allows it to fully exploit state-of-art AI technologies. Experimental\nresults show that ARCeR is able to successfully process prompts even in cases\nthat LLMs or basic RAG systems are not able to cope with. Furthermore, ARCeR is\nable to target any CR framework provided that specific knowledge is made\navailable to it.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12143v1",
    "published_date": "2025-04-16 14:53:28 UTC",
    "updated_date": "2025-04-16 14:53:28 UTC"
  },
  {
    "arxiv_id": "2504.12137v1",
    "title": "Efficient Contrastive Decoding with Probabilistic Hallucination Detection - Mitigating Hallucinations in Large Vision Language Models -",
    "authors": [
      "Laura Fieback",
      "Nishilkumar Balar",
      "Jakob Spiegelberg",
      "Hanno Gottschalk"
    ],
    "abstract": "Despite recent advances in Large Vision Language Models (LVLMs), these models\nstill suffer from generating hallucinatory responses that do not align with the\nvisual input provided. To mitigate such hallucinations, we introduce Efficient\nContrastive Decoding (ECD), a simple method that leverages probabilistic\nhallucination detection to shift the output distribution towards contextually\naccurate answers at inference time. By contrasting token probabilities and\nhallucination scores, ECD subtracts hallucinated concepts from the original\ndistribution, effectively suppressing hallucinations. Notably, our proposed\nmethod can be applied to any open-source LVLM and does not require additional\nLVLM training. We evaluate our method on several benchmark datasets and across\ndifferent LVLMs. Our experiments show that ECD effectively mitigates\nhallucinations, outperforming state-of-the-art methods with respect to\nperformance on LVLM benchmarks and computation time.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12137v1",
    "published_date": "2025-04-16 14:50:25 UTC",
    "updated_date": "2025-04-16 14:50:25 UTC"
  },
  {
    "arxiv_id": "2504.12110v1",
    "title": "Towards LLM Agents for Earth Observation",
    "authors": [
      "Chia Hsiang Kao",
      "Wenting Zhao",
      "Shreelekha Revankar",
      "Samuel Speas",
      "Snehal Bhagat",
      "Rajeev Datta",
      "Cheng Perng Phoo",
      "Utkarsh Mall",
      "Carl Vondrick",
      "Kavita Bala",
      "Bharath Hariharan"
    ],
    "abstract": "Earth Observation (EO) provides critical planetary data for environmental\nmonitoring, disaster management, climate science, and other scientific domains.\nHere we ask: Are AI systems ready for reliable Earth Observation? We introduce\n\\datasetnamenospace, a benchmark of 140 yes/no questions from NASA Earth\nObservatory articles across 13 topics and 17 satellite sensors. Using Google\nEarth Engine API as a tool, LLM agents can only achieve an accuracy of 33%\nbecause the code fails to run over 58% of the time. We improve the failure rate\nfor open models by fine-tuning synthetic data, allowing much smaller models\n(Llama-3.1-8B) to achieve comparable accuracy to much larger ones (e.g.,\nDeepSeek-R1). Taken together, our findings identify significant challenges to\nbe solved before AI agents can automate earth observation, and suggest paths\nforward. The project page is available at\nhttps://iandrover.github.io/UnivEarth.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "36 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.12110v1",
    "published_date": "2025-04-16 14:19:25 UTC",
    "updated_date": "2025-04-16 14:19:25 UTC"
  },
  {
    "arxiv_id": "2504.12090v1",
    "title": "Reasoning-Based AI for Startup Evaluation (R.A.I.S.E.): A Memory-Augmented, Multi-Step Decision Framework",
    "authors": [
      "Jack Preuveneers",
      "Joseph Ternasky",
      "Fuat Alican",
      "Yigit Ihlamur"
    ],
    "abstract": "We present a novel framework that bridges the gap between the\ninterpretability of decision trees and the advanced reasoning capabilities of\nlarge language models (LLMs) to predict startup success. Our approach leverages\nchain-of-thought prompting to generate detailed reasoning logs, which are\nsubsequently distilled into structured, human-understandable logical rules. The\npipeline integrates multiple enhancements - efficient data ingestion, a\ntwo-step refinement process, ensemble candidate sampling, simulated\nreinforcement learning scoring, and persistent memory - to ensure both stable\ndecision-making and transparent output. Experimental evaluations on curated\nstartup datasets demonstrate that our combined pipeline improves precision by\n54% from 0.225 to 0.346 and accuracy by 50% from 0.46 to 0.70 compared to a\nstandalone OpenAI o3 model. Notably, our model achieves over 2x the precision\nof a random classifier (16%). By combining state-of-the-art AI reasoning with\nexplicit rule-based explanations, our method not only augments traditional\ndecision-making processes but also facilitates expert intervention and\ncontinuous policy refinement. This work lays the foundation for the\nimplementation of interpretable LLM-powered decision frameworks in high-stakes\ninvestment environments and other domains that require transparent and\ndata-driven insights.",
    "categories": [
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12090v1",
    "published_date": "2025-04-16 13:53:42 UTC",
    "updated_date": "2025-04-16 13:53:42 UTC"
  },
  {
    "arxiv_id": "2504.12088v1",
    "title": "AttentionDrop: A Novel Regularization Method for Transformer Models",
    "authors": [
      "Mirza Samad Ahmed Baig",
      "Syeda Anshrah Gillani",
      "Abdul Akbar Khan",
      "Shahid Munir Shah"
    ],
    "abstract": "Transformer-based architectures achieve state-of-the-art performance across a\nwide range of tasks in natural language processing, computer vision, and\nspeech. However, their immense capacity often leads to overfitting, especially\nwhen training data is limited or noisy. We propose AttentionDrop, a unified\nfamily of stochastic regularization techniques that operate directly on the\nself-attention distributions. We introduces three variants: 1. Hard Attention\nMasking: randomly zeroes out top-k attention logits per query to encourage\ndiverse context utilization. 2. Blurred Attention Smoothing: applies a dynamic\nGaussian convolution over attention logits to diffuse overly peaked\ndistributions. 3. Consistency-Regularized AttentionDrop: enforces output\nstability under multiple independent AttentionDrop perturbations via a KL-based\nconsistency loss.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.12088v1",
    "published_date": "2025-04-16 13:51:16 UTC",
    "updated_date": "2025-04-16 13:51:16 UTC"
  },
  {
    "arxiv_id": "2504.12082v1",
    "title": "Selective Demonstration Retrieval for Improved Implicit Hate Speech Detection",
    "authors": [
      "Yumin Kim",
      "Hwanhee Lee"
    ],
    "abstract": "Hate speech detection is a crucial area of research in natural language\nprocessing, essential for ensuring online community safety. However, detecting\nimplicit hate speech, where harmful intent is conveyed in subtle or indirect\nways, remains a major challenge. Unlike explicit hate speech, implicit\nexpressions often depend on context, cultural subtleties, and hidden biases,\nmaking them more challenging to identify consistently. Additionally, the\ninterpretation of such speech is influenced by external knowledge and\ndemographic biases, resulting in varied detection results across different\nlanguage models. Furthermore, Large Language Models often show heightened\nsensitivity to toxic language and references to vulnerable groups, which can\nlead to misclassifications. This over-sensitivity results in false positives\n(incorrectly identifying harmless statements as hateful) and false negatives\n(failing to detect genuinely harmful content). Addressing these issues requires\nmethods that not only improve detection precision but also reduce model biases\nand enhance robustness. To address these challenges, we propose a novel method,\nwhich utilizes in-context learning without requiring model fine-tuning. By\nadaptively retrieving demonstrations that focus on similar groups or those with\nthe highest similarity scores, our approach enhances contextual comprehension.\nExperimental results show that our method outperforms current state-of-the-art\ntechniques. Implementation details and code are available at TBD.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12082v1",
    "published_date": "2025-04-16 13:43:23 UTC",
    "updated_date": "2025-04-16 13:43:23 UTC"
  },
  {
    "arxiv_id": "2504.12063v1",
    "title": "Optimizing Compound Retrieval Systems",
    "authors": [
      "Harrie Oosterhuis",
      "Rolf Jagerman",
      "Zhen Qin",
      "Xuanhui Wang"
    ],
    "abstract": "Modern retrieval systems do not rely on a single ranking model to construct\ntheir rankings. Instead, they generally take a cascading approach where a\nsequence of ranking models are applied in multiple re-ranking stages. Thereby,\nthey balance the quality of the top-K ranking with computational costs by\nlimiting the number of documents each model re-ranks. However, the cascading\napproach is not the only way models can interact to form a retrieval system.\n  We propose the concept of compound retrieval systems as a broader class of\nretrieval systems that apply multiple prediction models. This encapsulates\ncascading models but also allows other types of interactions than top-K\nre-ranking. In particular, we enable interactions with large language models\n(LLMs) which can provide relative relevance comparisons. We focus on the\noptimization of compound retrieval system design which uniquely involves\nlearning where to apply the component models and how to aggregate their\npredictions into a final ranking. This work shows how our compound approach can\ncombine the classic BM25 retrieval model with state-of-the-art (pairwise) LLM\nrelevance predictions, while optimizing a given ranking metric and efficiency\ntarget. Our experimental results show optimized compound retrieval systems\nprovide better trade-offs between effectiveness and efficiency than cascading\napproaches, even when applied in a self-supervised manner.\n  With the introduction of compound retrieval systems, we hope to inspire the\ninformation retrieval field to more out-of-the-box thinking on how prediction\nmodels can interact to form rankings.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.12063v1",
    "published_date": "2025-04-16 13:18:16 UTC",
    "updated_date": "2025-04-16 13:18:16 UTC"
  },
  {
    "arxiv_id": "2504.12039v1",
    "title": "RadMamba: Efficient Human Activity Recognition through Radar-based Micro-Doppler-Oriented Mamba State-Space Model",
    "authors": [
      "Yizhuo Wu",
      "Francesco Fioranelli",
      "Chang Gao"
    ],
    "abstract": "Radar-based HAR has emerged as a promising alternative to conventional\nmonitoring approaches, such as wearable devices and camera-based systems, due\nto its unique privacy preservation and robustness advantages. However, existing\nsolutions based on convolutional and recurrent neural networks, although\neffective, are computationally demanding during deployment. This limits their\napplicability in scenarios with constrained resources or those requiring\nmultiple sensors. Advanced architectures, such as ViT and SSM architectures,\noffer improved modeling capabilities and have made efforts toward lightweight\ndesigns. However, their computational complexity remains relatively high. To\nleverage the strengths of transformer architectures while simultaneously\nenhancing accuracy and reducing computational complexity, this paper introduces\nRadMamba, a parameter-efficient, radar micro-Doppler-oriented Mamba SSM\nspecifically tailored for radar-based HAR. Across three diverse datasets,\nRadMamba matches the top-performing previous model's 99.8% classification\naccuracy on Dataset DIAT with only 1/400 of its parameters and equals the\nleading models' 92.0% accuracy on Dataset CI4R with merely 1/10 of their\nparameters. In scenarios with continuous sequences of actions evaluated on\nDataset UoG2020, RadMamba surpasses other models with significantly higher\nparameter counts by at least 3%, achieving this with only 6.7k parameters. Our\ncode is available at: https://github.com/lab-emi/AIRHAR.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2504.12039v1",
    "published_date": "2025-04-16 12:54:11 UTC",
    "updated_date": "2025-04-16 12:54:11 UTC"
  },
  {
    "arxiv_id": "2504.12031v1",
    "title": "Proof-Carrying Neuro-Symbolic Code",
    "authors": [
      "Ekaterina Komendantskaya"
    ],
    "abstract": "This invited paper introduces the concept of \"proof-carrying neuro-symbolic\ncode\" and explains its meaning and value, from both the \"neural\" and the\n\"symbolic\" perspectives. The talk outlines the first successes and challenges\nthat this new area of research faces.",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.LO",
      "F.3.1; F.3.2; F.3.3; I.2.0"
    ],
    "primary_category": "cs.PL",
    "comment": "Invited paper at CiE 2025. arXiv admin note: text overlap with\n  arXiv:2501.05867",
    "pdf_url": "http://arxiv.org/pdf/2504.12031v1",
    "published_date": "2025-04-16 12:42:18 UTC",
    "updated_date": "2025-04-16 12:42:18 UTC"
  },
  {
    "arxiv_id": "2504.12012v1",
    "title": "Purposefully Induced Psychosis (PIP): Embracing Hallucination as Imagination in Large Language Models",
    "authors": [
      "Kris Pilcher",
      "Esen K. Tütüncü"
    ],
    "abstract": "Hallucinations in Large Language Models (LLMs) are widely regarded as errors\n- outputs that deviate from factual accuracy. However, in creative or\nexploratory contexts, these \"mistakes\" may represent unexpected avenues for\ninnovation. We introduce Purposefully Induced Psychosis (PIP), a novel approach\nthat amplifies LLM hallucinations for imaginative tasks such as speculative\nfiction, interactive storytelling, and mixed-reality simulations. Drawing on\nHerman Melville's Moby-Dick, where Pip's \"madness\" reveals profound insight, we\nreframe hallucinations as a source of computational imagination rather than a\nflaw. Our method fine-tunes LLMs to encourage speculative, metaphorical, and\nsurreal outputs - hallucinations that are useful when factual accuracy is not\nthe chief objective. Inspired by the consensual illusions of theater and stage\nmagic, PIP situates these creative missteps in contexts where users willingly\nsuspend disbelief, thereby transforming \"errors\" into catalysts for new ways of\nthinking. We discuss potential applications, design principles for ensuring\nuser consent, preliminary observations, and implications for broader AI ethics\nand human-AI collaboration.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.12012v1",
    "published_date": "2025-04-16 12:13:02 UTC",
    "updated_date": "2025-04-16 12:13:02 UTC"
  },
  {
    "arxiv_id": "2504.12011v1",
    "title": "Balancing Graph Embedding Smoothness in Self-Supervised Learning via Information-Theoretic Decomposition",
    "authors": [
      "Heesoo Jung",
      "Hogun Park"
    ],
    "abstract": "Self-supervised learning (SSL) in graphs has garnered significant attention,\nparticularly in employing Graph Neural Networks (GNNs) with pretext tasks\ninitially designed for other domains, such as contrastive learning and feature\nreconstruction. However, it remains uncertain whether these methods effectively\nreflect essential graph properties, precisely representation similarity with\nits neighbors. We observe that existing methods position opposite ends of a\nspectrum driven by the graph embedding smoothness, with each end corresponding\nto outperformance on specific downstream tasks. Decomposing the SSL objective\ninto three terms via an information-theoretic framework with a neighbor\nrepresentation variable reveals that this polarization stems from an imbalance\namong the terms, which existing methods may not effectively maintain. Further\ninsights suggest that balancing between the extremes can lead to improved\nperformance across a wider range of downstream tasks. A framework, BSG\n(Balancing Smoothness in Graph SSL), introduces novel loss functions designed\nto supplement the representation quality in graph-based SSL by balancing the\nderived three terms: neighbor loss, minimal loss, and divergence loss. We\npresent a theoretical analysis of the effects of these loss functions,\nhighlighting their significance from both the SSL and graph smoothness\nperspectives. Extensive experiments on multiple real-world datasets across node\nclassification and link prediction consistently demonstrate that BSG achieves\nstate-of-the-art performance, outperforming existing methods. Our\nimplementation code is available at https://github.com/steve30572/BSG.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the Web Conference (WWW) 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.12011v1",
    "published_date": "2025-04-16 12:09:56 UTC",
    "updated_date": "2025-04-16 12:09:56 UTC"
  },
  {
    "arxiv_id": "2504.12007v1",
    "title": "Generative Recommendation with Continuous-Token Diffusion",
    "authors": [
      "Haohao Qu",
      "Wenqi Fan",
      "Shanru Lin"
    ],
    "abstract": "In recent years, there has been a significant trend toward using large\nlanguage model (LLM)-based recommender systems (RecSys). Current research\nprimarily focuses on representing complex user-item interactions within a\ndiscrete space to align with the inherent discrete nature of language models.\nHowever, this approach faces limitations due to its discrete nature: (i)\ninformation is often compressed during discretization; (ii) the tokenization\nand generation for the vast number of users and items in real-world scenarios\nare constrained by a limited vocabulary. Embracing continuous data presents a\npromising alternative to enhance expressive capabilities, though this approach\nis still in its early stages. To address this gap, we propose a novel\nframework, DeftRec, which incorporates \\textbf{de}noising di\\textbf{f}fusion\nmodels to enable LLM-based RecSys to seamlessly support continuous\n\\textbf{t}oken as input and target. First, we introduce a robust tokenizer with\na masking operation and an additive K-way architecture to index users and\nitems, capturing their complex collaborative relationships into continuous\ntokens. Crucially, we develop a denoising diffusion model to process user\npreferences within continuous domains by conditioning on reasoning content from\npre-trained large language model. During the denoising process, we reformulate\nthe objective to include negative interactions, building a comprehensive\nunderstanding of user preferences for effective and accurate recommendation\ngeneration. Finally, given a continuous token as output, recommendations can be\neasily generated through score-based retrieval. Extensive experiments\ndemonstrate the effectiveness of the proposed methods, showing that DeftRec\nsurpasses competitive benchmarks, including both traditional and emerging\nLLM-based RecSys.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12007v1",
    "published_date": "2025-04-16 12:01:03 UTC",
    "updated_date": "2025-04-16 12:01:03 UTC"
  },
  {
    "arxiv_id": "2504.11997v1",
    "title": "A Computationally Efficient Algorithm for Infinite-Horizon Average-Reward Linear MDPs",
    "authors": [
      "Kihyuk Hong",
      "Ambuj Tewari"
    ],
    "abstract": "We study reinforcement learning in infinite-horizon average-reward settings\nwith linear MDPs. Previous work addresses this problem by approximating the\naverage-reward setting by discounted setting and employing a value\niteration-based algorithm that uses clipping to constrain the span of the value\nfunction for improved statistical efficiency. However, the clipping procedure\nrequires computing the minimum of the value function over the entire state\nspace, which is prohibitive since the state space in linear MDP setting can be\nlarge or even infinite. In this paper, we introduce a value iteration method\nwith efficient clipping operation that only requires computing the minimum of\nvalue functions over the set of states visited by the algorithm. Our algorithm\nenjoys the same regret bound as the previous work while being computationally\nefficient, with computational complexity that is independent of the size of the\nstate space.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11997v1",
    "published_date": "2025-04-16 11:47:41 UTC",
    "updated_date": "2025-04-16 11:47:41 UTC"
  },
  {
    "arxiv_id": "2504.11986v1",
    "title": "Language Models as Quasi-Crystalline Thought: Structure, Constraint, and Emergence in Generative Systems",
    "authors": [
      "Jose Manuel Guevara-Vela"
    ],
    "abstract": "This essay proposes an analogy between large language models (LLMs) and\nquasicrystals: systems that exhibit global coherence without periodic\nrepetition and that are generated through local constraints. While LLMs are\noften evaluated in terms of predictive accuracy, factuality, or alignment, this\nstructural perspective suggests that their most characteristic behavior is the\nproduction of internally resonant linguistic patterns. Just as quasicrystals\nforced a redefinition of order in physical systems, viewing LLMs as generators\nof quasi-structured language opens new paths for evaluation and design:\nprivileging propagation of constraint over token-level accuracy, and coherence\nof form over fixed meaning. LLM outputs should be read not only for what they\nsay, but for the patterns of constraint and coherence that organize them. This\nshift reframes generative language as a space of emergent patterning: LLMs are\nneither fully random nor strictly rule-based, but defined by a logic of\nconstraint, resonance, and structural depth.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11986v1",
    "published_date": "2025-04-16 11:27:47 UTC",
    "updated_date": "2025-04-16 11:27:47 UTC"
  },
  {
    "arxiv_id": "2504.11977v1",
    "title": "Leveraging Machine Learning Models to Predict the Outcome of Digital Medical Triage Interviews",
    "authors": [
      "Sofia Krylova",
      "Fabian Schmidt",
      "Vladimir Vlassov"
    ],
    "abstract": "Many existing digital triage systems are questionnaire-based, guiding\npatients to appropriate care levels based on information (e.g., symptoms,\nmedical history, and urgency) provided by the patients answering\nquestionnaires. Such a system often uses a deterministic model with predefined\nrules to determine care levels. It faces challenges with incomplete triage\ninterviews since it can only assist patients who finish the process. In this\nstudy, we explore the use of machine learning (ML) to predict outcomes of\nunfinished interviews, aiming to enhance patient care and service quality.\nPredicting triage outcomes from incomplete data is crucial for patient safety\nand healthcare efficiency. Our findings show that decision-tree models,\nparticularly LGBMClassifier and CatBoostClassifier, achieve over 80\\% accuracy\nin predicting outcomes from complete interviews while having a linear\ncorrelation between the prediction accuracy and interview completeness degree.\nFor example, LGBMClassifier achieves 88,2\\% prediction accuracy for interviews\nwith 100\\% completeness, 79,6\\% accuracy for interviews with 80\\% completeness,\n58,9\\% accuracy for 60\\% completeness, and 45,7\\% accuracy for 40\\%\ncompleteness. The TabTransformer model demonstrated exceptional accuracy of\nover 80\\% for all degrees of completeness but required extensive training time,\nindicating a need for more powerful computational resources. The study\nhighlights the linear correlation between interview completeness and predictive\npower of the decision-tree models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 4 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.11977v1",
    "published_date": "2025-04-16 11:17:23 UTC",
    "updated_date": "2025-04-16 11:17:23 UTC"
  },
  {
    "arxiv_id": "2504.11967v2",
    "title": "Securing the Skies: A Comprehensive Survey on Anti-UAV Methods, Benchmarking, and Future Directions",
    "authors": [
      "Yifei Dong",
      "Fengyi Wu",
      "Sanjian Zhang",
      "Guangyu Chen",
      "Yuzhi Hu",
      "Masumi Yano",
      "Jingdong Sun",
      "Siyu Huang",
      "Feng Liu",
      "Qi Dai",
      "Zhi-Qi Cheng"
    ],
    "abstract": "Unmanned Aerial Vehicles (UAVs) are indispensable for infrastructure\ninspection, surveillance, and related tasks, yet they also introduce critical\nsecurity challenges. This survey provides a wide-ranging examination of the\nanti-UAV domain, centering on three core objectives-classification, detection,\nand tracking-while detailing emerging methodologies such as diffusion-based\ndata synthesis, multi-modal fusion, vision-language modeling, self-supervised\nlearning, and reinforcement learning. We systematically evaluate\nstate-of-the-art solutions across both single-modality and multi-sensor\npipelines (spanning RGB, infrared, audio, radar, and RF) and discuss\nlarge-scale as well as adversarially oriented benchmarks. Our analysis reveals\npersistent gaps in real-time performance, stealth detection, and swarm-based\nscenarios, underscoring pressing needs for robust, adaptive anti-UAV systems.\nBy highlighting open research directions, we aim to foster innovation and guide\nthe development of next-generation defense strategies in an era marked by the\nextensive use of UAVs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR Workshop Anti-UAV 2025. 15 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.11967v2",
    "published_date": "2025-04-16 10:58:33 UTC",
    "updated_date": "2025-04-17 09:25:04 UTC"
  },
  {
    "arxiv_id": "2504.11952v1",
    "title": "Robust and Fine-Grained Detection of AI Generated Texts",
    "authors": [
      "Ram Mohan Rao Kadiyala",
      "Siddartha Pullakhandam",
      "Kanwal Mehreen",
      "Drishti Sharma",
      "Siddhant Gupta",
      "Jebish Purbey",
      "Ashay Srivastava",
      "Subhasya TippaReddy",
      "Arvind Reddy Bobbili",
      "Suraj Telugara Chandrashekhar",
      "Modabbir Adeeb",
      "Srinadh Vura",
      "Hamza Farooq"
    ],
    "abstract": "An ideal detection system for machine generated content is supposed to work\nwell on any generator as many more advanced LLMs come into existence day by\nday. Existing systems often struggle with accurately identifying AI-generated\ncontent over shorter texts. Further, not all texts might be entirely authored\nby a human or LLM, hence we focused more over partial cases i.e human-LLM\nco-authored texts. Our paper introduces a set of models built for the task of\ntoken classification which are trained on an extensive collection of\nhuman-machine co-authored texts, which performed well over texts of unseen\ndomains, unseen generators, texts by non-native speakers and those with\nadversarial inputs. We also introduce a new dataset of over 2.4M such texts\nmostly co-authored by several popular proprietary LLMs over 23 languages. We\nalso present findings of our models' performance over each texts of each domain\nand generator. Additional findings include comparison of performance against\neach adversarial method, length of input texts and characteristics of generated\ntexts compared to the original human authored texts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2025 Feb ARR Submission",
    "pdf_url": "http://arxiv.org/pdf/2504.11952v1",
    "published_date": "2025-04-16 10:29:30 UTC",
    "updated_date": "2025-04-16 10:29:30 UTC"
  },
  {
    "arxiv_id": "2504.11944v1",
    "title": "VIPO: Value Function Inconsistency Penalized Offline Reinforcement Learning",
    "authors": [
      "Xuyang Chen",
      "Guojian Wang",
      "Keyu Yan",
      "Lin Zhao"
    ],
    "abstract": "Offline reinforcement learning (RL) learns effective policies from\npre-collected datasets, offering a practical solution for applications where\nonline interactions are risky or costly. Model-based approaches are\nparticularly advantageous for offline RL, owing to their data efficiency and\ngeneralizability. However, due to inherent model errors, model-based methods\noften artificially introduce conservatism guided by heuristic uncertainty\nestimation, which can be unreliable. In this paper, we introduce VIPO, a novel\nmodel-based offline RL algorithm that incorporates self-supervised feedback\nfrom value estimation to enhance model training. Specifically, the model is\nlearned by additionally minimizing the inconsistency between the value learned\ndirectly from the offline data and the one estimated from the model. We perform\ncomprehensive evaluations from multiple perspectives to show that VIPO can\nlearn a highly accurate model efficiently and consistently outperform existing\nmethods. It offers a general framework that can be readily integrated into\nexisting model-based offline RL algorithms to systematically enhance model\naccuracy. As a result, VIPO achieves state-of-the-art performance on almost all\ntasks in both D4RL and NeoRL benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11944v1",
    "published_date": "2025-04-16 10:23:44 UTC",
    "updated_date": "2025-04-16 10:23:44 UTC"
  },
  {
    "arxiv_id": "2504.11942v1",
    "title": "ADAT: Time-Series-Aware Adaptive Transformer Architecture for Sign Language Translation",
    "authors": [
      "Nada Shahin",
      "Leila Ismail"
    ],
    "abstract": "Current sign language machine translation systems rely on recognizing hand\nmovements, facial expressions and body postures, and natural language\nprocessing, to convert signs into text. Recent approaches use Transformer\narchitectures to model long-range dependencies via positional encoding.\nHowever, they lack accuracy in recognizing fine-grained, short-range temporal\ndependencies between gestures captured at high frame rates. Moreover, their\nhigh computational complexity leads to inefficient training. To mitigate these\nissues, we propose an Adaptive Transformer (ADAT), which incorporates\ncomponents for enhanced feature extraction and adaptive feature weighting\nthrough a gating mechanism to emphasize contextually relevant features while\nreducing training overhead and maintaining translation accuracy. To evaluate\nADAT, we introduce MedASL, the first public medical American Sign Language\ndataset. In sign-to-gloss-to-text experiments, ADAT outperforms the\nencoder-decoder transformer, improving BLEU-4 accuracy by 0.1% while reducing\ntraining time by 14.33% on PHOENIX14T and 3.24% on MedASL. In sign-to-text\nexperiments, it improves accuracy by 8.7% and reduces training time by 2.8% on\nPHOENIX14T and achieves 4.7% higher accuracy and 7.17% faster training on\nMedASL. Compared to encoder-only and decoder-only baselines in sign-to-text,\nADAT is at least 6.8% more accurate despite being up to 12.1% slower due to its\ndual-stream structure.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "I.2.6; I.2.7; I.2.10; I.4.8; I.4.9; I.4.10"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11942v1",
    "published_date": "2025-04-16 10:20:11 UTC",
    "updated_date": "2025-04-16 10:20:11 UTC"
  },
  {
    "arxiv_id": "2504.11919v1",
    "title": "Rethinking the Generation of High-Quality CoT Data from the Perspective of LLM-Adaptive Question Difficulty Grading",
    "authors": [
      "Qianjin Yu",
      "Keyu Wu",
      "Zihan Chen",
      "Chushu Zhang",
      "Manlin Mei",
      "Lingjun Huang",
      "Fang Tan",
      "Yongsheng Du",
      "Kunlin Liu",
      "Yurui Zhu"
    ],
    "abstract": "Recently, DeepSeek-R1 (671B) (DeepSeek-AIet al., 2025) has demonstrated its\nexcellent reasoning ability in complex tasks and has publiclyshared its\nmethodology. This provides potentially high-quality chain-of-thought (CoT) data\nfor stimulating the reasoning abilities of small-sized large language models\n(LLMs). To generate high-quality CoT data for different LLMs, we seek an\nefficient method for generating high-quality CoT data with LLM-Adaptive\nquestiondifficulty levels. First, we grade the difficulty of the questions\naccording to the reasoning ability of the LLMs themselves and construct a\nLLM-Adaptive question database. Second, we sample the problem database based on\na distribution of difficulty levels of the questions and then use DeepSeek-R1\n(671B) (DeepSeek-AI et al., 2025) to generate the corresponding high-quality\nCoT data with correct answers. Thanks to the construction of CoT data with\nLLM-Adaptive difficulty levels, we have significantly reduced the cost of data\ngeneration and enhanced the efficiency of model supervised fine-tuning (SFT).\nFinally, we have validated the effectiveness and generalizability of the\nproposed method in the fields of complex mathematical competitions and code\ngeneration tasks. Notably, with only 2k high-quality mathematical CoT data, our\nZMath-32B surpasses DeepSeek-Distill-32B in math reasoning task. Similarly,\nwith only 2k high-quality code CoT data, our ZCode-32B surpasses\nDeepSeek-Distill-32B in code reasoning tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11919v1",
    "published_date": "2025-04-16 09:55:34 UTC",
    "updated_date": "2025-04-16 09:55:34 UTC"
  },
  {
    "arxiv_id": "2504.11901v2",
    "title": "Causality-enhanced Decision-Making for Autonomous Mobile Robots in Dynamic Environments",
    "authors": [
      "Luca Castri",
      "Gloria Beraldo",
      "Nicola Bellotto"
    ],
    "abstract": "The growing integration of robots in shared environments -- such as\nwarehouses, shopping centres, and hospitals -- demands a deep understanding of\nthe underlying dynamics and human behaviours, including how, when, and where\nindividuals engage in various activities and interactions. This knowledge goes\nbeyond simple correlation studies and requires a more comprehensive causal\nanalysis. By leveraging causal inference to model cause-and-effect\nrelationships, we can better anticipate critical environmental factors and\nenable autonomous robots to plan and execute tasks more effectively. To this\nend, we propose a novel causality-based decision-making framework that reasons\nover a learned causal model to predict battery usage and human obstructions,\nunderstanding how these factors could influence robot task execution. Such\nreasoning framework assists the robot in deciding when and how to complete a\ngiven task. To achieve this, we developed also PeopleFlow, a new Gazebo-based\nsimulator designed to model context-sensitive human-robot spatial interactions\nin shared workspaces. PeopleFlow features realistic human and robot\ntrajectories influenced by contextual factors such as time, environment layout,\nand robot state, and can simulate a large number of agents. While the simulator\nis general-purpose, in this paper we focus on a warehouse-like environment as a\ncase study, where we conduct an extensive evaluation benchmarking our causal\napproach against a non-causal baseline. Our findings demonstrate the efficacy\nof the proposed solutions, highlighting how causal reasoning enables autonomous\nrobots to operate more efficiently and safely in dynamic environments shared\nwith humans.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Causal Discovery and Inference - Robot Autonomy - Human-Robot Spatial\n  Interaction - Decision-Making",
    "pdf_url": "http://arxiv.org/pdf/2504.11901v2",
    "published_date": "2025-04-16 09:26:04 UTC",
    "updated_date": "2025-04-17 08:41:44 UTC"
  },
  {
    "arxiv_id": "2504.11896v1",
    "title": "Learning Physics-Informed Color-Aware Transforms for Low-Light Image Enhancement",
    "authors": [
      "Xingxing Yang",
      "Jie Chen",
      "Zaifeng Yang"
    ],
    "abstract": "Image decomposition offers deep insights into the imaging factors of visual\ndata and significantly enhances various advanced computer vision tasks. In this\nwork, we introduce a novel approach to low-light image enhancement based on\ndecomposed physics-informed priors. Existing methods that directly map\nlow-light to normal-light images in the sRGB color space suffer from\ninconsistent color predictions and high sensitivity to spectral power\ndistribution (SPD) variations, resulting in unstable performance under diverse\nlighting conditions. To address these challenges, we introduce a\nPhysics-informed Color-aware Transform (PiCat), a learning-based framework that\nconverts low-light images from the sRGB color space into deep\nillumination-invariant descriptors via our proposed Color-aware Transform\n(CAT). This transformation enables robust handling of complex lighting and SPD\nvariations. Complementing this, we propose the Content-Noise Decomposition\nNetwork (CNDN), which refines the descriptor distributions to better align with\nwell-lit conditions by mitigating noise and other distortions, thereby\neffectively restoring content representations to low-light images. The CAT and\nthe CNDN collectively act as a physical prior, guiding the transformation\nprocess from low-light to normal-light domains. Our proposed PiCat framework\ndemonstrates superior performance compared to state-of-the-art methods across\nfive benchmark datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICME 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.11896v1",
    "published_date": "2025-04-16 09:23:38 UTC",
    "updated_date": "2025-04-16 09:23:38 UTC"
  },
  {
    "arxiv_id": "2504.11882v1",
    "title": "Seeking and leveraging alternative variable dependency concepts in gray-box-elusive bimodal land-use allocation problems",
    "authors": [
      "J. Maciążek",
      "M. W. Przewozniczek",
      "J. Schwaab"
    ],
    "abstract": "Solving land-use allocation problems can help us to deal with some of the\nmost urgent global environmental issues. Since these problems are NP-hard,\neffective optimizers are needed to handle them. The knowledge about variable\ndependencies allows for proposing such tools. However, in this work, we\nconsider a real-world multi-objective problem for which standard variable\ndependency discovery techniques are inapplicable. Therefore, using\nlinkage-based variation operators is unreachable. To address this issue, we\npropose a definition of problem-dedicated variable dependency. On this base, we\npropose obtaining masks of dependent variables. Using them, we construct three\nnovel crossover operators. The results concerning real-world test cases show\nthat introducing our propositions into two well-known optimizers (NSGA-II,\nMOEA/D) dedicated to multi-objective optimization significantly improves their\neffectiveness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11882v1",
    "published_date": "2025-04-16 09:06:55 UTC",
    "updated_date": "2025-04-16 09:06:55 UTC"
  },
  {
    "arxiv_id": "2504.11864v1",
    "title": "Moving between high-quality optima using multi-satisfiability characteristics in hard-to-solve Max3Sat instances",
    "authors": [
      "J. Piatek",
      "M. W. Przewozniczek",
      "F. Chicano",
      "R. Tinós"
    ],
    "abstract": "Gray-box optimization proposes effective and efficient optimizers of general\nuse. To this end, it leverages information about variable dependencies and the\nsubfunction-based problem representation. These approaches were already shown\neffective by enabling \\textit{tunnelling} between local optima even if these\nmoves require the modification of many dependent variables. Tunnelling is\nuseful in solving the maximum satisfiability problem (MaxSat), which can be\nreformulated to Max3Sat. Since many real-world problems can be brought to\nsolving the MaxSat/Max3Sat instances, it is important to solve them effectively\nand efficiently. Therefore, we focus on Max3Sat instances for which tunnelling\nfails to introduce improving moves between locally optimal high-quality\nsolutions and the region of globally optimal solutions. We analyze the features\nof such instances on the ground of phase transitions. Based on these\nobservations, we propose manipulating clause-satisfiability characteristics\nthat allow connecting high-quality solutions distant in the solution space. We\nutilize multi-satisfiability characteristics in the optimizer built from\ntypical gray-box mechanisms. The experimental study shows that the proposed\noptimizer can solve those Max3Sat instances that are out of the grasp of\nstate-of-the-art gray-box optimizers. At the same time, it remains effective\nfor instances that have already been successfully solved by gray-box.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11864v1",
    "published_date": "2025-04-16 08:38:08 UTC",
    "updated_date": "2025-04-16 08:38:08 UTC"
  },
  {
    "arxiv_id": "2504.11855v1",
    "title": "EngramNCA: a Neural Cellular Automaton Model of Memory Transfer",
    "authors": [
      "Etienne Guichard",
      "Felix Reimers",
      "Mia Kvalsund",
      "Mikkel Lepperød",
      "Stefano Nichele"
    ],
    "abstract": "This study introduces EngramNCA, a neural cellular automaton (NCA) that\nintegrates both publicly visible states and private, cell-internal memory\nchannels, drawing inspiration from emerging biological evidence suggesting that\nmemory storage extends beyond synaptic modifications to include intracellular\nmechanisms. The proposed model comprises two components: GeneCA, an NCA trained\nto develop distinct morphologies from seed cells containing immutable \"gene\"\nencodings, and GenePropCA, an auxiliary NCA that modulates the private\n\"genetic\" memory of cells without altering their visible states. This\narchitecture enables the encoding and propagation of complex morphologies\nthrough the interaction of visible and private channels, facilitating the\ngrowth of diverse structures from a shared \"genetic\" substrate. EngramNCA\nsupports the emergence of hierarchical and coexisting morphologies, offering\ninsights into decentralized memory storage and transfer in artificial systems.\nThese findings have potential implications for the development of adaptive,\nself-organizing systems and may contribute to the broader understanding of\nmemory mechanisms in both biological and synthetic contexts.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11855v1",
    "published_date": "2025-04-16 08:23:09 UTC",
    "updated_date": "2025-04-16 08:23:09 UTC"
  },
  {
    "arxiv_id": "2504.11844v1",
    "title": "Evaluating the Goal-Directedness of Large Language Models",
    "authors": [
      "Tom Everitt",
      "Cristina Garbacea",
      "Alexis Bellot",
      "Jonathan Richens",
      "Henry Papadatos",
      "Siméon Campos",
      "Rohin Shah"
    ],
    "abstract": "To what extent do LLMs use their capabilities towards their given goal? We\ntake this as a measure of their goal-directedness. We evaluate\ngoal-directedness on tasks that require information gathering, cognitive\neffort, and plan execution, where we use subtasks to infer each model's\nrelevant capabilities. Our evaluations of LLMs from Google DeepMind, OpenAI,\nand Anthropic show that goal-directedness is relatively consistent across\ntasks, differs from task performance, and is only moderately sensitive to\nmotivational prompts. Notably, most models are not fully goal-directed. We hope\nour goal-directedness evaluations will enable better monitoring of LLM\nprogress, and enable more deliberate design choices of agentic properties in\nLLMs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11844v1",
    "published_date": "2025-04-16 08:07:08 UTC",
    "updated_date": "2025-04-16 08:07:08 UTC"
  },
  {
    "arxiv_id": "2504.11837v1",
    "title": "FiSMiness: A Finite State Machine Based Paradigm for Emotional Support Conversations",
    "authors": [
      "Yue Zhao",
      "Qingqing Gu",
      "Xiaoyu Wang",
      "Teng Chen",
      "Zhonglin Jiang",
      "Yong Chen",
      "Luo Ji"
    ],
    "abstract": "Emotional support conversation (ESC) aims to alleviate the emotional distress\nof individuals through effective conversations. Although large language models\n(LLMs) have obtained remarkable progress on ESC, most of these studies might\nnot define the diagram from the state model perspective, therefore providing a\nsuboptimal solution for long-term satisfaction. To address such an issue, we\nleverage the Finite State Machine (FSM) on LLMs, and propose a framework called\nFiSMiness. Our framework allows a single LLM to bootstrap the planning during\nESC, and self-reason the seeker's emotion, support strategy and the final\nresponse upon each conversational turn. Substantial experiments on ESC datasets\nsuggest that FiSMiness outperforms many baselines, including direct inference,\nself-refine, chain of thought, finetuning, and external-assisted methods, even\nthose with many more parameters.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted by CMCL",
    "pdf_url": "http://arxiv.org/pdf/2504.11837v1",
    "published_date": "2025-04-16 07:52:06 UTC",
    "updated_date": "2025-04-16 07:52:06 UTC"
  },
  {
    "arxiv_id": "2504.11829v1",
    "title": "Déjà Vu: Multilingual LLM Evaluation through the Lens of Machine Translation Evaluation",
    "authors": [
      "Julia Kreutzer",
      "Eleftheria Briakou",
      "Sweta Agrawal",
      "Marzieh Fadaee",
      "Kocmi Tom"
    ],
    "abstract": "Generation capabilities and language coverage of multilingual large language\nmodels (mLLMs) are advancing rapidly. However, evaluation practices for\ngenerative abilities of mLLMs are still lacking comprehensiveness, scientific\nrigor, and consistent adoption across research labs, which undermines their\npotential to meaningfully guide mLLM development. We draw parallels with\nmachine translation (MT) evaluation, a field that faced similar challenges and\nhas, over decades, developed transparent reporting standards and reliable\nevaluations for multilingual generative models. Through targeted experiments\nacross key stages of the generative evaluation pipeline, we demonstrate how\nbest practices from MT evaluation can deepen the understanding of quality\ndifferences between models. Additionally, we identify essential components for\nrobust meta-evaluation of mLLMs, ensuring the evaluation methods themselves are\nrigorously assessed. We distill these insights into a checklist of actionable\nrecommendations for mLLM research and development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11829v1",
    "published_date": "2025-04-16 07:38:19 UTC",
    "updated_date": "2025-04-16 07:38:19 UTC"
  },
  {
    "arxiv_id": "2504.11820v1",
    "title": "Real-World Depth Recovery via Structure Uncertainty Modeling and Inaccurate GT Depth Fitting",
    "authors": [
      "Delong Suzhang",
      "Meng Yang"
    ],
    "abstract": "The low-quality structure in raw depth maps is prevalent in real-world RGB-D\ndatasets, which makes real-world depth recovery a critical task in recent\nyears. However, the lack of paired raw-ground truth (raw-GT) data in the real\nworld poses challenges for generalized depth recovery. Existing methods\ninsufficiently consider the diversity of structure misalignment in raw depth\nmaps, which leads to poor generalization in real-world depth recovery. Notably,\nrandom structure misalignments are not limited to raw depth data but also\naffect GT depth in real-world datasets. In the proposed method, we tackle the\ngeneralization problem from both input and output perspectives. For input, we\nenrich the diversity of structure misalignment in raw depth maps by designing a\nnew raw depth generation pipeline, which helps the network avoid overfitting to\na specific condition. Furthermore, a structure uncertainty module is designed\nto explicitly identify the misaligned structure for input raw depth maps to\nbetter generalize in unseen scenarios. Notably the well-trained depth\nfoundation model (DFM) can help the structure uncertainty module estimate the\nstructure uncertainty better. For output, a robust feature alignment module is\ndesigned to precisely align with the accurate structure of RGB images avoiding\nthe interference of inaccurate GT depth. Extensive experiments on multiple\ndatasets demonstrate the proposed method achieves competitive accuracy and\ngeneralization capabilities across various challenging raw depth maps.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11820v1",
    "published_date": "2025-04-16 07:14:01 UTC",
    "updated_date": "2025-04-16 07:14:01 UTC"
  },
  {
    "arxiv_id": "2504.11812v1",
    "title": "Learning Strategies in Particle Swarm Optimizer: A Critical Review and Performance Analysis",
    "authors": [
      "Dikshit Chauhan",
      "Shivani",
      "P. N. Suganthan"
    ],
    "abstract": "Nature has long inspired the development of swarm intelligence (SI), a key\nbranch of artificial intelligence that models collective behaviors observed in\nbiological systems for solving complex optimization problems. Particle swarm\noptimization (PSO) is widely adopted among SI algorithms due to its simplicity\nand efficiency. Despite numerous learning strategies proposed to enhance PSO's\nperformance in terms of convergence speed, robustness, and adaptability, no\ncomprehensive and systematic analysis of these strategies exists. We review and\nclassify various learning strategies to address this gap, assessing their\nimpact on optimization performance. Additionally, a comparative experimental\nevaluation is conducted to examine how these strategies influence PSO's search\ndynamics. Finally, we discuss open challenges and future directions,\nemphasizing the need for self-adaptive, intelligent PSO variants capable of\naddressing increasingly complex real-world problems.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "53 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.11812v1",
    "published_date": "2025-04-16 06:50:02 UTC",
    "updated_date": "2025-04-16 06:50:02 UTC"
  },
  {
    "arxiv_id": "2504.11793v2",
    "title": "Selective Attention Federated Learning: Improving Privacy and Efficiency for Clinical Text Classification",
    "authors": [
      "Yue Li",
      "Lihong Zhang"
    ],
    "abstract": "Federated Learning (FL) faces major challenges regarding communication\noverhead and model privacy when training large language models (LLMs),\nespecially in healthcare applications. To address these, we introduce Selective\nAttention Federated Learning (SAFL), a novel approach that dynamically\nfine-tunes only those transformer layers identified as attention-critical. By\nemploying attention patterns to determine layer importance, SAFL significantly\nreduces communication bandwidth and enhances differential privacy resilience.\nEvaluations on clinical NLP benchmarks (i2b2 Clinical Concept Extraction and\nMIMIC-III discharge summaries) demonstrate that SAFL achieves competitive\nperformance with centralized models while substantially improving communication\nefficiency and privacy preservation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11793v2",
    "published_date": "2025-04-16 05:59:29 UTC",
    "updated_date": "2025-04-17 06:24:14 UTC"
  },
  {
    "arxiv_id": "2504.11792v1",
    "title": "Large Language Models for Drug Overdose Prediction from Longitudinal Medical Records",
    "authors": [
      "Md Sultan Al Nahian",
      "Chris Delcher",
      "Daniel Harris",
      "Peter Akpunonu",
      "Ramakanth Kavuluru"
    ],
    "abstract": "The ability to predict drug overdose risk from a patient's medical records is\ncrucial for timely intervention and prevention. Traditional machine learning\nmodels have shown promise in analyzing longitudinal medical records for this\ntask. However, recent advancements in large language models (LLMs) offer an\nopportunity to enhance prediction performance by leveraging their ability to\nprocess long textual data and their inherent prior knowledge across diverse\ntasks. In this study, we assess the effectiveness of Open AI's GPT-4o LLM in\npredicting drug overdose events using patients' longitudinal insurance claims\nrecords. We evaluate its performance in both fine-tuned and zero-shot settings,\ncomparing them to strong traditional machine learning methods as baselines. Our\nresults show that LLMs not only outperform traditional models in certain\nsettings but can also predict overdose risk in a zero-shot setting without\ntask-specific training. These findings highlight the potential of LLMs in\nclinical decision support, particularly for drug overdose risk prediction.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11792v1",
    "published_date": "2025-04-16 05:52:22 UTC",
    "updated_date": "2025-04-16 05:52:22 UTC"
  },
  {
    "arxiv_id": "2504.11788v1",
    "title": "Enhancing Web Agents with Explicit Rollback Mechanisms",
    "authors": [
      "Zhisong Zhang",
      "Tianqing Fang",
      "Kaixin Ma",
      "Wenhao Yu",
      "Hongming Zhang",
      "Haitao Mi",
      "Dong Yu"
    ],
    "abstract": "With recent advancements in large language models, web agents have been\ngreatly improved. However, dealing with complex and dynamic web environments\nrequires more advanced planning and search abilities. Previous studies usually\nadopt a greedy one-way search strategy, which may struggle to recover from\nerroneous states. In this work, we enhance web agents with an explicit rollback\nmechanism, enabling the agent to revert back to a previous state in its\nnavigation trajectory. This mechanism gives the model the flexibility to\ndirectly control the search process, leading to an effective and efficient web\nnavigation method. We conduct experiments on two live web navigation benchmarks\nwith zero-shot and fine-tuning settings. The results demonstrate the\neffectiveness of our proposed approach.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11788v1",
    "published_date": "2025-04-16 05:41:20 UTC",
    "updated_date": "2025-04-16 05:41:20 UTC"
  },
  {
    "arxiv_id": "2504.11781v1",
    "title": "ACMamba: Fast Unsupervised Anomaly Detection via An Asymmetrical Consensus State Space Model",
    "authors": [
      "Guanchun Wang",
      "Xiangrong Zhang",
      "Yifei Zhang",
      "Zelin Peng",
      "Tianyang Zhang",
      "Xu Tang",
      "Licheng Jiao"
    ],
    "abstract": "Unsupervised anomaly detection in hyperspectral images (HSI), aiming to\ndetect unknown targets from backgrounds, is challenging for earth surface\nmonitoring. However, current studies are hindered by steep computational costs\ndue to the high-dimensional property of HSI and dense sampling-based training\nparadigm, constraining their rapid deployment. Our key observation is that,\nduring training, not all samples within the same homogeneous area are\nindispensable, whereas ingenious sampling can provide a powerful substitute for\nreducing costs. Motivated by this, we propose an Asymmetrical Consensus State\nSpace Model (ACMamba) to significantly reduce computational costs without\ncompromising accuracy. Specifically, we design an asymmetrical anomaly\ndetection paradigm that utilizes region-level instances as an efficient\nalternative to dense pixel-level samples. In this paradigm, a low-cost\nMamba-based module is introduced to discover global contextual attributes of\nregions that are essential for HSI reconstruction. Additionally, we develop a\nconsensus learning strategy from the optimization perspective to simultaneously\nfacilitate background reconstruction and anomaly compression, further\nalleviating the negative impact of anomaly reconstruction. Theoretical analysis\nand extensive experiments across eight benchmarks verify the superiority of\nACMamba, demonstrating a faster speed and stronger performance over the\nstate-of-the-art.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.11781v1",
    "published_date": "2025-04-16 05:33:42 UTC",
    "updated_date": "2025-04-16 05:33:42 UTC"
  },
  {
    "arxiv_id": "2504.11780v1",
    "title": "Agile Retrospectives: What went well? What didn't go well? What should we do?",
    "authors": [
      "Maria Spichkova",
      "Hina Lee",
      "Kevin Iwan",
      "Madeleine Zwart",
      "Yuwon Yoon",
      "Xiaohan Qin"
    ],
    "abstract": "In Agile/Scrum software development, the idea of retrospective meetings\n(retros) is one of the core elements of the project process. In this paper, we\npresent our work in progress focusing on two aspects: analysis of potential\nusage of generative AI for information interaction within retrospective\nmeetings, and visualisation of retros' information to software development\nteams. We also present our prototype tool RetroAI++, focusing on retros-related\nfunctionalities.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Preprint. Accepted to the 20th International Conference on Evaluation\n  of Novel Approaches to Software Engineering (ENASE 2025). Final version to be\n  published by SCITEPRESS, http://www.scitepress.org",
    "pdf_url": "http://arxiv.org/pdf/2504.11780v1",
    "published_date": "2025-04-16 05:33:35 UTC",
    "updated_date": "2025-04-16 05:33:35 UTC"
  },
  {
    "arxiv_id": "2504.11774v1",
    "title": "PCDiff: Proactive Control for Ownership Protection in Diffusion Models with Watermark Compatibility",
    "authors": [
      "Keke Gai",
      "Ziyue Shen",
      "Jing Yu",
      "Liehuang Zhu",
      "Qi Wu"
    ],
    "abstract": "With the growing demand for protecting the intellectual property (IP) of\ntext-to-image diffusion models, we propose PCDiff -- a proactive access control\nframework that redefines model authorization by regulating generation quality.\nAt its core, PCDIFF integrates a trainable fuser module and hierarchical\nauthentication layers into the decoder architecture, ensuring that only users\nwith valid encrypted credentials can generate high-fidelity images. In the\nabsence of valid keys, the system deliberately degrades output quality,\neffectively preventing unauthorized exploitation.Importantly, while the primary\nmechanism enforces active access control through architectural intervention,\nits decoupled design retains compatibility with existing watermarking\ntechniques. This satisfies the need of model owners to actively control model\nownership while preserving the traceability capabilities provided by\ntraditional watermarking approaches.Extensive experimental evaluations confirm\na strong dependency between credential verification and image quality across\nvarious attack scenarios. Moreover, when combined with typical post-processing\noperations, PCDIFF demonstrates powerful performance alongside conventional\nwatermarking methods. This work shifts the paradigm from passive detection to\nproactive enforcement of authorization, laying the groundwork for IP management\nof diffusion models.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11774v1",
    "published_date": "2025-04-16 05:28:50 UTC",
    "updated_date": "2025-04-16 05:28:50 UTC"
  },
  {
    "arxiv_id": "2504.11765v1",
    "title": "Shared Disk KV Cache Management for Efficient Multi-Instance Inference in RAG-Powered LLMs",
    "authors": [
      "Hyungwoo Lee",
      "Kihyun Kim",
      "Jinwoo Kim",
      "Jungmin So",
      "Myung-Hoon Cha",
      "Hong-Yeon Kim",
      "James J. Kim",
      "Youngjae Kim"
    ],
    "abstract": "Recent large language models (LLMs) face increasing inference latency as\ninput context length and model size continue to grow. In particular, the\nretrieval-augmented generation (RAG) technique, which enhances LLM responses by\nincorporating external knowledge, exacerbates this issue by significantly\nincreasing the number of input tokens. This expansion in token length leads to\na substantial rise in computational overhead, particularly during the prefill\nstage, resulting in prolonged time-to-first-token (TTFT). To address this\nissue, this paper proposes a method to reduce TTFT by leveraging a disk-based\nkey-value (KV) cache to lessen the computational burden during the prefill\nstage. We also introduce a disk-based shared KV cache management system, called\nShared RAG-DCache, for multi-instance LLM RAG service environments. This\nsystem, together with an optimal system configuration, improves both throughput\nand latency under given resource constraints. Shared RAG-DCache exploits the\nlocality of documents related to user queries in RAG, as well as the queueing\ndelay in LLM inference services. It proactively generates and stores disk KV\ncaches for query-related documents and shares them across multiple LLM\ninstances to enhance inference performance. In experiments on a single host\nequipped with 2 GPUs and 1 CPU, Shared RAG-DCache achieved a 15~71% increase in\nthroughput and up to a 12~65% reduction in latency, depending on the resource\nconfiguration.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11765v1",
    "published_date": "2025-04-16 04:59:18 UTC",
    "updated_date": "2025-04-16 04:59:18 UTC"
  },
  {
    "arxiv_id": "2504.11754v1",
    "title": "GrabS: Generative Embodied Agent for 3D Object Segmentation without Scene Supervision",
    "authors": [
      "Zihui Zhang",
      "Yafei Yang",
      "Hongtao Wen",
      "Bo Yang"
    ],
    "abstract": "We study the hard problem of 3D object segmentation in complex point clouds\nwithout requiring human labels of 3D scenes for supervision. By relying on the\nsimilarity of pretrained 2D features or external signals such as motion to\ngroup 3D points as objects, existing unsupervised methods are usually limited\nto identifying simple objects like cars or their segmented objects are often\ninferior due to the lack of objectness in pretrained features. In this paper,\nwe propose a new two-stage pipeline called GrabS. The core concept of our\nmethod is to learn generative and discriminative object-centric priors as a\nfoundation from object datasets in the first stage, and then design an embodied\nagent to learn to discover multiple objects by querying against the pretrained\ngenerative priors in the second stage. We extensively evaluate our method on\ntwo real-world datasets and a newly created synthetic dataset, demonstrating\nremarkable segmentation performance, clearly surpassing all existing\nunsupervised methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025 Spotlight. Code and data are available at:\n  https://github.com/vLAR-group/GrabS",
    "pdf_url": "http://arxiv.org/pdf/2504.11754v1",
    "published_date": "2025-04-16 04:13:53 UTC",
    "updated_date": "2025-04-16 04:13:53 UTC"
  },
  {
    "arxiv_id": "2504.11750v1",
    "title": "Characterizing and Optimizing LLM Inference Workloads on CPU-GPU Coupled Architectures",
    "authors": [
      "Prabhu Vellaisamy",
      "Thomas Labonte",
      "Sourav Chakraborty",
      "Matt Turner",
      "Samantika Sury",
      "John Paul Shen"
    ],
    "abstract": "Large language model (LLM)-based inference workloads increasingly dominate\ndata center costs and resource utilization. Therefore, understanding the\ninference workload characteristics on evolving CPU-GPU coupled architectures is\ncrucial for optimization. This paper presents an in-depth analysis of LLM\ninference behavior on loosely-coupled (PCIe A100/H100) and closely-coupled\n(GH200) systems. We analyze performance dynamics using fine-grained\noperator-to-kernel trace analysis, facilitated by our novel profiler SKIP and\nmetrics like Total Kernel Launch and Queuing Time (TKLQT). Results show that\nclosely-coupled (CC) GH200 significantly outperforms loosely-coupled (LC)\nsystems at large batch sizes, achieving 1.9x-2.7x faster prefill latency for\nLlama 3.2-1B. However, our analysis also reveals that GH200 remains CPU-bound\nup to 4x larger batch sizes than LC systems. In this extended CPU-bound region,\nwe identify the performance characteristics of the Grace CPU as a key factor\ncontributing to higher inference latency at low batch sizes on GH200. We\ndemonstrate that TKLQT accurately identifies this CPU/GPU-bound transition\npoint. Based on this analysis, we further show that kernel fusion offers\nsignificant potential to mitigate GH200's low-batch latency bottleneck by\nreducing kernel launch overhead. This detailed kernel-level characterization\nprovides critical insights for optimizing diverse CPU-GPU coupling strategies.\nThis work is an initial effort, and we plan to explore other major AI/DL\nworkloads that demand different degrees of CPU-GPU heterogeneous architectures.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.AR",
      "cs.PF"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted for ISPASS 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.11750v1",
    "published_date": "2025-04-16 04:02:39 UTC",
    "updated_date": "2025-04-16 04:02:39 UTC"
  },
  {
    "arxiv_id": "2504.11741v1",
    "title": "Climbing the Ladder of Reasoning: What LLMs Can-and Still Can't-Solve after SFT?",
    "authors": [
      "Yiyou Sun",
      "Georgia Zhou",
      "Hao Wang",
      "Dacheng Li",
      "Nouha Dziri",
      "Dawn Song"
    ],
    "abstract": "Recent supervised fine-tuning (SFT) approaches have significantly improved\nlanguage models' performance on mathematical reasoning tasks, even when models\nare trained at a small scale. However, the specific capabilities enhanced\nthrough such fine-tuning remain poorly understood. In this paper, we conduct a\ndetailed analysis of model performance on the AIME24 dataset to understand how\nreasoning capabilities evolve. We discover a ladder-like structure in problem\ndifficulty, categorize questions into four tiers (Easy, Medium, Hard, and\nExtremely Hard (Exh)), and identify the specific requirements for advancing\nbetween tiers. We find that progression from Easy to Medium tier requires\nadopting an R1 reasoning style with minimal SFT (500-1K instances), while\nHard-level questions suffer from frequent model's errors at each step of the\nreasoning chain, with accuracy plateauing at around 65% despite logarithmic\nscaling. Exh-level questions present a fundamentally different challenge; they\nrequire unconventional problem-solving skills that current models uniformly\nstruggle with. Additional findings reveal that carefully curated small-scale\ndatasets offer limited advantage-scaling dataset size proves far more\neffective. Our analysis provides a clearer roadmap for advancing language model\ncapabilities in mathematical reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11741v1",
    "published_date": "2025-04-16 03:39:38 UTC",
    "updated_date": "2025-04-16 03:39:38 UTC"
  },
  {
    "arxiv_id": "2504.11726v1",
    "title": "Saga: Capturing Multi-granularity Semantics from Massive Unlabelled IMU Data for User Perception",
    "authors": [
      "Yunzhe Li",
      "Facheng Hu",
      "Hongzi Zhu",
      "Shifan Zhang",
      "Liang Zhang",
      "Shan Chang",
      "Minyi Guo"
    ],
    "abstract": "Inertial measurement units (IMUs), have been prevalently used in a wide range\nof mobile perception applications such as activity recognition and user\nauthentication, where a large amount of labelled data are normally required to\ntrain a satisfactory model. However, it is difficult to label micro-activities\nin massive IMU data due to the hardness of understanding raw IMU data and the\nlack of ground truth. In this paper, we propose a novel fine-grained user\nperception approach, called Saga, which only needs a small amount of labelled\nIMU data to achieve stunning user perception accuracy. The core idea of Saga is\nto first pre-train a backbone feature extraction model, utilizing the rich\nsemantic information of different levels embedded in the massive unlabelled IMU\ndata. Meanwhile, for a specific downstream user perception application,\nBayesian Optimization is employed to determine the optimal weights for\npre-training tasks involving different semantic levels. We implement Saga on\nfive typical mobile phones and evaluate Saga on three typical tasks on three\nIMU datasets. Results show that when only using about 100 training samples per\nclass, Saga can achieve over 90% accuracy of the full-fledged model trained on\nover ten thousands training samples with no additional system overhead.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "2025 IEEE 45th International Conference on Distributed Computing\n  Systems (ICDCS)",
    "pdf_url": "http://arxiv.org/pdf/2504.11726v1",
    "published_date": "2025-04-16 03:03:42 UTC",
    "updated_date": "2025-04-16 03:03:42 UTC"
  },
  {
    "arxiv_id": "2504.11713v1",
    "title": "Adjoint Sampling: Highly Scalable Diffusion Samplers via Adjoint Matching",
    "authors": [
      "Aaron Havens",
      "Benjamin Kurt Miller",
      "Bing Yan",
      "Carles Domingo-Enrich",
      "Anuroop Sriram",
      "Brandon Wood",
      "Daniel Levine",
      "Bin Hu",
      "Brandon Amos",
      "Brian Karrer",
      "Xiang Fu",
      "Guan-Horng Liu",
      "Ricky T. Q. Chen"
    ],
    "abstract": "We introduce Adjoint Sampling, a highly scalable and efficient algorithm for\nlearning diffusion processes that sample from unnormalized densities, or energy\nfunctions. It is the first on-policy approach that allows significantly more\ngradient updates than the number of energy evaluations and model samples,\nallowing us to scale to much larger problem settings than previously explored\nby similar methods. Our framework is theoretically grounded in stochastic\noptimal control and shares the same theoretical guarantees as Adjoint Matching,\nbeing able to train without the need for corrective measures that push samples\ntowards the target distribution. We show how to incorporate key symmetries, as\nwell as periodic boundary conditions, for modeling molecules in both cartesian\nand torsional coordinates. We demonstrate the effectiveness of our approach\nthrough extensive experiments on classical energy functions, and further scale\nup to neural network-based energy models where we perform amortized conformer\ngeneration across many molecular systems. To encourage further research in\ndeveloping highly scalable sampling methods, we plan to open source these\nchallenging benchmarks, where successful methods can directly impact progress\nin computational chemistry.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11713v1",
    "published_date": "2025-04-16 02:20:06 UTC",
    "updated_date": "2025-04-16 02:20:06 UTC"
  },
  {
    "arxiv_id": "2504.11711v2",
    "title": "The Hitchhiker's Guide to Program Analysis, Part II: Deep Thoughts by LLMs",
    "authors": [
      "Haonan Li",
      "Hang Zhang",
      "Kexin Pei",
      "Zhiyun Qian"
    ],
    "abstract": "Static analysis is a cornerstone for software vulnerability detection, yet it\noften struggles with the classic precision-scalability trade-off. In practice,\nsuch tools often produce high false positive rates, particularly in large\ncodebases like the Linux kernel. This imprecision can arise from simplified\nvulnerability modeling and over-approximation of path and data constraints.\nWhile large language models (LLMs) show promise in code understanding, their\nnaive application to program analysis yields unreliable results due to inherent\nreasoning limitations. We introduce BugLens, a post-refinement framework that\nsignificantly improves static analysis precision. BugLens guides an LLM to\nfollow traditional analysis steps by assessing buggy code patterns for security\nimpact and validating the constraints associated with static warnings.\nEvaluated on real-world Linux kernel bugs, BugLens raises precision from 0.10\n(raw) and 0.50 (semi-automated refinement) to 0.72, substantially reducing\nfalse positives and revealing four previously unreported vulnerabilities. Our\nresults suggest that a structured LLM-based workflow can meaningfully enhance\nthe effectiveness of static analysis tools.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11711v2",
    "published_date": "2025-04-16 02:17:06 UTC",
    "updated_date": "2025-04-17 02:28:35 UTC"
  },
  {
    "arxiv_id": "2504.11707v1",
    "title": "Towards Safe Synthetic Image Generation On the Web: A Multimodal Robust NSFW Defense and Million Scale Dataset",
    "authors": [
      "Muhammad Shahid Muneer",
      "Simon S. Woo"
    ],
    "abstract": "In the past years, we have witnessed the remarkable success of Text-to-Image\n(T2I) models and their widespread use on the web. Extensive research in making\nT2I models produce hyper-realistic images has led to new concerns, such as\ngenerating Not-Safe-For-Work (NSFW) web content and polluting the web society.\nTo help prevent misuse of T2I models and create a safer web environment for\nusers features like NSFW filters and post-hoc security checks are used in these\nmodels. However, recent work unveiled how these methods can easily fail to\nprevent misuse. In particular, adversarial attacks on text and image modalities\ncan easily outplay defensive measures. %Exploiting such leads to the growing\nconcern of preventing adversarial attacks on text and image modalities.\nMoreover, there is currently no robust multimodal NSFW dataset that includes\nboth prompt and image pairs and adversarial examples. This work proposes a\nmillion-scale prompt and image dataset generated using open-source diffusion\nmodels. Second, we develop a multimodal defense to distinguish safe and NSFW\ntext and images, which is robust against adversarial attacks and directly\nalleviates current challenges. Our extensive experiments show that our model\nperforms well against existing SOTA NSFW detection methods in terms of accuracy\nand recall, drastically reducing the Attack Success Rate (ASR) in multimodal\nadversarial attack scenarios. Code:\nhttps://github.com/shahidmuneer/multimodal-nsfw-defense.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Short Paper The Web Conference",
    "pdf_url": "http://arxiv.org/pdf/2504.11707v1",
    "published_date": "2025-04-16 02:10:42 UTC",
    "updated_date": "2025-04-16 02:10:42 UTC"
  },
  {
    "arxiv_id": "2504.11704v1",
    "title": "A Library of LLM Intrinsics for Retrieval-Augmented Generation",
    "authors": [
      "Marina Danilevsky",
      "Kristjan Greenewald",
      "Chulaka Gunasekara",
      "Maeda Hanafi",
      "Lihong He",
      "Yannis Katsis",
      "Krishnateja Killamsetty",
      "Yatin Nandwani",
      "Lucian Popa",
      "Dinesh Raghu",
      "Frederick Reiss",
      "Vraj Shah",
      "Khoi-Nguyen Tran",
      "Huaiyu Zhu",
      "Luis Lastras"
    ],
    "abstract": "In the developer community for large language models (LLMs), there is not yet\na clean pattern analogous to a software library, to support very large scale\ncollaboration. Even for the commonplace use case of Retrieval-Augmented\nGeneration (RAG), it is not currently possible to write a RAG application\nagainst a well-defined set of APIs that are agreed upon by different LLM\nproviders. Inspired by the idea of compiler intrinsics, we propose some\nelements of such a concept through introducing a library of LLM Intrinsics for\nRAG. An LLM intrinsic is defined as a capability that can be invoked through a\nwell-defined API that is reasonably stable and independent of how the LLM\nintrinsic itself is implemented. The intrinsics in our library are released as\nLoRA adapters on HuggingFace, and through a software interface with clear\nstructured input/output characteristics on top of vLLM as an inference\nplatform, accompanied in both places with documentation and code. This article\ndescribes the intended usage, training details, and evaluations for each\nintrinsic, as well as compositions of multiple intrinsics.",
    "categories": [
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11704v1",
    "published_date": "2025-04-16 02:02:22 UTC",
    "updated_date": "2025-04-16 02:02:22 UTC"
  },
  {
    "arxiv_id": "2504.11703v1",
    "title": "Progent: Programmable Privilege Control for LLM Agents",
    "authors": [
      "Tianneng Shi",
      "Jingxuan He",
      "Zhun Wang",
      "Linyu Wu",
      "Hongwei Li",
      "Wenbo Guo",
      "Dawn Song"
    ],
    "abstract": "LLM agents are an emerging form of AI systems where large language models\n(LLMs) serve as the central component, utilizing a diverse set of tools to\ncomplete user-assigned tasks. Despite their great potential, LLM agents pose\nsignificant security risks. When interacting with the external world, they may\nencounter malicious commands from attackers, leading to the execution of\ndangerous actions. A promising way to address this is by enforcing the\nprinciple of least privilege: allowing only essential actions for task\ncompletion while blocking unnecessary ones. However, achieving this is\nchallenging, as it requires covering diverse agent scenarios while preserving\nboth security and utility.\n  We introduce Progent, the first privilege control mechanism for LLM agents.\nAt its core is a domain-specific language for flexibly expressing privilege\ncontrol policies applied during agent execution. These policies provide\nfine-grained constraints over tool calls, deciding when tool calls are\npermissible and specifying fallbacks if they are not. This enables agent\ndevelopers and users to craft suitable policies for their specific use cases\nand enforce them deterministically to guarantee security. Thanks to its modular\ndesign, integrating Progent does not alter agent internals and requires only\nminimal changes to agent implementation, enhancing its practicality and\npotential for widespread adoption. To automate policy writing, we leverage LLMs\nto generate policies based on user queries, which are then updated dynamically\nfor improved security and utility. Our extensive evaluation shows that it\nenables strong security while preserving high utility across three distinct\nscenarios or benchmarks: AgentDojo, ASB, and AgentPoison. Furthermore, we\nperform an in-depth analysis, showcasing the effectiveness of its core\ncomponents and the resilience of its automated policy generation against\nadaptive attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11703v1",
    "published_date": "2025-04-16 01:58:40 UTC",
    "updated_date": "2025-04-16 01:58:40 UTC"
  },
  {
    "arxiv_id": "2504.11686v1",
    "title": "Can GPT tell us why these images are synthesized? Empowering Multimodal Large Language Models for Forensics",
    "authors": [
      "Yiran He",
      "Yun Cao",
      "Bowen Yang",
      "Zeyu Zhang"
    ],
    "abstract": "The rapid development of generative AI facilitates content creation and makes\nimage manipulation easier and more difficult to detect. While multimodal Large\nLanguage Models (LLMs) have encoded rich world knowledge, they are not\ninherently tailored for combating AI-generated Content (AIGC) and struggle to\ncomprehend local forgery details. In this work, we investigate the application\nof multimodal LLMs in forgery detection. We propose a framework capable of\nevaluating image authenticity, localizing tampered regions, providing evidence,\nand tracing generation methods based on semantic tampering clues. Our method\ndemonstrates that the potential of LLMs in forgery analysis can be effectively\nunlocked through meticulous prompt engineering and the application of few-shot\nlearning techniques. We conduct qualitative and quantitative experiments and\nshow that GPT4V can achieve an accuracy of 92.1% in Autosplice and 86.3% in\nLaMa, which is competitive with state-of-the-art AIGC detection methods. We\nfurther discuss the limitations of multimodal LLMs in such tasks and propose\npotential improvements.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 11 figures, 13IHMMSec2025",
    "pdf_url": "http://arxiv.org/pdf/2504.11686v1",
    "published_date": "2025-04-16 01:02:46 UTC",
    "updated_date": "2025-04-16 01:02:46 UTC"
  },
  {
    "arxiv_id": "2504.11671v1",
    "title": "Steering Prosocial AI Agents: Computational Basis of LLM's Decision Making in Social Simulation",
    "authors": [
      "Ji Ma"
    ],
    "abstract": "Large language models (LLMs) increasingly serve as human-like decision-making\nagents in social science and applied settings. These LLM-agents are typically\nassigned human-like characters and placed in real-life contexts. However, how\nthese characters and contexts shape an LLM's behavior remains underexplored.\nThis study proposes and tests methods for probing, quantifying, and modifying\nan LLM's internal representations in a Dictator Game -- a classic behavioral\nexperiment on fairness and prosocial behavior. We extract ``vectors of variable\nvariations'' (e.g., ``male'' to ``female'') from the LLM's internal state.\nManipulating these vectors during the model's inference can substantially alter\nhow those variables relate to the model's decision-making. This approach offers\na principled way to study and regulate how social concepts can be encoded and\nengineered within transformer-based models, with implications for alignment,\ndebiasing, and designing AI agents for social simulations in both academic and\ncommercial applications.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11671v1",
    "published_date": "2025-04-16 00:02:28 UTC",
    "updated_date": "2025-04-16 00:02:28 UTC"
  }
]