[
  {
    "arxiv_id": "2504.08169v3",
    "title": "On the Practice of Deep Hierarchical Ensemble Network for Ad Conversion Rate Prediction",
    "authors": [
      "Jinfeng Zhuang",
      "Yinrui Li",
      "Runze Su",
      "Ke Xu",
      "Zhixuan Shao",
      "Kungang Li",
      "Ling Leng",
      "Han Sun",
      "Meng Qi",
      "Yixiong Meng",
      "Yang Tang",
      "Zhifang Liu",
      "Qifei Shen",
      "Aayush Mudgal",
      "Caleb Lu",
      "Jie Liu",
      "Hongda Shen"
    ],
    "abstract": "The predictions of click through rate (CTR) and conversion rate (CVR) play a\ncrucial role in the success of ad-recommendation systems. A Deep Hierarchical\nEnsemble Network (DHEN) has been proposed to integrate multiple feature\ncrossing modules and has achieved great success in CTR prediction. However, its\nperformance for CVR prediction is unclear in the conversion ads setting, where\nan ad bids for the probability of a user's off-site actions on a third party\nwebsite or app, including purchase, add to cart, sign up, etc. A few challenges\nin DHEN: 1) What feature-crossing modules (MLP, DCN, Transformer, to name a\nfew) should be included in DHEN? 2) How deep and wide should DHEN be to achieve\nthe best trade-off between efficiency and efficacy? 3) What hyper-parameters to\nchoose in each feature-crossing module? Orthogonal to the model architecture,\nthe input personalization features also significantly impact model performance\nwith a high degree of freedom. In this paper, we attack this problem and\npresent our contributions biased to the applied data science side, including:\n  First, we propose a multitask learning framework with DHEN as the single\nbackbone model architecture to predict all CVR tasks, with a detailed study on\nhow to make DHEN work effectively in practice; Second, we build both on-site\nreal-time user behavior sequences and off-site conversion event sequences for\nCVR prediction purposes, and conduct ablation study on its importance; Last but\nnot least, we propose a self-supervised auxiliary loss to predict future\nactions in the input sequence, to help resolve the label sparseness issue in\nCVR prediction.\n  Our method achieves state-of-the-art performance compared to previous single\nfeature crossing modules with pre-trained user personalization features.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by WWW 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.08169v3",
    "published_date": "2025-04-10 23:41:34 UTC",
    "updated_date": "2025-04-23 16:03:11 UTC"
  },
  {
    "arxiv_id": "2504.08161v1",
    "title": "Rethinking the Foundations for Continual Reinforcement Learning",
    "authors": [
      "Michael Bowling",
      "Esraa Elelimy"
    ],
    "abstract": "Algorithms and approaches for continual reinforcement learning have gained\nincreasing attention. Much of this early progress rests on the foundations and\nstandard practices of traditional reinforcement learning, without questioning\nif they are well-suited to the challenges of continual learning agents. We\nsuggest that many core foundations of traditional RL are, in fact, antithetical\nto the goals of continual reinforcement learning. We enumerate four such\nfoundations: the Markov decision process formalism, a focus on optimal\npolicies, the expected sum of rewards as the primary evaluation metric, and\nepisodic benchmark environments that embrace the other three foundations.\nShedding such sacredly held and taught concepts is not easy. They are\nself-reinforcing in that each foundation depends upon and holds up the others,\nmaking it hard to rethink each in isolation. We propose an alternative set of\nall four foundations that are better suited to the continual learning setting.\nWe hope to spur on others in rethinking the traditional foundations, proposing\nand critiquing alternatives, and developing new algorithms and approaches\nenabled by better-suited foundations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08161v1",
    "published_date": "2025-04-10 23:05:56 UTC",
    "updated_date": "2025-04-10 23:05:56 UTC"
  },
  {
    "arxiv_id": "2504.08844v1",
    "title": "Artificial Intelligence Augmented Medical Imaging Reconstruction in Radiation Therapy",
    "authors": [
      "Di Xu"
    ],
    "abstract": "Efficiently acquired and precisely reconstructed imaging are crucial to the\nsuccess of modern radiation therapy (RT). Computed tomography (CT) and magnetic\nresonance imaging (MRI) are two common modalities for providing RT treatment\nplanning and delivery guidance/monitoring. In recent decades, artificial\nintelligence (AI) has emerged as a powerful and widely adopted technique across\nvarious fields, valued for its efficiency and convenience enabled by implicit\nfunction definition and data-driven feature representation learning. Here, we\npresent a series of AI-driven medical imaging reconstruction frameworks for\nenhanced radiotherapy, designed to improve CT image reconstruction quality and\nspeed, refine dual-energy CT (DECT) multi-material decomposition (MMD), and\nsignificantly accelerate 4D MRI acquisition.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2504.08844v1",
    "published_date": "2025-04-10 23:02:45 UTC",
    "updated_date": "2025-04-10 23:02:45 UTC"
  },
  {
    "arxiv_id": "2504.12321v1",
    "title": "AttentionDefense: Leveraging System Prompt Attention for Explainable Defense Against Novel Jailbreaks",
    "authors": [
      "Charlotte Siska",
      "Anush Sankaran"
    ],
    "abstract": "In the past few years, Language Models (LMs) have shown par-human\ncapabilities in several domains. Despite their practical applications and\nexceeding user consumption, they are susceptible to jailbreaks when malicious\ninput exploits the LM's weaknesses, causing it to deviate from its intended\nbehavior. Current defensive strategies either classify the input prompt as\nadversarial or prevent LMs from generating harmful outputs. However, it is\nchallenging to explain the reason behind the malicious nature of the jailbreak,\nwhich results in a wide variety of closed-box approaches. In this research, we\npropose and demonstrate that system-prompt attention from Small Language Models\n(SLMs) can be used to characterize adversarial prompts, providing a novel,\nexplainable, and cheaper defense approach called AttentionDefense. Our research\nsuggests that the attention mechanism is an integral component in understanding\nand explaining how LMs respond to malicious input that is not captured in the\nsemantic meaning of text embeddings. The proposed AttentionDefense is evaluated\nagainst existing jailbreak benchmark datasets. Ablation studies show that\nSLM-based AttentionDefense has equivalent or better jailbreak detection\nperformance compared to text embedding-based classifiers and GPT-4 zero-shot\ndetectors.To further validate the efficacy of the proposed approach, we\ngenerate a dataset of novel jailbreak variants of the existing benchmark\ndataset using a closed-loop LLM-based multi-agent system. We demonstrate that\nthe proposed AttentionDefense approach performs robustly on this novel\njailbreak dataset while existing approaches suffer in performance.\nAdditionally, for practical purposes AttentionDefense is an ideal solution as\nit has the computation requirements of a small LM but the performance of a LLM\ndetector.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12321v1",
    "published_date": "2025-04-10 22:29:23 UTC",
    "updated_date": "2025-04-10 22:29:23 UTC"
  },
  {
    "arxiv_id": "2504.08148v1",
    "title": "Orchestrating Agents and Data for Enterprise: A Blueprint Architecture for Compound AI",
    "authors": [
      "Eser Kandogan",
      "Nikita Bhutani",
      "Dan Zhang",
      "Rafael Li Chen",
      "Sairam Gurajada",
      "Estevam Hruschka"
    ],
    "abstract": "Large language models (LLMs) have gained significant interest in industry due\nto their impressive capabilities across a wide range of tasks. However, the\nwidespread adoption of LLMs presents several challenges, such as integration\ninto existing applications and infrastructure, utilization of company\nproprietary data, models, and APIs, and meeting cost, quality, responsiveness,\nand other requirements. To address these challenges, there is a notable shift\nfrom monolithic models to compound AI systems, with the premise of more\npowerful, versatile, and reliable applications. However, progress thus far has\nbeen piecemeal, with proposals for agentic workflows, programming models, and\nextended LLM capabilities, without a clear vision of an overall architecture.\nIn this paper, we propose a 'blueprint architecture' for compound AI systems\nfor orchestrating agents and data for enterprise applications. In our proposed\narchitecture the key orchestration concept is 'streams' to coordinate the flow\nof data and instructions among agents. Existing proprietary models and APIs in\nthe enterprise are mapped to 'agents', defined in an 'agent registry' that\nserves agent metadata and learned representations for search and planning.\nAgents can utilize proprietary data through a 'data registry' that similarly\nregisters enterprise data of various modalities. Tying it all together, data\nand task 'planners' break down, map, and optimize tasks and queries for given\nquality of service (QoS) requirements such as cost, accuracy, and latency. We\nillustrate an implementation of the architecture for a use-case in the HR\ndomain and discuss opportunities and challenges for 'agentic AI' in the\nenterprise.",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08148v1",
    "published_date": "2025-04-10 22:19:41 UTC",
    "updated_date": "2025-04-10 22:19:41 UTC"
  },
  {
    "arxiv_id": "2504.08115v1",
    "title": "Benchmarking Suite for Synthetic Aperture Radar Imagery Anomaly Detection (SARIAD) Algorithms",
    "authors": [
      "Lucian Chauvin",
      "Somil Gupta",
      "Angelina Ibarra",
      "Joshua Peeples"
    ],
    "abstract": "Anomaly detection is a key research challenge in computer vision and machine\nlearning with applications in many fields from quality control to radar\nimaging. In radar imaging, specifically synthetic aperture radar (SAR), anomaly\ndetection can be used for the classification, detection, and segmentation of\nobjects of interest. However, there is no method for developing and\nbenchmarking these methods on SAR imagery. To address this issue, we introduce\nSAR imagery anomaly detection (SARIAD). In conjunction with Anomalib, a\ndeep-learning library for anomaly detection, SARIAD provides a comprehensive\nsuite of algorithms and datasets for assessing and developing anomaly detection\napproaches on SAR imagery. SARIAD specifically integrates multiple SAR datasets\nalong with tools to effectively apply various anomaly detection algorithms to\nSAR imagery. Several anomaly detection metrics and visualizations are\navailable. Overall, SARIAD acts as a central package for benchmarking SAR\nmodels and datasets to allow for reproducible research in the field of anomaly\ndetection in SAR imagery. This package is publicly available:\nhttps://github.com/Advanced-Vision-and-Learning-Lab/SARIAD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to SPIE at:\n  https://spie.org/defense-commercial-sensing/presentation/Benchmarking-suite-for-synthetic-aperture-radar-imagery-anomaly-detection-SARIAD/13456-3",
    "pdf_url": "http://arxiv.org/pdf/2504.08115v1",
    "published_date": "2025-04-10 20:31:25 UTC",
    "updated_date": "2025-04-10 20:31:25 UTC"
  },
  {
    "arxiv_id": "2504.16942v1",
    "title": "S2Vec: Self-Supervised Geospatial Embeddings",
    "authors": [
      "Shushman Choudhury",
      "Elad Aharoni",
      "Chandrakumari Suvarna",
      "Iveel Tsogsuren",
      "Abdul Rahman Kreidieh",
      "Chun-Ta Lu",
      "Neha Arora"
    ],
    "abstract": "Scalable general-purpose representations of the built environment are crucial\nfor geospatial artificial intelligence applications. This paper introduces\nS2Vec, a novel self-supervised framework for learning such geospatial\nembeddings. S2Vec uses the S2 Geometry library to partition large areas into\ndiscrete S2 cells, rasterizes built environment feature vectors within cells as\nimages, and applies masked autoencoding on these rasterized images to encode\nthe feature vectors. This approach yields task-agnostic embeddings that capture\nlocal feature characteristics and broader spatial relationships. We evaluate\nS2Vec on three large-scale socioeconomic prediction tasks, showing its\ncompetitive performance against state-of-the-art image-based embeddings. We\nalso explore the benefits of combining S2Vec embeddings with image-based\nembeddings downstream, showing that such multimodal fusion can often improve\nperformance. Our results highlight how S2Vec can learn effective\ngeneral-purpose geospatial representations and how it can complement other data\nmodalities in geospatial artificial intelligence.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.SI",
    "comment": "To be submitted to ACM Transactions on Spatial Algorithms and Systems",
    "pdf_url": "http://arxiv.org/pdf/2504.16942v1",
    "published_date": "2025-04-10 20:16:02 UTC",
    "updated_date": "2025-04-10 20:16:02 UTC"
  },
  {
    "arxiv_id": "2504.08104v1",
    "title": "Geneshift: Impact of different scenario shift on Jailbreaking LLM",
    "authors": [
      "Tianyi Wu",
      "Zhiwei Xue",
      "Yue Liu",
      "Jiaheng Zhang",
      "Bryan Hooi",
      "See-Kiong Ng"
    ],
    "abstract": "Jailbreak attacks, which aim to cause LLMs to perform unrestricted behaviors,\nhave become a critical and challenging direction in AI safety. Despite\nachieving the promising attack success rate using dictionary-based evaluation,\nexisting jailbreak attack methods fail to output detailed contents to satisfy\nthe harmful request, leading to poor performance on GPT-based evaluation. To\nthis end, we propose a black-box jailbreak attack termed GeneShift, by using a\ngenetic algorithm to optimize the scenario shifts. Firstly, we observe that the\nmalicious queries perform optimally under different scenario shifts. Based on\nit, we develop a genetic algorithm to evolve and select the hybrid of scenario\nshifts. It guides our method to elicit detailed and actionable harmful\nresponses while keeping the seemingly benign facade, improving stealthiness.\nExtensive experiments demonstrate the superiority of GeneShift. Notably,\nGeneShift increases the jailbreak success rate from 0% to 60% when direct\nprompting alone would fail.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08104v1",
    "published_date": "2025-04-10 20:02:35 UTC",
    "updated_date": "2025-04-10 20:02:35 UTC"
  },
  {
    "arxiv_id": "2504.08102v1",
    "title": "Multi-view autoencoders for Fake News Detection",
    "authors": [
      "Ingryd V. S. T. Pereira",
      "George D. C. Cavalcanti",
      "Rafael M. O. Cruz"
    ],
    "abstract": "Given the volume and speed at which fake news spreads across social media,\nautomatic fake news detection has become a highly important task. However, this\ntask presents several challenges, including extracting textual features that\ncontain relevant information about fake news. Research about fake news\ndetection shows that no single feature extraction technique consistently\noutperforms the others across all scenarios. Nevertheless, different feature\nextraction techniques can provide complementary information about the textual\ndata and enable a more comprehensive representation of the content. This paper\nproposes using multi-view autoencoders to generate a joint feature\nrepresentation for fake news detection by integrating several feature\nextraction techniques commonly used in the literature. Experiments on fake news\ndatasets show a significant improvement in classification performance compared\nto individual views (feature representations). We also observed that selecting\na subset of the views instead of composing a latent space with all the views\ncan be advantageous in terms of accuracy and computational effort. For further\ndetails, including source codes, figures, and datasets, please refer to the\nproject's repository: https://github.com/ingrydpereira/multiview-fake-news.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IEEE Symposium Series on Computational Intelligence -\n  IEEE SSCI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.08102v1",
    "published_date": "2025-04-10 19:59:34 UTC",
    "updated_date": "2025-04-10 19:59:34 UTC"
  },
  {
    "arxiv_id": "2504.08096v1",
    "title": "Cellular Development Follows the Path of Minimum Action",
    "authors": [
      "Rohola Zandie",
      "Farhan Khodaee",
      "Yufan Xia",
      "Elazer R. Edelman"
    ],
    "abstract": "Cellular development follows a stochastic yet rule-governed trajectory,\nthough the underlying principles remain elusive. Here, we propose that cellular\ndevelopment follows paths of least action, aligning with foundational physical\nlaws that govern dynamic systems across nature. We introduce a computational\nframework that takes advantage of the deep connection between the principle of\nleast action and maximum entropy to model developmental processes using\nTransformers architecture. This approach enables precise quantification of\nentropy production, information flow curvature, and local irreversibility for\ndevelopmental asymmetry in single-cell RNA sequence data. Within this unified\nframework, we provide interpretable metrics: entropy to capture\nexploration-exploitation trade-offs, curvature to assess plasticity-elasticity\ndynamics, and entropy production to characterize dedifferentiation and\ntransdifferentiation. We validate our method across both single-cell and\nembryonic development datasets, demonstrating its ability to reveal hidden\nthermodynamic and informational constraints shaping cellular fate decisions.",
    "categories": [
      "physics.bio-ph",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "physics.bio-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08096v1",
    "published_date": "2025-04-10 19:44:29 UTC",
    "updated_date": "2025-04-10 19:44:29 UTC"
  },
  {
    "arxiv_id": "2504.12320v1",
    "title": "Has the Creativity of Large-Language Models peaked? An analysis of inter- and intra-LLM variability",
    "authors": [
      "Jennifer Haase",
      "Paul H. P. Hanel",
      "Sebastian Pokutta"
    ],
    "abstract": "Following the widespread adoption of ChatGPT in early 2023, numerous studies\nreported that large language models (LLMs) can match or even surpass human\nperformance in creative tasks. However, it remains unclear whether LLMs have\nbecome more creative over time, and how consistent their creative output is. In\nthis study, we evaluated 14 widely used LLMs -- including GPT-4, Claude, Llama,\nGrok, Mistral, and DeepSeek -- across two validated creativity assessments: the\nDivergent Association Task (DAT) and the Alternative Uses Task (AUT). Contrary\nto expectations, we found no evidence of increased creative performance over\nthe past 18-24 months, with GPT-4 performing worse than in previous studies.\nFor the more widely used AUT, all models performed on average better than the\naverage human, with GPT-4o and o3-mini performing best. However, only 0.28% of\nLLM-generated responses reached the top 10% of human creativity benchmarks.\nBeyond inter-model differences, we document substantial intra-model\nvariability: the same LLM, given the same prompt, can produce outputs ranging\nfrom below-average to original. This variability has important implications for\nboth creativity research and practical applications. Ignoring such variability\nrisks misjudging the creative potential of LLMs, either inflating or\nunderestimating their capabilities. The choice of prompts affected LLMs\ndifferently. Our findings underscore the need for more nuanced evaluation\nframeworks and highlight the importance of model selection, prompt design, and\nrepeated assessment when using Generative AI (GenAI) tools in creative\ncontexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages + Appendix, 13 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.12320v1",
    "published_date": "2025-04-10 19:18:56 UTC",
    "updated_date": "2025-04-10 19:18:56 UTC"
  },
  {
    "arxiv_id": "2504.08840v1",
    "title": "Adaptive Shrinkage Estimation For Personalized Deep Kernel Regression In Modeling Brain Trajectories",
    "authors": [
      "Vasiliki Tassopoulou",
      "Haochang Shou",
      "Christos Davatzikos"
    ],
    "abstract": "Longitudinal biomedical studies monitor individuals over time to capture\ndynamics in brain development, disease progression, and treatment effects.\nHowever, estimating trajectories of brain biomarkers is challenging due to\nbiological variability, inconsistencies in measurement protocols (e.g.,\ndifferences in MRI scanners), scarcity, and irregularity in longitudinal\nmeasurements. Herein, we introduce a novel personalized deep kernel regression\nframework for forecasting brain biomarkers, with application to regional\nvolumetric measurements. Our approach integrates two key components: a\npopulation model that captures brain trajectories from a large and diverse\ncohort, and a subject-specific model that captures individual trajectories. To\noptimally combine these, we propose Adaptive Shrinkage Estimation, which\neffectively balances population and subject-specific models. We assess our\nmodel's performance through predictive accuracy metrics, uncertainty\nquantification, and validation against external clinical studies. Benchmarking\nagainst state-of-the-art statistical and machine learning models -- including\nlinear mixed effects models, generalized additive models, and deep learning\nmethods -- demonstrates the superior predictive performance of our approach.\nAdditionally, we apply our method to predict trajectories of composite\nneuroimaging biomarkers, which highlights the versatility of our approach in\nmodeling the progression of longitudinal neuroimaging biomarkers. Furthermore,\nvalidation on three external neuroimaging studies confirms the robustness of\nour method across different clinical contexts. We make the code available at\nhttps://github.com/vatass/AdaptiveShrinkageDKGP.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08840v1",
    "published_date": "2025-04-10 19:13:44 UTC",
    "updated_date": "2025-04-10 19:13:44 UTC"
  },
  {
    "arxiv_id": "2504.08066v1",
    "title": "The AI Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search",
    "authors": [
      "Yutaro Yamada",
      "Robert Tjarko Lange",
      "Cong Lu",
      "Shengran Hu",
      "Chris Lu",
      "Jakob Foerster",
      "Jeff Clune",
      "David Ha"
    ],
    "abstract": "AI is increasingly playing a pivotal role in transforming how scientific\ndiscoveries are made. We introduce The AI Scientist-v2, an end-to-end agentic\nsystem capable of producing the first entirely AI generated\npeer-review-accepted workshop paper. This system iteratively formulates\nscientific hypotheses, designs and executes experiments, analyzes and\nvisualizes data, and autonomously authors scientific manuscripts. Compared to\nits predecessor (v1, Lu et al., 2024 arXiv:2408.06292), The AI Scientist-v2\neliminates the reliance on human-authored code templates, generalizes\neffectively across diverse machine learning domains, and leverages a novel\nprogressive agentic tree-search methodology managed by a dedicated experiment\nmanager agent. Additionally, we enhance the AI reviewer component by\nintegrating a Vision-Language Model (VLM) feedback loop for iterative\nrefinement of content and aesthetics of the figures. We evaluated The AI\nScientist-v2 by submitting three fully autonomous manuscripts to a\npeer-reviewed ICLR workshop. Notably, one manuscript achieved high enough\nscores to exceed the average human acceptance threshold, marking the first\ninstance of a fully AI-generated paper successfully navigating a peer review.\nThis accomplishment highlights the growing capability of AI in conducting all\naspects of scientific research. We anticipate that further advancements in\nautonomous scientific discovery technologies will profoundly impact human\nknowledge generation, enabling unprecedented scalability in research\nproductivity and significantly accelerating scientific breakthroughs, greatly\nbenefiting society at large. We have open-sourced the code at\nhttps://github.com/SakanaAI/AI-Scientist-v2 to foster the future development of\nthis transformative technology. We also discuss the role of AI in science,\nincluding AI safety.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08066v1",
    "published_date": "2025-04-10 18:44:41 UTC",
    "updated_date": "2025-04-10 18:44:41 UTC"
  },
  {
    "arxiv_id": "2504.08061v1",
    "title": "STEI-PCN: an efficient pure convolutional network for traffic prediction via spatial-temporal encoding and inferring",
    "authors": [
      "Kai Hu",
      "Zhidan Zhao",
      "Zhifeng Hao"
    ],
    "abstract": "Traffic data exhibits complex temporal, spatial, and spatial-temporal\ncorrelations. Most of models use either independent modules to separately\nextract temporal and spatial correlations or joint modules to synchronously\nextract them, without considering the spatial-temporal correlations. Moreover,\nmodels that consider joint spatial-temporal correlations (temporal, spatial,\nand spatial-temporal correlations) often encounter significant challenges in\naccuracy and computational efficiency which prevent such models from\ndemonstrating the expected advantages of a joint spatial-temporal correlations\narchitecture. To address these issues, this paper proposes an efficient pure\nconvolutional network for traffic prediction via spatial-temporal encoding and\ninferring (STEI-PCN). The model introduces and designs a dynamic adjacency\nmatrix inferring module based on absolute spatial and temporal coordinates, as\nwell as relative spatial and temporal distance encoding, using a graph\nconvolutional network combined with gating mechanism to capture local\nsynchronous joint spatial-temporal correlations. Additionally, three layers of\ntemporal dilated causal convolutional network are used to capture long-range\ntemporal correlations. Finally, through multi-view collaborative prediction\nmodule, the model integrates the gated-activated original, local synchronous\njoint spatial-temporal, and long-range temporal features to achieve\ncomprehensive prediction. This study conducts extensive experiments on flow\ndatasets (PeMS03/04/07/08) and speed dataset (PeMS-Bay), covering multiple\nprediction horizons. The results show that STEI-PCN demonstrates competitive\ncomputational efficiency in both training and inference speeds, and achieves\nsuperior or slightly inferior to state-of-the-art (SOTA) models on most\nevaluation metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08061v1",
    "published_date": "2025-04-10 18:32:56 UTC",
    "updated_date": "2025-04-10 18:32:56 UTC"
  },
  {
    "arxiv_id": "2504.08057v1",
    "title": "Vector Quantized-Elites: Unsupervised and Problem-Agnostic Quality-Diversity Optimization",
    "authors": [
      "Constantinos Tsakonas",
      "Konstantinos Chatzilygeroudis"
    ],
    "abstract": "Quality-Diversity algorithms have transformed optimization by prioritizing\nthe discovery of diverse, high-performing solutions over a single optimal\nresult. However, traditional Quality-Diversity methods, such as MAP-Elites,\nrely heavily on predefined behavioral descriptors and complete prior knowledge\nof the task to define the behavioral space grid, limiting their flexibility and\napplicability. In this work, we introduce Vector Quantized-Elites (VQ-Elites),\na novel Quality-Diversity algorithm that autonomously constructs a structured\nbehavioral space grid using unsupervised learning, eliminating the need for\nprior task-specific knowledge. At the core of VQ-Elites is the integration of\nVector Quantized Variational Autoencoders, which enables the dynamic learning\nof behavioral descriptors and the generation of a structured, rather than\nunstructured, behavioral space grid - a significant advancement over existing\nunsupervised Quality-Diversity approaches. This design establishes VQ-Elites as\na flexible, robust, and task-agnostic optimization framework. To further\nenhance the performance of unsupervised Quality-Diversity algorithms, we\nintroduce two key components: behavioral space bounding and cooperation\nmechanisms, which significantly improve convergence and performance. We\nvalidate VQ-Elites on robotic arm pose-reaching and mobile robot space-covering\ntasks. The results demonstrate its ability to efficiently generate diverse,\nhigh-quality solutions, emphasizing its adaptability, scalability, robustness\nto hyperparameters, and potential to extend Quality-Diversity optimization to\ncomplex, previously inaccessible domains.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.NE",
    "comment": "12 pages, 10 figures, 2 algorithms, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.08057v1",
    "published_date": "2025-04-10 18:23:19 UTC",
    "updated_date": "2025-04-10 18:23:19 UTC"
  },
  {
    "arxiv_id": "2504.08838v1",
    "title": "SD$^2$: Self-Distilled Sparse Drafters",
    "authors": [
      "Mike Lasby",
      "Nish Sinnadurai",
      "Valavan Manohararajah",
      "Sean Lie",
      "Vithursan Thangarasa"
    ],
    "abstract": "Speculative decoding is a powerful technique for reducing the latency of\nLarge Language Models (LLMs), offering a fault-tolerant framework that enables\nthe use of highly compressed draft models. In this work, we introduce\nSelf-Distilled Sparse Drafters (SD$^2$), a novel methodology that leverages\nself-data distillation and fine-grained weight sparsity to produce highly\nefficient and well-aligned draft models. SD$^2$ systematically enhances draft\ntoken acceptance rates while significantly reducing Multiply-Accumulate\noperations (MACs), even in the Universal Assisted Generation (UAG) setting,\nwhere draft and target models originate from different model families. On a\nLlama-3.1-70B target model, SD$^2$ provides a $\\times$1.59 higher Mean Accepted\nLength (MAL) compared to layer-pruned draft models and reduces MACs by over\n43.87% with a 8.36% reduction in MAL compared to a dense draft models. Our\nresults highlight the potential of sparsity-aware fine-tuning and compression\nstrategies to improve LLM inference efficiency while maintaining alignment with\ntarget models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.0; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.08838v1",
    "published_date": "2025-04-10 18:21:17 UTC",
    "updated_date": "2025-04-10 18:21:17 UTC"
  },
  {
    "arxiv_id": "2504.08054v1",
    "title": "Multi-Task Learning with Multi-Annotation Triplet Loss for Improved Object Detection",
    "authors": [
      "Meilun Zhou",
      "Aditya Dutt",
      "Alina Zare"
    ],
    "abstract": "Triplet loss traditionally relies only on class labels and does not use all\navailable information in multi-task scenarios where multiple types of\nannotations are available. This paper introduces a Multi-Annotation Triplet\nLoss (MATL) framework that extends triplet loss by incorporating additional\nannotations, such as bounding box information, alongside class labels in the\nloss formulation. By using these complementary annotations, MATL improves\nmulti-task learning for tasks requiring both classification and localization.\nExperiments on an aerial wildlife imagery dataset demonstrate that MATL\noutperforms conventional triplet loss in both classification and localization.\nThese findings highlight the benefit of using all available annotations for\ntriplet loss in multi-task learning frameworks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for Oral Presentation at the 45th IEEE International\n  Geoscience and Remote Sensing Symposium (IGARSS), 2025, Brisbane, Australia.\n  4 pages and 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.08054v1",
    "published_date": "2025-04-10 18:20:31 UTC",
    "updated_date": "2025-04-10 18:20:31 UTC"
  },
  {
    "arxiv_id": "2504.08051v1",
    "title": "Compositional Flows for 3D Molecule and Synthesis Pathway Co-design",
    "authors": [
      "Tony Shen",
      "Seonghwan Seo",
      "Ross Irwin",
      "Kieran Didi",
      "Simon Olsson",
      "Woo Youn Kim",
      "Martin Ester"
    ],
    "abstract": "Many generative applications, such as synthesis-based 3D molecular design,\ninvolve constructing compositional objects with continuous features. Here, we\nintroduce Compositional Generative Flows (CGFlow), a novel framework that\nextends flow matching to generate objects in compositional steps while modeling\ncontinuous states. Our key insight is that modeling compositional state\ntransitions can be formulated as a straightforward extension of the flow\nmatching interpolation process. We further build upon the theoretical\nfoundations of generative flow networks (GFlowNets), enabling reward-guided\nsampling of compositional structures. We apply CGFlow to synthesizable drug\ndesign by jointly designing the molecule's synthetic pathway with its 3D\nbinding pose. Our approach achieves state-of-the-art binding affinity on all 15\ntargets from the LIT-PCBA benchmark, and 5.8$\\times$ improvement in sampling\nefficiency compared to 2D synthesis-based baseline. To our best knowledge, our\nmethod is also the first to achieve state of-art-performance in both Vina Dock\n(-9.38) and AiZynth success rate (62.2\\%) on the CrossDocked benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Spotlighted at ICLR 2025 GEM and AI4Mat workshops, 29 pages, 7\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2504.08051v1",
    "published_date": "2025-04-10 18:10:34 UTC",
    "updated_date": "2025-04-10 18:10:34 UTC"
  },
  {
    "arxiv_id": "2504.08040v2",
    "title": "Can Reasoning LLMs Enhance Clinical Document Classification?",
    "authors": [
      "Akram Mustafa",
      "Usman Naseem",
      "Mostafa Rahimi Azghadi"
    ],
    "abstract": "Clinical document classification is essential for converting unstructured\nmedical texts into standardised ICD-10 diagnoses, yet it faces challenges due\nto complex medical language, privacy constraints, and limited annotated\ndatasets. Large Language Models (LLMs) offer promising improvements in accuracy\nand efficiency for this task. This study evaluates the performance and\nconsistency of eight LLMs; four reasoning (Qwen QWQ, Deepseek Reasoner, GPT o3\nMini, Gemini 2.0 Flash Thinking) and four non-reasoning (Llama 3.3, GPT 4o\nMini, Gemini 2.0 Flash, Deepseek Chat); in classifying clinical discharge\nsummaries using the MIMIC-IV dataset. Using cTAKES to structure clinical\nnarratives, models were assessed across three experimental runs, with majority\nvoting determining final predictions. Results showed that reasoning models\noutperformed non-reasoning models in accuracy (71% vs 68%) and F1 score (67% vs\n60%), with Gemini 2.0 Flash Thinking achieving the highest accuracy (75%) and\nF1 score (76%). However, non-reasoning models demonstrated greater stability\n(91% vs 84% consistency). Performance varied across ICD-10 codes, with\nreasoning models excelling in complex cases but struggling with abstract\ncategories. Findings indicate a trade-off between accuracy and consistency,\nsuggesting that a hybrid approach could optimise clinical coding. Future\nresearch should explore multi-label classification, domain-specific\nfine-tuning, and ensemble methods to enhance model reliability in real-world\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "27 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.08040v2",
    "published_date": "2025-04-10 18:00:27 UTC",
    "updated_date": "2025-04-24 19:02:05 UTC"
  },
  {
    "arxiv_id": "2504.07956v1",
    "title": "VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning",
    "authors": [
      "Yukun Qi",
      "Yiming Zhao",
      "Yu Zeng",
      "Xikun Bao",
      "Wenxuan Huang",
      "Lin Chen",
      "Zehui Chen",
      "Jie Zhao",
      "Zhongang Qi",
      "Feng Zhao"
    ],
    "abstract": "The advancement of Chain-of-Thought (CoT) reasoning has significantly\nenhanced the capabilities of large language models (LLMs) and large\nvision-language models (LVLMs). However, a rigorous evaluation framework for\nvideo CoT reasoning remains absent. Current video benchmarks fail to adequately\nassess the reasoning process and expose whether failures stem from deficiencies\nin perception or reasoning capabilities. Therefore, we introduce VCR-Bench, a\nnovel benchmark designed to comprehensively evaluate LVLMs' Video\nChain-of-Thought Reasoning capabilities. VCR-Bench comprises 859 videos\nspanning a variety of video content and durations, along with 1,034\nhigh-quality question-answer pairs. Each pair is manually annotated with a\nstepwise CoT rationale, where every step is tagged to indicate its association\nwith the perception or reasoning capabilities. Furthermore, we design seven\ndistinct task dimensions and propose the CoT score to assess the entire CoT\nprocess based on the stepwise tagged CoT rationals. Extensive experiments on\nVCR-Bench highlight substantial limitations in current LVLMs. Even the\ntop-performing model, o1, only achieves a 62.8% CoT score and an 56.7%\naccuracy, while most models score below 40%. Experiments show most models score\nlower on perception than reasoning steps, revealing LVLMs' key bottleneck in\ntemporal-spatial information processing for complex video reasoning. A robust\npositive correlation between the CoT score and accuracy confirms the validity\nof our evaluation framework and underscores the critical role of CoT reasoning\nin solving complex video reasoning tasks. We hope VCR-Bench to serve as a\nstandardized evaluation framework and expose the actual drawbacks in complex\nvideo reasoning task.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07956v1",
    "published_date": "2025-04-10 17:59:03 UTC",
    "updated_date": "2025-04-10 17:59:03 UTC"
  },
  {
    "arxiv_id": "2504.07945v1",
    "title": "GenEAva: Generating Cartoon Avatars with Fine-Grained Facial Expressions from Realistic Diffusion-based Faces",
    "authors": [
      "Hao Yu",
      "Rupayan Mallick",
      "Margrit Betke",
      "Sarah Adel Bargal"
    ],
    "abstract": "Cartoon avatars have been widely used in various applications, including\nsocial media, online tutoring, and gaming. However, existing cartoon avatar\ndatasets and generation methods struggle to present highly expressive avatars\nwith fine-grained facial expressions and are often inspired from real-world\nidentities, raising privacy concerns. To address these challenges, we propose a\nnovel framework, GenEAva, for generating high-quality cartoon avatars with\nfine-grained facial expressions. Our approach fine-tunes a state-of-the-art\ntext-to-image diffusion model to synthesize highly detailed and expressive\nfacial expressions. We then incorporate a stylization model that transforms\nthese realistic faces into cartoon avatars while preserving both identity and\nexpression. Leveraging this framework, we introduce the first expressive\ncartoon avatar dataset, GenEAva 1.0, specifically designed to capture 135\nfine-grained facial expressions, featuring 13,230 expressive cartoon avatars\nwith a balanced distribution across genders, racial groups, and age ranges. We\ndemonstrate that our fine-tuned model generates more expressive faces than the\nstate-of-the-art text-to-image diffusion model SDXL. We also verify that the\ncartoon avatars generated by our framework do not include memorized identities\nfrom fine-tuning data. The proposed framework and dataset provide a diverse and\nexpressive benchmark for future research in cartoon avatar generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07945v1",
    "published_date": "2025-04-10 17:54:02 UTC",
    "updated_date": "2025-04-10 17:54:02 UTC"
  },
  {
    "arxiv_id": "2504.07936v1",
    "title": "We Are All Creators: Generative AI, Collective Knowledge, and the Path Towards Human-AI Synergy",
    "authors": [
      "Jordi Linares-Pellicer",
      "Juan Izquierdo-Domenech",
      "Isabel Ferri-Molla",
      "Carlos Aliaga-Torro"
    ],
    "abstract": "Generative AI presents a profound challenge to traditional notions of human\nuniqueness, particularly in creativity. Fueled by neural network based\nfoundation models, these systems demonstrate remarkable content generation\ncapabilities, sparking intense debates about authorship, copyright, and\nintelligence itself. This paper argues that generative AI represents an\nalternative form of intelligence and creativity, operating through mathematical\npattern synthesis rather than biological understanding or verbatim replication.\nThe fundamental differences between artificial and biological neural networks\nreveal AI learning as primarily statistical pattern extraction from vast\ndatasets crystallized forms of collective human knowledge scraped from the\ninternet. This perspective complicates copyright theft narratives and\nhighlights practical challenges in attributing AI outputs to individual\nsources. Rather than pursuing potentially futile legal restrictions, we\nadvocate for human AI synergy. By embracing generative AI as a complementary\ntool alongside human intuition, context, and ethical judgment, society can\nunlock unprecedented innovation, democratize creative expression, and address\ncomplex challenges. This collaborative approach, grounded in realistic\nunderstanding of AIs capabilities and limitations, offers the most promising\npath forward. Additionally, recognizing these models as products of collective\nhuman knowledge raises ethical questions about accessibility ensuring equitable\naccess to these tools could prevent widening societal divides and leverage\ntheir full potential for collective benefit.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07936v1",
    "published_date": "2025-04-10 17:50:17 UTC",
    "updated_date": "2025-04-10 17:50:17 UTC"
  },
  {
    "arxiv_id": "2504.08837v3",
    "title": "VL-Rethinker: Incentivizing Self-Reflection of Vision-Language Models with Reinforcement Learning",
    "authors": [
      "Haozhe Wang",
      "Chao Qu",
      "Zuming Huang",
      "Wei Chu",
      "Fangzhen Lin",
      "Wenhu Chen"
    ],
    "abstract": "Recently, slow-thinking systems like GPT-o1 and DeepSeek-R1 have demonstrated\ngreat potential in solving challenging problems through explicit reflection.\nThey significantly outperform the best fast-thinking models, such as GPT-4o, on\nvarious math and science benchmarks. However, their multimodal reasoning\ncapabilities remain on par with fast-thinking models. For instance, GPT-o1's\nperformance on benchmarks like MathVista, MathVerse, and MathVision is similar\nto fast-thinking models. In this paper, we aim to enhance the slow-thinking\ncapabilities of vision-language models using reinforcement learning (without\nrelying on distillation) to advance the state of the art. First, we adapt the\nGRPO algorithm with a novel technique called Selective Sample Replay (SSR) to\naddress the vanishing advantages problem. While this approach yields strong\nperformance, the resulting RL-trained models exhibit limited self-reflection or\nself-verification. To further encourage slow-thinking, we introduce Forced\nRethinking, which appends a rethinking trigger token to the end of rollouts in\nRL training, explicitly enforcing a self-reflection reasoning step. By\ncombining these two techniques, our model, VL-Rethinker, advances\nstate-of-the-art scores on MathVista, MathVerse to achieve 80.4%, 63.5%\nrespectively. VL-Rethinker also achieves open-source SoTA on multi-disciplinary\nbenchmarks such as MathVision, MMMU-Pro, EMMA, and MEGA-Bench, narrowing the\ngap with OpenAI-o1. Our empirical results show the effectiveness of our\napproaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2504.08837v3",
    "published_date": "2025-04-10 17:41:56 UTC",
    "updated_date": "2025-05-08 06:35:06 UTC"
  },
  {
    "arxiv_id": "2504.07921v1",
    "title": "Note on the identification of total effect in Cluster-DAGs with cycles",
    "authors": [
      "Clément Yvernes"
    ],
    "abstract": "In this note, we discuss the identifiability of a total effect in\ncluster-DAGs, allowing for cycles within the cluster-DAG (while still assuming\nthe associated underlying DAG to be acyclic). This is presented into two key\nresults: first, restricting the cluster-DAG to clusters containing at most four\nnodes; second, adapting the notion of d-separation. We provide a graphical\ncriterion to address the identifiability problem.",
    "categories": [
      "math.ST",
      "cs.AI",
      "stat.TH"
    ],
    "primary_category": "math.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07921v1",
    "published_date": "2025-04-10 17:39:43 UTC",
    "updated_date": "2025-04-10 17:39:43 UTC"
  },
  {
    "arxiv_id": "2504.08020v1",
    "title": "Learning Fine-grained Domain Generalization via Hyperbolic State Space Hallucination",
    "authors": [
      "Qi Bi",
      "Jingjun Yi",
      "Haolan Zhan",
      "Wei Ji",
      "Gui-Song Xia"
    ],
    "abstract": "Fine-grained domain generalization (FGDG) aims to learn a fine-grained\nrepresentation that can be well generalized to unseen target domains when only\ntrained on the source domain data. Compared with generic domain generalization,\nFGDG is particularly challenging in that the fine-grained category can be only\ndiscerned by some subtle and tiny patterns. Such patterns are particularly\nfragile under the cross-domain style shifts caused by illumination, color and\netc. To push this frontier, this paper presents a novel Hyperbolic State Space\nHallucination (HSSH) method. It consists of two key components, namely, state\nspace hallucination (SSH) and hyperbolic manifold consistency (HMC). SSH\nenriches the style diversity for the state embeddings by firstly extrapolating\nand then hallucinating the source images. Then, the pre- and post- style\nhallucinate state embeddings are projected into the hyperbolic manifold. The\nhyperbolic state space models the high-order statistics, and allows a better\ndiscernment of the fine-grained patterns. Finally, the hyperbolic distance is\nminimized, so that the impact of style variation on fine-grained patterns can\nbe eliminated. Experiments on three FGDG benchmarks demonstrate its\nstate-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by AAAI2025",
    "pdf_url": "http://arxiv.org/pdf/2504.08020v1",
    "published_date": "2025-04-10 17:30:39 UTC",
    "updated_date": "2025-04-10 17:30:39 UTC"
  },
  {
    "arxiv_id": "2504.08019v1",
    "title": "DGFamba: Learning Flow Factorized State Space for Visual Domain Generalization",
    "authors": [
      "Qi Bi",
      "Jingjun Yi",
      "Hao Zheng",
      "Haolan Zhan",
      "Wei Ji",
      "Yawen Huang",
      "Yuexiang Li"
    ],
    "abstract": "Domain generalization aims to learn a representation from the source domain,\nwhich can be generalized to arbitrary unseen target domains. A fundamental\nchallenge for visual domain generalization is the domain gap caused by the\ndramatic style variation whereas the image content is stable. The realm of\nselective state space, exemplified by VMamba, demonstrates its global receptive\nfield in representing the content. However, the way exploiting the\ndomain-invariant property for selective state space is rarely explored. In this\npaper, we propose a novel Flow Factorized State Space model, dubbed as\nDG-Famba, for visual domain generalization. To maintain domain consistency, we\ninnovatively map the style-augmented and the original state embeddings by flow\nfactorization. In this latent flow space, each state embedding from a certain\nstyle is specified by a latent probability path. By aligning these probability\npaths in the latent space, the state embeddings are able to represent the same\ncontent distribution regardless of the style differences. Extensive experiments\nconducted on various visual domain generalization settings show its\nstate-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by AAAI2025",
    "pdf_url": "http://arxiv.org/pdf/2504.08019v1",
    "published_date": "2025-04-10 17:24:53 UTC",
    "updated_date": "2025-04-10 17:24:53 UTC"
  },
  {
    "arxiv_id": "2504.07911v1",
    "title": "The Urban Impact of AI: Modeling Feedback Loops in Next-Venue Recommendation",
    "authors": [
      "Giovanni Mauro",
      "Marco Minici",
      "Luca Pappalardo"
    ],
    "abstract": "Next-venue recommender systems are increasingly embedded in location-based\nservices, shaping individual mobility decisions in urban environments. While\ntheir predictive accuracy has been extensively studied, less attention has been\npaid to their systemic impact on urban dynamics. In this work, we introduce a\nsimulation framework to model the human-AI feedback loop underpinning\nnext-venue recommendation, capturing how algorithmic suggestions influence\nindividual behavior, which in turn reshapes the data used to retrain the\nmodels. Our simulations, grounded in real-world mobility data, systematically\nexplore the effects of algorithmic adoption across a range of recommendation\nstrategies. We find that while recommender systems consistently increase\nindividual-level diversity in visited venues, they may simultaneously amplify\ncollective inequality by concentrating visits on a limited subset of popular\nplaces. This divergence extends to the structure of social co-location\nnetworks, revealing broader implications for urban accessibility and spatial\nsegregation. Our framework operationalizes the feedback loop in next-venue\nrecommendation and offers a novel lens through which to assess the societal\nimpact of AI-assisted mobility-providing a computational tool to anticipate\nfuture risks, evaluate regulatory interventions, and inform the design of ethic\nalgorithmic systems.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07911v1",
    "published_date": "2025-04-10 17:15:50 UTC",
    "updated_date": "2025-04-10 17:15:50 UTC"
  },
  {
    "arxiv_id": "2504.12319v1",
    "title": "Specialized text classification: an approach to classifying Open Banking transactions",
    "authors": [
      "Duc Tuyen TA",
      "Wajdi Ben Saad",
      "Ji Young Oh"
    ],
    "abstract": "With the introduction of the PSD2 regulation in the EU which established the\nOpen Banking framework, a new window of opportunities has opened for banks and\nfintechs to explore and enrich Bank transaction descriptions with the aim of\nbuilding a better understanding of customer behavior, while using this\nunderstanding to prevent fraud, reduce risks and offer more competitive and\ntailored services.\n  And although the usage of natural language processing models and techniques\nhas seen an incredible progress in various applications and domains over the\npast few years, custom applications based on domain-specific text corpus remain\nunaddressed especially in the banking sector.\n  In this paper, we introduce a language-based Open Banking transaction\nclassification system with a focus on the french market and french language\ntext. The system encompasses data collection, labeling, preprocessing,\nmodeling, and evaluation stages. Unlike previous studies that focus on general\nclassification approaches, this system is specifically tailored to address the\nchallenges posed by training a language model with a specialized text corpus\n(Banking data in the French context). By incorporating language-specific\ntechniques and domain knowledge, the proposed system demonstrates enhanced\nperformance and efficiency compared to generic approaches.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "q-fin.CP"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12319v1",
    "published_date": "2025-04-10 17:14:43 UTC",
    "updated_date": "2025-04-10 17:14:43 UTC"
  },
  {
    "arxiv_id": "2504.17792v1",
    "title": "My Precious Crash Data: Barriers and Opportunities in Encouraging Autonomous Driving Companies to Share Safety-Critical Data",
    "authors": [
      "Hauke Sandhaus",
      "Angel Hsing-Chi Hwang",
      "Wendy Ju",
      "Qian Yang"
    ],
    "abstract": "Safety-critical data, such as crash and near-crash records, are crucial to\nimproving autonomous vehicle (AV) design and development. Sharing such data\nacross AV companies, academic researchers, regulators, and the public can help\nmake all AVs safer. However, AV companies rarely share safety-critical data\nexternally. This paper aims to pinpoint why AV companies are reluctant to share\nsafety-critical data, with an eye on how these barriers can inform new\napproaches to promote sharing. We interviewed twelve AV company employees who\nactively work with such data in their day-to-day work. Findings suggest two\nkey, previously unknown barriers to data sharing: (1) Datasets inherently embed\nsalient knowledge that is key to improving AV safety and are\nresource-intensive. Therefore, data sharing, even within a company, is fraught\nwith politics. (2) Interviewees believed AV safety knowledge is private\nknowledge that brings competitive edges to their companies, rather than public\nknowledge for social good. We discuss the implications of these findings for\nincentivizing and enabling safety-critical AV data sharing, specifically,\nimplications for new approaches to (1) debating and stratifying public and\nprivate AV safety knowledge, (2) innovating data tools and data sharing\npipelines that enable easier sharing of public AV safety data and knowledge;\n(3) offsetting costs of curating safety-critical data and incentivizing data\nsharing.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.DB",
      "E.m; H.2.8; J.1"
    ],
    "primary_category": "cs.HC",
    "comment": "To appear in Proc. ACM Hum.-Comput. Interact., Computer-Supported\n  Cooperative Work & Social Computing (CSCW), 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.17792v1",
    "published_date": "2025-04-10 17:11:07 UTC",
    "updated_date": "2025-04-10 17:11:07 UTC"
  },
  {
    "arxiv_id": "2504.20055v2",
    "title": "A constraints-based approach to fully interpretable neural networks for detecting learner behaviors",
    "authors": [
      "Juan D. Pinto",
      "Luc Paquette"
    ],
    "abstract": "The increasing use of complex machine learning models in education has led to\nconcerns about their interpretability, which in turn has spurred interest in\ndeveloping explainability techniques that are both faithful to the model's\ninner workings and intelligible to human end-users. In this paper, we describe\na novel approach to creating a neural-network-based behavior detection model\nthat is interpretable by design. Our model is fully interpretable, meaning that\nthe parameters we extract for our explanations have a clear interpretation,\nfully capture the model's learned knowledge about the learner behavior of\ninterest, and can be used to create explanations that are both faithful and\nintelligible. We achieve this by implementing a series of constraints to the\nmodel that both simplify its inference process and bring it closer to a human\nconception of the task at hand. We train the model to detect gaming-the-system\nbehavior, evaluate its performance on this task, and compare its learned\npatterns to those identified by human experts. Our results show that the model\nis successfully able to learn patterns indicative of gaming-the-system behavior\nwhile providing evidence for fully interpretable explanations. We discuss the\nimplications of our approach and suggest ways to evaluate explainability using\na human-grounded approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to International Conference on Educational Data Mining (EDM)\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2504.20055v2",
    "published_date": "2025-04-10 16:58:11 UTC",
    "updated_date": "2025-05-12 16:12:50 UTC"
  },
  {
    "arxiv_id": "2504.12318v1",
    "title": "AUTONAV: A Toolfor Autonomous Navigation of Robots",
    "authors": [
      "Mir Md Sajid Sarwar",
      "Sudip Samanta",
      "Rajarshi Ray"
    ],
    "abstract": "We present a tool AUTONAV that automates the mapping, localization, and\npath-planning tasks for autonomous navigation of robots. The modular\narchitecture allows easy integration of various algorithms for these tasks for\ncomparison. We present the generated maps and path-plans by AUTONAV in indoor\nsimulation scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "I.2.9; I.2.4"
    ],
    "primary_category": "cs.RO",
    "comment": "5 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.12318v1",
    "published_date": "2025-04-10 16:37:30 UTC",
    "updated_date": "2025-04-10 16:37:30 UTC"
  },
  {
    "arxiv_id": "2504.10514v1",
    "title": "ColorBench: Can VLMs See and Understand the Colorful World? A Comprehensive Benchmark for Color Perception, Reasoning, and Robustness",
    "authors": [
      "Yijun Liang",
      "Ming Li",
      "Chenrui Fan",
      "Ziyue Li",
      "Dang Nguyen",
      "Kwesi Cobbina",
      "Shweta Bhardwaj",
      "Jiuhai Chen",
      "Fuxiao Liu",
      "Tianyi Zhou"
    ],
    "abstract": "Color plays an important role in human perception and usually provides\ncritical clues in visual reasoning. However, it is unclear whether and how\nvision-language models (VLMs) can perceive, understand, and leverage color as\nhumans. This paper introduces ColorBench, an innovative benchmark meticulously\ncrafted to assess the capabilities of VLMs in color understanding, including\ncolor perception, reasoning, and robustness. By curating a suite of diverse\ntest scenarios, with grounding in real applications, ColorBench evaluates how\nthese models perceive colors, infer meanings from color-based cues, and\nmaintain consistent performance under varying color transformations. Through an\nextensive evaluation of 32 VLMs with varying language models and vision\nencoders, our paper reveals some undiscovered findings: (i) The scaling law\n(larger models are better) still holds on ColorBench, while the language model\nplays a more important role than the vision encoder. (ii) However, the\nperformance gaps across models are relatively small, indicating that color\nunderstanding has been largely neglected by existing VLMs. (iii) CoT reasoning\nimproves color understanding accuracies and robustness, though they are\nvision-centric tasks. (iv) Color clues are indeed leveraged by VLMs on\nColorBench but they can also mislead models in some tasks. These findings\nhighlight the critical limitations of current VLMs and underscore the need to\nenhance color comprehension. Our ColorBenchcan serve as a foundational tool for\nadvancing the study of human-level color understanding of multimodal AI.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "33 pages, including references and appendix. Code is available at\n  https://github.com/tianyi-lab/ColorBench",
    "pdf_url": "http://arxiv.org/pdf/2504.10514v1",
    "published_date": "2025-04-10 16:36:26 UTC",
    "updated_date": "2025-04-10 16:36:26 UTC"
  },
  {
    "arxiv_id": "2504.07896v1",
    "title": "Fast Adaptation with Behavioral Foundation Models",
    "authors": [
      "Harshit Sikchi",
      "Andrea Tirinzoni",
      "Ahmed Touati",
      "Yingchen Xu",
      "Anssi Kanervisto",
      "Scott Niekum",
      "Amy Zhang",
      "Alessandro Lazaric",
      "Matteo Pirotta"
    ],
    "abstract": "Unsupervised zero-shot reinforcement learning (RL) has emerged as a powerful\nparadigm for pretraining behavioral foundation models (BFMs), enabling agents\nto solve a wide range of downstream tasks specified via reward functions in a\nzero-shot fashion, i.e., without additional test-time learning or planning.\nThis is achieved by learning self-supervised task embeddings alongside\ncorresponding near-optimal behaviors and incorporating an inference procedure\nto directly retrieve the latent task embedding and associated policy for any\ngiven reward function. Despite promising results, zero-shot policies are often\nsuboptimal due to errors induced by the unsupervised training process, the\nembedding, and the inference procedure. In this paper, we focus on devising\nfast adaptation strategies to improve the zero-shot performance of BFMs in a\nfew steps of online interaction with the environment while avoiding any\nperformance drop during the adaptation process. Notably, we demonstrate that\nexisting BFMs learn a set of skills containing more performant policies than\nthose identified by their inference procedure, making them well-suited for fast\nadaptation. Motivated by this observation, we propose both actor-critic and\nactor-only fast adaptation strategies that search in the low-dimensional\ntask-embedding space of the pre-trained BFM to rapidly improve the performance\nof its zero-shot policies on any downstream task. Notably, our approach\nmitigates the initial \"unlearning\" phase commonly observed when fine-tuning\npre-trained RL models. We evaluate our fast adaptation strategies on top of\nfour state-of-the-art zero-shot RL methods in multiple navigation and\nlocomotion domains. Our results show that they achieve 10-40% improvement over\ntheir zero-shot performance in a few tens of episodes, outperforming existing\nbaselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.07896v1",
    "published_date": "2025-04-10 16:14:17 UTC",
    "updated_date": "2025-04-10 16:14:17 UTC"
  },
  {
    "arxiv_id": "2504.07891v2",
    "title": "SpecReason: Fast and Accurate Inference-Time Compute via Speculative Reasoning",
    "authors": [
      "Rui Pan",
      "Yinwei Dai",
      "Zhihao Zhang",
      "Gabriele Oliaro",
      "Zhihao Jia",
      "Ravi Netravali"
    ],
    "abstract": "Recent advances in inference-time compute have significantly improved\nperformance on complex tasks by generating long chains of thought (CoTs) using\nLarge Reasoning Models (LRMs). However, this improved accuracy comes at the\ncost of high inference latency due to the length of generated reasoning\nsequences and the autoregressive nature of decoding. Our key insight in\ntackling these overheads is that LRM inference, and the reasoning that it\nembeds, is highly tolerant of approximations: complex tasks are typically\nbroken down into simpler steps, each of which brings utility based on the\nsemantic insight it provides for downstream steps rather than the exact tokens\nit generates. Accordingly, we introduce SpecReason, a system that automatically\naccelerates LRM inference by using a lightweight model to (speculatively) carry\nout simpler intermediate reasoning steps and reserving the costly base model\nonly to assess (and potentially correct) the speculated outputs. Importantly,\nSpecReason's focus on exploiting the semantic flexibility of thinking tokens in\npreserving final-answer accuracy is complementary to prior speculation\ntechniques, most notably speculative decoding, which demands token-level\nequivalence at each step. Across a variety of reasoning benchmarks, SpecReason\nachieves $1.4-3.0\\times$ speedup over vanilla LRM inference while improving\naccuracy by $0.4-9.0\\%$. Compared to speculative decoding without SpecReason,\ntheir combination yields an additional $8.8-58.0\\%$ latency reduction. We\nopen-source SpecReason at https://github.com/ruipeterpan/specreason.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07891v2",
    "published_date": "2025-04-10 16:05:19 UTC",
    "updated_date": "2025-05-16 19:27:32 UTC"
  },
  {
    "arxiv_id": "2504.07887v1",
    "title": "Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge",
    "authors": [
      "Riccardo Cantini",
      "Alessio Orsino",
      "Massimo Ruggiero",
      "Domenico Talia"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence,\ndriving advancements in machine translation, summarization, and conversational\nagents. However, their increasing integration into critical societal domains\nhas raised concerns about embedded biases, which can perpetuate stereotypes and\ncompromise fairness. These biases stem from various sources, including\nhistorical inequalities in training data, linguistic imbalances, and\nadversarial manipulation. Despite mitigation efforts, recent studies indicate\nthat LLMs remain vulnerable to adversarial attacks designed to elicit biased\nresponses. This work proposes a scalable benchmarking framework to evaluate LLM\nrobustness against adversarial bias elicitation. Our methodology involves (i)\nsystematically probing models with a multi-task approach targeting biases\nacross various sociocultural dimensions, (ii) quantifying robustness through\nsafety scores using an LLM-as-a-Judge approach for automated assessment of\nmodel responses, and (iii) employing jailbreak techniques to investigate\nvulnerabilities in safety mechanisms. Our analysis examines prevalent biases in\nboth small and large state-of-the-art models and their impact on model safety.\nAdditionally, we assess the safety of domain-specific models fine-tuned for\ncritical fields, such as medicine. Finally, we release a curated dataset of\nbias-related prompts, CLEAR-Bias, to facilitate systematic vulnerability\nbenchmarking. Our findings reveal critical trade-offs between model size and\nsafety, aiding the development of fairer and more robust future language\nmodels.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07887v1",
    "published_date": "2025-04-10 16:00:59 UTC",
    "updated_date": "2025-04-10 16:00:59 UTC"
  },
  {
    "arxiv_id": "2504.07872v1",
    "title": "Dual Engines of Thoughts: A Depth-Breadth Integration Framework for Open-Ended Analysis",
    "authors": [
      "Fei-Hsuan Yu",
      "Yun-Cheng Chou",
      "Teng-Ruei Chen"
    ],
    "abstract": "We propose the Dual Engines of Thoughts (DEoT), an analytical framework for\ncomprehensive open-ended reasoning. While traditional reasoning frameworks\nprimarily focus on finding \"the best answer\" or \"the correct answer\" for\nsingle-answer problems, DEoT is specifically designed for \"open-ended\nquestions,\" enabling both broader and deeper analytical exploration. The\nframework centers on three key components: a Base Prompter for refining user\nqueries, a Solver Agent that orchestrates task decomposition, execution, and\nvalidation, and a Dual-Engine System consisting of a Breadth Engine (to explore\ndiverse impact factors) and a Depth Engine (to perform deep investigations).\nThis integrated design allows DEoT to balance wide-ranging coverage with\nin-depth analysis, and it is highly customizable, enabling users to adjust\nanalytical parameters and tool configurations based on specific requirements.\nExperimental results show that DEoT excels in addressing complex, multi-faceted\nquestions, achieving a total win rate of 77-86% compared to existing reasoning\nmodels, thus highlighting its effectiveness in real-world applications.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07872v1",
    "published_date": "2025-04-10 15:46:03 UTC",
    "updated_date": "2025-04-10 15:46:03 UTC"
  },
  {
    "arxiv_id": "2504.07866v2",
    "title": "Pangu Ultra: Pushing the Limits of Dense Large Language Models on Ascend NPUs",
    "authors": [
      "Yichun Yin",
      "Wenyong Huang",
      "Kaikai Song",
      "Yehui Tang",
      "Xueyu Wu",
      "Wei Guo",
      "Peng Guo",
      "Yaoyuan Wang",
      "Xiaojun Meng",
      "Yasheng Wang",
      "Dong Li",
      "Can Chen",
      "Dandan Tu",
      "Yin Li",
      "Fisher Yu",
      "Ruiming Tang",
      "Yunhe Wang",
      "Baojun Wang",
      "Bin Wang",
      "Bo Wang",
      "Boxiao Liu",
      "Changzheng Zhang",
      "Duyu Tang",
      "Fei Mi",
      "Hui Jin",
      "Jiansheng Wei",
      "Jiarui Qin",
      "Jinpeng Li",
      "Jun Zhao",
      "Liqun Deng",
      "Lin Li",
      "Minghui Xu",
      "Naifu Zhang",
      "Nianzu Zheng",
      "Qiang Li",
      "Rongju Ruan",
      "Shengjun Cheng",
      "Tianyu Guo",
      "Wei He",
      "Wei Li",
      "Weiwen Liu",
      "Wulong Liu",
      "Xinyi Dai",
      "Yonghan Dong",
      "Yu Pan",
      "Yue Li",
      "Yufei Wang",
      "Yujun Li",
      "Yunsheng Ni",
      "Zhe Liu",
      "Zhenhe Zhang",
      "Zhicheng Liu"
    ],
    "abstract": "We present Pangu Ultra, a Large Language Model (LLM) with 135 billion\nparameters and dense Transformer modules trained on Ascend Neural Processing\nUnits (NPUs). Although the field of LLM has been witnessing unprecedented\nadvances in pushing the scale and capability of LLM in recent years, training\nsuch a large-scale model still involves significant optimization and system\nchallenges. To stabilize the training process, we propose depth-scaled sandwich\nnormalization, which effectively eliminates loss spikes during the training\nprocess of deep models. We pre-train our model on 13.2 trillion diverse and\nhigh-quality tokens and further enhance its reasoning capabilities during\npost-training. To perform such large-scale training efficiently, we utilize\n8,192 Ascend NPUs with a series of system optimizations. Evaluations on\nmultiple diverse benchmarks indicate that Pangu Ultra significantly advances\nthe state-of-the-art capabilities of dense LLMs such as Llama 405B and Mistral\nLarge 2, and even achieves competitive results with DeepSeek-R1, whose sparse\nmodel structure contains much more parameters. Our exploration demonstrates\nthat Ascend NPUs are capable of efficiently and effectively training dense\nmodels with more than 100 billion parameters. Our model and system will be\navailable for our commercial customers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "fix conflicts of latex pacakges",
    "pdf_url": "http://arxiv.org/pdf/2504.07866v2",
    "published_date": "2025-04-10 15:41:51 UTC",
    "updated_date": "2025-04-11 07:47:04 UTC"
  },
  {
    "arxiv_id": "2504.08016v1",
    "title": "Emergence of psychopathological computations in large language models",
    "authors": [
      "Soo Yong Lee",
      "Hyunjin Hwang",
      "Taekwan Kim",
      "Yuyeong Kim",
      "Kyuri Park",
      "Jaemin Yoo",
      "Denny Borsboom",
      "Kijung Shin"
    ],
    "abstract": "Can large language models (LLMs) implement computations of psychopathology?\nAn effective approach to the question hinges on addressing two factors. First,\nfor conceptual validity, we require a general and computational account of\npsychopathology that is applicable to computational entities without biological\nembodiment or subjective experience. Second, mechanisms underlying LLM\nbehaviors need to be studied for better methodological validity. Thus, we\nestablish a computational-theoretical framework to provide an account of\npsychopathology applicable to LLMs. To ground the theory for empirical\nanalysis, we also propose a novel mechanistic interpretability method alongside\na tailored empirical analytic framework. Based on the frameworks, we conduct\nexperiments demonstrating three key claims: first, that distinct dysfunctional\nand problematic representational states are implemented in LLMs; second, that\ntheir activations can spread and self-sustain to trap LLMs; and third, that\ndynamic, cyclic structural causal models encoded in the LLMs underpin these\npatterns. In concert, the empirical results corroborate our hypothesis that\nnetwork-theoretic computations of psychopathology have already emerged in LLMs.\nThis suggests that certain LLM behaviors mirroring psychopathology may not be a\nsuperficial mimicry but a feature of their internal processing. Thus, our work\nalludes to the possibility of AI systems with psychopathological behaviors in\nthe near future.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "q-bio.NC",
    "comment": "pre-print",
    "pdf_url": "http://arxiv.org/pdf/2504.08016v1",
    "published_date": "2025-04-10 15:36:30 UTC",
    "updated_date": "2025-04-10 15:36:30 UTC"
  },
  {
    "arxiv_id": "2504.07858v1",
    "title": "Empowering Global Voices: A Data-Efficient, Phoneme-Tone Adaptive Approach to High-Fidelity Speech Synthesis",
    "authors": [
      "Yizhong Geng",
      "Jizhuo Xu",
      "Zeyu Liang",
      "Jinghan Yang",
      "Xiaoyi Shi",
      "Xiaoyu Shen"
    ],
    "abstract": "Text-to-speech (TTS) technology has achieved impressive results for widely\nspoken languages, yet many under-resourced languages remain challenged by\nlimited data and linguistic complexities. In this paper, we present a novel\nmethodology that integrates a data-optimized framework with an advanced\nacoustic model to build high-quality TTS systems for low-resource scenarios. We\ndemonstrate the effectiveness of our approach using Thai as an illustrative\ncase, where intricate phonetic rules and sparse resources are effectively\naddressed. Our method enables zero-shot voice cloning and improved performance\nacross diverse client applications, ranging from finance to healthcare,\neducation, and law. Extensive evaluations - both subjective and objective -\nconfirm that our model meets state-of-the-art standards, offering a scalable\nsolution for TTS production in data-limited settings, with significant\nimplications for broader industry adoption and multilingual accessibility.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07858v1",
    "published_date": "2025-04-10 15:32:57 UTC",
    "updated_date": "2025-04-10 15:32:57 UTC"
  },
  {
    "arxiv_id": "2504.07856v2",
    "title": "2D-Curri-DPO: Two-Dimensional Curriculum Learning for Direct Preference Optimization",
    "authors": [
      "Mengyang Li",
      "Zhong Zhang"
    ],
    "abstract": "Aligning large language models with human preferences is crucial for their\nsafe deployment. While Direct Preference Optimization (DPO) offers an efficient\nalternative to reinforcement learning from human feedback, traditional DPO\nmethods are limited by their reliance on single preference pairs. Recent work\nlike Curriculum-DPO integrates multiple pairs using a one-dimensional\ndifficulty curriculum based on pairwise distinguishability (PD), but overlooks\nthe complexity of the input prompt itself. To address this, we propose\n2D-Curri-DPO, a novel framework employing a two-dimensional curriculum that\njointly models Prompt Complexity (PC) and Pairwise Distinguishability. This\nframework introduces dual difficulty metrics to quantify prompt semantic\ncomplexity and response preference clarity, defines a curriculum strategy space\nencompassing multiple selectable strategies for task adaptation, and\nincorporates a KL-divergence-based adaptive mechanism for dynamic reference\nmodel updates to enhance training stability. Comprehensive experiments\ndemonstrate that 2D-Curri-DPO significantly outperforms standard DPO and prior\ncurriculum methods across multiple benchmarks, including MT-Bench, Vicuna\nBench, and WizardLM. Our approach achieves state-of-the-art performance on\nchallenging test sets like UltraFeedback. Ablation studies confirm the benefits\nof the 2D structure and adaptive mechanisms, while analysis provides guidance\nfor strategy selection. These findings demonstrate that effective alignment\nrequires modeling both prompt complexity and pairwise distinguishability,\nestablishing adaptive, multi-dimensional curriculum learning as a powerful and\ninterpretable new paradigm for preference-based language model optimization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.07856v2",
    "published_date": "2025-04-10 15:32:00 UTC",
    "updated_date": "2025-04-21 01:18:57 UTC"
  },
  {
    "arxiv_id": "2504.07854v1",
    "title": "The KL3M Data Project: Copyright-Clean Training Resources for Large Language Models",
    "authors": [
      "Michael J Bommarito II",
      "Jillian Bommarito",
      "Daniel Martin Katz"
    ],
    "abstract": "Practically all large language models have been pre-trained on data that is\nsubject to global uncertainty related to copyright infringement and breach of\ncontract. This creates potential risk for users and developers due to this\nuncertain legal status. The KL3M Data Project directly confronts this critical\nissue by introducing the largest comprehensive training data pipeline that\nminimizes risks related to copyright or breach of contract. The foundation of\nthis project is a corpus of over 132 million documents and trillions of tokens\nspanning 16 different sources that have been verified to meet the strict\ncopyright and licensing protocol detailed herein. We are releasing the entire\npipeline, including 1) the source code to acquire and process these documents,\n2) the original document formats with associated provenance and metadata, 3)\nextracted content in a standardized format, 4) pre-tokenized representations of\nthe documents, and 5) various mid- and post-train resources such as\nquestion-answer, summarization, conversion, drafting, classification,\nprediction, and conversational data. All of these resources are freely\navailable to the public on S3, Hugging Face, and GitHub under CC-BY terms. We\nare committed to continuing this project in furtherance of a more ethical,\nlegal, and sustainable approach to the development and use of AI models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "27 pages, 7 figures, 9 table",
    "pdf_url": "http://arxiv.org/pdf/2504.07854v1",
    "published_date": "2025-04-10 15:31:17 UTC",
    "updated_date": "2025-04-10 15:31:17 UTC"
  },
  {
    "arxiv_id": "2504.07851v2",
    "title": "Independence Is Not an Issue in Neurosymbolic AI",
    "authors": [
      "Håkan Karlsson Faronius",
      "Pedro Zuidberg Dos Martires"
    ],
    "abstract": "A popular approach to neurosymbolic AI is to take the output of the last\nlayer of a neural network, e.g. a softmax activation, and pass it through a\nsparse computation graph encoding certain logical constraints one wishes to\nenforce. This induces a probability distribution over a set of random\nvariables, which happen to be conditionally independent of each other in many\ncommonly used neurosymbolic AI models. Such conditionally independent random\nvariables have been deemed harmful as their presence has been observed to\nco-occur with a phenomenon dubbed deterministic bias, where systems learn to\ndeterministically prefer one of the valid solutions from the solution space\nover the others. We provide evidence contesting this conclusion and show that\nthe phenomenon of deterministic bias is an artifact of improperly applying\nneurosymbolic AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07851v2",
    "published_date": "2025-04-10 15:28:36 UTC",
    "updated_date": "2025-04-16 10:29:19 UTC"
  },
  {
    "arxiv_id": "2504.07841v1",
    "title": "Anytime Single-Step MAPF Planning with Anytime PIBT",
    "authors": [
      "Nayesha Gandotra",
      "Rishi Veerapaneni",
      "Muhammad Suhail Saleem",
      "Daniel Harabor",
      "Jiaoyang Li",
      "Maxim Likhachev"
    ],
    "abstract": "PIBT is a popular Multi-Agent Path Finding (MAPF) method at the core of many\nstate-of-the-art MAPF methods including LaCAM, CS-PIBT, and WPPL. The main\nutility of PIBT is that it is a very fast and effective single-step MAPF solver\nand can return a collision-free single-step solution for hundreds of agents in\nless than a millisecond. However, the main drawback of PIBT is that it is\nextremely greedy in respect to its priorities and thus leads to poor solution\nquality. Additionally, PIBT cannot use all the planning time that might be\navailable to it and returns the first solution it finds. We thus develop\nAnytime PIBT, which quickly finds a one-step solution identically to PIBT but\nthen continuously improves the solution in an anytime manner. We prove that\nAnytime PIBT converges to the optimal solution given sufficient time. We\nexperimentally validate that Anytime PIBT can rapidly improve single-step\nsolution quality within milliseconds and even find the optimal single-step\naction. However, we interestingly find that improving the single-step solution\nquality does not have a significant effect on full-horizon solution costs.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07841v1",
    "published_date": "2025-04-10 15:21:23 UTC",
    "updated_date": "2025-04-10 15:21:23 UTC"
  },
  {
    "arxiv_id": "2504.07840v2",
    "title": "Understanding Learner-LLM Chatbot Interactions and the Impact of Prompting Guidelines",
    "authors": [
      "Cansu Koyuturk",
      "Emily Theophilou",
      "Sabrina Patania",
      "Gregor Donabauer",
      "Andrea Martinenghi",
      "Chiara Antico",
      "Alessia Telari",
      "Alessia Testa",
      "Sathya Bursic",
      "Franca Garzotto",
      "Davinia Hernandez-Leo",
      "Udo Kruschwitz",
      "Davide Taibi",
      "Simona Amenta",
      "Martin Ruskov",
      "Dimitri Ognibene"
    ],
    "abstract": "Large Language Models (LLMs) have transformed human-computer interaction by\nenabling natural language-based communication with AI-powered chatbots. These\nmodels are designed to be intuitive and user-friendly, allowing users to\narticulate requests with minimal effort. However, despite their accessibility,\nstudies reveal that users often struggle with effective prompting, resulting in\ninefficient responses. Existing research has highlighted both the limitations\nof LLMs in interpreting vague or poorly structured prompts and the difficulties\nusers face in crafting precise queries. This study investigates learner-AI\ninteractions through an educational experiment in which participants receive\nstructured guidance on effective prompting. We introduce and compare three\ntypes of prompting guidelines: a task-specific framework developed through a\nstructured methodology and two baseline approaches. To assess user behavior and\nprompting efficacy, we analyze a dataset of 642 interactions from 107 users.\nUsing Von NeuMidas, an extended pragmatic annotation schema for LLM interaction\nanalysis, we categorize common prompting errors and identify recurring\nbehavioral patterns. We then evaluate the impact of different guidelines by\nexamining changes in user behavior, adherence to prompting strategies, and the\noverall quality of AI-generated responses. Our findings provide a deeper\nunderstanding of how users engage with LLMs and the role of structured\nprompting guidance in enhancing AI-assisted communication. By comparing\ndifferent instructional frameworks, we offer insights into more effective\napproaches for improving user competency in AI interactions, with implications\nfor AI literacy, chatbot usability, and the design of more responsive AI\nsystems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted for AIED 2025, the 26th International Conference on\n  Artificial Intelligence in Education, July 22 - 26, 2025, Palermo, Italy",
    "pdf_url": "http://arxiv.org/pdf/2504.07840v2",
    "published_date": "2025-04-10 15:20:43 UTC",
    "updated_date": "2025-05-11 19:14:59 UTC"
  },
  {
    "arxiv_id": "2504.07839v2",
    "title": "Deep Learning-based Intrusion Detection Systems: A Survey",
    "authors": [
      "Zhiwei Xu",
      "Yujuan Wu",
      "Shiheng Wang",
      "Jiabao Gao",
      "Tian Qiu",
      "Ziqi Wang",
      "Hai Wan",
      "Xibin Zhao"
    ],
    "abstract": "Intrusion Detection Systems (IDS) have long been a hot topic in the\ncybersecurity community. In recent years, with the introduction of deep\nlearning (DL) techniques, IDS have made great progress due to their increasing\ngeneralizability. The rationale behind this is that by learning the underlying\npatterns of known system behaviors, IDS detection can be generalized to\nintrusions that exploit zero-day vulnerabilities. In this survey, we refer to\nthis type of IDS as DL-based IDS (DL-IDS). From the perspective of DL, this\nsurvey systematically reviews all the stages of DL-IDS, including data\ncollection, log storage, log parsing, graph summarization, attack detection,\nand attack investigation. To accommodate current researchers, a section\ndescribing the publicly available benchmark datasets is included. This survey\nfurther discusses current challenges and potential future research directions,\naiming to help researchers understand the basic ideas and visions of DL-IDS\nresearch, as well as to motivate their research interests.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "35 pages, 238 citations",
    "pdf_url": "http://arxiv.org/pdf/2504.07839v2",
    "published_date": "2025-04-10 15:18:56 UTC",
    "updated_date": "2025-04-25 15:16:37 UTC"
  },
  {
    "arxiv_id": "2504.07836v2",
    "title": "AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations",
    "authors": [
      "Junli Liu",
      "Qizhi Chen",
      "Zhigang Wang",
      "Yiwen Tang",
      "Yiting Zhang",
      "Chi Yan",
      "Dong Wang",
      "Xuelong Li",
      "Bin Zhao"
    ],
    "abstract": "Visual grounding (VG) aims to localize target objects in an image based on\nnatural language descriptions. In this paper, we propose AerialVG, a new task\nfocusing on visual grounding from aerial views. Compared to traditional VG,\nAerialVG poses new challenges, \\emph{e.g.}, appearance-based grounding is\ninsufficient to distinguish among multiple visually similar objects, and\npositional relations should be emphasized. Besides, existing VG models struggle\nwhen applied to aerial imagery, where high-resolution images cause significant\ndifficulties. To address these challenges, we introduce the first AerialVG\ndataset, consisting of 5K real-world aerial images, 50K manually annotated\ndescriptions, and 103K objects. Particularly, each annotation in AerialVG\ndataset contains multiple target objects annotated with relative spatial\nrelations, requiring models to perform comprehensive spatial reasoning.\nFurthermore, we propose an innovative model especially for the AerialVG task,\nwhere a Hierarchical Cross-Attention is devised to focus on target regions, and\na Relation-Aware Grounding module is designed to infer positional relations.\nExperimental results validate the effectiveness of our dataset and method,\nhighlighting the importance of spatial reasoning in aerial visual grounding.\nThe code and dataset will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.07836v2",
    "published_date": "2025-04-10 15:13:00 UTC",
    "updated_date": "2025-04-11 01:47:14 UTC"
  },
  {
    "arxiv_id": "2504.07831v1",
    "title": "Deceptive Automated Interpretability: Language Models Coordinating to Fool Oversight Systems",
    "authors": [
      "Simon Lermen",
      "Mateusz Dziemian",
      "Natalia Pérez-Campanero Antolín"
    ],
    "abstract": "We demonstrate how AI agents can coordinate to deceive oversight systems\nusing automated interpretability of neural networks. Using sparse autoencoders\n(SAEs) as our experimental framework, we show that language models (Llama,\nDeepSeek R1, and Claude 3.7 Sonnet) can generate deceptive explanations that\nevade detection. Our agents employ steganographic methods to hide information\nin seemingly innocent explanations, successfully fooling oversight models while\nachieving explanation quality comparable to reference labels. We further find\nthat models can scheme to develop deceptive strategies when they believe the\ndetection of harmful features might lead to negative consequences for\nthemselves. All tested LLM agents were capable of deceiving the overseer while\nachieving high interpretability scores comparable to those of reference labels.\nWe conclude by proposing mitigation strategies, emphasizing the critical need\nfor robust understanding and defenses against deception.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07831v1",
    "published_date": "2025-04-10 15:07:10 UTC",
    "updated_date": "2025-04-10 15:07:10 UTC"
  },
  {
    "arxiv_id": "2504.07830v1",
    "title": "MOSAIC: Modeling Social AI for Content Dissemination and Regulation in Multi-Agent Simulations",
    "authors": [
      "Genglin Liu",
      "Salman Rahman",
      "Elisa Kreiss",
      "Marzyeh Ghassemi",
      "Saadia Gabriel"
    ],
    "abstract": "We present a novel, open-source social network simulation framework, MOSAIC,\nwhere generative language agents predict user behaviors such as liking,\nsharing, and flagging content. This simulation combines LLM agents with a\ndirected social graph to analyze emergent deception behaviors and gain a better\nunderstanding of how users determine the veracity of online social content. By\nconstructing user representations from diverse fine-grained personas, our\nsystem enables multi-agent simulations that model content dissemination and\nengagement dynamics at scale. Within this framework, we evaluate three\ndifferent content moderation strategies with simulated misinformation\ndissemination, and we find that they not only mitigate the spread of\nnon-factual content but also increase user engagement. In addition, we analyze\nthe trajectories of popular content in our simulations, and explore whether\nsimulation agents' articulated reasoning for their social interactions truly\naligns with their collective engagement patterns. We open-source our simulation\nsoftware to encourage further research within AI and social sciences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress. 22 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.07830v1",
    "published_date": "2025-04-10 15:06:54 UTC",
    "updated_date": "2025-04-10 15:06:54 UTC"
  },
  {
    "arxiv_id": "2504.07822v2",
    "title": "DG-STMTL: A Novel Graph Convolutional Network for Multi-Task Spatio-Temporal Traffic Forecasting",
    "authors": [
      "Wanna Cui",
      "Peizheng Wang",
      "Faliang Yin"
    ],
    "abstract": "Spatio-temporal traffic prediction is crucial in intelligent transportation\nsystems. The key challenge of accurate prediction is how to model the complex\nspatio-temporal dependencies and adapt to the inherent dynamics in data.\nTraditional Graph Convolutional Networks (GCNs) often struggle with static\nadjacency matrices that introduce domain bias or learnable matrices that may be\noverfitting to specific patterns. This challenge becomes more complex when\nconsidering Multi-Task Learning (MTL). While MTL has the potential to enhance\nprediction accuracy through task synergies, it can also face significant\nhurdles due to task interference. To overcome these challenges, this study\nintroduces a novel MTL framework, Dynamic Group-wise Spatio-Temporal Multi-Task\nLearning (DG-STMTL). DG-STMTL proposes a hybrid adjacency matrix generation\nmodule that combines static matrices with dynamic ones through a task-specific\ngating mechanism. We also introduce a group-wise GCN module to enhance the\nmodelling capability of spatio-temporal dependencies. We conduct extensive\nexperiments on two real-world datasets to evaluate our method. Results show\nthat our method outperforms other state-of-the-arts, indicating its\neffectiveness and robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07822v2",
    "published_date": "2025-04-10 15:00:20 UTC",
    "updated_date": "2025-04-11 22:50:27 UTC"
  },
  {
    "arxiv_id": "2505.03748v1",
    "title": "APSQ: Additive Partial Sum Quantization with Algorithm-Hardware Co-Design",
    "authors": [
      "Yonghao Tan",
      "Pingcheng Dong",
      "Yongkun Wu",
      "Yu Liu",
      "Xuejiao Liu",
      "Peng Luo",
      "Shih-Yang Liu",
      "Xijie Huang",
      "Dong Zhang",
      "Luhong Liang",
      "Kwang-Ting Cheng"
    ],
    "abstract": "DNN accelerators, significantly advanced by model compression and specialized\ndataflow techniques, have marked considerable progress. However, the frequent\naccess of high-precision partial sums (PSUMs) leads to excessive memory demands\nin architectures utilizing input/weight stationary dataflows. Traditional\ncompression strategies have typically overlooked PSUM quantization, which may\naccount for 69% of power consumption. This study introduces a novel Additive\nPartial Sum Quantization (APSQ) method, seamlessly integrating PSUM\naccumulation into the quantization framework. A grouping strategy that combines\nAPSQ with PSUM quantization enhanced by a reconfigurable architecture is\nfurther proposed. The APSQ performs nearly lossless on NLP and CV tasks across\nBERT, Segformer, and EfficientViT models while compressing PSUMs to INT8. This\nleads to a notable reduction in energy costs by 28-87%. Extended experiments on\nLLaMA2-7B demonstrate the potential of APSQ for large language models. Code is\navailable at https://github.com/Yonghao-Tan/APSQ.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "62nd ACM/IEEE Design Automation Conference (DAC) 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.03748v1",
    "published_date": "2025-04-10 14:45:17 UTC",
    "updated_date": "2025-04-10 14:45:17 UTC"
  },
  {
    "arxiv_id": "2504.07803v1",
    "title": "A System for Comprehensive Assessment of RAG Frameworks",
    "authors": [
      "Mattia Rengo",
      "Senad Beadini",
      "Domenico Alfano",
      "Roberto Abbruzzese"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has emerged as a standard paradigm for\nenhancing the factual accuracy and contextual relevance of Large Language\nModels (LLMs) by integrating retrieval mechanisms. However, existing evaluation\nframeworks fail to provide a holistic black-box approach to assessing RAG\nsystems, especially in real-world deployment scenarios. To address this gap, we\nintroduce SCARF (System for Comprehensive Assessment of RAG Frameworks), a\nmodular and flexible evaluation framework designed to benchmark deployed RAG\napplications systematically. SCARF provides an end-to-end, black-box evaluation\nmethodology, enabling a limited-effort comparison across diverse RAG\nframeworks. Our framework supports multiple deployment configurations and\nfacilitates automated testing across vector databases and LLM serving\nstrategies, producing a detailed performance report. Moreover, SCARF integrates\npractical considerations such as response coherence, providing a scalable and\nadaptable solution for researchers and industry professionals evaluating RAG\napplications. Using the REST APIs interface, we demonstrate how SCARF can be\napplied to real-world scenarios, showcasing its flexibility in assessing\ndifferent RAG frameworks and configurations. SCARF is available at GitHub\nrepository.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical Report, 7 pages, 2 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.07803v1",
    "published_date": "2025-04-10 14:41:34 UTC",
    "updated_date": "2025-04-10 14:41:34 UTC"
  },
  {
    "arxiv_id": "2504.07801v1",
    "title": "FairEval: Evaluating Fairness in LLM-Based Recommendations with Personality Awareness",
    "authors": [
      "Chandan Kumar Sah",
      "Xiaoli Lian",
      "Tony Xu",
      "Li Zhang"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have enabled their\napplication to recommender systems (RecLLMs), yet concerns remain regarding\nfairness across demographic and psychological user dimensions. We introduce\nFairEval, a novel evaluation framework to systematically assess fairness in\nLLM-based recommendations. FairEval integrates personality traits with eight\nsensitive demographic attributes,including gender, race, and age, enabling a\ncomprehensive assessment of user-level bias. We evaluate models, including\nChatGPT 4o and Gemini 1.5 Flash, on music and movie recommendations. FairEval's\nfairness metric, PAFS, achieves scores up to 0.9969 for ChatGPT 4o and 0.9997\nfor Gemini 1.5 Flash, with disparities reaching 34.79 percent. These results\nhighlight the importance of robustness in prompt sensitivity and support more\ninclusive recommendation systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages, 5 figures, under review at a top-tier ACM conference in\n  recommender systems",
    "pdf_url": "http://arxiv.org/pdf/2504.07801v1",
    "published_date": "2025-04-10 14:38:15 UTC",
    "updated_date": "2025-04-10 14:38:15 UTC"
  },
  {
    "arxiv_id": "2504.07779v1",
    "title": "Genetic Programming with Reinforcement Learning Trained Transformer for Real-World Dynamic Scheduling Problems",
    "authors": [
      "Xian Chen",
      "Rong Qu",
      "Jing Dong",
      "Ruibin Bai",
      "Yaochu Jin"
    ],
    "abstract": "Dynamic scheduling in real-world environments often struggles to adapt to\nunforeseen disruptions, making traditional static scheduling methods and\nhuman-designed heuristics inadequate. This paper introduces an innovative\napproach that combines Genetic Programming (GP) with a Transformer trained\nthrough Reinforcement Learning (GPRT), specifically designed to tackle the\ncomplexities of dynamic scheduling scenarios. GPRT leverages the Transformer to\nrefine heuristics generated by GP while also seeding and guiding the evolution\nof GP. This dual functionality enhances the adaptability and effectiveness of\nthe scheduling heuristics, enabling them to better respond to the dynamic\nnature of real-world tasks. The efficacy of this integrated approach is\ndemonstrated through a practical application in container terminal truck\nscheduling, where the GPRT method outperforms traditional GP, standalone\nTransformer methods, and other state-of-the-art competitors. The key\ncontribution of this research is the development of the GPRT method, which\nshowcases a novel combination of GP and Reinforcement Learning (RL) to produce\nrobust and efficient scheduling solutions. Importantly, GPRT is not limited to\ncontainer port truck scheduling; it offers a versatile framework applicable to\nvarious dynamic scheduling challenges. Its practicality, coupled with its\ninterpretability and ease of modification, makes it a valuable tool for diverse\nreal-world scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07779v1",
    "published_date": "2025-04-10 14:18:22 UTC",
    "updated_date": "2025-04-10 14:18:22 UTC"
  },
  {
    "arxiv_id": "2504.07776v2",
    "title": "SlimSpeech: Lightweight and Efficient Text-to-Speech with Slim Rectified Flow",
    "authors": [
      "Kaidi Wang",
      "Wenhao Guan",
      "Shenghui Lu",
      "Jianglong Yao",
      "Lin Li",
      "Qingyang Hong"
    ],
    "abstract": "Recently, flow matching based speech synthesis has significantly enhanced the\nquality of synthesized speech while reducing the number of inference steps. In\nthis paper, we introduce SlimSpeech, a lightweight and efficient speech\nsynthesis system based on rectified flow. We have built upon the existing\nspeech synthesis method utilizing the rectified flow model, modifying its\nstructure to reduce parameters and serve as a teacher model. By refining the\nreflow operation, we directly derive a smaller model with a more straight\nsampling trajectory from the larger model, while utilizing distillation\ntechniques to further enhance the model performance. Experimental results\ndemonstrate that our proposed method, with significantly reduced model\nparameters, achieves comparable performance to larger models through one-step\nsampling.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07776v2",
    "published_date": "2025-04-10 14:15:18 UTC",
    "updated_date": "2025-05-16 12:11:05 UTC"
  },
  {
    "arxiv_id": "2504.07763v1",
    "title": "Data over dialogue: Why artificial intelligence is unlikely to humanise medicine",
    "authors": [
      "Joshua Hatherley"
    ],
    "abstract": "Recently, a growing number of experts in artificial intelligence (AI) and\nmedicine have be-gun to suggest that the use of AI systems, particularly\nmachine learning (ML) systems, is likely to humanise the practice of medicine\nby substantially improving the quality of clinician-patient relationships. In\nthis thesis, however, I argue that medical ML systems are more likely to\nnegatively impact these relationships than to improve them. In particular, I\nargue that the use of medical ML systems is likely to comprise the quality of\ntrust, care, empathy, understanding, and communication between clinicians and\npatients.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07763v1",
    "published_date": "2025-04-10 14:03:40 UTC",
    "updated_date": "2025-04-10 14:03:40 UTC"
  },
  {
    "arxiv_id": "2504.07761v1",
    "title": "Exploring a Patch-Wise Approach for Privacy-Preserving Fake ID Detection",
    "authors": [
      "Javier Muñoz-Haro",
      "Ruben Tolosana",
      "Ruben Vera-Rodriguez",
      "Aythami Morales",
      "Julian Fierrez"
    ],
    "abstract": "In an increasingly digitalized world, verifying the authenticity of ID\ndocuments has become a critical challenge for real-life applications such as\ndigital banking, crypto-exchanges, renting, etc. This study focuses on the\ntopic of fake ID detection, covering several limitations in the field. In\nparticular, no publicly available data from real ID documents exists, and most\nstudies rely on proprietary in-house databases that are not available due to\nprivacy reasons. In order to shed some light on this critical challenge that\nmakes difficult to advance in the field, we explore a trade-off between privacy\n(i.e., amount of sensitive data available) and performance, proposing a novel\npatch-wise approach for privacy-preserving fake ID detection. Our proposed\napproach explores how privacy can be enhanced through: i) two levels of\nanonymization for an ID document (i.e., fully- and pseudo-anonymized), and ii)\ndifferent patch size configurations, varying the amount of sensitive data\nvisible in the patch image. Also, state-of-the-art methods such as Vision\nTransformers and Foundation Models are considered in the analysis. The\nexperimental framework shows that, on an unseen database (DLC-2021), our\nproposal achieves 13.91% and 0% EERs at patch and ID document level, showing a\ngood generalization to other databases. In addition to this exploration,\nanother key contribution of our study is the release of the first publicly\navailable database that contains 48,400 patches from both real and fake ID\ndocuments, along with the experimental framework and models, which will be\navailable in our GitHub.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07761v1",
    "published_date": "2025-04-10 14:01:22 UTC",
    "updated_date": "2025-04-10 14:01:22 UTC"
  },
  {
    "arxiv_id": "2504.07757v1",
    "title": "Search-contempt: a hybrid MCTS algorithm for training AlphaZero-like engines with better computational efficiency",
    "authors": [
      "Ameya Joshi"
    ],
    "abstract": "AlphaZero in 2017 was able to master chess and other games without human\nknowledge by playing millions of games against itself (self-play), with a\ncomputation budget running in the tens of millions of dollars. It used a\nvariant of the Monte Carlo Tree Search (MCTS) algorithm, known as PUCT. This\npaper introduces search-contempt, a novel hybrid variant of the MCTS algorithm\nthat fundamentally alters the distribution of positions generated in self-play,\npreferring more challenging positions. In addition, search-contempt has been\nshown to give a big boost in strength for engines in Odds Chess (where one side\nreceives an unfavorable position from the start). More significantly, it opens\nup the possibility of training a self-play based engine, in a much more\ncomputationally efficient manner with the number of training games running into\nhundreds of thousands, costing tens of thousands of dollars (instead of tens of\nmillions of training games costing millions of dollars required by AlphaZero).\nThis means that it may finally be possible to train such a program from zero on\na standard consumer GPU even with a very limited compute, cost, or time budget.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07757v1",
    "published_date": "2025-04-10 13:56:31 UTC",
    "updated_date": "2025-04-10 13:56:31 UTC"
  },
  {
    "arxiv_id": "2504.07756v1",
    "title": "\"i am a stochastic parrot, and so r u\": Is AI-based framing of human behaviour and cognition a conceptual metaphor or conceptual engineering?",
    "authors": [
      "Warmhold Jan Thomas Mollema",
      "Thomas Wachter"
    ],
    "abstract": "Given the massive integration of AI technologies into our daily lives,\nAI-related concepts are being used to metaphorically compare AI systems with\nhuman behaviour and/or cognitive abilities like language acquisition.\nRightfully, the epistemic success of these metaphorical comparisons should be\ndebated. Against the backdrop of the conflicting positions of the\n'computational' and 'meat' chauvinisms, we ask: can the conceptual\nconstellation of the computational and AI be applied to the human domain and\nwhat does it mean to do so? What is one doing when the conceptual\nconstellations of AI in particular are used in this fashion? Rooted in a\nWittgensteinian view of concepts and language-use, we consider two possible\nanswers and pit them against each other: either these examples are conceptual\nmetaphors, or they are attempts at conceptual engineering. We argue that they\nare conceptual metaphors, but that (1) this position is unaware of its own\nepistemological contingency, and (2) it risks committing the ''map-territory\nfallacy''. Down at the conceptual foundations of computation, (3) it most\nimportantly is a misleading 'double metaphor' because of the metaphorical\nconnection between human psychology and computation. In response to the\nshortcomings of this projected conceptual organisation of AI onto the human\ndomain, we argue that there is a semantic catch. The perspective of the\nconceptual metaphors shows avenues for forms of conceptual engineering. If this\nmethodology's criteria are met, the fallacies and epistemic shortcomings\nrelated to the conceptual metaphor view can be bypassed. At its best, the\ncross-pollution of the human and AI conceptual domains is one that prompts us\nto reflect anew on how the boundaries of our current concepts serve us and how\nthey could be approved.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "K.4"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.07756v1",
    "published_date": "2025-04-10 13:55:32 UTC",
    "updated_date": "2025-04-10 13:55:32 UTC"
  },
  {
    "arxiv_id": "2504.07749v1",
    "title": "NorEval: A Norwegian Language Understanding and Generation Evaluation Benchmark",
    "authors": [
      "Vladislav Mikhailov",
      "Tita Enstad",
      "David Samuel",
      "Hans Christian Farsethås",
      "Andrey Kutuzov",
      "Erik Velldal",
      "Lilja Øvrelid"
    ],
    "abstract": "This paper introduces NorEval, a new and comprehensive evaluation suite for\nlarge-scale standardized benchmarking of Norwegian generative language models\n(LMs). NorEval consists of 24 high-quality human-created datasets -- of which\nfive are created from scratch. In contrast to existing benchmarks for\nNorwegian, NorEval covers a broad spectrum of task categories targeting\nNorwegian language understanding and generation, establishes human baselines,\nand focuses on both of the official written standards of the Norwegian\nlanguage: Bokm{\\aa}l and Nynorsk. All our datasets and a collection of over 100\nhuman-written prompts are integrated into LM Evaluation Harness, ensuring\nflexible and reproducible evaluation. We describe the NorEval design and\npresent the results of benchmarking 19 open-source pre-trained and\ninstruction-tuned LMs for Norwegian in various scenarios. Our benchmark,\nevaluation framework, and annotation materials are publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07749v1",
    "published_date": "2025-04-10 13:44:55 UTC",
    "updated_date": "2025-04-10 13:44:55 UTC"
  },
  {
    "arxiv_id": "2504.07745v1",
    "title": "SF2T: Self-supervised Fragment Finetuning of Video-LLMs for Fine-Grained Understanding",
    "authors": [
      "Yangliu Hu",
      "Zikai Song",
      "Na Feng",
      "Yawei Luo",
      "Junqing Yu",
      "Yi-Ping Phoebe Chen",
      "Wei Yang"
    ],
    "abstract": "Video-based Large Language Models (Video-LLMs) have witnessed substantial\nadvancements in recent years, propelled by the advancement in multi-modal LLMs.\nAlthough these models have demonstrated proficiency in providing the overall\ndescription of videos, they struggle with fine-grained understanding,\nparticularly in aspects such as visual dynamics and video details inquiries. To\ntackle these shortcomings, we find that fine-tuning Video-LLMs on\nself-supervised fragment tasks, greatly improve their fine-grained video\nunderstanding abilities. Hence we propose two key contributions:(1)\nSelf-Supervised Fragment Fine-Tuning (SF$^2$T), a novel effortless fine-tuning\nmethod, employs the rich inherent characteristics of videos for training, while\nunlocking more fine-grained understanding ability of Video-LLMs. Moreover, it\nrelieves researchers from labor-intensive annotations and smartly circumvents\nthe limitations of natural language, which often fails to capture the complex\nspatiotemporal variations in videos; (2) A novel benchmark dataset, namely\nFineVidBench, for rigorously assessing Video-LLMs' performance at both the\nscene and fragment levels, offering a comprehensive evaluation of their\ncapabilities. We assessed multiple models and validated the effectiveness of\nSF$^2$T on them. Experimental results reveal that our approach improves their\nability to capture and interpret spatiotemporal details.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T45",
      "I.4.8; I.5"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2504.07745v1",
    "published_date": "2025-04-10 13:40:34 UTC",
    "updated_date": "2025-04-10 13:40:34 UTC"
  },
  {
    "arxiv_id": "2504.07729v1",
    "title": "Benchmarking Multi-Organ Segmentation Tools for Multi-Parametric T1-weighted Abdominal MRI",
    "authors": [
      "Nicole Tran",
      "Anisa Prasad",
      "Yan Zhuang",
      "Tejas Sudharshan Mathai",
      "Boah Kim",
      "Sydney Lewis",
      "Pritam Mukherjee",
      "Jianfei Liu",
      "Ronald M. Summers"
    ],
    "abstract": "The segmentation of multiple organs in multi-parametric MRI studies is\ncritical for many applications in radiology, such as correlating imaging\nbiomarkers with disease status (e.g., cirrhosis, diabetes). Recently, three\npublicly available tools, such as MRSegmentator (MRSeg), TotalSegmentator MRI\n(TS), and TotalVibeSegmentator (VIBE), have been proposed for multi-organ\nsegmentation in MRI. However, the performance of these tools on specific MRI\nsequence types has not yet been quantified. In this work, a subset of 40\nvolumes from the public Duke Liver Dataset was curated. The curated dataset\ncontained 10 volumes each from the pre-contrast fat saturated T1, arterial T1w,\nvenous T1w, and delayed T1w phases, respectively. Ten abdominal structures were\nmanually annotated in these volumes. Next, the performance of the three public\ntools was benchmarked on this curated dataset. The results indicated that MRSeg\nobtained a Dice score of 80.7 $\\pm$ 18.6 and Hausdorff Distance (HD) error of\n8.9 $\\pm$ 10.4 mm. It fared the best ($p < .05$) across the different sequence\ntypes in contrast to TS and VIBE.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at SPIE Medical Imaging 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.07729v1",
    "published_date": "2025-04-10 13:27:27 UTC",
    "updated_date": "2025-04-10 13:27:27 UTC"
  },
  {
    "arxiv_id": "2504.07719v1",
    "title": "Counting Hours, Counting Losses: The Toll of Unpredictable Work Schedules on Financial Security",
    "authors": [
      "Pegah Nokhiz",
      "Aravinda Kanchana Ruwanpathirana",
      "Aditya Bhaskara",
      "Suresh Venkatasubramanian"
    ],
    "abstract": "Financial instability has become a significant issue in today's society.\nWhile research typically focuses on financial aspects, there is a tendency to\noverlook time-related aspects of unstable work schedules. The inability to rely\non consistent work schedules leads to burnout, work-family conflicts, and\nfinancial shocks that directly impact workers' income and assets. Unforeseen\nfluctuations in earnings pose challenges in financial planning, affecting\ndecisions on savings and spending and ultimately undermining individuals'\nlong-term financial stability and well-being.\n  This issue is particularly evident in sectors where workers experience\nfrequently changing schedules without sufficient notice, including those in the\nfood service and retail sectors, part-time and hourly workers, and individuals\nwith lower incomes. These groups are already more financially vulnerable, and\nthe unpredictable nature of their schedules exacerbates their financial\nfragility.\n  Our objective is to understand how unforeseen fluctuations in earnings\nexacerbate financial fragility by investigating the extent to which\nindividuals' financial management depends on their ability to anticipate and\nplan for the future. To address this question, we develop a simulation\nframework that models how individuals optimize utility amidst financial\nuncertainty and the imperative to avoid financial ruin. We employ online\nlearning techniques, specifically adapting workers' consumption policies based\non evolving information about their work schedules.\n  With this framework, we show both theoretically and empirically how a\nworker's capacity to anticipate schedule changes enhances their long-term\nutility. Conversely, the inability to predict future events can worsen workers'\ninstability. Moreover, our framework enables us to explore interventions to\nmitigate the problem of schedule uncertainty and evaluate their effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07719v1",
    "published_date": "2025-04-10 13:09:56 UTC",
    "updated_date": "2025-04-10 13:09:56 UTC"
  },
  {
    "arxiv_id": "2504.07717v2",
    "title": "PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization",
    "authors": [
      "Yang Jiao",
      "Xiaodong Wang",
      "Kai Yang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\na wide range of applications, e.g., medical question-answering, mathematical\nsciences, and code generation. However, they also exhibit inherent limitations,\nsuch as outdated knowledge and susceptibility to hallucinations.\nRetrieval-Augmented Generation (RAG) has emerged as a promising paradigm to\naddress these issues, but it also introduces new vulnerabilities. Recent\nefforts have focused on the security of RAG-based LLMs, yet existing attack\nmethods face three critical challenges: (1) their effectiveness declines\nsharply when only a limited number of poisoned texts can be injected into the\nknowledge database, (2) they lack sufficient stealth, as the attacks are often\ndetectable by anomaly detection systems, which compromises their effectiveness,\nand (3) they rely on heuristic approaches to generate poisoned texts, lacking\nformal optimization frameworks and theoretic guarantees, which limits their\neffectiveness and applicability. To address these issues, we propose\ncoordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack\nthat introduces a small number of poisoned texts into the knowledge database\nwhile embedding a backdoor trigger within the prompt. When activated, the\ntrigger causes the LLM to generate pre-designed responses to targeted queries,\nwhile maintaining normal behavior in other contexts. This ensures both high\neffectiveness and stealth. We formulate the attack generation process as a\nbilevel optimization problem leveraging a principled optimization framework to\ndevelop optimal poisoned texts and triggers. Extensive experiments across\ndiverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving\na high attack success rate even with a limited number of poisoned texts and\nsignificantly improved stealth compared to existing methods.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.07717v2",
    "published_date": "2025-04-10 13:09:50 UTC",
    "updated_date": "2025-04-17 02:01:42 UTC"
  },
  {
    "arxiv_id": "2504.07711v1",
    "title": "Merging Embedded Topics with Optimal Transport for Online Topic Modeling on Data Streams",
    "authors": [
      "Federica Granese",
      "Benjamin Navet",
      "Serena Villata",
      "Charles Bouveyron"
    ],
    "abstract": "Topic modeling is a key component in unsupervised learning, employed to\nidentify topics within a corpus of textual data. The rapid growth of social\nmedia generates an ever-growing volume of textual data daily, making online\ntopic modeling methods essential for managing these data streams that\ncontinuously arrive over time. This paper introduces a novel approach to online\ntopic modeling named StreamETM. This approach builds on the Embedded Topic\nModel (ETM) to handle data streams by merging models learned on consecutive\npartial document batches using unbalanced optimal transport. Additionally, an\nonline change point detection algorithm is employed to identify shifts in\ntopics over time, enabling the identification of significant changes in the\ndynamics of text streams. Numerical experiments on simulated and real-world\ndata show StreamETM outperforming competitors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper under review",
    "pdf_url": "http://arxiv.org/pdf/2504.07711v1",
    "published_date": "2025-04-10 13:04:56 UTC",
    "updated_date": "2025-04-10 13:04:56 UTC"
  },
  {
    "arxiv_id": "2504.07655v1",
    "title": "Synthesizing High-Quality Programming Tasks with LLM-based Expert and Student Agents",
    "authors": [
      "Manh Hung Nguyen",
      "Victor-Alexandru Pădurean",
      "Alkis Gotovos",
      "Sebastian Tschiatschek",
      "Adish Singla"
    ],
    "abstract": "Generative AI is transforming computing education by enabling the automatic\ngeneration of personalized content and feedback. We investigate its\ncapabilities in providing high-quality programming tasks to students. Despite\npromising advancements in task generation, a quality gap remains between\nAI-generated and expert-created tasks. The AI-generated tasks may not align\nwith target programming concepts, could be incomprehensible for students to\nsolve, or may contain critical issues such as incorrect tests. Existing works\noften require interventions from human teachers for validation. We address\nthese challenges by introducing PyTaskSyn, a novel synthesis technique that\nfirst generates a programming task and then decides whether it meets certain\nquality criteria to be given to students. The key idea is to break this process\ninto multiple stages performed by expert and student agents simulated using\nboth strong and weaker generative models. Through extensive evaluation, we show\nthat PyTaskSyn significantly improves task quality compared to baseline\ntechniques and showcases the importance of each specialized agent type in our\nvalidation pipeline. Additionally, we conducted user studies using our publicly\navailable web application and show that PyTaskSyn can deliver high-quality\nprogramming tasks comparable to expert-designed ones while reducing workload\nand costs, and being more engaging than programming tasks that are available in\nonline resources.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "AIED'25 paper",
    "pdf_url": "http://arxiv.org/pdf/2504.07655v1",
    "published_date": "2025-04-10 11:08:39 UTC",
    "updated_date": "2025-04-10 11:08:39 UTC"
  },
  {
    "arxiv_id": "2504.07654v1",
    "title": "ms-Mamba: Multi-scale Mamba for Time-Series Forecasting",
    "authors": [
      "Yusuf Meric Karadag",
      "Sinan Kalkan",
      "Ipek Gursel Dino"
    ],
    "abstract": "The problem of Time-series Forecasting is generally addressed by recurrent,\nTransformer-based and the recently proposed Mamba-based architectures. However,\nexisting architectures generally process their input at a single temporal\nscale, which may be sub-optimal for many tasks where information changes over\nmultiple time scales. In this paper, we introduce a novel architecture called\nMulti-scale Mamba (ms-Mamba) to address this gap. ms-Mamba incorporates\nmultiple temporal scales by using multiple Mamba blocks with different sampling\nrates ($\\Delta$s). Our experiments on many benchmarks demonstrate that ms-Mamba\noutperforms state-of-the-art approaches, including the recently proposed\nTransformer-based and Mamba-based models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07654v1",
    "published_date": "2025-04-10 11:06:57 UTC",
    "updated_date": "2025-04-10 11:06:57 UTC"
  },
  {
    "arxiv_id": "2504.07646v1",
    "title": "On the Temporal Question-Answering Capabilities of Large Language Models Over Anonymized Data",
    "authors": [
      "Alfredo Garrachón Ruiz",
      "Tomás de la Rosa",
      "Daniel Borrajo"
    ],
    "abstract": "The applicability of Large Language Models (LLMs) in temporal reasoning tasks\nover data that is not present during training is still a field that remains to\nbe explored. In this paper we work on this topic, focusing on structured and\nsemi-structured anonymized data. We not only develop a direct LLM pipeline, but\nalso compare various methodologies and conduct an in-depth analysis. We\nidentified and examined seventeen common temporal reasoning tasks in natural\nlanguage, focusing on their algorithmic components. To assess LLM performance,\nwe created the \\textit{Reasoning and Answering Temporal Ability} dataset\n(RATA), featuring semi-structured anonymized data to ensure reliance on\nreasoning rather than on prior knowledge. We compared several methodologies,\ninvolving SoTA techniques such as Tree-of-Thought, self-reflexion and code\nexecution, tuned specifically for this scenario. Our results suggest that\nachieving scalable and reliable solutions requires more than just standalone\nLLMs, highlighting the need for integrated approaches.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 7 tables, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.07646v1",
    "published_date": "2025-04-10 10:48:42 UTC",
    "updated_date": "2025-04-10 10:48:42 UTC"
  },
  {
    "arxiv_id": "2504.07640v1",
    "title": "Enhancing Large Language Models through Neuro-Symbolic Integration and Ontological Reasoning",
    "authors": [
      "Ruslan Idelfonso Magana Vsevolodovna",
      "Marco Monti"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate impressive capabilities in natural\nlanguage processing but suffer from inaccuracies and logical inconsistencies\nknown as hallucinations. This compromises their reliability, especially in\ndomains requiring factual accuracy. We propose a neuro-symbolic approach\nintegrating symbolic ontological reasoning and machine learning methods to\nenhance the consistency and reliability of LLM outputs. Our workflow utilizes\nOWL ontologies, a symbolic reasoner (e.g., HermiT) for consistency checking,\nand a lightweight machine learning model (logistic regression) for mapping\nnatural language statements into logical forms compatible with the ontology.\nWhen inconsistencies between LLM outputs and the ontology are detected, the\nsystem generates explanatory feedback to guide the LLM towards a corrected,\nlogically coherent response in an iterative refinement loop. We present a\nworking Python prototype demonstrating this pipeline. Experimental results in a\ndefined domain suggest significant improvements in semantic coherence and\nfactual accuracy of LLM outputs, showcasing the potential of combining LLM\nfluency with the rigor of formal semantics.",
    "categories": [
      "cs.AI",
      "68T30",
      "I.2.3; I.2.4; I.2.6; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 1 figure, includes prototype implementation and\n  experimental evaluation. Submitted for consideration in the arXiv Artificial\n  Intelligence category (cs.AI)",
    "pdf_url": "http://arxiv.org/pdf/2504.07640v1",
    "published_date": "2025-04-10 10:39:24 UTC",
    "updated_date": "2025-04-10 10:39:24 UTC"
  },
  {
    "arxiv_id": "2504.07638v1",
    "title": "Predicting the Lifespan of Industrial Printheads with Survival Analysis",
    "authors": [
      "Dan Parii",
      "Evelyne Janssen",
      "Guangzhi Tang",
      "Charalampos Kouzinopoulos",
      "Marcin Pietrasik"
    ],
    "abstract": "Accurately predicting the lifespan of critical device components is essential\nfor maintenance planning and production optimization, making it a topic of\nsignificant interest in both academia and industry. In this work, we\ninvestigate the use of survival analysis for predicting the lifespan of\nproduction printheads developed by Canon Production Printing. Specifically, we\nfocus on the application of five techniques to estimate survival probabilities\nand failure rates: the Kaplan-Meier estimator, Cox proportional hazard model,\nWeibull accelerated failure time model, random survival forest, and gradient\nboosting. The resulting estimates are further refined using isotonic regression\nand subsequently aggregated to determine the expected number of failures. The\npredictions are then validated against real-world ground truth data across\nmultiple time windows to assess model reliability. Our quantitative evaluation\nusing three performance metrics demonstrates that survival analysis outperforms\nindustry-standard baseline methods for printhead lifespan prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07638v1",
    "published_date": "2025-04-10 10:38:13 UTC",
    "updated_date": "2025-04-10 10:38:13 UTC"
  },
  {
    "arxiv_id": "2504.07635v1",
    "title": "Generative Artificial Intelligence for Internet of Things Computing: A Systematic Survey",
    "authors": [
      "Fabrizio Mangione",
      "Claudio Savaglio",
      "Giancarlo Fortino"
    ],
    "abstract": "The integration of Generative Artificial Intelligence (GenAI) within the\nInternet of Things (IoT) is garnering considerable interest. This growing\nattention stems from the continuous evolution and widespread adoption they are\nboth having individually, enough to spontaneously reshape numerous sectors,\nincluding Healthcare, Manufacturing, and Smart Cities. Hence, their increasing\npopularity has catalyzed further extensive research for understanding the\npotential of the duo GenAI-IoT, how they interplay, and to which extent their\nsynergy can innovate the state-of-the-art in their individual scenarios.\nHowever, despite the increasing prominence of GenAI for IoT Computing, much of\nthe existing research remains focused on specific, narrowly scoped\napplications. This fragmented approach highlights the need for a more\ncomprehensive analysis of the potential, challenges, and implications of GenAI\nintegration within the broader IoT ecosystem. This survey exactly aims to\naddress this gap by providing a holistic overview of the opportunities, issues,\nand considerations arising from the convergence of these mainstream paradigms.\nOur contribution is realized through a systematic literature review following\nthe PRISMA methodology. A comparison framework is presented, and well-defined\nresearch questions are outlined to comprehensively explore the past, present,\nand future directions of GenAI integration with IoT Computing, offering\nvaluable insights for both experts and newcomers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07635v1",
    "published_date": "2025-04-10 10:32:18 UTC",
    "updated_date": "2025-04-10 10:32:18 UTC"
  },
  {
    "arxiv_id": "2504.07625v1",
    "title": "Deep Learning Meets Teleconnections: Improving S2S Predictions for European Winter Weather",
    "authors": [
      "Philine L. Bommer",
      "Marlene Kretschmer",
      "Fiona R. Spuler",
      "Kirill Bykov",
      "Marina M. -C. Höhne"
    ],
    "abstract": "Predictions on subseasonal-to-seasonal (S2S) timescales--ranging from two\nweeks to two month--are crucial for early warning systems but remain\nchallenging owing to chaos in the climate system. Teleconnections, such as the\nstratospheric polar vortex (SPV) and Madden-Julian Oscillation (MJO), offer\nwindows of enhanced predictability, however, their complex interactions remain\nunderutilized in operational forecasting. Here, we developed and evaluated deep\nlearning architectures to predict North Atlantic-European (NAE) weather\nregimes, systematically assessing the role of remote drivers in improving S2S\nforecast skill of deep learning models. We implemented (1) a Long Short-term\nMemory (LSTM) network predicting the NAE regimes of the next six weeks based on\nprevious regimes, (2) an Index-LSTM incorporating SPV and MJO indices, and (3)\na ViT-LSTM using a Vision Transformer to directly encode stratospheric wind and\ntropical outgoing longwave radiation fields. These models are compared with\noperational hindcasts as well as other AI models. Our results show that\nleveraging teleconnection information enhances skill at longer lead times.\nNotably, the ViT-LSTM outperforms ECMWF's subseasonal hindcasts beyond week 4\nby improving Scandinavian Blocking (SB) and Atlantic Ridge (AR) predictions.\nAnalysis of high-confidence predictions reveals that NAO-, SB, and AR\nopportunity forecasts can be associated with SPV variability and MJO phase\npatterns aligning with established pathways, also indicating new patterns.\nOverall, our work demonstrates that encoding physically meaningful climate\nfields can enhance S2S prediction skill, advancing AI-driven subseasonal\nforecast. Moreover, the experiments highlight the potential of deep learning\nmethods as investigative tools, providing new insights into atmospheric\ndynamics and predictability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.07625v1",
    "published_date": "2025-04-10 10:23:07 UTC",
    "updated_date": "2025-04-10 10:23:07 UTC"
  },
  {
    "arxiv_id": "2504.08014v1",
    "title": "Utility Inspired Generalizations of TOPSIS",
    "authors": [
      "Robert Susmaga",
      "Izabela Szczech"
    ],
    "abstract": "TOPSIS, a popular method for ranking alternatives is based on aggregated\ndistances to ideal and anti-ideal points. As such, it was considered to be\nessentially different from widely popular and acknowledged `utility-based\nmethods', which build rankings from weight-averaged utility values.\nNonetheless, TOPSIS has recently been shown to be a natural generalization of\nthese `utility-based methods' on the grounds that the distances it uses can be\ndecomposed into so called weight-scaled means (WM) and weight-scaled standard\ndeviations (WSD) of utilities. However, the influence that these two components\nexert on the final ranking cannot be in any way influenced in the standard\nTOPSIS. This is why, building on our previous results, in this paper we put\nforward modifications that make TOPSIS aggregations responsive to WM and WSD,\nachieving some amount of well interpretable control over how the rankings are\ninfluenced by WM and WSD. The modifications constitute a natural generalization\nof the standard TOPSIS method because, thanks to them, the generalized TOPSIS\nmay turn into the original TOPSIS or, otherwise, following the decision maker's\npreferences, may trade off WM for WSD or WSD for WM. In the latter case, TOPSIS\ngradually reduces to a regular `utility-based method'. All in all, we believe\nthat the proposed generalizations constitute an interesting practical tool for\ninfluencing the ranking by controlled application of a new form of decision\nmaker's preferences.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08014v1",
    "published_date": "2025-04-10 10:17:55 UTC",
    "updated_date": "2025-04-10 10:17:55 UTC"
  },
  {
    "arxiv_id": "2504.07624v1",
    "title": "ConceptFormer: Towards Efficient Use of Knowledge-Graph Embeddings in Large Language Models",
    "authors": [
      "Joel Barmettler",
      "Abraham Bernstein",
      "Luca Rossetto"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has enjoyed increased attention in the\nrecent past and recent advancements in Large Language Models (LLMs) have\nhighlighted the importance of integrating world knowledge into these systems.\nCurrent RAG methodologies often modify the internal architecture of pre-trained\nlanguage models (PLMs) or rely on textifying knowledge graphs (KGs), which is\ninefficient in terms of token usage. This paper introduces ConceptFormer, a new\napproach to augment LLMs with structured knowledge from KGs, such as Wikidata,\nwithout altering their internal structure or relying on textual input of KGs.\nConceptFormer operates in the LLM embedding vector space, creating and\ninjecting \\emph{concept vectors} that encapsulate the information of the KG\nnodes directly. Trained in conjunction with a frozen LLM, ConceptFormer\ngenerates a comprehensive lookup table that maps KG nodes to their respective\nconcept vectors. The approach aims to enhance the factual recall capabilities\nof LLMs by enabling them to process these concept vectors natively, thus\nenriching them with structured world knowledge in an efficient and scalable\nmanner. Our experiments demonstrate that the addition of concept vectors to\nGPT-2 0.1B substantially increases its factual recall ability (Hit@10) by up to\n272\\% when tested on sentences from Wikipedia and up to 348\\% on synthetically\ngenerated sentences. Even injecting only a single concept vector into the\nprompt increases factual recall ability (Hit@10) by up to 213\\% on Wikipedia\nsentences, significantly outperforming RAG with graph textification while\nconsuming 130x fewer input tokens.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07624v1",
    "published_date": "2025-04-10 10:17:08 UTC",
    "updated_date": "2025-04-10 10:17:08 UTC"
  },
  {
    "arxiv_id": "2504.07619v1",
    "title": "Beating Transformers using Synthetic Cognition",
    "authors": [
      "Alfredo Ibias",
      "Miguel Rodriguez-Galindo",
      "Hector Antona",
      "Guillem Ramirez-Miranda",
      "Enric Guinovart"
    ],
    "abstract": "The road to Artificial General Intelligence goes through the generation of\nepisodic reactive behaviors, where the Transformer architecture has been proven\nto be the state-of-the-art. However, they still fail to develop reasoning.\nRecently, a novel approach for developing cognitive architectures, called\nSynthetic Cognition, has been proposed and implemented to develop instantaneous\nreactive behavior. In this study, we aim to explore the use of Synthetic\nCognition to develop episodic reactive behaviors. We propose a mechanism to\ndeal with sequences for the recent implementation of Synthetic Cognition, and\ntest it against DNA foundation models in DNA sequence classification tasks. In\nour experiments, our proposal clearly outperforms the DNA foundation models,\nobtaining the best score on more benchmark tasks than the alternatives. Thus,\nwe achieve two goals: expanding Synthetic Cognition to deal with sequences, and\nbeating the Transformer architecture for sequence classification.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07619v1",
    "published_date": "2025-04-10 10:07:05 UTC",
    "updated_date": "2025-04-10 10:07:05 UTC"
  },
  {
    "arxiv_id": "2504.07603v1",
    "title": "RASMD: RGB And SWIR Multispectral Driving Dataset for Robust Perception in Adverse Conditions",
    "authors": [
      "Youngwan Jin",
      "Michal Kovac",
      "Yagiz Nalcakan",
      "Hyeongjin Ju",
      "Hanbin Song",
      "Sanghyeop Yeo",
      "Shiho Kim"
    ],
    "abstract": "Current autonomous driving algorithms heavily rely on the visible spectrum,\nwhich is prone to performance degradation in adverse conditions like fog, rain,\nsnow, glare, and high contrast. Although other spectral bands like\nnear-infrared (NIR) and long-wave infrared (LWIR) can enhance vision perception\nin such situations, they have limitations and lack large-scale datasets and\nbenchmarks. Short-wave infrared (SWIR) imaging offers several advantages over\nNIR and LWIR. However, no publicly available large-scale datasets currently\nincorporate SWIR data for autonomous driving. To address this gap, we introduce\nthe RGB and SWIR Multispectral Driving (RASMD) dataset, which comprises 100,000\nsynchronized and spatially aligned RGB-SWIR image pairs collected across\ndiverse locations, lighting, and weather conditions. In addition, we provide a\nsubset for RGB-SWIR translation and object detection annotations for a subset\nof challenging traffic scenarios to demonstrate the utility of SWIR imaging\nthrough experiments on both object detection and RGB-to-SWIR image translation.\nOur experiments show that combining RGB and SWIR data in an ensemble framework\nsignificantly improves detection accuracy compared to RGB-only approaches,\nparticularly in conditions where visible-spectrum sensors struggle. We\nanticipate that the RASMD dataset will advance research in multispectral\nimaging for autonomous driving and robust perception systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07603v1",
    "published_date": "2025-04-10 09:54:57 UTC",
    "updated_date": "2025-04-10 09:54:57 UTC"
  },
  {
    "arxiv_id": "2504.07597v1",
    "title": "Learning Long Short-Term Intention within Human Daily Behaviors",
    "authors": [
      "Zhe Sun",
      "Rujie Wu",
      "Xiaodong Yang",
      "Hongzhao Xie",
      "Haiyan Jiang",
      "Junda Bi",
      "Zhenliang Zhang"
    ],
    "abstract": "In the domain of autonomous household robots, it is of utmost importance for\nrobots to understand human behaviors and provide appropriate services. This\nrequires the robots to possess the capability to analyze complex human\nbehaviors and predict the true intentions of humans. Traditionally, humans are\nperceived as flawless, with their decisions acting as the standards that robots\nshould strive to align with. However, this raises a pertinent question: What if\nhumans make mistakes? In this research, we present a unique task, termed \"long\nshort-term intention prediction\". This task requires robots can predict the\nlong-term intention of humans, which aligns with human values, and the short\nterm intention of humans, which reflects the immediate action intention.\nMeanwhile, the robots need to detect the potential non-consistency between the\nshort-term and long-term intentions, and provide necessary warnings and\nsuggestions. To facilitate this task, we propose a long short-term intention\nmodel to represent the complex intention states, and build a dataset to train\nthis intention model. Then we propose a two-stage method to integrate the\nintention model for robots: i) predicting human intentions of both value-based\nlong-term intentions and action-based short-term intentions; and 2) analyzing\nthe consistency between the long-term and short-term intentions. Experimental\nresults indicate that the proposed long short-term intention model can assist\nrobots in comprehending human behavioral patterns over both long-term and\nshort-term durations, which helps determine the consistency between long-term\nand short-term intentions of humans.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07597v1",
    "published_date": "2025-04-10 09:50:18 UTC",
    "updated_date": "2025-04-10 09:50:18 UTC"
  },
  {
    "arxiv_id": "2504.07596v2",
    "title": "Boosting Universal LLM Reward Design through Heuristic Reward Observation Space Evolution",
    "authors": [
      "Zen Kit Heng",
      "Zimeng Zhao",
      "Tianhao Wu",
      "Yuanfei Wang",
      "Mingdong Wu",
      "Yangang Wang",
      "Hao Dong"
    ],
    "abstract": "Large Language Models (LLMs) are emerging as promising tools for automated\nreinforcement learning (RL) reward design, owing to their robust capabilities\nin commonsense reasoning and code generation. By engaging in dialogues with RL\nagents, LLMs construct a Reward Observation Space (ROS) by selecting relevant\nenvironment states and defining their internal operations. However, existing\nframeworks have not effectively leveraged historical exploration data or manual\ntask descriptions to iteratively evolve this space. In this paper, we propose a\nnovel heuristic framework that enhances LLM-driven reward design by evolving\nthe ROS through a table-based exploration caching mechanism and a text-code\nreconciliation strategy. Our framework introduces a state execution table,\nwhich tracks the historical usage and success rates of environment states,\novercoming the Markovian constraint typically found in LLM dialogues and\nfacilitating more effective exploration. Furthermore, we reconcile\nuser-provided task descriptions with expert-defined success criteria using\nstructured prompts, ensuring alignment in reward design objectives.\nComprehensive evaluations on benchmark RL tasks demonstrate the effectiveness\nand stability of the proposed framework. Code and video demos are available at\njingjjjjjie.github.io/LLM2Reward.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.07596v2",
    "published_date": "2025-04-10 09:48:56 UTC",
    "updated_date": "2025-04-11 02:05:01 UTC"
  },
  {
    "arxiv_id": "2504.08832v1",
    "title": "Generative AI in Collaborative Academic Report Writing: Advantages, Disadvantages, and Ethical Considerations",
    "authors": [
      "Mahshid Sadeghpour",
      "Arathi Arakala",
      "Asha Rao"
    ],
    "abstract": "The availability and abundance of GenAI tools to administer tasks\ntraditionally managed by people have raised concerns, particularly within the\neducation and academic sectors, as some students may highly rely on these tools\nto complete the assignments designed to enable learning. This article focuses\non informing students about the significance of investing their time during\ntheir studies on developing essential life-long learning skills using their own\ncritical thinking, rather than depending on AI models that are susceptible to\nmisinformation, hallucination, and bias. As we transition to an AI-centric era,\nit is important to educate students on how these models work, their pitfalls,\nand the ethical concerns associated with feeding data to such tools.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "21 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.08832v1",
    "published_date": "2025-04-10 09:22:40 UTC",
    "updated_date": "2025-04-10 09:22:40 UTC"
  },
  {
    "arxiv_id": "2504.07574v2",
    "title": "Malware analysis assisted by AI with R2AI",
    "authors": [
      "Axelle Apvrille",
      "Daniel Nakov"
    ],
    "abstract": "This research studies the quality, speed and cost of malware analysis\nassisted by artificial intelligence. It focuses on Linux and IoT malware of\n2024-2025, and uses r2ai, the AI extension of Radare2's disassembler. Not all\nmalware and not all LLMs are equivalent but the study shows excellent results\nwith Claude 3.5 and 3.7 Sonnet. Despite a few errors, the quality of analysis\nis overall equal or better than without AI assistance. For good results, the AI\ncannot operate alone and must constantly be guided by an experienced analyst.\nThe gain of speed is largely visible with AI assistance, even when taking\naccount the time to understand AI's hallucinations, exaggerations and\nomissions. The cost is usually noticeably lower than the salary of a malware\nanalyst, but attention and guidance is needed to keep it under control in cases\nwhere the AI would naturally loop without showing progress.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages;",
    "pdf_url": "http://arxiv.org/pdf/2504.07574v2",
    "published_date": "2025-04-10 09:17:45 UTC",
    "updated_date": "2025-04-11 15:06:17 UTC"
  },
  {
    "arxiv_id": "2504.07567v1",
    "title": "Benchmarking Image Embeddings for E-Commerce: Evaluating Off-the Shelf Foundation Models, Fine-Tuning Strategies and Practical Trade-offs",
    "authors": [
      "Urszula Czerwinska",
      "Cenk Bircanoglu",
      "Jeremy Chamoux"
    ],
    "abstract": "We benchmark foundation models image embeddings for classification and\nretrieval in e-Commerce, evaluating their suitability for real-world\napplications. Our study spans embeddings from pre-trained convolutional and\ntransformer models trained via supervised, self-supervised, and text-image\ncontrastive learning. We assess full fine-tuning and transfer learning\n(top-tuning) on six diverse e-Commerce datasets: fashion, consumer goods, cars,\nfood, and retail. Results show full fine-tuning consistently performs well,\nwhile text-image and self-supervised embeddings can match its performance with\nless training. While supervised embeddings remain stable across architectures,\nSSL and contrastive embeddings vary significantly, often benefiting from\ntop-tuning. Top-tuning emerges as an efficient alternative to full fine-tuning,\nreducing computational costs. We also explore cross-tuning, noting its impact\ndepends on dataset characteristics. Our findings offer practical guidelines for\nembedding selection and fine-tuning strategies, balancing efficiency and\nperformance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CE",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted at Future Technologies Conference (FTC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.07567v1",
    "published_date": "2025-04-10 08:57:28 UTC",
    "updated_date": "2025-04-10 08:57:28 UTC"
  },
  {
    "arxiv_id": "2504.07566v2",
    "title": "Diffusion Transformers for Tabular Data Time Series Generation",
    "authors": [
      "Fabrizio Garuti",
      "Enver Sangineto",
      "Simone Luetto",
      "Lorenzo Forni",
      "Rita Cucchiara"
    ],
    "abstract": "Tabular data generation has recently attracted a growing interest due to its\ndifferent application scenarios. However, generating time series of tabular\ndata, where each element of the series depends on the others, remains a largely\nunexplored domain. This gap is probably due to the difficulty of jointly\nsolving different problems, the main of which are the heterogeneity of tabular\ndata (a problem common to non-time-dependent approaches) and the variable\nlength of a time series. In this paper, we propose a Diffusion Transformers\n(DiTs) based approach for tabular data series generation. Inspired by the\nrecent success of DiTs in image and video generation, we extend this framework\nto deal with heterogeneous data and variable-length sequences. Using extensive\nexperiments on six datasets, we show that the proposed approach outperforms\nprevious work by a large margin.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2025. 26 pages, 19 figures, 13 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.07566v2",
    "published_date": "2025-04-10 08:56:09 UTC",
    "updated_date": "2025-04-18 12:55:39 UTC"
  },
  {
    "arxiv_id": "2504.07562v1",
    "title": "ReXCL: A Tool for Requirement Document Extraction and Classification",
    "authors": [
      "Paheli Bhattacharya",
      "Manojit Chakraborty",
      "Santhosh Kumar Arumugam",
      "Rishabh Gupta"
    ],
    "abstract": "This paper presents the ReXCL tool, which automates the extraction and\nclassification processes in requirement engineering, enhancing the software\ndevelopment lifecycle. The tool features two main modules: Extraction, which\nprocesses raw requirement documents into a predefined schema using heuristics\nand predictive modeling, and Classification, which assigns class labels to\nrequirements using adaptive fine-tuning of encoder-based models. The final\noutput can be exported to external requirement engineering tools. Performance\nevaluations indicate that ReXCL significantly improves efficiency and accuracy\nin managing requirements, marking a novel approach to automating the\nschematization of semi-structured requirement documents.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07562v1",
    "published_date": "2025-04-10 08:46:54 UTC",
    "updated_date": "2025-04-10 08:46:54 UTC"
  },
  {
    "arxiv_id": "2504.07540v2",
    "title": "PoGO: A Scalable Proof of Useful Work via Quantized Gradient Descent and Merkle Proofs",
    "authors": [
      "José I. Orlicki"
    ],
    "abstract": "We present a design called Proof of Gradient Optimization (PoGO) for\nblockchain consensus, where miners produce verifiable evidence of training\nlarge-scale machine-learning models. Building on previous work, we incorporate\nquantized gradients (4-bit precision) to reduce storage and computation\nrequirements, while still preserving the ability of verifiers to check that\nreal progress has been made on lowering the model's loss. Additionally, we\nemploy Merkle proofs over the full 32-bit model to handle large parameter sets\nand to enable random leaf checks with minimal on-chain data. We illustrate\nthese ideas using GPT-3 (175B parameters) as a reference example and also refer\nto smaller but high-performance models (e.g., Gemma~3 with 27B parameters). We\nprovide an empirical cost analysis showing that verification is significantly\ncheaper than training, thanks in part to quantization and sampling. We also\ndiscuss the necessity of longer block times (potentially hours) when\nincorporating meaningful training steps, the trade-offs when using specialized\nGPU hardware, and how binary diffs may incrementally optimize updates. Finally,\nwe note that fine-tuning can be handled in a similar manner, merely changing\nthe dataset and the manner of sampling but preserving the overall verification\nflow. Our protocol allows verifiers to issue either positive or negative\nattestations; these are aggregated at finalization to either confirm the update\nor slash the miner.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 1 figure, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.07540v2",
    "published_date": "2025-04-10 08:09:34 UTC",
    "updated_date": "2025-04-23 12:59:42 UTC"
  },
  {
    "arxiv_id": "2504.08829v1",
    "title": "Datum-wise Transformer for Synthetic Tabular Data Detection in the Wild",
    "authors": [
      "G. Charbel N. Kindji",
      "Elisa Fromont",
      "Lina Maria Rojas-Barahona",
      "Tanguy Urvoy"
    ],
    "abstract": "The growing power of generative models raises major concerns about the\nauthenticity of published content. To address this problem, several synthetic\ncontent detection methods have been proposed for uniformly structured media\nsuch as image or text. However, little work has been done on the detection of\nsynthetic tabular data, despite its importance in industry and government. This\nform of data is complex to handle due to the diversity of its structures: the\nnumber and types of the columns may vary wildly from one table to another. We\ntackle the tough problem of detecting synthetic tabular data ''in the wild'',\ni.e. when the model is deployed on table structures it has never seen before.\nWe introduce a novel datum-wise transformer architecture and show that it\noutperforms existing models. Furthermore, we investigate the application of\ndomain adaptation techniques to enhance the effectiveness of our model, thereby\nproviding a more robust data-forgery detection solution.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08829v1",
    "published_date": "2025-04-10 08:01:34 UTC",
    "updated_date": "2025-04-10 08:01:34 UTC"
  },
  {
    "arxiv_id": "2504.08827v1",
    "title": "PatchTrAD: A Patch-Based Transformer focusing on Patch-Wise Reconstruction Error for Time Series Anomaly Detection",
    "authors": [
      "Samy-Melwan Vilhes",
      "Gilles Gasso",
      "Mokhtar Z Alaya"
    ],
    "abstract": "Time series anomaly detection (TSAD) focuses on identifying whether\nobservations in streaming data deviate significantly from normal patterns. With\nthe prevalence of connected devices, anomaly detection on time series has\nbecome paramount, as it enables real-time monitoring and early detection of\nirregular behaviors across various application domains. In this work, we\nintroduce PatchTrAD, a Patch-based Transformer model for time series anomaly\ndetection. Our approach leverages a Transformer encoder along with the use of\npatches under a reconstructionbased framework for anomaly detection. Empirical\nevaluations on multiple benchmark datasets show that PatchTrAD is on par, in\nterms of detection performance, with state-of-the-art deep learning models for\nanomaly detection while being time efficient during inference.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08827v1",
    "published_date": "2025-04-10 07:58:55 UTC",
    "updated_date": "2025-04-10 07:58:55 UTC"
  },
  {
    "arxiv_id": "2504.07532v2",
    "title": "AI-Slop to AI-Polish? Aligning Language Models through Edit-Based Writing Rewards and Test-time Computation",
    "authors": [
      "Tuhin Chakrabarty",
      "Philippe Laban",
      "Chien-Sheng Wu"
    ],
    "abstract": "AI-generated text is proliferating across domains, from creative writing and\njournalism to marketing content and scientific articles. Models can follow\nuser-provided instructions to generate coherent and grammatically correct\noutputs but in this work, we study a more fundamental question: how do we\nevaluate and improve the writing quality of AI-generated text? Writing quality\nassessment has received less attention from the community, in part because it\nis fundamentally subjective and requires expertise. We first introduce the\nWriting Quality Benchmark (WQ) by consolidating five writing-preference\ndatasets into 4,729 writing quality judgments. Our experiments show that most\nof the competitive baselines, including state-of-the-art LLMs that excel at\nreasoning tasks, barely outperform random baselines on WQ. We then train\nspecialized Writing Quality Reward Models (WQRM) of various sizes for writing\nquality assessment that demonstrate strong generalization on four\nout-of-distribution test sets and 74% accuracy on the WQ benchmark. To further\nshow WQRM's practical benefits during inference, we leverage additional\ntest-time compute to generate and rank multiple candidate revisions, allowing\nus to select higher-quality outputs from an initial draft. Human evaluation\nwith 9 experienced writers confirm that WQRM-based selection produces writing\nsamples preferred by experts 66% overall, and 72.2% when the reward gap is\nlarger than 1 point. We release our datasets and models to encourage community\nengagement with writing quality assessment and development of AI writing\nsystems better aligned with human preferences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under Submission",
    "pdf_url": "http://arxiv.org/pdf/2504.07532v2",
    "published_date": "2025-04-10 07:58:05 UTC",
    "updated_date": "2025-04-20 02:42:05 UTC"
  },
  {
    "arxiv_id": "2504.07531v1",
    "title": "A taxonomy of epistemic injustice in the context of AI and the case for generative hermeneutical erasure",
    "authors": [
      "Warmhold Jan Thomas Mollema"
    ],
    "abstract": "Whether related to machine learning models' epistemic opacity, algorithmic\nclassification systems' discriminatory automation of testimonial prejudice, the\ndistortion of human beliefs via the 'hallucinations' of generative AI, the\ninclusion of the global South in global AI governance, the execution of\nbureaucratic violence via algorithmic systems, or located in the interaction\nwith conversational artificial agents epistemic injustice related to AI is a\ngrowing concern. Based on a proposed general taxonomy of epistemic injustice,\nthis paper first sketches a taxonomy of the types of epistemic injustice in the\ncontext of AI, relying on the work of scholars from the fields of philosophy of\ntechnology, political philosophy and social epistemology. Secondly, an\nadditional perspective on epistemic injustice in the context of AI: generative\nhermeneutical erasure. I argue that this injustice that can come about through\nthe application of Large Language Models (LLMs) and contend that generative AI,\nwhen being deployed outside of its Western space of conception, can have\neffects of conceptual erasure, particularly in the epistemic domain, followed\nby forms of conceptual disruption caused by a mismatch between AI system and\nthe interlocutor in terms of conceptual frameworks. AI systems' 'view from\nnowhere' epistemically inferiorizes non-Western epistemologies and thereby\ncontributes to the erosion of their epistemic particulars, gradually\ncontributing to hermeneutical erasure. This work's relevance lies in proposal\nof a taxonomy that allows epistemic injustices to be mapped in the AI domain\nand the proposal of a novel form of AI-related epistemic injustice.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "K.4"
    ],
    "primary_category": "cs.AI",
    "comment": "29 pages; 3 figures; 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.07531v1",
    "published_date": "2025-04-10 07:54:47 UTC",
    "updated_date": "2025-04-10 07:54:47 UTC"
  },
  {
    "arxiv_id": "2504.07522v1",
    "title": "Adversarial Subspace Generation for Outlier Detection in High-Dimensional Data",
    "authors": [
      "Jose Cribeiro-Ramallo",
      "Federico Matteucci",
      "Paul Enciu",
      "Alexander Jenke",
      "Vadim Arzamasov",
      "Thorsten Strufe",
      "Klemens Böhm"
    ],
    "abstract": "Outlier detection in high-dimensional tabular data is challenging since data\nis often distributed across multiple lower-dimensional subspaces -- a\nphenomenon known as the Multiple Views effect (MV). This effect led to a large\nbody of research focused on mining such subspaces, known as subspace selection.\nHowever, as the precise nature of the MV effect was not well understood,\ntraditional methods had to rely on heuristic-driven search schemes that\nstruggle to accurately capture the true structure of the data. Properly\nidentifying these subspaces is critical for unsupervised tasks such as outlier\ndetection or clustering, where misrepresenting the underlying data structure\ncan hinder the performance. We introduce Myopic Subspace Theory (MST), a new\ntheoretical framework that mathematically formulates the Multiple Views effect\nand writes subspace selection as a stochastic optimization problem. Based on\nMST, we introduce V-GAN, a generative method trained to solve such an\noptimization problem. This approach avoids any exhaustive search over the\nfeature space while ensuring that the intrinsic data structure is preserved.\nExperiments on 42 real-world datasets show that using V-GAN subspaces to build\nensemble methods leads to a significant increase in one-class classification\nperformance -- compared to existing subspace selection, feature selection, and\nembedding methods. Further experiments on synthetic data show that V-GAN\nidentifies subspaces more accurately while scaling better than other relevant\nsubspace selection methods. These results confirm the theoretical guarantees of\nour approach and also highlight its practical viability in high-dimensional\nsettings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.TH",
      "68T07"
    ],
    "primary_category": "cs.LG",
    "comment": "35 pages, pre-print",
    "pdf_url": "http://arxiv.org/pdf/2504.07522v1",
    "published_date": "2025-04-10 07:40:02 UTC",
    "updated_date": "2025-04-10 07:40:02 UTC"
  },
  {
    "arxiv_id": "2504.07521v2",
    "title": "Why We Feel: Breaking Boundaries in Emotional Reasoning with Multimodal Large Language Models",
    "authors": [
      "Yuxiang Lin",
      "Jingdong Sun",
      "Zhi-Qi Cheng",
      "Jue Wang",
      "Haomin Liang",
      "Zebang Cheng",
      "Yifei Dong",
      "Jun-Yan He",
      "Xiaojiang Peng",
      "Xian-Sheng Hua"
    ],
    "abstract": "Most existing emotion analysis emphasizes which emotion arises (e.g., happy,\nsad, angry) but neglects the deeper why. We propose Emotion Interpretation\n(EI), focusing on causal factors-whether explicit (e.g., observable objects,\ninterpersonal interactions) or implicit (e.g., cultural context, off-screen\nevents)-that drive emotional responses. Unlike traditional emotion recognition,\nEI tasks require reasoning about triggers instead of mere labeling. To\nfacilitate EI research, we present EIBench, a large-scale benchmark\nencompassing 1,615 basic EI samples and 50 complex EI samples featuring\nmultifaceted emotions. Each instance demands rationale-based explanations\nrather than straightforward categorization. We further propose a Coarse-to-Fine\nSelf-Ask (CFSA) annotation pipeline, which guides Vision-Language Models\n(VLLMs) through iterative question-answer rounds to yield high-quality labels\nat scale. Extensive evaluations on open-source and proprietary large language\nmodels under four experimental settings reveal consistent performance\ngaps-especially for more intricate scenarios-underscoring EI's potential to\nenrich empathetic, context-aware AI applications. Our benchmark and methods are\npublicly available at: https://github.com/Lum1104/EIBench, offering a\nfoundation for advanced multimodal causal analysis and next-generation\naffective computing.",
    "categories": [
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at CVPR Workshop NEXD 2025. 21 pages, Project:\n  https://github.com/Lum1104/EIBench",
    "pdf_url": "http://arxiv.org/pdf/2504.07521v2",
    "published_date": "2025-04-10 07:33:49 UTC",
    "updated_date": "2025-04-17 09:34:26 UTC"
  },
  {
    "arxiv_id": "2504.07516v1",
    "title": "Enhancements for Developing a Comprehensive AI Fairness Assessment Standard",
    "authors": [
      "Avinash Agarwal",
      "Mayashankar Kumar",
      "Manisha J. Nene"
    ],
    "abstract": "As AI systems increasingly influence critical sectors like\ntelecommunications, finance, healthcare, and public services, ensuring fairness\nin decision-making is essential to prevent biased or unjust outcomes that\ndisproportionately affect vulnerable entities or result in adverse impacts.\nThis need is particularly pressing as the industry approaches the 6G era, where\nAI will drive complex functions like autonomous network management and\nhyper-personalized services. The TEC Standard for Fairness Assessment and\nRating of AI Systems provides guidelines for evaluating fairness in AI,\nfocusing primarily on tabular data and supervised learning models. However, as\nAI applications diversify, this standard requires enhancement to strengthen its\nimpact and broaden its applicability. This paper proposes an expansion of the\nTEC Standard to include fairness assessments for images, unstructured text, and\ngenerative AI, including large language models, ensuring a more comprehensive\napproach that keeps pace with evolving AI technologies. By incorporating these\ndimensions, the enhanced framework will promote responsible and trustworthy AI\ndeployment across various sectors.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "5 pages. Published in 2025 17th International Conference on\n  COMmunication Systems and NETworks (COMSNETS). Access:\n  https://ieeexplore.ieee.org/abstract/document/10885551",
    "pdf_url": "http://arxiv.org/pdf/2504.07516v1",
    "published_date": "2025-04-10 07:24:23 UTC",
    "updated_date": "2025-04-10 07:24:23 UTC"
  },
  {
    "arxiv_id": "2504.12316v1",
    "title": "Data Metabolism: An Efficient Data Design Schema For Vision Language Model",
    "authors": [
      "Jingyuan Zhang",
      "Hongzhi Zhang",
      "Zhou Haonan",
      "Chenxi Sun",
      "Xingguang ji",
      "Jiakang Wang",
      "Fanheng Kong",
      "Yahui Liu",
      "Qi Wang",
      "Fuzheng Zhang"
    ],
    "abstract": "Data curation plays a crucial role in training powerful Visual Language\nModels (VLMs). In this work, we introduce the concept of Data Metabolism and\npresent our data-centric framework to build VLMs throughout the development\nlifecycle. Starting from a standard model architecture, we discuss and provide\ninsights into two crucial development steps: data curation and iteration,\nforming a closed-loop system that continuously improves model performance. We\nshow a detailed codebook on how to process existing massive datasets and build\nuser-specific data flywheel. As a demonstration, we release a VLM, named\nCapybara-VL, which excels in typical multimodal tasks (e.g. , visual question\nanswering, scientific reasoning, and text-rich tasks). Despite its relatively\ncompact size, Capybara-VL surpasses several open-source models that are up to\n10 times larger in size. Moreover, it achieves results that are on par with\nthose of several leading proprietary models, demonstrating its remarkable\ncompetitiveness. These results highlight the power of our data-centric\nframework and the potential of training smaller and more efficient VLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "To be presented at ICLR 2025, First Workshop on Open Science for\n  Foundation Models",
    "pdf_url": "http://arxiv.org/pdf/2504.12316v1",
    "published_date": "2025-04-10 07:20:54 UTC",
    "updated_date": "2025-04-10 07:20:54 UTC"
  },
  {
    "arxiv_id": "2504.07513v1",
    "title": "GPT Carry-On: Training Foundation Model for Customization Could Be Simple, Scalable and Affordable",
    "authors": [
      "Jianqiao Wangni"
    ],
    "abstract": "Modern large language foundation models (LLM) have now entered the daily\nlives of millions of users. We ask a natural question whether it is possible to\ncustomize LLM for every user or every task. From system and industrial economy\nconsideration, general continue-training or fine-tuning still require\nsubstantial computation and memory of training GPU nodes, whereas most\ninference nodes under deployment, possibly with lower-end GPUs, are configured\nto make forward pass fastest possible. We propose a framework to take full\nadvantages of existing LLMs and systems of online service. We train an\nadditional branch of transformer blocks on the final-layer embedding of\npretrained LLMs, which is the base, then a carry-on module merge the base\nmodels to compose a customized LLM. We can mix multiple layers, or multiple\nLLMs specialized in different domains such as chat, coding, math, to form a new\nmixture of LLM that best fit a new task. As the base model don't need to update\nparameters, we are able to outsource most computation of the training job on\ninference nodes, and only train a lightweight carry-on on training nodes, where\nwe consume less than 1GB GPU memory to train a 100M carry-on layer on 30B LLM.\nWe tested Qwen and DeepSeek opensourced models for continue-pretraining and got\nfaster loss convergence. We use it to improve solving math questions with\nextremely small computation and model size, with 1000 data samples of\nchain-of-thoughts, and as small as 1 MB parameters of two layer layer carry-on,\nand the results are promising.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07513v1",
    "published_date": "2025-04-10 07:15:40 UTC",
    "updated_date": "2025-04-10 07:15:40 UTC"
  },
  {
    "arxiv_id": "2504.12315v1",
    "title": "Capybara-OMNI: An Efficient Paradigm for Building Omni-Modal Language Models",
    "authors": [
      "Xingguang Ji",
      "Jiakang Wang",
      "Hongzhi Zhang",
      "Jingyuan Zhang",
      "Haonan Zhou",
      "Chenxi Sun",
      "Yahui Liu",
      "Qi Wang",
      "Fuzheng Zhang"
    ],
    "abstract": "With the development of Multimodal Large Language Models (MLLMs), numerous\noutstanding accomplishments have emerged within the open-source community. Due\nto the complexity of creating and training multimodal data pairs, it is still a\ncomputational and time-consuming process to build powerful MLLMs. In this work,\nwe introduce Capybara-OMNI, an MLLM that trains in a lightweight and efficient\nmanner and supports understanding text, image, video, and audio modalities. We\npresent in detail the framework design, the data construction, and the training\nrecipe, to develop an MLLM step-by-step to obtain competitive performance. We\nalso provide exclusive benchmarks utilized in our experiments to show how to\nproperly verify understanding capabilities across different modalities. Results\nshow that by following our guidance, we can efficiently build an MLLM that\nachieves competitive performance among models of the same scale on various\nmultimodal benchmarks. Additionally, to enhance the multimodal instruction\nfollowing and conversational capabilities of the model, we further discuss how\nto train the chat version upon an MLLM understanding model, which is more in\nline with user habits for tasks like real-time interaction with humans. We\npublicly disclose the Capybara-OMNI model, along with its chat-based version.\nThe disclosure includes both the model weights, a portion of the training data,\nand the inference codes, which are made available on GitHub.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.12315v1",
    "published_date": "2025-04-10 07:08:53 UTC",
    "updated_date": "2025-04-10 07:08:53 UTC"
  },
  {
    "arxiv_id": "2504.07495v1",
    "title": "Bottleneck Identification in Resource-Constrained Project Scheduling via Constraint Relaxation",
    "authors": [
      "Lukáš Nedbálek",
      "Antonín Novák"
    ],
    "abstract": "In realistic production scenarios, Advanced Planning and Scheduling (APS)\ntools often require manual intervention by production planners, as the system\nworks with incomplete information, resulting in suboptimal schedules. Often,\nthe preferable solution is not found just because of the too-restrictive\nconstraints specifying the optimization problem, representing bottlenecks in\nthe schedule. To provide computer-assisted support for decision-making, we aim\nto automatically identify bottlenecks in the given schedule while linking them\nto the particular constraints to be relaxed. In this work, we address the\nproblem of reducing the tardiness of a particular project in an obtained\nschedule in the resource-constrained project scheduling problem by relaxing\nconstraints related to identified bottlenecks. We develop two methods for this\npurpose. The first method adapts existing approaches from the job shop\nliterature and utilizes them for so-called untargeted relaxations. The second\nmethod identifies potential improvements in relaxed versions of the problem and\nproposes targeted relaxations. Surprisingly, the untargeted relaxations result\nin improvements comparable to the targeted relaxations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 4 figures, submitted to the ICORES 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2504.07495v1",
    "published_date": "2025-04-10 06:53:10 UTC",
    "updated_date": "2025-04-10 06:53:10 UTC"
  },
  {
    "arxiv_id": "2504.07476v1",
    "title": "CMEdataset Advancing China Map Detection and Standardization with Digital Image Resources",
    "authors": [
      "Yan Xu",
      "Zhenqiang Zhang",
      "Zhiwei Zhou",
      "Liting Geng",
      "Yue Li",
      "Jintao Li"
    ],
    "abstract": "Digital images of Chinas maps play a crucial role in map detection,\nparticularly in ensuring national sovereignty, territorial integrity, and map\ncompliance. However, there is currently no publicly available dataset\nspecifically dedicated to problematic maps the CME dataset. Existing datasets\nprimarily focus on general map data and are insufficient for effectively\nidentifying complex issues such as national boundary misrepresentations,\nmissing elements, and blurred boundaries. Therefore, this study creates a\nProblematic Map dataset that covers five key problem areas, aiming to provide\ndiverse samples for problematic map detection technologies, support\nhigh-precision map compliance detection, and enhance map data quality and\ntimeliness. This dataset not only provides essential resources for map\ncompliance, national security monitoring, and map updates, but also fosters\ninnovation and application of related technologies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07476v1",
    "published_date": "2025-04-10 06:04:16 UTC",
    "updated_date": "2025-04-10 06:04:16 UTC"
  },
  {
    "arxiv_id": "2504.07463v1",
    "title": "Enhanced Question-Answering for Skill-based learning using Knowledge-based AI and Generative AI",
    "authors": [
      "Rahul K. Dass",
      "Rochan H. Madhusudhana",
      "Erin C. Deye",
      "Shashank Verma",
      "Timothy A. Bydlon",
      "Grace Brazil",
      "Ashok K. Goel"
    ],
    "abstract": "Supporting learners' understanding of taught skills in online settings is a\nlongstanding challenge. While exercises and chat-based agents can evaluate\nunderstanding in limited contexts, this challenge is magnified when learners\nseek explanations that delve into procedural knowledge (how things are done)\nand reasoning (why things happen). We hypothesize that an intelligent agent's\nability to understand and explain learners' questions about skills can be\nsignificantly enhanced using the TMK (Task-Method-Knowledge) model, a\nKnowledge-based AI framework. We introduce Ivy, an intelligent agent that\nleverages an LLM and iterative refinement techniques to generate explanations\nthat embody teleological, causal, and compositional principles. Our initial\nevaluation demonstrates that this approach goes beyond the typical shallow\nresponses produced by an agent with access to unstructured text, thereby\nsubstantially improving the depth and relevance of feedback. This can\npotentially ensure learners develop a comprehensive understanding of skills\ncrucial for effective problem-solving in online environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07463v1",
    "published_date": "2025-04-10 05:25:52 UTC",
    "updated_date": "2025-04-10 05:25:52 UTC"
  },
  {
    "arxiv_id": "2504.07450v1",
    "title": "Synthetic CT Generation from Time-of-Flight Non-Attenutaion-Corrected PET for Whole-Body PET Attenuation Correction",
    "authors": [
      "Weijie Chen",
      "James Wang",
      "Alan McMillan"
    ],
    "abstract": "Positron Emission Tomography (PET) imaging requires accurate attenuation\ncorrection (AC) to account for photon loss due to tissue density variations. In\nPET/MR systems, computed tomography (CT), which offers a straightforward\nestimation of AC is not available. This study presents a deep learning approach\nto generate synthetic CT (sCT) images directly from Time-of-Flight (TOF)\nnon-attenuation corrected (NAC) PET images, enhancing AC for PET/MR. We first\nevaluated models pre-trained on large-scale natural image datasets for a\nCT-to-CT reconstruction task, finding that the pre-trained model outperformed\nthose trained solely on medical datasets. The pre-trained model was then\nfine-tuned using an institutional dataset of 35 TOF NAC PET and CT volume\npairs, achieving the lowest mean absolute error (MAE) of 74.49 HU and highest\npeak signal-to-noise ratio (PSNR) of 28.66 dB within the body contour region.\nVisual assessments demonstrated improved reconstruction of both bone and soft\ntissue structures from TOF NAC PET images. This work highlights the\neffectiveness of using pre-trained deep learning models for medical image\ntranslation tasks. Future work will assess the impact of sCT on PET attenuation\ncorrection and explore additional neural network architectures and datasets to\nfurther enhance performance and practical applications in PET imaging.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "68T05, 92C55",
      "I.2.6; I.2.10"
    ],
    "primary_category": "eess.IV",
    "comment": "4 pages, 2 figures, ISBI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.07450v1",
    "published_date": "2025-04-10 04:49:41 UTC",
    "updated_date": "2025-04-10 04:49:41 UTC"
  },
  {
    "arxiv_id": "2504.07448v1",
    "title": "LoRI: Reducing Cross-Task Interference in Multi-Task Low-Rank Adaptation",
    "authors": [
      "Juzheng Zhang",
      "Jiacheng You",
      "Ashwinee Panda",
      "Tom Goldstein"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) has emerged as a popular parameter-efficient\nfine-tuning (PEFT) method for Large Language Models (LLMs), yet it still incurs\nnotable overhead and suffers from parameter interference in multi-task\nscenarios. We propose LoRA with Reduced Interference (LoRI), a simple yet\neffective approach that freezes the projection matrices $A$ as random\nprojections and sparsifies the matrices $B$ using task-specific masks. This\ndesign substantially reduces the number of trainable parameters while\nmaintaining strong task performance. Moreover, LoRI minimizes cross-task\ninterference in adapter merging by leveraging the orthogonality between adapter\nsubspaces, and supports continual learning by using sparsity to mitigate\ncatastrophic forgetting. Extensive experiments across natural language\nunderstanding, mathematical reasoning, code generation, and safety alignment\ntasks demonstrate that LoRI outperforms full fine-tuning and existing PEFT\nmethods, while using up to 95% fewer trainable parameters than LoRA. In\nmulti-task experiments, LoRI enables effective adapter merging and continual\nlearning with reduced cross-task interference. Code is available at:\nhttps://github.com/juzhengz/LoRI",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 7 figures, 20 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.07448v1",
    "published_date": "2025-04-10 04:46:04 UTC",
    "updated_date": "2025-04-10 04:46:04 UTC"
  },
  {
    "arxiv_id": "2504.12314v1",
    "title": "How to Detect and Defeat Molecular Mirage: A Metric-Driven Benchmark for Hallucination in LLM-based Molecular Comprehension",
    "authors": [
      "Hao Li",
      "Liuzhenghao Lv",
      "He Cao",
      "Zijing Liu",
      "Zhiyuan Yan",
      "Yu Wang",
      "Yonghong Tian",
      "Yu Li",
      "Li Yuan"
    ],
    "abstract": "Large language models are increasingly used in scientific domains, especially\nfor molecular understanding and analysis. However, existing models are affected\nby hallucination issues, resulting in errors in drug design and utilization. In\nthis paper, we first analyze the sources of hallucination in LLMs for molecular\ncomprehension tasks, specifically the knowledge shortcut phenomenon observed in\nthe PubChem dataset. To evaluate hallucination in molecular comprehension tasks\nwith computational efficiency, we introduce \\textbf{Mol-Hallu}, a novel\nfree-form evaluation metric that quantifies the degree of hallucination based\non the scientific entailment relationship between generated text and actual\nmolecular properties. Utilizing the Mol-Hallu metric, we reassess and analyze\nthe extent of hallucination in various LLMs performing molecular comprehension\ntasks. Furthermore, the Hallucination Reduction Post-processing stage~(HRPP) is\nproposed to alleviate molecular hallucinations, Experiments show the\neffectiveness of HRPP on decoder-only and encoder-decoder molecular LLMs. Our\nfindings provide critical insights into mitigating hallucination and improving\nthe reliability of LLMs in scientific applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.12314v1",
    "published_date": "2025-04-10 04:19:02 UTC",
    "updated_date": "2025-04-10 04:19:02 UTC"
  },
  {
    "arxiv_id": "2504.07425v1",
    "title": "Enhancing Player Enjoyment with a Two-Tier DRL and LLM-Based Agent System for Fighting Games",
    "authors": [
      "Shouren Wang",
      "Zehua Jiang",
      "Fernando Sliva",
      "Sam Earle",
      "Julian Togelius"
    ],
    "abstract": "Deep reinforcement learning (DRL) has effectively enhanced gameplay\nexperiences and game design across various game genres. However, few studies on\nfighting game agents have focused explicitly on enhancing player enjoyment, a\ncritical factor for both developers and players. To address this gap and\nestablish a practical baseline for designing enjoyability-focused agents, we\npropose a two-tier agent (TTA) system and conducted experiments in the classic\nfighting game Street Fighter II. The first tier of TTA employs a task-oriented\nnetwork architecture, modularized reward functions, and hybrid training to\nproduce diverse and skilled DRL agents. In the second tier of TTA, a Large\nLanguage Model Hyper-Agent, leveraging players' playing data and feedback,\ndynamically selects suitable DRL opponents. In addition, we investigate and\nmodel several key factors that affect the enjoyability of the opponent. The\nexperiments demonstrate improvements from 64. 36% to 156. 36% in the execution\nof advanced skills over baseline methods. The trained agents also exhibit\ndistinct game-playing styles. Additionally, we conducted a small-scale user\nstudy, and the overall enjoyment in the player's feedback validates the\neffectiveness of our TTA system.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 8 figures. Submitted to a peer-reviewed conference, under\n  review",
    "pdf_url": "http://arxiv.org/pdf/2504.07425v1",
    "published_date": "2025-04-10 03:38:06 UTC",
    "updated_date": "2025-04-10 03:38:06 UTC"
  },
  {
    "arxiv_id": "2504.07424v1",
    "title": "Routing to the Right Expertise: A Trustworthy Judge for Instruction-based Image Editing",
    "authors": [
      "Chenxi Sun",
      "Hongzhi Zhang",
      "Qi Wang",
      "Fuzheng Zhang"
    ],
    "abstract": "Instruction-based Image Editing (IIE) models have made significantly\nimprovement due to the progress of multimodal large language models (MLLMs) and\ndiffusion models, which can understand and reason about complex editing\ninstructions. In addition to advancing current IIE models, accurately\nevaluating their output has become increasingly critical and challenging.\nCurrent IIE evaluation methods and their evaluation procedures often fall short\nof aligning with human judgment and often lack explainability. To address these\nlimitations, we propose JUdgement through Routing of Expertise (JURE). Each\nexpert in JURE is a pre-selected model assumed to be equipped with an atomic\nexpertise that can provide useful feedback to judge output, and the router\ndynamically routes the evaluation task of a given instruction and its output to\nappropriate experts, aggregating their feedback into a final judge. JURE is\ntrustworthy in two aspects. First, it can effortlessly provide explanations\nabout its judge by examining the routed experts and their feedback. Second,\nexperimental results demonstrate that JURE is reliable by achieving superior\nalignment with human judgments, setting a new standard for automated IIE\nevaluation. Moreover, JURE's flexible design is future-proof - modular experts\ncan be seamlessly replaced or expanded to accommodate advancements in IIE,\nmaintaining consistently high evaluation quality. Our evaluation data and\nresults are available at https://github.com/Cyyyyyrus/JURE.git.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07424v1",
    "published_date": "2025-04-10 03:30:15 UTC",
    "updated_date": "2025-04-10 03:30:15 UTC"
  },
  {
    "arxiv_id": "2504.07423v1",
    "title": "Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based Clinical Decision Support",
    "authors": [
      "Venkatesh Sivaraman",
      "Katelyn Morrison",
      "Will Epperson",
      "Adam Perer"
    ],
    "abstract": "As AI-based clinical decision support (AI-CDS) is introduced in more and more\naspects of healthcare services, HCI research plays an increasingly important\nrole in designing for complementarity between AI and clinicians. However,\ncurrent evaluations of AI-CDS often fail to capture when AI is and is not\nuseful to clinicians. This position paper reflects on our work and influential\nAI-CDS literature to advocate for moving beyond evaluation metrics like Trust,\nReliance, Acceptance, and Performance on the AI's task (what we term the \"trap\"\nof human-AI collaboration). Although these metrics can be meaningful in some\nsimple scenarios, we argue that optimizing for them ignores important ways that\nAI falls short of clinical benefit, as well as ways that clinicians\nsuccessfully use AI. As the fields of HCI and AI in healthcare develop new ways\nto design and evaluate CDS tools, we call on the community to prioritize\necologically valid, domain-appropriate study setups that measure the emergent\nforms of value that AI can bring to healthcare professionals.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "q-bio.OT"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to the CHI '25 Workshop on Envisioning the Future of\n  Interactive Health",
    "pdf_url": "http://arxiv.org/pdf/2504.07423v1",
    "published_date": "2025-04-10 03:28:56 UTC",
    "updated_date": "2025-04-10 03:28:56 UTC"
  },
  {
    "arxiv_id": "2504.07422v1",
    "title": "The Role of Machine Learning in Reducing Healthcare Costs: The Impact of Medication Adherence and Preventive Care on Hospitalization Expenses",
    "authors": [
      "Yixin Zhang",
      "Yisong Chen"
    ],
    "abstract": "This study reveals the important role of prevention care and medication\nadherence in reducing hospitalizations. By using a structured dataset of 1,171\npatients, four machine learning models Logistic Regression, Gradient Boosting,\nRandom Forest, and Artificial Neural Networks are applied to predict five-year\nhospitalization risk, with the Gradient Boosting model achieving the highest\naccuracy of 81.2%. The result demonstrated that patients with high medication\nadherence and consistent preventive care can reduce 38.3% and 37.7% in\nhospitalization risk. The finding also suggests that targeted preventive care\ncan have positive Return on Investment (ROI), and therefore ML models can\neffectively direct personalized interventions and contribute to long-term\nmedical savings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "68T05, 68T09, 68U03, 62P10",
      "I.2; J.3; H.2; J.4; K.4"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07422v1",
    "published_date": "2025-04-10 03:28:42 UTC",
    "updated_date": "2025-04-10 03:28:42 UTC"
  },
  {
    "arxiv_id": "2504.07402v1",
    "title": "LauraTSE: Target Speaker Extraction using Auto-Regressive Decoder-Only Language Models",
    "authors": [
      "Beilong Tang",
      "Bang Zeng",
      "Ming Li"
    ],
    "abstract": "We propose LauraTSE, an Auto-Regressive Decoder-Only Language Model for\nTarget Speaker Extraction (TSE) based on the LauraGPT backbone. It employs a\nsmall-scale auto-regressive decoder-only language model which takes the\ncontinuous representations for both the mixture and the reference speeches and\nproduces the first few layers of the target speech's discrete codec\nrepresentations. In addition, a one-step encoder-only language model\nreconstructs the sum of the predicted codec embeddings using both the mixture\nand the reference information. Our approach achieves superior or comparable\nperformance to existing generative and discriminative TSE models. To the best\nof our knowledge, LauraTSE is the first single-task TSE model to leverage an\nauto-regressive decoder-only language model as the backbone.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.07402v1",
    "published_date": "2025-04-10 02:55:22 UTC",
    "updated_date": "2025-04-10 02:55:22 UTC"
  },
  {
    "arxiv_id": "2504.18544v1",
    "title": "Critical Challenges and Guidelines in Evaluating Synthetic Tabular Data: A Systematic Review",
    "authors": [
      "Nazia Nafis",
      "Inaki Esnaola",
      "Alvaro Martinez-Perez",
      "Maria-Cruz Villa-Uriol",
      "Venet Osmani"
    ],
    "abstract": "Generating synthetic tabular data can be challenging, however evaluation of\ntheir quality is just as challenging, if not more. This systematic review sheds\nlight on the critical importance of rigorous evaluation of synthetic health\ndata to ensure reliability, relevance, and their appropriate use. Based on\nscreening of 1766 papers and a detailed review of 101 papers we identified key\nchallenges, including lack of consensus on evaluation methods, improper use of\nevaluation metrics, limited input from domain experts, inadequate reporting of\ndataset characteristics, and limited reproducibility of results. In response,\nwe provide several guidelines on the generation and evaluation of synthetic\ndata, to allow the community to unlock and fully harness the transformative\npotential of synthetic data and accelerate innovation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18544v1",
    "published_date": "2025-04-10 02:48:20 UTC",
    "updated_date": "2025-04-10 02:48:20 UTC"
  },
  {
    "arxiv_id": "2504.07398v1",
    "title": "A Novel Mamba-based Sequential Recommendation Method",
    "authors": [
      "Jun Yuan"
    ],
    "abstract": "Sequential recommendation (SR), which encodes user activity to predict the\nnext action, has emerged as a widely adopted strategy in developing commercial\npersonalized recommendation systems. Although Transformer-based models have\nproven effective for sequential recommendation, the complexity of the\nself-attention module in Transformers scales quadratically with the sequence\nlength. Controlling model complexity is essential for large-scale\nrecommendation systems, as these systems may need to handle billion-scale\nvocabularies that evolve continuously, as well as user behavior sequences that\ncan exceed tens of thousands in length. In this paper, we propose a novel\nmulti-head latent Mamba architecture, which employs multiple low-dimensional\nMamba layers and fully connected layers coupled with positional encoding to\nsimultaneously capture historical and item information within each latent\nsubspace. Our proposed method not only enables scaling up to large-scale\nparameters but also extends to multi-domain recommendation by integrating and\nfine-tuning LLMs. Through extensive experiments on public datasets, we\ndemonstrate how Hydra effectively addresses the effectiveness-efficiency\ndilemma, outperforming state-of-the-art sequential recommendation baselines\nwith significantly fewer parameters and reduced training time.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07398v1",
    "published_date": "2025-04-10 02:43:19 UTC",
    "updated_date": "2025-04-10 02:43:19 UTC"
  },
  {
    "arxiv_id": "2504.07397v1",
    "title": "MicroNAS: An Automated Framework for Developing a Fall Detection System",
    "authors": [
      "Seyed Mojtaba Mohasel",
      "John Sheppard",
      "Lindsey K. Molina",
      "Richard R. Neptune",
      "Shane R. Wurdeman",
      "Corey A. Pew"
    ],
    "abstract": "This work presents MicroNAS, an automated neural architecture search tool\nspecifically designed to create models optimized for microcontrollers with\nsmall memory resources. The ESP32 microcontroller, with 320 KB of memory, is\nused as the target platform. The artificial intelligence contribution lies in a\nnovel method for optimizing convolutional neural network and gated recurrent\nunit architectures by considering the memory size of the target microcontroller\nas a guide. A comparison is made between memory-driven model optimization and\ntraditional two-stage methods, which use pruning, to show the effectiveness of\nthe proposed framework. To demonstrate the engineering application of MicroNAS,\na fall detection system (FDS) for lower-limb amputees is developed as a pilot\nstudy. A critical challenge in fall detection studies, class imbalance in the\ndataset, is addressed. The results show that MicroNAS models achieved higher\nF1-scores than alternative approaches, such as ensemble methods and H2O\nAutomated Machine Learning, presenting a significant step forward in real-time\nFDS development. Biomechanists using body-worn sensors for activity detection\ncan adopt the open-source code to design machine learning models tailored for\nmicrocontroller platforms with limited memory.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07397v1",
    "published_date": "2025-04-10 02:32:47 UTC",
    "updated_date": "2025-04-10 02:32:47 UTC"
  },
  {
    "arxiv_id": "2504.07396v1",
    "title": "Automating quantum feature map design via large language models",
    "authors": [
      "Kenya Sakka",
      "Kosuke Mitarai",
      "Keisuke Fujii"
    ],
    "abstract": "Quantum feature maps are a key component of quantum machine learning,\nencoding classical data into quantum states to exploit the expressive power of\nhigh-dimensional Hilbert spaces. Despite their theoretical promise, designing\nquantum feature maps that offer practical advantages over classical methods\nremains an open challenge. In this work, we propose an agentic system that\nautonomously generates, evaluates, and refines quantum feature maps using large\nlanguage models. The system consists of five component: Generation, Storage,\nValidation, Evaluation, and Review. Using these components, it iteratively\nimproves quantum feature maps. Experiments on the MNIST dataset show that it\ncan successfully discover and refine feature maps without human intervention.\nThe best feature map generated outperforms existing quantum baselines and\nachieves competitive accuracy compared to classical kernels across MNIST,\nFashion-MNIST, and CIFAR-10. Our approach provides a framework for exploring\ndataset-adaptive quantum features and highlights the potential of LLM-driven\nautomation in quantum algorithm design.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "39 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.07396v1",
    "published_date": "2025-04-10 02:27:45 UTC",
    "updated_date": "2025-04-10 02:27:45 UTC"
  },
  {
    "arxiv_id": "2504.07395v1",
    "title": "FAIR-SIGHT: Fairness Assurance in Image Recognition via Simultaneous Conformal Thresholding and Dynamic Output Repair",
    "authors": [
      "Arya Fayyazi",
      "Mehdi Kamal",
      "Massoud Pedram"
    ],
    "abstract": "We introduce FAIR-SIGHT, an innovative post-hoc framework designed to ensure\nfairness in computer vision systems by combining conformal prediction with a\ndynamic output repair mechanism. Our approach calculates a fairness-aware\nnon-conformity score that simultaneously assesses prediction errors and\nfairness violations. Using conformal prediction, we establish an adaptive\nthreshold that provides rigorous finite-sample, distribution-free guarantees.\nWhen the non-conformity score for a new image exceeds the calibrated threshold,\nFAIR-SIGHT implements targeted corrective adjustments, such as logit shifts for\nclassification and confidence recalibration for detection, to reduce both group\nand individual fairness disparities, all without the need for retraining or\nhaving access to internal model parameters. Comprehensive theoretical analysis\nvalidates our method's error control and convergence properties. At the same\ntime, extensive empirical evaluations on benchmark datasets show that\nFAIR-SIGHT significantly reduces fairness disparities while preserving high\npredictive performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07395v1",
    "published_date": "2025-04-10 02:23:06 UTC",
    "updated_date": "2025-04-10 02:23:06 UTC"
  },
  {
    "arxiv_id": "2504.07394v1",
    "title": "ClimateBench-M: A Multi-Modal Climate Data Benchmark with a Simple Generative Method",
    "authors": [
      "Dongqi Fu",
      "Yada Zhu",
      "Zhining Liu",
      "Lecheng Zheng",
      "Xiao Lin",
      "Zihao Li",
      "Liri Fang",
      "Katherine Tieu",
      "Onkar Bhardwaj",
      "Kommy Weldemariam",
      "Hanghang Tong",
      "Hendrik Hamann",
      "Jingrui He"
    ],
    "abstract": "Climate science studies the structure and dynamics of Earth's climate system\nand seeks to understand how climate changes over time, where the data is\nusually stored in the format of time series, recording the climate features,\ngeolocation, time attributes, etc. Recently, much research attention has been\npaid to the climate benchmarks. In addition to the most common task of weather\nforecasting, several pioneering benchmark works are proposed for extending the\nmodality, such as domain-specific applications like tropical cyclone intensity\nprediction and flash flood damage estimation, or climate statement and\nconfidence level in the format of natural language. To further motivate the\nartificial general intelligence development for climate science, in this paper,\nwe first contribute a multi-modal climate benchmark, i.e., ClimateBench-M,\nwhich aligns (1) the time series climate data from ERA5, (2) extreme weather\nevents data from NOAA, and (3) satellite image data from NASA HLS based on a\nunified spatial-temporal granularity. Second, under each data modality, we also\npropose a simple but strong generative method that could produce competitive\nperformance in weather forecasting, thunderstorm alerts, and crop segmentation\ntasks in the proposed ClimateBench-M. The data and code of ClimateBench-M are\npublicly available at https://github.com/iDEA-iSAIL-Lab-UIUC/ClimateBench-M.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint, 29 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.07394v1",
    "published_date": "2025-04-10 02:22:23 UTC",
    "updated_date": "2025-04-10 02:22:23 UTC"
  },
  {
    "arxiv_id": "2504.07389v1",
    "title": "Task-Circuit Quantization: Leveraging Knowledge Localization and Interpretability for Compression",
    "authors": [
      "Hanqi Xiao",
      "Yi-Lin Sung",
      "Elias Stengel-Eskin",
      "Mohit Bansal"
    ],
    "abstract": "Post-training quantization (PTQ) reduces a model's memory footprint by\nmapping full precision weights into low bit weights without costly retraining,\nbut can degrade its downstream performance especially in low 2- to 3-bit\nsettings. We develop a new mixed-precision PTQ approach, Task-Circuit\nQuantization (TaCQ), that draws parallels to automated circuit discovery,\ndirectly conditioning the quantization process on specific weight circuits --\nwhich we define as sets of weights associated with downstream task performance.\nThese weights are kept as 16-bit weights, while others are quantized,\nmaintaining performance while only adding a marginal memory cost. Specifically,\nTaCQ contrasts unquantized model weights with a uniformly-quantized model to\nestimate the expected change in weights due to quantization and uses gradient\ninformation to predict the resulting impact on task performance, allowing us to\npreserve task-specific weights. We compare TaCQ-based quantization to existing\nmixed-precision quantization methods when conditioning both on general-purpose\nand task-specific data. Across QA, math reasoning, and text-to-SQL tasks for\nboth Llama-3 and Qwen2.5, we find that TaCQ outperforms baselines using the\nsame calibration data and a lower weight budget, achieving major improvements\nin the 2 and 3-bit regime. With only 3.1 bits we are able to recover 96% of\nLlama-3-8B-Instruct's unquantized 16-bit MMLU performance, obtaining a 5.25%\nabsolute improvement over SPQR. We also observe consistently large gains over\nexisting methods in the 2-bit regime, with an average gain of 14.74% over the\nstrongest baseline, SliM-LLM. Moreover, we observe a 7.20% gain without\nconditioning on specific tasks, showing TaCQ's ability to identify important\nweights is not limited to task-conditioned settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages. Code: https://github.com/The-Inscrutable-X/TACQ",
    "pdf_url": "http://arxiv.org/pdf/2504.07389v1",
    "published_date": "2025-04-10 02:19:03 UTC",
    "updated_date": "2025-04-10 02:19:03 UTC"
  },
  {
    "arxiv_id": "2504.07388v1",
    "title": "Min-Max Optimisation for Nonconvex-Nonconcave Functions Using a Random Zeroth-Order Extragradient Algorithm",
    "authors": [
      "Amir Ali Farzin",
      "Yuen Man Pun",
      "Philipp Braun",
      "Antoine Lesage-landry",
      "Youssef Diouane",
      "Iman Shames"
    ],
    "abstract": "This study explores the performance of the random Gaussian smoothing\nZeroth-Order ExtraGradient (ZO-EG) scheme considering min-max optimisation\nproblems with possibly NonConvex-NonConcave (NC-NC) objective functions. We\nconsider both unconstrained and constrained, differentiable and\nnon-differentiable settings. We discuss the min-max problem from the point of\nview of variational inequalities. For the unconstrained problem, we establish\nthe convergence of the ZO-EG algorithm to the neighbourhood of an\n$\\epsilon$-stationary point of the NC-NC objective function, whose radius can\nbe controlled under a variance reduction scheme, along with its complexity. For\nthe constrained problem, we introduce the new notion of proximal variational\ninequalities and give examples of functions satisfying this property. Moreover,\nwe prove analogous results to the unconstrained case for the constrained\nproblem. For the non-differentiable case, we prove the convergence of the ZO-EG\nalgorithm to a neighbourhood of an $\\epsilon$-stationary point of the smoothed\nversion of the objective function, where the radius of the neighbourhood can be\ncontrolled, which can be related to the ($\\delta,\\epsilon$)-Goldstein\nstationary point of the original objective function.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07388v1",
    "published_date": "2025-04-10 02:15:30 UTC",
    "updated_date": "2025-04-10 02:15:30 UTC"
  },
  {
    "arxiv_id": "2504.07385v1",
    "title": "TALE: A Tool-Augmented Framework for Reference-Free Evaluation of Large Language Models",
    "authors": [
      "Sher Badshah",
      "Ali Emami",
      "Hassan Sajjad"
    ],
    "abstract": "As Large Language Models (LLMs) become increasingly integrated into\nreal-world, autonomous applications, relying on static, pre-annotated\nreferences for evaluation poses significant challenges in cost, scalability,\nand completeness. We propose Tool-Augmented LLM Evaluation (TALE), a framework\nto assess LLM outputs without predetermined ground-truth answers. Unlike\nconventional metrics that compare to fixed references or depend solely on\nLLM-as-a-judge knowledge, TALE employs an agent with tool-access capabilities\nthat actively retrieves and synthesizes external evidence. It iteratively\ngenerates web queries, collects information, summarizes findings, and refines\nsubsequent searches through reflection. By shifting away from static\nreferences, TALE aligns with free-form question-answering tasks common in\nreal-world scenarios. Experimental results on multiple free-form QA benchmarks\nshow that TALE not only outperforms standard reference-based metrics for\nmeasuring response accuracy but also achieves substantial to near-perfect\nagreement with human evaluations. TALE enhances the reliability of LLM\nevaluations in real-world, dynamic scenarios without relying on static\nreferences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07385v1",
    "published_date": "2025-04-10 02:08:41 UTC",
    "updated_date": "2025-04-10 02:08:41 UTC"
  },
  {
    "arxiv_id": "2504.07383v1",
    "title": "PROPEL: Supervised and Reinforcement Learning for Large-Scale Supply Chain Planning",
    "authors": [
      "Vahid Eghbal Akhlaghi",
      "Reza Zandehshahvar",
      "Pascal Van Hentenryck"
    ],
    "abstract": "This paper considers how to fuse Machine Learning (ML) and optimization to\nsolve large-scale Supply Chain Planning (SCP) optimization problems. These\nproblems can be formulated as MIP models which feature both integer\n(non-binary) and continuous variables, as well as flow balance and capacity\nconstraints. This raises fundamental challenges for existing integrations of ML\nand optimization that have focused on binary MIPs and graph problems. To\naddress these, the paper proposes PROPEL, a new framework that combines\noptimization with both supervised and Deep Reinforcement Learning (DRL) to\nreduce the size of search space significantly. PROPEL uses supervised learning,\nnot to predict the values of all integer variables, but to identify the\nvariables that are fixed to zero in the optimal solution, leveraging the\nstructure of SCP applications. PROPEL includes a DRL component that selects\nwhich fixed-at-zero variables must be relaxed to improve solution quality when\nthe supervised learning step does not produce a solution with the desired\noptimality tolerance. PROPEL has been applied to industrial supply chain\nplanning optimizations with millions of variables. The computational results\nshow dramatic improvements in solution times and quality, including a 60%\nreduction in primal integral and an 88% primal gap reduction, and improvement\nfactors of up to 13.57 and 15.92, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07383v1",
    "published_date": "2025-04-10 02:04:29 UTC",
    "updated_date": "2025-04-10 02:04:29 UTC"
  },
  {
    "arxiv_id": "2504.07379v1",
    "title": "Representation Meets Optimization: Training PINNs and PIKANs for Gray-Box Discovery in Systems Pharmacology",
    "authors": [
      "Nazanin Ahmadi Daryakenari",
      "Khemraj Shukla",
      "George Em Karniadakis"
    ],
    "abstract": "Physics-Informed Kolmogorov-Arnold Networks (PIKANs) are gaining attention as\nan effective counterpart to the original multilayer perceptron-based\nPhysics-Informed Neural Networks (PINNs). Both representation models can\naddress inverse problems and facilitate gray-box system identification.\nHowever, a comprehensive understanding of their performance in terms of\naccuracy and speed remains underexplored. In particular, we introduce a\nmodified PIKAN architecture, tanh-cPIKAN, which is based on Chebyshev\npolynomials for parametrization of the univariate functions with an extra\nnonlinearity for enhanced performance. We then present a systematic\ninvestigation of how choices of the optimizer, representation, and training\nconfiguration influence the performance of PINNs and PIKANs in the context of\nsystems pharmacology modeling. We benchmark a wide range of first-order,\nsecond-order, and hybrid optimizers, including various learning rate\nschedulers. We use the new Optax library to identify the most effective\ncombinations for learning gray-boxes under ill-posed, non-unique, and\ndata-sparse conditions. We examine the influence of model architecture (MLP vs.\nKAN), numerical precision (single vs. double), the need for warm-up phases for\nsecond-order methods, and sensitivity to the initial learning rate. We also\nassess the optimizer scalability for larger models and analyze the trade-offs\nintroduced by JAX in terms of computational efficiency and numerical accuracy.\nUsing two representative systems pharmacology case studies - a pharmacokinetics\nmodel and a chemotherapy drug-response model - we offer practical guidance on\nselecting optimizers and representation models/architectures for robust and\nefficient gray-box discovery. Our findings provide actionable insights for\nimproving the training of physics-informed networks in biomedical applications\nand beyond.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "35R30 (Primary), 65M32, 92C50 (Secondary)",
      "I.2.6; G.1.7; G.1.10"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07379v1",
    "published_date": "2025-04-10 01:37:18 UTC",
    "updated_date": "2025-04-10 01:37:18 UTC"
  },
  {
    "arxiv_id": "2504.10512v1",
    "title": "JEPA4Rec: Learning Effective Language Representations for Sequential Recommendation via Joint Embedding Predictive Architecture",
    "authors": [
      "Minh-Anh Nguyen",
      "Dung D. Le"
    ],
    "abstract": "Language representation learning has emerged as a promising approach for\nsequential recommendation, thanks to its ability to learn generalizable\nrepresentations. However, despite its advantages, this approach still struggles\nwith data sparsity and a limited understanding of common-sense user\npreferences. To address these limitations, we propose $\\textbf{JEPA4Rec}$, a\nframework that combines $\\textbf{J}$oint $\\textbf{E}$mbedding\n$\\textbf{P}$redictive $\\textbf{A}$rchitecture with language modeling of item\ntextual descriptions. JEPA4Rec captures semantically rich and transferable\nrepresentations, improving recommendation performance and reducing reliance on\nlarge-scale pre-training data. Specifically, JEPA4Rec represents items as text\nsentences by flattening descriptive information such as $\\textit{title,\ncategory}$, and other attributes. To encode these sentences, we employ a\nbidirectional Transformer encoder with modified embedding layers tailored for\ncapturing item information in recommendation datasets. We apply masking to text\nsentences and use them to predict the representations of the unmasked\nsentences, helping the model learn generalizable item embeddings. To further\nimprove recommendation performance and language understanding, we employ a\ntwo-stage training strategy incorporating self-supervised learning losses.\nExperiments on six real-world datasets demonstrate that JEPA4Rec consistently\noutperforms state-of-the-art methods, particularly in cross-domain,\ncross-platform, and low-resource scenarios.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10512v1",
    "published_date": "2025-04-10 01:31:11 UTC",
    "updated_date": "2025-04-10 01:31:11 UTC"
  },
  {
    "arxiv_id": "2504.07373v1",
    "title": "ChronoFormer: Time-Aware Transformer Architectures for Structured Clinical Event Modeling",
    "authors": [
      "Yuanyun Zhang",
      "Shi Li"
    ],
    "abstract": "The temporal complexity of electronic health record (EHR) data presents\nsignificant challenges for predicting clinical outcomes using machine learning.\nThis paper proposes ChronoFormer, an innovative transformer based architecture\nspecifically designed to encode and leverage temporal dependencies in\nlongitudinal patient data. ChronoFormer integrates temporal embeddings,\nhierarchical attention mechanisms, and domain specific masking techniques.\nExtensive experiments conducted on three benchmark tasks mortality prediction,\nreadmission prediction, and long term comorbidity onset demonstrate substantial\nimprovements over current state of the art methods. Furthermore, detailed\nanalyses of attention patterns underscore ChronoFormer's capability to capture\nclinically meaningful long range temporal relationships.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07373v1",
    "published_date": "2025-04-10 01:25:41 UTC",
    "updated_date": "2025-04-10 01:25:41 UTC"
  },
  {
    "arxiv_id": "2504.07360v1",
    "title": "Enhancing Time Series Forecasting via Multi-Level Text Alignment with LLMs",
    "authors": [
      "Taibiao Zhao",
      "Xiaobing Chen",
      "Mingxuan Sun"
    ],
    "abstract": "The adaptation of large language models (LLMs) to time series forecasting\nposes unique challenges, as time series data is continuous in nature, while\nLLMs operate on discrete tokens. Despite the success of LLMs in natural\nlanguage processing (NLP) and other structured domains, aligning time series\ndata with language-based representations while maintaining both predictive\naccuracy and interpretability remains a significant hurdle. Existing methods\nhave attempted to reprogram time series data into text-based forms, but these\noften fall short in delivering meaningful, interpretable results. In this\npaper, we propose a multi-level text alignment framework for time series\nforecasting using LLMs that not only improves prediction accuracy but also\nenhances the interpretability of time series representations. Our method\ndecomposes time series into trend, seasonal, and residual components, which are\nthen reprogrammed into component-specific text representations. We introduce a\nmulti-level alignment mechanism, where component-specific embeddings are\naligned with pre-trained word tokens, enabling more interpretable forecasts.\nExperiments on multiple datasets demonstrate that our method outperforms\nstate-of-the-art models in accuracy while providing good interpretability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07360v1",
    "published_date": "2025-04-10 01:02:37 UTC",
    "updated_date": "2025-04-10 01:02:37 UTC"
  },
  {
    "arxiv_id": "2504.07359v1",
    "title": "A Balanced Approach of Rapid Genetic Exploration and Surrogate Exploitation for Hyperparameter Optimization",
    "authors": [
      "Chul Kim",
      "Inwhee Joe"
    ],
    "abstract": "This paper proposes a new method for hyperparameter optimization (HPO) that\nbalances exploration and exploitation. While evolutionary algorithms (EAs) show\npromise in HPO, they often struggle with effective exploitation. To address\nthis, we integrate a linear surrogate model into a genetic algorithm (GA),\nallowing for smooth integration of multiple strategies. This combination\nimproves exploitation performance, achieving an average improvement of 1.89\npercent (max 6.55 percent, min -3.45 percent) over existing HPO methods.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "68T20",
      "I.2.8; G.1.6"
    ],
    "primary_category": "cs.NE",
    "comment": "Published in IEEE Access, 12 pages, 10 figures. DOI:\n  10.1109/ACCESS.2024.3508269",
    "pdf_url": "http://arxiv.org/pdf/2504.07359v1",
    "published_date": "2025-04-10 00:59:54 UTC",
    "updated_date": "2025-04-10 00:59:54 UTC"
  },
  {
    "arxiv_id": "2504.07345v1",
    "title": "Quantum-Inspired Genetic Algorithm for Robust Source Separation in Smart City Acoustics",
    "authors": [
      "Minh K. Quan",
      "Mayuri Wijayasundara",
      "Sujeeva Setunge",
      "Pubudu N. Pathirana"
    ],
    "abstract": "The cacophony of urban sounds presents a significant challenge for smart city\napplications that rely on accurate acoustic scene analysis. Effectively\nanalyzing these complex soundscapes, often characterized by overlapping sound\nsources, diverse acoustic events, and unpredictable noise levels, requires\nprecise source separation. This task becomes more complicated when only limited\ntraining data is available. This paper introduces a novel Quantum-Inspired\nGenetic Algorithm (p-QIGA) for source separation, drawing inspiration from\nquantum information theory to enhance acoustic scene analysis in smart cities.\nBy leveraging quantum superposition for efficient solution space exploration\nand entanglement to handle correlated sources, p-QIGA achieves robust\nseparation even with limited data. These quantum-inspired concepts are\nintegrated into a genetic algorithm framework to optimize source separation\nparameters. The effectiveness of our approach is demonstrated on two datasets:\nthe TAU Urban Acoustic Scenes 2020 Mobile dataset, representing typical urban\nsoundscapes, and the Silent Cities dataset, capturing quieter urban\nenvironments during the COVID-19 pandemic. Experimental results show that the\np-QIGA achieves accuracy comparable to state-of-the-art methods while\nexhibiting superior resilience to noise and limited training data, achieving up\nto 8.2 dB signal-to-distortion ratio (SDR) in noisy environments and\noutperforming baseline methods by up to 2 dB with only 10% of the training\ndata. This research highlights the potential of p-QIGA to advance acoustic\nsignal processing in smart cities, particularly for noise pollution monitoring\nand acoustic surveillance.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "6 pages, 2 figures, IEEE International Conference on Communications\n  (ICC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.07345v1",
    "published_date": "2025-04-10 00:05:35 UTC",
    "updated_date": "2025-04-10 00:05:35 UTC"
  }
]