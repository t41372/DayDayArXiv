{
  "date": "2025-05-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-13 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 133 篇论文，主要聚焦 AI、机器学习、强化学习和多模态模型等领域，强调模型可靠性、效率提升和实际应用；令人印象深刻的文章包括对大型语言模型（LLMs）的可靠性优化（如 Adarsh Kumar 等作者的论文）和强化学习在连续控制中的创新（如 Hazim Alzorgan 的论文），这些工作展示了 AI 在复杂任务中的潜力，同时也涉及知名学者如 Michael Bowling 的贡献。\n\n下面，我将挑选并简要讨论部分关键论文，先从重要和高话题度的文章入手（如 LLM 和强化学习相关），然后快速掠过其他领域的内容。重点保留核心学术术语，并突出主要贡献和发现。\n\n### LLM 和生成模型领域（高话题度，优先讨论）\n- **Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification**（中文：提升大型语言模型的可靠性：结合思维链、检索增强生成、自一致性和自验证）  \n  这篇论文由 Adarsh Kumar 等作者提出，探讨了通过 CoT（思维链提示）、RAG（检索增强生成）、自一致性和自验证策略来减少 LLM 的幻觉问题。主要贡献是通过比较评估这些方法，证明了结合外部知识和自校正机制能显著提高事实准确性和响应连贯性，适用于复杂任务。\n\n- **Automated Meta Prompt Engineering for Alignment with the Theory of Mind**（中文：基于理论心智的自动元提示工程）  \n  作者包括 Aaron Baughman 和 Rahul Agarwal，这篇工作创新性地使用强化学习优化 LLM 的提示，以匹配人类心理预期。主要发现是通过实验验证了 LLM 在生成文本时能预测并整合人类编辑，实现了 53.8% 的内容对齐率，提升了 AI 在实际应用（如体育事件报道）中的可用性。\n\n- **Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions**（中文：基于模板引导的肺段重建：使用神经隐式函数）  \n  这篇论文提出了一种高效的肺部重建方法，使用神经隐式函数和模板变形。主要贡献是开发了新数据集 Lung3D 和评估指标，显著提高了重建精度，适用于肺癌手术规划。\n\n- **Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation**（中文：量子增强神经网络参数生成的微分量子架构搜索）  \n  作者团队包括 Samuel Yen-Chi Chen，该工作探索了量子架构搜索来优化神经网络参数。主要发现是通过端到端优化，实现了在分类和强化学习任务上的性能提升，展示了量子计算在 AI 中的潜力。\n\n其他 LLM 相关论文，如 \"Evaluating Simplification Algorithms for Interpretability of Time Series Classification\"，快速掠过：这些工作聚焦 LLM 在时间序列解释中的应用，但贡献较为常规，仅提升了模型可解释性。\n\n### 强化学习和决策领域（重要且有实际影响）\n- **Monte Carlo Beam Search for Actor-Critic Reinforcement Learning in Continuous Control**（中文：蒙特卡洛束搜索在 Actor-Critic 强化学习中的应用：针对连续控制）  \n  Hazim Alzorgan 等作者的工作引入了 MCBS 方法，结合束搜索和蒙特卡洛回滚来提升 Actor-Critic（如 TD3）的探索效率。主要贡献是实验证明了在基准环境（如 HalfCheetah-v4）中，MCBS 比传统方法（如 SAC、PPO）更快收敛，90% 奖励在 20 万步内实现。\n\n- **Deep Reinforcement Learning for Power Grid Multi-Stage Cascading Failure Mitigation**（中文：深度强化学习在电力网格多阶段级联故障缓解中的应用）  \n  这篇论文将多阶段故障视为强化学习任务，使用确定性策略梯度算法训练代理。主要发现是通过 IEEE 14-bus 和 118-bus 系统验证，显著降低了故障风险，适用于实时电网管理。\n\n- **Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition**（中文：基于自编码器的持续强化学习：任务和新环境识别）  \n  作者包括 Boi Faltings，该工作使用自编码器检测新任务并保持知识。主要贡献是实现了无外部信号的持续学习，实验显示代理能有效适应新环境。\n\n其他强化学习论文，如 \"Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning\"，快速掠过：该工作优化了多代理强化学习在空战中的决策，但影响相对有限，仅在模拟环境中有效。\n\n### 计算机视觉和图像处理领域（部分有创新，但快速掠过）\n- **TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System**（中文：TrialMatchAI：端到端 AI 驱动的临床试验推荐系统）  \n  这篇论文构建了 AI 系统用于患者匹配临床试验。主要贡献是通过多模态数据处理实现了高准确率（90%以上），但整体应用性需进一步验证。\n\n其他视觉相关论文，如 \"Template-Guided Reconstruction of Pulmonary Segments\"，已在上面讨论；其余如 \"Object detection in adverse weather conditions\" 等，仅快速提到：这些工作提升了物体检测鲁棒性，但实验规模较小，贡献不显著。\n\n### 其他领域（快速掠过，低优先级）\n- 量子计算论文，如 \"Differentiable Quantum Architecture Search\"，已在上面提及；其他如 \"GPML: Graph Processing for Machine Learning\"，主要贡献是处理网络流量图，但实用性一般。\n- 生物和医疗论文，如 \"CellTypeAgent\"，使用 LLM 进行细胞类型标注，准确率高，但数据依赖性强。\n- 总体上，这些论文（如遥感、文本生成等）虽有创新，但不为核心话题，仅简要指出它们在特定领域的微小进展，例如 \"ExEBench\" 为极端事件基准提供了新数据集。\n\n总之，今天的论文突出了 AI 在可靠性、决策和实际应用中的进展，LLM 和强化学习领域尤为活跃。未来，关注模型鲁棒性和实际部署将是关键方向。如果您对特定论文感兴趣，可以进一步探讨！",
  "papers": [
    {
      "arxiv_id": "2505.09031v1",
      "title": "Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification",
      "title_zh": "提升 LLMs 的可靠性：结合 CoT、RAG、自一致性和自验证",
      "authors": [
        "Adarsh Kumar",
        "Hwiyoon Kim",
        "Jawahar Sai Nathani",
        "Neil Roy"
      ],
      "abstract": "Hallucination, where large language models (LLMs) generate confident but\nincorrect or irrelevant information, remains a key limitation in their\napplication to complex, open-ended tasks. Chain-of-thought (CoT) prompting has\nemerged as a promising method for improving multistep reasoning by guiding\nmodels through intermediate steps. However, CoT alone does not fully address\nthe hallucination problem. In this work, we investigate how combining CoT with\nretrieval-augmented generation (RAG), as well as applying self-consistency and\nself-verification strategies, can reduce hallucinations and improve factual\naccuracy. By incorporating external knowledge sources during reasoning and\nenabling models to verify or revise their own outputs, we aim to generate more\naccurate and coherent responses. We present a comparative evaluation of\nbaseline LLMs against CoT, CoT+RAG, self-consistency, and self-verification\ntechniques. Our results highlight the effectiveness of each method and identify\nthe most robust approach for minimizing hallucinations while preserving fluency\nand reasoning depth.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 的幻觉问题（生成自信但不正确的信息），提出了一种结合 Chain-of-Thought (CoT) 提示、Retrieval-Augmented Generation (RAG)、Self-Consistency 和 Self-Verification 的方法，以提升模型的多步推理准确性和事实可靠性。CoT 用于指导中间推理步骤，RAG 整合外部知识来源，而 Self-Consistency 和 Self-Verification 则帮助模型验证并修正输出，从而生成更连贯的响应。通过比较基线模型与这些技术的表现，实验结果显示，该组合方法将幻觉减少了显著幅度，同时保持了响应的流畅性和推理深度，并确定了最稳健的整体策略。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09031v1",
      "published_date": "2025-05-13 23:57:02 UTC",
      "updated_date": "2025-05-13 23:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:10.751023"
    },
    {
      "arxiv_id": "2505.09029v1",
      "title": "Monte Carlo Beam Search for Actor-Critic Reinforcement Learning in Continuous Control",
      "title_zh": "Monte Carlo 束搜索用于 Actor-Critic 强化学习中的连续控制",
      "authors": [
        "Hazim Alzorgan",
        "Abolfazl Razi"
      ],
      "abstract": "Actor-critic methods, like Twin Delayed Deep Deterministic Policy Gradient\n(TD3), depend on basic noise-based exploration, which can result in less than\noptimal policy convergence. In this study, we introduce Monte Carlo Beam Search\n(MCBS), a new hybrid method that combines beam search and Monte Carlo rollouts\nwith TD3 to improve exploration and action selection. MCBS produces several\ncandidate actions around the policy's output and assesses them through\nshort-horizon rollouts, enabling the agent to make better-informed choices. We\ntest MCBS across various continuous-control benchmarks, including\nHalfCheetah-v4, Walker2d-v5, and Swimmer-v5, showing enhanced sample efficiency\nand performance compared to standard TD3 and other baseline methods like SAC,\nPPO, and A2C. Our findings emphasize MCBS's capability to enhance policy\nlearning through structured look-ahead search while ensuring computational\nefficiency. Additionally, we offer a detailed analysis of crucial\nhyperparameters, such as beam width and rollout depth, and explore adaptive\nstrategies to optimize MCBS for complex control tasks. Our method shows a\nhigher convergence rate across different environments compared to TD3, SAC,\nPPO, and A2C. For instance, we achieved 90% of the maximum achievable reward\nwithin around 200 thousand timesteps compared to 400 thousand timesteps for the\nsecond-best method.",
      "tldr_zh": "本研究针对 Actor-critic 方法（如 TD3）的噪声-based 探索问题，提出 Monte Carlo Beam Search (MCBS)，一种将 beam search 和 Monte Carlo rollouts 与 TD3 结合的混合方法，以提升探索和行动选择。MCBS 通过生成多个候选动作并利用短时限 rollouts 进行评估，帮助代理做出更明智的决策。实验在 HalfCheetah-v4、Walker2d-v5 和 Swimmer-v5 等连续控制基准上显示，MCBS 比 TD3、SAC、PPO 和 A2C 等基线方法具有更高的样本效率和性能，例如在 200k timesteps 内达到 90% 最大奖励，而第二佳方法需 400k timesteps。此外，该方法通过分析超参数如 beam width 和 rollout depth，实现了更快的收敛率和计算效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09029v1",
      "published_date": "2025-05-13 23:56:12 UTC",
      "updated_date": "2025-05-13 23:56:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:12.063161"
    },
    {
      "arxiv_id": "2505.09027v1",
      "title": "Tests as Prompt: A Test-Driven-Development Benchmark for LLM Code Generation",
      "title_zh": "测试作为提示：一个测试驱动开发基准用于 LLM 代码生成",
      "authors": [
        "Yi Cui"
      ],
      "abstract": "We introduce WebApp1K, a novel benchmark for evaluating large language models\n(LLMs) in test-driven development (TDD) tasks, where test cases serve as both\nprompt and verification for code generation. Unlike traditional approaches\nrelying on natural language prompts, our benchmark emphasizes the ability of\nLLMs to interpret and implement functionality directly from test cases,\nreflecting real-world software development practices. Comprising 1000 diverse\nchallenges across 20 application domains, the benchmark evaluates LLMs on their\nability to generate compact, functional code under the constraints of context\nlength and multi-feature complexity. Our findings highlight instruction\nfollowing and in-context learning as critical capabilities for TDD success,\nsurpassing the importance of general coding proficiency or pretraining\nknowledge. Through comprehensive evaluation of 19 frontier models, we reveal\nperformance bottlenecks, such as instruction loss in long prompts, and provide\na detailed error analysis spanning multiple root causes. This work underscores\nthe practical value of TDD-specific benchmarks and lays the foundation for\nadvancing LLM capabilities in rigorous, application-driven coding scenarios.",
      "tldr_zh": "本文提出 WebApp1K 基准，用于评估大型语言模型 (LLMs) 在测试驱动开发 (TDD) 任务中的代码生成性能，其中测试用例同时作为提示和验证机制，模拟真实软件开发实践。基准包括 1000 个多样化挑战，跨越 20 个应用领域，重点测试 LLMs 在上下文长度和多特征复杂性约束下生成紧凑、功能性代码的能力。研究发现，指令遵循和 in-context learning 是 TDD 成功的关键因素，比一般编码能力或预训练知识更重要；通过评估 19 个前沿模型，揭示了长提示中的指令丢失等性能瓶颈，并提供了详细的错误分析。该工作强调了 TDD 特定基准的实际价值，为提升 LLMs 在严格应用驱动编码场景中的能力奠定基础。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "arXiv admin note: text overlap with arXiv:2409.05177",
      "pdf_url": "http://arxiv.org/pdf/2505.09027v1",
      "published_date": "2025-05-13 23:47:12 UTC",
      "updated_date": "2025-05-13 23:47:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:14.988874"
    },
    {
      "arxiv_id": "2505.09024v1",
      "title": "Automated Meta Prompt Engineering for Alignment with the Theory of Mind",
      "title_zh": "自动化元提示工程，用于与心智理论的对齐",
      "authors": [
        "Aaron Baughman",
        "Rahul Agarwal",
        "Eduardo Morales",
        "Gozde Akay"
      ],
      "abstract": "We introduce a method of meta-prompting that jointly produces fluent text for\ncomplex tasks while optimizing the similarity of neural states between a\nhuman's mental expectation and a Large Language Model's (LLM) neural\nprocessing. A technique of agentic reinforcement learning is applied, in which\nan LLM as a Judge (LLMaaJ) teaches another LLM, through in-context learning,\nhow to produce content by interpreting the intended and unintended generated\ntext traits. To measure human mental beliefs around content production, users\nmodify long form AI-generated text articles before publication at the US Open\n2024 tennis Grand Slam. Now, an LLMaaJ can solve the Theory of Mind (ToM)\nalignment problem by anticipating and including human edits within the creation\nof text from an LLM. Throughout experimentation and by interpreting the results\nof a live production system, the expectations of human content reviewers had\n100% of alignment with AI 53.8% of the time with an average iteration count of\n4.38. The geometric interpretation of content traits such as factualness,\nnovelty, repetitiveness, and relevancy over a Hilbert vector space combines\nspatial volume (all trait importance) with vertices alignment (individual trait\nrelevance) enabled the LLMaaJ to optimize on Human ToM. This resulted in an\nincrease in content quality by extending the coverage of tennis action. Our\nwork that was deployed at the US Open 2024 has been used across other live\nevents within sports and entertainment.",
      "tldr_zh": "本文提出了一种自动化元提示工程方法，用于优化大型语言模型(LLM)与人类心理期望的相似性，从而实现Theory of Mind (ToM)对齐。该方法通过agentic reinforcement learning和LLM as a Judge (LLMaaJ)技术，让一个LLM通过in-context learning指导另一个LLM生成符合人类意图的流畅文本。实验基于US Open 2024的用户修改数据，结果显示AI与人类期望一致率达53.8%，平均迭代次数为4.38，并通过Hilbert向量空间的几何解释优化了内容特征如事实性和新颖性。该框架已在体育和娱乐事件中部署，提高了AI生成内容的整体质量。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.09024v1",
      "published_date": "2025-05-13 23:42:36 UTC",
      "updated_date": "2025-05-13 23:42:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:15.918268"
    },
    {
      "arxiv_id": "2505.09022v1",
      "title": "Block-Biased Mamba for Long-Range Sequence Processing",
      "title_zh": "块偏置 Mamba 用于长程序列处理",
      "authors": [
        "Annan Yu",
        "N. Benjamin Erichson"
      ],
      "abstract": "Mamba extends earlier state space models (SSMs) by introducing\ninput-dependent dynamics, and has demonstrated strong empirical performance\nacross a range of domains, including language modeling, computer vision, and\nfoundation models. However, a surprising weakness remains: despite being built\non architectures designed for long-range dependencies, Mamba performs poorly on\nlong-range sequential tasks. Understanding and addressing this gap is important\nfor improving Mamba's universality and versatility. In this work, we analyze\nMamba's limitations through three perspectives: expressiveness, inductive bias,\nand training stability. Our theoretical results show how Mamba falls short in\neach of these aspects compared to earlier SSMs such as S4D. To address these\nissues, we propose $\\text{B}_2\\text{S}_6$, a simple extension of Mamba's S6\nunit that combines block-wise selective dynamics with a channel-specific bias.\nWe prove that these changes equip the model with a better-suited inductive bias\nand improve its expressiveness and stability. Empirically,\n$\\text{B}_2\\text{S}_6$ outperforms S4 and S4D on Long-Range Arena (LRA) tasks\nwhile maintaining Mamba's performance on language modeling benchmarks.",
      "tldr_zh": "该研究分析了 Mamba 模型在处理长序列任务时的局限性，包括表达能力(expressiveness)、归纳偏差(inductive bias)和训练稳定性(training stability)方面的不足，并与早期的状态空间模型(SSMs)如 S4D 进行了比较。作者提出了一种简单扩展 $\\text{B}_2\\text{S}_6$，通过结合块-wise 选择性动态和通道特定偏差(channel-specific bias)，来提升 Mamba 的 S6 单元的性能。实验结果显示，$\\text{B}_2\\text{S}_6$ 在 Long-Range Arena (LRA) 任务上超过了 S4 和 S4D，同时在语言建模基准上保持了 Mamba 的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09022v1",
      "published_date": "2025-05-13 23:34:09 UTC",
      "updated_date": "2025-05-13 23:34:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:18.648191"
    },
    {
      "arxiv_id": "2505.09021v1",
      "title": "AI-Mediated Code Comment Improvement",
      "title_zh": "人工智能介导的代码注释改进",
      "authors": [
        "Maria Dhakal",
        "Chia-Yi Su",
        "Robert Wallace",
        "Chris Fakhimi",
        "Aakash Bansal",
        "Toby Li",
        "Yu Huang",
        "Collin McMillan"
      ],
      "abstract": "This paper describes an approach to improve code comments along different\nquality axes by rewriting those comments with customized Artificial\nIntelligence (AI)-based tools. We conduct an empirical study followed by\ngrounded theory qualitative analysis to determine the quality axes to improve.\nThen we propose a procedure using a Large Language Model (LLM) to rewrite\nexisting code comments along the quality axes. We implement our procedure using\nGPT-4o, then distil the results into a smaller model capable of being run\nin-house, so users can maintain data custody. We evaluate both our approach\nusing GPT-4o and the distilled model versions. We show in an evaluation how our\nprocedure improves code comments along the quality axes. We release all data\nand source code in an online repository for reproducibility.",
      "tldr_zh": "本研究提出了一种通过AI（Artificial Intelligence）工具改进代码注释的方法，针对多个质量维度进行重写。首先，通过实证研究和grounded theory质性分析确定改进的重点维度，然后使用Large Language Model (LLM)如GPT-4o来重写现有代码注释，并将模型提炼到较小版本以支持内部运行并保持数据托管。实验评估显示，该方法显著提升了代码注释的质量。研究团队已开源所有数据和源代码，以确保可重复性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09021v1",
      "published_date": "2025-05-13 23:31:32 UTC",
      "updated_date": "2025-05-13 23:31:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:18.631948"
    },
    {
      "arxiv_id": "2505.09012v1",
      "title": "Deep Reinforcement Learning for Power Grid Multi-Stage Cascading Failure Mitigation",
      "title_zh": "深度强化学习用于电力电网多阶段级联故障缓解",
      "authors": [
        "Bo Meng",
        "Chenghao Xu",
        "Yongli Zhu"
      ],
      "abstract": "Cascading failures in power grids can lead to grid collapse, causing severe\ndisruptions to social operations and economic activities. In certain cases,\nmulti-stage cascading failures can occur. However, existing\ncascading-failure-mitigation strategies are usually single-stage-based,\noverlooking the complexity of the multi-stage scenario. This paper treats the\nmulti-stage cascading failure problem as a reinforcement learning task and\ndevelops a simulation environment. The reinforcement learning agent is then\ntrained via the deterministic policy gradient algorithm to achieve continuous\nactions. Finally, the effectiveness of the proposed approach is validated on\nthe IEEE 14-bus and IEEE 118-bus systems.",
      "tldr_zh": "这篇论文针对电力网的多阶段级联故障(Cascading Failure)问题，提出了一种基于深度强化学习(Deep Reinforcement Learning)的缓解策略，以应对现有单阶段方法的局限性。作者将多阶段故障建模为强化学习任务，开发了一个模拟环境，并使用确定性策略梯度算法(Deterministic Policy Gradient Algorithm)训练代理来实现连续动作。实验结果在 IEEE 14-bus 和 IEEE 118-bus 系统上验证了该方法的有效性，展示了其在预防电网崩溃方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09012v1",
      "published_date": "2025-05-13 23:01:34 UTC",
      "updated_date": "2025-05-13 23:01:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:20.866489"
    },
    {
      "arxiv_id": "2505.09003v1",
      "title": "Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition",
      "title_zh": "基于自编码器驱动的任务和新环境识别的持续强化学习",
      "authors": [
        "Zeki Doruk Erden",
        "Donia Gasmi",
        "Boi Faltings"
      ],
      "abstract": "Continual learning for reinforcement learning agents remains a significant\nchallenge, particularly in preserving and leveraging existing information\nwithout an external signal to indicate changes in tasks or environments. In\nthis study, we explore the effectiveness of autoencoders in detecting new tasks\nand matching observed environments to previously encountered ones. Our approach\nintegrates policy optimization with familiarity autoencoders within an\nend-to-end continual learning system. This system can recognize and learn new\ntasks or environments while preserving knowledge from earlier experiences and\ncan selectively retrieve relevant knowledge when re-encountering a known\nenvironment. Initial results demonstrate successful continual learning without\nexternal signals to indicate task changes or reencounters, showing promise for\nthis methodology.",
      "tldr_zh": "本研究探讨了强化学习（Reinforcement Learning）中的持续学习（Continual Learning）挑战，特别是在没有外部信号的情况下如何保留和利用现有信息。研究提出了一种基于 autoencoders 驱动的方法，通过熟悉度 autoencoders（Familiarity Autoencoders）与策略优化（Policy Optimization）整合的端到端系统，来识别新任务或环境，同时保留先前的知识并在重新遇到已知环境时选择性检索相关信息。初步实验结果表明，该方法无需外部信号即可成功实现持续学习，展示了其在动态环境中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Autonomous Robots and Multirobot Systems (ARMS)\n  workshop at AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09003v1",
      "published_date": "2025-05-13 22:38:54 UTC",
      "updated_date": "2025-05-13 22:38:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:23.397673"
    },
    {
      "arxiv_id": "2505.08995v1",
      "title": "Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning",
      "title_zh": "通过分层多智能体强化学习增强空中作战战术",
      "authors": [
        "Ardian Selmonaj",
        "Oleg Szehr",
        "Giacomo Del Rio",
        "Alessandro Antonucci",
        "Adrian Schneider",
        "Michael Rüegsegger"
      ],
      "abstract": "This work presents a Hierarchical Multi-Agent Reinforcement Learning\nframework for analyzing simulated air combat scenarios involving heterogeneous\nagents. The objective is to identify effective Courses of Action that lead to\nmission success within preset simulations, thereby enabling the exploration of\nreal-world defense scenarios at low cost and in a safe-to-fail setting.\nApplying deep Reinforcement Learning in this context poses specific challenges,\nsuch as complex flight dynamics, the exponential size of the state and action\nspaces in multi-agent systems, and the capability to integrate real-time\ncontrol of individual units with look-ahead planning. To address these\nchallenges, the decision-making process is split into two levels of\nabstraction: low-level policies control individual units, while a high-level\ncommander policy issues macro commands aligned with the overall mission\ntargets. This hierarchical structure facilitates the training process by\nexploiting policy symmetries of individual agents and by separating control\nfrom command tasks. The low-level policies are trained for individual combat\ncontrol in a curriculum of increasing complexity. The high-level commander is\nthen trained on mission targets given pre-trained control policies. The\nempirical validation confirms the advantages of the proposed framework.",
      "tldr_zh": "本文提出一个Hierarchical Multi-Agent Reinforcement Learning框架，用于分析模拟空战场景中异构代理的有效Courses of Action，从而以低成本和安全方式探索真实防御情境。该框架将决策过程分为两个抽象级别：低级别政策负责单个单位的实时控制，高级别指挥政策发布与整体任务目标一致的宏观命令，并通过课程学习（curriculum of increasing complexity）逐步训练这些政策。实验结果证实，该分层结构利用了代理政策的对称性，显著提升了任务成功率，并在复杂飞行动态和多代理系统中表现出优势。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as journal chapter in Deep Learning Applications, Vol. 1,\n  by Taylor & Francis",
      "pdf_url": "http://arxiv.org/pdf/2505.08995v1",
      "published_date": "2025-05-13 22:13:48 UTC",
      "updated_date": "2025-05-13 22:13:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:25.856392"
    },
    {
      "arxiv_id": "2505.08988v1",
      "title": "Generalization in Monitored Markov Decision Processes (Mon-MDPs)",
      "title_zh": "监控 Markov 决策过程 (Mon-MDPs) 中的泛化",
      "authors": [
        "Montaser Mohammedalamen",
        "Michael Bowling"
      ],
      "abstract": "Reinforcement learning (RL) typically models the interaction between the\nagent and environment as a Markov decision process (MDP), where the rewards\nthat guide the agent's behavior are always observable. However, in many\nreal-world scenarios, rewards are not always observable, which can be modeled\nas a monitored Markov decision process (Mon-MDP). Prior work on Mon-MDPs have\nbeen limited to simple, tabular cases, restricting their applicability to\nreal-world problems. This work explores Mon-MDPs using function approximation\n(FA) and investigates the challenges involved. We show that combining function\napproximation with a learned reward model enables agents to generalize from\nmonitored states with observable rewards, to unmonitored environment states\nwith unobservable rewards. Therefore, we demonstrate that such generalization\nwith a reward model achieves near-optimal policies in environments formally\ndefined as unsolvable. However, we identify a critical limitation of such\nfunction approximation, where agents incorrectly extrapolate rewards due to\novergeneralization, resulting in undesirable behaviors. To mitigate\novergeneralization, we propose a cautious police optimization method leveraging\nreward uncertainty. This work serves as a step towards bridging this gap\nbetween Mon-MDP theory and real-world applications.",
      "tldr_zh": "这篇论文探讨了Monitored Markov Decision Processes (Mon-MDPs)，一种强化学习（Reinforcement Learning）框架，其中奖励并非总是可观察的，现有研究仅限于简单表格场景，限制了实际应用。作者引入函数逼近（Function Approximation）和学习奖励模型，使代理能够从有可观察奖励的监控状态推广到无奖励的非监控状态，从而实现接近最优策略，甚至在理论上不可解的环境中。实验揭示了过度泛化的问题，可能导致代理错误外推奖励并产生不良行为。为此，他们提出了一种基于奖励不确定性的谨慎策略优化方法，以缓解这些问题。该工作桥接了Mon-MDP理论与真实世界应用的差距。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2505.08988v1",
      "published_date": "2025-05-13 21:58:25 UTC",
      "updated_date": "2025-05-13 21:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:27.835904"
    },
    {
      "arxiv_id": "2505.08964v1",
      "title": "GPML: Graph Processing for Machine Learning",
      "title_zh": "GPML：面向机器学习的图处理",
      "authors": [
        "Majed Jaber",
        "Julien Michel",
        "Nicolas Boutry",
        "Pierre Parrend"
      ],
      "abstract": "The dramatic increase of complex, multi-step, and rapidly evolving attacks in\ndynamic networks involves advanced cyber-threat detectors. The GPML (Graph\nProcessing for Machine Learning) library addresses this need by transforming\nraw network traffic traces into graph representations, enabling advanced\ninsights into network behaviors. The library provides tools to detect anomalies\nin interaction and community shifts in dynamic networks. GPML supports\ncommunity and spectral metrics extraction, enhancing both real-time detection\nand historical forensics analysis. This library supports modern cybersecurity\nchallenges with a robust, graph-based approach.",
      "tldr_zh": "这篇论文介绍了GPML库（Graph Processing for Machine Learning），它通过将原始网络流量转化为图表示，来应对动态网络中复杂、多步骤攻击的检测需求。GPML提供工具支持异常检测、社区变化分析，以及社区和谱指标提取，从而增强实时检测和历史取证分析。该库采用图-based方法，为现代网络安全挑战提供了一个稳健且高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08964v1",
      "published_date": "2025-05-13 21:10:46 UTC",
      "updated_date": "2025-05-13 21:10:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:35.325160"
    },
    {
      "arxiv_id": "2505.08939v1",
      "title": "Tracing the Invisible: Understanding Students' Judgment in AI-Supported Design Work",
      "title_zh": "追踪隐形：理解学生在AI支持的设计工作中的判断",
      "authors": [
        "Suchismita Naik",
        "Prakash Shukla",
        "Ike Obi",
        "Jessica Backus",
        "Nancy Rasche",
        "Paul Parsons"
      ],
      "abstract": "As generative AI tools become integrated into design workflows, students\nincreasingly engage with these tools not just as aids, but as collaborators.\nThis study analyzes reflections from 33 student teams in an HCI design course\nto examine the kinds of judgments students make when using AI tools. We found\nboth established forms of design judgment (e.g., instrumental, appreciative,\nquality) and emergent types: agency-distribution judgment and reliability\njudgment. These new forms capture how students negotiate creative\nresponsibility with AI and assess the trustworthiness of its outputs. Our\nfindings suggest that generative AI introduces new layers of complexity into\ndesign reasoning, prompting students to reflect not only on what AI produces,\nbut also on how and when to rely on it. By foregrounding these judgments, we\noffer a conceptual lens for understanding how students engage in co-creative\nsensemaking with AI in design contexts.",
      "tldr_zh": "本研究分析了33个学生团队在HCI设计课程中使用生成式AI工具时的判断过程，揭示了学生如何将AI视为合作者而非单纯辅助工具。研究发现，学生做出了传统设计判断（如工具性、欣赏性和质量判断）以及新兴判断，包括agency-distribution judgment（代理分配判断）和reliability judgment（可靠性判断），这些帮助他们协商创造责任和评估AI输出的可信度。结果显示，generative AI引入了设计推理的新复杂性，促使学生反思AI产出的内容、时机和依赖方式。该框架为理解学生在设计环境中与AI进行co-creative sensemaking（共同创造性意义构建）提供了概念视角。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "5 pages, 2 Tables, In Creativity and Cognition 2025, June 23--25,\n  2025, Virtual, United Kingdom",
      "pdf_url": "http://arxiv.org/pdf/2505.08939v1",
      "published_date": "2025-05-13 20:08:10 UTC",
      "updated_date": "2025-05-13 20:08:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:38.379342"
    },
    {
      "arxiv_id": "2505.08919v1",
      "title": "Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions",
      "title_zh": "模板引导的神经隐式函数肺段重建",
      "authors": [
        "Kangxian Xie",
        "Yufei Zhu",
        "Kaiming Kuang",
        "Li Zhang",
        "Hongwei Bran Li",
        "Mingchen Gao",
        "Jiancheng Yang"
      ],
      "abstract": "High-quality 3D reconstruction of pulmonary segments plays a crucial role in\nsegmentectomy and surgical treatment planning for lung cancer. Due to the\nresolution requirement of the target reconstruction, conventional deep\nlearning-based methods often suffer from computational resource constraints or\nlimited granularity. Conversely, implicit modeling is favored due to its\ncomputational efficiency and continuous representation at any resolution. We\npropose a neural implicit function-based method to learn a 3D surface to\nachieve anatomy-aware, precise pulmonary segment reconstruction, represented as\na shape by deforming a learnable template. Additionally, we introduce two\nclinically relevant evaluation metrics to assess the reconstruction\ncomprehensively. Further, due to the absence of publicly available shape\ndatasets to benchmark reconstruction algorithms, we developed a shape dataset\nnamed Lung3D, including the 3D models of 800 labeled pulmonary segments and the\ncorresponding airways, arteries, veins, and intersegmental veins. We\ndemonstrate that the proposed approach outperforms existing methods, providing\na new perspective for pulmonary segment reconstruction. Code and data will be\navailable at https://github.com/M3DV/ImPulSe.",
      "tldr_zh": "这篇论文提出了一种基于neural implicit functions的肺段3D重建方法，通过变形一个可学习的模板来实现解剖感知的精确重建，从而解决传统深度学习方法在计算资源和颗粒度上的限制。研究者引入了两个临床相关的评估指标，并开发了Lung3D数据集，该数据集包含800个标记的肺段3D模型及其相关结构，如气道、动脉、静脉和段间静脉。实验结果表明，该方法优于现有技术，为肺癌手术规划提供了一个新的视角。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "In revision process",
      "pdf_url": "http://arxiv.org/pdf/2505.08919v1",
      "published_date": "2025-05-13 19:31:01 UTC",
      "updated_date": "2025-05-13 19:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:39.971953"
    },
    {
      "arxiv_id": "2505.08918v1",
      "title": "When repeats drive the vocabulary: a Byte-Pair Encoding analysis of T2T primate genomes",
      "title_zh": "当重复序列驱动词汇：T2T 灵长类动物基因组的字节对编码分析",
      "authors": [
        "Marina Popova",
        "Iaroslav Chelombitko",
        "Aleksey Komissarov"
      ],
      "abstract": "The emergence of telomere-to-telomere (T2T) genome assemblies has opened new\navenues for comparative genomics, yet effective tokenization strategies for\ngenomic sequences remain underexplored. In this pilot study, we apply Byte Pair\nEncoding (BPE) to nine T2T primate genomes including three human assemblies by\ntraining independent BPE tokenizers with a fixed vocabulary of 512,000 tokens\nusing our custom tool, dnaBPE. Our analysis reveals that only 11,569 tokens are\nshared across all assemblies, while nearly 991,854 tokens are unique to a\nsingle genome, indicating a rapid decline in shared vocabulary with increasing\nassembly comparisons. Moreover, phylogenetic trees derived from token overlap\nfailed to recapitulate established primate relationships, a discrepancy\nattributed to the disproportionate influence of species-specific high-copy\nrepetitive elements. These findings underscore the dual nature of BPE\ntokenization: while it effectively compresses repetitive sequences, its\nsensitivity to high-copy elements limits its utility as a universal tool for\ncomparative genomics. We discuss potential hybrid strategies and repeat-masking\napproaches to refine genomic tokenization, emphasizing the need for\ndomain-specific adaptations in the development of large-scale genomic language\nmodels. The dnaBPE tool used in this study is open-source and available at\nhttps://github.com/aglabx/dnaBPE.",
      "tldr_zh": "本研究分析了 Byte-Pair Encoding (BPE) 在九个 T2T 灵长类基因组（包括三个人类组装）中的应用，使用自定义工具 dnaBPE 训练独立分词器，每个词汇表固定为 512,000 tokens。结果显示，仅有 11,569 个 tokens 在所有基因组中共享，而近 991,854 个 tokens 是独有的，导致基于 tokens 重叠构建的系统发育树无法准确重现已知灵长类关系，这主要归因于物种特异的高拷贝重复元素的影响。研究强调，BPE 虽能有效压缩重复序列，但其对高拷贝元素的敏感性限制了其在比较基因组学中的通用性，并建议采用混合策略和重复掩码方法来改进基因组分词，从而推动大规模基因组语言模型的领域适应。工具 dnaBPE 已开源，可在 https://github.com/aglabx/dnaBPE 获取。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "ICLR 2025 Workshop on Machine Learning for Genomics Explorations",
      "pdf_url": "http://arxiv.org/pdf/2505.08918v1",
      "published_date": "2025-05-13 19:27:58 UTC",
      "updated_date": "2025-05-13 19:27:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:43.340708"
    },
    {
      "arxiv_id": "2505.08916v1",
      "title": "A New Tractable Description Logic under Categorical Semantics",
      "title_zh": "基于范畴语义的一种新的可处理描述逻辑",
      "authors": [
        "Chan Le Duc",
        "Ludovic Brieulle"
      ],
      "abstract": "Biomedical ontologies contain numerous concept or role names involving\nnegative knowledge such as lacks_part, absence_of. Such a representation with\nlabels rather than logical constructors would not allow a reasoner to interpret\nlacks_part as a kind of negation of has_part. It is known that adding negation\nto the tractable Description Logic (DL) EL allowing for conjunction,\nexistential restriction and concept inclusion makes it intractable since the\nobtained logic includes implicitly disjunction and universal restriction which\ninteract with other constructors. In this paper, we propose a new extension of\nEL with a weakened negation allowing to represent negative knowledge while\nretaining tractability. To this end, we introduce categorical semantics of all\nlogical constructors of the DL SH including EL with disjunction, negation,\nuniversal restriction, role inclusion and transitive roles. The categorical\nsemantics of a logical constructor is usually described as a set of categorical\nproperties referring to several objects without using set membership. To\nrestore tractability, we have to weaken semantics of disjunction and universal\nrestriction by identifying \\emph{independent} categorical properties that are\nresponsible for intractability, and dropping them from the set of categorical\nproperties. We show that the logic resulting from weakening semantics is more\nexpressive than EL with the bottom concept, transitive roles and role\ninclusion.",
      "tldr_zh": "本文提出了一种基于分类语义（categorical semantics）的可处理描述逻辑（Description Logic）扩展，针对生物医学本体中负知识（如 lacks_part）的表示问题，引入弱化的否定操作，以避免 EL 逻辑中添加标准否定导致的不可处理性。方法包括定义 SH 逻辑的分类语义，并通过识别和去除导致不可处理性的独立分类属性（如析取和全称限制的某些属性），从而保留逻辑的可处理性。新逻辑比 EL（加上底概念、传递角色和角色包含）更具表达性，为处理负知识提供了更有效的框架。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08916v1",
      "published_date": "2025-05-13 19:25:21 UTC",
      "updated_date": "2025-05-13 19:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:44.158682"
    },
    {
      "arxiv_id": "2505.09653v1",
      "title": "Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation",
      "title_zh": "在量子增强神经网络参数生成中的可微量子架构搜索",
      "authors": [
        "Samuel Yen-Chi Chen",
        "Chen-Yu Liu",
        "Kuan-Cheng Chen",
        "Wei-Jia Huang",
        "Yen-Jui Chang",
        "Wei-Hao Huang"
      ],
      "abstract": "The rapid advancements in quantum computing (QC) and machine learning (ML)\nhave led to the emergence of quantum machine learning (QML), which integrates\nthe strengths of both fields. Among QML approaches, variational quantum\ncircuits (VQCs), also known as quantum neural networks (QNNs), have shown\npromise both empirically and theoretically. However, their broader adoption is\nhindered by reliance on quantum hardware during inference. Hardware\nimperfections and limited access to quantum devices pose practical challenges.\nTo address this, the Quantum-Train (QT) framework leverages the exponential\nscaling of quantum amplitudes to generate classical neural network parameters,\nenabling inference without quantum hardware and achieving significant parameter\ncompression. Yet, designing effective quantum circuit architectures for such\nquantum-enhanced neural programmers remains non-trivial and often requires\nexpertise in quantum information science. In this paper, we propose an\nautomated solution using differentiable optimization. Our method jointly\noptimizes both conventional circuit parameters and architectural parameters in\nan end-to-end manner via automatic differentiation. We evaluate the proposed\nframework on classification, time-series prediction, and reinforcement learning\ntasks. Simulation results show that our method matches or outperforms manually\ndesigned QNN architectures. This work offers a scalable and automated pathway\nfor designing QNNs that can generate classical neural network parameters across\ndiverse applications.",
      "tldr_zh": "该论文针对量子神经网络（QNNs）的设计挑战，提出了一种可微量子架构搜索方法，以优化量子增强神经网络参数生成。研究基于 Quantum-Train (QT) 框架，利用量子振幅生成经典神经网络参数，从而避免推理阶段依赖量子硬件。方法通过自动微分联合优化电路参数和架构参数，在分类、时间序列预测和强化学习任务上，实验结果显示其性能与手动设计的 QNNs 相当或更优，为自动化、可扩展的量子机器学习（QML）应用提供了新途径。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09653v1",
      "published_date": "2025-05-13 19:01:08 UTC",
      "updated_date": "2025-05-13 19:01:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:45.487521"
    },
    {
      "arxiv_id": "2505.08905v1",
      "title": "Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora",
      "title_zh": "基于无监督文档语料库的语言模型合成数据评估",
      "authors": [
        "Michael Majurski",
        "Cynthia Matuszek"
      ],
      "abstract": "Language Models (LMs) continue to advance, improving response quality and\ncoherence. Given Internet-scale training datasets, LMs have likely encountered\nmuch of what users might ask them to generate in some form during their\ntraining. A plethora of evaluation benchmarks have been constructed to assess\nmodel quality, response appropriateness, and reasoning capabilities. However,\nthe human effort required for benchmark construction is limited and being\nrapidly outpaced by the size and scope of the models under evaluation.\nAdditionally, having humans build a benchmark for every possible domain of\ninterest is impractical. Therefore, we propose a methodology for automating the\nconstruction of fact-based synthetic data model evaluations grounded in\ndocument populations. This work leverages those very same LMs to evaluate\ndomain-specific knowledge automatically, using only grounding documents (e.g.,\na textbook) as input. This synthetic data benchmarking approach corresponds\nwell with human curated questions with a Spearman ranking correlation of 0.96\nand a benchmark evaluation Pearson accuracy correlation of 0.79. This novel\ntool supports generating both multiple choice and open-ended synthetic data\nquestions to gain diagnostic insight of LM capability. We apply this\nmethodology to evaluate model performance on a recent relevant arXiv preprint,\ndiscovering a surprisingly strong performance from Gemma3 models.",
      "tldr_zh": "本文提出一种自动化方法，用于评估 Language Models (LMs) 的合成数据性能，该方法基于无监督文档语料（如教科书），利用 LMs 本身生成事实-based 的评估问题，以解决传统基准建设人力有限的问题。该方法能产生多项选择和开放式合成问题，与人工策划的基准高度一致，Spearman ranking correlation 达 0.96，Pearson accuracy correlation 达 0.79。通过应用此方法评估最近的 arXiv 预印本，研究发现 Gemma3 模型表现出意外的强大性能，为高效诊断 LMs 能力提供了新工具。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08905v1",
      "published_date": "2025-05-13 18:50:03 UTC",
      "updated_date": "2025-05-13 18:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:48.537739"
    },
    {
      "arxiv_id": "2505.08904v1",
      "title": "FareShare: A Tool for Labor Organizers to Estimate Lost Wages and Contest Arbitrary AI and Algorithmic Deactivations",
      "title_zh": "FareShare：一种用于劳动组织者估计损失工资并挑战任意 AI 和算法停用的工具",
      "authors": [
        "Varun Nagaraj Rao",
        "Samantha Dalal",
        "Andrew Schwartz",
        "Amna Liaqat",
        "Dana Calacci",
        "Andrés Monroy-Hernández"
      ],
      "abstract": "What happens when a rideshare driver is suddenly locked out of the platform\nconnecting them to riders, wages, and daily work? Deactivation-the abrupt\nremoval of gig workers' platform access-typically occurs through arbitrary AI\nand algorithmic decisions with little explanation or recourse. This represents\none of the most severe forms of algorithmic control and often devastates\nworkers' financial stability. Recent U.S. state policies now mandate appeals\nprocesses and recovering compensation during the period of wrongful\ndeactivation based on past earnings. Yet, labor organizers still lack effective\ntools to support these complex, error-prone workflows. We designed FareShare, a\ncomputational tool automating lost wage estimation for deactivated drivers,\nthrough a 6 month partnership with the State of Washington's largest rideshare\nlabor union. Over the following 3 months, our field deployment of FareShare\nregistered 178 account signups. We observed that the tool could reduce lost\nwage calculation time by over 95%, eliminate manual data entry errors, and\nenable legal teams to generate arbitration-ready reports more efficiently.\nBeyond these gains, the deployment also surfaced important socio-technical\nchallenges around trust, consent, and tool adoption in high-stakes labor\ncontexts.",
      "tldr_zh": "这篇论文介绍了 FareShare，一种专为劳工组织者设计的工具，用于估算网约车司机因 AI 和 Algorithmic Deactivations（算法停用）而导致的工资损失，并支持上诉流程。该工具通过与华盛顿州最大网约车工会的6个月合作开发，实现了自动化计算，显著减少了手动数据输入错误和计算时间（超过95%的效率提升）。在3个月的现场部署中，FareShare 吸引了178个账户注册，并暴露了信任、同意和工具采用等社会技术挑战，为高风险劳工环境中抗争算法控制提供了实用解决方案。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08904v1",
      "published_date": "2025-05-13 18:46:47 UTC",
      "updated_date": "2025-05-13 18:46:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:50.556871"
    },
    {
      "arxiv_id": "2505.08902v1",
      "title": "Performance Gains of LLMs With Humans in a World of LLMs Versus Humans",
      "title_zh": "在大语言模型与人类的世界中，大语言模型与人类协作的性能提升",
      "authors": [
        "Lucas McCullum",
        "Pelagie Ami Agassi",
        "Leo Anthony Celi",
        "Daniel K. Ebner",
        "Chrystinne Oliveira Fernandes",
        "Rachel S. Hicklen",
        "Mkliwa Koumbia",
        "Lisa Soleymani Lehmann",
        "David Restrepo"
      ],
      "abstract": "Currently, a considerable research effort is devoted to comparing LLMs to a\ngroup of human experts, where the term \"expert\" is often ill-defined or\nvariable, at best, in a state of constantly updating LLM releases. Without\nproper safeguards in place, LLMs will threaten to cause harm to the established\nstructure of safe delivery of patient care which has been carefully developed\nthroughout history to keep the safety of the patient at the forefront. A key\ndriver of LLM innovation is founded on community research efforts which, if\ncontinuing to operate under \"humans versus LLMs\" principles, will expedite this\ntrend. Therefore, research efforts moving forward must focus on effectively\ncharacterizing the safe use of LLMs in clinical settings that persist across\nthe rapid development of novel LLM models. In this communication, we\ndemonstrate that rather than comparing LLMs to humans, there is a need to\ndevelop strategies enabling efficient work of humans with LLMs in an almost\nsymbiotic manner.",
      "tldr_zh": "当前研究常将大型语言模型（LLMs）与人类专家进行比较，但这种“LLMs versus humans”的方法存在问题，包括专家定义模糊和潜在安全风险，尤其在临床环境中可能危害患者安全。作者指出，持续这种竞争导向的研究将加速LLMs的负面影响，因此未来应聚焦于开发策略，让人类与LLMs高效协作，形成一种近似共生的合作模式。该方法有助于在LLMs快速迭代的背景下，确保其在医疗等领域的安全可靠应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08902v1",
      "published_date": "2025-05-13 18:44:22 UTC",
      "updated_date": "2025-05-13 18:44:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:51.028411"
    },
    {
      "arxiv_id": "2505.08896v1",
      "title": "Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections",
      "title_zh": "基于深度强化学习的自动车辆纵向控制策略在信号灯路口",
      "authors": [
        "Pankaj Kumar",
        "Aditya Mishra",
        "Pranamesh Chakraborty",
        "Subrahmanya Swamy Peruru"
      ],
      "abstract": "Developing an autonomous vehicle control strategy for signalised\nintersections (SI) is one of the challenging tasks due to its inherently\ncomplex decision-making process. This study proposes a Deep Reinforcement\nLearning (DRL) based longitudinal vehicle control strategy at SI. A\ncomprehensive reward function has been formulated with a particular focus on\n(i) distance headway-based efficiency reward, (ii) decision-making criteria\nduring amber light, and (iii) asymmetric acceleration/ deceleration response,\nalong with the traditional safety and comfort criteria. This reward function\nhas been incorporated with two popular DRL algorithms, Deep Deterministic\nPolicy Gradient (DDPG) and Soft-Actor Critic (SAC), which can handle the\ncontinuous action space of acceleration/deceleration. The proposed models have\nbeen trained on the combination of real-world leader vehicle (LV) trajectories\nand simulated trajectories generated using the Ornstein-Uhlenbeck (OU) process.\nThe overall performance of the proposed models has been tested using Cumulative\nDistribution Function (CDF) plots and compared with the real-world trajectory\ndata. The results show that the RL models successfully maintain lower distance\nheadway (i.e., higher efficiency) and jerk compared to human-driven vehicles\nwithout compromising safety. Further, to assess the robustness of the proposed\nmodels, we evaluated the model performance on diverse safety-critical\nscenarios, in terms of car-following and traffic signal compliance. Both DDPG\nand SAC models successfully handled the critical scenarios, while the DDPG\nmodel showed smoother action profiles compared to the SAC model. Overall, the\nresults confirm that DRL-based longitudinal vehicle control strategy at SI can\nhelp to improve traffic safety, efficiency, and comfort.",
      "tldr_zh": "这篇论文提出了一种基于 Deep Reinforcement Learning (DRL) 的纵向控制策略，用于自动车辆在信号灯交叉口的决策，以应对其复杂性。研究设计了一个全面的奖励函数，强调距离间距效率、琥珀灯决策和非对称加/减速响应，同时整合安全和舒适标准，并应用 DDPG 和 SAC 算法处理连续动作空间。实验结果显示，该策略在真实和模拟轨迹上训练后，能比人类驾驶车辆实现更低的距离间距和加速度冲击，同时确保安全，并在安全关键场景中表现出色。总体而言，这为提升交通安全、效率和舒适提供了有效方法。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08896v1",
      "published_date": "2025-05-13 18:38:42 UTC",
      "updated_date": "2025-05-13 18:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:43:54.319753"
    },
    {
      "arxiv_id": "2505.08894v1",
      "title": "WaLLM -- Insights from an LLM-Powered Chatbot deployment via WhatsApp",
      "title_zh": "WaLLM -- 通过 WhatsApp 部署的 LLM 驱动聊天机器人的见解",
      "authors": [
        "Hiba Eltigani",
        "Rukhshan Haroon",
        "Asli Kocak",
        "Abdullah Bin Faisal",
        "Noah Martin",
        "Fahad Dogar"
      ],
      "abstract": "Recent advances in generative AI, such as ChatGPT, have transformed access to\ninformation in education, knowledge-seeking, and everyday decision-making.\nHowever, in many developing regions, access remains a challenge due to the\npersistent digital divide. To help bridge this gap, we developed WaLLM - a\ncustom AI chatbot over WhatsApp, a widely used communication platform in\ndeveloping regions. Beyond answering queries, WaLLM offers several features to\nenhance user engagement: a daily top question, suggested follow-up questions,\ntrending and recent queries, and a leaderboard-based reward system. Our service\nhas been operational for over 6 months, amassing over 14.7K queries from\napproximately 100 users. In this paper, we present WaLLM's design and a\nsystematic analysis of logs to understand user interactions. Our results show\nthat 55% of user queries seek factual information. \"Health and well-being\" was\nthe most popular topic (28%), including queries about nutrition and disease,\nsuggesting users view WaLLM as a reliable source. Two-thirds of users' activity\noccurred within 24 hours of the daily top question. Users who accessed the\n\"Leaderboard\" interacted with WaLLM 3x as those who did not. We conclude by\ndiscussing implications for culture-based customization, user interface design,\nand appropriate calibration of users' trust in AI systems for developing\nregions.",
      "tldr_zh": "本文介绍了 WaLLM，一款基于 WhatsApp 的 LLM 驱动聊天机器人，旨在桥接发展中地区的数字鸿沟，提供查询回答、每日热门问题、建议后续问题以及排行榜奖励系统等功能。该系统运行6个月，处理了14.7K查询，分析显示55%的查询为事实信息，“健康和福祉”主题占比28%，且用户互动高度依赖每日问题和排行榜。研究发现，查看排行榜的用户互动频率是其他用户的3倍，并讨论了针对发展中地区的文化定制、用户界面设计和用户对 AI 信任的校准建议。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08894v1",
      "published_date": "2025-05-13 18:36:18 UTC",
      "updated_date": "2025-05-13 18:36:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:02.737764"
    },
    {
      "arxiv_id": "2505.08878v1",
      "title": "Optimized Couplings for Watermarking Large Language Models",
      "title_zh": "大语言模型水印的优化耦合",
      "authors": [
        "Dor Tsur",
        "Carol Xuan Long",
        "Claudio Mayrink Verdun",
        "Hsiang Hsu",
        "Haim Permuter",
        "Flavio P. Calmon"
      ],
      "abstract": "Large-language models (LLMs) are now able to produce text that is, in many\ncases, seemingly indistinguishable from human-generated content. This has\nfueled the development of watermarks that imprint a ``signal'' in LLM-generated\ntext with minimal perturbation of an LLM's output. This paper provides an\nanalysis of text watermarking in a one-shot setting. Through the lens of\nhypothesis testing with side information, we formulate and analyze the\nfundamental trade-off between watermark detection power and distortion in\ngenerated textual quality. We argue that a key component in watermark design is\ngenerating a coupling between the side information shared with the watermark\ndetector and a random partition of the LLM vocabulary. Our analysis identifies\nthe optimal coupling and randomization strategy under the worst-case LLM\nnext-token distribution that satisfies a min-entropy constraint. We provide a\nclosed-form expression of the resulting detection rate under the proposed\nscheme and quantify the cost in a max-min sense. Finally, we provide an array\nof numerical results, comparing the proposed scheme with the theoretical\noptimum and existing schemes, in both synthetic data and LLM watermarking. Our\ncode is available at https://github.com/Carol-Long/CC_Watermark",
      "tldr_zh": "该论文分析了在大型语言模型 (LLMs) 生成文本中添加水印的技术，以最小化对文本质量的干扰，同时提升水印检测能力。通过假设测试框架，该研究探讨了检测功率与文本失真之间的基本权衡，并提出了优化耦合和词汇随机分区策略，以应对最坏情况下的LLMs分布。实验结果显示，该方案在合成数据和实际LLMs水印测试中，检测率接近理论最优，并量化了与现有方法的性能差距，为高效水印设计提供了理论基础。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at ISIT25",
      "pdf_url": "http://arxiv.org/pdf/2505.08878v1",
      "published_date": "2025-05-13 18:08:12 UTC",
      "updated_date": "2025-05-13 18:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:02.867432"
    },
    {
      "arxiv_id": "2505.08854v1",
      "title": "Generative AI for Autonomous Driving: Frontiers and Opportunities",
      "title_zh": "生成式人工智能用于自动驾驶：前沿与机遇",
      "authors": [
        "Yuping Wang",
        "Shuo Xing",
        "Cui Can",
        "Renjie Li",
        "Hongyuan Hua",
        "Kexin Tian",
        "Zhaobin Mo",
        "Xiangbo Gao",
        "Keshu Wu",
        "Sulong Zhou",
        "Hengxu You",
        "Juntong Peng",
        "Junge Zhang",
        "Zehao Wang",
        "Rui Song",
        "Mingxuan Yan",
        "Walter Zimmer",
        "Xingcheng Zhou",
        "Peiran Li",
        "Zhaohan Lu",
        "Chia-Ju Chen",
        "Yue Huang",
        "Ryan A. Rossi",
        "Lichao Sun",
        "Hongkai Yu",
        "Zhiwen Fan",
        "Frank Hao Yang",
        "Yuhao Kang",
        "Ross Greer",
        "Chenxi Liu",
        "Eun Hak Lee",
        "Xuan Di",
        "Xinyue Ye",
        "Liu Ren",
        "Alois Knoll",
        "Xiaopeng Li",
        "Shuiwang Ji",
        "Masayoshi Tomizuka",
        "Marco Pavone",
        "Tianbao Yang",
        "Jing Du",
        "Ming-Hsuan Yang",
        "Hua Wei",
        "Ziran Wang",
        "Yang Zhou",
        "Jiachen Li",
        "Zhengzhong Tu"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) constitutes a transformative\ntechnological wave that reconfigures industries through its unparalleled\ncapabilities for content creation, reasoning, planning, and multimodal\nunderstanding. This revolutionary force offers the most promising path yet\ntoward solving one of engineering's grandest challenges: achieving reliable,\nfully autonomous driving, particularly the pursuit of Level 5 autonomy. This\nsurvey delivers a comprehensive and critical synthesis of the emerging role of\nGenAI across the autonomous driving stack. We begin by distilling the\nprinciples and trade-offs of modern generative modeling, encompassing VAEs,\nGANs, Diffusion Models, and Large Language Models (LLMs). We then map their\nfrontier applications in image, LiDAR, trajectory, occupancy, video generation\nas well as LLM-guided reasoning and decision making. We categorize practical\napplications, such as synthetic data workflows, end-to-end driving strategies,\nhigh-fidelity digital twin systems, smart transportation networks, and\ncross-domain transfer to embodied AI. We identify key obstacles and\npossibilities such as comprehensive generalization across rare cases,\nevaluation and safety checks, budget-limited implementation, regulatory\ncompliance, ethical concerns, and environmental effects, while proposing\nresearch plans across theoretical assurances, trust metrics, transport\nintegration, and socio-technical influence. By unifying these threads, the\nsurvey provides a forward-looking reference for researchers, engineers, and\npolicymakers navigating the convergence of generative AI and advanced\nautonomous mobility. An actively maintained repository of cited works is\navailable at https://github.com/taco-group/GenAI4AD.",
      "tldr_zh": "这篇综述探讨了 Generative AI (GenAI) 在自动驾驶领域的革命性潜力，特别是推动实现 Level 5 自治，通过内容创建、推理和多模态理解来解决工程挑战。论文总结了现代生成模型的原理和权衡，包括 VAEs、GANs、Diffusion Models 和 Large Language Models (LLMs)，并映射它们在图像、LiDAR、轨迹生成以及 LLM 引导决策等方面的前沿应用。作者分类了实际场景如合成数据工作流、端到端驾驶策略和高保真数字孪生系统，同时识别关键障碍（如泛化、安全评估和伦理问题），并提出研究方向包括理论保证、交通整合和 socio-technical 影响，以指导未来发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08854v1",
      "published_date": "2025-05-13 17:59:20 UTC",
      "updated_date": "2025-05-13 17:59:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:07.241309"
    },
    {
      "arxiv_id": "2505.08783v1",
      "title": "CodePDE: An Inference Framework for LLM-driven PDE Solver Generation",
      "title_zh": "CodePDE：一种LLM驱动的PDE求解器生成推理框架",
      "authors": [
        "Shanda Li",
        "Tanya Marwah",
        "Junhong Shen",
        "Weiwei Sun",
        "Andrej Risteski",
        "Yiming Yang",
        "Ameet Talwalkar"
      ],
      "abstract": "Partial differential equations (PDEs) are fundamental to modeling physical\nsystems, yet solving them remains a complex challenge. Traditional numerical\nsolvers rely on expert knowledge to implement and are computationally\nexpensive, while neural-network-based solvers require large training datasets\nand often lack interpretability. In this work, we frame PDE solving as a code\ngeneration task and introduce CodePDE, the first inference framework for\ngenerating PDE solvers using large language models (LLMs). Leveraging advanced\ninference-time algorithms and scaling strategies, CodePDE unlocks critical\ncapacities of LLM for PDE solving: reasoning, debugging, selfrefinement, and\ntest-time scaling -- all without task-specific tuning. CodePDE achieves\nsuperhuman performance across a range of representative PDE problems. We also\npresent a systematic empirical analysis of LLM generated solvers, analyzing\ntheir accuracy, efficiency, and numerical scheme choices. Our findings\nhighlight the promise and the current limitations of LLMs in PDE solving,\noffering a new perspective on solver design and opportunities for future model\ndevelopment. Our code is available at https://github.com/LithiumDA/CodePDE.",
      "tldr_zh": "本研究将偏微分方程(PDE)求解视为代码生成任务，提出CodePDE，这是首个基于大型语言模型(LLMs)的推理框架，用于生成PDE求解器。CodePDE利用高级推理时算法和缩放策略，实现LLMs在PDE求解中的关键能力，如推理、调试、自我改进和测试时缩放，而无需任务特定微调。实验结果显示，CodePDE在多种代表性PDE问题上实现了超人性能，并通过系统实证分析评估了生成求解器的准确性、效率和数值方案选择。该框架突出了LLMs在PDE求解中的潜力，同时揭示了其当前局限性，为未来求解器设计提供新视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08783v1",
      "published_date": "2025-05-13 17:58:08 UTC",
      "updated_date": "2025-05-13 17:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:09.067086"
    },
    {
      "arxiv_id": "2505.08778v1",
      "title": "ARC-NCA: Towards Developmental Solutions to the Abstraction and Reasoning Corpus",
      "title_zh": "ARC-NCA：面向抽象和推理语料库的发展性解决方案",
      "authors": [
        "Etienne Guichard",
        "Felix Reimers",
        "Mia Kvalsund",
        "Mikkel Lepperød",
        "Stefano Nichele"
      ],
      "abstract": "The Abstraction and Reasoning Corpus (ARC), later renamed ARC-AGI, poses a\nfundamental challenge in artificial general intelligence (AGI), requiring\nsolutions that exhibit robust abstraction and reasoning capabilities across\ndiverse tasks, while only few (with median count of three) correct examples are\npresented. While ARC-AGI remains very challenging for artificial intelligence\nsystems, it is rather easy for humans. This paper introduces ARC-NCA, a\ndevelopmental approach leveraging standard Neural Cellular Automata (NCA) and\nNCA enhanced with hidden memories (EngramNCA) to tackle the ARC-AGI benchmark.\nNCAs are employed for their inherent ability to simulate complex dynamics and\nemergent patterns, mimicking developmental processes observed in biological\nsystems. Developmental solutions may offer a promising avenue for enhancing\nAI's problem-solving capabilities beyond mere training data extrapolation.\nARC-NCA demonstrates how integrating developmental principles into\ncomputational models can foster adaptive reasoning and abstraction. We show\nthat our ARC-NCA proof-of-concept results may be comparable to, and sometimes\nsurpass, that of ChatGPT 4.5, at a fraction of the cost.",
      "tldr_zh": "这篇论文针对 Abstraction and Reasoning Corpus (ARC-AGI) 基准提出了一种发育式解决方案 ARC-NCA，利用 Neural Cellular Automata (NCA) 和其增强版 EngramNCA 来模拟生物系统的复杂动态和模式，从而提升 AI 在抽象和推理任务上的能力。ARC-NCA 通过整合发育原则，帮助模型在仅提供少量示例（如中位数三个）的情况下进行适应性推理。实验结果表明，该方法在 ARC-AGI 基准上的表现可与 ChatGPT 4.5 相当或更优，同时显著降低了计算成本。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08778v1",
      "published_date": "2025-05-13 17:55:43 UTC",
      "updated_date": "2025-05-13 17:55:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:10.903706"
    },
    {
      "arxiv_id": "2505.08765v2",
      "title": "Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology",
      "title_zh": "迈向城市空间中自主无人机视觉物体搜索：基准和智能体方法",
      "authors": [
        "Yatai Ji",
        "Zhengqiu Zhu",
        "Yong Zhao",
        "Beidan Liu",
        "Chen Gao",
        "Yihao Zhao",
        "Sihang Qiu",
        "Yue Hu",
        "Quanjun Yin",
        "Yong Li"
      ],
      "abstract": "Aerial Visual Object Search (AVOS) tasks in urban environments require\nUnmanned Aerial Vehicles (UAVs) to autonomously search for and identify target\nobjects using visual and textual cues without external guidance. Existing\napproaches struggle in complex urban environments due to redundant semantic\nprocessing, similar object distinction, and the exploration-exploitation\ndilemma. To bridge this gap and support the AVOS task, we introduce CityAVOS,\nthe first benchmark dataset for autonomous search of common urban objects. This\ndataset comprises 2,420 tasks across six object categories with varying\ndifficulty levels, enabling comprehensive evaluation of UAV agents' search\ncapabilities. To solve the AVOS tasks, we also propose PRPSearcher\n(Perception-Reasoning-Planning Searcher), a novel agentic method powered by\nmulti-modal large language models (MLLMs) that mimics human three-tier\ncognition. Specifically, PRPSearcher constructs three specialized maps: an\nobject-centric dynamic semantic map enhancing spatial perception, a 3D\ncognitive map based on semantic attraction values for target reasoning, and a\n3D uncertainty map for balanced exploration-exploitation search. Also, our\napproach incorporates a denoising mechanism to mitigate interference from\nsimilar objects and utilizes an Inspiration Promote Thought (IPT) prompting\nmechanism for adaptive action planning. Experimental results on CityAVOS\ndemonstrate that PRPSearcher surpasses existing baselines in both success rate\nand search efficiency (on average: +37.69% SR, +28.96% SPL, -30.69% MSS, and\n-46.40% NE). While promising, the performance gap compared to humans highlights\nthe need for better semantic reasoning and spatial exploration capabilities in\nAVOS tasks. This work establishes a foundation for future advances in embodied\ntarget search. Dataset and source code are available at\nhttps://anonymous.4open.science/r/CityAVOS-3DF8.",
      "tldr_zh": "本篇论文针对城市环境中的Aerial Visual Object Search (AVOS)任务，引入了首个基准数据集CityAVOS，该数据集包含2,420个任务、六类常见对象及不同难度水平，用于评估无人机代理的搜索能力。论文提出PRPSearcher，一种基于多模态大语言模型(MLLMs)的代理方法，模仿人类三层认知，通过构建对象中心动态语义地图、3D认知地图和3D不确定性地图，并结合去噪机制和Inspiration Promote Thought (IPT)提示机制，实现平衡的探索-利用策略。实验结果显示，PRPSearcher在CityAVOS上显著优于基线模型（平均提升37.69% SR、28.96% SPL，并降低30.69% MSS和46.40% NE），但与人类性能仍有差距，强调未来需加强语义推理和空间探索，为embodied target search提供基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08765v2",
      "published_date": "2025-05-13 17:34:54 UTC",
      "updated_date": "2025-05-14 01:30:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:14.754902"
    },
    {
      "arxiv_id": "2505.08747v1",
      "title": "Advancing Food Nutrition Estimation via Visual-Ingredient Feature Fusion",
      "title_zh": "通过视觉-成分特征融合提升食物营养估计",
      "authors": [
        "Huiyan Qi",
        "Bin Zhu",
        "Chong-Wah Ngo",
        "Jingjing Chen",
        "Ee-Peng Lim"
      ],
      "abstract": "Nutrition estimation is an important component of promoting healthy eating\nand mitigating diet-related health risks. Despite advances in tasks such as\nfood classification and ingredient recognition, progress in nutrition\nestimation is limited due to the lack of datasets with nutritional annotations.\nTo address this issue, we introduce FastFood, a dataset with 84,446 images\nacross 908 fast food categories, featuring ingredient and nutritional\nannotations. In addition, we propose a new model-agnostic Visual-Ingredient\nFeature Fusion (VIF$^2$) method to enhance nutrition estimation by integrating\nvisual and ingredient features. Ingredient robustness is improved through\nsynonym replacement and resampling strategies during training. The\ningredient-aware visual feature fusion module combines ingredient features and\nvisual representation to achieve accurate nutritional prediction. During\ntesting, ingredient predictions are refined using large multimodal models by\ndata augmentation and majority voting. Our experiments on both FastFood and\nNutrition5k datasets validate the effectiveness of our proposed method built in\ndifferent backbones (e.g., Resnet, InceptionV3 and ViT), which demonstrates the\nimportance of ingredient information in nutrition estimation.\nhttps://huiyanqi.github.io/fastfood-nutrition-estimation/.",
      "tldr_zh": "该论文针对营养估算领域的进展不足问题，引入了FastFood数据集，包含84,446张图像和908个快餐类别，并提供了成分和营养注解，以解决数据集缺乏的难题。作者提出了一种模型无关的Visual-Ingredient Feature Fusion (VIF²)方法，通过整合视觉特征和成分特征、采用同义词替换及重采样策略来提升成分鲁棒性和营养预测准确性。实验在FastFood和Nutrition5k数据集上验证了VIF²的有效性，其在不同骨干网络（如ResNet、InceptionV3和ViT）上均表现出色，突显了成分信息在营养估算中的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication in ACM International Conference on\n  Multimedia Retrieval 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08747v1",
      "published_date": "2025-05-13 17:01:21 UTC",
      "updated_date": "2025-05-13 17:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:14.581307"
    },
    {
      "arxiv_id": "2505.08744v1",
      "title": "DeepMath-Creative: A Benchmark for Evaluating Mathematical Creativity of Large Language Models",
      "title_zh": "DeepMath-Creative：用于评估大型语言模型数学创造力的基准",
      "authors": [
        "Xiaoyang Chen",
        "Xinan Dai",
        "Yu Du",
        "Qian Feng",
        "Naixu Guo",
        "Tingshuo Gu",
        "Yuting Gao",
        "Yingyi Gao",
        "Xudong Han",
        "Xiang Jiang",
        "Yilin Jin",
        "Hongyi Lin",
        "Shisheng Lin",
        "Xiangnan Li",
        "Yuante Li",
        "Yixing Li",
        "Zhentao Lai",
        "Zilu Ma",
        "Yingrong Peng",
        "Jiacheng Qian",
        "Hao-Yu Sun",
        "Jianbo Sun",
        "Zirui Wang",
        "Siwei Wu",
        "Zian Wang",
        "Bin Xu",
        "Jianghao Xu",
        "Yiyang Yu",
        "Zichuan Yang",
        "Hongji Zha",
        "Ruichong Zhang"
      ],
      "abstract": "To advance the mathematical proficiency of large language models (LLMs), the\nDeepMath team has launched an open-source initiative aimed at developing an\nopen mathematical LLM and systematically evaluating its mathematical\ncreativity. This paper represents the initial contribution of this initiative.\nWhile recent developments in mathematical LLMs have predominantly emphasized\nreasoning skills, as evidenced by benchmarks on elementary to\nundergraduate-level mathematical tasks, the creative capabilities of these\nmodels have received comparatively little attention, and evaluation datasets\nremain scarce. To address this gap, we propose an evaluation criteria for\nmathematical creativity and introduce DeepMath-Creative, a novel, high-quality\nbenchmark comprising constructive problems across algebra, geometry, analysis,\nand other domains. We conduct a systematic evaluation of mainstream LLMs'\ncreative problem-solving abilities using this dataset. Experimental results\nshow that even under lenient scoring criteria -- emphasizing core solution\ncomponents and disregarding minor inaccuracies, such as small logical gaps,\nincomplete justifications, or redundant explanations -- the best-performing\nmodel, O3 Mini, achieves merely 70% accuracy, primarily on basic\nundergraduate-level constructive tasks. Performance declines sharply on more\ncomplex problems, with models failing to provide substantive strategies for\nopen problems. These findings suggest that, although current LLMs display a\ndegree of constructive proficiency on familiar and lower-difficulty problems,\nsuch performance is likely attributable to the recombination of memorized\npatterns rather than authentic creative insight or novel synthesis.",
      "tldr_zh": "该研究介绍了 DeepMath-Creative 基准，这是 DeepMath 团队为评估大型语言模型 (LLMs) 的数学创造力而提出的开源倡议。基准包括代数、几何、分析等领域的构建性问题，并定义了相应的评估标准，以填补现有数学 LLM 基准对创造力关注不足的空白。实验结果显示，即使在宽松评分标准下，最佳模型 O3 Mini 在基础本科级任务上仅达到 70% 准确率，而在更复杂或开放问题上表现急剧下降，表明当前 LLMs 的创造力可能主要依赖记忆模式而非真正创新。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08744v1",
      "published_date": "2025-05-13 16:58:05 UTC",
      "updated_date": "2025-05-13 16:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:16.202513"
    },
    {
      "arxiv_id": "2505.08728v1",
      "title": "Securing RAG: A Risk Assessment and Mitigation Framework",
      "title_zh": "强化 RAG 安全：风险评估和缓解框架",
      "authors": [
        "Lukas Ammann",
        "Sara Ott",
        "Christoph R. Landolt",
        "Marco P. Lehmann"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) has emerged as the de facto industry\nstandard for user-facing NLP applications, offering the ability to integrate\ndata without re-training or fine-tuning Large Language Models (LLMs). This\ncapability enhances the quality and accuracy of responses but also introduces\nnovel security and privacy challenges, particularly when sensitive data is\nintegrated. With the rapid adoption of RAG, securing data and services has\nbecome a critical priority. This paper first reviews the vulnerabilities of RAG\npipelines, and outlines the attack surface from data pre-processing and data\nstorage management to integration with LLMs. The identified risks are then\npaired with corresponding mitigations in a structured overview. In a second\nstep, the paper develops a framework that combines RAG-specific security\nconsiderations, with existing general security guidelines, industry standards,\nand best practices. The proposed framework aims to guide the implementation of\nrobust, compliant, secure, and trustworthy RAG systems.",
      "tldr_zh": "本论文探讨了 Retrieval Augmented Generation (RAG) 在 NLP 应用中的安全和隐私挑战，RAG 能提升响应质量但在整合敏感数据时引入新风险，如数据预处理、存储管理和 LLM 集成中的漏洞。论文首先审查这些漏洞，概述攻击面，并将识别的风险与相应的缓解措施配对，提供结构化概述。随后，提出一个框架，将 RAG 特定的安全考虑与现有通用安全指南、行业标准和最佳实践相结合，旨在指导实现稳健、合规且可信的 RAG 系统。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages, 3 figures, Sara Ott and Lukas Ammann contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2505.08728v1",
      "published_date": "2025-05-13 16:39:00 UTC",
      "updated_date": "2025-05-13 16:39:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:18.042185"
    },
    {
      "arxiv_id": "2505.08727v1",
      "title": "Memorization-Compression Cycles Improve Generalization",
      "title_zh": "记忆-压缩循环改善泛化",
      "authors": [
        "Fangyuan Yu"
      ],
      "abstract": "We prove theoretically that generalization improves not only through data\nscaling but also by compressing internal representations. To operationalize\nthis insight, we introduce the Information Bottleneck Language Modeling (IBLM)\nobjective, which reframes language modeling as a constrained optimization\nproblem: minimizing representation entropy subject to optimal prediction\nperformance. Empirically, we observe an emergent memorization-compression cycle\nduring LLM pretraining, evidenced by oscillation positive/negative gradient\nalignment between cross-entropy and Matrix-Based Entropy (MBE), a measure of\nrepresentation entropy. This pattern closely mirrors the predictive-compressive\ntrade-off prescribed by IBLM and also parallels the biological alternation\nbetween awake learning and sleep consolidation. Motivated by this observation,\nwe propose Gated Phase Transition (GAPT), a training algorithm that adaptively\nswitches between memorization and compression phases. When applied to GPT-2\npretraining on FineWeb dataset, GAPT reduces MBE by 50% and improves\ncross-entropy by 4.8%. GAPT improves OOD generalizatino by 35% in a pretraining\ntask on arithmetic multiplication. In a setting designed to simulate\ncatastrophic forgetting, GAPT reduces interference by compressing and\nseparating representations, achieving a 97% improvement in separation -\nparalleling the functional role of sleep consolidation.",
      "tldr_zh": "本研究理论证明，通过压缩内部表示而非仅依赖数据扩展，可以改善模型泛化。作者引入 Information Bottleneck Language Modeling (IBLM) 目标，将语言建模重构为受限优化问题，即在保持最佳预测性能的同时最小化表示熵。实验观察到 LLM 预训练中出现的记忆-压缩循环，并提出 Gated Phase Transition (GAPT) 算法，通过自适应切换记忆和压缩阶段来优化训练。在实际应用中，GAPT 在 GPT-2 预训练上减少 Matrix-Based Entropy (MBE) 50%、改善交叉熵 4.8%，并在 OOD 泛化任务中提升 35%、减少灾难性遗忘干扰达 97%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08727v1",
      "published_date": "2025-05-13 16:37:54 UTC",
      "updated_date": "2025-05-13 16:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:21.694337"
    },
    {
      "arxiv_id": "2505.08719v1",
      "title": "PWC-MoE: Privacy-Aware Wireless Collaborative Mixture of Experts",
      "title_zh": "PWC-MoE：隐私感知无线协作混合专家模型",
      "authors": [
        "Yang Su",
        "Na Yan",
        "Yansha Deng",
        "Robert Schober"
      ],
      "abstract": "Large language models (LLMs) hosted on cloud servers alleviate the\ncomputational and storage burdens on local devices but raise privacy concerns\ndue to sensitive data transmission and require substantial communication\nbandwidth, which is challenging in constrained environments. In contrast, small\nlanguage models (SLMs) running locally enhance privacy but suffer from limited\nperformance on complex tasks. To balance computational cost, performance, and\nprivacy protection under bandwidth constraints, we propose a privacy-aware\nwireless collaborative mixture of experts (PWC-MoE) framework. Specifically,\nPWC-MoE employs a sparse privacy-aware gating network to dynamically route\nsensitive tokens to privacy experts located on local clients, while\nnon-sensitive tokens are routed to non-privacy experts located at the remote\nbase station. To achieve computational efficiency, the gating network ensures\nthat each token is dynamically routed to and processed by only one expert. To\nenhance scalability and prevent overloading of specific experts, we introduce a\ngroup-wise load-balancing mechanism for the gating network that evenly\ndistributes sensitive tokens among privacy experts and non-sensitive tokens\namong non-privacy experts. To adapt to bandwidth constraints while preserving\nmodel performance, we propose a bandwidth-adaptive and importance-aware token\noffloading scheme. This scheme incorporates an importance predictor to evaluate\nthe importance scores of non-sensitive tokens, prioritizing the most important\ntokens for transmission to the base station based on their predicted importance\nand the available bandwidth. Experiments demonstrate that the PWC-MoE framework\neffectively preserves privacy and maintains high performance even in\nbandwidth-constrained environments, offering a practical solution for deploying\nLLMs in privacy-sensitive and bandwidth-limited scenarios.",
      "tldr_zh": "该研究提出PWC-MoE框架，旨在平衡大型语言模型(LLMs)的计算成本、性能和隐私保护问题，尤其在带宽受限环境中。框架采用sparse privacy-aware gating network动态路由敏感tokens到本地客户端的privacy experts，而非敏感tokens路由到远程基站的non-privacy experts，确保每个token仅由一个expert处理以提高效率。同时，引入group-wise load-balancing机制均衡负载分布，以及bandwidth-adaptive and importance-aware token offloading方案，通过importance predictor优先传输重要tokens。实验结果表明，PWC-MoE在隐私保护和性能维护方面表现出色，为部署LLMs于隐私敏感和带宽有限的场景提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08719v1",
      "published_date": "2025-05-13 16:27:07 UTC",
      "updated_date": "2025-05-13 16:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:28.822823"
    },
    {
      "arxiv_id": "2505.08849v1",
      "title": "Improved Algorithms for Differentially Private Language Model Alignment",
      "title_zh": "差分隐私语言模型对齐的改进算法",
      "authors": [
        "Keyu Chen",
        "Hao Tang",
        "Qinglin Liu",
        "Yizhao Xu"
      ],
      "abstract": "Language model alignment is crucial for ensuring that large language models\n(LLMs) align with human preferences, yet it often involves sensitive user data,\nraising significant privacy concerns. While prior work has integrated\ndifferential privacy (DP) with alignment techniques, their performance remains\nlimited. In this paper, we propose novel algorithms for privacy-preserving\nalignment and rigorously analyze their effectiveness across varying privacy\nbudgets and models. Our framework can be deployed on two celebrated alignment\ntechniques, namely direct preference optimization (DPO) and reinforcement\nlearning from human feedback (RLHF). Through systematic experiments on\nlarge-scale language models, we demonstrate that our approach achieves\nstate-of-the-art performance. Notably, one of our algorithms, DP-AdamW,\ncombined with DPO, surpasses existing methods, improving alignment quality by\nup to 15% under moderate privacy budgets ({\\epsilon}=2-5). We further\ninvestigate the interplay between privacy guarantees, alignment efficacy, and\ncomputational demands, providing practical guidelines for optimizing these\ntrade-offs.",
      "tldr_zh": "这篇论文针对语言模型对齐（language model alignment）中涉及敏感用户数据的隐私问题，提出改进的差分隐私（differential privacy, DP）算法，以提升大型语言模型（LLMs）的对齐性能。新的框架可应用于直接偏好优化（direct preference optimization, DPO）和人类反馈强化学习（reinforcement learning from human feedback, RLHF），并通过大规模实验验证其有效性。实验结果显示，该方法在中等隐私预算（ε=2-5）下，DP-AdamW算法结合DPO比现有方法提高对齐质量高达15%。此外，论文探讨了隐私保证、对齐效能和计算需求之间的权衡，提供实用优化指导。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08849v1",
      "published_date": "2025-05-13 16:18:59 UTC",
      "updated_date": "2025-05-13 16:18:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:32.369750"
    },
    {
      "arxiv_id": "2505.08706v1",
      "title": "Big Data and the Computational Social Science of Entrepreneurship and Innovation",
      "title_zh": "大数据与创业与创新的计算社会科学",
      "authors": [
        "Ningzi Li",
        "Shiyang Lai",
        "James Evans"
      ],
      "abstract": "As large-scale social data explode and machine-learning methods evolve,\nscholars of entrepreneurship and innovation face new research opportunities but\nalso unique challenges. This chapter discusses the difficulties of leveraging\nlarge-scale data to identify technological and commercial novelty, document new\nventure origins, and forecast competition between new technologies and\ncommercial forms. It suggests how scholars can take advantage of new text,\nnetwork, image, audio, and video data in two distinct ways that advance\ninnovation and entrepreneurship research. First, machine-learning models,\ncombined with large-scale data, enable the construction of precision\nmeasurements that function as system-level observatories of innovation and\nentrepreneurship across human societies. Second, new artificial intelligence\nmodels fueled by big data generate 'digital doubles' of technology and\nbusiness, forming laboratories for virtual experimentation about innovation and\nentrepreneurship processes and policies. The chapter argues for the advancement\nof theory development and testing in entrepreneurship and innovation by\ncoupling big data with big models.",
      "tldr_zh": "这篇论文探讨了大数据和计算社会科学在创业和创新领域的应用，随着大规模社会数据的爆发和机器学习方法的进步，研究者面临识别技术新颖性、记录新企业起源以及预测竞争的独特挑战。论文建议学者利用文本、网络、图像、音频和视频等新数据类型，通过两种方式推进研究：首先，将机器学习模型与大数据结合，构建精确测量作为创新和创业的系统级观测台；其次，利用人工智能模型生成技术与业务的“数字双胞胎”，创建虚拟实验实验室用于测试创新过程和政策。该研究强调，通过大数据与大数据模型的整合，可以加速创业和创新理论的发展与验证。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY",
        "cs.SI",
        "q-fin.EC",
        "stat.AP"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08706v1",
      "published_date": "2025-05-13 16:13:18 UTC",
      "updated_date": "2025-05-13 16:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:33.182205"
    },
    {
      "arxiv_id": "2505.08705v1",
      "title": "Controllable Image Colorization with Instance-aware Texts and Masks",
      "title_zh": "基于实例感知文本和掩码的可控图像着色",
      "authors": [
        "Yanru An",
        "Ling Gui",
        "Qiang Hu",
        "Chunlei Cai",
        "Tianxiao Ye",
        "Xiaoyun Zhang",
        "Yanfeng Wang"
      ],
      "abstract": "Recently, the application of deep learning in image colorization has received\nwidespread attention. The maturation of diffusion models has further advanced\nthe development of image colorization models. However, current mainstream image\ncolorization models still face issues such as color bleeding and color binding\nerrors, and cannot colorize images at the instance level. In this paper, we\npropose a diffusion-based colorization method MT-Color to achieve precise\ninstance-aware colorization with use-provided guidance. To tackle color\nbleeding issue, we design a pixel-level mask attention mechanism that\nintegrates latent features and conditional gray image features through\ncross-attention. We use segmentation masks to construct cross-attention masks,\npreventing pixel information from exchanging between different instances. We\nalso introduce an instance mask and text guidance module that extracts instance\nmasks and text representations of each instance, which are then fused with\nlatent features through self-attention, utilizing instance masks to form\nself-attention masks to prevent instance texts from guiding the colorization of\nother areas, thus mitigating color binding errors. Furthermore, we apply a\nmulti-instance sampling strategy, which involves sampling each instance region\nseparately and then fusing the results. Additionally, we have created a\nspecialized dataset for instance-level colorization tasks, GPT-color, by\nleveraging large visual language models on existing image datasets. Qualitative\nand quantitative experiments show that our model and dataset outperform\nprevious methods and datasets.",
      "tldr_zh": "本文提出了一种基于 diffusion models 的图像着色方法 MT-Color，能够实现精确的实例感知着色，通过用户提供的文本和掩码指导来避免颜色溢出和颜色绑定错误问题。该方法引入像素级掩码注意力机制和实例掩码与文本指导模块，利用 cross-attention 和 self-attention 防止不同实例间信息交换，并采用多实例采样策略来融合结果。此外，作者创建了专门的数据集 GPT-color，并通过定性和定量实验证明，该模型和数据集在性能上优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08705v1",
      "published_date": "2025-05-13 16:13:06 UTC",
      "updated_date": "2025-05-13 16:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:35.796157"
    },
    {
      "arxiv_id": "2505.08704v1",
      "title": "LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs",
      "title_zh": "基于 LLM 的提示集成方法，用于从 EHRs 中可靠地识别医疗实体",
      "authors": [
        "K M Sajjadul Islam",
        "Ayesha Siddika Nipu",
        "Jiawei Wu",
        "Praveen Madiraju"
      ],
      "abstract": "Electronic Health Records (EHRs) are digital records of patient information,\noften containing unstructured clinical text. Named Entity Recognition (NER) is\nessential in EHRs for extracting key medical entities like problems, tests, and\ntreatments to support downstream clinical applications. This paper explores\nprompt-based medical entity recognition using large language models (LLMs),\nspecifically GPT-4o and DeepSeek-R1, guided by various prompt engineering\ntechniques, including zero-shot, few-shot, and an ensemble approach. Among all\nstrategies, GPT-4o with prompt ensemble achieved the highest classification\nperformance with an F1-score of 0.95 and recall of 0.98, outperforming\nDeepSeek-R1 on the task. The ensemble method improved reliability by\naggregating outputs through embedding-based similarity and majority voting.",
      "tldr_zh": "该论文探讨了使用大语言模型（LLMs）如 GPT-4o 和 DeepSeek-R1 进行电子健康记录（EHRs）中的命名实体识别（NER），以提取关键医疗实体（如问题、测试和治疗）支持临床应用。研究采用了各种提示工程技术，包括 zero-shot、few-shot 和 prompt ensemble 方法，其中 prompt ensemble 通过 embedding-based similarity 和 majority voting 聚合输出，提高了识别的可靠性和准确性。结果表明，GPT-4o 与 prompt ensemble 取得了最高的分类性能，F1-score 为 0.95 和 recall 为 0.98，优于 DeepSeek-R1。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "IEEE 26th International Conference on Information Reuse and\n  Integration for Data Science (IRI 2025), San Jose, CA, USA",
      "pdf_url": "http://arxiv.org/pdf/2505.08704v1",
      "published_date": "2025-05-13 16:11:29 UTC",
      "updated_date": "2025-05-13 16:11:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:38.304587"
    },
    {
      "arxiv_id": "2505.08694v1",
      "title": "A Survey of Deep Learning for Complex Speech Spectrograms",
      "title_zh": "复杂语音谱图的深度学习综述",
      "authors": [
        "Yuying Xie",
        "Zheng-Hua Tan"
      ],
      "abstract": "Recent advancements in deep learning have significantly impacted the field of\nspeech signal processing, particularly in the analysis and manipulation of\ncomplex spectrograms. This survey provides a comprehensive overview of the\nstate-of-the-art techniques leveraging deep neural networks for processing\ncomplex spectrograms, which encapsulate both magnitude and phase information.\nWe begin by introducing complex spectrograms and their associated features for\nvarious speech processing tasks. Next, we explore the key components and\narchitectures of complex-valued neural networks, which are specifically\ndesigned to handle complex-valued data and have been applied for complex\nspectrogram processing. We then discuss various training strategies and loss\nfunctions tailored for training neural networks to process and model complex\nspectrograms. The survey further examines key applications, including phase\nretrieval, speech enhancement, and speech separation, where deep learning has\nachieved significant progress by leveraging complex spectrograms or their\nderived feature representations. Additionally, we examine the intersection of\ncomplex spectrograms with generative models. This survey aims to serve as a\nvaluable resource for researchers and practitioners in the field of speech\nsignal processing and complex-valued neural networks.",
      "tldr_zh": "这篇调查论文综述了深度学习在处理 complex spectrograms（包含幅度和相位信息）方面的最新进展，涵盖了 complex-valued neural networks 的关键架构、训练策略和损失函数。论文介绍了这些技术在语音处理任务中的应用，如 phase retrieval、speech enhancement 和 speech separation，并探讨了与生成模型的交集。总体上，它为语音信号处理和复杂值神经网络的研究人员提供了全面资源，突显了深度学习在复杂谱图分析中的显著成效。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08694v1",
      "published_date": "2025-05-13 15:53:01 UTC",
      "updated_date": "2025-05-13 15:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:39.674948"
    },
    {
      "arxiv_id": "2505.08691v1",
      "title": "VizCV: AI-assisted visualization of researchers' publications tracks",
      "title_zh": "VizCV: AI 辅助的研究者出版物轨迹可视化",
      "authors": [
        "Vladimír Lazárik",
        "Marco Agus",
        "Barbora Kozlíková",
        "Pere-Pau Vázquez"
      ],
      "abstract": "Analyzing how the publication records of scientists and research groups have\nevolved over the years is crucial for assessing their expertise since it can\nsupport the management of academic environments by assisting with career\nplanning and evaluation. We introduce VizCV, a novel web-based end-to-end\nvisual analytics framework that enables the interactive exploration of\nresearchers' scientific trajectories. It incorporates AI-assisted analysis and\nsupports automated reporting of career evolution. Our system aims to model\ncareer progression through three key dimensions: a) research topic evolution to\ndetect and visualize shifts in scholarly focus over time, b) publication record\nand the corresponding impact, c) collaboration dynamics depicting the growth\nand transformation of a researcher's co-authorship network. AI-driven insights\nprovide automated explanations of career transitions, detecting significant\nshifts in research direction, impact surges, or collaboration expansions. The\nsystem also supports comparative analysis between researchers, allowing users\nto compare topic trajectories and impact growth. Our interactive, multi-tab and\nmultiview system allows for the exploratory analysis of career milestones under\ndifferent perspectives, such as the most impactful articles, emerging research\nthemes, or obtaining a detailed analysis of the contribution of the researcher\nin a subfield. The key contributions include AI/ML techniques for: a) topic\nanalysis, b) dimensionality reduction for visualizing patterns and trends, c)\nthe interactive creation of textual descriptions of facets of data through\nconfigurable prompt generation and large language models, that include key\nindicators, to help understanding the career development of individuals or\ngroups.",
      "tldr_zh": "本研究介绍了 VizCV，一种基于网络的视觉分析框架，用于交互式探索研究人员的出版轨迹，以支持职业规划和评估。VizCV 通过三个关键维度建模职业进展：研究主题演变、出版记录及其影响，以及合作动态，利用 AI/ML 技术进行主题分析、降维可视化和自动化文本生成。系统提供 AI 驱动的洞见，如检测研究方向转变、影响激增或合作网络扩展，并支持研究人员之间的比较分析。总体贡献包括提升了学术环境的管理效率，并通过交互式多视图设计，方便用户探索关键里程碑和新兴主题。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 9 figures. Subtmitted",
      "pdf_url": "http://arxiv.org/pdf/2505.08691v1",
      "published_date": "2025-05-13 15:47:59 UTC",
      "updated_date": "2025-05-13 15:47:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:40.496756"
    },
    {
      "arxiv_id": "2505.08687v1",
      "title": "AC-PKAN: Attention-Enhanced and Chebyshev Polynomial-Based Physics-Informed Kolmogorov-Arnold Networks",
      "title_zh": "AC-PKAN：注意力增强且基于Chebyshev多项式的物理信息Kolmogorov-Arnold Networks",
      "authors": [
        "Hangwei Zhang",
        "Zhimu Huang",
        "Yan Wang"
      ],
      "abstract": "Kolmogorov-Arnold Networks (KANs) have recently shown promise for solving\npartial differential equations (PDEs). Yet their original formulation is\ncomputationally and memory intensive, motivating the introduction of Chebyshev\nType-I-based KANs (Chebyshev1KANs). Although Chebyshev1KANs have outperformed\nthe vanilla KANs architecture, our rigorous theoretical analysis reveals that\nthey still suffer from rank collapse, ultimately limiting their expressive\ncapacity. To overcome these limitations, we enhance Chebyshev1KANs by\nintegrating wavelet-activated MLPs with learnable parameters and an internal\nattention mechanism. We prove that this design preserves a full-rank Jacobian\nand is capable of approximating solutions to PDEs of arbitrary order.\nFurthermore, to alleviate the loss instability and imbalance introduced by the\nChebyshev polynomial basis, we externally incorporate a Residual Gradient\nAttention (RGA) mechanism that dynamically re-weights individual loss terms\naccording to their gradient norms and residual magnitudes. By jointly\nleveraging internal and external attention, we present AC-PKAN, a novel\narchitecture that constitutes an enhancement to weakly supervised\nPhysics-Informed Neural Networks (PINNs) and extends the expressive power of\nKANs. Experimental results from nine benchmark tasks across three domains show\nthat AC-PKAN consistently outperforms or matches state-of-the-art models such\nas PINNsFormer, establishing it as a highly effective tool for solving complex\nreal-world engineering problems in zero-data or data-sparse regimes. The code\nwill be made publicly available upon acceptance.",
      "tldr_zh": "本研究针对Kolmogorov-Arnold Networks (KANs)在解决偏微分方程 (PDEs) 时存在的计算密集和rank collapse问题，提出了一种增强版Chebyshev1KANs架构。AC-PKAN通过整合wavelet-activated MLPs、内部attention机制和外部Residual Gradient Attention (RGA)机制，实现了full-rank Jacobian的保持，并提升了PDEs任意阶解的逼近能力，同时缓解了Chebyshev polynomial基础带来的损失不稳定。实验结果显示，AC-PKAN在九个基准任务中优于或匹配状态模型如PINNsFormer，尤其在零数据或数据稀疏环境中，为Physics-Informed Neural Networks (PINNs)提供了更强的表达力和实际应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08687v1",
      "published_date": "2025-05-13 15:46:10 UTC",
      "updated_date": "2025-05-13 15:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:44.645159"
    },
    {
      "arxiv_id": "2505.08681v1",
      "title": "A Mamba-based Network for Semi-supervised Singing Melody Extraction Using Confidence Binary Regularization",
      "title_zh": "一种基于 Mamba 的网络，用于半监督歌唱旋律提取，使用置信度二元正则化",
      "authors": [
        "Xiaoliang He",
        "Kangjie Dong",
        "Jingkai Cao",
        "Shuai Yu",
        "Wei Li",
        "Yi Yu"
      ],
      "abstract": "Singing melody extraction (SME) is a key task in the field of music\ninformation retrieval. However, existing methods are facing several\nlimitations: firstly, prior models use transformers to capture the contextual\ndependencies, which requires quadratic computation resulting in low efficiency\nin the inference stage. Secondly, prior works typically rely on\nfrequencysupervised methods to estimate the fundamental frequency (f0), which\nignores that the musical performance is actually based on notes. Thirdly,\ntransformers typically require large amounts of labeled data to achieve optimal\nperformances, but the SME task lacks of sufficient annotated data. To address\nthese issues, in this paper, we propose a mamba-based network, called\nSpectMamba, for semi-supervised singing melody extraction using confidence\nbinary regularization. In particular, we begin by introducing vision mamba to\nachieve computational linear complexity. Then, we propose a novel note-f0\ndecoder that allows the model to better mimic the musical performance. Further,\nto alleviate the scarcity of the labeled data, we introduce a confidence binary\nregularization (CBR) module to leverage the unlabeled data by maximizing the\nprobability of the correct classes. The proposed method is evaluated on several\npublic datasets and the conducted experiments demonstrate the effectiveness of\nour proposed method.",
      "tldr_zh": "该论文针对唱歌旋律提取（SME）任务的效率和数据不足问题，提出了一种基于 Mamba 的网络SpectMamba，用于半监督学习。SpectMamba 采用 Vision Mamba 架构来实现线性计算复杂度，取代了传统 Transformers 的二次方复杂度；同时，引入了 note-f0 解码器以更好地模拟音乐表演基于音符的特性，并通过 Confidence Binary Regularization (CBR) 模块利用未标注数据最大化正确类别的概率。实验在多个公共数据集上验证了该方法的有效性，展示了显著的性能提升。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08681v1",
      "published_date": "2025-05-13 15:43:35 UTC",
      "updated_date": "2025-05-13 15:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:45.474665"
    },
    {
      "arxiv_id": "2505.08673v1",
      "title": "A Study of Data-driven Methods for Inventory Optimization",
      "title_zh": "数据驱动方法用于库存优化的研究",
      "authors": [
        "Lee Yeung Ping",
        "Patrick Wong",
        "Tan Cheng Han"
      ],
      "abstract": "This paper shows a comprehensive analysis of three algorithms (Time Series,\nRandom Forest (RF) and Deep Reinforcement Learning) into three inventory models\n(the Lost Sales, Dual-Sourcing and Multi-Echelon Inventory Model). These\nmethodologies are applied in the supermarket context. The main purpose is to\nanalyse efficient methods for the data-driven. Their possibility, potential and\ncurrent challenges are taken into consideration in this report. By comparing\nthe results in each model, the effectiveness of each algorithm is evaluated\nbased on several key performance indicators, including forecast accuracy,\nadaptability to market changes, and overall impact on inventory costs and\ncustomer satisfaction levels. The data visualization tools and statistical\nmetrics are the indicators for the comparisons and show some obvious trends and\npatterns that can guide decision-making in inventory management. These tools\nenable managers to not only track the performance of different algorithms in\nreal-time but also to drill down into specific data points to understand the\nunderlying causes of inventory fluctuations. This level of detail is crucial\nfor pinpointing inefficiencies and areas for improvement within the supply\nchain.",
      "tldr_zh": "本研究对三种数据驱动算法（Time Series、Random Forest (RF) 和 Deep Reinforcement Learning）在三种库存模型（Lost Sales、Dual-Sourcing 和 Multi-Echelon Inventory Model）中的应用进行了全面分析，旨在评估其在超市库存管理中的效率。研究通过关键绩效指标如预测准确性、市场适应性、库存成本和客户满意度进行比较，结果显示这些算法在处理库存优化方面存在明显趋势和潜力。数据可视化和统计指标进一步帮助识别挑战、实时跟踪性能，并为供应链决策提供指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08673v1",
      "published_date": "2025-05-13 15:35:23 UTC",
      "updated_date": "2025-05-13 15:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:47.103448"
    },
    {
      "arxiv_id": "2505.08847v1",
      "title": "On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction",
      "title_zh": "关于可解释性、隐私和预测性能与解释辅助模型提取的相互作用",
      "authors": [
        "Fatima Ezzeddine",
        "Rinad Akel",
        "Ihab Sbeity",
        "Silvia Giordano",
        "Marc Langheinrich",
        "Omran Ayoub"
      ],
      "abstract": "Machine Learning as a Service (MLaaS) has gained important attraction as a\nmeans for deploying powerful predictive models, offering ease of use that\nenables organizations to leverage advanced analytics without substantial\ninvestments in specialized infrastructure or expertise. However, MLaaS\nplatforms must be safeguarded against security and privacy attacks, such as\nmodel extraction (MEA) attacks. The increasing integration of explainable AI\n(XAI) within MLaaS has introduced an additional privacy challenge, as attackers\ncan exploit model explanations particularly counterfactual explanations (CFs)\nto facilitate MEA. In this paper, we investigate the trade offs among model\nperformance, privacy, and explainability when employing Differential Privacy\n(DP), a promising technique for mitigating CF facilitated MEA. We evaluate two\ndistinct DP strategies: implemented during the classification model training\nand at the explainer during CF generation.",
      "tldr_zh": "本论文探讨了在 Machine Learning as a Service (MLaaS) 中，Explainability、Privacy 和 Predictive Performance 之间的相互作用，特别是针对 Explanation-assisted Model Extraction (MEA) 攻击。研究发现，攻击者可利用 Explainable AI (XAI) 中的 Counterfactual Explanations (CFs) 来辅助模型提取，从而增加隐私风险。为缓解此问题，作者引入 Differential Privacy (DP) 作为一种策略，并评估了两种方法：一种在分类模型训练期间实施，另一种在 CF 生成的解释器上应用。结果显示，DP 能有效提升隐私保护，但会带来模型性能和可解释性的权衡。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08847v1",
      "published_date": "2025-05-13 15:27:06 UTC",
      "updated_date": "2025-05-13 15:27:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:55.138347"
    },
    {
      "arxiv_id": "2505.08664v1",
      "title": "A Social Robot with Inner Speech for Dietary Guidance",
      "title_zh": "一种具有内部语音的社交机器人用于饮食指导",
      "authors": [
        "Valerio Belcamino",
        "Alessandro Carfì",
        "Valeria Seidita",
        "Fulvio Mastrogiovanni",
        "Antonio Chella"
      ],
      "abstract": "We explore the use of inner speech as a mechanism to enhance transparency and\ntrust in social robots for dietary advice. In humans, inner speech structures\nthought processes and decision-making; in robotics, it improves explainability\nby making reasoning explicit. This is crucial in healthcare scenarios, where\ntrust in robotic assistants depends on both accurate recommendations and\nhuman-like dialogue, which make interactions more natural and engaging.\nBuilding on this, we developed a social robot that provides dietary advice, and\nwe provided the architecture with inner speech capabilities to validate user\ninput, refine reasoning, and generate clear justifications. The system\nintegrates large language models for natural language understanding and a\nknowledge graph for structured dietary information. By making decisions more\ntransparent, our approach strengthens trust and improves human-robot\ninteraction in healthcare. We validated this by measuring the computational\nefficiency of our architecture and conducting a small user study, which\nassessed the reliability of inner speech in explaining the robot's behavior.",
      "tldr_zh": "这篇论文探讨了使用inner speech机制来提升社交机器人在饮食指导中的透明度和信任度，模仿人类内部思考过程以使机器人决策更具可解释性。研究开发了一个社交机器人系统，整合large language models进行自然语言理解和knowledge graph提供结构化饮食信息，并通过inner speech验证用户输入、精炼推理并生成清晰理由。该方法通过计算效率评估和用户研究证实了其在改善人类-机器人互动可靠性方面的有效性，尤其适用于医疗场景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08664v1",
      "published_date": "2025-05-13 15:26:52 UTC",
      "updated_date": "2025-05-13 15:26:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:56.820698"
    },
    {
      "arxiv_id": "2505.08657v1",
      "title": "A Comparative Study of Human Activity Recognition: Motion, Tactile, and multi-modal Approaches",
      "title_zh": "人类活动识别的比较研究：运动、触觉及多模态方法",
      "authors": [
        "Valerio Belcamino",
        "Nhat Minh Dinh Le",
        "Quan Khanh Luu",
        "Alessandro Carfì",
        "Van Anh Ho",
        "Fulvio Mastrogiovanni"
      ],
      "abstract": "Human activity recognition (HAR) is essential for effective Human-Robot\nCollaboration (HRC), enabling robots to interpret and respond to human actions.\nThis study evaluates the ability of a vision-based tactile sensor to classify\n15 activities, comparing its performance to an IMU-based data glove.\nAdditionally, we propose a multi-modal framework combining tactile and motion\ndata to leverage their complementary strengths. We examined three approaches:\nmotion-based classification (MBC) using IMU data, tactile-based classification\n(TBC) with single or dual video streams, and multi-modal classification (MMC)\nintegrating both. Offline validation on segmented datasets assessed each\nconfiguration's accuracy under controlled conditions, while online validation\non continuous action sequences tested online performance. Results showed the\nmulti-modal approach consistently outperformed single-modality methods,\nhighlighting the potential of integrating tactile and motion sensing to enhance\nHAR systems for collaborative robotics.",
      "tldr_zh": "这篇论文比较了人类活动识别 (HAR) 在人机协作 (HRC) 中的不同方法，包括基于运动的分类 (MBC)、基于触觉的分类 (TBC) 和多模态分类 (MMC)。研究评估了视觉触觉传感器对15种活动的分类性能，并将其与基于 IMU 的数据手套进行对比，同时提出一个整合触觉和运动数据的多模态框架，以利用它们的互补优势。实验结果显示，多模态方法在离线和在线验证中均显著优于单模态方法，提升了 HAR 系统的准确性，并为协作机器人应用提供了重要潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08657v1",
      "published_date": "2025-05-13 15:20:21 UTC",
      "updated_date": "2025-05-13 15:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:44:59.985828"
    },
    {
      "arxiv_id": "2505.08643v1",
      "title": "WixQA: A Multi-Dataset Benchmark for Enterprise Retrieval-Augmented Generation",
      "title_zh": "WixQA：企业检索增强生成的多数据集基准",
      "authors": [
        "Dvir Cohen",
        "Lin Burg",
        "Sviatoslav Pykhnivskyi",
        "Hagit Gur",
        "Stanislav Kovynov",
        "Olga Atzmon",
        "Gilad Barkan"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) is a cornerstone of modern question\nanswering (QA) systems, enabling grounded answers based on external knowledge.\nAlthough recent progress has been driven by open-domain datasets, enterprise QA\nsystems need datasets that mirror the concrete, domain-specific issues users\nraise in day-to-day support scenarios. Critically, evaluating end-to-end RAG\nsystems requires benchmarks comprising not only question--answer pairs but also\nthe specific knowledge base (KB) snapshot from which answers were derived. To\naddress this need, we introduce WixQA, a benchmark suite featuring QA datasets\nprecisely grounded in the released KB corpus, enabling holistic evaluation of\nretrieval and generation components. WixQA includes three distinct QA datasets\nderived from Wix.com customer support interactions and grounded in a snapshot\nof the public Wix Help Center KB: (i) WixQA-ExpertWritten, 200 real user\nqueries with expert-authored, multi-step answers; (ii) WixQA-Simulated, 200\nexpert-validated QA pairs distilled from user dialogues; and (iii)\nWixQA-Synthetic, 6,222 LLM-generated QA pairs, with one pair systematically\nderived from each article in the knowledge base. We release the KB snapshot\nalongside the datasets under MIT license and provide comprehensive baseline\nresults, forming a unique benchmark for evaluating enterprise RAG systems in\nrealistic enterprise environments.",
      "tldr_zh": "本研究引入了 WixQA，这是一个多数据集基准，用于评估企业级 Retrieval-Augmented Generation (RAG) 系统，以解决现有开源数据集在实际企业支持场景中的局限性。WixQA 包括三个数据集：(i) WixQA-ExpertWritten，包含 200 个真实用户查询及专家撰写的多步答案；(ii) WixQA-Simulated，200 个从用户对话中提炼并专家验证的 QA 对；以及 (iii) WixQA-Synthetic，6,222 个基于知识 base (KB) 文章的 LLM 生成 QA 对。这些数据集与 KB 快照一同发布，并提供全面基线结果，便于对 RAG 的检索和生成组件进行整体评估，从而为企业环境下的 QA 系统优化提供可靠工具。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08643v1",
      "published_date": "2025-05-13 15:02:54 UTC",
      "updated_date": "2025-05-13 15:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:01.258878"
    },
    {
      "arxiv_id": "2505.08846v1",
      "title": "Evaluating Simplification Algorithms for Interpretability of Time Series Classification",
      "title_zh": "评估用于时间序列分类可解释性的简化算法",
      "authors": [
        "Felix Marti-Perez",
        "Brigt Håvardstun",
        "Cèsar Ferri",
        "Carlos Monserrat",
        "Jan Arne Telle"
      ],
      "abstract": "In this work, we introduce metrics to evaluate the use of simplified time\nseries in the context of interpretability of a TSC - a Time Series Classifier.\nSuch simplifications are important because time series data, in contrast to\ntext and image data, are not intuitively understandable to humans. These\nmetrics are related to the complexity of the simplifications - how many\nsegments they contain - and to their loyalty - how likely they are to maintain\nthe classification of the original time series. We employ these metrics to\nevaluate four distinct simplification algorithms, across several TSC algorithms\nand across datasets of varying characteristics, from seasonal or stationary to\nshort or long. Our findings suggest that using simplifications for\ninterpretability of TSC is much better than using the original time series,\nparticularly when the time series are seasonal, non-stationary and/or with low\nentropy.",
      "tldr_zh": "本研究引入了评估简化时间序列在时间序列分类器 (TSC) 可解释性方面的指标，包括简化复杂性（如段数）和忠诚度（如保持原分类的概率），以解决时间序列数据不易被人类直观理解的问题。研究者使用这些指标评估了四种不同的简化算法，在多种 TSC 算法和各种特性数据集（如季节性、非平稳、短或长）上进行测试。结果表明，使用简化时间序列进行 TSC 可解释性比直接使用原时间序列更有效，尤其在季节性、非平稳和低熵数据集上。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08846v1",
      "published_date": "2025-05-13 15:00:56 UTC",
      "updated_date": "2025-05-13 15:00:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:03.483473"
    },
    {
      "arxiv_id": "2505.08638v1",
      "title": "TRAIL: Trace Reasoning and Agentic Issue Localization",
      "title_zh": "TRAIL：跟踪推理与智能体问题定位",
      "authors": [
        "Darshan Deshpande",
        "Varun Gangal",
        "Hersh Mehta",
        "Jitin Krishnan",
        "Anand Kannappan",
        "Rebecca Qian"
      ],
      "abstract": "The increasing adoption of agentic workflows across diverse domains brings a\ncritical need to scalably and systematically evaluate the complex traces these\nsystems generate. Current evaluation methods depend on manual, domain-specific\nhuman analysis of lengthy workflow traces - an approach that does not scale\nwith the growing complexity and volume of agentic outputs. Error analysis in\nthese settings is further complicated by the interplay of external tool outputs\nand language model reasoning, making it more challenging than traditional\nsoftware debugging. In this work, we (1) articulate the need for robust and\ndynamic evaluation methods for agentic workflow traces, (2) introduce a formal\ntaxonomy of error types encountered in agentic systems, and (3) present a set\nof 148 large human-annotated traces (TRAIL) constructed using this taxonomy and\ngrounded in established agentic benchmarks. To ensure ecological validity, we\ncurate traces from both single and multi-agent systems, focusing on real-world\napplications such as software engineering and open-world information retrieval.\nOur evaluations reveal that modern long context LLMs perform poorly at trace\ndebugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our\ndataset and code are made publicly available to support and accelerate future\nresearch in scalable evaluation for agentic workflows.",
      "tldr_zh": "该研究强调了评估 agentic workflows 产生的复杂 traces 的需求，提出了一种可扩展的方法来应对当前依赖手动分析的局限性。论文引入了 agentic 系统错误类型的正式 taxonomy，并构建了 TRAIL 数据集，包含 148 个由人类标注的 traces，聚焦于软件工程和开放世界信息检索领域。实验结果显示，现代长上下文 LLMs 在 trace 调试上表现欠佳，最佳模型 Gemini-2.5-pro 仅获得 11% 的分数；数据集和代码已公开，以支持未来 agentic workflows 的评估研究。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Dataset link: https://huggingface.co/datasets/PatronusAI/TRAIL",
      "pdf_url": "http://arxiv.org/pdf/2505.08638v1",
      "published_date": "2025-05-13 14:55:31 UTC",
      "updated_date": "2025-05-13 14:55:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:05.177155"
    },
    {
      "arxiv_id": "2505.08628v1",
      "title": "Integrating Natural Language Processing and Exercise Monitoring for Early Diagnosis of Metabolic Syndrome: A Deep Learning Approach",
      "title_zh": "整合自然语言处理与运动监测用于代谢综合征早期诊断：一种深度学习方法",
      "authors": [
        "Yichen Zhao",
        "Yuhua Wang",
        "Xi Cheng",
        "Junhao Fang",
        "Yang Yang"
      ],
      "abstract": "Metabolic syndrome (MetS) is a medication condition characterized by\nabdominal obesity, insulin resistance, hypertension and hyperlipidemia. It\nincreases the risk of majority of chronic diseases, including type 2 diabetes\nmellitus, and affects about one quarter of the global population. Therefore,\nearly detection and timely intervention for MetS are crucial. Standard\ndiagnosis for MetS components requires blood tests conducted within medical\ninstitutions. However, it is frequently underestimated, leading to unmet need\nfor care for MetS population. This study aims to use the least physiological\ndata and free texts about exercises related activities, which are obtained\neasily in daily life, to diagnosis MetS. We collected the data from 40\nvolunteers in a nursing home and used data augmentation to reduce the\nimbalance. We propose a deep learning framework for classifying MetS that\nintegrates natural language processing (NLP) and exercise monitoring. The\nresults showed that the best model reported a high positive result (AUROC=0.806\nand REC=76.3%) through 3-fold cross-validation. Feature importance analysis\nrevealed that text and minimum heart rate on a daily basis contribute the most\nin the classification of MetS. This study demonstrates the potential\napplication of data that are easily measurable in daily life for the early\ndiagnosis of MetS, which could contribute to reducing the cost of screening and\nmanagement for MetS population.",
      "tldr_zh": "本研究针对代谢综合征 (MetS)，一种涉及腹部肥胖、胰岛素抵抗、高血压和血脂异常的疾病，提出了一种整合自然语言处理 (NLP) 和运动监测的深度学习框架，以实现早期诊断。研究使用日常生活中易获取的数据（如运动相关文本和生理指标）从40名养老院志愿者处收集数据，并通过数据增强处理不平衡问题。结果显示，最佳模型在3折交叉验证中达到AUROC=0.806和REC=76.3%，特征重要性分析表明文本和每日最低心率是关键因素。该方法证明了利用日常数据进行MetS早期诊断的可行性，有助于降低筛查和管理成本。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08628v1",
      "published_date": "2025-05-13 14:48:36 UTC",
      "updated_date": "2025-05-13 14:48:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:07.525128"
    },
    {
      "arxiv_id": "2505.08622v1",
      "title": "Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models",
      "title_zh": "视觉引导解码：无梯度硬提示逆转与语言模型",
      "authors": [
        "Donghoon Kim",
        "Minji Bae",
        "Kyuhong Shim",
        "Byonghyo Shim"
      ],
      "abstract": "Text-to-image generative models like DALL-E and Stable Diffusion have\nrevolutionized visual content creation across various applications, including\nadvertising, personalized media, and design prototyping. However, crafting\neffective textual prompts to guide these models remains challenging, often\nrequiring extensive trial and error. Existing prompt inversion approaches, such\nas soft and hard prompt techniques, are not so effective due to the limited\ninterpretability and incoherent prompt generation. To address these issues, we\npropose Visually Guided Decoding (VGD), a gradient-free approach that leverages\nlarge language models (LLMs) and CLIP-based guidance to generate coherent and\nsemantically aligned prompts. In essence, VGD utilizes the robust text\ngeneration capabilities of LLMs to produce human-readable prompts. Further, by\nemploying CLIP scores to ensure alignment with user-specified visual concepts,\nVGD enhances the interpretability, generalization, and flexibility of prompt\ngeneration without the need for additional training. Our experiments\ndemonstrate that VGD outperforms existing prompt inversion techniques in\ngenerating understandable and contextually relevant prompts, facilitating more\nintuitive and controllable interactions with text-to-image models.",
      "tldr_zh": "该论文提出 Visually Guided Decoding (VGD)，一种无梯度硬提示反演方法，利用大型语言模型 (LLMs) 和 CLIP-based guidance 来生成连贯且语义对齐的文本提示，以解决文本到图像生成模型（如 DALL-E 和 Stable Diffusion）中提示创建的挑战。VGD 结合 LLMs 的文本生成能力与 CLIP 分数，确保提示的可读性和与用户视觉概念的精确对齐，同时无需额外训练，提高了方法的解释性、泛化和灵活性。实验结果表明，VGD 在生成可理解且上下文相关的提示方面优于现有技术，促进了更直观的用户交互。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08622v1",
      "published_date": "2025-05-13 14:40:22 UTC",
      "updated_date": "2025-05-13 14:40:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:10.456172"
    },
    {
      "arxiv_id": "2505.08620v1",
      "title": "Resource-Efficient Language Models: Quantization for Fast and Accessible Inference",
      "title_zh": "资源高效语言模型：量化用于快速和可访问推理",
      "authors": [
        "Tollef Emil Jørgensen"
      ],
      "abstract": "Large language models have significantly advanced natural language\nprocessing, yet their heavy resource demands pose severe challenges regarding\nhardware accessibility and energy consumption. This paper presents a focused\nand high-level review of post-training quantization (PTQ) techniques designed\nto optimize the inference efficiency of LLMs by the end-user, including details\non various quantization schemes, granularities, and trade-offs. The aim is to\nprovide a balanced overview between the theory and applications of\npost-training quantization.",
      "tldr_zh": "这篇论文审视了大型语言模型 (LLMs) 的资源需求问题，包括硬件可访问性和能源消耗的挑战。作者提供了一个高层次的回顾，聚焦于后训练量化 (PTQ) 技术，以优化 LLMs 的推理效率，涵盖各种量化方案、粒度和权衡。总体而言，该综述平衡了理论基础与实际应用，帮助用户实现更快速、可访问的模型部署。",
      "categories": [
        "cs.AI",
        "68T07",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 9 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.08620v1",
      "published_date": "2025-05-13 14:39:33 UTC",
      "updated_date": "2025-05-13 14:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:11.010458"
    },
    {
      "arxiv_id": "2505.08845v1",
      "title": "Validation of Conformal Prediction in Cervical Atypia Classification",
      "title_zh": "Conformal Prediction 在宫颈非典型分类中的验证",
      "authors": [
        "Misgina Tsighe Hagos",
        "Antti Suutala",
        "Dmitrii Bychkov",
        "Hakan Kücükel",
        "Joar von Bahr",
        "Milda Poceviciute",
        "Johan Lundin",
        "Nina Linder",
        "Claes Lundström"
      ],
      "abstract": "Deep learning based cervical cancer classification can potentially increase\naccess to screening in low-resource regions. However, deep learning models are\noften overconfident and do not reliably reflect diagnostic uncertainty.\nMoreover, they are typically optimized to generate maximum-likelihood\npredictions, which fail to convey uncertainty or ambiguity in their results.\nSuch challenges can be addressed using conformal prediction, a model-agnostic\nframework for generating prediction sets that contain likely classes for\ntrained deep-learning models. The size of these prediction sets indicates model\nuncertainty, contracting as model confidence increases. However, existing\nconformal prediction evaluation primarily focuses on whether the prediction set\nincludes or covers the true class, often overlooking the presence of extraneous\nclasses. We argue that prediction sets should be truthful and valuable to end\nusers, ensuring that the listed likely classes align with human expectations\nrather than being overly relaxed and including false positives or unlikely\nclasses. In this study, we comprehensively validate conformal prediction sets\nusing expert annotation sets collected from multiple annotators. We evaluate\nthree conformal prediction approaches applied to three deep-learning models\ntrained for cervical atypia classification. Our expert annotation-based\nanalysis reveals that conventional coverage-based evaluations overestimate\nperformance and that current conformal prediction methods often produce\nprediction sets that are not well aligned with human labels. Additionally, we\nexplore the capabilities of the conformal prediction methods in identifying\nambiguous and out-of-distribution data.",
      "tldr_zh": "这篇论文验证了 Conformal Prediction 在宫颈非典型分类（cervical atypia classification）中的应用，以解决深度学习模型的过度自信和不确定性问题。作者通过专家标注评估三种 Conformal Prediction 方法在三种深度学习模型上的性能，强调预测集应与人类期望一致，避免包含无关或错误类别。研究发现，传统基于覆盖率的评估高估了模型表现，而当前方法生成的预测集往往与人类标签不匹配。此外，论文探讨了这些方法在识别模糊数据和分布外数据（out-of-distribution data）方面的能力，为更可靠的医疗AI分类提供见解。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08845v1",
      "published_date": "2025-05-13 14:37:58 UTC",
      "updated_date": "2025-05-13 14:37:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:13.409273"
    },
    {
      "arxiv_id": "2505.08844v1",
      "title": "CellTypeAgent: Trustworthy cell type annotation with Large Language Models",
      "title_zh": "CellTypeAgent：利用大语言模型的可信细胞类型注释",
      "authors": [
        "Jiawen Chen",
        "Jianghao Zhang",
        "Huaxiu Yao",
        "Yun Li"
      ],
      "abstract": "Cell type annotation is a critical yet laborious step in single-cell RNA\nsequencing analysis. We present a trustworthy large language model (LLM)-agent,\nCellTypeAgent, which integrates LLMs with verification from relevant databases.\nCellTypeAgent achieves higher accuracy than existing methods while mitigating\nhallucinations. We evaluated CellTypeAgent across nine real datasets involving\n303 cell types from 36 tissues. This combined approach holds promise for more\nefficient and reliable cell type annotation.",
      "tldr_zh": "本文提出 CellTypeAgent，一种可信赖的基于 Large Language Models (LLMs) 的代理系统，用于单细胞 RNA sequencing 分析中的细胞类型注释。该系统通过整合 LLMs 与相关数据库的验证机制，提高注释准确率并有效减少 hallucinations。在九个真实数据集上进行评估，涵盖 303 种细胞类型和 36 种组织，CellTypeAgent 优于现有方法。这种结合方法有望提升细胞类型注释的效率和可靠性。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "68T20",
        "I.2.1"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08844v1",
      "published_date": "2025-05-13 14:34:11 UTC",
      "updated_date": "2025-05-13 14:34:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:21.283842"
    },
    {
      "arxiv_id": "2505.08599v1",
      "title": "MINIMALIST: switched-capacitor circuits for efficient in-memory computation of gated recurrent units",
      "title_zh": "MINIMALIST：开关电容电路用于门控循环单元的高效内存内计算",
      "authors": [
        "Sebastian Billaudelle",
        "Laura Kriener",
        "Filippo Moro",
        "Tristan Torchet",
        "Melika Payvand"
      ],
      "abstract": "Recurrent neural networks (RNNs) have been a long-standing candidate for\nprocessing of temporal sequence data, especially in memory-constrained systems\nthat one may find in embedded edge computing environments. Recent advances in\ntraining paradigms have now inspired new generations of efficient RNNs. We\nintroduce a streamlined and hardware-compatible architecture based on minimal\ngated recurrent units (GRUs), and an accompanying efficient mixed-signal\nhardware implementation of the model. The proposed design leverages\nswitched-capacitor circuits not only for in-memory computation (IMC), but also\nfor the gated state updates. The mixed-signal cores rely solely on commodity\ncircuits consisting of metal capacitors, transmission gates, and a clocked\ncomparator, thus greatly facilitating scaling and transfer to other technology\nnodes.\n  We benchmark the performance of our architecture on time series data,\nintroducing all constraints required for a direct mapping to the hardware\nsystem. The direct compatibility is verified in mixed-signal simulations,\nreproducing data recorded from the software-only network model.",
      "tldr_zh": "该论文提出MINIMALIST架构，利用switched-capacitor电路实现高效的in-memory computation (IMC)，针对门控循环单元(GRUs)优化RNNs在内存受限嵌入式系统中的性能。设计采用简化minimal GRUs模型，并通过混合信号硬件，包括金属电容、传输门和时钟比较器，处理门控状态更新，便于技术节点扩展。实验在时间序列数据上基准测试显示，该架构直接兼容硬件，并在混合信号模拟中验证了与软件模型的一致性。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08599v1",
      "published_date": "2025-05-13 14:13:41 UTC",
      "updated_date": "2025-05-13 14:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:23.483656"
    },
    {
      "arxiv_id": "2505.08589v1",
      "title": "MESSI: A Multi-Elevation Semantic Segmentation Image Dataset of an Urban Environment",
      "title_zh": "MESSI：城市环境的多高度语义分割图像数据集",
      "authors": [
        "Barak Pinkovich",
        "Boaz Matalon",
        "Ehud Rivlin",
        "Hector Rotstein"
      ],
      "abstract": "This paper presents a Multi-Elevation Semantic Segmentation Image (MESSI)\ndataset comprising 2525 images taken by a drone flying over dense urban\nenvironments. MESSI is unique in two main features. First, it contains images\nfrom various altitudes, allowing us to investigate the effect of depth on\nsemantic segmentation. Second, it includes images taken from several different\nurban regions (at different altitudes). This is important since the variety\ncovers the visual richness captured by a drone's 3D flight, performing\nhorizontal and vertical maneuvers. MESSI contains images annotated with\nlocation, orientation, and the camera's intrinsic parameters and can be used to\ntrain a deep neural network for semantic segmentation or other applications of\ninterest (e.g., localization, navigation, and tracking). This paper describes\nthe dataset and provides annotation details. It also explains how semantic\nsegmentation was performed using several neural network models and shows\nseveral relevant statistics. MESSI will be published in the public domain to\nserve as an evaluation benchmark for semantic segmentation using images\ncaptured by a drone or similar vehicle flying over a dense urban environment.",
      "tldr_zh": "本研究引入了MESSI数据集，该数据集包含2525张由无人机在密集城市环境中拍摄的多高度图像，用于语义分割任务。MESSI的独特之处在于图像覆盖不同海拔和城市区域，便于分析高度对语义分割的影响，并附带位置、方向和相机参数的标注，可支持深度神经网络的训练及应用如定位、导航和跟踪。论文详细描述了数据集的标注过程、实验统计数据，并使用多种神经网络模型进行了语义分割测试；该数据集将公开发布，作为无人机图像语义分割的基准基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08589v1",
      "published_date": "2025-05-13 14:01:07 UTC",
      "updated_date": "2025-05-13 14:01:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:25.841075"
    },
    {
      "arxiv_id": "2505.08588v1",
      "title": "Small but Significant: On the Promise of Small Language Models for Accessible AIED",
      "title_zh": "小而显著：关于小语言模型用于可访问 AIED 的潜力",
      "authors": [
        "Yumou Wei",
        "Paulo Carvalho",
        "John Stamper"
      ],
      "abstract": "GPT has become nearly synonymous with large language models (LLMs), an\nincreasingly popular term in AIED proceedings. A simple keyword-based search\nreveals that 61% of the 76 long and short papers presented at AIED 2024\ndescribe novel solutions using LLMs to address some of the long-standing\nchallenges in education, and 43% specifically mention GPT. Although LLMs\npioneered by GPT create exciting opportunities to strengthen the impact of AI\non education, we argue that the field's predominant focus on GPT and other\nresource-intensive LLMs (with more than 10B parameters) risks neglecting the\npotential impact that small language models (SLMs) can make in providing\nresource-constrained institutions with equitable and affordable access to\nhigh-quality AI tools. Supported by positive results on knowledge component\n(KC) discovery, a critical challenge in AIED, we demonstrate that SLMs such as\nPhi-2 can produce an effective solution without elaborate prompting strategies.\nHence, we call for more attention to developing SLM-based AIED approaches.",
      "tldr_zh": "该论文指出，AIED 领域过度依赖大型语言模型 (LLMs) 如 GPT，导致资源密集型工具（如超过 10B 参数的模型）可能加剧不平等，而忽略了小语言模型 (SLMs) 的潜力。作者通过实验展示，SLMs 如 Phi-2 在知识组件 (KC) 发现任务中能提供有效解决方案，无需复杂的提示策略，从而为资源有限的机构提供公平且负担得起的 AI 工具。最终，论文呼吁更多开发基于 SLM 的 AIED 方法，以提升教育领域的可访问性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "This vision paper advocates using small language models (e.g., Phi-2)\n  in AI for education (AIED)",
      "pdf_url": "http://arxiv.org/pdf/2505.08588v1",
      "published_date": "2025-05-13 13:58:29 UTC",
      "updated_date": "2025-05-13 13:58:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:26.877634"
    },
    {
      "arxiv_id": "2505.08552v1",
      "title": "DFA-CON: A Contrastive Learning Approach for Detecting Copyright Infringement in DeepFake Art",
      "title_zh": "DFA-CON：一种用于检测 DeepFake 艺术中版权侵犯的对比学习方法",
      "authors": [
        "Haroon Wahab",
        "Hassan Ugail",
        "Irfan Mehmood"
      ],
      "abstract": "Recent proliferation of generative AI tools for visual content\ncreation-particularly in the context of visual artworks-has raised serious\nconcerns about copyright infringement and forgery. The large-scale datasets\nused to train these models often contain a mixture of copyrighted and\nnon-copyrighted artworks. Given the tendency of generative models to memorize\ntraining patterns, they are susceptible to varying degrees of copyright\nviolation. Building on the recently proposed DeepfakeArt Challenge benchmark,\nthis work introduces DFA-CON, a contrastive learning framework designed to\ndetect copyright-infringing or forged AI-generated art. DFA-CON learns a\ndiscriminative representation space, posing affinity among original artworks\nand their forged counterparts within a contrastive learning framework. The\nmodel is trained across multiple attack types, including inpainting, style\ntransfer, adversarial perturbation, and cutmix. Evaluation results demonstrate\nrobust detection performance across most attack types, outperforming recent\npretrained foundation models. Code and model checkpoints will be released\npublicly upon acceptance.",
      "tldr_zh": "这篇论文提出了 DFA-CON，一种基于 Contrastive Learning 的框架，用于检测 DeepFake Art 中的版权侵权问题。框架通过学习原创艺术品与其伪造版本之间的区分性表示空间，并在多种攻击类型（如 Inpainting、Style Transfer、Adversarial Perturbation 和 CutMix）上进行训练。实验结果显示，DFA-CON 在大多数攻击类型上表现出色，超过了现有的预训练基础模型。代码和模型检查点将在论文接受后公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08552v1",
      "published_date": "2025-05-13 13:23:52 UTC",
      "updated_date": "2025-05-13 13:23:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:29.404068"
    },
    {
      "arxiv_id": "2505.08548v1",
      "title": "From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation",
      "title_zh": "从感知到行动：桥接推理与决策用于机器人操控",
      "authors": [
        "Yifu Yuan",
        "Haiqin Cui",
        "Yibin Chen",
        "Zibin Dong",
        "Fei Ni",
        "Longxin Kou",
        "Jinyi Liu",
        "Pengyi Li",
        "Yan Zheng",
        "Jianye Hao"
      ],
      "abstract": "Achieving generalization in robotic manipulation remains a critical\nchallenge, particularly for unseen scenarios and novel tasks. Current\nVision-Language-Action (VLA) models, while building on top of general\nVision-Language Models (VLMs), still fall short of achieving robust zero-shot\nperformance due to the scarcity and heterogeneity prevalent in embodied\ndatasets. To address these limitations, we propose FSD (From Seeing to Doing),\na novel vision-language model that generates intermediate representations\nthrough spatial relationship reasoning, providing fine-grained guidance for\nrobotic manipulation. Our approach combines a hierarchical data pipeline for\ntraining with a self-consistency mechanism that aligns spatial coordinates with\nvisual signals. Through extensive experiments, we comprehensively validated\nFSD's capabilities in both \"seeing\" and \"doing,\" achieving outstanding\nperformance across 8 benchmarks for general spatial reasoning and embodied\nreference abilities, as well as on our proposed more challenging benchmark\nVABench. We also verified zero-shot capabilities in robot manipulation,\ndemonstrating significant performance improvements over baseline methods in\nboth SimplerEnv and real robot settings. Experimental results show that FSD\nachieves 54.1% success rate in SimplerEnv and 72% success rate across 8\nreal-world tasks, outperforming the strongest baseline by 30%.",
      "tldr_zh": "这篇论文针对机器人操作中的泛化挑战，提出了 FSD（From Seeing to Doing）模型，通过空间关系推理生成中间表示，以提供细粒度的视觉-语言-动作（VLA）指导。FSD 结合分层数据管道（hierarchical data pipeline）和自一致性机制（self-consistency mechanism），将空间坐标与视觉信号对齐，从而提升模型在零样本场景下的鲁棒性。实验结果显示，FSD 在 8 个基准测试和 VABench 上表现出色，并在 SimplerEnv 和真实机器人环境中实现 54.1% 和 72% 的成功率，比最强基线方法提高了 30%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Early version",
      "pdf_url": "http://arxiv.org/pdf/2505.08548v1",
      "published_date": "2025-05-13 13:20:46 UTC",
      "updated_date": "2025-05-13 13:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:32.335848"
    },
    {
      "arxiv_id": "2505.08542v1",
      "title": "Guiding LLM-based Smart Contract Generation with Finite State Machine",
      "title_zh": "利用有限状态机指导基于LLM的智能合约生成",
      "authors": [
        "Hao Luo",
        "Yuhao Lin",
        "Xiao Yan",
        "Xintong Hu",
        "Yuxiang Wang",
        "Qiming Zeng",
        "Hao Wang",
        "Jiawei Jiang"
      ],
      "abstract": "Smart contract is a kind of self-executing code based on blockchain\ntechnology with a wide range of application scenarios, but the traditional\ngeneration method relies on manual coding and expert auditing, which has a high\nthreshold and low efficiency. Although Large Language Models (LLMs) show great\npotential in programming tasks, they still face challenges in smart contract\ngeneration w.r.t. effectiveness and security. To solve these problems, we\npropose FSM-SCG, a smart contract generation framework based on finite state\nmachine (FSM) and LLMs, which significantly improves the quality of the\ngenerated code by abstracting user requirements to generate FSM, guiding LLMs\nto generate smart contracts, and iteratively optimizing the code with the\nfeedback of compilation and security checks. The experimental results show that\nFSM-SCG significantly improves the quality of smart contract generation.\nCompared to the best baseline, FSM-SCG improves the compilation success rate of\ngenerated smart contract code by at most 48%, and reduces the average\nvulnerability risk score by approximately 68%.",
      "tldr_zh": "该研究针对智能合约（smart contract）生成面临的效率和安全挑战，提出了一种基于有限状态机（FSM）和大语言模型（LLMs）的框架 FSM-SCG。通过将用户需求抽象为 FSM 引导 LLMs 生成代码，并结合编译和安全检查的反馈进行迭代优化，从而显著提升生成代码的质量。与最佳基线相比，FSM-SCG 将编译成功率提高最多 48%，并将平均漏洞风险分数降低约 68%。这项工作为高效、安全的智能合约开发提供了新方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08542v1",
      "published_date": "2025-05-13 13:13:26 UTC",
      "updated_date": "2025-05-13 13:13:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:33.427355"
    },
    {
      "arxiv_id": "2505.08532v1",
      "title": "The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large Language Models Unmask Fake News",
      "title_zh": "通过辩论，真相会变得更清晰！ 利用大型语言模型的多智能体系统揭露假新闻",
      "authors": [
        "Yuhan Liu",
        "Yuxuan Liu",
        "Xiaoqing Zhang",
        "Xiuying Chen",
        "Rui Yan"
      ],
      "abstract": "In today's digital environment, the rapid propagation of fake news via social\nnetworks poses significant social challenges. Most existing detection methods\neither employ traditional classification models, which suffer from low\ninterpretability and limited generalization capabilities, or craft specific\nprompts for large language models (LLMs) to produce explanations and results\ndirectly, failing to leverage LLMs' reasoning abilities fully. Inspired by the\nsaying that \"truth becomes clearer through debate,\" our study introduces a\nnovel multi-agent system with LLMs named TruEDebate (TED) to enhance the\ninterpretability and effectiveness of fake news detection. TED employs a\nrigorous debate process inspired by formal debate settings. Central to our\napproach are two innovative components: the DebateFlow Agents and the\nInsightFlow Agents. The DebateFlow Agents organize agents into two teams, where\none supports and the other challenges the truth of the news. These agents\nengage in opening statements, cross-examination, rebuttal, and closing\nstatements, simulating a rigorous debate process akin to human discourse\nanalysis, allowing for a thorough evaluation of news content. Concurrently, the\nInsightFlow Agents consist of two specialized sub-agents: the Synthesis Agent\nand the Analysis Agent. The Synthesis Agent summarizes the debates and provides\nan overarching viewpoint, ensuring a coherent and comprehensive evaluation. The\nAnalysis Agent, which includes a role-aware encoder and a debate graph,\nintegrates role embeddings and models the interactions between debate roles and\narguments using an attention mechanism, providing the final judgment.",
      "tldr_zh": "本研究提出了一种名为 TruEDebate (TED) 的多智能体系统，利用大型语言模型 (LLMs) 通过辩论过程提升假新闻检测的解释性和有效性，以应对社交网络上假新闻的快速传播问题。系统包括 DebateFlow Agents，将代理分成支持和挑战两队，进行开场陈述、交叉审问、反驳和结尾陈述，模拟人类辩论以彻底评估新闻内容；以及 InsightFlow Agents，由 Synthesis Agent（总结辩论并提供整体观点）和 Analysis Agent（使用角色感知编码器和辩论图整合互动）组成，提供最终判断。相比传统分类模型或简单提示方法，TED 更充分利用 LLMs 的推理能力，显著提高了检测的准确性和可解释性。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "SIGIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08532v1",
      "published_date": "2025-05-13 13:03:20 UTC",
      "updated_date": "2025-05-13 13:03:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:36.208953"
    },
    {
      "arxiv_id": "2505.08529v1",
      "title": "ExEBench: Benchmarking Foundation Models on Extreme Earth Events",
      "title_zh": "ExEBench：在极端地球事件上对基础模型进行基准测试",
      "authors": [
        "Shan Zhao",
        "Zhitong Xiong",
        "Jie Zhao",
        "Xiao Xiang Zhu"
      ],
      "abstract": "Our planet is facing increasingly frequent extreme events, which pose major\nrisks to human lives and ecosystems. Recent advances in machine learning (ML),\nespecially with foundation models (FMs) trained on extensive datasets, excel in\nextracting features and show promise in disaster management. Nevertheless,\nthese models often inherit biases from training data, challenging their\nperformance over extreme values. To explore the reliability of FM in the\ncontext of extreme events, we introduce \\textbf{ExE}Bench (\\textbf{Ex}treme\n\\textbf{E}arth Benchmark), a collection of seven extreme event categories\nacross floods, wildfires, storms, tropical cyclones, extreme precipitation,\nheatwaves, and cold waves. The dataset features global coverage, varying data\nvolumes, and diverse data sources with different spatial, temporal, and\nspectral characteristics. To broaden the real-world impact of FMs, we include\nmultiple challenging ML tasks that are closely aligned with operational needs\nin extreme events detection, monitoring, and forecasting. ExEBench aims to (1)\nassess FM generalizability across diverse, high-impact tasks and domains, (2)\npromote the development of novel ML methods that benefit disaster management,\nand (3) offer a platform for analyzing the interactions and cascading effects\nof extreme events to advance our understanding of Earth system, especially\nunder the climate change expected in the decades to come. The dataset and code\nare public https://github.com/zhaoshan2/EarthExtreme-Bench.",
      "tldr_zh": "本研究引入了ExEBench，这是一个针对极端地球事件的基准测试平台，用于评估Foundation Models (FMs)在处理floods、wildfires、storms、tropical cyclones、extreme precipitation、heatwaves和cold waves等七类事件时的可靠性和泛化能力。数据集涵盖全球范围、多种数据量和多样数据来源，包括不同的空间、时间和光谱特性，并包含与灾害检测、监测和预测相关的实际ML任务。ExEBench的目的是评估FMs在高影响任务中的性能、推动新型ML方法在灾害管理中的应用，以及分析极端事件的互动和级联效应，以应对未来气候变化挑战；数据集和代码已公开于https://github.com/zhaoshan2/EarthExtreme-Bench。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08529v1",
      "published_date": "2025-05-13 13:02:04 UTC",
      "updated_date": "2025-05-13 13:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:37.820109"
    },
    {
      "arxiv_id": "2505.08528v1",
      "title": "GradMix: Gradient-based Selective Mixup for Robust Data Augmentation in Class-Incremental Learning",
      "title_zh": "GradMix：基于梯度的选择性 Mixup 用于类别增量学习中的鲁棒数据增强",
      "authors": [
        "Minsu Kim",
        "Seong-Hyeon Hwang",
        "Steven Euijong Whang"
      ],
      "abstract": "In the context of continual learning, acquiring new knowledge while\nmaintaining previous knowledge presents a significant challenge. Existing\nmethods often use experience replay techniques that store a small portion of\nprevious task data for training. In experience replay approaches, data\naugmentation has emerged as a promising strategy to further improve the model\nperformance by mixing limited previous task data with sufficient current task\ndata. However, we theoretically and empirically analyze that training with\nmixed samples from random sample pairs may harm the knowledge of previous tasks\nand cause greater catastrophic forgetting. We then propose GradMix, a robust\ndata augmentation method specifically designed for mitigating catastrophic\nforgetting in class-incremental learning. GradMix performs gradient-based\nselective mixup using a class-based criterion that mixes only samples from\nhelpful class pairs and not from detrimental class pairs for reducing\ncatastrophic forgetting. Our experiments on various real datasets show that\nGradMix outperforms data augmentation baselines in accuracy by minimizing the\nforgetting of previous knowledge.",
      "tldr_zh": "在持续学习（continual learning）中，类增量学习（class-incremental learning）面临获取新知识的同时避免灾难性遗忘（catastrophic forgetting）的挑战，现有经验回放（experience replay）方法虽使用数据增强（data augmentation）混合旧和新数据，但随机混合样本可能加剧遗忘问题。研究提出 GradMix，一种基于梯度的选择性混合（gradient-based selective mixup）方法，通过类-based criterion 只混合有益的类对，从而减少对旧知识的干扰。实验在各种真实数据集上显示，GradMix 比数据增强基线方法在准确率上表现出色，有效最小化了灾难性遗忘。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08528v1",
      "published_date": "2025-05-13 13:01:38 UTC",
      "updated_date": "2025-05-13 13:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:39.694364"
    },
    {
      "arxiv_id": "2505.08522v1",
      "title": "On the Complexity and Properties of Preferential Propositional Dependence Logic",
      "title_zh": "关于优先命题依赖逻辑的复杂性和属性",
      "authors": [
        "Kai Sauerwald",
        "Arne Meier",
        "Juha Kontinen"
      ],
      "abstract": "This paper considers the complexity and properties of KLM-style preferential\nreasoning in the setting of propositional logic with team semantics and\ndependence atoms, also known as propositional dependence logic. Preferential\nteam-based reasoning is shown to be cumulative, yet violates System~P. We give\nintuitive conditions that fully characterise those cases where preferential\npropositional dependence logic satisfies System~P. We show that these\ncharacterisations do, surprisingly, not carry over to preferential team-based\npropositional logic. Furthermore, we show how classical entailment and\ndependence logic entailment can be expressed in terms of non-trivial\npreferential models. Finally, we present the complexity of preferential\nteam-based reasoning for two natural representations. This includes novel\ncomplexity results for classical (non-team-based) preferential reasoning.",
      "tldr_zh": "本文探讨了在命题逻辑中，使用团队语义（team semantics）和依赖原子（dependence atoms）的 KLM-style 优先推理的复杂性和属性。研究发现，这种优先团队推理是累积的，但违反了 System P，并提供了直观的条件来完全表征优先命题依赖逻辑满足 System P 的情况，这些条件不适用于优先团队命题逻辑。主要贡献包括展示了经典蕴涵和依赖逻辑蕴涵如何通过非平凡的优先模型表达，并分析了两种自然表示下优先团队推理的复杂度，包括经典优先推理的新复杂度结果。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "03B70, 03B62",
        "I.2.3; F.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08522v1",
      "published_date": "2025-05-13 12:54:59 UTC",
      "updated_date": "2025-05-13 12:54:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:47.982723"
    },
    {
      "arxiv_id": "2505.08516v1",
      "title": "Learning Advanced Self-Attention for Linear Transformers in the Singular Value Domain",
      "title_zh": "在奇异值域中学习先进的自注意力机制用于线性Transformer",
      "authors": [
        "Hyowon Wi",
        "Jeongwhan Choi",
        "Noseong Park"
      ],
      "abstract": "Transformers have demonstrated remarkable performance across diverse domains.\nThe key component of Transformers is self-attention, which learns the\nrelationship between any two tokens in the input sequence. Recent studies have\nrevealed that the self-attention can be understood as a normalized adjacency\nmatrix of a graph. Notably, from the perspective of graph signal processing\n(GSP), the self-attention can be equivalently defined as a simple graph filter,\napplying GSP using the value vector as the signal. However, the self-attention\nis a graph filter defined with only the first order of the polynomial matrix,\nand acts as a low-pass filter preventing the effective leverage of various\nfrequency information. Consequently, existing self-attention mechanisms are\ndesigned in a rather simplified manner. Therefore, we propose a novel method,\ncalled \\underline{\\textbf{A}}ttentive \\underline{\\textbf{G}}raph\n\\underline{\\textbf{F}}ilter (AGF), interpreting the self-attention as learning\nthe graph filter in the singular value domain from the perspective of graph\nsignal processing for directed graphs with the linear complexity w.r.t. the\ninput length $n$, i.e., $\\mathcal{O}(nd^2)$. In our experiments, we demonstrate\nthat AGF achieves state-of-the-art performance on various tasks, including Long\nRange Arena benchmark and time series classification.",
      "tldr_zh": "本研究探讨了 Transformers 中 self-attention 的局限性，即其作为一阶多项式图滤波器，仅充当低通滤波器，无法有效利用各种频率信息。作者提出了一种新方法 AGF（Attentive Graph Filter），从图信号处理（GSP）的视角，将 self-attention 解释为在奇异值域学习图滤波器，并针对有向图实现线性复杂度（O(nd^2)）。实验结果显示，AGF 在 Long Range Arena benchmark 和时间序列分类任务上达到了 state-of-the-art 性能，显著提升了模型的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "IJCAI25 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2505.08516v1",
      "published_date": "2025-05-13 12:48:04 UTC",
      "updated_date": "2025-05-13 12:48:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:48.933586"
    },
    {
      "arxiv_id": "2505.08508v1",
      "title": "TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System to Streamline Patient-to-Trial Matching",
      "title_zh": "TrialMatchAI: 端到端 AI 驱动的临床试验推荐系统，用于简化患者到试验匹配",
      "authors": [
        "Majd Abdallah",
        "Sigve Nakken",
        "Mariska Bierkens",
        "Johanna Galvis",
        "Alexis Groppi",
        "Slim Karkar",
        "Lana Meiqari",
        "Maria Alexandra Rujano",
        "Steve Canham",
        "Rodrigo Dienstmann",
        "Remond Fijneman",
        "Eivind Hovig",
        "Gerrit Meijer",
        "Macha Nikolski"
      ],
      "abstract": "Patient recruitment remains a major bottleneck in clinical trials, calling\nfor scalable and automated solutions. We present TrialMatchAI, an AI-powered\nrecommendation system that automates patient-to-trial matching by processing\nheterogeneous clinical data, including structured records and unstructured\nphysician notes. Built on fine-tuned, open-source large language models (LLMs)\nwithin a retrieval-augmented generation framework, TrialMatchAI ensures\ntransparency and reproducibility and maintains a lightweight deployment\nfootprint suitable for clinical environments. The system normalizes biomedical\nentities, retrieves relevant trials using a hybrid search strategy combining\nlexical and semantic similarity, re-ranks results, and performs criterion-level\neligibility assessments using medical Chain-of-Thought reasoning. This pipeline\ndelivers explainable outputs with traceable decision rationales. In real-world\nvalidation, 92 percent of oncology patients had at least one relevant trial\nretrieved within the top 20 recommendations. Evaluation across synthetic and\nreal clinical datasets confirmed state-of-the-art performance, with expert\nassessment validating over 90 percent accuracy in criterion-level eligibility\nclassification, particularly excelling in biomarker-driven matches. Designed\nfor modularity and privacy, TrialMatchAI supports Phenopackets-standardized\ndata, enables secure local deployment, and allows seamless replacement of LLM\ncomponents as more advanced models emerge. By enhancing efficiency and\ninterpretability and offering lightweight, open-source deployment, TrialMatchAI\nprovides a scalable solution for AI-driven clinical trial matching in precision\nmedicine.",
      "tldr_zh": "该研究介绍了 TrialMatchAI，一种端到端的 AI 驱动临床试验推荐系统，旨在通过处理异构临床数据（如结构化记录和非结构化医生笔记）来自动化患者与试验匹配。系统基于 fine-tuned 的开源 LLMs 和检索增强生成框架 (RAG)，采用混合搜索策略（结合词汇和语义相似性）进行试验检索，并使用医疗 Chain-of-Thought 推理进行资格评估，提供可解释的决策依据。在真实世界验证中，92% 的肿瘤患者在 top 20 推荐中至少有一个相关试验，且资格分类准确率超过 90%，特别是在生物标记驱动匹配中表现出色。作为一个模块化、注重隐私的开源解决方案，TrialMatchAI 支持 Phenopackets 标准化数据和本地安全部署，提升了临床试验的效率和可扩展性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08508v1",
      "published_date": "2025-05-13 12:39:06 UTC",
      "updated_date": "2025-05-13 12:39:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:54.050549"
    },
    {
      "arxiv_id": "2505.08498v1",
      "title": "LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using Large Language Models",
      "title_zh": "LCES：通过成对比较使用大语言模型的零样本自动作文评分",
      "authors": [
        "Takumi Shibata",
        "Yuichi Miyamura"
      ],
      "abstract": "Recent advances in large language models (LLMs) have enabled zero-shot\nautomated essay scoring (AES), providing a promising way to reduce the cost and\neffort of essay scoring in comparison with manual grading. However, most\nexisting zero-shot approaches rely on LLMs to directly generate absolute\nscores, which often diverge from human evaluations owing to model biases and\ninconsistent scoring. To address these limitations, we propose LLM-based\nComparative Essay Scoring (LCES), a method that formulates AES as a pairwise\ncomparison task. Specifically, we instruct LLMs to judge which of two essays is\nbetter, collect many such comparisons, and convert them into continuous scores.\nConsidering that the number of possible comparisons grows quadratically with\nthe number of essays, we improve scalability by employing RankNet to\nefficiently transform LLM preferences into scalar scores. Experiments using AES\nbenchmark datasets show that LCES outperforms conventional zero-shot methods in\naccuracy while maintaining computational efficiency. Moreover, LCES is robust\nacross different LLM backbones, highlighting its applicability to real-world\nzero-shot AES.",
      "tldr_zh": "该研究提出LCES，一种基于大型语言模型(LLM)的零-shot自动作文评分方法，通过将评分转化为成对比较任务来解决现有方法的偏差和不一致问题。具体而言，LCES指导LLM判断两篇作文孰优，收集比较结果并使用RankNet高效转换为连续分数，从而提高可扩展性。实验在AES基准数据集上显示，LCES在准确性上优于传统零-shot方法，同时保持计算效率，并展示出在不同LLM基础上的鲁棒性，适用于实际场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08498v1",
      "published_date": "2025-05-13 12:26:16 UTC",
      "updated_date": "2025-05-13 12:26:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:52.871012"
    },
    {
      "arxiv_id": "2505.08492v1",
      "title": "Achieving Scalable Robot Autonomy via neurosymbolic planning using lightweight local LLM",
      "title_zh": "通过使用轻量级本地 LLM 的神经符号规划实现可扩展的机器人自治",
      "authors": [
        "Nicholas Attolino",
        "Alessio Capitanelli",
        "Fulvio Mastrogiovanni"
      ],
      "abstract": "PDDL-based symbolic task planning remains pivotal for robot autonomy yet\nstruggles with dynamic human-robot collaboration due to scalability,\nre-planning demands, and delayed plan availability. Although a few\nneurosymbolic frameworks have previously leveraged LLMs such as GPT-3 to\naddress these challenges, reliance on closed-source, remote models with limited\ncontext introduced critical constraints: third-party dependency, inconsistent\nresponse times, restricted plan length and complexity, and multi-domain\nscalability issues. We present Gideon, a novel framework that enables the\ntransition to modern, smaller, local LLMs with extended context length. Gideon\nintegrates a novel problem generator to systematically generate large-scale\ndatasets of realistic domain-problem-plan tuples for any domain, and adapts\nneurosymbolic planning for local LLMs, enabling on-device execution and\nextended context for multi-domain support. Preliminary experiments in\nsingle-domain scenarios performed on Qwen-2.5 1.5B and trained on 8k-32k\nsamples, demonstrate a valid plan percentage of 66.1% (32k model) and show that\nthe figure can be further scaled through additional data. Multi-domain tests on\n16k samples yield an even higher 70.6% planning validity rate, proving\nextensibility across domains and signaling that data variety can have a\npositive effect on learning efficiency. Although long-horizon planning and\nreduced model size make Gideon training much less efficient than baseline\nmodels based on larger LLMs, the results are still significant considering that\nthe trained model is about 120x smaller than baseline and that significant\nadvantages can be achieved in inference efficiency, scalability, and\nmulti-domain adaptability, all critical factors in human-robot collaboration.\nTraining inefficiency can be mitigated by Gideon's streamlined data generation\npipeline.",
      "tldr_zh": "该论文解决了PDDL-based symbolic task planning在动态人机协作中的可扩展性、再规划需求和延迟问题，提出Gideon框架，使用轻量级本地LLM（如Qwen-2.5 1.5B）实现神经符号规划(neurosymbolic planning)。Gideon整合了一个新颖的问题生成器，系统生成大规模现实数据集，支持本地执行、扩展上下文和多域适应。实验结果显示，在单域场景中训练8k-32k样本后，有效计划百分比达66.1%（32k模型），多域测试中达70.6%，证明数据多样性提升了学习效率。尽管训练效率较低，但Gideon的模型比基线小120倍，在推理效率和可扩展性上显著优势，可通过优化数据生成管道缓解。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "I.2.6; I.2.8; I.2.9"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 3 figures, 4 tables, accepted at IAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08492v1",
      "published_date": "2025-05-13 12:22:38 UTC",
      "updated_date": "2025-05-13 12:22:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:59.708011"
    },
    {
      "arxiv_id": "2505.08487v1",
      "title": "An adaptive sampling algorithm for data-generation to build a data-manifold for physical problem surrogate modeling",
      "title_zh": "一种用于数据生成的自适应采样算法，以构建物理问题代理建模的数据流形",
      "authors": [
        "Chetra Mang",
        "Axel TahmasebiMoradi",
        "David Danan",
        "Mouadh Yagoubi"
      ],
      "abstract": "Physical models classically involved Partial Differential equations (PDE) and\ndepending of their underlying complexity and the level of accuracy required,\nand known to be computationally expensive to numerically solve them. Thus, an\nidea would be to create a surrogate model relying on data generated by such\nsolver. However, training such a model on an imbalanced data have been shown to\nbe a very difficult task. Indeed, if the distribution of input leads to a poor\nresponse manifold representation, the model may not learn well and\nconsequently, it may not predict the outcome with acceptable accuracy. In this\nwork, we present an Adaptive Sampling Algorithm for Data Generation (ASADG)\ninvolving a physical model. As the initial input data may not accurately\nrepresent the response manifold in higher dimension, this algorithm iteratively\nadds input data into it. At each step the barycenter of each simplicial\ncomplex, that the manifold is discretized into, is added as new input data, if\na certain threshold is satisfied. We demonstrate the efficiency of the data\nsampling algorithm in comparison with LHS method for generating more\nrepresentative input data. To do so, we focus on the construction of a harmonic\ntransport problem metamodel by generating data through a classical solver. By\nusing such algorithm, it is possible to generate the same number of input data\nas LHS while providing a better representation of the response manifold.",
      "tldr_zh": "这篇论文针对物理问题代理建模（surrogate modeling）提出了一种自适应采样算法 ASADG，用于生成更具代表性的数据流形（data-manifold），以解决偏微分方程（PDE）模型计算开销大且数据不平衡导致训练困难的问题。ASADG 通过迭代过程，在每个步骤添加单纯复形（simplicial complex）的重心作为新输入数据，前提是满足特定阈值，从而改善响应流形的表示。相比于 LHS 方法，该算法在构建谐波传输问题元模型时，能以相同数据量提供更准确的流形表示，实验证明其效率更高。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08487v1",
      "published_date": "2025-05-13 12:17:10 UTC",
      "updated_date": "2025-05-13 12:17:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:58.670311"
    },
    {
      "arxiv_id": "2505.09651v1",
      "title": "Unlocking Location Intelligence: A Survey from Deep Learning to The LLM Era",
      "title_zh": "开启位置智能：从深度学习到大语言模型时代的综述",
      "authors": [
        "Xixuan Hao",
        "Yutian Jiang",
        "Xingchen Zou",
        "Jiabo Liu",
        "Yifang Yin",
        "Yuxuan Liang"
      ],
      "abstract": "Location Intelligence (LI), the science of transforming location-centric\ngeospatial data into actionable knowledge, has become a cornerstone of modern\nspatial decision-making. The rapid evolution of Geospatial Representation\nLearning is fundamentally reshaping LI development through two successive\ntechnological revolutions: the deep learning breakthrough and the emerging\nlarge language model (LLM) paradigm. While deep neural networks (DNNs) have\ndemonstrated remarkable success in automated feature extraction from structured\ngeospatial data (e.g., satellite imagery, GPS trajectories), the recent\nintegration of LLMs introduces transformative capabilities for cross-modal\ngeospatial reasoning and unstructured geo-textual data processing. This survey\npresents a comprehensive review of geospatial representation learning across\nboth technological eras, organizing them into a structured taxonomy based on\nthe complete pipeline comprising: (1) data perspective, (2) methodological\nperspective and (3) application perspective. We also highlight current\nadvancements, discuss existing limitations, and propose potential future\nresearch directions in the LLM era. This work offers a thorough exploration of\nthe field and providing a roadmap for further innovation in LI. The summary of\nthe up-to-date paper list can be found in\nhttps://github.com/CityMind-Lab/Awesome-Location-Intelligence and will undergo\ncontinuous updates.",
      "tldr_zh": "这篇调查论文探讨了Location Intelligence (LI)，即将位置中心地理空间数据转化为可行动知识的核心科学，并审视了Geospatial Representation Learning从Deep Learning到Large Language Model (LLM)时代的发展历程。论文将这一领域组织成一个结构化分类框架，包括数据视角、方法视角和应用视角，强调Deep Neural Networks (DNNs)在处理结构化数据（如卫星图像和GPS轨迹）方面的成功，以及LLM在跨模态地理空间推理和非结构化geo-textual数据处理上的变革性潜力。最终，该工作总结了当前进展、现有局限性，并提出LLM时代的未来研究方向，提供了一个全面的LI创新路线图。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09651v1",
      "published_date": "2025-05-13 12:16:26 UTC",
      "updated_date": "2025-05-13 12:16:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:45:59.899035"
    },
    {
      "arxiv_id": "2505.08485v1",
      "title": "BAT: Benchmark for Auto-bidding Task",
      "title_zh": "BAT：自动竞价任务基准",
      "authors": [
        "Alexandra Khirianova",
        "Ekaterina Solodneva",
        "Andrey Pudovikov",
        "Sergey Osokin",
        "Egor Samosvat",
        "Yuriy Dorn",
        "Alexander Ledovsky",
        "Yana Zenkova"
      ],
      "abstract": "The optimization of bidding strategies for online advertising slot auctions\npresents a critical challenge across numerous digital marketplaces. A\nsignificant obstacle to the development, evaluation, and refinement of\nreal-time autobidding algorithms is the scarcity of comprehensive datasets and\nstandardized benchmarks.\n  To address this deficiency, we present an auction benchmark encompassing the\ntwo most prevalent auction formats. We implement a series of robust baselines\non a novel dataset, addressing the most salient Real-Time Bidding (RTB) problem\ndomains: budget pacing uniformity and Cost Per Click (CPC) constraint\noptimization. This benchmark provides a user-friendly and intuitive framework\nfor researchers and practitioners to develop and refine innovative autobidding\nalgorithms, thereby facilitating advancements in the field of programmatic\nadvertising. The implementation and additional resources can be accessed at the\nfollowing repository (https://github.com/avito-tech/bat-autobidding-benchmark,\nhttps://doi.org/10.5281/zenodo.14794182).",
      "tldr_zh": "该论文提出 BAT 基准，用于评估自动出价任务，旨在解决在线广告竞拍中出价策略优化的关键挑战，特别是缺乏全面数据集和标准化基准的问题。基准涵盖两种常见拍卖格式，并基于一个新数据集实现了稳健的基线模型，针对 Real-Time Bidding (RTB) 领域的预算 pacing uniformity 和 Cost Per Click (CPC) 约束优化。该框架提供了一个用户友好的平台，帮助研究者和从业者开发和完善创新的自动出价算法，从而推动程序化广告领域的进步。资源可通过 GitHub 仓库和 DOI 访问（https://github.com/avito-tech/bat-autobidding-benchmark）。",
      "categories": [
        "cs.AI",
        "stat.ML",
        "91B26"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 10 figures, WWW 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2505.08485v1",
      "published_date": "2025-05-13 12:12:34 UTC",
      "updated_date": "2025-05-13 12:12:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:02.170634"
    },
    {
      "arxiv_id": "2505.08474v1",
      "title": "Distributed Quantum Neural Networks on Distributed Photonic Quantum Computing",
      "title_zh": "分布式量子神经网络在分布式光子量子计算上",
      "authors": [
        "Kuan-Cheng Chen",
        "Chen-Yu Liu",
        "Yu Shang",
        "Felix Burt",
        "Kin K. Leung"
      ],
      "abstract": "We introduce a distributed quantum-classical framework that synergizes\nphotonic quantum neural networks (QNNs) with matrix-product-state (MPS) mapping\nto achieve parameter-efficient training of classical neural networks. By\nleveraging universal linear-optical decompositions of $M$-mode interferometers\nand photon-counting measurement statistics, our architecture generates neural\nparameters through a hybrid quantum-classical workflow: photonic QNNs with\n$M(M+1)/2$ trainable parameters produce high-dimensional probability\ndistributions that are mapped to classical network weights via an MPS model\nwith bond dimension $\\chi$. Empirical validation on MNIST classification\ndemonstrates that photonic QT achieves an accuracy of $95.50\\% \\pm 0.84\\%$\nusing 3,292 parameters ($\\chi = 10$), compared to $96.89\\% \\pm 0.31\\%$ for\nclassical baselines with 6,690 parameters. Moreover, a ten-fold compression\nratio is achieved at $\\chi = 4$, with a relative accuracy loss of less than\n$3\\%$. The framework outperforms classical compression techniques (weight\nsharing/pruning) by 6--12\\% absolute accuracy while eliminating quantum\nhardware requirements during inference through classical deployment of\ncompressed parameters. Simulations incorporating realistic photonic noise\ndemonstrate the framework's robustness to near-term hardware imperfections.\nAblation studies confirm quantum necessity: replacing photonic QNNs with random\ninputs collapses accuracy to chance level ($10.0\\% \\pm 0.5\\%$). Photonic\nquantum computing's room-temperature operation, inherent scalability through\nspatial-mode multiplexing, and HPC-integrated architecture establish a\npractical pathway for distributed quantum machine learning, combining the\nexpressivity of photonic Hilbert spaces with the deployability of classical\nneural networks.",
      "tldr_zh": "本文提出了一种分布式量子-经典框架，将 photonic quantum neural networks (QNNs) 与 matrix-product-state (MPS) 映射相结合，实现参数高效的经典神经网络训练。该框架利用 M 模式干涉仪的线性光学分解和光子计数测量，生成高维概率分布并映射为经典网络权重，在 MNIST 分类任务上达到 95.50% ± 0.84% 准确率，仅需 3,292 参数，比经典基线减少参数并实现十倍压缩比（准确率损失不到 3%）。实验结果显示，该方法比传统压缩技术（如权重共享或剪枝）高出 6-12% 绝对准确率，且对光子噪声具有鲁棒性，证明了 photonic QNNs 在分布式量子机器学习中的必要性和实用价值。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08474v1",
      "published_date": "2025-05-13 11:58:45 UTC",
      "updated_date": "2025-05-13 11:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:05.754937"
    },
    {
      "arxiv_id": "2505.08463v1",
      "title": "RepCali: High Efficient Fine-tuning Via Representation Calibration in Latent Space for Pre-trained Language Models",
      "title_zh": "RepCali：通过在潜在空间中表示校准实现的高效微调，针对预训练语言模型",
      "authors": [
        "Fujun Zhang",
        "XiangDong Su"
      ],
      "abstract": "Fine-tuning pre-trained language models (PLMs) has become a dominant paradigm\nin applying PLMs to downstream tasks. However, with limited fine-tuning, PLMs\nstill struggle with the discrepancies between the representation obtained from\nthe PLMs' encoder and the optimal input to the PLMs' decoder. This paper\ntackles this challenge by learning to calibrate the representation of PLMs in\nthe latent space. In the proposed representation calibration method (RepCali),\nwe integrate a specific calibration block to the latent space after the encoder\nand use the calibrated output as the decoder input. The merits of the proposed\nRepCali include its universality to all PLMs with encoder-decoder\narchitectures, its plug-and-play nature, and ease of implementation. Extensive\nexperiments on 25 PLM-based models across 8 tasks (including both English and\nChinese datasets) demonstrate that the proposed RepCali offers desirable\nenhancements to PLMs (including LLMs) and significantly improves the\nperformance of downstream tasks. Comparison experiments across 4 benchmark\ntasks indicate that RepCali is superior to the representative fine-tuning\nbaselines.",
      "tldr_zh": "本论文提出 RepCali 方法，通过在 Latent Space 中校准预训练语言模型 (PLMs) 的表示，来解决微调过程中编码器输出与解码器输入不匹配的问题。该方法引入一个校准块 (Calibration Block)，使其适用于所有编码器-解码器架构的 PLMs，并具备即插即用和易实现的特点。在 25 个 PLM 模型和 8 个任务（包括英语和中文数据集）上的广泛实验表明，RepCali 显著提升了下游任务的性能，并在 4 个基准任务中优于其他微调基线。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08463v1",
      "published_date": "2025-05-13 11:47:00 UTC",
      "updated_date": "2025-05-13 11:47:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:07.447065"
    },
    {
      "arxiv_id": "2505.08841v1",
      "title": "Will AI Take My Job? Evolving Perceptions of Automation and Labor Risk in Latin America",
      "title_zh": "AI 会抢走我的工作吗？ 拉丁美洲对自动化和劳动力风险感知的演变",
      "authors": [
        "Andrea Cremaschi",
        "Dae-Jin Lee",
        "Manuele Leonelli"
      ],
      "abstract": "As artificial intelligence and robotics increasingly reshape the global labor\nmarket, understanding public perceptions of these technologies becomes\ncritical. We examine how these perceptions have evolved across Latin America,\nusing survey data from the 2017, 2018, 2020, and 2023 waves of the\nLatinobar\\'ometro. Drawing on responses from over 48,000 individuals across 16\ncountries, we analyze fear of job loss due to artificial intelligence and\nrobotics. Using statistical modeling and latent class analysis, we identify key\nstructural and ideological predictors of concern, with education level and\npolitical orientation emerging as the most consistent drivers. Our findings\nreveal substantial temporal and cross-country variation, with a notable peak in\nfear during 2018 and distinct attitudinal profiles emerging from latent\nsegmentation. These results offer new insights into the social and structural\ndimensions of AI anxiety in emerging economies and contribute to a broader\nunderstanding of public attitudes toward automation beyond the Global North.",
      "tldr_zh": "这篇论文考察了拉丁美洲公众对人工智能（AI）和机器人自动化导致工作丢失的恐惧如何演变，基于2017至2023年Latinobarómetro调查数据，涵盖16个国家超过48,000个样本。研究采用统计建模和潜在类分析（latent class analysis），发现教育水平和政治倾向是恐惧的主要预测因素，并揭示了时间和国家间的显著差异，如2018年的恐惧高峰。结果为理解新兴经济体AI焦虑的社会结构维度提供了新见解，并扩展了对全球北方以外地区公众态度的认知。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08841v1",
      "published_date": "2025-05-13 11:43:02 UTC",
      "updated_date": "2025-05-13 11:43:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:15.727255"
    },
    {
      "arxiv_id": "2505.08459v1",
      "title": "Strategy-Augmented Planning for Large Language Models via Opponent Exploitation",
      "title_zh": "通过对手利用的策略增强规划用于大型语言模型",
      "authors": [
        "Shuai Xu",
        "Sijia Cui",
        "Yanna Wang",
        "Bo Xu",
        "Qi Wang"
      ],
      "abstract": "Efficiently modeling and exploiting opponents is a long-standing challenge in\nadversarial domains. Large Language Models (LLMs) trained on extensive textual\ndata have recently demonstrated outstanding performance in general tasks,\nintroducing new research directions for opponent modeling. Some studies\nprimarily focus on directly using LLMs to generate decisions based on the\nelaborate prompt context that incorporates opponent descriptions, while these\napproaches are limited to scenarios where LLMs possess adequate domain\nexpertise. To address that, we introduce a two-stage Strategy-Augmented\nPlanning (SAP) framework that significantly enhances the opponent exploitation\ncapabilities of LLM-based agents by utilizing a critical component, the\nStrategy Evaluation Network (SEN). Specifically, in the offline stage, we\nconstruct an explicit strategy space and subsequently collect strategy-outcome\npair data for training the SEN network. During the online phase, SAP\ndynamically recognizes the opponent's strategies and greedily exploits them by\nsearching best response strategy on the well-trained SEN, finally translating\nstrategy to a course of actions by carefully designed prompts. Experimental\nresults show that SAP exhibits robust generalization capabilities, allowing it\nto perform effectively not only against previously encountered opponent\nstrategies but also against novel, unseen strategies. In the MicroRTS\nenvironment, SAP achieves a 85.35\\% performance improvement over baseline\nmethods and matches the competitiveness of reinforcement learning approaches\nagainst state-of-the-art (SOTA) rule-based AI.",
      "tldr_zh": "该研究提出Strategy-Augmented Planning (SAP)框架，以提升Large Language Models (LLMs)在对抗环境中的对手利用能力，解决LLMs在缺乏领域专业知识时的局限性。SAP采用两阶段方法：在离线阶段构建策略空间并训练Strategy Evaluation Network (SEN)来收集策略-结果数据；在在线阶段动态识别对手策略，并通过SEN搜索最佳响应策略，最后通过精心设计的提示转化为行动序列。实验结果表明，SAP在MicroRTS环境中比基线方法提升85.35%的性能，并展现出对已知和未知对手策略的鲁棒泛化能力，与强化学习方法相当。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08459v1",
      "published_date": "2025-05-13 11:41:10 UTC",
      "updated_date": "2025-05-13 11:41:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:18.123091"
    },
    {
      "arxiv_id": "2505.08451v1",
      "title": "Adaptive Bias Generalized Rollout Policy Adaptation on the Flexible Job-Shop Scheduling Problem",
      "title_zh": "自适应偏差广义 Rollout 策略适应于柔性作业车间调度问题",
      "authors": [
        "Lotfi Kobrosly",
        "Marc-Emmanuel Coupvent des Graviers",
        "Christophe Guettier",
        "Tristan Cazenave"
      ],
      "abstract": "The Flexible Job-Shop Scheduling Problem (FJSSP) is an NP-hard combinatorial\noptimization problem, with several application domains, especially for\nmanufacturing purposes. The objective is to\n  efficiently schedule multiple operations on dissimilar machines. These\noperations are gathered into jobs, and operations pertaining to the same job\nneed to be scheduled sequentially. Different methods have been previously\ntested to solve this problem, such as Constraint Solving, Tabu Search, Genetic\nAlgorithms, or Monte Carlo Tree Search (MCTS). We propose a novel algorithm\nderived from the Generalized Nested Rollout Policy Adaptation, developed to\nsolve the FJSSP. We report encouraging experimental results, as our algorithm\nperforms better than other MCTS-based approaches, even if makespans obtained on\nlarge instances are still far from known upper bounds.",
      "tldr_zh": "这篇论文针对 Flexible Job-Shop Scheduling Problem (FJSSP)，一个 NP-hard 的组合优化问题，提出了一种新算法 Adaptive Bias Generalized Rollout Policy Adaptation，用于高效调度多作业操作在不同机器上的顺序执行。算法基于 Generalized Nested Rollout Policy Adaptation 的改进版本，旨在优化作业调度过程，并与现有方法如 Constraint Solving、Tabu Search、Genetic Algorithms 或 Monte Carlo Tree Search (MCTS) 进行比较。实验结果显示，该算法在性能上优于其他 MCTS-based 方法，但在大实例上的 makespan 仍低于已知上界，表明仍有改进潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The 19th Learning and Intelligent OptimizatioN Conference, LION19\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08451v1",
      "published_date": "2025-05-13 11:27:18 UTC",
      "updated_date": "2025-05-13 11:27:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:19.687245"
    },
    {
      "arxiv_id": "2505.08446v1",
      "title": "Agent-as-a-Service based on Agent Network",
      "title_zh": "基于代理网络的Agent-as-a-Service",
      "authors": [
        "Yuhan Zhu",
        "Haojie Liu",
        "Jian Wang",
        "Bing Li",
        "Zikang Yin",
        "Yefei Liao"
      ],
      "abstract": "The rise of large model-based AI agents has spurred interest in Multi-Agent\nSystems (MAS) for their capabilities in decision-making, collaboration, and\nadaptability. While the Model Context Protocol (MCP) addresses tool invocation\nand data exchange challenges via a unified protocol, it lacks support for\norganizing agent-level collaboration. To bridge this gap, we propose\nAgent-as-a-Service based on Agent Network (AaaS-AN), a service-oriented\nparadigm grounded in the Role-Goal-Process-Service (RGPS) standard. AaaS-AN\nunifies the entire agent lifecycle, including construction, integration,\ninteroperability, and networked collaboration, through two core components: (1)\na dynamic Agent Network, which models agents and agent groups as vertexes that\nself-organize within the network based on task and role dependencies; (2)\nservice-oriented agents, incorporating service discovery, registration, and\ninteroperability protocols. These are orchestrated by a Service Scheduler,\nwhich leverages an Execution Graph to enable distributed coordination, context\ntracking, and runtime task management. We validate AaaS-AN on mathematical\nreasoning and application-level code generation tasks, which outperforms\nstate-of-the-art baselines. Notably, we constructed a MAS based on AaaS-AN\ncontaining agent groups, Robotic Process Automation (RPA) workflows, and MCP\nservers over 100 agent services. We also release a dataset containing 10,000\nlong-horizon multi-agent workflows to facilitate future research on long-chain\ncollaboration in MAS.",
      "tldr_zh": "该论文提出了一种名为 Agent-as-a-Service based on Agent Network (AaaS-AN) 的服务导向框架，旨在解决 Multi-Agent Systems (MAS) 中代理协作的不足，同时扩展 Model Context Protocol (MCP) 的功能。AaaS-AN 基于 Role-Goal-Process-Service (RGPS) 标准，通过动态 Agent Network 实现代理和代理组的自组织，以及服务导向代理结合 Service Scheduler 和 Execution Graph 来处理分布式协调和任务管理。实验结果显示，该框架在数学推理和代码生成任务上超越了现有基线，并开源了一个包含 10,000 个长链多代理工作流的数据集，以促进未来 MAS 协作研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "work in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.08446v1",
      "published_date": "2025-05-13 11:15:19 UTC",
      "updated_date": "2025-05-13 11:15:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:24.073741"
    },
    {
      "arxiv_id": "2505.08445v1",
      "title": "Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency",
      "title_zh": "优化检索增强生成：超参数对性能和效率影响的分析",
      "authors": [
        "Adel Ammar",
        "Anis Koubaa",
        "Omer Nacar",
        "Wadii Boulila"
      ],
      "abstract": "Large language models achieve high task performance yet often hallucinate or\nrely on outdated knowledge. Retrieval-augmented generation (RAG) addresses\nthese gaps by coupling generation with external search. We analyse how\nhyperparameters influence speed and quality in RAG systems, covering Chroma and\nFaiss vector stores, chunking policies, cross-encoder re-ranking, and\ntemperature, and we evaluate six metrics: faithfulness, answer correctness,\nanswer relevancy, context precision, context recall, and answer similarity.\nChroma processes queries 13% faster, whereas Faiss yields higher retrieval\nprecision, revealing a clear speed-accuracy trade-off. Naive fixed-length\nchunking with small windows and minimal overlap outperforms semantic\nsegmentation while remaining the quickest option. Re-ranking provides modest\ngains in retrieval quality yet increases runtime by roughly a factor of 5, so\nits usefulness depends on latency constraints. These results help practitioners\nbalance computational cost and accuracy when tuning RAG systems for\ntransparent, up-to-date responses. Finally, we re-evaluate the top\nconfigurations with a corrective RAG workflow and show that their advantages\npersist when the model can iteratively request additional evidence. We obtain a\nnear-perfect context precision (99%), which demonstrates that RAG systems can\nachieve extremely high retrieval accuracy with the right combination of\nhyperparameters, with significant implications for applications where retrieval\nquality directly impacts downstream task performance, such as clinical decision\nsupport in healthcare.",
      "tldr_zh": "该研究分析了检索增强生成（RAG）系统的超参数对性能和效率的影响，包括 Chroma 和 Faiss 向量存储、chunking 策略、cross-encoder re-ranking 以及 temperature 等因素，并评估了 faithfulness、answer correctness、answer relevancy、context precision、context recall 和 answer similarity 等六个指标。结果表明，Chroma 处理查询快 13%，但 Faiss 提供更高检索精度，显示出速度与准确性的权衡；固定长度 chunking（小窗口和最小重叠）优于语义分割，且更快速，而 re-ranking 虽略微提升质量但会增加约 5 倍运行时间，其应用取决于延迟限制。最终，通过优化配置并结合 corrective RAG 工作流，研究实现了近乎完美的 context precision（99%），为医疗决策支持等应用提供高精度检索的指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08445v1",
      "published_date": "2025-05-13 11:13:27 UTC",
      "updated_date": "2025-05-13 11:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:24.881377"
    },
    {
      "arxiv_id": "2505.08438v1",
      "title": "A Survey of 3D Reconstruction with Event Cameras: From Event-based Geometry to Neural 3D Rendering",
      "title_zh": "事件相机3D重建的综述：从基于事件的几何学到神经3D渲染",
      "authors": [
        "Chuanzhi Xu",
        "Haoxian Zhou",
        "Langyi Chen",
        "Haodong Chen",
        "Ying Zhou",
        "Vera Chung",
        "Qiang Qu"
      ],
      "abstract": "Event cameras have emerged as promising sensors for 3D reconstruction due to\ntheir ability to capture per-pixel brightness changes asynchronously. Unlike\nconventional frame-based cameras, they produce sparse and temporally rich data\nstreams, which enable more accurate 3D reconstruction and open up the\npossibility of performing reconstruction in extreme environments such as\nhigh-speed motion, low light, or high dynamic range scenes. In this survey, we\nprovide the first comprehensive review focused exclusively on 3D reconstruction\nusing event cameras. The survey categorises existing works into three major\ntypes based on input modality - stereo, monocular, and multimodal systems, and\nfurther classifies them by reconstruction approach, including geometry-based,\ndeep learning-based, and recent neural rendering techniques such as Neural\nRadiance Fields and 3D Gaussian Splatting. Methods with a similar research\nfocus were organised chronologically into the most subdivided groups. We also\nsummarise public datasets relevant to event-based 3D reconstruction. Finally,\nwe highlight current research limitations in data availability, evaluation,\nrepresentation, and dynamic scene handling, and outline promising future\nresearch directions. This survey aims to serve as a comprehensive reference and\na roadmap for future developments in event-driven 3D reconstruction.",
      "tldr_zh": "这篇调查论文回顾了事件相机在3D重建中的应用，强调其捕捉异步像素亮度变化的优势，使其在高速运动、低光照或高动态范围等极端环境中实现更精确的重建。论文将现有方法分类为基于立体、单目和多模态系统的类型，并进一步细分为几何-based、深度学习-based以及神经渲染技术（如Neural Radiance Fields和3D Gaussian Splatting），并按时间顺序组织相似研究。最终，论文总结了相关公共数据集，指出当前挑战包括数据可用性、评估方法、场景表示和动态处理，并为事件驱动3D重建的未来发展提供路线图。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "35 pages, 12 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.08438v1",
      "published_date": "2025-05-13 11:04:04 UTC",
      "updated_date": "2025-05-13 11:04:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:25.187948"
    },
    {
      "arxiv_id": "2505.08435v2",
      "title": "Hakim: Farsi Text Embedding Model",
      "title_zh": "Hakim：波斯语文本嵌入模型",
      "authors": [
        "Mehran Sarmadi",
        "Morteza Alikhani",
        "Erfan Zinvandi",
        "Zahra Pourbahman"
      ],
      "abstract": "Recent advancements in text embedding have significantly improved natural\nlanguage understanding across many languages, yet Persian remains notably\nunderrepresented in large-scale embedding research. In this paper, we present\nHakim, a novel state-of-the-art Persian text embedding model that achieves a\n8.5% performance improvement over existing approaches on the FaMTEB benchmark,\noutperforming all previously developed Persian language models. As part of this\nwork, we introduce three new datasets - Corpesia, Pairsia-sup, and\nPairsia-unsup - to support supervised and unsupervised training scenarios.\nAdditionally, Hakim is designed for applications in chatbots and\nretrieval-augmented generation (RAG) systems, particularly addressing retrieval\ntasks that require incorporating message history within these systems. We also\npropose a new baseline model built on the BERT architecture. Our language model\nconsistently achieves higher accuracy across various Persian NLP tasks, while\nthe RetroMAE-based model proves particularly effective for textual information\nretrieval applications. Together, these contributions establish a new\nfoundation for advancing Persian language understanding.",
      "tldr_zh": "本研究介绍了 Hakim，一种先进的 Farsi（波斯语）文本嵌入模型，在 FaMTEB 基准上比现有方法提升了 8.5% 的性能，超越了所有先前波斯语模型。论文同时引入了三个新数据集——Corpesia、Pairsia-sup 和 Pairsia-unsup——以支持监督和无监督训练场景，并提出一个基于 BERT 架构的新基准模型。Hakim 特别适用于聊天机器人和检索增强生成（RAG）系统，尤其在处理消息历史的相关检索任务中表现出色，为波斯语自然语言理解奠定了新基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08435v2",
      "published_date": "2025-05-13 10:57:32 UTC",
      "updated_date": "2025-05-14 13:47:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:27.056632"
    },
    {
      "arxiv_id": "2505.08404v1",
      "title": "Explaining Autonomous Vehicles with Intention-aware Policy Graphs",
      "title_zh": "利用意图感知策略图解释自动驾驶车辆",
      "authors": [
        "Sara Montese",
        "Victor Gimenez-Abalos",
        "Atia Cortés",
        "Ulises Cortés",
        "Sergio Alvarez-Napagao"
      ],
      "abstract": "The potential to improve road safety, reduce human driving error, and promote\nenvironmental sustainability have enabled the field of autonomous driving to\nprogress rapidly over recent decades. The performance of autonomous vehicles\nhas significantly improved thanks to advancements in Artificial Intelligence,\nparticularly Deep Learning. Nevertheless, the opacity of their decision-making,\nrooted in the use of accurate yet complex AI models, has created barriers to\ntheir societal trust and regulatory acceptance, raising the need for\nexplainability. We propose a post-hoc, model-agnostic solution to provide\nteleological explanations for the behaviour of an autonomous vehicle in urban\nenvironments. Building on Intention-aware Policy Graphs, our approach enables\nthe extraction of interpretable and reliable explanations of vehicle behaviour\nin the nuScenes dataset from global and local perspectives. We demonstrate the\npotential of these explanations to assess whether the vehicle operates within\nacceptable legal boundaries and to identify possible vulnerabilities in\nautonomous driving datasets and models.",
      "tldr_zh": "自动驾驶技术的快速发展提高了道路安全和环保性，但其决策过程的不透明性导致了社会信任和监管挑战，因此需要提供teleological解释。论文提出一种后验（post-hoc）和模型无关（model-agnostic）的解决方案，利用Intention-aware Policy Graphs从全局和本地视角提取可解释的车辆行为解释。实验基于nuScenes数据集，展示了这些解释在评估车辆是否符合法律边界以及识别自动驾驶数据集和模型漏洞方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to Workshop EXTRAAMAS 2025 in AAMAS Conference",
      "pdf_url": "http://arxiv.org/pdf/2505.08404v1",
      "published_date": "2025-05-13 09:58:32 UTC",
      "updated_date": "2025-05-13 09:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:28.589792"
    },
    {
      "arxiv_id": "2505.08403v1",
      "title": "ConDiSim: Conditional Diffusion Models for Simulation Based Inference",
      "title_zh": "ConDiSim：条件扩散模型用于基于模拟的推理",
      "authors": [
        "Mayank Nautiyal",
        "Andreas Hellander",
        "Prashant Singh"
      ],
      "abstract": "We present a conditional diffusion model - ConDiSim, for simulation-based\ninference of complex systems with intractable likelihoods. ConDiSim leverages\ndenoising diffusion probabilistic models to approximate posterior\ndistributions, consisting of a forward process that adds Gaussian noise to\nparameters, and a reverse process learning to denoise, conditioned on observed\ndata. This approach effectively captures complex dependencies and\nmulti-modalities within posteriors. ConDiSim is evaluated across ten benchmark\nproblems and two real-world test problems, where it demonstrates effective\nposterior approximation accuracy while maintaining computational efficiency and\nstability in model training. ConDiSim offers a robust and extensible framework\nfor simulation-based inference, particularly suitable for parameter inference\nworkflows requiring fast inference methods.",
      "tldr_zh": "该研究提出了一种条件扩散模型ConDiSim，用于处理模拟基于推理的复杂系统，该模型通过去噪扩散概率模型（denoising diffusion probabilistic models）来近似后验分布，包括添加高斯噪声的前向过程和基于观察数据的反向去噪过程，从而有效捕捉复杂的依赖性和多模态后验。ConDiSim在10个基准问题和2个真实世界问题上进行了评估，展示了出色的后验近似准确性，同时保持了计算效率和训练稳定性。作为一个鲁棒且可扩展的框架，ConDiSim特别适用于需要快速参数推断的模拟基于推理工作流。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08403v1",
      "published_date": "2025-05-13 09:58:23 UTC",
      "updated_date": "2025-05-13 09:58:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:31.914727"
    },
    {
      "arxiv_id": "2505.08392v1",
      "title": "Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping",
      "title_zh": "加速链式思维推理：当目标梯度重要性遇上动态跳过",
      "authors": [
        "Ren Zhuang",
        "Ben Wang",
        "Shuifa Sun"
      ],
      "abstract": "Large Language Models leverage Chain-of-Thought (CoT) prompting for complex\ntasks, but their reasoning traces are often excessively verbose and\ninefficient, leading to significant computational costs and latency. Current\nCoT compression techniques typically rely on generic importance metrics and\nstatic compression rates, which may inadvertently remove functionally critical\ntokens or fail to adapt to varying reasoning complexity. To overcome these\nlimitations, we propose Adaptive GoGI-Skip, a novel framework learning dynamic\nCoT compression via supervised fine-tuning. This approach introduces two\nsynergistic innovations: (1) Goal-Gradient Importance (GoGI), a novel metric\naccurately identifying functionally relevant tokens by measuring the gradient\ninfluence of their intermediate representations on the final answer loss, and\n(2) Adaptive Dynamic Skipping (ADS), a mechanism dynamically regulating the\ncompression rate based on runtime model uncertainty while ensuring local\ncoherence through an adaptive N-token constraint. To our knowledge, this is the\nfirst work unifying a goal-oriented, gradient-based importance metric with\ndynamic, uncertainty-aware skipping for CoT compression. Trained on compressed\nMATH data, Adaptive GoGI-Skip demonstrates strong cross-domain generalization\nacross diverse reasoning benchmarks including AIME, GPQA, and GSM8K. It\nachieves substantial efficiency gains - reducing CoT token counts by over 45%\non average and delivering 1.6-2.0 times inference speedups - while maintaining\nhigh reasoning accuracy. Notably, it significantly outperforms existing\nbaselines by preserving accuracy even at high effective compression rates,\nadvancing the state of the art in the CoT reasoning efficiency-accuracy\ntrade-off.",
      "tldr_zh": "这篇论文提出了 Adaptive GoGI-Skip 框架，通过监督微调来加速 Chain-of-Thought (CoT) 推理，解决现有方法在压缩时可能移除关键 tokens 的问题。框架的核心创新包括 Goal-Gradient Importance (GoGI) 指标，该指标通过测量中间表示对最终答案损失的梯度影响来识别功能相关 tokens，以及 Adaptive Dynamic Skipping (ADS) 机制，该机制根据模型不确定性动态调整压缩率并确保局部连贯性。实验结果显示，在 MATH 数据上训练后，该框架在 AIME、GPQA 和 GSM8K 等基准上实现了跨域泛化，平均减少 CoT tokens 超过 45%、推理速度提高 1.6-2.0 倍，同时保持高准确率，显著优于现有基线并推进了 CoT 推理的效率-准确性权衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08392v1",
      "published_date": "2025-05-13 09:39:18 UTC",
      "updated_date": "2025-05-13 09:39:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:36.970666"
    },
    {
      "arxiv_id": "2505.08376v1",
      "title": "Adaptive Diffusion Policy Optimization for Robotic Manipulation",
      "title_zh": "自适应扩散策略优化用于机器人操作",
      "authors": [
        "Huiyun Jiang",
        "Zhuang Yang"
      ],
      "abstract": "Recent studies have shown the great potential of diffusion models in\nimproving reinforcement learning (RL) by modeling complex policies, expressing\na high degree of multi-modality, and efficiently handling high-dimensional\ncontinuous control tasks. However, there is currently limited research on how\nto optimize diffusion-based polices (e.g., Diffusion Policy) fast and stably.\nIn this paper, we propose an Adam-based Diffusion Policy Optimization (ADPO), a\nfast algorithmic framework containing best practices for fine-tuning\ndiffusion-based polices in robotic control tasks using the adaptive gradient\ndescent method in RL. Adaptive gradient method is less studied in training RL,\nlet alone diffusion-based policies. We confirm that ADPO outperforms other\ndiffusion-based RL methods in terms of overall effectiveness for fine-tuning on\nstandard robotic tasks. Concretely, we conduct extensive experiments on\nstandard robotic control tasks to test ADPO, where, particularly, six popular\ndiffusion-based RL methods are provided as benchmark methods. Experimental\nresults show that ADPO acquires better or comparable performance than the\nbaseline methods. Finally, we systematically analyze the sensitivity of\nmultiple hyperparameters in standard robotics tasks, providing guidance for\nsubsequent practical applications. Our video demonstrations are released in\nhttps://github.com/Timeless-lab/ADPO.git.",
      "tldr_zh": "该研究提出 ADPO（Adam-based Diffusion Policy Optimization），一种用于机器人操作的算法框架，通过自适应梯度下降方法（如 Adam）快速稳定地微调基于扩散的策略（例如 Diffusion Policy），以提升强化学习（RL）在高维连续控制任务中的性能。相比其他扩散-based RL 方法，ADPO 在标准机器人任务上表现出色，实验结果显示其在六种基准方法中获得更好或相当的性能。作者还系统分析了多个超参数的敏感性，并提供视频演示，以指导后续实际应用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08376v1",
      "published_date": "2025-05-13 09:21:45 UTC",
      "updated_date": "2025-05-13 09:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:44.980039"
    },
    {
      "arxiv_id": "2505.08366v1",
      "title": "Non-contact Vital Signs Detection in Dynamic Environments",
      "title_zh": "动态环境中的非接触式生命体征检测",
      "authors": [
        "Shuai Sun",
        "Chong-Xi Liang",
        "Chengwei Ye",
        "Huanzhen Zhang",
        "Kangsheng Wang"
      ],
      "abstract": "Accurate phase demodulation is critical for vital sign detection using\nmillimeter-wave radar. However, in complex environments, time-varying DC\noffsets and phase imbalances can severely degrade demodulation performance. To\naddress this, we propose a novel DC offset calibration method alongside a\nHilbert and Differential Cross-Multiply (HADCM) demodulation algorithm. The\napproach estimates time-varying DC offsets from neighboring signal peaks and\nvalleys, then employs both differential forms and Hilbert transforms of the I/Q\nchannel signals to extract vital sign information. Simulation and experimental\nresults demonstrate that the proposed method maintains robust performance under\nlow signal-to-noise ratios. Compared to existing demodulation techniques, it\noffers more accurate signal recovery in challenging scenarios and effectively\nsuppresses noise interference.",
      "tldr_zh": "该研究针对毫米波雷达在动态环境中进行非接触式生命体征检测时，时间变化的 DC offset 和相位不平衡导致的解调性能下降问题，提出了一种新型 DC offset 校准方法和 Hilbert and Differential Cross-Multiply (HADCM) 解调算法。该方法通过从相邻信号峰值和谷值估计时间变化的 DC offset，并结合 I/Q 通道信号的差分形式和 Hilbert transform，提取准确的生命体征信息。模拟和实验结果显示，该方法在低信噪比条件下保持鲁棒性能，与现有技术相比，提供更精确的信号恢复并有效抑制噪声干扰。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08366v1",
      "published_date": "2025-05-13 09:11:48 UTC",
      "updated_date": "2025-05-13 09:11:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:46.691912"
    },
    {
      "arxiv_id": "2505.08364v1",
      "title": "Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation",
      "title_zh": "像人类学习：通过自适应难度课程学习和专家指导的自重构提升大型语言模型的推理能力",
      "authors": [
        "Enci Zhang",
        "Xingang Yan",
        "Wei Lin",
        "Tianxiang Zhang",
        "Qianchun Lu"
      ],
      "abstract": "Despite impressive progress in areas like mathematical reasoning, large\nlanguage models still face significant challenges in consistently solving\ncomplex problems. Drawing inspiration from key human learning strategies, we\npropose two novel strategies to enhance the capability of large language models\nto solve these complex problems. First, Adaptive Difficulty Curriculum Learning\n(ADCL) is a novel curriculum learning strategy that tackles the Difficulty\nShift phenomenon (i.e., a model's perception of problem difficulty dynamically\nchanges during training) by periodically re-estimating difficulty within\nupcoming data batches to maintain alignment with the model's evolving\ncapabilities. Second, Expert-Guided Self-Reformulation (EGSR) is a novel\nreinforcement learning strategy that bridges the gap between imitation learning\nand pure exploration by guiding models to reformulate expert solutions within\ntheir own conceptual framework, rather than relying on direct imitation,\nfostering deeper understanding and knowledge assimilation. Extensive\nexperiments on challenging mathematical reasoning benchmarks, using Qwen2.5-7B\nas the base model, demonstrate that these human-inspired strategies\nsynergistically and significantly enhance performance. Notably, their combined\napplication improves performance over the standard Zero-RL baseline by 10% on\nthe AIME24 benchmark and 16.6% on AIME25.",
      "tldr_zh": "该论文受人类学习策略启发，提出两种新方法来提升大型语言模型（LLMs）的复杂问题推理能力：Adaptive Difficulty Curriculum Learning (ADCL) 通过动态重新评估数据批次难度来应对 Difficulty Shift 现象，确保训练过程与模型能力保持一致；Expert-Guided Self-Reformulation (EGSR) 则是一种强化学习策略，指导模型在自身概念框架内重述专家解决方案，以促进更深入的知识吸收和理解。实验在数学推理基准上使用 Qwen2.5-7B 作为基模型，结果显示，这两种策略结合应用比标准 Zero-RL 基线在 AIME24 上提高了 10%、在 AIME25 上提高了 16.6% 的性能。这些创新方法为增强 LLMs 的可靠性和泛化能力提供了重要途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 3 figs",
      "pdf_url": "http://arxiv.org/pdf/2505.08364v1",
      "published_date": "2025-05-13 09:10:48 UTC",
      "updated_date": "2025-05-13 09:10:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:50.023177"
    },
    {
      "arxiv_id": "2505.08361v1",
      "title": "Modeling Unseen Environments with Language-guided Composable Causal Components in Reinforcement Learning",
      "title_zh": "在强化学习中使用语言引导的可组合因果组件建模未知环境",
      "authors": [
        "Xinyue Wang",
        "Biwei Huang"
      ],
      "abstract": "Generalization in reinforcement learning (RL) remains a significant\nchallenge, especially when agents encounter novel environments with unseen\ndynamics. Drawing inspiration from human compositional reasoning -- where known\ncomponents are reconfigured to handle new situations -- we introduce World\nModeling with Compositional Causal Components (WM3C). This novel framework\nenhances RL generalization by learning and leveraging compositional causal\ncomponents. Unlike previous approaches focusing on invariant representation\nlearning or meta-learning, WM3C identifies and utilizes causal dynamics among\ncomposable elements, facilitating robust adaptation to new tasks. Our approach\nintegrates language as a compositional modality to decompose the latent space\ninto meaningful components and provides theoretical guarantees for their unique\nidentification under mild assumptions. Our practical implementation uses a\nmasked autoencoder with mutual information constraints and adaptive sparsity\nregularization to capture high-level semantic information and effectively\ndisentangle transition dynamics. Experiments on numerical simulations and\nreal-world robotic manipulation tasks demonstrate that WM3C significantly\noutperforms existing methods in identifying latent processes, improving policy\nlearning, and generalizing to unseen tasks.",
      "tldr_zh": "这篇论文提出了 WM3C 框架，用于提升强化学习（RL）在面对未见环境动态时的泛化能力，灵感来源于人类的组合推理，通过学习和利用可组合因果组件（compositional causal components）来实现鲁棒适应。框架整合语言作为组合模态（compositional modality），分解潜在空间（latent space）成有意义组件，并使用 masked autoencoder 结合 mutual information constraints 和 adaptive sparsity regularization 来捕捉语义信息和分离过渡动态，提供理论保证。实验在数值模拟和真实机器人操作任务中表明，WM3C 在识别潜在过程、改进策略学习和泛化到未见任务上显著优于现有方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08361v1",
      "published_date": "2025-05-13 09:08:28 UTC",
      "updated_date": "2025-05-13 09:08:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:51.998595"
    },
    {
      "arxiv_id": "2505.08350v1",
      "title": "STORYANCHORS: Generating Consistent Multi-Scene Story Frames for Long-Form Narratives",
      "title_zh": "STORYANCHORS：生成一致的多场景故事框架用于长篇叙事",
      "authors": [
        "Bo Wang",
        "Haoyang Huang",
        "Zhiyin Lu",
        "Fengyuan Liu",
        "Guoqing Ma",
        "Jianlong Yuan",
        "Yuan Zhang",
        "Nan Duan"
      ],
      "abstract": "This paper introduces StoryAnchors, a unified framework for generating\nhigh-quality, multi-scene story frames with strong temporal consistency. The\nframework employs a bidirectional story generator that integrates both past and\nfuture contexts to ensure temporal consistency, character continuity, and\nsmooth scene transitions throughout the narrative. Specific conditions are\nintroduced to distinguish story frame generation from standard video synthesis,\nfacilitating greater scene diversity and enhancing narrative richness. To\nfurther improve generation quality, StoryAnchors integrates Multi-Event Story\nFrame Labeling and Progressive Story Frame Training, enabling the model to\ncapture both overarching narrative flow and event-level dynamics. This approach\nsupports the creation of editable and expandable story frames, allowing for\nmanual modifications and the generation of longer, more complex sequences.\nExtensive experiments show that StoryAnchors outperforms existing open-source\nmodels in key areas such as consistency, narrative coherence, and scene\ndiversity. Its performance in narrative consistency and story richness is also\non par with GPT-4o. Ultimately, StoryAnchors pushes the boundaries of\nstory-driven frame generation, offering a scalable, flexible, and highly\neditable foundation for future research.",
      "tldr_zh": "本文提出StoryAnchors框架，用于生成高质量、多场景故事框架，确保长篇叙事的时序一致性、角色连续性和平滑场景过渡。该框架采用bidirectional story generator整合过去和未来上下文，并结合Multi-Event Story Frame Labeling和Progressive Story Frame Training，增强场景多样性、叙事丰富性和事件级动态，支持可编辑和可扩展的序列生成。实验结果显示，StoryAnchors在一致性、叙事连贯性和场景多样性方面优于现有开源模型，并在叙事一致性和故事丰富性上与GPT-4o相当，最终为故事驱动框架生成提供了一个可扩展、灵活的基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08350v1",
      "published_date": "2025-05-13 08:48:10 UTC",
      "updated_date": "2025-05-13 08:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:54.107800"
    },
    {
      "arxiv_id": "2505.08349v1",
      "title": "FAD: Frequency Adaptation and Diversion for Cross-domain Few-shot Learning",
      "title_zh": "FAD：频率适应与分流用于跨域少样本学习",
      "authors": [
        "Ruixiao Shi",
        "Fu Feng",
        "Yucheng Xie",
        "Jing Wang",
        "Xin Geng"
      ],
      "abstract": "Cross-domain few-shot learning (CD-FSL) requires models to generalize from\nlimited labeled samples under significant distribution shifts. While recent\nmethods enhance adaptability through lightweight task-specific modules, they\noperate solely in the spatial domain and overlook frequency-specific variations\nthat are often critical for robust transfer. We observe that spatially similar\nimages across domains can differ substantially in their spectral\nrepresentations, with low and high frequencies capturing complementary semantic\ninformation at coarse and fine levels. This indicates that uniform spatial\nadaptation may overlook these spectral distinctions, thus constraining\ngeneralization. To address this, we introduce Frequency Adaptation and\nDiversion (FAD), a frequency-aware framework that explicitly models and\nmodulates spectral components. At its core is the Frequency Diversion Adapter,\nwhich transforms intermediate features into the frequency domain using the\ndiscrete Fourier transform (DFT), partitions them into low, mid, and\nhigh-frequency bands via radial masks, and reconstructs each band using inverse\nDFT (IDFT). Each frequency band is then adapted using a dedicated convolutional\nbranch with a kernel size tailored to its spectral scale, enabling targeted and\ndisentangled adaptation across frequencies. Extensive experiments on the\nMeta-Dataset benchmark demonstrate that FAD consistently outperforms\nstate-of-the-art methods on both seen and unseen domains, validating the\nutility of frequency-domain representations and band-wise adaptation for\nimproving generalization in CD-FSL.",
      "tldr_zh": "本研究针对跨域少样本学习(CD-FSL)中分布偏移问题，提出了一种频率感知框架Frequency Adaptation and Diversion (FAD)，通过显式建模和调节频率域组件来提升模型的泛化能力。FAD的核心组件Frequency Diversion Adapter使用Discrete Fourier Transform (DFT)将特征转换为频率域，并将频带分区为低、中和高频，然后通过Inverse DFT (IDFT)重构并采用专属卷积分支针对每个频带进行适应，从而捕捉不同频率的互补语义信息。在Meta-Dataset基准上的广泛实验显示，FAD在已见和未见域上均超过了最先进方法，验证了频率域表示和带状适应的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08349v1",
      "published_date": "2025-05-13 08:48:06 UTC",
      "updated_date": "2025-05-13 08:48:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:55.420132"
    },
    {
      "arxiv_id": "2505.08345v1",
      "title": "SHAP-based Explanations are Sensitive to Feature Representation",
      "title_zh": "基于 SHAP 的解释对特征表示敏感",
      "authors": [
        "Hyunseung Hwang",
        "Andrew Bell",
        "Joao Fonseca",
        "Venetia Pliatsika",
        "Julia Stoyanovich",
        "Steven Euijong Whang"
      ],
      "abstract": "Local feature-based explanations are a key component of the XAI toolkit.\nThese explanations compute feature importance values relative to an\n``interpretable'' feature representation. In tabular data, feature values\nthemselves are often considered interpretable. This paper examines the impact\nof data engineering choices on local feature-based explanations. We demonstrate\nthat simple, common data engineering techniques, such as representing age with\na histogram or encoding race in a specific way, can manipulate feature\nimportance as determined by popular methods like SHAP. Notably, the sensitivity\nof explanations to feature representation can be exploited by adversaries to\nobscure issues like discrimination. While the intuition behind these results is\nstraightforward, their systematic exploration has been lacking. Previous work\nhas focused on adversarial attacks on feature-based explainers by biasing data\nor manipulating models. To the best of our knowledge, this is the first study\ndemonstrating that explainers can be misled by standard, seemingly innocuous\ndata engineering techniques.",
      "tldr_zh": "这篇论文探讨了基于SHAP的局部特征解释在XAI（可解释AI）工具中的敏感性，强调特征表示方式会显著影响特征重要性的计算。在表格数据中，常见的数据工程技术，如使用直方图表示年龄或特定编码种族，能操纵SHAP等方法的输出结果，从而潜在地隐藏歧视等问题。研究首次系统地证明了这些看似无害的标准数据工程选择可能误导解释器，与以往专注于数据偏置或模型操纵的攻击不同，这为提升解释器的鲁棒性提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ACM FAccT 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08345v1",
      "published_date": "2025-05-13 08:43:09 UTC",
      "updated_date": "2025-05-13 08:43:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:56.863291"
    },
    {
      "arxiv_id": "2505.08343v1",
      "title": "An Identifiable Cost-Aware Causal Decision-Making Framework Using Counterfactual Reasoning",
      "title_zh": "一种可识别的成本感知因果决策框架，使用反事实推理",
      "authors": [
        "Ruichu Cai",
        "Xi Chen",
        "Jie Qiao",
        "Zijian Li",
        "Yuequn Liu",
        "Wei Chen",
        "Keli Zhang",
        "Jiale Zheng"
      ],
      "abstract": "Decision making under abnormal conditions is a critical process that involves\nevaluating the current state and determining the optimal action to restore the\nsystem to a normal state at an acceptable cost. However, in such scenarios,\nexisting decision-making frameworks highly rely on reinforcement learning or\nroot cause analysis, resulting in them frequently neglecting the cost of the\nactions or failing to incorporate causal mechanisms adequately. By relaxing the\nexisting causal decision framework to solve the necessary cause, we propose a\nminimum-cost causal decision (MiCCD) framework via counterfactual reasoning to\naddress the above challenges. Emphasis is placed on making counterfactual\nreasoning processes identifiable in the presence of a large amount of mixed\nanomaly data, as well as finding the optimal intervention state in a continuous\ndecision space. Specifically, it formulates a surrogate model based on causal\ngraphs, using abnormal pattern clustering labels as supervisory signals. This\nenables the approximation of the structural causal model among the variables\nand lays a foundation for identifiable counterfactual reasoning. With the\ncausal structure approximated, we then established an optimization model based\non counterfactual estimation. The Sequential Least Squares Programming (SLSQP)\nalgorithm is further employed to optimize intervention strategies while taking\ncosts into account. Experimental evaluations on both synthetic and real-world\ndatasets reveal that MiCCD outperforms conventional methods across multiple\nmetrics, including F1-score, cost efficiency, and ranking quality(nDCG@k\nvalues), thus validating its efficacy and broad applicability.",
      "tldr_zh": "这篇论文提出了一种可识别的成本感知因果决策框架 MiCCD，通过反事实推理（counterfactual reasoning）来解决异常条件下决策问题，该框架放宽了现有因果决策方法以关注必要原因并最小化行动成本。MiCCD 使用因果图（causal graphs）构建代理模型，以异常模式聚类标签作为监督信号，近似结构因果模型（structural causal model），并通过 Sequential Least Squares Programming (SLSQP) 算法优化干预策略。实验结果表明，该框架在合成和真实数据集上在 F1-score、成本效率和排名质量（nDCG@k）等指标上优于传统方法，证明了其有效性和广泛适用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08343v1",
      "published_date": "2025-05-13 08:41:45 UTC",
      "updated_date": "2025-05-13 08:41:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:46:59.775541"
    },
    {
      "arxiv_id": "2505.08341v1",
      "title": "Benchmarking AI scientists in omics data-driven biological research",
      "title_zh": "在组学数据驱动的生物研究中对 AI 科学家的基准测试",
      "authors": [
        "Erpai Luo",
        "Jinmeng Jia",
        "Yifan Xiong",
        "Xiangyu Li",
        "Xiaobo Guo",
        "Baoqi Yu",
        "Lei Wei",
        "Xuegong Zhang"
      ],
      "abstract": "The rise of large language models and multi-agent systems has sparked growing\ninterest in AI scientists capable of autonomous biological research. However,\nexisting benchmarks either focus on reasoning without data or on data analysis\nwith predefined statistical answers, lacking realistic, data-driven evaluation\nsettings. Here, we introduce the Biological AI Scientist Benchmark (BaisBench),\na benchmark designed to assess AI scientists' ability to generate biological\ndiscoveries through data analysis and reasoning with external knowledge.\nBaisBench comprises two tasks: cell type annotation on 31 expert-labeled\nsingle-cell datasets, and scientific discovery through answering 198\nmultiple-choice questions derived from the biological insights of 41 recent\nsingle-cell studies. Systematic experiments on state-of-the-art AI scientists\nand LLM agents showed that while promising, current models still substantially\nunderperform human experts on both tasks. We hope BaisBench will fill this gap\nand serve as a foundation for advancing and evaluating AI models for scientific\ndiscovery. The benchmark can be found at: https://github.com/EperLuo/BaisBench.",
      "tldr_zh": "该研究引入了Biological AI Scientist Benchmark (BaisBench)，一个用于评估AI科学家在组学数据驱动的生物研究中的性能基准，旨在弥补现有基准忽略真实数据分析和推理的不足。基准包括两个任务：基于31个专家标记的单细胞数据集进行细胞类型注释，以及回答198个多选科学发现问题，这些问题源于41个最近单细胞研究的生物洞见。实验结果显示，当前最先进的AI模型和LLM代理在这些任务上远逊于人类专家，证明了BaisBench在推动AI科学发现方面的潜在价值，可在https://github.com/EperLuo/BaisBench获取。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "q-bio.GN"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08341v1",
      "published_date": "2025-05-13 08:33:54 UTC",
      "updated_date": "2025-05-13 08:33:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:00.643103"
    },
    {
      "arxiv_id": "2505.08336v1",
      "title": "A computer vision-based model for occupancy detection using low-resolution thermal images",
      "title_zh": "基于计算机视觉的低分辨率热图像占用检测模型",
      "authors": [
        "Xue Cui",
        "Vincent Gbouna Zakka",
        "Minhyun Lee"
      ],
      "abstract": "Occupancy plays an essential role in influencing the energy consumption and\noperation of heating, ventilation, and air conditioning (HVAC) systems.\nTraditional HVAC typically operate on fixed schedules without considering\noccupancy. Advanced occupant-centric control (OCC) adopted occupancy status in\nregulating HVAC operations. RGB images combined with computer vision (CV)\ntechniques are widely used for occupancy detection, however, the detailed\nfacial and body features they capture raise significant privacy concerns.\nLow-resolution thermal images offer a non-invasive solution that mitigates\nprivacy issues. The study developed an occupancy detection model utilizing\nlow-resolution thermal images and CV techniques, where transfer learning was\napplied to fine-tune the You Only Look Once version 5 (YOLOv5) model. The\ndeveloped model ultimately achieved satisfactory performance, with precision,\nrecall, mAP50, and mAP50 values approaching 1.000. The contributions of this\nmodel lie not only in mitigating privacy concerns but also in reducing\ncomputing resource demands.",
      "tldr_zh": "该论文提出了一种基于 computer vision (CV) 的占用检测模型，使用低分辨率热图像来优化 heating, ventilation, and air conditioning (HVAC) 系统的能耗管理，同时缓解传统 RGB 图像带来的隐私问题。模型通过 transfer learning 技术 fine-tune You Only Look Once version 5 (YOLOv5) 模型，实现对占用情况的准确识别。实验结果显示，模型的 precision、recall 和 mAP50 值均接近 1.000，其主要贡献在于减少隐私风险并降低计算资源需求。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08336v1",
      "published_date": "2025-05-13 08:27:50 UTC",
      "updated_date": "2025-05-13 08:27:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:03.562475"
    },
    {
      "arxiv_id": "2505.08838v1",
      "title": "Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts",
      "title_zh": "超声报告生成：利用多模态大型语言模型实现标准化文本",
      "authors": [
        "Peixuan Ge",
        "Tongkun Su",
        "Faqin Lv",
        "Baoliang Zhao",
        "Peng Zhang",
        "Chi Hong Wong",
        "Liang Yao",
        "Yu Sun",
        "Zenan Wang",
        "Pak Kin Wong",
        "Ying Hu"
      ],
      "abstract": "Ultrasound (US) report generation is a challenging task due to the\nvariability of US images, operator dependence, and the need for standardized\ntext. Unlike X-ray and CT, US imaging lacks consistent datasets, making\nautomation difficult. In this study, we propose a unified framework for\nmulti-organ and multilingual US report generation, integrating fragment-based\nmultilingual training and leveraging the standardized nature of US reports. By\naligning modular text fragments with diverse imaging data and curating a\nbilingual English-Chinese dataset, the method achieves consistent and\nclinically accurate text generation across organ sites and languages.\nFine-tuning with selective unfreezing of the vision transformer (ViT) further\nimproves text-image alignment. Compared to the previous state-of-the-art KMVE\nmethod, our approach achieves relative gains of about 2\\% in BLEU scores,\napproximately 3\\% in ROUGE-L, and about 15\\% in CIDEr, while significantly\nreducing errors such as missing or incorrect content. By unifying multi-organ\nand multi-language report generation into a single, scalable framework, this\nwork demonstrates strong potential for real-world clinical workflows.",
      "tldr_zh": "本文提出一个统一的框架，利用多模态大型语言模型(Multimodal Large Language Models)，针对超声(US)报告生成问题，处理图像变异性、操作者依赖性和标准化文本需求。框架通过基于碎片的多语言训练、对齐模块化文本碎片与多样化图像数据，以及构建英中双语数据集和微调视觉变压器(ViT)的选择性解冻，来实现多器官和多语言的临床准确文本生成。与现有最先进方法KMVE相比，该方法在BLEU得分上提高约2%、ROUGE-L提高约3%、CIDEr提高约15%，并显著减少缺失或错误内容。这为真实临床工作流程提供了可扩展的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08838v1",
      "published_date": "2025-05-13 08:27:01 UTC",
      "updated_date": "2025-05-13 08:27:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:12.136980"
    },
    {
      "arxiv_id": "2505.08327v1",
      "title": "Low-Complexity Inference in Continual Learning via Compressed Knowledge Transfer",
      "title_zh": "基于压缩知识转移的持续学习低复杂度推理",
      "authors": [
        "Zhenrong Liu",
        "Janne M. J. Huttunen",
        "Mikko Honkala"
      ],
      "abstract": "Continual learning (CL) aims to train models that can learn a sequence of\ntasks without forgetting previously acquired knowledge. A core challenge in CL\nis balancing stability -- preserving performance on old tasks -- and plasticity\n-- adapting to new ones. Recently, large pre-trained models have been widely\nadopted in CL for their ability to support both, offering strong generalization\nfor new tasks and resilience against forgetting. However, their high\ncomputational cost at inference time limits their practicality in real-world\napplications, especially those requiring low latency or energy efficiency. To\naddress this issue, we explore model compression techniques, including pruning\nand knowledge distillation (KD), and propose two efficient frameworks tailored\nfor class-incremental learning (CIL), a challenging CL setting where task\nidentities are unavailable during inference. The pruning-based framework\nincludes pre- and post-pruning strategies that apply compression at different\ntraining stages. The KD-based framework adopts a teacher-student architecture,\nwhere a large pre-trained teacher transfers downstream-relevant knowledge to a\ncompact student. Extensive experiments on multiple CIL benchmarks demonstrate\nthat the proposed frameworks achieve a better trade-off between accuracy and\ninference complexity, consistently outperforming strong baselines. We further\nanalyze the trade-offs between the two frameworks in terms of accuracy and\nefficiency, offering insights into their use across different scenarios.",
      "tldr_zh": "该研究针对持续学习（Continual Learning）中的核心挑战，即平衡稳定性（stability）和可塑性（plasticity），提出两种基于模型压缩技术的框架，以降低大型预训练模型的推理复杂度。框架包括基于修剪（pruning）的策略（如预修剪和后修剪），以及基于知识蒸馏（knowledge distillation, KD）的师生架构，其中大型教师模型将相关知识转移到紧凑学生模型，用于类增量学习（class-incremental learning, CIL）。实验在多个CIL基准上表明，这些框架在准确性和推理效率之间实现了更好的权衡，并显著优于现有基线，提供宝贵的场景适应性洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08327v1",
      "published_date": "2025-05-13 08:07:40 UTC",
      "updated_date": "2025-05-13 08:07:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:14.072043"
    },
    {
      "arxiv_id": "2505.08325v1",
      "title": "FedRS-Bench: Realistic Federated Learning Datasets and Benchmarks in Remote Sensing",
      "title_zh": "FedRS-Bench：遥感领域的真实联邦学习数据集和基准",
      "authors": [
        "Haodong Zhao",
        "Peng Peng",
        "Chiyu Chen",
        "Linqing Huang",
        "Gongshen Liu"
      ],
      "abstract": "Remote sensing (RS) images are usually produced at an unprecedented scale,\nyet they are geographically and institutionally distributed, making centralized\nmodel training challenging due to data-sharing restrictions and privacy\nconcerns. Federated learning (FL) offers a solution by enabling collaborative\nmodel training across decentralized RS data sources without exposing raw data.\nHowever, there lacks a realistic federated dataset and benchmark in RS. Prior\nworks typically rely on manually partitioned single dataset, which fail to\ncapture the heterogeneity and scale of real-world RS data, and often use\ninconsistent experimental setups, hindering fair comparison. To address this\ngap, we propose a realistic federated RS dataset, termed FedRS. FedRS consists\nof eight datasets that cover various sensors and resolutions and builds 135\nclients, which is representative of realistic operational scenarios. Data for\neach client come from the same source, exhibiting authentic federated\nproperties such as skewed label distributions, imbalanced client data volumes,\nand domain heterogeneity across clients. These characteristics reflect\npractical challenges in federated RS and support evaluation of FL methods at\nscale. Based on FedRS, we implement 10 baseline FL algorithms and evaluation\nmetrics to construct the comprehensive FedRS-Bench. The experimental results\ndemonstrate that FL can consistently improve model performance over training on\nisolated data silos, while revealing performance trade-offs of different\nmethods under varying client heterogeneity and availability conditions. We hope\nFedRS-Bench will accelerate research on large-scale, realistic FL in RS by\nproviding a standardized, rich testbed and facilitating fair comparisons across\nfuture works. The source codes and dataset are available at\nhttps://fedrs-bench.github.io/.",
      "tldr_zh": "该论文提出了 FedRS，一个真实的联邦学习（Federated Learning, FL）数据集和基准 FedRS-Bench，用于遥感（Remote Sensing, RS）领域，以解决现有数据集无法捕捉真实世界数据异质性和规模的问题。FedRS 包含八个数据集和 135 个客户端，模拟了实际场景中的标签分布偏差、数据量不平衡以及跨客户端领域异质性。基于此，研究实现了 10 个基线 FL 算法，并通过实验证明 FL 能显著提升模型性能，同时揭示不同方法在客户端异质性和可用性条件下的性能权衡。FedRS-Bench 提供了一个标准化的测试平台，有望加速大规模 FL 在 RS 领域的研发。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08325v1",
      "published_date": "2025-05-13 08:04:03 UTC",
      "updated_date": "2025-05-13 08:04:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:17.039751"
    },
    {
      "arxiv_id": "2505.08319v1",
      "title": "Reciprocity as the Foundational Substrate of Society: How Reciprocal Dynamics Scale into Social Systems",
      "title_zh": "互惠作为社会的基础基质：互惠动态如何扩展到社会系统",
      "authors": [
        "Egil Diau"
      ],
      "abstract": "A major bottleneck in multi-agent AI is the lack of simulateable models for\nthe bottom-up emergence of social structure under realistic behavioral\nconstraints. Similarly, many foundational theories in economics and sociology\nincluding the concepts of \"institutions\" and \"norms\" tend to describe social\nstructures post hoc, often relying on implicit assumptions of shared culture,\nmorality, or symbolic agreement. These concepts are often treated as primitives\nrather than reconstructed from agent-level behavior, leaving both their origins\nand operational definitions under-specified. To address this, we propose a\nthree-stage bottom-up framework: Reciprocal Dynamics, capturing\nindividual-level reciprocal exchanges; Norm Stabilization, the consolidation of\nshared expectations; and Institutional Construction, the externalization of\nstable patterns into scalable structures. By grounding social emergence in\nagent-level reciprocity, our framework enables the systematic exploration of\nhow moral, cultural, and institutional structures emerge from cognitively\nminimal interactions.",
      "tldr_zh": "该论文指出，多智能体 AI 领域缺乏模拟社会结构自下而上涌现的模型，而经济学和社会学理论（如\"institutions\"和\"norms\"）往往事后描述这些结构，依赖于共享文化或道德的假设，而非从代理级行为重建。为解决此问题，研究提出一个三阶段框架：Reciprocal Dynamics（捕捉个体级互惠交换）、Norm Stabilization（巩固共享期望）、和Institutional Construction（将稳定模式外化为可扩展结构）。通过将社会涌现建立在代理级互惠基础上，该框架系统探索道德、文化和机构结构如何从认知最小交互中自然产生。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CY",
      "comment": "First draft extending the first position paper. Main framework\n  complete; historical examples and references will be updated",
      "pdf_url": "http://arxiv.org/pdf/2505.08319v1",
      "published_date": "2025-05-13 07:50:01 UTC",
      "updated_date": "2025-05-13 07:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:17.275944"
    },
    {
      "arxiv_id": "2505.08295v1",
      "title": "A Practical Introduction to Deep Reinforcement Learning",
      "title_zh": "深度强化学习的实用介绍",
      "authors": [
        "Yinghan Sun",
        "Hongxi Wang",
        "Hua Chen",
        "Wei Zhang"
      ],
      "abstract": "Deep reinforcement learning (DRL) has emerged as a powerful framework for\nsolving sequential decision-making problems, achieving remarkable success in a\nwide range of applications, including game AI, autonomous driving, biomedicine,\nand large language models. However, the diversity of algorithms and the\ncomplexity of theoretical foundations often pose significant challenges for\nbeginners seeking to enter the field. This tutorial aims to provide a concise,\nintuitive, and practical introduction to DRL, with a particular focus on the\nProximal Policy Optimization (PPO) algorithm, which is one of the most widely\nused and effective DRL methods. To facilitate learning, we organize all\nalgorithms under the Generalized Policy Iteration (GPI) framework, offering\nreaders a unified and systematic perspective. Instead of lengthy theoretical\nproofs, we emphasize intuitive explanations, illustrative examples, and\npractical engineering techniques. This work serves as an efficient and\naccessible guide, helping readers rapidly progress from basic concepts to the\nimplementation of advanced DRL algorithms.",
      "tldr_zh": "这篇论文提供了一个简洁、直观且实用的深度强化学习 (DRL) 入门教程，旨在帮助初学者克服算法多样性和理论复杂性的挑战。教程特别聚焦于 Proximal Policy Optimization (PPO) 算法，并将所有算法组织在 Generalized Policy Iteration (GPI) 框架下，提供统一的系统视角。作者强调直观解释、示例和工程技巧，而不是理论证明，从而使读者能够快速从基础概念过渡到实现高级 DRL 算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08295v1",
      "published_date": "2025-05-13 07:19:16 UTC",
      "updated_date": "2025-05-13 07:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:18.374892"
    },
    {
      "arxiv_id": "2505.08293v1",
      "title": "M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis",
      "title_zh": "M3G：多粒度手势生成器，用于音频驱动的全身人体动作合成",
      "authors": [
        "Zhizhuo Yin",
        "Yuk Hang Tsui",
        "Pan Hui"
      ],
      "abstract": "Generating full-body human gestures encompassing face, body, hands, and\nglobal movements from audio is a valuable yet challenging task in virtual\navatar creation. Previous systems focused on tokenizing the human gestures\nframewisely and predicting the tokens of each frame from the input audio.\nHowever, one observation is that the number of frames required for a complete\nexpressive human gesture, defined as granularity, varies among different human\ngesture patterns. Existing systems fail to model these gesture patterns due to\nthe fixed granularity of their gesture tokens. To solve this problem, we\npropose a novel framework named Multi-Granular Gesture Generator (M3G) for\naudio-driven holistic gesture generation. In M3G, we propose a novel\nMulti-Granular VQ-VAE (MGVQ-VAE) to tokenize motion patterns and reconstruct\nmotion sequences from different temporal granularities. Subsequently, we\nproposed a multi-granular token predictor that extracts multi-granular\ninformation from audio and predicts the corresponding motion tokens. Then M3G\nreconstructs the human gestures from the predicted tokens using the MGVQ-VAE.\nBoth objective and subjective experiments demonstrate that our proposed M3G\nframework outperforms the state-of-the-art methods in terms of generating\nnatural and expressive full-body human gestures.",
      "tldr_zh": "本文提出 M3G（Multi-Granular Gesture Generator）框架，用于音频驱动的全身体势合成，包括面部、身体、手部和全局运动，以解决现有系统忽略不同手势模式粒度差异的问题。M3G 引入 Multi-Granular VQ-VAE (MGVQ-VAE) 来标记和重建多粒度运动序列，并使用多粒度标记预测器从音频提取信息预测相应标记，从而生成完整的身体势。实验结果表明，M3G 在客观和主观评估中优于现有方法，能产生更自然和富有表现力的全身体势。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.SD",
        "eess.AS",
        "I.3.6"
      ],
      "primary_category": "cs.GR",
      "comment": "9 Pages, 4 figures, submitted to NIPS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08293v1",
      "published_date": "2025-05-13 07:16:58 UTC",
      "updated_date": "2025-05-13 07:16:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:22.001427"
    },
    {
      "arxiv_id": "2505.08266v1",
      "title": "Open the Eyes of MPNN: Vision Enhances MPNN in Link Prediction",
      "title_zh": "开启 MPNN 的眼睛：视觉增强 MPNN 在链接预测中",
      "authors": [
        "Yanbin Wei",
        "Xuehao Wang",
        "Zhan Zhuang",
        "Yang Chen",
        "Shuhao Chen",
        "Yulong Zhang",
        "Yu Zhang",
        "James Kwok"
      ],
      "abstract": "Message-passing graph neural networks (MPNNs) and structural features (SFs)\nare cornerstones for the link prediction task. However, as a common and\nintuitive mode of understanding, the potential of visual perception has been\noverlooked in the MPNN community. For the first time, we equip MPNNs with\nvision structural awareness by proposing an effective framework called Graph\nVision Network (GVN), along with a more efficient variant (E-GVN). Extensive\nempirical results demonstrate that with the proposed frameworks, GVN\nconsistently benefits from the vision enhancement across seven link prediction\ndatasets, including challenging large-scale graphs. Such improvements are\ncompatible with existing state-of-the-art (SOTA) methods and GVNs achieve new\nSOTA results, thereby underscoring a promising novel direction for link\nprediction.",
      "tldr_zh": "该研究指出，消息传递图神经网络(MPNNs)和结构特征(SFs)是链接预测任务的核心，但视觉感知潜力长期被忽略。为此，作者提出Graph Vision Network (GVN)框架及其高效变体(E-GVN)，通过整合视觉结构感知来增强MPNNs的表现。在七个链接预测数据集上的广泛实验显示，GVN框架显著提升了性能，与现有SOTA方法兼容，并实现了新的SOTA结果，从而开辟了链接预测领域的视觉增强新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08266v1",
      "published_date": "2025-05-13 06:32:23 UTC",
      "updated_date": "2025-05-13 06:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:22.726713"
    },
    {
      "arxiv_id": "2505.08265v1",
      "title": "LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification",
      "title_zh": "LLM 增强器 for GNNs：从因果机制识别视角的分析",
      "authors": [
        "Hang Gao",
        "Wenxuan Huang",
        "Fengge Wu",
        "Junsuo Zhao",
        "Changwen Zheng",
        "Huaping Liu"
      ],
      "abstract": "The use of large language models (LLMs) as feature enhancers to optimize node\nrepresentations, which are then used as inputs for graph neural networks\n(GNNs), has shown significant potential in graph representation learning.\nHowever, the fundamental properties of this approach remain underexplored. To\naddress this issue, we propose conducting a more in-depth analysis of this\nissue based on the interchange intervention method. First, we construct a\nsynthetic graph dataset with controllable causal relationships, enabling\nprecise manipulation of semantic relationships and causal modeling to provide\ndata for analysis. Using this dataset, we conduct interchange interventions to\nexamine the deeper properties of LLM enhancers and GNNs, uncovering their\nunderlying logic and internal mechanisms. Building on the analytical results,\nwe design a plug-and-play optimization module to improve the information\ntransfer between LLM enhancers and GNNs. Experiments across multiple datasets\nand models validate the proposed module.",
      "tldr_zh": "本研究从因果机制识别（Causal Mechanism Identification）的视角分析使用大型语言模型（LLMs）作为特征增强器来优化节点表示，并将其输入图神经网络（GNNs）以提升图表示学习。研究者构建了可控因果关系的合成图数据集，并采用 interchange intervention 方法进行深入干预实验，揭示了 LLM 增强器和 GNNs 的底层逻辑与内部机制。基于这些分析结果，他们设计了一个即插即用优化模块，以改善 LLM 和 GNNs 之间的信息传输，并在多个数据集和模型上验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08265v1",
      "published_date": "2025-05-13 06:29:25 UTC",
      "updated_date": "2025-05-13 06:29:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:25.685485"
    },
    {
      "arxiv_id": "2505.08264v1",
      "title": "Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning",
      "title_zh": "自动课程学习用于驾驶场景：面向鲁棒且高效的强化学习",
      "authors": [
        "Ahmed Abouelazm",
        "Tim Weinstein",
        "Tim Joseph",
        "Philip Schörner",
        "J. Marius Zöllner"
      ],
      "abstract": "This paper addresses the challenges of training end-to-end autonomous driving\nagents using Reinforcement Learning (RL). RL agents are typically trained in a\nfixed set of scenarios and nominal behavior of surrounding road users in\nsimulations, limiting their generalization and real-life deployment. While\ndomain randomization offers a potential solution by randomly sampling driving\nscenarios, it frequently results in inefficient training and sub-optimal\npolicies due to the high variance among training scenarios. To address these\nlimitations, we propose an automatic curriculum learning framework that\ndynamically generates driving scenarios with adaptive complexity based on the\nagent's evolving capabilities. Unlike manually designed curricula that\nintroduce expert bias and lack scalability, our framework incorporates a\n``teacher'' that automatically generates and mutates driving scenarios based on\ntheir learning potential -- an agent-centric metric derived from the agent's\ncurrent policy -- eliminating the need for expert design. The framework\nenhances training efficiency by excluding scenarios the agent has mastered or\nfinds too challenging. We evaluate our framework in a reinforcement learning\nsetting where the agent learns a driving policy from camera images. Comparative\nresults against baseline methods, including fixed scenario training and domain\nrandomization, demonstrate that our approach leads to enhanced generalization,\nachieving higher success rates: +9\\% in low traffic density, +21\\% in high\ntraffic density, and faster convergence with fewer training steps. Our findings\nhighlight the potential of ACL in improving the robustness and efficiency of\nRL-based autonomous driving agents.",
      "tldr_zh": "本文提出一种自动课程学习框架（Automatic Curriculum Learning），用于强化学习（RL）中的自动驾驶场景训练，以解决传统方法在泛化和效率上的局限性，如固定场景训练和领域随机化（domain randomization）导致的低效问题。该框架引入一个“教师”组件，根据代理当前策略的“学习潜力”动态生成和变异驾驶场景，自动调整复杂度并排除已掌握或过难的场景，从而消除专家偏见并提升训练效率。在实验中，与基线方法相比，该框架显著提高了代理的泛化能力，在低交通密度下成功率提升9%、高密度下提升21%，并实现了更快收敛，证明了其在提升RL-based自动驾驶代理鲁棒性和效率方面的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.08264v1",
      "published_date": "2025-05-13 06:26:57 UTC",
      "updated_date": "2025-05-13 06:26:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:28.595346"
    },
    {
      "arxiv_id": "2505.08261v1",
      "title": "Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration",
      "title_zh": "通过自适应上下文压缩增强缓存增强生成 (CAG) 以实现可扩展知识集成",
      "authors": [
        "Rishabh Agrawal",
        "Himanshu Kumar"
      ],
      "abstract": "The rapid progress in large language models (LLMs) has paved the way for\nnovel approaches in knowledge-intensive tasks. Among these, Cache-Augmented\nGeneration (CAG) has emerged as a promising alternative to Retrieval-Augmented\nGeneration (RAG). CAG minimizes retrieval latency and simplifies system design\nby preloading knowledge into the model's context. However, challenges persist\nin scaling CAG to accommodate large and dynamic knowledge bases effectively.\nThis paper introduces Adaptive Contextual Compression (ACC), an innovative\ntechnique designed to dynamically compress and manage context inputs, enabling\nefficient utilization of the extended memory capabilities of modern LLMs. To\nfurther address the limitations of standalone CAG, we propose a Hybrid CAG-RAG\nFramework, which integrates selective retrieval to augment preloaded contexts\nin scenarios requiring additional information. Comprehensive evaluations on\ndiverse datasets highlight the proposed methods' ability to enhance\nscalability, optimize efficiency, and improve multi-hop reasoning performance,\noffering practical solutions for real-world knowledge integration challenges.",
      "tldr_zh": "本论文针对Cache-Augmented Generation (CAG)在处理大型动态知识库时的挑战，提出了Adaptive Contextual Compression (ACC)技术，该方法通过动态压缩和管理上下文输入，提升了大型语言模型(LLMs)的内存利用效率和整体性能。同时，作者引入了Hybrid CAG-RAG Framework，将选择性检索与预加载上下文相结合，以处理需要额外信息的场景。实验评估在多样数据集上证明，这些创新方法显著提高了系统的可扩展性、效率和多跳推理能力，为实际知识整合任务提供了有效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08261v1",
      "published_date": "2025-05-13 06:24:48 UTC",
      "updated_date": "2025-05-13 06:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:29.431385"
    },
    {
      "arxiv_id": "2505.08835v1",
      "title": "Robustness Analysis against Adversarial Patch Attacks in Fully Unmanned Stores",
      "title_zh": "针对全无人商店的对抗性补丁攻击鲁棒性分析",
      "authors": [
        "Hyunsik Na",
        "Wonho Lee",
        "Seungdeok Roh",
        "Sohee Park",
        "Daeseon Choi"
      ],
      "abstract": "The advent of convenient and efficient fully unmanned stores equipped with\nartificial intelligence-based automated checkout systems marks a new era in\nretail. However, these systems have inherent artificial intelligence security\nvulnerabilities, which are exploited via adversarial patch attacks,\nparticularly in physical environments. This study demonstrated that adversarial\npatches can severely disrupt object detection models used in unmanned stores,\nleading to issues such as theft, inventory discrepancies, and interference. We\ninvestigated three types of adversarial patch attacks -- Hiding, Creating, and\nAltering attacks -- and highlighted their effectiveness. We also introduce the\nnovel color histogram similarity loss function by leveraging attacker knowledge\nof the color information of a target class object. Besides the traditional\nconfusion-matrix-based attack success rate, we introduce a new\nbounding-boxes-based metric to analyze the practical impact of these attacks.\nStarting with attacks on object detection models trained on snack and fruit\ndatasets in a digital environment, we evaluated the effectiveness of\nadversarial patches in a physical testbed that mimicked a real unmanned store\nwith RGB cameras and realistic conditions. Furthermore, we assessed the\nrobustness of these attacks in black-box scenarios, demonstrating that shadow\nattacks can enhance success rates of attacks even without direct access to\nmodel parameters. Our study underscores the necessity for robust defense\nstrategies to protect unmanned stores from adversarial threats. Highlighting\nthe limitations of the current defense mechanisms in real-time detection\nsystems and discussing various proactive measures, we provide insights into\nimproving the robustness of object detection models and fortifying unmanned\nretail environments against these attacks.",
      "tldr_zh": "本研究分析了全无人商店中物体检测模型对对抗性补丁攻击（adversarial patch attacks）的鲁棒性，这些攻击可能导致盗窃、库存不一致等问题。研究者调查了三种攻击类型——Hiding、Creating 和 Altering 攻击，并引入了新的 color histogram similarity loss function，利用目标类对象的颜色信息来提升攻击效果；此外，还开发了基于边界框的指标来评估实际影响。实验在数字和物理模拟环境中进行，包括黑盒场景，结果显示这些攻击在真实无人商店条件下高度有效，并证明了影子攻击（shadow attacks）能提高成功率。该研究强调了强化防御策略的必要性，并讨论了当前实时检测系统的局限性，以改进物体检测模型的鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08835v1",
      "published_date": "2025-05-13 06:24:32 UTC",
      "updated_date": "2025-05-13 06:24:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:37.318004"
    },
    {
      "arxiv_id": "2505.08253v1",
      "title": "Evaluating LLM Metrics Through Real-World Capabilities",
      "title_zh": "通过真实世界能力评估大型语言模型指标",
      "authors": [
        "Justin K Miller",
        "Wenjia Tang"
      ],
      "abstract": "As generative AI becomes increasingly embedded in everyday workflows, it is\nimportant to evaluate its performance in ways that reflect real-world usage\nrather than abstract notions of intelligence. Unlike many existing benchmarks\nthat assess general intelligence, our approach focuses on real-world utility,\nevaluating how well models support users in everyday tasks. While current\nbenchmarks emphasize code generation or factual recall, users rely on AI for a\nmuch broader range of activities-from writing assistance and summarization to\ncitation formatting and stylistic feedback. In this paper, we analyze\nlarge-scale survey data and usage logs to identify six core capabilities that\nrepresent how people commonly use Large Language Models (LLMs): Summarization,\nTechnical Assistance, Reviewing Work, Data Structuring, Generation, and\nInformation Retrieval. We then assess the extent to which existing benchmarks\ncover these capabilities, revealing significant gaps in coverage, efficiency\nmeasurement, and interpretability. Drawing on this analysis, we use\nhuman-centered criteria to identify gaps in how well current benchmarks reflect\ncommon usage that is grounded in five practical criteria: coherence, accuracy,\nclarity, relevance, and efficiency. For four of the six capabilities, we\nidentify the benchmarks that best align with real-world tasks and use them to\ncompare leading models. We find that Google Gemini outperforms other\nmodels-including OpenAI's GPT, xAI's Grok, Meta's LLaMA, Anthropic's Claude,\nDeepSeek, and Qwen from Alibaba-on these utility-focused metrics.",
      "tldr_zh": "这篇论文评估大型语言模型(LLMs)的性能，强调以真实世界使用场景为基础，而不是抽象智能，通过分析大规模调查数据和使用日志，识别出六大核心能力：Summarization（总结）、Technical Assistance（技术辅助）、Reviewing Work（审查工作）、Data Structuring（数据结构化）、Generation（生成）和Information Retrieval（信息检索）。研究发现，现有的基准测试在这些能力的覆盖、效率测量和可解释性方面存在显著缺口，并使用人类中心标准（coherence、accuracy、clarity、relevance 和 efficiency）来识别差距。针对六大能力中的四种，论文比较了领先模型的表现，结果显示 Google Gemini 在这些实用指标上优于 OpenAI's GPT、xAI's Grok、Meta's LLaMA 等模型。该方法为更贴近实际应用的 AI 评估提供了重要见解。",
      "categories": [
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages main text, 5 pages references, 20 pages appendix; includes 3\n  figures and 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.08253v1",
      "published_date": "2025-05-13 06:02:37 UTC",
      "updated_date": "2025-05-13 06:02:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:40.946320"
    },
    {
      "arxiv_id": "2505.08245v1",
      "title": "Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement",
      "title_zh": "大语言模型心理测量学：评估、验证和增强的系统综述",
      "authors": [
        "Haoran Ye",
        "Jing Jin",
        "Yuhang Xie",
        "Xin Zhang",
        "Guojie Song"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has outpaced\ntraditional evaluation methodologies. It presents novel challenges, such as\nmeasuring human-like psychological constructs, navigating beyond static and\ntask-specific benchmarks, and establishing human-centered evaluation. These\nchallenges intersect with Psychometrics, the science of quantifying the\nintangible aspects of human psychology, such as personality, values, and\nintelligence. This survey introduces and synthesizes an emerging\ninterdisciplinary field of LLM Psychometrics, which leverages psychometric\ninstruments, theories, and principles to evaluate, understand, and enhance\nLLMs. We systematically explore the role of Psychometrics in shaping\nbenchmarking principles, broadening evaluation scopes, refining methodologies,\nvalidating results, and advancing LLM capabilities. This paper integrates\ndiverse perspectives to provide a structured framework for researchers across\ndisciplines, enabling a more comprehensive understanding of this nascent field.\nUltimately, we aim to provide actionable insights for developing future\nevaluation paradigms that align with human-level AI and promote the advancement\nof human-centered AI systems for societal benefit. A curated repository of LLM\npsychometric resources is available at\nhttps://github.com/valuebyte-ai/Awesome-LLM-Psychometrics.",
      "tldr_zh": "这篇论文系统回顾了 Large Language Models (LLMs) 的心理测量学评估、验证和提升，介绍了 LLM Psychometrics 这一新兴跨学科领域，以量化人类心理结构（如个性、价值观和智力）来应对 LLMs 的挑战。论文探讨了 Psychometrics 在基准原则扩展、评估范围拓宽、方法优化、结果验证以及提升 LLM 能力方面的作用，并整合多学科视角提供了一个结构化框架。最终，该研究为开发人类中心 AI 评估范式提供了可操作见解，促进社会有益的 AI 进步，并附带了一个资源仓库（https://github.com/valuebyte-ai/Awesome-LLM-Psychometrics）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "63 pages, 482 references",
      "pdf_url": "http://arxiv.org/pdf/2505.08245v1",
      "published_date": "2025-05-13 05:47:51 UTC",
      "updated_date": "2025-05-13 05:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:42.065634"
    },
    {
      "arxiv_id": "2505.08834v1",
      "title": "Crowd Scene Analysis using Deep Learning Techniques",
      "title_zh": "利用深度学习技术的人群场景分析",
      "authors": [
        "Muhammad Junaid Asif"
      ],
      "abstract": "Our research is focused on two main applications of crowd scene analysis\ncrowd counting and anomaly detection In recent years a large number of\nresearches have been presented in the domain of crowd counting We addressed two\nmain challenges in this domain 1 Deep learning models are datahungry paradigms\nand always need a large amount of annotated data for the training of algorithm\nIt is timeconsuming and costly task to annotate such large amount of data\nSelfsupervised training is proposed to deal with this challenge 2 MCNN consists\nof multicolumns of CNN with different sizes of filters by presenting a novel\napproach based on a combination of selfsupervised training and MultiColumn CNN\nThis enables the model to learn features at different levels and makes it\neffective in dealing with challenges of occluded scenes nonuniform density\ncomplex backgrounds and scale invariation The proposed model was evaluated on\npublicly available data sets such as ShanghaiTech and UCFQNRF by means of MAE\nand MSE A spatiotemporal model based on VGG19 is proposed for crowd anomaly\ndetection addressing challenges like lighting environmental conditions\nunexpected objects and scalability The model extracts spatial and temporal\nfeatures allowing it to be generalized to realworld scenes Spatial features are\nlearned using CNN while temporal features are learned using LSTM blocks The\nmodel works on binary classification and can detect normal or abnormal behavior\nThe models performance is improved by replacing fully connected layers with\ndense residual blocks Experiments on the Hockey Fight dataset and SCVD dataset\nshow our models outperform other stateoftheart approaches",
      "tldr_zh": "本研究聚焦于使用深度学习技术的人群场景分析，主要涉及人群计数和异常检测两个应用。针对人群计数，论文提出结合自监督训练和 MultiColumn CNN (MCNN) 的新方法，以解决数据标注需求大、遮挡、非均匀密度、复杂背景和尺度不变性等挑战，并在 ShanghaiTech 和 UCFQNRF 数据集上通过 MAE 和 MSE 指标评估，模型性能显著提升。对于异常检测，开发了基于 VGG19 的时空模型，利用 CNN 提取空间特征和 LSTM 提取时间特征，进行二元分类，在 Hockey Fight 和 SCVD 数据集上优于现有方法。总的来说，该工作提高了人群场景分析的鲁棒性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "MS Graduate Research Thesis",
      "pdf_url": "http://arxiv.org/pdf/2505.08834v1",
      "published_date": "2025-05-13 05:29:30 UTC",
      "updated_date": "2025-05-13 05:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:44.888232"
    },
    {
      "arxiv_id": "2505.08234v1",
      "title": "Removing Watermarks with Partial Regeneration using Semantic Information",
      "title_zh": "使用语义信息的部分再生移除水印",
      "authors": [
        "Krti Tallam",
        "John Kevin Cava",
        "Caleb Geniesse",
        "N. Benjamin Erichson",
        "Michael W. Mahoney"
      ],
      "abstract": "As AI-generated imagery becomes ubiquitous, invisible watermarks have emerged\nas a primary line of defense for copyright and provenance. The newest\nwatermarking schemes embed semantic signals - content-aware patterns that are\ndesigned to survive common image manipulations - yet their true robustness\nagainst adaptive adversaries remains under-explored. We expose a previously\nunreported vulnerability and introduce SemanticRegen, a three-stage, label-free\nattack that erases state-of-the-art semantic and invisible watermarks while\nleaving an image's apparent meaning intact. Our pipeline (i) uses a\nvision-language model to obtain fine-grained captions, (ii) extracts foreground\nmasks with zero-shot segmentation, and (iii) inpaints only the background via\nan LLM-guided diffusion model, thereby preserving salient objects and style\ncues. Evaluated on 1,000 prompts across four watermarking systems - TreeRing,\nStegaStamp, StableSig, and DWT/DCT - SemanticRegen is the only method to defeat\nthe semantic TreeRing watermark (p = 0.10 > 0.05) and reduces bit-accuracy\nbelow 0.75 for the remaining schemes, all while maintaining high perceptual\nquality (masked SSIM = 0.94 +/- 0.01). We further introduce masked SSIM (mSSIM)\nto quantify fidelity within foreground regions, showing that our attack\nachieves up to 12 percent higher mSSIM than prior diffusion-based attackers.\nThese results highlight an urgent gap between current watermark defenses and\nthe capabilities of adaptive, semantics-aware adversaries, underscoring the\nneed for watermarking algorithms that are resilient to content-preserving\nregenerative attacks.",
      "tldr_zh": "该论文提出了一种名为 SemanticRegen 的三阶段无标签攻击方法，用于移除 AI 生成图像中的先进语义和隐形水印，同时保留图像的主要内容和风格。方法包括使用视觉语言模型获取细粒度标题、零样本分割提取前景掩码，以及通过 LLM 引导的扩散模型仅修复背景。实验在 1000 个提示和四个水印系统（TreeRing、StegaStamp、StableSig 和 DWT/DCT）上评估，SemanticRegen 成功击败了 TreeRing 水印（p = 0.10 > 0.05），并将其他方案的位准确率降至 0.75 以下，同时保持高感知质量（masked SSIM = 0.94 +/- 0.01）。这些结果突显了当前水印防御机制的漏洞，强调需要开发更抗内容保留型再生攻击的水印算法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08234v1",
      "published_date": "2025-05-13 05:25:06 UTC",
      "updated_date": "2025-05-13 05:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:46.444451"
    },
    {
      "arxiv_id": "2505.08228v1",
      "title": "Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix",
      "title_zh": "使用 Instruct Pix2Pix 在恶劣天气条件下进行自动驾驶车辆的对象检测",
      "authors": [
        "Unai Gurbindo",
        "Axel Brando",
        "Jaume Abella",
        "Caroline König"
      ],
      "abstract": "Enhancing the robustness of object detection systems under adverse weather\nconditions is crucial for the advancement of autonomous driving technology.\nThis study presents a novel approach leveraging the diffusion model Instruct\nPix2Pix to develop prompting methodologies that generate realistic datasets\nwith weather-based augmentations aiming to mitigate the impact of adverse\nweather on the perception capabilities of state-of-the-art object detection\nmodels, including Faster R-CNN and YOLOv10. Experiments were conducted in two\nenvironments, in the CARLA simulator where an initial evaluation of the\nproposed data augmentation was provided, and then on the real-world image data\nsets BDD100K and ACDC demonstrating the effectiveness of the approach in real\nenvironments.\n  The key contributions of this work are twofold: (1) identifying and\nquantifying the performance gap in object detection models under challenging\nweather conditions, and (2) demonstrating how tailored data augmentation\nstrategies can significantly enhance the robustness of these models. This\nresearch establishes a solid foundation for improving the reliability of\nperception systems in demanding environmental scenarios, and provides a pathway\nfor future advancements in autonomous driving.",
      "tldr_zh": "本研究针对自动驾驶车辆在恶劣天气条件下进行物体检测的鲁棒性问题，提出了一种新方法，使用扩散模型 Instruct Pix2Pix 生成带有天气增强的真实数据集，从而提升 Faster R-CNN 和 YOLOv10 等模型的感知能力。实验在 CARLA 模拟器以及真实数据集 BDD100K 和 ACDC 上进行，结果显示该方法显著缩小了模型在恶劣天气下的性能差距。研究的关键贡献包括识别并量化物体检测模型的性能缺陷，以及证明定制数据增强策略能有效提高模型的可靠性，为自动驾驶感知系统的改进提供重要基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.6; I.2.10; I.4.8; I.5.1"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures. Accepted at the International Joint Conference on\n  Neural Networks (IJCNN) 2025 (to appear)",
      "pdf_url": "http://arxiv.org/pdf/2505.08228v1",
      "published_date": "2025-05-13 05:12:07 UTC",
      "updated_date": "2025-05-13 05:12:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:48.157518"
    },
    {
      "arxiv_id": "2505.08223v1",
      "title": "Reinforcement Learning-based Fault-Tolerant Control for Quadrotor with Online Transformer Adaptation",
      "title_zh": "基于强化学习的四旋翼无人机容错控制，结合在线Transformer适应",
      "authors": [
        "Dohyun Kim",
        "Jayden Dongwoo Lee",
        "Hyochoong Bang",
        "Jungho Bae"
      ],
      "abstract": "Multirotors play a significant role in diverse field robotics applications\nbut remain highly susceptible to actuator failures, leading to rapid\ninstability and compromised mission reliability. While various fault-tolerant\ncontrol (FTC) strategies using reinforcement learning (RL) have been widely\nexplored, most previous approaches require prior knowledge of the multirotor\nmodel or struggle to adapt to new configurations. To address these limitations,\nwe propose a novel hybrid RL-based FTC framework integrated with a\ntransformer-based online adaptation module. Our framework leverages a\ntransformer architecture to infer latent representations in real time, enabling\nadaptation to previously unseen system models without retraining. We evaluate\nour method in a PyBullet simulation under loss-of-effectiveness actuator\nfaults, achieving a 95% success rate and a positional root mean square error\n(RMSE) of 0.129 m, outperforming existing adaptation methods with 86% success\nand an RMSE of 0.153 m. Further evaluations on quadrotors with varying\nconfigurations confirm the robustness of our framework across untrained\ndynamics. These results demonstrate the potential of our framework to enhance\nthe adaptability and reliability of multirotors, enabling efficient fault\nmanagement in dynamic and uncertain environments. Website is available at\nhttp://00dhkim.me/paper/rl-ftc",
      "tldr_zh": "本研究针对多旋翼飞行器（如 quadrotor）易受 actuator failures 影响导致不稳定的问题，提出了一种新型混合 Reinforcement Learning (RL)-based Fault-Tolerant Control (FTC) 框架，结合 transformer-based online adaptation 模块。该框架利用 transformer 架构实时推断潜在表示，能够适应未见过的系统模型，而无需先验知识或重新训练。在 PyBullet 模拟环境中，该方法在 loss-of-effectiveness 故障场景下实现了95%的成功率和0.129 m的 positional RMSE，优于现有方法的86%成功率和0.153 m RMSE。此外，在不同 quadrotor 配置上的评估证实了框架的鲁棒性，提升了多旋翼在动态不确定环境中的适应性和可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accpted at the 2025 IEEE International Conference on Robotics &\n  Automation (ICRA) Workshop: Robots in the Wild",
      "pdf_url": "http://arxiv.org/pdf/2505.08223v1",
      "published_date": "2025-05-13 04:50:29 UTC",
      "updated_date": "2025-05-13 04:50:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:49.942678"
    },
    {
      "arxiv_id": "2505.08222v1",
      "title": "Scaling Multi Agent Reinforcement Learning for Underwater Acoustic Tracking via Autonomous Vehicles",
      "title_zh": "通过自主车辆扩展多智能体强化学习用于水下声学跟踪",
      "authors": [
        "Matteo Gallici",
        "Ivan Masmitja",
        "Mario Martín"
      ],
      "abstract": "Autonomous vehicles (AV) offer a cost-effective solution for scientific\nmissions such as underwater tracking. Recently, reinforcement learning (RL) has\nemerged as a powerful method for controlling AVs in complex marine\nenvironments. However, scaling these techniques to a fleet--essential for\nmulti-target tracking or targets with rapid, unpredictable motion--presents\nsignificant computational challenges. Multi-Agent Reinforcement Learning (MARL)\nis notoriously sample-inefficient, and while high-fidelity simulators like\nGazebo's LRAUV provide 100x faster-than-real-time single-robot simulations,\nthey offer no significant speedup for multi-vehicle scenarios, making MARL\ntraining impractical. To address these limitations, we propose an iterative\ndistillation method that transfers high-fidelity simulations into a simplified,\nGPU-accelerated environment while preserving high-level dynamics. This approach\nachieves up to a 30,000x speedup over Gazebo through parallelization, enabling\nefficient training via end-to-end GPU acceleration. Additionally, we introduce\na novel Transformer-based architecture (TransfMAPPO) that learns multi-agent\npolicies invariant to the number of agents and targets, significantly improving\nsample efficiency. Following large-scale curriculum learning conducted entirely\non GPU, we perform extensive evaluations in Gazebo, demonstrating that our\nmethod maintains tracking errors below 5 meters over extended durations, even\nin the presence of multiple fast-moving targets. This work bridges the gap\nbetween large-scale MARL training and high-fidelity deployment, providing a\nscalable framework for autonomous fleet control in real-world sea missions.",
      "tldr_zh": "该研究针对水下声学跟踪中多代理强化学习(MARL)的计算挑战，提出了一种可扩展框架，用于控制自主车辆(AV)舰队。研究引入迭代蒸馏方法，将高保真模拟器如 Gazebo 转移到简化、GPU 加速的环境中，实现高达 30,000 倍的训练加速，同时开发了新型 Transformer-based 架构 TransfMAPPO，以学习与代理和目标数量无关的政策，提高样本效率。通过大规模 GPU 上的课程学习，实验在 Gazebo 中证明，该方法能将跟踪错误保持在 5 米以下，即使面对多个快速移动目标，从而为真实海域任务提供可靠的自主舰队控制框架。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08222v1",
      "published_date": "2025-05-13 04:42:30 UTC",
      "updated_date": "2025-05-13 04:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:51.384477"
    },
    {
      "arxiv_id": "2505.08215v1",
      "title": "Unveiling the Best Practices for Applying Speech Foundation Models to Speech Intelligibility Prediction for Hearing-Impaired People",
      "title_zh": "揭示将语音基础模型应用于听力障碍人士语音可懂度预测的最佳实践",
      "authors": [
        "Haoshuai Zhou",
        "Boxuan Cao",
        "Changgeng Mo",
        "Linkai Li",
        "Shan Xiang Wang"
      ],
      "abstract": "Speech foundation models (SFMs) have demonstrated strong performance across a\nvariety of downstream tasks, including speech intelligibility prediction for\nhearing-impaired people (SIP-HI). However, optimizing SFMs for SIP-HI has been\ninsufficiently explored. In this paper, we conduct a comprehensive study to\nidentify key design factors affecting SIP-HI performance with 5 SFMs, focusing\non encoder layer selection, prediction head architecture, and ensemble\nconfigurations. Our findings show that, contrary to traditional use-all-layers\nmethods, selecting a single encoder layer yields better results. Additionally,\ntemporal modeling is crucial for effective prediction heads. We also\ndemonstrate that ensembling multiple SFMs improves performance, with stronger\nindividual models providing greater benefit. Finally, we explore the\nrelationship between key SFM attributes and their impact on SIP-HI performance.\nOur study offers practical insights into effectively adapting SFMs for speech\nintelligibility prediction for hearing-impaired populations.",
      "tldr_zh": "本文研究了优化语音基础模型（SFMs）应用于听障人士语音可懂度预测（SIP-HI）的关键实践，通过分析5个SFMs的编码器层选择、预测头架构和集成配置。研究发现，与传统使用所有层的方法不同，选择单个编码器层并加入时间建模可显著提升预测性能，而集成多个SFMs能进一步改善效果，更强的单个模型带来更大益处。最终，该研究探讨了SFM属性与SIP-HI性能的关系，提供实用见解以有效适应SFMs用于听障人群的语音预测。",
      "categories": [
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08215v1",
      "published_date": "2025-05-13 04:07:59 UTC",
      "updated_date": "2025-05-13 04:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:53.746158"
    },
    {
      "arxiv_id": "2505.08202v1",
      "title": "AI and Generative AI Transforming Disaster Management: A Survey of Damage Assessment and Response Techniques",
      "title_zh": "人工智能与生成式人工智能转变灾害管理：损害评估和响应技术的调查",
      "authors": [
        "Aman Raj",
        "Lakshit Arora",
        "Sanjay Surendranath Girija",
        "Shashank Kapoor",
        "Dipen Pradhan",
        "Ankit Shetgaonkar"
      ],
      "abstract": "Natural disasters, including earthquakes, wildfires and cyclones, bear a huge\nrisk on human lives as well as infrastructure assets. An effective response to\ndisaster depends on the ability to rapidly and efficiently assess the intensity\nof damage. Artificial Intelligence (AI) and Generative Artificial Intelligence\n(GenAI) presents a breakthrough solution, capable of combining knowledge from\nmultiple types and sources of data, simulating realistic scenarios of disaster,\nand identifying emerging trends at a speed previously unimaginable. In this\npaper, we present a comprehensive review on the prospects of AI and GenAI in\ndamage assessment for various natural disasters, highlighting both its\nstrengths and limitations. We talk about its application to multimodal data\nsuch as text, image, video, and audio, and also cover major issues of data\nprivacy, security, and ethical use of the technology during crises. The paper\nalso recognizes the threat of Generative AI misuse, in the form of\ndissemination of misinformation and for adversarial attacks. Finally, we\noutline avenues of future research, emphasizing the need for secure, reliable,\nand ethical Generative AI systems for disaster management in general. We\nbelieve that this work represents the first comprehensive survey of Gen-AI\ntechniques being used in the field of Disaster Assessment and Response.",
      "tldr_zh": "这篇论文对 AI 和 Generative AI 在灾害管理中的应用进行了首次全面综述，焦点在于损害评估和响应技术，如地震、野火和 cyclones 的风险评估。论文讨论了这些技术如何利用多模态数据（包括文本、图像、视频和音频）来快速模拟灾害场景、识别趋势，并突出了其优势（如高效处理数据）和局限性（如数据隐私、安全问题以及 Generative AI 的误用风险，例如传播 misinformation 或进行 adversarial attacks）。最后，论文强调未来研究的方向，呼吁开发安全、可靠且伦理的 AI 系统，以提升灾害响应的整体效能。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted in IEEE Compsac 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08202v1",
      "published_date": "2025-05-13 03:33:31 UTC",
      "updated_date": "2025-05-13 03:33:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:47:56.062218"
    },
    {
      "arxiv_id": "2505.08200v1",
      "title": "A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection in LLM Outputs",
      "title_zh": "预测头与质疑头：预训练的不确定性量化头用于LLM输出中的幻觉检测",
      "authors": [
        "Artem Shelmanov",
        "Ekaterina Fadeeva",
        "Akim Tsvigun",
        "Ivan Tsvigun",
        "Zhuohan Xie",
        "Igor Kiselev",
        "Nico Daheim",
        "Caiqi Zhang",
        "Artem Vazhentsev",
        "Mrinmaya Sachan",
        "Preslav Nakov",
        "Timothy Baldwin"
      ],
      "abstract": "Large Language Models (LLMs) have the tendency to hallucinate, i.e., to\nsporadically generate false or fabricated information. This presents a major\nchallenge, as hallucinations often appear highly convincing and users generally\nlack the tools to detect them. Uncertainty quantification (UQ) provides a\nframework for assessing the reliability of model outputs, aiding in the\nidentification of potential hallucinations. In this work, we introduce\npre-trained UQ heads: supervised auxiliary modules for LLMs that substantially\nenhance their ability to capture uncertainty compared to unsupervised UQ\nmethods. Their strong performance stems from the powerful Transformer\narchitecture in their design and informative features derived from LLM\nattention maps. Experimental evaluation shows that these heads are highly\nrobust and achieve state-of-the-art performance in claim-level hallucination\ndetection across both in-domain and out-of-domain prompts. Moreover, these\nmodules demonstrate strong generalization to languages they were not explicitly\ntrained on. We pre-train a collection of UQ heads for popular LLM series,\nincluding Mistral, Llama, and Gemma 2. We publicly release both the code and\nthe pre-trained heads.",
      "tldr_zh": "本文提出了一种预训练的不确定性量化 (UQ) heads 模块，用于检测大语言模型 (LLMs) 输出中的幻觉问题。这些 heads 是监督辅助模块，基于 Transformer 架构和 LLM 注意力图的特征，显著提升了模型捕获不确定性的能力，比无监督 UQ 方法更有效。实验结果显示，该模块在声明级幻觉检测中达到最先进性能，具有高鲁棒性和跨语言泛化能力，能够处理域内和域外提示。作者公开了针对 Mistral、Llama 和 Gemma 2 等系列的预训练 heads 代码和模型，促进进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08200v1",
      "published_date": "2025-05-13 03:30:26 UTC",
      "updated_date": "2025-05-13 03:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:05.248343"
    },
    {
      "arxiv_id": "2505.08830v1",
      "title": "Federated Large Language Models: Feasibility, Robustness, Security and Future Directions",
      "title_zh": "联邦大型语言模型：可行性、稳健性、安全性和未来方向",
      "authors": [
        "Wenhao Jiang",
        "Yuchuan Luo",
        "Guilin Deng",
        "Silong Chen",
        "Xu Yang",
        "Shihong Wu",
        "Xinwen Gao",
        "Lin Liu",
        "Shaojing Fu"
      ],
      "abstract": "The integration of Large Language Models (LLMs) and Federated Learning (FL)\npresents a promising solution for joint training on distributed data while\npreserving privacy and addressing data silo issues. However, this emerging\nfield, known as Federated Large Language Models (FLLM), faces significant\nchallenges, including communication and computation overheads, heterogeneity,\nprivacy and security concerns. Current research has primarily focused on the\nfeasibility of FLLM, but future trends are expected to emphasize enhancing\nsystem robustness and security. This paper provides a comprehensive review of\nthe latest advancements in FLLM, examining challenges from four critical\nperspectives: feasibility, robustness, security, and future directions. We\npresent an exhaustive survey of existing studies on FLLM feasibility, introduce\nmethods to enhance robustness in the face of resource, data, and task\nheterogeneity, and analyze novel risks associated with this integration,\nincluding privacy threats and security challenges. We also review the latest\ndevelopments in defense mechanisms and explore promising future research\ndirections, such as few-shot learning, machine unlearning, and IP protection.\nThis survey highlights the pressing need for further research to enhance system\nrobustness and security while addressing the unique challenges posed by the\nintegration of FL and LLM.",
      "tldr_zh": "这篇论文审视了Federated Large Language Models (FLLM)，即将Large Language Models (LLMs)与Federated Learning (FL)整合，以实现分布式数据联合训练，同时保护隐私并解决数据孤岛问题。论文从可行性、鲁棒性和安全性三个关键视角全面回顾了现有研究，介绍了提升系统鲁棒性的方法（如应对资源、数据和任务异质性）以及分析隐私威胁和安全挑战的防御机制。最终，论文强调未来研究方向，包括few-shot learning、machine unlearning和IP保护，以推动FLLM的可靠性和安全性发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "35 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08830v1",
      "published_date": "2025-05-13 03:23:54 UTC",
      "updated_date": "2025-05-13 03:23:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:06.392061"
    },
    {
      "arxiv_id": "2505.08195v1",
      "title": "Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations",
      "title_zh": "Aitomia：您的智能助手，用于AI驱动的原子模拟和量子化学模拟",
      "authors": [
        "Jinming Hu",
        "Hassan Nawaz",
        "Yuting Rui",
        "Lijie Chi",
        "Arif Ullah",
        "Pavlo O. Dral"
      ],
      "abstract": "We have developed Aitomia - a platform powered by AI to assist in performing\nAI-driven atomistic and quantum chemical (QC) simulations. This intelligent\nassistant platform is equipped with chatbots and AI agents to help experts and\nguide non-experts in setting up and running the atomistic simulations,\nmonitoring their computation status, analyzing the simulation results, and\nsummarizing them for the user in text and graphical forms. We achieve these\ngoals by exploiting fine-tuned open-source large language models (LLMs),\nrule-based agents, and a retrieval-augmented generation (RAG) system. Aitomia\nleverages the versatility of our MLatom ecosystem for AI-enhanced computational\nchemistry. This intelligent assistant is going to be integrated into the\nAitomistic Hub and XACS online computing services, with some functionality\nalready publicly available as described at http://mlatom.com/aitomia. Aitomia\nis expected to lower the barrier to performing atomistic simulations,\naccelerating research and development in the relevant fields.",
      "tldr_zh": "本研究介绍了Aitomia，一种AI驱动的智能助手平台，用于辅助原子级(atomistic)和量子化学(QC)模拟。该平台配备聊天机器人和AI代理，帮助用户设置、运行模拟、监控计算状态、分析结果，并以文本和图形形式总结输出。Aitomia利用微调的开源大型语言模型(LLMs)、基于规则的代理和检索增强生成(RAG)系统，基于MLatom生态系统构建，并计划集成到Aitomistic Hub和XACS服务中。总体而言，该平台有望降低原子模拟的门槛，加速相关领域的研发。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "physics.chem-ph"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08195v1",
      "published_date": "2025-05-13 03:11:41 UTC",
      "updated_date": "2025-05-13 03:11:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:08.222846"
    },
    {
      "arxiv_id": "2505.08189v1",
      "title": "DSADF: Thinking Fast and Slow for Decision Making",
      "title_zh": "DSADF：快速思考与缓慢思考用于决策",
      "authors": [
        "Alex Zhihao Dou",
        "Dongfei Cui",
        "Jun Yan",
        "Weida Wang",
        "Benteng Chen",
        "Haoming Wang",
        "Zeke Xie",
        "Shufei Zhang"
      ],
      "abstract": "Although Reinforcement Learning (RL) agents are effective in well-defined\nenvironments, they often struggle to generalize their learned policies to\ndynamic settings due to their reliance on trial-and-error interactions. Recent\nwork has explored applying Large Language Models (LLMs) or Vision Language\nModels (VLMs) to boost the generalization of RL agents through policy\noptimization guidance or prior knowledge. However, these approaches often lack\nseamless coordination between the RL agent and the foundation model, leading to\nunreasonable decision-making in unfamiliar environments and efficiency\nbottlenecks. Making full use of the inferential capabilities of foundation\nmodels and the rapid response capabilities of RL agents and enhancing the\ninteraction between the two to form a dual system is still a lingering\nscientific question. To address this problem, we draw inspiration from\nKahneman's theory of fast thinking (System 1) and slow thinking (System 2),\ndemonstrating that balancing intuition and deep reasoning can achieve nimble\ndecision-making in a complex world. In this study, we propose a Dual-System\nAdaptive Decision Framework (DSADF), integrating two complementary modules:\nSystem 1, comprising an RL agent and a memory space for fast and intuitive\ndecision making, and System 2, driven by a VLM for deep and analytical\nreasoning. DSADF facilitates efficient and adaptive decision-making by\ncombining the strengths of both systems. The empirical study in the video game\nenvironment: Crafter and Housekeep demonstrates the effectiveness of our\nproposed method, showing significant improvements in decision abilities for\nboth unseen and known tasks.",
      "tldr_zh": "该论文针对强化学习（RL）代理在动态环境中的泛化难题，提出双系统自适应决策框架（DSADF），受 Kahneman 的快思考（System 1）和慢思考（System 2）理论启发。DSADF 整合了 System 1（由 RL 代理和记忆空间驱动的快速直观决策）和 System 2（由视觉语言模型（VLM）驱动的深度分析推理），从而实现高效协调与自适应决策。实验在视频游戏环境 Crafter 和 Housekeep 中验证了该框架的有效性，显示在已知和未知任务中决策能力显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08189v1",
      "published_date": "2025-05-13 02:58:04 UTC",
      "updated_date": "2025-05-13 02:58:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:10.573579"
    },
    {
      "arxiv_id": "2505.08179v1",
      "title": "Feasibility-Aware Pessimistic Estimation: Toward Long-Horizon Safety in Offline RL",
      "title_zh": "可行性感知悲观估计：面向离线强化学习中的长时域安全",
      "authors": [
        "Zhikun Tao",
        "Gang Xiong",
        "He Fang",
        "Zhen Shen",
        "Yunjun Han",
        "Qing-Shan Jia"
      ],
      "abstract": "Offline safe reinforcement learning(OSRL) derives constraint-satisfying\npolicies from pre-collected datasets, offers a promising avenue for deploying\nRL in safety-critical real-world domains such as robotics. However, the\nmajority of existing approaches emphasize only short-term safety, neglecting\nlong-horizon considerations. Consequently, they may violate safety constraints\nand fail to ensure sustained protection during online deployment. Moreover, the\nlearned policies often struggle to handle states and actions that are not\npresent or out-of-distribution(OOD) from the offline dataset, and exhibit\nlimited sample efficiency. To address these challenges, we propose a novel\nframework Feasibility-Aware offline Safe Reinforcement Learning with CVAE-based\nPessimism (FASP). First, we employ Hamilton-Jacobi (H-J) reachability analysis\nto generate reliable safety labels, which serve as supervisory signals for\ntraining both a conditional variational autoencoder (CVAE) and a safety\nclassifier. This approach not only ensures high sampling efficiency but also\nprovides rigorous long-horizon safety guarantees. Furthermore, we utilize\npessimistic estimation methods to estimate the Q-value of reward and cost,\nwhich mitigates the extrapolation errors induces by OOD actions, and penalize\nunsafe actions to enabled the agent to proactively avoid high-risk behaviors.\nMoreover, we theoretically prove the validity of this pessimistic estimation.\nExtensive experiments on DSRL benchmarks demonstrate that FASP algorithm\nachieves competitive performance across multiple experimental tasks,\nparticularly outperforming state-of-the-art algorithms in terms of safety.",
      "tldr_zh": "本研究针对Offline RL中的长期安全挑战，提出FASP框架，以解决现有OSRL方法忽略长时段约束、处理OOD状态和动作效率低的问题。FASP利用Hamilton-Jacobi reachability analysis生成安全标签，结合CVAE训练安全分类器，并采用pessimistic estimation方法来估计奖励和成本的Q-value，从而惩罚不安全动作并减少外推错误。实验结果显示，在DSRL benchmarks上，FASP在安全性能方面显著优于最先进算法，并提供了理论证明其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08179v1",
      "published_date": "2025-05-13 02:32:49 UTC",
      "updated_date": "2025-05-13 02:32:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:12.886730"
    },
    {
      "arxiv_id": "2505.08176v1",
      "title": "Behind the Noise: Conformal Quantile Regression Reveals Emergent Representations",
      "title_zh": "噪声背后：保形分位数回归揭示新兴表示",
      "authors": [
        "Petrus H. Zwart",
        "Tamas Varga",
        "Odeta Qafoku",
        "James A. Sethian"
      ],
      "abstract": "Scientific imaging often involves long acquisition times to obtain\nhigh-quality data, especially when probing complex, heterogeneous systems.\nHowever, reducing acquisition time to increase throughput inevitably introduces\nsignificant noise into the measurements. We present a machine learning approach\nthat not only denoises low-quality measurements with calibrated uncertainty\nbounds, but also reveals emergent structure in the latent space. By using\nensembles of lightweight, randomly structured neural networks trained via\nconformal quantile regression, our method performs reliable denoising while\nuncovering interpretable spatial and chemical features -- without requiring\nlabels or segmentation. Unlike conventional approaches focused solely on image\nrestoration, our framework leverages the denoising process itself to drive the\nemergence of meaningful representations. We validate the approach on real-world\ngeobiochemical imaging data, showing how it supports confident interpretation\nand guides experimental design under resource constraints.",
      "tldr_zh": "本研究针对科学成像中缩短获取时间导致的噪声问题，提出了一种机器学习方法，使用 ensembles of lightweight, randomly structured neural networks 通过 conformal quantile regression 训练，实现低质量测量的去噪并提供校准的不确定性边界，同时揭示潜在空间的 emergent representations。该方法无需标签或分割，即可发现可解释的空间和化学特征，并利用去噪过程驱动有意义的表示出现。在真实地质生化成像数据上验证后，结果显示该框架提升了解释自信度，并指导资源受限的实验设计。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08176v1",
      "published_date": "2025-05-13 02:27:12 UTC",
      "updated_date": "2025-05-13 02:27:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:15.033759"
    },
    {
      "arxiv_id": "2505.08175v2",
      "title": "Fast Text-to-Audio Generation with Adversarial Post-Training",
      "title_zh": "快速文本到音频生成技术：采用对抗性后训练",
      "authors": [
        "Zachary Novack",
        "Zach Evans",
        "Zack Zukowski",
        "Josiah Taylor",
        "CJ Carr",
        "Julian Parker",
        "Adnan Al-Sinan",
        "Gian Marco Iodice",
        "Julian McAuley",
        "Taylor Berg-Kirkpatrick",
        "Jordi Pons"
      ],
      "abstract": "Text-to-audio systems, while increasingly performant, are slow at inference\ntime, thus making their latency unpractical for many creative applications. We\npresent Adversarial Relativistic-Contrastive (ARC) post-training, the first\nadversarial acceleration algorithm for diffusion/flow models not based on\ndistillation. While past adversarial post-training methods have struggled to\ncompare against their expensive distillation counterparts, ARC post-training is\na simple procedure that (1) extends a recent relativistic adversarial\nformulation to diffusion/flow post-training and (2) combines it with a novel\ncontrastive discriminator objective to encourage better prompt adherence. We\npair ARC post-training with a number optimizations to Stable Audio Open and\nbuild a model capable of generating $\\approx$12s of 44.1kHz stereo audio in\n$\\approx$75ms on an H100, and $\\approx$7s on a mobile edge-device, the fastest\ntext-to-audio model to our knowledge.",
      "tldr_zh": "该研究针对文本到音频系统在推理时的延迟问题，提出了一种新型对抗性加速算法Adversarial Relativistic-Contrastive (ARC) post-training，用于扩散/流动模型，而非依赖于复杂的蒸馏方法。ARC后训练扩展了相对论对抗性公式，并结合了新的对比判别器目标，以提升提示遵守和生成效率。实验结果显示，通过优化Stable Audio Open模型，该方法能在H100硬件上生成约12秒的44.1kHz立体音频仅需75ms，在移动边缘设备上生成约7秒音频，成为已知的最快文本到音频模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08175v2",
      "published_date": "2025-05-13 02:25:47 UTC",
      "updated_date": "2025-05-14 06:07:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:16.031654"
    },
    {
      "arxiv_id": "2505.08168v1",
      "title": "Exploiting Text Semantics for Few and Zero Shot Node Classification on Text-attributed Graph",
      "title_zh": "利用文本语义进行文本属性图上的少样本和零样本节点分类",
      "authors": [
        "Yuxiang Wang",
        "Xiao Yan",
        "Shiyu Jin",
        "Quanqing Xu",
        "Chuang Hu",
        "Yuanyuan Zhu",
        "Bo Du",
        "Jia Wu",
        "Jiawei Jiang"
      ],
      "abstract": "Text-attributed graph (TAG) provides a text description for each graph node,\nand few- and zero-shot node classification on TAGs have many applications in\nfields such as academia and social networks. Existing work utilizes various\ngraph-based augmentation techniques to train the node and text embeddings,\nwhile text-based augmentations are largely unexplored. In this paper, we\npropose Text Semantics Augmentation (TSA) to improve accuracy by introducing\nmore text semantic supervision signals. Specifically, we design two\naugmentation techniques, i.e., positive semantics matching and negative\nsemantics contrast, to provide more reference texts for each graph node or text\ndescription. Positive semantic matching retrieves texts with similar embeddings\nto match with a graph node. Negative semantic contrast adds a negative prompt\nto construct a text description with the opposite semantics, which is\ncontrasted with the original node and text. We evaluate TSA on 5 datasets and\ncompare with 13 state-of-the-art baselines. The results show that TSA\nconsistently outperforms all baselines, and its accuracy improvements over the\nbest-performing baseline are usually over 5%.",
      "tldr_zh": "本文针对文本属性图(Text-attributed Graph)上的少样本(Few-shot)和零样本(Zero-shot)节点分类问题，提出了一种文本语义增强方法(Text Semantics Augmentation, TSA)，通过引入更多文本语义监督信号来提升分类准确率。TSA 包括正向语义匹配(Positive Semantics Matching)，用于检索相似嵌入的参考文本，以及负向语义对比(Negative Semantics Contrast)，通过添加负面提示构建相反语义描述并进行对比。在5个数据集上的实验显示，TSA 比13个最先进基线模型的表现一致优越，通常提高超过5%的准确率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08168v1",
      "published_date": "2025-05-13 02:06:08 UTC",
      "updated_date": "2025-05-13 02:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:18.599040"
    },
    {
      "arxiv_id": "2505.08167v2",
      "title": "Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage",
      "title_zh": "融合双向思维链和奖励机制：一种增强大型语言模型针对中国非物质文化遗产问答能力的方法",
      "authors": [
        "Ruilin Liu",
        "Zhixiao Zhao",
        "Jieqiong Li",
        "Chang Liu",
        "Dongbo Wang"
      ],
      "abstract": "The rapid development of large language models (LLMs) has provided\nsignificant support and opportunities for the advancement of domain-specific\nLLMs. However, fine-tuning these large models using Intangible Cultural\nHeritage (ICH) data inevitably faces challenges such as bias, incorrect\nknowledge inheritance, and catastrophic forgetting. To address these issues, we\npropose a novel training method that integrates a bidirectional chains of\nthought and a reward mechanism. This method is built upon ICH-Qwen, a large\nlanguage model specifically designed for the field of intangible cultural\nheritage. The proposed method enables the model to not only perform forward\nreasoning but also enhances the accuracy of the generated answers by utilizing\nreverse questioning and reverse reasoning to activate the model's latent\nknowledge. Additionally, a reward mechanism is introduced during training to\noptimize the decision-making process. This mechanism improves the quality of\nthe model's outputs through structural and content evaluations with different\nweighting schemes. We conduct comparative experiments on ICH-Qwen, with results\ndemonstrating that our method outperforms 0-shot, step-by-step reasoning,\nknowledge distillation, and question augmentation methods in terms of accuracy,\nBleu-4, and Rouge-L scores on the question-answering task. Furthermore, the\npaper highlights the effectiveness of combining the bidirectional chains of\nthought and reward mechanism through ablation experiments. In addition, a\nseries of generalizability experiments are conducted, with results showing that\nthe proposed method yields improvements on various domain-specific datasets and\nadvanced models in areas such as Finance, Wikidata, and StrategyQA. This\ndemonstrates that the method is adaptable to multiple domains and provides a\nvaluable approach for model training in future applications across diverse\nfields.",
      "tldr_zh": "该研究提出了一种融合双向链式思考（bidirectional chains of thought）和奖励机制（reward mechanism）的新训练方法，旨在提升大型语言模型（LLMs）在中文非物质文化遗产（ICH）领域的问答能力，解决微调过程中的偏差、错误知识继承和灾难性遗忘问题。该方法基于ICH-Qwen模型，通过正向推理与反向质疑/推理激活模型的潜在知识，并引入奖励机制优化决策过程，以结构和内容评估提高输出质量。实验结果显示，该方法在问答任务中超越0-shot、step-by-step reasoning、knowledge distillation和question augmentation方法，在准确性、Bleu-4和Rouge-L分数上表现出色；此外，消融实验和泛化实验证明其在Finance、Wikidata和StrategyQA等领域的适用性，为多领域模型训练提供宝贵途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08167v2",
      "published_date": "2025-05-13 02:05:25 UTC",
      "updated_date": "2025-05-14 01:35:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:21.315460"
    },
    {
      "arxiv_id": "2505.08163v1",
      "title": "Decoding Neighborhood Environments with Large Language Models",
      "title_zh": "使用大型语言模型解码社区环境",
      "authors": [
        "Andrew Cart",
        "Shaohu Zhang",
        "Melanie Escue",
        "Xugui Zhou",
        "Haitao Zhao",
        "Prashanth BusiReddyGari",
        "Beiyu Lin",
        "Shuang Li"
      ],
      "abstract": "Neighborhood environments include physical and environmental conditions such\nas housing quality, roads, and sidewalks, which significantly influence human\nhealth and well-being. Traditional methods for assessing these environments,\nincluding field surveys and geographic information systems (GIS), are\nresource-intensive and challenging to evaluate neighborhood environments at\nscale. Although machine learning offers potential for automated analysis, the\nlaborious process of labeling training data and the lack of accessible models\nhinder scalability. This study explores the feasibility of large language\nmodels (LLMs) such as ChatGPT and Gemini as tools for decoding neighborhood\nenvironments (e.g., sidewalk and powerline) at scale. We train a robust\nYOLOv11-based model, which achieves an average accuracy of 99.13% in detecting\nsix environmental indicators, including streetlight, sidewalk, powerline,\napartment, single-lane road, and multilane road. We then evaluate four LLMs,\nincluding ChatGPT, Gemini, Claude, and Grok, to assess their feasibility,\nrobustness, and limitations in identifying these indicators, with a focus on\nthe impact of prompting strategies and fine-tuning. We apply majority voting\nwith the top three LLMs to achieve over 88% accuracy, which demonstrates LLMs\ncould be a useful tool to decode the neighborhood environment without any\ntraining effort.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型(LLMs)来大规模解码社区环境（如人行道和电线），以解决传统方法（如实地调查和GIS）的资源密集型问题。研究者首先训练了一个基于YOLOv11的模型，实现了99.13%的平均准确率，用于检测六种环境指标，包括街灯、单车道和多车道道路。接着，他们评估了ChatGPT、Gemini、Claude和Grok等四种LLMs的鲁棒性和局限性，重点测试提示策略和fine-tuning的影响，并通过多数投票机制达到了超过88%的识别准确率。该研究证明了LLMs无需额外训练即可作为高效工具，助力社区环境评估并提升公共健康分析。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08163v1",
      "published_date": "2025-05-13 01:54:54 UTC",
      "updated_date": "2025-05-13 01:54:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:24.904195"
    },
    {
      "arxiv_id": "2505.08158v1",
      "title": "Feature Fitted Online Conformal Prediction for Deep Time Series Forecasting Model",
      "title_zh": "特征拟合的在线保形预测用于深度时间序列预测模型",
      "authors": [
        "Xiannan Huang",
        "Shuhan Qiu"
      ],
      "abstract": "Time series forecasting is critical for many applications, where deep\nlearning-based point prediction models have demonstrated strong performance.\nHowever, in practical scenarios, there is also a need to quantify predictive\nuncertainty through online confidence intervals. Existing confidence interval\nmodeling approaches building upon these deep point prediction models suffer\nfrom key limitations: they either require costly retraining, fail to fully\nleverage the representational strengths of deep models, or lack theoretical\nguarantees. To address these gaps, we propose a lightweight conformal\nprediction method that provides valid coverage and shorter interval lengths\nwithout retraining. Our approach leverages features extracted from pre-trained\npoint prediction models to fit a residual predictor and construct confidence\nintervals, further enhanced by an adaptive coverage control mechanism.\nTheoretically, we prove that our method achieves asymptotic coverage\nconvergence, with error bounds dependent on the feature quality of the\nunderlying point prediction model. Experiments on 12 datasets demonstrate that\nour method delivers tighter confidence intervals while maintaining desired\ncoverage rates. Code, model and dataset in\n\\href{https://github.com/xiannanhuang/FFDCI}{Github}",
      "tldr_zh": "该论文提出了一种轻量级的 Feature Fitted Online Conformal Prediction 方法，用于深度时间序列预测模型，以量化预测不确定性并提供在线置信区间。该方法利用预训练点预测模型提取的特征来拟合残差预测器，并结合自适应覆盖控制机制，构建更精确的置信区间，而无需昂贵的重新训练。理论上，论文证明了该方法实现了渐近覆盖收敛，其错误边界依赖于底层模型的特征质量。实验在12个数据集上显示，该方法在保持所需覆盖率的同时，显著缩短了置信区间长度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08158v1",
      "published_date": "2025-05-13 01:33:53 UTC",
      "updated_date": "2025-05-13 01:33:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:33.432943"
    },
    {
      "arxiv_id": "2505.08157v1",
      "title": "Hyperbolic Contrastive Learning with Model-augmentation for Knowledge-aware Recommendation",
      "title_zh": "双曲对比学习结合模型增强用于知识感知推荐",
      "authors": [
        "Shengyin Sun",
        "Chen Ma"
      ],
      "abstract": "Benefiting from the effectiveness of graph neural networks (GNNs) and\ncontrastive learning, GNN-based contrastive learning has become mainstream for\nknowledge-aware recommendation. However, most existing contrastive\nlearning-based methods have difficulties in effectively capturing the\nunderlying hierarchical structure within user-item bipartite graphs and\nknowledge graphs. Moreover, they commonly generate positive samples for\ncontrastive learning by perturbing the graph structure, which may lead to a\nshift in user preference learning. To overcome these limitations, we propose\nhyperbolic contrastive learning with model-augmentation for knowledge-aware\nrecommendation. To capture the intrinsic hierarchical graph structures, we\nfirst design a novel Lorentzian knowledge aggregation mechanism, which enables\nmore effective representations of users and items. Then, we propose three\nmodel-level augmentation techniques to assist Hyperbolic contrastive learning.\nDifferent from the classical structure-level augmentation (e.g., edge\ndropping), the proposed model-augmentations can avoid preference shifts between\nthe augmented positive pair. Finally, we conduct extensive experiments to\ndemonstrate the superiority (maximum improvement of $11.03\\%$) of proposed\nmethods over existing baselines.",
      "tldr_zh": "本文提出了一种名为 Hyperbolic Contrastive Learning with Model-augmentation 的方法，用于提升知识感知推荐系统的性能。该方法通过 Lorentzian Knowledge Aggregation 机制来捕捉用户-物品二分图和知识图的内在层次结构，从而更有效地表示用户和物品特征。与传统基于结构扰动的对比学习不同，该框架引入三种模型级别增强技术，避免了用户偏好学习偏移的问题。实验结果显示，该方法在相关任务上比现有基线模型提高了最多 11.03% 的性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08157v1",
      "published_date": "2025-05-13 01:30:27 UTC",
      "updated_date": "2025-05-13 01:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:35.024131"
    },
    {
      "arxiv_id": "2505.08155v1",
      "title": "Efficient and Scalable Neural Symbolic Search for Knowledge Graph Complex Query Answering",
      "title_zh": "高效且可扩展的神经符号搜索用于知识图谱复杂查询回答",
      "authors": [
        "Weizhi Fei",
        "Zihao Wang",
        "hang Yin",
        "Shukai Zhao",
        "Wei Zhang",
        "Yangqiu Song"
      ],
      "abstract": "Complex Query Answering (CQA) aims to retrieve answer sets for complex\nlogical formulas from incomplete knowledge graphs, which is a crucial yet\nchallenging task in knowledge graph reasoning. While neuro-symbolic search\nutilized neural link predictions achieve superior accuracy, they encounter\nsignificant complexity bottlenecks: (i) Data complexity typically scales\nquadratically with the number of entities in the knowledge graph, and (ii)\nQuery complexity becomes NP-hard for cyclic queries. Consequently, these\napproaches struggle to effectively scale to larger knowledge graphs and more\ncomplex queries. To address these challenges, we propose an efficient and\nscalable symbolic search framework. First, we propose two constraint strategies\nto compute neural logical indices to reduce the domain of variables, thereby\ndecreasing the data complexity of symbolic search. Additionally, we introduce\nan approximate algorithm based on local search to tackle the NP query\ncomplexity of cyclic queries. Experiments on various CQA benchmarks demonstrate\nthat our framework reduces the computational load of symbolic methods by 90\\%\nwhile maintaining nearly the same performance, thus alleviating both efficiency\nand scalability issues.",
      "tldr_zh": "该论文针对知识图谱（Knowledge Graph）中的复杂查询回答（Complex Query Answering, CQA）任务，提出了一种高效可扩展的神经符号搜索框架，以解决现有方法在数据复杂性（随实体数量二次方增长）和查询复杂性（循环查询为 NP-hard）方面的瓶颈。框架通过两种约束策略计算神经逻辑索引，减少变量域，从而降低数据复杂性；同时引入基于局部搜索的近似算法来处理循环查询。实验在各种 CQA 基准上证明，该框架将符号方法的计算负载减少了 90%，同时保持几乎相同的性能，从而显著提升了效率和可扩展性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08155v1",
      "published_date": "2025-05-13 01:24:09 UTC",
      "updated_date": "2025-05-13 01:24:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:38.356596"
    },
    {
      "arxiv_id": "2505.08151v1",
      "title": "Foundation Models Knowledge Distillation For Battery Capacity Degradation Forecast",
      "title_zh": "基础模型知识蒸馏用于电池容量衰减预测",
      "authors": [
        "Joey Chan",
        "Zhen Chen",
        "Ershun Pan"
      ],
      "abstract": "Accurate estimation of lithium-ion battery capacity degradation is critical\nfor enhancing the reliability and safety of battery operations. Traditional\nexpert models, tailored to specific scenarios, provide isolated estimations.\nWith the rapid advancement of data-driven techniques, a series of\ngeneral-purpose time-series foundation models have been developed. However,\nfoundation models specifically designed for battery capacity degradation remain\nlargely unexplored. To enable zero-shot generalization in battery degradation\nprediction using large model technology, this study proposes a\ndegradation-aware fine-tuning strategy for time-series foundation models. We\napply this strategy to fine-tune the Timer model on approximately 10 GB of\nopen-source battery charge discharge data. Validation on our released\nCycleLife-SJTUIE dataset demonstrates that the fine-tuned Battery-Timer\npossesses strong zero-shot generalization capability in capacity degradation\nforecasting. To address the computational challenges of deploying large models,\nwe further propose a knowledge distillation framework that transfers the\nknowledge of pre-trained foundation models into compact expert models.\nDistillation results across several state-of-the-art time-series expert models\nconfirm that foundation model knowledge significantly improves the\nmulti-condition generalization of expert models.",
      "tldr_zh": "该研究针对锂离子电池容量退化预测问题，提出了一种退化感知微调策略（degradation-aware fine-tuning strategy），用于针对时间序列基础模型（foundation models）实现零样本泛化（zero-shot generalization）。他们将此策略应用于Timer模型，使用约10 GB的开源电池数据进行微调，结果显示微调后的Battery-Timer在CycleLife-SJTUIE数据集上表现出色，提升了容量退化预测的准确性。为解决大模型部署的计算挑战，该研究进一步开发了知识蒸馏框架（knowledge distillation framework），将基础模型的知识转移到紧凑的专家模型中，显著提高了专家模型的多条件泛化能力。实验验证证实，这种方法在多个状态-of-the-art时间序列专家模型上取得了积极成果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08151v1",
      "published_date": "2025-05-13 01:03:35 UTC",
      "updated_date": "2025-05-13 01:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:39.004653"
    },
    {
      "arxiv_id": "2505.08829v2",
      "title": "Aggregating Concepts of Accuracy and Fairness in Prediction Algorithms",
      "title_zh": "预测算法中准确性和公平性概念的聚合",
      "authors": [
        "David Kinney"
      ],
      "abstract": "An algorithm that outputs predictions about the state of the world will\nalmost always be designed with the implicit or explicit goal of outputting\naccurate predictions (i.e., predictions that are likely to be true). In\naddition, the rise of increasingly powerful predictive algorithms brought about\nby the recent revolution in artificial intelligence has led to an emphasis on\nbuilding predictive algorithms that are fair, in the sense that their\npredictions do not systematically evince bias or bring about harm to certain\nindividuals or groups. This state of affairs presents two conceptual\nchallenges. First, the goals of accuracy and fairness can sometimes be in\ntension, and there are no obvious normative guidelines for managing the\ntrade-offs between these two desiderata when they arise. Second, there are many\ndistinct ways of measuring both the accuracy and fairness of a predictive\nalgorithm; here too, there are no obvious guidelines on how to aggregate our\npreferences for predictive algorithms that satisfy disparate measures of\nfairness and accuracy to various extents. The goal of this paper is to address\nthese challenges by arguing that there are good reasons for using a linear\ncombination of accuracy and fairness metrics to measure the\nall-things-considered value of a predictive algorithm for agents who care about\nboth accuracy and fairness. My argument depends crucially on a classic result\nin the preference aggregation literature due to Harsanyi. After making this\nformal argument, I apply my result to an analysis of accuracy-fairness\ntrade-offs using the COMPAS dataset compiled by Angwin et al.",
      "tldr_zh": "该论文探讨了预测算法中准确性（accuracy）和公平性（fairness）的聚合问题，指出这两个目标可能相互冲突，且缺乏规范指导如何权衡。作者基于 Harsanyi 的偏好聚合经典结果，论证使用准确性和公平性指标的线性组合（linear combination）来评估算法的整体价值。最终，通过分析 COMPAS dataset，该方法为处理准确性与公平性权衡提供了实用框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08829v2",
      "published_date": "2025-05-13 01:00:25 UTC",
      "updated_date": "2025-05-15 12:19:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:40.400453"
    },
    {
      "arxiv_id": "2505.08148v1",
      "title": "A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem",
      "title_zh": "OpenAI 生态系统中自定义 GPTs 漏洞的大规模实证分析",
      "authors": [
        "Sunday Oyinlola Ogundoyin",
        "Muhammad Ikram",
        "Hassan Jameel Asghar",
        "Benjamin Zi Hao Zhao",
        "Dali Kaafar"
      ],
      "abstract": "Millions of users leverage generative pretrained transformer (GPT)-based\nlanguage models developed by leading model providers for a wide range of tasks.\nTo support enhanced user interaction and customization, many platforms-such as\nOpenAI-now enable developers to create and publish tailored model instances,\nknown as custom GPTs, via dedicated repositories or application stores. These\ncustom GPTs empower users to browse and interact with specialized applications\ndesigned to meet specific needs. However, as custom GPTs see growing adoption,\nconcerns regarding their security vulnerabilities have intensified. Existing\nresearch on these vulnerabilities remains largely theoretical, often lacking\nempirical, large-scale, and statistically rigorous assessments of associated\nrisks.\n  In this study, we analyze 14,904 custom GPTs to assess their susceptibility\nto seven exploitable threats, such as roleplay-based attacks, system prompt\nleakage, phishing content generation, and malicious code synthesis, across\nvarious categories and popularity tiers within the OpenAI marketplace. We\nintroduce a multi-metric ranking system to examine the relationship between a\ncustom GPT's popularity and its associated security risks.\n  Our findings reveal that over 95% of custom GPTs lack adequate security\nprotections. The most prevalent vulnerabilities include roleplay-based\nvulnerabilities (96.51%), system prompt leakage (92.20%), and phishing\n(91.22%). Furthermore, we demonstrate that OpenAI's foundational models exhibit\ninherent security weaknesses, which are often inherited or amplified in custom\nGPTs. These results highlight the urgent need for enhanced security measures\nand stricter content moderation to ensure the safe deployment of GPT-based\napplications.",
      "tldr_zh": "本文通过对 OpenAI 生态中的 14,904 个 custom GPTs 进行大规模实证分析，评估了七种安全漏洞，包括 roleplay-based attacks、system prompt leakage、phishing content generation 和 malicious code synthesis。研究引入多指标排名系统，考察了 custom GPTs 的流行度与风险之间的关系，发现超过 95% 的 custom GPTs 缺乏足够保护，其中 roleplay-based vulnerabilities (96.51%)、system prompt leakage (92.20%) 和 phishing (91.22%) 最常见。结果表明，OpenAI 的基础模型存在固有安全弱点，这些问题在 custom GPTs 中被继承或放大，强调了加强安全措施和内容审核的迫切需求。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08148v1",
      "published_date": "2025-05-13 00:51:07 UTC",
      "updated_date": "2025-05-13 00:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:43.544396"
    },
    {
      "arxiv_id": "2505.08828v1",
      "title": "Human-AI Collaboration or Academic Misconduct? Measuring AI Use in Student Writing Through Stylometric Evidence",
      "title_zh": "人类-AI 协作还是学术不端行为？通过文体计量证据测量学生写作中的 AI 使用",
      "authors": [
        "Eduardo Araujo Oliveira",
        "Madhavi Mohoni",
        "Sonsoles López-Pernas",
        "Mohammed Saqr"
      ],
      "abstract": "As human-AI collaboration becomes increasingly prevalent in educational\ncontexts, understanding and measuring the extent and nature of such\ninteractions pose significant challenges. This research investigates the use of\nauthorship verification (AV) techniques not as a punitive measure, but as a\nmeans to quantify AI assistance in academic writing, with a focus on promoting\ntransparency, interpretability, and student development. Building on prior\nwork, we structured our investigation into three stages: dataset selection and\nexpansion, AV method development, and systematic evaluation. Using three\ndatasets - including a public dataset (PAN-14) and two from University of\nMelbourne students from various courses - we expanded the data to include\nLLM-generated texts, totalling 1,889 documents and 540 authorship problems from\n506 students. We developed an adapted Feature Vector Difference AV methodology\nto construct robust academic writing profiles for students, designed to capture\nmeaningful, individual characteristics of their writing. The method's\neffectiveness was evaluated across multiple scenarios, including distinguishing\nbetween student-authored and LLM-generated texts and testing resilience against\nLLMs' attempts to mimic student writing styles. Results demonstrate the\nenhanced AV classifier's ability to identify stylometric discrepancies and\nmeasure human-AI collaboration at word and sentence levels while providing\neducators with a transparent tool to support academic integrity investigations.\nThis work advances AV technology, offering actionable insights into the\ndynamics of academic writing in an AI-driven era.",
      "tldr_zh": "本研究探讨了在教育环境中人类-AI 协作的程度及其对学术诚信的影响，通过 Authorship Verification (AV) 技术量化 AI 在学生写作中的辅助作用，以促进透明性、解释性和学生发展。研究分为三个阶段：数据集扩展（包括 PAN-14 和墨尔本大学学生数据集，总计 1,889 文档）、开发适应后的 Feature Vector Difference AV 方法来捕捉学生个人写作特征，以及系统评估其在区分学生写作与 LLM 生成文本方面的有效性。结果显示，该方法能准确识别风格差异，并在单词和句子级别测量人类-AI 协作，提供教育者一个透明工具，支持学术诚信调查，并为 AI 驱动时代学术写作动态带来可行动见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 10 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.08828v1",
      "published_date": "2025-05-13 00:36:36 UTC",
      "updated_date": "2025-05-13 00:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:45.226985"
    },
    {
      "arxiv_id": "2505.08143v1",
      "title": "Communication Styles and Reader Preferences of LLM and Human Experts in Explaining Health Information",
      "title_zh": "LLM 与人类专家在解释健康信息时的沟通风格和读者偏好",
      "authors": [
        "Jiawei Zhou",
        "Kritika Venkatachalam",
        "Minje Choi",
        "Koustuv Saha",
        "Munmun De Choudhury"
      ],
      "abstract": "With the wide adoption of large language models (LLMs) in information\nassistance, it is essential to examine their alignment with human communication\nstyles and values. We situate this study within the context of fact-checking\nhealth information, given the critical challenge of rectifying conceptions and\nbuilding trust. Recent studies have explored the potential of LLM for health\ncommunication, but style differences between LLMs and human experts and\nassociated reader perceptions remain under-explored. In this light, our study\nevaluates the communication styles of LLMs, focusing on how their explanations\ndiffer from those of humans in three core components of health communication:\ninformation, sender, and receiver. We compiled a dataset of 1498 health\nmisinformation explanations from authoritative fact-checking organizations and\ngenerated LLM responses to inaccurate health information. Drawing from health\ncommunication theory, we evaluate communication styles across three key\ndimensions of information linguistic features, sender persuasive strategies,\nand receiver value alignments. We further assessed human perceptions through a\nblinded evaluation with 99 participants. Our findings reveal that LLM-generated\narticles showed significantly lower scores in persuasive strategies, certainty\nexpressions, and alignment with social values and moral foundations. However,\nhuman evaluation demonstrated a strong preference for LLM content, with over\n60% responses favoring LLM articles for clarity, completeness, and\npersuasiveness. Our results suggest that LLMs' structured approach to\npresenting information may be more effective at engaging readers despite\nscoring lower on traditional measures of quality in fact-checking and health\ncommunication.",
      "tldr_zh": "本研究比较了大型语言模型(LLMs)和人类专家在解释健康信息时的沟通风格，聚焦于事实检查领域，并评估了信息语言特征、发送者说服策略以及接收者价值对齐等三个核心维度。研究者编译了1498条健康错误信息解释数据集，从权威组织获取数据并生成LLMs响应，然后通过99名参与者的 blinded evaluation 分析人类感知。结果显示，LLMs在说服策略、确定性表达和社会价值对齐上得分较低，但超过60%的受访者更青睐LLMs的内容，因为其清晰、完整和说服力，这表明LLMs的结构化方法更有效地吸引读者。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08143v1",
      "published_date": "2025-05-13 00:32:38 UTC",
      "updated_date": "2025-05-13 00:32:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:47.737880"
    },
    {
      "arxiv_id": "2505.08140v1",
      "title": "Lost in Transmission: When and Why LLMs Fail to Reason Globally",
      "title_zh": "传输中的迷失：LLMs 何时以及为什么无法进行全局推理",
      "authors": [
        "Tobias Schnabel",
        "Kiran Tomlinson",
        "Adith Swaminathan",
        "Jennifer Neville"
      ],
      "abstract": "Despite their many successes, transformer-based large language models (LLMs)\ncontinue to struggle with tasks that require complex reasoning over large parts\nof their input. We argue that these failures arise due to capacity limits on\nthe accurate flow of information within LLMs. To formalize this issue, we\nintroduce the bounded attention prefix oracle (BAPO) model, a new computational\nframework that models bandwidth constraints on attention heads, the mechanism\nfor internal communication in LLMs. We show that several important reasoning\nproblems like graph reachability require high communication bandwidth for BAPOs\nto solve; we call these problems BAPO-hard. Our experiments corroborate our\ntheoretical predictions: GPT-4, Claude, and Gemini succeed on BAPO-easy tasks\nand fail even on relatively small BAPO-hard tasks. BAPOs also reveal another\nbenefit of chain of thought (CoT): we prove that breaking down a task using CoT\ncan turn any BAPO-hard problem into a BAPO-easy one. Our results offer\nprincipled explanations for key LLM failures and suggest directions for\narchitectures and inference methods that mitigate bandwidth limits.",
      "tldr_zh": "这篇论文探讨了Transformer-based的大型语言模型(LLMs)在处理需要全局复杂推理的任务时失败的原因，归因于内部信息流动的带宽限制。作者引入了bounded attention prefix oracle (BAPO)模型来形式化注意力头的通信约束，并证明某些推理问题如图可达性是BAPO-hard，需要高带宽才能解决。实验验证显示，GPT-4、Claude和Gemini在BAPO-easy任务上表现良好，但在相对较小的BAPO-hard任务上失败；此外，chain of thought (CoT)方法能将BAPO-hard问题转化为BAPO-easy，从而缓解带宽限制。研究为解释LLMs的关键失败并指导未来架构和推理方法的改进提供了原则性见解。",
      "categories": [
        "cs.AI",
        "cs.FL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08140v1",
      "published_date": "2025-05-13 00:25:23 UTC",
      "updated_date": "2025-05-13 00:25:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:51.115274"
    },
    {
      "arxiv_id": "2505.08138v1",
      "title": "Mirror Mirror on the Wall, Have I Forgotten it All? A New Framework for Evaluating Machine Unlearning",
      "title_zh": "镜子镜子墙上的镜子，一切都忘了吗？一种评估机器遗忘的新框架",
      "authors": [
        "Brennon Brimhall",
        "Philip Mathew",
        "Neil Fendley",
        "Yinzhi Cao",
        "Matthew Green"
      ],
      "abstract": "Machine unlearning methods take a model trained on a dataset and a forget\nset, then attempt to produce a model as if it had only been trained on the\nexamples not in the forget set. We empirically show that an adversary is able\nto distinguish between a mirror model (a control model produced by retraining\nwithout the data to forget) and a model produced by an unlearning method across\nrepresentative unlearning methods from the literature. We build distinguishing\nalgorithms based on evaluation scores in the literature (i.e. membership\ninference scores) and Kullback-Leibler divergence.\n  We propose a strong formal definition for machine unlearning called\ncomputational unlearning. Computational unlearning is defined as the inability\nfor an adversary to distinguish between a mirror model and a model produced by\nan unlearning method. If the adversary cannot guess better than random (except\nwith negligible probability), then we say that an unlearning method achieves\ncomputational unlearning.\n  Our computational unlearning definition provides theoretical structure to\nprove unlearning feasibility results. For example, our computational unlearning\ndefinition immediately implies that there are no deterministic computational\nunlearning methods for entropic learning algorithms. We also explore the\nrelationship between differential privacy (DP)-based unlearning methods and\ncomputational unlearning, showing that DP-based approaches can satisfy\ncomputational unlearning at the cost of an extreme utility collapse. These\nresults demonstrate that current methodology in the literature fundamentally\nfalls short of achieving computational unlearning. We conclude by identifying\nseveral open questions for future work.",
      "tldr_zh": "该论文提出了一种新框架，用于评估机器遗忘（machine unlearning），即从训练模型中移除特定数据（forget set）后，使其表现如同仅用剩余数据训练。研究者通过经验实验证明，攻击者能使用成员推理分数（membership inference scores）和 Kullback-Leibler divergence 区分遗忘方法产生的模型与镜像模型（mirror model）。他们定义了计算遗忘（computational unlearning）作为强有力标准，即攻击者无法超越随机猜测来区分模型，并证明某些算法（如熵学习算法）无法实现确定性计算遗忘，同时差分隐私（DP）-based 方法虽可满足此标准，但会大幅降低模型实用性。最终，论文强调当前方法不足以真正实现计算遗忘，并指出未来研究的开放问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08138v1",
      "published_date": "2025-05-13 00:23:17 UTC",
      "updated_date": "2025-05-13 00:23:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:51.951898"
    },
    {
      "arxiv_id": "2505.08135v1",
      "title": "Leveraging AI for Productive and Trustworthy HPC Software: Challenges and Research Directions",
      "title_zh": "利用 AI 提升 HPC 软件生产力和可信赖性：挑战与研究方向",
      "authors": [
        "Keita Teranishi",
        "Harshitha Menon",
        "William F. Godoy",
        "Prasanna Balaprakash",
        "David Bau",
        "Tal Ben-Nun",
        "Abhinav Bathele",
        "Franz Franchetti",
        "Michael Franusich",
        "Todd Gamblin",
        "Giorgis Georgakoudis",
        "Tom Goldstein",
        "Arjun Guha",
        "Steven Hahn",
        "Costin Iancu",
        "Zheming Jin",
        "Terry Jones",
        "Tze Meng Low",
        "Het Mankad",
        "Narasinga Rao Miniskar",
        "Mohammad Alaul Haque Monil",
        "Daniel Nichols",
        "Konstantinos Parasyris",
        "Swaroop Pophale",
        "Pedro Valero-Lara",
        "Jeffrey S. Vetter",
        "Samuel Williams",
        "Aaron Young"
      ],
      "abstract": "We discuss the challenges and propose research directions for using AI to\nrevolutionize the development of high-performance computing (HPC) software. AI\ntechnologies, in particular large language models, have transformed every\naspect of software development. For its part, HPC software is recognized as a\nhighly specialized scientific field of its own. We discuss the challenges\nassociated with leveraging state-of-the-art AI technologies to develop such a\nunique and niche class of software and outline our research directions in the\ntwo US Department of Energy--funded projects for advancing HPC Software via AI:\nEllora and Durban.",
      "tldr_zh": "本论文探讨了利用 AI，特别是大型语言模型（large language models），来提升高性能计算（HPC）软件开发的生产力和可信度所面临的挑战。\n它强调了 HPC 软件作为高度专业化科学领域的独特特性，导致 AI 技术在应用中存在知识缺口和适应性问题。\n论文提出了针对这些挑战的研究方向，并概述了两个美国能源部资助的项目——Ellora 和 Durban——以推动 AI 在 HPC 软件开发中的创新和改进。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 1 Figure, Accepted at \"The 1st International Workshop on\n  Foundational Large Language Models Advances for HPC\" LLM4HPC to be held in\n  conjunction with ISC High Performance 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08135v1",
      "published_date": "2025-05-13 00:12:45 UTC",
      "updated_date": "2025-05-13 00:12:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:48:59.476727"
    },
    {
      "arxiv_id": "2505.08133v1",
      "title": "One Bad NOFO? AI Governance in Federal Grantmaking",
      "title_zh": "一个糟糕的 NOFO？联邦资助中的 AI 治理",
      "authors": [
        "Dan Bateyko",
        "Karen Levy"
      ],
      "abstract": "Much scholarship considers how U.S. federal agencies govern artificial\nintelligence (AI) through rulemaking and their own internal use policies. But\nagencies have an overlooked AI governance role: setting discretionary grant\npolicy when directing billions of dollars in federal financial assistance.\nThese dollars enable state and local entities to study, create, and use AI.\nThis funding not only goes to dedicated AI programs, but also to grantees using\nAI in the course of meeting their routine grant objectives. As discretionary\ngrantmakers, agencies guide and restrict what grant winners do -- a hidden\nlever for AI governance. Agencies pull this lever by setting program\nobjectives, judging criteria, and restrictions for AI use. Using a novel\ndataset of over 40,000 non-defense federal grant notices of funding opportunity\n(NOFOs) posted to Grants.gov between 2009 and 2024, we analyze how agencies\nregulate the use of AI by grantees. We select records mentioning AI and review\ntheir stated goals and requirements. We find agencies promoting AI in notice\nnarratives, shaping adoption in ways other records of grant policy might fail\nto capture. Of the grant opportunities that mention AI, we find only a handful\nof AI-specific judging criteria or restrictions. This silence holds even when\nagencies fund AI uses in contexts affecting people's rights and which, under an\nanalogous federal procurement regime, would result in extra oversight. These\nfindings recast grant notices as a site of AI policymaking -- albeit one that\nis developing out of step with other regulatory efforts and incomplete in its\nconsideration of transparency, accountability, and privacy protections. The\npaper concludes by drawing lessons from AI procurement scholarship, while\nidentifying distinct challenges in grantmaking that invite further study.",
      "tldr_zh": "本研究探讨了美国联邦机构在拨款政策中治理 AI 的作用，这是一个被忽略的领域，特别是通过设置项目目标、评判标准和使用限制来指导数十亿美元的联邦资助。研究者分析了一个包含 2009-2024 年超过 40,000 个非国防联邦资助机会通知 (NOFOs) 的新数据集，发现机构在通知中积极推广 AI 使用，但仅有少数机会设置了具体的 AI 评判标准或限制。即便在涉及人民权利的 AI 应用场景中，这种监管缺失与联邦采购制度下的额外监督形成对比，导致透明、问责和隐私保护方面存在缺陷。论文从 AI 采购研究中汲取教训，并强调拨款通知作为 AI 政策制定场所的独特挑战，需要进一步研究。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.5.2"
      ],
      "primary_category": "cs.CY",
      "comment": "In The 2025 ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT '25), June 23---26, 2025, Athens, Greece. 13 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08133v1",
      "published_date": "2025-05-13 00:08:22 UTC",
      "updated_date": "2025-05-13 00:08:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:49:02.044506"
    },
    {
      "arxiv_id": "2505.08130v1",
      "title": "ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval",
      "title_zh": "ALOHA：利用分层检索赋能多语言代理以支持大学导向",
      "authors": [
        "Mingxu Tao",
        "Bowen Tang",
        "Mingxuan Ma",
        "Yining Zhang",
        "Hourun Li",
        "Feifan Wen",
        "Hao Ma",
        "Jia Yang"
      ],
      "abstract": "The rise of Large Language Models~(LLMs) revolutionizes information\nretrieval, allowing users to obtain required answers through complex\ninstructions within conversations. However, publicly available services remain\ninadequate in addressing the needs of faculty and students to search\ncampus-specific information. It is primarily due to the LLM's lack of\ndomain-specific knowledge and the limitation of search engines in supporting\nmultilingual and timely scenarios. To tackle these challenges, we introduce\nALOHA, a multilingual agent enhanced by hierarchical retrieval for university\norientation. We also integrate external APIs into the front-end interface to\nprovide interactive service. The human evaluation and case study show our\nproposed system has strong capabilities to yield correct, timely, and\nuser-friendly responses to the queries in multiple languages, surpassing\ncommercial chatbots and search engines. The system has been deployed and has\nprovided service for more than 12,000 people.",
      "tldr_zh": "该研究引入了ALOHA系统，这是一个基于Hierarchical Retrieval的多语言代理框架，旨在解决Large Language Models (LLMs)在大学校园特定信息检索中的局限性，如缺乏领域知识和多语言支持。ALOHA通过分层检索和外部API整合，提供交互式服务，支持用户在对话中提出复杂查询。人类评估和案例研究表明，该系统在多语言场景下生成正确、及时且用户友好的响应，优于商业聊天机器人和搜索引擎，并已部署服务超过12,000人。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in NAACL 2025 Demo Track",
      "pdf_url": "http://arxiv.org/pdf/2505.08130v1",
      "published_date": "2025-05-13 00:01:03 UTC",
      "updated_date": "2025-05-13 00:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:49:03.277402"
    },
    {
      "arxiv_id": "2505.08129v1",
      "title": "High-order Regularization for Machine Learning and Learning-based Control",
      "title_zh": "高阶正则化用于机器学习和基于学习控制",
      "authors": [
        "Xinghua Liu",
        "Ming Cao"
      ],
      "abstract": "The paper proposes a novel regularization procedure for machine learning. The\nproposed high-order regularization (HR) provides new insight into\nregularization, which is widely used to train a neural network that can be\nutilized to approximate the action-value function in general reinforcement\nlearning problems. The proposed HR method ensures the provable convergence of\nthe approximation algorithm, which makes the much-needed connection between\nregularization and explainable learning using neural networks. The proposed HR\nmethod theoretically demonstrates that regularization can be regarded as an\napproximation in terms of inverse mapping with explicitly calculable\napproximation error, and the $L_2$ regularization is a lower-order case of the\nproposed method. We provide lower and upper bounds for the error of the\nproposed HR solution, which helps build a reliable model. We also find that\nregularization with the proposed HR can be regarded as a contraction. We prove\nthat the generalizability of neural networks can be maximized with a proper\nregularization matrix, and the proposed HR is applicable for neural networks\nwith any mapping matrix. With the theoretical explanation of the extreme\nlearning machine for neural network training and the proposed high-order\nregularization, one can better interpret the output of the neural network, thus\nleading to explainable learning. We present a case study based on regularized\nextreme learning neural networks to demonstrate the application of the proposed\nHR and give the corresponding incremental HR solution. We verify the\nperformance of the proposed HR method by solving a classic control problem in\nreinforcement learning. The result demonstrates the superior performance of the\nmethod with significant enhancement in the generalizability of the neural\nnetwork.",
      "tldr_zh": "该论文提出了一种新型的高阶正则化 (HR) 方法，用于机器学习和基于学习的控制系统，旨在训练神经网络逼近强化学习中的动作价值函数，并确保算法的收敛性。HR 通过理论证明，将正则化视为逆映射的逼近，提供可计算的逼近误差界，并证明其比 L2 正则化更高级别，能够最大化神经网络的泛化能力，同时增强模型的可解释性。实验结果显示，应用 HR 于极值学习神经网络的案例中显著提升了性能，并在强化学习控制问题上验证了其优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08129v1",
      "published_date": "2025-05-13 00:00:23 UTC",
      "updated_date": "2025-05-13 00:00:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:49:06.921035"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 134,
  "processed_papers_count": 134,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T10:49:32.725663"
}