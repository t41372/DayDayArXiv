[
  {
    "arxiv_id": "2505.09031v1",
    "title": "Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification",
    "authors": [
      "Adarsh Kumar",
      "Hwiyoon Kim",
      "Jawahar Sai Nathani",
      "Neil Roy"
    ],
    "abstract": "Hallucination, where large language models (LLMs) generate confident but incorrect or irrelevant information, remains a key limitation in their application to complex, open-ended tasks. Chain-of-thought (CoT) prompting has emerged as a promising method for improving multistep reasoning by guiding models through intermediate steps. However, CoT alone does not fully address the hallucination problem. In this work, we investigate how combining CoT with retrieval-augmented generation (RAG), as well as applying self-consistency and self-verification strategies, can reduce hallucinations and improve factual accuracy. By incorporating external knowledge sources during reasoning and enabling models to verify or revise their own outputs, we aim to generate more accurate and coherent responses. We present a comparative evaluation of baseline LLMs against CoT, CoT+RAG, self-consistency, and self-verification techniques. Our results highlight the effectiveness of each method and identify the most robust approach for minimizing hallucinations while preserving fluency and reasoning depth.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.09031v1",
    "published_date": "2025-05-13 23:57:02 UTC",
    "updated_date": "2025-05-13 23:57:02 UTC"
  },
  {
    "arxiv_id": "2505.09029v1",
    "title": "Monte Carlo Beam Search for Actor-Critic Reinforcement Learning in Continuous Control",
    "authors": [
      "Hazim Alzorgan",
      "Abolfazl Razi"
    ],
    "abstract": "Actor-critic methods, like Twin Delayed Deep Deterministic Policy Gradient (TD3), depend on basic noise-based exploration, which can result in less than optimal policy convergence. In this study, we introduce Monte Carlo Beam Search (MCBS), a new hybrid method that combines beam search and Monte Carlo rollouts with TD3 to improve exploration and action selection. MCBS produces several candidate actions around the policy's output and assesses them through short-horizon rollouts, enabling the agent to make better-informed choices. We test MCBS across various continuous-control benchmarks, including HalfCheetah-v4, Walker2d-v5, and Swimmer-v5, showing enhanced sample efficiency and performance compared to standard TD3 and other baseline methods like SAC, PPO, and A2C. Our findings emphasize MCBS's capability to enhance policy learning through structured look-ahead search while ensuring computational efficiency. Additionally, we offer a detailed analysis of crucial hyperparameters, such as beam width and rollout depth, and explore adaptive strategies to optimize MCBS for complex control tasks. Our method shows a higher convergence rate across different environments compared to TD3, SAC, PPO, and A2C. For instance, we achieved 90% of the maximum achievable reward within around 200 thousand timesteps compared to 400 thousand timesteps for the second-best method.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.09029v1",
    "published_date": "2025-05-13 23:56:12 UTC",
    "updated_date": "2025-05-13 23:56:12 UTC"
  },
  {
    "arxiv_id": "2505.09027v1",
    "title": "Tests as Prompt: A Test-Driven-Development Benchmark for LLM Code Generation",
    "authors": [
      "Yi Cui"
    ],
    "abstract": "We introduce WebApp1K, a novel benchmark for evaluating large language models (LLMs) in test-driven development (TDD) tasks, where test cases serve as both prompt and verification for code generation. Unlike traditional approaches relying on natural language prompts, our benchmark emphasizes the ability of LLMs to interpret and implement functionality directly from test cases, reflecting real-world software development practices. Comprising 1000 diverse challenges across 20 application domains, the benchmark evaluates LLMs on their ability to generate compact, functional code under the constraints of context length and multi-feature complexity. Our findings highlight instruction following and in-context learning as critical capabilities for TDD success, surpassing the importance of general coding proficiency or pretraining knowledge. Through comprehensive evaluation of 19 frontier models, we reveal performance bottlenecks, such as instruction loss in long prompts, and provide a detailed error analysis spanning multiple root causes. This work underscores the practical value of TDD-specific benchmarks and lays the foundation for advancing LLM capabilities in rigorous, application-driven coding scenarios.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "arXiv admin note: text overlap with arXiv:2409.05177",
    "pdf_url": "https://arxiv.org/pdf/2505.09027v1",
    "published_date": "2025-05-13 23:47:12 UTC",
    "updated_date": "2025-05-13 23:47:12 UTC"
  },
  {
    "arxiv_id": "2505.09024v1",
    "title": "Automated Meta Prompt Engineering for Alignment with the Theory of Mind",
    "authors": [
      "Aaron Baughman",
      "Rahul Agarwal",
      "Eduardo Morales",
      "Gozde Akay"
    ],
    "abstract": "We introduce a method of meta-prompting that jointly produces fluent text for complex tasks while optimizing the similarity of neural states between a human's mental expectation and a Large Language Model's (LLM) neural processing. A technique of agentic reinforcement learning is applied, in which an LLM as a Judge (LLMaaJ) teaches another LLM, through in-context learning, how to produce content by interpreting the intended and unintended generated text traits. To measure human mental beliefs around content production, users modify long form AI-generated text articles before publication at the US Open 2024 tennis Grand Slam. Now, an LLMaaJ can solve the Theory of Mind (ToM) alignment problem by anticipating and including human edits within the creation of text from an LLM. Throughout experimentation and by interpreting the results of a live production system, the expectations of human content reviewers had 100% of alignment with AI 53.8% of the time with an average iteration count of 4.38. The geometric interpretation of content traits such as factualness, novelty, repetitiveness, and relevancy over a Hilbert vector space combines spatial volume (all trait importance) with vertices alignment (individual trait relevance) enabled the LLMaaJ to optimize on Human ToM. This resulted in an increase in content quality by extending the coverage of tennis action. Our work that was deployed at the US Open 2024 has been used across other live events within sports and entertainment.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 6 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.09024v1",
    "published_date": "2025-05-13 23:42:36 UTC",
    "updated_date": "2025-05-13 23:42:36 UTC"
  },
  {
    "arxiv_id": "2505.09022v1",
    "title": "Block-Biased Mamba for Long-Range Sequence Processing",
    "authors": [
      "Annan Yu",
      "N. Benjamin Erichson"
    ],
    "abstract": "Mamba extends earlier state space models (SSMs) by introducing input-dependent dynamics, and has demonstrated strong empirical performance across a range of domains, including language modeling, computer vision, and foundation models. However, a surprising weakness remains: despite being built on architectures designed for long-range dependencies, Mamba performs poorly on long-range sequential tasks. Understanding and addressing this gap is important for improving Mamba's universality and versatility. In this work, we analyze Mamba's limitations through three perspectives: expressiveness, inductive bias, and training stability. Our theoretical results show how Mamba falls short in each of these aspects compared to earlier SSMs such as S4D. To address these issues, we propose $\\text{B}_2\\text{S}_6$, a simple extension of Mamba's S6 unit that combines block-wise selective dynamics with a channel-specific bias. We prove that these changes equip the model with a better-suited inductive bias and improve its expressiveness and stability. Empirically, $\\text{B}_2\\text{S}_6$ outperforms S4 and S4D on Long-Range Arena (LRA) tasks while maintaining Mamba's performance on language modeling benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.09022v1",
    "published_date": "2025-05-13 23:34:09 UTC",
    "updated_date": "2025-05-13 23:34:09 UTC"
  },
  {
    "arxiv_id": "2505.09021v1",
    "title": "AI-Mediated Code Comment Improvement",
    "authors": [
      "Maria Dhakal",
      "Chia-Yi Su",
      "Robert Wallace",
      "Chris Fakhimi",
      "Aakash Bansal",
      "Toby Li",
      "Yu Huang",
      "Collin McMillan"
    ],
    "abstract": "This paper describes an approach to improve code comments along different quality axes by rewriting those comments with customized Artificial Intelligence (AI)-based tools. We conduct an empirical study followed by grounded theory qualitative analysis to determine the quality axes to improve. Then we propose a procedure using a Large Language Model (LLM) to rewrite existing code comments along the quality axes. We implement our procedure using GPT-4o, then distil the results into a smaller model capable of being run in-house, so users can maintain data custody. We evaluate both our approach using GPT-4o and the distilled model versions. We show in an evaluation how our procedure improves code comments along the quality axes. We release all data and source code in an online repository for reproducibility.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.09021v1",
    "published_date": "2025-05-13 23:31:32 UTC",
    "updated_date": "2025-05-13 23:31:32 UTC"
  },
  {
    "arxiv_id": "2505.09012v1",
    "title": "Deep Reinforcement Learning for Power Grid Multi-Stage Cascading Failure Mitigation",
    "authors": [
      "Bo Meng",
      "Chenghao Xu",
      "Yongli Zhu"
    ],
    "abstract": "Cascading failures in power grids can lead to grid collapse, causing severe disruptions to social operations and economic activities. In certain cases, multi-stage cascading failures can occur. However, existing cascading-failure-mitigation strategies are usually single-stage-based, overlooking the complexity of the multi-stage scenario. This paper treats the multi-stage cascading failure problem as a reinforcement learning task and develops a simulation environment. The reinforcement learning agent is then trained via the deterministic policy gradient algorithm to achieve continuous actions. Finally, the effectiveness of the proposed approach is validated on the IEEE 14-bus and IEEE 118-bus systems.",
    "categories": [
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore, Apr. 28, 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.09012v1",
    "published_date": "2025-05-13 23:01:34 UTC",
    "updated_date": "2025-05-13 23:01:34 UTC"
  },
  {
    "arxiv_id": "2505.09003v1",
    "title": "Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition",
    "authors": [
      "Zeki Doruk Erden",
      "Donia Gasmi",
      "Boi Faltings"
    ],
    "abstract": "Continual learning for reinforcement learning agents remains a significant challenge, particularly in preserving and leveraging existing information without an external signal to indicate changes in tasks or environments. In this study, we explore the effectiveness of autoencoders in detecting new tasks and matching observed environments to previously encountered ones. Our approach integrates policy optimization with familiarity autoencoders within an end-to-end continual learning system. This system can recognize and learn new tasks or environments while preserving knowledge from earlier experiences and can selectively retrieve relevant knowledge when re-encountering a known environment. Initial results demonstrate successful continual learning without external signals to indicate task changes or reencounters, showing promise for this methodology.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in the Autonomous Robots and Multirobot Systems (ARMS) workshop at AAMAS 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.09003v1",
    "published_date": "2025-05-13 22:38:54 UTC",
    "updated_date": "2025-05-13 22:38:54 UTC"
  },
  {
    "arxiv_id": "2505.08995v1",
    "title": "Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning",
    "authors": [
      "Ardian Selmonaj",
      "Oleg Szehr",
      "Giacomo Del Rio",
      "Alessandro Antonucci",
      "Adrian Schneider",
      "Michael Rüegsegger"
    ],
    "abstract": "This work presents a Hierarchical Multi-Agent Reinforcement Learning framework for analyzing simulated air combat scenarios involving heterogeneous agents. The objective is to identify effective Courses of Action that lead to mission success within preset simulations, thereby enabling the exploration of real-world defense scenarios at low cost and in a safe-to-fail setting. Applying deep Reinforcement Learning in this context poses specific challenges, such as complex flight dynamics, the exponential size of the state and action spaces in multi-agent systems, and the capability to integrate real-time control of individual units with look-ahead planning. To address these challenges, the decision-making process is split into two levels of abstraction: low-level policies control individual units, while a high-level commander policy issues macro commands aligned with the overall mission targets. This hierarchical structure facilitates the training process by exploiting policy symmetries of individual agents and by separating control from command tasks. The low-level policies are trained for individual combat control in a curriculum of increasing complexity. The high-level commander is then trained on mission targets given pre-trained control policies. The empirical validation confirms the advantages of the proposed framework.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as journal chapter in Deep Learning Applications, Vol. 1, by Taylor & Francis",
    "pdf_url": "https://arxiv.org/pdf/2505.08995v1",
    "published_date": "2025-05-13 22:13:48 UTC",
    "updated_date": "2025-05-13 22:13:48 UTC"
  },
  {
    "arxiv_id": "2505.08988v1",
    "title": "Generalization in Monitored Markov Decision Processes (Mon-MDPs)",
    "authors": [
      "Montaser Mohammedalamen",
      "Michael Bowling"
    ],
    "abstract": "Reinforcement learning (RL) typically models the interaction between the agent and environment as a Markov decision process (MDP), where the rewards that guide the agent's behavior are always observable. However, in many real-world scenarios, rewards are not always observable, which can be modeled as a monitored Markov decision process (Mon-MDP). Prior work on Mon-MDPs have been limited to simple, tabular cases, restricting their applicability to real-world problems. This work explores Mon-MDPs using function approximation (FA) and investigates the challenges involved. We show that combining function approximation with a learned reward model enables agents to generalize from monitored states with observable rewards, to unmonitored environment states with unobservable rewards. Therefore, we demonstrate that such generalization with a reward model achieves near-optimal policies in environments formally defined as unsolvable. However, we identify a critical limitation of such function approximation, where agents incorrectly extrapolate rewards due to overgeneralization, resulting in undesirable behaviors. To mitigate overgeneralization, we propose a cautious police optimization method leveraging reward uncertainty. This work serves as a step towards bridging this gap between Mon-MDP theory and real-world applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under Review",
    "pdf_url": "https://arxiv.org/pdf/2505.08988v1",
    "published_date": "2025-05-13 21:58:25 UTC",
    "updated_date": "2025-05-13 21:58:25 UTC"
  },
  {
    "arxiv_id": "2505.13487v2",
    "title": "Detecting Prefix Bias in LLM-based Reward Models",
    "authors": [
      "Ashwin Kumar",
      "Yuzi He",
      "Aram H. Markosyan",
      "Bobbie Chern",
      "Imanol Arrieta-Ibarra"
    ],
    "abstract": "Reinforcement Learning with Human Feedback (RLHF) has emerged as a key paradigm for task-specific fine-tuning of language models using human preference data. While numerous publicly available preference datasets provide pairwise comparisons of responses, the potential for biases in the resulting reward models remains underexplored. In this work, we introduce novel methods to detect and evaluate prefix bias -- a systematic shift in model preferences triggered by minor variations in query prefixes -- in LLM-based reward models trained on such datasets. We leverage these metrics to reveal significant biases in preference models across racial and gender dimensions. Our comprehensive evaluation spans diverse open-source preference datasets and reward model architectures, demonstrating susceptibility to this kind of bias regardless of the underlying model architecture. Furthermore, we propose a data augmentation strategy to mitigate these biases, showing its effectiveness in reducing the impact of prefix bias. Our findings highlight the critical need for bias-aware dataset design and evaluation in developing fair and reliable reward models, contributing to the broader discourse on fairness in AI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.13487v2",
    "published_date": "2025-05-13 21:50:03 UTC",
    "updated_date": "2025-06-19 04:38:26 UTC"
  },
  {
    "arxiv_id": "2505.08964v1",
    "title": "GPML: Graph Processing for Machine Learning",
    "authors": [
      "Majed Jaber",
      "Julien Michel",
      "Nicolas Boutry",
      "Pierre Parrend"
    ],
    "abstract": "The dramatic increase of complex, multi-step, and rapidly evolving attacks in dynamic networks involves advanced cyber-threat detectors. The GPML (Graph Processing for Machine Learning) library addresses this need by transforming raw network traffic traces into graph representations, enabling advanced insights into network behaviors. The library provides tools to detect anomalies in interaction and community shifts in dynamic networks. GPML supports community and spectral metrics extraction, enhancing both real-time detection and historical forensics analysis. This library supports modern cybersecurity challenges with a robust, graph-based approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08964v1",
    "published_date": "2025-05-13 21:10:46 UTC",
    "updated_date": "2025-05-13 21:10:46 UTC"
  },
  {
    "arxiv_id": "2505.08939v1",
    "title": "Tracing the Invisible: Understanding Students' Judgment in AI-Supported Design Work",
    "authors": [
      "Suchismita Naik",
      "Prakash Shukla",
      "Ike Obi",
      "Jessica Backus",
      "Nancy Rasche",
      "Paul Parsons"
    ],
    "abstract": "As generative AI tools become integrated into design workflows, students increasingly engage with these tools not just as aids, but as collaborators. This study analyzes reflections from 33 student teams in an HCI design course to examine the kinds of judgments students make when using AI tools. We found both established forms of design judgment (e.g., instrumental, appreciative, quality) and emergent types: agency-distribution judgment and reliability judgment. These new forms capture how students negotiate creative responsibility with AI and assess the trustworthiness of its outputs. Our findings suggest that generative AI introduces new layers of complexity into design reasoning, prompting students to reflect not only on what AI produces, but also on how and when to rely on it. By foregrounding these judgments, we offer a conceptual lens for understanding how students engage in co-creative sensemaking with AI in design contexts.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "5 pages, 2 Tables, In Creativity and Cognition 2025, June 23--25, 2025, Virtual, United Kingdom",
    "pdf_url": "https://arxiv.org/pdf/2505.08939v1",
    "published_date": "2025-05-13 20:08:10 UTC",
    "updated_date": "2025-05-13 20:08:10 UTC"
  },
  {
    "arxiv_id": "2505.08919v2",
    "title": "Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions",
    "authors": [
      "Kangxian Xie",
      "Yufei Zhu",
      "Kaiming Kuang",
      "Li Zhang",
      "Hongwei Bran Li",
      "Mingchen Gao",
      "Jiancheng Yang"
    ],
    "abstract": "High-quality 3D reconstruction of pulmonary segments plays a crucial role in segmentectomy and surgical planning for the treatment of lung cancer. Due to the resolution requirement of the target reconstruction, conventional deep learning-based methods often suffer from computational resource constraints or limited granularity. Conversely, implicit modeling is favored due to its computational efficiency and continuous representation at any resolution. We propose a neural implicit function-based method to learn a 3D surface to achieve anatomy-aware, precise pulmonary segment reconstruction, represented as a shape by deforming a learnable template. Additionally, we introduce two clinically relevant evaluation metrics to comprehensively assess the quality of the reconstruction. Furthermore, to address the lack of publicly available shape datasets for benchmarking reconstruction algorithms, we developed a shape dataset named Lung3D, which includes the 3D models of 800 labeled pulmonary segments and their corresponding airways, arteries, veins, and intersegmental veins. We demonstrate that the proposed approach outperforms existing methods, providing a new perspective for pulmonary segment reconstruction. Code and data will be available at https://github.com/HINTLab/ImPulSe.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "Manuscript accepted by Medical Image Analysis, 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08919v2",
    "published_date": "2025-05-13 19:31:01 UTC",
    "updated_date": "2025-12-15 18:56:33 UTC"
  },
  {
    "arxiv_id": "2505.08918v1",
    "title": "When repeats drive the vocabulary: a Byte-Pair Encoding analysis of T2T primate genomes",
    "authors": [
      "Marina Popova",
      "Iaroslav Chelombitko",
      "Aleksey Komissarov"
    ],
    "abstract": "The emergence of telomere-to-telomere (T2T) genome assemblies has opened new avenues for comparative genomics, yet effective tokenization strategies for genomic sequences remain underexplored. In this pilot study, we apply Byte Pair Encoding (BPE) to nine T2T primate genomes including three human assemblies by training independent BPE tokenizers with a fixed vocabulary of 512,000 tokens using our custom tool, dnaBPE. Our analysis reveals that only 11,569 tokens are shared across all assemblies, while nearly 991,854 tokens are unique to a single genome, indicating a rapid decline in shared vocabulary with increasing assembly comparisons. Moreover, phylogenetic trees derived from token overlap failed to recapitulate established primate relationships, a discrepancy attributed to the disproportionate influence of species-specific high-copy repetitive elements. These findings underscore the dual nature of BPE tokenization: while it effectively compresses repetitive sequences, its sensitivity to high-copy elements limits its utility as a universal tool for comparative genomics. We discuss potential hybrid strategies and repeat-masking approaches to refine genomic tokenization, emphasizing the need for domain-specific adaptations in the development of large-scale genomic language models. The dnaBPE tool used in this study is open-source and available at https://github.com/aglabx/dnaBPE.",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "ICLR 2025 Workshop on Machine Learning for Genomics Explorations",
    "pdf_url": "https://arxiv.org/pdf/2505.08918v1",
    "published_date": "2025-05-13 19:27:58 UTC",
    "updated_date": "2025-05-13 19:27:58 UTC"
  },
  {
    "arxiv_id": "2505.08916v1",
    "title": "A New Tractable Description Logic under Categorical Semantics",
    "authors": [
      "Chan Le Duc",
      "Ludovic Brieulle"
    ],
    "abstract": "Biomedical ontologies contain numerous concept or role names involving negative knowledge such as lacks_part, absence_of. Such a representation with labels rather than logical constructors would not allow a reasoner to interpret lacks_part as a kind of negation of has_part. It is known that adding negation to the tractable Description Logic (DL) EL allowing for conjunction, existential restriction and concept inclusion makes it intractable since the obtained logic includes implicitly disjunction and universal restriction which interact with other constructors. In this paper, we propose a new extension of EL with a weakened negation allowing to represent negative knowledge while retaining tractability. To this end, we introduce categorical semantics of all logical constructors of the DL SH including EL with disjunction, negation, universal restriction, role inclusion and transitive roles. The categorical semantics of a logical constructor is usually described as a set of categorical properties referring to several objects without using set membership. To restore tractability, we have to weaken semantics of disjunction and universal restriction by identifying \\emph{independent} categorical properties that are responsible for intractability, and dropping them from the set of categorical properties. We show that the logic resulting from weakening semantics is more expressive than EL with the bottom concept, transitive roles and role inclusion.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08916v1",
    "published_date": "2025-05-13 19:25:21 UTC",
    "updated_date": "2025-05-13 19:25:21 UTC"
  },
  {
    "arxiv_id": "2505.09653v1",
    "title": "Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation",
    "authors": [
      "Samuel Yen-Chi Chen",
      "Chen-Yu Liu",
      "Kuan-Cheng Chen",
      "Wei-Jia Huang",
      "Yen-Jui Chang",
      "Wei-Hao Huang"
    ],
    "abstract": "The rapid advancements in quantum computing (QC) and machine learning (ML) have led to the emergence of quantum machine learning (QML), which integrates the strengths of both fields. Among QML approaches, variational quantum circuits (VQCs), also known as quantum neural networks (QNNs), have shown promise both empirically and theoretically. However, their broader adoption is hindered by reliance on quantum hardware during inference. Hardware imperfections and limited access to quantum devices pose practical challenges. To address this, the Quantum-Train (QT) framework leverages the exponential scaling of quantum amplitudes to generate classical neural network parameters, enabling inference without quantum hardware and achieving significant parameter compression. Yet, designing effective quantum circuit architectures for such quantum-enhanced neural programmers remains non-trivial and often requires expertise in quantum information science. In this paper, we propose an automated solution using differentiable optimization. Our method jointly optimizes both conventional circuit parameters and architectural parameters in an end-to-end manner via automatic differentiation. We evaluate the proposed framework on classification, time-series prediction, and reinforcement learning tasks. Simulation results show that our method matches or outperforms manually designed QNN architectures. This work offers a scalable and automated pathway for designing QNNs that can generate classical neural network parameters across diverse applications.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.09653v1",
    "published_date": "2025-05-13 19:01:08 UTC",
    "updated_date": "2025-05-13 19:01:08 UTC"
  },
  {
    "arxiv_id": "2505.08905v2",
    "title": "Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora",
    "authors": [
      "Michael Majurski",
      "Cynthia Matuszek"
    ],
    "abstract": "Language Models (LMs) continue to advance, improving response quality and coherence. Given Internet-scale training datasets, LMs have likely encountered much of what users may ask them to generate in some form during their training. A plethora of evaluation benchmarks have been constructed to assess model quality, response appropriateness, and reasoning capabilities. However, the human effort required for benchmark construction is rapidly being outpaced by the size and scope of the models under evaluation. Having humans build a benchmark for every possible domain of interest is impractical. Therefore, we propose a methodology for automating the construction of fact-based synthetic data model evaluations grounded in document populations. This work leverages the same LMs to evaluate domain-specific knowledge automatically, using only grounding documents (e.g., a textbook) as input. This synthetic data benchmarking approach corresponds well with human curated questions producing a Spearman ranking correlation of 0.97 and a benchmark evaluation Pearson accuracy correlation of 0.75. This novel approach supports generating both multiple choice and open-ended synthetic data questions to gain diagnostic insight of LM capability. We apply this methodology to evaluate model performance on two recent arXiv preprints, discovering a surprisingly strong performance from Gemma-3 models on open-ended questions. Code is available at https://github.com/mmajurski/grounded-synth-lm-benchmark",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08905v2",
    "published_date": "2025-05-13 18:50:03 UTC",
    "updated_date": "2025-05-16 01:35:01 UTC"
  },
  {
    "arxiv_id": "2505.08904v1",
    "title": "FareShare: A Tool for Labor Organizers to Estimate Lost Wages and Contest Arbitrary AI and Algorithmic Deactivations",
    "authors": [
      "Varun Nagaraj Rao",
      "Samantha Dalal",
      "Andrew Schwartz",
      "Amna Liaqat",
      "Dana Calacci",
      "Andrés Monroy-Hernández"
    ],
    "abstract": "What happens when a rideshare driver is suddenly locked out of the platform connecting them to riders, wages, and daily work? Deactivation-the abrupt removal of gig workers' platform access-typically occurs through arbitrary AI and algorithmic decisions with little explanation or recourse. This represents one of the most severe forms of algorithmic control and often devastates workers' financial stability. Recent U.S. state policies now mandate appeals processes and recovering compensation during the period of wrongful deactivation based on past earnings. Yet, labor organizers still lack effective tools to support these complex, error-prone workflows. We designed FareShare, a computational tool automating lost wage estimation for deactivated drivers, through a 6 month partnership with the State of Washington's largest rideshare labor union. Over the following 3 months, our field deployment of FareShare registered 178 account signups. We observed that the tool could reduce lost wage calculation time by over 95%, eliminate manual data entry errors, and enable legal teams to generate arbitration-ready reports more efficiently. Beyond these gains, the deployment also surfaced important socio-technical challenges around trust, consent, and tool adoption in high-stakes labor contexts.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08904v1",
    "published_date": "2025-05-13 18:46:47 UTC",
    "updated_date": "2025-05-13 18:46:47 UTC"
  },
  {
    "arxiv_id": "2505.08902v1",
    "title": "Performance Gains of LLMs With Humans in a World of LLMs Versus Humans",
    "authors": [
      "Lucas McCullum",
      "Pelagie Ami Agassi",
      "Leo Anthony Celi",
      "Daniel K. Ebner",
      "Chrystinne Oliveira Fernandes",
      "Rachel S. Hicklen",
      "Mkliwa Koumbia",
      "Lisa Soleymani Lehmann",
      "David Restrepo"
    ],
    "abstract": "Currently, a considerable research effort is devoted to comparing LLMs to a group of human experts, where the term \"expert\" is often ill-defined or variable, at best, in a state of constantly updating LLM releases. Without proper safeguards in place, LLMs will threaten to cause harm to the established structure of safe delivery of patient care which has been carefully developed throughout history to keep the safety of the patient at the forefront. A key driver of LLM innovation is founded on community research efforts which, if continuing to operate under \"humans versus LLMs\" principles, will expedite this trend. Therefore, research efforts moving forward must focus on effectively characterizing the safe use of LLMs in clinical settings that persist across the rapid development of novel LLM models. In this communication, we demonstrate that rather than comparing LLMs to humans, there is a need to develop strategies enabling efficient work of humans with LLMs in an almost symbiotic manner.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08902v1",
    "published_date": "2025-05-13 18:44:22 UTC",
    "updated_date": "2025-05-13 18:44:22 UTC"
  },
  {
    "arxiv_id": "2505.08896v1",
    "title": "Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections",
    "authors": [
      "Pankaj Kumar",
      "Aditya Mishra",
      "Pranamesh Chakraborty",
      "Subrahmanya Swamy Peruru"
    ],
    "abstract": "Developing an autonomous vehicle control strategy for signalised intersections (SI) is one of the challenging tasks due to its inherently complex decision-making process. This study proposes a Deep Reinforcement Learning (DRL) based longitudinal vehicle control strategy at SI. A comprehensive reward function has been formulated with a particular focus on (i) distance headway-based efficiency reward, (ii) decision-making criteria during amber light, and (iii) asymmetric acceleration/ deceleration response, along with the traditional safety and comfort criteria. This reward function has been incorporated with two popular DRL algorithms, Deep Deterministic Policy Gradient (DDPG) and Soft-Actor Critic (SAC), which can handle the continuous action space of acceleration/deceleration. The proposed models have been trained on the combination of real-world leader vehicle (LV) trajectories and simulated trajectories generated using the Ornstein-Uhlenbeck (OU) process. The overall performance of the proposed models has been tested using Cumulative Distribution Function (CDF) plots and compared with the real-world trajectory data. The results show that the RL models successfully maintain lower distance headway (i.e., higher efficiency) and jerk compared to human-driven vehicles without compromising safety. Further, to assess the robustness of the proposed models, we evaluated the model performance on diverse safety-critical scenarios, in terms of car-following and traffic signal compliance. Both DDPG and SAC models successfully handled the critical scenarios, while the DDPG model showed smoother action profiles compared to the SAC model. Overall, the results confirm that DRL-based longitudinal vehicle control strategy at SI can help to improve traffic safety, efficiency, and comfort.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08896v1",
    "published_date": "2025-05-13 18:38:42 UTC",
    "updated_date": "2025-05-13 18:38:42 UTC"
  },
  {
    "arxiv_id": "2505.08894v1",
    "title": "WaLLM -- Insights from an LLM-Powered Chatbot deployment via WhatsApp",
    "authors": [
      "Hiba Eltigani",
      "Rukhshan Haroon",
      "Asli Kocak",
      "Abdullah Bin Faisal",
      "Noah Martin",
      "Fahad Dogar"
    ],
    "abstract": "Recent advances in generative AI, such as ChatGPT, have transformed access to information in education, knowledge-seeking, and everyday decision-making. However, in many developing regions, access remains a challenge due to the persistent digital divide. To help bridge this gap, we developed WaLLM - a custom AI chatbot over WhatsApp, a widely used communication platform in developing regions. Beyond answering queries, WaLLM offers several features to enhance user engagement: a daily top question, suggested follow-up questions, trending and recent queries, and a leaderboard-based reward system. Our service has been operational for over 6 months, amassing over 14.7K queries from approximately 100 users. In this paper, we present WaLLM's design and a systematic analysis of logs to understand user interactions. Our results show that 55% of user queries seek factual information. \"Health and well-being\" was the most popular topic (28%), including queries about nutrition and disease, suggesting users view WaLLM as a reliable source. Two-thirds of users' activity occurred within 24 hours of the daily top question. Users who accessed the \"Leaderboard\" interacted with WaLLM 3x as those who did not. We conclude by discussing implications for culture-based customization, user interface design, and appropriate calibration of users' trust in AI systems for developing regions.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08894v1",
    "published_date": "2025-05-13 18:36:18 UTC",
    "updated_date": "2025-05-13 18:36:18 UTC"
  },
  {
    "arxiv_id": "2505.08878v1",
    "title": "Optimized Couplings for Watermarking Large Language Models",
    "authors": [
      "Dor Tsur",
      "Carol Xuan Long",
      "Claudio Mayrink Verdun",
      "Hsiang Hsu",
      "Haim Permuter",
      "Flavio P. Calmon"
    ],
    "abstract": "Large-language models (LLMs) are now able to produce text that is, in many cases, seemingly indistinguishable from human-generated content. This has fueled the development of watermarks that imprint a ``signal'' in LLM-generated text with minimal perturbation of an LLM's output. This paper provides an analysis of text watermarking in a one-shot setting. Through the lens of hypothesis testing with side information, we formulate and analyze the fundamental trade-off between watermark detection power and distortion in generated textual quality. We argue that a key component in watermark design is generating a coupling between the side information shared with the watermark detector and a random partition of the LLM vocabulary. Our analysis identifies the optimal coupling and randomization strategy under the worst-case LLM next-token distribution that satisfies a min-entropy constraint. We provide a closed-form expression of the resulting detection rate under the proposed scheme and quantify the cost in a max-min sense. Finally, we provide an array of numerical results, comparing the proposed scheme with the theoretical optimum and existing schemes, in both synthetic data and LLM watermarking. Our code is available at https://github.com/Carol-Long/CC_Watermark",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.IT"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at ISIT25",
    "pdf_url": "https://arxiv.org/pdf/2505.08878v1",
    "published_date": "2025-05-13 18:08:12 UTC",
    "updated_date": "2025-05-13 18:08:12 UTC"
  },
  {
    "arxiv_id": "2505.08854v1",
    "title": "Generative AI for Autonomous Driving: Frontiers and Opportunities",
    "authors": [
      "Yuping Wang",
      "Shuo Xing",
      "Cui Can",
      "Renjie Li",
      "Hongyuan Hua",
      "Kexin Tian",
      "Zhaobin Mo",
      "Xiangbo Gao",
      "Keshu Wu",
      "Sulong Zhou",
      "Hengxu You",
      "Juntong Peng",
      "Junge Zhang",
      "Zehao Wang",
      "Rui Song",
      "Mingxuan Yan",
      "Walter Zimmer",
      "Xingcheng Zhou",
      "Peiran Li",
      "Zhaohan Lu",
      "Chia-Ju Chen",
      "Yue Huang",
      "Ryan A. Rossi",
      "Lichao Sun",
      "Hongkai Yu",
      "Zhiwen Fan",
      "Frank Hao Yang",
      "Yuhao Kang",
      "Ross Greer",
      "Chenxi Liu",
      "Eun Hak Lee",
      "Xuan Di",
      "Xinyue Ye",
      "Liu Ren",
      "Alois Knoll",
      "Xiaopeng Li",
      "Shuiwang Ji",
      "Masayoshi Tomizuka",
      "Marco Pavone",
      "Tianbao Yang",
      "Jing Du",
      "Ming-Hsuan Yang",
      "Hua Wei",
      "Ziran Wang",
      "Yang Zhou",
      "Jiachen Li",
      "Zhengzhong Tu"
    ],
    "abstract": "Generative Artificial Intelligence (GenAI) constitutes a transformative technological wave that reconfigures industries through its unparalleled capabilities for content creation, reasoning, planning, and multimodal understanding. This revolutionary force offers the most promising path yet toward solving one of engineering's grandest challenges: achieving reliable, fully autonomous driving, particularly the pursuit of Level 5 autonomy. This survey delivers a comprehensive and critical synthesis of the emerging role of GenAI across the autonomous driving stack. We begin by distilling the principles and trade-offs of modern generative modeling, encompassing VAEs, GANs, Diffusion Models, and Large Language Models (LLMs). We then map their frontier applications in image, LiDAR, trajectory, occupancy, video generation as well as LLM-guided reasoning and decision making. We categorize practical applications, such as synthetic data workflows, end-to-end driving strategies, high-fidelity digital twin systems, smart transportation networks, and cross-domain transfer to embodied AI. We identify key obstacles and possibilities such as comprehensive generalization across rare cases, evaluation and safety checks, budget-limited implementation, regulatory compliance, ethical concerns, and environmental effects, while proposing research plans across theoretical assurances, trust metrics, transport integration, and socio-technical influence. By unifying these threads, the survey provides a forward-looking reference for researchers, engineers, and policymakers navigating the convergence of generative AI and advanced autonomous mobility. An actively maintained repository of cited works is available at https://github.com/taco-group/GenAI4AD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08854v1",
    "published_date": "2025-05-13 17:59:20 UTC",
    "updated_date": "2025-05-13 17:59:20 UTC"
  },
  {
    "arxiv_id": "2505.08783v1",
    "title": "CodePDE: An Inference Framework for LLM-driven PDE Solver Generation",
    "authors": [
      "Shanda Li",
      "Tanya Marwah",
      "Junhong Shen",
      "Weiwei Sun",
      "Andrej Risteski",
      "Yiming Yang",
      "Ameet Talwalkar"
    ],
    "abstract": "Partial differential equations (PDEs) are fundamental to modeling physical systems, yet solving them remains a complex challenge. Traditional numerical solvers rely on expert knowledge to implement and are computationally expensive, while neural-network-based solvers require large training datasets and often lack interpretability. In this work, we frame PDE solving as a code generation task and introduce CodePDE, the first inference framework for generating PDE solvers using large language models (LLMs). Leveraging advanced inference-time algorithms and scaling strategies, CodePDE unlocks critical capacities of LLM for PDE solving: reasoning, debugging, selfrefinement, and test-time scaling -- all without task-specific tuning. CodePDE achieves superhuman performance across a range of representative PDE problems. We also present a systematic empirical analysis of LLM generated solvers, analyzing their accuracy, efficiency, and numerical scheme choices. Our findings highlight the promise and the current limitations of LLMs in PDE solving, offering a new perspective on solver design and opportunities for future model development. Our code is available at https://github.com/LithiumDA/CodePDE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08783v1",
    "published_date": "2025-05-13 17:58:08 UTC",
    "updated_date": "2025-05-13 17:58:08 UTC"
  },
  {
    "arxiv_id": "2505.08778v1",
    "title": "ARC-NCA: Towards Developmental Solutions to the Abstraction and Reasoning Corpus",
    "authors": [
      "Etienne Guichard",
      "Felix Reimers",
      "Mia Kvalsund",
      "Mikkel Lepperød",
      "Stefano Nichele"
    ],
    "abstract": "The Abstraction and Reasoning Corpus (ARC), later renamed ARC-AGI, poses a fundamental challenge in artificial general intelligence (AGI), requiring solutions that exhibit robust abstraction and reasoning capabilities across diverse tasks, while only few (with median count of three) correct examples are presented. While ARC-AGI remains very challenging for artificial intelligence systems, it is rather easy for humans. This paper introduces ARC-NCA, a developmental approach leveraging standard Neural Cellular Automata (NCA) and NCA enhanced with hidden memories (EngramNCA) to tackle the ARC-AGI benchmark. NCAs are employed for their inherent ability to simulate complex dynamics and emergent patterns, mimicking developmental processes observed in biological systems. Developmental solutions may offer a promising avenue for enhancing AI's problem-solving capabilities beyond mere training data extrapolation. ARC-NCA demonstrates how integrating developmental principles into computational models can foster adaptive reasoning and abstraction. We show that our ARC-NCA proof-of-concept results may be comparable to, and sometimes surpass, that of ChatGPT 4.5, at a fraction of the cost.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08778v1",
    "published_date": "2025-05-13 17:55:43 UTC",
    "updated_date": "2025-05-13 17:55:43 UTC"
  },
  {
    "arxiv_id": "2505.22674v1",
    "title": "PSBench: a large-scale benchmark for estimating the accuracy of protein complex structural models",
    "authors": [
      "Pawan Neupane",
      "Jian Liu",
      "Jianlin Cheng"
    ],
    "abstract": "Predicting protein complex structures is essential for protein function analysis, protein design, and drug discovery. While AI methods like AlphaFold can predict accurate structural models for many protein complexes, reliably estimating the quality of these predicted models (estimation of model accuracy, or EMA) for model ranking and selection remains a major challenge. A key barrier to developing effective machine learning-based EMA methods is the lack of large, diverse, and well-annotated datasets for training and evaluation. To address this gap, we introduce PSBench, a benchmark suite comprising four large-scale, labeled datasets generated during the 15th and 16th community-wide Critical Assessment of Protein Structure Prediction (CASP15 and CASP16). PSBench includes over one million structural models covering a wide range of protein sequence lengths, complex stoichiometries, functional classes, and modeling difficulties. Each model is annotated with multiple complementary quality scores at the global, local, and interface levels. PSBench also provides multiple evaluation metrics and baseline EMA methods to facilitate rigorous comparisons. To demonstrate PSBench's utility, we trained and evaluated GATE, a graph transformer-based EMA method, on the CASP15 data. GATE was blindly tested in CASP16 (2024), where it ranked among the top-performing EMA methods. These results highlight PSBench as a valuable resource for advancing EMA research in protein complex modeling. PSBench is publicly available at: https://github.com/BioinfoMachineLearning/PSBench.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.22674v1",
    "published_date": "2025-05-13 17:47:12 UTC",
    "updated_date": "2025-05-13 17:47:12 UTC"
  },
  {
    "arxiv_id": "2506.01969v2",
    "title": "FlashMLA-ETAP: Efficient Transpose Attention Pipeline for Accelerating MLA Inference on NVIDIA H20 GPUs",
    "authors": [
      "Pengcuo Dege",
      "Qiuming Luo",
      "Rui Mao",
      "Chang Kong"
    ],
    "abstract": "Efficient inference of Multi-Head Latent Attention (MLA) is challenged by deploying the DeepSeek-R1 671B model on a single Multi-GPU server. This paper introduces FlashMLA-ETAP, a novel framework that enhances MLA inference for the single-instance deployment scenario on NVIDIA H20 GPUs. We propose the Efficient Transpose Attention Pipeline (ETAP), which reconfigures attention computation through transposition to align the KV context length with the \\(M\\)-dimension in WGMMA operations, significantly reducing redundant computations. FlashMLA-ETAP achieves a 2.78x speedup over FlashMLA at 64K sequence length (batch size 16), with 5.24x and 4.94x improvements over FlashAttention-3 and FlashInfer, respectively, while maintaining numerical stability with a 15.2x lower RMSE (\\(1.25 \\times 10^{-5}\\)) than FlashAttention-3. Furthermore, ETAP's design enables seamless integration into frameworks like FlashAttention-3 and FlashInfer, supported by a detailed theoretical analysis. Our work addresses a critical gap in resource-constrained inference, offering a scalable solution for mid-tier GPUs and paving the way for broader adoption in hardware-aware optimization. Code is available at https://github.com/pengcuo/FlashMLA-ETAP.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "15 pages, conference",
    "pdf_url": "https://arxiv.org/pdf/2506.01969v2",
    "published_date": "2025-05-13 17:45:34 UTC",
    "updated_date": "2025-06-04 03:20:26 UTC"
  },
  {
    "arxiv_id": "2505.08765v2",
    "title": "Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology",
    "authors": [
      "Yatai Ji",
      "Zhengqiu Zhu",
      "Yong Zhao",
      "Beidan Liu",
      "Chen Gao",
      "Yihao Zhao",
      "Sihang Qiu",
      "Yue Hu",
      "Quanjun Yin",
      "Yong Li"
    ],
    "abstract": "Aerial Visual Object Search (AVOS) tasks in urban environments require Unmanned Aerial Vehicles (UAVs) to autonomously search for and identify target objects using visual and textual cues without external guidance. Existing approaches struggle in complex urban environments due to redundant semantic processing, similar object distinction, and the exploration-exploitation dilemma. To bridge this gap and support the AVOS task, we introduce CityAVOS, the first benchmark dataset for autonomous search of common urban objects. This dataset comprises 2,420 tasks across six object categories with varying difficulty levels, enabling comprehensive evaluation of UAV agents' search capabilities. To solve the AVOS tasks, we also propose PRPSearcher (Perception-Reasoning-Planning Searcher), a novel agentic method powered by multi-modal large language models (MLLMs) that mimics human three-tier cognition. Specifically, PRPSearcher constructs three specialized maps: an object-centric dynamic semantic map enhancing spatial perception, a 3D cognitive map based on semantic attraction values for target reasoning, and a 3D uncertainty map for balanced exploration-exploitation search. Also, our approach incorporates a denoising mechanism to mitigate interference from similar objects and utilizes an Inspiration Promote Thought (IPT) prompting mechanism for adaptive action planning. Experimental results on CityAVOS demonstrate that PRPSearcher surpasses existing baselines in both success rate and search efficiency (on average: +37.69% SR, +28.96% SPL, -30.69% MSS, and -46.40% NE). While promising, the performance gap compared to humans highlights the need for better semantic reasoning and spatial exploration capabilities in AVOS tasks. This work establishes a foundation for future advances in embodied target search. Dataset and source code are available at https://anonymous.4open.science/r/CityAVOS-3DF8.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08765v2",
    "published_date": "2025-05-13 17:34:54 UTC",
    "updated_date": "2025-05-14 01:30:03 UTC"
  },
  {
    "arxiv_id": "2505.08747v1",
    "title": "Advancing Food Nutrition Estimation via Visual-Ingredient Feature Fusion",
    "authors": [
      "Huiyan Qi",
      "Bin Zhu",
      "Chong-Wah Ngo",
      "Jingjing Chen",
      "Ee-Peng Lim"
    ],
    "abstract": "Nutrition estimation is an important component of promoting healthy eating and mitigating diet-related health risks. Despite advances in tasks such as food classification and ingredient recognition, progress in nutrition estimation is limited due to the lack of datasets with nutritional annotations. To address this issue, we introduce FastFood, a dataset with 84,446 images across 908 fast food categories, featuring ingredient and nutritional annotations. In addition, we propose a new model-agnostic Visual-Ingredient Feature Fusion (VIF$^2$) method to enhance nutrition estimation by integrating visual and ingredient features. Ingredient robustness is improved through synonym replacement and resampling strategies during training. The ingredient-aware visual feature fusion module combines ingredient features and visual representation to achieve accurate nutritional prediction. During testing, ingredient predictions are refined using large multimodal models by data augmentation and majority voting. Our experiments on both FastFood and Nutrition5k datasets validate the effectiveness of our proposed method built in different backbones (e.g., Resnet, InceptionV3 and ViT), which demonstrates the importance of ingredient information in nutrition estimation. https://huiyanqi.github.io/fastfood-nutrition-estimation/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication in ACM International Conference on Multimedia Retrieval 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08747v1",
    "published_date": "2025-05-13 17:01:21 UTC",
    "updated_date": "2025-05-13 17:01:21 UTC"
  },
  {
    "arxiv_id": "2505.08744v1",
    "title": "DeepMath-Creative: A Benchmark for Evaluating Mathematical Creativity of Large Language Models",
    "authors": [
      "Xiaoyang Chen",
      "Xinan Dai",
      "Yu Du",
      "Qian Feng",
      "Naixu Guo",
      "Tingshuo Gu",
      "Yuting Gao",
      "Yingyi Gao",
      "Xudong Han",
      "Xiang Jiang",
      "Yilin Jin",
      "Hongyi Lin",
      "Shisheng Lin",
      "Xiangnan Li",
      "Yuante Li",
      "Yixing Li",
      "Zhentao Lai",
      "Zilu Ma",
      "Yingrong Peng",
      "Jiacheng Qian",
      "Hao-Yu Sun",
      "Jianbo Sun",
      "Zirui Wang",
      "Siwei Wu",
      "Zian Wang",
      "Bin Xu",
      "Jianghao Xu",
      "Yiyang Yu",
      "Zichuan Yang",
      "Hongji Zha",
      "Ruichong Zhang"
    ],
    "abstract": "To advance the mathematical proficiency of large language models (LLMs), the DeepMath team has launched an open-source initiative aimed at developing an open mathematical LLM and systematically evaluating its mathematical creativity. This paper represents the initial contribution of this initiative. While recent developments in mathematical LLMs have predominantly emphasized reasoning skills, as evidenced by benchmarks on elementary to undergraduate-level mathematical tasks, the creative capabilities of these models have received comparatively little attention, and evaluation datasets remain scarce. To address this gap, we propose an evaluation criteria for mathematical creativity and introduce DeepMath-Creative, a novel, high-quality benchmark comprising constructive problems across algebra, geometry, analysis, and other domains. We conduct a systematic evaluation of mainstream LLMs' creative problem-solving abilities using this dataset. Experimental results show that even under lenient scoring criteria -- emphasizing core solution components and disregarding minor inaccuracies, such as small logical gaps, incomplete justifications, or redundant explanations -- the best-performing model, O3 Mini, achieves merely 70% accuracy, primarily on basic undergraduate-level constructive tasks. Performance declines sharply on more complex problems, with models failing to provide substantive strategies for open problems. These findings suggest that, although current LLMs display a degree of constructive proficiency on familiar and lower-difficulty problems, such performance is likely attributable to the recombination of memorized patterns rather than authentic creative insight or novel synthesis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.08744v1",
    "published_date": "2025-05-13 16:58:05 UTC",
    "updated_date": "2025-05-13 16:58:05 UTC"
  },
  {
    "arxiv_id": "2505.08728v2",
    "title": "Securing RAG: A Risk Assessment and Mitigation Framework",
    "authors": [
      "Lukas Ammann",
      "Sara Ott",
      "Christoph R. Landolt",
      "Marco P. Lehmann"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has emerged as the de facto industry standard for user-facing NLP applications, offering the ability to integrate data without re-training or fine-tuning Large Language Models (LLMs). This capability enhances the quality and accuracy of responses but also introduces novel security and privacy challenges, particularly when sensitive data is integrated. With the rapid adoption of RAG, securing data and services has become a critical priority. This paper first reviews the vulnerabilities of RAG pipelines, and outlines the attack surface from data pre-processing and data storage management to integration with LLMs. The identified risks are then paired with corresponding mitigations in a structured overview. In a second step, the paper develops a framework that combines RAG-specific security considerations, with existing general security guidelines, industry standards, and best practices. The proposed framework aims to guide the implementation of robust, compliant, secure, and trustworthy RAG systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages, 3 figures, Sara Ott and Lukas Ammann contributed equally. This work has been submitted to the IEEE for possible publication",
    "pdf_url": "https://arxiv.org/pdf/2505.08728v2",
    "published_date": "2025-05-13 16:39:00 UTC",
    "updated_date": "2025-05-21 09:45:04 UTC"
  },
  {
    "arxiv_id": "2505.08727v2",
    "title": "Memorization-Compression Cycles Improve Generalization",
    "authors": [
      "Fangyuan Yu"
    ],
    "abstract": "We prove theoretically that generalization improves not only through data scaling but also by compressing internal representations. To operationalize this insight, we introduce the Information Bottleneck Language Modeling (IBLM) objective, which reframes language modeling as a constrained optimization problem: minimizing representation entropy subject to optimal prediction performance. Empirically, we observe an emergent memorization-compression cycle during LLM pretraining, evidenced by oscillation positive/negative gradient alignment between cross-entropy and Matrix-Based Entropy (MBE), a measure of representation entropy. This pattern closely mirrors the predictive-compressive trade-off prescribed by IBLM and also parallels the biological alternation between awake learning and sleep consolidation. Motivated by this observation, we propose Gated Phase Transition (GAPT), a training algorithm that adaptively switches between memorization and compression phases. When applied to GPT-2 pretraining on FineWeb dataset, GAPT reduces MBE by 50% and improves cross-entropy by 4.8%. GAPT improves OOD generalizatino by 35% in a pretraining task on arithmetic multiplication. In a setting designed to simulate catastrophic forgetting, GAPT reduces interference by compressing and separating representations, achieving a 97% improvement in separation - paralleling the functional role of sleep consolidation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 6 figures, NeurIPS2025 NEGEL Workshop",
    "pdf_url": "https://arxiv.org/pdf/2505.08727v2",
    "published_date": "2025-05-13 16:37:54 UTC",
    "updated_date": "2025-10-22 08:10:52 UTC"
  },
  {
    "arxiv_id": "2505.08719v1",
    "title": "PWC-MoE: Privacy-Aware Wireless Collaborative Mixture of Experts",
    "authors": [
      "Yang Su",
      "Na Yan",
      "Yansha Deng",
      "Robert Schober"
    ],
    "abstract": "Large language models (LLMs) hosted on cloud servers alleviate the computational and storage burdens on local devices but raise privacy concerns due to sensitive data transmission and require substantial communication bandwidth, which is challenging in constrained environments. In contrast, small language models (SLMs) running locally enhance privacy but suffer from limited performance on complex tasks. To balance computational cost, performance, and privacy protection under bandwidth constraints, we propose a privacy-aware wireless collaborative mixture of experts (PWC-MoE) framework. Specifically, PWC-MoE employs a sparse privacy-aware gating network to dynamically route sensitive tokens to privacy experts located on local clients, while non-sensitive tokens are routed to non-privacy experts located at the remote base station. To achieve computational efficiency, the gating network ensures that each token is dynamically routed to and processed by only one expert. To enhance scalability and prevent overloading of specific experts, we introduce a group-wise load-balancing mechanism for the gating network that evenly distributes sensitive tokens among privacy experts and non-sensitive tokens among non-privacy experts. To adapt to bandwidth constraints while preserving model performance, we propose a bandwidth-adaptive and importance-aware token offloading scheme. This scheme incorporates an importance predictor to evaluate the importance scores of non-sensitive tokens, prioritizing the most important tokens for transmission to the base station based on their predicted importance and the available bandwidth. Experiments demonstrate that the PWC-MoE framework effectively preserves privacy and maintains high performance even in bandwidth-constrained environments, offering a practical solution for deploying LLMs in privacy-sensitive and bandwidth-limited scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08719v1",
    "published_date": "2025-05-13 16:27:07 UTC",
    "updated_date": "2025-05-13 16:27:07 UTC"
  },
  {
    "arxiv_id": "2505.08849v1",
    "title": "Improved Algorithms for Differentially Private Language Model Alignment",
    "authors": [
      "Keyu Chen",
      "Hao Tang",
      "Qinglin Liu",
      "Yizhao Xu"
    ],
    "abstract": "Language model alignment is crucial for ensuring that large language models (LLMs) align with human preferences, yet it often involves sensitive user data, raising significant privacy concerns. While prior work has integrated differential privacy (DP) with alignment techniques, their performance remains limited. In this paper, we propose novel algorithms for privacy-preserving alignment and rigorously analyze their effectiveness across varying privacy budgets and models. Our framework can be deployed on two celebrated alignment techniques, namely direct preference optimization (DPO) and reinforcement learning from human feedback (RLHF). Through systematic experiments on large-scale language models, we demonstrate that our approach achieves state-of-the-art performance. Notably, one of our algorithms, DP-AdamW, combined with DPO, surpasses existing methods, improving alignment quality by up to 15% under moderate privacy budgets (ε=2-5). We further investigate the interplay between privacy guarantees, alignment efficacy, and computational demands, providing practical guidelines for optimizing these trade-offs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08849v1",
    "published_date": "2025-05-13 16:18:59 UTC",
    "updated_date": "2025-05-13 16:18:59 UTC"
  },
  {
    "arxiv_id": "2505.08706v1",
    "title": "Big Data and the Computational Social Science of Entrepreneurship and Innovation",
    "authors": [
      "Ningzi Li",
      "Shiyang Lai",
      "James Evans"
    ],
    "abstract": "As large-scale social data explode and machine-learning methods evolve, scholars of entrepreneurship and innovation face new research opportunities but also unique challenges. This chapter discusses the difficulties of leveraging large-scale data to identify technological and commercial novelty, document new venture origins, and forecast competition between new technologies and commercial forms. It suggests how scholars can take advantage of new text, network, image, audio, and video data in two distinct ways that advance innovation and entrepreneurship research. First, machine-learning models, combined with large-scale data, enable the construction of precision measurements that function as system-level observatories of innovation and entrepreneurship across human societies. Second, new artificial intelligence models fueled by big data generate 'digital doubles' of technology and business, forming laboratories for virtual experimentation about innovation and entrepreneurship processes and policies. The chapter argues for the advancement of theory development and testing in entrepreneurship and innovation by coupling big data with big models.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CY",
      "cs.SI",
      "stat.AP"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08706v1",
    "published_date": "2025-05-13 16:13:18 UTC",
    "updated_date": "2025-05-13 16:13:18 UTC"
  },
  {
    "arxiv_id": "2505.08705v2",
    "title": "Instance-aware Image Colorization with Controllable Textual Descriptions and Segmentation Masks",
    "authors": [
      "Yanru An",
      "Ling Gui",
      "Chunlei Cai",
      "Tianxiao Ye",
      "JIangchao Yao",
      "Guangtao Zhai",
      "Qiang Hu",
      "Xiaoyun Zhang"
    ],
    "abstract": "Recently, the application of deep learning in image colorization has received widespread attention. The maturation of diffusion models has further advanced the development of image colorization models. However, current mainstream image colorization models still face issues such as color bleeding and color binding errors, and cannot colorize images at the instance level. In this paper, we propose a diffusion-based colorization method MT-Color to achieve precise instance-aware colorization with use-provided guidance. To tackle color bleeding issue, we design a pixel-level mask attention mechanism that integrates latent features and conditional gray image features through cross-attention. We use segmentation masks to construct cross-attention masks, preventing pixel information from exchanging between different instances. We also introduce an instance mask and text guidance module that extracts instance masks and text representations of each instance, which are then fused with latent features through self-attention, utilizing instance masks to form self-attention masks to prevent instance texts from guiding the colorization of other areas, thus mitigating color binding errors. Furthermore, we apply a multi-instance sampling strategy, which involves sampling each instance region separately and then fusing the results. Additionally, we have created a specialized dataset for instance-level colorization tasks, GPT-color, by leveraging large visual language models on existing image datasets. Qualitative and quantitative experiments show that our model and dataset outperform previous methods and datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08705v2",
    "published_date": "2025-05-13 16:13:06 UTC",
    "updated_date": "2025-09-25 07:25:28 UTC"
  },
  {
    "arxiv_id": "2505.08704v2",
    "title": "LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs",
    "authors": [
      "K M Sajjadul Islam",
      "Ayesha Siddika Nipu",
      "Jiawei Wu",
      "Praveen Madiraju"
    ],
    "abstract": "Electronic Health Records (EHRs) are digital records of patient information, often containing unstructured clinical text. Named Entity Recognition (NER) is essential in EHRs for extracting key medical entities like problems, tests, and treatments to support downstream clinical applications. This paper explores prompt-based medical entity recognition using large language models (LLMs), specifically GPT-4o and DeepSeek-R1, guided by various prompt engineering techniques, including zero-shot, few-shot, and an ensemble approach. Among all strategies, GPT-4o with prompt ensemble achieved the highest classification performance with an F1-score of 0.95 and recall of 0.98, outperforming DeepSeek-R1 on the task. The ensemble method improved reliability by aggregating outputs through embedding-based similarity and majority voting.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "IEEE 26th International Conference on Information Reuse and Integration for Data Science (IRI 2025), San Jose, CA, USA",
    "pdf_url": "https://arxiv.org/pdf/2505.08704v2",
    "published_date": "2025-05-13 16:11:29 UTC",
    "updated_date": "2025-05-25 21:34:53 UTC"
  },
  {
    "arxiv_id": "2505.08694v2",
    "title": "A Survey of Deep Learning for Complex Speech Spectrograms",
    "authors": [
      "Yuying Xie",
      "Zheng-Hua Tan"
    ],
    "abstract": "Recent advancements in deep learning have significantly impacted the field of speech signal processing, particularly in the analysis and manipulation of complex spectrograms. This survey provides a comprehensive overview of the state-of-the-art techniques leveraging deep neural networks for processing complex spectrograms, which encapsulate both magnitude and phase information. We begin by introducing complex spectrograms and their associated features for various speech processing tasks. Next, we examine the key components and architectures of complex-valued neural networks, which are specifically designed to handle complex-valued data and have been applied to complex spectrogram processing. As recent studies have primarily focused on applying real-valued neural networks to complex spectrograms, we revisit these approaches and their architectural designs. We then discuss various training strategies and loss functions tailored for training neural networks to process and model complex spectrograms. The survey further examines key applications, including phase retrieval, speech enhancement, and speaker separation, where deep learning has achieved significant progress by leveraging complex spectrograms or their derived feature representations. Additionally, we examine the intersection of complex spectrograms with generative models. This survey aims to serve as a valuable resource for researchers and practitioners in the field of speech signal processing, deep learning and related fields.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08694v2",
    "published_date": "2025-05-13 15:53:01 UTC",
    "updated_date": "2025-10-03 14:14:44 UTC"
  },
  {
    "arxiv_id": "2505.08691v1",
    "title": "VizCV: AI-assisted visualization of researchers' publications tracks",
    "authors": [
      "Vladimír Lazárik",
      "Marco Agus",
      "Barbora Kozlíková",
      "Pere-Pau Vázquez"
    ],
    "abstract": "Analyzing how the publication records of scientists and research groups have evolved over the years is crucial for assessing their expertise since it can support the management of academic environments by assisting with career planning and evaluation. We introduce VizCV, a novel web-based end-to-end visual analytics framework that enables the interactive exploration of researchers' scientific trajectories. It incorporates AI-assisted analysis and supports automated reporting of career evolution. Our system aims to model career progression through three key dimensions: a) research topic evolution to detect and visualize shifts in scholarly focus over time, b) publication record and the corresponding impact, c) collaboration dynamics depicting the growth and transformation of a researcher's co-authorship network. AI-driven insights provide automated explanations of career transitions, detecting significant shifts in research direction, impact surges, or collaboration expansions. The system also supports comparative analysis between researchers, allowing users to compare topic trajectories and impact growth. Our interactive, multi-tab and multiview system allows for the exploratory analysis of career milestones under different perspectives, such as the most impactful articles, emerging research themes, or obtaining a detailed analysis of the contribution of the researcher in a subfield. The key contributions include AI/ML techniques for: a) topic analysis, b) dimensionality reduction for visualizing patterns and trends, c) the interactive creation of textual descriptions of facets of data through configurable prompt generation and large language models, that include key indicators, to help understanding the career development of individuals or groups.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, 9 figures. Subtmitted",
    "pdf_url": "https://arxiv.org/pdf/2505.08691v1",
    "published_date": "2025-05-13 15:47:59 UTC",
    "updated_date": "2025-05-13 15:47:59 UTC"
  },
  {
    "arxiv_id": "2505.08687v2",
    "title": "AC-PKAN: Attention-Enhanced and Chebyshev Polynomial-Based Physics-Informed Kolmogorov-Arnold Networks",
    "authors": [
      "Hangwei Zhang",
      "Zhimu Huang",
      "Yan Wang"
    ],
    "abstract": "Kolmogorov-Arnold Networks (KANs) have recently shown promise for solving partial differential equations (PDEs). Yet their original formulation is computationally and memory intensive, motivating the introduction of Chebyshev Type-I-based KANs (Chebyshev1KANs). Although Chebyshev1KANs have outperformed the vanilla KANs architecture, our rigorous theoretical analysis reveals that they still suffer from rank collapse, ultimately limiting their expressive capacity. To overcome these limitations, we enhance Chebyshev1KANs by integrating wavelet-activated MLPs with learnable parameters and an internal attention mechanism. We prove that this design preserves a full-rank Jacobian and is capable of approximating solutions to PDEs of arbitrary order. Furthermore, to alleviate the loss instability and imbalance introduced by the Chebyshev polynomial basis, we externally incorporate a Residual Gradient Attention (RGA) mechanism that dynamically re-weights individual loss terms according to their gradient norms and residual magnitudes. By jointly leveraging internal and external attention, we present AC-PKAN, a novel architecture that constitutes an enhancement to weakly supervised Physics-Informed Neural Networks (PINNs) and extends the expressive power of KANs. Experimental results from nine benchmark tasks across three domains show that AC-PKAN consistently outperforms or matches state-of-the-art models such as PINNsFormer, establishing it as a highly effective tool for solving complex real-world engineering problems in zero-data or data-sparse regimes. The code will be made publicly available upon acceptance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08687v2",
    "published_date": "2025-05-13 15:46:10 UTC",
    "updated_date": "2026-01-16 11:15:18 UTC"
  },
  {
    "arxiv_id": "2505.08681v1",
    "title": "A Mamba-based Network for Semi-supervised Singing Melody Extraction Using Confidence Binary Regularization",
    "authors": [
      "Xiaoliang He",
      "Kangjie Dong",
      "Jingkai Cao",
      "Shuai Yu",
      "Wei Li",
      "Yi Yu"
    ],
    "abstract": "Singing melody extraction (SME) is a key task in the field of music information retrieval. However, existing methods are facing several limitations: firstly, prior models use transformers to capture the contextual dependencies, which requires quadratic computation resulting in low efficiency in the inference stage. Secondly, prior works typically rely on frequencysupervised methods to estimate the fundamental frequency (f0), which ignores that the musical performance is actually based on notes. Thirdly, transformers typically require large amounts of labeled data to achieve optimal performances, but the SME task lacks of sufficient annotated data. To address these issues, in this paper, we propose a mamba-based network, called SpectMamba, for semi-supervised singing melody extraction using confidence binary regularization. In particular, we begin by introducing vision mamba to achieve computational linear complexity. Then, we propose a novel note-f0 decoder that allows the model to better mimic the musical performance. Further, to alleviate the scarcity of the labeled data, we introduce a confidence binary regularization (CBR) module to leverage the unlabeled data by maximizing the probability of the correct classes. The proposed method is evaluated on several public datasets and the conducted experiments demonstrate the effectiveness of our proposed method.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08681v1",
    "published_date": "2025-05-13 15:43:35 UTC",
    "updated_date": "2025-05-13 15:43:35 UTC"
  },
  {
    "arxiv_id": "2505.08673v1",
    "title": "A Study of Data-driven Methods for Inventory Optimization",
    "authors": [
      "Lee Yeung Ping",
      "Patrick Wong",
      "Tan Cheng Han"
    ],
    "abstract": "This paper shows a comprehensive analysis of three algorithms (Time Series, Random Forest (RF) and Deep Reinforcement Learning) into three inventory models (the Lost Sales, Dual-Sourcing and Multi-Echelon Inventory Model). These methodologies are applied in the supermarket context. The main purpose is to analyse efficient methods for the data-driven. Their possibility, potential and current challenges are taken into consideration in this report. By comparing the results in each model, the effectiveness of each algorithm is evaluated based on several key performance indicators, including forecast accuracy, adaptability to market changes, and overall impact on inventory costs and customer satisfaction levels. The data visualization tools and statistical metrics are the indicators for the comparisons and show some obvious trends and patterns that can guide decision-making in inventory management. These tools enable managers to not only track the performance of different algorithms in real-time but also to drill down into specific data points to understand the underlying causes of inventory fluctuations. This level of detail is crucial for pinpointing inefficiencies and areas for improvement within the supply chain.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08673v1",
    "published_date": "2025-05-13 15:35:23 UTC",
    "updated_date": "2025-05-13 15:35:23 UTC"
  },
  {
    "arxiv_id": "2505.08847v1",
    "title": "On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction",
    "authors": [
      "Fatima Ezzeddine",
      "Rinad Akel",
      "Ihab Sbeity",
      "Silvia Giordano",
      "Marc Langheinrich",
      "Omran Ayoub"
    ],
    "abstract": "Machine Learning as a Service (MLaaS) has gained important attraction as a means for deploying powerful predictive models, offering ease of use that enables organizations to leverage advanced analytics without substantial investments in specialized infrastructure or expertise. However, MLaaS platforms must be safeguarded against security and privacy attacks, such as model extraction (MEA) attacks. The increasing integration of explainable AI (XAI) within MLaaS has introduced an additional privacy challenge, as attackers can exploit model explanations particularly counterfactual explanations (CFs) to facilitate MEA. In this paper, we investigate the trade offs among model performance, privacy, and explainability when employing Differential Privacy (DP), a promising technique for mitigating CF facilitated MEA. We evaluate two distinct DP strategies: implemented during the classification model training and at the explainer during CF generation.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08847v1",
    "published_date": "2025-05-13 15:27:06 UTC",
    "updated_date": "2025-05-13 15:27:06 UTC"
  },
  {
    "arxiv_id": "2505.08664v1",
    "title": "A Social Robot with Inner Speech for Dietary Guidance",
    "authors": [
      "Valerio Belcamino",
      "Alessandro Carfì",
      "Valeria Seidita",
      "Fulvio Mastrogiovanni",
      "Antonio Chella"
    ],
    "abstract": "We explore the use of inner speech as a mechanism to enhance transparency and trust in social robots for dietary advice. In humans, inner speech structures thought processes and decision-making; in robotics, it improves explainability by making reasoning explicit. This is crucial in healthcare scenarios, where trust in robotic assistants depends on both accurate recommendations and human-like dialogue, which make interactions more natural and engaging. Building on this, we developed a social robot that provides dietary advice, and we provided the architecture with inner speech capabilities to validate user input, refine reasoning, and generate clear justifications. The system integrates large language models for natural language understanding and a knowledge graph for structured dietary information. By making decisions more transparent, our approach strengthens trust and improves human-robot interaction in healthcare. We validated this by measuring the computational efficiency of our architecture and conducting a small user study, which assessed the reliability of inner speech in explaining the robot's behavior.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08664v1",
    "published_date": "2025-05-13 15:26:52 UTC",
    "updated_date": "2025-05-13 15:26:52 UTC"
  },
  {
    "arxiv_id": "2505.08657v1",
    "title": "A Comparative Study of Human Activity Recognition: Motion, Tactile, and multi-modal Approaches",
    "authors": [
      "Valerio Belcamino",
      "Nhat Minh Dinh Le",
      "Quan Khanh Luu",
      "Alessandro Carfì",
      "Van Anh Ho",
      "Fulvio Mastrogiovanni"
    ],
    "abstract": "Human activity recognition (HAR) is essential for effective Human-Robot Collaboration (HRC), enabling robots to interpret and respond to human actions. This study evaluates the ability of a vision-based tactile sensor to classify 15 activities, comparing its performance to an IMU-based data glove. Additionally, we propose a multi-modal framework combining tactile and motion data to leverage their complementary strengths. We examined three approaches: motion-based classification (MBC) using IMU data, tactile-based classification (TBC) with single or dual video streams, and multi-modal classification (MMC) integrating both. Offline validation on segmented datasets assessed each configuration's accuracy under controlled conditions, while online validation on continuous action sequences tested online performance. Results showed the multi-modal approach consistently outperformed single-modality methods, highlighting the potential of integrating tactile and motion sensing to enhance HAR systems for collaborative robotics.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08657v1",
    "published_date": "2025-05-13 15:20:21 UTC",
    "updated_date": "2025-05-13 15:20:21 UTC"
  },
  {
    "arxiv_id": "2505.08643v1",
    "title": "WixQA: A Multi-Dataset Benchmark for Enterprise Retrieval-Augmented Generation",
    "authors": [
      "Dvir Cohen",
      "Lin Burg",
      "Sviatoslav Pykhnivskyi",
      "Hagit Gur",
      "Stanislav Kovynov",
      "Olga Atzmon",
      "Gilad Barkan"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) is a cornerstone of modern question answering (QA) systems, enabling grounded answers based on external knowledge. Although recent progress has been driven by open-domain datasets, enterprise QA systems need datasets that mirror the concrete, domain-specific issues users raise in day-to-day support scenarios. Critically, evaluating end-to-end RAG systems requires benchmarks comprising not only question--answer pairs but also the specific knowledge base (KB) snapshot from which answers were derived. To address this need, we introduce WixQA, a benchmark suite featuring QA datasets precisely grounded in the released KB corpus, enabling holistic evaluation of retrieval and generation components. WixQA includes three distinct QA datasets derived from Wix.com customer support interactions and grounded in a snapshot of the public Wix Help Center KB: (i) WixQA-ExpertWritten, 200 real user queries with expert-authored, multi-step answers; (ii) WixQA-Simulated, 200 expert-validated QA pairs distilled from user dialogues; and (iii) WixQA-Synthetic, 6,222 LLM-generated QA pairs, with one pair systematically derived from each article in the knowledge base. We release the KB snapshot alongside the datasets under MIT license and provide comprehensive baseline results, forming a unique benchmark for evaluating enterprise RAG systems in realistic enterprise environments.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08643v1",
    "published_date": "2025-05-13 15:02:54 UTC",
    "updated_date": "2025-05-13 15:02:54 UTC"
  },
  {
    "arxiv_id": "2505.08846v2",
    "title": "Evaluating Simplification Algorithms for Interpretability of Time Series Classification",
    "authors": [
      "Brigt Håvardstun",
      "Felix Marti-Perez",
      "Cèsar Ferri",
      "Jan Arne Telle"
    ],
    "abstract": "In this work, we introduce metrics to evaluate the use of simplified time series in the context of interpretability of a TSC -- a Time Series Classifier. Such simplifications are important because time series data, in contrast to text and image data, are not intuitively under- standable to humans. These metrics are related to the complexity of the simplifications -- how many segments they contain -- and to their loyalty -- how likely they are to maintain the classification of the original time series. We focus on simplifications that select a subset of the original data points, and show that these typically have high Shapley value, thereby aiding interpretability. We employ these metrics to experimentally evaluate four distinct simplification algorithms, across several TSC algorithms and across datasets of varying characteristics, from seasonal or stationary to short or long. We subsequently perform a human-grounded evaluation with forward simulation, that confirms also the practical utility of the introduced metrics to evaluate the use of simplifications in the context of interpretability of TSC. Our findings are summarized in a framework for deciding, for a given TSC, if the various simplifications are likely to aid in its interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08846v2",
    "published_date": "2025-05-13 15:00:56 UTC",
    "updated_date": "2025-10-31 19:24:20 UTC"
  },
  {
    "arxiv_id": "2505.08638v3",
    "title": "TRAIL: Trace Reasoning and Agentic Issue Localization",
    "authors": [
      "Darshan Deshpande",
      "Varun Gangal",
      "Hersh Mehta",
      "Jitin Krishnan",
      "Anand Kannappan",
      "Rebecca Qian"
    ],
    "abstract": "The increasing adoption of agentic workflows across diverse domains brings a critical need to scalably and systematically evaluate the complex traces these systems generate. Current evaluation methods depend on manual, domain-specific human analysis of lengthy workflow traces - an approach that does not scale with the growing complexity and volume of agentic outputs. Error analysis in these settings is further complicated by the interplay of external tool outputs and language model reasoning, making it more challenging than traditional software debugging. In this work, we (1) articulate the need for robust and dynamic evaluation methods for agentic workflow traces, (2) introduce a formal taxonomy of error types encountered in agentic systems, and (3) present a set of 148 large human-annotated traces (TRAIL) constructed using this taxonomy and grounded in established agentic benchmarks. To ensure ecological validity, we curate traces from both single and multi-agent systems, focusing on real-world applications such as software engineering and open-world information retrieval. Our evaluations reveal that modern long context LLMs perform poorly at trace debugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our dataset and code are made publicly available to support and accelerate future research in scalable evaluation for agentic workflows.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Dataset: https://huggingface.co/datasets/PatronusAI/TRAIL",
    "pdf_url": "https://arxiv.org/pdf/2505.08638v3",
    "published_date": "2025-05-13 14:55:31 UTC",
    "updated_date": "2025-06-23 21:06:11 UTC"
  },
  {
    "arxiv_id": "2505.08628v1",
    "title": "Integrating Natural Language Processing and Exercise Monitoring for Early Diagnosis of Metabolic Syndrome: A Deep Learning Approach",
    "authors": [
      "Yichen Zhao",
      "Yuhua Wang",
      "Xi Cheng",
      "Junhao Fang",
      "Yang Yang"
    ],
    "abstract": "Metabolic syndrome (MetS) is a medication condition characterized by abdominal obesity, insulin resistance, hypertension and hyperlipidemia. It increases the risk of majority of chronic diseases, including type 2 diabetes mellitus, and affects about one quarter of the global population. Therefore, early detection and timely intervention for MetS are crucial. Standard diagnosis for MetS components requires blood tests conducted within medical institutions. However, it is frequently underestimated, leading to unmet need for care for MetS population. This study aims to use the least physiological data and free texts about exercises related activities, which are obtained easily in daily life, to diagnosis MetS. We collected the data from 40 volunteers in a nursing home and used data augmentation to reduce the imbalance. We propose a deep learning framework for classifying MetS that integrates natural language processing (NLP) and exercise monitoring. The results showed that the best model reported a high positive result (AUROC=0.806 and REC=76.3%) through 3-fold cross-validation. Feature importance analysis revealed that text and minimum heart rate on a daily basis contribute the most in the classification of MetS. This study demonstrates the potential application of data that are easily measurable in daily life for the early diagnosis of MetS, which could contribute to reducing the cost of screening and management for MetS population.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08628v1",
    "published_date": "2025-05-13 14:48:36 UTC",
    "updated_date": "2025-05-13 14:48:36 UTC"
  },
  {
    "arxiv_id": "2505.08622v2",
    "title": "Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models",
    "authors": [
      "Donghoon Kim",
      "Minji Bae",
      "Kyuhong Shim",
      "Byonghyo Shim"
    ],
    "abstract": "Text-to-image generative models like DALL-E and Stable Diffusion have revolutionized visual content creation across various applications, including advertising, personalized media, and design prototyping. However, crafting effective textual prompts to guide these models remains challenging, often requiring extensive trial and error. Existing prompt inversion approaches, such as soft and hard prompt techniques, are not so effective due to the limited interpretability and incoherent prompt generation. To address these issues, we propose Visually Guided Decoding (VGD), a gradient-free approach that leverages large language models (LLMs) and CLIP-based guidance to generate coherent and semantically aligned prompts. In essence, VGD utilizes the robust text generation capabilities of LLMs to produce human-readable prompts. Further, by employing CLIP scores to ensure alignment with user-specified visual concepts, VGD enhances the interpretability, generalization, and flexibility of prompt generation without the need for additional training. Our experiments demonstrate that VGD outperforms existing prompt inversion techniques in generating understandable and contextually relevant prompts, facilitating more intuitive and controllable interactions with text-to-image models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2025 (Official Code: https://github.com/DonghoonKim-1938/VGD)",
    "pdf_url": "https://arxiv.org/pdf/2505.08622v2",
    "published_date": "2025-05-13 14:40:22 UTC",
    "updated_date": "2025-07-21 05:47:57 UTC"
  },
  {
    "arxiv_id": "2505.08620v1",
    "title": "Resource-Efficient Language Models: Quantization for Fast and Accessible Inference",
    "authors": [
      "Tollef Emil Jørgensen"
    ],
    "abstract": "Large language models have significantly advanced natural language processing, yet their heavy resource demands pose severe challenges regarding hardware accessibility and energy consumption. This paper presents a focused and high-level review of post-training quantization (PTQ) techniques designed to optimize the inference efficiency of LLMs by the end-user, including details on various quantization schemes, granularities, and trade-offs. The aim is to provide a balanced overview between the theory and applications of post-training quantization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 9 figures, preprint",
    "pdf_url": "https://arxiv.org/pdf/2505.08620v1",
    "published_date": "2025-05-13 14:39:33 UTC",
    "updated_date": "2025-05-13 14:39:33 UTC"
  },
  {
    "arxiv_id": "2505.08845v1",
    "title": "Validation of Conformal Prediction in Cervical Atypia Classification",
    "authors": [
      "Misgina Tsighe Hagos",
      "Antti Suutala",
      "Dmitrii Bychkov",
      "Hakan Kücükel",
      "Joar von Bahr",
      "Milda Poceviciute",
      "Johan Lundin",
      "Nina Linder",
      "Claes Lundström"
    ],
    "abstract": "Deep learning based cervical cancer classification can potentially increase access to screening in low-resource regions. However, deep learning models are often overconfident and do not reliably reflect diagnostic uncertainty. Moreover, they are typically optimized to generate maximum-likelihood predictions, which fail to convey uncertainty or ambiguity in their results. Such challenges can be addressed using conformal prediction, a model-agnostic framework for generating prediction sets that contain likely classes for trained deep-learning models. The size of these prediction sets indicates model uncertainty, contracting as model confidence increases. However, existing conformal prediction evaluation primarily focuses on whether the prediction set includes or covers the true class, often overlooking the presence of extraneous classes. We argue that prediction sets should be truthful and valuable to end users, ensuring that the listed likely classes align with human expectations rather than being overly relaxed and including false positives or unlikely classes. In this study, we comprehensively validate conformal prediction sets using expert annotation sets collected from multiple annotators. We evaluate three conformal prediction approaches applied to three deep-learning models trained for cervical atypia classification. Our expert annotation-based analysis reveals that conventional coverage-based evaluations overestimate performance and that current conformal prediction methods often produce prediction sets that are not well aligned with human labels. Additionally, we explore the capabilities of the conformal prediction methods in identifying ambiguous and out-of-distribution data.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08845v1",
    "published_date": "2025-05-13 14:37:58 UTC",
    "updated_date": "2025-05-13 14:37:58 UTC"
  },
  {
    "arxiv_id": "2505.08844v1",
    "title": "CellTypeAgent: Trustworthy cell type annotation with Large Language Models",
    "authors": [
      "Jiawen Chen",
      "Jianghao Zhang",
      "Huaxiu Yao",
      "Yun Li"
    ],
    "abstract": "Cell type annotation is a critical yet laborious step in single-cell RNA sequencing analysis. We present a trustworthy large language model (LLM)-agent, CellTypeAgent, which integrates LLMs with verification from relevant databases. CellTypeAgent achieves higher accuracy than existing methods while mitigating hallucinations. We evaluated CellTypeAgent across nine real datasets involving 303 cell types from 36 tissues. This combined approach holds promise for more efficient and reliable cell type annotation.",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08844v1",
    "published_date": "2025-05-13 14:34:11 UTC",
    "updated_date": "2025-05-13 14:34:11 UTC"
  },
  {
    "arxiv_id": "2505.08599v1",
    "title": "MINIMALIST: switched-capacitor circuits for efficient in-memory computation of gated recurrent units",
    "authors": [
      "Sebastian Billaudelle",
      "Laura Kriener",
      "Filippo Moro",
      "Tristan Torchet",
      "Melika Payvand"
    ],
    "abstract": "Recurrent neural networks (RNNs) have been a long-standing candidate for processing of temporal sequence data, especially in memory-constrained systems that one may find in embedded edge computing environments. Recent advances in training paradigms have now inspired new generations of efficient RNNs. We introduce a streamlined and hardware-compatible architecture based on minimal gated recurrent units (GRUs), and an accompanying efficient mixed-signal hardware implementation of the model. The proposed design leverages switched-capacitor circuits not only for in-memory computation (IMC), but also for the gated state updates. The mixed-signal cores rely solely on commodity circuits consisting of metal capacitors, transmission gates, and a clocked comparator, thus greatly facilitating scaling and transfer to other technology nodes.\n  We benchmark the performance of our architecture on time series data, introducing all constraints required for a direct mapping to the hardware system. The direct compatibility is verified in mixed-signal simulations, reproducing data recorded from the software-only network model.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08599v1",
    "published_date": "2025-05-13 14:13:41 UTC",
    "updated_date": "2025-05-13 14:13:41 UTC"
  },
  {
    "arxiv_id": "2505.08589v1",
    "title": "MESSI: A Multi-Elevation Semantic Segmentation Image Dataset of an Urban Environment",
    "authors": [
      "Barak Pinkovich",
      "Boaz Matalon",
      "Ehud Rivlin",
      "Hector Rotstein"
    ],
    "abstract": "This paper presents a Multi-Elevation Semantic Segmentation Image (MESSI) dataset comprising 2525 images taken by a drone flying over dense urban environments. MESSI is unique in two main features. First, it contains images from various altitudes, allowing us to investigate the effect of depth on semantic segmentation. Second, it includes images taken from several different urban regions (at different altitudes). This is important since the variety covers the visual richness captured by a drone's 3D flight, performing horizontal and vertical maneuvers. MESSI contains images annotated with location, orientation, and the camera's intrinsic parameters and can be used to train a deep neural network for semantic segmentation or other applications of interest (e.g., localization, navigation, and tracking). This paper describes the dataset and provides annotation details. It also explains how semantic segmentation was performed using several neural network models and shows several relevant statistics. MESSI will be published in the public domain to serve as an evaluation benchmark for semantic segmentation using images captured by a drone or similar vehicle flying over a dense urban environment.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08589v1",
    "published_date": "2025-05-13 14:01:07 UTC",
    "updated_date": "2025-05-13 14:01:07 UTC"
  },
  {
    "arxiv_id": "2505.08588v1",
    "title": "Small but Significant: On the Promise of Small Language Models for Accessible AIED",
    "authors": [
      "Yumou Wei",
      "Paulo Carvalho",
      "John Stamper"
    ],
    "abstract": "GPT has become nearly synonymous with large language models (LLMs), an increasingly popular term in AIED proceedings. A simple keyword-based search reveals that 61% of the 76 long and short papers presented at AIED 2024 describe novel solutions using LLMs to address some of the long-standing challenges in education, and 43% specifically mention GPT. Although LLMs pioneered by GPT create exciting opportunities to strengthen the impact of AI on education, we argue that the field's predominant focus on GPT and other resource-intensive LLMs (with more than 10B parameters) risks neglecting the potential impact that small language models (SLMs) can make in providing resource-constrained institutions with equitable and affordable access to high-quality AI tools. Supported by positive results on knowledge component (KC) discovery, a critical challenge in AIED, we demonstrate that SLMs such as Phi-2 can produce an effective solution without elaborate prompting strategies. Hence, we call for more attention to developing SLM-based AIED approaches.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "This vision paper advocates using small language models (e.g., Phi-2) in AI for education (AIED)",
    "pdf_url": "https://arxiv.org/pdf/2505.08588v1",
    "published_date": "2025-05-13 13:58:29 UTC",
    "updated_date": "2025-05-13 13:58:29 UTC"
  },
  {
    "arxiv_id": "2505.08552v1",
    "title": "DFA-CON: A Contrastive Learning Approach for Detecting Copyright Infringement in DeepFake Art",
    "authors": [
      "Haroon Wahab",
      "Hassan Ugail",
      "Irfan Mehmood"
    ],
    "abstract": "Recent proliferation of generative AI tools for visual content creation-particularly in the context of visual artworks-has raised serious concerns about copyright infringement and forgery. The large-scale datasets used to train these models often contain a mixture of copyrighted and non-copyrighted artworks. Given the tendency of generative models to memorize training patterns, they are susceptible to varying degrees of copyright violation. Building on the recently proposed DeepfakeArt Challenge benchmark, this work introduces DFA-CON, a contrastive learning framework designed to detect copyright-infringing or forged AI-generated art. DFA-CON learns a discriminative representation space, posing affinity among original artworks and their forged counterparts within a contrastive learning framework. The model is trained across multiple attack types, including inpainting, style transfer, adversarial perturbation, and cutmix. Evaluation results demonstrate robust detection performance across most attack types, outperforming recent pretrained foundation models. Code and model checkpoints will be released publicly upon acceptance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08552v1",
    "published_date": "2025-05-13 13:23:52 UTC",
    "updated_date": "2025-05-13 13:23:52 UTC"
  },
  {
    "arxiv_id": "2505.08548v2",
    "title": "From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation",
    "authors": [
      "Yifu Yuan",
      "Haiqin Cui",
      "Yibin Chen",
      "Zibin Dong",
      "Fei Ni",
      "Longxin Kou",
      "Jinyi Liu",
      "Pengyi Li",
      "Yan Zheng",
      "Jianye Hao"
    ],
    "abstract": "Achieving generalization in robotic manipulation remains a critical challenge, particularly for unseen scenarios and novel tasks. Current Vision-Language-Action (VLA) models, while building on top of general Vision-Language Models (VLMs), still fall short of achieving robust zero-shot performance due to the scarcity and heterogeneity prevalent in embodied datasets. To address these limitations, we propose FSD (From Seeing to Doing), a novel vision-language model that generates intermediate representations through spatial relationship reasoning, providing fine-grained guidance for robotic manipulation. Our approach combines a hierarchical data pipeline for training with a self-consistency mechanism that aligns spatial coordinates with visual signals. Through extensive experiments, we comprehensively validated FSD's capabilities in both \"seeing\" and \"doing,\" achieving outstanding performance across 8 benchmarks for general spatial reasoning and embodied reference abilities, as well as on our proposed more challenging benchmark VABench. We also verified zero-shot capabilities in robot manipulation, demonstrating significant performance improvements over baseline methods in both SimplerEnv and real robot settings. Experimental results show that FSD achieves 40.6% success rate in SimplerEnv and 72% success rate across 8 real-world tasks, outperforming the strongest baseline by 30%.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Our project homepage: https://embodied-fsd.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2505.08548v2",
    "published_date": "2025-05-13 13:20:46 UTC",
    "updated_date": "2025-05-27 03:37:39 UTC"
  },
  {
    "arxiv_id": "2505.08542v1",
    "title": "Guiding LLM-based Smart Contract Generation with Finite State Machine",
    "authors": [
      "Hao Luo",
      "Yuhao Lin",
      "Xiao Yan",
      "Xintong Hu",
      "Yuxiang Wang",
      "Qiming Zeng",
      "Hao Wang",
      "Jiawei Jiang"
    ],
    "abstract": "Smart contract is a kind of self-executing code based on blockchain technology with a wide range of application scenarios, but the traditional generation method relies on manual coding and expert auditing, which has a high threshold and low efficiency. Although Large Language Models (LLMs) show great potential in programming tasks, they still face challenges in smart contract generation w.r.t. effectiveness and security. To solve these problems, we propose FSM-SCG, a smart contract generation framework based on finite state machine (FSM) and LLMs, which significantly improves the quality of the generated code by abstracting user requirements to generate FSM, guiding LLMs to generate smart contracts, and iteratively optimizing the code with the feedback of compilation and security checks. The experimental results show that FSM-SCG significantly improves the quality of smart contract generation. Compared to the best baseline, FSM-SCG improves the compilation success rate of generated smart contract code by at most 48%, and reduces the average vulnerability risk score by approximately 68%.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08542v1",
    "published_date": "2025-05-13 13:13:26 UTC",
    "updated_date": "2025-05-13 13:13:26 UTC"
  },
  {
    "arxiv_id": "2505.17043v1",
    "title": "QRA++: Quantified Reproducibility Assessment for Common Types of Results in Natural Language Processing",
    "authors": [
      "Anya Belz"
    ],
    "abstract": "Reproduction studies reported in NLP provide individual data points which in combination indicate worryingly low levels of reproducibility in the field. Because each reproduction study reports quantitative conclusions based on its own, often not explicitly stated, criteria for reproduction success/failure, the conclusions drawn are hard to interpret, compare, and learn from. In this paper, we present QRA++, a quantitative approach to reproducibility assessment that (i) produces continuous-valued degree of reproducibility assessments at three levels of granularity; (ii) utilises reproducibility measures that are directly comparable across different studies; and (iii) grounds expectations about degree of reproducibility in degree of similarity between experiments. QRA++ enables more informative reproducibility assessments to be conducted, and conclusions to be drawn about what causes reproducibility to be better/poorer. We illustrate this by applying QRA++ to three example sets of comparable experiments, revealing clear evidence that degree of reproducibility depends on similarity of experiment properties, but also system type and evaluation method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.17043v1",
    "published_date": "2025-05-13 13:04:04 UTC",
    "updated_date": "2025-05-13 13:04:04 UTC"
  },
  {
    "arxiv_id": "2505.08532v1",
    "title": "The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large Language Models Unmask Fake News",
    "authors": [
      "Yuhan Liu",
      "Yuxuan Liu",
      "Xiaoqing Zhang",
      "Xiuying Chen",
      "Rui Yan"
    ],
    "abstract": "In today's digital environment, the rapid propagation of fake news via social networks poses significant social challenges. Most existing detection methods either employ traditional classification models, which suffer from low interpretability and limited generalization capabilities, or craft specific prompts for large language models (LLMs) to produce explanations and results directly, failing to leverage LLMs' reasoning abilities fully. Inspired by the saying that \"truth becomes clearer through debate,\" our study introduces a novel multi-agent system with LLMs named TruEDebate (TED) to enhance the interpretability and effectiveness of fake news detection. TED employs a rigorous debate process inspired by formal debate settings. Central to our approach are two innovative components: the DebateFlow Agents and the InsightFlow Agents. The DebateFlow Agents organize agents into two teams, where one supports and the other challenges the truth of the news. These agents engage in opening statements, cross-examination, rebuttal, and closing statements, simulating a rigorous debate process akin to human discourse analysis, allowing for a thorough evaluation of news content. Concurrently, the InsightFlow Agents consist of two specialized sub-agents: the Synthesis Agent and the Analysis Agent. The Synthesis Agent summarizes the debates and provides an overarching viewpoint, ensuring a coherent and comprehensive evaluation. The Analysis Agent, which includes a role-aware encoder and a debate graph, integrates role embeddings and models the interactions between debate roles and arguments using an attention mechanism, providing the final judgment.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "SIGIR 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08532v1",
    "published_date": "2025-05-13 13:03:20 UTC",
    "updated_date": "2025-05-13 13:03:20 UTC"
  },
  {
    "arxiv_id": "2505.08529v1",
    "title": "ExEBench: Benchmarking Foundation Models on Extreme Earth Events",
    "authors": [
      "Shan Zhao",
      "Zhitong Xiong",
      "Jie Zhao",
      "Xiao Xiang Zhu"
    ],
    "abstract": "Our planet is facing increasingly frequent extreme events, which pose major risks to human lives and ecosystems. Recent advances in machine learning (ML), especially with foundation models (FMs) trained on extensive datasets, excel in extracting features and show promise in disaster management. Nevertheless, these models often inherit biases from training data, challenging their performance over extreme values. To explore the reliability of FM in the context of extreme events, we introduce \\textbf{ExE}Bench (\\textbf{Ex}treme \\textbf{E}arth Benchmark), a collection of seven extreme event categories across floods, wildfires, storms, tropical cyclones, extreme precipitation, heatwaves, and cold waves. The dataset features global coverage, varying data volumes, and diverse data sources with different spatial, temporal, and spectral characteristics. To broaden the real-world impact of FMs, we include multiple challenging ML tasks that are closely aligned with operational needs in extreme events detection, monitoring, and forecasting. ExEBench aims to (1) assess FM generalizability across diverse, high-impact tasks and domains, (2) promote the development of novel ML methods that benefit disaster management, and (3) offer a platform for analyzing the interactions and cascading effects of extreme events to advance our understanding of Earth system, especially under the climate change expected in the decades to come. The dataset and code are public https://github.com/zhaoshan2/EarthExtreme-Bench.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08529v1",
    "published_date": "2025-05-13 13:02:04 UTC",
    "updated_date": "2025-05-13 13:02:04 UTC"
  },
  {
    "arxiv_id": "2505.08528v2",
    "title": "GradMix: Gradient-based Selective Mixup for Robust Data Augmentation in Class-Incremental Learning",
    "authors": [
      "Minsu Kim",
      "Seong-Hyeon Hwang",
      "Steven Euijong Whang"
    ],
    "abstract": "In the context of continual learning, acquiring new knowledge while maintaining previous knowledge presents a significant challenge. Existing methods often use experience replay techniques that store a small portion of previous task data for training. In experience replay approaches, data augmentation has emerged as a promising strategy to further improve the model performance by mixing limited previous task data with sufficient current task data. However, we theoretically and empirically analyze that training with mixed samples from random sample pairs may harm the knowledge of previous tasks and cause greater catastrophic forgetting. We then propose GradMix, a robust data augmentation method specifically designed for mitigating catastrophic forgetting in class-incremental learning. GradMix performs gradient-based selective mixup using a class-based criterion that mixes only samples from helpful class pairs and not from detrimental class pairs for reducing catastrophic forgetting. Our experiments on various real datasets show that GradMix outperforms data augmentation baselines in accuracy by minimizing the forgetting of previous knowledge.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to KDD 2026",
    "pdf_url": "https://arxiv.org/pdf/2505.08528v2",
    "published_date": "2025-05-13 13:01:38 UTC",
    "updated_date": "2025-12-23 06:18:57 UTC"
  },
  {
    "arxiv_id": "2505.08522v1",
    "title": "On the Complexity and Properties of Preferential Propositional Dependence Logic",
    "authors": [
      "Kai Sauerwald",
      "Arne Meier",
      "Juha Kontinen"
    ],
    "abstract": "This paper considers the complexity and properties of KLM-style preferential reasoning in the setting of propositional logic with team semantics and dependence atoms, also known as propositional dependence logic. Preferential team-based reasoning is shown to be cumulative, yet violates System~P. We give intuitive conditions that fully characterise those cases where preferential propositional dependence logic satisfies System~P. We show that these characterisations do, surprisingly, not carry over to preferential team-based propositional logic. Furthermore, we show how classical entailment and dependence logic entailment can be expressed in terms of non-trivial preferential models. Finally, we present the complexity of preferential team-based reasoning for two natural representations. This includes novel complexity results for classical (non-team-based) preferential reasoning.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08522v1",
    "published_date": "2025-05-13 12:54:59 UTC",
    "updated_date": "2025-05-13 12:54:59 UTC"
  },
  {
    "arxiv_id": "2505.08516v1",
    "title": "Learning Advanced Self-Attention for Linear Transformers in the Singular Value Domain",
    "authors": [
      "Hyowon Wi",
      "Jeongwhan Choi",
      "Noseong Park"
    ],
    "abstract": "Transformers have demonstrated remarkable performance across diverse domains. The key component of Transformers is self-attention, which learns the relationship between any two tokens in the input sequence. Recent studies have revealed that the self-attention can be understood as a normalized adjacency matrix of a graph. Notably, from the perspective of graph signal processing (GSP), the self-attention can be equivalently defined as a simple graph filter, applying GSP using the value vector as the signal. However, the self-attention is a graph filter defined with only the first order of the polynomial matrix, and acts as a low-pass filter preventing the effective leverage of various frequency information. Consequently, existing self-attention mechanisms are designed in a rather simplified manner. Therefore, we propose a novel method, called \\underline{\\textbf{A}}ttentive \\underline{\\textbf{G}}raph \\underline{\\textbf{F}}ilter (AGF), interpreting the self-attention as learning the graph filter in the singular value domain from the perspective of graph signal processing for directed graphs with the linear complexity w.r.t. the input length $n$, i.e., $\\mathcal{O}(nd^2)$. In our experiments, we demonstrate that AGF achieves state-of-the-art performance on various tasks, including Long Range Arena benchmark and time series classification.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IJCAI25 Accepted",
    "pdf_url": "https://arxiv.org/pdf/2505.08516v1",
    "published_date": "2025-05-13 12:48:04 UTC",
    "updated_date": "2025-05-13 12:48:04 UTC"
  },
  {
    "arxiv_id": "2505.08508v1",
    "title": "TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System to Streamline Patient-to-Trial Matching",
    "authors": [
      "Majd Abdallah",
      "Sigve Nakken",
      "Mariska Bierkens",
      "Johanna Galvis",
      "Alexis Groppi",
      "Slim Karkar",
      "Lana Meiqari",
      "Maria Alexandra Rujano",
      "Steve Canham",
      "Rodrigo Dienstmann",
      "Remond Fijneman",
      "Eivind Hovig",
      "Gerrit Meijer",
      "Macha Nikolski"
    ],
    "abstract": "Patient recruitment remains a major bottleneck in clinical trials, calling for scalable and automated solutions. We present TrialMatchAI, an AI-powered recommendation system that automates patient-to-trial matching by processing heterogeneous clinical data, including structured records and unstructured physician notes. Built on fine-tuned, open-source large language models (LLMs) within a retrieval-augmented generation framework, TrialMatchAI ensures transparency and reproducibility and maintains a lightweight deployment footprint suitable for clinical environments. The system normalizes biomedical entities, retrieves relevant trials using a hybrid search strategy combining lexical and semantic similarity, re-ranks results, and performs criterion-level eligibility assessments using medical Chain-of-Thought reasoning. This pipeline delivers explainable outputs with traceable decision rationales. In real-world validation, 92 percent of oncology patients had at least one relevant trial retrieved within the top 20 recommendations. Evaluation across synthetic and real clinical datasets confirmed state-of-the-art performance, with expert assessment validating over 90 percent accuracy in criterion-level eligibility classification, particularly excelling in biomarker-driven matches. Designed for modularity and privacy, TrialMatchAI supports Phenopackets-standardized data, enables secure local deployment, and allows seamless replacement of LLM components as more advanced models emerge. By enhancing efficiency and interpretability and offering lightweight, open-source deployment, TrialMatchAI provides a scalable solution for AI-driven clinical trial matching in precision medicine.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08508v1",
    "published_date": "2025-05-13 12:39:06 UTC",
    "updated_date": "2025-05-13 12:39:06 UTC"
  },
  {
    "arxiv_id": "2505.08498v2",
    "title": "LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using Large Language Models",
    "authors": [
      "Takumi Shibata",
      "Yuichi Miyamura"
    ],
    "abstract": "Recent advances in large language models (LLMs) have enabled zero-shot automated essay scoring (AES), providing a promising way to reduce the cost and effort of essay scoring in comparison with manual grading. However, most existing zero-shot approaches rely on LLMs to directly generate absolute scores, which often diverge from human evaluations owing to model biases and inconsistent scoring. To address these limitations, we propose LLM-based Comparative Essay Scoring (LCES), a method that formulates AES as a pairwise comparison task. Specifically, we instruct LLMs to judge which of two essays is better, collect many such comparisons, and convert them into continuous scores. Considering that the number of possible comparisons grows quadratically with the number of essays, we improve scalability by employing RankNet to efficiently transform LLM preferences into scalar scores. Experiments using AES benchmark datasets show that LCES outperforms conventional zero-shot methods in accuracy while maintaining computational efficiency. Moreover, LCES is robust across different LLM backbones, highlighting its applicability to real-world zero-shot AES.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2025 (Main Conference)",
    "pdf_url": "https://arxiv.org/pdf/2505.08498v2",
    "published_date": "2025-05-13 12:26:16 UTC",
    "updated_date": "2025-09-21 10:54:09 UTC"
  },
  {
    "arxiv_id": "2505.08492v2",
    "title": "Achieving Scalable Robot Autonomy via neurosymbolic planning using lightweight local LLM",
    "authors": [
      "Nicholas Attolino",
      "Alessio Capitanelli",
      "Fulvio Mastrogiovanni"
    ],
    "abstract": "PDDL-based symbolic task planning remains pivotal for robot autonomy yet struggles with dynamic human-robot collaboration due to scalability, re-planning demands, and delayed plan availability. Although a few neurosymbolic frameworks have previously leveraged LLMs such as GPT-3 to address these challenges, reliance on closed-source, remote models with limited context introduced critical constraints: third-party dependency, inconsistent response times, restricted plan length and complexity, and multi-domain scalability issues. We present Gideon, a novel framework that enables the transition to modern, smaller, local LLMs with extended context length. Gideon integrates a novel problem generator to systematically generate large-scale datasets of realistic domain-problem-plan tuples for any domain, and adapts neurosymbolic planning for local LLMs, enabling on-device execution and extended context for multi-domain support. Preliminary experiments in single-domain scenarios performed on Qwen-2.5 1.5B and trained on 8k-32k samples, demonstrate a valid plan percentage of 66.1% (32k model) and show that the figure can be further scaled through additional data. Multi-domain tests on 16k samples yield an even higher 70.6% planning validity rate, proving extensibility across domains and signaling that data variety can have a positive effect on learning efficiency. Although long-horizon planning and reduced model size make Gideon training much less efficient than baseline models based on larger LLMs, the results are still significant considering that the trained model is about 120x smaller than baseline and that significant advantages can be achieved in inference efficiency, scalability, and multi-domain adaptability, all critical factors in human-robot collaboration. Training inefficiency can be mitigated by Gideon's streamlined data generation pipeline.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 3 figures, 4 tables, accepted at IAS 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08492v2",
    "published_date": "2025-05-13 12:22:38 UTC",
    "updated_date": "2025-05-17 11:55:07 UTC"
  },
  {
    "arxiv_id": "2505.08487v1",
    "title": "An adaptive sampling algorithm for data-generation to build a data-manifold for physical problem surrogate modeling",
    "authors": [
      "Chetra Mang",
      "Axel TahmasebiMoradi",
      "David Danan",
      "Mouadh Yagoubi"
    ],
    "abstract": "Physical models classically involved Partial Differential equations (PDE) and depending of their underlying complexity and the level of accuracy required, and known to be computationally expensive to numerically solve them. Thus, an idea would be to create a surrogate model relying on data generated by such solver. However, training such a model on an imbalanced data have been shown to be a very difficult task. Indeed, if the distribution of input leads to a poor response manifold representation, the model may not learn well and consequently, it may not predict the outcome with acceptable accuracy. In this work, we present an Adaptive Sampling Algorithm for Data Generation (ASADG) involving a physical model. As the initial input data may not accurately represent the response manifold in higher dimension, this algorithm iteratively adds input data into it. At each step the barycenter of each simplicial complex, that the manifold is discretized into, is added as new input data, if a certain threshold is satisfied. We demonstrate the efficiency of the data sampling algorithm in comparison with LHS method for generating more representative input data. To do so, we focus on the construction of a harmonic transport problem metamodel by generating data through a classical solver. By using such algorithm, it is possible to generate the same number of input data as LHS while providing a better representation of the response manifold.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08487v1",
    "published_date": "2025-05-13 12:17:10 UTC",
    "updated_date": "2025-05-13 12:17:10 UTC"
  },
  {
    "arxiv_id": "2505.09651v1",
    "title": "Unlocking Location Intelligence: A Survey from Deep Learning to The LLM Era",
    "authors": [
      "Xixuan Hao",
      "Yutian Jiang",
      "Xingchen Zou",
      "Jiabo Liu",
      "Yifang Yin",
      "Yuxuan Liang"
    ],
    "abstract": "Location Intelligence (LI), the science of transforming location-centric geospatial data into actionable knowledge, has become a cornerstone of modern spatial decision-making. The rapid evolution of Geospatial Representation Learning is fundamentally reshaping LI development through two successive technological revolutions: the deep learning breakthrough and the emerging large language model (LLM) paradigm. While deep neural networks (DNNs) have demonstrated remarkable success in automated feature extraction from structured geospatial data (e.g., satellite imagery, GPS trajectories), the recent integration of LLMs introduces transformative capabilities for cross-modal geospatial reasoning and unstructured geo-textual data processing. This survey presents a comprehensive review of geospatial representation learning across both technological eras, organizing them into a structured taxonomy based on the complete pipeline comprising: (1) data perspective, (2) methodological perspective and (3) application perspective. We also highlight current advancements, discuss existing limitations, and propose potential future research directions in the LLM era. This work offers a thorough exploration of the field and providing a roadmap for further innovation in LI. The summary of the up-to-date paper list can be found in https://github.com/CityMind-Lab/Awesome-Location-Intelligence and will undergo continuous updates.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.09651v1",
    "published_date": "2025-05-13 12:16:26 UTC",
    "updated_date": "2025-05-13 12:16:26 UTC"
  },
  {
    "arxiv_id": "2505.08485v1",
    "title": "BAT: Benchmark for Auto-bidding Task",
    "authors": [
      "Alexandra Khirianova",
      "Ekaterina Solodneva",
      "Andrey Pudovikov",
      "Sergey Osokin",
      "Egor Samosvat",
      "Yuriy Dorn",
      "Alexander Ledovsky",
      "Yana Zenkova"
    ],
    "abstract": "The optimization of bidding strategies for online advertising slot auctions presents a critical challenge across numerous digital marketplaces. A significant obstacle to the development, evaluation, and refinement of real-time autobidding algorithms is the scarcity of comprehensive datasets and standardized benchmarks.\n  To address this deficiency, we present an auction benchmark encompassing the two most prevalent auction formats. We implement a series of robust baselines on a novel dataset, addressing the most salient Real-Time Bidding (RTB) problem domains: budget pacing uniformity and Cost Per Click (CPC) constraint optimization. This benchmark provides a user-friendly and intuitive framework for researchers and practitioners to develop and refine innovative autobidding algorithms, thereby facilitating advancements in the field of programmatic advertising. The implementation and additional resources can be accessed at the following repository (https://github.com/avito-tech/bat-autobidding-benchmark, https://doi.org/10.5281/zenodo.14794182).",
    "categories": [
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 10 figures, WWW 2025 conference",
    "pdf_url": "https://arxiv.org/pdf/2505.08485v1",
    "published_date": "2025-05-13 12:12:34 UTC",
    "updated_date": "2025-05-13 12:12:34 UTC"
  },
  {
    "arxiv_id": "2505.18164v1",
    "title": "Model-Distributed Inference for Large Language Models at the Edge",
    "authors": [
      "Davide Macario",
      "Hulya Seferoglu",
      "Erdem Koyuncu"
    ],
    "abstract": "We introduce Model-Distributed Inference for Large-Language Models (MDI-LLM), a novel framework designed to facilitate the deployment of state-of-the-art large-language models (LLMs) across low-power devices at the edge. This is accomplished by dividing the model into multiple partitions, which are then assigned to different devices/nodes within the network. These nodes exchange intermediate activation vectors via device-to-device links, enabling collaborative computation. To enhance the efficiency of this process, we propose the \"recurrent pipeline parallelism\" technique, which reduces idle time on each device and facilitates parallel inference during the generation of multiple text sequences. By leveraging the combined computational resources of multiple edge devices, MDI-LLM enables the deployment of LLMs that exceed the memory capacity of individual devices, making it possible to perform inference on low-cost hardware. Furthermore, as the number of participating devices increases, MDI-LLM boosts token generation throughput and reduces memory consumption per device.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.18164v1",
    "published_date": "2025-05-13 12:07:37 UTC",
    "updated_date": "2025-05-13 12:07:37 UTC"
  },
  {
    "arxiv_id": "2505.08474v1",
    "title": "Distributed Quantum Neural Networks on Distributed Photonic Quantum Computing",
    "authors": [
      "Kuan-Cheng Chen",
      "Chen-Yu Liu",
      "Yu Shang",
      "Felix Burt",
      "Kin K. Leung"
    ],
    "abstract": "We introduce a distributed quantum-classical framework that synergizes photonic quantum neural networks (QNNs) with matrix-product-state (MPS) mapping to achieve parameter-efficient training of classical neural networks. By leveraging universal linear-optical decompositions of $M$-mode interferometers and photon-counting measurement statistics, our architecture generates neural parameters through a hybrid quantum-classical workflow: photonic QNNs with $M(M+1)/2$ trainable parameters produce high-dimensional probability distributions that are mapped to classical network weights via an MPS model with bond dimension $χ$. Empirical validation on MNIST classification demonstrates that photonic QT achieves an accuracy of $95.50\\% \\pm 0.84\\%$ using 3,292 parameters ($χ= 10$), compared to $96.89\\% \\pm 0.31\\%$ for classical baselines with 6,690 parameters. Moreover, a ten-fold compression ratio is achieved at $χ= 4$, with a relative accuracy loss of less than $3\\%$. The framework outperforms classical compression techniques (weight sharing/pruning) by 6--12\\% absolute accuracy while eliminating quantum hardware requirements during inference through classical deployment of compressed parameters. Simulations incorporating realistic photonic noise demonstrate the framework's robustness to near-term hardware imperfections. Ablation studies confirm quantum necessity: replacing photonic QNNs with random inputs collapses accuracy to chance level ($10.0\\% \\pm 0.5\\%$). Photonic quantum computing's room-temperature operation, inherent scalability through spatial-mode multiplexing, and HPC-integrated architecture establish a practical pathway for distributed quantum machine learning, combining the expressivity of photonic Hilbert spaces with the deployability of classical neural networks.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08474v1",
    "published_date": "2025-05-13 11:58:45 UTC",
    "updated_date": "2025-05-13 11:58:45 UTC"
  },
  {
    "arxiv_id": "2505.08463v2",
    "title": "RepCali: High Efficient Fine-tuning Via Representation Calibration in Latent Space for Pre-trained Language Models",
    "authors": [
      "Fujun Zhang",
      "Xiaoying Fan",
      "XiangDong Su",
      "Guanglai Gao"
    ],
    "abstract": "Fine-tuning pre-trained language models (PLMs) has become a dominant paradigm in applying PLMs to downstream tasks. However, with limited fine-tuning, PLMs still struggle with the discrepancies between the representation obtained from the PLMs' encoder and the optimal input to the PLMs' decoder. This paper tackles this challenge by learning to calibrate the representation of PLMs in the latent space. In the proposed representation calibration method (RepCali), we integrate a specific calibration block to the latent space after the encoder and use the calibrated output as the decoder input. The merits of the proposed RepCali include its universality to all PLMs with encoder-decoder architectures, its plug-and-play nature, and ease of implementation. Extensive experiments on 25 PLM-based models across 8 tasks (including both English and Chinese datasets) demonstrate that the proposed RepCali offers desirable enhancements to PLMs (including LLMs) and significantly improves the performance of downstream tasks. Comparison experiments across 4 benchmark tasks indicate that RepCali is superior to the representative fine-tuning baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.08463v2",
    "published_date": "2025-05-13 11:47:00 UTC",
    "updated_date": "2025-05-29 05:01:48 UTC"
  },
  {
    "arxiv_id": "2505.08841v2",
    "title": "Will AI Take My Job? Evolving Perceptions of Automation and Labor Risk in Latin America",
    "authors": [
      "Andrea Cremaschi",
      "Dae-Jin Lee",
      "Manuele Leonelli"
    ],
    "abstract": "As artificial intelligence and robotics increasingly reshape the global labor market, understanding public perceptions of these technologies becomes critical. We examine how these perceptions have evolved across Latin America, using survey data from the 2017, 2018, 2020, and 2023 waves of the Latinobarómetro. Drawing on responses from over 48,000 individuals across 16 countries, we analyze fear of job loss due to artificial intelligence and robotics. Using statistical modeling and latent class analysis, we identify key structural and ideological predictors of concern, with education level and political orientation emerging as the most consistent drivers. Our findings reveal substantial temporal and cross-country variation, with a notable peak in fear during 2018 and distinct attitudinal profiles emerging from latent segmentation. These results offer new insights into the social and structural dimensions of AI anxiety in emerging economies and contribute to a broader understanding of public attitudes toward automation beyond the Global North.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08841v2",
    "published_date": "2025-05-13 11:43:02 UTC",
    "updated_date": "2025-07-29 20:43:16 UTC"
  },
  {
    "arxiv_id": "2505.08459v2",
    "title": "Strategy-Augmented Planning for Large Language Models via Opponent Exploitation",
    "authors": [
      "Shuai Xu",
      "Sijia Cui",
      "Yanna Wang",
      "Bo Xu",
      "Qi Wang"
    ],
    "abstract": "Efficiently modeling and exploiting opponents is a long-standing challenge in adversarial domains. Large Language Models (LLMs) trained on extensive textual data have recently demonstrated outstanding performance in general tasks, introducing new research directions for opponent modeling. Some studies primarily focus on directly using LLMs to generate decisions based on the elaborate prompt context that incorporates opponent descriptions, while these approaches are limited to scenarios where LLMs possess adequate domain expertise. To address that, we introduce a two-stage Strategy-Augmented Planning (SAP) framework that significantly enhances the opponent exploitation capabilities of LLM-based agents by utilizing a critical component, the Strategy Evaluation Network (SEN). Specifically, in the offline stage, we construct an explicit strategy space and subsequently collect strategy-outcome pair data for training the SEN network. During the online phase, SAP dynamically recognizes the opponent's strategies and greedily exploits them by searching best response strategy on the well-trained SEN, finally translating strategy to a course of actions by carefully designed prompts. Experimental results show that SAP exhibits robust generalization capabilities, allowing it to perform effectively not only against previously encountered opponent strategies but also against novel, unseen strategies. In the MicroRTS environment, SAP achieves a $85.35\\%$ performance improvement over baseline methods and matches the competitiveness of reinforcement learning approaches against state-of-the-art (SOTA) rule-based AI. Our code is available at https://github.com/hsushuai/SAP.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to IJCNN 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08459v2",
    "published_date": "2025-05-13 11:41:10 UTC",
    "updated_date": "2025-06-01 11:53:16 UTC"
  },
  {
    "arxiv_id": "2505.08451v2",
    "title": "Adaptive Bias Generalized Rollout Policy Adaptation on the Flexible Job-Shop Scheduling Problem",
    "authors": [
      "Lotfi Kobrosly",
      "Marc-Emmanuel Coupvent des Graviers",
      "Christophe Guettier",
      "Tristan Cazenave"
    ],
    "abstract": "The Flexible Job-Shop Scheduling Problem (FJSSP) is an NP-hard combinatorial optimization problem, with several application domains, especially for manufacturing purposes. The objective is to efficiently schedule multiple operations on dissimilar machines. These operations are gathered into jobs, and operations pertaining to the same job need to be scheduled sequentially. Different methods have been previously tested to solve this problem, such as Constraint Solving, Tabu Search, Genetic Algorithms, or Monte Carlo Tree Search (MCTS). We propose a novel algorithm derived from the Generalized Nested Rollout Policy Adaptation, developed to solve the FJSSP. We report encouraging experimental results, as our algorithm performs better than other MCTS-based approaches, even if makespans obtained on large instances are still far from known upper bounds.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "The 19th Learning and Intelligent OptimizatioN Conference, LION19 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08451v2",
    "published_date": "2025-05-13 11:27:18 UTC",
    "updated_date": "2025-05-20 09:34:45 UTC"
  },
  {
    "arxiv_id": "2505.08446v1",
    "title": "Agent-as-a-Service based on Agent Network",
    "authors": [
      "Yuhan Zhu",
      "Haojie Liu",
      "Jian Wang",
      "Bing Li",
      "Zikang Yin",
      "Yefei Liao"
    ],
    "abstract": "The rise of large model-based AI agents has spurred interest in Multi-Agent Systems (MAS) for their capabilities in decision-making, collaboration, and adaptability. While the Model Context Protocol (MCP) addresses tool invocation and data exchange challenges via a unified protocol, it lacks support for organizing agent-level collaboration. To bridge this gap, we propose Agent-as-a-Service based on Agent Network (AaaS-AN), a service-oriented paradigm grounded in the Role-Goal-Process-Service (RGPS) standard. AaaS-AN unifies the entire agent lifecycle, including construction, integration, interoperability, and networked collaboration, through two core components: (1) a dynamic Agent Network, which models agents and agent groups as vertexes that self-organize within the network based on task and role dependencies; (2) service-oriented agents, incorporating service discovery, registration, and interoperability protocols. These are orchestrated by a Service Scheduler, which leverages an Execution Graph to enable distributed coordination, context tracking, and runtime task management. We validate AaaS-AN on mathematical reasoning and application-level code generation tasks, which outperforms state-of-the-art baselines. Notably, we constructed a MAS based on AaaS-AN containing agent groups, Robotic Process Automation (RPA) workflows, and MCP servers over 100 agent services. We also release a dataset containing 10,000 long-horizon multi-agent workflows to facilitate future research on long-chain collaboration in MAS.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "work in progress",
    "pdf_url": "https://arxiv.org/pdf/2505.08446v1",
    "published_date": "2025-05-13 11:15:19 UTC",
    "updated_date": "2025-05-13 11:15:19 UTC"
  },
  {
    "arxiv_id": "2505.08445v1",
    "title": "Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency",
    "authors": [
      "Adel Ammar",
      "Anis Koubaa",
      "Omer Nacar",
      "Wadii Boulila"
    ],
    "abstract": "Large language models achieve high task performance yet often hallucinate or rely on outdated knowledge. Retrieval-augmented generation (RAG) addresses these gaps by coupling generation with external search. We analyse how hyperparameters influence speed and quality in RAG systems, covering Chroma and Faiss vector stores, chunking policies, cross-encoder re-ranking, and temperature, and we evaluate six metrics: faithfulness, answer correctness, answer relevancy, context precision, context recall, and answer similarity. Chroma processes queries 13% faster, whereas Faiss yields higher retrieval precision, revealing a clear speed-accuracy trade-off. Naive fixed-length chunking with small windows and minimal overlap outperforms semantic segmentation while remaining the quickest option. Re-ranking provides modest gains in retrieval quality yet increases runtime by roughly a factor of 5, so its usefulness depends on latency constraints. These results help practitioners balance computational cost and accuracy when tuning RAG systems for transparent, up-to-date responses. Finally, we re-evaluate the top configurations with a corrective RAG workflow and show that their advantages persist when the model can iteratively request additional evidence. We obtain a near-perfect context precision (99%), which demonstrates that RAG systems can achieve extremely high retrieval accuracy with the right combination of hyperparameters, with significant implications for applications where retrieval quality directly impacts downstream task performance, such as clinical decision support in healthcare.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08445v1",
    "published_date": "2025-05-13 11:13:27 UTC",
    "updated_date": "2025-05-13 11:13:27 UTC"
  },
  {
    "arxiv_id": "2505.08438v3",
    "title": "A Survey of 3D Reconstruction with Event Cameras",
    "authors": [
      "Chuanzhi Xu",
      "Haoxian Zhou",
      "Langyi Chen",
      "Haodong Chen",
      "Zeke Zexi Hu",
      "Zhicheng Lu",
      "Ying Zhou",
      "Vera Chung",
      "Qiang Qu",
      "Weidong Cai"
    ],
    "abstract": "Event cameras are rapidly emerging as powerful vision sensors for 3D reconstruction, uniquely capable of asynchronously capturing per-pixel brightness changes. Compared to traditional frame-based cameras, event cameras produce sparse yet temporally dense data streams, enabling robust and accurate 3D reconstruction even under challenging conditions such as high-speed motion, low illumination, and extreme dynamic range scenarios. These capabilities offer substantial promise for transformative applications across various fields, including autonomous driving, robotics, aerial navigation, and immersive virtual reality. In this survey, we present the first comprehensive review exclusively dedicated to event-based 3D reconstruction. Existing approaches are systematically categorised based on input modality into stereo, monocular, and multimodal systems, and further classified according to reconstruction methodologies, including geometry-based techniques, deep learning approaches, and neural rendering techniques such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). Within each category, methods are chronologically organised to highlight the evolution of key concepts and advancements. Furthermore, we provide a detailed summary of publicly available datasets specifically suited to event-based reconstruction tasks. Finally, we discuss significant open challenges in dataset availability, standardised evaluation, effective representation, and dynamic scene reconstruction, outlining insightful directions for future research. This survey aims to serve as an essential reference and provides a clear and motivating roadmap toward advancing the state of the art in event-driven 3D reconstruction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This survey has been accepted for publication in the Computational Visual Media Journal",
    "pdf_url": "https://arxiv.org/pdf/2505.08438v3",
    "published_date": "2025-05-13 11:04:04 UTC",
    "updated_date": "2025-12-22 09:39:55 UTC"
  },
  {
    "arxiv_id": "2505.08435v3",
    "title": "Hakim: Farsi Text Embedding Model",
    "authors": [
      "Mehran Sarmadi",
      "Morteza Alikhani",
      "Erfan Zinvandi",
      "Zahra Pourbahman"
    ],
    "abstract": "Recent advancements in text embedding have significantly improved natural language understanding across many languages, yet Persian remains notably underrepresented in large-scale embedding research. In this paper, we present Hakim, a novel state-of-the-art Persian text embedding model that achieves a 8.5% performance improvement over existing approaches on the FaMTEB benchmark, outperforming all previously developed Persian language models. As part of this work, we introduce three new datasets - Corpesia, Pairsia-sup, and Pairsia-unsup - to support supervised and unsupervised training scenarios. Additionally, Hakim is designed for applications in chatbots and retrieval-augmented generation (RAG) systems, particularly addressing retrieval tasks that require incorporating message history within these systems. We also propose a new baseline model built on the BERT architecture. Our language model consistently achieves higher accuracy across various Persian NLP tasks, while the RetroMAE-based model proves particularly effective for textual information retrieval applications. Together, these contributions establish a new foundation for advancing Persian language understanding.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08435v3",
    "published_date": "2025-05-13 10:57:32 UTC",
    "updated_date": "2025-10-08 19:13:17 UTC"
  },
  {
    "arxiv_id": "2505.08404v1",
    "title": "Explaining Autonomous Vehicles with Intention-aware Policy Graphs",
    "authors": [
      "Sara Montese",
      "Victor Gimenez-Abalos",
      "Atia Cortés",
      "Ulises Cortés",
      "Sergio Alvarez-Napagao"
    ],
    "abstract": "The potential to improve road safety, reduce human driving error, and promote environmental sustainability have enabled the field of autonomous driving to progress rapidly over recent decades. The performance of autonomous vehicles has significantly improved thanks to advancements in Artificial Intelligence, particularly Deep Learning. Nevertheless, the opacity of their decision-making, rooted in the use of accurate yet complex AI models, has created barriers to their societal trust and regulatory acceptance, raising the need for explainability. We propose a post-hoc, model-agnostic solution to provide teleological explanations for the behaviour of an autonomous vehicle in urban environments. Building on Intention-aware Policy Graphs, our approach enables the extraction of interpretable and reliable explanations of vehicle behaviour in the nuScenes dataset from global and local perspectives. We demonstrate the potential of these explanations to assess whether the vehicle operates within acceptable legal boundaries and to identify possible vulnerabilities in autonomous driving datasets and models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to Workshop EXTRAAMAS 2025 in AAMAS Conference",
    "pdf_url": "https://arxiv.org/pdf/2505.08404v1",
    "published_date": "2025-05-13 09:58:32 UTC",
    "updated_date": "2025-05-13 09:58:32 UTC"
  },
  {
    "arxiv_id": "2505.08403v2",
    "title": "ConDiSim: Conditional Diffusion Models for Simulation Based Inference",
    "authors": [
      "Mayank Nautiyal",
      "Andreas Hellander",
      "Prashant Singh"
    ],
    "abstract": "We present a conditional diffusion model - ConDiSim, for simulation-based inference of complex systems with intractable likelihoods. ConDiSim leverages denoising diffusion probabilistic models to approximate posterior distributions, consisting of a forward process that adds Gaussian noise to parameters, and a reverse process learning to denoise, conditioned on observed data. This approach effectively captures complex dependencies and multi-modalities within posteriors. ConDiSim is evaluated across ten benchmark problems and two real-world test problems, where it demonstrates effective posterior approximation accuracy while maintaining computational efficiency and stability in model training. ConDiSim offers a robust and extensible framework for simulation-based inference, particularly suitable for parameter inference workflows requiring fast inference methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08403v2",
    "published_date": "2025-05-13 09:58:23 UTC",
    "updated_date": "2025-10-16 14:53:05 UTC"
  },
  {
    "arxiv_id": "2505.08392v2",
    "title": "Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping",
    "authors": [
      "Ren Zhuang",
      "Ben Wang",
      "Shuifa Sun"
    ],
    "abstract": "Large Language Models leverage Chain-of-Thought (CoT) prompting for complex tasks, but their reasoning traces are often excessively verbose and inefficient, leading to significant computational costs and latency. Current CoT compression techniques typically rely on generic importance metrics and static compression rates, which may inadvertently remove functionally critical tokens or fail to adapt to varying reasoning complexity. To overcome these limitations, we propose Adaptive GoGI-Skip, a novel framework learning dynamic CoT compression via supervised fine-tuning. This approach introduces two synergistic innovations: (1) Goal-Gradient Importance (GoGI), a novel metric accurately identifying functionally relevant tokens by measuring the gradient influence of their intermediate representations on the final answer loss, and (2) Adaptive Dynamic Skipping (ADS), a mechanism dynamically regulating the compression rate based on runtime model uncertainty while ensuring local coherence through an adaptive N-token constraint. To our knowledge, this is the first work unifying a goal-oriented, gradient-based importance metric with dynamic, uncertainty-aware skipping for CoT compression. Trained on compressed MATH data, Adaptive GoGI-Skip demonstrates strong cross-domain generalization across diverse reasoning benchmarks including AIME, GPQA, and GSM8K. It achieves substantial efficiency gains - reducing CoT token counts by over 45% on average and delivering 1.6-2.0 times inference speedups - while maintaining high reasoning accuracy. Notably, it significantly outperforms existing baselines by preserving accuracy even at high effective compression rates, advancing the state of the art in the CoT reasoning efficiency-accuracy trade-off.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08392v2",
    "published_date": "2025-05-13 09:39:18 UTC",
    "updated_date": "2025-05-17 14:59:34 UTC"
  },
  {
    "arxiv_id": "2505.08376v1",
    "title": "Adaptive Diffusion Policy Optimization for Robotic Manipulation",
    "authors": [
      "Huiyun Jiang",
      "Zhuang Yang"
    ],
    "abstract": "Recent studies have shown the great potential of diffusion models in improving reinforcement learning (RL) by modeling complex policies, expressing a high degree of multi-modality, and efficiently handling high-dimensional continuous control tasks. However, there is currently limited research on how to optimize diffusion-based polices (e.g., Diffusion Policy) fast and stably. In this paper, we propose an Adam-based Diffusion Policy Optimization (ADPO), a fast algorithmic framework containing best practices for fine-tuning diffusion-based polices in robotic control tasks using the adaptive gradient descent method in RL. Adaptive gradient method is less studied in training RL, let alone diffusion-based policies. We confirm that ADPO outperforms other diffusion-based RL methods in terms of overall effectiveness for fine-tuning on standard robotic tasks. Concretely, we conduct extensive experiments on standard robotic control tasks to test ADPO, where, particularly, six popular diffusion-based RL methods are provided as benchmark methods. Experimental results show that ADPO acquires better or comparable performance than the baseline methods. Finally, we systematically analyze the sensitivity of multiple hyperparameters in standard robotics tasks, providing guidance for subsequent practical applications. Our video demonstrations are released in https://github.com/Timeless-lab/ADPO.git.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08376v1",
    "published_date": "2025-05-13 09:21:45 UTC",
    "updated_date": "2025-05-13 09:21:45 UTC"
  },
  {
    "arxiv_id": "2505.08366v1",
    "title": "Non-contact Vital Signs Detection in Dynamic Environments",
    "authors": [
      "Shuai Sun",
      "Chong-Xi Liang",
      "Chengwei Ye",
      "Huanzhen Zhang",
      "Kangsheng Wang"
    ],
    "abstract": "Accurate phase demodulation is critical for vital sign detection using millimeter-wave radar. However, in complex environments, time-varying DC offsets and phase imbalances can severely degrade demodulation performance. To address this, we propose a novel DC offset calibration method alongside a Hilbert and Differential Cross-Multiply (HADCM) demodulation algorithm. The approach estimates time-varying DC offsets from neighboring signal peaks and valleys, then employs both differential forms and Hilbert transforms of the I/Q channel signals to extract vital sign information. Simulation and experimental results demonstrate that the proposed method maintains robust performance under low signal-to-noise ratios. Compared to existing demodulation techniques, it offers more accurate signal recovery in challenging scenarios and effectively suppresses noise interference.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08366v1",
    "published_date": "2025-05-13 09:11:48 UTC",
    "updated_date": "2025-05-13 09:11:48 UTC"
  },
  {
    "arxiv_id": "2505.08364v2",
    "title": "Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation",
    "authors": [
      "Enci Zhang",
      "Xingang Yan",
      "Wei Lin",
      "Tianxiang Zhang",
      "Qianchun Lu"
    ],
    "abstract": "Despite impressive progress in areas like mathematical reasoning, large language models still face significant challenges in consistently solving complex problems. Drawing inspiration from key human learning strategies, we propose two novel strategies to enhance the capability of large language models to solve these complex problems. First, Adaptive Difficulty Curriculum Learning (ADCL) is a novel curriculum learning strategy that tackles the Difficulty Shift phenomenon (i.e., a model's perception of problem difficulty dynamically changes during training) by periodically re-estimating difficulty within upcoming data batches to maintain alignment with the model's evolving capabilities. Second, Expert-Guided Self-Reformulation (EGSR) is a novel reinforcement learning strategy that bridges the gap between imitation learning and pure exploration by guiding models to reformulate expert solutions within their own conceptual framework, rather than relying on direct imitation, fostering deeper understanding and knowledge assimilation. Extensive experiments on challenging mathematical reasoning benchmarks, using Qwen2.5-7B as the base model, demonstrate that these human-inspired strategies synergistically and significantly enhance performance. Notably, their combined application improves performance over the standard Zero-RL baseline by 10% on the AIME24 benchmark and 16.6% on AIME25.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 3 figs",
    "pdf_url": "https://arxiv.org/pdf/2505.08364v2",
    "published_date": "2025-05-13 09:10:48 UTC",
    "updated_date": "2025-09-17 13:35:33 UTC"
  },
  {
    "arxiv_id": "2505.08361v1",
    "title": "Modeling Unseen Environments with Language-guided Composable Causal Components in Reinforcement Learning",
    "authors": [
      "Xinyue Wang",
      "Biwei Huang"
    ],
    "abstract": "Generalization in reinforcement learning (RL) remains a significant challenge, especially when agents encounter novel environments with unseen dynamics. Drawing inspiration from human compositional reasoning -- where known components are reconfigured to handle new situations -- we introduce World Modeling with Compositional Causal Components (WM3C). This novel framework enhances RL generalization by learning and leveraging compositional causal components. Unlike previous approaches focusing on invariant representation learning or meta-learning, WM3C identifies and utilizes causal dynamics among composable elements, facilitating robust adaptation to new tasks. Our approach integrates language as a compositional modality to decompose the latent space into meaningful components and provides theoretical guarantees for their unique identification under mild assumptions. Our practical implementation uses a masked autoencoder with mutual information constraints and adaptive sparsity regularization to capture high-level semantic information and effectively disentangle transition dynamics. Experiments on numerical simulations and real-world robotic manipulation tasks demonstrate that WM3C significantly outperforms existing methods in identifying latent processes, improving policy learning, and generalizing to unseen tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08361v1",
    "published_date": "2025-05-13 09:08:28 UTC",
    "updated_date": "2025-05-13 09:08:28 UTC"
  },
  {
    "arxiv_id": "2505.08350v2",
    "title": "STORYANCHORS: Generating Consistent Multi-Scene Story Frames for Long-Form Narratives",
    "authors": [
      "Bo Wang",
      "Haoyang Huang",
      "Zhiying Lu",
      "Fengyuan Liu",
      "Guoqing Ma",
      "Jianlong Yuan",
      "Yuan Zhang",
      "Nan Duan",
      "Daxin Jiang"
    ],
    "abstract": "This paper introduces StoryAnchors, a unified framework for generating high-quality, multi-scene story frames with strong temporal consistency. The framework employs a bidirectional story generator that integrates both past and future contexts to ensure temporal consistency, character continuity, and smooth scene transitions throughout the narrative. Specific conditions are introduced to distinguish story frame generation from standard video synthesis, facilitating greater scene diversity and enhancing narrative richness. To further improve generation quality, StoryAnchors integrates Multi-Event Story Frame Labeling and Progressive Story Frame Training, enabling the model to capture both overarching narrative flow and event-level dynamics. This approach supports the creation of editable and expandable story frames, allowing for manual modifications and the generation of longer, more complex sequences. Extensive experiments show that StoryAnchors outperforms existing open-source models in key areas such as consistency, narrative coherence, and scene diversity. Its performance in narrative consistency and story richness is also on par with GPT-4o. Ultimately, StoryAnchors pushes the boundaries of story-driven frame generation, offering a scalable, flexible, and highly editable foundation for future research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08350v2",
    "published_date": "2025-05-13 08:48:10 UTC",
    "updated_date": "2025-05-17 00:50:44 UTC"
  },
  {
    "arxiv_id": "2505.08349v1",
    "title": "FAD: Frequency Adaptation and Diversion for Cross-domain Few-shot Learning",
    "authors": [
      "Ruixiao Shi",
      "Fu Feng",
      "Yucheng Xie",
      "Jing Wang",
      "Xin Geng"
    ],
    "abstract": "Cross-domain few-shot learning (CD-FSL) requires models to generalize from limited labeled samples under significant distribution shifts. While recent methods enhance adaptability through lightweight task-specific modules, they operate solely in the spatial domain and overlook frequency-specific variations that are often critical for robust transfer. We observe that spatially similar images across domains can differ substantially in their spectral representations, with low and high frequencies capturing complementary semantic information at coarse and fine levels. This indicates that uniform spatial adaptation may overlook these spectral distinctions, thus constraining generalization. To address this, we introduce Frequency Adaptation and Diversion (FAD), a frequency-aware framework that explicitly models and modulates spectral components. At its core is the Frequency Diversion Adapter, which transforms intermediate features into the frequency domain using the discrete Fourier transform (DFT), partitions them into low, mid, and high-frequency bands via radial masks, and reconstructs each band using inverse DFT (IDFT). Each frequency band is then adapted using a dedicated convolutional branch with a kernel size tailored to its spectral scale, enabling targeted and disentangled adaptation across frequencies. Extensive experiments on the Meta-Dataset benchmark demonstrate that FAD consistently outperforms state-of-the-art methods on both seen and unseen domains, validating the utility of frequency-domain representations and band-wise adaptation for improving generalization in CD-FSL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08349v1",
    "published_date": "2025-05-13 08:48:06 UTC",
    "updated_date": "2025-05-13 08:48:06 UTC"
  },
  {
    "arxiv_id": "2505.08345v1",
    "title": "SHAP-based Explanations are Sensitive to Feature Representation",
    "authors": [
      "Hyunseung Hwang",
      "Andrew Bell",
      "Joao Fonseca",
      "Venetia Pliatsika",
      "Julia Stoyanovich",
      "Steven Euijong Whang"
    ],
    "abstract": "Local feature-based explanations are a key component of the XAI toolkit. These explanations compute feature importance values relative to an ``interpretable'' feature representation. In tabular data, feature values themselves are often considered interpretable. This paper examines the impact of data engineering choices on local feature-based explanations. We demonstrate that simple, common data engineering techniques, such as representing age with a histogram or encoding race in a specific way, can manipulate feature importance as determined by popular methods like SHAP. Notably, the sensitivity of explanations to feature representation can be exploited by adversaries to obscure issues like discrimination. While the intuition behind these results is straightforward, their systematic exploration has been lacking. Previous work has focused on adversarial attacks on feature-based explainers by biasing data or manipulating models. To the best of our knowledge, this is the first study demonstrating that explainers can be misled by standard, seemingly innocuous data engineering techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ACM FAccT 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08345v1",
    "published_date": "2025-05-13 08:43:09 UTC",
    "updated_date": "2025-05-13 08:43:09 UTC"
  },
  {
    "arxiv_id": "2506.13768v1",
    "title": "'Memory States' from Almost Nothing: Representing and Computing in a Non-associative Algebra",
    "authors": [
      "Stefan Reimann"
    ],
    "abstract": "This note presents a non-associative algebraic framework for the representation and computation of information items in high-dimensional space. This framework is consistent with the principles of spatial computing and with the empirical findings in cognitive science about memory. Computations are performed through a process of multiplication-like binding and non-associative interference-like bundling. Models that rely on associative bundling typically lose order information, which necessitates the use of auxiliary order structures, such as position markers, to represent sequential information that is important for cognitive tasks. In contrast, the non-associative bundling proposed allows the construction of sparse representations of arbitrarily long sequences that maintain their temporal structure across arbitrary lengths. In this operation, noise is a constituent element of the representation of order information, rather than a means of obscuring it. The non-associative nature of the proposed framework results in the representation of a single sequence by two distinct states. The L-state, generated through left-associative bundling, continuously updates and emphasises a recency effect, while the R-state, formed through right-associative bundling, encodes finite sequences or chunks, capturing a primacy effect. The construction of these states may be associated with activity in the prefrontal cortex in relation to short-term memory and hippocampal encoding in long-term memory, respectively. The accuracy of retrieval is contingent upon a decision-making process that is based on the mutual information between the memory states and the cue. The model is able to replicate the Serial Position Curve, which reflects the empirical recency and primacy effects observed in cognitive experiments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "27 pages, 6 figures, journal article (accepted)",
    "pdf_url": "https://arxiv.org/pdf/2506.13768v1",
    "published_date": "2025-05-13 08:43:02 UTC",
    "updated_date": "2025-05-13 08:43:02 UTC"
  },
  {
    "arxiv_id": "2505.08343v1",
    "title": "An Identifiable Cost-Aware Causal Decision-Making Framework Using Counterfactual Reasoning",
    "authors": [
      "Ruichu Cai",
      "Xi Chen",
      "Jie Qiao",
      "Zijian Li",
      "Yuequn Liu",
      "Wei Chen",
      "Keli Zhang",
      "Jiale Zheng"
    ],
    "abstract": "Decision making under abnormal conditions is a critical process that involves evaluating the current state and determining the optimal action to restore the system to a normal state at an acceptable cost. However, in such scenarios, existing decision-making frameworks highly rely on reinforcement learning or root cause analysis, resulting in them frequently neglecting the cost of the actions or failing to incorporate causal mechanisms adequately. By relaxing the existing causal decision framework to solve the necessary cause, we propose a minimum-cost causal decision (MiCCD) framework via counterfactual reasoning to address the above challenges. Emphasis is placed on making counterfactual reasoning processes identifiable in the presence of a large amount of mixed anomaly data, as well as finding the optimal intervention state in a continuous decision space. Specifically, it formulates a surrogate model based on causal graphs, using abnormal pattern clustering labels as supervisory signals. This enables the approximation of the structural causal model among the variables and lays a foundation for identifiable counterfactual reasoning. With the causal structure approximated, we then established an optimization model based on counterfactual estimation. The Sequential Least Squares Programming (SLSQP) algorithm is further employed to optimize intervention strategies while taking costs into account. Experimental evaluations on both synthetic and real-world datasets reveal that MiCCD outperforms conventional methods across multiple metrics, including F1-score, cost efficiency, and ranking quality(nDCG@k values), thus validating its efficacy and broad applicability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08343v1",
    "published_date": "2025-05-13 08:41:45 UTC",
    "updated_date": "2025-05-13 08:41:45 UTC"
  },
  {
    "arxiv_id": "2505.08341v2",
    "title": "Benchmarking AI scientists for omics data driven biological discovery",
    "authors": [
      "Erpai Luo",
      "Jinmeng Jia",
      "Yifan Xiong",
      "Xiangyu Li",
      "Xiaobo Guo",
      "Baoqi Yu",
      "Minsheng Hao",
      "Lei Wei",
      "Xuegong Zhang"
    ],
    "abstract": "Recent advances in large language models have enabled the emergence of AI scientists that aim to autonomously analyze biological data and assist scientific discovery. Despite rapid progress, it remains unclear to what extent these systems can extract meaningful biological insights from real experimental data. Existing benchmarks either evaluate reasoning in the absence of data or focus on predefined analytical outputs, failing to reflect realistic, data-driven biological research. Here, we introduce BAISBench (Biological AI Scientist Benchmark), a benchmark for evaluating AI scientists on real single-cell transcriptomic datasets. BAISBench comprises two tasks: cell type annotation across 15 expert-labeled datasets, and scientific discovery through 193 multiple-choice questions derived from biological conclusions reported in 41 published single-cell studies. We evaluated several representative AI scientists using BAISBench and, to provide a human performance baseline, invited six graduate-level bioinformaticians to collectively complete the same tasks. The results show that while current AI scientists fall short of fully autonomous biological discovery, they already demonstrate substantial potential in supporting data-driven biological research. These results position BAISBench as a practical benchmark for characterizing the current capabilities and limitations of AI scientists in biological research. We expect BAISBench to serve as a practical evaluation framework for guiding the development of more capable AI scientists and for helping biologists identify AI systems that can effectively support real-world research workflows. The BAISBench can be found at: https://github.com/EperLuo/BAISBench, https://huggingface.co/datasets/EperLuo/BaisBench.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "q-bio.GN"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08341v2",
    "published_date": "2025-05-13 08:33:54 UTC",
    "updated_date": "2026-01-18 09:39:51 UTC"
  },
  {
    "arxiv_id": "2505.08336v1",
    "title": "A computer vision-based model for occupancy detection using low-resolution thermal images",
    "authors": [
      "Xue Cui",
      "Vincent Gbouna Zakka",
      "Minhyun Lee"
    ],
    "abstract": "Occupancy plays an essential role in influencing the energy consumption and operation of heating, ventilation, and air conditioning (HVAC) systems. Traditional HVAC typically operate on fixed schedules without considering occupancy. Advanced occupant-centric control (OCC) adopted occupancy status in regulating HVAC operations. RGB images combined with computer vision (CV) techniques are widely used for occupancy detection, however, the detailed facial and body features they capture raise significant privacy concerns. Low-resolution thermal images offer a non-invasive solution that mitigates privacy issues. The study developed an occupancy detection model utilizing low-resolution thermal images and CV techniques, where transfer learning was applied to fine-tune the You Only Look Once version 5 (YOLOv5) model. The developed model ultimately achieved satisfactory performance, with precision, recall, mAP50, and mAP50 values approaching 1.000. The contributions of this model lie not only in mitigating privacy concerns but also in reducing computing resource demands.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08336v1",
    "published_date": "2025-05-13 08:27:50 UTC",
    "updated_date": "2025-05-13 08:27:50 UTC"
  },
  {
    "arxiv_id": "2505.08838v2",
    "title": "Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts",
    "authors": [
      "Peixuan Ge",
      "Tongkun Su",
      "Faqin Lv",
      "Baoliang Zhao",
      "Peng Zhang",
      "Chi Hong Wong",
      "Liang Yao",
      "Yu Sun",
      "Zenan Wang",
      "Pak Kin Wong",
      "Ying Hu"
    ],
    "abstract": "Ultrasound (US) report generation is a challenging task due to the variability of US images, operator dependence, and the need for standardized text. Unlike X-ray and CT, US imaging lacks consistent datasets, making automation difficult. In this study, we propose a unified framework for multi-organ and multilingual US report generation, integrating fragment-based multilingual training and leveraging the standardized nature of US reports. By aligning modular text fragments with diverse imaging data and curating a bilingual English-Chinese dataset, the method achieves consistent and clinically accurate text generation across organ sites and languages. Fine-tuning with selective unfreezing of the vision transformer (ViT) further improves text-image alignment. Compared to the previous state-of-the-art KMVE method, our approach achieves relative gains of about 2\\% in BLEU scores, approximately 3\\% in ROUGE-L, and about 15\\% in CIDEr, while significantly reducing errors such as missing or incorrect content. By unifying multi-organ and multi-language report generation into a single, scalable framework, this work demonstrates strong potential for real-world clinical workflows.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08838v2",
    "published_date": "2025-05-13 08:27:01 UTC",
    "updated_date": "2025-05-19 04:30:42 UTC"
  },
  {
    "arxiv_id": "2505.08327v1",
    "title": "Low-Complexity Inference in Continual Learning via Compressed Knowledge Transfer",
    "authors": [
      "Zhenrong Liu",
      "Janne M. J. Huttunen",
      "Mikko Honkala"
    ],
    "abstract": "Continual learning (CL) aims to train models that can learn a sequence of tasks without forgetting previously acquired knowledge. A core challenge in CL is balancing stability -- preserving performance on old tasks -- and plasticity -- adapting to new ones. Recently, large pre-trained models have been widely adopted in CL for their ability to support both, offering strong generalization for new tasks and resilience against forgetting. However, their high computational cost at inference time limits their practicality in real-world applications, especially those requiring low latency or energy efficiency. To address this issue, we explore model compression techniques, including pruning and knowledge distillation (KD), and propose two efficient frameworks tailored for class-incremental learning (CIL), a challenging CL setting where task identities are unavailable during inference. The pruning-based framework includes pre- and post-pruning strategies that apply compression at different training stages. The KD-based framework adopts a teacher-student architecture, where a large pre-trained teacher transfers downstream-relevant knowledge to a compact student. Extensive experiments on multiple CIL benchmarks demonstrate that the proposed frameworks achieve a better trade-off between accuracy and inference complexity, consistently outperforming strong baselines. We further analyze the trade-offs between the two frameworks in terms of accuracy and efficiency, offering insights into their use across different scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08327v1",
    "published_date": "2025-05-13 08:07:40 UTC",
    "updated_date": "2025-05-13 08:07:40 UTC"
  },
  {
    "arxiv_id": "2505.08325v1",
    "title": "FedRS-Bench: Realistic Federated Learning Datasets and Benchmarks in Remote Sensing",
    "authors": [
      "Haodong Zhao",
      "Peng Peng",
      "Chiyu Chen",
      "Linqing Huang",
      "Gongshen Liu"
    ],
    "abstract": "Remote sensing (RS) images are usually produced at an unprecedented scale, yet they are geographically and institutionally distributed, making centralized model training challenging due to data-sharing restrictions and privacy concerns. Federated learning (FL) offers a solution by enabling collaborative model training across decentralized RS data sources without exposing raw data. However, there lacks a realistic federated dataset and benchmark in RS. Prior works typically rely on manually partitioned single dataset, which fail to capture the heterogeneity and scale of real-world RS data, and often use inconsistent experimental setups, hindering fair comparison. To address this gap, we propose a realistic federated RS dataset, termed FedRS. FedRS consists of eight datasets that cover various sensors and resolutions and builds 135 clients, which is representative of realistic operational scenarios. Data for each client come from the same source, exhibiting authentic federated properties such as skewed label distributions, imbalanced client data volumes, and domain heterogeneity across clients. These characteristics reflect practical challenges in federated RS and support evaluation of FL methods at scale. Based on FedRS, we implement 10 baseline FL algorithms and evaluation metrics to construct the comprehensive FedRS-Bench. The experimental results demonstrate that FL can consistently improve model performance over training on isolated data silos, while revealing performance trade-offs of different methods under varying client heterogeneity and availability conditions. We hope FedRS-Bench will accelerate research on large-scale, realistic FL in RS by providing a standardized, rich testbed and facilitating fair comparisons across future works. The source codes and dataset are available at https://fedrs-bench.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08325v1",
    "published_date": "2025-05-13 08:04:03 UTC",
    "updated_date": "2025-05-13 08:04:03 UTC"
  },
  {
    "arxiv_id": "2505.08295v1",
    "title": "A Practical Introduction to Deep Reinforcement Learning",
    "authors": [
      "Yinghan Sun",
      "Hongxi Wang",
      "Hua Chen",
      "Wei Zhang"
    ],
    "abstract": "Deep reinforcement learning (DRL) has emerged as a powerful framework for solving sequential decision-making problems, achieving remarkable success in a wide range of applications, including game AI, autonomous driving, biomedicine, and large language models. However, the diversity of algorithms and the complexity of theoretical foundations often pose significant challenges for beginners seeking to enter the field. This tutorial aims to provide a concise, intuitive, and practical introduction to DRL, with a particular focus on the Proximal Policy Optimization (PPO) algorithm, which is one of the most widely used and effective DRL methods. To facilitate learning, we organize all algorithms under the Generalized Policy Iteration (GPI) framework, offering readers a unified and systematic perspective. Instead of lengthy theoretical proofs, we emphasize intuitive explanations, illustrative examples, and practical engineering techniques. This work serves as an efficient and accessible guide, helping readers rapidly progress from basic concepts to the implementation of advanced DRL algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08295v1",
    "published_date": "2025-05-13 07:19:16 UTC",
    "updated_date": "2025-05-13 07:19:16 UTC"
  },
  {
    "arxiv_id": "2505.08293v2",
    "title": "M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis",
    "authors": [
      "Zhizhuo Yin",
      "Yuk Hang Tsui",
      "Pan Hui"
    ],
    "abstract": "Generating full-body human gestures encompassing face, body, hands, and global movements from audio is a valuable yet challenging task in virtual avatar creation. Previous systems focused on tokenizing the human gestures framewisely and predicting the tokens of each frame from the input audio. However, one observation is that the number of frames required for a complete expressive human gesture, defined as granularity, varies among different human gesture patterns. Existing systems fail to model these gesture patterns due to the fixed granularity of their gesture tokens. To solve this problem, we propose a novel framework named Multi-Granular Gesture Generator (M3G) for audio-driven holistic gesture generation. In M3G, we propose a novel Multi-Granular VQ-VAE (MGVQ-VAE) to tokenize motion patterns and reconstruct motion sequences from different temporal granularities. Subsequently, we proposed a multi-granular token predictor that extracts multi-granular information from audio and predicts the corresponding motion tokens. Then M3G reconstructs the human gestures from the predicted tokens using the MGVQ-VAE. Both objective and subjective experiments demonstrate that our proposed M3G framework outperforms the state-of-the-art methods in terms of generating natural and expressive full-body human gestures.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.GR",
    "comment": "9 Pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2505.08293v2",
    "published_date": "2025-05-13 07:16:58 UTC",
    "updated_date": "2025-05-19 14:01:45 UTC"
  },
  {
    "arxiv_id": "2505.08266v3",
    "title": "Open Your Eyes: Vision Enhances Message Passing Neural Networks in Link Prediction",
    "authors": [
      "Yanbin Wei",
      "Xuehao Wang",
      "Zhan Zhuang",
      "Yang Chen",
      "Shuhao Chen",
      "Yulong Zhang",
      "Yu Zhang",
      "James Kwok"
    ],
    "abstract": "Message-passing graph neural networks (MPNNs) and structural features (SFs) are cornerstones for the link prediction task. However, as a common and intuitive mode of understanding, the potential of visual perception has been overlooked in the MPNN community. For the first time, we equip MPNNs with vision structural awareness by proposing an effective framework called Graph Vision Network (GVN), along with a more efficient variant (E-GVN). Extensive empirical results demonstrate that with the proposed frameworks, GVN consistently benefits from the vision enhancement across seven link prediction datasets, including challenging large-scale graphs. Such improvements are compatible with existing state-of-the-art (SOTA) methods and GVNs achieve new SOTA results, thereby underscoring a promising novel direction for link prediction.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08266v3",
    "published_date": "2025-05-13 06:32:23 UTC",
    "updated_date": "2025-06-06 09:03:54 UTC"
  },
  {
    "arxiv_id": "2505.08265v3",
    "title": "LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification",
    "authors": [
      "Hang Gao",
      "Wenxuan Huang",
      "Fengge Wu",
      "Junsuo Zhao",
      "Changwen Zheng",
      "Huaping Liu"
    ],
    "abstract": "The use of large language models (LLMs) as feature enhancers to optimize node representations, which are then used as inputs for graph neural networks (GNNs), has shown significant potential in graph representation learning. However, the fundamental properties of this approach remain underexplored. To address this issue, we propose conducting a more in-depth analysis of this issue based on the interchange intervention method. First, we construct a synthetic graph dataset with controllable causal relationships, enabling precise manipulation of semantic relationships and causal modeling to provide data for analysis. Using this dataset, we conduct interchange interventions to examine the deeper properties of LLM enhancers and GNNs, uncovering their underlying logic and internal mechanisms. Building on the analytical results, we design a plug-and-play optimization module to improve the information transfer between LLM enhancers and GNNs. Experiments across multiple datasets and models validate the proposed module.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08265v3",
    "published_date": "2025-05-13 06:29:25 UTC",
    "updated_date": "2025-06-11 05:16:38 UTC"
  },
  {
    "arxiv_id": "2505.08264v2",
    "title": "Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning",
    "authors": [
      "Ahmed Abouelazm",
      "Tim Weinstein",
      "Tim Joseph",
      "Philip Schörner",
      "J. Marius Zöllner"
    ],
    "abstract": "This paper addresses the challenges of training end-to-end autonomous driving agents using Reinforcement Learning (RL). RL agents are typically trained in a fixed set of scenarios and nominal behavior of surrounding road users in simulations, limiting their generalization and real-life deployment. While domain randomization offers a potential solution by randomly sampling driving scenarios, it frequently results in inefficient training and sub-optimal policies due to the high variance among training scenarios. To address these limitations, we propose an automatic curriculum learning framework that dynamically generates driving scenarios with adaptive complexity based on the agent's evolving capabilities. Unlike manually designed curricula that introduce expert bias and lack scalability, our framework incorporates a ``teacher'' that automatically generates and mutates driving scenarios based on their learning potential -- an agent-centric metric derived from the agent's current policy -- eliminating the need for expert design. The framework enhances training efficiency by excluding scenarios the agent has mastered or finds too challenging. We evaluate our framework in a reinforcement learning setting where the agent learns a driving policy from camera images. Comparative results against baseline methods, including fixed scenario training and domain randomization, demonstrate that our approach leads to enhanced generalization, achieving higher success rates: +9% in low traffic density, +21% in high traffic density, and faster convergence with fewer training steps. Our findings highlight the potential of ACL in improving the robustness and efficiency of RL-based autonomous driving agents.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)",
    "pdf_url": "https://arxiv.org/pdf/2505.08264v2",
    "published_date": "2025-05-13 06:26:57 UTC",
    "updated_date": "2025-07-11 09:23:36 UTC"
  },
  {
    "arxiv_id": "2505.08261v1",
    "title": "Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration",
    "authors": [
      "Rishabh Agrawal",
      "Himanshu Kumar"
    ],
    "abstract": "The rapid progress in large language models (LLMs) has paved the way for novel approaches in knowledge-intensive tasks. Among these, Cache-Augmented Generation (CAG) has emerged as a promising alternative to Retrieval-Augmented Generation (RAG). CAG minimizes retrieval latency and simplifies system design by preloading knowledge into the model's context. However, challenges persist in scaling CAG to accommodate large and dynamic knowledge bases effectively. This paper introduces Adaptive Contextual Compression (ACC), an innovative technique designed to dynamically compress and manage context inputs, enabling efficient utilization of the extended memory capabilities of modern LLMs. To further address the limitations of standalone CAG, we propose a Hybrid CAG-RAG Framework, which integrates selective retrieval to augment preloaded contexts in scenarios requiring additional information. Comprehensive evaluations on diverse datasets highlight the proposed methods' ability to enhance scalability, optimize efficiency, and improve multi-hop reasoning performance, offering practical solutions for real-world knowledge integration challenges.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08261v1",
    "published_date": "2025-05-13 06:24:48 UTC",
    "updated_date": "2025-05-13 06:24:48 UTC"
  },
  {
    "arxiv_id": "2505.08835v1",
    "title": "Robustness Analysis against Adversarial Patch Attacks in Fully Unmanned Stores",
    "authors": [
      "Hyunsik Na",
      "Wonho Lee",
      "Seungdeok Roh",
      "Sohee Park",
      "Daeseon Choi"
    ],
    "abstract": "The advent of convenient and efficient fully unmanned stores equipped with artificial intelligence-based automated checkout systems marks a new era in retail. However, these systems have inherent artificial intelligence security vulnerabilities, which are exploited via adversarial patch attacks, particularly in physical environments. This study demonstrated that adversarial patches can severely disrupt object detection models used in unmanned stores, leading to issues such as theft, inventory discrepancies, and interference. We investigated three types of adversarial patch attacks -- Hiding, Creating, and Altering attacks -- and highlighted their effectiveness. We also introduce the novel color histogram similarity loss function by leveraging attacker knowledge of the color information of a target class object. Besides the traditional confusion-matrix-based attack success rate, we introduce a new bounding-boxes-based metric to analyze the practical impact of these attacks. Starting with attacks on object detection models trained on snack and fruit datasets in a digital environment, we evaluated the effectiveness of adversarial patches in a physical testbed that mimicked a real unmanned store with RGB cameras and realistic conditions. Furthermore, we assessed the robustness of these attacks in black-box scenarios, demonstrating that shadow attacks can enhance success rates of attacks even without direct access to model parameters. Our study underscores the necessity for robust defense strategies to protect unmanned stores from adversarial threats. Highlighting the limitations of the current defense mechanisms in real-time detection systems and discussing various proactive measures, we provide insights into improving the robustness of object detection models and fortifying unmanned retail environments against these attacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08835v1",
    "published_date": "2025-05-13 06:24:32 UTC",
    "updated_date": "2025-05-13 06:24:32 UTC"
  },
  {
    "arxiv_id": "2505.08253v1",
    "title": "Evaluating LLM Metrics Through Real-World Capabilities",
    "authors": [
      "Justin K Miller",
      "Wenjia Tang"
    ],
    "abstract": "As generative AI becomes increasingly embedded in everyday workflows, it is important to evaluate its performance in ways that reflect real-world usage rather than abstract notions of intelligence. Unlike many existing benchmarks that assess general intelligence, our approach focuses on real-world utility, evaluating how well models support users in everyday tasks. While current benchmarks emphasize code generation or factual recall, users rely on AI for a much broader range of activities-from writing assistance and summarization to citation formatting and stylistic feedback. In this paper, we analyze large-scale survey data and usage logs to identify six core capabilities that represent how people commonly use Large Language Models (LLMs): Summarization, Technical Assistance, Reviewing Work, Data Structuring, Generation, and Information Retrieval. We then assess the extent to which existing benchmarks cover these capabilities, revealing significant gaps in coverage, efficiency measurement, and interpretability. Drawing on this analysis, we use human-centered criteria to identify gaps in how well current benchmarks reflect common usage that is grounded in five practical criteria: coherence, accuracy, clarity, relevance, and efficiency. For four of the six capabilities, we identify the benchmarks that best align with real-world tasks and use them to compare leading models. We find that Google Gemini outperforms other models-including OpenAI's GPT, xAI's Grok, Meta's LLaMA, Anthropic's Claude, DeepSeek, and Qwen from Alibaba-on these utility-focused metrics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages main text, 5 pages references, 20 pages appendix; includes 3 figures and 4 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.08253v1",
    "published_date": "2025-05-13 06:02:37 UTC",
    "updated_date": "2025-05-13 06:02:37 UTC"
  },
  {
    "arxiv_id": "2505.08245v2",
    "title": "Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement",
    "authors": [
      "Haoran Ye",
      "Jing Jin",
      "Yuhang Xie",
      "Xin Zhang",
      "Guojie Song"
    ],
    "abstract": "The advancement of large language models (LLMs) has outpaced traditional evaluation methodologies. This progress presents novel challenges, such as measuring human-like psychological constructs, moving beyond static and task-specific benchmarks, and establishing human-centered evaluation. These challenges intersect with psychometrics, the science of quantifying the intangible aspects of human psychology, such as personality, values, and intelligence. This review paper introduces and synthesizes the emerging interdisciplinary field of LLM Psychometrics, which leverages psychometric instruments, theories, and principles to evaluate, understand, and enhance LLMs. The reviewed literature systematically shapes benchmarking principles, broadens evaluation scopes, refines methodologies, validates results, and advances LLM capabilities. Diverse perspectives are integrated to provide a structured framework for researchers across disciplines, enabling a more comprehensive understanding of this nascent field. Ultimately, the review provides actionable insights for developing future evaluation paradigms that align with human-level AI and promote the advancement of human-centered AI systems for societal benefit. A curated repository of LLM psychometric resources is available at https://github.com/valuebyte-ai/Awesome-LLM-Psychometrics.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "474 references",
    "pdf_url": "https://arxiv.org/pdf/2505.08245v2",
    "published_date": "2025-05-13 05:47:51 UTC",
    "updated_date": "2025-07-13 08:25:01 UTC"
  },
  {
    "arxiv_id": "2505.08834v2",
    "title": "Crowd Scene Analysis using Deep Learning Techniques",
    "authors": [
      "Muhammad Junaid Asif"
    ],
    "abstract": "Our research is focused on two main applications of crowd scene analysis crowd counting and anomaly detection In recent years a large number of researches have been presented in the domain of crowd counting We addressed two main challenges in this domain 1 Deep learning models are datahungry paradigms and always need a large amount of annotated data for the training of algorithm It is timeconsuming and costly task to annotate such large amount of data Selfsupervised training is proposed to deal with this challenge 2 MCNN consists of multicolumns of CNN with different sizes of filters by presenting a novel approach based on a combination of selfsupervised training and MultiColumn CNN This enables the model to learn features at different levels and makes it effective in dealing with challenges of occluded scenes nonuniform density complex backgrounds and scale invariation The proposed model was evaluated on publicly available data sets such as ShanghaiTech and UCFQNRF by means of MAE and MSE A spatiotemporal model based on VGG19 is proposed for crowd anomaly detection addressing challenges like lighting environmental conditions unexpected objects and scalability The model extracts spatial and temporal features allowing it to be generalized to realworld scenes Spatial features are learned using CNN while temporal features are learned using LSTM blocks The model works on binary classification and can detect normal or abnormal behavior The models performance is improved by replacing fully connected layers with dense residual blocks Experiments on the Hockey Fight dataset and SCVD dataset show our models outperform other stateoftheart approaches",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "MS Graduate Research Thesis",
    "pdf_url": "https://arxiv.org/pdf/2505.08834v2",
    "published_date": "2025-05-13 05:29:30 UTC",
    "updated_date": "2025-06-04 03:58:31 UTC"
  },
  {
    "arxiv_id": "2505.08234v1",
    "title": "Removing Watermarks with Partial Regeneration using Semantic Information",
    "authors": [
      "Krti Tallam",
      "John Kevin Cava",
      "Caleb Geniesse",
      "N. Benjamin Erichson",
      "Michael W. Mahoney"
    ],
    "abstract": "As AI-generated imagery becomes ubiquitous, invisible watermarks have emerged as a primary line of defense for copyright and provenance. The newest watermarking schemes embed semantic signals - content-aware patterns that are designed to survive common image manipulations - yet their true robustness against adaptive adversaries remains under-explored. We expose a previously unreported vulnerability and introduce SemanticRegen, a three-stage, label-free attack that erases state-of-the-art semantic and invisible watermarks while leaving an image's apparent meaning intact. Our pipeline (i) uses a vision-language model to obtain fine-grained captions, (ii) extracts foreground masks with zero-shot segmentation, and (iii) inpaints only the background via an LLM-guided diffusion model, thereby preserving salient objects and style cues. Evaluated on 1,000 prompts across four watermarking systems - TreeRing, StegaStamp, StableSig, and DWT/DCT - SemanticRegen is the only method to defeat the semantic TreeRing watermark (p = 0.10 > 0.05) and reduces bit-accuracy below 0.75 for the remaining schemes, all while maintaining high perceptual quality (masked SSIM = 0.94 +/- 0.01). We further introduce masked SSIM (mSSIM) to quantify fidelity within foreground regions, showing that our attack achieves up to 12 percent higher mSSIM than prior diffusion-based attackers. These results highlight an urgent gap between current watermark defenses and the capabilities of adaptive, semantics-aware adversaries, underscoring the need for watermarking algorithms that are resilient to content-preserving regenerative attacks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08234v1",
    "published_date": "2025-05-13 05:25:06 UTC",
    "updated_date": "2025-05-13 05:25:06 UTC"
  },
  {
    "arxiv_id": "2505.08228v2",
    "title": "Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix",
    "authors": [
      "Unai Gurbindo",
      "Axel Brando",
      "Jaume Abella",
      "Caroline König"
    ],
    "abstract": "Enhancing the robustness of object detection systems under adverse weather conditions is crucial for the advancement of autonomous driving technology. This study presents a novel approach leveraging the diffusion model Instruct Pix2Pix to develop prompting methodologies that generate realistic datasets with weather-based augmentations aiming to mitigate the impact of adverse weather on the perception capabilities of state-of-the-art object detection models, including Faster R-CNN and YOLOv10. Experiments were conducted in two environments, in the CARLA simulator where an initial evaluation of the proposed data augmentation was provided, and then on the real-world image data sets BDD100K and ACDC demonstrating the effectiveness of the approach in real environments.\n  The key contributions of this work are twofold: (1) identifying and quantifying the performance gap in object detection models under challenging weather conditions, and (2) demonstrating how tailored data augmentation strategies can significantly enhance the robustness of these models. This research establishes a solid foundation for improving the reliability of perception systems in demanding environmental scenarios, and provides a pathway for future advancements in autonomous driving.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 5 figures. Accepted at the International Joint Conference on Neural Networks (IJCNN) 2025 (to appear)",
    "pdf_url": "https://arxiv.org/pdf/2505.08228v2",
    "published_date": "2025-05-13 05:12:07 UTC",
    "updated_date": "2025-06-30 05:56:45 UTC"
  },
  {
    "arxiv_id": "2505.08223v1",
    "title": "Reinforcement Learning-based Fault-Tolerant Control for Quadrotor with Online Transformer Adaptation",
    "authors": [
      "Dohyun Kim",
      "Jayden Dongwoo Lee",
      "Hyochoong Bang",
      "Jungho Bae"
    ],
    "abstract": "Multirotors play a significant role in diverse field robotics applications but remain highly susceptible to actuator failures, leading to rapid instability and compromised mission reliability. While various fault-tolerant control (FTC) strategies using reinforcement learning (RL) have been widely explored, most previous approaches require prior knowledge of the multirotor model or struggle to adapt to new configurations. To address these limitations, we propose a novel hybrid RL-based FTC framework integrated with a transformer-based online adaptation module. Our framework leverages a transformer architecture to infer latent representations in real time, enabling adaptation to previously unseen system models without retraining. We evaluate our method in a PyBullet simulation under loss-of-effectiveness actuator faults, achieving a 95% success rate and a positional root mean square error (RMSE) of 0.129 m, outperforming existing adaptation methods with 86% success and an RMSE of 0.153 m. Further evaluations on quadrotors with varying configurations confirm the robustness of our framework across untrained dynamics. These results demonstrate the potential of our framework to enhance the adaptability and reliability of multirotors, enabling efficient fault management in dynamic and uncertain environments. Website is available at http://00dhkim.me/paper/rl-ftc",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accpted at the 2025 IEEE International Conference on Robotics & Automation (ICRA) Workshop: Robots in the Wild",
    "pdf_url": "https://arxiv.org/pdf/2505.08223v1",
    "published_date": "2025-05-13 04:50:29 UTC",
    "updated_date": "2025-05-13 04:50:29 UTC"
  },
  {
    "arxiv_id": "2505.08222v2",
    "title": "Scaling Multi Agent Reinforcement Learning for Underwater Acoustic Tracking via Autonomous Vehicles",
    "authors": [
      "Matteo Gallici",
      "Ivan Masmitja",
      "Mario Martín"
    ],
    "abstract": "Autonomous vehicles (AV) offer a cost-effective solution for scientific missions such as underwater tracking. Recently, reinforcement learning (RL) has emerged as a powerful method for controlling AVs in complex marine environments. However, scaling these techniques to a fleet--essential for multi-target tracking or targets with rapid, unpredictable motion--presents significant computational challenges. Multi-Agent Reinforcement Learning (MARL) is notoriously sample-inefficient, and while high-fidelity simulators like Gazebo's LRAUV provide 100x faster-than-real-time single-robot simulations, they offer no significant speedup for multi-vehicle scenarios, making MARL training impractical. To address these limitations, we propose an iterative distillation method that transfers high-fidelity simulations into a simplified, GPU-accelerated environment while preserving high-level dynamics. This approach achieves up to a 30,000x speedup over Gazebo through parallelization, enabling efficient training via end-to-end GPU acceleration. Additionally, we introduce a novel Transformer-based architecture (TransfMAPPO) that learns multi-agent policies invariant to the number of agents and targets, significantly improving sample efficiency. Following large-scale curriculum learning conducted entirely on GPU, we perform extensive evaluations in Gazebo, demonstrating that our method maintains tracking errors below 5 meters over extended durations, even in the presence of multiple fast-moving targets. This work bridges the gap between large-scale MARL training and high-fidelity deployment, providing a scalable framework for autonomous fleet control in real-world sea missions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08222v2",
    "published_date": "2025-05-13 04:42:30 UTC",
    "updated_date": "2025-10-17 13:57:11 UTC"
  },
  {
    "arxiv_id": "2505.11528v6",
    "title": "LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation",
    "authors": [
      "Yuhang Huang",
      "Jiazhao Zhang",
      "Shilong Zou",
      "Xinwang Liu",
      "Ruizhen Hu",
      "Kai Xu"
    ],
    "abstract": "Predictive manipulation has recently gained considerable attention in the Embodied AI community due to its potential to improve robot policy performance by leveraging predicted states. However, generating accurate future visual states of robot-object interactions from world models remains a well-known challenge, particularly in achieving high-quality pixel-level representations. To this end, we propose LaDi-WM, a world model that predicts the latent space of future states using diffusion modeling. Specifically, LaDi-WM leverages the well-established latent space aligned with pre-trained Visual Foundation Models (VFMs), which comprises both geometric features (DINO-based) and semantic features (CLIP-based). We find that predicting the evolution of the latent space is easier to learn and more generalizable than directly predicting pixel-level images. Building on LaDi-WM, we design a diffusion policy that iteratively refines output actions by incorporating forecasted states, thereby generating more consistent and accurate results. Extensive experiments on both synthetic and real-world benchmarks demonstrate that LaDi-WM significantly enhances policy performance by 27.9\\% on the LIBERO-LONG benchmark and 20\\% on the real-world scenario. Furthermore, our world model and policies achieve impressive generalizability in real-world experiments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "CoRL 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.11528v6",
    "published_date": "2025-05-13 04:42:14 UTC",
    "updated_date": "2025-09-12 13:58:52 UTC"
  },
  {
    "arxiv_id": "2505.08215v1",
    "title": "Unveiling the Best Practices for Applying Speech Foundation Models to Speech Intelligibility Prediction for Hearing-Impaired People",
    "authors": [
      "Haoshuai Zhou",
      "Boxuan Cao",
      "Changgeng Mo",
      "Linkai Li",
      "Shan Xiang Wang"
    ],
    "abstract": "Speech foundation models (SFMs) have demonstrated strong performance across a variety of downstream tasks, including speech intelligibility prediction for hearing-impaired people (SIP-HI). However, optimizing SFMs for SIP-HI has been insufficiently explored. In this paper, we conduct a comprehensive study to identify key design factors affecting SIP-HI performance with 5 SFMs, focusing on encoder layer selection, prediction head architecture, and ensemble configurations. Our findings show that, contrary to traditional use-all-layers methods, selecting a single encoder layer yields better results. Additionally, temporal modeling is crucial for effective prediction heads. We also demonstrate that ensembling multiple SFMs improves performance, with stronger individual models providing greater benefit. Finally, we explore the relationship between key SFM attributes and their impact on SIP-HI performance. Our study offers practical insights into effectively adapting SFMs for speech intelligibility prediction for hearing-impaired populations.",
    "categories": [
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08215v1",
    "published_date": "2025-05-13 04:07:59 UTC",
    "updated_date": "2025-05-13 04:07:59 UTC"
  },
  {
    "arxiv_id": "2505.08202v1",
    "title": "AI and Generative AI Transforming Disaster Management: A Survey of Damage Assessment and Response Techniques",
    "authors": [
      "Aman Raj",
      "Lakshit Arora",
      "Sanjay Surendranath Girija",
      "Shashank Kapoor",
      "Dipen Pradhan",
      "Ankit Shetgaonkar"
    ],
    "abstract": "Natural disasters, including earthquakes, wildfires and cyclones, bear a huge risk on human lives as well as infrastructure assets. An effective response to disaster depends on the ability to rapidly and efficiently assess the intensity of damage. Artificial Intelligence (AI) and Generative Artificial Intelligence (GenAI) presents a breakthrough solution, capable of combining knowledge from multiple types and sources of data, simulating realistic scenarios of disaster, and identifying emerging trends at a speed previously unimaginable. In this paper, we present a comprehensive review on the prospects of AI and GenAI in damage assessment for various natural disasters, highlighting both its strengths and limitations. We talk about its application to multimodal data such as text, image, video, and audio, and also cover major issues of data privacy, security, and ethical use of the technology during crises. The paper also recognizes the threat of Generative AI misuse, in the form of dissemination of misinformation and for adversarial attacks. Finally, we outline avenues of future research, emphasizing the need for secure, reliable, and ethical Generative AI systems for disaster management in general. We believe that this work represents the first comprehensive survey of Gen-AI techniques being used in the field of Disaster Assessment and Response.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted in IEEE Compsac 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08202v1",
    "published_date": "2025-05-13 03:33:31 UTC",
    "updated_date": "2025-05-13 03:33:31 UTC"
  },
  {
    "arxiv_id": "2505.08200v1",
    "title": "A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection in LLM Outputs",
    "authors": [
      "Artem Shelmanov",
      "Ekaterina Fadeeva",
      "Akim Tsvigun",
      "Ivan Tsvigun",
      "Zhuohan Xie",
      "Igor Kiselev",
      "Nico Daheim",
      "Caiqi Zhang",
      "Artem Vazhentsev",
      "Mrinmaya Sachan",
      "Preslav Nakov",
      "Timothy Baldwin"
    ],
    "abstract": "Large Language Models (LLMs) have the tendency to hallucinate, i.e., to sporadically generate false or fabricated information. This presents a major challenge, as hallucinations often appear highly convincing and users generally lack the tools to detect them. Uncertainty quantification (UQ) provides a framework for assessing the reliability of model outputs, aiding in the identification of potential hallucinations. In this work, we introduce pre-trained UQ heads: supervised auxiliary modules for LLMs that substantially enhance their ability to capture uncertainty compared to unsupervised UQ methods. Their strong performance stems from the powerful Transformer architecture in their design and informative features derived from LLM attention maps. Experimental evaluation shows that these heads are highly robust and achieve state-of-the-art performance in claim-level hallucination detection across both in-domain and out-of-domain prompts. Moreover, these modules demonstrate strong generalization to languages they were not explicitly trained on. We pre-train a collection of UQ heads for popular LLM series, including Mistral, Llama, and Gemma 2. We publicly release both the code and the pre-trained heads.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08200v1",
    "published_date": "2025-05-13 03:30:26 UTC",
    "updated_date": "2025-05-13 03:30:26 UTC"
  },
  {
    "arxiv_id": "2505.08830v1",
    "title": "Federated Large Language Models: Feasibility, Robustness, Security and Future Directions",
    "authors": [
      "Wenhao Jiang",
      "Yuchuan Luo",
      "Guilin Deng",
      "Silong Chen",
      "Xu Yang",
      "Shihong Wu",
      "Xinwen Gao",
      "Lin Liu",
      "Shaojing Fu"
    ],
    "abstract": "The integration of Large Language Models (LLMs) and Federated Learning (FL) presents a promising solution for joint training on distributed data while preserving privacy and addressing data silo issues. However, this emerging field, known as Federated Large Language Models (FLLM), faces significant challenges, including communication and computation overheads, heterogeneity, privacy and security concerns. Current research has primarily focused on the feasibility of FLLM, but future trends are expected to emphasize enhancing system robustness and security. This paper provides a comprehensive review of the latest advancements in FLLM, examining challenges from four critical perspectives: feasibility, robustness, security, and future directions. We present an exhaustive survey of existing studies on FLLM feasibility, introduce methods to enhance robustness in the face of resource, data, and task heterogeneity, and analyze novel risks associated with this integration, including privacy threats and security challenges. We also review the latest developments in defense mechanisms and explore promising future research directions, such as few-shot learning, machine unlearning, and IP protection. This survey highlights the pressing need for further research to enhance system robustness and security while addressing the unique challenges posed by the integration of FL and LLM.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "35 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.08830v1",
    "published_date": "2025-05-13 03:23:54 UTC",
    "updated_date": "2025-05-13 03:23:54 UTC"
  },
  {
    "arxiv_id": "2505.08195v3",
    "title": "Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations",
    "authors": [
      "Jinming Hu",
      "Hassan Nawaz",
      "Yuting Rui",
      "Lijie Chi",
      "Arif Ullah",
      "Pavlo O. Dral"
    ],
    "abstract": "We have developed Aitomia - a platform powered by AI to assist in performing AI-driven atomistic and quantum chemical (QC) simulations. This evolving intelligent assistant platform is equipped with chatbots and AI agents to help experts and guide non-experts in setting up and running atomistic simulations, monitoring their computational status, analyzing simulation results, and summarizing them for the user in both textual and graphical forms. We achieve these goals by exploiting large language models that leverage the versatility of our MLatom ecosystem, supporting AI-enhanced computational chemistry tasks ranging from ground-state to excited-state calculations, including geometry optimizations, thermochemistry, and spectral calculations. The multi-agent implementation enables autonomous executions of the complex computational workflows, such as the computation of the reaction enthalpies. Aitomia is the first intelligent assistant publicly accessible online on a cloud computing platform for atomistic simulations of broad scope (Aitomistic Hub at https://aitomistic.xyz). It may also be deployed locally as described at http://mlatom.com/aitomia. Aitomia is expected to lower the barrier to performing atomistic simulations, thereby democratizing simulations and accelerating research and development in relevant fields.",
    "categories": [
      "physics.comp-ph",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "physics.chem-ph"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08195v3",
    "published_date": "2025-05-13 03:11:41 UTC",
    "updated_date": "2025-07-22 01:10:54 UTC"
  },
  {
    "arxiv_id": "2505.08189v2",
    "title": "DSADF: Thinking Fast and Slow for Decision Making",
    "authors": [
      "Zhihao Dou",
      "Dongfei Cui",
      "Jun Yan",
      "Weida Wang",
      "Benteng Chen",
      "Haoming Wang",
      "Zeke Xie",
      "Shufei Zhang"
    ],
    "abstract": "Although Reinforcement Learning (RL) agents are effective in well-defined environments, they often struggle to generalize their learned policies to dynamic settings due to their reliance on trial-and-error interactions. Recent work has explored applying Large Language Models (LLMs) or Vision Language Models (VLMs) to boost the generalization of RL agents through policy optimization guidance or prior knowledge. However, these approaches often lack seamless coordination between the RL agent and the foundation model, leading to unreasonable decision-making in unfamiliar environments and efficiency bottlenecks. Making full use of the inferential capabilities of foundation models and the rapid response capabilities of RL agents and enhancing the interaction between the two to form a dual system is still a lingering scientific question. To address this problem, we draw inspiration from Kahneman's theory of fast thinking (System 1) and slow thinking (System 2), demonstrating that balancing intuition and deep reasoning can achieve nimble decision-making in a complex world. In this study, we propose a Dual-System Adaptive Decision Framework (DSADF), integrating two complementary modules: System 1, comprising an RL agent and a memory space for fast and intuitive decision making, and System 2, driven by a VLM for deep and analytical reasoning. DSADF facilitates efficient and adaptive decision-making by combining the strengths of both systems. The empirical study in the video game environment: Crafter and Housekeep demonstrates the effectiveness of our proposed method, showing significant improvements in decision abilities for both unseen and known tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08189v2",
    "published_date": "2025-05-13 02:58:04 UTC",
    "updated_date": "2025-08-25 08:03:43 UTC"
  },
  {
    "arxiv_id": "2505.08176v1",
    "title": "Behind the Noise: Conformal Quantile Regression Reveals Emergent Representations",
    "authors": [
      "Petrus H. Zwart",
      "Tamas Varga",
      "Odeta Qafoku",
      "James A. Sethian"
    ],
    "abstract": "Scientific imaging often involves long acquisition times to obtain high-quality data, especially when probing complex, heterogeneous systems. However, reducing acquisition time to increase throughput inevitably introduces significant noise into the measurements. We present a machine learning approach that not only denoises low-quality measurements with calibrated uncertainty bounds, but also reveals emergent structure in the latent space. By using ensembles of lightweight, randomly structured neural networks trained via conformal quantile regression, our method performs reliable denoising while uncovering interpretable spatial and chemical features -- without requiring labels or segmentation. Unlike conventional approaches focused solely on image restoration, our framework leverages the denoising process itself to drive the emergence of meaningful representations. We validate the approach on real-world geobiochemical imaging data, showing how it supports confident interpretation and guides experimental design under resource constraints.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08176v1",
    "published_date": "2025-05-13 02:27:12 UTC",
    "updated_date": "2025-05-13 02:27:12 UTC"
  },
  {
    "arxiv_id": "2505.08175v3",
    "title": "Fast Text-to-Audio Generation with Adversarial Post-Training",
    "authors": [
      "Zachary Novack",
      "Zach Evans",
      "Zack Zukowski",
      "Josiah Taylor",
      "CJ Carr",
      "Julian Parker",
      "Adnan Al-Sinan",
      "Gian Marco Iodice",
      "Julian McAuley",
      "Taylor Berg-Kirkpatrick",
      "Jordi Pons"
    ],
    "abstract": "Text-to-audio systems, while increasingly performant, are slow at inference time, thus making their latency unpractical for many creative applications. We present Adversarial Relativistic-Contrastive (ARC) post-training, the first adversarial acceleration algorithm for diffusion/flow models not based on distillation. While past adversarial post-training methods have struggled to compare against their expensive distillation counterparts, ARC post-training is a simple procedure that (1) extends a recent relativistic adversarial formulation to diffusion/flow post-training and (2) combines it with a novel contrastive discriminator objective to encourage better prompt adherence. We pair ARC post-training with a number optimizations to Stable Audio Open and build a model capable of generating $\\approx$12s of 44.1kHz stereo audio in $\\approx$75ms on an H100, and $\\approx$7s on a mobile edge-device, the fastest text-to-audio model to our knowledge.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08175v3",
    "published_date": "2025-05-13 02:25:47 UTC",
    "updated_date": "2025-05-20 02:54:49 UTC"
  },
  {
    "arxiv_id": "2505.08168v1",
    "title": "Exploiting Text Semantics for Few and Zero Shot Node Classification on Text-attributed Graph",
    "authors": [
      "Yuxiang Wang",
      "Xiao Yan",
      "Shiyu Jin",
      "Quanqing Xu",
      "Chuang Hu",
      "Yuanyuan Zhu",
      "Bo Du",
      "Jia Wu",
      "Jiawei Jiang"
    ],
    "abstract": "Text-attributed graph (TAG) provides a text description for each graph node, and few- and zero-shot node classification on TAGs have many applications in fields such as academia and social networks. Existing work utilizes various graph-based augmentation techniques to train the node and text embeddings, while text-based augmentations are largely unexplored. In this paper, we propose Text Semantics Augmentation (TSA) to improve accuracy by introducing more text semantic supervision signals. Specifically, we design two augmentation techniques, i.e., positive semantics matching and negative semantics contrast, to provide more reference texts for each graph node or text description. Positive semantic matching retrieves texts with similar embeddings to match with a graph node. Negative semantic contrast adds a negative prompt to construct a text description with the opposite semantics, which is contrasted with the original node and text. We evaluate TSA on 5 datasets and compare with 13 state-of-the-art baselines. The results show that TSA consistently outperforms all baselines, and its accuracy improvements over the best-performing baseline are usually over 5%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08168v1",
    "published_date": "2025-05-13 02:06:08 UTC",
    "updated_date": "2025-05-13 02:06:08 UTC"
  },
  {
    "arxiv_id": "2505.08167v4",
    "title": "Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage",
    "authors": [
      "Ruilin Liu",
      "Zhixiao Zhao",
      "Jieqiong Li",
      "Chang Liu",
      "Dongbo Wang"
    ],
    "abstract": "The rapid development of large language models (LLMs) has provided significant support and opportunities for the advancement of domain-specific LLMs. However, fine-tuning these large models using Intangible Cultural Heritage (ICH) data inevitably faces challenges such as bias, incorrect knowledge inheritance, and catastrophic forgetting. To address these issues, we propose a novel training method that integrates a bidirectional chains of thought and a reward mechanism. This method is built upon ICH-Qwen, a large language model specifically designed for the field of intangible cultural heritage. The proposed method enables the model to not only perform forward reasoning but also enhances the accuracy of the generated answers by utilizing reverse questioning and reverse reasoning to activate the model's latent knowledge. Additionally, a reward mechanism is introduced during training to optimize the decision-making process. This mechanism improves the quality of the model's outputs through structural and content evaluations with different weighting schemes. We conduct comparative experiments on ICH-Qwen, with results demonstrating that our method outperforms 0-shot, step-by-step reasoning, knowledge distillation, and question augmentation methods in terms of accuracy, Bleu-4, and Rouge-L scores on the question-answering task. Furthermore, the paper highlights the effectiveness of combining the bidirectional chains of thought and reward mechanism through ablation experiments. In addition, a series of generalizability experiments are conducted, with results showing that the proposed method yields improvements on various domain-specific datasets and advanced models in areas such as Finance, Wikidata, and StrategyQA. This demonstrates that the method is adaptable to multiple domains and provides a valuable approach for model training in future applications across diverse fields.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "We want to withdraw this paper due to data usage permission issues identified after submission. We discovered that our use of certain intangible cultural heritage materials required additional community permissions and institutional ethical approvals that were not obtained",
    "pdf_url": "https://arxiv.org/pdf/2505.08167v4",
    "published_date": "2025-05-13 02:05:25 UTC",
    "updated_date": "2025-06-10 14:34:45 UTC"
  },
  {
    "arxiv_id": "2505.08163v1",
    "title": "Decoding Neighborhood Environments with Large Language Models",
    "authors": [
      "Andrew Cart",
      "Shaohu Zhang",
      "Melanie Escue",
      "Xugui Zhou",
      "Haitao Zhao",
      "Prashanth BusiReddyGari",
      "Beiyu Lin",
      "Shuang Li"
    ],
    "abstract": "Neighborhood environments include physical and environmental conditions such as housing quality, roads, and sidewalks, which significantly influence human health and well-being. Traditional methods for assessing these environments, including field surveys and geographic information systems (GIS), are resource-intensive and challenging to evaluate neighborhood environments at scale. Although machine learning offers potential for automated analysis, the laborious process of labeling training data and the lack of accessible models hinder scalability. This study explores the feasibility of large language models (LLMs) such as ChatGPT and Gemini as tools for decoding neighborhood environments (e.g., sidewalk and powerline) at scale. We train a robust YOLOv11-based model, which achieves an average accuracy of 99.13% in detecting six environmental indicators, including streetlight, sidewalk, powerline, apartment, single-lane road, and multilane road. We then evaluate four LLMs, including ChatGPT, Gemini, Claude, and Grok, to assess their feasibility, robustness, and limitations in identifying these indicators, with a focus on the impact of prompting strategies and fine-tuning. We apply majority voting with the top three LLMs to achieve over 88% accuracy, which demonstrates LLMs could be a useful tool to decode the neighborhood environment without any training effort.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.08163v1",
    "published_date": "2025-05-13 01:54:54 UTC",
    "updated_date": "2025-05-13 01:54:54 UTC"
  },
  {
    "arxiv_id": "2505.08158v1",
    "title": "Feature Fitted Online Conformal Prediction for Deep Time Series Forecasting Model",
    "authors": [
      "Xiannan Huang",
      "Shuhan Qiu"
    ],
    "abstract": "Time series forecasting is critical for many applications, where deep learning-based point prediction models have demonstrated strong performance. However, in practical scenarios, there is also a need to quantify predictive uncertainty through online confidence intervals. Existing confidence interval modeling approaches building upon these deep point prediction models suffer from key limitations: they either require costly retraining, fail to fully leverage the representational strengths of deep models, or lack theoretical guarantees. To address these gaps, we propose a lightweight conformal prediction method that provides valid coverage and shorter interval lengths without retraining. Our approach leverages features extracted from pre-trained point prediction models to fit a residual predictor and construct confidence intervals, further enhanced by an adaptive coverage control mechanism. Theoretically, we prove that our method achieves asymptotic coverage convergence, with error bounds dependent on the feature quality of the underlying point prediction model. Experiments on 12 datasets demonstrate that our method delivers tighter confidence intervals while maintaining desired coverage rates. Code, model and dataset in \\href{https://github.com/xiannanhuang/FFDCI}{Github}",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08158v1",
    "published_date": "2025-05-13 01:33:53 UTC",
    "updated_date": "2025-05-13 01:33:53 UTC"
  },
  {
    "arxiv_id": "2505.08157v1",
    "title": "Hyperbolic Contrastive Learning with Model-augmentation for Knowledge-aware Recommendation",
    "authors": [
      "Shengyin Sun",
      "Chen Ma"
    ],
    "abstract": "Benefiting from the effectiveness of graph neural networks (GNNs) and contrastive learning, GNN-based contrastive learning has become mainstream for knowledge-aware recommendation. However, most existing contrastive learning-based methods have difficulties in effectively capturing the underlying hierarchical structure within user-item bipartite graphs and knowledge graphs. Moreover, they commonly generate positive samples for contrastive learning by perturbing the graph structure, which may lead to a shift in user preference learning. To overcome these limitations, we propose hyperbolic contrastive learning with model-augmentation for knowledge-aware recommendation. To capture the intrinsic hierarchical graph structures, we first design a novel Lorentzian knowledge aggregation mechanism, which enables more effective representations of users and items. Then, we propose three model-level augmentation techniques to assist Hyperbolic contrastive learning. Different from the classical structure-level augmentation (e.g., edge dropping), the proposed model-augmentations can avoid preference shifts between the augmented positive pair. Finally, we conduct extensive experiments to demonstrate the superiority (maximum improvement of $11.03\\%$) of proposed methods over existing baselines.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "18 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.08157v1",
    "published_date": "2025-05-13 01:30:27 UTC",
    "updated_date": "2025-05-13 01:30:27 UTC"
  },
  {
    "arxiv_id": "2505.08155v3",
    "title": "Efficient and Scalable Neural Symbolic Search for Knowledge Graph Complex Query Answering",
    "authors": [
      "Weizhi Fei",
      "Zihao Wang",
      "hang Yin",
      "Shukai Zhao",
      "Wei Zhang",
      "Yangqiu Song"
    ],
    "abstract": "Complex Query Answering (CQA) aims to retrieve answer sets for complex logical formulas from incomplete knowledge graphs, which is a crucial yet challenging task in knowledge graph reasoning. While neuro-symbolic search utilized neural link predictions achieve superior accuracy, they encounter significant complexity bottlenecks: (i) Data complexity typically scales quadratically with the number of entities in the knowledge graph, and (ii) Query complexity becomes NP-hard for cyclic queries. Consequently, these approaches struggle to effectively scale to larger knowledge graphs and more complex queries. To address these challenges, we propose an efficient and scalable symbolic search framework. First, we propose two constraint strategies to compute neural logical indices to reduce the domain of variables, thereby decreasing the data complexity of symbolic search. Additionally, we introduce an approximate algorithm based on local search to tackle the NP query complexity of cyclic queries. Experiments on various CQA benchmarks demonstrate that our framework reduces the computational load of symbolic methods by 90\\% while maintaining nearly the same performance, thus alleviating both efficiency and scalability issues.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08155v3",
    "published_date": "2025-05-13 01:24:09 UTC",
    "updated_date": "2025-05-20 12:09:36 UTC"
  },
  {
    "arxiv_id": "2505.08151v4",
    "title": "Foundation Models Knowledge Distillation For Battery Capacity Degradation Forecast",
    "authors": [
      "Joey Chan",
      "Zhen Chen",
      "Ershun Pan"
    ],
    "abstract": "Accurate forecasting of lithium-ion battery capacity degradation is critical for reliable and safe operation, yet remains challenging under distribution shifts across scales and operating regimes. Here we investigate a time-series foundation model, that is, a large pre-trained time-series model for capacity degradation forecasting, and propose a degradation-aware fine-tuning strategy that aligns the model to capacity trajectories while retaining broadly transferable temporal structure. We instantiate this approach by fine-tuning the Timer model on 220,153 cycles of open-source charge-discharge records to obtain Battery-Timer. Using our released CycleLife-SJTUIE dataset, a real-world industrial collection from an energy-storage station with long-horizon cycling, we evaluate capacity generalization from small cells to large-scale storage systems and across varying operating conditions. Battery-Timer consistently outperforms specialized expert models. To address deployment cost, we further introduce knowledge distillation, a teacher-student transfer that compresses the foundation model's behavior into compact expert models. Distillation across several state-of-the-art time-series experts improves multi-condition capacity generalization while substantially reducing computational overhead, indicating a practical path to deployable cross-scale degradation forecasting by combining a foundation model with targeted distillation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08151v4",
    "published_date": "2025-05-13 01:03:35 UTC",
    "updated_date": "2025-12-06 06:33:18 UTC"
  },
  {
    "arxiv_id": "2505.08829v3",
    "title": "Aggregating Concepts of Fairness and Accuracy in Prediction Algorithms",
    "authors": [
      "David Kinney"
    ],
    "abstract": "An algorithm that outputs predictions about the state of the world will almost always be designed with the implicit or explicit goal of outputting accurate predictions (i.e., predictions that are likely to be true). In addition, the rise of increasingly powerful predictive algorithms brought about by the recent revolution in artificial intelligence has led to an emphasis on building predictive algorithms that are fair, in the sense that their predictions do not systematically evince bias or bring about harm to certain individuals or groups. This state of affairs presents two conceptual challenges. First, the goals of accuracy and fairness can sometimes be in tension, and there are no obvious normative guidelines for managing the trade-offs between these two desiderata when they arise. Second, there are many distinct ways of measuring both the accuracy and fairness of a predictive algorithm; here too, there are no obvious guidelines on how to aggregate our preferences for predictive algorithms that satisfy disparate measures of fairness and accuracy to various extents. The goal of this paper is to address these challenges by arguing that there are good reasons for using a linear combination of accuracy and fairness metrics to measure the all-things-considered value of a predictive algorithm for agents who care about both accuracy and fairness. My argument depends crucially on a classic result in the preference aggregation literature due to Harsanyi. After making this formal argument, I apply my result to an analysis of accuracy-fairness trade-offs using the COMPAS dataset compiled by Angwin et al.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08829v3",
    "published_date": "2025-05-13 01:00:25 UTC",
    "updated_date": "2025-07-05 14:43:59 UTC"
  },
  {
    "arxiv_id": "2505.08148v1",
    "title": "A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem",
    "authors": [
      "Sunday Oyinlola Ogundoyin",
      "Muhammad Ikram",
      "Hassan Jameel Asghar",
      "Benjamin Zi Hao Zhao",
      "Dali Kaafar"
    ],
    "abstract": "Millions of users leverage generative pretrained transformer (GPT)-based language models developed by leading model providers for a wide range of tasks. To support enhanced user interaction and customization, many platforms-such as OpenAI-now enable developers to create and publish tailored model instances, known as custom GPTs, via dedicated repositories or application stores. These custom GPTs empower users to browse and interact with specialized applications designed to meet specific needs. However, as custom GPTs see growing adoption, concerns regarding their security vulnerabilities have intensified. Existing research on these vulnerabilities remains largely theoretical, often lacking empirical, large-scale, and statistically rigorous assessments of associated risks.\n  In this study, we analyze 14,904 custom GPTs to assess their susceptibility to seven exploitable threats, such as roleplay-based attacks, system prompt leakage, phishing content generation, and malicious code synthesis, across various categories and popularity tiers within the OpenAI marketplace. We introduce a multi-metric ranking system to examine the relationship between a custom GPT's popularity and its associated security risks.\n  Our findings reveal that over 95% of custom GPTs lack adequate security protections. The most prevalent vulnerabilities include roleplay-based vulnerabilities (96.51%), system prompt leakage (92.20%), and phishing (91.22%). Furthermore, we demonstrate that OpenAI's foundational models exhibit inherent security weaknesses, which are often inherited or amplified in custom GPTs. These results highlight the urgent need for enhanced security measures and stricter content moderation to ensure the safe deployment of GPT-based applications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08148v1",
    "published_date": "2025-05-13 00:51:07 UTC",
    "updated_date": "2025-05-13 00:51:07 UTC"
  },
  {
    "arxiv_id": "2505.08828v1",
    "title": "Human-AI Collaboration or Academic Misconduct? Measuring AI Use in Student Writing Through Stylometric Evidence",
    "authors": [
      "Eduardo Araujo Oliveira",
      "Madhavi Mohoni",
      "Sonsoles López-Pernas",
      "Mohammed Saqr"
    ],
    "abstract": "As human-AI collaboration becomes increasingly prevalent in educational contexts, understanding and measuring the extent and nature of such interactions pose significant challenges. This research investigates the use of authorship verification (AV) techniques not as a punitive measure, but as a means to quantify AI assistance in academic writing, with a focus on promoting transparency, interpretability, and student development. Building on prior work, we structured our investigation into three stages: dataset selection and expansion, AV method development, and systematic evaluation. Using three datasets - including a public dataset (PAN-14) and two from University of Melbourne students from various courses - we expanded the data to include LLM-generated texts, totalling 1,889 documents and 540 authorship problems from 506 students. We developed an adapted Feature Vector Difference AV methodology to construct robust academic writing profiles for students, designed to capture meaningful, individual characteristics of their writing. The method's effectiveness was evaluated across multiple scenarios, including distinguishing between student-authored and LLM-generated texts and testing resilience against LLMs' attempts to mimic student writing styles. Results demonstrate the enhanced AV classifier's ability to identify stylometric discrepancies and measure human-AI collaboration at word and sentence levels while providing educators with a transparent tool to support academic integrity investigations. This work advances AV technology, offering actionable insights into the dynamics of academic writing in an AI-driven era.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 10 figures, 11 tables",
    "pdf_url": "https://arxiv.org/pdf/2505.08828v1",
    "published_date": "2025-05-13 00:36:36 UTC",
    "updated_date": "2025-05-13 00:36:36 UTC"
  },
  {
    "arxiv_id": "2505.08143v1",
    "title": "Communication Styles and Reader Preferences of LLM and Human Experts in Explaining Health Information",
    "authors": [
      "Jiawei Zhou",
      "Kritika Venkatachalam",
      "Minje Choi",
      "Koustuv Saha",
      "Munmun De Choudhury"
    ],
    "abstract": "With the wide adoption of large language models (LLMs) in information assistance, it is essential to examine their alignment with human communication styles and values. We situate this study within the context of fact-checking health information, given the critical challenge of rectifying conceptions and building trust. Recent studies have explored the potential of LLM for health communication, but style differences between LLMs and human experts and associated reader perceptions remain under-explored. In this light, our study evaluates the communication styles of LLMs, focusing on how their explanations differ from those of humans in three core components of health communication: information, sender, and receiver. We compiled a dataset of 1498 health misinformation explanations from authoritative fact-checking organizations and generated LLM responses to inaccurate health information. Drawing from health communication theory, we evaluate communication styles across three key dimensions of information linguistic features, sender persuasive strategies, and receiver value alignments. We further assessed human perceptions through a blinded evaluation with 99 participants. Our findings reveal that LLM-generated articles showed significantly lower scores in persuasive strategies, certainty expressions, and alignment with social values and moral foundations. However, human evaluation demonstrated a strong preference for LLM content, with over 60% responses favoring LLM articles for clarity, completeness, and persuasiveness. Our results suggest that LLMs' structured approach to presenting information may be more effective at engaging readers despite scoring lower on traditional measures of quality in fact-checking and health communication.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08143v1",
    "published_date": "2025-05-13 00:32:38 UTC",
    "updated_date": "2025-05-13 00:32:38 UTC"
  },
  {
    "arxiv_id": "2505.08140v4",
    "title": "Lost in Transmission: When and Why LLMs Fail to Reason Globally",
    "authors": [
      "Tobias Schnabel",
      "Kiran Tomlinson",
      "Adith Swaminathan",
      "Jennifer Neville"
    ],
    "abstract": "Despite their many successes, transformer-based large language models (LLMs) continue to struggle with tasks that require complex reasoning over large parts of their input. We argue that these failures arise due to capacity limits on the accurate flow of information within LLMs. To formalize this issue, we introduce the bounded attention prefix oracle (BAPO) model, a new computational framework that models bandwidth constraints on attention heads, the mechanism for internal communication in LLMs. We show that several important reasoning problems like graph reachability require high communication bandwidth for BAPOs to solve; we call these problems BAPO-hard. Our experiments corroborate our theoretical predictions: GPT-4o, Claude, and Gemini succeed on BAPO-easy tasks and fail even on relatively small BAPO-hard tasks. BAPOs also reveal another benefit of chain of thought (CoT): we prove that breaking down a task using CoT can turn any BAPO-hard problem into a BAPO-easy one. Our results offer principled explanations for key LLM failures and suggest directions for architectures and inference methods that mitigate bandwidth limits.",
    "categories": [
      "cs.AI",
      "cs.FL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "36 pages; accepted to NeurIPS '25 (spotlight)",
    "pdf_url": "https://arxiv.org/pdf/2505.08140v4",
    "published_date": "2025-05-13 00:25:23 UTC",
    "updated_date": "2025-10-24 21:28:22 UTC"
  },
  {
    "arxiv_id": "2505.08138v1",
    "title": "Mirror Mirror on the Wall, Have I Forgotten it All? A New Framework for Evaluating Machine Unlearning",
    "authors": [
      "Brennon Brimhall",
      "Philip Mathew",
      "Neil Fendley",
      "Yinzhi Cao",
      "Matthew Green"
    ],
    "abstract": "Machine unlearning methods take a model trained on a dataset and a forget set, then attempt to produce a model as if it had only been trained on the examples not in the forget set. We empirically show that an adversary is able to distinguish between a mirror model (a control model produced by retraining without the data to forget) and a model produced by an unlearning method across representative unlearning methods from the literature. We build distinguishing algorithms based on evaluation scores in the literature (i.e. membership inference scores) and Kullback-Leibler divergence.\n  We propose a strong formal definition for machine unlearning called computational unlearning. Computational unlearning is defined as the inability for an adversary to distinguish between a mirror model and a model produced by an unlearning method. If the adversary cannot guess better than random (except with negligible probability), then we say that an unlearning method achieves computational unlearning.\n  Our computational unlearning definition provides theoretical structure to prove unlearning feasibility results. For example, our computational unlearning definition immediately implies that there are no deterministic computational unlearning methods for entropic learning algorithms. We also explore the relationship between differential privacy (DP)-based unlearning methods and computational unlearning, showing that DP-based approaches can satisfy computational unlearning at the cost of an extreme utility collapse. These results demonstrate that current methodology in the literature fundamentally falls short of achieving computational unlearning. We conclude by identifying several open questions for future work.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08138v1",
    "published_date": "2025-05-13 00:23:17 UTC",
    "updated_date": "2025-05-13 00:23:17 UTC"
  },
  {
    "arxiv_id": "2505.08135v1",
    "title": "Leveraging AI for Productive and Trustworthy HPC Software: Challenges and Research Directions",
    "authors": [
      "Keita Teranishi",
      "Harshitha Menon",
      "William F. Godoy",
      "Prasanna Balaprakash",
      "David Bau",
      "Tal Ben-Nun",
      "Abhinav Bhatele",
      "Franz Franchetti",
      "Michael Franusich",
      "Todd Gamblin",
      "Giorgis Georgakoudis",
      "Tom Goldstein",
      "Arjun Guha",
      "Steven Hahn",
      "Costin Iancu",
      "Zheming Jin",
      "Terry Jones",
      "Tze Meng Low",
      "Het Mankad",
      "Narasinga Rao Miniskar",
      "Mohammad Alaul Haque Monil",
      "Daniel Nichols",
      "Konstantinos Parasyris",
      "Swaroop Pophale",
      "Pedro Valero-Lara",
      "Jeffrey S. Vetter",
      "Samuel Williams",
      "Aaron Young"
    ],
    "abstract": "We discuss the challenges and propose research directions for using AI to revolutionize the development of high-performance computing (HPC) software. AI technologies, in particular large language models, have transformed every aspect of software development. For its part, HPC software is recognized as a highly specialized scientific field of its own. We discuss the challenges associated with leveraging state-of-the-art AI technologies to develop such a unique and niche class of software and outline our research directions in the two US Department of Energy--funded projects for advancing HPC Software via AI: Ellora and Durban.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages, 1 Figure, Accepted at \"The 1st International Workshop on Foundational Large Language Models Advances for HPC\" LLM4HPC to be held in conjunction with ISC High Performance 2025",
    "pdf_url": "https://arxiv.org/pdf/2505.08135v1",
    "published_date": "2025-05-13 00:12:45 UTC",
    "updated_date": "2025-05-13 00:12:45 UTC"
  },
  {
    "arxiv_id": "2505.08133v2",
    "title": "One Bad NOFO? AI Governance in Federal Grantmaking",
    "authors": [
      "Dan Bateyko",
      "Karen Levy"
    ],
    "abstract": "Much scholarship considers how U.S. federal agencies govern artificial intelligence (AI) through rulemaking and their own internal use policies. But agencies have an overlooked AI governance role: setting discretionary grant policy when directing billions of dollars in federal financial assistance. These dollars enable state and local entities to study, create, and use AI. This funding not only goes to dedicated AI programs, but also to grantees using AI in the course of meeting their routine grant objectives. As discretionary grantmakers, agencies guide and restrict what grant winners do -- a hidden lever for AI governance. Agencies pull this lever by setting program objectives, judging criteria, and restrictions for AI use. Using a novel dataset of over 40,000 non-defense federal grant notices of funding opportunity (NOFOs) posted to the U.S. federal grants website between 2009 and 2024, we analyze how agencies regulate the use of AI by grantees. We select records mentioning AI and review their stated goals and requirements. We find agencies promoting AI in notice narratives, shaping adoption in ways other records of grant policy might fail to capture. Of the grant opportunities that mention AI, we find only a handful of AI-specific judging criteria or restrictions. This silence holds even when agencies fund AI uses in contexts affecting people's rights and which, under an analogous federal procurement regime, would result in extra oversight. These findings recast grant notices as a site of AI policymaking -- albeit one that is developing out of step with other regulatory efforts and incomplete in its consideration of transparency, accountability, and privacy protections. The paper concludes by drawing lessons from AI procurement scholarship, while identifying distinct challenges in grantmaking that invite further study.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "In The 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT '25), June 23---26, 2025, Athens, Greece. 13 pages",
    "pdf_url": "https://arxiv.org/pdf/2505.08133v2",
    "published_date": "2025-05-13 00:08:22 UTC",
    "updated_date": "2025-05-21 18:33:28 UTC"
  },
  {
    "arxiv_id": "2505.08130v1",
    "title": "ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval",
    "authors": [
      "Mingxu Tao",
      "Bowen Tang",
      "Mingxuan Ma",
      "Yining Zhang",
      "Hourun Li",
      "Feifan Wen",
      "Hao Ma",
      "Jia Yang"
    ],
    "abstract": "The rise of Large Language Models~(LLMs) revolutionizes information retrieval, allowing users to obtain required answers through complex instructions within conversations. However, publicly available services remain inadequate in addressing the needs of faculty and students to search campus-specific information. It is primarily due to the LLM's lack of domain-specific knowledge and the limitation of search engines in supporting multilingual and timely scenarios. To tackle these challenges, we introduce ALOHA, a multilingual agent enhanced by hierarchical retrieval for university orientation. We also integrate external APIs into the front-end interface to provide interactive service. The human evaluation and case study show our proposed system has strong capabilities to yield correct, timely, and user-friendly responses to the queries in multiple languages, surpassing commercial chatbots and search engines. The system has been deployed and has provided service for more than 12,000 people.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in NAACL 2025 Demo Track",
    "pdf_url": "https://arxiv.org/pdf/2505.08130v1",
    "published_date": "2025-05-13 00:01:03 UTC",
    "updated_date": "2025-05-13 00:01:03 UTC"
  },
  {
    "arxiv_id": "2505.08129v1",
    "title": "High-order Regularization for Machine Learning and Learning-based Control",
    "authors": [
      "Xinghua Liu",
      "Ming Cao"
    ],
    "abstract": "The paper proposes a novel regularization procedure for machine learning. The proposed high-order regularization (HR) provides new insight into regularization, which is widely used to train a neural network that can be utilized to approximate the action-value function in general reinforcement learning problems. The proposed HR method ensures the provable convergence of the approximation algorithm, which makes the much-needed connection between regularization and explainable learning using neural networks. The proposed HR method theoretically demonstrates that regularization can be regarded as an approximation in terms of inverse mapping with explicitly calculable approximation error, and the $L_2$ regularization is a lower-order case of the proposed method. We provide lower and upper bounds for the error of the proposed HR solution, which helps build a reliable model. We also find that regularization with the proposed HR can be regarded as a contraction. We prove that the generalizability of neural networks can be maximized with a proper regularization matrix, and the proposed HR is applicable for neural networks with any mapping matrix. With the theoretical explanation of the extreme learning machine for neural network training and the proposed high-order regularization, one can better interpret the output of the neural network, thus leading to explainable learning. We present a case study based on regularized extreme learning neural networks to demonstrate the application of the proposed HR and give the corresponding incremental HR solution. We verify the performance of the proposed HR method by solving a classic control problem in reinforcement learning. The result demonstrates the superior performance of the method with significant enhancement in the generalizability of the neural network.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2505.08129v1",
    "published_date": "2025-05-13 00:00:23 UTC",
    "updated_date": "2025-05-13 00:00:23 UTC"
  }
]