[
  {
    "arxiv_id": "2505.09031v1",
    "title": "Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification",
    "authors": [
      "Adarsh Kumar",
      "Hwiyoon Kim",
      "Jawahar Sai Nathani",
      "Neil Roy"
    ],
    "abstract": "Hallucination, where large language models (LLMs) generate confident but\nincorrect or irrelevant information, remains a key limitation in their\napplication to complex, open-ended tasks. Chain-of-thought (CoT) prompting has\nemerged as a promising method for improving multistep reasoning by guiding\nmodels through intermediate steps. However, CoT alone does not fully address\nthe hallucination problem. In this work, we investigate how combining CoT with\nretrieval-augmented generation (RAG), as well as applying self-consistency and\nself-verification strategies, can reduce hallucinations and improve factual\naccuracy. By incorporating external knowledge sources during reasoning and\nenabling models to verify or revise their own outputs, we aim to generate more\naccurate and coherent responses. We present a comparative evaluation of\nbaseline LLMs against CoT, CoT+RAG, self-consistency, and self-verification\ntechniques. Our results highlight the effectiveness of each method and identify\nthe most robust approach for minimizing hallucinations while preserving fluency\nand reasoning depth.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09031v1",
    "published_date": "2025-05-13 23:57:02 UTC",
    "updated_date": "2025-05-13 23:57:02 UTC"
  },
  {
    "arxiv_id": "2505.09029v1",
    "title": "Monte Carlo Beam Search for Actor-Critic Reinforcement Learning in Continuous Control",
    "authors": [
      "Hazim Alzorgan",
      "Abolfazl Razi"
    ],
    "abstract": "Actor-critic methods, like Twin Delayed Deep Deterministic Policy Gradient\n(TD3), depend on basic noise-based exploration, which can result in less than\noptimal policy convergence. In this study, we introduce Monte Carlo Beam Search\n(MCBS), a new hybrid method that combines beam search and Monte Carlo rollouts\nwith TD3 to improve exploration and action selection. MCBS produces several\ncandidate actions around the policy's output and assesses them through\nshort-horizon rollouts, enabling the agent to make better-informed choices. We\ntest MCBS across various continuous-control benchmarks, including\nHalfCheetah-v4, Walker2d-v5, and Swimmer-v5, showing enhanced sample efficiency\nand performance compared to standard TD3 and other baseline methods like SAC,\nPPO, and A2C. Our findings emphasize MCBS's capability to enhance policy\nlearning through structured look-ahead search while ensuring computational\nefficiency. Additionally, we offer a detailed analysis of crucial\nhyperparameters, such as beam width and rollout depth, and explore adaptive\nstrategies to optimize MCBS for complex control tasks. Our method shows a\nhigher convergence rate across different environments compared to TD3, SAC,\nPPO, and A2C. For instance, we achieved 90% of the maximum achievable reward\nwithin around 200 thousand timesteps compared to 400 thousand timesteps for the\nsecond-best method.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09029v1",
    "published_date": "2025-05-13 23:56:12 UTC",
    "updated_date": "2025-05-13 23:56:12 UTC"
  },
  {
    "arxiv_id": "2505.09027v1",
    "title": "Tests as Prompt: A Test-Driven-Development Benchmark for LLM Code Generation",
    "authors": [
      "Yi Cui"
    ],
    "abstract": "We introduce WebApp1K, a novel benchmark for evaluating large language models\n(LLMs) in test-driven development (TDD) tasks, where test cases serve as both\nprompt and verification for code generation. Unlike traditional approaches\nrelying on natural language prompts, our benchmark emphasizes the ability of\nLLMs to interpret and implement functionality directly from test cases,\nreflecting real-world software development practices. Comprising 1000 diverse\nchallenges across 20 application domains, the benchmark evaluates LLMs on their\nability to generate compact, functional code under the constraints of context\nlength and multi-feature complexity. Our findings highlight instruction\nfollowing and in-context learning as critical capabilities for TDD success,\nsurpassing the importance of general coding proficiency or pretraining\nknowledge. Through comprehensive evaluation of 19 frontier models, we reveal\nperformance bottlenecks, such as instruction loss in long prompts, and provide\na detailed error analysis spanning multiple root causes. This work underscores\nthe practical value of TDD-specific benchmarks and lays the foundation for\nadvancing LLM capabilities in rigorous, application-driven coding scenarios.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "arXiv admin note: text overlap with arXiv:2409.05177",
    "pdf_url": "http://arxiv.org/pdf/2505.09027v1",
    "published_date": "2025-05-13 23:47:12 UTC",
    "updated_date": "2025-05-13 23:47:12 UTC"
  },
  {
    "arxiv_id": "2505.09024v1",
    "title": "Automated Meta Prompt Engineering for Alignment with the Theory of Mind",
    "authors": [
      "Aaron Baughman",
      "Rahul Agarwal",
      "Eduardo Morales",
      "Gozde Akay"
    ],
    "abstract": "We introduce a method of meta-prompting that jointly produces fluent text for\ncomplex tasks while optimizing the similarity of neural states between a\nhuman's mental expectation and a Large Language Model's (LLM) neural\nprocessing. A technique of agentic reinforcement learning is applied, in which\nan LLM as a Judge (LLMaaJ) teaches another LLM, through in-context learning,\nhow to produce content by interpreting the intended and unintended generated\ntext traits. To measure human mental beliefs around content production, users\nmodify long form AI-generated text articles before publication at the US Open\n2024 tennis Grand Slam. Now, an LLMaaJ can solve the Theory of Mind (ToM)\nalignment problem by anticipating and including human edits within the creation\nof text from an LLM. Throughout experimentation and by interpreting the results\nof a live production system, the expectations of human content reviewers had\n100% of alignment with AI 53.8% of the time with an average iteration count of\n4.38. The geometric interpretation of content traits such as factualness,\nnovelty, repetitiveness, and relevancy over a Hilbert vector space combines\nspatial volume (all trait importance) with vertices alignment (individual trait\nrelevance) enabled the LLMaaJ to optimize on Human ToM. This resulted in an\nincrease in content quality by extending the coverage of tennis action. Our\nwork that was deployed at the US Open 2024 has been used across other live\nevents within sports and entertainment.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 6 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.09024v1",
    "published_date": "2025-05-13 23:42:36 UTC",
    "updated_date": "2025-05-13 23:42:36 UTC"
  },
  {
    "arxiv_id": "2505.09022v1",
    "title": "Block-Biased Mamba for Long-Range Sequence Processing",
    "authors": [
      "Annan Yu",
      "N. Benjamin Erichson"
    ],
    "abstract": "Mamba extends earlier state space models (SSMs) by introducing\ninput-dependent dynamics, and has demonstrated strong empirical performance\nacross a range of domains, including language modeling, computer vision, and\nfoundation models. However, a surprising weakness remains: despite being built\non architectures designed for long-range dependencies, Mamba performs poorly on\nlong-range sequential tasks. Understanding and addressing this gap is important\nfor improving Mamba's universality and versatility. In this work, we analyze\nMamba's limitations through three perspectives: expressiveness, inductive bias,\nand training stability. Our theoretical results show how Mamba falls short in\neach of these aspects compared to earlier SSMs such as S4D. To address these\nissues, we propose $\\text{B}_2\\text{S}_6$, a simple extension of Mamba's S6\nunit that combines block-wise selective dynamics with a channel-specific bias.\nWe prove that these changes equip the model with a better-suited inductive bias\nand improve its expressiveness and stability. Empirically,\n$\\text{B}_2\\text{S}_6$ outperforms S4 and S4D on Long-Range Arena (LRA) tasks\nwhile maintaining Mamba's performance on language modeling benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09022v1",
    "published_date": "2025-05-13 23:34:09 UTC",
    "updated_date": "2025-05-13 23:34:09 UTC"
  },
  {
    "arxiv_id": "2505.09021v1",
    "title": "AI-Mediated Code Comment Improvement",
    "authors": [
      "Maria Dhakal",
      "Chia-Yi Su",
      "Robert Wallace",
      "Chris Fakhimi",
      "Aakash Bansal",
      "Toby Li",
      "Yu Huang",
      "Collin McMillan"
    ],
    "abstract": "This paper describes an approach to improve code comments along different\nquality axes by rewriting those comments with customized Artificial\nIntelligence (AI)-based tools. We conduct an empirical study followed by\ngrounded theory qualitative analysis to determine the quality axes to improve.\nThen we propose a procedure using a Large Language Model (LLM) to rewrite\nexisting code comments along the quality axes. We implement our procedure using\nGPT-4o, then distil the results into a smaller model capable of being run\nin-house, so users can maintain data custody. We evaluate both our approach\nusing GPT-4o and the distilled model versions. We show in an evaluation how our\nprocedure improves code comments along the quality axes. We release all data\nand source code in an online repository for reproducibility.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09021v1",
    "published_date": "2025-05-13 23:31:32 UTC",
    "updated_date": "2025-05-13 23:31:32 UTC"
  },
  {
    "arxiv_id": "2505.09012v1",
    "title": "Deep Reinforcement Learning for Power Grid Multi-Stage Cascading Failure Mitigation",
    "authors": [
      "Bo Meng",
      "Chenghao Xu",
      "Yongli Zhu"
    ],
    "abstract": "Cascading failures in power grids can lead to grid collapse, causing severe\ndisruptions to social operations and economic activities. In certain cases,\nmulti-stage cascading failures can occur. However, existing\ncascading-failure-mitigation strategies are usually single-stage-based,\noverlooking the complexity of the multi-stage scenario. This paper treats the\nmulti-stage cascading failure problem as a reinforcement learning task and\ndevelops a simulation environment. The reinforcement learning agent is then\ntrained via the deterministic policy gradient algorithm to achieve continuous\nactions. Finally, the effectiveness of the proposed approach is validated on\nthe IEEE 14-bus and IEEE 118-bus systems.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.09012v1",
    "published_date": "2025-05-13 23:01:34 UTC",
    "updated_date": "2025-05-13 23:01:34 UTC"
  },
  {
    "arxiv_id": "2505.09003v1",
    "title": "Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition",
    "authors": [
      "Zeki Doruk Erden",
      "Donia Gasmi",
      "Boi Faltings"
    ],
    "abstract": "Continual learning for reinforcement learning agents remains a significant\nchallenge, particularly in preserving and leveraging existing information\nwithout an external signal to indicate changes in tasks or environments. In\nthis study, we explore the effectiveness of autoencoders in detecting new tasks\nand matching observed environments to previously encountered ones. Our approach\nintegrates policy optimization with familiarity autoencoders within an\nend-to-end continual learning system. This system can recognize and learn new\ntasks or environments while preserving knowledge from earlier experiences and\ncan selectively retrieve relevant knowledge when re-encountering a known\nenvironment. Initial results demonstrate successful continual learning without\nexternal signals to indicate task changes or reencounters, showing promise for\nthis methodology.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in the Autonomous Robots and Multirobot Systems (ARMS)\n  workshop at AAMAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.09003v1",
    "published_date": "2025-05-13 22:38:54 UTC",
    "updated_date": "2025-05-13 22:38:54 UTC"
  },
  {
    "arxiv_id": "2505.08995v1",
    "title": "Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning",
    "authors": [
      "Ardian Selmonaj",
      "Oleg Szehr",
      "Giacomo Del Rio",
      "Alessandro Antonucci",
      "Adrian Schneider",
      "Michael Rüegsegger"
    ],
    "abstract": "This work presents a Hierarchical Multi-Agent Reinforcement Learning\nframework for analyzing simulated air combat scenarios involving heterogeneous\nagents. The objective is to identify effective Courses of Action that lead to\nmission success within preset simulations, thereby enabling the exploration of\nreal-world defense scenarios at low cost and in a safe-to-fail setting.\nApplying deep Reinforcement Learning in this context poses specific challenges,\nsuch as complex flight dynamics, the exponential size of the state and action\nspaces in multi-agent systems, and the capability to integrate real-time\ncontrol of individual units with look-ahead planning. To address these\nchallenges, the decision-making process is split into two levels of\nabstraction: low-level policies control individual units, while a high-level\ncommander policy issues macro commands aligned with the overall mission\ntargets. This hierarchical structure facilitates the training process by\nexploiting policy symmetries of individual agents and by separating control\nfrom command tasks. The low-level policies are trained for individual combat\ncontrol in a curriculum of increasing complexity. The high-level commander is\nthen trained on mission targets given pre-trained control policies. The\nempirical validation confirms the advantages of the proposed framework.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as journal chapter in Deep Learning Applications, Vol. 1,\n  by Taylor & Francis",
    "pdf_url": "http://arxiv.org/pdf/2505.08995v1",
    "published_date": "2025-05-13 22:13:48 UTC",
    "updated_date": "2025-05-13 22:13:48 UTC"
  },
  {
    "arxiv_id": "2505.08988v1",
    "title": "Generalization in Monitored Markov Decision Processes (Mon-MDPs)",
    "authors": [
      "Montaser Mohammedalamen",
      "Michael Bowling"
    ],
    "abstract": "Reinforcement learning (RL) typically models the interaction between the\nagent and environment as a Markov decision process (MDP), where the rewards\nthat guide the agent's behavior are always observable. However, in many\nreal-world scenarios, rewards are not always observable, which can be modeled\nas a monitored Markov decision process (Mon-MDP). Prior work on Mon-MDPs have\nbeen limited to simple, tabular cases, restricting their applicability to\nreal-world problems. This work explores Mon-MDPs using function approximation\n(FA) and investigates the challenges involved. We show that combining function\napproximation with a learned reward model enables agents to generalize from\nmonitored states with observable rewards, to unmonitored environment states\nwith unobservable rewards. Therefore, we demonstrate that such generalization\nwith a reward model achieves near-optimal policies in environments formally\ndefined as unsolvable. However, we identify a critical limitation of such\nfunction approximation, where agents incorrectly extrapolate rewards due to\novergeneralization, resulting in undesirable behaviors. To mitigate\novergeneralization, we propose a cautious police optimization method leveraging\nreward uncertainty. This work serves as a step towards bridging this gap\nbetween Mon-MDP theory and real-world applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2505.08988v1",
    "published_date": "2025-05-13 21:58:25 UTC",
    "updated_date": "2025-05-13 21:58:25 UTC"
  },
  {
    "arxiv_id": "2505.08964v1",
    "title": "GPML: Graph Processing for Machine Learning",
    "authors": [
      "Majed Jaber",
      "Julien Michel",
      "Nicolas Boutry",
      "Pierre Parrend"
    ],
    "abstract": "The dramatic increase of complex, multi-step, and rapidly evolving attacks in\ndynamic networks involves advanced cyber-threat detectors. The GPML (Graph\nProcessing for Machine Learning) library addresses this need by transforming\nraw network traffic traces into graph representations, enabling advanced\ninsights into network behaviors. The library provides tools to detect anomalies\nin interaction and community shifts in dynamic networks. GPML supports\ncommunity and spectral metrics extraction, enhancing both real-time detection\nand historical forensics analysis. This library supports modern cybersecurity\nchallenges with a robust, graph-based approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08964v1",
    "published_date": "2025-05-13 21:10:46 UTC",
    "updated_date": "2025-05-13 21:10:46 UTC"
  },
  {
    "arxiv_id": "2505.08939v1",
    "title": "Tracing the Invisible: Understanding Students' Judgment in AI-Supported Design Work",
    "authors": [
      "Suchismita Naik",
      "Prakash Shukla",
      "Ike Obi",
      "Jessica Backus",
      "Nancy Rasche",
      "Paul Parsons"
    ],
    "abstract": "As generative AI tools become integrated into design workflows, students\nincreasingly engage with these tools not just as aids, but as collaborators.\nThis study analyzes reflections from 33 student teams in an HCI design course\nto examine the kinds of judgments students make when using AI tools. We found\nboth established forms of design judgment (e.g., instrumental, appreciative,\nquality) and emergent types: agency-distribution judgment and reliability\njudgment. These new forms capture how students negotiate creative\nresponsibility with AI and assess the trustworthiness of its outputs. Our\nfindings suggest that generative AI introduces new layers of complexity into\ndesign reasoning, prompting students to reflect not only on what AI produces,\nbut also on how and when to rely on it. By foregrounding these judgments, we\noffer a conceptual lens for understanding how students engage in co-creative\nsensemaking with AI in design contexts.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "5 pages, 2 Tables, In Creativity and Cognition 2025, June 23--25,\n  2025, Virtual, United Kingdom",
    "pdf_url": "http://arxiv.org/pdf/2505.08939v1",
    "published_date": "2025-05-13 20:08:10 UTC",
    "updated_date": "2025-05-13 20:08:10 UTC"
  },
  {
    "arxiv_id": "2505.08919v1",
    "title": "Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions",
    "authors": [
      "Kangxian Xie",
      "Yufei Zhu",
      "Kaiming Kuang",
      "Li Zhang",
      "Hongwei Bran Li",
      "Mingchen Gao",
      "Jiancheng Yang"
    ],
    "abstract": "High-quality 3D reconstruction of pulmonary segments plays a crucial role in\nsegmentectomy and surgical treatment planning for lung cancer. Due to the\nresolution requirement of the target reconstruction, conventional deep\nlearning-based methods often suffer from computational resource constraints or\nlimited granularity. Conversely, implicit modeling is favored due to its\ncomputational efficiency and continuous representation at any resolution. We\npropose a neural implicit function-based method to learn a 3D surface to\nachieve anatomy-aware, precise pulmonary segment reconstruction, represented as\na shape by deforming a learnable template. Additionally, we introduce two\nclinically relevant evaluation metrics to assess the reconstruction\ncomprehensively. Further, due to the absence of publicly available shape\ndatasets to benchmark reconstruction algorithms, we developed a shape dataset\nnamed Lung3D, including the 3D models of 800 labeled pulmonary segments and the\ncorresponding airways, arteries, veins, and intersegmental veins. We\ndemonstrate that the proposed approach outperforms existing methods, providing\na new perspective for pulmonary segment reconstruction. Code and data will be\navailable at https://github.com/M3DV/ImPulSe.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "In revision process",
    "pdf_url": "http://arxiv.org/pdf/2505.08919v1",
    "published_date": "2025-05-13 19:31:01 UTC",
    "updated_date": "2025-05-13 19:31:01 UTC"
  },
  {
    "arxiv_id": "2505.08918v1",
    "title": "When repeats drive the vocabulary: a Byte-Pair Encoding analysis of T2T primate genomes",
    "authors": [
      "Marina Popova",
      "Iaroslav Chelombitko",
      "Aleksey Komissarov"
    ],
    "abstract": "The emergence of telomere-to-telomere (T2T) genome assemblies has opened new\navenues for comparative genomics, yet effective tokenization strategies for\ngenomic sequences remain underexplored. In this pilot study, we apply Byte Pair\nEncoding (BPE) to nine T2T primate genomes including three human assemblies by\ntraining independent BPE tokenizers with a fixed vocabulary of 512,000 tokens\nusing our custom tool, dnaBPE. Our analysis reveals that only 11,569 tokens are\nshared across all assemblies, while nearly 991,854 tokens are unique to a\nsingle genome, indicating a rapid decline in shared vocabulary with increasing\nassembly comparisons. Moreover, phylogenetic trees derived from token overlap\nfailed to recapitulate established primate relationships, a discrepancy\nattributed to the disproportionate influence of species-specific high-copy\nrepetitive elements. These findings underscore the dual nature of BPE\ntokenization: while it effectively compresses repetitive sequences, its\nsensitivity to high-copy elements limits its utility as a universal tool for\ncomparative genomics. We discuss potential hybrid strategies and repeat-masking\napproaches to refine genomic tokenization, emphasizing the need for\ndomain-specific adaptations in the development of large-scale genomic language\nmodels. The dnaBPE tool used in this study is open-source and available at\nhttps://github.com/aglabx/dnaBPE.",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "ICLR 2025 Workshop on Machine Learning for Genomics Explorations",
    "pdf_url": "http://arxiv.org/pdf/2505.08918v1",
    "published_date": "2025-05-13 19:27:58 UTC",
    "updated_date": "2025-05-13 19:27:58 UTC"
  },
  {
    "arxiv_id": "2505.08916v1",
    "title": "A New Tractable Description Logic under Categorical Semantics",
    "authors": [
      "Chan Le Duc",
      "Ludovic Brieulle"
    ],
    "abstract": "Biomedical ontologies contain numerous concept or role names involving\nnegative knowledge such as lacks_part, absence_of. Such a representation with\nlabels rather than logical constructors would not allow a reasoner to interpret\nlacks_part as a kind of negation of has_part. It is known that adding negation\nto the tractable Description Logic (DL) EL allowing for conjunction,\nexistential restriction and concept inclusion makes it intractable since the\nobtained logic includes implicitly disjunction and universal restriction which\ninteract with other constructors. In this paper, we propose a new extension of\nEL with a weakened negation allowing to represent negative knowledge while\nretaining tractability. To this end, we introduce categorical semantics of all\nlogical constructors of the DL SH including EL with disjunction, negation,\nuniversal restriction, role inclusion and transitive roles. The categorical\nsemantics of a logical constructor is usually described as a set of categorical\nproperties referring to several objects without using set membership. To\nrestore tractability, we have to weaken semantics of disjunction and universal\nrestriction by identifying \\emph{independent} categorical properties that are\nresponsible for intractability, and dropping them from the set of categorical\nproperties. We show that the logic resulting from weakening semantics is more\nexpressive than EL with the bottom concept, transitive roles and role\ninclusion.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08916v1",
    "published_date": "2025-05-13 19:25:21 UTC",
    "updated_date": "2025-05-13 19:25:21 UTC"
  },
  {
    "arxiv_id": "2505.09653v1",
    "title": "Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation",
    "authors": [
      "Samuel Yen-Chi Chen",
      "Chen-Yu Liu",
      "Kuan-Cheng Chen",
      "Wei-Jia Huang",
      "Yen-Jui Chang",
      "Wei-Hao Huang"
    ],
    "abstract": "The rapid advancements in quantum computing (QC) and machine learning (ML)\nhave led to the emergence of quantum machine learning (QML), which integrates\nthe strengths of both fields. Among QML approaches, variational quantum\ncircuits (VQCs), also known as quantum neural networks (QNNs), have shown\npromise both empirically and theoretically. However, their broader adoption is\nhindered by reliance on quantum hardware during inference. Hardware\nimperfections and limited access to quantum devices pose practical challenges.\nTo address this, the Quantum-Train (QT) framework leverages the exponential\nscaling of quantum amplitudes to generate classical neural network parameters,\nenabling inference without quantum hardware and achieving significant parameter\ncompression. Yet, designing effective quantum circuit architectures for such\nquantum-enhanced neural programmers remains non-trivial and often requires\nexpertise in quantum information science. In this paper, we propose an\nautomated solution using differentiable optimization. Our method jointly\noptimizes both conventional circuit parameters and architectural parameters in\nan end-to-end manner via automatic differentiation. We evaluate the proposed\nframework on classification, time-series prediction, and reinforcement learning\ntasks. Simulation results show that our method matches or outperforms manually\ndesigned QNN architectures. This work offers a scalable and automated pathway\nfor designing QNNs that can generate classical neural network parameters across\ndiverse applications.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09653v1",
    "published_date": "2025-05-13 19:01:08 UTC",
    "updated_date": "2025-05-13 19:01:08 UTC"
  },
  {
    "arxiv_id": "2505.08905v1",
    "title": "Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora",
    "authors": [
      "Michael Majurski",
      "Cynthia Matuszek"
    ],
    "abstract": "Language Models (LMs) continue to advance, improving response quality and\ncoherence. Given Internet-scale training datasets, LMs have likely encountered\nmuch of what users might ask them to generate in some form during their\ntraining. A plethora of evaluation benchmarks have been constructed to assess\nmodel quality, response appropriateness, and reasoning capabilities. However,\nthe human effort required for benchmark construction is limited and being\nrapidly outpaced by the size and scope of the models under evaluation.\nAdditionally, having humans build a benchmark for every possible domain of\ninterest is impractical. Therefore, we propose a methodology for automating the\nconstruction of fact-based synthetic data model evaluations grounded in\ndocument populations. This work leverages those very same LMs to evaluate\ndomain-specific knowledge automatically, using only grounding documents (e.g.,\na textbook) as input. This synthetic data benchmarking approach corresponds\nwell with human curated questions with a Spearman ranking correlation of 0.96\nand a benchmark evaluation Pearson accuracy correlation of 0.79. This novel\ntool supports generating both multiple choice and open-ended synthetic data\nquestions to gain diagnostic insight of LM capability. We apply this\nmethodology to evaluate model performance on a recent relevant arXiv preprint,\ndiscovering a surprisingly strong performance from Gemma3 models.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08905v1",
    "published_date": "2025-05-13 18:50:03 UTC",
    "updated_date": "2025-05-13 18:50:03 UTC"
  },
  {
    "arxiv_id": "2505.08904v1",
    "title": "FareShare: A Tool for Labor Organizers to Estimate Lost Wages and Contest Arbitrary AI and Algorithmic Deactivations",
    "authors": [
      "Varun Nagaraj Rao",
      "Samantha Dalal",
      "Andrew Schwartz",
      "Amna Liaqat",
      "Dana Calacci",
      "Andrés Monroy-Hernández"
    ],
    "abstract": "What happens when a rideshare driver is suddenly locked out of the platform\nconnecting them to riders, wages, and daily work? Deactivation-the abrupt\nremoval of gig workers' platform access-typically occurs through arbitrary AI\nand algorithmic decisions with little explanation or recourse. This represents\none of the most severe forms of algorithmic control and often devastates\nworkers' financial stability. Recent U.S. state policies now mandate appeals\nprocesses and recovering compensation during the period of wrongful\ndeactivation based on past earnings. Yet, labor organizers still lack effective\ntools to support these complex, error-prone workflows. We designed FareShare, a\ncomputational tool automating lost wage estimation for deactivated drivers,\nthrough a 6 month partnership with the State of Washington's largest rideshare\nlabor union. Over the following 3 months, our field deployment of FareShare\nregistered 178 account signups. We observed that the tool could reduce lost\nwage calculation time by over 95%, eliminate manual data entry errors, and\nenable legal teams to generate arbitration-ready reports more efficiently.\nBeyond these gains, the deployment also surfaced important socio-technical\nchallenges around trust, consent, and tool adoption in high-stakes labor\ncontexts.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08904v1",
    "published_date": "2025-05-13 18:46:47 UTC",
    "updated_date": "2025-05-13 18:46:47 UTC"
  },
  {
    "arxiv_id": "2505.08902v1",
    "title": "Performance Gains of LLMs With Humans in a World of LLMs Versus Humans",
    "authors": [
      "Lucas McCullum",
      "Pelagie Ami Agassi",
      "Leo Anthony Celi",
      "Daniel K. Ebner",
      "Chrystinne Oliveira Fernandes",
      "Rachel S. Hicklen",
      "Mkliwa Koumbia",
      "Lisa Soleymani Lehmann",
      "David Restrepo"
    ],
    "abstract": "Currently, a considerable research effort is devoted to comparing LLMs to a\ngroup of human experts, where the term \"expert\" is often ill-defined or\nvariable, at best, in a state of constantly updating LLM releases. Without\nproper safeguards in place, LLMs will threaten to cause harm to the established\nstructure of safe delivery of patient care which has been carefully developed\nthroughout history to keep the safety of the patient at the forefront. A key\ndriver of LLM innovation is founded on community research efforts which, if\ncontinuing to operate under \"humans versus LLMs\" principles, will expedite this\ntrend. Therefore, research efforts moving forward must focus on effectively\ncharacterizing the safe use of LLMs in clinical settings that persist across\nthe rapid development of novel LLM models. In this communication, we\ndemonstrate that rather than comparing LLMs to humans, there is a need to\ndevelop strategies enabling efficient work of humans with LLMs in an almost\nsymbiotic manner.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08902v1",
    "published_date": "2025-05-13 18:44:22 UTC",
    "updated_date": "2025-05-13 18:44:22 UTC"
  },
  {
    "arxiv_id": "2505.08896v1",
    "title": "Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections",
    "authors": [
      "Pankaj Kumar",
      "Aditya Mishra",
      "Pranamesh Chakraborty",
      "Subrahmanya Swamy Peruru"
    ],
    "abstract": "Developing an autonomous vehicle control strategy for signalised\nintersections (SI) is one of the challenging tasks due to its inherently\ncomplex decision-making process. This study proposes a Deep Reinforcement\nLearning (DRL) based longitudinal vehicle control strategy at SI. A\ncomprehensive reward function has been formulated with a particular focus on\n(i) distance headway-based efficiency reward, (ii) decision-making criteria\nduring amber light, and (iii) asymmetric acceleration/ deceleration response,\nalong with the traditional safety and comfort criteria. This reward function\nhas been incorporated with two popular DRL algorithms, Deep Deterministic\nPolicy Gradient (DDPG) and Soft-Actor Critic (SAC), which can handle the\ncontinuous action space of acceleration/deceleration. The proposed models have\nbeen trained on the combination of real-world leader vehicle (LV) trajectories\nand simulated trajectories generated using the Ornstein-Uhlenbeck (OU) process.\nThe overall performance of the proposed models has been tested using Cumulative\nDistribution Function (CDF) plots and compared with the real-world trajectory\ndata. The results show that the RL models successfully maintain lower distance\nheadway (i.e., higher efficiency) and jerk compared to human-driven vehicles\nwithout compromising safety. Further, to assess the robustness of the proposed\nmodels, we evaluated the model performance on diverse safety-critical\nscenarios, in terms of car-following and traffic signal compliance. Both DDPG\nand SAC models successfully handled the critical scenarios, while the DDPG\nmodel showed smoother action profiles compared to the SAC model. Overall, the\nresults confirm that DRL-based longitudinal vehicle control strategy at SI can\nhelp to improve traffic safety, efficiency, and comfort.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08896v1",
    "published_date": "2025-05-13 18:38:42 UTC",
    "updated_date": "2025-05-13 18:38:42 UTC"
  },
  {
    "arxiv_id": "2505.08894v1",
    "title": "WaLLM -- Insights from an LLM-Powered Chatbot deployment via WhatsApp",
    "authors": [
      "Hiba Eltigani",
      "Rukhshan Haroon",
      "Asli Kocak",
      "Abdullah Bin Faisal",
      "Noah Martin",
      "Fahad Dogar"
    ],
    "abstract": "Recent advances in generative AI, such as ChatGPT, have transformed access to\ninformation in education, knowledge-seeking, and everyday decision-making.\nHowever, in many developing regions, access remains a challenge due to the\npersistent digital divide. To help bridge this gap, we developed WaLLM - a\ncustom AI chatbot over WhatsApp, a widely used communication platform in\ndeveloping regions. Beyond answering queries, WaLLM offers several features to\nenhance user engagement: a daily top question, suggested follow-up questions,\ntrending and recent queries, and a leaderboard-based reward system. Our service\nhas been operational for over 6 months, amassing over 14.7K queries from\napproximately 100 users. In this paper, we present WaLLM's design and a\nsystematic analysis of logs to understand user interactions. Our results show\nthat 55% of user queries seek factual information. \"Health and well-being\" was\nthe most popular topic (28%), including queries about nutrition and disease,\nsuggesting users view WaLLM as a reliable source. Two-thirds of users' activity\noccurred within 24 hours of the daily top question. Users who accessed the\n\"Leaderboard\" interacted with WaLLM 3x as those who did not. We conclude by\ndiscussing implications for culture-based customization, user interface design,\nand appropriate calibration of users' trust in AI systems for developing\nregions.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08894v1",
    "published_date": "2025-05-13 18:36:18 UTC",
    "updated_date": "2025-05-13 18:36:18 UTC"
  },
  {
    "arxiv_id": "2505.08878v1",
    "title": "Optimized Couplings for Watermarking Large Language Models",
    "authors": [
      "Dor Tsur",
      "Carol Xuan Long",
      "Claudio Mayrink Verdun",
      "Hsiang Hsu",
      "Haim Permuter",
      "Flavio P. Calmon"
    ],
    "abstract": "Large-language models (LLMs) are now able to produce text that is, in many\ncases, seemingly indistinguishable from human-generated content. This has\nfueled the development of watermarks that imprint a ``signal'' in LLM-generated\ntext with minimal perturbation of an LLM's output. This paper provides an\nanalysis of text watermarking in a one-shot setting. Through the lens of\nhypothesis testing with side information, we formulate and analyze the\nfundamental trade-off between watermark detection power and distortion in\ngenerated textual quality. We argue that a key component in watermark design is\ngenerating a coupling between the side information shared with the watermark\ndetector and a random partition of the LLM vocabulary. Our analysis identifies\nthe optimal coupling and randomization strategy under the worst-case LLM\nnext-token distribution that satisfies a min-entropy constraint. We provide a\nclosed-form expression of the resulting detection rate under the proposed\nscheme and quantify the cost in a max-min sense. Finally, we provide an array\nof numerical results, comparing the proposed scheme with the theoretical\noptimum and existing schemes, in both synthetic data and LLM watermarking. Our\ncode is available at https://github.com/Carol-Long/CC_Watermark",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at ISIT25",
    "pdf_url": "http://arxiv.org/pdf/2505.08878v1",
    "published_date": "2025-05-13 18:08:12 UTC",
    "updated_date": "2025-05-13 18:08:12 UTC"
  },
  {
    "arxiv_id": "2505.08854v1",
    "title": "Generative AI for Autonomous Driving: Frontiers and Opportunities",
    "authors": [
      "Yuping Wang",
      "Shuo Xing",
      "Cui Can",
      "Renjie Li",
      "Hongyuan Hua",
      "Kexin Tian",
      "Zhaobin Mo",
      "Xiangbo Gao",
      "Keshu Wu",
      "Sulong Zhou",
      "Hengxu You",
      "Juntong Peng",
      "Junge Zhang",
      "Zehao Wang",
      "Rui Song",
      "Mingxuan Yan",
      "Walter Zimmer",
      "Xingcheng Zhou",
      "Peiran Li",
      "Zhaohan Lu",
      "Chia-Ju Chen",
      "Yue Huang",
      "Ryan A. Rossi",
      "Lichao Sun",
      "Hongkai Yu",
      "Zhiwen Fan",
      "Frank Hao Yang",
      "Yuhao Kang",
      "Ross Greer",
      "Chenxi Liu",
      "Eun Hak Lee",
      "Xuan Di",
      "Xinyue Ye",
      "Liu Ren",
      "Alois Knoll",
      "Xiaopeng Li",
      "Shuiwang Ji",
      "Masayoshi Tomizuka",
      "Marco Pavone",
      "Tianbao Yang",
      "Jing Du",
      "Ming-Hsuan Yang",
      "Hua Wei",
      "Ziran Wang",
      "Yang Zhou",
      "Jiachen Li",
      "Zhengzhong Tu"
    ],
    "abstract": "Generative Artificial Intelligence (GenAI) constitutes a transformative\ntechnological wave that reconfigures industries through its unparalleled\ncapabilities for content creation, reasoning, planning, and multimodal\nunderstanding. This revolutionary force offers the most promising path yet\ntoward solving one of engineering's grandest challenges: achieving reliable,\nfully autonomous driving, particularly the pursuit of Level 5 autonomy. This\nsurvey delivers a comprehensive and critical synthesis of the emerging role of\nGenAI across the autonomous driving stack. We begin by distilling the\nprinciples and trade-offs of modern generative modeling, encompassing VAEs,\nGANs, Diffusion Models, and Large Language Models (LLMs). We then map their\nfrontier applications in image, LiDAR, trajectory, occupancy, video generation\nas well as LLM-guided reasoning and decision making. We categorize practical\napplications, such as synthetic data workflows, end-to-end driving strategies,\nhigh-fidelity digital twin systems, smart transportation networks, and\ncross-domain transfer to embodied AI. We identify key obstacles and\npossibilities such as comprehensive generalization across rare cases,\nevaluation and safety checks, budget-limited implementation, regulatory\ncompliance, ethical concerns, and environmental effects, while proposing\nresearch plans across theoretical assurances, trust metrics, transport\nintegration, and socio-technical influence. By unifying these threads, the\nsurvey provides a forward-looking reference for researchers, engineers, and\npolicymakers navigating the convergence of generative AI and advanced\nautonomous mobility. An actively maintained repository of cited works is\navailable at https://github.com/taco-group/GenAI4AD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08854v1",
    "published_date": "2025-05-13 17:59:20 UTC",
    "updated_date": "2025-05-13 17:59:20 UTC"
  },
  {
    "arxiv_id": "2505.08783v1",
    "title": "CodePDE: An Inference Framework for LLM-driven PDE Solver Generation",
    "authors": [
      "Shanda Li",
      "Tanya Marwah",
      "Junhong Shen",
      "Weiwei Sun",
      "Andrej Risteski",
      "Yiming Yang",
      "Ameet Talwalkar"
    ],
    "abstract": "Partial differential equations (PDEs) are fundamental to modeling physical\nsystems, yet solving them remains a complex challenge. Traditional numerical\nsolvers rely on expert knowledge to implement and are computationally\nexpensive, while neural-network-based solvers require large training datasets\nand often lack interpretability. In this work, we frame PDE solving as a code\ngeneration task and introduce CodePDE, the first inference framework for\ngenerating PDE solvers using large language models (LLMs). Leveraging advanced\ninference-time algorithms and scaling strategies, CodePDE unlocks critical\ncapacities of LLM for PDE solving: reasoning, debugging, selfrefinement, and\ntest-time scaling -- all without task-specific tuning. CodePDE achieves\nsuperhuman performance across a range of representative PDE problems. We also\npresent a systematic empirical analysis of LLM generated solvers, analyzing\ntheir accuracy, efficiency, and numerical scheme choices. Our findings\nhighlight the promise and the current limitations of LLMs in PDE solving,\noffering a new perspective on solver design and opportunities for future model\ndevelopment. Our code is available at https://github.com/LithiumDA/CodePDE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08783v1",
    "published_date": "2025-05-13 17:58:08 UTC",
    "updated_date": "2025-05-13 17:58:08 UTC"
  },
  {
    "arxiv_id": "2505.08778v1",
    "title": "ARC-NCA: Towards Developmental Solutions to the Abstraction and Reasoning Corpus",
    "authors": [
      "Etienne Guichard",
      "Felix Reimers",
      "Mia Kvalsund",
      "Mikkel Lepperød",
      "Stefano Nichele"
    ],
    "abstract": "The Abstraction and Reasoning Corpus (ARC), later renamed ARC-AGI, poses a\nfundamental challenge in artificial general intelligence (AGI), requiring\nsolutions that exhibit robust abstraction and reasoning capabilities across\ndiverse tasks, while only few (with median count of three) correct examples are\npresented. While ARC-AGI remains very challenging for artificial intelligence\nsystems, it is rather easy for humans. This paper introduces ARC-NCA, a\ndevelopmental approach leveraging standard Neural Cellular Automata (NCA) and\nNCA enhanced with hidden memories (EngramNCA) to tackle the ARC-AGI benchmark.\nNCAs are employed for their inherent ability to simulate complex dynamics and\nemergent patterns, mimicking developmental processes observed in biological\nsystems. Developmental solutions may offer a promising avenue for enhancing\nAI's problem-solving capabilities beyond mere training data extrapolation.\nARC-NCA demonstrates how integrating developmental principles into\ncomputational models can foster adaptive reasoning and abstraction. We show\nthat our ARC-NCA proof-of-concept results may be comparable to, and sometimes\nsurpass, that of ChatGPT 4.5, at a fraction of the cost.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08778v1",
    "published_date": "2025-05-13 17:55:43 UTC",
    "updated_date": "2025-05-13 17:55:43 UTC"
  },
  {
    "arxiv_id": "2505.08765v2",
    "title": "Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology",
    "authors": [
      "Yatai Ji",
      "Zhengqiu Zhu",
      "Yong Zhao",
      "Beidan Liu",
      "Chen Gao",
      "Yihao Zhao",
      "Sihang Qiu",
      "Yue Hu",
      "Quanjun Yin",
      "Yong Li"
    ],
    "abstract": "Aerial Visual Object Search (AVOS) tasks in urban environments require\nUnmanned Aerial Vehicles (UAVs) to autonomously search for and identify target\nobjects using visual and textual cues without external guidance. Existing\napproaches struggle in complex urban environments due to redundant semantic\nprocessing, similar object distinction, and the exploration-exploitation\ndilemma. To bridge this gap and support the AVOS task, we introduce CityAVOS,\nthe first benchmark dataset for autonomous search of common urban objects. This\ndataset comprises 2,420 tasks across six object categories with varying\ndifficulty levels, enabling comprehensive evaluation of UAV agents' search\ncapabilities. To solve the AVOS tasks, we also propose PRPSearcher\n(Perception-Reasoning-Planning Searcher), a novel agentic method powered by\nmulti-modal large language models (MLLMs) that mimics human three-tier\ncognition. Specifically, PRPSearcher constructs three specialized maps: an\nobject-centric dynamic semantic map enhancing spatial perception, a 3D\ncognitive map based on semantic attraction values for target reasoning, and a\n3D uncertainty map for balanced exploration-exploitation search. Also, our\napproach incorporates a denoising mechanism to mitigate interference from\nsimilar objects and utilizes an Inspiration Promote Thought (IPT) prompting\nmechanism for adaptive action planning. Experimental results on CityAVOS\ndemonstrate that PRPSearcher surpasses existing baselines in both success rate\nand search efficiency (on average: +37.69% SR, +28.96% SPL, -30.69% MSS, and\n-46.40% NE). While promising, the performance gap compared to humans highlights\nthe need for better semantic reasoning and spatial exploration capabilities in\nAVOS tasks. This work establishes a foundation for future advances in embodied\ntarget search. Dataset and source code are available at\nhttps://anonymous.4open.science/r/CityAVOS-3DF8.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08765v2",
    "published_date": "2025-05-13 17:34:54 UTC",
    "updated_date": "2025-05-14 01:30:03 UTC"
  },
  {
    "arxiv_id": "2505.08747v1",
    "title": "Advancing Food Nutrition Estimation via Visual-Ingredient Feature Fusion",
    "authors": [
      "Huiyan Qi",
      "Bin Zhu",
      "Chong-Wah Ngo",
      "Jingjing Chen",
      "Ee-Peng Lim"
    ],
    "abstract": "Nutrition estimation is an important component of promoting healthy eating\nand mitigating diet-related health risks. Despite advances in tasks such as\nfood classification and ingredient recognition, progress in nutrition\nestimation is limited due to the lack of datasets with nutritional annotations.\nTo address this issue, we introduce FastFood, a dataset with 84,446 images\nacross 908 fast food categories, featuring ingredient and nutritional\nannotations. In addition, we propose a new model-agnostic Visual-Ingredient\nFeature Fusion (VIF$^2$) method to enhance nutrition estimation by integrating\nvisual and ingredient features. Ingredient robustness is improved through\nsynonym replacement and resampling strategies during training. The\ningredient-aware visual feature fusion module combines ingredient features and\nvisual representation to achieve accurate nutritional prediction. During\ntesting, ingredient predictions are refined using large multimodal models by\ndata augmentation and majority voting. Our experiments on both FastFood and\nNutrition5k datasets validate the effectiveness of our proposed method built in\ndifferent backbones (e.g., Resnet, InceptionV3 and ViT), which demonstrates the\nimportance of ingredient information in nutrition estimation.\nhttps://huiyanqi.github.io/fastfood-nutrition-estimation/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication in ACM International Conference on\n  Multimedia Retrieval 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08747v1",
    "published_date": "2025-05-13 17:01:21 UTC",
    "updated_date": "2025-05-13 17:01:21 UTC"
  },
  {
    "arxiv_id": "2505.08744v1",
    "title": "DeepMath-Creative: A Benchmark for Evaluating Mathematical Creativity of Large Language Models",
    "authors": [
      "Xiaoyang Chen",
      "Xinan Dai",
      "Yu Du",
      "Qian Feng",
      "Naixu Guo",
      "Tingshuo Gu",
      "Yuting Gao",
      "Yingyi Gao",
      "Xudong Han",
      "Xiang Jiang",
      "Yilin Jin",
      "Hongyi Lin",
      "Shisheng Lin",
      "Xiangnan Li",
      "Yuante Li",
      "Yixing Li",
      "Zhentao Lai",
      "Zilu Ma",
      "Yingrong Peng",
      "Jiacheng Qian",
      "Hao-Yu Sun",
      "Jianbo Sun",
      "Zirui Wang",
      "Siwei Wu",
      "Zian Wang",
      "Bin Xu",
      "Jianghao Xu",
      "Yiyang Yu",
      "Zichuan Yang",
      "Hongji Zha",
      "Ruichong Zhang"
    ],
    "abstract": "To advance the mathematical proficiency of large language models (LLMs), the\nDeepMath team has launched an open-source initiative aimed at developing an\nopen mathematical LLM and systematically evaluating its mathematical\ncreativity. This paper represents the initial contribution of this initiative.\nWhile recent developments in mathematical LLMs have predominantly emphasized\nreasoning skills, as evidenced by benchmarks on elementary to\nundergraduate-level mathematical tasks, the creative capabilities of these\nmodels have received comparatively little attention, and evaluation datasets\nremain scarce. To address this gap, we propose an evaluation criteria for\nmathematical creativity and introduce DeepMath-Creative, a novel, high-quality\nbenchmark comprising constructive problems across algebra, geometry, analysis,\nand other domains. We conduct a systematic evaluation of mainstream LLMs'\ncreative problem-solving abilities using this dataset. Experimental results\nshow that even under lenient scoring criteria -- emphasizing core solution\ncomponents and disregarding minor inaccuracies, such as small logical gaps,\nincomplete justifications, or redundant explanations -- the best-performing\nmodel, O3 Mini, achieves merely 70% accuracy, primarily on basic\nundergraduate-level constructive tasks. Performance declines sharply on more\ncomplex problems, with models failing to provide substantive strategies for\nopen problems. These findings suggest that, although current LLMs display a\ndegree of constructive proficiency on familiar and lower-difficulty problems,\nsuch performance is likely attributable to the recombination of memorized\npatterns rather than authentic creative insight or novel synthesis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.08744v1",
    "published_date": "2025-05-13 16:58:05 UTC",
    "updated_date": "2025-05-13 16:58:05 UTC"
  },
  {
    "arxiv_id": "2505.08728v1",
    "title": "Securing RAG: A Risk Assessment and Mitigation Framework",
    "authors": [
      "Lukas Ammann",
      "Sara Ott",
      "Christoph R. Landolt",
      "Marco P. Lehmann"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has emerged as the de facto industry\nstandard for user-facing NLP applications, offering the ability to integrate\ndata without re-training or fine-tuning Large Language Models (LLMs). This\ncapability enhances the quality and accuracy of responses but also introduces\nnovel security and privacy challenges, particularly when sensitive data is\nintegrated. With the rapid adoption of RAG, securing data and services has\nbecome a critical priority. This paper first reviews the vulnerabilities of RAG\npipelines, and outlines the attack surface from data pre-processing and data\nstorage management to integration with LLMs. The identified risks are then\npaired with corresponding mitigations in a structured overview. In a second\nstep, the paper develops a framework that combines RAG-specific security\nconsiderations, with existing general security guidelines, industry standards,\nand best practices. The proposed framework aims to guide the implementation of\nrobust, compliant, secure, and trustworthy RAG systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages, 3 figures, Sara Ott and Lukas Ammann contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2505.08728v1",
    "published_date": "2025-05-13 16:39:00 UTC",
    "updated_date": "2025-05-13 16:39:00 UTC"
  },
  {
    "arxiv_id": "2505.08727v1",
    "title": "Memorization-Compression Cycles Improve Generalization",
    "authors": [
      "Fangyuan Yu"
    ],
    "abstract": "We prove theoretically that generalization improves not only through data\nscaling but also by compressing internal representations. To operationalize\nthis insight, we introduce the Information Bottleneck Language Modeling (IBLM)\nobjective, which reframes language modeling as a constrained optimization\nproblem: minimizing representation entropy subject to optimal prediction\nperformance. Empirically, we observe an emergent memorization-compression cycle\nduring LLM pretraining, evidenced by oscillation positive/negative gradient\nalignment between cross-entropy and Matrix-Based Entropy (MBE), a measure of\nrepresentation entropy. This pattern closely mirrors the predictive-compressive\ntrade-off prescribed by IBLM and also parallels the biological alternation\nbetween awake learning and sleep consolidation. Motivated by this observation,\nwe propose Gated Phase Transition (GAPT), a training algorithm that adaptively\nswitches between memorization and compression phases. When applied to GPT-2\npretraining on FineWeb dataset, GAPT reduces MBE by 50% and improves\ncross-entropy by 4.8%. GAPT improves OOD generalizatino by 35% in a pretraining\ntask on arithmetic multiplication. In a setting designed to simulate\ncatastrophic forgetting, GAPT reduces interference by compressing and\nseparating representations, achieving a 97% improvement in separation -\nparalleling the functional role of sleep consolidation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.08727v1",
    "published_date": "2025-05-13 16:37:54 UTC",
    "updated_date": "2025-05-13 16:37:54 UTC"
  },
  {
    "arxiv_id": "2505.08719v1",
    "title": "PWC-MoE: Privacy-Aware Wireless Collaborative Mixture of Experts",
    "authors": [
      "Yang Su",
      "Na Yan",
      "Yansha Deng",
      "Robert Schober"
    ],
    "abstract": "Large language models (LLMs) hosted on cloud servers alleviate the\ncomputational and storage burdens on local devices but raise privacy concerns\ndue to sensitive data transmission and require substantial communication\nbandwidth, which is challenging in constrained environments. In contrast, small\nlanguage models (SLMs) running locally enhance privacy but suffer from limited\nperformance on complex tasks. To balance computational cost, performance, and\nprivacy protection under bandwidth constraints, we propose a privacy-aware\nwireless collaborative mixture of experts (PWC-MoE) framework. Specifically,\nPWC-MoE employs a sparse privacy-aware gating network to dynamically route\nsensitive tokens to privacy experts located on local clients, while\nnon-sensitive tokens are routed to non-privacy experts located at the remote\nbase station. To achieve computational efficiency, the gating network ensures\nthat each token is dynamically routed to and processed by only one expert. To\nenhance scalability and prevent overloading of specific experts, we introduce a\ngroup-wise load-balancing mechanism for the gating network that evenly\ndistributes sensitive tokens among privacy experts and non-sensitive tokens\namong non-privacy experts. To adapt to bandwidth constraints while preserving\nmodel performance, we propose a bandwidth-adaptive and importance-aware token\noffloading scheme. This scheme incorporates an importance predictor to evaluate\nthe importance scores of non-sensitive tokens, prioritizing the most important\ntokens for transmission to the base station based on their predicted importance\nand the available bandwidth. Experiments demonstrate that the PWC-MoE framework\neffectively preserves privacy and maintains high performance even in\nbandwidth-constrained environments, offering a practical solution for deploying\nLLMs in privacy-sensitive and bandwidth-limited scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08719v1",
    "published_date": "2025-05-13 16:27:07 UTC",
    "updated_date": "2025-05-13 16:27:07 UTC"
  },
  {
    "arxiv_id": "2505.08849v1",
    "title": "Improved Algorithms for Differentially Private Language Model Alignment",
    "authors": [
      "Keyu Chen",
      "Hao Tang",
      "Qinglin Liu",
      "Yizhao Xu"
    ],
    "abstract": "Language model alignment is crucial for ensuring that large language models\n(LLMs) align with human preferences, yet it often involves sensitive user data,\nraising significant privacy concerns. While prior work has integrated\ndifferential privacy (DP) with alignment techniques, their performance remains\nlimited. In this paper, we propose novel algorithms for privacy-preserving\nalignment and rigorously analyze their effectiveness across varying privacy\nbudgets and models. Our framework can be deployed on two celebrated alignment\ntechniques, namely direct preference optimization (DPO) and reinforcement\nlearning from human feedback (RLHF). Through systematic experiments on\nlarge-scale language models, we demonstrate that our approach achieves\nstate-of-the-art performance. Notably, one of our algorithms, DP-AdamW,\ncombined with DPO, surpasses existing methods, improving alignment quality by\nup to 15% under moderate privacy budgets ({\\epsilon}=2-5). We further\ninvestigate the interplay between privacy guarantees, alignment efficacy, and\ncomputational demands, providing practical guidelines for optimizing these\ntrade-offs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08849v1",
    "published_date": "2025-05-13 16:18:59 UTC",
    "updated_date": "2025-05-13 16:18:59 UTC"
  },
  {
    "arxiv_id": "2505.08706v1",
    "title": "Big Data and the Computational Social Science of Entrepreneurship and Innovation",
    "authors": [
      "Ningzi Li",
      "Shiyang Lai",
      "James Evans"
    ],
    "abstract": "As large-scale social data explode and machine-learning methods evolve,\nscholars of entrepreneurship and innovation face new research opportunities but\nalso unique challenges. This chapter discusses the difficulties of leveraging\nlarge-scale data to identify technological and commercial novelty, document new\nventure origins, and forecast competition between new technologies and\ncommercial forms. It suggests how scholars can take advantage of new text,\nnetwork, image, audio, and video data in two distinct ways that advance\ninnovation and entrepreneurship research. First, machine-learning models,\ncombined with large-scale data, enable the construction of precision\nmeasurements that function as system-level observatories of innovation and\nentrepreneurship across human societies. Second, new artificial intelligence\nmodels fueled by big data generate 'digital doubles' of technology and\nbusiness, forming laboratories for virtual experimentation about innovation and\nentrepreneurship processes and policies. The chapter argues for the advancement\nof theory development and testing in entrepreneurship and innovation by\ncoupling big data with big models.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CY",
      "cs.SI",
      "q-fin.EC",
      "stat.AP"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08706v1",
    "published_date": "2025-05-13 16:13:18 UTC",
    "updated_date": "2025-05-13 16:13:18 UTC"
  },
  {
    "arxiv_id": "2505.08705v1",
    "title": "Controllable Image Colorization with Instance-aware Texts and Masks",
    "authors": [
      "Yanru An",
      "Ling Gui",
      "Qiang Hu",
      "Chunlei Cai",
      "Tianxiao Ye",
      "Xiaoyun Zhang",
      "Yanfeng Wang"
    ],
    "abstract": "Recently, the application of deep learning in image colorization has received\nwidespread attention. The maturation of diffusion models has further advanced\nthe development of image colorization models. However, current mainstream image\ncolorization models still face issues such as color bleeding and color binding\nerrors, and cannot colorize images at the instance level. In this paper, we\npropose a diffusion-based colorization method MT-Color to achieve precise\ninstance-aware colorization with use-provided guidance. To tackle color\nbleeding issue, we design a pixel-level mask attention mechanism that\nintegrates latent features and conditional gray image features through\ncross-attention. We use segmentation masks to construct cross-attention masks,\npreventing pixel information from exchanging between different instances. We\nalso introduce an instance mask and text guidance module that extracts instance\nmasks and text representations of each instance, which are then fused with\nlatent features through self-attention, utilizing instance masks to form\nself-attention masks to prevent instance texts from guiding the colorization of\nother areas, thus mitigating color binding errors. Furthermore, we apply a\nmulti-instance sampling strategy, which involves sampling each instance region\nseparately and then fusing the results. Additionally, we have created a\nspecialized dataset for instance-level colorization tasks, GPT-color, by\nleveraging large visual language models on existing image datasets. Qualitative\nand quantitative experiments show that our model and dataset outperform\nprevious methods and datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08705v1",
    "published_date": "2025-05-13 16:13:06 UTC",
    "updated_date": "2025-05-13 16:13:06 UTC"
  },
  {
    "arxiv_id": "2505.08704v1",
    "title": "LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs",
    "authors": [
      "K M Sajjadul Islam",
      "Ayesha Siddika Nipu",
      "Jiawei Wu",
      "Praveen Madiraju"
    ],
    "abstract": "Electronic Health Records (EHRs) are digital records of patient information,\noften containing unstructured clinical text. Named Entity Recognition (NER) is\nessential in EHRs for extracting key medical entities like problems, tests, and\ntreatments to support downstream clinical applications. This paper explores\nprompt-based medical entity recognition using large language models (LLMs),\nspecifically GPT-4o and DeepSeek-R1, guided by various prompt engineering\ntechniques, including zero-shot, few-shot, and an ensemble approach. Among all\nstrategies, GPT-4o with prompt ensemble achieved the highest classification\nperformance with an F1-score of 0.95 and recall of 0.98, outperforming\nDeepSeek-R1 on the task. The ensemble method improved reliability by\naggregating outputs through embedding-based similarity and majority voting.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "IEEE 26th International Conference on Information Reuse and\n  Integration for Data Science (IRI 2025), San Jose, CA, USA",
    "pdf_url": "http://arxiv.org/pdf/2505.08704v1",
    "published_date": "2025-05-13 16:11:29 UTC",
    "updated_date": "2025-05-13 16:11:29 UTC"
  },
  {
    "arxiv_id": "2505.08694v1",
    "title": "A Survey of Deep Learning for Complex Speech Spectrograms",
    "authors": [
      "Yuying Xie",
      "Zheng-Hua Tan"
    ],
    "abstract": "Recent advancements in deep learning have significantly impacted the field of\nspeech signal processing, particularly in the analysis and manipulation of\ncomplex spectrograms. This survey provides a comprehensive overview of the\nstate-of-the-art techniques leveraging deep neural networks for processing\ncomplex spectrograms, which encapsulate both magnitude and phase information.\nWe begin by introducing complex spectrograms and their associated features for\nvarious speech processing tasks. Next, we explore the key components and\narchitectures of complex-valued neural networks, which are specifically\ndesigned to handle complex-valued data and have been applied for complex\nspectrogram processing. We then discuss various training strategies and loss\nfunctions tailored for training neural networks to process and model complex\nspectrograms. The survey further examines key applications, including phase\nretrieval, speech enhancement, and speech separation, where deep learning has\nachieved significant progress by leveraging complex spectrograms or their\nderived feature representations. Additionally, we examine the intersection of\ncomplex spectrograms with generative models. This survey aims to serve as a\nvaluable resource for researchers and practitioners in the field of speech\nsignal processing and complex-valued neural networks.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08694v1",
    "published_date": "2025-05-13 15:53:01 UTC",
    "updated_date": "2025-05-13 15:53:01 UTC"
  },
  {
    "arxiv_id": "2505.08691v1",
    "title": "VizCV: AI-assisted visualization of researchers' publications tracks",
    "authors": [
      "Vladimír Lazárik",
      "Marco Agus",
      "Barbora Kozlíková",
      "Pere-Pau Vázquez"
    ],
    "abstract": "Analyzing how the publication records of scientists and research groups have\nevolved over the years is crucial for assessing their expertise since it can\nsupport the management of academic environments by assisting with career\nplanning and evaluation. We introduce VizCV, a novel web-based end-to-end\nvisual analytics framework that enables the interactive exploration of\nresearchers' scientific trajectories. It incorporates AI-assisted analysis and\nsupports automated reporting of career evolution. Our system aims to model\ncareer progression through three key dimensions: a) research topic evolution to\ndetect and visualize shifts in scholarly focus over time, b) publication record\nand the corresponding impact, c) collaboration dynamics depicting the growth\nand transformation of a researcher's co-authorship network. AI-driven insights\nprovide automated explanations of career transitions, detecting significant\nshifts in research direction, impact surges, or collaboration expansions. The\nsystem also supports comparative analysis between researchers, allowing users\nto compare topic trajectories and impact growth. Our interactive, multi-tab and\nmultiview system allows for the exploratory analysis of career milestones under\ndifferent perspectives, such as the most impactful articles, emerging research\nthemes, or obtaining a detailed analysis of the contribution of the researcher\nin a subfield. The key contributions include AI/ML techniques for: a) topic\nanalysis, b) dimensionality reduction for visualizing patterns and trends, c)\nthe interactive creation of textual descriptions of facets of data through\nconfigurable prompt generation and large language models, that include key\nindicators, to help understanding the career development of individuals or\ngroups.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, 9 figures. Subtmitted",
    "pdf_url": "http://arxiv.org/pdf/2505.08691v1",
    "published_date": "2025-05-13 15:47:59 UTC",
    "updated_date": "2025-05-13 15:47:59 UTC"
  },
  {
    "arxiv_id": "2505.08687v1",
    "title": "AC-PKAN: Attention-Enhanced and Chebyshev Polynomial-Based Physics-Informed Kolmogorov-Arnold Networks",
    "authors": [
      "Hangwei Zhang",
      "Zhimu Huang",
      "Yan Wang"
    ],
    "abstract": "Kolmogorov-Arnold Networks (KANs) have recently shown promise for solving\npartial differential equations (PDEs). Yet their original formulation is\ncomputationally and memory intensive, motivating the introduction of Chebyshev\nType-I-based KANs (Chebyshev1KANs). Although Chebyshev1KANs have outperformed\nthe vanilla KANs architecture, our rigorous theoretical analysis reveals that\nthey still suffer from rank collapse, ultimately limiting their expressive\ncapacity. To overcome these limitations, we enhance Chebyshev1KANs by\nintegrating wavelet-activated MLPs with learnable parameters and an internal\nattention mechanism. We prove that this design preserves a full-rank Jacobian\nand is capable of approximating solutions to PDEs of arbitrary order.\nFurthermore, to alleviate the loss instability and imbalance introduced by the\nChebyshev polynomial basis, we externally incorporate a Residual Gradient\nAttention (RGA) mechanism that dynamically re-weights individual loss terms\naccording to their gradient norms and residual magnitudes. By jointly\nleveraging internal and external attention, we present AC-PKAN, a novel\narchitecture that constitutes an enhancement to weakly supervised\nPhysics-Informed Neural Networks (PINNs) and extends the expressive power of\nKANs. Experimental results from nine benchmark tasks across three domains show\nthat AC-PKAN consistently outperforms or matches state-of-the-art models such\nas PINNsFormer, establishing it as a highly effective tool for solving complex\nreal-world engineering problems in zero-data or data-sparse regimes. The code\nwill be made publicly available upon acceptance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08687v1",
    "published_date": "2025-05-13 15:46:10 UTC",
    "updated_date": "2025-05-13 15:46:10 UTC"
  },
  {
    "arxiv_id": "2505.08681v1",
    "title": "A Mamba-based Network for Semi-supervised Singing Melody Extraction Using Confidence Binary Regularization",
    "authors": [
      "Xiaoliang He",
      "Kangjie Dong",
      "Jingkai Cao",
      "Shuai Yu",
      "Wei Li",
      "Yi Yu"
    ],
    "abstract": "Singing melody extraction (SME) is a key task in the field of music\ninformation retrieval. However, existing methods are facing several\nlimitations: firstly, prior models use transformers to capture the contextual\ndependencies, which requires quadratic computation resulting in low efficiency\nin the inference stage. Secondly, prior works typically rely on\nfrequencysupervised methods to estimate the fundamental frequency (f0), which\nignores that the musical performance is actually based on notes. Thirdly,\ntransformers typically require large amounts of labeled data to achieve optimal\nperformances, but the SME task lacks of sufficient annotated data. To address\nthese issues, in this paper, we propose a mamba-based network, called\nSpectMamba, for semi-supervised singing melody extraction using confidence\nbinary regularization. In particular, we begin by introducing vision mamba to\nachieve computational linear complexity. Then, we propose a novel note-f0\ndecoder that allows the model to better mimic the musical performance. Further,\nto alleviate the scarcity of the labeled data, we introduce a confidence binary\nregularization (CBR) module to leverage the unlabeled data by maximizing the\nprobability of the correct classes. The proposed method is evaluated on several\npublic datasets and the conducted experiments demonstrate the effectiveness of\nour proposed method.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08681v1",
    "published_date": "2025-05-13 15:43:35 UTC",
    "updated_date": "2025-05-13 15:43:35 UTC"
  },
  {
    "arxiv_id": "2505.08673v1",
    "title": "A Study of Data-driven Methods for Inventory Optimization",
    "authors": [
      "Lee Yeung Ping",
      "Patrick Wong",
      "Tan Cheng Han"
    ],
    "abstract": "This paper shows a comprehensive analysis of three algorithms (Time Series,\nRandom Forest (RF) and Deep Reinforcement Learning) into three inventory models\n(the Lost Sales, Dual-Sourcing and Multi-Echelon Inventory Model). These\nmethodologies are applied in the supermarket context. The main purpose is to\nanalyse efficient methods for the data-driven. Their possibility, potential and\ncurrent challenges are taken into consideration in this report. By comparing\nthe results in each model, the effectiveness of each algorithm is evaluated\nbased on several key performance indicators, including forecast accuracy,\nadaptability to market changes, and overall impact on inventory costs and\ncustomer satisfaction levels. The data visualization tools and statistical\nmetrics are the indicators for the comparisons and show some obvious trends and\npatterns that can guide decision-making in inventory management. These tools\nenable managers to not only track the performance of different algorithms in\nreal-time but also to drill down into specific data points to understand the\nunderlying causes of inventory fluctuations. This level of detail is crucial\nfor pinpointing inefficiencies and areas for improvement within the supply\nchain.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08673v1",
    "published_date": "2025-05-13 15:35:23 UTC",
    "updated_date": "2025-05-13 15:35:23 UTC"
  },
  {
    "arxiv_id": "2505.08847v1",
    "title": "On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction",
    "authors": [
      "Fatima Ezzeddine",
      "Rinad Akel",
      "Ihab Sbeity",
      "Silvia Giordano",
      "Marc Langheinrich",
      "Omran Ayoub"
    ],
    "abstract": "Machine Learning as a Service (MLaaS) has gained important attraction as a\nmeans for deploying powerful predictive models, offering ease of use that\nenables organizations to leverage advanced analytics without substantial\ninvestments in specialized infrastructure or expertise. However, MLaaS\nplatforms must be safeguarded against security and privacy attacks, such as\nmodel extraction (MEA) attacks. The increasing integration of explainable AI\n(XAI) within MLaaS has introduced an additional privacy challenge, as attackers\ncan exploit model explanations particularly counterfactual explanations (CFs)\nto facilitate MEA. In this paper, we investigate the trade offs among model\nperformance, privacy, and explainability when employing Differential Privacy\n(DP), a promising technique for mitigating CF facilitated MEA. We evaluate two\ndistinct DP strategies: implemented during the classification model training\nand at the explainer during CF generation.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08847v1",
    "published_date": "2025-05-13 15:27:06 UTC",
    "updated_date": "2025-05-13 15:27:06 UTC"
  },
  {
    "arxiv_id": "2505.08664v1",
    "title": "A Social Robot with Inner Speech for Dietary Guidance",
    "authors": [
      "Valerio Belcamino",
      "Alessandro Carfì",
      "Valeria Seidita",
      "Fulvio Mastrogiovanni",
      "Antonio Chella"
    ],
    "abstract": "We explore the use of inner speech as a mechanism to enhance transparency and\ntrust in social robots for dietary advice. In humans, inner speech structures\nthought processes and decision-making; in robotics, it improves explainability\nby making reasoning explicit. This is crucial in healthcare scenarios, where\ntrust in robotic assistants depends on both accurate recommendations and\nhuman-like dialogue, which make interactions more natural and engaging.\nBuilding on this, we developed a social robot that provides dietary advice, and\nwe provided the architecture with inner speech capabilities to validate user\ninput, refine reasoning, and generate clear justifications. The system\nintegrates large language models for natural language understanding and a\nknowledge graph for structured dietary information. By making decisions more\ntransparent, our approach strengthens trust and improves human-robot\ninteraction in healthcare. We validated this by measuring the computational\nefficiency of our architecture and conducting a small user study, which\nassessed the reliability of inner speech in explaining the robot's behavior.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08664v1",
    "published_date": "2025-05-13 15:26:52 UTC",
    "updated_date": "2025-05-13 15:26:52 UTC"
  },
  {
    "arxiv_id": "2505.08657v1",
    "title": "A Comparative Study of Human Activity Recognition: Motion, Tactile, and multi-modal Approaches",
    "authors": [
      "Valerio Belcamino",
      "Nhat Minh Dinh Le",
      "Quan Khanh Luu",
      "Alessandro Carfì",
      "Van Anh Ho",
      "Fulvio Mastrogiovanni"
    ],
    "abstract": "Human activity recognition (HAR) is essential for effective Human-Robot\nCollaboration (HRC), enabling robots to interpret and respond to human actions.\nThis study evaluates the ability of a vision-based tactile sensor to classify\n15 activities, comparing its performance to an IMU-based data glove.\nAdditionally, we propose a multi-modal framework combining tactile and motion\ndata to leverage their complementary strengths. We examined three approaches:\nmotion-based classification (MBC) using IMU data, tactile-based classification\n(TBC) with single or dual video streams, and multi-modal classification (MMC)\nintegrating both. Offline validation on segmented datasets assessed each\nconfiguration's accuracy under controlled conditions, while online validation\non continuous action sequences tested online performance. Results showed the\nmulti-modal approach consistently outperformed single-modality methods,\nhighlighting the potential of integrating tactile and motion sensing to enhance\nHAR systems for collaborative robotics.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08657v1",
    "published_date": "2025-05-13 15:20:21 UTC",
    "updated_date": "2025-05-13 15:20:21 UTC"
  },
  {
    "arxiv_id": "2505.08643v1",
    "title": "WixQA: A Multi-Dataset Benchmark for Enterprise Retrieval-Augmented Generation",
    "authors": [
      "Dvir Cohen",
      "Lin Burg",
      "Sviatoslav Pykhnivskyi",
      "Hagit Gur",
      "Stanislav Kovynov",
      "Olga Atzmon",
      "Gilad Barkan"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) is a cornerstone of modern question\nanswering (QA) systems, enabling grounded answers based on external knowledge.\nAlthough recent progress has been driven by open-domain datasets, enterprise QA\nsystems need datasets that mirror the concrete, domain-specific issues users\nraise in day-to-day support scenarios. Critically, evaluating end-to-end RAG\nsystems requires benchmarks comprising not only question--answer pairs but also\nthe specific knowledge base (KB) snapshot from which answers were derived. To\naddress this need, we introduce WixQA, a benchmark suite featuring QA datasets\nprecisely grounded in the released KB corpus, enabling holistic evaluation of\nretrieval and generation components. WixQA includes three distinct QA datasets\nderived from Wix.com customer support interactions and grounded in a snapshot\nof the public Wix Help Center KB: (i) WixQA-ExpertWritten, 200 real user\nqueries with expert-authored, multi-step answers; (ii) WixQA-Simulated, 200\nexpert-validated QA pairs distilled from user dialogues; and (iii)\nWixQA-Synthetic, 6,222 LLM-generated QA pairs, with one pair systematically\nderived from each article in the knowledge base. We release the KB snapshot\nalongside the datasets under MIT license and provide comprehensive baseline\nresults, forming a unique benchmark for evaluating enterprise RAG systems in\nrealistic enterprise environments.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08643v1",
    "published_date": "2025-05-13 15:02:54 UTC",
    "updated_date": "2025-05-13 15:02:54 UTC"
  },
  {
    "arxiv_id": "2505.08846v1",
    "title": "Evaluating Simplification Algorithms for Interpretability of Time Series Classification",
    "authors": [
      "Felix Marti-Perez",
      "Brigt Håvardstun",
      "Cèsar Ferri",
      "Carlos Monserrat",
      "Jan Arne Telle"
    ],
    "abstract": "In this work, we introduce metrics to evaluate the use of simplified time\nseries in the context of interpretability of a TSC - a Time Series Classifier.\nSuch simplifications are important because time series data, in contrast to\ntext and image data, are not intuitively understandable to humans. These\nmetrics are related to the complexity of the simplifications - how many\nsegments they contain - and to their loyalty - how likely they are to maintain\nthe classification of the original time series. We employ these metrics to\nevaluate four distinct simplification algorithms, across several TSC algorithms\nand across datasets of varying characteristics, from seasonal or stationary to\nshort or long. Our findings suggest that using simplifications for\ninterpretability of TSC is much better than using the original time series,\nparticularly when the time series are seasonal, non-stationary and/or with low\nentropy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08846v1",
    "published_date": "2025-05-13 15:00:56 UTC",
    "updated_date": "2025-05-13 15:00:56 UTC"
  },
  {
    "arxiv_id": "2505.08638v1",
    "title": "TRAIL: Trace Reasoning and Agentic Issue Localization",
    "authors": [
      "Darshan Deshpande",
      "Varun Gangal",
      "Hersh Mehta",
      "Jitin Krishnan",
      "Anand Kannappan",
      "Rebecca Qian"
    ],
    "abstract": "The increasing adoption of agentic workflows across diverse domains brings a\ncritical need to scalably and systematically evaluate the complex traces these\nsystems generate. Current evaluation methods depend on manual, domain-specific\nhuman analysis of lengthy workflow traces - an approach that does not scale\nwith the growing complexity and volume of agentic outputs. Error analysis in\nthese settings is further complicated by the interplay of external tool outputs\nand language model reasoning, making it more challenging than traditional\nsoftware debugging. In this work, we (1) articulate the need for robust and\ndynamic evaluation methods for agentic workflow traces, (2) introduce a formal\ntaxonomy of error types encountered in agentic systems, and (3) present a set\nof 148 large human-annotated traces (TRAIL) constructed using this taxonomy and\ngrounded in established agentic benchmarks. To ensure ecological validity, we\ncurate traces from both single and multi-agent systems, focusing on real-world\napplications such as software engineering and open-world information retrieval.\nOur evaluations reveal that modern long context LLMs perform poorly at trace\ndebugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our\ndataset and code are made publicly available to support and accelerate future\nresearch in scalable evaluation for agentic workflows.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Dataset link: https://huggingface.co/datasets/PatronusAI/TRAIL",
    "pdf_url": "http://arxiv.org/pdf/2505.08638v1",
    "published_date": "2025-05-13 14:55:31 UTC",
    "updated_date": "2025-05-13 14:55:31 UTC"
  },
  {
    "arxiv_id": "2505.08628v1",
    "title": "Integrating Natural Language Processing and Exercise Monitoring for Early Diagnosis of Metabolic Syndrome: A Deep Learning Approach",
    "authors": [
      "Yichen Zhao",
      "Yuhua Wang",
      "Xi Cheng",
      "Junhao Fang",
      "Yang Yang"
    ],
    "abstract": "Metabolic syndrome (MetS) is a medication condition characterized by\nabdominal obesity, insulin resistance, hypertension and hyperlipidemia. It\nincreases the risk of majority of chronic diseases, including type 2 diabetes\nmellitus, and affects about one quarter of the global population. Therefore,\nearly detection and timely intervention for MetS are crucial. Standard\ndiagnosis for MetS components requires blood tests conducted within medical\ninstitutions. However, it is frequently underestimated, leading to unmet need\nfor care for MetS population. This study aims to use the least physiological\ndata and free texts about exercises related activities, which are obtained\neasily in daily life, to diagnosis MetS. We collected the data from 40\nvolunteers in a nursing home and used data augmentation to reduce the\nimbalance. We propose a deep learning framework for classifying MetS that\nintegrates natural language processing (NLP) and exercise monitoring. The\nresults showed that the best model reported a high positive result (AUROC=0.806\nand REC=76.3%) through 3-fold cross-validation. Feature importance analysis\nrevealed that text and minimum heart rate on a daily basis contribute the most\nin the classification of MetS. This study demonstrates the potential\napplication of data that are easily measurable in daily life for the early\ndiagnosis of MetS, which could contribute to reducing the cost of screening and\nmanagement for MetS population.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08628v1",
    "published_date": "2025-05-13 14:48:36 UTC",
    "updated_date": "2025-05-13 14:48:36 UTC"
  },
  {
    "arxiv_id": "2505.08622v1",
    "title": "Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models",
    "authors": [
      "Donghoon Kim",
      "Minji Bae",
      "Kyuhong Shim",
      "Byonghyo Shim"
    ],
    "abstract": "Text-to-image generative models like DALL-E and Stable Diffusion have\nrevolutionized visual content creation across various applications, including\nadvertising, personalized media, and design prototyping. However, crafting\neffective textual prompts to guide these models remains challenging, often\nrequiring extensive trial and error. Existing prompt inversion approaches, such\nas soft and hard prompt techniques, are not so effective due to the limited\ninterpretability and incoherent prompt generation. To address these issues, we\npropose Visually Guided Decoding (VGD), a gradient-free approach that leverages\nlarge language models (LLMs) and CLIP-based guidance to generate coherent and\nsemantically aligned prompts. In essence, VGD utilizes the robust text\ngeneration capabilities of LLMs to produce human-readable prompts. Further, by\nemploying CLIP scores to ensure alignment with user-specified visual concepts,\nVGD enhances the interpretability, generalization, and flexibility of prompt\ngeneration without the need for additional training. Our experiments\ndemonstrate that VGD outperforms existing prompt inversion techniques in\ngenerating understandable and contextually relevant prompts, facilitating more\nintuitive and controllable interactions with text-to-image models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08622v1",
    "published_date": "2025-05-13 14:40:22 UTC",
    "updated_date": "2025-05-13 14:40:22 UTC"
  },
  {
    "arxiv_id": "2505.08620v1",
    "title": "Resource-Efficient Language Models: Quantization for Fast and Accessible Inference",
    "authors": [
      "Tollef Emil Jørgensen"
    ],
    "abstract": "Large language models have significantly advanced natural language\nprocessing, yet their heavy resource demands pose severe challenges regarding\nhardware accessibility and energy consumption. This paper presents a focused\nand high-level review of post-training quantization (PTQ) techniques designed\nto optimize the inference efficiency of LLMs by the end-user, including details\non various quantization schemes, granularities, and trade-offs. The aim is to\nprovide a balanced overview between the theory and applications of\npost-training quantization.",
    "categories": [
      "cs.AI",
      "68T07",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 9 figures, preprint",
    "pdf_url": "http://arxiv.org/pdf/2505.08620v1",
    "published_date": "2025-05-13 14:39:33 UTC",
    "updated_date": "2025-05-13 14:39:33 UTC"
  },
  {
    "arxiv_id": "2505.08845v1",
    "title": "Validation of Conformal Prediction in Cervical Atypia Classification",
    "authors": [
      "Misgina Tsighe Hagos",
      "Antti Suutala",
      "Dmitrii Bychkov",
      "Hakan Kücükel",
      "Joar von Bahr",
      "Milda Poceviciute",
      "Johan Lundin",
      "Nina Linder",
      "Claes Lundström"
    ],
    "abstract": "Deep learning based cervical cancer classification can potentially increase\naccess to screening in low-resource regions. However, deep learning models are\noften overconfident and do not reliably reflect diagnostic uncertainty.\nMoreover, they are typically optimized to generate maximum-likelihood\npredictions, which fail to convey uncertainty or ambiguity in their results.\nSuch challenges can be addressed using conformal prediction, a model-agnostic\nframework for generating prediction sets that contain likely classes for\ntrained deep-learning models. The size of these prediction sets indicates model\nuncertainty, contracting as model confidence increases. However, existing\nconformal prediction evaluation primarily focuses on whether the prediction set\nincludes or covers the true class, often overlooking the presence of extraneous\nclasses. We argue that prediction sets should be truthful and valuable to end\nusers, ensuring that the listed likely classes align with human expectations\nrather than being overly relaxed and including false positives or unlikely\nclasses. In this study, we comprehensively validate conformal prediction sets\nusing expert annotation sets collected from multiple annotators. We evaluate\nthree conformal prediction approaches applied to three deep-learning models\ntrained for cervical atypia classification. Our expert annotation-based\nanalysis reveals that conventional coverage-based evaluations overestimate\nperformance and that current conformal prediction methods often produce\nprediction sets that are not well aligned with human labels. Additionally, we\nexplore the capabilities of the conformal prediction methods in identifying\nambiguous and out-of-distribution data.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08845v1",
    "published_date": "2025-05-13 14:37:58 UTC",
    "updated_date": "2025-05-13 14:37:58 UTC"
  },
  {
    "arxiv_id": "2505.08844v1",
    "title": "CellTypeAgent: Trustworthy cell type annotation with Large Language Models",
    "authors": [
      "Jiawen Chen",
      "Jianghao Zhang",
      "Huaxiu Yao",
      "Yun Li"
    ],
    "abstract": "Cell type annotation is a critical yet laborious step in single-cell RNA\nsequencing analysis. We present a trustworthy large language model (LLM)-agent,\nCellTypeAgent, which integrates LLMs with verification from relevant databases.\nCellTypeAgent achieves higher accuracy than existing methods while mitigating\nhallucinations. We evaluated CellTypeAgent across nine real datasets involving\n303 cell types from 36 tissues. This combined approach holds promise for more\nefficient and reliable cell type annotation.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "68T20",
      "I.2.1"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08844v1",
    "published_date": "2025-05-13 14:34:11 UTC",
    "updated_date": "2025-05-13 14:34:11 UTC"
  },
  {
    "arxiv_id": "2505.08599v1",
    "title": "MINIMALIST: switched-capacitor circuits for efficient in-memory computation of gated recurrent units",
    "authors": [
      "Sebastian Billaudelle",
      "Laura Kriener",
      "Filippo Moro",
      "Tristan Torchet",
      "Melika Payvand"
    ],
    "abstract": "Recurrent neural networks (RNNs) have been a long-standing candidate for\nprocessing of temporal sequence data, especially in memory-constrained systems\nthat one may find in embedded edge computing environments. Recent advances in\ntraining paradigms have now inspired new generations of efficient RNNs. We\nintroduce a streamlined and hardware-compatible architecture based on minimal\ngated recurrent units (GRUs), and an accompanying efficient mixed-signal\nhardware implementation of the model. The proposed design leverages\nswitched-capacitor circuits not only for in-memory computation (IMC), but also\nfor the gated state updates. The mixed-signal cores rely solely on commodity\ncircuits consisting of metal capacitors, transmission gates, and a clocked\ncomparator, thus greatly facilitating scaling and transfer to other technology\nnodes.\n  We benchmark the performance of our architecture on time series data,\nintroducing all constraints required for a direct mapping to the hardware\nsystem. The direct compatibility is verified in mixed-signal simulations,\nreproducing data recorded from the software-only network model.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08599v1",
    "published_date": "2025-05-13 14:13:41 UTC",
    "updated_date": "2025-05-13 14:13:41 UTC"
  },
  {
    "arxiv_id": "2505.08589v1",
    "title": "MESSI: A Multi-Elevation Semantic Segmentation Image Dataset of an Urban Environment",
    "authors": [
      "Barak Pinkovich",
      "Boaz Matalon",
      "Ehud Rivlin",
      "Hector Rotstein"
    ],
    "abstract": "This paper presents a Multi-Elevation Semantic Segmentation Image (MESSI)\ndataset comprising 2525 images taken by a drone flying over dense urban\nenvironments. MESSI is unique in two main features. First, it contains images\nfrom various altitudes, allowing us to investigate the effect of depth on\nsemantic segmentation. Second, it includes images taken from several different\nurban regions (at different altitudes). This is important since the variety\ncovers the visual richness captured by a drone's 3D flight, performing\nhorizontal and vertical maneuvers. MESSI contains images annotated with\nlocation, orientation, and the camera's intrinsic parameters and can be used to\ntrain a deep neural network for semantic segmentation or other applications of\ninterest (e.g., localization, navigation, and tracking). This paper describes\nthe dataset and provides annotation details. It also explains how semantic\nsegmentation was performed using several neural network models and shows\nseveral relevant statistics. MESSI will be published in the public domain to\nserve as an evaluation benchmark for semantic segmentation using images\ncaptured by a drone or similar vehicle flying over a dense urban environment.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08589v1",
    "published_date": "2025-05-13 14:01:07 UTC",
    "updated_date": "2025-05-13 14:01:07 UTC"
  },
  {
    "arxiv_id": "2505.08588v1",
    "title": "Small but Significant: On the Promise of Small Language Models for Accessible AIED",
    "authors": [
      "Yumou Wei",
      "Paulo Carvalho",
      "John Stamper"
    ],
    "abstract": "GPT has become nearly synonymous with large language models (LLMs), an\nincreasingly popular term in AIED proceedings. A simple keyword-based search\nreveals that 61% of the 76 long and short papers presented at AIED 2024\ndescribe novel solutions using LLMs to address some of the long-standing\nchallenges in education, and 43% specifically mention GPT. Although LLMs\npioneered by GPT create exciting opportunities to strengthen the impact of AI\non education, we argue that the field's predominant focus on GPT and other\nresource-intensive LLMs (with more than 10B parameters) risks neglecting the\npotential impact that small language models (SLMs) can make in providing\nresource-constrained institutions with equitable and affordable access to\nhigh-quality AI tools. Supported by positive results on knowledge component\n(KC) discovery, a critical challenge in AIED, we demonstrate that SLMs such as\nPhi-2 can produce an effective solution without elaborate prompting strategies.\nHence, we call for more attention to developing SLM-based AIED approaches.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "This vision paper advocates using small language models (e.g., Phi-2)\n  in AI for education (AIED)",
    "pdf_url": "http://arxiv.org/pdf/2505.08588v1",
    "published_date": "2025-05-13 13:58:29 UTC",
    "updated_date": "2025-05-13 13:58:29 UTC"
  },
  {
    "arxiv_id": "2505.08552v1",
    "title": "DFA-CON: A Contrastive Learning Approach for Detecting Copyright Infringement in DeepFake Art",
    "authors": [
      "Haroon Wahab",
      "Hassan Ugail",
      "Irfan Mehmood"
    ],
    "abstract": "Recent proliferation of generative AI tools for visual content\ncreation-particularly in the context of visual artworks-has raised serious\nconcerns about copyright infringement and forgery. The large-scale datasets\nused to train these models often contain a mixture of copyrighted and\nnon-copyrighted artworks. Given the tendency of generative models to memorize\ntraining patterns, they are susceptible to varying degrees of copyright\nviolation. Building on the recently proposed DeepfakeArt Challenge benchmark,\nthis work introduces DFA-CON, a contrastive learning framework designed to\ndetect copyright-infringing or forged AI-generated art. DFA-CON learns a\ndiscriminative representation space, posing affinity among original artworks\nand their forged counterparts within a contrastive learning framework. The\nmodel is trained across multiple attack types, including inpainting, style\ntransfer, adversarial perturbation, and cutmix. Evaluation results demonstrate\nrobust detection performance across most attack types, outperforming recent\npretrained foundation models. Code and model checkpoints will be released\npublicly upon acceptance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08552v1",
    "published_date": "2025-05-13 13:23:52 UTC",
    "updated_date": "2025-05-13 13:23:52 UTC"
  },
  {
    "arxiv_id": "2505.08548v1",
    "title": "From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation",
    "authors": [
      "Yifu Yuan",
      "Haiqin Cui",
      "Yibin Chen",
      "Zibin Dong",
      "Fei Ni",
      "Longxin Kou",
      "Jinyi Liu",
      "Pengyi Li",
      "Yan Zheng",
      "Jianye Hao"
    ],
    "abstract": "Achieving generalization in robotic manipulation remains a critical\nchallenge, particularly for unseen scenarios and novel tasks. Current\nVision-Language-Action (VLA) models, while building on top of general\nVision-Language Models (VLMs), still fall short of achieving robust zero-shot\nperformance due to the scarcity and heterogeneity prevalent in embodied\ndatasets. To address these limitations, we propose FSD (From Seeing to Doing),\na novel vision-language model that generates intermediate representations\nthrough spatial relationship reasoning, providing fine-grained guidance for\nrobotic manipulation. Our approach combines a hierarchical data pipeline for\ntraining with a self-consistency mechanism that aligns spatial coordinates with\nvisual signals. Through extensive experiments, we comprehensively validated\nFSD's capabilities in both \"seeing\" and \"doing,\" achieving outstanding\nperformance across 8 benchmarks for general spatial reasoning and embodied\nreference abilities, as well as on our proposed more challenging benchmark\nVABench. We also verified zero-shot capabilities in robot manipulation,\ndemonstrating significant performance improvements over baseline methods in\nboth SimplerEnv and real robot settings. Experimental results show that FSD\nachieves 54.1% success rate in SimplerEnv and 72% success rate across 8\nreal-world tasks, outperforming the strongest baseline by 30%.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Early version",
    "pdf_url": "http://arxiv.org/pdf/2505.08548v1",
    "published_date": "2025-05-13 13:20:46 UTC",
    "updated_date": "2025-05-13 13:20:46 UTC"
  },
  {
    "arxiv_id": "2505.08542v1",
    "title": "Guiding LLM-based Smart Contract Generation with Finite State Machine",
    "authors": [
      "Hao Luo",
      "Yuhao Lin",
      "Xiao Yan",
      "Xintong Hu",
      "Yuxiang Wang",
      "Qiming Zeng",
      "Hao Wang",
      "Jiawei Jiang"
    ],
    "abstract": "Smart contract is a kind of self-executing code based on blockchain\ntechnology with a wide range of application scenarios, but the traditional\ngeneration method relies on manual coding and expert auditing, which has a high\nthreshold and low efficiency. Although Large Language Models (LLMs) show great\npotential in programming tasks, they still face challenges in smart contract\ngeneration w.r.t. effectiveness and security. To solve these problems, we\npropose FSM-SCG, a smart contract generation framework based on finite state\nmachine (FSM) and LLMs, which significantly improves the quality of the\ngenerated code by abstracting user requirements to generate FSM, guiding LLMs\nto generate smart contracts, and iteratively optimizing the code with the\nfeedback of compilation and security checks. The experimental results show that\nFSM-SCG significantly improves the quality of smart contract generation.\nCompared to the best baseline, FSM-SCG improves the compilation success rate of\ngenerated smart contract code by at most 48%, and reduces the average\nvulnerability risk score by approximately 68%.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08542v1",
    "published_date": "2025-05-13 13:13:26 UTC",
    "updated_date": "2025-05-13 13:13:26 UTC"
  },
  {
    "arxiv_id": "2505.08532v1",
    "title": "The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large Language Models Unmask Fake News",
    "authors": [
      "Yuhan Liu",
      "Yuxuan Liu",
      "Xiaoqing Zhang",
      "Xiuying Chen",
      "Rui Yan"
    ],
    "abstract": "In today's digital environment, the rapid propagation of fake news via social\nnetworks poses significant social challenges. Most existing detection methods\neither employ traditional classification models, which suffer from low\ninterpretability and limited generalization capabilities, or craft specific\nprompts for large language models (LLMs) to produce explanations and results\ndirectly, failing to leverage LLMs' reasoning abilities fully. Inspired by the\nsaying that \"truth becomes clearer through debate,\" our study introduces a\nnovel multi-agent system with LLMs named TruEDebate (TED) to enhance the\ninterpretability and effectiveness of fake news detection. TED employs a\nrigorous debate process inspired by formal debate settings. Central to our\napproach are two innovative components: the DebateFlow Agents and the\nInsightFlow Agents. The DebateFlow Agents organize agents into two teams, where\none supports and the other challenges the truth of the news. These agents\nengage in opening statements, cross-examination, rebuttal, and closing\nstatements, simulating a rigorous debate process akin to human discourse\nanalysis, allowing for a thorough evaluation of news content. Concurrently, the\nInsightFlow Agents consist of two specialized sub-agents: the Synthesis Agent\nand the Analysis Agent. The Synthesis Agent summarizes the debates and provides\nan overarching viewpoint, ensuring a coherent and comprehensive evaluation. The\nAnalysis Agent, which includes a role-aware encoder and a debate graph,\nintegrates role embeddings and models the interactions between debate roles and\narguments using an attention mechanism, providing the final judgment.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08532v1",
    "published_date": "2025-05-13 13:03:20 UTC",
    "updated_date": "2025-05-13 13:03:20 UTC"
  },
  {
    "arxiv_id": "2505.08529v1",
    "title": "ExEBench: Benchmarking Foundation Models on Extreme Earth Events",
    "authors": [
      "Shan Zhao",
      "Zhitong Xiong",
      "Jie Zhao",
      "Xiao Xiang Zhu"
    ],
    "abstract": "Our planet is facing increasingly frequent extreme events, which pose major\nrisks to human lives and ecosystems. Recent advances in machine learning (ML),\nespecially with foundation models (FMs) trained on extensive datasets, excel in\nextracting features and show promise in disaster management. Nevertheless,\nthese models often inherit biases from training data, challenging their\nperformance over extreme values. To explore the reliability of FM in the\ncontext of extreme events, we introduce \\textbf{ExE}Bench (\\textbf{Ex}treme\n\\textbf{E}arth Benchmark), a collection of seven extreme event categories\nacross floods, wildfires, storms, tropical cyclones, extreme precipitation,\nheatwaves, and cold waves. The dataset features global coverage, varying data\nvolumes, and diverse data sources with different spatial, temporal, and\nspectral characteristics. To broaden the real-world impact of FMs, we include\nmultiple challenging ML tasks that are closely aligned with operational needs\nin extreme events detection, monitoring, and forecasting. ExEBench aims to (1)\nassess FM generalizability across diverse, high-impact tasks and domains, (2)\npromote the development of novel ML methods that benefit disaster management,\nand (3) offer a platform for analyzing the interactions and cascading effects\nof extreme events to advance our understanding of Earth system, especially\nunder the climate change expected in the decades to come. The dataset and code\nare public https://github.com/zhaoshan2/EarthExtreme-Bench.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08529v1",
    "published_date": "2025-05-13 13:02:04 UTC",
    "updated_date": "2025-05-13 13:02:04 UTC"
  },
  {
    "arxiv_id": "2505.08528v1",
    "title": "GradMix: Gradient-based Selective Mixup for Robust Data Augmentation in Class-Incremental Learning",
    "authors": [
      "Minsu Kim",
      "Seong-Hyeon Hwang",
      "Steven Euijong Whang"
    ],
    "abstract": "In the context of continual learning, acquiring new knowledge while\nmaintaining previous knowledge presents a significant challenge. Existing\nmethods often use experience replay techniques that store a small portion of\nprevious task data for training. In experience replay approaches, data\naugmentation has emerged as a promising strategy to further improve the model\nperformance by mixing limited previous task data with sufficient current task\ndata. However, we theoretically and empirically analyze that training with\nmixed samples from random sample pairs may harm the knowledge of previous tasks\nand cause greater catastrophic forgetting. We then propose GradMix, a robust\ndata augmentation method specifically designed for mitigating catastrophic\nforgetting in class-incremental learning. GradMix performs gradient-based\nselective mixup using a class-based criterion that mixes only samples from\nhelpful class pairs and not from detrimental class pairs for reducing\ncatastrophic forgetting. Our experiments on various real datasets show that\nGradMix outperforms data augmentation baselines in accuracy by minimizing the\nforgetting of previous knowledge.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08528v1",
    "published_date": "2025-05-13 13:01:38 UTC",
    "updated_date": "2025-05-13 13:01:38 UTC"
  },
  {
    "arxiv_id": "2505.08522v1",
    "title": "On the Complexity and Properties of Preferential Propositional Dependence Logic",
    "authors": [
      "Kai Sauerwald",
      "Arne Meier",
      "Juha Kontinen"
    ],
    "abstract": "This paper considers the complexity and properties of KLM-style preferential\nreasoning in the setting of propositional logic with team semantics and\ndependence atoms, also known as propositional dependence logic. Preferential\nteam-based reasoning is shown to be cumulative, yet violates System~P. We give\nintuitive conditions that fully characterise those cases where preferential\npropositional dependence logic satisfies System~P. We show that these\ncharacterisations do, surprisingly, not carry over to preferential team-based\npropositional logic. Furthermore, we show how classical entailment and\ndependence logic entailment can be expressed in terms of non-trivial\npreferential models. Finally, we present the complexity of preferential\nteam-based reasoning for two natural representations. This includes novel\ncomplexity results for classical (non-team-based) preferential reasoning.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "03B70, 03B62",
      "I.2.3; F.4.1"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08522v1",
    "published_date": "2025-05-13 12:54:59 UTC",
    "updated_date": "2025-05-13 12:54:59 UTC"
  },
  {
    "arxiv_id": "2505.08516v1",
    "title": "Learning Advanced Self-Attention for Linear Transformers in the Singular Value Domain",
    "authors": [
      "Hyowon Wi",
      "Jeongwhan Choi",
      "Noseong Park"
    ],
    "abstract": "Transformers have demonstrated remarkable performance across diverse domains.\nThe key component of Transformers is self-attention, which learns the\nrelationship between any two tokens in the input sequence. Recent studies have\nrevealed that the self-attention can be understood as a normalized adjacency\nmatrix of a graph. Notably, from the perspective of graph signal processing\n(GSP), the self-attention can be equivalently defined as a simple graph filter,\napplying GSP using the value vector as the signal. However, the self-attention\nis a graph filter defined with only the first order of the polynomial matrix,\nand acts as a low-pass filter preventing the effective leverage of various\nfrequency information. Consequently, existing self-attention mechanisms are\ndesigned in a rather simplified manner. Therefore, we propose a novel method,\ncalled \\underline{\\textbf{A}}ttentive \\underline{\\textbf{G}}raph\n\\underline{\\textbf{F}}ilter (AGF), interpreting the self-attention as learning\nthe graph filter in the singular value domain from the perspective of graph\nsignal processing for directed graphs with the linear complexity w.r.t. the\ninput length $n$, i.e., $\\mathcal{O}(nd^2)$. In our experiments, we demonstrate\nthat AGF achieves state-of-the-art performance on various tasks, including Long\nRange Arena benchmark and time series classification.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IJCAI25 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2505.08516v1",
    "published_date": "2025-05-13 12:48:04 UTC",
    "updated_date": "2025-05-13 12:48:04 UTC"
  },
  {
    "arxiv_id": "2505.08508v1",
    "title": "TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System to Streamline Patient-to-Trial Matching",
    "authors": [
      "Majd Abdallah",
      "Sigve Nakken",
      "Mariska Bierkens",
      "Johanna Galvis",
      "Alexis Groppi",
      "Slim Karkar",
      "Lana Meiqari",
      "Maria Alexandra Rujano",
      "Steve Canham",
      "Rodrigo Dienstmann",
      "Remond Fijneman",
      "Eivind Hovig",
      "Gerrit Meijer",
      "Macha Nikolski"
    ],
    "abstract": "Patient recruitment remains a major bottleneck in clinical trials, calling\nfor scalable and automated solutions. We present TrialMatchAI, an AI-powered\nrecommendation system that automates patient-to-trial matching by processing\nheterogeneous clinical data, including structured records and unstructured\nphysician notes. Built on fine-tuned, open-source large language models (LLMs)\nwithin a retrieval-augmented generation framework, TrialMatchAI ensures\ntransparency and reproducibility and maintains a lightweight deployment\nfootprint suitable for clinical environments. The system normalizes biomedical\nentities, retrieves relevant trials using a hybrid search strategy combining\nlexical and semantic similarity, re-ranks results, and performs criterion-level\neligibility assessments using medical Chain-of-Thought reasoning. This pipeline\ndelivers explainable outputs with traceable decision rationales. In real-world\nvalidation, 92 percent of oncology patients had at least one relevant trial\nretrieved within the top 20 recommendations. Evaluation across synthetic and\nreal clinical datasets confirmed state-of-the-art performance, with expert\nassessment validating over 90 percent accuracy in criterion-level eligibility\nclassification, particularly excelling in biomarker-driven matches. Designed\nfor modularity and privacy, TrialMatchAI supports Phenopackets-standardized\ndata, enables secure local deployment, and allows seamless replacement of LLM\ncomponents as more advanced models emerge. By enhancing efficiency and\ninterpretability and offering lightweight, open-source deployment, TrialMatchAI\nprovides a scalable solution for AI-driven clinical trial matching in precision\nmedicine.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08508v1",
    "published_date": "2025-05-13 12:39:06 UTC",
    "updated_date": "2025-05-13 12:39:06 UTC"
  },
  {
    "arxiv_id": "2505.08498v1",
    "title": "LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using Large Language Models",
    "authors": [
      "Takumi Shibata",
      "Yuichi Miyamura"
    ],
    "abstract": "Recent advances in large language models (LLMs) have enabled zero-shot\nautomated essay scoring (AES), providing a promising way to reduce the cost and\neffort of essay scoring in comparison with manual grading. However, most\nexisting zero-shot approaches rely on LLMs to directly generate absolute\nscores, which often diverge from human evaluations owing to model biases and\ninconsistent scoring. To address these limitations, we propose LLM-based\nComparative Essay Scoring (LCES), a method that formulates AES as a pairwise\ncomparison task. Specifically, we instruct LLMs to judge which of two essays is\nbetter, collect many such comparisons, and convert them into continuous scores.\nConsidering that the number of possible comparisons grows quadratically with\nthe number of essays, we improve scalability by employing RankNet to\nefficiently transform LLM preferences into scalar scores. Experiments using AES\nbenchmark datasets show that LCES outperforms conventional zero-shot methods in\naccuracy while maintaining computational efficiency. Moreover, LCES is robust\nacross different LLM backbones, highlighting its applicability to real-world\nzero-shot AES.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.08498v1",
    "published_date": "2025-05-13 12:26:16 UTC",
    "updated_date": "2025-05-13 12:26:16 UTC"
  },
  {
    "arxiv_id": "2505.08492v1",
    "title": "Achieving Scalable Robot Autonomy via neurosymbolic planning using lightweight local LLM",
    "authors": [
      "Nicholas Attolino",
      "Alessio Capitanelli",
      "Fulvio Mastrogiovanni"
    ],
    "abstract": "PDDL-based symbolic task planning remains pivotal for robot autonomy yet\nstruggles with dynamic human-robot collaboration due to scalability,\nre-planning demands, and delayed plan availability. Although a few\nneurosymbolic frameworks have previously leveraged LLMs such as GPT-3 to\naddress these challenges, reliance on closed-source, remote models with limited\ncontext introduced critical constraints: third-party dependency, inconsistent\nresponse times, restricted plan length and complexity, and multi-domain\nscalability issues. We present Gideon, a novel framework that enables the\ntransition to modern, smaller, local LLMs with extended context length. Gideon\nintegrates a novel problem generator to systematically generate large-scale\ndatasets of realistic domain-problem-plan tuples for any domain, and adapts\nneurosymbolic planning for local LLMs, enabling on-device execution and\nextended context for multi-domain support. Preliminary experiments in\nsingle-domain scenarios performed on Qwen-2.5 1.5B and trained on 8k-32k\nsamples, demonstrate a valid plan percentage of 66.1% (32k model) and show that\nthe figure can be further scaled through additional data. Multi-domain tests on\n16k samples yield an even higher 70.6% planning validity rate, proving\nextensibility across domains and signaling that data variety can have a\npositive effect on learning efficiency. Although long-horizon planning and\nreduced model size make Gideon training much less efficient than baseline\nmodels based on larger LLMs, the results are still significant considering that\nthe trained model is about 120x smaller than baseline and that significant\nadvantages can be achieved in inference efficiency, scalability, and\nmulti-domain adaptability, all critical factors in human-robot collaboration.\nTraining inefficiency can be mitigated by Gideon's streamlined data generation\npipeline.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "I.2.6; I.2.8; I.2.9"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 3 figures, 4 tables, accepted at IAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08492v1",
    "published_date": "2025-05-13 12:22:38 UTC",
    "updated_date": "2025-05-13 12:22:38 UTC"
  },
  {
    "arxiv_id": "2505.08487v1",
    "title": "An adaptive sampling algorithm for data-generation to build a data-manifold for physical problem surrogate modeling",
    "authors": [
      "Chetra Mang",
      "Axel TahmasebiMoradi",
      "David Danan",
      "Mouadh Yagoubi"
    ],
    "abstract": "Physical models classically involved Partial Differential equations (PDE) and\ndepending of their underlying complexity and the level of accuracy required,\nand known to be computationally expensive to numerically solve them. Thus, an\nidea would be to create a surrogate model relying on data generated by such\nsolver. However, training such a model on an imbalanced data have been shown to\nbe a very difficult task. Indeed, if the distribution of input leads to a poor\nresponse manifold representation, the model may not learn well and\nconsequently, it may not predict the outcome with acceptable accuracy. In this\nwork, we present an Adaptive Sampling Algorithm for Data Generation (ASADG)\ninvolving a physical model. As the initial input data may not accurately\nrepresent the response manifold in higher dimension, this algorithm iteratively\nadds input data into it. At each step the barycenter of each simplicial\ncomplex, that the manifold is discretized into, is added as new input data, if\na certain threshold is satisfied. We demonstrate the efficiency of the data\nsampling algorithm in comparison with LHS method for generating more\nrepresentative input data. To do so, we focus on the construction of a harmonic\ntransport problem metamodel by generating data through a classical solver. By\nusing such algorithm, it is possible to generate the same number of input data\nas LHS while providing a better representation of the response manifold.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08487v1",
    "published_date": "2025-05-13 12:17:10 UTC",
    "updated_date": "2025-05-13 12:17:10 UTC"
  },
  {
    "arxiv_id": "2505.09651v1",
    "title": "Unlocking Location Intelligence: A Survey from Deep Learning to The LLM Era",
    "authors": [
      "Xixuan Hao",
      "Yutian Jiang",
      "Xingchen Zou",
      "Jiabo Liu",
      "Yifang Yin",
      "Yuxuan Liang"
    ],
    "abstract": "Location Intelligence (LI), the science of transforming location-centric\ngeospatial data into actionable knowledge, has become a cornerstone of modern\nspatial decision-making. The rapid evolution of Geospatial Representation\nLearning is fundamentally reshaping LI development through two successive\ntechnological revolutions: the deep learning breakthrough and the emerging\nlarge language model (LLM) paradigm. While deep neural networks (DNNs) have\ndemonstrated remarkable success in automated feature extraction from structured\ngeospatial data (e.g., satellite imagery, GPS trajectories), the recent\nintegration of LLMs introduces transformative capabilities for cross-modal\ngeospatial reasoning and unstructured geo-textual data processing. This survey\npresents a comprehensive review of geospatial representation learning across\nboth technological eras, organizing them into a structured taxonomy based on\nthe complete pipeline comprising: (1) data perspective, (2) methodological\nperspective and (3) application perspective. We also highlight current\nadvancements, discuss existing limitations, and propose potential future\nresearch directions in the LLM era. This work offers a thorough exploration of\nthe field and providing a roadmap for further innovation in LI. The summary of\nthe up-to-date paper list can be found in\nhttps://github.com/CityMind-Lab/Awesome-Location-Intelligence and will undergo\ncontinuous updates.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09651v1",
    "published_date": "2025-05-13 12:16:26 UTC",
    "updated_date": "2025-05-13 12:16:26 UTC"
  },
  {
    "arxiv_id": "2505.08485v1",
    "title": "BAT: Benchmark for Auto-bidding Task",
    "authors": [
      "Alexandra Khirianova",
      "Ekaterina Solodneva",
      "Andrey Pudovikov",
      "Sergey Osokin",
      "Egor Samosvat",
      "Yuriy Dorn",
      "Alexander Ledovsky",
      "Yana Zenkova"
    ],
    "abstract": "The optimization of bidding strategies for online advertising slot auctions\npresents a critical challenge across numerous digital marketplaces. A\nsignificant obstacle to the development, evaluation, and refinement of\nreal-time autobidding algorithms is the scarcity of comprehensive datasets and\nstandardized benchmarks.\n  To address this deficiency, we present an auction benchmark encompassing the\ntwo most prevalent auction formats. We implement a series of robust baselines\non a novel dataset, addressing the most salient Real-Time Bidding (RTB) problem\ndomains: budget pacing uniformity and Cost Per Click (CPC) constraint\noptimization. This benchmark provides a user-friendly and intuitive framework\nfor researchers and practitioners to develop and refine innovative autobidding\nalgorithms, thereby facilitating advancements in the field of programmatic\nadvertising. The implementation and additional resources can be accessed at the\nfollowing repository (https://github.com/avito-tech/bat-autobidding-benchmark,\nhttps://doi.org/10.5281/zenodo.14794182).",
    "categories": [
      "cs.AI",
      "stat.ML",
      "91B26"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 10 figures, WWW 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2505.08485v1",
    "published_date": "2025-05-13 12:12:34 UTC",
    "updated_date": "2025-05-13 12:12:34 UTC"
  },
  {
    "arxiv_id": "2505.08474v1",
    "title": "Distributed Quantum Neural Networks on Distributed Photonic Quantum Computing",
    "authors": [
      "Kuan-Cheng Chen",
      "Chen-Yu Liu",
      "Yu Shang",
      "Felix Burt",
      "Kin K. Leung"
    ],
    "abstract": "We introduce a distributed quantum-classical framework that synergizes\nphotonic quantum neural networks (QNNs) with matrix-product-state (MPS) mapping\nto achieve parameter-efficient training of classical neural networks. By\nleveraging universal linear-optical decompositions of $M$-mode interferometers\nand photon-counting measurement statistics, our architecture generates neural\nparameters through a hybrid quantum-classical workflow: photonic QNNs with\n$M(M+1)/2$ trainable parameters produce high-dimensional probability\ndistributions that are mapped to classical network weights via an MPS model\nwith bond dimension $\\chi$. Empirical validation on MNIST classification\ndemonstrates that photonic QT achieves an accuracy of $95.50\\% \\pm 0.84\\%$\nusing 3,292 parameters ($\\chi = 10$), compared to $96.89\\% \\pm 0.31\\%$ for\nclassical baselines with 6,690 parameters. Moreover, a ten-fold compression\nratio is achieved at $\\chi = 4$, with a relative accuracy loss of less than\n$3\\%$. The framework outperforms classical compression techniques (weight\nsharing/pruning) by 6--12\\% absolute accuracy while eliminating quantum\nhardware requirements during inference through classical deployment of\ncompressed parameters. Simulations incorporating realistic photonic noise\ndemonstrate the framework's robustness to near-term hardware imperfections.\nAblation studies confirm quantum necessity: replacing photonic QNNs with random\ninputs collapses accuracy to chance level ($10.0\\% \\pm 0.5\\%$). Photonic\nquantum computing's room-temperature operation, inherent scalability through\nspatial-mode multiplexing, and HPC-integrated architecture establish a\npractical pathway for distributed quantum machine learning, combining the\nexpressivity of photonic Hilbert spaces with the deployability of classical\nneural networks.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08474v1",
    "published_date": "2025-05-13 11:58:45 UTC",
    "updated_date": "2025-05-13 11:58:45 UTC"
  },
  {
    "arxiv_id": "2505.08463v1",
    "title": "RepCali: High Efficient Fine-tuning Via Representation Calibration in Latent Space for Pre-trained Language Models",
    "authors": [
      "Fujun Zhang",
      "XiangDong Su"
    ],
    "abstract": "Fine-tuning pre-trained language models (PLMs) has become a dominant paradigm\nin applying PLMs to downstream tasks. However, with limited fine-tuning, PLMs\nstill struggle with the discrepancies between the representation obtained from\nthe PLMs' encoder and the optimal input to the PLMs' decoder. This paper\ntackles this challenge by learning to calibrate the representation of PLMs in\nthe latent space. In the proposed representation calibration method (RepCali),\nwe integrate a specific calibration block to the latent space after the encoder\nand use the calibrated output as the decoder input. The merits of the proposed\nRepCali include its universality to all PLMs with encoder-decoder\narchitectures, its plug-and-play nature, and ease of implementation. Extensive\nexperiments on 25 PLM-based models across 8 tasks (including both English and\nChinese datasets) demonstrate that the proposed RepCali offers desirable\nenhancements to PLMs (including LLMs) and significantly improves the\nperformance of downstream tasks. Comparison experiments across 4 benchmark\ntasks indicate that RepCali is superior to the representative fine-tuning\nbaselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.08463v1",
    "published_date": "2025-05-13 11:47:00 UTC",
    "updated_date": "2025-05-13 11:47:00 UTC"
  },
  {
    "arxiv_id": "2505.08841v1",
    "title": "Will AI Take My Job? Evolving Perceptions of Automation and Labor Risk in Latin America",
    "authors": [
      "Andrea Cremaschi",
      "Dae-Jin Lee",
      "Manuele Leonelli"
    ],
    "abstract": "As artificial intelligence and robotics increasingly reshape the global labor\nmarket, understanding public perceptions of these technologies becomes\ncritical. We examine how these perceptions have evolved across Latin America,\nusing survey data from the 2017, 2018, 2020, and 2023 waves of the\nLatinobar\\'ometro. Drawing on responses from over 48,000 individuals across 16\ncountries, we analyze fear of job loss due to artificial intelligence and\nrobotics. Using statistical modeling and latent class analysis, we identify key\nstructural and ideological predictors of concern, with education level and\npolitical orientation emerging as the most consistent drivers. Our findings\nreveal substantial temporal and cross-country variation, with a notable peak in\nfear during 2018 and distinct attitudinal profiles emerging from latent\nsegmentation. These results offer new insights into the social and structural\ndimensions of AI anxiety in emerging economies and contribute to a broader\nunderstanding of public attitudes toward automation beyond the Global North.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08841v1",
    "published_date": "2025-05-13 11:43:02 UTC",
    "updated_date": "2025-05-13 11:43:02 UTC"
  },
  {
    "arxiv_id": "2505.08459v1",
    "title": "Strategy-Augmented Planning for Large Language Models via Opponent Exploitation",
    "authors": [
      "Shuai Xu",
      "Sijia Cui",
      "Yanna Wang",
      "Bo Xu",
      "Qi Wang"
    ],
    "abstract": "Efficiently modeling and exploiting opponents is a long-standing challenge in\nadversarial domains. Large Language Models (LLMs) trained on extensive textual\ndata have recently demonstrated outstanding performance in general tasks,\nintroducing new research directions for opponent modeling. Some studies\nprimarily focus on directly using LLMs to generate decisions based on the\nelaborate prompt context that incorporates opponent descriptions, while these\napproaches are limited to scenarios where LLMs possess adequate domain\nexpertise. To address that, we introduce a two-stage Strategy-Augmented\nPlanning (SAP) framework that significantly enhances the opponent exploitation\ncapabilities of LLM-based agents by utilizing a critical component, the\nStrategy Evaluation Network (SEN). Specifically, in the offline stage, we\nconstruct an explicit strategy space and subsequently collect strategy-outcome\npair data for training the SEN network. During the online phase, SAP\ndynamically recognizes the opponent's strategies and greedily exploits them by\nsearching best response strategy on the well-trained SEN, finally translating\nstrategy to a course of actions by carefully designed prompts. Experimental\nresults show that SAP exhibits robust generalization capabilities, allowing it\nto perform effectively not only against previously encountered opponent\nstrategies but also against novel, unseen strategies. In the MicroRTS\nenvironment, SAP achieves a 85.35\\% performance improvement over baseline\nmethods and matches the competitiveness of reinforcement learning approaches\nagainst state-of-the-art (SOTA) rule-based AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to IJCNN 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08459v1",
    "published_date": "2025-05-13 11:41:10 UTC",
    "updated_date": "2025-05-13 11:41:10 UTC"
  },
  {
    "arxiv_id": "2505.08451v1",
    "title": "Adaptive Bias Generalized Rollout Policy Adaptation on the Flexible Job-Shop Scheduling Problem",
    "authors": [
      "Lotfi Kobrosly",
      "Marc-Emmanuel Coupvent des Graviers",
      "Christophe Guettier",
      "Tristan Cazenave"
    ],
    "abstract": "The Flexible Job-Shop Scheduling Problem (FJSSP) is an NP-hard combinatorial\noptimization problem, with several application domains, especially for\nmanufacturing purposes. The objective is to\n  efficiently schedule multiple operations on dissimilar machines. These\noperations are gathered into jobs, and operations pertaining to the same job\nneed to be scheduled sequentially. Different methods have been previously\ntested to solve this problem, such as Constraint Solving, Tabu Search, Genetic\nAlgorithms, or Monte Carlo Tree Search (MCTS). We propose a novel algorithm\nderived from the Generalized Nested Rollout Policy Adaptation, developed to\nsolve the FJSSP. We report encouraging experimental results, as our algorithm\nperforms better than other MCTS-based approaches, even if makespans obtained on\nlarge instances are still far from known upper bounds.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "The 19th Learning and Intelligent OptimizatioN Conference, LION19\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08451v1",
    "published_date": "2025-05-13 11:27:18 UTC",
    "updated_date": "2025-05-13 11:27:18 UTC"
  },
  {
    "arxiv_id": "2505.08446v1",
    "title": "Agent-as-a-Service based on Agent Network",
    "authors": [
      "Yuhan Zhu",
      "Haojie Liu",
      "Jian Wang",
      "Bing Li",
      "Zikang Yin",
      "Yefei Liao"
    ],
    "abstract": "The rise of large model-based AI agents has spurred interest in Multi-Agent\nSystems (MAS) for their capabilities in decision-making, collaboration, and\nadaptability. While the Model Context Protocol (MCP) addresses tool invocation\nand data exchange challenges via a unified protocol, it lacks support for\norganizing agent-level collaboration. To bridge this gap, we propose\nAgent-as-a-Service based on Agent Network (AaaS-AN), a service-oriented\nparadigm grounded in the Role-Goal-Process-Service (RGPS) standard. AaaS-AN\nunifies the entire agent lifecycle, including construction, integration,\ninteroperability, and networked collaboration, through two core components: (1)\na dynamic Agent Network, which models agents and agent groups as vertexes that\nself-organize within the network based on task and role dependencies; (2)\nservice-oriented agents, incorporating service discovery, registration, and\ninteroperability protocols. These are orchestrated by a Service Scheduler,\nwhich leverages an Execution Graph to enable distributed coordination, context\ntracking, and runtime task management. We validate AaaS-AN on mathematical\nreasoning and application-level code generation tasks, which outperforms\nstate-of-the-art baselines. Notably, we constructed a MAS based on AaaS-AN\ncontaining agent groups, Robotic Process Automation (RPA) workflows, and MCP\nservers over 100 agent services. We also release a dataset containing 10,000\nlong-horizon multi-agent workflows to facilitate future research on long-chain\ncollaboration in MAS.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "work in progress",
    "pdf_url": "http://arxiv.org/pdf/2505.08446v1",
    "published_date": "2025-05-13 11:15:19 UTC",
    "updated_date": "2025-05-13 11:15:19 UTC"
  },
  {
    "arxiv_id": "2505.08445v1",
    "title": "Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency",
    "authors": [
      "Adel Ammar",
      "Anis Koubaa",
      "Omer Nacar",
      "Wadii Boulila"
    ],
    "abstract": "Large language models achieve high task performance yet often hallucinate or\nrely on outdated knowledge. Retrieval-augmented generation (RAG) addresses\nthese gaps by coupling generation with external search. We analyse how\nhyperparameters influence speed and quality in RAG systems, covering Chroma and\nFaiss vector stores, chunking policies, cross-encoder re-ranking, and\ntemperature, and we evaluate six metrics: faithfulness, answer correctness,\nanswer relevancy, context precision, context recall, and answer similarity.\nChroma processes queries 13% faster, whereas Faiss yields higher retrieval\nprecision, revealing a clear speed-accuracy trade-off. Naive fixed-length\nchunking with small windows and minimal overlap outperforms semantic\nsegmentation while remaining the quickest option. Re-ranking provides modest\ngains in retrieval quality yet increases runtime by roughly a factor of 5, so\nits usefulness depends on latency constraints. These results help practitioners\nbalance computational cost and accuracy when tuning RAG systems for\ntransparent, up-to-date responses. Finally, we re-evaluate the top\nconfigurations with a corrective RAG workflow and show that their advantages\npersist when the model can iteratively request additional evidence. We obtain a\nnear-perfect context precision (99%), which demonstrates that RAG systems can\nachieve extremely high retrieval accuracy with the right combination of\nhyperparameters, with significant implications for applications where retrieval\nquality directly impacts downstream task performance, such as clinical decision\nsupport in healthcare.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08445v1",
    "published_date": "2025-05-13 11:13:27 UTC",
    "updated_date": "2025-05-13 11:13:27 UTC"
  },
  {
    "arxiv_id": "2505.08438v1",
    "title": "A Survey of 3D Reconstruction with Event Cameras: From Event-based Geometry to Neural 3D Rendering",
    "authors": [
      "Chuanzhi Xu",
      "Haoxian Zhou",
      "Langyi Chen",
      "Haodong Chen",
      "Ying Zhou",
      "Vera Chung",
      "Qiang Qu"
    ],
    "abstract": "Event cameras have emerged as promising sensors for 3D reconstruction due to\ntheir ability to capture per-pixel brightness changes asynchronously. Unlike\nconventional frame-based cameras, they produce sparse and temporally rich data\nstreams, which enable more accurate 3D reconstruction and open up the\npossibility of performing reconstruction in extreme environments such as\nhigh-speed motion, low light, or high dynamic range scenes. In this survey, we\nprovide the first comprehensive review focused exclusively on 3D reconstruction\nusing event cameras. The survey categorises existing works into three major\ntypes based on input modality - stereo, monocular, and multimodal systems, and\nfurther classifies them by reconstruction approach, including geometry-based,\ndeep learning-based, and recent neural rendering techniques such as Neural\nRadiance Fields and 3D Gaussian Splatting. Methods with a similar research\nfocus were organised chronologically into the most subdivided groups. We also\nsummarise public datasets relevant to event-based 3D reconstruction. Finally,\nwe highlight current research limitations in data availability, evaluation,\nrepresentation, and dynamic scene handling, and outline promising future\nresearch directions. This survey aims to serve as a comprehensive reference and\na roadmap for future developments in event-driven 3D reconstruction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "35 pages, 12 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.08438v1",
    "published_date": "2025-05-13 11:04:04 UTC",
    "updated_date": "2025-05-13 11:04:04 UTC"
  },
  {
    "arxiv_id": "2505.08435v2",
    "title": "Hakim: Farsi Text Embedding Model",
    "authors": [
      "Mehran Sarmadi",
      "Morteza Alikhani",
      "Erfan Zinvandi",
      "Zahra Pourbahman"
    ],
    "abstract": "Recent advancements in text embedding have significantly improved natural\nlanguage understanding across many languages, yet Persian remains notably\nunderrepresented in large-scale embedding research. In this paper, we present\nHakim, a novel state-of-the-art Persian text embedding model that achieves a\n8.5% performance improvement over existing approaches on the FaMTEB benchmark,\noutperforming all previously developed Persian language models. As part of this\nwork, we introduce three new datasets - Corpesia, Pairsia-sup, and\nPairsia-unsup - to support supervised and unsupervised training scenarios.\nAdditionally, Hakim is designed for applications in chatbots and\nretrieval-augmented generation (RAG) systems, particularly addressing retrieval\ntasks that require incorporating message history within these systems. We also\npropose a new baseline model built on the BERT architecture. Our language model\nconsistently achieves higher accuracy across various Persian NLP tasks, while\nthe RetroMAE-based model proves particularly effective for textual information\nretrieval applications. Together, these contributions establish a new\nfoundation for advancing Persian language understanding.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08435v2",
    "published_date": "2025-05-13 10:57:32 UTC",
    "updated_date": "2025-05-14 13:47:12 UTC"
  },
  {
    "arxiv_id": "2505.08404v1",
    "title": "Explaining Autonomous Vehicles with Intention-aware Policy Graphs",
    "authors": [
      "Sara Montese",
      "Victor Gimenez-Abalos",
      "Atia Cortés",
      "Ulises Cortés",
      "Sergio Alvarez-Napagao"
    ],
    "abstract": "The potential to improve road safety, reduce human driving error, and promote\nenvironmental sustainability have enabled the field of autonomous driving to\nprogress rapidly over recent decades. The performance of autonomous vehicles\nhas significantly improved thanks to advancements in Artificial Intelligence,\nparticularly Deep Learning. Nevertheless, the opacity of their decision-making,\nrooted in the use of accurate yet complex AI models, has created barriers to\ntheir societal trust and regulatory acceptance, raising the need for\nexplainability. We propose a post-hoc, model-agnostic solution to provide\nteleological explanations for the behaviour of an autonomous vehicle in urban\nenvironments. Building on Intention-aware Policy Graphs, our approach enables\nthe extraction of interpretable and reliable explanations of vehicle behaviour\nin the nuScenes dataset from global and local perspectives. We demonstrate the\npotential of these explanations to assess whether the vehicle operates within\nacceptable legal boundaries and to identify possible vulnerabilities in\nautonomous driving datasets and models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to Workshop EXTRAAMAS 2025 in AAMAS Conference",
    "pdf_url": "http://arxiv.org/pdf/2505.08404v1",
    "published_date": "2025-05-13 09:58:32 UTC",
    "updated_date": "2025-05-13 09:58:32 UTC"
  },
  {
    "arxiv_id": "2505.08403v1",
    "title": "ConDiSim: Conditional Diffusion Models for Simulation Based Inference",
    "authors": [
      "Mayank Nautiyal",
      "Andreas Hellander",
      "Prashant Singh"
    ],
    "abstract": "We present a conditional diffusion model - ConDiSim, for simulation-based\ninference of complex systems with intractable likelihoods. ConDiSim leverages\ndenoising diffusion probabilistic models to approximate posterior\ndistributions, consisting of a forward process that adds Gaussian noise to\nparameters, and a reverse process learning to denoise, conditioned on observed\ndata. This approach effectively captures complex dependencies and\nmulti-modalities within posteriors. ConDiSim is evaluated across ten benchmark\nproblems and two real-world test problems, where it demonstrates effective\nposterior approximation accuracy while maintaining computational efficiency and\nstability in model training. ConDiSim offers a robust and extensible framework\nfor simulation-based inference, particularly suitable for parameter inference\nworkflows requiring fast inference methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08403v1",
    "published_date": "2025-05-13 09:58:23 UTC",
    "updated_date": "2025-05-13 09:58:23 UTC"
  },
  {
    "arxiv_id": "2505.08392v1",
    "title": "Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping",
    "authors": [
      "Ren Zhuang",
      "Ben Wang",
      "Shuifa Sun"
    ],
    "abstract": "Large Language Models leverage Chain-of-Thought (CoT) prompting for complex\ntasks, but their reasoning traces are often excessively verbose and\ninefficient, leading to significant computational costs and latency. Current\nCoT compression techniques typically rely on generic importance metrics and\nstatic compression rates, which may inadvertently remove functionally critical\ntokens or fail to adapt to varying reasoning complexity. To overcome these\nlimitations, we propose Adaptive GoGI-Skip, a novel framework learning dynamic\nCoT compression via supervised fine-tuning. This approach introduces two\nsynergistic innovations: (1) Goal-Gradient Importance (GoGI), a novel metric\naccurately identifying functionally relevant tokens by measuring the gradient\ninfluence of their intermediate representations on the final answer loss, and\n(2) Adaptive Dynamic Skipping (ADS), a mechanism dynamically regulating the\ncompression rate based on runtime model uncertainty while ensuring local\ncoherence through an adaptive N-token constraint. To our knowledge, this is the\nfirst work unifying a goal-oriented, gradient-based importance metric with\ndynamic, uncertainty-aware skipping for CoT compression. Trained on compressed\nMATH data, Adaptive GoGI-Skip demonstrates strong cross-domain generalization\nacross diverse reasoning benchmarks including AIME, GPQA, and GSM8K. It\nachieves substantial efficiency gains - reducing CoT token counts by over 45%\non average and delivering 1.6-2.0 times inference speedups - while maintaining\nhigh reasoning accuracy. Notably, it significantly outperforms existing\nbaselines by preserving accuracy even at high effective compression rates,\nadvancing the state of the art in the CoT reasoning efficiency-accuracy\ntrade-off.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08392v1",
    "published_date": "2025-05-13 09:39:18 UTC",
    "updated_date": "2025-05-13 09:39:18 UTC"
  },
  {
    "arxiv_id": "2505.08376v1",
    "title": "Adaptive Diffusion Policy Optimization for Robotic Manipulation",
    "authors": [
      "Huiyun Jiang",
      "Zhuang Yang"
    ],
    "abstract": "Recent studies have shown the great potential of diffusion models in\nimproving reinforcement learning (RL) by modeling complex policies, expressing\na high degree of multi-modality, and efficiently handling high-dimensional\ncontinuous control tasks. However, there is currently limited research on how\nto optimize diffusion-based polices (e.g., Diffusion Policy) fast and stably.\nIn this paper, we propose an Adam-based Diffusion Policy Optimization (ADPO), a\nfast algorithmic framework containing best practices for fine-tuning\ndiffusion-based polices in robotic control tasks using the adaptive gradient\ndescent method in RL. Adaptive gradient method is less studied in training RL,\nlet alone diffusion-based policies. We confirm that ADPO outperforms other\ndiffusion-based RL methods in terms of overall effectiveness for fine-tuning on\nstandard robotic tasks. Concretely, we conduct extensive experiments on\nstandard robotic control tasks to test ADPO, where, particularly, six popular\ndiffusion-based RL methods are provided as benchmark methods. Experimental\nresults show that ADPO acquires better or comparable performance than the\nbaseline methods. Finally, we systematically analyze the sensitivity of\nmultiple hyperparameters in standard robotics tasks, providing guidance for\nsubsequent practical applications. Our video demonstrations are released in\nhttps://github.com/Timeless-lab/ADPO.git.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08376v1",
    "published_date": "2025-05-13 09:21:45 UTC",
    "updated_date": "2025-05-13 09:21:45 UTC"
  },
  {
    "arxiv_id": "2505.08366v1",
    "title": "Non-contact Vital Signs Detection in Dynamic Environments",
    "authors": [
      "Shuai Sun",
      "Chong-Xi Liang",
      "Chengwei Ye",
      "Huanzhen Zhang",
      "Kangsheng Wang"
    ],
    "abstract": "Accurate phase demodulation is critical for vital sign detection using\nmillimeter-wave radar. However, in complex environments, time-varying DC\noffsets and phase imbalances can severely degrade demodulation performance. To\naddress this, we propose a novel DC offset calibration method alongside a\nHilbert and Differential Cross-Multiply (HADCM) demodulation algorithm. The\napproach estimates time-varying DC offsets from neighboring signal peaks and\nvalleys, then employs both differential forms and Hilbert transforms of the I/Q\nchannel signals to extract vital sign information. Simulation and experimental\nresults demonstrate that the proposed method maintains robust performance under\nlow signal-to-noise ratios. Compared to existing demodulation techniques, it\noffers more accurate signal recovery in challenging scenarios and effectively\nsuppresses noise interference.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08366v1",
    "published_date": "2025-05-13 09:11:48 UTC",
    "updated_date": "2025-05-13 09:11:48 UTC"
  },
  {
    "arxiv_id": "2505.08364v1",
    "title": "Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation",
    "authors": [
      "Enci Zhang",
      "Xingang Yan",
      "Wei Lin",
      "Tianxiang Zhang",
      "Qianchun Lu"
    ],
    "abstract": "Despite impressive progress in areas like mathematical reasoning, large\nlanguage models still face significant challenges in consistently solving\ncomplex problems. Drawing inspiration from key human learning strategies, we\npropose two novel strategies to enhance the capability of large language models\nto solve these complex problems. First, Adaptive Difficulty Curriculum Learning\n(ADCL) is a novel curriculum learning strategy that tackles the Difficulty\nShift phenomenon (i.e., a model's perception of problem difficulty dynamically\nchanges during training) by periodically re-estimating difficulty within\nupcoming data batches to maintain alignment with the model's evolving\ncapabilities. Second, Expert-Guided Self-Reformulation (EGSR) is a novel\nreinforcement learning strategy that bridges the gap between imitation learning\nand pure exploration by guiding models to reformulate expert solutions within\ntheir own conceptual framework, rather than relying on direct imitation,\nfostering deeper understanding and knowledge assimilation. Extensive\nexperiments on challenging mathematical reasoning benchmarks, using Qwen2.5-7B\nas the base model, demonstrate that these human-inspired strategies\nsynergistically and significantly enhance performance. Notably, their combined\napplication improves performance over the standard Zero-RL baseline by 10% on\nthe AIME24 benchmark and 16.6% on AIME25.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 3 figs",
    "pdf_url": "http://arxiv.org/pdf/2505.08364v1",
    "published_date": "2025-05-13 09:10:48 UTC",
    "updated_date": "2025-05-13 09:10:48 UTC"
  },
  {
    "arxiv_id": "2505.08361v1",
    "title": "Modeling Unseen Environments with Language-guided Composable Causal Components in Reinforcement Learning",
    "authors": [
      "Xinyue Wang",
      "Biwei Huang"
    ],
    "abstract": "Generalization in reinforcement learning (RL) remains a significant\nchallenge, especially when agents encounter novel environments with unseen\ndynamics. Drawing inspiration from human compositional reasoning -- where known\ncomponents are reconfigured to handle new situations -- we introduce World\nModeling with Compositional Causal Components (WM3C). This novel framework\nenhances RL generalization by learning and leveraging compositional causal\ncomponents. Unlike previous approaches focusing on invariant representation\nlearning or meta-learning, WM3C identifies and utilizes causal dynamics among\ncomposable elements, facilitating robust adaptation to new tasks. Our approach\nintegrates language as a compositional modality to decompose the latent space\ninto meaningful components and provides theoretical guarantees for their unique\nidentification under mild assumptions. Our practical implementation uses a\nmasked autoencoder with mutual information constraints and adaptive sparsity\nregularization to capture high-level semantic information and effectively\ndisentangle transition dynamics. Experiments on numerical simulations and\nreal-world robotic manipulation tasks demonstrate that WM3C significantly\noutperforms existing methods in identifying latent processes, improving policy\nlearning, and generalizing to unseen tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08361v1",
    "published_date": "2025-05-13 09:08:28 UTC",
    "updated_date": "2025-05-13 09:08:28 UTC"
  },
  {
    "arxiv_id": "2505.08350v1",
    "title": "STORYANCHORS: Generating Consistent Multi-Scene Story Frames for Long-Form Narratives",
    "authors": [
      "Bo Wang",
      "Haoyang Huang",
      "Zhiyin Lu",
      "Fengyuan Liu",
      "Guoqing Ma",
      "Jianlong Yuan",
      "Yuan Zhang",
      "Nan Duan"
    ],
    "abstract": "This paper introduces StoryAnchors, a unified framework for generating\nhigh-quality, multi-scene story frames with strong temporal consistency. The\nframework employs a bidirectional story generator that integrates both past and\nfuture contexts to ensure temporal consistency, character continuity, and\nsmooth scene transitions throughout the narrative. Specific conditions are\nintroduced to distinguish story frame generation from standard video synthesis,\nfacilitating greater scene diversity and enhancing narrative richness. To\nfurther improve generation quality, StoryAnchors integrates Multi-Event Story\nFrame Labeling and Progressive Story Frame Training, enabling the model to\ncapture both overarching narrative flow and event-level dynamics. This approach\nsupports the creation of editable and expandable story frames, allowing for\nmanual modifications and the generation of longer, more complex sequences.\nExtensive experiments show that StoryAnchors outperforms existing open-source\nmodels in key areas such as consistency, narrative coherence, and scene\ndiversity. Its performance in narrative consistency and story richness is also\non par with GPT-4o. Ultimately, StoryAnchors pushes the boundaries of\nstory-driven frame generation, offering a scalable, flexible, and highly\neditable foundation for future research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08350v1",
    "published_date": "2025-05-13 08:48:10 UTC",
    "updated_date": "2025-05-13 08:48:10 UTC"
  },
  {
    "arxiv_id": "2505.08349v1",
    "title": "FAD: Frequency Adaptation and Diversion for Cross-domain Few-shot Learning",
    "authors": [
      "Ruixiao Shi",
      "Fu Feng",
      "Yucheng Xie",
      "Jing Wang",
      "Xin Geng"
    ],
    "abstract": "Cross-domain few-shot learning (CD-FSL) requires models to generalize from\nlimited labeled samples under significant distribution shifts. While recent\nmethods enhance adaptability through lightweight task-specific modules, they\noperate solely in the spatial domain and overlook frequency-specific variations\nthat are often critical for robust transfer. We observe that spatially similar\nimages across domains can differ substantially in their spectral\nrepresentations, with low and high frequencies capturing complementary semantic\ninformation at coarse and fine levels. This indicates that uniform spatial\nadaptation may overlook these spectral distinctions, thus constraining\ngeneralization. To address this, we introduce Frequency Adaptation and\nDiversion (FAD), a frequency-aware framework that explicitly models and\nmodulates spectral components. At its core is the Frequency Diversion Adapter,\nwhich transforms intermediate features into the frequency domain using the\ndiscrete Fourier transform (DFT), partitions them into low, mid, and\nhigh-frequency bands via radial masks, and reconstructs each band using inverse\nDFT (IDFT). Each frequency band is then adapted using a dedicated convolutional\nbranch with a kernel size tailored to its spectral scale, enabling targeted and\ndisentangled adaptation across frequencies. Extensive experiments on the\nMeta-Dataset benchmark demonstrate that FAD consistently outperforms\nstate-of-the-art methods on both seen and unseen domains, validating the\nutility of frequency-domain representations and band-wise adaptation for\nimproving generalization in CD-FSL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08349v1",
    "published_date": "2025-05-13 08:48:06 UTC",
    "updated_date": "2025-05-13 08:48:06 UTC"
  },
  {
    "arxiv_id": "2505.08345v1",
    "title": "SHAP-based Explanations are Sensitive to Feature Representation",
    "authors": [
      "Hyunseung Hwang",
      "Andrew Bell",
      "Joao Fonseca",
      "Venetia Pliatsika",
      "Julia Stoyanovich",
      "Steven Euijong Whang"
    ],
    "abstract": "Local feature-based explanations are a key component of the XAI toolkit.\nThese explanations compute feature importance values relative to an\n``interpretable'' feature representation. In tabular data, feature values\nthemselves are often considered interpretable. This paper examines the impact\nof data engineering choices on local feature-based explanations. We demonstrate\nthat simple, common data engineering techniques, such as representing age with\na histogram or encoding race in a specific way, can manipulate feature\nimportance as determined by popular methods like SHAP. Notably, the sensitivity\nof explanations to feature representation can be exploited by adversaries to\nobscure issues like discrimination. While the intuition behind these results is\nstraightforward, their systematic exploration has been lacking. Previous work\nhas focused on adversarial attacks on feature-based explainers by biasing data\nor manipulating models. To the best of our knowledge, this is the first study\ndemonstrating that explainers can be misled by standard, seemingly innocuous\ndata engineering techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ACM FAccT 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08345v1",
    "published_date": "2025-05-13 08:43:09 UTC",
    "updated_date": "2025-05-13 08:43:09 UTC"
  },
  {
    "arxiv_id": "2505.08343v1",
    "title": "An Identifiable Cost-Aware Causal Decision-Making Framework Using Counterfactual Reasoning",
    "authors": [
      "Ruichu Cai",
      "Xi Chen",
      "Jie Qiao",
      "Zijian Li",
      "Yuequn Liu",
      "Wei Chen",
      "Keli Zhang",
      "Jiale Zheng"
    ],
    "abstract": "Decision making under abnormal conditions is a critical process that involves\nevaluating the current state and determining the optimal action to restore the\nsystem to a normal state at an acceptable cost. However, in such scenarios,\nexisting decision-making frameworks highly rely on reinforcement learning or\nroot cause analysis, resulting in them frequently neglecting the cost of the\nactions or failing to incorporate causal mechanisms adequately. By relaxing the\nexisting causal decision framework to solve the necessary cause, we propose a\nminimum-cost causal decision (MiCCD) framework via counterfactual reasoning to\naddress the above challenges. Emphasis is placed on making counterfactual\nreasoning processes identifiable in the presence of a large amount of mixed\nanomaly data, as well as finding the optimal intervention state in a continuous\ndecision space. Specifically, it formulates a surrogate model based on causal\ngraphs, using abnormal pattern clustering labels as supervisory signals. This\nenables the approximation of the structural causal model among the variables\nand lays a foundation for identifiable counterfactual reasoning. With the\ncausal structure approximated, we then established an optimization model based\non counterfactual estimation. The Sequential Least Squares Programming (SLSQP)\nalgorithm is further employed to optimize intervention strategies while taking\ncosts into account. Experimental evaluations on both synthetic and real-world\ndatasets reveal that MiCCD outperforms conventional methods across multiple\nmetrics, including F1-score, cost efficiency, and ranking quality(nDCG@k\nvalues), thus validating its efficacy and broad applicability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08343v1",
    "published_date": "2025-05-13 08:41:45 UTC",
    "updated_date": "2025-05-13 08:41:45 UTC"
  },
  {
    "arxiv_id": "2505.08341v1",
    "title": "Benchmarking AI scientists in omics data-driven biological research",
    "authors": [
      "Erpai Luo",
      "Jinmeng Jia",
      "Yifan Xiong",
      "Xiangyu Li",
      "Xiaobo Guo",
      "Baoqi Yu",
      "Lei Wei",
      "Xuegong Zhang"
    ],
    "abstract": "The rise of large language models and multi-agent systems has sparked growing\ninterest in AI scientists capable of autonomous biological research. However,\nexisting benchmarks either focus on reasoning without data or on data analysis\nwith predefined statistical answers, lacking realistic, data-driven evaluation\nsettings. Here, we introduce the Biological AI Scientist Benchmark (BaisBench),\na benchmark designed to assess AI scientists' ability to generate biological\ndiscoveries through data analysis and reasoning with external knowledge.\nBaisBench comprises two tasks: cell type annotation on 31 expert-labeled\nsingle-cell datasets, and scientific discovery through answering 198\nmultiple-choice questions derived from the biological insights of 41 recent\nsingle-cell studies. Systematic experiments on state-of-the-art AI scientists\nand LLM agents showed that while promising, current models still substantially\nunderperform human experts on both tasks. We hope BaisBench will fill this gap\nand serve as a foundation for advancing and evaluating AI models for scientific\ndiscovery. The benchmark can be found at: https://github.com/EperLuo/BaisBench.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "q-bio.GN"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08341v1",
    "published_date": "2025-05-13 08:33:54 UTC",
    "updated_date": "2025-05-13 08:33:54 UTC"
  },
  {
    "arxiv_id": "2505.08336v1",
    "title": "A computer vision-based model for occupancy detection using low-resolution thermal images",
    "authors": [
      "Xue Cui",
      "Vincent Gbouna Zakka",
      "Minhyun Lee"
    ],
    "abstract": "Occupancy plays an essential role in influencing the energy consumption and\noperation of heating, ventilation, and air conditioning (HVAC) systems.\nTraditional HVAC typically operate on fixed schedules without considering\noccupancy. Advanced occupant-centric control (OCC) adopted occupancy status in\nregulating HVAC operations. RGB images combined with computer vision (CV)\ntechniques are widely used for occupancy detection, however, the detailed\nfacial and body features they capture raise significant privacy concerns.\nLow-resolution thermal images offer a non-invasive solution that mitigates\nprivacy issues. The study developed an occupancy detection model utilizing\nlow-resolution thermal images and CV techniques, where transfer learning was\napplied to fine-tune the You Only Look Once version 5 (YOLOv5) model. The\ndeveloped model ultimately achieved satisfactory performance, with precision,\nrecall, mAP50, and mAP50 values approaching 1.000. The contributions of this\nmodel lie not only in mitigating privacy concerns but also in reducing\ncomputing resource demands.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08336v1",
    "published_date": "2025-05-13 08:27:50 UTC",
    "updated_date": "2025-05-13 08:27:50 UTC"
  },
  {
    "arxiv_id": "2505.08838v1",
    "title": "Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts",
    "authors": [
      "Peixuan Ge",
      "Tongkun Su",
      "Faqin Lv",
      "Baoliang Zhao",
      "Peng Zhang",
      "Chi Hong Wong",
      "Liang Yao",
      "Yu Sun",
      "Zenan Wang",
      "Pak Kin Wong",
      "Ying Hu"
    ],
    "abstract": "Ultrasound (US) report generation is a challenging task due to the\nvariability of US images, operator dependence, and the need for standardized\ntext. Unlike X-ray and CT, US imaging lacks consistent datasets, making\nautomation difficult. In this study, we propose a unified framework for\nmulti-organ and multilingual US report generation, integrating fragment-based\nmultilingual training and leveraging the standardized nature of US reports. By\naligning modular text fragments with diverse imaging data and curating a\nbilingual English-Chinese dataset, the method achieves consistent and\nclinically accurate text generation across organ sites and languages.\nFine-tuning with selective unfreezing of the vision transformer (ViT) further\nimproves text-image alignment. Compared to the previous state-of-the-art KMVE\nmethod, our approach achieves relative gains of about 2\\% in BLEU scores,\napproximately 3\\% in ROUGE-L, and about 15\\% in CIDEr, while significantly\nreducing errors such as missing or incorrect content. By unifying multi-organ\nand multi-language report generation into a single, scalable framework, this\nwork demonstrates strong potential for real-world clinical workflows.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08838v1",
    "published_date": "2025-05-13 08:27:01 UTC",
    "updated_date": "2025-05-13 08:27:01 UTC"
  },
  {
    "arxiv_id": "2505.08327v1",
    "title": "Low-Complexity Inference in Continual Learning via Compressed Knowledge Transfer",
    "authors": [
      "Zhenrong Liu",
      "Janne M. J. Huttunen",
      "Mikko Honkala"
    ],
    "abstract": "Continual learning (CL) aims to train models that can learn a sequence of\ntasks without forgetting previously acquired knowledge. A core challenge in CL\nis balancing stability -- preserving performance on old tasks -- and plasticity\n-- adapting to new ones. Recently, large pre-trained models have been widely\nadopted in CL for their ability to support both, offering strong generalization\nfor new tasks and resilience against forgetting. However, their high\ncomputational cost at inference time limits their practicality in real-world\napplications, especially those requiring low latency or energy efficiency. To\naddress this issue, we explore model compression techniques, including pruning\nand knowledge distillation (KD), and propose two efficient frameworks tailored\nfor class-incremental learning (CIL), a challenging CL setting where task\nidentities are unavailable during inference. The pruning-based framework\nincludes pre- and post-pruning strategies that apply compression at different\ntraining stages. The KD-based framework adopts a teacher-student architecture,\nwhere a large pre-trained teacher transfers downstream-relevant knowledge to a\ncompact student. Extensive experiments on multiple CIL benchmarks demonstrate\nthat the proposed frameworks achieve a better trade-off between accuracy and\ninference complexity, consistently outperforming strong baselines. We further\nanalyze the trade-offs between the two frameworks in terms of accuracy and\nefficiency, offering insights into their use across different scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08327v1",
    "published_date": "2025-05-13 08:07:40 UTC",
    "updated_date": "2025-05-13 08:07:40 UTC"
  },
  {
    "arxiv_id": "2505.08325v1",
    "title": "FedRS-Bench: Realistic Federated Learning Datasets and Benchmarks in Remote Sensing",
    "authors": [
      "Haodong Zhao",
      "Peng Peng",
      "Chiyu Chen",
      "Linqing Huang",
      "Gongshen Liu"
    ],
    "abstract": "Remote sensing (RS) images are usually produced at an unprecedented scale,\nyet they are geographically and institutionally distributed, making centralized\nmodel training challenging due to data-sharing restrictions and privacy\nconcerns. Federated learning (FL) offers a solution by enabling collaborative\nmodel training across decentralized RS data sources without exposing raw data.\nHowever, there lacks a realistic federated dataset and benchmark in RS. Prior\nworks typically rely on manually partitioned single dataset, which fail to\ncapture the heterogeneity and scale of real-world RS data, and often use\ninconsistent experimental setups, hindering fair comparison. To address this\ngap, we propose a realistic federated RS dataset, termed FedRS. FedRS consists\nof eight datasets that cover various sensors and resolutions and builds 135\nclients, which is representative of realistic operational scenarios. Data for\neach client come from the same source, exhibiting authentic federated\nproperties such as skewed label distributions, imbalanced client data volumes,\nand domain heterogeneity across clients. These characteristics reflect\npractical challenges in federated RS and support evaluation of FL methods at\nscale. Based on FedRS, we implement 10 baseline FL algorithms and evaluation\nmetrics to construct the comprehensive FedRS-Bench. The experimental results\ndemonstrate that FL can consistently improve model performance over training on\nisolated data silos, while revealing performance trade-offs of different\nmethods under varying client heterogeneity and availability conditions. We hope\nFedRS-Bench will accelerate research on large-scale, realistic FL in RS by\nproviding a standardized, rich testbed and facilitating fair comparisons across\nfuture works. The source codes and dataset are available at\nhttps://fedrs-bench.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08325v1",
    "published_date": "2025-05-13 08:04:03 UTC",
    "updated_date": "2025-05-13 08:04:03 UTC"
  },
  {
    "arxiv_id": "2505.08319v1",
    "title": "Reciprocity as the Foundational Substrate of Society: How Reciprocal Dynamics Scale into Social Systems",
    "authors": [
      "Egil Diau"
    ],
    "abstract": "A major bottleneck in multi-agent AI is the lack of simulateable models for\nthe bottom-up emergence of social structure under realistic behavioral\nconstraints. Similarly, many foundational theories in economics and sociology\nincluding the concepts of \"institutions\" and \"norms\" tend to describe social\nstructures post hoc, often relying on implicit assumptions of shared culture,\nmorality, or symbolic agreement. These concepts are often treated as primitives\nrather than reconstructed from agent-level behavior, leaving both their origins\nand operational definitions under-specified. To address this, we propose a\nthree-stage bottom-up framework: Reciprocal Dynamics, capturing\nindividual-level reciprocal exchanges; Norm Stabilization, the consolidation of\nshared expectations; and Institutional Construction, the externalization of\nstable patterns into scalable structures. By grounding social emergence in\nagent-level reciprocity, our framework enables the systematic exploration of\nhow moral, cultural, and institutional structures emerge from cognitively\nminimal interactions.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CY",
    "comment": "First draft extending the first position paper. Main framework\n  complete; historical examples and references will be updated",
    "pdf_url": "http://arxiv.org/pdf/2505.08319v1",
    "published_date": "2025-05-13 07:50:01 UTC",
    "updated_date": "2025-05-13 07:50:01 UTC"
  },
  {
    "arxiv_id": "2505.08295v1",
    "title": "A Practical Introduction to Deep Reinforcement Learning",
    "authors": [
      "Yinghan Sun",
      "Hongxi Wang",
      "Hua Chen",
      "Wei Zhang"
    ],
    "abstract": "Deep reinforcement learning (DRL) has emerged as a powerful framework for\nsolving sequential decision-making problems, achieving remarkable success in a\nwide range of applications, including game AI, autonomous driving, biomedicine,\nand large language models. However, the diversity of algorithms and the\ncomplexity of theoretical foundations often pose significant challenges for\nbeginners seeking to enter the field. This tutorial aims to provide a concise,\nintuitive, and practical introduction to DRL, with a particular focus on the\nProximal Policy Optimization (PPO) algorithm, which is one of the most widely\nused and effective DRL methods. To facilitate learning, we organize all\nalgorithms under the Generalized Policy Iteration (GPI) framework, offering\nreaders a unified and systematic perspective. Instead of lengthy theoretical\nproofs, we emphasize intuitive explanations, illustrative examples, and\npractical engineering techniques. This work serves as an efficient and\naccessible guide, helping readers rapidly progress from basic concepts to the\nimplementation of advanced DRL algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08295v1",
    "published_date": "2025-05-13 07:19:16 UTC",
    "updated_date": "2025-05-13 07:19:16 UTC"
  },
  {
    "arxiv_id": "2505.08293v1",
    "title": "M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis",
    "authors": [
      "Zhizhuo Yin",
      "Yuk Hang Tsui",
      "Pan Hui"
    ],
    "abstract": "Generating full-body human gestures encompassing face, body, hands, and\nglobal movements from audio is a valuable yet challenging task in virtual\navatar creation. Previous systems focused on tokenizing the human gestures\nframewisely and predicting the tokens of each frame from the input audio.\nHowever, one observation is that the number of frames required for a complete\nexpressive human gesture, defined as granularity, varies among different human\ngesture patterns. Existing systems fail to model these gesture patterns due to\nthe fixed granularity of their gesture tokens. To solve this problem, we\npropose a novel framework named Multi-Granular Gesture Generator (M3G) for\naudio-driven holistic gesture generation. In M3G, we propose a novel\nMulti-Granular VQ-VAE (MGVQ-VAE) to tokenize motion patterns and reconstruct\nmotion sequences from different temporal granularities. Subsequently, we\nproposed a multi-granular token predictor that extracts multi-granular\ninformation from audio and predicts the corresponding motion tokens. Then M3G\nreconstructs the human gestures from the predicted tokens using the MGVQ-VAE.\nBoth objective and subjective experiments demonstrate that our proposed M3G\nframework outperforms the state-of-the-art methods in terms of generating\nnatural and expressive full-body human gestures.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.SD",
      "eess.AS",
      "I.3.6"
    ],
    "primary_category": "cs.GR",
    "comment": "9 Pages, 4 figures, submitted to NIPS 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08293v1",
    "published_date": "2025-05-13 07:16:58 UTC",
    "updated_date": "2025-05-13 07:16:58 UTC"
  },
  {
    "arxiv_id": "2505.08266v1",
    "title": "Open the Eyes of MPNN: Vision Enhances MPNN in Link Prediction",
    "authors": [
      "Yanbin Wei",
      "Xuehao Wang",
      "Zhan Zhuang",
      "Yang Chen",
      "Shuhao Chen",
      "Yulong Zhang",
      "Yu Zhang",
      "James Kwok"
    ],
    "abstract": "Message-passing graph neural networks (MPNNs) and structural features (SFs)\nare cornerstones for the link prediction task. However, as a common and\nintuitive mode of understanding, the potential of visual perception has been\noverlooked in the MPNN community. For the first time, we equip MPNNs with\nvision structural awareness by proposing an effective framework called Graph\nVision Network (GVN), along with a more efficient variant (E-GVN). Extensive\nempirical results demonstrate that with the proposed frameworks, GVN\nconsistently benefits from the vision enhancement across seven link prediction\ndatasets, including challenging large-scale graphs. Such improvements are\ncompatible with existing state-of-the-art (SOTA) methods and GVNs achieve new\nSOTA results, thereby underscoring a promising novel direction for link\nprediction.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08266v1",
    "published_date": "2025-05-13 06:32:23 UTC",
    "updated_date": "2025-05-13 06:32:23 UTC"
  },
  {
    "arxiv_id": "2505.08265v1",
    "title": "LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification",
    "authors": [
      "Hang Gao",
      "Wenxuan Huang",
      "Fengge Wu",
      "Junsuo Zhao",
      "Changwen Zheng",
      "Huaping Liu"
    ],
    "abstract": "The use of large language models (LLMs) as feature enhancers to optimize node\nrepresentations, which are then used as inputs for graph neural networks\n(GNNs), has shown significant potential in graph representation learning.\nHowever, the fundamental properties of this approach remain underexplored. To\naddress this issue, we propose conducting a more in-depth analysis of this\nissue based on the interchange intervention method. First, we construct a\nsynthetic graph dataset with controllable causal relationships, enabling\nprecise manipulation of semantic relationships and causal modeling to provide\ndata for analysis. Using this dataset, we conduct interchange interventions to\nexamine the deeper properties of LLM enhancers and GNNs, uncovering their\nunderlying logic and internal mechanisms. Building on the analytical results,\nwe design a plug-and-play optimization module to improve the information\ntransfer between LLM enhancers and GNNs. Experiments across multiple datasets\nand models validate the proposed module.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08265v1",
    "published_date": "2025-05-13 06:29:25 UTC",
    "updated_date": "2025-05-13 06:29:25 UTC"
  },
  {
    "arxiv_id": "2505.08264v1",
    "title": "Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning",
    "authors": [
      "Ahmed Abouelazm",
      "Tim Weinstein",
      "Tim Joseph",
      "Philip Schörner",
      "J. Marius Zöllner"
    ],
    "abstract": "This paper addresses the challenges of training end-to-end autonomous driving\nagents using Reinforcement Learning (RL). RL agents are typically trained in a\nfixed set of scenarios and nominal behavior of surrounding road users in\nsimulations, limiting their generalization and real-life deployment. While\ndomain randomization offers a potential solution by randomly sampling driving\nscenarios, it frequently results in inefficient training and sub-optimal\npolicies due to the high variance among training scenarios. To address these\nlimitations, we propose an automatic curriculum learning framework that\ndynamically generates driving scenarios with adaptive complexity based on the\nagent's evolving capabilities. Unlike manually designed curricula that\nintroduce expert bias and lack scalability, our framework incorporates a\n``teacher'' that automatically generates and mutates driving scenarios based on\ntheir learning potential -- an agent-centric metric derived from the agent's\ncurrent policy -- eliminating the need for expert design. The framework\nenhances training efficiency by excluding scenarios the agent has mastered or\nfinds too challenging. We evaluate our framework in a reinforcement learning\nsetting where the agent learns a driving policy from camera images. Comparative\nresults against baseline methods, including fixed scenario training and domain\nrandomization, demonstrate that our approach leads to enhanced generalization,\nachieving higher success rates: +9\\% in low traffic density, +21\\% in high\ntraffic density, and faster convergence with fewer training steps. Our findings\nhighlight the potential of ACL in improving the robustness and efficiency of\nRL-based autonomous driving agents.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.08264v1",
    "published_date": "2025-05-13 06:26:57 UTC",
    "updated_date": "2025-05-13 06:26:57 UTC"
  },
  {
    "arxiv_id": "2505.08261v1",
    "title": "Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration",
    "authors": [
      "Rishabh Agrawal",
      "Himanshu Kumar"
    ],
    "abstract": "The rapid progress in large language models (LLMs) has paved the way for\nnovel approaches in knowledge-intensive tasks. Among these, Cache-Augmented\nGeneration (CAG) has emerged as a promising alternative to Retrieval-Augmented\nGeneration (RAG). CAG minimizes retrieval latency and simplifies system design\nby preloading knowledge into the model's context. However, challenges persist\nin scaling CAG to accommodate large and dynamic knowledge bases effectively.\nThis paper introduces Adaptive Contextual Compression (ACC), an innovative\ntechnique designed to dynamically compress and manage context inputs, enabling\nefficient utilization of the extended memory capabilities of modern LLMs. To\nfurther address the limitations of standalone CAG, we propose a Hybrid CAG-RAG\nFramework, which integrates selective retrieval to augment preloaded contexts\nin scenarios requiring additional information. Comprehensive evaluations on\ndiverse datasets highlight the proposed methods' ability to enhance\nscalability, optimize efficiency, and improve multi-hop reasoning performance,\noffering practical solutions for real-world knowledge integration challenges.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08261v1",
    "published_date": "2025-05-13 06:24:48 UTC",
    "updated_date": "2025-05-13 06:24:48 UTC"
  },
  {
    "arxiv_id": "2505.08835v1",
    "title": "Robustness Analysis against Adversarial Patch Attacks in Fully Unmanned Stores",
    "authors": [
      "Hyunsik Na",
      "Wonho Lee",
      "Seungdeok Roh",
      "Sohee Park",
      "Daeseon Choi"
    ],
    "abstract": "The advent of convenient and efficient fully unmanned stores equipped with\nartificial intelligence-based automated checkout systems marks a new era in\nretail. However, these systems have inherent artificial intelligence security\nvulnerabilities, which are exploited via adversarial patch attacks,\nparticularly in physical environments. This study demonstrated that adversarial\npatches can severely disrupt object detection models used in unmanned stores,\nleading to issues such as theft, inventory discrepancies, and interference. We\ninvestigated three types of adversarial patch attacks -- Hiding, Creating, and\nAltering attacks -- and highlighted their effectiveness. We also introduce the\nnovel color histogram similarity loss function by leveraging attacker knowledge\nof the color information of a target class object. Besides the traditional\nconfusion-matrix-based attack success rate, we introduce a new\nbounding-boxes-based metric to analyze the practical impact of these attacks.\nStarting with attacks on object detection models trained on snack and fruit\ndatasets in a digital environment, we evaluated the effectiveness of\nadversarial patches in a physical testbed that mimicked a real unmanned store\nwith RGB cameras and realistic conditions. Furthermore, we assessed the\nrobustness of these attacks in black-box scenarios, demonstrating that shadow\nattacks can enhance success rates of attacks even without direct access to\nmodel parameters. Our study underscores the necessity for robust defense\nstrategies to protect unmanned stores from adversarial threats. Highlighting\nthe limitations of the current defense mechanisms in real-time detection\nsystems and discussing various proactive measures, we provide insights into\nimproving the robustness of object detection models and fortifying unmanned\nretail environments against these attacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08835v1",
    "published_date": "2025-05-13 06:24:32 UTC",
    "updated_date": "2025-05-13 06:24:32 UTC"
  },
  {
    "arxiv_id": "2505.08253v1",
    "title": "Evaluating LLM Metrics Through Real-World Capabilities",
    "authors": [
      "Justin K Miller",
      "Wenjia Tang"
    ],
    "abstract": "As generative AI becomes increasingly embedded in everyday workflows, it is\nimportant to evaluate its performance in ways that reflect real-world usage\nrather than abstract notions of intelligence. Unlike many existing benchmarks\nthat assess general intelligence, our approach focuses on real-world utility,\nevaluating how well models support users in everyday tasks. While current\nbenchmarks emphasize code generation or factual recall, users rely on AI for a\nmuch broader range of activities-from writing assistance and summarization to\ncitation formatting and stylistic feedback. In this paper, we analyze\nlarge-scale survey data and usage logs to identify six core capabilities that\nrepresent how people commonly use Large Language Models (LLMs): Summarization,\nTechnical Assistance, Reviewing Work, Data Structuring, Generation, and\nInformation Retrieval. We then assess the extent to which existing benchmarks\ncover these capabilities, revealing significant gaps in coverage, efficiency\nmeasurement, and interpretability. Drawing on this analysis, we use\nhuman-centered criteria to identify gaps in how well current benchmarks reflect\ncommon usage that is grounded in five practical criteria: coherence, accuracy,\nclarity, relevance, and efficiency. For four of the six capabilities, we\nidentify the benchmarks that best align with real-world tasks and use them to\ncompare leading models. We find that Google Gemini outperforms other\nmodels-including OpenAI's GPT, xAI's Grok, Meta's LLaMA, Anthropic's Claude,\nDeepSeek, and Qwen from Alibaba-on these utility-focused metrics.",
    "categories": [
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages main text, 5 pages references, 20 pages appendix; includes 3\n  figures and 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.08253v1",
    "published_date": "2025-05-13 06:02:37 UTC",
    "updated_date": "2025-05-13 06:02:37 UTC"
  },
  {
    "arxiv_id": "2505.08245v1",
    "title": "Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement",
    "authors": [
      "Haoran Ye",
      "Jing Jin",
      "Yuhang Xie",
      "Xin Zhang",
      "Guojie Song"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has outpaced\ntraditional evaluation methodologies. It presents novel challenges, such as\nmeasuring human-like psychological constructs, navigating beyond static and\ntask-specific benchmarks, and establishing human-centered evaluation. These\nchallenges intersect with Psychometrics, the science of quantifying the\nintangible aspects of human psychology, such as personality, values, and\nintelligence. This survey introduces and synthesizes an emerging\ninterdisciplinary field of LLM Psychometrics, which leverages psychometric\ninstruments, theories, and principles to evaluate, understand, and enhance\nLLMs. We systematically explore the role of Psychometrics in shaping\nbenchmarking principles, broadening evaluation scopes, refining methodologies,\nvalidating results, and advancing LLM capabilities. This paper integrates\ndiverse perspectives to provide a structured framework for researchers across\ndisciplines, enabling a more comprehensive understanding of this nascent field.\nUltimately, we aim to provide actionable insights for developing future\nevaluation paradigms that align with human-level AI and promote the advancement\nof human-centered AI systems for societal benefit. A curated repository of LLM\npsychometric resources is available at\nhttps://github.com/valuebyte-ai/Awesome-LLM-Psychometrics.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "63 pages, 482 references",
    "pdf_url": "http://arxiv.org/pdf/2505.08245v1",
    "published_date": "2025-05-13 05:47:51 UTC",
    "updated_date": "2025-05-13 05:47:51 UTC"
  },
  {
    "arxiv_id": "2505.08834v1",
    "title": "Crowd Scene Analysis using Deep Learning Techniques",
    "authors": [
      "Muhammad Junaid Asif"
    ],
    "abstract": "Our research is focused on two main applications of crowd scene analysis\ncrowd counting and anomaly detection In recent years a large number of\nresearches have been presented in the domain of crowd counting We addressed two\nmain challenges in this domain 1 Deep learning models are datahungry paradigms\nand always need a large amount of annotated data for the training of algorithm\nIt is timeconsuming and costly task to annotate such large amount of data\nSelfsupervised training is proposed to deal with this challenge 2 MCNN consists\nof multicolumns of CNN with different sizes of filters by presenting a novel\napproach based on a combination of selfsupervised training and MultiColumn CNN\nThis enables the model to learn features at different levels and makes it\neffective in dealing with challenges of occluded scenes nonuniform density\ncomplex backgrounds and scale invariation The proposed model was evaluated on\npublicly available data sets such as ShanghaiTech and UCFQNRF by means of MAE\nand MSE A spatiotemporal model based on VGG19 is proposed for crowd anomaly\ndetection addressing challenges like lighting environmental conditions\nunexpected objects and scalability The model extracts spatial and temporal\nfeatures allowing it to be generalized to realworld scenes Spatial features are\nlearned using CNN while temporal features are learned using LSTM blocks The\nmodel works on binary classification and can detect normal or abnormal behavior\nThe models performance is improved by replacing fully connected layers with\ndense residual blocks Experiments on the Hockey Fight dataset and SCVD dataset\nshow our models outperform other stateoftheart approaches",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "MS Graduate Research Thesis",
    "pdf_url": "http://arxiv.org/pdf/2505.08834v1",
    "published_date": "2025-05-13 05:29:30 UTC",
    "updated_date": "2025-05-13 05:29:30 UTC"
  },
  {
    "arxiv_id": "2505.08234v1",
    "title": "Removing Watermarks with Partial Regeneration using Semantic Information",
    "authors": [
      "Krti Tallam",
      "John Kevin Cava",
      "Caleb Geniesse",
      "N. Benjamin Erichson",
      "Michael W. Mahoney"
    ],
    "abstract": "As AI-generated imagery becomes ubiquitous, invisible watermarks have emerged\nas a primary line of defense for copyright and provenance. The newest\nwatermarking schemes embed semantic signals - content-aware patterns that are\ndesigned to survive common image manipulations - yet their true robustness\nagainst adaptive adversaries remains under-explored. We expose a previously\nunreported vulnerability and introduce SemanticRegen, a three-stage, label-free\nattack that erases state-of-the-art semantic and invisible watermarks while\nleaving an image's apparent meaning intact. Our pipeline (i) uses a\nvision-language model to obtain fine-grained captions, (ii) extracts foreground\nmasks with zero-shot segmentation, and (iii) inpaints only the background via\nan LLM-guided diffusion model, thereby preserving salient objects and style\ncues. Evaluated on 1,000 prompts across four watermarking systems - TreeRing,\nStegaStamp, StableSig, and DWT/DCT - SemanticRegen is the only method to defeat\nthe semantic TreeRing watermark (p = 0.10 > 0.05) and reduces bit-accuracy\nbelow 0.75 for the remaining schemes, all while maintaining high perceptual\nquality (masked SSIM = 0.94 +/- 0.01). We further introduce masked SSIM (mSSIM)\nto quantify fidelity within foreground regions, showing that our attack\nachieves up to 12 percent higher mSSIM than prior diffusion-based attackers.\nThese results highlight an urgent gap between current watermark defenses and\nthe capabilities of adaptive, semantics-aware adversaries, underscoring the\nneed for watermarking algorithms that are resilient to content-preserving\nregenerative attacks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08234v1",
    "published_date": "2025-05-13 05:25:06 UTC",
    "updated_date": "2025-05-13 05:25:06 UTC"
  },
  {
    "arxiv_id": "2505.08228v1",
    "title": "Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix",
    "authors": [
      "Unai Gurbindo",
      "Axel Brando",
      "Jaume Abella",
      "Caroline König"
    ],
    "abstract": "Enhancing the robustness of object detection systems under adverse weather\nconditions is crucial for the advancement of autonomous driving technology.\nThis study presents a novel approach leveraging the diffusion model Instruct\nPix2Pix to develop prompting methodologies that generate realistic datasets\nwith weather-based augmentations aiming to mitigate the impact of adverse\nweather on the perception capabilities of state-of-the-art object detection\nmodels, including Faster R-CNN and YOLOv10. Experiments were conducted in two\nenvironments, in the CARLA simulator where an initial evaluation of the\nproposed data augmentation was provided, and then on the real-world image data\nsets BDD100K and ACDC demonstrating the effectiveness of the approach in real\nenvironments.\n  The key contributions of this work are twofold: (1) identifying and\nquantifying the performance gap in object detection models under challenging\nweather conditions, and (2) demonstrating how tailored data augmentation\nstrategies can significantly enhance the robustness of these models. This\nresearch establishes a solid foundation for improving the reliability of\nperception systems in demanding environmental scenarios, and provides a pathway\nfor future advancements in autonomous driving.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.6; I.2.10; I.4.8; I.5.1"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 5 figures. Accepted at the International Joint Conference on\n  Neural Networks (IJCNN) 2025 (to appear)",
    "pdf_url": "http://arxiv.org/pdf/2505.08228v1",
    "published_date": "2025-05-13 05:12:07 UTC",
    "updated_date": "2025-05-13 05:12:07 UTC"
  },
  {
    "arxiv_id": "2505.08223v1",
    "title": "Reinforcement Learning-based Fault-Tolerant Control for Quadrotor with Online Transformer Adaptation",
    "authors": [
      "Dohyun Kim",
      "Jayden Dongwoo Lee",
      "Hyochoong Bang",
      "Jungho Bae"
    ],
    "abstract": "Multirotors play a significant role in diverse field robotics applications\nbut remain highly susceptible to actuator failures, leading to rapid\ninstability and compromised mission reliability. While various fault-tolerant\ncontrol (FTC) strategies using reinforcement learning (RL) have been widely\nexplored, most previous approaches require prior knowledge of the multirotor\nmodel or struggle to adapt to new configurations. To address these limitations,\nwe propose a novel hybrid RL-based FTC framework integrated with a\ntransformer-based online adaptation module. Our framework leverages a\ntransformer architecture to infer latent representations in real time, enabling\nadaptation to previously unseen system models without retraining. We evaluate\nour method in a PyBullet simulation under loss-of-effectiveness actuator\nfaults, achieving a 95% success rate and a positional root mean square error\n(RMSE) of 0.129 m, outperforming existing adaptation methods with 86% success\nand an RMSE of 0.153 m. Further evaluations on quadrotors with varying\nconfigurations confirm the robustness of our framework across untrained\ndynamics. These results demonstrate the potential of our framework to enhance\nthe adaptability and reliability of multirotors, enabling efficient fault\nmanagement in dynamic and uncertain environments. Website is available at\nhttp://00dhkim.me/paper/rl-ftc",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accpted at the 2025 IEEE International Conference on Robotics &\n  Automation (ICRA) Workshop: Robots in the Wild",
    "pdf_url": "http://arxiv.org/pdf/2505.08223v1",
    "published_date": "2025-05-13 04:50:29 UTC",
    "updated_date": "2025-05-13 04:50:29 UTC"
  },
  {
    "arxiv_id": "2505.08222v1",
    "title": "Scaling Multi Agent Reinforcement Learning for Underwater Acoustic Tracking via Autonomous Vehicles",
    "authors": [
      "Matteo Gallici",
      "Ivan Masmitja",
      "Mario Martín"
    ],
    "abstract": "Autonomous vehicles (AV) offer a cost-effective solution for scientific\nmissions such as underwater tracking. Recently, reinforcement learning (RL) has\nemerged as a powerful method for controlling AVs in complex marine\nenvironments. However, scaling these techniques to a fleet--essential for\nmulti-target tracking or targets with rapid, unpredictable motion--presents\nsignificant computational challenges. Multi-Agent Reinforcement Learning (MARL)\nis notoriously sample-inefficient, and while high-fidelity simulators like\nGazebo's LRAUV provide 100x faster-than-real-time single-robot simulations,\nthey offer no significant speedup for multi-vehicle scenarios, making MARL\ntraining impractical. To address these limitations, we propose an iterative\ndistillation method that transfers high-fidelity simulations into a simplified,\nGPU-accelerated environment while preserving high-level dynamics. This approach\nachieves up to a 30,000x speedup over Gazebo through parallelization, enabling\nefficient training via end-to-end GPU acceleration. Additionally, we introduce\na novel Transformer-based architecture (TransfMAPPO) that learns multi-agent\npolicies invariant to the number of agents and targets, significantly improving\nsample efficiency. Following large-scale curriculum learning conducted entirely\non GPU, we perform extensive evaluations in Gazebo, demonstrating that our\nmethod maintains tracking errors below 5 meters over extended durations, even\nin the presence of multiple fast-moving targets. This work bridges the gap\nbetween large-scale MARL training and high-fidelity deployment, providing a\nscalable framework for autonomous fleet control in real-world sea missions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08222v1",
    "published_date": "2025-05-13 04:42:30 UTC",
    "updated_date": "2025-05-13 04:42:30 UTC"
  },
  {
    "arxiv_id": "2505.08215v1",
    "title": "Unveiling the Best Practices for Applying Speech Foundation Models to Speech Intelligibility Prediction for Hearing-Impaired People",
    "authors": [
      "Haoshuai Zhou",
      "Boxuan Cao",
      "Changgeng Mo",
      "Linkai Li",
      "Shan Xiang Wang"
    ],
    "abstract": "Speech foundation models (SFMs) have demonstrated strong performance across a\nvariety of downstream tasks, including speech intelligibility prediction for\nhearing-impaired people (SIP-HI). However, optimizing SFMs for SIP-HI has been\ninsufficiently explored. In this paper, we conduct a comprehensive study to\nidentify key design factors affecting SIP-HI performance with 5 SFMs, focusing\non encoder layer selection, prediction head architecture, and ensemble\nconfigurations. Our findings show that, contrary to traditional use-all-layers\nmethods, selecting a single encoder layer yields better results. Additionally,\ntemporal modeling is crucial for effective prediction heads. We also\ndemonstrate that ensembling multiple SFMs improves performance, with stronger\nindividual models providing greater benefit. Finally, we explore the\nrelationship between key SFM attributes and their impact on SIP-HI performance.\nOur study offers practical insights into effectively adapting SFMs for speech\nintelligibility prediction for hearing-impaired populations.",
    "categories": [
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08215v1",
    "published_date": "2025-05-13 04:07:59 UTC",
    "updated_date": "2025-05-13 04:07:59 UTC"
  },
  {
    "arxiv_id": "2505.08202v1",
    "title": "AI and Generative AI Transforming Disaster Management: A Survey of Damage Assessment and Response Techniques",
    "authors": [
      "Aman Raj",
      "Lakshit Arora",
      "Sanjay Surendranath Girija",
      "Shashank Kapoor",
      "Dipen Pradhan",
      "Ankit Shetgaonkar"
    ],
    "abstract": "Natural disasters, including earthquakes, wildfires and cyclones, bear a huge\nrisk on human lives as well as infrastructure assets. An effective response to\ndisaster depends on the ability to rapidly and efficiently assess the intensity\nof damage. Artificial Intelligence (AI) and Generative Artificial Intelligence\n(GenAI) presents a breakthrough solution, capable of combining knowledge from\nmultiple types and sources of data, simulating realistic scenarios of disaster,\nand identifying emerging trends at a speed previously unimaginable. In this\npaper, we present a comprehensive review on the prospects of AI and GenAI in\ndamage assessment for various natural disasters, highlighting both its\nstrengths and limitations. We talk about its application to multimodal data\nsuch as text, image, video, and audio, and also cover major issues of data\nprivacy, security, and ethical use of the technology during crises. The paper\nalso recognizes the threat of Generative AI misuse, in the form of\ndissemination of misinformation and for adversarial attacks. Finally, we\noutline avenues of future research, emphasizing the need for secure, reliable,\nand ethical Generative AI systems for disaster management in general. We\nbelieve that this work represents the first comprehensive survey of Gen-AI\ntechniques being used in the field of Disaster Assessment and Response.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted in IEEE Compsac 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08202v1",
    "published_date": "2025-05-13 03:33:31 UTC",
    "updated_date": "2025-05-13 03:33:31 UTC"
  },
  {
    "arxiv_id": "2505.08200v1",
    "title": "A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection in LLM Outputs",
    "authors": [
      "Artem Shelmanov",
      "Ekaterina Fadeeva",
      "Akim Tsvigun",
      "Ivan Tsvigun",
      "Zhuohan Xie",
      "Igor Kiselev",
      "Nico Daheim",
      "Caiqi Zhang",
      "Artem Vazhentsev",
      "Mrinmaya Sachan",
      "Preslav Nakov",
      "Timothy Baldwin"
    ],
    "abstract": "Large Language Models (LLMs) have the tendency to hallucinate, i.e., to\nsporadically generate false or fabricated information. This presents a major\nchallenge, as hallucinations often appear highly convincing and users generally\nlack the tools to detect them. Uncertainty quantification (UQ) provides a\nframework for assessing the reliability of model outputs, aiding in the\nidentification of potential hallucinations. In this work, we introduce\npre-trained UQ heads: supervised auxiliary modules for LLMs that substantially\nenhance their ability to capture uncertainty compared to unsupervised UQ\nmethods. Their strong performance stems from the powerful Transformer\narchitecture in their design and informative features derived from LLM\nattention maps. Experimental evaluation shows that these heads are highly\nrobust and achieve state-of-the-art performance in claim-level hallucination\ndetection across both in-domain and out-of-domain prompts. Moreover, these\nmodules demonstrate strong generalization to languages they were not explicitly\ntrained on. We pre-train a collection of UQ heads for popular LLM series,\nincluding Mistral, Llama, and Gemma 2. We publicly release both the code and\nthe pre-trained heads.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08200v1",
    "published_date": "2025-05-13 03:30:26 UTC",
    "updated_date": "2025-05-13 03:30:26 UTC"
  },
  {
    "arxiv_id": "2505.08830v1",
    "title": "Federated Large Language Models: Feasibility, Robustness, Security and Future Directions",
    "authors": [
      "Wenhao Jiang",
      "Yuchuan Luo",
      "Guilin Deng",
      "Silong Chen",
      "Xu Yang",
      "Shihong Wu",
      "Xinwen Gao",
      "Lin Liu",
      "Shaojing Fu"
    ],
    "abstract": "The integration of Large Language Models (LLMs) and Federated Learning (FL)\npresents a promising solution for joint training on distributed data while\npreserving privacy and addressing data silo issues. However, this emerging\nfield, known as Federated Large Language Models (FLLM), faces significant\nchallenges, including communication and computation overheads, heterogeneity,\nprivacy and security concerns. Current research has primarily focused on the\nfeasibility of FLLM, but future trends are expected to emphasize enhancing\nsystem robustness and security. This paper provides a comprehensive review of\nthe latest advancements in FLLM, examining challenges from four critical\nperspectives: feasibility, robustness, security, and future directions. We\npresent an exhaustive survey of existing studies on FLLM feasibility, introduce\nmethods to enhance robustness in the face of resource, data, and task\nheterogeneity, and analyze novel risks associated with this integration,\nincluding privacy threats and security challenges. We also review the latest\ndevelopments in defense mechanisms and explore promising future research\ndirections, such as few-shot learning, machine unlearning, and IP protection.\nThis survey highlights the pressing need for further research to enhance system\nrobustness and security while addressing the unique challenges posed by the\nintegration of FL and LLM.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "35 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.08830v1",
    "published_date": "2025-05-13 03:23:54 UTC",
    "updated_date": "2025-05-13 03:23:54 UTC"
  },
  {
    "arxiv_id": "2505.08195v1",
    "title": "Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations",
    "authors": [
      "Jinming Hu",
      "Hassan Nawaz",
      "Yuting Rui",
      "Lijie Chi",
      "Arif Ullah",
      "Pavlo O. Dral"
    ],
    "abstract": "We have developed Aitomia - a platform powered by AI to assist in performing\nAI-driven atomistic and quantum chemical (QC) simulations. This intelligent\nassistant platform is equipped with chatbots and AI agents to help experts and\nguide non-experts in setting up and running the atomistic simulations,\nmonitoring their computation status, analyzing the simulation results, and\nsummarizing them for the user in text and graphical forms. We achieve these\ngoals by exploiting fine-tuned open-source large language models (LLMs),\nrule-based agents, and a retrieval-augmented generation (RAG) system. Aitomia\nleverages the versatility of our MLatom ecosystem for AI-enhanced computational\nchemistry. This intelligent assistant is going to be integrated into the\nAitomistic Hub and XACS online computing services, with some functionality\nalready publicly available as described at http://mlatom.com/aitomia. Aitomia\nis expected to lower the barrier to performing atomistic simulations,\naccelerating research and development in the relevant fields.",
    "categories": [
      "physics.comp-ph",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "physics.chem-ph"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08195v1",
    "published_date": "2025-05-13 03:11:41 UTC",
    "updated_date": "2025-05-13 03:11:41 UTC"
  },
  {
    "arxiv_id": "2505.08189v1",
    "title": "DSADF: Thinking Fast and Slow for Decision Making",
    "authors": [
      "Alex Zhihao Dou",
      "Dongfei Cui",
      "Jun Yan",
      "Weida Wang",
      "Benteng Chen",
      "Haoming Wang",
      "Zeke Xie",
      "Shufei Zhang"
    ],
    "abstract": "Although Reinforcement Learning (RL) agents are effective in well-defined\nenvironments, they often struggle to generalize their learned policies to\ndynamic settings due to their reliance on trial-and-error interactions. Recent\nwork has explored applying Large Language Models (LLMs) or Vision Language\nModels (VLMs) to boost the generalization of RL agents through policy\noptimization guidance or prior knowledge. However, these approaches often lack\nseamless coordination between the RL agent and the foundation model, leading to\nunreasonable decision-making in unfamiliar environments and efficiency\nbottlenecks. Making full use of the inferential capabilities of foundation\nmodels and the rapid response capabilities of RL agents and enhancing the\ninteraction between the two to form a dual system is still a lingering\nscientific question. To address this problem, we draw inspiration from\nKahneman's theory of fast thinking (System 1) and slow thinking (System 2),\ndemonstrating that balancing intuition and deep reasoning can achieve nimble\ndecision-making in a complex world. In this study, we propose a Dual-System\nAdaptive Decision Framework (DSADF), integrating two complementary modules:\nSystem 1, comprising an RL agent and a memory space for fast and intuitive\ndecision making, and System 2, driven by a VLM for deep and analytical\nreasoning. DSADF facilitates efficient and adaptive decision-making by\ncombining the strengths of both systems. The empirical study in the video game\nenvironment: Crafter and Housekeep demonstrates the effectiveness of our\nproposed method, showing significant improvements in decision abilities for\nboth unseen and known tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08189v1",
    "published_date": "2025-05-13 02:58:04 UTC",
    "updated_date": "2025-05-13 02:58:04 UTC"
  },
  {
    "arxiv_id": "2505.08179v1",
    "title": "Feasibility-Aware Pessimistic Estimation: Toward Long-Horizon Safety in Offline RL",
    "authors": [
      "Zhikun Tao",
      "Gang Xiong",
      "He Fang",
      "Zhen Shen",
      "Yunjun Han",
      "Qing-Shan Jia"
    ],
    "abstract": "Offline safe reinforcement learning(OSRL) derives constraint-satisfying\npolicies from pre-collected datasets, offers a promising avenue for deploying\nRL in safety-critical real-world domains such as robotics. However, the\nmajority of existing approaches emphasize only short-term safety, neglecting\nlong-horizon considerations. Consequently, they may violate safety constraints\nand fail to ensure sustained protection during online deployment. Moreover, the\nlearned policies often struggle to handle states and actions that are not\npresent or out-of-distribution(OOD) from the offline dataset, and exhibit\nlimited sample efficiency. To address these challenges, we propose a novel\nframework Feasibility-Aware offline Safe Reinforcement Learning with CVAE-based\nPessimism (FASP). First, we employ Hamilton-Jacobi (H-J) reachability analysis\nto generate reliable safety labels, which serve as supervisory signals for\ntraining both a conditional variational autoencoder (CVAE) and a safety\nclassifier. This approach not only ensures high sampling efficiency but also\nprovides rigorous long-horizon safety guarantees. Furthermore, we utilize\npessimistic estimation methods to estimate the Q-value of reward and cost,\nwhich mitigates the extrapolation errors induces by OOD actions, and penalize\nunsafe actions to enabled the agent to proactively avoid high-risk behaviors.\nMoreover, we theoretically prove the validity of this pessimistic estimation.\nExtensive experiments on DSRL benchmarks demonstrate that FASP algorithm\nachieves competitive performance across multiple experimental tasks,\nparticularly outperforming state-of-the-art algorithms in terms of safety.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08179v1",
    "published_date": "2025-05-13 02:32:49 UTC",
    "updated_date": "2025-05-13 02:32:49 UTC"
  },
  {
    "arxiv_id": "2505.08176v1",
    "title": "Behind the Noise: Conformal Quantile Regression Reveals Emergent Representations",
    "authors": [
      "Petrus H. Zwart",
      "Tamas Varga",
      "Odeta Qafoku",
      "James A. Sethian"
    ],
    "abstract": "Scientific imaging often involves long acquisition times to obtain\nhigh-quality data, especially when probing complex, heterogeneous systems.\nHowever, reducing acquisition time to increase throughput inevitably introduces\nsignificant noise into the measurements. We present a machine learning approach\nthat not only denoises low-quality measurements with calibrated uncertainty\nbounds, but also reveals emergent structure in the latent space. By using\nensembles of lightweight, randomly structured neural networks trained via\nconformal quantile regression, our method performs reliable denoising while\nuncovering interpretable spatial and chemical features -- without requiring\nlabels or segmentation. Unlike conventional approaches focused solely on image\nrestoration, our framework leverages the denoising process itself to drive the\nemergence of meaningful representations. We validate the approach on real-world\ngeobiochemical imaging data, showing how it supports confident interpretation\nand guides experimental design under resource constraints.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08176v1",
    "published_date": "2025-05-13 02:27:12 UTC",
    "updated_date": "2025-05-13 02:27:12 UTC"
  },
  {
    "arxiv_id": "2505.08175v2",
    "title": "Fast Text-to-Audio Generation with Adversarial Post-Training",
    "authors": [
      "Zachary Novack",
      "Zach Evans",
      "Zack Zukowski",
      "Josiah Taylor",
      "CJ Carr",
      "Julian Parker",
      "Adnan Al-Sinan",
      "Gian Marco Iodice",
      "Julian McAuley",
      "Taylor Berg-Kirkpatrick",
      "Jordi Pons"
    ],
    "abstract": "Text-to-audio systems, while increasingly performant, are slow at inference\ntime, thus making their latency unpractical for many creative applications. We\npresent Adversarial Relativistic-Contrastive (ARC) post-training, the first\nadversarial acceleration algorithm for diffusion/flow models not based on\ndistillation. While past adversarial post-training methods have struggled to\ncompare against their expensive distillation counterparts, ARC post-training is\na simple procedure that (1) extends a recent relativistic adversarial\nformulation to diffusion/flow post-training and (2) combines it with a novel\ncontrastive discriminator objective to encourage better prompt adherence. We\npair ARC post-training with a number optimizations to Stable Audio Open and\nbuild a model capable of generating $\\approx$12s of 44.1kHz stereo audio in\n$\\approx$75ms on an H100, and $\\approx$7s on a mobile edge-device, the fastest\ntext-to-audio model to our knowledge.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08175v2",
    "published_date": "2025-05-13 02:25:47 UTC",
    "updated_date": "2025-05-14 06:07:26 UTC"
  },
  {
    "arxiv_id": "2505.08168v1",
    "title": "Exploiting Text Semantics for Few and Zero Shot Node Classification on Text-attributed Graph",
    "authors": [
      "Yuxiang Wang",
      "Xiao Yan",
      "Shiyu Jin",
      "Quanqing Xu",
      "Chuang Hu",
      "Yuanyuan Zhu",
      "Bo Du",
      "Jia Wu",
      "Jiawei Jiang"
    ],
    "abstract": "Text-attributed graph (TAG) provides a text description for each graph node,\nand few- and zero-shot node classification on TAGs have many applications in\nfields such as academia and social networks. Existing work utilizes various\ngraph-based augmentation techniques to train the node and text embeddings,\nwhile text-based augmentations are largely unexplored. In this paper, we\npropose Text Semantics Augmentation (TSA) to improve accuracy by introducing\nmore text semantic supervision signals. Specifically, we design two\naugmentation techniques, i.e., positive semantics matching and negative\nsemantics contrast, to provide more reference texts for each graph node or text\ndescription. Positive semantic matching retrieves texts with similar embeddings\nto match with a graph node. Negative semantic contrast adds a negative prompt\nto construct a text description with the opposite semantics, which is\ncontrasted with the original node and text. We evaluate TSA on 5 datasets and\ncompare with 13 state-of-the-art baselines. The results show that TSA\nconsistently outperforms all baselines, and its accuracy improvements over the\nbest-performing baseline are usually over 5%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08168v1",
    "published_date": "2025-05-13 02:06:08 UTC",
    "updated_date": "2025-05-13 02:06:08 UTC"
  },
  {
    "arxiv_id": "2505.08167v2",
    "title": "Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage",
    "authors": [
      "Ruilin Liu",
      "Zhixiao Zhao",
      "Jieqiong Li",
      "Chang Liu",
      "Dongbo Wang"
    ],
    "abstract": "The rapid development of large language models (LLMs) has provided\nsignificant support and opportunities for the advancement of domain-specific\nLLMs. However, fine-tuning these large models using Intangible Cultural\nHeritage (ICH) data inevitably faces challenges such as bias, incorrect\nknowledge inheritance, and catastrophic forgetting. To address these issues, we\npropose a novel training method that integrates a bidirectional chains of\nthought and a reward mechanism. This method is built upon ICH-Qwen, a large\nlanguage model specifically designed for the field of intangible cultural\nheritage. The proposed method enables the model to not only perform forward\nreasoning but also enhances the accuracy of the generated answers by utilizing\nreverse questioning and reverse reasoning to activate the model's latent\nknowledge. Additionally, a reward mechanism is introduced during training to\noptimize the decision-making process. This mechanism improves the quality of\nthe model's outputs through structural and content evaluations with different\nweighting schemes. We conduct comparative experiments on ICH-Qwen, with results\ndemonstrating that our method outperforms 0-shot, step-by-step reasoning,\nknowledge distillation, and question augmentation methods in terms of accuracy,\nBleu-4, and Rouge-L scores on the question-answering task. Furthermore, the\npaper highlights the effectiveness of combining the bidirectional chains of\nthought and reward mechanism through ablation experiments. In addition, a\nseries of generalizability experiments are conducted, with results showing that\nthe proposed method yields improvements on various domain-specific datasets and\nadvanced models in areas such as Finance, Wikidata, and StrategyQA. This\ndemonstrates that the method is adaptable to multiple domains and provides a\nvaluable approach for model training in future applications across diverse\nfields.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.08167v2",
    "published_date": "2025-05-13 02:05:25 UTC",
    "updated_date": "2025-05-14 01:35:33 UTC"
  },
  {
    "arxiv_id": "2505.08163v1",
    "title": "Decoding Neighborhood Environments with Large Language Models",
    "authors": [
      "Andrew Cart",
      "Shaohu Zhang",
      "Melanie Escue",
      "Xugui Zhou",
      "Haitao Zhao",
      "Prashanth BusiReddyGari",
      "Beiyu Lin",
      "Shuang Li"
    ],
    "abstract": "Neighborhood environments include physical and environmental conditions such\nas housing quality, roads, and sidewalks, which significantly influence human\nhealth and well-being. Traditional methods for assessing these environments,\nincluding field surveys and geographic information systems (GIS), are\nresource-intensive and challenging to evaluate neighborhood environments at\nscale. Although machine learning offers potential for automated analysis, the\nlaborious process of labeling training data and the lack of accessible models\nhinder scalability. This study explores the feasibility of large language\nmodels (LLMs) such as ChatGPT and Gemini as tools for decoding neighborhood\nenvironments (e.g., sidewalk and powerline) at scale. We train a robust\nYOLOv11-based model, which achieves an average accuracy of 99.13% in detecting\nsix environmental indicators, including streetlight, sidewalk, powerline,\napartment, single-lane road, and multilane road. We then evaluate four LLMs,\nincluding ChatGPT, Gemini, Claude, and Grok, to assess their feasibility,\nrobustness, and limitations in identifying these indicators, with a focus on\nthe impact of prompting strategies and fine-tuning. We apply majority voting\nwith the top three LLMs to achieve over 88% accuracy, which demonstrates LLMs\ncould be a useful tool to decode the neighborhood environment without any\ntraining effort.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.08163v1",
    "published_date": "2025-05-13 01:54:54 UTC",
    "updated_date": "2025-05-13 01:54:54 UTC"
  },
  {
    "arxiv_id": "2505.08158v1",
    "title": "Feature Fitted Online Conformal Prediction for Deep Time Series Forecasting Model",
    "authors": [
      "Xiannan Huang",
      "Shuhan Qiu"
    ],
    "abstract": "Time series forecasting is critical for many applications, where deep\nlearning-based point prediction models have demonstrated strong performance.\nHowever, in practical scenarios, there is also a need to quantify predictive\nuncertainty through online confidence intervals. Existing confidence interval\nmodeling approaches building upon these deep point prediction models suffer\nfrom key limitations: they either require costly retraining, fail to fully\nleverage the representational strengths of deep models, or lack theoretical\nguarantees. To address these gaps, we propose a lightweight conformal\nprediction method that provides valid coverage and shorter interval lengths\nwithout retraining. Our approach leverages features extracted from pre-trained\npoint prediction models to fit a residual predictor and construct confidence\nintervals, further enhanced by an adaptive coverage control mechanism.\nTheoretically, we prove that our method achieves asymptotic coverage\nconvergence, with error bounds dependent on the feature quality of the\nunderlying point prediction model. Experiments on 12 datasets demonstrate that\nour method delivers tighter confidence intervals while maintaining desired\ncoverage rates. Code, model and dataset in\n\\href{https://github.com/xiannanhuang/FFDCI}{Github}",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08158v1",
    "published_date": "2025-05-13 01:33:53 UTC",
    "updated_date": "2025-05-13 01:33:53 UTC"
  },
  {
    "arxiv_id": "2505.08157v1",
    "title": "Hyperbolic Contrastive Learning with Model-augmentation for Knowledge-aware Recommendation",
    "authors": [
      "Shengyin Sun",
      "Chen Ma"
    ],
    "abstract": "Benefiting from the effectiveness of graph neural networks (GNNs) and\ncontrastive learning, GNN-based contrastive learning has become mainstream for\nknowledge-aware recommendation. However, most existing contrastive\nlearning-based methods have difficulties in effectively capturing the\nunderlying hierarchical structure within user-item bipartite graphs and\nknowledge graphs. Moreover, they commonly generate positive samples for\ncontrastive learning by perturbing the graph structure, which may lead to a\nshift in user preference learning. To overcome these limitations, we propose\nhyperbolic contrastive learning with model-augmentation for knowledge-aware\nrecommendation. To capture the intrinsic hierarchical graph structures, we\nfirst design a novel Lorentzian knowledge aggregation mechanism, which enables\nmore effective representations of users and items. Then, we propose three\nmodel-level augmentation techniques to assist Hyperbolic contrastive learning.\nDifferent from the classical structure-level augmentation (e.g., edge\ndropping), the proposed model-augmentations can avoid preference shifts between\nthe augmented positive pair. Finally, we conduct extensive experiments to\ndemonstrate the superiority (maximum improvement of $11.03\\%$) of proposed\nmethods over existing baselines.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.08157v1",
    "published_date": "2025-05-13 01:30:27 UTC",
    "updated_date": "2025-05-13 01:30:27 UTC"
  },
  {
    "arxiv_id": "2505.08155v1",
    "title": "Efficient and Scalable Neural Symbolic Search for Knowledge Graph Complex Query Answering",
    "authors": [
      "Weizhi Fei",
      "Zihao Wang",
      "hang Yin",
      "Shukai Zhao",
      "Wei Zhang",
      "Yangqiu Song"
    ],
    "abstract": "Complex Query Answering (CQA) aims to retrieve answer sets for complex\nlogical formulas from incomplete knowledge graphs, which is a crucial yet\nchallenging task in knowledge graph reasoning. While neuro-symbolic search\nutilized neural link predictions achieve superior accuracy, they encounter\nsignificant complexity bottlenecks: (i) Data complexity typically scales\nquadratically with the number of entities in the knowledge graph, and (ii)\nQuery complexity becomes NP-hard for cyclic queries. Consequently, these\napproaches struggle to effectively scale to larger knowledge graphs and more\ncomplex queries. To address these challenges, we propose an efficient and\nscalable symbolic search framework. First, we propose two constraint strategies\nto compute neural logical indices to reduce the domain of variables, thereby\ndecreasing the data complexity of symbolic search. Additionally, we introduce\nan approximate algorithm based on local search to tackle the NP query\ncomplexity of cyclic queries. Experiments on various CQA benchmarks demonstrate\nthat our framework reduces the computational load of symbolic methods by 90\\%\nwhile maintaining nearly the same performance, thus alleviating both efficiency\nand scalability issues.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08155v1",
    "published_date": "2025-05-13 01:24:09 UTC",
    "updated_date": "2025-05-13 01:24:09 UTC"
  },
  {
    "arxiv_id": "2505.08151v1",
    "title": "Foundation Models Knowledge Distillation For Battery Capacity Degradation Forecast",
    "authors": [
      "Joey Chan",
      "Zhen Chen",
      "Ershun Pan"
    ],
    "abstract": "Accurate estimation of lithium-ion battery capacity degradation is critical\nfor enhancing the reliability and safety of battery operations. Traditional\nexpert models, tailored to specific scenarios, provide isolated estimations.\nWith the rapid advancement of data-driven techniques, a series of\ngeneral-purpose time-series foundation models have been developed. However,\nfoundation models specifically designed for battery capacity degradation remain\nlargely unexplored. To enable zero-shot generalization in battery degradation\nprediction using large model technology, this study proposes a\ndegradation-aware fine-tuning strategy for time-series foundation models. We\napply this strategy to fine-tune the Timer model on approximately 10 GB of\nopen-source battery charge discharge data. Validation on our released\nCycleLife-SJTUIE dataset demonstrates that the fine-tuned Battery-Timer\npossesses strong zero-shot generalization capability in capacity degradation\nforecasting. To address the computational challenges of deploying large models,\nwe further propose a knowledge distillation framework that transfers the\nknowledge of pre-trained foundation models into compact expert models.\nDistillation results across several state-of-the-art time-series expert models\nconfirm that foundation model knowledge significantly improves the\nmulti-condition generalization of expert models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08151v1",
    "published_date": "2025-05-13 01:03:35 UTC",
    "updated_date": "2025-05-13 01:03:35 UTC"
  },
  {
    "arxiv_id": "2505.08829v2",
    "title": "Aggregating Concepts of Accuracy and Fairness in Prediction Algorithms",
    "authors": [
      "David Kinney"
    ],
    "abstract": "An algorithm that outputs predictions about the state of the world will\nalmost always be designed with the implicit or explicit goal of outputting\naccurate predictions (i.e., predictions that are likely to be true). In\naddition, the rise of increasingly powerful predictive algorithms brought about\nby the recent revolution in artificial intelligence has led to an emphasis on\nbuilding predictive algorithms that are fair, in the sense that their\npredictions do not systematically evince bias or bring about harm to certain\nindividuals or groups. This state of affairs presents two conceptual\nchallenges. First, the goals of accuracy and fairness can sometimes be in\ntension, and there are no obvious normative guidelines for managing the\ntrade-offs between these two desiderata when they arise. Second, there are many\ndistinct ways of measuring both the accuracy and fairness of a predictive\nalgorithm; here too, there are no obvious guidelines on how to aggregate our\npreferences for predictive algorithms that satisfy disparate measures of\nfairness and accuracy to various extents. The goal of this paper is to address\nthese challenges by arguing that there are good reasons for using a linear\ncombination of accuracy and fairness metrics to measure the\nall-things-considered value of a predictive algorithm for agents who care about\nboth accuracy and fairness. My argument depends crucially on a classic result\nin the preference aggregation literature due to Harsanyi. After making this\nformal argument, I apply my result to an analysis of accuracy-fairness\ntrade-offs using the COMPAS dataset compiled by Angwin et al.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08829v2",
    "published_date": "2025-05-13 01:00:25 UTC",
    "updated_date": "2025-05-15 12:19:18 UTC"
  },
  {
    "arxiv_id": "2505.08148v1",
    "title": "A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem",
    "authors": [
      "Sunday Oyinlola Ogundoyin",
      "Muhammad Ikram",
      "Hassan Jameel Asghar",
      "Benjamin Zi Hao Zhao",
      "Dali Kaafar"
    ],
    "abstract": "Millions of users leverage generative pretrained transformer (GPT)-based\nlanguage models developed by leading model providers for a wide range of tasks.\nTo support enhanced user interaction and customization, many platforms-such as\nOpenAI-now enable developers to create and publish tailored model instances,\nknown as custom GPTs, via dedicated repositories or application stores. These\ncustom GPTs empower users to browse and interact with specialized applications\ndesigned to meet specific needs. However, as custom GPTs see growing adoption,\nconcerns regarding their security vulnerabilities have intensified. Existing\nresearch on these vulnerabilities remains largely theoretical, often lacking\nempirical, large-scale, and statistically rigorous assessments of associated\nrisks.\n  In this study, we analyze 14,904 custom GPTs to assess their susceptibility\nto seven exploitable threats, such as roleplay-based attacks, system prompt\nleakage, phishing content generation, and malicious code synthesis, across\nvarious categories and popularity tiers within the OpenAI marketplace. We\nintroduce a multi-metric ranking system to examine the relationship between a\ncustom GPT's popularity and its associated security risks.\n  Our findings reveal that over 95% of custom GPTs lack adequate security\nprotections. The most prevalent vulnerabilities include roleplay-based\nvulnerabilities (96.51%), system prompt leakage (92.20%), and phishing\n(91.22%). Furthermore, we demonstrate that OpenAI's foundational models exhibit\ninherent security weaknesses, which are often inherited or amplified in custom\nGPTs. These results highlight the urgent need for enhanced security measures\nand stricter content moderation to ensure the safe deployment of GPT-based\napplications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08148v1",
    "published_date": "2025-05-13 00:51:07 UTC",
    "updated_date": "2025-05-13 00:51:07 UTC"
  },
  {
    "arxiv_id": "2505.08828v1",
    "title": "Human-AI Collaboration or Academic Misconduct? Measuring AI Use in Student Writing Through Stylometric Evidence",
    "authors": [
      "Eduardo Araujo Oliveira",
      "Madhavi Mohoni",
      "Sonsoles López-Pernas",
      "Mohammed Saqr"
    ],
    "abstract": "As human-AI collaboration becomes increasingly prevalent in educational\ncontexts, understanding and measuring the extent and nature of such\ninteractions pose significant challenges. This research investigates the use of\nauthorship verification (AV) techniques not as a punitive measure, but as a\nmeans to quantify AI assistance in academic writing, with a focus on promoting\ntransparency, interpretability, and student development. Building on prior\nwork, we structured our investigation into three stages: dataset selection and\nexpansion, AV method development, and systematic evaluation. Using three\ndatasets - including a public dataset (PAN-14) and two from University of\nMelbourne students from various courses - we expanded the data to include\nLLM-generated texts, totalling 1,889 documents and 540 authorship problems from\n506 students. We developed an adapted Feature Vector Difference AV methodology\nto construct robust academic writing profiles for students, designed to capture\nmeaningful, individual characteristics of their writing. The method's\neffectiveness was evaluated across multiple scenarios, including distinguishing\nbetween student-authored and LLM-generated texts and testing resilience against\nLLMs' attempts to mimic student writing styles. Results demonstrate the\nenhanced AV classifier's ability to identify stylometric discrepancies and\nmeasure human-AI collaboration at word and sentence levels while providing\neducators with a transparent tool to support academic integrity investigations.\nThis work advances AV technology, offering actionable insights into the\ndynamics of academic writing in an AI-driven era.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 10 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.08828v1",
    "published_date": "2025-05-13 00:36:36 UTC",
    "updated_date": "2025-05-13 00:36:36 UTC"
  },
  {
    "arxiv_id": "2505.08143v1",
    "title": "Communication Styles and Reader Preferences of LLM and Human Experts in Explaining Health Information",
    "authors": [
      "Jiawei Zhou",
      "Kritika Venkatachalam",
      "Minje Choi",
      "Koustuv Saha",
      "Munmun De Choudhury"
    ],
    "abstract": "With the wide adoption of large language models (LLMs) in information\nassistance, it is essential to examine their alignment with human communication\nstyles and values. We situate this study within the context of fact-checking\nhealth information, given the critical challenge of rectifying conceptions and\nbuilding trust. Recent studies have explored the potential of LLM for health\ncommunication, but style differences between LLMs and human experts and\nassociated reader perceptions remain under-explored. In this light, our study\nevaluates the communication styles of LLMs, focusing on how their explanations\ndiffer from those of humans in three core components of health communication:\ninformation, sender, and receiver. We compiled a dataset of 1498 health\nmisinformation explanations from authoritative fact-checking organizations and\ngenerated LLM responses to inaccurate health information. Drawing from health\ncommunication theory, we evaluate communication styles across three key\ndimensions of information linguistic features, sender persuasive strategies,\nand receiver value alignments. We further assessed human perceptions through a\nblinded evaluation with 99 participants. Our findings reveal that LLM-generated\narticles showed significantly lower scores in persuasive strategies, certainty\nexpressions, and alignment with social values and moral foundations. However,\nhuman evaluation demonstrated a strong preference for LLM content, with over\n60% responses favoring LLM articles for clarity, completeness, and\npersuasiveness. Our results suggest that LLMs' structured approach to\npresenting information may be more effective at engaging readers despite\nscoring lower on traditional measures of quality in fact-checking and health\ncommunication.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08143v1",
    "published_date": "2025-05-13 00:32:38 UTC",
    "updated_date": "2025-05-13 00:32:38 UTC"
  },
  {
    "arxiv_id": "2505.08140v1",
    "title": "Lost in Transmission: When and Why LLMs Fail to Reason Globally",
    "authors": [
      "Tobias Schnabel",
      "Kiran Tomlinson",
      "Adith Swaminathan",
      "Jennifer Neville"
    ],
    "abstract": "Despite their many successes, transformer-based large language models (LLMs)\ncontinue to struggle with tasks that require complex reasoning over large parts\nof their input. We argue that these failures arise due to capacity limits on\nthe accurate flow of information within LLMs. To formalize this issue, we\nintroduce the bounded attention prefix oracle (BAPO) model, a new computational\nframework that models bandwidth constraints on attention heads, the mechanism\nfor internal communication in LLMs. We show that several important reasoning\nproblems like graph reachability require high communication bandwidth for BAPOs\nto solve; we call these problems BAPO-hard. Our experiments corroborate our\ntheoretical predictions: GPT-4, Claude, and Gemini succeed on BAPO-easy tasks\nand fail even on relatively small BAPO-hard tasks. BAPOs also reveal another\nbenefit of chain of thought (CoT): we prove that breaking down a task using CoT\ncan turn any BAPO-hard problem into a BAPO-easy one. Our results offer\nprincipled explanations for key LLM failures and suggest directions for\narchitectures and inference methods that mitigate bandwidth limits.",
    "categories": [
      "cs.AI",
      "cs.FL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.08140v1",
    "published_date": "2025-05-13 00:25:23 UTC",
    "updated_date": "2025-05-13 00:25:23 UTC"
  },
  {
    "arxiv_id": "2505.08138v1",
    "title": "Mirror Mirror on the Wall, Have I Forgotten it All? A New Framework for Evaluating Machine Unlearning",
    "authors": [
      "Brennon Brimhall",
      "Philip Mathew",
      "Neil Fendley",
      "Yinzhi Cao",
      "Matthew Green"
    ],
    "abstract": "Machine unlearning methods take a model trained on a dataset and a forget\nset, then attempt to produce a model as if it had only been trained on the\nexamples not in the forget set. We empirically show that an adversary is able\nto distinguish between a mirror model (a control model produced by retraining\nwithout the data to forget) and a model produced by an unlearning method across\nrepresentative unlearning methods from the literature. We build distinguishing\nalgorithms based on evaluation scores in the literature (i.e. membership\ninference scores) and Kullback-Leibler divergence.\n  We propose a strong formal definition for machine unlearning called\ncomputational unlearning. Computational unlearning is defined as the inability\nfor an adversary to distinguish between a mirror model and a model produced by\nan unlearning method. If the adversary cannot guess better than random (except\nwith negligible probability), then we say that an unlearning method achieves\ncomputational unlearning.\n  Our computational unlearning definition provides theoretical structure to\nprove unlearning feasibility results. For example, our computational unlearning\ndefinition immediately implies that there are no deterministic computational\nunlearning methods for entropic learning algorithms. We also explore the\nrelationship between differential privacy (DP)-based unlearning methods and\ncomputational unlearning, showing that DP-based approaches can satisfy\ncomputational unlearning at the cost of an extreme utility collapse. These\nresults demonstrate that current methodology in the literature fundamentally\nfalls short of achieving computational unlearning. We conclude by identifying\nseveral open questions for future work.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08138v1",
    "published_date": "2025-05-13 00:23:17 UTC",
    "updated_date": "2025-05-13 00:23:17 UTC"
  },
  {
    "arxiv_id": "2505.08135v1",
    "title": "Leveraging AI for Productive and Trustworthy HPC Software: Challenges and Research Directions",
    "authors": [
      "Keita Teranishi",
      "Harshitha Menon",
      "William F. Godoy",
      "Prasanna Balaprakash",
      "David Bau",
      "Tal Ben-Nun",
      "Abhinav Bathele",
      "Franz Franchetti",
      "Michael Franusich",
      "Todd Gamblin",
      "Giorgis Georgakoudis",
      "Tom Goldstein",
      "Arjun Guha",
      "Steven Hahn",
      "Costin Iancu",
      "Zheming Jin",
      "Terry Jones",
      "Tze Meng Low",
      "Het Mankad",
      "Narasinga Rao Miniskar",
      "Mohammad Alaul Haque Monil",
      "Daniel Nichols",
      "Konstantinos Parasyris",
      "Swaroop Pophale",
      "Pedro Valero-Lara",
      "Jeffrey S. Vetter",
      "Samuel Williams",
      "Aaron Young"
    ],
    "abstract": "We discuss the challenges and propose research directions for using AI to\nrevolutionize the development of high-performance computing (HPC) software. AI\ntechnologies, in particular large language models, have transformed every\naspect of software development. For its part, HPC software is recognized as a\nhighly specialized scientific field of its own. We discuss the challenges\nassociated with leveraging state-of-the-art AI technologies to develop such a\nunique and niche class of software and outline our research directions in the\ntwo US Department of Energy--funded projects for advancing HPC Software via AI:\nEllora and Durban.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages, 1 Figure, Accepted at \"The 1st International Workshop on\n  Foundational Large Language Models Advances for HPC\" LLM4HPC to be held in\n  conjunction with ISC High Performance 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.08135v1",
    "published_date": "2025-05-13 00:12:45 UTC",
    "updated_date": "2025-05-13 00:12:45 UTC"
  },
  {
    "arxiv_id": "2505.08133v1",
    "title": "One Bad NOFO? AI Governance in Federal Grantmaking",
    "authors": [
      "Dan Bateyko",
      "Karen Levy"
    ],
    "abstract": "Much scholarship considers how U.S. federal agencies govern artificial\nintelligence (AI) through rulemaking and their own internal use policies. But\nagencies have an overlooked AI governance role: setting discretionary grant\npolicy when directing billions of dollars in federal financial assistance.\nThese dollars enable state and local entities to study, create, and use AI.\nThis funding not only goes to dedicated AI programs, but also to grantees using\nAI in the course of meeting their routine grant objectives. As discretionary\ngrantmakers, agencies guide and restrict what grant winners do -- a hidden\nlever for AI governance. Agencies pull this lever by setting program\nobjectives, judging criteria, and restrictions for AI use. Using a novel\ndataset of over 40,000 non-defense federal grant notices of funding opportunity\n(NOFOs) posted to Grants.gov between 2009 and 2024, we analyze how agencies\nregulate the use of AI by grantees. We select records mentioning AI and review\ntheir stated goals and requirements. We find agencies promoting AI in notice\nnarratives, shaping adoption in ways other records of grant policy might fail\nto capture. Of the grant opportunities that mention AI, we find only a handful\nof AI-specific judging criteria or restrictions. This silence holds even when\nagencies fund AI uses in contexts affecting people's rights and which, under an\nanalogous federal procurement regime, would result in extra oversight. These\nfindings recast grant notices as a site of AI policymaking -- albeit one that\nis developing out of step with other regulatory efforts and incomplete in its\nconsideration of transparency, accountability, and privacy protections. The\npaper concludes by drawing lessons from AI procurement scholarship, while\nidentifying distinct challenges in grantmaking that invite further study.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.5.2"
    ],
    "primary_category": "cs.CY",
    "comment": "In The 2025 ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT '25), June 23---26, 2025, Athens, Greece. 13 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.08133v1",
    "published_date": "2025-05-13 00:08:22 UTC",
    "updated_date": "2025-05-13 00:08:22 UTC"
  },
  {
    "arxiv_id": "2505.08130v1",
    "title": "ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval",
    "authors": [
      "Mingxu Tao",
      "Bowen Tang",
      "Mingxuan Ma",
      "Yining Zhang",
      "Hourun Li",
      "Feifan Wen",
      "Hao Ma",
      "Jia Yang"
    ],
    "abstract": "The rise of Large Language Models~(LLMs) revolutionizes information\nretrieval, allowing users to obtain required answers through complex\ninstructions within conversations. However, publicly available services remain\ninadequate in addressing the needs of faculty and students to search\ncampus-specific information. It is primarily due to the LLM's lack of\ndomain-specific knowledge and the limitation of search engines in supporting\nmultilingual and timely scenarios. To tackle these challenges, we introduce\nALOHA, a multilingual agent enhanced by hierarchical retrieval for university\norientation. We also integrate external APIs into the front-end interface to\nprovide interactive service. The human evaluation and case study show our\nproposed system has strong capabilities to yield correct, timely, and\nuser-friendly responses to the queries in multiple languages, surpassing\ncommercial chatbots and search engines. The system has been deployed and has\nprovided service for more than 12,000 people.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in NAACL 2025 Demo Track",
    "pdf_url": "http://arxiv.org/pdf/2505.08130v1",
    "published_date": "2025-05-13 00:01:03 UTC",
    "updated_date": "2025-05-13 00:01:03 UTC"
  },
  {
    "arxiv_id": "2505.08129v1",
    "title": "High-order Regularization for Machine Learning and Learning-based Control",
    "authors": [
      "Xinghua Liu",
      "Ming Cao"
    ],
    "abstract": "The paper proposes a novel regularization procedure for machine learning. The\nproposed high-order regularization (HR) provides new insight into\nregularization, which is widely used to train a neural network that can be\nutilized to approximate the action-value function in general reinforcement\nlearning problems. The proposed HR method ensures the provable convergence of\nthe approximation algorithm, which makes the much-needed connection between\nregularization and explainable learning using neural networks. The proposed HR\nmethod theoretically demonstrates that regularization can be regarded as an\napproximation in terms of inverse mapping with explicitly calculable\napproximation error, and the $L_2$ regularization is a lower-order case of the\nproposed method. We provide lower and upper bounds for the error of the\nproposed HR solution, which helps build a reliable model. We also find that\nregularization with the proposed HR can be regarded as a contraction. We prove\nthat the generalizability of neural networks can be maximized with a proper\nregularization matrix, and the proposed HR is applicable for neural networks\nwith any mapping matrix. With the theoretical explanation of the extreme\nlearning machine for neural network training and the proposed high-order\nregularization, one can better interpret the output of the neural network, thus\nleading to explainable learning. We present a case study based on regularized\nextreme learning neural networks to demonstrate the application of the proposed\nHR and give the corresponding incremental HR solution. We verify the\nperformance of the proposed HR method by solving a classic control problem in\nreinforcement learning. The result demonstrates the superior performance of the\nmethod with significant enhancement in the generalizability of the neural\nnetwork.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08129v1",
    "published_date": "2025-05-13 00:00:23 UTC",
    "updated_date": "2025-05-13 00:00:23 UTC"
  }
]