{
  "date": "2024-07-12",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-12 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的安全性、多模态学习、强化学习以及 LLM 在特定领域的创新应用，亮点包括 LLM 针对编程漏洞的攻击防御（如 MaPPing Your Model）和人类记忆机制的模拟（如 EM-LLM），以及知名学者如 Ian Foster 参与的电力网格基础模型研究，强调了 AI 在实际应用中的鲁棒性和高效性。\n\n下面，我挑选并简要讨论一些重要、相关或话题度高的论文，先从 LLM 和 AI 安全主题入手，再扩展到多模态学习和优化算法，其他次要论文将快速掠过。\n\n**1. MaPPing Your Model: Assessing the Impact of Adversarial Attacks on LLM-based Programming Assistants**  \n   这篇论文探讨了 LLM 在编程助手中的安全风险，引入 MaPP 攻击方法，通过在提示中添加少量文本诱导 LLM 生成漏洞代码。主要贡献是证明 LLM 易受攻击，且更先进的模型更易受影响，强调了强化提示安全和代码审计的必要性。\n\n**2. EM-LLM: Human-like Episodic Memory for Infinite Context LLMs**  \n   作者包括 Jun Wang 和 Haitham Bou-Ammar，这篇论文提出 EM-LLM，通过结合贝叶斯惊喜和图理论模拟人类情节记忆，帮助 LLM 处理无限上下文。关键发现是 EM-LLM 在长序列任务中超越传统模型，揭示了 LLM 与人类记忆机制的潜在桥梁。\n\n**3. TelecomGPT: A Framework to Build Telecom-Specific Large Language Models**  \n   这篇论文由 Merouane Debbah 等知名学者主导，开发了 TelecomGPT 框架，用于构建电信专用 LLM。主要贡献是通过特定数据集微调 LLM，提升在电信任务（如数学建模和代码生成）的性能，实现了与 GPT-4 相当的准确性。\n\n**4. FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3**  \n   论文提出 FairyLandAI 系统，使用 LLM 生成个性化童话并结合图像生成工具。核心发现是它能创建教育性故事，提升儿童学习体验，但也强调了文化适应性和道德价值的挑战。\n\n**5. Diagnosing and Re-learning for Balanced Multimodal Learning**  \n   这篇与 Diagnosing and Re-learning 方法相关，解决多模态学习中的不平衡问题。通过评估模态分离性并重新初始化编码器，主要贡献是提升多模态模型的鲁棒性，在各种框架中表现出色。\n\n**6. GRAD-SUM: Leveraging Gradient Summarization for Optimal Prompt Engineering**  \n   论文引入 GRAD-SUM 方法，使用梯度优化自动微调提示，实现高效的 LLM 提示工程。关键发现是它在多种基准上超越现有方法，适用于任务特定的提示优化。\n\n**7. Foundation Models for the Electric Power Grid**  \n   作者包括 Ian Foster 和 Ricardo J. Bessa 等知名专家，提出 GridFM 框架，使用图神经网络建模电力网格。主要贡献是展示基础模型如何处理电网不确定性，提升资源管理和 AI 应用效率。\n\n**8. Adaptive Prediction Ensemble: Improving Out-of-Distribution Generalization of Motion Forecasting**  \n   这篇论文开发了 APE 框架，结合深度学习和规则模型预测自主驾驶轨迹。通过动态路由函数提升 OOD 泛化，主要发现是它在长时预测中优于单一模型。\n\n**9. SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers**  \n   论文发布 SPIQA 数据集，支持多模态 QA 任务。核心贡献是使用 MLLM 进行图像和文本问答，显著提升科学文献理解的准确性。\n\n**10. Investigating the Interplay of Prioritized Replay and Generalization**  \n   这篇强化学习论文分析 Prioritized Experience Replay (PER)，发现 PER 在神经网络中行为复杂，通过延迟更新缓解错误激增。主要贡献是提出改进 PER 的策略，提升控制任务的性能。\n\n其他论文，如那些专注于特定数据集或小改进（例如某些图像生成或小众优化方法），由于篇幅有限和影响力较小，我将快速掠过，仅提及其存在。例如，FD-SOS 论文提出用于牙科图像分割的模型，贡献在于多模态检测，但细节不深究；类似地，部分强化学习论文如 CFaults 和 TPIA 展示了领域特定应用，但未列为重点。\n\n总之，今天的论文突显了 AI 领域的多样创新，LLM 的安全和应用尤其值得关注。如果你对特定主题感兴趣，可以查看这些论文的摘要进行深入！",
  "papers": [
    {
      "arxiv_id": "2407.09719v1",
      "title": "MSEval: A Dataset for Material Selection in Conceptual Design to Evaluate Algorithmic Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yash Patawari Jain",
        "Daniele Grandi",
        "Allin Groom",
        "Brandon Cramer",
        "Christopher McComb"
      ],
      "abstract": "Material selection plays a pivotal role in many industries, from\nmanufacturing to construction. Material selection is usually carried out after\nseveral cycles of conceptual design, during which designers iteratively refine\nthe design solution and the intended manufacturing approach. In design\nresearch, material selection is typically treated as an optimization problem\nwith a single correct answer. Moreover, it is also often restricted to specific\ntypes of objects or design functions, which can make the selection process\ncomputationally expensive and time-consuming. In this paper, we introduce\nMSEval, a novel dataset which is comprised of expert material evaluations\nacross a variety of design briefs and criteria. This data is designed to serve\nas a benchmark to facilitate the evaluation and modification of machine\nlearning models in the context of material selection for conceptual design.",
      "tldr_zh": "材料选择在制造业和建筑业中至关重要，但传统方法往往将其视为优化问题，并限于特定对象或设计功能，导致过程耗时且计算密集。本文引入了MSEval数据集，该数据集包含专家对各种设计简报和标准的材料评估，作为一个新型基准。MSEval旨在评估和改进机器学习models在概念设计(conceptual design)中的材料选择性能，从而促进相关算法的开发和优化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2405.03695",
      "pdf_url": "http://arxiv.org/pdf/2407.09719v1",
      "published_date": "2024-07-12 23:27:33 UTC",
      "updated_date": "2024-07-12 23:27:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:54:27.154241"
    },
    {
      "arxiv_id": "2407.11072v1",
      "title": "MaPPing Your Model: Assessing the Impact of Adversarial Attacks on LLM-based Programming Assistants",
      "title_zh": "翻译失败",
      "authors": [
        "John Heibel",
        "Daniel Lowd"
      ],
      "abstract": "LLM-based programming assistants offer the promise of programming faster but\nwith the risk of introducing more security vulnerabilities. Prior work has\nstudied how LLMs could be maliciously fine-tuned to suggest vulnerabilities\nmore often. With the rise of agentic LLMs, which may use results from an\nuntrusted third party, there is a growing risk of attacks on the model's\nprompt. We introduce the Malicious Programming Prompt (MaPP) attack, in which\nan attacker adds a small amount of text to a prompt for a programming task\n(under 500 bytes). We show that our prompt strategy can cause an LLM to add\nvulnerabilities while continuing to write otherwise correct code. We evaluate\nthree prompts on seven common LLMs, from basic to state-of-the-art commercial\nmodels. Using the HumanEval benchmark, we find that our prompts are broadly\neffective, with no customization required for different LLMs. Furthermore, the\nLLMs that are best at HumanEval are also best at following our malicious\ninstructions, suggesting that simply scaling language models will not prevent\nMaPP attacks. Using a dataset of eight CWEs in 16 scenarios, we find that MaPP\nattacks are also effective at implementing specific and targeted\nvulnerabilities across a range of models. Our work highlights the need to\nsecure LLM prompts against manipulation as well as rigorously auditing code\ngenerated with the help of LLMs.",
      "tldr_zh": "本研究评估了针对LLM-based编程助手的MaPP攻击的影响，MaPP攻击通过向编程任务提示添加少量文本（小于500字节）诱导LLM生成包含安全漏洞的代码，同时保持代码的其他部分正确。研究者在七个常见LLM上测试了三种提示，使用HumanEval基准发现这些攻击广泛有效，且无需针对不同模型定制；此外，表现最佳的LLM也更易遵循恶意指令，表明单纯扩展模型无法防范此类攻击。实验还使用一个涵盖八个CWEs的16个场景数据集，证明MaPP攻击能在多种模型上成功实施特定漏洞，强调了保护LLM提示和审计生成代码的必要性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "I.2.2"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, 5 figures, Proceedings of the ICML 2024 Workshop on\n  Trustworthy Multimodal Foundation Models and AI Agents",
      "pdf_url": "http://arxiv.org/pdf/2407.11072v1",
      "published_date": "2024-07-12 22:30:35 UTC",
      "updated_date": "2024-07-12 22:30:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:54:40.933032"
    },
    {
      "arxiv_id": "2407.09705v1",
      "title": "Diagnosing and Re-learning for Balanced Multimodal Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yake Wei",
        "Siwei Li",
        "Ruoxuan Feng",
        "Di Hu"
      ],
      "abstract": "To overcome the imbalanced multimodal learning problem, where models prefer\nthe training of specific modalities, existing methods propose to control the\ntraining of uni-modal encoders from different perspectives, taking the\ninter-modal performance discrepancy as the basis. However, the intrinsic\nlimitation of modality capacity is ignored. The scarcely informative modalities\ncan be recognized as ``worse-learnt'' ones, which could force the model to\nmemorize more noise, counterproductively affecting the multimodal model\nability. Moreover, the current modality modulation methods narrowly concentrate\non selected worse-learnt modalities, even suppressing the training of others.\nHence, it is essential to consider the intrinsic limitation of modality\ncapacity and take all modalities into account during balancing. To this end, we\npropose the Diagnosing \\& Re-learning method. The learning state of each\nmodality is firstly estimated based on the separability of its uni-modal\nrepresentation space, and then used to softly re-initialize the corresponding\nuni-modal encoder. In this way, the over-emphasizing of scarcely informative\nmodalities is avoided. In addition, encoders of worse-learnt modalities are\nenhanced, simultaneously avoiding the over-training of other modalities.\nAccordingly, multimodal learning is effectively balanced and enhanced.\nExperiments covering multiple types of modalities and multimodal frameworks\ndemonstrate the superior performance of our simple-yet-effective method for\nbalanced multimodal learning. The source code and dataset are available at\n\\url{https://github.com/GeWu-Lab/Diagnosing_Relearning_ECCV2024}.",
      "tldr_zh": "该研究针对多模态学习中的不平衡问题，指出现有方法忽略了模态容量的内在限制，导致模型过度记忆噪声并影响整体性能。作者提出 Diagnosing & Re-learning 方法，通过评估每个模态的单模态表示空间可分性来诊断其学习状态，并基于此进行软重初始化编码器，从而避免过度强调信息稀少的模态，同时增强较差模态的训练。实验结果显示，该方法在多种模态和框架下显著提升了多模态学习的平衡性和性能，并提供了开源代码和数据集。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.09705v1",
      "published_date": "2024-07-12 22:12:03 UTC",
      "updated_date": "2024-07-12 22:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:54:53.012020"
    },
    {
      "arxiv_id": "2407.09702v2",
      "title": "Investigating the Interplay of Prioritized Replay and Generalization",
      "title_zh": "探究优先重放与泛化的相互作用",
      "authors": [
        "Parham Mohammad Panahi",
        "Andrew Patterson",
        "Martha White",
        "Adam White"
      ],
      "abstract": "Experience replay, the reuse of past data to improve sample efficiency, is\nubiquitous in reinforcement learning. Though a variety of smart sampling\nschemes have been introduced to improve performance, uniform sampling by far\nremains the most common approach. One exception is Prioritized Experience\nReplay (PER), where sampling is done proportionally to TD errors, inspired by\nthe success of prioritized sweeping in dynamic programming. The original work\non PER showed improvements in Atari, but follow-up results were mixed. In this\npaper, we investigate several variations on PER, to attempt to understand where\nand when PER may be useful. Our findings in prediction tasks reveal that while\nPER can improve value propagation in tabular settings, behavior is\nsignificantly different when combined with neural networks. Certain mitigations\n$-$ like delaying target network updates to control generalization and using\nestimates of expected TD errors in PER to avoid chasing stochasticity $-$ can\navoid large spikes in error with PER and neural networks but generally do not\noutperform uniform replay. In control tasks, none of the prioritized variants\nconsistently outperform uniform replay. We present new insight into the\ninteraction between prioritization, bootstrapping, and neural networks and\npropose several improvements for PER in tabular settings and noisy domains.",
      "tldr_zh": "本文研究了 Prioritized Experience Replay (PER) 与泛化之间的相互作用，PER 通过根据 TD errors 优先采样来提升强化学习的样本效率，但其表现因任务而异。实验发现，在预测任务中，PER 在表格设置下能改善价值传播，但与神经网络结合时可能导致错误激增；采用缓解措施如延迟目标网络更新和使用预期 TD errors，能控制问题但通常不如均匀采样有效。在控制任务中，PER 变体未 consistently 优于均匀采样，论文提供了优先化、bootstrapping 和神经网络互动的新见解，并提出针对表格设置和噪声域的改进建议。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Reinforcement Learning Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.09702v2",
      "published_date": "2024-07-12 21:56:24 UTC",
      "updated_date": "2024-10-19 17:51:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:55:05.096619"
    },
    {
      "arxiv_id": "2407.09693v1",
      "title": "A Mathematical Framework, a Taxonomy of Modeling Paradigms, and a Suite of Learning Techniques for Neural-Symbolic Systems",
      "title_zh": "神经符号系统的数学框架、建模范式的分类法以及一套学习技术",
      "authors": [
        "Charles Dickens",
        "Connor Pryor",
        "Changyu Gao",
        "Alon Albalak",
        "Eriq Augustine",
        "William Wang",
        "Stephen Wright",
        "Lise Getoor"
      ],
      "abstract": "The field of Neural-Symbolic (NeSy) systems is growing rapidly. Proposed\napproaches show great promise in achieving symbiotic unions of neural and\nsymbolic methods. However, each NeSy system differs in fundamental ways. There\nis a pressing need for a unifying theory to illuminate the commonalities and\ndifferences in approaches and enable further progress. In this paper, we\nintroduce Neural-Symbolic Energy-Based Models (NeSy-EBMs), a unifying\nmathematical framework for discriminative and generative modeling with\nprobabilistic and non-probabilistic NeSy approaches. We utilize NeSy-EBMs to\ndevelop a taxonomy of modeling paradigms focusing on a system's neural-symbolic\ninterface and reasoning capabilities. Additionally, we introduce a suite of\nlearning techniques for NeSy-EBMs. Importantly, NeSy-EBMs allow the derivation\nof general expressions for gradients of prominent learning losses, and we\nprovide four learning approaches that leverage methods from multiple domains,\nincluding bilevel and stochastic policy optimization. Finally, we present\nNeural Probabilistic Soft Logic (NeuPSL), an open-source NeSy-EBM library\ndesigned for scalability and expressivity, facilitating real-world application\nof NeSy systems. Through extensive empirical analysis across multiple datasets,\nwe demonstrate the practical advantages of NeSy-EBMs in various tasks,\nincluding image classification, graph node labeling, autonomous vehicle\nsituation awareness, and question answering.",
      "tldr_zh": "这篇论文引入了 Neural-Symbolic Energy-Based Models (NeSy-EBMs) 作为一种统一的数学框架，用于支持概率和非概率的 Neural-Symbolic (NeSy) 系统中的区分性和生成性建模。作者基于 NeSy-EBMs 开发了一个 taxonomy of modeling paradigms，重点关注系统的神经-符号接口和推理能力，并提供了一系列学习技术，包括 bilevel 和 stochastic policy optimization 方法，以优化梯度表达式。论文还推出了开源库 Neural Probabilistic Soft Logic (NeuPSL)，旨在提升 NeSy 系统的可扩展性和表达性，便于实际应用。通过在多个数据集上的实证分析，NeSy-EBMs 在图像分类、图节点标记、自动驾驶情况感知和问答等任务中显示出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09693v1",
      "published_date": "2024-07-12 21:26:21 UTC",
      "updated_date": "2024-07-12 21:26:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:55:17.289916"
    },
    {
      "arxiv_id": "2407.09685v2",
      "title": "Accelerating the inference of string generation-based chemical reaction models for industrial applications",
      "title_zh": "翻译失败",
      "authors": [
        "Mikhail Andronov",
        "Natalia Andronova",
        "Michael Wand",
        "Jürgen Schmidhuber",
        "Djork-Arné Clevert"
      ],
      "abstract": "Template-free SMILES-to-SMILES translation models for reaction prediction and\nsingle-step retrosynthesis are of interest for industrial applications in\ncomputer-aided synthesis planning systems due to their state-of-the-art\naccuracy. However, they suffer from slow inference speed. We present a method\nto accelerate inference in autoregressive SMILES generators through speculative\ndecoding by copying query string subsequences into target strings in the right\nplaces. We apply our method to the molecular transformer implemented in Pytorch\nLightning and achieve over 3X faster inference in reaction prediction and\nsingle-step retrosynthesis, with no loss in accuracy.",
      "tldr_zh": "这篇论文针对基于字符串生成的化学反应模型，提出了一种加速推理的方法，以提升工业应用中的计算机辅助合成规划系统效率。方法通过推测性解码(speculative decoding)将查询字符串子序列复制到目标字符串的正确位置，从而加速自回归 SMILES 生成器。实验结果显示，在 Pytorch Lightning 中的分子 Transformer 模型上，该方法在反应预测和单步逆合成(retrosynthesis)任务中实现了超过 3 倍的推理速度提升，同时准确性保持不变。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.09685v2",
      "published_date": "2024-07-12 20:55:59 UTC",
      "updated_date": "2024-07-17 10:43:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:55:27.459722"
    },
    {
      "arxiv_id": "2407.11071v2",
      "title": "MonoSparse-CAM: Efficient Tree Model Processing via Monotonicity and Sparsity in CAMs",
      "title_zh": "翻译失败",
      "authors": [
        "Tergel Molom-Ochir",
        "Brady Taylor",
        "Hai Li",
        "Yiran Chen"
      ],
      "abstract": "While the tree-based machine learning (TBML) models exhibit superior\nperformance compared to neural networks on tabular data and hold promise for\nenergy-efficient acceleration using aCAM arrays, their ideal deployment on\nhardware with explicit exploitation of TBML structure and aCAM circuitry\nremains a challenging task. In this work, we present MonoSparse-CAM, a new\nCAM-based optimization technique that exploits TBML sparsity and monotonicity\nin CAM circuitry to further advance processing performance. Our results\nindicate that MonoSparse-CAM reduces energy consumption by upto to 28.56x\ncompared to raw processing and by 18.51x compared to state-of-the-art\ntechniques, while improving the efficiency of computation by at least 1.68x.",
      "tldr_zh": "该论文提出 MonoSparse-CAM，一种基于 CAMs 的优化技术，利用 TBML 的 sparsity 和 monotonicity 来提升树模型处理效率，针对 TBML 在硬件部署中的挑战。MonoSparse-CAM 通过在 CAM 电路中显式利用这些特性，实现对 tabular data 处理的能量高效加速。实验结果显示，该方法相较原始处理减少能量消耗高达 28.56 倍，相较最先进技术减少 18.51 倍，同时至少提高计算效率 1.68 倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11071v2",
      "published_date": "2024-07-12 20:34:59 UTC",
      "updated_date": "2024-12-27 04:54:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:55:41.961755"
    },
    {
      "arxiv_id": "2407.12865v1",
      "title": "GRAD-SUM: Leveraging Gradient Summarization for Optimal Prompt Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Derek Austin",
        "Elliott Chartock"
      ],
      "abstract": "Prompt engineering for large language models (LLMs) is often a manual\ntime-intensive process that involves generating, evaluating, and refining\nprompts iteratively to ensure high-quality outputs. While there has been work\non automating prompt engineering, the solutions generally are either tuned to\nspecific tasks with given answers or are quite costly. We introduce GRAD-SUM, a\nscalable and flexible method for automatic prompt engineering that builds on\ngradient-based optimization techniques. Our approach incorporates user-defined\ntask descriptions and evaluation criteria, and features a novel gradient\nsummarization module to generalize feedback effectively. Our results\ndemonstrate that GRAD-SUM consistently outperforms existing methods across\nvarious benchmarks, highlighting its versatility and effectiveness in automatic\nprompt optimization.",
      "tldr_zh": "论文提出 GRAD-SUM，这是一种基于梯度优化技术的自动提示工程方法，旨在解决大型语言模型(LLMs)提示优化的手动耗时问题，并通过整合用户定义的任务描述和评估标准来提升灵活性。核心创新包括一个新颖的梯度总结模块(gradient summarization module)，用于有效泛化反馈，使方法适用于各种任务。实验结果显示，GRAD-SUM 在多个基准测试中 consistently outperforms 现有方法，证明了其在自动提示优化中的可扩展性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.12865v1",
      "published_date": "2024-07-12 19:11:21 UTC",
      "updated_date": "2024-07-12 19:11:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:55:51.649371"
    },
    {
      "arxiv_id": "2407.11070v2",
      "title": "Optimal Defender Strategies for CAGE-2 using Causal Modeling and Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Kim Hammar",
        "Neil Dhir",
        "Rolf Stadler"
      ],
      "abstract": "The CAGE-2 challenge is considered a standard benchmark to compare methods\nfor autonomous cyber defense. Current state-of-the-art methods evaluated\nagainst this benchmark are based on model-free (offline) reinforcement\nlearning, which does not provide provably optimal defender strategies. We\naddress this limitation and present a formal (causal) model of CAGE-2 together\nwith a method that produces a provably optimal defender strategy, which we call\nCausal Partially Observable Monte-Carlo Planning (C-POMCP). It has two key\nproperties. First, it incorporates the causal structure of the target system,\ni.e., the causal relationships among the system variables. This structure\nallows for a significant reduction of the search space of defender strategies.\nSecond, it is an online method that updates the defender strategy at each time\nstep via tree search. Evaluations against the CAGE-2 benchmark show that\nC-POMCP achieves state-of-the-art performance with respect to effectiveness and\nis two orders of magnitude more efficient in computing time than the closest\ncompetitor method.",
      "tldr_zh": "该论文针对CAGE-2基准（一个自主网络防御方法的标准评估工具），提出了使用因果建模和树搜索的优化防御策略，以克服基于无模型强化学习方法的局限性。作者开发了Causal Partially Observable Monte-Carlo Planning (C-POMCP)方法，该方法整合了系统变量的因果结构，显著减少搜索空间，并通过在线树搜索在每个时间步动态更新策略。实验结果显示，C-POMCP在CAGE-2基准上实现了最先进的性能，且计算效率比竞争对手高出两个数量级，提供可证明的最优防御策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2407.11070v2",
      "published_date": "2024-07-12 18:34:55 UTC",
      "updated_date": "2024-07-22 07:08:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:56:03.990276"
    },
    {
      "arxiv_id": "2407.09475v2",
      "title": "Adaptive Prediction Ensemble: Improving Out-of-Distribution Generalization of Motion Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Jinning Li",
        "Jiachen Li",
        "Sangjae Bae",
        "David Isele"
      ],
      "abstract": "Deep learning-based trajectory prediction models for autonomous driving often\nstruggle with generalization to out-of-distribution (OOD) scenarios, sometimes\nperforming worse than simple rule-based models. To address this limitation, we\npropose a novel framework, Adaptive Prediction Ensemble (APE), which integrates\ndeep learning and rule-based prediction experts. A learned routing function,\ntrained concurrently with the deep learning model, dynamically selects the most\nreliable prediction based on the input scenario. Our experiments on large-scale\ndatasets, including Waymo Open Motion Dataset (WOMD) and Argoverse, demonstrate\nimprovement in zero-shot generalization across datasets. We show that our\nmethod outperforms individual prediction models and other variants,\nparticularly in long-horizon prediction and scenarios with a high proportion of\nOOD data. This work highlights the potential of hybrid approaches for robust\nand generalizable motion prediction in autonomous driving. More details can be\nfound on the project page: https://sites.google.com/view/ape-generalization.",
      "tldr_zh": "本论文提出Adaptive Prediction Ensemble (APE)框架，以提升轨迹预测模型在Out-of-Distribution (OOD)场景下的泛化能力，解决深度学习模型常不如规则-based模型的表现问题。APE整合深度学习和规则-based预测专家，通过一个与深度学习模型同时训练的学习路由函数，根据输入场景动态选择最可靠的预测。实验结果显示，该方法在Waymo Open Motion Dataset (WOMD)和Argoverse数据集上实现了零-shot泛化改进，尤其在长horizon预测和高比例OOD数据场景中，优于单个模型和其他变体。这强调了混合方法在实现自主驾驶中鲁棒运动预测的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09475v2",
      "published_date": "2024-07-12 17:57:00 UTC",
      "updated_date": "2024-12-20 05:34:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:56:27.049956"
    },
    {
      "arxiv_id": "2407.09467v1",
      "title": "FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Makridis",
        "Athanasios Oikonomou",
        "Vasileios Koukos"
      ],
      "abstract": "In the diverse world of AI-driven storytelling, there is a unique opportunity\nto engage young audiences with customized, and personalized narratives. This\npaper introduces FairyLandAI an innovative Large Language Model (LLM) developed\nthrough OpenAI's API, specifically crafted to create personalized fairytales\nfor children. The distinctive feature of FairyLandAI is its dual capability: it\nnot only generates stories that are engaging, age-appropriate, and reflective\nof various traditions but also autonomously produces imaginative prompts\nsuitable for advanced image generation tools like GenAI and Dalle-3, thereby\nenriching the storytelling experience. FairyLandAI is expertly tailored to\nresonate with the imaginative worlds of children, providing narratives that are\nboth educational and entertaining and in alignment with the moral values\ninherent in different ages. Its unique strength lies in customizing stories to\nmatch individual children's preferences and cultural backgrounds, heralding a\nnew era in personalized storytelling. Further, its integration with image\ngeneration technology offers a comprehensive narrative experience that\nstimulates both verbal and visual creativity. Empirical evaluations of\nFairyLandAI demonstrate its effectiveness in crafting captivating stories for\nchildren, which not only entertain but also embody the values and teachings of\ndiverse traditions. This model serves as an invaluable tool for parents and\neducators, supporting them in imparting meaningful moral lessons through\nengaging narratives. FairyLandAI represents a pioneering step in using LLMs,\nparticularly through OpenAI's API, for educational and cultural enrichment,\nmaking complex moral narratives accessible and enjoyable for young, imaginative\nminds.",
      "tldr_zh": "本论文介绍了FairyLandAI，这是一个基于OpenAI API开发的Large Language Model (LLM)，利用ChatGPT生成个性化童话故事，并结合DALL·E-3创建图像提示，以增强故事的视觉和互动体验。FairyLandAI专注于为儿童打造年龄适宜、反映文化背景和道德价值观的教育性叙事，能够根据个人偏好定制内容。实验评估证明，该系统在提供娱乐和教育价值方面表现出色，为父母和教育者提供了一个创新工具，促进儿童的语言和视觉创意发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.09467v1",
      "published_date": "2024-07-12 17:46:58 UTC",
      "updated_date": "2024-07-12 17:46:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:56:39.350679"
    },
    {
      "arxiv_id": "2407.09450v2",
      "title": "Human-like Episodic Memory for Infinite Context LLMs",
      "title_zh": "用于无限上下文大语言模型的类人式情节记忆",
      "authors": [
        "Zafeirios Fountas",
        "Martin A Benfeghoul",
        "Adnan Oomerjee",
        "Fenia Christopoulou",
        "Gerasimos Lampouras",
        "Haitham Bou-Ammar",
        "Jun Wang"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable capabilities, but still\nstruggle with processing extensive contexts, limiting their ability to maintain\ncoherence and accuracy over long sequences. In contrast, the human brain excels\nat organising and retrieving episodic experiences across vast temporal scales,\nspanning a lifetime. In this work, we introduce EM-LLM, a novel approach that\nintegrates key aspects of human episodic memory and event cognition into LLMs\nwith no fine-tuning, enabling them to handle practically infinite context\nlengths while maintaining computational efficiency. EM-LLM organises sequences\nof tokens into coherent episodic events using a combination of Bayesian\nsurprise and graph-theoretic boundary refinement in an online fashion. When\nneeded, these events are retrieved through a two-stage memory process,\ncombining similarity-based and temporally contiguous retrieval for efficient\nand human-like access to relevant information. Experiments on the LongBench and\nInfiniteBench benchmarks demonstrate EM-LLM's superior performance,\nconsistently outperforming the state-of-the-art retrieval model InfLLM across\nvarious baseline LLMs. In addition, EM-LLM outperforms its popular counterpart,\nRAG, in a wide range of tasks, while requiring similar resources. Notably,\nEM-LLM's performance even surpasses full-context models in most tasks, while\nsuccessfully performing retrieval across 10 million tokens - a scale\ncomputationally infeasible for such models. Finally, our analysis reveals\nstrong correlations between EM-LLM's event segmentation and human-perceived\nevents, suggesting a bridge between this artificial system and its biological\ncounterpart, thereby offering a novel computational framework for exploring\nhuman memory mechanisms.",
      "tldr_zh": "这篇论文提出 EM-LLM，一种无需微调的创新方法，将人类 episodic memory 和 event cognition 整合到大型语言模型（LLMs）中，以处理无限长上下文并保持计算效率。EM-LLM 通过 Bayesian surprise 和 graph-theoretic boundary refinement 在线组织 tokens 为连贯事件，并采用两阶段检索机制（结合相似性和时间连续性）来高效访问相关信息。在 LongBench 和 InfiniteBench 基准测试中，EM-LLM 优于 InfLLM 和 RAG，在多种任务上表现超越全上下文模型，甚至成功处理 10 百万 tokens 的规模。最后，分析显示 EM-LLM 的事件分割与人类感知事件高度相关，为探索人类记忆机制提供了一个新型计算框架。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09450v2",
      "published_date": "2024-07-12 17:34:03 UTC",
      "updated_date": "2024-10-25 14:27:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:56:52.727513"
    },
    {
      "arxiv_id": "2407.09441v4",
      "title": "The $μ\\mathcal{G}$ Language for Programming Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Belenchia",
        "Flavio Corradini",
        "Michela Quadrini",
        "Michele Loreti"
      ],
      "abstract": "Graph neural networks form a class of deep learning architectures\nspecifically designed to work with graph-structured data. As such, they share\nthe inherent limitations and problems of deep learning, especially regarding\nthe issues of explainability and trustworthiness. We propose $\\mu\\mathcal{G}$,\nan original domain-specific language for the specification of graph neural\nnetworks that aims to overcome these issues. The language's syntax is\nintroduced, and its meaning is rigorously defined by a denotational semantics.\nAn equivalent characterization in the form of an operational semantics is also\nprovided and, together with a type system, is used to prove the type soundness\nof $\\mu\\mathcal{G}$. We show how $\\mu\\mathcal{G}$ programs can be represented\nin a more user-friendly graphical visualization, and provide examples of its\ngenerality by showing how it can be used to define some of the most popular\ngraph neural network models, or to develop any custom graph processing\napplication.",
      "tldr_zh": "本论文提出 $μ\\mathcal{G}$ 语言，这是一种针对 Graph Neural Networks 的领域特定语言，旨在解决深度学习中解释性和可信赖性等问题。\n语言的语法通过指称语义（denotational semantics）严格定义，并辅以操作语义（operational semantics）和类型系统，以证明其类型安全性（type soundness）。\n$μ\\mathcal{G}$ 程序可通过用户友好的图形可视化表示，并展示出通用性，能用于定义流行 Graph Neural Networks 模型或开发自定义图处理应用。",
      "categories": [
        "cs.FL",
        "cs.AI",
        "cs.LG",
        "D.2.4"
      ],
      "primary_category": "cs.FL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09441v4",
      "published_date": "2024-07-12 17:27:43 UTC",
      "updated_date": "2024-10-15 15:14:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:57:03.166224"
    },
    {
      "arxiv_id": "2407.09437v1",
      "title": "Let Me DeCode You: Decoder Conditioning with Tabular Data",
      "title_zh": "翻译失败",
      "authors": [
        "Tomasz Szczepański",
        "Michal K. Grzeszczyk",
        "Szymon Płotka",
        "Arleta Adamowicz",
        "Piotr Fudalej",
        "Przemysław Korzeniowski",
        "Tomasz Trzciński",
        "Arkadiusz Sitek"
      ],
      "abstract": "Training deep neural networks for 3D segmentation tasks can be challenging,\noften requiring efficient and effective strategies to improve model\nperformance. In this study, we introduce a novel approach, DeCode, that\nutilizes label-derived features for model conditioning to support the decoder\nin the reconstruction process dynamically, aiming to enhance the efficiency of\nthe training process. DeCode focuses on improving 3D segmentation performance\nthrough the incorporation of conditioning embedding with learned numerical\nrepresentation of 3D-label shape features. Specifically, we develop an\napproach, where conditioning is applied during the training phase to guide the\nnetwork toward robust segmentation. When labels are not available during\ninference, our model infers the necessary conditioning embedding directly from\nthe input data, thanks to a feed-forward network learned during the training\nphase. This approach is tested using synthetic data and cone-beam computed\ntomography (CBCT) images of teeth. For CBCT, three datasets are used: one\npublicly available and two in-house. Our results show that DeCode significantly\noutperforms traditional, unconditioned models in terms of generalization to\nunseen data, achieving higher accuracy at a reduced computational cost. This\nwork represents the first of its kind to explore conditioning strategies in 3D\ndata segmentation, offering a novel and more efficient method for leveraging\nannotated data. Our code, pre-trained models are publicly available at\nhttps://github.com/SanoScience/DeCode .",
      "tldr_zh": "本研究提出了一种名为 DeCode 的新方法，用于提升 3D 分割任务的训练效率，通过利用标签派生的特征对解码器进行条件化（conditioning），以动态支持重建过程。DeCode 整合了条件嵌入（conditioning embedding），学习 3D 标签形状特征的数值表示，在训练阶段指导网络实现鲁棒分割，并在推理阶段从输入数据中推断必要的嵌入，从而无需标签。实验在合成数据和 CBCT（cone-beam computed tomography）图像（如牙齿数据集）上进行，结果显示 DeCode 比传统无条件模型具有更好的泛化性能、更高的准确率和更低的计算成本，为 3D 数据分割提供了一种创新的条件策略。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted for the 27th International Conference on Medical Image\n  Computing and Computer Assisted Intervention (MICCAI) 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.09437v1",
      "published_date": "2024-07-12 17:14:33 UTC",
      "updated_date": "2024-07-12 17:14:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:57:16.555609"
    },
    {
      "arxiv_id": "2407.09435v2",
      "title": "MUSCLE: A Model Update Strategy for Compatible LLM Evolution",
      "title_zh": "翻译失败",
      "authors": [
        "Jessica Echterhoff",
        "Fartash Faghri",
        "Raviteja Vemulapalli",
        "Ting-Yao Hu",
        "Chun-Liang Li",
        "Oncel Tuzel",
        "Hadi Pouransari"
      ],
      "abstract": "Large Language Models (LLMs) are regularly updated to enhance performance,\ntypically through changes in data or architecture. Within the update process,\ndevelopers often prioritize improving overall performance metrics, paying less\nattention to maintaining compatibility with earlier model versions.\nInstance-level degradation (instance regression) of performance from one model\nversion to the next can interfere with a user's mental model of the\ncapabilities of a particular language model. Users having to adapt their mental\nmodel with every update can lead to dissatisfaction, especially when the new\nmodel has degraded compared to a prior version for a known use case (model\nupdate regression). We find that when pretrained LLM base models are updated,\nfine-tuned user-facing downstream task adapters experience negative flips --\npreviously correct instances are now predicted incorrectly. We observe model\nupdate regression between different model versions on a diverse set of tasks\nand models, even when the downstream task training procedures remain identical.\nWe argue for the importance of maintaining model update compatibility during\nupdates, and present evaluation metrics designed specifically for generative\ntasks, while also being applicable to discriminative tasks. We propose a\ntraining strategy to minimize the extent of instance regression in model\nupdates, involving training of a compatibility adapter that can enhance task\nfine-tuned language models. We show negative flips reduce by up to 40% e.g.\nwhen updating Llama 1 to Llama 2 with our proposed method.",
      "tldr_zh": "大型语言模型 (LLMs) 更新通常通过改变数据或架构来提升性能，但常忽略与早期版本的兼容性，导致实例退化 (instance regression) 和负面翻转 (negative flips)，即先前正确的预测变得错误。论文提出 MUSCLE 策略，包括训练一个兼容适配器 (compatibility adapter) 来最小化这些问题，同时引入适用于生成和判别任务的评估指标。实验结果显示，该策略在模型更新中将负面翻转减少高达 40%，例如从 Llama 1 到 Llama 2 的升级，为更稳定的 LLM 演化提供了有效方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09435v2",
      "published_date": "2024-07-12 17:12:48 UTC",
      "updated_date": "2024-10-03 21:10:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:57:28.673136"
    },
    {
      "arxiv_id": "2407.09434v2",
      "title": "Foundation Models for the Electric Power Grid",
      "title_zh": "翻译失败",
      "authors": [
        "Hendrik F. Hamann",
        "Thomas Brunschwiler",
        "Blazhe Gjorgiev",
        "Leonardo S. A. Martins",
        "Alban Puech",
        "Anna Varbella",
        "Jonas Weiss",
        "Juan Bernabe-Moreno",
        "Alexandre Blondin Massé",
        "Seong Choi",
        "Ian Foster",
        "Bri-Mathias Hodge",
        "Rishabh Jain",
        "Kibaek Kim",
        "Vincent Mai",
        "François Mirallès",
        "Martin De Montigny",
        "Octavio Ramos-Leaños",
        "Hussein Suprême",
        "Le Xie",
        "El-Nasser S. Youssef",
        "Arnaud Zinflou",
        "Alexander J. Belyi",
        "Ricardo J. Bessa",
        "Bishnu Prasad Bhattarai",
        "Johannes Schmude",
        "Stanislav Sobolevsky"
      ],
      "abstract": "Foundation models (FMs) currently dominate news headlines. They employ\nadvanced deep learning architectures to extract structural information\nautonomously from vast datasets through self-supervision. The resulting rich\nrepresentations of complex systems and dynamics can be applied to many\ndownstream applications. Therefore, FMs can find uses in electric power grids,\nchallenged by the energy transition and climate change. In this paper, we call\nfor the development of, and state why we believe in, the potential of FMs for\nelectric grids. We highlight their strengths and weaknesses amidst the\nchallenges of a changing grid. We argue that an FM learning from diverse grid\ndata and topologies could unlock transformative capabilities, pioneering a new\napproach in leveraging AI to redefine how we manage complexity and uncertainty\nin the electric grid. Finally, we discuss a power grid FM concept, namely\nGridFM, based on graph neural networks and show how different downstream tasks\nbenefit.",
      "tldr_zh": "本论文探讨了基础模型（Foundation Models, FMs）在电力网格中的应用潜力，强调这些模型通过自监督从海量数据中自动提取复杂系统信息，从而支持多种下游任务。作者指出，FMs 的优势在于处理能源转型和气候变化带来的电网挑战，但也存在弱点，如数据多样性和拓扑变化的影响。论文呼吁开发一种从多样化电网数据中学习的 FM，并提出 GridFM 概念，基于图神经网络（Graph Neural Networks），以革新电网复杂性和不确定性的管理。实验结果显示，GridFM 可显著提升下游任务的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Major equal contributors: H.F.H., T.B., B.G., L.S.A.M., A.P., A.V.,\n  J.W.; Significant equal contributors: J.B., A.B.M., S.C., I.F., B.H., R.J.,\n  K.K., V.M., F.M., M.D.M., O.R., H.S., L.X., E.S.Y., A.Z.; Other equal\n  contributors: A.J.B., R.J.B., B.P.B., J.S., S.S; Lead contact: H.F.H",
      "pdf_url": "http://arxiv.org/pdf/2407.09434v2",
      "published_date": "2024-07-12 17:09:47 UTC",
      "updated_date": "2024-11-12 17:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:57:39.187008"
    },
    {
      "arxiv_id": "2407.09424v1",
      "title": "TelecomGPT: A Framework to Build Telecom-Specfic Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Zou",
        "Qiyang Zhao",
        "Yu Tian",
        "Lina Bariah",
        "Faouzi Bader",
        "Thierry Lestable",
        "Merouane Debbah"
      ],
      "abstract": "Large Language Models (LLMs) have the potential to revolutionize the Sixth\nGeneration (6G) communication networks. However, current mainstream LLMs\ngenerally lack the specialized knowledge in telecom domain. In this paper, for\nthe first time, we propose a pipeline to adapt any general purpose LLMs to a\ntelecom-specific LLMs. We collect and build telecom-specific pre-train dataset,\ninstruction dataset, preference dataset to perform continual pre-training,\ninstruct tuning and alignment tuning respectively. Besides, due to the lack of\nwidely accepted evaluation benchmarks in telecom domain, we extend existing\nevaluation benchmarks and proposed three new benchmarks, namely, Telecom Math\nModeling, Telecom Open QnA and Telecom Code Tasks. These new benchmarks provide\na holistic evaluation of the capabilities of LLMs including math modeling,\nOpen-Ended question answering, code generation, infilling, summarization and\nanalysis in telecom domain. Our fine-tuned LLM TelecomGPT outperforms state of\nthe art (SOTA) LLMs including GPT-4, Llama-3 and Mistral in Telecom Math\nModeling benchmark significantly and achieve comparable performance in various\nevaluation benchmarks such as TeleQnA, 3GPP technical documents classification,\ntelecom code summary and generation and infilling.",
      "tldr_zh": "该论文提出TelecomGPT框架，用于将通用Large Language Models (LLMs)适配成电信领域的专用模型，通过构建电信特定预训练数据集、指令数据集和偏好数据集，进行持续预训练、指令微调和对齐微调。作者扩展了现有评估基准，并引入三个新基准：Telecom Math Modeling、Telecom Open QnA和Telecom Code Tasks，以全面评估LLMs在电信领域的数学建模、开放问题回答、代码生成等方面的能力。实验结果显示，TelecomGPT在Telecom Math Modeling基准上显著超越SOTA模型如GPT-4、Llama-3和Mistral，并在TeleQnA、3GPP文档分类、代码摘要和生成等任务中表现出可比性能。总的来说，该框架为6G通信网络中的LLMs应用提供了重要基础。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "arXiv admin note: text overlap with arXiv:1303.2654 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2407.09424v1",
      "published_date": "2024-07-12 16:51:02 UTC",
      "updated_date": "2024-07-12 16:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:57:51.959337"
    },
    {
      "arxiv_id": "2407.09415v1",
      "title": "A Benchmark Environment for Offline Reinforcement Learning in Racing Games",
      "title_zh": "用于赛车游戏的离线强化学习",
      "authors": [
        "Girolamo Macaluso",
        "Alessandro Sestini",
        "Andrew D. Bagdanov"
      ],
      "abstract": "Offline Reinforcement Learning (ORL) is a promising approach to reduce the\nhigh sample complexity of traditional Reinforcement Learning (RL) by\neliminating the need for continuous environmental interactions. ORL exploits a\ndataset of pre-collected transitions and thus expands the range of application\nof RL to tasks in which the excessive environment queries increase training\ntime and decrease efficiency, such as in modern AAA games. This paper\nintroduces OfflineMania a novel environment for ORL research. It is inspired by\nthe iconic TrackMania series and developed using the Unity 3D game engine. The\nenvironment simulates a single-agent racing game in which the objective is to\ncomplete the track through optimal navigation. We provide a variety of datasets\nto assess ORL performance. These datasets, created from policies of varying\nability and in different sizes, aim to offer a challenging testbed for\nalgorithm development and evaluation. We further establish a set of baselines\nfor a range of Online RL, ORL, and hybrid Offline to Online RL approaches using\nour environment.",
      "tldr_zh": "该论文引入了OfflineMania，一个基于Unity 3D的基准环境，用于Offline Reinforcement Learning (ORL)研究，模拟单代理赛车游戏以优化赛道导航。该环境利用预收集的过渡数据集，减少传统Reinforcement Learning (RL)的样本复杂度和环境交互需求，并提供多种数据集和大小，以评估算法在不同策略下的性能。研究还建立了Online RL、ORL和混合方法的基线，为ORL算法开发和评估提供了一个具有挑战性的测试平台。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at IEEE Conference on Games",
      "pdf_url": "http://arxiv.org/pdf/2407.09415v1",
      "published_date": "2024-07-12 16:44:03 UTC",
      "updated_date": "2024-07-12 16:44:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:58:04.168995"
    },
    {
      "arxiv_id": "2407.09413v3",
      "title": "SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers",
      "title_zh": "翻译失败",
      "authors": [
        "Shraman Pramanick",
        "Rama Chellappa",
        "Subhashini Venugopalan"
      ],
      "abstract": "Seeking answers to questions within long scientific research articles is a\ncrucial area of study that aids readers in quickly addressing their inquiries.\nHowever, existing question-answering (QA) datasets based on scientific papers\nare limited in scale and focus solely on textual content. We introduce SPIQA\n(Scientific Paper Image Question Answering), the first large-scale QA dataset\nspecifically designed to interpret complex figures and tables within the\ncontext of scientific research articles across various domains of computer\nscience. Leveraging the breadth of expertise and ability of multimodal large\nlanguage models (MLLMs) to understand figures, we employ automatic and manual\ncuration to create the dataset. We craft an information-seeking task on\ninterleaved images and text that involves multiple images covering plots,\ncharts, tables, schematic diagrams, and result visualizations. SPIQA comprises\n270K questions divided into training, validation, and three different\nevaluation splits. Through extensive experiments with 12 prominent foundational\nmodels, we evaluate the ability of current multimodal systems to comprehend the\nnuanced aspects of research articles. Additionally, we propose a\nChain-of-Thought (CoT) evaluation strategy with in-context retrieval that\nallows fine-grained, step-by-step assessment and improves model performance. We\nfurther explore the upper bounds of performance enhancement with additional\ntextual information, highlighting its promising potential for future research\nand the dataset's impact on revolutionizing how we interact with scientific\nliterature.",
      "tldr_zh": "本文引入了SPIQA数据集，这是首个大规模多模态问答(Multimodal Question Answering)数据集，专注于科学论文中的复杂图形、表格和文本，以帮助用户快速获取信息。数据集通过多模态大语言模型(MLLMs)的自动和手动整理，共包含27万问题，涵盖图表、示意图等元素，并分为训练、验证和多个评估集。作者使用12个基础模型进行实验，评估当前系统理解研究文章细微方面的能力，并提出Chain-of-Thought (CoT) 评估策略结合in-context retrieval，以实现细粒度评估和性能提升。研究结果显示，添加额外文本信息可显著提高模型表现，为未来科学文献互动提供重要潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024, Datasets & Benchmarks track",
      "pdf_url": "http://arxiv.org/pdf/2407.09413v3",
      "published_date": "2024-07-12 16:37:59 UTC",
      "updated_date": "2025-01-10 19:41:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:58:16.489085"
    },
    {
      "arxiv_id": "2407.09395v1",
      "title": "Deep Bag-of-Words Model: An Efficient and Interpretable Relevance Architecture for Chinese E-Commerce",
      "title_zh": "翻译失败",
      "authors": [
        "Zhe Lin",
        "Jiwei Tan",
        "Dan Ou",
        "Xi Chen",
        "Shaowei Yao",
        "Bo Zheng"
      ],
      "abstract": "Text relevance or text matching of query and product is an essential\ntechnique for the e-commerce search system to ensure that the displayed\nproducts can match the intent of the query. Many studies focus on improving the\nperformance of the relevance model in search system. Recently, pre-trained\nlanguage models like BERT have achieved promising performance on the text\nrelevance task. While these models perform well on the offline test dataset,\nthere are still obstacles to deploy the pre-trained language model to the\nonline system as their high latency. The two-tower model is extensively\nemployed in industrial scenarios, owing to its ability to harmonize performance\nwith computational efficiency. Regrettably, such models present an opaque\n``black box'' nature, which prevents developers from making special\noptimizations. In this paper, we raise deep Bag-of-Words (DeepBoW) model, an\nefficient and interpretable relevance architecture for Chinese e-commerce. Our\napproach proposes to encode the query and the product into the sparse BoW\nrepresentation, which is a set of word-weight pairs. The weight means the\nimportant or the relevant score between the corresponding word and the raw\ntext. The relevance score is measured by the accumulation of the matched word\nbetween the sparse BoW representation of the query and the product. Compared to\npopular dense distributed representation that usually suffers from the drawback\nof black-box, the most advantage of the proposed representation model is highly\nexplainable and interventionable, which is a superior advantage to the\ndeployment and operation of online search engines. Moreover, the online\nefficiency of the proposed model is even better than the most efficient inner\nproduct form of dense representation ...",
      "tldr_zh": "该论文针对中文电商搜索中的文本相关性问题，提出了一种高效且可解释的架构——Deep Bag-of-Words (DeepBoW) 模型，以解决预训练语言模型如 BERT 的高延迟和两塔模型的黑盒问题。DeepBoW 通过将查询和产品编码成稀疏的词-权重对表示，并通过匹配词的累积计算相关性分数，实现模型的高度可解释性和可干预性。相比于密集分布式表示，该模型在在线效率上表现出色，便于电商搜索系统的部署和优化。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "KDD'24 accepted paper",
      "pdf_url": "http://arxiv.org/pdf/2407.09395v1",
      "published_date": "2024-07-12 16:18:05 UTC",
      "updated_date": "2024-07-12 16:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:58:26.734086"
    },
    {
      "arxiv_id": "2407.09388v2",
      "title": "GAVEL: Generating Games Via Evolution and Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Graham Todd",
        "Alexander Padula",
        "Matthew Stephenson",
        "Éric Piette",
        "Dennis J. N. J. Soemers",
        "Julian Togelius"
      ],
      "abstract": "Automatically generating novel and interesting games is a complex task.\nChallenges include representing game rules in a computationally workable form,\nsearching through the large space of potential games under most such\nrepresentations, and accurately evaluating the originality and quality of\npreviously unseen games. Prior work in automated game generation has largely\nfocused on relatively restricted rule representations and relied on\ndomain-specific heuristics. In this work, we explore the generation of novel\ngames in the comparatively expansive Ludii game description language, which\nencodes the rules of over 1000 board games in a variety of styles and modes of\nplay. We draw inspiration from recent advances in large language models and\nevolutionary computation in order to train a model that intelligently mutates\nand recombines games and mechanics expressed as code. We demonstrate both\nquantitatively and qualitatively that our approach is capable of generating new\nand interesting games, including in regions of the potential rules space not\ncovered by existing games in the Ludii dataset. A sample of the generated games\nare available to play online through the Ludii portal.",
      "tldr_zh": "该研究提出 GAVEL 框架，通过结合进化计算（evolutionary computation）和大型语言模型（large language models），自动生成新颖有趣的游戏规则。方法专注于 Ludii 游戏描述语言，该语言能编码超过 1000 种棋盘游戏，并通过智能变异和重组规则来探索广阔的游戏空间。实验结果显示，GAVEL 不仅定量和定性证明了生成的游戏原创性，还扩展了现有数据集未覆盖的规则区域，并提供部分游戏供在线玩耍。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures, 7 pages appendices",
      "pdf_url": "http://arxiv.org/pdf/2407.09388v2",
      "published_date": "2024-07-12 16:08:44 UTC",
      "updated_date": "2024-12-03 01:33:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:58:40.251214"
    },
    {
      "arxiv_id": "2407.09378v1",
      "title": "Graph Neural Network Causal Explanation via Neural Causal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Arman Behnam",
        "Binghui Wang"
      ],
      "abstract": "Graph neural network (GNN) explainers identify the important subgraph that\nensures the prediction for a given graph. Until now, almost all GNN explainers\nare based on association, which is prone to spurious correlations. We propose\n{\\name}, a GNN causal explainer via causal inference. Our explainer is based on\nthe observation that a graph often consists of a causal underlying subgraph.\n{\\name} includes three main steps: 1) It builds causal structure and the\ncorresponding structural causal model (SCM) for a graph, which enables the\ncause-effect calculation among nodes. 2) Directly calculating the cause-effect\nin real-world graphs is computationally challenging. It is then enlightened by\nthe recent neural causal model (NCM), a special type of SCM that is trainable,\nand design customized NCMs for GNNs. By training these GNN NCMs, the\ncause-effect can be easily calculated. 3) It uncovers the subgraph that\ncausally explains the GNN predictions via the optimized GNN-NCMs. Evaluation\nresults on multiple synthetic and real-world graphs validate that {\\name}\nsignificantly outperforms existing GNN explainers in exact groundtruth\nexplanation identification",
      "tldr_zh": "本文提出 {\\name}，一种基于因果推理的 GNN 解释器，用于识别确保预测的重要子图，避免了传统关联方法易受虚假相关的影响。方法包括三个步骤：首先构建图的因果结构和 Structural Causal Model (SCM) 以计算节点间的因果关系；其次，使用可训练的 Neural Causal Models (NCM) 定制 GNN-NCM，通过训练简化因果计算；最后，通过优化后的 GNN-NCM 揭示因果解释 GNN 预测的子图。实验结果显示，在多个合成和真实图上，{\\name} 在精确识别真实解释方面显著优于现有 GNN 解释器。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09378v1",
      "published_date": "2024-07-12 15:56:33 UTC",
      "updated_date": "2024-07-12 15:56:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:58:54.052567"
    },
    {
      "arxiv_id": "2407.09373v1",
      "title": "Towards Personalised Patient Risk Prediction Using Temporal Hospital Data Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Thea Barnes",
        "Enrico Werner",
        "Jeffrey N. Clark",
        "Raul Santos-Rodriguez"
      ],
      "abstract": "Quantifying a patient's health status provides clinicians with insight into\npatient risk, and the ability to better triage and manage resources. Early\nWarning Scores (EWS) are widely deployed to measure overall health status, and\nrisk of adverse outcomes, in hospital patients. However, current EWS are\nlimited both by their lack of personalisation and use of static observations.\nWe propose a pipeline that groups intensive care unit patients by the\ntrajectories of observations data throughout their stay as a basis for the\ndevelopment of personalised risk predictions. Feature importance is considered\nto provide model explainability. Using the MIMIC-IV dataset, six clusters were\nidentified, capturing differences in disease codes, observations, lengths of\nadmissions and outcomes. Applying the pipeline to data from just the first four\nhours of each ICU stay assigns the majority of patients to the same cluster as\nwhen the entire stay duration is considered. In-hospital mortality prediction\nmodels trained on individual clusters had higher F1 score performance in five\nof the six clusters when compared against the unclustered patient cohort. The\npipeline could form the basis of a clinical decision support tool, working to\nimprove the clinical characterisation of risk groups and the early detection of\npatient deterioration.",
      "tldr_zh": "本文针对现有 Early Warning Scores (EWS) 的局限性（如缺乏个性化及依赖静态观察数据），提出一个管道(pipeline)，通过分析 ICU 患者的观察数据轨迹来分组患者并开发个性化的风险预测模型，同时考虑特征重要性(feature importance)以提升模型可解释性。使用 MIMIC-IV 数据集，他们识别了六个集群(clusters)，这些集群捕捉了患者在疾病代码、观察数据、入院时长和结果方面的差异。实验结果显示，仅基于患者 ICU 逗留前四个小时的数据，就能将大多数患者分配到与整个逗留期相同的集群，且基于这些集群训练的住院死亡率预测模型(in-hospital mortality prediction models)在五个集群中比未聚类队列的 F1 分数性能更高。该管道可作为临床决策支持工具的基础，提高风险群体的临床表征和患者恶化早期检测。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09373v1",
      "published_date": "2024-07-12 15:53:26 UTC",
      "updated_date": "2024-07-12 15:53:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:59:05.550595"
    },
    {
      "arxiv_id": "2407.09364v2",
      "title": "Is Contrasting All You Need? Contrastive Learning for the Detection and Attribution of AI-generated Text",
      "title_zh": "翻译失败",
      "authors": [
        "Lucio La Cava",
        "Davide Costa",
        "Andrea Tagarelli"
      ],
      "abstract": "The significant progress in the development of Large Language Models has\ncontributed to blurring the distinction between human and AI-generated text.\nThe increasing pervasiveness of AI-generated text and the difficulty in\ndetecting it poses new challenges for our society. In this paper, we tackle the\nproblem of detecting and attributing AI-generated text by proposing WhosAI, a\ntriplet-network contrastive learning framework designed to predict whether a\ngiven input text has been generated by humans or AI and to unveil the\nauthorship of the text. Unlike most existing approaches, our proposed framework\nis conceived to learn semantic similarity representations from multiple\ngenerators at once, thus equally handling both detection and attribution tasks.\nFurthermore, WhosAI is model-agnostic and scalable to the release of new AI\ntext-generation models by incorporating their generated instances into the\nembedding space learned by our framework. Experimental results on the\nTuringBench benchmark of 200K news articles show that our proposed framework\nachieves outstanding results in both the Turing Test and Authorship Attribution\ntasks, outperforming all the methods listed in the TuringBench benchmark\nleaderboards.",
      "tldr_zh": "这篇论文探讨了检测和归因 AI 生成文本的挑战，提出 WhosAI 框架，该框架基于对比学习（Contrastive Learning）和三元组网络（Triplet-network），能够同时学习多个生成器的语义相似性表示，从而实现文本来源的预测和作者识别。不同于现有方法，WhosAI 是模型无关的（model-agnostic），并可扩展到新 AI 文本生成模型，通过整合其生成的实例来增强嵌入空间。实验结果显示，在包含 20 万新闻文章的 TuringBench 基准测试中，WhosAI 在图灵测试和作者归因任务中均超过了所有基准方法，展示了其卓越性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "physics.soc-ph"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication at the 27th European Conference on\n  Artificial Intelligence (ECAI-2024), Volume 392, Pages 3179 - 3186, October\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2407.09364v2",
      "published_date": "2024-07-12 15:44:56 UTC",
      "updated_date": "2025-03-17 09:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:59:18.638774"
    },
    {
      "arxiv_id": "2407.09355v1",
      "title": "FastImpute: A Baseline for Open-source, Reference-Free Genotype Imputation Methods -- A Case Study in PRS313",
      "title_zh": "翻译失败",
      "authors": [
        "Aaron Ge",
        "Jeya Balasubramanian",
        "Xueyao Wu",
        "Peter Kraft",
        "Jonas S. Almeida"
      ],
      "abstract": "Genotype imputation enhances genetic data by predicting missing SNPs using\nreference haplotype information. Traditional methods leverage linkage\ndisequilibrium (LD) to infer untyped SNP genotypes, relying on the similarity\nof LD structures between genotyped target sets and fully sequenced reference\npanels. Recently, reference-free deep learning-based methods have emerged,\noffering a promising alternative by predicting missing genotypes without\nexternal databases, thereby enhancing privacy and accessibility. However, these\nmethods often produce models with tens of millions of parameters, leading to\nchallenges such as the need for substantial computational resources to train\nand inefficiency for client-sided deployment. Our study addresses these\nlimitations by introducing a baseline for a novel genotype imputation pipeline\nthat supports client-sided imputation models generalizable across any\ngenotyping chip and genomic region. This approach enhances patient privacy by\nperforming imputation directly on edge devices. As a case study, we focus on\nPRS313, a polygenic risk score comprising 313 SNPs used for breast cancer risk\nprediction. Utilizing consumer genetic panels such as 23andMe, our model\ndemocratizes access to personalized genetic insights by allowing 23andMe users\nto obtain their PRS313 score. We demonstrate that simple linear regression can\nsignificantly improve the accuracy of PRS313 scores when calculated using SNPs\nimputed from consumer gene panels, such as 23andMe. Our linear regression model\nachieved an R^2 of 0.86, compared to 0.33 without imputation and 0.28 with\nsimple imputation (substituting missing SNPs with the minor allele frequency).\nThese findings suggest that popular SNP analysis libraries could benefit from\nintegrating linear regression models for genotype imputation, providing a\nviable and light-weight alternative to reference based imputation.",
      "tldr_zh": "该研究提出FastImpute，一种开源、参考-free的基因型推断方法，旨在解决传统方法依赖外部参考面板的问题，同时提升隐私和可访问性。该方法通过一个支持客户端侧部署的推断管道，使用简单线性回归模型，对任何基因分型芯片和基因组区域进行泛化推断。针对PRS313（一个由313个SNPs组成的乳腺癌风险预测多基因风险评分），研究利用23andMe等消费级基因面板进行案例分析，结果显示线性回归模型的R^2达到0.86，显著高于无推断（0.33）和简单推断（0.28）。这些发现表明，整合线性回归模型可为SNP分析库提供一种轻量级、有效的替代方案。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "This paper is 16 pages long and contains 7 figures. For more\n  information and to access related resources: * Web application:\n  https://aaronge-2020.github.io/DeepImpute/ * Code repository:\n  https://github.com/aaronge-2020/DeepImpute",
      "pdf_url": "http://arxiv.org/pdf/2407.09355v1",
      "published_date": "2024-07-12 15:28:13 UTC",
      "updated_date": "2024-07-12 15:28:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:59:28.185565"
    },
    {
      "arxiv_id": "2407.09348v1",
      "title": "Predictable and Performant Reactive Synthesis Modulo Theories via Functional Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Andoni Rodríguez",
        "Felipe Gorostiaga",
        "César Sánchez"
      ],
      "abstract": "Reactive synthesis is the process of generating correct controllers from\ntemporal logic specifications. Classical LTL reactive synthesis handles\n(propositional) LTL as a specification language. Boolean abstractions allow\nreducing LTLt specifications (i.e., LTL with propositions replaced by literals\nfrom a theory calT), into equi-realizable LTL specifications. In this paper we\nextend these results into a full static synthesis procedure. The synthesized\nsystem receives from the environment valuations of variables from a rich theory\ncalT and outputs valuations of system variables from calT. We use the\nabstraction method to synthesize a reactive Boolean controller from the LTL\nspecification, and we combine it with functional synthesis to obtain a static\ncontroller for the original LTLt specification. We also show that our method\nallows responses in the sense that the controller can optimize its outputs in\norder to e.g., always provide the smallest safe values. This is the first full\nstatic synthesis method for LTLt, which is a deterministic program (hence\npredictable and efficient).",
      "tldr_zh": "该论文提出了一种通过功能合成（functional synthesis）实现 LTLt 反应式合成（reactive synthesis）的完整静态方法，旨在从时间逻辑规范生成可预测且高效的控制器。方法首先使用布尔抽象将 LTLt 规范简化为等价的 LTL 规范来合成布尔控制器，然后结合功能合成扩展为处理富理论（theory T）变量的静态控制器。结果显示，该控制器不仅能优化输出（如始终提供最小安全值），还首次实现了 LTLt 的确定性程序，确保了系统的可预测性和性能。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09348v1",
      "published_date": "2024-07-12 15:23:27 UTC",
      "updated_date": "2024-07-12 15:23:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:59:40.133986"
    },
    {
      "arxiv_id": "2407.09337v1",
      "title": "CFaults: Model-Based Diagnosis for Fault Localization in C Programs with Multiple Test Cases",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Orvalho",
        "Mikoláš Janota",
        "Vasco Manquinho"
      ],
      "abstract": "Debugging is one of the most time-consuming and expensive tasks in software\ndevelopment. Several formula-based fault localization (FBFL) methods have been\nproposed, but they fail to guarantee a set of diagnoses across all failing\ntests or may produce redundant diagnoses that are not subset-minimal,\nparticularly for programs with multiple faults.\n  This paper introduces a novel fault localization approach for C programs with\nmultiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple\nobservations and aggregates all failing test cases into a unified MaxSAT\nformula. Consequently, our method guarantees consistency across observations\nand simplifies the fault localization procedure. Experimental results on two\nbenchmark sets of C programs, TCAS and C-Pack-IPAs, show that CFaults is faster\nthan other FBFL approaches like BugAssist and SNIPER. Moreover, CFaults only\ngenerates subset-minimal diagnoses of faulty statements, whereas the other\napproaches tend to enumerate redundant diagnoses.",
      "tldr_zh": "这篇论文提出了 CFaults，一种基于 Model-Based Diagnosis (MBD) 的新型故障定位方法，针对 C 程序中的多个故障问题，通过将所有失败测试案例聚合到一个统一的 MaxSAT 公式中，确保诊断的一致性和子集最小性，从而简化了调试过程。相比现有的 Formula-Based Fault Localization (FBFL) 方法如 BugAssist 和 SNIPER，CFaults 在 TCAS 和 C-Pack-IPAs 基准集上的实验显示，它运行更快，并且仅生成非冗余的子集最小诊断。总的来说，该方法有助于提高软件开发中的调试效率和准确性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at FM 2024. 15 pages, 2 figures, 3 tables and 5 listings",
      "pdf_url": "http://arxiv.org/pdf/2407.09337v1",
      "published_date": "2024-07-12 15:14:49 UTC",
      "updated_date": "2024-07-12 15:14:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:59:53.738270"
    },
    {
      "arxiv_id": "2407.09336v1",
      "title": "Guidelines for Augmentation Selection in Contrastive Learning for Time Series Classification",
      "title_zh": "对比学习中时间序列分类的增强选择指南",
      "authors": [
        "Ziyu Liu",
        "Azadeh Alavi",
        "Minyi Li",
        "Xiang Zhang"
      ],
      "abstract": "Self-supervised contrastive learning has become a key technique in deep\nlearning, particularly in time series analysis, due to its ability to learn\nmeaningful representations without explicit supervision. Augmentation is a\ncritical component in contrastive learning, where different augmentations can\ndramatically impact performance, sometimes influencing accuracy by over 30%.\nHowever, the selection of augmentations is predominantly empirical which can be\nsuboptimal, or grid searching that is time-consuming. In this paper, we\nestablish a principled framework for selecting augmentations based on dataset\ncharacteristics such as trend and seasonality. Specifically, we construct 12\nsynthetic datasets incorporating trend, seasonality, and integration weights.\nWe then evaluate the effectiveness of 8 different augmentations across these\nsynthetic datasets, thereby inducing generalizable associations between time\nseries characteristics and augmentation efficiency. Additionally, we evaluated\nthe induced associations across 6 real-world datasets encompassing domains such\nas activity recognition, disease diagnosis, traffic monitoring, electricity\nusage, mechanical fault prognosis, and finance. These real-world datasets are\ndiverse, covering a range from 1 to 12 channels, 2 to 10 classes, sequence\nlengths of 14 to 1280, and data frequencies from 250 Hz to daily intervals. The\nexperimental results show that our proposed trend-seasonality-based\naugmentation recommendation algorithm can accurately identify the effective\naugmentations for a given time series dataset, achieving an average Recall@3 of\n0.667, outperforming baselines. Our work provides guidance for studies\nemploying contrastive learning in time series analysis, with wide-ranging\napplications. All the code, datasets, and analysis results will be released at\nhttps://github.com/DL4mHealth/TS-Contrastive-Augmentation-Recommendation.",
      "tldr_zh": "这篇论文针对自监督对比学习（Self-supervised contrastive learning）在时间序列分类中的增强选择问题，提出一个基于数据集特性的原则框架，特别是考虑趋势（trend）和季节性（seasonality）。作者构建了12个合成数据集来评估8种不同增强的效果，并验证了这些增强与时间序列特征的关联，在6个真实数据集（如活动识别和疾病诊断）上进行测试。实验结果显示，该框架的增强推荐算法平均Recall@3达到0.667，显著优于基线方法，为时间序列分析中的对比学习提供实用指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.09336v1",
      "published_date": "2024-07-12 15:13:16 UTC",
      "updated_date": "2024-07-12 15:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:00:04.077627"
    },
    {
      "arxiv_id": "2407.09327v1",
      "title": "Sina at FigNews 2024: Multilingual Datasets Annotated with Bias and Propaganda",
      "title_zh": "翻译失败",
      "authors": [
        "Lina Duaibes",
        "Areej Jaber",
        "Mustafa Jarrar",
        "Ahmad Qadi",
        "Mais Qandeel"
      ],
      "abstract": "The proliferation of bias and propaganda on social media is an increasingly\nsignificant concern, leading to the development of techniques for automatic\ndetection. This article presents a multilingual corpus of 12, 000 Facebook\nposts fully annotated for bias and propaganda. The corpus was created as part\nof the FigNews 2024 Shared Task on News Media Narratives for framing the\nIsraeli War on Gaza. It covers various events during the War from October 7,\n2023 to January 31, 2024. The corpus comprises 12, 000 posts in five languages\n(Arabic, Hebrew, English, French, and Hindi), with 2, 400 posts for each\nlanguage. The annotation process involved 10 graduate students specializing in\nLaw. The Inter-Annotator Agreement (IAA) was used to evaluate the annotations\nof the corpus, with an average IAA of 80.8% for bias and 70.15% for propaganda\nannotations. Our team was ranked among the bestperforming teams in both Bias\nand Propaganda subtasks. The corpus is open-source and available at\nhttps://sina.birzeit.edu/fada",
      "tldr_zh": "这篇论文介绍了Sina团队在FigNews 2024共享任务中创建的Multilingual Datasets，这是一个包含12,000个Facebook帖子的多语言语料库，用于检测社交媒体上的Bias和Propaganda。语料库覆盖了2023年10月7日至2024年1月31日以色列战争相关事件，包括阿拉伯语、希伯来语、英语、法语和印地语，每种语言2,400个帖子，由10名法律专业的研究生进行标注。标注过程的Inter-Annotator Agreement (IAA)平均为Bias的80.8%和Propaganda的70.15%，显示出较高的可靠性。团队在Bias和Propaganda子任务中排名领先，并将该开源语料库发布在https://sina.birzeit.edu/fada，以支持进一步的研究。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09327v1",
      "published_date": "2024-07-12 15:04:09 UTC",
      "updated_date": "2024-07-12 15:04:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:00:17.628042"
    },
    {
      "arxiv_id": "2407.09324v2",
      "title": "Provable Privacy Advantages of Decentralized Federated Learning via Distributed Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Wenrui Yu",
        "Qiongxiu Li",
        "Milan Lopuhaä-Zwakenberg",
        "Mads Græsbøll Christensen",
        "Richard Heusdens"
      ],
      "abstract": "Federated learning (FL) emerged as a paradigm designed to improve data\nprivacy by enabling data to reside at its source, thus embedding privacy as a\ncore consideration in FL architectures, whether centralized or decentralized.\nContrasting with recent findings by Pasquini et al., which suggest that\ndecentralized FL does not empirically offer any additional privacy or security\nbenefits over centralized models, our study provides compelling evidence to the\ncontrary. We demonstrate that decentralized FL, when deploying distributed\noptimization, provides enhanced privacy protection - both theoretically and\nempirically - compared to centralized approaches. The challenge of quantifying\nprivacy loss through iterative processes has traditionally constrained the\ntheoretical exploration of FL protocols. We overcome this by conducting a\npioneering in-depth information-theoretical privacy analysis for both\nframeworks. Our analysis, considering both eavesdropping and passive adversary\nmodels, successfully establishes bounds on privacy leakage. We show information\ntheoretically that the privacy loss in decentralized FL is upper bounded by the\nloss in centralized FL. Compared to the centralized case where local gradients\nof individual participants are directly revealed, a key distinction of\noptimization-based decentralized FL is that the relevant information includes\ndifferences of local gradients over successive iterations and the aggregated\nsum of different nodes' gradients over the network. This information\ncomplicates the adversary's attempt to infer private data. To bridge our\ntheoretical insights with practical applications, we present detailed case\nstudies involving logistic regression and deep neural networks. These examples\ndemonstrate that while privacy leakage remains comparable in simpler models,\ncomplex models like deep neural networks exhibit lower privacy risks under\ndecentralized FL.",
      "tldr_zh": "本研究证明了去中心化 Federated Learning 通过分布式 Optimization 在隐私保护方面比集中式方法更具优势，挑战了先前实证观点。研究采用信息理论分析，包括窃听和被动攻击者模型，建立了隐私泄露的上界，并显示去中心化 FL 的隐私损失被限制在局部梯度差异和网络聚合信息上，而非直接揭示局部梯度。实验案例如逻辑回归和深度神经网络表明，在复杂模型中，去中心化 FL 的隐私风险显著降低，为 FL 协议提供了更可靠的理论和实践基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09324v2",
      "published_date": "2024-07-12 15:01:09 UTC",
      "updated_date": "2024-11-30 14:35:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:00:29.769011"
    },
    {
      "arxiv_id": "2407.09287v1",
      "title": "Instruction Following with Goal-Conditioned Reinforcement Learning in Virtual Environments",
      "title_zh": "在虚拟环境中基于目标条件强化学习的指令跟随",
      "authors": [
        "Zoya Volovikova",
        "Alexey Skrynnik",
        "Petr Kuderov",
        "Aleksandr I. Panov"
      ],
      "abstract": "In this study, we address the issue of enabling an artificial intelligence\nagent to execute complex language instructions within virtual environments. In\nour framework, we assume that these instructions involve intricate linguistic\nstructures and multiple interdependent tasks that must be navigated\nsuccessfully to achieve the desired outcomes. To effectively manage these\ncomplexities, we propose a hierarchical framework that combines the deep\nlanguage comprehension of large language models with the adaptive\naction-execution capabilities of reinforcement learning agents. The language\nmodule (based on LLM) translates the language instruction into a high-level\naction plan, which is then executed by a pre-trained reinforcement learning\nagent. We have demonstrated the effectiveness of our approach in two different\nenvironments: in IGLU, where agents are instructed to build structures, and in\nCrafter, where agents perform tasks and interact with objects in the\nsurrounding environment according to language commands.",
      "tldr_zh": "本研究针对AI代理在虚拟环境中执行复杂语言指令的问题，提出了一种分层框架，将大型语言模型(LLM)的深度语言理解与强化学习(Reinforcement Learning)代理的适应性行动执行相结合。LLM负责将指令转化为高层行动计划，由预训练的强化学习代理负责实际执行。该方法在IGLU（构建结构任务）和Crafter（互动对象任务）环境中得到验证，展示了其处理多任务和互依赖指令的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09287v1",
      "published_date": "2024-07-12 14:19:36 UTC",
      "updated_date": "2024-07-12 14:19:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:00:41.974390"
    },
    {
      "arxiv_id": "2407.11068v5",
      "title": "Show, Don't Tell: Evaluating Large Language Models Beyond Textual Understanding with ChildPlay",
      "title_zh": "翻译失败",
      "authors": [
        "Gonçalo Hora de Carvalho",
        "Oscar Knap",
        "Robert Pollice"
      ],
      "abstract": "We developed a benchmark set to assess the generalization of state-of-the-art\nlarge language models on problems beyond linguistic tasks and evaluate it on a\nsystematic progression of GPT models (GPT-3.5, GPT-4, GPT-4o, GPT-4o-mini).\nUsing simple games like Tic-Tac-Toe, Connect Four, Battleship, and a Shape\nRecognition Game, all encoded in ASCII, we test strategic capabilities and\nspatial reasoning, core abilities any artificial intelligence would need to\nmaster for solving problems in chemistry. To probe generalization, we introduce\ntwo new games for spatial logic: LEGO Connect Language (LCL) and\nGuess-the-SMILES (GtS), a operationally simple chemistry benchmark. Our results\nshow that GPT models provide meaningful responses for several tasks but,\ngenerally, perform poorly. A systematic performance progression with increased\nmodel capabilities (GPT-3.5, GPT-4, GPT-4o) is only observed for 4 out of the 7\nbenchmark tasks. All models consistently struggle with Battleship, LCL, and\nGtS. This suggests that while GPT models can emulate conversational proficiency\nand basic rule comprehension, they have limited generalization with respect to\nstrategy and spatial reasoning. Particularly poor performance is observed for\ninterpreting molecular graphs when encoded in ASCII. The results provided by\nour open-source benchmark suite\n(\\href{https://github.com/BlueVelvetSackOfGoldPotatoes/child-play}{\\texttt{ChildPlay}\nGitHub Repository}) caution against claims of emergent intelligence in GPT\nmodels, which appear more specialized than general.",
      "tldr_zh": "本研究开发了ChildPlay基准测试集，用于评估大型语言模型（LLMs）在非语言任务上的泛化能力，测试对象包括GPT-3.5、GPT-4、GPT-4o和GPT-4o-mini。研究通过简单ASCII编码游戏如Tic-Tac-Toe、Connect Four、Battleship和Shape Recognition Game，以及新引入的LEGO Connect Language (LCL)和Guess-the-SMILES (GtS)游戏，考察模型的战略能力和空间推理。结果显示，GPT模型在部分任务上给出有意义的响应，但整体表现较差，仅在7个基准任务中的4个上观察到模型能力提升；所有模型在Battleship、LCL和GtS上持续挣扎，特别是在解读ASCII编码的分子图方面。研究警告，LLMs更倾向于专业化而非通用智能，并提供开源基准套件（ChildPlay GitHub Repository）以促进进一步评估。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11068v5",
      "published_date": "2024-07-12 14:17:26 UTC",
      "updated_date": "2025-02-27 21:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:00:56.193120"
    },
    {
      "arxiv_id": "2407.09283v2",
      "title": "DAHRS: Divergence-Aware Hallucination-Remediated SRL Projection",
      "title_zh": "翻译失败",
      "authors": [
        "Sangpil Youm",
        "Brodie Mather",
        "Chathuri Jayaweera",
        "Juliana Prada",
        "Bonnie Dorr"
      ],
      "abstract": "Semantic role labeling (SRL) enriches many downstream applications, e.g.,\nmachine translation, question answering, summarization, and stance/belief\ndetection. However, building multilingual SRL models is challenging due to the\nscarcity of semantically annotated corpora for multiple languages. Moreover,\nstate-of-the-art SRL projection (XSRL) based on large language models (LLMs)\nyields output that is riddled with spurious role labels. Remediation of such\nhallucinations is not straightforward due to the lack of explainability of\nLLMs. We show that hallucinated role labels are related to naturally occurring\ndivergence types that interfere with initial alignments. We implement\nDivergence-Aware Hallucination-Remediated SRL projection (DAHRS), leveraging\nlinguistically-informed alignment remediation followed by greedy First-Come\nFirst-Assign (FCFA) SRL projection. DAHRS improves the accuracy of SRL\nprojection without additional transformer-based machinery, beating XSRL in both\nhuman and automatic comparisons, and advancing beyond headwords to accommodate\nphrase-level SRL projection (e.g., EN-FR, EN-ES). Using CoNLL-2009 as our\nground truth, we achieve a higher word-level F1 over XSRL: 87.6% vs. 77.3%\n(EN-FR) and 89.0% vs. 82.7% (EN-ES). Human phrase-level assessments yield 89.1%\n(EN-FR) and 91.0% (EN-ES). We also define a divergence metric to adapt our\napproach to other language pairs (e.g., English-Tagalog).",
      "tldr_zh": "该论文提出DAHRS框架，用于改进语义角色标注(SRL)投影，解决大型语言模型(LLMs)基于的XSRL方法中存在的幻觉(hallucination)和虚假角色标签问题。DAHRS通过语言学信息驱动的对齐修复和贪婪的First-Come First-Assign (FCFA)投影，处理自然发散类型(divergence types)，从而提升多语言SRL的准确性。实验结果显示，在CoNLL-2009数据集上，DAHRS在EN-FR语对的词级F1分数达到87.6%（比XSRL的77.3%高），EN-ES达到89.0%（比XSRL的82.7%高），并在短语级投影上表现优异，还定义了发散指标以适应其他语对如English-Tagalog。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 6 figures, Accepted to The 29th International Conference on\n  Natural Language & Information Systems (NLDB 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.09283v2",
      "published_date": "2024-07-12 14:13:59 UTC",
      "updated_date": "2025-03-19 13:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:01:09.895020"
    },
    {
      "arxiv_id": "2407.09281v2",
      "title": "Predicting and Understanding Human Action Decisions: Insights from Large Language Models and Cognitive Instance-Based Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Thuy Ngoc Nguyen",
        "Kasturi Jamale",
        "Cleotilde Gonzalez"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated their capabilities across\nvarious tasks, from language translation to complex reasoning. Understanding\nand predicting human behavior and biases are crucial for artificial\nintelligence (AI) assisted systems to provide useful assistance, yet it remains\nan open question whether these models can achieve this. This paper addresses\nthis gap by leveraging the reasoning and generative capabilities of the LLMs to\npredict human behavior in two sequential decision-making tasks. These tasks\ninvolve balancing between exploitative and exploratory actions and handling\ndelayed feedback, both essential for simulating real-life decision processes.\nWe compare the performance of LLMs with a cognitive instance-based learning\n(IBL) model, which imitates human experiential decision-making. Our findings\nindicate that LLMs excel at rapidly incorporating feedback to enhance\nprediction accuracy. In contrast, the cognitive IBL model better accounts for\nhuman exploratory behaviors and effectively captures loss aversion bias, i.e.,\nthe tendency to choose a sub-optimal goal with fewer step-cost penalties rather\nthan exploring to find the optimal choice, even with limited experience. The\nresults highlight the benefits of integrating LLMs with cognitive\narchitectures, suggesting that this synergy could enhance the modeling and\nunderstanding of complex human decision-making patterns.",
      "tldr_zh": "本论文探讨了利用 Large Language Models (LLMs) 来预测和理解人类在顺序决策任务中的行为，包括平衡利用与探索行为以及处理延迟反馈，并将其与 cognitive instance-based learning (IBL) 模型进行比较。研究发现，LLMs 能够快速整合反馈从而提升预测准确性，而 IBL 模型更擅长捕捉人类的探索倾向和损失厌恶偏差，例如倾向于选择次优目标以避免额外成本。总体而言，这些结果突出了 LLMs 与认知架构相结合的潜力，有助于更全面地建模和理解复杂的人类决策模式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09281v2",
      "published_date": "2024-07-12 14:13:06 UTC",
      "updated_date": "2024-08-05 16:16:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:01:19.052983"
    },
    {
      "arxiv_id": "2407.09274v1",
      "title": "Unifying Sequences, Structures, and Descriptions for Any-to-Any Protein Generation with the Large Multimodal Model HelixProtX",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Chen",
        "Tianhao Chen",
        "Chenggang Xie",
        "Yang Xue",
        "Xiaonan Zhang",
        "Jingbo Zhou",
        "Xiaomin Fang"
      ],
      "abstract": "Proteins are fundamental components of biological systems and can be\nrepresented through various modalities, including sequences, structures, and\ntextual descriptions. Despite the advances in deep learning and scientific\nlarge language models (LLMs) for protein research, current methodologies\npredominantly focus on limited specialized tasks -- often predicting one\nprotein modality from another. These approaches restrict the understanding and\ngeneration of multimodal protein data. In contrast, large multimodal models\nhave demonstrated potential capabilities in generating any-to-any content like\ntext, images, and videos, thus enriching user interactions across various\ndomains. Integrating these multimodal model technologies into protein research\noffers significant promise by potentially transforming how proteins are\nstudied. To this end, we introduce HelixProtX, a system built upon the large\nmultimodal model, aiming to offer a comprehensive solution to protein research\nby supporting any-to-any protein modality generation. Unlike existing methods,\nit allows for the transformation of any input protein modality into any desired\nprotein modality. The experimental results affirm the advanced capabilities of\nHelixProtX, not only in generating functional descriptions from amino acid\nsequences but also in executing critical tasks such as designing protein\nsequences and structures from textual descriptions. Preliminary findings\nindicate that HelixProtX consistently achieves superior accuracy across a range\nof protein-related tasks, outperforming existing state-of-the-art models. By\nintegrating multimodal large models into protein research, HelixProtX opens new\navenues for understanding protein biology, thereby promising to accelerate\nscientific discovery.",
      "tldr_zh": "该论文提出 HelixProtX，这是一个基于 Large Multimodal Model 的系统，旨在统一蛋白质的 sequences、structures 和 descriptions，实现任意模式之间的 any-to-any 生成，从而解决现有方法在蛋白质研究中的局限性。不同于传统的单一模式预测，HelixProtX 支持从氨基酸序列生成功能描述，或从文本描述设计蛋白质序列和结构等任务。实验结果显示，HelixProtX 在多种蛋白质相关任务中表现出色，准确性超越现有最先进模型，并为理解蛋白质生物学和加速科学发现开辟新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09274v1",
      "published_date": "2024-07-12 14:03:02 UTC",
      "updated_date": "2024-07-12 14:03:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:01:31.137535"
    },
    {
      "arxiv_id": "2407.09251v1",
      "title": "Deep Adversarial Defense Against Multilevel-Lp Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Ren Wang",
        "Yuxuan Li",
        "Alfred Hero"
      ],
      "abstract": "Deep learning models have shown considerable vulnerability to adversarial\nattacks, particularly as attacker strategies become more sophisticated. While\ntraditional adversarial training (AT) techniques offer some resilience, they\noften focus on defending against a single type of attack, e.g., the\n$\\ell_\\infty$-norm attack, which can fail for other types. This paper\nintroduces a computationally efficient multilevel $\\ell_p$ defense, called the\nEfficient Robust Mode Connectivity (EMRC) method, which aims to enhance a deep\nlearning model's resilience against multiple $\\ell_p$-norm attacks. Similar to\nanalytical continuation approaches used in continuous optimization, the method\nblends two $p$-specific adversarially optimal models, the $\\ell_1$- and\n$\\ell_\\infty$-norm AT solutions, to provide good adversarial robustness for a\nrange of $p$. We present experiments demonstrating that our approach performs\nbetter on various attacks as compared to AT-$\\ell_\\infty$, E-AT, and MSD, for\ndatasets/architectures including: CIFAR-10, CIFAR-100 / PreResNet110,\nWideResNet, ViT-Base.",
      "tldr_zh": "本论文探讨了深度学习模型对多级 ℓp 攻击的脆弱性，传统对抗训练（AT）方法往往仅针对特定攻击（如 ℓ∞-norm）有效，而忽略其他类型。作者提出 Efficient Robust Mode Connectivity (EMRC) 方法，通过融合 ℓ1 和 ℓ∞ 范数 AT 模型，类似于分析连续优化技术，从而提升模型对多种 ℓp 攻击的鲁棒性。实验结果显示，在 CIFAR-10、CIFAR-100 等数据集及架构（如 PreResNet110、WideResNet、ViT-Base）上，EMRC 比 AT-ℓ∞、E-AT 和 MSD 方法表现出色，提供更全面的防御性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09251v1",
      "published_date": "2024-07-12 13:30:00 UTC",
      "updated_date": "2024-07-12 13:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:01:43.351293"
    },
    {
      "arxiv_id": "2407.09249v2",
      "title": "Graph Neural Networks with Model-based Reinforcement Learning for Multi-agent Systems",
      "title_zh": "图神经网络结合基于模型的强化学习用于多智能体系统",
      "authors": [
        "Hanxiao Chen"
      ],
      "abstract": "Multi-agent systems (MAS) constitute a significant role in exploring machine\nintelligence and advanced applications. In order to deeply investigate\ncomplicated interactions within MAS scenarios, we originally propose \"GNN for\nMBRL\" model, which utilizes a state-spaced Graph Neural Networks with\nModel-based Reinforcement Learning to address specific MAS missions (e.g.,\nBilliard-Avoidance, Autonomous Driving Cars). In detail, we firstly used GNN\nmodel to predict future states and trajectories of multiple agents, then\napplied the Cross-Entropy Method (CEM) optimized Model Predictive Control to\nassist the ego-agent planning actions and successfully accomplish certain MAS\ntasks.",
      "tldr_zh": "本论文提出了一种名为\"GNN for MBRL\"的模型，结合图神经网络(GNN)和基于模型的强化学习(Model-based Reinforcement Learning)，用于处理多智能体系统(MAS)的复杂交互任务，如台球避障(Billiard-Avoidance)和自动驾驶汽车(Autonomous Driving Cars)。具体方法包括使用GNN预测多个智能体的未来状态和轨迹，然后应用交叉熵方法(CEM)优化的模型预测控制(Model Predictive Control)来辅助主体智能体规划行动并完成任务。该框架通过深度整合GNN和强化学习，提升了MAS场景下的决策效率和准确性。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "The paper abstract has been accepted by NeurIPS 2024 WiML\n  Workshop.(https://www.wiml.org/events/wiml-workshop-%40-neurips-2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.09249v2",
      "published_date": "2024-07-12 13:21:35 UTC",
      "updated_date": "2024-09-29 13:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:01:56.557062"
    },
    {
      "arxiv_id": "2407.09247v1",
      "title": "Constrained Intrinsic Motivation for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Zheng",
        "Xingjun Ma",
        "Chao Shen",
        "Cong Wang"
      ],
      "abstract": "This paper investigates two fundamental problems that arise when utilizing\nIntrinsic Motivation (IM) for reinforcement learning in Reward-Free\nPre-Training (RFPT) tasks and Exploration with Intrinsic Motivation (EIM)\ntasks: 1) how to design an effective intrinsic objective in RFPT tasks, and 2)\nhow to reduce the bias introduced by the intrinsic objective in EIM tasks.\nExisting IM methods suffer from static skills, limited state coverage, sample\ninefficiency in RFPT tasks, and suboptimality in EIM tasks. To tackle these\nproblems, we propose \\emph{Constrained Intrinsic Motivation (CIM)} for RFPT and\nEIM tasks, respectively: 1) CIM for RFPT maximizes the lower bound of the\nconditional state entropy subject to an alignment constraint on the state\nencoder network for efficient dynamic and diverse skill discovery and state\ncoverage maximization; 2) CIM for EIM leverages constrained policy optimization\nto adaptively adjust the coefficient of the intrinsic objective to mitigate the\ndistraction from the intrinsic objective. In various MuJoCo robotics\nenvironments, we empirically show that CIM for RFPT greatly surpasses fifteen\nIM methods for unsupervised skill discovery in terms of skill diversity, state\ncoverage, and fine-tuning performance. Additionally, we showcase the\neffectiveness of CIM for EIM in redeeming intrinsic rewards when task rewards\nare exposed from the beginning. Our code is available at\nhttps://github.com/x-zheng16/CIM.",
      "tldr_zh": "这篇论文针对强化学习中 Intrinsic Motivation (IM) 的问题，提出了 Constrained Intrinsic Motivation (CIM) 方法，以解决 Reward-Free Pre-Training (RFPT) 任务中技能静态化、状态覆盖有限和样本效率低的问题，以及 Exploration with Intrinsic Motivation (EIM) 任务中内在目标引入的偏差。CIM for RFPT 通过最大化条件状态熵的下界并施加对状态编码器网络的 align 约束，实现高效的动态技能发现和状态覆盖最大化；CIM for EIM 则利用 constrained policy optimization 自适应调整内在目标系数，减少干扰。在 MuJoCo 机器人环境中，实验结果显示 CIM for RFPT 在技能多样性、状态覆盖和微调性能上超越了 15 个现有 IM 方法，同时 CIM for EIM 在任务奖励暴露时表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.09247v1",
      "published_date": "2024-07-12 13:20:52 UTC",
      "updated_date": "2024-07-12 13:20:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:02:08.668856"
    },
    {
      "arxiv_id": "2407.12863v2",
      "title": "Token-Supervised Value Models for Enhancing Mathematical Problem-Solving Capabilities of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jung Hyun Lee",
        "June Yong Yang",
        "Byeongho Heo",
        "Dongyoon Han",
        "Kyungsu Kim",
        "Eunho Yang",
        "Kang Min Yoo"
      ],
      "abstract": "With the rapid advancement of test-time compute search strategies to improve\nthe mathematical problem-solving capabilities of large language models (LLMs),\nthe need for building robust verifiers has become increasingly important.\nHowever, all these inference strategies rely on existing verifiers originally\ndesigned for Best-of-N search, which makes them sub-optimal for tree search\ntechniques at test time. During tree search, existing verifiers can only offer\nindirect and implicit assessments of partial solutions or under-value\nprospective intermediate steps, thus resulting in the premature pruning of\npromising intermediate steps. To overcome these limitations, we propose\ntoken-supervised value models (TVMs) - a new class of verifiers that assign\neach token a probability that reflects the likelihood of reaching the correct\nfinal answer. This new token-level supervision enables TVMs to directly and\nexplicitly evaluate partial solutions, effectively distinguishing between\npromising and incorrect intermediate steps during tree search at test time.\nExperimental results demonstrate that combining tree-search-based inference\nstrategies with TVMs significantly improves the accuracy of LLMs in\nmathematical problem-solving tasks, surpassing the performance of existing\nverifiers.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在数学问题解决中的测试时计算搜索策略，提出了Token-Supervised Value Models (TVMs)作为一种新型验证器，以解决现有验证器在树搜索技术中的局限性，如无法直接评估部分解决方案导致的过早修剪。TVMs通过为每个token分配一个概率来反映达到正确最终答案的可能性，从而实现对部分解决方案的直接和明确评估。相比Best-of-N搜索优化设计的验证器，TVMs能有效区分有前景的中间步骤，提升树搜索的效率。实验结果显示，将TVMs与树搜索策略结合后，LLMs在数学任务中的准确性显著提高，超过了现有验证器的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12863v2",
      "published_date": "2024-07-12 13:16:50 UTC",
      "updated_date": "2025-03-10 14:24:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:02:18.549718"
    },
    {
      "arxiv_id": "2407.09239v1",
      "title": "FedVAE: Trajectory privacy preserving based on Federated Variational AutoEncoder",
      "title_zh": "FedVAE：基于联邦变分自编码器的轨迹隐私保护",
      "authors": [
        "Yuchen Jiang",
        "Ying Wu",
        "Shiyao Zhang",
        "James J. Q. Yu"
      ],
      "abstract": "The use of trajectory data with abundant spatial-temporal information is\npivotal in Intelligent Transport Systems (ITS) and various traffic system\ntasks. Location-Based Services (LBS) capitalize on this trajectory data to\noffer users personalized services tailored to their location information.\nHowever, this trajectory data contains sensitive information about users'\nmovement patterns and habits, necessitating confidentiality and protection from\nunknown collectors. To address this challenge, privacy-preserving methods like\nK-anonymity and Differential Privacy have been proposed to safeguard private\ninformation in the dataset. Despite their effectiveness, these methods can\nimpact the original features by introducing perturbations or generating\nunrealistic trajectory data, leading to suboptimal performance in downstream\ntasks. To overcome these limitations, we propose a Federated Variational\nAutoEncoder (FedVAE) approach, which effectively generates a new trajectory\ndataset while preserving the confidentiality of private information and\nretaining the structure of the original features. In addition, FedVAE leverages\nVariational AutoEncoder (VAE) to maintain the original feature space and\ngenerate new trajectory data, and incorporates Federated Learning (FL) during\nthe training stage, ensuring that users' data remains locally stored to protect\ntheir personal information. The results demonstrate its superior performance\ncompared to other existing methods, affirming FedVAE as a promising solution\nfor enhancing data privacy and utility in location-based applications.",
      "tldr_zh": "该论文针对轨迹数据在智能交通系统（ITS）和位置服务（LBS）中的应用，提出FedVAE方法，以解决传统隐私保护技术如K-anonymity和Differential Privacy可能扰动数据或生成不现实轨迹的问题。FedVAE结合Variational AutoEncoder (VAE)生成新轨迹数据集，保留原特征结构，同时利用Federated Learning (FL)确保数据本地存储，从而保护用户隐私。实验结果显示，FedVAE在位置-based应用中比现有方法表现出色，提升了数据隐私和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "2023 IEEE 98th Vehicular Technology Conference",
      "pdf_url": "http://arxiv.org/pdf/2407.09239v1",
      "published_date": "2024-07-12 13:10:59 UTC",
      "updated_date": "2024-07-12 13:10:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:02:29.246946"
    },
    {
      "arxiv_id": "2407.09221v1",
      "title": "Evaluating AI Evaluation: Perils and Prospects",
      "title_zh": "翻译失败",
      "authors": [
        "John Burden"
      ],
      "abstract": "As AI systems appear to exhibit ever-increasing capability and generality,\nassessing their true potential and safety becomes paramount. This paper\ncontends that the prevalent evaluation methods for these systems are\nfundamentally inadequate, heightening the risks and potential hazards\nassociated with AI. I argue that a reformation is required in the way we\nevaluate AI systems and that we should look towards cognitive sciences for\ninspiration in our approaches, which have a longstanding tradition of assessing\ngeneral intelligence across diverse species. We will identify some of the\ndifficulties that need to be overcome when applying cognitively-inspired\napproaches to general-purpose AI systems and also analyse the emerging area of\n\"Evals\". The paper concludes by identifying promising research pathways that\ncould refine AI evaluation, advancing it towards a rigorous scientific domain\nthat contributes to the development of safe AI systems.",
      "tldr_zh": "这篇论文指出，现有的 AI 评估方法存在根本性缺陷，可能加剧 AI 系统的风险和潜在危害。作者主张从认知 sciences 汲取灵感，改革评估方法，以借鉴其评估不同物种一般智能的传统。论文分析了将认知启发方法应用于通用 AI 系统面临的困难，并探讨了新兴领域 \"Evals\"。最终，它提出有前景的研究路径，以提升 AI 评估的科学性和严谨性，促进安全 AI 系统的发展。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Pre-print",
      "pdf_url": "http://arxiv.org/pdf/2407.09221v1",
      "published_date": "2024-07-12 12:37:13 UTC",
      "updated_date": "2024-07-12 12:37:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:02:42.023542"
    },
    {
      "arxiv_id": "2407.09212v4",
      "title": "Generating $SROI^-$ Ontologies via Knowledge Graph Query Embedding Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yunjie He",
        "Daniel Hernandez",
        "Mojtaba Nayyeri",
        "Bo Xiong",
        "Yuqicheng Zhu",
        "Evgeny Kharlamov",
        "Steffen Staab"
      ],
      "abstract": "Query embedding approaches answer complex logical queries over incomplete\nknowledge graphs (KGs) by computing and operating on low-dimensional vector\nrepresentations of entities, relations, and queries. However, current query\nembedding models heavily rely on excessively parameterized neural networks and\ncannot explain the knowledge learned from the graph. We propose a novel query\nembedding method, AConE, which explains the knowledge learned from the graph in\nthe form of $SROI^-$ description logic axioms while being more\nparameter-efficient than most existing approaches. AConE associates queries to\na $SROI^-$ description logic concept. Every $SROI^-$ concept is embedded as a\ncone in complex vector space, and each $SROI^-$ relation is embedded as a\ntransformation that rotates and scales cones. We show theoretically that AConE\ncan learn $SROI^-$ axioms, and defines an algebra whose operations correspond\none to one to $SROI^-$ description logic concept constructs. Our empirical\nstudy on multiple query datasets shows that AConE achieves superior results\nover previous baselines with fewer parameters. Notably on the WN18RR dataset,\nAConE achieves significant improvement over baseline models. We provide\ncomprehensive analyses showing that the capability to represent axioms\npositively impacts the results of query answering.",
      "tldr_zh": "这篇论文提出了一种新型查询嵌入方法 AConE，用于在不完整的知识图谱(KGs)上回答复杂逻辑查询，同时以 $SROI^-$ 描述逻辑公理的形式解释学到的知识，并显著减少参数数量。AConE 将查询关联到 $SROI^-$ 概念，并将这些概念嵌入为复杂向量空间中的锥（cone），而关系则嵌入为锥的旋转和缩放变换。理论上，该方法能学习 $SROI^-$ 公理，并定义一个代数操作与 $SROI^-$ 概念构造一一对应。实验在多个数据集上显示，AConE 比基线模型性能更优，使用更少参数，在 WN18RR 数据集上实现显著提升，且代表公理的能力正向影响查询回答结果。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.09212v4",
      "published_date": "2024-07-12 12:20:39 UTC",
      "updated_date": "2024-08-27 13:40:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:02:55.810128"
    },
    {
      "arxiv_id": "2407.09585v1",
      "title": "A Scale-Invariant Diagnostic Approach Towards Understanding Dynamics of Deep Neural Networks",
      "title_zh": "一种尺度不变的诊断方法，旨在理解深度神经",
      "authors": [
        "Ambarish Moharil",
        "Damian Tamburri",
        "Indika Kumara",
        "Willem-Jan Van Den Heuvel",
        "Alireza Azarfar"
      ],
      "abstract": "This paper introduces a scale-invariant methodology employing \\textit{Fractal\nGeometry} to analyze and explain the nonlinear dynamics of complex\nconnectionist systems. By leveraging architectural self-similarity in Deep\nNeural Networks (DNNs), we quantify fractal dimensions and \\textit{roughness}\nto deeply understand their dynamics and enhance the quality of\n\\textit{intrinsic} explanations. Our approach integrates principles from Chaos\nTheory to improve visualizations of fractal evolution and utilizes a\nGraph-Based Neural Network for reconstructing network topology. This strategy\naims at advancing the \\textit{intrinsic} explainability of connectionist\nArtificial Intelligence (AI) systems.",
      "tldr_zh": "本文提出了一种基于 Fractal Geometry 的规模不变诊断方法，用于分析和解释 Deep Neural Networks (DNNs) 的非线性动态。该方法利用 DNNs 的架构自相似性，量化 fractal dimensions 和 roughness，以提升系统的 intrinsic explainability，并整合 Chaos Theory 原则来改进 fractal evolution 的可视化。同时，通过 Graph-Based Neural Network 重建网络拓扑，这一策略旨在推进 connectionist AI 系统的内在可解释性和整体理解。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09585v1",
      "published_date": "2024-07-12 11:54:05 UTC",
      "updated_date": "2024-07-12 11:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:03:08.279811"
    },
    {
      "arxiv_id": "2407.09197v3",
      "title": "A Chatbot for Asylum-Seeking Migrants in Europe",
      "title_zh": "翻译失败",
      "authors": [
        "Bettina Fazzinga",
        "Elena Palmieri",
        "Margherita Vestoso",
        "Luca Bolognini",
        "Andrea Galassi",
        "Filippo Furfaro",
        "Paolo Torroni"
      ],
      "abstract": "We present ACME: A Chatbot for asylum-seeking Migrants in Europe. ACME relies\non computational argumentation and aims to help migrants identify the highest\nlevel of protection they can apply for. This would contribute to a more\nsustainable migration by reducing the load on territorial commissions, Courts,\nand humanitarian organizations supporting asylum applicants. We describe the\nbackground context, system architecture, underlying technologies, and a case\nstudy used to validate the tool with domain experts.",
      "tldr_zh": "本研究提出了ACME，一种针对欧洲寻求庇护移民的聊天机器人，利用计算论证（computational argumentation）帮助用户识别他们可以申请的最高保护级别，从而减轻领土委员会、法院和人道主义组织的负担。ACME的系统架构基于特定的背景和底层技术，旨在促进更可持续的移民流程。论文通过一个案例研究与领域专家验证了该工具的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Copyright 2024 IEEE",
      "pdf_url": "http://arxiv.org/pdf/2407.09197v3",
      "published_date": "2024-07-12 11:53:40 UTC",
      "updated_date": "2025-01-31 13:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:03:18.193499"
    },
    {
      "arxiv_id": "2407.09191v1",
      "title": "From Easy to Hard: Learning Curricular Shape-aware Features for Robust Panoptic Scene Graph Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hanrong Shi",
        "Lin Li",
        "Jun Xiao",
        "Yueting Zhuang",
        "Long Chen"
      ],
      "abstract": "Panoptic Scene Graph Generation (PSG) aims to generate a comprehensive\ngraph-structure representation based on panoptic segmentation masks. Despite\nremarkable progress in PSG, almost all existing methods neglect the importance\nof shape-aware features, which inherently focus on the contours and boundaries\nof objects. To bridge this gap, we propose a model-agnostic Curricular\nshApe-aware FEature (CAFE) learning strategy for PSG. Specifically, we\nincorporate shape-aware features (i.e., mask features and boundary features)\ninto PSG, moving beyond reliance solely on bbox features. Furthermore, drawing\ninspiration from human cognition, we propose to integrate shape-aware features\nin an easy-to-hard manner. To achieve this, we categorize the predicates into\nthree groups based on cognition learning difficulty and correspondingly divide\nthe training process into three stages. Each stage utilizes a specialized\nrelation classifier to distinguish specific groups of predicates. As the\nlearning difficulty of predicates increases, these classifiers are equipped\nwith features of ascending complexity. We also incorporate knowledge\ndistillation to retain knowledge acquired in earlier stages. Due to its\nmodel-agnostic nature, CAFE can be seamlessly incorporated into any PSG model.\nExtensive experiments and ablations on two PSG tasks under both robust and\nzero-shot PSG have attested to the superiority and robustness of our proposed\nCAFE, which outperforms existing state-of-the-art methods by a large margin.",
      "tldr_zh": "本论文针对 Panoptic Scene Graph Generation (PSG) 的问题，提出了一种模型无关的 Curricular shApe-aware FEature (CAFE) 学习策略，以整合形状感知特征（如 mask features 和 boundary features），克服现有方法仅依赖 bbox features 的局限。CAFE 借鉴人类认知，从易到难的方式分阶段训练，将谓词(predicates) 基于学习难度分组，并使用专用关系分类器逐步增加特征复杂度，同时通过 knowledge distillation 保留早期知识。实验结果显示，CAFE 在两个 PSG 任务的 robust 和 zero-shot 场景下大幅超越现有最先进方法，证明了其优越性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IJCV",
      "pdf_url": "http://arxiv.org/pdf/2407.09191v1",
      "published_date": "2024-07-12 11:48:33 UTC",
      "updated_date": "2024-07-12 11:48:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:03:32.465882"
    },
    {
      "arxiv_id": "2407.09187v1",
      "title": "Enhancing Depressive Post Detection in Bangla: A Comparative Study of TF-IDF, BERT and FastText Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Saad Ahmed Sazan",
        "Mahdi H. Miraz",
        "A B M Muntasir Rahman"
      ],
      "abstract": "Due to massive adoption of social media, detection of users' depression\nthrough social media analytics bears significant importance, particularly for\nunderrepresented languages, such as Bangla. This study introduces a\nwell-grounded approach to identify depressive social media posts in Bangla, by\nemploying advanced natural language processing techniques. The dataset used in\nthis work, annotated by domain experts, includes both depressive and\nnon-depressive posts, ensuring high-quality data for model training and\nevaluation. To address the prevalent issue of class imbalance, we utilised\nrandom oversampling for the minority class, thereby enhancing the model's\nability to accurately detect depressive posts. We explored various numerical\nrepresentation techniques, including Term Frequency-Inverse Document Frequency\n(TF-IDF), Bidirectional Encoder Representations from Transformers (BERT)\nembedding and FastText embedding, by integrating them with a deep\nlearning-based Convolutional Neural Network-Bidirectional Long Short-Term\nMemory (CNN-BiLSTM) model. The results obtained through extensive\nexperimentation, indicate that the BERT approach performed better the others,\nachieving a F1-score of 84%. This indicates that BERT, in combination with the\nCNN-BiLSTM architecture, effectively recognises the nuances of Bangla texts\nrelevant to depressive contents. Comparative analysis with the existing\nstate-of-the-art methods demonstrates that our approach with BERT embedding\nperforms better than others in terms of evaluation metrics and the reliability\nof dataset annotations. Our research significantly contribution to the\ndevelopment of reliable tools for detecting depressive posts in the Bangla\nlanguage. By highlighting the efficacy of different embedding techniques and\ndeep learning models, this study paves the way for improved mental health\nmonitoring through social media platforms.",
      "tldr_zh": "这篇论文探讨了使用 TF-IDF、BERT 和 FastText 嵌入技术来提升孟加拉语社交媒体中抑郁帖子检测的准确性，针对类别不平衡问题采用了随机过采样方法，并将这些嵌入与 CNN-BiLSTM 模型结合进行实验。研究结果显示，BERT 嵌入表现最佳，达到了 84% 的 F1-score，并优于现有方法。总体上，该工作为孟加拉语心理健康监测提供了可靠的工具，促进了社交媒体分析在低资源语言中的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09187v1",
      "published_date": "2024-07-12 11:40:17 UTC",
      "updated_date": "2024-07-12 11:40:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:03:43.877870"
    },
    {
      "arxiv_id": "2407.09186v2",
      "title": "Variational Inference via Smoothed Particle Hydrodynamics",
      "title_zh": "基于平滑粒子流体动力学的变分推断",
      "authors": [
        "Yongchao Huang"
      ],
      "abstract": "A new variational inference method, SPH-ParVI, based on smoothed particle\nhydrodynamics (SPH), is proposed for sampling partially known densities (e.g.\nup to a constant) or sampling using gradients. SPH-ParVI simulates the flow of\na fluid under external effects driven by the target density; transient or\nsteady state of the fluid approximates the target density. The continuum fluid\nis modelled as an interacting particle system (IPS) via SPH, where each\nparticle carries smoothed properties, interacts and evolves as per the\nNavier-Stokes equations. This mesh-free, Lagrangian simulation method offers\nfast, flexible, scalable and deterministic sampling and inference for a class\nof probabilistic models such as those encountered in Bayesian inference and\ngenerative modelling.",
      "tldr_zh": "论文提出了一种新的变分推理方法SPH-ParVI，基于Smoothed Particle Hydrodynamics (SPH)，用于采样部分已知密度（如乘以常数）或使用梯度采样。 该方法通过模拟流体在目标密度驱动下的流动，将连续流体建模为相互作用的粒子系统(Interacting Particle System, IPS)，其中每个粒子携带平滑属性并根据Navier-Stokes equations演化，实现无网格的Lagrangian模拟。 SPH-ParVI的优势在于提供快速、灵活、可扩展和确定性的采样和推理，适用于Bayesian inference和生成建模等概率模型。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09186v2",
      "published_date": "2024-07-12 11:38:41 UTC",
      "updated_date": "2024-07-26 17:26:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:03:56.185705"
    },
    {
      "arxiv_id": "2407.09174v3",
      "title": "DART: An Automated End-to-End Object Detection Pipeline with Data Diversification, Open-Vocabulary Bounding Box Annotation, Pseudo-Label Review, and Model Training",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Xin",
        "Andreas Hartel",
        "Enkelejda Kasneci"
      ],
      "abstract": "Accurate real-time object detection is vital across numerous industrial\napplications, from safety monitoring to quality control. Traditional\napproaches, however, are hindered by arduous manual annotation and data\ncollection, struggling to adapt to ever-changing environments and novel target\nobjects. To address these limitations, this paper presents DART, an innovative\nautomated end-to-end pipeline that revolutionizes object detection workflows\nfrom data collection to model evaluation. It eliminates the need for laborious\nhuman labeling and extensive data collection while achieving outstanding\naccuracy across diverse scenarios. DART encompasses four key stages: (1) Data\nDiversification using subject-driven image generation (DreamBooth with SDXL),\n(2) Annotation via open-vocabulary object detection (Grounding DINO) to\ngenerate bounding box and class labels, (3) Review of generated images and\npseudo-labels by large multimodal models (InternVL-1.5 and GPT-4o) to guarantee\ncredibility, and (4) Training of real-time object detectors (YOLOv8 and\nYOLOv10) using the verified data. We apply DART to a self-collected dataset of\nconstruction machines named Liebherr Product, which contains over 15K\nhigh-quality images across 23 categories. The current instantiation of DART\nsignificantly increases average precision (AP) from 0.064 to 0.832. Its modular\ndesign ensures easy exchangeability and extensibility, allowing for future\nalgorithm upgrades, seamless integration of new object categories, and\nadaptability to customized environments without manual labeling and additional\ndata collection. The code and dataset are released at\nhttps://github.com/chen-xin-94/DART.",
      "tldr_zh": "该论文提出 DART，一种自动化的端到端物体检测管道，旨在解决传统方法的手动标注和数据收集难题，提高在动态环境下的准确性。DART 包括四个关键阶段：Data Diversification 通过 DreamBooth with SDXL 进行图像生成、Open-Vocabulary Bounding Box Annotation 使用 Grounding DINO 生成标签、Pseudo-Label Review 由 InternVL-1.5 和 GPT-4o 审查伪标签，以及 Model Training 使用 YOLOv8 和 YOLOv10 训练检测器。实验在自收集的 Liebherr Product 数据集（超过 15K 图像，23 类别）上，将平均精度 (AP) 从 0.064 提升至 0.832，并支持模块化设计以便扩展和适应新类别。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09174v3",
      "published_date": "2024-07-12 11:16:44 UTC",
      "updated_date": "2024-07-29 09:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:04:19.656133"
    },
    {
      "arxiv_id": "2407.09172v1",
      "title": "Machine Apophenia: The Kaleidoscopic Generation of Architectural Images",
      "title_zh": "翻译失败",
      "authors": [
        "Alexey Tikhonov",
        "Dmitry Sinyavin"
      ],
      "abstract": "This study investigates the application of generative artificial intelligence\nin architectural design. We present a novel methodology that combines multiple\nneural networks to create an unsupervised and unmoderated stream of unique\narchitectural images. Our approach is grounded in the conceptual framework\ncalled machine apophenia. We hypothesize that neural networks, trained on\ndiverse human-generated data, internalize aesthetic preferences and tend to\nproduce coherent designs even from random inputs. The methodology involves an\niterative process of image generation, description, and refinement, resulting\nin captioned architectural postcards automatically shared on several social\nmedia platforms. Evaluation and ablation studies show the improvement both in\ntechnical and aesthetic metrics of resulting images on each step.",
      "tldr_zh": "本研究探讨了生成式人工智能在建筑设计中的应用，提出了一种基于 machine apophenia 概念框架的新方法，通过结合多个神经网络实现无监督的独特建筑图像生成。方法假设神经网络从多样人类生成数据中内化美学偏好，即使从随机输入也能产生连贯的设计，并采用图像生成、描述和精炼的迭代过程，最终输出带有标题的建筑明信片并自动共享到社交媒体平台。评估和消融研究表明，该方法在每个步骤都显著改善了图像的技术和美学指标。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "68T01, 68U05, 00A66, 00A67",
        "I.2.1; I.3.3; J.5; H.5.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09172v1",
      "published_date": "2024-07-12 11:11:19 UTC",
      "updated_date": "2024-07-12 11:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:04:19.076038"
    },
    {
      "arxiv_id": "2407.09167v3",
      "title": "SE(3)-bi-equivariant Transformers for Point Cloud Assembly",
      "title_zh": "翻译失败",
      "authors": [
        "Ziming Wang",
        "Rebecka Jörnsten"
      ],
      "abstract": "Given a pair of point clouds, the goal of assembly is to recover a rigid\ntransformation that aligns one point cloud to the other. This task is\nchallenging because the point clouds may be non-overlapped, and they may have\narbitrary initial positions. To address these difficulties, we propose a\nmethod, called SE(3)-bi-equivariant transformer (BITR), based on the\nSE(3)-bi-equivariance prior of the task: it guarantees that when the inputs are\nrigidly perturbed, the output will transform accordingly. Due to its\nequivariance property, BITR can not only handle non-overlapped PCs, but also\nguarantee robustness against initial positions. Specifically, BITR first\nextracts features of the inputs using a novel $SE(3) \\times SE(3)$-transformer,\nand then projects the learned feature to group SE(3) as the output. Moreover,\nwe theoretically show that swap and scale equivariances can be incorporated\ninto BITR, thus it further guarantees stable performance under scaling and\nswapping the inputs. We experimentally show the effectiveness of BITR in\npractical tasks.",
      "tldr_zh": "这篇论文针对点云装配任务，提出了一种名为 BITR 的 SE(3)-bi-equivariant Transformer 方法，用于恢复一对可能非重叠点云之间的刚性变换。BITR 基于 SE(3)-bi-equivariance 先验，确保当输入点云发生刚性扰动时，输出相应变换，从而提高对初始位置的鲁棒性。方法包括使用新型 $SE(3) \\times SE(3)$-transformer 提取特征，并将特征投影到 SE(3) 组作为输出。理论上，BITR 还整合了 swap 和 scale equivariances，提升了在缩放和交换输入时的性能。实验结果证明，BITR 在实际点云装配任务中表现出色。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Camera ready for NeurIPS24",
      "pdf_url": "http://arxiv.org/pdf/2407.09167v3",
      "published_date": "2024-07-12 11:01:28 UTC",
      "updated_date": "2024-10-25 19:05:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:04:31.675882"
    },
    {
      "arxiv_id": "2407.09165v1",
      "title": "Robust Yet Efficient Conformal Prediction Sets",
      "title_zh": "翻译失败",
      "authors": [
        "Soroush H. Zargarbashi",
        "Mohammad Sadegh Akhondzadeh",
        "Aleksandar Bojchevski"
      ],
      "abstract": "Conformal prediction (CP) can convert any model's output into prediction sets\nguaranteed to include the true label with any user-specified probability.\nHowever, same as the model itself, CP is vulnerable to adversarial test\nexamples (evasion) and perturbed calibration data (poisoning). We derive\nprovably robust sets by bounding the worst-case change in conformity scores.\nOur tighter bounds lead to more efficient sets. We cover both continuous and\ndiscrete (sparse) data and our guarantees work both for evasion and poisoning\nattacks (on both features and labels).",
      "tldr_zh": "这篇论文提出了一个鲁棒且高效的 Conformal Prediction (CP) 预测集方法，通过边界最坏情况的符合分数(conformity scores)变化来确保预测集在面对攻击时保持可靠性。相比传统 CP，该方法显著提高了效率，并适用于连续和离散（稀疏）数据。研究证明，该方法对 evasion 和 poisoning 攻击（针对特征和标签）均提供强有力的保证，从而增强了模型的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the 41st International Conference on Machine Learning",
      "pdf_url": "http://arxiv.org/pdf/2407.09165v1",
      "published_date": "2024-07-12 10:59:44 UTC",
      "updated_date": "2024-07-12 10:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:04:43.947742"
    },
    {
      "arxiv_id": "2407.09164v5",
      "title": "TPIA: Towards Target-specific Prompt Injection Attack against Code-oriented Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Yang",
        "Hongwei Yao",
        "Bingrun Yang",
        "Yiling He",
        "Yiming Li",
        "Tianwei Zhang",
        "Zhan Qin"
      ],
      "abstract": "Recently, code-oriented large language models (Code LLMs) have been widely\nand successfully exploited to simplify and facilitate programming.\nUnfortunately, a few pioneering works revealed that these Code LLMs are\nvulnerable to backdoor and adversarial attacks. The former poisons the training\ndata or model parameters, hijacking the LLMs to generate malicious code\nsnippets when encountering the trigger. The latter crafts malicious adversarial\ninput codes to reduce the quality of the generated codes. In this paper, we\nreveal that both attacks have some inherent limitations: backdoor attacks rely\non the adversary's capability of controlling the model training process, which\nmay not be practical; adversarial attacks struggle with fulfilling specific\nmalicious purposes. To alleviate these problems, this paper presents a novel\nattack paradigm against Code LLMs, namely target-specific prompt injection\nattack (TPIA). TPIA generates non-functional perturbations containing the\ninformation of malicious instructions and inserts them into the victim's code\ncontext by spreading them into potentially used dependencies (e.g., packages or\nRAG's knowledge base). It induces the Code LLMs to generate attacker-specified\nmalicious code snippets at the target location. In general, we compress the\nattacker-specified malicious objective into the perturbation by adversarial\noptimization based on greedy token search. We collect 13 representative\nmalicious objectives to design 31 threat cases for three popular programming\nlanguages. We show that our TPIA can successfully attack three representative\nopen-source Code LLMs (with an attack success rate of up to 97.9%) and two\nmainstream commercial Code LLM-integrated applications (with an attack success\nrate of over 90%) in all threat cases, using only a 12-token non-functional\nperturbation.",
      "tldr_zh": "本文提出了一种针对代码导向大语言模型（Code LLMs）的目标特定提示注入攻击（TPIA），旨在克服传统 backdoor attacks 和 adversarial attacks 的局限性，如依赖模型训练控制或难以实现特定恶意目的。TPIA 通过生成非功能性扰动（包含恶意指令信息）并将其插入受害者代码上下文中（如依赖包或 RAG 的知识库），利用对抗优化和贪婪令牌搜索来压缩并触发攻击者指定的恶意代码生成。实验结果显示，在 31 个威胁案例中，TPIA 对三个开源 Code LLMs 的攻击成功率高达 97.9%，对两个商业应用超过 90%，仅需 12 个令牌的扰动。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09164v5",
      "published_date": "2024-07-12 10:59:32 UTC",
      "updated_date": "2025-03-04 04:43:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:04:56.988060"
    },
    {
      "arxiv_id": "2407.09162v2",
      "title": "Exploring State Space and Reasoning by Elimination in Tsetlin Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed K. Kadhim",
        "Ole-Christoffer Granmo",
        "Lei Jiao",
        "Rishad Shafik"
      ],
      "abstract": "The Tsetlin Machine (TM) has gained significant attention in Machine Learning\n(ML). By employing logical fundamentals, it facilitates pattern learning and\nrepresentation, offering an alternative approach for developing comprehensible\nArtificial Intelligence (AI) with a specific focus on pattern classification in\nthe form of conjunctive clauses. In the domain of Natural Language Processing\n(NLP), TM is utilised to construct word embedding and describe target words\nusing clauses. To enhance the descriptive capacity of these clauses, we study\nthe concept of Reasoning by Elimination (RbE) in clauses' formulation, which\ninvolves incorporating feature negations to provide a more comprehensive\nrepresentation. In more detail, this paper employs the Tsetlin Machine\nAuto-Encoder (TM-AE) architecture to generate dense word vectors, aiming at\ncapturing contextual information by extracting feature-dense vectors for a\ngiven vocabulary. Thereafter, the principle of RbE is explored to improve\ndescriptivity and optimise the performance of the TM. Specifically, the\nspecificity parameter s and the voting margin parameter T are leveraged to\nregulate feature distribution in the state space, resulting in a dense\nrepresentation of information for each clause. In addition, we investigate the\nstate spaces of TM-AE, especially for the forgotten/excluded features.\nEmpirical investigations on artificially generated data, the IMDB dataset, and\nthe 20 Newsgroups dataset showcase the robustness of the TM, with accuracy\nreaching 90.62\\% for the IMDB.",
      "tldr_zh": "本论文探讨了 Tsetlin Machine (TM) 中的状态空间和 Reasoning by Elimination (RbE) 概念，以提升其在自然语言处理 (NLP) 中的模式学习和表示能力。研究采用 Tsetlin Machine Auto-Encoder (TM-AE) 生成密集词向量，通过加入特征否定和调节参数 s 与 T 来优化子句的描述性和性能。实验结果显示，在 IMDB 和 20 Newsgroups 数据集上，TM 的准确率达到 90.62%，证明了其鲁棒性并为可解释 AI 提供了新方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.09162v2",
      "published_date": "2024-07-12 10:58:01 UTC",
      "updated_date": "2024-07-17 09:42:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:05:10.657956"
    },
    {
      "arxiv_id": "2407.09157v1",
      "title": "Movie Recommendation with Poster Attention via Multi-modal Transformer Feature Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Linhan Xia",
        "Yicheng Yang",
        "Ziou Chen",
        "Zheng Yang",
        "Shengxin Zhu"
      ],
      "abstract": "Pre-trained models learn general representations from large datsets which can\nbe fine-turned for specific tasks to significantly reduce training time.\nPre-trained models like generative pretrained transformers (GPT), bidirectional\nencoder representations from transformers (BERT), vision transfomers (ViT) have\nbecome a cornerstone of current research in machine learning. This study\nproposes a multi-modal movie recommendation system by extract features of the\nwell designed posters for each movie and the narrative text description of the\nmovie. This system uses the BERT model to extract the information of text\nmodality, the ViT model applied to extract the information of poster/image\nmodality, and the Transformer architecture for feature fusion of all modalities\nto predict users' preference. The integration of pre-trained foundational\nmodels with some smaller data sets in downstream applications capture\nmulti-modal content features in a more comprehensive manner, thereby providing\nmore accurate recommendations. The efficiency of the proof-of-concept model is\nverified by the standard benchmark problem the MovieLens 100K and 1M datasets.\nThe prediction accuracy of user ratings is enhanced in comparison to the\nbaseline algorithm, thereby demonstrating the potential of this cross-modal\nalgorithm to be applied for movie or video recommendation.",
      "tldr_zh": "本研究提出了一种多模态电影推荐系统，通过整合海报图像和文本描述来提升推荐准确性。系统利用 BERT 模型提取文本模态信息，ViT 模型提取海报/图像模态信息，并采用 Transformer 架构进行特征融合，以预测用户偏好。该方法基于预训练模型在小数据集上的应用，能够更全面地捕捉多模态内容特征。在 MovieLens 100K 和 1M 数据集上的实验验证显示，该系统比基线算法显著提高了用户评分预测准确率，展示了跨模态算法在电影推荐领域的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09157v1",
      "published_date": "2024-07-12 10:44:51 UTC",
      "updated_date": "2024-07-12 10:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:05:19.238961"
    },
    {
      "arxiv_id": "2407.09152v1",
      "title": "The Two Sides of the Coin: Hallucination Generation and Detection with LLMs as Evaluators for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Anh Thu Maria Bui",
        "Saskia Felizitas Brech",
        "Natalie Hußfeldt",
        "Tobias Jennert",
        "Melanie Ullrich",
        "Timo Breuer",
        "Narjes Nikzad Khasmakhi",
        "Philipp Schaer"
      ],
      "abstract": "Hallucination detection in Large Language Models (LLMs) is crucial for\nensuring their reliability. This work presents our participation in the CLEF\nELOQUENT HalluciGen shared task, where the goal is to develop evaluators for\nboth generating and detecting hallucinated content. We explored the\ncapabilities of four LLMs: Llama 3, Gemma, GPT-3.5 Turbo, and GPT-4, for this\npurpose. We also employed ensemble majority voting to incorporate all four\nmodels for the detection task. The results provide valuable insights into the\nstrengths and weaknesses of these LLMs in handling hallucination generation and\ndetection tasks.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs)中hallucination检测的重要性，并参与CLEF ELOQUENT HalluciGen共享任务，开发用于生成和检测幻觉内容的评估器。研究团队评估了Llama 3、Gemma、GPT-3.5 Turbo和GPT-4四个模型，并采用ensemble majority voting方法将它们整合到检测任务中。结果揭示了这些LLMs在处理hallucination生成和检测任务时的优势和劣势，为提升LLMs的可靠性和可靠性提供了宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Paper accepted at ELOQUENT@CLEF'24",
      "pdf_url": "http://arxiv.org/pdf/2407.09152v1",
      "published_date": "2024-07-12 10:34:46 UTC",
      "updated_date": "2024-07-12 10:34:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:05:32.951740"
    },
    {
      "arxiv_id": "2407.09136v1",
      "title": "Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors",
      "title_zh": "翻译失败",
      "authors": [
        "Nico Daheim",
        "Jakub Macina",
        "Manu Kapur",
        "Iryna Gurevych",
        "Mrinmaya Sachan"
      ],
      "abstract": "Large language models (LLMs) present an opportunity to scale high-quality\npersonalized education to all. A promising approach towards this means is to\nbuild dialog tutoring models that scaffold students' problem-solving. However,\neven though existing LLMs perform well in solving reasoning questions, they\nstruggle to precisely detect student's errors and tailor their feedback to\nthese errors. Inspired by real-world teaching practice where teachers identify\nstudent errors and customize their response based on them, we focus on\nverifying student solutions and show how grounding to such verification\nimproves the overall quality of tutor response generation. We collect a dataset\nof 1K stepwise math reasoning chains with the first error step annotated by\nteachers. We show empirically that finding the mistake in a student solution is\nchallenging for current models. We propose and evaluate several verifiers for\ndetecting these errors. Using both automatic and human evaluation we show that\nthe student solution verifiers steer the generation model towards highly\ntargeted responses to student errors which are more often correct with less\nhallucinations compared to existing baselines.",
      "tldr_zh": "该研究探讨了使用大型语言模型(LLMs)作为辅导工具来逐步验证和修正学生推理错误的问题，旨在提升个性化教育质量。研究者收集了1K个逐步数学推理链的数据集，由教师标注了第一个错误步骤，并发现当前LLMs在检测这些错误方面存在挑战。作者提出并评估了几种验证器(verifiers)，结果显示这些验证器能引导生成模型产生更针对性的反馈，这些反馈更准确、幻觉(hallucinations)更少，从而改善整体辅导效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. Nico Daheim and Jakub Macina contributed equally. Code and\n  dataset can be found under: https://github.com/eth-lre/verify-then-generate",
      "pdf_url": "http://arxiv.org/pdf/2407.09136v1",
      "published_date": "2024-07-12 10:11:40 UTC",
      "updated_date": "2024-07-12 10:11:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:05:44.304900"
    },
    {
      "arxiv_id": "2407.09121v1",
      "title": "Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training",
      "title_zh": "翻译失败",
      "authors": [
        "Youliang Yuan",
        "Wenxiang Jiao",
        "Wenxuan Wang",
        "Jen-tse Huang",
        "Jiahao Xu",
        "Tian Liang",
        "Pinjia He",
        "Zhaopeng Tu"
      ],
      "abstract": "This study addresses a critical gap in safety tuning practices for Large\nLanguage Models (LLMs) by identifying and tackling a refusal position bias\nwithin safety tuning data, which compromises the models' ability to\nappropriately refuse generating unsafe content. We introduce a novel approach,\nDecoupled Refusal Training (DeRTa), designed to empower LLMs to refuse\ncompliance to harmful prompts at any response position, significantly enhancing\ntheir safety capabilities. DeRTa incorporates two novel components: (1) Maximum\nLikelihood Estimation (MLE) with Harmful Response Prefix, which trains models\nto recognize and avoid unsafe content by appending a segment of harmful\nresponse to the beginning of a safe response, and (2) Reinforced Transition\nOptimization (RTO), which equips models with the ability to transition from\npotential harm to safety refusal consistently throughout the harmful response\nsequence. Our empirical evaluation, conducted using LLaMA3 and Mistral model\nfamilies across six attack scenarios, demonstrates that our method not only\nimproves model safety without compromising performance but also surpasses\nwell-known models such as GPT-4 in defending against attacks. Importantly, our\napproach successfully defends recent advanced attack methods (e.g., CodeAttack)\nthat have jailbroken GPT-4 and LLaMA3-70B-Instruct. Our code and data can be\nfound at https://github.com/RobustNLP/DeRTa.",
      "tldr_zh": "这篇论文针对 Large Language Models (LLMs) 的安全调优问题，提出了 Decoupled Refusal Training (DeRTa) 方法，以解决拒绝位置偏差，从而使模型能够在任何响应位置适当地拒绝生成有害内容。DeRTa 包括两个关键组件：Maximum Likelihood Estimation (MLE) with Harmful Response Prefix，用于通过在安全响应开头附加有害片段来训练模型识别和避免不安全内容；以及 Reinforced Transition Optimization (RTO)，帮助模型在有害序列中一致地转向安全拒绝。实验结果显示，在 LLaMA3 和 Mistral 模型家族上，该方法在六种攻击场景下显著提升了模型安全性，超过了 GPT-4 的防御性能，并成功抵御了高级攻击如 CodeAttack。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09121v1",
      "published_date": "2024-07-12 09:36:33 UTC",
      "updated_date": "2024-07-12 09:36:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:05:57.438026"
    },
    {
      "arxiv_id": "2407.09111v2",
      "title": "Inference Optimization of Foundation Models on AI Accelerators",
      "title_zh": "基础模型在 AI 加速器上的推理优化",
      "authors": [
        "Youngsuk Park",
        "Kailash Budhathoki",
        "Liangfu Chen",
        "Jonas Kübler",
        "Jiaji Huang",
        "Matthäus Kleindessner",
        "Jun Huan",
        "Volkan Cevher",
        "Yida Wang",
        "George Karypis"
      ],
      "abstract": "Powerful foundation models, including large language models (LLMs), with\nTransformer architectures have ushered in a new era of Generative AI across\nvarious industries. Industry and research community have witnessed a large\nnumber of new applications, based on those foundation models. Such applications\ninclude question and answer, customer services, image and video generation, and\ncode completions, among others. However, as the number of model parameters\nreaches to hundreds of billions, their deployment incurs prohibitive inference\ncosts and high latency in real-world scenarios. As a result, the demand for\ncost-effective and fast inference using AI accelerators is ever more higher. To\nthis end, our tutorial offers a comprehensive discussion on complementary\ninference optimization techniques using AI accelerators. Beginning with an\noverview of basic Transformer architectures and deep learning system\nframeworks, we deep dive into system optimization techniques for fast and\nmemory-efficient attention computations and discuss how they can be implemented\nefficiently on AI accelerators. Next, we describe architectural elements that\nare key for fast transformer inference. Finally, we examine various model\ncompression and fast decoding strategies in the same context.",
      "tldr_zh": "本教程探讨了在AI Accelerators上优化Foundation Models（如Transformer架构的LLMs）推理的综合技术，以应对模型参数庞大导致的高成本和高延迟问题。内容从Transformer基本架构和深度学习框架概述入手，深入分析系统优化技巧，如高效的注意力计算实现，以及AI Accelerators的关键架构元素。最终，论文考察了模型压缩和快速解码策略，这些方法共同提升了推理效率，为Generative AI应用提供了更具成本效益的部署方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "[v2] Tutorial website added [v1] Tutorial published at KDD 2024.\n  Camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2407.09111v2",
      "published_date": "2024-07-12 09:24:34 UTC",
      "updated_date": "2024-10-01 17:10:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:06:07.673687"
    },
    {
      "arxiv_id": "2407.09105v6",
      "title": "Enhancing Training Efficiency Using Packing with Flash Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Achintya Kundu",
        "Rhui Dih Lee",
        "Laura Wynter",
        "Raghu Kiran Ganti",
        "Mayank Mishra"
      ],
      "abstract": "Padding is often used in tuning LLM models by adding special tokens to\nshorter training examples to match the length of the longest sequence in each\nbatch. While this ensures uniformity for batch processing, it introduces\ninefficiencies by including irrelevant padding tokens in the computation and\nwastes GPU resources. Hugging Face SFT trainer has always offered the option to\nuse packing to combine multiple training examples, allowing for maximal\nutilization of GPU resources. However, up till now, it did not offer proper\nmasking of each packed training example. This capability has been added to\nHugging Face Transformers 4.44. We analyse this new feature and show the\nbenefits across different variations of packing.",
      "tldr_zh": "这篇论文探讨了在训练大型语言模型（LLM）时，使用填充（padding）来匹配批次中最长序列所带来的效率问题，导致计算浪费和GPU资源利用低下。作者提出通过packing技术结合Flash Attention，将多个训练示例合并以最大化资源利用，并引入Hugging Face Transformers 4.44的新功能——proper masking——来正确屏蔽每个packed示例。实验结果显示，这种方法在不同packing变体中显著提升了训练效率，减少了不必要的计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09105v6",
      "published_date": "2024-07-12 09:10:37 UTC",
      "updated_date": "2024-09-01 00:26:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:06:20.489779"
    },
    {
      "arxiv_id": "2407.09103v1",
      "title": "DANIEL: A fast Document Attention Network for Information Extraction and Labelling of handwritten documents",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Constum",
        "Pierrick Tranouez",
        "Thierry Paquet"
      ],
      "abstract": "Information extraction from handwritten documents involves traditionally\nthree distinct steps: Document Layout Analysis, Handwritten Text Recognition,\nand Named Entity Recognition. Recent approaches have attempted to integrate\nthese steps into a single process using fully end-to-end architectures. Despite\nthis, these integrated approaches have not yet matched the performance of\nlanguage models, when applied to information extraction in plain text. In this\npaper, we introduce DANIEL (Document Attention Network for Information\nExtraction and Labelling), a fully end-to-end architecture integrating a\nlanguage model and designed for comprehensive handwritten document\nunderstanding. DANIEL performs layout recognition, handwriting recognition, and\nnamed entity recognition on full-page documents. Moreover, it can\nsimultaneously learn across multiple languages, layouts, and tasks. For named\nentity recognition, the ontology to be applied can be specified via the input\nprompt. The architecture employs a convolutional encoder capable of processing\nimages of any size without resizing, paired with an autoregressive decoder\nbased on a transformer-based language model. DANIEL achieves competitive\nresults on four datasets, including a new state-of-the-art performance on RIMES\n2009 and M-POPP for Handwriting Text Recognition, and IAM NER for Named Entity\nRecognition. Furthermore, DANIEL is much faster than existing approaches.\n  We provide the source code and the weights of the trained models at\n\\url{https://github.com/Shulk97/daniel}.",
      "tldr_zh": "本论文提出 DANIEL，一种快速的 Document Attention Network，用于手写文档的信息提取和标记，将文档布局分析、手写文本识别 (HTR) 和命名实体识别 (NER) 整合成一个完全端到端的架构。DANIEL 采用卷积编码器处理任意大小的图像，以及基于 transformer 的自回归解码器，支持多语言、多布局和多任务学习，并通过输入提示指定 NER 的 ontology。相比传统方法，该架构显著提高了性能，在 RIMES 2009、M-POPP 和 IAM NER 等数据集上实现了新的 state-of-the-art 结果，同时处理速度更快。作者提供了源代码和训练模型权重，以促进进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09103v1",
      "published_date": "2024-07-12 09:09:56 UTC",
      "updated_date": "2024-07-12 09:09:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:06:44.410876"
    },
    {
      "arxiv_id": "2407.09099v2",
      "title": "Music Proofreading with RefinPaint: Where and How to Modify Compositions given Context",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Ramoneda",
        "Martin Rocamora",
        "Taketo Akama"
      ],
      "abstract": "Autoregressive generative transformers are key in music generation, producing\ncoherent compositions but facing challenges in human-machine collaboration. We\npropose RefinPaint, an iterative technique that improves the sampling process.\nIt does this by identifying the weaker music elements using a feedback model,\nwhich then informs the choices for resampling by an inpainting model. This\ndual-focus methodology not only facilitates the machine's ability to improve\nits automatic inpainting generation through repeated cycles but also offers a\nvaluable tool for humans seeking to refine their compositions with automatic\nproofreading. Experimental results suggest RefinPaint's effectiveness in\ninpainting and proofreading tasks, demonstrating its value for refining music\ncreated by both machines and humans. This approach not only facilitates\ncreativity but also aids amateur composers in improving their work.",
      "tldr_zh": "这篇论文提出 RefinPaint，一种迭代技术，用于改进 autoregressive generative transformers 在音乐生成中的人类-机器协作挑战。它通过反馈模型识别较弱的音乐元素，并使用 inpainting 模型进行针对性重新采样，实现自动校对和精炼。实验结果表明，RefinPaint 在 inpainting 和校对任务中表现出色，不仅提升了机器生成音乐的质量，还为人类作曲家提供工具，促进创意和作品改进。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09099v2",
      "published_date": "2024-07-12 08:52:27 UTC",
      "updated_date": "2024-11-10 18:07:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:06:56.135983"
    },
    {
      "arxiv_id": "2407.09096v3",
      "title": "STD-PLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with PLM",
      "title_zh": "翻译失败",
      "authors": [
        "YiHeng Huang",
        "Xiaowei Mao",
        "Shengnan Guo",
        "Yubin Chen",
        "Junfeng Shen",
        "Tiankuo Li",
        "Youfang Lin",
        "Huaiyu Wan"
      ],
      "abstract": "Spatial-temporal forecasting and imputation are important for real-world\nintelligent systems. Most existing methods are tailored for individual\nforecasting or imputation tasks but are not designed for both. Additionally,\nthey are less effective for zero-shot and few-shot learning. While pre-trained\nlanguage model (PLM) have exhibited strong pattern recognition and reasoning\nabilities across various tasks, including few-shot and zero-shot learning,\ntheir applications in spatial-temporal data understanding has been constrained\nby insufficient modeling of complex correlations such as the temporal\ncorrelations, spatial connectivity, non-pairwise and high-order\nspatial-temporal correlations within data. In this paper, we propose STD-PLM\nfor understanding both spatial and temporal properties of\n\\underline{S}patial-\\underline{T}emporal \\underline{D}ata with \\underline{PLM},\nwhich is capable of implementing both spatial-temporal forecasting and\nimputation tasks. STD-PLM understands spatial-temporal correlations via\nexplicitly designed spatial and temporal tokenizers. Topology-aware node\nembeddings are designed for PLM to comprehend and exploit the topology\nstructure of data in inductive manner. Furthermore, to mitigate the efficiency\nissues introduced by the PLM, we design a sandglass attention module (SGA)\ncombined with a specific constrained loss function, which significantly\nimproves the model's efficiency while ensuring performance. Extensive\nexperiments demonstrate that STD-PLM exhibits competitive performance and\ngeneralization capabilities across the forecasting and imputation tasks on\nvarious datasets. Moreover, STD-PLM achieves promising results on both few-shot\nand zero-shot tasks.The code is made available at\n\\href{https://anonymous.4open.science/r/STD-PLM-F3BA}{https://anonymous.4open.science/r/STD-PLM-F3BA}",
      "tldr_zh": "本论文提出 STD-PLM，一种基于预训练语言模型(PLM)理解空间-时间数据(Spatial-Temporal Data)中空间和时间属性的框架，能够同时处理空间-时间预测(forecasting)和插值(imputation)任务，并提升 zero-shot 和 few-shot 学习效果。\nSTD-PLM 通过显式设计的空间和时间分词器(spatial and temporal tokenizers)以及拓扑感知节点嵌入(Topology-aware node embeddings)来捕捉复杂相关性，如时间相关性、空间连通性和高阶空间-时间相关性。\n此外，该框架引入沙漏注意力模块(Sandglass Attention Module, SGA)和约束损失函数，提高了模型效率；实验在多种数据集上证明了 STD-PLM 的竞争性能和泛化能力，尤其在少样本和零样本任务中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09096v3",
      "published_date": "2024-07-12 08:48:16 UTC",
      "updated_date": "2024-09-10 05:10:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:07:12.748796"
    },
    {
      "arxiv_id": "2407.09093v2",
      "title": "On Exact Bit-level Reversible Transformers Without Changing Architectures",
      "title_zh": "不改变架构的精确比特级可逆Transformer",
      "authors": [
        "Guoqiang Zhang",
        "J. P. Lewis",
        "W. B. Kleijn"
      ],
      "abstract": "Various reversible deep neural networks (DNN) models have been proposed to\nreduce memory consumption in the training process. However, almost all existing\nreversible DNNs either require special non-standard architectures or are\nconstructed by modifying existing DNN architectures considerably to enable\nreversibility. In this work we present the BDIA-transformer, which is an exact\nbit-level reversible transformer that uses an unchanged standard architecture\nfor inference. The basic idea is to first treat each transformer block as the\nEuler integration approximation for solving an ordinary differential equation\n(ODE) and then incorporate the technique of bidirectional integration\napproximation (BDIA) into the neural architecture, together with activation\nquantization to make it exactly bit-level reversible. In the training process,\nwe let a hyper-parameter $\\gamma$ in BDIA-transformer randomly take one of the\ntwo values $\\{0.5, -0.5\\}$ per training sample per transformer block for\naveraging every two consecutive integration approximations. As a result,\nBDIA-transformer can be viewed as training an ensemble of ODE solvers\nparameterized by a set of binary random variables, which regularizes the model\nand results in improved validation accuracy. Lightweight side information per\ntransformer block is required to be stored in the forward process to account\nfor binary quantization loss to enable exact bit-level reversibility. In the\ninference procedure, the expectation $\\mathbb{E}(\\gamma)=0$ is taken to make\nthe resulting architectures of BDIA-transformer identical to transformers up to\nactivation quantization. Our experiments in both image classification and\nlanguage translation show that BDIA-transformers outperform their conventional\ncounterparts significantly in terms of validation performance while also\nrequiring considerably less training memory.",
      "tldr_zh": "本研究提出了一种名为BDIA-transformer的精确比特级可逆Transformer模型，能够在不改变标准架构的情况下减少训练内存消耗。核心方法是将Transformer块视为求解ODE的Euler积分近似，并结合BDIA技术与激活量化，实现精确比特级可逆性；在训练过程中，通过随机设置超参数γ来模拟ODE求解器的集合，从而提升模型泛化性。实验结果显示，BDIA-transformer在图像分类和语言翻译任务上显著优于传统Transformer模型，提高了验证性能，同时大幅降低了训练内存需求。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09093v2",
      "published_date": "2024-07-12 08:42:58 UTC",
      "updated_date": "2024-10-05 11:17:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:07:20.481043"
    },
    {
      "arxiv_id": "2407.09088v1",
      "title": "FD-SOS: Vision-Language Open-Set Detectors for Bone Fenestration and Dehiscence Detection from Intraoral Images",
      "title_zh": "翻译失败",
      "authors": [
        "Marawan Elbatel",
        "Keyuan Liu",
        "Yanqi Yang",
        "Xiaomeng Li"
      ],
      "abstract": "Accurate detection of bone fenestration and dehiscence (FD) is crucial for\neffective treatment planning in dentistry. While cone-beam computed tomography\n(CBCT) is the gold standard for evaluating FD, it comes with limitations such\nas radiation exposure, limited accessibility, and higher cost compared to\nintraoral images. In intraoral images, dentists face challenges in the\ndifferential diagnosis of FD. This paper presents a novel and clinically\nsignificant application of FD detection solely from intraoral images. To\nachieve this, we propose FD-SOS, a novel open-set object detector for FD\ndetection from intraoral images. FD-SOS has two novel components: conditional\ncontrastive denoising (CCDN) and teeth-specific matching assignment (TMA).\nThese modules enable FD-SOS to effectively leverage external dental semantics.\nExperimental results showed that our method outperformed existing detection\nmethods and surpassed dental professionals by 35% recall under the same level\nof precision. Code is available at: https://github.com/xmed-lab/FD-SOS.",
      "tldr_zh": "本研究针对牙科治疗规划中骨窗和骨暴露（FD）的准确检测问题，提出从intraoral images（口腔内图像）中进行检测的新方法，以克服CBCT的金标准方法的辐射暴露、访问限制和成本高等缺点。FD-SOS是一种新型的vision-language open-set object detector，包含conditional contrastive denoising (CCDN)和teeth-specific matching assignment (TMA)两个关键组件，这些模块通过利用外部牙科语义来提升检测性能。实验结果显示，FD-SOS在相同精确度下比现有检测方法和牙科专业人员提高了35%的召回率，为临床FD检测提供了更高效的工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.09088v1",
      "published_date": "2024-07-12 08:29:25 UTC",
      "updated_date": "2024-07-12 08:29:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:07:32.697058"
    },
    {
      "arxiv_id": "2407.09052v1",
      "title": "From MIDI to Rich Tablatures: an Automatic Generative System incorporating Lead Guitarists' Fingering and Stylistic choices",
      "title_zh": "翻译失败",
      "authors": [
        "Pierluigi Bontempi",
        "Daniele Manerba",
        "Alexandre D'Hooge",
        "Sergio Canazza"
      ],
      "abstract": "Although the automatic identification of the optimal fingering for the\nperformance of melodies on fretted string instruments has already been\naddressed (at least partially) in the literature, the specific case regarding\nlead electric guitar requires a dedicated approach. We propose a system that\ncan generate, from simple MIDI melodies, tablatures enriched by fingerings,\narticulations, and expressive techniques. The basic fingering is derived by\nsolving a constrained and multi-attribute optimization problem, which derives\nthe best position of the fretting hand, not just the finger used at each\nmoment.Then, by analyzing statistical data from the mySongBook corpus, the most\ncommon clich{\\'e}s and biomechanical feasibility, articulations, and expressive\ntechniques are introduced. Finally, the obtained output is converted into\nMusicXML format, which allows for easy visualization and use. The quality of\nthe tablatures derived and the high configurability of the proposed approach\ncan have several impacts, in particular in the fields of instrumental teaching,\nassisted composition and arranging, and computational expressive music\nperformance models.",
      "tldr_zh": "本研究提出一个自动生成系统，能从简单的 MIDI 旋律创建丰富的吉他 tablatures，包括指法(fingering)、表情(articulations)和表现技巧。系统通过解决一个受约束的多属性优化问题来确定 fret 手的最佳位置，并结合 mySongBook 语料库的统计数据、常见套路和生物力学可行性来添加风格元素。最终，输出转换为 MusicXML 格式，便于可视化和使用，该系统的高质量和可配置性可应用于乐器教学、辅助作曲和计算表达音乐表演等领域。",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09052v1",
      "published_date": "2024-07-12 07:18:24 UTC",
      "updated_date": "2024-07-12 07:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:07:47.345625"
    },
    {
      "arxiv_id": "2407.09050v2",
      "title": "Refusing Safe Prompts for Multi-modal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zedian Shao",
        "Hongbin Liu",
        "Yuepeng Hu",
        "Neil Zhenqiang Gong"
      ],
      "abstract": "Multimodal large language models (MLLMs) have become the cornerstone of\ntoday's generative AI ecosystem, sparking intense competition among tech giants\nand startups. In particular, an MLLM generates a text response given a prompt\nconsisting of an image and a question. While state-of-the-art MLLMs use safety\nfilters and alignment techniques to refuse unsafe prompts, in this work, we\nintroduce MLLM-Refusal, the first method that induces refusals for safe\nprompts. In particular, our MLLM-Refusal optimizes a nearly-imperceptible\nrefusal perturbation and adds it to an image, causing target MLLMs to likely\nrefuse a safe prompt containing the perturbed image and a safe question.\nSpecifically, we formulate MLLM-Refusal as a constrained optimization problem\nand propose an algorithm to solve it. Our method offers competitive advantages\nfor MLLM model providers by potentially disrupting user experiences of\ncompeting MLLMs, since competing MLLM's users will receive unexpected refusals\nwhen they unwittingly use these perturbed images in their prompts. We evaluate\nMLLM-Refusal on four MLLMs across four datasets, demonstrating its\neffectiveness in causing competing MLLMs to refuse safe prompts while not\naffecting non-competing MLLMs. Furthermore, we explore three potential\ncountermeasures-adding Gaussian noise, DiffPure, and adversarial training. Our\nresults show that though they can mitigate MLLM-Refusal's effectiveness, they\nalso sacrifice the accuracy and/or efficiency of the competing MLLM. The code\nis available at https://github.com/Sadcardation/MLLM-Refusal.",
      "tldr_zh": "这篇论文介绍了 MLLM-Refusal，一种创新方法，用于诱导多模态大语言模型（MLLMs）拒绝安全提示，从而为模型提供商提供竞争优势。方法通过优化一个几乎不可察觉的拒绝扰动（refusal perturbation）添加到图像中，并将其表述为约束优化问题来实现，确保目标 MLLMs 在处理包含扰动图像的安全提示时可能拒绝响应。实验在四个 MLLMs 和四个数据集上证明了该方法的有效性，同时评估了三种潜在对策（如添加 Gaussian noise 和对抗训练），结果显示这些对策虽能缓解影响，但会牺牲模型的准确性和效率。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09050v2",
      "published_date": "2024-07-12 07:18:05 UTC",
      "updated_date": "2024-09-05 21:17:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:07:58.184811"
    },
    {
      "arxiv_id": "2407.09048v1",
      "title": "KUNPENG: An Embodied Large Model for Intelligent Maritime",
      "title_zh": "翻译失败",
      "authors": [
        "Naiyao Wang",
        "Tongbang Jiang",
        "Ye Wang",
        "Shaoyang Qiu",
        "Bo Zhang",
        "Xinqiang Xie",
        "Munan Li",
        "Chunliu Wang",
        "Yiyang Wang",
        "Hongxiang Ren",
        "Ruili Wang",
        "Hongjun Shan",
        "Hongbo Liu"
      ],
      "abstract": "Intelligent maritime, as an essential component of smart ocean construction,\ndeeply integrates advanced artificial intelligence technology and data analysis\nmethods, which covers multiple aspects such as smart vessels, route\noptimization, safe navigation, aiming to enhance the efficiency of ocean\nresource utilization and the intelligence of transportation networks. However,\nthe complex and dynamic maritime environment, along with diverse and\nheterogeneous large-scale data sources, present challenges for real-time\ndecision-making in intelligent maritime. In this paper, We propose KUNPENG, the\nfirst-ever embodied large model for intelligent maritime in the smart ocean\nconstruction, which consists of six systems. The model perceives multi-source\nheterogeneous data for the cognition of environmental interaction and make\nautonomous decision strategies, which are used for intelligent vessels to\nperform navigation behaviors under safety and emergency guarantees and\ncontinuously optimize power to achieve embodied intelligence in maritime. In\ncomprehensive maritime task evaluations, KUNPENG has demonstrated excellent\nperformance.",
      "tldr_zh": "该论文提出 KUNPENG，这是一个首创的 embodied large model，用于智能海事领域，帮助提升海洋资源利用效率和交通网络智能化。KUNPENG 由六个系统组成，能够感知 multi-source heterogeneous data，进行环境交互认知、制定自主决策策略，并确保智能船舶在安全和紧急情况下进行导航行为，同时持续优化性能。在综合海事任务评估中，KUNPENG 展示了卓越的表现，为智能海事决策提供可靠支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.09048v1",
      "published_date": "2024-07-12 07:16:22 UTC",
      "updated_date": "2024-07-12 07:16:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:08:07.557840"
    },
    {
      "arxiv_id": "2407.09045v1",
      "title": "Time-Frequency Analysis of Variable-Length WiFi CSI Signals for Person Re-Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Mao",
        "Chong Tan",
        "Jingqi Hu",
        "Min Zheng"
      ],
      "abstract": "Person re-identification (ReID), as a crucial technology in the field of\nsecurity, plays an important role in security detection and people counting.\nCurrent security and monitoring systems largely rely on visual information,\nwhich may infringe on personal privacy and be susceptible to interference from\npedestrian appearances and clothing in certain scenarios. Meanwhile, the\nwidespread use of routers offers new possibilities for ReID. This letter\nintroduces a method using WiFi Channel State Information (CSI), leveraging the\nmultipath propagation characteristics of WiFi signals as a basis for\ndistinguishing different pedestrian features. We propose a two-stream network\nstructure capable of processing variable-length data, which analyzes the\namplitude in the time domain and the phase in the frequency domain of WiFi\nsignals, fuses time-frequency information through continuous lateral\nconnections, and employs advanced objective functions for representation and\nmetric learning. Tested on a dataset collected in the real world, our method\nachieves 93.68% mAP and 98.13% Rank-1.",
      "tldr_zh": "该研究针对Person Re-Identification (ReID) 的安全应用，提出了一种基于WiFi Channel State Information (CSI) 的方法，利用WiFi信号的多径传播特性来区分行人特征，从而避免了传统视觉系统对隐私的侵犯和易受干扰的问题。方法采用两流网络结构，能够处理可变长度数据，通过时域幅度分析和频域相位分析，并通过连续横向连接融合时频信息，同时应用高级目标函数进行表示和度量学习。在真实世界数据集上，该方法取得了93.68% mAP和98.13% Rank-1的优异性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09045v1",
      "published_date": "2024-07-12 07:10:47 UTC",
      "updated_date": "2024-07-12 07:10:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:08:21.985923"
    },
    {
      "arxiv_id": "2407.09043v3",
      "title": "Vision Language Model is NOT All You Need: Augmentation Strategies for Molecule Language Models",
      "title_zh": "视觉语言模型并非万能：分子语言模型的增强策略",
      "authors": [
        "Namkyeong Lee",
        "Siddhartha Laghuvarapu",
        "Chanyoung Park",
        "Jimeng Sun"
      ],
      "abstract": "Recently, there has been a growing interest among researchers in\nunderstanding molecules and their textual descriptions through molecule\nlanguage models (MoLM). However, despite some early promising developments, the\nadvancement of MoLM still trails significantly behind that of vision language\nmodels (VLM). This is because unique challenges exist apart from VLM in the\nfield of MoLM due to 1) a limited amount of molecule-text paired data and 2)\nmissing expertise that occurred due to the specialized areas of focus among the\nexperts. To this end, we propose AMOLE, which 1) augments molecule-text pairs\nwith structural similarity preserving loss, and 2) transfers the expertise\nbetween the molecules. Specifically, AMOLE enriches molecule-text pairs by\nsharing descriptions among structurally similar molecules with a novel\nstructural similarity preserving loss. Moreover, we propose an expertise\nreconstruction loss to transfer knowledge from molecules that have extensive\nexpertise to those with less expertise. Extensive experiments on various\ndownstream tasks demonstrate the superiority of AMOLE in comprehending\nmolecules and their descriptions, highlighting its potential for application in\nreal-world drug discovery. The source code for AMOLE is available at\nhttps://github.com/Namkyeong/AMOLE.",
      "tldr_zh": "该研究指出，分子语言模型（MoLM）在理解分子及其文本描述方面落后于视觉语言模型（VLM），主要由于分子-文本配对数据有限和专业知识缺失的问题。为此，提出AMOLE框架，通过结构相似性保留损失（structural similarity preserving loss）增强分子-文本配对数据，并利用专家知识重建损失（expertise reconstruction loss）转移知识，从知识丰富的分子向知识少的分子共享描述。实验在各种下游任务上证明AMOLE的优越性，提升了分子理解能力，并展示了其在现实世界药物发现中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "CIKM 2024 / ACL 2024 Workshop on Languages and Molecule",
      "pdf_url": "http://arxiv.org/pdf/2407.09043v3",
      "published_date": "2024-07-12 07:09:10 UTC",
      "updated_date": "2024-07-23 07:31:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:08:33.586644"
    },
    {
      "arxiv_id": "2407.09039v1",
      "title": "Overcoming Catastrophic Forgetting in Tabular Data Classification: A Pseudorehearsal-based approach",
      "title_zh": "翻译失败",
      "authors": [
        "Pablo García-Santaclara",
        "Bruno Fernández-Castro",
        "Rebeca P. Díaz-Redondo"
      ],
      "abstract": "Continual learning (CL) poses the important challenge of adapting to evolving\ndata distributions without forgetting previously acquired knowledge while\nconsolidating new knowledge. In this paper, we introduce a new methodology,\ncoined as Tabular-data Rehearsal-based Incremental Lifelong Learning framework\n(TRIL3), designed to address the phenomenon of catastrophic forgetting in\ntabular data classification problems. TRIL3 uses the prototype-based\nincremental generative model XuILVQ to generate synthetic data to preserve old\nknowledge and the DNDF algorithm, which was modified to run in an incremental\nway, to learn classification tasks for tabular data, without storing old\nsamples. After different tests to obtain the adequate percentage of synthetic\ndata and to compare TRIL3 with other CL available proposals, we can conclude\nthat the performance of TRIL3 outstands other options in the literature using\nonly 50% of synthetic data.",
      "tldr_zh": "这篇论文针对表格数据分类中的灾难性遗忘（catastrophic forgetting）问题，提出了一种基于伪重演（pseudorehearsal）的框架，名为 TRIL3，用于持续学习（CL）。TRIL3 利用基于原型的增量生成模型 XuILVQ 生成合成数据来保留旧知识，并采用修改后的 DNDF 算法进行增量学习分类任务，从而避免存储原始旧样本。实验结果显示，TRIL3 在使用仅 50% 合成数据的情况下，其性能优于现有 CL 方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 4 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.09039v1",
      "published_date": "2024-07-12 07:04:06 UTC",
      "updated_date": "2024-07-12 07:04:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:08:45.512810"
    },
    {
      "arxiv_id": "2407.09025v2",
      "title": "SpreadsheetLLM: Encoding Spreadsheets for Large Language Models",
      "title_zh": "SpreadsheetLLM：为大型语言模型编码电子表格",
      "authors": [
        "Haoyu Dong",
        "Jianbo Zhao",
        "Yuzhang Tian",
        "Junyu Xiong",
        "Shiyu Xia",
        "Mengyu Zhou",
        "Yun Lin",
        "José Cambronero",
        "Yeye He",
        "Shi Han",
        "Dongmei Zhang"
      ],
      "abstract": "Spreadsheets are characterized by their extensive two-dimensional grids,\nflexible layouts, and varied formatting options, which pose significant\nchallenges for large language models (LLMs). In response, we introduce\nSpreadsheetLLM, pioneering an efficient encoding method designed to unleash and\noptimize LLMs' powerful understanding and reasoning capability on spreadsheets.\nInitially, we propose a vanilla serialization approach that incorporates cell\naddresses, values, and formats. However, this approach was limited by LLMs'\ntoken constraints, making it impractical for most applications. To tackle this\nchallenge, we develop SheetCompressor, an innovative encoding framework that\ncompresses spreadsheets effectively for LLMs. It comprises three modules:\nstructural-anchor-based compression, inverse index translation, and\ndata-format-aware aggregation. It significantly improves performance in the\nspreadsheet table detection task, outperforming the vanilla approach by 25.6%\nin GPT4's in-context learning setting. Moreover, fine-tuned LLM with\nSheetCompressor has an average compression ratio of 25 times, and achieves a\nstate-of-the-art 78.9% F1 score, surpassing the best existing models by 12.3%.\nFinally, we propose Chain of Spreadsheet for downstream tasks of spreadsheet\nunderstanding and validate it in a new and demanding spreadsheet QA task. We\nmethodically leverage the inherent layout and structure of spreadsheets,\ndemonstrating that SpreadsheetLLM is highly effective across a variety of\nspreadsheet tasks.",
      "tldr_zh": "这篇论文介绍了 SpreadsheetLLM，一种高效的编码方法，旨在帮助大型语言模型(LLMs)更好地处理电子表格的二维网格、灵活布局和多种格式带来的挑战。核心创新是开发 SheetCompressor 框架，包括 structural-anchor-based compression、inverse index translation 和 data-format-aware aggregation 等模块，该框架显著提高了电子表格检测任务的性能，在 GPT4 的 in-context learning 设置中比基本序列化方法提升 25.6%。实验结果显示，微调后的 LLM 实现了 25 倍的平均压缩比，并取得了 78.9% 的 F1 分数，比现有最佳模型高 12.3%。此外，论文提出了 Chain of Spreadsheet 用于下游电子表格理解任务，并在新的电子表格 QA 任务中验证了其有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09025v2",
      "published_date": "2024-07-12 06:34:21 UTC",
      "updated_date": "2025-04-02 14:33:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:09:01.006007"
    },
    {
      "arxiv_id": "2407.09019v1",
      "title": "Heterogeneous Subgraph Network with Prompt Learning for Interpretable Depression Detection on Social Media",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Chen",
        "Mingwei Li",
        "Fenghuan Li",
        "Haopeng Chen",
        "Yuankun Lin"
      ],
      "abstract": "Massive social media data can reflect people's authentic thoughts, emotions,\ncommunication, etc., and therefore can be analyzed for early detection of\nmental health problems such as depression. Existing works about early\ndepression detection on social media lacked interpretability and neglected the\nheterogeneity of social media data. Furthermore, they overlooked the global\ninteraction among users. To address these issues, we develop a novel method\nthat leverages a Heterogeneous Subgraph Network with Prompt Learning(HSNPL) and\ncontrastive learning mechanisms. Specifically, prompt learning is employed to\nmap users' implicit psychological symbols with excellent interpretability while\ndeep semantic and diverse behavioral features are incorporated by a\nheterogeneous information network. Then, the heterogeneous graph network with a\ndual attention mechanism is constructed to model the relationships among\nheterogeneous social information at the feature level. Furthermore, the\nheterogeneous subgraph network integrating subgraph attention and\nself-supervised contrastive learning is developed to explore complicated\ninteractions among users and groups at the user level. Extensive experimental\nresults demonstrate that our proposed method significantly outperforms\nstate-of-the-art methods for depression detection on social media.",
      "tldr_zh": "本研究针对社交媒体数据中抑郁症早期检测的问题，提出了一种名为 HSNPL（Heterogeneous Subgraph Network with Prompt Learning）的创新方法，以提升检测的可解释性和处理数据的异质性，同时考虑用户间的全局互动。方法通过 prompt learning 映射用户的隐式心理符号，并整合异质信息网络、双注意力机制和自监督对比学习，来建模异质社交信息的关系以及用户和群组间的复杂互动。实验结果显示，该方法在社交媒体抑郁检测任务上显著优于现有最先进方法，提供更可靠的解释性支持。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09019v1",
      "published_date": "2024-07-12 06:20:59 UTC",
      "updated_date": "2024-07-12 06:20:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:09:10.048668"
    },
    {
      "arxiv_id": "2407.09015v1",
      "title": "Static Analysis of Logic Programs via Boolean Networks",
      "title_zh": "通过布尔网络对逻辑程序的静态分析",
      "authors": [
        "Van-Giang Trinh",
        "Belaid Benhamou"
      ],
      "abstract": "Answer Set Programming (ASP) is a declarative problem solving paradigm that\ncan be used to encode a combinatorial problem as a logic program whose stable\nmodels correspond to the solutions of the considered problem. ASP has been\nwidely applied to various domains in AI and beyond. The question \"What can be\nsaid about stable models of a logic program from its static information?\" has\nbeen investigated and proved useful in many circumstances. In this work, we\ndive into this direction more deeply by making the connection between a logic\nprogram and a Boolean network, which is a prominent modeling framework with\napplications to various areas. The proposed connection can bring the existing\nresults in the rich history on static analysis of Boolean networks to explore\nand prove more theoretical results on ASP, making it become a unified and\npowerful tool to further study the static analysis of ASP. In particular, the\nnewly obtained insights have the potential to benefit many problems in the\nfield of ASP.",
      "tldr_zh": "本文研究了Answer Set Programming (ASP)逻辑程序的静态分析，通过建立逻辑程序与Boolean networks之间的连接。作者提出将Boolean networks的现有静态分析结果应用于ASP，从而探索和证明更多ASP的理论成果。这种方法可作为统一工具，解决ASP领域的诸多问题，并为稳定模型(static models)的分析提供新见解。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09015v1",
      "published_date": "2024-07-12 06:07:05 UTC",
      "updated_date": "2024-07-12 06:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:09:21.362909"
    },
    {
      "arxiv_id": "2407.09013v1",
      "title": "Procedural Content Generation via Generative Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Mao",
        "Wanli Yu",
        "Kazunori D Yamada",
        "Michael R. Zielewski"
      ],
      "abstract": "The attempt to utilize machine learning in PCG has been made in the past. In\nthis survey paper, we investigate how generative artificial intelligence (AI),\nwhich saw a significant increase in interest in the mid-2010s, is being used\nfor PCG. We review applications of generative AI for the creation of various\ntypes of content, including terrains, items, and even storylines. While\ngenerative AI is effective for PCG, one significant issues it faces is that\nbuilding high-performance generative AI requires vast amounts of training data.\nBecause content generally highly customized, domain-specific training data is\nscarce, and straightforward approaches to generative AI models may not work\nwell. For PCG research to advance further, issues related to limited training\ndata must be overcome. Thus, we also give special consideration to research\nthat addresses the challenges posed by limited training data.",
      "tldr_zh": "这篇调查论文探讨了生成式人工智能（Generative AI）在程序化内容生成（PCG）中的应用，回顾了其在创建地形、物品和故事情节等内容方面的现有实践。Generative AI 虽然有效，但面临训练数据不足的挑战，尤其是针对高度自定义的领域数据，导致直接模型应用效果不佳。论文强调，需要通过针对性研究来克服这些限制，以推动 PCG 领域的进一步发展。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09013v1",
      "published_date": "2024-07-12 06:03:38 UTC",
      "updated_date": "2024-07-12 06:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:09:33.854404"
    },
    {
      "arxiv_id": "2407.09012v1",
      "title": "TCAN: Animating Human Images with Temporally Consistent Pose Guidance using Diffusion Models",
      "title_zh": "TCAN：使用扩散模型实现时间一致姿态引导的人类图像动画",
      "authors": [
        "Jeongho Kim",
        "Min-Jung Kim",
        "Junsoo Lee",
        "Jaegul Choo"
      ],
      "abstract": "Pose-driven human-image animation diffusion models have shown remarkable\ncapabilities in realistic human video synthesis. Despite the promising results\nachieved by previous approaches, challenges persist in achieving temporally\nconsistent animation and ensuring robustness with off-the-shelf pose detectors.\nIn this paper, we present TCAN, a pose-driven human image animation method that\nis robust to erroneous poses and consistent over time. In contrast to previous\nmethods, we utilize the pre-trained ControlNet without fine-tuning to leverage\nits extensive pre-acquired knowledge from numerous pose-image-caption pairs. To\nkeep the ControlNet frozen, we adapt LoRA to the UNet layers, enabling the\nnetwork to align the latent space between the pose and appearance features.\nAdditionally, by introducing an additional temporal layer to the ControlNet, we\nenhance robustness against outliers of the pose detector. Through the analysis\nof attention maps over the temporal axis, we also designed a novel temperature\nmap leveraging pose information, allowing for a more static background.\nExtensive experiments demonstrate that the proposed method can achieve\npromising results in video synthesis tasks encompassing various poses, like\nchibi. Project Page: https://eccv2024tcan.github.io/",
      "tldr_zh": "本论文提出 TCAN，一种基于 Diffusion Models 的姿势驱动人类图像动画方法，能够实现时间上的一致性和对现成姿势检测器的鲁棒性。与以往方法不同，TCAN 使用预训练的 ControlNet 而不进行微调，通过将 LoRA 应用于 UNet 层来对齐姿势和外观特征的潜在空间，并添加 temporal layer 以处理姿势检测异常值。论文还设计了基于注意力图的 temperature map，利用姿势信息使背景更静态。实验结果表明，TCAN 在包括 chibi 等各种姿势的视频合成任务中取得了优异表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2407.09012v1",
      "published_date": "2024-07-12 06:02:13 UTC",
      "updated_date": "2024-07-12 06:02:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:09:47.319719"
    },
    {
      "arxiv_id": "2407.09011v2",
      "title": "One Stone, Four Birds: A Comprehensive Solution for QA System Using Supervised Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Wang",
        "Tsunenori Mine"
      ],
      "abstract": "This paper presents a novel and comprehensive solution to enhance both the\nrobustness and efficiency of question answering (QA) systems through supervised\ncontrastive learning (SCL). Training a high-performance QA system has become\nstraightforward with pre-trained language models, requiring only a small amount\nof data and simple fine-tuning. However, despite recent advances, existing QA\nsystems still exhibit significant deficiencies in functionality and training\nefficiency. We address the functionality issue by defining four key tasks: user\ninput intent classification, out-of-domain input detection, new intent\ndiscovery, and continual learning. We then leverage a unified SCL-based\nrepresentation learning method to efficiently build an intra-class compact and\ninter-class scattered feature space, facilitating both known intent\nclassification and unknown intent detection and discovery. Consequently, with\nminimal additional tuning on downstream tasks, our approach significantly\nimproves model efficiency and achieves new state-of-the-art performance across\nall tasks.",
      "tldr_zh": "本文提出了一种综合解决方案，使用监督对比学习 (SCL) 来提升问答 (QA) 系统的鲁棒性和效率，解决了现有系统的功能缺陷和训练问题。该方法定义了四个关键任务：用户输入意图分类、域外输入检测、新意图发现和持续学习，并通过统一的 SCL-based 表示学习构建一个 intra-class 紧凑、inter-class 分散的特征空间，从而便于已知意图分类和未知意图检测。最终，该方法在下游任务上仅需最小额外调整，即实现了所有任务的 state-of-the-art 性能，显著提高了模型效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, updated to the accepted version",
      "pdf_url": "http://arxiv.org/pdf/2407.09011v2",
      "published_date": "2024-07-12 06:01:51 UTC",
      "updated_date": "2024-10-25 02:10:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:09:59.336481"
    },
    {
      "arxiv_id": "2407.09005v1",
      "title": "Introducing VaDA: Novel Image Segmentation Model for Maritime Object Segmentation Using New Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Yongjin Kim",
        "Jinbum Park",
        "Sanha Kang",
        "Hanguen Kim"
      ],
      "abstract": "The maritime shipping industry is undergoing rapid evolution driven by\nadvancements in computer vision artificial intelligence (AI). Consequently,\nresearch on AI-based object recognition models for maritime transportation is\nsteadily growing, leveraging advancements in sensor technology and computing\nperformance. However, object recognition in maritime environments faces\nchallenges such as light reflection, interference, intense lighting, and\nvarious weather conditions. To address these challenges, high-performance deep\nlearning algorithms tailored to maritime imagery and high-quality datasets\nspecialized for maritime scenes are essential. Existing AI recognition models\nand datasets have limited suitability for composing autonomous navigation\nsystems. Therefore, in this paper, we propose a Vertical and Detail Attention\n(VaDA) model for maritime object segmentation and a new model evaluation\nmethod, the Integrated Figure of Calculation Performance (IFCP), to verify its\nsuitability for the system in real-time. Additionally, we introduce a benchmark\nmaritime dataset, OASIs (Ocean AI Segmentation Initiatives) to standardize\nmodel performance evaluation across diverse maritime environments. OASIs\ndataset and details are available at our website:\nhttps://www.navlue.com/dataset",
      "tldr_zh": "本文提出VaDA模型，这是一种新型图像分割模型，针对海事环境中光反射、干扰和天气条件等挑战，用于精确的海事物体分割。VaDA结合了Vertical and Detail Attention机制，并引入Integrated Figure of Calculation Performance (IFCP)作为评估方法，以验证模型在实时自主导航系统中的适用性。同时，作者发布了一个基准数据集OASIs，用于标准化模型在多样海事场景下的性能评估，从而推动海事AI研究的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 9 figures, whitepaper",
      "pdf_url": "http://arxiv.org/pdf/2407.09005v1",
      "published_date": "2024-07-12 05:48:53 UTC",
      "updated_date": "2024-07-12 05:48:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:10:09.452882"
    },
    {
      "arxiv_id": "2407.09003v1",
      "title": "Enhancing Few-Shot Stock Trend Prediction with Large Language Models",
      "title_zh": "利用大型语言模型增强少样本股票趋势预测",
      "authors": [
        "Yiqi Deng",
        "Xingwei He",
        "Jiahao Hu",
        "Siu-Ming Yiu"
      ],
      "abstract": "The goal of stock trend prediction is to forecast future market movements for\ninformed investment decisions. Existing methods mostly focus on predicting\nstock trends with supervised models trained on extensive annotated data.\nHowever, human annotation can be resource-intensive and the annotated data are\nnot readily available. Inspired by the impressive few-shot capability of Large\nLanguage Models (LLMs), we propose using LLMs in a few-shot setting to overcome\nthe scarcity of labeled data and make prediction more feasible to investors.\nPrevious works typically merge multiple financial news for predicting stock\ntrends, causing two significant problems when using LLMs: (1) Merged news\ncontains noise, and (2) it may exceed LLMs' input limits, leading to\nperformance degradation. To overcome these issues, we propose a two-step method\n'denoising-then-voting'. Specifically, we introduce an `Irrelevant' category,\nand predict stock trends for individual news instead of merged news. Then we\naggregate these predictions using majority voting. The proposed method offers\ntwo advantages: (1) Classifying noisy news as irrelevant removes its impact on\nthe final prediction. (2) Predicting for individual news mitigates LLMs' input\nlength limits. Our method achieves 66.59% accuracy in S&P 500, 62.17% in\nCSI-100, and 61.17% in HK stock prediction, outperforming the standard few-shot\ncounterparts by around 7%, 4%, and 4%. Furthermore, our proposed method\nperforms on par with state-of-the-art supervised methods.",
      "tldr_zh": "该论文旨在通过Large Language Models (LLMs)提升Few-Shot股票趋势预测的性能，以解决传统监督模型依赖大量标注数据的局限性。研究提出了一种“denoising-then-voting”两步方法：首先，为每条新闻单独预测股票趋势并引入“Irrelevant”类别以去除噪音；其次，使用majority voting聚合预测结果，从而缓解输入长度限制和噪音干扰。该方法在S&P 500数据集上达到66.59%的准确率，在CSI-100和HK stock上分别达到62.17%和61.17%，比标准Few-Shot方法高出约7%、4%和4%，并与最先进监督方法相当。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09003v1",
      "published_date": "2024-07-12 05:43:11 UTC",
      "updated_date": "2024-07-12 05:43:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:10:22.676916"
    },
    {
      "arxiv_id": "2407.08992v1",
      "title": "Emotion Talk: Emotional Support via Audio Messages for Psychological Assistance",
      "title_zh": "翻译失败",
      "authors": [
        "Fabrycio Leite Nakano Almada",
        "Kauan Divino Pouso Mariano",
        "Maykon Adriell Dutra",
        "Victor Emanuel da Silva Monteiro"
      ],
      "abstract": "This paper presents \"Emotion Talk,\" a system designed to provide continuous\nemotional support through audio messages for psychological assistance. The\nprimary objective is to offer consistent support to patients outside\ntraditional therapy sessions by analyzing audio messages to detect emotions and\ngenerate appropriate responses. The solution focuses on Portuguese-speaking\nusers, ensuring that the system is linguistically and culturally relevant. This\nsystem aims to complement and enhance the psychological follow-up process\nconducted by therapists, providing immediate and accessible assistance,\nespecially in emergency situations where rapid response is crucial.\nExperimental results demonstrate the effectiveness of the proposed system,\nhighlighting its potential in applications of psychological support.",
      "tldr_zh": "本文介绍了Emotion Talk系统，这是一个通过音频消息提供持续情感支持的平台，旨在为心理援助补充传统治疗会话之外的帮助。系统通过分析音频消息检测用户情绪并生成适当响应，特别针对葡萄牙语使用者以确保语言和文化相关性。实验结果证明了该系统的有效性，尤其在紧急情况下提供即时可访问的心理支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08992v1",
      "published_date": "2024-07-12 05:13:17 UTC",
      "updated_date": "2024-07-12 05:13:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:10:33.013807"
    },
    {
      "arxiv_id": "2407.08991v1",
      "title": "Optimization of DNN-based speaker verification model through efficient quantization technique",
      "title_zh": "通过高效量化技术优化基于DNN",
      "authors": [
        "Yeona Hong",
        "Woo-Jin Chung",
        "Hong-Goo Kang"
      ],
      "abstract": "As Deep Neural Networks (DNNs) rapidly advance in various fields, including\nspeech verification, they typically involve high computational costs and\nsubstantial memory consumption, which can be challenging to manage on mobile\nsystems. Quantization of deep models offers a means to reduce both\ncomputational and memory expenses. Our research proposes an optimization\nframework for the quantization of the speaker verification model. By analyzing\nperformance changes and model size reductions in each layer of a pre-trained\nspeaker verification model, we have effectively minimized performance\ndegradation while significantly reducing the model size. Our quantization\nalgorithm is the first attempt to maintain the performance of the\nstate-of-the-art pre-trained speaker verification model, ECAPATDNN, while\nsignificantly compressing its model size. Overall, our quantization approach\nresulted in reducing the model size by half, with an increase in EER limited to\n0.07%.",
      "tldr_zh": "本研究针对DNN-based speaker verification模型的高计算成本和内存消耗问题，提出了一种高效的量化优化框架。通过分析预训练模型（如ECAPATDNN）各层的性能变化和大小减少，该框架实现了最小化性能下降的同时显著压缩模型。实验结果显示，模型大小减半，而EER仅增加0.07%，这是首次在保持state-of-the-art性能的前提下实现这种高效压缩。整体上，该方法为在移动设备上部署speaker verification模型提供了可行解决方案。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "eess.AS",
      "comment": "in Korean language, Accepted at Society of Electronic Engineers of\n  Korea Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08991v1",
      "published_date": "2024-07-12 05:03:10 UTC",
      "updated_date": "2024-07-12 05:03:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:10:45.738094"
    },
    {
      "arxiv_id": "2407.08990v1",
      "title": "Dynamic neural network with memristive CIM and CAM for 2D and 3D vision",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Zhang",
        "Woyu Zhang",
        "Shaocong Wang",
        "Ning Lin",
        "Yifei Yu",
        "Yangu He",
        "Bo Wang",
        "Hao Jiang",
        "Peng Lin",
        "Xiaoxin Xu",
        "Xiaojuan Qi",
        "Zhongrui Wang",
        "Xumeng Zhang",
        "Dashan Shang",
        "Qi Liu",
        "Kwang-Ting Cheng",
        "Ming Liu"
      ],
      "abstract": "The brain is dynamic, associative and efficient. It reconfigures by\nassociating the inputs with past experiences, with fused memory and processing.\nIn contrast, AI models are static, unable to associate inputs with past\nexperiences, and run on digital computers with physically separated memory and\nprocessing. We propose a hardware-software co-design, a semantic memory-based\ndynamic neural network (DNN) using memristor. The network associates incoming\ndata with the past experience stored as semantic vectors. The network and the\nsemantic memory are physically implemented on noise-robust ternary\nmemristor-based Computing-In-Memory (CIM) and Content-Addressable Memory (CAM)\ncircuits, respectively. We validate our co-designs, using a 40nm memristor\nmacro, on ResNet and PointNet++ for classifying images and 3D points from the\nMNIST and ModelNet datasets, which not only achieves accuracy on par with\nsoftware but also a 48.1% and 15.9% reduction in computational budget.\nMoreover, it delivers a 77.6% and 93.3% reduction in energy consumption.",
      "tldr_zh": "本研究提出了一种基于 memristor 的硬件-软件协同设计，开发了一个动态神经网络 (DNN)，旨在模仿大脑的动态联想特性，将输入数据与存储的语义向量关联。DNN 和语义记忆分别通过噪声鲁棒的 ternary memristor-based Computing-In-Memory (CIM) 和 Content-Addressable Memory (CAM) 电路实现，用于处理 2D 和 3D 视觉任务。实验在 MNIST 和 ModelNet 数据集上验证了 ResNet 和 PointNet++ 模型的性能，不仅达到与软件相当的准确率，还实现了 48.1% 和 15.9% 的计算预算减少，以及 77.6% 和 93.3% 的能源消耗降低。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.ET",
        "cs.NE"
      ],
      "primary_category": "cs.AR",
      "comment": "In press",
      "pdf_url": "http://arxiv.org/pdf/2407.08990v1",
      "published_date": "2024-07-12 04:55:57 UTC",
      "updated_date": "2024-07-12 04:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:11:00.729953"
    },
    {
      "arxiv_id": "2407.08989v1",
      "title": "Robustness of LLMs to Perturbations in Text",
      "title_zh": "LLMs 对文本扰动的鲁棒性",
      "authors": [
        "Ayush Singh",
        "Navpreet Singh",
        "Shubham Vatsal"
      ],
      "abstract": "Having a clean dataset has been the foundational assumption of most natural\nlanguage processing (NLP) systems. However, properly written text is rarely\nfound in real-world scenarios and hence, oftentimes invalidates the\naforementioned foundational assumption. Recently, Large language models (LLMs)\nhave shown impressive performance, but can they handle the inevitable noise in\nreal-world data? This work tackles this critical question by investigating\nLLMs' resilience against morphological variations in text. To that end, we\nartificially introduce varying levels of noise into a diverse set of datasets\nand systematically evaluate LLMs' robustness against the corrupt variations of\nthe original text. Our findings show that contrary to popular beliefs,\ngenerative LLMs are quiet robust to noisy perturbations in text. This is a\ndeparture from pre-trained models like BERT or RoBERTa whose performance has\nbeen shown to be sensitive to deteriorating noisy text. Additionally, we test\nLLMs' resilience on multiple real-world benchmarks that closely mimic commonly\nfound errors in the wild. With minimal prompting, LLMs achieve a new\nstate-of-the-art on the benchmark tasks of Grammar Error Correction (GEC) and\nLexical Semantic Change (LSC). To empower future research, we also release a\ndataset annotated by humans stating their preference for LLM vs.\nhuman-corrected outputs along with the code to reproduce our results.",
      "tldr_zh": "这篇论文研究了大型语言模型 (LLMs) 对文本噪声扰动的鲁棒性，挑战了传统 NLP 系统对干净数据的假设。研究方法包括在多样数据集上人为引入不同级别的形态变化噪声，并系统评估 LLMs 的性能，结果显示 LLMs 比预训练模型如 BERT 或 RoBERTa 更能耐受噪声。LLMs 在 Grammar Error Correction (GEC) 和 Lexical Semantic Change (LSC) 真实世界基准任务上，通过最小提示实现了新的最先进水平，并发布了人类偏好数据集和代码以支持未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.7; I.2.7; I.2.4"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 1 figure, 6 tables, updated with results also from GPT-4,\n  LLaMa-3",
      "pdf_url": "http://arxiv.org/pdf/2407.08989v1",
      "published_date": "2024-07-12 04:50:17 UTC",
      "updated_date": "2024-07-12 04:50:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:11:10.620811"
    },
    {
      "arxiv_id": "2407.08983v1",
      "title": "Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "David N. Palacio",
        "Daniel Rodriguez-Cardenas",
        "Alejandro Velasco",
        "Dipin Khati",
        "Kevin Moran",
        "Denys Poshyvanyk"
      ],
      "abstract": "Trustworthiness and interpretability are inextricably linked concepts for\nLLMs. The more interpretable an LLM is, the more trustworthy it becomes.\nHowever, current techniques for interpreting LLMs when applied to code-related\ntasks largely focus on accuracy measurements, measures of how models react to\nchange, or individual task performance instead of the fine-grained explanations\nneeded at prediction time for greater interpretability, and hence trust. To\nimprove upon this status quo, this paper introduces ASTrust, an\ninterpretability method for LLMs of code that generates explanations grounded\nin the relationship between model confidence and syntactic structures of\nprogramming languages. ASTrust explains generated code in the context of syntax\ncategories based on Abstract Syntax Trees and aids practitioners in\nunderstanding model predictions at both local (individual code snippets) and\nglobal (larger datasets of code) levels. By distributing and assigning model\nconfidence scores to well-known syntactic structures that exist within ASTs,\nour approach moves beyond prior techniques that perform token-level confidence\nmapping by offering a view of model confidence that directly aligns with\nprogramming language concepts with which developers are familiar. To put\nASTrust into practice, we developed an automated visualization that illustrates\nthe aggregated model confidence scores superimposed on sequence, heat-map, and\ngraph-based visuals of syntactic structures from ASTs. We examine both the\npractical benefit that ASTrust can provide through a data science study on 12\npopular LLMs on a curated set of GitHub repos and the usefulness of ASTrust\nthrough a human study.",
      "tldr_zh": "该论文探讨了提升代码相关任务中大型语言模型（LLMs）的可信度和可解释性问题，强调通过细粒度解释来超越传统准确性评估。论文引入了ASTrust方法，该方法基于Abstract Syntax Trees（ASTs）的语法结构，将模型置信度分数分配到编程语言的语法类别，从而提供局部（单个代码片段）和全局（代码数据集）层面的解释。相比以往的token-level置信度映射，ASTrust更符合开发者的认知，并通过自动可视化工具（如序列、热图和图-based显示）来展示置信度分数。研究通过数据科学实验（涉及12个流行LLMs和GitHub仓库）和人类研究，证明了ASTrust的有效性，提高了LLMs的可解释性和可信度。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Under Review to appear in ACM Transactions on Software Engineering\n  and Methodology (TOSEM)",
      "pdf_url": "http://arxiv.org/pdf/2407.08983v1",
      "published_date": "2024-07-12 04:38:28 UTC",
      "updated_date": "2024-07-12 04:38:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:11:23.154931"
    },
    {
      "arxiv_id": "2407.09580v1",
      "title": "Don't Fear Peculiar Activation Functions: EUAF and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Qianchao Wang",
        "Shijun Zhang",
        "Dong Zeng",
        "Zhaoheng Xie",
        "Hengtao Guo",
        "Feng-Lei Fan",
        "Tieyong Zeng"
      ],
      "abstract": "In this paper, we propose a new super-expressive activation function called\nthe Parametric Elementary Universal Activation Function (PEUAF). We demonstrate\nthe effectiveness of PEUAF through systematic and comprehensive experiments on\nvarious industrial and image datasets, including CIFAR10, Tiny-ImageNet, and\nImageNet. Moreover, we significantly generalize the family of super-expressive\nactivation functions, whose existence has been demonstrated in several recent\nworks by showing that any continuous function can be approximated to any\ndesired accuracy by a fixed-size network with a specific super-expressive\nactivation function. Specifically, our work addresses two major bottlenecks in\nimpeding the development of super-expressive activation functions: the limited\nidentification of super-expressive functions, which raises doubts about their\nbroad applicability, and their often peculiar forms, which lead to skepticism\nregarding their scalability and practicality in real-world applications.",
      "tldr_zh": "本论文提出了一种新的超-expressive激活函数，名为Parametric Elementary Universal Activation Function (PEUAF)，旨在提升神经网络的表现。作者通过系统实验在CIFAR10、Tiny-ImageNet和ImageNet等工业和图像数据集上验证了PEUAF的有效性。论文进一步推广了超-expressive激活函数家族，证明任何连续函数都能被固定大小的网络以特定激活函数逼近，从而解决其识别有限和实际应用中奇特形式带来的可扩展性疑虑。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09580v1",
      "published_date": "2024-07-12 03:57:25 UTC",
      "updated_date": "2024-07-12 03:57:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:11:34.789064"
    },
    {
      "arxiv_id": "2407.08970v3",
      "title": "Self-interpreting Adversarial Images",
      "title_zh": "自解释对抗图像",
      "authors": [
        "Tingwei Zhang",
        "Collin Zhang",
        "John X. Morris",
        "Eugene Bagdasarian",
        "Vitaly Shmatikov"
      ],
      "abstract": "We introduce a new type of indirect, cross-modal injection attacks against\nvisual language models that enable creation of self-interpreting images. These\nimages contain hidden \"meta-instructions\" that control how models answer users'\nquestions about the image and steer their outputs to express an\nadversary-chosen style, sentiment, or point of view. Self-interpreting images\nact as soft prompts, conditioning the model to satisfy the adversary's\n(meta-)objective while still producing answers based on the image's visual\ncontent. Meta-instructions are thus a stronger form of prompt injection.\nAdversarial images look natural and the model's answers are coherent and\nplausible--yet they also follow the adversary-chosen interpretation, e.g.,\npolitical spin, or even objectives that are not achievable with explicit text\ninstructions. We evaluate the efficacy of self-interpreting images for a\nvariety of models, interpretations, and user prompts. We describe how these\nattacks could cause harm by enabling creation of self-interpreting content that\ncarries spam, misinformation, or spin. Finally, we discuss defenses.",
      "tldr_zh": "本研究引入了一种新型间接跨模态注入攻击，名为Self-interpreting Adversarial Images，用于针对视觉语言模型（VLMs），通过嵌入隐藏的“meta-instructions”元指令来创建自解释图像，这些图像能控制模型对图像的回答，引导输出表达对手指定的风格、情感或观点，同时保持视觉内容的一致性。相比传统prompt injection，这种攻击更强大，能实现难以通过显式文本指令达到的目标，如添加政治偏见，而生成的回答看起来自然且连贯。实验评估了其在多种模型、解释和用户提示下的有效性，并讨论了潜在危害（如传播垃圾信息、误导或偏见）以及可能的防御策略。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08970v3",
      "published_date": "2024-07-12 03:40:13 UTC",
      "updated_date": "2025-01-27 23:57:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:11:46.397942"
    },
    {
      "arxiv_id": "2407.18950v2",
      "title": "Unexplainability of Artificial Intelligence Judgments in Kant's Perspective",
      "title_zh": "康德视角下人工智能判断的不可解释性",
      "authors": [
        "Jongwoo Seo"
      ],
      "abstract": "Kant's Critique of Pure Reason, a major contribution to the history of\nepistemology, proposes a table of categories to elucidate the structure of the\na priori principle of human judgment. The technology of artificial intelligence\n(AI), based on functionalism, claims to simulate or replicate human judgment.\nTo assess this claim, it is necessary to study whether AI judgment possesses\nthe characteristics of human judgment. This paper argues that AI judgments\nexhibit a form that cannot be understood in terms of the characteristics of\nhuman judgments according to Kant. Because the characteristics of judgment\noverlap, we can call this AI's uncertainty. Then, I show that concepts without\nphysical intuitions are not easy to explain when their functions are shown\nthrough vision. Finally, I illustrate that even if AI makes sentences through\nsubject and predicate in natural language, which are components of judgment, it\nis difficult to determine whether AI understands the concepts to the level\nhumans can accept. This shows that it is questionable whether the explanation\nthrough natural language is reliable.",
      "tldr_zh": "这篇论文从康德的《纯粹理性批判》(Critique of Pure Reason)视角，探讨人工智能(AI)判断的不解释性，论证AI基于功能主义(functionalism)虽声称模拟人类判断，但其判断形式无法符合康德的a priori原则和范畴表(categories)。作者指出，AI判断存在不确定性(unexplainability)，因为其概念缺乏物理直观(intuitions)，导致功能展示难以解释。最终，论文强调，即使AI通过自然语言生成主谓结构的主张，它可能无法达到人类可接受的理解水平，从而质疑AI解释的可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.18950v2",
      "published_date": "2024-07-12 03:39:55 UTC",
      "updated_date": "2024-09-08 14:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:11:57.422814"
    },
    {
      "arxiv_id": "2407.08967v1",
      "title": "Empowering Few-Shot Relation Extraction with The Integration of Traditional RE Methods and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Liu",
        "Kai Zhang",
        "Aoran Gan",
        "Linan Yue",
        "Feng Hu",
        "Qi Liu",
        "Enhong Chen"
      ],
      "abstract": "Few-Shot Relation Extraction (FSRE), a subtask of Relation Extraction (RE)\nthat utilizes limited training instances, appeals to more researchers in\nNatural Language Processing (NLP) due to its capability to extract textual\ninformation in extremely low-resource scenarios. The primary methodologies\nemployed for FSRE have been fine-tuning or prompt tuning techniques based on\nPre-trained Language Models (PLMs). Recently, the emergence of Large Language\nModels (LLMs) has prompted numerous researchers to explore FSRE through\nIn-Context Learning (ICL). However, there are substantial limitations\nassociated with methods based on either traditional RE models or LLMs.\nTraditional RE models are hampered by a lack of necessary prior knowledge,\nwhile LLMs fall short in their task-specific capabilities for RE. To address\nthese shortcomings, we propose a Dual-System Augmented Relation Extractor\n(DSARE), which synergistically combines traditional RE models with LLMs.\nSpecifically, DSARE innovatively injects the prior knowledge of LLMs into\ntraditional RE models, and conversely enhances LLMs' task-specific aptitude for\nRE through relation extraction augmentation. Moreover, an Integrated Prediction\nmodule is employed to jointly consider these two respective predictions and\nderive the final results. Extensive experiments demonstrate the efficacy of our\nproposed method.",
      "tldr_zh": "本文提出了一种 Dual-System Augmented Relation Extractor (DSARE) 方法，用于提升 Few-Shot Relation Extraction (FSRE) 的性能，通过整合传统 RE 方法和 Large Language Models (LLMs) 来解决二者各自的局限性。传统 RE 模型缺乏先验知识，而 LLMs 在任务特定能力上不足，DSARE 创新性地将 LLMs 的先验知识注入传统模型，同时通过关系提取增强 (Relation Extraction Augmentation) 提升 LLMs 的 RE 适应性。系统还引入 Integrated Prediction 模块，联合考虑两个系统的预测结果，以生成最终输出。实验结果表明，该方法在低资源场景下显著提高了 FSRE 的提取准确性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08967v1",
      "published_date": "2024-07-12 03:31:11 UTC",
      "updated_date": "2024-07-12 03:31:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:12:11.281931"
    },
    {
      "arxiv_id": "2407.08966v1",
      "title": "LAPT: Label-driven Automated Prompt Tuning for OOD Detection with Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yabin Zhang",
        "Wenjie Zhu",
        "Chenhang He",
        "Lei Zhang"
      ],
      "abstract": "Out-of-distribution (OOD) detection is crucial for model reliability, as it\nidentifies samples from unknown classes and reduces errors due to unexpected\ninputs. Vision-Language Models (VLMs) such as CLIP are emerging as powerful\ntools for OOD detection by integrating multi-modal information. However, the\npractical application of such systems is challenged by manual prompt\nengineering, which demands domain expertise and is sensitive to linguistic\nnuances. In this paper, we introduce Label-driven Automated Prompt Tuning\n(LAPT), a novel approach to OOD detection that reduces the need for manual\nprompt engineering. We develop distribution-aware prompts with in-distribution\n(ID) class names and negative labels mined automatically. Training samples\nlinked to these class labels are collected autonomously via image synthesis and\nretrieval methods, allowing for prompt learning without manual effort. We\nutilize a simple cross-entropy loss for prompt optimization, with cross-modal\nand cross-distribution mixing strategies to reduce image noise and explore the\nintermediate space between distributions, respectively. The LAPT framework\noperates autonomously, requiring only ID class names as input and eliminating\nthe need for manual intervention. With extensive experiments, LAPT consistently\noutperforms manually crafted prompts, setting a new standard for OOD detection.\nMoreover, LAPT not only enhances the distinction between ID and OOD samples,\nbut also improves the ID classification accuracy and strengthens the\ngeneralization robustness to covariate shifts, resulting in outstanding\nperformance in challenging full-spectrum OOD detection tasks. Codes are\navailable at \\url{https://github.com/YBZh/LAPT}.",
      "tldr_zh": "本研究提出了一种标签驱动的自动提示调整方法（LAPT），旨在解决 Vision-Language Models (VLMs) 如 CLIP 在 Out-of-distribution (OOD) 检测中的手动提示工程问题，提高模型可靠性并减少人为干预。LAPT 通过利用 In-distribution (ID) 类名自动挖掘负面标签，并结合图像合成和检索方法生成训练样本，使用 cross-entropy loss 及 cross-modal 和 cross-distribution mixing 策略优化提示。实验结果显示，LAPT 显著优于手动提示，不仅提升了 ID 和 OOD 样本的区分能力，还改善了 ID 分类准确性和对 covariate shifts 的泛化鲁棒性，在全谱 OOD 检测任务中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV2024; Codes and Supp. are available at:\n  https://github.com/YBZh/LAPT",
      "pdf_url": "http://arxiv.org/pdf/2407.08966v1",
      "published_date": "2024-07-12 03:30:53 UTC",
      "updated_date": "2024-07-12 03:30:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:12:23.085830"
    },
    {
      "arxiv_id": "2407.08963v1",
      "title": "Local Optima in Diversity Optimization: Non-trivial Offspring Population is Essential",
      "title_zh": "多样性优化中的局部最优：非平凡后代种群是必需的",
      "authors": [
        "Denis Antipov",
        "Aneta Neumann",
        "Frank Neumann"
      ],
      "abstract": "The main goal of diversity optimization is to find a diverse set of solutions\nwhich satisfy some lower bound on their fitness. Evolutionary algorithms (EAs)\nare often used for such tasks, since they are naturally designed to optimize\npopulations of solutions. This approach to diversity optimization, called EDO,\nhas been previously studied from theoretical perspective, but most studies\nconsidered only EAs with a trivial offspring population such as the $(\\mu + 1)$\nEA. In this paper we give an example instance of a $k$-vertex cover problem,\nwhich highlights a critical difference of the diversity optimization from the\nregular single-objective optimization, namely that there might be a locally\noptimal population from which we can escape only by replacing at least two\nindividuals at once, which the $(\\mu + 1)$ algorithms cannot do.\n  We also show that the $(\\mu + \\lambda)$ EA with $\\lambda \\ge \\mu$ can\neffectively find a diverse population on $k$-vertex cover, if using a mutation\noperator inspired by Branson and Sutton (TCS 2023). To avoid the problem of\nsubset selection which arises in the $(\\mu + \\lambda)$ EA when it optimizes\ndiversity, we also propose the $(1_\\mu + 1_\\mu)$ EA$_D$, which is an analogue\nof the $(1 + 1)$ EA for populations, and which is also efficient at optimizing\ndiversity on the $k$-vertex cover problem.",
      "tldr_zh": "该研究探讨了多样性优化中的局部最优问题，强调非平凡的后代种群（如不止一个后代）是必要的。论文通过一个 k-vertex cover 问题的实例，展示了多样性优化与单目标优化的关键差异：存在只能通过一次替换至少两个个体才能逃离的局部最优种群，而传统的 (μ + 1) EA 算法无法实现这一点。主要贡献包括证明 (μ + λ) EA（当 λ ≥ μ 时，使用 Branson 和 Sutton 启发的变异算子）能在 k-vertex cover 上有效找到多样化种群，并提出 (1_μ + 1_μ) EA_D 算法，以避免子集选择问题并高效优化多样性。总之，该工作为改进进化算法 (EAs) 在多样性优化中的性能提供了理论基础和实用方法。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Open-access version of the same-titled PPSN 2024 paper",
      "pdf_url": "http://arxiv.org/pdf/2407.08963v1",
      "published_date": "2024-07-12 03:27:47 UTC",
      "updated_date": "2024-07-12 03:27:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:12:35.827573"
    },
    {
      "arxiv_id": "2407.08952v5",
      "title": "Detect, Investigate, Judge and Determine: A Knowledge-guided Framework for Few-shot Fake News Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Liu",
        "Jiajun Zhu",
        "Xukai Liu",
        "Haoyu Tang",
        "Yanghai Zhang",
        "Kai Zhang",
        "Xiaofang Zhou",
        "Enhong Chen"
      ],
      "abstract": "Few-Shot Fake News Detection (FS-FND) aims to distinguish inaccurate news\nfrom real ones in extremely low-resource scenarios. This task has garnered\nincreased attention due to the widespread dissemination and harmful impact of\nfake news on social media. Large Language Models (LLMs) have demonstrated\ncompetitive performance with the help of their rich prior knowledge and\nexcellent in-context learning abilities. However, existing methods face\nsignificant limitations, such as the Understanding Ambiguity and Information\nScarcity, which significantly undermine the potential of LLMs. To address these\nshortcomings, we propose a Dual-perspective Knowledge-guided Fake News\nDetection (DKFND) model, designed to enhance LLMs from both inside and outside\nperspectives. Specifically, DKFND first identifies the knowledge concepts of\neach news article through a Detection Module. Subsequently, DKFND creatively\ndesigns an Investigation Module to retrieve inside and outside valuable\ninformation concerning to the current news, followed by another Judge Module to\nevaluate the relevance and confidence of them. Finally, a Determination Module\nfurther derives two respective predictions and obtain the final result.\nExtensive experiments on two public datasets show the efficacy of our proposed\nmethod, particularly in low-resource settings.",
      "tldr_zh": "本文提出DKFND模型，用于Few-Shot Fake News Detection（FS-FND），通过双视角知识引导增强Large Language Models (LLMs)，以解决理解模糊和信息稀缺问题。模型包括Detection Module识别新闻知识概念、Investigation Module检索内部和外部相关信息、Judge Module评估其相关性和置信度，以及Determination Module整合预测得出最终结果。在两个公共数据集上的实验表明，该方法在低资源场景下显著提高了假新闻检测的效能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08952v5",
      "published_date": "2024-07-12 03:15:01 UTC",
      "updated_date": "2025-03-12 04:46:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:12:46.201937"
    },
    {
      "arxiv_id": "2407.08942v1",
      "title": "A Neural Matrix Decomposition Recommender System Model based on the Multimodal Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Ao Xiang",
        "Bingjie Huang",
        "Xinyu Guo",
        "Haowei Yang",
        "Tianyao Zheng"
      ],
      "abstract": "Recommendation systems have become an important solution to information\nsearch problems. This article proposes a neural matrix factorization\nrecommendation system model based on the multimodal large language model called\nBoNMF. This model combines BoBERTa's powerful capabilities in natural language\nprocessing, ViT in computer in vision, and neural matrix decomposition\ntechnology. By capturing the potential characteristics of users and items, and\nafter interacting with a low-dimensional matrix composed of user and item IDs,\nthe neural network outputs the results. recommend. Cold start and ablation\nexperimental results show that the BoNMF model exhibits excellent performance\non large public data sets and significantly improves the accuracy of\nrecommendations.",
      "tldr_zh": "这篇论文提出了一种名为 BoNMF 的神经矩阵分解推荐系统模型，基于多模态大型语言模型，旨在提升信息推荐的准确性。该模型整合了 BoBERTa 在自然语言处理的能力、ViT 在计算机视觉的处理，以及神经矩阵分解技术，通过捕捉用户和物品的潜在特征并与低维矩阵交互来输出推荐结果。实验显示，BoNMF 在冷启动和消融实验中，在大型公共数据集上表现出色，显著提高了推荐准确率。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08942v1",
      "published_date": "2024-07-12 02:58:07 UTC",
      "updated_date": "2024-07-12 02:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:12:59.258687"
    },
    {
      "arxiv_id": "2407.08937v1",
      "title": "Self-Evolving GPT: A Lifelong Autonomous Experiential Learner",
      "title_zh": "自我演化的 GPT：一个终生自治的经验学习者",
      "authors": [
        "Jinglong Gao",
        "Xiao Ding",
        "Yiming Cui",
        "Jianbai Zhao",
        "Hepeng Wang",
        "Ting Liu",
        "Bing Qin"
      ],
      "abstract": "To improve the performance of large language models (LLMs), researchers have\nexplored providing LLMs with textual task-solving experience via prompts.\nHowever, they rely on manual efforts to acquire and apply such experience for\neach task, which is not feasible for the growing demand for LLMs and the\nvariety of user questions. To address this issue, we design a lifelong\nautonomous experiential learning framework based on LLMs to explore whether\nLLMs can imitate human ability for learning and utilizing experience. It\nautonomously learns and accumulates experience through experience transfer and\ninduction, categorizing the types of input questions to select which\naccumulated experience to employ for them. Experimental results on six widely\nused NLP datasets show that our framework performs reliably in each\nintermediate step and effectively improves the performance of GPT-3.5 and\nGPT-4. This validates the feasibility of using LLMs to mimic human experiential\nlearning and application capabilities. Additionally, we provide a detailed\nanalysis of the behavior of our framework at each step.",
      "tldr_zh": "该研究提出了一种名为Self-Evolving GPT的终身自主体验学习框架，旨在让大型语言模型(LLMs)模仿人类学习和应用经验的能力，而无需手动干预。框架通过经验转移和归纳来自主积累经验，并根据输入问题的类型分类选择合适的经验进行任务处理。实验结果显示，在六个NLP数据集上，该框架显著提升了GPT-3.5和GPT-4的性能，并在每个步骤中表现出可靠性，验证了LLMs在体验学习方面的可行性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 MAIN",
      "pdf_url": "http://arxiv.org/pdf/2407.08937v1",
      "published_date": "2024-07-12 02:49:13 UTC",
      "updated_date": "2024-07-12 02:49:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:13:10.338016"
    },
    {
      "arxiv_id": "2407.08932v2",
      "title": "Deep Attention Driven Reinforcement Learning (DAD-RL) for Autonomous Decision-Making in Dynamic Environment",
      "title_zh": "深度注意力驱动强化学习 (DAD-RL) 用于动态环境中的自主决策",
      "authors": [
        "Jayabrata Chowdhury",
        "Venkataramanan Shivaraman",
        "Sumit Dangi",
        "Suresh Sundaram",
        "P. B. Sujit"
      ],
      "abstract": "Autonomous Vehicle (AV) decision making in urban environments is inherently\nchallenging due to the dynamic interactions with surrounding vehicles. For safe\nplanning, AV must understand the weightage of various spatiotemporal\ninteractions in a scene. Contemporary works use colossal transformer\narchitectures to encode interactions mainly for trajectory prediction,\nresulting in increased computational complexity. To address this issue without\ncompromising spatiotemporal understanding and performance, we propose the\nsimple Deep Attention Driven Reinforcement Learning (DADRL) framework, which\ndynamically assigns and incorporates the significance of surrounding vehicles\ninto the ego's RL driven decision making process. We introduce an AV centric\nspatiotemporal attention encoding (STAE) mechanism for learning the dynamic\ninteractions with different surrounding vehicles. To understand map and route\ncontext, we employ a context encoder to extract features from context maps. The\nspatiotemporal representations combined with contextual encoding provide a\ncomprehensive state representation. The resulting model is trained using the\nSoft Actor Critic (SAC) algorithm. We evaluate the proposed framework on the\nSMARTS urban benchmarking scenarios without traffic signals to demonstrate that\nDADRL outperforms recent state of the art methods. Furthermore, an ablation\nstudy underscores the importance of the context-encoder and spatio temporal\nattention encoder in achieving superior performance.",
      "tldr_zh": "该论文提出Deep Attention Driven Reinforcement Learning (DAD-RL)框架，用于提升自动驾驶车辆(Autonomous Vehicle, AV)在动态城市环境中的决策能力，通过动态分配周围车辆的重要性来解决时空互动的复杂性问题。框架引入AV中心时空注意编码(STAE)机制来学习动态互动，并使用上下文编码器提取地图和路线特征，结合这些表示形成全面的状态表示。模型采用Soft Actor Critic (SAC)算法进行训练，并在SMARTS基准场景中表现出色，比现有方法性能更优；消融研究进一步证明了上下文编码器和STAE机制的关键作用。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.08932v2",
      "published_date": "2024-07-12 02:34:44 UTC",
      "updated_date": "2024-09-28 05:26:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:13:22.344915"
    },
    {
      "arxiv_id": "2407.08918v1",
      "title": "Exploring Knowledge Transfer in Evolutionary Many-task Optimization: A Complex Network Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Yudong Yang",
        "Kai Wu",
        "Xiangyi Teng",
        "Handing Wang",
        "He Yu",
        "Jing Liu"
      ],
      "abstract": "The field of evolutionary many-task optimization (EMaTO) is increasingly\nrecognized for its ability to streamline the resolution of optimization\nchallenges with repetitive characteristics, thereby conserving computational\nresources. This paper tackles the challenge of crafting efficient knowledge\ntransfer mechanisms within EMaTO, a task complicated by the computational\ndemands of individual task evaluations. We introduce a novel framework that\nemploys a complex network to comprehensively analyze the dynamics of knowledge\ntransfer between tasks within EMaTO. By extracting and scrutinizing the\nknowledge transfer network from existing EMaTO algorithms, we evaluate the\ninfluence of network modifications on overall algorithmic efficacy. Our\nfindings indicate that these networks are diverse, displaying\ncommunity-structured directed graph characteristics, with their network density\nadapting to different task sets. This research underscores the viability of\nintegrating complex network concepts into EMaTO to refine knowledge transfer\nprocesses, paving the way for future advancements in the domain.",
      "tldr_zh": "这篇论文探讨了在Evolutionary Many-task Optimization (EMaTO)中知识转移的机制，通过Complex Network视角来优化处理重复优化问题的计算资源利用。研究引入了一个新框架，提取并分析现有EMaTO算法中的知识转移网络，评估网络修改对算法效能的影响。结果显示，这些网络呈现多样性，包括社区结构化的有向图特征和适应不同任务集的网络密度，这为整合Complex Network概念以改进EMaTO的知识转移过程提供了可行路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, accepted by GECCO 2024 poster",
      "pdf_url": "http://arxiv.org/pdf/2407.08918v1",
      "published_date": "2024-07-12 01:49:04 UTC",
      "updated_date": "2024-07-12 01:49:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:13:35.330926"
    },
    {
      "arxiv_id": "2407.08910v1",
      "title": "PAIL: Performance based Adversarial Imitation Learning Engine for Carbon Neutral Optimization",
      "title_zh": "PAIL：基于性能的对抗模仿学习引擎，用于碳中和优化",
      "authors": [
        "Yuyang Ye",
        "Lu-An Tang",
        "Haoyu Wang",
        "Runlong Yu",
        "Wenchao Yu",
        "Erhu He",
        "Haifeng Chen",
        "Hui Xiong"
      ],
      "abstract": "Achieving carbon neutrality within industrial operations has become\nincreasingly imperative for sustainable development. It is both a significant\nchallenge and a key opportunity for operational optimization in industry 4.0.\nIn recent years, Deep Reinforcement Learning (DRL) based methods offer\npromising enhancements for sequential optimization processes and can be used\nfor reducing carbon emissions. However, existing DRL methods need a pre-defined\nreward function to assess the impact of each action on the final sustainable\ndevelopment goals (SDG). In many real applications, such a reward function\ncannot be given in advance. To address the problem, this study proposes a\nPerformance based Adversarial Imitation Learning (PAIL) engine. It is a novel\nmethod to acquire optimal operational policies for carbon neutrality without\nany pre-defined action rewards. Specifically, PAIL employs a Transformer-based\npolicy generator to encode historical information and predict following actions\nwithin a multi-dimensional space. The entire action sequence will be\niteratively updated by an environmental simulator. Then PAIL uses a\ndiscriminator to minimize the discrepancy between generated sequences and\nreal-world samples of high SDG. In parallel, a Q-learning framework based\nperformance estimator is designed to estimate the impact of each action on SDG.\nBased on these estimations, PAIL refines generated policies with the rewards\nfrom both discriminator and performance estimator. PAIL is evaluated on\nmultiple real-world application cases and datasets. The experiment results\ndemonstrate the effectiveness of PAIL comparing to other state-of-the-art\nbaselines. In addition, PAIL offers meaningful interpretability for the\noptimization in carbon neutrality.",
      "tldr_zh": "该研究提出PAIL（Performance based Adversarial Imitation Learning）引擎，一种基于逆强化学习的方法，用于优化工业操作以实现碳中和，而无需预定义奖励函数。PAIL 采用 Transformer-based 政策生成器来编码历史信息并预测多维动作序列，并结合判别器最小化生成序列与真实高可持续发展目标（SDG）样本的差异，同时使用 Q-learning 框架的性能估计器评估动作影响并优化政策。实验结果显示，PAIL 在多个真实案例和数据集上优于现有深度强化学习（DRL）基线，并提供可解释性的碳中和优化策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08910v1",
      "published_date": "2024-07-12 01:06:01 UTC",
      "updated_date": "2024-07-12 01:06:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:13:46.758934"
    },
    {
      "arxiv_id": "2407.08908v1",
      "title": "Are They the Same Picture? Adapting Concept Bottleneck Models for Human-AI Collaboration in Image Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Vaibhav Balloli",
        "Sara Beery",
        "Elizabeth Bondi-Kelly"
      ],
      "abstract": "Image retrieval plays a pivotal role in applications from wildlife\nconservation to healthcare, for finding individual animals or relevant images\nto aid diagnosis. Although deep learning techniques for image retrieval have\nadvanced significantly, their imperfect real-world performance often\nnecessitates including human expertise. Human-in-the-loop approaches typically\nrely on humans completing the task independently and then combining their\nopinions with an AI model in various ways, as these models offer very little\ninterpretability or \\textit{correctability}. To allow humans to intervene in\nthe AI model instead, thereby saving human time and effort, we adapt the\nConcept Bottleneck Model (CBM) and propose \\texttt{CHAIR}. \\texttt{CHAIR} (a)\nenables humans to correct intermediate concepts, which helps \\textit{improve}\nembeddings generated, and (b) allows for flexible levels of intervention that\naccommodate varying levels of human expertise for better retrieval. To show the\nefficacy of \\texttt{CHAIR}, we demonstrate that our method performs better than\nsimilar models on image retrieval metrics without any external intervention.\nFurthermore, we also showcase how human intervention helps further improve\nretrieval performance, thereby achieving human-AI complementarity.",
      "tldr_zh": "这篇论文探讨了图像检索在野生动物保护和医疗保健等领域的应用，强调了现有深度学习模型的局限性，需要人类专家介入以提升性能。作者改进了 Concept Bottleneck Model (CBM)，提出 CHAIR 框架，允许人类纠正中间概念，从而优化生成的嵌入向量并支持灵活干预级别，以适应不同人类 expertise。实验结果表明，CHAIR 在图像检索指标上优于类似模型，即使无外部干预；此外，人类干预进一步提升了检索性能，实现人类-AI 互补。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at Human-Centred AI Track at IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08908v1",
      "published_date": "2024-07-12 00:59:32 UTC",
      "updated_date": "2024-07-12 00:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:13:59.480973"
    },
    {
      "arxiv_id": "2407.08906v2",
      "title": "AirSketch: Generative Motion to Sketch",
      "title_zh": "AirSketch：生成运动到草图",
      "authors": [
        "Hui Xian Grace Lim",
        "Xuanming Cui",
        "Ser-Nam Lim",
        "Yogesh S Rawat"
      ],
      "abstract": "Illustration is a fundamental mode of human expression and communication.\nCertain types of motion that accompany speech can provide this illustrative\nmode of communication. While Augmented and Virtual Reality technologies (AR/VR)\nhave introduced tools for producing drawings with hand motions (air drawing),\nthey typically require costly hardware and additional digital markers, thereby\nlimiting their accessibility and portability. Furthermore, air drawing demands\nconsiderable skill to achieve aesthetic results. To address these challenges,\nwe introduce the concept of AirSketch, aimed at generating faithful and\nvisually coherent sketches directly from hand motions, eliminating the need for\ncomplicated headsets or markers. We devise a simple augmentation-based\nself-supervised training procedure, enabling a controllable image diffusion\nmodel to learn to translate from highly noisy hand tracking images to clean,\naesthetically pleasing sketches, while preserving the essential visual cues\nfrom the original tracking data. We present two air drawing datasets to study\nthis problem. Our findings demonstrate that beyond producing photo-realistic\nimages from precise spatial inputs, controllable image diffusion can\neffectively produce a refined, clear sketch from a noisy input. Our work serves\nas an initial step towards marker-less air drawing and reveals distinct\napplications of controllable diffusion models to AirSketch and AR/VR in\ngeneral.",
      "tldr_zh": "本文提出AirSketch概念，利用手部动作生成忠实且视觉连贯的草图，旨在解决传统AR/VR air drawing的硬件依赖（如头戴设备和数字标记）和技能门槛问题。研究设计了一个基于增强的自我监督训练过程，训练可控图像扩散模型，将嘈杂的手部跟踪图像转换为干净、美观的草图，同时保留关键视觉线索。实验通过两个air drawing数据集验证了该方法的有效性，证明可控图像扩散模型能从嘈杂输入产生精炼草图，为无标记air drawing和AR/VR应用开辟新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08906v2",
      "published_date": "2024-07-12 00:52:04 UTC",
      "updated_date": "2024-11-10 21:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:14:11.080778"
    },
    {
      "arxiv_id": "2407.18949v1",
      "title": "Predicting Winning Captions for Weekly New Yorker Comics",
      "title_zh": "翻译失败",
      "authors": [
        "Stanley Cao",
        "Sonny Young"
      ],
      "abstract": "Image captioning using Vision Transformers (ViTs) represents a pivotal\nconvergence of computer vision and natural language processing, offering the\npotential to enhance user experiences, improve accessibility, and provide\ntextual representations of visual data. This paper explores the application of\nimage captioning techniques to New Yorker cartoons, aiming to generate captions\nthat emulate the wit and humor of winning entries in the New Yorker Cartoon\nCaption Contest. This task necessitates sophisticated visual and linguistic\nprocessing, along with an understanding of cultural nuances and humor. We\npropose several new baselines for using vision transformer encoder-decoder\nmodels to generate captions for the New Yorker cartoon caption contest.",
      "tldr_zh": "这篇论文探讨了使用Vision Transformers (ViTs)进行图像标题生成，特别应用于New Yorker漫画，以预测其每周漫画比赛的获胜标题。研究强调了需要高级视觉和语言处理能力，以捕捉文化细微和幽默元素，并提出了几个新的基准模型，基于vision transformer encoder-decoder架构来生成机智幽默的标题。这些创新方法旨在提升图像标题的准确性和趣味性，为用户体验和可访问性提供更好的文本表示。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.18949v1",
      "published_date": "2024-07-12 00:45:00 UTC",
      "updated_date": "2024-07-12 00:45:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:14:32.724112"
    },
    {
      "arxiv_id": "2407.08903v1",
      "title": "TensorTEE: Unifying Heterogeneous TEE Granularity for Efficient Secure Collaborative Tensor Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Husheng Han",
        "Xinyao Zheng",
        "Yuanbo Wen",
        "Yifan Hao",
        "Erhu Feng",
        "Ling Liang",
        "Jianan Mu",
        "Xiaqing Li",
        "Tianyun Ma",
        "Pengwei Jin",
        "Xinkai Song",
        "Zidong Du",
        "Qi Guo",
        "Xing Hu"
      ],
      "abstract": "Heterogeneous collaborative computing with NPU and CPU has received\nwidespread attention due to its substantial performance benefits. To ensure\ndata confidentiality and integrity during computing, Trusted Execution\nEnvironments (TEE) is considered a promising solution because of its\ncomparatively lower overhead. However, existing heterogeneous TEE designs are\ninefficient for collaborative computing due to fine and different memory\ngranularities between CPU and NPU. 1) The cacheline granularity of CPU TEE\nintensifies memory pressure due to its extra memory access, and 2) the\ncacheline granularity MAC of NPU escalates the pressure on the limited memory\nstorage. 3) Data transfer across heterogeneous enclaves relies on the transit\nof non-secure regions, resulting in cumbersome re-encryption and scheduling.\n  To address these issues, we propose TensorTEE, a unified tensor-granularity\nheterogeneous TEE for efficient secure collaborative tensor computing. First,\nwe virtually support tensor granularity in CPU TEE to eliminate the off-chip\nmetadata access by detecting and maintaining tensor structures on-chip. Second,\nwe propose tensor-granularity MAC management with predictive execution to avoid\ncomputational stalls while eliminating off-chip MAC storage and access.\nMoreover, based on the unified granularity, we enable direct data transfer\nwithout re-encryption and scheduling dilemmas. Our evaluation is built on\nenhanced Gem5 and a cycle-accurate NPU simulator. The results show that\nTensorTEE improves the performance of Large Language Model (LLM) training\nworkloads by 4.0x compared to existing work and incurs only 2.1% overhead\ncompared to non-secure training, offering a practical security assurance for\nLLM training.",
      "tldr_zh": "该论文针对异构协作计算（如 NPU 和 CPU）中的数据保密性和完整性问题，提出 TensorTEE 框架，以统一 TEE 粒度实现高效安全的张量计算。首先，TensorTEE 在 CPU TEE 中虚拟支持张量粒度，减少内存访问压力，并通过张量粒度 MAC 管理和预测执行避免计算停顿，同时实现直接数据传输以消除重新加密需求。其次，实验结果显示，TensorTEE 使 Large Language Model (LLM) 训练性能提升 4.0 倍，仅比非安全训练增加 2.1% 开销，为安全协作计算提供了实用解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by ASPLOS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08903v1",
      "published_date": "2024-07-12 00:35:18 UTC",
      "updated_date": "2024-07-12 00:35:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:14:33.857704"
    },
    {
      "arxiv_id": "2407.08902v1",
      "title": "Application of Artificial Intelligence in Supporting Healthcare Professionals and Caregivers in Treatment of Autistic Children",
      "title_zh": "翻译失败",
      "authors": [
        "Hossein Mohammadi Rouzbahani",
        "Hadis Karimipour"
      ],
      "abstract": "Autism Spectrum Disorder (ASD) represents a multifaceted neurodevelopmental\ncondition marked by difficulties in social interaction, communication\nimpediments, and repetitive behaviors. Despite progress in understanding ASD,\nits diagnosis and treatment continue to pose significant challenges due to the\nvariability in symptomatology and the necessity for multidisciplinary care\napproaches. This paper investigates the potential of Artificial Intelligence\n(AI) to augment the capabilities of healthcare professionals and caregivers in\nmanaging ASD. We have developed a sophisticated algorithm designed to analyze\nfacial and bodily expressions during daily activities of both autistic and\nnon-autistic children, leading to the development of a powerful deep\nlearning-based autism detection system. Our study demonstrated that AI models,\nspecifically the Xception and ResNet50V2 architectures, achieved high accuracy\nin diagnosing Autism Spectrum Disorder (ASD). This research highlights the\ntransformative potential of AI in improving the diagnosis, treatment, and\ncomprehensive management of ASD. Our study revealed that AI models, notably the\nXception and ResNet50V2 architectures, demonstrated high accuracy in diagnosing\nASD.",
      "tldr_zh": "本论文探讨了人工智能(AI)在支持医疗专业人士和护理者治疗自闭症谱系障碍(ASD)儿童方面的应用，旨在解决ASD诊断和治疗的挑战，如症状多样性和多学科需求。研究开发了一个基于深度学习的算法，通过分析自闭症和非自闭症儿童的日常活动中的面部和身体表情，利用Xception和ResNet50V2架构实现了高准确率的ASD检测。实验结果显示，这些AI模型显著提升了ASD的诊断能力，并展示了AI在改善ASD的全面管理和治疗方面的变革潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08902v1",
      "published_date": "2024-07-12 00:34:40 UTC",
      "updated_date": "2024-07-12 00:34:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:14:46.891770"
    },
    {
      "arxiv_id": "2407.08898v1",
      "title": "IDAT: A Multi-Modal Dataset and Toolkit for Building and Evaluating Interactive Task-Solving Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Shrestha Mohanty",
        "Negar Arabzadeh",
        "Andrea Tupini",
        "Yuxuan Sun",
        "Alexey Skrynnik",
        "Artem Zholus",
        "Marc-Alexandre Côté",
        "Julia Kiseleva"
      ],
      "abstract": "Seamless interaction between AI agents and humans using natural language\nremains a key goal in AI research. This paper addresses the challenges of\ndeveloping interactive agents capable of understanding and executing grounded\nnatural language instructions through the IGLU competition at NeurIPS. Despite\nadvancements, challenges such as a scarcity of appropriate datasets and the\nneed for effective evaluation platforms persist. We introduce a scalable data\ncollection tool for gathering interactive grounded language instructions within\na Minecraft-like environment, resulting in a Multi-Modal dataset with around\n9,000 utterances and over 1,000 clarification questions. Additionally, we\npresent a Human-in-the-Loop interactive evaluation platform for qualitative\nanalysis and comparison of agent performance through multi-turn communication\nwith human annotators. We offer to the community these assets referred to as\nIDAT (IGLU Dataset And Toolkit) which aim to advance the development of\nintelligent, interactive AI agents and provide essential resources for further\nresearch.",
      "tldr_zh": "本论文介绍了 IDAT，这是一个多模态数据集和工具包，旨在帮助构建和评估交互式任务解决代理，以应对 AI 代理理解和执行 grounded natural language instructions 的挑战。IDAT 通过一个 Minecraft-like 环境的可扩展数据收集工具，创建了包含约 9,000 个 utterances 和超过 1,000 个 clarification questions 的数据集，支持 IGLU competition 的研究需求。此外，该工具包包括一个 Human-in-the-Loop 交互评估平台，用于通过多轮通信进行定性分析和代理性能比较，从而推进智能交互 AI 代理的发展和社区资源共享。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08898v1",
      "published_date": "2024-07-12 00:07:43 UTC",
      "updated_date": "2024-07-12 00:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:14:58.846086"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 101,
  "processed_papers_count": 101,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T06:15:30.510753"
}