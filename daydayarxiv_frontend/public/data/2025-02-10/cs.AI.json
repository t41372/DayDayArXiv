{
  "date": "2025-02-10",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-10 的 arXiv 中文 TLDR 快报！今天的论文主要聚焦于 AI 模型优化（如 LLM 的多语言应用和知识蒸馏）、图神经网络、强化学习以及医疗领域的创新应用，亮点包括 TripoSG 在 3D 生成的突破性贡献和 Krutrim LLM 针对十亿级多语用户的设计，同时强调了知名学者如 Jure Leskovec 和 Leslie Pack Kaelbling 的相关工作。\n\n### 重点论文讨论\n我们挑选了今天最重要和有话题度的论文先聊，包括 LLM 优化、医疗 AI 和图神经网络领域。其他论文会快速掠过，只提核心点。\n\n1. **TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models**  \n   这篇论文由 Yangguang Li 等作者提出，聚焦 3D 形状生成。贡献在于提出 TripoSG 框架，使用大规模修正流模型训练，实现了高保真 3D 网格生成，显著提高了图像对齐和泛化能力。发现显示它在图像生成任务中超越了扩散模型，强调了数据规模对 3D 生成的影响。\n\n2. **Krutrim LLM: Multilingual Foundational Model for over a Billion People**  \n   作者 Aditya Kallappa 等构建了一个针对印度语境的多语言 LLM。关键贡献是使用最大规模的 Indic 数据集训练，解决了数据不平衡问题。发现表明它在 Indic 基准上优于 LLaMA-2，同时保持英语性能，适用于全球十亿用户，突出了 LLM 在低资源语言中的潜力。\n\n3. **Foundation Models for Anomaly Detection: Vision and Challenges**  \n   Runlong Yu 等作者探讨了基础模型在异常检测中的应用。贡献包括提出一个框架，将基础模型用于多领域异常检测，并分析挑战如泛化和鲁棒性。发现强调了这些模型在工业和医疗中的潜力，但需解决数据噪声问题。\n\n4. **Can ChatGPT Diagnose Alzheimer's Disease?**  \n   Quoc-Toan Nguyen 等研究 ChatGPT 在阿尔茨海默病诊断中的表现。贡献是使用 9300 条电子健康记录评估其性能，发现它在 MRI 和认知测试分析中表现出色，但准确性仍有局限，提示了 LLM 在医疗中的潜在应用和风险。\n\n5. **Graph Neural Networks at a Fraction**  \n   Rucha Bhalchandra Joshi 等作者优化了图神经网络。贡献在于提出四元数图神经网络（QMPNN），减少了参数量，同时保持性能。发现显示它在节点分类和链接预测任务中高效，Jure Leskovec 等学者的相关工作进一步强化了图学习的可扩展性。\n\n接下来，我们快速聊聊相关或次要论文，把它们归类讨论，避免冗长。\n\n**LLM 和 AI 优化相关（快速掠过）**  \n- **Hallucination Detection: A Probabilistic Framework Using Embeddings Distance Analysis**：Emanuele Ricco 等提出基于嵌入距离的幻觉检测框架。贡献是量化 LLM 的幻觉问题，发现模型在歧义样本上过度自信。  \n- **Confidence Improves Self-Consistency in LLMs**：Amir Taubenfeld 等发现置信度提升能优化 LLM 的自一致性。贡献在于改进解码策略，发现它在推理任务中减少错误。其他如 \"Is LLM an Overconfident Judge?\" 等论文类似，强调 LLM 评估的可靠性，但不那么突破性。\n\n**医疗和生物应用（简要提及）**  \n- **Foundation Model of Electronic Records for Adaptive Risk Estimation**：Pawel Renc 等开发 ETHOS 模型，用于电子健康记录的风险预测。贡献是动态风险评估，发现它在 ICU 预测中优于传统方法。  \n- **Towards Efficient and Intelligent Laser Weeding: Method and Dataset for Weed Stem Detection**：Dingning Liu 等提出激光除草模型。贡献是构建数据集和检测框架，发现它提高了农业效率，但主题较窄。\n\n**图神经网络和机器学习（相关论文合并）**  \n- **Neighborhood-Order Learning Graph Attention Network for Fake News Detection**：Batool Lakzaei 等改进图注意力网络。贡献在于动态学习邻居顺序，发现它在假新闻检测中更鲁棒。  \n- **Rateless Joint Source-Channel Coding, and a Blueprint for 6G Semantic Communications System Design**：Saeed R. Khosravirad 提出无速率联合源-信道编码。贡献是设计 6G 系统蓝图，发现它提升了语义通信效率。其他如 \"Powerformer\" 等论文优化了时序预测，但影响较小。\n\n其他论文如 \"TimeKAN\"（时序预测模型）和 \"CSR-Bench\"（LLM 代理基准）等，虽然有技术贡献，但主题较具体或不那么引人注目，就不展开了。总之，今天的论文突出了 AI 在实际应用中的潜力，但也暴露了模型泛化和鲁棒性的挑战。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2502.07132v2",
      "title": "Interactive Data Harmonization with LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Aécio Santos",
        "Eduardo H. M. Pena",
        "Roque Lopez",
        "Juliana Freire"
      ],
      "abstract": "Data harmonization is an essential task that entails integrating datasets\nfrom diverse sources. Despite years of research in this area, it remains a\ntime-consuming and challenging task due to schema mismatches, varying\nterminologies, and differences in data collection methodologies. This paper\npresents the case for agentic data harmonization as a means to both empower\nexperts to harmonize their data and to streamline the process. We introduce\nHarmonia, a system that combines LLM-based reasoning, an interactive user\ninterface, and a library of data harmonization primitives to automate the\nsynthesis of data harmonization pipelines. We demonstrate Harmonia in a\nclinical data harmonization scenario, where it helps to interactively create\nreusable pipelines that map datasets to a standard format. Finally, we discuss\nchallenges and open problems, and suggest research directions for advancing our\nvision.",
      "tldr_zh": "该研究探讨了数据协调（data harmonization）的挑战，包括模式不匹配（schema mismatches）、术语差异和数据收集方法多样性等问题，并提出使用LLM Agents进行交互式数据协调。论文引入Harmonia系统，该系统结合LLM-based reasoning、交互式用户界面和数据协调原语库（data harmonization primitives），以自动化合成数据协调管道，并在临床数据场景中演示其帮助创建可重用管道，将数据集映射到标准格式。最后，讨论了相关挑战、开放问题和未来研究方向，以推进这一愿景。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07132v2",
      "published_date": "2025-02-10 23:50:09 UTC",
      "updated_date": "2025-03-05 18:33:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:16:27.180672"
    },
    {
      "arxiv_id": "2502.07130v1",
      "title": "Unconstrained Body Recognition at Altitude and Range: Comparing Four Approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Blake A Myers",
        "Matthew Q Hill",
        "Veda Nandan Gandi",
        "Thomas M Metz",
        "Alice J O'Toole"
      ],
      "abstract": "This study presents an investigation of four distinct approaches to long-term\nperson identification using body shape. Unlike short-term re-identification\nsystems that rely on temporary features (e.g., clothing), we focus on learning\npersistent body shape characteristics that remain stable over time. We\nintroduce a body identification model based on a Vision Transformer (ViT) (Body\nIdentification from Diverse Datasets, BIDDS) and on a Swin-ViT model\n(Swin-BIDDS). We also expand on previous approaches based on the Linguistic and\nNon-linguistic Core ResNet Identity Models (LCRIM and NLCRIM), but with\nimproved training. All models are trained on a large and diverse dataset of\nover 1.9 million images of approximately 5k identities across 9 databases.\nPerformance was evaluated on standard re-identification benchmark datasets\n(MARS, MSMT17, Outdoor Gait, DeepChange) and on an unconstrained dataset that\nincludes images at a distance (from close-range to 1000m), at altitude (from an\nunmanned aerial vehicle, UAV), and with clothing change. A comparative analysis\nacross these models provides insights into how different backbone architectures\nand input image sizes impact long-term body identification performance across\nreal-world conditions.",
      "tldr_zh": "本研究比较了四种方法，用于长期基于体型的不受约束体型识别（Unconstrained Body Recognition），重点关注持久的体形特征而非临时特征如服装。论文引入了基于 Vision Transformer (ViT) 的 Body Identification from Diverse Datasets (BIDDS) 模型和基于 Swin-ViT 的 Swin-BIDDS 模型，并对 Linguistic and Non-linguistic Core ResNet Identity Models (LCRIM 和 NLCRIM) 进行了改进训练，所有模型均在包含超过190万张图像和约5000个身份的多样化数据集上训练。性能评估包括标准基准数据集（如 MARS、MSMT17、Outdoor Gait、DeepChange）以及一个不受约束数据集，涵盖远距离（至1000m）、高空（从 Unmanned Aerial Vehicle, UAV 拍摄）和服装变化场景。通过比较不同骨干架构和输入图像大小，该研究提供了对真实条件下长期体型识别性能的宝贵洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07130v1",
      "published_date": "2025-02-10 23:49:06 UTC",
      "updated_date": "2025-02-10 23:49:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:16:42.451529"
    },
    {
      "arxiv_id": "2502.07128v1",
      "title": "Cardiverse: Harnessing LLMs for Novel Card Game Prototyping",
      "title_zh": "翻译失败",
      "authors": [
        "Danrui Li",
        "Sen Zhang",
        "Sam S. Sohn",
        "Kaidong Hu",
        "Muhammad Usman",
        "Mubbasir Kapadia"
      ],
      "abstract": "The prototyping of computer games, particularly card games, requires\nextensive human effort in creative ideation and gameplay evaluation. Recent\nadvances in Large Language Models (LLMs) offer opportunities to automate and\nstreamline these processes. However, it remains challenging for LLMs to design\nnovel game mechanics beyond existing databases, generate consistent gameplay\nenvironments, and develop scalable gameplay AI for large-scale evaluations.\nThis paper addresses these challenges by introducing a comprehensive automated\ncard game prototyping framework. The approach highlights a graph-based indexing\nmethod for generating novel game designs, an LLM-driven system for consistent\ngame code generation validated by gameplay records, and a gameplay AI\nconstructing method that uses an ensemble of LLM-generated action-value\nfunctions optimized through self-play. These contributions aim to accelerate\ncard game prototyping, reduce human labor, and lower barriers to entry for game\ndevelopers.",
      "tldr_zh": "该研究提出Cardiverse框架，利用Large Language Models (LLMs)来自动化纸牌游戏的原型设计，解决LLMs在生成创新游戏机制、一致游戏环境和可扩展游戏AI方面的挑战。框架包括基于图的索引方法(graph-based indexing)来创建新颖游戏设计、LLM驱动的系统生成并通过游戏记录验证一致的游戏代码，以及使用LLM生成的行动价值函数集合通过自对弈(self-play)优化来构建游戏AI。这些贡献旨在加速纸牌游戏原型开发，减少人力投入，并降低游戏开发者的进入门槛。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.07128v1",
      "published_date": "2025-02-10 23:47:35 UTC",
      "updated_date": "2025-02-10 23:47:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:16:51.479942"
    },
    {
      "arxiv_id": "2502.15754v1",
      "title": "Text2Net: Transforming Plain-text To A Dynamic Interactive Network Simulation Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Marefat",
        "Abbaas Alif Mohamed Nishar",
        "Ashwin Ashok"
      ],
      "abstract": "This paper introduces Text2Net, an innovative text-based network simulation\nengine that leverages natural language processing (NLP) and large language\nmodels (LLMs) to transform plain-text descriptions of network topologies into\ndynamic, interactive simulations. Text2Net simplifies the process of\nconfiguring network simulations, eliminating the need for users to master\nvendor-specific syntaxes or navigate complex graphical interfaces. Through\nqualitative and quantitative evaluations, we demonstrate Text2Net's ability to\nsignificantly reduce the time and effort required to deploy network scenarios\ncompared to traditional simulators like EVE-NG. By automating repetitive tasks\nand enabling intuitive interaction, Text2Net enhances accessibility for\nstudents, educators, and professionals. The system facilitates hands-on\nlearning experiences for students that bridge the gap between theoretical\nknowledge and practical application. The results showcase its scalability\nacross various network complexities, marking a significant step toward\nrevolutionizing network education and professional use cases, such as\nproof-of-concept testing.",
      "tldr_zh": "这篇论文介绍了 Text2Net，一种创新的文本网络模拟引擎，利用 NLP 和 LLMs 将纯文本描述的网络拓扑转化为动态交互式模拟环境，从而简化配置过程并避免使用供应商特定语法或复杂图形界面。Text2Net 通过自动化重复任务，提升了学生、教育者和专业人士的可访问性，并桥接了理论知识与实际应用的差距。定性和定量评估显示，与传统模拟器如 EVE-NG 相比，它显著减少了部署时间和努力，并证明了其在各种网络复杂性上的可扩展性，为网络教育和专业测试带来革命性变革。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "7 pages, 9 figures, Accepted at IEEE SoutheastCon 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.15754v1",
      "published_date": "2025-02-10 23:45:57 UTC",
      "updated_date": "2025-02-10 23:45:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:17:03.750613"
    },
    {
      "arxiv_id": "2502.07115v4",
      "title": "Online Scheduling for LLM Inference with KV Cache Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Jaillet",
        "Jiashuo Jiang",
        "Konstantina Mellou",
        "Marco Molinaro",
        "Chara Podimata",
        "Zijie Zhou"
      ],
      "abstract": "Large Language Model (LLM) inference, where a trained model generates text\none word at a time in response to user prompts, is a computationally intensive\nprocess requiring efficient scheduling to optimize latency and resource\nutilization. A key challenge in LLM inference is the management of the\nKey-Value (KV) cache, which reduces redundant computations but introduces\nmemory constraints. In this work, we model LLM inference with KV cache\nconstraints theoretically and propose a novel batching and scheduling algorithm\nthat minimizes inference latency while effectively managing the KV cache's\nmemory.\n  More specifically, we make the following contributions. First, to evaluate\nthe performance of online algorithms for scheduling in LLM inference, we\nintroduce a hindsight optimal benchmark, formulated as an integer program that\ncomputes the minimum total inference latency under full future information.\nSecond, we prove that no deterministic online algorithm can achieve a constant\ncompetitive ratio when the arrival process is arbitrary. Third, motivated by\nthe computational intractability of solving the integer program at scale, we\npropose a polynomial-time online scheduling algorithm and show that under\ncertain conditions it can achieve a constant competitive ratio. We also\ndemonstrate our algorithm's strong empirical performance by comparing it to the\nhindsight optimal in a synthetic dataset. Finally, we conduct empirical\nevaluations on a real-world public LLM inference dataset, simulating the\nLlama2-70B model on A100 GPUs, and show that our algorithm significantly\noutperforms the benchmark algorithms. Overall, our results offer a path toward\nmore sustainable and cost-effective LLM deployment.",
      "tldr_zh": "这篇论文针对大型语言模型(LLM)推理过程中的调度问题，特别关注Key-Value (KV)缓存的内存约束，提出了一种优化延迟和资源利用的在线批量处理算法。该算法通过理论建模LLM推理，并引入一个后见最优基准（整数规划问题）来评估性能，同时证明了在任意到达过程中，没有确定性在线算法能达到常数竞争比。论文的主要贡献包括提出一个多项式时间在线调度算法，在特定条件下实现常数竞争比，并在合成和真实数据集（如Llama2-70B模型在A100 GPU上的模拟）中实证验证，该算法显著优于基准，提升了LLM部署的可持续性和成本效益。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07115v4",
      "published_date": "2025-02-10 23:11:44 UTC",
      "updated_date": "2025-05-20 16:29:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:17:15.501287"
    },
    {
      "arxiv_id": "2502.07090v2",
      "title": "Generative Distribution Prediction: A Unified Approach to Multimodal Learning",
      "title_zh": "生成式分布预测：一种多模态学习统一方法",
      "authors": [
        "Xinyu Tian",
        "Xiaotong Shen"
      ],
      "abstract": "Accurate prediction with multimodal data-encompassing tabular, textual, and\nvisual inputs or outputs-is fundamental to advancing analytics in diverse\napplication domains. Traditional approaches often struggle to integrate\nheterogeneous data types while maintaining high predictive accuracy. We\nintroduce Generative Distribution Prediction (GDP), a novel framework that\nleverages multimodal synthetic data generation-such as conditional diffusion\nmodels-to enhance predictive performance across structured and unstructured\nmodalities. GDP is model-agnostic, compatible with any high-fidelity generative\nmodel, and supports transfer learning for domain adaptation. We establish a\nrigorous theoretical foundation for GDP, providing statistical guarantees on\nits predictive accuracy when using diffusion models as the generative backbone.\nBy estimating the data-generating distribution and adapting to various loss\nfunctions for risk minimization, GDP enables accurate point predictions across\nmultimodal settings. We empirically validate GDP on four supervised learning\ntasks-tabular data prediction, question answering, image captioning, and\nadaptive quantile regression-demonstrating its versatility and effectiveness\nacross diverse domains.",
      "tldr_zh": "本研究提出Generative Distribution Prediction (GDP)，一种统一的框架，用于处理多模态数据（如表格、文本和视觉输入/输出），以提升预测准确性。GDP 通过利用条件扩散模型等生成技术创建合成数据，增强对异构模态的整合，并支持模型无关性、迁移学习和领域适应。论文建立了GDP的理论基础，提供使用扩散模型时的统计保证，并通过估计数据生成分布和适应各种损失函数实现风险最小化。在四个监督学习任务（表格数据预测、问答、图像字幕和自适应分位数回归）上进行的实证验证，证明了GDP的通用性和有效性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "31 pages 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07090v2",
      "published_date": "2025-02-10 22:30:35 UTC",
      "updated_date": "2025-03-09 17:40:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:17:27.623725"
    },
    {
      "arxiv_id": "2502.07072v3",
      "title": "IRepair: An Intent-Aware Approach to Repair Data-Driven Errors in Large Language Models",
      "title_zh": "IRepair：一种意图感知方法，用于修复大语言模型中的数据驱动错误",
      "authors": [
        "Sayem Mohammad Imtiaz",
        "Astha Singh",
        "Fraol Batole",
        "Hridesh Rajan"
      ],
      "abstract": "Not a day goes by without hearing about the impressive feats of large\nlanguage models (LLMs), and equally, not a day passes without hearing about\ntheir challenges. LLMs are notoriously vulnerable to biases in their dataset,\nleading to issues such as toxicity. While domain-adaptive training has been\nemployed to mitigate these issues, these techniques often address all model\nparameters indiscriminately during the repair process, resulting in poor repair\nquality and reduced model versatility. In this paper, we introduce a novel\ndynamic slicing-based intent-aware LLM repair strategy, IRepair. This approach\nselectively targets the most error-prone sections of the model for repair.\nSpecifically, we propose dynamically slicing the model's most sensitive layers\nthat require immediate attention, concentrating repair efforts on those areas.\nThis method enables more effective repairs with potentially less impact on the\nmodel's overall performance by altering a smaller portion of the model. We\nevaluated our technique on three models from the GPT2 and GPT-Neo families,\nwith parameters ranging from 800M to 1.6B, in a toxicity mitigation setup. Our\nresults show that IRepair repairs errors 43.6% more effectively while causing\n46% less disruption to general performance compared to the closest baseline,\ndirect preference optimization. Our empirical analysis also reveals that errors\nare more concentrated in a smaller section of the model, with the top 20% of\nlayers exhibiting 773% more error density than the remaining 80\\%. This\nhighlights the need for selective repair. Additionally, we demonstrate that a\ndynamic selection approach is essential for addressing errors dispersed\nthroughout the model, ensuring a robust and efficient repair.",
      "tldr_zh": "本论文提出 IRepair，一种意图感知(intent-aware)的方法，用于修复大型语言模型(LLMs)中的数据驱动错误，如数据集偏见导致的毒性问题。IRepair 通过动态切片(dynamic slicing)技术，选择性地针对模型中最敏感层进行修复，从而减少对整体性能的干扰。实验在 GPT2 和 GPT-Neo 系列模型（参数从 800M 到 1.6B）上评估，结果显示 IRepair 比直接偏好优化(direct preference optimization)基准提高了 43.6% 的修复效果，同时降低了 46% 的性能干扰。研究还发现，模型错误主要集中在前 20% 的层中，错误密度比剩余层高 773%，突显了选择性修复的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as full research paper at FSE'2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07072v3",
      "published_date": "2025-02-10 22:07:02 UTC",
      "updated_date": "2025-03-11 17:08:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:17:40.729917"
    },
    {
      "arxiv_id": "2502.07064v1",
      "title": "Contextual Thompson Sampling via Generation of Missing Data",
      "title_zh": "翻译失败",
      "authors": [
        "Kelly W. Zhang",
        "Tiffany Tianhui Cai",
        "Hongseok Namkoong",
        "Daniel Russo"
      ],
      "abstract": "We introduce a framework for Thompson sampling contextual bandit algorithms,\nin which the algorithm's ability to quantify uncertainty and make decisions\ndepends on the quality of a generative model that is learned offline. Instead\nof viewing uncertainty in the environment as arising from unobservable latent\nparameters, our algorithm treats uncertainty as stemming from missing, but\npotentially observable, future outcomes. If these future outcomes were all\nobserved, one could simply make decisions using an \"oracle\" policy fit on the\ncomplete dataset. Inspired by this conceptualization, at each decision-time,\nour algorithm uses a generative model to probabilistically impute missing\nfuture outcomes, fits a policy using the imputed complete dataset, and uses\nthat policy to select the next action. We formally show that this algorithm is\na generative formulation of Thompson Sampling and prove a state-of-the-art\nregret bound for it. Notably, our regret bound i) depends on the probabilistic\ngenerative model only through the quality of its offline prediction loss, and\nii) applies to any method of fitting the \"oracle\" policy, which easily allows\none to adapt Thompson sampling to decision-making settings with fairness and/or\nresource constraints.",
      "tldr_zh": "该研究提出了一种基于生成缺失数据的框架，用于上下文Thompson Sampling bandit算法，通过离线学习的生成模型来量化不确定性，并将不确定性视为缺失的未来结果而非潜参数。算法在决策时，使用生成模型推断缺失数据，基于推断后的完整数据集拟合一个“oracle”策略，并据此选择行动。该方法被证明是一种Thompson Sampling的生成形式，具有最先进的regret bound，且仅依赖生成模型的离线预测损失质量，同时支持适应公平性和资源约束的决策场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07064v1",
      "published_date": "2025-02-10 21:57:00 UTC",
      "updated_date": "2025-02-10 21:57:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:17:51.247221"
    },
    {
      "arxiv_id": "2502.07059v1",
      "title": "Federated Continual Learning: Concepts, Challenges, and Solutions",
      "title_zh": "联邦持续学习：概念、挑战和解决方案",
      "authors": [
        "Parisa Hamedi",
        "Roozbeh Razavi-Far",
        "Ehsan Hallaji"
      ],
      "abstract": "Federated Continual Learning (FCL) has emerged as a robust solution for\ncollaborative model training in dynamic environments, where data samples are\ncontinuously generated and distributed across multiple devices. This survey\nprovides a comprehensive review of FCL, focusing on key challenges such as\nheterogeneity, model stability, communication overhead, and privacy\npreservation. We explore various forms of heterogeneity and their impact on\nmodel performance. Solutions to non-IID data, resource-constrained platforms,\nand personalized learning are reviewed in an effort to show the complexities of\nhandling heterogeneous data distributions. Next, we review techniques for\nensuring model stability and avoiding catastrophic forgetting, which are\ncritical in non-stationary environments. Privacy-preserving techniques are\nanother aspect of FCL that have been reviewed in this work. This survey has\nintegrated insights from federated learning and continual learning to present\nstrategies for improving the efficacy and scalability of FCL systems, making it\napplicable to a wide range of real-world scenarios.",
      "tldr_zh": "这篇论文对 Federated Continual Learning (FCL) 进行了全面调查，探讨了其在动态环境中进行分布式模型训练的核心概念和挑战，包括数据异质性、模型稳定性、通信开销以及隐私保护。论文分析了各种异质性的影响，并审查了针对 non-IID 数据、资源受限平台和个性化学习的解决方案，以缓解这些问题。最终，它整合了 federated learning 和 continual learning 的见解，提出策略来提升 FCL 系统的效力和可扩展性，使其适用于多种真实场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07059v1",
      "published_date": "2025-02-10 21:51:02 UTC",
      "updated_date": "2025-02-10 21:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:18:04.055867"
    },
    {
      "arxiv_id": "2502.07056v1",
      "title": "Autonomous Deep Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Amy Yu",
        "Erik Lebedev",
        "Lincoln Everett",
        "Xiaoxin Chen",
        "Terry Chen"
      ],
      "abstract": "This technical brief introduces Deep Agent, an advanced autonomous AI system\ndesigned to manage complex multi-phase tasks through a novel hierarchical task\nmanagement architecture. The system's foundation is built on our Hierarchical\nTask DAG (HTDAG) framework, which dynamically decomposes high-level objectives\ninto manageable sub-tasks while rigorously maintaining dependencies and\nexecution coherence. Deep Agent advances beyond traditional agent systems\nthrough three key innovations: First, it implements a recursive two-stage\nplanner-executor architecture that enables continuous task refinement and\nadaptation as circumstances change. Second, it features an Autonomous API &\nTool Creation (AATC) system that automatically generates reusable components\nfrom UI interactions, substantially reducing operational costs for similar\ntasks. Third, it incorporates Prompt Tweaking Engine and Autonomous Prompt\nFeedback Learning components that optimize Large Language Model prompts for\nspecific scenarios, enhancing both inference accuracy and operational\nstability. These components are integrated to form a service infrastructure\nthat manages user contexts, handles complex task dependencies, and orchestrates\nend-to-end agentic workflow execution. Through this sophisticated architecture,\nDeep Agent establishes a novel paradigm in self-governing AI systems,\ndemonstrating robust capability to independently handle intricate, multi-step\ntasks while maintaining consistent efficiency and reliability through\ncontinuous self-optimization.",
      "tldr_zh": "该研究介绍了 Autonomous Deep Agent，一种先进的自主 AI 系统，通过 Hierarchical Task DAG (HTDAG) 框架动态分解高水平目标为可管理子任务，并严格维护依赖性和执行一致性。系统包含三个关键创新：递归的两阶段规划-执行器架构，支持任务的持续细化和适应；Autonomous API & Tool Creation (AATC) 系统，从 UI 交互自动生成可重用组件，降低操作成本；以及 Prompt Tweaking Engine 和 Autonomous Prompt Feedback Learning 组件，优化大语言模型提示以提升推理准确性和稳定性。这些组件整合成服务基础设施，使 Deep Agent 能够独立处理复杂多步任务，并通过持续自优化实现高效可靠的端到端工作流执行。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.6; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07056v1",
      "published_date": "2025-02-10 21:46:54 UTC",
      "updated_date": "2025-02-10 21:46:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:18:17.263522"
    },
    {
      "arxiv_id": "2502.07049v2",
      "title": "LLMs in Software Security: A Survey of Vulnerability Detection Techniques and Insights",
      "title_zh": "翻译失败",
      "authors": [
        "Ze Sheng",
        "Zhicheng Chen",
        "Shuning Gu",
        "Heqing Huang",
        "Guofei Gu",
        "Jeff Huang"
      ],
      "abstract": "Large Language Models (LLMs) are emerging as transformative tools for\nsoftware vulnerability detection, addressing critical challenges in the\nsecurity domain. Traditional methods, such as static and dynamic analysis,\noften falter due to inefficiencies, high false positive rates, and the growing\ncomplexity of modern software systems. By leveraging their ability to analyze\ncode structures, identify patterns, and generate repair suggestions, LLMs,\nexemplified by models like GPT, BERT, and CodeBERT, present a novel and\nscalable approach to mitigating vulnerabilities. This paper provides a detailed\nsurvey of LLMs in vulnerability detection. It examines key aspects, including\nmodel architectures, application methods, target languages, fine-tuning\nstrategies, datasets, and evaluation metrics. We also analyze the scope of\ncurrent research problems, highlighting the strengths and weaknesses of\nexisting approaches. Further, we address challenges such as cross-language\nvulnerability detection, multimodal data integration, and repository-level\nanalysis. Based on these findings, we propose solutions for issues like dataset\nscalability, model interpretability, and applications in low-resource\nscenarios. Our contributions are threefold: (1) a systematic review of how LLMs\nare applied in vulnerability detection; (2) an analysis of shared patterns and\ndifferences across studies, with a unified framework for understanding the\nfield; and (3) a summary of key challenges and future research directions. This\nwork provides valuable insights for advancing LLM-based vulnerability\ndetection. We also maintain and regularly update latest selected paper on\nhttps://github.com/OwenSanzas/LLM-For-Vulnerability-Detection",
      "tldr_zh": "这篇论文对大型语言模型 (LLMs) 在软件安全领域的漏洞检测技术进行了全面调查，强调了 LLMs 如 GPT、BERT 和 CodeBERT 在分析代码结构、识别模式和生成修复建议方面的优势，相比传统静态和动态分析方法更具可扩展性。调查涵盖了模型架构、应用方法、目标语言、微调策略、数据集和评估指标，并分析了现有研究的优势（如高效性）和劣势（如高假阳性率）。论文的主要贡献包括系统回顾 LLMs 的应用、提供一个统一框架分析研究模式，以及提出解决方案应对挑战，如跨语言检测、多模态数据整合和数据集可扩展性，同时指出了未来研究方向。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "33 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.07049v2",
      "published_date": "2025-02-10 21:33:38 UTC",
      "updated_date": "2025-02-12 23:19:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:18:30.440115"
    },
    {
      "arxiv_id": "2502.07046v2",
      "title": "SnipGen: A Mining Repository Framework for Evaluating LLMs for Code",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Rodriguez-Cardenas",
        "Alejandro Velasco",
        "Denys Poshyvanyk"
      ],
      "abstract": "Language Models (LLMs), such as transformer-based neural networks trained on\nbillions of parameters, have become increasingly prevalent in software\nengineering (SE). These models, trained on extensive datasets that include code\nrepositories, exhibit remarkable capabilities for SE tasks. However, evaluating\ntheir effectiveness poses significant challenges, primarily due to the\npotential overlap between the datasets used for training and those employed for\nevaluation. To address this issue, we introduce SnipGen, a comprehensive\nrepository mining framework designed to leverage prompt engineering across\nvarious downstream tasks for code generation. SnipGen aims to mitigate data\ncontamination by generating robust testbeds and crafting tailored data points\nto assist researchers and practitioners in evaluating LLMs for code-related\ntasks. In our exploratory study, SnipGen mined approximately 227K data points\nfrom 338K recent code changes in GitHub commits, focusing on method-level\ngranularity. SnipGen features a collection of prompt templates that can be\ncombined to create a Chain-of-Thought-like sequence of prompts, enabling a\nnuanced assessment of LLMs' code generation quality. By providing the mining\ntool, the methodology, and the dataset, SnipGen empowers researchers and\npractitioners to rigorously evaluate and interpret LLMs' performance in\nsoftware engineering contexts.",
      "tldr_zh": "该研究引入了SnipGen，一种代码仓库挖掘框架，用于评估LLMs（Language Models）在代码生成任务中的性能，以解决训练数据和评估数据重叠导致的数据污染问题。SnipGen通过提示工程（prompt engineering）从GitHub的338K代码变化中挖掘约227K数据点，聚焦方法级粒度，并提供可组合的提示模板，形成类似Chain-of-Thought的序列，以进行细致评估。实验结果显示，该框架为研究者和从业者提供了鲁棒的测试集和工具，帮助他们在软件工程上下文中更准确地解释LLMs的表现。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "5 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.07046v2",
      "published_date": "2025-02-10 21:28:15 UTC",
      "updated_date": "2025-02-16 18:39:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:18:40.128919"
    },
    {
      "arxiv_id": "2502.07045v2",
      "title": "Scalable and Ethical Insider Threat Detection through Data Synthesis and Analysis by LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Haywood Gelman",
        "John D. Hastings"
      ],
      "abstract": "Insider threats wield an outsized influence on organizations,\ndisproportionate to their small numbers. This is due to the internal access\ninsiders have to systems, information, and infrastructure. %One example of this\ninfluence is where anonymous respondents submit web-based job search site\nreviews, an insider threat risk to organizations. Signals for such risks may be\nfound in anonymous submissions to public web-based job search site reviews.\nThis research studies the potential for large language models (LLMs) to analyze\nand detect insider threat sentiment within job site reviews. Addressing ethical\ndata collection concerns, this research utilizes synthetic data generation\nusing LLMs alongside existing job review datasets. A comparative analysis of\nsentiment scores generated by LLMs is benchmarked against expert human scoring.\nFindings reveal that LLMs demonstrate alignment with human evaluations in most\ncases, thus effectively identifying nuanced indicators of threat sentiment. The\nperformance is lower on human-generated data than synthetic data, suggesting\nareas for improvement in evaluating real-world data. Text diversity analysis\nfound differences between human-generated and LLM-generated datasets, with\nsynthetic data exhibiting somewhat lower diversity. Overall, the results\ndemonstrate the applicability of LLMs to insider threat detection, and a\nscalable solution for insider sentiment testing by overcoming ethical and\nlogistical barriers tied to data acquisition.",
      "tldr_zh": "该研究探讨了使用大型语言模型（LLMs）分析和检测内部威胁（insider threat）情绪，特别是从公开工作搜索网站评论中识别潜在风险。为了解决伦理数据收集问题，研究采用LLMs生成合成数据（synthetic data）并与现有数据集结合，进行LLMs情绪分数与专家人类评分的比较分析。结果显示，LLMs在大多数情况下与人类评估一致，能有效识别威胁情绪的细微指标，但其在人类生成数据上的表现不如合成数据，且合成数据显示出较低的文本多样性。总体而言，此方法提供了一种可扩展的解决方案，克服了数据获取的伦理和后勤障碍，为内部威胁检测开辟了新路径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "C.2.0; I.2.7; K.4.1; H.3.3"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, 0 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.07045v2",
      "published_date": "2025-02-10 21:27:06 UTC",
      "updated_date": "2025-04-07 16:01:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:18:52.590722"
    },
    {
      "arxiv_id": "2502.07036v2",
      "title": "Automated Consistency Analysis of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Patwardhan",
        "Vivek Vaidya",
        "Ashish Kundu"
      ],
      "abstract": "Generative AI (Gen AI) with large language models (LLMs) are being widely\nadopted across the industry, academia and government. Cybersecurity is one of\nthe key sectors where LLMs can be and/or are already being used. There are a\nnumber of problems that inhibit the adoption of trustworthy Gen AI and LLMs in\ncybersecurity and such other critical areas. One of the key challenge to the\ntrustworthiness and reliability of LLMs is: how consistent an LLM is in its\nresponses? In this paper, we have analyzed and developed a formal definition of\nconsistency of responses of LLMs. We have formally defined what is consistency\nof responses and then develop a framework for consistency evaluation. The paper\nproposes two approaches to validate consistency: self-validation, and\nvalidation across multiple LLMs. We have carried out extensive experiments for\nseveral LLMs such as GPT4oMini, GPT3.5, Gemini, Cohere, and Llama3, on a\nsecurity benchmark consisting of several cybersecurity questions: informational\nand situational. Our experiments corroborate the fact that even though these\nLLMs are being considered and/or already being used for several cybersecurity\ntasks today, they are often inconsistent in their responses, and thus are\nuntrustworthy and unreliable for cybersecurity.",
      "tldr_zh": "本研究分析了大语言模型（LLMs）在响应一致性方面的挑战，特别是其在 cybersecurity 领域的应用，强调了不一致性导致的不可信和不可靠问题。论文首先正式定义了 LLMs 响应的 consistency，并开发了一个评估框架，同时提出两种验证方法：self-validation 和跨多个 LLMs 的 validation。实验使用 GPT4oMini、GPT3.5、Gemini、Cohere 和 Llama3 等模型，在 cybersecurity 基准测试（如 informational 和 situational 问题）上进行测试，结果显示这些 LLMs 经常在响应中出现不一致，从而证明其在关键任务中不可信。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages, 12 figures, 3 tables, 3 algorithms, 2024 IEEE 6th\n  International Conference on Trust, Privacy and Security in Intelligent\n  Systems, and Applications (TPS-ISA), Washington, DC, USA",
      "pdf_url": "http://arxiv.org/pdf/2502.07036v2",
      "published_date": "2025-02-10 21:03:24 UTC",
      "updated_date": "2025-03-10 18:14:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:19:05.231839"
    },
    {
      "arxiv_id": "2502.07029v2",
      "title": "Leveraging Allophony in Self-Supervised Speech Models for Atypical Pronunciation Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Kwanghee Choi",
        "Eunjung Yeo",
        "Kalvin Chang",
        "Shinji Watanabe",
        "David Mortensen"
      ],
      "abstract": "Allophony refers to the variation in the phonetic realization of a phoneme\nbased on its phonetic environment. Modeling allophones is crucial for atypical\npronunciation assessment, which involves distinguishing atypical from typical\npronunciations. However, recent phoneme classifier-based approaches often\nsimplify this by treating various realizations as a single phoneme, bypassing\nthe complexity of modeling allophonic variation. Motivated by the acoustic\nmodeling capabilities of frozen self-supervised speech model (S3M) features, we\npropose MixGoP, a novel approach that leverages Gaussian mixture models to\nmodel phoneme distributions with multiple subclusters. Our experiments show\nthat MixGoP achieves state-of-the-art performance across four out of five\ndatasets, including dysarthric and non-native speech. Our analysis further\nsuggests that S3M features capture allophonic variation more effectively than\nMFCCs and Mel spectrograms, highlighting the benefits of integrating MixGoP\nwith S3M features.",
      "tldr_zh": "本文提出MixGoP方法，利用高斯混合模型(Gaussian mixture models)来建模音素的allophony变体，从而提升非典型发音评估的准确性，该方法基于自监督语音模型(S3M)特征处理典型和非典型发音的差异。实验结果显示，MixGoP在五个数据集中的四个上达到了最先进性能，包括dysarthric和non-native语音。分析进一步表明，S3M特征比MFCCs和Mel spectrograms更有效地捕捉allophony变体，突显了该方法的优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025. Codebase available at\n  https://github.com/juice500ml/acoustic-units-for-ood",
      "pdf_url": "http://arxiv.org/pdf/2502.07029v2",
      "published_date": "2025-02-10 20:46:42 UTC",
      "updated_date": "2025-03-24 03:38:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:19:18.170813"
    },
    {
      "arxiv_id": "2502.07026v2",
      "title": "Machine Learning for Everyone: Simplifying Healthcare Analytics with BigQuery ML",
      "title_zh": "机器学习人人可用：使用 BigQuery ML 简化医疗保健分析",
      "authors": [
        "Mohammad Amir Salari",
        "Bahareh Rahmani"
      ],
      "abstract": "Machine learning (ML) transforms healthcare by enabling predictive analytics,\npersonalized treatments, and improved patient outcomes. However, traditional ML\nworkflows often require specialized skills, infrastructure, and resources,\nlimiting accessibility for many healthcare professionals. This paper explores\nhow BigQuery ML Cloud service helps healthcare researchers and data analysts to\nbuild and deploy models using SQL, without need for advanced ML knowledge. Our\nresults demonstrate that the Boosted Tree model achieved the highest\nperformance among the three models making it highly effective for diabetes\nprediction. BigQuery ML directly integrates predictive analytics into their\nworkflows to inform decision-making and support patient care. We reveal this\ncapability through a case study on diabetes prediction using the Diabetes\nHealth Indicators Dataset. Our study underscores BigQuery ML's role in\ndemocratizing machine learning, enabling faster, scalable, and efficient\npredictive analytics that can directly enhance healthcare decision-making\nprocesses. This study aims to bridge the gap between advanced machine learning\nand practical healthcare analytics by providing detailed insights into BigQuery\nML's capabilities. By demonstrating its utility in a real-world case study, we\nhighlight its potential to simplify complex workflows and expand access to\npredictive tools for a broader audience of healthcare professionals.",
      "tldr_zh": "这篇论文探讨了如何利用 BigQuery ML 云服务简化医疗保健分析，使用 SQL 构建和部署 Machine Learning (ML) 模型，从而降低专业技能门槛，让医疗研究者和数据分析师更易上手。研究通过糖尿病预测案例（使用 Diabetes Health Indicators Dataset）证明，Boosted Tree 模型在三种模型中表现出最高性能，有效提升预测准确性。总体而言，该工作桥接了高级 ML 与实际医疗分析的差距，促进更快速、可扩展的预测工具，助力决策和患者护理的优化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Focus: Artificial Intelligence, Healthcare analytics, cloud\n  computing, BigQuery ML",
      "pdf_url": "http://arxiv.org/pdf/2502.07026v2",
      "published_date": "2025-02-10 20:38:53 UTC",
      "updated_date": "2025-02-21 21:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:19:29.006491"
    },
    {
      "arxiv_id": "2502.07022v1",
      "title": "AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements",
      "title_zh": "AIMS.au：一个用于分析公司声明中现代奴隶制对策的数据集",
      "authors": [
        "Adriana Eufrosina Bora",
        "Pierre-Luc St-Charles",
        "Mirko Bronzi",
        "Arsène Fansi Tchango",
        "Bruno Rousseau",
        "Kerrie Mengersen"
      ],
      "abstract": "Despite over a decade of legislative efforts to address modern slavery in the\nsupply chains of large corporations, the effectiveness of government oversight\nremains hampered by the challenge of scrutinizing thousands of statements\nannually. While Large Language Models (LLMs) can be considered a well\nestablished solution for the automatic analysis and summarization of documents,\nrecognizing concrete modern slavery countermeasures taken by companies and\ndifferentiating those from vague claims remains a challenging task. To help\nevaluate and fine-tune LLMs for the assessment of corporate statements, we\nintroduce a dataset composed of 5,731 modern slavery statements taken from the\nAustralian Modern Slavery Register and annotated at the sentence level. This\npaper details the construction steps for the dataset that include the careful\ndesign of annotation specifications, the selection and preprocessing of\nstatements, and the creation of high-quality annotation subsets for effective\nmodel evaluations. To demonstrate our dataset's utility, we propose a machine\nlearning methodology for the detection of sentences relevant to mandatory\nreporting requirements set by the Australian Modern Slavery Act. We then follow\nthis methodology to benchmark modern language models under zero-shot and\nsupervised learning settings.",
      "tldr_zh": "该研究引入了AIMS.au数据集，包含5,731个来自澳大利亚现代奴隶制注册的企业声明，按句子级别标注，旨在评估Large Language Models (LLMs)识别具体现代奴隶制对策的能力。该数据集的构建涉及精心设计标注规范、声明选择和预处理，以及创建高质量标注子集，以支持模型评估。研究提出了一种机器学习方法，用于检测与澳大利亚Modern Slavery Act强制报告要求相关的句子，并通过零样本和监督学习设置对现代语言模型进行基准测试，展示了数据集在提升LLMs分析准确性方面的实用价值。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Camera ready. ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.07022v1",
      "published_date": "2025-02-10 20:30:32 UTC",
      "updated_date": "2025-02-10 20:30:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:19:39.944835"
    },
    {
      "arxiv_id": "2502.07017v1",
      "title": "Finding Words Associated with DIF: Predicting Differential Item Functioning using LLMs and Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Hotaka Maeda",
        "Yikai Lu"
      ],
      "abstract": "We fine-tuned and compared several encoder-based Transformer large language\nmodels (LLM) to predict differential item functioning (DIF) from the item text.\nWe then applied explainable artificial intelligence (XAI) methods to these\nmodels to identify specific words associated with DIF. The data included 42,180\nitems designed for English language arts and mathematics summative state\nassessments among students in grades 3 to 11. Prediction $R^2$ ranged from .04\nto .32 among eight focal and reference group pairs. Our findings suggest that\nmany words associated with DIF reflect minor sub-domains included in the test\nblueprint by design, rather than construct-irrelevant item content that should\nbe removed from assessments. This may explain why qualitative reviews of DIF\nitems often yield confusing or inconclusive results. Our approach can be used\nto screen words associated with DIF during the item-writing process for\nimmediate revision, or help review traditional DIF analysis results by\nhighlighting key words in the text. Extensions of this research can enhance the\nfairness of assessment programs, especially those that lack resources to build\nhigh-quality items, and among smaller subpopulations where we do not have\nsufficient sample sizes for traditional DIF analyses.",
      "tldr_zh": "本文研究了使用微调的 Transformer 编码器 LLMs 来从项目文本预测 Differential Item Functioning (DIF)，并结合 Explainable AI (XAI) 方法识别与 DIF 相关的特定单词。基于 42,180 项针对 3 到 11 年级学生的英语和数学评估项目，预测 R² 范围从 0.04 到 0.32。研究发现，许多与 DIF 相关的单词反映了测试蓝图中的次要子领域，而非应移除的结构无关内容，这可能解释了传统 DIF 分析的定性审查往往混乱或不确定。最终，此方法可用于项目编写过程中的单词筛选或结果审查，以提升评估程序的公平性，尤其在资源有限或样本量小的子群体中。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 2 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.07017v1",
      "published_date": "2025-02-10 20:22:32 UTC",
      "updated_date": "2025-02-10 20:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:19:55.467287"
    },
    {
      "arxiv_id": "2502.07828v1",
      "title": "Some things to know about achieving artificial general intelligence",
      "title_zh": "关于实现人工通用智能的一些需知事项",
      "authors": [
        "Herbert Roitblat"
      ],
      "abstract": "Current and foreseeable GenAI models are not capable of achieving artificial\ngeneral intelligence because they are burdened with anthropogenic debt. They\ndepend heavily on human input to provide well-structured problems,\narchitecture, and training data. They cast every problem as a language pattern\nlearning problem and are thus not capable of the kind of autonomy needed to\nachieve artificial general intelligence. Current models succeed at their tasks\nbecause people solve most of the problems to which these models are directed,\nleaving only simple computations for the model to perform, such as gradient\ndescent. Another barrier is the need to recognize that there are multiple kinds\nof problems, some of which cannot be solved by available computational methods\n(for example, \"insight problems\"). Current methods for evaluating models\n(benchmarks and tests) are not adequate to identify the generality of the\nsolutions, because it is impossible to infer the means by which a problem was\nsolved from the fact of its solution. A test could be passed, for example, by a\ntest-specific or a test-general method. It is a logical fallacy (affirming the\nconsequent) to infer a method of solution from the observation of success.",
      "tldr_zh": "这篇论文讨论了当前GenAI模型无法实现artificial general intelligence (AGI)的主要原因，包括anthropogenic debt导致的过度依赖人类输入（如问题结构、架构和训练数据）。论文指出，GenAI将所有问题视为语言模式学习任务，缺乏所需的自治性，且仅处理简单计算，而复杂问题如“insight problems”无法用现有方法解决。另一个关键问题是，当前的评估方法（如基准测试）不足以判断解决方案的普遍性，因为从成功结果推断方法是一种逻辑谬误（affirming the consequent）。总之，论文强调了克服这些障碍的必要性，以推进AGI的发展。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07828v1",
      "published_date": "2025-02-10 20:10:26 UTC",
      "updated_date": "2025-02-10 20:10:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:20:05.758164"
    },
    {
      "arxiv_id": "2502.07827v2",
      "title": "Implicit Language Models are RNNs: Balancing Parallelization and Expressivity",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Schöne",
        "Babak Rahmani",
        "Heiner Kremer",
        "Fabian Falck",
        "Hitesh Ballani",
        "Jannes Gladrow"
      ],
      "abstract": "State-space models (SSMs) and transformers dominate the language modeling\nlandscape. However, they are constrained to a lower computational complexity\nthan classical recurrent neural networks (RNNs), limiting their expressivity.\nIn contrast, RNNs lack parallelization during training, raising fundamental\nquestions about the trade off between parallelization and expressivity. We\npropose implicit SSMs, which iterate a transformation until convergence to a\nfixed point. Theoretically, we show that implicit SSMs implement the non-linear\nstate-transitions of RNNs. Empirically, we find that only approximate\nfixed-point convergence suffices, enabling the design of a scalable training\ncurriculum that largely retains parallelization, with full convergence required\nonly for a small subset of tokens. Our approach demonstrates superior\nstate-tracking capabilities on regular languages, surpassing transformers and\nSSMs. We further scale implicit SSMs to natural language reasoning tasks and\npretraining of large-scale language models up to 1.3B parameters on 207B tokens\n- representing, to our knowledge, the largest implicit model trained to date.\nNotably, our implicit models outperform their explicit counterparts on standard\nbenchmarks.",
      "tldr_zh": "该论文探讨了状态空间模型(SSMs)和 transformers 在语言建模中的计算复杂度限制，以及与循环神经网络(RNNs)之间并行化和表达性的权衡问题。作者提出 implicit SSMs，通过迭代变换直到固定点收敛，理论上实现了 RNNs 的非线性状态转换，并设计了可扩展的训练课程，只需对少量 tokens 进行完全收敛，从而保留大部分并行化。实验结果表明，implicit SSMs 在正则语言的状态跟踪上优于 transformers 和 SSMs，并在自然语言推理任务及大规模预训练（达 1.3B 参数和 207B tokens）中表现出色，超越了 explicit 对应模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 12 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.07827v2",
      "published_date": "2025-02-10 19:59:31 UTC",
      "updated_date": "2025-02-14 10:17:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:20:17.698692"
    },
    {
      "arxiv_id": "2502.07001v2",
      "title": "From Image to Video: An Empirical Study of Diffusion Representations",
      "title_zh": "从图像到视频：扩散表示的实证研究",
      "authors": [
        "Pedro Vélez",
        "Luisa F. Polanía",
        "Yi Yang",
        "Chuhan Zhang",
        "Rishabh Kabra",
        "Anurag Arnab",
        "Mehdi S. M. Sajjadi"
      ],
      "abstract": "Diffusion models have revolutionized generative modeling, enabling\nunprecedented realism in image and video synthesis. This success has sparked\ninterest in leveraging their representations for visual understanding tasks.\nWhile recent works have explored this potential for image generation, the\nvisual understanding capabilities of video diffusion models remain largely\nuncharted. To address this gap, we systematically compare the same model\narchitecture trained for video versus image generation, analyzing the\nperformance of their latent representations on various downstream tasks\nincluding image classification, action recognition, depth estimation, and\ntracking. Results show that video diffusion models consistently outperform\ntheir image counterparts, though we find a striking range in the extent of this\nsuperiority. We further analyze features extracted from different layers and\nwith varying noise levels, as well as the effect of model size and training\nbudget on representation and generation quality. This work marks the first\ndirect comparison of video and image diffusion objectives for visual\nunderstanding, offering insights into the role of temporal information in\nrepresentation learning.",
      "tldr_zh": "本文通过实证研究比较了图像和视频diffusion models在视觉理解任务中的表示能力，重点分析相同模型架构在视频与图像生成训练下的表现差异。研究评估了这些模型在图像分类、动作识别、深度估计和跟踪等下游任务上的性能，结果显示视频diffusion models整体优于图像模型，但优势程度因任务而异。进一步探讨了特征提取层、噪声水平、模型大小和训练预算对表示和生成质量的影响，为理解时间信息在representation learning中的作用提供了新见解。这项工作首次直接比较了视频和图像diffusion目标在视觉理解中的效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07001v2",
      "published_date": "2025-02-10 19:53:46 UTC",
      "updated_date": "2025-03-19 21:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:20:29.371529"
    },
    {
      "arxiv_id": "2502.06994v1",
      "title": "SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Xuehang Guo",
        "Xingyao Wang",
        "Yangyi Chen",
        "Sha Li",
        "Chi Han",
        "Manling Li",
        "Heng Ji"
      ],
      "abstract": "Software engineering (SE) is increasingly collaborative, with developers\nworking together on shared complex codebases. Effective collaboration in shared\nenvironments requires participants -- whether humans or AI agents -- to stay on\nthe same page as their environment evolves. When a collaborator's understanding\ndiverges from the current state -- what we term the out-of-sync challenge --\nthe collaborator's actions may fail, leading to integration issues. In this\nwork, we introduce SyncMind, a framework that systematically defines the\nout-of-sync problem faced by large language model (LLM) agents in collaborative\nsoftware engineering (CSE). Based on SyncMind, we create SyncBench, a benchmark\nfeaturing 24,332 instances of agent out-of-sync scenarios in real-world CSE\nderived from 21 popular GitHub repositories with executable verification tests.\nExperiments on SyncBench uncover critical insights into existing LLM agents'\ncapabilities and limitations. Besides substantial performance gaps among agents\n(from Llama-3.1 agent <= 3.33% to Claude-3.5-Sonnet >= 28.18%), their\nconsistently low collaboration willingness (<= 4.86%) suggests fundamental\nlimitations of existing LLM in CSE. However, when collaboration occurs, it\npositively correlates with out-of-sync recovery success. Minimal performance\ndifferences in agents' resource-aware out-of-sync recoveries further reveal\ntheir significant lack of resource awareness and adaptability, shedding light\non future resource-efficient collaborative systems. Code and data are openly\navailable on our project website: https://xhguo7.github.io/SyncMind/.",
      "tldr_zh": "这篇论文引入了 SyncMind 框架，用于系统定义和衡量大型语言模型 (LLM) 代理在协作软件工程 (CSE) 中的 out-of-sync 问题，即代理理解与环境状态脱节导致的行动失败。基于 SyncMind，他们开发了 SyncBench 基准测试，涵盖 24,332 个真实场景实例，从 21 个热门 GitHub 仓库中提取，并附带可执行验证测试。实验结果显示，现有机型代理存在显著性能差距（例如 Llama-3.1 代理 ≤3.33%，Claude-3.5-Sonnet ≥28.18%）、协作意愿极低（≤4.86%），且在资源感知和适应性方面表现不足，但协作行为与 out-of-sync 恢复成功正相关，为构建高效 CSE 系统提供了关键洞见。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06994v1",
      "published_date": "2025-02-10 19:38:36 UTC",
      "updated_date": "2025-02-10 19:38:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:20:42.228910"
    },
    {
      "arxiv_id": "2502.06976v1",
      "title": "Who is Helping Whom? Analyzing Inter-dependencies to Evaluate Cooperation in Human-AI Teaming",
      "title_zh": "谁在帮助谁？ 分析相互依赖性以评估人类-AI 团队",
      "authors": [
        "Upasana Biswas",
        "Siddhant Bhambri",
        "Subbarao Kambhampati"
      ],
      "abstract": "The long-standing research challenges of Human-AI Teaming(HAT) and Zero-shot\nCooperation(ZSC) have been tackled by applying multi-agent reinforcement\nlearning(MARL) to train an agent by optimizing the environment reward function\nand evaluating their performance through task performance metrics such as task\nreward. However, such evaluation focuses only on task completion, while being\nagnostic to `how' the two agents work with each other. Specifically, we are\ninterested in understanding the cooperation arising within the team when\ntrained agents are paired with humans. To formally address this problem, we\npropose the concept of interdependence to measure how much agents rely on each\nother's actions to achieve the shared goal, as a key metric for evaluating\ncooperation in human-agent teams. Towards this, we ground this concept through\na symbolic formalism and define evaluation metrics that allow us to assess the\ndegree of reliance between the agents' actions. We pair state-of-the-art agents\ntrained through MARL for HAT, with learned human models for the the popular\nOvercooked domain, and evaluate the team performance for these human-agent\nteams. Our results demonstrate that trained agents are not able to induce\ncooperative behavior, reporting very low levels of interdependence across all\nthe teams. We also report that teaming performance of a team is not necessarily\ncorrelated with the task reward.",
      "tldr_zh": "这篇论文针对 Human-AI Teaming (HAT) 和 Zero-shot Cooperation (ZSC) 的研究挑战，提出使用“互依赖性”(interdependence)作为评估人类-代理团队合作的关键指标，以弥补传统 Multi-Agent Reinforcement Learning (MARL) 方法仅关注任务奖励的局限。\n作者通过符号形式主义定义互依赖性指标，量化代理之间行动的依赖程度，并在 Overcooked 领域中将 MARL 训练的代理与人类模型配对进行实验。\n结果显示，训练代理无法有效诱导合作行为，导致团队互依赖性水平很低，且团队绩效与任务奖励不一定相关。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06976v1",
      "published_date": "2025-02-10 19:16:20 UTC",
      "updated_date": "2025-02-10 19:16:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:20:53.459830"
    },
    {
      "arxiv_id": "2502.06975v1",
      "title": "Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Mathis Pink",
        "Qinyuan Wu",
        "Vy Ai Vo",
        "Javier Turek",
        "Jianing Mu",
        "Alexander Huth",
        "Mariya Toneva"
      ],
      "abstract": "As Large Language Models (LLMs) evolve from text-completion tools into fully\nfledged agents operating in dynamic environments, they must address the\nchallenge of continually learning and retaining long-term knowledge. Many\nbiological systems solve these challenges with episodic memory, which supports\nsingle-shot learning of instance-specific contexts. Inspired by this, we\npresent an episodic memory framework for LLM agents, centered around five key\nproperties of episodic memory that underlie adaptive and context-sensitive\nbehavior. With various research efforts already partially covering these\nproperties, this position paper argues that now is the right time for an\nexplicit, integrated focus on episodic memory to catalyze the development of\nlong-term agents. To this end, we outline a roadmap that unites several\nresearch directions under the goal to support all five properties of episodic\nmemory for more efficient long-term LLM agents.",
      "tldr_zh": "论文认为，episodic memory 是 LLM 代理实现长期知识保留和持续学习的缺失关键，因为它能支持单次学习和上下文敏感行为。作者提出一个以 episodic memory 的五个关键属性为核心的框架，旨在帮助 LLM 代理在动态环境中更有效地适应和学习。该框架整合了现有研究方向，并概述了一个路线图，以推动开发更高效的长期 LLM 代理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06975v1",
      "published_date": "2025-02-10 19:14:51 UTC",
      "updated_date": "2025-02-10 19:14:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:21:04.920311"
    },
    {
      "arxiv_id": "2502.06963v1",
      "title": "Task Offloading in Vehicular Edge Computing using Deep Reinforcement Learning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Ashab Uddin",
        "Ahmed Hamdi Sakr",
        "Ning Zhang"
      ],
      "abstract": "The increasing demand for Intelligent Transportation Systems (ITS) has\nintroduced significant challenges in managing the complex,\ncomputation-intensive tasks generated by modern vehicles while offloading tasks\nto external computing infrastructures such as edge computing (EC), nearby\nvehicular , and UAVs has become influential solution to these challenges.\nHowever, traditional computational offloading strategies often struggle to\nadapt to the dynamic and heterogeneous nature of vehicular environments. In\nthis study, we explored the potential of Reinforcement Learning (RL) and Deep\nReinforcement Learning (DRL) frameworks to optimize computational offloading\nthrough adaptive, real-time decision-making, and we have thoroughly\ninvestigated the Markov Decision Process (MDP) approaches on the existing\nliterature. The paper focuses on key aspects such as standardized learning\nmodels, optimized reward structures, and collaborative multi-agent systems,\naiming to advance the understanding and application of DRL in vehicular\nnetworks. Our findings offer insights into enhancing the efficiency,\nscalability, and robustness of ITS, setting the stage for future innovations in\nthis rapidly evolving field.",
      "tldr_zh": "本调查探讨了在车辆边缘计算中，使用 Deep Reinforcement Learning (DRL) 优化任务卸载的潜在应用，以应对智能交通系统 (ITS) 中复杂计算任务的挑战。论文分析了 Reinforcement Learning (RL) 和 DRL 的自适应实时决策机制，特别是 Markov Decision Process (MDP) 方法、标准化学习模型、优化奖励结构以及协作多智能体系统。研究发现，这些框架能显著提升 ITS 的效率、可扩展性和鲁棒性，为车辆网络的未来创新提供重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.MA",
        "Machine Learning, Reinforcement Learning, Multi Agent Reinforcement\n  Learning, Computational Offloading and Edge Computing"
      ],
      "primary_category": "cs.LG",
      "comment": "27 Pages, 3 Figures, 3 Tables",
      "pdf_url": "http://arxiv.org/pdf/2502.06963v1",
      "published_date": "2025-02-10 19:02:20 UTC",
      "updated_date": "2025-02-10 19:02:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:21:16.702995"
    },
    {
      "arxiv_id": "2502.06788v1",
      "title": "EVEv2: Improved Baselines for Encoder-Free Vision-Language Models",
      "title_zh": "EVEv2：改进的无编码器视觉语言模型基线",
      "authors": [
        "Haiwen Diao",
        "Xiaotong Li",
        "Yufeng Cui",
        "Yueze Wang",
        "Haoge Deng",
        "Ting Pan",
        "Wenxuan Wang",
        "Huchuan Lu",
        "Xinlong Wang"
      ],
      "abstract": "Existing encoder-free vision-language models (VLMs) are rapidly narrowing the\nperformance gap with their encoder-based counterparts, highlighting the\npromising potential for unified multimodal systems with structural simplicity\nand efficient deployment. We systematically clarify the performance gap between\nVLMs using pre-trained vision encoders, discrete tokenizers, and minimalist\nvisual layers from scratch, deeply excavating the under-examined\ncharacteristics of encoder-free VLMs. We develop efficient strategies for\nencoder-free VLMs that rival mainstream encoder-based ones. After an in-depth\ninvestigation, we launch EVEv2.0, a new and improved family of encoder-free\nVLMs. We show that: (i) Properly decomposing and hierarchically associating\nvision and language within a unified model reduces interference between\nmodalities. (ii) A well-designed training strategy enables effective\noptimization for encoder-free VLMs. Through extensive evaluation, our EVEv2.0\nrepresents a thorough study for developing a decoder-only architecture across\nmodalities, demonstrating superior data efficiency and strong vision-reasoning\ncapability. Code is publicly available at: https://github.com/baaivision/EVE.",
      "tldr_zh": "这篇论文介绍了 EVEv2.0，一种改进的无编码器 Vision-Language Models (VLMs)，通过系统分析性能差距，开发高效策略来缩小与有编码器模型的差距。作者强调了正确分解和层次化关联视觉与语言模态，以减少模态间的干扰，并采用精心设计的训练策略来优化模型。实验结果显示，EVEv2.0 展示了优越的数据效率和强大的视觉推理能力，为跨模态的解码器-only 架构提供了全面研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06788v1",
      "published_date": "2025-02-10 18:59:58 UTC",
      "updated_date": "2025-02-10 18:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:21:29.428638"
    },
    {
      "arxiv_id": "2502.06786v3",
      "title": "Matryoshka Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Nair",
        "Puranjay Datta",
        "Jeff Dean",
        "Prateek Jain",
        "Aditya Kusupati"
      ],
      "abstract": "Quantizing model weights is critical for reducing the communication and\ninference costs of large models. However, quantizing models -- especially to\nlow precisions like int4 or int2 -- requires a trade-off in model quality;\nint2, in particular, is known to severely degrade model quality. Consequently,\npractitioners are often forced to maintain multiple models with different\nquantization levels or serve a single model that best satisfies the\nquality-latency trade-off. On the other hand, integer data types, such as int8,\ninherently possess a nested (Matryoshka) structure where smaller bit-width\nintegers, like int4 or int2, are nested within the most significant bits.\nLeveraging this insight, in this paper, we propose Matryoshka Quantization\n(MatQuant), a novel multi-scale quantization technique that alleviates the\naforementioned challenge. This technique allows us to train and maintain a\nsingle quantized model but serve it with the precision demanded by the\ndeployment. Furthermore, leveraging MatQuant's co-training and co-distillation\nregularization, int2 precision models extracted by MatQuant outperform standard\nint2 quantization by up to to 4% and 7% with OmniQuant and QAT as base\nalgorithms respectively. Finally, we demonstrate that by using an extra bit to\nrepresent outliers, a model with an effective precision of 2.05-bit gives an\nadditional 6% improvement with OmniQuant as the base algorithm.",
      "tldr_zh": "这篇论文提出了 Matryoshka Quantization (MatQuant)，一种多尺度量化技术，旨在解决模型权重量化到低精度（如 int4 或 int2）时质量下降的问题，通过利用整数数据类型的嵌套结构（如 int8 包含 int4），实现训练和维护单一量化模型但根据部署需求提供不同精度。MatQuant 引入联合训练和联合蒸馏正则化，使其提取的 int2 模型比标准 int2 量化提高了 4% 和 7%（分别以 OmniQuant 和 QAT 为基线算法）。实验结果显示，使用额外位表示异常值，可将模型有效精度提升至 2.05-bit，并额外获得 6% 的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06786v3",
      "published_date": "2025-02-10 18:59:10 UTC",
      "updated_date": "2025-03-03 17:54:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:21:42.186938"
    },
    {
      "arxiv_id": "2502.06784v1",
      "title": "RelGNN: Composite Message Passing for Relational Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tianlang Chen",
        "Charilaos Kanatsoulis",
        "Jure Leskovec"
      ],
      "abstract": "Predictive tasks on relational databases are critical in real-world\napplications spanning e-commerce, healthcare, and social media. To address\nthese tasks effectively, Relational Deep Learning (RDL) encodes relational data\nas graphs, enabling Graph Neural Networks (GNNs) to exploit relational\nstructures for improved predictions. However, existing heterogeneous GNNs often\noverlook the intrinsic structural properties of relational databases, leading\nto modeling inefficiencies. Here we introduce RelGNN, a novel GNN framework\nspecifically designed to capture the unique characteristics of relational\ndatabases. At the core of our approach is the introduction of atomic routes,\nwhich are sequences of nodes forming high-order tripartite structures. Building\nupon these atomic routes, RelGNN designs new composite message passing\nmechanisms between heterogeneous nodes, allowing direct single-hop interactions\nbetween them. This approach avoids redundant aggregations and mitigates\ninformation entanglement, ultimately leading to more efficient and accurate\npredictive modeling. RelGNN is evaluated on 30 diverse real-world tasks from\nRelBench (Fey et al., 2024), and consistently achieves state-of-the-art\naccuracy with up to 25% improvement.",
      "tldr_zh": "该研究针对关系数据库中的预测任务，提出 RelGNN 框架，以更好地捕捉关系数据的内在结构，避免现有异构 GNNs 的建模低效问题。\nRelGNN 引入 atomic routes（原子路由）作为高阶三方结构的节点序列，并设计了新的 composite message passing 机制，实现异构节点之间的直接单跳交互，从而减少冗余聚合和信息纠缠。\n实验结果显示，RelGNN 在 RelBench 的 30 个真实世界任务上，实现了最先进准确率，并取得了高达 25% 的改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.06784v1",
      "published_date": "2025-02-10 18:58:40 UTC",
      "updated_date": "2025-02-10 18:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:21:53.264706"
    },
    {
      "arxiv_id": "2502.06779v1",
      "title": "KARST: Multi-Kernel Kronecker Adaptation with Re-Scaling Transmission for Visual Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Zhu",
        "Haiwen Diao",
        "Shang Gao",
        "Long Chen",
        "Huchuan Lu"
      ],
      "abstract": "Fine-tuning pre-trained vision models for specific tasks is a common practice\nin computer vision. However, this process becomes more expensive as models grow\nlarger. Recently, parameter-efficient fine-tuning (PEFT) methods have emerged\nas a popular solution to improve training efficiency and reduce storage needs\nby tuning additional low-rank modules within pre-trained backbones. Despite\ntheir advantages, they struggle with limited representation capabilities and\nmisalignment with pre-trained intermediate features. To address these issues,\nwe introduce an innovative Multi-Kernel Kronecker Adaptation with Re-Scaling\nTransmission (KARST) for various recognition tasks. Specifically, its\nmulti-kernel design extends Kronecker projections horizontally and separates\nadaptation matrices into multiple complementary spaces, reducing parameter\ndependency and creating more compact subspaces. Besides, it incorporates extra\nlearnable re-scaling factors to better align with pre-trained feature\ndistributions, allowing for more flexible and balanced feature aggregation.\nExtensive experiments validate that our KARST outperforms other PEFT\ncounterparts with a negligible inference cost due to its re-parameterization\ncharacteristics. Code is publicly available at:\nhttps://github.com/Lucenova/KARST.",
      "tldr_zh": "该研究针对视觉分类任务中细调预训练模型的效率问题，提出了一种参数高效细调(PEFT)方法——KARST（Multi-Kernel Kronecker Adaptation with Re-Scaling Transmission）。KARST 通过多核设计扩展 Kronecker 投影，将适应矩阵分解为多个互补子空间，减少参数依赖并创建更紧凑的表示，同时引入可学习的再缩放因子以更好地与预训练特征分布对齐，实现灵活的特征聚合。实验结果显示，KARST 在各种识别任务中优于其他 PEFT 方法，几乎不增加推理成本，并支持再参数化特性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 3 figures, Accepted by ICASSP2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06779v1",
      "published_date": "2025-02-10 18:56:14 UTC",
      "updated_date": "2025-02-10 18:56:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:22:05.081869"
    },
    {
      "arxiv_id": "2502.06776v1",
      "title": "Towards Internet-Scale Training For Agents",
      "title_zh": "迈向互联网规模的代理训练",
      "authors": [
        "Brandon Trabucco",
        "Gunnar Sigurdsson",
        "Robinson Piramuthu",
        "Ruslan Salakhutdinov"
      ],
      "abstract": "The predominant approach for training web navigation agents gathers human\ndemonstrations for a set of popular websites and hand-written tasks, but it is\nbecoming clear that human data are an inefficient resource. We develop a\npipeline to facilitate Internet-scale training for agents without laborious\nhuman annotations. In the first stage, an LLM generates tasks for 150k diverse\nwebsites. In the next stage, LLM agents complete tasks and produce\ntrajectories. In the final stage, an LLM reviews the trajectories and judges\ntheir success. Language models are competitive with human annotators, detecting\nand filtering out harmful content with an accuracy of 97%, generating feasible\ntasks with an 89% rate, and judging successful trajectories with an 82.6%\naccuracy. Scaling the pipeline, agents based on Llama 3.1 70B solve 16.7% of\ntasks for 150k sites. Training on the data generated by our pipeline is\ncompetitive with training on human demonstrations. In data-limited settings\nderived from Mind2Web and WebLINX, we improve Step Accuracy by up to +89.5% and\n+122.1% respectively for agents trained on mixtures of data from our pipeline,\nand human data. When training agents with all available human data from these\nbenchmarks, agents fail to generalize to diverse real sites, and adding our\ndata improves their generalization by +149.0% for WebLINX and +156.3% for\nMind2Web. Code will be available at: data-for-agents.github.io.",
      "tldr_zh": "该研究提出了一种无需繁重人类标注的管道(pipeline)，用于实现互联网规模的代理训练，针对网页导航代理的传统依赖人类演示问题。该管道包括三个阶段：LLM 生成针对15万多样网站的任务、LLM 代理完成任务并产生轨迹，以及LLM 审查轨迹以判断成功，LLM 在检测有害内容、生成可行任务和评估轨迹方面的准确率分别达到97%、89%和82.6%。实验显示，基于Llama 3.1 70B的代理解决了16.7%的任务；在数据有限场景中，使用管道生成数据混合人类数据，可将Mind2Web和WebLINX的Step Accuracy提高最多89.5%和122.1%；此外，添加管道数据显著提升代理的泛化能力，在WebLINX和Mind2Web上改善分别为149.0%和156.3%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06776v1",
      "published_date": "2025-02-10 18:54:05 UTC",
      "updated_date": "2025-02-10 18:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:22:18.914780"
    },
    {
      "arxiv_id": "2502.06773v1",
      "title": "On the Emergence of Thinking in LLMs I: Searching for the Right Intuition",
      "title_zh": "翻译失败",
      "authors": [
        "Guanghao Ye",
        "Khiem Duc Pham",
        "Xinzhi Zhang",
        "Sivakanth Gopi",
        "Baolin Peng",
        "Beibin Li",
        "Janardhan Kulkarni",
        "Huseyin A. Inan"
      ],
      "abstract": "Recent AI advancements, such as OpenAI's new models, are transforming LLMs\ninto LRMs (Large Reasoning Models) that perform reasoning during inference,\ntaking extra time and compute for higher-quality outputs. We aim to uncover the\nalgorithmic framework for training LRMs. Methods like self-consistency, PRM,\nand AlphaZero suggest reasoning as guided search. We ask: what is the simplest,\nmost scalable way to enable search in LLMs?\n  We propose a post-training framework called Reinforcement Learning via\nSelf-Play (RLSP). RLSP involves three steps: (1) supervised fine-tuning with\nhuman or synthetic demonstrations of the reasoning process, (2) using an\nexploration reward signal to encourage diverse and efficient reasoning\nbehaviors, and (3) RL training with an outcome verifier to ensure correctness\nwhile preventing reward hacking. Our key innovation is to decouple exploration\nand correctness signals during PPO training, carefully balancing them to\nimprove performance and efficiency.\n  Empirical studies in the math domain show that RLSP improves reasoning. On\nthe Llama-3.1-8B-Instruct model, RLSP can boost performance by 23% in MATH-500\ntest set; On AIME 2024 math problems, Qwen2.5-32B-Instruct improved by 10% due\nto RLSP. However, a more important finding of this work is that the models\ntrained using RLSP, even with the simplest exploration reward that encourages\nthe model to take more intermediate steps, showed several emergent behaviors\nsuch as backtracking, exploration of ideas, and verification. These findings\ndemonstrate that RLSP framework might be enough to enable emergence of complex\nreasoning abilities in LLMs when scaled. Lastly, we propose a theory as to why\nRLSP search strategy is more suitable for LLMs inspired by a remarkable result\nthat says CoT provably increases computational power of LLMs, which grows as\nthe number of steps in CoT \\cite{li2024chain,merrill2023expresssive}.",
      "tldr_zh": "本论文探讨了LLMs（Large Language Models）向LRMs（Large Reasoning Models）的演变，旨在寻找训练LRMs的最简单可扩展方法。作者提出RLSP（Reinforcement Learning via Self-Play）框架，包括监督微调、探索奖励鼓励多样性推理，以及RL训练以确保正确性，从而提升模型的搜索和推理能力。在数学任务上，RLSP使Llama-3.1-8B-Instruct在MATH-500测试集上提升23%，Qwen2.5-32B-Instruct在AIME 2024问题上提升10%，并观察到紧急行为如backtracking和idea exploration。最终，论文提出理论解释RLSP的搜索策略如何像CoT（Chain-of-Thought）一样增强LLMs的计算能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Abstract shortened for arXiv",
      "pdf_url": "http://arxiv.org/pdf/2502.06773v1",
      "published_date": "2025-02-10 18:52:04 UTC",
      "updated_date": "2025-02-10 18:52:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:22:31.032980"
    },
    {
      "arxiv_id": "2502.06927v1",
      "title": "Neighborhood-Order Learning Graph Attention Network for Fake News Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Batool Lakzaei",
        "Mostafa Haghir Chehreghani",
        "Alireza Bagheri"
      ],
      "abstract": "Fake news detection is a significant challenge in the digital age, which has\nbecome increasingly important with the proliferation of social media and online\ncommunication networks. Graph Neural Networks (GNN)-based methods have shown\nhigh potential in analyzing graph-structured data for this problem. However, a\nmajor limitation in conventional GNN architectures is their inability to\neffectively utilize information from neighbors beyond the network's layer\ndepth, which can reduce the model's accuracy and effectiveness. In this paper,\nwe propose a novel model called Neighborhood-Order Learning Graph Attention\nNetwork (NOL-GAT) for fake news detection. This model allows each node in each\nlayer to independently learn its optimal neighborhood order. By doing so, the\nmodel can purposefully and efficiently extract critical information from\ndistant neighbors. The NOL-GAT architecture consists of two main components: a\nHop Network that determines the optimal neighborhood order and an Embedding\nNetwork that updates node embeddings using these optimal neighborhoods. To\nevaluate the model's performance, experiments are conducted on various fake\nnews datasets. Results demonstrate that NOL-GAT significantly outperforms\nbaseline models in metrics such as accuracy and F1-score, particularly in\nscenarios with limited labeled data. Features such as mitigating the\nover-squashing problem, improving information flow, and reducing computational\ncomplexity further highlight the advantages of the proposed model.",
      "tldr_zh": "该研究针对假新闻检测的挑战，提出了一种新型模型Neighborhood-Order Learning Graph Attention Network (NOL-GAT)，旨在克服传统Graph Neural Networks (GNN)无法有效利用超过层深度的邻居信息的问题。NOL-GAT的核心机制包括Hop Network用于确定每个节点的optimal neighborhood order，以及Embedding Network基于这些顺序更新节点嵌入，从而高效提取远距离邻居的关键信息。实验结果显示，该模型在多种假新闻数据集上显著优于基线模型，在准确性和F1-score方面表现突出，尤其在标签数据有限的场景中，同时缓解了over-squashing问题并降低了计算复杂性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "37 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.06927v1",
      "published_date": "2025-02-10 18:51:57 UTC",
      "updated_date": "2025-02-10 18:51:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:22:43.596983"
    },
    {
      "arxiv_id": "2502.06772v2",
      "title": "ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates",
      "title_zh": "翻译失败",
      "authors": [
        "Ling Yang",
        "Zhaochen Yu",
        "Bin Cui",
        "Mengdi Wang"
      ],
      "abstract": "We present that hierarchical LLM reasoning via scaling thought templates can\neffectively optimize the reasoning search space and outperform the mathematical\nreasoning capabilities of powerful LLMs like OpenAI o1-preview and DeepSeek V3.\nWe train our ReasonFlux-32B model with only 8 GPUs and introduces three\ninnovations: (i) a structured and generic thought template library, containing\naround 500 high-level thought templates capable of generalizing to similar or\nrelevant reasoning problems; (ii) performing hierarchical reinforcement\nlearning on a sequence of thought templates instead of long CoTs, optimizing a\nbase LLM to plan out an optimal template trajectory for gradually handling\ncomplex problems; (iii) a brand new inference scaling system that enables\nhierarchical LLM reasoning by adaptively scaling thought templates at inference\ntime. With a template trajectory containing more explainable reasoning\nstructures than DeepSeek-R1 and o3-mini, our ReasonFlux-32B significantly\nadvances math reasoning capabilities to state-of-the-art levels. Notably, on\nthe MATH benchmark, it achieves an accuracy of 91.2% and surpasses o1-preview\nby 6.7%. On the USA Math Olympiad (AIME) benchmark, ReasonFlux-32B solves an\naverage of 56.7% of problems, surpassing o1-preview and DeepSeek-V3 by 27% and\n45%, respectively. Code: https://github.com/Gen-Verse/ReasonFlux",
      "tldr_zh": "该研究提出ReasonFlux，一种通过扩展思想模板(scaling thought templates)实现层次化LLM推理的方法，能够优化推理搜索空间并超越OpenAI o1-preview和DeepSeek V3的数学推理能力。创新点包括构建一个包含约500个高层思想模板的结构化库、在思想模板序列上进行hierarchical reinforcement learning以规划最佳轨迹，以及一个自适应推理缩放系统来处理复杂问题。实验结果显示，ReasonFlux-32B模型在MATH基准上达到91.2%的准确率，比o1-preview高6.7%；在USA Math Olympiad (AIME)基准上，解决56.7%的问题，比o1-preview和DeepSeek-V3分别高27%和45%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Code: https://github.com/Gen-Verse/ReasonFlux",
      "pdf_url": "http://arxiv.org/pdf/2502.06772v2",
      "published_date": "2025-02-10 18:51:47 UTC",
      "updated_date": "2025-03-11 02:46:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:22:57.337566"
    },
    {
      "arxiv_id": "2502.06759v4",
      "title": "Rationalization Models for Text-to-SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Gaetano Rossiello",
        "Nhan Pham",
        "Michael Glass",
        "Junkyu Lee",
        "Dharmashankar Subramanian"
      ],
      "abstract": "We introduce a framework for generating Chain-of-Thought (CoT) rationales to\nenhance text-to-SQL model fine-tuning. These rationales consist of intermediate\nSQL statements and explanations, serving as incremental steps toward\nconstructing the final SQL query. The process begins with manually annotating a\nsmall set of examples, which are then used to prompt a large language model in\nan iterative, dynamic few-shot knowledge distillation procedure from a teacher\nmodel. A rationalization model is subsequently trained on the validated\ndecomposed queries, enabling extensive synthetic CoT annotations for\ntext-to-SQL datasets. To evaluate the approach, we fine-tune small language\nmodels with and without these rationales on the BIRD dataset. Results indicate\nthat step-by-step query generation improves execution accuracy, especially for\nmoderately and highly complex queries, while also enhancing explainability.",
      "tldr_zh": "本研究提出了一种理性化模型框架，用于生成 Chain-of-Thought (CoT) 推理，以提升 Text-to-SQL 模型的微调效果。这些推理包括中间 SQL 语句和解释，作为构建最终 SQL 查询的逐步过程，通过手动标注少量示例、迭代动态少样本知识蒸馏和训练理性化模型来生成合成 CoT 注解。实验在 BIRD 数据集上微调小语言模型，结果显示逐步查询生成显著提高了执行准确率，尤其在中等和高度复杂查询上，同时增强了模型的可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "Published at ICLR 2025 Workshop on Reasoning and Planning for LLMs",
      "pdf_url": "http://arxiv.org/pdf/2502.06759v4",
      "published_date": "2025-02-10 18:38:57 UTC",
      "updated_date": "2025-03-20 13:46:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:23:06.070946"
    },
    {
      "arxiv_id": "2502.06751v1",
      "title": "What makes a good feedforward computational graph?",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Vitvitskyi",
        "João G. M. Araújo",
        "Marc Lackenby",
        "Petar Veličković"
      ],
      "abstract": "As implied by the plethora of literature on graph rewiring, the choice of\ncomputational graph employed by a neural network can make a significant impact\non its downstream performance. Certain effects related to the computational\ngraph, such as under-reaching and over-squashing, may even render the model\nincapable of learning certain functions. Most of these effects have only been\nthoroughly studied in the domain of undirected graphs; however, recent years\nhave seen a significant rise in interest in feedforward computational graphs:\ndirected graphs without any back edges. In this paper, we study the desirable\nproperties of a feedforward computational graph, discovering two important\ncomplementary measures: fidelity and mixing time, and evaluating a few popular\nchoices of graphs through the lens of these measures. Our study is backed by\nboth theoretical analyses of the metrics' asymptotic behaviour for various\ngraphs, as well as correlating these metrics to the performance of trained\nneural network models using the corresponding graphs.",
      "tldr_zh": "本论文探讨了前馈计算图(feedforward computational graph)的设计如何影响神经网络性能，特别是针对 under-reaching 和 over-squashing 等问题，这些可能导致模型无法学习特定函数。论文提出了两个关键互补指标：fidelity（保真度）和 mixing time（混合时间），用于评估前馈计算图的理想属性。作者通过理论分析这些指标在各种图上的渐近行为，并结合训练神经网络模型的实验，验证了这些指标与模型性能的相关性。最终，研究为优化计算图选择提供了指导，帮助提升神经网络的鲁棒性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Work in progress -- comments welcome. 16 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06751v1",
      "published_date": "2025-02-10 18:26:40 UTC",
      "updated_date": "2025-02-10 18:26:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:23:18.745801"
    },
    {
      "arxiv_id": "2502.12161v1",
      "title": "Integrating Artificial Intelligence and Geophysical Insights for Earthquake Forecasting: A Cross-Disciplinary Review",
      "title_zh": "翻译失败",
      "authors": [
        "Zhang Ying",
        "Wen Congcong",
        "Sornette Didier",
        "Zhan Chengxiang"
      ],
      "abstract": "Earthquake forecasting remains a significant scientific challenge, with\ncurrent methods falling short of achieving the performance necessary for\nmeaningful societal benefits. Traditional models, primarily based on past\nseismicity and geomechanical data, struggle to capture the complexity of\nseismic patterns and often overlook valuable non-seismic precursors such as\ngeophysical, geochemical, and atmospheric anomalies. The integration of such\ndiverse data sources into forecasting models, combined with advancements in AI\ntechnologies, offers a promising path forward. AI methods, particularly deep\nlearning, excel at processing complex, large-scale datasets, identifying subtle\npatterns, and handling multidimensional relationships, making them well-suited\nfor overcoming the limitations of conventional approaches.\n  This review highlights the importance of combining AI with geophysical\nknowledge to create robust, physics-informed forecasting models. It explores\ncurrent AI methods, input data types, loss functions, and practical\nconsiderations for model development, offering guidance to both geophysicists\nand AI researchers. While many AI-based studies oversimplify earthquake\nprediction, neglecting critical features such as data imbalance and\nspatio-temporal clustering, the integration of specialized geophysical insights\ninto AI models can address these shortcomings.\n  We emphasize the importance of interdisciplinary collaboration, urging\ngeophysicists to experiment with AI architectures thoughtfully and encouraging\nAI experts to deepen their understanding of seismology. By bridging these\ndisciplines, we can develop more accurate, reliable, and societally impactful\nearthquake forecasting tools.",
      "tldr_zh": "该评论探讨了地震预测的挑战，指出传统模型基于过去地震和地机械数据，无法充分捕捉复杂地震模式，并忽略了诸如地球物理、地球化学和大气异常等非地震前兆。作者强调整合AI技术，特别是深度学习，来处理大规模复杂数据集、识别微妙模式和多维关系，从而提升预测准确性。论文审视了当前AI方法、输入数据类型、损失函数和模型开发实践，呼吁通过跨学科合作将地球物理见解融入AI模型，以解决数据不平衡和时空聚类等问题，最终开发更可靠的地震预测工具。",
      "categories": [
        "physics.geo-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.12161v1",
      "published_date": "2025-02-10 18:26:05 UTC",
      "updated_date": "2025-02-10 18:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:23:33.313591"
    },
    {
      "arxiv_id": "2502.06925v1",
      "title": "Occam's model: Selecting simpler representations for better transferability estimation",
      "title_zh": "Occam's model: 选择更简单的表示以实现更好的迁移性估计",
      "authors": [
        "Prabhant Singh",
        "Sibylle Hess",
        "Joaquin Vanschoren"
      ],
      "abstract": "Fine-tuning models that have been pre-trained on large datasets has become a\ncornerstone of modern machine learning workflows. With the widespread\navailability of online model repositories, such as Hugging Face, it is now\neasier than ever to fine-tune pre-trained models for specific tasks. This\nraises a critical question: which pre-trained model is most suitable for a\ngiven task? This problem is called transferability estimation. In this work, we\nintroduce two novel and effective metrics for estimating the transferability of\npre-trained models. Our approach is grounded in viewing transferability as a\nmeasure of how easily a pre-trained model's representations can be trained to\nseparate target classes, providing a unique perspective on transferability\nestimation. We rigorously evaluate the proposed metrics against\nstate-of-the-art alternatives across diverse problem settings, demonstrating\ntheir robustness and practical utility. Additionally, we present theoretical\ninsights that explain our metrics' efficacy and adaptability to various\nscenarios. We experimentally show that our metrics increase Kendall's Tau by up\nto 32% compared to the state-of-the-art baselines.",
      "tldr_zh": "这篇论文提出了Occam's model，一种用于提升transferability estimation的新方法，通过引入两个新指标来评估预训练模型表示的简单性，从而更好地预测模型在特定任务上的迁移性能。这些指标基于一个新视角，即衡量预训练模型表示是否容易被训练来区分目标类别，并在多种问题设置下显示出比现有方法更强的鲁棒性和实用性。实验结果表明，该方法比最先进基线提高了Kendall's Tau最多32%，并通过理论分析解释了其有效性和适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06925v1",
      "published_date": "2025-02-10 18:23:24 UTC",
      "updated_date": "2025-02-10 18:23:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:23:41.926906"
    },
    {
      "arxiv_id": "2502.06742v1",
      "title": "Gradient Multi-Normalization for Stateless and Scalable LLM Training",
      "title_zh": "翻译失败",
      "authors": [
        "Meyer Scetbon",
        "Chao Ma",
        "Wenbo Gong",
        "Edward Meeds"
      ],
      "abstract": "Training large language models (LLMs) typically relies on adaptive optimizers\nlike Adam (Kingma & Ba, 2015) which store additional state information to\naccelerate convergence but incur significant memory overhead. Recent efforts,\nsuch as SWAN (Ma et al., 2024) address this by eliminating the need for\noptimizer states while achieving performance comparable to Adam via a\nmulti-step preprocessing procedure applied to instantaneous gradients.\nMotivated by the success of SWAN, we introduce a novel framework for designing\nstateless optimizers that normalizes stochastic gradients according to multiple\nnorms. To achieve this, we propose a simple alternating scheme to enforce the\nnormalization of gradients w.r.t these norms. We show that our procedure can\nproduce, up to an arbitrary precision, a fixed-point of the problem, and that\nSWAN is a particular instance of our approach with carefully chosen norms,\nproviding a deeper understanding of its design. However, SWAN's computationally\nexpensive whitening/orthogonalization step limit its practicality for large\nLMs. Using our principled perspective, we develop of a more efficient,\nscalable, and practical stateless optimizer. Our algorithm relaxes the\nproperties of SWAN, significantly reducing its computational cost while\nretaining its memory efficiency, making it applicable to training large-scale\nmodels. Experiments on pre-training LLaMA models with up to 1 billion\nparameters demonstrate a 3X speedup over Adam with significantly reduced memory\nrequirements, outperforming other memory-efficient baselines.",
      "tldr_zh": "本文提出了一种梯度多重归一化框架，用于无状态和可扩展的大语言模型（LLMs）训练，通过多种范数（norms）对随机梯度进行归一化，以消除传统优化器如 Adam 的内存开销。框架采用简单的交替方案来强制执行归一化，证明其能产生问题的固定点，并揭示 SWAN 作为其特例，同时开发了一个更高效的优化器，减少了 SWAN 的计算成本。实验显示，在预训练 LLaMA 模型（最多 10 亿参数）时，该优化器比 Adam 快 3 倍，内存需求显著降低，并优于其他内存高效基线。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06742v1",
      "published_date": "2025-02-10 18:09:53 UTC",
      "updated_date": "2025-02-10 18:09:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:23:55.371557"
    },
    {
      "arxiv_id": "2502.06736v1",
      "title": "Low-power Spike-based Wearable Analytics on RRAM Crossbars",
      "title_zh": "翻译失败",
      "authors": [
        "Abhiroop Bhattacharjee",
        "Jinquan Shi",
        "Wei-Chen Chen",
        "Xinxin Wang",
        "Priyadarshini Panda"
      ],
      "abstract": "This work introduces a spike-based wearable analytics system utilizing\nSpiking Neural Networks (SNNs) deployed on an In-memory Computing engine based\non RRAM crossbars, which are known for their compactness and energy-efficiency.\nGiven the hardware constraints and noise characteristics of the underlying RRAM\ncrossbars, we propose online adaptation of pre-trained SNNs in real-time using\nDirect Feedback Alignment (DFA) against traditional backpropagation (BP).\nDirect Feedback Alignment (DFA) learning, that allows layer-parallel gradient\ncomputations, acts as a fast, energy & area-efficient method for online\nadaptation of SNNs on RRAM crossbars, unleashing better algorithmic performance\nagainst those adapted using BP. Through extensive simulations using our\nin-house hardware evaluation engine called DFA_Sim, we find that DFA achieves\nupto 64.1% lower energy consumption, 10.1% lower area overhead, and a 2.1x\nreduction in latency compared to BP, while delivering upto 7.55% higher\ninference accuracy on human activity recognition (HAR) tasks.",
      "tldr_zh": "本研究提出了一种低功耗的基于 Spiking Neural Networks (SNNs) 的可穿戴分析系统，利用 RRAM 交叉阵列作为内存计算引擎，以实现紧凑和节能的硬件部署。\n为应对 RRAM 的硬件约束和噪声特性，该系统采用 Direct Feedback Alignment (DFA) 进行预训练 SNNs 的实时在线适应，而不是传统的 backpropagation (BP)，从而实现层并行梯度计算并提升效率。\n实验通过内部模拟引擎 DFA_Sim 显示，DFA 比 BP 节省能源高达 64.1%，降低面积开销 10.1%，减少延迟 2.1 倍，同时在人类活动识别 (HAR) 任务上提高推理准确率达 7.55%。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.ET",
      "comment": "Accepted in 2025 IEEE International Symposium on Circuits and Systems\n  (ISCAS)",
      "pdf_url": "http://arxiv.org/pdf/2502.06736v1",
      "published_date": "2025-02-10 18:00:05 UTC",
      "updated_date": "2025-02-10 18:00:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:24:07.543829"
    },
    {
      "arxiv_id": "2502.06733v1",
      "title": "Dynamic Loss-Based Sample Reweighting for Improved Large Language Model Pretraining",
      "title_zh": "动态基于损失的样本再",
      "authors": [
        "Daouda Sow",
        "Herbert Woisetschläger",
        "Saikiran Bulusu",
        "Shiqiang Wang",
        "Hans-Arno Jacobsen",
        "Yingbin Liang"
      ],
      "abstract": "Pretraining large language models (LLMs) on vast and heterogeneous datasets\nis crucial for achieving state-of-the-art performance across diverse downstream\ntasks. However, current training paradigms treat all samples equally,\noverlooking the importance or relevance of individual samples throughout the\ntraining process. Existing reweighting strategies, which primarily focus on\ngroup-level data importance, fail to leverage fine-grained instance-level\ninformation and do not adapt dynamically to individual sample importance as\ntraining progresses. In this paper, we introduce novel algorithms for dynamic,\ninstance-level data reweighting aimed at improving both the efficiency and\neffectiveness of LLM pretraining. Our methods adjust the weight of each\ntraining sample based on its loss value in an online fashion, allowing the\nmodel to dynamically focus on more informative or important samples at the\ncurrent training stage. In particular, our framework allows us to\nsystematically devise reweighting strategies deprioritizing redundant or\nuninformative data, which we find tend to work best. Furthermore, we develop a\nnew theoretical framework for analyzing the impact of loss-based reweighting on\nthe convergence of gradient-based optimization, providing the first formal\ncharacterization of how these strategies affect convergence bounds. We\nempirically validate our approach across a spectrum of tasks, from pretraining\n7B and 1.4B parameter LLMs to smaller-scale language models and linear\nregression problems, demonstrating that our loss-based reweighting approach can\nlead to faster convergence and significantly improved performance.",
      "tldr_zh": "该论文提出了一种动态损失-based 样本再加权方法，以提升大型语言模型(LLM)的预训练效率和效果，解决现有策略忽略实例级信息和动态适应的局限性。该方法通过在线调整每个训练样本的权重基于其损失值，让模型优先关注更具信息性的样本，同时去优先处理冗余或无信息数据。论文还开发了一个新的理论框架，分析这种再加权策略对梯度优化收敛的影响。实验验证显示，在预训练7B和1.4B参数的LLM以及其他任务上，该方法实现了更快收敛和显著性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication at ICLR 2025. Code base available:\n  https://github.com/sowmaster/Sample-Level-Loss-Reweighting-ICLR-2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06733v1",
      "published_date": "2025-02-10 17:57:15 UTC",
      "updated_date": "2025-02-10 17:57:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:24:18.999785"
    },
    {
      "arxiv_id": "2502.06728v2",
      "title": "FlexDeMo: Decoupled Momentum Optimization for Hybrid Sharded Data Parallel Training",
      "title_zh": "翻译失败",
      "authors": [
        "Mogens Henrik From",
        "Jacob Nielsen",
        "Lukas Galke",
        "Peter Schneider-Kamp"
      ],
      "abstract": "Training large neural network models requires extensive computational\nresources, often distributed across several nodes and accelerators. Recent\nfindings suggest that it may be sufficient to only exchange the fast moving\ncomponents of the gradients, while accumulating momentum locally (Decoupled\nMomentum, or DeMo). However, when considering larger models that do not fit on\na single accelerator, the exchange of gradient information and the integration\nof DeMo needs to be reconsidered. Here, we propose employing a hybrid sharded\ndata parallel training strategy, FlexDeMo, whereby nodes fully shard model\nparameters locally between different accelerators, while inter-node\ncommunication bandwidth requirements are reduced by synchronizing only\nfast-moving components instead of the full gradients. This effectively combines\nprevious hybrid sharded strategies with the advantages of decoupled momentum.\nOur experimental results show that FlexDeMo is on par with hybrid sharded data\nparallel training employing AdamW and full gradient synchronization in terms of\nvalidation loss, demonstrating its viability. Furthermore, FlexDeMo achieves\nimproved training speed compared to full gradient synchronization across nodes.\nIn a bandwidth-constrained 2-node setup, FlexDeMo allows reaching desired\nlevels of validation loss faster than hybrid sharded data parallel training\nwith full gradient synchronization.",
      "tldr_zh": "这篇论文提出了 FlexDeMo，一种结合 Decoupled Momentum 的混合分片数据并行训练方法，用于高效训练大型神经网络模型。FlexDeMo 通过在节点间仅同步梯度的快速移动组件，而在本地完全分片模型参数，从而减少了通信带宽需求，同时保留了 Decoupled Momentum 的优势。实验结果显示，FlexDeMo 在验证损失方面与使用 AdamW 和完整梯度同步的基线相当，但训练速度更快，尤其在带宽受限的2节点设置中，能更快达到目标性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06728v2",
      "published_date": "2025-02-10 17:55:59 UTC",
      "updated_date": "2025-03-18 16:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:24:31.204703"
    },
    {
      "arxiv_id": "2502.06727v1",
      "title": "Application of Artificial Intelligence (AI) in Civil Engineering",
      "title_zh": "人工智能 (AI) 在土木工程中的应用",
      "authors": [
        "Temitope Funmilayo Awolusi",
        "Bernard Chukwuemeka Finbarrs-Ezema",
        "Isaac Munachimdinamma Chukwudulue",
        "Marc Azab"
      ],
      "abstract": "Hard computing generally deals with precise data, which provides ideal\nsolutions to problems. However, in the civil engineering field, amongst other\ndisciplines, that is not always the case as real-world systems are continuously\nchanging. Here lies the need to explore soft computing methods and artificial\nintelligence to solve civil engineering shortcomings. The integration of\nadvanced computational models, including Artificial Neural Networks (ANNs),\nFuzzy Logic, Genetic Algorithms (GAs), and Probabilistic Reasoning, has\nrevolutionized the domain of civil engineering. These models have significantly\nadvanced diverse sub-fields by offering innovative solutions and improved\nanalysis capabilities. Sub-fields such as: slope stability analysis, bearing\ncapacity, water quality and treatment, transportation systems, air quality,\nstructural materials, etc. ANNs predict non-linearities and provide accurate\nestimates. Fuzzy logic uses an efficient decision-making process to provide a\nmore precise assessment of systems. Lastly, while GAs optimizes models (based\non evolutionary processes) for better outcomes, probabilistic reasoning lowers\ntheir statistical uncertainties.",
      "tldr_zh": "该论文探讨了人工智能(AI)在土木工程中的应用，以解决硬计算在处理真实世界动态系统时的局限性，转而采用软计算方法。关键技术包括Artificial Neural Networks (ANNs)、Fuzzy Logic、Genetic Algorithms (GAs)和Probabilistic Reasoning，这些模型为坡度稳定性分析、承载能力、水质处理、交通系统等子领域提供了创新解决方案。ANNs擅长预测非线性问题并提升准确性，Fuzzy Logic优化决策过程，而GAs和Probabilistic Reasoning则通过进化优化和统计不确定性降低，显著提高了工程分析能力。总的来说，该研究展示了AI如何革新土木工程的效率和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Kindly cite published version if given access",
      "pdf_url": "http://arxiv.org/pdf/2502.06727v1",
      "published_date": "2025-02-10 17:55:52 UTC",
      "updated_date": "2025-02-10 17:55:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:24:45.720921"
    },
    {
      "arxiv_id": "2502.06924v4",
      "title": "XAMBA: Enabling Efficient State Space Models on Resource-Constrained Neural Processing Units",
      "title_zh": "翻译失败",
      "authors": [
        "Arghadip Das",
        "Arnab Raha",
        "Shamik Kundu",
        "Soumendu Kumar Ghosh",
        "Deepak Mathaikutty",
        "Vijay Raghunathan"
      ],
      "abstract": "State-Space Models (SSMs) have emerged as efficient alternatives to\ntransformers for sequential data tasks, offering linear or near-linear\nscalability with sequence length, making them ideal for long-sequence\napplications in NLP, vision, and edge AI, including real-time transcription,\ntranslation, and contextual search. These applications require lightweight,\nhigh-performance models for deployment on resource-constrained devices like\nlaptops and PCs. Designing specialized accelerators for every emerging neural\nnetwork is costly and impractical; instead, optimizing models for existing NPUs\nin AI PCs provides a scalable solution. To this end, we propose XAMBA, the\nfirst framework to enable and optimize SSMs on commercial off-the-shelf (COTS)\nstate-of-the-art (SOTA) NPUs. XAMBA follows a three-step methodology: (1)\nenabling SSMs on NPUs, (2) optimizing performance to meet KPI requirements, and\n(3) trading accuracy for additional performance gains. After enabling SSMs on\nNPUs, XAMBA mitigates key bottlenecks using CumBA and ReduBA, replacing\nsequential CumSum and ReduceSum operations with matrix-based computations,\nsignificantly improving execution speed and memory efficiency. Additionally,\nActiBA enhances performance by approximating expensive activation functions\n(e.g., Swish, Softplus) using piecewise linear mappings, reducing latency with\nminimal accuracy loss. Evaluations on an Intel Core Ultra Series 2 AI PC show\nthat XAMBA achieves up to 4.8X speed-up over the baseline. Our implementation\nis available at https://github.com/arghadippurdue/XAMBA.",
      "tldr_zh": "该论文提出 XAMBA 框架，用于在资源受限的 Neural Processing Units (NPUs) 上启用和优化 State-Space Models (SSMs)，以支持 NLP、视觉和边缘 AI 等长序列任务。XAMBA 采用三步方法：首先启用 SSMs on NPUs，其次通过 CumBA 和 ReduBA 将顺序操作（如 CumSum 和 ReduceSum）替换为矩阵计算以提升速度和内存效率，最后使用 ActiBA 近似激活函数（如 Swish 和 Softplus）来进一步减少延迟，同时最小化准确性损失。实验结果显示，在 Intel Core Ultra Series 2 AI PC 上，XAMBA 相对于基线模型实现了高达 4.8 倍的加速，为部署轻量级模型提供了可扩展解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06924v4",
      "published_date": "2025-02-10 17:33:30 UTC",
      "updated_date": "2025-03-31 03:26:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:24:55.304772"
    },
    {
      "arxiv_id": "2502.06923v1",
      "title": "Do Attention Heads Compete or Cooperate during Counting?",
      "title_zh": "注意力头在计数过程中是竞争还是合作？",
      "authors": [
        "Pál Zsámboki",
        "Ádám Fraknói",
        "Máté Gedeon",
        "András Kornai",
        "Zsolt Zombori"
      ],
      "abstract": "We present an in-depth mechanistic interpretability analysis of training\nsmall transformers on an elementary task, counting, which is a crucial\ndeductive step in many algorithms. In particular, we investigate the\ncollaboration/competition among the attention heads: we ask whether the\nattention heads behave as a pseudo-ensemble, all solving the same subtask, or\nthey perform different subtasks, meaning that they can only solve the original\ntask in conjunction. Our work presents evidence that on the semantics of the\ncounting task, attention heads behave as a pseudo-ensemble, but their outputs\nneed to be aggregated in a non-uniform manner in order to create an encoding\nthat conforms to the syntax. Our source code will be available upon\npublication.",
      "tldr_zh": "这篇论文对小型 Transformer 模型在计数任务上的训练进行了深入的机制解释分析，焦点是 attention heads 之间的协作或竞争行为。研究发现，attention heads 在计数的语义上表现为 pseudo-ensemble，即它们共同解决相同的子任务，但它们的输出需要以非均匀方式聚合，以创建符合语法的编码。总体而言，该工作揭示了 Transformer 模型内部动态的新洞见，并计划公开源代码以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06923v1",
      "published_date": "2025-02-10 17:21:39 UTC",
      "updated_date": "2025-02-10 17:21:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:25:06.040122"
    },
    {
      "arxiv_id": "2502.06693v1",
      "title": "Recent Advances, Applications and Open Challenges in Machine Learning for Health: Reflections from Research Roundtables at ML4H 2024 Symposium",
      "title_zh": "翻译失败",
      "authors": [
        "Amin Adibi",
        "Xu Cao",
        "Zongliang Ji",
        "Jivat Neet Kaur",
        "Winston Chen",
        "Elizabeth Healey",
        "Brighton Nuwagira",
        "Wenqian Ye",
        "Geoffrey Woollard",
        "Maxwell A Xu",
        "Hejie Cui",
        "Johnny Xi",
        "Trenton Chang",
        "Vasiliki Bikia",
        "Nicole Zhang",
        "Ayush Noori",
        "Yuan Xia",
        "Md. Belal Hossain",
        "Hanna A. Frank",
        "Alina Peluso",
        "Yuan Pu",
        "Shannon Zejiang Shen",
        "John Wu",
        "Adibvafa Fallahpour",
        "Sazan Mahbub",
        "Ross Duncan",
        "Yuwei Zhang",
        "Yurui Cao",
        "Zuheng Xu",
        "Michael Craig",
        "Rahul G. Krishnan",
        "Rahmatollah Beheshti",
        "James M. Rehg",
        "Mohammad Ehsanul Karim",
        "Megan Coffee",
        "Leo Anthony Celi",
        "Jason Alan Fries",
        "Mohsen Sadatsafavi",
        "Dennis Shung",
        "Shannon McWeeney",
        "Jessica Dafflon",
        "Sarah Jabbour"
      ],
      "abstract": "The fourth Machine Learning for Health (ML4H) symposium was held in person on\nDecember 15th and 16th, 2024, in the traditional, ancestral, and unceded\nterritories of the Musqueam, Squamish, and Tsleil-Waututh Nations in Vancouver,\nBritish Columbia, Canada. The symposium included research roundtable sessions\nto foster discussions between participants and senior researchers on timely and\nrelevant topics for the ML4H community. The organization of the research\nroundtables at the conference involved 13 senior and 27 junior chairs across 13\ntables. Each roundtable session included an invited senior chair (with\nsubstantial experience in the field), junior chairs (responsible for\nfacilitating the discussion), and attendees from diverse backgrounds with an\ninterest in the session's topic.",
      "tldr_zh": "这篇论文回顾了2024年ML4H（Machine Learning for Health）研讨会的圆桌讨论，聚焦于机器学习在健康领域的最新进展、应用和开放挑战。会议于12月15-16日在加拿大温哥华举行，由13位资深主席和27位初级主席组织，涵盖13个主题，每个圆桌包括资深专家、初级 facilitator 和多背景参与者，促进深度交流。讨论旨在推动ML4H社区的合作与创新，为未来研究指出了关键问题和机遇。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06693v1",
      "published_date": "2025-02-10 17:17:09 UTC",
      "updated_date": "2025-02-10 17:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:25:19.600882"
    },
    {
      "arxiv_id": "2502.06692v1",
      "title": "Multi-label Scandinavian Language Identification (SLIDE)",
      "title_zh": "翻译失败",
      "authors": [
        "Mariia Fedorova",
        "Jonas Sebulon Frydenberg",
        "Victoria Handford",
        "Victoria Ovedie Chruickshank Langø",
        "Solveig Helene Willoch",
        "Marthe Løken Midtgaard",
        "Yves Scherrer",
        "Petter Mæhlum",
        "David Samuel"
      ],
      "abstract": "Identifying closely related languages at sentence level is difficult, in\nparticular because it is often impossible to assign a sentence to a single\nlanguage. In this paper, we focus on multi-label sentence-level Scandinavian\nlanguage identification (LID) for Danish, Norwegian Bokm\\r{a}l, Norwegian\nNynorsk, and Swedish. We present the Scandinavian Language Identification and\nEvaluation, SLIDE, a manually curated multi-label evaluation dataset and a\nsuite of LID models with varying speed-accuracy tradeoffs. We demonstrate that\nthe ability to identify multiple languages simultaneously is necessary for any\naccurate LID method, and present a novel approach to training such multi-label\nLID models.",
      "tldr_zh": "这篇论文针对斯堪的纳维亚语言（如Danish、Norwegian Bokmål、Norwegian Nynorsk和Swedish）的句子级多标签语言识别(LID)问题，强调了由于语言密切相关而难以将句子分配给单一语言的挑战。研究者引入了SLIDE，这是一个手动整理的多标签评估数据集，以及一系列速度-准确性权衡的LID模型。实验结果证明，同时识别多种语言的能力对准确的LID方法至关重要，并提出了一种新颖的训练多标签LID模型的方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06692v1",
      "published_date": "2025-02-10 17:16:55 UTC",
      "updated_date": "2025-02-10 17:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:25:30.510843"
    },
    {
      "arxiv_id": "2502.06922v1",
      "title": "Synthetic Audio Helps for Cognitive State Tasks",
      "title_zh": "合成音频有助于认知状态任务",
      "authors": [
        "Adil Soubki",
        "John Murzaku",
        "Peter Zeng",
        "Owen Rambow"
      ],
      "abstract": "The NLP community has broadly focused on text-only approaches of cognitive\nstate tasks, but audio can provide vital missing cues through prosody. We posit\nthat text-to-speech models learn to track aspects of cognitive state in order\nto produce naturalistic audio, and that the signal audio models implicitly\nidentify is orthogonal to the information that language models exploit. We\npresent Synthetic Audio Data fine-tuning (SAD), a framework where we show that\n7 tasks related to cognitive state modeling benefit from multimodal training on\nboth text and zero-shot synthetic audio data from an off-the-shelf TTS system.\nWe show an improvement over the text-only modality when adding synthetic audio\ndata to text-only corpora. Furthermore, on tasks and corpora that do contain\ngold audio, we show our SAD framework achieves competitive performance with\ntext and synthetic audio compared to text and gold audio.",
      "tldr_zh": "这篇论文探讨了在认知状态任务中加入音频数据的重要性，指出 NLP 社区主要依赖文本-only 方法，而音频通过语调提供关键线索。作者提出 Synthetic Audio Data fine-tuning (SAD) 框架，利用文本和零-shot 合成音频数据（来自现成 TTS 系统）进行多模态训练，结果显示7个认知状态建模任务的性能得到提升，比纯文本语料库更有效。此外，在包含真实音频的任务上，SAD 框架使用文本与合成音频的组合，实现了与文本加真实音频相当的竞争性表现，证明了合成音频的可行性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "John Murzaku and Adil Soubki contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2502.06922v1",
      "published_date": "2025-02-10 17:16:24 UTC",
      "updated_date": "2025-02-10 17:16:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:25:43.279649"
    },
    {
      "arxiv_id": "2502.06684v1",
      "title": "EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Arbel",
        "David Salinas",
        "Frank Hutter"
      ],
      "abstract": "Recent foundational models for tabular data, such as TabPFN, have\ndemonstrated remarkable effectiveness in adapting to new tasks through\nin-context learning. However, these models overlook a crucial equivariance\nproperty: the arbitrary ordering of target dimensions should not influence\nmodel predictions. In this study, we identify this oversight as a source of\nincompressible error, termed the equivariance gap, which introduces instability\nin predictions. To mitigate these issues, we propose a novel model designed to\npreserve equivariance across output dimensions. Our experimental results\nindicate that our proposed model not only addresses these pitfalls effectively\nbut also achieves competitive benchmark performance.",
      "tldr_zh": "本研究指出，现有的表格数据基础模型如TabPFN，虽然在in-context learning中表现出色，但忽略了目标维度的任意排列不应影响预测的equivariance属性，导致预测不稳定和equivariance gap错误。作者提出EquiTabPFN模型，通过设计目标排列不变性机制，确保输出维度的equivariance，从而缓解这些问题。实验结果显示，EquiTabPFN不仅有效解决了上述缺陷，还在基准测试中取得了与现有模型相当的竞争性性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06684v1",
      "published_date": "2025-02-10 17:11:20 UTC",
      "updated_date": "2025-02-10 17:11:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:25:54.175228"
    },
    {
      "arxiv_id": "2502.06681v1",
      "title": "CHIRLA: Comprehensive High-resolution Identification and Re-identification for Large-scale Analysis",
      "title_zh": "CHIRLA：全面高分辨率识别和再识别用于大规模分析",
      "authors": [
        "Bessie Dominguez-Dager",
        "Felix Escalona",
        "Francisco Gomez-Donoso",
        "Miguel Cazorla"
      ],
      "abstract": "Person re-identification (Re-ID) is a key challenge in computer vision,\nrequiring the matching of individuals across different cameras, locations, and\ntime periods. While most research focuses on short-term scenarios with minimal\nappearance changes, real-world applications demand robust Re-ID systems capable\nof handling long-term scenarios, where persons' appearances can change\nsignificantly due to variations in clothing and physical characteristics. In\nthis paper, we present CHIRLA, Comprehensive High-resolution Identification and\nRe-identification for Large-scale Analysis, a novel dataset specifically\ndesigned for long-term person Re-ID. CHIRLA consists of recordings from\nstrategically placed cameras over a seven-month period, capturing significant\nvariations in both temporal and appearance attributes, including controlled\nchanges in participants' clothing and physical features. The dataset includes\n22 individuals, four connected indoor environments, and seven cameras. We\ncollected more than five hours of video that we semi-automatically labeled to\ngenerate around one million bounding boxes with identity annotations. By\nintroducing this comprehensive benchmark, we aim to facilitate the development\nand evaluation of Re-ID algorithms that can reliably perform in challenging,\nlong-term real-world scenarios.",
      "tldr_zh": "该论文针对计算机视觉中的 Person Re-ID（人重新识别）挑战，提出 CHIRLA 数据集，这是一个专为长期场景设计的基准，用于处理外观变化（如服装和身体特征）。CHIRLA 通过战略放置的7个摄像头在7个月内收集超过5小时视频，涵盖22个个体和4个连接的室内环境，并半自动标注约100万个带身份的边界框。数据集的多样性和规模有助于开发更鲁棒的 Re-ID 算法，提升在真实世界长期场景下的性能和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06681v1",
      "published_date": "2025-02-10 17:07:43 UTC",
      "updated_date": "2025-02-10 17:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:26:06.416604"
    },
    {
      "arxiv_id": "2502.06921v2",
      "title": "GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units",
      "title_zh": "翻译失败",
      "authors": [
        "Arghadip Das",
        "Shamik Kundu",
        "Arnab Raha",
        "Soumendu Ghosh",
        "Deepak Mathaikutty",
        "Vijay Raghunathan"
      ],
      "abstract": "Graph Neural Networks (GNNs) are vital for learning from graph-structured\ndata, enabling applications in network analysis, recommendation systems, and\nspeech analytics. Deploying them on edge devices like client PCs and laptops\nenhances real-time processing, privacy, and cloud independence. GNNs aid\nRetrieval-Augmented Generation (RAG) for Large Language Models (LLMs) and\nenable event-based vision tasks. However, irregular memory access, sparsity,\nand dynamic structures cause high latency and energy overhead on\nresource-constrained devices. While modern edge processors integrate CPUs,\nGPUs, and NPUs, NPUs designed for data-parallel tasks struggle with irregular\nGNN computations. We introduce GraNNite, the first hardware-aware framework\noptimizing GNN execution on commercial-off-the-shelf (COTS) SOTA DNN\naccelerators via a structured three-step methodology: (1) enabling NPU\nexecution, (2) optimizing performance, and (3) trading accuracy for efficiency\ngains. Step 1 employs GraphSplit for workload distribution and StaGr for static\naggregation, while GrAd and NodePad handle dynamic graphs. Step 2 boosts\nperformance using EffOp for control-heavy tasks and GraSp for sparsity\nexploitation. Graph Convolution optimizations PreG, SymG, and CacheG reduce\nredundancy and memory transfers. Step 3 balances quality versus efficiency,\nwhere QuantGr applies INT8 quantization, and GrAx1, GrAx2, and GrAx3 accelerate\nattention, broadcast-add, and SAGE-max aggregation. On Intel Core Ultra AI PCs,\nGraNNite achieves 2.6X to 7.6X speedups over default NPU mappings and up to\n8.6X energy gains over CPUs and GPUs, delivering 10.8X and 6.7X higher\nperformance than CPUs and GPUs, respectively, across GNN models.",
      "tldr_zh": "该研究提出 GraNNite，一种硬件感知框架，旨在优化 Graph Neural Networks (GNNs) 在资源受限的 Neural Processing Units (NPUs) 上高效执行，以解决 GNNs 的不规则内存访问、稀疏性和动态结构导致的高延迟和能量开销问题。GraNNite 通过三步方法实现优化：(1) 启用 NPU 执行，使用 GraphSplit、StaGr、GrAd 和 NodePad 处理工作负载和动态图；(2) 提升性能，通过 EffOp、GraSp 以及 PreG、SymG 和 CacheG 优化控制密集任务和稀疏性；(3) 权衡准确性与效率，使用 QuantGr 进行 INT8 量化，以及 GrAx1、GrAx2 和 GrAx3 加速特定聚合操作。在 Intel Core Ultra AI PCs 上，GraNNite 比默认 NPU 映射实现 2.6X 到 7.6X 的加速，并提供高达 8.6X 的能量效率提升，整体性能比 CPU 和 GPU 分别高出 10.8X 和 6.7X。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06921v2",
      "published_date": "2025-02-10 17:03:02 UTC",
      "updated_date": "2025-02-13 02:05:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:26:20.093643"
    },
    {
      "arxiv_id": "2502.09645v1",
      "title": "From No to Know: Taxonomy, Challenges, and Opportunities for Negation Understanding in Multimodal Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mayank Vatsa",
        "Aparna Bharati",
        "Surbhi Mittal",
        "Richa Singh"
      ],
      "abstract": "Negation, a linguistic construct conveying absence, denial, or contradiction,\nposes significant challenges for multilingual multimodal foundation models.\nThese models excel in tasks like machine translation, text-guided generation,\nimage captioning, audio interactions, and video processing but often struggle\nto accurately interpret negation across diverse languages and cultural\ncontexts. In this perspective paper, we propose a comprehensive taxonomy of\nnegation constructs, illustrating how structural, semantic, and cultural\nfactors influence multimodal foundation models. We present open research\nquestions and highlight key challenges, emphasizing the importance of\naddressing these issues to achieve robust negation handling. Finally, we\nadvocate for specialized benchmarks, language-specific tokenization,\nfine-grained attention mechanisms, and advanced multimodal architectures. These\nstrategies can foster more adaptable and semantically precise multimodal\nfoundation models, better equipped to navigate and accurately interpret the\ncomplexities of negation in multilingual, multimodal environments.",
      "tldr_zh": "这篇论文探讨了否定（negation）在多模态基础模型（multimodal foundation models）中的理解挑战，强调这些模型在机器翻译、图像描述和视频处理等任务中表现优异，但往往无法准确处理跨语言和文化语境下的否定结构。作者提出一个全面的否定分类体系（taxonomy），分析了结构、语义和文化因素对模型的影响，并指出了关键研究问题和挑战，以提升模型的鲁棒性。最后，论文建议采用专门基准测试（benchmarks）、语言特定标记化、细粒度注意力机制以及先进的多模态架构，来开发更适应性和精确的模型，助力多语言多模态环境中的否定处理。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09645v1",
      "published_date": "2025-02-10 16:55:13 UTC",
      "updated_date": "2025-02-10 16:55:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:26:31.731765"
    },
    {
      "arxiv_id": "2502.06669v1",
      "title": "Boosting Self-Efficacy and Performance of Large Language Models via Verbal Efficacy Stimulations",
      "title_zh": "通过语言效能刺激提升大型语言模型的自我效能和性能",
      "authors": [
        "Rui Chen",
        "Tailai Peng",
        "Xinran Xie",
        "Dekun Lin",
        "Zhe Cui",
        "Zheng Chen"
      ],
      "abstract": "Significant improvements have been observed in the zero-shot capabilities of\nthe Large Language Models (LLMs). Due to their high sensitivity to input,\nresearch has increasingly focused on enhancing LLMs' performance via direct and\nsimple prompt engineering rather than intricate domain adaptation. Studies\nsuggest that LLMs exhibit emotional intelligence, and both positive and\nnegative emotions can potentially enhance task performances. However, prior\ninteraction prompts have predominantly concentrated on a single stimulus type,\nneglecting to compare different stimulus effects, examine the influence of\nvarying task difficulties, or explore underlying mechanisms. This paper,\ninspired by the positive correlation between self-efficacy and task performance\nwithin the social cognitive theory, introduces Verbal Efficacy Stimulations\n(VES). Our VES comprises three types of verbal prompts: encouraging,\nprovocative, and critical, addressing six aspects such as helpfulness and\ncompetence. And we further categorize task difficulty, aiming to extensively\ninvestigate how distinct VES influence the self-efficacy and task achievements\nof language models at varied levels of difficulty. The experimental results\nshow that the three types of VES improve the performance of LLMs on most tasks,\nand the most effective VES varies for different models. In extensive\nexperiments, we have obtained some findings consistent with psychological\ntheories, providing novel insights for future research.",
      "tldr_zh": "该研究基于社会认知理论，引入 Verbal Efficacy Stimulations (VES) 作为一种提示工程方法，包括鼓励、挑衅和批评三种verbal提示，针对LLMs的帮助性、能力和其他六个方面，以提升大语言模型(Large Language Models)的自我效能和任务性能。实验设计中，研究者分类了不同任务难度，系统地探讨了VES对LLMs影响的机制和效果。结果显示，三种VES在大多数任务上改善了LLMs的表现，且最有效的VES因模型不同而异，这些发现与心理理论一致，为未来LLMs优化提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "to be published in ICONIP 2024",
      "pdf_url": "http://arxiv.org/pdf/2502.06669v1",
      "published_date": "2025-02-10 16:54:03 UTC",
      "updated_date": "2025-02-10 16:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:26:43.467118"
    },
    {
      "arxiv_id": "2502.06666v1",
      "title": "Automatic Evaluation of Healthcare LLMs Beyond Question-Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Arias-Duart",
        "Pablo Agustin Martin-Torres",
        "Daniel Hinjos",
        "Pablo Bernabeu-Perez",
        "Lucia Urcelay Ganzabal",
        "Marta Gonzalez Mallo",
        "Ashwin Kumar Gururajan",
        "Enrique Lopez-Cuena",
        "Sergio Alvarez-Napagao",
        "Dario Garcia-Gasulla"
      ],
      "abstract": "Current Large Language Models (LLMs) benchmarks are often based on open-ended\nor close-ended QA evaluations, avoiding the requirement of human labor.\nClose-ended measurements evaluate the factuality of responses but lack\nexpressiveness. Open-ended capture the model's capacity to produce discourse\nresponses but are harder to assess for correctness. These two approaches are\ncommonly used, either independently or together, though their relationship\nremains poorly understood. This work is focused on the healthcare domain, where\nboth factuality and discourse matter greatly. It introduces a comprehensive,\nmulti-axis suite for healthcare LLM evaluation, exploring correlations between\nopen and close benchmarks and metrics. Findings include blind spots and\noverlaps in current methodologies. As an updated sanity check, we release a new\nmedical benchmark --CareQA-- with both open and closed variants. Finally, we\npropose a novel metric for open-ended evaluations -- Relaxed Perplexity -- to\nmitigate the identified limitations.",
      "tldr_zh": "本研究超越传统的问答（QA）评估，针对医疗领域的大型语言模型（LLMs）提出一个全面的多轴评估套件，以探索开放式和封闭式基准之间的相关性，并揭示这些方法中的盲点和重叠。研究发现，现有评估在事实性和话语表达方面存在局限性，因此发布了新的医疗基准CareQA，包括开放和封闭变体，作为更可靠的健全性检查。同时，作者提出了一种新指标——Relaxed Perplexity，用于缓解开放式评估的限制，提高LLMs在医疗场景中的可靠性和准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06666v1",
      "published_date": "2025-02-10 16:52:39 UTC",
      "updated_date": "2025-02-10 16:52:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:26:56.452441"
    },
    {
      "arxiv_id": "2502.06664v2",
      "title": "Evaluation of Deep Audio Representations for Hearables",
      "title_zh": "翻译失败",
      "authors": [
        "Fabian Gröger",
        "Pascal Baumann",
        "Ludovic Amruthalingam",
        "Laurent Simon",
        "Ruksana Giurda",
        "Simone Lionetti"
      ],
      "abstract": "Effectively steering hearable devices requires understanding the acoustic\nenvironment around the user. In the computational analysis of sound scenes,\nfoundation models have emerged as the state of the art to produce\nhigh-performance, robust, multi-purpose audio representations. We introduce and\nrelease Deep Evaluation of Audio Representations (DEAR), the first dataset and\nbenchmark to evaluate the efficacy of foundation models in capturing essential\nacoustic properties for hearables. The dataset includes 1,158 audio tracks,\neach 30 seconds long, created by spatially mixing proprietary monologues with\ncommercial, high-quality recordings of everyday acoustic scenes. Our benchmark\nencompasses eight tasks that assess the general context, speech sources, and\ntechnical acoustic properties of the audio scenes. Through our evaluation of\nfour general-purpose audio representation models, we demonstrate that the BEATs\nmodel significantly surpasses its counterparts. This superiority underscores\nthe advantage of models trained on diverse audio collections, confirming their\napplicability to a wide array of auditory tasks, including encoding the\nenvironment properties necessary for hearable steering. The DEAR dataset and\nassociated code are available at https://dear-dataset.github.io.",
      "tldr_zh": "该论文引入了 DEAR 数据集和基准，用于评估 foundation models 在 hearables 设备中捕捉声学属性的效能。数据集包含 1,158 个 30 秒音频轨道，通过将专有独白与商业高品质日常声学场景录音混合而成，并涵盖八个任务，包括音频场景的一般上下文、语音来源和技术属性。评估结果显示，BEATs 模型在四个通用音频表示模型中表现最佳，显著优于其他模型，这突出了基于多样音频集合训练的模型在 hearables 环境编码方面的优势。DEAR 数据集和相关代码已公开可用，可从指定链接获取。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.06664v2",
      "published_date": "2025-02-10 16:51:11 UTC",
      "updated_date": "2025-02-24 10:07:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:27:07.804004"
    },
    {
      "arxiv_id": "2502.06656v3",
      "title": "A Frontier AI Risk Management Framework: Bridging the Gap Between Current AI Practices and Established Risk Management",
      "title_zh": "前沿 AI 风险管理框架：桥接当前 AI 实践与已建立风险管理之间的差距",
      "authors": [
        "Simeon Campos",
        "Henry Papadatos",
        "Fabien Roger",
        "Chloé Touzet",
        "Otter Quarks",
        "Malcolm Murray"
      ],
      "abstract": "The recent development of powerful AI systems has highlighted the need for\nrobust risk management frameworks in the AI industry. Although companies have\nbegun to implement safety frameworks, current approaches often lack the\nsystematic rigor found in other high-risk industries. This paper presents a\ncomprehensive risk management framework for the development of frontier AI that\nbridges this gap by integrating established risk management principles with\nemerging AI-specific practices. The framework consists of four key components:\n(1) risk identification (through literature review, open-ended red-teaming, and\nrisk modeling), (2) risk analysis and evaluation using quantitative metrics and\nclearly defined thresholds, (3) risk treatment through mitigation measures such\nas containment, deployment controls, and assurance processes, and (4) risk\ngovernance establishing clear organizational structures and accountability.\nDrawing from best practices in mature industries such as aviation or nuclear\npower, while accounting for AI's unique challenges, this framework provides AI\ndevelopers with actionable guidelines for implementing robust risk management.\nThe paper details how each component should be implemented throughout the\nlife-cycle of the AI system - from planning through deployment - and emphasizes\nthe importance and feasibility of conducting risk management work prior to the\nfinal training run to minimize the burden associated with it.",
      "tldr_zh": "本论文提出一个前沿AI风险管理框架（Frontier AI Risk Management Framework），旨在桥接当前AI实践与成熟行业风险管理（如航空或核能）之间的差距。该框架包括四个关键组件：（1）风险识别（通过文献审查、开放式红队测试和风险建模），（2）风险分析和评估（使用量化指标和明确阈值），（3）风险处理（采用缓解措施如containment、deployment controls和assurance processes），以及（4）风险治理（建立清晰的组织结构和责任）。框架整合了传统风险管理原则与AI特定实践，并在AI系统生命周期中提供可操作指导，强调在最终训练运行前进行风险管理以降低实施负担，从而提升AI开发的系统性和安全性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06656v3",
      "published_date": "2025-02-10 16:47:00 UTC",
      "updated_date": "2025-02-19 16:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:27:20.675654"
    },
    {
      "arxiv_id": "2502.06655v2",
      "title": "Unbiased Evaluation of Large Language Models from a Causal Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Meilin Chen",
        "Jian Tian",
        "Liang Ma",
        "Di Xie",
        "Weijie Chen",
        "Jiang Zhu"
      ],
      "abstract": "Benchmark contamination has become a significant concern in the LLM\nevaluation community. Previous Agents-as-an-Evaluator address this issue by\ninvolving agents in the generation of questions. Despite their success, the\nbiases in Agents-as-an-Evaluator methods remain largely unexplored. In this\npaper, we present a theoretical formulation of evaluation bias, providing\nvaluable insights into designing unbiased evaluation protocols. Furthermore, we\nidentify two type of bias in Agents-as-an-Evaluator through carefully designed\nprobing tasks on a minimal Agents-as-an-Evaluator setup. To address these\nissues, we propose the Unbiased Evaluator, an evaluation protocol that delivers\na more comprehensive, unbiased, and interpretable assessment of LLMs.Extensive\nexperiments reveal significant room for improvement in current LLMs.\nAdditionally, we demonstrate that the Unbiased Evaluator not only offers strong\nevidence of benchmark contamination but also provides interpretable evaluation\nresults.",
      "tldr_zh": "本论文从因果视角探讨了大语言模型（LLMs）的无偏差评估，针对基准污染（benchmark contamination）问题指出了现有Agents-as-an-Evaluator方法中的潜在偏差。作者通过理论公式化评估偏差并设计探测任务，识别了两种具体偏差，并提出Unbiased Evaluator协议，这是一种更全面、无偏差且可解释的评估框架。实验结果显示，当前LLMs存在显著改进空间，且Unbiased Evaluator不仅证明了基准污染的存在，还提供了可解释的评估结果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06655v2",
      "published_date": "2025-02-10 16:45:18 UTC",
      "updated_date": "2025-05-12 14:34:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:27:31.363101"
    },
    {
      "arxiv_id": "2502.06648v2",
      "title": "The 2021 Tokyo Olympics Multilingual News Article Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Erik Novak",
        "Erik Calcina",
        "Dunja Mladenić",
        "Marko Grobelnik"
      ],
      "abstract": "In this paper, we introduce a dataset of multilingual news articles covering\nthe 2021 Tokyo Olympics. A total of 10,940 news articles were gathered from\n1,918 different publishers, covering 1,350 sub-events of the 2021 Olympics, and\npublished between July 1, 2021, and August 14, 2021. These articles are written\nin nine languages from different language families and in different scripts. To\ncreate the dataset, the raw news articles were first retrieved via a service\nthat collects and analyzes news articles. Then, the articles were grouped using\nan online clustering algorithm, with each group containing articles reporting\non the same sub-event. Finally, the groups were manually annotated and\nevaluated. The development of this dataset aims to provide a resource for\nevaluating the performance of multilingual news clustering algorithms, for\nwhich limited datasets are available. It can also be used to analyze the\ndynamics and events of the 2021 Tokyo Olympics from different perspectives. The\ndataset is available in CSV format and can be accessed from the CLARIN.SI\nrepository.",
      "tldr_zh": "本论文介绍了“The 2021 Tokyo Olympics Multilingual News Article Dataset”，一个涵盖2021东京奥运会的多语言新闻文章数据集，共包括10,940篇来自1,918个出版商的文章，覆盖1,350个子事件，并使用九种不同语言和脚本。\n数据集的创建过程涉及通过新闻检索服务收集原始文章，随后使用在线聚类算法（online clustering algorithm）对文章进行分组，最后进行手动标注和评估。\n该数据集可用于评估多语言新闻聚类算法（multilingual news clustering algorithms）的性能，并提供资源分析奥运会动态和事件。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06648v2",
      "published_date": "2025-02-10 16:38:03 UTC",
      "updated_date": "2025-02-13 20:46:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:27:45.152904"
    },
    {
      "arxiv_id": "2502.06635v2",
      "title": "Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building a Chinese-Centric LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Qingshui Gu",
        "Shu Li",
        "Tianyu Zheng",
        "Zhaoxiang Zhang"
      ],
      "abstract": "Steel-LLM is a Chinese-centric language model developed from scratch with the\ngoal of creating a high-quality, open-source model despite limited\ncomputational resources. Launched in March 2024, the project aimed to train a\n1-billion-parameter model on a large-scale dataset, prioritizing transparency\nand the sharing of practical insights to assist others in the community. The\ntraining process primarily focused on Chinese data, with a small proportion of\nEnglish data included, addressing gaps in existing open-source LLMs by\nproviding a more detailed and practical account of the model-building journey.\nSteel-LLM has demonstrated competitive performance on benchmarks such as CEVAL\nand CMMLU, outperforming early models from larger institutions. This paper\nprovides a comprehensive summary of the project's key contributions, including\ndata collection, model design, training methodologies, and the challenges\nencountered along the way, offering a valuable resource for researchers and\npractitioners looking to develop their own LLMs. The model checkpoints and\ntraining script are available at https://github.com/zhanshijinwat/Steel-LLM.",
      "tldr_zh": "Steel-LLM 是一个从零开始开发的、以中文为中心的开源语言模型（LLM），旨在在计算资源有限的情况下构建高品质模型，并通过透明分享实际见解来填补现有开源 LLM 的空白。项目主要使用大规模中文数据集（辅以少量英文数据）进行训练，涵盖数据收集、模型设计和训练方法等方面，同时详细记录了遇到的挑战。实验结果显示，Steel-LLM 在 CEVAL 和 CMMLU 等基准测试中表现出色，超越了某些大型机构的早期模型。该模型的检查点和训练脚本已在 GitHub 上开源，提供宝贵资源供研究者和从业者参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06635v2",
      "published_date": "2025-02-10 16:31:37 UTC",
      "updated_date": "2025-02-13 07:31:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:27:56.125370"
    },
    {
      "arxiv_id": "2502.06634v1",
      "title": "Automatic Annotation Augmentation Boosts Translation between Molecules and Natural Language",
      "title_zh": "自动注释增强提升分子与自然语言之间的翻译",
      "authors": [
        "Zhiqiang Zhong",
        "Simon Sataa-Yu Larsen",
        "Haoyu Guo",
        "Tao Tang",
        "Kuangyu Zhou",
        "Davide Mottin"
      ],
      "abstract": "Recent advancements in AI for biological research focus on integrating\nmolecular data with natural language to accelerate drug discovery. However, the\nscarcity of high-quality annotations limits progress in this area. This paper\nintroduces LA$^3$, a Language-based Automatic Annotation Augmentation framework\nthat leverages large language models to augment existing datasets, thereby\nimproving AI training. We demonstrate the effectiveness of LA$^3$ by creating\nan enhanced dataset, LaChEBI-20, where we systematically rewrite the\nannotations of molecules from an established dataset. These rewritten\nannotations preserve essential molecular information while providing more\nvaried sentence structures and vocabulary. Using LaChEBI-20, we train LaMolT5\nbased on a benchmark architecture to learn the mapping between molecular\nrepresentations and augmented annotations.\n  Experimental results on text-based *de novo* molecule generation and molecule\ncaptioning demonstrate that LaMolT5 outperforms state-of-the-art models.\nNotably, incorporating LA$^3$ leads to improvements of up to 301% over the\nbenchmark architecture. Furthermore, we validate the effectiveness of LA$^3$\nnotable applications in *image*, *text* and *graph* tasks, affirming its\nversatility and utility.",
      "tldr_zh": "本研究提出LA$^3$框架，利用大型语言模型自动增强分子数据集的标注，以解决AI在生物研究中整合分子数据和自然语言时标注稀缺的问题。研究通过系统重写现有数据集的标注，创建了增强版LaChEBI-20数据集，确保保留了核心分子信息的同时增加了句子多样性，并以此训练LaMolT5模型来学习分子表示与标注之间的映射。实验结果显示，LaMolT5在文本-based *de novo* 分子生成和分子描述任务中优于最先进模型，提升高达301%，并在图像、文本和图任务中验证了LA$^3$的通用性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06634v1",
      "published_date": "2025-02-10 16:29:21 UTC",
      "updated_date": "2025-02-10 16:29:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:28:08.016250"
    },
    {
      "arxiv_id": "2502.06633v1",
      "title": "Combining Large Language Models with Static Analyzers for Code Review Generation",
      "title_zh": "将大语言模型与静态分析器结合用于代码审查生成",
      "authors": [
        "Imen Jaoua",
        "Oussama Ben Sghaier",
        "Houari Sahraoui"
      ],
      "abstract": "Code review is a crucial but often complex, subjective, and time-consuming\nactivity in software development. Over the past decades, significant efforts\nhave been made to automate this process. Early approaches focused on\nknowledge-based systems (KBS) that apply rule-based mechanisms to detect code\nissues, providing precise feedback but struggling with complex,\ncontext-dependent cases. More recent work has shifted toward fine-tuning\npre-trained language models for code review, enabling broader issue coverage\nbut often at the expense of precision. In this paper, we propose a hybrid\napproach that combines the strengths of KBS and learning-based systems (LBS) to\ngenerate high-quality, comprehensive code reviews. Our method integrates\nknowledge at three distinct stages of the language model pipeline: during data\npreparation (Data-Augmented Training, DAT), at inference (Retrieval-Augmented\nGeneration, RAG), and after inference (Naive Concatenation of Outputs, NCO). We\nempirically evaluate our combination strategies against standalone KBS and LBS\nfine-tuned on a real-world dataset. Our results show that these hybrid\nstrategies enhance the relevance, completeness, and overall quality of review\ncomments, effectively bridging the gap between rule-based tools and deep\nlearning models.",
      "tldr_zh": "该论文提出了一种混合方法，将 Large Language Models 与 Static Analyzers 结合，用于生成高质量的代码审查，从而克服了基于知识的系统 (KBS) 的精确性局限和基于学习的系统 (LBS) 的精度问题。该方法在语言模型管道的三个阶段整合知识：数据准备阶段的 Data-Augmented Training (DAT)、推理阶段的 Retrieval-Augmented Generation (RAG)，以及推理后的 Naive Concatenation of Outputs (NCO)。实验结果显示，这种策略在真实数据集上显著提升了审查评论的相关性、完整性和整体质量，有效桥接了规则工具和深度学习模型的差距。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06633v1",
      "published_date": "2025-02-10 16:29:12 UTC",
      "updated_date": "2025-02-10 16:29:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:28:21.684150"
    },
    {
      "arxiv_id": "2502.06632v1",
      "title": "Few-Shot Classification and Anatomical Localization of Tissues in SPECT Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed Abdul Hafeez Khan",
        "Samuel Morries Boddepalli",
        "Siddhartha Bhattacharyya",
        "Debasis Mitra"
      ],
      "abstract": "Accurate classification and anatomical localization are essential for\neffective medical diagnostics and research, which may be efficiently performed\nusing deep learning techniques. However, availability of limited labeled data\nposes a significant challenge. To address this, we adapted Prototypical\nNetworks and the Propagation-Reconstruction Network (PRNet) for few-shot\nclassification and localization, respectively, in Single Photon Emission\nComputed Tomography (SPECT) images. For the proof of concept we used a\n2D-sliced image cropped around heart. The Prototypical Network, with a\npre-trained ResNet-18 backbone, classified ventricles, myocardium, and liver\ntissues with 96.67% training and 93.33% validation accuracy. PRNet, adapted for\n2D imaging with an encoder-decoder architecture and skip connections, achieved\na training loss of 1.395, accurately reconstructing patches and capturing\nspatial relationships. These results highlight the potential of Prototypical\nNetworks for tissue classification with limited labeled data and PRNet for\nanatomical landmark localization, paving the way for improved performance in\ndeep learning frameworks.",
      "tldr_zh": "本研究针对SPECT图像中组织分类和解剖定位的挑战，特别是在标签数据有限的情况下，适应了Prototypical Networks用于少样本分类，以及PRNet用于定位。Prototypical Networks采用预训练的ResNet-18骨干网络，对心室、心肌和肝脏组织实现了96.67%的训练准确率和93.33%的验证准确率。PRNet通过编码器-解码器架构和跳跃连接，达到了1.395的训练损失，并准确重建图像补丁及捕获空间关系。这些结果证明了这些方法在少样本数据下的潜力，为SPECT图像深度学习框架的性能提升铺平了道路。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "2 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06632v1",
      "published_date": "2025-02-10 16:28:35 UTC",
      "updated_date": "2025-02-10 16:28:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:28:34.364772"
    },
    {
      "arxiv_id": "2502.06631v1",
      "title": "Conformal Predictions for Human Action Recognition with Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bary Tim",
        "Fuchs Clément",
        "Macq Benoît"
      ],
      "abstract": "Human-In-The-Loop (HITL) frameworks are integral to many real-world computer\nvision systems, enabling human operators to make informed decisions with AI\nassistance. Conformal Predictions (CP), which provide label sets with rigorous\nguarantees on ground truth inclusion probabilities, have recently gained\ntraction as a valuable tool in HITL settings. One key application area is video\nsurveillance, closely associated with Human Action Recognition (HAR). This\nstudy explores the application of CP on top of state-of-the-art HAR methods\nthat utilize extensively pre-trained Vision-Language Models (VLMs). Our\nfindings reveal that CP can significantly reduce the average number of\ncandidate classes without modifying the underlying VLM. However, these\nreductions often result in distributions with long tails. To address this, we\nintroduce a method based on tuning the temperature parameter of the VLMs to\nminimize these tails without requiring additional calibration data. Our code is\nmade available on GitHub at the address https://github.com/tbary/CP4VLM.",
      "tldr_zh": "本研究探讨了 Conformal Predictions (CP) 在 Human Action Recognition (HAR) 中的应用，旨在为 Human-In-The-Loop (HITL) 框架提供可靠的标签集保证。研究发现，通过在基于预训练 Vision-Language Models (VLMs) 的 HAR 方法上应用 CP，可以显著减少候选类别的平均数量，而无需修改底层模型。然而，这往往导致分布出现长尾问题。为解决此问题，作者提出了一种调整 VLM 温度参数的方法，以最小化长尾分布，且不需额外校准数据。该方法为视频监控等领域的 AI 辅助决策提供了更高效且可靠的工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06631v1",
      "published_date": "2025-02-10 16:27:20 UTC",
      "updated_date": "2025-02-10 16:27:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:28:45.330830"
    },
    {
      "arxiv_id": "2502.06920v1",
      "title": "Direct Estimation of Pediatric Heart Rate Variability from BOLD-fMRI: A Machine Learning Approach Using Dynamic Connectivity",
      "title_zh": "翻译失败",
      "authors": [
        "Abdoljalil Addeh",
        "Karen Ardila",
        "Rebecca J Williams",
        "G. Bruce Pike",
        "M. Ethan MacDonald"
      ],
      "abstract": "In many pediatric fMRI studies, cardiac signals are often missing or of poor\nquality. A tool to extract Heart Rate Variation (HRV) waveforms directly from\nfMRI data, without the need for peripheral recording devices, would be highly\nbeneficial. We developed a machine learning framework to accurately reconstruct\nHRV for pediatric applications. A hybrid model combining one-dimensional\nConvolutional Neural Networks (1D-CNN) and Gated Recurrent Units (GRU) analyzed\nBOLD signals from 628 ROIs, integrating past and future data. The model\nachieved an 8% improvement in HRV accuracy, as evidenced by enhanced\nperformance metrics. This approach eliminates the need for peripheral\nphotoplethysmography devices, reduces costs, and simplifies procedures in\npediatric fMRI. Additionally, it improves the robustness of pediatric fMRI\nstudies, which are more sensitive to physiological and developmental variations\nthan those in adults.",
      "tldr_zh": "这篇论文提出了一种机器学习方法，直接从BOLD-fMRI数据中估计儿科Heart Rate Variability (HRV)，以解决心脏信号缺失或质量差的问题，无需外围记录设备。方法采用1D-CNN和GRU的混合模型，分析来自628个ROIs的BOLD信号，并整合动态连接性以处理过去和未来的数据。结果显示，HRV准确性提高了8%，通过增强的性能指标验证；此方法简化儿科fMRI程序、降低成本，并提升研究的稳健性，尤其适用于生理和发育变化敏感的儿科场景。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG",
        "68T07 (Primary), 92C55, 62P10 (Secondary)"
      ],
      "primary_category": "eess.IV",
      "comment": "5 pages, 5 figures, ISMSMR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06920v1",
      "published_date": "2025-02-10 16:24:18 UTC",
      "updated_date": "2025-02-10 16:24:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:28:57.555300"
    },
    {
      "arxiv_id": "2502.06608v3",
      "title": "TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models",
      "title_zh": "TripoSG：使用大规模修正流模型的高保真 3D 形状合成",
      "authors": [
        "Yangguang Li",
        "Zi-Xin Zou",
        "Zexiang Liu",
        "Dehu Wang",
        "Yuan Liang",
        "Zhipeng Yu",
        "Xingchao Liu",
        "Yuan-Chen Guo",
        "Ding Liang",
        "Wanli Ouyang",
        "Yan-Pei Cao"
      ],
      "abstract": "Recent advancements in diffusion techniques have propelled image and video\ngeneration to unprecedented levels of quality, significantly accelerating the\ndeployment and application of generative AI. However, 3D shape generation\ntechnology has so far lagged behind, constrained by limitations in 3D data\nscale, complexity of 3D data processing, and insufficient exploration of\nadvanced techniques in the 3D domain. Current approaches to 3D shape generation\nface substantial challenges in terms of output quality, generalization\ncapability, and alignment with input conditions. We present TripoSG, a new\nstreamlined shape diffusion paradigm capable of generating high-fidelity 3D\nmeshes with precise correspondence to input images. Specifically, we propose:\n1) A large-scale rectified flow transformer for 3D shape generation, achieving\nstate-of-the-art fidelity through training on extensive, high-quality data. 2)\nA hybrid supervised training strategy combining SDF, normal, and eikonal losses\nfor 3D VAE, achieving high-quality 3D reconstruction performance. 3) A data\nprocessing pipeline to generate 2 million high-quality 3D samples, highlighting\nthe crucial rules for data quality and quantity in training 3D generative\nmodels. Through comprehensive experiments, we have validated the effectiveness\nof each component in our new framework. The seamless integration of these parts\nhas enabled TripoSG to achieve state-of-the-art performance in 3D shape\ngeneration. The resulting 3D shapes exhibit enhanced detail due to\nhigh-resolution capabilities and demonstrate exceptional fidelity to input\nimages. Moreover, TripoSG demonstrates improved versatility in generating 3D\nmodels from diverse image styles and contents, showcasing strong generalization\ncapabilities. To foster progress and innovation in the field of 3D generation,\nwe will make our model publicly available.",
      "tldr_zh": "本论文介绍了TripoSG，一种高保真3D形状生成框架，使用大规模rectified flow transformer模型，通过训练超过200万高质量3D样本，解决了现有3D生成技术在输出质量、泛化能力和输入对齐方面的挑战。TripoSG的关键创新包括一个混合监督训练策略，结合SDF、normal和eikonal损失来优化3D VAE，实现精确的3D重建，以及一个高效的数据处理管道来提升模型性能。实验验证显示，该框架在3D形状生成中达到最先进水平，生成的3D网格具有高分辨率细节和对输入图像的出色忠实度，并展示了强大的泛化能力，模型将公开以推动领域发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06608v3",
      "published_date": "2025-02-10 16:07:54 UTC",
      "updated_date": "2025-03-27 17:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:29:10.179336"
    },
    {
      "arxiv_id": "2502.06919v2",
      "title": "Select before Act: Spatially Decoupled Action Repetition for Continuous Control",
      "title_zh": "翻译失败",
      "authors": [
        "Buqing Nie",
        "Yangqing Fu",
        "Yue Gao"
      ],
      "abstract": "Reinforcement Learning (RL) has achieved remarkable success in various\ncontinuous control tasks, such as robot manipulation and locomotion. Different\nto mainstream RL which makes decisions at individual steps, recent studies have\nincorporated action repetition into RL, achieving enhanced action persistence\nwith improved sample efficiency and superior performance. However, existing\nmethods treat all action dimensions as a whole during repetition, ignoring\nvariations among them. This constraint leads to inflexibility in decisions,\nwhich reduces policy agility with inferior effectiveness. In this work, we\npropose a novel repetition framework called SDAR, which implements Spatially\nDecoupled Action Repetition through performing closed-loop act-or-repeat\nselection for each action dimension individually. SDAR achieves more flexible\nrepetition strategies, leading to an improved balance between action\npersistence and diversity. Compared to existing repetition frameworks, SDAR is\nmore sample efficient with higher policy performance and reduced action\nfluctuation. Experiments are conducted on various continuous control scenarios,\ndemonstrating the effectiveness of spatially decoupled repetition design\nproposed in this work.",
      "tldr_zh": "本文研究发现，现有的 Reinforcement Learning (RL) 方法在连续控制任务中虽通过动作重复提升了样本效率和性能，但因将所有动作维度视为整体，导致决策不灵活。作者提出了一种新框架 SDAR (Spatially Decoupled Action Repetition)，通过对每个动作维度独立进行闭环的 act-or-repeat 选择，实现更灵活的重复策略，从而平衡动作持久性和多样性。与现有方法相比，SDAR 显著提高了样本效率、政策性能并减少了动作波动，在各种连续控制场景的实验中证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06919v2",
      "published_date": "2025-02-10 16:07:28 UTC",
      "updated_date": "2025-03-06 05:25:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:29:20.921971"
    },
    {
      "arxiv_id": "2503.04760v1",
      "title": "Agentic AI and the Cyber Arms Race",
      "title_zh": "翻译失败",
      "authors": [
        "Sean Oesch",
        "Jack Hutchins",
        "Phillipe Austria",
        "Amul Chaulagain"
      ],
      "abstract": "Agentic AI is shifting the cybersecurity landscape as attackers and defenders\nleverage AI agents to augment humans and automate common tasks. In this\narticle, we examine the implications for cyber warfare and global politics as\nAgentic AI becomes more powerful and enables the broad proliferation of\ncapabilities only available to the most well resourced actors today.",
      "tldr_zh": "这篇文章探讨了 Agentic AI 如何改变网络安全格局，攻击者和防御者利用 AI 代理增强人类能力并自动化常见任务。作者分析了 Agentic AI 的增强可能加剧网络战争，并对全球政治产生深远影响。最终，该研究强调 Agentic AI 的广泛扩散将使原本仅限于资源丰富的实体的高级能力普及开来，从而引发新的安全挑战。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "4 pages, 1 figure, due to be published in Computer Magazine",
      "pdf_url": "http://arxiv.org/pdf/2503.04760v1",
      "published_date": "2025-02-10 16:06:29 UTC",
      "updated_date": "2025-02-10 16:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:29:32.123710"
    },
    {
      "arxiv_id": "2502.06607v3",
      "title": "Illegal Waste Detection in Remote Sensing Images: A Case Study",
      "title_zh": "遥感图像中的非法废物检测：一个案例研究",
      "authors": [
        "Federico Gibellini",
        "Piero Fraternali",
        "Giacomo Boracchi",
        "Luca Morandini",
        "Thomas Martinoli",
        "Andrea Diecidue",
        "Simona Malegori"
      ],
      "abstract": "Environmental crime is the third largest criminal activity worldwide, with\nsignificant revenues coming from illegal management of solid waste. Thanks to\nthe increasing availability and the decreasing cost of Very High Resolution\nRemote Sensing (VHR RS) images, the fight against environmental crime can\nnowadays rely on modern image-analysis tools to support photo-interpretation\nfor scanning vast territories in search of illegal waste disposal sites. This\npaper illustrates a semi-automatic waste detection pipeline, developed in\ncollaboration with a regional environmental protection agency, for detecting\ncandidate illegal dumping sites in VHR RS images. To optimize the effectiveness\nof the waste detector, extensive experiments evaluate such design choices as\nthe network architecture, the ground resolution and geographic span of the\ninput images, as well as the pretraining procedures. The best model attains\nremarkable performance, achieving 92.02% F1-Score and 94.56% Accuracy. A\ngeneralization study assesses the performance variation when the detector\nprocesses images from a territory substantially different from the one used\nduring training, incurring only a moderate performance loss, i.e., 6.5%\ndecrease in the F1-Score. Finally, an exercise in which photo interpreters\ncompare the territory scanning effort with and without the support of the waste\ndetector assesses the concrete benefit of using a computer-aided image analysis\ntool in a professional environment protection agency. Results show that a\nreduction up to 30% of the time spent for waste site detection can be attained.",
      "tldr_zh": "本文提出了一种半自动废物检测管道，用于在Very High Resolution Remote Sensing (VHR RS) images中识别非法废物倾倒现场，作为与地区环境保护机构合作的一个案例研究。该管道通过优化网络架构、图像分辨率、地理范围和预训练程序，实现了最佳模型的92.02% F1-Score和94.56% Accuracy表现。泛化实验显示，该模型在不同区域图像上的性能仅下降6.5% F1-Score，并在实际应用中帮助减少30%的现场检测时间，从而提升了环境犯罪监测效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06607v3",
      "published_date": "2025-02-10 16:04:54 UTC",
      "updated_date": "2025-05-15 08:22:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:29:45.547751"
    },
    {
      "arxiv_id": "2502.06601v1",
      "title": "Amortized In-Context Bayesian Posterior Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Sarthak Mittal",
        "Niels Leif Bracher",
        "Guillaume Lajoie",
        "Priyank Jaini",
        "Marcus Brubaker"
      ],
      "abstract": "Bayesian inference provides a natural way of incorporating prior beliefs and\nassigning a probability measure to the space of hypotheses. Current solutions\nrely on iterative routines like Markov Chain Monte Carlo (MCMC) sampling and\nVariational Inference (VI), which need to be re-run whenever new observations\nare available. Amortization, through conditional estimation, is a viable\nstrategy to alleviate such difficulties and has been the guiding principle\nbehind simulation-based inference, neural processes and in-context methods\nusing pre-trained models. In this work, we conduct a thorough comparative\nanalysis of amortized in-context Bayesian posterior estimation methods from the\nlens of different optimization objectives and architectural choices. Such\nmethods train an amortized estimator to perform posterior parameter inference\nby conditioning on a set of data examples passed as context to a sequence model\nsuch as a transformer. In contrast to language models, we leverage permutation\ninvariant architectures as the true posterior is invariant to the ordering of\ncontext examples. Our empirical study includes generalization to\nout-of-distribution tasks, cases where the assumed underlying model is\nmisspecified, and transfer from simulated to real problems. Subsequently, it\nhighlights the superiority of the reverse KL estimator for predictive problems,\nespecially when combined with the transformer architecture and normalizing\nflows.",
      "tldr_zh": "本文提出了一种Amortized In-Context Bayesian Posterior Estimation方法，通过条件估计来解决传统Bayesian推理（如MCMC和VI）的重新计算问题，实现高效的后验参数推断。研究对不同优化目标和架构（如permutation invariant architectures和transformer）进行了全面比较分析，强调了在序列模型中利用上下文数据例子进行训练的优势。实验结果显示，reverse KL estimator在预测问题中表现出色，尤其与transformer和normalizing flows结合时，能够实现对分布外任务、模型错配以及从模拟到真实问题的良好泛化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06601v1",
      "published_date": "2025-02-10 16:00:48 UTC",
      "updated_date": "2025-02-10 16:00:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:29:57.050702"
    },
    {
      "arxiv_id": "2502.06600v2",
      "title": "Evaluation of Multilingual Image Captioning: How far can we get with CLIP models?",
      "title_zh": "翻译失败",
      "authors": [
        "Gonçalo Gomes",
        "Chrysoula Zerva",
        "Bruno Martins"
      ],
      "abstract": "The evaluation of image captions, looking at both linguistic fluency and\nsemantic correspondence to visual contents, has witnessed a significant effort.\nStill, despite advancements such as the CLIPScore metric, multilingual\ncaptioning evaluation has remained relatively unexplored. This work presents\nseveral strategies, and extensive experiments, related to evaluating CLIPScore\nvariants in multilingual settings. To address the lack of multilingual test\ndata, we consider two different strategies: (1) using quality aware\nmachine-translated datasets with human judgements, and (2) re-purposing\nmultilingual datasets that target semantic inference and reasoning. Our results\nhighlight the potential of finetuned multilingual models to generalize across\nlanguages and to handle complex linguistic challenges. Tests with\nmachine-translated data show that multilingual CLIPScore models can maintain a\nhigh correlation with human judgements across different languages, and\nadditional tests with natively multilingual and multicultural data further\nattest to the high-quality assessments.",
      "tldr_zh": "本研究评估了多语言图像标题生成模型的性能，焦点在于 CLIPScore 指标及其在多语言环境下的应用，探讨了 CLIP 模型的潜力。作者提出了两种策略来解决多语言测试数据不足的问题：(1) 使用质量感知的机器翻译数据集结合人工判断，(2) 重新利用针对语义推理的多语言数据集。通过广泛实验，结果显示微调的多语言 CLIPScore 模型能够跨语言泛化，并有效处理复杂的语言挑战，在不同语言中与人工判断保持高相关性。总的来说，这为多语言图像标题评估提供了可靠的方法论基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in Findings of NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06600v2",
      "published_date": "2025-02-10 16:00:00 UTC",
      "updated_date": "2025-02-17 15:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:30:08.814214"
    },
    {
      "arxiv_id": "2502.06589v1",
      "title": "Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training",
      "title_zh": "Hephaestus：通过持续预训练提升大型语言模型的基础代理能力",
      "authors": [
        "Yuchen Zhuang",
        "Jingfeng Yang",
        "Haoming Jiang",
        "Xin Liu",
        "Kewei Cheng",
        "Sanket Lokegaonkar",
        "Yifan Gao",
        "Qing Ping",
        "Tianyi Liu",
        "Binxuan Huang",
        "Zheng Li",
        "Zhengyang Wang",
        "Pei Chen",
        "Ruijie Wang",
        "Rongzhi Zhang",
        "Nasser Zalmout",
        "Priyanka Nigam",
        "Bing Yin",
        "Chao Zhang"
      ],
      "abstract": "Due to the scarcity of agent-oriented pre-training data, LLM-based autonomous\nagents typically rely on complex prompting or extensive fine-tuning, which\noften fails to introduce new capabilities while preserving strong\ngeneralizability. We introduce Hephaestus-Forge, the first large-scale\npre-training corpus designed to enhance the fundamental capabilities of LLM\nagents in API function calling, intrinsic reasoning and planning, and adapting\nto environmental feedback. Hephaestus-Forge comprises 103B agent-specific data\nencompassing 76,537 APIs, including both tool documentation to introduce\nknowledge of API functions and function calling trajectories to strengthen\nintrinsic reasoning. To explore effective training protocols, we investigate\nscaling laws to identify the optimal recipe in data mixing ratios. By continual\npre-training on Hephaestus-Forge, Hephaestus outperforms small- to medium-scale\nopen-source LLMs and rivals commercial LLMs on three agent benchmarks,\ndemonstrating the effectiveness of our pre-training corpus in enhancing\nfundamental agentic capabilities and generalization of LLMs to new tasks or\nenvironments.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）代理能力的提升问题，引入了Hephaestus-Forge，这是首个大规模预训练语料库，包含103B代理特定数据和76,537 APIs，包括工具文档用于引入API知识，以及函数调用轨迹强化内在推理和规划。研究者通过调查缩放定律优化数据混合比率，并采用continual pre-training协议训练Hephaestus模型。实验结果显示，Hephaestus在三个代理基准上超过了小型到中型开源LLMs，并与商业LLMs相当，证明了该语料库在增强LLMs的根本代理能力和任务泛化方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2502.06589v1",
      "published_date": "2025-02-10 15:54:34 UTC",
      "updated_date": "2025-02-10 15:54:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:30:23.202831"
    },
    {
      "arxiv_id": "2502.06577v1",
      "title": "The Minimal Search Space for Conditional Causal Bandits",
      "title_zh": "条件因果老虎机的最小搜索空间",
      "authors": [
        "Francisco N. F. Q. Simoes",
        "Itai Feigenbaum",
        "Mehdi Dastani",
        "Thijs van Ommen"
      ],
      "abstract": "Causal knowledge can be used to support decision-making problems. This has\nbeen recognized in the causal bandits literature, where a causal (multi-armed)\nbandit is characterized by a causal graphical model and a target variable. The\narms are then interventions on the causal model, and rewards are samples of the\ntarget variable. Causal bandits were originally studied with a focus on hard\ninterventions. We focus instead on cases where the arms are conditional\ninterventions, which more accurately model many real-world decision-making\nproblems by allowing the value of the intervened variable to be chosen based on\nthe observed values of other variables. This paper presents a graphical\ncharacterization of the minimal set of nodes guaranteed to contain the optimal\nconditional intervention, which maximizes the expected reward. We then propose\nan efficient algorithm with a time complexity of $O(|V| + |E|)$ to identify\nthis minimal set of nodes. We prove that the graphical characterization and the\nproposed algorithm are correct. Finally, we empirically demonstrate that our\nalgorithm significantly prunes the search space and substantially accelerates\nconvergence rates when integrated into standard multi-armed bandit algorithms.",
      "tldr_zh": "该论文探讨了在因果多臂赌博机(causal bandits)中，使用条件干预(conditional interventions)来优化决策问题，这些干预允许基于其他变量的值选择干预变量，从而更符合现实场景。论文提供了一个图形化表征(graphical characterization)，标识出保证包含最优条件干预的最小节点集，以最大化预期奖励，并提出了一种高效算法，时间复杂度为O(|V| + |E|)。实验证明，该算法显著减少搜索空间并加速标准多臂赌博机算法的收敛速度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to ICML2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06577v1",
      "published_date": "2025-02-10 15:45:18 UTC",
      "updated_date": "2025-02-10 15:45:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:30:34.622559"
    },
    {
      "arxiv_id": "2502.06575v1",
      "title": "Predictive Red Teaming: Breaking Policies Without Breaking Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Anirudha Majumdar",
        "Mohit Sharma",
        "Dmitry Kalashnikov",
        "Sumeet Singh",
        "Pierre Sermanet",
        "Vikas Sindhwani"
      ],
      "abstract": "Visuomotor policies trained via imitation learning are capable of performing\nchallenging manipulation tasks, but are often extremely brittle to lighting,\nvisual distractors, and object locations. These vulnerabilities can depend\nunpredictably on the specifics of training, and are challenging to expose\nwithout time-consuming and expensive hardware evaluations. We propose the\nproblem of predictive red teaming: discovering vulnerabilities of a policy with\nrespect to environmental factors, and predicting the corresponding performance\ndegradation without hardware evaluations in off-nominal scenarios. In order to\nachieve this, we develop RoboART: an automated red teaming (ART) pipeline that\n(1) modifies nominal observations using generative image editing to vary\ndifferent environmental factors, and (2) predicts performance under each\nvariation using a policy-specific anomaly detector executed on edited\nobservations. Experiments across 500+ hardware trials in twelve off-nominal\nconditions for visuomotor diffusion policies demonstrate that RoboART predicts\nperformance degradation with high accuracy (less than 0.19 average difference\nbetween predicted and real success rates). We also demonstrate how predictive\nred teaming enables targeted data collection: fine-tuning with data collected\nunder conditions predicted to be adverse boosts baseline performance by 2-7x.",
      "tldr_zh": "本文提出预测性红队测试（predictive red teaming）方法，用于识别通过模仿学习训练的视动策略（visuomotor policies）对照明、视觉干扰和物体位置等环境因素的脆弱性，并预测非标准场景下的性能下降，而无需耗时硬件评估。作者开发了RoboART框架，该框架通过生成式图像编辑修改观察数据，并利用策略特定的异常检测器在编辑观察上预测性能。实验在500+硬件试验中验证了RoboART的准确性（预测和实际成功率平均差异小于0.19），并展示了通过针对这些不利条件收集数据进行微调，能将基线性能提升2-7倍。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06575v1",
      "published_date": "2025-02-10 15:44:34 UTC",
      "updated_date": "2025-02-10 15:44:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:30:47.451007"
    },
    {
      "arxiv_id": "2502.06574v1",
      "title": "On the Impact of the Utility in Semivalue-based Data Valuation",
      "title_zh": "翻译失败",
      "authors": [
        "Mélissa Tamine",
        "Benjamin Heymann",
        "Patrick Loiseau",
        "Maxime Vono"
      ],
      "abstract": "Semivalue-based data valuation in machine learning (ML) quantifies the\ncontribution of individual data points to a downstream ML task by leveraging\nprinciples from cooperative game theory and the notion of utility. While this\nframework has been used in practice for assessing data quality, our experiments\nreveal inconsistent valuation outcomes across different utilities, albeit all\nrelated to ML performance. Beyond raising concerns about the reliability of\ndata valuation, this inconsistency is challenging to interpret, as it stems\nfrom the complex interaction of the utility with data points and semivalue\nweights, which has barely been studied in prior work. In this paper, we take a\nfirst step toward clarifying the utility impact on semivalue-based data\nvaluation. Specifically, we provide geometric interpretations of this impact\nfor a broad family of classification utilities, which includes the accuracy and\nthe arithmetic mean. We introduce the notion of spatial signatures: given a\nsemivalue, data points can be embedded into a two-dimensional space, and\nutility functions map to the dual of this space. This geometric perspective\nseparates the influence of the dataset and semivalue from that of the utility,\nproviding a theoretical explanation for the experimentally observed sensitivity\nof valuation outcomes to the utility choice.",
      "tldr_zh": "这篇论文探讨了在机器学习中，Semivalue-based data valuation 的效用（utility）函数对数据点贡献估值的冲击，实验显示不同 utility（如与 ML 性能相关的 accuracy 和 arithmetic mean）会导致估值结果不一致，从而质疑估值的可靠性。作者通过几何解释分析了这一影响，引入了 spatial signatures 概念，将数据点嵌入二维空间，并让 utility 函数映射到该空间的对偶空间。这样的视角分离了数据集、semivalue 和 utility 的作用，提供理论解释，揭示了估值敏感性的根源。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "34 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06574v1",
      "published_date": "2025-02-10 15:42:38 UTC",
      "updated_date": "2025-02-10 15:42:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:30:59.428557"
    },
    {
      "arxiv_id": "2502.06572v2",
      "title": "LawGPT: Knowledge-Guided Data Generation and Its Application to Legal LLM",
      "title_zh": "LawGPT：知识引导的数据生成及其在法律LLM中的应用",
      "authors": [
        "Zhi Zhou",
        "Kun-Yang Yu",
        "Shi-Yu Tian",
        "Xiao-Wen Yang",
        "Jiang-Xin Shi",
        "Pengxiao Song",
        "Yi-Xuan Jin",
        "Lan-Zhe Guo",
        "Yu-Feng Li"
      ],
      "abstract": "Large language models (LLMs), both proprietary and open-source, have\ndemonstrated remarkable capabilities across various natural language processing\ntasks. However, they face significant limitations in legal reasoning tasks.\nProprietary models introduce data privacy risks and high inference costs, while\nopen-source models underperform due to insufficient legal domain training data.\nTo address these limitations, we study data generation for legal reasoning to\nimprove the legal reasoning performance of open-source LLMs with the help of\nproprietary LLMs. This is challenging due to the lack of legal knowledge in\nproprietary LLMs and the difficulty in verifying the generated data. We propose\nKgDG, a knowledge-guided data generation framework for legal reasoning. Our\nframework enables leveraging legal knowledge to enhance generation diversity\nand introduces a refinement and verification process to ensure the quality of\ngenerated data. Moreover, we expand the generated dataset to further enhance\nthe LLM reasoning capabilities. Using KgDG, we create a synthetic legal\nreasoning dataset containing 50K high-quality examples. Our trained model\nLawGPT outperforms existing legal-specific LLMs and achieves performance\ncomparable to proprietary LLMs, demonstrating the effectiveness of KgDG and\nLawGPT. Our code and resources is publicly available at\nhttps://github.com/LAMDASZ-ML/Knowledge-Guide-Data-Generation .",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在法律推理任务中的局限性（如专有模型的隐私和成本问题，以及开源模型的数据不足），提出了一种知识引导的数据生成框架（KgDG）。KgDG 通过利用法律知识增强生成数据的多样性，并引入精炼和验证过程，确保数据质量，同时扩展数据集以提升 LLM 的推理能力。利用该框架，研究者创建了包含 50K 高质量例子的合成法律推理数据集，并训练出 LawGPT 模型，该模型在性能上超过了现有法律特定 LLMs，并与专有 LLMs 相当。代码和资源已公开可用，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.06572v2",
      "published_date": "2025-02-10 15:40:35 UTC",
      "updated_date": "2025-02-13 07:24:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:31:11.282987"
    },
    {
      "arxiv_id": "2502.06918v1",
      "title": "Leveraging GPT-4o Efficiency for Detecting Rework Anomaly in Business Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Derakhshan",
        "Paolo Ceravolo",
        "Fatemeh Mohammadi"
      ],
      "abstract": "This paper investigates the effectiveness of GPT-4o-2024-08-06, one of the\nLarge Language Models (LLM) from OpenAI, in detecting business process\nanomalies, with a focus on rework anomalies. In our study, we developed a\nGPT-4o-based tool capable of transforming event logs into a structured format\nand identifying reworked activities within business event logs. The analysis\nwas performed on a synthetic dataset designed to contain rework anomalies but\nfree of loops. To evaluate the anomaly detection capabilities of GPT\n4o-2024-08-06, we used three prompting techniques: zero-shot, one-shot, and\nfew-shot. These techniques were tested on different anomaly distributions,\nnamely normal, uniform, and exponential, to identify the most effective\napproach for each case. The results demonstrate the strong performance of\nGPT-4o-2024-08-06. On our dataset, the model achieved 96.14% accuracy with\none-shot prompting for the normal distribution, 97.94% accuracy with few-shot\nprompting for the uniform distribution, and 74.21% accuracy with few-shot\nprompting for the exponential distribution. These results highlight the model's\npotential as a reliable tool for detecting rework anomalies in event logs and\nhow anomaly distribution and prompting strategy influence the model's\nperformance.",
      "tldr_zh": "本论文探讨了利用 GPT-4o-2024-08-06 检测业务流程中 rework anomalies 的有效性，开发了一个基于该模型的工具，将事件日志转换为结构化格式并识别异常。研究使用了零样本（zero-shot）、一样本（one-shot）和少样本（few-shot）提示技术，在包含正常、均匀和指数分布的合成数据集上进行测试。结果显示，one-shot 提示在正常分布下准确率达 96.14%，few-shot 提示在均匀分布下达 97.94%，而在指数分布下为 74.21%。这些发现突出了 GPT-4o 在异常检测中的潜力，并强调了提示策略和异常分布对性能的影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 5 images, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.06918v1",
      "published_date": "2025-02-10 15:34:37 UTC",
      "updated_date": "2025-02-10 15:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:31:24.066198"
    },
    {
      "arxiv_id": "2502.06559v1",
      "title": "Can We Trust AI Benchmarks? An Interdisciplinary Review of Current Issues in AI Evaluation",
      "title_zh": "我们能信任 AI 基准测试吗？ AI 评估当前问题的跨学科综述",
      "authors": [
        "Maria Eriksson",
        "Erasmo Purificato",
        "Arman Noroozian",
        "Joao Vinagre",
        "Guillaume Chaslot",
        "Emilia Gomez",
        "David Fernandez-Llorca"
      ],
      "abstract": "Quantitative Artificial Intelligence (AI) Benchmarks have emerged as\nfundamental tools for evaluating the performance, capability, and safety of AI\nmodels and systems. Currently, they shape the direction of AI development and\nare playing an increasingly prominent role in regulatory frameworks. As their\ninfluence grows, however, so too does concerns about how and with what effects\nthey evaluate highly sensitive topics such as capabilities, including\nhigh-impact capabilities, safety and systemic risks. This paper presents an\ninterdisciplinary meta-review of about 100 studies that discuss shortcomings in\nquantitative benchmarking practices, published in the last 10 years. It brings\ntogether many fine-grained issues in the design and application of benchmarks\n(such as biases in dataset creation, inadequate documentation, data\ncontamination, and failures to distinguish signal from noise) with broader\nsociotechnical issues (such as an over-focus on evaluating text-based AI models\naccording to one-time testing logic that fails to account for how AI models are\nincreasingly multimodal and interact with humans and other technical systems).\nOur review also highlights a series of systemic flaws in current benchmarking\npractices, such as misaligned incentives, construct validity issues, unknown\nunknowns, and problems with the gaming of benchmark results. Furthermore, it\nunderscores how benchmark practices are fundamentally shaped by cultural,\ncommercial and competitive dynamics that often prioritise state-of-the-art\nperformance at the expense of broader societal concerns. By providing an\noverview of risks associated with existing benchmarking procedures, we\nproblematise disproportionate trust placed in benchmarks and contribute to\nongoing efforts to improve the accountability and relevance of quantitative AI\nbenchmarks within the complexities of real-world scenarios.",
      "tldr_zh": "这篇论文通过对过去10年约100篇研究的跨学科元回顾，审视了AI benchmarks在评估AI模型性能、安全性和能力方面的缺陷，包括数据集偏差、数据污染以及对多模态AI和人类交互的忽略。回顾突出了系统性问题，如激励机制失调、结构有效性问题、基准结果操纵，以及文化和商业动态对基准的影响，这些往往优先考虑性能而非社会风险。最终，该研究质疑了对AI benchmarks的过度信任，并为提升其问责性和实际应用相关性提供改进建议。",
      "categories": [
        "cs.AI",
        "I.2.0; A.1"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT) 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06559v1",
      "published_date": "2025-02-10 15:25:06 UTC",
      "updated_date": "2025-02-10 15:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:31:35.710946"
    },
    {
      "arxiv_id": "2502.06917v1",
      "title": "Krum Federated Chain (KFC): Using blockchain to defend against adversarial attacks in Federated Learning",
      "title_zh": "Krum Federated Chain (KFC)：利用区块链防御联邦学习中的对抗性攻击",
      "authors": [
        "Mario García-Márquez",
        "Nuria Rodríguez-Barroso",
        "M. Victoria Luzón",
        "Francisco Herrera"
      ],
      "abstract": "Federated Learning presents a nascent approach to machine learning, enabling\ncollaborative model training across decentralized devices while safeguarding\ndata privacy. However, its distributed nature renders it susceptible to\nadversarial attacks. Integrating blockchain technology with Federated Learning\noffers a promising avenue to enhance security and integrity. In this paper, we\ntackle the potential of blockchain in defending Federated Learning against\nadversarial attacks. First, we test Proof of Federated Learning, a well known\nconsensus mechanism designed ad-hoc to federated contexts, as a defense\nmechanism demonstrating its efficacy against Byzantine and backdoor attacks\nwhen at least one miner remains uncompromised. Second, we propose Krum\nFederated Chain, a novel defense strategy combining Krum and Proof of Federated\nLearning, valid to defend against any configuration of Byzantine or backdoor\nattacks, even when all miners are compromised. Our experiments conducted on\nimage classification datasets validate the effectiveness of our proposed\napproaches.",
      "tldr_zh": "本论文探讨了在 Federated Learning 中使用区块链技术防御 adversarial attacks，以提升系统安全性和完整性。首先，测试了 Proof of Federated Learning 共识机制，证明其在至少一个矿工未被入侵的情况下，能有效抵御 Byzantine 和 backdoor attacks。其次，提出 Krum Federated Chain (KFC)，一种结合 Krum 和 Proof of Federated Learning 的新策略，能够应对任何配置的这些攻击，即使所有矿工被入侵。实验结果在图像分类数据集上验证了这些方法的有效性，为 Federated Learning 的安全应用提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to Neural Networks",
      "pdf_url": "http://arxiv.org/pdf/2502.06917v1",
      "published_date": "2025-02-10 15:15:50 UTC",
      "updated_date": "2025-02-10 15:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:31:46.942124"
    },
    {
      "arxiv_id": "2502.17462v1",
      "title": "The Case for Cleaner Biosignals: High-fidelity Neural Compressor Enables Transfer from Cleaner iEEG to Noisier EEG",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Stefano Carzaniga",
        "Gary Tom Hoppeler",
        "Michael Hersche",
        "Kaspar Anton Schindler",
        "Abbas Rahimi"
      ],
      "abstract": "All data modalities are not created equal, even when the signal they measure\ncomes from the same source. In the case of the brain, two of the most important\ndata modalities are the scalp electroencephalogram (EEG), and the intracranial\nelectroencephalogram (iEEG). They are used by human experts, supported by deep\nlearning (DL) models, to accomplish a variety of tasks, such as seizure\ndetection and motor imagery classification. Although the differences between\nEEG and iEEG are well understood by human experts, the performance of DL models\nacross these two modalities remains under-explored. To help characterize the\nimportance of clean data on the performance of DL models, we propose\nBrainCodec, a high-fidelity EEG and iEEG neural compressor. We find that\ntraining BrainCodec on iEEG and then transferring to EEG yields higher\nreconstruction quality than training on EEG directly. In addition, we also find\nthat training BrainCodec on both EEG and iEEG improves fidelity when\nreconstructing EEG. Our work indicates that data sources with higher SNR, such\nas iEEG, provide better performance across the board also in the medical\ntime-series domain. BrainCodec also achieves up to a 64x compression on iEEG\nand EEG without a notable decrease in quality. BrainCodec markedly surpasses\ncurrent state-of-the-art compression models both in final compression ratio and\nin reconstruction fidelity. We also evaluate the fidelity of the compressed\nsignals objectively on a seizure detection and a motor imagery task performed\nby standard DL models. Here, we find that BrainCodec achieves a reconstruction\nfidelity high enough to ensure no performance degradation on the downstream\ntasks. Finally, we collect the subjective assessment of an expert neurologist,\nthat confirms the high reconstruction quality of BrainCodec in a realistic\nscenario. The code is available at\nhttps://github.com/IBM/eeg-ieeg-brain-compressor.",
      "tldr_zh": "本文提出 BrainCodec，一种高保真神经压缩器，用于压缩和重建 EEG 和 iEEG 脑电信号，通过利用高信噪比（SNR）的 iEEG 数据训练并转移到噪声更大的 EEG 上，实现更高的重建质量。实验结果显示，BrainCodec 实现了高达 64 倍的压缩比，同时在下游任务如癫痫检测和运动想象分类中保持了 DL 模型的性能，且超过了现有最先进模型。该方法强调了使用更清洁数据源（如 iEEG）的优势，为医疗时间序列数据处理提供了新见解。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Published at ICLR 2025, see\n  https://openreview.net/forum?id=b57IG6N20B. Code is available at\n  https://github.com/IBM/eeg-ieeg-brain-compressor",
      "pdf_url": "http://arxiv.org/pdf/2502.17462v1",
      "published_date": "2025-02-10 15:05:06 UTC",
      "updated_date": "2025-02-10 15:05:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:31:58.981087"
    },
    {
      "arxiv_id": "2502.07825v1",
      "title": "Pre-Trained Video Generative Models as World Simulators",
      "title_zh": "预训练视频生成模型作为世界模拟器",
      "authors": [
        "Haoran He",
        "Yang Zhang",
        "Liang Lin",
        "Zhongwen Xu",
        "Ling Pan"
      ],
      "abstract": "Video generative models pre-trained on large-scale internet datasets have\nachieved remarkable success, excelling at producing realistic synthetic videos.\nHowever, they often generate clips based on static prompts (e.g., text or\nimages), limiting their ability to model interactive and dynamic scenarios. In\nthis paper, we propose Dynamic World Simulation (DWS), a novel approach to\ntransform pre-trained video generative models into controllable world\nsimulators capable of executing specified action trajectories. To achieve\nprecise alignment between conditioned actions and generated visual changes, we\nintroduce a lightweight, universal action-conditioned module that seamlessly\nintegrates into any existing model. Instead of focusing on complex visual\ndetails, we demonstrate that consistent dynamic transition modeling is the key\nto building powerful world simulators. Building upon this insight, we further\nintroduce a motion-reinforced loss that enhances action controllability by\ncompelling the model to capture dynamic changes more effectively. Experiments\ndemonstrate that DWS can be versatilely applied to both diffusion and\nautoregressive transformer models, achieving significant improvements in\ngenerating action-controllable, dynamically consistent videos across games and\nrobotics domains. Moreover, to facilitate the applications of the learned world\nsimulator in downstream tasks such as model-based reinforcement learning, we\npropose prioritized imagination to improve sample efficiency, demonstrating\ncompetitive performance compared with state-of-the-art methods.",
      "tldr_zh": "本文提出 Dynamic World Simulation (DWS)，一种将预训练视频生成模型转化为可控世界模拟器的方法，以解决这些模型基于静态提示（如文本或图像）而无法有效处理交互动态场景的局限性。DWS 引入轻量级动作条件模块和 motion-reinforced loss，确保动作轨迹与视觉变化的精确对齐，并通过强化动态过渡建模提升生成视频的一致性。实验结果显示，该方法适用于扩散模型和自回归 transformer 模型，在游戏和机器人领域显著提高动作可控性，并通过 prioritized imagination 提升下游任务如基于模型的强化学习的样本效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.07825v1",
      "published_date": "2025-02-10 14:49:09 UTC",
      "updated_date": "2025-02-10 14:49:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:32:11.407062"
    },
    {
      "arxiv_id": "2502.06523v1",
      "title": "Tighter Value-Function Approximations for POMDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Merlijn Krale",
        "Wietze Koops",
        "Sebastian Junges",
        "Thiago D. Simão",
        "Nils Jansen"
      ],
      "abstract": "Solving partially observable Markov decision processes (POMDPs) typically\nrequires reasoning about the values of exponentially many state beliefs.\nTowards practical performance, state-of-the-art solvers use value bounds to\nguide this reasoning. However, sound upper value bounds are often\ncomputationally expensive to compute, and there is a tradeoff between the\ntightness of such bounds and their computational cost. This paper introduces\nnew and provably tighter upper value bounds than the commonly used fast\ninformed bound. Our empirical evaluation shows that, despite their additional\ncomputational overhead, the new upper bounds accelerate state-of-the-art POMDP\nsolvers on a wide range of benchmarks.",
      "tldr_zh": "这篇论文针对部分可观测马尔可夫决策过程（POMDPs）提出更紧的价值函数上界（upper value bounds），以优化求解过程中对指数级状态信念的推理。相比常用的fast informed bound，新上界虽然增加了计算开销，但被证明在紧密度上更具优势。实验评估显示，这些上界显著加速了现有POMDP求解器，在广泛基准上提升了整体性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "AAMAS 2025 submission",
      "pdf_url": "http://arxiv.org/pdf/2502.06523v1",
      "published_date": "2025-02-10 14:48:09 UTC",
      "updated_date": "2025-02-10 14:48:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:32:22.132291"
    },
    {
      "arxiv_id": "2503.05703v1",
      "title": "What I cannot execute, I do not understand: Training and Evaluating LLMs on Program Execution Traces",
      "title_zh": "翻译失败",
      "authors": [
        "Jordi Armengol-Estapé",
        "Quentin Carbonneaux",
        "Tianjun Zhang",
        "Aram H. Markosyan",
        "Volker Seeker",
        "Chris Cummins",
        "Melanie Kambadur",
        "Michael F. P. O'Boyle",
        "Sida Wang",
        "Gabriel Synnaeve",
        "Hugh James Leather"
      ],
      "abstract": "Code generation and understanding are critical capabilities for large\nlanguage models (LLMs). Thus, most LLMs are pretrained and fine-tuned on code\ndata. However, these datasets typically treat code as static strings and rarely\nexploit the dynamic information about their execution. Building upon previous\nwork on trace modeling, we study Execution Tuning (E.T.), a training procedure\nin which we explicitly model real-world program execution traces without\nrequiring manual test annotations. We train and evaluate models on different\nexecution trace granularities (line and instruction-level) and strategies on\nthe task of output prediction, obtaining around 80% accuracy on CruxEval and\nMBPP, and showing the advantages of dynamic scratchpads (i.e., self-contained\nintermediate computations updated by the model rather than accumulated as a\nhistory of past computations) on long executions (up to 14k steps). Finally, we\ndiscuss E.T.'s practical applications.",
      "tldr_zh": "这篇论文探讨了训练大型语言模型 (LLMs) 以提升代码生成和理解能力的问题，提出 Execution Tuning (E.T.) 方法，通过显式建模程序执行痕迹（如行级和指令级）而非静态代码字符串。E.T. 不需要手动测试注解，在输出预测任务上训练模型，并在 CruxEval 和 MBPP 基准测试中实现约 80% 的准确率。研究突出了动态 scratchpads 的优势，即模型更新自包含的中间计算，这在长执行任务（高达 14k 步骤）上表现尤为突出。最后，论文讨论了 E.T. 在实际应用中的潜力，如改进代码处理效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05703v1",
      "published_date": "2025-02-10 14:42:13 UTC",
      "updated_date": "2025-02-10 14:42:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:32:35.230079"
    },
    {
      "arxiv_id": "2502.06516v1",
      "title": "Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Soobin Um",
        "Beomsu Kim",
        "Jong Chul Ye"
      ],
      "abstract": "Minority samples are underrepresented instances located in low-density\nregions of a data manifold, and are valuable in many generative AI\napplications, such as data augmentation, creative content generation, etc.\nUnfortunately, existing diffusion-based minority generators often rely on\ncomputationally expensive guidance dedicated for minority generation. To\naddress this, here we present a simple yet powerful guidance-free approach\ncalled Boost-and-Skip for generating minority samples using diffusion models.\nThe key advantage of our framework requires only two minimal changes to\nstandard generative processes: (i) variance-boosted initialization and (ii)\ntimestep skipping. We highlight that these seemingly-trivial modifications are\nsupported by solid theoretical and empirical evidence, thereby effectively\npromoting emergence of underrepresented minority features. Our comprehensive\nexperiments demonstrate that Boost-and-Skip greatly enhances the capability of\ngenerating minority samples, even rivaling guidance-based state-of-the-art\napproaches while requiring significantly fewer computations.",
      "tldr_zh": "本论文针对扩散模型(diffusion models)生成少数样本(minority samples)的挑战，提出了一种简单无指导的Boost-and-Skip框架，以解决现有方法依赖计算密集型指导的问题。该框架仅需对标准生成过程进行两个最小改动：(i) 方差增强初始化(variance-boosted initialization)和(ii) 时间步跳过(timestep skipping)，这些改动基于坚实的理论和经验证据，有效提升了 underrepresented 少数特征的生成能力。实验结果表明，Boost-and-Skip显著提高了少数样本生成性能，甚至可与基于指导的state-of-the-art方法媲美，但所需计算资源大幅减少。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06516v1",
      "published_date": "2025-02-10 14:37:26 UTC",
      "updated_date": "2025-02-10 14:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:32:47.381409"
    },
    {
      "arxiv_id": "2502.06494v1",
      "title": "GuideLLM: Exploring LLM-Guided Conversation with Applications in Autobiography Interviewing",
      "title_zh": "GuideLLM：探索LLM引导对话及其在自传访谈中的应用",
      "authors": [
        "Jinhao Duan",
        "Xinyu Zhao",
        "Zhuoxuan Zhang",
        "Eunhye Ko",
        "Lily Boddy",
        "Chenan Wang",
        "Tianhao Li",
        "Alexander Rasgon",
        "Junyuan Hong",
        "Min Kyung Lee",
        "Chenxi Yuan",
        "Qi Long",
        "Ying Ding",
        "Tianlong Chen",
        "Kaidi Xu"
      ],
      "abstract": "Although Large Language Models (LLMs) succeed in human-guided conversations\nsuch as instruction following and question answering, the potential of\nLLM-guided conversations-where LLMs direct the discourse and steer the\nconversation's objectives-remains under-explored. In this study, we first\ncharacterize LLM-guided conversation into three fundamental components: (i)\nGoal Navigation; (ii) Context Management; (iii) Empathetic Engagement, and\npropose GuideLLM as an installation. We then implement an interviewing\nenvironment for the evaluation of LLM-guided conversation. Specifically,\nvarious topics are involved in this environment for comprehensive interviewing\nevaluation, resulting in around 1.4k turns of utterances, 184k tokens, and over\n200 events mentioned during the interviewing for each chatbot evaluation. We\ncompare GuideLLM with 6 state-of-the-art LLMs such as GPT-4o and\nLlama-3-70b-Instruct, from the perspective of interviewing quality, and\nautobiography generation quality. For automatic evaluation, we derive user\nproxies from multiple autobiographies and employ LLM-as-a-judge to score LLM\nbehaviors. We further conduct a human-involved experiment by employing 45 human\nparticipants to chat with GuideLLM and baselines. We then collect human\nfeedback, preferences, and ratings regarding the qualities of conversation and\nautobiography. Experimental results indicate that GuideLLM significantly\noutperforms baseline LLMs in automatic evaluation and achieves consistent\nleading performances in human ratings.",
      "tldr_zh": "本研究探讨了LLM-guided conversation的概念，即大型语言模型(LLMs)主导对话并引导目标，提出GuideLLM框架，该框架包括Goal Navigation、Context Management和Empathetic Engagement三个核心组件，并应用于自传采访场景。研究构建了一个全面的采访环境，涉及多种主题，生成约1.4k轮对话、184k标记和200多个事件，用于评估LLMs的表现。作者通过自动评估（使用用户代理和LLM-as-a-judge）和人类实验（45名参与者提供反馈），将GuideLLM与GPT-4o和Llama-3-70b-Instruct等6个基线模型比较。实验结果表明，GuideLLM在对话质量和自传生成质量上显著优于基线模型，并在人类评分中表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages; the first three authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2502.06494v1",
      "published_date": "2025-02-10 14:11:32 UTC",
      "updated_date": "2025-02-10 14:11:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:32:59.568726"
    },
    {
      "arxiv_id": "2502.06491v2",
      "title": "Model-Based Offline Reinforcement Learning with Reliability-Guaranteed Sequence Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Shenghong He"
      ],
      "abstract": "Model-based offline reinforcement learning (MORL) aims to learn a policy by\nexploiting a dynamics model derived from an existing dataset. Applying\nconservative quantification to the dynamics model, most existing works on MORL\ngenerate trajectories that approximate the real data distribution to facilitate\npolicy learning by using current information (e.g., the state and action at\ntime step $t$). However, these works neglect the impact of historical\ninformation on environmental dynamics, leading to the generation of unreliable\ntrajectories that may not align with the real data distribution. In this paper,\nwe propose a new MORL algorithm \\textbf{R}eliability-guaranteed\n\\textbf{T}ransformer (RT), which can eliminate unreliable trajectories by\ncalculating the cumulative reliability of the generated trajectory (i.e., using\na weighted variational distance away from the real data). Moreover, by sampling\ncandidate actions with high rewards, RT can efficiently generate high-return\ntrajectories from the existing offline data. We theoretically prove the\nperformance guarantees of RT in policy learning, and empirically demonstrate\nits effectiveness against state-of-the-art model-based methods on several\nbenchmark tasks.",
      "tldr_zh": "这篇论文针对基于模型的离线强化学习 (MORL) 的问题，提出了一种新算法 Reliability-guaranteed Transformer (RT)，通过计算生成的轨迹累积可靠性（使用加权变异距离与真实数据分布的距离）来消除不可靠轨迹，并采样高奖励候选动作以从现有离线数据中高效生成高回报轨迹。RT 算法考虑了历史信息对环境动态的影响，提高了轨迹的准确性。论文理论证明了 RT 在策略学习中的性能保证，并在多个基准任务上实验验证其优于最先进模型-based 方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06491v2",
      "published_date": "2025-02-10 14:08:55 UTC",
      "updated_date": "2025-05-03 07:43:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:33:10.560591"
    },
    {
      "arxiv_id": "2502.06490v2",
      "title": "Recent Advances in Discrete Speech Tokens: A Review",
      "title_zh": "离散语音标记的最近进展：综述",
      "authors": [
        "Yiwei Guo",
        "Zhihan Li",
        "Hankun Wang",
        "Bohan Li",
        "Chongtian Shao",
        "Hanglei Zhang",
        "Chenpeng Du",
        "Xie Chen",
        "Shujie Liu",
        "Kai Yu"
      ],
      "abstract": "The rapid advancement of speech generation technologies in the era of large\nlanguage models (LLMs) has established discrete speech tokens as a foundational\nparadigm for speech representation. These tokens, characterized by their\ndiscrete, compact, and concise nature, are not only advantageous for efficient\ntransmission and storage, but also inherently compatible with the language\nmodeling framework, enabling seamless integration of speech into text-dominated\nLLM architectures. Current research categorizes discrete speech tokens into two\nprincipal classes: acoustic tokens and semantic tokens, each of which has\nevolved into a rich research domain characterized by unique design philosophies\nand methodological approaches. This survey systematically synthesizes the\nexisting taxonomy and recent innovations in discrete speech tokenization,\nconducts a critical examination of the strengths and limitations of each\nparadigm, and presents systematic experimental comparisons across token types.\nFurthermore, we identify persistent challenges in the field and propose\npotential research directions, aiming to offer actionable insights to inspire\nfuture advancements in the development and application of discrete speech\ntokens.",
      "tldr_zh": "这篇综述论文回顾了离散语音标记（discrete speech tokens）在语音生成技术中的最新进展，这些标记以其离散、紧凑和简洁的特性，有助于高效传输、存储，并与大型语言模型（LLMs）无缝整合。论文将离散语音标记分为两大类：acoustic tokens 和 semantic tokens，并系统分析了每类的设计理念、方法创新、优势与局限性，同时进行了跨类型实验比较。最终，论文指出了当前领域的关键挑战，如兼容性和扩展性问题，并提出了潜在的研究方向，以推动离散语音标记的应用和发展。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.MM",
        "cs.SD",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "23 pages, 8 figures, 3 tables. Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2502.06490v2",
      "published_date": "2025-02-10 14:08:25 UTC",
      "updated_date": "2025-02-16 08:11:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:33:22.057985"
    },
    {
      "arxiv_id": "2502.06485v2",
      "title": "WyckoffDiff -- A Generative Diffusion Model for Crystal Symmetry",
      "title_zh": "翻译失败",
      "authors": [
        "Filip Ekström Kelvinius",
        "Oskar B. Andersson",
        "Abhijith S. Parackal",
        "Dong Qian",
        "Rickard Armiento",
        "Fredrik Lindsten"
      ],
      "abstract": "Crystalline materials often exhibit a high level of symmetry. However, most\ngenerative models do not account for symmetry, but rather model each atom\nwithout any constraints on its position or element. We propose a generative\nmodel, Wyckoff Diffusion (WyckoffDiff), which generates symmetry-based\ndescriptions of crystals. This is enabled by considering a crystal structure\nrepresentation that encodes all symmetry, and we design a novel neural network\narchitecture which enables using this representation inside a discrete\ngenerative model framework. In addition to respecting symmetry by construction,\nthe discrete nature of our model enables fast generation. We additionally\npresent a new metric, Fr\\'echet Wrenformer Distance, which captures the\nsymmetry aspects of the materials generated, and we benchmark WyckoffDiff\nagainst recently proposed generative models for crystal generation. Code is\navailable online at https://github.com/httk/wyckoffdiff",
      "tldr_zh": "该论文提出WyckoffDiff，一种考虑晶体对称性的生成扩散模型，用于生成基于对称描述的晶体结构，以解决传统模型忽略原子位置和元素约束的问题。模型采用一种编码所有对称性的晶体表示，并设计新型神经网络架构，使其在离散生成框架中运行，确保生成过程天生符合对称性并实现快速生成。同时，论文引入Fréchet Wrenformer Distance新指标，并通过基准测试证明WyckoffDiff在晶体生成性能上优于现有模型，代码已在GitHub上公开。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "Code is available online at https://github.com/httk/wyckoffdiff",
      "pdf_url": "http://arxiv.org/pdf/2502.06485v2",
      "published_date": "2025-02-10 14:04:23 UTC",
      "updated_date": "2025-04-30 06:08:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:33:33.976796"
    },
    {
      "arxiv_id": "2502.06472v1",
      "title": "KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment",
      "title_zh": "KARMA：利用多智能体大语言模型进行自动知识图谱增强",
      "authors": [
        "Yuxing Lu",
        "Jinzhuo Wang"
      ],
      "abstract": "Maintaining comprehensive and up-to-date knowledge graphs (KGs) is critical\nfor modern AI systems, but manual curation struggles to scale with the rapid\ngrowth of scientific literature. This paper presents KARMA, a novel framework\nemploying multi-agent large language models (LLMs) to automate KG enrichment\nthrough structured analysis of unstructured text. Our approach employs nine\ncollaborative agents, spanning entity discovery, relation extraction, schema\nalignment, and conflict resolution that iteratively parse documents, verify\nextracted knowledge, and integrate it into existing graph structures while\nadhering to domain-specific schema. Experiments on 1,200 PubMed articles from\nthree different domains demonstrate the effectiveness of KARMA in knowledge\ngraph enrichment, with the identification of up to 38,230 new entities while\nachieving 83.1\\% LLM-verified correctness and reducing conflict edges by 18.6\\%\nthrough multi-layer assessments.",
      "tldr_zh": "该研究提出KARMA框架，利用多智能体Large Language Models (LLMs)自动丰富知识图谱(KGs)，以应对手动维护无法跟上科学文献快速增长的挑战。框架包括九个协作代理，负责实体发现、关系提取、模式对齐和冲突解决，通过迭代解析文档、验证提取知识并整合到现有图结构中，同时遵守领域特定模式。实验在1200篇PubMed文章上验证了KARMA的有效性，识别多达38,230个新实体，实现83.1%的LLM验证正确率，并通过多层评估减少冲突边18.6%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.06472v1",
      "published_date": "2025-02-10 13:51:36 UTC",
      "updated_date": "2025-02-10 13:51:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:33:46.482844"
    },
    {
      "arxiv_id": "2502.06470v1",
      "title": "A Survey of Theory of Mind in Large Language Models: Evaluations, Representations, and Safety Risks",
      "title_zh": "翻译失败",
      "authors": [
        "Hieu Minh \"Jord\" Nguyen"
      ],
      "abstract": "Theory of Mind (ToM), the ability to attribute mental states to others and\npredict their behaviour, is fundamental to social intelligence. In this paper,\nwe survey studies evaluating behavioural and representational ToM in Large\nLanguage Models (LLMs), identify important safety risks from advanced LLM ToM\ncapabilities, and suggest several research directions for effective evaluation\nand mitigation of these risks.",
      "tldr_zh": "这篇论文对Theory of Mind (ToM)在大语言模型(LLMs)中的表现进行调查，重点评估了LLMs在行为和表征ToM方面的能力。论文回顾了现有研究，识别出高级LLM ToM功能可能带来的重要安全风险，如潜在的误用或不可预测行为。最终，它提出了有效评估和缓解这些风险的研究方向，以提升LLMs的安全性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Advancing Artificial Intelligence through Theory of Mind Workshop,\n  AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06470v1",
      "published_date": "2025-02-10 13:50:25 UTC",
      "updated_date": "2025-02-10 13:50:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:33:59.118165"
    },
    {
      "arxiv_id": "2502.17460v1",
      "title": "Finetuning and Quantization of EEG-Based Foundational BioSignal Models on ECG and PPG Data for Blood Pressure Estimation",
      "title_zh": "基于 EEG 的基础生物信号模型",
      "authors": [
        "Bálint Tóth",
        "Dominik Senti",
        "Thorir Mar Ingolfsson",
        "Jeffrey Zweidler",
        "Alexandre Elsig",
        "Luca Benini",
        "Yawei Li"
      ],
      "abstract": "Blood pressure (BP) is a key indicator of cardiovascular health. As\nhypertension remains a global cause of morbidity and mortality, accurate,\ncontinuous, and non-invasive BP monitoring is therefore of paramount\nimportance. Photoplethysmography (PPG) and electrocardiography (ECG) can\npotentially enable continuous BP monitoring, yet training accurate and robust\nmachine learning (ML) models remains challenging due to variability in data\nquality and patient-specific factors. Recently, multiple research groups\nexplored Electroencephalographic (EEG)--based foundation models and\ndemonstrated their exceptional ability to learn rich temporal resolution.\nConsidering the morphological similarities between different biosignals, the\nquestion arises of whether a model pre-trained on one modality can effectively\nbe exploited to improve the accuracy of a different signal type. In this work,\nwe take an initial step towards generalized biosignal foundation models by\ninvestigating whether model representations learned from abundant EEG data can\neffectively be transferred to ECG/PPG data solely with fine-tuning, without the\nneed for large-scale additional pre-training, for the BP estimation task.\nEvaluations on the MIMIC-III and VitalDB datasets demonstrate that our approach\nachieves near state-of-the-art accuracy for diastolic BP (mean absolute error\nof 1.57 mmHg) and surpasses by 1.5x the accuracy of prior works for systolic BP\n(mean absolute error 2.72 mmHg). Additionally, we perform dynamic INT8\nquantization, reducing the smallest model size by over 3.5x (from 13.73 MB down\nto 3.83 MB) while preserving performance, thereby enabling unobtrusive,\nreal-time BP monitoring on resource-constrained wearable devices.",
      "tldr_zh": "本研究探讨了将基于 EEG 的基础生物信号模型通过 fine-tuning 应用于 ECG 和 PPG 数据，以实现非侵入式血壓估計，旨在克服数据质量和患者因素的挑战。实验在 MIMIC-III 和 VitalDB 数据集上表明，该方法在舒张压的 mean absolute error 达到 1.57 mmHg，在收缩压上比先前工作提高了 1.5 倍（mean absolute error 2.72 mmHg）。此外，通过动态 INT8 quantization，将模型大小从 13.73 MB 縮减到 3.83 MB，同时保持性能，使其适用于资源受限的可穿戴设备进行实时监测。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "7 pages, 1 figure, 5 tables, preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.17460v1",
      "published_date": "2025-02-10 13:33:12 UTC",
      "updated_date": "2025-02-10 13:33:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:34:12.543735"
    },
    {
      "arxiv_id": "2502.06453v2",
      "title": "MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard Perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Kaixuan Huang",
        "Jiacheng Guo",
        "Zihao Li",
        "Xiang Ji",
        "Jiawei Ge",
        "Wenzhe Li",
        "Yingqing Guo",
        "Tianle Cai",
        "Hui Yuan",
        "Runzhe Wang",
        "Yue Wu",
        "Ming Yin",
        "Shange Tang",
        "Yangsibo Huang",
        "Chi Jin",
        "Xinyun Chen",
        "Chiyuan Zhang",
        "Mengdi Wang"
      ],
      "abstract": "Large language models have demonstrated impressive performance on challenging\nmathematical reasoning tasks, which has triggered the discussion of whether the\nperformance is achieved by true reasoning capability or memorization. To\ninvestigate this question, prior work has constructed mathematical benchmarks\nwhen questions undergo simple perturbations -- modifications that still\npreserve the underlying reasoning patterns of the solutions. However, no work\nhas explored hard perturbations, which fundamentally change the nature of the\nproblem so that the original solution steps do not apply. To bridge the gap, we\nconstruct MATH-P-Simple and MATH-P-Hard via simple perturbation and hard\nperturbation, respectively. Each consists of 279 perturbed math problems\nderived from level-5 (hardest) problems in the MATH dataset (Hendrycksmath et.\nal., 2021). We observe significant performance drops on MATH-P-Hard across\nvarious models, including o1-mini (-16.49%) and gemini-2.0-flash-thinking\n(-12.9%). We also raise concerns about a novel form of memorization where\nmodels blindly apply learned problem-solving skills without assessing their\napplicability to modified contexts. This issue is amplified when using original\nproblems for in-context learning. We call for research efforts to address this\nchallenge, which is critical for developing more robust and reliable reasoning\nmodels.",
      "tldr_zh": "本文评估了大型语言模型（LLMs）的数学推理能力，针对现有研究的不足，引入了硬扰动（hard perturbations）来测试模型是否依赖于记忆而非真正推理。研究构建了 MATH-P-Simple 和 MATH-P-Hard 基准数据集，每个包含 279 个从 MATH 数据集 level-5 问题派生的扰动问题。实验结果显示，模型在 MATH-P-Hard 上性能显著下降，例如 o1-mini 下降 16.49%、gemini-2.0-flash-thinking 下降 12.9%，揭示了模型可能盲目应用 in-context learning 学到的技能而不评估其适用性。作者呼吁更多研究来解决这一挑战，以开发更鲁棒可靠的推理模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "v2: fix bugs in Fig. 1",
      "pdf_url": "http://arxiv.org/pdf/2502.06453v2",
      "published_date": "2025-02-10 13:31:46 UTC",
      "updated_date": "2025-02-12 23:16:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:34:23.953855"
    },
    {
      "arxiv_id": "2502.06440v1",
      "title": "SIGMA: Sheaf-Informed Geometric Multi-Agent Pathfinding",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhao Liao",
        "Weihang Xia",
        "Yuhong Cao",
        "Weiheng Dai",
        "Chengyang He",
        "Wenjun Wu",
        "Guillaume Sartoretti"
      ],
      "abstract": "The Multi-Agent Path Finding (MAPF) problem aims to determine the shortest\nand collision-free paths for multiple agents in a known, potentially\nobstacle-ridden environment. It is the core challenge for robotic deployments\nin large-scale logistics and transportation. Decentralized learning-based\napproaches have shown great potential for addressing the MAPF problems,\noffering more reactive and scalable solutions. However, existing learning-based\nMAPF methods usually rely on agents making decisions based on a limited field\nof view (FOV), resulting in short-sighted policies and inefficient cooperation\nin complex scenarios. There, a critical challenge is to achieve consensus on\npotential movements between agents based on limited observations and\ncommunications. To tackle this challenge, we introduce a new framework that\napplies sheaf theory to decentralized deep reinforcement learning, enabling\nagents to learn geometric cross-dependencies between each other through local\nconsensus and utilize them for tightly cooperative decision-making. In\nparticular, sheaf theory provides a mathematical proof of conditions for\nachieving global consensus through local observation. Inspired by this, we\nincorporate a neural network to approximately model the consensus in latent\nspace based on sheaf theory and train it through self-supervised learning.\nDuring the task, in addition to normal features for MAPF as in previous works,\neach agent distributedly reasons about a learned consensus feature, leading to\nefficient cooperation on pathfinding and collision avoidance. As a result, our\nproposed method demonstrates significant improvements over state-of-the-art\nlearning-based MAPF planners, especially in relatively large and complex\nscenarios, demonstrating its superiority over baselines in various simulations\nand real-world robot experiments.",
      "tldr_zh": "这篇论文针对Multi-Agent Path Finding (MAPF)问题，提出了一种名为SIGMA的框架，利用sheaf theory整合到去中心化深度强化学习中，以解决代理在有限视野下导致的短视决策和低效合作挑战。框架通过神经网络在潜在空间中建模局部共识特征，让代理学习几何交叉依赖，从而实现更紧密的路径规划和碰撞避免决策。实验结果表明，SIGMA在各种模拟和真实机器人环境中显著优于现有方法，尤其在大型复杂场景中，展示了其在机器人部署中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for presentation at the 2025 IEEE International Conference\n  on Robotics and Automation (ICRA)",
      "pdf_url": "http://arxiv.org/pdf/2502.06440v1",
      "published_date": "2025-02-10 13:17:34 UTC",
      "updated_date": "2025-02-10 13:17:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:34:36.049041"
    },
    {
      "arxiv_id": "2502.06439v1",
      "title": "Testing software for non-discrimination: an updated and extended audit in the Italian car insurance domain",
      "title_zh": "软件非歧视测试：意大利汽车保险领域的更新和扩展审计",
      "authors": [
        "Marco Rondina",
        "Antonio Vetrò",
        "Riccardo Coppola",
        "Oumaima Regragrui",
        "Alessandro Fabris",
        "Gianmaria Silvello",
        "Gian Antonio Susto",
        "Juan Carlos De Martin"
      ],
      "abstract": "Context. As software systems become more integrated into society's\ninfrastructure, the responsibility of software professionals to ensure\ncompliance with various non-functional requirements increases. These\nrequirements include security, safety, privacy, and, increasingly,\nnon-discrimination.\n  Motivation. Fairness in pricing algorithms grants equitable access to basic\nservices without discriminating on the basis of protected attributes.\n  Method. We replicate a previous empirical study that used black box testing\nto audit pricing algorithms used by Italian car insurance companies, accessible\nthrough a popular online system. With respect to the previous study, we\nenlarged the number of tests and the number of demographic variables under\nanalysis.\n  Results. Our work confirms and extends previous findings, highlighting the\nproblematic permanence of discrimination across time: demographic variables\nsignificantly impact pricing to this day, with birthplace remaining the main\ndiscriminatory factor against individuals not born in Italian cities. We also\nfound that driver profiles can determine the number of quotes available to the\nuser, denying equal opportunities to all.\n  Conclusion. The study underscores the importance of testing for\nnon-discrimination in software systems that affect people's everyday lives.\nPerforming algorithmic audits over time makes it possible to evaluate the\nevolution of such algorithms. It also demonstrates the role that empirical\nsoftware engineering can play in making software systems more accountable.",
      "tldr_zh": "本文研究更新并扩展了对意大利汽车保险领域定价算法的审计，使用 black box testing 方法，增加了测试数量和 demographic variables 的分析，以评估软件系统的非歧视性。结果显示，人口统计变量如出生地持续显著影响定价，导致对非意大利出生者的歧视，且某些驾驶员配置文件会限制用户可获得的报价机会，进而加剧不平等。研究强调，进行 algorithmic audits 的重要性，以追踪算法演变并提升软件系统的问责制。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "14 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2502.06439v1",
      "published_date": "2025-02-10 13:16:01 UTC",
      "updated_date": "2025-02-10 13:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:34:48.266340"
    },
    {
      "arxiv_id": "2502.06438v1",
      "title": "FEMBA: Efficient and Scalable EEG Analysis with a Bidirectional Mamba Foundation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Tegon",
        "Thorir Mar Ingolfsson",
        "Xiaying Wang",
        "Luca Benini",
        "Yawei Li"
      ],
      "abstract": "Accurate and efficient electroencephalography (EEG) analysis is essential for\ndetecting seizures and artifacts in long-term monitoring, with applications\nspanning hospital diagnostics to wearable health devices. Robust EEG analytics\nhave the potential to greatly improve patient care. However, traditional deep\nlearning models, especially Transformer-based architectures, are hindered by\ntheir quadratic time and memory complexity, making them less suitable for\nresource-constrained environments. To address these challenges, we present\nFEMBA (Foundational EEG Mamba + Bidirectional Architecture), a novel\nself-supervised framework that establishes new efficiency benchmarks for EEG\nanalysis through bidirectional state-space modeling. Unlike Transformer-based\nmodels, which incur quadratic time and memory complexity, FEMBA scales linearly\nwith sequence length, enabling more scalable and efficient processing of\nextended EEG recordings. Trained on over 21,000 hours of unlabeled EEG and\nfine-tuned on three downstream tasks, FEMBA achieves competitive performance in\ncomparison with transformer models, with significantly lower computational\ncost. Specifically, it reaches 81.82% balanced accuracy (0.8921 AUROC) on TUAB\nand 0.949 AUROC on TUAR, while a tiny 7.8M-parameter variant demonstrates\nviability for resource-constrained devices. These results pave the way for\nscalable, general-purpose EEG analytics in both clinical and highlight FEMBA as\na promising candidate for wearable applications.",
      "tldr_zh": "本研究提出FEMBA，一种高效且可扩展的EEG分析框架，采用双向Mamba基础模型来解决传统Transformer-based模型的二次时间和内存复杂度问题，从而适用于资源受限环境。FEMBA通过自监督学习在超过21,000小时的无标签EEG数据上训练，并在三个下游任务中微调，实现了与Transformer模型相当的性能，同时显著降低计算成本。具体而言，它在TUAB数据集上达到81.82%平衡准确率（0.8921 AUROC）和TUAR上0.949 AUROC，一个小型7.8M参数变体则适合可穿戴设备应用。这些结果为临床诊断和可穿戴健康设备的EEG分析铺平了道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 3 figures, 5 tables, pre-print",
      "pdf_url": "http://arxiv.org/pdf/2502.06438v1",
      "published_date": "2025-02-10 13:15:52 UTC",
      "updated_date": "2025-02-10 13:15:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:35:00.772138"
    },
    {
      "arxiv_id": "2502.06432v2",
      "title": "Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single-Image Denoising",
      "title_zh": "Prompt-SID：通过潜在扩散学习结构",
      "authors": [
        "Huaqiu Li",
        "Wang Zhang",
        "Xiaowan Hu",
        "Tao Jiang",
        "Zikang Chen",
        "Haoqian Wang"
      ],
      "abstract": "Many studies have concentrated on constructing supervised models utilizing\npaired datasets for image denoising, which proves to be expensive and\ntime-consuming. Current self-supervised and unsupervised approaches typically\nrely on blind-spot networks or sub-image pairs sampling, resulting in pixel\ninformation loss and destruction of detailed structural information, thereby\nsignificantly constraining the efficacy of such methods. In this paper, we\nintroduce Prompt-SID, a prompt-learning-based single image denoising framework\nthat emphasizes preserving of structural details. This approach is trained in a\nself-supervised manner using downsampled image pairs. It captures\noriginal-scale image information through structural encoding and integrates\nthis prompt into the denoiser. To achieve this, we propose a structural\nrepresentation generation model based on the latent diffusion process and\ndesign a structural attention module within the transformer-based denoiser\narchitecture to decode the prompt. Additionally, we introduce a scale replay\ntraining mechanism, which effectively mitigates the scale gap from images of\ndifferent resolutions. We conduct comprehensive experiments on synthetic,\nreal-world, and fluorescence imaging datasets, showcasing the remarkable\neffectiveness of Prompt-SID. Our code will be released at\nhttps://github.com/huaqlili/Prompt-SID.",
      "tldr_zh": "该论文提出 Prompt-SID，一种基于提示学习的自监督单图像去噪框架，旨在解决传统方法依赖配对数据集的成本问题，并避免现有自监督方法导致的像素信息丢失和结构细节破坏。Prompt-SID 通过下采样图像配对进行训练，利用基于 latent diffusion 的结构表示生成模型来捕获原始尺度图像信息，并设计结构注意力模块整合到 Transformer-based denoiser 中以解码提示。此外，该框架引入规模重放训练机制来缓解不同分辨率图像的规模差距，并在合成、真实世界和荧光成像数据集上的实验中展示了显著的去噪效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06432v2",
      "published_date": "2025-02-10 13:09:47 UTC",
      "updated_date": "2025-03-13 12:49:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:35:12.674845"
    },
    {
      "arxiv_id": "2502.09644v1",
      "title": "From Argumentation to Deliberation: Perspectivized Stance Vectors for Fine-grained (Dis)agreement Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Moritz Plenz",
        "Philipp Heinisch",
        "Janosch Gehring",
        "Philipp Cimiano",
        "Anette Frank"
      ],
      "abstract": "Debating over conflicting issues is a necessary first step towards resolving\nconflicts. However, intrinsic perspectives of an arguer are difficult to\novercome by persuasive argumentation skills. Proceeding from a debate to a\ndeliberative process, where we can identify actionable options for resolving a\nconflict requires a deeper analysis of arguments and the perspectives they are\ngrounded in - as it is only from there that one can derive mutually agreeable\nresolution steps. In this work we develop a framework for a deliberative\nanalysis of arguments in a computational argumentation setup. We conduct a\nfine-grained analysis of perspectivized stances expressed in the arguments of\ndifferent arguers or stakeholders on a given issue, aiming not only to identify\ntheir opposing views, but also shared perspectives arising from their\nattitudes, values or needs. We formalize this analysis in Perspectivized Stance\nVectors that characterize the individual perspectivized stances of all arguers\non a given issue. We construct these vectors by determining issue- and\nargument-specific concepts, and predict an arguer's stance relative to each of\nthem. The vectors allow us to measure a modulated (dis)agreement between\narguers, structured by perspectives, which allows us to identify actionable\npoints for conflict resolution, as a first step towards deliberation.",
      "tldr_zh": "本研究提出一个框架，将辩论过程转向审议分析，焦点在于细粒度分析（fine-grained (Dis)agreement Analysis）论点中的视角化立场（Perspectivized Stance Vectors），以识别不同论者的对立观点和共享视角，如态度、价值观或需求。研究通过构建基于问题和论点特定概念的Perspectivized Stance Vectors，来量化每个论者在这些概念上的立场，从而实现对（dis）agreement的调制测量。最终，该方法有助于发现可行动的冲突解决点，作为迈向审议过程的第一步。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL Findings 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.09644v1",
      "published_date": "2025-02-10 13:08:46 UTC",
      "updated_date": "2025-02-10 13:08:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:35:23.272680"
    },
    {
      "arxiv_id": "2502.06916v1",
      "title": "Hyper Compressed Fine-Tuning of Large Foundation Models with Quantum Inspired Adapters",
      "title_zh": "翻译失败",
      "authors": [
        "Snehal Raj",
        "Brian Coyle"
      ],
      "abstract": "Fine-tuning pre-trained large foundation models for specific tasks has become\nincreasingly challenging due to the computational and storage demands\nassociated with full parameter updates. Parameter-Efficient Fine-Tuning (PEFT)\nmethods address this issue by updating only a small subset of model parameters\nusing adapter modules. In this work, we propose \\emph{Quantum-Inspired\nAdapters}, a PEFT approach inspired by Hamming-weight preserving quantum\ncircuits from quantum machine learning literature. These models can be both\nexpressive and parameter-efficient by operating in a combinatorially large\nspace while simultaneously preserving orthogonality in weight parameters. We\ntest our proposed adapters by adapting large language models and large vision\ntransformers on benchmark datasets. Our method can achieve 99.2\\% of the\nperformance of existing fine-tuning methods such LoRA with a 44x parameter\ncompression on language understanding datasets like GLUE and VTAB. Compared to\nexisting orthogonal fine-tuning methods such as OFT or BOFT, we achieve 98\\%\nrelative performance with 25x fewer parameters. This demonstrates competitive\nperformance paired with a significant reduction in trainable parameters.\nThrough ablation studies, we determine that combining multiple Hamming-weight\norders with orthogonality and matrix compounding are essential for performant\nfine-tuning. Our findings suggest that Quantum-Inspired Adapters offer a\npromising direction for efficient adaptation of language and vision models in\nresource-constrained environments.",
      "tldr_zh": "本文提出Quantum-Inspired Adapters，一种受量子机器学习中Hamming-weight保持量子电路启发的Parameter-Efficient Fine-Tuning (PEFT)方法，用于高效微调大型基础模型，显著减少计算和存储需求。该方法通过在组合空间中操作并保持参数正交性，实现高表达性和参数效率。在GLUE和VTAB等基准数据集上测试，Quantum-Inspired Adapters达到LoRA的99.2%性能，但参数压缩44倍；与OFT或BOFT相比，相对性能达98%，参数减少25倍。消融研究显示，结合多个Hamming-weight顺序、正交性和矩阵复合是性能关键，为资源受限环境下的语言和视觉模型适应提供新方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 9 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.06916v1",
      "published_date": "2025-02-10 13:06:56 UTC",
      "updated_date": "2025-02-10 13:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:35:36.863766"
    },
    {
      "arxiv_id": "2503.04758v2",
      "title": "Chat-GPT: An AI Based Educational Revolution",
      "title_zh": "Chat-GPT：基于人工智能的教育革命",
      "authors": [
        "Sasa Maric",
        "Sonja Maric",
        "Lana Maric"
      ],
      "abstract": "The AI revolution is gathering momentum at an unprecedented rate. Over the\npast decade, we have witnessed a seemingly inevitable integration of AI in\nevery facet of our lives. Much has been written about the potential\nrevolutionary impact of AI in education. AI has the potential to completely\nrevolutionise the educational landscape as we could see entire courses and\ndegrees developed by programs such as ChatGPT. AI has the potential to develop\ncourses, set assignments, grade and provide feedback to students much faster\nthan a team of teachers. In addition, because of its dynamic nature, it has the\npotential to continuously improve its content. In certain fields such as\ncomputer science, where technology is continuously evolving, AI based\napplications can provide dynamically changing, relevant material to students.\nAI has the potential to replace entire degrees and may challenge the concept of\nhigher education institutions. We could also see entire new disciplines emerge\nas a consequence of AI. This paper examines the practical impact of ChatGPT and\nwhy it is believed that its implementation is a critical step towards a new era\nof education. We investigate the impact that ChatGPT will have on learning,\nproblem solving skills and cognitive ability of students. We examine the\npositives, negatives and many other aspects of AI and its applications\nthroughout this paper.",
      "tldr_zh": "这篇论文探讨了ChatGPT作为AI驱动的教育革命，强调AI如何彻底改变教育景观，包括开发课程、布置作业、评分和提供反馈的速度远超传统教师。论文分析了ChatGPT的动态特性，能够持续优化内容，尤其在快速演变的领域如计算机科学中，提供相关且更新的学习材料，并可能挑战高等教育机构的角色，甚至催生新学科。同时，研究考察了ChatGPT对学生学习、问题解决技能和认知能力的影响，包括其积极面（如效率提升）和消极面（如潜在取代人类教育），认为其实施是迈向新时代教育的关键步骤。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04758v2",
      "published_date": "2025-02-10 13:03:35 UTC",
      "updated_date": "2025-03-10 06:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:35:47.031558"
    },
    {
      "arxiv_id": "2502.06425v2",
      "title": "Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroki Watanabe",
        "Motonobu Uchikoshi"
      ],
      "abstract": "Large language models (LLMs) are increasingly utilized in domains such as\nfinance, healthcare, and interpersonal relationships to provide advice tailored\nto user traits and contexts. However, this personalization often relies on\nsensitive data, raising critical privacy concerns and necessitating data\nminimization. To address these challenges, we propose a framework that\nintegrates zero-knowledge proof (ZKP) technology, specifically zkVM, with\nLLM-based chatbots. This integration enables privacy-preserving data sharing by\nverifying user traits without disclosing sensitive information. Our research\nintroduces both an architecture and a prompting strategy for this approach.\nThrough empirical evaluation, we clarify the current constraints and\nperformance limitations of both zkVM and the proposed prompting strategy,\nthereby demonstrating their practical feasibility in real-world scenarios.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)提供个性化建议时依赖敏感数据引发的隐私问题，提出了一种整合 Zero-Knowledge Proofs (ZKP) 技术的框架，特别是使用 zkVM 与 LLM-based chatbots 相结合。该框架通过验证用户特征而不泄露敏感信息，实现隐私保护的数据共享，并引入相应的架构和提示策略。通过实证评估，研究展示了该方法的实际可行性，同时指出了 zkVM 和提示策略的性能限制和挑战。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to The ACM Web Conference (WWW) 2025 Short Paper Track",
      "pdf_url": "http://arxiv.org/pdf/2502.06425v2",
      "published_date": "2025-02-10 13:02:00 UTC",
      "updated_date": "2025-04-24 00:37:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:35:59.050148"
    },
    {
      "arxiv_id": "2502.06424v1",
      "title": "CS-SHAP: Extending SHAP to Cyclic-Spectral Domain for Better Interpretability of Intelligent Fault Diagnosis",
      "title_zh": "CS-SHAP：将 SHAP 扩展到循环-谱域以提升智能故障诊断的可解释性",
      "authors": [
        "Qian Chen",
        "Xingjian Dong",
        "Kui Hu",
        "Kangkang Chen",
        "Zhike Peng",
        "Guang Meng"
      ],
      "abstract": "Neural networks (NNs), with their powerful nonlinear mapping and end-to-end\ncapabilities, are widely applied in mechanical intelligent fault diagnosis\n(IFD). However, as typical black-box models, they pose challenges in\nunderstanding their decision basis and logic, limiting their deployment in\nhigh-reliability scenarios. Hence, various methods have been proposed to\nenhance the interpretability of IFD. Among these, post-hoc approaches can\nprovide explanations without changing model architecture, preserving its\nflexibility and scalability. However, existing post-hoc methods often suffer\nfrom limitations in explanation forms. They either require preprocessing that\ndisrupts the end-to-end nature or overlook fault mechanisms, leading to\nsuboptimal explanations. To address these issues, we derived the\ncyclic-spectral (CS) transform and proposed the CS-SHAP by extending Shapley\nadditive explanations (SHAP) to the CS domain. CS-SHAP can evaluate\ncontributions from both carrier and modulation frequencies, aligning more\nclosely with fault mechanisms and delivering clearer and more accurate\nexplanations. Three datasets are utilized to validate the superior\ninterpretability of CS-SHAP, ensuring its correctness, reproducibility, and\npractical performance. With open-source code and outstanding interpretability,\nCS-SHAP has the potential to be widely adopted and become the post-hoc\ninterpretability benchmark in IFD, even in other classification tasks. The code\nis available on https://github.com/ChenQian0618/CS-SHAP.",
      "tldr_zh": "该研究针对神经网络在机械智能故障诊断（IFD）中的黑盒问题，提出 CS-SHAP 方法，通过扩展 Shapley Additive Explanations (SHAP) 到循环谱（Cyclic-Spectral）域，评估载波和调制频率的贡献，以提供更符合故障机制的解释。相比现有后验方法，CS-SHAP 避免了预处理干扰端到端特性，并通过三个数据集验证其解释的正确性、可重复性和实际性能。实验结果显示，该方法显著提升了解释的清晰度和准确性，具有潜力成为 IFD 和其他分类任务的后验解释基准，并已开源代码于 GitHub。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06424v1",
      "published_date": "2025-02-10 13:00:49 UTC",
      "updated_date": "2025-02-10 13:00:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:36:11.664800"
    },
    {
      "arxiv_id": "2502.06415v2",
      "title": "Systematic Outliers in Large Language Models",
      "title_zh": "大型语言模型中的系统异常值",
      "authors": [
        "Yongqi An",
        "Xu Zhao",
        "Tao Yu",
        "Ming Tang",
        "Jinqiao Wang"
      ],
      "abstract": "Outliers have been widely observed in Large Language Models (LLMs),\nsignificantly impacting model performance and posing challenges for model\ncompression. Understanding the functionality and formation mechanisms of these\noutliers is critically important. Existing works, however, largely focus on\nreducing the impact of outliers from an algorithmic perspective, lacking an\nin-depth investigation into their causes and roles. In this work, we provide a\ndetailed analysis of the formation process, underlying causes, and functions of\noutliers in LLMs. We define and categorize three types of outliers-activation\noutliers, weight outliers, and attention outliers-and analyze their\ndistributions across different dimensions, uncovering inherent connections\nbetween their occurrences and their ultimate influence on the attention\nmechanism. Based on these observations, we hypothesize and explore the\nmechanisms by which these outliers arise and function, demonstrating through\ntheoretical derivations and experiments that they emerge due to the\nself-attention mechanism's softmax operation. These outliers act as implicit\ncontext-aware scaling factors within the attention mechanism. As these outliers\nstem from systematic influences, we term them systematic outliers. Our study\nnot only enhances the understanding of Transformer-based LLMs but also shows\nthat structurally eliminating outliers can accelerate convergence and improve\nmodel compression. The code is avilable at\nhttps://github.com/an-yongqi/systematic-outliers.",
      "tldr_zh": "本文研究了 Large Language Models (LLMs) 中的 systematic outliers，这些异常值会显著影响模型性能和压缩。作者定义并分类了三种类型：activation outliers、weight outliers 和 attention outliers，并通过理论推导和实验分析揭示了它们源于自注意力机制的 softmax 操作，并作为隐式上下文感知缩放因子。结果显示，消除这些 systematic outliers 可以加速模型收敛并提升压缩效果，从而加深了对 Transformer-based LLMs 的理解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICLR 2025. Project Page:\n  https://github.com/an-yongqi/systematic-outliers",
      "pdf_url": "http://arxiv.org/pdf/2502.06415v2",
      "published_date": "2025-02-10 12:54:17 UTC",
      "updated_date": "2025-02-26 01:59:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:36:23.768040"
    },
    {
      "arxiv_id": "2502.07823v1",
      "title": "Runtime Tunable Tsetlin Machines for Edge Inference on eFPGAs",
      "title_zh": "用于 eFPGAs",
      "authors": [
        "Tousif Rahman",
        "Gang Mao",
        "Bob Pattison",
        "Sidharth Maheshwari",
        "Marcos Sartori",
        "Adrian Wheeldon",
        "Rishad Shafik",
        "Alex Yakovlev"
      ],
      "abstract": "Embedded Field-Programmable Gate Arrays (eFPGAs) allow for the design of\nhardware accelerators of edge Machine Learning (ML) applications at a lower\npower budget compared with traditional FPGA platforms. However, the limited\neFPGA logic and memory significantly constrain compute capabilities and model\nsize. As such, ML application deployment on eFPGAs is in direct contrast with\nthe most recent FPGA approaches developing architecture-specific\nimplementations and maximizing throughput over resource frugality. This paper\nfocuses on the opposite side of this trade-off: the proposed eFPGA accelerator\nfocuses on minimizing resource usage and allowing flexibility for on-field\nrecalibration over throughput. This allows for runtime changes in model size,\narchitecture, and input data dimensionality without offline resynthesis. This\nis made possible through the use of a bitwise compressed inference architecture\nof the Tsetlin Machine (TM) algorithm. TM compute does not require any\nmultiplication operations, being limited to only bitwise AND, OR, NOT,\nsummations and additions. Additionally, TM model compression allows the entire\nmodel to fit within the on-chip block RAM of the eFPGA. The paper uses this\naccelerator to propose a strategy for runtime model tuning in the field. The\nproposed approach uses 2.5x fewer Look-up-Tables (LUTs) and 3.38x fewer\nregisters than the current most resource-fugal design and achieves up to 129x\nenergy reduction compared with low-power microcontrollers running the same ML\napplication.",
      "tldr_zh": "这篇论文提出了一种在嵌入式现场可编程门阵列 (eFPGAs) 上运行的 Runtime Tunable Tsetlin Machines (TM) 加速器，用于边缘机器学习 (ML) 推理，重点是最小化资源使用并支持运行时调整模型大小、架构和输入数据维度，而无需离线重新合成。加速器采用 TM 算法的位压缩推理架构，仅需 bitwise AND, OR, NOT, summations 和 additions 等操作，使整个模型能完全放入 eFPGA 的片上块 RAM 中。该方法与现有设计相比，使用了 2.5 倍更少的 Look-up-Tables (LUTs) 和 3.38 倍更少的 registers，并实现了高达 129 倍的能量减少，适用于低功耗边缘应用。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted as a full paper by the 2025 EDGE AI FOUNDATION Austin",
      "pdf_url": "http://arxiv.org/pdf/2502.07823v1",
      "published_date": "2025-02-10 12:49:22 UTC",
      "updated_date": "2025-02-10 12:49:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:36:37.069273"
    },
    {
      "arxiv_id": "2502.07822v1",
      "title": "PDM-SSD: Single-Stage Three-Dimensional Object Detector With Point Dilation",
      "title_zh": "翻译失败",
      "authors": [
        "Ao Liang",
        "Haiyang Hua",
        "Jian Fang",
        "Wenyu Chen",
        "Huaici Zhao"
      ],
      "abstract": "Current Point-based detectors can only learn from the provided points, with\nlimited receptive fields and insufficient global learning capabilities for such\ntargets. In this paper, we present a novel Point Dilation Mechanism for\nsingle-stage 3D detection (PDM-SSD) that takes advantage of these two\nrepresentations. Specifically, we first use a PointNet-style 3D backbone for\nefficient feature encoding. Then, a neck with Point Dilation Mechanism (PDM) is\nused to expand the feature space, which involves two key steps: point dilation\nand feature filling. The former expands points to a certain size grid centered\naround the sampled points in Euclidean space. The latter fills the unoccupied\ngrid with feature for backpropagation using spherical harmonic coefficients and\nGaussian density function in terms of direction and scale. Next, we associate\nmultiple dilation centers and fuse coefficients to obtain sparse grid features\nthrough height compression. Finally, we design a hybrid detection head for\njoint learning, where on one hand, the scene heatmap is predicted to complement\nthe voting point set for improved detection accuracy, and on the other hand,\nthe target probability of detected boxes are calibrated through feature fusion.\nOn the challenging Karlsruhe Institute of Technology and Toyota Technological\nInstitute (KITTI) dataset, PDM-SSD achieves state-of-the-art results for\nmulti-class detection among single-modal methods with an inference speed of 68\nframes. We also demonstrate the advantages of PDM-SSD in detecting sparse and\nincomplete objects through numerous object-level instances. Additionally, PDM\ncan serve as an auxiliary network to establish a connection between sampling\npoints and object centers, thereby improving the accuracy of the model without\nsacrificing inference speed. Our code will be available at\nhttps://github.com/AlanLiangC/PDM-SSD.git.",
      "tldr_zh": "本文提出PDM-SSD，一种单阶段三维对象检测器，引入Point Dilation Mechanism (PDM)来扩展特征空间，解决现有Point-based检测器在感受野和全局学习能力上的局限性。该机制包括点膨胀（将采样点扩展到以点为中心的网格）和特征填充（使用球谐系数和高斯密度函数填充未占网格），并结合混合检测头通过场景热图预测和特征融合提升检测准确率。在KITTI数据集上，PDM-SSD在单模态方法中实现最先进的多类检测性能，推理速度达68帧/秒，并显著改善稀疏和不完整对象的检测效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07822v1",
      "published_date": "2025-02-10 12:41:13 UTC",
      "updated_date": "2025-02-10 12:41:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:36:48.724627"
    },
    {
      "arxiv_id": "2502.15749v2",
      "title": "TCProF: Time-Complexity Prediction SSL Framework",
      "title_zh": "TCProF：时间复杂度预测自监督学习框架",
      "authors": [
        "Joonghyuk Hahn",
        "Hyeseon Ahn",
        "Jungin Kim",
        "Soohan Lim",
        "Yo-Sub Han"
      ],
      "abstract": "Time complexity is a theoretic measure to determine the amount of time the\nalgorithm needs for its execution. In reality, developers write algorithms into\ncode snippets within limited resources, making the calculation of a code's time\ncomplexity a fundamental task. However, determining the precise time complexity\nof a code is theoretically undecidable. In response, recent advancements have\nleaned toward deploying datasets for code time complexity prediction and\ninitiating preliminary experiments for this challenge. We investigate the\nchallenge in low-resource scenarios where only a few labeled instances are\ngiven for training. Remarkably, we are the first to introduce TCProF: a\nTime-Complexity Prediction SSL Framework as an effective solution for code time\ncomplexity prediction in low-resource settings. TCProF significantly boosts\nperformance by integrating our augmentation, symbolic modules, and a\nco-training mechanism, achieving a more than 60% improvement over self-training\napproaches. We further provide an extensive comparative analysis between\nTCProF, ChatGPT, and Gemini-Pro, offering a detailed evaluation of our\napproach. Our code is at https://github.com/peer0/few-shot-tc.",
      "tldr_zh": "这篇论文针对低资源场景下代码时间复杂度预测的挑战，提出了TCProF：一个Time-Complexity Prediction SSL Framework，作为首个自监督学习解决方案。该框架通过整合augmentation（数据增强）、symbolic modules（符号模块）和co-training mechanism（联合训练机制），显著提升预测性能，比自训练方法提高了超过60%。作者还对TCProF与ChatGPT和Gemini-Pro进行了详细比较分析，并开源了代码（https://github.com/peer0/few-shot-tc）。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "26 pages, 13 figures, This paper has been accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.15749v2",
      "published_date": "2025-02-10 12:39:33 UTC",
      "updated_date": "2025-03-21 01:48:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:36:59.662932"
    },
    {
      "arxiv_id": "2502.06395v1",
      "title": "AppVLM: A Lightweight Vision Language Model for Online App Control",
      "title_zh": "AppVLM：轻量级视觉语言模型用于在线应用控制",
      "authors": [
        "Georgios Papoudakis",
        "Thomas Coste",
        "Zhihao Wu",
        "Jianye Hao",
        "Jun Wang",
        "Kun Shao"
      ],
      "abstract": "The utilisation of foundation models as smartphone assistants, termed app\nagents, is a critical research challenge. These agents aim to execute human\ninstructions on smartphones by interpreting textual instructions and performing\nactions via the device's interface. While promising, current approaches face\nsignificant limitations. Methods that use large proprietary models, such as\nGPT-4o, are computationally expensive, while those that use smaller fine-tuned\nmodels often lack adaptability to out-of-distribution tasks. In this work, we\nintroduce AppVLM, a lightweight Vision-Language Model (VLM). First, we\nfine-tune it offline on the AndroidControl dataset. Then, we refine its policy\nby collecting data from the AndroidWorld environment and performing further\ntraining iterations. Our results indicate that AppVLM achieves the highest\naction prediction accuracy in offline evaluation on the AndroidControl dataset,\ncompared to all evaluated baselines, and matches GPT-4o in online task\ncompletion success rate in the AndroidWorld environment, while being up to ten\ntimes faster. This makes AppVLM a practical and efficient solution for\nreal-world deployment.",
      "tldr_zh": "该研究针对智能手机助手（app agents）的挑战，提出了一种轻量级视觉语言模型（VLM）AppVLM，用于解释文本指令并通过设备界面执行动作，以解决现有方法计算开销大或适应性差的问题。AppVLM 先在 AndroidControl 数据集上进行离线微调，然后通过在 AndroidWorld 环境中收集数据并迭代训练来优化其策略。实验结果显示，AppVLM 在 AndroidControl 的离线动作预测准确率超越所有基线模型，并在 AndroidWorld 的在线任务完成成功率上与 GPT-4o 相当，但速度快 10 倍，从而提供了一个实用高效的实时部署解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06395v1",
      "published_date": "2025-02-10 12:32:21 UTC",
      "updated_date": "2025-02-10 12:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:37:11.540157"
    },
    {
      "arxiv_id": "2503.13463v1",
      "title": "Completeness of Datasets Documentation on ML/AI repositories: an Empirical Investigation",
      "title_zh": "ML/AI ",
      "authors": [
        "Marco Rondina",
        "Antonio Vetrò",
        "Juan Carlos De Martin"
      ],
      "abstract": "ML/AI is the field of computer science and computer engineering that arguably\nreceived the most attention and funding over the last decade. Data is the key\nelement of ML/AI, so it is becoming increasingly important to ensure that users\nare fully aware of the quality of the datasets that they use, and of the\nprocess generating them, so that possible negative impacts on downstream\neffects can be tracked, analysed, and, where possible, mitigated. One of the\ntools that can be useful in this perspective is dataset documentation. The aim\nof this work is to investigate the state of dataset documentation practices,\nmeasuring the completeness of the documentation of several popular datasets in\nML/AI repositories. We created a dataset documentation schema -- the\nDocumentation Test Sheet (DTS) -- that identifies the information that should\nalways be attached to a dataset (to ensure proper dataset choice and informed\nuse), according to relevant studies in the literature. We verified 100 popular\ndatasets from four different repositories with the DTS to investigate which\ninformation was present. Overall, we observed a lack of relevant documentation,\nespecially about the context of data collection and data processing,\nhighlighting a paucity of transparency.",
      "tldr_zh": "本研究调查了 ML/AI 仓库中数据集文档的完整性，旨在评估用户对数据集质量和生成过程的了解，以减少潜在负面影响。研究者开发了 Documentation Test Sheet (DTS) 模式，根据文献标识了应包含的关键信息，并使用 DTS 检查了四个仓库中的 100 个流行数据集。结果显示，大部分数据集文档缺乏透明度，尤其是在数据收集和处理上下文方面，突显了 ML/AI 领域文档实践的不足。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13463v1",
      "published_date": "2025-02-10 12:31:42 UTC",
      "updated_date": "2025-02-10 12:31:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:37:22.450031"
    },
    {
      "arxiv_id": "2502.06379v1",
      "title": "Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo",
      "title_zh": "翻译失败",
      "authors": [
        "Filip Ekström Kelvinius",
        "Zheng Zhao",
        "Fredrik Lindsten"
      ],
      "abstract": "A recent line of research has exploited pre-trained generative diffusion\nmodels as priors for solving Bayesian inverse problems. We contribute to this\nresearch direction by designing a sequential Monte Carlo method for\nlinear-Gaussian inverse problems which builds on ``decoupled diffusion\", where\nthe generative process is designed such that larger updates to the sample are\npossible. The method is asymptotically exact and we demonstrate the\neffectiveness of our Decoupled Diffusion Sequential Monte Carlo (DDSMC)\nalgorithm on both synthetic data and image reconstruction tasks. Further, we\ndemonstrate how the approach can be extended to discrete data.",
      "tldr_zh": "这篇论文提出了一种基于Decoupled Diffusion的Sequential Monte Carlo方法，用于解决线性高斯Bayesian Inverse Problems。该方法通过设计生成过程来允许更大样本更新，并确保算法的渐近精确性。实验结果显示，Decoupled Diffusion Sequential Monte Carlo (DDSMC)算法在合成数据和图像重建任务上表现出色，并成功扩展到离散数据处理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06379v1",
      "published_date": "2025-02-10 11:59:02 UTC",
      "updated_date": "2025-02-10 11:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:37:35.053937"
    },
    {
      "arxiv_id": "2502.07821v1",
      "title": "Amnesia as a Catalyst for Enhancing Black Box Pixel Attacks in Image Classification and Object Detection",
      "title_zh": "Amnesia 作为催化剂，用于增强图像分类和目标检测中的黑箱像素攻击",
      "authors": [
        "Dongsu Song",
        "Daehwa Ko",
        "Jay Hoon Jung"
      ],
      "abstract": "It is well known that query-based attacks tend to have relatively higher\nsuccess rates in adversarial black-box attacks. While research on black-box\nattacks is actively being conducted, relatively few studies have focused on\npixel attacks that target only a limited number of pixels. In image\nclassification, query-based pixel attacks often rely on patches, which heavily\ndepend on randomness and neglect the fact that scattered pixels are more\nsuitable for adversarial attacks. Moreover, to the best of our knowledge,\nquery-based pixel attacks have not been explored in the field of object\ndetection. To address these issues, we propose a novel pixel-based black-box\nattack called Remember and Forget Pixel Attack using Reinforcement\nLearning(RFPAR), consisting of two main components: the Remember and Forget\nprocesses. RFPAR mitigates randomness and avoids patch dependency by leveraging\nrewards generated through a one-step RL algorithm to perturb pixels. RFPAR\neffectively creates perturbed images that minimize the confidence scores while\nadhering to limited pixel constraints. Furthermore, we advance our proposed\nattack beyond image classification to object detection, where RFPAR reduces the\nconfidence scores of detected objects to avoid detection. Experiments on the\nImageNet-1K dataset for classification show that RFPAR outperformed\nstate-of-the-art query-based pixel attacks. For object detection, using the\nMSCOCO dataset with YOLOv8 and DDQ, RFPAR demonstrates comparable mAP reduction\nto state-of-the-art query-based attack while requiring fewer query. Further\nexperiments on the Argoverse dataset using YOLOv8 confirm that RFPAR\neffectively removed objects on a larger scale dataset. Our code is available at\nhttps://github.com/KAU-QuantumAILab/RFPAR.",
      "tldr_zh": "本论文提出了一种名为RFPAR的像素-based黑盒攻击方法，利用Reinforcement Learning的Remember and Forget过程，针对图像分类和对象检测任务扰动有限像素，以降低模型置信度分数并减少随机性依赖。RFPAR通过一步RL算法生成奖励来优化像素扰动，在ImageNet-1K数据集上表现出色，优于现有查询-based像素攻击。实验结果显示，在MSCOCO数据集上使用YOLOv8和DDQ，RFPAR实现了可比的mAP减少但查询更少，并在Argoverse数据集上有效移除对象。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a poster at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2502.07821v1",
      "published_date": "2025-02-10 11:49:41 UTC",
      "updated_date": "2025-02-10 11:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:37:48.891088"
    },
    {
      "arxiv_id": "2502.06374v2",
      "title": "Hyperparameters in Score-Based Membership Inference Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Gauri Pradhan",
        "Joonas Jälkö",
        "Marlon Tobaben",
        "Antti Honkela"
      ],
      "abstract": "Membership Inference Attacks (MIAs) have emerged as a valuable framework for\nevaluating privacy leakage by machine learning models. Score-based MIAs are\ndistinguished, in particular, by their ability to exploit the confidence scores\nthat the model generates for particular inputs. Existing score-based MIAs\nimplicitly assume that the adversary has access to the target model's\nhyperparameters, which can be used to train the shadow models for the attack.\nIn this work, we demonstrate that the knowledge of target hyperparameters is\nnot a prerequisite for MIA in the transfer learning setting. Based on this, we\npropose a novel approach to select the hyperparameters for training the shadow\nmodels for MIA when the attacker has no prior knowledge about them by matching\nthe output distributions of target and shadow models. We demonstrate that using\nthe new approach yields hyperparameters that lead to an attack near\nindistinguishable in performance from an attack that uses target\nhyperparameters to train the shadow models. Furthermore, we study the empirical\nprivacy risk of unaccounted use of training data for hyperparameter\noptimization (HPO) in differentially private (DP) transfer learning. We find no\nstatistically significant evidence that performing HPO using training data\nwould increase vulnerability to MIA.",
      "tldr_zh": "本文研究了基于分数的成员推断攻击 (Score-based MIAs)，这些攻击依赖于模型的置信分数来评估机器学习模型的隐私泄露，但传统方法假设攻击者知道目标模型的超参数。作者证明，在迁移学习 (Transfer Learning) 设置中，攻击者无需获取目标超参数，而是提出了一种新方法，通过匹配目标模型和影子模型的输出分布来选择影子模型的超参数。实验结果显示，该方法的效果几乎与直接使用目标超参数训练影子模型相当，进一步探讨了在差分隐私 (DP) 迁移学习中，使用训练数据进行超参数优化 (HPO) 是否会增加隐私风险，但未发现统计显著证据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been accepted for publication in the 3rd IEEE\n  Conference on Secure and Trustworthy Machine Learning (SaTML'25). The final\n  version will be available on IEEE Xplore",
      "pdf_url": "http://arxiv.org/pdf/2502.06374v2",
      "published_date": "2025-02-10 11:44:46 UTC",
      "updated_date": "2025-02-27 05:44:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:38:00.487262"
    },
    {
      "arxiv_id": "2502.06348v2",
      "title": "AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Gao",
        "Yuan Wang",
        "Qingsong Wei",
        "Yong Liu",
        "Rick Siow Mong Goh",
        "David Lo"
      ],
      "abstract": "Decentralized finance (DeFi) applications depend on accurate price oracles to\nensure secure transactions, yet these oracles are highly vulnerable to\nmanipulation, enabling attackers to exploit smart contract vulnerabilities for\nunfair asset valuation and financial gain. Detecting such manipulations\ntraditionally relies on the manual effort of experienced experts, presenting\nsignificant challenges. In this paper, we propose a novel LLM-driven framework\nthat automates the detection of price oracle manipulations by leveraging the\ncomplementary strengths of different LLM models (LLMs). Our approach begins\nwith domain-specific knowledge extraction, where an LLM model synthesizes\nprecise insights about price oracle vulnerabilities from top-tier academic\npapers, eliminating the need for profound expertise from developers or\nauditors. This knowledge forms the foundation for a second LLM model to\ngenerate structured, context-aware chain of thought prompts, which guide a\nthird LLM model in accurately identifying manipulation patterns in smart\ncontracts. We validate the effectiveness of framework through experiments on 60\nknown vulnerabilities from 46 real-world DeFi attacks or projects spanning 2021\nto 2023. The best performing combination of LLMs (Haiku-Haiku-4o-mini)\nidentified by AiRacleX demonstrate a 2.58-times improvement in recall (0.667 vs\n0.259) compared to the state-of-the-art tool GPTScan, while maintaining\ncomparable precision. Furthermore, our framework demonstrates the feasibility\nof replacing commercial models with open-source alternatives, enhancing privacy\nand security for developers.",
      "tldr_zh": "本文提出 AiRacleX，一种基于 LLM 的框架，用于自动检测 DeFi 中的价格预言机操纵问题，通过 LLM 驱动的知识挖掘和提示生成来减少对专家手动干预的依赖。该框架利用多个 LLM 模型的互补优势：首先一个 LLM 从顶尖学术论文中提取领域特定知识，其次生成结构化的 chain of thought prompts，最后引导第三个 LLM 识别智能合约中的操纵模式。在实验中，AiRacleX 在 60 个真实漏洞数据集上比现有工具 GPTScan 的召回率提高了 2.58 倍（0.667 vs 0.259），并支持开源模型替换以提升隐私和安全。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06348v2",
      "published_date": "2025-02-10 10:58:09 UTC",
      "updated_date": "2025-02-11 03:40:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:38:13.115994"
    },
    {
      "arxiv_id": "2502.06341v1",
      "title": "Facial Analysis Systems and Down Syndrome",
      "title_zh": "面部分析系统与唐氏综合征",
      "authors": [
        "Marco Rondina",
        "Fabiana Vinci",
        "Antonio Vetrò",
        "Juan Carlos De Martin"
      ],
      "abstract": "The ethical, social and legal issues surrounding facial analysis technologies\nhave been widely debated in recent years. Key critics have argued that these\ntechnologies can perpetuate bias and discrimination, particularly against\nmarginalized groups. We contribute to this field of research by reporting on\nthe limitations of facial analysis systems with the faces of people with Down\nsyndrome: this particularly vulnerable group has received very little attention\nin the literature so far. This study involved the creation of a specific\ndataset of face images. An experimental group with faces of people with Down\nsyndrome, and a control group with faces of people who are not affected by the\nsyndrome. Two commercial tools were tested on the dataset, along three tasks:\ngender recognition, age prediction and face labelling. The results show an\noverall lower accuracy of prediction in the experimental group, and other\nspecific patterns of performance differences: i) high error rates in gender\nrecognition in the category of males with Down syndrome; ii) adults with Down\nsyndrome were more often incorrectly labelled as children; iii) social\nstereotypes are propagated in both the control and experimental groups, with\nlabels related to aesthetics more often associated with women, and labels\nrelated to education level and skills more often associated with men. These\nresults, although limited in scope, shed new light on the biases that alter\nface classification when applied to faces of people with Down syndrome. They\nconfirm the structural limitation of the technology, which is inherently\ndependent on the datasets used to train the models.",
      "tldr_zh": "本文研究了面部分析系统(Facial Analysis Systems)在处理唐氏综合征(Down Syndrome)患者面部时的局限性，揭示了这些技术可能加剧偏见和歧视的问题。研究创建了一个特定数据集，包括唐氏综合征患者实验组和对照组面部图像，并测试了两个商业工具在性别识别(Gender Recognition)、年龄预测(Age Prediction)和面部标签(Face Labelling)任务上的表现。结果显示，实验组的准确率整体较低，男性患者在性别识别中错误率显著升高，成年患者常被错误标记为儿童，且社会刻板印象（如与女性相关的美学标签和与男性相关的教育标签）在两组中均传播。该研究确认了技术的结构性限制，强调其依赖于训练数据集，并呼吁更多关注弱势群体在AI应用中的公平性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06341v1",
      "published_date": "2025-02-10 10:43:55 UTC",
      "updated_date": "2025-02-10 10:43:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:38:25.798858"
    },
    {
      "arxiv_id": "2502.06336v1",
      "title": "DefTransNet: A Transformer-based Method for Non-Rigid Point Cloud Registration in the Simulation of Soft Tissue Deformation",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Monji-Azad",
        "Marvin Kinz",
        "Siddharth Kothari",
        "Robin Khanna",
        "Amrei Carla Mihan",
        "David Maennel",
        "Claudia Scherl",
        "Juergen Hesser"
      ],
      "abstract": "Soft-tissue surgeries, such as tumor resections, are complicated by tissue\ndeformations that can obscure the accurate location and shape of tissues. By\nrepresenting tissue surfaces as point clouds and applying non-rigid point cloud\nregistration (PCR) methods, surgeons can better understand tissue deformations\nbefore, during, and after surgery. Existing non-rigid PCR methods, such as\nfeature-based approaches, struggle with robustness against challenges like\nnoise, outliers, partial data, and large deformations, making accurate point\ncorrespondence difficult. Although learning-based PCR methods, particularly\nTransformer-based approaches, have recently shown promise due to their\nattention mechanisms for capturing interactions, their robustness remains\nlimited in challenging scenarios. In this paper, we present DefTransNet, a\nnovel end-to-end Transformer-based architecture for non-rigid PCR. DefTransNet\nis designed to address the key challenges of deformable registration, including\nlarge deformations, outliers, noise, and partial data, by inputting source and\ntarget point clouds and outputting displacement vector fields. The proposed\nmethod incorporates a learnable transformation matrix to enhance robustness to\naffine transformations, integrates global and local geometric information, and\ncaptures long-range dependencies among points using Transformers. We validate\nour approach on four datasets: ModelNet, SynBench, 4DMatch, and DeformedTissue,\nusing both synthetic and real-world data to demonstrate the generalization of\nour proposed method. Experimental results demonstrate that DefTransNet\noutperforms current state-of-the-art registration networks across various\nchallenging conditions. Our code and data are publicly available.",
      "tldr_zh": "本论文针对软组织手术（如肿瘤切除）中组织变形的挑战，提出了一种基于Transformer的非刚性点云注册方法DefTransNet，以帮助外科医生更准确地理解组织变形。该方法采用端到端架构，输入源和目标点云，输出位移矢量场，并通过可学习的变换矩阵整合全球和局部几何信息，以及Transformer捕获点之间的长程依赖，从而提升对噪声、异常值、部分数据和大变形的鲁棒性。在ModelNet、SynBench、4DMatch和DeformedTissue数据集上的实验验证显示，DefTransNet在各种复杂条件下优于现有最先进注册网络，证明了其泛化能力。代码和数据已公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06336v1",
      "published_date": "2025-02-10 10:37:21 UTC",
      "updated_date": "2025-02-10 10:37:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:38:38.705894"
    },
    {
      "arxiv_id": "2502.06327v1",
      "title": "Prompt-Driven Continual Graph Learning",
      "title_zh": "提示驱动的持续图学习",
      "authors": [
        "Qi Wang",
        "Tianfei Zhou",
        "Ye Yuan",
        "Rui Mao"
      ],
      "abstract": "Continual Graph Learning (CGL), which aims to accommodate new tasks over\nevolving graph data without forgetting prior knowledge, is garnering\nsignificant research interest. Mainstream solutions adopt the memory\nreplay-based idea, ie, caching representative data from earlier tasks for\nretraining the graph model. However, this strategy struggles with scalability\nissues for constantly evolving graphs and raises concerns regarding data\nprivacy. Inspired by recent advancements in the prompt-based learning paradigm,\nthis paper introduces a novel prompt-driven continual graph learning\n(PROMPTCGL) framework, which learns a separate prompt for each incoming task\nand maintains the underlying graph neural network model fixed. In this way,\nPROMPTCGL naturally avoids catastrophic forgetting of knowledge from previous\ntasks. More specifically, we propose hierarchical prompting to instruct the\nmodel from both feature- and topology-level to fully address the variability of\ntask graphs in dynamic continual learning. Additionally, we develop a\npersonalized prompt generator to generate tailored prompts for each graph node\nwhile minimizing the number of prompts needed, leading to constant memory\nconsumption regardless of the graph scale. Extensive experiments on four\nbenchmarks show that PROMPTCGL achieves superior performance against existing\nCGL approaches while significantly reducing memory consumption. Our code is\navailable at https://github.com/QiWang98/PromptCGL.",
      "tldr_zh": "这篇论文针对 Continual Graph Learning (CGL) 的挑战，提出了一种基于提示学习的框架 PromptCGL，以处理演变图数据上的新任务，同时避免对先前知识的灾难性遗忘。不同于主流的 memory replay 方法，PromptCGL 为每个新任务学习单独的提示，并保持底层图神经网络模型固定，从而解决可扩展性和数据隐私问题。具体而言，该框架引入 hierarchical prompting，从特征和拓扑层面指导模型，并开发 personalized prompt generator，为每个图节点生成定制提示，以最小化提示数量并实现恒定的内存消耗。在四个基准实验中，PromptCGL 比现有 CGL 方法表现出色，同时显著减少内存消耗。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 7figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06327v1",
      "published_date": "2025-02-10 10:28:11 UTC",
      "updated_date": "2025-02-10 10:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:38:51.171007"
    },
    {
      "arxiv_id": "2502.06324v1",
      "title": "UniDemoiré: Towards Universal Image Demoiréing with Data Generation and Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Zemin Yang",
        "Yujing Sun",
        "Xidong Peng",
        "Siu Ming Yiu",
        "Yuexin Ma"
      ],
      "abstract": "Image demoir\\'eing poses one of the most formidable challenges in image\nrestoration, primarily due to the unpredictable and anisotropic nature of\nmoir\\'e patterns. Limited by the quantity and diversity of training data,\ncurrent methods tend to overfit to a single moir\\'e domain, resulting in\nperformance degradation for new domains and restricting their robustness in\nreal-world applications. In this paper, we propose a universal image\ndemoir\\'eing solution, UniDemoir\\'e, which has superior generalization\ncapability. Notably, we propose innovative and effective data generation and\nsynthesis methods that can automatically provide vast high-quality moir\\'e\nimages to train a universal demoir\\'eing model. Our extensive experiments\ndemonstrate the cutting-edge performance and broad potential of our approach\nfor generalized image demoir\\'eing.",
      "tldr_zh": "图像去摩尔纹（Image Demoiréing）是图像恢复领域的重大挑战，由于摩尔纹模式的不确定性和各向异性，现有的方法往往因训练数据量和多样性不足而过拟合单一领域。论文提出UniDemoiré，一种通用的解决方案，通过创新的数据生成和合成方法自动生成大量高质量的摩尔纹图像，用于训练具有优越泛化能力的模型。实验结果证明，该方法在各种场景下实现了前沿性能，并展示了其在真实世界泛化图像去摩尔纹的广阔潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06324v1",
      "published_date": "2025-02-10 10:20:11 UTC",
      "updated_date": "2025-02-10 10:20:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:39:01.331844"
    },
    {
      "arxiv_id": "2502.08664v1",
      "title": "Motion Forecasting for Autonomous Vehicles: A Survey",
      "title_zh": "自动驾驶车辆的运动预测：综述",
      "authors": [
        "Jianxin Shi",
        "Jinhao Chen",
        "Yuandong Wang",
        "Li Sun",
        "Chunyang Liu",
        "Wei Xiong",
        "Tianyu Wo"
      ],
      "abstract": "In recent years, the field of autonomous driving has attracted increasingly\nsignificant public interest. Accurately forecasting the future behavior of\nvarious traffic participants is essential for the decision-making of Autonomous\nVehicles (AVs). In this paper, we focus on both scenario-based and\nperception-based motion forecasting for AVs. We propose a formal problem\nformulation for motion forecasting and summarize the main challenges\nconfronting this area of research. We also detail representative datasets and\nevaluation metrics pertinent to this field. Furthermore, this study classifies\nrecent research into two main categories: supervised learning and\nself-supervised learning, reflecting the evolving paradigms in both\nscenario-based and perception-based motion forecasting. In the context of\nsupervised learning, we thoroughly examine and analyze each key element of the\nmethodology. For self-supervised learning, we summarize commonly adopted\ntechniques. The paper concludes and discusses potential research directions,\naiming to propel progress in this vital area of AV technology.",
      "tldr_zh": "本论文对自动驾驶车辆（Autonomous Vehicles, AVs）的运动预测进行了全面调查，强调了准确预测交通参与者行为对于AVs决策的重要性。它提出了运动预测的正式问题表述，总结了主要挑战、代表性数据集（如场景-based和perception-based数据集）和评估指标，并将现有研究分类为监督学习和自监督学习，详细分析了每类方法的关键元素和常用技术。最终，论文讨论了潜在的研究方向，以推动该领域的进展。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "31 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.08664v1",
      "published_date": "2025-02-10 10:13:24 UTC",
      "updated_date": "2025-02-10 10:13:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:39:12.851724"
    },
    {
      "arxiv_id": "2502.06314v2",
      "title": "From Pixels to Components: Eigenvector Masking for Visual Representation Learning",
      "title_zh": "从像素到组件：特征向量掩码用于视觉表示学习",
      "authors": [
        "Alice Bizeul",
        "Thomas Sutter",
        "Alain Ryser",
        "Bernhard Schölkopf",
        "Julius von Kügelgen",
        "Julia E. Vogt"
      ],
      "abstract": "Predicting masked from visible parts of an image is a powerful\nself-supervised approach for visual representation learning. However, the\ncommon practice of masking random patches of pixels exhibits certain failure\nmodes, which can prevent learning meaningful high-level features, as required\nfor downstream tasks. We propose an alternative masking strategy that operates\non a suitable transformation of the data rather than on the raw pixels.\nSpecifically, we perform principal component analysis and then randomly mask a\nsubset of components, which accounts for a fixed ratio of the data variance.\nThe learning task then amounts to reconstructing the masked components from the\nvisible ones. Compared to local patches of pixels, the principal components of\nimages carry more global information. We thus posit that predicting masked from\nvisible components involves more high-level features, allowing our masking\nstrategy to extract more useful representations. This is corroborated by our\nempirical findings which demonstrate improved image classification performance\nfor component over pixel masking. Our method thus constitutes a simple and\nrobust data-driven alternative to traditional masked image modeling approaches.",
      "tldr_zh": "该论文提出了一种名为“Eigenvector Masking”的新策略，用于改进自监督视觉表示学习，解决传统随机像素掩盖方法在学习高级特征时的失败模式。方法涉及对图像数据进行主成分分析(PCA)，然后随机掩盖占数据方差固定比例的组件，要求模型从可见组件重建被掩盖部分，从而利用组件的全局信息提取更有效的表示。实验结果显示，与像素掩盖相比，该方法在图像分类任务上显著提升性能，提供了一种简单且稳健的数据驱动替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Under review",
      "pdf_url": "http://arxiv.org/pdf/2502.06314v2",
      "published_date": "2025-02-10 10:06:46 UTC",
      "updated_date": "2025-02-11 16:04:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:39:24.815758"
    },
    {
      "arxiv_id": "2502.06914v2",
      "title": "UniZyme: A Unified Protein Cleavage Site Predictor Enhanced with Enzyme Active-Site Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Chenao Li",
        "Shuo Yan",
        "Enyan Dai"
      ],
      "abstract": "Enzyme-catalyzed protein cleavage is essential for many biological functions.\nAccurate prediction of cleavage sites can facilitate various applications such\nas drug development, enzyme design, and a deeper understanding of biological\nmechanisms. However, most existing models are restricted to an individual\nenzyme, which neglects shared knowledge of enzymes and fails generalize to\nnovel enzymes. Thus, we introduce a unified protein cleavage site predictor\nnamed UniZyme, which can generalize across diverse enzymes. To enhance the\nenzyme encoding for the protein cleavage site prediction, UniZyme employs a\nnovel biochemically-informed model architecture along with active-site\nknowledge of proteolytic enzymes. Extensive experiments demonstrate that\nUniZyme achieves high accuracy in predicting cleavage sites across a range of\nproteolytic enzymes, including unseen enzymes. The code is available in\nhttps://anonymous.4open.science/r/UniZyme-4A67.",
      "tldr_zh": "本研究提出 UniZyme，一种统一的蛋白质裂解位点预测器，旨在解决现有模型仅限于单个酶的局限性，从而实现对多种酶的泛化预测。UniZyme 采用新型的生物化学信息模型架构，并整合酶活性位点知识来增强酶编码，从而提高预测准确性。实验结果显示，该模型在各种蛋白质裂解酶上，包括未见酶，均取得了高准确率，为药物开发和酶设计等应用提供了有力工具。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "92E10, 68T07, 68Q32, 92D15",
        "I.2.6; I.2.7; J.3"
      ],
      "primary_category": "q-bio.QM",
      "comment": "18 pages,8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06914v2",
      "published_date": "2025-02-10 09:46:26 UTC",
      "updated_date": "2025-02-12 16:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:39:37.274472"
    },
    {
      "arxiv_id": "2502.08663v1",
      "title": "Hallucination Detection: A Probabilistic Framework Using Embeddings Distance Analysis",
      "title_zh": "幻觉检测：使用嵌入距离分析的概率框架",
      "authors": [
        "Emanuele Ricco",
        "Lorenzo Cima",
        "Roberto Di Pietro"
      ],
      "abstract": "Hallucinations are one of the major issues affecting LLMs, hindering their\nwide adoption in production systems. While current research solutions for\ndetecting hallucinations are mainly based on heuristics, in this paper we\nintroduce a mathematically sound methodology to reason about hallucination, and\nleverage it to build a tool to detect hallucinations. To the best of our\nknowledge, we are the first to show that hallucinated content has structural\ndifferences with respect to correct content. To prove this result, we resort to\nthe Minkowski distances in the embedding space. Our findings demonstrate\nstatistically significant differences in the embedding distance distributions,\nthat are also scale free -- they qualitatively hold regardless of the distance\nnorm used and the number of keywords, questions, or responses. We leverage\nthese structural differences to develop a tool to detect hallucinated\nresponses, achieving an accuracy of 66\\% for a specific configuration of system\nparameters -- comparable with the best results in the field. In conclusion, the\nsuggested methodology is promising and novel, possibly paving the way for\nfurther research in the domain, also along the directions highlighted in our\nfuture work.",
      "tldr_zh": "本文提出一个基于概率框架的幻觉检测方法，使用嵌入距离分析（embeddings distance analysis）来解决大型语言模型（LLMs）中的幻觉问题，这是首次证明幻觉内容在结构上与正确内容存在显著差异。方法通过Minkowski distances在嵌入空间中分析距离分布，揭示这些差异是统计上显著且无尺度的（scale-free），不依赖于距离范数或内容规模。基于此，作者开发了一个检测工具，实现了66%的准确率，与领域内最佳结果相当。该框架为幻觉检测研究提供了新颖的数学基础，并为未来工作指明了方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.08663v1",
      "published_date": "2025-02-10 09:44:13 UTC",
      "updated_date": "2025-02-10 09:44:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:39:49.817910"
    },
    {
      "arxiv_id": "2502.06298v1",
      "title": "SeaExam and SeaBench: Benchmarking LLMs with Local Multilingual Questions in Southeast Asia",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoqun Liu",
        "Wenxuan Zhang",
        "Jiahao Ying",
        "Mahani Aljunied",
        "Anh Tuan Luu",
        "Lidong Bing"
      ],
      "abstract": "This study introduces two novel benchmarks, SeaExam and SeaBench, designed to\nevaluate the capabilities of Large Language Models (LLMs) in Southeast Asian\n(SEA) application scenarios. Unlike existing multilingual datasets primarily\nderived from English translations, these benchmarks are constructed based on\nreal-world scenarios from SEA regions. SeaExam draws from regional educational\nexams to form a comprehensive dataset that encompasses subjects such as local\nhistory and literature. In contrast, SeaBench is crafted around multi-turn,\nopen-ended tasks that reflect daily interactions within SEA communities. Our\nevaluations demonstrate that SeaExam and SeaBench more effectively discern LLM\nperformance on SEA language tasks compared to their translated benchmarks. This\nhighlights the importance of using real-world queries to assess the\nmultilingual capabilities of LLMs.",
      "tldr_zh": "这篇论文引入了两个新基准——SeaExam 和 SeaBench，用于评估大型语言模型 (LLMs) 在东南亚 (SEA) 应用场景中的多语言能力。这些基准基于真实东南亚地区场景构建，而非英语翻译数据集，其中 SeaExam 源自区域教育考试，涵盖本地历史和文学等主题；SeaBench 则设计为多轮开放式任务，反映日常社区互动。实验结果表明，与翻译基准相比，SeaExam 和 SeaBench 更有效地区分 LLMs 在 SEA 语言任务上的表现，突出了使用真实查询评估多语言能力的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Findings of NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06298v1",
      "published_date": "2025-02-10 09:40:25 UTC",
      "updated_date": "2025-02-10 09:40:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:40:01.557843"
    },
    {
      "arxiv_id": "2502.08662v2",
      "title": "RoToR: Towards More Reliable Responses for Order-Invariant Inputs",
      "title_zh": "RoToR：针对顺序无关输入的更可靠响应",
      "authors": [
        "Soyoung Yoon",
        "Dongha Ahn",
        "Youngwon Lee",
        "Minkyu Jung",
        "HyungJoo Jang",
        "Seung-won Hwang"
      ],
      "abstract": "Mitigating positional bias of language models (LMs) for listwise inputs is a\nwell-known and important problem (e.g., lost-in-the-middle). While zero-shot\norder-invariant LMs have been proposed to solve this issue, their success on\npractical listwise problems has been limited. In this work, as a first\ncontribution, we identify and overcome two limitations to make zero-shot\ninvariant LMs more practical: (1) training and inference distribution mismatch\narising from modifying positional ID assignments to enforce invariance, and (2)\nfailure to adapt to a mixture of order-invariant and sensitive inputs in\npractical listwise problems. Then, to overcome these issues we propose (1)\nRoToR, a zero-shot invariant LM for genuinely order-invariant inputs with\nminimal modifications of positional IDs, and (2) Selective Routing, an adaptive\nframework that handles both order-invariant and order-sensitive inputs in\nlistwise tasks. On the Lost in the middle (LitM), Knowledge Graph QA (KGQA),\nand MMLU benchmarks, we show that RoToR with Selective Routing can effectively\nhandle practical listwise input tasks in a zero-shot manner.",
      "tldr_zh": "该论文针对语言模型（LMs）在处理列表式输入时的位置偏差问题（如lost-in-the-middle），提出RoToR框架，以提升响应可靠性。RoToR通过最小修改位置ID来实现零样本顺序不变（zero-shot order-invariant）输入处理，并引入Selective Routing机制来适应混合的顺序不变和顺序敏感输入。实验结果显示，在Lost in the middle (LitM)、Knowledge Graph QA (KGQA)和MMLU基准上，RoToR与Selective Routing在零样本场景下有效提高了任务性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.08662v2",
      "published_date": "2025-02-10 09:34:15 UTC",
      "updated_date": "2025-03-07 09:55:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:40:14.196995"
    },
    {
      "arxiv_id": "2502.09642v2",
      "title": "Krutrim LLM: Multilingual Foundational Model for over a Billion People",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Kallappa",
        "Palash Kamble",
        "Abhinav Ravi",
        "Akshat Patidar",
        "Vinayak Dhruv",
        "Deepak Kumar",
        "Raghav Awasthi",
        "Arveti Manjunath",
        "Himanshu Gupta",
        "Shubham Agarwal",
        "Kumar Ashish",
        "Gautam Bhargava",
        "Chandra Khatri"
      ],
      "abstract": "India is a diverse society with unique challenges in developing AI systems,\nincluding linguistic diversity, oral traditions, data accessibility, and\nscalability. Existing foundation models are primarily trained on English,\nlimiting their effectiveness for India's population. Indic languages comprise\nonly 1 percent of Common Crawl corpora despite India representing 18 percent of\nthe global population, leading to linguistic biases. Thousands of regional\nlanguages, dialects, and code mixing create additional representation\nchallenges due to sparse training data.\n  We introduce Krutrim LLM, a 2 trillion token multilingual model designed for\nIndia's linguistic landscape. It incorporates the largest known Indic dataset,\nmitigating data scarcity and ensuring balanced performance across dialects.\nKrutrim outperforms or matches state-of-the-art models on Indic benchmarks\nwhile maintaining competitive English performance. Despite being significantly\nsmaller in training flops, Krutrim LLM matches or exceeds models like LLAMA-2\non 10 out of 16 tasks, with an average score of 0.57 versus 0.55. This\nevidences Krutrim's flexible multilingual fluency across diverse linguistic\ncontexts.\n  Krutrim is integrated with real-time search to improve factual accuracy in\nconversational AI applications. This enhances accessibility for over 1 billion\nusers worldwide. Through intentional design choices addressing data imbalances,\nKrutrim LLM signifies meaningful progress in building ethical, globally\nrepresentative AI models.",
      "tldr_zh": "该论文介绍了Krutrim LLM，一种针对印度语言多样性的多语言基础模型，旨在解决现有AI模型的语言偏见和数据稀缺问题，通过整合最大的Indic数据集和2万亿token的训练数据，实现对数千种方言和代码混合的平衡性能。相比LLAMA-2等模型，Krutrim在Indic基准上表现出色或相当，同时保持竞争性的英语表现，在16个任务中平均分数达0.57，并在10个任务上超越对手，尽管其训练FLOPs更小。Krutrim还与实时搜索集成，提升对话AI的实际准确性和可访问性，为超过10亿用户提供更具代表性和道德的全球AI解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09642v2",
      "published_date": "2025-02-10 09:32:08 UTC",
      "updated_date": "2025-02-24 06:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:40:26.325982"
    },
    {
      "arxiv_id": "2502.06289v1",
      "title": "Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?",
      "title_zh": "翻译失败",
      "authors": [
        "Qingshan Hou",
        "Yukun Zhou",
        "Jocelyn Hui Lin Goh",
        "Ke Zou",
        "Samantha Min Er Yew",
        "Sahana Srinivasan",
        "Meng Wang",
        "Thaddaeus Lo",
        "Xiaofeng Lei",
        "Siegfried K. Wagner",
        "Mark A. Chia",
        "Dawei Yang",
        "Hongyang Jiang",
        "AnRan Ran",
        "Rui Santos",
        "Gabor Mark Somfai",
        "Juan Helen Zhou",
        "Haoyu Chen",
        "Qingyu Chen",
        "Carol Yim-Lui Cheung",
        "Pearse A. Keane",
        "Yih Chung Tham"
      ],
      "abstract": "The advent of foundation models (FMs) is transforming medical domain. In\nophthalmology, RETFound, a retina-specific FM pre-trained sequentially on 1.4\nmillion natural images and 1.6 million retinal images, has demonstrated high\nadaptability across clinical applications. Conversely, DINOv2, a\ngeneral-purpose vision FM pre-trained on 142 million natural images, has shown\npromise in non-medical domains. However, its applicability to clinical tasks\nremains underexplored. To address this, we conducted head-to-head evaluations\nby fine-tuning RETFound and three DINOv2 models (large, base, small) for ocular\ndisease detection and systemic disease prediction tasks, across eight\nstandardized open-source ocular datasets, as well as the Moorfields AlzEye and\nthe UK Biobank datasets. DINOv2-large model outperformed RETFound in detecting\ndiabetic retinopathy (AUROC=0.850-0.952 vs 0.823-0.944, across three datasets,\nall P<=0.007) and multi-class eye diseases (AUROC=0.892 vs. 0.846, P<0.001). In\nglaucoma, DINOv2-base model outperformed RETFound (AUROC=0.958 vs 0.940,\nP<0.001). Conversely, RETFound achieved superior performance over all DINOv2\nmodels in predicting heart failure, myocardial infarction, and ischaemic stroke\n(AUROC=0.732-0.796 vs 0.663-0.771, all P<0.001). These trends persisted even\nwith 10% of the fine-tuning data. These findings showcase the distinct\nscenarios where general-purpose and domain-specific FMs excel, highlighting the\nimportance of aligning FM selection with task-specific requirements to optimise\nclinical performance.",
      "tldr_zh": "这篇论文比较了通用视觉基础模型（Foundation Model）DINOv2 和 视网膜特定模型 RETFound，在眼部疾病检测和系统性疾病预测任务上的性能，通过微调模型并在多个数据集（如 Moorfields AlzEye 和 UK Biobank）上进行评估。结果显示，DINOv2-large 在检测糖尿病视网膜病变（AUROC=0.850-0.952 vs 0.823-0.944）和多类眼部疾病（AUROC=0.892 vs 0.846）上优于 RETFound，而 RETFound 在预测心脏衰竭、心肌梗塞和缺血性中风（AUROC=0.732-0.796 vs 0.663-0.771）方面表现更好。这些趋势即使在微调数据减少到 10% 时依然存在，强调了根据任务需求选择通用或领域特定 FM 的重要性，以优化临床表现。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06289v1",
      "published_date": "2025-02-10 09:31:39 UTC",
      "updated_date": "2025-02-10 09:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:40:39.574718"
    },
    {
      "arxiv_id": "2502.06285v1",
      "title": "End-to-End Multi-Microphone Speaker Extraction Using Relative Transfer Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Aviad Eisenberg",
        "Sharon Gannot",
        "Shlomo E. Chazan"
      ],
      "abstract": "This paper introduces a multi-microphone method for extracting a desired\nspeaker from a mixture involving multiple speakers and directional noise in a\nreverberant environment. In this work, we propose leveraging the instantaneous\nrelative transfer function (RTF), estimated from a reference utterance recorded\nin the same position as the desired source. The effectiveness of the RTF-based\nspatial cue is compared with direction of arrival (DOA)-based spatial cue and\nthe conventional spectral embedding. Experimental results in challenging\nacoustic scenarios demonstrate that using spatial cues yields better\nperformance than the spectral-based cue and that the instantaneous RTF\noutperforms the DOA-based spatial cue.",
      "tldr_zh": "这篇论文提出了一种端到端多麦克风说话者提取方法，用于从混响环境中包含多个说话者和方向性噪声的混合信号中提取所需说话者。方法利用即时 Relative Transfer Functions (RTF)，通过从与目标源相同位置记录的参考语音进行估计，作为空间线索。实验结果显示，与 Direction of Arrival (DOA) 基于的空间线索和传统的频谱嵌入相比，使用 RTF 的方法在挑战性声学场景中表现出色，性能更优。总的来说，该方法提升了说话者提取的准确性，为复杂音频处理提供了新途径。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06285v1",
      "published_date": "2025-02-10 09:27:44 UTC",
      "updated_date": "2025-02-10 09:27:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:40:49.389329"
    },
    {
      "arxiv_id": "2502.06913v2",
      "title": "A Simple yet Effective DDG Predictor is An Unsupervised Antibody Optimizer and Explainer",
      "title_zh": "翻译失败",
      "authors": [
        "Lirong Wu",
        "Yunfan Liu",
        "Haitao Lin",
        "Yufei Huang",
        "Guojiang Zhao",
        "Zhifeng Gao",
        "Stan Z. Li"
      ],
      "abstract": "The proteins that exist today have been optimized over billions of years of\nnatural evolution, during which nature creates random mutations and selects\nthem. The discovery of functionally promising mutations is challenged by the\nlimited evolutionary accessible regions, i.e., only a small region on the\nfitness landscape is beneficial. There have been numerous priors used to\nconstrain protein evolution to regions of landscapes with high-fitness\nvariants, among which the change in binding free energy (DDG) of protein\ncomplexes upon mutations is one of the most commonly used priors. However, the\nhuge mutation space poses two challenges: (1) how to improve the efficiency of\nDDG prediction for fast mutation screening; and (2) how to explain mutation\npreferences and efficiently explore accessible evolutionary regions. To address\nthese challenges, we propose a lightweight DDG predictor (Light-DDG), which\nadopts a structure-aware Transformer as the backbone and enhances it by\nknowledge distilled from existing powerful but computationally heavy DDG\npredictors. Additionally, we augmented, annotated, and released a large-scale\ndataset containing millions of mutation data for pre-training Light-DDG. We\nfind that such a simple yet effective Light-DDG can serve as a good\nunsupervised antibody optimizer and explainer. For the target antibody, we\npropose a novel Mutation Explainer to learn mutation preferences, which\naccounts for the marginal benefit of each mutation per residue. To further\nexplore accessible evolutionary regions, we conduct preference-guided antibody\noptimization and evaluate antibody candidates quickly using Light-DDG to\nidentify desirable mutations.",
      "tldr_zh": "本研究针对蛋白质进化中的突变筛选挑战，提出了一种简单有效的轻量级 DDG 预测器（Light-DDG），其基于结构感知 Transformer 骨干，并通过知识蒸馏从现有复杂模型中增强性能，同时发布了一个包含数百万突变数据的预训练数据集。Light-DDG 作为无监督抗体优化器和解释器，能够通过新型 Mutation Explainer 学习每个残基的突变偏好，并评估边际收益。实验结果显示，该方法显著提高了突变筛选效率，并有助于探索高适配性进化区域，从而优化抗体候选。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06913v2",
      "published_date": "2025-02-10 09:26:57 UTC",
      "updated_date": "2025-02-13 11:42:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:41:02.260022"
    },
    {
      "arxiv_id": "2502.06282v1",
      "title": "Jakiro: Boosting Speculative Decoding with Decoupled Multi-Head via MoE",
      "title_zh": "翻译失败",
      "authors": [
        "Haiduo Huang",
        "Fuwei Yang",
        "Zhenhua Liu",
        "Yixing Xu",
        "Jinze Li",
        "Yang Liu",
        "Xuanwu Yin",
        "Dong Li",
        "Pengju Ren",
        "Emad Barsoum"
      ],
      "abstract": "Speculative decoding (SD) accelerates large language model inference by using\na smaller draft model to predict multiple tokens, which are then verified in\nparallel by the larger target model. However, the limited capacity of the draft\nmodel often necessitates tree-based sampling to improve prediction accuracy,\nwhere multiple candidates are generated at each step. We identify a key\nlimitation in this approach: the candidates at the same step are derived from\nthe same representation, limiting diversity and reducing overall effectiveness.\nTo address this, we propose Jakiro, leveraging Mixture of Experts (MoE), where\nindependent experts generate diverse predictions, effectively decoupling\ncorrelations among candidates. Furthermore, we introduce a hybrid inference\nstrategy, combining autoregressive decoding for initial tokens with parallel\ndecoding for subsequent stages, and enhance the latter with contrastive\nmechanism in features to improve accuracy. Our method significantly boosts\nprediction accuracy and achieves higher inference speedups. Extensive\nexperiments across diverse models validate the effectiveness and robustness of\nour approach, establishing a new SOTA in speculative decoding. Our codes are\navailable at https://github.com/haiduo/Jakiro.",
      "tldr_zh": "该论文针对 Speculative Decoding (SD) 中候选预测多样性不足的问题，提出 Jakiro 方法，通过 Mixture of Experts (MoE) 机制让独立 experts 生成解耦的多头预测，从而提升预测准确性和整体效率。Jakiro 还引入混合推理策略，将 autoregressive decoding 用于初始 tokens，并结合 parallel decoding 和 contrastive mechanism 来优化后续阶段的处理。实验在多种模型上验证了该方法的有效性，实现了更高的推理加速并建立了新的 SOTA 状态。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06282v1",
      "published_date": "2025-02-10 09:24:06 UTC",
      "updated_date": "2025-02-10 09:24:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:41:14.104625"
    },
    {
      "arxiv_id": "2502.10441v1",
      "title": "AI Alignment at Your Discretion",
      "title_zh": "翻译失败",
      "authors": [
        "Maarten Buyl",
        "Hadi Khalaf",
        "Claudio Mayrink Verdun",
        "Lucas Monteiro Paes",
        "Caio C. Vieira Machado",
        "Flavio du Pin Calmon"
      ],
      "abstract": "In AI alignment, extensive latitude must be granted to annotators, either\nhuman or algorithmic, to judge which model outputs are `better' or `safer.' We\nrefer to this latitude as alignment discretion. Such discretion remains largely\nunexamined, posing two risks: (i) annotators may use their power of discretion\narbitrarily, and (ii) models may fail to mimic this discretion. To study this\nphenomenon, we draw on legal concepts of discretion that structure how\ndecision-making authority is conferred and exercised, particularly in cases\nwhere principles conflict or their application is unclear or irrelevant.\nExtended to AI alignment, discretion is required when alignment principles and\nrules are (inevitably) conflicting or indecisive. We present a set of metrics\nto systematically analyze when and how discretion in AI alignment is exercised,\nsuch that both risks (i) and (ii) can be observed. Moreover, we distinguish\nbetween human and algorithmic discretion and analyze the discrepancy between\nthem. By measuring both human and algorithmic discretion over safety alignment\ndatasets, we reveal layers of discretion in the alignment process that were\npreviously unaccounted for. Furthermore, we demonstrate how algorithms trained\non these datasets develop their own forms of discretion in interpreting and\napplying these principles, which challenges the purpose of having any\nprinciples at all. Our paper presents the first step towards formalizing this\ncore gap in current alignment processes, and we call on the community to\nfurther scrutinize and control alignment discretion.",
      "tldr_zh": "该论文探讨了 AI 对齐（AI alignment）中的“alignment discretion”，即标注者（人类或算法）在判断模型输出是否“更好”或“更安全”时所拥有的自由度，并指出了这种自由度可能导致的两个风险：标注者任意行使权力，以及模型无法模仿该自由度。作者借鉴法律概念，提出一组指标来系统分析 discretion 的何时和如何应用，区分人类和算法 discretion，并通过在安全对齐数据集上的测量揭示了之前未被计量的 discretion 层级。研究发现，算法在训练后会发展出自己的 discretion 形式，这可能挑战对齐原则的效用，并呼吁社区进一步正式化和控制 alignment discretion。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10441v1",
      "published_date": "2025-02-10 09:19:52 UTC",
      "updated_date": "2025-02-10 09:19:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:41:25.505149"
    },
    {
      "arxiv_id": "2502.06274v1",
      "title": "HODDI: A Dataset of High-Order Drug-Drug Interactions for Computational Pharmacovigilance",
      "title_zh": "HODDI：用于计算药物警戒的高阶药物-药物相互作用数据集",
      "authors": [
        "Zhaoying Wang",
        "Yingdan Shi",
        "Xiang Liu",
        "Can Chen",
        "Jun Wen",
        "Ren Wang"
      ],
      "abstract": "Drug-side effect research is vital for understanding adverse reactions\narising in complex multi-drug therapies. However, the scarcity of higher-order\ndatasets that capture the combinatorial effects of multiple drugs severely\nlimits progress in this field. Existing resources such as TWOSIDES primarily\nfocus on pairwise interactions. To fill this critical gap, we introduce HODDI,\nthe first Higher-Order Drug-Drug Interaction Dataset, constructed from U.S.\nFood and Drug Administration (FDA) Adverse Event Reporting System (FAERS)\nrecords spanning the past decade, to advance computational pharmacovigilance.\nHODDI contains 109,744 records involving 2,506 unique drugs and 4,569 unique\nside effects, specifically curated to capture multi-drug interactions and their\ncollective impact on adverse effects. Comprehensive statistical analyses\ndemonstrate HODDI's extensive coverage and robust analytical metrics, making it\na valuable resource for studying higher-order drug relationships. Evaluating\nHODDI with multiple models, we found that simple Multi-Layer Perceptron (MLP)\ncan outperform graph models, while hypergraph models demonstrate superior\nperformance in capturing complex multi-drug interactions, further validating\nHODDI's effectiveness. Our findings highlight the inherent value of\nhigher-order information in drug-side effect prediction and position HODDI as a\nbenchmark dataset for advancing research in pharmacovigilance, drug safety, and\npersonalized medicine. The dataset and codes are available at\nhttps://github.com/TIML-Group/HODDI.",
      "tldr_zh": "该研究引入了 HODDI，这是一个专注于高阶药物-药物互动（Higher-Order Drug-Drug Interactions）的首个数据集，旨在填补现有资源如 TWOSIDES 只关注成对互动的空白。HODDI 基于美国 FDA 的 Adverse Event Reporting System (FAERS) 记录构建，包含 109,744 条记录、2,506 个独特药物和 4,569 个独特副作用，用于分析多药物组合对副作用的集体影响。实验评估显示，简单 Multi-Layer Perceptron (MLP) 模型优于图模型，而 hypergraph 模型在捕捉复杂多药物互动方面表现出色，这突显了 HODDI 在 computational pharmacovigilance、药物安全和个性化医学领域的基准价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.MN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06274v1",
      "published_date": "2025-02-10 09:18:51 UTC",
      "updated_date": "2025-02-10 09:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:41:38.163891"
    },
    {
      "arxiv_id": "2502.10440v1",
      "title": "Towards Copyright Protection for Knowledge Bases of Retrieval-augmented Language Models via Ownership Verification with Reasoning",
      "title_zh": "迈向检索增强语言模型知识库的版权",
      "authors": [
        "Junfeng Guo",
        "Yiming Li",
        "Ruibo Chen",
        "Yihan Wu",
        "Chenxi Liu",
        "Yanshuo Chen",
        "Heng Huang"
      ],
      "abstract": "Large language models (LLMs) are increasingly integrated into real-world\napplications through retrieval-augmented generation (RAG) mechanisms to\nsupplement their responses with up-to-date and domain-specific knowledge.\nHowever, the valuable and often proprietary nature of the knowledge bases used\nin RAG introduces the risk of unauthorized usage by adversaries. Existing\nmethods that can be generalized as watermarking techniques to protect these\nknowledge bases typically involve poisoning attacks. However, these methods\nrequire to alter the results of verification samples (\\eg, generating incorrect\noutputs), inevitably making them susceptible to anomaly detection and even\nintroduce new security risks. To address these challenges, we propose \\name{}\nfor `harmless' copyright protection of knowledge bases. Instead of manipulating\nLLM's final output, \\name{} implants distinct verification behaviors in the\nspace of chain-of-thought (CoT) reasoning, maintaining the correctness of the\nfinal answer. Our method has three main stages: (1) \\textbf{Generating CoTs}:\nFor each verification question, we generate two CoTs, including a target CoT\nfor building watermark behaviors; (2) \\textbf{Optimizing Watermark Phrases and\nTarget CoTs}: We optimize them to minimize retrieval errors under the black-box\nsetting of suspicious LLM, ensuring that the watermarked verification queries\nactivate the target CoTs without being activated in non-watermarked ones; (3)\n\\textbf{Ownership Verification}: We exploit a pairwise Wilcoxon test to\nstatistically verify whether a suspicious LLM is augmented with the protected\nknowledge base by comparing its responses to watermarked and benign\nverification queries. Our experiments on diverse benchmarks demonstrate that\n\\name{} effectively protects knowledge bases against unauthorized usage while\npreserving the integrity and performance of the RAG.",
      "tldr_zh": "这篇论文针对检索增强生成(RAG)模型的知识库版权保护问题，提出了一种名为\\name{}的方法，通过在Chain-of-Thought (CoT)推理过程中植入无害水印行为来实现所有权验证，而不改变最终输出正确性。方法包括三个阶段：生成CoT以构建水印行为、优化水印短语和目标CoT以最小化检索错误，以及使用pairwise Wilcoxon test统计测试比较水印和普通查询的响应来验证可疑LLM是否使用了受保护知识库。实验在多样基准上证明，\\name{}能有效防止知识库的未授权使用，同时保持RAG的性能和完整性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "The first two authors contributed equally to this work. 19 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.10440v1",
      "published_date": "2025-02-10 09:15:56 UTC",
      "updated_date": "2025-02-10 09:15:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:41:50.860820"
    },
    {
      "arxiv_id": "2502.07820v1",
      "title": "Low-Rank Compression for IMC Arrays",
      "title_zh": "低秩压缩用于 IMC 数组",
      "authors": [
        "Kang Eun Jeon",
        "Johnny Rhe",
        "Jong Hwan Ko"
      ],
      "abstract": "In this study, we address the challenge of low-rank model compression in the\ncontext of in-memory computing (IMC) architectures. Traditional pruning\napproaches, while effective in model size reduction, necessitate additional\nperipheral circuitry to manage complex dataflows and mitigate dislocation\nissues, leading to increased area and energy overheads. To circumvent these\ndrawbacks, we propose leveraging low-rank compression techniques, which, unlike\npruning, streamline the dataflow and seamlessly integrate with IMC\narchitectures. However, low-rank compression presents its own set of\nchallenges, namely i) suboptimal IMC array utilization and ii) compromised\naccuracy. To address these issues, we introduce a novel approach i) employing\nshift and duplicate kernel (SDK) mapping technique, which exploits idle IMC\ncolumns for parallel processing, and ii) group low-rank convolution, which\nmitigates the information imbalance in the decomposed matrices. Our\nexperimental results demonstrate that our proposed method achieves up to 2.5x\nspeedup or +20.9% accuracy boost over existing pruning techniques.",
      "tldr_zh": "本研究针对 in-memory computing (IMC) 架构中的低秩模型压缩挑战，提出使用 low-rank compression 技术来简化数据流并避免传统修剪方法带来的额外外围电路开销。针对 low-rank compression 的问题，包括 IMC 阵列利用率不佳和准确性下降，该方法引入 shift and duplicate kernel (SDK) mapping 技术利用空闲列进行并行处理，以及 group low-rank convolution 来缓解分解矩阵中的信息不平衡。实验结果显示，该方法相较现有修剪技术实现高达2.5倍的速度提升或20.9%的准确性提升。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted to appear at DATE'25 (Lyon, France)",
      "pdf_url": "http://arxiv.org/pdf/2502.07820v1",
      "published_date": "2025-02-10 08:57:39 UTC",
      "updated_date": "2025-02-10 08:57:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:42:02.346100"
    },
    {
      "arxiv_id": "2502.06257v1",
      "title": "K-ON: Stacking Knowledge On the Head Layer of Large Language Model",
      "title_zh": "K-ON：在大语言模型",
      "authors": [
        "Lingbing Guo",
        "Yichi Zhang",
        "Zhongpu Bo",
        "Zhuo Chen",
        "Mengshu Sun",
        "Zhiqiang Zhang",
        "Wen Zhang",
        "Huajun Chen"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have significantly\nimproved various natural language processing (NLP) tasks. Typically, LLMs are\ntrained to predict the next token, aligning well with many NLP tasks. However,\nin knowledge graph (KG) scenarios, entities are the fundamental units and\nidentifying an entity requires at least several tokens. This leads to a\ngranularity mismatch between KGs and natural languages. To address this issue,\nwe propose K-ON, which integrates KG knowledge into the LLM by employing\nmultiple head layers for next k-step prediction. K-ON can not only generate\nentity-level results in one step, but also enables contrastive loss against\nentities, which is the most powerful tool in KG representation learning.\nExperimental results show that K-ON outperforms state-of-the-art methods that\nincorporate text and even the other modalities.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）和知识图谱（KG）之间的粒度不匹配问题提出了一种新方法K-ON，通过在LLMs的头层上添加多个层来实现下一个k步预测，从而整合KG知识。K-ON允许一次性生成实体级别的结果，并利用对比损失（contrastive loss）增强KG表示学习。实验结果显示，K-ON在相关任务上超过了现有整合文本或其他模态的方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2025 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2502.06257v1",
      "published_date": "2025-02-10 08:45:56 UTC",
      "updated_date": "2025-02-10 08:45:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:42:13.105864"
    },
    {
      "arxiv_id": "2502.06255v1",
      "title": "Towards Efficient and Intelligent Laser Weeding: Method and Dataset for Weed Stem Detection",
      "title_zh": "迈向高效且智能的激光除草",
      "authors": [
        "Dingning Liu",
        "Jinzhe Li",
        "Haoyang Su",
        "Bei Cui",
        "Zhihui Wang",
        "Qingbo Yuan",
        "Wanli Ouyang",
        "Nanqing Dong"
      ],
      "abstract": "Weed control is a critical challenge in modern agriculture, as weeds compete\nwith crops for essential nutrient resources, significantly reducing crop yield\nand quality. Traditional weed control methods, including chemical and\nmechanical approaches, have real-life limitations such as associated\nenvironmental impact and efficiency. An emerging yet effective approach is\nlaser weeding, which uses a laser beam as the stem cutter. Although there have\nbeen studies that use deep learning in weed recognition, its application in\nintelligent laser weeding still requires a comprehensive understanding. Thus,\nthis study represents the first empirical investigation of weed recognition for\nlaser weeding. To increase the efficiency of laser beam cut and avoid damaging\nthe crops of interest, the laser beam shall be directly aimed at the weed root.\nYet, weed stem detection remains an under-explored problem. We integrate the\ndetection of crop and weed with the localization of weed stem into one\nend-to-end system. To train and validate the proposed system in a real-life\nscenario, we curate and construct a high-quality weed stem detection dataset\nwith human annotations. The dataset consists of 7,161 high-resolution pictures\ncollected in the field with annotations of 11,151 instances of weed.\nExperimental results show that the proposed system improves weeding accuracy by\n6.7% and reduces energy cost by 32.3% compared to existing weed recognition\nsystems.",
      "tldr_zh": "本研究针对现代农业中杂草控制的挑战，提出了一种高效智能激光除草方法，该方法通过端到端系统整合作物和杂草检测与杂草茎定位，以提高激光束切割的准确性和效率。研究者构建了一个高质量数据集，包含7,161张田间高分辨率图片和11,151个杂草实例的人工标注，用于训练和验证该系统。实验结果显示，与现有杂草识别系统相比，该方法将除草准确率提高了6.7%，并降低了32.3%的能源成本，为可持续农业提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI-AISI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06255v1",
      "published_date": "2025-02-10 08:42:46 UTC",
      "updated_date": "2025-02-10 08:42:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:42:26.143653"
    },
    {
      "arxiv_id": "2502.06249v2",
      "title": "Conditioning through indifference in quantum mechanics",
      "title_zh": "翻译失败",
      "authors": [
        "Keano De Vos",
        "Gert de Cooman"
      ],
      "abstract": "We can learn (more) about the state a quantum system is in through\nmeasurements. We look at how to describe the uncertainty about a quantum\nsystem's state conditional on executing such measurements. We show that by\nexploiting the interplay between desirability, coherence and indifference, a\ngeneral rule for conditioning can be derived. We then apply this rule to\nconditioning on measurement outcomes, and show how it generalises to\nconditioning on a set of measurement outcomes.",
      "tldr_zh": "本论文探讨了在量子力学中，通过测量来更新对系统状态不确定性的条件化（conditioning）方法。作者通过利用期望性（desirability）、一致性（coherence）和冷漠性（indifference）的相互作用，推导出一个通用的条件化规则，以描述测量后的状态不确定性。该规则不仅适用于单个测量结果，还可推广到一组测量结果的条件化，从而为量子系统状态的精确学习提供了新框架。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "math.PR"
      ],
      "primary_category": "quant-ph",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.06249v2",
      "published_date": "2025-02-10 08:27:02 UTC",
      "updated_date": "2025-04-20 12:38:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:42:37.616901"
    },
    {
      "arxiv_id": "2502.06235v2",
      "title": "Conditioning and AGM-like belief change in the Desirability-Indifference framework",
      "title_zh": "翻译失败",
      "authors": [
        "Kathelijne Coussement",
        "Gert de Cooman",
        "Keano De Vos"
      ],
      "abstract": "We show how the AGM framework for belief change (expansion, revision,\ncontraction) can be extended to deal with conditioning in the so-called\nDesirability-Indifference framework, based on abstract notions of accepting and\nrejecting options, as well as on abstract notions of events. This level of\nabstraction allows us to deal simultaneously with classical and quantum\nprobability theory.",
      "tldr_zh": "本研究扩展了AGM framework，用于处理信念变化（包括expansion、revision和contraction），并将其应用于Desirability-Indifference framework中，以实现conditioning。框架基于抽象的选项接受/拒绝概念以及事件概念，这种抽象设计允许同时处理经典和量子probability theory。该方法为更广泛的概率理论应用提供了灵活的基础。",
      "categories": [
        "cs.AI",
        "math.PR",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.06235v2",
      "published_date": "2025-02-10 08:11:00 UTC",
      "updated_date": "2025-04-20 12:51:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:42:49.612925"
    },
    {
      "arxiv_id": "2502.06233v1",
      "title": "Confidence Improves Self-Consistency in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Taubenfeld",
        "Tom Sheffer",
        "Eran Ofek",
        "Amir Feder",
        "Ariel Goldstein",
        "Zorik Gekhman",
        "Gal Yona"
      ],
      "abstract": "Self-consistency decoding enhances LLMs' performance on reasoning tasks by\nsampling diverse reasoning paths and selecting the most frequent answer.\nHowever, it is computationally expensive, as sampling many of these (lengthy)\npaths is required to increase the chances that the correct answer emerges as\nthe most frequent one. To address this, we introduce Confidence-Informed\nSelf-Consistency (CISC). CISC performs a weighted majority vote based on\nconfidence scores obtained directly from the model. By prioritizing\nhigh-confidence paths, it can identify the correct answer with a significantly\nsmaller sample size. When tested on nine models and four datasets, CISC\noutperforms self-consistency in nearly all configurations, reducing the\nrequired number of reasoning paths by over 40% on average. In addition, we\nintroduce the notion of within-question confidence evaluation, after showing\nthat standard evaluation methods are poor predictors of success in\ndistinguishing correct and incorrect answers to the same question. In fact, the\nmost calibrated confidence method proved to be the least effective for CISC.\nLastly, beyond these practical implications, our results and analyses show that\nLLMs can effectively judge the correctness of their own outputs, contributing\nto the ongoing debate on this topic.",
      "tldr_zh": "这篇论文提出 Confidence-Informed Self-Consistency (CISC) 方法，通过利用模型生成的置信度分数进行加权多数投票，优化了 LLMs 在推理任务中的自一致性解码，从而显著减少所需的推理路径采样数量。相比传统自一致性解码，CISC 在九个模型和四个数据集上几乎所有配置中表现出色，平均减少超过40%的计算开销。论文还引入问题内置信度评估的概念，揭示标准评估方法在区分同一问题正确与错误答案时效果不佳，并证明 LLMs 可以有效判断自身输出的正确性，为相关研究提供新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06233v1",
      "published_date": "2025-02-10 08:10:29 UTC",
      "updated_date": "2025-02-10 08:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:43:02.195057"
    },
    {
      "arxiv_id": "2502.06217v1",
      "title": "Examining False Positives under Inference Scaling for Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Wang",
        "Nan Yang",
        "Liang Wang",
        "Furu Wei"
      ],
      "abstract": "Recent advancements in language models have led to significant improvements\nin mathematical reasoning across various benchmarks. However, most of these\nbenchmarks rely on automatic evaluation methods that only compare final answers\nusing heuristics, without verifying the underlying reasoning steps. This\nlimitation results in false positive solutions, where models may produce\ncorrect final answers but with flawed deduction paths. In this paper, we\nsystematically examine the prevalence of false positive solutions in\nmathematical problem solving for language models. We analyze the\ncharacteristics and extent of this issue across different open-source models,\ndatasets of varying difficulty levels, and decoding strategies. Specifically,\nwe explore how false positives influence the inference time scaling behavior of\nlanguage models. Our experimental results reveal that: (1) false positive\nsolutions persist across different models, datasets, and decoding methods, (2)\nsampling-based inference time scaling methods do not alleviate the problem, and\n(3) the pass@N evaluation metric is more susceptible to false positives,\nsuggesting a significantly lower scaling ceiling than what automatic\nevaluations indicate. Additionally, we analyze specific instances of false\npositives and discuss potential limitations in self-improvement techniques and\nsynthetic data generation under such conditions.",
      "tldr_zh": "本研究调查了语言模型在数学推理中的 false positives 问题，即模型输出正确最终答案但推理过程有缺陷的现象。作者分析了这些问题在不同开源模型、数据集难度水平和解码策略下的普遍性和特征，并探讨了 false positives 对 inference scaling 行为的影响。实验结果显示：false positives 在各种设置中持续存在，基于采样的 inference scaling 方法无法缓解问题，且 pass@N 评估指标更容易受其影响，导致实际缩放上限远低于自动评估显示。此外，论文讨论了这种现象对自提升技术和合成数据生成的潜在限制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06217v1",
      "published_date": "2025-02-10 07:49:35 UTC",
      "updated_date": "2025-02-10 07:49:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:43:13.632040"
    },
    {
      "arxiv_id": "2502.06215v1",
      "title": "LessLeak-Bench: A First Investigation of Data Leakage in LLMs Across 83 Software Engineering Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Zhou",
        "Martin Weyssow",
        "Ratnadira Widyasari",
        "Ting Zhang",
        "Junda He",
        "Yunbo Lyu",
        "Jianming Chang",
        "Beiqi Zhang",
        "Dan Huang",
        "David Lo"
      ],
      "abstract": "Large Language Models (LLMs) are widely utilized in software engineering (SE)\ntasks, such as code generation and automated program repair. However, their\nreliance on extensive and often undisclosed pre-training datasets raises\nsignificant concerns about data leakage, where the evaluation benchmark data is\nunintentionally ``seen'' by LLMs during the model's construction phase. The\ndata leakage issue could largely undermine the validity of LLM-based research\nand evaluations. Despite the increasing use of LLMs in the SE community, there\nis no comprehensive study that assesses the extent of data leakage in SE\nbenchmarks for LLMs yet. To address this gap, this paper presents the first\nlarge-scale analysis of data leakage in 83 SE benchmarks concerning LLMs. Our\nresults show that in general, data leakage in SE benchmarks is minimal, with\naverage leakage ratios of only 4.8\\%, 2.8\\%, and 0.7\\% for Python, Java, and\nC/C++ benchmarks, respectively. However, some benchmarks exhibit relatively\nhigher leakage ratios, which raises concerns about their bias in evaluation.\nFor instance, QuixBugs and BigCloneBench have leakage ratios of 100.0\\% and\n55.7\\%, respectively. Furthermore, we observe that data leakage has a\nsubstantial impact on LLM evaluation. We also identify key causes of high data\nleakage, such as the direct inclusion of benchmark data in pre-training\ndatasets and the use of coding platforms like LeetCode for benchmark\nconstruction. To address the data leakage, we introduce\n\\textbf{LessLeak-Bench}, a new benchmark that removes leaked samples from the\n83 SE benchmarks, enabling more reliable LLM evaluations in future research.\nOur study enhances the understanding of data leakage in SE benchmarks and\nprovides valuable insights for future research involving LLMs in SE.",
      "tldr_zh": "该论文首次对83个软件工程(SE)基准中的数据泄露问题进行了大规模调查，发现整体泄露率较低（Python 4.8%、Java 2.8%、C/C++ 0.7%），但某些基准如QuixBugs和BigCloneBench的泄露率高达100%和55.7%，这可能导致评估偏差。研究揭示了数据泄露对LLMs性能评估的重大影响，并将原因归因于基准数据直接包含在预训练数据集或使用如LeetCode的平台。作者引入了LessLeak-Bench，这是一个去除泄露样本的新基准，以支持更可靠的LLMs在SE任务中的评估，并为未来研究提供宝贵见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.06215v1",
      "published_date": "2025-02-10 07:33:49 UTC",
      "updated_date": "2025-02-10 07:33:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:43:26.841127"
    },
    {
      "arxiv_id": "2502.06207v3",
      "title": "Is LLM an Overconfident Judge? Unveiling the Capabilities of LLMs in Detecting Offensive Language with Annotation Disagreement",
      "title_zh": "翻译失败",
      "authors": [
        "Junyu Lu",
        "Kai Ma",
        "Kaichun Wang",
        "Kelaiti Xiao",
        "Roy Ka-Wei Lee",
        "Bo Xu",
        "Liang Yang",
        "Hongfei Lin"
      ],
      "abstract": "Large Language Models (LLMs) have become essential for offensive language\ndetection, yet their ability to handle annotation disagreement remains\nunderexplored. Disagreement samples, which arise from subjective\ninterpretations, pose a unique challenge due to their ambiguous nature.\nUnderstanding how LLMs process these cases, particularly their confidence\nlevels, can offer insight into their alignment with human annotators. This\nstudy systematically evaluates the performance of multiple LLMs in detecting\noffensive language at varying levels of annotation agreement. We analyze binary\nclassification accuracy, examine the relationship between model confidence and\nhuman disagreement, and explore how disagreement samples influence model\ndecision-making during few-shot learning and instruction fine-tuning. Our\nfindings reveal that LLMs struggle with low-agreement samples, often exhibiting\noverconfidence in these ambiguous cases. However, utilizing disagreement\nsamples in training improves both detection accuracy and model alignment with\nhuman judgment. These insights provide a foundation for enhancing LLM-based\noffensive language detection in real-world moderation tasks.",
      "tldr_zh": "本研究评估了LLMs在检测攻击性语言时的能力，特别关注annotation disagreement（标注分歧）的影响，发现LLMs在低一致性样本上往往表现出过度自信，导致准确率下降。研究方法包括分析二元分类准确率、模型置信度与人类分歧的关系，以及探索disagreement samples在few-shot learning和instruction fine-tuning中的作用。结果显示，使用这些分歧样本进行训练能显著提升检测性能和模型与人类判断的alignment，为改进LLMs在真实世界moderation任务中的应用提供了重要基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, accepted at the ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06207v3",
      "published_date": "2025-02-10 07:14:26 UTC",
      "updated_date": "2025-05-18 09:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:43:38.957784"
    },
    {
      "arxiv_id": "2502.06205v1",
      "title": "C-3PO: Compact Plug-and-Play Proxy Optimization to Achieve Human-like Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Guoxin Chen",
        "Minpeng Liao",
        "Peiying Yu",
        "Dingmin Wang",
        "Zile Qiao",
        "Chao Yang",
        "Xin Zhao",
        "Kai Fan"
      ],
      "abstract": "Retrieval-augmented generation (RAG) systems face a fundamental challenge in\naligning independently developed retrievers and large language models (LLMs).\nExisting approaches typically involve modifying either component or introducing\nsimple intermediate modules, resulting in practical limitations and sub-optimal\nperformance. Inspired by human search behavior -- typically involving a\nback-and-forth process of proposing search queries and reviewing documents, we\npropose C-3PO, a proxy-centric framework that facilitates communication between\nretrievers and LLMs through a lightweight multi-agent system. Our framework\nimplements three specialized agents that collaboratively optimize the entire\nRAG pipeline without altering the retriever and LLMs. These agents work\ntogether to assess the need for retrieval, generate effective queries, and\nselect information suitable for the LLMs. To enable effective multi-agent\ncoordination, we develop a tree-structured rollout approach for reward credit\nassignment in reinforcement learning. Extensive experiments in both in-domain\nand out-of-distribution scenarios demonstrate that C-3PO significantly enhances\nRAG performance while maintaining plug-and-play flexibility and superior\ngeneralization capabilities.",
      "tldr_zh": "本研究提出C-3PO框架，一种紧凑的Plug-and-Play代理优化方法，旨在解决Retrieval-Augmented Generation (RAG)系统中检索器和Large Language Models (LLMs)对齐的挑战，通过模仿人类搜索行为（反复提出查询和审查文档）来提升系统性能。框架采用轻量级Multi-Agent System，包括三个专门代理，负责评估检索需求、生成有效查询和选择适合LLMs的信息，同时使用树结构展开（tree-structured rollout）方法进行强化学习中的奖励信用分配，而无需修改原有组件。实验结果显示，C-3PO在域内和域外场景显著提升RAG性能，并保持了Plug-and-Play灵活性和优秀的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Ongong work",
      "pdf_url": "http://arxiv.org/pdf/2502.06205v1",
      "published_date": "2025-02-10 07:04:32 UTC",
      "updated_date": "2025-02-10 07:04:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:43:49.834254"
    },
    {
      "arxiv_id": "2502.06193v3",
      "title": "Can LLMs Replace Human Evaluators? An Empirical Study of LLM-as-a-Judge in Software Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiqi Wang",
        "Jiyu Guo",
        "Cuiyun Gao",
        "Guodong Fan",
        "Chun Yong Chong",
        "Xin Xia"
      ],
      "abstract": "Recently, large language models (LLMs) have been deployed to tackle various\nsoftware engineering (SE) tasks like code generation, significantly advancing\nthe automation of SE tasks. However, assessing the quality of these\nLLM-generated code and text remains challenging. The commonly used Pass@k\nmetric necessitates extensive unit tests and configured environments, demands a\nhigh labor cost, and is not suitable for evaluating LLM-generated text.\nConventional metrics like BLEU, which measure only lexical rather than semantic\nsimilarity, have also come under scrutiny. In response, a new trend has emerged\nto employ LLMs for automated evaluation, known as LLM-as-a-judge. These\nLLM-as-a-judge methods are claimed to better mimic human assessment than\nconventional metrics without relying on high-quality reference answers.\nNevertheless, their exact human alignment in SE tasks remains unexplored.\n  In this paper, we empirically explore LLM-as-a-judge methods for evaluating\nSE tasks, focusing on their alignment with human judgments. We select seven\nLLM-as-a-judge methods that utilize general-purpose LLMs, alongside two LLMs\nspecifically fine-tuned for evaluation. After generating and manually scoring\nLLM responses on three recent SE datasets of code translation, code generation,\nand code summarization, we then prompt these methods to evaluate each response.\nFinally, we compare the scores generated by these methods with human\nevaluation. The results indicate that output-based methods reach the highest\nPearson correlation of 81.32 and 68.51 with human scores in code translation\nand generation, achieving near-human evaluation, noticeably outperforming\nChrF++, one of the best conventional metrics, at 34.23 and 64.92. Such\noutput-based methods prompt LLMs to output judgments directly, and exhibit more\nbalanced score distributions that resemble human score patterns. Finally, we\nprovide...",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）是否能取代人类评估者，特别针对软件工程（SE）任务中的 LLM-as-a-Judge 方法。研究者通过实证实验，使用七种基于通用 LLMs 的方法和两种针对评估 fine-tuned 的 LLMs，对代码翻译、代码生成和代码总结等数据集的 LLM 输出进行评估，并与人类评分进行比较。结果显示，output-based 方法在代码翻译和生成任务上与人类评分的 Pearson correlation 分别达到 81.32 和 68.51，显著优于传统指标如 ChrF++（分别为 34.23 和 64.92），并展现出更平衡的评分分布。该研究证明 LLM-as-a-Judge 在 SE 任务中可实现近似人类水平的评估，但仍需进一步优化。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by ISSTA 2025:\n  https://conf.researchr.org/details/issta-2025/issta-2025-papers/85/Can-LLMs-replace-Human-Evaluators-An-Empirical-Study-of-LLM-as-a-Judge-in-Software-E",
      "pdf_url": "http://arxiv.org/pdf/2502.06193v3",
      "published_date": "2025-02-10 06:49:29 UTC",
      "updated_date": "2025-04-21 08:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:44:02.756776"
    },
    {
      "arxiv_id": "2502.06192v2",
      "title": "Right Time to Learn:Promoting Generalization via Bio-inspired Spacing Effect in Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Guanglong Sun",
        "Hongwei Yan",
        "Liyuan Wang",
        "Qian Li",
        "Bo Lei",
        "Yi Zhong"
      ],
      "abstract": "Knowledge distillation (KD) is a powerful strategy for training deep neural\nnetworks (DNNs). Although it was originally proposed to train a more compact\n\"student\" model from a large \"teacher\" model, many recent efforts have focused\non adapting it to promote generalization of the model itself, such as online KD\nand self KD. Here, we propose an accessible and compatible strategy named\nSpaced KD to improve the effectiveness of both online KD and self KD, in which\nthe student model distills knowledge from a teacher model trained with a space\ninterval ahead. This strategy is inspired by a prominent theory named spacing\neffect in biological learning and memory, positing that appropriate intervals\nbetween learning trials can significantly enhance learning performance. With\nboth theoretical and empirical analyses, we demonstrate that the benefits of\nthe proposed Spaced KD stem from convergence to a flatter loss landscape during\nstochastic gradient descent (SGD). We perform extensive experiments to validate\nthe effectiveness of Spaced KD in improving the learning performance of DNNs\n(e.g., the performance gain is up to 2.31% and 3.34% on Tiny-ImageNet over\nonline KD and self KD, respectively). Our codes have been released on github\nhttps://github.com/SunGL001/Spaced-KD.",
      "tldr_zh": "该论文提出了一种名为Spaced KD 的新策略，用于提升知识蒸馏（Knowledge Distillation）在深度神经网络（DNNs）中的泛化性能，特别针对在线KD和自KD方法。Spaced KD 受生物学习中的间隔效应（spacing effect）启发，让学生模型从提前间隔训练的教师模型中学习，从而在随机梯度下降（SGD）过程中收敛到更平坦的损失景观。实验结果显示，Spaced KD 在 Tiny-ImageNet 数据集上分别比在线KD和自KD 提高了 2.31% 和 3.34% 的性能，为改进DNNs的学习效果提供了有效的兼容性方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06192v2",
      "published_date": "2025-02-10 06:48:04 UTC",
      "updated_date": "2025-05-19 14:51:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:44:14.956798"
    },
    {
      "arxiv_id": "2502.06185v1",
      "title": "Discourse-Driven Evaluation: Unveiling Factual Inconsistency in Long Document Summarization",
      "title_zh": "话语驱动评估：揭示长文档摘要中的事实不一致",
      "authors": [
        "Yang Zhong",
        "Diane Litman"
      ],
      "abstract": "Detecting factual inconsistency for long document summarization remains\nchallenging, given the complex structure of the source article and long summary\nlength. In this work, we study factual inconsistency errors and connect them\nwith a line of discourse analysis. We find that errors are more common in\ncomplex sentences and are associated with several discourse features. We\npropose a framework that decomposes long texts into discourse-inspired chunks\nand utilizes discourse information to better aggregate sentence-level scores\npredicted by natural language inference models. Our approach shows improved\nperformance on top of different model baselines over several evaluation\nbenchmarks, covering rich domains of texts, focusing on long document\nsummarization. This underscores the significance of incorporating discourse\nfeatures in developing models for scoring summaries for long document factual\ninconsistency.",
      "tldr_zh": "这篇论文探讨了在长文档摘要中检测事实不一致性（factual inconsistency）的挑战，并将其与话语分析（discourse analysis）联系起来。研究发现，这些错误更常见于复杂句子，并与特定话语特征相关。作者提出一个框架，将长文本分解成话语启发的块（discourse-inspired chunks），并利用话语信息来更好地聚合自然语言推理模型（natural language inference models）的句子级分数。该方法在多个基准测试中显著提升了性能，强调了在开发事实不一致性评分模型时整合话语特征的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2502.06185v1",
      "published_date": "2025-02-10 06:30:15 UTC",
      "updated_date": "2025-02-10 06:30:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:44:27.181947"
    },
    {
      "arxiv_id": "2502.06180v1",
      "title": "RideKE: Leveraging Low-Resource, User-Generated Twitter Content for Sentiment and Emotion Detection in Kenyan Code-Switched Dataset",
      "title_zh": "RideKE：利用低资源用户生成 Twitter 内容进行肯尼亚代码切换数据集中的情感和情绪检测",
      "authors": [
        "Naome A. Etori",
        "Maria L. Gini"
      ],
      "abstract": "Social media has become a crucial open-access platform for individuals to\nexpress opinions and share experiences. However, leveraging low-resource\nlanguage data from Twitter is challenging due to scarce, poor-quality content\nand the major variations in language use, such as slang and code-switching.\nIdentifying tweets in these languages can be difficult as Twitter primarily\nsupports high-resource languages. We analyze Kenyan code-switched data and\nevaluate four state-of-the-art (SOTA) transformer-based pretrained models for\nsentiment and emotion classification, using supervised and semi-supervised\nmethods. We detail the methodology behind data collection and annotation, and\nthe challenges encountered during the data curation phase. Our results show\nthat XLM-R outperforms other models; for sentiment analysis, XLM-R supervised\nmodel achieves the highest accuracy (69.2\\%) and F1 score (66.1\\%), XLM-R\nsemi-supervised (67.2\\% accuracy, 64.1\\% F1 score). In emotion analysis,\nDistilBERT supervised leads in accuracy (59.8\\%) and F1 score (31\\%), mBERT\nsemi-supervised (accuracy (59\\% and F1 score 26.5\\%). AfriBERTa models show the\nlowest accuracy and F1 scores. All models tend to predict neutral sentiment,\nwith Afri-BERT showing the highest bias and unique sensitivity to empathy\nemotion. https://github.com/NEtori21/Ride_hailing",
      "tldr_zh": "本研究提出RideKE框架，利用Twitter上的低资源、用户生成内容（如Kenyan code-switched数据集）来检测情感（sentiment）和情绪（emotion），以应对语言变异（如俚语和代码切换）的挑战。研究者评估了四种SOTA transformer-based预训练模型（XLM-R、DistilBERT、mBERT和AfriBERTa），采用监督和半监督方法进行情感和情绪分类，并详细说明了数据收集、标注及相关难题。结果显示，XLM-R在情感分析中表现最佳（监督模型准确率69.2%、F1分数66.1%），DistilBERT在情绪分析中领先（监督准确率59.8%、F1分数31%），但所有模型均倾向预测中性情感，且AfriBERTa显示出最高偏差和对empathy情绪的独特敏感性。该框架为低资源语言的文本分析提供了实用见解，并提供了开源代码（https://github.com/NEtori21/Ride_hailing）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in WASSA 2024",
      "pdf_url": "http://arxiv.org/pdf/2502.06180v1",
      "published_date": "2025-02-10 06:18:07 UTC",
      "updated_date": "2025-02-10 06:18:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:44:41.134209"
    },
    {
      "arxiv_id": "2502.06173v1",
      "title": "Uncertainty-Aware Adaptation of Large Language Models for Protein-Protein Interaction Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Sanket Jantre",
        "Tianle Wang",
        "Gilchan Park",
        "Kriti Chopra",
        "Nicholas Jeon",
        "Xiaoning Qian",
        "Nathan M. Urban",
        "Byung-Jun Yoon"
      ],
      "abstract": "Identification of protein-protein interactions (PPIs) helps derive cellular\nmechanistic understanding, particularly in the context of complex conditions\nsuch as neurodegenerative disorders, metabolic syndromes, and cancer. Large\nLanguage Models (LLMs) have demonstrated remarkable potential in predicting\nprotein structures and interactions via automated mining of vast biomedical\nliterature; yet their inherent uncertainty remains a key challenge for deriving\nreproducible findings, critical for biomedical applications. In this study, we\npresent an uncertainty-aware adaptation of LLMs for PPI analysis, leveraging\nfine-tuned LLaMA-3 and BioMedGPT models. To enhance prediction reliability, we\nintegrate LoRA ensembles and Bayesian LoRA models for uncertainty\nquantification (UQ), ensuring confidence-calibrated insights into protein\nbehavior. Our approach achieves competitive performance in PPI identification\nacross diverse disease contexts while addressing model uncertainty, thereby\nenhancing trustworthiness and reproducibility in computational biology. These\nfindings underscore the potential of uncertainty-aware LLM adaptation for\nadvancing precision medicine and biomedical research.",
      "tldr_zh": "该论文提出了一种不确定性感知的 Large Language Models (LLMs) 适应方法，用于蛋白质-蛋白质相互作用 (PPIs) 分析，以解决LLMs在生物医学应用中不确定性导致的可重复性问题。方法通过 fine-tuned LLaMA-3 和 BioMedGPT 模型，结合 LoRA ensembles 和 Bayesian LoRA 进行不确定性量化 (UQ)，从而提升预测的可靠性和置信度。实验结果显示，该方法在多种疾病背景下实现了竞争性的 PPI 识别性能，并增强了计算生物学的可信度和可重复性，为精确医学和生物医学研究提供了重要潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06173v1",
      "published_date": "2025-02-10 05:54:36 UTC",
      "updated_date": "2025-02-10 05:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:44:51.437586"
    },
    {
      "arxiv_id": "2502.06170v1",
      "title": "An Interpretable Implicit-Based Approach for Modeling Local Spatial Effects: A Case Study of Global Gross Primary Productivity",
      "title_zh": "翻译失败",
      "authors": [
        "Siqi Du",
        "Hongsheng Huang",
        "Kaixin Shen",
        "Ziqi Liu",
        "Shengjun Tang"
      ],
      "abstract": "In Earth sciences, unobserved factors exhibit non-stationary spatial\ndistributions, causing the relationships between features and targets to\ndisplay spatial heterogeneity. In geographic machine learning tasks,\nconventional statistical learning methods often struggle to capture spatial\nheterogeneity, leading to unsatisfactory prediction accuracy and unreliable\ninterpretability. While approaches like Geographically Weighted Regression\n(GWR) capture local variations, they fall short of uncovering global patterns\nand tracking the continuous evolution of spatial heterogeneity. Motivated by\nthis limitation, we propose a novel perspective - that is, simultaneously\nmodeling common features across different locations alongside spatial\ndifferences using deep neural networks. The proposed method is a dual-branch\nneural network with an encoder-decoder structure. In the encoding stage, the\nmethod aggregates node information in a spatiotemporal conditional graph using\nGCN and LSTM, encoding location-specific spatiotemporal heterogeneity as an\nimplicit conditional vector. Additionally, a self-attention-based encoder is\nused to extract location-invariant common features from the data. In the\ndecoding stage, the approach employs a conditional generation strategy that\npredicts response variables and interpretative weights based on data features\nunder spatiotemporal conditions. The approach is validated by predicting\nvegetation gross primary productivity (GPP) using global climate and land cover\ndata from 2001 to 2020. Trained on 50 million samples and tested on 2.8\nmillion, the proposed model achieves an RMSE of 0.836, outperforming LightGBM\n(1.063) and TabNet (0.944). Visualization analyses indicate that our method can\nreveal the distribution differences of the dominant factors of GPP across\nvarious times and locations.",
      "tldr_zh": "本文提出了一种基于隐式方法的创新框架，用于建模地球科学中空间异质性问题，特别是特征与目标关系的非平稳分布。该方法采用双分支神经网络，包括GCN和LSTM编码位置特定的时空异质性作为隐式条件向量，以及自注意力机制提取位置不变的共同特征；在解码阶段，通过条件生成策略预测响应变量并提供解释权重。针对全球植被总初级生产力(GPP)的预测，该模型在2001-2020年数据上训练，RMSE达到0.836，优于LightGBM(1.063)和TabNet(0.944)，并通过可视化分析揭示了GPP主导因素在不同时间和位置的分布差异。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06170v1",
      "published_date": "2025-02-10 05:44:54 UTC",
      "updated_date": "2025-02-10 05:44:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:45:06.216948"
    },
    {
      "arxiv_id": "2502.06167v1",
      "title": "Universal Approximation of Visual Autoregressive Transformers",
      "title_zh": "视觉自回归变压器的通用逼近",
      "authors": [
        "Yifang Chen",
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "We investigate the fundamental limits of transformer-based foundation models,\nextending our analysis to include Visual Autoregressive (VAR) transformers. VAR\nrepresents a big step toward generating images using a novel, scalable,\ncoarse-to-fine ``next-scale prediction'' framework. These models set a new\nquality bar, outperforming all previous methods, including Diffusion\nTransformers, while having state-of-the-art performance for image synthesis\ntasks. Our primary contributions establish that, for single-head VAR\ntransformers with a single self-attention layer and single interpolation layer,\nthe VAR Transformer is universal. From the statistical perspective, we prove\nthat such simple VAR transformers are universal approximators for any\nimage-to-image Lipschitz functions. Furthermore, we demonstrate that flow-based\nautoregressive transformers inherit similar approximation capabilities. Our\nresults provide important design principles for effective and computationally\nefficient VAR Transformer strategies that can be used to extend their utility\nto more sophisticated VAR models in image generation and other related areas.",
      "tldr_zh": "本文研究了基于Transformer的基础模型的根本限制，特别是扩展到Visual Autoregressive (VAR) transformers，证明了其在图像生成中的通用近似能力。VAR模型采用可扩展的“next-scale prediction”框架，从粗到细生成图像，并在图像合成任务中超越了Diffusion Transformers等现有方法。研究进一步证明，单头VAR transformers（仅含一个自注意力层和插值层）可以近似任何图像到图像的Lipschitz函数，并为基于流的autoregressive transformers提供类似能力，从而为更高效的图像生成模型设计提供重要原则。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06167v1",
      "published_date": "2025-02-10 05:36:30 UTC",
      "updated_date": "2025-02-10 05:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:45:15.247032"
    },
    {
      "arxiv_id": "2502.06911v1",
      "title": "Foundation Models for Anomaly Detection: Vision and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Ren",
        "Tao Tang",
        "Hong Jia",
        "Haytham Fayek",
        "Xiaodong Li",
        "Suyu Ma",
        "Xiwei Xu",
        "Feng Xia"
      ],
      "abstract": "As data continues to grow in volume and complexity across domains such as\nfinance, manufacturing, and healthcare, effective anomaly detection is\nessential for identifying irregular patterns that may signal critical issues.\nRecently, foundation models (FMs) have emerged as a powerful tool for advancing\nanomaly detection. They have demonstrated unprecedented capabilities in\nenhancing anomaly identification, generating detailed data descriptions, and\nproviding visual explanations. This survey presents the first comprehensive\nreview of recent advancements in FM-based anomaly detection. We propose a novel\ntaxonomy that classifies FMs into three categories based on their roles in\nanomaly detection tasks, i.e., as encoders, detectors, or interpreters. We\nprovide a systematic analysis of state-of-the-art methods and discuss key\nchallenges in leveraging FMs for improved anomaly detection. We also outline\nfuture research directions in this rapidly evolving field.",
      "tldr_zh": "本论文对 Foundation Models (FMs) 在 Anomaly Detection 中的应用进行了首次全面回顾，强调 FMs 在识别异常模式、生成数据描述和提供视觉解释方面的强大能力。作者提出了一种新分类法，将 FMs 分为编码器、检测器或解释器，并系统分析了现有最先进的方法，同时讨论了关键挑战，如模型适应性和数据复杂性。论文还概述了未来研究方向，包括提升 FMs 的鲁棒性和跨领域应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06911v1",
      "published_date": "2025-02-10 05:01:08 UTC",
      "updated_date": "2025-02-10 05:01:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:45:27.093429"
    },
    {
      "arxiv_id": "2502.06153v2",
      "title": "Low Tensor-Rank Adaptation of Kolmogorov--Arnold Networks",
      "title_zh": "Kolmogorov--Arnold 网络的低张量秩适应",
      "authors": [
        "Yihang Gao",
        "Michael K. Ng",
        "Vincent Y. F. Tan"
      ],
      "abstract": "Kolmogorov--Arnold networks (KANs) have demonstrated their potential as an\nalternative to multi-layer perceptions (MLPs) in various domains, especially\nfor science-related tasks. However, transfer learning of KANs remains a\nrelatively unexplored area. In this paper, inspired by Tucker decomposition of\ntensors and evidence on the low tensor-rank structure in KAN parameter updates,\nwe develop low tensor-rank adaptation (LoTRA) for fine-tuning KANs. We study\nthe expressiveness of LoTRA based on Tucker decomposition approximations.\nFurthermore, we provide a theoretical analysis to select the learning rates for\neach LoTRA component to enable efficient training. Our analysis also shows that\nusing identical learning rates across all components leads to inefficient\ntraining, highlighting the need for an adaptive learning rate strategy. Beyond\ntheoretical insights, we explore the application of LoTRA for efficiently\nsolving various partial differential equations (PDEs) by fine-tuning KANs.\nAdditionally, we propose Slim KANs that incorporate the inherent\nlow-tensor-rank properties of KAN parameter tensors to reduce model size while\nmaintaining superior performance. Experimental results validate the efficacy of\nthe proposed learning rate selection strategy and demonstrate the effectiveness\nof LoTRA for transfer learning of KANs in solving PDEs. Further evaluations on\nSlim KANs for function representation and image classification tasks highlight\nthe expressiveness of LoTRA and the potential for parameter reduction through\nlow tensor-rank decomposition.",
      "tldr_zh": "本论文提出了一种低张量秩适应（LoTRA）方法，用于微调Kolmogorov--Arnold networks (KANs)，以提升其在科学任务中的迁移学习效率。该方法基于Tucker decomposition和KAN参数更新的低张量秩结构，并通过理论分析优化每个LoTRA组件的学习率，避免使用统一学习率导致的训练低效。实验结果显示，LoTRA在解决偏微分方程（PDEs）等任务中显著提高了KANs的性能，同时作者引入Slim KANs，利用低张量秩特性减少模型参数，同时保持高表达能力，在函数表示和图像分类任务上表现出色。总的来说，该工作为KANs的迁移学习提供了高效策略，并验证了其实际应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06153v2",
      "published_date": "2025-02-10 04:57:07 UTC",
      "updated_date": "2025-02-14 01:43:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:45:40.144872"
    },
    {
      "arxiv_id": "2502.06152v3",
      "title": "The Value of Information in Human-AI Decision-making",
      "title_zh": "人类-人工智能决策中的信息价值",
      "authors": [
        "Ziyang Guo",
        "Yifan Wu",
        "Jason Hartline",
        "Jessica Hullman"
      ],
      "abstract": "Multiple agents -- including humans and AI models -- are often paired on\ndecision tasks with the expectation of achieving complementary performance,\nwhere the combined performance of both agents outperforms either one alone.\nHowever, knowing how to improve the performance of a human-AI team is often\ndifficult without knowing more about what particular information and strategies\neach agent employs. We provide a decision-theoretic framework for\ncharacterizing the value of information -- and consequently, opportunities for\nagents to better exploit available information -- in AI-assisted decision\nworkflows. We demonstrate the use of the framework for model selection,\nempirical evaluation of human-AI performance, and explanation design. We\npropose a novel information-based explanation technique that adapts SHAP, a\nsaliency-based explanation, to explain information value in decision making.",
      "tldr_zh": "这篇论文探讨了人类和AI模型在决策任务中的合作性能，强调了解每个代理的信息和策略对于提升团队表现的重要性。作者提出一个决策理论框架，用于表征信息价值，并识别代理更好地利用信息的机遇。该框架应用于模型选择、人类-AI性能的实证评估以及解释设计，并引入了一种新颖的信息-based解释技术，该技术改编了SHAP方法，以解释决策中的信息价值。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06152v3",
      "published_date": "2025-02-10 04:50:42 UTC",
      "updated_date": "2025-04-15 19:26:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:45:50.346982"
    },
    {
      "arxiv_id": "2502.06151v1",
      "title": "Powerformer: A Transformer with Weighted Causal Attention for Time-series Forecasting",
      "title_zh": "Powerformer：一种带有加权因果注意力的Transformer，用于时间序列预测",
      "authors": [
        "Kareem Hegazy",
        "Michael W. Mahoney",
        "N. Benjamin Erichson"
      ],
      "abstract": "Transformers have recently shown strong performance in time-series\nforecasting, but their all-to-all attention mechanism overlooks the (temporal)\ncausal and often (temporally) local nature of data. We introduce Powerformer, a\nnovel Transformer variant that replaces noncausal attention weights with causal\nweights that are reweighted according to a smooth heavy-tailed decay. This\nsimple yet effective modification endows the model with an inductive bias\nfavoring temporally local dependencies, while still allowing sufficient\nflexibility to learn the unique correlation structure of each dataset. Our\nempirical results demonstrate that Powerformer not only achieves\nstate-of-the-art accuracy on public time-series benchmarks, but also that it\noffers improved interpretability of attention patterns. Our analyses show that\nthe model's locality bias is amplified during training, demonstrating an\ninterplay between time-series data and power-law-based attention. These\nfindings highlight the importance of domain-specific modifications to the\nTransformer architecture for time-series forecasting, and they establish\nPowerformer as a strong, efficient, and principled baseline for future research\nand real-world applications.",
      "tldr_zh": "该研究提出Powerformer，一种改进的Transformer模型，用于时间序列预测，通过将非因果注意力机制替换为加权因果注意力（weighted causal attention），并根据平滑重尾衰减（smooth heavy-tailed decay）重新调整权重，从而引入归纳偏差（inductive bias）以优先考虑时间上局部的依赖关系，同时保持对数据集独特相关结构的灵活性。实验结果显示，Powerformer在公共时间序列基准上实现了最先进的准确率，并提升了注意力模式的解释性。进一步分析表明，该模型的局部性偏差在训练过程中被放大，突显了时间序列数据与基于幂律的注意力机制之间的互动。最后，该工作强调了对Transformer架构进行领域特定修改的重要性，并将Powerformer确立为高效且原则性的未来研究基线。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06151v1",
      "published_date": "2025-02-10 04:42:11 UTC",
      "updated_date": "2025-02-10 04:42:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:46:03.698569"
    },
    {
      "arxiv_id": "2502.06146v2",
      "title": "Guided Exploration for Efficient Relational Model Learning",
      "title_zh": "用于高效关系模型学习的引导式探索",
      "authors": [
        "Annie Feng",
        "Nishanth Kumar",
        "Tomas Lozano-Perez",
        "Leslie Pack-Kaelbling"
      ],
      "abstract": "Efficient exploration is critical for learning relational models in\nlarge-scale environments with complex, long-horizon tasks. Random exploration\nmethods often collect redundant or irrelevant data, limiting their ability to\nlearn accurate relational models of the environment. Goal-literal babbling\n(GLIB) improves upon random exploration by setting and planning to novel goals,\nbut its reliance on random actions and random novel goal selection limits its\nscalability to larger domains. In this work, we identify the principles\nunderlying efficient exploration in relational domains: (1) operator\ninitialization with demonstrations that cover the distinct lifted effects\nnecessary for planning and (2) refining preconditions to collect maximally\ninformative transitions by selecting informative goal-action pairs and\nexecuting plans to them. To demonstrate these principles, we introduce\nBaking-Large, a challenging domain with extensive state-action spaces and\nlong-horizon tasks. We evaluate methods using oracle-driven demonstrations for\noperator initialization and precondition-targeting guidance to efficiently\ngather critical transitions. Experiments show that both the oracle\ndemonstrations and precondition-targeting oracle guidance significantly improve\nsample efficiency and generalization, paving the way for future methods to use\nthese principles to efficiently learn accurate relational models in complex\ndomains.",
      "tldr_zh": "本研究针对大型环境中的复杂长期任务，提出了一种引导探索(Guided Exploration)方法，以提升relational model的学习效率。现有方法如随机探索和GLIB依赖随机动作和目标选择，易收集冗余数据；本文识别了两个关键原理：(1) 使用演示初始化operator以覆盖distinct lifted effects，(2) 通过选择informative goal-action pairs并执行计划来精炼preconditions，从而收集最大信息transitions。为验证这些原理，引入了Baking-Large领域进行实验，结果显示oracle-driven demonstrations和precondition-targeting guidance显著提高了sample efficiency和generalization，为在复杂领域高效学习accurate relational models提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06146v2",
      "published_date": "2025-02-10 04:23:01 UTC",
      "updated_date": "2025-05-10 04:07:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:46:15.211300"
    },
    {
      "arxiv_id": "2502.07819v1",
      "title": "Enhancing kidney transplantation through multi-agent kidney exchange programs: A comprehensive review and optimization models",
      "title_zh": "翻译失败",
      "authors": [
        "Shayan Sharifi"
      ],
      "abstract": "This paper presents a comprehensive review of the last two decades of\nresearch on Kidney Exchange Programs (KEPs), systematically categorizing and\nclassifying key contributions to provide readers with a structured\nunderstanding of advancements in the field. The review highlights the evolution\nof KEP methodologies and lays the foundation for our contribution. We propose\nthree mathematical models aimed at improving both the quantity and quality of\nkidney transplants. Model 1 maximizes the number of transplants by focusing on\ncompatibility based on blood type and PRA, without additional constraints.\nModel 2 introduces a minimum Human Leukocyte Antigen (HLA) compatibility\nthreshold to enhance transplant quality, though this leads to fewer matches.\nModel 3 extends the problem to a Multi-Agent Kidney Exchange Program (MKEP),\npooling incompatible donor-recipient pairs across multiple agents, resulting in\na higher number of successful transplants while ensuring fairness across\nagents. Sensitivity analyses demonstrate trade-offs between transplant quantity\nand quality, with Model 3 striking the optimal balance by leveraging\nmulti-agent collaboration to improve both the number and quality of\ntransplants. These findings underscore the potential benefits of more\nintegrated kidney exchange systems.",
      "tldr_zh": "这篇论文回顾了过去20年Kidney Exchange Programs (KEPs)的研究进展，并系统分类了关键贡献，突出了KEPs方法的发展。作者提出三个数学模型：Model 1 基于血型和PRA兼容性最大化移植数量；Model 2 引入Human Leukocyte Antigen (HLA)兼容性阈值以提升移植质量，但可能减少匹配；Model 3 扩展到Multi-Agent Kidney Exchange Program (MKEP)，通过跨多个代理池化配对来同时提高移植数量并确保公平。敏感性分析显示，Model 3 在多代理协作中实现了数量和质量的最佳平衡，强调了更集成的肾脏交换系统的潜在益处。",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07819v1",
      "published_date": "2025-02-10 04:21:42 UTC",
      "updated_date": "2025-02-10 04:21:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:46:28.266283"
    },
    {
      "arxiv_id": "2502.09640v1",
      "title": "Online Social Support Detection in Spanish Social Media Texts",
      "title_zh": "西班牙语社交媒体",
      "authors": [
        "Moein Shahiki Tash",
        "Luis Ramos",
        "Zahra Ahani",
        "Raul Monroy",
        "Olga kolesnikova",
        "Hiram Calvo",
        "Grigori Sidorov"
      ],
      "abstract": "The advent of social media has transformed communication, enabling\nindividuals to share their experiences, seek support, and participate in\ndiverse discussions. While extensive research has focused on identifying\nharmful content like hate speech, the recognition and promotion of positive and\nsupportive interactions remain largely unexplored. This study proposes an\ninnovative approach to detecting online social support in Spanish-language\nsocial media texts. We introduce the first annotated dataset specifically\ncreated for this task, comprising 3,189 YouTube comments classified as\nsupportive or non-supportive. To address data imbalance, we employed GPT-4o to\ngenerate paraphrased comments and create a balanced dataset. We then evaluated\nsocial support classification using traditional machine learning models, deep\nlearning architectures, and transformer-based models, including GPT-4o, but\nonly on the unbalanced dataset. Subsequently, we utilized a transformer model\nto compare the performance between the balanced and unbalanced datasets. Our\nfindings indicate that the balanced dataset yielded improved results for Task 2\n(Individual and Group) and Task 3 (Nation, Other, LGBTQ, Black Community,\nWomen, Religion), whereas GPT-4o performed best for Task 1 (Social Support and\nNon-Support). This study highlights the significance of fostering a supportive\nonline environment and lays the groundwork for future research in automated\nsocial support detection.",
      "tldr_zh": "这项研究针对西班牙语社交媒体文本，提出了一种检测在线 social support 的创新方法，并引入了首个标注数据集，包含3,189条YouTube评论，分类为支持性或非支持性。\n为了解决数据不平衡问题，研究者使用GPT-4o生成改写评论，创建平衡数据集，并评估了传统机器学习、深度学习和Transformer模型（如GPT-4o）在不平衡和平衡数据集上的表现。\n结果表明，平衡数据集在Task 2（Individual and Group）和Task 3（Nation, Other, LGBTQ, Black Community, Women, Religion）上取得了更好的性能，而GPT-4o在Task 1（Social Support and Non-Support）上表现最佳。\n这项工作突出了促进支持性在线环境的重要性，并为未来的自动social support检测研究奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09640v1",
      "published_date": "2025-02-10 04:04:23 UTC",
      "updated_date": "2025-02-10 04:04:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:46:41.327965"
    },
    {
      "arxiv_id": "2502.06136v3",
      "title": "Graph Neural Networks at a Fraction",
      "title_zh": "翻译失败",
      "authors": [
        "Rucha Bhalchandra Joshi",
        "Sagar Prakash Barad",
        "Nidhi Tiwari",
        "Subhankar Mishra"
      ],
      "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for learning\nrepresentations of graph-structured data. In addition to real-valued GNNs,\nquaternion GNNs also perform well on tasks on graph-structured data. With the\naim of reducing the energy footprint, we reduce the model size while\nmaintaining accuracy comparable to that of the original-sized GNNs. This paper\nintroduces Quaternion Message Passing Neural Networks (QMPNNs), a framework\nthat leverages quaternion space to compute node representations. Our approach\noffers a generalizable method for incorporating quaternion representations into\nGNN architectures at one-fourth of the original parameter count. Furthermore,\nwe present a novel perspective on Graph Lottery Tickets, redefining their\napplicability within the context of GNNs and QMPNNs. We specifically aim to\nfind the initialization lottery from the subnetwork of the GNNs that can\nachieve comparable performance to the original GNN upon training. Thereby\nreducing the trainable model parameters even further. To validate the\neffectiveness of our proposed QMPNN framework and LTH for both GNNs and QMPNNs,\nwe evaluate their performance on real-world datasets across three fundamental\ngraph-based tasks: node classification, link prediction, and graph\nclassification.",
      "tldr_zh": "这篇论文提出了 Quaternion Message Passing Neural Networks (QMPNNs)，一种利用四元数空间的框架，用于在图神经网络 (GNNs) 中计算节点表示，仅需原参数量的四分之一，同时保持与原模型相当的准确性。作者重新定义了 Graph Lottery Tickets (LTH)，旨在从 GNNs 的子网络中识别出可实现类似性能的初始化子网络，从而进一步减少可训练参数。实验结果显示，该方法在真实数据集上表现良好，适用于节点分类、链接预测和图分类等核心图任务。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 2 figures, accepted at PAKDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06136v3",
      "published_date": "2025-02-10 03:55:09 UTC",
      "updated_date": "2025-02-28 06:26:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:46:52.744129"
    },
    {
      "arxiv_id": "2502.06910v2",
      "title": "TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting",
      "title_zh": "TimeKAN：基于 KAN 的频率分解学习架构，用于长期时间",
      "authors": [
        "Songtao Huang",
        "Zhen Zhao",
        "Can Li",
        "Lei Bai"
      ],
      "abstract": "Real-world time series often have multiple frequency components that are\nintertwined with each other, making accurate time series forecasting\nchallenging. Decomposing the mixed frequency components into multiple single\nfrequency components is a natural choice. However, the information density of\npatterns varies across different frequencies, and employing a uniform modeling\napproach for different frequency components can lead to inaccurate\ncharacterization. To address this challenges, inspired by the flexibility of\nthe recent Kolmogorov-Arnold Network (KAN), we propose a KAN-based Frequency\nDecomposition Learning architecture (TimeKAN) to address the complex\nforecasting challenges caused by multiple frequency mixtures. Specifically,\nTimeKAN mainly consists of three components: Cascaded Frequency Decomposition\n(CFD) blocks, Multi-order KAN Representation Learning (M-KAN) blocks and\nFrequency Mixing blocks. CFD blocks adopt a bottom-up cascading approach to\nobtain series representations for each frequency band. Benefiting from the high\nflexibility of KAN, we design a novel M-KAN block to learn and represent\nspecific temporal patterns within each frequency band. Finally, Frequency\nMixing blocks is used to recombine the frequency bands into the original\nformat. Extensive experimental results across multiple real-world time series\ndatasets demonstrate that TimeKAN achieves state-of-the-art performance as an\nextremely lightweight architecture. Code is available at\nhttps://github.com/huangst21/TimeKAN.",
      "tldr_zh": "该论文提出 TimeKAN，一种基于 Kolmogorov-Arnold Network (KAN) 的频率分解学习架构，用于解决长期时间序列预测中多频率成分交织的挑战。TimeKAN 主要包括 Cascaded Frequency Decomposition (CFD) 块用于自下而上分解频率带、Multi-order KAN Representation Learning (M-KAN) 块针对每个频率带学习特定时间模式，以及 Frequency Mixing 块重新组合频率成分。实验结果显示，在多个真实世界数据集上，TimeKAN 作为一种极轻量级模型，实现了最先进预测性能。代码已在 https://github.com/huangst21/TimeKAN 开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06910v2",
      "published_date": "2025-02-10 03:51:26 UTC",
      "updated_date": "2025-02-26 09:04:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:47:04.989579"
    },
    {
      "arxiv_id": "2502.06134v1",
      "title": "Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning",
      "title_zh": "通过自监督学习在不规则医疗时间序列中整合序列和图像建模",
      "authors": [
        "Liuqing Chen",
        "Shuhong Xiao",
        "Shixian Ding",
        "Shanhai Hu",
        "Lingyun Sun"
      ],
      "abstract": "Medical time series are often irregular and face significant missingness,\nposing challenges for data analysis and clinical decision-making. Existing\nmethods typically adopt a single modeling perspective, either treating series\ndata as sequences or transforming them into image representations for further\nclassification. In this paper, we propose a joint learning framework that\nincorporates both sequence and image representations. We also design three\nself-supervised learning strategies to facilitate the fusion of sequence and\nimage representations, capturing a more generalizable joint representation. The\nresults indicate that our approach outperforms seven other state-of-the-art\nmodels in three representative real-world clinical datasets. We further\nvalidate our approach by simulating two major types of real-world missingness\nthrough leave-sensors-out and leave-samples-out techniques. The results\ndemonstrate that our approach is more robust and significantly surpasses other\nbaselines in terms of classification performance.",
      "tldr_zh": "该研究针对不规则的医疗时间序列数据及其缺失问题，提出一个联合学习框架，将序列建模和图像表示相结合，以提升数据分析和临床决策的准确性。通过设计三种自监督学习(self-supervised learning)策略，该框架融合序列和图像表示，捕获更通用的联合表示，从而提高模型的泛化能力。实验结果表明，该方法在三个真实临床数据集上优于七个最先进模型，并在模拟真实缺失场景（如leave-sensors-out和leave-samples-out）时表现出显著的鲁棒性和分类性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 2 figures, AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06134v1",
      "published_date": "2025-02-10 03:49:41 UTC",
      "updated_date": "2025-02-10 03:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:47:15.845851"
    },
    {
      "arxiv_id": "2502.06909v2",
      "title": "Meta-Computing Enhanced Federated Learning in IIoT: Satisfaction-Aware Incentive Scheme via DRL-Based Stackelberg Game",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohuan Li",
        "Shaowen Qin",
        "Xin Tang",
        "Jiawen Kang",
        "Jin Ye",
        "Zhonghua Zhao",
        "Yusi Zheng",
        "Dusit Niyato"
      ],
      "abstract": "The Industrial Internet of Things (IIoT) leverages Federated Learning (FL)\nfor distributed model training while preserving data privacy, and\nmeta-computing enhances FL by optimizing and integrating distributed computing\nresources, improving efficiency and scalability. Efficient IIoT operations\nrequire a trade-off between model quality and training latency. Consequently, a\nprimary challenge of FL in IIoT is to optimize overall system performance by\nbalancing model quality and training latency. This paper designs a satisfaction\nfunction that accounts for data size, Age of Information (AoI), and training\nlatency for meta-computing. Additionally, the satisfaction function is\nincorporated into the utility functions to incentivize nodes in IIoT\nparticipation in model training. We model the utility functions of servers and\nnodes as a two-stage Stackelberg game and employ a deep reinforcement learning\napproach to learn the Stackelberg equilibrium. This approach ensures balanced\nrewards and enhances the applicability of the incentive scheme for IIoT.\nSimulation results demonstrate that, under the same budget constraints, the\nproposed incentive scheme improves utility by at least 23.7% compared to\nexisting FL schemes without compromising model accuracy.",
      "tldr_zh": "该论文提出了一种基于meta-computing增强的Federated Learning (FL)框架，用于Industrial Internet of Things (IIoT)，通过设计一个考虑数据大小、Age of Information (AoI)和训练延迟的satisfaction function来激励节点参与模型训练。作者将服务器和节点的效用函数建模为一个两阶段Stackelberg game，并采用deep reinforcement learning (DRL)方法学习Stackelberg equilibrium，以平衡模型质量和训练延迟。模拟结果显示，在相同预算约束下，该激励方案比现有FL方案提高了至少23.7%的效用，同时保持了模型准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06909v2",
      "published_date": "2025-02-10 03:33:36 UTC",
      "updated_date": "2025-04-20 13:34:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:47:27.035367"
    },
    {
      "arxiv_id": "2502.06127v1",
      "title": "Improved YOLOv5s model for key components detection of power transmission lines",
      "title_zh": "改进的 YOLOv5s 模型用于电力传输线路关键组件检测",
      "authors": [
        "Chen Chen",
        "Guowu Yuan",
        "Hao Zhou",
        "Yi Ma"
      ],
      "abstract": "High-voltage transmission lines are located far from the road, resulting in\ninconvenient inspection work and rising maintenance costs. Intelligent\ninspection of power transmission lines has become increasingly important.\nHowever, subsequent intelligent inspection relies on accurately detecting\nvarious key components. Due to the low detection accuracy of key components in\ntransmission line image inspection, this paper proposed an improved object\ndetection model based on the YOLOv5s (You Only Look Once Version 5 Small) model\nto improve the detection accuracy of key components of transmission lines.\nAccording to the characteristics of the power grid inspection image, we first\nmodify the distance measurement in the k-means clustering to improve the anchor\nmatching of the YOLOv5s model. Then, we add the convolutional block attention\nmodule (CBAM) attention mechanism to the backbone network to improve accuracy.\nFinally, we apply the focal loss function to reduce the impact of class\nimbalance. Our improved method's mAP (mean average precision) reached 98.1%,\nthe precision reached 97.5%, the recall reached 94.4%, and the detection rate\nreached 84.8 FPS (frames per second). The experimental results show that our\nimproved model improves detection accuracy and has performance advantages over\nother models.",
      "tldr_zh": "该论文针对高压输电线关键组件检测准确率低的问题，提出了一种基于 YOLOv5s 模型的改进对象检测方法，以提升智能巡检效率。改进包括修改 k-means 聚类中的距离测量来优化 anchor 匹配、在主干网络中添加 CBAM 注意力机制来提高准确性，以及采用 focal loss 函数来缓解类别不平衡影响。实验结果显示，改进模型的 mAP 达到 98.1%、精度 97.5%、召回率 94.4%、检测速度 84.8 FPS，并表现出比其他模型更优的性能优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06127v1",
      "published_date": "2025-02-10 03:29:34 UTC",
      "updated_date": "2025-02-10 03:29:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:47:39.984390"
    },
    {
      "arxiv_id": "2502.06124v3",
      "title": "Foundation Model of Electronic Medical Records for Adaptive Risk Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Pawel Renc",
        "Michal K. Grzeszczyk",
        "Nassim Oufattole",
        "Deirdre Goode",
        "Yugang Jia",
        "Szymon Bieganski",
        "Matthew B. A. McDermott",
        "Jaroslaw Was",
        "Anthony E. Samir",
        "Jonathan W. Cunningham",
        "David W. Bates",
        "Arkadiusz Sitek"
      ],
      "abstract": "The U.S. allocates nearly 18% of its GDP to healthcare but experiences lower\nlife expectancy and higher preventable death rates compared to other\nhigh-income nations. Hospitals struggle to predict critical outcomes such as\nmortality, ICU admission, and prolonged hospital stays. Traditional early\nwarning systems, like NEWS and MEWS, rely on static variables and fixed\nthresholds, limiting their adaptability, accuracy, and personalization. We\ndeveloped the Enhanced Transformer for Health Outcome Simulation (ETHOS), an AI\nmodel that tokenizes patient health timelines (PHTs) from EHRs and uses\ntransformer-based architectures to predict future PHTs. The Adaptive Risk\nEstimation System (ARES) leverages ETHOS to compute dynamic, personalized risk\nprobabilities for clinician-defined critical events. ARES also features a\npersonalized explainability module highlighting key clinical factors\ninfluencing risk estimates. We evaluated ARES on the MIMIC-IV v2.2 dataset in\nemergency department settings, benchmarking its performance against traditional\nearly warning systems and machine learning models. From 299,721 unique\npatients, 285,622 PHTs (60% with hospital admissions) were processed,\ncomprising over 357 million tokens. ETHOS outperformed benchmark models in\npredicting hospital admissions, ICU admissions, and prolonged stays, achieving\nsuperior AUC scores. Its risk estimates were robust across demographic\nsubgroups, with calibration curves confirming model reliability. The\nexplainability module provided valuable insights into patient-specific risk\nfactors. ARES, powered by ETHOS, advances predictive healthcare AI by\ndelivering dynamic, real-time, personalized risk estimation with\npatient-specific explainability. Its adaptability and accuracy offer a\ntransformative tool for clinical decision-making, potentially improving patient\noutcomes and resource allocation.",
      "tldr_zh": "本研究针对美国医疗系统的高支出与低效率问题，开发了Enhanced Transformer for Health Outcome Simulation (ETHOS)模型，该模型通过对电子健康记录(EHRs)中的患者健康时间线(PHTs)进行标记化和transformer-based架构，预测未来健康事件，并支持Adaptive Risk Estimation System (ARES)实现动态、个性化的风险概率计算。ARES还包括一个可解释性模块，突出影响风险的关键临床因素。在MIMIC-IV v2.2数据集上评估，ETHOS在预测医院入院、ICU入院和延长住院方面优于传统系统和机器学习基准模型，取得了更高的AUC分数，并显示出跨人口统计子群的稳健性和可靠性。该系统为预测性医疗AI提供了一个适应性工具，可能改善临床决策、患者结果和资源分配。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Fix affiliation list",
      "pdf_url": "http://arxiv.org/pdf/2502.06124v3",
      "published_date": "2025-02-10 03:22:39 UTC",
      "updated_date": "2025-03-13 22:37:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:47:53.878567"
    },
    {
      "arxiv_id": "2502.06117v1",
      "title": "Revisiting Dynamic Graph Clustering via Matrix Factorization",
      "title_zh": "翻译失败",
      "authors": [
        "Dongyuan Li",
        "Satoshi Kosugi",
        "Ying Zhang",
        "Manabu Okumura",
        "Feng Xia",
        "Renhe Jiang"
      ],
      "abstract": "Dynamic graph clustering aims to detect and track time-varying clusters in\ndynamic graphs, revealing the evolutionary mechanisms of complex real-world\ndynamic systems. Matrix factorization-based methods are promising approaches\nfor this task; however, these methods often struggle with scalability and can\nbe time-consuming when applied to large-scale dynamic graphs. Moreover, they\ntend to lack robustness and are vulnerable to real-world noisy data. To address\nthese issues, we make three key contributions. First, to improve scalability,\nwe propose temporal separated matrix factorization, where a single matrix is\ndivided into multiple smaller matrices for independent factorization, resulting\nin faster computation. Second, to improve robustness, we introduce\nbi-clustering regularization, which jointly optimizes graph embedding and\nclustering, thereby filtering out noisy features from the graph embeddings.\nThird, to further enhance effectiveness and efficiency, we propose selective\nembedding updating, where we update only the embeddings of dynamic nodes while\nthe embeddings of static nodes are fixed among different timestamps.\nExperimental results on six synthetic and five real-world benchmarks\ndemonstrate the scalability, robustness and effectiveness of our proposed\nmethod. Source code is available at https://github.com/Clearloveyuan/DyG-MF.",
      "tldr_zh": "本文重新审视了基于 matrix factorization 的动态图聚类方法，旨在解决其在可扩展性、计算效率和鲁棒性方面的不足。作者提出了三个关键创新：temporal separated matrix factorization，将矩阵分解为多个独立子矩阵以加速计算；bi-clustering regularization，通过联合优化图嵌入和聚类来过滤噪声特征；以及selective embedding updating，仅更新动态节点的嵌入以提高效率。实验结果显示，该方法在六个合成和五个真实世界基准上显著提升了可扩展性、鲁棒性和整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by TheWebConf 2025 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2502.06117v1",
      "published_date": "2025-02-10 02:57:46 UTC",
      "updated_date": "2025-02-10 02:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:48:04.621377"
    },
    {
      "arxiv_id": "2502.06111v2",
      "title": "CSR-Bench: Benchmarking LLM Agents in Deployment of Computer Science Research Repositories",
      "title_zh": "CSR-Bench：计算机科学研究仓库部署中 LLM 代理的基准测试",
      "authors": [
        "Yijia Xiao",
        "Runhui Wang",
        "Luyang Kong",
        "Davor Golac",
        "Wei Wang"
      ],
      "abstract": "The increasing complexity of computer science research projects demands more\neffective tools for deploying code repositories. Large Language Models (LLMs),\nsuch as Anthropic Claude and Meta Llama, have demonstrated significant\nadvancements across various fields of computer science research, including the\nautomation of diverse software engineering tasks. To evaluate the effectiveness\nof LLMs in handling complex code development tasks of research projects,\nparticularly for NLP/CV/AI/ML/DM topics, we introduce CSR-Bench, a benchmark\nfor Computer Science Research projects. This benchmark assesses LLMs from\nvarious aspects including accuracy, efficiency, and deployment script quality,\naiming to explore their potential in conducting computer science research\nautonomously. We also introduce a novel framework, CSR-Agents, that utilizes\nmultiple LLM agents to automate the deployment of GitHub code repositories of\ncomputer science research projects. Specifically, by checking instructions from\nmarkdown files and interpreting repository structures, the model generates and\niteratively improves bash commands that set up the experimental environments\nand deploy the code to conduct research tasks. Preliminary results from\nCSR-Bench indicate that LLM agents can significantly enhance the workflow of\nrepository deployment, thereby boosting developer productivity and improving\nthe management of developmental workflows.",
      "tldr_zh": "本研究引入CSR-Bench，一种基准测试，用于评估大型语言模型(LLMs)如Anthropic Claude和Meta Llama在部署计算机科学研究仓库时的表现，重点关注NLP/CV/AI/ML/DM等主题的代码开发任务。CSR-Bench从准确性、效率和部署脚本质量等方面评估LLMs的潜力，以探索其在自主进行计算机科学研究中的应用。同时，提出CSR-Agents框架，利用多个LLM代理通过检查markdown文件中的指令、解释仓库结构，并生成和迭代bash命令来自动化GitHub代码仓库的部署。初步实验结果表明，该框架显著提升了仓库部署的工作流程，提高了开发人员生产力和开发管理效率。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06111v2",
      "published_date": "2025-02-10 02:46:29 UTC",
      "updated_date": "2025-02-11 20:25:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:48:15.426932"
    },
    {
      "arxiv_id": "2502.06907v1",
      "title": "Can ChatGPT Diagnose Alzheimer's Disease?",
      "title_zh": "ChatGPT 能诊断阿尔茨海默病吗？",
      "authors": [
        "Quoc-Toan Nguyen",
        "Linh Le",
        "Xuan-The Tran",
        "Thomas Do",
        "Chin-Teng Lin"
      ],
      "abstract": "Can ChatGPT diagnose Alzheimer's Disease (AD)? AD is a devastating\nneurodegenerative condition that affects approximately 1 in 9 individuals aged\n65 and older, profoundly impairing memory and cognitive function. This paper\nutilises 9300 electronic health records (EHRs) with data from Magnetic\nResonance Imaging (MRI) and cognitive tests to address an intriguing question:\nAs a general-purpose task solver, can ChatGPT accurately detect AD using EHRs?\nWe present an in-depth evaluation of ChatGPT using a black-box approach with\nzero-shot and multi-shot methods. This study unlocks ChatGPT's capability to\nanalyse MRI and cognitive test results, as well as its potential as a\ndiagnostic tool for AD. By automating aspects of the diagnostic process, this\nresearch opens a transformative approach for the healthcare system,\nparticularly in addressing disparities in resource-limited regions where AD\nspecialists are scarce. Hence, it offers a foundation for a promising method\nfor early detection, supporting individuals with timely interventions, which is\nparamount for Quality of Life (QoL).",
      "tldr_zh": "这篇论文评估了ChatGPT在诊断Alzheimer's Disease (AD)方面的能力，使用9300个电子健康记录 (EHRs) 包括Magnetic Resonance Imaging (MRI) 和认知测试数据。研究采用零-shot和multi-shot黑盒方法进行评估，发现ChatGPT能准确分析这些数据，并展现出作为AD诊断工具的潜力。该方法有望自动化诊断过程，特别是在资源有限的地区，促进早期干预并提升患者的生活质量 (QoL)。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.06907v1",
      "published_date": "2025-02-10 02:41:08 UTC",
      "updated_date": "2025-02-10 02:41:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:48:27.504187"
    },
    {
      "arxiv_id": "2502.06106v1",
      "title": "Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yueyan Li",
        "Caixia Yuan",
        "Xiaojie Wang"
      ],
      "abstract": "The study of mechanistic interpretability aims to reverse-engineer a model to\nexplain its behaviors. While recent studies have focused on the static\nmechanism of a certain behavior, the training dynamics inside a model remain to\nbe explored. In this work, we develop an interpretable method for fine-tuning\nand reveal the mechanism behind learning. We first propose the concept of node\nredundancy as an extension of intrinsic dimension and explain the idea behind\ncircuit discovery from a fresh view. Based on the theory, we propose\ncircuit-tuning, a two-stage algorithm that iteratively performs circuit\ndiscovery to mask out irrelevant edges and updates the remaining parameters\nresponsible for a specific task. Experiments show that our method not only\nimproves performance on a wide range of tasks but is also scalable while\npreserving general capabilities. We visualize and analyze the circuits before,\nduring, and after fine-tuning, providing new insights into the\nself-organization mechanism of a neural network in the learning process.",
      "tldr_zh": "本研究提出了一种基于机械解释性(mechanistic interpretability)的circuit-tuning方法，用于识别神经网络参数冗余并优化fine-tuning过程。首先，引入节点冗余(node redundancy)概念作为内在维度(intrinsic dimension)的扩展，并从新视角解释电路发现(circuit discovery)。该方法采用两阶段算法，迭代发现并屏蔽无关边(edges)，仅更新负责特定任务的剩余参数。实验结果显示，circuit-tuning在多种任务上提升了性能，同时保持可扩展性和通用能力，并通过可视化分析揭示了神经网络在学习过程中的自组织机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06106v1",
      "published_date": "2025-02-10 02:35:53 UTC",
      "updated_date": "2025-02-10 02:35:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:48:39.831428"
    },
    {
      "arxiv_id": "2502.06105v1",
      "title": "Comprehensive Framework for Evaluating Conversational AI Chatbots",
      "title_zh": "对话式 AI 聊天机器人的全面评估框架",
      "authors": [
        "Shailja Gupta",
        "Rajesh Ranjan",
        "Surya Narayan Singh"
      ],
      "abstract": "Conversational AI chatbots are transforming industries by streamlining\ncustomer service, automating transactions, and enhancing user engagement.\nHowever, evaluating these systems remains a challenge, particularly in\nfinancial services, where compliance, user trust, and operational efficiency\nare critical. This paper introduces a novel evaluation framework that\nsystematically assesses chatbots across four dimensions: cognitive and\nconversational intelligence, user experience, operational efficiency, and\nethical and regulatory compliance. By integrating advanced AI methodologies\nwith financial regulations, the framework bridges theoretical foundations and\nreal-world deployment challenges. Additionally, we outline future research\ndirections, emphasizing improvements in conversational coherence, real-time\nadaptability, and fairness.",
      "tldr_zh": "这篇论文提出一个全面框架，用于评估对话式 AI 聊天机器人，尤其在金融服务领域，解决合规性、用户信任和操作效率等挑战。框架系统评估四个维度：认知和对话智能、用户体验、操作效率以及伦理和监管合规，通过整合高级 AI 方法与金融法规，桥接理论基础与实际部署问题。此外，论文概述了未来研究方向，包括提升对话连贯性、实时适应性和公平性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "2 Figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06105v1",
      "published_date": "2025-02-10 02:27:34 UTC",
      "updated_date": "2025-02-10 02:27:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:48:52.714466"
    },
    {
      "arxiv_id": "2502.18484v1",
      "title": "AI Enhanced Ontology Driven NLP for Intelligent Cloud Resource Query Processing Using Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Krishna Chaitanya Sunkara",
        "Krishnaiah Narukulla"
      ],
      "abstract": "The conventional resource search in cloud infrastructure relies on\nkeyword-based searches or GUIDs, which demand exact matches and significant\nuser effort to locate resources. These conventional search approaches often\nfail to interpret the intent behind natural language queries, making resource\ndiscovery inefficient and inaccessible to users. Though there exists some form\nof NLP based search engines, they are limited and focused more on analyzing the\nNLP query itself and extracting identifiers to find the resources. But they\nfail to search resources based on their behavior or operations or their\ncapabilities or relationships or features or business relevance or the dynamic\nchanging state or the knowledge these resources have. The search criteria has\nbeen changing with the inundation of AI based services which involved\ndiscovering not just the requested resources and identifiers but seeking\ninsights. The real intent of a search has never been to just to list the\nresources but with some actual context such as to understand causes of some\nbehavior in the system, compliance checks, capacity estimations, network\nconstraints, or troubleshooting or business insights. This paper proposes an\nadvanced Natural Language Processing (NLP) enhanced by ontology-based semantics\nto enable intuitive, human-readable queries which allows users to actually\ndiscover the intent-of-search itself. By constructing an ontology of cloud\nresources, their interactions, and behaviors, the proposed framework enables\ndynamic intent extraction and relevance ranking using Latent Semantic Indexing\n(LSI) and AI models. It introduces an automated pipeline which integrates\nontology extraction by AI powered data crawlers, building a semantic knowledge\nbase for context aware resource discovery.",
      "tldr_zh": "本研究针对传统云资源搜索的局限性（如依赖关键词匹配，无法理解查询意图或资源行为），提出了一种AI增强的本体（Ontology）驱动的NLP框架，用于智能云资源查询处理。框架通过构建云资源的知识图谱（Knowledge Graphs），整合Latent Semantic Indexing (LSI)和AI模型，实现动态意图提取、相关性排名和上下文感知的资源发现。最终，该方法支持直观的自然语言查询，提供更全面的洞察，如系统行为分析、合规检查和业务相关性，从而显著提升查询效率和用户体验。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "8 pages, 5 figures, 4 tables. This paper not published at else where\n  yet. The experimental setup has a potential to be revised using real time\n  resources. Authors: Krishna Chaitanya Sunkara (IEEE Senior Member, Raleigh,\n  NC, USA, Independent Researcher), Krishnaiah Narukulla (IEEE Senior Member,\n  San Jose, CA, USA, Independent Researcher)",
      "pdf_url": "http://arxiv.org/pdf/2502.18484v1",
      "published_date": "2025-02-10 02:15:13 UTC",
      "updated_date": "2025-02-10 02:15:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:49:05.167194"
    },
    {
      "arxiv_id": "2502.06097v2",
      "title": "NLGR: Utilizing Neighbor Lists for Generative Rerank in Personalized Recommendation Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Shuli Wang",
        "Xue Wei",
        "Senjie Kou",
        "Chi Wang",
        "Wenshuai Chen",
        "Qi Tang",
        "Yinhua Zhu",
        "Xiong Xiao",
        "Xingxing Wang"
      ],
      "abstract": "Reranking plays a crucial role in modern multi-stage recommender systems by\nrearranging the initial ranking list. Due to the inherent challenges of\ncombinatorial search spaces, some current research adopts an\nevaluator-generator paradigm, with a generator generating feasible sequences\nand an evaluator selecting the best sequence based on the estimated list\nutility. However, these methods still face two issues. Firstly, due to the goal\ninconsistency problem between the evaluator and generator, the generator tends\nto fit the local optimal solution of exposure distribution rather than\ncombinatorial space optimization. Secondly, the strategy of generating target\nitems one by one is difficult to achieve optimality because it ignores the\ninformation of subsequent items.\n  To address these issues, we propose a utilizing Neighbor Lists model for\nGenerative Reranking (NLGR), which aims to improve the performance of the\ngenerator in the combinatorial space. NLGR follows the evaluator-generator\nparadigm and improves the generator's training and generating methods.\nSpecifically, we use neighbor lists in combination space to enhance the\ntraining process, making the generator perceive the relative scores and find\nthe optimization direction. Furthermore, we propose a novel sampling-based\nnon-autoregressive generation method, which allows the generator to jump\nflexibly from the current list to any neighbor list. Extensive experiments on\npublic and industrial datasets validate NLGR's effectiveness and we have\nsuccessfully deployed NLGR on the Meituan food delivery platform.",
      "tldr_zh": "该研究针对多阶段推荐系统中的 reranking 问题，提出了 NLGR 模型，以解决现有 evaluator-generator 范式下生成器易陷入局部最优和忽略后续项目信息的挑战。NLGR 通过利用 neighbor lists 增强生成器的训练过程，使其能感知相对分数并优化组合空间；同时，引入了一种基于采样的 non-autoregressive 生成方法，允许生成器灵活跳转到邻居列表。实验在公共和工业数据集上验证了 NLGR 的有效性，并已在 Meituan 食品配送平台成功部署。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by WWW 2025 Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2502.06097v2",
      "published_date": "2025-02-10 02:06:17 UTC",
      "updated_date": "2025-02-11 14:44:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:49:15.746708"
    },
    {
      "arxiv_id": "2502.06096v2",
      "title": "Post-detection inference for sequential changepoint localization",
      "title_zh": "翻译失败",
      "authors": [
        "Aytijhya Saha",
        "Aaditya Ramdas"
      ],
      "abstract": "This paper addresses a fundamental but largely unexplored challenge in\nsequential changepoint analysis: conducting inference following a detected\nchange. We study the problem of localizing the changepoint using only the data\nobserved up to a data-dependent stopping time at which a sequential detection\nalgorithm $\\mathcal A$ declares a change. We first construct confidence sets\nfor the unknown changepoint when pre- and post-change distributions are assumed\nto be known. We then extend our framework to composite pre- and post-change\nscenarios. We impose no conditions on the observation space or on $\\mathcal A$\n-- we only need to be able to run $\\mathcal A$ on simulated data sequences. In\nsummary, this work offers both theoretically sound and practically effective\ntools for sequential changepoint localization.",
      "tldr_zh": "这篇论文探讨了顺序变化点分析(sequential changepoint analysis)中的关键挑战：在检测到变化后，使用检测停止时间前的数据进行变化点定位。作者首先构建置信集(confidence sets)来估计未知变化点，假设变化前后分布(pre- and post-change distributions)已知；随后扩展到复合场景中分布未知的情况。方法不依赖于特定观察空间或检测算法$\\mathcal A$，只需能在模拟数据上运行算法，从而提供理论上可靠且实际有效的顺序变化点定位工具。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06096v2",
      "published_date": "2025-02-10 02:01:30 UTC",
      "updated_date": "2025-03-10 13:20:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:49:27.947931"
    },
    {
      "arxiv_id": "2502.06095v1",
      "title": "Rateless Joint Source-Channel Coding, and a Blueprint for 6G Semantic Communications System Design",
      "title_zh": "翻译失败",
      "authors": [
        "Saeed R. Khosravirad"
      ],
      "abstract": "This paper introduces rateless joint source-channel coding (rateless JSCC).\nThe code is rateless in that it is designed and optimized for a continuum of\ncoding rates such that it achieves a desired distortion for any rate in that\ncontinuum. We further introduce rate-adaptive and stable communication link\noperation to accommodate rateless JSCCs. The link operation resembles a ``bit\npipe'' that is identified by its rate in bits per frame, and, by the rate of\nbits that are flipped in each frame. Thus, the link operation is rate-adaptive\nsuch that it punctures the rateless JSCC codeword to adapt its length (and\ncoding rate) to the underlying channel capacity, and is stable in maintaining\nthe bit flipping ratio across time frames.\n  Next, a new family of autoencoder rateless JSCC codes are introduced. The\ncode family is dubbed RLACS code (read as relax code, standing for ratelss and\nlossy autoencoder channel and source code). The code is tested for\nreconstruction loss of image signals and demonstrates powerful performance that\nis resilient to variation of channel quality. RLACS code is readily applicable\nto the case of semantic distortion suited to variety of semantic and\neffectiveness communications use cases.\n  In the second part of the paper, we dive into the practical concerns around\nsemantic communication and provide a blueprint for semantic networking system\ndesign relying on updating the existing network systems with some essential\nmodifications. We further outline a comprehensive list of open research\nproblems and development challenges towards a practical 6G communications\nsystem design that enables semantic networking.",
      "tldr_zh": "本文提出了一种 rateless joint source-channel coding (rateless JSCC)，该编码针对连续编码率进行设计和优化，能够在任意给定率下实现期望的失真，同时引入 rate-adaptive 和 stable 通信链路操作，以适应通道容量变化并保持稳定性。作者开发了 RLACS code（一种基于 autoencoder 的 rateless 和 lossy 编码），在图像信号重建测试中表现出色，对通道质量变化具有弹性，并适用于语义失真场景。论文还为 6G 语义通信系统设计提供了一个蓝图，包括对现有网络系统的必要修改，并概述了相关开放研究问题和开发挑战。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "39 pages, 9 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.06095v1",
      "published_date": "2025-02-10 01:49:16 UTC",
      "updated_date": "2025-02-10 01:49:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:49:40.910800"
    },
    {
      "arxiv_id": "2502.06906v1",
      "title": "Learning-based estimation of cattle weight gain and its influencing factors",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Riaz Hasib Hossain",
        "Rafiqul Islam",
        "Shawn R. McGrath",
        "Md Zahidul Islam",
        "David Lamb"
      ],
      "abstract": "Many cattle farmers still depend on manual methods to measure the live weight\ngain of cattle at set intervals, which is time consuming, labour intensive, and\nstressful for both the animals and handlers. A remote and autonomous monitoring\nsystem using machine learning (ML) or deep learning (DL) can provide a more\nefficient and less invasive method and also predictive capabilities for future\ncattle weight gain (CWG). This system allows continuous monitoring and\nestimation of individual cattle live weight gain, growth rates and weight\nfluctuations considering various factors like environmental conditions, genetic\npredispositions, feed availability, movement patterns and behaviour. Several\nresearchers have explored the efficiency of estimating CWG using ML and DL\nalgorithms. However, estimating CWG suffers from a lack of consistency in its\napplication. Moreover, ML or DL can provide weight gain estimations based on\nseveral features that vary in existing research. Additionally, previous studies\nhave encountered various data related challenges when estimating CWG. This\npaper presents a comprehensive investigation in estimating CWG using advanced\nML techniques based on research articles (between 2004 and 2024). This study\ninvestigates the current tools, methods, and features used in CWG estimation,\nas well as their strengths and weaknesses. The findings highlight the\nsignificance of using advanced ML approaches in CWG estimation and its critical\ninfluence on factors. Furthermore, this study identifies potential research\ngaps and provides research direction on CWG prediction, which serves as a\nreference for future research in this area.",
      "tldr_zh": "这篇论文探讨了使用机器学习 (ML) 和深度学习 (DL) 估算牛体重增益 (CWG) 的方法，以取代传统手动测量，减少时间消耗、劳动力需求，并降低对动物和处理者的压力。研究通过回顾2004-2024年间的研究文献，调查了当前工具、方法和影响因素（如环境条件、遗传倾向、饲料可用性、运动模式和行为）的优缺点，并突出了高级 ML 技术的优势。论文识别了现有 CWG 估算中的不一致性和数据挑战，并为未来预测提供研究方向，以提升远程自主监测系统的效率和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06906v1",
      "published_date": "2025-02-10 01:45:57 UTC",
      "updated_date": "2025-02-10 01:45:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:49:52.891080"
    },
    {
      "arxiv_id": "2502.06905v1",
      "title": "Lightweight Dataset Pruning without Full Training via Example Difficulty and Prediction Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Yeseul Cho",
        "Baekrok Shin",
        "Changmin Kang",
        "Chulhee Yun"
      ],
      "abstract": "Recent advances in deep learning rely heavily on massive datasets, leading to\nsubstantial storage and training costs. Dataset pruning aims to alleviate this\ndemand by discarding redundant examples. However, many existing methods require\ntraining a model with a full dataset over a large number of epochs before being\nable to prune the dataset, which ironically makes the pruning process more\nexpensive than just training the model on the entire dataset. To overcome this\nlimitation, we introduce a Difficulty and Uncertainty-Aware Lightweight (DUAL)\nscore, which aims to identify important samples from the early training stage\nby considering both example difficulty and prediction uncertainty. To address a\ncatastrophic accuracy drop at an extreme pruning, we further propose a\nratio-adaptive sampling using Beta distribution. Experiments on various\ndatasets and learning scenarios such as image classification with label noise\nand image corruption, and model architecture generalization demonstrate the\nsuperiority of our method over previous state-of-the-art (SOTA) approaches.\nSpecifically, on ImageNet-1k, our method reduces the time cost for pruning to\n66% compared to previous methods while achieving a SOTA, specifically 60% test\naccuracy at a 90% pruning ratio. On CIFAR datasets, the time cost is reduced to\njust 15% while maintaining SOTA performance.",
      "tldr_zh": "该论文提出了一种轻量级数据集修剪方法，通过 DUAL score（Difficulty and Uncertainty-Aware Lightweight score）在早期训练阶段评估样本难度和预测不确定性，从而避免了传统方法需要完整数据集训练的弊端。论文进一步引入基于 Beta distribution 的 ratio-adaptive sampling 策略，以防止极端修剪导致准确率急剧下降。实验结果显示，该方法在 ImageNet-1k 上将修剪时间减少至 66%，并在 90% 修剪率下实现 60% 测试准确率（SOTA 水平）；在 CIFAR 数据集上，修剪时间仅为 15%，同时保持 SOTA 性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06905v1",
      "published_date": "2025-02-10 01:18:40 UTC",
      "updated_date": "2025-02-10 01:18:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:50:05.337961"
    },
    {
      "arxiv_id": "2502.06084v1",
      "title": "Physics-Guided Foundation Model for Scientific Discovery: An Application to Aquatic Science",
      "title_zh": "翻译失败",
      "authors": [
        "Runlong Yu",
        "Chonghao Qiu",
        "Robert Ladwig",
        "Paul Hanson",
        "Yiqun Xie",
        "Xiaowei Jia"
      ],
      "abstract": "Physics-guided machine learning (PGML) has become a prevalent approach in\nstudying scientific systems due to its ability to integrate scientific theories\nfor enhancing machine learning (ML) models. However, most PGML approaches are\ntailored to isolated and relatively simple tasks, which limits their\napplicability to complex systems involving multiple interacting processes and\nnumerous influencing features. In this paper, we propose a\n\\textit{\\textbf{P}hysics-\\textbf{G}uided \\textbf{F}oundation \\textbf{M}odel\n(\\textbf{PGFM})} that combines pre-trained ML models and physics-based models\nand leverages their complementary strengths to improve the modeling of multiple\ncoupled processes. To effectively conduct pre-training, we construct a\nsimulated environmental system that encompasses a wide range of influencing\nfeatures and various simulated variables generated by physics-based models. The\nmodel is pre-trained in this system to adaptively select important feature\ninteractions guided by multi-task objectives. We then fine-tune the model for\neach specific task using true observations, while maintaining consistency with\nestablished physical theories, such as the principles of mass and energy\nconservation. We demonstrate the effectiveness of this methodology in modeling\nwater temperature and dissolved oxygen dynamics in real-world lakes. The\nproposed PGFM is also broadly applicable to a range of scientific fields where\nphysics-based models are being used.",
      "tldr_zh": "该研究提出了一种Physics-Guided Foundation Model (PGFM)，旨在通过结合预训练机器学习模型和基于物理的模型，解决传统Physics-Guided Machine Learning (PGML)方法在处理复杂多过程系统时的局限性。PGFM构建了一个模拟环境系统，用于预训练模型，使其能自适应选择重要特征交互，并通过多任务目标指导。模型随后在真实观测数据上进行微调，确保与物理理论（如质量和能量守恒）一致，并在水文科学中成功模拟湖泊水温和溶解氧动态。实验结果证明，PGFM在这些任务上表现出色，并可广泛应用于其他依赖物理模型的科学领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06084v1",
      "published_date": "2025-02-10 00:48:10 UTC",
      "updated_date": "2025-02-10 00:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T09:50:15.412053"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 169,
  "processed_papers_count": 169,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T09:50:36.097666"
}