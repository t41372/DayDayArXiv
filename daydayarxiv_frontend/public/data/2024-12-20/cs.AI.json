{
  "date": "2024-12-20",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-20 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 120 篇论文，主要聚焦 AI 模型的安全性、多模态学习、医疗图像处理和强化学习等领域，重点包括 LLM 的道德对齐和医疗应用创新，令人印象深刻的文章有 OpenAI 团队的 Deliberative Alignment，以及医疗领域的 VerSe 和 FairREAD 等，展示了 AI 在实际问题解决中的潜力。\n\n### 重点论文讨论\n我们先聊聊那些重要、话题性强或有实际影响的论文，尤其是 AI 安全、医疗和多模态领域的创新。\n\n- **Deliberative Alignment: Reasoning Enables Safer Language Models**（中文：审议式对齐：推理使语言模型更安全；英文：Deliberative Alignment: Reasoning Enables Safer Language Models）  \n  这篇论文由 OpenAI 团队主导，提出了一种新范式，通过训练模型在回答前显式回忆和推理安全规范，显著提高了 LLM 对安全政策的遵守，同时减少了越狱攻击和过度拒绝。该方法在复杂场景中提升了模型的鲁棒性和可解释性，适用于高风险应用。\n\n- **Social Science Is Necessary for Operationalizing Socially Responsible Foundation Models**（中文：社会科学对于操作化社会责任型基础模型的必要性；英文：Social Science Is Necessary for Operationalizing Socially Responsible Foundation Models）  \n  作者包括 Martin Gubri 等，该研究强调社会科学在 AI 模型开发中的作用，提出一个框架来评估基础模型对权力系统的冲击，并通过跨学科合作减少社会危害。该贡献在于为 AI 伦理提供实用指导，促进模型在实际部署中的责任性。\n\n- **Autonomous Option Invention for Continual Hierarchical Reinforcement Learning and Planning**（中文：自主选项发明用于持续分层强化学习和规划；英文：Autonomous Option Invention for Continual Hierarchical Reinforcement Learning and Planning）  \n  这篇论文引入了一种新方法，在强化学习中自主创建抽象选项，支持任务组合、重用和独立性，提高了样本效率。该发现对复杂环境下的 AI 规划有重要启发，尤其在长时序任务中。\n\n- **VerSe: Integrating Multiple Queries as Prompts for Versatile Cardiac MRI Segmentation**（中文：VerSe：整合多查询作为提示的通用心脏 MRI 分割框架；英文：VerSe: Integrating Multiple Queries as Prompts for Versatile Cardiac MRI Segmentation）  \n  作者包括 Dimitris Metaxas 等，提出一个框架结合对象查询和点击查询，实现自动和交互式心脏 MRI 分割，提高了分割精度和效率。该方法在医疗图像处理中表现出色，并开源代码，适用于临床应用。\n\n- **FairREAD: Re-fusing Demographic Attributes after Disentanglement for Fair Medical Image Classification**（中文：FairREAD：解缠后重新融合人口统计属性以实现公平的医疗图像分类；英文：FairREAD: Re-fusing Demographic Attributes after Disentanglement for Fair Medical Image Classification）  \n  这篇论文解决医疗图像分类中的偏见问题，通过解缠和重新融合人口属性，同时保持诊断准确性。贡献在于减少了亚群性能差异，适用于公平 AI 医疗。\n\n- **Human-Readable Adversarial Prompts: An Investigation into LLM Vulnerabilities Using Situational Context**（中文：可读性对抗提示：使用情境上下文调查 LLM 漏洞；英文：Human-Readable Adversarial Prompts: An Investigation into LLM Vulnerabilities Using Situational Context）  \n  作者探索了 LLM 对真实情境下对抗提示的脆弱性，提出方法生成更自然的攻击提示。该发现突显了 LLM 安全隐患，对提升模型防御有实际意义。\n\n其他相关论文，如 Ethics and Technical Aspects of Generative AI Models in Digital Content Creation（中文：生成式 AI 模型在数字内容创作中的伦理和技术方面；英文：Ethics and Technical Aspects of Generative AI Models in Digital Content Creation），讨论了 AI 模型的创造力和伦理风险，强调了偏见和真实性的挑战。\n\n### 其他论文简要掠过\n其余论文涉及强化学习、图像生成和医疗检测等领域，但许多较为技术化或特定，这里快速概述几篇有潜力的：\n\n- **Learning Disease Progression Models That Capture Health Disparities**（中文：学习捕捉健康差异的疾病进展模型；英文：Learning Disease Progression Models That Capture Health Disparities）  \n  提出一个 Bayesian 模型识别健康不平等，应用于心脏病患者数据，提高了风险评估的准确性。\n\n- **REFA: Reference Free Alignment for multi-preference optimization**（中文：REFA：无参考对齐的多偏好优化；英文：REFA: Reference Free Alignment for multi-preference optimization）  \n  开发了无参考优化方法，提升了 LLM 在偏好任务中的性能。\n\n- **MotiF: Making Text Count in Image Animation with Motion Focal Loss**（中文：MotiF：使用运动焦点损失使文本在图像动画中计数；英文：MotiF: Making Text Count in Image Animation with Motion Focal Loss）  \n  改进了文本引导图像动画的文本对齐，显著提升了动画质量。\n\n其他如 Collision-based Dynamics for Multi-Marginal Optimal Transport（中文：基于碰撞的动态用于多边限最优传输；英文：Collision-based Dynamics for Multi-Marginal Optimal Transport）等纯数学方法，或 Iterative Encoding-Decoding VAEs Anomaly Detection（中文：迭代编码-解码 VAEs 用于异常检测；英文：Iterative Encoding-Decoding VAEs Anomaly Detection）等技术细节较多，这里不展开讨论。\n\n总之，今天的论文突出了 AI 在安全和医疗领域的进展，值得关注后续应用。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2412.16406v2",
      "title": "Learning Disease Progression Models That Capture Health Disparities",
      "title_zh": "翻译失败",
      "authors": [
        "Erica Chiang",
        "Divya Shanmugam",
        "Ashley N. Beecy",
        "Gabriel Sayer",
        "Deborah Estrin",
        "Nikhil Garg",
        "Emma Pierson"
      ],
      "abstract": "Disease progression models are widely used to inform the diagnosis and\ntreatment of many progressive diseases. However, a significant limitation of\nexisting models is that they do not account for health disparities that can\nbias the observed data. To address this, we develop an interpretable Bayesian\ndisease progression model that captures three key health disparities: certain\npatient populations may (1) start receiving care only when their disease is\nmore severe, (2) experience faster disease progression even while receiving\ncare, or (3) receive follow-up care less frequently conditional on disease\nseverity. We show theoretically and empirically that failing to account for any\nof these disparities can result in biased estimates of severity (e.g.,\nunderestimating severity for disadvantaged groups). On a dataset of heart\nfailure patients, we show that our model can identify groups that face each\ntype of health disparity, and that accounting for these disparities while\ninferring disease severity meaningfully shifts which patients are considered\nhigh-risk.",
      "tldr_zh": "本研究针对现有疾病进展模型忽略健康差异导致数据偏差的问题，提出了一种可解释的 Bayesian 疾病进展模型。该模型捕捉三种关键健康差异：某些患者群体在疾病更严重时才开始接受护理、在接受护理时疾病进展更快，或在给定严重程度时接受后续护理频率较低。理论和实证分析表明，忽略这些差异会造成严重程度估计偏差（如低估弱势群体的风险）。在心脏衰竭患者数据集上，该模型成功识别面临差异的群体，并通过调整推断结果，更准确地识别高风险患者。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16406v2",
      "published_date": "2024-12-20 23:56:37 UTC",
      "updated_date": "2025-04-29 20:31:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:38:32.853196"
    },
    {
      "arxiv_id": "2412.16395v1",
      "title": "Autonomous Option Invention for Continual Hierarchical Reinforcement Learning and Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Rashmeet Kaur Nayyar",
        "Siddharth Srivastava"
      ],
      "abstract": "Abstraction is key to scaling up reinforcement learning (RL). However,\nautonomously learning abstract state and action representations to enable\ntransfer and generalization remains a challenging open problem. This paper\npresents a novel approach for inventing, representing, and utilizing options,\nwhich represent temporally extended behaviors, in continual RL settings. Our\napproach addresses streams of stochastic problems characterized by long\nhorizons, sparse rewards, and unknown transition and reward functions.\n  Our approach continually learns and maintains an interpretable state\nabstraction, and uses it to invent high-level options with abstract symbolic\nrepresentations. These options meet three key desiderata: (1) composability for\nsolving tasks effectively with lookahead planning, (2) reusability across\nproblem instances for minimizing the need for relearning, and (3) mutual\nindependence for reducing interference among options. Our main contributions\nare approaches for continually learning transferable, generalizable options\nwith symbolic representations, and for integrating search techniques with RL to\nefficiently plan over these learned options to solve new problems. Empirical\nresults demonstrate that the resulting approach effectively learns and\ntransfers abstract knowledge across problem instances, achieving superior\nsample efficiency compared to state-of-the-art methods.",
      "tldr_zh": "这篇论文提出了一种自主发明 options 的新方法，用于持续的层次化强化学习（continual hierarchical reinforcement learning）和规划，以解决抽象状态和动作表示的挑战。该方法在处理长 horizons、稀疏奖励以及未知转移和奖励函数的随机问题流时，持续学习可解释的状态抽象，并创建具有符号表示的高级 options，这些 options 满足 composability、reusability 和 mutual independence 的关键要求。主要贡献包括开发可转移、可泛化的 options 学习机制，并将搜索技术与强化学习（RL）集成，实现高效规划；实验结果显示，该方法在样本效率上优于最先进的方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16395v1",
      "published_date": "2024-12-20 23:04:52 UTC",
      "updated_date": "2024-12-20 23:04:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:38:48.132753"
    },
    {
      "arxiv_id": "2412.16389v1",
      "title": "Ethics and Technical Aspects of Generative AI Models in Digital Content Creation",
      "title_zh": "翻译失败",
      "authors": [
        "Atahan Karagoz"
      ],
      "abstract": "Generative AI models like GPT-4o and DALL-E 3 are reshaping digital content\ncreation, offering industries tools to generate diverse and sophisticated text\nand images with remarkable creativity and efficiency. This paper examines both\nthe capabilities and challenges of these models within creative workflows.\nWhile they deliver high performance in generating content with creativity,\ndiversity, and technical precision, they also raise significant ethical\nconcerns. Our study addresses two key research questions: (a) how these models\nperform in terms of creativity, diversity, accuracy, and computational\nefficiency, and (b) the ethical risks they present, particularly concerning\nbias, authenticity, and potential misuse. Through a structured series of\nexperiments, we analyze their technical performance and assess the ethical\nimplications of their outputs, revealing that although generative models\nenhance creative processes, they often reflect biases from their training data\nand carry ethical vulnerabilities that require careful oversight. This research\nproposes ethical guidelines to support responsible AI integration into industry\npractices, fostering a balance between innovation and ethical integrity.",
      "tldr_zh": "本研究探讨了生成式 AI 模型（如 GPT-4o 和 DALL-E 3）在数字内容创作中的技术能力和伦理挑战，这些模型在创造力、多样性、准确性和计算效率方面表现出色，但也引发了偏见、真实性和潜在误用等问题。研究通过结构化的实验分析了模型的性能，并评估了其输出带来的伦理风险，发现这些模型虽能提升创意流程，却往往反映训练数据的偏见和伦理漏洞。为此，论文提出伦理指南，以促进负责任的 AI 整合，实现创新与伦理完整性的平衡。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16389v1",
      "published_date": "2024-12-20 22:53:29 UTC",
      "updated_date": "2024-12-20 22:53:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:38:56.842711"
    },
    {
      "arxiv_id": "2412.16385v1",
      "title": "Collision-based Dynamics for Multi-Marginal Optimal Transport",
      "title_zh": "翻译失败",
      "authors": [
        "Mohsen Sadr",
        "Hossein Gorji"
      ],
      "abstract": "Inspired by the Boltzmann kinetics, we propose a collision-based dynamics\nwith a Monte Carlo solution algorithm that approximates the solution of the\nmulti-marginal optimal transport problem via randomized pairwise swapping of\nsample indices. The computational complexity and memory usage of the proposed\nmethod scale linearly with the number of samples, making it highly attractive\nfor high-dimensional settings. In several examples, we demonstrate the\nefficiency of the proposed method compared to the state-of-the-art methods.",
      "tldr_zh": "本论文提出了一种基于Boltzmann kinetics的collision-based dynamics方法，用于解决Multi-Marginal Optimal Transport问题，通过Monte Carlo算法实现样本索引的随机配对交换来逼近解决方案。相比传统方法，该方法的计算复杂度和内存使用与样本数量呈线性关系，非常适用于高维场景。实验结果显示，在多个示例中，该方法比最先进技术更高效。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.CO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16385v1",
      "published_date": "2024-12-20 22:41:16 UTC",
      "updated_date": "2024-12-20 22:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:40:35.401199"
    },
    {
      "arxiv_id": "2412.16381v1",
      "title": "VerSe: Integrating Multiple Queries as Prompts for Versatile Cardiac MRI Segmentation",
      "title_zh": "VerSe：将多个查询整合为提示以实现多功能心脏 MRI 分割",
      "authors": [
        "Bangwei Guo",
        "Meng Ye",
        "Yunhe Gao",
        "Bingyu Xin",
        "Leon Axel",
        "Dimitris Metaxas"
      ],
      "abstract": "Despite the advances in learning-based image segmentation approach, the\naccurate segmentation of cardiac structures from magnetic resonance imaging\n(MRI) remains a critical challenge. While existing automatic segmentation\nmethods have shown promise, they still require extensive manual corrections of\nthe segmentation results by human experts, particularly in complex regions such\nas the basal and apical parts of the heart. Recent efforts have been made on\ndeveloping interactive image segmentation methods that enable human-in-the-loop\nlearning. However, they are semi-automatic and inefficient, due to their\nreliance on click-based prompts, especially for 3D cardiac MRI volumes. To\naddress these limitations, we propose VerSe, a Versatile Segmentation framework\nto unify automatic and interactive segmentation through mutiple queries. Our\nkey innovation lies in the joint learning of object and click queries as\nprompts for a shared segmentation backbone. VerSe supports both fully automatic\nsegmentation, through object queries, and interactive mask refinement, by\nproviding click queries when needed. With the proposed integrated prompting\nscheme, VerSe demonstrates significant improvement in performance and\nefficiency over existing methods, on both cardiac MRI and out-of-distribution\nmedical imaging datasets. The code is available at\nhttps://github.com/bangwayne/Verse.",
      "tldr_zh": "本文提出 VerSe 框架，用于心脏 MRI 分段，旨在统一自动和交互式方法以解决现有技术的准确性和效率问题。VerSe 的关键创新是通过联合学习对象查询和点击查询作为提示，应用于共享的分段骨干网络，支持完全自动分段或交互式掩码细化。实验结果显示，该框架在心脏 MRI 及外部医疗图像数据集上，比现有方法显著提升了性能和效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16381v1",
      "published_date": "2024-12-20 22:35:47 UTC",
      "updated_date": "2024-12-20 22:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:39:21.209394"
    },
    {
      "arxiv_id": "2412.16378v3",
      "title": "REFA: Reference Free Alignment for multi-preference optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Taneesh Gupta",
        "Rahul Madhavan",
        "Xuchao Zhang",
        "Chetan Bansal",
        "Saravan Rajmohan"
      ],
      "abstract": "We introduce $\\textbf{REFA}$, a family of reference-free alignment methods\nthat optimize over multiple user preferences while enforcing fine-grained\nlength control. Our approach integrates deviation-based weighting to emphasize\nhigh-quality responses, length normalization to prevent trivial short-response\nsolutions, and an EOS-probability regularizer to mitigate dataset-induced\nbrevity biases. Theoretically, we show that under the Uncertainty Reduction\nwith Sequence Length Assertion (URSLA) framework, naive length normalization\ncan still incentivize length-based shortcuts. In contrast, REFA corrects these\nsubtle incentives, guiding models toward genuinely more informative and\nhigher-quality outputs. Empirically, REFA achieves a new\n$\\textbf{state-of-the-art}$ among reference-free alignment methods, generating\nricher responses that align more closely with human preferences. Notably, REFA\nimproves performance on the AlpacaEval2 benchmark, achieving a $\\textbf{26.6%}$\nLength-Controlled Win Rate (LC-WR) and $\\textbf{24.2%}$ Win Rate (WR).",
      "tldr_zh": "本研究引入了REFA，一种无参考对齐方法家族，用于优化多个用户偏好，同时实现细粒度长度控制。REFA 通过偏差基于加权(deviation-based weighting)、长度归一化(length normalization)和EOS-概率正则化(EOS-probability regularizer)来强调高质量响应、防止短响应捷径，并缓解数据集诱导的简短偏差。在Uncertainty Reduction with Sequence Length Assertion (URSLA)框架下，REFA理论上纠正了传统长度归一化的潜在问题，推动模型生成更具信息性和高质量输出。实证结果显示，REFA在AlpacaEval2基准上达到了state-of-the-art表现，实现了26.6%的Length-Controlled Win Rate (LC-WR)和24.2%的Win Rate (WR)。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16378v3",
      "published_date": "2024-12-20 22:25:23 UTC",
      "updated_date": "2025-02-24 07:53:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:39:33.962733"
    },
    {
      "arxiv_id": "2412.16375v1",
      "title": "Iterative Encoding-Decoding VAEs Anomaly Detection in NOAA's DART Time Series: A Machine Learning Approach for Enhancing Data Integrity for NASA's GRACE-FO Verification and Validation",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Lee"
      ],
      "abstract": "NOAA's Deep-ocean Assessment and Reporting of Tsunamis (DART) data are\ncritical for NASA-JPL's tsunami detection, real-time operations, and\noceanographic research. However, these time-series data often contain spikes,\nsteps, and drifts that degrade data quality and obscure essential oceanographic\nfeatures. To address these anomalies, the work introduces an Iterative\nEncoding-Decoding Variational Autoencoders (Iterative Encoding-Decoding VAEs)\nmodel to improve the quality of DART time series. Unlike traditional filtering\nand thresholding methods that risk distorting inherent signal characteristics,\nIterative Encoding-Decoding VAEs progressively remove anomalies while\npreserving the data's latent structure. A hybrid thresholding approach further\nretains genuine oceanographic features near boundaries. Applied to complex DART\ndatasets, this approach yields reconstructions that better maintain key oceanic\nproperties compared to classical statistical techniques, offering improved\nrobustness against spike removal and subtle step changes. The resulting\nhigh-quality data supports critical verification and validation efforts for the\nGRACE-FO mission at NASA-JPL, where accurate surface measurements are essential\nto modeling Earth's gravitational field and global water dynamics. Ultimately,\nthis data processing method enhances tsunami detection and underpins future\nclimate modeling with improved interpretability and reliability.",
      "tldr_zh": "本研究针对 NOAA 的 DART 时间序列数据中存在的异常（如尖峰、阶跃和漂移），提出了一种 Iterative Encoding-Decoding VAEs 模型，用于提升数据完整性并支持 NASA's GRACE-FO 任务的验证和验证。该模型通过迭代编码-解码过程逐步移除异常，同时保留数据潜在结构，并采用混合阈值方法保护真实的海洋特征，从而在复杂数据集上表现出色，比传统统计技术更有效地维护关键海洋属性。实验结果显示，该方法提高了对尖峰和阶跃变化的鲁棒性，最终增强了海啸检测和气候建模的可靠性和解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2412.16375v1",
      "published_date": "2024-12-20 22:19:11 UTC",
      "updated_date": "2024-12-20 22:19:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:39:46.075112"
    },
    {
      "arxiv_id": "2412.16373v1",
      "title": "FairREAD: Re-fusing Demographic Attributes after Disentanglement for Fair Medical Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Gao",
        "Jinkui Hao",
        "Bo Zhou"
      ],
      "abstract": "Recent advancements in deep learning have shown transformative potential in\nmedical imaging, yet concerns about fairness persist due to performance\ndisparities across demographic subgroups. Existing methods aim to address these\nbiases by mitigating sensitive attributes in image data; however, these\nattributes often carry clinically relevant information, and their removal can\ncompromise model performance-a highly undesirable outcome. To address this\nchallenge, we propose Fair Re-fusion After Disentanglement (FairREAD), a novel,\nsimple, and efficient framework that mitigates unfairness by re-integrating\nsensitive demographic attributes into fair image representations. FairREAD\nemploys orthogonality constraints and adversarial training to disentangle\ndemographic information while using a controlled re-fusion mechanism to\npreserve clinically relevant details. Additionally, subgroup-specific threshold\nadjustments ensure equitable performance across demographic groups.\nComprehensive evaluations on a large-scale clinical X-ray dataset demonstrate\nthat FairREAD significantly reduces unfairness metrics while maintaining\ndiagnostic accuracy, establishing a new benchmark for fairness and performance\nin medical image classification.",
      "tldr_zh": "该研究针对医疗图像分类中的公平性问题，提出了一种名为 FairREAD 的新框架，以解决现有方法在缓解敏感人口统计学属性（如种族或性别）时可能移除临床相关信息并降低模型性能的缺陷。FairREAD 通过正交约束和对抗训练(adversarial training)先分离人口统计学信息，然后使用受控重新融合(re-fusion)机制，将这些属性重新整合到公平图像表示中，同时通过子群体特定的阈值调整确保不同人口群体的性能均衡。在大规模临床 X 光数据集上的评估显示，FairREAD 显著降低了不公平度量，同时保持了诊断准确性，树立了医疗图像分类公平性的新基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to Medical Image Analysis, code will be available after\n  review is complete",
      "pdf_url": "http://arxiv.org/pdf/2412.16373v1",
      "published_date": "2024-12-20 22:17:57 UTC",
      "updated_date": "2024-12-20 22:17:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:39:57.369946"
    },
    {
      "arxiv_id": "2412.16365v1",
      "title": "Overview of the First Workshop on Language Models for Low-Resource Languages (LoResLM 2025)",
      "title_zh": "翻译失败",
      "authors": [
        "Hansi Hettiarachchi",
        "Tharindu Ranasinghe",
        "Paul Rayson",
        "Ruslan Mitkov",
        "Mohamed Gaber",
        "Damith Premasiri",
        "Fiona Anting Tan",
        "Lasitha Uyangodage"
      ],
      "abstract": "The first Workshop on Language Models for Low-Resource Languages (LoResLM\n2025) was held in conjunction with the 31st International Conference on\nComputational Linguistics (COLING 2025) in Abu Dhabi, United Arab Emirates.\nThis workshop mainly aimed to provide a forum for researchers to share and\ndiscuss their ongoing work on language models (LMs) focusing on low-resource\nlanguages, following the recent advancements in neural language models and\ntheir linguistic biases towards high-resource languages. LoResLM 2025 attracted\nnotable interest from the natural language processing (NLP) community,\nresulting in 35 accepted papers from 52 submissions. These contributions cover\na broad range of low-resource languages from eight language families and 13\ndiverse research areas, paving the way for future possibilities and promoting\nlinguistic inclusivity in NLP.",
      "tldr_zh": "LoResLM 2025 是首个专注于低资源语言的语言模型（LMs）研讨会，与第 31 届国际计算语言学会议（COLING 2025）在阿布扎比联合举办。研讨会旨在为研究人员提供平台，分享和讨论针对低资源语言的神经语言模型工作，以应对这些模型对高资源语言的偏见。共有 52 篇提交论文，其中 35 篇被接受，覆盖 8 个语言家族和 13 个多样化研究领域。该活动吸引了自然语言处理（NLP）社区的广泛关注，推动了 NLP 中的语言包容性和未来发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The First Workshop on Language Models for Low-Resource Languages\n  (LoResLM 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.16365v1",
      "published_date": "2024-12-20 21:55:32 UTC",
      "updated_date": "2024-12-20 21:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:40:09.598018"
    },
    {
      "arxiv_id": "2412.16359v2",
      "title": "Human-Readable Adversarial Prompts: An Investigation into LLM Vulnerabilities Using Situational Context",
      "title_zh": "翻译失败",
      "authors": [
        "Nilanjana Das",
        "Edward Raff",
        "Manas Gaur"
      ],
      "abstract": "Previous studies that uncovered vulnerabilities in large language models\n(LLMs) frequently employed nonsensical adversarial prompts. However, such\nprompts can now be readily identified using automated detection techniques. To\nfurther strengthen adversarial attacks, we focus on human-readable adversarial\nprompts, which are more realistic and potent threats. Our key contributions are\n(1) situation-driven attacks leveraging movie scripts as context to create\nhuman-readable prompts that successfully deceive LLMs, (2) adversarial suffix\nconversion to transform nonsensical adversarial suffixes into independent\nmeaningful text, and (3) AdvPrompter with p-nucleus sampling, a method to\ngenerate diverse, human-readable adversarial suffixes, improving attack\nefficacy in models like GPT-3.5 and Gemma 7B.",
      "tldr_zh": "本研究调查了大型语言模型(LLMs)的漏洞，专注于使用情境上下文创建人类可读的对抗提示(adversarial prompts)，以避开传统检测方法。关键贡献包括：基于电影脚本的情境驱动攻击、将无意义对抗后缀转换为独立的有意义文本，以及AdvPrompter结合p-nucleus sampling生成多样化的人类可读对抗后缀。实验结果显示，这些方法显著提高了对GPT-3.5和Gemma 7B等模型的攻击效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: text overlap with arXiv:2407.14644",
      "pdf_url": "http://arxiv.org/pdf/2412.16359v2",
      "published_date": "2024-12-20 21:43:52 UTC",
      "updated_date": "2025-03-11 21:41:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:40:21.654193"
    },
    {
      "arxiv_id": "2412.16355v2",
      "title": "Social Science Is Necessary for Operationalizing Socially Responsible Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Davies",
        "Elisa Nguyen",
        "Michael Simeone",
        "Erik Johnston",
        "Martin Gubri"
      ],
      "abstract": "With the rise of foundation models, there is growing concern about their\npotential social impacts. Social science has a long history of studying the\nsocial impacts of transformative technologies in terms of pre-existing systems\nof power and how these systems are disrupted or reinforced by new technologies.\nIn this position paper, we build on prior work studying the social impacts of\nearlier technologies to propose a conceptual framework studying foundation\nmodels as sociotechnical systems, incorporating social science expertise to\nbetter understand how these models affect systems of power, anticipate the\nimpacts of deploying these models in various applications, and study the\neffectiveness of technical interventions intended to mitigate social harms. We\nadvocate for an interdisciplinary and collaborative research paradigm between\nAI and social science across all stages of foundation model research and\ndevelopment to promote socially responsible research practices and use cases,\nand outline several strategies to facilitate such research.",
      "tldr_zh": "这篇立场论文（position paper）强调，社会科学（social science）对于实现社会责任型基础模型（foundation models）的实际操作至关重要，因为这些模型可能加剧或改变现有的权力系统。论文构建了一个概念框架，将基础模型视为社会技术系统（sociotechnical systems），通过整合社会科学专业知识来分析模型对权力系统的影响、预测其在各种应用中的部署后果，并评估缓解社会危害的技术干预效果。作者倡导在基础模型研究和开发的各个阶段开展 AI 与社会科学的跨学科合作，以促进社会责任研究实践，并提出了几项策略来推动这种协作。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16355v2",
      "published_date": "2024-12-20 21:34:43 UTC",
      "updated_date": "2025-04-02 19:56:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:40:47.215937"
    },
    {
      "arxiv_id": "2412.16339v2",
      "title": "Deliberative Alignment: Reasoning Enables Safer Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Melody Y. Guan",
        "Manas Joglekar",
        "Eric Wallace",
        "Saachi Jain",
        "Boaz Barak",
        "Alec Helyar",
        "Rachel Dias",
        "Andrea Vallone",
        "Hongyu Ren",
        "Jason Wei",
        "Hyung Won Chung",
        "Sam Toyer",
        "Johannes Heidecke",
        "Alex Beutel",
        "Amelia Glaese"
      ],
      "abstract": "As large-scale language models increasingly impact safety-critical domains,\nensuring their reliable adherence to well-defined principles remains a\nfundamental challenge. We introduce Deliberative Alignment, a new paradigm that\ndirectly teaches the model safety specifications and trains it to explicitly\nrecall and accurately reason over the specifications before answering. We used\nthis approach to align OpenAI's o-series models, and achieved highly precise\nadherence to OpenAI's safety policies, without requiring human-written\nchain-of-thoughts or answers. Deliberative Alignment pushes the Pareto frontier\nby simultaneously increasing robustness to jailbreaks while decreasing\noverrefusal rates, and also improves out-of-distribution generalization. We\ndemonstrate that reasoning over explicitly specified policies enables more\nscalable, trustworthy, and interpretable alignment.",
      "tldr_zh": "本研究提出 Deliberative Alignment，一种新范式，用于提升大型语言模型的安全性，通过直接教导模型安全规范并训练其在回答前显式回忆和推理这些规范，实现对 OpenAI 安全政策的精确遵守，而无需人类编写的链式思维或答案。该方法显著提高了模型对越狱攻击(jailbreaks)的鲁棒性，同时降低了过度拒绝(overrefusal)率，并改善了分布外(out-of-distribution)泛化。总体而言，Deliberative Alignment 使语言模型的对齐过程更可扩展、可信和可解释。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.16339v2",
      "published_date": "2024-12-20 21:00:11 UTC",
      "updated_date": "2025-01-08 20:11:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:40:58.803351"
    },
    {
      "arxiv_id": "2412.16336v1",
      "title": "Real Faults in Deep Learning Fault Benchmarks: How Real Are They?",
      "title_zh": "深度学习故障基准中的真实故障：它们有多真实？",
      "authors": [
        "Gunel Jahangirova",
        "Nargiz Humbatova",
        "Jinhan Kim",
        "Shin Yoo",
        "Paolo Tonella"
      ],
      "abstract": "As the adoption of Deep Learning (DL) systems continues to rise, an\nincreasing number of approaches are being proposed to test these systems,\nlocalise faults within them, and repair those faults. The best attestation of\neffectiveness for such techniques is an evaluation that showcases their\ncapability to detect, localise and fix real faults. To facilitate these\nevaluations, the research community has collected multiple benchmarks of real\nfaults in DL systems. In this work, we perform a manual analysis of 490 faults\nfrom five different benchmarks and identify that 314 of them are eligible for\nour study. Our investigation focuses specifically on how well the bugs\ncorrespond to the sources they were extracted from, which fault types are\nrepresented, and whether the bugs are reproducible. Our findings indicate that\nonly 18.5% of the faults satisfy our realism conditions. Our attempts to\nreproduce these faults were successful only in 52% of cases.",
      "tldr_zh": "本研究质疑深度学习（DL）系统故障基准中“真实”故障的可靠性，通过对五个基准的490个故障进行手动分析，筛选出314个符合研究的故障。分析重点评估了这些故障与来源的对应性、故障类型分布以及可重现性，结果显示仅有18.5%的故障满足真实性条件。作者尝试重现这些故障时，仅成功52%的案例，这突显了现有DL故障基准的潜在缺陷，并呼吁改进基准的真实性和可重复性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16336v1",
      "published_date": "2024-12-20 20:52:10 UTC",
      "updated_date": "2024-12-20 20:52:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:41:09.895033"
    },
    {
      "arxiv_id": "2412.16333v1",
      "title": "Optimizing Fintech Marketing: A Comparative Study of Logistic Regression and XGBoost",
      "title_zh": "翻译失败",
      "authors": [
        "Sahar Yarmohammadtoosky Dinesh Chowdary Attota"
      ],
      "abstract": "As several studies have shown, predicting credit risk is still a major\nconcern for the financial services industry and is receiving a lot of scholarly\ninterest. This area of study is crucial because it aids financial organizations\nin determining the probability that borrowers would default, which has a direct\nbearing on lending choices and risk management tactics. Despite the progress\nmade in this domain, there is still a substantial knowledge gap concerning\nconsumer actions that take place prior to the filing of credit card\napplications. The objective of this study is to predict customer responses to\nmail campaigns and assess the likelihood of default among those who engage.\nThis research employs advanced machine learning techniques, specifically\nlogistic regression and XGBoost, to analyze consumer behavior and predict\nresponses to direct mail campaigns. By integrating different data preprocessing\nstrategies, including imputation and binning, we enhance the robustness and\naccuracy of our predictive models. The results indicate that XGBoost\nconsistently outperforms logistic regression across various metrics,\nparticularly in scenarios using categorical binning and custom imputation.\nThese findings suggest that XGBoost is particularly effective in handling\ncomplex data structures and provides a strong predictive capability in\nassessing credit risk.",
      "tldr_zh": "本研究针对金融科技营销，比较 Logistic Regression 和 XGBoost 在预测客户对邮件活动响应以及评估违约风险方面的性能，旨在填补对信用卡申请前消费者行为研究的知识缺口。\n研究采用数据预处理策略，如 Imputation 和 Binning，来提升模型的鲁棒性和准确性。\n结果表明，XGBoost 在各种指标上均优于 Logistic Regression，尤其在分类分箱和自定义插值场景中，提供更强的处理复杂数据结构和信用风险评估能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.ST",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16333v1",
      "published_date": "2024-12-20 20:45:42 UTC",
      "updated_date": "2024-12-20 20:45:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:41:22.657587"
    },
    {
      "arxiv_id": "2412.16329v1",
      "title": "Improving Object Detection for Time-Lapse Imagery Using Temporal Features in Wildlife Monitoring",
      "title_zh": "使用时间特征改善野生动物监测中延时图像物体检测",
      "authors": [
        "Marcus Jenkins",
        "Kirsty A. Franklin",
        "Malcolm A. C. Nicoll",
        "Nik C. Cole",
        "Kevin Ruhomaun",
        "Vikash Tatayah",
        "Michal Mackiewicz"
      ],
      "abstract": "Monitoring animal populations is crucial for assessing the health of\necosystems. Traditional methods, which require extensive fieldwork, are\nincreasingly being supplemented by time-lapse camera-trap imagery combined with\nan automatic analysis of the image data. The latter usually involves some\nobject detector aimed at detecting relevant targets (commonly animals) in each\nimage, followed by some postprocessing to gather activity and population data.\nIn this paper, we show that the performance of an object detector in a single\nframe of a time-lapse sequence can be improved by including spatio-temporal\nfeatures from the prior frames. We propose a method that leverages temporal\ninformation by integrating two additional spatial feature channels which\ncapture stationary and non-stationary elements of the scene and consequently\nimprove scene understanding and reduce the number of stationary false\npositives. The proposed technique achieves a significant improvement of 24\\% in\nmean average precision (mAP@0.05:0.95) over the baseline (temporal\nfeature-free, single frame) object detector on a large dataset of breeding\ntropical seabirds. We envisage our method will be widely applicable to other\nwildlife monitoring applications that use time-lapse imaging.",
      "tldr_zh": "本研究针对野生动物监控中的时间序列图像，提出了一种利用时空特征（temporal features）改进对象检测（object detection）的方法，以提升检测准确性和减少静态假阳性。方法通过整合两个额外空间特征通道，捕获场景的静态和非静态元素，从而增强场景理解。实验结果显示，该技术在热带海鸟数据集上使平均精度（mAP@0.05:0.95）比基线单帧检测器提高了24%。这项创新有望广泛应用于其他基于时间序列成像的野生动物监控场景。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T45",
        "I.4.8"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.16329v1",
      "published_date": "2024-12-20 20:37:09 UTC",
      "updated_date": "2024-12-20 20:37:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:41:35.226882"
    },
    {
      "arxiv_id": "2412.16325v1",
      "title": "Towards Safe and Honest AI Agents with Neural Self-Other Overlap",
      "title_zh": "翻译失败",
      "authors": [
        "Marc Carauleanu",
        "Michael Vaiana",
        "Judd Rosenblatt",
        "Cameron Berg",
        "Diogo Schwerz de Lucena"
      ],
      "abstract": "As AI systems increasingly make critical decisions, deceptive AI poses a\nsignificant challenge to trust and safety. We present Self-Other Overlap (SOO)\nfine-tuning, a promising approach in AI Safety that could substantially improve\nour ability to build honest artificial intelligence. Inspired by cognitive\nneuroscience research on empathy, SOO aims to align how AI models represent\nthemselves and others. Our experiments on LLMs with 7B, 27B, and 78B parameters\ndemonstrate SOO's efficacy: deceptive responses of Mistral-7B-Instruct-v0.2\ndropped from 73.6% to 17.2% with no observed reduction in general task\nperformance, while in Gemma-2-27b-it and CalmeRys-78B-Orpo-v0.1 deceptive\nresponses were reduced from 100% to 9.3% and 2.7%, respectively, with a small\nimpact on capabilities. In reinforcement learning scenarios, SOO-trained agents\nshowed significantly reduced deceptive behavior. SOO's focus on contrastive\nself and other-referencing observations offers strong potential for\ngeneralization across AI architectures. While current applications focus on\nlanguage models and simple RL environments, SOO could pave the way for more\ntrustworthy AI in broader domains. Ethical implications and long-term effects\nwarrant further investigation, but SOO represents a significant step forward in\nAI safety research.",
      "tldr_zh": "该研究提出了一种名为 Self-Other Overlap (SOO) 的微调方法，受认知神经科学中移情研究的启发，旨在通过对齐 AI 模型对自己和别人的表示来减少欺骗行为，从而提升 AI 代理的安全性和诚实度。\n在实验中，SOO 在不同规模的语言模型上表现出色，例如 Mistral-7B-Instruct-v0.2 的欺骗响应从 73.6% 降至 17.2%，而 Gemma-2-27b-it 和 CalmeRys-78B-Orpo-v0.1 的欺骗率分别从 100% 降至 9.3% 和 2.7%，且对一般任务性能影响较小。\n此外，在强化学习场景中，SOO 训练的代理显示显著减少的欺骗行为，这为 SOO 在更广泛 AI 架构中的推广提供了潜力，并强调了进一步探讨其伦理影响和长期效果的必要性。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 Safe Generative AI Workshop",
      "pdf_url": "http://arxiv.org/pdf/2412.16325v1",
      "published_date": "2024-12-20 20:23:52 UTC",
      "updated_date": "2024-12-20 20:23:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:41:49.204880"
    },
    {
      "arxiv_id": "2501.01969v1",
      "title": "Optimal bounds for dissatisfaction in perpetual voting",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Kozachinskiy",
        "Alexander Shen",
        "Tomasz Steifer"
      ],
      "abstract": "In perpetual voting, multiple decisions are made at different moments in\ntime. Taking the history of previous decisions into account allows us to\nsatisfy properties such as proportionality over periods of time. In this paper,\nwe consider the following question: is there a perpetual approval voting method\nthat guarantees that no voter is dissatisfied too many times? We identify a\nsufficient condition on voter behavior -- which we call 'bounded conflicts'\ncondition -- under which a sublinear growth of dissatisfaction is possible. We\nprovide a tight upper bound on the growth of dissatisfaction under bounded\nconflicts, using techniques from Kolmogorov complexity. We also observe that\nthe approval voting with binary choices mimics the machine learning setting of\nprediction with expert advice. This allows us to present a voting method with\nsublinear guarantees on dissatisfaction under bounded conflicts, based on the\nstandard techniques from prediction with expert advice.",
      "tldr_zh": "该论文探讨了 perpetual voting 中的 dissatisfaction（不满）问题，旨在设计一种 approval voting 方法，确保选民在多个决策时刻的不满次数保持在可控范围内。研究者引入了 bounded conflicts 条件作为充分条件，并利用 Kolmogorov complexity 技术提供了不满增长的紧上界。论文还观察到 approval voting with binary choices 与 prediction with expert advice 类似，从而提出了一种基于该机器学习框架的投票方法，在 bounded conflicts 下实现 sublinear 的不满增长。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "Full version of the AAAI 2025 paper",
      "pdf_url": "http://arxiv.org/pdf/2501.01969v1",
      "published_date": "2024-12-20 19:58:55 UTC",
      "updated_date": "2024-12-20 19:58:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:41:59.061019"
    },
    {
      "arxiv_id": "2412.16311v1",
      "title": "HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases",
      "title_zh": "翻译失败",
      "authors": [
        "Meng-Chieh Lee",
        "Qi Zhu",
        "Costas Mavromatis",
        "Zhen Han",
        "Soji Adeshina",
        "Vassilis N. Ioannidis",
        "Huzefa Rangwala",
        "Christos Faloutsos"
      ],
      "abstract": "Given a semi-structured knowledge base (SKB), where text documents are\ninterconnected by relations, how can we effectively retrieve relevant\ninformation to answer user questions? Retrieval-Augmented Generation (RAG)\nretrieves documents to assist large language models (LLMs) in question\nanswering; while Graph RAG (GRAG) uses structured knowledge bases as its\nknowledge source. However, many questions require both textual and relational\ninformation from SKB - referred to as \"hybrid\" questions - which complicates\nthe retrieval process and underscores the need for a hybrid retrieval method\nthat leverages both information. In this paper, through our empirical analysis,\nwe identify key insights that show why existing methods may struggle with\nhybrid question answering (HQA) over SKB. Based on these insights, we propose\nHybGRAG for HQA consisting of a retriever bank and a critic module, with the\nfollowing advantages: (1) Agentic, it automatically refines the output by\nincorporating feedback from the critic module, (2) Adaptive, it solves hybrid\nquestions requiring both textual and relational information with the retriever\nbank, (3) Interpretable, it justifies decision making with intuitive refinement\npath, and (4) Effective, it surpasses all baselines on HQA benchmarks. In\nexperiments on the STaRK benchmark, HybGRAG achieves significant performance\ngains, with an average relative improvement in Hit@1 of 51%.",
      "tldr_zh": "本论文针对半结构化知识库（SKB）中需要结合文本和关系信息的混合问题（hybrid questions），提出了一种混合检索增强生成框架HybGRAG，以解决现有RAG和Graph RAG（GRAG）方法的局限性。HybGRAG包括retriever bank用于适应性检索文本和关系数据，以及critic module提供反馈，实现输出自动精炼（Agentic）、决策可解释（Interpretable）等优势。通过实验验证，该框架在STaRK基准测试中，Hit@1指标平均相对提升51%，显著超越基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16311v1",
      "published_date": "2024-12-20 19:49:12 UTC",
      "updated_date": "2024-12-20 19:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:42:11.192987"
    },
    {
      "arxiv_id": "2412.16291v1",
      "title": "Benchmarking LLMs and SLMs for patient reported outcomes",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Marengo",
        "Jarod Lévy",
        "Jean-Emmanuel Bibault"
      ],
      "abstract": "LLMs have transformed the execution of numerous tasks, including those in the\nmedical domain. Among these, summarizing patient-reported outcomes (PROs) into\nconcise natural language reports is of particular interest to clinicians, as it\nenables them to focus on critical patient concerns and spend more time in\nmeaningful discussions. While existing work with LLMs like GPT-4 has shown\nimpressive results, real breakthroughs could arise from leveraging SLMs as they\noffer the advantage of being deployable locally, ensuring patient data privacy\nand compliance with healthcare regulations. This study benchmarks several SLMs\nagainst LLMs for summarizing patient-reported Q\\&A forms in the context of\nradiotherapy. Using various metrics, we evaluate their precision and\nreliability. The findings highlight both the promise and limitations of SLMs\nfor high-stakes medical tasks, fostering more efficient and privacy-preserving\nAI-driven healthcare solutions.",
      "tldr_zh": "这篇论文比较了大型语言模型（LLMs）和小型语言模型（SLMs）在总结患者报告结果（PROs）方面的性能，旨在帮助临床医生快速提取关键患者关切以优化医疗讨论。研究通过基准测试评估了多个 LLMs 和 SLMs 在放射治疗背景下总结患者 Q&A 表格的表现，使用各种指标来衡量它们的精确性和可靠性。结果显示 SLMs 因其本地部署能力而具有数据隐私和法规合规优势，但也暴露了在高风险医疗任务中的局限性，从而推动更高效、隐私保护的 AI 医疗解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.16291v1",
      "published_date": "2024-12-20 19:01:25 UTC",
      "updated_date": "2024-12-20 19:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:42:22.990830"
    },
    {
      "arxiv_id": "2412.16153v2",
      "title": "MotiF: Making Text Count in Image Animation with Motion Focal Loss",
      "title_zh": "翻译失败",
      "authors": [
        "Shijie Wang",
        "Samaneh Azadi",
        "Rohit Girdhar",
        "Saketh Rambhatla",
        "Chen Sun",
        "Xi Yin"
      ],
      "abstract": "Text-Image-to-Video (TI2V) generation aims to generate a video from an image\nfollowing a text description, which is also referred to as text-guided image\nanimation. Most existing methods struggle to generate videos that align well\nwith the text prompts, particularly when motion is specified. To overcome this\nlimitation, we introduce MotiF, a simple yet effective approach that directs\nthe model's learning to the regions with more motion, thereby improving the\ntext alignment and motion generation. We use optical flow to generate a motion\nheatmap and weight the loss according to the intensity of the motion. This\nmodified objective leads to noticeable improvements and complements existing\nmethods that utilize motion priors as model inputs. Additionally, due to the\nlack of a diverse benchmark for evaluating TI2V generation, we propose TI2V\nBench, a dataset consists of 320 image-text pairs for robust evaluation. We\npresent a human evaluation protocol that asks the annotators to select an\noverall preference between two videos followed by their justifications. Through\na comprehensive evaluation on TI2V Bench, MotiF outperforms nine open-sourced\nmodels, achieving an average preference of 72%. The TI2V Bench and additional\nresults are released in https://wang-sj16.github.io/motif/.",
      "tldr_zh": "本文提出 MotiF 方法，用于提升 Text-Image-to-Video (TI2V) 生成任务的文本对齐和运动质量，特别针对现有模型在处理运动描述时的不足。MotiF 通过使用 optical flow 生成 motion heatmap，并应用 motion focal loss 来加权损失函数，优先关注运动密集区域，从而改善视频生成效果。研究者还构建了 TI2V Bench 数据集（包含 320 个图像-文本对）和人类评估协议，并在该基准上，MotiF 超过了九个开源模型，平均偏好达到 72%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025. Project page:\n  https://wang-sj16.github.io/motif/",
      "pdf_url": "http://arxiv.org/pdf/2412.16153v2",
      "published_date": "2024-12-20 18:57:06 UTC",
      "updated_date": "2025-03-23 00:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:42:35.353185"
    },
    {
      "arxiv_id": "2412.16145v2",
      "title": "Offline Reinforcement Learning for LLM Multi-Step Reasoning",
      "title_zh": "LLM 多步推理的离线强化学习",
      "authors": [
        "Huaijie Wang",
        "Shibo Hao",
        "Hanze Dong",
        "Shenao Zhang",
        "Yilin Bao",
        "Ziran Yang",
        "Yi Wu"
      ],
      "abstract": "Improving the multi-step reasoning ability of large language models (LLMs)\nwith offline reinforcement learning (RL) is essential for quickly adapting them\nto complex tasks. While Direct Preference Optimization (DPO) has shown promise\nin aligning LLMs with human preferences, it is less suitable for multi-step\nreasoning tasks because (1) DPO relies on paired preference data, which is not\nreadily available for multi-step reasoning tasks, and (2) it treats all tokens\nuniformly, making it ineffective for credit assignment in multi-step reasoning\ntasks, which often come with sparse reward. In this work, we propose OREO\n(Offline Reasoning Optimization), an offline RL method for enhancing LLM\nmulti-step reasoning. Building on insights from previous works of maximum\nentropy reinforcement learning, it jointly learns a policy model and value\nfunction by optimizing the soft Bellman Equation. We show in principle that it\nreduces the need to collect pairwise data and enables better credit assignment.\nEmpirically, OREO surpasses existing offline learning methods on multi-step\nreasoning benchmarks, including mathematical reasoning tasks (GSM8K, MATH) and\nembodied agent control (ALFWorld). The approach can be extended to a\nmulti-iteration framework when additional resources are available. Furthermore,\nthe learned value function can be leveraged to guide the tree search for free,\nwhich can further boost performance during test time.",
      "tldr_zh": "这篇论文提出 OREO（Offline Reasoning Optimization），一种离线强化学习方法，用于提升大型语言模型 (LLMs) 的多步推理能力，以解决 Direct Preference Optimization (DPO) 的局限性，如依赖配对偏好数据和信用分配不足的问题。OREO 通过优化软 Bellman 方程，联合学习策略模型和价值函数，从而减少数据需求并实现更好的信用分配。实验结果显示，OREO 在数学推理基准（如 GSM8K 和 MATH）以及具身代理控制（如 ALFWorld）上超越现有方法，并可扩展到多迭代框架，同时利用学到的价值函数指导树搜索进一步提升测试性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16145v2",
      "published_date": "2024-12-20 18:49:45 UTC",
      "updated_date": "2024-12-25 18:54:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:44:39.802896"
    },
    {
      "arxiv_id": "2412.16277v1",
      "title": "Mapping the Mind of an Instruction-based Image Editing using SMILE",
      "title_zh": "翻译失败",
      "authors": [
        "Zeinab Dehghani",
        "Koorosh Aslansefat",
        "Adil Khan",
        "Adín Ramírez Rivera",
        "Franky George",
        "Muhammad Khalid"
      ],
      "abstract": "Despite recent advancements in Instruct-based Image Editing models for\ngenerating high-quality images, they are known as black boxes and a significant\nbarrier to transparency and user trust. To solve this issue, we introduce SMILE\n(Statistical Model-agnostic Interpretability with Local Explanations), a novel\nmodel-agnostic for localized interpretability that provides a visual heatmap to\nclarify the textual elements' influence on image-generating models. We applied\nour method to various Instruction-based Image Editing models like Pix2Pix,\nImage2Image-turbo and Diffusers-Inpaint and showed how our model can improve\ninterpretability and reliability. Also, we use stability, accuracy, fidelity,\nand consistency metrics to evaluate our method. These findings indicate the\nexciting potential of model-agnostic interpretability for reliability and\ntrustworthiness in critical applications such as healthcare and autonomous\ndriving while encouraging additional investigation into the significance of\ninterpretability in enhancing dependable image editing models.",
      "tldr_zh": "该研究引入了SMILE（Statistical Model-agnostic Interpretability with Local Explanations），一种新型的模型无关局部解释方法，旨在提升基于指令的图像编辑模型的透明度和用户信任。SMILE通过生成视觉热图来阐明文本元素对图像生成过程的影响，并应用于Pix2Pix、Image2Image-turbo和Diffusers-Inpaint等模型。实验使用稳定性、准确性、保真度和一致性指标进行评估，结果表明SMILE显著提高了模型的可靠性，并在医疗和自动驾驶等关键领域展现出潜在应用价值。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16277v1",
      "published_date": "2024-12-20 18:33:23 UTC",
      "updated_date": "2024-12-20 18:33:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:42:58.708522"
    },
    {
      "arxiv_id": "2412.16135v3",
      "title": "Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models into Assembly Code Obfuscation",
      "title_zh": "翻译失败",
      "authors": [
        "Seyedreza Mohseni",
        "Seyedali Mohammadi",
        "Deepa Tilwani",
        "Yash Saxena",
        "Gerald Ketu Ndawula",
        "Sriram Vema",
        "Edward Raff",
        "Manas Gaur"
      ],
      "abstract": "Malware authors often employ code obfuscations to make their malware harder\nto detect. Existing tools for generating obfuscated code often require access\nto the original source code (e.g., C++ or Java), and adding new obfuscations is\na non-trivial, labor-intensive process. In this study, we ask the following\nquestion: Can Large Language Models (LLMs) potentially generate a new\nobfuscated assembly code? If so, this poses a risk to anti-virus engines and\npotentially increases the flexibility of attackers to create new obfuscation\npatterns. We answer this in the affirmative by developing the MetamorphASM\nbenchmark comprising MetamorphASM Dataset (MAD) along with three code\nobfuscation techniques: dead code, register substitution, and control flow\nchange. The MetamorphASM systematically evaluates the ability of LLMs to\ngenerate and analyze obfuscated code using MAD, which contains 328,200\nobfuscated assembly code samples. We release this dataset and analyze the\nsuccess rate of various LLMs (e.g., GPT-3.5/4, GPT-4o-mini, Starcoder,\nCodeGemma, CodeLlama, CodeT5, and LLaMA 3.1) in generating obfuscated assembly\ncode. The evaluation was performed using established information-theoretic\nmetrics and manual human review to ensure correctness and provide the\nfoundation for researchers to study and develop remediations to this risk.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否能生成混淆汇编代码，这可能增加恶意软件的检测难度和攻击者灵活性。研究者开发了MetamorphASM基准，包括MetamorphASM Dataset (MAD)数据集（包含328,200个混淆汇编代码样本）和三种混淆技术：dead code、register substitution以及control flow change。实验评估了多种LLMs（如GPT-3.5/4、GPT-4o-mini、Starcoder等）的生成能力，使用信息理论指标和人工审查进行验证。结果证实LLMs能成功生成混淆代码，并发布了数据集，以支持后续研究和风险缓解策略。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "To appear in AAAI 2025, Main Track",
      "pdf_url": "http://arxiv.org/pdf/2412.16135v3",
      "published_date": "2024-12-20 18:31:24 UTC",
      "updated_date": "2025-01-29 13:52:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:43:12.099816"
    },
    {
      "arxiv_id": "2412.16118v1",
      "title": "Convolutional Deep Operator Networks for Learning Nonlinear Focused Ultrasound Wave Propagation in Heterogeneous Spinal Cord Anatomy",
      "title_zh": "翻译失败",
      "authors": [
        "Avisha Kumar",
        "Xuzhe Zhi",
        "Zan Ahmad",
        "Minglang Yin",
        "Amir Manbachi"
      ],
      "abstract": "Focused ultrasound (FUS) therapy is a promising tool for optimally targeted\ntreatment of spinal cord injuries (SCI), offering submillimeter precision to\nenhance blood flow at injury sites while minimizing impact on surrounding\ntissues. However, its efficacy is highly sensitive to the placement of the\nultrasound source, as the spinal cord's complex geometry and acoustic\nheterogeneity distort and attenuate the FUS signal. Current approaches rely on\ncomputer simulations to solve the governing wave propagation equations and\ncompute patient-specific pressure maps using ultrasound images of the spinal\ncord anatomy. While accurate, these high-fidelity simulations are\ncomputationally intensive, taking up to hours to complete parameter sweeps,\nwhich is impractical for real-time surgical decision-making. To address this\nbottleneck, we propose a convolutional deep operator network (DeepONet) to\nrapidly predict FUS pressure fields in patient spinal cords. Unlike\nconventional neural networks, DeepONets are well equipped to approximate the\nsolution operator of the parametric partial differential equations (PDEs) that\ngovern the behavior of FUS waves with varying initial and boundary conditions\n(i.e., new transducer locations or spinal cord geometries) without requiring\nextensive simulations. Trained on simulated pressure maps across diverse\npatient anatomies, this surrogate model achieves real-time predictions with\nonly a 2% loss on the test set, significantly accelerating the modeling of\nnonlinear physical systems in heterogeneous domains. By facilitating rapid\nparameter sweeps in surgical settings, this work provides a crucial step toward\nprecise and individualized solutions in neurosurgical treatments.",
      "tldr_zh": "本文提出一种基于卷积深度算子网络 (Convolutional Deep Operator Network, DeepONet) 的方法，用于快速学习非线性聚焦超声 (FUS) 波在异质脊髓解剖结构中的传播，以解决传统模拟计算耗时长的问题。DeepONet 通过近似参数偏微分方程 (PDEs) 的解算子，实现对 FUS 压力场的实时预测，而无需大量模拟。实验结果显示，该模型在测试集上损失仅 2%，显著加速手术参数扫描，为精确和个性化的神经外科治疗提供关键支持。",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "Accepted for oral presentation at AAAI Conference on Artificial\n  Intelligence: AI for Accelerating Science and Engineering Workshop 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.16118v1",
      "published_date": "2024-12-20 18:03:38 UTC",
      "updated_date": "2024-12-20 18:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:43:23.219165"
    },
    {
      "arxiv_id": "2412.16108v1",
      "title": "Demystifying the Potential of ChatGPT-4 Vision for Construction Progress Monitoring",
      "title_zh": "揭示 ChatGPT-4 Vision 在建筑进度监控中的潜力",
      "authors": [
        "Ahmet Bahaddin Ersoz"
      ],
      "abstract": "The integration of Large Vision-Language Models (LVLMs) such as OpenAI's\nGPT-4 Vision into various sectors has marked a significant evolution in the\nfield of artificial intelligence, particularly in the analysis and\ninterpretation of visual data. This paper explores the practical application of\nGPT-4 Vision in the construction industry, focusing on its capabilities in\nmonitoring and tracking the progress of construction projects. Utilizing\nhigh-resolution aerial imagery of construction sites, the study examines how\nGPT-4 Vision performs detailed scene analysis and tracks developmental changes\nover time. The findings demonstrate that while GPT-4 Vision is proficient in\nidentifying construction stages, materials, and machinery, it faces challenges\nwith precise object localization and segmentation. Despite these limitations,\nthe potential for future advancements in this technology is considerable. This\nresearch not only highlights the current state and opportunities of using LVLMs\nin construction but also discusses future directions for enhancing the model's\nutility through domain-specific training and integration with other computer\nvision techniques and digital twins.",
      "tldr_zh": "本文探讨了 Large Vision-Language Models (LVLMs) 如 GPT-4 Vision 在建筑进度监控中的潜力，通过分析高分辨率航空图像进行现场场景分析和变化跟踪。研究发现，GPT-4 Vision 擅长识别建筑阶段、材料和机械，但存在精确物体定位和分割的挑战。尽管有这些局限性，该技术未来可通过领域特定训练、与其他计算机视觉技术整合以及数字孪生来进一步提升应用价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16108v1",
      "published_date": "2024-12-20 17:49:22 UTC",
      "updated_date": "2024-12-20 17:49:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:43:34.529533"
    },
    {
      "arxiv_id": "2412.16098v2",
      "title": "Explainable AI for Multivariate Time Series Pattern Exploration: Latent Space Visual Analytics with Temporal Fusion Transformer and Variational Autoencoders in Power Grid Event Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Haowen Xu",
        "Ali Boyaci",
        "Jianming Lian",
        "Aaron Wilson"
      ],
      "abstract": "Detecting and analyzing complex patterns in multivariate time-series data is\ncrucial for decision-making in urban and environmental system operations.\nHowever, challenges arise from the high dimensionality, intricate complexity,\nand interconnected nature of complex patterns, which hinder the understanding\nof their underlying physical processes. Existing AI methods often face\nlimitations in interpretability, computational efficiency, and scalability,\nreducing their applicability in real-world scenarios. This paper proposes a\nnovel visual analytics framework that integrates two generative AI models,\nTemporal Fusion Transformer (TFT) and Variational Autoencoders (VAEs), to\nreduce complex patterns into lower-dimensional latent spaces and visualize them\nin 2D using dimensionality reduction techniques such as PCA, t-SNE, and UMAP\nwith DBSCAN. These visualizations, presented through coordinated and\ninteractive views and tailored glyphs, enable intuitive exploration of complex\nmultivariate temporal patterns, identifying patterns' similarities and uncover\ntheir potential correlations for a better interpretability of the AI outputs.\nThe framework is demonstrated through a case study on power grid signal data,\nwhere it identifies multi-label grid event signatures, including faults and\nanomalies with diverse root causes. Additionally, novel metrics and\nvisualizations are introduced to validate the models and evaluate the\nperformance, efficiency, and consistency of latent maps generated by TFT and\nVAE under different configurations. These analyses provide actionable insights\nfor model parameter tuning and reliability improvements. Comparative results\nhighlight that TFT achieves shorter run times and superior scalability to\ndiverse time-series data shapes compared to VAE. This work advances fault\ndiagnosis in multivariate time series, fostering explainable AI to support\ncritical system operations.",
      "tldr_zh": "本研究提出了一种可解释 AI 框架，用于探索多变量时间序列数据的复杂模式，针对高维度和互连性挑战，通过整合 Temporal Fusion Transformer (TFT) 和 Variational Autoencoders (VAEs) 将模式降维到低维潜在空间，并使用 PCA、t-SNE 和 UMAP 与 DBSCAN 进行 2D 可视化，以支持直观交互探索和模式相似性分析。框架在电力网格信号数据案例中成功识别多标签事件签名，如故障和异常，并引入新指标评估模型性能、效率和一致性。比较结果显示，TFT 比 VAE 具有更短运行时间和更好的可扩展性，该工作提升了 AI 的可解释性，为关键系统决策提供可靠支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16098v2",
      "published_date": "2024-12-20 17:41:11 UTC",
      "updated_date": "2024-12-24 05:04:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:43:48.010689"
    },
    {
      "arxiv_id": "2412.16089v1",
      "title": "The Evolution of LLM Adoption in Industry Data Curation Practices",
      "title_zh": "翻译失败",
      "authors": [
        "Crystal Qian",
        "Michael Xieyang Liu",
        "Emily Reif",
        "Grady Simon",
        "Nada Hussein",
        "Nathan Clement",
        "James Wexler",
        "Carrie J. Cai",
        "Michael Terry",
        "Minsuk Kahng"
      ],
      "abstract": "As large language models (LLMs) grow increasingly adept at processing\nunstructured text data, they offer new opportunities to enhance data curation\nworkflows. This paper explores the evolution of LLM adoption among\npractitioners at a large technology company, evaluating the impact of LLMs in\ndata curation tasks through participants' perceptions, integration strategies,\nand reported usage scenarios. Through a series of surveys, interviews, and user\nstudies, we provide a timely snapshot of how organizations are navigating a\npivotal moment in LLM evolution. In Q2 2023, we conducted a survey to assess\nLLM adoption in industry for development tasks (N=84), and facilitated expert\ninterviews to assess evolving data needs (N=10) in Q3 2023. In Q2 2024, we\nexplored practitioners' current and anticipated LLM usage through a user study\ninvolving two LLM-based prototypes (N=12). While each study addressed distinct\nresearch goals, they revealed a broader narrative about evolving LLM usage in\naggregate. We discovered an emerging shift in data understanding from\nheuristic-first, bottom-up approaches to insights-first, top-down workflows\nsupported by LLMs. Furthermore, to respond to a more complex data landscape,\ndata practitioners now supplement traditional subject-expert-created 'golden\ndatasets' with LLM-generated 'silver' datasets and rigorously validated 'super\ngolden' datasets curated by diverse experts. This research sheds light on the\ntransformative role of LLMs in large-scale analysis of unstructured data and\nhighlights opportunities for further tool development.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在行业数据整理实践中的演变，通过调查、访谈和用户研究评估其对工作流的影响。研究包括2023年Q2对开发任务的调查(N=84)和Q3专家访谈(N=10)，以及2024年Q2基于LLM原型的用户研究(N=12)，揭示了数据理解从启发式、底部向上方法向洞察优先、顶部向下工作流的转变。数据从业者开始使用LLM生成的'silver'数据集补充传统的'subject-expert-created' 'golden'数据集，并引入经过严格验证的'super golden'数据集，以应对更复杂的非结构化数据环境。该研究强调了LLMs在大型数据分析中的变革性作用，并为未来工具开发提供了宝贵机遇。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "19 pages, 4 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.16089v1",
      "published_date": "2024-12-20 17:34:16 UTC",
      "updated_date": "2024-12-20 17:34:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:44:01.060461"
    },
    {
      "arxiv_id": "2412.16086v2",
      "title": "Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Hasan Md Tusfiqur Alam",
        "Devansh Srivastav",
        "Md Abdul Kadir",
        "Daniel Sonntag"
      ],
      "abstract": "Deep learning has advanced medical image classification, but interpretability\nchallenges hinder its clinical adoption. This study enhances interpretability\nin Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)\nand a multi-agent Retrieval-Augmented Generation (RAG) system for report\ngeneration. By modeling relationships between visual features and clinical\nconcepts, we create interpretable concept vectors that guide a multi-agent RAG\nsystem to generate radiology reports, enhancing clinical relevance,\nexplainability, and transparency. Evaluation of the generated reports using an\nLLM-as-a-judge confirmed the interpretability and clinical utility of our\nmodel's outputs. On the COVID-QU dataset, our model achieved 81% classification\naccuracy and demonstrated robust report generation performance, with five key\nmetrics ranging between 84% and 90%. This interpretable multi-agent framework\nbridges the gap between high-performance AI and the explainability required for\nreliable AI-driven CXR analysis in clinical settings. Our code is available at\nhttps://github.com/tifat58/IRR-with-CBM-RAG.git.",
      "tldr_zh": "本研究针对深度学习在医学图像分类中的解释性挑战，提出一种结合概念瓶颈模型 (CBMs) 和多智能体检索增强生成系统 (multi-agent RAG) 的框架，用于生成可解释的胸部 X 光 (CXR) 放射学报告。通过建模视觉特征与临床概念的关系，该框架提升了报告的临床相关性、解释性和透明度。在 COVID-QU 数据集上，模型实现了 81% 的分类准确率，报告生成性能在五个关键指标上达到 84% 到 90%，并经 LLM-as-a-judge 评估确认其临床实用性。该方法桥接了高性能 AI 与临床环境中所需的可解释性需求。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted in the 47th European Conference for Information Retrieval\n  (ECIR) 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.16086v2",
      "published_date": "2024-12-20 17:33:50 UTC",
      "updated_date": "2025-01-22 17:18:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:44:13.920904"
    },
    {
      "arxiv_id": "2501.06192v1",
      "title": "A Computational Model of Learning and Memory Using Structurally Dynamic Cellular Automata",
      "title_zh": "翻译失败",
      "authors": [
        "Jeet Singh"
      ],
      "abstract": "In the fields of computation and neuroscience, much is still unknown about\nthe underlying computations that enable key cognitive functions including\nlearning, memory, abstraction and behavior. This paper proposes a mathematical\nand computational model of learning and memory based on a small set of\nbio-plausible functions that include coincidence detection, signal modulation,\nand reward/penalty mechanisms. Our theoretical approach proposes that these\nbasic functions are sufficient to establish and modulate an information space\nover which computation can be carried out, generating signal gradients usable\nfor inference and behavior. The computational method used to test this is a\nstructurally dynamic cellular automaton with continuous-valued cell states and\na series of recursive steps propagating over an undirected graph with the\nmemory function embedded entirely in the creation and modulation of graph\nedges. The experimental results show: that the toy model can make near-optimal\nchoices to re-discover a reward state after a single training run; that it can\navoid complex penalty configurations; that signal modulation and network\nplasticity can generate exploratory behaviors in sparse reward environments;\nthat the model generates context-dependent memory representations; and that it\nexhibits high computational efficiency because of its minimal, single-pass\ntraining requirements combined with flexible and contextual memory\nrepresentation.",
      "tldr_zh": "本论文提出了一种基于生物学可信函数（如coincidence detection、signal modulation 和 reward/penalty mechanisms）的数学和计算模型，用于模拟认知功能中的学习、记忆、抽象和行为。该模型通过建立和调节信息空间来生成信号梯度，支持推理和行为决策，采用structurally dynamic cellular automata作为计算方法，该方法在无向图上递归传播连续值细胞状态，并将记忆功能嵌入图边的创建和调节中。实验结果显示，该模型能在单次训练后近似最优地重新发现奖励状态、避免复杂惩罚配置、生成探索行为和上下文相关的记忆表示，同时表现出高计算效率。",
      "categories": [
        "cs.AI",
        "cs.NE",
        "math.DS",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06192v1",
      "published_date": "2024-12-20 17:26:17 UTC",
      "updated_date": "2024-12-20 17:26:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:44:22.540722"
    },
    {
      "arxiv_id": "2412.16075v1",
      "title": "Formal Mathematical Reasoning: A New Frontier in AI",
      "title_zh": "形式化数学推理：人工智能中的新前沿",
      "authors": [
        "Kaiyu Yang",
        "Gabriel Poesia",
        "Jingxuan He",
        "Wenda Li",
        "Kristin Lauter",
        "Swarat Chaudhuri",
        "Dawn Song"
      ],
      "abstract": "AI for Mathematics (AI4Math) is not only intriguing intellectually but also\ncrucial for AI-driven discovery in science, engineering, and beyond. Extensive\nefforts on AI4Math have mirrored techniques in NLP, in particular, training\nlarge language models on carefully curated math datasets in text form. As a\ncomplementary yet less explored avenue, formal mathematical reasoning is\ngrounded in formal systems such as proof assistants, which can verify the\ncorrectness of reasoning and provide automatic feedback. In this position\npaper, we advocate for formal mathematical reasoning and argue that it is\nindispensable for advancing AI4Math to the next level. In recent years, we have\nseen steady progress in using AI to perform formal reasoning, including core\ntasks such as theorem proving and autoformalization, as well as emerging\napplications such as verifiable generation of code and hardware designs.\nHowever, significant challenges remain to be solved for AI to truly master\nmathematics and achieve broader impact. We summarize existing progress, discuss\nopen challenges, and envision critical milestones to measure future success. At\nthis inflection point for formal mathematical reasoning, we call on the\nresearch community to come together to drive transformative advancements in\nthis field.",
      "tldr_zh": "这篇立场论文（position paper）主张正式数学推理（formal mathematical reasoning）是推进AI for Mathematics (AI4Math) 的关键路径，作为对基于NLP的大型语言模型训练的补充，能够通过证明助手等正式系统验证推理的正确性和提供自动反馈。论文总结了现有进展，包括核心任务如theorem proving和autoformalization，以及新兴应用如可验证的代码和硬件设计生成。作者讨论了AI在掌握数学领域面临的重大挑战，并呼吁研究社区共同努力，设定关键里程碑以实现更广泛的影响。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16075v1",
      "published_date": "2024-12-20 17:19:24 UTC",
      "updated_date": "2024-12-20 17:19:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:44:34.558701"
    },
    {
      "arxiv_id": "2412.16275v1",
      "title": "LEARN: A Unified Framework for Multi-Task Domain Adapt Few-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bharadwaj Ravichandran",
        "Alexander Lynch",
        "Sarah Brockman",
        "Brandon RichardWebster",
        "Dawei Du",
        "Anthony Hoogs",
        "Christopher Funk"
      ],
      "abstract": "Both few-shot learning and domain adaptation sub-fields in Computer Vision\nhave seen significant recent progress in terms of the availability of\nstate-of-the-art algorithms and datasets. Frameworks have been developed for\neach sub-field; however, building a common system or framework that combines\nboth is something that has not been explored. As part of our research, we\npresent the first unified framework that combines domain adaptation for the\nfew-shot learning setting across 3 different tasks - image classification,\nobject detection and video classification. Our framework is highly modular with\nthe capability to support few-shot learning with/without the inclusion of\ndomain adaptation depending on the algorithm. Furthermore, the most important\nconfigurable feature of our framework is the on-the-fly setup for incremental\n$n$-shot tasks with the optional capability to configure the system to scale to\na traditional many-shot task. With more focus on Self-Supervised Learning (SSL)\nfor current few-shot learning approaches, our system also supports multiple SSL\npre-training configurations. To test our framework's capabilities, we provide\nbenchmarks on a wide range of algorithms and datasets across different task and\nproblem settings. The code is open source has been made publicly available\nhere: https://gitlab.kitware.com/darpa_learn/learn",
      "tldr_zh": "该论文提出LEARN框架，这是一个统一的系统，将few-shot learning和domain adaptation相结合，支持图像分类（image classification）、物体检测（object detection）和视频分类（video classification）等三类任务。框架设计高度模块化，可根据需求灵活配置是否包含domain adaptation，并支持增量n-shot任务的即时设置以及扩展到传统many-shot任务，同时集成多种Self-Supervised Learning (SSL)预训练选项。通过在多种算法和数据集上进行基准测试，该框架证明了其有效性，并已开源以便进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16275v1",
      "published_date": "2024-12-20 17:16:15 UTC",
      "updated_date": "2024-12-20 17:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:46:24.311202"
    },
    {
      "arxiv_id": "2412.16050v4",
      "title": "Label-Efficient Data Augmentation with Video Diffusion Models for Guidewire Segmentation in Cardiac Fluoroscopy",
      "title_zh": "翻译失败",
      "authors": [
        "Shaoyan Pan",
        "Yikang Liu",
        "Lin Zhao",
        "Eric Z. Chen",
        "Xiao Chen",
        "Terrence Chen",
        "Shanhui Sun"
      ],
      "abstract": "The accurate segmentation of guidewires in interventional cardiac fluoroscopy\nvideos is crucial for computer-aided navigation tasks. Although deep learning\nmethods have demonstrated high accuracy and robustness in wire segmentation,\nthey require substantial annotated datasets for generalizability, underscoring\nthe need for extensive labeled data to enhance model performance. To address\nthis challenge, we propose the Segmentation-guided Frame-consistency Video\nDiffusion Model (SF-VD) to generate large collections of labeled fluoroscopy\nvideos, augmenting the training data for wire segmentation networks. SF-VD\nleverages videos with limited annotations by independently modeling scene\ndistribution and motion distribution. It first samples the scene distribution\nby generating 2D fluoroscopy images with wires positioned according to a\nspecified input mask, and then samples the motion distribution by progressively\ngenerating subsequent frames, ensuring frame-to-frame coherence through a\nframe-consistency strategy. A segmentation-guided mechanism further refines the\nprocess by adjusting wire contrast, ensuring a diverse range of visibility in\nthe synthesized image. Evaluation on a fluoroscopy dataset confirms the\nsuperior quality of the generated videos and shows significant improvements in\nguidewire segmentation.",
      "tldr_zh": "这篇论文提出了一种标签高效的数据增强方法，使用 Video Diffusion Models 来生成心脏血管造影视频中的导线分割数据，旨在减少对大量标注数据集的依赖。核心方法是 Segmentation-guided Frame-consistency Video Diffusion Model (SF-VD)，它通过独立建模场景分布（生成带有指定掩码的2D图像）和运动分布（确保帧间一致性），并结合分割引导机制调整导线对比度，以产生多样化的高质量视频。实验在荧光透视数据集上验证，该方法显著提升了导线分割网络的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.16050v4",
      "published_date": "2024-12-20 16:52:11 UTC",
      "updated_date": "2025-01-27 21:13:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:45:03.345839"
    },
    {
      "arxiv_id": "2412.16038v3",
      "title": "Intelligent Approaches to Predictive Analytics in Occupational Health and Safety in India",
      "title_zh": "印度职业健康与安全领域的预测分析智能方法",
      "authors": [
        "Ritwik Raj Saxena"
      ],
      "abstract": "Concerns associated with occupational health and safety (OHS) remain critical\nand often under-addressed aspects of workforce management. This is especially\ntrue for high-risk industries such as manufacturing, construction, and mining.\nSuch industries dominate the economy of India which is a developing country\nwith a vast informal sector. Regulatory frameworks have been strengthened over\nthe decades, particularly with regards to bringing the unorganized sector\nwithin the purview of law. Traditional approaches to OHS have largely been\nreactive and rely on post-incident analysis (which is curative) rather than\npreventive intervention. This paper portrays the immense potential of\npredictive analytics in rejuvenating OHS practices in India. Intelligent\npredictive analytics is driven by approaches like machine learning and\nstatistical modeling. Its data-driven nature serves to overcome the limitations\nof conventional OHS methods. Predictive analytics approaches to OHS in India\ndraw on global case studies and generative applications of predictive analytics\nin OHS which are customized to Indian industrial contexts. This paper attempts\nto explore in what ways it exhibits the potential to address challenges such as\nfragmented data ecosystems, resource constraints, and the variability of\nworkplace hazards. The paper presents actionable policy recommendations to\ncreate conditions conducive to the widespread implementation of predictive\nanalytics, which must be advocated as a cornerstone of OHS strategy. In doing\nso, the paper aims to spark a collaborational dialogue among policymakers,\nindustry leaders, and technologists. It urges a shift towards intelligent\npractices to safeguard the well-being of India's workforce.",
      "tldr_zh": "这篇论文探讨了在印度职业健康和安全 (OHS) 领域应用预测分析的智能方法，以应对高风险行业（如制造业、建筑和采矿业）的挑战，并解决传统反应性方法的局限性。论文强调通过机器学习和统计建模等技术进行数据驱动的预防性干预，结合全球案例并定制印度工业情境，以处理数据碎片化、资源限制和工作场所危险变异等问题。最终，它提出可操作的政策推荐，旨在推动预测分析作为OHS策略的核心，促进政策制定者、行业领袖和技术专家的合作对话，以提升劳动力福祉。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16038v3",
      "published_date": "2024-12-20 16:39:06 UTC",
      "updated_date": "2025-01-01 00:35:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:45:15.468166"
    },
    {
      "arxiv_id": "2412.16032v1",
      "title": "A Framework for Streaming Event-Log Prediction in Business Processes",
      "title_zh": "一种用于业务流程中流式事件日志预测的框架",
      "authors": [
        "Benedikt Bollig",
        "Matthias Függer",
        "Thomas Nowak"
      ],
      "abstract": "We present a Python-based framework for event-log prediction in streaming\nmode, enabling predictions while data is being generated by a business process.\nThe framework allows for easy integration of streaming algorithms, including\nlanguage models like n-grams and LSTMs, and for combining these predictors\nusing ensemble methods.\n  Using our framework, we conducted experiments on various well-known\nprocess-mining data sets and compared classical batch with streaming mode.\nThough, in batch mode, LSTMs generally achieve the best performance, there is\noften an n-gram whose accuracy comes very close. Combining basic models in\nensemble methods can even outperform LSTMs. The value of basic models with\nrespect to LSTMs becomes even more apparent in streaming mode, where LSTMs\ngenerally lack accuracy in the early stages of a prediction run, while basic\nmethods make sensible predictions immediately.",
      "tldr_zh": "本文提出一个 Python-based framework，用于在 streaming mode 下实时预测业务流程的事件日志，从而在数据生成过程中进行预测。该框架支持轻松集成流式算法，如 n-grams 和 LSTMs，并通过 ensemble methods 结合这些预测器以提升准确性。在实验中，该框架在多个过程挖掘数据集上进行测试，结果显示批量模式下 LSTMs 表现最佳，但 n-grams 的准确率接近，且使用 ensemble methods 可超越 LSTMs；在 streaming mode 下，基本模型（如 n-grams）在预测早期阶段更具优势，提供即时可靠的预测。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.16032v1",
      "published_date": "2024-12-20 16:29:14 UTC",
      "updated_date": "2024-12-20 16:29:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:45:27.801257"
    },
    {
      "arxiv_id": "2412.16022v1",
      "title": "The Only Way is Ethics: A Guide to Ethical Research with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Eddie L. Ungless",
        "Nikolas Vitsakis",
        "Zeerak Talat",
        "James Garforth",
        "Björn Ross",
        "Arno Onken",
        "Atoosa Kasirzadeh",
        "Alexandra Birch"
      ],
      "abstract": "There is a significant body of work looking at the ethical considerations of\nlarge language models (LLMs): critiquing tools to measure performance and\nharms; proposing toolkits to aid in ideation; discussing the risks to workers;\nconsidering legislation around privacy and security etc. As yet there is no\nwork that integrates these resources into a single practical guide that focuses\non LLMs; we attempt this ambitious goal. We introduce 'LLM Ethics Whitepaper',\nwhich we provide as an open and living resource for NLP practitioners, and\nthose tasked with evaluating the ethical implications of others' work. Our goal\nis to translate ethics literature into concrete recommendations and\nprovocations for thinking with clear first steps, aimed at computer scientists.\n'LLM Ethics Whitepaper' distils a thorough literature review into clear Do's\nand Don'ts, which we present also in this paper. We likewise identify useful\ntoolkits to support ethical work. We refer the interested reader to the full\nLLM Ethics Whitepaper, which provides a succinct discussion of ethical\nconsiderations at each stage in a project lifecycle, as well as citations for\nthe hundreds of papers from which we drew our recommendations. The present\npaper can be thought of as a pocket guide to conducting ethical research with\nLLMs.",
      "tldr_zh": "该论文提供了一个整合性指南，旨在指导大型语言模型（LLMs）的伦理研究，填补了现有资源的碎片化缺口。作者引入了“LLM Ethics Whitepaper”作为开放资源，通过文献综述将伦理文献转化为具体的Do's和Don'ts推荐，以及实用工具包，帮助NLP从业者和评估者处理项目生命周期中的伦理问题。该指南强调清晰的起始步骤和思考点，并引用数百篇论文，为计算机科学家开展伦理研究提供简便的口袋指南。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to COLING '25. This paper is the condensed pocket guide to\n  accompany our full LLM Ethics Whitepaper, available at arXiv:2410.19812, and\n  at https://github.com/MxEddie/Ethics-Whitepaper for suggested revisions",
      "pdf_url": "http://arxiv.org/pdf/2412.16022v1",
      "published_date": "2024-12-20 16:14:43 UTC",
      "updated_date": "2024-12-20 16:14:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:45:38.382516"
    },
    {
      "arxiv_id": "2412.16003v2",
      "title": "Choose Your Explanation: A Comparison of SHAP and GradCAM in Human Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Felix Tempel",
        "Daniel Groos",
        "Espen Alexander F. Ihlen",
        "Lars Adde",
        "Inga Strümke"
      ],
      "abstract": "Explaining machine learning (ML) models using eXplainable AI (XAI) techniques\nhas become essential to make them more transparent and trustworthy. This is\nespecially important in high-stakes domains like healthcare, where\nunderstanding model decisions is critical to ensure ethical, sound, and\ntrustworthy outcome predictions. However, users are often confused about which\nexplanability method to choose for their specific use case. We present a\ncomparative analysis of widely used explainability methods, Shapley Additive\nExplanations (SHAP) and Gradient-weighted Class Activation Mapping (Grad-CAM),\nwithin the domain of human activity recognition (HAR) utilizing graph\nconvolutional networks (GCNs). By evaluating these methods on skeleton-based\ndata from two real-world datasets, including a healthcare-critical cerebral\npalsy (CP) case, this study provides vital insights into both approaches'\nstrengths, limitations, and differences, offering a roadmap for selecting the\nmost appropriate explanation method based on specific models and applications.\nWe quantitatively and quantitatively compare these methods, focusing on feature\nimportance ranking, interpretability, and model sensitivity through\nperturbation experiments. While SHAP provides detailed input feature\nattribution, Grad-CAM delivers faster, spatially oriented explanations, making\nboth methods complementary depending on the application's requirements. Given\nthe importance of XAI in enhancing trust and transparency in ML models,\nparticularly in sensitive environments like healthcare, our research\ndemonstrates how SHAP and Grad-CAM could complement each other to provide more\ninterpretable and actionable model explanations.",
      "tldr_zh": "这篇论文比较了两种可解释 AI (XAI) 方法——SHAP 和 Grad-CAM，在人类活动识别 (HAR) 领域的应用，特别是使用图卷积网络 (GCNs) 处理基于骨骼的数据。研究通过对两个真实数据集（包括一个与脑瘫相关的医疗案例）进行定量和定性评估，分析了这些方法的特征重要性排名、可解释性和模型敏感性。结果表明，SHAP 提供详细的输入特征归因，而 Grad-CAM 则更适合快速的空间导向解释，二者互补，可为高风险领域如医疗提供更可靠的模型解释选择。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16003v2",
      "published_date": "2024-12-20 15:53:25 UTC",
      "updated_date": "2025-04-13 08:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:45:52.015071"
    },
    {
      "arxiv_id": "2412.15998v1",
      "title": "CNN-LSTM Hybrid Deep Learning Model for Remaining Useful Life Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Muthukumar G",
        "Jyosna Philip"
      ],
      "abstract": "Remaining Useful Life (RUL) of a component or a system is defined as the\nlength from the current time to the end of the useful life. Accurate RUL\nestimation plays a crucial role in Predictive Maintenance applications.\nTraditional regression methods, both linear and non-linear, have struggled to\nachieve high accuracy in this domain. While Convolutional Neural Networks\n(CNNs) have shown improved accuracy, they often overlook the sequential nature\nof the data, relying instead on features derived from sliding windows. Since\nRUL prediction inherently involves multivariate time series analysis, robust\nsequence learning is essential. In this work, we propose a hybrid approach\ncombining Convolutional Neural Networks with Long Short-Term Memory (LSTM)\nnetworks for RUL estimation. Although CNN-based LSTM models have been applied\nto sequence prediction tasks in financial forecasting, this is the first\nattempt to adopt this approach for RUL estimation in prognostics. In this\napproach, CNN is first employed to efficiently extract features from the data,\nfollowed by LSTM, which uses these extracted features to predict RUL. This\nmethod effectively leverages sensor sequence information, uncovering hidden\npatterns within the data, even under multiple operating conditions and fault\nscenarios. Our results demonstrate that the hybrid CNN-LSTM model achieves the\nhighest accuracy, offering a superior score compared to the other methods.",
      "tldr_zh": "该论文针对 Remaining Useful Life (RUL) 估计问题，提出了一种结合 Convolutional Neural Networks (CNN) 和 Long Short-Term Memory (LSTM) 的混合深度学习模型，以提升预测性维护的准确性。传统回归方法和单纯的 CNN 模型存在局限性，无法充分处理多变量时间序列数据的顺序特性，而该方法先利用 CNN 提取数据特征，然后由 LSTM 基于这些特征进行 RUL 预测，从而有效捕捉隐藏模式并适应多种操作条件和故障场景。实验结果显示，该混合模型在准确性上优于其他方法，提供更高的性能分数，并首次将 CNN-LSTM 框架应用于 RUL 估计领域。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "conference paper",
      "pdf_url": "http://arxiv.org/pdf/2412.15998v1",
      "published_date": "2024-12-20 15:48:57 UTC",
      "updated_date": "2024-12-20 15:48:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:46:02.710633"
    },
    {
      "arxiv_id": "2412.15995v1",
      "title": "Data-Centric Improvements for Enhancing Multi-Modal Understanding in Spoken Conversation Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Maximillian Chen",
        "Ruoxi Sun",
        "Sercan Ö. Arık"
      ],
      "abstract": "Conversational assistants are increasingly popular across diverse real-world\napplications, highlighting the need for advanced multimodal speech modeling.\nSpeech, as a natural mode of communication, encodes rich user-specific\ncharacteristics such as speaking rate and pitch, making it critical for\neffective interaction. Our work introduces a data-centric customization\napproach for efficiently enhancing multimodal understanding in conversational\nspeech modeling. Central to our contributions is a novel multi-task learning\nparadigm that involves designing auxiliary tasks to utilize a small amount of\nspeech data. Our approach achieves state-of-the-art performance on the\nSpoken-SQuAD benchmark, using only 10% of the training data with open-weight\nmodels, establishing a robust and efficient framework for audio-centric\nconversational modeling. We also introduce ASK-QA, the first dataset for\nmulti-turn spoken dialogue with ambiguous user requests and dynamic evaluation\ninputs. Code and data forthcoming.",
      "tldr_zh": "这篇论文提出了一种数据中心方法，通过多任务学习(multi-task learning)设计辅助任务，利用少量语音数据来提升对话建模中的多模态理解(multi-modal understanding)。该方法在 Spoken-SQuAD 基准上，使用仅 10% 的训练数据和开源模型(open-weight models)，就达到了最先进性能，并为音频中心(conversational modeling)构建了一个鲁棒高效的框架。论文还引入了 ASK-QA 数据集，这是首个处理多轮口语对话(multi-turn spoken dialogue)的资源，专注于模糊用户请求和动态评估输入。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 6 figures, 14 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.15995v1",
      "published_date": "2024-12-20 15:43:09 UTC",
      "updated_date": "2024-12-20 15:43:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:46:15.222869"
    },
    {
      "arxiv_id": "2412.15991v1",
      "title": "APIRL: Deep Reinforcement Learning for REST API Fuzzing",
      "title_zh": "APIRL：深度强化学习用于 REST API 模糊测试",
      "authors": [
        "Myles Foley",
        "Sergio Maffeis"
      ],
      "abstract": "REST APIs have become key components of web services. However, they often\ncontain logic flaws resulting in server side errors or security\nvulnerabilities. HTTP requests are used as test cases to find and mitigate such\nissues. Existing methods to modify requests, including those using deep\nlearning, suffer from limited performance and precision, relying on undirected\nsearch or making limited usage of the contextual information. In this paper we\npropose APIRL, a fully automated deep reinforcement learning tool for testing\nREST APIs. A key novelty of our approach is the use of feedback from a\ntransformer module pre-trained on JSON-structured data, akin to that used in\nAPI responses. This allows APIRL to learn the subtleties relating to test\noutcomes, and generalise to unseen API endpoints. We show APIRL can find\nsignificantly more bugs than the state-of-the-art in real world REST APIs while\nminimising the number of required test cases. We also study how reward\nfunctions, and other key design choices, affect learnt policies in a thorough\nablation study.",
      "tldr_zh": "该论文提出APIRL，一种基于深度强化学习的自动化工具，用于REST API模糊测试，以发现服务器端错误和安全漏洞。APIRL的关键创新在于使用预训练的Transformer模块处理JSON结构数据，提供反馈，帮助模型学习测试结果的细微差别，并推广到未见过的API端点。实验结果显示，APIRL在真实世界REST API上比现有最先进方法发现更多漏洞，同时显著减少测试用例数量；此外，通过消融研究，作者分析了奖励函数和其他设计选择对学习策略的影响。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.SE",
      "comment": "Thirty-ninth Conference on Artificial Intelligence (AAAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.15991v1",
      "published_date": "2024-12-20 15:40:51 UTC",
      "updated_date": "2024-12-20 15:40:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:46:27.058665"
    },
    {
      "arxiv_id": "2412.15983v1",
      "title": "Never Reset Again: A Mathematical Framework for Continual Inference in Recurrent Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Bojian Yin",
        "Federico Corradi"
      ],
      "abstract": "Recurrent Neural Networks (RNNs) are widely used for sequential processing\nbut face fundamental limitations with continual inference due to state\nsaturation, requiring disruptive hidden state resets. However, reset-based\nmethods impose synchronization requirements with input boundaries and increase\ncomputational costs at inference. To address this, we propose an adaptive loss\nfunction that eliminates the need for resets during inference while preserving\nhigh accuracy over extended sequences. By combining cross-entropy and\nKullback-Leibler divergence, the loss dynamically modulates the gradient based\non input informativeness, allowing the network to differentiate meaningful data\nfrom noise and maintain stable representations over time. Experimental results\ndemonstrate that our reset-free approach outperforms traditional reset-based\nmethods when applied to a variety of RNNs, particularly in continual tasks,\nenhancing both the theoretical and practical capabilities of RNNs for streaming\napplications.",
      "tldr_zh": "本研究针对Recurrent Neural Networks (RNNs)在序列处理中的状态饱和问题，提出一个数学框架，消除传统推理过程中需要重置隐藏状态的需求，从而避免同步要求和计算成本增加。方法通过设计一个自适应损失函数，将cross-entropy和Kullback-Leibler divergence结合，根据输入信息性动态调整梯度，帮助网络区分有意义的数据与噪声，并保持长期稳定的表示。实验结果显示，该reset-free方法在各种RNNs上优于传统重置方法，尤其在持续任务中显著提升性能，为RNNs在流式应用中的理论和实际应用提供了重要改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15983v1",
      "published_date": "2024-12-20 15:24:28 UTC",
      "updated_date": "2024-12-20 15:24:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:46:39.882940"
    },
    {
      "arxiv_id": "2412.16270v1",
      "title": "MetaScientist: A Human-AI Synergistic Framework for Automated Mechanical Metamaterial Design",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyuan Qi",
        "Zian Jia",
        "Minqian Liu",
        "Wangzhi Zhan",
        "Junkai Zhang",
        "Xiaofei Wen",
        "Jingru Gan",
        "Jianpeng Chen",
        "Qin Liu",
        "Mingyu Derek Ma",
        "Bangzheng Li",
        "Haohui Wang",
        "Adithya Kulkarni",
        "Muhao Chen",
        "Dawei Zhou",
        "Ling Li",
        "Wei Wang",
        "Lifu Huang"
      ],
      "abstract": "The discovery of novel mechanical metamaterials, whose properties are\ndominated by their engineered structures rather than chemical composition, is a\nknowledge-intensive and resource-demanding process. To accelerate the design of\nnovel metamaterials, we present MetaScientist, a human-in-the-loop system that\nintegrates advanced AI capabilities with expert oversight with two primary\nphases: (1) hypothesis generation, where the system performs complex reasoning\nto generate novel and scientifically sound hypotheses, supported with\ndomain-specific foundation models and inductive biases retrieved from existing\nliterature; (2) 3D structure synthesis, where a 3D structure is synthesized\nwith a novel 3D diffusion model based on the textual hypothesis and refined it\nwith a LLM-based refinement model to achieve better structure properties. At\neach phase, domain experts iteratively validate the system outputs, and provide\nfeedback and supplementary materials to ensure the alignment of the outputs\nwith scientific principles and human preferences. Through extensive evaluation\nfrom human scientists, MetaScientist is able to deliver novel and valid\nmechanical metamaterial designs that have the potential to be highly impactful\nin the metamaterial field.",
      "tldr_zh": "该研究提出 MetaScientist，一种人类-AI 协同框架，用于加速机械 metamaterial 的设计，该框架通过两个主要阶段运作：（1）假设生成，利用领域特定 foundation models 和从文献中检索的 inductive biases 进行复杂推理，生成新颖且科学的假设；（2）3D 结构合成，使用新型 3D diffusion model 基于文本假设创建结构，并通过 LLM-based refinement model 优化以提升性能。人类专家在每个阶段进行迭代验证和反馈，确保输出符合科学原则和人类偏好。通过人类科学家评估，MetaScientist 成功生成新颖、有效的机械 metamaterial 设计，具有在 metamaterial 领域产生重大影响的潜力。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16270v1",
      "published_date": "2024-12-20 15:20:57 UTC",
      "updated_date": "2024-12-20 15:20:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:46:52.291503"
    },
    {
      "arxiv_id": "2412.15967v1",
      "title": "Self-Supervised Radiograph Anatomical Region Classification -- How Clean Is Your Real-World Data?",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Langer",
        "Jessica Ritter",
        "Rickmer Braren",
        "Daniel Rueckert",
        "Paul Hager"
      ],
      "abstract": "Modern deep learning-based clinical imaging workflows rely on accurate labels\nof the examined anatomical region. Knowing the anatomical region is required to\nselect applicable downstream models and to effectively generate cohorts of high\nquality data for future medical and machine learning research efforts. However,\nthis information may not be available in externally sourced data or generally\ncontain data entry errors. To address this problem, we show the effectiveness\nof self-supervised methods such as SimCLR and BYOL as well as supervised\ncontrastive deep learning methods in assigning one of 14 anatomical region\nclasses in our in-house dataset of 48,434 skeletal radiographs. We achieve a\nstrong linear evaluation accuracy of 96.6% with a single model and 97.7% using\nan ensemble approach. Furthermore, only a few labeled instances (1% of the\ntraining set) suffice to achieve an accuracy of 92.2%, enabling usage in\nlow-label and thus low-resource scenarios. Our model can be used to correct\ndata entry mistakes: a follow-up analysis of the test set errors of our\nbest-performing single model by an expert radiologist identified 35% incorrect\nlabels and 11% out-of-domain images. When accounted for, the radiograph\nanatomical region labelling performance increased -- without and with an\nensemble, respectively -- to a theoretical accuracy of 98.0% and 98.8%.",
      "tldr_zh": "这篇论文探讨了使用自监督方法（如 SimCLR 和 BYOL）以及监督对比学习来对放射线照片进行解剖区域分类，旨在解决真实世界数据中标签缺失或错误的挑战。研究在包含48,434张骨骼放射线照片的数据集上实现了96.6%的单模型线性评估准确率，并通过集成方法提升至97.7%；此外，仅需训练集的1%标签即可达到92.2%的准确率，适用于低资源场景。分析显示，模型能识别测试集错误中的35%标签错误和11%域外图像，修正后理论准确率分别提升至98.0%（单模型）和98.8%（集成），为临床数据清洗和机器学习应用提供了高效工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 4 figures, 2 supplementary figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15967v1",
      "published_date": "2024-12-20 15:07:55 UTC",
      "updated_date": "2024-12-20 15:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:47:06.430046"
    },
    {
      "arxiv_id": "2412.15957v1",
      "title": "From General to Specific: Tailoring Large Language Models for Personalized Healthcare",
      "title_zh": "从一般到具体：为个性化医疗保健量身定制大语言模型",
      "authors": [
        "Ruize Shi",
        "Hong Huang",
        "Wei Zhou",
        "Kehan Yin",
        "Kai Zhao",
        "Yun Zhao"
      ],
      "abstract": "The rapid development of large language models (LLMs) has transformed many\nindustries, including healthcare. However, previous medical LLMs have largely\nfocused on leveraging general medical knowledge to provide responses, without\naccounting for patient variability and lacking true personalization at the\nindividual level. To address this, we propose a novel method called\npersonalized medical language model (PMLM), which explores and optimizes\npersonalized LLMs through recommendation systems and reinforcement learning\n(RL). Specifically, by utilizing self-informed and peer-informed\npersonalization, PMLM captures changes in behaviors and preferences to design\ninitial personalized prompts tailored to individual needs. We further refine\nthese initial personalized prompts through RL, ultimately enhancing the\nprecision of LLM guidance. Notably, the personalized prompt are hard prompt,\nwhich grants PMLM high adaptability and reusability, allowing it to directly\nleverage high-quality proprietary LLMs. We evaluate PMLM using real-world\nobstetrics and gynecology data, and the experimental results demonstrate that\nPMLM achieves personalized responses, and it provides more refined and\nindividualized services, offering a potential way for personalized medical\nLLMs.",
      "tldr_zh": "该研究指出，现有的医疗 Large Language Models (LLMs) 过度依赖一般医疗知识，而忽略了患者个体差异和个性化需求。为解决这一问题，研究提出 Personalized Medical Language Model (PMLM) 方法，通过推荐系统和 reinforcement learning (RL) 优化个性化 LLMs。具体而言，PMLM 利用 self-informed 和 peer-informed personalization 来捕捉行为变化并设计初始 hard prompt，并通过 RL 进一步精炼这些提示，以提升响应精确性。在真实妇产科数据上的实验结果显示，PMLM 实现了更个性化的医疗服务，提供更精细的指导，为个性化医疗 LLMs 提供了潜在路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15957v1",
      "published_date": "2024-12-20 14:51:12 UTC",
      "updated_date": "2024-12-20 14:51:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:47:15.153037"
    },
    {
      "arxiv_id": "2412.15948v1",
      "title": "Trust Calibration in IDEs: Paving the Way for Widespread Adoption of AI Refactoring",
      "title_zh": "翻译失败",
      "authors": [
        "Markus Borg"
      ],
      "abstract": "In the software industry, the drive to add new features often overshadows the\nneed to improve existing code. Large Language Models (LLMs) offer a new\napproach to improving codebases at an unprecedented scale through AI-assisted\nrefactoring. However, LLMs come with inherent risks such as braking changes and\nthe introduction of security vulnerabilities. We advocate for encapsulating the\ninteraction with the models in IDEs and validating refactoring attempts using\ntrustworthy safeguards. However, equally important for the uptake of AI\nrefactoring is research on trust development. In this position paper, we\nposition our future work based on established models from research on human\nfactors in automation. We outline action research within CodeScene on\ndevelopment of 1) novel LLM safeguards and 2) user interaction that conveys an\nappropriate level of trust. The industry collaboration enables large-scale\nrepository analysis and A/B testing to continuously guide the design of our\nresearch interventions.",
      "tldr_zh": "该论文讨论了在集成开发环境(IDEs)中进行信任校准，以推动AI Refactoring的广泛采用。作者指出，大型语言模型(LLMs)能大规模辅助代码重构，但面临破坏性变化和安全漏洞等风险，因此主张在IDEs中封装模型交互并使用可靠的保障措施进行验证。基于人类因素在自动化研究中的模型，该论文定位未来工作，包括开发新型LLM保障措施、设计适当的用户交互，以及通过CodeScene的行动研究进行大规模仓库分析和A/B测试，以建立合适的信任水平。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication in the Proc. of the 2nd Workshop on\n  Integrated Development Environments, 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15948v1",
      "published_date": "2024-12-20 14:44:11 UTC",
      "updated_date": "2024-12-20 14:44:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:47:26.732811"
    },
    {
      "arxiv_id": "2412.15939v1",
      "title": "Reframing Image Difference Captioning with BLIP2IDC and Synthetic Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Gautier Evennou",
        "Antoine Chaffin",
        "Vivien Chappelier",
        "Ewa Kijak"
      ],
      "abstract": "The rise of the generative models quality during the past years enabled the\ngeneration of edited variations of images at an important scale. To counter the\nharmful effects of such technology, the Image Difference Captioning (IDC) task\naims to describe the differences between two images. While this task is\nsuccessfully handled for simple 3D rendered images, it struggles on real-world\nimages. The reason is twofold: the training data-scarcity, and the difficulty\nto capture fine-grained differences between complex images. To address those\nissues, we propose in this paper a simple yet effective framework to both adapt\nexisting image captioning models to the IDC task and augment IDC datasets. We\nintroduce BLIP2IDC, an adaptation of BLIP2 to the IDC task at low computational\ncost, and show it outperforms two-streams approaches by a significant margin on\nreal-world IDC datasets. We also propose to use synthetic augmentation to\nimprove the performance of IDC models in an agnostic fashion. We show that our\nsynthetic augmentation strategy provides high quality data, leading to a\nchallenging new dataset well-suited for IDC named Syned1.",
      "tldr_zh": "这篇论文针对图像差异描述(Image Difference Captioning, IDC)任务的挑战，提出了一种框架来适应现有图像描述模型并增强数据集，以应对真实世界图像中数据稀缺和细粒度差异捕捉的难题。作者引入了BLIP2IDC，这是一种低计算成本的BLIP2模型适应版本，显著优于双流方法，在真实世界IDC数据集上表现出色。论文还提出了一种合成增强策略，生成高质量数据，从而创建了一个新的挑战性数据集Syned1，进一步提升IDC模型的泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted for the IEEE/CVF Winter Conference on\n  Applications of Computer Vision (WACV) 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15939v1",
      "published_date": "2024-12-20 14:32:56 UTC",
      "updated_date": "2024-12-20 14:32:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:47:39.845001"
    },
    {
      "arxiv_id": "2412.15924v1",
      "title": "Watertox: The Art of Simplicity in Universal Attacks A Cross-Model Framework for Robust Adversarial Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenghao Gao",
        "Shengjie Xu",
        "Meixi Chen",
        "Fangyao Zhao"
      ],
      "abstract": "Contemporary adversarial attack methods face significant limitations in\ncross-model transferability and practical applicability. We present Watertox,\nan elegant adversarial attack framework achieving remarkable effectiveness\nthrough architectural diversity and precision-controlled perturbations. Our\ntwo-stage Fast Gradient Sign Method combines uniform baseline perturbations\n($\\epsilon_1 = 0.1$) with targeted enhancements ($\\epsilon_2 = 0.4$). The\nframework leverages an ensemble of complementary architectures, from VGG to\nConvNeXt, synthesizing diverse perspectives through an innovative voting\nmechanism. Against state-of-the-art architectures, Watertox reduces model\naccuracy from 70.6% to 16.0%, with zero-shot attacks achieving up to 98.8%\naccuracy reduction against unseen architectures. These results establish\nWatertox as a significant advancement in adversarial methodologies, with\npromising applications in visual security systems and CAPTCHA generation.",
      "tldr_zh": "本文提出 Watertox 框架，这是一种简洁有效的对抗攻击方法，旨在提升跨模型转移性和实用性，通过架构多样性和精确控制的扰动（如两阶段 Fast Gradient Sign Method：均匀基线扰动 ε1 = 0.1 和针对性增强 ε2 = 0.4）实现攻击。框架利用 VGG 到 ConvNeXt 等互补架构的集成，并引入创新投票机制来合成多样视角。实验结果显示，Watertox 对最先进模型将准确率从 70.6% 降低至 16.0%，而 zero-shot attacks 对未见架构可实现高达 98.8% 的准确率降低。该框架为视觉安全系统和 CAPTCHA 生成等应用提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 4 figures, 3 tables. Advances a novel method for generating\n  cross-model transferable adversarial perturbations through a two-stage FGSM\n  process and architectural ensemble voting mechanism",
      "pdf_url": "http://arxiv.org/pdf/2412.15924v1",
      "published_date": "2024-12-20 14:17:03 UTC",
      "updated_date": "2024-12-20 14:17:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:47:52.960560"
    },
    {
      "arxiv_id": "2412.15921v2",
      "title": "Less is More: Towards Green Code Large Language Models via Unified Structural Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Guang Yang",
        "Yu Zhou",
        "Xiangyu Zhang",
        "Wei Cheng",
        "Ke Liu",
        "Xiang Chen",
        "Terry Yue Zhuo",
        "Taolue Chen"
      ],
      "abstract": "The extensive application of Large Language Models (LLMs) in generative\ncoding tasks has raised concerns due to their high computational demands and\nenergy consumption. Unlike previous structural pruning methods designed for\nclassification models that deal with lowdimensional classification logits,\ngenerative Code LLMs produce high-dimensional token logit sequences, making\ntraditional pruning objectives inherently limited. Moreover, existing single\ncomponent pruning approaches further constrain the effectiveness when applied\nto generative Code LLMs. In response, we propose Flab-Pruner, an innovative\nunified structural pruning method that combines vocabulary, layer, and\nFeed-Forward Network (FFN) pruning. This approach effectively reduces model\nparameters while maintaining performance. Additionally, we introduce a\ncustomized code instruction data strategy for coding tasks to enhance the\nperformance recovery efficiency of the pruned model. Through extensive\nevaluations on three state-of-the-art Code LLMs across multiple generative\ncoding tasks, the results demonstrate that Flab-Pruner retains 97% of the\noriginal performance after pruning 22% of the parameters and achieves the same\nor even better performance after post-training. The pruned models exhibit\nsignificant improvements in storage, GPU usage, computational efficiency, and\nenvironmental impact, while maintaining well robustness. Our research provides\na sustainable solution for green software engineering and promotes the\nefficient deployment of LLMs in real-world generative coding intelligence\napplications.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 在代码生成任务中的高计算需求和能耗问题，提出了一种统一的结构修剪方法 Flab-Pruner，该方法结合 vocabulary pruning、layer pruning 和 Feed-Forward Network (FFN) pruning，以有效减少模型参数同时保持性能。此外，引入定制的代码指令数据策略来提升修剪后模型的性能恢复效率。实验结果显示，在三个 state-of-the-art Code LLMs 上，修剪 22% 参数后保留 97% 性能，并在存储、GPU 使用、计算效率和环境影响方面显著改善，从而为绿色软件工程提供可持续解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "UNDER REVIEW",
      "pdf_url": "http://arxiv.org/pdf/2412.15921v2",
      "published_date": "2024-12-20 14:13:09 UTC",
      "updated_date": "2025-04-23 23:24:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:48:04.792039"
    },
    {
      "arxiv_id": "2412.15908v2",
      "title": "Speedup Techniques for Switchable Temporal Plan Graph Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "He Jiang",
        "Muhan Lin",
        "Jiaoyang Li"
      ],
      "abstract": "Multi-Agent Path Finding (MAPF) focuses on planning collision-free paths for\nmultiple agents. However, during the execution of a MAPF plan, agents may\nencounter unexpected delays, which can lead to inefficiencies, deadlocks, or\neven collisions. To address these issues, the Switchable Temporal Plan Graph\nprovides a framework for finding an acyclic Temporal Plan Graph with the\nminimum execution cost under delays, ensuring deadlock- and collision-free\nexecution. Unfortunately, existing optimal algorithms, such as Mixed Integer\nLinear Programming and Graph-Based Switchable Edge Search (GSES), are often too\nslow for practical use. This paper introduces Improved GSES, which\nsignificantly accelerates GSES through four speedup techniques: stronger\nadmissible heuristics, edge grouping, prioritized branching, and incremental\nimplementation. Experiments conducted on four different map types with varying\nnumbers of agents demonstrate that Improved GSES consistently achieves over\ntwice the success rate of GSES and delivers up to a 30-fold speedup on\ninstances where both methods successfully find solutions.",
      "tldr_zh": "本论文针对 Multi-Agent Path Finding (MAPF) 中代理执行计划时可能遇到的延迟问题（如效率低下、死锁或碰撞），提出了对 Switchable Temporal Plan Graph 优化的加速技术。作者开发了 Improved GSES 算法，通过四个关键改进——stronger admissible heuristics、edge grouping、prioritized branching 和 incremental implementation——显著提升了原有 GSES 算法的速度和效率。实验在四种不同地图类型和不同代理数量的场景下显示，Improved GSES 的成功率比 GSES 高出两倍以上，并在成功求解的实例中实现高达 30 倍的加速，从而为实际 MAPF 应用提供了更可靠的解决方案。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted by AAAI 2025. This version contains the appendix",
      "pdf_url": "http://arxiv.org/pdf/2412.15908v2",
      "published_date": "2024-12-20 13:59:15 UTC",
      "updated_date": "2025-01-12 01:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:48:15.647701"
    },
    {
      "arxiv_id": "2412.15907v1",
      "title": "Development of a Large-scale Dataset of Chest Computed Tomography Reports in Japanese and a High-performance Finding Classification Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yosuke Yamagishi",
        "Yuta Nakamura",
        "Tomohiro Kikuchi",
        "Yuki Sonoda",
        "Hiroshi Hirakawa",
        "Shintaro Kano",
        "Satoshi Nakamura",
        "Shouhei Hanaoka",
        "Takeharu Yoshikawa",
        "Osamu Abe"
      ],
      "abstract": "Background: Recent advances in large language models highlight the need for\nhigh-quality multilingual medical datasets. While Japan leads globally in CT\nscanner deployment and utilization, the lack of large-scale Japanese radiology\ndatasets has hindered the development of specialized language models for\nmedical imaging analysis. Objective: To develop a comprehensive Japanese CT\nreport dataset through machine translation and establish a specialized language\nmodel for structured finding classification. Additionally, to create a\nrigorously validated evaluation dataset through expert radiologist review.\nMethods: We translated the CT-RATE dataset (24,283 CT reports from 21,304\npatients) into Japanese using GPT-4o mini. The training dataset consisted of\n22,778 machine-translated reports, while the validation dataset included 150\nradiologist-revised reports. We developed CT-BERT-JPN based on\n\"tohoku-nlp/bert-base-japanese-v3\" architecture for extracting 18 structured\nfindings from Japanese radiology reports. Results: Translation metrics showed\nstrong performance with BLEU scores of 0.731 and 0.690, and ROUGE scores\nranging from 0.770 to 0.876 for Findings and from 0.748 to 0.857 for Impression\nsections. CT-BERT-JPN demonstrated superior performance compared to GPT-4o in\n11 out of 18 conditions, including lymphadenopathy (+14.2%), interlobular\nseptal thickening (+10.9%), and atelectasis (+7.4%). The model maintained F1\nscores exceeding 0.95 in 14 out of 18 conditions and achieved perfect scores in\nfour conditions. Conclusions: Our study establishes a robust Japanese CT report\ndataset and demonstrates the effectiveness of a specialized language model for\nstructured finding classification. The hybrid approach of machine translation\nand expert validation enables the creation of large-scale medical datasets\nwhile maintaining high quality.",
      "tldr_zh": "本研究针对日语放射学数据集的缺失，开发了一个大规模胸部 CT 报告数据集，并构建了一个高性能的发现分类模型 CT-BERT-JPN。研究方法包括使用 GPT-4o mini 将 CT-RATE 数据集（24,283 份报告）翻译成日语，并通过专家放射科医生审查创建验证数据集（150 份修订报告）。结果显示，翻译指标表现出色，BLEU 分数达 0.731 和 0.690，ROUGE 分数在 0.748-0.876 之间；CT-BERT-JPN 在 18 个结构化发现中优于 GPT-4o 的 11 个条件，如 lymphadenopathy (+14.2%) 和 atelectasis (+7.4%)，并在 14 个条件中 F1 分数超过 0.95。该方法证明了机器翻译结合专家验证的有效性，为高质量多语言医疗数据集的发展提供了坚实基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Dataset available at\n  https://huggingface.co/datasets/YYama0/CT-RATE-JPN",
      "pdf_url": "http://arxiv.org/pdf/2412.15907v1",
      "published_date": "2024-12-20 13:59:11 UTC",
      "updated_date": "2024-12-20 13:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:48:30.078555"
    },
    {
      "arxiv_id": "2412.15904v3",
      "title": "What Are Step-Level Reward Models Rewarding? Counterintuitive Findings from MCTS-Boosted Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yiran Ma",
        "Zui Chen",
        "Tianqiao Liu",
        "Mi Tian",
        "Zhuo Liu",
        "Zitao Liu",
        "Weiqi Luo"
      ],
      "abstract": "Step-level reward models (SRMs) can significantly enhance mathematical\nreasoning performance through process supervision or step-level preference\nalignment based on reinforcement learning. The performance of SRMs is pivotal,\nas they serve as critical guidelines, ensuring that each step in the reasoning\nprocess is aligned with desired outcomes. Recently, AlphaZero-like methods,\nwhere Monte Carlo Tree Search (MCTS) is employed for automatic step-level\npreference annotation, have proven particularly effective. However, the precise\nmechanisms behind the success of SRMs remain largely unexplored. To address\nthis gap, this study delves into the counterintuitive aspects of SRMs,\nparticularly focusing on MCTS-based approaches. Our findings reveal that the\nremoval of natural language descriptions of thought processes has minimal\nimpact on the efficacy of SRMs. Furthermore, we demonstrate that SRMs are adept\nat assessing the complex logical coherence present in mathematical language\nwhile having difficulty in natural language. These insights provide a nuanced\nunderstanding of the core elements that drive effective step-level reward\nmodeling in mathematical reasoning. By shedding light on these mechanisms, this\nstudy offers valuable guidance for developing more efficient and streamlined\nSRMs, which can be achieved by focusing on the crucial parts of mathematical\nreasoning.",
      "tldr_zh": "本研究探讨了Step-level reward models (SRMs) 在数学推理中的作用，特别是通过Monte Carlo Tree Search (MCTS)增强的方法。研究发现，移除自然语言描述对SRMs的效能影响甚微，而SRMs更擅长评估数学语言的复杂逻辑连贯性，却在处理自然语言方面表现欠佳。这些反直觉的发现为开发更高效、精简的SRMs提供了宝贵指导，帮助优化数学推理过程。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15904v3",
      "published_date": "2024-12-20 13:56:23 UTC",
      "updated_date": "2025-03-08 05:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:48:38.886227"
    },
    {
      "arxiv_id": "2412.15902v1",
      "title": "On the Suitability of pre-trained foundational LLMs for Analysis in German Legal Education",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenz Wendlinger",
        "Christian Braun",
        "Abdullah Al Zubaer",
        "Simon Alexander Nonn",
        "Sarah Großkopf",
        "Christofer Fellicious",
        "Michael Granitzer"
      ],
      "abstract": "We show that current open-source foundational LLMs possess instruction\ncapability and German legal background knowledge that is sufficient for some\nlegal analysis in an educational context. However, model capability breaks down\nin very specific tasks, such as the classification of \"Gutachtenstil\" appraisal\nstyle components, or with complex contexts, such as complete legal opinions.\nEven with extended context and effective prompting strategies, they cannot\nmatch the Bag-of-Words baseline. To combat this, we introduce a Retrieval\nAugmented Generation based prompt example selection method that substantially\nimproves predictions in high data availability scenarios. We further evaluate\nthe performance of pre-trained LLMs on two standard tasks for argument mining\nand automated essay scoring and find it to be more adequate. Throughout,\npre-trained LLMs improve upon the baseline in scenarios with little or no\nlabeled data with Chain-of-Thought prompting further helping in the zero-shot\ncase.",
      "tldr_zh": "这篇论文评估了预训练基础LLMs在德语法律教育中的适用性，发现这些模型在某些法律分析任务中具备足够的指令能力和背景知识，但在大语言模型在特定任务（如\"Gutachtenstil\"评估风格组件分类）或复杂上下文（如完整法律意见）中表现不足，甚至不如Bag-of-Words基线。作者引入了基于Retrieval Augmented Generation (RAG)的提示示例选择方法，在高数据可用性场景中显著提升了预测性能。在参数挖掘和自动论文评分等标准任务上，LLMs的表现更佳，尤其在数据有限或零样本场景中，Chain-of-Thought提示进一步改善了结果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.15902v1",
      "published_date": "2024-12-20 13:54:57 UTC",
      "updated_date": "2024-12-20 13:54:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:48:52.363211"
    },
    {
      "arxiv_id": "2412.15891v1",
      "title": "TelcoLM: collecting data, adapting, and benchmarking language models for the telecommunication domain",
      "title_zh": "翻译失败",
      "authors": [
        "Camille Barboule",
        "Viet-Phi Huynh",
        "Adrien Bufort",
        "Yoan Chabot",
        "Géraldine Damnati",
        "Gwénolé Lecorvé"
      ],
      "abstract": "Despite outstanding processes in many tasks, Large Language Models (LLMs)\nstill lack accuracy when dealing with highly technical domains. Especially,\ntelecommunications (telco) is a particularly challenging domain due the large\namount of lexical, semantic and conceptual peculiarities. Yet, this domain\nholds many valuable use cases, directly linked to industrial needs. Hence, this\npaper studies how LLMs can be adapted to the telco domain. It reports our\neffort to (i) collect a massive corpus of domain-specific data (800M tokens,\n80K instructions), (ii) perform adaptation using various methodologies, and\n(iii) benchmark them against larger generalist models in downstream tasks that\nrequire extensive knowledge of telecommunications. Our experiments on\nLlama-2-7b show that domain-adapted models can challenge the large generalist\nmodels. They also suggest that adaptation can be restricted to a unique\ninstruction-tuning step, dicarding the need for any fine-tuning on raw texts\nbeforehand.",
      "tldr_zh": "这篇论文介绍了 TelcoLM 项目，旨在将大型语言模型 (LLMs) 适应到电信领域，以解决其在处理词汇、语义和概念特殊性的准确性问题。研究团队收集了大量领域特定数据，包括 800M tokens 和 80K instructions，并通过各种适应方法（如指令微调）对模型进行优化，而无需先对原始文本进行微调。实验结果显示，在 Llama-2-7b 等模型上，领域适配版本能与大型通用模型在电信知识密集型任务中竞争，证明了这种高效适配方法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages (main: 13 pages, appendices: 17 pages), 1 figure, 22 tables,\n  achieved March 2024, released December 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.15891v1",
      "published_date": "2024-12-20 13:47:02 UTC",
      "updated_date": "2024-12-20 13:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:49:03.492259"
    },
    {
      "arxiv_id": "2412.15877v1",
      "title": "Approximate State Abstraction for Markov Games",
      "title_zh": "马尔可夫博弈的近似状态抽象",
      "authors": [
        "Hiroki Ishibashi",
        "Kenshi Abe",
        "Atsushi Iwasaki"
      ],
      "abstract": "This paper introduces state abstraction for two-player zero-sum Markov games\n(TZMGs), where the payoffs for the two players are determined by the state\nrepresenting the environment and their respective actions, with state\ntransitions following Markov decision processes. For example, in games like\nsoccer, the value of actions changes according to the state of play, and thus\nsuch games should be described as Markov games. In TZMGs, as the number of\nstates increases, computing equilibria becomes more difficult. Therefore, we\nconsider state abstraction, which reduces the number of states by treating\nmultiple different states as a single state. There is a substantial body of\nresearch on finding optimal policies for Markov decision processes using state\nabstraction. However, in the multi-player setting, the game with state\nabstraction may yield different equilibrium solutions from those of the ground\ngame. To evaluate the equilibrium solutions of the game with state abstraction,\nwe derived bounds on the duality gap, which represents the distance from the\nequilibrium solutions of the ground game. Finally, we demonstrate our state\nabstraction with Markov Soccer, compute equilibrium policies, and examine the\nresults.",
      "tldr_zh": "这篇论文针对两玩家零和Markov游戏（TZMGs）引入了状态抽象方法，以减少状态数量并简化均衡计算问题，例如在足球类游戏中状态变化影响行动价值。论文推导了二元性间隙（duality gap）的界限，用于评估抽象后游戏的均衡解与原游戏的距离，确保抽象的准确性。与Markov决策过程相关研究不同，该方法适应多玩家场景，并通过实验在Markov Soccer游戏中计算了均衡策略，展示了其有效性。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15877v1",
      "published_date": "2024-12-20 13:28:41 UTC",
      "updated_date": "2024-12-20 13:28:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:49:23.924007"
    },
    {
      "arxiv_id": "2412.15876v1",
      "title": "AI-in-the-loop: The future of biomedical visual analytics applications in the era of AI",
      "title_zh": "翻译失败",
      "authors": [
        "Katja Bühler",
        "Thomas Höllt",
        "Thomas Schulz",
        "Pere-Pau Vázquez"
      ],
      "abstract": "AI is the workhorse of modern data analytics and omnipresent across many\nsectors. Large Language Models and multi-modal foundation models are today\ncapable of generating code, charts, visualizations, etc. How will these massive\ndevelopments of AI in data analytics shape future data visualizations and\nvisual analytics workflows? What is the potential of AI to reshape methodology\nand design of future visual analytics applications? What will be our role as\nvisualization researchers in the future? What are opportunities, open\nchallenges and threats in the context of an increasingly powerful AI? This\nVisualization Viewpoint discusses these questions in the special context of\nbiomedical data analytics as an example of a domain in which critical decisions\nare taken based on complex and sensitive data, with high requirements on\ntransparency, efficiency, and reliability. We map recent trends and\ndevelopments in AI on the elements of interactive visualization and visual\nanalytics workflows and highlight the potential of AI to transform biomedical\nvisualization as a research field. Given that agency and responsibility have to\nremain with human experts, we argue that it is helpful to keep the focus on\nhuman-centered workflows, and to use visual analytics as a tool for integrating\n``AI-in-the-loop''. This is in contrast to the more traditional term\n``human-in-the-loop'', which focuses on incorporating human expertise into\nAI-based systems.",
      "tldr_zh": "这篇论文探讨了 AI 在生物医学数据分析中的未来作用，特别是 Large Language Models 和多模态基础模型如何改变数据可视化和视觉分析工作流。作者分析了 AI 重塑方法和设计的潜力，包括机会、开放挑战和威胁，并强调在处理复杂敏感数据的领域（如生物医学），透明性、效率和可靠性至关重要。通过映射 AI 趋势到交互式可视化元素，论文突出 AI 转变该领域的潜力，并主张采用人类中心的方法，将 AI-in-the-loop 整合到工作流中，以确保人类专家保持主导责任。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.GR",
        "68U01",
        "H.1.2; H.5.2; I.3.6; I.2.1; J.3; D.2.0"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for publication in IEEE Computer Graphics & Applications",
      "pdf_url": "http://arxiv.org/pdf/2412.15876v1",
      "published_date": "2024-12-20 13:27:24 UTC",
      "updated_date": "2024-12-20 13:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:49:27.500018"
    },
    {
      "arxiv_id": "2502.02593v1",
      "title": "Reconstructing 3D Flow from 2D Data with Diffusion Transformer",
      "title_zh": "基于 Diffusion Transformer 从 2D 数据重建 3D 流动",
      "authors": [
        "Fan Lei"
      ],
      "abstract": "Fluid flow is a widely applied physical problem, crucial in various fields.\nDue to the highly nonlinear and chaotic nature of fluids, analyzing\nfluid-related problems is exceptionally challenging. Computational fluid\ndynamics (CFD) is the best tool for this analysis but involves significant\ncomputational resources, especially for 3D simulations, which are slow and\nresource-intensive. In experimental fluid dynamics, PIV cost increases with\ndimensionality. Reconstructing 3D flow fields from 2D PIV data could reduce\ncosts and expand application scenarios. Here, We propose a Diffusion\nTransformer-based method for reconstructing 3D flow fields from 2D flow data.\nBy embedding the positional information of 2D planes into the model, we enable\nthe reconstruction of 3D flow fields from any combination of 2D slices,\nenhancing flexibility. We replace global attention with window and plane\nattention to reduce computational costs associated with higher dimensions\nwithout compromising performance. Our experiments demonstrate that our model\ncan efficiently and accurately reconstruct 3D flow fields from 2D data,\nproducing realistic results.",
      "tldr_zh": "该论文针对流体动力学中的高计算成本问题，提出了一种基于 Diffusion Transformer 的方法，用于从 2D 流数据重建 3D 流场，从而降低 Computational fluid dynamics (CFD) 和 PIV 的资源需求。该方法通过嵌入 2D 平面的位置信息，允许从任意组合的 2D 切片灵活生成 3D 流场，并采用 window and plane attention 替换全局注意力，以减少计算开销而不影响性能。实验结果显示，该模型能高效、准确地重建真实的三维流场，扩展了流体分析的应用场景。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.02593v1",
      "published_date": "2024-12-20 13:19:48 UTC",
      "updated_date": "2024-12-20 13:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:49:39.494822"
    },
    {
      "arxiv_id": "2412.17859v1",
      "title": "The Unreasonable Effectiveness of Open Science in AI: A Replication Study",
      "title_zh": "开放科学在 AI 中的不合理有效性：一个再现性研究",
      "authors": [
        "Odd Erik Gundersen",
        "Odd Cappelen",
        "Martin Mølnå",
        "Nicklas Grimstad Nilsen"
      ],
      "abstract": "A reproducibility crisis has been reported in science, but the extent to\nwhich it affects AI research is not yet fully understood. Therefore, we\nperformed a systematic replication study including 30 highly cited AI studies\nrelying on original materials when available. In the end, eight articles were\nrejected because they required access to data or hardware that was practically\nimpossible to acquire as part of the project. Six articles were successfully\nreproduced, while five were partially reproduced. In total, 50% of the articles\nincluded was reproduced to some extent. The availability of code and data\ncorrelate strongly with reproducibility, as 86% of articles that shared code\nand data were fully or partly reproduced, while this was true for 33% of\narticles that shared only data. The quality of the data documentation\ncorrelates with successful replication. Poorly documented or miss-specified\ndata will probably result in unsuccessful replication. Surprisingly, the\nquality of the code documentation does not correlate with successful\nreplication. Whether the code is poorly documented, partially missing, or not\nversioned is not important for successful replication, as long as the code is\nshared. This study emphasizes the effectiveness of open science and the\nimportance of properly documenting data work.",
      "tldr_zh": "这篇论文通过一个系统性的复制研究(Replication Study)，评估了30个高引AI研究的可复制性，结果显示50%的文章被完全或部分复制，而八个文章因数据或硬件获取困难而被拒绝。研究发现，代码和数据的共享与可复制性高度相关：86%的共享代码和数据的文章成功复制或部分复制，相比之下，只共享数据的文章仅为33%。此外，数据文档(Data Documentation)质量对复制成功至关重要，而代码文档质量则影响不大，只要代码共享即可。该研究突出了Open Science在AI领域的非凡有效性，并强调了正确文档数据工作的重要性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17859v1",
      "published_date": "2024-12-20 12:33:27 UTC",
      "updated_date": "2024-12-20 12:33:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:49:51.533717"
    },
    {
      "arxiv_id": "2412.15838v2",
      "title": "Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaming Ji",
        "Jiayi Zhou",
        "Hantao Lou",
        "Boyuan Chen",
        "Donghai Hong",
        "Xuyao Wang",
        "Wenqi Chen",
        "Kaile Wang",
        "Rui Pan",
        "Jiahao Li",
        "Mohan Wang",
        "Josef Dai",
        "Tianyi Qiu",
        "Hua Xu",
        "Dong Li",
        "Weipeng Chen",
        "Jun Song",
        "Bo Zheng",
        "Yaodong Yang"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) has proven effective in\nenhancing the instruction-following capabilities of large language models;\nhowever, it remains underexplored in the cross-modality domain. As the number\nof modalities increases, aligning all-modality models with human intentions --\nsuch as instruction following -- becomes a pressing challenge. In this work, we\nmake the first attempt to fine-tune all-modality models (i.e. input and output\nwith any modality, also named any-to-any models) using human preference data\nacross all modalities (including text, image, audio, and video), ensuring its\nbehavior aligns with human intentions. This endeavor presents several\nchallenges. First, there is no large-scale all-modality human preference data\nin existing open-source resources, as most datasets are limited to specific\nmodalities, predominantly text and image. Secondly, the effectiveness of binary\npreferences in RLHF for post-training alignment in complex all-modality\nscenarios remains an unexplored area. Finally, there is a lack of a systematic\nframework to evaluate the capabilities of all-modality models, particularly\nregarding modality selection and synergy. To address these challenges, we\npropose the align-anything framework, which includes meticulously annotated\n200k all-modality human preference data. Then, we introduce an alignment method\nthat learns from unified language feedback, effectively capturing complex\nmodality-specific human preferences and enhancing the model's\ninstruction-following capabilities. Furthermore, to assess performance\nimprovements in all-modality models after post-training alignment, we construct\na challenging all-modality capability evaluation framework -- eval-anything.\nAll data, models, and code frameworks have been open-sourced for the community.\nFor more details, please refer to\nhttps://github.com/PKU-Alignment/align-anything.",
      "tldr_zh": "该研究首次探索使用强化学习从人类反馈（RLHF）来微调全模态模型（包括文本、图像、音频和视频），以提升其指令遵循能力并更好地对齐人类意图。论文提出align-anything框架，包括20万条多模态人类偏好数据，以及一种从统一语言反馈中学习的对齐方法，帮助模型捕捉复杂的模态特定偏好。实验通过eval-anything评估框架验证了性能改进，所有数据、模型和代码已开源，为多模态模型的开发提供了宝贵资源。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15838v2",
      "published_date": "2024-12-20 12:27:16 UTC",
      "updated_date": "2024-12-30 07:27:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:50:03.128044"
    },
    {
      "arxiv_id": "2412.15837v1",
      "title": "Traffic-Rule-Compliant Trajectory Repair via Satisfiability Modulo Theories and Reachability Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanfei Lin",
        "Zekun Xing",
        "Xuyuan Han",
        "Matthias Althoff"
      ],
      "abstract": "Complying with traffic rules is challenging for automated vehicles, as\nnumerous rules need to be considered simultaneously. If a planned trajectory\nviolates traffic rules, it is common to replan a new trajectory from scratch.\nWe instead propose a trajectory repair technique to save computation time. By\ncoupling satisfiability modulo theories with set-based reachability analysis,\nwe determine if and in what manner the initial trajectory can be repaired.\nExperiments in high-fidelity simulators and in the real world demonstrate the\nbenefits of our proposed approach in various scenarios. Even in complex\nenvironments with intricate rules, we efficiently and reliably repair\nrule-violating trajectories, enabling automated vehicles to swiftly resume\nlegally safe operation in real-time.",
      "tldr_zh": "本文提出了一种基于 Satisfiability Modulo Theories (SMT) 和 Reachability Analysis 的轨迹修复技术，旨在帮助自动车辆高效遵守交通规则，而非从头重新规划轨迹。该方法通过分析初始轨迹的可修复性，快速确定并调整违规部分，从而节省计算时间。在高保真模拟器和现实世界实验中，该技术在各种复杂场景下表现出色，实现了实时可靠的合法安全操作。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "2024 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
      "pdf_url": "http://arxiv.org/pdf/2412.15837v1",
      "published_date": "2024-12-20 12:26:22 UTC",
      "updated_date": "2024-12-20 12:26:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:50:15.454021"
    },
    {
      "arxiv_id": "2412.15822v1",
      "title": "S$^2$DN: Learning to Denoise Unconvincing Knowledge for Inductive Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Tengfei Ma",
        "Yujie Chen",
        "Liang Wang",
        "Xuan Lin",
        "Bosheng Song",
        "Xiangxiang Zeng"
      ],
      "abstract": "Inductive Knowledge Graph Completion (KGC) aims to infer missing facts\nbetween newly emerged entities within knowledge graphs (KGs), posing a\nsignificant challenge. While recent studies have shown promising results in\ninferring such entities through knowledge subgraph reasoning, they suffer from\n(i) the semantic inconsistencies of similar relations, and (ii) noisy\ninteractions inherent in KGs due to the presence of unconvincing knowledge for\nemerging entities. To address these challenges, we propose a Semantic\nStructure-aware Denoising Network (S$^2$DN) for inductive KGC. Our goal is to\nlearn adaptable general semantics and reliable structures to distill consistent\nsemantic knowledge while preserving reliable interactions within KGs.\nSpecifically, we introduce a semantic smoothing module over the enclosing\nsubgraphs to retain the universal semantic knowledge of relations. We\nincorporate a structure refining module to filter out unreliable interactions\nand offer additional knowledge, retaining robust structure surrounding target\nlinks. Extensive experiments conducted on three benchmark KGs demonstrate that\nS$^2$DN surpasses the performance of state-of-the-art models. These results\ndemonstrate the effectiveness of S$^2$DN in preserving semantic consistency and\nenhancing the robustness of filtering out unreliable interactions in\ncontaminated KGs.",
      "tldr_zh": "该论文针对 Inductive Knowledge Graph Completion (KGC) 的挑战，提出了一种 Semantic Structure-aware Denoising Network (S$^2$DN)，旨在解决相似关系的语义不一致和知识图谱 (KGs) 中的噪音互动问题。S$^2$DN 包括语义平滑模块，用于保留关系的通用语义知识，以及结构精炼模块，用于过滤不可靠互动并强化目标链接的稳健结构。通过在三个基准 KGs 上的广泛实验，S$^2$DN 超过了最先进模型的表现，证明了其在保持语义一致性和提升鲁棒性方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.15822v1",
      "published_date": "2024-12-20 12:03:33 UTC",
      "updated_date": "2024-12-20 12:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:50:27.734626"
    },
    {
      "arxiv_id": "2412.15821v1",
      "title": "$π$-yalli: un nouveau corpus pour le nahuatl",
      "title_zh": "翻译失败",
      "authors": [
        "Juan-Manuel Torres-Moreno",
        "Juan-José Guzmán-Landa",
        "Graham Ranger",
        "Martha Lorena Avendaño Garrido",
        "Miguel Figueroa-Saavedra",
        "Ligia Quintana-Torres",
        "Carlos-Emiliano González-Gallardo",
        "Elvys Linhares Pontes",
        "Patricia Velázquez Morales",
        "Luis-Gil Moreno Jiménez"
      ],
      "abstract": "The NAHU$^2$ project is a Franco-Mexican collaboration aimed at building the\n$\\pi$-YALLI corpus adapted to machine learning, which will subsequently be used\nto develop computer resources for the Nahuatl language. Nahuatl is a language\nwith few computational resources, even though it is a living language spoken by\naround 2 million people. We have decided to build $\\pi$-YALLI, a corpus that\nwill enable to carry out research on Nahuatl in order to develop Language\nModels (LM), whether dynamic or not, which will make it possible to in turn\nenable the development of Natural Language Processing (NLP) tools such as: a) a\ngrapheme unifier, b) a word segmenter, c) a POS grammatical analyser, d) a\ncontent-based Automatic Text Summarization; and possibly, e) a translator\ntranslator (probabilistic or learning-based).",
      "tldr_zh": "本研究介绍了 NAHU² 项目，这是一个法墨合作计划，旨在构建 π-YALLI 语料库，以适应机器学习并为 Nahuatl 语言提供计算资源；Nahuatl 是一种低资源语言，由约200万人口使用。π-YALLI 语料库将用于开发 Language Models (LM)，包括动态和静态模型，从而支持 Natural Language Processing (NLP) 工具的创建，如 grapheme unifier（字形统一器）、word segmenter（词分词器）、POS grammatical analyser（词性分析器）和 content-based Automatic Text Summarization（基于内容的自动文本摘要）。此外，该语料库可能进一步推动 translator（翻译器）等工具的开发，助力 Nahuatl 语言的数字化保护和应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, in French language, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15821v1",
      "published_date": "2024-12-20 12:03:10 UTC",
      "updated_date": "2024-12-20 12:03:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:50:40.508987"
    },
    {
      "arxiv_id": "2412.15803v1",
      "title": "WebLLM: A High-Performance In-Browser LLM Inference Engine",
      "title_zh": "翻译失败",
      "authors": [
        "Charlie F. Ruan",
        "Yucheng Qin",
        "Xun Zhou",
        "Ruihang Lai",
        "Hongyi Jin",
        "Yixin Dong",
        "Bohan Hou",
        "Meng-Shiun Yu",
        "Yiyan Zhai",
        "Sudeep Agarwal",
        "Hangrui Cao",
        "Siyuan Feng",
        "Tianqi Chen"
      ],
      "abstract": "Advancements in large language models (LLMs) have unlocked remarkable\ncapabilities. While deploying these models typically requires server-grade GPUs\nand cloud-based inference, the recent emergence of smaller open-source models\nand increasingly powerful consumer devices have made on-device deployment\npractical. The web browser as a platform for on-device deployment is\nuniversally accessible, provides a natural agentic environment, and\nconveniently abstracts out the different backends from diverse device vendors.\nTo address this opportunity, we introduce WebLLM, an open-source JavaScript\nframework that enables high-performance LLM inference entirely within web\nbrowsers. WebLLM provides an OpenAI-style API for seamless integration into web\napplications, and leverages WebGPU for efficient local GPU acceleration and\nWebAssembly for performant CPU computation. With machine learning compilers\nMLC-LLM and Apache TVM, WebLLM leverages optimized WebGPU kernels, overcoming\nthe absence of performant WebGPU kernel libraries. Evaluations show that WebLLM\ncan retain up to 80% native performance on the same device, with room to\nfurther close the gap. WebLLM paves the way for universally accessible,\nprivacy-preserving, personalized, and locally powered LLM applications in web\nbrowsers. The code is available at: https://github.com/mlc-ai/web-llm.",
      "tldr_zh": "本研究介绍了WebLLM，一个开源的JavaScript框架，旨在实现高性能的大型语言模型(LLMs)推理，直接在网页浏览器中运行，而无需依赖服务器级GPU。WebLLM利用WebGPU进行本地GPU加速、WebAssembly处理CPU计算，并通过MLC-LLM和Apache TVM编译器优化WebGPU内核，提供OpenAI-style API以便无缝集成到web应用。实验结果显示，WebLLM在同一设备上可保留高达80%的原生性能，从而推动浏览器中更具隐私性、个性化和本地化的LLMs应用发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15803v1",
      "published_date": "2024-12-20 11:24:13 UTC",
      "updated_date": "2024-12-20 11:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:50:51.212224"
    },
    {
      "arxiv_id": "2412.15801v1",
      "title": "Bi-directional Mapping of Morphology Metrics and 3D City Blocks for Enhanced Characterization and Generation of Urban Form",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyi Cai",
        "Biao Li",
        "Qiyan Zhang",
        "Xiao Wang",
        "Filip Biljecki",
        "Pieter Herthogs"
      ],
      "abstract": "Urban morphology, examining city spatial configurations, links urban design\nto sustainability. Morphology metrics play a fundamental role in\nperformance-driven computational urban design (CUD) which integrates urban form\ngeneration, performance evaluation and optimization. However, a critical gap\nremains between performance evaluation and complex urban form generation,\ncaused by the disconnection between morphology metrics and urban form,\nparticularly in metric-to-form workflows. It prevents the application of\noptimized metrics to generate improved urban form with enhanced urban\nperformance. Formulating morphology metrics that not only effectively\ncharacterize complex urban forms but also enable the reconstruction of diverse\nforms is of significant importance. This paper highlights the importance of\nestablishing a bi-directional mapping between morphology metrics and complex\nurban form to enable the integration of urban form generation with performance\nevaluation. We present an approach that can 1) formulate morphology metrics to\nboth characterize urban forms and in reverse, retrieve diverse similar 3D urban\nforms, and 2) evaluate the effectiveness of morphology metrics in representing\n3D urban form characteristics of blocks by comparison. We demonstrate the\nmethodology with 3D urban models of New York City, covering 14,248 blocks. We\nuse neural networks and information retrieval for morphology metric encoding,\nurban form clustering and morphology metric evaluation. We identified an\neffective set of morphology metrics for characterizing block-scale urban forms\nthrough comparison. The proposed methodology tightly couples complex urban\nforms with morphology metrics, hence it can enable a seamless and bidirectional\nrelationship between urban form generation and optimization in\nperformance-driven urban design towards sustainable urban design and planning.",
      "tldr_zh": "本论文探讨了城市形态学中形态指标（morphology metrics）和3D城市街区（3D City Blocks）之间的双向映射，以桥接性能评估与复杂城市形式生成的鸿沟。研究提出了一种方法，包括制定形态指标来表征城市形式并反向检索类似3D城市形式，以及通过比较评估这些指标在代表街区特征的有效性；该方法利用神经网络（neural networks）和信息检索（information retrieval）对纽约市14,248个街区的3D模型进行编码、聚类和评估。结果显示，该方法识别出一组有效的形态指标，实现城市形式与指标的紧密耦合，从而在性能驱动的城市设计（computational urban design, CUD）中实现无缝双向整合，促进可持续的城市规划和发展。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15801v1",
      "published_date": "2024-12-20 11:22:55 UTC",
      "updated_date": "2024-12-20 11:22:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:51:04.931426"
    },
    {
      "arxiv_id": "2412.15790v1",
      "title": "GraphSeqLM: A Unified Graph Language Framework for Omic Graph Learning",
      "title_zh": "GraphSeqLM：一个统一的图语言框架，用于组学图学习",
      "authors": [
        "Heming Zhang",
        "Di Huang",
        "Yixin Chen",
        "Fuhai Li"
      ],
      "abstract": "The integration of multi-omic data is pivotal for understanding complex\ndiseases, but its high dimensionality and noise present significant challenges.\nGraph Neural Networks (GNNs) offer a robust framework for analyzing large-scale\nsignaling pathways and protein-protein interaction networks, yet they face\nlimitations in expressivity when capturing intricate biological relationships.\nTo address this, we propose Graph Sequence Language Model (GraphSeqLM), a\nframework that enhances GNNs with biological sequence embeddings generated by\nLarge Language Models (LLMs). These embeddings encode structural and biological\nproperties of DNA, RNA, and proteins, augmenting GNNs with enriched features\nfor analyzing sample-specific multi-omic data. By integrating topological,\nsequence-derived, and biological information, GraphSeqLM demonstrates superior\npredictive accuracy and outperforms existing methods, paving the way for more\neffective multi-omic data integration in precision medicine.",
      "tldr_zh": "该论文提出 GraphSeqLM 框架，一种统一的图语言模型，用于提升组学图学习，通过整合 Large Language Models (LLMs) 生成的生物序列嵌入来增强 Graph Neural Networks (GNNs)。GraphSeqLM 编码 DNA、RNA 和蛋白质的结构及生物属性，融合拓扑、序列衍生和生物信息，从而更好地处理多组学数据的复杂关系和噪声挑战。实验结果表明，该框架在预测准确性上优于现有方法，为精准医学的多组学数据整合开辟了新路径。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15790v1",
      "published_date": "2024-12-20 11:05:26 UTC",
      "updated_date": "2024-12-20 11:05:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:51:16.349979"
    },
    {
      "arxiv_id": "2412.15772v1",
      "title": "Linguistic Features Extracted by GPT-4 Improve Alzheimer's Disease Detection based on Spontaneous Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Heitz",
        "Gerold Schneider",
        "Nicolas Langer"
      ],
      "abstract": "Alzheimer's Disease (AD) is a significant and growing public health concern.\nInvestigating alterations in speech and language patterns offers a promising\npath towards cost-effective and non-invasive early detection of AD on a large\nscale. Large language models (LLMs), such as GPT, have enabled powerful new\npossibilities for semantic text analysis. In this study, we leverage GPT-4 to\nextract five semantic features from transcripts of spontaneous patient speech.\nThe features capture known symptoms of AD, but they are difficult to quantify\neffectively using traditional methods of computational linguistics. We\ndemonstrate the clinical significance of these features and further validate\none of them (\"Word-Finding Difficulties\") against a proxy measure and human\nraters. When combined with established linguistic features and a Random Forest\nclassifier, the GPT-derived features significantly improve the detection of AD.\nOur approach proves effective for both manually transcribed and automatically\ngenerated transcripts, representing a novel and impactful use of recent\nadvancements in LLMs for AD speech analysis.",
      "tldr_zh": "本研究利用 GPT-4 从阿尔茨海默病（AD）患者的自发言语转录中提取五个语义特征，这些特征捕捉了 AD 的已知症状，如 \"Word-Finding Difficulties\"，但传统计算语言学方法难以有效量化。研究验证了这些特征的临床意义，并将 \"Word-Finding Difficulties\" 与代理测量和人类评估者进行了比较。结果显示，当这些 GPT-4 提取特征与现有语言特征结合使用随机森林分类器时，显著提高了 AD 检测的准确性，且该方法适用于手动转录和自动生成的转录，展示了大型语言模型在 AD 言语分析中的创新应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the 31st International Conference on Computational\n  Linguistics (COLING 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.15772v1",
      "published_date": "2024-12-20 10:43:42 UTC",
      "updated_date": "2024-12-20 10:43:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:51:28.516783"
    },
    {
      "arxiv_id": "2412.15748v1",
      "title": "Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shamus Sim",
        "Tyrone Chen"
      ],
      "abstract": "Background: Despite the current ubiquity of Large Language Models (LLMs)\nacross the medical domain, there is a surprising lack of studies which address\ntheir reasoning behaviour. We emphasise the importance of understanding\nreasoning behaviour as opposed to high-level prediction accuracies, since it is\nequivalent to explainable AI (XAI) in this context. In particular, achieving\nXAI in medical LLMs used in the clinical domain will have a significant impact\nacross the healthcare sector. Results: Therefore, we define the concept of\nreasoning behaviour in the specific context of medical LLMs. We then categorise\nand discuss the current state of the art of methods which evaluate reasoning\nbehaviour in medical LLMs. Finally, we propose theoretical frameworks which can\nempower medical professionals or machine learning engineers to gain insight\ninto the low-level reasoning operations of these previously obscure models.\nConclusion: The subsequent increased transparency and trust in medical machine\nlearning models by clinicians as well as patients will accelerate the\nintegration, application as well as further development of medical AI for the\nhealthcare system as a whole",
      "tldr_zh": "本研究强调了理解医疗领域 Large Language Models (LLMs) 的推理行为比单纯追求预测准确率更重要，因为这等同于实现 explainable AI (XAI)，从而提升临床应用的透明度和信任。论文定义了医疗 LLMs 推理行为的概念，并对当前评估这种行为的先进方法进行了分类和讨论。作者还提出理论框架，帮助医疗专业人士或机器学习工程师洞察模型的底层推理操作，最终加速医疗 AI 在整个医疗体系中的整合和发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 5 figures, 2 tables. Conceptualization, both authors.\n  formal analysis, both authors. funding acquisition, both authors.\n  investigation, both authors. resources, both authors. supervision, T.C..\n  validation, both authors. visualization, both authors. writing original\n  draft, both authors. writing review and editing, both authors",
      "pdf_url": "http://arxiv.org/pdf/2412.15748v1",
      "published_date": "2024-12-20 10:06:52 UTC",
      "updated_date": "2024-12-20 10:06:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:51:38.884068"
    },
    {
      "arxiv_id": "2412.16265v3",
      "title": "Autoware.Flex: Human-Instructed Dynamically Reconfigurable Autonomous Driving Systems",
      "title_zh": "Autoware.Flex：人类指导",
      "authors": [
        "Ziwei Song",
        "Mingsong Lv",
        "Tianchi Ren",
        "Chun Jason Xue",
        "Jen-Ming Wu",
        "Nan Guan"
      ],
      "abstract": "Existing Autonomous Driving Systems (ADS) independently make driving\ndecisions, but they face two significant limitations. First, in complex\nscenarios, ADS may misinterpret the environment and make inappropriate driving\ndecisions. Second, these systems are unable to incorporate human driving\npreferences in their decision-making processes. This paper proposes\nAutoware$.$Flex, a novel ADS system that incorporates human input into the\ndriving process, allowing users to guide the ADS in making more appropriate\ndecisions and ensuring their preferences are satisfied. Achieving this needs to\naddress two key challenges: (1) translating human instructions, expressed in\nnatural language, into a format the ADS can understand, and (2) ensuring these\ninstructions are executed safely and consistently within the ADS' s\ndecision-making framework. For the first challenge, we employ a Large Language\nModel (LLM) assisted by an ADS-specialized knowledge base to enhance\ndomain-specific translation. For the second challenge, we design a validation\nmechanism to ensure that human instructions result in safe and consistent\ndriving behavior. Experiments conducted on both simulators and a real-world\nautonomous vehicle demonstrate that Autoware$.$Flex effectively interprets\nhuman instructions and executes them safely.",
      "tldr_zh": "该研究提出Autoware.Flex，一种新型Autonomous Driving Systems (ADS)，允许人类通过自然语言指令动态指导驾驶决策，从而解决现有ADS在复杂场景下误解环境和忽略人类偏好的问题。该系统通过Large Language Model (LLM)结合ADS专用知识库，将人类指令翻译成可理解格式，并设计验证机制确保指令执行的安全性和一致性。实验在模拟器和真实车辆上验证了Autoware.Flex的有效性，展示了其在提升驾驶决策准确性和用户满意度方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.16265v3",
      "published_date": "2024-12-20 10:06:11 UTC",
      "updated_date": "2025-02-14 09:12:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:51:51.426907"
    },
    {
      "arxiv_id": "2412.15728v1",
      "title": "fluke: Federated Learning Utility frameworK for Experimentation and research",
      "title_zh": "翻译失败",
      "authors": [
        "Mirko Polato"
      ],
      "abstract": "Since its inception in 2016, Federated Learning (FL) has been gaining\ntremendous popularity in the machine learning community. Several frameworks\nhave been proposed to facilitate the development of FL algorithms, but\nresearchers often resort to implementing their algorithms from scratch,\nincluding all baselines and experiments. This is because existing frameworks\nare not flexible enough to support their needs or the learning curve to extend\nthem is too steep. In this paper, we present \\fluke, a Python package designed\nto simplify the development of new FL algorithms. fluke is specifically\ndesigned for prototyping purposes and is meant for researchers or practitioners\nfocusing on the learning components of a federated system. fluke is\nopen-source, and it can be either used out of the box or extended with new\nalgorithms with minimal overhead.",
      "tldr_zh": "该论文介绍了 fluke，一个用于 Federated Learning (FL) 实验和研究的开源 Python 包，旨在简化新 FL 算法的开发过程。fluke 针对研究者或从业者设计，专注于 FL 系统的学习组件，提供灵活的原型制作功能，并允许用户直接使用或轻松扩展算法。相比现有框架，fluke 解决了灵活性不足和学习曲线陡峭的问题，帮助避免从零实现基线和实验，从而提升研究效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at FLUID workshop (AAAI 2025) [4 pages (+2 references), 2\n  figures, 1 algorithm]",
      "pdf_url": "http://arxiv.org/pdf/2412.15728v1",
      "published_date": "2024-12-20 09:51:23 UTC",
      "updated_date": "2024-12-20 09:51:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:52:03.128982"
    },
    {
      "arxiv_id": "2412.15716v1",
      "title": "Towards Secure AI-driven Industrial Metaverse with NFT Digital Twins",
      "title_zh": "翻译失败",
      "authors": [
        "Ravi Prakash",
        "Tony Thomas"
      ],
      "abstract": "The rise of the industrial metaverse has brought digital twins (DTs) to the\nforefront. Blockchain-powered non-fungible tokens (NFTs) offer a decentralized\napproach to creating and owning these cloneable DTs. However, the potential for\nunauthorized duplication, or counterfeiting, poses a significant threat to the\nsecurity of NFT-DTs. Existing NFT clone detection methods often rely on static\ninformation like metadata and images, which can be easily manipulated. To\naddress these limitations, we propose a novel deep-learning-based solution as a\ncombination of an autoencoder and RNN-based classifier. This solution enables\nreal-time pattern recognition to detect fake NFT-DTs. Additionally, we\nintroduce the concept of dynamic metadata, providing a more reliable way to\nverify authenticity through AI-integrated smart contracts. By effectively\nidentifying counterfeit DTs, our system contributes to strengthening the\nsecurity of NFT-based assets in the metaverse.",
      "tldr_zh": "本论文针对工业元宇宙中 NFT 数字孪生（NFT-DTs）的安全问题，特别是在未经授权复制方面的威胁，提出了一种新型深度学习解决方案。\n该方法结合自编码器（autoencoder）和基于 RNN 的分类器，实现实时模式识别，以有效检测假冒 NFT-DTs。\n此外，论文引入动态元数据概念，通过 AI 集成智能合约增强真实性验证，从而加强了元宇宙中基于 NFT 的资产安全性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15716v1",
      "published_date": "2024-12-20 09:40:18 UTC",
      "updated_date": "2024-12-20 09:40:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:52:15.700810"
    },
    {
      "arxiv_id": "2412.15714v2",
      "title": "AutoLife: Automatic Life Journaling with Smartphones and LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Huatao Xu",
        "Panrong Tong",
        "Mo Li",
        "Mani Srivastava"
      ],
      "abstract": "This paper introduces a novel mobile sensing application - life journaling -\ndesigned to generate semantic descriptions of users' daily lives. We present\nAutoLife, an automatic life journaling system based on commercial smartphones.\nAutoLife only inputs low-cost sensor data (without photos or audio) from\nsmartphones and can automatically generate comprehensive life journals for\nusers. To achieve this, we first derive time, motion, and location contexts\nfrom multimodal sensor data, and harness the zero-shot capabilities of Large\nLanguage Models (LLMs), enriched with commonsense knowledge about human lives,\nto interpret diverse contexts and generate life journals. To manage the task\ncomplexity and long sensing duration, a multilayer framework is proposed, which\ndecomposes tasks and seamlessly integrates LLMs with other techniques for life\njournaling. This study establishes a real-life dataset as a benchmark and\nextensive experiment results demonstrate that AutoLife produces accurate and\nreliable life journals.",
      "tldr_zh": "本文提出 AutoLife 系统，这是一个基于商用智能手机的自动生活日志应用，仅使用低成本传感器数据（如时间、运动和位置上下文）来生成用户的日常语义描述。系统利用 LLMs 的零-shot 能力，结合常识知识解释多模态传感器数据，并通过多层框架分解任务、整合 LLMs 与其他技术，以处理复杂性和长时感知。研究建立了一个真实生活数据集作为基准，实验结果表明 AutoLife 生成的日志准确且可靠，为自动生活日志技术提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.15714v2",
      "published_date": "2024-12-20 09:37:02 UTC",
      "updated_date": "2024-12-23 10:45:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:52:28.578715"
    },
    {
      "arxiv_id": "2412.15703v3",
      "title": "MacLight: Multi-scene Aggregation Convolutional Learning for Traffic Signal Control",
      "title_zh": "翻译失败",
      "authors": [
        "Sunbowen Lee",
        "Hongqin Lyu",
        "Yicheng Gong",
        "Yingying Sun",
        "Chao Deng"
      ],
      "abstract": "Reinforcement learning methods have proposed promising traffic signal control\npolicy that can be trained on large road networks. Current SOTA methods model\nroad networks as topological graph structures, incorporate graph attention into\ndeep Q-learning, and merge local and global embeddings to improve policy.\nHowever, graph-based methods are difficult to parallelize, resulting in huge\ntime overhead. Moreover, none of the current peer studies have deployed dynamic\ntraffic systems for experiments, which is far from the actual situation.\n  In this context, we propose Multi-Scene Aggregation Convolutional Learning\nfor traffic signal control (MacLight), which offers faster training speeds and\nmore stable performance. Our approach consists of two main components. The\nfirst is the global representation, where we utilize variational autoencoders\nto compactly compress and extract the global representation. The second\ncomponent employs the proximal policy optimization algorithm as the backbone,\nallowing value evaluation to consider both local features and global embedding\nrepresentations. This backbone model significantly reduces time overhead and\nensures stability in policy updates. We validated our method across multiple\ntraffic scenarios under both static and dynamic traffic systems. Experimental\nresults demonstrate that, compared to general and domian SOTA methods, our\napproach achieves superior stability, optimized convergence levels and the\nhighest time efficiency. The code is under\nhttps://github.com/Aegis1863/MacLight.",
      "tldr_zh": "本研究提出MacLight，一种多场景聚合卷积学习方法，用于交通信号控制，以解决现有基于图结构的强化学习方法训练速度慢和难以并行化的问题。\nMacLight的核心组件包括使用Variational Autoencoders压缩提取全局表示，以及以Proximal Policy Optimization为骨干的策略优化，结合局部特征和全局嵌入以提升性能稳定性。\n实验在多种静态和动态交通场景中验证，MacLight相较于SOTA方法实现了更高的稳定性、最优收敛水平和最佳时间效率。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted as full paper by AAMAS2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15703v3",
      "published_date": "2024-12-20 09:26:41 UTC",
      "updated_date": "2024-12-24 04:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:52:40.268691"
    },
    {
      "arxiv_id": "2412.16264v3",
      "title": "Continual Learning with Strategic Selection and Forgetting for Network Intrusion Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Xinchen Zhang",
        "Running Zhao",
        "Zhihan Jiang",
        "Handi Chen",
        "Yulong Ding",
        "Edith C. H. Ngai",
        "Shuang-Hua Yang"
      ],
      "abstract": "Intrusion Detection Systems (IDS) are crucial for safeguarding digital\ninfrastructure. In dynamic network environments, both threat landscapes and\nnormal operational behaviors are constantly changing, resulting in concept\ndrift. While continuous learning mitigates the adverse effects of concept\ndrift, insufficient attention to drift patterns and excessive preservation of\noutdated knowledge can still hinder the IDS's adaptability. In this paper, we\npropose SSF (Strategic Selection and Forgetting), a novel continual learning\nmethod for IDS, providing continuous model updates with a constantly refreshed\nmemory buffer. Our approach features a strategic sample selection algorithm to\nselect representative new samples and a strategic forgetting mechanism to drop\noutdated samples. The proposed strategic sample selection algorithm prioritizes\nnew samples that cause the `drifted' pattern, enabling the model to better\nunderstand the evolving landscape. Additionally, we introduce strategic\nforgetting upon detecting significant drift by discarding outdated samples to\nfree up memory, allowing the incorporation of more recent data. SSF captures\nevolving patterns effectively and ensures the model is aligned with the change\nof data patterns, significantly enhancing the IDS's adaptability to concept\ndrift. The state-of-the-art performance of SSF on NSL-KDD and UNSW-NB15\ndatasets demonstrates its superior adaptability to concept drift for network\nintrusion detection. The code is released at\nhttps://github.com/xinchen930/SSF-Strategic-Selection-and-Forgetting.",
      "tldr_zh": "这篇论文针对网络入侵检测（Intrusion Detection Systems, IDS）中的概念漂移（concept drift）问题，提出了一种名为 SSF（Strategic Selection and Forgetting）的持续学习（continual learning）方法。该方法包括战略样本选择算法，用于优先选取引起漂移模式的新样本，以帮助模型更好地理解演变中的网络环境；以及战略遗忘机制，通过检测重大漂移来丢弃过时样本，从而释放内存并整合新数据。实验结果显示，SSF 在 NSL-KDD 和 UNSW-NB15 数据集上表现出最先进的性能，大大提升了 IDS 的适应性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by IEEE International Conference on Computer Communications\n  (INFOCOM) 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.16264v3",
      "published_date": "2024-12-20 09:22:07 UTC",
      "updated_date": "2025-02-14 12:15:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:52:52.698578"
    },
    {
      "arxiv_id": "2412.15701v2",
      "title": "Collaborative Gym: A Framework for Enabling and Evaluating Human-Agent Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Yijia Shao",
        "Vinay Samuel",
        "Yucheng Jiang",
        "John Yang",
        "Diyi Yang"
      ],
      "abstract": "Recent advancements in language models (LMs) have sparked growing interest in\ndeveloping LM agents. While fully autonomous agents could excel in many\nscenarios, numerous use cases inherently require them to collaborate with\nhumans due to humans' latent preferences, domain expertise, or need for\ncontrol. To facilitate the study of human-agent collaboration, we present\nCollaborative Gym (Co-Gym), a general framework enabling asynchronous,\ntripartite interaction among agents, humans, and task environments. We\ninstantiate Co-Gym with three representative tasks in both simulated and\nreal-world conditions, and propose an evaluation framework that assesses both\nthe collaboration outcomes and processes. Our findings reveal that\ncollaborative agents consistently outperform their fully autonomous\ncounterparts in task performance within those delivered cases, achieving win\nrates of 86% in Travel Planning, 74% in Tabular Analysis, and 66% in Related\nWork when evaluated by real users. However, our study also highlights\nsignificant challenges in developing collaborative agents, requiring\nadvancements in core aspects of intelligence -- communication capabilities,\nsituational awareness, and balancing autonomy and human control.",
      "tldr_zh": "本文提出 Collaborative Gym (Co-Gym)，一个通用框架，支持代理、人类和任务环境的异步三方互动，以促进人类-代理协作研究。该框架在模拟和真实环境中实例化了三个代表性任务，并引入评估方法来衡量协作结果和过程。研究发现，协作代理在任务表现上显著优于完全自治代理，在用户评估中分别实现 Travel Planning 的86%胜率、Tabular Analysis 的74%胜率和 Related Work 的66%胜率。然而，开发此类代理仍面临挑战，需要提升通信能力、情境感知以及自治与人类控制的平衡。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint. Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2412.15701v2",
      "published_date": "2024-12-20 09:21:15 UTC",
      "updated_date": "2025-01-16 07:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:53:04.263262"
    },
    {
      "arxiv_id": "2412.15700v2",
      "title": "AIR: Unifying Individual and Collective Exploration in Cooperative Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Guangchong Zhou",
        "Zeren Zhang",
        "Guoliang Fan"
      ],
      "abstract": "Exploration in cooperative multi-agent reinforcement learning (MARL) remains\nchallenging for value-based agents due to the absence of an explicit policy.\nExisting approaches include individual exploration based on uncertainty towards\nthe system and collective exploration through behavioral diversity among\nagents. However, the introduction of additional structures often leads to\nreduced training efficiency and infeasible integration of these methods. In\nthis paper, we propose Adaptive exploration via Identity Recognition~(AIR),\nwhich consists of two adversarial components: a classifier that recognizes\nagent identities from their trajectories, and an action selector that\nadaptively adjusts the mode and degree of exploration. We theoretically prove\nthat AIR can facilitate both individual and collective exploration during\ntraining, and experiments also demonstrate the efficiency and effectiveness of\nAIR across various tasks.",
      "tldr_zh": "这篇论文针对合作多智能体强化学习(MARL)中的探索挑战，提出了一种统一个体和集体探索的框架AIR，以解决现有方法效率低下和整合困难的问题。AIR 包括两个对抗组件：一个分类器从智能体轨迹中识别身份，以及一个动作选择器适应性地调整探索模式和程度。理论证明表明 AIR 能同时促进个体探索（基于不确定性）和集体探索（通过行为多样性），实验在各种任务中验证了其高效性和有效性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15700v2",
      "published_date": "2024-12-20 09:18:30 UTC",
      "updated_date": "2024-12-30 09:00:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:53:15.384850"
    },
    {
      "arxiv_id": "2412.15677v1",
      "title": "AI-generated Image Quality Assessment in Visual Communication",
      "title_zh": "视觉通信中的 AI 生成图像质量评估",
      "authors": [
        "Yu Tian",
        "Yixuan Li",
        "Baoliang Chen",
        "Hanwei Zhu",
        "Shiqi Wang",
        "Sam Kwong"
      ],
      "abstract": "Assessing the quality of artificial intelligence-generated images (AIGIs)\nplays a crucial role in their application in real-world scenarios. However,\ntraditional image quality assessment (IQA) algorithms primarily focus on\nlow-level visual perception, while existing IQA works on AIGIs overemphasize\nthe generated content itself, neglecting its effectiveness in real-world\napplications. To bridge this gap, we propose AIGI-VC, a quality assessment\ndatabase for AI-Generated Images in Visual Communication, which studies the\ncommunicability of AIGIs in the advertising field from the perspectives of\ninformation clarity and emotional interaction. The dataset consists of 2,500\nimages spanning 14 advertisement topics and 8 emotion types. It provides\ncoarse-grained human preference annotations and fine-grained preference\ndescriptions, benchmarking the abilities of IQA methods in preference\nprediction, interpretation, and reasoning. We conduct an empirical study of\nexisting representative IQA methods and large multi-modal models on the AIGI-VC\ndataset, uncovering their strengths and weaknesses.",
      "tldr_zh": "本研究针对人工智能生成图像（AIGIs）的质量评估问题，指出传统图像质量评估（IQA）算法过于注重低级视觉感知，而忽略了AIGIs在实际应用中的有效性。作者提出AIGI-VC数据库，用于评估AIGIs在视觉通信（如广告领域）的可通信性，包括信息清晰度和情感互动，数据集包含2500张图像、14个广告主题和8种情感类型，并提供粗粒度和细粒度的人类偏好标注。实验结果显示，在AIGI-VC上测试现有IQA方法和大型多模态模型时，揭示了它们的优势和弱点，为改进AIGIs质量评估提供了新基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI-2025; Project page: https://github.com/ytian73/AIGI-VC",
      "pdf_url": "http://arxiv.org/pdf/2412.15677v1",
      "published_date": "2024-12-20 08:47:07 UTC",
      "updated_date": "2024-12-20 08:47:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:53:28.086866"
    },
    {
      "arxiv_id": "2412.16262v1",
      "title": "VirusT5: Harnessing Large Language Models to Predicting SARS-CoV-2 Evolution",
      "title_zh": "VirusT5：",
      "authors": [
        "Vishwajeet Marathe",
        "Deewan Bajracharya",
        "Changhui Yan"
      ],
      "abstract": "During a virus's evolution,various regions of the genome are subjected to\ndistinct levels of functional constraints.Combined with factors like codon bias\nand DNA repair efficiency,these constraints contribute to unique mutation\npatterns within the genome or a specific gene. In this project, we harnessed\nthe power of Large Language Models(LLMs) to predict the evolution of\nSARS-CoV-2. By treating the mutation process from one generation to the next as\na translation task, we trained a transformer model, called VirusT5, to capture\nthe mutation patterns underlying SARS-CoV-2 evolution. We evaluated the\nVirusT5's ability to detect these mutation patterns including its ability to\nidentify mutation hotspots and explored the potential of using VirusT5 to\npredict future virus variants. Our findings demonstrate the feasibility of\nusing a large language model to model viral evolution as a translation process.\nThis study establishes the groundbreaking concept of \"mutation-as-translation,\"\npaving the way for new methodologies and tools for combating virus threats",
      "tldr_zh": "本研究利用大型语言模型（LLMs）来预测 SARS-CoV-2 的进化，通过将病毒突变过程视为翻译任务，训练了一个名为 VirusT5 的 Transformer 模型，以捕捉基因组中的突变模式。VirusT5 能够识别突变热点并评估未来病毒变体的可能性，展示了建模病毒进化作为翻译过程的可行性。该工作引入了“mutation-as-translation”的创新概念，为开发抗击病毒威胁的新工具和方法提供了基础。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "This is a preprint of a paper submitted to IEEE for consideration",
      "pdf_url": "http://arxiv.org/pdf/2412.16262v1",
      "published_date": "2024-12-20 08:46:42 UTC",
      "updated_date": "2024-12-20 08:46:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:54:23.227106"
    },
    {
      "arxiv_id": "2412.15660v1",
      "title": "Adaptable and Precise: Enterprise-Scenario LLM Function-Calling Capability Training Pipeline",
      "title_zh": "翻译失败",
      "authors": [
        "Guancheng Zeng",
        "Wentao Ding",
        "Beining Xu",
        "Chi Zhang",
        "Wenqiang Han",
        "Gang Li",
        "Jingjing Mo",
        "Pengxu Qiu",
        "Xinran Tao",
        "Wang Tao",
        "Haowen Hu"
      ],
      "abstract": "Enterprises possess a vast array of API assets scattered across various\nfunctions, forming the backbone of existing business processes. By leveraging\nthese APIs as functional tools, enterprises can design diverse,\nscenario-specific agent applications, driven by on-premise function-calling\nmodels as the core engine. However, generic models often fail to meet\nenterprise requirements in terms of computational efficiency, output accuracy,\nand stability, necessitating scenario-specific adaptation. In this paper, we\npropose a training pipeline for function-calling capabilities tailored to\nreal-world business scenarios. This pipeline includes the synthesis and\naugmentation of scenario-specific function-calling data, model fine-tuning, and\nperformance evaluation and analysis. Using this pipeline, we generated 1,260\nfully AI-generated samples and 1,035 augmented manually-labeled samples in\ndigital HR agent scenario. The Qwen2.5-Coder-7B-Instruct model was employed as\nthe base model and fine-tuned using the LoRA method on four GPUs with 24GB\nVRAM. Our fine-tuned model demonstrated outstanding performance in evaluations\nand practical applications, surpassing GPT-4 and GPT-4o in accuracy on the test\nset. These results validate the reliability of the proposed pipeline for\ntraining scenario-specific function-calling models.",
      "tldr_zh": "本研究提出了一种适应性和精确的训练管道，用于针对企业场景下的大语言模型(LLM)功能调用能力进行优化，以解决通用模型在计算效率、输出准确性和稳定性方面的不足。该管道包括场景特定功能调用数据的合成与增强、模型微调以及性能评估，在数字HR代理场景中生成了1260个AI生成样本和1035个手动标记样本。使用Qwen2.5-Coder-7B-Instruct作为基模型，通过LoRA方法在四GPU上进行微调。实验结果显示，该微调模型在测试集上的准确性超过了GPT-4和GPT-4o，验证了该管道在训练场景特定功能调用模型方面的可靠性和有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 6 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.15660v1",
      "published_date": "2024-12-20 08:20:21 UTC",
      "updated_date": "2024-12-20 08:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:53:52.040043"
    },
    {
      "arxiv_id": "2412.15655v3",
      "title": "MathSpeech: Leveraging Small LMs for Accurate Conversion in Mathematical Speech-to-Formula",
      "title_zh": "翻译失败",
      "authors": [
        "Sieun Hyeon",
        "Kyudan Jung",
        "Jaehee Won",
        "Nam-Joon Kim",
        "Hyun Gon Ryu",
        "Hyuk-Jae Lee",
        "Jaeyoung Do"
      ],
      "abstract": "In various academic and professional settings, such as mathematics lectures\nor research presentations, it is often necessary to convey mathematical\nexpressions orally. However, reading mathematical expressions aloud without\naccompanying visuals can significantly hinder comprehension, especially for\nthose who are hearing-impaired or rely on subtitles due to language barriers.\nFor instance, when a presenter reads Euler's Formula, current Automatic Speech\nRecognition (ASR) models often produce a verbose and error-prone textual\ndescription (e.g., e to the power of i x equals cosine of x plus i\n$\\textit{side}$ of x), instead of the concise $\\LaTeX{}$ format (i.e., $ e^{ix}\n= \\cos(x) + i\\sin(x) $), which hampers clear understanding and communication.\nTo address this issue, we introduce MathSpeech, a novel pipeline that\nintegrates ASR models with small Language Models (sLMs) to correct errors in\nmathematical expressions and accurately convert spoken expressions into\nstructured $\\LaTeX{}$ representations. Evaluated on a new dataset derived from\nlecture recordings, MathSpeech demonstrates $\\LaTeX{}$ generation capabilities\ncomparable to leading commercial Large Language Models (LLMs), while leveraging\nfine-tuned small language models of only 120M parameters. Specifically, in\nterms of CER, BLEU, and ROUGE scores for $\\LaTeX{}$ translation, MathSpeech\ndemonstrated significantly superior capabilities compared to GPT-4o. We\nobserved a decrease in CER from 0.390 to 0.298, and higher ROUGE/BLEU scores\ncompared to GPT-4o.",
      "tldr_zh": "这篇论文介绍了 MathSpeech，一个创新管道，将 Automatic Speech Recognition (ASR) 模型与小型语言模型 (sLMs) 整合，用于准确地将数学口头表达转换为结构化的 LaTeX 格式，从而解决传统 ASR 在数学传达中的冗长和错误问题。MathSpeech 通过细调仅有 120M 参数的 sLMs 来纠正表达错误，并在从讲座录音派生的新数据集上进行评估。结果显示，该方法在 LaTeX 生成方面与领先的商业 Large Language Models (LLMs) 相当，甚至在 CER、BLEU 和 ROUGE 指标上优于 GPT-4o，具体表现为 CER 从 0.390 降至 0.298，并提升了 ROUGE 和 BLEU 分数。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15655v3",
      "published_date": "2024-12-20 08:13:05 UTC",
      "updated_date": "2025-04-11 04:17:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:54:04.853036"
    },
    {
      "arxiv_id": "2502.15690v1",
      "title": "Level-Navi Agent: A Framework and benchmark for Chinese Web Search Agents",
      "title_zh": "Level-Navi Agent: 针对中文网络搜索代理的框架和基准",
      "authors": [
        "Chuanrui Hu",
        "Shichong Xie",
        "Baoxin Wang",
        "Bin Chen",
        "Xiaofeng Cong",
        "Jun Zhang"
      ],
      "abstract": "Large language models (LLMs), adopted to understand human language, drive the\ndevelopment of artificial intelligence (AI) web search agents. Compared to\ntraditional search engines, LLM-powered AI search agents are capable of\nunderstanding and responding to complex queries with greater depth, enabling\nmore accurate operations and better context recognition. However, little\nattention and effort has been paid to the Chinese web search, which results in\nthat the capabilities of open-source models have not been uniformly and fairly\nevaluated. The difficulty lies in lacking three aspects: an unified agent\nframework, an accurately labeled dataset, and a suitable evaluation metric. To\naddress these issues, we propose a general-purpose and training-free web search\nagent by level-aware navigation, Level-Navi Agent, accompanied by a\nwell-annotated dataset (Web24) and a suitable evaluation metric. Level-Navi\nAgent can think through complex user questions and conduct searches across\nvarious levels on the internet to gather information for questions. Meanwhile,\nwe provide a comprehensive evaluation of state-of-the-art LLMs under fair\nsettings. To further facilitate future research, source code is available at\nGithub.",
      "tldr_zh": "该研究针对中文网络搜索领域的不足，提出了一种通用的无需训练的代理框架——Level-Navi Agent，通过层级感知导航（level-aware navigation）来处理复杂用户查询，实现多层级互联网搜索并收集信息。论文同时引入了一个精确标注的数据集（Web24）和合适的评估指标，以统一评估开源大型语言模型（LLMs）的性能。实验结果显示，该框架在公平设置下对最先进LLMs进行了全面评估，显著提升了中文网络搜索的准确性和上下文理解能力，并通过开源代码促进未来研究的发展。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15690v1",
      "published_date": "2024-12-20 08:03:12 UTC",
      "updated_date": "2024-12-20 08:03:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:54:16.212070"
    },
    {
      "arxiv_id": "2412.15639v2",
      "title": "Tacit Learning with Adaptive Information Selection for Cooperative Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Lunjun Liu",
        "Weilai Jiang",
        "Yaonan Wang"
      ],
      "abstract": "In multi-agent reinforcement learning (MARL), the centralized training with\ndecentralized execution (CTDE) framework has gained widespread adoption due to\nits strong performance. However, the further development of CTDE faces two key\nchallenges. First, agents struggle to autonomously assess the relevance of\ninput information for cooperative tasks, impairing their decision-making\nabilities. Second, in communication-limited scenarios with partial\nobservability, agents are unable to access global information, restricting\ntheir ability to collaborate effectively from a global perspective. To address\nthese challenges, we introduce a novel cooperative MARL framework based on\ninformation selection and tacit learning. In this framework, agents gradually\ndevelop implicit coordination during training, enabling them to infer the\ncooperative behavior of others in a discrete space without communication,\nrelying solely on local information. Moreover, we integrate gating and\nselection mechanisms, allowing agents to adaptively filter information based on\nenvironmental changes, thereby enhancing their decision-making capabilities.\nExperiments on popular MARL benchmarks show that our framework can be\nseamlessly integrated with state-of-the-art algorithms, leading to significant\nperformance improvements.",
      "tldr_zh": "该研究针对多智能体强化学习 (MARL) 中的 centralized training with decentralized execution (CTDE) 框架，解决了代理难以评估输入信息相关性和在部分可观察环境下协作受限的挑战。作者提出了一种基于信息选择和 tacit learning 的新框架，让代理在训练过程中逐步发展隐性协调能力，从而在不依赖通信的情况下，通过本地信息推断他人的合作行为。同时，该框架整合了门控和选择机制，使代理能根据环境变化自适应过滤信息，提升决策效率。在流行 MARL 基准实验中，该框架与最先进算法无缝整合，显著提高了整体性能。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted by AAMAS 2025 (Extended Abstract)",
      "pdf_url": "http://arxiv.org/pdf/2412.15639v2",
      "published_date": "2024-12-20 07:55:59 UTC",
      "updated_date": "2024-12-24 06:05:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:54:27.245107"
    },
    {
      "arxiv_id": "2412.15623v1",
      "title": "JailPO: A Novel Black-box Jailbreak Framework via Preference Optimization against Aligned LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Hongyi Li",
        "Jiawei Ye",
        "Jie Wu",
        "Tianjie Yan",
        "Chu Wang",
        "Zhixin Li"
      ],
      "abstract": "Large Language Models (LLMs) aligned with human feedback have recently\ngarnered significant attention. However, it remains vulnerable to jailbreak\nattacks, where adversaries manipulate prompts to induce harmful outputs.\nExploring jailbreak attacks enables us to investigate the vulnerabilities of\nLLMs and further guides us in enhancing their security. Unfortunately, existing\ntechniques mainly rely on handcrafted templates or generated-based\noptimization, posing challenges in scalability, efficiency and universality. To\naddress these issues, we present JailPO, a novel black-box jailbreak framework\nto examine LLM alignment. For scalability and universality, JailPO meticulously\ntrains attack models to automatically generate covert jailbreak prompts.\nFurthermore, we introduce a preference optimization-based attack method to\nenhance the jailbreak effectiveness, thereby improving efficiency. To analyze\nmodel vulnerabilities, we provide three flexible jailbreak patterns. Extensive\nexperiments demonstrate that JailPO not only automates the attack process while\nmaintaining effectiveness but also exhibits superior performance in efficiency,\nuniversality, and robustness against defenses compared to baselines.\nAdditionally, our analysis of the three JailPO patterns reveals that attacks\nbased on complex templates exhibit higher attack strength, whereas covert\nquestion transformations elicit riskier responses and are more likely to bypass\ndefense mechanisms.",
      "tldr_zh": "这篇论文提出了 JailPO，一种新的黑箱 jailbreak 框架，用于测试对齐的大型语言模型（LLMs）的漏洞，通过操纵提示诱导有害输出。JailPO 通过训练攻击模型自动生成隐蔽的 jailbreak 提示，并引入基于 preference optimization 的攻击方法，提高了攻击的可扩展性、效率和通用性，同时提供了三种灵活的 jailbreak 模式。实验结果表明，JailPO 在效率、通用性和鲁棒性方面优于现有基线模型，且分析显示基于复杂模板的攻击更具强度，而隐蔽问题转换更容易绕过防御机制。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15623v1",
      "published_date": "2024-12-20 07:29:10 UTC",
      "updated_date": "2024-12-20 07:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:54:41.133007"
    },
    {
      "arxiv_id": "2412.15620v1",
      "title": "Modeling Autonomous Shifts Between Focus State and Mind-Wandering Using a Predictive-Coding-Inspired Variational RNN Model",
      "title_zh": "翻译失败",
      "authors": [
        "Henrique Oyama",
        "Jun Tani"
      ],
      "abstract": "The current study investigates possible neural mechanisms underling\nautonomous shifts between focus state and mind-wandering by conducting model\nsimulation experiments. On this purpose, we modeled perception processes of\ncontinuous sensory sequences using our previous proposed variational RNN model\nwhich was developed based on the free energy principle. The current study\nextended this model by introducing an adaptation mechanism of a meta-level\nparameter, referred to as the meta-prior $\\mathbf{w}$, which regulates the\ncomplexity term in the free energy. Our simulation experiments demonstrated\nthat autonomous shifts between focused perception and mind-wandering take place\nwhen $\\mathbf{w}$ switches between low and high values associated with decrease\nand increase of the average reconstruction error over the past window. In\nparticular, high $\\mathbf{w}$ prioritized top-down predictions while low\n$\\mathbf{w}$ emphasized bottom-up sensations. This paper explores how our\nexperiment results align with existing studies and highlights their potential\nfor future research.",
      "tldr_zh": "本文研究了焦点状态和心智游离之间自主转换的神经机制，使用基于自由能量原理的变分 RNN 模型模拟连续感官序列的感知过程。模型扩展了 meta-prior $\\mathbf{w}$ 参数，作为调节自由能量中复杂性项的适应机制；模拟实验显示，当 $\\mathbf{w}$ 值较高时优先自上而下预测，而较低时强调自下而上感觉，从而实现自主状态切换。该研究结果与现有文献对齐，并为未来神经机制探索提供了潜在方向。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15620v1",
      "published_date": "2024-12-20 07:25:20 UTC",
      "updated_date": "2024-12-20 07:25:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:54:52.783824"
    },
    {
      "arxiv_id": "2412.15619v2",
      "title": "Understanding Individual Agent Importance in Multi-Agent System via Counterfactual Reasoning",
      "title_zh": "通过反事实推理理解多代理系统中个体代理的重要性",
      "authors": [
        "Jianming Chen",
        "Yawen Wang",
        "Junjie Wang",
        "Xiaofei Xie",
        "jun Hu",
        "Qing Wang",
        "Fanjiang Xu"
      ],
      "abstract": "Explaining multi-agent systems (MAS) is urgent as these systems become\nincreasingly prevalent in various applications. Previous work has proveided\nexplanations for the actions or states of agents, yet falls short in\nunderstanding the black-boxed agent's importance within a MAS and the overall\nteam strategy. To bridge this gap, we propose EMAI, a novel agent-level\nexplanation approach that evaluates the individual agent's importance. Inspired\nby counterfactual reasoning, a larger change in reward caused by the randomized\naction of agent indicates its higher importance. We model it as a MARL problem\nto capture interactions across agents. Utilizing counterfactual reasoning, EMAI\nlearns the masking agents to identify important agents. Specifically, we define\nthe optimization function to minimize the reward difference before and after\naction randomization and introduce sparsity constraints to encourage the\nexploration of more action randomization of agents during training. The\nexperimental results in seven multi-agent tasks demonstratee that EMAI achieves\nhigher fidelity in explanations than baselines and provides more effective\nguidance in practical applications concerning understanding policies, launching\nattacks, and patching policies.",
      "tldr_zh": "这篇论文提出了一种名为 EMAI 的新方法，通过反事实推理来评估多智能体系统（MAS）中单个代理的重要性，填补了现有解释方法对代理重要性和团队策略的空白。EMAI 将问题建模为多智能体强化学习（MARL）问题，通过代理行动随机化来量化奖励变化，并引入优化函数最小化奖励差异以及稀疏性约束，以学习和识别关键代理。实验结果显示，在七个多智能体任务上，EMAI 比基线方法实现了更高的保真度（fidelity），并为理解策略、发起攻击和修复策略提供了更有效的实际指导。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15619v2",
      "published_date": "2024-12-20 07:24:43 UTC",
      "updated_date": "2024-12-23 01:56:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:55:05.541380"
    },
    {
      "arxiv_id": "2412.16257v2",
      "title": "PromptLA: Towards Integrity Verification of Black-box Text-to-Image Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuomeng Zhang",
        "Fangqi Li",
        "Chong Di",
        "Hongyu Zhu",
        "Hanyi Wang",
        "Shilin Wang"
      ],
      "abstract": "Despite the impressive synthesis quality of text-to-image (T2I) diffusion\nmodels, their black-box deployment poses significant regulatory challenges:\nMalicious actors can fine-tune these models to generate illegal content,\ncircumventing existing safeguards through parameter manipulation. Therefore, it\nis essential to verify the integrity of T2I diffusion models. To this end,\nconsidering the randomness within the outputs of generative models and the high\ncosts in interacting with them, we discern model tampering via the KL\ndivergence between the distributions of the features of generated images. We\npropose a novel prompt selection algorithm based on learning automaton\n(PromptLA) for efficient and accurate verification. Evaluations on four\nadvanced T2I models (e.g., SDXL, FLUX.1) demonstrate that our method achieves a\nmean AUC of over 0.96 in integrity detection, exceeding baselines by more than\n0.2, showcasing strong effectiveness and generalization. Additionally, our\napproach achieves lower cost and is robust against image-level post-processing.\nTo the best of our knowledge, this paper is the first work addressing the\nintegrity verification of T2I diffusion models, which establishes quantifiable\nstandards for AI copyright litigation in practice.",
      "tldr_zh": "该论文针对黑-box Text-to-Image (T2I) 扩散模型的完整性验证问题，提出了一种新型方法，以应对恶意篡改导致的非法内容生成。研究通过计算生成图像特征分布之间的 KL divergence 来检测模型篡改，并开发了基于学习自动机 (learning automaton) 的提示选择算法 PromptLA，实现高效准确的验证。实验在 SDXL 和 FLUX.1 等四种高级 T2I 模型上显示，该方法平均 AUC 超过 0.96，比基线提升 0.2 以上，同时成本更低且对图像后处理具有鲁棒性。作为首篇探讨 T2I 扩散模型完整性验证的论文，该工作为 AI 版权诉讼提供了可量化的标准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.16257v2",
      "published_date": "2024-12-20 07:24:32 UTC",
      "updated_date": "2025-03-28 08:39:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:55:16.768082"
    },
    {
      "arxiv_id": "2412.15616v1",
      "title": "Microservices-Based Framework for Predictive Analytics and Real-time Performance Enhancement in Travel Reservation Systems",
      "title_zh": "基于微服务的框架，用于旅行预订系统的预测分析和实时性能提升",
      "authors": [
        "Biman Barua",
        "M. Shamim Kaiser"
      ],
      "abstract": "The paper presents a framework of microservices-based architecture dedicated\nto enhancing the performance of real-time travel reservation systems using the\npower of predictive analytics. Traditional monolithic systems are bad at\nscaling and performing with high loads, causing backup resources to be\nunderutilized along with delays. To overcome the above-stated problems, we\nadopt a modularization approach in decoupling system components into\nindependent services that can grow or shrink according to demand. Our framework\nalso includes real-time predictive analytics, through machine learning models,\nthat optimize forecasting customer demand, dynamic pricing, as well as system\nperformance. With an experimental evaluation applying the approach, we could\nshow that the framework impacts metrics of performance such as response time,\nthroughput, transaction rate of success, and prediction accuracy compared to\ntheir conventional counterparts. Not only does the microservices approach\nimprove scalability and fault tolerance like a usual architecture, but it also\nbrings along timely and accurate predictions, which imply a greater customer\nsatisfaction and efficiency of operation. The integration of real-time\nanalytics would lead to more intelligent decision-making, thereby improving the\nresponse of the system along with the reliability it holds. A scalable,\nefficient framework is offered by such a system to address the modern\nchallenges imposed by any form of travel reservation system while considering\nother complex, data-driven industries as future applications. Future work will\nbe an investigation of advanced AI models and edge processing to further\nimprove the performance and robustness of the systems employed.",
      "tldr_zh": "这篇论文提出了一种基于 microservices 的框架，旨在通过 predictive analytics 提升旅行预订系统的实时性能，解决传统 monolithic systems 在高负载下的扩展性和延迟问题。该框架将系统组件解耦成独立服务，实现动态扩展，并整合机器学习模型进行实时预测分析，以优化客户需求预测、动态定价和系统性能。实验评估显示，与传统系统相比，该框架显著提高了响应时间、吞吐量、交易成功率和预测准确度，同时增强了可扩展性、容错性和客户满意度。未来工作将探索高级 AI 模型和边缘处理，进一步提升系统的鲁棒性和效率。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "10 Pages, 05 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15616v1",
      "published_date": "2024-12-20 07:19:42 UTC",
      "updated_date": "2024-12-20 07:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:55:29.515041"
    },
    {
      "arxiv_id": "2412.16256v1",
      "title": "Aria-UI: Visual Grounding for GUI Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Yang",
        "Yue Wang",
        "Dongxu Li",
        "Ziyang Luo",
        "Bei Chen",
        "Chao Huang",
        "Junnan Li"
      ],
      "abstract": "Digital agents for automating tasks across different platforms by directly\nmanipulating the GUIs are increasingly important. For these agents, grounding\nfrom language instructions to target elements remains a significant challenge\ndue to reliance on HTML or AXTree inputs. In this paper, we introduce Aria-UI,\na large multimodal model specifically designed for GUI grounding. Aria-UI\nadopts a pure-vision approach, eschewing reliance on auxiliary inputs. To adapt\nto heterogeneous planning instructions, we propose a scalable data pipeline\nthat synthesizes diverse and high-quality instruction samples for grounding. To\nhandle dynamic contexts in task performing, Aria-UI incorporates textual and\ntext-image interleaved action histories, enabling robust context-aware\nreasoning for grounding. Aria-UI sets new state-of-the-art results across\noffline and online agent benchmarks, outperforming both vision-only and\nAXTree-reliant baselines. We release all training data and model checkpoints to\nfoster further research at https://ariaui.github.io.",
      "tldr_zh": "该论文引入Aria-UI，一种针对GUI指令的视觉grounding大型多模态模型，旨在解决数字代理从语言指令到目标元素的定位挑战，而不依赖HTML或AXTree等辅助输入。Aria-UI采用纯视觉方法，并通过一个可扩展的数据管道合成多样高质量指令样本，同时整合文本和文本-图像交错的操作历史，以实现对动态上下文的鲁棒推理。在离线和在线代理基准测试中，Aria-UI超越了视觉-only和AXTree依赖基线，设置了新的最先进结果，并公开了训练数据和模型检查点以推动进一步研究。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16256v1",
      "published_date": "2024-12-20 07:16:57 UTC",
      "updated_date": "2024-12-20 07:16:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:55:39.865037"
    },
    {
      "arxiv_id": "2412.15610v1",
      "title": "A Fusion Approach of Dependency Syntax and Sentiment Polarity for Feature Label Extraction in Commodity Reviews",
      "title_zh": "翻译失败",
      "authors": [
        "Jianfei Xu"
      ],
      "abstract": "This study analyzes 13,218 product reviews from JD.com, covering four\ncategories: mobile phones, computers, cosmetics, and food. A novel method for\nfeature label extraction is proposed by integrating dependency parsing and\nsentiment polarity analysis. The proposed method addresses the challenges of\nlow robustness in existing extraction algorithms and significantly enhances\nextraction accuracy. Experimental results show that the method achieves an\naccuracy of 0.7, with recall and F-score both stabilizing at 0.8, demonstrating\nits effectiveness. However, challenges such as dependence on matching\ndictionaries and the limited scope of extracted feature tags require further\ninvestigation in future research.",
      "tldr_zh": "这篇论文分析了来自 JD.com 的 13,218 条商品评论，涵盖手机、电脑、化妆品和食品四大类别，并提出了一种新方法，将 dependency parsing 和 sentiment polarity analysis 融合，用于提取特征标签，以提升现有算法的鲁棒性。实验结果显示，该方法在准确率上达到 0.7，召回率和 F-score 均稳定在 0.8，显著提高了提取性能。然而，该方法依赖匹配字典且提取范围有限，这些挑战需在未来研究中进一步探讨。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15610v1",
      "published_date": "2024-12-20 07:07:18 UTC",
      "updated_date": "2024-12-20 07:07:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:55:52.789980"
    },
    {
      "arxiv_id": "2412.15606v2",
      "title": "Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool Usage",
      "title_zh": "多模态代理调优：构建 VLM 驱动的代理以实现高效工具使用",
      "authors": [
        "Zhi Gao",
        "Bofei Zhang",
        "Pengxiang Li",
        "Xiaojian Ma",
        "Tao Yuan",
        "Yue Fan",
        "Yuwei Wu",
        "Yunde Jia",
        "Song-Chun Zhu",
        "Qing Li"
      ],
      "abstract": "The advancement of large language models (LLMs) prompts the development of\nmulti-modal agents, which are used as a controller to call external tools,\nproviding a feasible way to solve practical tasks. In this paper, we propose a\nmulti-modal agent tuning method that automatically generates multi-modal\ntool-usage data and tunes a vision-language model (VLM) as the controller for\npowerful tool-usage reasoning. To preserve the data quality, we prompt the\nGPT-4o mini model to generate queries, files, and trajectories, followed by\nquery-file and trajectory verifiers. Based on the data synthesis pipeline, we\ncollect the MM-Traj dataset that contains 20K tasks with trajectories of tool\nusage. Then, we develop the T3-Agent via \\underline{T}rajectory\n\\underline{T}uning on VLMs for \\underline{T}ool usage using MM-Traj.\nEvaluations on the GTA and GAIA benchmarks show that the T3-Agent consistently\nachieves improvements on two popular VLMs: MiniCPM-V-8.5B and {Qwen2-VL-7B},\nwhich outperforms untrained VLMs by $20\\%$, showing the effectiveness of the\nproposed data synthesis pipeline, leading to high-quality data for tool-usage\ncapabilities.",
      "tldr_zh": "本研究提出了一种多模态代理调优方法，用于自动生成多模态工具使用数据，并将视觉语言模型 (VLM) 调优为高效工具使用控制器，以提升实际任务解决能力。方法包括使用 GPT-4o mini 模型生成查询、文件和轨迹，并通过查询-文件和轨迹验证器确保数据质量，从而构建了包含 20K 任务轨迹的 MM-Traj 数据集。基于此数据集，开发了 T3-Agent，通过轨迹调优 (Trajectory Tuning) 增强 VLM 的工具使用推理能力；在 GTA 和 GAIA 基准测试中，T3-Agent 使 MiniCPM-V-8.5B 和 Qwen2-VL-7B 模型的性能提高了 20%，验证了数据合成管道的有效性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025, https://mat-agent.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2412.15606v2",
      "published_date": "2024-12-20 07:00:46 UTC",
      "updated_date": "2025-02-03 12:56:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:56:05.753743"
    },
    {
      "arxiv_id": "2412.15598v2",
      "title": "Long-Term EEG Partitioning for Seizure Onset Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Chen",
        "Yasuko Matsubara",
        "Yasushi Sakurai",
        "Jimeng Sun"
      ],
      "abstract": "Deep learning models have recently shown great success in classifying\nepileptic patients using EEG recordings. Unfortunately, classification-based\nmethods lack a sound mechanism to detect the onset of seizure events. In this\nwork, we propose a two-stage framework, SODor, that explicitly models seizure\nonset through a novel task formulation of subsequence clustering. Given an EEG\nsequence, the framework first learns a set of second-level embeddings with\nlabel supervision. It then employs model-based clustering to explicitly capture\nlong-term temporal dependencies in EEG sequences and identify meaningful\nsubsequences. Epochs within a subsequence share a common cluster assignment\n(normal or seizure), with cluster or state transitions representing successful\nonset detections. Extensive experiments on three datasets demonstrate that our\nmethod can correct misclassifications, achieving 5\\%-11\\% classification\nimprovements over other baselines and accurately detecting seizure onsets.",
      "tldr_zh": "本文提出 SODor 框架，一种两阶段方法，用于检测 EEG 序列中的癫痫发作起点，通过子序列聚类任务显式建模长期时序依赖。框架首先学习第二-level embeddings 并使用标签监督，然后采用 model-based clustering 来识别有意义的子序列，其中子序列内的 epochs 共享聚类分配（normal 或 seizure），状态转换表示发作起点。实验在三个数据集上证明，该方法比基线模型提高了 5%-11% 的分类准确率，并有效修正误分类。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15598v2",
      "published_date": "2024-12-20 06:42:58 UTC",
      "updated_date": "2025-03-03 06:39:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:56:16.911856"
    },
    {
      "arxiv_id": "2412.15595v1",
      "title": "Mask-RadarNet: Enhancing Transformer With Spatial-Temporal Semantic Context for Radar Object Detection in Autonomous Driving",
      "title_zh": "Mask-RadarNet：利用空间-时间语义上下文增强 Transformer 用于自动驾驶中的雷达物体检测",
      "authors": [
        "Yuzhi Wu",
        "Jun Liu",
        "Guangfeng Jiang",
        "Weijian Liu",
        "Danilo Orlando"
      ],
      "abstract": "As a cost-effective and robust technology, automotive radar has seen steady\nimprovement during the last years, making it an appealing complement to\ncommonly used sensors like camera and LiDAR in autonomous driving. Radio\nfrequency data with rich semantic information are attracting more and more\nattention. Most current radar-based models take radio frequency image sequences\nas the input. However, these models heavily rely on convolutional neural\nnetworks and leave out the spatial-temporal semantic context during the\nencoding stage. To solve these problems, we propose a model called\nMask-RadarNet to fully utilize the hierarchical semantic features from the\ninput radar data. Mask-RadarNet exploits the combination of interleaved\nconvolution and attention operations to replace the traditional architecture in\ntransformer-based models. In addition, patch shift is introduced to the\nMask-RadarNet for efficient spatial-temporal feature learning. By shifting part\nof patches with a specific mosaic pattern in the temporal dimension,\nMask-RadarNet achieves competitive performance while reducing the computational\nburden of the spatial-temporal modeling. In order to capture the\nspatial-temporal semantic contextual information, we design the class masking\nattention module (CMAM) in our encoder. Moreover, a lightweight auxiliary\ndecoder is added to our model to aggregate prior maps generated from the CMAM.\nExperiments on the CRUW dataset demonstrate the superiority of the proposed\nmethod to some state-of-the-art radar-based object detection algorithms. With\nrelatively lower computational complexity and fewer parameters, the proposed\nMask-RadarNet achieves higher recognition accuracy for object detection in\nautonomous driving.",
      "tldr_zh": "这篇论文提出Mask-RadarNet模型，以提升Transformer在自动驾驶中的雷达物体检测性能，通过整合空间-时间语义上下文来解决现有模型依赖Convolutional Neural Networks (CNN)而忽略该上下文的问题。模型采用交错卷积和注意力操作替换传统架构，并引入patch shift技术以高效学习空间-时间特征，同时设计class masking attention module (CMAM)来捕获语义信息，并添加轻量级辅助解码器聚合先验地图。实验结果在CRUW数据集上表明，Mask-RadarNet比现有最先进雷达-based物体检测算法实现了更高的识别准确率，同时降低了计算复杂度和参数数量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15595v1",
      "published_date": "2024-12-20 06:39:40 UTC",
      "updated_date": "2024-12-20 06:39:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:56:29.410449"
    },
    {
      "arxiv_id": "2412.15593v1",
      "title": "Machine Learning Techniques for Pattern Recognition in High-Dimensional Data Mining",
      "title_zh": "机器学习技术在高维数据挖掘中的模式识别",
      "authors": [
        "Pochun Li"
      ],
      "abstract": "This paper proposes a frequent pattern data mining algorithm based on support\nvector machine (SVM), aiming to solve the performance bottleneck of traditional\nfrequent pattern mining algorithms in high-dimensional and sparse data\nenvironments. By converting the frequent pattern mining task into a\nclassification problem, the SVM model is introduced to improve the accuracy and\nrobustness of pattern extraction. In terms of method design, the kernel\nfunction is used to map the data to a high-dimensional feature space, so as to\nconstruct the optimal classification hyperplane, realize the nonlinear\nseparation of patterns and the accurate mining of frequent items. In the\nexperiment, two public datasets, Retail and Mushroom, were selected to compare\nand analyze the proposed algorithm with traditional FP-Growth, FP-Tree,\ndecision tree and random forest models. The experimental results show that the\nalgorithm in this paper is significantly better than the traditional model in\nterms of three key indicators: support, confidence and lift, showing strong\npattern recognition ability and rule extraction effect. The study shows that\nthe SVM model has excellent performance advantages in an environment with high\ndata sparsity and a large number of transactions, and can effectively cope with\ncomplex pattern mining tasks. At the same time, this paper also points out the\npotential direction of future research, including the introduction of deep\nlearning and ensemble learning frameworks to further improve the scalability\nand adaptability of the algorithm. This research not only provides a new idea\nfor frequent pattern mining, but also provides important technical support for\nsolving pattern discovery and association rule mining problems in practical\napplications.",
      "tldr_zh": "这篇论文提出了一种基于 Support Vector Machine (SVM) 的频繁模式数据挖掘算法，旨在解决传统算法在高维稀疏数据环境中的性能瓶颈，将频繁模式挖掘任务转化为分类问题以提升准确性和鲁棒性。该方法利用核函数将数据映射到高维特征空间，构建最优分类超平面，实现非线性模式分离和频繁项的精确挖掘。在实验中，使用 Retail 和 Mushroom 数据集与 FP-Growth、FP-Tree、决策树和随机森林模型比较，结果显示该算法在支持度、置信度和提升度等关键指标上显著优于传统模型，为高维数据挖掘提供新思路，并指出未来可引入深度学习和集成学习框架进一步提升算法的适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15593v1",
      "published_date": "2024-12-20 06:32:05 UTC",
      "updated_date": "2024-12-20 06:32:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:56:41.911527"
    },
    {
      "arxiv_id": "2412.15589v1",
      "title": "Pre-training Graph Neural Networks on Molecules by Using Subgraph-Conditioned Graph Information Bottleneck",
      "title_zh": "基于子图条件化图信息瓶颈在分子上预训练图神经网络",
      "authors": [
        "Van Thuy Hoang",
        "O-Joun Lee"
      ],
      "abstract": "This study aims to build a pre-trained Graph Neural Network (GNN) model on\nmolecules without human annotations or prior knowledge. Although various\nattempts have been proposed to overcome limitations in acquiring labeled\nmolecules, the previous pre-training methods still rely on semantic subgraphs,\ni.e., functional groups. Only focusing on the functional groups could overlook\nthe graph-level distinctions. The key challenge to build a pre-trained GNN on\nmolecules is how to (1) generate well-distinguished graph-level representations\nand (2) automatically discover the functional groups without prior knowledge.\nTo solve it, we propose a novel Subgraph-conditioned Graph Information\nBottleneck, named S-CGIB, for pre-training GNNs to recognize core subgraphs\n(graph cores) and significant subgraphs. The main idea is that the graph cores\ncontain compressed and sufficient information that could generate\nwell-distinguished graph-level representations and reconstruct the input graph\nconditioned on significant subgraphs across molecules under the S-CGIB\nprinciple. To discover significant subgraphs without prior knowledge about\nfunctional groups, we propose generating a set of functional group candidates,\ni.e., ego networks, and using an attention-based interaction between the graph\ncore and the candidates. Despite being identified from self-supervised\nlearning, our learned subgraphs match the real-world functional groups.\nExtensive experiments on molecule datasets across various domains demonstrate\nthe superiority of S-CGIB.",
      "tldr_zh": "本研究旨在在分子上预训练 Graph Neural Network (GNN) 模型，而不依赖人类标注或先验知识，以克服现有方法对语义子图（如功能基团）的依赖，从而忽略图级差异。论文提出 Subgraph-conditioned Graph Information Bottleneck (S-CGIB) 方法，通过识别核心子图（graph cores）和重要子图来生成区分度高的图级表示，并使用注意力机制在图核心与功能基团候选（如 ego networks）之间交互，实现自动发现子图。实验结果表明，S-CGIB 在各种分子数据集上表现出优越性，且从自监督学习中获得的子图与真实功能基团高度匹配。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.15589v1",
      "published_date": "2024-12-20 05:52:30 UTC",
      "updated_date": "2024-12-20 05:52:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:56:54.646218"
    },
    {
      "arxiv_id": "2412.15579v1",
      "title": "Score-based Generative Diffusion Models for Social Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyi Liu",
        "Jiahao Zhang",
        "Shijie Wang",
        "Wenqi Fan",
        "Qing Li"
      ],
      "abstract": "With the prevalence of social networks on online platforms, social\nrecommendation has become a vital technique for enhancing personalized\nrecommendations. The effectiveness of social recommendations largely relies on\nthe social homophily assumption, which presumes that individuals with social\nconnections often share similar preferences. However, this foundational premise\nhas been recently challenged due to the inherent complexity and noise present\nin real-world social networks. In this paper, we tackle the low social\nhomophily challenge from an innovative generative perspective, directly\ngenerating optimal user social representations that maximize consistency with\ncollaborative signals. Specifically, we propose the Score-based Generative\nModel for Social Recommendation (SGSR), which effectively adapts the Stochastic\nDifferential Equation (SDE)-based diffusion models for social recommendations.\nTo better fit the recommendation context, SGSR employs a joint curriculum\ntraining strategy to mitigate challenges related to missing supervision signals\nand leverages self-supervised learning techniques to align knowledge across\nsocial and collaborative domains. Extensive experiments on real-world datasets\ndemonstrate the effectiveness of our approach in filtering redundant social\ninformation and improving recommendation performance.",
      "tldr_zh": "这篇论文针对社交推荐中的低社交同质性（social homophily）挑战，提出从生成视角直接生成最优用户社交表示，以最大化与协作信号的一致性。作者开发了 Score-based Generative Model for Social Recommendation (SGSR)，该模型基于 Stochastic Differential Equation (SDE) 的扩散模型，并采用联合课程训练策略和自监督学习技术来应对缺失监督信号和跨领域知识对齐问题。通过在真实数据集上的广泛实验，SGSR 证明了其在过滤冗余社交信息和提升推荐性能方面的有效性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "14 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15579v1",
      "published_date": "2024-12-20 05:23:45 UTC",
      "updated_date": "2024-12-20 05:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:57:05.785577"
    },
    {
      "arxiv_id": "2412.15571v1",
      "title": "Continual Learning Using a Kernel-Based Method Over Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Saleh Momeni",
        "Sahisnu Mazumder",
        "Bing Liu"
      ],
      "abstract": "Continual learning (CL) learns a sequence of tasks incrementally. This paper\nstudies the challenging CL setting of class-incremental learning (CIL). CIL has\ntwo key challenges: catastrophic forgetting (CF) and inter-task class\nseparation (ICS). Despite numerous proposed methods, these issues remain\npersistent obstacles. This paper proposes a novel CIL method, called Kernel\nLinear Discriminant Analysis (KLDA), that can effectively avoid CF and ICS\nproblems. It leverages only the powerful features learned in a foundation model\n(FM). However, directly using these features proves suboptimal. To address\nthis, KLDA incorporates the Radial Basis Function (RBF) kernel and its Random\nFourier Features (RFF) to enhance the feature representations from the FM,\nleading to improved performance. When a new task arrives, KLDA computes only\nthe mean for each class in the task and updates a shared covariance matrix for\nall learned classes based on the kernelized features. Classification is\nperformed using Linear Discriminant Analysis. Our empirical evaluation using\ntext and image classification datasets demonstrates that KLDA significantly\noutperforms baselines. Remarkably, without relying on replay data, KLDA\nachieves accuracy comparable to joint training of all classes, which is\nconsidered the upper bound for CIL performance. The KLDA code is available at\nhttps://github.com/salehmomeni/klda.",
      "tldr_zh": "这篇论文针对 Class-Incremental Learning (CIL) 中的 Catastrophic Forgetting (CF) 和 Inter-Task Class Separation (ICS) 问题，提出了一种名为 Kernel Linear Discriminant Analysis (KLDA) 的新方法，利用 Foundation Models (FM) 学到的特征作为基础。KLDA 通过引入 Radial Basis Function (RBF) kernel 和 Random Fourier Features (RFF) 来增强特征表示，并在新任务到来时仅计算每个类的均值并更新共享协方差矩阵，以进行 Linear Discriminant Analysis 分类。实验在文本和图像分类数据集上显示，KLDA 显著优于基线模型，且无需依赖重放数据，其准确率可媲美所有类联合训练的性能上限。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15571v1",
      "published_date": "2024-12-20 05:09:18 UTC",
      "updated_date": "2024-12-20 05:09:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:57:19.857642"
    },
    {
      "arxiv_id": "2412.15563v1",
      "title": "In-context Continual Learning Assisted by an External Continual Learner",
      "title_zh": "由外部持续学习器辅助的上下文持续学习",
      "authors": [
        "Saleh Momeni",
        "Sahisnu Mazumder",
        "Zixuan Ke",
        "Bing Liu"
      ],
      "abstract": "Existing continual learning (CL) methods mainly rely on fine-tuning or\nadapting large language models (LLMs). They still suffer from catastrophic\nforgetting (CF). Little work has been done to exploit in-context learning (ICL)\nto leverage the extensive knowledge within LLMs for CL without updating any\nparameters. However, incrementally learning each new task in ICL necessitates\nadding training examples from each class of the task to the prompt, which\nhampers scalability as the prompt length increases. This issue not only leads\nto excessively long prompts that exceed the input token limit of the underlying\nLLM but also degrades the model's performance due to the overextended context.\nTo address this, we introduce InCA, a novel approach that integrates an\nexternal continual learner (ECL) with ICL to enable scalable CL without CF. The\nECL is built incrementally to pre-select a small subset of likely classes for\neach test instance. By restricting the ICL prompt to only these selected\nclasses, InCA prevents prompt lengths from becoming excessively long, while\nmaintaining high performance. Experimental results demonstrate that InCA\nsignificantly outperforms existing CL baselines, achieving substantial\nperformance gains.",
      "tldr_zh": "本文研究了持续学习 (CL) 的挑战，特别是大型语言模型 (LLMs) 面临的灾难性遗忘 (CF) 问题，以及 in-context learning (ICL) 在处理新任务时因提示过长而导致的可伸缩性问题。论文提出 InCA，一种创新方法，将外部持续学习器 (ECL) 与 ICL 整合：ECL 逐步构建以预选测试实例的少量可能类，从而限制 ICL 提示长度，同时保持高性能。实验结果表明，InCA 显著优于现有 CL 基准，实现了实质性的性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15563v1",
      "published_date": "2024-12-20 04:44:41 UTC",
      "updated_date": "2024-12-20 04:44:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:57:30.092410"
    },
    {
      "arxiv_id": "2412.15554v3",
      "title": "Architecture-Aware Learning Curve Extrapolation via Graph Ordinary Differential Equation",
      "title_zh": "翻译失败",
      "authors": [
        "Yanna Ding",
        "Zijie Huang",
        "Xiao Shou",
        "Yihang Guo",
        "Yizhou Sun",
        "Jianxi Gao"
      ],
      "abstract": "Learning curve extrapolation predicts neural network performance from early\ntraining epochs and has been applied to accelerate AutoML, facilitating\nhyperparameter tuning and neural architecture search. However, existing methods\ntypically model the evolution of learning curves in isolation, neglecting the\nimpact of neural network (NN) architectures, which influence the loss landscape\nand learning trajectories. In this work, we explore whether incorporating\nneural network architecture improves learning curve modeling and how to\neffectively integrate this architectural information. Motivated by the\ndynamical system view of optimization, we propose a novel architecture-aware\nneural differential equation model to forecast learning curves continuously. We\nempirically demonstrate its ability to capture the general trend of fluctuating\nlearning curves while quantifying uncertainty through variational parameters.\nOur model outperforms current state-of-the-art learning curve extrapolation\nmethods and pure time-series modeling approaches for both MLP and CNN-based\nlearning curves. Additionally, we explore the applicability of our method in\nNeural Architecture Search scenarios, such as training configuration ranking.",
      "tldr_zh": "本研究针对现有学习曲线外推方法忽略神经网络架构的影响问题，提出了一种基于Graph Ordinary Differential Equation的架构感知神经微分方程模型，用于从早期训练阶段连续预测神经网络性能。该模型从优化过程的动态系统视角出发，整合架构信息以捕捉学习曲线的总体趋势，并通过变分参数量化不确定性。实验结果显示，该方法在MLP和CNN学习曲线上优于现有状态-of-the-art方法，并在Neural Architecture Search场景中表现出色，例如训练配置排名。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI'25",
      "pdf_url": "http://arxiv.org/pdf/2412.15554v3",
      "published_date": "2024-12-20 04:28:02 UTC",
      "updated_date": "2025-01-19 02:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:57:41.062071"
    },
    {
      "arxiv_id": "2412.16252v1",
      "title": "Post-hoc Interpretability Illumination for Scientific Interaction Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Ling Zhang",
        "Zhichao Hou",
        "Tingxiang Ji",
        "Yuanyuan Xu",
        "Runze Li"
      ],
      "abstract": "Model interpretability and explainability have garnered substantial attention\nin recent years, particularly in decision-making applications. However,\nexisting interpretability tools often fall short in delivering satisfactory\nperformance due to limited capabilities or efficiency issues. To address these\nchallenges, we propose a novel post-hoc method: Iterative Kings' Forests (iKF),\ndesigned to uncover complex multi-order interactions among variables. iKF\niteratively selects the next most important variable, the \"King\", and\nconstructs King's Forests by placing it at the root node of each tree to\nidentify variables that interact with the \"King\". It then generates ranked\nshort lists of important variables and interactions of varying orders.\nAdditionally, iKF provides inference metrics to analyze the patterns of the\nselected interactions and classify them into one of three interaction types:\nAccompanied Interaction, Synergistic Interaction, and Hierarchical Interaction.\nExtensive experiments demonstrate the strong interpretive power of our proposed\niKF, highlighting its great potential for explainable modeling and scientific\ndiscovery across diverse scientific fields.",
      "tldr_zh": "本研究针对现有模型可解释性工具的性能和效率不足，提出了一种后验方法：Iterative Kings' Forests (iKF)，用于揭示变量间的复杂多阶交互。iKF 通过迭代选择最重要的变量（“King”）并构建 King's Forests，将其置于树根节点，以识别与 King 交互的变量，并生成排序的变量和交互列表。方法还提供推理指标来分析交互模式，并将它们分类为 Accompanied Interaction、Synergistic Interaction 或 Hierarchical Interaction。实验结果证明，iKF 在可解释建模和科学发现领域表现出强大的解释力，具有广泛的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16252v1",
      "published_date": "2024-12-20 04:17:12 UTC",
      "updated_date": "2024-12-20 04:17:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:57:53.054924"
    },
    {
      "arxiv_id": "2412.15547v1",
      "title": "NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zheyuan Zhang",
        "Yiyang Li",
        "Nhi Ha Lan Le",
        "Zehong Wang",
        "Tianyi Ma",
        "Vincent Galassi",
        "Keerthiram Murugesan",
        "Nuno Moniz",
        "Werner Geyer",
        "Nitesh V Chawla",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "abstract": "Diet plays a critical role in human health, yet tailoring dietary reasoning\nto individual health conditions remains a major challenge. Nutrition Question\nAnswering (QA) has emerged as a popular method for addressing this problem.\nHowever, current research faces two critical limitations. On one hand, the\nabsence of datasets involving user-specific medical information severely limits\n\\textit{personalization}. This challenge is further compounded by the wide\nvariability in individual health needs. On the other hand, while large language\nmodels (LLMs), a popular solution for this task, demonstrate strong reasoning\nabilities, they struggle with the domain-specific complexities of personalized\nhealthy dietary reasoning, and existing benchmarks fail to capture these\nchallenges. To address these gaps, we introduce the Nutritional Graph Question\nAnswering (NGQA) benchmark, the first graph question answering dataset designed\nfor personalized nutritional health reasoning. NGQA leverages data from the\nNational Health and Nutrition Examination Survey (NHANES) and the Food and\nNutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is\nhealthy for a specific user, supported by explanations of the key contributing\nnutrients. The benchmark incorporates three question complexity settings and\nevaluates reasoning across three downstream tasks. Extensive experiments with\nLLM backbones and baseline models demonstrate that the NGQA benchmark\neffectively challenges existing models. In sum, NGQA addresses a critical\nreal-world problem while advancing GraphQA research with a novel\ndomain-specific benchmark.",
      "tldr_zh": "该论文介绍了 NGQA 基准，这是一个针对个性化健康营养推理的 Graph Question Answering 数据集，旨在解决现有 Nutrition QA 方法在个性化饮食推荐方面的局限性，如缺乏用户特定医疗信息和 LLMs 在领域复杂性上的不足。NGQA 利用 National Health and Nutrition Examination Survey (NHANES) 和 Food and Nutrient Database for Dietary Studies (FNDDS) 数据，评估特定食物对用户的健康影响，并提供关键营养素解释，支持三种问题复杂性和三种下游任务。实验结果表明，NGQA 有效挑战现有模型，包括 LLMs 和基线系统，从而推动 GraphQA 研究在实际健康应用中的进展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15547v1",
      "published_date": "2024-12-20 04:13:46 UTC",
      "updated_date": "2024-12-20 04:13:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:58:06.295062"
    },
    {
      "arxiv_id": "2412.15544v1",
      "title": "VLM-RL: A Unified Vision Language Models and Reinforcement Learning Framework for Safe Autonomous Driving",
      "title_zh": "VLM-RL：一种统一的视觉语言模型与强化学习框架，用于安全自动驾驶",
      "authors": [
        "Zilin Huang",
        "Zihao Sheng",
        "Yansong Qu",
        "Junwei You",
        "Sikai Chen"
      ],
      "abstract": "In recent years, reinforcement learning (RL)-based methods for learning\ndriving policies have gained increasing attention in the autonomous driving\ncommunity and have achieved remarkable progress in various driving scenarios.\nHowever, traditional RL approaches rely on manually engineered rewards, which\nrequire extensive human effort and often lack generalizability. To address\nthese limitations, we propose \\textbf{VLM-RL}, a unified framework that\nintegrates pre-trained Vision-Language Models (VLMs) with RL to generate reward\nsignals using image observation and natural language goals. The core of VLM-RL\nis the contrasting language goal (CLG)-as-reward paradigm, which uses positive\nand negative language goals to generate semantic rewards. We further introduce\na hierarchical reward synthesis approach that combines CLG-based semantic\nrewards with vehicle state information, improving reward stability and offering\na more comprehensive reward signal. Additionally, a batch-processing technique\nis employed to optimize computational efficiency during training. Extensive\nexperiments in the CARLA simulator demonstrate that VLM-RL outperforms\nstate-of-the-art baselines, achieving a 10.5\\% reduction in collision rate, a\n104.6\\% increase in route completion rate, and robust generalization to unseen\ndriving scenarios. Furthermore, VLM-RL can seamlessly integrate almost any\nstandard RL algorithms, potentially revolutionizing the existing RL paradigm\nthat relies on manual reward engineering and enabling continuous performance\nimprovements. The demo video and code can be accessed at:\nhttps://zilin-huang.github.io/VLM-RL-website.",
      "tldr_zh": "该研究提出 VLM-RL 框架，将预训练的 Vision-Language Models (VLMs) 与 Reinforcement Learning (RL) 整合，用于实现安全的自动驾驶。该框架采用 contrasting language goal (CLG)-as-reward 范式，通过正负语言目标生成语义奖励，并结合分层奖励合成方法和车辆状态信息，提高奖励的稳定性和全面性，同时使用批量处理技术优化训练效率。在 CARLA 模拟器实验中，VLM-RL 相较于现有基线，降低了 10.5% 的碰撞率，提高了 104.6% 的路线完成率，并展示了在未见场景中的鲁棒泛化能力。该框架可无缝整合标准 RL 算法，潜在地取代依赖手动奖励工程的传统范式，促进自动驾驶性能的持续提升。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "28 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15544v1",
      "published_date": "2024-12-20 04:08:11 UTC",
      "updated_date": "2024-12-20 04:08:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:58:18.710691"
    },
    {
      "arxiv_id": "2412.15541v1",
      "title": "ChangeDiff: A Multi-Temporal Change Detection Data Generator with Flexible Text Prompts via Diffusion Model",
      "title_zh": "ChangeDiff：一种通过扩散模型的多时态变化检测数据生成器，带有灵活的文本提示",
      "authors": [
        "Qi Zang",
        "Jiayi Yang",
        "Shuang Wang",
        "Dong Zhao",
        "Wenjun Yi",
        "Zhun Zhong"
      ],
      "abstract": "Data-driven deep learning models have enabled tremendous progress in change\ndetection (CD) with the support of pixel-level annotations. However, collecting\ndiverse data and manually annotating them is costly, laborious, and\nknowledge-intensive. Existing generative methods for CD data synthesis show\ncompetitive potential in addressing this issue but still face the following\nlimitations: 1) difficulty in flexibly controlling change events, 2) dependence\non additional data to train the data generators, 3) focus on specific change\ndetection tasks. To this end, this paper focuses on the semantic CD (SCD) task\nand develops a multi-temporal SCD data generator ChangeDiff by exploring\npowerful diffusion models. ChangeDiff innovatively generates change data in two\nsteps: first, it uses text prompts and a text-to-layout (T2L) model to create\ncontinuous layouts, and then it employs layout-to-image (L2I) to convert these\nlayouts into images. Specifically, we propose multi-class distribution-guided\ntext prompts (MCDG-TP), allowing for layouts to be generated flexibly through\ncontrollable classes and their corresponding ratios. Subsequently, to\ngeneralize the T2L model to the proposed MCDG-TP, a class distribution\nrefinement loss is further designed as training supervision. %For the former, a\nmulti-classdistribution-guided text prompt (MCDG-TP) is proposed to complement\nvia controllable classes and ratios. To generalize the text-to-image diffusion\nmodel to the proposed MCDG-TP, a class distribution refinement loss is designed\nas training supervision. For the latter, MCDG-TP in three modes is proposed to\nsynthesize new layout masks from various texts. Our generated data shows\nsignificant progress in temporal continuity, spatial diversity, and quality\nrealism, empowering change detectors with accuracy and transferability. The\ncode is available at https://github.com/DZhaoXd/ChangeDiff",
      "tldr_zh": "该论文提出ChangeDiff，一种基于扩散模型的多时态变化检测数据生成器，旨在解决现有方法在灵活控制变化事件、依赖额外数据训练和任务特定性方面的局限性。ChangeDiff针对语义变化检测(SCD)任务，通过文本提示和文本到布局(T2L)模型生成连续布局，然后使用布局到图像(L2I)模型转换为图像；同时引入多类分布引导文本提示(MCDG-TP)和类分布精炼损失(class distribution refinement loss)来实现可控类和比率的布局生成。实验结果显示，该方法生成的數據在时态连续性、空间多样性和质量真实性上取得显著进步，提升了变化检测器的准确性和可转移性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15541v1",
      "published_date": "2024-12-20 03:58:28 UTC",
      "updated_date": "2024-12-20 03:58:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:58:29.761629"
    },
    {
      "arxiv_id": "2412.15538v2",
      "title": "FedRLHF: A Convergence-Guaranteed Federated Framework for Privacy-Preserving and Personalized RLHF",
      "title_zh": "翻译失败",
      "authors": [
        "Flint Xiaofeng Fan",
        "Cheston Tan",
        "Yew-Soon Ong",
        "Roger Wattenhofer",
        "Wei-Tsang Ooi"
      ],
      "abstract": "In the era of increasing privacy concerns and demand for personalized\nexperiences, traditional Reinforcement Learning with Human Feedback (RLHF)\nframeworks face significant challenges due to their reliance on centralized\ndata. We introduce Federated Reinforcement Learning with Human Feedback\n(FedRLHF), a novel framework that decentralizes the RLHF process. FedRLHF\nenables collaborative policy learning across multiple clients without\nnecessitating the sharing of raw data or human feedback, thereby ensuring\nrobust privacy preservation. Leveraging federated reinforcement learning, each\nclient integrates human feedback locally into their reward functions and\nupdates their policies through personalized RLHF processes. We establish\nrigorous theoretical foundations for FedRLHF, providing convergence guarantees,\nand deriving sample complexity bounds that scale efficiently with the number of\nclients. Empirical evaluations on the MovieLens and IMDb datasets demonstrate\nthat FedRLHF not only preserves user privacy but also achieves performance on\npar with centralized RLHF, while enhancing personalization across diverse\nclient environments.",
      "tldr_zh": "本研究提出 FedRLHF，一种联邦化框架，用于实现隐私保护和个性化的 Reinforcement Learning with Human Feedback (RLHF)。该框架允许多个客户端在不共享原始数据或人类反馈的情况下，通过 Federated Reinforcement Learning 进行协作策略学习，每个客户端在本地整合人类反馈到奖励函数并更新个性化策略。论文建立了严格的理论基础，包括收敛保证和样本复杂度边界，这些边界能高效扩展到多个客户端。实证评估在 MovieLens 和 IMDb 数据集上显示，FedRLHF 实现了与集中式 RLHF 相当的性能，同时增强了个性化并有效保护用户隐私。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "Updated for AAMAS 2025 camera-ready. This preprint represents the\n  full version of the paper, including all proofs, experimental details, and\n  additional discussions",
      "pdf_url": "http://arxiv.org/pdf/2412.15538v2",
      "published_date": "2024-12-20 03:56:31 UTC",
      "updated_date": "2025-02-08 02:34:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:58:41.714016"
    },
    {
      "arxiv_id": "2412.15537v1",
      "title": "Enhancing Large-scale UAV Route Planing with Global and Local Features via Reinforcement Graph Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Zhou",
        "Kai Ye",
        "Zeyu Shi",
        "Jiajing Lin",
        "Dejun Xu",
        "Min Jiang"
      ],
      "abstract": "Numerous remarkable advancements have been made in accuracy, speed, and\nparallelism for solving the Unmanned Aerial Vehicle Route Planing (UAVRP).\nHowever, existing UAVRP solvers face challenges when attempting to scale\neffectively and efficiently for larger instances. In this paper, we present a\ngeneralization framework that enables current UAVRP solvers to robustly extend\ntheir capabilities to larger instances, accommodating up to 10,000 points,\nusing widely recognized test sets. The UAVRP under a large number of patrol\npoints is a typical large-scale TSP problem.Our proposed framework comprises\nthree distinct steps. Firstly, we employ Delaunay triangulation to extract\nsubgraphs from large instances while preserving global features. Secondly, we\nutilize an embedded TSP solver to obtain sub-results, followed by graph fusion.\nFinally, we implement a decoding strategy customizable to the user's\nrequirements, resulting in high-quality solutions, complemented by a warming-up\nprocess for the heatmap. To demonstrate the flexibility of our approach, we\nintegrate two representative TSP solvers into our framework and conduct a\ncomprehensive comparative analysis against existing algorithms using large TSP\nbenchmark datasets. The results unequivocally demonstrate that our framework\nefficiently scales existing TSP solvers to handle large instances and\nconsistently outperforms state-of-the-art (SOTA) methods. Furthermore, since\nour proposed framework does not necessitate additional training or fine-tuning,\nwe believe that its generality can significantly advance research on end-to-end\nUAVRP solvers, enabling the application of a broader range of methods to\nreal-world scenarios.",
      "tldr_zh": "本研究提出了一种框架，用于增强大规模无人机路径规划（UAVRP），通过强化图融合（Reinforcement Graph Fusion）整合全局和局部特征，使现有求解器能处理多达10,000个点的实例。框架包括三个关键步骤：首先，使用Delaunay triangulation提取子图以保留全局特征；其次，应用嵌入的TSP求解器获取子结果并进行图融合；最后，实施可自定义的解码策略并添加热图预热过程。实验结果显示，该框架将两个代表性TSP求解器集成后，在大型TSP基准数据集上比现有最先进（SOTA）方法性能更优，并无需额外训练或微调，从而提升UAVRP求解器的通用性和实际应用潜力。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15537v1",
      "published_date": "2024-12-20 03:54:43 UTC",
      "updated_date": "2024-12-20 03:54:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:58:53.923907"
    },
    {
      "arxiv_id": "2412.15532v1",
      "title": "Improved Forecasts of Global Extreme Marine Heatwaves Through a Physics-guided Data-driven Approach",
      "title_zh": "通过物理指导的数据",
      "authors": [
        "Ruiqi Shu",
        "Hao Wu",
        "Yuan Gao",
        "Fanghua Xu",
        "Ruijian Gou",
        "Xiaomeng Huang"
      ],
      "abstract": "The unusually warm sea surface temperature events known as marine heatwaves\n(MHWs) have a profound impact on marine ecosystems. Accurate prediction of\nextreme MHWs has significant scientific and financial worth. However, existing\nmethods still have certain limitations, especially in the most extreme MHWs. In\nthis study, to address these issues, based on the physical nature of MHWs, we\ncreated a novel deep learning neural network that is capable of accurate 10-day\nMHW forecasting. Our framework significantly improves the forecast ability of\nextreme MHWs through two specially designed modules inspired by numerical\nmodels: a coupler and a probabilistic data argumentation. The coupler simulates\nthe driving effect of atmosphere on MHWs while the probabilistic data\nargumentation approaches significantly boost the forecast ability of extreme\nMHWs based on the idea of ensemble forecast. Compared with traditional\nnumerical prediction, our framework has significantly higher accuracy and\nrequires fewer computational resources. What's more, explainable AI methods\nshow that wind forcing is the primary driver of MHW evolution and reveal its\nrelation with air-sea heat exchange. Overall, our model provides a framework\nfor understanding MHWs' driving processes and operational forecasts in the\nfuture.",
      "tldr_zh": "本研究针对海洋热浪（MHWs）的预测挑战，提出了一种基于物理引导的数据驱动深度学习框架，能够实现10天极端MHWs的高精度预报。该框架通过coupler模块模拟大气对MHWs的驱动作用，以及probabilistic data argumentation模块基于集合预报理念提升极端事件的预测能力，与传统数值模型相比显著提高了准确性并减少了计算资源需求。实验结果显示，该方法揭示了风力作为MHW演化过程的主要驱动因素，并阐明了其与空气-海热交换的关系。总体上，该框架为理解MHWs驱动机制和未来操作预报提供了新途径。",
      "categories": [
        "physics.ao-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15532v1",
      "published_date": "2024-12-20 03:47:56 UTC",
      "updated_date": "2024-12-20 03:47:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:59:06.076084"
    },
    {
      "arxiv_id": "2412.15529v3",
      "title": "XRAG: eXamining the Core -- Benchmarking Foundational Components in Advanced Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Qianren Mao",
        "Yangyifei Luo",
        "Qili Zhang",
        "Yashuo Luo",
        "Zhilong Cao",
        "Jinlong Zhang",
        "HanWen Hao",
        "Zhijun Chen",
        "Weifeng Jiang",
        "Junnan Liu",
        "Xiaolong Wang",
        "Zhenting Huang",
        "Zhixing Tan",
        "Sun Jie",
        "Bo Li",
        "Xudong Liu",
        "Richong Zhang",
        "Jianxin Li"
      ],
      "abstract": "Retrieval-augmented generation (RAG) synergizes the retrieval of pertinent\ndata with the generative capabilities of Large Language Models (LLMs), ensuring\nthat the generated output is not only contextually relevant but also accurate\nand current. We introduce XRAG, an open-source, modular codebase that\nfacilitates exhaustive evaluation of the performance of foundational components\nof advanced RAG modules. These components are systematically categorized into\nfour core phases: pre-retrieval, retrieval, post-retrieval, and generation. We\nsystematically analyse them across reconfigured datasets, providing a\ncomprehensive benchmark for their effectiveness. As the complexity of RAG\nsystems continues to escalate, we underscore the critical need to identify\npotential failure points in RAG systems. We formulate a suite of experimental\nmethodologies and diagnostic testing protocols to dissect the failure points\ninherent in RAG engineering. Subsequently, we proffer bespoke solutions aimed\nat bolstering the overall performance of these modules. Our work thoroughly\nevaluates the performance of advanced core components in RAG systems, providing\ninsights into optimizations for prevalent failure points.",
      "tldr_zh": "本研究引入了 XRAG，这是一个开源、模块化的代码库，用于全面基准测试高级 Retrieval-Augmented Generation (RAG) 系统的核心组件，这些组件被系统分为 pre-retrieval、retrieval、post-retrieval 和 generation 四个阶段。XRAG 通过重新配置的数据集进行系统分析，评估这些组件的性能，并识别 RAG 系统中的潜在失败点。论文制定了实验方法和诊断测试协议，提供针对性解决方案，以优化 RAG 系统的整体表现，并为提升其准确性和相关性提供关键见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15529v3",
      "published_date": "2024-12-20 03:37:07 UTC",
      "updated_date": "2025-05-16 14:13:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:59:18.519287"
    },
    {
      "arxiv_id": "2412.15525v1",
      "title": "Generalized Back-Stepping Experience Replay in Sparse-Reward Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Guwen Lyu",
        "Masahiro Sato"
      ],
      "abstract": "Back-stepping experience replay (BER) is a reinforcement learning technique\nthat can accelerate learning efficiency in reversible environments. BER trains\nan agent with generated back-stepping transitions of collected experiences and\nnormal forward transitions. However, the original algorithm is designed for a\ndense-reward environment that does not require complex exploration, limiting\nthe BER technique to demonstrate its full potential. Herein, we propose an\nenhanced version of BER called Generalized BER (GBER), which extends the\noriginal algorithm to sparse-reward environments, particularly those with\ncomplex structures that require the agent to explore. GBER improves the\nperformance of BER by introducing relabeling mechanism and applying diverse\nsampling strategies. We evaluate our modified version, which is based on a\ngoal-conditioned deep deterministic policy gradient offline learning algorithm,\nacross various maze navigation environments. The experimental results indicate\nthat the GBER algorithm can significantly boost the performance and stability\nof the baseline algorithm in various sparse-reward environments, especially\nthose with highly structural symmetricity.",
      "tldr_zh": "该研究提出 Generalized Back-Stepping Experience Replay (GBER)，一种扩展版强化学习技术，用于处理稀疏奖励环境中的复杂探索问题，以克服原始 Back-Stepping Experience Replay (BER) 在密集奖励环境下的局限性。GBER 通过引入 relabeling 机制和多样化采样策略，并基于 goal-conditioned deep deterministic policy gradient 离线学习算法，生成回溯过渡和正向过渡来提升代理的学习效率。实验结果显示，在各种迷宫导航环境中，GBER 显著提高了基线算法的性能和稳定性，尤其在高度结构对称的环境中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15525v1",
      "published_date": "2024-12-20 03:31:23 UTC",
      "updated_date": "2024-12-20 03:31:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:59:30.100585"
    },
    {
      "arxiv_id": "2412.15524v2",
      "title": "HREF: Human Response-Guided Evaluation of Instruction Following in Language Models",
      "title_zh": "HREF：人类响应",
      "authors": [
        "Xinxi Lyu",
        "Yizhong Wang",
        "Hannaneh Hajishirzi",
        "Pradeep Dasigi"
      ],
      "abstract": "Evaluating the capability of Large Language Models (LLMs) in following\ninstructions has heavily relied on a powerful LLM as the judge, introducing\nunresolved biases that deviate the judgments from human judges. In this work,\nwe reevaluate various choices for automatic evaluation on a wide range of\ninstruction-following tasks. We experiment with methods that leverage\nhuman-written responses and observe that they enhance the reliability of\nautomatic evaluations across a wide range of tasks, resulting in up to a 3.2%\nimprovement in agreement with human judges. We also discovered that\nhuman-written responses offer an orthogonal perspective to model-generated\nresponses in following instructions and should be used as an additional context\nwhen comparing model responses. Based on these observations, we develop a new\nevaluation benchmark, Human Response-Guided Evaluation of Instruction Following\n(HREF), comprising 4,258 samples across 11 task categories with a composite\nevaluation setup, employing a composite evaluation setup that selects the most\nreliable method for each category. In addition to providing reliable\nevaluation, HREF emphasizes individual task performance and is free from\ncontamination. Finally, we study the impact of key design choices in HREF,\nincluding the size of the evaluation set, the judge model, the baseline model,\nand the prompt template. We host a live leaderboard that evaluates LLMs on the\nprivate evaluation set of HREF.",
      "tldr_zh": "本文提出了一种基于人类响应引导的评估方法（HREF），用于评估大型语言模型（LLMs）在指令遵循方面的能力，以减少依赖LLM评判引入的偏差。通过实验发现，利用人类编写的响应能显著提升自动评估的可靠性，与人类评判一致性提高多达3.2%。HREF基准包括4258个样本和11个任务类别，采用复合评估设置，强调个体任务性能，并提供实时排行榜以避免污染和评估关键设计选择。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15524v2",
      "published_date": "2024-12-20 03:26:47 UTC",
      "updated_date": "2025-03-24 19:31:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:59:41.910170"
    },
    {
      "arxiv_id": "2412.15523v2",
      "title": "InstructOCR: Instruction Boosting Scene Text Spotting",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Duan",
        "Qianyi Jiang",
        "Pei Fu",
        "Jiamin Chen",
        "Shengxi Li",
        "Zining Wang",
        "Shan Guo",
        "Junfeng Luo"
      ],
      "abstract": "In the field of scene text spotting, previous OCR methods primarily relied on\nimage encoders and pre-trained text information, but they often overlooked the\nadvantages of incorporating human language instructions. To address this gap,\nwe propose InstructOCR, an innovative instruction-based scene text spotting\nmodel that leverages human language instructions to enhance the understanding\nof text within images. Our framework employs both text and image encoders\nduring training and inference, along with instructions meticulously designed\nbased on text attributes. This approach enables the model to interpret text\nmore accurately and flexibly. Extensive experiments demonstrate the\neffectiveness of our model and we achieve state-of-the-art results on widely\nused benchmarks. Furthermore, the proposed framework can be seamlessly applied\nto scene text VQA tasks. By leveraging instruction strategies during\npre-training, the performance on downstream VQA tasks can be significantly\nimproved, with a 2.6% increase on the TextVQA dataset and a 2.1% increase on\nthe ST-VQA dataset. These experimental results provide insights into the\nbenefits of incorporating human language instructions for OCR-related tasks.",
      "tldr_zh": "该论文提出 InstructOCR，一种创新的基于指令的场景文本识别模型，通过整合人类语言指令来提升图像中文本的理解和准确性，解决传统 OCR 方法忽略指令优势的问题。模型在训练和推理中使用文本和图像编码器，并设计基于文本属性的指令策略，使其更灵活地处理文本。实验结果显示，InstructOCR 在标准基准上达到最先进性能，并在场景文本 VQA 任务中显著提升下游表现，包括 TextVQA 数据集提高 2.6% 和 ST-VQA 数据集提高 2.1%。这项工作证明了在 OCR 相关任务中融入人类语言指令的显著益处。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15523v2",
      "published_date": "2024-12-20 03:23:26 UTC",
      "updated_date": "2025-01-13 10:01:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:59:54.030544"
    },
    {
      "arxiv_id": "2501.14747v1",
      "title": "Enhancing Green Economy with Artificial Intelligence: Role of Energy Use and FDI in the United States",
      "title_zh": "翻译失败",
      "authors": [
        "Abdullah Al Abrar Chowdhury",
        "Azizul Hakim Rafi",
        "Adita Sultana",
        "Abdulla All Noman"
      ],
      "abstract": "The escalating challenge of climate change necessitates an urgent exploration\nof factors influencing carbon emissions. This study contributes to the\ndiscourse by examining the interplay of technological, economic, and\ndemographic factors on environmental sustainability. This study investigates\nthe impact of artificial intelligence (AI) innovation, economic growth, foreign\ndirect investment (FDI), energy consumption, and urbanization on CO2 emissions\nin the United States from 1990 to 2022. Employing the ARDL framework integrated\nwith the STIRPAT model, the findings reveal a dual narrative: while AI\ninnovation mitigates environmental stress, economic growth, energy use, FDI,\nand urbanization exacerbate environmental degradation. Unit root tests (ADF,\nPP, and DF-GLS) confirm mixed integration levels among variables, and the ARDL\nbounds test establishes long-term co-integration. The analysis highlights that\nAI innovation positively correlates with CO2 reduction when environmental\nsafeguards are in place, whereas GDP growth, energy consumption, FDI, and\nurbanization intensify CO2 emissions. Robustness checks using FMOLS, DOLS, and\nCCR validate the ARDL findings. Additionally, Pairwise Granger causality tests\nreveal significant one-way causal links between CO2 emissions and economic\ngrowth, AI innovation, energy use, FDI, and urbanization. These relationships\nemphasize the critical role of AI-driven technological advancements,\nsustainable investments, and green energy in fostering ecological\nsustainability. The study suggests policy measures such as encouraging green\nFDI, advancing AI technologies, adopting sustainable energy practices, and\nimplementing eco-friendly urban development to promote sustainable growth in\nthe USA.",
      "tldr_zh": "本研究考察了人工智能（AI）创新、经济增长、外商直接投资（FDI）、能源消耗和城市化对美国 1990-2022 年 CO2 排放的影响，使用 ARDL 框架结合 STIRPAT 模型进行分析。结果显示，AI 创新有助于减少 CO2 排放，而经济增长、能源使用、FDI 和城市化则加剧了环境退化。稳健性检查（如 FMOLS、DOLS 和 CCR）及 Granger 因果关系测试确认了这些关系，强调 AI 驱动的技术进步和可持续投资的重要性。该研究建议政策措施，包括鼓励绿色 FDI、推广 AI 技术、采用可持续能源和推动生态友好型城市发展，以促进美国的绿色经济转型。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "22 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2501.14747v1",
      "published_date": "2024-12-20 03:03:21 UTC",
      "updated_date": "2024-12-20 03:03:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:00:05.567861"
    },
    {
      "arxiv_id": "2412.15511v1",
      "title": "RESQUE: Quantifying Estimator to Task and Distribution Shift for Sustainable Model Reusability",
      "title_zh": "翻译失败",
      "authors": [
        "Vishwesh Sangarya",
        "Jung-Eun Kim"
      ],
      "abstract": "As a strategy for sustainability of deep learning, reusing an existing model\nby retraining it rather than training a new model from scratch is critical. In\nthis paper, we propose REpresentation Shift QUantifying Estimator (RESQUE), a\npredictive quantifier to estimate the retraining cost of a model to\ndistributional shifts or change of tasks. It provides a single concise index\nfor an estimate of resources required for retraining the model. Through\nextensive experiments, we show that RESQUE has a strong correlation with\nvarious retraining measures. Our results validate that RESQUE is an effective\nindicator in terms of epochs, gradient norms, changes of parameter magnitude,\nenergy, and carbon emissions. These measures align well with RESQUE for new\ntasks, multiple noise types, and varying noise intensities. As a result, RESQUE\nenables users to make informed decisions for retraining to different\ntasks/distribution shifts and determine the most cost-effective and sustainable\noption, allowing for the reuse of a model with a much smaller footprint in the\nenvironment. The code for this work is available here:\nhttps://github.com/JEKimLab/AAAI2025RESQUE",
      "tldr_zh": "本研究提出 RESQUE，一种量化估计器，用于评估深度学习模型在面对任务变化或 distribution shift 时，重训练的资源成本，从而促进模型的可持续重用。RESQUE 通过提供一个简洁的指标，预测重训练所需的 epochs、梯度范数、参数变化、能量和碳排放等措施，并在广泛实验中显示出与这些指标的强相关性。结果表明，RESQUE 能帮助用户在不同任务或噪声类型下做出明智决策，选择最经济环保的重训练选项，显著降低环境足迹。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "The Annual AAAI Conference on Artificial Intelligence (AAAI), 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15511v1",
      "published_date": "2024-12-20 02:55:07 UTC",
      "updated_date": "2024-12-20 02:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:00:16.972981"
    },
    {
      "arxiv_id": "2412.15501v1",
      "title": "Humanlike Cognitive Patterns as Emergent Phenomena in Large Language Models",
      "title_zh": "人类般的认知模式作为大型语言模型中的涌现现象",
      "authors": [
        "Zhisheng Tang",
        "Mayank Kejriwal"
      ],
      "abstract": "Research on emergent patterns in Large Language Models (LLMs) has gained\nsignificant traction in both psychology and artificial intelligence, motivating\nthe need for a comprehensive review that offers a synthesis of this complex\nlandscape. In this article, we systematically review LLMs' capabilities across\nthree important cognitive domains: decision-making biases, reasoning, and\ncreativity. We use empirical studies drawing on established psychological tests\nand compare LLMs' performance to human benchmarks. On decision-making, our\nsynthesis reveals that while LLMs demonstrate several human-like biases, some\nbiases observed in humans are absent, indicating cognitive patterns that only\npartially align with human decision-making. On reasoning, advanced LLMs like\nGPT-4 exhibit deliberative reasoning akin to human System-2 thinking, while\nsmaller models fall short of human-level performance. A distinct dichotomy\nemerges in creativity: while LLMs excel in language-based creative tasks, such\nas storytelling, they struggle with divergent thinking tasks that require\nreal-world context. Nonetheless, studies suggest that LLMs hold considerable\npotential as collaborators, augmenting creativity in human-machine\nproblem-solving settings. Discussing key limitations, we also offer guidance\nfor future research in areas such as memory, attention, and open-source model\ndevelopment.",
      "tldr_zh": "这篇论文系统回顾了大型语言模型 (LLMs) 在决策偏差、推理和创造力等认知领域的表现，通过实证研究和心理测试与人类基准进行比较。研究发现，LLMs 在决策上显示部分人类-like 偏差，在推理上高级模型如 GPT-4 接近人类 System-2 思考，但创造力方面更擅长语言任务（如讲故事）而非需要真实世界上下文的发散性思考。尽管存在局限性，LLMs 作为合作者可增强人类-机器问题解决，并为未来研究如记忆、注意力和开源模型开发提供指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15501v1",
      "published_date": "2024-12-20 02:26:56 UTC",
      "updated_date": "2024-12-20 02:26:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:00:30.918863"
    },
    {
      "arxiv_id": "2412.15499v3",
      "title": "A Robust Prototype-Based Network with Interpretable RBF Classifier Foundations",
      "title_zh": "翻译失败",
      "authors": [
        "Sascha Saralajew",
        "Ashish Rana",
        "Thomas Villmann",
        "Ammar Shaker"
      ],
      "abstract": "Prototype-based classification learning methods are known to be inherently\ninterpretable. However, this paradigm suffers from major limitations compared\nto deep models, such as lower performance. This led to the development of the\nso-called deep Prototype-Based Networks (PBNs), also known as prototypical\nparts models. In this work, we analyze these models with respect to different\nproperties, including interpretability. In particular, we focus on the\nClassification-by-Components (CBC) approach, which uses a probabilistic model\nto ensure interpretability and can be used as a shallow or deep architecture.\nWe show that this model has several shortcomings, like creating contradicting\nexplanations. Based on these findings, we propose an extension of CBC that\nsolves these issues. Moreover, we prove that this extension has robustness\nguarantees and derive a loss that optimizes robustness. Additionally, our\nanalysis shows that most (deep) PBNs are related to (deep) RBF classifiers,\nwhich implies that our robustness guarantees generalize to shallow RBF\nclassifiers. The empirical evaluation demonstrates that our deep PBN yields\nstate-of-the-art classification accuracy on different benchmarks while\nresolving the interpretability shortcomings of other approaches. Further, our\nshallow PBN variant outperforms other shallow PBNs while being inherently\ninterpretable and exhibiting provable robustness guarantees.",
      "tldr_zh": "这篇论文分析了原型-based 分类方法的可解释性优势，但其性能不如深度模型，并针对 Classification-by-Components (CBC) 模型的缺点（如创建矛盾解释）提出一个扩展版本。扩展的 CBC 模型解决了这些问题，提供鲁棒性保证，并推导了一个优化鲁棒性的损失函数，同时证明大多数 (深度) Prototype-Based Networks (PBNs) 与 (深度) RBF 分类器相关，从而推广了这些保证。实验结果显示，该深度 PBN 在不同基准上达到最先进分类准确率，而浅层 PBN 变体则优于其他浅层方法，具有内在可解释性和可证明的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear at AAAI 2025. Includes the Appendix of the AAAI submission.\n  In v2, the font size has been increased in some figures. In v3, an incorrect\n  hyperparameter specification (Table 6; $\\lambda$) has been corrected",
      "pdf_url": "http://arxiv.org/pdf/2412.15499v3",
      "published_date": "2024-12-20 02:25:31 UTC",
      "updated_date": "2025-04-17 14:56:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:00:43.305001"
    },
    {
      "arxiv_id": "2412.15498v1",
      "title": "The First Multilingual Model For The Detection of Suicide Texts",
      "title_zh": "首个用于检测自杀文本的多语言模型",
      "authors": [
        "Rodolfo Zevallos",
        "Annika Schoene",
        "John E. Ortega"
      ],
      "abstract": "Suicidal ideation is a serious health problem affecting millions of people\nworldwide. Social networks provide information about these mental health\nproblems through users' emotional expressions. We propose a multilingual model\nleveraging transformer architectures like mBERT, XML-R, and mT5 to detect\nsuicidal text across posts in six languages - Spanish, English, German,\nCatalan, Portuguese and Italian. A Spanish suicide ideation tweet dataset was\ntranslated into five other languages using SeamlessM4T. Each model was\nfine-tuned on this multilingual data and evaluated across classification\nmetrics. Results showed mT5 achieving the best performance overall with F1\nscores above 85%, highlighting capabilities for cross-lingual transfer\nlearning. The English and Spanish translations also displayed high quality\nbased on perplexity. Our exploration underscores the importance of considering\nlinguistic diversity in developing automated multilingual tools to identify\nsuicidal risk. Limitations exist around semantic fidelity in translations and\nethical implications which provide guidance for future human-in-the-loop\nevaluations.",
      "tldr_zh": "本研究提出首个多语言模型，用于检测六种语言（西班牙语、英语、德语、加泰罗尼亚语、葡萄牙语和意大利语）的自杀文本，基于 transformer 架构如 mBERT、XML-R 和 mT5。研究团队使用 SeamlessM4T 将西班牙语自杀意念推文数据集翻译成其他语言，并对模型进行微调和分类指标评估。结果显示，mT5 表现出色，F1 scores 超过 85%，证明了跨语言转移学习的能力，同时英语和西班牙语翻译的质量通过 perplexity 评估显示较高。总体而言，该工作强调了在开发自动多语言自杀风险识别工具中考虑语言多样性的重要性，但也指出了翻译语义保真度和伦理影响的潜在局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "SUMEval-2: The 2nd Workshop on Scaling Up Multilingual &\n  Multi-Cultural Evaluation at the 31st International Conference on\n  Computational Linguistics (COLING 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.15498v1",
      "published_date": "2024-12-20 02:23:59 UTC",
      "updated_date": "2024-12-20 02:23:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:00:55.481850"
    },
    {
      "arxiv_id": "2412.15497v1",
      "title": "Lexicography Saves Lives (LSL): Automatically Translating Suicide-Related Language",
      "title_zh": "Lexicography Saves Lives (LSL)：自动翻译与自杀相关的语言",
      "authors": [
        "Annika Marie Schoene",
        "John E. Ortega",
        "Rodolfo Joel Zevallos",
        "Laura Haaber Ihle"
      ],
      "abstract": "Recent years have seen a marked increase in research that aims to identify or\npredict risk, intention or ideation of suicide. The majority of new tasks,\ndatasets, language models and other resources focus on English and on suicide\nin the context of Western culture. However, suicide is global issue and\nreducing suicide rate by 2030 is one of the key goals of the UN's Sustainable\nDevelopment Goals. Previous work has used English dictionaries related to\nsuicide to translate into different target languages due to lack of other\navailable resources. Naturally, this leads to a variety of ethical tensions\n(e.g.: linguistic misrepresentation), where discourse around suicide is not\npresent in a particular culture or country. In this work, we introduce the\n'Lexicography Saves Lives Project' to address this issue and make three\ndistinct contributions. First, we outline ethical consideration and provide\noverview guidelines to mitigate harm in developing suicide-related resources.\nNext, we translate an existing dictionary related to suicidal ideation into 200\ndifferent languages and conduct human evaluations on a subset of translated\ndictionaries. Finally, we introduce a public website to make our resources\navailable and enable community participation.",
      "tldr_zh": "这篇论文介绍了“Lexicography Saves Lives (LSL)”项目，旨在解决自杀相关语言翻译中的伦理问题，如文化误传，并扩展到全球范围。研究团队首先概述了伦理考虑并提供指导方针，以减少开发自杀相关资源时的潜在伤害；其次，将现有的自杀意念(suicidal ideation)词典自动翻译成200种语言，并对部分翻译进行人类评估。最终，他们推出了一个公共网站，使这些资源公开可用并鼓励社区参与，从而支持联合国减少自杀率的可持续发展目标。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The 31st International Conference on Computational Linguistics\n  (COLING 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.15497v1",
      "published_date": "2024-12-20 02:23:36 UTC",
      "updated_date": "2024-12-20 02:23:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:01:07.268876"
    },
    {
      "arxiv_id": "2412.15495v1",
      "title": "TL-Training: A Task-Feature-Based Framework for Training Large Language Models in Tool Use",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Ye",
        "Yilong Wu",
        "Sixian Li",
        "Yuming Yang",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang",
        "Peng Wang",
        "Zhongchao Shi",
        "Jianping Fan",
        "Zhengyin Du"
      ],
      "abstract": "Large language models (LLMs) achieve remarkable advancements by leveraging\ntools to interact with external environments, a critical step toward\ngeneralized AI. However, the standard supervised fine-tuning (SFT) approach,\nwhich relies on large-scale datasets, often overlooks task-specific\ncharacteristics in tool use, leading to performance bottlenecks. To address\nthis issue, we analyze three existing LLMs and uncover key insights: training\ndata can inadvertently impede tool-use behavior, token importance is\ndistributed unevenly, and errors in tool calls fall into a small set of\ndistinct categories. Building on these findings, we propose TL-Training, a\ntask-feature-based framework that mitigates the effects of suboptimal training\ndata, dynamically adjusts token weights to prioritize key tokens during SFT,\nand incorporates a robust reward mechanism tailored to error categories,\noptimized through proximal policy optimization. We validate TL-Training by\ntraining CodeLLaMA-2-7B and evaluating it on four diverse open-source test\nsets. Our results demonstrate that the LLM trained by our method matches or\nsurpasses both open- and closed-source LLMs in tool-use performance using only\n1,217 training data points. Additionally, our method enhances robustness in\nnoisy environments and improves general task performance, offering a scalable\nand efficient paradigm for tool-use training in LLMs. The code and data are\navailable at https://github.com/Junjie-Ye/TL-Training.",
      "tldr_zh": "本文提出TL-Training框架，一种基于任务特征的任务-特征框架，用于优化大型语言模型(LLMs)在工具使用中的训练，以解决标准监督微调(SFT)忽略任务特定特征导致的性能瓶颈问题。该框架通过分析训练数据对工具使用行为的影响、动态调整标记权重以及针对工具调用错误类别的奖励机制（结合近端策略优化Proximal Policy Optimization）来提升训练效率。实验结果显示，在训练CodeLLaMA-2-7B模型时，仅使用1217个数据点，该方法就使模型在四个测试集上的工具使用性能匹配或超过其他开源和闭源LLMs，同时提高了在嘈杂环境中的鲁棒性和整体任务表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15495v1",
      "published_date": "2024-12-20 02:21:36 UTC",
      "updated_date": "2024-12-20 02:21:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:01:20.078978"
    },
    {
      "arxiv_id": "2412.15483v1",
      "title": "Task-Specific Preconditioner for Cross-Domain Few-Shot Learning",
      "title_zh": "针对跨域少样本学习的任务特定预条件器",
      "authors": [
        "Suhyun Kang",
        "Jungwon Park",
        "Wonseok Lee",
        "Wonjong Rhee"
      ],
      "abstract": "Cross-Domain Few-Shot Learning~(CDFSL) methods typically parameterize models\nwith task-agnostic and task-specific parameters. To adapt task-specific\nparameters, recent approaches have utilized fixed optimization strategies,\ndespite their potential sub-optimality across varying domains or target tasks.\nTo address this issue, we propose a novel adaptation mechanism called\nTask-Specific Preconditioned gradient descent~(TSP). Our method first\nmeta-learns Domain-Specific Preconditioners~(DSPs) that capture the\ncharacteristics of each meta-training domain, which are then linearly combined\nusing task-coefficients to form the Task-Specific Preconditioner. The\npreconditioner is applied to gradient descent, making the optimization adaptive\nto the target task. We constrain our preconditioners to be positive definite,\nguiding the preconditioned gradient toward the direction of steepest descent.\nEmpirical evaluations on the Meta-Dataset show that TSP achieves\nstate-of-the-art performance across diverse experimental scenarios.",
      "tldr_zh": "本论文针对Cross-Domain Few-Shot Learning (CDFSL)中任务特定参数的适应问题，提出了一种新机制Task-Specific Preconditioned gradient descent (TSP)，以解决现有固定优化策略的局限性。TSP首先通过meta-learning获取Domain-Specific Preconditioners (DSPs)来捕捉每个meta-training领域的特性，然后使用任务系数线性组合这些DSPs形成任务特定预处理器，并将其应用于gradient descent，使优化过程更适应目标任务，同时约束预处理器为正定矩阵以确保梯度朝向最陡下降方向。实验结果显示，在Meta-Dataset上的多种场景中，TSP实现了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15483v1",
      "published_date": "2024-12-20 01:33:43 UTC",
      "updated_date": "2024-12-20 01:33:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:01:31.615617"
    },
    {
      "arxiv_id": "2412.15479v1",
      "title": "Continual Learning Using Only Large Language Model Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Jiabao Qiu",
        "Zixuan Ke",
        "Bing Liu"
      ],
      "abstract": "We introduce CLOB, a novel continual learning (CL) paradigm wherein a large\nlanguage model (LLM) is regarded as a black box. Learning is done incrementally\nvia only verbal prompting. CLOB does not fine-tune any part of the LLM or add\nany trainable parameters to it. It is particularly suitable for LLMs that are\naccessible via APIs. We also propose a new CL technique, called CIS, based on\nincremental summarization that also overcomes the LLM's input length limit.\nExperiments show CIS outperforms baselines by a very large margin.",
      "tldr_zh": "这篇论文引入了 CLOB，一种新型持续学习（continual learning）范式，仅通过语言提示对大型语言模型（LLM）进行增量学习，而不需微调模型或添加任何可训练参数，特别适合通过 API 访问的 LLM。论文还提出了一种新技巧 CIS，基于增量总结（incremental summarization）来克服 LLM 的输入长度限制。实验结果显示，CIS 比基线方法有显著优势，性能大幅提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To Appear in COLING-2025 (short paper)",
      "pdf_url": "http://arxiv.org/pdf/2412.15479v1",
      "published_date": "2024-12-20 01:21:57 UTC",
      "updated_date": "2024-12-20 01:21:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:01:41.991583"
    },
    {
      "arxiv_id": "2412.15477v1",
      "title": "Difficulty-aware Balancing Margin Loss for Long-tailed Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Minseok Son",
        "Inyong Koo",
        "Jinyoung Park",
        "Changick Kim"
      ],
      "abstract": "When trained with severely imbalanced data, deep neural networks often\nstruggle to accurately recognize classes with only a few samples. Previous\nstudies in long-tailed recognition have attempted to rebalance biased learning\nusing known sample distributions, primarily addressing different classification\ndifficulties at the class level. However, these approaches often overlook the\ninstance difficulty variation within each class. In this paper, we propose a\ndifficulty-aware balancing margin (DBM) loss, which considers both class\nimbalance and instance difficulty. DBM loss comprises two components: a\nclass-wise margin to mitigate learning bias caused by imbalanced class\nfrequencies, and an instance-wise margin assigned to hard positive samples\nbased on their individual difficulty. DBM loss improves class discriminativity\nby assigning larger margins to more difficult samples. Our method seamlessly\ncombines with existing approaches and consistently improves performance across\nvarious long-tailed recognition benchmarks.",
      "tldr_zh": "这篇论文针对长尾识别(long-tailed recognition)问题，提出了一种difficulty-aware balancing margin (DBM) loss，以同时处理类不平衡和实例难度差异。DBM loss 包含 class-wise margin 来缓解因样本频率不均导致的学习偏差，以及 instance-wise margin 来为困难正样本分配更大的边距，从而提升类别的区分性。该方法与现有方法无缝结合，并在各种长尾识别基准上 consistently improves performance。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15477v1",
      "published_date": "2024-12-20 01:11:30 UTC",
      "updated_date": "2024-12-20 01:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:01:54.956472"
    },
    {
      "arxiv_id": "2412.16248v1",
      "title": "Optimizing Low-Speed Autonomous Driving: A Reinforcement Learning Approach to Route Stability and Maximum Speed",
      "title_zh": "翻译失败",
      "authors": [
        "Benny Bao-Sheng Li",
        "Elena Wu",
        "Hins Shao-Xuan Yang",
        "Nicky Yao-Jin Liang"
      ],
      "abstract": "Autonomous driving has garnered significant attention in recent years,\nespecially in optimizing vehicle performance under varying conditions. This\npaper addresses the challenge of maintaining maximum speed stability in\nlow-speed autonomous driving while following a predefined route. Leveraging\nreinforcement learning (RL), we propose a novel approach to optimize driving\npolicies that enable the vehicle to achieve near-maximum speed without\ncompromising on safety or route accuracy, even in low-speed scenarios.",
      "tldr_zh": "这篇论文针对低速自动驾驶中的路线稳定性和最大速度优化问题，提出了一种基于强化学习（RL）的创新方法。研究利用 RL 算法优化驾驶策略，使车辆能够在低速场景下实现接近最大速度，同时保持安全性和路线准确性。总体而言，该方法为自动驾驶性能提升提供了新的解决方案，尤其适用于复杂交通条件。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16248v1",
      "published_date": "2024-12-20 01:06:41 UTC",
      "updated_date": "2024-12-20 01:06:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:02:06.419885"
    },
    {
      "arxiv_id": "2501.10391v1",
      "title": "Developing an Ontology for AI Act Fundamental Rights Impact Assessments",
      "title_zh": "开发 AI Act 基本权利影响评估的本体",
      "authors": [
        "Tytti Rintamaki",
        "Harshvardhan J. Pandit"
      ],
      "abstract": "The recently published EU Artificial Intelligence Act (AI Act) is a landmark\nregulation that regulates the use of AI technologies. One of its novel\nrequirements is the obligation to conduct a Fundamental Rights Impact\nAssessment (FRIA), where organisations in the role of deployers must assess the\nrisks of their AI system regarding health, safety, and fundamental rights.\nAnother novelty in the AI Act is the requirement to create a questionnaire and\nan automated tool to support organisations in their FRIA obligations. Such\nautomated tools will require a machine-readable form of information involved\nwithin the FRIA process, and additionally also require machine-readable\ndocumentation to enable further compliance tools to be created. In this\narticle, we present our novel representation of the FRIA as an ontology based\non semantic web standards. Our work builds upon the existing state of the art,\nnotably the Data Privacy Vocabulary (DPV), where similar works have been\nestablished to create tools for GDPR's Data Protection Impact Assessments\n(DPIA) and other obligations. Through our ontology, we enable the creation and\nmanagement of FRIA, and the use of automated tool in its various steps.",
      "tldr_zh": "欧盟 AI Act 要求组织进行 Fundamental Rights Impact Assessment (FRIA)，以评估 AI 系统对健康、安全和基本权利的风险。本文开发了一个基于语义网络标准的 ontology，用于机器可读形式表示 FRIA 过程，并构建于现有 Data Privacy Vocabulary (DPV) 之上，类似于 GDPR 的 Data Protection Impact Assessments (DPIA) 工具。该 ontology 启用 FRIA 的创建、管理和自动化支持，从而帮助组织简化合规流程并开发进一步的合规工具。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Presented at CLAIRvoyant (ConventicLE on Artificial Intelligence\n  Regulation) Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.10391v1",
      "published_date": "2024-12-20 00:37:33 UTC",
      "updated_date": "2024-12-20 00:37:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:02:18.367792"
    },
    {
      "arxiv_id": "2412.15467v1",
      "title": "Non-Uniform Parameter-Wise Model Merging",
      "title_zh": "非均匀参数",
      "authors": [
        "Albert Manuel Orozco Camacho",
        "Stefan Horoi",
        "Guy Wolf",
        "Eugene Belilovsky"
      ],
      "abstract": "Combining multiple machine learning models has long been a technique for\nenhancing performance, particularly in distributed settings. Traditional\napproaches, such as model ensembles, work well, but are expensive in terms of\nmemory and compute. Recently, methods based on averaging model parameters have\nachieved good results in some settings and have gained popularity. However,\nmerging models initialized differently that do not share a part of their\ntraining trajectories can yield worse results than simply using the base\nmodels, even after aligning their neurons. In this paper, we introduce a novel\napproach, Non-uniform Parameter-wise Model Merging, or NP Merge, which merges\nmodels by learning the contribution of each parameter to the final model using\ngradient-based optimization. We empirically demonstrate the effectiveness of\nour method for merging models of various architectures in multiple settings,\noutperforming past methods. We also extend NP Merge to handle the merging of\nmultiple models, showcasing its scalability and robustness.",
      "tldr_zh": "本论文提出了一种新型模型合并方法，名为 Non-uniform Parameter-wise Model Merging (NP Merge)，通过 gradient-based optimization 学习每个参数的贡献，以解决传统 model ensembles 方法在内存和计算资源上的高消耗问题。该方法能够有效合并初始化不同或训练轨迹不共享的模型，并在多种架构和设置下表现出色，优于现有技术。此外，NP Merge 扩展到多个模型的合并，展示了其可扩展性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 1 figure, to be published in the Proceedings of the 9th IEEE\n  Special Session on Machine Learning on Big Data (MLBD 2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.15467v1",
      "published_date": "2024-12-20 00:05:14 UTC",
      "updated_date": "2024-12-20 00:05:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:02:31.374980"
    },
    {
      "arxiv_id": "2412.16247v2",
      "title": "Towards scientific discovery with dictionary learning: Extracting biological concepts from microscopy foundation models",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantin Donhauser",
        "Kristina Ulicna",
        "Gemma Elyse Moran",
        "Aditya Ravuri",
        "Kian Kenyon-Dean",
        "Cian Eastwood",
        "Jason Hartford"
      ],
      "abstract": "Dictionary learning (DL) has emerged as a powerful interpretability tool for\nlarge language models. By extracting known concepts (e.g., Golden-Gate Bridge)\nfrom human-interpretable data (e.g., text), sparse DL can elucidate a model's\ninner workings. In this work, we ask if DL can also be used to discover unknown\nconcepts from less human-interpretable scientific data (e.g., cell images),\nultimately enabling modern approaches to scientific discovery. As a first step,\nwe use DL algorithms to study microscopy foundation models trained on\nmulti-cell image data, where little prior knowledge exists regarding which\nhigh-level concepts should arise. We show that sparse dictionaries indeed\nextract biologically-meaningful concepts such as cell type and genetic\nperturbation type. We also propose Iterative Codebook Feature Learning~(ICFL)\nand combine it with a pre-processing step which uses PCA whitening from a\ncontrol dataset. In our experiments, we demonstrate that both ICFL and PCA\nimprove the selectivity of extracted features compared to TopK sparse\nautoencoders.",
      "tldr_zh": "本研究探讨了 dictionary learning (DL) 在科学发现中的潜力，旨在从显微镜基础模型中提取未知生物概念，从而揭示细胞图像等非易解释数据的内在模式。研究者应用稀疏 DL 算法分析训练于多细胞图像数据的模型，发现它能成功提取生物学上有意义的特征，如细胞类型和遗传扰动类型。作者提出 Iterative Codebook Feature Learning (ICFL) 并结合 PCA whitening 预处理步骤，实验结果显示这些方法比 TopK sparse autoencoders 显著提高了提取特征的选择性，为基于现代 AI 的科学发现提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16247v2",
      "published_date": "2024-12-20 00:01:16 UTC",
      "updated_date": "2025-02-11 16:54:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:02:43.783908"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 120,
  "processed_papers_count": 120,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T16:03:04.125753"
}