[
  {
    "arxiv_id": "2402.01728v1",
    "title": "Hardware Phi-1.5B: A Large Language Model Encodes Hardware Domain Specific Knowledge",
    "authors": [
      "Weimin Fu",
      "Shijie Li",
      "Yifang Zhao",
      "Haocheng Ma",
      "Raj Dutta",
      "Xuan Zhang",
      "Kaichen Yang",
      "Yier Jin",
      "Xiaolong Guo"
    ],
    "abstract": "In the rapidly evolving semiconductor industry, where research, design,\nverification, and manufacturing are intricately linked, the potential of Large\nLanguage Models to revolutionize hardware design and security verification is\nimmense. The primary challenge, however, lies in the complexity of hardware\nspecific issues that are not adequately addressed by the natural language or\nsoftware code knowledge typically acquired during the pretraining stage.\nAdditionally, the scarcity of datasets specific to the hardware domain poses a\nsignificant hurdle in developing a foundational model. Addressing these\nchallenges, this paper introduces Hardware Phi 1.5B, an innovative large\nlanguage model specifically tailored for the hardware domain of the\nsemiconductor industry. We have developed a specialized, tiered dataset\ncomprising small, medium, and large subsets and focused our efforts on\npretraining using the medium dataset. This approach harnesses the compact yet\nefficient architecture of the Phi 1.5B model. The creation of this first\npretrained, hardware domain specific large language model marks a significant\nadvancement, offering improved performance in hardware design and verification\ntasks and illustrating a promising path forward for AI applications in the\nsemiconductor sector.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01728v1",
    "published_date": "2024-01-27 22:49:43 UTC",
    "updated_date": "2024-01-27 22:49:43 UTC"
  },
  {
    "arxiv_id": "2401.15509v1",
    "title": "Style-News: Incorporating Stylized News Generation and Adversarial Verification for Neural Fake News Detection",
    "authors": [
      "Wei-Yao Wang",
      "Yu-Chieh Chang",
      "Wen-Chih Peng"
    ],
    "abstract": "With the improvements in generative models, the issues of producing\nhallucinations in various domains (e.g., law, writing) have been brought to\npeople's attention due to concerns about misinformation. In this paper, we\nfocus on neural fake news, which refers to content generated by neural networks\naiming to mimic the style of real news to deceive people. To prevent harmful\ndisinformation spreading fallaciously from malicious social media (e.g.,\ncontent farms), we propose a novel verification framework, Style-News, using\npublisher metadata to imply a publisher's template with the corresponding text\ntypes, political stance, and credibility. Based on threat modeling aspects, a\nstyle-aware neural news generator is introduced as an adversary for generating\nnews content conditioning for a specific publisher, and style and source\ndiscriminators are trained to defend against this attack by identifying which\npublisher the style corresponds with, and discriminating whether the source of\nthe given news is human-written or machine-generated. To evaluate the quality\nof the generated content, we integrate various dimensional metrics (language\nfluency, content preservation, and style adherence) and demonstrate that\nStyle-News significantly outperforms the previous approaches by a margin of\n0.35 for fluency, 15.24 for content, and 0.38 for style at most. Moreover, our\ndiscriminative model outperforms state-of-the-art baselines in terms of\npublisher prediction (up to 4.64%) and neural fake news detection (+6.94%\n$\\sim$ 31.72%).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "EACL 2024 Main Track",
    "pdf_url": "http://arxiv.org/pdf/2401.15509v1",
    "published_date": "2024-01-27 21:35:29 UTC",
    "updated_date": "2024-01-27 21:35:29 UTC"
  },
  {
    "arxiv_id": "2402.01727v1",
    "title": "Prompting Diverse Ideas: Increasing AI Idea Variance",
    "authors": [
      "Lennart Meincke",
      "Ethan R. Mollick",
      "Christian Terwiesch"
    ],
    "abstract": "Unlike routine tasks where consistency is prized, in creativity and\ninnovation the goal is to create a diverse set of ideas. This paper delves into\nthe burgeoning interest in employing Artificial Intelligence (AI) to enhance\nthe productivity and quality of the idea generation process. While previous\nstudies have found that the average quality of AI ideas is quite high, prior\nresearch also has pointed to the inability of AI-based brainstorming to create\nsufficient dispersion of ideas, which limits novelty and the quality of the\noverall best idea. Our research investigates methods to increase the dispersion\nin AI-generated ideas. Using GPT-4, we explore the effect of different\nprompting methods on Cosine Similarity, the number of unique ideas, and the\nspeed with which the idea space gets exhausted. We do this in the domain of\ndeveloping a new product development for college students, priced under $50. In\nthis context, we find that (1) pools of ideas generated by GPT-4 with various\nplausible prompts are less diverse than ideas generated by groups of human\nsubjects (2) the diversity of AI generated ideas can be substantially improved\nusing prompt engineering (3) Chain-of-Thought (CoT) prompting leads to the\nhighest diversity of ideas of all prompts we evaluated and was able to come\nclose to what is achieved by groups of human subjects. It also was capable of\ngenerating the highest number of unique ideas of any prompt we studied.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01727v1",
    "published_date": "2024-01-27 21:02:50 UTC",
    "updated_date": "2024-01-27 21:02:50 UTC"
  },
  {
    "arxiv_id": "2401.15496v3",
    "title": "Baichuan2-Sum: Instruction Finetune Baichuan2-7B Model for Dialogue Summarization",
    "authors": [
      "Jianfei Xiao",
      "Yancan Chen",
      "Yimin Ou",
      "Hanyi Yu",
      "Kai Shu",
      "Yiyong Xiao"
    ],
    "abstract": "Large language models (LLMs) like Llama, Baichuan and Bloom models show\nremarkable ability with instruction fine-tuning in many natural language tasks.\nNevertheless, for the dialogue summarization task, which aims to generate\nsummaries for different roles in dialogue, most of the state-of-the-art methods\nconduct on small models (e.g Bart and Bert). Existing methods try to add task\nspecified optimization on small models like adding global-local centrality\nscore to models. In this paper, we propose an instruction fine-tuning model:\nBaichuan2-Sum, for role-oriented diaglouge summarization. By setting different\ninstructions for different roles, the model can learn from the dialogue\ninteractions and output the expected summaries. Furthermore, we applied NEFTune\ntechnique to add suitable noise during training to improve the results. The\nexperiments demonstrate that the proposed model achieves the new\nstate-of-the-art results on two public dialogue summarization datasets: CSDS\nand SAMSUM. We release our model and related codes to facilitate future studies\non dialogue summarization task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15496v3",
    "published_date": "2024-01-27 20:20:39 UTC",
    "updated_date": "2024-04-04 03:15:15 UTC"
  },
  {
    "arxiv_id": "2402.04268v1",
    "title": "ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning",
    "authors": [
      "A. Ghafarollahi",
      "M. J. Buehler"
    ],
    "abstract": "Designing de novo proteins beyond those found in nature holds significant\npromise for advancements in both scientific and engineering applications.\nCurrent methodologies for protein design often rely on AI-based models, such as\nsurrogate models that address end-to-end problems by linking protein structure\nto material properties or vice versa. However, these models frequently focus on\nspecific material objectives or structural properties, limiting their\nflexibility when incorporating out-of-domain knowledge into the design process\nor comprehensive data analysis is required. In this study, we introduce\nProtAgents, a platform for de novo protein design based on Large Language\nModels (LLMs), where multiple AI agents with distinct capabilities\ncollaboratively address complex tasks within a dynamic environment. The\nversatility in agent development allows for expertise in diverse domains,\nincluding knowledge retrieval, protein structure analysis, physics-based\nsimulations, and results analysis. The dynamic collaboration between agents,\nempowered by LLMs, provides a versatile approach to tackling protein design and\nanalysis problems, as demonstrated through diverse examples in this study. The\nproblems of interest encompass designing new proteins, analyzing protein\nstructures and obtaining new first-principles data -- natural vibrational\nfrequencies -- via physics simulations. The concerted effort of the system\nallows for powerful automated and synergistic design of de novo proteins with\ntargeted mechanical properties. The flexibility in designing the agents, on one\nhand, and their capacity in autonomous collaboration through the dynamic\nLLM-based multi-agent environment on the other hand, unleashes great potentials\nof LLMs in addressing multi-objective materials problems and opens up new\navenues for autonomous materials discovery and design.",
    "categories": [
      "cond-mat.soft",
      "cs.AI",
      "cs.CL",
      "q-bio.BM"
    ],
    "primary_category": "cond-mat.soft",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.04268v1",
    "published_date": "2024-01-27 20:19:49 UTC",
    "updated_date": "2024-01-27 20:19:49 UTC"
  },
  {
    "arxiv_id": "2401.15489v3",
    "title": "Distilling Privileged Multimodal Information for Expression Recognition using Optimal Transport",
    "authors": [
      "Muhammad Haseeb Aslam",
      "Muhammad Osama Zeeshan",
      "Soufiane Belharbi",
      "Marco Pedersoli",
      "Alessandro Koerich",
      "Simon Bacon",
      "Eric Granger"
    ],
    "abstract": "Deep learning models for multimodal expression recognition have reached\nremarkable performance in controlled laboratory environments because of their\nability to learn complementary and redundant semantic information. However,\nthese models struggle in the wild, mainly because of the unavailability and\nquality of modalities used for training. In practice, only a subset of the\ntraining-time modalities may be available at test time. Learning with\nprivileged information enables models to exploit data from additional\nmodalities that are only available during training. State-of-the-art knowledge\ndistillation (KD) methods have been proposed to distill information from\nmultiple teacher models (each trained on a modality) to a common student model.\nThese privileged KD methods typically utilize point-to-point matching, yet have\nno explicit mechanism to capture the structural information in the teacher\nrepresentation space formed by introducing the privileged modality. Experiments\nwere performed on two challenging problems - pain estimation on the Biovid\ndataset (ordinal classification) and arousal-valance prediction on the Affwild2\ndataset (regression). Results show that our proposed method can outperform\nstate-of-the-art privileged KD methods on these problems. The diversity among\nmodalities and fusion architectures indicates that PKDOT is modality- and\nmodel-agnostic.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15489v3",
    "published_date": "2024-01-27 19:44:15 UTC",
    "updated_date": "2024-04-29 01:01:35 UTC"
  },
  {
    "arxiv_id": "2401.15487v1",
    "title": "Artificial Intelligence: Arguments for Catastrophic Risk",
    "authors": [
      "Adam Bales",
      "William D'Alessandro",
      "Cameron Domenico Kirk-Giannini"
    ],
    "abstract": "Recent progress in artificial intelligence (AI) has drawn attention to the\ntechnology's transformative potential, including what some see as its prospects\nfor causing large-scale harm. We review two influential arguments purporting to\nshow how AI could pose catastrophic risks. The first argument -- the Problem of\nPower-Seeking -- claims that, under certain assumptions, advanced AI systems\nare likely to engage in dangerous power-seeking behavior in pursuit of their\ngoals. We review reasons for thinking that AI systems might seek power, that\nthey might obtain it, that this could lead to catastrophe, and that we might\nbuild and deploy such systems anyway. The second argument claims that the\ndevelopment of human-level AI will unlock rapid further progress, culminating\nin AI systems far more capable than any human -- this is the Singularity\nHypothesis. Power-seeking behavior on the part of such systems might be\nparticularly dangerous. We discuss a variety of objections to both arguments\nand conclude by assessing the state of the debate.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.15487v1",
    "published_date": "2024-01-27 19:34:13 UTC",
    "updated_date": "2024-01-27 19:34:13 UTC"
  },
  {
    "arxiv_id": "2401.16443v1",
    "title": "Evaluating Deep Networks for Detecting User Familiarity with VR from Hand Interactions",
    "authors": [
      "Mingjun Li",
      "Numan Zafar",
      "Natasha Kholgade Banerjee",
      "Sean Banerjee"
    ],
    "abstract": "As VR devices become more prevalent in the consumer space, VR applications\nare likely to be increasingly used by users unfamiliar with VR. Detecting the\nfamiliarity level of a user with VR as an interaction medium provides the\npotential of providing on-demand training for acclimatization and prevents the\nuser from being burdened by the VR environment in accomplishing their tasks. In\nthis work, we present preliminary results of using deep classifiers to conduct\nautomatic detection of familiarity with VR by using hand tracking of the user\nas they interact with a numeric passcode entry panel to unlock a VR door. We\nuse a VR door as we envision it to the first point of entry to collaborative\nvirtual spaces, such as meeting rooms, offices, or clinics. Users who are\nunfamiliar with VR will have used their hands to open doors with passcode entry\npanels in the real world. Thus, while the user may not be familiar with VR,\nthey would be familiar with the task of opening the door. Using a pilot dataset\nconsisting of 7 users familiar with VR, and 7 not familiar with VR, we acquire\nhighest accuracy of 88.03\\% when 6 test users, 3 familiar and 3 not familiar,\nare evaluated with classifiers trained using data from the remaining 8 users.\nOur results indicate potential for using user movement data to detect\nfamiliarity for the simple yet important task of secure passcode-based access.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "AIxVR 2024 poster paper",
    "pdf_url": "http://arxiv.org/pdf/2401.16443v1",
    "published_date": "2024-01-27 19:15:24 UTC",
    "updated_date": "2024-01-27 19:15:24 UTC"
  },
  {
    "arxiv_id": "2401.15480v2",
    "title": "Social Interpretable Reinforcement Learning",
    "authors": [
      "Leonardo Lucio Custode",
      "Giovanni Iacca"
    ],
    "abstract": "Reinforcement Learning (RL) bears the promise of being a game-changer in many\napplications. However, since most of the literature in the field is currently\nfocused on opaque models, the use of RL in high-stakes scenarios, where\ninterpretability is crucial, is still limited. Recently, some approaches to\ninterpretable RL, e.g., based on Decision Trees, have been proposed, but one of\nthe main limitations of these techniques is their training cost. To overcome\nthis limitation, we propose a new method, called Social Interpretable RL\n(SIRL), that can substantially reduce the number of episodes needed for\ntraining. Our method mimics a social learning process, where each agent in a\ngroup learns to solve a given task based both on its own individual experience\nas well as the experience acquired together with its peers. Our approach is\ndivided into the following two phases. (1) In the collaborative phase, all the\nagents in the population interact with a shared instance of the environment,\nwhere each agent observes the state and independently proposes an action. Then,\nvoting is performed to choose the action that will actually be deployed in the\nenvironment. (2) In the individual phase, then, each agent refines its\nindividual performance by interacting with its own instance of the environment.\nThis mechanism makes the agents experience a larger number of episodes with\nlittle impact on the computational cost of the process. Our results (on 6\nwidely-known RL benchmarks) show that SIRL not only reduces the computational\ncost by a factor varying from a minimum of 43% to a maximum 76%, but it also\nincreases the convergence speed and, often, improves the quality of the\nsolutions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "I.2.6; I.2.8"
    ],
    "primary_category": "cs.LG",
    "comment": "45 pages, 25 figures, accepted at evo*2025",
    "pdf_url": "http://arxiv.org/pdf/2401.15480v2",
    "published_date": "2024-01-27 19:05:21 UTC",
    "updated_date": "2025-01-21 18:49:43 UTC"
  },
  {
    "arxiv_id": "2401.15469v2",
    "title": "Wind speed super-resolution and validation: from ERA5 to CERRA via diffusion models",
    "authors": [
      "Fabio Merizzi",
      "Andrea Asperti",
      "Stefano Colamonaco"
    ],
    "abstract": "The Copernicus Regional Reanalysis for Europe, CERRA, is a high-resolution\nregional reanalysis dataset for the European domain. In recent years it has\nshown significant utility across various climate-related tasks, ranging from\nforecasting and climate change research to renewable energy prediction,\nresource management, air quality risk assessment, and the forecasting of rare\nevents, among others. Unfortunately, the availability of CERRA is lagging two\nyears behind the current date, due to constraints in acquiring the requisite\nexternal data and the intensive computational demands inherent in its\ngeneration. As a solution, this paper introduces a novel method using diffusion\nmodels to approximate CERRA downscaling in a data-driven manner, without\nadditional informations. By leveraging the lower resolution ERA5 dataset, which\nprovides boundary conditions for CERRA, we approach this as a super-resolution\ntask. Focusing on wind speed around Italy, our model, trained on existing CERRA\ndata, shows promising results, closely mirroring original CERRA data.\nValidation with in-situ observations further confirms the model's accuracy in\napproximating ground measurements.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15469v2",
    "published_date": "2024-01-27 17:43:08 UTC",
    "updated_date": "2024-01-31 10:17:28 UTC"
  },
  {
    "arxiv_id": "2401.15463v1",
    "title": "DataFrame QA: A Universal LLM Framework on DataFrame Question Answering Without Data Exposure",
    "authors": [
      "Junyi Ye",
      "Mengnan Du",
      "Guiling Wang"
    ],
    "abstract": "This paper introduces DataFrame question answering (QA), a novel task that\nutilizes large language models (LLMs) to generate Pandas queries for\ninformation retrieval and data analysis on dataframes, emphasizing safe and\nnon-revealing data handling. Our method, which solely relies on dataframe\ncolumn names, not only ensures data privacy but also significantly reduces the\ncontext window in the prompt, streamlining information processing and\naddressing major challenges in LLM-based data analysis. We propose DataFrame QA\nas a comprehensive framework that includes safe Pandas query generation and\ncode execution. Various LLMs, notably GPT-4, are evaluated using the pass@1\nmetric on the renowned WikiSQL and our newly developed 'UCI-DataFrameQA',\ntailored for complex data analysis queries. Our findings indicate that GPT-4\nachieves pass@1 rates of 86% on WikiSQL and 97% on UCI-DataFrameQA,\nunderscoring its capability in securely retrieving and aggregating dataframe\nvalues and conducting sophisticated data analyses. This approach, deployable in\na zero-shot manner without prior training or adjustments, proves to be highly\nadaptable and secure for diverse applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15463v1",
    "published_date": "2024-01-27 17:06:53 UTC",
    "updated_date": "2024-01-27 17:06:53 UTC"
  },
  {
    "arxiv_id": "2401.15443v5",
    "title": "DiffuserLite: Towards Real-time Diffusion Planning",
    "authors": [
      "Zibin Dong",
      "Jianye Hao",
      "Yifu Yuan",
      "Fei Ni",
      "Yitian Wang",
      "Pengyi Li",
      "Yan Zheng"
    ],
    "abstract": "Diffusion planning has been recognized as an effective decision-making\nparadigm in various domains. The capability of generating high-quality\nlong-horizon trajectories makes it a promising research direction. However,\nexisting diffusion planning methods suffer from low decision-making frequencies\ndue to the expensive iterative sampling cost. To alleviate this, we introduce\nDiffuserLite, a super fast and lightweight diffusion planning framework, which\nemploys a planning refinement process (PRP) to generate coarse-to-fine-grained\ntrajectories, significantly reducing the modeling of redundant information and\nleading to notable increases in decision-making frequency. Our experimental\nresults demonstrate that DiffuserLite achieves a decision-making frequency of\n122.2Hz (112.7x faster than predominant frameworks) and reaches\nstate-of-the-art performance on D4RL, Robomimic, and FinRL benchmarks. In\naddition, DiffuserLite can also serve as a flexible plugin to increase the\ndecision-making frequency of other diffusion planning algorithms, providing a\nstructural design reference for future works. More details and visualizations\nare available at https://diffuserlite.github.io/.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15443v5",
    "published_date": "2024-01-27 15:30:49 UTC",
    "updated_date": "2024-10-25 03:36:07 UTC"
  },
  {
    "arxiv_id": "2402.01726v2",
    "title": "AI Does Not Alter Perceptions of Text Messages",
    "authors": [
      "N'yoma Diamond"
    ],
    "abstract": "For many people, anxiety, depression, and other social and mental factors can\nmake composing text messages an active challenge. To remedy this problem, large\nlanguage models (LLMs) may yet prove to be the perfect tool to assist users\nthat would otherwise find texting difficult or stressful. However, despite\nrapid uptake in LLM usage, considerations for their assistive usage in text\nmessage composition have not been explored. A primary concern regarding LLM\nusage is that poor public sentiment regarding AI introduces the possibility\nthat its usage may harm perceptions of AI-assisted text messages, making usage\ncounter-productive. To (in)validate this possibility, we explore how the belief\nthat a text message did or did not receive AI assistance in composition alters\nits perceived tone, clarity, and ability to convey intent. In this study, we\nsurvey the perceptions of 26 participants on 18 randomly labeled pre-composed\ntext messages. In analyzing the participants' ratings of message tone, clarity,\nand ability to convey intent, we find that there is no statistically\nsignificant evidence that the belief that AI is utilized alters recipient\nperceptions. This provides hopeful evidence that LLM-based text message\ncomposition assistance can be implemented without the risk of\ncounter-productive outcomes.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01726v2",
    "published_date": "2024-01-27 14:32:12 UTC",
    "updated_date": "2024-02-07 17:04:31 UTC"
  },
  {
    "arxiv_id": "2401.16441v1",
    "title": "FaKnow: A Unified Library for Fake News Detection",
    "authors": [
      "Yiyuan Zhu",
      "Yongjun Li",
      "Jialiang Wang",
      "Ming Gao",
      "Jiali Wei"
    ],
    "abstract": "Over the past years, a large number of fake news detection algorithms based\non deep learning have emerged. However, they are often developed under\ndifferent frameworks, each mandating distinct utilization methodologies,\nconsequently hindering reproducibility. Additionally, a substantial amount of\nredundancy characterizes the code development of such fake news detection\nmodels. To address these concerns, we propose FaKnow, a unified and\ncomprehensive fake news detection algorithm library. It encompasses a variety\nof widely used fake news detection models, categorized as content-based and\nsocial context-based approaches. This library covers the full spectrum of the\nmodel training and evaluation process, effectively organizing the data, models,\nand training procedures within a unified framework. Furthermore, it furnishes a\nseries of auxiliary functionalities and tools, including visualization, and\nlogging. Our work contributes to the standardization and unification of fake\nnews detection research, concurrently facilitating the endeavors of researchers\nin this field. The open-source code and documentation can be accessed at\nhttps://github.com/NPURG/FaKnow and https://faknow.readthedocs.io,\nrespectively.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16441v1",
    "published_date": "2024-01-27 13:29:17 UTC",
    "updated_date": "2024-01-27 13:29:17 UTC"
  },
  {
    "arxiv_id": "2401.15390v1",
    "title": "A microservice architecture for real-time IoT data processing: A reusable Web of things approach for smart ports",
    "authors": [
      "Guadalupe Ortiz",
      "Juan Boubeta-Puig",
      "Javier Criado",
      "David Corral-Plaza",
      "Alfonso Garcia-de-Prado",
      "Inmaculada Medina-Bulo",
      "Luis Iribarne"
    ],
    "abstract": "Major advances in telecommunications and the Internet of Things have given\nrise to numerous smart city scenarios in which smart services are provided.\nWhat was once a dream for the future has now become reality. However, the need\nto provide these smart services quickly, efficiently, in an interoperable\nmanner and in real time is a cutting-edge technological challenge. Although\nsome software architectures offer solutions in this area, these are often\nlimited in terms of reusability and maintenance by independent modules,\ninvolving the need for system downtime when maintaining or evolving, as well as\nby a lack of standards in terms of the interoperability of their interface. In\nthis paper, we propose a fully reusable microservice architecture, standardized\nthrough the use of the Web of things paradigm, and with high efficiency in\nreal-time data processing, supported by complex event processing techniques. To\nillustrate the proposal, we present a fully reusable implementation of the\nmicroservices necessary for the deployment of the architecture in the field of\nair quality monitoring and alerting in smart ports. The performance evaluation\nof this architecture shows excellent results.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15390v1",
    "published_date": "2024-01-27 11:40:38 UTC",
    "updated_date": "2024-01-27 11:40:38 UTC"
  },
  {
    "arxiv_id": "2401.15378v5",
    "title": "A RAG-based Question Answering System Proposal for Understanding Islam: MufassirQAS LLM",
    "authors": [
      "Ahmet Yusuf Alan",
      "Enis Karaarslan",
      "Ã–mer Aydin"
    ],
    "abstract": "Challenges exist in learning and understanding religions, such as the\ncomplexity and depth of religious doctrines and teachings. Chatbots as\nquestion-answering systems can help in solving these challenges. LLM chatbots\nuse NLP techniques to establish connections between topics and accurately\nrespond to complex questions. These capabilities make it perfect for\nenlightenment on religion as a question-answering chatbot. However, LLMs also\ntend to generate false information, known as hallucination. Also, the chatbots'\nresponses can include content that insults personal religious beliefs,\ninterfaith conflicts, and controversial or sensitive topics. It must avoid such\ncases without promoting hate speech or offending certain groups of people or\ntheir beliefs. This study uses a vector database-based Retrieval Augmented\nGeneration (RAG) approach to enhance the accuracy and transparency of LLMs. Our\nquestion-answering system is called \"MufassirQAS\". We created a database\nconsisting of several open-access books that include Turkish context. These\nbooks contain Turkish translations and interpretations of Islam. This database\nis utilized to answer religion-related questions and ensure our answers are\ntrustworthy. The relevant part of the dataset, which LLM also uses, is\npresented along with the answer. We have put careful effort into creating\nsystem prompts that give instructions to prevent harmful, offensive, or\ndisrespectful responses to respect people's values and provide reliable\nresults. The system answers and shares additional information, such as the page\nnumber from the respective book and the articles referenced for obtaining the\ninformation. MufassirQAS and ChatGPT are also tested with sensitive questions.\nWe got better performance with our system. Study and enhancements are still in\nprogress. Results and future works are given.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15378v5",
    "published_date": "2024-01-27 10:50:11 UTC",
    "updated_date": "2025-03-18 17:14:43 UTC"
  },
  {
    "arxiv_id": "2401.16440v1",
    "title": "Beyond Eviction Prediction: Leveraging Local Spatiotemporal Public Records to Inform Action",
    "authors": [
      "Tasfia Mashiat",
      "Alex DiChristofano",
      "Patrick J. Fowler",
      "Sanmay Das"
    ],
    "abstract": "There has been considerable recent interest in scoring properties on the\nbasis of eviction risk. The success of methods for eviction prediction is\ntypically evaluated using different measures of predictive accuracy. However,\nthe underlying goal of such prediction is to direct appropriate assistance to\nhouseholds that may be at greater risk so they remain stably housed. Thus, we\nmust ask the question of how useful such predictions are in targeting outreach\nefforts - informing action. In this paper, we investigate this question using a\nnovel dataset that matches information on properties, evictions, and owners. We\nperform an eviction prediction task to produce risk scores and then use these\nrisk scores to plan targeted outreach policies. We show that the risk scores\nare, in fact, useful, enabling a theoretical team of caseworkers to reach more\neviction-prone properties in the same amount of time, compared to outreach\npolicies that are either neighborhood-based or focus on buildings with a recent\nhistory of evictions. We also discuss the importance of neighborhood and\nownership features in both risk prediction and targeted outreach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16440v1",
    "published_date": "2024-01-27 09:29:11 UTC",
    "updated_date": "2024-01-27 09:29:11 UTC"
  },
  {
    "arxiv_id": "2401.15356v4",
    "title": "A Decision Theoretic Framework for Measuring AI Reliance",
    "authors": [
      "Ziyang Guo",
      "Yifan Wu",
      "Jason Hartline",
      "Jessica Hullman"
    ],
    "abstract": "Humans frequently make decisions with the aid of artificially intelligent\n(AI) systems. A common pattern is for the AI to recommend an action to the\nhuman who retains control over the final decision. Researchers have identified\nensuring that a human has appropriate reliance on an AI as a critical component\nof achieving complementary performance. We argue that the current definition of\nappropriate reliance used in such research lacks formal statistical grounding\nand can lead to contradictions. We propose a formal definition of reliance,\nbased on statistical decision theory, which separates the concepts of reliance\nas the probability the decision-maker follows the AI's recommendation from\nchallenges a human may face in differentiating the signals and forming accurate\nbeliefs about the situation. Our definition gives rise to a framework that can\nbe used to guide the design and interpretation of studies on human-AI\ncomplementarity and reliance. Using recent AI-advised decision making studies\nfrom literature, we demonstrate how our framework can be used to separate the\nloss due to mis-reliance from the loss due to not accurately differentiating\nthe signals. We evaluate these losses by comparing to a baseline and a\nbenchmark for complementary performance defined by the expected payoff achieved\nby a rational decision-maker facing the same decision task as the behavioral\ndecision-makers.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15356v4",
    "published_date": "2024-01-27 09:13:09 UTC",
    "updated_date": "2024-05-12 19:33:49 UTC"
  },
  {
    "arxiv_id": "2401.15351v2",
    "title": "A Survey on Neural Topic Models: Methods, Applications, and Challenges",
    "authors": [
      "Xiaobao Wu",
      "Thong Nguyen",
      "Anh Tuan Luu"
    ],
    "abstract": "Topic models have been prevalent for decades to discover latent topics and\ninfer topic proportions of documents in an unsupervised fashion. They have been\nwidely used in various applications like text analysis and context\nrecommendation. Recently, the rise of neural networks has facilitated the\nemergence of a new research field -- Neural Topic Models (NTMs). Different from\nconventional topic models, NTMs directly optimize parameters without requiring\nmodel-specific derivations. This endows NTMs with better scalability and\nflexibility, resulting in significant research attention and plentiful new\nmethods and applications. In this paper, we present a comprehensive survey on\nneural topic models concerning methods, applications, and challenges.\nSpecifically, we systematically organize current NTM methods according to their\nnetwork structures and introduce the NTMs for various scenarios like short\ntexts and bilingual documents. We also discuss a wide range of popular\napplications built on NTMs. Finally, we highlight the challenges confronted by\nNTMs to inspire future research. We accompany this survey with a repository for\neasier access to the mentioned paper resources:\nhttps://github.com/bobxwu/Paper-Neural-Topic-Models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Artificial Intelligence Review. See\n  https://doi.org/10.1007/s10462-023-10661-7 and a paper list at\n  https://github.com/BobXWu/Paper-Neural-Topic-Models",
    "pdf_url": "http://arxiv.org/pdf/2401.15351v2",
    "published_date": "2024-01-27 08:52:19 UTC",
    "updated_date": "2024-06-24 12:08:06 UTC"
  },
  {
    "arxiv_id": "2401.15347v1",
    "title": "A Comprehensive Survey of Compression Algorithms for Language Models",
    "authors": [
      "Seungcheol Park",
      "Jaehyeon Choi",
      "Sojin Lee",
      "U Kang"
    ],
    "abstract": "How can we compress language models without sacrificing accuracy? The number\nof compression algorithms for language models is rapidly growing to benefit\nfrom remarkable advances of recent language models without side effects due to\nthe gigantic size of language models, such as increased carbon emissions and\nexpensive maintenance fees. While numerous compression algorithms have shown\nremarkable progress in compressing language models, it ironically becomes\nchallenging to capture emerging trends and identify the fundamental concepts\nunderlying them due to the excessive number of algorithms. In this paper, we\nsurvey and summarize diverse compression algorithms including pruning,\nquantization, knowledge distillation, low-rank approximation, parameter\nsharing, and efficient architecture design. We not only summarize the overall\ntrend of diverse compression algorithms but also select representative\nalgorithms and provide in-depth analyses of them. We discuss the value of each\ncategory of compression algorithms, and the desired properties of low-cost\ncompression algorithms which have a significant impact due to the emergence of\nlarge language models. Finally, we introduce promising future research topics\nbased on our survey results.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15347v1",
    "published_date": "2024-01-27 08:38:56 UTC",
    "updated_date": "2024-01-27 08:38:56 UTC"
  },
  {
    "arxiv_id": "2402.01725v1",
    "title": "Fortifying Ethical Boundaries in AI: Advanced Strategies for Enhancing Security in Large Language Models",
    "authors": [
      "Yunhong He",
      "Jianling Qiu",
      "Wei Zhang",
      "Zhengqing Yuan"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced capabilities in natural language processing and artificial\nintelligence. These models, including GPT-3.5 and LLaMA-2, have revolutionized\ntext generation, translation, and question-answering tasks due to the\ntransformative Transformer model. Despite their widespread use, LLMs present\nchallenges such as ethical dilemmas when models are compelled to respond\ninappropriately, susceptibility to phishing attacks, and privacy violations.\nThis paper addresses these challenges by introducing a multi-pronged approach\nthat includes: 1) filtering sensitive vocabulary from user input to prevent\nunethical responses; 2) detecting role-playing to halt interactions that could\nlead to 'prison break' scenarios; 3) implementing custom rule engines to\nrestrict the generation of prohibited content; and 4) extending these\nmethodologies to various LLM derivatives like Multi-Model Large Language Models\n(MLLMs). Our approach not only fortifies models against unethical manipulations\nand privacy breaches but also maintains their high performance across tasks. We\ndemonstrate state-of-the-art performance under various attack prompts, without\ncompromising the model's core functionalities. Furthermore, the introduction of\ndifferentiated security levels empowers users to control their personal data\ndisclosure. Our methods contribute to reducing social risks and conflicts\narising from technological abuse, enhance data protection, and promote social\nequity. Collectively, this research provides a framework for balancing the\nefficiency of question-answering systems with user privacy and ethical\nstandards, ensuring a safer user experience and fostering trust in AI\ntechnology.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01725v1",
    "published_date": "2024-01-27 08:09:33 UTC",
    "updated_date": "2024-01-27 08:09:33 UTC"
  },
  {
    "arxiv_id": "2401.15337v1",
    "title": "Deep Learning with Information Fusion and Model Interpretation for Health Monitoring of Fetus based on Long-term Prenatal Electronic Fetal Heart Rate Monitoring Data",
    "authors": [
      "Zenghui Lin",
      "Xintong Liu",
      "Nan Wang",
      "Ruichen Li",
      "Qingao Liu",
      "Jingying Ma",
      "Liwei Wang",
      "Yan Wang",
      "Shenda Hong"
    ],
    "abstract": "Long-term fetal heart rate (FHR) monitoring during the antepartum period,\nincreasingly popularized by electronic FHR monitoring, represents a growing\napproach in FHR monitoring. This kind of continuous monitoring, in contrast to\nthe short-term one, collects an extended period of fetal heart data. This\noffers a more comprehensive understanding of fetus's conditions. However, the\ninterpretation of long-term antenatal fetal heart monitoring is still in its\nearly stages, lacking corresponding clinical standards. Furthermore, the\nsubstantial amount of data generated by continuous monitoring imposes a\nsignificant burden on clinical work when analyzed manually. To address above\nchallenges, this study develops an automatic analysis system named LARA\n(Long-term Antepartum Risk Analysis system) for continuous FHR monitoring,\ncombining deep learning and information fusion methods. LARA's core is a\nwell-established convolutional neural network (CNN) model. It processes\nlong-term FHR data as input and generates a Risk Distribution Map (RDM) and\nRisk Index (RI) as the analysis results. We evaluate LARA on inner test\ndataset, the performance metrics are as follows: AUC 0.872, accuracy 0.816,\nspecificity 0.811, sensitivity 0.806, precision 0.271, and F1 score 0.415. In\nour study, we observe that long-term FHR monitoring data with higher RI is more\nlikely to result in adverse outcomes (p=0.0021). In conclusion, this study\nintroduces LARA, the first automated analysis system for long-term FHR\nmonitoring, initiating the further explorations into its clinical value in the\nfuture.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15337v1",
    "published_date": "2024-01-27 07:59:54 UTC",
    "updated_date": "2024-01-27 07:59:54 UTC"
  },
  {
    "arxiv_id": "2401.15335v2",
    "title": "L-AutoDA: Leveraging Large Language Models for Automated Decision-based Adversarial Attacks",
    "authors": [
      "Ping Guo",
      "Fei Liu",
      "Xi Lin",
      "Qingchuan Zhao",
      "Qingfu Zhang"
    ],
    "abstract": "In the rapidly evolving field of machine learning, adversarial attacks\npresent a significant challenge to model robustness and security.\nDecision-based attacks, which only require feedback on the decision of a model\nrather than detailed probabilities or scores, are particularly insidious and\ndifficult to defend against. This work introduces L-AutoDA (Large Language\nModel-based Automated Decision-based Adversarial Attacks), a novel approach\nleveraging the generative capabilities of Large Language Models (LLMs) to\nautomate the design of these attacks. By iteratively interacting with LLMs in\nan evolutionary framework, L-AutoDA automatically designs competitive attack\nalgorithms efficiently without much human effort. We demonstrate the efficacy\nof L-AutoDA on CIFAR-10 dataset, showing significant improvements over baseline\nmethods in both success rate and computational efficiency. Our findings\nunderscore the potential of language models as tools for adversarial attack\ngeneration and highlight new avenues for the development of robust AI systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Camera ready version for GECCO'24 workshop",
    "pdf_url": "http://arxiv.org/pdf/2401.15335v2",
    "published_date": "2024-01-27 07:57:20 UTC",
    "updated_date": "2024-05-22 11:40:21 UTC"
  },
  {
    "arxiv_id": "2401.15324v1",
    "title": "Neutrino Reconstruction in TRIDENT Based on Graph Neural Network",
    "authors": [
      "Cen Mo",
      "Fuyudi Zhang",
      "Liang Li"
    ],
    "abstract": "TRopIcal DEep-sea Neutrino Telescope (TRIDENT) is a next-generation neutrino\ntelescope to be located in the South China Sea. With a large detector volume\nand the use of advanced hybrid digital optical modules (hDOMs), TRIDENT aims to\ndiscover multiple astrophysical neutrino sources and probe all-flavor neutrino\nphysics. The reconstruction resolution of primary neutrinos is on the critical\npath to these scientific goals. We have developed a novel reconstruction method\nbased on graph neural network (GNN) for TRIDENT. In this paper, we present the\nreconstruction performance of the GNN-based approach on both track- and\nshower-like neutrino events in TRIDENT.",
    "categories": [
      "hep-ex",
      "cs.AI"
    ],
    "primary_category": "hep-ex",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15324v1",
    "published_date": "2024-01-27 06:57:24 UTC",
    "updated_date": "2024-01-27 06:57:24 UTC"
  },
  {
    "arxiv_id": "2401.15323v1",
    "title": "Music Auto-Tagging with Robust Music Representation Learned via Domain Adversarial Training",
    "authors": [
      "Haesun Joung",
      "Kyogu Lee"
    ],
    "abstract": "Music auto-tagging is crucial for enhancing music discovery and\nrecommendation. Existing models in Music Information Retrieval (MIR) struggle\nwith real-world noise such as environmental and speech sounds in multimedia\ncontent. This study proposes a method inspired by speech-related tasks to\nenhance music auto-tagging performance in noisy settings. The approach\nintegrates Domain Adversarial Training (DAT) into the music domain, enabling\nrobust music representations that withstand noise. Unlike previous research,\nthis approach involves an additional pretraining phase for the domain\nclassifier, to avoid performance degradation in the subsequent phase. Adding\nvarious synthesized noisy music data improves the model's generalization across\ndifferent noise levels. The proposed architecture demonstrates enhanced\nperformance in music auto-tagging by effectively utilizing unlabeled noisy\nmusic data. Additional experiments with supplementary unlabeled data further\nimproves the model's performance, underscoring its robust generalization\ncapabilities and broad applicability.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.IR",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages, 3 figures, accepted to ICASSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.15323v1",
    "published_date": "2024-01-27 06:56:51 UTC",
    "updated_date": "2024-01-27 06:56:51 UTC"
  },
  {
    "arxiv_id": "2401.15318v2",
    "title": "Gaussian Splashing: Unified Particles for Versatile Motion Synthesis and Rendering",
    "authors": [
      "Yutao Feng",
      "Xiang Feng",
      "Yintong Shang",
      "Ying Jiang",
      "Chang Yu",
      "Zeshun Zong",
      "Tianjia Shao",
      "Hongzhi Wu",
      "Kun Zhou",
      "Chenfanfu Jiang",
      "Yin Yang"
    ],
    "abstract": "We demonstrate the feasibility of integrating physics-based animations of\nsolids and fluids with 3D Gaussian Splatting (3DGS) to create novel effects in\nvirtual scenes reconstructed using 3DGS. Leveraging the coherence of the\nGaussian Splatting and Position-Based Dynamics (PBD) in the underlying\nrepresentation, we manage rendering, view synthesis, and the dynamics of solids\nand fluids in a cohesive manner. Similar to GaussianShader, we enhance each\nGaussian kernel with an added normal, aligning the kernel's orientation with\nthe surface normal to refine the PBD simulation. This approach effectively\neliminates spiky noises that arise from rotational deformation in solids. It\nalso allows us to integrate physically based rendering to augment the dynamic\nsurface reflections on fluids. Consequently, our framework is capable of\nrealistically reproducing surface highlights on dynamic fluids and facilitating\ninteractions between scene objects and fluids from new views. For more\ninformation, please visit our project page at\n\\url{https://gaussiansplashing.github.io/}.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15318v2",
    "published_date": "2024-01-27 06:45:22 UTC",
    "updated_date": "2024-07-23 04:05:53 UTC"
  },
  {
    "arxiv_id": "2402.01724v1",
    "title": "CERM: Context-aware Literature-based Discovery via Sentiment Analysis",
    "authors": [
      "Julio Christian Young",
      "Uchenna Akujuobi"
    ],
    "abstract": "Driven by the abundance of biomedical publications, we introduce a sentiment\nanalysis task to understand food-health relationship. Prior attempts to\nincorporate health into recipe recommendation and analysis systems have\nprimarily focused on ingredient nutritional components or utilized basic\ncomputational models trained on curated labeled data. Enhanced models that\ncapture the inherent relationship between food ingredients and biomedical\nconcepts can be more beneficial for food-related research, given the wealth of\ninformation in biomedical texts. Considering the costly data labeling process,\nthese models should effectively utilize both labeled and unlabeled data. This\npaper introduces Entity Relationship Sentiment Analysis (ERSA), a new task that\ncaptures the sentiment of a text based on an entity pair. ERSA extends the\nwidely studied Aspect Based Sentiment Analysis (ABSA) task. Specifically, our\nstudy concentrates on the ERSA task applied to biomedical texts, focusing on\n(entity-entity) pairs of biomedical and food concepts. ERSA poses a significant\nchallenge compared to traditional sentiment analysis tasks, as sentence\nsentiment may not align with entity relationship sentiment. Additionally, we\npropose CERM, a semi-supervised architecture that combines different word\nembeddings to enhance the encoding of the ERSA task. Experimental results\nshowcase the model's efficiency across diverse learning scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01724v1",
    "published_date": "2024-01-27 06:40:08 UTC",
    "updated_date": "2024-01-27 06:40:08 UTC"
  },
  {
    "arxiv_id": "2401.15299v3",
    "title": "SupplyGraph: A Benchmark Dataset for Supply Chain Planning using Graph Neural Networks",
    "authors": [
      "Azmine Toushik Wasi",
      "MD Shafikul Islam",
      "Adipto Raihan Akib"
    ],
    "abstract": "Graph Neural Networks (GNNs) have gained traction across different domains\nsuch as transportation, bio-informatics, language processing, and computer\nvision. However, there is a noticeable absence of research on applying GNNs to\nsupply chain networks. Supply chain networks are inherently graph-like in\nstructure, making them prime candidates for applying GNN methodologies. This\nopens up a world of possibilities for optimizing, predicting, and solving even\nthe most complex supply chain problems. A major setback in this approach lies\nin the absence of real-world benchmark datasets to facilitate the research and\nresolution of supply chain problems using GNNs. To address the issue, we\npresent a real-world benchmark dataset for temporal tasks, obtained from one of\nthe leading FMCG companies in Bangladesh, focusing on supply chain planning for\nproduction purposes. The dataset includes temporal data as node features to\nenable sales predictions, production planning, and the identification of\nfactory issues. By utilizing this dataset, researchers can employ GNNs to\naddress numerous supply chain problems, thereby advancing the field of supply\nchain analytics and planning. Source: https://github.com/CIOL-SUST/SupplyGraph",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.SY",
      "eess.SY",
      "stat.AP",
      "I.2.1; I.2.8; E.0; J.2; H.3.7"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to 4th workshop on Graphs and more Complex structures for\n  Learning and Reasoning, colocated with AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.15299v3",
    "published_date": "2024-01-27 05:14:17 UTC",
    "updated_date": "2025-01-15 09:23:55 UTC"
  },
  {
    "arxiv_id": "2401.15296v2",
    "title": "Recognizing Identities From Human Skeletons: A Survey on 3D Skeleton Based Person Re-Identification",
    "authors": [
      "Haocong Rao",
      "Chunyan Miao"
    ],
    "abstract": "Person re-identification via 3D skeletons is an important emerging research\narea that attracts increasing attention within the pattern recognition\ncommunity. With distinctive advantages across various application scenarios,\nnumerous 3D skeleton based person re-identification (SRID) methods with diverse\nskeleton modeling and learning paradigms have been proposed in recent years. In\nthis survey, we provide a comprehensive review and analysis of recent SRID\nadvances. First of all, we define the SRID task and provide an overview of its\norigin and major advancements. Secondly, we formulate a systematic taxonomy\nthat organizes existing methods into three categories based on different\nskeleton modeling ($i.e.,$ hand-crafted, sequence-based, graph-based). Then, we\nelaborate on the representative models along these three categories with an\nanalysis of their merits and limitations. Meanwhile, we provide an in-depth\nreview of mainstream supervised, self-supervised, and unsupervised SRID\nlearning paradigms and corresponding skeleton semantics learning tasks. A\nthorough evaluation of state-of-the-art SRID methods is further conducted over\nvarious types of benchmarks and protocols to compare their effectiveness and\nefficiency. Finally, we discuss the challenges of existing studies along with\npromising directions for future research, highlighting research impacts and\npotential applications of SRID.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "A curated collection of valuable resources (papers, codes, data,\n  etc.) is available at https://github.com/Kali-Hac/SRID",
    "pdf_url": "http://arxiv.org/pdf/2401.15296v2",
    "published_date": "2024-01-27 04:52:24 UTC",
    "updated_date": "2025-02-06 13:44:23 UTC"
  },
  {
    "arxiv_id": "2401.15293v1",
    "title": "SkipViT: Speeding Up Vision Transformers with a Token-Level Skip Connection",
    "authors": [
      "Foozhan Ataiefard",
      "Walid Ahmed",
      "Habib Hajimolahoseini",
      "Saina Asani",
      "Farnoosh Javadi",
      "Mohammad Hassanpour",
      "Omar Mohamed Awad",
      "Austin Wen",
      "Kangling Liu",
      "Yang Liu"
    ],
    "abstract": "Vision transformers are known to be more computationally and data-intensive\nthan CNN models. These transformer models such as ViT, require all the input\nimage tokens to learn the relationship among them. However, many of these\ntokens are not informative and may contain irrelevant information such as\nunrelated background or unimportant scenery. These tokens are overlooked by the\nmulti-head self-attention (MHSA), resulting in many redundant and unnecessary\ncomputations in MHSA and the feed-forward network (FFN). In this work, we\npropose a method to optimize the amount of unnecessary interactions between\nunimportant tokens by separating and sending them through a different low-cost\ncomputational path. Our method does not add any parameters to the ViT model and\naims to find the best trade-off between training throughput and achieving a 0%\nloss in the Top-1 accuracy of the final model. Our experimental results on\ntraining ViT-small from scratch show that SkipViT is capable of effectively\ndropping 55% of the tokens while gaining more than 13% training throughput and\nmaintaining classification accuracy at the level of the baseline model on\nHuawei Ascend910A.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15293v1",
    "published_date": "2024-01-27 04:24:49 UTC",
    "updated_date": "2024-01-27 04:24:49 UTC"
  },
  {
    "arxiv_id": "2401.15284v5",
    "title": "Beyond principlism: Practical strategies for ethical AI use in research practices",
    "authors": [
      "Zhicheng Lin"
    ],
    "abstract": "The rapid adoption of generative artificial intelligence (AI) in scientific\nresearch, particularly large language models (LLMs), has outpaced the\ndevelopment of ethical guidelines, leading to a Triple-Too problem: too many\nhigh-level ethical initiatives, too abstract principles lacking contextual and\npractical relevance, and too much focus on restrictions and risks over benefits\nand utilities. Existing approaches, including principlism (reliance on abstract\nethical principles), formalism (rigid application of rules), and technical\nsolutionism (overemphasis on technological fixes), offer little practical\nguidance for addressing ethical challenges of AI in scientific research\npractices. To bridge the gap between abstract principles and day-to-day\nresearch practices, a user-centered, realism-inspired approach is proposed\nhere. It outlines five specific goals for ethical AI use: 1) understanding\nmodel training and output, including bias mitigation strategies; 2) respecting\nprivacy, confidentiality, and copyright; 3) avoiding plagiarism and policy\nviolations; 4) applying AI beneficially compared to alternatives; and 5) using\nAI transparently and reproducibly. Each goal is accompanied by actionable\nstrategies and realistic cases of misuse and corrective measures. I argue that\nethical AI application requires evaluating its utility against existing\nalternatives rather than isolated performance metrics. Additionally, I propose\ndocumentation guidelines to enhance transparency and reproducibility in\nAI-assisted research. Moving forward, we need targeted professional\ndevelopment, training programs, and balanced enforcement mechanisms to promote\nresponsible AI use while fostering innovation. By refining these ethical\nguidelines and adapting them to emerging AI capabilities, we can accelerate\nscientific progress without compromising research integrity.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted in: AI and Ethics. 20 pages, 1 figure, 3 tables, 2 boxes",
    "pdf_url": "http://arxiv.org/pdf/2401.15284v5",
    "published_date": "2024-01-27 03:53:25 UTC",
    "updated_date": "2024-10-03 16:13:55 UTC"
  },
  {
    "arxiv_id": "2402.01723v1",
    "title": "An Empirical Study on Large Language Models in Accuracy and Robustness under Chinese Industrial Scenarios",
    "authors": [
      "Zongjie Li",
      "Wenying Qiu",
      "Pingchuan Ma",
      "Yichen Li",
      "You Li",
      "Sijia He",
      "Baozheng Jiang",
      "Shuai Wang",
      "Weixi Gu"
    ],
    "abstract": "Recent years have witnessed the rapid development of large language models\n(LLMs) in various domains. To better serve the large number of Chinese users,\nmany commercial vendors in China have adopted localization strategies, training\nand providing local LLMs specifically customized for Chinese users.\nFurthermore, looking ahead, one of the key future applications of LLMs will be\npractical deployment in industrial production by enterprises and users in those\nsectors. However, the accuracy and robustness of LLMs in industrial scenarios\nhave not been well studied. In this paper, we present a comprehensive empirical\nstudy on the accuracy and robustness of LLMs in the context of the Chinese\nindustrial production area. We manually collected 1,200 domain-specific\nproblems from 8 different industrial sectors to evaluate LLM accuracy.\nFurthermore, we designed a metamorphic testing framework containing four\nindustrial-specific stability categories with eight abilities, totaling 13,631\nquestions with variants to evaluate LLM robustness. In total, we evaluated 9\ndifferent LLMs developed by Chinese vendors, as well as four different LLMs\ndeveloped by global vendors. Our major findings include: (1) Current LLMs\nexhibit low accuracy in Chinese industrial contexts, with all LLMs scoring less\nthan 0.6. (2) The robustness scores vary across industrial sectors, and local\nLLMs overall perform worse than global ones. (3) LLM robustness differs\nsignificantly across abilities. Global LLMs are more robust under\nlogical-related variants, while advanced local LLMs perform better on problems\nrelated to understanding Chinese industrial terminology. Our study results\nprovide valuable guidance for understanding and promoting the industrial domain\ncapabilities of LLMs from both development and industrial enterprise\nperspectives. The results further motivate possible research directions and\ntooling support.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01723v1",
    "published_date": "2024-01-27 03:37:55 UTC",
    "updated_date": "2024-01-27 03:37:55 UTC"
  },
  {
    "arxiv_id": "2401.15270v2",
    "title": "SimFair: Physics-Guided Fairness-Aware Learning with Simulation Models",
    "authors": [
      "Zhihao Wang",
      "Yiqun Xie",
      "Zhili Li",
      "Xiaowei Jia",
      "Zhe Jiang",
      "Aolin Jia",
      "Shuo Xu"
    ],
    "abstract": "Fairness-awareness has emerged as an essential building block for the\nresponsible use of artificial intelligence in real applications. In many cases,\ninequity in performance is due to the change in distribution over different\nregions. While techniques have been developed to improve the transferability of\nfairness, a solution to the problem is not always feasible with no samples from\nthe new regions, which is a bottleneck for pure data-driven attempts.\nFortunately, physics-based mechanistic models have been studied for many\nproblems with major social impacts. We propose SimFair, a physics-guided\nfairness-aware learning framework, which bridges the data limitation by\nintegrating physical-rule-based simulation and inverse modeling into the\ntraining design. Using temperature prediction as an example, we demonstrate the\neffectiveness of the proposed SimFair in fairness preservation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to AAAI 2024 (preprint)",
    "pdf_url": "http://arxiv.org/pdf/2401.15270v2",
    "published_date": "2024-01-27 02:36:30 UTC",
    "updated_date": "2024-02-05 22:22:49 UTC"
  },
  {
    "arxiv_id": "2401.15269v3",
    "title": "Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models",
    "authors": [
      "Minbyul Jeong",
      "Jiwoong Sohn",
      "Mujeen Sung",
      "Jaewoo Kang"
    ],
    "abstract": "Recent proprietary large language models (LLMs), such as GPT-4, have achieved\na milestone in tackling diverse challenges in the biomedical domain, ranging\nfrom multiple-choice questions to long-form generations. To address challenges\nthat still cannot be handled with the encoded knowledge of LLMs, various\nretrieval-augmented generation (RAG) methods have been developed by searching\ndocuments from the knowledge corpus and appending them unconditionally or\nselectively to the input of LLMs for generation. However, when applying\nexisting methods to different domain-specific problems, poor generalization\nbecomes apparent, leading to fetching incorrect documents or making inaccurate\njudgments. In this paper, we introduce Self-BioRAG, a framework reliable for\nbiomedical text that specializes in generating explanations, retrieving\ndomain-specific documents, and self-reflecting generated responses. We utilize\n84k filtered biomedical instruction sets to train Self-BioRAG that can assess\nits generated explanations with customized reflective tokens. Our work proves\nthat domain-specific components, such as a retriever, domain-related document\ncorpus, and instruction sets are necessary for adhering to domain-related\ninstructions. Using three major medical question-answering benchmark datasets,\nexperimental results of Self-BioRAG demonstrate significant performance gains\nby achieving a 7.2% absolute improvement on average over the state-of-the-art\nopen-foundation model with a parameter size of 7B or less. Overall, we analyze\nthat Self-BioRAG finds the clues in the question, retrieves relevant documents\nif needed, and understands how to answer with information from retrieved\ndocuments and encoded knowledge as a medical expert does. We release our data\nand code for training our framework components and model weights (7B and 13B)\nto enhance capabilities in biomedical and clinical domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "ISMB 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.15269v3",
    "published_date": "2024-01-27 02:29:42 UTC",
    "updated_date": "2024-06-18 02:10:15 UTC"
  },
  {
    "arxiv_id": "2401.15268v2",
    "title": "Towards Stable Preferences for Stakeholder-aligned Machine Learning",
    "authors": [
      "Haleema Sheraz",
      "Stefan C. Kremer",
      "Joshua August Skorburg",
      "Graham Taylor",
      "Walter Sinnott-Armstrong",
      "Kyle Boerstler"
    ],
    "abstract": "In response to the pressing challenge of kidney allocation, characterized by\ngrowing demands for organs, this research sets out to develop a data-driven\nsolution to this problem, which also incorporates stakeholder values. The\nprimary objective of this study is to create a method for learning both\nindividual and group-level preferences pertaining to kidney allocations.\nDrawing upon data from the 'Pairwise Kidney Patient Online Survey.' Leveraging\ntwo distinct datasets and evaluating across three levels - Individual, Group\nand Stability - we employ machine learning classifiers assessed through several\nmetrics. The Individual level model predicts individual participant\npreferences, the Group level model aggregates preferences across participants,\nand the Stability level model, an extension of the Group level, evaluates the\nstability of these preferences over time. By incorporating stakeholder\npreferences into the kidney allocation process, we aspire to advance the\nethical dimensions of organ transplantation, contributing to more transparent\nand equitable practices while promoting the integration of moral values into\nalgorithmic decision-making.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Work in Progress",
    "pdf_url": "http://arxiv.org/pdf/2401.15268v2",
    "published_date": "2024-01-27 02:21:31 UTC",
    "updated_date": "2024-02-02 20:39:57 UTC"
  },
  {
    "arxiv_id": "2402.01722v1",
    "title": "Enhancing Large Language Model Performance To Answer Questions and Extract Information More Accurately",
    "authors": [
      "Liang Zhang",
      "Katherine Jijo",
      "Spurthi Setty",
      "Eden Chung",
      "Fatima Javid",
      "Natan Vidra",
      "Tommy Clifford"
    ],
    "abstract": "Large Language Models (LLMs) generate responses to questions; however, their\neffectiveness is often hindered by sub-optimal quality of answers and\noccasional failures to provide accurate responses to questions. To address\nthese challenges, a fine-tuning process is employed, involving feedback and\nexamples to refine models. The objective is to enhance AI models through\ncontinuous feedback loops, utilizing metrics such as cosine similarity, LLM\nevaluation and Rouge-L scores to evaluate the models. Leveraging LLMs like\nGPT-3.5, GPT4ALL, and LLaMA2, and Claude, this approach is benchmarked on\nfinancial datasets, including the FinanceBench and RAG Instruct Benchmark\nTester Dataset, illustrating the necessity of fine-tuning. The results showcase\nthe capability of fine-tuned models to surpass the accuracy of zero-shot LLMs,\nproviding superior question and answering capabilities. Notably, the\ncombination of fine-tuning the LLM with a process known as Retrieval Augmented\nGeneration (RAG) proves to generate responses with improved accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01722v1",
    "published_date": "2024-01-27 00:18:07 UTC",
    "updated_date": "2024-01-27 00:18:07 UTC"
  }
]