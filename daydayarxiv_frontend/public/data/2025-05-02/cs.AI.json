{
  "date": "2025-05-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-02 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、安全性、迁移学习和强化学习等领域，亮点包括 LLM 的攻击防御机制、模型量化技术，以及 NVIDIA 等机构的 Llama-Nemotron 系列高效推理模型，这些工作突显了 AI 效率和鲁棒性的前沿进展。\n\n### 重点论文讨论\n今天共有 101 篇论文，我将优先选取那些具有话题性、创新性和潜在影响的论文进行简要分析，并将相关主题归类讨论。其他较常规或应用导向的论文（如某些图像处理或特定领域优化）将快速掠过，只提核心点。\n\n#### LLM 安全与优化（高话题度领域）\n这一组论文探讨了大型语言模型（LLMs）的安全漏洞、量化压缩和迁移学习，涉及攻击防御和高效训练，是本日最令人印象深刻的主题。\n- **LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures（LLM 安全性：漏洞、攻击、防御和对策）**  \n  主要贡献：系统总结了 LLM 在训练和部署阶段的攻击类型（如提示攻击和模型窃取），并分类防御策略（预防和检测）。发现防御机制需平衡性能和鲁棒性。该工作为 LLM 安全提供全面框架，强调了实际部署中的伦理挑战。\n- **Attack and defense techniques in large language models: A survey and new perspectives（大型语言模型中的攻击和防御技术：调查与新视角）**  \n  主要贡献：调研了 LLM 的攻击（如对抗提示）和防御方法，提出新方向如自适应防御。该论文扩展了现有研究，揭示防御的动态挑战。\n- **MoEQuant: Enhancing Quantization for Mixture-of-Experts Large Language Models via Expert-Balanced Sampling and Affinity Guidance（MoEQuant：通过专家平衡采样和亲和力引导增强混合专家 LLM 的量化）**  \n  主要贡献：针对混合专家模型，提出专家平衡采样和亲和力引导量化方法，显著提升了低比特量化性能（e.g., 4-bit 量化下准确率提升超 10%）。这为资源受限环境下的 LLM 部署提供了高效方案。\n- **RWKVQuant: Quantizing the RWKV Family with Proxy Guided Hybrid of Scalar and Vector Quantization（RWKVQuant：使用代理引导的标量和向量量化混合量化 RWKV 系列模型）**  \n  主要贡献：引入代理引导的混合量化策略，优化 RWKV 模型的计算效率（e.g., 3-bit 量化下准确率损失小于 1%）。发现这种方法在推理加速中表现出色。\n- **Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models（寻求碰撞：使用检索增强 LLM 生成在线安全关键自动驾驶场景）**  \n  主要贡献：利用检索增强 LLM 生成动态对抗场景，提高自动驾驶的安全测试（e.g., 碰撞率提升 75%）。这展示了 LLM 在实时模拟中的潜力。\n\n其他 LLM 相关论文（如知识蒸馏和微调）显示了模型适应性的进展，但细节较常规，故快速掠过：例如，**Reduced-order structure-property linkages for stochastic metamaterials（减少阶结构-属性联系用于随机元材料）** 探索了模型压缩，但焦点不在 LLM，故不展开。\n\n#### 强化学习与规划（创新性方法引人注目）\n这些论文强调了强化学习的安全性和规划效率，部分与知名机构相关。\n- **Skill-based Safe Reinforcement Learning with Risk Planning（基于技能的安全强化学习与风险规划）**  \n  主要贡献：提出 Safe Skill Planning 框架，使用离线数据学习风险预测器，提升在线安全策略（e.g., 在机器人模拟环境中性能优于现有方法）。这为风险敏感应用提供了实用工具。\n- **SIME: Enhancing Policy Self-Improvement with Modal-level Exploration（SIME：通过模态级探索增强策略自我改进）**  \n  主要贡献：引入模态级探索机制，帮助强化学习代理生成多样交互数据，提高机器人任务性能（e.g., 模拟和真实实验均见效）。该工作突出了探索在自我改进中的作用。\n- **Llama-Nemotron: Efficient Reasoning Models（Llama-Nemotron：高效推理模型）**  \n  主要贡献：NVIDIA 团队发布的新模型系列，支持动态推理切换，提升推理效率（e.g., 与 DeepSeek-R1 相当，但推断吞吐量更高）。这体现了知名机构在高效 AI 上的领先。\n\n其他强化学习论文（如路径规划）虽有进展，但较基础，故简要：例如，**PipeSpec: Breaking Stage Dependencies in Hierarchical LLM Decoding（PipeSpec：打破层次 LLM 解码中的阶段依赖）** 优化了模型推断，但影响力不如上述。\n\n#### 计算机视觉与图像处理（快速掠过，选核心）\n这一领域论文较多，但多为应用优化，我仅挑出代表性 ones。\n- **CDFormer: Cross-Domain Few-Shot Object Detection Transformer Against Feature Confusion（CDFormer：对抗特征混淆的跨域少样本物体检测 Transformer）**  \n  主要贡献：提出区分对象-背景和对象-对象混淆的模块，提升跨域物体检测准确率（e.g., mAP 提升 12.9%）。这为少样本场景提供了新框架。\n- **Any-to-Any Vision-Language Model for Multimodal X-ray Imaging and Radiological Report Generation（Any-to-Any 视觉-语言模型用于多模态 X 射线成像和放射学报告生成）**  \n  主要贡献：开发多模态生成模型，支持图像和报告的互生，提高医学诊断准确性（e.g., FID 和 BLEU 分数优于基线）。发现其在下游任务中与真实数据相当。\n\n其他视觉论文（如异常检测）虽有技术细节，但较常规，不再深究。\n\n#### 其他领域（快速总结）\n剩余论文涉及量子计算、医学 AI 和数据处理等。其中，**GENMO: A GENeralist Model for Human MOtion（GENMO：通用人类运动模型）** 提出统一运动生成和估计框架，提升机器人运动理解（e.g., NVIDIA 相关工作，展示跨任务适应性）。其他如医学 AI 和数据增强论文（如 **DetoxAI** 和 **An Adaptive Framework for Autoregressive Forecasting**）虽有实用价值，但不具话题度，故仅提核心：它们改善了公平性和预测准确性，却未带来突破性创新。\n\n总之，今天的 arXiv 论文强调了 AI 的效率、安全和泛化能力，LLM 相关工作尤其值得关注。如果您对特定主题感兴趣，建议查看这些论文的摘要！明天的快报见。",
  "papers": [
    {
      "arxiv_id": "2505.01635v1",
      "title": "Dendritic Computing with Multi-Gate Ferroelectric Field-Effect Transistors",
      "title_zh": "翻译失败",
      "authors": [
        "A N M Nafiul Islam",
        "Xuezhong Niu",
        "Jiahui Duan",
        "Shubham Kumar",
        "Kai Ni",
        "Abhronil Sengupta"
      ],
      "abstract": "Although inspired by neuronal systems in the brain, artificial neural\nnetworks generally employ point-neurons, which offer far less computational\ncomplexity than their biological counterparts. Neurons have dendritic arbors\nthat connect to different sets of synapses and offer local non-linear\naccumulation - playing a pivotal role in processing and learning. Inspired by\nthis, we propose a novel neuron design based on a multi-gate ferroelectric\nfield-effect transistor that mimics dendrites. It leverages ferroelectric\nnonlinearity for local computations within dendritic branches, while utilizing\nthe transistor action to generate the final neuronal output. The branched\narchitecture paves the way for utilizing smaller crossbar arrays in hardware\nintegration, leading to greater efficiency. Using an experimentally calibrated\ndevice-circuit-algorithm co-simulation framework, we demonstrate that networks\nincorporating our dendritic neurons achieve superior performance in comparison\nto much larger networks without dendrites ($\\sim$17$\\times$ fewer trainable\nweight parameters). These findings suggest that dendritic hardware can\nsignificantly improve computational efficiency, and learning capacity of\nneuromorphic systems optimized for edge applications.",
      "tldr_zh": "该论文提出了一种新型神经元设计，使用多-gate ferroelectric field-effect transistors 模仿生物神经元的树突结构，实现局部非线性积累和计算。设计利用铁电非线性在树突分支内进行本地计算，并通过晶体管作用生成最终输出，从而允许硬件集成中使用更小的交叉阵列，提高计算效率。通过实验校准的设备-电路-算法联合模拟框架，研究表明，采用这种树突神经元的网络比无树突网络性能更优，仅需约17倍更少的训练权重参数，并显著提升神经形态系统的学习能力和边缘应用潜力。",
      "categories": [
        "cs.ET",
        "cs.AI"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01635v1",
      "published_date": "2025-05-02 23:59:08 UTC",
      "updated_date": "2025-05-02 23:59:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:50:57.631727"
    },
    {
      "arxiv_id": "2505.01632v1",
      "title": "Transfer Learning-Based Deep Residual Learning for Speech Recognition in Clean and Noisy Environments",
      "title_zh": "基于迁移学习的深度残差学习用于干净和嘈杂环境的语音识别",
      "authors": [
        "Noussaiba Djeffal",
        "Djamel Addou",
        "Hamza Kheddar",
        "Sid Ahmed Selouani"
      ],
      "abstract": "Addressing the detrimental impact of non-stationary environmental noise on\nautomatic speech recognition (ASR) has been a persistent and significant\nresearch focus. Despite advancements, this challenge continues to be a major\nconcern. Recently, data-driven supervised approaches, such as deep neural\nnetworks, have emerged as promising alternatives to traditional unsupervised\nmethods. With extensive training, these approaches have the potential to\novercome the challenges posed by diverse real-life acoustic environments. In\nthis light, this paper introduces a novel neural framework that incorporates a\nrobust frontend into ASR systems in both clean and noisy environments.\nUtilizing the Aurora-2 speech database, the authors evaluate the effectiveness\nof an acoustic feature set for Mel-frequency, employing the approach of\ntransfer learning based on Residual neural network (ResNet). The experimental\nresults demonstrate a significant improvement in recognition accuracy compared\nto convolutional neural networks (CNN) and long short-term memory (LSTM)\nnetworks. They achieved accuracies of 98.94% in clean and 91.21% in noisy mode.",
      "tldr_zh": "这篇论文针对环境噪声对自动语音识别 (ASR) 的负面影响，提出了一种基于迁移学习 (Transfer Learning) 的深度残差网络 (ResNet) 框架，将稳健的前端整合到 ASR 系统，以适应干净和嘈杂环境。作者使用 Aurora-2 语音数据库和 Mel-frequency 声学特征进行实验评估，与传统的卷积神经网络 (CNN) 和长短时记忆网络 (LSTM) 相比，该方法显著提高了识别准确率。结果显示，在干净环境中准确率达 98.94%，在嘈杂环境中达 91.21%，为噪声鲁棒性 ASR 系统提供了有效解决方案。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01632v1",
      "published_date": "2025-05-02 23:42:27 UTC",
      "updated_date": "2025-05-02 23:42:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:51:12.970958"
    },
    {
      "arxiv_id": "2505.01619v1",
      "title": "Skill-based Safe Reinforcement Learning with Risk Planning",
      "title_zh": "基于技能的安全强化学习与风险规划",
      "authors": [
        "Hanping Zhang",
        "Yuhong Guo"
      ],
      "abstract": "Safe Reinforcement Learning (Safe RL) aims to ensure safety when an RL agent\nconducts learning by interacting with real-world environments where improper\nactions can induce high costs or lead to severe consequences. In this paper, we\npropose a novel Safe Skill Planning (SSkP) approach to enhance effective safe\nRL by exploiting auxiliary offline demonstration data. SSkP involves a\ntwo-stage process. First, we employ PU learning to learn a skill risk predictor\nfrom the offline demonstration data. Then, based on the learned skill risk\npredictor, we develop a novel risk planning process to enhance online safe RL\nand learn a risk-averse safe policy efficiently through interactions with the\nonline RL environment, while simultaneously adapting the skill risk predictor\nto the environment. We conduct experiments in several benchmark robotic\nsimulation environments. The experimental results demonstrate that the proposed\napproach consistently outperforms previous state-of-the-art safe RL methods.",
      "tldr_zh": "本论文提出了一种名为 SSkP 的新方法，用于提升 Safe Reinforcement Learning (Safe RL) 的有效性，通过利用辅助离线演示数据来避免高成本或严重后果。SSkP 采用两阶段过程：首先使用 PU learning 学习一个 skill risk predictor；然后基于此预测器开发风险规划过程，以在线环境中高效学习风险厌恶的 safe policy，同时适应环境变化。实验结果显示，在多个基准机器人模拟环境中，SSkP  consistently outperforms 先前的最先进 Safe RL 方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01619v1",
      "published_date": "2025-05-02 22:48:27 UTC",
      "updated_date": "2025-05-02 22:48:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:51:22.615388"
    },
    {
      "arxiv_id": "2505.05492v1",
      "title": "DetoxAI: a Python Toolkit for Debiasing Deep Learning Models in Computer Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Ignacy Stępka",
        "Lukasz Sztukiewicz",
        "Michał Wiliński",
        "Jerzy Stefanowski"
      ],
      "abstract": "While machine learning fairness has made significant progress in recent\nyears, most existing solutions focus on tabular data and are poorly suited for\nvision-based classification tasks, which rely heavily on deep learning. To\nbridge this gap, we introduce DetoxAI, an open-source Python library for\nimproving fairness in deep learning vision classifiers through post-hoc\ndebiasing. DetoxAI implements state-of-the-art debiasing algorithms, fairness\nmetrics, and visualization tools. It supports debiasing via interventions in\ninternal representations and includes attribution-based visualization tools and\nquantitative algorithmic fairness metrics to show how bias is mitigated. This\npaper presents the motivation, design, and use cases of DetoxAI, demonstrating\nits tangible value to engineers and researchers.",
      "tldr_zh": "这篇论文介绍了 DetoxAI，一个开源 Python 工具包，旨在通过后处理偏置（post-hoc debiasing）来改善计算机视觉中深度学习模型的公平性，从而桥接现有解决方案在视觉分类任务上的不足。DetoxAI 实现了状态-of-the-art 偏置算法、fairness metrics 和 visualization tools，支持通过干预内部表示来缓解偏置，并提供归因可视化和量化公平性指标。工具包的设计专注于实用性，包含各种用例，帮助工程师和研究者评估并减轻模型偏置。该工作展示了 DetoxAI 在提升视觉任务公平性方面的实际价值。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05492v1",
      "published_date": "2025-05-02 22:47:39 UTC",
      "updated_date": "2025-05-02 22:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:51:34.520108"
    },
    {
      "arxiv_id": "2505.01618v2",
      "title": "Don't be lazy: CompleteP enables compute-efficient deep transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Nolan Dey",
        "Bin Claire Zhang",
        "Lorenzo Noci",
        "Mufan Li",
        "Blake Bordelon",
        "Shane Bergsma",
        "Cengiz Pehlevan",
        "Boris Hanin",
        "Joel Hestness"
      ],
      "abstract": "We study compute efficiency of LLM training when using different\nparameterizations, i.e., rules for adjusting model and optimizer\nhyperparameters (HPs) as model size changes. Some parameterizations fail to\ntransfer optimal base HPs (such as learning rate) across changes in model\ndepth, requiring practitioners to either re-tune these HPs as they scale up\n(expensive), or accept sub-optimal training when re-tuning is prohibitive. Even\nwhen they achieve HP transfer, we develop theory to show parameterizations may\nstill exist in the lazy learning regime where layers learn only features close\nto their linearization, preventing effective use of depth and nonlinearity.\nFinally, we identify and adopt the parameterization we call CompleteP that\nachieves both depth-wise HP transfer and non-lazy learning in all layers.\nCompleteP enables a wider range of model width/depth ratios to remain\ncompute-efficient, unlocking shapes better suited for different hardware\nsettings and operational contexts. Moreover, CompleteP enables 12-34% compute\nefficiency improvements over the prior state-of-the-art.",
      "tldr_zh": "本研究探讨了LLM训练中不同参数化（parameterizations）对计算效率的影响，指出传统方法往往无法实现超参数（HPs）的深度转移，导致重新调整成本高昂或出现lazy learning问题，从而限制模型深度的有效利用。作者提出了CompleteP参数化，它确保了深度-wise HP转移和非lazy learning，使所有层都能充分利用深度和非线性。CompleteP允许更广泛的模型宽度/深度比，适应不同硬件设置，并实现了12-34%的计算效率提升。总的来说，该方法为高效的deep transformers训练提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 main pages, 16 appendix pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.01618v2",
      "published_date": "2025-05-02 22:45:14 UTC",
      "updated_date": "2025-05-14 17:09:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:51:46.333441"
    },
    {
      "arxiv_id": "2505.01615v1",
      "title": "Multimodal and Multiview Deep Fusion for Autonomous Marine Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Dimitrios Dagdilelis",
        "Panagiotis Grigoriadis",
        "Roberto Galeazzi"
      ],
      "abstract": "We propose a cross attention transformer based method for multimodal sensor\nfusion to build a birds eye view of a vessels surroundings supporting safer\nautonomous marine navigation. The model deeply fuses multiview RGB and long\nwave infrared images with sparse LiDAR point clouds. Training also integrates X\nband radar and electronic chart data to inform predictions. The resulting view\nprovides a detailed reliable scene representation improving navigational\naccuracy and robustness. Real world sea trials confirm the methods\neffectiveness even in adverse weather and complex maritime settings.",
      "tldr_zh": "我们提出了一种基于 cross attention transformer 的多模态传感器融合方法，用于构建船只周围的鸟瞰视图，从而支持更安全的自主海洋导航。该方法深度融合多视图 RGB 和长波红外图像与稀疏 LiDAR 点云，并在训练中整合 X 波段雷达和电子海图数据，以生成详细可靠的场景表示，提高导航的准确性和鲁棒性。真实海试结果证实，该方法在恶劣天气和复杂海洋环境中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01615v1",
      "published_date": "2025-05-02 22:32:50 UTC",
      "updated_date": "2025-05-02 22:32:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:51:57.455351"
    },
    {
      "arxiv_id": "2505.07835v2",
      "title": "Intelligent Product 3.0: Decentralised AI Agents and Web3 Intelligence Standards",
      "title_zh": "翻译失败",
      "authors": [
        "Alex C. Y. Wong",
        "Duncan McFarlane",
        "C. Ellarby",
        "M. Lee",
        "M. Kuok"
      ],
      "abstract": "Twenty-five years ago, the specification of the Intelligent Product was\nestablished, envisaging real-time connectivity that not only enables products\nto gather accurate data about themselves but also allows them to assess and\ninfluence their own destiny. Early work by the Auto-ID project focused on\ncreating a single, open-standard repository for storing and retrieving product\ninformation, laying a foundation for scalable connectivity. A decade later, the\napproach was revisited in light of low-cost RFID systems that promised a\nlow-cost link between physical goods and networked information environments.\nSince then, advances in blockchain, Web3, and artificial intelligence have\nintroduced unprecedented levels of resilience, consensus, and autonomy. By\nleveraging decentralised identity, blockchain-based product information and\nhistory, and intelligent AI-to-AI collaboration, this paper examines these\ndevelopments and outlines a new specification for the Intelligent Product 3.0,\nillustrating how decentralised and AI-driven capabilities facilitate seamless\ninteraction between physical AI and everyday products.",
      "tldr_zh": "这篇论文回顾了 Intelligent Product 的演变，从 25 年前的规格到 Auto-ID 项目和低成本 RFID 系统的发展，强调了区块链、Web3 和人工智能带来的韧性、共识和自治。论文提出 Intelligent Product 3.0 的新规格，利用去中心化身份、区块链-based 产品信息和历史，以及 AI-to-AI 协作，实现产品的实时连接和自主决策。主要贡献在于，通过这些去中心化 AI 代理和 Web3 Intelligence Standards，促进物理 AI 与日常产品的无缝交互，提升产品的智能和适应性。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.MA",
        "I.2.11; C.3; C.2.4"
      ],
      "primary_category": "cs.NI",
      "comment": "18 pages, 1 Figure, 3 Tables; Corrected typo in Section 3.4 heading",
      "pdf_url": "http://arxiv.org/pdf/2505.07835v2",
      "published_date": "2025-05-02 22:01:17 UTC",
      "updated_date": "2025-05-14 11:10:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:52:09.825027"
    },
    {
      "arxiv_id": "2505.01595v1",
      "title": "Always Tell Me The Odds: Fine-grained Conditional Probability Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Liaoyaqi Wang",
        "Zhengping Jiang",
        "Anqi Liu",
        "Benjamin Van Durme"
      ],
      "abstract": "We present a state-of-the-art model for fine-grained probability estimation\nof propositions conditioned on context. Recent advances in large language\nmodels (LLMs) have significantly enhanced their reasoning capabilities,\nparticularly on well-defined tasks with complete information. However, LLMs\ncontinue to struggle with making accurate and well-calibrated probabilistic\npredictions under uncertainty or partial information. While incorporating\nuncertainty into model predictions often boosts performance, obtaining reliable\nestimates of that uncertainty remains understudied. In particular, LLM\nprobability estimates tend to be coarse and biased towards more frequent\nnumbers. Through a combination of human and synthetic data creation and\nassessment, scaling to larger models, and better supervision, we propose a set\nof strong and precise probability estimation models. We conduct systematic\nevaluations across tasks that rely on conditional probability estimation and\nshow that our approach consistently outperforms existing fine-tuned and\nprompting-based methods by a large margin.",
      "tldr_zh": "本论文提出了一种先进的模型，用于细粒度的条件概率估计（fine-grained conditional probability estimation），以解决大型语言模型（LLMs）在不确定性或部分信息下预测不准确、校准差且偏向常见数字的问题。通过结合人类和合成数据创建、模型规模扩展以及改进监督，该方法开发出一套精确的概率估计模型。在依赖条件概率估计的任务中，实验结果显示该方法大幅优于现有的 fine-tuned 和 prompting-based 方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01595v1",
      "published_date": "2025-05-02 21:33:18 UTC",
      "updated_date": "2025-05-02 21:33:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:52:21.591723"
    },
    {
      "arxiv_id": "2505.01592v1",
      "title": "PIPA: A Unified Evaluation Protocol for Diagnosing Interactive Planning Agents",
      "title_zh": "PIPA：用于诊断交互式规划代理的统一评估协议",
      "authors": [
        "Takyoung Kim",
        "Janvijay Singh",
        "Shuhaib Mehri",
        "Emre Can Acikgoz",
        "Sagnik Mukherjee",
        "Nimet Beyza Bozdag",
        "Sumuk Shashidhar",
        "Gokhan Tur",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "The growing capabilities of large language models (LLMs) in\ninstruction-following and context-understanding lead to the era of agents with\nnumerous applications. Among these, task planning agents have become especially\nprominent in realistic scenarios involving complex internal pipelines, such as\ncontext understanding, tool management, and response generation. However,\nexisting benchmarks predominantly evaluate agent performance based on task\ncompletion as a proxy for overall effectiveness. We hypothesize that merely\nimproving task completion is misaligned with maximizing user satisfaction, as\nusers interact with the entire agentic process and not only the end result. To\naddress this gap, we propose PIPA, a unified evaluation protocol that\nconceptualizes the behavioral process of interactive task planning agents\nwithin a partially observable Markov Decision Process (POMDP) paradigm. The\nproposed protocol offers a comprehensive assessment of agent performance\nthrough a set of atomic evaluation criteria, allowing researchers and\npractitioners to diagnose specific strengths and weaknesses within the agent's\ndecision-making pipeline. Our analyses show that agents excel in different\nbehavioral stages, with user satisfaction shaped by both outcomes and\nintermediate behaviors. We also highlight future directions, including systems\nthat leverage multiple agents and the limitations of user simulators in task\nplanning.",
      "tldr_zh": "这篇论文提出PIPA，一种统一的评估协议，用于诊断交互式任务规划代理的性能，解决现有基准仅依赖任务完成指标而忽略用户对整个代理过程满意度的局限。PIPA将代理行为概念化为部分可观测Markov决策过程(POMDP)，通过一组原子评估标准全面评估代理在上下文理解、工具管理和响应生成等决策管道中的优势和劣势。研究分析显示，代理在不同行为阶段表现出色，用户满意度受任务结果和中间行为双重影响，并指出了未来方向，如多代理系统和用户模拟器(User Simulators)的潜在挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.01592v1",
      "published_date": "2025-05-02 21:27:10 UTC",
      "updated_date": "2025-05-02 21:27:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:52:33.808362"
    },
    {
      "arxiv_id": "2505.03819v2",
      "title": "Focus on the Likely: Test-time Instance-based Uncertainty Removal",
      "title_zh": "翻译失败",
      "authors": [
        "Johannes Schneider"
      ],
      "abstract": "We ask: Does focusing on classes predicted as likely improve model\npredictions? We aim for an affirmative answer by proposing two novel test-time\nfine-tuning methods to improve uncertain model predictions. Instead of greedily\nselecting the most likely class, we introduce an additional step, \\emph{focus\non the likely classes}, to refine predictions. By applying a theoretically\nmotivated single gradient descent step with a large learning rate, we refine\npredictions when an initial forward pass indicates high uncertainty. This\naligns predictions more closely with the ideal of assigning zero probability to\nless plausible outcomes. The experimental evaluation demonstrates accuracy\ngains for one of our methods, which emphasizes shared features among likely\nclasses, across diverse text and image domain models. %Our theoretical\ndiscussion provides a deeper understanding, highlighting the varying impact of\nshared and non-shared features among (focus) classes. %Our discussion also\nsuggests an interesting view on standard, offline training vs. test-time\ntraining: Opposing optimization rationales regarding breadth of feature\ndependence are preferable during each training phase.",
      "tldr_zh": "该论文探讨了是否关注预测为可能的类能改善模型预测，并提出两种新的测试-time fine-tuning方法来精炼不确定预测。具体方法包括引入“focus on the likely classes”步骤，使用理论驱动的单个gradient descent步骤（结合大学习率），以将不太可能的输出概率分配为零。实验结果显示，其中一种强调likely classes之间shared features的方法，在各种文本和图像领域模型上实现了准确率提升。理论分析进一步揭示了shared和non-shared features的影响，以及标准离线训练与test-time training在优化策略上的差异。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03819v2",
      "published_date": "2025-05-02 21:06:53 UTC",
      "updated_date": "2025-05-16 15:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:52:45.868218"
    },
    {
      "arxiv_id": "2505.01584v2",
      "title": "Understanding and Exploiting Plasticity for Non-stationary Network Resource Adaptation",
      "title_zh": "理解并利用可塑性以适应非平稳网络资源",
      "authors": [
        "Zhiqiang He",
        "Zhi Liu"
      ],
      "abstract": "Adapting to non-stationary network conditions presents significant challenges\nfor resource adaptation. However, current solutions primarily rely on\nstationary assumptions. While data-driven reinforcement learning approaches\noffer promising solutions for handling network dynamics, our systematic\ninvestigation reveals a critical limitation: neural networks suffer from\nplasticity loss, significantly impeding their ability to adapt to evolving\nnetwork conditions. Through theoretical analysis of neural propagation\nmechanisms, we demonstrate that existing dormant neuron metrics inadequately\ncharacterize neural plasticity loss. To address this limitation, we have\ndeveloped the Silent Neuron theory, which provides a more comprehensive\nframework for understanding plasticity degradation. Based on these theoretical\ninsights, we propose the Reset Silent Neuron (ReSiN), which preserves neural\nplasticity through strategic neuron resets guided by both forward and backward\npropagation states. In our implementation of an adaptive video streaming\nsystem, ReSiN has shown significant improvements over existing solutions,\nachieving up to 168% higher bitrate and 108% better quality of experience (QoE)\nwhile maintaining comparable smoothness. Furthermore, ReSiN consistently\noutperforms in stationary environments, demonstrating its robust adaptability\nacross different network conditions.",
      "tldr_zh": "该研究探讨了神经网络在非静态网络条件下适应资源时的可塑性损失(plasticity loss)问题，通过系统分析发现现有指标不足以准确表征这一问题。作者提出了Silent Neuron理论作为更全面的框架，并开发了Reset Silent Neuron (ReSiN)方法，利用前向和后向传播状态指导神经元重置，以保留神经可塑性。实验结果显示，在自适应视频流系统中，ReSiN比现有方案提高了高达168%的比特率和108%的QoE，同时保持可比平滑度，并在静态环境中表现出色，证明了其鲁棒适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01584v2",
      "published_date": "2025-05-02 21:03:03 UTC",
      "updated_date": "2025-05-06 02:36:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:52:57.551034"
    },
    {
      "arxiv_id": "2505.01583v1",
      "title": "TEMPURA: Temporal Event Masked Prediction and Understanding for Reasoning in Action",
      "title_zh": "TEMPURA：时间事件掩码预测和理解用于行动中的推理",
      "authors": [
        "Jen-Hao Cheng",
        "Vivian Wang",
        "Huayu Wang",
        "Huapeng Zhou",
        "Yi-Hao Peng",
        "Hou-I Liu",
        "Hsiang-Wei Huang",
        "Kuang-Ming Chen",
        "Cheng-Yen Yang",
        "Wenhao Chai",
        "Yi-Ling Chen",
        "Vibhav Vineet",
        "Qin Cai",
        "Jenq-Neng Hwang"
      ],
      "abstract": "Understanding causal event relationships and achieving fine-grained temporal\ngrounding in videos remain challenging for vision-language models. Existing\nmethods either compress video tokens to reduce temporal resolution, or treat\nvideos as unsegmented streams, which obscures fine-grained event boundaries and\nlimits the modeling of causal dependencies. We propose TEMPURA (Temporal Event\nMasked Prediction and Understanding for Reasoning in Action), a two-stage\ntraining framework that enhances video temporal understanding. TEMPURA first\napplies masked event prediction reasoning to reconstruct missing events and\ngenerate step-by-step causal explanations from dense event annotations, drawing\ninspiration from effective infilling techniques. TEMPURA then learns to perform\nvideo segmentation and dense captioning to decompose videos into\nnon-overlapping events with detailed, timestamp-aligned descriptions. We train\nTEMPURA on VER, a large-scale dataset curated by us that comprises 1M training\ninstances and 500K videos with temporally aligned event descriptions and\nstructured reasoning steps. Experiments on temporal grounding and highlight\ndetection benchmarks demonstrate that TEMPURA outperforms strong baseline\nmodels, confirming that integrating causal reasoning with fine-grained temporal\nsegmentation leads to improved video understanding.",
      "tldr_zh": "这篇论文提出 TEMPURA，一种两阶段训练框架，用于提升视觉语言模型在视频中的时间事件理解和因果推理，解决现有方法在细粒度事件边界和因果依赖建模方面的局限。TEMPURA 的第一阶段采用 masked event prediction reasoning 来重建缺失事件并生成逐步因果解释；第二阶段则进行视频分割和密集标注，将视频分解成非重叠事件并提供时间戳对齐的描述。他们构建了 VER 数据集，包括 1M 训练实例和 500K 视频，以支持训练。实验结果显示，TEMPURA 在时间定位和突出检测基准上优于强基线模型，证明将因果推理与细粒度时间分割相结合能显著改善视频理解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01583v1",
      "published_date": "2025-05-02 21:00:17 UTC",
      "updated_date": "2025-05-02 21:00:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:53:10.496247"
    },
    {
      "arxiv_id": "2505.02859v1",
      "title": "Enhancing ML Model Interpretability: Leveraging Fine-Tuned Large Language Models for Better Understanding of AI",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas Bokstaller",
        "Julia Altheimer",
        "Julian Dormehl",
        "Alina Buss",
        "Jasper Wiltfang",
        "Johannes Schneider",
        "Maximilian Röglinger"
      ],
      "abstract": "Across various sectors applications of eXplainableAI (XAI) gained momentum as\nthe increasing black-boxedness of prevailing Machine Learning (ML) models\nbecame apparent. In parallel, Large Language Models (LLMs) significantly\ndeveloped in their abilities to understand human language and complex patterns.\nBy combining both, this paper presents a novel reference architecture for the\ninterpretation of XAI through an interactive chatbot powered by a fine-tuned\nLLM. We instantiate the reference architecture in the context of\nState-of-Health (SoH) prediction for batteries and validate its design in\nmultiple evaluation and demonstration rounds. The evaluation indicates that the\nimplemented prototype enhances the human interpretability of ML, especially for\nusers with less experience with XAI.",
      "tldr_zh": "这篇论文提出了一种新颖的参考架构，通过微调的大型语言模型(LLMs)驱动的交互式聊天机器人，来提升机器学习(ML)模型的可解释性(eXplainable AI, XAI)，以应对ML模型日益黑盒化的挑战。该架构结合了LLMs对人类语言和复杂模式的理解能力，并在电池State-of-Health (SoH)预测的实际场景中进行实例化与验证。实验结果显示，该原型显著提高了ML模型的人类可解释性，特别是对XAI经验较少的用户。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02859v1",
      "published_date": "2025-05-02 20:57:55 UTC",
      "updated_date": "2025-05-02 20:57:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:53:25.767182"
    },
    {
      "arxiv_id": "2505.01572v1",
      "title": "PipeSpec: Breaking Stage Dependencies in Hierarchical LLM Decoding",
      "title_zh": "PipeSpec: 在分层LLM解码中打破阶段依赖性",
      "authors": [
        "Bradley McDanel",
        "Sai Qian Zhang",
        "Yunhai Hu",
        "Zining Liu"
      ],
      "abstract": "Speculative decoding accelerates large language model inference by using\nsmaller draft models to generate candidate tokens for parallel verification.\nHowever, current approaches are limited by sequential stage dependencies that\nprevent full hardware utilization. We present PipeSpec, a framework that\ngeneralizes speculative decoding to $k$ models arranged in a hierarchical\npipeline, enabling asynchronous execution with lightweight coordination for\nprediction verification and rollback. Our analytical model characterizes token\ngeneration rates across pipeline stages and proves guaranteed throughput\nimprovements over traditional decoding for any non-zero acceptance rate. We\nfurther derive closed-form expressions for steady-state verification\nprobabilities that explain the empirical benefits of pipeline depth.\nExperimental results show that PipeSpec achieves up to 2.54$\\times$ speedup\nwhile outperforming state-of-the-art methods. We validate PipeSpec across text\nsummarization and code generation tasks using LLaMA 2 and 3 models,\ndemonstrating that pipeline efficiency increases with model depth, providing a\nscalable approach to accelerating LLM inference on multi-device systems.",
      "tldr_zh": "该论文提出PipeSpec框架，用于打破层次化LLM解码中的阶段依赖性，从而加速大型语言模型推理。PipeSpec将推测解码扩展到k个模型的层次化管道中，支持异步执行和轻量级协调机制，用于预测验证和回滚。分析模型证明了该框架在任何非零接受率下均能提升吞吐量，并导出了稳态验证概率的闭式表达式来解释管道深度的益处。实验结果显示，PipeSpec在文本摘要和代码生成任务上，使用LLaMA 2和3模型实现了高达2.54×的加速，并优于现有最先进方法，提供了一种可扩展的LLM推理优化方案。",
      "categories": [
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 5 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.01572v1",
      "published_date": "2025-05-02 20:29:31 UTC",
      "updated_date": "2025-05-02 20:29:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:53:34.156284"
    },
    {
      "arxiv_id": "2505.03818v1",
      "title": "Program Semantic Inequivalence Game with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio Valerio Miceli-Barone",
        "Vaishak Belle",
        "Ali Payani"
      ],
      "abstract": "Large Language Models (LLMs) can achieve strong performance on everyday\ncoding tasks, but they can fail on complex tasks that require non-trivial\nreasoning about program semantics. Finding training examples to teach LLMs to\nsolve these tasks can be challenging.\n  In this work, we explore a method to synthetically generate code reasoning\ntraining data based on a semantic inequivalence game SInQ: a generator agent\ncreates program variants that are semantically distinct, derived from a dataset\nof real-world programming tasks, while an evaluator agent has to identify input\nexamples that cause the original programs and the generated variants to diverge\nin their behaviour, with the agents training each other semi-adversarially. We\nprove that this setup enables theoretically unlimited improvement through\nself-play in the limit of infinite computational resources.\n  We evaluated our approach on multiple code generation and understanding\nbenchmarks, including cross-language vulnerability detection (Lu et al., 2021),\nwhere our method improves vulnerability detection in C/C++ code despite being\ntrained exclusively on Python code, and the challenging Python builtin\nidentifier swap benchmark (Miceli-Barone et al., 2023), showing that whereas\nmodern LLMs still struggle with this benchmark, our approach yields substantial\nimprovements.\n  We release the code needed to replicate the experiments, as well as the\ngenerated synthetic data, which can be used to fine-tune LLMs.",
      "tldr_zh": "本文提出了一种基于语义不等价游戏(SInQ)的合成数据生成方法，以提升Large Language Models(LLMs)在复杂代码推理任务上的性能。SInQ 涉及一个生成器代理创建从真实编程任务派生的语义不同程序变体，以及一个评估器代理识别导致原始程序和变体行为分歧的输入示例，通过半对抗训练(semi-adversarially)相互提升。理论证明，该框架在无限计算资源下可通过自博弈(self-play)实现持续改进。在实验中，该方法显著提高了跨语言漏洞检测(cross-language vulnerability detection)和Python内置标识符交换基准(Python builtin identifier swap benchmark)的性能，即使仅在Python代码上训练，也提升了C/C++代码的漏洞检测能力。论文开源了实验代码和合成数据，供微调LLMs使用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03818v1",
      "published_date": "2025-05-02 20:03:35 UTC",
      "updated_date": "2025-05-02 20:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:53:51.420783"
    },
    {
      "arxiv_id": "2505.01563v1",
      "title": "TutorGym: A Testbed for Evaluating AI Agents as Tutors and Students",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Weitekamp",
        "Momin N. Siddiqui",
        "Christopher J. MacLellan"
      ],
      "abstract": "Recent improvements in large language model (LLM) performance on academic\nbenchmarks, such as MATH and GSM8K, have emboldened their use as standalone\ntutors and as simulations of human learning. However, these new applications\nrequire more than evaluations of final solution generation. We introduce\nTutorGym to evaluate these applications more directly. TutorGym is a standard\ninterface for testing artificial intelligence (AI) agents within existing\nintelligent tutoring systems (ITS) that have been tested and refined in\nclassroom studies, including Cognitive Tutors (CTAT), Apprentice Tutors, and\nOATutors. TutorGym is more than a simple problem-solution benchmark, it\nsituates AI agents within the interactive interfaces of existing ITSs. At each\nstep of problem-solving, AI agents are asked what they would do as a tutor or\nas a learner. As tutors, AI agents are prompted to provide tutoring support --\nsuch as generating examples, hints, and step-level correctness feedback --\nwhich can be evaluated directly against the adaptive step-by-step support\nprovided by existing ITSs. As students, agents directly learn from ITS\ninstruction, and their mistakes and learning trajectories can be compared to\nstudent data. TutorGym establishes a common framework for training and\nevaluating diverse AI agents, including LLMs, computational models of learning,\nand reinforcement learning agents, within a growing suite of learning\nenvironments. Currently, TutorGym includes 223 different tutor domains. In an\ninitial evaluation, we find that current LLMs are poor at tutoring -- none did\nbetter than chance at labeling incorrect actions, and next-step actions were\ncorrect only ~52-70% of the time -- but they could produce remarkably\nhuman-like learning curves when trained as students with in-context learning.",
      "tldr_zh": "该论文引入了 TutorGym，这是一个标准测试平台，用于直接评估 AI 代理作为导师和学生的表现，超越传统问题解决基准。TutorGym 将 AI 代理整合到现有的智能辅导系统（如 Cognitive Tutors 和 Apprentice Tutors）中，让代理在每个问题解决步骤提供支持（如生成提示和反馈）或模拟学习过程，并支持多种 AI 模型的训练和评估，包括 LLMs 和强化学习代理。初步实验发现，当前 LLMs 在辅导方面表现不佳（如标记错误动作的准确率低于随机水平，下一步骤正确率仅52-70%），但通过 in-context learning 作为学生时，能产生类似于人类的学习曲线。",
      "categories": [
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01563v1",
      "published_date": "2025-05-02 20:03:21 UTC",
      "updated_date": "2025-05-02 20:03:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:53:58.564232"
    },
    {
      "arxiv_id": "2505.01557v1",
      "title": "Contextures: Representations from Contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Runtian Zhai",
        "Kai Yang",
        "Che-Ping Tsai",
        "Burak Varici",
        "Zico Kolter",
        "Pradeep Ravikumar"
      ],
      "abstract": "Despite the empirical success of foundation models, we do not have a\nsystematic characterization of the representations that these models learn. In\nthis paper, we establish the contexture theory. It shows that a large class of\nrepresentation learning methods can be characterized as learning from the\nassociation between the input and a context variable. Specifically, we show\nthat many popular methods aim to approximate the top-d singular functions of\nthe expectation operator induced by the context, in which case we say that the\nrepresentation learns the contexture. We demonstrate the generality of the\ncontexture theory by proving that representation learning within various\nlearning paradigms -- supervised, self-supervised, and manifold learning -- can\nall be studied from such a perspective. We also prove that the representations\nthat learn the contexture are optimal on those tasks that are compatible with\nthe context. One important implication of the contexture theory is that once\nthe model is large enough to approximate the top singular functions, further\nscaling up the model size yields diminishing returns. Therefore, scaling is not\nall we need, and further improvement requires better contexts. To this end, we\nstudy how to evaluate the usefulness of a context without knowing the\ndownstream tasks. We propose a metric and show by experiments that it\ncorrelates well with the actual performance of the encoder on many real\ndatasets.",
      "tldr_zh": "本论文提出了 contexture theory，这是一种系统性表征 foundation models 表示学习的框架，认为这些模型通过输入与上下文变量的关联来学习表示。\n作者证明了许多流行方法（如监督、自监督和流形学习）旨在近似上下文诱导的期望运算符的顶 d 个 singular functions，从而学习 contexture，这些表示在兼容任务上最优。\n理论还揭示，一旦模型足够大以逼近这些 singular functions，进一步扩大模型规模将带来递减收益，因此改进需要更好的上下文。\n论文提出了一种评估上下文有用性的指标，并通过实验在多个真实数据集上验证其与编码器实际性能的相关性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025, longer version. arXiv admin note: substantial text overlap\n  with arXiv:2504.19792",
      "pdf_url": "http://arxiv.org/pdf/2505.01557v1",
      "published_date": "2025-05-02 19:50:56 UTC",
      "updated_date": "2025-05-02 19:50:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:54:13.356360"
    },
    {
      "arxiv_id": "2505.01542v1",
      "title": "Emotions in the Loop: A Survey of Affective Computing for Emotional Support",
      "title_zh": "翻译失败",
      "authors": [
        "Karishma Hegde",
        "Hemadri Jayalath"
      ],
      "abstract": "In a world where technology is increasingly embedded in our everyday\nexperiences, systems that sense and respond to human emotions are elevating\ndigital interaction. At the intersection of artificial intelligence and\nhuman-computer interaction, affective computing is emerging with innovative\nsolutions where machines are humanized by enabling them to process and respond\nto user emotions. This survey paper explores recent research contributions in\naffective computing applications in the area of emotion recognition, sentiment\nanalysis and personality assignment developed using approaches like large\nlanguage models (LLMs), multimodal techniques, and personalized AI systems. We\nanalyze the key contributions and innovative methodologies applied by the\nselected research papers by categorizing them into four domains: AI chatbot\napplications, multimodal input systems, mental health and therapy applications,\nand affective computing for safety applications. We then highlight the\ntechnological strengths as well as the research gaps and challenges related to\nthese studies. Furthermore, the paper examines the datasets used in each study,\nhighlighting how modality, scale, and diversity impact the development and\nperformance of affective models. Finally, the survey outlines ethical\nconsiderations and proposes future directions to develop applications that are\nmore safe, empathetic and practical.",
      "tldr_zh": "这篇调查论文探讨了情感计算(affective computing)在情感支持中的应用，涵盖了情感识别、情感分析和个性分配等领域，采用大型语言模型(LLMs)、多模态技术(multimodal techniques)以及个性化AI系统等方法。论文将研究分类为AI聊天机器人应用、多模态输入系统、心理健康和治疗应用，以及情感计算的安全应用，并分析了这些领域的关键贡献、技术优势、研究空白和挑战，同时考察了数据集的模态、规模及多样性对模型性能的影响。最后，它强调了伦理考虑，并提出未来方向，以开发更安全、更有同理心(empathetic)的实用应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2.10; I.2.7; H.5.2"
      ],
      "primary_category": "cs.HC",
      "comment": "20 pages, 7 tables, 96 references. Survey paper on affective\n  computing applications using large language models, multimodal AI, and\n  therapeutic chatbots",
      "pdf_url": "http://arxiv.org/pdf/2505.01542v1",
      "published_date": "2025-05-02 19:06:05 UTC",
      "updated_date": "2025-05-02 19:06:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:54:22.773983"
    },
    {
      "arxiv_id": "2505.01539v1",
      "title": "Parameterized Argumentation-based Reasoning Tasks for Benchmarking Generative Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Cor Steging",
        "Silja Renooij",
        "Bart Verheij"
      ],
      "abstract": "Generative large language models as tools in the legal domain have the\npotential to improve the justice system. However, the reasoning behavior of\ncurrent generative models is brittle and poorly understood, hence cannot be\nresponsibly applied in the domains of law and evidence. In this paper, we\nintroduce an approach for creating benchmarks that can be used to evaluate the\nreasoning capabilities of generative language models. These benchmarks are\ndynamically varied, scalable in their complexity, and have formally unambiguous\ninterpretations. In this study, we illustrate the approach on the basis of\nwitness testimony, focusing on the underlying argument attack structure. We\ndynamically generate both linear and non-linear argument attack graphs of\nvarying complexity and translate these into reasoning puzzles about witness\ntestimony expressed in natural language. We show that state-of-the-art large\nlanguage models often fail in these reasoning puzzles, already at low\ncomplexity. Obvious mistakes are made by the models, and their inconsistent\nperformance indicates that their reasoning capabilities are brittle.\nFurthermore, at higher complexity, even state-of-the-art models specifically\npresented for reasoning capabilities make mistakes. We show the viability of\nusing a parametrized benchmark with varying complexity to evaluate the\nreasoning capabilities of generative language models. As such, the findings\ncontribute to a better understanding of the limitations of the reasoning\ncapabilities of generative models, which is essential when designing\nresponsible AI systems in the legal domain.",
      "tldr_zh": "本文提出了一种参数化论证推理任务，用于评估生成式语言模型（Generative Language Models）的推理能力，这些任务动态生成、可扩展复杂性，并具有正式无歧义的解释。方法以证人证词为基础，构建线性或非线性论证攻击图（Argument Attack Graphs），并转化为自然语言推理谜题。实验显示，状态艺术模型在低复杂度任务中已频频出错，推理行为不稳定，在更高复杂度下表现更差。该方法有助于揭示模型的推理局限性，支持法律领域负责任的AI系统设计。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "This manuscript has been accepted for presentation as a short paper\n  at the 20th International Conference of AI & Law in Chicago, June 16 to 20 of\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2505.01539v1",
      "published_date": "2025-05-02 19:04:34 UTC",
      "updated_date": "2025-05-02 19:04:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:54:33.705044"
    },
    {
      "arxiv_id": "2505.01531v1",
      "title": "An Adaptive Framework for Autoregressive Forecasting in CFD Using Hybrid Modal Decomposition and Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Rodrigo Abadía-Heredia",
        "Manuel Lopez-Martin",
        "Soledad Le Clainche"
      ],
      "abstract": "This work presents, to the best of the authors' knowledge, the first\ngeneralizable and fully data-driven adaptive framework designed to stabilize\ndeep learning (DL) autoregressive forecasting models over long time horizons,\nwith the goal of reducing the computational cost required in computational\nfluid dynamics (CFD) simulations.The proposed methodology alternates between\ntwo phases: (i) predicting the evolution of the flow field over a selected time\ninterval using a trained DL model, and (ii) updating the model with newly\ngenerated CFD data when stability degrades, thus maintaining accurate long-term\nforecasting. This adaptive retraining strategy ensures robustness while\navoiding the accumulation of predictive errors typical in autoregressive\nmodels. The framework is validated across three increasingly complex flow\nregimes, from laminar to turbulent, demonstrating from 30 \\% to 95 \\% reduction\nin computational cost without compromising physical consistency or accuracy.\nIts entirely data-driven nature makes it easily adaptable to a wide range of\ntime-dependent simulation problems. The code implementing this methodology is\navailable as open-source and it will be integrated into the upcoming release of\nthe ModelFLOWs-app.",
      "tldr_zh": "该研究提出了一种自适应框架，用于在计算流体动力学（CFD）中稳定深度学习（DL）自回归预测模型，旨在通过减少计算成本来实现长期预测。该框架交替两个阶段：（i）使用训练的 DL 模型预测流场演化，（ii）当预测稳定性下降时，通过新生成的 CFD 数据更新模型，从而避免自回归模型的错误积累。在从层流到湍流的三个复杂流动制度上验证，该框架实现了30%到95%的计算成本减少，同时保持物理一致性和准确性，作为首个通用的数据驱动方法，便于扩展到其他时间相关模拟问题。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "47 pages, single-column, 15 figures and 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.01531v1",
      "published_date": "2025-05-02 18:33:41 UTC",
      "updated_date": "2025-05-02 18:33:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:54:47.079171"
    },
    {
      "arxiv_id": "2505.01530v1",
      "title": "Automated Parsing of Engineering Drawings for Structured Information Extraction Using a Fine-tuned Document Understanding Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Tayyab Khan",
        "Zane Yong",
        "Lequn Chen",
        "Jun Ming Tan",
        "Wenhe Feng",
        "Seung Ki Moon"
      ],
      "abstract": "Accurate extraction of key information from 2D engineering drawings is\ncrucial for high-precision manufacturing. Manual extraction is time-consuming\nand error-prone, while traditional Optical Character Recognition (OCR)\ntechniques often struggle with complex layouts and overlapping symbols,\nresulting in unstructured outputs. To address these challenges, this paper\nproposes a novel hybrid deep learning framework for structured information\nextraction by integrating an oriented bounding box (OBB) detection model with a\ntransformer-based document parsing model (Donut). An in-house annotated dataset\nis used to train YOLOv11 for detecting nine key categories: Geometric\nDimensioning and Tolerancing (GD&T), General Tolerances, Measures, Materials,\nNotes, Radii, Surface Roughness, Threads, and Title Blocks. Detected OBBs are\ncropped into images and labeled to fine-tune Donut for structured JSON output.\nFine-tuning strategies include a single model trained across all categories and\ncategory-specific models. Results show that the single model consistently\noutperforms category-specific ones across all evaluation metrics, achieving\nhigher precision (94.77% for GD&T), recall (100% for most), and F1 score\n(97.3%), while reducing hallucination (5.23%). The proposed framework improves\naccuracy, reduces manual effort, and supports scalable deployment in\nprecision-driven industries.",
      "tldr_zh": "这篇论文提出了一种混合深度学习框架，用于从 2D 工程图中自动提取结构化信息，解决传统 Optical Character Recognition (OCR) 在复杂布局和重叠符号方面的局限性。该框架结合了 YOLOv11 检测模型来识别九个关键类别（如 Geometric Dimensioning and Tolerancing (GD&T)、Title Blocks 等），并使用微调后的 Donut 模型将检测到的 oriented bounding box (OBB) 图像处理成结构化 JSON 输出。实验结果显示，单一模型训练策略在精确率（94.77% for GD&T）、召回率（100% for most）和 F1 分数（97.3%）上优于类别特定模型，同时将幻觉现象降低至 5.23%。该方法提高了信息提取的准确性和效率，支持在精密制造行业的可扩展部署。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been submitted to the IEEE International Conference on\n  Industrial Engineering and Engineering Management (IEEM 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.01530v1",
      "published_date": "2025-05-02 18:33:21 UTC",
      "updated_date": "2025-05-02 18:33:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:55:01.044311"
    },
    {
      "arxiv_id": "2505.01524v1",
      "title": "The DCR Delusion: Measuring the Privacy Risk of Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Zexi Yao",
        "Nataša Krčo",
        "Georgi Ganev",
        "Yves-Alexandre de Montjoye"
      ],
      "abstract": "Synthetic data has become an increasingly popular way to share data without\nrevealing sensitive information. Though Membership Inference Attacks (MIAs) are\nwidely considered the gold standard for empirically assessing the privacy of a\nsynthetic dataset, practitioners and researchers often rely on simpler proxy\nmetrics such as Distance to Closest Record (DCR). These metrics estimate\nprivacy by measuring the similarity between the training data and generated\nsynthetic data. This similarity is also compared against that between the\ntraining data and a disjoint holdout set of real records to construct a binary\nprivacy test. If the synthetic data is not more similar to the training data\nthan the holdout set is, it passes the test and is considered private. In this\nwork we show that, while computationally inexpensive, DCR and other\ndistance-based metrics fail to identify privacy leakage. Across multiple\ndatasets and both classical models such as Baynet and CTGAN and more recent\ndiffusion models, we show that datasets deemed private by proxy metrics are\nhighly vulnerable to MIAs. We similarly find both the binary privacy test and\nthe continuous measure based on these metrics to be uninformative of actual\nmembership inference risk. We further show that these failures are consistent\nacross different metric hyperparameter settings and record selection methods.\nFinally, we argue DCR and other distance-based metrics to be flawed by design\nand show a example of a simple leakage they miss in practice. With this work,\nwe hope to motivate practitioners to move away from proxy metrics to MIAs as\nthe rigorous, comprehensive standard of evaluating privacy of synthetic data,\nin particular to make claims of datasets being legally anonymous.",
      "tldr_zh": "本研究质疑了使用 Distance to Closest Record (DCR) 等代理指标来评估合成数据的隐私风险，指出这些基于距离的简单指标无法准确识别隐私泄漏，尽管它们计算成本低廉。作者通过实验在多个数据集和模型（如Baynet、CTGAN和扩散模型）上比较DCR与Membership Inference Attacks (MIAs)，发现被DCR判断为私有的数据集实际上对MIAs高度脆弱。结果显示，这种失效现象在不同指标超参数和记录选择方法下均一致，并论证DCR等指标设计上存在根本缺陷，最终呼吁采用MIAs作为更可靠的标准，以确保合成数据的合法匿名性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01524v1",
      "published_date": "2025-05-02 18:21:14 UTC",
      "updated_date": "2025-05-02 18:21:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:55:10.852091"
    },
    {
      "arxiv_id": "2505.01523v1",
      "title": "Subset Selection for Fine-Tuning: A Utility-Diversity Balanced Approach for Mathematical Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Madhav Kotecha",
        "Vijendra Kumar Vaishya",
        "Smita Gautam",
        "Suraj Racha"
      ],
      "abstract": "We propose a refined approach to efficiently fine-tune large language models\n(LLMs) on specific domains like the mathematical domain by employing a budgeted\nsubset selection method. Our approach combines utility and diversity metrics to\nselect the most informative and representative training examples. The final\ngoal is to achieve near-full dataset performance with meticulously selected\ndata points from the entire dataset while significantly reducing computational\ncost and training time and achieving competitive performance as the full\ndataset. The utility metric incorporates both perplexity and Chain-of-Thought\n(CoT) loss to identify challenging examples that contribute most to model\nlearning, while the diversity metric ensures broad coverage across mathematical\nsubdomains. We evaluate our method on LLaMA-3 8B and Phi-3 models, comparing\nagainst several baseline approaches, including random selection,\ndiversity-based sampling, and existing state-of-the-art subset selection\ntechniques.",
      "tldr_zh": "本研究提出了一种平衡效用和多样性的子集选择方法，用于在数学领域微调大型语言模型(LLMs)，旨在通过选择最具信息性和代表性的训练样本，实现接近全数据集性能的同时显著降低计算成本和训练时间。该方法使用perplexity和Chain-of-Thought (CoT)损失作为效用指标，优先选取具有挑战性的样本；同时，通过多样性指标确保覆盖数学子领域。实验在LLaMA-3 8B和Phi-3模型上进行，与随机选择、多样性采样等基线方法比较，证明了该方法的有效性和竞争力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T05"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.01523v1",
      "published_date": "2025-05-02 18:20:44 UTC",
      "updated_date": "2025-05-02 18:20:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:55:23.320995"
    },
    {
      "arxiv_id": "2505.03817v1",
      "title": "Modeling Behavioral Preferences of Cyber Adversaries Using Inverse Reinforcement Learning",
      "title_zh": "使用逆强化学习建模网络对手的行为偏好",
      "authors": [
        "Aditya Shinde",
        "Prashant Doshi"
      ],
      "abstract": "This paper presents a holistic approach to attacker preference modeling from\nsystem-level audit logs using inverse reinforcement learning (IRL). Adversary\nmodeling is an important capability in cybersecurity that lets defenders\ncharacterize behaviors of potential attackers, which enables attribution to\nknown cyber adversary groups. Existing approaches rely on documenting an\never-evolving set of attacker tools and techniques to track known threat\nactors. Although attacks evolve constantly, attacker behavioral preferences are\nintrinsic and less volatile. Our approach learns the behavioral preferences of\ncyber adversaries from forensics data on their tools and techniques. We model\nthe attacker as an expert decision-making agent with unknown behavioral\npreferences situated in a computer host. We leverage attack provenance graphs\nof audit logs to derive a state-action trajectory of the attack. We test our\napproach on open datasets of audit logs containing real attack data. Our\nresults demonstrate for the first time that low-level forensics data can\nautomatically reveal an adversary's subjective preferences, which serves as an\nadditional dimension to modeling and documenting cyber adversaries. Attackers'\npreferences tend to be invariant despite their different tools and indicate\npredispositions that are inherent to the attacker. As such, these inferred\npreferences can potentially serve as unique behavioral signatures of attackers\nand improve threat attribution.",
      "tldr_zh": "这篇论文提出了一种使用逆强化学习 (Inverse Reinforcement Learning, IRL) 从系统级审计日志中建模网络攻击者行为偏好的整体方法，以帮助防御者表征攻击行为并实现威胁归因。作者将攻击者视为专家决策代理，通过分析攻击来源图 (attack provenance graphs) 提取状态-行动轨迹，学习其内在偏好，这些偏好相对稳定且独立于具体工具。实验在真实攻击数据集上验证了该方法，能自动揭示攻击者的主观偏好，并将其作为独特行为签名，提高威胁归因的准确性和有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03817v1",
      "published_date": "2025-05-02 18:20:14 UTC",
      "updated_date": "2025-05-02 18:20:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:55:35.834338"
    },
    {
      "arxiv_id": "2505.01514v1",
      "title": "Securing the Future of IVR: AI-Driven Innovation with Agile Security, Data Regulation, and Ethical AI Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Khushbu Mehboob Shaikh",
        "Georgios Giannakopoulos"
      ],
      "abstract": "The rapid digitalization of communication systems has elevated Interactive\nVoice Response (IVR) technologies to become critical interfaces for customer\nengagement. With Artificial Intelligence (AI) now driving these platforms,\nensuring secure, compliant, and ethically designed development practices is\nmore imperative than ever. AI-powered IVRs leverage Natural Language Processing\n(NLP) and Machine Learning (ML) to personalize interactions, automate service\ndelivery, and optimize user experiences. However, these innovations expose\nsystems to heightened risks, including data privacy breaches, AI decision\nopacity, and model security vulnerabilities. This paper analyzes the evolution\nof IVRs from static code-based designs to adaptive AI-driven systems,\npresenting a cybersecurity-centric perspective. We propose a practical\ngovernance framework that embeds agile security principles, compliance with\nglobal data legislation, and user-centric ethics. Emphasizing\nprivacy-by-design, adaptive risk modeling, and transparency, the paper argues\nthat ethical AI integration is not a feature but a strategic imperative.\nThrough this multidimensional lens, we highlight how modern IVRs can transition\nfrom communication tools to intelligent, secure, and accountable digital\nfrontlines-resilient against emerging threats and aligned with societal\nexpectations.",
      "tldr_zh": "这篇论文探讨了互动语音响应（IVR）技术的演变，从静态代码系统转向AI驱动系统，利用自然语言处理（NLP）和机器学习（ML）来个性化交互和优化用户体验，但也面临数据隐私泄露、AI决策不透明以及模型安全漏洞等风险。作者提出一个实用的治理框架，整合敏捷安全原则、全球数据法规合规（如隐私-by-design）和用户导向的伦理AI整合，以确保IVR系统的安全性和透明度。最终，该框架强调伦理AI不仅是功能特性，更是战略必需，帮助IVR转变为智能、安全且负责任的数字前沿，抵抗新兴威胁并满足社会期望。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 1 figure, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.01514v1",
      "published_date": "2025-05-02 18:03:02 UTC",
      "updated_date": "2025-05-02 18:03:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:55:46.493953"
    },
    {
      "arxiv_id": "2505.01425v1",
      "title": "GENMO: A GENeralist Model for Human MOtion",
      "title_zh": "翻译失败",
      "authors": [
        "Jiefeng Li",
        "Jinkun Cao",
        "Haotian Zhang",
        "Davis Rempe",
        "Jan Kautz",
        "Umar Iqbal",
        "Ye Yuan"
      ],
      "abstract": "Human motion modeling traditionally separates motion generation and\nestimation into distinct tasks with specialized models. Motion generation\nmodels focus on creating diverse, realistic motions from inputs like text,\naudio, or keyframes, while motion estimation models aim to reconstruct accurate\nmotion trajectories from observations like videos. Despite sharing underlying\nrepresentations of temporal dynamics and kinematics, this separation limits\nknowledge transfer between tasks and requires maintaining separate models. We\npresent GENMO, a unified Generalist Model for Human Motion that bridges motion\nestimation and generation in a single framework. Our key insight is to\nreformulate motion estimation as constrained motion generation, where the\noutput motion must precisely satisfy observed conditioning signals. Leveraging\nthe synergy between regression and diffusion, GENMO achieves accurate global\nmotion estimation while enabling diverse motion generation. We also introduce\nan estimation-guided training objective that exploits in-the-wild videos with\n2D annotations and text descriptions to enhance generative diversity.\nFurthermore, our novel architecture handles variable-length motions and mixed\nmultimodal conditions (text, audio, video) at different time intervals,\noffering flexible control. This unified approach creates synergistic benefits:\ngenerative priors improve estimated motions under challenging conditions like\nocclusions, while diverse video data enhances generation capabilities.\nExtensive experiments demonstrate GENMO's effectiveness as a generalist\nframework that successfully handles multiple human motion tasks within a single\nmodel.",
      "tldr_zh": "这项研究提出了 GENMO，一种统一的通用模型，用于人体运动建模，将传统的运动生成和估计任务整合到一个框架中，避免了单独维护多个模型的局限。GENMO 通过将运动估计重新表述为受约束的运动生成，并结合回归和扩散机制，实现精确的全局运动估计，同时支持多样化的生成。模型还引入了估计引导训练目标，利用野外视频的2D标注和文本描述来提升生成多样性，并在处理可变长度运动及混合多模态条件（文本、音频、视频）方面表现出色。实验结果表明，GENMO 作为通用框架，不仅在挑战条件下（如遮挡）改善了估计准确性，还增强了整体生成能力，成功处理多种人体运动任务。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.GR",
      "comment": "Project page: https://research.nvidia.com/labs/dair/genmo/",
      "pdf_url": "http://arxiv.org/pdf/2505.01425v1",
      "published_date": "2025-05-02 17:59:55 UTC",
      "updated_date": "2025-05-02 17:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:55:59.731849"
    },
    {
      "arxiv_id": "2505.03816v1",
      "title": "Geospatial and Temporal Trends in Urban Transportation: A Study of NYC Taxis and Pathao Food Deliveries",
      "title_zh": "翻译失败",
      "authors": [
        "Bidyarthi Paul",
        "Fariha Tasnim Chowdhury",
        "Dipta Biswas",
        "Meherin Sultana"
      ],
      "abstract": "Urban transportation plays a vital role in modern city life, affecting how\nefficiently people and goods move around. This study analyzes transportation\npatterns using two datasets: the NYC Taxi Trip dataset from New York City and\nthe Pathao Food Trip dataset from Dhaka, Bangladesh. Our goal is to identify\nkey trends in demand, peak times, and important geographical hotspots. We start\nwith Exploratory Data Analysis (EDA) to understand the basic characteristics of\nthe datasets. Next, we perform geospatial analysis to map out high-demand and\nlow-demand regions. We use the SARIMAX model for time series analysis to\nforecast demand patterns, capturing seasonal and weekly variations. Lastly, we\napply clustering techniques to identify significant areas of high and low\ndemand. Our findings provide valuable insights for optimizing fleet management\nand resource allocation in both passenger transport and food delivery services.\nThese insights can help improve service efficiency, better meet customer needs,\nand enhance urban transportation systems in diverse urban environments.",
      "tldr_zh": "这篇论文研究了纽约市出租车和孟加拉国达卡Pathao食品配送的地理空间和时间趋势，旨在识别需求模式、峰值时间以及关键地理热点。研究采用Exploratory Data Analysis (EDA)分析数据特征、geospatial analysis映射高低需求区域，以及SARIMAX模型进行时间序列预测和clustering techniques识别重要区域。结果提供优化车队管理和资源分配的见解，有助于提升服务效率和城市交通系统的整体表现。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03816v1",
      "published_date": "2025-05-02 17:41:17 UTC",
      "updated_date": "2025-05-02 17:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:56:10.323568"
    },
    {
      "arxiv_id": "2505.01396v1",
      "title": "SIME: Enhancing Policy Self-Improvement with Modal-level Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Jin",
        "Jun Lv",
        "Wenye Yu",
        "Hongjie Fang",
        "Yong-Lu Li",
        "Cewu Lu"
      ],
      "abstract": "Self-improvement requires robotic systems to initially learn from\nhuman-provided data and then gradually enhance their capabilities through\ninteraction with the environment. This is similar to how humans improve their\nskills through continuous practice. However, achieving effective\nself-improvement is challenging, primarily because robots tend to repeat their\nexisting abilities during interactions, often failing to generate new, valuable\ndata for learning. In this paper, we identify the key to successful\nself-improvement: modal-level exploration and data selection. By incorporating\na modal-level exploration mechanism during policy execution, the robot can\nproduce more diverse and multi-modal interactions. At the same time, we select\nthe most valuable trials and high-quality segments from these interactions for\nlearning. We successfully demonstrate effective robot self-improvement on both\nsimulation benchmarks and real-world experiments. The capability for\nself-improvement will enable us to develop more robust and high-success-rate\nrobotic control strategies at a lower cost. Our code and experiment scripts are\navailable at https://ericjin2002.github.io/SIME/",
      "tldr_zh": "该论文探讨了机器人自我提升（self-improvement）的挑战，即机器人倾向于重复现有能力，导致无法生成新数据。作者提出SIME框架，通过引入modal-level exploration机制来增强策略执行的多样性和多模态互动，同时结合数据选择策略，选择最有价值的试验和段落用于学习。实验在模拟基准和真实环境中证明了该方法的有效性，有助于以更低成本开发更稳健、高成功率的机器人控制策略。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01396v1",
      "published_date": "2025-05-02 17:13:03 UTC",
      "updated_date": "2025-05-02 17:13:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:56:22.957378"
    },
    {
      "arxiv_id": "2505.03814v1",
      "title": "Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ganghua Wang",
        "Zhaorun Chen",
        "Bo Li",
        "Haifeng Xu"
      ],
      "abstract": "As foundation models continue to scale, the size of trained models grows\nexponentially, presenting significant challenges for their evaluation. Current\nevaluation practices involve curating increasingly large datasets to assess the\nperformance of large language models (LLMs). However, there is a lack of\nsystematic analysis and guidance on determining the sufficiency of test data or\nselecting informative samples for evaluation. This paper introduces a\ncertifiable and cost-efficient evaluation framework for LLMs. Our framework\nadapts to different evaluation objectives and outputs confidence intervals that\ncontain true values with high probability. We use ``test sample complexity'' to\nquantify the number of test points needed for a certifiable evaluation and\nderive tight bounds on test sample complexity. Based on the developed theory,\nwe develop a partition-based algorithm, named Cer-Eval, that adaptively selects\ntest points to minimize the cost of LLM evaluation. Real-world experiments\ndemonstrate that Cer-Eval can save 20% to 40% test points across various\nbenchmarks, while maintaining an estimation error level comparable to the\ncurrent evaluation process and providing a 95% confidence guarantee.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）的评估挑战，提出了一种可认证（certifiable）和成本高效（cost-efficient）的评估框架Cer-Eval，以解决测试数据规模不足和选择问题。该框架适应不同评估目标，通过计算“test sample complexity”来量化所需测试点数量，并推导出紧致的边界，支持输出高概率包含真实值的置信区间（confidence intervals）。基于此理论，Cer-Eval采用基于分区的(partition-based)算法，自适应地选择测试点，以最小化评估成本。实验结果显示，该框架在各种基准上可节省20%至40%的测试点，同时保持与现有方法相当的估计误差水平，并提供95%的置信保证。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03814v1",
      "published_date": "2025-05-02 17:05:01 UTC",
      "updated_date": "2025-05-02 17:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:56:36.055792"
    },
    {
      "arxiv_id": "2505.01390v1",
      "title": "Multimodal Doctor-in-the-Loop: A Clinically-Guided Explainable Framework for Predicting Pathological Response in Non-Small Cell Lung Cancer",
      "title_zh": "翻译失败",
      "authors": [
        "Alice Natalina Caragliano",
        "Claudia Tacconi",
        "Carlo Greco",
        "Lorenzo Nibid",
        "Edy Ippolito",
        "Michele Fiore",
        "Giuseppe Perrone",
        "Sara Ramella",
        "Paolo Soda",
        "Valerio Guarrasi"
      ],
      "abstract": "This study proposes a novel approach combining Multimodal Deep Learning with\nintrinsic eXplainable Artificial Intelligence techniques to predict\npathological response in non-small cell lung cancer patients undergoing\nneoadjuvant therapy. Due to the limitations of existing radiomics and unimodal\ndeep learning approaches, we introduce an intermediate fusion strategy that\nintegrates imaging and clinical data, enabling efficient interaction between\ndata modalities. The proposed Multimodal Doctor-in-the-Loop method further\nenhances clinical relevance by embedding clinicians' domain knowledge directly\ninto the training process, guiding the model's focus gradually from broader\nlung regions to specific lesions. Results demonstrate improved predictive\naccuracy and explainability, providing insights into optimal data integration\nstrategies for clinical applications.",
      "tldr_zh": "本研究提出了一种Multimodal Doctor-in-the-Loop框架，结合Multimodal Deep Learning和eXplainable Artificial Intelligence，旨在预测非小细胞肺癌患者接受neoadjuvant therapy后的病理反应，以克服现有radiomics和单模态深度学习方法的局限性。\n该框架采用中间融合策略整合影像和临床数据，并将临床医生的领域知识嵌入训练过程，逐步引导模型从broader lung regions聚焦到specific lesions，从而提升模型的临床相关性和可解释性。\n实验结果表明，该方法显著提高了预测准确性，并提供了优化数据整合策略的宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2502.17503",
      "pdf_url": "http://arxiv.org/pdf/2505.01390v1",
      "published_date": "2025-05-02 16:57:37 UTC",
      "updated_date": "2025-05-02 16:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:56:47.044167"
    },
    {
      "arxiv_id": "2505.02856v1",
      "title": "AI Education in a Mirror: Challenges Faced by Academic and Industry Experts",
      "title_zh": "人工智能教育的镜像：学术与行业专家面临的挑战",
      "authors": [
        "Mahir Akgun",
        "Hadi Hosseini"
      ],
      "abstract": "As Artificial Intelligence (AI) technologies continue to evolve, the gap\nbetween academic AI education and real-world industry challenges remains an\nimportant area of investigation. This study provides preliminary insights into\nchallenges AI professionals encounter in both academia and industry, based on\nsemi-structured interviews with 14 AI experts - eight from industry and six\nfrom academia. We identify key challenges related to data quality and\navailability, model scalability, practical constraints, user behavior, and\nexplainability. While both groups experience data and model adaptation\ndifficulties, industry professionals more frequently highlight deployment\nconstraints, resource limitations, and external dependencies, whereas academics\nemphasize theoretical adaptation and standardization issues. These exploratory\nfindings suggest that AI curricula could better integrate real-world\ncomplexities, software engineering principles, and interdisciplinary learning,\nwhile recognizing the broader educational goals of building foundational and\nethical reasoning skills.",
      "tldr_zh": "这篇论文通过对14名AI专家（8名行业专家和6名学术专家）的半结构化采访，探讨了学术AI教育与实际行业挑战之间的差距。研究识别出关键挑战，包括数据质量和可用性、模型可扩展性、实际约束、用户行为以及可解释性。行业专家更强调部署约束、资源限制和外部依赖，而学术专家则关注理论适应和标准化问题。这些初步发现建议，AI课程应更好地整合真实世界复杂性、软件工程原则和跨学科学习，同时强化基础和伦理推理技能，以提升教育效果。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "To appear in AIED 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.02856v1",
      "published_date": "2025-05-02 16:52:49 UTC",
      "updated_date": "2025-05-02 16:52:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:56:59.535142"
    },
    {
      "arxiv_id": "2505.01383v1",
      "title": "FalconWing: An Open-Source Platform for Ultra-Light Fixed-Wing Aircraft Research",
      "title_zh": "FalconWing：用于超轻型固定翼飞机研究的开源平台",
      "authors": [
        "Yan Miao",
        "Will Shen",
        "Hang Cui",
        "Sayan Mitra"
      ],
      "abstract": "We present FalconWing -- an open-source, ultra-lightweight (150 g) fixed-wing\nplatform for autonomy research. The hardware platform integrates a small\ncamera, a standard airframe, offboard computation, and radio communication for\nmanual overrides. We demonstrate FalconWing's capabilities by developing and\ndeploying a purely vision-based control policy for autonomous landing (without\nIMU or motion capture) using a novel real-to-sim-to-real learning approach. Our\nlearning approach: (1) constructs a photorealistic simulation environment via\n3D Gaussian splatting trained on real-world images; (2) identifies nonlinear\ndynamics from vision-estimated real-flight data; and (3) trains a multi-modal\nVision Transformer (ViT) policy through simulation-only imitation learning. The\nViT architecture fuses single RGB image with the history of control actions via\nself-attention, preserving temporal context while maintaining real-time 20 Hz\ninference. When deployed zero-shot on the hardware platform, this policy\nachieves an 80% success rate in vision-based autonomous landings. Together with\nthe hardware specifications, we also open-source the system dynamics, the\nsoftware for photorealistic simulator and the learning approach.",
      "tldr_zh": "本研究介绍了FalconWing，一种开源的超轻型（150 g）固定翼平台，用于自主性研究，该平台集成了小型相机、标准机身、外部计算和无线通信以支持手动干预。研究团队开发了一种纯视觉控制策略，通过实-仿-实学习方法实现自主着陆：首先利用3D Gaussian splatting基于真实图像构建光照真实的模拟环境，其次从视觉估计的真实飞行数据中识别非线性动态，最后通过模拟-only模仿学习训练多模态Vision Transformer (ViT)策略，该策略融合单RGB图像与控制历史，实现20 Hz实时推理。部署后，该策略在硬件平台上零-shot测试中实现了80%的自主着陆成功率，并开源了硬件规范、系统动态、光照真实模拟器和学习方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01383v1",
      "published_date": "2025-05-02 16:47:05 UTC",
      "updated_date": "2025-05-02 16:47:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:57:11.699490"
    },
    {
      "arxiv_id": "2505.01485v1",
      "title": "CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code",
      "title_zh": "翻译失败",
      "authors": [
        "Tasnim Ahmed",
        "Salimur Choudhury"
      ],
      "abstract": "Linear Programming (LP) problems aim to find the optimal solution to an\nobjective under constraints. These problems typically require domain knowledge,\nmathematical skills, and programming ability, presenting significant challenges\nfor non-experts. This study explores the efficiency of Large Language Models\n(LLMs) in generating solver-specific LP code. We propose CHORUS, a\nretrieval-augmented generation (RAG) framework for synthesizing Gurobi-based LP\ncode from natural language problem statements. CHORUS incorporates a\nhierarchical tree-like chunking strategy for theoretical contents and generates\nadditional metadata based on code examples from documentation to facilitate\nself-contained, semantically coherent retrieval. Two-stage retrieval approach\nof CHORUS followed by cross-encoder reranking further ensures contextual\nrelevance. Finally, expertly crafted prompt and structured parser with\nreasoning steps improve code generation performance significantly. Experiments\non the NL4Opt-Code benchmark show that CHORUS improves the performance of\nopen-source LLMs such as Llama3.1 (8B), Llama3.3 (70B), Phi4 (14B), Deepseek-r1\n(32B), and Qwen2.5-coder (32B) by a significant margin compared to baseline and\nconventional RAG. It also allows these open-source LLMs to outperform or match\nthe performance of much stronger baselines-GPT3.5 and GPT4 while requiring far\nfewer computational resources. Ablation studies further demonstrate the\nimportance of expert prompting, hierarchical chunking, and structured\nreasoning.",
      "tldr_zh": "这篇论文提出 CHORUS，一个零样本层次化检索和编排框架，用于从自然语言问题语句生成 Linear Programming (LP) 代码，旨在帮助非专家克服领域知识和编程挑战。CHORUS 基于检索增强生成 (RAG) 技术，结合层次化树状分块策略、两阶段检索、跨编码器 reranking 以及专家级提示和结构化解析器，以提升 Large Language Models (LLMs) 的代码生成准确性和语义连贯性。在 NL4Opt-Code 基准测试中，CHORUS 显著提高了开源 LLMs（如 Llama3.1 和 Llama3.3）的性能，使其超越或匹配更强大的基线模型如 GPT3.5 和 GPT4，同时大幅减少计算资源需求。消融研究进一步证明了专家提示、层次化分块和结构化推理在框架中的关键作用。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted for presentation at the 19th Learning\n  and Intelligent Optimization Conference (LION 19)",
      "pdf_url": "http://arxiv.org/pdf/2505.01485v1",
      "published_date": "2025-05-02 16:36:57 UTC",
      "updated_date": "2025-05-02 16:36:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:57:27.090250"
    },
    {
      "arxiv_id": "2505.01372v1",
      "title": "Evaluating Explanations: An Explanatory Virtues Framework for Mechanistic Interpretability -- The Strange Science Part I.ii",
      "title_zh": "翻译失败",
      "authors": [
        "Kola Ayonrinde",
        "Louis Jaburi"
      ],
      "abstract": "Mechanistic Interpretability (MI) aims to understand neural networks through\ncausal explanations. Though MI has many explanation-generating methods,\nprogress has been limited by the lack of a universal approach to evaluating\nexplanations. Here we analyse the fundamental question \"What makes a good\nexplanation?\" We introduce a pluralist Explanatory Virtues Framework drawing on\nfour perspectives from the Philosophy of Science - the Bayesian, Kuhnian,\nDeutschian, and Nomological - to systematically evaluate and improve\nexplanations in MI. We find that Compact Proofs consider many explanatory\nvirtues and are hence a promising approach. Fruitful research directions\nimplied by our framework include (1) clearly defining explanatory simplicity,\n(2) focusing on unifying explanations and (3) deriving universal principles for\nneural networks. Improved MI methods enhance our ability to monitor, predict,\nand steer AI systems.",
      "tldr_zh": "本研究针对Mechanistic Interpretability (MI)中因果解释的评估问题，提出一个多元主义Explanatory Virtues Framework，基于Bayesian、Kuhnian、Deutschian和Nomological四个哲学科学视角，系统评估和改进神经网络解释的质量。框架强调解释的优点，如简洁性和统一性，发现Compact Proofs是一种兼顾多重优点的有前景方法。论文还指出了未来研究方向，包括清晰定义解释简单性、关注统一解释以及推导神经网络的通用原则。通过提升MI方法，该框架有助于更好地监控、预测和引导AI系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages (plus appendices), 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.01372v1",
      "published_date": "2025-05-02 16:18:40 UTC",
      "updated_date": "2025-05-02 16:18:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:57:34.784525"
    },
    {
      "arxiv_id": "2505.01482v1",
      "title": "Understanding LLM Scientific Reasoning through Promptings and Model's Explanation on the Answers",
      "title_zh": "翻译失败",
      "authors": [
        "Alice Rueda",
        "Mohammed S. Hassan",
        "Argyrios Perivolaris",
        "Bazen G. Teferra",
        "Reza Samavi",
        "Sirisha Rambhatla",
        "Yuqi Wu",
        "Yanbo Zhang",
        "Bo Cao",
        "Divya Sharma",
        "Sridhar Krishnan Venkat Bhat"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding, reasoning, and problem-solving across various\ndomains. However, their ability to perform complex, multi-step reasoning\ntask-essential for applications in science, medicine, and law-remains an area\nof active investigation. This paper examines the reasoning capabilities of\ncontemporary LLMs, analyzing their strengths, limitations, and potential for\nimprovement. The study uses prompt engineering techniques on the Graduate-Level\nGoogleProof Q&A (GPQA) dataset to assess the scientific reasoning of GPT-4o.\nFive popular prompt engineering techniques and two tailored promptings were\ntested: baseline direct answer (zero-shot), chain-of-thought (CoT), zero-shot\nCoT, self-ask, self-consistency, decomposition, and multipath promptings. Our\nfindings indicate that while LLMs exhibit emergent reasoning abilities, they\noften rely on pattern recognition rather than true logical inference, leading\nto inconsistencies in complex problem-solving. The results indicated that\nself-consistency outperformed the other prompt engineering technique with an\naccuracy of 52.99%, followed by direct answer (52.23%). Zero-shot CoT (50%)\noutperformed multipath (48.44%), decomposition (47.77%), self-ask (46.88%), and\nCoT (43.75%). Self-consistency performed the second worst in explaining the\nanswers. Simple techniques such as direct answer, CoT, and zero-shot CoT have\nthe best scientific reasoning. We propose a research agenda aimed at bridging\nthese gaps by integrating structured reasoning frameworks, hybrid AI\napproaches, and human-in-the-loop methodologies. By critically evaluating the\nreasoning mechanisms of LLMs, this paper contributes to the ongoing discourse\non the future of artificial general intelligence and the development of more\nrobust, trustworthy AI systems.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在科学推理方面的能力，通过在Graduate-Level GoogleProof Q&A (GPQA)数据集上应用多种prompt engineering技术（如zero-shot、chain-of-thought (CoT)、zero-shot CoT、self-ask、self-consistency、decomposition和multipath）来测试GPT-4o的表现。研究发现，self-consistency提示技术取得了最高的准确率（52.99%），而简单技术如direct answer和zero-shot CoT在科学推理中表现最佳，但LLMs往往依赖模式识别而非真正的逻辑推理，导致复杂问题解决的不一致性。作者提出未来研究议程，包括整合结构化推理框架、混合AI方法和人类参与，以提升LLMs的可靠性和可信度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01482v1",
      "published_date": "2025-05-02 16:16:17 UTC",
      "updated_date": "2025-05-02 16:16:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:57:48.576178"
    },
    {
      "arxiv_id": "2505.01353v1",
      "title": "Differentiable Nonlinear Model Predictive Control",
      "title_zh": "可微分非线性模型预测控制",
      "authors": [
        "Jonathan Frey",
        "Katrin Baumgärtner",
        "Gianluca Frison",
        "Dirk Reinhardt",
        "Jasper Hoffmann",
        "Leonard Fichtner",
        "Sebastien Gros",
        "Moritz Diehl"
      ],
      "abstract": "The efficient computation of parametric solution sensitivities is a key\nchallenge in the integration of learning-enhanced methods with nonlinear model\npredictive control (MPC), as their availability is crucial for many learning\nalgorithms. While approaches presented in the machine learning community are\nlimited to convex or unconstrained formulations, this paper discusses the\ncomputation of solution sensitivities of general nonlinear programs (NLPs)\nusing the implicit function theorem (IFT) and smoothed optimality conditions\ntreated in interior-point methods (IPM). We detail sensitivity computation\nwithin a sequential quadratic programming (SQP) method which employs an IPM for\nthe quadratic subproblems. The publication is accompanied by an efficient\nopen-source implementation within the framework, providing both forward and\nadjoint sensitivities for general optimal control problems, achieving speedups\nexceeding 3x over the state-of-the-art solver mpc.pytorch.",
      "tldr_zh": "该研究解决了将学习增强方法与非线性模型预测控制（Nonlinear Model Predictive Control, MPC）整合时，高效计算参数解敏感性的关键挑战，特别是针对一般非线性规划（NLP）。作者使用隐函数定理（Implicit Function Theorem, IFT）和平滑最优性条件（在内部点方法，IPM 中处理），在顺序二次规划（Sequential Quadratic Programming, SQP）框架内详细阐述了敏感性计算方法。实验结果显示，该方法提供高效的开源实现，支持前向和伴随敏感性，并比现有最先进求解器 mpc.pytorch 提速超过 3 倍，从而为学习与优化控制的结合提供了新工具。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "19 page, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.01353v1",
      "published_date": "2025-05-02 15:43:37 UTC",
      "updated_date": "2025-05-02 15:43:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:57:58.883515"
    },
    {
      "arxiv_id": "2505.01343v1",
      "title": "BalancEdit: Dynamically Balancing the Generality-Locality Trade-off in Multi-modal Model Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Dongliang Guo",
        "Mengxuan Hu",
        "Zihan Guan",
        "Thomas Hartvigsen",
        "Sheng Li"
      ],
      "abstract": "Large multi-modal models inevitably decay over time as facts change and\npreviously learned information becomes outdated. Traditional approaches such as\nfine-tuning are often impractical for updating these models due to their size\nand complexity. Instead, direct knowledge editing within the models presents a\nmore viable solution. Current model editing techniques, however, typically\noverlook the unique influence ranges of different facts, leading to compromised\nmodel performance in terms of both generality and locality. To address this\nissue, we introduce the concept of the generality-locality trade-off in\nmulti-modal model editing. We develop a new model editing dataset named OKEDIT,\nspecifically designed to effectively evaluate this trade-off. Building on this\nfoundation, we propose BalancEdit, a novel method for balanced model editing\nthat dynamically achieves an optimal balance between generality and locality.\nBalancEdit utilizes a unique mechanism that generates both positive and\nnegative samples for each fact to accurately determine its influence scope and\nincorporates these insights into the model's latent space using a discrete,\nlocalized codebook of edits, without modifying the underlying model weights. To\nour knowledge, this is the first approach explicitly addressing the\ngenerality-locality trade-off in multi-modal model editing. Our comprehensive\nresults confirm the effectiveness of BalancEdit, demonstrating minimal\ntrade-offs while maintaining robust editing capabilities. Our code and dataset\nwill be available.",
      "tldr_zh": "该论文针对大型 multi-modal models 随着时间变化而过时的挑战，引入 generality-locality trade-off 概念，并开发了 OKEDIT 数据集来评估这一权衡问题。BalancEdit 方法通过生成正负样本动态确定不同事实的影响范围，并在模型的 latent space 中使用离散的 localized codebook 进行编辑，从而避免修改底层模型权重。实验结果证明，BalancEdit 实现了最小 trade-off，同时保持了稳健的知识编辑能力，并将公开代码和数据集。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01343v1",
      "published_date": "2025-05-02 15:31:32 UTC",
      "updated_date": "2025-05-02 15:31:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:58:13.008097"
    },
    {
      "arxiv_id": "2505.01328v1",
      "title": "Constrained Network Adversarial Attacks: Validity, Robustness, and Transferability",
      "title_zh": "翻译失败",
      "authors": [
        "Anass Grini",
        "Oumaima Taheri",
        "Btissam El Khamlichi",
        "Amal El Fallah-Seghrouchni"
      ],
      "abstract": "While machine learning has significantly advanced Network Intrusion Detection\nSystems (NIDS), particularly within IoT environments where devices generate\nlarge volumes of data and are increasingly susceptible to cyber threats, these\nmodels remain vulnerable to adversarial attacks. Our research reveals a\ncritical flaw in existing adversarial attack methodologies: the frequent\nviolation of domain-specific constraints, such as numerical and categorical\nlimits, inherent to IoT and network traffic. This leads to up to 80.3% of\nadversarial examples being invalid, significantly overstating real-world\nvulnerabilities. These invalid examples, though effective in fooling models, do\nnot represent feasible attacks within practical IoT deployments. Consequently,\nrelying on these results can mislead resource allocation for defense, inflating\nthe perceived susceptibility of IoT-enabled NIDS models to adversarial\nmanipulation. Furthermore, we demonstrate that simpler surrogate models like\nMulti-Layer Perceptron (MLP) generate more valid adversarial examples compared\nto complex architectures such as CNNs and LSTMs. Using the MLP as a surrogate,\nwe analyze the transferability of adversarial severity to other ML/DL models\ncommonly used in IoT contexts. This work underscores the importance of\nconsidering both domain constraints and model architecture when evaluating and\ndesigning robust ML/DL models for security-critical IoT and network\napplications.",
      "tldr_zh": "这篇论文揭示了现有对抗攻击方法在IoT和网络流量中的领域特定约束问题，导致高达80.3%的对抗样本无效，从而夸大真实模型漏洞并误导防御资源分配。研究发现，简单模型如Multi-Layer Perceptron (MLP)比复杂架构如CNNs和LSTMs生成更多有效对抗样本，并使用MLP作为代理模型分析了这些样本的转移性到其他ML/DL模型。最终，该工作强调在评估和设计IoT网络入侵检测系统(NIDS)时，必须考虑约束和模型架构，以提升模型的鲁棒性和实际安全性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01328v1",
      "published_date": "2025-05-02 15:01:42 UTC",
      "updated_date": "2025-05-02 15:01:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:58:22.932995"
    },
    {
      "arxiv_id": "2505.05491v1",
      "title": "MDDFNet: Mamba-based Dynamic Dual Fusion Network for Traffic Sign Detection",
      "title_zh": "翻译失败",
      "authors": [
        "TianYi Yu"
      ],
      "abstract": "The Detection of small objects, especially traffic signs, is a critical\nsub-task in object detection and autonomous driving. Despite signficant\nprogress in previous research, two main challenges remain. First, the issue of\nfeature extraction being too singular. Second, the detection process struggles\nto efectively handle objects of varying sizes or scales. These problems are\nalso prevalent in general object detection tasks. To address these challenges,\nwe propose a novel object detection network, Mamba-based Dynamic Dual Fusion\nNetwork (MDDFNet), for traffic sign detection. The network integrates a dynamic\ndual fusion module and a Mamba-based backbone to simultaneously tackle the\naforementioned issues. Specifically, the dynamic dual fusion module utilizes\nmultiple branches to consolidate various spatial and semantic information, thus\nenhancing feature diversity. The Mamba-based backbone leverages global feature\nfusion and local feature interaction, combining features in an adaptive manner\nto generate unique classification characteristics. Extensive experiments\nconducted on the TT100K (Tsinghua-Tencent 100K) datasets demonstrate that\nMDDFNet outperforms other state-of-the-art detectors, maintaining real-time\nprocessing capabilities of single-stage models while achieving superior\nperformance. This confirms the efectiveness of MDDFNet in detecting small\ntraffic signs.",
      "tldr_zh": "该研究针对交通标志检测中的小物体挑战，提出了一种新型网络 MDDFNet，以解决特征提取单一和处理不同规模物体的问题。MDDFNet 整合了动态双融合模块（dynamic dual fusion module），通过多个分支增强空间和语义信息的多样性，以及 Mamba-based backbone，利用全局特征融合和本地特征交互实现自适应特征结合。实验在 TT100K 数据集上显示，MDDFNet 优于其他最先进检测器，保持单阶段模型的实时处理能力，同时显著提高了小交通标志的检测准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05491v1",
      "published_date": "2025-05-02 14:53:25 UTC",
      "updated_date": "2025-05-02 14:53:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:58:34.634851"
    },
    {
      "arxiv_id": "2505.01476v1",
      "title": "CostFilter-AD: Enhancing Anomaly Detection through Matching Cost Filtering",
      "title_zh": "CostFilter-AD：通过匹配成本过滤增强异常检测",
      "authors": [
        "Zhe Zhang",
        "Mingxiu Cai",
        "Hanxiao Wang",
        "Gaochang Wu",
        "Tianyou Chai",
        "Xiatian Zhu"
      ],
      "abstract": "Unsupervised anomaly detection (UAD) seeks to localize the anomaly mask of an\ninput image with respect to normal samples. Either by reconstructing normal\ncounterparts (reconstruction-based) or by learning an image feature embedding\nspace (embedding-based), existing approaches fundamentally rely on image-level\nor feature-level matching to derive anomaly scores. Often, such a matching\nprocess is inaccurate yet overlooked, leading to sub-optimal detection. To\naddress this issue, we introduce the concept of cost filtering, borrowed from\nclassical matching tasks, such as depth and flow estimation, into the UAD\nproblem. We call this approach {\\em CostFilter-AD}. Specifically, we first\nconstruct a matching cost volume between the input and normal samples,\ncomprising two spatial dimensions and one matching dimension that encodes\npotential matches. To refine this, we propose a cost volume filtering network,\nguided by the input observation as an attention query across multiple feature\nlayers, which effectively suppresses matching noise while preserving edge\nstructures and capturing subtle anomalies. Designed as a generic\npost-processing plug-in, CostFilter-AD can be integrated with either\nreconstruction-based or embedding-based methods. Extensive experiments on\nMVTec-AD and VisA benchmarks validate the generic benefits of CostFilter-AD for\nboth single- and multi-class UAD tasks. Code and models will be released at\nhttps://github.com/ZHE-SAPI/CostFilter-AD.",
      "tldr_zh": "本文提出 CostFilter-AD 方法，以解决无监督异常检测 (UAD) 中匹配过程不准确导致的检测 suboptimal 问题。通过借鉴经典匹配任务（如深度和光流估计），该方法首先构建输入图像与正常样本之间的匹配成本体积，然后使用一个成本体积过滤网络，以输入观察作为注意力查询，抑制匹配噪声、保留边缘结构并捕获细微异常。CostFilter-AD 设计为通用后处理插件，可整合到重建-based 或 embedding-based 方法中；实验在 MVTec-AD 和 VisA 基准上验证了其在单类和多类 UAD 任务中的显著性能提升。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "20 pages, 11 figures, 10 tables, accepted by Forty-Second\n  International Conference on Machine Learning ( ICML 2025 )",
      "pdf_url": "http://arxiv.org/pdf/2505.01476v1",
      "published_date": "2025-05-02 14:52:34 UTC",
      "updated_date": "2025-05-02 14:52:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:58:47.120122"
    },
    {
      "arxiv_id": "2505.01315v2",
      "title": "Helping Large Language Models Protect Themselves: An Enhanced Filtering and Summarization System",
      "title_zh": "翻译失败",
      "authors": [
        "Sheikh Samit Muhaimin",
        "Spyridon Mastorakis"
      ],
      "abstract": "The recent growth in the use of Large Language Models has made them\nvulnerable to sophisticated adversarial assaults, manipulative prompts, and\nencoded malicious inputs. Existing countermeasures frequently necessitate\nretraining models, which is computationally costly and impracticable for\ndeployment. Without the need for retraining or fine-tuning, this study presents\na unique defense paradigm that allows LLMs to recognize, filter, and defend\nagainst adversarial or malicious inputs on their own. There are two main parts\nto the suggested framework: (1) A prompt filtering module that uses\nsophisticated Natural Language Processing (NLP) techniques, including zero-shot\nclassification, keyword analysis, and encoded content detection (e.g. base64,\nhexadecimal, URL encoding), to detect, decode, and classify harmful inputs; and\n(2) A summarization module that processes and summarizes adversarial research\nliterature to give the LLM context-aware defense knowledge. This approach\nstrengthens LLMs' resistance to adversarial exploitation by fusing text\nextraction, summarization, and harmful prompt analysis. According to\nexperimental results, this integrated technique has a 98.71% success rate in\nidentifying harmful patterns, manipulative language structures, and encoded\nprompts. By employing a modest amount of adversarial research literature as\ncontext, the methodology also allows the model to react correctly to harmful\ninputs with a larger percentage of jailbreak resistance and refusal rate. While\nmaintaining the quality of LLM responses, the framework dramatically increases\nLLM's resistance to hostile misuse, demonstrating its efficacy as a quick and\neasy substitute for time-consuming, retraining-based defenses.",
      "tldr_zh": "这篇论文提出了一种无需重新训练或微调的防御框架，帮助Large Language Models (LLMs) 自主识别、过滤和抵御对抗性攻击、操纵提示及编码恶意输入。框架包括两个核心模块：提示过滤模块，利用Natural Language Processing (NLP) 技术如zero-shot classification、关键词分析和编码内容检测（例如base64、十六进制、URL编码）来检测及分类有害输入；以及总结模块，通过处理和总结对抗性研究文献，提供上下文感知的防御知识。实验结果显示，该系统在识别有害模式上成功率达98.71%，显著提升了LLMs的越狱抵抗力和拒绝率，同时保持了模型响应的质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01315v2",
      "published_date": "2025-05-02 14:42:26 UTC",
      "updated_date": "2025-05-05 14:46:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:58:59.367089"
    },
    {
      "arxiv_id": "2505.01309v1",
      "title": "Enhancing SPARQL Query Rewriting for Complex Ontology Alignments",
      "title_zh": "针对复杂本体对齐的 SPARQL 查询重写增强",
      "authors": [
        "Anicet Lepetit Ondo",
        "Laurence Capus",
        "Mamadou Bousso"
      ],
      "abstract": "SPARQL query rewriting is a fundamental mechanism for uniformly querying\nheterogeneous ontologies in the Linked Data Web. However, the complexity of\nontology alignments, particularly rich correspondences (c : c), makes this\nprocess challenging. Existing approaches primarily focus on simple (s : s) and\npartially complex ( s : c) alignments, thereby overlooking the challenges posed\nby more expressive alignments. Moreover, the intricate syntax of SPARQL\npresents a barrier for non-expert users seeking to fully exploit the knowledge\nencapsulated in ontologies. This article proposes an innovative approach for\nthe automatic rewriting of SPARQL queries from a source ontology to a target\nontology, based on a user's need expressed in natural language. It leverages\nthe principles of equivalence transitivity as well as the advanced capabilities\nof large language models such as GPT-4. By integrating these elements, this\napproach stands out for its ability to efficiently handle complex alignments,\nparticularly (c : c) correspondences , by fully exploiting their\nexpressiveness. Additionally, it facilitates access to aligned ontologies for\nusers unfamiliar with SPARQL, providing a flexible solution for querying\nheterogeneous data.",
      "tldr_zh": "该论文针对SPARQL查询重写在处理复杂本体对齐（特别是c : c对应关系）时的挑战，提出了一种创新方法。该方法利用等价传递性原则和大型语言模型（如GPT-4）自动将SPARQL查询从源本体重写到目标本体，基于用户用自然语言表达的需求。通过充分利用复杂对齐的表达性，该方法显著提高了查询效率，并解决了现有方法对简单对齐（s : s）和部分复杂对齐（s : c）的局限性。该创新方案使不熟悉SPARQL的非专家用户能够更轻松地查询异构数据，提供了一个灵活且高效的解决方案。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01309v1",
      "published_date": "2025-05-02 14:38:13 UTC",
      "updated_date": "2025-05-02 14:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:59:10.991225"
    },
    {
      "arxiv_id": "2505.01307v1",
      "title": "Document Retrieval Augmented Fine-Tuning (DRAFT) for safety-critical software assessments",
      "title_zh": "文档检索增强微调 (DRAFT) 用于安全关键软件评估",
      "authors": [
        "Regan Bolton",
        "Mohammadreza Sheikhfathollahi",
        "Simon Parkinson",
        "Vanessa Vulovic",
        "Gary Bamford",
        "Dan Basher",
        "Howard Parkinson"
      ],
      "abstract": "Safety critical software assessment requires robust assessment against\ncomplex regulatory frameworks, a process traditionally limited by manual\nevaluation. This paper presents Document Retrieval-Augmented Fine-Tuning\n(DRAFT), a novel approach that enhances the capabilities of a large language\nmodel (LLM) for safety-critical compliance assessment. DRAFT builds upon\nexisting Retrieval-Augmented Generation (RAG) techniques by introducing a novel\nfine-tuning framework that accommodates our dual-retrieval architecture, which\nsimultaneously accesses both software documentation and applicable reference\nstandards. To fine-tune DRAFT, we develop a semi-automated dataset generation\nmethodology that incorporates variable numbers of relevant documents with\nmeaningful distractors, closely mirroring real-world assessment scenarios.\nExperiments with GPT-4o-mini demonstrate a 7% improvement in correctness over\nthe baseline model, with qualitative improvements in evidence handling,\nresponse structure, and domain-specific reasoning. DRAFT represents a practical\napproach to improving compliance assessment systems while maintaining the\ntransparency and evidence-based reasoning essential in regulatory domains.",
      "tldr_zh": "本文提出了一种名为 Document Retrieval-Augmented Fine-Tuning (DRAFT) 的新方法，用于提升大型语言模型 (LLM) 在安全关键软件评估中的性能。DRAFT 基于 Retrieval-Augmented Generation (RAG) 技术，引入双重检索架构，同时访问软件文档和参考标准，并采用半自动数据集生成方法，以包含相关文档和干扰项，模拟真实评估场景。实验结果显示，在 GPT-4o-mini 模型上，DRAFT 比基线模型正确率提高了 7%，并在证据处理、响应结构和领域特定推理方面实现了定性提升。该方法为安全关键软件的合规性评估提供了实用、可透明的解决方案，确保基于证据的推理。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01307v1",
      "published_date": "2025-05-02 14:34:33 UTC",
      "updated_date": "2025-05-02 14:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:59:23.804355"
    },
    {
      "arxiv_id": "2505.01305v1",
      "title": "Early Detection of Patient Deterioration from Real-Time Wearable Monitoring System",
      "title_zh": "翻译失败",
      "authors": [
        "Lo Pang-Yun Ting",
        "Hong-Pei Chen",
        "An-Shan Liu",
        "Chun-Yin Yeh",
        "Po-Lin Chen",
        "Kun-Ta Chuang"
      ],
      "abstract": "Early detection of patient deterioration is crucial for reducing mortality\nrates. Heart rate data has shown promise in assessing patient health, and\nwearable devices offer a cost-effective solution for real-time monitoring.\nHowever, extracting meaningful insights from diverse heart rate data and\nhandling missing values in wearable device data remain key challenges. To\naddress these challenges, we propose TARL, an innovative approach that models\nthe structural relationships of representative subsequences, known as\nshapelets, in heart rate time series. TARL creates a shapelet-transition\nknowledge graph to model shapelet dynamics in heart rate time series,\nindicating illness progression and potential future changes. We further\nintroduce a transition-aware knowledge embedding to reinforce relationships\namong shapelets and quantify the impact of missing values, enabling the\nformulation of comprehensive heart rate representations. These representations\ncapture explanatory structures and predict future heart rate trends, aiding\nearly illness detection. We collaborate with physicians and nurses to gather\nICU patient heart rate data from wearables and diagnostic metrics assessing\nillness severity for evaluating deterioration. Experiments on real-world ICU\ndata demonstrate that TARL achieves both high reliability and early detection.\nA case study further showcases TARL's explainable detection process,\nhighlighting its potential as an AI-driven tool to assist clinicians in\nrecognizing early signs of patient deterioration.",
      "tldr_zh": "本文提出 TARL 方法，利用可穿戴设备的心率时间序列数据，通过识别代表性子序列（shapelets）和构建 shapelet-transition 知识图谱，来早期检测患者恶化。TARL 引入 transition-aware 知识嵌入强化 shapelets 间的关系，并量化缺失值的影响，以生成全面的心率表示并预测未来趋势。实验在真实 ICU 数据上证明，TARL 实现了高可靠性和早期检测，并通过案例研究展示了其可解释性过程，为临床医生提供 AI 辅助工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01305v1",
      "published_date": "2025-05-02 14:32:44 UTC",
      "updated_date": "2025-05-02 14:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:59:35.228357"
    },
    {
      "arxiv_id": "2505.06257v1",
      "title": "Beyond Attention: Toward Machines with Intrinsic Higher Mental States",
      "title_zh": "超越注意力：向着具有内在高级心理状态的机器",
      "authors": [
        "Ahsan Adeel"
      ],
      "abstract": "Attending to what is relevant is fundamental to both the mammalian brain and\nmodern machine learning models such as Transformers. Yet, determining relevance\nremains a core challenge, traditionally offloaded to learning algorithms like\nbackpropagation. Inspired by recent cellular neurobiological evidence linking\nneocortical pyramidal cells to distinct mental states, this work shows how\nmodels (e.g., Transformers) can emulate high-level perceptual processing and\nawake thought (imagination) states to pre-select relevant information before\napplying attention. Triadic neuronal-level modulation loops among questions\n($Q$), clues (keys, $K$), and hypotheses (values, $V$) enable diverse, deep,\nparallel reasoning chains at the representation level and allow a rapid shift\nfrom initial biases to refined understanding. This leads to orders-of-magnitude\nfaster learning with significantly reduced computational demand (e.g., fewer\nheads, layers, and tokens), at an approximate cost of $\\mathcal{O}(N)$, where\n$N$ is the number of input tokens. Results span reinforcement learning (e.g.,\nCarRacing in a high-dimensional visual setup), computer vision, and natural\nlanguage question answering.",
      "tldr_zh": "该论文提出超越传统注意力机制的方法，旨在让机器（如 Transformers）通过模拟高级感知处理和清醒思考（imagination）状态，预选相关信息以实现内在的高级心理状态。该方法受神经生物学启发，引入Triadic neuronal-level modulation loops 涉及Q、K、V，启用深度并行推理链，显著提升学习速度并减少计算需求（如减少 heads、layers 和 tokens，复杂度约为O(N)）。实验结果显示，在reinforcement learning（如CarRacing高维视觉任务）、计算机视觉和自然语言问答等领域，该框架实现了数量级级的更快学习和更高效性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06257v1",
      "published_date": "2025-05-02 14:31:10 UTC",
      "updated_date": "2025-05-02 14:31:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:59:47.512329"
    },
    {
      "arxiv_id": "2505.01475v2",
      "title": "CodeSSM: Towards State Space Models for Code Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Shweta Verma",
        "Abhinav Anand",
        "Mira Mezini"
      ],
      "abstract": "Although transformers are widely used for various code-specific tasks, they\nhave some significant limitations. In this paper, we investigate State Space\nModels (SSMs) as a potential alternative to transformers for code understanding\ntasks, such as code retrieval, classification, and clone detection. Previous\nresearch has already demonstrated that SSMs are more compute-efficient than\ntransformers. In our work, we show that SSMs are also more sample-efficient and\ncan effectively extrapolate to longer contexts (beyond the pretraining context)\nduring fine-tuning. Through comprehensive experiments, we demonstrate that SSMs\ncould serve as a viable alternative to transformers for code understanding\ntasks, while addressing some of the major limitations associated with\ntransformers.",
      "tldr_zh": "本论文探讨了 State Space Models (SSMs) 作为 transformers 在代码理解任务（如代码检索、分类和克隆检测）中的潜在替代方案。研究发现，SSMs 不仅在计算效率上优于 transformers，还具备更高的样本效率，并能有效外推到训练超出长度的上下文。实验结果表明，SSMs 可以解决 transformers 的主要局限性，提供一种可行的备选模型。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01475v2",
      "published_date": "2025-05-02 14:27:49 UTC",
      "updated_date": "2025-05-21 15:24:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:59:59.079094"
    },
    {
      "arxiv_id": "2505.01474v1",
      "title": "Watermark Overwriting Attack on StegaStamp algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "I. F. Serzhenko",
        "L. A. Khaertdinova",
        "M. A. Pautov",
        "A. V. Antsiferova"
      ],
      "abstract": "This paper presents an attack method on the StegaStamp watermarking algorithm\nthat completely removes watermarks from an image with minimal quality loss,\ndeveloped as part of the NeurIPS \"Erasing the invisible\" competition.",
      "tldr_zh": "本研究提出了一种针对 StegaStamp 算法的水印覆盖攻击方法，能够完全移除图像中的水印，同时保持图像质量的最小损失。该方法作为 NeurIPS \"Erasing the invisible\" 比赛的一部分开发，展示了在水印安全领域的新型攻击策略。通过实验验证，该攻击有效性强，为评估和改进水印算法提供了重要见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01474v1",
      "published_date": "2025-05-02 14:07:43 UTC",
      "updated_date": "2025-05-02 14:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:00:09.580110"
    },
    {
      "arxiv_id": "2505.01288v2",
      "title": "ViSA-Flow: Accelerating Robot Skill Learning via Large-Scale Video Semantic Action Flow",
      "title_zh": "ViSA-Flow：通过大规模视频语义动作流加速机器人技能学习",
      "authors": [
        "Changhe Chen",
        "Quantao Yang",
        "Xiaohao Xu",
        "Nima Fazeli",
        "Olov Andersson"
      ],
      "abstract": "One of the central challenges preventing robots from acquiring complex\nmanipulation skills is the prohibitive cost of collecting large-scale robot\ndemonstrations. In contrast, humans are able to learn efficiently by watching\nothers interact with their environment. To bridge this gap, we introduce\nsemantic action flow as a core intermediate representation capturing the\nessential spatio-temporal manipulator-object interactions, invariant to\nsuperficial visual differences. We present ViSA-Flow, a framework that learns\nthis representation self-supervised from unlabeled large-scale video data.\nFirst, a generative model is pre-trained on semantic action flows automatically\nextracted from large-scale human-object interaction video data, learning a\nrobust prior over manipulation structure. Second, this prior is efficiently\nadapted to a target robot by fine-tuning on a small set of robot demonstrations\nprocessed through the same semantic abstraction pipeline. We demonstrate\nthrough extensive experiments on the CALVIN benchmark and real-world tasks that\nViSA-Flow achieves state-of-the-art performance, particularly in low-data\nregimes, outperforming prior methods by effectively transferring knowledge from\nhuman video observation to robotic execution. Videos are available at\nhttps://visaflow-web.github.io/ViSAFLOW.",
      "tldr_zh": "机器人学习复杂操作技能的主要挑战是收集大规模演示数据的成本高，而ViSA-Flow框架通过引入semantic action flow作为核心中间表示，捕捉空间-时间操纵器-物体互动并忽略表面视觉差异，从而加速技能学习。框架首先从大规模无标签人类-物体互动视频中自监督提取semantic action flows，预训练一个生成模型以学习鲁棒的操纵结构先验；随后，通过少量机器人演示数据和相同的semantic abstraction pipeline进行微调，高效适应目标机器人。实验在CALVIN benchmark和真实任务上证明，ViSA-Flow在低数据条件下表现出色，优于现有方法，实现从人类视频观察到机器人执行的有效知识转移。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01288v2",
      "published_date": "2025-05-02 14:03:06 UTC",
      "updated_date": "2025-05-12 13:37:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:00:24.634408"
    },
    {
      "arxiv_id": "2505.01286v1",
      "title": "2DXformer: Dual Transformers for Wind Power Forecasting with Dual Exogenous Variables",
      "title_zh": "翻译失败",
      "authors": [
        "Yajuan Zhang",
        "Jiahai Jiang",
        "Yule Yan",
        "Liang Yang",
        "Ping Zhang"
      ],
      "abstract": "Accurate wind power forecasting can help formulate scientific dispatch plans,\nwhich is of great significance for maintaining the safety, stability, and\nefficient operation of the power system. In recent years, wind power\nforecasting methods based on deep learning have focused on extracting the\nspatiotemporal correlations among data, achieving significant improvements in\nforecasting accuracy. However, they exhibit two limitations. First, there is a\nlack of modeling for the inter-variable relationships, which limits the\naccuracy of the forecasts. Second, by treating endogenous and exogenous\nvariables equally, it leads to unnecessary interactions between the endogenous\nand exogenous variables, increasing the complexity of the model. In this paper,\nwe propose the 2DXformer, which, building upon the previous work's focus on\nspatiotemporal correlations, addresses the aforementioned two limitations.\nSpecifically, we classify the inputs of the model into three types: exogenous\nstatic variables, exogenous dynamic variables, and endogenous variables. First,\nwe embed these variables as variable tokens in a channel-independent manner.\nThen, we use the attention mechanism to capture the correlations among\nexogenous variables. Finally, we employ a multi-layer perceptron with residual\nconnections to model the impact of exogenous variables on endogenous variables.\nExperimental results on two real-world large-scale datasets indicate that our\nproposed 2DXformer can further improve the performance of wind power\nforecasting. The code is available in this repository:\n\\href{https://github.com/jseaj/2DXformer}{https://github.com/jseaj/2DXformer}.",
      "tldr_zh": "该论文提出 2DXformer，一种双 Transformer 框架，用于风力发电预测，旨在解决现有深度学习方法在变量间关系建模和内生与外生变量交互方面的局限性。具体而言，2DXformer 将输入分类为外生静态变量、外生动态变量和内生变量，通过通道独立的变量嵌入、注意力机制捕获外生变量相关性，以及多层感知器与残差连接建模外生变量对内生变量的影响，从而提升预测准确性。在两个真实世界大型数据集上的实验结果表明，该方法显著提高了风力发电预测性能，并提供了开源代码以便复现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICDM 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.01286v1",
      "published_date": "2025-05-02 14:00:48 UTC",
      "updated_date": "2025-05-02 14:00:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:00:34.944329"
    },
    {
      "arxiv_id": "2505.01283v1",
      "title": "Reduced-order structure-property linkages for stochastic metamaterials",
      "title_zh": "随机元材料的降阶结构-性能联系",
      "authors": [
        "Hooman Danesh",
        "Maruthi Annamaraju",
        "Tim Brepols",
        "Stefanie Reese",
        "Surya R. Kalidindi"
      ],
      "abstract": "The capabilities of additive manufacturing have facilitated the design and\nproduction of mechanical metamaterials with diverse unit cell geometries.\nEstablishing linkages between the vast design space of unit cells and their\neffective mechanical properties is critical for the efficient design and\nperformance evaluation of such metamaterials. However, physics-based\nsimulations of metamaterial unit cells across the entire design space are\ncomputationally expensive, necessitating a materials informatics framework to\nefficiently capture complex structure-property relationships. In this work,\nprincipal component analysis of 2-point correlation functions is performed to\nextract the salient features from a large dataset of randomly generated 2D\nmetamaterials. Physics-based simulations are performed using a fast Fourier\ntransform (FFT)-based homogenization approach to efficiently compute the\nhomogenized effective elastic stiffness across the extensive unit cell designs.\nSubsequently, Gaussian process regression is used to generate reduced-order\nsurrogates, mapping unit cell designs to their homogenized effective elastic\nconstant. It is demonstrated that the adopted workflow enables a high-value\nlow-dimensional representation of the voluminous stochastic metamaterial\ndataset, facilitating the construction of robust structure-property maps.\nFinally, an uncertainty-based active learning framework is utilized to train a\nsurrogate model with a significantly smaller number of data points compared to\nthe original full dataset. It is shown that a dataset as small as $0.61\\%$ of\nthe entire dataset is sufficient to generate accurate and robust\nstructure-property maps.",
      "tldr_zh": "本文提出了一种减少阶的结构-属性关联框架，用于处理随机 metamaterials 的设计空间问题，通过 principal component analysis 分析 2-point correlation functions 从大量 2D metamaterials 数据中提取关键特征，并结合 FFT-based homogenization 方法快速计算 homogenized effective elastic stiffness。接着，使用 Gaussian process regression 构建 reduced-order surrogates，将 unit cell 设计映射到有效弹性常数，实现高效的 structure-property 关系建模。该方法通过 uncertainty-based active learning 框架，仅需原数据集的 0.61% 数据点，即可生成准确且鲁棒的结构-属性映射图，显著降低了计算成本。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01283v1",
      "published_date": "2025-05-02 13:58:47 UTC",
      "updated_date": "2025-05-02 13:58:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:00:47.104128"
    },
    {
      "arxiv_id": "2505.01281v1",
      "title": "A Physics-preserved Transfer Learning Method for Differential Equations",
      "title_zh": "翻译失败",
      "authors": [
        "Hao-Ran Yang",
        "Chuan-Xian Ren"
      ],
      "abstract": "While data-driven methods such as neural operator have achieved great success\nin solving differential equations (DEs), they suffer from domain shift problems\ncaused by different learning environments (with data bias or equation changes),\nwhich can be alleviated by transfer learning (TL). However, existing TL methods\nadopted in DEs problems lack either generalizability in general DEs problems or\nphysics preservation during training. In this work, we focus on a general\ntransfer learning method that adaptively correct the domain shift and preserve\nphysical information. Mathematically, we characterize the data domain as\nproduct distribution and the essential problems as distribution bias and\noperator bias. A Physics-preserved Optimal Tensor Transport (POTT) method that\nsimultaneously admits generalizability to common DEs and physics preservation\nof specific problem is proposed to adapt the data-driven model to target domain\nutilizing the push-forward distribution induced by the POTT map. Extensive\nexperiments demonstrate the superior performance, generalizability and physics\npreservation of the proposed POTT method.",
      "tldr_zh": "该研究针对数据驱动方法（如神经算子）在解决微分方程（DEs）时遇到的领域转移问题（如数据偏差或方程变化），提出了一种通用迁移学习（TL）方法，以自适应修正偏差并保留物理信息。数学上，该方法将数据域表征为乘积分布，并通过Physics-preserved Optimal Tensor Transport (POTT) 技术处理分布偏差和算子偏差，利用POTT映射诱导的推前分布来适应模型到目标域。实验结果显示，POTT方法在泛化性和物理保留方面表现出色，显著提升了性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01281v1",
      "published_date": "2025-05-02 13:58:36 UTC",
      "updated_date": "2025-05-02 13:58:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:00:58.719204"
    },
    {
      "arxiv_id": "2505.01261v1",
      "title": "Enhancing Obsolescence Forecasting with Deep Generative Data Augmentation: A Semi-Supervised Framework for Low-Data Industrial Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Elie Saad",
        "Mariem Besbes",
        "Marc Zolghadri",
        "Victor Czmil",
        "Claude Baron",
        "Vincent Bourgeois"
      ],
      "abstract": "The challenge of electronic component obsolescence is particularly critical\nin systems with long life cycles. Various obsolescence management methods are\nemployed to mitigate its impact, with obsolescence forecasting being a highly\nsought-after and prominent approach. As a result, numerous machine\nlearning-based forecasting methods have been proposed. However, machine\nlearning models require a substantial amount of relevant data to achieve high\nprecision, which is lacking in the current obsolescence landscape in some\nsituations. This work introduces a novel framework for obsolescence forecasting\nbased on deep learning. The proposed framework solves the lack of available\ndata through deep generative modeling, where new obsolescence cases are\ngenerated and used to augment the training dataset. The augmented dataset is\nthen used to train a classical machine learning-based obsolescence forecasting\nmodel. To train classical forecasting models using augmented datasets, existing\nclassical supervised-learning classifiers are adapted for semi-supervised\nlearning within this framework. The proposed framework demonstrates\nstate-of-the-art results on benchmarking datasets.",
      "tldr_zh": "这篇论文提出了一种基于深度生成数据扩充（deep generative data augmentation）的半监督框架（semi-supervised framework），旨在提升电子元件过时预测（obsolescence forecasting）的准确性，尤其适用于数据稀缺的工业场景。框架通过深度生成模型创建新过时案例来扩充训练数据集，并将经典监督学习分类器适应为半监督学习，以训练机器学习模型。实验结果表明，该框架在基准数据集上实现了最先进的状态-ofthe-art性能，有效缓解了长寿命系统中的数据不足问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01261v1",
      "published_date": "2025-05-02 13:28:50 UTC",
      "updated_date": "2025-05-02 13:28:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:01:10.286156"
    },
    {
      "arxiv_id": "2505.01238v1",
      "title": "EvalxNLP: A Framework for Benchmarking Post-Hoc Explainability Methods on NLP Models",
      "title_zh": "EvalxNLP：用于在 NLP 模型上基准测试事后解释性方法的框架",
      "authors": [
        "Mahdi Dhaini",
        "Kafaite Zahra Hussain",
        "Efstratios Zaradoukas",
        "Gjergji Kasneci"
      ],
      "abstract": "As Natural Language Processing (NLP) models continue to evolve and become\nintegral to high-stakes applications, ensuring their interpretability remains a\ncritical challenge. Given the growing variety of explainability methods and\ndiverse stakeholder requirements, frameworks that help stakeholders select\nappropriate explanations tailored to their specific use cases are increasingly\nimportant. To address this need, we introduce EvalxNLP, a Python framework for\nbenchmarking state-of-the-art feature attribution methods for transformer-based\nNLP models. EvalxNLP integrates eight widely recognized explainability\ntechniques from the Explainable AI (XAI) literature, enabling users to generate\nand evaluate explanations based on key properties such as faithfulness,\nplausibility, and complexity. Our framework also provides interactive,\nLLM-based textual explanations, facilitating user understanding of the\ngenerated explanations and evaluation outcomes. Human evaluation results\nindicate high user satisfaction with EvalxNLP, suggesting it is a promising\nframework for benchmarking explanation methods across diverse user groups. By\noffering a user-friendly and extensible platform, EvalxNLP aims at\ndemocratizing explainability tools and supporting the systematic comparison and\nadvancement of XAI techniques in NLP.",
      "tldr_zh": "本论文介绍了 EvalxNLP，一个用于基准测试 NLP 模型后验解释性方法的 Python 框架，旨在帮助用户根据特定应用场景选择合适的解释方法。该框架整合了八种先进的特征归因技术，支持基于 faithfulness（忠实度）、plausibility（合理性）和 complexity（复杂度）等属性的解释生成和评估，并提供交互式 LLM-based 文本解释以提升用户理解。实验结果显示，人类评估对 EvalxNLP 的满意度很高，证明其作为基准工具的潜力，并有助于推动 XAI 技术在 NLP 领域的系统比较和进步。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the xAI World Conference (2025) - System Demonstration",
      "pdf_url": "http://arxiv.org/pdf/2505.01238v1",
      "published_date": "2025-05-02 13:00:05 UTC",
      "updated_date": "2025-05-02 13:00:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:01:23.003002"
    },
    {
      "arxiv_id": "2505.02854v1",
      "title": "Ensuring Reproducibility in Generative AI Systems for General Use Cases: A Framework for Regression Testing and Open Datasets",
      "title_zh": "确保生成式人工智能系统在通用用例中的可重复性：一个用于回归测试和开放数据集的框架",
      "authors": [
        "Masumi Morishige",
        "Ryo Koshihara"
      ],
      "abstract": "Reproducibility and reliability remain pressing challenges for generative AI\nsystems whose behavior can drift with each model update or prompt revision. We\nintroduce GPR-bench, a lightweight, extensible benchmark that operationalizes\nregression testing for general purpose use cases. GPR-bench couples an open,\nbilingual (English and Japanese) dataset covering eight task categories (e.g.,\ntext generation, code generation, and information retrieval) and 10 scenarios\nin each task categories (80 total test cases for each language) with an\nautomated evaluation pipeline that employs \"LLM-as-a-Judge\" scoring of\ncorrectness and conciseness. Experiments across three recent model versions -\ngpt-4o-mini, o3-mini, and o4-mini - and two prompt configurations (default\nversus concise-writing instruction) reveal heterogeneous quality. Our results\nshow that newer models generally improve correctness, but the differences are\nmodest and not statistically significant, suggesting that GPR-bench may not be\nsufficiently challenging to differentiate between recent model versions. In\ncontrast, the concise-writing instruction significantly enhances conciseness\n(+12.37 pp, Mann-Whitney U test: p < 0.001, effect size r = 0.2995) with\nminimal degradations on accuracy (-1.7 pp), demonstrating the effectiveness of\nprompt engineering. Released under the MIT License, GPR- bench lowers the\nbarrier to initiating reproducibility monitoring and provides a foundation for\ncommunity-driven extensions, while also raising important considerations about\nbenchmark design for rapidly evolving language models.",
      "tldr_zh": "本文提出 GPR-bench，一种轻量级、可扩展的基准框架，用于确保通用生成式 AI 系统的可重复性和可靠性，通过回归 testing 进行操作化评估。该框架结合了一个开放的双语（英语和日语）数据集，涵盖八个任务类别（如文本生成、代码生成和信息检索）以及每个类别的10个场景（总计80个测试案例每种语言），并采用 LLM-as-a-Judge 的自动化评估管道来评分正确性和简洁性。实验结果显示，三种模型版本（gpt-4o-mini、o3-mini 和 o4-mini）在新版本中正确性略有改善，但差异不显著；然而，简洁写作指令显著提升了输出简洁性（+12.37 pp），同时仅轻微降低准确性（-1.7 pp），突显了提示工程的有效性。GPR-bench 以 MIT License 发布，降低了可重复性监控的门槛，并为社区驱动扩展提供了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.02854v1",
      "published_date": "2025-05-02 12:31:43 UTC",
      "updated_date": "2025-05-02 12:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:01:36.732824"
    },
    {
      "arxiv_id": "2505.02853v1",
      "title": "A Computational Model of Inclusive Pedagogy: From Understanding to Application",
      "title_zh": "包容性教学法的计算模型：从理解到应用",
      "authors": [
        "Francesco Balzan",
        "Pedro P. Santos",
        "Maurizio Gabbrielli",
        "Mahault Albarracin",
        "Manuel Lopes"
      ],
      "abstract": "Human education transcends mere knowledge transfer, it relies on\nco-adaptation dynamics -- the mutual adjustment of teaching and learning\nstrategies between agents. Despite its centrality, computational models of\nco-adaptive teacher-student interactions (T-SI) remain underdeveloped. We argue\nthat this gap impedes Educational Science in testing and scaling contextual\ninsights across diverse settings, and limits the potential of Machine Learning\nsystems, which struggle to emulate and adaptively support human learning\nprocesses. To address this, we present a computational T-SI model that\nintegrates contextual insights on human education into a testable framework. We\nuse the model to evaluate diverse T-SI strategies in a realistic synthetic\nclassroom setting, simulating student groups with unequal access to sensory\ninformation. Results show that strategies incorporating co-adaptation\nprinciples (e.g., bidirectional agency) outperform unilateral approaches (i.e.,\nwhere only the teacher or the student is active), improving the learning\noutcomes for all learning types. Beyond the testing and scaling of\ncontext-dependent educational insights, our model enables hypothesis generation\nin controlled yet adaptable environments. This work bridges non-computational\ntheories of human education with scalable, inclusive AI in Education systems,\nproviding a foundation for equitable technologies that dynamically adapt to\nlearner needs.",
      "tldr_zh": "该论文指出，人类教育依赖于教学和学习策略之间的共同适应（co-adaptation），但现有计算模型（T-SI）不足，导致教育科学难以测试和扩展，以及Machine Learning系统无法有效模拟人类学习。该研究提出一个计算T-SI模型，将人类教育的背景洞见整合进可测试框架，并在模拟课堂环境中评估不同策略，结果显示采用双向代理等共同适应原则的策略优于单向方法，提升了所有学习类型的学习成果。该模型不仅促进教育洞见的测试和扩展，还桥接非计算理论与可扩展的AI教育系统，支持开发动态适应学习者需求的公平技术。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "This is a preprint version of a manuscript intended for submission to\n  the International Journal of Artificial Intelligence in Education (IJAIED)",
      "pdf_url": "http://arxiv.org/pdf/2505.02853v1",
      "published_date": "2025-05-02 12:26:31 UTC",
      "updated_date": "2025-05-02 12:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:01:47.028379"
    },
    {
      "arxiv_id": "2505.03811v1",
      "title": "ScarceGAN: Discriminative Classification Framework for Rare Class Identification for Longitudinal Data with Weak Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Surajit Chakrabarty",
        "Rukma Talwadker",
        "Tridib Mukherjee"
      ],
      "abstract": "This paper introduces ScarceGAN which focuses on identification of extremely\nrare or scarce samples from multi-dimensional longitudinal telemetry data with\nsmall and weak label prior. We specifically address: (i) severe scarcity in\npositive class, stemming from both underlying organic skew in the data, as well\nas extremely limited labels; (ii) multi-class nature of the negative samples,\nwith uneven density distributions and partially overlapping feature\ndistributions; and (iii) massively unlabelled data leading to tiny and weak\nprior on both positive and negative classes, and possibility of unseen or\nunknown behavior in the unlabelled set, especially in the negative class.\nAlthough related to PU learning problems, we contend that knowledge (or lack of\nit) on the negative class can be leveraged to learn the compliment of it (i.e.,\nthe positive class) better in a semi-supervised manner. To this effect,\nScarceGAN re-formulates semi-supervised GAN by accommodating weakly labelled\nmulti-class negative samples and the available positive samples. It relaxes the\nsupervised discriminator's constraint on exact differentiation between negative\nsamples by introducing a 'leeway' term for samples with noisy prior. We propose\nmodifications to the cost objectives of discriminator, in supervised and\nunsupervised path as well as that of the generator. For identifying risky\nplayers in skill gaming, this formulation in whole gives us a recall of over\n85% (~60% jump over vanilla semi-supervised GAN) on our scarce class with very\nminimal verbosity in the unknown space. Further ScarceGAN outperforms the\nrecall benchmarks established by recent GAN based specialized models for the\npositive imbalanced class identification and establishes a new benchmark in\nidentifying one of rare attack classes (0.09%) in the intrusion dataset from\nthe KDDCUP99 challenge.",
      "tldr_zh": "这篇论文引入了 ScarceGAN，一种判别分类框架，旨在从多维纵向遥测数据中识别极度稀有的正类样本，同时处理正类样本稀少、多类负样本分布不均以及弱先验的问题。ScarceGAN 通过修改半监督 GAN 的成本目标，包括引入“leeway”术语来容忍噪声先验，并利用负类知识在半监督方式下更好地学习正类。实验结果显示，在技能游戏数据集上，ScarceGAN 的召回率超过 85%（比传统半监督 GAN 提高约 60%），并在 KDDCUP99 数据集中为识别稀有攻击类 (0.09%) 建立了新基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03811v1",
      "published_date": "2025-05-02 12:17:37 UTC",
      "updated_date": "2025-05-02 12:17:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:01:59.804140"
    },
    {
      "arxiv_id": "2505.03810v1",
      "title": "Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free",
      "title_zh": "翻译失败",
      "authors": [
        "Euntae Choi",
        "Sumin Song",
        "Woosang Lim",
        "Sungjoo Yoo"
      ],
      "abstract": "Large Language Models (LLMs) face deployment challenges due to high\ncomputational costs, and while Post-Training Quantization (PTQ) offers a\nsolution, existing rotation-based methods struggle at very low bit-widths like\n2-bit. We introduce a novel, training-free approach to construct an improved\nrotation matrix, addressing the limitations of current methods. The key\ncontributions include leveraging the Walsh-Hadamard transform with sequency\nordering, which clusters similar frequency components to reduce quantization\nerror compared to standard Hadamard matrices, significantly improving\nperformance. Furthermore, we propose a Grouped Sequency-arranged Rotation (GSR)\nusing block-diagonal matrices with smaller Walsh blocks, effectively isolating\noutlier impacts and achieving performance comparable to optimization-based\nmethods without requiring any training. Our method demonstrates robust\nperformance on reasoning tasks and Perplexity (PPL) score on WikiText-2. Our\nmethod also enhances results even when applied over existing learned rotation\ntechniques.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)的部署挑战，提出了一种无需训练的优化方法Grouped Sequency-arranged Rotation (GSR)，以改善Post-Training Quantization (PTQ)在低位宽（如2-bit）下的性能。GSR利用Walsh-Hadamard transform结合sequency ordering，将相似的频率组件聚类，减少量化错误，并通过块对角矩阵和更小的Walsh块来隔离异常影响，实现与优化-based方法相当的效果。实验结果显示，该方法在推理任务和WikiText-2的Perplexity (PPL)分数上表现出色，甚至能提升现有learned rotation技术的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.03810v1",
      "published_date": "2025-05-02 11:51:29 UTC",
      "updated_date": "2025-05-02 11:51:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:02:10.764338"
    },
    {
      "arxiv_id": "2505.01198v1",
      "title": "Gender Bias in Explainability: Investigating Performance Disparity in Post-hoc Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Dhaini",
        "Ege Erdogan",
        "Nils Feldhus",
        "Gjergji Kasneci"
      ],
      "abstract": "While research on applications and evaluations of explanation methods\ncontinues to expand, fairness of the explanation methods concerning disparities\nin their performance across subgroups remains an often overlooked aspect. In\nthis paper, we address this gap by showing that, across three tasks and five\nlanguage models, widely used post-hoc feature attribution methods exhibit\nsignificant gender disparity with respect to their faithfulness, robustness,\nand complexity. These disparities persist even when the models are pre-trained\nor fine-tuned on particularly unbiased datasets, indicating that the\ndisparities we observe are not merely consequences of biased training data. Our\nresults highlight the importance of addressing disparities in explanations when\ndeveloping and applying explainability methods, as these can lead to biased\noutcomes against certain subgroups, with particularly critical implications in\nhigh-stakes contexts. Furthermore, our findings underscore the importance of\nincorporating the fairness of explanations, alongside overall model fairness\nand explainability, as a requirement in regulatory frameworks.",
      "tldr_zh": "本研究调查了后验特征归因方法（post-hoc feature attribution methods）在性别子群间的性能差异，发现这些方法在忠诚度（faithfulness）、鲁棒性（robustness）和复杂性（complexity）方面存在显著性别偏见。研究涉及三个任务和五个语言模型，即使使用无偏数据集进行预训练或微调，差异依然明显，表明问题并非源于训练数据。结果强调，在开发和应用解释方法时，必须关注解释的公平性，以避免对特定子群的偏见，尤其在高风险场景。最终，该研究呼吁将解释公平性纳入监管框架，与模型的整体公平性和可解释性一同考虑。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.01198v1",
      "published_date": "2025-05-02 11:41:25 UTC",
      "updated_date": "2025-05-02 11:41:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:02:22.983232"
    },
    {
      "arxiv_id": "2505.03809v1",
      "title": "When Dynamic Data Selection Meets Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Suorong Yang",
        "Peng Ye",
        "Furao Shen",
        "Dongzhan Zhou"
      ],
      "abstract": "Dynamic data selection aims to accelerate training with lossless performance.\nHowever, reducing training data inherently limits data diversity, potentially\nhindering generalization. While data augmentation is widely used to enhance\ndiversity, it is typically not optimized in conjunction with selection. As a\nresult, directly combining these techniques fails to fully exploit their\nsynergies. To tackle the challenge, we propose a novel online data training\nframework that, for the first time, unifies dynamic data selection and\naugmentation, achieving both training efficiency and enhanced performance. Our\nmethod estimates each sample's joint distribution of local density and\nmultimodal semantic consistency, allowing for the targeted selection of\naugmentation-suitable samples while suppressing the inclusion of noisy or\nambiguous data. This enables a more significant reduction in dataset size\nwithout sacrificing model generalization. Experimental results demonstrate that\nour method outperforms existing state-of-the-art approaches on various\nbenchmark datasets and architectures, e.g., reducing 50\\% training costs on\nImageNet-1k with lossless performance. Furthermore, our approach enhances noise\nresistance and improves model robustness, reinforcing its practical utility in\nreal-world scenarios.",
      "tldr_zh": "本文探讨了动态数据选择（dynamic data selection）和数据增强（data augmentation）的结合问题，提出一个新型在线训练框架，以解决动态选择减少数据多样性而影响泛化的挑战。该框架通过估计每个样本的局部密度和多模态语义一致性的联合分布，选择适合增强的样本并抑制噪声或模糊数据，从而实现数据集规模显著减少，同时提升模型泛化能力。实验结果表明，该方法在 ImageNet-1k 等基准数据集上优于现有技术，可减少50%训练成本而不损失性能，并增强模型的噪声抵抗力和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03809v1",
      "published_date": "2025-05-02 11:38:48 UTC",
      "updated_date": "2025-05-02 11:38:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:02:35.219001"
    },
    {
      "arxiv_id": "2505.01192v1",
      "title": "Exploring the Impact of Explainable AI and Cognitive Capabilities on Users' Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Federico Maria Cau",
        "Lucio Davide Spano"
      ],
      "abstract": "Artificial Intelligence (AI) systems are increasingly used for\ndecision-making across domains, raising debates over the information and\nexplanations they should provide. Most research on Explainable AI (XAI) has\nfocused on feature-based explanations, with less attention on alternative\nstyles. Personality traits like the Need for Cognition (NFC) can also lead to\ndifferent decision-making outcomes among low and high NFC individuals. We\ninvestigated how presenting AI information (prediction, confidence, and\naccuracy) and different explanation styles (example-based, feature-based,\nrule-based, and counterfactual) affect accuracy, reliance on AI, and cognitive\nload in a loan application scenario. We also examined low and high NFC\nindividuals' differences in prioritizing XAI interface elements (loan\nattributes, AI information, and explanations), accuracy, and cognitive load.\nOur findings show that high AI confidence significantly increases reliance on\nAI while reducing cognitive load. Feature-based explanations did not enhance\naccuracy compared to other conditions. Although counterfactual explanations\nwere less understandable, they enhanced overall accuracy, increasing reliance\non AI and reducing cognitive load when AI predictions were correct. Both low\nand high NFC individuals prioritized explanations after loan attributes,\nleaving AI information as the least important. However, we found no significant\ndifferences between low and high NFC groups in accuracy or cognitive load,\nraising questions about the role of personality traits in AI-assisted\ndecision-making. These findings highlight the need for user-centric\npersonalization in XAI interfaces, incorporating diverse explanation styles and\nexploring multiple personality traits and other user characteristics to\noptimize human-AI collaboration.",
      "tldr_zh": "本文研究了 Explainable AI (XAI) 和认知能力（如 Need for Cognition (NFC)）对用户决策的影响，焦点在于不同解释风格（example-based、feature-based、rule-based 和 counterfactual）以及 AI 信息（预测、置信度和准确率）在贷款申请场景中的作用。实验结果显示，高 AI 置信度显著增加了用户对 AI 的依赖并降低了认知负荷，而 counterfactual 解释虽不易理解，但提升了整体准确性；然而，feature-based 解释未显著改善准确性。低和高 NFC 群体在优先处理 XAI 接口元素（如贷款属性和解释）上相似，但未显示决策准确性或认知负荷上的显著差异。该研究强调了需要用户中心化的 XAI 接口设计，结合多种解释风格和个性特征，以优化人类-AI 协作。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.01192v1",
      "published_date": "2025-05-02 11:30:53 UTC",
      "updated_date": "2025-05-02 11:30:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:02:47.955275"
    },
    {
      "arxiv_id": "2505.01186v1",
      "title": "Secure Cluster-Based Hierarchical Federated Learning in Vehicular Networks",
      "title_zh": "车辆网络中的安全基于集群的分层联邦",
      "authors": [
        "M. Saeid HaghighiFard",
        "Sinem Coleri"
      ],
      "abstract": "Hierarchical Federated Learning (HFL) has recently emerged as a promising\nsolution for intelligent decision-making in vehicular networks, helping to\naddress challenges such as limited communication resources, high vehicle\nmobility, and data heterogeneity. However, HFL remains vulnerable to\nadversarial and unreliable vehicles, whose misleading updates can significantly\ncompromise the integrity and convergence of the global model. To address these\nchallenges, we propose a novel defense framework that integrates dynamic\nvehicle selection with robust anomaly detection within a cluster-based HFL\narchitecture, specifically designed to counter Gaussian noise and gradient\nascent attacks. The framework performs a comprehensive reliability assessment\nfor each vehicle by evaluating historical accuracy, contribution frequency, and\nanomaly records. Anomaly detection combines Z-score and cosine similarity\nanalyses on model updates to identify both statistical outliers and directional\ndeviations in model updates. To further refine detection, an adaptive\nthresholding mechanism is incorporated into the cosine similarity metric,\ndynamically adjusting the threshold based on the historical accuracy of each\nvehicle to enforce stricter standards for consistently high-performing\nvehicles. In addition, a weighted gradient averaging mechanism is implemented,\nwhich assigns higher weights to gradient updates from more trustworthy\nvehicles. To defend against coordinated attacks, a cross-cluster consistency\ncheck is applied to identify collaborative attacks in which multiple\ncompromised clusters coordinate misleading updates. Together, these mechanisms\nform a multi-level defense strategy to filter out malicious contributions\neffectively. Simulation results show that the proposed algorithm significantly\nreduces convergence time compared to benchmark methods across both 1-hop and\n3-hop topologies.",
      "tldr_zh": "该论文针对车辆网络中的 Hierarchical Federated Learning (HFL) 安全问题，提出了一种基于集群的防御框架，以应对恶意车辆带来的 Gaussian noise 和 gradient ascent attacks 等威胁。该框架整合动态车辆选择、异常检测（结合 Z-score 和 cosine similarity 分析）、可靠性评估（基于历史准确性、贡献频率和异常记录）、自适应阈值机制、加权梯度平均以及跨集群一致性检查等多级策略，有效过滤恶意更新并防范协调攻击。实验模拟结果显示，该算法在 1-hop 和 3-hop 拓扑下显著缩短了模型收敛时间，比基准方法表现出色。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01186v1",
      "published_date": "2025-05-02 11:01:00 UTC",
      "updated_date": "2025-05-02 11:01:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:03:00.787877"
    },
    {
      "arxiv_id": "2505.01185v1",
      "title": "EnviKal-Loc: Sub-10m Indoor LoRaWAN Localization using an Environmental-Aware Path Loss and Adaptive RSSI Smoothing",
      "title_zh": "翻译失败",
      "authors": [
        "Nahshon Mokua Obiri",
        "Kristof Van Laerhoven"
      ],
      "abstract": "LoRaWAN technology's extensive coverage positions it as a strong contender\nfor large-scale IoT deployments. However, achieving sub-10 m accuracy in indoor\nlocalization remains challenging due to complex environmental conditions,\nmultipath fading, and transient obstructions. This paper proposes a lightweight\nbut robust approach combining adaptive filtering with an extended log-distance,\nmulti-wall path loss and shadowing (PLS) model. Our methodology augments\nconventional models with critical LoRaWAN parameters (received signal strength\nindicator (RSSI), frequency, and signal-to-noise ratio (SNR)) and dynamic\nenvironmental indicators (temperature, humidity, carbon dioxide, particulate\nmatter, and barometric pressure). An adaptive Kalman filter reduces RSSI\nfluctuations, isolating persistent trends from momentary noise. Using a\nsix-month dataset of 1,328,334 field measurements, we evaluate three models:\nthe baseline COST 231 multi-wall model (MWM), the baseline model augmented with\nenvironmental parameters (MWM-EP), and a forward-only adaptive Kalman-filtered\nRSSI version of the latter (MWM-EP-KF). Results confirm that the MWM-EP-KF\nachieves a mean absolute error (MAE) of 5.81 m, outperforming both the MWM-EP\n(10.56 m) and the baseline MWM framework (17.98 m). Environmental augmentation\nreduces systematic errors by 41.22%, while Kalman filtering significantly\nenhances robustness under high RSSI volatility by 42.63%, on average across all\ndevices. These findings present an interpretable, efficient solution for\nprecise indoor LoRaWAN localization in dynamically changing environments.",
      "tldr_zh": "本研究提出EnviKal-Loc，一种轻量级方法，用于实现室内LoRaWAN定位的亚10米精度，解决复杂环境、多径衰落和暂时性障碍带来的挑战。该方法结合扩展的log-distance多墙路径损失和阴影(PLS)模型，融入LoRaWAN参数（如RSSI、频率和SNR）以及动态环境指标（如温度、湿度和颗粒物），并使用自适应Kalman过滤器减少RSSI波动。实验基于六个月的1,328,334场测量数据，评估了三个模型，结果显示MWM-EP-KF模型的平均绝对误差(MAE)为5.81 m，优于基线MWM（17.98 m）和MWM-EP（10.56 m）。环境参数增强减少了系统错误41.22%，而Kalman过滤器提高了鲁棒性42.63%，为动态环境下的精确室内LoRaWAN定位提供了高效、可解释的解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01185v1",
      "published_date": "2025-05-02 11:00:40 UTC",
      "updated_date": "2025-05-02 11:00:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:03:13.511121"
    },
    {
      "arxiv_id": "2505.01182v2",
      "title": "TSTMotion: Training-free Scene-aware Text-to-motion Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyan Guo",
        "Haoxuan Qu",
        "Hossein Rahmani",
        "Dewen Soh",
        "Ping Hu",
        "Qiuhong Ke",
        "Jun Liu"
      ],
      "abstract": "Text-to-motion generation has recently garnered significant research\ninterest, primarily focusing on generating human motion sequences in blank\nbackgrounds. However, human motions commonly occur within diverse 3D scenes,\nwhich has prompted exploration into scene-aware text-to-motion generation\nmethods. Yet, existing scene-aware methods often rely on large-scale\nground-truth motion sequences in diverse 3D scenes, which poses practical\nchallenges due to the expensive cost. To mitigate this challenge, we are the\nfirst to propose a \\textbf{T}raining-free \\textbf{S}cene-aware\n\\textbf{T}ext-to-\\textbf{Motion} framework, dubbed as \\textbf{TSTMotion}, that\nefficiently empowers pre-trained blank-background motion generators with the\nscene-aware capability. Specifically, conditioned on the given 3D scene and\ntext description, we adopt foundation models together to reason, predict and\nvalidate a scene-aware motion guidance. Then, the motion guidance is\nincorporated into the blank-background motion generators with two\nmodifications, resulting in scene-aware text-driven motion sequences. Extensive\nexperiments demonstrate the efficacy and generalizability of our proposed\nframework. We release our code in \\href{https://tstmotion.github.io/}{Project\nPage}.",
      "tldr_zh": "这篇论文提出TSTMotion，一种无需训练的场景感知文本到动作(Text-to-motion)生成框架，旨在解决现有方法依赖昂贵大规模真实动作数据的难题。该框架利用基础模型(foundation models)基于给定3D场景和文本描述进行推理、预测和验证，从而生成场景感知的动作指导。随后，通过对预训练的空白背景动作生成器进行两个修改，将动作指导整合进来，产生符合场景的动作序列。实验结果证明了TSTMotion的有效性和泛化性，为文本驱动的场景aware动作生成提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICME2025",
      "pdf_url": "http://arxiv.org/pdf/2505.01182v2",
      "published_date": "2025-05-02 10:50:04 UTC",
      "updated_date": "2025-05-05 05:14:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:03:22.672958"
    },
    {
      "arxiv_id": "2505.01181v1",
      "title": "Explainable AI Based Diagnosis of Poisoning Attacks in Evolutionary Swarms",
      "title_zh": "翻译失败",
      "authors": [
        "Mehrdad Asadi",
        "Roxana Rădulescu",
        "Ann Nowé"
      ],
      "abstract": "Swarming systems, such as for example multi-drone networks, excel at\ncooperative tasks like monitoring, surveillance, or disaster assistance in\ncritical environments, where autonomous agents make decentralized decisions in\norder to fulfill team-level objectives in a robust and efficient manner.\nUnfortunately, team-level coordinated strategies in the wild are vulnerable to\ndata poisoning attacks, resulting in either inaccurate coordination or\nadversarial behavior among the agents. To address this challenge, we contribute\na framework that investigates the effects of such data poisoning attacks, using\nexplainable AI methods. We model the interaction among agents using\nevolutionary intelligence, where an optimal coalition strategically emerges to\nperform coordinated tasks. Then, through a rigorous evaluation, the swarm model\nis systematically poisoned using data manipulation attacks. We showcase the\napplicability of explainable AI methods to quantify the effects of poisoning on\nthe team strategy and extract footprint characterizations that enable\ndiagnosing. Our findings indicate that when the model is poisoned above 10%,\nnon-optimal strategies resulting in inefficient cooperation can be identified.",
      "tldr_zh": "该研究针对进化群系统（如多无人机网络）中的数据中毒攻击提出一个框架，利用Explainable AI方法来诊断攻击的影响。这些攻击可能导致代理间协调失效或敌对行为，框架通过进化智能模型化代理互动，创建最佳联盟并系统地模拟数据操纵攻击。实验结果显示，当模型被毒害超过10%时，可识别出非最优策略，进而量化攻击对团队合作效率的负面影响，为增强群系统的鲁棒性提供诊断工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in short form in Genetic and Evolutionary Computation\n  Conference (GECCO '25 Companion), 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.01181v1",
      "published_date": "2025-05-02 10:48:40 UTC",
      "updated_date": "2025-05-02 10:48:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:03:34.796016"
    },
    {
      "arxiv_id": "2505.01177v1",
      "title": "LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures",
      "title_zh": "LLM 安全：漏洞、攻击、防御和对策",
      "authors": [
        "Francisco Aguilera-Martínez",
        "Fernando Berzal"
      ],
      "abstract": "As large language models (LLMs) continue to evolve, it is critical to assess\nthe security threats and vulnerabilities that may arise both during their\ntraining phase and after models have been deployed. This survey seeks to define\nand categorize the various attacks targeting LLMs, distinguishing between those\nthat occur during the training phase and those that affect already trained\nmodels. A thorough analysis of these attacks is presented, alongside an\nexploration of defense mechanisms designed to mitigate such threats. Defenses\nare classified into two primary categories: prevention-based and\ndetection-based defenses. Furthermore, our survey summarizes possible attacks\nand their corresponding defense strategies. It also provides an evaluation of\nthe effectiveness of the known defense mechanisms for the different security\nthreats. Our survey aims to offer a structured framework for securing LLMs,\nwhile also identifying areas that require further research to improve and\nstrengthen defenses against emerging security challenges.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型(LLMs)的安全问题，包括训练阶段和部署后的vulnerabilities、attacks及其分类。论文分析了各种攻击类型，并提出了预防-based和detection-based defenses作为应对策略，同时评估了这些防御机制的有效性。最终，它提供了一个结构化的框架来强化LLMs的安全，并指出了需要进一步研究的领域，以应对新兴威胁。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01177v1",
      "published_date": "2025-05-02 10:35:26 UTC",
      "updated_date": "2025-05-02 10:35:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:03:46.837270"
    },
    {
      "arxiv_id": "2505.01169v2",
      "title": "Distilling Two-Timed Flow Models by Separately Matching Initial and Terminal Velocities",
      "title_zh": "通过分别匹配初始和终端速度蒸",
      "authors": [
        "Pramook Khungurn",
        "Pratch Piyawongwisal",
        "Sira Sriswasdi",
        "Supasorn Suwajanakorn"
      ],
      "abstract": "A flow matching model learns a time-dependent vector field $v_t(x)$ that\ngenerates a probability path $\\{ p_t \\}_{0 \\leq t \\leq 1}$ that interpolates\nbetween a well-known noise distribution ($p_0$) and the data distribution\n($p_1$). It can be distilled into a two-timed flow model (TTFM) $\\phi_{s,x}(t)$\nthat can transform a sample belonging to the distribution at an initial time\n$s$ to another belonging to the distribution at a terminal time $t$ in one\nfunction evaluation. We present a new loss function for TTFM distillation\ncalled the \\emph{initial/terminal velocity matching} (ITVM) loss that extends\nthe Lagrangian Flow Map Distillation (LFMD) loss proposed by Boffi et al. by\nadding redundant terms to match the initial velocities at time $s$, removing\nthe derivative from the terminal velocity term at time $t$, and using a version\nof the model under training, stabilized by exponential moving averaging (EMA),\nto compute the target terminal average velocity. Preliminary experiments show\nthat our loss leads to better few-step generation performance on multiple types\nof datasets and model architectures over baselines.",
      "tldr_zh": "该论文提出了一种新的损失函数Initial/Terminal Velocity Matching (ITVM) loss，用于将flow matching model蒸馏成Two-Timed Flow Model (TTFM)，以高效地将样本从初始时间s的分布转换到终端时间t的分布。ITVM loss扩展了Lagrangian Flow Map Distillation (LFMD) loss，通过添加初始速度匹配、移除终端速度的导数项，并使用Exponential Moving Averaging (EMA)稳定化的模型计算目标终端平均速度，从而提高模型的准确性。初步实验结果显示，该方法在多种数据集和模型架构上提升了少步生成性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01169v2",
      "published_date": "2025-05-02 10:17:49 UTC",
      "updated_date": "2025-05-06 08:22:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:03:59.505463"
    },
    {
      "arxiv_id": "2505.01168v1",
      "title": "Harmonizing Intra-coherence and Inter-divergence in Ensemble Attacks for Adversarial Transferability",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoyang Ma",
        "Zhihao Wu",
        "Wang Lu",
        "Xin Gao",
        "Jinghang Yue",
        "Taolin Zhang",
        "Lipo Wang",
        "Youfang Lin",
        "Jing Wang"
      ],
      "abstract": "The development of model ensemble attacks has significantly improved the\ntransferability of adversarial examples, but this progress also poses severe\nthreats to the security of deep neural networks. Existing methods, however,\nface two critical challenges: insufficient capture of shared gradient\ndirections across models and a lack of adaptive weight allocation mechanisms.\nTo address these issues, we propose a novel method Harmonized Ensemble for\nAdversarial Transferability (HEAT), which introduces domain generalization into\nadversarial example generation for the first time. HEAT consists of two key\nmodules: Consensus Gradient Direction Synthesizer, which uses Singular Value\nDecomposition to synthesize shared gradient directions; and Dual-Harmony Weight\nOrchestrator which dynamically balances intra-domain coherence, stabilizing\ngradients within individual models, and inter-domain diversity, enhancing\ntransferability across models. Experimental results demonstrate that HEAT\nsignificantly outperforms existing methods across various datasets and\nsettings, offering a new perspective and direction for adversarial attack\nresearch.",
      "tldr_zh": "该研究针对模型集成攻击（Ensemble Attacks）中存在的不足，如未能充分捕获模型间的共享梯度方向和缺乏自适应权重分配机制，提出了一种新方法Harmonized Ensemble for Adversarial Transferability (HEAT)。HEAT首次将Domain Generalization引入对抗样本生成，包括两个关键模块：Consensus Gradient Direction Synthesizer，使用Singular Value Decomposition (SVD)合成共享梯度方向；以及Dual-Harmony Weight Orchestrator，动态平衡intra-domain coherence（域内一致性）和inter-domain diversity（域间多样性），以稳定模型内梯度和增强跨模型转移性。实验结果显示，HEAT在多种数据集和设置下显著优于现有方法，为对抗攻击研究提供了新视角和方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01168v1",
      "published_date": "2025-05-02 10:17:33 UTC",
      "updated_date": "2025-05-02 10:17:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:04:11.251605"
    },
    {
      "arxiv_id": "2505.01162v1",
      "title": "On the Limitations of Steering in Language Model Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Chebrolu Niranjan",
        "Kokil Jaidka",
        "Gerard Christopher Yeo"
      ],
      "abstract": "Steering vectors are a promising approach to aligning language model behavior\nat inference time. In this paper, we propose a framework to assess the\nlimitations of steering vectors as alignment mechanisms. Using a framework of\ntransformer hook interventions and antonym-based function vectors, we evaluate\nthe role of prompt structure and context complexity in steering effectiveness.\nOur findings indicate that steering vectors are promising for specific\nalignment tasks, such as value alignment, but may not provide a robust\nfoundation for general-purpose alignment in LLMs, particularly in complex\nscenarios. We establish a methodological foundation for future investigations\ninto steering capabilities of reasoning models.",
      "tldr_zh": "本论文探讨了steering vectors作为语言模型对齐机制的局限性，并提出一个评估框架来分析其有效性。该框架利用transformer hook interventions和antonym-based function vectors，评估了提示结构和上下文复杂度的影响。研究发现，steering vectors在特定任务如value alignment上表现出色，但无法为LLMs的一般目的对齐提供稳健支持，尤其在复杂场景中；同时，该工作为未来探究推理模型的steering能力奠定了方法基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01162v1",
      "published_date": "2025-05-02 10:08:34 UTC",
      "updated_date": "2025-05-02 10:08:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:04:23.024952"
    },
    {
      "arxiv_id": "2505.01130v1",
      "title": "Risk Analysis and Design Against Adversarial Actions",
      "title_zh": "翻译失败",
      "authors": [
        "Marco C. Campi",
        "Algo Carè",
        "Luis G. Crespo",
        "Simone Garatti",
        "Federico A. Ramponi"
      ],
      "abstract": "Learning models capable of providing reliable predictions in the face of\nadversarial actions has become a central focus of the machine learning\ncommunity in recent years. This challenge arises from observing that data\nencountered at deployment time often deviate from the conditions under which\nthe model was trained. In this paper, we address deployment-time adversarial\nactions and propose a versatile, well-principled framework to evaluate the\nmodel's robustness against attacks of diverse types and intensities. While we\ninitially focus on Support Vector Regression (SVR), the proposed approach\nextends naturally to the broad domain of learning via relaxed optimization\ntechniques. Our results enable an assessment of the model vulnerability without\nrequiring additional test data and operate in a distribution-free setup. These\nresults not only provide a tool to enhance trust in the model's applicability\nbut also aid in selecting among competing alternatives. Later in the paper, we\nshow that our findings also offer useful insights for establishing new results\nwithin the out-of-distribution framework.",
      "tldr_zh": "该论文探讨了机器学习模型在面对对抗性 actions 时如何提供可靠预测的问题，提出一个通用的框架来评估模型对不同类型和强度的攻击的鲁棒性。框架最初针对 Support Vector Regression (SVR)，并扩展到基于松弛优化技术的更广泛学习方法，无需额外测试数据且在 distribution-free 设置下运作。该方法不仅有助于评估模型漏洞、增强信任并选择最佳模型，还为 out-of-distribution 框架提供新的见解和结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01130v1",
      "published_date": "2025-05-02 09:16:44 UTC",
      "updated_date": "2025-05-02 09:16:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:04:35.086394"
    },
    {
      "arxiv_id": "2505.03807v1",
      "title": "Facilitating Video Story Interaction with Multi-Agent Collaborative System",
      "title_zh": "通过多智能体协作系统促进视频故事互动",
      "authors": [
        "Yiwen Zhang",
        "Jianing Hao",
        "Zhan Wang",
        "Hongling Sheng",
        "Wei Zeng"
      ],
      "abstract": "Video story interaction enables viewers to engage with and explore narrative\ncontent for personalized experiences. However, existing methods are limited to\nuser selection, specially designed narratives, and lack customization. To\naddress this, we propose an interactive system based on user intent. Our system\nuses a Vision Language Model (VLM) to enable machines to understand video\nstories, combining Retrieval-Augmented Generation (RAG) and a Multi-Agent\nSystem (MAS) to create evolving characters and scene experiences. It includes\nthree stages: 1) Video story processing, utilizing VLM and prior knowledge to\nsimulate human understanding of stories across three modalities. 2) Multi-space\nchat, creating growth-oriented characters through MAS interactions based on\nuser queries and story stages. 3) Scene customization, expanding and\nvisualizing various story scenes mentioned in dialogue. Applied to the Harry\nPotter series, our study shows the system effectively portrays emergent\ncharacter social behavior and growth, enhancing the interactive experience in\nthe video story world.",
      "tldr_zh": "该研究提出了一种基于用户意图的交互系统，用于提升视频故事互动的个性化体验，以解决现有方法在用户选择和自定义方面的局限性。该系统整合 Vision Language Model (VLM)、Retrieval-Augmented Generation (RAG) 和 Multi-Agent System (MAS)，分为三个阶段：视频故事处理（利用 VLM 和先验知识模拟跨模态故事理解）、多空间聊天（通过 MAS 基于用户查询创建成长导向角色），以及场景自定义（扩展并可视化对话中的故事场景）。应用于 Harry Potter 系列后，系统成功展现了角色社会行为和成长动态，显著增强了用户的互动体验。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "cs.HC",
      "comment": "Prepared and submitted in 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.03807v1",
      "published_date": "2025-05-02 09:08:13 UTC",
      "updated_date": "2025-05-02 09:08:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:04:47.383171"
    },
    {
      "arxiv_id": "2505.03806v1",
      "title": "Perception-Informed Neural Networks: Beyond Physics-Informed Neural Networks",
      "title_zh": "感知信息神经网络：超越物理信息神经网络",
      "authors": [
        "Mehran Mazandarani",
        "Marzieh Najariyan"
      ],
      "abstract": "This article introduces Perception-Informed Neural Networks (PrINNs), a\nframework designed to incorporate perception-based information into neural\nnetworks, addressing both systems with known and unknown physics laws or\ndifferential equations. Moreover, PrINNs extend the concept of Physics-Informed\nNeural Networks (PINNs) and their variants, offering a platform for the\nintegration of diverse forms of perception precisiation, including singular,\nprobability distribution, possibility distribution, interval, and fuzzy graph.\nIn fact, PrINNs allow neural networks to model dynamical systems by integrating\nexpert knowledge and perception-based information through loss functions,\nenabling the creation of modern data-driven models. Some of the key\ncontributions include Mixture of Experts Informed Neural Networks (MOEINNs),\nwhich combine heterogeneous expert knowledge into the network, and\nTransformed-Knowledge Informed Neural Networks (TKINNs), which facilitate the\nincorporation of meta-information for enhanced model performance. Additionally,\nFuzzy-Informed Neural Networks (FINNs) as a modern class of fuzzy deep neural\nnetworks leverage fuzzy logic constraints within a deep learning architecture,\nallowing online training without pre-training and eliminating the need for\ndefuzzification. PrINNs represent a significant step forward in bridging the\ngap between traditional physics-based modeling and modern data-driven\napproaches, enabling neural networks to learn from both structured physics laws\nand flexible perception-based rules. This approach empowers neural networks to\noperate in uncertain environments, model complex systems, and discover new\nforms of differential equations, making PrINNs a powerful tool for advancing\ncomputational science and engineering.",
      "tldr_zh": "本论文引入了 Perception-Informed Neural Networks (PrINNs)，一种扩展 Physics-Informed Neural Networks (PINNs) 的框架，用于将感知信息（如 singular、概率分布、可能性分布、区间和模糊图）整合到神经网络中，适用于已知或未知物理定律的系统。PrINNs 通过损失函数结合专家知识和感知数据，实现对动态系统的建模，并提出关键变体如 Mixture of Experts Informed Neural Networks (MOEINNs) 用于融合异质专家知识、Transformed-Knowledge Informed Neural Networks (TKINNs) 用于提升模型性能，以及 Fuzzy-Informed Neural Networks (FINNs) 作为模糊深度神经网络，支持在线训练并省去反模糊化过程。该框架桥接了传统物理建模与数据驱动方法，使神经网络能够在不确定环境中处理复杂系统、发现新微分方程，并推动计算科学和工程领域的进步。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03806v1",
      "published_date": "2025-05-02 09:08:07 UTC",
      "updated_date": "2025-05-02 09:08:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:05:00.620242"
    },
    {
      "arxiv_id": "2505.02851v1",
      "title": "30DayGen: Leveraging LLMs to Create a Content Corpus for Habit Formation",
      "title_zh": "30DayGen：利用 LLMs 创建用于习惯养成的内容语料库",
      "authors": [
        "Franklin Zhang",
        "Sonya Zhang",
        "Alon Halevy"
      ],
      "abstract": "In this paper, we present 30 Day Me, a habit formation application that\nleverages Large Language Models (LLMs) to help users break down their goals\ninto manageable, actionable steps and track their progress. Central to the app\nis the 30DAYGEN system, which generates 3,531 unique 30-day challenges sourced\nfrom over 15K webpages, and enables runtime search of challenge ideas aligned\nwith user-defined goals. We showcase how LLMs can be harnessed to rapidly\nconstruct domain specific content corpora for behavioral and educational\npurposes, and propose a practical pipeline that incorporates effective LLM\nenhanced approaches for content generation and semantic deduplication.",
      "tldr_zh": "本研究提出30DayGen系统，利用Large Language Models (LLMs)构建内容语料库，以支持习惯形成应用30 Day Me。系统从超过15K网页中生成3,531个独特的30天挑战，并提供运行时搜索功能，帮助用户将目标分解为可操作步骤并跟踪进度。研究展示了LLMs在快速创建行为和教育领域特定内容的潜力，并引入了一个实用管道，包括内容生成和语义去重技术，以提升效率和质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "I.2.7; H.3.1; H.3.3"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages (main content), 4 figures. Submitted to ACL BEA2025",
      "pdf_url": "http://arxiv.org/pdf/2505.02851v1",
      "published_date": "2025-05-02 08:53:27 UTC",
      "updated_date": "2025-05-02 08:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:05:11.302102"
    },
    {
      "arxiv_id": "2505.03804v1",
      "title": "MoEQuant: Enhancing Quantization for Mixture-of-Experts Large Language Models via Expert-Balanced Sampling and Affinity Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Xing Hu",
        "Zhixuan Chen",
        "Dawei Yang",
        "Zukang Xu",
        "Chen Xu",
        "Zhihang Yuan",
        "Sifan Zhou",
        "Jiangyong Yu"
      ],
      "abstract": "Mixture-of-Experts (MoE) large language models (LLMs), which leverage dynamic\nrouting and sparse activation to enhance efficiency and scalability, have\nachieved higher performance while reducing computational costs. However, these\nmodels face significant memory overheads, limiting their practical deployment\nand broader adoption. Post-training quantization (PTQ), a widely used method\nfor compressing LLMs, encounters severe accuracy degradation and diminished\ngeneralization performance when applied to MoE models. This paper investigates\nthe impact of MoE's sparse and dynamic characteristics on quantization and\nidentifies two primary challenges: (1) Inter-expert imbalance, referring to the\nuneven distribution of samples across experts, which leads to insufficient and\nbiased calibration for less frequently utilized experts; (2) Intra-expert\nimbalance, arising from MoE's unique aggregation mechanism, which leads to\nvarying degrees of correlation between different samples and their assigned\nexperts. To address these challenges, we propose MoEQuant, a novel quantization\nframework tailored for MoE LLMs. MoE-Quant includes two novel techniques: 1)\nExpert-Balanced Self-Sampling (EBSS) is an efficient sampling method that\nefficiently constructs a calibration set with balanced expert distributions by\nleveraging the cumulative probabilities of tokens and expert balance metrics as\nguiding factors. 2) Affinity-Guided Quantization (AGQ), which incorporates\naffinities between experts and samples into the quantization process, thereby\naccurately assessing the impact of individual samples on different experts\nwithin the MoE layer. Experiments demonstrate that MoEQuant achieves\nsubstantial performance gains (more than 10 points accuracy gain in the\nHumanEval for DeepSeekMoE-16B under 4-bit quantization) and boosts efficiency.",
      "tldr_zh": "本文提出 MoEQuant，一种针对 Mixture-of-Experts (MoE) 大语言模型的量化框架，旨在解决后训练量化 (PTQ) 过程中出现的专家间不平衡 (Inter-expert imbalance) 和专家内不平衡 (Intra-expert imbalance) 问题，从而减少准确性下降和提升泛化性能。MoEQuant 包括两个关键技术：Expert-Balanced Self-Sampling (EBSS)，通过 token 的累积概率和专家平衡指标构建高效的平衡校准集；以及 Affinity-Guided Quantization (AGQ)，将样本与专家的亲和力融入量化过程，以精确评估样本对专家的影响。实验结果显示，MoEQuant 在 4-bit 量化下显著提升了模型性能，例如 DeepSeekMoE-16B 在 HumanEval 中的准确率提高了超过 10 点，并提高了整体效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03804v1",
      "published_date": "2025-05-02 08:51:55 UTC",
      "updated_date": "2025-05-02 08:51:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:05:26.167394"
    },
    {
      "arxiv_id": "2505.03803v1",
      "title": "RWKVQuant: Quantizing the RWKV Family with Proxy Guided Hybrid of Scalar and Vector Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Xu",
        "Yuxuan Yue",
        "Zukang Xu",
        "Xing Hu",
        "Jiangyong Yu",
        "Zhixuan Chen",
        "Sifan Zhou",
        "Zhihang Yuan",
        "Dawei Yang"
      ],
      "abstract": "RWKV is a modern RNN architecture with comparable performance to Transformer,\nbut still faces challenges when deployed to resource-constrained devices. Post\nTraining Quantization (PTQ), which is a an essential technique to reduce model\nsize and inference latency, has been widely used in Transformer models.\nHowever, it suffers significant degradation of performance when applied to\nRWKV. This paper investigates and identifies two key constraints inherent in\nthe properties of RWKV: (1) Non-linear operators hinder the parameter-fusion of\nboth smooth- and rotation-based quantization, introducing extra computation\noverhead. (2) The larger amount of uniformly distributed weights poses\nchallenges for cluster-based quantization, leading to reduced accuracy. To this\nend, we propose RWKVQuant, a PTQ framework tailored for RWKV models, consisting\nof two novel techniques: (1) a coarse-to-fine proxy capable of adaptively\nselecting different quantization approaches by assessing the uniformity and\nidentifying outliers in the weights, and (2) a codebook optimization algorithm\nthat enhances the performance of cluster-based quantization methods for\nelement-wise multiplication in RWKV. Experiments show that RWKVQuant can\nquantize RWKV-6-14B into about 3-bit with less than 1% accuracy loss and 2.14x\nspeed up.",
      "tldr_zh": "该论文针对 RWKV 模型在资源受限设备上的部署挑战，提出 RWKVQuant 框架，以解决 Post Training Quantization (PTQ) 导致的性能下降问题，特别是非线性操作带来的额外计算开销和权重分布均匀性的量化难题。RWKVQuant 包括两个关键技术：coarse-to-fine proxy，用于根据权重均匀性和异常值自适应选择 scalar and vector quantization 方法；以及 codebook optimization 算法，提升基于聚类的量化在 RWKV 中的准确性。实验结果显示，该框架能将 RWKV-6-14B 模型量化到约 3-bit，仅损失不到 1% 的准确率，并实现 2.14x 的推理速度提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03803v1",
      "published_date": "2025-05-02 08:47:49 UTC",
      "updated_date": "2025-05-02 08:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:05:36.817134"
    },
    {
      "arxiv_id": "2505.03802v2",
      "title": "Efficient Fine-Tuning of Quantized Models via Adaptive Rank and Bitwidth",
      "title_zh": "通过自适应秩和位宽实现量化模型的高效微调",
      "authors": [
        "Changhai Zhou",
        "Yuhua Zhou",
        "Qian Qiao",
        "Weizhong Zhang",
        "Cheng Jin"
      ],
      "abstract": "QLoRA effectively combines low-bit quantization and LoRA to achieve\nmemory-friendly fine-tuning for large language models (LLM). Recently, methods\nbased on SVD for continuous update iterations to initialize LoRA matrices to\naccommodate quantization errors have generally failed to consistently improve\nperformance. Dynamic mixed precision is a natural idea for continuously\nimproving the fine-tuning performance of quantized models, but previous methods\noften optimize low-rank subspaces or quantization components separately,\nwithout considering their synergy. To address this, we propose\n\\textbf{QR-Adaptor}, a unified, gradient-free strategy that uses partial\ncalibration data to jointly search the quantization components and the rank of\nlow-rank spaces for each layer, thereby continuously improving model\nperformance. QR-Adaptor does not minimize quantization error but treats\nprecision and rank allocation as a discrete optimization problem guided by\nactual downstream performance and memory usage. Compared to state-of-the-art\n(SOTA) quantized LoRA fine-tuning methods, our approach achieves a 4.89\\%\naccuracy improvement on GSM8K, and in some cases even outperforms the 16-bit\nfine-tuned model while maintaining the memory footprint of the 4-bit setting.",
      "tldr_zh": "该论文提出了一种高效的量化模型微调方法，名为 QR-Adaptor，它通过联合搜索每个层的量化组件和低秩空间的秩，来优化大型语言模型（LLM）的微调性能，同时考虑精度和秩的协同作用。不同于传统的 SVD 基于方法，QR-Adaptor 采用无梯度策略，使用部分校准数据将精度和秩分配视为基于下游性能和内存使用的离散优化问题，从而避免最小化量化错误。实验结果显示，与 SOTA 量化 LoRA 微调方法相比，QR-Adaptor 在 GSM8K 数据集上实现了 4.89% 的准确率提升，并在某些情况下超过了 16-bit 微调模型，同时保持 4-bit 设置的内存占用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This preprint is being withdrawn because not all original authors are\n  continuing with the paper. Responsibility for the manuscript has been taken\n  over by a subset of the original authors, who will revise and resubmit it\n  independently. To avoid confusion regarding authorship and future versions of\n  the work, we request that this version be removed from arXiv",
      "pdf_url": "http://arxiv.org/pdf/2505.03802v2",
      "published_date": "2025-05-02 08:46:01 UTC",
      "updated_date": "2025-05-20 03:31:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:05:48.080031"
    },
    {
      "arxiv_id": "2505.01109v1",
      "title": "Self-Supervision Enhances Instance-based Multiple Instance Learning Methods in Digital Pathology: A Benchmark Study",
      "title_zh": "自监督学习提升数字病理学中基于实例的多实例学习方法：一项基准研究",
      "authors": [
        "Ali Mammadov",
        "Loic Le Folgoc",
        "Julien Adam",
        "Anne Buronfosse",
        "Gilles Hayem",
        "Guillaume Hocquet",
        "Pietro Gori"
      ],
      "abstract": "Multiple Instance Learning (MIL) has emerged as the best solution for Whole\nSlide Image (WSI) classification. It consists of dividing each slide into\npatches, which are treated as a bag of instances labeled with a global label.\nMIL includes two main approaches: instance-based and embedding-based. In the\nformer, each patch is classified independently, and then the patch scores are\naggregated to predict the bag label. In the latter, bag classification is\nperformed after aggregating patch embeddings. Even if instance-based methods\nare naturally more interpretable, embedding-based MILs have usually been\npreferred in the past due to their robustness to poor feature extractors.\nHowever, recently, the quality of feature embeddings has drastically increased\nusing self-supervised learning (SSL). Nevertheless, many authors continue to\nendorse the superiority of embedding-based MIL. To investigate this further, we\nconduct 710 experiments across 4 datasets, comparing 10 MIL strategies, 6\nself-supervised methods with 4 backbones, 4 foundation models, and various\npathology-adapted techniques. Furthermore, we introduce 4 instance-based MIL\nmethods never used before in the pathology domain. Through these extensive\nexperiments, we show that with a good SSL feature extractor, simple\ninstance-based MILs, with very few parameters, obtain similar or better\nperformance than complex, state-of-the-art (SOTA) embedding-based MIL methods,\nsetting new SOTA results on the BRACS and Camelyon16 datasets. Since simple\ninstance-based MIL methods are naturally more interpretable and explainable to\nclinicians, our results suggest that more effort should be put into\nwell-adapted SSL methods for WSI rather than into complex embedding-based MIL\nmethods.",
      "tldr_zh": "本研究通过基准实验探讨了自监督学习(SSL)如何提升实例-based Multiple Instance Learning(MIL)方法在数字病理学Whole Slide Image(WSI)分类中的表现，比较了实例-based 和 embedding-based MIL 方法。研究者进行了710个实验，涉及10种MIL策略、6种SSL方法、4种骨干网络、4种基础模型，并引入4种之前未在病理领域使用的实例-based MIL方法。结果显示，使用高质量SSL特征提取器的简单实例-based MIL方法能达到或超过复杂state-of-the-art(SOTA) embedding-based 方法的性能，并在BRACS和Camelyon16数据集上设置新SOTA记录；因此，建议优先开发适应WSI的SSL方法，以提升模型的可解释性和临床实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication in the Journal of Medical Imaging (SPIE)",
      "pdf_url": "http://arxiv.org/pdf/2505.01109v1",
      "published_date": "2025-05-02 08:43:50 UTC",
      "updated_date": "2025-05-02 08:43:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:06:00.116772"
    },
    {
      "arxiv_id": "2505.01094v1",
      "title": "Multi-Objective Reinforcement Learning for Water Management",
      "title_zh": "多目标强化学习用于水资源管理",
      "authors": [
        "Zuzanna Osika",
        "Roxana Radelescu",
        "Jazmin Zatarain Salazar",
        "Frans Oliehoek",
        "Pradeep K. Murukannaiah"
      ],
      "abstract": "Many real-world problems (e.g., resource management, autonomous driving, drug\ndiscovery) require optimizing multiple, conflicting objectives. Multi-objective\nreinforcement learning (MORL) extends classic reinforcement learning to handle\nmultiple objectives simultaneously, yielding a set of policies that capture\nvarious trade-offs. However, the MORL field lacks complex, realistic\nenvironments and benchmarks. We introduce a water resource (Nile river basin)\nmanagement case study and model it as a MORL environment. We then benchmark\nexisting MORL algorithms on this task. Our results show that specialized water\nmanagement methods outperform state-of-the-art MORL approaches, underscoring\nthe scalability challenges MORL algorithms face in real-world scenarios.",
      "tldr_zh": "该论文探讨了 Multi-Objective Reinforcement Learning (MORL) 在处理多个冲突目标的现实问题（如水资源管理）中的应用，扩展了传统强化学习以生成平衡权衡的一系列策略。研究者引入了尼罗河盆地水资源管理作为复杂 MORL 环境，并对现有算法进行了基准测试。结果表明，专门的水管理方法比最先进的 MORL 算法表现更好，暴露了 MORL 在真实场景中的可扩展性挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.01094v1",
      "published_date": "2025-05-02 08:14:01 UTC",
      "updated_date": "2025-05-02 08:14:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:06:12.230165"
    },
    {
      "arxiv_id": "2505.01091v1",
      "title": "Any-to-Any Vision-Language Model for Multimodal X-ray Imaging and Radiological Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Daniele Molino",
        "Francesco di Feola",
        "Linlin Shen",
        "Paolo Soda",
        "Valerio Guarrasi"
      ],
      "abstract": "Generative models have revolutionized Artificial Intelligence (AI),\nparticularly in multimodal applications. However, adapting these models to the\nmedical domain poses unique challenges due to the complexity of medical data\nand the stringent need for clinical accuracy. In this work, we introduce a\nframework specifically designed for multimodal medical data generation. By\nenabling the generation of multi-view chest X-rays and their associated\nclinical report, it bridges the gap between general-purpose vision-language\nmodels and the specialized requirements of healthcare. Leveraging the MIMIC-CXR\ndataset, the proposed framework shows superior performance in generating\nhigh-fidelity images and semantically coherent reports. Our quantitative\nevaluation reveals significant results in terms of FID and BLEU scores,\nshowcasing the quality of the generated data. Notably, our framework achieves\ncomparable or even superior performance compared to real data on downstream\ndisease classification tasks, underlining its potential as a tool for medical\nresearch and diagnostics. This study highlights the importance of\ndomain-specific adaptations in enhancing the relevance and utility of\ngenerative models for clinical applications, paving the way for future\nadvancements in synthetic multimodal medical data generation.",
      "tldr_zh": "本研究提出了一种Any-to-Any Vision-Language Model框架，专注于多模态医疗数据生成，能够同时生成多视图胸部X-ray图像及其相关临床报告，从而解决通用视觉语言模型在医疗领域的适应性挑战。框架利用MIMIC-CXR数据集进行训练，展示了在生成高保真图像和语义连贯报告方面的优越性能，量化评估显示FID和BLEU分数显著提升，并在下游疾病分类任务中达到或超过真实数据的表现。该工作强调了领域特定适配的重要性，为合成多模态医疗数据的生成提供新工具，推动医疗研究和诊断的创新。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2501.04614",
      "pdf_url": "http://arxiv.org/pdf/2505.01091v1",
      "published_date": "2025-05-02 08:07:24 UTC",
      "updated_date": "2025-05-02 08:07:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:06:23.108282"
    },
    {
      "arxiv_id": "2505.03801v1",
      "title": "Large Language Model Compression with Global Rank and Sparsity Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Changhai Zhou",
        "Qian Qiao",
        "Weizhong Zhang",
        "Cheng Jin"
      ],
      "abstract": "Low-rank and sparse composite approximation is a natural idea to compress\nLarge Language Models (LLMs). However, such an idea faces two primary\nchallenges that adversely affect the performance of existing methods. The first\nchallenge relates to the interaction and cooperation between low-rank and\nsparse matrices, while the second involves determining weight allocation across\ndifferent layers, as redundancy varies considerably among them. To address\nthese challenges, we propose a novel two-stage LLM compression method with the\ncapability of global rank and sparsity optimization. It is noteworthy that the\noverall optimization space is vast, making comprehensive optimization\ncomputationally prohibitive. Therefore, to reduce the optimization space, our\nfirst stage utilizes robust principal component analysis to decompose the\nweight matrices of LLMs into low-rank and sparse components, which span the low\ndimensional and sparse spaces containing the resultant low-rank and sparse\nmatrices, respectively. In the second stage, we propose a probabilistic global\noptimization technique to jointly identify the low-rank and sparse structures\nwithin the above two spaces. The appealing feature of our approach is its\nability to automatically detect the redundancy across different layers and to\nmanage the interaction between the sparse and low-rank components. Extensive\nexperimental results indicate that our method significantly surpasses\nstate-of-the-art techniques for sparsification and composite approximation.",
      "tldr_zh": "该研究提出了一种新型的大型语言模型（LLMs）压缩方法，通过全局秩和稀疏优化来解决低秩和稀疏矩阵之间的交互问题以及不同层权重分配的挑战。该方法采用两阶段策略：第一阶段使用鲁棒主成分分析（RPCA）将权重矩阵分解为低秩和稀疏组件，以缩小优化空间；第二阶段则通过概率全局优化技术联合识别这些组件中的结构，从而自动检测层间冗余并管理稀疏与低秩的交互。实验结果显示，该方法在稀疏化和复合逼近方面显著优于现有技术。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.03801v1",
      "published_date": "2025-05-02 08:00:48 UTC",
      "updated_date": "2025-05-02 08:00:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:06:35.721043"
    },
    {
      "arxiv_id": "2505.01085v1",
      "title": "Artificial Intelligence in Government: Why People Feel They Lose Control",
      "title_zh": "人工智能在政府：为什么人们感到失去控制",
      "authors": [
        "Alexander Wuttke",
        "Adrian Rauchfleisch",
        "Andreas Jungherr"
      ],
      "abstract": "The use of Artificial Intelligence (AI) in public administration is expanding\nrapidly, moving from automating routine tasks to deploying generative and\nagentic systems that autonomously act on goals. While AI promises greater\nefficiency and responsiveness, its integration into government functions raises\nconcerns about fairness, transparency, and accountability. This article applies\nprincipal-agent theory (PAT) to conceptualize AI adoption as a special case of\ndelegation, highlighting three core tensions: assessability (can decisions be\nunderstood?), dependency (can the delegation be reversed?), and contestability\n(can decisions be challenged?). These structural challenges may lead to a\n\"failure-by-success\" dynamic, where early functional gains obscure long-term\nrisks to democratic legitimacy. To test this framework, we conducted a\npre-registered factorial survey experiment across tax, welfare, and law\nenforcement domains. Our findings show that although efficiency gains initially\nbolster trust, they simultaneously reduce citizens' perceived control. When the\nstructural risks come to the foreground, institutional trust and perceived\ncontrol both drop sharply, suggesting that hidden costs of AI adoption\nsignificantly shape public attitudes. The study demonstrates that PAT offers a\npowerful lens for understanding the institutional and political implications of\nAI in government, emphasizing the need for policymakers to address delegation\nrisks transparently to maintain public trust.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在政府中的应用如何导致公众感到失去控制，运用委托理论（Principal-Agent Theory, PAT）来分析AI采用作为委托特例的三个核心紧张关系：可评估性（决定是否能被理解）、依赖性（委托是否能被撤销）和可争辩性（决定是否能被挑战）。研究通过在税务、福利和执法领域的预注册因子调查实验发现，虽然AI的效率提升最初增强了公众信任，但同时降低了感知控制，且当这些结构风险显现时，机构信任和控制感均急剧下降。论文强调，PAT 提供了一个理解AI在政府机构和政治影响的有力框架，呼吁政策制定者透明处理委托风险，以维护民主合法性和公众信任。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01085v1",
      "published_date": "2025-05-02 07:46:41 UTC",
      "updated_date": "2025-05-02 07:46:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:06:48.267871"
    },
    {
      "arxiv_id": "2505.01081v1",
      "title": "MADIL: An MDL-based Framework for Efficient Program Synthesis in the ARC Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Sébastien Ferré"
      ],
      "abstract": "Artificial Intelligence (AI) has achieved remarkable success in specialized\ntasks but struggles with efficient skill acquisition and generalization. The\nAbstraction and Reasoning Corpus (ARC) benchmark evaluates intelligence based\non minimal training requirements. While Large Language Models (LLMs) have\nrecently improved ARC performance, they rely on extensive pre-training and high\ncomputational costs. We introduce MADIL (MDL-based AI), a novel approach\nleveraging the Minimum Description Length (MDL) principle for efficient\ninductive learning. MADIL performs pattern-based decomposition, enabling\nstructured generalization. While its performance (7% at ArcPrize 2024) remains\nbelow LLM-based methods, it offers greater efficiency and interpretability.\nThis paper details MADIL's methodology, its application to ARC, and\nexperimental evaluations.",
      "tldr_zh": "人工智能（AI）在专业任务上取得显著成功，但高效技能获取和泛化能力仍面临挑战；为此，本文提出 MADIL 框架，该框架基于 Minimum Description Length (MDL) 原理，通过模式分解（pattern-based decomposition）实现结构化的归纳学习，以提升程序合成效率。MADIL 在 Abstraction and Reasoning Corpus (ARC) 基准测试中表现为 7% 的准确率（ArcPrize 2024），尽管低于 Large Language Models (LLMs) 方法，但其优势在于更高的计算效率和可解释性。该研究详细阐述了 MADIL 的方法论、ARC 应用以及实验评估结果，为高效智能系统开发提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "54 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.01081v1",
      "published_date": "2025-05-02 07:39:08 UTC",
      "updated_date": "2025-05-02 07:39:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:07:00.618552"
    },
    {
      "arxiv_id": "2505.01073v1",
      "title": "Retrieval Augmented Learning: A Retrial-based Large Language Model Self-Supervised Learning and Autonomous Knowledge Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zongyuan Li",
        "Pengfei Li",
        "Runnan Qi",
        "Yanan Ni",
        "Lumin Jiang",
        "Hui Wu",
        "Xuebo Zhang",
        "Kuihua Huang",
        "Xian Guo"
      ],
      "abstract": "The lack of domain-specific data in the pre-training of Large Language Models\n(LLMs) severely limits LLM-based decision systems in specialized applications,\nwhile post-training a model in the scenarios requires significant computational\nresources. In this paper, we present Retrial-Augmented Learning (RAL), a\nreward-free self-supervised learning framework for LLMs that operates without\nmodel training. By developing Retrieval-Augmented Generation (RAG) into a\nmodule for organizing intermediate data, we realized a three-stage autonomous\nknowledge generation of proposing a hypothesis, validating the hypothesis, and\ngenerating the knowledge. The method is evaluated in the LLM-PySC2 environment,\na representative decision-making platform that combines sufficient complexity\nwith domain-specific knowledge requirements. Experiments demonstrate that the\nproposed method effectively reduces hallucination by generating and utilizing\nvalidated knowledge, and increases decision-making performance at an extremely\nlow cost. Meanwhile, the approach exhibits potential in\nout-of-distribution(OOD) tasks, robustness, and transferability, making it a\ncost-friendly but effective solution for decision-making problems and\nautonomous knowledge generation.",
      "tldr_zh": "这篇论文提出了 Retrial-Augmented Learning (RAL)，一种基于 Large Language Models (LLMs) 的无奖励自监督学习框架，用于解决模型在特定领域数据不足的问题，而无需进行模型训练。RAL 通过将 Retrieval-Augmented Generation (RAG) 转化为中间数据组织模块，实现一个三阶段自主知识生成过程：提出假设、验证假设和生成知识。在 LLM-PySC2 环境中实验显示，该方法显著减少了幻觉，提高了决策性能，并展示了低成本、out-of-distribution (OOD) 任务潜力、鲁棒性和可转移性优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01073v1",
      "published_date": "2025-05-02 07:25:01 UTC",
      "updated_date": "2025-05-02 07:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:07:14.149109"
    },
    {
      "arxiv_id": "2505.01070v1",
      "title": "Improving Group Fairness in Knowledge Distillation via Laplace Approximation of Early Exits",
      "title_zh": "翻译失败",
      "authors": [
        "Edvin Fasth",
        "Sagar Singh"
      ],
      "abstract": "Knowledge distillation (KD) has become a powerful tool for training compact\nstudent models using larger, pretrained teacher models, often requiring less\ndata and computational resources. Teacher models typically possess more layers\nand thus exhibit richer feature representations compared to their student\ncounterparts. Furthermore, student models tend to learn simpler, surface-level\nfeatures in their early layers. This discrepancy can increase errors in groups\nwhere labels spuriously correlate with specific input attributes, leading to a\ndecline in group fairness even when overall accuracy remains comparable to the\nteacher. To mitigate these challenges, Early-Exit Neural Networks (EENNs),\nwhich enable predictions at multiple intermediate layers, have been employed.\nConfidence margins derived from these early exits have been utilized to\nreweight both cross-entropy and distillation losses on a per-instance basis. In\nthis paper, we propose that leveraging Laplace approximation-based methods to\nobtain well-calibrated uncertainty estimates can also effectively reweight\nchallenging instances and improve group fairness. We hypothesize that Laplace\napproximation offers a more robust identification of difficult or ambiguous\ninstances compared to margin-based approaches. To validate our claims, we\nbenchmark our approach using a Bert-based model on the MultiNLI dataset.",
      "tldr_zh": "本文提出一种改进知识蒸馏（KD）中组公平性（Group Fairness）的方法，通过在Early Exits处应用Laplace近似来获取更可靠的不确定性估计，从而重新加权交叉熵和蒸馏损失函数。相比传统的基于置信度边际（Confidence Margins）方法，该方法能更robust地识别困难或模糊实例，减少标签与输入属性间虚假相关导致的错误。实验在MultiNLI数据集上使用Bert-based模型进行benchmark，结果显示该方法有效提升了组公平性，同时保持了与教师模型相当的整体准确率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.01070v1",
      "published_date": "2025-05-02 07:18:52 UTC",
      "updated_date": "2025-05-02 07:18:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:07:23.879818"
    },
    {
      "arxiv_id": "2505.01068v1",
      "title": "Multimodal Transformers are Hierarchical Modal-wise Heterogeneous Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Yijie Jin",
        "Junjie Peng",
        "Xuanchao Lin",
        "Haochen Yuan",
        "Lan Wang",
        "Cangzhi Zheng"
      ],
      "abstract": "Multimodal Sentiment Analysis (MSA) is a rapidly developing field that\nintegrates multimodal information to recognize sentiments, and existing models\nhave made significant progress in this area. The central challenge in MSA is\nmultimodal fusion, which is predominantly addressed by Multimodal Transformers\n(MulTs). Although act as the paradigm, MulTs suffer from efficiency concerns.\nIn this work, from the perspective of efficiency optimization, we propose and\nprove that MulTs are hierarchical modal-wise heterogeneous graphs (HMHGs), and\nwe introduce the graph-structured representation pattern of MulTs. Based on\nthis pattern, we propose an Interlaced Mask (IM) mechanism to design the\nGraph-Structured and Interlaced-Masked Multimodal Transformer (GsiT). It is\nformally equivalent to MulTs which achieves an efficient weight-sharing\nmechanism without information disorder through IM, enabling All-Modal-In-One\nfusion with only 1/3 of the parameters of pure MulTs. A Triton kernel called\nDecomposition is implemented to ensure avoiding additional computational\noverhead. Moreover, it achieves significantly higher performance than\ntraditional MulTs. To further validate the effectiveness of GsiT itself and the\nHMHG concept, we integrate them into multiple state-of-the-art models and\ndemonstrate notable performance improvements and parameter reduction on widely\nused MSA datasets.",
      "tldr_zh": "这篇论文证明 Multimodal Transformers (MulTs) 可以视为 hierarchical modal-wise heterogeneous graphs (HMHGs)，从而从效率角度优化多模态情感分析 (MSA) 中的多模态融合问题。作者提出 Graph-Structured and Interlaced-Masked Multimodal Transformer (GsiT)，通过 Interlaced Mask (IM) 机制实现权重共享，仅需 MulTs 1/3 的参数，同时采用 Decomposition Triton kernel 避免额外计算开销。实验结果显示，GsiT 不仅在 MSA 数据集上显著提升了性能，还在多种状态-of-the-art 模型中实现了参数减少和性能改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01068v1",
      "published_date": "2025-05-02 07:18:00 UTC",
      "updated_date": "2025-05-02 07:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:07:36.167989"
    },
    {
      "arxiv_id": "2505.01067v1",
      "title": "A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories",
      "title_zh": "AI供应链中的一个生锈环节：检测模型",
      "authors": [
        "Ziqi Ding",
        "Qian Fu",
        "Junchen Ding",
        "Gelei Deng",
        "Yi Liu",
        "Yuekang Li"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have spurred the\ndevelopment of diverse AI applications from code generation and video editing\nto text generation; however, AI supply chains such as Hugging Face, which host\npretrained models and their associated configuration files contributed by the\npublic, face significant security challenges; in particular, configuration\nfiles originally intended to set up models by specifying parameters and initial\nsettings can be exploited to execute unauthorized code, yet research has\nlargely overlooked their security compared to that of the models themselves; in\nthis work, we present the first comprehensive study of malicious configurations\non Hugging Face, identifying three attack scenarios (file, website, and\nrepository operations) that expose inherent risks; to address these threats, we\nintroduce CONFIGSCAN, an LLM-based tool that analyzes configuration files in\nthe context of their associated runtime code and critical libraries,\neffectively detecting suspicious elements with low false positive rates and\nhigh accuracy; our extensive evaluation uncovers thousands of suspicious\nrepositories and configuration files, underscoring the urgent need for enhanced\nsecurity validation in AI model hosting platforms.",
      "tldr_zh": "本研究揭示了AI供应链（如Hugging Face）中模型仓库的配置文件的潜在安全风险，这些文件可被利用执行未授权代码，但相关研究长期被忽略。论文首次对Hugging Face上的恶意配置进行全面分析，识别了三种攻击场景（文件、网站和仓库操作），并引入CONFIGSCAN——一种基于LLMs的工具，通过分析配置文件及其关联的运行时代码和关键库，实现低假阳性率和高准确率的检测。实验结果发现数千个可疑仓库和配置文件，强调AI模型托管平台亟需加强安全验证措施。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01067v1",
      "published_date": "2025-05-02 07:16:20 UTC",
      "updated_date": "2025-05-02 07:16:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:07:50.768038"
    },
    {
      "arxiv_id": "2505.01065v1",
      "title": "Good News for Script Kiddies? Evaluating Large Language Models for Automated Exploit Generation",
      "title_zh": "翻译失败",
      "authors": [
        "David Jin",
        "Qian Fu",
        "Yuekang Li"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncode-related tasks, raising concerns about their potential for automated\nexploit generation (AEG). This paper presents the first systematic study on\nLLMs' effectiveness in AEG, evaluating both their cooperativeness and technical\nproficiency. To mitigate dataset bias, we introduce a benchmark with refactored\nversions of five software security labs. Additionally, we design an LLM-based\nattacker to systematically prompt LLMs for exploit generation. Our experiments\nreveal that GPT-4 and GPT-4o exhibit high cooperativeness, comparable to\nuncensored models, while Llama3 is the most resistant. However, no model\nsuccessfully generates exploits for refactored labs, though GPT-4o's minimal\nerrors highlight the potential for LLM-driven AEG advancements.",
      "tldr_zh": "这篇论文首次系统评估大型语言模型 (LLMs) 在自动漏洞利用生成 (AEG) 中的有效性，关注模型的合作性和技术熟练度。研究者引入了一个基准，使用重构版本的五个软件安全实验室来减少数据集偏差，并设计了基于 LLM 的攻击者系统提示模型生成漏洞。实验结果显示，GPT-4 和 GPT-4o 表现出高合作性，与未审查模型相当，而 Llama3 最抗拒；然而，没有模型成功生成重构实验室的漏洞。总体而言，这突显了 LLMs 在 AEG 领域的潜力，但也暴露了当前技术的局限性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01065v1",
      "published_date": "2025-05-02 07:15:22 UTC",
      "updated_date": "2025-05-02 07:15:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:08:01.440303"
    },
    {
      "arxiv_id": "2505.03800v1",
      "title": "Design description of Wisdom Computing Persperctive",
      "title_zh": "翻译失败",
      "authors": [
        "TianYi Yu"
      ],
      "abstract": "This course design aims to develop and research a handwriting matrix\nrecognition and step-by-step visual calculation process display system,\naddressing the issue of abstract formulas and complex calculation steps that\nstudents find difficult to understand when learning mathematics. By integrating\nartificial intelligence with visualization animation technology, the system\nenhances precise recognition of handwritten matrix content through the\nintroduction of Mamba backbone networks, completes digital extraction and\nmatrix reconstruction using the YOLO model, and simultaneously combines\nCoordAttention coordinate attention mechanisms to improve the accurate grasp of\ncharacter spatial positions. The calculation process is demonstrated frame by\nframe through the Manim animation engine, vividly showcasing each mathematical\ncalculation step, helping students intuitively understand the intrinsic logic\nof mathematical operations. Through dynamically generating animation processes\nfor different computational tasks, the system exhibits high modularity and\nflexibility, capable of generating various mathematical operation examples in\nreal-time according to student needs. By innovating human-computer interaction\nmethods, it brings mathematical calculation processes to life, helping students\nbridge the gap between knowledge and understanding on a deeper level,\nultimately achieving a learning experience where \"every step is understood.\"\nThe system's scalability and interactivity make it an intuitive, user-friendly,\nand efficient auxiliary tool in education.",
      "tldr_zh": "本研究设计了一个手写矩阵识别和逐步视觉计算过程显示系统，旨在解决学生在学习数学时对抽象公式和复杂计算步骤的理解难题。该系统整合人工智能与可视化动画技术，使用 Mamba backbone networks 进行手写矩阵的精确识别，结合 YOLO 模型实现数字提取和矩阵重建，并通过 CoordAttention 机制提升字符空间位置的准确把握。系统利用 Manim animation engine 逐帧展示计算过程，提供动态交互式动画，帮助学生直观理解数学运算逻辑，并根据需求实时生成示例，提升学习体验和教育效率。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03800v1",
      "published_date": "2025-05-02 07:12:10 UTC",
      "updated_date": "2025-05-02 07:12:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:08:12.438128"
    },
    {
      "arxiv_id": "2505.01059v1",
      "title": "Model Tensor Planning",
      "title_zh": "模型张量规划",
      "authors": [
        "An T. Le",
        "Khai Nguyen",
        "Minh Nhat Vu",
        "João Carvalho",
        "Jan Peters"
      ],
      "abstract": "Sampling-based model predictive control (MPC) offers strong performance in\nnonlinear and contact-rich robotic tasks, yet often suffers from poor\nexploration due to locally greedy sampling schemes. We propose \\emph{Model\nTensor Planning} (MTP), a novel sampling-based MPC framework that introduces\nhigh-entropy control trajectory generation through structured tensor sampling.\nBy sampling over randomized multipartite graphs and interpolating control\ntrajectories with B-splines and Akima splines, MTP ensures smooth and globally\ndiverse control candidates. We further propose a simple $\\beta$-mixing strategy\nthat blends local exploitative and global exploratory samples within the\nmodified Cross-Entropy Method (CEM) update, balancing control refinement and\nexploration. Theoretically, we show that MTP achieves asymptotic path coverage\nand maximum entropy in the control trajectory space in the limit of infinite\ntensor depth and width.\n  Our implementation is fully vectorized using JAX and compatible with MuJoCo\nXLA, supporting \\emph{Just-in-time} (JIT) compilation and batched rollouts for\nreal-time control with online domain randomization. Through experiments on\nvarious challenging robotic tasks, ranging from dexterous in-hand manipulation\nto humanoid locomotion, we demonstrate that MTP outperforms standard MPC and\nevolutionary strategy baselines in task success and control robustness. Design\nand sensitivity ablations confirm the effectiveness of MTP tensor sampling\nstructure, spline interpolation choices, and mixing strategy. Altogether, MTP\noffers a scalable framework for robust exploration in model-based planning and\ncontrol.",
      "tldr_zh": "该论文提出 Model Tensor Planning (MTP)，一种新型采样-based Model Predictive Control (MPC) 框架，通过结构化的张量采样和随机多部分图采样，生成高熵控制轨迹，并利用 B-splines 和 Akima splines 插值确保轨迹平滑多样性，同时引入 β-mixing 策略在修改后的 Cross-Entropy Method (CEM) 中平衡局部开发与全局探索。理论上，MTP 在无限张量深度和宽度下实现渐进路径覆盖和最大熵。实验结果显示，在各种挑战性机器人任务（如灵巧手部操作和人形运动）中，MTP 比标准 MPC 和进化策略基线显著提升任务成功率和控制鲁棒性，证明了其张量采样结构、样条插值及混合策略的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "22 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.01059v1",
      "published_date": "2025-05-02 07:09:38 UTC",
      "updated_date": "2025-05-02 07:09:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:08:26.560228"
    },
    {
      "arxiv_id": "2505.02850v1",
      "title": "Harnessing Structured Knowledge: A Concept Map-Based Approach for High-Quality Multiple Choice Question Generation with Effective Distractors",
      "title_zh": "利用",
      "authors": [
        "Nicy Scaria",
        "Silvester John Joseph Kennedy",
        "Diksha Seth",
        "Ananya Thakur",
        "Deepak Subramani"
      ],
      "abstract": "Generating high-quality MCQs, especially those targeting diverse cognitive\nlevels and incorporating common misconceptions into distractor design, is\ntime-consuming and expertise-intensive, making manual creation impractical at\nscale. Current automated approaches typically generate questions at lower\ncognitive levels and fail to incorporate domain-specific misconceptions. This\npaper presents a hierarchical concept map-based framework that provides\nstructured knowledge to guide LLMs in generating MCQs with distractors. We\nchose high-school physics as our test domain and began by developing a\nhierarchical concept map covering major Physics topics and their\ninterconnections with an efficient database design. Next, through an automated\npipeline, topic-relevant sections of these concept maps are retrieved to serve\nas a structured context for the LLM to generate questions and distractors that\nspecifically target common misconceptions. Lastly, an automated validation is\ncompleted to ensure that the generated MCQs meet the requirements provided. We\nevaluate our framework against two baseline approaches: a base LLM and a\nRAG-based generation. We conducted expert evaluations and student assessments\nof the generated MCQs. Expert evaluation shows that our method significantly\noutperforms the baseline approaches, achieving a success rate of 75.20% in\nmeeting all quality criteria compared to approximately 37% for both baseline\nmethods. Student assessment data reveal that our concept map-driven approach\nachieved a significantly lower guess success rate of 28.05% compared to 37.10%\nfor the baselines, indicating a more effective assessment of conceptual\nunderstanding. The results demonstrate that our concept map-based approach\nenables robust assessment across cognitive levels and instant identification of\nconceptual gaps, facilitating faster feedback loops and targeted interventions\nat scale.",
      "tldr_zh": "本文提出了一种基于层次概念图的框架，利用结构化知识指导LLMs生成高质量MCQs及其有效干扰项，针对高中物理领域的常见误区和不同认知水平。该方法通过构建概念图、检索相关部分并结合自动化验证管道，确保生成的题目更准确地评估概念理解。与基线方法（base LLM和RAG-based）相比，实验结果显示本文框架在专家评估中成功率达75.20%，学生评估中猜测成功率仅28.05%，显著提升了评估的稳健性和针对性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02850v1",
      "published_date": "2025-05-02 06:36:06 UTC",
      "updated_date": "2025-05-02 06:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:08:37.116006"
    },
    {
      "arxiv_id": "2505.01043v1",
      "title": "Low-Precision Training of Large Language Models: Methods, Challenges, and Opportunities",
      "title_zh": "大语言模型的低精度训练：方法、挑战与机会",
      "authors": [
        "Zhiwei Hao",
        "Jianyuan Guo",
        "Li Shen",
        "Yong Luo",
        "Han Hu",
        "Guoxia Wang",
        "Dianhai Yu",
        "Yonggang Wen",
        "Dacheng Tao"
      ],
      "abstract": "Large language models (LLMs) have achieved impressive performance across\nvarious domains. However, the substantial hardware resources required for their\ntraining present a significant barrier to efficiency and scalability. To\nmitigate this challenge, low-precision training techniques have been widely\nadopted, leading to notable advancements in training efficiency. Despite these\ngains, low-precision training involves several components$\\unicode{x2013}$such\nas weights, activations, and gradients$\\unicode{x2013}$each of which can be\nrepresented in different numerical formats. The resulting diversity has created\na fragmented landscape in low-precision training research, making it difficult\nfor researchers to gain a unified overview of the field. This survey provides a\ncomprehensive review of existing low-precision training methods. To\nsystematically organize these approaches, we categorize them into three primary\ngroups based on their underlying numerical formats, which is a key factor\ninfluencing hardware compatibility, computational efficiency, and ease of\nreference for readers. The categories are: (1) fixed-point and integer-based\nmethods, (2) floating-point-based methods, and (3) customized format-based\nmethods. Additionally, we discuss quantization-aware training approaches, which\nshare key similarities with low-precision training during forward propagation.\nFinally, we highlight several promising research directions to advance this\nfield. A collection of papers discussed in this survey is provided in\nhttps://github.com/Hao840/Awesome-Low-Precision-Training.",
      "tldr_zh": "这篇论文审视了低精度训练(Low-Precision Training)在大型语言模型(LLMs)中的应用，以解决训练过程中的硬件资源消耗问题，并提升效率。论文对现有方法进行了全面回顾，并按数值格式分类为三大类：(1) 固定点和整数-based方法，(2) 浮点-based方法，以及(3) 自定义格式-based方法，以帮助研究者更好地理解硬件兼容性和计算效率。论文还讨论了量化感知训练(Quantization-Aware Training)的相似性，并指出了未来研究方向，如进一步优化和整合这些技术，以推动LLMs的扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01043v1",
      "published_date": "2025-05-02 06:33:25 UTC",
      "updated_date": "2025-05-02 06:33:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:08:48.721559"
    },
    {
      "arxiv_id": "2505.01036v1",
      "title": "Stagnation in Evolutionary Algorithms: Convergence $\\neq$ Optimality",
      "title_zh": "进化算法中的停滞：收敛 ≠ 最优性",
      "authors": [
        "Xiaojun Zhou"
      ],
      "abstract": "In the evolutionary computation community, it is widely believed that\nstagnation impedes convergence in evolutionary algorithms, and that convergence\ninherently indicates optimality. However, this perspective is misleading. In\nthis study, it is the first to highlight that the stagnation of an individual\ncan actually facilitate the convergence of the entire population, and\nconvergence does not necessarily imply optimality, not even local optimality.\nConvergence alone is insufficient to ensure the effectiveness of evolutionary\nalgorithms. Several counterexamples are provided to illustrate this argument.",
      "tldr_zh": "本研究挑战了进化算法（Evolutionary Algorithms）领域的传统观点，即停滞会阻碍收敛，且收敛等同于最优。论文首次指出，个体的停滞实际上可以促进整个种群的收敛，但收敛并不必然表示最优，甚至不保证局部最优。作者通过提供几个反例来证明这一论点，强调仅凭收敛无法确保进化算法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01036v1",
      "published_date": "2025-05-02 06:19:09 UTC",
      "updated_date": "2025-05-02 06:19:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:09:00.794475"
    },
    {
      "arxiv_id": "2505.03799v1",
      "title": "Scalability Matters: Overcoming Challenges in InstructGLM with Similarity-Degree-Based Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Hyun Lee",
        "Chris Yi",
        "Maminur Islam",
        "B. D. S. Aritra"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in various\nnatural language processing tasks; however, their application to graph-related\nproblems remains limited, primarily due to scalability constraints and the\nabsence of dedicated mechanisms for processing graph structures. Existing\napproaches predominantly integrate LLMs with Graph Neural Networks (GNNs),\nusing GNNs as feature encoders or auxiliary components. However, directly\nencoding graph structures within LLMs has been underexplored, particularly in\nthe context of large-scale graphs where token limitations hinder effective\nrepresentation. To address these challenges, we propose SDM-InstructGLM, a\nnovel instruction-tuned Graph Language Model (InstructGLM) framework that\nenhances scalability and efficiency without relying on GNNs. Our method\nintroduces a similarity-degree-based biased random walk mechanism, which\nselectively samples and encodes graph information based on node-feature\nsimilarity and degree centrality, ensuring an adaptive and structured\nrepresentation within the LLM. This approach significantly improves token\nefficiency, mitigates information loss due to random sampling, and enhances\nperformance on graph-based tasks such as node classification and link\nprediction. Furthermore, our results demonstrate the feasibility of LLM-only\ngraph processing, enabling scalable and interpretable Graph Language Models\n(GLMs) optimized through instruction-based fine-tuning. This work paves the way\nfor GNN-free approaches to graph learning, leveraging LLMs as standalone graph\nreasoning models. Our source code is available on GitHub.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在图相关任务中的可扩展性挑战，提出了一种新型框架SDM-InstructGLM，通过指令调整优化图语言模型（InstructGLM），无需依赖图神经网络（GNNs）。该框架引入基于节点特征相似度和度中心性的偏置随机游走机制，选择性地采样和编码图信息，从而提升token效率、减少信息损失，并在节点分类和链接预测等任务上显著提高性能。结果证明了LLM-only图处理的 feasibility，为可扩展的、解释性强的GNN-free图学习方法铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published in International Joint Conference on Neural Networks\n  (IJCNN), 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03799v1",
      "published_date": "2025-05-02 06:08:21 UTC",
      "updated_date": "2025-05-02 06:08:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:09:13.903940"
    },
    {
      "arxiv_id": "2505.01468v1",
      "title": "One Search Fits All: Pareto-Optimal Eco-Friendly Model Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Filippo Betello",
        "Antonio Purificato",
        "Vittoria Vineis",
        "Gabriele Tolomei",
        "Fabrizio Silvestri"
      ],
      "abstract": "The environmental impact of Artificial Intelligence (AI) is emerging as a\nsignificant global concern, particularly regarding model training. In this\npaper, we introduce GREEN (Guided Recommendations of Energy-Efficient\nNetworks), a novel, inference-time approach for recommending Pareto-optimal AI\nmodel configurations that optimize validation performance and energy\nconsumption across diverse AI domains and tasks. Our approach directly\naddresses the limitations of current eco-efficient neural architecture search\nmethods, which are often restricted to specific architectures or tasks. Central\nto this work is EcoTaskSet, a dataset comprising training dynamics from over\n1767 experiments across computer vision, natural language processing, and\nrecommendation systems using both widely used and cutting-edge architectures.\nLeveraging this dataset and a prediction model, our approach demonstrates\neffectiveness in selecting the best model configuration based on user\npreferences. Experimental results show that our method successfully identifies\nenergy-efficient configurations while ensuring competitive performance.",
      "tldr_zh": "本论文针对AI模型训练的环境影响，引入了GREEN方法，这是一种推理时的推荐框架，用于选择Pareto-Optimal的模型配置，以优化验证性能和能源消耗。\nGREEN直接解决了当前神经架构搜索方法的局限性，通过利用EcoTaskSet数据集（包含1767个实验的训练动态，覆盖计算机视觉、自然语言处理和推荐系统），结合预测模型根据用户偏好进行推荐。\n实验结果显示，该方法成功识别了能源高效的配置，同时确保了与基线模型相媲美的性能表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 11 tables, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.01468v1",
      "published_date": "2025-05-02 05:59:21 UTC",
      "updated_date": "2025-05-02 05:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:09:25.026945"
    },
    {
      "arxiv_id": "2505.01028v1",
      "title": "Adaptive Wizard for Removing Cross-Tier Misconfigurations in Active Directory",
      "title_zh": "翻译失败",
      "authors": [
        "Huy Q. Ngo",
        "Mingyu Guo",
        "Hung Nguyen"
      ],
      "abstract": "Security vulnerabilities in Windows Active Directory (AD) systems are\ntypically modeled using an attack graph and hardening AD systems involves an\niterative workflow: security teams propose an edge to remove, and IT operations\nteams manually review these fixes before implementing the removal. As\nverification requires significant manual effort, we formulate an Adaptive Path\nRemoval Problem to minimize the number of steps in this iterative removal\nprocess. In our model, a wizard proposes an attack path in each step and\npresents it as a set of multiple-choice options to the IT admin. The IT admin\nthen selects one edge from the proposed set to remove. This process continues\nuntil the target $t$ is disconnected from source $s$ or the number of proposed\npaths reaches $B$. The model aims to optimize the human effort by minimizing\nthe expected number of interactions between the IT admin and the security\nwizard. We first prove that the problem is $\\mathcal{\\#P}$-hard. We then\npropose a set of solutions including an exact algorithm, an approximate\nalgorithm, and several scalable heuristics. Our best heuristic, called DPR, can\noperate effectively on larger-scale graphs compared to the exact algorithm and\nconsistently outperforms the approximate algorithm across all graphs. We verify\nthe effectiveness of our algorithms on several synthetic AD graphs and an AD\nattack graph collected from a real organization.",
      "tldr_zh": "这篇论文针对 Windows Active Directory (AD) 中的安全漏洞，提出 Adaptive Wizard 模型，以最小化移除攻击路径的迭代过程，从而减少 IT 管理员的手动努力。论文定义了 Adaptive Path Removal Problem，证明其为 #P-hard，并开发了精确算法、近似算法和可扩展启发式算法，其中最佳启发式算法 DPR 在较大规模图上表现突出。实验结果显示，DPR 算法在合成 AD 图和真实组织攻击图上 consistently 优于其他方法，提升了安全加固的效率。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "To be appear in IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.01028v1",
      "published_date": "2025-05-02 05:55:56 UTC",
      "updated_date": "2025-05-02 05:55:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:09:37.894721"
    },
    {
      "arxiv_id": "2505.01016v1",
      "title": "Fine-Tuning Without Forgetting: Adaptation of YOLOv8 Preserves COCO Performance",
      "title_zh": "无需遗忘",
      "authors": [
        "Vishal Gandhi",
        "Sagar Gandhi"
      ],
      "abstract": "The success of large pre-trained object detectors hinges on their\nadaptability to diverse downstream tasks. While fine-tuning is the standard\nadaptation method, specializing these models for challenging fine-grained\ndomains necessitates careful consideration of feature granularity. The critical\nquestion remains: how deeply should the pre-trained backbone be fine-tuned to\noptimize for the specialized task without incurring catastrophic forgetting of\nthe original general capabilities? Addressing this, we present a systematic\nempirical study evaluating the impact of fine-tuning depth. We adapt a standard\nYOLOv8n model to a custom, fine-grained fruit detection dataset by\nprogressively unfreezing backbone layers (freeze points at layers 22, 15, and\n10) and training. Performance was rigorously evaluated on both the target fruit\ndataset and, using a dual-head evaluation architecture, on the original COCO\nvalidation set. Our results demonstrate unequivocally that deeper fine-tuning\n(unfreezing down to layer 10) yields substantial performance gains (e.g., +10\\%\nabsolute mAP50) on the fine-grained fruit task compared to only training the\nhead. Strikingly, this significant adaptation and specialization resulted in\nnegligible performance degradation (<0.1\\% absolute mAP difference) on the COCO\nbenchmark across all tested freeze levels. We conclude that adapting\nmid-to-late backbone features is highly effective for fine-grained\nspecialization. Critically, our results demonstrate this adaptation can be\nachieved without the commonly expected penalty of catastrophic forgetting,\npresenting a compelling case for exploring deeper fine-tuning strategies,\nparticularly when targeting complex domains or when maximizing specialized\nperformance is paramount.",
      "tldr_zh": "这篇论文探讨了微调YOLOv8模型以适应细粒度任务（如水果检测）的方法，同时避免灾难性遗忘。研究通过系统实验逐步解冻骨干网络层（从layer 22到layer 10），评估其对目标任务和原COCO数据集的影响。结果显示，更深层微调（如解冻到layer 10）显著提升了细粒度任务的性能（mAP50提高10%），而COCO基准上的性能几乎无损（<0.1% mAP差异）。总之，该研究证明了适应中到后期的骨干特征是高效策略，可为复杂领域的模型优化提供指导。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01016v1",
      "published_date": "2025-05-02 05:27:14 UTC",
      "updated_date": "2025-05-02 05:27:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:09:50.405162"
    },
    {
      "arxiv_id": "2505.01015v1",
      "title": "Value Portrait: Understanding Values of LLMs with Human-aligned Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Jongwook Han",
        "Dongmin Choi",
        "Woojung Song",
        "Eun-Ju Lee",
        "Yohan Jo"
      ],
      "abstract": "The importance of benchmarks for assessing the values of language models has\nbeen pronounced due to the growing need of more authentic, human-aligned\nresponses. However, existing benchmarks rely on human or machine annotations\nthat are vulnerable to value-related biases. Furthermore, the tested scenarios\noften diverge from real-world contexts in which models are commonly used to\ngenerate text and express values. To address these issues, we propose the Value\nPortrait benchmark, a reliable framework for evaluating LLMs' value\norientations with two key characteristics. First, the benchmark consists of\nitems that capture real-life user-LLM interactions, enhancing the relevance of\nassessment results to real-world LLM usage and thus ecological validity.\nSecond, each item is rated by human subjects based on its similarity to their\nown thoughts, and correlations between these ratings and the subjects' actual\nvalue scores are derived. This psychometrically validated approach ensures that\nitems strongly correlated with specific values serve as reliable items for\nassessing those values. Through evaluating 27 LLMs with our benchmark, we find\nthat these models prioritize Benevolence, Security, and Self-Direction values\nwhile placing less emphasis on Tradition, Power, and Achievement values. Also,\nour analysis reveals biases in how LLMs perceive various demographic groups,\ndeviating from real human data.",
      "tldr_zh": "该研究提出 Value Portrait 基准，用于评估大型语言模型（LLMs）的价值取向，以解决现有基准易受偏见影响且脱离现实场景的问题。Value Portrait 通过收集真实用户-LLM 互动项目，并采用人类评分及其与实际价值分数的相关性分析，确保评估的心理测量有效性和可靠性。实验评估了 27 个 LLMs，发现这些模型更注重 Benevolence（仁慈）、Security（安全）和 Self-Direction（自我指导）价值，而较少强调 Tradition（传统）、Power（权力）和 Achievement（成就）价值；此外，LLMs 在感知不同人口统计群体时存在偏见，与人类数据不一致。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "32 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.01015v1",
      "published_date": "2025-05-02 05:26:50 UTC",
      "updated_date": "2025-05-02 05:26:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:10:00.842939"
    },
    {
      "arxiv_id": "2505.01009v1",
      "title": "Improving Large Language Model Planning with Action Sequence Similarity",
      "title_zh": "通过动作序列相似性改进大语言模型的规划能力",
      "authors": [
        "Xinran Zhao",
        "Hanie Sedghi",
        "Bernd Bohnet",
        "Dale Schuurmans",
        "Azade Nova"
      ],
      "abstract": "Planning is essential for artificial intelligence systems to look ahead and\nproactively determine a course of actions to reach objectives in the virtual\nand real world. Recent work on large language models (LLMs) sheds light on\ntheir planning capability in various tasks. However, it remains unclear what\nsignals in the context influence the model performance. In this work, we\nexplore how to improve the model planning capability through in-context\nlearning (ICL), specifically, what signals can help select the exemplars.\nThrough extensive experiments, we observe that commonly used problem similarity\nmay result in false positives with drastically different plans, which can\nmislead the model. In response, we propose to sample and filter exemplars\nleveraging plan side action sequence similarity (AS). We propose GRASE-DC: a\ntwo-stage pipeline that first re-samples high AS exemplars and then curates the\nselected exemplars with dynamic clustering on AS to achieve a balance of\nrelevance and diversity. Our experimental result confirms that GRASE-DC\nachieves significant performance improvement on various planning tasks (up to\n~11-40 point absolute accuracy improvement with 27.3% fewer exemplars needed on\naverage). With GRASE-DC* + VAL, where we iteratively apply GRASE-DC with a\nvalidator, we are able to even boost the performance by 18.9% more.\n  Extensive analysis validates the consistent performance improvement of\nGRASE-DC with various backbone LLMs and on both classical planning and natural\nlanguage planning benchmarks. GRASE-DC can further boost the planning accuracy\nby ~24 absolute points on harder problems using simpler problems as exemplars\nover a random baseline. This demonstrates its ability to generalize to\nout-of-distribution problems.",
      "tldr_zh": "这篇论文探讨了如何通过行动序列相似性 (Action Sequence Similarity, AS) 改进大型语言模型 (LLMs) 的规划能力，针对传统相似性方法可能导致模型误导的问题。作者提出 GRASE-DC 框架，一个两阶段管道：首先重新采样基于 AS 的高相似示例，然后通过动态聚类平衡相关性和多样性。实验结果显示，GRASE-DC 在各种规划任务上显著提升了准确率（最高提高 11-40 点），平均减少 27.3% 示例，且结合验证器后进一步提升 18.9%，证明其在不同 LLM 和基准上的泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.01009v1",
      "published_date": "2025-05-02 05:16:17 UTC",
      "updated_date": "2025-05-02 05:16:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:10:14.887102"
    },
    {
      "arxiv_id": "2505.01007v1",
      "title": "Towards the Resistance of Neural Network Watermarking to Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Ling Tang",
        "Yuefeng Chen",
        "Hui Xue",
        "Quanshi Zhang"
      ],
      "abstract": "This paper proves a new watermarking method to embed the ownership\ninformation into a deep neural network (DNN), which is robust to fine-tuning.\nSpecifically, we prove that when the input feature of a convolutional layer\nonly contains low-frequency components, specific frequency components of the\nconvolutional filter will not be changed by gradient descent during the\nfine-tuning process, where we propose a revised Fourier transform to extract\nfrequency components from the convolutional filter. Additionally, we also prove\nthat these frequency components are equivariant to weight scaling and weight\npermutations. In this way, we design a watermark module to encode the watermark\ninformation to specific frequency components in a convolutional filter.\nPreliminary experiments demonstrate the effectiveness of our method.",
      "tldr_zh": "这篇论文提出了一种新的神经网络水印方法，旨在嵌入深度神经网络 (DNN) 的所有权信息，并使其对 fine-tuning 过程具有鲁棒性。方法基于当卷积层输入特征仅包含低频组件时，特定频率组件不会被 gradient descent 改变，并引入修正的 Fourier transform 来提取这些组件。论文证明这些频率组件对 weight scaling 和 weight permutations 等变，从而设计了一个水印模块将信息编码到卷积过滤器的特定频段中。初步实验验证了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01007v1",
      "published_date": "2025-05-02 05:11:17 UTC",
      "updated_date": "2025-05-02 05:11:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:10:25.377742"
    },
    {
      "arxiv_id": "2505.06256v1",
      "title": "SpectrumFM: A Foundation Model for Intelligent Spectrum Management",
      "title_zh": "SpectrumFM：智能频谱管理的基础模型",
      "authors": [
        "Fuhui Zhou",
        "Chunyu Liu",
        "Hao Zhang",
        "Wei Wu",
        "Qihui Wu",
        "Derrick Wing Kwan Ng",
        "Tony Q. S. Quek",
        "Chan-Byoung Chae"
      ],
      "abstract": "Intelligent spectrum management is crucial for improving spectrum efficiency\nand achieving secure utilization of spectrum resources. However, existing\nintelligent spectrum management methods, typically based on small-scale models,\nsuffer from notable limitations in recognition accuracy, convergence speed, and\ngeneralization, particularly in the complex and dynamic spectrum environments.\nTo address these challenges, this paper proposes a novel spectrum foundation\nmodel, termed SpectrumFM, establishing a new paradigm for spectrum management.\nSpectrumFM features an innovative encoder architecture that synergistically\nexploits the convolutional neural networks and the multi-head self-attention\nmechanisms to enhance feature extraction and enable robust representation\nlearning. The model is pre-trained via two novel self-supervised learning\ntasks, namely masked reconstruction and next-slot signal prediction, which\nleverage large-scale in-phase and quadrature (IQ) data to achieve comprehensive\nand transferable spectrum representations. Furthermore, a parameter-efficient\nfine-tuning strategy is proposed to enable SpectrumFM to adapt to various\ndownstream spectrum management tasks, including automatic modulation\nclassification (AMC), wireless technology classification (WTC), spectrum\nsensing (SS), and anomaly detection (AD). Extensive experiments demonstrate\nthat SpectrumFM achieves superior performance in terms of accuracy, robustness,\nadaptability, few-shot learning efficiency, and convergence speed, consistently\noutperforming conventional methods across multiple benchmarks. Specifically,\nSpectrumFM improves AMC accuracy by up to 12.1% and WTC accuracy by 9.3%,\nachieves an area under the curve (AUC) of 0.97 in SS at -4 dB signal-to-noise\nratio (SNR), and enhances AD performance by over 10%.",
      "tldr_zh": "该研究针对现有智能频谱管理方法的识别准确率、收敛速度和泛化能力不足问题，提出了一种新型频谱基础模型SpectrumFM，以提升频谱资源的效率和安全利用。SpectrumFM采用创新的编码器架构，结合卷积神经网络(CNN)和多头自注意力机制(Multi-Head Self-Attention)，并通过两个自监督学习任务——masked reconstruction和next-slot signal prediction——利用大规模IQ数据进行预训练，实现全面的频谱表示学习。模型还引入参数高效的微调策略，使其适应多种下游任务，包括自动调制分类(AMC)、无线技术分类(WTC)、频谱感知(SS)和异常检测(AD)。实验结果显示，SpectrumFM在多个基准上表现出色，AMC准确率提高12.1%、WTC准确率提高9.3%、SS在-4 dB SNR下的AUC达0.97，并使AD性能提升超过10%。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06256v1",
      "published_date": "2025-05-02 04:06:39 UTC",
      "updated_date": "2025-05-02 04:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:10:38.227725"
    },
    {
      "arxiv_id": "2505.00983v1",
      "title": "Toward Data-centric Directed Graph Learning: An Entropy-driven Approach",
      "title_zh": "面向数据中心的有向图学习：一种熵驱动的方法",
      "authors": [
        "Xunkai Li",
        "Zhengyu Wu",
        "Kaichi Yu",
        "Hongchao Qin",
        "Guang Zeng",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "The directed graph (digraph), as a generalization of undirected graphs,\nexhibits superior representation capability in modeling complex topology\nsystems and has garnered considerable attention in recent years. Despite the\nnotable efforts made by existing DiGraph Neural Networks (DiGNNs) to leverage\ndirected edges, they still fail to comprehensively delve into the abundant data\nknowledge concealed in the digraphs. This data-level limitation results in\nmodel-level sub-optimal predictive performance and underscores the necessity of\nfurther exploring the potential correlations between the directed edges\n(topology) and node profiles (feature and labels) from a data-centric\nperspective, thereby empowering model-centric neural networks with stronger\nencoding capabilities.\n  In this paper, we propose \\textbf{E}ntropy-driven \\textbf{D}igraph\nknowl\\textbf{E}dge distillatio\\textbf{N} (EDEN), which can serve as a\ndata-centric digraph learning paradigm or a model-agnostic hot-and-plug\ndata-centric Knowledge Distillation (KD) module. The core idea is to achieve\ndata-centric ML, guided by our proposed hierarchical encoding theory for\nstructured data. Specifically, EDEN first utilizes directed structural\nmeasurements from a topology perspective to construct a coarse-grained\nHierarchical Knowledge Tree (HKT). Subsequently, EDEN quantifies the mutual\ninformation of node profiles to refine knowledge flow in the HKT, enabling\ndata-centric KD supervision within model training. As a general framework, EDEN\ncan also naturally extend to undirected scenarios and demonstrate satisfactory\nperformance. In our experiments, EDEN has been widely evaluated on 14 (di)graph\ndatasets (homophily and heterophily) and across 4 downstream tasks. The results\ndemonstrate that EDEN attains SOTA performance and exhibits strong improvement\nfor prevalent (Di)GNNs.",
      "tldr_zh": "本论文针对现有有向图神经网络 (DiGNNs) 在利用图数据知识方面存在的不足，提出了一种数据中心的方法：熵驱动的有向图知识蒸馏框架 (EDEN)。EDEN 基于分层编码理论，首先通过有向结构测量构建粗粒度分层知识树 (HKT)，然后量化节点属性的互信息来细化知识流，实现数据中心的知识蒸馏 (KD) 监督，从而提升模型的编码能力和预测性能。实验结果显示，EDEN 在 14 个（有向）图数据集和 4 个下游任务上达到 SOTA 性能，并显著改善了现有 (Di)GNNs 的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00983v1",
      "published_date": "2025-05-02 04:06:00 UTC",
      "updated_date": "2025-05-02 04:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:10:50.716700"
    },
    {
      "arxiv_id": "2505.00979v2",
      "title": "Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models",
      "title_zh": "Synthesize-on-Graph：知识丰富的合成数据生成用于大型语言模型的继续预训练",
      "authors": [
        "Xuhui Jiang",
        "Shengjie Ma",
        "Chengjin Xu",
        "Cehao Yang",
        "Liyu Zhang",
        "Jian Guo"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success but remain\ndata-inefficient, especially when learning from small, specialized corpora with\nlimited and proprietary data. Existing synthetic data generation methods for\ncontinue pre-training focus on intra-document content and overlook\ncross-document knowledge associations, limiting content diversity and depth. We\npropose Synthetic-on-Graph (SoG), a synthetic data generation framework that\nincorporates cross-document knowledge associations for efficient corpus\nexpansion. SoG constructs a context graph by extracting entities and concepts\nfrom the original corpus, representing cross-document associations, and\nemploying a graph walk strategy for knowledge-associated sampling. This\nenhances synthetic data diversity and coherence, enabling models to learn\ncomplex knowledge structures and handle rare knowledge. To further improve\nsynthetic data quality, we integrate Chain-of-Thought (CoT) and Contrastive\nClarifying (CC) synthetic, enhancing reasoning processes and discriminative\npower. Experiments show that SoG outperforms the state-of-the-art (SOTA) method\nin a multi-hop document Q&A dataset while performing comparably to the SOTA\nmethod on the reading comprehension task datasets, which also underscores the\nbetter generalization capability of SoG. Our work advances synthetic data\ngeneration and provides practical solutions for efficient knowledge acquisition\nin LLMs, especially in domains with limited data availability.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 在小规模专有数据集上数据效率低下的问题，提出 Synthetic-on-Graph (SoG) 框架，用于生成知识丰富的合成数据以进行继续预训练。SoG 通过构建上下文图提取实体和概念，捕捉跨文档知识关联，并采用图走策略进行采样，同时整合 Chain-of-Thought (CoT) 和 Contrastive Clarifying (CC) 技术，以提升合成数据的多样性、连贯性和推理能力。实验结果显示，SoG 在多跳文档问答数据集上优于现有最先进 (SOTA) 方法，在阅读理解任务上表现相当，并展示了更强的泛化能力。该框架为 LLMs 在数据有限领域高效获取知识提供了实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00979v2",
      "published_date": "2025-05-02 03:40:39 UTC",
      "updated_date": "2025-05-19 02:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:11:03.052899"
    },
    {
      "arxiv_id": "2505.00976v1",
      "title": "Attack and defense techniques in large language models: A survey and new perspectives",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyu Liao",
        "Kang Chen",
        "Yuanguo Lin",
        "Kangkang Li",
        "Yunxuan Liu",
        "Hefeng Chen",
        "Xingwang Huang",
        "Yuanhui Yu"
      ],
      "abstract": "Large Language Models (LLMs) have become central to numerous natural language\nprocessing tasks, but their vulnerabilities present significant security and\nethical challenges. This systematic survey explores the evolving landscape of\nattack and defense techniques in LLMs. We classify attacks into adversarial\nprompt attack, optimized attacks, model theft, as well as attacks on\napplication of LLMs, detailing their mechanisms and implications. Consequently,\nwe analyze defense strategies, including prevention-based and detection-based\ndefense methods. Although advances have been made, challenges remain to adapt\nto the dynamic threat landscape, balance usability with robustness, and address\nresource constraints in defense implementation. We highlight open problems,\nincluding the need for adaptive scalable defenses, explainable security\ntechniques, and standardized evaluation frameworks. This survey provides\nactionable insights and directions for developing secure and resilient LLMs,\nemphasizing the importance of interdisciplinary collaboration and ethical\nconsiderations to mitigate risks in real-world applications.",
      "tldr_zh": "这篇调查论文系统地探讨了大型语言模型 (LLMs) 中的攻击和防御技术，分类了攻击类型包括对抗提示攻击 (adversarial prompt attack)、优化攻击 (optimized attacks) 和模型窃取 (model theft)，并分析了这些攻击的机制和影响。论文进一步评估了防御策略，如基于预防和检测的方法，尽管取得了进展，但仍面临适应动态威胁、平衡可用性与鲁棒性以及资源约束的挑战。最终，它强调了开放问题如开发适应性可扩展防御、可解释的安全技术以及标准化评估框架的必要性，并为构建安全且弹性的 LLMs 提供了可操作见解和未来方向。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00976v1",
      "published_date": "2025-05-02 03:37:52 UTC",
      "updated_date": "2025-05-02 03:37:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:11:15.001323"
    },
    {
      "arxiv_id": "2505.00972v1",
      "title": "Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuewen Mei",
        "Tong Nie",
        "Jian Sun",
        "Ye Tian"
      ],
      "abstract": "Simulation-based testing is crucial for validating autonomous vehicles (AVs),\nyet existing scenario generation methods either overfit to common driving\npatterns or operate in an offline, non-interactive manner that fails to expose\nrare, safety-critical corner cases. In this paper, we introduce an online,\nretrieval-augmented large language model (LLM) framework for generating\nsafety-critical driving scenarios. Our method first employs an LLM-based\nbehavior analyzer to infer the most dangerous intent of the background vehicle\nfrom the observed state, then queries additional LLM agents to synthesize\nfeasible adversarial trajectories. To mitigate catastrophic forgetting and\naccelerate adaptation, we augment the framework with a dynamic memorization and\nretrieval bank of intent-planner pairs, automatically expanding its behavioral\nlibrary when novel intents arise. Evaluations using the Waymo Open Motion\nDataset demonstrate that our model reduces the mean minimum time-to-collision\nfrom 1.62 to 1.08 s and incurs a 75% collision rate, substantially\noutperforming baselines.",
      "tldr_zh": "这篇论文提出了一种在线的检索增强大语言模型 (Retrieval Augmented Large Language Models) 框架，用于生成自动驾驶的安全关键场景，以解决现有方法过度拟合常见模式或无法捕捉罕见风险的问题。该框架通过 LLM 基于观察到的车辆状态推断最危险意图，并由其他 LLM 代理合成可行的对抗轨迹，同时利用动态记忆和检索银行自动扩展行为库以缓解灾难性遗忘。实验结果显示，在 Waymo Open Motion Dataset 上，该方法将平均最小碰撞时间从 1.62 秒减少到 1.08 秒，并实现了 75% 的碰撞率，大大超过了基线模型的表现。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00972v1",
      "published_date": "2025-05-02 03:22:00 UTC",
      "updated_date": "2025-05-02 03:22:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:11:28.857174"
    },
    {
      "arxiv_id": "2505.00968v1",
      "title": "Tree-Sliced Wasserstein Distance with Nonlinear Projection",
      "title_zh": "翻译失败",
      "authors": [
        "Thanh Tran",
        "Viet-Hoang Tran",
        "Thanh Chu",
        "Trang Pham",
        "Laurent El Ghaoui",
        "Tam Le",
        "Tan M. Nguyen"
      ],
      "abstract": "Tree-Sliced methods have recently emerged as an alternative to the\ntraditional Sliced Wasserstein (SW) distance, replacing one-dimensional lines\nwith tree-based metric spaces and incorporating a splitting mechanism for\nprojecting measures. This approach enhances the ability to capture the\ntopological structures of integration domains in Sliced Optimal Transport while\nmaintaining low computational costs. Building on this foundation, we propose a\nnovel nonlinear projectional framework for the Tree-Sliced Wasserstein (TSW)\ndistance, substituting the linear projections in earlier versions with general\nprojections, while ensuring the injectivity of the associated Radon Transform\nand preserving the well-definedness of the resulting metric. By designing\nappropriate projections, we construct efficient metrics for measures on both\nEuclidean spaces and spheres. Finally, we validate our proposed metric through\nextensive numerical experiments for Euclidean and spherical datasets.\nApplications include gradient flows, self-supervised learning, and generative\nmodels, where our methods demonstrate significant improvements over recent SW\nand TSW variants.",
      "tldr_zh": "本研究提出了一种基于非线性投影的 Tree-Sliced Wasserstein (TSW) 距离框架，将传统线性投影替换为通用投影，同时确保相关 Radon Transform 的注入性和度量定义的良好性，从而更好地捕捉 Sliced Optimal Transport 中整合域的拓扑结构。作者通过设计合适的投影，构建了适用于欧氏空间和球面的高效度量，并在广泛的数值实验中验证了其在欧氏和球面数据集上的优越性能。相比于现有的 Sliced Wasserstein (SW) 和 TSW 变体，该方法在梯度流、自监督学习和生成模型等应用中实现了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00968v1",
      "published_date": "2025-05-02 03:06:25 UTC",
      "updated_date": "2025-05-02 03:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:11:39.448521"
    },
    {
      "arxiv_id": "2505.02849v1",
      "title": "Enhancing tutoring systems by leveraging tailored promptings and domain knowledge with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mohsen Balavar",
        "Wenli Yang",
        "David Herbert",
        "Soonja Yeom"
      ],
      "abstract": "Recent advancements in artificial intelligence (AI) and machine learning have\nreignited interest in their impact on Computer-based Learning (CBL). AI-driven\ntools like ChatGPT and Intelligent Tutoring Systems (ITS) have enhanced\nlearning experiences through personalisation and flexibility. ITSs can adapt to\nindividual learning needs and provide customised feedback based on a student's\nperformance, cognitive state, and learning path. Despite these advances,\nchallenges remain in accommodating diverse learning styles and delivering\nreal-time, context-aware feedback. Our research aims to address these gaps by\nintegrating skill-aligned feedback via Retrieval Augmented Generation (RAG)\ninto prompt engineering for Large Language Models (LLMs) and developing an\napplication to enhance learning through personalised tutoring in a computer\nscience programming context. The pilot study evaluated a proposed system using\nthree quantitative metrics: readability score, response time, and feedback\ndepth, across three programming tasks of varying complexity. The system\nsuccessfully sorted simulated students into three skill-level categories and\nprovided context-aware feedback. This targeted approach demonstrated better\neffectiveness and adaptability compared to general methods.",
      "tldr_zh": "这篇论文探讨了如何通过整合 Retrieval Augmented Generation (RAG) 和提示工程到 Large Language Models (LLMs) 中，提升 Intelligent Tutoring Systems (ITS) 的效果，以解决适应多样学习风格和提供实时反馈的挑战。研究开发了一个应用，在计算机科学编程任务中提供技能匹配的个性化反馈，并使用 RAG 技术根据学生的表现、认知状态和学习路径生成定制化指导。试点研究通过 readability score、response time 和 feedback depth 等量化指标评估，发现该系统能准确分类学生技能水平，提供上下文感知反馈，并比一般方法更有效和适应性强。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02849v1",
      "published_date": "2025-05-02 02:30:39 UTC",
      "updated_date": "2025-05-02 02:30:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:11:50.858332"
    },
    {
      "arxiv_id": "2505.00949v3",
      "title": "Llama-Nemotron: Efficient Reasoning Models",
      "title_zh": "Llama-Nemotron：高效推理模型",
      "authors": [
        "Akhiad Bercovich",
        "Itay Levy",
        "Izik Golan",
        "Mohammad Dabbah",
        "Ran El-Yaniv",
        "Omri Puny",
        "Ido Galil",
        "Zach Moshe",
        "Tomer Ronen",
        "Najeeb Nabwani",
        "Ido Shahaf",
        "Oren Tropp",
        "Ehud Karpas",
        "Ran Zilberstein",
        "Jiaqi Zeng",
        "Soumye Singhal",
        "Alexander Bukharin",
        "Yian Zhang",
        "Tugrul Konuk",
        "Gerald Shen",
        "Ameya Sunil Mahabaleshwarkar",
        "Bilal Kartal",
        "Yoshi Suhara",
        "Olivier Delalleau",
        "Zijia Chen",
        "Zhilin Wang",
        "David Mosallanezhad",
        "Adi Renduchintala",
        "Haifeng Qian",
        "Dima Rekesh",
        "Fei Jia",
        "Somshubra Majumdar",
        "Vahid Noroozi",
        "Wasi Uddin Ahmad",
        "Sean Narenthiran",
        "Aleksander Ficek",
        "Mehrzad Samadi",
        "Jocelyn Huang",
        "Siddhartha Jain",
        "Igor Gitman",
        "Ivan Moshkov",
        "Wei Du",
        "Shubham Toshniwal",
        "George Armstrong",
        "Branislav Kisacanin",
        "Matvei Novikov",
        "Daria Gitman",
        "Evelina Bakhturina",
        "Jane Polak Scowcroft",
        "John Kamalu",
        "Dan Su",
        "Kezhi Kong",
        "Markus Kliegl",
        "Rabeeh Karimi",
        "Ying Lin",
        "Sanjeev Satheesh",
        "Jupinder Parmar",
        "Pritam Gundecha",
        "Brandon Norick",
        "Joseph Jennings",
        "Shrimai Prabhumoye",
        "Syeda Nahida Akter",
        "Mostofa Patwary",
        "Abhinav Khattar",
        "Deepak Narayanan",
        "Roger Waleffe",
        "Jimmy Zhang",
        "Bor-Yiing Su",
        "Guyue Huang",
        "Terry Kong",
        "Parth Chadha",
        "Sahil Jain",
        "Christine Harvey",
        "Elad Segal",
        "Jining Huang",
        "Sergey Kashirsky",
        "Robert McQueen",
        "Izzy Putterman",
        "George Lam",
        "Arun Venkatesan",
        "Sherry Wu",
        "Vinh Nguyen",
        "Manoj Kilaru",
        "Andrew Wang",
        "Anna Warno",
        "Abhilash Somasamudramath",
        "Sandip Bhaskar",
        "Maka Dong",
        "Nave Assaf",
        "Shahar Mor",
        "Omer Ullman Argov",
        "Scot Junkin",
        "Oleksandr Romanenko",
        "Pedro Larroy",
        "Monika Katariya",
        "Marco Rovinelli",
        "Viji Balas",
        "Nicholas Edelman",
        "Anahita Bhiwandiwalla",
        "Muthu Subramaniam",
        "Smita Ithape",
        "Karthik Ramamoorthy",
        "Yuting Wu",
        "Suguna Varshini Velury",
        "Omri Almog",
        "Joyjit Daw",
        "Denys Fridman",
        "Erick Galinkin",
        "Michael Evans",
        "Shaona Ghosh",
        "Katherine Luna",
        "Leon Derczynski",
        "Nikki Pope",
        "Eileen Long",
        "Seth Schneider",
        "Guillermo Siman",
        "Tomasz Grzegorzek",
        "Pablo Ribalta",
        "Monika Katariya",
        "Chris Alexiuk",
        "Joey Conway",
        "Trisha Saar",
        "Ann Guan",
        "Krzysztof Pawelec",
        "Shyamala Prayaga",
        "Oleksii Kuchaiev",
        "Boris Ginsburg",
        "Oluwatobi Olabiyi",
        "Kari Briski",
        "Jonathan Cohen",
        "Bryan Catanzaro",
        "Jonah Alben",
        "Yonatan Geifman",
        "Eric Chung"
      ],
      "abstract": "We introduce the Llama-Nemotron series of models, an open family of\nheterogeneous reasoning models that deliver exceptional reasoning capabilities,\ninference efficiency, and an open license for enterprise use. The family comes\nin three sizes -- Nano (8B), Super (49B), and Ultra (253B) -- and performs\ncompetitively with state-of-the-art reasoning models such as DeepSeek-R1 while\noffering superior inference throughput and memory efficiency. In this report,\nwe discuss the training procedure for these models, which entails using neural\narchitecture search from Llama 3 models for accelerated inference, knowledge\ndistillation, and continued pretraining, followed by a reasoning-focused\npost-training stage consisting of two main parts: supervised fine-tuning and\nlarge scale reinforcement learning. Llama-Nemotron models are the first\nopen-source models to support a dynamic reasoning toggle, allowing users to\nswitch between standard chat and reasoning modes during inference. To further\nsupport open research and facilitate model development, we provide the\nfollowing resources: 1. We release the Llama-Nemotron reasoning models --\nLN-Nano, LN-Super, and LN-Ultra -- under the commercially permissive NVIDIA\nOpen Model License Agreement. 2. We release the complete post-training dataset:\nLlama-Nemotron-Post-Training-Dataset. 3. We also release our training\ncodebases: NeMo, NeMo-Aligner, and Megatron-LM.",
      "tldr_zh": "我们介绍了 Llama-Nemotron 系列高效推理模型，包括 Nano (8B)、Super (49B) 和 Ultra (253B) 三个尺寸，这些模型在推理能力上与 DeepSeek-R1 等最先进模型竞争，同时提供更高的推理吞吐量和内存效率。训练过程涉及从 Llama 3 模型的 neural architecture search 进行加速推理、knowledge distillation 和继续预训练，随后通过 supervised fine-tuning 和大规模 reinforcement learning 进行推理-focused 的后期训练。这些模型是首个开源支持动态推理切换的功能，允许用户在标准聊天和推理模式间无缝切换。为了促进开源研究，我们发布了 Llama-Nemotron 模型、完整的后期训练数据集 Llama-Nemotron-Post-Training-Dataset，以及训练代码库 NeMo、NeMo-Aligner 和 Megatron-LM。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00949v3",
      "published_date": "2025-05-02 01:35:35 UTC",
      "updated_date": "2025-05-14 16:47:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:12:04.647270"
    },
    {
      "arxiv_id": "2505.02848v1",
      "title": "Aligning Large Language Models with Healthcare Stakeholders: A Pathway to Trustworthy AI Integration",
      "title_zh": "将大型语言模型与医疗利益相关者对齐：通往可信赖 AI 整合的途径",
      "authors": [
        "Kexin Ding",
        "Mu Zhou",
        "Akshay Chaudhari",
        "Shaoting Zhang",
        "Dimitris N. Metaxas"
      ],
      "abstract": "The wide exploration of large language models (LLMs) raises the awareness of\nalignment between healthcare stakeholder preferences and model outputs. This\nalignment becomes a crucial foundation to empower the healthcare workflow\neffectively, safely, and responsibly. Yet the varying behaviors of LLMs may not\nalways match with healthcare stakeholders' knowledge, demands, and values. To\nenable a human-AI alignment, healthcare stakeholders will need to perform\nessential roles in guiding and enhancing the performance of LLMs. Human\nprofessionals must participate in the entire life cycle of adopting LLM in\nhealthcare, including training data curation, model training, and inference. In\nthis review, we discuss the approaches, tools, and applications of alignments\nbetween healthcare stakeholders and LLMs. We demonstrate that LLMs can better\nfollow human values by properly enhancing healthcare knowledge integration,\ntask understanding, and human guidance. We provide outlooks on enhancing the\nalignment between humans and LLMs to build trustworthy real-world healthcare\napplications.",
      "tldr_zh": "这篇论文探讨了如何将大型语言模型 (LLMs) 与医疗利益相关者的偏好对齐，以确保医疗工作流程的安全、有效和负责任整合。作者强调人类专业人士在 LLM 生命周期中的关键角色，包括训练数据整理、模型训练和推理过程，以解决模型行为与利益相关者知识、需求和价值观的潜在不匹配。论文审视了相关方法、工具和应用，展示了通过增强医疗知识整合、任务理解及人类指导来提升 LLM 性能的途径，并展望了构建可信实医疗应用的未来前景。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.02848v1",
      "published_date": "2025-05-02 00:59:49 UTC",
      "updated_date": "2025-05-02 00:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:12:14.555256"
    },
    {
      "arxiv_id": "2505.00938v1",
      "title": "CDFormer: Cross-Domain Few-Shot Object Detection Transformer Against Feature Confusion",
      "title_zh": "翻译失败",
      "authors": [
        "Boyuan Meng",
        "Xiaohan Zhang",
        "Peilin Li",
        "Zhe Wu",
        "Yiming Li",
        "Wenkai Zhao",
        "Beinan Yu",
        "Hui-Liang Shen"
      ],
      "abstract": "Cross-domain few-shot object detection (CD-FSOD) aims to detect novel objects\nacross different domains with limited class instances. Feature confusion,\nincluding object-background confusion and object-object confusion, presents\nsignificant challenges in both cross-domain and few-shot settings. In this\nwork, we introduce CDFormer, a cross-domain few-shot object detection\ntransformer against feature confusion, to address these challenges. The method\nspecifically tackles feature confusion through two key modules:\nobject-background distinguishing (OBD) and object-object distinguishing (OOD).\nThe OBD module leverages a learnable background token to differentiate between\nobjects and background, while the OOD module enhances the distinction between\nobjects of different classes. Experimental results demonstrate that CDFormer\noutperforms previous state-of-the-art approaches, achieving 12.9% mAP, 11.0%\nmAP, and 10.4% mAP improvements under the 1/5/10 shot settings, respectively,\nwhen fine-tuned.",
      "tldr_zh": "本研究针对跨域少样本对象检测 (CD-FSOD) 中的特征混淆问题，包括对象-背景混淆和对象-对象混淆，提出了一种基于 Transformer 的模型 CDFormer。该模型通过对象-背景区分 (OBD) 模块利用可学习的背景 token 来区分对象与背景，以及对象-对象区分 (OOD) 模块增强不同类对象间的区分，从而有效缓解这些挑战。实验结果表明，CDFormer 在 1/5/10 shot 设置下分别比现有最先进方法提高了 12.9%、11.0% 和 10.4% 的 mAP，为跨域少样本检测提供了显著改进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00938v1",
      "published_date": "2025-05-02 00:46:25 UTC",
      "updated_date": "2025-05-02 00:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:12:27.877124"
    },
    {
      "arxiv_id": "2505.00935v1",
      "title": "Autonomous Embodied Agents: When Robotics Meets Deep Learning Reasoning",
      "title_zh": "自治的具身代理：当机器人学遇见深度学习推理",
      "authors": [
        "Roberto Bigazzi"
      ],
      "abstract": "The increase in available computing power and the Deep Learning revolution\nhave allowed the exploration of new topics and frontiers in Artificial\nIntelligence research. A new field called Embodied Artificial Intelligence,\nwhich places at the intersection of Computer Vision, Robotics, and Decision\nMaking, has been gaining importance during the last few years, as it aims to\nfoster the development of smart autonomous robots and their deployment in\nsociety. The recent availability of large collections of 3D models for\nphotorealistic robotic simulation has allowed faster and safe training of\nlearning-based agents for millions of frames and a careful evaluation of their\nbehavior before deploying the models on real robotic platforms. These\nintelligent agents are intended to perform a certain task in a possibly unknown\nenvironment. To this end, during the training in simulation, the agents learn\nto perform continuous interactions with the surroundings, such as gathering\ninformation from the environment, encoding and extracting useful cues for the\ntask, and performing actions towards the final goal; where every action of the\nagent influences the interactions. This dissertation follows the complete\ncreation process of embodied agents for indoor environments, from their concept\nto their implementation and deployment. We aim to contribute to research in\nEmbodied AI and autonomous agents, in order to foster future work in this\nfield. We present a detailed analysis of the procedure behind implementing an\nintelligent embodied agent, comprehending a thorough description of the current\nstate-of-the-art in literature, technical explanations of the proposed methods,\nand accurate experimental studies on relevant robotic tasks.",
      "tldr_zh": "这篇论文探讨了 Autonomous Embodied Agents 的发展，将 Robotics 与 Deep Learning Reasoning 相结合，旨在推进 Embodied AI 领域，通过计算机视觉、机器人和决策的交叉应用来创建智能自主机器人。论文详细描述了使用 photorealistic 3D 模型进行仿真训练的过程，让代理在模拟环境中学习与周围的连续互动，包括信息收集、线索提取和行动执行，以适应未知环境。最终，通过文献综述、技术方法解释和实验研究，论文为相关机器人任务提供了全面分析，并为 Embodied AI 的未来研究奠定了基础。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Ph.D. Dissertation",
      "pdf_url": "http://arxiv.org/pdf/2505.00935v1",
      "published_date": "2025-05-02 00:43:28 UTC",
      "updated_date": "2025-05-02 00:43:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:12:40.502160"
    },
    {
      "arxiv_id": "2505.07834v1",
      "title": "ai.txt: A Domain-Specific Language for Guiding AI Interactions with the Internet",
      "title_zh": "ai.txt：一种用于指导AI与互联网",
      "authors": [
        "Yuekang Li",
        "Wei Song",
        "Bangshuo Zhu",
        "Dong Gong",
        "Yi Liu",
        "Gelei Deng",
        "Chunyang Chen",
        "Lei Ma",
        "Jun Sun",
        "Toby Walsh",
        "Jingling Xue"
      ],
      "abstract": "We introduce ai.txt, a novel domain-specific language (DSL) designed to\nexplicitly regulate interactions between AI models, agents, and web content,\naddressing critical limitations of the widely adopted robots.txt standard. As\nAI increasingly engages with online materials for tasks such as training,\nsummarization, and content modification, existing regulatory methods lack the\nnecessary granularity and semantic expressiveness to ensure ethical and legal\ncompliance. ai.txt extends traditional URL-based access controls by enabling\nprecise element-level regulations and incorporating natural language\ninstructions interpretable by AI systems. To facilitate practical deployment,\nwe provide an integrated development environment with code autocompletion and\nautomatic XML generation. Furthermore, we propose two compliance mechanisms:\nXML-based programmatic enforcement and natural language prompt integration, and\ndemonstrate their effectiveness through preliminary experiments and case\nstudies. Our approach aims to aid the governance of AI-Internet interactions,\npromoting responsible AI use in digital ecosystems.",
      "tldr_zh": "论文引入了ai.txt，一种新型领域特定语言（DSL），旨在明确规范AI模型、代理与网络内容的交互，解决robots.txt标准的粒度和语义表达不足问题。ai.txt扩展了传统的URL-based访问控制，支持元素级别的调控和可由AI系统解释的自然语言指令，以确保伦理和法律合规。为便于部署，该框架提供集成开发环境（IDE），包括代码自动完成和自动XML生成，并提出两种合规机制：基于XML的程序化执行和自然语言提示集成。初步实验和案例研究证明，ai.txt在指导AI-Internet交互方面有效，促进了数字生态系统中负责任的AI使用。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CR",
        "cs.PL"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07834v1",
      "published_date": "2025-05-02 00:33:00 UTC",
      "updated_date": "2025-05-02 00:33:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:12:51.808986"
    },
    {
      "arxiv_id": "2505.00932v1",
      "title": "A Self-Supervised Transformer for Unusable Shared Bike Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yin Huang",
        "Yongqi Dong",
        "Youhua Tang",
        "Alvaro García Hernandez"
      ],
      "abstract": "The rapid expansion of bike-sharing systems (BSS) has greatly improved urban\n\"last-mile\" connectivity, yet large-scale deployments face escalating\noperational challenges, particularly in detecting faulty bikes. Existing\ndetection approaches either rely on static model-based thresholds that overlook\ndynamic spatiotemporal (ST) usage patterns or employ supervised learning\nmethods that struggle with label scarcity and class imbalance. To address these\nlimitations, this paper proposes a novel Self-Supervised Transformer\n(SSTransformer) framework for automatically detecting unusable shared bikes,\nleveraging ST features extracted from GPS trajectories and trip records. The\nmodel incorporates a self-supervised pre-training strategy to enhance its\nfeature extraction capabilities, followed by fine-tuning for efficient status\nrecognition. In the pre-training phase, the Transformer encoder learns\ngeneralized representations of bike movement via a self-supervised objective;\nin the fine-tuning phase, the encoder is adapted to a downstream binary\nclassification task. Comprehensive experiments on a real-world dataset of\n10,730 bikes (1,870 unusable, 8,860 normal) from Chengdu, China, demonstrate\nthat SSTransformer significantly outperforms traditional machine learning,\nensemble learning, and deep learning baselines, achieving the best accuracy\n(97.81%), precision (0.8889), and F1-score (0.9358). This work highlights the\neffectiveness of self-supervised Transformer on ST data for capturing complex\nanomalies in BSS, paving the way toward more reliable and scalable maintenance\nsolutions for shared mobility.",
      "tldr_zh": "这篇论文针对共享单车系统（BSS）中检测故障单车的挑战，提出了一种新型Self-Supervised Transformer (SSTransformer)框架，利用GPS轨迹和行程记录提取spatiotemporal (ST)特征，以克服现有方法的静态阈值局限和监督学习中的标签稀缺问题。框架通过自监督预训练阶段学习单车运动的泛化表示，然后在微调阶段进行二元分类任务，以高效识别不可用单车。在成都真实数据集（10,730辆单车）上的实验显示，SSTransformer优于传统机器学习、集成学习和深度学习基线，实现了97.81%的准确率、0.8889的精确率和0.9358的F1-score。该方法为共享移动系统的可靠维护提供了可扩展解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 5 figures, under review by the 2025 IEEE International\n  Conference on Intelligent Transportation Systems (IEEE ITSC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.00932v1",
      "published_date": "2025-05-02 00:20:38 UTC",
      "updated_date": "2025-05-02 00:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:13:04.867656"
    },
    {
      "arxiv_id": "2505.00931v1",
      "title": "Large Language Model-Driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing",
      "title_zh": "大语言模型驱动的英语学习者写作语法准确性动态评估",
      "authors": [
        "Timur Jaganov",
        "John Blake",
        "Julián Villegas",
        "Nicholas Carr"
      ],
      "abstract": "This study investigates the potential for Large Language Models (LLMs) to\nscale-up Dynamic Assessment (DA). To facilitate such an investigation, we first\ndeveloped DynaWrite-a modular, microservices-based grammatical tutoring\napplication which supports multiple LLMs to generate dynamic feedback to\nlearners of English. Initial testing of 21 LLMs, revealed GPT-4o and neural\nchat to have the most potential to scale-up DA in the language learning\nclassroom. Further testing of these two candidates found both models performed\nsimilarly in their ability to accurately identify grammatical errors in user\nsentences. However, GPT-4o consistently outperformed neural chat in the quality\nof its DA by generating clear, consistent, and progressively explicit hints.\nReal-time responsiveness and system stability were also confirmed through\ndetailed performance testing, with GPT-4o exhibiting sufficient speed and\nstability. This study shows that LLMs can be used to scale-up dynamic\nassessment and thus enable dynamic assessment to be delivered to larger groups\nthan possible in traditional teacher-learner settings.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）如何扩展动态评估（DA）以评估英语学习者写作的语法准确性。研究团队开发了DynaWrite应用，这是一个模块化微服务系统，支持多个LLMs生成动态反馈，并在测试21个LLMs后，发现GPT-4o和neural chat最具潜力。进一步比较显示，GPT-4o在识别语法错误、提供清晰一致的渐进式提示方面优于neural chat，同时表现出色的时间响应和系统稳定性。该研究证明，LLMs可有效扩展DA，使其适用于更大规模的语言学习群体，而非传统的一对一教学模式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 8 Figures. This work has been submitted to the IEEE for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2505.00931v1",
      "published_date": "2025-05-02 00:19:50 UTC",
      "updated_date": "2025-05-02 00:19:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T19:13:15.985185"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 112,
  "processed_papers_count": 112,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T19:13:40.910108"
}