[
  {
    "arxiv_id": "2411.03562v1",
    "title": "Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level",
    "authors": [
      "Antoine Grosnit",
      "Alexandre Maraval",
      "James Doran",
      "Giuseppe Paolo",
      "Albert Thomas",
      "Refinath Shahul Hameed Nabeezath Beevi",
      "Jonas Gonzalez",
      "Khyati Khandelwal",
      "Ignacio Iacobacci",
      "Abdelhakim Benechehab",
      "Hamza Cherkaoui",
      "Youssef Attia El-Hili",
      "Kun Shao",
      "Jianye Hao",
      "Jun Yao",
      "Balazs Kegl",
      "Haitham Bou-Ammar",
      "Jun Wang"
    ],
    "abstract": "We introduce Agent K v1.0, an end-to-end autonomous data science agent\ndesigned to automate, optimise, and generalise across diverse data science\ntasks. Fully automated, Agent K v1.0 manages the entire data science life cycle\nby learning from experience. It leverages a highly flexible structured\nreasoning framework to enable it to dynamically process memory in a nested\nstructure, effectively learning from accumulated experience stored to handle\ncomplex reasoning tasks. It optimises long- and short-term memory by\nselectively storing and retrieving key information, guiding future decisions\nbased on environmental rewards. This iterative approach allows it to refine\ndecisions without fine-tuning or backpropagation, achieving continuous\nimprovement through experiential learning. We evaluate our agent's apabilities\nusing Kaggle competitions as a case study. Following a fully automated\nprotocol, Agent K v1.0 systematically addresses complex and multimodal data\nscience tasks, employing Bayesian optimisation for hyperparameter tuning and\nfeature engineering. Our new evaluation framework rigorously assesses Agent K\nv1.0's end-to-end capabilities to generate and send submissions starting from a\nKaggle competition URL. Results demonstrate that Agent K v1.0 achieves a 92.5\\%\nsuccess rate across tasks, spanning tabular, computer vision, NLP, and\nmultimodal domains. When benchmarking against 5,856 human Kaggle competitors by\ncalculating Elo-MMR scores for each, Agent K v1.0 ranks in the top 38\\%,\ndemonstrating an overall skill level comparable to Expert-level users. Notably,\nits Elo-MMR score falls between the first and third quartiles of scores\nachieved by human Grandmasters. Furthermore, our results indicate that Agent K\nv1.0 has reached a performance level equivalent to Kaggle Grandmaster, with a\nrecord of 6 gold, 3 silver, and 7 bronze medals, as defined by Kaggle's\nprogression system.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03562v1",
    "published_date": "2024-11-05 23:55:23 UTC",
    "updated_date": "2024-11-05 23:55:23 UTC"
  },
  {
    "arxiv_id": "2411.03551v1",
    "title": "Enhancing Weakly Supervised Semantic Segmentation for Fibrosis via Controllable Image Generation",
    "authors": [
      "Zhiling Yue",
      "Yingying Fang",
      "Liutao Yang",
      "Nikhil Baid",
      "Simon Walsh",
      "Guang Yang"
    ],
    "abstract": "Fibrotic Lung Disease (FLD) is a severe condition marked by lung stiffening\nand scarring, leading to respiratory decline. High-resolution computed\ntomography (HRCT) is critical for diagnosing and monitoring FLD; however,\nfibrosis appears as irregular, diffuse patterns with unclear boundaries,\nleading to high inter-observer variability and time-intensive manual\nannotation. To tackle this challenge, we propose DiffSeg, a novel weakly\nsupervised semantic segmentation (WSSS) method that uses image-level\nannotations to generate pixel-level fibrosis segmentation, reducing the need\nfor fine-grained manual labeling. Additionally, our DiffSeg incorporates a\ndiffusion-based generative model to synthesize HRCT images with different\nlevels of fibrosis from healthy slices, enabling the generation of the\nfibrosis-injected slices and their paired fibrosis location. Experiments\nindicate that our method significantly improves the accuracy of pseudo masks\ngenerated by existing WSSS methods, greatly reducing the complexity of manual\nlabeling and enhancing the consistency of the generated masks.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03551v1",
    "published_date": "2024-11-05 23:11:26 UTC",
    "updated_date": "2024-11-05 23:11:26 UTC"
  },
  {
    "arxiv_id": "2411.03542v1",
    "title": "Exploring the Benefits of Domain-Pretraining of Generative Large Language Models for Chemistry",
    "authors": [
      "Anurag Acharya",
      "Shivam Sharma",
      "Robin Cosbey",
      "Megha Subramanian",
      "Scott Howland",
      "Maria Glenski"
    ],
    "abstract": "A proliferation of Large Language Models (the GPT series, BLOOM, LLaMA, and\nmore) are driving forward novel development of multipurpose AI for a variety of\ntasks, particularly natural language processing (NLP) tasks. These models\ndemonstrate strong performance on a range of tasks; however, there has been\nevidence of brittleness when applied to more niche or narrow domains where\nhallucinations or fluent but incorrect responses reduce performance. Given the\ncomplex nature of scientific domains, it is prudent to investigate the\ntrade-offs of leveraging off-the-shelf versus more targeted foundation models\nfor scientific domains. In this work, we examine the benefits of in-domain\npre-training for a given scientific domain, chemistry, and compare these to\nopen-source, off-the-shelf models with zero-shot and few-shot prompting. Our\nresults show that not only do in-domain base models perform reasonably well on\nin-domain tasks in a zero-shot setting but that further adaptation using\ninstruction fine-tuning yields impressive performance on chemistry-specific\ntasks such as named entity recognition and molecular formula generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03542v1",
    "published_date": "2024-11-05 22:45:10 UTC",
    "updated_date": "2024-11-05 22:45:10 UTC"
  },
  {
    "arxiv_id": "2411.05829v1",
    "title": "Utilizing RNN for Real-time Cryptocurrency Price Prediction and Trading Strategy Optimization",
    "authors": [
      "Shamima Nasrin Tumpa",
      "Kehelwala Dewage Gayan Maduranga"
    ],
    "abstract": "This study explores the use of Recurrent Neural Networks (RNN) for real-time\ncryptocurrency price prediction and optimized trading strategies. Given the\nhigh volatility of the cryptocurrency market, traditional forecasting models\noften fall short. By leveraging RNNs' capability to capture long-term patterns\nin time-series data, this research aims to improve accuracy in price prediction\nand develop effective trading strategies. The project follows a structured\napproach involving data collection, preprocessing, and model refinement,\nfollowed by rigorous backtesting for profitability and risk assessment. This\nwork contributes to both the academic and practical fields by providing a\nrobust predictive model and optimized trading strategies that address the\nchallenges of cryptocurrency trading.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "q-fin.ST",
    "comment": "10 pages, 16 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2411.05829v1",
    "published_date": "2024-11-05 22:44:52 UTC",
    "updated_date": "2024-11-05 22:44:52 UTC"
  },
  {
    "arxiv_id": "2411.03537v1",
    "title": "Two-Stage Pretraining for Molecular Property Prediction in the Wild",
    "authors": [
      "Kevin Tirta Wijaya",
      "Minghao Guo",
      "Michael Sun",
      "Hans-Peter Seidel",
      "Wojciech Matusik",
      "Vahid Babaei"
    ],
    "abstract": "Accurate property prediction is crucial for accelerating the discovery of new\nmolecules. Although deep learning models have achieved remarkable success,\ntheir performance often relies on large amounts of labeled data that are\nexpensive and time-consuming to obtain. Thus, there is a growing need for\nmodels that can perform well with limited experimentally-validated data. In\nthis work, we introduce MoleVers, a versatile pretrained model designed for\nvarious types of molecular property prediction in the wild, i.e., where\nexperimentally-validated molecular property labels are scarce. MoleVers adopts\na two-stage pretraining strategy. In the first stage, the model learns\nmolecular representations from large unlabeled datasets via masked atom\nprediction and dynamic denoising, a novel task enabled by a new branching\nencoder architecture. In the second stage, MoleVers is further pretrained using\nauxiliary labels obtained with inexpensive computational methods, enabling\nsupervised learning without the need for costly experimental data. This\ntwo-stage framework allows MoleVers to learn representations that generalize\neffectively across various downstream datasets. We evaluate MoleVers on a new\nbenchmark comprising 22 molecular datasets with diverse types of properties,\nthe majority of which contain 50 or fewer training labels reflecting real-world\nconditions. MoleVers achieves state-of-the-art results on 20 out of the 22\ndatasets, and ranks second among the remaining two, highlighting its ability to\nbridge the gap between data-hungry models and real-world conditions where\npractically-useful labels are scarce.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03537v1",
    "published_date": "2024-11-05 22:36:17 UTC",
    "updated_date": "2024-11-05 22:36:17 UTC"
  },
  {
    "arxiv_id": "2411.03531v1",
    "title": "Personalized Video Summarization by Multimodal Video Understanding",
    "authors": [
      "Brian Chen",
      "Xiangyuan Zhao",
      "Yingnan Zhu"
    ],
    "abstract": "Video summarization techniques have been proven to improve the overall user\nexperience when it comes to accessing and comprehending video content. If the\nuser's preference is known, video summarization can identify significant\ninformation or relevant content from an input video, aiding them in obtaining\nthe necessary information or determining their interest in watching the\noriginal video. Adapting video summarization to various types of video and user\npreferences requires significant training data and expensive human labeling. To\nfacilitate such research, we proposed a new benchmark for video summarization\nthat captures various user preferences. Also, we present a pipeline called\nVideo Summarization with Language (VSL) for user-preferred video summarization\nthat is based on pre-trained visual language models (VLMs) to avoid the need to\ntrain a video summarization system on a large training dataset. The pipeline\ntakes both video and closed captioning as input and performs semantic analysis\nat the scene level by converting video frames into text. Subsequently, the\nuser's genre preference was used as the basis for selecting the pertinent\ntextual scenes. The experimental results demonstrate that our proposed pipeline\noutperforms current state-of-the-art unsupervised video summarization models.\nWe show that our method is more adaptable across different datasets compared to\nsupervised query-based video summarization models. In the end, the runtime\nanalysis demonstrates that our pipeline is more suitable for practical use when\nscaling up the number of user preferences and videos.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "In Proceedings of CIKM 2024 Applied Research Track",
    "pdf_url": "http://arxiv.org/pdf/2411.03531v1",
    "published_date": "2024-11-05 22:14:35 UTC",
    "updated_date": "2024-11-05 22:14:35 UTC"
  },
  {
    "arxiv_id": "2411.03524v1",
    "title": "Mitigating Metric Bias in Minimum Bayes Risk Decoding",
    "authors": [
      "Geza Kovacs",
      "Daniel Deutsch",
      "Markus Freitag"
    ],
    "abstract": "While Minimum Bayes Risk (MBR) decoding using metrics such as COMET or\nMetricX has outperformed traditional decoding methods such as greedy or beam\nsearch, it introduces a challenge we refer to as metric bias. As MBR decoding\naims to produce translations that score highly according to a specific utility\nmetric, this very process makes it impossible to use the same metric for both\ndecoding and evaluation, as improvements might simply be due to reward hacking\nrather than reflecting real quality improvements. In this work we find that\ncompared to human ratings, neural metrics not only overestimate the quality of\nMBR decoding when the same metric is used as the utility metric, but they also\noverestimate the quality of MBR/QE decoding with other neural utility metrics\nas well. We also show that the metric bias issue can be mitigated by using an\nensemble of utility metrics during MBR decoding: human evaluations show that\nMBR decoding using an ensemble of utility metrics outperforms a single utility\nmetric.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear at WMT2024",
    "pdf_url": "http://arxiv.org/pdf/2411.03524v1",
    "published_date": "2024-11-05 22:01:27 UTC",
    "updated_date": "2024-11-05 22:01:27 UTC"
  },
  {
    "arxiv_id": "2411.03522v1",
    "title": "Exploring the Potentials and Challenges of Using Large Language Models for the Analysis of Transcriptional Regulation of Long Non-coding RNAs",
    "authors": [
      "Wei Wang",
      "Zhichao Hou",
      "Xiaorui Liu",
      "Xinxia Peng"
    ],
    "abstract": "Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03522v1",
    "published_date": "2024-11-05 21:57:38 UTC",
    "updated_date": "2024-11-05 21:57:38 UTC"
  },
  {
    "arxiv_id": "2411.11808v1",
    "title": "Character-level Tokenizations as Powerful Inductive Biases for RNA Foundational Models",
    "authors": [
      "Adrián Morales-Pastor",
      "Raquel Vázquez-Reza",
      "Miłosz Wieczór",
      "Clàudia Valverde",
      "Manel Gil-Sorribes",
      "Bertran Miquel-Oliver",
      "Álvaro Ciudad",
      "Alexis Molina"
    ],
    "abstract": "RNA is a vital biomolecule with numerous roles and functions within cells,\nand interest in targeting it for therapeutic purposes has grown significantly\nin recent years. However, fully understanding and predicting RNA behavior,\nparticularly for applications in drug discovery, remains a challenge due to the\ncomplexity of RNA structures and interactions. While foundational models in\nbiology have demonstrated success in modeling several biomolecules, especially\nproteins, achieving similar breakthroughs for RNA has proven more difficult.\nCurrent RNA models have yet to match the performance observed in the protein\ndomain, leaving an important gap in computational biology. In this work, we\npresent ChaRNABERT, a suite of sample and parameter-efficient RNA foundational\nmodels, that through a learnable tokenization process, are able to reach\nstate-of-the-art performance on several tasks in established benchmarks. We\nextend its testing in relevant downstream tasks such as RNA-protein and\naptamer-protein interaction prediction. Weights and inference code for\nChaRNABERT-8M will be provided for academic research use. The other models will\nbe available upon request.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "q-bio.QM",
    "comment": "First version. Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2411.11808v1",
    "published_date": "2024-11-05 21:56:16 UTC",
    "updated_date": "2024-11-05 21:56:16 UTC"
  },
  {
    "arxiv_id": "2411.03519v1",
    "title": "AI Metropolis: Scaling Large Language Model-based Multi-Agent Simulation with Out-of-order Execution",
    "authors": [
      "Zhiqiang Xie",
      "Hao Kang",
      "Ying Sheng",
      "Tushar Krishna",
      "Kayvon Fatahalian",
      "Christos Kozyrakis"
    ],
    "abstract": "With more advanced natural language understanding and reasoning capabilities,\nlarge language model (LLM)-powered agents are increasingly developed in\nsimulated environments to perform complex tasks, interact with other agents,\nand exhibit emergent behaviors relevant to social science and gaming. However,\ncurrent multi-agent simulations frequently suffer from inefficiencies due to\nthe limited parallelism caused by false dependencies, resulting in performance\nbottlenecks. In this paper, we introduce AI Metropolis, a simulation engine\nthat improves the efficiency of LLM agent simulations by incorporating\nout-of-order execution scheduling. By dynamically tracking real dependencies\nbetween agents, AI Metropolis minimizes false dependencies, enhancing\nparallelism and enabling efficient hardware utilization. Our evaluations\ndemonstrate that AI Metropolis achieves speedups from 1.3x to 4.15x over\nstandard parallel simulation with global synchronization, approaching optimal\nperformance as the number of agents increases.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03519v1",
    "published_date": "2024-11-05 21:54:14 UTC",
    "updated_date": "2024-11-05 21:54:14 UTC"
  },
  {
    "arxiv_id": "2411.03513v1",
    "title": "Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy",
    "authors": [
      "Razvan-Gabriel Dumitru",
      "Paul-Ioan Clotan",
      "Vikas Yadav",
      "Darius Peteleaza",
      "Mihai Surdeanu"
    ],
    "abstract": "This paper introduces a novel model compression approach through dynamic\nlayer-specific pruning in Large Language Models (LLMs), enhancing the\ntraditional methodology established by SliceGPT. By transitioning from constant\nto dynamic slicing, our method leverages the newly proposed Layer Redundancy\n(LR) score, which assesses how much change each layer changes its input by\nmeasuring the cosine similarity of the input to the output of the layer. We use\nthis score to prune parts of individual layers based on redundancy in such a\nway that the average pruned percentage for all layers is a fixed value. We\nconducted extensive experiments using models like Llama3-8B and Mistral-7B on\nmultiple datasets, evaluating different slicing bases and percentages to\ndetermine optimal configurations that balance efficiency and performance. Our\nfindings show that our dynamic slicing approach not only maintains but, in many\ncases, enhances model performance compared to the baseline established by\nconstant slicing methods. For instance, in several settings, we see performance\nimprovements of up to 5% over the SliceGPT baseline. Additionally, a perplexity\ndecrease by as much as 7% was observed across multiple benchmarks, validating\nthe effectiveness of our method. The code, model weights, and datasets are\nopen-sourced at https://github.com/RazvanDu/DynamicSlicing.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7; I.2.0"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.03513v1",
    "published_date": "2024-11-05 21:19:49 UTC",
    "updated_date": "2024-11-05 21:19:49 UTC"
  },
  {
    "arxiv_id": "2411.03495v1",
    "title": "Automatic Generation of Question Hints for Mathematics Problems using Large Language Models in Educational Technology",
    "authors": [
      "Junior Cedric Tonga",
      "Benjamin Clement",
      "Pierre-Yves Oudeyer"
    ],
    "abstract": "The automatic generation of hints by Large Language Models (LLMs) within\nIntelligent Tutoring Systems (ITSs) has shown potential to enhance student\nlearning. However, generating pedagogically sound hints that address student\nmisconceptions and adhere to specific educational objectives remains\nchallenging. This work explores using LLMs (GPT-4o and Llama-3-8B-instruct) as\nteachers to generate effective hints for students simulated through LLMs\n(GPT-3.5-turbo, Llama-3-8B-Instruct, or Mistral-7B-instruct-v0.3) tackling math\nexercises designed for human high-school students, and designed using cognitive\nscience principles. We present here the study of several dimensions: 1)\nidentifying error patterns made by simulated students on secondary-level math\nexercises; 2) developing various prompts for GPT-4o as a teacher and evaluating\ntheir effectiveness in generating hints that enable simulated students to\nself-correct; and 3) testing the best-performing prompts, based on their\nability to produce relevant hints and facilitate error correction, with\nLlama-3-8B-Instruct as the teacher, allowing for a performance comparison with\nGPT-4o. The results show that model errors increase with higher temperature\nsettings. Notably, when hints are generated by GPT-4o, the most effective\nprompts include prompts tailored to specific errors as well as prompts\nproviding general hints based on common mathematical errors. Interestingly,\nLlama-3-8B-Instruct as a teacher showed better overall performance than GPT-4o.\nAlso the problem-solving and response revision capabilities of the LLMs as\nstudents, particularly GPT-3.5-turbo, improved significantly after receiving\nhints, especially at lower temperature settings. However, models like\nMistral-7B-Instruct demonstrated a decline in performance as the temperature\nincreased.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NeurIPS 2024 Workshop on Large Foundation Models for\n  Educational Assessment (FM-Assess)",
    "pdf_url": "http://arxiv.org/pdf/2411.03495v1",
    "published_date": "2024-11-05 20:18:53 UTC",
    "updated_date": "2024-11-05 20:18:53 UTC"
  },
  {
    "arxiv_id": "2411.03486v1",
    "title": "LLM Generated Distribution-Based Prediction of US Electoral Results, Part I",
    "authors": [
      "Caleb Bradshaw",
      "Caelen Miller",
      "Sean Warnick"
    ],
    "abstract": "This paper introduces distribution-based prediction, a novel approach to\nusing Large Language Models (LLMs) as predictive tools by interpreting output\ntoken probabilities as distributions representing the models' learned\nrepresentation of the world. This distribution-based nature offers an\nalternative perspective for analyzing algorithmic fidelity, complementing the\napproach used in silicon sampling. We demonstrate the use of distribution-based\nprediction in the context of recent United States presidential election,\nshowing that this method can be used to determine task specific bias, prompt\nnoise, and algorithmic fidelity. This approach has significant implications for\nassessing the reliability and increasing transparency of LLM-based predictions\nacross various domains.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 10 Figures, Pre-print",
    "pdf_url": "http://arxiv.org/pdf/2411.03486v1",
    "published_date": "2024-11-05 20:10:25 UTC",
    "updated_date": "2024-11-05 20:10:25 UTC"
  },
  {
    "arxiv_id": "2411.15143v1",
    "title": "dafny-annotator: AI-Assisted Verification of Dafny Programs",
    "authors": [
      "Gabriel Poesia",
      "Chloe Loughridge",
      "Nada Amin"
    ],
    "abstract": "Formal verification has the potential to drastically reduce software bugs,\nbut its high additional cost has hindered large-scale adoption. While Dafny\npresents a promise to significantly reduce the effort to write verified\nprograms, users are often required to provide logical annotations to aid the\nverifier. Here, we explore using a combination of Large Language Models and\nsearch to build dafny-annotator: a tool that adds logical annotations to a\nDafny method until the verifier can prove it correct. On a test set from the\nDafnyBench collection of programs, greedy search guided by LLaMa 3.1 8B\nsuccessfully annotates only 15.7% of the methods. Since this data-driven\napproach is hindered by the lack of large-scale training data, we propose a\nmethod for open-ended synthesis of new Dafny programs in a flexible pipeline\nwhere LLMs formulate high-level ideas, implement them, and incrementally\npropose changes to existing programs, which Dafny validates. This gives us a\nsynthetic dataset, DafnySynth, which we use to augment DafnyBench for training.\nFine-tuning on both datasets boosts LLaMa 8B's success rate to 50.6% --\nsignificantly better than the base model, or training on either dataset alone.\nOur results suggest a path towards capable AI assistants for languages that\ndon't yet have large-scale human-generated examples. In turn, such assistants\nmight reduce friction for users and ultimately drive adoption.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15143v1",
    "published_date": "2024-11-05 19:27:56 UTC",
    "updated_date": "2024-11-05 19:27:56 UTC"
  },
  {
    "arxiv_id": "2411.03455v2",
    "title": "Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents",
    "authors": [
      "Benjamin Rombaut",
      "Sogol Masoumzadeh",
      "Kirill Vasilevski",
      "Dayi Lin",
      "Ahmed E. Hassan"
    ],
    "abstract": "As foundation models (FMs) play an increasingly prominent role in complex\nsoftware systems, such as agentic software, they introduce significant\nobservability and debuggability challenges. Although recent Large Reasoning\nModels (LRMs) generate their thought processes as part of the output, in many\nscenarios fast-thinking Large Language Models (LLMs) are still preferred due to\nlatency constraints. LLM-powered agents operate autonomously with opaque\nimplicit reasoning, making it difficult to debug their unexpected behaviors or\nerrors. In this paper, we introduce Watson, a novel framework that provides\nreasoning observability into the implicit reasoning processes of agents driven\nby fast-thinking LLMs, allowing the identification and localization of errors\nand guidance for corrections. We demonstrate the accuracy of the recovered\nimplicit reasoning trace by Watson and its usefulness through debugging and\nimproving the performance of LLM-powered agents in two scenarios: Massive\nMultitask Language Understanding (MMLU) benchmark and SWE-bench-lite. Using\nWatson, we were able to observe and identify the implicit reasoning errors, and\nautomatically provide targeted corrections at runtime that improve the Pass@1\nof agents on MMLU and SWE-bench-lite by 7.58 (13.45% relative improvement) and\n7.76 (12.31% relative improvement) percentage points, respectively, without\nupdates to models or the cognitive architecture of the agents.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03455v2",
    "published_date": "2024-11-05 19:13:22 UTC",
    "updated_date": "2025-03-06 02:55:37 UTC"
  },
  {
    "arxiv_id": "2411.03449v1",
    "title": "AI Horizon Scanning -- White Paper p3395, IEEE-SA. Part III: Technology Watch: a selection of key developments, emerging technologies, and industry trends in Artificial Intelligence",
    "authors": [
      "George Tambouratzis",
      "Marina Cortês",
      "Andrew R. Liddle"
    ],
    "abstract": "Generative Artificial Intelligence (AI) technologies are in a phase of\nunprecedented rapid development following the landmark release of Chat-GPT,\nwhich brought the phenomenon to wide public attention. As the deployment of AI\nproducts rises geometrically, considerable attention is being given to the\nthreats and opportunities that AI technologies offer, and to the need for\nregulatory and standards initiatives to ensure that use of the technology\naligns with societal needs and generates broad benefits while mitigating risks\nand threats. This manuscript is the third of a series of White Papers informing\nthe development of IEEE-SA's p3995 {\\it `Standard for the Implementation of\nSafeguards, Controls, and Preventive Techniques for Artificial Intelligence\nModels'} \\cite{P3395}, Chair Marina Cort\\^{e}s. This part focuses on assessing\ncalmly and objectively, as far as is possible, the current state of Artificial\nIntelligence (AI) technology development and identifying predominant trends,\nprospects, and ensuing risks. It necessarily forms a snapshot of the current\ninstant of a rapidly-evolving landscape, with new products and innovations\nemerging continuously. While our main focus is on software and hardware\ndevelopments and their corporate context, we also briefly review progress on\nrobotics within the AI context and describe some implications of the\nsubstantial and growing AI energy demand.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "This is an interim version of our p3395 WG White Paper, Part III. We\n  will update this version, until publication by IEEE-SA, Sponsor Committee -\n  Artificial Intelligence Standards Committee (C/AISC);\n  https://standards.ieee.org/ieee/3395/11378/ This White Paper is companion to\n  Part I available at arXiv:2410.01808",
    "pdf_url": "http://arxiv.org/pdf/2411.03449v1",
    "published_date": "2024-11-05 19:04:42 UTC",
    "updated_date": "2024-11-05 19:04:42 UTC"
  },
  {
    "arxiv_id": "2411.03445v1",
    "title": "Solving Trojan Detection Competitions with Linear Weight Classification",
    "authors": [
      "Todd Huster",
      "Peter Lin",
      "Razvan Stefanescu",
      "Emmanuel Ekwedike",
      "Ritu Chadha"
    ],
    "abstract": "Neural networks can conceal malicious Trojan backdoors that allow a trigger\nto covertly change the model behavior. Detecting signs of these backdoors,\nparticularly without access to any triggered data, is the subject of ongoing\nresearch and open challenges. In one common formulation of the problem, we are\ngiven a set of clean and poisoned models and need to predict whether a given\ntest model is clean or poisoned. In this paper, we introduce a detector that\nworks remarkably well across many of the existing datasets and domains. It is\nobtained by training a binary classifier on a large number of models' weights\nafter performing a few different pre-processing steps including feature\nselection and standardization, reference model weights subtraction, and model\nalignment prior to detection. We evaluate this algorithm on a diverse set of\nTrojan detection benchmarks and domains and examine the cases where the\napproach is most and least effective.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 4 Figures",
    "pdf_url": "http://arxiv.org/pdf/2411.03445v1",
    "published_date": "2024-11-05 19:00:34 UTC",
    "updated_date": "2024-11-05 19:00:34 UTC"
  },
  {
    "arxiv_id": "2411.03312v2",
    "title": "Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters",
    "authors": [
      "Kevin Y. Li",
      "Sachin Goyal",
      "Joao D. Semedo",
      "J. Zico Kolter"
    ],
    "abstract": "Vision Language Models (VLMs) have demonstrated strong capabilities across\nvarious visual understanding and reasoning tasks, driven by incorporating image\nrepresentations into the token inputs of Large Language Models (LLMs). However,\ntheir real-world deployment is often constrained by high latency during\ninference due to the substantial compute required by the LLM to process the\nlarge number of input tokens, predominantly arising from the image. To reduce\ninference costs, one can either downsize the LLM or reduce the number of input\ntokens needed to represent the image, the latter of which has been the focus of\nmany recent efforts around token compression. However, it is unclear what the\noptimal trade-off is given a fixed inference budget. We first characterize this\noptimal trade-off between the number of visual tokens and LLM parameters by\nestablishing scaling laws that capture variations in performance with these two\nfactors. Our results reveal a surprising trend: for visual reasoning tasks, the\ninference-optimal behavior in VLMs is achieved by using the largest LLM that\nfits within the inference budget while minimizing visual token count - often to\na single token. While the token reduction literature has mainly focused on\nmaintaining base model performance by modestly reducing the token count (e.g.,\n$5-10\\times$), our results indicate that the compute-optimal inference regime\nrequires operating under even higher token compression ratios. Based on these\ninsights, we take the first steps toward designing token compression algorithms\ntailored for high-compression settings, utilizing prompt-based compression of\ntokens. Our work underscores the performance and efficiency benefits of\noperating in low visual token regimes and the importance of developing tailored\ntoken reduction algorithms for such conditions. Code is available at\nhttps://github.com/locuslab/llava-token-compression.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.03312v2",
    "published_date": "2024-11-05 18:54:21 UTC",
    "updated_date": "2025-04-21 09:34:59 UTC"
  },
  {
    "arxiv_id": "2411.03409v1",
    "title": "STEER: Flexible Robotic Manipulation via Dense Language Grounding",
    "authors": [
      "Laura Smith",
      "Alex Irpan",
      "Montserrat Gonzalez Arenas",
      "Sean Kirmani",
      "Dmitry Kalashnikov",
      "Dhruv Shah",
      "Ted Xiao"
    ],
    "abstract": "The complexity of the real world demands robotic systems that can\nintelligently adapt to unseen situations. We present STEER, a robot learning\nframework that bridges high-level, commonsense reasoning with precise, flexible\nlow-level control. Our approach translates complex situational awareness into\nactionable low-level behavior through training language-grounded policies with\ndense annotation. By structuring policy training around fundamental, modular\nmanipulation skills expressed in natural language, STEER exposes an expressive\ninterface for humans or Vision-Language Models (VLMs) to intelligently\norchestrate the robot's behavior by reasoning about the task and context. Our\nexperiments demonstrate the skills learned via STEER can be combined to\nsynthesize novel behaviors to adapt to new situations or perform completely new\ntasks without additional data collection or training.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: https://lauramsmith.github.io/steer/",
    "pdf_url": "http://arxiv.org/pdf/2411.03409v1",
    "published_date": "2024-11-05 18:48:12 UTC",
    "updated_date": "2024-11-05 18:48:12 UTC"
  },
  {
    "arxiv_id": "2411.03389v3",
    "title": "Neurons for Neutrons: A Transformer Model for Computation Load Estimation on Domain-Decomposed Neutron Transport Problems",
    "authors": [
      "Alexander Mote",
      "Todd Palmer",
      "Lizhong Chen"
    ],
    "abstract": "Domain decomposition is a technique used to reduce memory overhead on large\nneutron transport problems. Currently, the optimal load-balanced processor\nallocation for these domains is typically determined through small-scale\nsimulations of the problem, which can be time-consuming for researchers and\nmust be repeated anytime a problem input is changed. We propose a Transformer\nmodel with a unique 3D input embedding, and input representations designed for\ndomain-decomposed neutron transport problems, which can predict the subdomain\ncomputation loads generated by small-scale simulations. We demonstrate that\nsuch a model trained on domain-decomposed Small Modular Reactor (SMR)\nsimulations achieves 98.2% accuracy while being able to skip the small-scale\nsimulation step entirely. Tests of the model's robustness on variant fuel\nassemblies, other problem geometries, and changes in simulation parameters are\nalso discussed.",
    "categories": [
      "physics.comp-ph",
      "cs.AI"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "25 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.03389v3",
    "published_date": "2024-11-05 18:17:51 UTC",
    "updated_date": "2025-03-31 21:36:30 UTC"
  },
  {
    "arxiv_id": "2411.05828v1",
    "title": "AI Multi-Agent Interoperability Extension for Managing Multiparty Conversations",
    "authors": [
      "Diego Gosmar",
      "Deborah A. Dahl",
      "Emmett Coin",
      "David Attwater"
    ],
    "abstract": "This paper presents a novel extension to the existing Multi-Agent\nInteroperability specifications of the Open Voice Interoperability Initiative\n(originally also known as OVON from the Open Voice Network). This extension\nenables AI agents developed with different technologies to communicate using a\nuniversal, natural language-based API or NLP-based standard APIs. Focusing on\nthe management of multiparty AI conversations, this work introduces new\nconcepts such as the Convener Agent, Floor-Shared Conversational Space, Floor\nManager, Multi-Conversant Support, and mechanisms for handling Interruptions\nand Uninvited Agents. Additionally, it explores the Convener's role as a\nmessage relay and controller of participant interactions, enhancing both\nscalability and security. These advancements are crucial for ensuring smooth,\nefficient, and secure interactions in scenarios where multiple AI agents need\nto collaborate, debate, or contribute to a discussion. The paper elaborates on\nthese concepts and provides practical examples, illustrating their\nimplementation within the conversation envelope structure.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.05828v1",
    "published_date": "2024-11-05 18:11:55 UTC",
    "updated_date": "2024-11-05 18:11:55 UTC"
  },
  {
    "arxiv_id": "2411.03300v1",
    "title": "VERITAS: A Unified Approach to Reliability Evaluation",
    "authors": [
      "Rajkumar Ramamurthy",
      "Meghana Arakkal Rajeev",
      "Oliver Molenschot",
      "James Zou",
      "Nazneen Rajani"
    ],
    "abstract": "Large language models (LLMs) often fail to synthesize information from their\ncontext to generate an accurate response. This renders them unreliable in\nknowledge intensive settings where reliability of the output is key. A critical\ncomponent for reliable LLMs is the integration of a robust fact-checking system\nthat can detect hallucinations across various formats. While several\nopen-access fact-checking models are available, their functionality is often\nlimited to specific tasks, such as grounded question-answering or entailment\nverification, and they perform less effectively in conversational settings. On\nthe other hand, closed-access models like GPT-4 and Claude offer greater\nflexibility across different contexts, including grounded dialogue\nverification, but are hindered by high costs and latency. In this work, we\nintroduce VERITAS, a family of hallucination detection models designed to\noperate flexibly across diverse contexts while minimizing latency and costs.\nVERITAS achieves state-of-the-art results considering average performance on\nall major hallucination detection benchmarks, with $10\\%$ increase in average\nperformance when compared to similar-sized models and get close to the\nperformance of GPT4 turbo with LLM-as-a-judge setting.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03300v1",
    "published_date": "2024-11-05 17:53:25 UTC",
    "updated_date": "2024-11-05 17:53:25 UTC"
  },
  {
    "arxiv_id": "2411.03294v3",
    "title": "Out-of-Distribution Recovery with Object-Centric Keypoint Inverse Policy for Visuomotor Imitation Learning",
    "authors": [
      "George Jiayuan Gao",
      "Tianyu Li",
      "Nadia Figueroa"
    ],
    "abstract": "We propose an object-centric recovery (OCR) framework to address the\nchallenges of out-of-distribution (OOD) scenarios in visuomotor policy\nlearning. Previous behavior cloning (BC) methods rely heavily on a large amount\nof labeled data coverage, failing in unfamiliar spatial states. Without relying\non extra data collection, our approach learns a recovery policy constructed by\nan inverse policy inferred from the object keypoint manifold gradient in the\noriginal training data. The recovery policy serves as a simple add-on to any\nbase visuomotor BC policy, agnostic to a specific method, guiding the system\nback towards the training distribution to ensure task success even in OOD\nsituations. We demonstrate the effectiveness of our object-centric framework in\nboth simulation and real robot experiments, achieving an improvement of 77.7\\%\nover the base policy in OOD. Furthermore, we show OCR's capacity to\nautonomously collect demonstrations for continual learning. Overall, we believe\nthis framework represents a step toward improving the robustness of visuomotor\npolicies in real-world settings. Project Website:\nhttps://sites.google.com/view/ocr-penn",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03294v3",
    "published_date": "2024-11-05 17:41:14 UTC",
    "updated_date": "2025-03-20 18:03:15 UTC"
  },
  {
    "arxiv_id": "2411.03292v2",
    "title": "Interaction2Code: Benchmarking MLLM-based Interactive Webpage Code Generation from Interactive Prototyping",
    "authors": [
      "Jingyu Xiao",
      "Yuxuan Wan",
      "Yintong Huo",
      "Zixin Wang",
      "Xinyi Xu",
      "Wenxuan Wang",
      "Zhiyao Xu",
      "Yuhang Wang",
      "Michael R. Lyu"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\nperformance on the design-to-code task, i.e., generating UI code from UI\nmock-ups. However, existing benchmarks only contain static web pages for\nevaluation and ignore the dynamic interaction, limiting the practicality,\nusability and user engagement of the generated webpages.\n  To bridge these gaps, we present the first systematic investigation of MLLMs\nin generating interactive webpages. Specifically, we formulate the\nInteraction-to-Code task and establish the Interaction2Code benchmark,\nencompassing 127 unique webpages and 374 distinct interactions across 15\nwebpage types and 31 interaction categories. Through comprehensive experiments\nutilizing state-of-the-art (SOTA) MLLMs, evaluated via both automatic metrics\nand human assessments, we identify four critical limitations of MLLM on\nInteraction-to-Code task: (1) inadequate generation of interaction compared\nwith full page, (2) prone to ten types of failure, (3) poor performance on\nvisually subtle interactions, and (4) insufficient undestanding on interaction\nwhen limited to single-modality visual descriptions. To address these\nlimitations, we propose four enhancement strategies: Interactive Element\nHighlighting, Failureaware Prompting (FAP), Visual Saliency Enhancement, and\nVisual-Textual Descriptions Combination, all aiming at improving MLLMs'\nperformance on the Interaction-toCode task. The Interaction2Code benchmark and\ncode are available in https://github. com/WebPAI/Interaction2Code.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "21 pages,14 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.03292v2",
    "published_date": "2024-11-05 17:40:03 UTC",
    "updated_date": "2025-02-20 06:59:43 UTC"
  },
  {
    "arxiv_id": "2411.03287v1",
    "title": "The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare",
    "authors": [
      "Souren Pashangpour",
      "Goldie Nejat"
    ],
    "abstract": "The potential use of large language models (LLMs) in healthcare robotics can\nhelp address the significant demand put on healthcare systems around the world\nwith respect to an aging demographic and a shortage of healthcare\nprofessionals. Even though LLMs have already been integrated into medicine to\nassist both clinicians and patients, the integration of LLMs within healthcare\nrobots has not yet been explored for clinical settings. In this perspective\npaper, we investigate the groundbreaking developments in robotics and LLMs to\nuniquely identify the needed system requirements for designing health specific\nLLM based robots in terms of multi modal communication through human robot\ninteractions (HRIs), semantic reasoning, and task planning. Furthermore, we\ndiscuss the ethical issues, open challenges, and potential future research\ndirections for this emerging innovative field.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.ET",
      "cs.HC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03287v1",
    "published_date": "2024-11-05 17:36:32 UTC",
    "updated_date": "2024-11-05 17:36:32 UTC"
  },
  {
    "arxiv_id": "2411.03284v1",
    "title": "SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents",
    "authors": [
      "Dawei Li",
      "Zhen Tan",
      "Peijia Qian",
      "Yifan Li",
      "Kumar Satvik Chaudhary",
      "Lijie Hu",
      "Jiayi Shen"
    ],
    "abstract": "While multi-agent systems have been shown to significantly enhance the\nperformance of Large Language Models (LLMs) across various tasks and\napplications, the dense interaction between scaling agents potentially hampers\ntheir efficiency and diversity. To address these challenges, we draw\ninspiration from the sparse mixture-of-agents (SMoE) and propose a sparse\nmixture-of-agents (SMoA) framework to improve the efficiency and diversity of\nmulti-agent LLMs. Unlike completely connected structures, SMoA introduces novel\nResponse Selection and Early Stopping mechanisms to sparsify information flows\namong individual LLM agents, striking a balance between performance and\nefficiency. Additionally, inspired by the expert diversity principle in SMoE\nframeworks for workload balance between experts, we assign distinct role\ndescriptions to each LLM agent, fostering diverse and divergent thinking.\nExtensive experiments on reasoning, alignment, and fairness benchmarks\ndemonstrate that SMoA achieves performance comparable to traditional\nmixture-of-agents approaches but with significantly lower computational costs.\nFurther analysis reveals that SMoA is more stable, has a greater capacity to\nscale, and offers considerable potential through hyper-parameter optimization.\nCode and data will be available at: https://github.com/David-Li0406/SMoA.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2411.03284v1",
    "published_date": "2024-11-05 17:33:39 UTC",
    "updated_date": "2024-11-05 17:33:39 UTC"
  },
  {
    "arxiv_id": "2411.03275v1",
    "title": "Causal Responsibility Attribution for Human-AI Collaboration",
    "authors": [
      "Yahang Qi",
      "Bernhard Schölkopf",
      "Zhijing Jin"
    ],
    "abstract": "As Artificial Intelligence (AI) systems increasingly influence\ndecision-making across various fields, the need to attribute responsibility for\nundesirable outcomes has become essential, though complicated by the complex\ninterplay between humans and AI. Existing attribution methods based on actual\ncausality and Shapley values tend to disproportionately blame agents who\ncontribute more to an outcome and rely on real-world measures of\nblameworthiness that may misalign with responsible AI standards. This paper\npresents a causal framework using Structural Causal Models (SCMs) to\nsystematically attribute responsibility in human-AI systems, measuring overall\nblameworthiness while employing counterfactual reasoning to account for agents'\nexpected epistemic levels. Two case studies illustrate the framework's\nadaptability in diverse human-AI collaboration scenarios.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03275v1",
    "published_date": "2024-11-05 17:17:45 UTC",
    "updated_date": "2024-11-05 17:17:45 UTC"
  },
  {
    "arxiv_id": "2411.14441v1",
    "title": "GeMID: Generalizable Models for IoT Device Identification",
    "authors": [
      "Kahraman Kostas",
      "Rabia Yasa Kostas",
      "Mike Just",
      "Michael A. Lones"
    ],
    "abstract": "With the proliferation of Internet of Things (IoT) devices, ensuring their\nsecurity has become paramount. Device identification (DI), which distinguishes\nIoT devices based on their traffic patterns, plays a crucial role in both\ndifferentiating devices and identifying vulnerable ones, closing a serious\nsecurity gap. However, existing approaches to DI that build machine learning\nmodels often overlook the challenge of model generalizability across diverse\nnetwork environments. In this study, we propose a novel framework to address\nthis limitation and evaluate the generalizability of DI models across datasets\ncollected within different network environments. Our approach involves a\ntwo-step process: first, we develop a feature and model selection method that\nis more robust to generalization issues by using a genetic algorithm with\nexternal feedback and datasets from distinct environments to refine the\nselections. Second, the resulting DI models are then tested on further\nindependent datasets in order to robustly assess their generalizability. We\ndemonstrate the effectiveness of our method by empirically comparing it to\nalternatives, highlighting how fundamental limitations of commonly employed\ntechniques such as sliding window and flow statistics limit their\ngeneralizability. Our findings advance research in IoT security and device\nidentification, offering insights into improving model effectiveness and\nmitigating risks in IoT networks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages main (9 figures, 2 tables), 19 pages Supplementary Material,\n  27 pages total",
    "pdf_url": "http://arxiv.org/pdf/2411.14441v1",
    "published_date": "2024-11-05 17:09:43 UTC",
    "updated_date": "2024-11-05 17:09:43 UTC"
  },
  {
    "arxiv_id": "2411.03376v1",
    "title": "An Open API Architecture to Discover the Trustworthy Explanation of Cloud AI Services",
    "authors": [
      "Zerui Wang",
      "Yan Liu",
      "Jun Huang"
    ],
    "abstract": "This article presents the design of an open-API-based explainable AI (XAI)\nservice to provide feature contribution explanations for cloud AI services.\nCloud AI services are widely used to develop domain-specific applications with\nprecise learning metrics. However, the underlying cloud AI services remain\nopaque on how the model produces the prediction. We argue that XAI operations\nare accessible as open APIs to enable the consolidation of the XAI operations\ninto the cloud AI services assessment. We propose a design using a microservice\narchitecture that offers feature contribution explanations for cloud AI\nservices without unfolding the network structure of the cloud models. We can\nalso utilize this architecture to evaluate the model performance and XAI\nconsistency metrics showing cloud AI services trustworthiness. We collect\nprovenance data from operational pipelines to enable reproducibility within the\nXAI service. Furthermore, we present the discovery scenarios for the\nexperimental tests regarding model performance and XAI consistency metrics for\nthe leading cloud vision AI services. The results confirm that the\narchitecture, based on open APIs, is cloud-agnostic. Additionally, data\naugmentations result in measurable improvements in XAI consistency metrics for\ncloud AI services.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "Published in: IEEE Transactions on Cloud Computing ( Volume: 12,\n  Issue: 2, April-June 2024)",
    "pdf_url": "http://arxiv.org/pdf/2411.03376v1",
    "published_date": "2024-11-05 16:52:22 UTC",
    "updated_date": "2024-11-05 16:52:22 UTC"
  },
  {
    "arxiv_id": "2411.03253v1",
    "title": "Discovering Data Structures: Nearest Neighbor Search and Beyond",
    "authors": [
      "Omar Salemohamed",
      "Laurent Charlin",
      "Shivam Garg",
      "Vatsal Sharan",
      "Gregory Valiant"
    ],
    "abstract": "We propose a general framework for end-to-end learning of data structures.\nOur framework adapts to the underlying data distribution and provides\nfine-grained control over query and space complexity. Crucially, the data\nstructure is learned from scratch, and does not require careful initialization\nor seeding with candidate data structures/algorithms. We first apply this\nframework to the problem of nearest neighbor search. In several settings, we\nare able to reverse-engineer the learned data structures and query algorithms.\nFor 1D nearest neighbor search, the model discovers optimal distribution\n(in)dependent algorithms such as binary search and variants of interpolation\nsearch. In higher dimensions, the model learns solutions that resemble k-d\ntrees in some regimes, while in others, they have elements of\nlocality-sensitive hashing. The model can also learn useful representations of\nhigh-dimensional data and exploit them to design effective data structures. We\nalso adapt our framework to the problem of estimating frequencies over a data\nstream, and believe it could also be a powerful discovery tool for new\nproblems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03253v1",
    "published_date": "2024-11-05 16:50:54 UTC",
    "updated_date": "2024-11-05 16:50:54 UTC"
  },
  {
    "arxiv_id": "2411.03252v1",
    "title": "Spontaneous Emergence of Agent Individuality through Social Interactions in LLM-Based Communities",
    "authors": [
      "Ryosuke Takata",
      "Atsushi Masumori",
      "Takashi Ikegami"
    ],
    "abstract": "We study the emergence of agency from scratch by using Large Language Model\n(LLM)-based agents. In previous studies of LLM-based agents, each agent's\ncharacteristics, including personality and memory, have traditionally been\npredefined. We focused on how individuality, such as behavior, personality, and\nmemory, can be differentiated from an undifferentiated state. The present LLM\nagents engage in cooperative communication within a group simulation,\nexchanging context-based messages in natural language. By analyzing this\nmulti-agent simulation, we report valuable new insights into how social norms,\ncooperation, and personality traits can emerge spontaneously. This paper\ndemonstrates that autonomously interacting LLM-powered agents generate\nhallucinations and hashtags to sustain communication, which, in turn, increases\nthe diversity of words within their interactions. Each agent's emotions shift\nthrough communication, and as they form communities, the personalities of the\nagents emerge and evolve accordingly. This computational modeling approach and\nits findings will provide a new method for analyzing collective artificial\nintelligence.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03252v1",
    "published_date": "2024-11-05 16:49:33 UTC",
    "updated_date": "2024-11-05 16:49:33 UTC"
  },
  {
    "arxiv_id": "2411.03250v1",
    "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models",
    "authors": [
      "Ying Zhou",
      "Xinyao Wang",
      "Yulei Niu",
      "Yaojie Shen",
      "Lexin Tang",
      "Fan Chen",
      "Ben He",
      "Le Sun",
      "Longyin Wen"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced their knowledge and generative capabilities, leading to a surge of\ninterest in leveraging LLMs for high-quality data synthesis. However, synthetic\ndata generation via prompting LLMs remains challenging due to LLMs' limited\nunderstanding of target data distributions and the complexity of prompt\nengineering, especially for structured formatted data. To address these issues,\nwe introduce DiffLM, a controllable data synthesis framework based on\nvariational autoencoder (VAE), which further (1) leverages diffusion models to\nreserve more information of original distribution and format structure in the\nlearned latent distribution and (2) decouples the learning of target\ndistribution knowledge from the LLM's generative objectives via a plug-and-play\nlatent feature injection module. As we observed significant discrepancies\nbetween the VAE's latent representations and the real data distribution, the\nlatent diffusion module is introduced into our framework to learn a fully\nexpressive latent distribution. Evaluations on seven real-world datasets with\nstructured formatted data (i.e., Tabular, Code and Tool data) demonstrate that\nDiffLM generates high-quality data, with performance on downstream tasks\nsurpassing that of real data by 2-7 percent in certain cases. The data and code\nwill be publicly available upon completion of internal review.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.03250v1",
    "published_date": "2024-11-05 16:47:53 UTC",
    "updated_date": "2024-11-05 16:47:53 UTC"
  },
  {
    "arxiv_id": "2411.03237v1",
    "title": "On the Detection of Non-Cooperative RISs: Scan B-Testing via Deep Support Vector Data Description",
    "authors": [
      "George Stamatelis",
      "Panagiotis Gavriilidis",
      "Aymen Fakhreddine",
      "George C. Alexandropoulos"
    ],
    "abstract": "In this paper, we study the problem of promptly detecting the presence of\nnon-cooperative activity from one or more Reconfigurable Intelligent Surfaces\n(RISs) with unknown characteristics lying in the vicinity of a Multiple-Input\nMultiple-Output (MIMO) communication system using Orthogonal Frequency-Division\nMultiplexing (OFDM) transmissions. We first present a novel wideband channel\nmodel incorporating RISs as well as non-reconfigurable stationary surfaces,\nwhich captures both the effect of the RIS actuation time on the channel in the\nfrequency domain as well as the difference between changing phase\nconfigurations during or among transmissions. Considering that RISs may operate\nunder the coordination of a third-party system, and thus, may negatively impact\nthe communication of the intended MIMO OFDM system, we present a novel RIS\nactivity detection framework that is unaware of the distribution of the phase\nconfiguration of any of the non-cooperative RISs. In particular, capitalizing\non the knowledge of the data distribution at the multi-antenna receiver, we\ndesign a novel online change point detection statistic that combines a deep\nsupport vector data description model with the scan $B$-test. The presented\nnumerical investigations demonstrate the improved detection accuracy as well as\ndecreased computational complexity of the proposed RIS detection approach over\nexisting change point detection schemes.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "6 pages, 4 figures, submitted to an IEEE conference",
    "pdf_url": "http://arxiv.org/pdf/2411.03237v1",
    "published_date": "2024-11-05 16:36:51 UTC",
    "updated_date": "2024-11-05 16:36:51 UTC"
  },
  {
    "arxiv_id": "2411.03231v2",
    "title": "Formal Logic-guided Robust Federated Learning against Poisoning Attacks",
    "authors": [
      "Dung Thuy Nguyen",
      "Ziyan An",
      "Taylor T. Johnson",
      "Meiyi Ma",
      "Kevin Leach"
    ],
    "abstract": "Federated Learning (FL) offers a promising solution to the privacy concerns\nassociated with centralized Machine Learning (ML) by enabling decentralized,\ncollaborative learning. However, FL is vulnerable to various security threats,\nincluding poisoning attacks, where adversarial clients manipulate the training\ndata or model updates to degrade overall model performance. Recognizing this\nthreat, researchers have focused on developing defense mechanisms to counteract\npoisoning attacks in FL systems. However, existing robust FL methods\npredominantly focus on computer vision tasks, leaving a gap in addressing the\nunique challenges of FL with time series data. In this paper, we present\nFLORAL, a defense mechanism designed to mitigate poisoning attacks in federated\nlearning for time-series tasks, even in scenarios with heterogeneous client\ndata and a large number of adversarial participants. Unlike traditional\nmodel-centric defenses, FLORAL leverages logical reasoning to evaluate client\ntrustworthiness by aligning their predictions with global time-series patterns,\nrather than relying solely on the similarity of client updates. Our approach\nextracts logical reasoning properties from clients, then hierarchically infers\nglobal properties, and uses these to verify client updates. Through formal\nlogic verification, we assess the robustness of each client contribution,\nidentifying deviations indicative of adversarial behavior. Experimental results\non two datasets demonstrate the superior performance of our approach compared\nto existing baseline methods, highlighting its potential to enhance the\nrobustness of FL to time series applications. Notably, FLORAL reduced the\nprediction error by 93.27% in the best-case scenario compared to the\nsecond-best baseline. Our code is available at\nhttps://anonymous.4open.science/r/FLORAL-Robust-FTS.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.LO"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages, 4 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.03231v2",
    "published_date": "2024-11-05 16:23:19 UTC",
    "updated_date": "2024-11-06 02:56:57 UTC"
  },
  {
    "arxiv_id": "2411.03225v2",
    "title": "Knowledge Graphs of Driving Scenes to Empower the Emerging Capabilities of Neurosymbolic AI",
    "authors": [
      "Ruwan Wickramarachchi",
      "Cory Henson",
      "Amit Sheth"
    ],
    "abstract": "In the era of Generative AI, Neurosymbolic AI is emerging as a powerful\napproach for tasks spanning from perception to cognition. The use of\nNeurosymbolic AI has been shown to achieve enhanced capabilities, including\nimproved grounding, alignment, explainability, and reliability. However, due to\nits nascent stage, there is a lack of widely available real-world benchmark\ndatasets tailored to Neurosymbolic AI tasks. To address this gap and support\nthe evaluation of current and future methods, we introduce DSceneKG -- a suite\nof knowledge graphs of driving scenes built from real-world, high-quality\nscenes from multiple open autonomous driving datasets. In this article, we\ndetail the construction process of DSceneKG and highlight its application in\nseven different tasks. DSceneKG is publicly accessible at:\nhttps://github.com/ruwantw/DSceneKG",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.03225v2",
    "published_date": "2024-11-05 16:15:33 UTC",
    "updated_date": "2024-11-07 15:41:20 UTC"
  },
  {
    "arxiv_id": "2411.03223v2",
    "title": "Beyond Grid Data: Exploring Graph Neural Networks for Earth Observation",
    "authors": [
      "Shan Zhao",
      "Zhaiyu Chen",
      "Zhitong Xiong",
      "Yilei Shi",
      "Sudipan Saha",
      "Xiao Xiang Zhu"
    ],
    "abstract": "Earth Observation (EO) data analysis has been significantly revolutionized by\ndeep learning (DL), with applications typically limited to grid-like data\nstructures. Graph Neural Networks (GNNs) emerge as an important innovation,\npropelling DL into the non-Euclidean domain. Naturally, GNNs can effectively\ntackle the challenges posed by diverse modalities, multiple sensors, and the\nheterogeneous nature of EO data. To introduce GNNs in the related domains, our\nreview begins by offering fundamental knowledge on GNNs. Then, we summarize the\ngeneric problems in EO, to which GNNs can offer potential solutions. Following\nthis, we explore a broad spectrum of GNNs' applications to scientific problems\nin Earth systems, covering areas such as weather and climate analysis, disaster\nmanagement, air quality monitoring, agriculture, land cover classification,\nhydrological process modeling, and urban modeling. The rationale behind\nadopting GNNs in these fields is explained, alongside methodologies for\norganizing graphs and designing favorable architectures for various tasks.\nFurthermore, we highlight methodological challenges of implementing GNNs in\nthese domains and possible solutions that could guide future research. While\nacknowledging that GNNs are not a universal solution, we conclude the paper by\ncomparing them with other popular architectures like transformers and analyzing\ntheir potential synergies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication in Geoscience and Remote Sensing Magazine\n  (GRSM)",
    "pdf_url": "http://arxiv.org/pdf/2411.03223v2",
    "published_date": "2024-11-05 16:12:12 UTC",
    "updated_date": "2024-11-06 09:10:46 UTC"
  },
  {
    "arxiv_id": "2411.03205v4",
    "title": "GIS Copilot: Towards an Autonomous GIS Agent for Spatial Analysis",
    "authors": [
      "Temitope Akinboyewa",
      "Zhenlong Li",
      "Huan Ning",
      "M. Naser Lessani"
    ],
    "abstract": "Recent advancements in Generative AI offer promising capabilities for spatial\nanalysis. Despite their potential, the integration of generative AI with\nestablished GIS platforms remains underexplored. In this study, we propose a\nframework for integrating LLMs directly into existing GIS platforms, using QGIS\nas an example. Our approach leverages the reasoning and programming\ncapabilities of LLMs to autonomously generate spatial analysis workflows and\ncode through an informed agent that has comprehensive documentation of key GIS\ntools and parameters. The implementation of this framework resulted in the\ndevelopment of a \"GIS Copilot\" that allows GIS users to interact with QGIS\nusing natural language commands for spatial analysis. The GIS Copilot was\nevaluated with over 100 spatial analysis tasks with three complexity levels:\nbasic tasks that require one GIS tool and typically involve one data layer to\nperform simple operations; intermediate tasks involving multi-step processes\nwith multiple tools, guided by user instructions; and advanced tasks which\ninvolve multi-step processes that require multiple tools but not guided by user\ninstructions, necessitating the agent to independently decide on and executes\nthe necessary steps. The evaluation reveals that the GIS Copilot demonstrates\nstrong potential in automating foundational GIS operations, with a high success\nrate in tool selection and code generation for basic and intermediate tasks,\nwhile challenges remain in achieving full autonomy for more complex tasks. This\nstudy contributes to the emerging vision of Autonomous GIS, providing a pathway\nfor non-experts to engage with geospatial analysis with minimal prior\nexpertise. While full autonomy is yet to be achieved, the GIS Copilot\ndemonstrates significant potential for simplifying GIS workflows and enhancing\ndecision-making processes.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.HC",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03205v4",
    "published_date": "2024-11-05 15:53:59 UTC",
    "updated_date": "2024-11-22 02:00:21 UTC"
  },
  {
    "arxiv_id": "2412.05282v2",
    "title": "International Scientific Report on the Safety of Advanced AI (Interim Report)",
    "authors": [
      "Yoshua Bengio",
      "Sören Mindermann",
      "Daniel Privitera",
      "Tamay Besiroglu",
      "Rishi Bommasani",
      "Stephen Casper",
      "Yejin Choi",
      "Danielle Goldfarb",
      "Hoda Heidari",
      "Leila Khalatbari",
      "Shayne Longpre",
      "Vasilios Mavroudis",
      "Mantas Mazeika",
      "Kwan Yee Ng",
      "Chinasa T. Okolo",
      "Deborah Raji",
      "Theodora Skeadas",
      "Florian Tramèr",
      "Bayo Adekanmbi",
      "Paul Christiano",
      "David Dalrymple",
      "Thomas G. Dietterich",
      "Edward Felten",
      "Pascale Fung",
      "Pierre-Olivier Gourinchas",
      "Nick Jennings",
      "Andreas Krause",
      "Percy Liang",
      "Teresa Ludermir",
      "Vidushi Marda",
      "Helen Margetts",
      "John A. McDermid",
      "Arvind Narayanan",
      "Alondra Nelson",
      "Alice Oh",
      "Gopal Ramchurn",
      "Stuart Russell",
      "Marietje Schaake",
      "Dawn Song",
      "Alvaro Soto",
      "Lee Tiedrich",
      "Gaël Varoquaux",
      "Andrew Yao",
      "Ya-Qin Zhang"
    ],
    "abstract": "This is the interim publication of the first International Scientific Report\non the Safety of Advanced AI. The report synthesises the scientific\nunderstanding of general-purpose AI -- AI that can perform a wide variety of\ntasks -- with a focus on understanding and managing its risks. A diverse group\nof 75 AI experts contributed to this report, including an international Expert\nAdvisory Panel nominated by 30 countries, the EU, and the UN. Led by the Chair,\nthese independent experts collectively had full discretion over the report's\ncontent.\n  The final report is available at arXiv:2501.17805",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Available under the open government license at\n  https://www.gov.uk/government/publications/international-scientific-report-on-the-safety-of-advanced-ai",
    "pdf_url": "http://arxiv.org/pdf/2412.05282v2",
    "published_date": "2024-11-05 15:47:23 UTC",
    "updated_date": "2025-04-09 11:34:12 UTC"
  },
  {
    "arxiv_id": "2411.03177v2",
    "title": "On Improved Conditioning Mechanisms and Pre-training Strategies for Diffusion Models",
    "authors": [
      "Tariq Berrada Ifriqi",
      "Pietro Astolfi",
      "Melissa Hall",
      "Reyhane Askari-Hemmat",
      "Yohann Benchetrit",
      "Marton Havasi",
      "Matthew Muckley",
      "Karteek Alahari",
      "Adriana Romero-Soriano",
      "Jakob Verbeek",
      "Michal Drozdzal"
    ],
    "abstract": "Large-scale training of latent diffusion models (LDMs) has enabled\nunprecedented quality in image generation. However, the key components of the\nbest performing LDM training recipes are oftentimes not available to the\nresearch community, preventing apple-to-apple comparisons and hindering the\nvalidation of progress in the field. In this work, we perform an in-depth study\nof LDM training recipes focusing on the performance of models and their\ntraining efficiency. To ensure apple-to-apple comparisons, we re-implement five\npreviously published models with their corresponding recipes. Through our\nstudy, we explore the effects of (i)~the mechanisms used to condition the\ngenerative model on semantic information (e.g., text prompt) and control\nmetadata (e.g., crop size, random flip flag, etc.) on the model performance,\nand (ii)~the transfer of the representations learned on smaller and\nlower-resolution datasets to larger ones on the training efficiency and model\nperformance. We then propose a novel conditioning mechanism that disentangles\nsemantic and control metadata conditionings and sets a new state-of-the-art in\nclass-conditional generation on the ImageNet-1k dataset -- with FID\nimprovements of 7% on 256 and 8% on 512 resolutions -- as well as text-to-image\ngeneration on the CC12M dataset -- with FID improvements of 8% on 256 and 23%\non 512 resolution.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as a conference paper (poster) for NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.03177v2",
    "published_date": "2024-11-05 15:22:26 UTC",
    "updated_date": "2025-01-20 09:02:20 UTC"
  },
  {
    "arxiv_id": "2411.03171v3",
    "title": "Navigating Extremes: Dynamic Sparsity in Large Output Spaces",
    "authors": [
      "Nasib Ullah",
      "Erik Schultheis",
      "Mike Lasby",
      "Yani Ioannou",
      "Rohit Babbar"
    ],
    "abstract": "In recent years, Dynamic Sparse Training (DST) has emerged as an alternative\nto post-training pruning for generating efficient models. In principle, DST\nallows for a more memory efficient training process, as it maintains sparsity\nthroughout the entire training run. However, current DST implementations fail\nto capitalize on this in practice. Because sparse matrix multiplication is much\nless efficient than dense matrix multiplication on GPUs, most implementations\nsimulate sparsity by masking weights. In this paper, we leverage recent\nadvances in semi-structured sparse training to apply DST in the domain of\nclassification with large output spaces, where memory-efficiency is paramount.\nWith a label space of possibly millions of candidates, the classification layer\nalone will consume several gigabytes of memory. Switching from a dense to a\nfixed fan-in sparse layer updated with sparse evolutionary training (SET);\nhowever, severely hampers training convergence, especially at the largest label\nspaces. We find that poor gradient flow from the sparse classifier to the dense\ntext encoder make it difficult to learn good input representations. By\nemploying an intermediate layer or adding an auxiliary training objective, we\nrecover most of the generalisation performance of the dense model. Overall, we\ndemonstrate the applicability and practical benefits of DST in a challenging\ndomain -- characterized by a highly skewed label distribution that differs\nsubstantially from typical DST benchmark datasets -- which enables end-to-end\ntraining with millions of labels on commodity hardware.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 7 figures, NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.03171v3",
    "published_date": "2024-11-05 15:19:29 UTC",
    "updated_date": "2025-02-09 19:46:51 UTC"
  },
  {
    "arxiv_id": "2411.03105v1",
    "title": "Evaluating Machine Learning Models against Clinical Protocols for Enhanced Interpretability and Continuity of Care",
    "authors": [
      "Christel Sirocchi",
      "Muhammad Suffian",
      "Federico Sabbatini",
      "Alessandro Bogliolo",
      "Sara Montagna"
    ],
    "abstract": "In clinical practice, decision-making relies heavily on established\nprotocols, often formalised as rules. Concurrently, Machine Learning (ML)\nmodels, trained on clinical data, aspire to integrate into medical\ndecision-making processes. However, despite the growing number of ML\napplications, their adoption into clinical practice remains limited. Two\ncritical concerns arise, relevant to the notions of consistency and continuity\nof care: (a) accuracy - the ML model, albeit more accurate, might introduce\nerrors that would not have occurred by applying the protocol; (b)\ninterpretability - ML models operating as black boxes might make predictions\nbased on relationships that contradict established clinical knowledge. In this\ncontext, the literature suggests using ML models integrating domain knowledge\nfor improved accuracy and interpretability. However, there is a lack of\nappropriate metrics for comparing ML models with clinical rules in addressing\nthese challenges. Accordingly, in this article, we first propose metrics to\nassess the accuracy of ML models with respect to the established protocol.\nSecondly, we propose an approach to measure the distance of explanations\nprovided by two rule sets, with the goal of comparing the explanation\nsimilarity between clinical rule-based systems and rules extracted from ML\nmodels. The approach is validated on the Pima Indians Diabetes dataset by\ntraining two neural networks - one exclusively on data, and the other\nintegrating a clinical protocol. Our findings demonstrate that the integrated\nML model achieves comparable performance to that of a fully data-driven model\nwhile exhibiting superior accuracy relative to the clinical protocol, ensuring\nenhanced continuity of care. Furthermore, we show that our integrated model\nprovides explanations for predictions that align more closely with the clinical\nprotocol compared to the data-driven model.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03105v1",
    "published_date": "2024-11-05 13:50:09 UTC",
    "updated_date": "2024-11-05 13:50:09 UTC"
  },
  {
    "arxiv_id": "2411.03098v2",
    "title": "Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation in a Limited Data Setting",
    "authors": [
      "Adrian B. Chłopowiec",
      "Adam R. Chłopowiec",
      "Krzysztof Galus",
      "Wojciech Cebula",
      "Martin Tabakov"
    ],
    "abstract": "Limited medical imaging datasets challenge deep learning models by increasing\nrisks of overfitting and reduced generalization, particularly in Generative\nAdversarial Networks (GANs), where discriminators may overfit, leading to\ntraining divergence. This constraint also impairs classification models trained\non small datasets. Generative Data Augmentation (GDA) addresses this by\nexpanding training datasets with synthetic data, although it requires training\na generative model. We propose and evaluate two local lesion generation\napproaches to address the challenge of augmenting small medical image datasets.\nThe first approach employs the Poisson Image Editing algorithm, a classical\nimage processing technique, to create realistic image composites that\noutperform current state-of-the-art methods. The second approach introduces a\nnovel generative method, leveraging a fine-tuned Image Inpainting GAN to\nsynthesize realistic lesions within specified regions of real training images.\nA comprehensive comparison of the two proposed methods demonstrates that\neffective local lesion generation in a data-constrained setting allows for\nreaching new state-of-the-art results in capsule endoscopy lesion\nclassification. Combination of our techniques achieves a macro F1-score of\n33.07%, surpassing the previous best result by 7.84 percentage points (p.p.) on\nthe highly imbalanced Kvasir Capsule Dataset, a benchmark for capsule\nendoscopy. To the best of our knowledge, this work is the first to apply a\nfine-tuned Image Inpainting GAN for GDA in medical imaging, demonstrating that\nan image-conditional GAN can be adapted effectively to limited datasets to\ngenerate high-quality examples, facilitating effective data augmentation.\nAdditionally, we show that combining this GAN-based approach with classical\nimage processing techniques further improves the results.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "54 pages, 35 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.03098v2",
    "published_date": "2024-11-05 13:44:25 UTC",
    "updated_date": "2024-12-04 10:52:25 UTC"
  },
  {
    "arxiv_id": "2411.03086v1",
    "title": "HFGaussian: Learning Generalizable Gaussian Human with Integrated Human Features",
    "authors": [
      "Arnab Dey",
      "Cheng-You Lu",
      "Andrew I. Comport",
      "Srinath Sridhar",
      "Chin-Teng Lin",
      "Jean Martinet"
    ],
    "abstract": "Recent advancements in radiance field rendering show promising results in 3D\nscene representation, where Gaussian splatting-based techniques emerge as\nstate-of-the-art due to their quality and efficiency. Gaussian splatting is\nwidely used for various applications, including 3D human representation.\nHowever, previous 3D Gaussian splatting methods either use parametric body\nmodels as additional information or fail to provide any underlying structure,\nlike human biomechanical features, which are essential for different\napplications. In this paper, we present a novel approach called HFGaussian that\ncan estimate novel views and human features, such as the 3D skeleton, 3D key\npoints, and dense pose, from sparse input images in real time at 25 FPS. The\nproposed method leverages generalizable Gaussian splatting technique to\nrepresent the human subject and its associated features, enabling efficient and\ngeneralizable reconstruction. By incorporating a pose regression network and\nthe feature splatting technique with Gaussian splatting, HFGaussian\ndemonstrates improved capabilities over existing 3D human methods, showcasing\nthe potential of 3D human representations with integrated biomechanics. We\nthoroughly evaluate our HFGaussian method against the latest state-of-the-art\ntechniques in human Gaussian splatting and pose estimation, demonstrating its\nreal-time, state-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03086v1",
    "published_date": "2024-11-05 13:31:04 UTC",
    "updated_date": "2024-11-05 13:31:04 UTC"
  },
  {
    "arxiv_id": "2411.03082v1",
    "title": "Self-supervised cross-modality learning for uncertainty-aware object detection and recognition in applications which lack pre-labelled training data",
    "authors": [
      "Irum Mehboob",
      "Li Sun",
      "Alireza Astegarpanah",
      "Rustam Stolkin"
    ],
    "abstract": "This paper shows how an uncertainty-aware, deep neural network can be trained\nto detect, recognise and localise objects in 2D RGB images, in applications\nlacking annotated train-ng datasets. We propose a self-supervising\nteacher-student pipeline, in which a relatively simple teacher classifier,\ntrained with only a few labelled 2D thumbnails, automatically processes a\nlarger body of unlabelled RGB-D data to teach a student network based on a\nmodified YOLOv3 architecture. Firstly, 3D object detection with back projection\nis used to automatically extract and teach 2D detection and localisation\ninformation to the student network. Secondly, a weakly supervised 2D thumbnail\nclassifier, with minimal training on a small number of hand-labelled images, is\nused to teach object category recognition. Thirdly, we use a Gaussian Process\nGP to encode and teach a robust uncertainty estimation functionality, so that\nthe student can output confidence scores with each categorization. The\nresulting student significantly outperforms the same YOLO architecture trained\ndirectly on the same amount of labelled data. Our GP-based approach yields\nrobust and meaningful uncertainty estimations for complex industrial object\nclassifications. The end-to-end network is also capable of real-time\nprocessing, needed for robotics applications. Our method can be applied to many\nimportant industrial tasks, where labelled datasets are typically unavailable.\nIn this paper, we demonstrate an example of detection, localisation, and object\ncategory recognition of nuclear mixed-waste materials in highly cluttered and\nunstructured scenes. This is critical for robotic sorting and handling of\nlegacy nuclear waste, which poses complex environmental remediation challenges\nin many nuclearised nations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.03082v1",
    "published_date": "2024-11-05 13:26:31 UTC",
    "updated_date": "2024-11-05 13:26:31 UTC"
  },
  {
    "arxiv_id": "2411.03059v1",
    "title": "Enhancing DP-SGD through Non-monotonous Adaptive Scaling Gradient Weight",
    "authors": [
      "Tao Huang",
      "Qingyu Huang",
      "Xin Shi",
      "Jiayang Meng",
      "Guolong Zheng",
      "Xu Yang",
      "Xun Yi"
    ],
    "abstract": "In the domain of deep learning, the challenge of protecting sensitive data\nwhile maintaining model utility is significant. Traditional Differential\nPrivacy (DP) techniques such as Differentially Private Stochastic Gradient\nDescent (DP-SGD) typically employ strategies like direct or per-sample adaptive\ngradient clipping. These methods, however, compromise model accuracy due to\ntheir critical influence on gradient handling, particularly neglecting the\nsignificant contribution of small gradients during later training stages. In\nthis paper, we introduce an enhanced version of DP-SGD, named Differentially\nPrivate Per-sample Adaptive Scaling Clipping (DP-PSASC). This approach replaces\ntraditional clipping with non-monotonous adaptive gradient scaling, which\nalleviates the need for intensive threshold setting and rectifies the\ndisproportionate weighting of smaller gradients. Our contribution is twofold.\nFirst, we develop a novel gradient scaling technique that effectively assigns\nproper weights to gradients, particularly small ones, thus improving learning\nunder differential privacy. Second, we integrate a momentum-based method into\nDP-PSASC to reduce bias from stochastic sampling, enhancing convergence rates.\nOur theoretical and empirical analyses confirm that DP-PSASC preserves privacy\nand delivers superior performance across diverse datasets, setting new\nstandards for privacy-sensitive applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03059v1",
    "published_date": "2024-11-05 12:47:30 UTC",
    "updated_date": "2024-11-05 12:47:30 UTC"
  },
  {
    "arxiv_id": "2411.03055v3",
    "title": "ATM: Improving Model Merging by Alternating Tuning and Merging",
    "authors": [
      "Luca Zhou",
      "Daniele Solombrino",
      "Donato Crisostomi",
      "Maria Sofia Bucarelli",
      "Fabrizio Silvestri",
      "Emanuele Rodolà"
    ],
    "abstract": "Model merging has recently emerged as a cost-efficient paradigm for\nmulti-task learning. Among current approaches, task arithmetic stands out for\nits simplicity and effectiveness. In this paper, we motivate the effectiveness\nof task vectors by linking them to multi-task gradients. We show that in a\nsingle-epoch scenario, if the optimization is performed via gradient descent,\ntask vectors are after one step mathematically equivalent to the gradients\nobtained via gradient descent in a multi-task setting, and still approximate\nthese gradients in subsequent epochs. Furthermore, we show that the\neffectiveness of task vectors is largely driven by the first epoch's gradient.\nGiven this parallel between task vectors and gradients, we propose viewing\nmodel merging as a single step in an iterative process that alternates between\ntuning and merging (ATM). We then propose two ways to utilize ATM. The first is\nto replace multi-task learning with ATM in scenarios where data sharing is\nprohibited, such as federated learning. The second is to improve the outcome of\nany model merging algorithm by applying a few post-hoc iterations of ATM on a\nsmall validation dataset, which is commonly available for hyperparameter\ntuning. Finally, we provide both empirical and theoretical support for the\neffectiveness of ATM, demonstrating that it minimizes an upper bound on the\nloss obtained by jointly finetuning all tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Main paper: 9 Pages, 9 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2411.03055v3",
    "published_date": "2024-11-05 12:42:42 UTC",
    "updated_date": "2025-03-27 08:57:30 UTC"
  },
  {
    "arxiv_id": "2411.03053v1",
    "title": "Gradient-Guided Conditional Diffusion Models for Private Image Reconstruction: Analyzing Adversarial Impacts of Differential Privacy and Denoising",
    "authors": [
      "Tao Huang",
      "Jiayang Meng",
      "Hong Chen",
      "Guolong Zheng",
      "Xu Yang",
      "Xun Yi",
      "Hua Wang"
    ],
    "abstract": "We investigate the construction of gradient-guided conditional diffusion\nmodels for reconstructing private images, focusing on the adversarial interplay\nbetween differential privacy noise and the denoising capabilities of diffusion\nmodels. While current gradient-based reconstruction methods struggle with\nhigh-resolution images due to computational complexity and prior knowledge\nrequirements, we propose two novel methods that require minimal modifications\nto the diffusion model's generation process and eliminate the need for prior\nknowledge. Our approach leverages the strong image generation capabilities of\ndiffusion models to reconstruct private images starting from randomly generated\nnoise, even when a small amount of differentially private noise has been added\nto the gradients. We also conduct a comprehensive theoretical analysis of the\nimpact of differential privacy noise on the quality of reconstructed images,\nrevealing the relationship among noise magnitude, the architecture of attacked\nmodels, and the attacker's reconstruction capability. Additionally, extensive\nexperiments validate the effectiveness of our proposed methods and the accuracy\nof our theoretical findings, suggesting new directions for privacy risk\nauditing using conditional diffusion models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03053v1",
    "published_date": "2024-11-05 12:39:21 UTC",
    "updated_date": "2024-11-05 12:39:21 UTC"
  },
  {
    "arxiv_id": "2411.03034v1",
    "title": "HumanVLM: Foundation for Human-Scene Vision-Language Model",
    "authors": [
      "Dawei Dai",
      "Xu Long",
      "Li Yutang",
      "Zhang Yuanhui",
      "Shuyin Xia"
    ],
    "abstract": "Human-scene vision-language tasks are increasingly prevalent in diverse\nsocial applications, yet recent advancements predominantly rely on models\nspecifically tailored to individual tasks. Emerging research indicates that\nlarge vision-language models (VLMs) can enhance performance across various\ndownstream vision-language understanding tasks. However, general-domain models\noften underperform in specialized fields. This study introduces a\ndomain-specific Large Vision-Language Model, Human-Scene Vision-Language Model\n(HumanVLM), designed to provide a foundation for human-scene Vision-Language\ntasks. Specifically, (1) we create a large-scale human-scene multimodal\nimage-text dataset (HumanCaption-10M) sourced from the Internet to facilitate\ndomain-specific alignment; (2) develop a captioning approach for human-centered\nimages, capturing human faces, bodies, and backgrounds, and construct a\nhigh-quality Human-Scene image-text dataset (HumanCaptionHQ, about 311k pairs)\nthat contain as much detailed information as possible about human; (3) Using\nHumanCaption-10M and HumanCaptionHQ, we train a HumanVLM. In the experiments,\nwe then evaluate our HumanVLM across varous downstream tasks, where it\ndemonstrates superior overall performance among multimodal models of comparable\nscale, particularly excelling in human-related tasks and significantly\noutperforming similar models, including Qwen2VL and ChatGPT-4o. HumanVLM,\nalongside the data introduced, will stimulate the research in human-around\nfields.",
    "categories": [
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "34 pages,11 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.03034v1",
    "published_date": "2024-11-05 12:14:57 UTC",
    "updated_date": "2024-11-05 12:14:57 UTC"
  },
  {
    "arxiv_id": "2411.05826v1",
    "title": "From Pixels to Prose: Advancing Multi-Modal Language Models for Remote Sensing",
    "authors": [
      "Xintian Sun",
      "Benji Peng",
      "Charles Zhang",
      "Fei Jin",
      "Qian Niu",
      "Junyu Liu",
      "Keyu Chen",
      "Ming Li",
      "Pohsun Feng",
      "Ziqian Bi",
      "Ming Liu",
      "Yichao Zhang"
    ],
    "abstract": "Remote sensing has evolved from simple image acquisition to complex systems\ncapable of integrating and processing visual and textual data. This review\nexamines the development and application of multi-modal language models (MLLMs)\nin remote sensing, focusing on their ability to interpret and describe\nsatellite imagery using natural language. We cover the technical underpinnings\nof MLLMs, including dual-encoder architectures, Transformer models,\nself-supervised and contrastive learning, and cross-modal integration. The\nunique challenges of remote sensing data--varying spatial resolutions, spectral\nrichness, and temporal changes--are analyzed for their impact on MLLM\nperformance. Key applications such as scene description, object detection,\nchange detection, text-to-image retrieval, image-to-text generation, and visual\nquestion answering are discussed to demonstrate their relevance in\nenvironmental monitoring, urban planning, and disaster response. We review\nsignificant datasets and resources supporting the training and evaluation of\nthese models. Challenges related to computational demands, scalability, data\nquality, and domain adaptation are highlighted. We conclude by proposing future\nresearch directions and technological advancements to further enhance MLLM\nutility in remote sensing.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2411.05826v1",
    "published_date": "2024-11-05 12:14:22 UTC",
    "updated_date": "2024-11-05 12:14:22 UTC"
  },
  {
    "arxiv_id": "2411.03027v1",
    "title": "Adaptive Genetic Selection based Pinning Control with Asymmetric Coupling for Multi-Network Heterogeneous Vehicular Systems",
    "authors": [
      "Weian Guo",
      "Ruizhi Sha",
      "Li Li",
      "Lun Zhang",
      "Dongyang Li"
    ],
    "abstract": "To alleviate computational load on RSUs and cloud platforms, reduce\ncommunication bandwidth requirements, and provide a more stable vehicular\nnetwork service, this paper proposes an optimized pinning control approach for\nheterogeneous multi-network vehicular ad-hoc networks (VANETs). In such\nnetworks, vehicles participate in multiple task-specific networks with\nasymmetric coupling and dynamic topologies. We first establish a rigorous\ntheoretical foundation by proving the stability of pinning control strategies\nunder both single and multi-network conditions, deriving sufficient stability\nconditions using Lyapunov theory and linear matrix inequalities (LMIs).\nBuilding on this theoretical groundwork, we propose an adaptive genetic\nalgorithm tailored to select optimal pinning nodes, effectively balancing LMI\nconstraints while prioritizing overlapping nodes to enhance control efficiency.\nExtensive simulations across various network scales demonstrate that our\napproach achieves rapid consensus with a reduced number of control nodes,\nparticularly when leveraging network overlaps. This work provides a\ncomprehensive solution for efficient control node selection in complex\nvehicular networks, offering practical implications for deploying large-scale\nintelligent transportation systems.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03027v1",
    "published_date": "2024-11-05 11:49:26 UTC",
    "updated_date": "2024-11-05 11:49:26 UTC"
  },
  {
    "arxiv_id": "2411.03025v1",
    "title": "DA-MoE: Addressing Depth-Sensitivity in Graph-Level Analysis through Mixture of Experts",
    "authors": [
      "Zelin Yao",
      "Chuang Liu",
      "Xianke Meng",
      "Yibing Zhan",
      "Jia Wu",
      "Shirui Pan",
      "Wenbin Hu"
    ],
    "abstract": "Graph neural networks (GNNs) are gaining popularity for processing\ngraph-structured data. In real-world scenarios, graph data within the same\ndataset can vary significantly in scale. This variability leads to\ndepth-sensitivity, where the optimal depth of GNN layers depends on the scale\nof the graph data. Empirically, fewer layers are sufficient for message passing\nin smaller graphs, while larger graphs typically require deeper networks to\ncapture long-range dependencies and global features. However, existing methods\ngenerally use a fixed number of GNN layers to generate representations for all\ngraphs, overlooking the depth-sensitivity issue in graph structure data. To\naddress this challenge, we propose the depth adaptive mixture of expert\n(DA-MoE) method, which incorporates two main improvements to GNN backbone:\n\\textbf{1)} DA-MoE employs different GNN layers, each considered an expert with\nits own parameters. Such a design allows the model to flexibly aggregate\ninformation at different scales, effectively addressing the depth-sensitivity\nissue in graph data. \\textbf{2)} DA-MoE utilizes GNN to capture the structural\ninformation instead of the linear projections in the gating network. Thus, the\ngating network enables the model to capture complex patterns and dependencies\nwithin the data. By leveraging these improvements, each expert in DA-MoE\nspecifically learns distinct graph patterns at different scales. Furthermore,\ncomprehensive experiments on the TU dataset and open graph benchmark (OGB) have\nshown that DA-MoE consistently surpasses existing baselines on various tasks,\nincluding graph, node, and link-level analyses. The code are available at\n\\url{https://github.com/Celin-Yao/DA-MoE}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8pages",
    "pdf_url": "http://arxiv.org/pdf/2411.03025v1",
    "published_date": "2024-11-05 11:46:27 UTC",
    "updated_date": "2024-11-05 11:46:27 UTC"
  },
  {
    "arxiv_id": "2411.03022v1",
    "title": "Flashy Backdoor: Real-world Environment Backdoor Attack on SNNs with DVS Cameras",
    "authors": [
      "Roberto Riaño",
      "Gorka Abad",
      "Stjepan Picek",
      "Aitor Urbieta"
    ],
    "abstract": "While security vulnerabilities in traditional Deep Neural Networks (DNNs)\nhave been extensively studied, the susceptibility of Spiking Neural Networks\n(SNNs) to adversarial attacks remains mostly underexplored. Until now, the\nmechanisms to inject backdoors into SNN models have been limited to digital\nscenarios; thus, we present the first evaluation of backdoor attacks in\nreal-world environments.\n  We begin by assessing the applicability of existing digital backdoor attacks\nand identifying their limitations for deployment in physical environments. To\naddress each of the found limitations, we present three novel backdoor attack\nmethods on SNNs, i.e., Framed, Strobing, and Flashy Backdoor. We also assess\nthe effectiveness of traditional backdoor procedures and defenses adapted for\nSNNs, such as pruning, fine-tuning, and fine-pruning. The results show that\nwhile these procedures and defenses can mitigate some attacks, they often fail\nagainst stronger methods like Flashy Backdoor or sacrifice too much clean\naccuracy, rendering the models unusable.\n  Overall, all our methods can achieve up to a 100% Attack Success Rate while\nmaintaining high clean accuracy in every tested dataset. Additionally, we\nevaluate the stealthiness of the triggers with commonly used metrics, finding\nthem highly stealthy. Thus, we propose new alternatives more suited for\nidentifying poisoned samples in these scenarios. Our results show that further\nresearch is needed to ensure the security of SNN-based systems against backdoor\nattacks and their safe application in real-world scenarios. The code,\nexperiments, and results are available in our repository.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.03022v1",
    "published_date": "2024-11-05 11:44:54 UTC",
    "updated_date": "2024-11-05 11:44:54 UTC"
  },
  {
    "arxiv_id": "2411.03012v1",
    "title": "Leveraging Large Language Models in Code Question Answering: Baselines and Issues",
    "authors": [
      "Georgy Andryushchenko",
      "Vladimir Ivanov",
      "Vladimir Makharev",
      "Elizaveta Tukhtina",
      "Aidar Valeev"
    ],
    "abstract": "Question answering over source code provides software engineers and project\nmanagers with helpful information about the implemented features of a software\nproduct. This paper presents a work devoted to using large language models for\nquestion answering over source code in Python. The proposed method for\nimplementing a source code question answering system involves fine-tuning a\nlarge language model on a unified dataset of questions and answers for Python\ncode. To achieve the highest quality answers, we tested various models trained\non datasets preprocessed in different ways: a dataset without grammar\ncorrection, a dataset with grammar correction, and a dataset augmented with the\ngenerated summaries. The model answers were also analyzed for errors manually.\nWe report BLEU-4, BERTScore F1, BLEURT, and Exact Match metric values, along\nwith the conclusions from the manual error analysis. The obtained experimental\nresults highlight the current problems of the research area, such as poor\nquality of the public genuine question-answering datasets. In addition, the\nfindings include the positive effect of the grammar correction of the training\ndata on the testing metric values. The addressed findings and issues could be\nimportant for other researchers who attempt to improve the quality of source\ncode question answering solutions. The training and evaluation code is publicly\navailable at https://github.com/IU-AES-AI4Code/CodeQuestionAnswering.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 3 figures, Accepted to NLP (CCIS) @ AIST'24",
    "pdf_url": "http://arxiv.org/pdf/2411.03012v1",
    "published_date": "2024-11-05 11:25:12 UTC",
    "updated_date": "2024-11-05 11:25:12 UTC"
  },
  {
    "arxiv_id": "2411.03008v1",
    "title": "Hierarchical Orchestra of Policies",
    "authors": [
      "Thomas P Cannon",
      "Özgür Simsek"
    ],
    "abstract": "Continual reinforcement learning poses a major challenge due to the tendency\nof agents to experience catastrophic forgetting when learning sequential tasks.\nIn this paper, we introduce a modularity-based approach, called Hierarchical\nOrchestra of Policies (HOP), designed to mitigate catastrophic forgetting in\nlifelong reinforcement learning. HOP dynamically forms a hierarchy of policies\nbased on a similarity metric between the current observations and previously\nencountered observations in successful tasks. Unlike other state-of-the-art\nmethods, HOP does not require task labelling, allowing for robust adaptation in\nenvironments where boundaries between tasks are ambiguous. Our experiments,\nconducted across multiple tasks in a procedurally generated suite of\nenvironments, demonstrate that HOP significantly outperforms baseline methods\nin retaining knowledge across tasks and performs comparably to state-of-the-art\ntransfer methods that require task labelling. Moreover, HOP achieves this\nwithout compromising performance when tasks remain constant, highlighting its\nversatility.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as a poster. NeurIPS IMOL",
    "pdf_url": "http://arxiv.org/pdf/2411.03008v1",
    "published_date": "2024-11-05 11:13:09 UTC",
    "updated_date": "2024-11-05 11:13:09 UTC"
  },
  {
    "arxiv_id": "2411.03007v1",
    "title": "Data Quality Awareness: A Journey from Traditional Data Management to Data Science Systems",
    "authors": [
      "Sijie Dong",
      "Soror Sahri",
      "Themis Palpanas"
    ],
    "abstract": "Artificial intelligence (AI) has transformed various fields, significantly\nimpacting our daily lives. A major factor in AI success is high-quality data.\nIn this paper, we present a comprehensive review of the evolution of data\nquality (DQ) awareness from traditional data management systems to modern\ndata-driven AI systems, which are integral to data science. We synthesize the\nexisting literature, highlighting the quality challenges and techniques that\nhave evolved from traditional data management to data science including big\ndata and ML fields. As data science systems support a wide range of activities,\nour focus in this paper lies specifically in the analytics aspect driven by\nmachine learning. We use the cause-effect connection between the quality\nchallenges of ML and those of big data to allow a more thorough understanding\nof emerging DQ challenges and the related quality awareness techniques in data\nscience systems. To the best of our knowledge, our paper is the first to\nprovide a review of DQ awareness spanning traditional and emergent data science\nsystems. We hope that readers will find this journey through the evolution of\ndata quality awareness insightful and valuable.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.03007v1",
    "published_date": "2024-11-05 11:12:25 UTC",
    "updated_date": "2024-11-05 11:12:25 UTC"
  },
  {
    "arxiv_id": "2411.03004v1",
    "title": "Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status",
    "authors": [
      "Samuel Lee",
      "Zach Wood-Doughty"
    ],
    "abstract": "Causal understanding is a fundamental goal of evidence-based medicine. When\nrandomization is impossible, causal inference methods allow the estimation of\ntreatment effects from retrospective analysis of observational data. However,\nsuch analyses rely on a number of assumptions, often including that of no\nunobserved confounding. In many practical settings, this assumption is violated\nwhen important variables are not explicitly measured in the clinical record.\nPrior work has proposed to address unobserved confounding with machine learning\nby imputing unobserved variables and then correcting for the classifier's\nmismeasurement. When such a classifier can be trained and the necessary\nassumptions are met, this method can recover an unbiased estimate of a causal\neffect. However, such work has been limited to synthetic data, simple\nclassifiers, and binary variables. This paper extends this methodology by using\na large language model trained on clinical notes to predict patients' smoking\nstatus, which would otherwise be an unobserved confounder. We then apply a\nmeasurement error correction on the categorical predicted smoking status to\nestimate the causal effect of transthoracic echocardiography on mortality in\nthe MIMIC dataset.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Advancements In Medical Foundation Models: Explainability,\n  Robustness, Security, and Beyond (AIM-FM) at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.03004v1",
    "published_date": "2024-11-05 11:05:53 UTC",
    "updated_date": "2024-11-05 11:05:53 UTC"
  },
  {
    "arxiv_id": "2411.02998v3",
    "title": "Accelerating Task Generalisation with Multi-Level Skill Hierarchies",
    "authors": [
      "Thomas P Cannon",
      "Özgür Simsek"
    ],
    "abstract": "Creating reinforcement learning agents that generalise effectively to new\ntasks is a key challenge in AI research. This paper introduces Fracture Cluster\nOptions (FraCOs), a multi-level hierarchical reinforcement learning method that\nachieves state-of-the-art performance on difficult generalisation tasks. FraCOs\nidentifies patterns in agent behaviour and forms options based on the expected\nfuture usefulness of those patterns, enabling rapid adaptation to new tasks. In\ntabular settings, FraCOs demonstrates effective transfer and improves\nperformance as it grows in hierarchical depth. We evaluate FraCOs against\nstate-of-the-art deep reinforcement learning algorithms in several complex\nprocedurally generated environments. Our results show that FraCOs achieves\nhigher in-distribution and out-of-distribution performance than competitors.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, accepted at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.02998v3",
    "published_date": "2024-11-05 11:00:09 UTC",
    "updated_date": "2025-03-30 10:36:39 UTC"
  },
  {
    "arxiv_id": "2411.02995v1",
    "title": "SUDS: A Strategy for Unsupervised Drift Sampling",
    "authors": [
      "Christofer Fellicious",
      "Lorenz Wendlinger",
      "Mario Gancarski",
      "Jelena Mitrovic",
      "Michael Granitzer"
    ],
    "abstract": "Supervised machine learning often encounters concept drift, where the data\ndistribution changes over time, degrading model performance. Existing drift\ndetection methods focus on identifying these shifts but often overlook the\nchallenge of acquiring labeled data for model retraining after a shift occurs.\nWe present the Strategy for Drift Sampling (SUDS), a novel method that selects\nhomogeneous samples for retraining using existing drift detection algorithms,\nthereby enhancing model adaptability to evolving data. SUDS seamlessly\nintegrates with current drift detection techniques. We also introduce the\nHarmonized Annotated Data Accuracy Metric (HADAM), a metric that evaluates\nclassifier performance in relation to the quantity of annotated data required\nto achieve the stated performance, thereby taking into account the difficulty\nof acquiring labeled data. Our contributions are twofold: SUDS combines drift\ndetection with strategic sampling to improve the retraining process, and HADAM\nprovides a metric that balances classifier performance with the amount of\nlabeled data, ensuring efficient resource utilization. Empirical results\ndemonstrate the efficacy of SUDS in optimizing labeled data use in dynamic\nenvironments, significantly improving the performance of machine learning\napplications in real-world scenarios. Our code is open source and available at\nhttps://github.com/cfellicious/SUDS/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 5 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.02995v1",
    "published_date": "2024-11-05 10:55:29 UTC",
    "updated_date": "2024-11-05 10:55:29 UTC"
  },
  {
    "arxiv_id": "2411.02988v2",
    "title": "Confidence Calibration of Classifiers with Many Classes",
    "authors": [
      "Adrien LeCoz",
      "Stéphane Herbin",
      "Faouzi Adjed"
    ],
    "abstract": "For classification models based on neural networks, the maximum predicted\nclass probability is often used as a confidence score. This score rarely\npredicts well the probability of making a correct prediction and requires a\npost-processing calibration step. However, many confidence calibration methods\nfail for problems with many classes. To address this issue, we transform the\nproblem of calibrating a multiclass classifier into calibrating a single\nsurrogate binary classifier. This approach allows for more efficient use of\nstandard calibration methods. We evaluate our approach on numerous neural\nnetworks used for image or text classification and show that it significantly\nenhances existing calibration methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024; code available at\n  https://github.com/allglc/tva-calibration",
    "pdf_url": "http://arxiv.org/pdf/2411.02988v2",
    "published_date": "2024-11-05 10:51:01 UTC",
    "updated_date": "2024-11-06 10:08:30 UTC"
  },
  {
    "arxiv_id": "2411.02983v1",
    "title": "Autonomous Decision Making for UAV Cooperative Pursuit-Evasion Game with Reinforcement Learning",
    "authors": [
      "Yang Zhao",
      "Zidong Nie",
      "Kangsheng Dong",
      "Qinghua Huang",
      "Xuelong Li"
    ],
    "abstract": "The application of intelligent decision-making in unmanned aerial vehicle\n(UAV) is increasing, and with the development of UAV 1v1 pursuit-evasion game,\nmulti-UAV cooperative game has emerged as a new challenge. This paper proposes\na deep reinforcement learning-based model for decision-making in multi-role UAV\ncooperative pursuit-evasion game, to address the challenge of enabling UAV to\nautonomously make decisions in complex game environments. In order to enhance\nthe training efficiency of the reinforcement learning algorithm in UAV\npursuit-evasion game environment that has high-dimensional state-action space,\nthis paper proposes multi-environment asynchronous double deep Q-network with\npriority experience replay algorithm to effectively train the UAV's game\npolicy. Furthermore, aiming to improve cooperation ability and task completion\nefficiency, as well as minimize the cost of UAVs in the pursuit-evasion game,\nthis paper focuses on the allocation of roles and targets within multi-UAV\nenvironment. The cooperative game decision model with varying numbers of UAVs\nare obtained by assigning diverse tasks and roles to the UAVs in different\nscenarios. The simulation results demonstrate that the proposed method enables\nautonomous decision-making of the UAVs in pursuit-evasion game scenarios and\nexhibits significant capabilities in cooperation.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.RO",
      "I.2.6; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 12 figures, 31 conference",
    "pdf_url": "http://arxiv.org/pdf/2411.02983v1",
    "published_date": "2024-11-05 10:45:30 UTC",
    "updated_date": "2024-11-05 10:45:30 UTC"
  },
  {
    "arxiv_id": "2411.02974v3",
    "title": "Region-Guided Attack on the Segment Anything Model (SAM)",
    "authors": [
      "Xiaoliang Liu",
      "Furao Shen",
      "Jian Zhao"
    ],
    "abstract": "The Segment Anything Model (SAM) is a cornerstone of image segmentation,\ndemonstrating exceptional performance across various applications, particularly\nin autonomous driving and medical imaging, where precise segmentation is\ncrucial. However, SAM is vulnerable to adversarial attacks that can\nsignificantly impair its functionality through minor input perturbations.\nTraditional techniques, such as FGSM and PGD, are often ineffective in\nsegmentation tasks due to their reliance on global perturbations that overlook\nspatial nuances. Recent methods like Attack-SAM-K and UAD have begun to address\nthese challenges, but they frequently depend on external cues and do not fully\nleverage the structural interdependencies within segmentation processes. This\nlimitation underscores the need for a novel adversarial strategy that exploits\nthe unique characteristics of segmentation tasks. In response, we introduce the\nRegion-Guided Attack (RGA), designed specifically for SAM. RGA utilizes a\nRegion-Guided Map (RGM) to manipulate segmented regions, enabling targeted\nperturbations that fragment large segments and expand smaller ones, resulting\nin erroneous outputs from SAM. Our experiments demonstrate that RGA achieves\nhigh success rates in both white-box and black-box scenarios, emphasizing the\nneed for robust defenses against such sophisticated attacks. RGA not only\nreveals SAM's vulnerabilities but also lays the groundwork for developing more\nresilient defenses against adversarial threats in image segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02974v3",
    "published_date": "2024-11-05 10:21:21 UTC",
    "updated_date": "2025-01-02 02:37:12 UTC"
  },
  {
    "arxiv_id": "2411.02973v1",
    "title": "[Vision Paper] PRObot: Enhancing Patient-Reported Outcome Measures for Diabetic Retinopathy using Chatbots and Generative AI",
    "authors": [
      "Maren Pielka",
      "Tobias Schneider",
      "Jan Terheyden",
      "Rafet Sifa"
    ],
    "abstract": "We present an outline of the first large language model (LLM) based chatbot\napplication in the context of patient-reported outcome measures (PROMs) for\ndiabetic retinopathy. By utilizing the capabilities of current LLMs, we enable\npatients to provide feedback about their quality of life and treatment progress\nvia an interactive application. The proposed framework offers significant\nadvantages over the current approach, which encompasses only qualitative\ncollection of survey data or a static survey with limited answer options. Using\nthe PROBot LLM-PROM application, patients will be asked tailored questions\nabout their individual challenges, and can give more detailed feedback on the\nprogress of their treatment. Based on this input, we will use machine learning\nto infer conventional PROM scores, which can be used by clinicians to evaluate\nthe treatment status. The goal of the application is to improve adherence to\nthe healthcare system and treatments, and thus ultimately reduce cases of\nsubsequent vision impairment. The approach needs to be further validated using\na survey and a clinical study.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02973v1",
    "published_date": "2024-11-05 10:18:53 UTC",
    "updated_date": "2024-11-05 10:18:53 UTC"
  },
  {
    "arxiv_id": "2411.02964v2",
    "title": "Speaker Emotion Recognition: Leveraging Self-Supervised Models for Feature Extraction Using Wav2Vec2 and HuBERT",
    "authors": [
      "Pourya Jafarzadeh",
      "Amir Mohammad Rostami",
      "Padideh Choobdar"
    ],
    "abstract": "Speech is the most natural way of expressing ourselves as humans. Identifying\nemotion from speech is a nontrivial task due to the ambiguous definition of\nemotion itself. Speaker Emotion Recognition (SER) is essential for\nunderstanding human emotional behavior. The SER task is challenging due to the\nvariety of speakers, background noise, complexity of emotions, and speaking\nstyles. It has many applications in education, healthcare, customer service,\nand Human-Computer Interaction (HCI). Previously, conventional machine learning\nmethods such as SVM, HMM, and KNN have been used for the SER task. In recent\nyears, deep learning methods have become popular, with convolutional neural\nnetworks and recurrent neural networks being used for SER tasks. The input of\nthese methods is mostly spectrograms and hand-crafted features. In this work,\nwe study the use of self-supervised transformer-based models, Wav2Vec2 and\nHuBERT, to determine the emotion of speakers from their voice. The models\nautomatically extract features from raw audio signals, which are then used for\nthe classification task. The proposed solution is evaluated on reputable\ndatasets, including RAVDESS, SHEMO, SAVEE, AESDD, and Emo-DB. The results show\nthe effectiveness of the proposed method on different datasets. Moreover, the\nmodel has been used for real-world applications like call center conversations,\nand the results demonstrate that the model accurately predicts emotions.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02964v2",
    "published_date": "2024-11-05 10:06:40 UTC",
    "updated_date": "2024-11-06 14:18:15 UTC"
  },
  {
    "arxiv_id": "2411.05028v1",
    "title": "Leveraging Transfer Learning and Multiple Instance Learning for HER2 Automatic Scoring of H\\&E Whole Slide Images",
    "authors": [
      "Rawan S. Abdulsadig",
      "Bryan M. Williams",
      "Nikolay Burlutskiy"
    ],
    "abstract": "Expression of human epidermal growth factor receptor 2 (HER2) is an important\nbiomarker in breast cancer patients who can benefit from cost-effective\nautomatic Hematoxylin and Eosin (H\\&E) HER2 scoring. However, developing such\nscoring models requires large pixel-level annotated datasets. Transfer learning\nallows prior knowledge from different datasets to be reused while\nmultiple-instance learning (MIL) allows the lack of detailed annotations to be\nmitigated. The aim of this work is to examine the potential of transfer\nlearning on the performance of deep learning models pre-trained on (i)\nImmunohistochemistry (IHC) images, (ii) H\\&E images and (iii) non-medical\nimages. A MIL framework with an attention mechanism is developed using\npre-trained models as patch-embedding models. It was found that embedding\nmodels pre-trained on H\\&E images consistently outperformed the others,\nresulting in an average AUC-ROC value of $0.622$ across the 4 HER2 scores\n($0.59-0.80$ per HER2 score). Furthermore, it was found that using\nmultiple-instance learning with an attention layer not only allows for good\nclassification results to be achieved, but it can also help with producing\nvisual indication of HER2-positive areas in the H\\&E slide image by utilising\nthe patch-wise attention weights.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05028v1",
    "published_date": "2024-11-05 09:44:48 UTC",
    "updated_date": "2024-11-05 09:44:48 UTC"
  },
  {
    "arxiv_id": "2411.02941v1",
    "title": "A Mamba Foundation Model for Time Series Forecasting",
    "authors": [
      "Haoyu Ma",
      "Yushu Chen",
      "Wenlai Zhao",
      "Jinzhe Yang",
      "Yingsheng Ji",
      "Xinghua Xu",
      "Xiaozhu Liu",
      "Hao Jing",
      "Shengzhuo Liu",
      "Guangwen Yang"
    ],
    "abstract": "Time series foundation models have demonstrated strong performance in\nzero-shot learning, making them well-suited for predicting rapidly evolving\npatterns in real-world applications where relevant training data are scarce.\nHowever, most of these models rely on the Transformer architecture, which\nincurs quadratic complexity as input length increases. To address this, we\nintroduce TSMamba, a linear-complexity foundation model for time series\nforecasting built on the Mamba architecture. The model captures temporal\ndependencies through both forward and backward Mamba encoders, achieving high\nprediction accuracy. To reduce reliance on large datasets and lower training\ncosts, TSMamba employs a two-stage transfer learning process that leverages\npretrained Mamba LLMs, allowing effective time series modeling with a moderate\ntraining set. In the first stage, the forward and backward backbones are\noptimized via patch-wise autoregressive prediction; in the second stage, the\nmodel trains a prediction head and refines other components for long-term\nforecasting. While the backbone assumes channel independence to manage varying\nchannel numbers across datasets, a channel-wise compressed attention module is\nintroduced to capture cross-channel dependencies during fine-tuning on specific\nmultivariate datasets. Experiments show that TSMamba's zero-shot performance is\ncomparable to state-of-the-art time series foundation models, despite using\nsignificantly less training data. It also achieves competitive or superior\nfull-shot performance compared to task-specific prediction models. The code\nwill be made publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02941v1",
    "published_date": "2024-11-05 09:34:05 UTC",
    "updated_date": "2024-11-05 09:34:05 UTC"
  },
  {
    "arxiv_id": "2411.02939v1",
    "title": "A Post-Training Enhanced Optimization Approach for Small Language Models",
    "authors": [
      "Keke Zhai"
    ],
    "abstract": "This paper delves into the continuous post-training optimization methods for\nsmall language models, and proposes a continuous post-training alignment data\nconstruction method for small language models. The core of this method is based\non the data guidance of large models, optimizing the diversity and accuracy of\nalignment data. In addition, to verify the effectiveness of the methods in this\npaper, we used Qwen2-0.5B-Instruct model as the baseline model for small\nlanguage models, using the alignment dataset constructed by our proposed\nmethod, we trained and compared several groups of experiments, including SFT\n(Supervised Fine Tuning) post-training experiment and KTO (Kahneman Tversky\noptimization) post-training experiment, as well as SFT-KTO two-stage\npost-training experiment and model weight fusion experiment. Finally, we\nevaluated and analyzed the performance of post-training models, and confirmed\nthat the continuous post-training optimization method proposed by us can\nsignificantly improve the performance of small language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02939v1",
    "published_date": "2024-11-05 09:32:26 UTC",
    "updated_date": "2024-11-05 09:32:26 UTC"
  },
  {
    "arxiv_id": "2411.02930v1",
    "title": "Textual Aesthetics in Large Language Models",
    "authors": [
      "Lingjie Jiang",
      "Shaohan Huang",
      "Xun Wu",
      "Furu Wei"
    ],
    "abstract": "Image aesthetics is a crucial metric in the field of image generation.\nHowever, textual aesthetics has not been sufficiently explored. With the\nwidespread application of large language models (LLMs), previous work has\nprimarily focused on the correctness of content and the helpfulness of\nresponses. Nonetheless, providing responses with textual aesthetics is also an\nimportant factor for LLMs, which can offer a cleaner layout and ensure greater\nconsistency and coherence in content. In this work, we introduce a pipeline for\naesthetics polishing and help construct a textual aesthetics dataset named\nTexAes. We propose a textual aesthetics-powered fine-tuning method based on\ndirect preference optimization, termed TAPO, which leverages textual aesthetics\nwithout compromising content correctness. Additionally, we develop two\nevaluation methods for textual aesthetics based on text and image analysis,\nrespectively. Our experiments demonstrate that using textual aesthetics data\nand employing the TAPO fine-tuning method not only improves aesthetic scores\nbut also enhances performance on general evaluation datasets such as\nAlpacalEval and Anera-hard.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02930v1",
    "published_date": "2024-11-05 09:22:08 UTC",
    "updated_date": "2024-11-05 09:22:08 UTC"
  },
  {
    "arxiv_id": "2411.02920v1",
    "title": "Domain Expansion and Boundary Growth for Open-Set Single-Source Domain Generalization",
    "authors": [
      "Pengkun Jiao",
      "Na Zhao",
      "Jingjing Chen",
      "Yu-Gang Jiang"
    ],
    "abstract": "Open-set single-source domain generalization aims to use a single-source\ndomain to learn a robust model that can be generalized to unknown target\ndomains with both domain shifts and label shifts. The scarcity of the source\ndomain and the unknown data distribution of the target domain pose a great\nchallenge for domain-invariant feature learning and unknown class recognition.\nIn this paper, we propose a novel learning approach based on domain expansion\nand boundary growth to expand the scarce source samples and enlarge the\nboundaries across the known classes that indirectly broaden the boundary\nbetween the known and unknown classes. Specifically, we achieve domain\nexpansion by employing both background suppression and style augmentation on\nthe source data to synthesize new samples. Then we force the model to distill\nconsistent knowledge from the synthesized samples so that the model can learn\ndomain-invariant information. Furthermore, we realize boundary growth across\nclasses by using edge maps as an additional modality of samples when training\nmulti-binary classifiers. In this way, it enlarges the boundary between the\ninliers and outliers, and consequently improves the unknown class recognition\nduring open-set generalization. Extensive experiments show that our approach\ncan achieve significant improvements and reach state-of-the-art performance on\nseveral cross-domain image classification datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "TMM 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.02920v1",
    "published_date": "2024-11-05 09:08:46 UTC",
    "updated_date": "2024-11-05 09:08:46 UTC"
  },
  {
    "arxiv_id": "2411.02914v1",
    "title": "Exploring the Interplay Between Video Generation and World Models in Autonomous Driving: A Survey",
    "authors": [
      "Ao Fu",
      "Yi Zhou",
      "Tao Zhou",
      "Yi Yang",
      "Bojun Gao",
      "Qun Li",
      "Guobin Wu",
      "Ling Shao"
    ],
    "abstract": "World models and video generation are pivotal technologies in the domain of\nautonomous driving, each playing a critical role in enhancing the robustness\nand reliability of autonomous systems. World models, which simulate the\ndynamics of real-world environments, and video generation models, which produce\nrealistic video sequences, are increasingly being integrated to improve\nsituational awareness and decision-making capabilities in autonomous vehicles.\nThis paper investigates the relationship between these two technologies,\nfocusing on how their structural parallels, particularly in diffusion-based\nmodels, contribute to more accurate and coherent simulations of driving\nscenarios. We examine leading works such as JEPA, Genie, and Sora, which\nexemplify different approaches to world model design, thereby highlighting the\nlack of a universally accepted definition of world models. These diverse\ninterpretations underscore the field's evolving understanding of how world\nmodels can be optimized for various autonomous driving tasks. Furthermore, this\npaper discusses the key evaluation metrics employed in this domain, such as\nChamfer distance for 3D scene reconstruction and Fr\\'echet Inception Distance\n(FID) for assessing the quality of generated video content. By analyzing the\ninterplay between video generation and world models, this survey identifies\ncritical challenges and future research directions, emphasizing the potential\nof these technologies to jointly advance the performance of autonomous driving\nsystems. The findings presented in this paper aim to provide a comprehensive\nunderstanding of how the integration of video generation and world models can\ndrive innovation in the development of safer and more reliable autonomous\nvehicles.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02914v1",
    "published_date": "2024-11-05 08:58:35 UTC",
    "updated_date": "2024-11-05 08:58:35 UTC"
  },
  {
    "arxiv_id": "2411.05825v1",
    "title": "SurfGNN: A robust surface-based prediction model with interpretability for coactivation maps of spatial and cortical features",
    "authors": [
      "Zhuoshuo Li",
      "Jiong Zhang",
      "Youbing Zeng",
      "Jiaying Lin",
      "Dan Zhang",
      "Jianjia Zhang",
      "Duan Xu",
      "Hosung Kim",
      "Bingguang Liu",
      "Mengting Liu"
    ],
    "abstract": "Current brain surface-based prediction models often overlook the variability\nof regional attributes at the cortical feature level. While graph neural\nnetworks (GNNs) excel at capturing regional differences, they encounter\nchallenges when dealing with complex, high-density graph structures. In this\nwork, we consider the cortical surface mesh as a sparse graph and propose an\ninterpretable prediction model-Surface Graph Neural Network (SurfGNN). SurfGNN\nemploys topology-sampling learning (TSL) and region-specific learning (RSL)\nstructures to manage individual cortical features at both lower and higher\nscales of the surface mesh, effectively tackling the challenges posed by the\noverly abundant mesh nodes and addressing the issue of heterogeneity in\ncortical regions. Building on this, a novel score-weighted fusion (SWF) method\nis implemented to merge nodal representations associated with each cortical\nfeature for prediction. We apply our model to a neonatal brain age prediction\ntask using a dataset of harmonized MR images from 481 subjects (503 scans).\nSurfGNN outperforms all existing state-of-the-art methods, demonstrating an\nimprovement of at least 9.0% and achieving a mean absolute error (MAE) of\n0.827+0.056 in postmenstrual weeks. Furthermore, it generates feature-level\nactivation maps, indicating its capability to identify robust regional\nvariations in different morphometric contributions for prediction.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CV",
      "J.3"
    ],
    "primary_category": "q-bio.NC",
    "comment": "15 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.05825v1",
    "published_date": "2024-11-05 08:39:53 UTC",
    "updated_date": "2024-11-05 08:39:53 UTC"
  },
  {
    "arxiv_id": "2411.02902v1",
    "title": "Membership Inference Attacks against Large Vision-Language Models",
    "authors": [
      "Zhan Li",
      "Yongtao Wu",
      "Yihang Chen",
      "Francesco Tonin",
      "Elias Abad Rocamora",
      "Volkan Cevher"
    ],
    "abstract": "Large vision-language models (VLLMs) exhibit promising capabilities for\nprocessing multi-modal tasks across various application scenarios. However,\ntheir emergence also raises significant data security concerns, given the\npotential inclusion of sensitive information, such as private photos and\nmedical records, in their training datasets. Detecting inappropriately used\ndata in VLLMs remains a critical and unresolved issue, mainly due to the lack\nof standardized datasets and suitable methodologies. In this study, we\nintroduce the first membership inference attack (MIA) benchmark tailored for\nvarious VLLMs to facilitate training data detection. Then, we propose a novel\nMIA pipeline specifically designed for token-level image detection. Lastly, we\npresent a new metric called MaxR\\'enyi-K%, which is based on the confidence of\nthe model output and applies to both text and image data. We believe that our\nwork can deepen the understanding and methodology of MIAs in the context of\nVLLMs. Our code and datasets are available at\nhttps://github.com/LIONS-EPFL/VL-MIA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.02902v1",
    "published_date": "2024-11-05 08:35:08 UTC",
    "updated_date": "2024-11-05 08:35:08 UTC"
  },
  {
    "arxiv_id": "2411.02886v2",
    "title": "TokenSelect: Efficient Long-Context Inference and Length Extrapolation for LLMs via Dynamic Token-Level KV Cache Selection",
    "authors": [
      "Wei Wu",
      "Zhuoshi Pan",
      "Chao Wang",
      "Liyi Chen",
      "Yunchu Bai",
      "Tianfu Wang",
      "Kun Fu",
      "Zheng Wang",
      "Hui Xiong"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has driven growing\ndemand for processing extended context sequences in contemporary applications.\nHowever, this progress faces two major challenges: performance degradation due\nto sequence lengths out-of-distribution, and excessively long inference times\ncaused by the quadratic computational complexity of attention. These issues\nhinder the application of LLMs in long-context scenarios. In this paper, we\npropose Dynamic Token-Level KV Cache Selection (TokenSelect), a training-free\nmethod for efficient and accurate long-context inference. TokenSelect builds\nupon the observation of non-contiguous attention sparsity, using Query-Key dot\nproducts to measure per-head KV Cache criticality at token-level. By per-head\nsoft voting mechanism, TokenSelect selectively involves a few critical KV cache\ntokens in attention calculation without sacrificing accuracy. To further\naccelerate TokenSelect, we design the Selection Cache based on observations of\nconsecutive Query similarity and implemented efficient dot product kernel,\nsignificantly reducing the overhead. A comprehensive evaluation of TokenSelect\ndemonstrates up to 23.84x speedup in attention computation and up to 2.28x\nacceleration in end-to-end latency, while providing superior performance\ncompared to state-of-the-art long-context inference methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02886v2",
    "published_date": "2024-11-05 07:56:24 UTC",
    "updated_date": "2025-03-03 05:49:41 UTC"
  },
  {
    "arxiv_id": "2411.02867v2",
    "title": "AtlasSeg: Atlas Prior Guided Dual-U-Net for Cortical Segmentation in Fetal Brain MRI",
    "authors": [
      "Haoan Xu",
      "Tianshu Zheng",
      "Xinyi Xu",
      "Yao Shen",
      "Jiwei Sun",
      "Cong Sun",
      "Guangbin Wang",
      "Zhaopeng Cui",
      "Dan Wu"
    ],
    "abstract": "Accurate automatic tissue segmentation in fetal brain MRI is a crucial step\nin clinical diagnosis but remains challenging, particularly due to the\ndynamically changing anatomy and tissue contrast during fetal development.\nExisting segmentation networks can only implicitly learn age-related features,\nleading to a decline in accuracy at extreme early or late gestational ages\n(GAs). To improve segmentation performance throughout gestation, we introduce\nAtlasSeg, a dual-U-shape convolution network that explicitly integrates\nGA-specific information as guidance. By providing a publicly available fetal\nbrain atlas with segmentation labels corresponding to relevant GAs, AtlasSeg\neffectively extracts age-specific patterns in the atlas branch and generates\nprecise tissue segmentation in the segmentation branch. Multi-scale spatial\nattention feature fusions are constructed during both encoding and decoding\nstages to enhance feature flow and facilitate better information interactions\nbetween two branches. We compared AtlasSeg with six well-established networks\nin a seven-tissue segmentation task, achieving the highest average Dice\nsimilarity coefficient of 0.91. The improvement was particularly evident in\nextreme early or late GA cases, where training data was scare. Furthermore,\nAtlasSeg exhibited minimal performance degradation on low-quality images with\ncontrast changes and noise, attributed to its anatomical shape priors. Overall,\nAtlasSeg demonstrated enhanced segmentation accuracy, better consistency across\nfetal ages, and robustness to perturbations, making it a powerful tool for\nreliable fetal brain MRI tissue segmentation, particularly suited for\ndiagnostic assessments during early gestation.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02867v2",
    "published_date": "2024-11-05 07:16:32 UTC",
    "updated_date": "2025-03-11 02:25:55 UTC"
  },
  {
    "arxiv_id": "2411.02864v1",
    "title": "Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning",
    "authors": [
      "Tao Zhang",
      "Ning Yan",
      "Masood Mortazavi",
      "Hoang H. Nguyen",
      "Zhongfen Deng",
      "Philip S. Yu"
    ],
    "abstract": "Large language models (LLMs) pre-trained on massive corpora have demonstrated\nimpressive few-shot learning capability on many NLP tasks. Recasting an NLP\ntask into a text-to-text generation task is a common practice so that\ngenerative LLMs can be prompted to resolve it. However, performing\ndocument-level relation extraction (DocRE) tasks with generative LLM models is\nstill challenging due to the structured output format of DocRE, which\ncomplicates the conversion to plain text. Limited information available in\nfew-shot samples and prompt instructions induce further difficulties and\nchallenges in relation extraction for mentioned entities in a document. In this\npaper, we represent the structured output as a graph-style triplet rather than\nnatural language expressions and leverage generative LLMs for the DocRE task.\nOur approach, the Graph-DPEP framework is grounded in the reasoning behind\ntriplet explanation thoughts presented in natural language. In this framework,\nwe first introduce a ``decomposed-plug\" method for performing the generation\nfrom LLMs over prompts with type-space decomposition to alleviate the burden of\ndistinguishing all relation types. Second, we employ a verifier for calibrating\nthe generation and identifying overlooked query entity pairs. Third, we develop\n\"ensemble-play\", reapplying generation on the entire type list by leveraging\nthe reasoning thoughts embedded in a sub-graph associated with the missing\nquery pair to address the missingness issue. Through extensive comparisons with\nexisting prompt techniques and alternative Language Models (LLMs), our\nframework demonstrates superior performance on publicly available benchmarks in\nexperiments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02864v1",
    "published_date": "2024-11-05 07:12:36 UTC",
    "updated_date": "2024-11-05 07:12:36 UTC"
  },
  {
    "arxiv_id": "2411.03365v1",
    "title": "Enhanced Real-Time Threat Detection in 5G Networks: A Self-Attention RNN Autoencoder Approach for Spectral Intrusion Analysis",
    "authors": [
      "Mohammadreza Kouchaki",
      "Minglong Zhang",
      "Aly S. Abdalla",
      "Guangchen Lan",
      "Christopher G. Brinton",
      "Vuk Marojevic"
    ],
    "abstract": "In the rapidly evolving landscape of 5G technology, safeguarding Radio\nFrequency (RF) environments against sophisticated intrusions is paramount,\nespecially in dynamic spectrum access and management. This paper presents an\nenhanced experimental model that integrates a self-attention mechanism with a\nRecurrent Neural Network (RNN)-based autoencoder for the detection of anomalous\nspectral activities in 5G networks at the waveform level. Our approach,\ngrounded in time-series analysis, processes in-phase and quadrature (I/Q)\nsamples to identify irregularities that could indicate potential jamming\nattacks. The model's architecture, augmented with a self-attention layer,\nextends the capabilities of RNN autoencoders, enabling a more nuanced\nunderstanding of temporal dependencies and contextual relationships within the\nRF spectrum. Utilizing a simulated 5G Radio Access Network (RAN) test-bed\nconstructed with srsRAN 5G and Software Defined Radios (SDRs), we generated a\ncomprehensive stream of data that reflects real-world RF spectrum conditions\nand attack scenarios. The model is trained to reconstruct standard signal\nbehavior, establishing a normative baseline against which deviations,\nindicative of security threats, are identified. The proposed architecture is\ndesigned to balance between detection precision and computational efficiency,\nso the LSTM network, enriched with self-attention, continues to optimize for\nminimal execution latency and power consumption. Conducted on a real-world\nSDR-based testbed, our results demonstrate the model's improved performance and\naccuracy in threat detection.\n  Keywords: self-attention, real-time intrusion detection, RNN autoencoder,\nTransformer architecture, LSTM, time series anomaly detection, 5G Security,\nspectrum access security.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "This article has been accepted for publication in WiOpt 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.03365v1",
    "published_date": "2024-11-05 07:01:15 UTC",
    "updated_date": "2024-11-05 07:01:15 UTC"
  },
  {
    "arxiv_id": "2411.02851v1",
    "title": "Learning to Unify Audio, Visual and Text for Audio-Enhanced Multilingual Visual Answer Localization",
    "authors": [
      "Zhibin Wen",
      "Bin Li"
    ],
    "abstract": "The goal of Multilingual Visual Answer Localization (MVAL) is to locate a\nvideo segment that answers a given multilingual question. Existing methods\neither focus solely on visual modality or integrate visual and subtitle\nmodalities. However, these methods neglect the audio modality in videos,\nconsequently leading to incomplete input information and poor performance in\nthe MVAL task. In this paper, we propose a unified Audio-Visual-Textual Span\nLocalization (AVTSL) method that incorporates audio modality to augment both\nvisual and textual representations for the MVAL task. Specifically, we\nintegrate features from three modalities and develop three predictors, each\ntailored to the unique contributions of the fused modalities: an audio-visual\npredictor, a visual predictor, and a textual predictor. Each predictor\ngenerates predictions based on its respective modality. To maintain consistency\nacross the predicted results, we introduce an Audio-Visual-Textual Consistency\nmodule. This module utilizes a Dynamic Triangular Loss (DTL) function, allowing\neach modality's predictor to dynamically learn from the others. This\ncollaborative learning ensures that the model generates consistent and\ncomprehensive answers. Extensive experiments show that our proposed method\noutperforms several state-of-the-art (SOTA) methods, which demonstrates the\neffectiveness of the audio modality.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02851v1",
    "published_date": "2024-11-05 06:49:14 UTC",
    "updated_date": "2024-11-05 06:49:14 UTC"
  },
  {
    "arxiv_id": "2411.02850v2",
    "title": "WASHtsApp -- A RAG-powered WhatsApp Chatbot for supporting rural African clean water access, sanitation and hygiene",
    "authors": [
      "Simon Kloker",
      "Alex Cedric Luyima",
      "Matthew Bazanya"
    ],
    "abstract": "This paper introduces WASHtsApp, a WhatsApp-based chatbot designed to educate\nrural African communities on clean water access, sanitation, and hygiene (WASH)\nprinciples. WASHtsApp leverages a Retrieval-Augmented Generation (RAG) approach\nto address the limitations of previous approaches with limited reach or missing\ncontextualization. The paper details the development process, employing Design\nScience Research Methodology. The evaluation consisted of two phases: content\nvalidation by four WASH experts and community validation by potential users.\nContent validation confirmed WASHtsApp's ability to provide accurate and\nrelevant WASH-related information. Community validation indicated high user\nacceptance and perceived usefulness of the chatbot. The paper concludes by\ndiscussing the potential for further development, including incorporating local\nlanguages and user data analysis for targeted interventions. It also proposes\nfuture research cycles focused on wider deployment and leveraging user data for\neducational purposes.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.CY",
    "comment": "Working Paper. Accepted at IST-Africa Conference 2025, Nairobi",
    "pdf_url": "http://arxiv.org/pdf/2411.02850v2",
    "published_date": "2024-11-05 06:44:15 UTC",
    "updated_date": "2025-02-18 10:43:41 UTC"
  },
  {
    "arxiv_id": "2411.02847v3",
    "title": "Dissecting the Failure of Invariant Learning on Graphs",
    "authors": [
      "Qixun Wang",
      "Yifei Wang",
      "Yisen Wang",
      "Xianghua Ying"
    ],
    "abstract": "Enhancing node-level Out-Of-Distribution (OOD) generalization on graphs\nremains a crucial area of research. In this paper, we develop a Structural\nCausal Model (SCM) to theoretically dissect the performance of two prominent\ninvariant learning methods -- Invariant Risk Minimization (IRM) and\nVariance-Risk Extrapolation (VREx) -- in node-level OOD settings. Our analysis\nreveals a critical limitation: due to the lack of class-conditional invariance\nconstraints, these methods may struggle to accurately identify the structure of\nthe predictive invariant ego-graph and consequently rely on spurious features.\nTo address this, we propose Cross-environment Intra-class Alignment (CIA),\nwhich explicitly eliminates spurious features by aligning cross-environment\nrepresentations conditioned on the same class, bypassing the need for explicit\nknowledge of the causal pattern structure. To adapt CIA to node-level OOD\nscenarios where environment labels are hard to obtain, we further propose\nCIA-LRA (Localized Reweighting Alignment) that leverages the distribution of\nneighboring labels to selectively align node representations, effectively\ndistinguishing and preserving invariant features while removing spurious ones,\nall without relying on environment labels. We theoretically prove CIA-LRA's\neffectiveness by deriving an OOD generalization error bound based on\nPAC-Bayesian analysis. Experiments on graph OOD benchmarks validate the\nsuperiority of CIA and CIA-LRA, marking a significant advancement in node-level\nOOD generalization. The codes are available at\nhttps://github.com/NOVAglow646/NeurIPS24-Invariant-Learning-on-Graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02847v3",
    "published_date": "2024-11-05 06:36:48 UTC",
    "updated_date": "2025-01-03 10:55:51 UTC"
  },
  {
    "arxiv_id": "2411.02844v1",
    "title": "Correlation of Object Detection Performance with Visual Saliency and Depth Estimation",
    "authors": [
      "Matthias Bartolo",
      "Dylan Seychell"
    ],
    "abstract": "As object detection techniques continue to evolve, understanding their\nrelationships with complementary visual tasks becomes crucial for optimising\nmodel architectures and computational resources. This paper investigates the\ncorrelations between object detection accuracy and two fundamental visual\ntasks: depth prediction and visual saliency prediction. Through comprehensive\nexperiments using state-of-the-art models (DeepGaze IIE, Depth Anything,\nDPT-Large, and Itti's model) on COCO and Pascal VOC datasets, we find that\nvisual saliency shows consistently stronger correlations with object detection\naccuracy (mA$\\rho$ up to 0.459 on Pascal VOC) compared to depth prediction\n(mA$\\rho$ up to 0.283). Our analysis reveals significant variations in these\ncorrelations across object categories, with larger objects showing correlation\nvalues up to three times higher than smaller objects. These findings suggest\nincorporating visual saliency features into object detection architectures\ncould be more beneficial than depth information, particularly for specific\nobject categories. The observed category-specific variations also provide\ninsights for targeted feature engineering and dataset design improvements,\npotentially leading to more efficient and accurate object detection systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code Available at:\n  https://github.com/mbar0075/Object-Detection-Correlation-Saliency-vs-Depth",
    "pdf_url": "http://arxiv.org/pdf/2411.02844v1",
    "published_date": "2024-11-05 06:34:19 UTC",
    "updated_date": "2024-11-05 06:34:19 UTC"
  },
  {
    "arxiv_id": "2411.02832v2",
    "title": "PersianRAG: A Retrieval-Augmented Generation System for Persian Language",
    "authors": [
      "Hossein Hosseini",
      "Mohammad Sobhan Zare",
      "Amir Hossein Mohammadi",
      "Arefeh Kazemi",
      "Zahra Zojaji",
      "Mohammad Ali Nematbakhsh"
    ],
    "abstract": "Retrieval augmented generation (RAG) models, which integrate large-scale\npre-trained generative models with external retrieval mechanisms, have shown\nsignificant success in various natural language processing (NLP) tasks.\nHowever, applying RAG models in Persian language as a low-resource language,\nposes distinct challenges. These challenges primarily involve the\npreprocessing, embedding, retrieval, prompt construction, language modeling,\nand response evaluation of the system. In this paper, we address the challenges\ntowards implementing a real-world RAG system for Persian language called\nPersianRAG. We propose novel solutions to overcome these obstacles and evaluate\nour approach using several Persian benchmark datasets. Our experimental results\ndemonstrate the capability of the PersianRAG framework to enhance question\nanswering task in Persian.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02832v2",
    "published_date": "2024-11-05 06:11:17 UTC",
    "updated_date": "2024-11-06 11:19:42 UTC"
  },
  {
    "arxiv_id": "2411.02830v1",
    "title": "Mixtures of In-Context Learners",
    "authors": [
      "Giwon Hong",
      "Emile van Krieken",
      "Edoardo Ponti",
      "Nikolay Malkin",
      "Pasquale Minervini"
    ],
    "abstract": "In-context learning (ICL) adapts LLMs by providing demonstrations without\nfine-tuning the model parameters; however, it does not differentiate between\ndemonstrations and quadratically increases the complexity of Transformer LLMs,\nexhausting the memory. As a solution, we propose Mixtures of In-Context\nLearners (MoICL), a novel approach to treat subsets of demonstrations as\nexperts and learn a weighting function to merge their output distributions\nbased on a training set. In our experiments, we show performance improvements\non 5 out of 7 classification datasets compared to a set of strong baselines (up\nto +13\\% compared to ICL and LENS). Moreover, we enhance the Pareto frontier of\nICL by reducing the inference time needed to achieve the same performance with\nfewer demonstrations. Finally, MoICL is more robust to out-of-domain (up to\n+11\\%), imbalanced (up to +49\\%), or noisy demonstrations (up to +38\\%) or can\nfilter these out from datasets. Overall, MoICL is a more expressive approach to\nlearning from demonstrations without exhausting the context window or memory.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02830v1",
    "published_date": "2024-11-05 06:02:41 UTC",
    "updated_date": "2024-11-05 06:02:41 UTC"
  },
  {
    "arxiv_id": "2411.05823v2",
    "title": "FlexCAD: Unified and Versatile Controllable CAD Generation with Fine-tuned Large Language Models",
    "authors": [
      "Zhanwei Zhang",
      "Shizhao Sun",
      "Wenxiao Wang",
      "Deng Cai",
      "Jiang Bian"
    ],
    "abstract": "Recently, there is a growing interest in creating computer-aided design (CAD)\nmodels based on user intent, known as controllable CAD generation. Existing\nwork offers limited controllability and needs separate models for different\ntypes of control, reducing efficiency and practicality. To achieve controllable\ngeneration across all CAD construction hierarchies, such as sketch-extrusion,\nextrusion, sketch, face, loop and curve, we propose FlexCAD, a unified model by\nfine-tuning large language models (LLMs). First, to enhance comprehension by\nLLMs, we represent a CAD model as a structured text by abstracting each\nhierarchy as a sequence of text tokens. Second, to address various controllable\ngeneration tasks in a unified model, we introduce a hierarchy-aware masking\nstrategy. Specifically, during training, we mask a hierarchy-aware field in the\nCAD text with a mask token. This field, composed of a sequence of tokens, can\nbe set flexibly to represent various hierarchies. Subsequently, we ask LLMs to\npredict this masked field. During inference, the user intent is converted into\na CAD text with a mask token replacing the part the user wants to modify, which\nis then fed into FlexCAD to generate new CAD models. Comprehensive experiments\non public dataset demonstrate the effectiveness of FlexCAD in both generation\nquality and controllability. Code will be available at\nhttps://github.com/microsoft/FlexCAD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.05823v2",
    "published_date": "2024-11-05 05:45:26 UTC",
    "updated_date": "2025-02-17 03:04:57 UTC"
  },
  {
    "arxiv_id": "2411.02820v3",
    "title": "DroidSpeak: KV Cache Sharing for Cross-LLM Communication and Multi-LLM Serving",
    "authors": [
      "Yuhan Liu",
      "Yuyang Huang",
      "Jiayi Yao",
      "Zhuohan Gu",
      "Kuntai Du",
      "Hanchen Li",
      "Yihua Cheng",
      "Junchen Jiang",
      "Shan Lu",
      "Madan Musuvathi",
      "Esha Choukse"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly employed in complex workflows,\nwhere different LLMs and fine-tuned variants collaboratively address complex\ntasks. However, these systems face significant inefficiencies due to redundant\ncontext processing of the shared context. We propose DroidSpeak, a framework\nthat optimizes context sharing between fine-tuned LLMs derived from the same\nfoundational model. DroidSpeak identifies critical layers in the KV cache and\nselectively recomputes them, enabling effective reuse of intermediate data\nwhile maintaining high accuracy.\n  Our approach balances computational efficiency and task fidelity,\nsignificantly reducing inference latency and throughput bottlenecks.\nExperiments on diverse datasets and model pairs demonstrate that DroidSpeak\nachieves up to 3x higher throughputs and 2.6x faster prefill times with\nnegligible accuracy loss compared to full recomputation.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02820v3",
    "published_date": "2024-11-05 05:41:41 UTC",
    "updated_date": "2024-12-19 23:52:16 UTC"
  },
  {
    "arxiv_id": "2411.02817v1",
    "title": "Conditional Vendi Score: An Information-Theoretic Approach to Diversity Evaluation of Prompt-based Generative Models",
    "authors": [
      "Mohammad Jalali",
      "Azim Ospanov",
      "Amin Gohari",
      "Farzan Farnia"
    ],
    "abstract": "Text-conditioned generation models are commonly evaluated based on the\nquality of the generated data and its alignment with the input text prompt. On\nthe other hand, several applications of prompt-based generative models require\nsufficient diversity in the generated data to ensure the models' capability of\ngenerating image and video samples possessing a variety of features. However,\nmost existing diversity metrics are designed for unconditional generative\nmodels, and thus cannot distinguish the diversity arising from variations in\ntext prompts and that contributed by the generative model itself. In this work,\nour goal is to quantify the prompt-induced and model-induced diversity in\nsamples generated by prompt-based models. We propose an information-theoretic\napproach for internal diversity quantification, where we decompose the\nkernel-based entropy $H(X)$ of the generated data $X$ into the sum of the\nconditional entropy $H(X|T)$, given text variable $T$, and the mutual\ninformation $I(X; T)$ between the text and data variables. We introduce the\n\\emph{Conditional-Vendi} score based on $H(X|T)$ to quantify the internal\ndiversity of the model and the \\emph{Information-Vendi} score based on $I(X;\nT)$ to measure the statistical relevance between the generated data and text\nprompts. We provide theoretical results to statistically interpret these scores\nand relate them to the unconditional Vendi score. We conduct several numerical\nexperiments to show the correlation between the Conditional-Vendi score and the\ninternal diversity of text-conditioned generative models. The codebase is\navailable at\n\\href{https://github.com/mjalali/conditional-vendi}{https://github.com/mjalali/conditional-vendi}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "math.IT",
      "68T07"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02817v1",
    "published_date": "2024-11-05 05:30:39 UTC",
    "updated_date": "2024-11-05 05:30:39 UTC"
  },
  {
    "arxiv_id": "2411.02797v1",
    "title": "DeepContext: A Context-aware, Cross-platform, and Cross-framework Tool for Performance Profiling and Analysis of Deep Learning Workloads",
    "authors": [
      "Qidong Zhao",
      "Hao Wu",
      "Yuming Hao",
      "Zilingfeng Ye",
      "Jiajia Li",
      "Xu Liu",
      "Keren Zhou"
    ],
    "abstract": "Effective performance profiling and analysis are essential for optimizing\ntraining and inference of deep learning models, especially given the growing\ncomplexity of heterogeneous computing environments. However, existing tools\noften lack the capability to provide comprehensive program context information\nand performance optimization insights for sophisticated interactions between\nCPUs and GPUs. This paper introduces DeepContext, a novel profiler that links\nprogram contexts across high-level Python code, deep learning frameworks,\nunderlying libraries written in C/C++, as well as device code executed on GPUs.\nDeepContext incorporates measurements of both coarse- and fine-grained\nperformance metrics for major deep learning frameworks, such as PyTorch and\nJAX, and is compatible with GPUs from both Nvidia and AMD, as well as various\nCPU architectures, including x86 and ARM. In addition, DeepContext integrates a\nnovel GUI that allows users to quickly identify hotpots and an innovative\nautomated performance analyzer that suggests users with potential optimizations\nbased on performance metrics and program context. Through detailed use cases,\nwe demonstrate how DeepContext can help users identify and analyze performance\nissues to enable quick and effective optimization of deep learning workloads.\nWe believe Deep Context is a valuable tool for users seeking to optimize\ncomplex deep learning workflows across multiple compute environments.",
    "categories": [
      "cs.PF",
      "cs.AI"
    ],
    "primary_category": "cs.PF",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02797v1",
    "published_date": "2024-11-05 04:15:26 UTC",
    "updated_date": "2024-11-05 04:15:26 UTC"
  },
  {
    "arxiv_id": "2411.02796v2",
    "title": "Specialized Foundation Models Struggle to Beat Supervised Baselines",
    "authors": [
      "Zongzhe Xu",
      "Ritvik Gupta",
      "Wenduo Cheng",
      "Alexander Shen",
      "Junhong Shen",
      "Ameet Talwalkar",
      "Mikhail Khodak"
    ],
    "abstract": "Following its success for vision and text, the \"foundation model\" (FM)\nparadigm -- pretraining large models on massive data, then fine-tuning on\ntarget tasks -- has rapidly expanded to domains in the sciences, engineering,\nhealthcare, and beyond. Has this achieved what the original FMs accomplished,\ni.e. the supplanting of traditional supervised learning in their domains? To\nanswer we look at three modalities -- genomics, satellite imaging, and time\nseries -- with multiple recent FMs and compare them to a standard supervised\nlearning workflow: model development, hyperparameter tuning, and training, all\nusing only data from the target task. Across these three specialized domains,\nwe find that it is consistently possible to train simple supervised models --\nno more complicated than a lightly modified wide ResNet or UNet -- that match\nor even outperform the latest foundation models. Our work demonstrates that the\nbenefits of large-scale pretraining have yet to be realized in many specialized\nareas, reinforces the need to compare new FMs to strong, well-tuned baselines,\nand introduces two new, easy-to-use, open-source, and automated workflows for\ndoing so.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "The first two authors contributed equally. The order was determined\n  by coin flip",
    "pdf_url": "http://arxiv.org/pdf/2411.02796v2",
    "published_date": "2024-11-05 04:10:59 UTC",
    "updated_date": "2025-03-21 03:59:29 UTC"
  },
  {
    "arxiv_id": "2411.02795v1",
    "title": "The Evolution of RWKV: Advancements in Efficient Language Modeling",
    "authors": [
      "Akul Datta"
    ],
    "abstract": "This paper reviews the development of the Receptance Weighted Key Value\n(RWKV) architecture, emphasizing its advancements in efficient language\nmodeling. RWKV combines the training efficiency of Transformers with the\ninference efficiency of RNNs through a novel linear attention mechanism. We\nexamine its core innovations, adaptations across various domains, and\nperformance advantages over traditional models. The paper also discusses\nchallenges and future directions for RWKV as a versatile architecture in deep\nlearning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02795v1",
    "published_date": "2024-11-05 04:10:05 UTC",
    "updated_date": "2024-11-05 04:10:05 UTC"
  },
  {
    "arxiv_id": "2411.02791v1",
    "title": "Language Models and Cycle Consistency for Self-Reflective Machine Translation",
    "authors": [
      "Jianqiao Wangni"
    ],
    "abstract": "This paper introduces a novel framework that leverages large language models\n(LLMs) for machine translation (MT). We start with one conjecture: an ideal\ntranslation should contain complete and accurate information for a strong\nenough LLM to recover the original sentence. We generate multiple translation\ncandidates from a source language A to a target language B, and subsequently\ntranslate these candidates back to the original language A. By evaluating the\ncycle consistency between the original and back-translated sentences using\nmetrics such as token-level precision and accuracy, we implicitly estimate the\ntranslation quality in language B, without knowing its ground-truth. This also\nhelps to evaluate the LLM translation capability, only with monolingual\ncorpora. For each source sentence, we identify the translation candidate with\noptimal cycle consistency with the original sentence as the final answer. Our\nexperiments demonstrate that larger LLMs, or the same LLM with more forward\npasses during inference, exhibit increased cycle consistency, aligning with the\nLLM model size scaling law and test-time computation scaling law. This work\nprovide methods for, 1) to implicitly evaluate translation quality of a\nsentence in the target language, 2), to evaluate capability of LLM for\nany-to-any-language translation, and 3), how to generate a better translation\nfor a specific LLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02791v1",
    "published_date": "2024-11-05 04:01:41 UTC",
    "updated_date": "2024-11-05 04:01:41 UTC"
  },
  {
    "arxiv_id": "2411.02788v2",
    "title": "When to Localize? A Risk-Constrained Reinforcement Learning Approach",
    "authors": [
      "Chak Lam Shek",
      "Kasra Torshizi",
      "Troi Williams",
      "Pratap Tokekar"
    ],
    "abstract": "In a standard navigation pipeline, a robot localizes at every time step to\nlower navigational errors. However, in some scenarios, a robot needs to\nselectively localize when it is expensive to obtain observations. For example,\nan underwater robot surfacing to localize too often hinders it from searching\nfor critical items underwater, such as black boxes from crashed aircraft. On\nthe other hand, if the robot never localizes, poor state estimates cause\nfailure to find the items due to inadvertently leaving the search area or\nentering hazardous, restricted areas. Motivated by these scenarios, we\ninvestigate approaches to help a robot determine \"when to localize?\" We\nformulate this as a bi-criteria optimization problem: minimize the number of\nlocalization actions while ensuring the probability of failure (due to\ncollision or not reaching a desired goal) remains bounded. In recent work, we\nshowed how to formulate this active localization problem as a constrained\nPartially Observable Markov Decision Process (POMDP), which was solved using an\nonline POMDP solver. However, this approach is too slow and requires full\nknowledge of the robot transition and observation models. In this paper, we\npresent RiskRL, a constrained Reinforcement Learning (RL) framework that\novercomes these limitations. RiskRL uses particle filtering and recurrent Soft\nActor-Critic network to learn a policy that minimizes the number of\nlocalizations while ensuring the probability of failure constraint is met. Our\nnumerical experiments show that RiskRL learns a robust policy that leads to at\nleast a 26% increase in success rates when traversing unseen test environments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02788v2",
    "published_date": "2024-11-05 03:54:00 UTC",
    "updated_date": "2025-04-29 19:14:29 UTC"
  },
  {
    "arxiv_id": "2411.02785v2",
    "title": "Stochastic Monkeys at Play: Random Augmentations Cheaply Break LLM Safety Alignment",
    "authors": [
      "Jason Vega",
      "Junsheng Huang",
      "Gaokai Zhang",
      "Hangoo Kang",
      "Minjia Zhang",
      "Gagandeep Singh"
    ],
    "abstract": "Safety alignment of Large Language Models (LLMs) has recently become a\ncritical objective of model developers. In response, a growing body of work has\nbeen investigating how safety alignment can be bypassed through various\njailbreaking methods, such as adversarial attacks. However, these jailbreak\nmethods can be rather costly or involve a non-trivial amount of creativity and\neffort, introducing the assumption that malicious users are high-resource or\nsophisticated. In this paper, we study how simple random augmentations to the\ninput prompt affect safety alignment effectiveness in state-of-the-art LLMs,\nsuch as Llama 3 and Qwen 2. We perform an in-depth evaluation of 17 different\nmodels and investigate the intersection of safety under random augmentations\nwith multiple dimensions: augmentation type, model size, quantization,\nfine-tuning-based defenses, and decoding strategies (e.g., sampling\ntemperature). We show that low-resource and unsophisticated attackers, i.e.\n$\\textit{stochastic monkeys}$, can significantly improve their chances of\nbypassing alignment with just 25 random augmentations per prompt. Source code\nand data: https://github.com/uiuc-focal-lab/stochastic-monkeys/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "v2: Updated with changes from peer review rebuttal. v1: Version under\n  peer review",
    "pdf_url": "http://arxiv.org/pdf/2411.02785v2",
    "published_date": "2024-11-05 03:51:13 UTC",
    "updated_date": "2024-12-05 12:58:44 UTC"
  },
  {
    "arxiv_id": "2411.02762v1",
    "title": "EcoCropsAID: Economic Crops Aerial Image Dataset for Land Use Classification",
    "authors": [
      "Sangdaow Noppitak",
      "Emmanuel Okafor",
      "Olarik Surinta"
    ],
    "abstract": "The EcoCropsAID dataset is a comprehensive collection of 5,400 aerial images\ncaptured between 2014 and 2018 using the Google Earth application. This dataset\nfocuses on five key economic crops in Thailand: rice, sugarcane, cassava,\nrubber, and longan. The images were collected at various crop growth stages:\nearly cultivation, growth, and harvest, resulting in significant variability\nwithin each category and similarities across different categories. These\nvariations, coupled with differences in resolution, color, and contrast\nintroduced by multiple remote imaging sensors, present substantial challenges\nfor land use classification. The dataset is an interdisciplinary resource that\nspans multiple research domains, including remote sensing, geoinformatics,\nartificial intelligence, and computer vision. The unique features of the\nEcoCropsAID dataset offer opportunities for researchers to explore novel\napproaches, such as extracting spatial and temporal features, developing deep\nlearning architectures, and implementing transformer-based models. The\nEcoCropsAID dataset provides a valuable platform for advancing research in land\nuse classification, with implications for optimizing agricultural practices and\nenhancing sustainable development. This study explicitly investigates the use\nof deep learning algorithms to classify economic crop areas in northeastern\nThailand, utilizing satellite imagery to address the challenges posed by\ndiverse patterns and similarities across categories.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.02762v1",
    "published_date": "2024-11-05 03:14:36 UTC",
    "updated_date": "2024-11-05 03:14:36 UTC"
  },
  {
    "arxiv_id": "2411.05027v1",
    "title": "Generative Artificial Intelligence Meets Synthetic Aperture Radar: A Survey",
    "authors": [
      "Zhongling Huang",
      "Xidan Zhang",
      "Zuqian Tang",
      "Feng Xu",
      "Mihai Datcu",
      "Junwei Han"
    ],
    "abstract": "SAR images possess unique attributes that present challenges for both human\nobservers and vision AI models to interpret, owing to their electromagnetic\ncharacteristics. The interpretation of SAR images encounters various hurdles,\nwith one of the primary obstacles being the data itself, which includes issues\nrelated to both the quantity and quality of the data. The challenges can be\naddressed using generative AI technologies. Generative AI, often known as\nGenAI, is a very advanced and powerful technology in the field of artificial\nintelligence that has gained significant attention. The advancement has created\npossibilities for the creation of texts, photorealistic pictures, videos, and\nmaterial in various modalities. This paper aims to comprehensively investigate\nthe intersection of GenAI and SAR. First, we illustrate the common data\ngeneration-based applications in SAR field and compare them with computer\nvision tasks, analyzing the similarity, difference, and general challenges of\nthem. Then, an overview of the latest GenAI models is systematically reviewed,\nincluding various basic models and their variations targeting the general\nchallenges. Additionally, the corresponding applications in SAR domain are also\nincluded. Specifically, we propose to summarize the physical model based\nsimulation approaches for SAR, and analyze the hybrid modeling methods that\ncombine the GenAI and interpretable models. The evaluation methods that have\nbeen or could be applied to SAR, are also explored. Finally, the potential\nchallenges and future prospects are discussed. To our best knowledge, this\nsurvey is the first exhaustive examination of the interdiscipline of SAR and\nGenAI, encompassing a wide range of topics, including deep neural networks,\nphysical models, computer vision, and SAR images. The resources of this survey\nare open-source at \\url{https://github.com/XAI4SAR/GenAIxSAR}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05027v1",
    "published_date": "2024-11-05 03:06:00 UTC",
    "updated_date": "2024-11-05 03:06:00 UTC"
  },
  {
    "arxiv_id": "2411.02746v1",
    "title": "A Bayesian explanation of machine learning models based on modes and functional ANOVA",
    "authors": [
      "Quan Long"
    ],
    "abstract": "Most methods in explainable AI (XAI) focus on providing reasons for the\nprediction of a given set of features. However, we solve an inverse explanation\nproblem, i.e., given the deviation of a label, find the reasons of this\ndeviation. We use a Bayesian framework to recover the ``true'' features,\nconditioned on the observed label value. We efficiently explain the deviation\nof a label value from the mode, by identifying and ranking the influential\nfeatures using the ``distances'' in the ANOVA functional decomposition. We show\nthat the new method is more human-intuitive and robust than methods based on\nmean values, e.g., SHapley Additive exPlanations (SHAP values). The extra costs\nof solving a Bayesian inverse problem are dimension-independent.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.CO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02746v1",
    "published_date": "2024-11-05 02:32:26 UTC",
    "updated_date": "2024-11-05 02:32:26 UTC"
  },
  {
    "arxiv_id": "2411.03359v1",
    "title": "Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection",
    "authors": [
      "Geng Yu",
      "Jianing Zhu",
      "Jiangchao Yao",
      "Bo Han"
    ],
    "abstract": "Out-of-distribution (OOD) detection is crucial for deploying reliable machine\nlearning models in open-world applications. Recent advances in CLIP-based OOD\ndetection have shown promising results via regularizing prompt tuning with OOD\nfeatures extracted from ID data. However, the irrelevant context mined from ID\ndata can be spurious due to the inaccurate foreground-background decomposition,\nthus limiting the OOD detection performance. In this work, we propose a novel\nframework, namely, Self-Calibrated Tuning (SCT), to mitigate this problem for\neffective OOD detection with only the given few-shot ID data. Specifically, SCT\nintroduces modulating factors respectively on the two components of the\noriginal learning objective. It adaptively directs the optimization process\nbetween the two tasks during training on data with different prediction\nuncertainty to calibrate the influence of OOD regularization, which is\ncompatible with many prompt tuning based OOD detection methods. Extensive\nexperiments and analyses have been conducted to characterize and demonstrate\nthe effectiveness of the proposed SCT. The code is publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.03359v1",
    "published_date": "2024-11-05 02:29:16 UTC",
    "updated_date": "2024-11-05 02:29:16 UTC"
  },
  {
    "arxiv_id": "2411.02722v1",
    "title": "Multimodal Commonsense Knowledge Distillation for Visual Question Answering",
    "authors": [
      "Shuo Yang",
      "Siwen Luo",
      "Soyeon Caren Han"
    ],
    "abstract": "Existing Multimodal Large Language Models (MLLMs) and Visual Language\nPretrained Models (VLPMs) have shown remarkable performances in the general\nVisual Question Answering (VQA). However, these models struggle with VQA\nquestions that require external commonsense knowledge due to the challenges in\ngenerating high-quality prompts and the high computational costs of\nfine-tuning. In this work, we propose a novel graph-based multimodal\ncommonsense knowledge distillation framework that constructs a unified\nrelational graph over commonsense knowledge, visual objects and questions\nthrough a Graph Convolutional Network (GCN) following a teacher-student\nenvironment. This proposed framework is flexible with any type of teacher and\nstudent models without further fine-tuning, and has achieved competitive\nperformances on the ScienceQA dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "AAAI 2025 (Accepted, Oral)",
    "pdf_url": "http://arxiv.org/pdf/2411.02722v1",
    "published_date": "2024-11-05 01:37:16 UTC",
    "updated_date": "2024-11-05 01:37:16 UTC"
  },
  {
    "arxiv_id": "2411.02714v1",
    "title": "Game Plot Design with an LLM-powered Assistant: An Empirical Study with Game Designers",
    "authors": [
      "Seyed Hossein Alavi",
      "Weijia Xu",
      "Nebojsa Jojic",
      "Daniel Kennett",
      "Raymond T. Ng",
      "Sudha Rao",
      "Haiyan Zhang",
      "Bill Dolan",
      "Vered Shwartz"
    ],
    "abstract": "We introduce GamePlot, an LLM-powered assistant that supports game designers\nin crafting immersive narratives for turn-based games, and allows them to test\nthese games through a collaborative game play and refine the plot throughout\nthe process. Our user study with 14 game designers shows high levels of both\nsatisfaction with the generated game plots and sense of ownership over the\nnarratives, but also reconfirms that LLM are limited in their ability to\ngenerate complex and truly innovative content. We also show that diverse user\npopulations have different expectations from AI assistants, and encourage\nresearchers to study how tailoring assistants to diverse user groups could\npotentially lead to increased job satisfaction and greater creativity and\ninnovation over time.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02714v1",
    "published_date": "2024-11-05 01:26:35 UTC",
    "updated_date": "2024-11-05 01:26:35 UTC"
  },
  {
    "arxiv_id": "2411.02712v1",
    "title": "V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization",
    "authors": [
      "Yuxi Xie",
      "Guanzhen Li",
      "Xiao Xu",
      "Min-Yen Kan"
    ],
    "abstract": "Large vision-language models (LVLMs) suffer from hallucination, resulting in\nmisalignment between the output textual response and the input visual content.\nRecent research indicates that the over-reliance on the Large Language Model\n(LLM) backbone, as one cause of the LVLM hallucination, inherently introduces\nbias from language priors, leading to insufficient context attention to the\nvisual inputs.\n  We tackle this issue of hallucination by mitigating such over-reliance\nthrough preference learning. We propose Vision-guided Direct Preference\nOptimization (V-DPO) to enhance visual context learning at training time. To\ninterpret the effectiveness and generalizability of V-DPO on different types of\ntraining data, we construct a synthetic dataset containing both response- and\nimage-contrast preference pairs, compared against existing human-annotated\nhallucination samples. Our approach achieves significant improvements compared\nwith baseline methods across various hallucination benchmarks. Our analysis\nindicates that V-DPO excels in learning from image-contrast preference data,\ndemonstrating its superior ability to elicit and understand nuances of visual\ncontext. Our code is publicly available at https://github.com/YuxiXie/V-DPO.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "EMNLP 2024 Findings; 9 pages, 6 figures, 5 tables (16 pages, 8\n  figures, 8 tables including references and appendices)",
    "pdf_url": "http://arxiv.org/pdf/2411.02712v1",
    "published_date": "2024-11-05 01:24:37 UTC",
    "updated_date": "2024-11-05 01:24:37 UTC"
  },
  {
    "arxiv_id": "2411.02708v1",
    "title": "Exploring Response Uncertainty in MLLMs: An Empirical Evaluation under Misleading Scenarios",
    "authors": [
      "Yunkai Dang",
      "Mengxi Gao",
      "Yibo Yan",
      "Xin Zou",
      "Yanggan Gu",
      "Aiwei Liu",
      "Xuming Hu"
    ],
    "abstract": "Ensuring that Multimodal Large Language Models (MLLMs) maintain consistency\nin their responses is essential for developing trustworthy multimodal\nintelligence. However, existing benchmarks include many samples where all MLLMs\n\\textit{exhibit high response uncertainty when encountering misleading\ninformation}, requiring even 5-15 response attempts per sample to effectively\nassess uncertainty. Therefore, we propose a two-stage pipeline: first, we\ncollect MLLMs' responses without misleading information, and then gather\nmisleading ones via specific misleading instructions. By calculating the\nmisleading rate, and capturing both correct-to-incorrect and\nincorrect-to-correct shifts between the two sets of responses, we can\neffectively metric the model's response uncertainty. Eventually, we establish a\n\\textbf{\\underline{M}}ultimodal \\textbf{\\underline{U}}ncertainty\n\\textbf{\\underline{B}}enchmark (\\textbf{MUB}) that employs both explicit and\nimplicit misleading instructions to comprehensively assess the vulnerability of\nMLLMs across diverse domains. Our experiments reveal that all open-source and\nclose-source MLLMs are highly susceptible to misleading instructions, with an\naverage misleading rate exceeding 86\\%. To enhance the robustness of MLLMs, we\nfurther fine-tune all open-source MLLMs by incorporating explicit and implicit\nmisleading data, which demonstrates a significant reduction in misleading\nrates. Our code is available at:\n\\href{https://github.com/Yunkai696/MUB}{https://github.com/Yunkai696/MUB}",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02708v1",
    "published_date": "2024-11-05 01:11:28 UTC",
    "updated_date": "2024-11-05 01:11:28 UTC"
  },
  {
    "arxiv_id": "2411.02704v1",
    "title": "RT-Affordance: Affordances are Versatile Intermediate Representations for Robot Manipulation",
    "authors": [
      "Soroush Nasiriany",
      "Sean Kirmani",
      "Tianli Ding",
      "Laura Smith",
      "Yuke Zhu",
      "Danny Driess",
      "Dorsa Sadigh",
      "Ted Xiao"
    ],
    "abstract": "We explore how intermediate policy representations can facilitate\ngeneralization by providing guidance on how to perform manipulation tasks.\nExisting representations such as language, goal images, and trajectory sketches\nhave been shown to be helpful, but these representations either do not provide\nenough context or provide over-specified context that yields less robust\npolicies. We propose conditioning policies on affordances, which capture the\npose of the robot at key stages of the task. Affordances offer expressive yet\nlightweight abstractions, are easy for users to specify, and facilitate\nefficient learning by transferring knowledge from large internet datasets. Our\nmethod, RT-Affordance, is a hierarchical model that first proposes an\naffordance plan given the task language, and then conditions the policy on this\naffordance plan to perform manipulation. Our model can flexibly bridge\nheterogeneous sources of supervision including large web datasets and robot\ntrajectories. We additionally train our model on cheap-to-collect in-domain\naffordance images, allowing us to learn new tasks without collecting any\nadditional costly robot trajectories. We show on a diverse set of novel tasks\nhow RT-Affordance exceeds the performance of existing methods by over 50%, and\nwe empirically demonstrate that affordances are robust to novel settings.\nVideos available at https://snasiriany.me/rt-affordance",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02704v1",
    "published_date": "2024-11-05 01:02:51 UTC",
    "updated_date": "2024-11-05 01:02:51 UTC"
  },
  {
    "arxiv_id": "2411.02695v1",
    "title": "JEL: Applying End-to-End Neural Entity Linking in JPMorgan Chase",
    "authors": [
      "Wanying Ding",
      "Vinay K. Chaudhri",
      "Naren Chittar",
      "Krishna Konakanchi"
    ],
    "abstract": "Knowledge Graphs have emerged as a compelling abstraction for capturing key\nrelationship among the entities of interest to enterprises and for integrating\ndata from heterogeneous sources. JPMorgan Chase (JPMC) is leading this trend by\nleveraging knowledge graphs across the organization for multiple mission\ncritical applications such as risk assessment, fraud detection, investment\nadvice, etc. A core problem in leveraging a knowledge graph is to link mentions\n(e.g., company names) that are encountered in textual sources to entities in\nthe knowledge graph. Although several techniques exist for entity linking, they\nare tuned for entities that exist in Wikipedia, and fail to generalize for the\nentities that are of interest to an enterprise. In this paper, we propose a\nnovel end-to-end neural entity linking model (JEL) that uses minimal context\ninformation and a margin loss to generate entity embeddings, and a Wide & Deep\nLearning model to match character and semantic information respectively. We\nshow that JEL achieves the state-of-the-art performance to link mentions of\ncompany names in financial news with entities in our knowledge graph. We report\non our efforts to deploy this model in the company-wide system to generate\nalerts in response to financial news. The methodology used for JEL is directly\napplicable and usable by other enterprises who need entity linking solutions\nfor data that are unique to their respective situations.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "8 pages, 4 figures, IAAI-21",
    "pdf_url": "http://arxiv.org/pdf/2411.02695v1",
    "published_date": "2024-11-05 00:46:25 UTC",
    "updated_date": "2024-11-05 00:46:25 UTC"
  },
  {
    "arxiv_id": "2411.02692v1",
    "title": "JPEC: A Novel Graph Neural Network for Competitor Retrieval in Financial Knowledge Graphs",
    "authors": [
      "Wanying Ding",
      "Manoj Cherukumalli",
      "Santosh Chikoti",
      "Vinay K. Chaudhri"
    ],
    "abstract": "Knowledge graphs have gained popularity for their ability to organize and\nanalyze complex data effectively. When combined with graph embedding\ntechniques, such as graph neural networks (GNNs), knowledge graphs become a\npotent tool in providing valuable insights. This study explores the application\nof graph embedding in identifying competitors from a financial knowledge graph.\nExisting state-of-the-art(SOTA) models face challenges due to the unique\nattributes of our knowledge graph, including directed and undirected\nrelationships, attributed nodes, and minimal annotated competitor connections.\nTo address these challenges, we propose a novel graph embedding model,\nJPEC(JPMorgan Proximity Embedding for Competitor Detection), which utilizes\ngraph neural network to learn from both first-order and second-order node\nproximity together with vital features for competitor retrieval. JPEC had\noutperformed most existing models in extensive experiments, showcasing its\neffectiveness in competitor retrieval.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.IR",
    "comment": "5 pages, 4 figures, accepted by SIGIR'24",
    "pdf_url": "http://arxiv.org/pdf/2411.02692v1",
    "published_date": "2024-11-05 00:39:22 UTC",
    "updated_date": "2024-11-05 00:39:22 UTC"
  }
]