{
  "date": "2025-03-23",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-23 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 上的论文热点集中在大型语言模型（LLM）的对齐、安全性和效率，以及多模态模型的应用与评估。特别值得关注的是 LLM 在协作、推理、文化适应性方面的研究，以及针对幻觉、越狱攻击的检测与防御。此外，AI 系统的监管（特别是欧盟 AI 法案）和伦理问题也得到了探讨。一些有趣的工作包括利用 AI 进行协作研究（AgentRxiv）、基于物理信息的数字孪生重建、以及探索 LLM 在跨文化数学问题上的表现。\n\n**重点论文概览：**\n\n*   **AI 协作新范式：** 来自 Sinan Aral 团队的实验揭示了人与 AI 协作能显著提高沟通量和生产力，但也指出了 AI 在多模态任务（如图像质量）上的局限性，并发现 AI 个性与人类个性的匹配会影响协作效果 (论文 2)。\n*   **LLM 自主研究协作平台 AgentRxiv：** 提出一个让 LLM Agent 实验室共享研究成果、迭代改进的框架，实验表明协作和借鉴先前研究能加速 AI 推理能力的提升 (论文 26)。\n*   **RLHF 的双刃剑：** 多篇论文探讨了 RLHF（基于人类反馈的强化学习）在对齐 LLM 时的利弊。虽然能提升模型表现，但也可能导致奖励过度优化 (论文 24)、产生更易被检测的文本 (论文 49)、牺牲基础能力（如帮助性和无害性）并增加推理成本 (论文 42)。SRMIR (论文 23) 提出使用影子奖励模型和内省推理来改进对齐，BSPO (论文 24) 则通过行为支持正则化缓解过度优化。\n*   **LLM 安全攻防战：** STShield (论文 59) 提出一种轻量级的单 Token 哨兵机制，实时检测 LLM 的越狱行为。MJA (论文 37) 则探索了基于隐喻的越狱攻击方法。ShED-HD (论文 1) 提出轻量级幻觉检测框架，适用于边缘设备。\n*   **文化背景影响 LLM 数学推理？** 一项研究发现，即使数学逻辑不变，将数学问题嵌入不同的文化背景（如人名、地名）也会影响 LLM 的表现，特别是小型模型，揭示了训练数据文化多样性的重要性 (论文 32)。\n*   **视觉模型新进展：** LocDiffusion (论文 22) 提出一种新颖的基于扩散模型的图像地理定位方法。PhysTwin (论文 46) 利用物理信息从视频重建可交互的变形物体数字孪生。PG-SAM (论文 5) 提出用医学 LLM 的细粒度文本先验指导 SAM 进行多器官分割。\n*   **AI 监管与伦理：** 两篇论文关注欧盟 AI 法案，一篇提出 AI 人权影响评估框架 HH4AI (论文 12)，另一篇分析了生成式 AI 水印技术的采用现状及其法律含义 (论文 20)。还有论文从国际法角度论证了监管 AI 以应对灾难性风险的义务 (论文 51)。\n\n---\n\n**详细论文介绍：**\n\n1.  **ShED-HD: 轻量级边缘设备幻觉检测的香农熵分布框架 (ShED-HD: A Shannon Entropy Distribution Framework for Lightweight Hallucination Detection on Edge Devices)**\n    *   **问题:** 现有 LLM 幻觉检测方法要么计算成本高，要么牺牲准确性，不适用于资源受限的边缘设备。\n    *   **方法:** 提出 ShED-HD 框架，使用轻量级 BiLSTM 结构和单头注意力，通过分类序列级别的熵模式来检测幻觉。它能高效捕捉整个输出序列的不确定性模式。\n    *   **贡献:** 在三个数据集上的评估表明，ShED-HD 在分布外设置中显著优于其他计算高效方法，在分布内设置中性能相当，为资源受限环境提供了低成本、准确且可泛化的幻觉检测方案。\n\n2.  **与 AI Agent 协作：关于团队合作、生产力和绩效的现场实验 (Collaborating with AI Agents: Field Experiments on Teamwork, Productivity, and Performance)**\n    *   **问题:** AI Agent 如何改变生产力、绩效和工作流程？\n    *   **方法:** 构建 MindMeld 实验平台，让 2310 名参与者随机分配到人-人或人-AI 团队（AI 具有随机个性特征）完成广告制作任务。分析了沟通、协作和工作流日志。\n    *   **发现:** 与 AI 协作使沟通量增加 137%，人类更专注于内容生成而非直接编辑。人-AI 团队社交消息减少 23%，人均生产力提高 60%，广告文案质量更高。但人-人团队图像质量更高。AI 个性与人类个性互补可增强协作。总体而言，人-AI 团队广告效果与人-人团队相似。AI Agent 可改善团队合作和生产力，尤其当其特性与人类互补时。\n\n3.  **使用先进机器学习技术和过采样方法增强脊柱手术结果预测 (Enhanced prediction of spine surgery outcomes using advanced machine learning techniques and oversampling methods)**\n    *   **贡献:** 提出一种结合过采样（RandomOverSampler, SMOTE）和网格搜索优化的机器学习方法来预测脊柱手术结果。在包含术前、心理测量、社会经济和分析变量的数据集上，增强的 KNN 模型准确率达 76%，F1 分数达 67%。\n\n4.  **自适应多保真度强化学习用于工程设计优化中的方差缩减 (Adaptive Multi-Fidelity Reinforcement Learning for Variance Reduction in Engineering Design Optimization)**\n    *   **问题:** 传统多保真度 RL 依赖模型层次结构，当模型误差分布不均匀时会增加策略学习的方差。\n    *   **方法:** 提出一种自适应多保真度 RL 框架，动态利用多个异构、非分层的低保真模型和一个高保真模型。根据低保真策略与高保真策略的一致性，自适应地使用低保真经验数据进行高效的目标学习。\n    *   **贡献:** 在八旋翼飞行器设计优化问题中验证，该方法显著减少了策略学习方差，改善了收敛性，并无需手动调整模型使用计划。\n\n5.  **PG-SAM: 带有医学先验指导的 SAM 用于多器官分割 (PG-SAM: Prior-Guided SAM with Medical for Multi-organ Segmentation)**\n    *   **问题:** SAM 在医学图像分割上准确性和鲁棒性下降，现有融合文本和图像的方法受文本粒度和领域差距影响。\n    *   **方法:** 提出 PG-SAM，利用细粒度的模态先验对齐器，结合医学 LLM 生成的细粒度文本来弥合领域差距，提升先验质量。解码器通过多级特征融合和迭代掩码优化器增强表达能力。\n    *   **贡献:** 在 Synapse 数据集上取得 SOTA 性能，为 SAM 提供了高质量语义信息，支持无提示学习。\n\n6.  **课堂中的 LLM：使用 AI 辅助编写的问题的结果和看法 (LLMs in the Classroom: Outcomes and Perceptions of Questions Written with the Aid of AI)**\n    *   **研究:** 随机部署由人类和 ChatGPT 辅助编写的问题，评估学生回答正确率及区分问题来源的能力。\n    *   **发现:** 学生无法显著区分问题来源 (p = .309)，但在 LLM 编写的问题上得分低近 9% (p < .01)。这可能意味着 AI 问题更难，或学生更熟悉教师的出题风格。研究提示使用 LLM 辅助出题需谨慎确保公平性和相关性。\n\n7.  **神经符号人工智能研究：医疗保健视角 (A Study on Neuro-Symbolic Artificial Intelligence: Healthcare Perspectives)**\n    *   **贡献:** 对神经符号 AI (NeSy) 进行了广泛综述 (分析了 977 篇文献)，重点关注其在医疗保健（特别是药物发现和蛋白质工程）中的应用。探讨了推理、可解释性、集成策略、41 个医疗用例、基准、数据集、当前方法的局限性以及未来研究方向。\n\n8.  **ViVa: 用于指导在线 RL 的视频训练价值函数 (ViVa: Video-Trained Value Functions for Guiding Online RL from Diverse Data)**\n    *   **问题:** 稀疏奖励下的在线 RL 缺乏引导，而专家离线数据稀少。\n    *   **方法:** 提出 ViVa，利用广泛可用的视频数据（互联网录像、非任务演示、失败案例等）学习最优目标条件价值函数，并将其融入奖励 shaping，以指导在线 RL。\n    *   **贡献:** 实验表明，视频训练的价值函数适用于多种数据源，能从人类视频预训练中正向迁移，泛化到未见目标，并随数据集大小扩展。\n\n9.  **FROG: 图上的公平移除 (FROG: Fair Removal on Graphs)**\n    *   **问题:** 现有的图机器遗忘算法在移除节点或边时未考虑对公平性的潜在影响。\n    *   **方法:** 提出 FROG，联合优化图结构和模型以实现公平遗忘。通过重连图（移除冗余边、增加目标边）来提高遗忘效率并保持公平性。引入最坏情况评估机制。\n    *   **贡献:** 在真实数据集上验证了方法在实现更优遗忘结果方面的有效性。\n\n10. **探索能量景观以获得最小反事实解释：在网络安全及其他领域的应用 (Exploring Energy Landscapes for Minimal Counterfactual Explanations: Applications in Cybersecurity and Beyond)**\n    *   **贡献:** 提出一个结合微扰理论和统计力学的新框架，用于生成最小反事实解释。将反事实搜索重新表述为能量最小化问题，利用玻尔兹曼分布建模候选扰动概率，并使用模拟退火进行迭代优化。在物联网网络安全基准数据集上验证了其提供可操作、可解释反事实的能力。\n\n11. **自适应物理信息神经网络：综述 (Adaptive Physics-informed Neural Networks: A Survey)**\n    *   **贡献:** 综述了利用迁移学习和元学习来解决 PINN 收敛限制和参数变化需重新优化问题的研究。这些方法提高了训练效率，能更快地适应新的 PDE，减少数据和计算资源需求。\n\n12. **HH4AI: 欧盟 AI 法案下 AI 人权影响评估的方法论框架 (HH4AI: A methodological Framework for AI Human Rights impact assessment under the EUAI ACT)**\n    *   **贡献:** 提出 HH4AI 方法论，一个结构化的 AI 系统人权影响评估方法，旨在符合欧盟 AI 法案要求。该方法包含 AI 系统概述、人权清单、影响评估和最终输出阶段，并通过过滤机制针对性评估问责制、AI 素养、数据治理和透明度等领域。\n\n13. **揭开欺骗性视觉效果：在误导性图表问答上对多模态大语言模型进行基准测试 (Unmasking Deceptive Visuals: Benchmarking Multimodal Large Language Models on Misleading Chart Question Answering)**\n    *   **问题:** MLLM 检测和解释误导性图表的能力尚未被系统评估。\n    *   **贡献:** 提出 Misleading ChartQA 基准数据集，包含 3000+ 样本，覆盖 21 种误导类型和 10 种图表类型。评估了 16 个 SOTA MLLM，揭示了它们在识别视觉欺骗上的局限性。同时提出一个检测和定位误导信息的新流程，以提高 MLLM 的准确性。\n\n14. **自注意力扩散模型用于零样本生物医学图像分割 (Self-Attention Diffusion Models for Zero-Shot Biomedical Image Segmentation: Unlocking New Frontiers in Medical Imaging)**\n    *   **贡献:** 提出 ADZUS，一种利用预训练自注意力扩散模型进行零样本生物医学图像分割的新方法。无需标注数据或领域知识，通过利用模型的生成和判别潜力进行分割。在多个数据集（皮肤病变、胸片感染、白细胞）上取得 SOTA 性能，但计算资源需求大。\n\n15. **AIGC 服务的战略性 Prompt 定价：以用户为中心的方法 (Strategic Prompt Pricing for AIGC Services: A User-Centric Approach)**\n    *   **问题:** 当前 AIGC 定价策略忽视了用户在选择和使用模型时的两步决策过程。\n    *   **方法:** 引入“提示模糊性”概念量化用户提示工程能力，并开发最优提示定价 (OPP) 算法。\n    *   **发现:** 提示模糊性较高的用户（能力较低）呈现非单调的提示使用模式。OPP 算法相比现有机制可将平台收益提高达 31.72%。\n\n16. **评估神经主题模型的负采样方法 (Evaluating Negative Sampling Approaches for Neural Topic Models)**\n    *   **贡献:** 全面分析了不同负采样策略对神经主题模型的影响。实验表明，在 VAE 主题模型的解码器中整合负采样能显著改善主题一致性、多样性和文档分类准确率。\n\n17. **SNRAware: 通过 SNR 单元训练和 G 因子图增强改进深度学习 MRI 去噪 (SNRAware: Improved Deep Learning MRI Denoising with SNR Unit Training and G-factor Map Augmentation)**\n    *   **贡献:** 提出 SNRAware 训练方案，利用 MRI 重建过程中的定量噪声分布信息来改进深度学习去噪性能和泛化能力。通过模拟大规模合成数据并向模型提供噪声信息，在分布内和分布外测试中均表现出良好性能和泛化性。\n\n18. **用于智能建筑和社区能源控制与规划的主动推理 (Active Inference for Energy Control and Planning in Smart Buildings and Communities)**\n    *   **贡献:** 提出一种新颖的双层主动推理 (AIF) 架构，用于建筑级和社区级的能源管理。利用自由能原理，每层都能适应变化条件并处理部分可观测性，无需大量传感器信息且尊重数据隐私。验证了模型在处理突变（如极端定价）时的鲁棒性。\n\n19. **DiffusionTalker: 通过个性化器引导蒸馏实现高效紧凑的语音驱动 3D 说话头 (DiffusionTalker: Efficient and Compact Speech-Driven 3D Talking Head via Personalizer-Guided Distillation)**\n    *   **问题:** 现有基于扩散模型的语音驱动 3D 面部动画方法缺乏个性化风格、准确唇语，且效率和紧凑性有待提高。\n    *   **方法:** 提出 DiffusionTalker，引入对比个性化器学习身份和情感嵌入，通过迭代蒸馏提高效率（>8x 加速）和紧凑性（存储减少 86.4%），并用个性化器增强器提升嵌入影响。\n    *   **贡献:** 实现了个性化、高效、紧凑的 3D 说话头生成。\n\n20. **生成式 AI 系统水印技术的实践采用及新欧盟 AI 法案下的影响 (Adoption of Watermarking for Generative AI Systems in Practice and Implications under the new EU AI Act)**\n    *   **研究:** 对 50 个广泛使用的 AI 图像生成系统进行了水印技术实施现状的实证分析，并结合欧盟 AI 法案进行法律分析。\n    *   **发现:** 识别了 AI 法案下相关的四类生成式 AI 图像系统及其法律义务，发现目前只有少数提供商实施了足够的水印实践。\n\n21. **处理超广角视网膜成像的高效深度学习方法 (Efficient Deep Learning Approaches for Processing Ultra-Widefield Retinal Imaging)**\n    *   **贡献:** 探索了在低性能计算单元上高效处理超广角 (UWF) 视网膜图像的方法，如策略性数据增强和模型集成，以平衡性能和计算资源，并利用 UWF 图像相比传统 CFP 方法的优势。\n\n22. **LocDiffusion: 通过在希尔伯特空间中扩散识别地球上的位置 (LocDiffusion: Identifying Locations on Earth by Diffusing in the Hilbert Space)**\n    *   **问题:** 现有图像地理定位方法（基于网格分类或图像检索）在测试图像空间分布不一致时性能下降。\n    *   **方法:** 提出 LocDiffusion，首个通过在隐藏位置嵌入空间中扩散地理位置信息的生成模型。开发了球谐狄拉克δ (SHDD) 表示法进行球面位置编解码，并提出 CS-UNet 架构学习条件反向过程。\n    *   **贡献:** 实现了有竞争力的地理定位性能，并对未见地理位置表现出更强的泛化能力。\n\n23. **SRMIR: 基于内省推理的影子奖励模型用于 LLM 对齐 (SRMIR: Shadow Reward Models Based on Introspective Reasoning for LLM Alignment)**\n    *   **问题:** 当前 LLM 对齐方法依赖昂贵的人工标注、存在对齐税、易受越狱攻击，且数据集分布不均。\n    *   **方法:** 提出 SRMIR，受成员推理攻击中影子模型的启发。首先利用 LLM 的内省推理能力构建平衡的安全 CoD 数据集，然后训练一组专门的奖励模型，通过组相对策略优化 (GRPO) 指导策略优化。\n    *   **贡献:** 实验证明 SRMIR 显著优于现有方法，特别是在使用分类化方法整合影子奖励模型时。\n\n24. **通过行为支持正则化缓解 RLHF 中的奖励过度优化 (Mitigating Reward Over-Optimization in RLHF via Behavior-Supported Regularization)**\n    *   **问题:** RLHF 中的奖励过度优化（reward hacking）导致模型偏离真实人类目标，主要源于奖励模型对分布外 (OOD) 响应的推断错误。\n    *   **方法:** 提出行为支持策略优化 (BSPO)。定义行为策略为奖励训练数据集的下一 Token 分布，以建模奖励模型的分布内 (ID) 区域。引入行为支持贝尔曼算子对价值函数进行正则化，惩罚 OOD 值而不影响 ID 值。\n    *   **贡献:** BSPO 减少了 RL 过程中 OOD 响应的生成，避免了推断错误导致的过高估计。理论证明了单调改进，实验验证了其有效性。\n\n25. **GeoBenchX: 针对多步地理空间任务的 LLM 基准测试 (GeoBenchX: Benchmarking LLMs for Multistep Geospatial Tasks)**\n    *   **贡献:** 建立了一个评估 LLM 在多步地理空间任务（与商业 GIS 相关）上能力的基准 GeoBenchX。评估了 7 个领先商业 LLM，发现 Sonnet 3.5 和 GPT-4o 表现最佳，但也存在几何关系理解错误、知识过时等问题。发布了基准集、评估框架和数据生成流程。\n\n26. **AgentRxiv: 迈向协作式自主研究 (AgentRxiv: Towards Collaborative Autonomous Research)**\n    *   **问题:** 现有 Agent 工作流在隔离中进行研究，无法持续改进先前结果。\n    *   **方法:** 提出 AgentRxiv 框架，允许 LLM Agent 实验室上传和检索报告，实现协作、分享见解和迭代研究。\n    *   **发现:** 访问先前研究的 Agent 比孤立 Agent 取得了更高的性能提升 (MATH-500 相对基线提升 11.4%)。多个 Agent 实验室通过 AgentRxiv 协作比孤立实验室进展更快 (相对基线提升 13.7%)。\n\n27. **临床文本中的时序关系抽取：基于 Span 的图 Transformer 方法 (Temporal Relation Extraction in Clinical Texts: A Span-based Graph Transformer Approach)**\n    *   **贡献:** 提出 GRAPHTREX，一种结合基于 Span 的实体关系抽取、临床 LPLM 和异构图 Transformer (HGT) 的新方法，用于抽取临床事件及其时序关系。HGT 通过创新的全局地标连接远距离实体，促进信息传播。在 I2B2 2012 数据集上将 SOTA 的 F1 分数提高了 5.5%，长距离关系提高了 8.9%。\n\n28. **关于 LLM 自动评分西班牙语开放式问题的有效性研究 (On the effectiveness of LLMs for automatic grading of open-ended questions in Spanish)**\n    *   **研究:** 探索不同 LLM 和提示技术在自动评分西班牙语简答题上的表现。\n    *   **发现:** 先进的 LLM（开源和专有）在准确性、精确度和一致性方面表现良好，但结果对提示风格敏感。最佳模型和提示组合在三级评分任务中准确率超 95%，二元评分中超 98%，显示了 LLM 在教育自动化中的潜力。\n\n29. **从已知到未知：使用基础模型重写观察-指令以增强视觉-语言导航 (Unseen from Seen: Rewriting Observation-Instruction Using Foundation Models for Augmenting Vision-Language Navigation)**\n    *   **问题:** VLN 领域数据稀缺阻碍了 Agent 向未见环境的泛化。\n    *   **方法:** 提出 RAM 范式，通过重写人工标注的训练数据直接创建未见的观察-指令对。结合 VLM 和 LLM 进行对象丰富的观察重写，再通过 T2IM 生成合成观察；提出观察对比指令重写，让 LLM 推理差异生成对齐指令。\n    *   **贡献:** 实现了无需模拟器、节省人力的 VLN 数据增强，在多个数据集上展示了优越性能和泛化能力。\n\n30. **用于高效多任务提示调整的动态任务向量分组 (Dynamic Task Vector Grouping for Efficient Multi-Task Prompt Tuning)**\n    *   **问题:** 现有 MTPT 方法一次性迁移所有或单个源任务的软提示，忽略了最优组合可能介于两者之间，且任务相似性在微调中动态变化。\n    *   **方法:** 提出 DTVG，使用任务向量度量相似性，基于目标相似性和知识一致性分组最优源任务组合，并在每个迭代步动态更新组合。\n    *   **贡献:** 实验表明 DTVG 能有效分组相似源任务，减少负迁移，达到 SOTA 性能。\n\n31. **从次优分类器决策：校准前后的超额风险 (Decision from Suboptimal Classifiers: Excess Risk Pre- and Post-Calibration)**\n    *   **贡献:** 量化了在二元决策中使用近似后验概率导致的超额风险（regret）。提供了由错误校准引起的 regret ($R^{\\mathrm{CL}}$) 和校准后分类器 regret ($R^{\\mathrm{GL}}$) 的解析表达式及界限。识别了仅需重校准和需要超越重校准的后训练的场景。这些量可在实践中估计，有助于判断高级后训练的成本效益。\n\n32. **文化翻译中的迷失：LLM 是否在跨文化背景下难以处理数学问题？ (Lost in Cultural Translation: Do LLMs Struggle with Math Across Cultural Contexts?)**\n    *   **研究:** 通过修改 GSM8K 数据集中的文化元素（人名、食物等）但保持数学逻辑不变，评估 LLM 在不同文化背景下的数学推理能力。\n    *   **发现:** LLM 在处理文化参考变化的数学问题时表现下降，即使数学结构不变。小型模型下降更明显。文化熟悉度似乎能增强数学推理。强调了需要更多样化的训练数据。\n\n33. **Vision-R1: 通过视觉引导强化学习在大型视觉语言模型中演进免人工对齐 (Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models via Vision-Guided Reinforcement Learning)**\n    *   **问题:** 构建高质量人类偏好数据和模仿这些偏好的奖励模型成本高昂且具挑战性。\n    *   **方法:** 提出 Vision-R1，一种视觉引导的类 R1 强化学习算法，利用确定的视觉反馈奖励模型。仅使用策划的指令数据，无需专门奖励模型或偏好数据集。包含标准驱动的奖励函数和渐进式规则细化策略。\n    *   **贡献:** 实验表明，使用 Vision-R1 微调 7B LVLM 可持续提升性能，甚至超越 10 倍大的 SOTA 模型。\n\n34. **SG-Tailor: 用于场景图操作的对象间常识关系推理 (SG-Tailor: Inter-Object Commonsense Relationship Reasoning for Scene Graph Manipulation)**\n    *   **问题:** 合理地操作场景图（添加节点、修改边）具有挑战性，因为图内存在复杂的相互依赖关系。\n    *   **方法:** 提出 SG-Tailor，一个自回归模型，预测任意两节点间的无冲突关系。能为新节点推断常识边，并解决边修改引起的冲突。采用 Cut-And-Stitch 策略全局调整图。\n    *   **贡献:** 在节点添加和边修改任务中优于竞争方法，可作为插件用于场景生成和机器人操作。\n\n35. **用 LLM 指导时空序列预测的架构搜索 (Instructing the Architecture Search for Spatial-temporal Sequence Forecasting with LLM)**\n    *   **问题:** 现有用于 STSF 的 NAS 方法耗时长且难以利用背景知识。\n    *   **方法:** 提出基于 LLM 的 NAS 方法。通过多级增强机制激发 LLM 能力：步骤级（提示工程分解任务，LLM 作指导者）、实例级（一步调优评估架构，记忆库累积知识）、任务级（两阶段搜索平衡探索与优化）。\n    *   **贡献:** 实验证明该方法在效率和效果上均优于现有用于 STSF 的 NAS 方法。\n\n36. **通过最优监控控制预测手动和自动驾驶中的多任务处理 (Predicting Multitasking in Manual and Automated Driving with Optimal Supervisory Control)**\n    *   **贡献:** 提出一个基于最优监控控制理论的计算认知模型，模拟人类在驾驶时的多任务处理。模型能预测多任务行为如何适应驾驶需求、交互任务和自动化水平的变化，并考虑了不同自动化程度下的情境依赖性。\n\n37. **基于隐喻的文本到图像模型越狱攻击 (Metaphor-based Jailbreaking Attacks on Text-to-Image Models)**\n    *   **问题:** 现有基于 LLM 的 T2I 越狱攻击缺乏明确指导，查询量大。\n    *   **方法:** 提出 MJA，受 Taboo 游戏启发，通过生成基于隐喻的对抗性提示来平衡攻击效果和查询效率。包含 LLM 多 Agent 生成模块 (MLAG) 和对抗性提示优化模块 (APO)。\n    *   **贡献:** MJA 在查询次数更少的情况下实现了更好的攻击效果，且对抗性提示在多种 T2I 模型上具有强迁移性。\n\n38. **利用深度强化学习和条件动作树优化精准农业中的导航和化学品施用 (Optimizing Navigation And Chemical Application in Precision Agriculture With Deep Reinforcement Learning And Conditional Action Tree)**\n    *   **贡献:** 提出一种基于 RL 的分层决策规划方案 (HAM-PPO)，用于机器人管理精准农业中的生物胁迫。高层动作指导探索，低层动作优化导航和化学品喷洒。目标是提高受感染区域覆盖率、减少电池消耗和化学品用量。实验表明 HAM-PPO 优于基线方法。\n\n39. **品尝更多，品尝更好：多样化数据和强模型助力半监督人群计数 (Taste More, Taste Better: Diverse Data and Strong Model Boost Semi-Supervised Crowd Counting)**\n    *   **贡献:** 提出 TMTB 框架。通过背景修复增强数据多样性；引入视觉状态空间模型 (Mamba) 作为骨干网络捕捉全局上下文；使用回归头和抗噪声分类头提供更鲁棒的监督。在四个基准数据集上取得 SOTA 性能。\n\n40. **Co-SemDepth: 航空图像上快速联合语义分割和深度估计 (Co-SemDepth: Fast Joint Semantic Segmentation and Depth Estimation on Aerial Images)**\n    *   **贡献:** 提出一个联合深度学习架构 Co-SemDepth，用于从无人机单目相机图像中快速准确地预测深度图和语义分割图。在 MidAir 和 Aeroscapes 数据集上验证了其有效性，速度快 (20.2 FPS on P5000) 且内存占用低。\n\n41. **多重选择中的平衡方向：用于领域泛化的算术元学习 (Balanced Direction from Multifarious Choices: Arithmetic Meta-Learning for Domain Generalization)**\n    *   **问题:** 现有基于梯度匹配的一阶元学习方法忽略了平衡参数应接近各源域最优参数质心这一关键因素。\n    *   **方法:** 提出算术元学习，使用算术加权梯度，在遵循梯度匹配原则的同时，通过估计域特定最优参数的质心来促进更精确的平衡。\n    *   **贡献:** 实验验证了该策略的有效性。\n\n42. **大型推理模型的权衡：对基础能力上审议式和自适应推理的实证分析 (Trade-offs in Large Reasoning Models: An Empirical Analysis of Deliberative and Adaptive Reasoning over Foundational Capabilities)**\n    *   **研究:** 系统评估了大型推理模型 (LRM) 如 o1/o3 和 DeepSeek-R1。\n    *   **发现:** 获得审议式推理能力（如长思维链）会显著降低 LRM 的基础能力（帮助性、无害性下降）并增加推理成本。然而，自适应推理（如零思考、少思考模式）可以有效缓解这些缺点。强调了开发能动态分配计算资源的多功能 LRM 的必要性。\n\n43. **PIM: 物理信息多任务预训练用于改进基于惯性传感器的人体活动识别 (PIM: Physics-Informed Multi-task Pre-training for Improving Inertial Sensor-Based Human Activity Recognition)**\n    *   **问题:** 基于 SSL 的 HAR 预训练方法常忽略可穿戴传感器数据的物理机制。\n    *   **方法:** 提出 PIM 框架，基于人体运动的基本物理方面（运动速度、角度、对称性）生成 pretext 任务进行 SSL 预训练。\n    *   **贡献:** 使模型能捕捉 HAR 的基本物理特征，尤其适用于多传感器系统。实验表明 PIM 优于现有 SOTA 方法。\n\n44. **视频编辑的镜头序列排序：基准、指标和电影学启发的计算方法 (Shot Sequence Ordering for Video Editing: Benchmarks, Metrics, and Cinematology-Inspired Computing Methods)**\n    *   **贡献:** 针对 AI 辅助视频编辑中的镜头序列排序 (SSO) 任务，发布了两个新基准数据集 AVE-Order 和 ActivityNet-Order。提出使用 Kendall Tau 距离作为评估指标，并设计相应损失函数。引入电影学嵌入概念，将元数据和镜头标签作为先验知识，并构建 AVE-Meta 数据集验证。\n\n45. **SplitFrozen: 用于异构资源受限设备上微调 LLM 的设备端模型冻结分裂学习 (SplitFrozen: Split Learning with Device-side Model Frozen for Fine-Tuning LLM on Heterogeneous Resource-Constrained Devices)**\n    *   **问题:** 在资源受限的边缘设备上微调 LLM 面临计算开销大、设备异构和数据不平衡的挑战。\n    *   **方法:** 提出 SplitFrozen 框架，将 LLM 划分为设备端冻结层和服务器端微调层。设备只执行前向传播，服务器端使用 LoRA 进行参数高效微调。采用流水线并行策略优化效率。\n    *   **贡献:** 实验表明 SplitFrozen 在极度不平衡数据下准确率优于 FedLoRA 和 SplitLoRA，同时显著减少设备计算量和总训练时间。\n\n46. **PhysTwin: 从视频中进行物理信息引导的可变形物体重建与仿真 (PhysTwin: Physics-Informed Reconstruction and Simulation of Deformable Objects from Videos)**\n    *   **贡献:** 提出 PhysTwin 框架，使用稀疏交互视频创建照片级和物理级真实、可实时交互的虚拟副本。结合了弹簧-质量模型（物理）、生成形状模型（几何）和高斯溅射（渲染）。通过基于优化的逆向建模框架从视频中重建几何、推断物理属性和复制外观。在重建、渲染、预测和仿真方面优于竞争方法。\n\n47. **用于无样本持续学习中抗漂移空间的 LoRA 减法 (LoRA Subtraction for Drift-Resistant Space in Exemplar-Free Continual Learning)**\n    *   **问题:** 无样本持续学习 (EFCL) 中特征漂移导致灾难性遗忘，现有方法难以捕捉特征空间的动态演变。\n    *   **方法:** 引入抗漂移空间 (DRS) 概念。提出 LoRA 减法 (LoRA-)，在处理新任务数据前，从初始预训练权重中减去旧任务的 LoRA 权重，以建立 DRS 进行模型训练。\n    *   **贡献:** LoRA- 增强稳定性、提高效率、简化实现。稳定特征漂移后可通过 triplet loss 提高可塑性。在多个数据集上取得 SOTA 结果，尤其在长任务序列上。\n\n48. **任意代码传递的可能被误解的证据 (The Misinterpretable Evidence Conveyed by Arbitrary Codes)**\n    *   **贡献:** 探讨了使用证据理论 (Evidence Theory) 来表示生物体之间和内部的任意通信代码的可能性。探索了适用于不同复杂程度生物（无预期能力、能外推、能读心）的不同方案。\n\n49. **理解 RLHF 对 LLM 生成文本质量和可检测性的影响 (Understanding the Effects of RLHF on the Quality and Detectability of LLM-Generated Texts)**\n    *   **研究:** 分析 RLHF 编辑后的文本在质量和被检测器（基于训练和零样本）识别的难易度上的变化。\n    *   **发现:** RLHF 虽然提高了文本质量，但也倾向于产生更易被检测、更长、更重复的输出。基于训练的检测器对短文本和含代码文本较脆弱，而零样本检测器更鲁棒。\n\n50. **用于边缘训练的动态梯度稀疏更新 (Dynamic Gradient Sparse Update for Edge Training)**\n    *   **问题:** 边缘设备训练的反向传播梯度计算需要大量内存。\n    *   **方法:** 提出动态梯度稀疏更新，只更新重要的通道和层，跳过不重要部分的梯度计算。通道选择在不同迭代中动态进行。\n    *   **贡献:** 在 CIFAR-10 上训练 MobileNetV2，仅更新 2% 卷积权重，内存占用 < 256KB，准确率 85.77%，特征内存使用减少 98%。\n\n51. **面对灾难性风险：监管人工智能的国际义务 (Confronting Catastrophic Risk: The International Obligation to Regulate Artificial Intelligence)**\n    *   **论点:** 基于预防原则（precautionary principle），认为国际法（特别是国际人权法下的生命权）要求各国有积极义务采取监管行动，以减轻 AI 可能带来的生存风险，即使科学确定性不足。\n\n52. **人机交互与用户满意度：来自 AI 产品在线评论的实证证据 (Human-AI Interaction and User Satisfaction: Empirical Evidence from Online Reviews of AI Products)**\n    *   **研究:** 分析了 G2 平台上超过 10 万条 AI 相关产品的用户评论，基于 HAI 指南识别了 7 个核心维度。\n    *   **发现:** 适应性、定制化、错误恢复和安全性四个维度的情感与总体用户满意度正相关。技术背景用户更关注系统层面（如可靠性），非技术用户更关注交互层面（如定制化）。\n\n53. **使用生成对抗填充网络对稀疏学习者表现数据进行生成式数据填充 (Generative Data Imputation for Sparse Learner Performance Data Using Generative Adversarial Imputation Networks)**\n    *   **贡献:** 提出使用 GAIN 进行生成式数据填充，以解决智能辅导系统 (ITS) 中学习者数据稀疏的问题。采用三维框架（学习者、问题、尝试次数），并用 CNN 和最小二乘损失优化。实验证明优于基线方法，填充数据能有效用于后续的贝叶斯知识追踪 (BKT)。\n\n54. **FedSKD: 使用多维相似性知识蒸馏的无聚合模型异构联邦学习 (FedSKD: Aggregation-free Model-heterogeneous Federated Learning using Multi-dimensional Similarity Knowledge Distillation)**\n    *   **问题:** 模型异构联邦学习 (MHFL) 现有方法依赖中心化聚合或限制模型结构，P2P 方法则易模型漂移。\n    *   **方法:** 提出 FedSKD，一种无聚合 MHFL 框架，通过轮流模型循环直接交换知识。核心是多维相似性知识蒸馏（批次、像素/体素、区域级别），实现异构模型间的双向知识迁移。\n    *   **贡献:** 在医学 FL 应用中优于 SOTA 基线，实现更好的个性化和泛化能力。\n\n55. **CAE: 在深度强化学习中将 Critic 重新用作探索者 (CAE: Repurposing the Critic as an Explorer in Deep Reinforcement Learning)**\n    *   **贡献:** 提出 CAE 算法，利用标准深度 RL 中的价值网络驱动探索，无需额外参数。结合线性多臂老虎机技术和缩放策略，实现高效探索和理论保证。提出扩展 CAE+，在价值网络学习困难时引入辅助网络（参数增加<1%）。在 MuJoCo 和 MiniHack 上优于 SOTA 基线。\n\n56. **物理引导的多保真度 DeepONet 用于数据高效的流场预测 (Physics-Guided Multi-Fidelity DeepONet for Data-Efficient Flow Field Prediction)**\n    *   **贡献:** 提出增强的多保真度 DeepONet 框架，用于高效时空流场预测，尤其在高保真数据稀缺时。改进包括：合并网络增强特征交互、时间位置编码、点采样策略、基于迁移学习的多保真框架（冻结预训练网络，微调合并网络）、时间导数引导采样（仅用 60% 高保真样本达到全数据训练精度）。\n\n57. **关于与大型语言模型交互中不完整性和模糊性作用的实证研究 (An Empirical Study of the Role of Incompleteness and Ambiguity in Interactions with Large Language Models)**\n    *   **贡献:** 提出一个神经符号框架模拟人与 LLM 的交互。定义了问题的不完整性和模糊性作为可从交互信息中推导的属性。结果表明，答案正确性与这些属性相关，多轮交互通常对包含这些属性的问题是必要的，且增加交互长度可减少不完整性/模糊性。\n\n58. **带有电子健康记录的经验检索增强可实现准确的出院问答 (Experience Retrieval-Augmentation with Electronic Health Records Enables Accurate Discharge QA)**\n    *   **问题:** 除了通用医学知识，基于案例的知识对 LLM 的临床推理也很重要。\n    *   **方法:** 提出 ExpRAG 框架，利用 EHR 进行经验检索增强。通过粗到细的检索（EHR 报告排序器 + 经验检索器）从其他患者出院报告中提取相关上下文。引入 DischargeQA 数据集进行评估。\n    *   **贡献:** ExpRAG 显著优于基于文本的排序器，突显了案例知识的重要性。\n\n59. **STShield: 用于大型语言模型实时越狱检测的单 Token 哨兵 (STShield: Single-Token Sentinel for Real-Time Jailbreak Detection in Large Language Models)**\n    *   **问题:** 现有 LLM 越狱防御方法要么易受自适应攻击，要么计算成本高。\n    *   **方法:** 提出 STShield，一种轻量级实时检测框架。引入单 Token 哨兵机制，在模型响应序列后附加二元安全指示符，利用 LLM 自身的对齐能力进行检测。结合监督微调和对抗训练。\n    *   **贡献:** 能成功防御多种越狱攻击，同时保持模型效用，计算开销小。\n\n60. **WLB-LLM: 用于大型语言模型训练的工作负载平衡 4D 并行 (WLB-LLM: Workload-Balanced 4D Parallelism for Large Language Model Training)**\n    *   **问题:** LLM 训练中的 4D 并行（数据、张量、流水线、上下文）存在工作负载不平衡问题。\n    *   **方法:** 提出 WLB-LLM。在流水线并行层面，采用感知工作负载的可变长度文档打包；在上下文并行层面，引入细粒度的按文档分片策略。\n    *   **贡献:** 显著缓解了 4D 并行训练中的负载不平衡，平均加速 1.23 倍。\n\n61. **Cat-AIR: 内容和任务感知的 All-in-One 图像恢复 (Cat-AIR: Content and Task-Aware All-in-One Image Restoration)**\n    *   **问题:** 现有 All-in-One 图像恢复方法难以高效处理多种退化类型。\n    *   **方法:** 提出 Cat-AIR 框架，包含交替的空间-通道注意力机制（跨层通道注意力和跨特征空间注意力），根据内容和任务复杂度分配计算。提出平滑学习策略适应新任务。\n    *   **贡献:** 在多种恢复任务上达到 SOTA，且 FLOPs 更少。\n\n62. **GLADMamba: 由选择性状态空间模型驱动的无监督图级异常检测 (GLADMamba: Unsupervised Graph-Level Anomaly Detection Powered by Selective State Space Model)**\n    *   **问题:** 现有 UGLAD 方法难以高效捕捉长程依赖且忽略谱信息。\n    *   **方法:** 提出 GLADMamba，首次将 Mamba (选择性 SSM) 引入 UGLAD。设计了 View-Fused Mamba (VFM) 和 Spectrum-Guided Mamba (SGM)，均为 Mamba-Transformer 风格架构，分别用于融合多视图信息和利用谱信息（瑞利商）指导嵌入精炼。\n    *   **贡献:** 在 12 个真实数据集上优于 SOTA 方法。\n\n63. **阈值穿越作为灾难性 AI 风险的尾部事件 (Threshold Crossings as Tail Events for Catastrophic AI Risk)**\n    *   **贡献:** 分析了 AI 系统中由分岔驱动的跳跃及其产生的重尾结果分布。通过分析控制参数在灾难阈值附近的随机波动如何产生极端结果，论证了突发大规模转变的概率与由此产生的损害分布的尾部概率紧密相关的条件。有助于 AI 风险的监控、缓解和控制。\n\n64. **用于验证物理定律的生成式 AI (Generative AI for Validating Physics Laws)**\n    *   **贡献:** 提出使用生成式 AI 来经验性地验证物理定律，以 Stefan-Boltzmann 定律为例。通过模拟反事实光度并迭代优化深度学习架构中的温度-光度关系。使用 Gaia DR3 数据发现结果与理论预测一致。提供了一种数据驱动的方法来完善理论理解。",
  "papers": [
    {
      "arxiv_id": "2503.18242v1",
      "title": "ShED-HD: A Shannon Entropy Distribution Framework for Lightweight Hallucination Detection on Edge Devices",
      "title_zh": "ShED-HD：面向边缘设备的轻量化幻觉检测香农熵分布框架",
      "authors": [
        "Aneesh Vathul",
        "Daniel Lee",
        "Sheryl Chen",
        "Arthi Tasmia"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities on a\nbroad array of NLP tasks, but their tendency to produce\nhallucinations$\\unicode{x2013}$plausible-sounding but factually incorrect\ncontent$\\unicode{x2013}$poses severe challenges in high-stakes domains.\nExisting hallucination detection methods either bear the computational cost of\nmultiple inference passes or sacrifice accuracy for efficiency with single-pass\napproaches, neither of which is ideal in resource-constrained environments such\nas edge devices. We propose the Shannon Entropy Distribution Hallucination\nDetector (ShED-HD), a novel hallucination detection framework that bridges this\ngap by classifying sequence-level entropy patterns using a lightweight BiLSTM\narchitecture with single-headed attention. In contrast to prior approaches,\nShED-HD efficiently detects distinctive uncertainty patterns across entire\noutput sequences, preserving contextual awareness. Through in-depth evaluation\non three datasets (BioASQ, TriviaQA, and Jeopardy Questions), we show that\nShED-HD significantly outperforms other computationally efficient approaches in\nthe out-of-distribution setting, while achieving comparable performance in the\nin-distribution setting. ShED-HD facilitates hallucination detection that is\nlow-cost, accurate, and generalizable, improving the credibility of content\ngenerated by LLMs in resource-constrained environments where trustworthy AI\nfunctionality is crucial.",
      "tldr_zh": "本研究提出ShED-HD框架，一种基于香农熵分布(Shannon Entropy Distribution)的轻量级幻觉检测方法，专门针对边缘设备设计。该框架通过轻量级BiLSTM架构和单头注意力机制，可高效识别大语言模型(LLMs)输出中的序列级熵分布模式，在单次推理中实现准确检测。实验表明，ShED-HD在BioASQ等三个数据集上显著优于其他高效方法（尤其适用于分布外场景），为资源受限环境下提升LLM生成内容的可信度提供了可行方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18242v1",
      "published_date": "2025-03-23 23:47:26 UTC",
      "updated_date": "2025-03-23 23:47:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:18:49.062861"
    },
    {
      "arxiv_id": "2503.18238v1",
      "title": "Collaborating with AI Agents: Field Experiments on Teamwork, Productivity, and Performance",
      "title_zh": "与AI智能体协作：关于团队合作、生产力与绩效的实地实验",
      "authors": [
        "Harang Ju",
        "Sinan Aral"
      ],
      "abstract": "To uncover how AI agents change productivity, performance, and work\nprocesses, we introduce MindMeld: an experimentation platform enabling humans\nand AI agents to collaborate in integrative workspaces. In a large-scale\nmarketing experiment on the platform, 2310 participants were randomly assigned\nto human-human and human-AI teams, with randomized AI personality traits. The\nteams exchanged 183,691 messages, and created 63,656 image edits, 1,960,095 ad\ncopy edits, and 10,375 AI-generated images while producing 11,138 ads for a\nlarge think tank. Analysis of fine-grained communication, collaboration, and\nworkflow logs revealed that collaborating with AI agents increased\ncommunication by 137% and allowed humans to focus 23% more on text and image\ncontent generation messaging and 20% less on direct text editing. Humans on\nHuman-AI teams sent 23% fewer social messages, creating 60% greater\nproductivity per worker and higher-quality ad copy. In contrast, human-human\nteams produced higher-quality images, suggesting that AI agents require\nfine-tuning for multimodal workflows. AI personality prompt randomization\nrevealed that AI traits can complement human personalities to enhance\ncollaboration. For example, conscientious humans paired with open AI agents\nimproved image quality, while extroverted humans paired with conscientious AI\nagents reduced the quality of text, images, and clicks. In field tests of ad\ncampaigns with ~5M impressions, ads with higher image quality produced by human\ncollaborations and higher text quality produced by AI collaborations performed\nsignificantly better on click-through rate and cost per click metrics. Overall,\nads created by human-AI teams performed similarly to those created by\nhuman-human teams. Together, these results suggest AI agents can improve\nteamwork and productivity, especially when tuned to complement human traits.",
      "tldr_zh": "该研究通过MindMeld平台对2310名参与者进行大规模实验，比较人-人团队和人-AI团队的工作表现。研究发现：人-AI团队使沟通量增加137%，员工生产力提升60%，并生成更高质量的广告文案，但人-人团队制作的图像质量更高。实验还表明，AI个性设置需与人类性格互补——例如尽责型人类与开放型AI搭配可提升图像质量。在500万次广告展示测试中，人-AI团队的整体表现与人-人团队相当，说明合理调校的AI能有效提升团队协作效率。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "56 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.18238v1",
      "published_date": "2025-03-23 23:20:32 UTC",
      "updated_date": "2025-03-23 23:20:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:19:01.872856"
    },
    {
      "arxiv_id": "2503.18996v1",
      "title": "Enhanced prediction of spine surgery outcomes using advanced machine learning techniques and oversampling methods",
      "title_zh": "基于先进机器学习技术与过采样方法增强脊柱手术效果预测",
      "authors": [
        "José Alberto Benítez-Andrades",
        "Camino Prada-García",
        "Nicolás Ordás-Reyes",
        "Marta Esteban Blanco",
        "Alicia Merayo",
        "Antonio Serrano-García"
      ],
      "abstract": "The study proposes an advanced machine learning approach to predict spine\nsurgery outcomes by incorporating oversampling techniques and grid search\noptimization. A variety of models including GaussianNB, ComplementNB, KNN,\nDecision Tree, and optimized versions with RandomOverSampler and SMOTE were\ntested on a dataset of 244 patients, which included pre-surgical, psychometric,\nsocioeconomic, and analytical variables. The enhanced KNN models achieved up to\n76% accuracy and a 67% F1-score, while grid-search optimization further\nimproved performance. The findings underscore the potential of these advanced\ntechniques to aid healthcare professionals in decision-making, with future\nresearch needed to refine these models on larger and more diverse datasets.",
      "tldr_zh": "该研究提出一种结合过采样技术和网格搜索优化的机器学习方法，用于预测脊柱手术结果。通过测试包括高斯朴素贝叶斯、KNN和决策树等多种模型，并使用RandomOverSampler和SMOTE处理数据不平衡问题，最终优化的KNN模型在244名患者数据集上达到76%准确率和67%的F1分数。研究表明这些先进技术能有效辅助医疗决策，未来需在更大规模数据集上进一步验证模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18996v1",
      "published_date": "2025-03-23 22:39:19 UTC",
      "updated_date": "2025-03-23 22:39:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:19:22.457579"
    },
    {
      "arxiv_id": "2503.18229v1",
      "title": "Adaptive Multi-Fidelity Reinforcement Learning for Variance Reduction in Engineering Design Optimization",
      "title_zh": "自适应多保真度强化学习：工程设计优化中的方差缩减方法",
      "authors": [
        "Akash Agrawal",
        "Christopher McComb"
      ],
      "abstract": "Multi-fidelity Reinforcement Learning (RL) frameworks efficiently utilize\ncomputational resources by integrating analysis models of varying accuracy and\ncosts. The prevailing methodologies, characterized by transfer learning,\nhuman-inspired strategies, control variate techniques, and adaptive sampling,\npredominantly depend on a structured hierarchy of models. However, this\nreliance on a model hierarchy can exacerbate variance in policy learning when\nthe underlying models exhibit heterogeneous error distributions across the\ndesign space. To address this challenge, this work proposes a novel adaptive\nmulti-fidelity RL framework, in which multiple heterogeneous, non-hierarchical\nlow-fidelity models are dynamically leveraged alongside a high-fidelity model\nto efficiently learn a high-fidelity policy. Specifically, low-fidelity\npolicies and their experience data are adaptively used for efficient targeted\nlearning, guided by their alignment with the high-fidelity policy. The\neffectiveness of the approach is demonstrated in an octocopter design\noptimization problem, utilizing two low-fidelity models alongside a\nhigh-fidelity simulator. The results demonstrate that the proposed approach\nsubstantially reduces variance in policy learning, leading to improved\nconvergence and consistent high-quality solutions relative to traditional\nhierarchical multi-fidelity RL methods. Moreover, the framework eliminates the\nneed for manually tuning model usage schedules, which can otherwise introduce\nsignificant computational overhead. This positions the framework as an\neffective variance-reduction strategy for multi-fidelity RL, while also\nmitigating the computational and operational burden of manual fidelity\nscheduling.",
      "tldr_zh": "本文提出了一种新型自适应多保真度强化学习框架，用于解决工程设计中传统分层多保真度方法因模型异质误差分布导致的策略学习方差增大问题。该方法创新性地动态整合多个非层次化低保真度模型与高保真度模型，通过自适应利用低保真度策略及其经验数据进行针对性学习，有效降低了策略学习的方差。在八旋翼飞行器设计优化案例中，该框架相比传统方法显著提升了收敛性和解的质量，同时无需人工调参模型使用计划，减轻了计算负担。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18229v1",
      "published_date": "2025-03-23 22:29:08 UTC",
      "updated_date": "2025-03-23 22:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:20:01.299331"
    },
    {
      "arxiv_id": "2503.18227v2",
      "title": "PG-SAM: Prior-Guided SAM with Medical for Multi-organ Segmentation",
      "title_zh": "PG-SAM：面向多器官分割的医学先验引导SAM模型",
      "authors": [
        "Yiheng Zhong",
        "Zihong Luo",
        "Chengzhi Liu",
        "Feilong Tang",
        "Zelin Peng",
        "Ming Hu",
        "Yingzhen Hu",
        "Jionglong Su",
        "Zongyuan Geand",
        "Imran Razzak"
      ],
      "abstract": "Segment Anything Model (SAM) demonstrates powerful zero-shot capabilities;\nhowever, its accuracy and robustness significantly decrease when applied to\nmedical image segmentation. Existing methods address this issue through\nmodality fusion, integrating textual and image information to provide more\ndetailed priors. In this study, we argue that the granularity of text and the\ndomain gap affect the accuracy of the priors. Furthermore, the discrepancy\nbetween high-level abstract semantics and pixel-level boundary details in\nimages can introduce noise into the fusion process. To address this, we propose\nPrior-Guided SAM (PG-SAM), which employs a fine-grained modality prior aligner\nto leverage specialized medical knowledge for better modality alignment. The\ncore of our method lies in efficiently addressing the domain gap with\nfine-grained text from a medical LLM. Meanwhile, it also enhances the priors'\nquality after modality alignment, ensuring more accurate segmentation. In\naddition, our decoder enhances the model's expressive capabilities through\nmulti-level feature fusion and iterative mask optimizer operations, supporting\nunprompted learning. We also propose a unified pipeline that effectively\nsupplies high-quality semantic information to SAM. Extensive experiments on the\nSynapse dataset demonstrate that the proposed PG-SAM achieves state-of-the-art\nperformance. Our anonymous code is released at\nhttps://github.com/logan-0623/PG-SAM.",
      "tldr_zh": "该研究提出PG-SAM（Prior-Guided SAM），通过引入细粒度模态先验对齐器解决医疗图像分割中SAM模型的领域适应问题。方法创新性地利用医学大语言模型(LLM)生成的细粒度文本先验，有效弥合模态差异并提升分割精度，同时通过多级特征融合和解码器优化增强模型表达能力。在Synapse数据集上的实验表明，PG-SAM实现了最先进的分割性能，为医学多器官分割提供了无需提示学习的高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18227v2",
      "published_date": "2025-03-23 22:06:07 UTC",
      "updated_date": "2025-03-25 13:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:20:20.483601"
    },
    {
      "arxiv_id": "2503.18995v1",
      "title": "LLMs in the Classroom: Outcomes and Perceptions of Questions Written with the Aid of AI",
      "title_zh": "课堂中的大语言模型：AI辅助编写试题的效果与学生认知研究",
      "authors": [
        "Gavin Witsken",
        "Igor Crk",
        "Eren Gultepe"
      ],
      "abstract": "We randomly deploy questions constructed with and without use of the LLM tool\nand gauge the ability of the students to correctly answer, as well as their\nability to correctly perceive the difference between human-authored and\nLLM-authored questions. In determining whether the questions written with the\naid of ChatGPT were consistent with the instructor's questions and source text,\nwe computed representative vectors of both the human and ChatGPT questions\nusing SBERT and compared cosine similarity to the course textbook. A\nnon-significant Mann-Whitney U test (z = 1.018, p = .309) suggests that\nstudents were unable to perceive whether questions were written with or without\nthe aid of ChatGPT. However, student scores on LLM-authored questions were\nalmost 9% lower (z = 2.702, p < .01). This result may indicate that either the\nAI questions were more difficult or that the students were more familiar with\nthe instructor's style of questions. Overall, the study suggests that while\nthere is potential for using LLM tools to aid in the construction of\nassessments, care must be taken to ensure that the questions are fair,\nwell-composed, and relevant to the course material.",
      "tldr_zh": "这项研究通过随机测试发现，学生无法区分教师编写和使用ChatGPT辅助编写的问题（p=0.309），但AI生成问题的得分显著降低9%（p<0.01）。研究采用SBERT向量计算显示，AI问题与教材相似度与教师自编问题无显著差异，但成绩差距可能源于AI问题难度更高或学生更适应教师出题风格。结果表明，虽然大语言模型（LLM）可用于辅助出题，但需确保问题的公平性、合理性和与课程内容的相关性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to AAAI 2025 Technical Track on AI Alignment",
      "pdf_url": "http://arxiv.org/pdf/2503.18995v1",
      "published_date": "2025-03-23 22:01:49 UTC",
      "updated_date": "2025-03-23 22:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:20:35.952265"
    },
    {
      "arxiv_id": "2503.18213v1",
      "title": "A Study on Neuro-Symbolic Artificial Intelligence: Healthcare Perspectives",
      "title_zh": "神经符号人工智能研究：医疗健康视角",
      "authors": [
        "Delower Hossain",
        "Jake Y Chen"
      ],
      "abstract": "Over the last few decades, Artificial Intelligence (AI) scientists have been\nconducting investigations to attain human-level performance by a machine in\naccomplishing a cognitive task. Within machine learning, the ultimate\naspiration is to attain Artificial General Intelligence (AGI) through a\nmachine. This pursuit has led to the exploration of two distinct AI paradigms.\nSymbolic AI, also known as classical or GOFAI (Good Old-Fashioned AI) and\nConnectionist (Sub-symbolic) AI, represented by Neural Systems, are two\nmutually exclusive paradigms. Symbolic AI excels in reasoning, explainability,\nand knowledge representation but faces challenges in processing complex\nreal-world data with noise. Conversely, deep learning (Black-Box systems)\nresearch breakthroughs in neural networks are notable, yet they lack reasoning\nand interpretability. Neuro-symbolic AI (NeSy), an emerging area of AI\nresearch, attempts to bridge this gap by integrating logical reasoning into\nneural networks, enabling them to learn and reason with symbolic\nrepresentations. While a long path, this strategy has made significant progress\ntowards achieving common sense reasoning by systems. This article conducts an\nextensive review of over 977 studies from prominent scientific databases (DBLP,\nACL, IEEExplore, Scopus, PubMed, ICML, ICLR), thoroughly examining the\nmultifaceted capabilities of Neuro-Symbolic AI, with a particular focus on its\nhealthcare applications, particularly in drug discovery, and Protein\nengineering research. The survey addresses vital themes, including reasoning,\nexplainability, integration strategies, 41 healthcare-related use cases,\nbenchmarking, datasets, current approach limitations from both healthcare and\nbroader perspectives, and proposed novel approaches for future experiments.",
      "tldr_zh": "本研究对神经符号人工智能(Neuro-Symbolic AI, NeSy)进行了全面综述，重点关注其在医疗保健领域的应用。NeSy通过将逻辑推理与神经网络相结合，弥补了符号AI在处理复杂数据方面的不足以及深度学习在可解释性上的缺陷。文章回顾了977项相关研究，详细探讨了NeSy在药物发现和蛋白质工程等医疗应用中的多方面能力，包括推理、可解释性、整合策略以及41个医疗用例。研究还提出了未来实验的新方法，为NeSy在医疗领域的进一步发展提供了方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.18213v1",
      "published_date": "2025-03-23 21:33:38 UTC",
      "updated_date": "2025-03-23 21:33:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:20:40.766396"
    },
    {
      "arxiv_id": "2503.18210v1",
      "title": "ViVa: Video-Trained Value Functions for Guiding Online RL from Diverse Data",
      "title_zh": "ViVa：利用视频训练的价值函数指导多样化数据驱动的在线强化学习",
      "authors": [
        "Nitish Dashora",
        "Dibya Ghosh",
        "Sergey Levine"
      ],
      "abstract": "Online reinforcement learning (RL) with sparse rewards poses a challenge\npartly because of the lack of feedback on states leading to the goal.\nFurthermore, expert offline data with reward signal is rarely available to\nprovide this feedback and bootstrap online learning. How can we guide online\nagents to the right solution without this on-task data? Reward shaping offers a\nsolution by providing fine-grained signal to nudge the policy towards the\noptimal solution. However, reward shaping often requires domain knowledge to\nhand-engineer heuristics for a specific goal. To enable more general and\ninexpensive guidance, we propose and analyze a data-driven methodology that\nautomatically guides RL by learning from widely available video data such as\nInternet recordings, off-task demonstrations, task failures, and undirected\nenvironment interaction. By learning a model of optimal goal-conditioned value\nfrom diverse passive data, we open the floor to scaling up and using various\ndata sources to model general goal-reaching behaviors relevant to guiding\nonline RL. Specifically, we use intent-conditioned value functions to learn\nfrom diverse videos and incorporate these goal-conditioned values into the\nreward. Our experiments show that video-trained value functions work well with\na variety of data sources, exhibit positive transfer from human video\npre-training, can generalize to unseen goals, and scale with dataset size.",
      "tldr_zh": "该研究提出ViVa方法，通过从多样化视频数据（如互联网录像、失败案例和环境交互）中学习最优目标条件价值函数，为稀疏奖励的在线强化学习(RL)提供自动引导。该方法利用意图条件价值函数从视频中建模通用目标达成行为，并将这些目标条件价值整合到奖励函数中。实验表明，视频训练的价值函数能有效利用多种数据源，展现人类视频预训练的正迁移能力，并可泛化到未见目标且随数据集规模扩展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18210v1",
      "published_date": "2025-03-23 21:24:33 UTC",
      "updated_date": "2025-03-23 21:24:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:21:02.027933"
    },
    {
      "arxiv_id": "2503.18197v1",
      "title": "FROG: Fair Removal on Graphs",
      "title_zh": "FROG：图数据公平性移除算法",
      "authors": [
        "Ziheng Chen",
        "Jiali Cheng",
        "Gabriele Tolomei",
        "Sijia Liu",
        "Hadi Amiri",
        "Yu Wang",
        "Kaushiki Nag",
        "Lu Lin"
      ],
      "abstract": "As compliance with privacy regulations becomes increasingly critical, the\ngrowing demand for data privacy has highlighted the significance of machine\nunlearning in many real world applications, such as social network and\nrecommender systems, many of which can be represented as graph-structured data.\nHowever, existing graph unlearning algorithms indiscriminately modify edges or\nnodes from well-trained models without considering the potential impact of such\nstructural modifications on fairness. For example, forgetting links between\nnodes with different genders in a social network may exacerbate group\ndisparities, leading to significant fairness concerns. To address these\nchallenges, we propose a novel approach that jointly optimizes the graph\nstructure and the corresponding model for fair unlearning tasks.\nSpecifically,our approach rewires the graph to enhance unlearning efficiency by\nremoving redundant edges that hinder forgetting while preserving fairness\nthrough targeted edge augmentation. Additionally, we introduce a worst-case\nevaluation mechanism to assess the reliability of fair unlearning performance.\nExtensive experiments on real-world datasets demonstrate the effectiveness of\nthe proposed approach in achieving superior unlearning outcomes.",
      "tldr_zh": "该研究提出FROG（Fair Removal on Graphs）方法，针对图结构数据中的机器遗忘（machine unlearning）问题，首次将公平性考量纳入图遗忘过程。该方法通过联合优化图结构和对应模型，在删除冗余边的同时进行针对性边增强，在保证遗忘效率的同时维护图的公平性。研究者还提出了最坏情况评估机制来验证公平遗忘的可靠性，实验证明该方法在现实数据集中能实现更优的遗忘效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18197v1",
      "published_date": "2025-03-23 20:39:53 UTC",
      "updated_date": "2025-03-23 20:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:21:22.036209"
    },
    {
      "arxiv_id": "2503.18185v1",
      "title": "Exploring Energy Landscapes for Minimal Counterfactual Explanations: Applications in Cybersecurity and Beyond",
      "title_zh": "探索最小反事实解释的能量景观：在网络安全及其他领域的应用",
      "authors": [
        "Spyridon Evangelatos",
        "Eleni Veroni",
        "Vasilis Efthymiou",
        "Christos Nikolopoulos",
        "Georgios Th. Papadopoulos",
        "Panagiotis Sarigiannidis"
      ],
      "abstract": "Counterfactual explanations have emerged as a prominent method in Explainable\nArtificial Intelligence (XAI), providing intuitive and actionable insights into\nMachine Learning model decisions. In contrast to other traditional feature\nattribution methods that assess the importance of input variables,\ncounterfactual explanations focus on identifying the minimal changes required\nto alter a model's prediction, offering a ``what-if'' analysis that is close to\nhuman reasoning. In the context of XAI, counterfactuals enhance transparency,\ntrustworthiness and fairness, offering explanations that are not just\ninterpretable but directly applicable in the decision-making processes.\n  In this paper, we present a novel framework that integrates perturbation\ntheory and statistical mechanics to generate minimal counterfactual\nexplanations in explainable AI. We employ a local Taylor expansion of a Machine\nLearning model's predictive function and reformulate the counterfactual search\nas an energy minimization problem over a complex landscape. In sequence, we\nmodel the probability of candidate perturbations leveraging the Boltzmann\ndistribution and use simulated annealing for iterative refinement. Our approach\nsystematically identifies the smallest modifications required to change a\nmodel's prediction while maintaining plausibility. Experimental results on\nbenchmark datasets for cybersecurity in Internet of Things environments,\ndemonstrate that our method provides actionable, interpretable counterfactuals\nand offers deeper insights into model sensitivity and decision boundaries in\nhigh-dimensional spaces.",
      "tldr_zh": "本研究提出了一种新颖的可解释AI框架，通过结合微扰理论和统计力学来生成最小反事实解释（counterfactual explanations）。该方法将机器学习模型的预测函数进行局部泰勒展开，并将反事实搜索重新表述为复杂能量景观中的最小化问题，利用玻尔兹曼分布建模候选扰动的概率分布，采用模拟退火算法进行迭代优化。实验证明，该方法能在物联网网络安全等场景中识别改变模型预测所需的最小修改，同时保持结果的合理性，为高维空间中的模型敏感性和决策边界提供了更深入的洞见。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18185v1",
      "published_date": "2025-03-23 19:48:37 UTC",
      "updated_date": "2025-03-23 19:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:21:45.931654"
    },
    {
      "arxiv_id": "2503.18181v1",
      "title": "Adaptive Physics-informed Neural Networks: A Survey",
      "title_zh": "自适应物理信息神经网络：研究综述",
      "authors": [
        "Edgar Torres",
        "Jonathan Schiefer",
        "Mathias Niepert"
      ],
      "abstract": "Physics-informed neural networks (PINNs) have emerged as a promising approach\nto solving partial differential equations (PDEs) using neural networks,\nparticularly in data-scarce scenarios, due to their unsupervised training\ncapability. However, limitations related to convergence and the need for\nre-optimization with each change in PDE parameters hinder their widespread\nadoption across scientific and engineering applications. This survey reviews\nexisting research that addresses these limitations through transfer learning\nand meta-learning. The covered methods improve the training efficiency,\nallowing faster adaptation to new PDEs with fewer data and computational\nresources. While traditional numerical methods solve systems of differential\nequations directly, neural networks learn solutions implicitly by adjusting\ntheir parameters. One notable advantage of neural networks is their ability to\nabstract away from specific problem domains, allowing them to retain, discard,\nor adapt learned representations to efficiently address similar problems. By\nexploring the application of these techniques to PINNs, this survey identifies\npromising directions for future research to facilitate the broader adoption of\nPINNs in a wide range of scientific and engineering applications.",
      "tldr_zh": "该综述探讨了自适应物理信息神经网络(PINNs)的最新进展，聚焦于解决传统PINNs在收敛性和参数适应性方面的局限性。研究指出，通过迁移学习和元学习方法可显著提升PINNs的训练效率，使其能以更少数据和计算资源快速适应新的偏微分方程(PDEs)。相较于传统数值方法，神经网络通过隐式学习解决方案并灵活调整参数，展现出跨问题域的泛化优势。文章为促进PINNs在科学工程领域的广泛应用指明了未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://openreview.net/forum?id=vz5P1Kbt6t",
      "pdf_url": "http://arxiv.org/pdf/2503.18181v1",
      "published_date": "2025-03-23 19:33:05 UTC",
      "updated_date": "2025-03-23 19:33:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:22:03.688275"
    },
    {
      "arxiv_id": "2503.18994v1",
      "title": "HH4AI: A methodological Framework for AI Human Rights impact assessment under the EUAI ACT",
      "title_zh": "HH4AI：欧盟《人工智能法案》下人权影响评估的方法论框架",
      "authors": [
        "Paolo Ceravolo",
        "Ernesto Damiani",
        "Maria Elisa D'Amico",
        "Bianca de Teffe Erb",
        "Simone Favaro",
        "Nannerel Fiano",
        "Paolo Gambatesa",
        "Simone La Porta",
        "Samira Maghool",
        "Lara Mauri",
        "Niccolo Panigada",
        "Lorenzo Maria Ratto Vaquer",
        "Marta A. Tamborini"
      ],
      "abstract": "This paper introduces the HH4AI Methodology, a structured approach to\nassessing the impact of AI systems on human rights, focusing on compliance with\nthe EU AI Act and addressing technical, ethical, and regulatory challenges. The\npaper highlights AIs transformative nature, driven by autonomy, data, and\ngoal-oriented design, and how the EU AI Act promotes transparency,\naccountability, and safety. A key challenge is defining and assessing\n\"high-risk\" AI systems across industries, complicated by the lack of\nuniversally accepted standards and AIs rapid evolution.\n  To address these challenges, the paper explores the relevance of ISO/IEC and\nIEEE standards, focusing on risk management, data quality, bias mitigation, and\ngovernance. It proposes a Fundamental Rights Impact Assessment (FRIA)\nmethodology, a gate-based framework designed to isolate and assess risks\nthrough phases including an AI system overview, a human rights checklist, an\nimpact assessment, and a final output phase. A filtering mechanism tailors the\nassessment to the system's characteristics, targeting areas like\naccountability, AI literacy, data governance, and transparency.\n  The paper illustrates the FRIA methodology through a fictional case study of\nan automated healthcare triage service. The structured approach enables\nsystematic filtering, comprehensive risk assessment, and mitigation planning,\neffectively prioritizing critical risks and providing clear remediation\nstrategies. This promotes better alignment with human rights principles and\nenhances regulatory compliance.",
      "tldr_zh": "该研究提出了HH4AI方法论框架，旨在系统评估AI系统对人权的影响，并确保符合欧盟《人工智能法案》要求。该框架基于分阶段的门控式设计，包含AI系统概述、人权清单检查、影响评估等环节，重点关注问责制、AI素养、数据治理和透明度等核心领域。通过虚构的医疗分诊案例验证表明，该方法能有效识别高风险AI系统、优先处理关键风险，并提供明确的缓解策略，有助于平衡技术创新与人权保护。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "19 pages, 7 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.18994v1",
      "published_date": "2025-03-23 19:10:14 UTC",
      "updated_date": "2025-03-23 19:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:22:24.053750"
    },
    {
      "arxiv_id": "2503.18172v1",
      "title": "Unmasking Deceptive Visuals: Benchmarking Multimodal Large Language Models on Misleading Chart Question Answering",
      "title_zh": "揭开欺骗性视觉图表的伪装：多模态大语言模型在误导性图表问答任务中的基准测试",
      "authors": [
        "Zixin Chen",
        "Sicheng Song",
        "Kashun Shum",
        "Yanna Lin",
        "Rui Sheng",
        "Huamin Qu"
      ],
      "abstract": "Misleading chart visualizations, which intentionally manipulate data\nrepresentations to support specific claims, can distort perceptions and lead to\nincorrect conclusions. Despite decades of research, misleading visualizations\nremain a widespread and pressing issue. Recent advances in multimodal large\nlanguage models (MLLMs) have demonstrated strong chart comprehension\ncapabilities, yet no existing work has systematically evaluated their ability\nto detect and interpret misleading charts. This paper introduces the Misleading\nChart Question Answering (Misleading ChartQA) Benchmark, a large-scale\nmultimodal dataset designed to assess MLLMs in identifying and reasoning about\nmisleading charts. It contains over 3,000 curated examples, covering 21 types\nof misleaders and 10 chart types. Each example includes standardized chart\ncode, CSV data, and multiple-choice questions with labeled explanations,\nvalidated through multi-round MLLM checks and exhausted expert human review. We\nbenchmark 16 state-of-the-art MLLMs on our dataset, revealing their limitations\nin identifying visually deceptive practices. We also propose a novel pipeline\nthat detects and localizes misleaders, enhancing MLLMs' accuracy in misleading\nchart interpretation. Our work establishes a foundation for advancing\nMLLM-driven misleading chart comprehension. We publicly release the sample\ndataset to support further research in this critical area.",
      "tldr_zh": "该研究针对误导性图表这一长期存在的可视化问题，提出了首个系统性评估多模态大语言模型(MLLMs)识别能力的Misleading ChartQA基准数据集。该数据集包含3,000多个涵盖21种误导类型和10种图表类别的标注样本，每个样本均包含标准化图表代码、CSV数据和带解释的多选题。研究测试了16种前沿MLLMs，揭示了它们在识别视觉欺骗手法上的局限性，并提出了一种能检测和定位误导元素的新型流程，显著提升了模型解读准确性。这项工作为推进MLLMs在误导性图表理解领域的发展奠定了基础，相关数据集已开源供后续研究使用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages in total. Under Review For ARR",
      "pdf_url": "http://arxiv.org/pdf/2503.18172v1",
      "published_date": "2025-03-23 18:56:33 UTC",
      "updated_date": "2025-03-23 18:56:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:22:46.110040"
    },
    {
      "arxiv_id": "2503.18170v1",
      "title": "Self-Attention Diffusion Models for Zero-Shot Biomedical Image Segmentation: Unlocking New Frontiers in Medical Imaging",
      "title_zh": "自注意力扩散模型在零样本生物医学图像分割中的应用：开启医学影像新前沿",
      "authors": [
        "Abderrachid Hamrani",
        "Anuradha Godavarty"
      ],
      "abstract": "Producing high-quality segmentation masks for medical images is a fundamental\nchallenge in biomedical image analysis. Recent research has explored\nlarge-scale supervised training to enable segmentation across various medical\nimaging modalities and unsupervised training to facilitate segmentation without\ndense annotations. However, constructing a model capable of segmenting diverse\nmedical images in a zero-shot manner without any annotations remains a\nsignificant hurdle. This paper introduces the Attention Diffusion Zero-shot\nUnsupervised System (ADZUS), a novel approach that leverages self-attention\ndiffusion models for zero-shot biomedical image segmentation. ADZUS harnesses\nthe intrinsic capabilities of pre-trained diffusion models, utilizing their\ngenerative and discriminative potentials to segment medical images without\nrequiring annotated training data or prior domain-specific knowledge. The ADZUS\narchitecture is detailed, with its integration of self-attention mechanisms\nthat facilitate context-aware and detail-sensitive segmentations being\nhighlighted. Experimental results across various medical imaging datasets,\nincluding skin lesion segmentation, chest X-ray infection segmentation, and\nwhite blood cell segmentation, reveal that ADZUS achieves state-of-the-art\nperformance. Notably, ADZUS reached Dice scores ranging from 88.7\\% to 92.9\\%\nand IoU scores from 66.3\\% to 93.3\\% across different segmentation tasks,\ndemonstrating significant improvements in handling novel, unseen medical\nimagery. It is noteworthy that while ADZUS demonstrates high effectiveness, it\ndemands substantial computational resources and extended processing times. The\nmodel's efficacy in zero-shot settings underscores its potential to reduce\nreliance on costly annotations and seamlessly adapt to new medical imaging\ntasks, thereby expanding the diagnostic capabilities of AI-driven medical\nimaging technologies.",
      "tldr_zh": "本文提出了一种新型零样本生物医学图像分割方法ADZUS（Attention Diffusion Zero-shot Unsupervised System），利用自注意力扩散模型（self-attention diffusion models）实现无需标注数据的医学图像分割。该方法结合预训练扩散模型的生成和判别能力，通过自注意力机制实现上下文感知的精确分割，在皮肤病变、胸部X光感染和白细胞分割等任务中达到当前最优性能（Dice分数88.7%-92.9%）。虽然计算资源需求较高，但ADZUS显著降低了对昂贵标注数据的依赖，为适应新型医学影像任务提供了有效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.18170v1",
      "published_date": "2025-03-23 18:47:12 UTC",
      "updated_date": "2025-03-23 18:47:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:23:04.986853"
    },
    {
      "arxiv_id": "2503.18168v1",
      "title": "Strategic Prompt Pricing for AIGC Services: A User-Centric Approach",
      "title_zh": "AIGC服务策略性提示定价：一种以用户为中心的方法",
      "authors": [
        "Xiang Li",
        "Bing Luo",
        "Jianwei Huang",
        "Yuan Luo"
      ],
      "abstract": "The rapid growth of AI-generated content (AIGC) services has created an\nurgent need for effective prompt pricing strategies, yet current approaches\noverlook users' strategic two-step decision-making process in selecting and\nutilizing generative AI models. This oversight creates two key technical\nchallenges: quantifying the relationship between user prompt capabilities and\ngeneration outcomes, and optimizing platform payoff while accounting for\nheterogeneous user behaviors. We address these challenges by introducing prompt\nambiguity, a theoretical framework that captures users' varying abilities in\nprompt engineering, and developing an Optimal Prompt Pricing (OPP) algorithm.\nOur analysis reveals a counterintuitive insight: users with higher prompt\nambiguity (i.e., lower capability) exhibit non-monotonic prompt usage patterns,\nfirst increasing then decreasing with ambiguity levels, reflecting complex\nchanges in marginal utility. Experimental evaluation using a character-level\nGPT-like model demonstrates that our OPP algorithm achieves up to 31.72%\nimprovement in platform payoff compared to existing pricing mechanisms,\nvalidating the importance of user-centric prompt pricing in AIGC services.",
      "tldr_zh": "该研究针对AI生成内容(AIGC)服务提出了一种用户导向的提示词定价策略，解决了现有方法忽视用户两阶段决策过程的关键问题。作者创新性地引入\"提示词模糊度\"(prompt ambiguity)理论框架来量化用户提示工程能力差异，并开发了最优提示定价(OPP)算法。研究发现高模糊度用户呈现先增后减的非单调使用模式，实验表明OPP算法使平台收益提升31.72%，验证了用户中心定价策略的有效性。",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted in WiOpt 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.18168v1",
      "published_date": "2025-03-23 18:41:06 UTC",
      "updated_date": "2025-03-23 18:41:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:23:24.250308"
    },
    {
      "arxiv_id": "2503.18167v2",
      "title": "Evaluating Negative Sampling Approaches for Neural Topic Models",
      "title_zh": "神经主题模型中负采样方法的评估",
      "authors": [
        "Suman Adhya",
        "Avishek Lahiri",
        "Debarshi Kumar Sanyal",
        "Partha Pratim Das"
      ],
      "abstract": "Negative sampling has emerged as an effective technique that enables deep\nlearning models to learn better representations by introducing the paradigm of\nlearn-to-compare. The goal of this approach is to add robustness to deep\nlearning models to learn better representation by comparing the positive\nsamples against the negative ones. Despite its numerous demonstrations in\nvarious areas of computer vision and natural language processing, a\ncomprehensive study of the effect of negative sampling in an unsupervised\ndomain like topic modeling has not been well explored. In this paper, we\npresent a comprehensive analysis of the impact of different negative sampling\nstrategies on neural topic models. We compare the performance of several\npopular neural topic models by incorporating a negative sampling technique in\nthe decoder of variational autoencoder-based neural topic models. Experiments\non four publicly available datasets demonstrate that integrating negative\nsampling into topic models results in significant enhancements across multiple\naspects, including improved topic coherence, richer topic diversity, and more\naccurate document classification. Manual evaluations also indicate that the\ninclusion of negative sampling into neural topic models enhances the quality of\nthe generated topics. These findings highlight the potential of negative\nsampling as a valuable tool for advancing the effectiveness of neural topic\nmodels.",
      "tldr_zh": "该论文系统评估了负采样(negative sampling)策略在神经主题模型(neural topic models)中的应用效果。研究通过在基于变分自编码器(VAE)的神经主题模型解码器中集成负采样技术，比较了不同策略对模型性能的影响。实验表明，负采样能显著提升主题连贯性、丰富主题多样性并提高文档分类准确率，人工评估也证实其可改善生成主题的质量，为神经主题模型的优化提供了有效工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Code is available at: https://github.com/AdhyaSuman/Eval_NegTM",
      "pdf_url": "http://arxiv.org/pdf/2503.18167v2",
      "published_date": "2025-03-23 18:39:01 UTC",
      "updated_date": "2025-03-25 05:53:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:23:44.404031"
    },
    {
      "arxiv_id": "2503.18162v1",
      "title": "SNRAware: Improved Deep Learning MRI Denoising with SNR Unit Training and G-factor Map Augmentation",
      "title_zh": "SNRAware：基于信噪比单元训练和G因子图增强的改进型深度学习MRI去噪方法",
      "authors": [
        "Hui Xue",
        "Sarah M. Hooper",
        "Iain Pierce",
        "Rhodri H. Davies",
        "John Stairs",
        "Joseph Naegele",
        "Adrienne E. Campbell-Washburn",
        "Charlotte Manisty",
        "James C. Moon",
        "Thomas A. Treibel",
        "Peter Kellman",
        "Michael S. Hansen"
      ],
      "abstract": "To develop and evaluate a new deep learning MR denoising method that\nleverages quantitative noise distribution information from the reconstruction\nprocess to improve denoising performance and generalization.\n  This retrospective study trained 14 different transformer and convolutional\nmodels with two backbone architectures on a large dataset of 2,885,236 images\nfrom 96,605 cardiac retro-gated cine complex series acquired at 3T. The\nproposed training scheme, termed SNRAware, leverages knowledge of the MRI\nreconstruction process to improve denoising performance by simulating large,\nhigh quality, and diverse synthetic datasets, and providing quantitative\ninformation about the noise distribution to the model. In-distribution testing\nwas performed on a hold-out dataset of 3000 samples with performance measured\nusing PSNR and SSIM, with ablation comparison without the noise augmentation.\nOut-of-distribution tests were conducted on cardiac real-time cine, first-pass\ncardiac perfusion, and neuro and spine MRI, all acquired at 1.5T, to test model\ngeneralization across imaging sequences, dynamically changing contrast,\ndifferent anatomies, and field strengths. The best model found in the\nin-distribution test generalized well to out-of-distribution samples,\ndelivering 6.5x and 2.9x CNR improvement for real-time cine and perfusion\nimaging, respectively. Further, a model trained with 100% cardiac cine data\ngeneralized well to a T1 MPRAGE neuro 3D scan and T2 TSE spine MRI.",
      "tldr_zh": "本研究提出了一种名为SNRAware的新型深度学习MRI去噪方法，通过利用重建过程中的定量噪声分布信息来提升去噪性能和泛化能力。研究采用包含288万张图像的庞大数据集，训练了14种基于Transformer和卷积架构的模型，并通过模拟高质量合成数据提供噪声分布信息。实验表明，该方法在分布内测试中表现优异，并在跨序列、对比度、解剖结构和场强的分布外测试中展现出良好的泛化能力，显著提升了实时心脏成像和灌注成像的信噪比。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18162v1",
      "published_date": "2025-03-23 18:16:36 UTC",
      "updated_date": "2025-03-23 18:16:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:24:07.563824"
    },
    {
      "arxiv_id": "2503.18161v1",
      "title": "Active Inference for Energy Control and Planning in Smart Buildings and Communities",
      "title_zh": "主动推理在智能建筑与社区能源控制与规划中的应用",
      "authors": [
        "Seyyed Danial Nazemi",
        "Mohsen A. Jafari",
        "Andrea Matta"
      ],
      "abstract": "Active Inference (AIF) is emerging as a powerful framework for\ndecision-making under uncertainty, yet its potential in engineering\napplications remains largely unexplored. In this work, we propose a novel\ndual-layer AIF architecture that addresses both building-level and\ncommunity-level energy management. By leveraging the free energy principle,\neach layer adapts to evolving conditions and handles partial observability\nwithout extensive sensor information and respecting data privacy. We validate\nthe continuous AIF model against both a perfect optimization baseline and a\nreinforcement learning-based approach. We also test the community AIF framework\nunder extreme pricing scenarios. The results highlight the model's robustness\nin handling abrupt changes. This study is the first to show how a distributed\nAIF works in engineering. It also highlights new opportunities for\nprivacy-preserving and uncertainty-aware control strategies in engineering\napplications.",
      "tldr_zh": "该研究提出了一种新型的双层主动推理（AIF）架构，用于智能建筑和社区的能源控制与规划。通过利用自由能原理（free energy principle），该框架能在有限传感器信息和保护数据隐私的前提下，自适应处理建筑级和社区级的能源管理问题。实验表明，该AIF模型在极端定价场景下表现出优异的鲁棒性，为工程领域提供了首个分布式主动推理的隐私保护型不确定性控制方案。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "Submitted to IEEE CASE 2025 (IEEE 21st International Conference on\n  Automation Science and Engineering)",
      "pdf_url": "http://arxiv.org/pdf/2503.18161v1",
      "published_date": "2025-03-23 18:03:01 UTC",
      "updated_date": "2025-03-23 18:03:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:24:27.404388"
    },
    {
      "arxiv_id": "2503.18159v1",
      "title": "DiffusionTalker: Efficient and Compact Speech-Driven 3D Talking Head via Personalizer-Guided Distillation",
      "title_zh": "DiffusionTalker：通过个性化引导蒸馏实现高效紧凑的语音驱动三维说话头生成",
      "authors": [
        "Peng Chen",
        "Xiaobao Wei",
        "Ming Lu",
        "Hui Chen",
        "Feng Tian"
      ],
      "abstract": "Real-time speech-driven 3D facial animation has been attractive in academia\nand industry. Traditional methods mainly focus on learning a deterministic\nmapping from speech to animation. Recent approaches start to consider the\nnondeterministic fact of speech-driven 3D face animation and employ the\ndiffusion model for the task. Existing diffusion-based methods can improve the\ndiversity of facial animation. However, personalized speaking styles conveying\naccurate lip language is still lacking, besides, efficiency and compactness\nstill need to be improved. In this work, we propose DiffusionTalker to address\nthe above limitations via personalizer-guided distillation. In terms of\npersonalization, we introduce a contrastive personalizer that learns identity\nand emotion embeddings to capture speaking styles from audio. We further\npropose a personalizer enhancer during distillation to enhance the influence of\nembeddings on facial animation. For efficiency, we use iterative distillation\nto reduce the steps required for animation generation and achieve more than 8x\nspeedup in inference. To achieve compactness, we distill the large teacher\nmodel into a smaller student model, reducing our model's storage by 86.4\\%\nwhile minimizing performance loss. After distillation, users can derive their\nidentity and emotion embeddings from audio to quickly create personalized\nanimations that reflect specific speaking styles. Extensive experiments are\nconducted to demonstrate that our method outperforms state-of-the-art methods.\nThe code will be released at: https://github.com/ChenVoid/DiffusionTalker.",
      "tldr_zh": "本文提出DiffusionTalker，通过个性化引导蒸馏技术实现高效紧凑的语音驱动3D人脸动画。该方法创新性地采用对比学习个人化模块，从音频中提取身份和情感嵌入特征以捕捉个性化说话风格，并通过蒸馏增强器强化这些特征对动画的影响。在效率方面，通过迭代蒸馏将推理速度提升8倍以上，同时将模型存储空间减少86.4%而保持性能。实验证明该方法在保持唇语准确性的同时，能快速生成反映特定说话风格的个性化动画，性能优于现有技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICME2025",
      "pdf_url": "http://arxiv.org/pdf/2503.18159v1",
      "published_date": "2025-03-23 17:55:54 UTC",
      "updated_date": "2025-03-23 17:55:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:24:45.255360"
    },
    {
      "arxiv_id": "2503.18156v1",
      "title": "Adoption of Watermarking for Generative AI Systems in Practice and Implications under the new EU AI Act",
      "title_zh": "生成式AI系统水印技术实践应用及其在欧盟新AI法案下的影响",
      "authors": [
        "Bram Rijsbosch",
        "Gijs van Dijck",
        "Konrad Kollnig"
      ],
      "abstract": "AI-generated images have become so good in recent years that individuals\ncannot distinguish them any more from \"real\" images. This development creates a\nseries of societal risks, and challenges our perception of what is true and\nwhat is not, particularly with the emergence of \"deep fakes\" that impersonate\nreal individuals. Watermarking, a technique that involves embedding identifying\ninformation within images to indicate their AI-generated nature, has emerged as\na primary mechanism to address the risks posed by AI-generated images. The\nimplementation of watermarking techniques is now becoming a legal requirement\nin many jurisdictions, including under the new 2024 EU AI Act. Despite the\nwidespread use of AI image generation systems, the current status of\nwatermarking implementation remains largely unexamined. Moreover, the practical\nimplications of the AI Act's watermarking requirements have not previously been\nstudied. The present paper therefore both provides an empirical analysis of 50\nof the most widely used AI systems for image generation, and embeds this\nempirical analysis into a legal analysis of the AI Act. We identify four\ncategories of generative AI image systems relevant under the AI Act, outline\nthe legal obligations for each category, and find that only a minority number\nof providers currently implement adequate watermarking practices.",
      "tldr_zh": "该研究探讨了生成式AI图像水印技术在实际应用中的采用情况及其在新版欧盟AI法案下的法律影响。通过对50个主流AI图像生成系统的实证分析发现，目前仅有少数提供商实施了充分的水印技术。研究建立了与AI法案相关的四类生成式AI系统分类，并详细阐述了各类别的法律义务，揭示了当前行业实践与法规要求之间的显著差距，为解决AI生成内容真实性认证问题提供了重要参考。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "12 pages, 7 figures, note that this work has not been published in a\n  peer reviewed venue yet. While we have made our best effort to ensure the\n  validity of our findings, it is therefore still work in progress and\n  potentially subject to change",
      "pdf_url": "http://arxiv.org/pdf/2503.18156v1",
      "published_date": "2025-03-23 17:55:33 UTC",
      "updated_date": "2025-03-23 17:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:25:03.885207"
    },
    {
      "arxiv_id": "2503.18151v1",
      "title": "Efficient Deep Learning Approaches for Processing Ultra-Widefield Retinal Imaging",
      "title_zh": "高效深度学习方法在超广角视网膜影像处理中的应用",
      "authors": [
        "Siwon Kim",
        "Wooyung Yun",
        "Jeongbin Oh",
        "Soomok Lee"
      ],
      "abstract": "Deep learning has emerged as the predominant solution for classifying medical\nimages. We intend to apply these developments to the ultra-widefield (UWF)\nretinal imaging dataset. Since UWF images can accurately diagnose various\nretina diseases, it is very important to clas sify them accurately and prevent\nthem with early treatment. However, processing images manually is\ntime-consuming and labor-intensive, and there are two challenges to automating\nthis process. First, high perfor mance usually requires high computational\nresources. Artificial intelli gence medical technology is better suited for\nplaces with limited medical resources, but using high-performance processing\nunits in such environ ments is challenging. Second, the problem of the accuracy\nof colour fun dus photography (CFP) methods. In general, the UWF method\nprovides more information for retinal diagnosis than the CFP method, but most\nof the research has been conducted based on the CFP method. Thus, we\ndemonstrate that these problems can be efficiently addressed in low performance\nunits using methods such as strategic data augmentation and model ensembles,\nwhich balance performance and computational re sources while utilizing UWF\nimages.",
      "tldr_zh": "该研究提出高效深度学习方法来处理超广角视网膜成像(UWF)，解决两个关键挑战：一是高性能模型通常需要高计算资源，而医疗AI往往需在资源有限环境下部署；二是现有研究多基于传统眼底彩照(CFP)方法，而UWF能提供更丰富的诊断信息。通过策略性数据增强和模型集成方法，研究团队实现了在低性能计算单元上高效处理UWF图像，平衡了性能与资源消耗。这一进展为在医疗资源有限地区推广AI视网膜疾病早期诊断提供了可行方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18151v1",
      "published_date": "2025-03-23 17:43:24 UTC",
      "updated_date": "2025-03-23 17:43:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:25:28.389237"
    },
    {
      "arxiv_id": "2503.18142v1",
      "title": "LocDiffusion: Identifying Locations on Earth by Diffusing in the Hilbert Space",
      "title_zh": "LocDiffusion：基于希尔伯特空间扩散的地球定位识别",
      "authors": [
        "Zhangyu Wang",
        "Jielu Zhang",
        "Zhongliang Zhou",
        "Qian Cao",
        "Nemin Wu",
        "Zeping Liu",
        "Lan Mu",
        "Yang Song",
        "Yiqun Xie",
        "Ni Lao",
        "Gengchen Mai"
      ],
      "abstract": "Image geolocalization is a fundamental yet challenging task, aiming at\ninferring the geolocation on Earth where an image is taken. Existing methods\napproach it either via grid-based classification or via image retrieval. Their\nperformance significantly suffers when the spatial distribution of test images\ndoes not align with such choices. To address these limitations, we propose to\nleverage diffusion as a mechanism for image geolocalization. To avoid the\nproblematic manifold reprojection step in diffusion, we developed a novel\nspherical positional encoding-decoding framework, which encodes points on a\nspherical surface (e.g., geolocations on Earth) into a Hilbert space of\nSpherical Harmonics coefficients and decodes points (geolocations) by\nmode-seeking. We call this type of position encoding Spherical Harmonics Dirac\nDelta (SHDD) Representation. We also propose a novel SirenNet-based\narchitecture called CS-UNet to learn the conditional backward process in the\nlatent SHDD space by minimizing a latent KL-divergence loss. We train a\nconditional latent diffusion model called LocDiffusion that generates\ngeolocations under the guidance of images -- to the best of our knowledge, the\nfirst generative model for image geolocalization by diffusing geolocation\ninformation in a hidden location embedding space. We evaluate our method\nagainst SOTA image geolocalization baselines. LocDiffusion achieves competitive\ngeolocalization performance and demonstrates significantly stronger\ngeneralizability to unseen geolocations.",
      "tldr_zh": "该研究提出LocDiffusion，首个基于扩散模型（Diffusion Model）的图像地理定位方法。通过创新的球谐狄拉克δ表示（SHDD），将地球表面的地理位置编码至希尔伯特空间，避免了传统扩散模型中复杂的流形重投影问题。团队开发了CS-UNet架构，通过在潜在SHDD空间最小化KL散度损失来学习条件逆向扩散过程。相比现有基于网格分类或图像检索的方法，LocDiffusion在未见过的地理位置表现出显著更强的泛化能力，成为首个在隐藏位置嵌入空间扩散地理信息的生成式定位模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18142v1",
      "published_date": "2025-03-23 17:15:26 UTC",
      "updated_date": "2025-03-23 17:15:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:25:51.759661"
    },
    {
      "arxiv_id": "2503.18991v1",
      "title": "SRMIR: Shadow Reward Models Based on Introspective Reasoning for LLM Alignment",
      "title_zh": "SRMIR：基于自省推理的阴影奖励模型用于大语言模型对齐",
      "authors": [
        "Ruoxi Cheng",
        "Shuirong Cao"
      ],
      "abstract": "Aligning large language models (LLMs) with human preferences and values is\nvital for application. However, current alignment methods face three main\nlimitations: (1) reliance on costly human annotation; (2) alignment tax; (3)\nshallow alignment vulnerable to jailbreak attacks. Additionally, current\nalignment datasets often suffer from uneven distributions, leading to\noverrepresentation of some topics and neglect of others. To address these\nissues, we propose SRMIR (Shadow Reward Models Based on Introspective\nReasoning), inspired by shadow models in membership inference attacks. We first\nconstruct a balanced safety Chain of Draft (CoD) dataset across $7$ harmful\ntypes with structured prompt leveraging the introspective reasoning\ncapabilities of LLMs, then train a set of specialized reward models to guide\npolicy optimization through Group Relative Policy Optimization (GRPO). We apply\ntwo strategies, linear combination and categorized approach, to integrate\nshadow reward models for policy optimization. By comparison, we find that the\nlatter achieves superior alignment despite higher computational costs.\nExperiments across several LLMs demonstrate SRMIR significantly outperforms\nexisting methods.",
      "tldr_zh": "本文提出SRMIR方法，通过自省推理构建影子奖励模型来解决大语言模型对齐问题。该方法首先利用LLMs的自省推理能力构建平衡的Chain of Draft安全数据集，然后训练一组专用奖励模型，并通过Group Relative Policy Optimization(GRPO)进行策略优化。实验表明，相比现有方法，SRMIR在多个大语言模型上表现更优，特别是在分类整合策略下能实现更好的对齐效果，尽管计算成本较高。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18991v1",
      "published_date": "2025-03-23 16:40:29 UTC",
      "updated_date": "2025-03-23 16:40:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:26:04.455066"
    },
    {
      "arxiv_id": "2503.18130v1",
      "title": "Mitigating Reward Over-Optimization in RLHF via Behavior-Supported Regularization",
      "title_zh": "通过行为支持正则化缓解RLHF中的奖励过优化问题",
      "authors": [
        "Juntao Dai",
        "Taiye Chen",
        "Yaodong Yang",
        "Qian Zheng",
        "Gang Pan"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) is an effective method for\naligning large language models (LLMs) with human values. However, reward\nover-optimization remains an open challenge leading to discrepancies between\nthe performance of LLMs under the reward model and the true human objectives. A\nprimary contributor to reward over-optimization is the extrapolation error that\narises when the reward model evaluates out-of-distribution (OOD) responses.\nHowever, current methods still fail to prevent the increasing frequency of OOD\nresponse generation during the reinforcement learning (RL) process and are not\neffective at handling extrapolation errors from OOD responses. In this work, we\npropose the Behavior-Supported Policy Optimization (BSPO) method to mitigate\nthe reward over-optimization issue. Specifically, we define behavior policy as\nthe next token distribution of the reward training dataset to model the\nin-distribution (ID) region of the reward model. Building on this, we introduce\nthe behavior-supported Bellman operator to regularize the value function,\npenalizing all OOD values without impacting the ID ones. Consequently, BSPO\nreduces the generation of OOD responses during the RL process, thereby avoiding\noverestimation caused by the reward model's extrapolation errors.\nTheoretically, we prove that BSPO guarantees a monotonic improvement of the\nsupported policy until convergence to the optimal behavior-supported policy.\nEmpirical results from extensive experiments show that BSPO outperforms\nbaselines in preventing reward over-optimization due to OOD evaluation and\nfinding the optimal ID policy.",
      "tldr_zh": "该研究针对强化学习人类反馈(RLHF)中的奖励过优化问题，提出了行为支持策略优化(BSPO)方法。通过定义基于奖励训练数据集的行为策略来建模奖励模型的分布内(ID)区域，并引入行为支持贝尔曼算子对值函数进行正则化，从而有效减少强化学习过程中分布外(OOD)响应的生成。理论证明BSPO能保证策略单调改进直至收敛至最优行为支持策略，实验结果表明该方法在防止OOD评估导致的奖励过优化和寻找最优ID策略方面优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.18130v1",
      "published_date": "2025-03-23 16:20:59 UTC",
      "updated_date": "2025-03-23 16:20:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:26:26.246228"
    },
    {
      "arxiv_id": "2503.18129v1",
      "title": "GeoBenchX: Benchmarking LLMs for Multistep Geospatial Tasks",
      "title_zh": "GeoBenchX：面向多步骤地理空间任务的大语言模型基准测试",
      "authors": [
        "Varvara Krechetova",
        "Denis Kochedykov"
      ],
      "abstract": "In this paper, we establish a benchmark for evaluating large language models\n(LLMs) on multi-step geospatial tasks relevant to commercial GIS practitioners.\nWe assess seven leading commercial LLMs (Sonnet 3.5 and 3.7, Haiku 3.5, Gemini\n2.0, GPT-4o, GPT-4o mini, and o3-mini) using a simple tool-calling agent\nequipped with 23 geospatial functions. Our benchmark comprises tasks across\nfour categories of increasing complexity, with both solvable and intentionally\nunsolvable tasks to test hallucination rejection. We develop an LLM-as-Judge\nevaluation framework to compare agent solutions against reference\nimplementations. Results show Sonnet 3.5 and GPT-4o achieve the best overall\nperformance, with Claude models excelling on solvable tasks while OpenAI models\nbetter identify unsolvable scenarios. We observe significant differences in\ntoken usage, with Anthropic models consuming substantially more tokens than\ncompetitors. Common errors include misunderstanding geometrical relationships,\nrelying on outdated knowledge, and inefficient data manipulation. The resulting\nbenchmark set, evaluation framework, and data generation pipeline are released\nas open-source resources, providing one more standardized method for ongoing\nevaluation of LLMs for GeoAI.",
      "tldr_zh": "该研究提出了GeoBenchX基准测试，用于评估大语言模型(LLMs)在商业地理信息系统(GIS)多步骤空间任务中的表现。通过配备23种地理空间功能的工具调用代理，测试了7种主流商业LLM在四类复杂度递增任务上的表现，包括可解和故意不可解任务以检验幻觉拒绝能力。结果显示Sonnet 3.5和GPT-4o综合表现最佳，而Claude模型擅长可解任务，OpenAI模型更擅长识别不可解场景。研究还发现Anthropic模型消耗的token数量显著更多，常见错误包括几何关系误解和低效数据处理。该基准测试套件和评估框架已开源，为GeoAI领域的LLM评估提供了标准化方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Github with code and benchmark set:\n  https://github.com/Solirinai/GeoBenchX",
      "pdf_url": "http://arxiv.org/pdf/2503.18129v1",
      "published_date": "2025-03-23 16:20:14 UTC",
      "updated_date": "2025-03-23 16:20:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:26:54.757705"
    },
    {
      "arxiv_id": "2503.18102v1",
      "title": "AgentRxiv: Towards Collaborative Autonomous Research",
      "title_zh": "AgentRxiv：迈向协作式自主研究",
      "authors": [
        "Samuel Schmidgall",
        "Michael Moor"
      ],
      "abstract": "Progress in scientific discovery is rarely the result of a single \"Eureka\"\nmoment, but is rather the product of hundreds of scientists incrementally\nworking together toward a common goal. While existing agent workflows are\ncapable of producing research autonomously, they do so in isolation, without\nthe ability to continuously improve upon prior research results. To address\nthese challenges, we introduce AgentRxiv-a framework that lets LLM agent\nlaboratories upload and retrieve reports from a shared preprint server in order\nto collaborate, share insights, and iteratively build on each other's research.\nWe task agent laboratories to develop new reasoning and prompting techniques\nand find that agents with access to their prior research achieve higher\nperformance improvements compared to agents operating in isolation (11.4%\nrelative improvement over baseline on MATH-500). We find that the best\nperforming strategy generalizes to benchmarks in other domains (improving on\naverage by 3.3%). Multiple agent laboratories sharing research through\nAgentRxiv are able to work together towards a common goal, progressing more\nrapidly than isolated laboratories, achieving higher overall accuracy (13.7%\nrelative improvement over baseline on MATH-500). These findings suggest that\nautonomous agents may play a role in designing future AI systems alongside\nhumans. We hope that AgentRxiv allows agents to collaborate toward research\ngoals and enables researchers to accelerate discovery.",
      "tldr_zh": "该研究提出了AgentRxiv框架，旨在实现AI智能体之间的协同自主科研。该框架通过建立共享预印本服务器，使LLM智能体实验室能够上传、检索研究报告，实现知识共享与迭代研究改进。实验表明，使用该协作系统的智能体在数学推理任务（MATH-500）上比孤立工作的智能体性能提升11.4%，且该方法可泛化至其他领域（平均提升3.3%）。多智能体实验室通过AgentRxiv协作时，在MATH-500上最终实现了13.7%的相对提升，展示了协同科研的显著优势。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18102v1",
      "published_date": "2025-03-23 15:16:42 UTC",
      "updated_date": "2025-03-23 15:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:27:04.481174"
    },
    {
      "arxiv_id": "2503.18085v1",
      "title": "Temporal Relation Extraction in Clinical Texts: A Span-based Graph Transformer Approach",
      "title_zh": "临床文本中的时序关系抽取：基于跨度的图变换器方法",
      "authors": [
        "Rochana Chaturvedi",
        "Peyman Baghershahi",
        "Sourav Medya",
        "Barbara Di Eugenio"
      ],
      "abstract": "Temporal information extraction from unstructured text is essential for\ncontextualizing events and deriving actionable insights, particularly in the\nmedical domain. We address the task of extracting clinical events and their\ntemporal relations using the well-studied I2B2 2012 Temporal Relations\nChallenge corpus. This task is inherently challenging due to complex clinical\nlanguage, long documents, and sparse annotations. We introduce GRAPHTREX, a\nnovel method integrating span-based entity-relation extraction, clinical large\npre-trained language models (LPLMs), and Heterogeneous Graph Transformers (HGT)\nto capture local and global dependencies. Our HGT component facilitates\ninformation propagation across the document through innovative global landmarks\nthat bridge distant entities. Our method improves the state-of-the-art with\n5.5% improvement in the tempeval $F_1$ score over the previous best and up to\n8.9% improvement on long-range relations, which presents a formidable\nchallenge. This work not only advances temporal information extraction but also\nlays the groundwork for improved diagnostic and prognostic models through\nenhanced temporal reasoning.",
      "tldr_zh": "这篇论文提出了一种名为GRAPHTREX的新型方法，用于从临床文本中提取事件及其时间关系。该方法结合了基于span的实体关系提取、临床大预训练语言模型(LPLMs)和异构图变换器(HGT)，通过创新的全局地标连接远距离实体，有效捕捉局部和全局依赖关系。在I2B2 2012 Temporal Relations Challenge语料库上的实验表明，该方法将tempeval F1分数提升了5.5%，在长距离关系识别上更是提高了8.9%。这项研究不仅推进了时间信息提取技术，还为通过增强的时间推理改进诊断和预后模型奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Introducing a novel method for joint extraction of medical events and\n  temporal relations from free-text, leveraging clinical LPLMs and\n  Heterogeneous Graph Transformers, achieving a 5.5% improvement over the\n  previous state-of-the-art and up to 8.9% on long-range relations",
      "pdf_url": "http://arxiv.org/pdf/2503.18085v1",
      "published_date": "2025-03-23 14:34:49 UTC",
      "updated_date": "2025-03-23 14:34:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:27:27.990774"
    },
    {
      "arxiv_id": "2503.18072v1",
      "title": "On the effectiveness of LLMs for automatic grading of open-ended questions in Spanish",
      "title_zh": "论大语言模型在西班牙语开放式问题自动评分中的有效性",
      "authors": [
        "Germán Capdehourat",
        "Isabel Amigo",
        "Brian Lorenzo",
        "Joaquín Trigo"
      ],
      "abstract": "Grading is a time-consuming and laborious task that educators must face. It\nis an important task since it provides feedback signals to learners, and it has\nbeen demonstrated that timely feedback improves the learning process. In recent\nyears, the irruption of LLMs has shed light on the effectiveness of automatic\ngrading. In this paper, we explore the performance of different LLMs and\nprompting techniques in automatically grading short-text answers to open-ended\nquestions. Unlike most of the literature, our study focuses on a use case where\nthe questions, answers, and prompts are all in Spanish. Experimental results\ncomparing automatic scores to those of human-expert evaluators show good\noutcomes in terms of accuracy, precision and consistency for advanced LLMs,\nboth open and proprietary. Results are notably sensitive to prompt styles,\nsuggesting biases toward certain words or content in the prompt. However, the\nbest combinations of models and prompt strategies, consistently surpasses an\naccuracy of 95% in a three-level grading task, which even rises up to more than\n98% when the it is simplified to a binary right or wrong rating problem, which\ndemonstrates the potential that LLMs have to implement this type of automation\nin education applications.",
      "tldr_zh": "本研究评估了大型语言模型(LLMs)在西班牙语开放式问题自动评分中的效果。实验表明，无论是开源还是专有LLMs，在西班牙语短文本答案评分任务中都能达到较高准确率(95%三级评分/98%二元评分)，但对提示词风格敏感。该研究证实了LLMs在教育领域自动评分应用中的潜力，特别为西班牙语教学场景提供了实证支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18072v1",
      "published_date": "2025-03-23 13:43:27 UTC",
      "updated_date": "2025-03-23 13:43:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:27:46.630971"
    },
    {
      "arxiv_id": "2503.18065v1",
      "title": "Unseen from Seen: Rewriting Observation-Instruction Using Foundation Models for Augmenting Vision-Language Navigation",
      "title_zh": "《未见源于可见：利用基础模型改写观察指令以增强视觉语言导航》",
      "authors": [
        "Ziming Wei",
        "Bingqian Lin",
        "Yunshuang Nie",
        "Jiaqi Chen",
        "Shikui Ma",
        "Hang Xu",
        "Xiaodan Liang"
      ],
      "abstract": "Data scarcity is a long-standing challenge in the Vision-Language Navigation\n(VLN) field, which extremely hinders the generalization of agents to unseen\nenvironments. Previous works primarily rely on additional simulator data or\nweb-collected images/videos to improve the generalization. However, the\nsimulator environments still face limited diversity, and the web-collected data\noften requires extensive labor to remove the noise. In this paper, we propose a\nRewriting-driven AugMentation (RAM) paradigm for VLN, which directly creates\nthe unseen observation-instruction pairs via rewriting human-annotated training\ndata. Benefiting from our rewriting mechanism, new observation-instruction can\nbe obtained in both simulator-free and labor-saving manners to promote\ngeneralization. Specifically, we first introduce Object-Enriched Observation\nRewriting, where we combine Vision-Language Models (VLMs) and Large Language\nModels (LLMs) to derive rewritten object-enriched scene descriptions, enabling\nobservation synthesis with diverse objects and spatial layouts via\nText-to-Image Generation Models (T2IMs). Then, we propose Observation-Contrast\nInstruction Rewriting, which generates observation-aligned rewritten\ninstructions by requiring LLMs to reason the difference between original and\nnew observations. We further develop a mixing-then-focusing training strategy\nwith a random observation cropping scheme, effectively enhancing data\ndistribution diversity while suppressing augmentation data noise during\ntraining. Experiments on both the discrete environments (R2R, REVERIE, and R4R\ndatasets) and continuous environments (R2R-CE dataset) show the superior\nperformance and impressive generalization ability of our method. Code is\navailable at https://github.com/SaDil13/VLN-RAM.",
      "tldr_zh": "本研究提出了一种基于重写机制的视觉语言导航(VLN)数据增强方法RAM，通过改写现有训练数据直接生成未见过的观察-指令对，解决了该领域长期存在的数据稀缺问题。该方法包含两个核心模块：(1)利用视觉语言模型(VLMs)和大语言模型(LLMs)进行物体增强的观察重写，通过文本到图像生成模型(T2IMs)合成多样化的场景；(2)开发观察对比的指令重写机制，使LLMs能根据新旧观察差异生成对齐的指令。实验表明，该框架在离散(R2R/REVERIE/R4R)和连续(R2R-CE)环境中均展现出优越性能和泛化能力，且无需额外模拟器或人工清洗网络数据。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18065v1",
      "published_date": "2025-03-23 13:18:17 UTC",
      "updated_date": "2025-03-23 13:18:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:28:07.702105"
    },
    {
      "arxiv_id": "2503.18063v1",
      "title": "Dynamic Task Vector Grouping for Efficient Multi-Task Prompt Tuning",
      "title_zh": "动态任务向量分组：面向高效多任务提示调优的方法",
      "authors": [
        "Pieyi Zhang",
        "Richong Zhang",
        "Zhijie Nie"
      ],
      "abstract": "Multi-task prompt tuning utilizes multiple high-resource source tasks to\nimprove performance on low-source target tasks. Existing approaches transfer\nthe soft prompt trained by combining all source tasks or a single\n``high-similar'' source task one-time-only. However, we find that the optimal\ntransfer performance often comes from a combination of source tasks, which is\nneither one nor all. Further, we find that the similarity between source and\ntarget tasks also changes dynamically during fine-tuning after transfering,\nmaking similarity calculation in the initiation stage inadequate. To address\nthese issues, we propose a method called Dynamic Task Vector Grouping (DTVG),\nwhose core ideas contain (1) measuring the task similarity with task vectors\ninstead of soft prompt, (2) grouping the optimal source task combination based\non two metrics: {\\it target similarity} and {\\it knowledge consistency}; (3)\ndynamically updating the combination in each iteration step. Extensive\nexperiments on the 26 NLP datasets under different settings demonstrate that\nDTVG effectively groups similar source tasks while reducing negative transfer,\nachieving the start-of-art performance.",
      "tldr_zh": "该研究提出动态任务向量分组(DTVG)方法，用于优化多任务提示调参(prompt tuning)。针对现有方法仅使用全部或单个高相似源任务的问题，DTVG通过任务向量(task vectors)动态评估源-目标任务的相似度，并基于目标相似度和知识一致性两指标进行最优任务组合分组。该方法在训练过程中持续更新任务组合，在26个NLP数据集上的实验表明，DTVG能有效减少负迁移，实现最优性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.18063v1",
      "published_date": "2025-03-23 13:09:04 UTC",
      "updated_date": "2025-03-23 13:09:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:28:24.731966"
    },
    {
      "arxiv_id": "2503.18025v1",
      "title": "Decision from Suboptimal Classifiers: Excess Risk Pre- and Post-Calibration",
      "title_zh": "次优分类器的决策：校准前后的超额风险分析",
      "authors": [
        "Alexandre Perez-Lebel",
        "Gael Varoquaux",
        "Sanmi Koyejo",
        "Matthieu Doutreligne",
        "Marine Le Morvan"
      ],
      "abstract": "Probabilistic classifiers are central for making informed decisions under\nuncertainty. Based on the maximum expected utility principle, optimal decision\nrules can be derived using the posterior class probabilities and\nmisclassification costs. Yet, in practice only learned approximations of the\noracle posterior probabilities are available. In this work, we quantify the\nexcess risk (a.k.a. regret) incurred using approximate posterior probabilities\nin batch binary decision-making. We provide analytical expressions for\nmiscalibration-induced regret ($R^{\\mathrm{CL}}$), as well as tight and\ninformative upper and lower bounds on the regret of calibrated classifiers\n($R^{\\mathrm{GL}}$). These expressions allow us to identify regimes where\nrecalibration alone addresses most of the regret, and regimes where the regret\nis dominated by the grouping loss, which calls for post-training beyond\nrecalibration. Crucially, both $R^{\\mathrm{CL}}$ and $R^{\\mathrm{GL}}$ can be\nestimated in practice using a calibration curve and a recent grouping loss\nestimator. On NLP experiments, we show that these quantities identify when the\nexpected gain of more advanced post-training is worth the operational cost.\nFinally, we highlight the potential of multicalibration approaches as efficient\nalternatives to costlier fine-tuning approaches.",
      "tldr_zh": "该研究量化了在二元分类决策中使用近似后验概率所导致的超额风险（excess risk）。论文提出了分析表达式来衡量校准不足引起的风险（R^CL），并为校准分类器的风险（R^GL）提供了紧致的上下界。研究揭示了两种关键场景：一种是仅通过重新校准即可显著降低风险的情况，另一种是风险主要由分组损失主导而需要进一步训练优化的场景。实验证明，这些风险指标能有效指导NLP任务中后训练策略的选择，并发现多校准方法可作为微调的高效替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18025v1",
      "published_date": "2025-03-23 10:52:36 UTC",
      "updated_date": "2025-03-23 10:52:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:28:46.722092"
    },
    {
      "arxiv_id": "2503.18018v1",
      "title": "Lost in Cultural Translation: Do LLMs Struggle with Math Across Cultural Contexts?",
      "title_zh": "文化翻译中的迷失：大语言模型在不同文化背景下的数学能力会受到影响吗？",
      "authors": [
        "Aabid Karim",
        "Abdul Karim",
        "Bhoomika Lohana",
        "Matt Keon",
        "Jaswinder Singh",
        "Abdul Sattar"
      ],
      "abstract": "Large Language Models (LLMs) have significantly advanced various fields,\nparticularly coding, mathematical reasoning, and logical problem solving.\nHowever, a critical question remains: Do these mathematical reasoning abilities\npersist when LLMs are presented with culturally adapted math problems?\nSpecifically, how do LLMs perform when faced with math problems embedded in\ncultural contexts that have no significant representation in main stream\nweb-scale AI training data? To explore this, we generated six synthetic\ncultural datasets from GSM8K, a widely used benchmark for assessing LLMs'\nmathematical reasoning skills. While preserving the mathematical logic and\nnumerical values of the original GSM8K test set, we modify cultural elements\nsuch as personal names, food items, place names, etc. These culturally adapted\ndatasets provide a more reliable framework for evaluating LLMs' mathematical\nreasoning under shifting cultural contexts. Our findings reveal that LLMs\nstruggle with math problems when cultural references change, even though the\nunderlying mathematical structure remains constant. Smaller models exhibit\ngreater performance drops compared to larger models. Interestingly, our results\nalso suggest that cultural familiarity can enhance mathematical reasoning. Even\nmodels with no explicit mathematical training but exposure to relevant cultural\ncontexts sometimes outperform larger, mathematically proficient models on\nculturally embedded math problems. This study highlights the impact of cultural\ncontext on the mathematical reasoning abilities of LLMs, underscoring the need\nfor more diverse and representative training data to improve robustness in\nreal-world applications. The benchmark data sets and script for reproducing the\nresults are available at\nhttps://github.com/akarim23131/Lost_in_Cultural_Translation",
      "tldr_zh": "本研究探讨了大语言模型(LLMs)在不同文化背景下的数学推理能力。通过基于GSM8K基准生成六种合成文化数据集，研究发现，即使数学逻辑和数值保持不变，LLMs在处理文化元素（如人名、食物、地名等）发生变化的数学问题时表现显著下降，且较小模型的性能下降更为明显。有趣的是，文化熟悉度能够增强数学推理能力，某些未经过专门数学训练但接触过相关文化背景的模型，在处理文化嵌入的数学问题时甚至优于更大的数学精通模型。这一发现强调了文化语境对LLMs数学推理能力的影响，表明需要更多样化和代表性的训练数据以提高实际应用中的鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18018v1",
      "published_date": "2025-03-23 10:35:39 UTC",
      "updated_date": "2025-03-23 10:35:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:29:04.111706"
    },
    {
      "arxiv_id": "2503.18013v1",
      "title": "Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models via Vision-Guided Reinforcement Learning",
      "title_zh": "Vision-R1：通过视觉引导强化学习实现大型视觉语言模型的无人类对齐进化",
      "authors": [
        "Yufei Zhan",
        "Yousong Zhu",
        "Shurong Zheng",
        "Hongyin Zhao",
        "Fan Yang",
        "Ming Tang",
        "Jinqiao Wang"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) typically follow a two-stage training\nparadigm-pretraining and supervised fine-tuning. Recently, preference\noptimization, derived from the language domain, has emerged as an effective\npost-training reinforcement strategy to enhance capabilities of LVLMs. However,\nconstructing high-quality human-annotated preference data and developing robust\nreward models to mimic these preferences are both costly and challenging.\nMotivated by this observation, we propose Vision-R1, a novel vision-guided\nR1-like reinforcement learning algorithm for LVLMs that rewards models with\ndefinitive vision feedback. It only leverages curated instruction data,\neliminating the need for specialized reward models and handcrafted preference\ndatasets. We incorporate a criterion-driven reward function that further\nintegrates multi-dimensional feedback to evaluate model completions\ncomprehensively based on the vision task logic. Furthermore, we introduce a\nprogressive rule refinement strategy that dynamically adjusts the reward\ncriteria during training, enabling continuous model improvement and mitigating\nreward hacking. Extensive experiments on both in-distribution and\nout-of-distribution benchmarks demonstrate that fine-tuning the 7B LVLMs with\nVision-R1 achieves consistent performance gains, with even up to 50%\nimprovement and surpassing the state-of-the-art 10x size model.",
      "tldr_zh": "本文提出Vision-R1算法，通过视觉引导的强化学习实现大视觉语言模型（LVLMs）的无人类标注对齐。该方法创新性地利用确定性视觉反馈作为奖励信号，省去了传统偏好优化所需的专业奖励模型和人工标注数据集。研究者设计了基于任务逻辑的多维度奖励函数，并采用渐进式规则优化策略动态调整奖励标准，有效防止奖励破解问题。实验表明，仅用7B参数的模型经Vision-R1微调后，性能最高提升50%，甚至超越10倍规模的现有最优模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project in development. Github:\n  https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1",
      "pdf_url": "http://arxiv.org/pdf/2503.18013v1",
      "published_date": "2025-03-23 10:21:14 UTC",
      "updated_date": "2025-03-23 10:21:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:29:23.760868"
    },
    {
      "arxiv_id": "2503.18988v1",
      "title": "SG-Tailor: Inter-Object Commonsense Relationship Reasoning for Scene Graph Manipulation",
      "title_zh": "SG-Tailor：面向场景图操控的物体间常识关系推理",
      "authors": [
        "Haoliang Shang",
        "Hanyu Wu",
        "Guangyao Zhai",
        "Boyang Sun",
        "Fangjinhua Wang",
        "Federico Tombari",
        "Marc Pollefeys"
      ],
      "abstract": "Scene graphs capture complex relationships among objects, serving as strong\npriors for content generation and manipulation. Yet, reasonably manipulating\nscene graphs -- whether by adding nodes or modifying edges -- remains a\nchallenging and untouched task. Tasks such as adding a node to the graph or\nreasoning about a node's relationships with all others are computationally\nintractable, as even a single edge modification can trigger conflicts due to\nthe intricate interdependencies within the graph. To address these challenges,\nwe introduce SG-Tailor, an autoregressive model that predicts the conflict-free\nrelationship between any two nodes. SG-Tailor not only infers inter-object\nrelationships, including generating commonsense edges for newly added nodes but\nalso resolves conflicts arising from edge modifications to produce coherent,\nmanipulated graphs for downstream tasks. For node addition, the model queries\nthe target node and other nodes from the graph to predict the appropriate\nrelationships. For edge modification, SG-Tailor employs a Cut-And-Stitch\nstrategy to solve the conflicts and globally adjust the graph. Extensive\nexperiments demonstrate that SG-Tailor outperforms competing methods by a large\nmargin and can be seamlessly integrated as a plug-in module for scene\ngeneration and robotic manipulation tasks.",
      "tldr_zh": "该研究提出了SG-Tailor，一种用于场景图（Scene Graph）操作的自回归模型，专注于解决对象间常识关系推理的难题。SG-Tailor通过预测无冲突的节点间关系，能够生成新增节点的常识边，并解决边修改引发的冲突，从而生成一致的操作后场景图。模型采用“Cut-And-Stitch”策略全局调整图结构，显著优于现有方法，并可作为插件模块无缝集成到场景生成和机器人操作任务中。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "The code will be available at https://github.com/josef5838/SG-Tailor",
      "pdf_url": "http://arxiv.org/pdf/2503.18988v1",
      "published_date": "2025-03-23 09:11:04 UTC",
      "updated_date": "2025-03-23 09:11:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:29:58.925956"
    },
    {
      "arxiv_id": "2503.17994v1",
      "title": "Instructing the Architecture Search for Spatial-temporal Sequence Forecasting with LLM",
      "title_zh": "基于大语言模型指导的时空序列预测架构搜索",
      "authors": [
        "Xin Xue",
        "Haoyi Zhou",
        "Tianyu Chen",
        "Shuai Zhang",
        "Yizhou Long",
        "Jianxin Li"
      ],
      "abstract": "Spatial-temporal sequence forecasting (STSF) is a long-standing research\nproblem with widespread real-world applications. Neural architecture search\n(NAS), which automates the neural network design, has been shown effective in\ntackling the STSF problem. However, the existing NAS methods for STSF focus on\ngenerating architectures in a time-consuming data-driven fashion, which heavily\nlimits their ability to use background knowledge and explore the complicated\nsearch trajectory. Large language models (LLMs) have shown remarkable ability\nin decision-making with comprehensive internal world knowledge, but how it\ncould benefit NAS for STSF remains unexplored. In this paper, we propose a\nnovel NAS method for STSF based on LLM. Instead of directly generate\narchitectures with LLM, We inspire the LLM's capability with a multi-level\nenhancement mechanism. Specifically, on the step-level, we decompose the\ngeneration task into decision steps with powerful prompt engineering and\ninspire LLM to serve as instructor for architecture search based on its\ninternal knowledge. On the instance-level, we utilize a one-step tuning\nframework to quickly evaluate the architecture instance and a memory bank to\ncumulate knowledge to improve LLM's search ability. On the task-level, we\npropose a two-stage architecture search, balancing the exploration stage and\noptimization stage, to reduce the possibility of being trapped in local optima.\nExtensive experimental results demonstrate that our method can achieve\ncompetitive effectiveness with superior efficiency against existing NAS methods\nfor STSF.",
      "tldr_zh": "本文提出了一种基于大语言模型(LLM)的新型神经架构搜索(NAS)方法，用于时空序列预测(STSF)任务。该方法通过三级增强机制激发LLM潜力：1)在步骤层面，将架构生成分解为决策步骤并运用提示工程；2)在实例层面，采用一步调优框架和记忆库累积知识；3)在任务层面，设计两阶段搜索策略平衡探索与优化。实验表明，该方法在保持高效的同时，性能优于现有STSF的NAS方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17994v1",
      "published_date": "2025-03-23 08:59:04 UTC",
      "updated_date": "2025-03-23 08:59:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:30:03.864592"
    },
    {
      "arxiv_id": "2503.17993v1",
      "title": "Predicting Multitasking in Manual and Automated Driving with Optimal Supervisory Control",
      "title_zh": "《预测手动与自动驾驶中的多任务行为：基于最优监控控制理论》",
      "authors": [
        "Jussi Jokinen",
        "Patrick Ebel",
        "Tuomo Kujala"
      ],
      "abstract": "Modern driving involves interactive technologies that can divert attention,\nincreasing the risk of accidents. This paper presents a computational cognitive\nmodel that simulates human multitasking while driving. Based on optimal\nsupervisory control theory, the model predicts how multitasking adapts to\nvariations in driving demands, interactive tasks, and automation levels. Unlike\nprevious models, it accounts for context-dependent multitasking across\ndifferent degrees of driving automation. The model predicts longer in-car\nglances on straight roads and shorter glances during curves. It also\nanticipates increased glance durations with driver aids such as lane-centering\nassistance and their interaction with environmental demands. Validated against\ntwo empirical datasets, the model offers insights into driver multitasking amid\nevolving in-car technologies and automation.",
      "tldr_zh": "本研究提出了一种基于最优监督控制理论的计算认知模型，用于预测手动和自动驾驶中的人类多任务行为。该模型创新性地考虑了不同自动化水平下情境依赖的多任务处理，能够预测驾驶员在直路（更长注视时间）和弯道（更短注视时间）等不同路况下的注意力分配模式。实验验证表明，模型能准确预测车道居中辅助等驾驶辅助技术对驾驶员注视时间的影响，为理解新兴车载技术环境下的驾驶员行为提供了理论框架。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "H.1.2"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17993v1",
      "published_date": "2025-03-23 08:56:53 UTC",
      "updated_date": "2025-03-23 08:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:30:24.816728"
    },
    {
      "arxiv_id": "2503.17987v1",
      "title": "Metaphor-based Jailbreaking Attacks on Text-to-Image Models",
      "title_zh": "基于隐喻的文本到图像模型越狱攻击",
      "authors": [
        "Chenyu Zhang",
        "Yiwen Ma",
        "Lanjun Wang",
        "Wenhui Li",
        "Yi Tu",
        "An-An Liu"
      ],
      "abstract": "To mitigate misuse, text-to-image~(T2I) models commonly incorporate safety\nfilters to prevent the generation of sensitive images. Unfortunately, recent\njailbreaking attack methods use LLMs to generate adversarial prompts that\neffectively bypass safety filters while generating sensitive images, revealing\nthe safety vulnerabilities within the T2I model. However, existing LLM-based\nattack methods lack explicit guidance, relying on substantial queries to\nachieve a successful attack, which limits their practicality in real-world\nscenarios. In this work, we introduce \\textbf{MJA}, a \\textbf{m}etaphor-based\n\\textbf{j}ailbreaking \\textbf{a}ttack method inspired by the Taboo game, aiming\nto balance the attack effectiveness and query efficiency by generating\nmetaphor-based adversarial prompts. Specifically, MJA consists of two modules:\nan LLM-based multi-agent generation module~(MLAG) and an adversarial prompt\noptimization module~(APO). MLAG decomposes the generation of metaphor-based\nadversarial prompts into three subtasks: metaphor retrieval, context matching,\nand adversarial prompt generation. Subsequently, MLAG coordinates three\nLLM-based agents to generate diverse adversarial prompts by exploring various\nmetaphors and contexts. To enhance the attack efficiency, APO first trains a\nsurrogate model to predict the attack results of adversarial prompts and then\ndesigns an acquisition strategy to adaptively identify optimal adversarial\nprompts. Experiments demonstrate that MJA achieves better attack effectiveness\nwhile requiring fewer queries compared to baseline methods. Moreover, our\nadversarial prompts exhibit strong transferability across various open-source\nand commercial T2I models. \\textcolor{red}{This paper includes model-generated\ncontent that may contain offensive or distressing material.}",
      "tldr_zh": "该研究提出了一种基于隐喻的越狱攻击方法MJA，通过模仿\"禁忌游戏\"机制来攻击文本到图像(T2I)模型的安全过滤器。该方法采用多智能体系统(MLAG)进行隐喻检索和对抗提示生成，并利用对抗提示优化模块(APO)训练代理模型预测攻击效果，显著提高了攻击效率。实验表明，相比现有方法，MJA能以更少的查询次数实现更高的攻击成功率，且生成的对抗提示在不同T2I模型间展现出强迁移性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "13 page3, 4 figures. This paper includes model-generated content that\n  may contain offensive or distressing material",
      "pdf_url": "http://arxiv.org/pdf/2503.17987v1",
      "published_date": "2025-03-23 08:40:39 UTC",
      "updated_date": "2025-03-23 08:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:30:51.411122"
    },
    {
      "arxiv_id": "2503.17985v1",
      "title": "Optimizing Navigation And Chemical Application in Precision Agriculture With Deep Reinforcement Learning And Conditional Action Tree",
      "title_zh": "基于深度强化学习与条件动作树的精准农业导航与施药优化",
      "authors": [
        "Mahsa Khosravi",
        "Zhanhong Jiang",
        "Joshua R Waite",
        "Sarah Jonesc",
        "Hernan Torres",
        "Arti Singh",
        "Baskar Ganapathysubramanian",
        "Asheesh Kumar Singh",
        "Soumik Sarkar"
      ],
      "abstract": "This paper presents a novel reinforcement learning (RL)-based planning scheme\nfor optimized robotic management of biotic stresses in precision agriculture.\nThe framework employs a hierarchical decision-making structure with conditional\naction masking, where high-level actions direct the robot's exploration, while\nlow-level actions optimize its navigation and efficient chemical spraying in\naffected areas. The key objectives of optimization include improving the\ncoverage of infected areas with limited battery power and reducing chemical\nusage, thus preventing unnecessary spraying of healthy areas of the field. Our\nnumerical experimental results demonstrate that the proposed method,\nHierarchical Action Masking Proximal Policy Optimization (HAM-PPO),\nsignificantly outperforms baseline practices, such as LawnMower navigation +\nindiscriminate spraying (Carpet Spray), in terms of yield recovery and resource\nefficiency. HAM-PPO consistently achieves higher yield recovery percentages and\nlower chemical costs across a range of infection scenarios. The framework also\nexhibits robustness to observation noise and generalizability under diverse\nenvironmental conditions, adapting to varying infection ranges and spatial\ndistribution patterns.",
      "tldr_zh": "该研究提出了一种基于深度强化学习（DRL）的分层决策框架HAM-PPO，用于优化精准农业中的机器人导航和化学药剂喷洒。该方法通过条件动作掩码技术，实现了高层决策（探索路径规划）和底层执行（精准施药）的协同优化，在保证感染区域覆盖的同时显著减少药剂使用量和能耗。实验表明，相比传统地毯式喷洒方法，HAM-PPO在不同感染场景下均能提高作物恢复率（最高达29.32%）并降低30%以上的化学成本，且对观测噪声和环境变化展现出良好的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "32 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.17985v1",
      "published_date": "2025-03-23 08:38:13 UTC",
      "updated_date": "2025-03-23 08:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:31:04.126202"
    },
    {
      "arxiv_id": "2503.17984v1",
      "title": "Taste More, Taste Better: Diverse Data and Strong Model Boost Semi-Supervised Crowd Counting",
      "title_zh": "尝多尝好：多样化数据与强模型助力半监督人群计数",
      "authors": [
        "Maochen Yang",
        "Zekun Li",
        "Jian Zhang",
        "Lei Qi",
        "Yinghuan Shi"
      ],
      "abstract": "Semi-supervised crowd counting is crucial for addressing the high annotation\ncosts of densely populated scenes. Although several methods based on\npseudo-labeling have been proposed, it remains challenging to effectively and\naccurately utilize unlabeled data. In this paper, we propose a novel framework\ncalled Taste More Taste Better (TMTB), which emphasizes both data and model\naspects. Firstly, we explore a data augmentation technique well-suited for the\ncrowd counting task. By inpainting the background regions, this technique can\neffectively enhance data diversity while preserving the fidelity of the entire\nscenes. Secondly, we introduce the Visual State Space Model as backbone to\ncapture the global context information from crowd scenes, which is crucial for\nextremely crowded, low-light, and adverse weather scenarios. In addition to the\ntraditional regression head for exact prediction, we employ an Anti-Noise\nclassification head to provide less exact but more accurate supervision, since\nthe regression head is sensitive to noise in manual annotations. We conduct\nextensive experiments on four benchmark datasets and show that our method\noutperforms state-of-the-art methods by a large margin. Code is publicly\navailable on https://github.com/syhien/taste_more_taste_better.",
      "tldr_zh": "该研究提出了一种名为TMTB的半监督人群计数框架，通过数据增强和模型优化两方面提升性能。在数据层面，采用背景修复技术增强场景多样性；模型层面则创新性地结合了Visual State Space Model主干网络和抗噪分类头，有效解决了极端拥挤、低光照等复杂场景的计数难题。实验表明，该方法在四个基准数据集上大幅超越现有最优技术，同时代码已开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.17984v1",
      "published_date": "2025-03-23 08:38:01 UTC",
      "updated_date": "2025-03-23 08:38:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:31:25.518603"
    },
    {
      "arxiv_id": "2503.17982v1",
      "title": "Co-SemDepth: Fast Joint Semantic Segmentation and Depth Estimation on Aerial Images",
      "title_zh": "Co-SemDepth：航拍图像上快速联合语义分割与深度估计算法",
      "authors": [
        "Yara AlaaEldin",
        "Francesca Odone"
      ],
      "abstract": "Understanding the geometric and semantic properties of the scene is crucial\nin autonomous navigation and particularly challenging in the case of Unmanned\nAerial Vehicle (UAV) navigation. Such information may be by obtained by\nestimating depth and semantic segmentation maps of the surrounding environment\nand for their practical use in autonomous navigation, the procedure must be\nperformed as close to real-time as possible. In this paper, we leverage\nmonocular cameras on aerial robots to predict depth and semantic maps in\nlow-altitude unstructured environments. We propose a joint deep-learning\narchitecture that can perform the two tasks accurately and rapidly, and\nvalidate its effectiveness on MidAir and Aeroscapes benchmark datasets. Our\njoint-architecture proves to be competitive or superior to the other single and\njoint architecture methods while performing its task fast predicting 20.2 FPS\non a single NVIDIA quadro p5000 GPU and it has a low memory footprint. All\ncodes for training and prediction can be found on this link:\nhttps://github.com/Malga-Vision/Co-SemDepth",
      "tldr_zh": "该研究提出**Co-SemDepth**，一种用于无人机（UAV）场景的快速联合深度估计与语义分割框架。该模型通过单目摄像头实现低空非结构化环境下的实时预测（20.2 FPS），在MidAir和Aeroscapes基准测试中展现出优于单任务及其他联合架构的性能。其轻量级设计（低内存占用）特别适合机载计算平台，代码已在GitHub开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17982v1",
      "published_date": "2025-03-23 08:25:07 UTC",
      "updated_date": "2025-03-23 08:25:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:31:45.193253"
    },
    {
      "arxiv_id": "2503.18987v1",
      "title": "Balanced Direction from Multifarious Choices: Arithmetic Meta-Learning for Domain Generalization",
      "title_zh": "多元选择中的平衡导向：面向领域泛化的算术元学习",
      "authors": [
        "Xiran Wang",
        "Jian Zhang",
        "Lei Qi",
        "Yinghuan Shi"
      ],
      "abstract": "Domain generalization is proposed to address distribution shift, arising from\nstatistical disparities between training source and unseen target domains. The\nwidely used first-order meta-learning algorithms demonstrate strong performance\nfor domain generalization by leveraging the gradient matching theory, which\naims to establish balanced parameters across source domains to reduce\noverfitting to any particular domain. However, our analysis reveals that there\nare actually numerous directions to achieve gradient matching, with current\nmethods representing just one possible path. These methods actually overlook\nanother critical factor that the balanced parameters should be close to the\ncentroid of optimal parameters of each source domain. To address this, we\npropose a simple yet effective arithmetic meta-learning with\narithmetic-weighted gradients. This approach, while adhering to the principles\nof gradient matching, promotes a more precise balance by estimating the\ncentroid between domain-specific optimal parameters. Experimental results\nvalidate the effectiveness of our strategy.",
      "tldr_zh": "本文提出了一种基于算术加权梯度的新型元学习方法（arithmetic meta-learning），用于解决领域泛化（domain generalization）中的分布偏移问题。研究发现当前一阶元学习方法仅实现了梯度匹配（gradient matching）的其中一种可能路径，而忽视了平衡参数应接近各源域最优参数质心这一关键因素。通过算术加权梯度策略，该方法在保持梯度匹配原则的同时，能更精确地估计域间最优参数质心，实验验证了该策略的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18987v1",
      "published_date": "2025-03-23 08:24:28 UTC",
      "updated_date": "2025-03-23 08:24:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:32:04.282573"
    },
    {
      "arxiv_id": "2503.17979v1",
      "title": "Trade-offs in Large Reasoning Models: An Empirical Analysis of Deliberative and Adaptive Reasoning over Foundational Capabilities",
      "title_zh": "大型推理模型的权衡取舍：基于基础能力的审慎推理与自适应推理实证分析",
      "authors": [
        "Weixiang Zhao",
        "Xingyu Sui",
        "Jiahe Guo",
        "Yulin Hu",
        "Yang Deng",
        "Yanyan Zhao",
        "Bing Qin",
        "Wanxiang Che",
        "Tat-Seng Chua",
        "Ting Liu"
      ],
      "abstract": "Recent advancements in Large Reasoning Models (LRMs), such as OpenAI's o1/o3\nand DeepSeek-R1, have demonstrated remarkable performance in specialized\nreasoning tasks through human-like deliberative thinking and long\nchain-of-thought reasoning. However, our systematic evaluation across various\nmodel families (DeepSeek, Qwen, and LLaMA) and scales (7B to 671B) reveals that\nacquiring these deliberative reasoning capabilities significantly reduces the\nfoundational capabilities of LRMs, including notable declines in helpfulness\nand harmlessness, alongside substantially increased inference costs.\nImportantly, we demonstrate that adaptive reasoning -- employing modes like\nZero-Thinking, Less-Thinking, and Summary-Thinking -- can effectively alleviate\nthese drawbacks. Our empirical insights underline the critical need for\ndeveloping more versatile LRMs capable of dynamically allocating inference-time\ncompute according to specific task characteristics.",
      "tldr_zh": "该研究系统评估了大型推理模型(LRMs)在获得类人深思熟虑推理能力时面临的关键权衡问题。实验发现，采用长链式思维推理(Chain-of-Thought)虽提升专业任务表现，但会显著削弱模型的基础能力(如helpfulness和harmlessness)，并大幅增加推理成本。研究提出自适应推理(Adaptive Reasoning)方案，通过Zero-Thinking等动态模式能有效缓解这些缺陷，为开发能按任务特性动态分配计算资源的通用LRMs提供了重要启示。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages. Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.17979v1",
      "published_date": "2025-03-23 08:18:51 UTC",
      "updated_date": "2025-03-23 08:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:33:05.693079"
    },
    {
      "arxiv_id": "2503.17978v1",
      "title": "PIM: Physics-Informed Multi-task Pre-training for Improving Inertial Sensor-Based Human Activity Recognition",
      "title_zh": "PIM：基于物理信息的多任务预训练提升惯性传感器人体活动识别",
      "authors": [
        "Dominique Nshimyimana",
        "Vitor Fortes Rey",
        "Sungho Suh",
        "Bo Zhou",
        "Paul Lukowicz"
      ],
      "abstract": "Human activity recognition (HAR) with deep learning models relies on large\namounts of labeled data, often challenging to obtain due to associated cost,\ntime, and labor. Self-supervised learning (SSL) has emerged as an effective\napproach to leverage unlabeled data through pretext tasks, such as masked\nreconstruction and multitask learning with signal processing-based data\naugmentations, to pre-train encoder models. However, such methods are often\nderived from computer vision approaches that disregard physical mechanisms and\nconstraints that govern wearable sensor data and the phenomena they reflect. In\nthis paper, we propose a physics-informed multi-task pre-training (PIM)\nframework for IMU-based HAR. PIM generates pre-text tasks based on the\nunderstanding of basic physical aspects of human motion: including movement\nspeed, angles of movement, and symmetry between sensor placements. Given a\nsensor signal, we calculate corresponding features using physics-based\nequations and use them as pretext tasks for SSL. This enables the model to\ncapture fundamental physical characteristics of human activities, which is\nespecially relevant for multi-sensor systems. Experimental evaluations on four\nHAR benchmark datasets demonstrate that the proposed method outperforms\nexisting state-of-the-art methods, including data augmentation and masked\nreconstruction, in terms of accuracy and F1 score. We have observed gains of\nalmost 10\\% in macro f1 score and accuracy with only 2 to 8 labeled examples\nper class and up to 3% when there is no reduction in the amount of training\ndata.",
      "tldr_zh": "该研究提出了一种物理信息多任务预训练框架PIM，用于改进基于惯性传感器(IMU)的人类活动识别(HAR)。通过结合人体运动的基本物理特性（如速度、角度和传感器对称性）设计自监督学习任务，该框架克服了传统视觉衍生方法忽视物理约束的局限性。实验表明，PIM在四个基准数据集上显著优于现有方法，在每类仅2-8个标注样本时实现近10%的F1分数提升，即使使用完整训练数据仍有3%的性能增益。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17978v1",
      "published_date": "2025-03-23 08:16:01 UTC",
      "updated_date": "2025-03-23 08:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:32:44.990991"
    },
    {
      "arxiv_id": "2503.17975v2",
      "title": "Shot Sequence Ordering for Video Editing: Benchmarks, Metrics, and Cinematology-Inspired Computing Methods",
      "title_zh": "视频剪辑中的镜头序列排序：基准测试、评估指标与电影学启发的计算方法",
      "authors": [
        "Yuzhi Li",
        "Haojun Xu",
        "Feng Tian"
      ],
      "abstract": "With the rising popularity of short video platforms, the demand for video\nproduction has increased substantially. However, high-quality video creation\ncontinues to rely heavily on professional editing skills and a nuanced\nunderstanding of visual language. To address this challenge, the Shot Sequence\nOrdering (SSO) task in AI-assisted video editing has emerged as a pivotal\napproach for enhancing video storytelling and the overall viewing experience.\nNevertheless, the progress in this field has been impeded by a lack of publicly\navailable benchmark datasets. In response, this paper introduces two novel\nbenchmark datasets, AVE-Order and ActivityNet-Order. Additionally, we employ\nthe Kendall Tau distance as an evaluation metric for the SSO task and propose\nthe Kendall Tau Distance-Cross Entropy Loss. We further introduce the concept\nof Cinematology Embedding, which incorporates movie metadata and shot labels as\nprior knowledge into the SSO model, and constructs the AVE-Meta dataset to\nvalidate the method's effectiveness. Experimental results indicate that the\nproposed loss function and method substantially enhance SSO task accuracy. All\ndatasets are publicly accessible at https://github.com/litchiar/ShotSeqBench.",
      "tldr_zh": "该研究针对AI辅助视频编辑中的镜头序列排序(SSO)任务，提出两个新基准数据集AVE-Order和ActivityNet-Order，并采用Kendall Tau距离作为评估指标。作者创新性地提出Kendall Tau距离交叉熵损失函数，并引入电影元数据和镜头标签作为先验知识的\"电影学嵌入\"(Cinematology Embedding)方法。实验证明，所提出的损失函数和方法显著提升了SSO任务的准确性，相关数据集已开源供研究社区使用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17975v2",
      "published_date": "2025-03-23 08:04:45 UTC",
      "updated_date": "2025-03-25 11:37:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:33:23.025046"
    },
    {
      "arxiv_id": "2503.18986v1",
      "title": "SplitFrozen: Split Learning with Device-side Model Frozen for Fine-Tuning LLM on Heterogeneous Resource-Constrained Devices",
      "title_zh": "SplitFrozen：面向异构资源受限设备的LLM微调技术——基于设备端模型冻结的拆分学习框架",
      "authors": [
        "Jian Ma",
        "Xinchen Lyu",
        "Jun Jiang",
        "Qimei Cui",
        "Haipeng Yao",
        "Xiaofeng Tao"
      ],
      "abstract": "Fine-tuning large language models (LLMs) on private, on-device data can\nempower tailored personalized AI agents. However, fine-tuning LLMs on\nresource-constrained edge devices faces significant challenges, including\nexcessive computation overhead, device heterogeneity, and data imbalance. This\npaper proposes SplitFrozen, a split learning framework that enables efficient\nLLM fine-tuning by strategically freezing device-side model layers while\ncentralizing parameter-efficient fine-tuning on the server. Our framework\npartitions LLMs into device-side frozen layers and server-side fine-tuning\nlayers, where heterogeneous resource-constrained devices execute only forward\npropagation. To minimize server-side training costs, we integrate Low-Rank\nAdaptation (LoRA) into the server-side layers. A pipeline parallelism strategy\nfurther optimizes training efficiency by decoupling device-server computations\nand leveraging decomposed backward propagation. Experiments on GPT-2 with the\nMRPC, MNLI-matched, and SST-2 datasets demonstrate that SplitFrozen outperforms\nFedLoRA and SplitLoRA by 69.4\\% model accuracy under extremely imbalanced data,\nwhile reducing up to 86.8\\% device-side computations and 50.2\\% total training\ntime. Experiments also validate the scalability of SplitFrozen on content\ngeneration task using Llama-3.2 model on GSM8K dataset.",
      "tldr_zh": "本文提出SplitFrozen框架，通过分割学习和设备端模型冻结策略，在资源受限的异构设备上实现高效LLM微调。该方法将大语言模型划分为设备端冻结层和服务器端微调层，设备仅需执行前向传播，同时服务器端采用LoRA（低秩适配）技术降低计算开销。实验表明，SplitFrozen在数据极度不平衡情况下比FedLoRA和SplitLoRA准确率提升69.4%，并减少86.8%设备端计算和50.2%总训练时间，在Llama-3.2模型的内容生成任务中也展现出良好扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18986v1",
      "published_date": "2025-03-23 08:03:44 UTC",
      "updated_date": "2025-03-23 08:03:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:33:24.874872"
    },
    {
      "arxiv_id": "2503.17973v1",
      "title": "PhysTwin: Physics-Informed Reconstruction and Simulation of Deformable Objects from Videos",
      "title_zh": "PhysTwin：基于物理信息的视频可变形物体重建与仿真",
      "authors": [
        "Hanxiao Jiang",
        "Hao-Yu Hsu",
        "Kaifeng Zhang",
        "Hsin-Ni Yu",
        "Shenlong Wang",
        "Yunzhu Li"
      ],
      "abstract": "Creating a physical digital twin of a real-world object has immense potential\nin robotics, content creation, and XR. In this paper, we present PhysTwin, a\nnovel framework that uses sparse videos of dynamic objects under interaction to\nproduce a photo- and physically realistic, real-time interactive virtual\nreplica. Our approach centers on two key components: (1) a physics-informed\nrepresentation that combines spring-mass models for realistic physical\nsimulation, generative shape models for geometry, and Gaussian splats for\nrendering; and (2) a novel multi-stage, optimization-based inverse modeling\nframework that reconstructs complete geometry, infers dense physical\nproperties, and replicates realistic appearance from videos. Our method\nintegrates an inverse physics framework with visual perception cues, enabling\nhigh-fidelity reconstruction even from partial, occluded, and limited\nviewpoints. PhysTwin supports modeling various deformable objects, including\nropes, stuffed animals, cloth, and delivery packages. Experiments show that\nPhysTwin outperforms competing methods in reconstruction, rendering, future\nprediction, and simulation under novel interactions. We further demonstrate its\napplications in interactive real-time simulation and model-based robotic motion\nplanning.",
      "tldr_zh": "该论文提出PhysTwin框架，通过稀疏视频数据重建可变形物体的数字化物理孪生体。该方法结合弹簧质量模型（spring-mass）进行物理仿真、生成式形状建模和高斯泼溅（Gaussian splats）渲染，开发了基于优化的逆向建模框架，能从视频中推断完整几何结构和密集物理属性。实验表明，PhysTwin在重建精度、实时交互仿真和新交互场景预测方面优于现有方法，可应用于绳类、布料等多种可变形物体的建模及机器人运动规划。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://jianghanxiao.github.io/phystwin-web/",
      "pdf_url": "http://arxiv.org/pdf/2503.17973v1",
      "published_date": "2025-03-23 07:49:19 UTC",
      "updated_date": "2025-03-23 07:49:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:33:44.720816"
    },
    {
      "arxiv_id": "2503.18985v1",
      "title": "LoRA Subtraction for Drift-Resistant Space in Exemplar-Free Continual Learning",
      "title_zh": "LoRA减法：无样本持续学习中抗特征漂移的空间构建",
      "authors": [
        "Xuan Liu",
        "Xiaobin Chang"
      ],
      "abstract": "In continual learning (CL), catastrophic forgetting often arises due to\nfeature drift. This challenge is particularly prominent in the exemplar-free\ncontinual learning (EFCL) setting, where samples from previous tasks cannot be\nretained, making it difficult to preserve prior knowledge. To address this\nissue, some EFCL methods aim to identify feature spaces that minimize the\nimpact on previous tasks while accommodating new ones. However, they rely on\nstatic features or outdated statistics stored from old tasks, which prevents\nthem from capturing the dynamic evolution of the feature space in CL, leading\nto performance degradation over time. In this paper, we introduce the\nDrift-Resistant Space (DRS), which effectively handles feature drifts without\nrequiring explicit feature modeling or the storage of previous tasks. A novel\nparameter-efficient fine-tuning approach called Low-Rank Adaptation Subtraction\n(LoRA-) is proposed to develop the DRS. This method subtracts the LoRA weights\nof old tasks from the initial pre-trained weight before processing new task\ndata to establish the DRS for model training. Therefore, LoRA- enhances\nstability, improves efficiency, and simplifies implementation. Furthermore,\nstabilizing feature drifts allows for better plasticity by learning with a\ntriplet loss. Our method consistently achieves state-of-the-art results,\nespecially for long task sequences, across multiple datasets.",
      "tldr_zh": "本文提出了一种名为\"LoRA减法\"(LoRA-)的参数高效微调方法，用于构建抗特征漂移空间(DRS)，解决无样本持续学习(EFCL)中的灾难性遗忘问题。该方法通过从预训练权重中减去旧任务的LoRA权重来建立DRS，无需存储旧任务数据或显式建模特征，既提升了模型稳定性又简化了实现。结合三重损失(triplet loss)学习，该方法在多个数据集上实现了最先进的性能，尤其擅长处理长任务序列。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18985v1",
      "published_date": "2025-03-23 07:38:53 UTC",
      "updated_date": "2025-03-23 07:38:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:34:03.758023"
    },
    {
      "arxiv_id": "2503.18984v1",
      "title": "The Misinterpretable Evidence Conveyed by Arbitrary Codes",
      "title_zh": "任意编码传递的易误解证据",
      "authors": [
        "Guido Fioretti"
      ],
      "abstract": "Evidence Theory is a mathematical framework for handling imprecise reasoning\nin the context of a judge evaluating testimonies or a detective evaluating\ncues, rather than a gambler playing games of chance. In comparison to\nProbability Theory, it is better equipped to deal with ambiguous information\nand novel possibilities. Furthermore, arrival and evaluation of testimonies\nimplies a communication channel.\n  This paper explores the possibility of employing Evidence Theory to represent\narbitrary communication codes between and within living organisms. In this\npaper, different schemes are explored for living organisms incapable of\nanticipation, animals sufficiently sophisticated to be capable of\nextrapolation, and humans capable of reading one other's minds.",
      "tldr_zh": "该论文探讨了如何运用证据理论(Evidence Theory)来表征生物体之间及内部的任意通信编码。相比概率论，证据理论更适合处理模糊信息和未知可能性，尤其适用于法官评估证词或侦探分析线索等需要处理不确定性的场景。研究针对三类不同认知能力的生物体（无法预测的简单生物、能进行外推的复杂动物、以及具备心智解读能力的人类）提出了相应的通信编码方案，扩展了证据理论在生物通信领域的应用框架。",
      "categories": [
        "cs.AI",
        "nlin.AO"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 4 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.18984v1",
      "published_date": "2025-03-23 07:31:26 UTC",
      "updated_date": "2025-03-23 07:31:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:34:24.358285"
    },
    {
      "arxiv_id": "2503.17965v1",
      "title": "Understanding the Effects of RLHF on the Quality and Detectability of LLM-Generated Texts",
      "title_zh": "理解RLHF对LLM生成文本质量与可检测性的影响",
      "authors": [
        "Beining Xu",
        "Arkaitz Zubiaga"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance on a\nrange of downstream NLP tasks by generating text that closely resembles human\nwriting. However, the ease of achieving this similarity raises concerns from\npotential malicious uses at scale by bad actors, as LLM-generated text becomes\nincreasingly difficult to discern from human text. Although detection methods\nhave been developed to address this issue, bad actors can further manipulate\nLLM-generated texts to make them less detectable. In this work, we study how\nfurther editing texts with Reinforcement Learning from Human Feedback (RLHF),\nwhich aligns model outputs with human preferences, affects (a) the quality of\ngenerated texts for two tasks, and (b) the performance of LLM-generated text\ndetectors, looking at both training-based and zero-shot detection methods.\nAlthough RLHF improves the quality of LLM-generated texts, we find that it also\ntends to produce more detectable, lengthy, and repetitive outputs.\nAdditionally, we observe that training-based detectors are vulnerable to short\ntexts and to texts that incorporate code, whereas zero-shot detectors exhibit\ngreater robustness.",
      "tldr_zh": "该论文研究了基于人类反馈的强化学习（RLHF）对大型语言模型（LLM）生成文本的质量和可检测性的影响。研究发现，虽然RLHF能提升生成文本的质量，但同时会导致文本更易被检测、篇幅更长且重复性更高。实验表明，基于训练的检测器对短文本和含代码的文本识别效果较差，而零样本检测器则表现出更强的鲁棒性。该研究揭示了RLHF在优化文本质量与隐蔽性之间的权衡关系。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.17965v1",
      "published_date": "2025-03-23 07:03:10 UTC",
      "updated_date": "2025-03-23 07:03:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:35:30.026851"
    },
    {
      "arxiv_id": "2503.17959v1",
      "title": "Dynamic Gradient Sparse Update for Edge Training",
      "title_zh": "动态梯度稀疏更新的边缘训练方法",
      "authors": [
        "I-Hsuan Li",
        "Tian-Sheuan Chang"
      ],
      "abstract": "Training on edge devices enables personalized model fine-tuning to enhance\nreal-world performance and maintain data privacy. However, the gradient\ncomputation for backpropagation in the training requires significant memory\nbuffers to store intermediate features and compute losses. This is unacceptable\nfor memory-constrained edge devices such as microcontrollers. To tackle this\nissue, we propose a training acceleration method using dynamic gradient sparse\nupdates. This method updates the important channels and layers only and skips\ngradient computation for the less important channels and layers to reduce\nmemory usage for each update iteration. In addition, the channel selection is\ndynamic for different iterations to traverse most of the parameters in the\nupdate layers along the time dimension for better performance. The experimental\nresult shows that the proposed method enables an ImageNet pre-trained\nMobileNetV2 trained on CIFAR-10 to achieve an accuracy of 85.77\\% while\nupdating only 2\\% of convolution weights within 256KB on-chip memory. This\nresults in a remarkable 98\\% reduction in feature memory usage compared to\ndense model training.",
      "tldr_zh": "该研究提出了一种动态梯度稀疏更新方法，用于解决边缘设备训练中的内存瓶颈问题。该方法通过动态选择重要通道和层进行梯度更新，跳过次要通道以减少内存占用，同时沿时间维度遍历大多数参数以保证模型性能。实验表明，在仅更新2%卷积权重的情况下，该方法能在256KB内存限制下使MobileNetV2在CIFAR-10上达到85.77%的准确率，相比密集训练减少98%的特征内存使用。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "published in IEEE International Symposium on Circuits and Systems\n  (IEEE ISCAS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2503.17959v1",
      "published_date": "2025-03-23 06:32:12 UTC",
      "updated_date": "2025-03-23 06:32:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:35:06.386046"
    },
    {
      "arxiv_id": "2503.18983v1",
      "title": "Confronting Catastrophic Risk: The International Obligation to Regulate Artificial Intelligence",
      "title_zh": "直面灾难性风险：国际社会监管人工智能的法律义务",
      "authors": [
        "Bryan Druzin",
        "Anatole Boute",
        "Michael Ramsden"
      ],
      "abstract": "While artificial intelligence (AI) holds enormous promise, many experts in\nthe field are warning that there is a non-trivial chance that the development\nof AI poses an existential threat to humanity. Existing regulatory initiative\ndo not address this threat but merely instead focus on discrete AI-related\nrisks such as consumer safety, cybersecurity, data protection, and privacy. In\nthe absence of regulatory action to address the possible risk of human\nextinction by AI, the question arises: What legal obligations, if any, does\npublic international law impose on states to regulate its development. Grounded\nin the precautionary principle, we argue that there exists an international\nobligation to mitigate the threat of human extinction by AI. Often invoked in\nrelation to environmental regulation and the regulation of potentially harmful\ntechnologies, the principle holds that in situations where there is the\npotential for significant harm, even in the absence of full scientific\ncertainty, preventive measures should not be postponed if delayed action may\nresult in irreversible consequences. We argue that the precautionary principle\nis a general principle of international law and, therefore, that there is a\npositive obligation on states under the right to life within international\nhuman rights law to proactively take regulatory action to mitigate the\npotential existential risk of AI. This is significant because, if an\ninternational obligation to regulate the development of AI can be established\nunder international law, then the basic legal framework would be in place to\naddress this evolving threat.",
      "tldr_zh": "这篇论文探讨了国际法对人工智能监管的义务问题。研究者基于\"预防原则\"(precautionary principle)主张，国际人权法中的生命权条款要求各国必须主动监管AI发展，以防范其可能导致的灭绝性风险。论文指出，当前AI监管仅关注消费者安全、隐私等具体风险，而忽视了AI可能威胁人类生存的更大风险。作者认为，即使缺乏完全科学确定性，国际法仍要求各国采取预防性措施，这为应对AI的潜在威胁建立了基本法律框架。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18983v1",
      "published_date": "2025-03-23 06:24:45 UTC",
      "updated_date": "2025-03-23 06:24:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:35:58.115443"
    },
    {
      "arxiv_id": "2503.17955v2",
      "title": "Human-AI Interaction and User Satisfaction: Empirical Evidence from Online Reviews of AI Products",
      "title_zh": "人机交互与用户满意度：来自AI产品在线评论的实证证据",
      "authors": [
        "Stefan Pasch",
        "Sun-Young Ha"
      ],
      "abstract": "Human-AI Interaction (HAI) guidelines and design principles have become\nincreasingly important in both industry and academia to guide the development\nof AI systems that align with user needs and expectations. However, large-scale\nempirical evidence on how HAI principles shape user satisfaction in practice\nremains limited. This study addresses that gap by analyzing over 100,000 user\nreviews of AI-related products from G2, a leading review platform for business\nsoftware and services. Based on widely adopted industry guidelines, we identify\nseven core HAI dimensions and examine their coverage and sentiment within the\nreviews. We find that the sentiment on four HAI dimensions-adaptability,\ncustomization, error recovery, and security-is positively associated with\noverall user satisfaction. Moreover, we show that engagement with HAI\ndimensions varies by professional background: Users with technical job roles\nare more likely to discuss system-focused aspects, such as reliability, while\nnon-technical users emphasize interaction-focused features like customization\nand feedback. Interestingly, the relationship between HAI sentiment and overall\nsatisfaction is not moderated by job role, suggesting that once an HAI\ndimension has been identified by users, its effect on satisfaction is\nconsistent across job roles.",
      "tldr_zh": "该研究通过分析商业软件平台G2上10万条AI产品用户评论，首次大规模验证了人机交互(HAI)原则对用户满意度的实际影响。研究发现：适应性、定制化、错误恢复和安全性这四个HAI维度与用户满意度呈显著正相关；技术背景用户更关注系统可靠性等性能指标，而非技术用户更重视定制化等交互功能。值得注意的是，HAI维度对满意度的提升效果在不同职业用户间具有一致性，表明核心交互原则具有普适价值。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17955v2",
      "published_date": "2025-03-23 06:16:49 UTC",
      "updated_date": "2025-03-25 01:44:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:36:24.160088"
    },
    {
      "arxiv_id": "2503.18982v1",
      "title": "Generative Data Imputation for Sparse Learner Performance Data Using Generative Adversarial Imputation Networks",
      "title_zh": "基于生成对抗填补网络的稀疏学习者表现数据生成式填补方法",
      "authors": [
        "Liang Zhang",
        "Jionghao Lin",
        "John Sabatini",
        "Diego Zapata-Rivera",
        "Carol Forsyth",
        "Yang Jiang",
        "John Hollander",
        "Xiangen Hu",
        "Arthur C. Graesser"
      ],
      "abstract": "Learner performance data collected by Intelligent Tutoring Systems (ITSs),\nsuch as responses to questions, is essential for modeling and predicting\nlearners' knowledge states. However, missing responses due to skips or\nincomplete attempts create data sparsity, challenging accurate assessment and\npersonalized instruction. To address this, we propose a generative imputation\napproach using Generative Adversarial Imputation Networks (GAIN). Our method\nfeatures a three-dimensional (3D) framework (learners, questions, and\nattempts), flexibly accommodating various sparsity levels. Enhanced by\nconvolutional neural networks and optimized with a least squares loss function,\nthe GAIN-based method aligns input and output dimensions to question-attempt\nmatrices along the learners' dimension. Extensive experiments using datasets\nfrom AutoTutor Adult Reading Comprehension (ARC), ASSISTments, and MATHia\ndemonstrate that our approach significantly outperforms tensor factorization\nand alternative GAN methods in imputation accuracy across different attempt\nscenarios. Bayesian Knowledge Tracing (BKT) further validates the effectiveness\nof the imputed data by estimating learning parameters: initial knowledge\n(P(L0)), learning rate (P(T)), guess rate (P(G)), and slip rate (P(S)). Results\nindicate the imputed data enhances model fit and closely mirrors original\ndistributions, capturing underlying learning behaviors reliably.\nKullback-Leibler (KL) divergence assessments confirm minimal divergence,\nshowing the imputed data preserves essential learning characteristics\neffectively. These findings underscore GAIN's capability as a robust imputation\ntool in ITSs, alleviating data sparsity and supporting adaptive, individualized\ninstruction, ultimately leading to more precise and responsive learner\nassessments and improved educational outcomes.",
      "tldr_zh": "该研究提出了一种基于生成对抗填补网络（GAIN）的三维生成数据填补方法，用于解决智能导学系统（ITS）中学习者表现数据的稀疏性问题。该方法通过卷积神经网络增强的三维框架（学习者-问题-尝试）和最小二乘损失函数优化，显著优于张量分解和其他GAN方法。实验在AutoTutor ARC、ASSISTments和MATHia数据集上验证了其有效性，贝叶斯知识追踪（BKT）和KL散度分析表明填补数据能准确保持原始学习行为特征。该成果为智能教育系统中的个性化教学提供了更精准的数据支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18982v1",
      "published_date": "2025-03-23 06:11:53 UTC",
      "updated_date": "2025-03-23 06:11:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:36:36.606897"
    },
    {
      "arxiv_id": "2503.18981v1",
      "title": "FedSKD: Aggregation-free Model-heterogeneous Federated Learning using Multi-dimensional Similarity Knowledge Distillation",
      "title_zh": "FedSKD：基于多维相似性知识蒸馏的无聚合模型异构联邦学习",
      "authors": [
        "Ziqiao Weng",
        "Weidong Cai",
        "Bo Zhou"
      ],
      "abstract": "Federated learning (FL) enables privacy-preserving collaborative model\ntraining without direct data sharing. Model-heterogeneous FL (MHFL) extends\nthis paradigm by allowing clients to train personalized models with\nheterogeneous architectures tailored to their computational resources and\napplication-specific needs. However, existing MHFL methods predominantly rely\non centralized aggregation, which introduces scalability and efficiency\nbottlenecks, or impose restrictions requiring partially identical model\narchitectures across clients. While peer-to-peer (P2P) FL removes server\ndependence, it suffers from model drift and knowledge dilution, limiting its\neffectiveness in heterogeneous settings. To address these challenges, we\npropose FedSKD, a novel MHFL framework that facilitates direct knowledge\nexchange through round-robin model circulation, eliminating the need for\ncentralized aggregation while allowing fully heterogeneous model architectures\nacross clients. FedSKD's key innovation lies in multi-dimensional similarity\nknowledge distillation, which enables bidirectional cross-client knowledge\ntransfer at batch, pixel/voxel, and region levels for heterogeneous models in\nFL. This approach mitigates catastrophic forgetting and model drift through\nprogressive reinforcement and distribution alignment while preserving model\nheterogeneity. Extensive evaluations on fMRI-based autism spectrum disorder\ndiagnosis and skin lesion classification demonstrate that FedSKD outperforms\nstate-of-the-art heterogeneous and homogeneous FL baselines, achieving superior\npersonalization (client-specific accuracy) and generalization\n(cross-institutional adaptability). These findings underscore FedSKD's\npotential as a scalable and robust solution for real-world medical federated\nlearning applications.",
      "tldr_zh": "本文提出FedSKD，一种基于多维相似性知识蒸馏(model-heterogeneous FL)的联邦学习新框架，解决了现有异构模型联邦学习中的集中式聚合瓶颈和模型漂移问题。该方法通过轮询式模型循环实现直接知识交换，支持完全异构的客户端模型架构，并创新性地在batch、像素/体素和区域三个维度进行双向知识迁移。在fMRI自闭症诊断和皮肤病变分类任务上的实验表明，FedSKD在个性化精度和跨机构泛化能力上均优于当前最优方法，为医疗联邦学习提供了可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 5 figure, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.18981v1",
      "published_date": "2025-03-23 05:33:10 UTC",
      "updated_date": "2025-03-23 05:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:37:00.623039"
    },
    {
      "arxiv_id": "2503.18980v1",
      "title": "CAE: Repurposing the Critic as an Explorer in Deep Reinforcement Learning",
      "title_zh": "CAE：在深度强化学习中重用评论家网络作为探索者",
      "authors": [
        "Yexin Li",
        "Pring Wong",
        "Hanfang Zhang",
        "Shuo Chen",
        "Siyuan Qi"
      ],
      "abstract": "Exploration remains a critical challenge in reinforcement learning, as many\nexisting methods either lack theoretical guarantees or fall short of practical\neffectiveness. In this paper, we introduce CAE, a lightweight algorithm that\nrepurposes the value networks in standard deep RL algorithms to drive\nexploration without introducing additional parameters. CAE utilizes any linear\nmulti-armed bandit technique and incorporates an appropriate scaling strategy,\nenabling efficient exploration with provable sub-linear regret bounds and\npractical stability. Notably, it is simple to implement, requiring only around\n10 lines of code. In complex tasks where learning an effective value network\nproves challenging, we propose CAE+, an extension of CAE that incorporates an\nauxiliary network. This extension increases the parameter count by less than 1%\nwhile maintaining implementation simplicity, adding only about 10 additional\nlines of code. Experiments on MuJoCo and MiniHack show that both CAE and CAE+\noutperform state-of-the-art baselines, bridging the gap between theoretical\nrigor and practical efficiency.",
      "tldr_zh": "该研究提出CAE算法，将深度强化学习中的价值网络(critic)重新用于探索任务，无需额外参数即可实现高效探索。该方法通过线性多臂老虎机技术和适当的缩放策略，既保证了理论上的次线性遗憾界，又具备实际稳定性（仅需约10行代码实现）。针对复杂任务还提出CAE+扩展方案，增加不到1%的参数（约20行代码）即可提升性能。在MuJoCo和MiniHack环境的实验表明，CAE系列算法在理论严谨性和实践效率方面均优于当前最优基线方法。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18980v1",
      "published_date": "2025-03-23 04:59:24 UTC",
      "updated_date": "2025-03-23 04:59:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:37:08.389903"
    },
    {
      "arxiv_id": "2503.17941v1",
      "title": "Physics-Guided Multi-Fidelity DeepONet for Data-Efficient Flow Field Prediction",
      "title_zh": "物理引导的多保真度DeepONet：面向数据高效流场预测的方法",
      "authors": [
        "Sunwoong Yang",
        "Youngkyu Lee",
        "Namwoo Kang"
      ],
      "abstract": "This study presents an enhanced multi-fidelity deep operator network\n(DeepONet) framework for efficient spatio-temporal flow field prediction, with\nparticular emphasis on practical scenarios where high-fidelity data is scarce.\nWe introduce several key innovations to improve the framework's efficiency and\naccuracy. First, we enhance the DeepONet architecture by incorporating a merge\nnetwork that enables more complex feature interactions between operator and\ncoordinate spaces, achieving a 50.4% reduction in prediction error compared to\ntraditional dot-product operations. We further optimize the architecture\nthrough temporal positional encoding and point-based sampling strategies,\nachieving a 7.57% improvement in prediction accuracy while reducing training\ntime by 96% through efficient sampling and automatic mixed precision training.\nBuilding upon this foundation, we develop a transfer learning-based\nmulti-fidelity framework that leverages knowledge from pre-trained low-fidelity\nmodels to guide high-fidelity predictions. Our approach freezes the pre-trained\nbranch and trunk networks while making only the merge network trainable during\nhigh-fidelity training, preserving valuable low-fidelity representations while\nefficiently adapting to high-fidelity features. Through systematic\ninvestigation, we demonstrate that this fine-tuning strategy not only\nsignificantly outperforms linear probing and full-tuning alternatives but also\nsurpasses conventional multi-fidelity frameworks by up to 76%, while achieving\nup to 43.7% improvement in prediction accuracy compared to single-fidelity\ntraining. The core contribution lies in our novel time-derivative guided\nsampling approach: it maintains prediction accuracy equivalent to models\ntrained with the full dataset while requiring only 60% of the original\nhigh-fidelity samples.",
      "tldr_zh": "该研究提出了一种基于物理引导的多保真度DeepONet框架，用于数据高效的流场预测。通过创新性地引入merge network增强特征交互，相比传统点积运算降低了50.4%的预测误差；采用迁移学习策略，冻结预训练的低保真度分支网络，仅微调merge network，使预测精度比单保真度训练提升43.7%。关键创新是时间导数引导采样方法，仅需60%的高保真度样本即可达到全数据集的预测精度，同时训练时间减少96%。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17941v1",
      "published_date": "2025-03-23 04:48:18 UTC",
      "updated_date": "2025-03-23 04:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:37:44.489758"
    },
    {
      "arxiv_id": "2503.17936v1",
      "title": "An Empirical Study of the Role of Incompleteness and Ambiguity in Interactions with Large Language Models",
      "title_zh": "大型语言模型交互中不完整性与模糊性作用的实证研究",
      "authors": [
        "Riya Naik",
        "Ashwin Srinivasan",
        "Estrid He",
        "Swati Agarwal"
      ],
      "abstract": "Natural language as a medium for human-computer interaction has long been\nanticipated, has been undergoing a sea-change with the advent of Large Language\nModels (LLMs) with startling capacities for processing and generating language.\nMany of us now treat LLMs as modern-day oracles, asking it almost any kind of\nquestion. Unlike its Delphic predecessor, consulting an LLM does not have to be\na single-turn activity (ask a question, receive an answer, leave); and -- also\nunlike the Pythia -- it is widely acknowledged that answers from LLMs can be\nimproved with additional context. In this paper, we aim to study when we need\nmulti-turn interactions with LLMs to successfully get a question answered; or\nconclude that a question is unanswerable. We present a neural symbolic\nframework that models the interactions between human and LLM agents. Through\nthe proposed framework, we define incompleteness and ambiguity in the questions\nas properties deducible from the messages exchanged in the interaction, and\nprovide results from benchmark problems, in which the answer-correctness is\nshown to depend on whether or not questions demonstrate the presence of\nincompleteness or ambiguity (according to the properties we identify). Our\nresults show multi-turn interactions are usually required for datasets which\nhave a high proportion of incompleteness or ambiguous questions; and that that\nincreasing interaction length has the effect of reducing incompleteness or\nambiguity. The results also suggest that our measures of incompleteness and\nambiguity can be useful tools for characterising interactions with an LLM on\nquestion-answeringproblems",
      "tldr_zh": "本研究探讨了在大型语言模型（LLMs）交互中，问题的不完整性和模糊性对多轮对话需求的影响。通过提出一种神经符号框架，研究将不完整性和模糊性定义为可从交互消息中推导的属性，并分析了这些属性对问题回答正确性的影响。实验结果表明，对于包含大量不完整或模糊问题的数据集，通常需要多轮交互来提高回答准确性，且增加交互长度能有效减少不完整性和模糊性。研究还表明，不完整性和模糊性的度量可用于描述LLMs在问答问题中的交互特征。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17936v1",
      "published_date": "2025-03-23 04:34:30 UTC",
      "updated_date": "2025-03-23 04:34:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:37:50.865890"
    },
    {
      "arxiv_id": "2503.17933v1",
      "title": "Experience Retrieval-Augmentation with Electronic Health Records Enables Accurate Discharge QA",
      "title_zh": "基于电子健康记录的经验检索增强实现精准出院问答",
      "authors": [
        "Justice Ou",
        "Tinglin Huang",
        "Yilun Zhao",
        "Ziyang Yu",
        "Peiqing Lu",
        "Rex Ying"
      ],
      "abstract": "To improve the reliability of Large Language Models (LLMs) in clinical\napplications, retrieval-augmented generation (RAG) is extensively applied to\nprovide factual medical knowledge. However, beyond general medical knowledge\nfrom open-ended datasets, clinical case-based knowledge is also critical for\neffective medical reasoning, as it provides context grounded in real-world\npatient experiences. Motivated by this, we propose Experience Retrieval\nAugmentation - ExpRAG framework based on Electronic Health Record (EHR), aiming\nto offer the relevant context from other patients' discharge reports. ExpRAG\nperforms retrieval through a coarse-to-fine process, utilizing an EHR-based\nreport ranker to efficiently identify similar patients, followed by an\nexperience retriever to extract task-relevant content for enhanced medical\nreasoning. To evaluate ExpRAG, we introduce DischargeQA, a clinical QA dataset\nwith 1,280 discharge-related questions across diagnosis, medication, and\ninstruction tasks. Each problem is generated using EHR data to ensure realistic\nand challenging scenarios. Experimental results demonstrate that ExpRAG\nconsistently outperforms a text-based ranker, achieving an average relative\nimprovement of 5.2%, highlighting the importance of case-based knowledge for\nmedical reasoning.",
      "tldr_zh": "该研究提出Experience Retrieval Augmentation（ExpRAG）框架，通过电子健康记录（EHR）检索增强临床问答系统。该方法采用从粗到精的检索策略，先通过EHR报告排序器快速定位相似病例，再用经验提取器获取任务相关医疗记录。研究团队构建了包含1,280个出院相关问题的DischargeQA临床问答数据集，涵盖诊断、用药和指导等任务。实验表明，ExpRAG比基于文本的检索器性能平均提升5.2%，证实了病例知识对医疗推理的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17933v1",
      "published_date": "2025-03-23 04:26:06 UTC",
      "updated_date": "2025-03-23 04:26:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:38:10.002949"
    },
    {
      "arxiv_id": "2503.17932v1",
      "title": "STShield: Single-Token Sentinel for Real-Time Jailbreak Detection in Large Language Models",
      "title_zh": "STShield：用于大语言模型实时越狱检测的单令牌哨兵机制",
      "authors": [
        "Xunguang Wang",
        "Wenxuan Wang",
        "Zhenlan Ji",
        "Zongjie Li",
        "Pingchuan Ma",
        "Daoyuan Wu",
        "Shuai Wang"
      ],
      "abstract": "Large Language Models (LLMs) have become increasingly vulnerable to jailbreak\nattacks that circumvent their safety mechanisms. While existing defense methods\neither suffer from adaptive attacks or require computationally expensive\nauxiliary models, we present STShield, a lightweight framework for real-time\njailbroken judgement. STShield introduces a novel single-token sentinel\nmechanism that appends a binary safety indicator to the model's response\nsequence, leveraging the LLM's own alignment capabilities for detection. Our\nframework combines supervised fine-tuning on normal prompts with adversarial\ntraining using embedding-space perturbations, achieving robust detection while\npreserving model utility. Extensive experiments demonstrate that STShield\nsuccessfully defends against various jailbreak attacks, while maintaining the\nmodel's performance on legitimate queries. Compared to existing approaches,\nSTShield achieves superior defense performance with minimal computational\noverhead, making it a practical solution for real-world LLM deployment.",
      "tldr_zh": "该研究提出STShield框架，通过创新的单令牌哨兵(single-token sentinel)机制实时检测大语言模型(LLMs)的越狱攻击(jailbreak)。该方法在模型响应序列中附加二进制安全指示器，利用LLM自身的对齐能力进行检测，结合监督微调和对抗训练，在保持模型性能的同时实现高效防御。实验表明，STShield能以最小计算开销有效抵御各类越狱攻击，相比现有方法具有更优的防御性能，为实际部署提供了实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.17932v1",
      "published_date": "2025-03-23 04:23:07 UTC",
      "updated_date": "2025-03-23 04:23:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:38:49.444169"
    },
    {
      "arxiv_id": "2503.17924v1",
      "title": "WLB-LLM: Workload-Balanced 4D Parallelism for Large Language Model Training",
      "title_zh": "WLB-LLM：面向大语言模型训练的工作负载均衡四维并行框架",
      "authors": [
        "Zheng Wang",
        "Anna Cai",
        "Xinfeng Xie",
        "Zaifeng Pan",
        "Yue Guan",
        "Weiwei Chu",
        "Jie Wang",
        "Shikai Li",
        "Jianyu Huang",
        "Chris Cai",
        "Yuchen Hao",
        "Yufei Ding"
      ],
      "abstract": "In this work, we present WLB-LLM, a workLoad-balanced 4D parallelism for\nlarge language model training. We first thoroughly analyze the workload\nimbalance issue in LLM training and identify two primary sources of imbalance\nat the pipeline parallelism and context parallelism levels. Then, to address\nthe imbalance issue, at the pipeline parallelism level, WLB-LLM incorporates a\nworkload-aware variable-length document packing method to balance the\ncomputation and communication workload across micro-batches. Additionally, at\nthe context parallelism level, WLB-LLM introduces a novel fine-grained\nper-document sharding strategy, ensuring each worker within a context\nparallelism group has an identical workload. Comprehensive experiments under\ndifferent model scales demonstrate that WLB-LLM significantly mitigates the\nworkload imbalance during 4D parallelism LLM training and achieves an average\nspeedup of 1.23x when applying WLB-LLM in our internal LLM training framework.",
      "tldr_zh": "该研究提出了WLB-LLM，一种面向大语言模型训练的负载均衡4D并行方法。针对训练过程中流水线并行(pipeline parallelism)和上下文并行(context parallelism)两个层面的负载不均衡问题，系统分别提出了解决方案：通过可变长度文档打包策略平衡微批间的计算/通信负载，并采用细粒度的文档分片策略确保工作节点间负载均衡。实验表明，该方法在不同规模模型训练中平均实现了1.23倍的加速效果。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "I.2.11"
      ],
      "primary_category": "cs.DC",
      "comment": "12 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.17924v1",
      "published_date": "2025-03-23 03:40:45 UTC",
      "updated_date": "2025-03-23 03:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:39:06.144910"
    },
    {
      "arxiv_id": "2503.17915v1",
      "title": "Cat-AIR: Content and Task-Aware All-in-One Image Restoration",
      "title_zh": "Cat-AIR：面向内容与任务感知的一体化图像恢复",
      "authors": [
        "Jiachen Jiang",
        "Tianyu Ding",
        "Ke Zhang",
        "Jinxin Zhou",
        "Tianyi Chen",
        "Ilya Zharkov",
        "Zhihui Zhu",
        "Luming Liang"
      ],
      "abstract": "All-in-one image restoration seeks to recover high-quality images from\nvarious types of degradation using a single model, without prior knowledge of\nthe corruption source. However, existing methods often struggle to effectively\nand efficiently handle multiple degradation types. We present Cat-AIR, a novel\n\\textbf{C}ontent \\textbf{A}nd \\textbf{T}ask-aware framework for\n\\textbf{A}ll-in-one \\textbf{I}mage \\textbf{R}estoration. Cat-AIR incorporates\nan alternating spatial-channel attention mechanism that adaptively balances the\nlocal and global information for different tasks. Specifically, we introduce\ncross-layer channel attentions and cross-feature spatial attentions that\nallocate computations based on content and task complexity. Furthermore, we\npropose a smooth learning strategy that allows for seamless adaptation to new\nrestoration tasks while maintaining performance on existing ones. Extensive\nexperiments demonstrate that Cat-AIR achieves state-of-the-art results across a\nwide range of restoration tasks, requiring fewer FLOPs than previous methods,\nestablishing new benchmarks for efficient all-in-one image restoration.",
      "tldr_zh": "本文提出Cat-AIR框架，一种内容与任务感知的统一图像复原方法，通过交替空间-通道注意力机制动态平衡不同任务的局部与全局信息。该方法创新性地引入跨层通道注意力和跨特征空间注意力，根据图像内容和任务复杂度自适应分配计算资源。实验表明，Cat-AIR在多种复原任务中达到最先进性能，同时计算量(FLOPs)少于现有方法，为高效统一图像复原设立了新基准。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17915v1",
      "published_date": "2025-03-23 03:25:52 UTC",
      "updated_date": "2025-03-23 03:25:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:39:26.774780"
    },
    {
      "arxiv_id": "2503.17903v1",
      "title": "GLADMamba: Unsupervised Graph-Level Anomaly Detection Powered by Selective State Space Model",
      "title_zh": "GLADMamba：基于选择性状态空间模型的无监督图级异常检测方法",
      "authors": [
        "Yali Fu",
        "Jindong Li",
        "Qi Wang",
        "Qianli Xing"
      ],
      "abstract": "Unsupervised graph-level anomaly detection (UGLAD) is a critical and\nchallenging task across various domains, such as social network analysis,\nanti-cancer drug discovery, and toxic molecule identification. However,\nexisting methods often struggle to capture the long-range dependencies\nefficiently and neglect the spectral information. Recently, selective State\nSpace Models (SSMs), particularly Mamba, have demonstrated remarkable\nadvantages in capturing long-range dependencies with linear complexity and a\nselection mechanism. Motivated by their success across various domains, we\npropose GLADMamba, a novel framework that adapts the selective state space\nmodel into UGLAD field. We design View-Fused Mamba (VFM) with a\nMamba-Transformer-style architecture to efficiently fuse information from\ndifferent views with a selective state mechanism. We also design\nSpectrum-Guided Mamba (SGM) with a Mamba-Transformer-style architecture to\nleverage the Rayleigh quotient to guide the embedding refining process.\nGLADMamba can dynamically focus on anomaly-related information while discarding\nirrelevant information for anomaly detection. To the best of our knowledge,\nthis is the first work to introduce Mamba and explicit spectral information to\nUGLAD. Extensive experiments on 12 real-world datasets demonstrate that\nGLADMamba outperforms existing state-of-the-art methods, achieving superior\nperformance in UGLAD. The code is available at\nhttps://github.com/Yali-F/GLADMamba.",
      "tldr_zh": "该研究提出GLADMamba框架，首次将选择性状态空间模型(Mamba)和显式频谱信息引入无监督图级异常检测(UGLAD)领域。通过设计View-Fused Mamba和Spectrum-Guided Mamba两种模块，该框架能动态聚焦异常相关信息，并利用Rayleigh商指导嵌入优化。在12个真实数据集上的实验表明，GLADMamba优于现有最优方法，有效解决了传统方法在长程依赖和频谱信息利用上的不足。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17903v1",
      "published_date": "2025-03-23 02:40:17 UTC",
      "updated_date": "2025-03-23 02:40:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:39:43.253889"
    },
    {
      "arxiv_id": "2503.18979v1",
      "title": "Threshold Crossings as Tail Events for Catastrophic AI Risk",
      "title_zh": "阈值穿越作为灾难性AI风险的尾部事件",
      "authors": [
        "Elija Perrier"
      ],
      "abstract": "We analyse circumstances in which bifurcation-driven jumps in AI systems with\ntheir emergent heavy-tailed outcome distributions. By analysing how a control\nparameter's random fluctuations near a catastrophic threshold generate extreme\noutcomes, we demonstrate in what circumstances the probability of a sudden,\nlarge-scale, transition aligns closely with the tail probability of the\nresulting damage distribution. Our results contribute to research in\nmonitoring, mitigation and control of AI systems when seeking to manage\npotentially catastrophic AI risk.",
      "tldr_zh": "该研究分析了AI系统在临界阈值附近的分岔现象及其引发的重尾分布风险。通过研究控制参数在灾难性阈值附近的随机波动如何导致极端后果，论文揭示了突发性大规模转变概率与损害分布尾部概率的关系。这项研究为监测、缓解和控制AI系统潜在灾难性风险提供了理论依据。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Under peer review",
      "pdf_url": "http://arxiv.org/pdf/2503.18979v1",
      "published_date": "2025-03-23 02:01:09 UTC",
      "updated_date": "2025-03-23 02:01:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:40:05.358237"
    },
    {
      "arxiv_id": "2503.17894v2",
      "title": "Generative AI for Validating Physics Laws",
      "title_zh": "生成式人工智能在物理定律验证中的应用",
      "authors": [
        "Maria Nareklishvili",
        "Nicholas Polson",
        "Vadim Sokolov"
      ],
      "abstract": "We present generative artificial intelligence (AI) to empirically validate\nfundamental laws of physics, focusing on the Stefan-Boltzmann law linking\nstellar temperature and luminosity. Our approach simulates counterfactual\nluminosities under hypothetical temperature regimes for each individual star\nand iteratively refines the temperature-luminosity relationship in a deep\nlearning architecture. We use Gaia DR3 data and find that, on average,\ntemperature's effect on luminosity increases with stellar radius and decreases\nwith absolute magnitude, consistent with theoretical predictions. By framing\nphysics laws as causal problems, our method offers a novel, data-driven\napproach to refine theoretical understanding and inform evidence-based policy\nand practice.",
      "tldr_zh": "该研究提出了一种利用生成式AI验证物理定律的新方法，重点验证了斯蒂芬-玻尔兹曼定律(Stefan-Boltzmann law)中恒星温度与光度之间的关系。通过深度学习架构模拟恒星在不同温度假设下的反事实光度，并迭代优化温度-光度关系模型。基于Gaia DR3数据的研究发现：温度对光度的影响随恒星半径增大而增强，随绝对星等减小而减弱，这与理论预测一致。该方法将物理定律转化为因果问题，为理论验证提供了一种数据驱动的新范式。",
      "categories": [
        "astro-ph.SR",
        "astro-ph.GA",
        "cs.AI"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17894v2",
      "published_date": "2025-03-23 00:57:26 UTC",
      "updated_date": "2025-03-25 14:31:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T18:40:25.919909"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 64,
  "processed_papers_count": 64,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-03-26T18:42:09.992072"
}