[
  {
    "arxiv_id": "2409.19829v1",
    "title": "Generalizability of Graph Neural Networks for Decentralized Unlabeled Motion Planning",
    "authors": [
      "Shreyas Muthusamy",
      "Damian Owerko",
      "Charilaos I. Kanatsoulis",
      "Saurav Agarwal",
      "Alejandro Ribeiro"
    ],
    "abstract": "Unlabeled motion planning involves assigning a set of robots to target\nlocations while ensuring collision avoidance, aiming to minimize the total\ndistance traveled. The problem forms an essential building block for\nmulti-robot systems in applications such as exploration, surveillance, and\ntransportation. We address this problem in a decentralized setting where each\nrobot knows only the positions of its $k$-nearest robots and $k$-nearest\ntargets. This scenario combines elements of combinatorial assignment and\ncontinuous-space motion planning, posing significant scalability challenges for\ntraditional centralized approaches. To overcome these challenges, we propose a\ndecentralized policy learned via a Graph Neural Network (GNN). The GNN enables\nrobots to determine (1) what information to communicate to neighbors and (2)\nhow to integrate received information with local observations for\ndecision-making. We train the GNN using imitation learning with the centralized\nHungarian algorithm as the expert policy, and further fine-tune it using\nreinforcement learning to avoid collisions and enhance performance. Extensive\nempirical evaluations demonstrate the scalability and effectiveness of our\napproach. The GNN policy trained on 100 robots generalizes to scenarios with up\nto 500 robots, outperforming state-of-the-art solutions by 8.6\\% on average and\nsignificantly surpassing greedy decentralized methods. This work lays the\nfoundation for solving multi-robot coordination problems in settings where\nscalability is important.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 6 figures, submitted to ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.19829v1",
    "published_date": "2024-09-29 23:57:25 UTC",
    "updated_date": "2024-09-29 23:57:25 UTC"
  },
  {
    "arxiv_id": "2409.19824v1",
    "title": "Counterfactual Evaluation of Ads Ranking Models through Domain Adaptation",
    "authors": [
      "Mohamed A. Radwan",
      "Himaghna Bhattacharjee",
      "Quinn Lanners",
      "Jiasheng Zhang",
      "Serkan Karakulak",
      "Houssam Nassif",
      "Murat Ali Bayir"
    ],
    "abstract": "We propose a domain-adapted reward model that works alongside an Offline A/B\ntesting system for evaluating ranking models. This approach effectively\nmeasures reward for ranking model changes in large-scale Ads recommender\nsystems, where model-free methods like IPS are not feasible. Our experiments\ndemonstrate that the proposed technique outperforms both the vanilla IPS method\nand approaches using non-generalized reward models.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "H.3.3; I.2.6"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted at the CONSEQUENCES'24 workshop, co-located with ACM\n  RecSys'24",
    "pdf_url": "http://arxiv.org/pdf/2409.19824v1",
    "published_date": "2024-09-29 23:12:04 UTC",
    "updated_date": "2024-09-29 23:12:04 UTC"
  },
  {
    "arxiv_id": "2409.19823v1",
    "title": "OrganiQ: Mitigating Classical Resource Bottlenecks of Quantum Generative Adversarial Networks on NISQ-Era Machines",
    "authors": [
      "Daniel Silver",
      "Tirthak Patel",
      "Aditya Ranjan",
      "William Cutler",
      "Devesh Tiwari"
    ],
    "abstract": "Driven by swift progress in hardware capabilities, quantum machine learning\nhas emerged as a research area of interest. Recently, quantum image generation\nhas produced promising results. However, prior quantum image generation\ntechniques rely on classical neural networks, limiting their quantum potential\nand image quality. To overcome this, we introduce OrganiQ, the first quantum\nGAN capable of producing high-quality images without using classical neural\nnetworks.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19823v1",
    "published_date": "2024-09-29 23:11:35 UTC",
    "updated_date": "2024-09-29 23:11:35 UTC"
  },
  {
    "arxiv_id": "2409.19820v1",
    "title": "Qompose: A Technique to Select Optimal Algorithm- Specific Layout for Neutral Atom Quantum Architectures",
    "authors": [
      "Daniel Silver",
      "Tirthak Patel",
      "Devesh Tiwari"
    ],
    "abstract": "As quantum computing architecture matures, it is important to investigate new\ntechnologies that lend unique advantages. In this work, we propose, Qompose, a\nneutral atom quantum computing framework for efficiently composing quantum\ncircuits on 2-D topologies of neutral atoms. Qompose selects an efficient\ntopology for any given circuit in order to optimize for length of execution\nthrough efficient parallelism and for overall fidelity. our extensive\nevaluation demonstrates the Qompose is effective for a large collection of\nrandomly-generated quantum circuits and a range of real-world benchmarks\nincluding VQE, ISING, and QAOA.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19820v1",
    "published_date": "2024-09-29 23:03:08 UTC",
    "updated_date": "2024-09-29 23:03:08 UTC"
  },
  {
    "arxiv_id": "2409.19817v1",
    "title": "Calibrating Language Models with Adaptive Temperature Scaling",
    "authors": [
      "Johnathan Xie",
      "Annie S. Chen",
      "Yoonho Lee",
      "Eric Mitchell",
      "Chelsea Finn"
    ],
    "abstract": "The effectiveness of large language models (LLMs) is not only measured by\ntheir ability to generate accurate outputs but also by their calibration-how\nwell their confidence scores reflect the probability of their outputs being\ncorrect. While unsupervised pre-training has been shown to yield LLMs with\nwell-calibrated conditional probabilities, recent studies have shown that after\nfine-tuning with reinforcement learning from human feedback (RLHF), the\ncalibration of these models degrades significantly. In this work, we introduce\nAdaptive Temperature Scaling (ATS), a post-hoc calibration method that predicts\na temperature scaling parameter for each token prediction. The predicted\ntemperature values adapt based on token-level features and are fit over a\nstandard supervised fine-tuning (SFT) dataset. The adaptive nature of ATS\naddresses the varying degrees of calibration shift that can occur after RLHF\nfine-tuning. ATS improves calibration by over 10-50% across three downstream\nnatural language evaluation benchmarks compared to prior calibration methods\nand does not impede performance improvements from RLHF.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.19817v1",
    "published_date": "2024-09-29 22:54:31 UTC",
    "updated_date": "2024-09-29 22:54:31 UTC"
  },
  {
    "arxiv_id": "2409.19816v1",
    "title": "Grounded Curriculum Learning",
    "authors": [
      "Linji Wang",
      "Zifan Xu",
      "Peter Stone",
      "Xuesu Xiao"
    ],
    "abstract": "The high cost of real-world data for robotics Reinforcement Learning (RL)\nleads to the wide usage of simulators. Despite extensive work on building\nbetter dynamics models for simulators to match with the real world, there is\nanother, often-overlooked mismatch between simulations and the real world,\nnamely the distribution of available training tasks. Such a mismatch is further\nexacerbated by existing curriculum learning techniques, which automatically\nvary the simulation task distribution without considering its relevance to the\nreal world. Considering these challenges, we posit that curriculum learning for\nrobotics RL needs to be grounded in real-world task distributions. To this end,\nwe propose Grounded Curriculum Learning (GCL), which aligns the simulated task\ndistribution in the curriculum with the real world, as well as explicitly\nconsiders what tasks have been given to the robot and how the robot has\nperformed in the past. We validate GCL using the BARN dataset on complex\nnavigation tasks, achieving a 6.8% and 6.5% higher success rate compared to a\nstate-of-the-art CL method and a curriculum designed by human experts,\nrespectively. These results show that GCL can enhance learning efficiency and\nnavigation performance by grounding the simulation task distribution in the\nreal world within an adaptive curriculum.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.19816v1",
    "published_date": "2024-09-29 22:54:08 UTC",
    "updated_date": "2024-09-29 22:54:08 UTC"
  },
  {
    "arxiv_id": "2409.19808v2",
    "title": "Can Models Learn Skill Composition from Examples?",
    "authors": [
      "Haoyu Zhao",
      "Simran Kaur",
      "Dingli Yu",
      "Anirudh Goyal",
      "Sanjeev Arora"
    ],
    "abstract": "As large language models (LLMs) become increasingly advanced, their ability\nto exhibit compositional generalization -- the capacity to combine learned\nskills in novel ways not encountered during training -- has garnered\nsignificant attention. This type of generalization, particularly in scenarios\nbeyond training data, is also of great interest in the study of AI safety and\nalignment. A recent study introduced the SKILL-MIX evaluation, where models are\ntasked with composing a short paragraph demonstrating the use of a specified\n$k$-tuple of language skills. While small models struggled with composing even\nwith $k=3$, larger models like GPT-4 performed reasonably well with $k=5$ and\n$6$.\n  In this paper, we employ a setup akin to SKILL-MIX to evaluate the capacity\nof smaller models to learn compositional generalization from examples.\nUtilizing a diverse set of language skills -- including rhetorical, literary,\nreasoning, theory of mind, and common sense -- GPT-4 was used to generate text\nsamples that exhibit random subsets of $k$ skills. Subsequent fine-tuning of 7B\nand 13B parameter models on these combined skill texts, for increasing values\nof $k$, revealed the following findings: (1) Training on combinations of $k=2$\nand $3$ skills results in noticeable improvements in the ability to compose\ntexts with $k=4$ and $5$ skills, despite models never having seen such examples\nduring training. (2) When skill categories are split into training and held-out\ngroups, models significantly improve at composing texts with held-out skills\nduring testing despite having only seen training skills during fine-tuning,\nillustrating the efficacy of the training approach even with previously unseen\nskills. This study also suggests that incorporating skill-rich (potentially\nsynthetic) text into training can substantially enhance the compositional\ncapabilities of models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.19808v2",
    "published_date": "2024-09-29 22:14:02 UTC",
    "updated_date": "2025-01-19 02:31:24 UTC"
  },
  {
    "arxiv_id": "2409.19806v1",
    "title": "PALM: Few-Shot Prompt Learning for Audio Language Models",
    "authors": [
      "Asif Hanif",
      "Maha Tufail Agro",
      "Mohammad Areeb Qazi",
      "Hanan Aldarmaki"
    ],
    "abstract": "Audio-Language Models (ALMs) have recently achieved remarkable success in\nzero-shot audio recognition tasks, which match features of audio waveforms with\nclass-specific text prompt features, inspired by advancements in\nVision-Language Models (VLMs). Given the sensitivity of zero-shot performance\nto the choice of hand-crafted text prompts, many prompt learning techniques\nhave been developed for VLMs. We explore the efficacy of these approaches in\nALMs and propose a novel method, Prompt Learning in Audio Language Models\n(PALM), which optimizes the feature space of the text encoder branch. Unlike\nexisting methods that work in the input space, our approach results in greater\ntraining efficiency. We demonstrate the effectiveness of our approach on 11\naudio recognition datasets, encompassing a variety of speech-processing tasks,\nand compare the results with three baselines in a few-shot learning setup. Our\nmethod is either on par with or outperforms other approaches while being\ncomputationally less demanding. Code is available at\nhttps://asif-hanif.github.io/palm/",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "EMNLP 2024 (Main)",
    "pdf_url": "http://arxiv.org/pdf/2409.19806v1",
    "published_date": "2024-09-29 22:06:07 UTC",
    "updated_date": "2024-09-29 22:06:07 UTC"
  },
  {
    "arxiv_id": "2409.19801v2",
    "title": "CRScore: Grounding Automated Evaluation of Code Review Comments in Code Claims and Smells",
    "authors": [
      "Atharva Naik",
      "Marcus Alenius",
      "Daniel Fried",
      "Carolyn Rose"
    ],
    "abstract": "The task of automated code review has recently gained a lot of attention from\nthe machine learning community. However, current review comment evaluation\nmetrics rely on comparisons with a human-written reference for a given code\nchange (also called a diff). Furthermore, code review is a one-to-many problem,\nlike generation and summarization, with many \"valid reviews\" for a diff. Thus,\nwe develop CRScore - a reference-free metric to measure dimensions of review\nquality like conciseness, comprehensiveness, and relevance. We design CRScore\nto evaluate reviews in a way that is grounded in claims and potential issues\ndetected in the code by LLMs and static analyzers. We demonstrate that CRScore\ncan produce valid, fine-grained scores of review quality that have the greatest\nalignment with human judgment among open source metrics (0.54 Spearman\ncorrelation) and are more sensitive than reference-based metrics. We also\nrelease a corpus of 2.9k human-annotated review quality scores for\nmachine-generated and GitHub review comments to support the development of\nautomated metrics.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19801v2",
    "published_date": "2024-09-29 21:53:18 UTC",
    "updated_date": "2025-03-16 18:22:15 UTC"
  },
  {
    "arxiv_id": "2409.19790v1",
    "title": "Analysis on Riemann Hypothesis with Cross Entropy Optimization and Reasoning",
    "authors": [
      "Kevin Li",
      "Fulu Li"
    ],
    "abstract": "In this paper, we present a novel framework for the analysis of Riemann\nHypothesis [27], which is composed of three key components: a) probabilistic\nmodeling with cross entropy optimization and reasoning; b) the application of\nthe law of large numbers; c) the application of mathematical inductions. The\nanalysis is mainly conducted by virtue of probabilistic modeling of cross\nentropy optimization and reasoning with rare event simulation techniques. The\napplication of the law of large numbers [2, 3, 6] and the application of\nmathematical inductions make the analysis of Riemann Hypothesis self-contained\nand complete to make sure that the whole complex plane is covered as\nconjectured in Riemann Hypothesis. We also discuss the method of enhanced top-p\nsampling with large language models (LLMs) for reasoning, where next token\nprediction is not just based on the estimated probabilities of each possible\ntoken in the current round but also based on accumulated path probabilities\namong multiple top-k chain of thoughts (CoTs) paths. The probabilistic modeling\nof cross entropy optimization and reasoning may suit well with the analysis of\nRiemann Hypothesis as Riemann Zeta functions are inherently dealing with the\nsums of infinite components of a complex number series.\n  We hope that our analysis in this paper could shed some light on some of the\ninsights of Riemann Hypothesis. The framework and techniques presented in this\npaper, coupled with recent developments with chain of thought (CoT) or diagram\nof thought (DoT) reasoning in large language models (LLMs) with reinforcement\nlearning (RL) [1, 7, 18, 21, 24, 34, 39-41], could pave the way for eventual\nproof of Riemann Hypothesis [27].",
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.19790v1",
    "published_date": "2024-09-29 21:25:58 UTC",
    "updated_date": "2024-09-29 21:25:58 UTC"
  },
  {
    "arxiv_id": "2409.19769v1",
    "title": "Adaptive Event-triggered Reinforcement Learning Control for Complex Nonlinear Systems",
    "authors": [
      "Umer Siddique",
      "Abhinav Sinha",
      "Yongcan Cao"
    ],
    "abstract": "In this paper, we propose an adaptive event-triggered reinforcement learning\ncontrol for continuous-time nonlinear systems, subject to bounded\nuncertainties, characterized by complex interactions. Specifically, the\nproposed method is capable of jointly learning both the control policy and the\ncommunication policy, thereby reducing the number of parameters and\ncomputational overhead when learning them separately or only one of them. By\naugmenting the state space with accrued rewards that represent the performance\nover the entire trajectory, we show that accurate and efficient determination\nof triggering conditions is possible without the need for explicit learning\ntriggering conditions, thereby leading to an adaptive non-stationary policy.\nFinally, we provide several numerical examples to demonstrate the effectiveness\nof the proposed approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19769v1",
    "published_date": "2024-09-29 20:42:19 UTC",
    "updated_date": "2024-09-29 20:42:19 UTC"
  },
  {
    "arxiv_id": "2409.19766v1",
    "title": "Towards Robust Extractive Question Answering Models: Rethinking the Training Methodology",
    "authors": [
      "Son Quoc Tran",
      "Matt Kretchmar"
    ],
    "abstract": "This paper proposes a novel training method to improve the robustness of\nExtractive Question Answering (EQA) models. Previous research has shown that\nexisting models, when trained on EQA datasets that include unanswerable\nquestions, demonstrate a significant lack of robustness against distribution\nshifts and adversarial attacks. Despite this, the inclusion of unanswerable\nquestions in EQA training datasets is essential for ensuring real-world\nreliability. Our proposed training method includes a novel loss function for\nthe EQA problem and challenges an implicit assumption present in numerous EQA\ndatasets. Models trained with our method maintain in-domain performance while\nachieving a notable improvement on out-of-domain datasets. This results in an\noverall F1 score improvement of 5.7 across all testing sets. Furthermore, our\nmodels exhibit significantly enhanced robustness against two types of\nadversarial attacks, with a performance decrease of only about a third compared\nto the default models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2409.19766v1",
    "published_date": "2024-09-29 20:35:57 UTC",
    "updated_date": "2024-09-29 20:35:57 UTC"
  },
  {
    "arxiv_id": "2409.19751v1",
    "title": "Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification",
    "authors": [
      "Mohamed Abdelhamid",
      "Abhyuday Desai"
    ],
    "abstract": "Class imbalance in binary classification tasks remains a significant\nchallenge in machine learning, often resulting in poor performance on minority\nclasses. This study comprehensively evaluates three widely-used strategies for\nhandling class imbalance: Synthetic Minority Over-sampling Technique (SMOTE),\nClass Weights tuning, and Decision Threshold Calibration. We compare these\nmethods against a baseline scenario of no-intervention across 15 diverse\nmachine learning models and 30 datasets from various domains, conducting a\ntotal of 9,000 experiments. Performance was primarily assessed using the\nF1-score, although our study also tracked results on additional 9 metrics\nincluding F2-score, precision, recall, Brier-score, PR-AUC, and AUC. Our\nresults indicate that all three strategies generally outperform the baseline,\nwith Decision Threshold Calibration emerging as the most consistently effective\ntechnique. However, we observed substantial variability in the best-performing\nmethod across datasets, highlighting the importance of testing multiple\napproaches for specific problems. This study provides valuable insights for\npractitioners dealing with imbalanced datasets and emphasizes the need for\ndataset-specific analysis in evaluating class imbalance handling techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "I.2.6; I.5.1; I.5.2; I.2.m"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages including appendix, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.19751v1",
    "published_date": "2024-09-29 16:02:32 UTC",
    "updated_date": "2024-09-29 16:02:32 UTC"
  },
  {
    "arxiv_id": "2409.19745v2",
    "title": "PEAR: Position-Embedding-Agnostic Attention Re-weighting Enhances Retrieval-Augmented Generation with Zero Inference Overhead",
    "authors": [
      "Tao Tan",
      "Yining Qian",
      "Ang Lv",
      "Hongzhan Lin",
      "Songhao Wu",
      "Yongbo Wang",
      "Feng Wang",
      "Jingtong Wu",
      "Xin Lu",
      "Rui Yan"
    ],
    "abstract": "Large language models (LLMs) enhanced with retrieval-augmented generation\n(RAG) have introduced a new paradigm for web search. However, the limited\ncontext awareness of LLMs degrades their performance on RAG tasks. Existing\nmethods to enhance context awareness are often inefficient, incurring time or\nmemory overhead during inference, and many are tailored to specific position\nembeddings. In this paper, we propose Position-Embedding-Agnostic attention\nRe-weighting (PEAR), which enhances the context awareness of LLMs with zero\ninference overhead. Specifically, on a proxy task focused on context copying,\nwe first detect heads which suppress the models' context awareness thereby\ndiminishing RAG performance. To weaken the impact of these heads, we re-weight\ntheir outputs with learnable coefficients. The LLM (with frozen parameters) is\noptimized by adjusting these coefficients to minimize loss on the proxy task.\nAs a result, the coefficients are optimized to values less than one, thereby\nreducing their tendency to suppress RAG performance. During inference, the\noptimized coefficients are fixed to re-weight these heads, regardless of the\nspecific task at hand. Our proposed PEAR offers two major advantages over\nprevious approaches: (1) It introduces zero additional inference overhead in\nterms of memory usage or inference time, while outperforming competitive\nbaselines in accuracy and efficiency across various RAG tasks. (2) It is\nindependent of position embedding algorithms, ensuring broader applicability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2409.19745v2",
    "published_date": "2024-09-29 15:40:54 UTC",
    "updated_date": "2024-10-07 14:17:44 UTC"
  },
  {
    "arxiv_id": "2409.19732v1",
    "title": "Unified Gradient-Based Machine Unlearning with Remain Geometry Enhancement",
    "authors": [
      "Zhehao Huang",
      "Xinwen Cheng",
      "JingHao Zheng",
      "Haoran Wang",
      "Zhengbao He",
      "Tao Li",
      "Xiaolin Huang"
    ],
    "abstract": "Machine unlearning (MU) has emerged to enhance the privacy and\ntrustworthiness of deep neural networks. Approximate MU is a practical method\nfor large-scale models. Our investigation into approximate MU starts with\nidentifying the steepest descent direction, minimizing the output\nKullback-Leibler divergence to exact MU inside a parameters' neighborhood. This\nprobed direction decomposes into three components: weighted forgetting gradient\nascent, fine-tuning retaining gradient descent, and a weight saliency matrix.\nSuch decomposition derived from Euclidean metric encompasses most existing\ngradient-based MU methods. Nevertheless, adhering to Euclidean space may result\nin sub-optimal iterative trajectories due to the overlooked geometric structure\nof the output probability space. We suggest embedding the unlearning update\ninto a manifold rendered by the remaining geometry, incorporating second-order\nHessian from the remaining data. It helps prevent effective unlearning from\ninterfering with the retained performance. However, computing the second-order\nHessian for large-scale models is intractable. To efficiently leverage the\nbenefits of Hessian modulation, we propose a fast-slow parameter update\nstrategy to implicitly approximate the up-to-date salient unlearning direction.\nFree from specific modal constraints, our approach is adaptable across computer\nvision unlearning tasks, including classification and generation. Extensive\nexperiments validate our efficacy and efficiency. Notably, our method\nsuccessfully performs class-forgetting on ImageNet using DiT and forgets a\nclass on CIFAR-10 using DDPM in just 50 steps, compared to thousands of steps\nrequired by previous methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024 as a Spotlight paper",
    "pdf_url": "http://arxiv.org/pdf/2409.19732v1",
    "published_date": "2024-09-29 15:17:33 UTC",
    "updated_date": "2024-09-29 15:17:33 UTC"
  },
  {
    "arxiv_id": "2409.19716v1",
    "title": "Constrained Reinforcement Learning for Safe Heat Pump Control",
    "authors": [
      "Baohe Zhang",
      "Lilli Frison",
      "Thomas Brox",
      "Joschka Bödecker"
    ],
    "abstract": "Constrained Reinforcement Learning (RL) has emerged as a significant research\narea within RL, where integrating constraints with rewards is crucial for\nenhancing safety and performance across diverse control tasks. In the context\nof heating systems in the buildings, optimizing the energy efficiency while\nmaintaining the residents' thermal comfort can be intuitively formulated as a\nconstrained optimization problem. However, to solve it with RL may require\nlarge amount of data. Therefore, an accurate and versatile simulator is\nfavored. In this paper, we propose a novel building simulator I4B which\nprovides interfaces for different usages and apply a model-free constrained RL\nalgorithm named constrained Soft Actor-Critic with Linear Smoothed Log Barrier\nfunction (CSAC-LB) to the heating optimization problem. Benchmarking against\nbaseline algorithms demonstrates CSAC-LB's efficiency in data exploration,\nconstraint satisfaction and performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19716v1",
    "published_date": "2024-09-29 14:15:13 UTC",
    "updated_date": "2024-09-29 14:15:13 UTC"
  },
  {
    "arxiv_id": "2410.00061v1",
    "title": "Neural Decompiling of Tracr Transformers",
    "authors": [
      "Hannes Thurnherr",
      "Kaspar Riesen"
    ],
    "abstract": "Recently, the transformer architecture has enabled substantial progress in\nmany areas of pattern recognition and machine learning. However, as with other\nneural network models, there is currently no general method available to\nexplain their inner workings. The present paper represents a first step towards\nthis direction. We utilize \\textit{Transformer Compiler for RASP} (Tracr) to\ngenerate a large dataset of pairs of transformer weights and corresponding RASP\nprograms. Based on this dataset, we then build and train a model, with the aim\nof recovering the RASP code from the compiled model. We demonstrate that the\nsimple form of Tracr compiled transformer weights is interpretable for such a\ndecompiler model. In an empirical evaluation, our model achieves exact\nreproductions on more than 30\\% of the test objects, while the remaining 70\\%\ncan generally be reproduced with only few errors. Additionally, more than 70\\%\nof the programs, produced by our model, are functionally equivalent to the\nground truth, and therefore a valid decompilation of the Tracr compiled\ntransformer weights.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.00061v1",
    "published_date": "2024-09-29 13:12:39 UTC",
    "updated_date": "2024-09-29 13:12:39 UTC"
  },
  {
    "arxiv_id": "2409.19689v2",
    "title": "InfantCryNet: A Data-driven Framework for Intelligent Analysis of Infant Cries",
    "authors": [
      "Mengze Hong",
      "Chen Jason Zhang",
      "Lingxiao Yang",
      "Yuanfeng Song",
      "Di Jiang"
    ],
    "abstract": "Understanding the meaning of infant cries is a significant challenge for\nyoung parents in caring for their newborns. The presence of background noise\nand the lack of labeled data present practical challenges in developing systems\nthat can detect crying and analyze its underlying reasons. In this paper, we\npresent a novel data-driven framework, \"InfantCryNet,\" for accomplishing these\ntasks. To address the issue of data scarcity, we employ pre-trained audio\nmodels to incorporate prior knowledge into our model. We propose the use of\nstatistical pooling and multi-head attention pooling techniques to extract\nfeatures more effectively. Additionally, knowledge distillation and model\nquantization are applied to enhance model efficiency and reduce the model size,\nbetter supporting industrial deployment in mobile devices. Experiments on\nreal-life datasets demonstrate the superior performance of the proposed\nframework, outperforming state-of-the-art baselines by 4.4% in classification\naccuracy. The model compression effectively reduces the model size by 7%\nwithout compromising performance and by up to 28% with only an 8% decrease in\naccuracy, offering practical insights for model selection and system design.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by the 16th Asian Conference on Machine Learning (ACML 2024)",
    "pdf_url": "http://arxiv.org/pdf/2409.19689v2",
    "published_date": "2024-09-29 12:35:47 UTC",
    "updated_date": "2025-02-04 10:23:05 UTC"
  },
  {
    "arxiv_id": "2409.19688v1",
    "title": "Machine Learning for Raman Spectroscopy-based Cyber-Marine Fish Biochemical Composition Analysis",
    "authors": [
      "Yun Zhou",
      "Gang Chen",
      "Bing Xue",
      "Mengjie Zhang",
      "Jeremy S. Rooney",
      "Kirill Lagutin",
      "Andrew MacKenzie",
      "Keith C. Gordon",
      "Daniel P. Killeen"
    ],
    "abstract": "The rapid and accurate detection of biochemical compositions in fish is a\ncrucial real-world task that facilitates optimal utilization and extraction of\nhigh-value products in the seafood industry. Raman spectroscopy provides a\npromising solution for quickly and non-destructively analyzing the biochemical\ncomposition of fish by associating Raman spectra with biochemical reference\ndata using machine learning regression models. This paper investigates\ndifferent regression models to address this task and proposes a new design of\nConvolutional Neural Networks (CNNs) for jointly predicting water, protein, and\nlipids yield. To the best of our knowledge, we are the first to conduct a\nsuccessful study employing CNNs to analyze the biochemical composition of fish\nbased on a very small Raman spectroscopic dataset. Our approach combines a\ntailored CNN architecture with the comprehensive data preparation procedure,\neffectively mitigating the challenges posed by extreme data scarcity. The\nresults demonstrate that our CNN can significantly outperform two\nstate-of-the-art CNN models and multiple traditional machine learning models,\npaving the way for accurate and automated analysis of fish biochemical\ncomposition.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19688v1",
    "published_date": "2024-09-29 12:28:19 UTC",
    "updated_date": "2024-09-29 12:28:19 UTC"
  },
  {
    "arxiv_id": "2409.19680v1",
    "title": "Instruction Embedding: Latent Representations of Instructions Towards Task Identification",
    "authors": [
      "Yiwei Li",
      "Jiayi Shi",
      "Shaoxiong Feng",
      "Peiwen Yuan",
      "Xinglin Wang",
      "Boyuan Pan",
      "Heda Wang",
      "Yao Hu",
      "Kan Li"
    ],
    "abstract": "Instruction data is crucial for improving the capability of Large Language\nModels (LLMs) to align with human-level performance. Recent research LIMA\ndemonstrates that alignment is essentially a process where the model adapts\ninstructions' interaction style or format to solve various tasks, leveraging\npre-trained knowledge and skills. Therefore, for instructional data, the most\nimportant aspect is the task it represents, rather than the specific semantics\nand knowledge information. The latent representations of instructions play\nroles for some instruction-related tasks like data selection and demonstrations\nretrieval. However, they are always derived from text embeddings, encompass\noverall semantic information that influences the representation of task\ncategories. In this work, we introduce a new concept, instruction embedding,\nand construct Instruction Embedding Benchmark (IEB) for its training and\nevaluation. Then, we propose a baseline Prompt-based Instruction Embedding\n(PIE) method to make the representations more attention on tasks. The\nevaluation of PIE, alongside other embedding methods on IEB with two designed\ntasks, demonstrates its superior performance in accurately identifying task\ncategories. Moreover, the application of instruction embeddings in four\ndownstream tasks showcases its effectiveness and suitability for\ninstruction-related tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.19680v1",
    "published_date": "2024-09-29 12:12:24 UTC",
    "updated_date": "2024-09-29 12:12:24 UTC"
  },
  {
    "arxiv_id": "2409.19676v2",
    "title": "See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning",
    "authors": [
      "Chengxin Zheng",
      "Junzhong Ji",
      "Yanzhao Shi",
      "Xiaodan Zhang",
      "Liangqiong Qu"
    ],
    "abstract": "Brain CT report generation is significant to aid physicians in diagnosing\ncranial diseases. Recent studies concentrate on handling the consistency\nbetween visual and textual pathological features to improve the coherence of\nreport. However, there exist some challenges: 1) Redundant visual representing:\nMassive irrelevant areas in 3D scans distract models from representing salient\nvisual contexts. 2) Shifted semantic representing: Limited medical corpus\ncauses difficulties for models to transfer the learned textual representations\nto generative layers. This study introduces a Pathological Clue-driven\nRepresentation Learning (PCRL) model to build cross-modal representations based\non pathological clues and naturally adapt them for accurate report generation.\nSpecifically, we construct pathological clues from perspectives of segmented\nregions, pathological entities, and report themes, to fully grasp visual\npathological patterns and learn cross-modal feature representations. To adapt\nthe representations for the text generation task, we bridge the gap between\nrepresentation learning and report generation by using a unified large language\nmodel (LLM) with task-tailored instructions. These crafted instructions enable\nthe LLM to be flexibly fine-tuned across tasks and smoothly transfer the\nsemantic representation for report generation. Experiments demonstrate that our\nmethod outperforms previous methods and achieves SoTA performance. Our code is\navailable at \"https://github.com/Chauncey-Jheng/PCRL-MRG\".",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Our work has been accepted by EMNLP2024 findings",
    "pdf_url": "http://arxiv.org/pdf/2409.19676v2",
    "published_date": "2024-09-29 12:08:20 UTC",
    "updated_date": "2024-10-01 10:42:32 UTC"
  },
  {
    "arxiv_id": "2409.19668v1",
    "title": "Local Search for Integer Quadratic Programming",
    "authors": [
      "Xiang He",
      "Peng Lin",
      "Shaowei Cai"
    ],
    "abstract": "Integer Quadratic Programming (IQP) is an important problem in operations\nresearch. Local search is a powerful method for solving hard problems, but the\nresearch on local search algorithms for IQP solving is still on its early\nstage. This paper develops an efficient local search solver for solving general\nIQP, called LS-IQCQP. We propose four new local search operators for IQP that\ncan handle quadratic terms in the objective function, constraints or both.\nFurthermore, a two-mode local search algorithm is introduced, utilizing newly\ndesigned scoring functions to enhance the search process. Experiments are\nconducted on standard IQP benchmarks QPLIB and MINLPLIB, comparing LS-IQCQP\nwith several state-of-the-art IQP solvers. Experimental results demonstrate\nthat LS-IQCQP is competitive with the most powerful commercial solver Gurobi\nand outperforms other state-of-the-art solvers. Moreover, LS-IQCQP has\nestablished 6 new records for QPLIB and MINLPLIB open instances.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19668v1",
    "published_date": "2024-09-29 11:45:44 UTC",
    "updated_date": "2024-09-29 11:45:44 UTC"
  },
  {
    "arxiv_id": "2409.19667v3",
    "title": "Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models",
    "authors": [
      "Xin Sky Li",
      "Weize Chen",
      "Qizhi Chu",
      "Haopeng Li",
      "Zhaojun Sun",
      "Ran Li",
      "Chen Qian",
      "Yiwei Wei",
      "Zhiyuan Liu",
      "Chuan Shi",
      "Maosong Sun",
      "Cheng Yang"
    ],
    "abstract": "The need to analyze graphs is ubiquitous across various fields, from social\nnetworks to biological research and recommendation systems. Therefore, enabling\nthe ability of large language models (LLMs) to process graphs is an important\nstep toward more advanced general intelligence. However, current LLM benchmarks\non graph analysis require models to directly reason over the prompts describing\ngraph topology, and are thus limited to small graphs with only a few dozens of\nnodes. In contrast, human experts typically write programs based on popular\nlibraries for task solving, and can thus handle graphs with different scales.\nTo this end, a question naturally arises: can LLMs analyze graphs like\nprofessionals? In this paper, we introduce ProGraph, a manually crafted\nbenchmark containing 3 categories of graph tasks. The benchmark expects\nsolutions based on programming instead of directly reasoning over raw inputs.\nOur findings reveal that the performance of current LLMs is unsatisfactory,\nwith the best model achieving only 36% accuracy. To bridge this gap, we propose\nLLM4Graph datasets, which include crawled documents and auto-generated codes\nbased on 6 widely used graph libraries. By augmenting closed-source LLMs with\ndocument retrieval and fine-tuning open-source ones on the codes, we show\n11-32% absolute improvements in their accuracies. Our results underscore that\nthe capabilities of LLMs in handling structured data are still under-explored,\nand show the effectiveness of LLM4Graph in enhancing LLMs' proficiency of graph\nanalysis. The benchmark, datasets and enhanced open-source models are available\nat https://github.com/BUPT-GAMMA/ProGraph.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.19667v3",
    "published_date": "2024-09-29 11:38:45 UTC",
    "updated_date": "2025-02-24 05:39:36 UTC"
  },
  {
    "arxiv_id": "2409.19663v2",
    "title": "Identifying Knowledge Editing Types in Large Language Models",
    "authors": [
      "Xiaopeng Li",
      "Shangwen Wang",
      "Shezheng Song",
      "Bin Ji",
      "Huijun Liu",
      "Shasha Li",
      "Jun Ma",
      "Jie Yu"
    ],
    "abstract": "Knowledge editing has emerged as an efficient technology for updating the\nknowledge of large language models (LLMs), attracting increasing attention in\nrecent years. However, there is a lack of effective measures to prevent the\nmalicious misuse of this technology, which could lead to harmful edits in LLMs.\nThese malicious modifications could cause LLMs to generate toxic content,\nmisleading users into inappropriate actions. In front of this risk, we\nintroduce a new task, Knowledge Editing Type Identification (KETI), aimed at\nidentifying different types of edits in LLMs, thereby providing timely alerts\nto users when encountering illicit edits. As part of this task, we propose\nKETIBench, which includes five types of harmful edits covering most popular\ntoxic types, as well as one benign factual edit. We develop four classical\nclassification models and three BERT-based models as baseline identifiers for\nboth open-source and closed-source LLMs. Our experimental results, across 42\ntrials involving two models and three knowledge editing methods, demonstrate\nthat all seven baseline identifiers achieve decent identification performance,\nhighlighting the feasibility of identifying malicious edits in LLMs. Additional\nanalyses reveal that the performance of the identifiers is independent of the\nreliability of the knowledge editing methods and exhibits cross-domain\ngeneralization, enabling the identification of edits from unknown sources. All\ndata and code are available in https://github.com/xpq-tech/KETI. Warning: This\npaper contains examples of toxic text.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2409.19663v2",
    "published_date": "2024-09-29 11:29:57 UTC",
    "updated_date": "2024-10-01 06:35:24 UTC"
  },
  {
    "arxiv_id": "2409.19655v2",
    "title": "Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales",
    "authors": [
      "Maor Reuben",
      "Ortal Slobodin",
      "Aviad Elyshar",
      "Idan-Chaim Cohen",
      "Orna Braun-Lewensohn",
      "Odeya Cohen",
      "Rami Puzis"
    ],
    "abstract": "Human-like personality traits have recently been discovered in large language\nmodels, raising the hypothesis that their (known and as yet undiscovered)\nbiases conform with human latent psychological constructs. While large\nconversational models may be tricked into answering psychometric\nquestionnaires, the latent psychological constructs of thousands of simpler\ntransformers, trained for other tasks, cannot be assessed because appropriate\npsychometric methods are currently lacking. Here, we show how standard\npsychological questionnaires can be reformulated into natural language\ninference prompts, and we provide a code library to support the psychometric\nassessment of arbitrary models. We demonstrate, using a sample of 88 publicly\navailable models, the existence of human-like mental health-related constructs\n(including anxiety, depression, and Sense of Coherence) which conform with\nstandard theories in human psychology and show similar correlations and\nmitigation strategies. The ability to interpret and rectify the performance of\nlanguage models by using psychological tools can boost the development of more\nexplainable, controllable, and trustworthy models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19655v2",
    "published_date": "2024-09-29 11:00:41 UTC",
    "updated_date": "2025-01-13 10:08:07 UTC"
  },
  {
    "arxiv_id": "2409.19650v1",
    "title": "Grounding 3D Scene Affordance From Egocentric Interactions",
    "authors": [
      "Cuiyu Liu",
      "Wei Zhai",
      "Yuhang Yang",
      "Hongchen Luo",
      "Sen Liang",
      "Yang Cao",
      "Zheng-Jun Zha"
    ],
    "abstract": "Grounding 3D scene affordance aims to locate interactive regions in 3D\nenvironments, which is crucial for embodied agents to interact intelligently\nwith their surroundings. Most existing approaches achieve this by mapping\nsemantics to 3D instances based on static geometric structure and visual\nappearance. This passive strategy limits the agent's ability to actively\nperceive and engage with the environment, making it reliant on predefined\nsemantic instructions. In contrast, humans develop complex interaction skills\nby observing and imitating how others interact with their surroundings. To\nempower the model with such abilities, we introduce a novel task: grounding 3D\nscene affordance from egocentric interactions, where the goal is to identify\nthe corresponding affordance regions in a 3D scene based on an egocentric video\nof an interaction. This task faces the challenges of spatial complexity and\nalignment complexity across multiple sources. To address these challenges, we\npropose the Egocentric Interaction-driven 3D Scene Affordance Grounding\n(Ego-SAG) framework, which utilizes interaction intent to guide the model in\nfocusing on interaction-relevant sub-regions and aligns affordance features\nfrom different sources through a bidirectional query decoder mechanism.\nFurthermore, we introduce the Egocentric Video-3D Scene Affordance Dataset\n(VSAD), covering a wide range of common interaction types and diverse 3D\nenvironments to support this task. Extensive experiments on VSAD validate both\nthe feasibility of the proposed task and the effectiveness of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19650v1",
    "published_date": "2024-09-29 10:46:19 UTC",
    "updated_date": "2024-09-29 10:46:19 UTC"
  },
  {
    "arxiv_id": "2409.19647v1",
    "title": "Fine-Tuning Hybrid Physics-Informed Neural Networks for Vehicle Dynamics Model Estimation",
    "authors": [
      "Shiming Fang",
      "Kaiyan Yu"
    ],
    "abstract": "Accurate dynamic modeling is critical for autonomous racing vehicles,\nespecially during high-speed and agile maneuvers where precise motion\nprediction is essential for safety. Traditional parameter estimation methods\nface limitations such as reliance on initial guesses, labor-intensive fitting\nprocedures, and complex testing setups. On the other hand, purely data-driven\nmachine learning methods struggle to capture inherent physical constraints and\ntypically require large datasets for optimal performance. To address these\nchallenges, this paper introduces the Fine-Tuning Hybrid Dynamics (FTHD)\nmethod, which integrates supervised and unsupervised Physics-Informed Neural\nNetworks (PINNs), combining physics-based modeling with data-driven techniques.\nFTHD fine-tunes a pre-trained Deep Dynamics Model (DDM) using a smaller\ntraining dataset, delivering superior performance compared to state-of-the-art\nmethods such as the Deep Pacejka Model (DPM) and outperforming the original\nDDM. Furthermore, an Extended Kalman Filter (EKF) is embedded within FTHD\n(EKF-FTHD) to effectively manage noisy real-world data, ensuring accurate\ndenoising while preserving the vehicle's essential physical characteristics.\nThe proposed FTHD framework is validated through scaled simulations using the\nBayesRace Physics-based Simulator and full-scale real-world experiments from\nthe Indy Autonomous Challenge. Results demonstrate that the hybrid approach\nsignificantly improves parameter estimation accuracy, even with reduced data,\nand outperforms existing models. EKF-FTHD enhances robustness by denoising\nreal-world data while maintaining physical insights, representing a notable\nadvancement in vehicle dynamics modeling for high-speed autonomous racing.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19647v1",
    "published_date": "2024-09-29 10:33:07 UTC",
    "updated_date": "2024-09-29 10:33:07 UTC"
  },
  {
    "arxiv_id": "2410.03724v2",
    "title": "Large Language Models Overcome the Machine Penalty When Acting Fairly but Not When Acting Selfishly or Altruistically",
    "authors": [
      "Zhen Wang",
      "Ruiqi Song",
      "Chen Shen",
      "Shiya Yin",
      "Zhao Song",
      "Balaraju Battu",
      "Lei Shi",
      "Danyang Jia",
      "Talal Rahwan",
      "Shuyue Hu"
    ],
    "abstract": "In social dilemmas where the collective and self-interests are at odds,\npeople typically cooperate less with machines than with fellow humans, a\nphenomenon termed the machine penalty. Overcoming this penalty is critical for\nsuccessful human-machine collectives, yet current solutions often involve\nethically-questionable tactics, like concealing machines' non-human nature. In\nthis study, with 1,152 participants, we explore the possibility of closing this\nresearch question by using Large Language Models (LLMs), in scenarios where\ncommunication is possible between interacting parties. We design three types of\nLLMs: (i) Cooperative, aiming to assist its human associate; (ii) Selfish,\nfocusing solely on maximizing its self-interest; and (iii) Fair, balancing its\nown and collective interest, while slightly prioritizing self-interest. Our\nfindings reveal that, when interacting with humans, fair LLMs are able to\ninduce cooperation levels comparable to those observed in human-human\ninteractions, even when their non-human nature is fully disclosed. In contrast,\nselfish and cooperative LLMs fail to achieve this goal. Post-experiment\nanalysis shows that all three types of LLMs succeed in forming mutual\ncooperation agreements with humans, yet only fair LLMs, which occasionally\nbreak their promises, are capable of instilling a perception among humans that\ncooperating with them is the social norm, and eliciting positive views on their\ntrustworthiness, mindfulness, intelligence, and communication quality. Our\nfindings suggest that for effective human-machine cooperation, bot\nmanufacturers should avoid designing machines with mere rational\ndecision-making or a sole focus on assisting humans. Instead, they should\ndesign machines capable of judiciously balancing their own interest and the\ninterest of humans.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.GT",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03724v2",
    "published_date": "2024-09-29 10:11:25 UTC",
    "updated_date": "2024-10-08 09:16:15 UTC"
  },
  {
    "arxiv_id": "2409.19638v1",
    "title": "BadHMP: Backdoor Attack against Human Motion Prediction",
    "authors": [
      "Chaohui Xu",
      "Si Wang",
      "Chip-Hong Chang"
    ],
    "abstract": "Precise future human motion prediction over subsecond horizons from past\nobservations is crucial for various safety-critical applications. To date, only\none study has examined the vulnerability of human motion prediction to evasion\nattacks. In this paper, we propose BadHMP, the first backdoor attack that\ntargets specifically human motion prediction. Our approach involves generating\npoisoned training samples by embedding a localized backdoor trigger in one arm\nof the skeleton, causing selected joints to remain relatively still or follow\npredefined motion in historical time steps. Subsequently, the future sequences\nare globally modified to the target sequences, and the entire training dataset\nis traversed to select the most suitable samples for poisoning. Our carefully\ndesigned backdoor triggers and targets guarantee the smoothness and naturalness\nof the poisoned samples, making them stealthy enough to evade detection by the\nmodel trainer while keeping the poisoned model unobtrusive in terms of\nprediction fidelity to untainted sequences. The target sequences can be\nsuccessfully activated by the designed input sequences even with a low poisoned\nsample injection ratio. Experimental results on two datasets (Human3.6M and\nCMU-Mocap) and two network architectures (LTD and HRI) demonstrate the\nhigh-fidelity, effectiveness, and stealthiness of BadHMP. Robustness of our\nattack against fine-tuning defense is also verified.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19638v1",
    "published_date": "2024-09-29 09:55:31 UTC",
    "updated_date": "2024-09-29 09:55:31 UTC"
  },
  {
    "arxiv_id": "2409.19629v1",
    "title": "A Survey on Graph Neural Networks for Remaining Useful Life Prediction: Methodologies, Evaluation and Future Trends",
    "authors": [
      "Yucheng Wang",
      "Min Wu",
      "Xiaoli Li",
      "Lihua Xie",
      "Zhenghua Chen"
    ],
    "abstract": "Remaining Useful Life (RUL) prediction is a critical aspect of Prognostics\nand Health Management (PHM), aimed at predicting the future state of a system\nto enable timely maintenance and prevent unexpected failures. While existing\ndeep learning methods have shown promise, they often struggle to fully leverage\nthe spatial information inherent in complex systems, limiting their\neffectiveness in RUL prediction. To address this challenge, recent research has\nexplored the use of Graph Neural Networks (GNNs) to model spatial information\nfor more accurate RUL prediction. This paper presents a comprehensive review of\nGNN techniques applied to RUL prediction, summarizing existing methods and\noffering guidance for future research. We first propose a novel taxonomy based\non the stages of adapting GNNs to RUL prediction, systematically categorizing\napproaches into four key stages: graph construction, graph modeling, graph\ninformation processing, and graph readout. By organizing the field in this way,\nwe highlight the unique challenges and considerations at each stage of the GNN\npipeline. Additionally, we conduct a thorough evaluation of various\nstate-of-the-art (SOTA) GNN methods, ensuring consistent experimental settings\nfor fair comparisons. This rigorous analysis yields valuable insights into the\nstrengths and weaknesses of different approaches, serving as an experimental\nguide for researchers and practitioners working in this area. Finally, we\nidentify and discuss several promising research directions that could further\nadvance the field, emphasizing the potential for GNNs to revolutionize RUL\nprediction and enhance the effectiveness of PHM strategies. The benchmarking\ncodes are available in GitHub:\nhttps://github.com/Frank-Wang-oss/GNN\\_RUL\\_Benchmarking.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19629v1",
    "published_date": "2024-09-29 09:38:07 UTC",
    "updated_date": "2024-09-29 09:38:07 UTC"
  },
  {
    "arxiv_id": "2410.00059v1",
    "title": "IDEA: An Inverse Domain Expert Adaptation Based Active DNN IP Protection Method",
    "authors": [
      "Chaohui Xu",
      "Qi Cui",
      "Jinxin Dong",
      "Weiyang He",
      "Chip-Hong Chang"
    ],
    "abstract": "Illegitimate reproduction, distribution and derivation of Deep Neural Network\n(DNN) models can inflict economic loss, reputation damage and even privacy\ninfringement. Passive DNN intellectual property (IP) protection methods such as\nwatermarking and fingerprinting attempt to prove the ownership upon IP\nviolation, but they are often too late to stop catastrophic damage of IP abuse\nand too feeble against strong adversaries. In this paper, we propose IDEA, an\nInverse Domain Expert Adaptation based proactive DNN IP protection method\nfeaturing active authorization and source traceability. IDEA generalizes active\nauthorization as an inverse problem of domain adaptation. The multi-adaptive\noptimization is solved by a mixture-of-experts model with one real and two fake\nexperts. The real expert re-optimizes the source model to correctly classify\ntest images with a unique model user key steganographically embedded. The fake\nexperts are trained to output random prediction on test images without or with\nincorrect user key embedded by minimizing their mutual information (MI) with\nthe real expert. The MoE model is knowledge distilled into a unified protected\nmodel to avoid leaking the expert model features by maximizing their MI with\nadditional multi-layer attention and contrastive representation loss\noptimization. IDEA not only prevents unauthorized users without the valid key\nto access the functional model, but also enable the model owner to validate the\ndeployed model and trace the source of IP infringement. We extensively evaluate\nIDEA on five datasets and four DNN models to demonstrate its effectiveness in\nauthorization control, culprit tracing success rate, and robustness against\nvarious attacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.00059v1",
    "published_date": "2024-09-29 09:34:33 UTC",
    "updated_date": "2024-09-29 09:34:33 UTC"
  },
  {
    "arxiv_id": "2409.19625v1",
    "title": "An action language-based formalisation of an abstract argumentation framework",
    "authors": [
      "Yann Munro",
      "Camilo Sarmiento",
      "Isabelle Bloch",
      "Gauvain Bourgne",
      "Catherine Pelachaud",
      "Marie-Jeanne Lesot"
    ],
    "abstract": "An abstract argumentation framework is a commonly used formalism to provide a\nstatic representation of a dialogue. However, the order of enunciation of the\narguments in an argumentative dialogue is very important and can affect the\noutcome of this dialogue. In this paper, we propose a new framework for\nmodelling abstract argumentation graphs, a model that incorporates the order of\nenunciation of arguments. By taking this order into account, we have the means\nto deduce a unique outcome for each dialogue, called an extension. We also\nestablish several properties, such as termination and correctness, and discuss\ntwo notions of completeness. In particular, we propose a modification of the\nprevious transformation based on a \"last enunciated last updated\" strategy,\nwhich verifies the second form of completeness.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "To be published in The 25th International Conference on Principles\n  and Practice of Multi-Agent Systems",
    "pdf_url": "http://arxiv.org/pdf/2409.19625v1",
    "published_date": "2024-09-29 09:24:29 UTC",
    "updated_date": "2024-09-29 09:24:29 UTC"
  },
  {
    "arxiv_id": "2409.19624v1",
    "title": "Storynizor: Consistent Story Generation via Inter-Frame Synchronized and Shuffled ID Injection",
    "authors": [
      "Yuhang Ma",
      "Wenting Xu",
      "Chaoyi Zhao",
      "Keqiang Sun",
      "Qinfeng Jin",
      "Zeng Zhao",
      "Changjie Fan",
      "Zhipeng Hu"
    ],
    "abstract": "Recent advances in text-to-image diffusion models have spurred significant\ninterest in continuous story image generation. In this paper, we introduce\nStorynizor, a model capable of generating coherent stories with strong\ninter-frame character consistency, effective foreground-background separation,\nand diverse pose variation. The core innovation of Storynizor lies in its key\nmodules: ID-Synchronizer and ID-Injector. The ID-Synchronizer employs an\nauto-mask self-attention module and a mask perceptual loss across inter-frame\nimages to improve the consistency of character generation, vividly representing\ntheir postures and backgrounds. The ID-Injector utilize a Shuffling Reference\nStrategy (SRS) to integrate ID features into specific locations, enhancing\nID-based consistent character generation. Additionally, to facilitate the\ntraining of Storynizor, we have curated a novel dataset called StoryDB\ncomprising 100, 000 images. This dataset contains single and multiple-character\nsets in diverse environments, layouts, and gestures with detailed descriptions.\nExperimental results indicate that Storynizor demonstrates superior coherent\nstory generation with high-fidelity character consistency, flexible postures,\nand vivid backgrounds compared to other character-specific methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19624v1",
    "published_date": "2024-09-29 09:15:51 UTC",
    "updated_date": "2024-09-29 09:15:51 UTC"
  },
  {
    "arxiv_id": "2409.19623v1",
    "title": "MCDDPM: Multichannel Conditional Denoising Diffusion Model for Unsupervised Anomaly Detection in Brain MRI",
    "authors": [
      "Vivek Kumar Trivedi",
      "Bheeshm Sharma",
      "P. Balamurugan"
    ],
    "abstract": "Detecting anomalies in brain MRI scans using supervised deep learning methods\npresents challenges due to anatomical diversity and labor-intensive requirement\nof pixel-level annotations. Generative models like Denoising Diffusion\nProbabilistic Model (DDPM) and their variants like pDDPM, mDDPM, cDDPM have\nrecently emerged to be powerful alternatives to perform unsupervised anomaly\ndetection in brain MRI scans. These methods leverage frame-level labels of\nhealthy brains to generate healthy tissues in brain MRI scans. During\ninference, when an anomalous (or unhealthy) scan image is presented as an\ninput, these models generate a healthy scan image corresponding to the input\nanomalous scan, and the difference map between the generated healthy scan image\nand the original anomalous scan image provide the necessary pixel level\nidentification of abnormal tissues. The generated healthy images from the DDPM,\npDDPM and mDDPM models however suffer from fidelity issues and contain\nartifacts that do not have medical significance. While cDDPM achieves slightly\nbetter fidelity and artifact suppression, it requires huge memory footprint and\nis computationally expensive than the other DDPM based models. In this work, we\npropose an improved version of DDPM called Multichannel Conditional Denoising\nDiffusion Probabilistic Model (MCDDPM) for unsupervised anomaly detection in\nbrain MRI scans. Our proposed model achieves high fidelity by making use of\nadditional information from the healthy images during the training process,\nenriching the representation power of DDPM models, with a computational cost\nand memory requirements on par with DDPM, pDDPM and mDDPM models. Experimental\nresults on multiple datasets (e.g. BraTS20, BraTS21) demonstrate promising\nperformance of the proposed method. The code is available at\nhttps://github.com/vivekkumartri/MCDDPM.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted in CISP-BMEI 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.19623v1",
    "published_date": "2024-09-29 09:15:24 UTC",
    "updated_date": "2024-09-29 09:15:24 UTC"
  },
  {
    "arxiv_id": "2409.19620v2",
    "title": "DropEdge not Foolproof: Effective Augmentation Method for Signed Graph Neural Networks",
    "authors": [
      "Zeyu Zhang",
      "Lu Li",
      "Shuyan Wan",
      "Sijie Wang",
      "Zhiyi Wang",
      "Zhiyuan Lu",
      "Dong Hao",
      "Wanli Li"
    ],
    "abstract": "The paper discusses signed graphs, which model friendly or antagonistic\nrelationships using edges marked with positive or negative signs, focusing on\nthe task of link sign prediction. While Signed Graph Neural Networks (SGNNs)\nhave advanced, they face challenges like graph sparsity and unbalanced\ntriangles. The authors propose using data augmentation (DA) techniques to\naddress these issues, although many existing methods are not suitable for\nsigned graphs due to a lack of side information. They highlight that the random\nDropEdge method, a rare DA approach applicable to signed graphs, does not\nenhance link sign prediction performance. In response, they introduce the\nSigned Graph Augmentation (SGA) framework, which includes a structure\naugmentation module to identify candidate edges and a strategy for selecting\nbeneficial candidates, ultimately improving SGNN training. Experimental results\nshow that SGA significantly boosts the performance of SGNN models, with a\nnotable 32.3% improvement in F1-micro for SGCN on the Slashdot dataset.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.19620v2",
    "published_date": "2024-09-29 09:13:23 UTC",
    "updated_date": "2024-10-01 23:15:48 UTC"
  },
  {
    "arxiv_id": "2409.19619v1",
    "title": "Discerning the Chaos: Detecting Adversarial Perturbations while Disentangling Intentional from Unintentional Noises",
    "authors": [
      "Anubhooti Jain",
      "Susim Roy",
      "Kwanit Gupta",
      "Mayank Vatsa",
      "Richa Singh"
    ],
    "abstract": "Deep learning models, such as those used for face recognition and attribute\nprediction, are susceptible to manipulations like adversarial noise and\nunintentional noise, including Gaussian and impulse noise. This paper\nintroduces CIAI, a Class-Independent Adversarial Intent detection network built\non a modified vision transformer with detection layers. CIAI employs a novel\nloss function that combines Maximum Mean Discrepancy and Center Loss to detect\nboth intentional (adversarial attacks) and unintentional noise, regardless of\nthe image class. It is trained in a multi-step fashion. We also introduce the\naspect of intent during detection that can act as an added layer of security.\nWe further showcase the performance of our proposed detector on CelebA,\nCelebA-HQ, LFW, AgeDB, and CIFAR-10 datasets. Our detector is able to detect\nboth intentional (like FGSM, PGD, and DeepFool) and unintentional (like\nGaussian and Salt & Pepper noises) perturbations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19619v1",
    "published_date": "2024-09-29 09:10:43 UTC",
    "updated_date": "2024-09-29 09:10:43 UTC"
  },
  {
    "arxiv_id": "2409.19603v1",
    "title": "One Token to Seg Them All: Language Instructed Reasoning Segmentation in Videos",
    "authors": [
      "Zechen Bai",
      "Tong He",
      "Haiyang Mei",
      "Pichao Wang",
      "Ziteng Gao",
      "Joya Chen",
      "Lei Liu",
      "Zheng Zhang",
      "Mike Zheng Shou"
    ],
    "abstract": "We introduce VideoLISA, a video-based multimodal large language model\ndesigned to tackle the problem of language-instructed reasoning segmentation in\nvideos. Leveraging the reasoning capabilities and world knowledge of large\nlanguage models, and augmented by the Segment Anything Model, VideoLISA\ngenerates temporally consistent segmentation masks in videos based on language\ninstructions. Existing image-based methods, such as LISA, struggle with video\ntasks due to the additional temporal dimension, which requires temporal dynamic\nunderstanding and consistent segmentation across frames. VideoLISA addresses\nthese challenges by integrating a Sparse Dense Sampling strategy into the\nvideo-LLM, which balances temporal context and spatial detail within\ncomputational constraints. Additionally, we propose a One-Token-Seg-All\napproach using a specially designed <TRK> token, enabling the model to segment\nand track objects across multiple frames. Extensive evaluations on diverse\nbenchmarks, including our newly introduced ReasonVOS benchmark, demonstrate\nVideoLISA's superior performance in video object segmentation tasks involving\ncomplex reasoning, temporal understanding, and object tracking. While optimized\nfor videos, VideoLISA also shows promising generalization to image\nsegmentation, revealing its potential as a unified foundation model for\nlanguage-instructed object segmentation. Code and model will be available at:\nhttps://github.com/showlab/VideoLISA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurlPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.19603v1",
    "published_date": "2024-09-29 07:47:15 UTC",
    "updated_date": "2024-09-29 07:47:15 UTC"
  },
  {
    "arxiv_id": "2409.19600v1",
    "title": "An Unbiased Risk Estimator for Partial Label Learning with Augmented Classes",
    "authors": [
      "Jiayu Hu",
      "Senlin Shu",
      "Beibei Li",
      "Tao Xiang",
      "Zhongshi He"
    ],
    "abstract": "Partial Label Learning (PLL) is a typical weakly supervised learning task,\nwhich assumes each training instance is annotated with a set of candidate\nlabels containing the ground-truth label. Recent PLL methods adopt\nidentification-based disambiguation to alleviate the influence of false\npositive labels and achieve promising performance. However, they require all\nclasses in the test set to have appeared in the training set, ignoring the fact\nthat new classes will keep emerging in real applications. To address this\nissue, in this paper, we focus on the problem of Partial Label Learning with\nAugmented Class (PLLAC), where one or more augmented classes are not visible in\nthe training stage but appear in the inference stage. Specifically, we propose\nan unbiased risk estimator with theoretical guarantees for PLLAC, which\nestimates the distribution of augmented classes by differentiating the\ndistribution of known classes from unlabeled data and can be equipped with\narbitrary PLL loss functions. Besides, we provide a theoretical analysis of the\nestimation error bound of the estimator, which guarantees the convergence of\nthe empirical risk minimizer to the true risk minimizer as the number of\ntraining data tends to infinity. Furthermore, we add a risk-penalty\nregularization term in the optimization objective to alleviate the influence of\nthe over-fitting issue caused by negative empirical risk. Extensive experiments\non benchmark, UCI and real-world datasets demonstrate the effectiveness of the\nproposed approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.19600v1",
    "published_date": "2024-09-29 07:36:16 UTC",
    "updated_date": "2024-09-29 07:36:16 UTC"
  },
  {
    "arxiv_id": "2409.19594v1",
    "title": "MASKDROID: Robust Android Malware Detection with Masked Graph Representations",
    "authors": [
      "Jingnan Zheng",
      "Jiaohao Liu",
      "An Zhang",
      "Jun Zeng",
      "Ziqi Yang",
      "Zhenkai Liang",
      "Tat-Seng Chua"
    ],
    "abstract": "Android malware attacks have posed a severe threat to mobile users,\nnecessitating a significant demand for the automated detection system. Among\nthe various tools employed in malware detection, graph representations (e.g.,\nfunction call graphs) have played a pivotal role in characterizing the\nbehaviors of Android apps. However, though achieving impressive performance in\nmalware detection, current state-of-the-art graph-based malware detectors are\nvulnerable to adversarial examples. These adversarial examples are meticulously\ncrafted by introducing specific perturbations to normal malicious inputs. To\ndefend against adversarial attacks, existing defensive mechanisms are typically\nsupplementary additions to detectors and exhibit significant limitations, often\nrelying on prior knowledge of adversarial examples and failing to defend\nagainst unseen types of attacks effectively. In this paper, we propose\nMASKDROID, a powerful detector with a strong discriminative ability to identify\nmalware and remarkable robustness against adversarial attacks. Specifically, we\nintroduce a masking mechanism into the Graph Neural Network (GNN) based\nframework, forcing MASKDROID to recover the whole input graph using a small\nportion (e.g., 20%) of randomly selected nodes.This strategy enables the model\nto understand the malicious semantics and learn more stable representations,\nenhancing its robustness against adversarial attacks. While capturing stable\nmalicious semantics in the form of dependencies inside the graph structures, we\nfurther employ a contrastive module to encourage MASKDROID to learn more\ncompact representations for both the benign and malicious classes to boost its\ndiscriminative power in detecting malware from benign apps and adversarial\nexamples.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19594v1",
    "published_date": "2024-09-29 07:22:47 UTC",
    "updated_date": "2024-09-29 07:22:47 UTC"
  },
  {
    "arxiv_id": "2409.19573v1",
    "title": "See then Tell: Enhancing Key Information Extraction with Vision Grounding",
    "authors": [
      "Shuhang Liu",
      "Zhenrong Zhang",
      "Pengfei Hu",
      "Jiefeng Ma",
      "Jun Du",
      "Qing Wang",
      "Jianshu Zhang",
      "Chenyu Liu"
    ],
    "abstract": "In the digital era, the ability to understand visually rich documents that\nintegrate text, complex layouts, and imagery is critical. Traditional Key\nInformation Extraction (KIE) methods primarily rely on Optical Character\nRecognition (OCR), which often introduces significant latency, computational\noverhead, and errors. Current advanced image-to-text approaches, which bypass\nOCR, typically yield plain text outputs without corresponding vision grounding.\nIn this paper, we introduce STNet (See then Tell Net), a novel end-to-end model\ndesigned to deliver precise answers with relevant vision grounding.\nDistinctively, STNet utilizes a unique <see> token to observe pertinent image\nareas, aided by a decoder that interprets physical coordinates linked to this\ntoken. Positioned at the outset of the answer text, the <see> token allows the\nmodel to first see--observing the regions of the image related to the input\nquestion--and then tell--providing articulated textual responses. To enhance\nthe model's seeing capabilities, we collect extensive structured table\nrecognition datasets. Leveraging the advanced text processing prowess of GPT-4,\nwe develop the TVG (TableQA with Vision Grounding) dataset, which not only\nprovides text-based Question Answering (QA) pairs but also incorporates precise\nvision grounding for these pairs. Our approach demonstrates substantial\nadvancements in KIE performance, achieving state-of-the-art results on publicly\navailable datasets such as CORD, SROIE, and DocVQA. The code will also be made\npublicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19573v1",
    "published_date": "2024-09-29 06:21:05 UTC",
    "updated_date": "2024-09-29 06:21:05 UTC"
  },
  {
    "arxiv_id": "2409.19572v1",
    "title": "Mitigating the Negative Impact of Over-association for Conversational Query Production",
    "authors": [
      "Ante Wang",
      "Linfeng Song",
      "Zijun Min",
      "Ge Xu",
      "Xiaoli Wang",
      "Junfeng Yao",
      "Jinsong Su"
    ],
    "abstract": "Conversational query generation aims at producing search queries from\ndialogue histories, which are then used to retrieve relevant knowledge from a\nsearch engine to help knowledge-based dialogue systems. Trained to maximize the\nlikelihood of gold queries, previous models suffer from the data hunger issue,\nand they tend to both drop important concepts from dialogue histories and\ngenerate irrelevant concepts at inference time. We attribute these issues to\nthe over-association phenomenon where a large number of gold queries are\nindirectly related to the dialogue topics, because annotators may unconsciously\nperform reasoning with their background knowledge when generating these gold\nqueries. We carefully analyze the negative effects of this phenomenon on\npretrained Seq2seq query producers and then propose effective instance-level\nweighting strategies for training to mitigate these issues from multiple\nperspectives. Experiments on two benchmarks, Wizard-of-Internet and DuSinc,\nshow that our strategies effectively alleviate the negative effects and lead to\nsignificant performance gains (2%-5% across automatic metrics and human\nevaluation). Further analysis shows that our model selects better concepts from\ndialogue histories and is 10 times more data efficient than the baseline. The\ncode is available at https://github.com/DeepLearnXMU/QG-OverAsso.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Information Processing & Management",
    "pdf_url": "http://arxiv.org/pdf/2409.19572v1",
    "published_date": "2024-09-29 06:19:59 UTC",
    "updated_date": "2024-09-29 06:19:59 UTC"
  },
  {
    "arxiv_id": "2409.19566v1",
    "title": "Abstractive Summarization of Low resourced Nepali language using Multilingual Transformers",
    "authors": [
      "Prakash Dhakal",
      "Daya Sagar Baral"
    ],
    "abstract": "Automatic text summarization in Nepali language is an unexplored area in\nnatural language processing (NLP). Although considerable research has been\ndedicated to extractive summarization, the area of abstractive summarization,\nespecially for low-resource languages such as Nepali, remains largely\nunexplored. This study explores the use of multilingual transformer models,\nspecifically mBART and mT5, for generating headlines for Nepali news articles\nthrough abstractive summarization. The research addresses key challenges\nassociated with summarizing texts in Nepali by first creating a summarization\ndataset through web scraping from various Nepali news portals. These\nmultilingual models were then fine-tuned using different strategies. The\nperformance of the fine-tuned models were then assessed using ROUGE scores and\nhuman evaluation to ensure the generated summaries were coherent and conveyed\nthe original meaning. During the human evaluation, the participants were asked\nto select the best summary among those generated by the models, based on\ncriteria such as relevance, fluency, conciseness, informativeness, factual\naccuracy, and coverage. During the evaluation with ROUGE scores, the 4-bit\nquantized mBART with LoRA model was found to be effective in generating better\nNepali news headlines in comparison to other models and also it was selected\n34.05% of the time during the human evaluation, outperforming all other\nfine-tuned models created for Nepali News headline generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19566v1",
    "published_date": "2024-09-29 05:58:27 UTC",
    "updated_date": "2024-09-29 05:58:27 UTC"
  },
  {
    "arxiv_id": "2409.19563v1",
    "title": "CLIP-based Camera-Agnostic Feature Learning for Intra-camera Person Re-Identification",
    "authors": [
      "Xuan Tan",
      "Xun Gong",
      "Yang Xiang"
    ],
    "abstract": "Contrastive Language-Image Pre-Training (CLIP) model excels in traditional\nperson re-identification (ReID) tasks due to its inherent advantage in\ngenerating textual descriptions for pedestrian images. However, applying CLIP\ndirectly to intra-camera supervised person re-identification (ICS ReID)\npresents challenges. ICS ReID requires independent identity labeling within\neach camera, without associations across cameras. This limits the effectiveness\nof text-based enhancements. To address this, we propose a novel framework\ncalled CLIP-based Camera-Agnostic Feature Learning (CCAFL) for ICS ReID.\nAccordingly, two custom modules are designed to guide the model to actively\nlearn camera-agnostic pedestrian features: Intra-Camera Discriminative Learning\n(ICDL) and Inter-Camera Adversarial Learning (ICAL). Specifically, we first\nestablish learnable textual prompts for intra-camera pedestrian images to\nobtain crucial semantic supervision signals for subsequent intra- and\ninter-camera learning. Then, we design ICDL to increase inter-class variation\nby considering the hard positive and hard negative samples within each camera,\nthereby learning intra-camera finer-grained pedestrian features. Additionally,\nwe propose ICAL to reduce inter-camera pedestrian feature discrepancies by\npenalizing the model's ability to predict the camera from which a pedestrian\nimage originates, thus enhancing the model's capability to recognize\npedestrians from different viewpoints. Extensive experiments on popular ReID\ndatasets demonstrate the effectiveness of our approach. Especially, on the\nchallenging MSMT17 dataset, we arrive at 58.9\\% in terms of mAP accuracy,\nsurpassing state-of-the-art methods by 7.6\\%. Code will be available at:\nhttps://github.com/Trangle12/CCAFL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted to IEEE TCSVT",
    "pdf_url": "http://arxiv.org/pdf/2409.19563v1",
    "published_date": "2024-09-29 05:43:01 UTC",
    "updated_date": "2024-09-29 05:43:01 UTC"
  },
  {
    "arxiv_id": "2409.19552v3",
    "title": "OmniXAS: A Universal Deep-Learning Framework for Materials X-ray Absorption Spectra",
    "authors": [
      "Shubha R. Kharel",
      "Fanchen Meng",
      "Xiaohui Qu",
      "Matthew R. Carbone",
      "Deyu Lu"
    ],
    "abstract": "X-ray absorption spectroscopy (XAS) is a powerful characterization technique\nfor probing the local chemical environment of absorbing atoms. However,\nanalyzing XAS data presents significant challenges, often requiring extensive,\ncomputationally intensive simulations, as well as significant domain expertise.\nThese limitations hinder the development of fast, robust XAS analysis pipelines\nthat are essential in high-throughput studies and for autonomous\nexperimentation. We address these challenges with OmniXAS, a framework that\ncontains a suite of transfer learning approaches for XAS prediction, each\ncontributing to improved accuracy and efficiency, as demonstrated on K-edge\nspectra database covering eight 3d transition metals (Ti-Cu). The OmniXAS\nframework is built upon three distinct strategies. First, we use M3GNet to\nderive latent representations of the local chemical environment of absorption\nsites as input for XAS prediction, achieving up to order-of-magnitude\nimprovements over conventional featurization techniques. Second, we employ a\nhierarchical transfer learning strategy, training a universal multi-task model\nacross elements before fine-tuning for element-specific predictions. Models\nbased on this cascaded approach after element-wise fine-tuning outperform\nelement-specific models by up to 69%. Third, we implement cross-fidelity\ntransfer learning, adapting a universal model to predict spectra generated by\nsimulation of a different fidelity with a higher computational cost. This\napproach improves prediction accuracy by up to 11% over models trained on the\ntarget fidelity alone. Our approach boosts the throughput of XAS modeling by\norders of magnitude versus first-principles simulations and is extendable to\nXAS prediction for a broader range of elements. This transfer learning\nframework is generalizable to enhance deep-learning models that target other\nproperties in materials research.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "Main manuscript: 23 pages, 14 figures. Supplemental material (13\n  pages, 6 figures) available as a separate file in arXiv ancillary files\n  (additional downloadable files)",
    "pdf_url": "http://arxiv.org/pdf/2409.19552v3",
    "published_date": "2024-09-29 04:41:10 UTC",
    "updated_date": "2025-04-15 17:22:42 UTC"
  },
  {
    "arxiv_id": "2410.10834v1",
    "title": "Focus On What Matters: Separated Models For Visual-Based RL Generalization",
    "authors": [
      "Di Zhang",
      "Bowen Lv",
      "Hai Zhang",
      "Feifan Yang",
      "Junqiao Zhao",
      "Hang Yu",
      "Chang Huang",
      "Hongtu Zhou",
      "Chen Ye",
      "Changjun Jiang"
    ],
    "abstract": "A primary challenge for visual-based Reinforcement Learning (RL) is to\ngeneralize effectively across unseen environments. Although previous studies\nhave explored different auxiliary tasks to enhance generalization, few adopt\nimage reconstruction due to concerns about exacerbating overfitting to\ntask-irrelevant features during training. Perceiving the pre-eminence of image\nreconstruction in representation learning, we propose SMG (Separated Models for\nGeneralization), a novel approach that exploits image reconstruction for\ngeneralization. SMG introduces two model branches to extract task-relevant and\ntask-irrelevant representations separately from visual observations via\ncooperatively reconstruction. Built upon this architecture, we further\nemphasize the importance of task-relevant features for generalization.\nSpecifically, SMG incorporates two additional consistency losses to guide the\nagent's focus toward task-relevant areas across different scenarios, thereby\nachieving free from overfitting. Extensive experiments in DMC demonstrate the\nSOTA performance of SMG in generalization, particularly excelling in\nvideo-background settings. Evaluations on robotic manipulation tasks further\nconfirm the robustness of SMG in real-world applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10834v1",
    "published_date": "2024-09-29 04:37:56 UTC",
    "updated_date": "2024-09-29 04:37:56 UTC"
  },
  {
    "arxiv_id": "2410.03723v1",
    "title": "Human Bias in the Face of AI: The Role of Human Judgement in AI Generated Text Evaluation",
    "authors": [
      "Tiffany Zhu",
      "Iain Weissburg",
      "Kexun Zhang",
      "William Yang Wang"
    ],
    "abstract": "As AI advances in text generation, human trust in AI generated content\nremains constrained by biases that go beyond concerns of accuracy. This study\nexplores how bias shapes the perception of AI versus human generated content.\nThrough three experiments involving text rephrasing, news article\nsummarization, and persuasive writing, we investigated how human raters respond\nto labeled and unlabeled content. While the raters could not differentiate the\ntwo types of texts in the blind test, they overwhelmingly favored content\nlabeled as \"Human Generated,\" over those labeled \"AI Generated,\" by a\npreference score of over 30%. We observed the same pattern even when the labels\nwere deliberately swapped. This human bias against AI has broader societal and\ncognitive implications, as it undervalues AI performance. This study highlights\nthe limitations of human judgment in interacting with AI and offers a\nfoundation for improving human-AI collaboration, especially in creative fields.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.03723v1",
    "published_date": "2024-09-29 04:31:45 UTC",
    "updated_date": "2024-09-29 04:31:45 UTC"
  },
  {
    "arxiv_id": "2409.19546v4",
    "title": "Asymptotic and Finite Sample Analysis of Nonexpansive Stochastic Approximations with Markovian Noise",
    "authors": [
      "Ethan Blaser",
      "Shangtong Zhang"
    ],
    "abstract": "Stochastic approximation is an important class of algorithms, and a large\nbody of previous analysis focuses on stochastic approximations driven by\ncontractive operators, which is not applicable in some important reinforcement\nlearning settings. This work instead investigates stochastic approximations\nwith merely nonexpansive operators. In particular, we study nonexpansive\nstochastic approximations with Markovian noise, providing both asymptotic and\nfinite sample analysis. Key to our analysis are a few novel bounds of noise\nterms resulting from the Poisson equation. As an application, we prove, for the\nfirst time, that the classical tabular average reward temporal difference\nlearning converges to a sample path dependent fixed point.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19546v4",
    "published_date": "2024-09-29 04:16:24 UTC",
    "updated_date": "2025-02-03 22:14:27 UTC"
  },
  {
    "arxiv_id": "2410.12798v1",
    "title": "Design of an Efficient Fan-Shaped Clustered Trust-Based Routing Model with QoS & Security-Aware Side-Chaining for IoV Deployments",
    "authors": [
      "Sadaf Ravindra Suryawanshi",
      "Praveen Gupta"
    ],
    "abstract": "The rapid expansion of Internet of Vehicles (IoV) deployments has\nnecessitated the creation of efficient and secure routing models to manage the\nmassive data traffic generated by interconnected devices & vehicles. For IoV\ndeployments, we propose a novel fan-shaped trust-based routing model with\nQuality of Service (QoS) and security-aware side-chaining. Our method employs\ntemporal levels of delay, throughput, Packet Delivery Ratio (PDR), and energy\nconsumption to determine optimal routing paths, thereby ensuring efficient data\ntransmissions. We employ the Bacterial Foraging Optimizer (BFO) algorithm to\nmanage side-chains within the network, which dynamically adjusts side-chain\nconfigurations to optimize system performance. The technique of fan-shaped\nclustering is used to group nodes into efficient clusters, allowing for more\nefficient communication and resource utilization sets. Extensive\nexperimentation and performance analysis are utilized to evaluate the proposed\nmodel. Existing blockchain-based security models have been significantly\nimproved by our findings. Our model achieves a remarkable 9.5% reduction in\ndelay, a 10.5% improvement in throughput, a 2.9% improvement in PDR, and a 4.5%\nreduction in energy consumption compared to alternative approaches. In\naddition, we evaluate the model's resistance to Sybil, Masquerading, and\nFlooding attacks, which are prevalent security threats for IoV deployments.\nEven under these attack scenarios, our model provides consistently higher QoS\nlevels compared to existing solutions, ensuring uninterrupted and reliable data\ntransmissions. In IoV deployments, the proposed routing model and side-chaining\nmanagement approach have numerous applications and use-cases like Smart cities,\nindustrial automation, healthcare systems, transportation networks, and\nenvironmental monitoring.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "https://ijisae.org/index.php/IJISAE/article/view/3770",
    "pdf_url": "http://arxiv.org/pdf/2410.12798v1",
    "published_date": "2024-09-29 03:58:50 UTC",
    "updated_date": "2024-09-29 03:58:50 UTC"
  },
  {
    "arxiv_id": "2409.19541v3",
    "title": "Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization",
    "authors": [
      "Shahed Masoudian",
      "Markus Frohmann",
      "Navid Rekabsaz",
      "Markus Schedl"
    ],
    "abstract": "Language models frequently inherit societal biases from their training data.\nNumerous techniques have been proposed to mitigate these biases during both the\npre-training and fine-tuning stages. However, fine-tuning a pre-trained\ndebiased language model on a downstream task can reintroduce biases into the\nmodel. Additionally, existing debiasing methods for downstream tasks either (i)\nrequire labels of protected attributes (e.g., age, race, or political views)\nthat are often not available or (ii) rely on indicators of bias, which\nrestricts their applicability to gender debiasing since they rely on\ngender-specific words. To address this, we introduce a novel debiasing\nregularization technique based on the class-wise variance of embeddings.\nCrucially, our method does not require attribute labels and targets any\nattribute, thus addressing the shortcomings of existing debiasing methods. Our\nexperiments on encoder language models and three datasets demonstrate that our\nmethod outperforms existing strong debiasing baselines that rely on target\nattribute labels while maintaining performance on the target task.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.19541v3",
    "published_date": "2024-09-29 03:56:50 UTC",
    "updated_date": "2024-10-02 04:15:11 UTC"
  },
  {
    "arxiv_id": "2409.19531v1",
    "title": "Understanding Clinical Decision-Making in Traditional East Asian Medicine through Dimensionality Reduction: An Empirical Investigation",
    "authors": [
      "Hyojin Bae",
      "Bongsu Kang",
      "Chang-Eop Kim"
    ],
    "abstract": "This study examines the clinical decision-making processes in Traditional\nEast Asian Medicine (TEAM) by reinterpreting pattern identification (PI)\nthrough the lens of dimensionality reduction. Focusing on the Eight Principle\nPattern Identification (EPPI) system and utilizing empirical data from the\nShang-Han-Lun, we explore the necessity and significance of prioritizing the\nExterior-Interior pattern in diagnosis and treatment selection. We test three\nhypotheses: whether the Ext-Int pattern contains the most information about\npatient symptoms, represents the most abstract and generalizable symptom\ninformation, and facilitates the selection of appropriate herbal prescriptions.\nEmploying quantitative measures such as the abstraction index,\ncross-conditional generalization performance, and decision tree regression, our\nresults demonstrate that the Exterior-Interior pattern represents the most\nabstract and generalizable symptom information, contributing to the efficient\nmapping between symptom and herbal prescription spaces. This research provides\nan objective framework for understanding the cognitive processes underlying\nTEAM, bridging traditional medical practices with modern computational\napproaches. The findings offer insights into the development of AI-driven\ndiagnostic tools in TEAM and conventional medicine, with the potential to\nadvance clinical practice, education, and research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "J.3; I.2.1"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.19531v1",
    "published_date": "2024-09-29 03:28:19 UTC",
    "updated_date": "2024-09-29 03:28:19 UTC"
  },
  {
    "arxiv_id": "2409.19527v2",
    "title": "BuildingView: Constructing Urban Building Exteriors Databases with Street View Imagery and Multimodal Large Language Mode",
    "authors": [
      "Zongrong Li",
      "Yunlei Su",
      "Hongrong Wang",
      "Wufan Zhao"
    ],
    "abstract": "Urban Building Exteriors are increasingly important in urban analytics,\ndriven by advancements in Street View Imagery and its integration with urban\nresearch. Multimodal Large Language Models (LLMs) offer powerful tools for\nurban annotation, enabling deeper insights into urban environments. However,\nchallenges remain in creating accurate and detailed urban building exterior\ndatabases, identifying critical indicators for energy efficiency, environmental\nsustainability, and human-centric design, and systematically organizing these\nindicators. To address these challenges, we propose BuildingView, a novel\napproach that integrates high-resolution visual data from Google Street View\nwith spatial information from OpenStreetMap via the Overpass API. This research\nimproves the accuracy of urban building exterior data, identifies key\nsustainability and design indicators, and develops a framework for their\nextraction and categorization. Our methodology includes a systematic literature\nreview, building and Street View sampling, and annotation using the ChatGPT-4O\nAPI. The resulting database, validated with data from New York City, Amsterdam,\nand Singapore, provides a comprehensive tool for urban studies, supporting\ninformed decision-making in urban planning, architectural design, and\nenvironmental policy. The code for BuildingView is available at\nhttps://github.com/Jasper0122/BuildingView.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.19527v2",
    "published_date": "2024-09-29 03:00:16 UTC",
    "updated_date": "2025-03-07 03:06:50 UTC"
  },
  {
    "arxiv_id": "2409.19526v1",
    "title": "Efficient Backdoor Defense in Multimodal Contrastive Learning: A Token-Level Unlearning Method for Mitigating Threats",
    "authors": [
      "Kuanrong Liu",
      "Siyuan Liang",
      "Jiawei Liang",
      "Pengwen Dai",
      "Xiaochun Cao"
    ],
    "abstract": "Multimodal contrastive learning uses various data modalities to create\nhigh-quality features, but its reliance on extensive data sources on the\nInternet makes it vulnerable to backdoor attacks. These attacks insert\nmalicious behaviors during training, which are activated by specific triggers\nduring inference, posing significant security risks. Despite existing\ncountermeasures through fine-tuning that reduce the malicious impacts of such\nattacks, these defenses frequently necessitate extensive training time and\ndegrade clean accuracy. In this study, we propose an efficient defense\nmechanism against backdoor threats using a concept known as machine unlearning.\nThis entails strategically creating a small set of poisoned samples to aid the\nmodel's rapid unlearning of backdoor vulnerabilities, known as Unlearn Backdoor\nThreats (UBT). We specifically use overfit training to improve backdoor\nshortcuts and accurately detect suspicious samples in the potential poisoning\ndata set. Then, we select fewer unlearned samples from suspicious samples for\nrapid forgetting in order to eliminate the backdoor effect and thus improve\nbackdoor defense efficiency. In the backdoor unlearning process, we present a\nnovel token-based portion unlearning training regime. This technique focuses on\nthe model's compromised elements, dissociating backdoor correlations while\nmaintaining the model's overall integrity. Extensive experimental results show\nthat our method effectively defends against various backdoor attack methods in\nthe CLIP model. Compared to SoTA backdoor defense methods, UBT achieves the\nlowest attack success rate while maintaining a high clean accuracy of the model\n(attack success rate decreases by 19% compared to SOTA, while clean accuracy\nincreases by 2.57%).",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19526v1",
    "published_date": "2024-09-29 02:55:38 UTC",
    "updated_date": "2024-09-29 02:55:38 UTC"
  },
  {
    "arxiv_id": "2409.19518v1",
    "title": "KODA: A Data-Driven Recursive Model for Time Series Forecasting and Data Assimilation using Koopman Operators",
    "authors": [
      "Ashutosh Singh",
      "Ashish Singh",
      "Tales Imbiriba",
      "Deniz Erdogmus",
      "Ricardo Borsoi"
    ],
    "abstract": "Approaches based on Koopman operators have shown great promise in forecasting\ntime series data generated by complex nonlinear dynamical systems (NLDS).\nAlthough such approaches are able to capture the latent state representation of\na NLDS, they still face difficulty in long term forecasting when applied to\nreal world data. Specifically many real-world NLDS exhibit time-varying\nbehavior, leading to nonstationarity that is hard to capture with such models.\nFurthermore they lack a systematic data-driven approach to perform data\nassimilation, that is, exploiting noisy measurements on the fly in the\nforecasting task. To alleviate the above issues, we propose a Koopman\noperator-based approach (named KODA - Koopman Operator with Data Assimilation)\nthat integrates forecasting and data assimilation in NLDS. In particular we use\na Fourier domain filter to disentangle the data into a physical component whose\ndynamics can be accurately represented by a Koopman operator, and residual\ndynamics that represents the local or time varying behavior that are captured\nby a flexible and learnable recursive model. We carefully design an\narchitecture and training criterion that ensures this decomposition lead to\nstable and long-term forecasts. Moreover, we introduce a course correction\nstrategy to perform data assimilation with new measurements at inference time.\nThe proposed approach is completely data-driven and can be learned end-to-end.\nThrough extensive experimental comparisons we show that KODA outperforms\nexisting state of the art methods on multiple time series benchmarks such as\nelectricity, temperature, weather, lorenz 63 and duffing oscillator\ndemonstrating its superior performance and efficacy along the three tasks a)\nforecasting, b) data assimilation and c) state prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19518v1",
    "published_date": "2024-09-29 02:25:48 UTC",
    "updated_date": "2024-09-29 02:25:48 UTC"
  },
  {
    "arxiv_id": "2409.19513v1",
    "title": "One Node Per User: Node-Level Federated Learning for Graph Neural Networks",
    "authors": [
      "Zhidong Gao",
      "Yuanxiong Guo",
      "Yanmin Gong"
    ],
    "abstract": "Graph Neural Networks (GNNs) training often necessitates gathering raw user\ndata on a central server, which raises significant privacy concerns. Federated\nlearning emerges as a solution, enabling collaborative model training without\nusers directly sharing their raw data. However, integrating federated learning\nwith GNNs presents unique challenges, especially when a client represents a\ngraph node and holds merely a single feature vector. In this paper, we propose\na novel framework for node-level federated graph learning. Specifically, we\ndecouple the message-passing and feature vector transformation processes of the\nfirst GNN layer, allowing them to be executed separately on the user devices\nand the cloud server. Moreover, we introduce a graph Laplacian term based on\nthe feature vector's latent representation to regulate the user-side model\nupdates. The experiment results on multiple datasets show that our approach\nachieves better performance compared with baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.19513v1",
    "published_date": "2024-09-29 02:16:07 UTC",
    "updated_date": "2024-09-29 02:16:07 UTC"
  },
  {
    "arxiv_id": "2410.10833v1",
    "title": "Online Client Scheduling and Resource Allocation for Efficient Federated Edge Learning",
    "authors": [
      "Zhidong Gao",
      "Zhenxiao Zhang",
      "Yu Zhang",
      "Tongnian Wang",
      "Yanmin Gong",
      "Yuanxiong Guo"
    ],
    "abstract": "Federated learning (FL) enables edge devices to collaboratively train a\nmachine learning model without sharing their raw data. Due to its\nprivacy-protecting benefits, FL has been deployed in many real-world\napplications. However, deploying FL over mobile edge networks with constrained\nresources such as power, bandwidth, and computation suffers from high training\nlatency and low model accuracy, particularly under data and system\nheterogeneity. In this paper, we investigate the optimal client scheduling and\nresource allocation for FL over mobile edge networks under resource constraints\nand uncertainty to minimize the training latency while maintaining the model\naccuracy. Specifically, we first analyze the impact of client sampling on model\nconvergence in FL and formulate a stochastic optimization problem that captures\nthe trade-off between the running time and model performance under\nheterogeneous and uncertain system resources. To solve the formulated problem,\nwe further develop an online control scheme based on Lyapunov-based\noptimization for client sampling and resource allocation without requiring the\nknowledge of future dynamics in the FL system. Extensive experimental results\ndemonstrate that the proposed scheme can improve both the training latency and\nresource efficiency compared with the existing schemes.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10833v1",
    "published_date": "2024-09-29 01:56:45 UTC",
    "updated_date": "2024-09-29 01:56:45 UTC"
  },
  {
    "arxiv_id": "2409.19509v1",
    "title": "Heterogeneity-Aware Resource Allocation and Topology Design for Hierarchical Federated Edge Learning",
    "authors": [
      "Zhidong Gao",
      "Yu Zhang",
      "Yanmin Gong",
      "Yuanxiong Guo"
    ],
    "abstract": "Federated Learning (FL) provides a privacy-preserving framework for training\nmachine learning models on mobile edge devices. Traditional FL algorithms,\ne.g., FedAvg, impose a heavy communication workload on these devices. To\nmitigate this issue, Hierarchical Federated Edge Learning (HFEL) has been\nproposed, leveraging edge servers as intermediaries for model aggregation.\nDespite its effectiveness, HFEL encounters challenges such as a slow\nconvergence rate and high resource consumption, particularly in the presence of\nsystem and data heterogeneity. However, existing works are mainly focused on\nimproving training efficiency for traditional FL, leaving the efficiency of\nHFEL largely unexplored. In this paper, we consider a two-tier HFEL system,\nwhere edge devices are connected to edge servers and edge servers are\ninterconnected through peer-to-peer (P2P) edge backhauls. Our goal is to\nenhance the training efficiency of the HFEL system through strategic resource\nallocation and topology design. Specifically, we formulate an optimization\nproblem to minimize the total training latency by allocating the computation\nand communication resources, as well as adjusting the P2P connections. To\nensure convergence under dynamic topologies, we analyze the convergence error\nbound and introduce a model consensus constraint into the optimization problem.\nThe proposed problem is then decomposed into several subproblems, enabling us\nto alternatively solve it online. Our method facilitates the efficient\nimplementation of large-scale FL at edge networks under data and system\nheterogeneity. Comprehensive experiment evaluation on benchmark datasets\nvalidates the effectiveness of the proposed method, demonstrating significant\nreductions in training latency while maintaining the model accuracy compared to\nvarious baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.19509v1",
    "published_date": "2024-09-29 01:48:04 UTC",
    "updated_date": "2024-09-29 01:48:04 UTC"
  },
  {
    "arxiv_id": "2409.19501v1",
    "title": "Learning Frame-Wise Emotion Intensity for Audio-Driven Talking-Head Generation",
    "authors": [
      "Jingyi Xu",
      "Hieu Le",
      "Zhixin Shu",
      "Yang Wang",
      "Yi-Hsuan Tsai",
      "Dimitris Samaras"
    ],
    "abstract": "Human emotional expression is inherently dynamic, complex, and fluid,\ncharacterized by smooth transitions in intensity throughout verbal\ncommunication. However, the modeling of such intensity fluctuations has been\nlargely overlooked by previous audio-driven talking-head generation methods,\nwhich often results in static emotional outputs. In this paper, we explore how\nemotion intensity fluctuates during speech, proposing a method for capturing\nand generating these subtle shifts for talking-head generation. Specifically,\nwe develop a talking-head framework that is capable of generating a variety of\nemotions with precise control over intensity levels. This is achieved by\nlearning a continuous emotion latent space, where emotion types are encoded\nwithin latent orientations and emotion intensity is reflected in latent norms.\nIn addition, to capture the dynamic intensity fluctuations, we adopt an\naudio-to-intensity predictor by considering the speaking tone that reflects the\nintensity. The training signals for this predictor are obtained through our\nemotion-agnostic intensity pseudo-labeling method without the need of\nframe-wise intensity labeling. Extensive experiments and analyses validate the\neffectiveness of our proposed method in accurately capturing and reproducing\nemotion intensity fluctuations in talking-head generation, thereby\nsignificantly enhancing the expressiveness and realism of the generated\noutputs.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19501v1",
    "published_date": "2024-09-29 01:02:01 UTC",
    "updated_date": "2024-09-29 01:02:01 UTC"
  },
  {
    "arxiv_id": "2410.05284v1",
    "title": "Psychometrics for Hypnopaedia-Aware Machinery via Chaotic Projection of Artificial Mental Imagery",
    "authors": [
      "Ching-Chun Chang",
      "Kai Gao",
      "Shuying Xu",
      "Anastasia Kordoni",
      "Christopher Leckie",
      "Isao Echizen"
    ],
    "abstract": "Neural backdoors represent insidious cybersecurity loopholes that render\nlearning machinery vulnerable to unauthorised manipulations, potentially\nenabling the weaponisation of artificial intelligence with catastrophic\nconsequences. A backdoor attack involves the clandestine infiltration of a\ntrigger during the learning process, metaphorically analogous to hypnopaedia,\nwhere ideas are implanted into a subject's subconscious mind under the state of\nhypnosis or unconsciousness. When activated by a sensory stimulus, the trigger\nevokes conditioned reflex that directs a machine to mount a predetermined\nresponse. In this study, we propose a cybernetic framework for constant\nsurveillance of backdoors threats, driven by the dynamic nature of\nuntrustworthy data sources. We develop a self-aware unlearning mechanism to\nautonomously detach a machine's behaviour from the backdoor trigger. Through\nreverse engineering and statistical inference, we detect deceptive patterns and\nestimate the likelihood of backdoor infection. We employ model inversion to\nelicit artificial mental imagery, using stochastic processes to disrupt\noptimisation pathways and avoid convergent but potentially flawed patterns.\nThis is followed by hypothesis analysis, which estimates the likelihood of each\npotentially malicious pattern being the true trigger and infers the probability\nof infection. The primary objective of this study is to maintain a stable state\nof equilibrium between knowledge fidelity and backdoor vulnerability.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05284v1",
    "published_date": "2024-09-29 00:59:26 UTC",
    "updated_date": "2024-09-29 00:59:26 UTC"
  },
  {
    "arxiv_id": "2409.19492v1",
    "title": "MedHalu: Hallucinations in Responses to Healthcare Queries by Large Language Models",
    "authors": [
      "Vibhor Agarwal",
      "Yiqiao Jin",
      "Mohit Chandra",
      "Munmun De Choudhury",
      "Srijan Kumar",
      "Nishanth Sastry"
    ],
    "abstract": "The remarkable capabilities of large language models (LLMs) in language\nunderstanding and generation have not rendered them immune to hallucinations.\nLLMs can still generate plausible-sounding but factually incorrect or\nfabricated information. As LLM-empowered chatbots become popular, laypeople may\nfrequently ask health-related queries and risk falling victim to these LLM\nhallucinations, resulting in various societal and healthcare implications. In\nthis work, we conduct a pioneering study of hallucinations in LLM-generated\nresponses to real-world healthcare queries from patients. We propose MedHalu, a\ncarefully crafted first-of-its-kind medical hallucination dataset with a\ndiverse range of health-related topics and the corresponding hallucinated\nresponses from LLMs with labeled hallucination types and hallucinated text\nspans. We also introduce MedHaluDetect framework to evaluate capabilities of\nvarious LLMs in detecting hallucinations. We also employ three groups of\nevaluators -- medical experts, LLMs, and laypeople -- to study who are more\nvulnerable to these medical hallucinations. We find that LLMs are much worse\nthan the experts. They also perform no better than laypeople and even worse in\nfew cases in detecting hallucinations. To fill this gap, we propose\nexpert-in-the-loop approach to improve hallucination detection through LLMs by\ninfusing expert reasoning. We observe significant performance gains for all the\nLLMs with an average macro-F1 improvement of 6.3 percentage points for GPT-4.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.19492v1",
    "published_date": "2024-09-29 00:09:01 UTC",
    "updated_date": "2024-09-29 00:09:01 UTC"
  }
]