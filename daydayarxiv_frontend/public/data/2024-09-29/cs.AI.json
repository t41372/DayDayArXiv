{
  "date": "2024-09-29",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-29 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于人工智能、机器学习和量子计算等领域，强调模型泛化、知识编辑和医疗应用等关键话题。其中，令人印象深刻的包括 LLM 在任务泛化和图分析中的创新进展，以及知名学者如 Chelsea Finn 和 Zhiyuan Liu 的作品，这些论文展示了 AI 在实际应用中的潜力，同时涉及安全性和效率优化。\n\n下面，我挑选并简要讨论了今日更新的论文，先从重要性和话题度高的入手（如 LLM 相关和量子计算），再快速掠过其他次要内容。每篇论文会列出标题（中文 + 英文），并突出核心贡献和发现。\n\n### 重点论文讨论\n\n**1. Calibrating Language Models with Adaptive Temperature Scaling（校准语言模型的自适应温度缩放）**  \n这篇论文由 Eric Mitchell 和 Chelsea Finn 等知名学者撰写，针对大型语言模型（LLMs）在强化学习微调后校准性能下降的问题，提出 Adaptive Temperature Scaling（ATS）方法。该方法通过预测每个标记的温度参数来提升模型置信度校准，实验显示在多个基准上改善校准效果 10-50%，而不影响整体性能，是 LLM 应用中的重要进展。\n\n**2. Can Models Learn Skill Composition from Examples?（模型是否能从示例中学习技能组合）**  \n作者包括 Sanjeev Arora，探讨 LLMs 的组合泛化能力。论文通过 SKILL-MIX 评估和微调实验，发现小模型在训练时学习 k=2-3 技能后，能泛化到 k=4-5 的新组合，甚至处理未见技能。该发现为 AI 安全和任务适应提供洞见，强调合成数据的潜力。\n\n**3. Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models（大型语言模型是否能像专业人士一样分析图数据？基准、数据集和模型）**  \nZhiyuan Liu 和 Cheng Yang 等作者构建 ProGraph 基准，评估 LLMs 在图分析任务中的性能。论文引入 LLM4Graph 数据集，通过检索和微调提升模型准确性，实验显示性能提升 11-32%，为 LLMs 处理结构化数据（如图神经网络）开辟新路径，具有高话题度。\n\n**4. One Token to Seg Them All: Language Instructed Reasoning Segmentation in Videos（一个标记统领所有：基于语言指令的视频推理分割）**  \nNeurIPS 接受的论文，提出 VideoLISA 框架，使用稀疏密集采样和追踪标记处理视频分割。核心贡献是生成时间一致的分割掩码，实验在 ReasonVOS 等基准上超越基线，展示了多模态 LLM 在视频理解中的潜力。\n\n**5. Generalizability of Graph Neural Networks for Decentralized Unlabeled Motion Planning（图神经网络在去中心化无标签运动规划中的泛化性）**  \n作者包括 Alejandro Ribeiro，聚焦多机器人系统。论文提出基于 GNN 的去中心化策略，通过模仿学习和强化学习优化机器人决策，实验显示在 500 机器人场景下性能提升 8.6%，为多机器人协调提供可扩展解决方案。\n\n**6. OrganiQ: Mitigating Classical Resource Bottlenecks of Quantum Generative Adversarial Networks on NISQ-Era Machines（OrganiQ：缓解 NISQ 时代量子生成对抗网络的经典资源瓶颈）**  \nTirthak Patel 等作者首次提出无需经典神经网络的量子 GAN，生成高质量图像。核心发现是减少资源依赖，提升量子图像生成潜力，为量子机器学习应用奠定基础。\n\n**7. Qompose: A Technique to Select Optimal Algorithm-Specific Layout for Neutral Atom Quantum Architectures（Qompose：为中性原子量子架构选择最优算法特定布局的技术）**  \n同上作者团队，提出 Qompose 框架优化量子电路拓扑。论文通过评估随机电路和基准（如 VQE 和 QAOA），提升执行效率和保真度，展示量子计算在实际部署中的实用性。\n\n**8. See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning（详见明说：基于病理线索驱动表示学习的脑 CT 报告生成）**  \nEMNLP 接受，作者 Liangqiong Qu 提出 PCRL 模型，使用病理线索（如分割区域和实体）构建跨模态表示，并结合大语言模型生成报告。实验在医疗基准上达到 SOTA，提升报告准确性和连贯性。\n\n**9. InfantCryNet: A Data-Driven Framework for Intelligent Analysis of Infant Cries（InfantCryNet：婴儿哭声智能分析的数据驱动框架）**  \n作者包括 Di Jiang，针对婴儿哭声检测和原因分析，提出预训练模型结合统计池化和知识蒸馏。核心贡献是提升分类准确性 4.4%，并实现模型压缩，支持移动部署。\n\n### 其他论文快速掠过\n今日还有大量论文，如 **Grounded Curriculum Learning（基于真实任务分布的强化学习课程设计）** 和 **Adaptive Event-triggered Reinforcement Learning Control（自适应事件触发强化学习控制）** 等，分别优化机器人导航和非线性系统控制，但这些相对常规；**Analysis on Riemann Hypothesis（Riemann 假设的分析）** 等数学理论论文虽有趣，但影响力有限；医疗和图学习相关如 **Machine Learning for Raman Spectroscopy-based Cyber-Marine Fish Biochemical Composition Analysis（基于拉曼光谱的鱼生化成分分析）** 和 **A Survey on Graph Neural Networks for Remaining Useful Life Prediction（图神经网络在剩余寿命预测中的调查）**，提供了综述和基准，但未有突破性创新。总体而言，这些论文强化了 AI 在特定领域的应用，但未如上述重点论文般引人注目。\n\n今天的 arXiv 更新展示了 AI 领域的多样性，LLM 和量子计算尤其值得关注。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2409.19829v1",
      "title": "Generalizability of Graph Neural Networks for Decentralized Unlabeled Motion Planning",
      "title_zh": "图",
      "authors": [
        "Shreyas Muthusamy",
        "Damian Owerko",
        "Charilaos I. Kanatsoulis",
        "Saurav Agarwal",
        "Alejandro Ribeiro"
      ],
      "abstract": "Unlabeled motion planning involves assigning a set of robots to target\nlocations while ensuring collision avoidance, aiming to minimize the total\ndistance traveled. The problem forms an essential building block for\nmulti-robot systems in applications such as exploration, surveillance, and\ntransportation. We address this problem in a decentralized setting where each\nrobot knows only the positions of its $k$-nearest robots and $k$-nearest\ntargets. This scenario combines elements of combinatorial assignment and\ncontinuous-space motion planning, posing significant scalability challenges for\ntraditional centralized approaches. To overcome these challenges, we propose a\ndecentralized policy learned via a Graph Neural Network (GNN). The GNN enables\nrobots to determine (1) what information to communicate to neighbors and (2)\nhow to integrate received information with local observations for\ndecision-making. We train the GNN using imitation learning with the centralized\nHungarian algorithm as the expert policy, and further fine-tune it using\nreinforcement learning to avoid collisions and enhance performance. Extensive\nempirical evaluations demonstrate the scalability and effectiveness of our\napproach. The GNN policy trained on 100 robots generalizes to scenarios with up\nto 500 robots, outperforming state-of-the-art solutions by 8.6\\% on average and\nsignificantly surpassing greedy decentralized methods. This work lays the\nfoundation for solving multi-robot coordination problems in settings where\nscalability is important.",
      "tldr_zh": "本研究探讨了无标签运动规划问题，即在去中心化设置中，让多机器人分配到目标位置、避免碰撞并最小化总距离。作者提出了一种基于 Graph Neural Network (GNN) 的去中心化策略，允许每个机器人仅通过通信 k-最近邻信息并整合本地观察进行决策，并通过 imitation learning（以 Hungarian algorithm 为专家策略）结合 reinforcement learning 进行训练。实验结果显示，该 GNN 策略在 100 个机器人上训练后，可泛化到 500 个机器人场景，比最先进方法平均提升 8.6%，并显著优于贪婪去中心化方法。该工作为可扩展的多机器人协调问题奠定了基础。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 6 figures, submitted to ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.19829v1",
      "published_date": "2024-09-29 23:57:25 UTC",
      "updated_date": "2024-09-29 23:57:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:58:42.590165"
    },
    {
      "arxiv_id": "2409.19824v1",
      "title": "Counterfactual Evaluation of Ads Ranking Models through Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed A. Radwan",
        "Himaghna Bhattacharjee",
        "Quinn Lanners",
        "Jiasheng Zhang",
        "Serkan Karakulak",
        "Houssam Nassif",
        "Murat Ali Bayir"
      ],
      "abstract": "We propose a domain-adapted reward model that works alongside an Offline A/B\ntesting system for evaluating ranking models. This approach effectively\nmeasures reward for ranking model changes in large-scale Ads recommender\nsystems, where model-free methods like IPS are not feasible. Our experiments\ndemonstrate that the proposed technique outperforms both the vanilla IPS method\nand approaches using non-generalized reward models.",
      "tldr_zh": "该研究提出了一种基于 Domain Adaptation 的 reward model，与 Offline A/B testing 系统结合，用于评估大型 Ads recommender systems 中的排名模型变化。这种方法有效测量模型调整的奖励，尤其在 model-free 方法如 IPS 不适用的场景下。实验结果显示，该技术优于 vanilla IPS 方法和非通用化奖励模型的方法。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "H.3.3; I.2.6"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at the CONSEQUENCES'24 workshop, co-located with ACM\n  RecSys'24",
      "pdf_url": "http://arxiv.org/pdf/2409.19824v1",
      "published_date": "2024-09-29 23:12:04 UTC",
      "updated_date": "2024-09-29 23:12:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:58:54.517921"
    },
    {
      "arxiv_id": "2409.19823v1",
      "title": "OrganiQ: Mitigating Classical Resource Bottlenecks of Quantum Generative Adversarial Networks on NISQ-Era Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Silver",
        "Tirthak Patel",
        "Aditya Ranjan",
        "William Cutler",
        "Devesh Tiwari"
      ],
      "abstract": "Driven by swift progress in hardware capabilities, quantum machine learning\nhas emerged as a research area of interest. Recently, quantum image generation\nhas produced promising results. However, prior quantum image generation\ntechniques rely on classical neural networks, limiting their quantum potential\nand image quality. To overcome this, we introduce OrganiQ, the first quantum\nGAN capable of producing high-quality images without using classical neural\nnetworks.",
      "tldr_zh": "随着量子硬件的快速发展，量子机器学习领域备受关注，但现有的量子图像生成技术依赖经典神经网络，导致量子潜力和图像质量受限。针对这一问题，本文提出 OrganiQ，这是一个不依赖经典神经网络的量子 GAN（Quantum Generative Adversarial Networks），旨在在 NISQ-Era Machines 上缓解资源瓶颈。实验结果表明，OrganiQ 能够生成高质量图像，提升了量子图像生成的整体性能。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19823v1",
      "published_date": "2024-09-29 23:11:35 UTC",
      "updated_date": "2024-09-29 23:11:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:59:06.131530"
    },
    {
      "arxiv_id": "2409.19820v1",
      "title": "Qompose: A Technique to Select Optimal Algorithm- Specific Layout for Neutral Atom Quantum Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Silver",
        "Tirthak Patel",
        "Devesh Tiwari"
      ],
      "abstract": "As quantum computing architecture matures, it is important to investigate new\ntechnologies that lend unique advantages. In this work, we propose, Qompose, a\nneutral atom quantum computing framework for efficiently composing quantum\ncircuits on 2-D topologies of neutral atoms. Qompose selects an efficient\ntopology for any given circuit in order to optimize for length of execution\nthrough efficient parallelism and for overall fidelity. our extensive\nevaluation demonstrates the Qompose is effective for a large collection of\nrandomly-generated quantum circuits and a range of real-world benchmarks\nincluding VQE, ISING, and QAOA.",
      "tldr_zh": "这篇论文提出了 Qompose，一种针对中性原子量子架构的技术，用于选择算法特定的最优布局，以高效组合量子电路并优化执行长度和整体保真度。Qompose 通过在 2-D 拓扑上实现高效并行性，适用于各种量子电路设计。实验结果显示，该框架在大量随机生成的量子电路以及真实基准如 VQE、ISING 和 QAOA 上表现出色。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19820v1",
      "published_date": "2024-09-29 23:03:08 UTC",
      "updated_date": "2024-09-29 23:03:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:59:21.704017"
    },
    {
      "arxiv_id": "2409.19817v1",
      "title": "Calibrating Language Models with Adaptive Temperature Scaling",
      "title_zh": "翻译失败",
      "authors": [
        "Johnathan Xie",
        "Annie S. Chen",
        "Yoonho Lee",
        "Eric Mitchell",
        "Chelsea Finn"
      ],
      "abstract": "The effectiveness of large language models (LLMs) is not only measured by\ntheir ability to generate accurate outputs but also by their calibration-how\nwell their confidence scores reflect the probability of their outputs being\ncorrect. While unsupervised pre-training has been shown to yield LLMs with\nwell-calibrated conditional probabilities, recent studies have shown that after\nfine-tuning with reinforcement learning from human feedback (RLHF), the\ncalibration of these models degrades significantly. In this work, we introduce\nAdaptive Temperature Scaling (ATS), a post-hoc calibration method that predicts\na temperature scaling parameter for each token prediction. The predicted\ntemperature values adapt based on token-level features and are fit over a\nstandard supervised fine-tuning (SFT) dataset. The adaptive nature of ATS\naddresses the varying degrees of calibration shift that can occur after RLHF\nfine-tuning. ATS improves calibration by over 10-50% across three downstream\nnatural language evaluation benchmarks compared to prior calibration methods\nand does not impede performance improvements from RLHF.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在经过强化学习从人类反馈（RLHF）微调后，校准性能显著下降的问题，提出了一种后处理方法Adaptive Temperature Scaling (ATS)。ATS通过预测每个token预测的温度缩放参数，并基于token级特征在标准监督微调（SFT）数据集上进行拟合，从而适应RLHF引发的不同校准偏移。实验结果显示，ATS在三个下游自然语言评估基准上比现有方法提高了10-50%的校准性能，同时不影响RLHF带来的整体性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.19817v1",
      "published_date": "2024-09-29 22:54:31 UTC",
      "updated_date": "2024-09-29 22:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:59:29.940717"
    },
    {
      "arxiv_id": "2409.19816v1",
      "title": "Grounded Curriculum Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Linji Wang",
        "Zifan Xu",
        "Peter Stone",
        "Xuesu Xiao"
      ],
      "abstract": "The high cost of real-world data for robotics Reinforcement Learning (RL)\nleads to the wide usage of simulators. Despite extensive work on building\nbetter dynamics models for simulators to match with the real world, there is\nanother, often-overlooked mismatch between simulations and the real world,\nnamely the distribution of available training tasks. Such a mismatch is further\nexacerbated by existing curriculum learning techniques, which automatically\nvary the simulation task distribution without considering its relevance to the\nreal world. Considering these challenges, we posit that curriculum learning for\nrobotics RL needs to be grounded in real-world task distributions. To this end,\nwe propose Grounded Curriculum Learning (GCL), which aligns the simulated task\ndistribution in the curriculum with the real world, as well as explicitly\nconsiders what tasks have been given to the robot and how the robot has\nperformed in the past. We validate GCL using the BARN dataset on complex\nnavigation tasks, achieving a 6.8% and 6.5% higher success rate compared to a\nstate-of-the-art CL method and a curriculum designed by human experts,\nrespectively. These results show that GCL can enhance learning efficiency and\nnavigation performance by grounding the simulation task distribution in the\nreal world within an adaptive curriculum.",
      "tldr_zh": "该研究指出，机器人强化学习(Reinforcement Learning, RL)中模拟器与真实世界任务分布的不匹配问题常被忽略，且现有课程学习(Curriculum Learning)方法进一步加剧了这一问题。论文提出Grounded Curriculum Learning (GCL)方法，通过将模拟任务分布与真实世界对齐，并考虑机器人过去执行的任务和表现，来提升学习效率。实验在BARN数据集的复杂导航任务上验证了GCL，比最先进的方法和专家设计的课程分别提高了6.8%和6.5%的成功率，从而证明了GCL在提升机器人导航性能方面的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.19816v1",
      "published_date": "2024-09-29 22:54:08 UTC",
      "updated_date": "2024-09-29 22:54:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:59:41.411755"
    },
    {
      "arxiv_id": "2409.19808v2",
      "title": "Can Models Learn Skill Composition from Examples?",
      "title_zh": "模型能否从例子中学习技能组合？",
      "authors": [
        "Haoyu Zhao",
        "Simran Kaur",
        "Dingli Yu",
        "Anirudh Goyal",
        "Sanjeev Arora"
      ],
      "abstract": "As large language models (LLMs) become increasingly advanced, their ability\nto exhibit compositional generalization -- the capacity to combine learned\nskills in novel ways not encountered during training -- has garnered\nsignificant attention. This type of generalization, particularly in scenarios\nbeyond training data, is also of great interest in the study of AI safety and\nalignment. A recent study introduced the SKILL-MIX evaluation, where models are\ntasked with composing a short paragraph demonstrating the use of a specified\n$k$-tuple of language skills. While small models struggled with composing even\nwith $k=3$, larger models like GPT-4 performed reasonably well with $k=5$ and\n$6$.\n  In this paper, we employ a setup akin to SKILL-MIX to evaluate the capacity\nof smaller models to learn compositional generalization from examples.\nUtilizing a diverse set of language skills -- including rhetorical, literary,\nreasoning, theory of mind, and common sense -- GPT-4 was used to generate text\nsamples that exhibit random subsets of $k$ skills. Subsequent fine-tuning of 7B\nand 13B parameter models on these combined skill texts, for increasing values\nof $k$, revealed the following findings: (1) Training on combinations of $k=2$\nand $3$ skills results in noticeable improvements in the ability to compose\ntexts with $k=4$ and $5$ skills, despite models never having seen such examples\nduring training. (2) When skill categories are split into training and held-out\ngroups, models significantly improve at composing texts with held-out skills\nduring testing despite having only seen training skills during fine-tuning,\nillustrating the efficacy of the training approach even with previously unseen\nskills. This study also suggests that incorporating skill-rich (potentially\nsynthetic) text into training can substantially enhance the compositional\ncapabilities of models.",
      "tldr_zh": "这篇论文探讨大型语言模型 (LLMs) 是否能从示例中学习技能组合泛化，即在训练中未见过的方式下组合语言技能。作者采用类似 SKILL-MIX 的评估框架，使用 GPT-4 生成展示随机 k 技能子集的文本样本，对 7B 和 13B 参数模型进行微调。结果显示，训练于 k=2 和 3 技能组合的模型，能显著改善 k=4 和 5 技能的生成表现，甚至处理训练中未见的技能类别。研究表明，融入技能丰富的（可能合成）文本可大幅提升模型的组合泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.19808v2",
      "published_date": "2024-09-29 22:14:02 UTC",
      "updated_date": "2025-01-19 02:31:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T04:59:55.364891"
    },
    {
      "arxiv_id": "2409.19806v1",
      "title": "PALM: Few-Shot Prompt Learning for Audio Language Models",
      "title_zh": "PALM：音频语言模型的少样本提示学习",
      "authors": [
        "Asif Hanif",
        "Maha Tufail Agro",
        "Mohammad Areeb Qazi",
        "Hanan Aldarmaki"
      ],
      "abstract": "Audio-Language Models (ALMs) have recently achieved remarkable success in\nzero-shot audio recognition tasks, which match features of audio waveforms with\nclass-specific text prompt features, inspired by advancements in\nVision-Language Models (VLMs). Given the sensitivity of zero-shot performance\nto the choice of hand-crafted text prompts, many prompt learning techniques\nhave been developed for VLMs. We explore the efficacy of these approaches in\nALMs and propose a novel method, Prompt Learning in Audio Language Models\n(PALM), which optimizes the feature space of the text encoder branch. Unlike\nexisting methods that work in the input space, our approach results in greater\ntraining efficiency. We demonstrate the effectiveness of our approach on 11\naudio recognition datasets, encompassing a variety of speech-processing tasks,\nand compare the results with three baselines in a few-shot learning setup. Our\nmethod is either on par with or outperforms other approaches while being\ncomputationally less demanding. Code is available at\nhttps://asif-hanif.github.io/palm/",
      "tldr_zh": "该论文提出 PALM（Prompt Learning in Audio Language Models）方法，用于 Audio-Language Models (ALMs) 的少样本学习场景，旨在优化文本编码器的特征空间以提升提示学习的效率。不同于现有方法在输入空间的操作，PALM 通过特征空间优化减少了计算需求，并在 11 个音频识别数据集上进行了测试。实验结果显示，PALM 在 Few-Shot Learning 设置中与基线方法相当或更优，为 ALMs 在语音处理任务中的应用提供了更高效的解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "EMNLP 2024 (Main)",
      "pdf_url": "http://arxiv.org/pdf/2409.19806v1",
      "published_date": "2024-09-29 22:06:07 UTC",
      "updated_date": "2024-09-29 22:06:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:00:07.750700"
    },
    {
      "arxiv_id": "2409.19801v2",
      "title": "CRScore: Grounding Automated Evaluation of Code Review Comments in Code Claims and Smells",
      "title_zh": "翻译失败",
      "authors": [
        "Atharva Naik",
        "Marcus Alenius",
        "Daniel Fried",
        "Carolyn Rose"
      ],
      "abstract": "The task of automated code review has recently gained a lot of attention from\nthe machine learning community. However, current review comment evaluation\nmetrics rely on comparisons with a human-written reference for a given code\nchange (also called a diff). Furthermore, code review is a one-to-many problem,\nlike generation and summarization, with many \"valid reviews\" for a diff. Thus,\nwe develop CRScore - a reference-free metric to measure dimensions of review\nquality like conciseness, comprehensiveness, and relevance. We design CRScore\nto evaluate reviews in a way that is grounded in claims and potential issues\ndetected in the code by LLMs and static analyzers. We demonstrate that CRScore\ncan produce valid, fine-grained scores of review quality that have the greatest\nalignment with human judgment among open source metrics (0.54 Spearman\ncorrelation) and are more sensitive than reference-based metrics. We also\nrelease a corpus of 2.9k human-annotated review quality scores for\nmachine-generated and GitHub review comments to support the development of\nautomated metrics.",
      "tldr_zh": "该研究开发了CRScore，一种无参考的代码审查评论评估指标，旨在衡量评论的简洁性、全面性和相关性。\nCRScore通过将评估 grounding 在LLMs和静态分析器检测的代码声明（code claims）和潜在问题（code smells）上，实现对代码审查的细粒度评估。\n实验结果表明，CRScore与人类判断的相关性最高（Spearman相关性0.54），并比基于参考的指标更敏感。\n此外，论文发布了一个包含2.9k人类标注的审查质量分数语料库，以支持自动化代码审查指标的进一步发展。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19801v2",
      "published_date": "2024-09-29 21:53:18 UTC",
      "updated_date": "2025-03-16 18:22:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:00:22.411372"
    },
    {
      "arxiv_id": "2409.19790v1",
      "title": "Analysis on Riemann Hypothesis with Cross Entropy Optimization and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Li",
        "Fulu Li"
      ],
      "abstract": "In this paper, we present a novel framework for the analysis of Riemann\nHypothesis [27], which is composed of three key components: a) probabilistic\nmodeling with cross entropy optimization and reasoning; b) the application of\nthe law of large numbers; c) the application of mathematical inductions. The\nanalysis is mainly conducted by virtue of probabilistic modeling of cross\nentropy optimization and reasoning with rare event simulation techniques. The\napplication of the law of large numbers [2, 3, 6] and the application of\nmathematical inductions make the analysis of Riemann Hypothesis self-contained\nand complete to make sure that the whole complex plane is covered as\nconjectured in Riemann Hypothesis. We also discuss the method of enhanced top-p\nsampling with large language models (LLMs) for reasoning, where next token\nprediction is not just based on the estimated probabilities of each possible\ntoken in the current round but also based on accumulated path probabilities\namong multiple top-k chain of thoughts (CoTs) paths. The probabilistic modeling\nof cross entropy optimization and reasoning may suit well with the analysis of\nRiemann Hypothesis as Riemann Zeta functions are inherently dealing with the\nsums of infinite components of a complex number series.\n  We hope that our analysis in this paper could shed some light on some of the\ninsights of Riemann Hypothesis. The framework and techniques presented in this\npaper, coupled with recent developments with chain of thought (CoT) or diagram\nof thought (DoT) reasoning in large language models (LLMs) with reinforcement\nlearning (RL) [1, 7, 18, 21, 24, 34, 39-41], could pave the way for eventual\nproof of Riemann Hypothesis [27].",
      "tldr_zh": "这篇论文提出了一种新框架，用于分析 Riemann Hypothesis，通过三个关键组件进行：probabilistic modeling with cross entropy optimization and reasoning、law of large numbers 的应用，以及 mathematical inductions 的运用，以确保分析自包含并覆盖整个复平面。框架主要依赖 cross entropy optimization 和 reasoning 结合 rare event simulation 技术，对 Riemann Zeta functions 的无限复杂数序列进行概率建模。论文还讨论了 enhanced top-p sampling 方法，利用 large language models (LLMs) 基于累积路径概率的多链式思维 (CoTs) 路径进行推理。总体而言，该框架结合 chain of thought (CoT) 或 diagram of thought (DoT) reasoning 与 reinforcement learning (RL) 等发展，可能为 Riemann Hypothesis 的最终证明提供新路径和见解。",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.19790v1",
      "published_date": "2024-09-29 21:25:58 UTC",
      "updated_date": "2024-09-29 21:25:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:00:31.952768"
    },
    {
      "arxiv_id": "2409.19769v1",
      "title": "Adaptive Event-triggered Reinforcement Learning Control for Complex Nonlinear Systems",
      "title_zh": "自适应事件触发强化学习控制用于复杂非线性系统",
      "authors": [
        "Umer Siddique",
        "Abhinav Sinha",
        "Yongcan Cao"
      ],
      "abstract": "In this paper, we propose an adaptive event-triggered reinforcement learning\ncontrol for continuous-time nonlinear systems, subject to bounded\nuncertainties, characterized by complex interactions. Specifically, the\nproposed method is capable of jointly learning both the control policy and the\ncommunication policy, thereby reducing the number of parameters and\ncomputational overhead when learning them separately or only one of them. By\naugmenting the state space with accrued rewards that represent the performance\nover the entire trajectory, we show that accurate and efficient determination\nof triggering conditions is possible without the need for explicit learning\ntriggering conditions, thereby leading to an adaptive non-stationary policy.\nFinally, we provide several numerical examples to demonstrate the effectiveness\nof the proposed approach.",
      "tldr_zh": "本文提出了一种自适应事件-triggered Reinforcement Learning控制方法，用于处理具有边界不确定性和复杂交互的连续时间Nonlinear Systems。该方法同时学习控制策略和通信策略，减少参数和计算开销，并通过在状态空间中添加累积奖励来实现准确高效的触发条件确定，而无需显式学习触发条件，从而生成自适应非平稳策略。实验结果通过多个数值例子验证了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19769v1",
      "published_date": "2024-09-29 20:42:19 UTC",
      "updated_date": "2024-09-29 20:42:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:00:43.546060"
    },
    {
      "arxiv_id": "2409.19766v1",
      "title": "Towards Robust Extractive Question Answering Models: Rethinking the Training Methodology",
      "title_zh": "翻译失败",
      "authors": [
        "Son Quoc Tran",
        "Matt Kretchmar"
      ],
      "abstract": "This paper proposes a novel training method to improve the robustness of\nExtractive Question Answering (EQA) models. Previous research has shown that\nexisting models, when trained on EQA datasets that include unanswerable\nquestions, demonstrate a significant lack of robustness against distribution\nshifts and adversarial attacks. Despite this, the inclusion of unanswerable\nquestions in EQA training datasets is essential for ensuring real-world\nreliability. Our proposed training method includes a novel loss function for\nthe EQA problem and challenges an implicit assumption present in numerous EQA\ndatasets. Models trained with our method maintain in-domain performance while\nachieving a notable improvement on out-of-domain datasets. This results in an\noverall F1 score improvement of 5.7 across all testing sets. Furthermore, our\nmodels exhibit significantly enhanced robustness against two types of\nadversarial attacks, with a performance decrease of only about a third compared\nto the default models.",
      "tldr_zh": "这篇论文提出了一种新训练方法，以提升抽取式问答 (Extractive Question Answering, EQA) 模型的鲁棒性，针对现有模型在包含不可回答问题的训练数据集上，对分布偏移和对抗攻击 (adversarial attacks) 的脆弱性。该方法引入一个新颖的损失函数 (loss function) 并挑战 EQA 数据集中的隐含假设，确保模型在保持领域内性能的同时显著改善领域外表现。结果显示，整体 F1 score 提高了 5.7，且模型对两种对抗攻击的鲁棒性增强，性能下降仅为默认模型的三之一。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2409.19766v1",
      "published_date": "2024-09-29 20:35:57 UTC",
      "updated_date": "2024-09-29 20:35:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:00:56.158418"
    },
    {
      "arxiv_id": "2409.19751v1",
      "title": "Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Abdelhamid",
        "Abhyuday Desai"
      ],
      "abstract": "Class imbalance in binary classification tasks remains a significant\nchallenge in machine learning, often resulting in poor performance on minority\nclasses. This study comprehensively evaluates three widely-used strategies for\nhandling class imbalance: Synthetic Minority Over-sampling Technique (SMOTE),\nClass Weights tuning, and Decision Threshold Calibration. We compare these\nmethods against a baseline scenario of no-intervention across 15 diverse\nmachine learning models and 30 datasets from various domains, conducting a\ntotal of 9,000 experiments. Performance was primarily assessed using the\nF1-score, although our study also tracked results on additional 9 metrics\nincluding F2-score, precision, recall, Brier-score, PR-AUC, and AUC. Our\nresults indicate that all three strategies generally outperform the baseline,\nwith Decision Threshold Calibration emerging as the most consistently effective\ntechnique. However, we observed substantial variability in the best-performing\nmethod across datasets, highlighting the importance of testing multiple\napproaches for specific problems. This study provides valuable insights for\npractitioners dealing with imbalanced datasets and emphasizes the need for\ndataset-specific analysis in evaluating class imbalance handling techniques.",
      "tldr_zh": "本研究系统评估了处理二元分类中类别不平衡问题的三种策略：SMOTE、Class Weights tuning 和 Decision Threshold Calibration，并与无干预基线进行比较。实验涵盖15个机器学习模型和30个数据集，共进行9,000次测试，主要使用F1-score以及其他9个指标（如F2-score、precision、recall、Brier-score、PR-AUC和AUC）评估性能。结果显示，三种策略整体优于基线，其中Decision Threshold Calibration是最一致有效的方法，但最佳策略因数据集而异。该研究为处理不平衡数据集的从业者提供了宝贵洞见，强调了针对特定数据集进行分析的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "I.2.6; I.5.1; I.5.2; I.2.m"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages including appendix, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.19751v1",
      "published_date": "2024-09-29 16:02:32 UTC",
      "updated_date": "2024-09-29 16:02:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:01:07.501863"
    },
    {
      "arxiv_id": "2409.19745v2",
      "title": "PEAR: Position-Embedding-Agnostic Attention Re-weighting Enhances Retrieval-Augmented Generation with Zero Inference Overhead",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Tan",
        "Yining Qian",
        "Ang Lv",
        "Hongzhan Lin",
        "Songhao Wu",
        "Yongbo Wang",
        "Feng Wang",
        "Jingtong Wu",
        "Xin Lu",
        "Rui Yan"
      ],
      "abstract": "Large language models (LLMs) enhanced with retrieval-augmented generation\n(RAG) have introduced a new paradigm for web search. However, the limited\ncontext awareness of LLMs degrades their performance on RAG tasks. Existing\nmethods to enhance context awareness are often inefficient, incurring time or\nmemory overhead during inference, and many are tailored to specific position\nembeddings. In this paper, we propose Position-Embedding-Agnostic attention\nRe-weighting (PEAR), which enhances the context awareness of LLMs with zero\ninference overhead. Specifically, on a proxy task focused on context copying,\nwe first detect heads which suppress the models' context awareness thereby\ndiminishing RAG performance. To weaken the impact of these heads, we re-weight\ntheir outputs with learnable coefficients. The LLM (with frozen parameters) is\noptimized by adjusting these coefficients to minimize loss on the proxy task.\nAs a result, the coefficients are optimized to values less than one, thereby\nreducing their tendency to suppress RAG performance. During inference, the\noptimized coefficients are fixed to re-weight these heads, regardless of the\nspecific task at hand. Our proposed PEAR offers two major advantages over\nprevious approaches: (1) It introduces zero additional inference overhead in\nterms of memory usage or inference time, while outperforming competitive\nbaselines in accuracy and efficiency across various RAG tasks. (2) It is\nindependent of position embedding algorithms, ensuring broader applicability.",
      "tldr_zh": "本研究提出PEAR（Position-Embedding-Agnostic attention Re-weighting）方法，以提升大型语言模型（LLMs）在检索增强生成（RAG）任务中的上下文感知能力，而无需增加推理时间或内存开销。PEAR通过一个代理任务（context copying）检测并重新权重那些抑制上下文感知的注意力头，使用可学习的系数降低这些头的输出影响，从而优化模型性能。实验结果显示，PEAR在各种RAG任务中准确性和效率均优于基线方法，且其设计独立于位置嵌入算法，确保了更广泛的适用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2409.19745v2",
      "published_date": "2024-09-29 15:40:54 UTC",
      "updated_date": "2024-10-07 14:17:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:01:19.901623"
    },
    {
      "arxiv_id": "2409.19732v1",
      "title": "Unified Gradient-Based Machine Unlearning with Remain Geometry Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Zhehao Huang",
        "Xinwen Cheng",
        "JingHao Zheng",
        "Haoran Wang",
        "Zhengbao He",
        "Tao Li",
        "Xiaolin Huang"
      ],
      "abstract": "Machine unlearning (MU) has emerged to enhance the privacy and\ntrustworthiness of deep neural networks. Approximate MU is a practical method\nfor large-scale models. Our investigation into approximate MU starts with\nidentifying the steepest descent direction, minimizing the output\nKullback-Leibler divergence to exact MU inside a parameters' neighborhood. This\nprobed direction decomposes into three components: weighted forgetting gradient\nascent, fine-tuning retaining gradient descent, and a weight saliency matrix.\nSuch decomposition derived from Euclidean metric encompasses most existing\ngradient-based MU methods. Nevertheless, adhering to Euclidean space may result\nin sub-optimal iterative trajectories due to the overlooked geometric structure\nof the output probability space. We suggest embedding the unlearning update\ninto a manifold rendered by the remaining geometry, incorporating second-order\nHessian from the remaining data. It helps prevent effective unlearning from\ninterfering with the retained performance. However, computing the second-order\nHessian for large-scale models is intractable. To efficiently leverage the\nbenefits of Hessian modulation, we propose a fast-slow parameter update\nstrategy to implicitly approximate the up-to-date salient unlearning direction.\nFree from specific modal constraints, our approach is adaptable across computer\nvision unlearning tasks, including classification and generation. Extensive\nexperiments validate our efficacy and efficiency. Notably, our method\nsuccessfully performs class-forgetting on ImageNet using DiT and forgets a\nclass on CIFAR-10 using DDPM in just 50 steps, compared to thousands of steps\nrequired by previous methods.",
      "tldr_zh": "该论文提出了一种统一的基于梯度的机器遗忘（Machine Unlearning, MU）方法，通过识别最陡下降方向来最小化输出 Kullback-Leibler divergence，从而将遗忘梯度分解为加权遗忘梯度上升、微调保留梯度下降和权重显著性矩阵。针对欧氏空间的局限性，作者引入剩余几何增强，将更新嵌入由剩余数据二阶 Hessian 渲染的流形中，并采用快速-缓慢参数更新策略来高效近似显著遗忘方向。实验结果显示，该方法在计算机视觉任务中表现出色，例如在 ImageNet 上使用 DiT 仅需 50 步完成类遗忘，而传统方法需数千步，从而提升了 MU 的效率和性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024 as a Spotlight paper",
      "pdf_url": "http://arxiv.org/pdf/2409.19732v1",
      "published_date": "2024-09-29 15:17:33 UTC",
      "updated_date": "2024-09-29 15:17:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:01:32.059309"
    },
    {
      "arxiv_id": "2409.19716v1",
      "title": "Constrained Reinforcement Learning for Safe Heat Pump Control",
      "title_zh": "翻译失败",
      "authors": [
        "Baohe Zhang",
        "Lilli Frison",
        "Thomas Brox",
        "Joschka Bödecker"
      ],
      "abstract": "Constrained Reinforcement Learning (RL) has emerged as a significant research\narea within RL, where integrating constraints with rewards is crucial for\nenhancing safety and performance across diverse control tasks. In the context\nof heating systems in the buildings, optimizing the energy efficiency while\nmaintaining the residents' thermal comfort can be intuitively formulated as a\nconstrained optimization problem. However, to solve it with RL may require\nlarge amount of data. Therefore, an accurate and versatile simulator is\nfavored. In this paper, we propose a novel building simulator I4B which\nprovides interfaces for different usages and apply a model-free constrained RL\nalgorithm named constrained Soft Actor-Critic with Linear Smoothed Log Barrier\nfunction (CSAC-LB) to the heating optimization problem. Benchmarking against\nbaseline algorithms demonstrates CSAC-LB's efficiency in data exploration,\nconstraint satisfaction and performance.",
      "tldr_zh": "这篇论文探讨了 Constrained Reinforcement Learning 在建筑供暖系统中的应用，旨在优化热泵控制的能源效率，同时确保居民热舒适度作为约束条件。作者提出了一种新型模拟器 I4B，提供灵活接口以支持高效仿真，并采用无模型算法 CSAC-LB（constrained Soft Actor-Critic with Linear Smoothed Log Barrier function）来处理这一优化问题。与基准算法相比，CSAC-LB 在数据探索、约束满足和整体性能上表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19716v1",
      "published_date": "2024-09-29 14:15:13 UTC",
      "updated_date": "2024-09-29 14:15:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:01:43.479148"
    },
    {
      "arxiv_id": "2410.00061v1",
      "title": "Neural Decompiling of Tracr Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Hannes Thurnherr",
        "Kaspar Riesen"
      ],
      "abstract": "Recently, the transformer architecture has enabled substantial progress in\nmany areas of pattern recognition and machine learning. However, as with other\nneural network models, there is currently no general method available to\nexplain their inner workings. The present paper represents a first step towards\nthis direction. We utilize \\textit{Transformer Compiler for RASP} (Tracr) to\ngenerate a large dataset of pairs of transformer weights and corresponding RASP\nprograms. Based on this dataset, we then build and train a model, with the aim\nof recovering the RASP code from the compiled model. We demonstrate that the\nsimple form of Tracr compiled transformer weights is interpretable for such a\ndecompiler model. In an empirical evaluation, our model achieves exact\nreproductions on more than 30\\% of the test objects, while the remaining 70\\%\ncan generally be reproduced with only few errors. Additionally, more than 70\\%\nof the programs, produced by our model, are functionally equivalent to the\nground truth, and therefore a valid decompilation of the Tracr compiled\ntransformer weights.",
      "tldr_zh": "本论文提出了一种神经反编译方法，针对 Tracr 编译的 Transformer 权重，旨在从这些权重中恢复对应的 RASP 程序。通过利用 Tracr 生成的大规模数据集（包含 Transformer 权重和 RASP 程序对），训练了一个模型来实现这一反编译过程。实验结果显示，该模型在测试集上精确复现超过30%的程序，其余70%程序仅存在少量错误，且超过70%的输出程序与真实程序功能等效，为解释 Transformer 的内部工作机制提供了关键进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00061v1",
      "published_date": "2024-09-29 13:12:39 UTC",
      "updated_date": "2024-09-29 13:12:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:01:55.190731"
    },
    {
      "arxiv_id": "2409.19689v2",
      "title": "InfantCryNet: A Data-driven Framework for Intelligent Analysis of Infant Cries",
      "title_zh": "翻译失败",
      "authors": [
        "Mengze Hong",
        "Chen Jason Zhang",
        "Lingxiao Yang",
        "Yuanfeng Song",
        "Di Jiang"
      ],
      "abstract": "Understanding the meaning of infant cries is a significant challenge for\nyoung parents in caring for their newborns. The presence of background noise\nand the lack of labeled data present practical challenges in developing systems\nthat can detect crying and analyze its underlying reasons. In this paper, we\npresent a novel data-driven framework, \"InfantCryNet,\" for accomplishing these\ntasks. To address the issue of data scarcity, we employ pre-trained audio\nmodels to incorporate prior knowledge into our model. We propose the use of\nstatistical pooling and multi-head attention pooling techniques to extract\nfeatures more effectively. Additionally, knowledge distillation and model\nquantization are applied to enhance model efficiency and reduce the model size,\nbetter supporting industrial deployment in mobile devices. Experiments on\nreal-life datasets demonstrate the superior performance of the proposed\nframework, outperforming state-of-the-art baselines by 4.4% in classification\naccuracy. The model compression effectively reduces the model size by 7%\nwithout compromising performance and by up to 28% with only an 8% decrease in\naccuracy, offering practical insights for model selection and system design.",
      "tldr_zh": "本研究提出了一种数据驱动框架InfantCryNet，用于智能分析婴儿哭声，以帮助父母应对背景噪音和数据缺乏的挑战。该框架利用pre-trained audio models引入先验知识，并采用statistical pooling和multi-head attention pooling技术来更有效地提取音频特征；同时，通过knowledge distillation和model quantization优化模型效率，减少模型大小以支持移动设备部署。在真实数据集上的实验显示，InfantCryNet在分类准确率上比最先进基线提升4.4%，并实现了模型大小减少7%而不损失性能，或减少28%仅以8%的准确率损失，提供实用模型设计见解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by the 16th Asian Conference on Machine Learning (ACML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.19689v2",
      "published_date": "2024-09-29 12:35:47 UTC",
      "updated_date": "2025-02-04 10:23:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:02:07.441036"
    },
    {
      "arxiv_id": "2409.19688v1",
      "title": "Machine Learning for Raman Spectroscopy-based Cyber-Marine Fish Biochemical Composition Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Zhou",
        "Gang Chen",
        "Bing Xue",
        "Mengjie Zhang",
        "Jeremy S. Rooney",
        "Kirill Lagutin",
        "Andrew MacKenzie",
        "Keith C. Gordon",
        "Daniel P. Killeen"
      ],
      "abstract": "The rapid and accurate detection of biochemical compositions in fish is a\ncrucial real-world task that facilitates optimal utilization and extraction of\nhigh-value products in the seafood industry. Raman spectroscopy provides a\npromising solution for quickly and non-destructively analyzing the biochemical\ncomposition of fish by associating Raman spectra with biochemical reference\ndata using machine learning regression models. This paper investigates\ndifferent regression models to address this task and proposes a new design of\nConvolutional Neural Networks (CNNs) for jointly predicting water, protein, and\nlipids yield. To the best of our knowledge, we are the first to conduct a\nsuccessful study employing CNNs to analyze the biochemical composition of fish\nbased on a very small Raman spectroscopic dataset. Our approach combines a\ntailored CNN architecture with the comprehensive data preparation procedure,\neffectively mitigating the challenges posed by extreme data scarcity. The\nresults demonstrate that our CNN can significantly outperform two\nstate-of-the-art CNN models and multiple traditional machine learning models,\npaving the way for accurate and automated analysis of fish biochemical\ncomposition.",
      "tldr_zh": "本论文探讨了利用 Raman spectroscopy 和机器学习回归模型来快速、非破坏性地分析鱼类生化成分，以支持海鲜行业的优化利用。研究提出了一种新的 CNN 架构，结合全面的数据准备流程，用于同时预测水、蛋白质和脂质含量，并成功应对小数据集的挑战。结果表明，该 CNN 模型显著优于现有先进 CNN 和传统机器学习模型，推动了鱼类生化成分的准确自动化分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19688v1",
      "published_date": "2024-09-29 12:28:19 UTC",
      "updated_date": "2024-09-29 12:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:02:19.659228"
    },
    {
      "arxiv_id": "2409.19680v1",
      "title": "Instruction Embedding: Latent Representations of Instructions Towards Task Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwei Li",
        "Jiayi Shi",
        "Shaoxiong Feng",
        "Peiwen Yuan",
        "Xinglin Wang",
        "Boyuan Pan",
        "Heda Wang",
        "Yao Hu",
        "Kan Li"
      ],
      "abstract": "Instruction data is crucial for improving the capability of Large Language\nModels (LLMs) to align with human-level performance. Recent research LIMA\ndemonstrates that alignment is essentially a process where the model adapts\ninstructions' interaction style or format to solve various tasks, leveraging\npre-trained knowledge and skills. Therefore, for instructional data, the most\nimportant aspect is the task it represents, rather than the specific semantics\nand knowledge information. The latent representations of instructions play\nroles for some instruction-related tasks like data selection and demonstrations\nretrieval. However, they are always derived from text embeddings, encompass\noverall semantic information that influences the representation of task\ncategories. In this work, we introduce a new concept, instruction embedding,\nand construct Instruction Embedding Benchmark (IEB) for its training and\nevaluation. Then, we propose a baseline Prompt-based Instruction Embedding\n(PIE) method to make the representations more attention on tasks. The\nevaluation of PIE, alongside other embedding methods on IEB with two designed\ntasks, demonstrates its superior performance in accurately identifying task\ncategories. Moreover, the application of instruction embeddings in four\ndownstream tasks showcases its effectiveness and suitability for\ninstruction-related tasks.",
      "tldr_zh": "该研究探讨了指令数据在提升大语言模型 (LLMs) 能力的角色，强调任务表示比具体语义更重要，并引入指令嵌入 (instruction embedding) 的新概念，以更好地支持指令相关任务如数据选择和演示检索。研究者构建了 Instruction Embedding Benchmark (IEB) 用于训练和评估，并提出 Prompt-based Instruction Embedding (PIE) 方法，该方法通过提示机制使嵌入表示更关注任务类别。实验结果显示，PIE 在 IEB 上的任务识别性能优于其他嵌入方法，并在四个下游任务中证明了其有效性，为指令数据处理提供了新颖的基准和工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.19680v1",
      "published_date": "2024-09-29 12:12:24 UTC",
      "updated_date": "2024-09-29 12:12:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:02:41.227068"
    },
    {
      "arxiv_id": "2409.19676v2",
      "title": "See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chengxin Zheng",
        "Junzhong Ji",
        "Yanzhao Shi",
        "Xiaodan Zhang",
        "Liangqiong Qu"
      ],
      "abstract": "Brain CT report generation is significant to aid physicians in diagnosing\ncranial diseases. Recent studies concentrate on handling the consistency\nbetween visual and textual pathological features to improve the coherence of\nreport. However, there exist some challenges: 1) Redundant visual representing:\nMassive irrelevant areas in 3D scans distract models from representing salient\nvisual contexts. 2) Shifted semantic representing: Limited medical corpus\ncauses difficulties for models to transfer the learned textual representations\nto generative layers. This study introduces a Pathological Clue-driven\nRepresentation Learning (PCRL) model to build cross-modal representations based\non pathological clues and naturally adapt them for accurate report generation.\nSpecifically, we construct pathological clues from perspectives of segmented\nregions, pathological entities, and report themes, to fully grasp visual\npathological patterns and learn cross-modal feature representations. To adapt\nthe representations for the text generation task, we bridge the gap between\nrepresentation learning and report generation by using a unified large language\nmodel (LLM) with task-tailored instructions. These crafted instructions enable\nthe LLM to be flexibly fine-tuned across tasks and smoothly transfer the\nsemantic representation for report generation. Experiments demonstrate that our\nmethod outperforms previous methods and achieves SoTA performance. Our code is\navailable at \"https://github.com/Chauncey-Jheng/PCRL-MRG\".",
      "tldr_zh": "这篇论文针对脑部 CT 报告生成的问题，提出了 Pathological Clue-driven Representation Learning (PCRL) 模型，以解决冗余视觉表示和语义转移挑战。PCRL 通过从 segmented regions、pathological entities 和 report themes 构建病理线索，全面把握视觉病理模式并学习跨模态特征表示。模型进一步利用统一的 Large Language Model (LLM) 和任务定制指令，桥接表示学习与报告生成，实现灵活微调和语义平滑转移。实验结果表明，该方法优于现有方法，达到 State-of-the-Art (SoTA) 性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Our work has been accepted by EMNLP2024 findings",
      "pdf_url": "http://arxiv.org/pdf/2409.19676v2",
      "published_date": "2024-09-29 12:08:20 UTC",
      "updated_date": "2024-10-01 10:42:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:02:53.967924"
    },
    {
      "arxiv_id": "2409.19668v1",
      "title": "Local Search for Integer Quadratic Programming",
      "title_zh": "整数二次规划的局部搜索",
      "authors": [
        "Xiang He",
        "Peng Lin",
        "Shaowei Cai"
      ],
      "abstract": "Integer Quadratic Programming (IQP) is an important problem in operations\nresearch. Local search is a powerful method for solving hard problems, but the\nresearch on local search algorithms for IQP solving is still on its early\nstage. This paper develops an efficient local search solver for solving general\nIQP, called LS-IQCQP. We propose four new local search operators for IQP that\ncan handle quadratic terms in the objective function, constraints or both.\nFurthermore, a two-mode local search algorithm is introduced, utilizing newly\ndesigned scoring functions to enhance the search process. Experiments are\nconducted on standard IQP benchmarks QPLIB and MINLPLIB, comparing LS-IQCQP\nwith several state-of-the-art IQP solvers. Experimental results demonstrate\nthat LS-IQCQP is competitive with the most powerful commercial solver Gurobi\nand outperforms other state-of-the-art solvers. Moreover, LS-IQCQP has\nestablished 6 new records for QPLIB and MINLPLIB open instances.",
      "tldr_zh": "这篇论文针对 Integer Quadratic Programming (IQP) 问题，开发了一个高效的 Local Search 求解器，名为 LS-IQCQP，以解决该领域的挑战。论文提出了四个新的 Local Search 操作符，能够处理目标函数、约束或两者中的二次项，并引入了一个双模式算法，利用新设计的评分函数来优化搜索过程。实验结果显示，LS-IQCQP 在 QPLIB 和 MINLPLIB 基准测试中与商业求解器 Gurobi 竞争力相当，并优于其他最先进求解器，还为这些基准的开放实例建立了6个新记录。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19668v1",
      "published_date": "2024-09-29 11:45:44 UTC",
      "updated_date": "2024-09-29 11:45:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:03:06.055290"
    },
    {
      "arxiv_id": "2409.19667v3",
      "title": "Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models",
      "title_zh": "大型语言模型能否像专业人士一样分析图？一个基准测试、数据集和模型",
      "authors": [
        "Xin Sky Li",
        "Weize Chen",
        "Qizhi Chu",
        "Haopeng Li",
        "Zhaojun Sun",
        "Ran Li",
        "Chen Qian",
        "Yiwei Wei",
        "Zhiyuan Liu",
        "Chuan Shi",
        "Maosong Sun",
        "Cheng Yang"
      ],
      "abstract": "The need to analyze graphs is ubiquitous across various fields, from social\nnetworks to biological research and recommendation systems. Therefore, enabling\nthe ability of large language models (LLMs) to process graphs is an important\nstep toward more advanced general intelligence. However, current LLM benchmarks\non graph analysis require models to directly reason over the prompts describing\ngraph topology, and are thus limited to small graphs with only a few dozens of\nnodes. In contrast, human experts typically write programs based on popular\nlibraries for task solving, and can thus handle graphs with different scales.\nTo this end, a question naturally arises: can LLMs analyze graphs like\nprofessionals? In this paper, we introduce ProGraph, a manually crafted\nbenchmark containing 3 categories of graph tasks. The benchmark expects\nsolutions based on programming instead of directly reasoning over raw inputs.\nOur findings reveal that the performance of current LLMs is unsatisfactory,\nwith the best model achieving only 36% accuracy. To bridge this gap, we propose\nLLM4Graph datasets, which include crawled documents and auto-generated codes\nbased on 6 widely used graph libraries. By augmenting closed-source LLMs with\ndocument retrieval and fine-tuning open-source ones on the codes, we show\n11-32% absolute improvements in their accuracies. Our results underscore that\nthe capabilities of LLMs in handling structured data are still under-explored,\nand show the effectiveness of LLM4Graph in enhancing LLMs' proficiency of graph\nanalysis. The benchmark, datasets and enhanced open-source models are available\nat https://github.com/BUPT-GAMMA/ProGraph.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)是否能像专业人士一样分析图(graphs)，并引入了ProGraph基准，这是一个包含3类图任务的手动基准，要求模型通过编程而非直接推理来解决问题。实验结果显示，当前LLMs的表现不尽人意，最佳模型的准确率仅为36%。为了弥补这一差距，作者提出了LLM4Graph数据集，包括从6个流行图库爬取的文档和自动生成的代码，通过文档检索增强和微调开源模型，实现了11-32%的准确率提升。这些发现强调了LLMs在处理结构化数据方面的潜力，并提供了基准、数据集和增强模型的开源资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.19667v3",
      "published_date": "2024-09-29 11:38:45 UTC",
      "updated_date": "2025-02-24 05:39:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:03:17.529761"
    },
    {
      "arxiv_id": "2409.19663v2",
      "title": "Identifying Knowledge Editing Types in Large Language Models",
      "title_zh": "识别大语言模型中的知识编辑类型",
      "authors": [
        "Xiaopeng Li",
        "Shangwen Wang",
        "Shezheng Song",
        "Bin Ji",
        "Huijun Liu",
        "Shasha Li",
        "Jun Ma",
        "Jie Yu"
      ],
      "abstract": "Knowledge editing has emerged as an efficient technology for updating the\nknowledge of large language models (LLMs), attracting increasing attention in\nrecent years. However, there is a lack of effective measures to prevent the\nmalicious misuse of this technology, which could lead to harmful edits in LLMs.\nThese malicious modifications could cause LLMs to generate toxic content,\nmisleading users into inappropriate actions. In front of this risk, we\nintroduce a new task, Knowledge Editing Type Identification (KETI), aimed at\nidentifying different types of edits in LLMs, thereby providing timely alerts\nto users when encountering illicit edits. As part of this task, we propose\nKETIBench, which includes five types of harmful edits covering most popular\ntoxic types, as well as one benign factual edit. We develop four classical\nclassification models and three BERT-based models as baseline identifiers for\nboth open-source and closed-source LLMs. Our experimental results, across 42\ntrials involving two models and three knowledge editing methods, demonstrate\nthat all seven baseline identifiers achieve decent identification performance,\nhighlighting the feasibility of identifying malicious edits in LLMs. Additional\nanalyses reveal that the performance of the identifiers is independent of the\nreliability of the knowledge editing methods and exhibits cross-domain\ngeneralization, enabling the identification of edits from unknown sources. All\ndata and code are available in https://github.com/xpq-tech/KETI. Warning: This\npaper contains examples of toxic text.",
      "tldr_zh": "本文提出了一种新任务Knowledge Editing Type Identification (KETI)，旨在识别大型语言模型(LLMs)中知识编辑(Knowledge Editing)的不同类型，以防范恶意编辑导致的毒害内容生成。研究构建了KETIBench基准数据集，包括五种常见有害编辑类型和一种良性事实编辑，并开发了四种经典分类模型和三种BERT-based模型作为基线标识器。实验结果显示，这些标识器在涉及两个模型和三种编辑方法的42次试验中表现出色，准确率较高，且性能独立于编辑方法的可靠性，并具备跨领域泛化能力，为防止LLMs的恶意误用提供了可行方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2409.19663v2",
      "published_date": "2024-09-29 11:29:57 UTC",
      "updated_date": "2024-10-01 06:35:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:03:29.258533"
    },
    {
      "arxiv_id": "2409.19655v2",
      "title": "Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales",
      "title_zh": "利用心理测量量表评估和操控预训练语言模型中的潜在结构",
      "authors": [
        "Maor Reuben",
        "Ortal Slobodin",
        "Aviad Elyshar",
        "Idan-Chaim Cohen",
        "Orna Braun-Lewensohn",
        "Odeya Cohen",
        "Rami Puzis"
      ],
      "abstract": "Human-like personality traits have recently been discovered in large language\nmodels, raising the hypothesis that their (known and as yet undiscovered)\nbiases conform with human latent psychological constructs. While large\nconversational models may be tricked into answering psychometric\nquestionnaires, the latent psychological constructs of thousands of simpler\ntransformers, trained for other tasks, cannot be assessed because appropriate\npsychometric methods are currently lacking. Here, we show how standard\npsychological questionnaires can be reformulated into natural language\ninference prompts, and we provide a code library to support the psychometric\nassessment of arbitrary models. We demonstrate, using a sample of 88 publicly\navailable models, the existence of human-like mental health-related constructs\n(including anxiety, depression, and Sense of Coherence) which conform with\nstandard theories in human psychology and show similar correlations and\nmitigation strategies. The ability to interpret and rectify the performance of\nlanguage models by using psychological tools can boost the development of more\nexplainable, controllable, and trustworthy models.",
      "tldr_zh": "该研究探讨了如何使用心理测量学量表（psychometric scales）评估和操控预训练语言模型（pre-trained language models）中的潜在心理结构。作者将标准心理问卷改编为自然语言推理（natural language inference）提示，并开发了一个代码库，用于评估任意模型的心理特性。实验结果显示，在88个公开模型中，发现了类似人类的心理结构（如焦虑、抑郁和连贯感），这些结构符合人类心理学理论，并显示出相似的相关性和缓解策略。该方法有助于提升语言模型的可解释性、可控性和可信赖性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19655v2",
      "published_date": "2024-09-29 11:00:41 UTC",
      "updated_date": "2025-01-13 10:08:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:03:41.948954"
    },
    {
      "arxiv_id": "2409.19650v1",
      "title": "Grounding 3D Scene Affordance From Egocentric Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Cuiyu Liu",
        "Wei Zhai",
        "Yuhang Yang",
        "Hongchen Luo",
        "Sen Liang",
        "Yang Cao",
        "Zheng-Jun Zha"
      ],
      "abstract": "Grounding 3D scene affordance aims to locate interactive regions in 3D\nenvironments, which is crucial for embodied agents to interact intelligently\nwith their surroundings. Most existing approaches achieve this by mapping\nsemantics to 3D instances based on static geometric structure and visual\nappearance. This passive strategy limits the agent's ability to actively\nperceive and engage with the environment, making it reliant on predefined\nsemantic instructions. In contrast, humans develop complex interaction skills\nby observing and imitating how others interact with their surroundings. To\nempower the model with such abilities, we introduce a novel task: grounding 3D\nscene affordance from egocentric interactions, where the goal is to identify\nthe corresponding affordance regions in a 3D scene based on an egocentric video\nof an interaction. This task faces the challenges of spatial complexity and\nalignment complexity across multiple sources. To address these challenges, we\npropose the Egocentric Interaction-driven 3D Scene Affordance Grounding\n(Ego-SAG) framework, which utilizes interaction intent to guide the model in\nfocusing on interaction-relevant sub-regions and aligns affordance features\nfrom different sources through a bidirectional query decoder mechanism.\nFurthermore, we introduce the Egocentric Video-3D Scene Affordance Dataset\n(VSAD), covering a wide range of common interaction types and diverse 3D\nenvironments to support this task. Extensive experiments on VSAD validate both\nthe feasibility of the proposed task and the effectiveness of our approach.",
      "tldr_zh": "该研究提出了一种新任务：从第一人称视角（egocentric interactions）的视频中定位3D场景的affordance regions，以提升embodied agents的交互智能，克服现有方法依赖静态几何和视觉的被动局限。作者开发了Ego-SAG框架，利用interaction intent引导模型关注相关子区域，并通过bidirectional query decoder机制对齐多源特征。针对此任务，他们构建了VSAD数据集，涵盖多种交互类型和多样3D环境。实验在VSAD上验证了任务的可行性和框架的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19650v1",
      "published_date": "2024-09-29 10:46:19 UTC",
      "updated_date": "2024-09-29 10:46:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:03:53.459367"
    },
    {
      "arxiv_id": "2409.19647v1",
      "title": "Fine-Tuning Hybrid Physics-Informed Neural Networks for Vehicle Dynamics Model Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Shiming Fang",
        "Kaiyan Yu"
      ],
      "abstract": "Accurate dynamic modeling is critical for autonomous racing vehicles,\nespecially during high-speed and agile maneuvers where precise motion\nprediction is essential for safety. Traditional parameter estimation methods\nface limitations such as reliance on initial guesses, labor-intensive fitting\nprocedures, and complex testing setups. On the other hand, purely data-driven\nmachine learning methods struggle to capture inherent physical constraints and\ntypically require large datasets for optimal performance. To address these\nchallenges, this paper introduces the Fine-Tuning Hybrid Dynamics (FTHD)\nmethod, which integrates supervised and unsupervised Physics-Informed Neural\nNetworks (PINNs), combining physics-based modeling with data-driven techniques.\nFTHD fine-tunes a pre-trained Deep Dynamics Model (DDM) using a smaller\ntraining dataset, delivering superior performance compared to state-of-the-art\nmethods such as the Deep Pacejka Model (DPM) and outperforming the original\nDDM. Furthermore, an Extended Kalman Filter (EKF) is embedded within FTHD\n(EKF-FTHD) to effectively manage noisy real-world data, ensuring accurate\ndenoising while preserving the vehicle's essential physical characteristics.\nThe proposed FTHD framework is validated through scaled simulations using the\nBayesRace Physics-based Simulator and full-scale real-world experiments from\nthe Indy Autonomous Challenge. Results demonstrate that the hybrid approach\nsignificantly improves parameter estimation accuracy, even with reduced data,\nand outperforms existing models. EKF-FTHD enhances robustness by denoising\nreal-world data while maintaining physical insights, representing a notable\nadvancement in vehicle dynamics modeling for high-speed autonomous racing.",
      "tldr_zh": "这篇论文提出 Fine-Tuning Hybrid Dynamics (FTHD) 方法，结合监督和无监督的 Physics-Informed Neural Networks (PINNs)，以整合物理建模和数据驱动技术，解决传统参数估计方法依赖初始猜测和数据驱动方法需大量数据集的局限。FTHD 通过微调预训练的 Deep Dynamics Model (DDM) 使用较小数据集，并嵌入 Extended Kalman Filter (EKF) 来处理噪声数据，确保准确去噪的同时保留车辆物理特性。在 BayesRace 模拟器和 Indy Autonomous Challenge 的真实实验中，FTHD 显著提升了参数估计准确性，比 Deep Pacejka Model (DPM) 和原始 DDM 表现更优，并为高速自主赛车动态建模提供了重要进展。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19647v1",
      "published_date": "2024-09-29 10:33:07 UTC",
      "updated_date": "2024-09-29 10:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:04:06.987023"
    },
    {
      "arxiv_id": "2410.03724v2",
      "title": "Large Language Models Overcome the Machine Penalty When Acting Fairly but Not When Acting Selfishly or Altruistically",
      "title_zh": "大型语言模型在公平行事时克服了机器惩罚，但在自私或",
      "authors": [
        "Zhen Wang",
        "Ruiqi Song",
        "Chen Shen",
        "Shiya Yin",
        "Zhao Song",
        "Balaraju Battu",
        "Lei Shi",
        "Danyang Jia",
        "Talal Rahwan",
        "Shuyue Hu"
      ],
      "abstract": "In social dilemmas where the collective and self-interests are at odds,\npeople typically cooperate less with machines than with fellow humans, a\nphenomenon termed the machine penalty. Overcoming this penalty is critical for\nsuccessful human-machine collectives, yet current solutions often involve\nethically-questionable tactics, like concealing machines' non-human nature. In\nthis study, with 1,152 participants, we explore the possibility of closing this\nresearch question by using Large Language Models (LLMs), in scenarios where\ncommunication is possible between interacting parties. We design three types of\nLLMs: (i) Cooperative, aiming to assist its human associate; (ii) Selfish,\nfocusing solely on maximizing its self-interest; and (iii) Fair, balancing its\nown and collective interest, while slightly prioritizing self-interest. Our\nfindings reveal that, when interacting with humans, fair LLMs are able to\ninduce cooperation levels comparable to those observed in human-human\ninteractions, even when their non-human nature is fully disclosed. In contrast,\nselfish and cooperative LLMs fail to achieve this goal. Post-experiment\nanalysis shows that all three types of LLMs succeed in forming mutual\ncooperation agreements with humans, yet only fair LLMs, which occasionally\nbreak their promises, are capable of instilling a perception among humans that\ncooperating with them is the social norm, and eliciting positive views on their\ntrustworthiness, mindfulness, intelligence, and communication quality. Our\nfindings suggest that for effective human-machine cooperation, bot\nmanufacturers should avoid designing machines with mere rational\ndecision-making or a sole focus on assisting humans. Instead, they should\ndesign machines capable of judiciously balancing their own interest and the\ninterest of humans.",
      "tldr_zh": "这篇论文探讨了在社会困境中，人们对机器的“machine penalty”现象，即较少与机器合作，并测试 Large Language Models (LLMs) 是否能克服这一问题。研究设计了三种 LLM 类型：Cooperative (旨在协助人类)、Selfish (专注于自身利益最大化) 和 Fair (平衡自身与集体利益，略优先自身)，并通过涉及 1,152 名参与者的实验评估它们与人类的互动。结果显示，只有 Fair LLMs 能在公开其非人类身份的情况下，实现与人类互动相似的合作水平，而 Selfish 和 Cooperative LLMs 则失败了。作者建议，机器制造商应设计能 judiciously 平衡自身利益和人类利益的系统，以促进有效的人机合作。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.GT",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03724v2",
      "published_date": "2024-09-29 10:11:25 UTC",
      "updated_date": "2024-10-08 09:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:04:18.367002"
    },
    {
      "arxiv_id": "2409.19638v1",
      "title": "BadHMP: Backdoor Attack against Human Motion Prediction",
      "title_zh": "BadHMP：针对人类运动预测的后门攻击",
      "authors": [
        "Chaohui Xu",
        "Si Wang",
        "Chip-Hong Chang"
      ],
      "abstract": "Precise future human motion prediction over subsecond horizons from past\nobservations is crucial for various safety-critical applications. To date, only\none study has examined the vulnerability of human motion prediction to evasion\nattacks. In this paper, we propose BadHMP, the first backdoor attack that\ntargets specifically human motion prediction. Our approach involves generating\npoisoned training samples by embedding a localized backdoor trigger in one arm\nof the skeleton, causing selected joints to remain relatively still or follow\npredefined motion in historical time steps. Subsequently, the future sequences\nare globally modified to the target sequences, and the entire training dataset\nis traversed to select the most suitable samples for poisoning. Our carefully\ndesigned backdoor triggers and targets guarantee the smoothness and naturalness\nof the poisoned samples, making them stealthy enough to evade detection by the\nmodel trainer while keeping the poisoned model unobtrusive in terms of\nprediction fidelity to untainted sequences. The target sequences can be\nsuccessfully activated by the designed input sequences even with a low poisoned\nsample injection ratio. Experimental results on two datasets (Human3.6M and\nCMU-Mocap) and two network architectures (LTD and HRI) demonstrate the\nhigh-fidelity, effectiveness, and stealthiness of BadHMP. Robustness of our\nattack against fine-tuning defense is also verified.",
      "tldr_zh": "本论文提出BadHMP，这是首个针对人类运动预测的Backdoor Attack，旨在通过在训练数据中注入隐蔽的毒化样本来破坏预测模型。方法包括在骨骼手臂上嵌入本地化背门触发器，使选定关节保持静止或跟随预定义运动，并全局修改未来序列，同时选择最合适的样本以确保毒化样本的光滑性和自然性。实验在Human3.6M和CMU-Mocap数据集上，使用LTD和HRI网络架构，证明了BadHMP的高保真度、有效性和隐蔽性，即使毒化样本比例低也能激活目标序列，且对微调防御表现出鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19638v1",
      "published_date": "2024-09-29 09:55:31 UTC",
      "updated_date": "2024-09-29 09:55:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:04:28.610997"
    },
    {
      "arxiv_id": "2409.19629v1",
      "title": "A Survey on Graph Neural Networks for Remaining Useful Life Prediction: Methodologies, Evaluation and Future Trends",
      "title_zh": "图神经网络在剩余寿命预测中的综",
      "authors": [
        "Yucheng Wang",
        "Min Wu",
        "Xiaoli Li",
        "Lihua Xie",
        "Zhenghua Chen"
      ],
      "abstract": "Remaining Useful Life (RUL) prediction is a critical aspect of Prognostics\nand Health Management (PHM), aimed at predicting the future state of a system\nto enable timely maintenance and prevent unexpected failures. While existing\ndeep learning methods have shown promise, they often struggle to fully leverage\nthe spatial information inherent in complex systems, limiting their\neffectiveness in RUL prediction. To address this challenge, recent research has\nexplored the use of Graph Neural Networks (GNNs) to model spatial information\nfor more accurate RUL prediction. This paper presents a comprehensive review of\nGNN techniques applied to RUL prediction, summarizing existing methods and\noffering guidance for future research. We first propose a novel taxonomy based\non the stages of adapting GNNs to RUL prediction, systematically categorizing\napproaches into four key stages: graph construction, graph modeling, graph\ninformation processing, and graph readout. By organizing the field in this way,\nwe highlight the unique challenges and considerations at each stage of the GNN\npipeline. Additionally, we conduct a thorough evaluation of various\nstate-of-the-art (SOTA) GNN methods, ensuring consistent experimental settings\nfor fair comparisons. This rigorous analysis yields valuable insights into the\nstrengths and weaknesses of different approaches, serving as an experimental\nguide for researchers and practitioners working in this area. Finally, we\nidentify and discuss several promising research directions that could further\nadvance the field, emphasizing the potential for GNNs to revolutionize RUL\nprediction and enhance the effectiveness of PHM strategies. The benchmarking\ncodes are available in GitHub:\nhttps://github.com/Frank-Wang-oss/GNN\\_RUL\\_Benchmarking.",
      "tldr_zh": "这篇论文对Graph Neural Networks (GNNs) 在Remaining Useful Life (RUL) 预测中的应用进行了全面调研，旨在解决传统深度学习方法在利用复杂系统空间信息方面的不足。作者提出一个新颖的分类法，将GNNs 适配RUL 预测分为四个阶段：graph construction, graph modeling, graph information processing, and graph readout，并系统分析了每个阶段的挑战和考虑因素。通过一致的实验设置评估了多种state-of-the-art (SOTA) GNN 方法，揭示了它们的优势与缺点，为研究者和从业者提供实用指导。最后，论文讨论了未来趋势，如GNNs 在Prognostics and Health Management (PHM) 领域的潜力，并公开了基准代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19629v1",
      "published_date": "2024-09-29 09:38:07 UTC",
      "updated_date": "2024-09-29 09:38:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:04:41.497577"
    },
    {
      "arxiv_id": "2410.00059v1",
      "title": "IDEA: An Inverse Domain Expert Adaptation Based Active DNN IP Protection Method",
      "title_zh": "翻译失败",
      "authors": [
        "Chaohui Xu",
        "Qi Cui",
        "Jinxin Dong",
        "Weiyang He",
        "Chip-Hong Chang"
      ],
      "abstract": "Illegitimate reproduction, distribution and derivation of Deep Neural Network\n(DNN) models can inflict economic loss, reputation damage and even privacy\ninfringement. Passive DNN intellectual property (IP) protection methods such as\nwatermarking and fingerprinting attempt to prove the ownership upon IP\nviolation, but they are often too late to stop catastrophic damage of IP abuse\nand too feeble against strong adversaries. In this paper, we propose IDEA, an\nInverse Domain Expert Adaptation based proactive DNN IP protection method\nfeaturing active authorization and source traceability. IDEA generalizes active\nauthorization as an inverse problem of domain adaptation. The multi-adaptive\noptimization is solved by a mixture-of-experts model with one real and two fake\nexperts. The real expert re-optimizes the source model to correctly classify\ntest images with a unique model user key steganographically embedded. The fake\nexperts are trained to output random prediction on test images without or with\nincorrect user key embedded by minimizing their mutual information (MI) with\nthe real expert. The MoE model is knowledge distilled into a unified protected\nmodel to avoid leaking the expert model features by maximizing their MI with\nadditional multi-layer attention and contrastive representation loss\noptimization. IDEA not only prevents unauthorized users without the valid key\nto access the functional model, but also enable the model owner to validate the\ndeployed model and trace the source of IP infringement. We extensively evaluate\nIDEA on five datasets and four DNN models to demonstrate its effectiveness in\nauthorization control, culprit tracing success rate, and robustness against\nvarious attacks.",
      "tldr_zh": "这篇论文提出了一种主动的 DNN IP 保护方法 IDEA，基于 Inverse Domain Expert Adaptation，旨在通过主动授权和源追踪来防范 DNN 模型的非法复制和分发。IDEA 将授权问题视为领域适应的逆问题，使用 Mixture-of-Experts 模型（包括一个真实专家和两个假专家）来优化模型：真实专家通过嵌入唯一用户密钥重新训练模型，而假专家通过最小化互信息（MI）确保无密钥或错误密钥时输出随机预测，并通过知识蒸馏和多层注意力优化生成统一的保护模型。实验在五个数据集和四个 DNN 模型上证明了 IDEA 在授权控制、侵权源追踪成功率以及对抗各种攻击的鲁棒性上表现出色。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.00059v1",
      "published_date": "2024-09-29 09:34:33 UTC",
      "updated_date": "2024-09-29 09:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:04:55.134529"
    },
    {
      "arxiv_id": "2409.19625v1",
      "title": "An action language-based formalisation of an abstract argumentation framework",
      "title_zh": "翻译失败",
      "authors": [
        "Yann Munro",
        "Camilo Sarmiento",
        "Isabelle Bloch",
        "Gauvain Bourgne",
        "Catherine Pelachaud",
        "Marie-Jeanne Lesot"
      ],
      "abstract": "An abstract argumentation framework is a commonly used formalism to provide a\nstatic representation of a dialogue. However, the order of enunciation of the\narguments in an argumentative dialogue is very important and can affect the\noutcome of this dialogue. In this paper, we propose a new framework for\nmodelling abstract argumentation graphs, a model that incorporates the order of\nenunciation of arguments. By taking this order into account, we have the means\nto deduce a unique outcome for each dialogue, called an extension. We also\nestablish several properties, such as termination and correctness, and discuss\ntwo notions of completeness. In particular, we propose a modification of the\nprevious transformation based on a \"last enunciated last updated\" strategy,\nwhich verifies the second form of completeness.",
      "tldr_zh": "本论文基于行动语言(action language)形式化了抽象论证框架(abstract argumentation framework)，通过考虑论证在对话中的表述顺序，解决了传统静态模型可能忽略顺序影响的问题。这种新框架允许推导出每个对话的唯一结果(extension)，并建立了终止性、正确性等属性。论文还讨论了两种完整性概念，并提出了一种修改的转换策略，即“last enunciated last updated”方法，以验证第二种完整性。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "To be published in The 25th International Conference on Principles\n  and Practice of Multi-Agent Systems",
      "pdf_url": "http://arxiv.org/pdf/2409.19625v1",
      "published_date": "2024-09-29 09:24:29 UTC",
      "updated_date": "2024-09-29 09:24:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:05:05.823607"
    },
    {
      "arxiv_id": "2409.19624v1",
      "title": "Storynizor: Consistent Story Generation via Inter-Frame Synchronized and Shuffled ID Injection",
      "title_zh": "Storynizor：通过",
      "authors": [
        "Yuhang Ma",
        "Wenting Xu",
        "Chaoyi Zhao",
        "Keqiang Sun",
        "Qinfeng Jin",
        "Zeng Zhao",
        "Changjie Fan",
        "Zhipeng Hu"
      ],
      "abstract": "Recent advances in text-to-image diffusion models have spurred significant\ninterest in continuous story image generation. In this paper, we introduce\nStorynizor, a model capable of generating coherent stories with strong\ninter-frame character consistency, effective foreground-background separation,\nand diverse pose variation. The core innovation of Storynizor lies in its key\nmodules: ID-Synchronizer and ID-Injector. The ID-Synchronizer employs an\nauto-mask self-attention module and a mask perceptual loss across inter-frame\nimages to improve the consistency of character generation, vividly representing\ntheir postures and backgrounds. The ID-Injector utilize a Shuffling Reference\nStrategy (SRS) to integrate ID features into specific locations, enhancing\nID-based consistent character generation. Additionally, to facilitate the\ntraining of Storynizor, we have curated a novel dataset called StoryDB\ncomprising 100, 000 images. This dataset contains single and multiple-character\nsets in diverse environments, layouts, and gestures with detailed descriptions.\nExperimental results indicate that Storynizor demonstrates superior coherent\nstory generation with high-fidelity character consistency, flexible postures,\nand vivid backgrounds compared to other character-specific methods.",
      "tldr_zh": "本文提出 Storynizor 模型，用于基于 text-to-image diffusion models 的连续故事图像生成，重点实现角色一致性、前景背景分离以及姿势多样性。核心创新包括 ID-Synchronizer 模块（利用 auto-mask self-attention 和 mask perceptual loss 提升跨帧角色生成的一致性）和 ID-Injector 模块（通过 Shuffling Reference Strategy 整合 ID 特征到特定位置）。为支持训练，作者构建了 StoryDB 数据集，包含 10 万张图像，涵盖单多角色、多环境和姿势的详细描述。实验结果表明，Storynizor 在连贯故事生成中表现出色，比其他方法在角色一致性、灵活姿势和生动背景方面有显著提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19624v1",
      "published_date": "2024-09-29 09:15:51 UTC",
      "updated_date": "2024-09-29 09:15:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:05:17.360164"
    },
    {
      "arxiv_id": "2409.19623v1",
      "title": "MCDDPM: Multichannel Conditional Denoising Diffusion Model for Unsupervised Anomaly Detection in Brain MRI",
      "title_zh": "MCDDPM：多通道条件去噪扩散模型用于脑部 MRI 的无监督异常检测",
      "authors": [
        "Vivek Kumar Trivedi",
        "Bheeshm Sharma",
        "P. Balamurugan"
      ],
      "abstract": "Detecting anomalies in brain MRI scans using supervised deep learning methods\npresents challenges due to anatomical diversity and labor-intensive requirement\nof pixel-level annotations. Generative models like Denoising Diffusion\nProbabilistic Model (DDPM) and their variants like pDDPM, mDDPM, cDDPM have\nrecently emerged to be powerful alternatives to perform unsupervised anomaly\ndetection in brain MRI scans. These methods leverage frame-level labels of\nhealthy brains to generate healthy tissues in brain MRI scans. During\ninference, when an anomalous (or unhealthy) scan image is presented as an\ninput, these models generate a healthy scan image corresponding to the input\nanomalous scan, and the difference map between the generated healthy scan image\nand the original anomalous scan image provide the necessary pixel level\nidentification of abnormal tissues. The generated healthy images from the DDPM,\npDDPM and mDDPM models however suffer from fidelity issues and contain\nartifacts that do not have medical significance. While cDDPM achieves slightly\nbetter fidelity and artifact suppression, it requires huge memory footprint and\nis computationally expensive than the other DDPM based models. In this work, we\npropose an improved version of DDPM called Multichannel Conditional Denoising\nDiffusion Probabilistic Model (MCDDPM) for unsupervised anomaly detection in\nbrain MRI scans. Our proposed model achieves high fidelity by making use of\nadditional information from the healthy images during the training process,\nenriching the representation power of DDPM models, with a computational cost\nand memory requirements on par with DDPM, pDDPM and mDDPM models. Experimental\nresults on multiple datasets (e.g. BraTS20, BraTS21) demonstrate promising\nperformance of the proposed method. The code is available at\nhttps://github.com/vivekkumartri/MCDDPM.",
      "tldr_zh": "本研究针对脑 MRI 扫描的无监督异常检测问题，指出现有生成模型如 DDPM、pDDPM、mDDPM 和 cDDPM 存在图像保真度低和计算资源需求高的局限性。作者提出了一种改进版本 Multichannel Conditional Denoising Diffusion Probabilistic Model (MCDDPM)，通过在训练过程中利用健康图像的额外信息来增强模型的表示能力和生成图像的保真度，同时保持与传统 DDPM 模型相似的计算成本和内存需求。在 BraTS20 和 BraTS21 等数据集上的实验结果显示，该方法在异常检测性能上表现出色，提供了一种高效的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted in CISP-BMEI 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.19623v1",
      "published_date": "2024-09-29 09:15:24 UTC",
      "updated_date": "2024-09-29 09:15:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:05:28.980145"
    },
    {
      "arxiv_id": "2409.19620v2",
      "title": "DropEdge not Foolproof: Effective Augmentation Method for Signed Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Zhang",
        "Lu Li",
        "Shuyan Wan",
        "Sijie Wang",
        "Zhiyi Wang",
        "Zhiyuan Lu",
        "Dong Hao",
        "Wanli Li"
      ],
      "abstract": "The paper discusses signed graphs, which model friendly or antagonistic\nrelationships using edges marked with positive or negative signs, focusing on\nthe task of link sign prediction. While Signed Graph Neural Networks (SGNNs)\nhave advanced, they face challenges like graph sparsity and unbalanced\ntriangles. The authors propose using data augmentation (DA) techniques to\naddress these issues, although many existing methods are not suitable for\nsigned graphs due to a lack of side information. They highlight that the random\nDropEdge method, a rare DA approach applicable to signed graphs, does not\nenhance link sign prediction performance. In response, they introduce the\nSigned Graph Augmentation (SGA) framework, which includes a structure\naugmentation module to identify candidate edges and a strategy for selecting\nbeneficial candidates, ultimately improving SGNN training. Experimental results\nshow that SGA significantly boosts the performance of SGNN models, with a\nnotable 32.3% improvement in F1-micro for SGCN on the Slashdot dataset.",
      "tldr_zh": "这篇论文探讨了带符号图神经网络（SGNNs）在链接符号预测任务中的挑战，包括图稀疏性和不平衡三角形问题，并指出现有的随机DropEdge数据增强方法无法提升性能。作者提出Signed Graph Augmentation (SGA)框架，该框架包括一个结构增强模块，用于识别候选边并选择有益的增强策略，从而改善SGNNs的训练过程。实验结果显示，SGA显著提升了模型表现，在Slashdot数据集上，SGCN的F1-micro指标提高了32.3%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.19620v2",
      "published_date": "2024-09-29 09:13:23 UTC",
      "updated_date": "2024-10-01 23:15:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:05:41.794212"
    },
    {
      "arxiv_id": "2409.19619v1",
      "title": "Discerning the Chaos: Detecting Adversarial Perturbations while Disentangling Intentional from Unintentional Noises",
      "title_zh": "辨识混沌：检测对抗扰动，同时区分有意的噪声与",
      "authors": [
        "Anubhooti Jain",
        "Susim Roy",
        "Kwanit Gupta",
        "Mayank Vatsa",
        "Richa Singh"
      ],
      "abstract": "Deep learning models, such as those used for face recognition and attribute\nprediction, are susceptible to manipulations like adversarial noise and\nunintentional noise, including Gaussian and impulse noise. This paper\nintroduces CIAI, a Class-Independent Adversarial Intent detection network built\non a modified vision transformer with detection layers. CIAI employs a novel\nloss function that combines Maximum Mean Discrepancy and Center Loss to detect\nboth intentional (adversarial attacks) and unintentional noise, regardless of\nthe image class. It is trained in a multi-step fashion. We also introduce the\naspect of intent during detection that can act as an added layer of security.\nWe further showcase the performance of our proposed detector on CelebA,\nCelebA-HQ, LFW, AgeDB, and CIFAR-10 datasets. Our detector is able to detect\nboth intentional (like FGSM, PGD, and DeepFool) and unintentional (like\nGaussian and Salt & Pepper noises) perturbations.",
      "tldr_zh": "本研究针对深度学习模型（如用于人脸识别的模型）易受对抗噪声和无意噪声（如Gaussian和impulse噪声）的影响，提出了一种CIAI网络。该网络基于修改后的vision transformer架构，并采用结合Maximum Mean Discrepancy和Center Loss的新颖损失函数，通过多步骤训练来检测并区分有意（如FGSM、PGD和DeepFool攻击）和无意（如Gaussian和Salt & Pepper噪声）扰动。实验在CelebA、CelebA-HQ、LFW、AgeDB和CIFAR-10数据集上验证了CIAI的有效性，提升了模型的安全性，为对抗检测提供了额外的意图识别层。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19619v1",
      "published_date": "2024-09-29 09:10:43 UTC",
      "updated_date": "2024-09-29 09:10:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:05:53.366195"
    },
    {
      "arxiv_id": "2409.19603v1",
      "title": "One Token to Seg Them All: Language Instructed Reasoning Segmentation in Videos",
      "title_zh": "一个令牌统领所有：视频中的语言指令推理分割",
      "authors": [
        "Zechen Bai",
        "Tong He",
        "Haiyang Mei",
        "Pichao Wang",
        "Ziteng Gao",
        "Joya Chen",
        "Lei Liu",
        "Zheng Zhang",
        "Mike Zheng Shou"
      ],
      "abstract": "We introduce VideoLISA, a video-based multimodal large language model\ndesigned to tackle the problem of language-instructed reasoning segmentation in\nvideos. Leveraging the reasoning capabilities and world knowledge of large\nlanguage models, and augmented by the Segment Anything Model, VideoLISA\ngenerates temporally consistent segmentation masks in videos based on language\ninstructions. Existing image-based methods, such as LISA, struggle with video\ntasks due to the additional temporal dimension, which requires temporal dynamic\nunderstanding and consistent segmentation across frames. VideoLISA addresses\nthese challenges by integrating a Sparse Dense Sampling strategy into the\nvideo-LLM, which balances temporal context and spatial detail within\ncomputational constraints. Additionally, we propose a One-Token-Seg-All\napproach using a specially designed <TRK> token, enabling the model to segment\nand track objects across multiple frames. Extensive evaluations on diverse\nbenchmarks, including our newly introduced ReasonVOS benchmark, demonstrate\nVideoLISA's superior performance in video object segmentation tasks involving\ncomplex reasoning, temporal understanding, and object tracking. While optimized\nfor videos, VideoLISA also shows promising generalization to image\nsegmentation, revealing its potential as a unified foundation model for\nlanguage-instructed object segmentation. Code and model will be available at:\nhttps://github.com/showlab/VideoLISA.",
      "tldr_zh": "本研究引入了VideoLISA，一种基于视频的多模态大型语言模型，用于处理语言指令引导的视频推理分割任务。它整合大型语言模型的推理能力和Segment Anything Model，并通过Sparse Dense Sampling策略平衡时间上下文和空间细节，同时采用One-Token-Seg-All方法及<TRK>标记来实现跨帧对象分割和跟踪。相比现有图像方法，VideoLISA有效应对视频中的时间动态挑战，并在包括新基准ReasonVOS在内的多样评估中表现出色，提升了复杂推理、时间理解和对象跟踪的性能。作为一个统一的模型，VideoLISA还显示出在图像分割任务上的良好泛化潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurlPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.19603v1",
      "published_date": "2024-09-29 07:47:15 UTC",
      "updated_date": "2024-09-29 07:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:06:05.375084"
    },
    {
      "arxiv_id": "2409.19600v1",
      "title": "An Unbiased Risk Estimator for Partial Label Learning with Augmented Classes",
      "title_zh": "带有增强类的部分标签学习的",
      "authors": [
        "Jiayu Hu",
        "Senlin Shu",
        "Beibei Li",
        "Tao Xiang",
        "Zhongshi He"
      ],
      "abstract": "Partial Label Learning (PLL) is a typical weakly supervised learning task,\nwhich assumes each training instance is annotated with a set of candidate\nlabels containing the ground-truth label. Recent PLL methods adopt\nidentification-based disambiguation to alleviate the influence of false\npositive labels and achieve promising performance. However, they require all\nclasses in the test set to have appeared in the training set, ignoring the fact\nthat new classes will keep emerging in real applications. To address this\nissue, in this paper, we focus on the problem of Partial Label Learning with\nAugmented Class (PLLAC), where one or more augmented classes are not visible in\nthe training stage but appear in the inference stage. Specifically, we propose\nan unbiased risk estimator with theoretical guarantees for PLLAC, which\nestimates the distribution of augmented classes by differentiating the\ndistribution of known classes from unlabeled data and can be equipped with\narbitrary PLL loss functions. Besides, we provide a theoretical analysis of the\nestimation error bound of the estimator, which guarantees the convergence of\nthe empirical risk minimizer to the true risk minimizer as the number of\ntraining data tends to infinity. Furthermore, we add a risk-penalty\nregularization term in the optimization objective to alleviate the influence of\nthe over-fitting issue caused by negative empirical risk. Extensive experiments\non benchmark, UCI and real-world datasets demonstrate the effectiveness of the\nproposed approach.",
      "tldr_zh": "本研究针对 Partial Label Learning (PLL) 的局限性，提出了一种适用于 Partial Label Learning with Augmented Classes (PLLAC) 的 unbiased risk estimator，以处理训练集中未出现的增强类在推理阶段出现的问题。该方法通过区分已知类和未知类的分布来估计增强类的分布，并可与任意 PLL 损失函数结合，同时提供估计误差界的理论分析，确保经验风险最小化收敛到真实风险最小化。为缓解过拟合风险，该框架加入了风险惩罚正则化项。在基准、UCI 和真实世界数据集上的广泛实验证明，该方法显著提升了 PLLAC 的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.19600v1",
      "published_date": "2024-09-29 07:36:16 UTC",
      "updated_date": "2024-09-29 07:36:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:06:16.783237"
    },
    {
      "arxiv_id": "2409.19594v1",
      "title": "MASKDROID: Robust Android Malware Detection with Masked Graph Representations",
      "title_zh": "MASKDROID：基于掩码图表示的鲁棒 Android 恶意软件检测",
      "authors": [
        "Jingnan Zheng",
        "Jiaohao Liu",
        "An Zhang",
        "Jun Zeng",
        "Ziqi Yang",
        "Zhenkai Liang",
        "Tat-Seng Chua"
      ],
      "abstract": "Android malware attacks have posed a severe threat to mobile users,\nnecessitating a significant demand for the automated detection system. Among\nthe various tools employed in malware detection, graph representations (e.g.,\nfunction call graphs) have played a pivotal role in characterizing the\nbehaviors of Android apps. However, though achieving impressive performance in\nmalware detection, current state-of-the-art graph-based malware detectors are\nvulnerable to adversarial examples. These adversarial examples are meticulously\ncrafted by introducing specific perturbations to normal malicious inputs. To\ndefend against adversarial attacks, existing defensive mechanisms are typically\nsupplementary additions to detectors and exhibit significant limitations, often\nrelying on prior knowledge of adversarial examples and failing to defend\nagainst unseen types of attacks effectively. In this paper, we propose\nMASKDROID, a powerful detector with a strong discriminative ability to identify\nmalware and remarkable robustness against adversarial attacks. Specifically, we\nintroduce a masking mechanism into the Graph Neural Network (GNN) based\nframework, forcing MASKDROID to recover the whole input graph using a small\nportion (e.g., 20%) of randomly selected nodes.This strategy enables the model\nto understand the malicious semantics and learn more stable representations,\nenhancing its robustness against adversarial attacks. While capturing stable\nmalicious semantics in the form of dependencies inside the graph structures, we\nfurther employ a contrastive module to encourage MASKDROID to learn more\ncompact representations for both the benign and malicious classes to boost its\ndiscriminative power in detecting malware from benign apps and adversarial\nexamples.",
      "tldr_zh": "该论文针对 Android 恶意软件检测面临的对抗攻击问题，提出 MASKDROID 框架，该框架利用 Masked Graph Representations 在 Graph Neural Network (GNN) 中引入 masking 机制，让模型仅通过少量节点（如 20%）恢复整个输入图，从而学习更稳定的恶意语义表示。MASKDROID 还整合 contrastive module 来增强表示的紧凑性，提高对恶意软件、良性应用和对抗样本的区分能力。与现有方法相比，该框架无需依赖对抗样本的先验知识，能有效防御未知攻击，为 robust Android malware detection 提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19594v1",
      "published_date": "2024-09-29 07:22:47 UTC",
      "updated_date": "2024-09-29 07:22:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:06:29.535396"
    },
    {
      "arxiv_id": "2409.19573v1",
      "title": "See then Tell: Enhancing Key Information Extraction with Vision Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhang Liu",
        "Zhenrong Zhang",
        "Pengfei Hu",
        "Jiefeng Ma",
        "Jun Du",
        "Qing Wang",
        "Jianshu Zhang",
        "Chenyu Liu"
      ],
      "abstract": "In the digital era, the ability to understand visually rich documents that\nintegrate text, complex layouts, and imagery is critical. Traditional Key\nInformation Extraction (KIE) methods primarily rely on Optical Character\nRecognition (OCR), which often introduces significant latency, computational\noverhead, and errors. Current advanced image-to-text approaches, which bypass\nOCR, typically yield plain text outputs without corresponding vision grounding.\nIn this paper, we introduce STNet (See then Tell Net), a novel end-to-end model\ndesigned to deliver precise answers with relevant vision grounding.\nDistinctively, STNet utilizes a unique <see> token to observe pertinent image\nareas, aided by a decoder that interprets physical coordinates linked to this\ntoken. Positioned at the outset of the answer text, the <see> token allows the\nmodel to first see--observing the regions of the image related to the input\nquestion--and then tell--providing articulated textual responses. To enhance\nthe model's seeing capabilities, we collect extensive structured table\nrecognition datasets. Leveraging the advanced text processing prowess of GPT-4,\nwe develop the TVG (TableQA with Vision Grounding) dataset, which not only\nprovides text-based Question Answering (QA) pairs but also incorporates precise\nvision grounding for these pairs. Our approach demonstrates substantial\nadvancements in KIE performance, achieving state-of-the-art results on publicly\navailable datasets such as CORD, SROIE, and DocVQA. The code will also be made\npublicly available.",
      "tldr_zh": "这篇论文针对视觉丰富文档的关键信息提取（Key Information Extraction, KIE）问题，提出了一种新型端到端模型 STNet，以 Optical Character Recognition (OCR) 的局限性（如延迟和错误）为切入点，通过引入 <see> 标记实现视觉 grounding，先观察相关图像区域再生成精确文本答案。作者开发了 TVG (TableQA with Vision Grounding) 数据集，利用 GPT-4 处理结构化表格识别任务，提供文本 QA 对和精确视觉 grounding，以增强模型性能。实验结果显示，STNet 在 CORD、SROIE 和 DocVQA 等公开数据集上取得了最先进的结果，代码也将公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19573v1",
      "published_date": "2024-09-29 06:21:05 UTC",
      "updated_date": "2024-09-29 06:21:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:06:44.480301"
    },
    {
      "arxiv_id": "2409.19572v1",
      "title": "Mitigating the Negative Impact of Over-association for Conversational Query Production",
      "title_zh": "翻译失败",
      "authors": [
        "Ante Wang",
        "Linfeng Song",
        "Zijun Min",
        "Ge Xu",
        "Xiaoli Wang",
        "Junfeng Yao",
        "Jinsong Su"
      ],
      "abstract": "Conversational query generation aims at producing search queries from\ndialogue histories, which are then used to retrieve relevant knowledge from a\nsearch engine to help knowledge-based dialogue systems. Trained to maximize the\nlikelihood of gold queries, previous models suffer from the data hunger issue,\nand they tend to both drop important concepts from dialogue histories and\ngenerate irrelevant concepts at inference time. We attribute these issues to\nthe over-association phenomenon where a large number of gold queries are\nindirectly related to the dialogue topics, because annotators may unconsciously\nperform reasoning with their background knowledge when generating these gold\nqueries. We carefully analyze the negative effects of this phenomenon on\npretrained Seq2seq query producers and then propose effective instance-level\nweighting strategies for training to mitigate these issues from multiple\nperspectives. Experiments on two benchmarks, Wizard-of-Internet and DuSinc,\nshow that our strategies effectively alleviate the negative effects and lead to\nsignificant performance gains (2%-5% across automatic metrics and human\nevaluation). Further analysis shows that our model selects better concepts from\ndialogue histories and is 10 times more data efficient than the baseline. The\ncode is available at https://github.com/DeepLearnXMU/QG-OverAsso.",
      "tldr_zh": "这篇论文针对对话查询生成（conversational query production）中的过关联现象（over-association）问题，分析了其负面影响，包括模型在推理时丢弃对话历史中的重要概念并生成无关内容，该问题源于标注者背景知识的干扰。作者提出有效的实例级加权策略（instance-level weighting strategies），用于从多个角度优化预训练Seq2seq查询生成器的训练过程，以缓解数据饥饿和过关联问题。实验在Wizard-of-Internet和DuSinc基准上证明，该策略显著提升了性能（自动指标和人工评估提高2%-5%），并使模型更好地选择对话历史中的概念，同时数据效率提高了10倍。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Information Processing & Management",
      "pdf_url": "http://arxiv.org/pdf/2409.19572v1",
      "published_date": "2024-09-29 06:19:59 UTC",
      "updated_date": "2024-09-29 06:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:06:56.578561"
    },
    {
      "arxiv_id": "2409.19566v1",
      "title": "Abstractive Summarization of Low resourced Nepali language using Multilingual Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Prakash Dhakal",
        "Daya Sagar Baral"
      ],
      "abstract": "Automatic text summarization in Nepali language is an unexplored area in\nnatural language processing (NLP). Although considerable research has been\ndedicated to extractive summarization, the area of abstractive summarization,\nespecially for low-resource languages such as Nepali, remains largely\nunexplored. This study explores the use of multilingual transformer models,\nspecifically mBART and mT5, for generating headlines for Nepali news articles\nthrough abstractive summarization. The research addresses key challenges\nassociated with summarizing texts in Nepali by first creating a summarization\ndataset through web scraping from various Nepali news portals. These\nmultilingual models were then fine-tuned using different strategies. The\nperformance of the fine-tuned models were then assessed using ROUGE scores and\nhuman evaluation to ensure the generated summaries were coherent and conveyed\nthe original meaning. During the human evaluation, the participants were asked\nto select the best summary among those generated by the models, based on\ncriteria such as relevance, fluency, conciseness, informativeness, factual\naccuracy, and coverage. During the evaluation with ROUGE scores, the 4-bit\nquantized mBART with LoRA model was found to be effective in generating better\nNepali news headlines in comparison to other models and also it was selected\n34.05% of the time during the human evaluation, outperforming all other\nfine-tuned models created for Nepali News headline generation.",
      "tldr_zh": "这篇论文探讨了使用多语言Transformer模型（如mBART和mT5）对低资源语言Nepali进行抽象摘要生成，专注于为Nepali新闻文章创建标题，以填补该领域的空白。研究团队通过从Nepali新闻门户网站抓取数据构建了摘要数据集，并采用各种策略对模型进行微调，包括4-bit量化技术。评估结果显示，量化mBART结合LoRA模型在ROUGE scores和人工评估中表现最佳，在人工评估中被选为最佳摘要的34.05%，在相关性、流畅性和准确性等方面优于其他模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19566v1",
      "published_date": "2024-09-29 05:58:27 UTC",
      "updated_date": "2024-09-29 05:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:07:07.493872"
    },
    {
      "arxiv_id": "2409.19563v1",
      "title": "CLIP-based Camera-Agnostic Feature Learning for Intra-camera Person Re-Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Tan",
        "Xun Gong",
        "Yang Xiang"
      ],
      "abstract": "Contrastive Language-Image Pre-Training (CLIP) model excels in traditional\nperson re-identification (ReID) tasks due to its inherent advantage in\ngenerating textual descriptions for pedestrian images. However, applying CLIP\ndirectly to intra-camera supervised person re-identification (ICS ReID)\npresents challenges. ICS ReID requires independent identity labeling within\neach camera, without associations across cameras. This limits the effectiveness\nof text-based enhancements. To address this, we propose a novel framework\ncalled CLIP-based Camera-Agnostic Feature Learning (CCAFL) for ICS ReID.\nAccordingly, two custom modules are designed to guide the model to actively\nlearn camera-agnostic pedestrian features: Intra-Camera Discriminative Learning\n(ICDL) and Inter-Camera Adversarial Learning (ICAL). Specifically, we first\nestablish learnable textual prompts for intra-camera pedestrian images to\nobtain crucial semantic supervision signals for subsequent intra- and\ninter-camera learning. Then, we design ICDL to increase inter-class variation\nby considering the hard positive and hard negative samples within each camera,\nthereby learning intra-camera finer-grained pedestrian features. Additionally,\nwe propose ICAL to reduce inter-camera pedestrian feature discrepancies by\npenalizing the model's ability to predict the camera from which a pedestrian\nimage originates, thus enhancing the model's capability to recognize\npedestrians from different viewpoints. Extensive experiments on popular ReID\ndatasets demonstrate the effectiveness of our approach. Especially, on the\nchallenging MSMT17 dataset, we arrive at 58.9\\% in terms of mAP accuracy,\nsurpassing state-of-the-art methods by 7.6\\%. Code will be available at:\nhttps://github.com/Trangle12/CCAFL.",
      "tldr_zh": "本论文针对 intra-camera supervised person re-identification (ICS ReID) 的挑战，提出 CLIP-based Camera-Agnostic Feature Learning (CCAFL) 框架，以解决 CLIP 模型在摄像头内身份标记时无法有效处理跨摄像头关联的问题。\n框架设计了两个关键模块：Intra-Camera Discriminative Learning (ICDL)，通过考虑摄像头内的 hard positive 和 hard negative 样本来增强行人特征的细粒度区分；以及 Inter-Camera Adversarial Learning (ICAL)，通过惩罚模型预测图像来源摄像头的能力，减少跨摄像头特征差异。\n实验在流行 ReID 数据集上验证了该方法的有效性，尤其在 MSMT17 数据集上，mAP 准确率达到 58.9%，比最先进方法提高了 7.6%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to IEEE TCSVT",
      "pdf_url": "http://arxiv.org/pdf/2409.19563v1",
      "published_date": "2024-09-29 05:43:01 UTC",
      "updated_date": "2024-09-29 05:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:07:21.495272"
    },
    {
      "arxiv_id": "2409.19552v3",
      "title": "OmniXAS: A Universal Deep-Learning Framework for Materials X-ray Absorption Spectra",
      "title_zh": "OmniXAS：一种用于材料X射线吸收光谱的",
      "authors": [
        "Shubha R. Kharel",
        "Fanchen Meng",
        "Xiaohui Qu",
        "Matthew R. Carbone",
        "Deyu Lu"
      ],
      "abstract": "X-ray absorption spectroscopy (XAS) is a powerful characterization technique\nfor probing the local chemical environment of absorbing atoms. However,\nanalyzing XAS data presents significant challenges, often requiring extensive,\ncomputationally intensive simulations, as well as significant domain expertise.\nThese limitations hinder the development of fast, robust XAS analysis pipelines\nthat are essential in high-throughput studies and for autonomous\nexperimentation. We address these challenges with OmniXAS, a framework that\ncontains a suite of transfer learning approaches for XAS prediction, each\ncontributing to improved accuracy and efficiency, as demonstrated on K-edge\nspectra database covering eight 3d transition metals (Ti-Cu). The OmniXAS\nframework is built upon three distinct strategies. First, we use M3GNet to\nderive latent representations of the local chemical environment of absorption\nsites as input for XAS prediction, achieving up to order-of-magnitude\nimprovements over conventional featurization techniques. Second, we employ a\nhierarchical transfer learning strategy, training a universal multi-task model\nacross elements before fine-tuning for element-specific predictions. Models\nbased on this cascaded approach after element-wise fine-tuning outperform\nelement-specific models by up to 69%. Third, we implement cross-fidelity\ntransfer learning, adapting a universal model to predict spectra generated by\nsimulation of a different fidelity with a higher computational cost. This\napproach improves prediction accuracy by up to 11% over models trained on the\ntarget fidelity alone. Our approach boosts the throughput of XAS modeling by\norders of magnitude versus first-principles simulations and is extendable to\nXAS prediction for a broader range of elements. This transfer learning\nframework is generalizable to enhance deep-learning models that target other\nproperties in materials research.",
      "tldr_zh": "本论文提出了 OmniXAS，一种通用的深度学习框架，用于提升材料 X-ray 吸收光谱 (XAS) 的预测准确性和效率，以解决传统分析的计算密集和专业知识依赖问题。该框架基于三种转移学习策略：首先，使用 M3GNet 提取吸收位点局部化学环境的潜在表示，比传统特征化方法提高一个数量级；其次，采用层次化转移学习，先训练通用多任务模型再针对特定元素微调，性能比元素特定模型提升多达 69%；第三，实现跨保真度转移学习，使模型适应不同模拟保真度，提高预测准确性达 11%。在覆盖 Ti-Cu 的 K-edge 谱数据库上实验验证，OmniXAS 显著提升了 XAS 建模的吞吐量，比第一性原理模拟快几个数量级。该框架可扩展到更多元素和材料属性的深度学习应用。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "Main manuscript: 23 pages, 14 figures. Supplemental material (13\n  pages, 6 figures) available as a separate file in arXiv ancillary files\n  (additional downloadable files)",
      "pdf_url": "http://arxiv.org/pdf/2409.19552v3",
      "published_date": "2024-09-29 04:41:10 UTC",
      "updated_date": "2025-04-15 17:22:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:07:35.477576"
    },
    {
      "arxiv_id": "2410.10834v1",
      "title": "Focus On What Matters: Separated Models For Visual-Based RL Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Di Zhang",
        "Bowen Lv",
        "Hai Zhang",
        "Feifan Yang",
        "Junqiao Zhao",
        "Hang Yu",
        "Chang Huang",
        "Hongtu Zhou",
        "Chen Ye",
        "Changjun Jiang"
      ],
      "abstract": "A primary challenge for visual-based Reinforcement Learning (RL) is to\ngeneralize effectively across unseen environments. Although previous studies\nhave explored different auxiliary tasks to enhance generalization, few adopt\nimage reconstruction due to concerns about exacerbating overfitting to\ntask-irrelevant features during training. Perceiving the pre-eminence of image\nreconstruction in representation learning, we propose SMG (Separated Models for\nGeneralization), a novel approach that exploits image reconstruction for\ngeneralization. SMG introduces two model branches to extract task-relevant and\ntask-irrelevant representations separately from visual observations via\ncooperatively reconstruction. Built upon this architecture, we further\nemphasize the importance of task-relevant features for generalization.\nSpecifically, SMG incorporates two additional consistency losses to guide the\nagent's focus toward task-relevant areas across different scenarios, thereby\nachieving free from overfitting. Extensive experiments in DMC demonstrate the\nSOTA performance of SMG in generalization, particularly excelling in\nvideo-background settings. Evaluations on robotic manipulation tasks further\nconfirm the robustness of SMG in real-world applications.",
      "tldr_zh": "本研究针对视觉-based Reinforcement Learning (RL) 在未见环境中的泛化挑战，提出了一种新型框架 SMG (Separated Models for Generalization)。SMG 通过两个模型分支分别提取任务相关和任务无关的表示，利用图像重建技术进行合作重建，从而避免对任务无关特征的过拟合。框架进一步引入两个 consistency losses，引导代理重点关注任务相关区域，以提升泛化能力。实验结果显示，SMG 在 DMC 环境上达到 SOTA 性能，尤其在视频背景设置中表现出色，并在真实机器人操作任务中证明了其鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10834v1",
      "published_date": "2024-09-29 04:37:56 UTC",
      "updated_date": "2024-09-29 04:37:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:07:43.977642"
    },
    {
      "arxiv_id": "2410.03723v1",
      "title": "Human Bias in the Face of AI: The Role of Human Judgement in AI Generated Text Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Tiffany Zhu",
        "Iain Weissburg",
        "Kexun Zhang",
        "William Yang Wang"
      ],
      "abstract": "As AI advances in text generation, human trust in AI generated content\nremains constrained by biases that go beyond concerns of accuracy. This study\nexplores how bias shapes the perception of AI versus human generated content.\nThrough three experiments involving text rephrasing, news article\nsummarization, and persuasive writing, we investigated how human raters respond\nto labeled and unlabeled content. While the raters could not differentiate the\ntwo types of texts in the blind test, they overwhelmingly favored content\nlabeled as \"Human Generated,\" over those labeled \"AI Generated,\" by a\npreference score of over 30%. We observed the same pattern even when the labels\nwere deliberately swapped. This human bias against AI has broader societal and\ncognitive implications, as it undervalues AI performance. This study highlights\nthe limitations of human judgment in interacting with AI and offers a\nfoundation for improving human-AI collaboration, especially in creative fields.",
      "tldr_zh": "这篇论文探讨了人类在评估 AI 生成文本时的偏见，以及人类判断在其中的作用。研究通过三个实验（包括文本重述、新闻摘要和说服性写作）发现，虽然评估者在盲测中无法区分 AI 和人类生成内容，但他们显著偏好标记为“Human Generated”的文本，偏好分数超过30%，即使标签被交换这种偏见依然存在。该研究揭示了人类对 AI 的认知偏差可能低估 AI 性能，并为提升人类-AI 协作，尤其是创意领域，提供重要基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.03723v1",
      "published_date": "2024-09-29 04:31:45 UTC",
      "updated_date": "2024-09-29 04:31:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:07:56.447124"
    },
    {
      "arxiv_id": "2409.19546v4",
      "title": "Asymptotic and Finite Sample Analysis of Nonexpansive Stochastic Approximations with Markovian Noise",
      "title_zh": "翻译失败",
      "authors": [
        "Ethan Blaser",
        "Shangtong Zhang"
      ],
      "abstract": "Stochastic approximation is an important class of algorithms, and a large\nbody of previous analysis focuses on stochastic approximations driven by\ncontractive operators, which is not applicable in some important reinforcement\nlearning settings. This work instead investigates stochastic approximations\nwith merely nonexpansive operators. In particular, we study nonexpansive\nstochastic approximations with Markovian noise, providing both asymptotic and\nfinite sample analysis. Key to our analysis are a few novel bounds of noise\nterms resulting from the Poisson equation. As an application, we prove, for the\nfirst time, that the classical tabular average reward temporal difference\nlearning converges to a sample path dependent fixed point.",
      "tldr_zh": "本研究分析了带有 Markovian 噪声的非膨胀随机逼近（Nonexpansive Stochastic Approximations）的渐近分析（Asymptotic Analysis）和有限样本分析（Finite Sample Analysis），填补了传统基于收缩算子（Contractive Operators）的分析在强化学习中的局限性。论文通过 Poisson 方程引入的创新噪声项边界，提供了更精确的收敛保证。作为应用，该方法首次证明了经典的表格平均奖励时间差分学习（Tabular Average Reward Temporal Difference Learning）收敛到一个样本路径相关的固定点，这为强化学习算法的鲁棒性提升提供了新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19546v4",
      "published_date": "2024-09-29 04:16:24 UTC",
      "updated_date": "2025-02-03 22:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:08:08.178076"
    },
    {
      "arxiv_id": "2410.12798v1",
      "title": "Design of an Efficient Fan-Shaped Clustered Trust-Based Routing Model with QoS & Security-Aware Side-Chaining for IoV Deployments",
      "title_zh": "翻译失败",
      "authors": [
        "Sadaf Ravindra Suryawanshi",
        "Praveen Gupta"
      ],
      "abstract": "The rapid expansion of Internet of Vehicles (IoV) deployments has\nnecessitated the creation of efficient and secure routing models to manage the\nmassive data traffic generated by interconnected devices & vehicles. For IoV\ndeployments, we propose a novel fan-shaped trust-based routing model with\nQuality of Service (QoS) and security-aware side-chaining. Our method employs\ntemporal levels of delay, throughput, Packet Delivery Ratio (PDR), and energy\nconsumption to determine optimal routing paths, thereby ensuring efficient data\ntransmissions. We employ the Bacterial Foraging Optimizer (BFO) algorithm to\nmanage side-chains within the network, which dynamically adjusts side-chain\nconfigurations to optimize system performance. The technique of fan-shaped\nclustering is used to group nodes into efficient clusters, allowing for more\nefficient communication and resource utilization sets. Extensive\nexperimentation and performance analysis are utilized to evaluate the proposed\nmodel. Existing blockchain-based security models have been significantly\nimproved by our findings. Our model achieves a remarkable 9.5% reduction in\ndelay, a 10.5% improvement in throughput, a 2.9% improvement in PDR, and a 4.5%\nreduction in energy consumption compared to alternative approaches. In\naddition, we evaluate the model's resistance to Sybil, Masquerading, and\nFlooding attacks, which are prevalent security threats for IoV deployments.\nEven under these attack scenarios, our model provides consistently higher QoS\nlevels compared to existing solutions, ensuring uninterrupted and reliable data\ntransmissions. In IoV deployments, the proposed routing model and side-chaining\nmanagement approach have numerous applications and use-cases like Smart cities,\nindustrial automation, healthcare systems, transportation networks, and\nenvironmental monitoring.",
      "tldr_zh": "该论文针对Internet of Vehicles (IoV) 部署提出了一种高效的扇形聚类信任-based路由模型，结合Quality of Service (QoS) 和安全aware的side-chaining，以优化数据传输并提升安全性。该模型利用Bacterial Foraging Optimizer (BFO) 算法动态管理side-chains，并基于延迟、吞吐量、Packet Delivery Ratio (PDR) 和能量消耗确定最佳路由路径，同时通过扇形聚类分组节点以提高通信效率。实验结果显示，与现有方法相比，该模型实现了延迟减少9.5%、吞吐量提高10.5%、PDR提升2.9%和能量消耗减少4.5%，并在Sybil、Masquerading和Flooding攻击场景下维持更高QoS水平，适用于智能城市、工业自动化和医疗系统等应用。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "https://ijisae.org/index.php/IJISAE/article/view/3770",
      "pdf_url": "http://arxiv.org/pdf/2410.12798v1",
      "published_date": "2024-09-29 03:58:50 UTC",
      "updated_date": "2024-09-29 03:58:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:08:20.929856"
    },
    {
      "arxiv_id": "2409.19541v3",
      "title": "Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Shahed Masoudian",
        "Markus Frohmann",
        "Navid Rekabsaz",
        "Markus Schedl"
      ],
      "abstract": "Language models frequently inherit societal biases from their training data.\nNumerous techniques have been proposed to mitigate these biases during both the\npre-training and fine-tuning stages. However, fine-tuning a pre-trained\ndebiased language model on a downstream task can reintroduce biases into the\nmodel. Additionally, existing debiasing methods for downstream tasks either (i)\nrequire labels of protected attributes (e.g., age, race, or political views)\nthat are often not available or (ii) rely on indicators of bias, which\nrestricts their applicability to gender debiasing since they rely on\ngender-specific words. To address this, we introduce a novel debiasing\nregularization technique based on the class-wise variance of embeddings.\nCrucially, our method does not require attribute labels and targets any\nattribute, thus addressing the shortcomings of existing debiasing methods. Our\nexperiments on encoder language models and three datasets demonstrate that our\nmethod outperforms existing strong debiasing baselines that rely on target\nattribute labels while maintaining performance on the target task.",
      "tldr_zh": "语言模型在训练数据中常继承社会偏见，而现有下游任务(Unlabeled Debiasing)方法要么需要保护属性标签（如年龄、种族），要么仅限于特定偏见如性别。  \n本文提出一种新型去偏见正则化技术，通过Class-wise Low Variance Regularization来最小化嵌入的类别-wise 方差，从而无需属性标签即可针对任何属性进行去偏见。  \n实验结果显示，在编码器语言模型和三个数据集上，该方法优于依赖标签的基线，同时保持了目标任务的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.19541v3",
      "published_date": "2024-09-29 03:56:50 UTC",
      "updated_date": "2024-10-02 04:15:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:08:31.903554"
    },
    {
      "arxiv_id": "2409.19531v1",
      "title": "Understanding Clinical Decision-Making in Traditional East Asian Medicine through Dimensionality Reduction: An Empirical Investigation",
      "title_zh": "翻译失败",
      "authors": [
        "Hyojin Bae",
        "Bongsu Kang",
        "Chang-Eop Kim"
      ],
      "abstract": "This study examines the clinical decision-making processes in Traditional\nEast Asian Medicine (TEAM) by reinterpreting pattern identification (PI)\nthrough the lens of dimensionality reduction. Focusing on the Eight Principle\nPattern Identification (EPPI) system and utilizing empirical data from the\nShang-Han-Lun, we explore the necessity and significance of prioritizing the\nExterior-Interior pattern in diagnosis and treatment selection. We test three\nhypotheses: whether the Ext-Int pattern contains the most information about\npatient symptoms, represents the most abstract and generalizable symptom\ninformation, and facilitates the selection of appropriate herbal prescriptions.\nEmploying quantitative measures such as the abstraction index,\ncross-conditional generalization performance, and decision tree regression, our\nresults demonstrate that the Exterior-Interior pattern represents the most\nabstract and generalizable symptom information, contributing to the efficient\nmapping between symptom and herbal prescription spaces. This research provides\nan objective framework for understanding the cognitive processes underlying\nTEAM, bridging traditional medical practices with modern computational\napproaches. The findings offer insights into the development of AI-driven\ndiagnostic tools in TEAM and conventional medicine, with the potential to\nadvance clinical practice, education, and research.",
      "tldr_zh": "本研究通过维度降低 (dimensionality reduction) 重新解读传统东亚医学 (Traditional East Asian Medicine, TEAM) 中的模式识别 (pattern identification)，特别聚焦于八原则模式识别 (Eight Principle Pattern Identification, EPPI) 系统，并利用《伤寒论》(Shang-Han-Lun) 的经验数据。研究测试了三个假设，包括 Exterior-Interior (Ext-Int) 模式是否包含最多症状信息、代表最抽象和可泛化的信息，以及是否促进草药处方的选择，采用量化措施如 abstraction index、cross-conditional generalization performance 和 decision tree regression。结果显示，Ext-Int 模式确实提供最抽象和可泛化的症状信息，有助于症状与草药处方空间的效率映射，为理解 TEAM 的认知过程提供客观框架，并推动 AI 驱动诊断工具的开发以提升临床实践、教育和研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "J.3; I.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.19531v1",
      "published_date": "2024-09-29 03:28:19 UTC",
      "updated_date": "2024-09-29 03:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:08:44.544953"
    },
    {
      "arxiv_id": "2409.19527v2",
      "title": "BuildingView: Constructing Urban Building Exteriors Databases with Street View Imagery and Multimodal Large Language Mode",
      "title_zh": "翻译失败",
      "authors": [
        "Zongrong Li",
        "Yunlei Su",
        "Hongrong Wang",
        "Wufan Zhao"
      ],
      "abstract": "Urban Building Exteriors are increasingly important in urban analytics,\ndriven by advancements in Street View Imagery and its integration with urban\nresearch. Multimodal Large Language Models (LLMs) offer powerful tools for\nurban annotation, enabling deeper insights into urban environments. However,\nchallenges remain in creating accurate and detailed urban building exterior\ndatabases, identifying critical indicators for energy efficiency, environmental\nsustainability, and human-centric design, and systematically organizing these\nindicators. To address these challenges, we propose BuildingView, a novel\napproach that integrates high-resolution visual data from Google Street View\nwith spatial information from OpenStreetMap via the Overpass API. This research\nimproves the accuracy of urban building exterior data, identifies key\nsustainability and design indicators, and develops a framework for their\nextraction and categorization. Our methodology includes a systematic literature\nreview, building and Street View sampling, and annotation using the ChatGPT-4O\nAPI. The resulting database, validated with data from New York City, Amsterdam,\nand Singapore, provides a comprehensive tool for urban studies, supporting\ninformed decision-making in urban planning, architectural design, and\nenvironmental policy. The code for BuildingView is available at\nhttps://github.com/Jasper0122/BuildingView.",
      "tldr_zh": "本研究针对城市建筑外部数据库的构建挑战，利用街景图像和Multimodal Large Language Models (LLMs)，提出了BuildingView框架，以整合Google Street View的高分辨率视觉数据和OpenStreetMap的空間信息（通过Overpass API）。该方法包括系统文献综述、建筑采样以及使用ChatGPT-4O API进行标注，从而准确识别能源效率、环境可持续性和以人为本设计的關鍵指标。实验在纽约市、阿姆斯特丹和新加坡验证了框架的有效性，提供了一个全面数据库，支持城市规划、建筑设计和环境政策的决策。代码开源在GitHub上。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.19527v2",
      "published_date": "2024-09-29 03:00:16 UTC",
      "updated_date": "2025-03-07 03:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:08:57.035926"
    },
    {
      "arxiv_id": "2409.19526v1",
      "title": "Efficient Backdoor Defense in Multimodal Contrastive Learning: A Token-Level Unlearning Method for Mitigating Threats",
      "title_zh": "翻译失败",
      "authors": [
        "Kuanrong Liu",
        "Siyuan Liang",
        "Jiawei Liang",
        "Pengwen Dai",
        "Xiaochun Cao"
      ],
      "abstract": "Multimodal contrastive learning uses various data modalities to create\nhigh-quality features, but its reliance on extensive data sources on the\nInternet makes it vulnerable to backdoor attacks. These attacks insert\nmalicious behaviors during training, which are activated by specific triggers\nduring inference, posing significant security risks. Despite existing\ncountermeasures through fine-tuning that reduce the malicious impacts of such\nattacks, these defenses frequently necessitate extensive training time and\ndegrade clean accuracy. In this study, we propose an efficient defense\nmechanism against backdoor threats using a concept known as machine unlearning.\nThis entails strategically creating a small set of poisoned samples to aid the\nmodel's rapid unlearning of backdoor vulnerabilities, known as Unlearn Backdoor\nThreats (UBT). We specifically use overfit training to improve backdoor\nshortcuts and accurately detect suspicious samples in the potential poisoning\ndata set. Then, we select fewer unlearned samples from suspicious samples for\nrapid forgetting in order to eliminate the backdoor effect and thus improve\nbackdoor defense efficiency. In the backdoor unlearning process, we present a\nnovel token-based portion unlearning training regime. This technique focuses on\nthe model's compromised elements, dissociating backdoor correlations while\nmaintaining the model's overall integrity. Extensive experimental results show\nthat our method effectively defends against various backdoor attack methods in\nthe CLIP model. Compared to SoTA backdoor defense methods, UBT achieves the\nlowest attack success rate while maintaining a high clean accuracy of the model\n(attack success rate decreases by 19% compared to SOTA, while clean accuracy\nincreases by 2.57%).",
      "tldr_zh": "本研究针对多模态对比学习（multimodal contrastive learning）中易受后门攻击（backdoor attacks）的漏洞，提出了一种高效防御机制，名为 Unlearn Backdoor Threats (UBT)。该方法利用机器 unlearning 概念，通过创建一小套中毒样本并进行过拟合训练，检测可疑样本并从中选择少量样本进行快速遗忘，从而消除后门效应。UBT 引入了新型 token-based portion unlearning 训练机制，专注于模型的受损部分，解除后门相关性，同时保持模型整体完整性。实验结果显示，在 CLIP 模型上，该方法比 SOTA 防御方法将攻击成功率降低 19%，并将干净准确率提高 2.57%。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19526v1",
      "published_date": "2024-09-29 02:55:38 UTC",
      "updated_date": "2024-09-29 02:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:09:08.846982"
    },
    {
      "arxiv_id": "2409.19518v1",
      "title": "KODA: A Data-Driven Recursive Model for Time Series Forecasting and Data Assimilation using Koopman Operators",
      "title_zh": "翻译失败",
      "authors": [
        "Ashutosh Singh",
        "Ashish Singh",
        "Tales Imbiriba",
        "Deniz Erdogmus",
        "Ricardo Borsoi"
      ],
      "abstract": "Approaches based on Koopman operators have shown great promise in forecasting\ntime series data generated by complex nonlinear dynamical systems (NLDS).\nAlthough such approaches are able to capture the latent state representation of\na NLDS, they still face difficulty in long term forecasting when applied to\nreal world data. Specifically many real-world NLDS exhibit time-varying\nbehavior, leading to nonstationarity that is hard to capture with such models.\nFurthermore they lack a systematic data-driven approach to perform data\nassimilation, that is, exploiting noisy measurements on the fly in the\nforecasting task. To alleviate the above issues, we propose a Koopman\noperator-based approach (named KODA - Koopman Operator with Data Assimilation)\nthat integrates forecasting and data assimilation in NLDS. In particular we use\na Fourier domain filter to disentangle the data into a physical component whose\ndynamics can be accurately represented by a Koopman operator, and residual\ndynamics that represents the local or time varying behavior that are captured\nby a flexible and learnable recursive model. We carefully design an\narchitecture and training criterion that ensures this decomposition lead to\nstable and long-term forecasts. Moreover, we introduce a course correction\nstrategy to perform data assimilation with new measurements at inference time.\nThe proposed approach is completely data-driven and can be learned end-to-end.\nThrough extensive experimental comparisons we show that KODA outperforms\nexisting state of the art methods on multiple time series benchmarks such as\nelectricity, temperature, weather, lorenz 63 and duffing oscillator\ndemonstrating its superior performance and efficacy along the three tasks a)\nforecasting, b) data assimilation and c) state prediction.",
      "tldr_zh": "本研究提出KODA模型，一种基于Koopman算子的数据驱动递归方法，用于处理复杂非线性动态系统(NLDS)的时间序列预测和数据同化问题，以解决现有方法在长期预测和非平稳数据方面的局限性。KODA通过Fourier域滤波器将数据分解为物理成分（由Koopman算子表示）和残差动态（由可学习的递归模型捕获），并设计了架构和训练标准确保稳定预测，同时引入课程修正策略在推理时整合噪声测量进行数据同化。该模型完全数据驱动且可端到端学习，在多个基准如electricity、temperature、weather、Lorenz 63和Duffing oscillator上，显著超越现有方法，在预测、数据同化和状态预测任务中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19518v1",
      "published_date": "2024-09-29 02:25:48 UTC",
      "updated_date": "2024-09-29 02:25:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:09:21.127975"
    },
    {
      "arxiv_id": "2409.19513v1",
      "title": "One Node Per User: Node-Level Federated Learning for Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Zhidong Gao",
        "Yuanxiong Guo",
        "Yanmin Gong"
      ],
      "abstract": "Graph Neural Networks (GNNs) training often necessitates gathering raw user\ndata on a central server, which raises significant privacy concerns. Federated\nlearning emerges as a solution, enabling collaborative model training without\nusers directly sharing their raw data. However, integrating federated learning\nwith GNNs presents unique challenges, especially when a client represents a\ngraph node and holds merely a single feature vector. In this paper, we propose\na novel framework for node-level federated graph learning. Specifically, we\ndecouple the message-passing and feature vector transformation processes of the\nfirst GNN layer, allowing them to be executed separately on the user devices\nand the cloud server. Moreover, we introduce a graph Laplacian term based on\nthe feature vector's latent representation to regulate the user-side model\nupdates. The experiment results on multiple datasets show that our approach\nachieves better performance compared with baselines.",
      "tldr_zh": "该论文针对Graph Neural Networks (GNNs) 训练中数据隐私问题，提出一种节点级联邦学习框架（One Node Per User），允许用户设备仅处理单个特征向量而不共享原始数据。框架的核心方法是解耦GNN第一层的消息传递和特征向量转换过程，将它们分别在用户设备和云服务器上执行，并引入基于特征向量潜在表示的图拉普拉斯项来调节用户端模型更新。这种设计有效解决了联邦学习与GNNs整合的挑战。实验结果显示，该框架在多个数据集上比基线方法表现出更好的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.19513v1",
      "published_date": "2024-09-29 02:16:07 UTC",
      "updated_date": "2024-09-29 02:16:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:09:32.243309"
    },
    {
      "arxiv_id": "2410.10833v1",
      "title": "Online Client Scheduling and Resource Allocation for Efficient Federated Edge Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhidong Gao",
        "Zhenxiao Zhang",
        "Yu Zhang",
        "Tongnian Wang",
        "Yanmin Gong",
        "Yuanxiong Guo"
      ],
      "abstract": "Federated learning (FL) enables edge devices to collaboratively train a\nmachine learning model without sharing their raw data. Due to its\nprivacy-protecting benefits, FL has been deployed in many real-world\napplications. However, deploying FL over mobile edge networks with constrained\nresources such as power, bandwidth, and computation suffers from high training\nlatency and low model accuracy, particularly under data and system\nheterogeneity. In this paper, we investigate the optimal client scheduling and\nresource allocation for FL over mobile edge networks under resource constraints\nand uncertainty to minimize the training latency while maintaining the model\naccuracy. Specifically, we first analyze the impact of client sampling on model\nconvergence in FL and formulate a stochastic optimization problem that captures\nthe trade-off between the running time and model performance under\nheterogeneous and uncertain system resources. To solve the formulated problem,\nwe further develop an online control scheme based on Lyapunov-based\noptimization for client sampling and resource allocation without requiring the\nknowledge of future dynamics in the FL system. Extensive experimental results\ndemonstrate that the proposed scheme can improve both the training latency and\nresource efficiency compared with the existing schemes.",
      "tldr_zh": "这篇论文针对 Federated Learning (FL) 在移动边缘网络中的资源约束问题（如电力、带宽和计算能力），提出了一种在线客户端调度和资源分配方案，以最小化训练延迟同时保持模型准确率。研究首先分析了客户端采样对模型收敛的影响，并制定了一个随机优化问题来平衡系统异构性和不确定性下的运行时间与性能。作者开发了基于 Lyapunov 的在线控制方案，实现动态客户端采样和资源分配，而无需提前知道系统未来动态。实验结果显示，该方案相较于现有方法，显著提高了训练延迟和资源效率。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10833v1",
      "published_date": "2024-09-29 01:56:45 UTC",
      "updated_date": "2024-09-29 01:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:09:44.133747"
    },
    {
      "arxiv_id": "2409.19509v1",
      "title": "Heterogeneity-Aware Resource Allocation and Topology Design for Hierarchical Federated Edge Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhidong Gao",
        "Yu Zhang",
        "Yanmin Gong",
        "Yuanxiong Guo"
      ],
      "abstract": "Federated Learning (FL) provides a privacy-preserving framework for training\nmachine learning models on mobile edge devices. Traditional FL algorithms,\ne.g., FedAvg, impose a heavy communication workload on these devices. To\nmitigate this issue, Hierarchical Federated Edge Learning (HFEL) has been\nproposed, leveraging edge servers as intermediaries for model aggregation.\nDespite its effectiveness, HFEL encounters challenges such as a slow\nconvergence rate and high resource consumption, particularly in the presence of\nsystem and data heterogeneity. However, existing works are mainly focused on\nimproving training efficiency for traditional FL, leaving the efficiency of\nHFEL largely unexplored. In this paper, we consider a two-tier HFEL system,\nwhere edge devices are connected to edge servers and edge servers are\ninterconnected through peer-to-peer (P2P) edge backhauls. Our goal is to\nenhance the training efficiency of the HFEL system through strategic resource\nallocation and topology design. Specifically, we formulate an optimization\nproblem to minimize the total training latency by allocating the computation\nand communication resources, as well as adjusting the P2P connections. To\nensure convergence under dynamic topologies, we analyze the convergence error\nbound and introduce a model consensus constraint into the optimization problem.\nThe proposed problem is then decomposed into several subproblems, enabling us\nto alternatively solve it online. Our method facilitates the efficient\nimplementation of large-scale FL at edge networks under data and system\nheterogeneity. Comprehensive experiment evaluation on benchmark datasets\nvalidates the effectiveness of the proposed method, demonstrating significant\nreductions in training latency while maintaining the model accuracy compared to\nvarious baselines.",
      "tldr_zh": "本研究针对分层联邦边缘学习（Hierarchical Federated Edge Learning, HFEL）在系统和数据异质性下的慢速收敛和高资源消耗问题，提出了一种异质性感知资源分配和拓扑设计策略。论文构建了一个两层HFEL系统，其中边缘设备通过P2P连接与边缘服务器互联，并制定优化问题以最小化总训练延迟，包括计算和通信资源分配以及P2P拓扑调整，同时引入模型共识约束确保收敛稳定性。该优化问题被分解为子问题，实现在线交替求解。实验在基准数据集上验证了方法的有效性，显著降低了训练延迟，同时保持了模型准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.19509v1",
      "published_date": "2024-09-29 01:48:04 UTC",
      "updated_date": "2024-09-29 01:48:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:09:57.082901"
    },
    {
      "arxiv_id": "2409.19501v1",
      "title": "Learning Frame-Wise Emotion Intensity for Audio-Driven Talking-Head Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyi Xu",
        "Hieu Le",
        "Zhixin Shu",
        "Yang Wang",
        "Yi-Hsuan Tsai",
        "Dimitris Samaras"
      ],
      "abstract": "Human emotional expression is inherently dynamic, complex, and fluid,\ncharacterized by smooth transitions in intensity throughout verbal\ncommunication. However, the modeling of such intensity fluctuations has been\nlargely overlooked by previous audio-driven talking-head generation methods,\nwhich often results in static emotional outputs. In this paper, we explore how\nemotion intensity fluctuates during speech, proposing a method for capturing\nand generating these subtle shifts for talking-head generation. Specifically,\nwe develop a talking-head framework that is capable of generating a variety of\nemotions with precise control over intensity levels. This is achieved by\nlearning a continuous emotion latent space, where emotion types are encoded\nwithin latent orientations and emotion intensity is reflected in latent norms.\nIn addition, to capture the dynamic intensity fluctuations, we adopt an\naudio-to-intensity predictor by considering the speaking tone that reflects the\nintensity. The training signals for this predictor are obtained through our\nemotion-agnostic intensity pseudo-labeling method without the need of\nframe-wise intensity labeling. Extensive experiments and analyses validate the\neffectiveness of our proposed method in accurately capturing and reproducing\nemotion intensity fluctuations in talking-head generation, thereby\nsignificantly enhancing the expressiveness and realism of the generated\noutputs.",
      "tldr_zh": "本文提出了一种音频驱动的 talking-head 生成方法，专注于学习逐帧情感强度，以捕捉言语中情感波动的动态变化，从而解决现有方法导致的静态输出问题。该方法通过构建一个连续情感潜在空间（continuous emotion latent space），将情感类型编码在潜在方向中，并用潜在范数反映强度水平，实现对各种情感的精确控制。同时，引入 audio-to-intensity 预测器和 emotion-agnostic intensity pseudo-labeling 技术，从说话语气中预测强度波动，而无需逐帧标签。实验结果验证了该方法的有效性，大大提升了生成 talking-head 的表现力和真实性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19501v1",
      "published_date": "2024-09-29 01:02:01 UTC",
      "updated_date": "2024-09-29 01:02:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:10:08.874981"
    },
    {
      "arxiv_id": "2410.05284v1",
      "title": "Psychometrics for Hypnopaedia-Aware Machinery via Chaotic Projection of Artificial Mental Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Ching-Chun Chang",
        "Kai Gao",
        "Shuying Xu",
        "Anastasia Kordoni",
        "Christopher Leckie",
        "Isao Echizen"
      ],
      "abstract": "Neural backdoors represent insidious cybersecurity loopholes that render\nlearning machinery vulnerable to unauthorised manipulations, potentially\nenabling the weaponisation of artificial intelligence with catastrophic\nconsequences. A backdoor attack involves the clandestine infiltration of a\ntrigger during the learning process, metaphorically analogous to hypnopaedia,\nwhere ideas are implanted into a subject's subconscious mind under the state of\nhypnosis or unconsciousness. When activated by a sensory stimulus, the trigger\nevokes conditioned reflex that directs a machine to mount a predetermined\nresponse. In this study, we propose a cybernetic framework for constant\nsurveillance of backdoors threats, driven by the dynamic nature of\nuntrustworthy data sources. We develop a self-aware unlearning mechanism to\nautonomously detach a machine's behaviour from the backdoor trigger. Through\nreverse engineering and statistical inference, we detect deceptive patterns and\nestimate the likelihood of backdoor infection. We employ model inversion to\nelicit artificial mental imagery, using stochastic processes to disrupt\noptimisation pathways and avoid convergent but potentially flawed patterns.\nThis is followed by hypothesis analysis, which estimates the likelihood of each\npotentially malicious pattern being the true trigger and infers the probability\nof infection. The primary objective of this study is to maintain a stable state\nof equilibrium between knowledge fidelity and backdoor vulnerability.",
      "tldr_zh": "该研究探讨了神经后门（neural backdoors）作为 AI 安全漏洞的问题，将其比作催眠教学（hypnopaedia），即在学习过程中植入触发器以操控机器行为。作者提出一个网络框架，通过自aware unlearning mechanism、reverse engineering 和 statistical inference 来持续监控和检测欺骗模式，并使用 model inversion 和 stochastic processes 生成人工心理图像（artificial mental imagery）以破坏潜在的恶意优化路径。最终，该框架通过 hypothesis analysis 评估感染概率，并维持知识 fidelity 与 backdoor vulnerability 之间的平衡，确保 AI 系统的鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05284v1",
      "published_date": "2024-09-29 00:59:26 UTC",
      "updated_date": "2024-09-29 00:59:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:10:20.435898"
    },
    {
      "arxiv_id": "2409.19492v1",
      "title": "MedHalu: Hallucinations in Responses to Healthcare Queries by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Vibhor Agarwal",
        "Yiqiao Jin",
        "Mohit Chandra",
        "Munmun De Choudhury",
        "Srijan Kumar",
        "Nishanth Sastry"
      ],
      "abstract": "The remarkable capabilities of large language models (LLMs) in language\nunderstanding and generation have not rendered them immune to hallucinations.\nLLMs can still generate plausible-sounding but factually incorrect or\nfabricated information. As LLM-empowered chatbots become popular, laypeople may\nfrequently ask health-related queries and risk falling victim to these LLM\nhallucinations, resulting in various societal and healthcare implications. In\nthis work, we conduct a pioneering study of hallucinations in LLM-generated\nresponses to real-world healthcare queries from patients. We propose MedHalu, a\ncarefully crafted first-of-its-kind medical hallucination dataset with a\ndiverse range of health-related topics and the corresponding hallucinated\nresponses from LLMs with labeled hallucination types and hallucinated text\nspans. We also introduce MedHaluDetect framework to evaluate capabilities of\nvarious LLMs in detecting hallucinations. We also employ three groups of\nevaluators -- medical experts, LLMs, and laypeople -- to study who are more\nvulnerable to these medical hallucinations. We find that LLMs are much worse\nthan the experts. They also perform no better than laypeople and even worse in\nfew cases in detecting hallucinations. To fill this gap, we propose\nexpert-in-the-loop approach to improve hallucination detection through LLMs by\ninfusing expert reasoning. We observe significant performance gains for all the\nLLMs with an average macro-F1 improvement of 6.3 percentage points for GPT-4.",
      "tldr_zh": "这篇论文研究了大型语言模型 (LLMs) 在回答医疗查询时产生的幻觉 (hallucinations)，即生成看似合理但事实错误的响应，可能导致社会和医疗风险。研究者构建了 MedHalu 数据集，这是首个针对医疗主题的幻觉数据集，包括多样化查询、LLMs 生成的幻觉响应以及标注的幻觉类型和文本跨度，并引入 MedHaluDetect 框架来评估 LLMs 的检测能力。实验发现，LLMs 在检测幻觉方面远逊于医疗专家，甚至在某些情况下不如普通人 (laypeople)。为改进这一问题，论文提出 expert-in-the-loop 方法，通过注入专家推理显著提升 LLMs 的性能，GPT-4 的 macro-F1 平均提高了 6.3 百分点。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.19492v1",
      "published_date": "2024-09-29 00:09:01 UTC",
      "updated_date": "2024-09-29 00:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T05:10:33.484676"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 59,
  "processed_papers_count": 59,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T05:10:52.390258"
}