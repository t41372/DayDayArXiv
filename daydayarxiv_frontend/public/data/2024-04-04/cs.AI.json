{
  "date": "2024-04-04",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-04 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 和机器学习的创新进展，包括大型语言模型（LLM）的优化与应用、强化学习、多模态模型以及图像处理等领域。其中，亮点是 Direct Nash Optimization（论文21）提出的 LLM 自提升方法，以及 Han Liu 等学者主导的多篇 Hopfield 模型相关研究（论文3-5），这些工作展示了 LLM 在复杂任务中的潜力，并推动了模型鲁棒性和效率的提升。\n\n下面，我将挑选并简要讨论部分重要、具有话题度和影响力的论文，先从 LLM 和强化学习相关的内容入手，然后快速概述其他值得注意的领域。对于较基础或非核心论文，我会简略掠过，以控制篇幅。\n\n**1. A Block-Coordinate Descent EMO Algorithm: Theoretical and Empirical Analysis（块坐标下降 EMO 算法：理论与实证分析）**  \n   作者包括 Benjamin Doerr 和 Frank Neumann，这篇论文提出了一种块坐标下降版本的 GSEMO 算法，用于多目标优化。贡献在于理论证明和实证结果显示，该算法在某些情况下比标准 GSEMO 更快，可能为大规模优化问题提供新见解。\n\n**3. BiSHop: Bi-Directional Cellular Learning for Tabular Data with Generalized Sparse Modern Hopfield Model（BiSHop：使用广义稀疏现代 Hopfield 模型的双向细胞学习，用于表格数据）**  \n   作者 Han Liu 等构建了 BiSHop 框架，处理表格数据的非旋转不变性和稀疏性。关键发现是通过双向模块和 Hopfield 层，该方法在多尺度表示学习中超越了现有 SOTA 方法，显著减少了超参数优化次数，适用于实际深度学习任务。\n\n**4. Outlier-Efficient Hopfield Layers for Large Transformer-Based Models（面向大型 Transformer 模型的异常值高效 Hopfield 层）**  \n   Han Liu 参与的另一篇，引入 OutEffHop 模型，优化 Transformer 中的异常值处理。贡献包括理论证明其收敛性和经验验证，实现了 22%+ 的输出异常减少，适用于 BERT 和 OPT 等模型，提升了量化性能。\n\n**5. Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models（现代 Hopfield 模型的统一记忆检索与更大容量）**  \n   继续 Han Liu 的系列，提出 U-Hop 模型，通过可学习特征映射和两阶段检索增强记忆容量。发现显示，该方法在关联记忆和深度学习任务中优于现有模型，显著降低了记忆混淆风险。\n\n**6. CBR-RAG: Case-Based Reasoning for Retrieval Augmented Generation in LLMs for Legal Question Answering（CBR-RAG：用于 LLM 法律问答的案例推理检索增强生成）**  \n   这篇论文将案例推理融入 LLM 的 RAG 框架中。主要贡献是提升了法律问答的准确性，通过不同相似性方法（如混合相似性）改善生成质量，实验证明其在证据相关性上显著优于基线。\n\n**9. SELF-[IN]CORRECT: LLMs Struggle with Discriminating Self-Generated Responses（SELF-[IN]CORRECT：LLM 在区分自生成响应方面存在挑战）**  \n   探讨 LLM 的自我改进限制，提出一个统一框架评估生成和区分能力。发现显示，LLM 无法可靠地提升自身输出，挑战了现有优化假设。\n\n**21. Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences（直接 Nash 优化：使用一般偏好指导 LLM 自提升）**  \n   微软研究团队的作品，引入 DNO 算法，直接优化 LLM 的偏好反馈。关键发现是，该方法在无需额外奖励的情况下显著提升模型性能，实验中 7B 参数模型在 AlpacaEval 2.0 上胜率达 33%，超越更大模型。\n\n**32. ReFT: Representation Finetuning for Language Models（ReFT：语言模型的表示微调）**  \n   提出 ReFT 方法，通过表示微调提升 LLM 效率。贡献在于参数效率高达 15x-65x 比 LoRA 更好，并在多任务上表现优异，展示了微调新范式。\n\n**37. CodeEditorBench: Evaluating Code Editing Capability of Large Language Models（CodeEditorBench：评估大型语言模型的代码编辑能力）**  \n   这篇论文构建了 CodeEditorBench 基准，评估 LLM 在代码调试和翻译等任务中的能力。发现 Gemini-Ultra 和 GPT-4 在基准上表现出色，强调了 LLM 在实际软件开发中的潜力。\n\n其他相关论文快速掠过：  \n- **论文2: PARIS3D: Reasoning-based 3D Part Segmentation Using Large Multimodal Model（PARIS3D：基于推理的多模态模型的 3D 部分分割）** 贡献了新数据集和模型，支持隐式文本查询的 3D 分割，实验显示其在多模态任务中竞争力强。  \n- **论文10: Dissecting Query-Key Interaction in Vision Transformers（剖析 Vision Transformers 中的查询-键交互）** 通过奇异值分解分析注意力机制，发现早期层更关注相似特征，晚期层提供上下文，支持视觉 Transformer 的解释性。  \n- **论文15: GenQREnsemble: Zero-Shot LLM Ensemble Prompting for Generative Query Reformulation（GenQREnsemble：用于生成式查询重构的零样本 LLM 集成提示）** 提出集成提示方法，提升检索性能，实验中 MAP 提升达 24%。  \n- **论文19: CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching（CoMat：通过图像-文本概念匹配对齐文本-图像扩散模型）** 优化扩散模型的文本-图像对齐，实验显示其在基准上超越基线。  \n- **论文33: SemGrasp: Semantic Grasp Generation via Language Aligned Discretization（SemGrasp：通过语言对齐离散化的语义抓取生成）** 构建 CapGrasp 数据集，支持语言指导的抓取生成，展示了多模态交互的潜力。  \n- **论文46: ChangeMamba: Remote Sensing Change Detection With Spatiotemporal State Space Model（ChangeMamba：使用时空状态空间模型的遥感变化检测）** 引入 Mamba 架构，提升变化检测精度，适用于二元和语义变化任务。  \n- **论文20, 50, 70 等医疗和应用论文** 如 Capabilities of Large Language Models in Control Engineering（LLM 在控制工程中的能力），这些工作探索 LLM 在专业领域的应用，但整体影响较小，仅证明了 LLM 的扩展性。\n\n今天的论文总体上体现了 AI 领域的快速迭代，LLM 优化和多模态模型是核心热点。更多细节可查阅 arXiv，以节省篇幅。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2404.03838v2",
      "title": "A Block-Coordinate Descent EMO Algorithm: Theoretical and Empirical Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Doerr",
        "Joshua Knowles",
        "Aneta Neumann",
        "Frank Neumann"
      ],
      "abstract": "We consider whether conditions exist under which block-coordinate descent is\nasymptotically efficient in evolutionary multi-objective optimization,\naddressing an open problem. Block-coordinate descent, where an optimization\nproblem is decomposed into $k$ blocks of decision variables and each of the\nblocks is optimized (with the others fixed) in a sequence, is a technique used\nin some large-scale optimization problems such as airline scheduling, however\nits use in multi-objective optimization is less studied. We propose a\nblock-coordinate version of GSEMO and compare its running time to the standard\nGSEMO algorithm. Theoretical and empirical results on a bi-objective test\nfunction, a variant of LOTZ, serve to demonstrate the existence of cases where\nblock-coordinate descent is faster. The result may yield wider insights into\nthis class of algorithms.",
      "tldr_zh": "这篇论文探讨了在进化多目标优化(EMO)中，块坐标下降(Block-Coordinate Descent)是否能实现渐近效率，针对一个开放问题进行分析。作者提出了一种块坐标版本的GSEMO算法，将优化问题分解为多个决策变量块，并依次优化每个块，同时与其他块固定。理论和实证结果显示，在一个双目标测试函数（LOTZ的变体）上，该算法在某些情况下比标准GSEMO运行更快。该研究为这类算法提供了更广泛的见解。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted at GECCO 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.03838v2",
      "published_date": "2024-04-04 23:50:18 UTC",
      "updated_date": "2024-04-11 00:13:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:40:15.922218"
    },
    {
      "arxiv_id": "2404.03836v1",
      "title": "PARIS3D: Reasoning-based 3D Part Segmentation Using Large Multimodal Model",
      "title_zh": "翻译失败",
      "authors": [
        "Amrin Kareem",
        "Jean Lahoud",
        "Hisham Cholakkal"
      ],
      "abstract": "Recent advancements in 3D perception systems have significantly improved\ntheir ability to perform visual recognition tasks such as segmentation.\nHowever, these systems still heavily rely on explicit human instruction to\nidentify target objects or categories, lacking the capability to actively\nreason and comprehend implicit user intentions. We introduce a novel\nsegmentation task known as reasoning part segmentation for 3D objects, aiming\nto output a segmentation mask based on complex and implicit textual queries\nabout specific parts of a 3D object. To facilitate evaluation and benchmarking,\nwe present a large 3D dataset comprising over 60k instructions paired with\ncorresponding ground-truth part segmentation annotations specifically curated\nfor reasoning-based 3D part segmentation. We propose a model that is capable of\nsegmenting parts of 3D objects based on implicit textual queries and generating\nnatural language explanations corresponding to 3D object segmentation requests.\nExperiments show that our method achieves competitive performance to models\nthat use explicit queries, with the additional abilities to identify part\nconcepts, reason about them, and complement them with world knowledge. Our\nsource code, dataset, and trained models are available at\nhttps://github.com/AmrinKareem/PARIS3D.",
      "tldr_zh": "该论文引入了基于推理的 3D 部分分割任务（reasoning part segmentation），旨在解决现有 3D 感知系统依赖显式人类指令的问题，通过处理复杂隐式文本查询来输出 3D 对象部分的分割掩码。作者构建了一个大型数据集，包含超过 60k 条指令及其地面真实分割标注，并提出一个使用 Large Multimodal Model 的模型，能够基于这些查询进行分割并生成自然语言解释。实验结果表明，该方法在性能上与使用显式查询的模型相当，同时具备识别部分概念、进行推理以及整合世界知识的能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.03836v1",
      "published_date": "2024-04-04 23:38:45 UTC",
      "updated_date": "2024-04-04 23:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:40:29.480964"
    },
    {
      "arxiv_id": "2404.03830v2",
      "title": "BiSHop: Bi-Directional Cellular Learning for Tabular Data with Generalized Sparse Modern Hopfield Model",
      "title_zh": "翻译失败",
      "authors": [
        "Chenwei Xu",
        "Yu-Chao Huang",
        "Jerry Yao-Chieh Hu",
        "Weijian Li",
        "Ammar Gilani",
        "Hsi-Sheng Goan",
        "Han Liu"
      ],
      "abstract": "We introduce the \\textbf{B}i-Directional \\textbf{S}parse \\textbf{Hop}field\nNetwork (\\textbf{BiSHop}), a novel end-to-end framework for deep tabular\nlearning. BiSHop handles the two major challenges of deep tabular learning:\nnon-rotationally invariant data structure and feature sparsity in tabular data.\nOur key motivation comes from the recent established connection between\nassociative memory and attention mechanisms. Consequently, BiSHop uses a\ndual-component approach, sequentially processing data both column-wise and\nrow-wise through two interconnected directional learning modules.\nComputationally, these modules house layers of generalized sparse modern\nHopfield layers, a sparse extension of the modern Hopfield model with adaptable\nsparsity. Methodologically, BiSHop facilitates multi-scale representation\nlearning, capturing both intra-feature and inter-feature interactions, with\nadaptive sparsity at each scale. Empirically, through experiments on diverse\nreal-world datasets, we demonstrate that BiSHop surpasses current SOTA methods\nwith significantly less HPO runs, marking it a robust solution for deep tabular\nlearning.",
      "tldr_zh": "这篇论文引入了 BiSHop，一种双向稀疏 Hopfield 网络框架，用于端到端深度表格学习，旨在解决表格数据的非旋转不变结构和特征稀疏性问题。BiSHop 通过两个互连的定向学习模块，顺序处理数据的列向和行向信息，并采用广义稀疏现代 Hopfield 层来实现多尺度表示学习，从而捕捉内部和外部特征交互。实验结果表明，BiSHop 在多种真实数据集上超越了当前 SOTA 方法，同时显著减少了 HPO（超参数优化）运行次数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages; Code available at https://github.com/MAGICS-LAB/BiSHop",
      "pdf_url": "http://arxiv.org/pdf/2404.03830v2",
      "published_date": "2024-04-04 23:13:32 UTC",
      "updated_date": "2024-07-12 22:45:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:40:39.804030"
    },
    {
      "arxiv_id": "2404.03828v2",
      "title": "Outlier-Efficient Hopfield Layers for Large Transformer-Based Models",
      "title_zh": "针对大型基于 Transformer 的模型的异常值高效",
      "authors": [
        "Jerry Yao-Chieh Hu",
        "Pei-Hsuan Chang",
        "Robin Luo",
        "Hong-Yu Chen",
        "Weijian Li",
        "Wei-Po Wang",
        "Han Liu"
      ],
      "abstract": "We introduce an Outlier-Efficient Modern Hopfield Model (termed\n$\\mathrm{OutEffHop}$) and use it to address the outlier inefficiency problem of\n{training} gigantic transformer-based models. Our main contribution is a novel\nassociative memory model facilitating \\textit{outlier-efficient} associative\nmemory retrievals. Interestingly, this memory model manifests a model-based\ninterpretation of an outlier-efficient attention mechanism (${\\rm Softmax}_1$):\nit is an approximation of the memory retrieval process of $\\mathrm{OutEffHop}$.\nMethodologically, this allows us to introduce novel outlier-efficient Hopfield\nlayers as powerful alternatives to traditional attention mechanisms, with\nsuperior post-quantization performance. Theoretically, the Outlier-Efficient\nModern Hopfield Model retains and improves the desirable properties of standard\nmodern Hopfield models, including fixed point convergence and exponential\nstorage capacity. Empirically, we demonstrate the efficacy of the proposed\nmodel across large-scale transformer-based and Hopfield-based models (including\nBERT, OPT, ViT, and STanHop-Net), benchmarking against state-of-the-art methods\nlike $\\mathtt{Clipped\\_Softmax}$ and $\\mathtt{Gated\\_Attention}$. Notably,\n$\\mathrm{OutEffHop}$ achieves an average reduction of 22+\\% in average kurtosis\nand 26+\\% in the maximum infinity norm of model outputs across four models.\nCode is available at \\href{https://github.com/MAGICS-LAB/OutEffHop}{GitHub};\nmodels are on\n\\href{https://huggingface.co/collections/magicslabnu/outeffhop-6610fcede8d2cda23009a98f}{Hugging\nFace Hub}; future updates are on\n\\href{https://arxiv.org/abs/2404.03828}{arXiv}.",
      "tldr_zh": "该论文提出了一种Outlier-Efficient Modern Hopfield Model（简称OutEffHop），旨在解决训练大型Transformer模型时遇到的异常值效率问题，作为一种高效的关联记忆模型。OutEffHop提供了一个基于模型的解释，近似于异常值高效的注意力机制（Softmax_1），并引入新型的Outlier-Efficient Hopfield层，以替代传统注意力机制，提升后量化性能。理论上，该模型保留了标准现代Hopfield模型的优点，如固定点收敛和指数存储容量。实证结果显示，在BERT、OPT、ViT和STanHop-Net等模型上，OutEffHop实现了平均峰度（kurtosis）减少22%以上，以及模型输出最大无穷范数减少26%以上，优于Clipped_Softmax和Gated_Attention等方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024; v2 updated to camera-ready version; Code\n  available at https://github.com/MAGICS-LAB/OutEffHop; Models are on Hugging\n  Face:\n  https://huggingface.co/collections/magicslabnu/outeffhop-6610fcede8d2cda23009a98f",
      "pdf_url": "http://arxiv.org/pdf/2404.03828v2",
      "published_date": "2024-04-04 23:08:43 UTC",
      "updated_date": "2024-06-26 20:50:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:40:53.062726"
    },
    {
      "arxiv_id": "2404.03827v3",
      "title": "Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dennis Wu",
        "Jerry Yao-Chieh Hu",
        "Teng-Yun Hsiao",
        "Han Liu"
      ],
      "abstract": "We propose a two-stage memory retrieval dynamics for modern Hopfield models,\ntermed $\\mathtt{U\\text{-}Hop}$, with enhanced memory capacity. Our key\ncontribution is a learnable feature map $\\Phi$ which transforms the Hopfield\nenergy function into kernel space. This transformation ensures convergence\nbetween the local minima of energy and the fixed points of retrieval dynamics\nwithin the kernel space. Consequently, the kernel norm induced by $\\Phi$ serves\nas a novel similarity measure. It utilizes the stored memory patterns as\nlearning data to enhance memory capacity across all modern Hopfield models.\nSpecifically, we accomplish this by constructing a separation loss\n$\\mathcal{L}_\\Phi$ that separates the local minima of kernelized energy by\nseparating stored memory patterns in kernel space. Methodologically,\n$\\mathtt{U\\text{-}Hop}$ memory retrieval process consists of: (Stage I)\nminimizing separation loss for a more uniform memory (local minimum)\ndistribution, followed by (Stage II) standard Hopfield energy minimization for\nmemory retrieval. This results in a significant reduction of possible\nmetastable states in the Hopfield energy function, thus enhancing memory\ncapacity by preventing memory confusion. Empirically, with real-world datasets,\nwe demonstrate that $\\mathtt{U\\text{-}Hop}$ outperforms all existing modern\nHopfield models and state-of-the-art similarity measures, achieving substantial\nimprovements in both associative memory retrieval and deep learning tasks. Code\nis available at https://github.com/MAGICS-LAB/UHop ; future updates are on\narXiv:2404.03827",
      "tldr_zh": "本研究提出了一种名为$\\mathtt{U\\text{-}Hop}$的现代Hopfield模型的双阶段记忆检索动态，以提升记忆容量。其核心创新是引入可学习的特征映射$\\Phi$，将Hopfield能量函数转换为核空间，并通过分离损失$\\mathcal{L}_\\Phi$在核空间中分离存储的记忆模式，从而实现更均匀的局部最小值分布和减少亚稳态。方法包括Stage I最小化$\\mathcal{L}_\\Phi$以优化记忆分布，以及Stage II进行标准Hopfield能量最小化以实现精确检索。实验结果显示，$\\mathtt{U\\text{-}Hop}$在真实数据集上超越现有Hopfield模型和最先进相似性度量，在关联记忆检索和深度学习任务中取得显著性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024; v3 added a note on follow-up UHop+\n  (arXiv:2410.23126); v2 updated to camera-ready version; Code available at\n  https://github.com/MAGICS-LAB/UHop",
      "pdf_url": "http://arxiv.org/pdf/2404.03827v3",
      "published_date": "2024-04-04 23:05:30 UTC",
      "updated_date": "2024-11-10 19:25:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:41:05.672906"
    },
    {
      "arxiv_id": "2404.04302v1",
      "title": "CBR-RAG: Case-Based Reasoning for Retrieval Augmented Generation in LLMs for Legal Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Nirmalie Wiratunga",
        "Ramitha Abeyratne",
        "Lasal Jayawardena",
        "Kyle Martin",
        "Stewart Massie",
        "Ikechukwu Nkisi-Orji",
        "Ruvan Weerasinghe",
        "Anne Liret",
        "Bruno Fleisch"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) enhances Large Language Model (LLM)\noutput by providing prior knowledge as context to input. This is beneficial for\nknowledge-intensive and expert reliant tasks, including legal\nquestion-answering, which require evidence to validate generated text outputs.\nWe highlight that Case-Based Reasoning (CBR) presents key opportunities to\nstructure retrieval as part of the RAG process in an LLM. We introduce CBR-RAG,\nwhere CBR cycle's initial retrieval stage, its indexing vocabulary, and\nsimilarity knowledge containers are used to enhance LLM queries with\ncontextually relevant cases. This integration augments the original LLM query,\nproviding a richer prompt. We present an evaluation of CBR-RAG, and examine\ndifferent representations (i.e. general and domain-specific embeddings) and\nmethods of comparison (i.e. inter, intra and hybrid similarity) on the task of\nlegal question-answering. Our results indicate that the context provided by\nCBR's case reuse enforces similarity between relevant components of the\nquestions and the evidence base leading to significant improvements in the\nquality of generated answers.",
      "tldr_zh": "该论文提出CBR-RAG框架，将Case-Based Reasoning (CBR)整合到Retrieval-Augmented Generation (RAG)中，以提升Large Language Model (LLM)在法律问答任务中的性能。CBR-RAG利用CBR的初始检索阶段、索引词汇和相似性知识容器，为LLM查询添加相关案例作为上下文，从而丰富提示内容。实验评估了不同表示方法（如一般和领域特定嵌入）及相似性比较方式（如内部、内部混合），结果显示CBR的案例重用显著提高了问题与证据库的相关性，导致生成答案质量得到显著提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to ICCBR'24",
      "pdf_url": "http://arxiv.org/pdf/2404.04302v1",
      "published_date": "2024-04-04 21:47:43 UTC",
      "updated_date": "2024-04-04 21:47:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:41:17.558897"
    },
    {
      "arxiv_id": "2404.04299v1",
      "title": "GENEVIC: GENetic data Exploration and Visualization via Intelligent interactive Console",
      "title_zh": "翻译失败",
      "authors": [
        "Anindita Nath",
        "Savannah Mwesigwa",
        "Yulin Dai",
        "Xiaoqian Jiang",
        "Zhongming Zhao"
      ],
      "abstract": "Summary: The vast generation of genetic data poses a significant challenge in\nefficiently uncovering valuable knowledge. Introducing GENEVIC, an AI-driven\nchat framework that tackles this challenge by bridging the gap between genetic\ndata generation and biomedical knowledge discovery. Leveraging generative AI,\nnotably ChatGPT, it serves as a biologist's 'copilot'. It automates the\nanalysis, retrieval, and visualization of customized domain-specific genetic\ninformation, and integrates functionalities to generate protein interaction\nnetworks, enrich gene sets, and search scientific literature from PubMed,\nGoogle Scholar, and arXiv, making it a comprehensive tool for biomedical\nresearch. In its pilot phase, GENEVIC is assessed using a curated database that\nranks genetic variants associated with Alzheimer's disease, schizophrenia, and\ncognition, based on their effect weights from the Polygenic Score Catalog, thus\nenabling researchers to prioritize genetic variants in complex diseases.\nGENEVIC's operation is user-friendly, accessible without any specialized\ntraining, secured by Azure OpenAI's HIPAA-compliant infrastructure, and\nevaluated for its efficacy through real-time query testing. As a prototype,\nGENEVIC is set to advance genetic research, enabling informed biomedical\ndecisions.\n  Availability and implementation: GENEVIC is publicly accessible at\nhttps://genevic-anath2024.streamlit.app. The underlying code is open-source and\navailable via GitHub at https://github.com/anath2110/GENEVIC.git.",
      "tldr_zh": "该研究引入了GENEVIC，一种AI驱动的聊天框架，利用生成式AI（如ChatGPT）作为生物学家的“副驾驶”，帮助高效探索和可视化遗传数据。GENEVIC自动化分析、检索和可视化定制的遗传信息，包括生成蛋白质交互网络、丰富基因集，以及搜索PubMed、Google Scholar和arXiv的科学文献。试点评估显示，它使用Polygenic Score Catalog的效应权重对阿尔茨海默病、精神分裂症和认知相关遗传变异进行优先级排序，提升了生物医学研究效率；该工具用户友好、无需专业训练，并通过Azure OpenAI的HIPAA合规基础设施确保安全，可在指定网站和GitHub上公开访问。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04299v1",
      "published_date": "2024-04-04 20:53:30 UTC",
      "updated_date": "2024-04-04 20:53:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:41:28.698546"
    },
    {
      "arxiv_id": "2404.03799v2",
      "title": "Language-Guided Instance-Aware Domain-Adaptive Panoptic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Elham Amin Mansour",
        "Ozan Unal",
        "Suman Saha",
        "Benjamin Bejar",
        "Luc Van Gool"
      ],
      "abstract": "The increasing relevance of panoptic segmentation is tied to the advancements\nin autonomous driving and AR/VR applications. However, the deployment of such\nmodels has been limited due to the expensive nature of dense data annotation,\ngiving rise to unsupervised domain adaptation (UDA). A key challenge in\npanoptic UDA is reducing the domain gap between a labeled source and an\nunlabeled target domain while harmonizing the subtasks of semantic and instance\nsegmentation to limit catastrophic interference. While considerable progress\nhas been achieved, existing approaches mainly focus on the adaptation of\nsemantic segmentation. In this work, we focus on incorporating instance-level\nadaptation via a novel instance-aware cross-domain mixing strategy IMix. IMix\nsignificantly enhances the panoptic quality by improving instance segmentation\nperformance. Specifically, we propose inserting high-confidence predicted\ninstances from the target domain onto source images, retaining the\nexhaustiveness of the resulting pseudo-labels while reducing the injected\nconfirmation bias. Nevertheless, such an enhancement comes at the cost of\ndegraded semantic performance, attributed to catastrophic forgetting. To\nmitigate this issue, we regularize our semantic branch by employing CLIP-based\ndomain alignment (CDA), exploiting the domain-robustness of natural language\nprompts. Finally, we present an end-to-end model incorporating these two\nmechanisms called LIDAPS, achieving state-of-the-art results on all popular\npanoptic UDA benchmarks.",
      "tldr_zh": "该论文针对全景分割（panoptic segmentation）在自动驾驶和 AR/VR 应用中的挑战，提出了一种无监督域适应（UDA）方法，以减少源域和目标域的差距，同时协调语义分割和实例分割。核心创新是引入实例感知跨域混合策略 IMix，将目标域的高置信度实例预测插入源域图像，以提升实例分割性能并减少确认偏差；同时，使用基于 CLIP 的域对齐（CDA）来正则化语义分支，缓解灾难性遗忘问题。最终，该端到端模型 LIDAPS 在所有主流 panoptic UDA 基准上实现了 state-of-the-art 结果，显著提高了全景质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the 2025 IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV)",
      "pdf_url": "http://arxiv.org/pdf/2404.03799v2",
      "published_date": "2024-04-04 20:42:49 UTC",
      "updated_date": "2024-12-25 23:27:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:41:41.336789"
    },
    {
      "arxiv_id": "2404.04298v3",
      "title": "SELF-[IN]CORRECT: LLMs Struggle with Discriminating Self-Generated Responses",
      "title_zh": "翻译失败",
      "authors": [
        "Dongwei Jiang",
        "Jingyu Zhang",
        "Orion Weller",
        "Nathaniel Weir",
        "Benjamin Van Durme",
        "Daniel Khashabi"
      ],
      "abstract": "Can LLMs consistently improve their previous outputs for better results? For\nthis to be true, LLMs would need to be better at discriminating among\npreviously-generated alternatives, than generating initial responses. We\nexplore the validity of this hypothesis in practice. We first formulate a\nunified framework that allows us to compare the generative and discriminative\ncapability of any model on any task. In our resulting experimental analysis of\nseveral open-source and industrial LLMs, we observe that models are not\nreliably better at discriminating among previously-generated alternatives than\ngenerating initial responses. This finding challenges the notion that LLMs may\nbe able to enhance their performance only through their own judgment.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）是否能通过辨别自身生成的响应来提升输出质量，为此假设 LLMs 在辨别先前备选方案方面应优于生成初始响应。作者提出一个统一的框架，用于比较各种模型在不同任务上的生成和辨别能力，并对多个开源和工业 LLMs 进行实验分析。结果显示，LLMs 在辨别自生成响应时并不可靠地优于生成新响应，这挑战了模型仅凭自身判断就能改进性能的观点。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04298v3",
      "published_date": "2024-04-04 20:27:37 UTC",
      "updated_date": "2024-09-06 01:14:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:41:52.135059"
    },
    {
      "arxiv_id": "2405.14880v4",
      "title": "Dissecting Query-Key Interaction in Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Pan",
        "Aaron Philip",
        "Ziqian Xie",
        "Odelia Schwartz"
      ],
      "abstract": "Self-attention in vision transformers is often thought to perform perceptual\ngrouping where tokens attend to other tokens with similar embeddings, which\ncould correspond to semantically similar features of an object. However,\nattending to dissimilar tokens can be beneficial by providing contextual\ninformation. We propose to analyze the query-key interaction by the singular\nvalue decomposition of the interaction matrix (i.e.\n${\\textbf{W}_q}^\\top\\textbf{W}_k$). We find that in many ViTs, especially those\nwith classification training objectives, early layers attend more to similar\ntokens, while late layers show increased attention to dissimilar tokens,\nproviding evidence corresponding to perceptual grouping and contextualization,\nrespectively. Many of these interactions between features represented by\nsingular vectors are interpretable and semantic, such as attention between\nrelevant objects, between parts of an object, or between the foreground and\nbackground. This offers a novel perspective on interpreting the attention\nmechanism, which contributes to understanding how transformer models utilize\ncontext and salient features when processing images.",
      "tldr_zh": "本文通过奇异值分解(SVD)分析视觉Transformer中query-key交互矩阵（即 \\({\\textbf{W}_q}^\\top\\textbf{W}_k\\)），探讨了注意力机制如何处理相似和不相似token。研究发现，早层更倾向于关注相似token以实现感知分组，而晚层则增加对不相似token的关注，以提供上下文信息；这些交互往往是可解释的语义关联，如对象间、对象部分间或前景与背景间的联系。该方法为理解Transformer模型如何利用上下文和显著特征处理图像提供了新颖视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14880v4",
      "published_date": "2024-04-04 20:06:07 UTC",
      "updated_date": "2025-01-14 01:57:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:42:04.206720"
    },
    {
      "arxiv_id": "2404.03789v1",
      "title": "Quantifying Uncertainty in Motion Prediction with Variational Bayesian Mixture",
      "title_zh": "利用变分贝叶斯混合模型量化运动预测中的不确定性",
      "authors": [
        "Juanwu Lu",
        "Can Cui",
        "Yunsheng Ma",
        "Aniket Bera",
        "Ziran Wang"
      ],
      "abstract": "Safety and robustness are crucial factors in developing trustworthy\nautonomous vehicles. One essential aspect of addressing these factors is to\nequip vehicles with the capability to predict future trajectories for all\nmoving objects in the surroundings and quantify prediction uncertainties. In\nthis paper, we propose the Sequential Neural Variational Agent (SeNeVA), a\ngenerative model that describes the distribution of future trajectories for a\nsingle moving object. Our approach can distinguish Out-of-Distribution data\nwhile quantifying uncertainty and achieving competitive performance compared to\nstate-of-the-art methods on the Argoverse 2 and INTERACTION datasets.\nSpecifically, a 0.446 meters minimum Final Displacement Error, a 0.203 meters\nminimum Average Displacement Error, and a 5.35% Miss Rate are achieved on the\nINTERACTION test set. Extensive qualitative and quantitative analysis is also\nprovided to evaluate the proposed model. Our open-source code is available at\nhttps://github.com/PurdueDigitalTwin/seneva.",
      "tldr_zh": "这篇论文提出了一种名为Sequential Neural Variational Agent (SeNeVA)的生成模型，用于量化自动驾驶车辆中移动物体未来轨迹预测的不确定性，从而提升安全性和鲁棒性。SeNeVA模型通过变分贝叶斯方法描述轨迹分布，能够区分Out-of-Distribution数据，并在Argoverse 2和INTERACTION数据集上实现与最先进方法相当的性能。具体而言，在INTERACTION测试集上，该模型达到了0.446米的minimum Final Displacement Error、0.203米的minimum Average Displacement Error和5.35%的Miss Rate。论文还提供了广泛的定性和定量分析，并开源了代码以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.03789v1",
      "published_date": "2024-04-04 20:04:12 UTC",
      "updated_date": "2024-04-04 20:04:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:42:19.491844"
    },
    {
      "arxiv_id": "2404.03784v2",
      "title": "A Layer Selection Approach to Test Time Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Sabyasachi Sahoo",
        "Mostafa ElAraby",
        "Jonas Ngnawe",
        "Yann Pequignot",
        "Frederic Precioso",
        "Christian Gagne"
      ],
      "abstract": "Test Time Adaptation (TTA) addresses the problem of distribution shift by\nadapting a pretrained model to a new domain during inference. When faced with\nchallenging shifts, most methods collapse and perform worse than the original\npretrained model. In this paper, we find that not all layers are equally\nreceptive to the adaptation, and the layers with the most misaligned gradients\noften cause performance degradation. To address this, we propose GALA, a novel\nlayer selection criterion to identify the most beneficial updates to perform\nduring test time adaptation. This criterion can also filter out unreliable\nsamples with noisy gradients. Its simplicity allows seamless integration with\nexisting TTA loss functions, thereby preventing degradation and focusing\nadaptation on the most trainable layers. This approach also helps to regularize\nadaptation to preserve the pretrained features, which are crucial for handling\nunseen domains. Through extensive experiments, we demonstrate that the proposed\nlayer selection framework improves the performance of existing TTA approaches\nacross multiple datasets, domain shifts, model architectures, and TTA losses.",
      "tldr_zh": "本研究针对Test Time Adaptation (TTA)中分布偏移问题，提出一种层选择方法GALA，以解决现有方法在挑战性偏移下性能退化的问题。GALA通过评估梯度错位层来识别最有益的更新，并过滤掉噪声样本，从而无缝集成到现有TTA损失函数中，同时保留预训练特征以应对未见领域。通过广泛实验，该框架显著提升了现有TTA方法的性能，适用于多种数据集、领域偏移、模型架构和损失函数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 8 figures, Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.03784v2",
      "published_date": "2024-04-04 19:55:11 UTC",
      "updated_date": "2025-02-23 15:31:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:42:29.126944"
    },
    {
      "arxiv_id": "2404.03775v1",
      "title": "A Systems Theoretic Approach to Online Machine Learning",
      "title_zh": "基于系统理论的在线机器学习方法",
      "authors": [
        "Anli du Preez",
        "Peter A. Beling",
        "Tyler Cody"
      ],
      "abstract": "The machine learning formulation of online learning is incomplete from a\nsystems theoretic perspective. Typically, machine learning research emphasizes\ndomains and tasks, and a problem solving worldview. It focuses on algorithm\nparameters, features, and samples, and neglects the perspective offered by\nconsidering system structure and system behavior or dynamics. Online learning\nis an active field of research and has been widely explored in terms of\nstatistical theory and computational algorithms, however, in general, the\nliterature still lacks formal system theoretical frameworks for modeling online\nlearning systems and resolving systems-related concept drift issues.\nFurthermore, while the machine learning formulation serves to classify methods\nand literature, the systems theoretic formulation presented herein serves to\nprovide a framework for the top-down design of online learning systems,\nincluding a novel definition of online learning and the identification of key\ndesign parameters. The framework is formulated in terms of input-output systems\nand is further divided into system structure and system behavior. Concept drift\nis a critical challenge faced in online learning, and this work formally\napproaches it as part of the system behavior characteristics. Healthcare\nprovider fraud detection using machine learning is used as a case study\nthroughout the paper to ground the discussion in a real-world online learning\nchallenge.",
      "tldr_zh": "本文从系统理论（systems theoretic）视角审视在线学习（online learning），指出传统机器学习方法忽略了系统结构和动态，从而无法有效处理概念漂移（concept drift）等问题。作者提出一个新的框架，用于在线学习系统的自上而下设计，包括一个novel definition of online learning和关键设计参数，将系统分为输入-输出系统、系统结构和系统行为。借助医疗保健提供者欺诈检测作为案例研究，该框架为构建更鲁棒的在线学习系统提供了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 18th Annual IEEE International Systems Conference\n  (SysCon)",
      "pdf_url": "http://arxiv.org/pdf/2404.03775v1",
      "published_date": "2024-04-04 19:36:47 UTC",
      "updated_date": "2024-04-04 19:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:42:41.730779"
    },
    {
      "arxiv_id": "2404.03753v2",
      "title": "A Reinforcement Learning based Reset Policy for CDCL SAT Solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Chunxiao Li",
        "Charlie Liu",
        "Jonathan Chung",
        "Zhengyang Lu",
        "Piyush Jha",
        "Vijay Ganesh"
      ],
      "abstract": "Restart policy is an important technique used in modern Conflict-Driven\nClause Learning (CDCL) solvers, wherein some parts of the solver state are\nerased at certain intervals during the run of the solver. In most solvers,\nvariable activities are preserved across restart boundaries, resulting in\nsolvers continuing to search parts of the assignment tree that are not far from\nthe one immediately prior to a restart. To enable the solver to search possibly\n\"distant\" parts of the assignment tree, we study the effect of resets, a\nvariant of restarts which not only erases the assignment trail, but also\nrandomizes the activity scores of the variables of the input formula after\nreset, thus potentially enabling a better global exploration of the search\nspace.\n  In this paper, we model the problem of whether to trigger reset as a\nmulti-armed bandit (MAB) problem, and propose two reinforcement learning (RL)\nbased adaptive reset policies using the Upper Confidence Bound (UCB) and\nThompson sampling algorithms. These two algorithms balance the\nexploration-exploitation tradeoff by adaptively choosing arms (reset vs. no\nreset) based on their estimated rewards during the solver's run. We implement\nour reset policies in four baseline SOTA CDCL solvers and compare the baselines\nagainst the reset versions on Satcoin benchmarks and SAT Competition instances.\nOur results show that RL-based reset versions outperform the corresponding\nbaseline solvers on both Satcoin and the SAT competition instances, suggesting\nthat our RL policy helps to dynamically and profitably adapt the reset\nfrequency for any given input instance. We also introduce the concept of a\npartial reset, where at least a constant number of variable activities are\nretained across reset boundaries. Building on previous results, we show that\nthere is an exponential separation between O(1) vs. $\\Omega(n)$-length partial\nresets.",
      "tldr_zh": "本文提出了一种基于 Reinforcement Learning 的 reset 策略，用于改进 Conflict-Driven Clause Learning (CDCL) SAT 求解器中的 restart 政策。该策略将触发 reset 建模为多臂赌博机 (MAB) 问题，利用 Upper Confidence Bound (UCB) 和 Thompson sampling 算法实现自适应选择，以更好地探索搜索空间并平衡探索-利用权衡。在四个 SOTA CDCL 求解器上实验表明，RL-based reset 版本在 Satcoin 基准和 SAT Competition 实例中性能优于基线求解器。此外，论文引入 partial reset 的概念，并证明 O(1) 与 Ω(n) 长度的 partial reset 之间存在指数级分离。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03753v2",
      "published_date": "2024-04-04 18:44:33 UTC",
      "updated_date": "2024-04-19 19:56:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:42:54.415560"
    },
    {
      "arxiv_id": "2404.03746v1",
      "title": "GenQREnsemble: Zero-Shot LLM Ensemble Prompting for Generative Query Reformulation",
      "title_zh": "翻译失败",
      "authors": [
        "Kaustubh Dhole",
        "Eugene Agichtein"
      ],
      "abstract": "Query Reformulation(QR) is a set of techniques used to transform a user's\noriginal search query to a text that better aligns with the user's intent and\nimproves their search experience. Recently, zero-shot QR has been shown to be a\npromising approach due to its ability to exploit knowledge inherent in large\nlanguage models. By taking inspiration from the success of ensemble prompting\nstrategies which have benefited many tasks, we investigate if they can help\nimprove query reformulation. In this context, we propose an ensemble based\nprompting technique, GenQREnsemble which leverages paraphrases of a zero-shot\ninstruction to generate multiple sets of keywords ultimately improving\nretrieval performance. We further introduce its post-retrieval variant,\nGenQREnsembleRF to incorporate pseudo relevant feedback. On evaluations over\nfour IR benchmarks, we find that GenQREnsemble generates better reformulations\nwith relative nDCG@10 improvements up to 18% and MAP improvements upto 24% over\nthe previous zero-shot state-of-art. On the MSMarco Passage Ranking task,\nGenQREnsembleRF shows relative gains of 5% MRR using pseudo-relevance feedback,\nand 9% nDCG@10 using relevant feedback documents.",
      "tldr_zh": "本文提出 GenQREnsemble，一种基于 Zero-Shot LLM Ensemble Prompting 的查询重构（Query Reformulation）技术，通过对 Zero-Shot 指令进行改写生成多个关键词集，从而提升检索性能，并引入其后检索变体 GenQREnsembleRF 以整合伪相关反馈。  \n该方法在四个 IR 基准测试中表现出色，相比之前的 Zero-Shot 状态艺术方法，nDCG@10 相对改善高达 18%，MAP 相对改善高达 24%。  \n在 MSMarco Passage Ranking 任务上，GenQREnsembleRF 使用伪相关反馈实现了 5% MRR 的相对提升，使用相关反馈文档则提升了 9% nDCG@10。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at ECIR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.03746v1",
      "published_date": "2024-04-04 18:35:25 UTC",
      "updated_date": "2024-04-04 18:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:43:07.301029"
    },
    {
      "arxiv_id": "2404.03745v3",
      "title": "Fakes of Varying Shades: How Warning Affects Human Perception and Engagement Regarding LLM Hallucinations",
      "title_zh": "翻译失败",
      "authors": [
        "Mahjabin Nahar",
        "Haeseung Seo",
        "Eun-Ju Lee",
        "Aiping Xiong",
        "Dongwon Lee"
      ],
      "abstract": "The widespread adoption and transformative effects of large language models\n(LLMs) have sparked concerns regarding their capacity to produce inaccurate and\nfictitious content, referred to as `hallucinations'. Given the potential risks\nassociated with hallucinations, humans should be able to identify them. This\nresearch aims to understand the human perception of LLM hallucinations by\nsystematically varying the degree of hallucination (genuine, minor\nhallucination, major hallucination) and examining its interaction with warning\n(i.e., a warning of potential inaccuracies: absent vs. present). Participants\n(N=419) from Prolific rated the perceived accuracy and engaged with content\n(e.g., like, dislike, share) in a Q/A format. Participants ranked content as\ntruthful in the order of genuine, minor hallucination, and major hallucination,\nand user engagement behaviors mirrored this pattern. More importantly, we\nobserved that warning improved the detection of hallucination without\nsignificantly affecting the perceived truthfulness of genuine content. We\nconclude by offering insights for future tools to aid human detection of\nhallucinations. All survey materials, demographic questions, and post-session\nquestions are available at:\nhttps://github.com/MahjabinNahar/fakes-of-varying-shades-survey-materials",
      "tldr_zh": "这篇论文探讨了警告如何影响人类对大型语言模型 (LLMs) 幻觉 (hallucinations) 的感知和互动，具体通过系统变幻觉程度（genuine、minor hallucination 和 major hallucination）并测试警告的存在与否。研究采用在线调查（N=419），让参与者评估内容的感知准确性和行为（如点赞、分享），结果显示参与者对真实性的判断顺序为 genuine > minor hallucination > major hallucination，且互动行为与之一致。关键发现是，警告显著提高了幻觉检测能力，同时不影响 genuine 内容的感知真实性，为开发未来辅助检测工具提供了重要见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.03745v3",
      "published_date": "2024-04-04 18:34:32 UTC",
      "updated_date": "2024-08-12 14:13:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:43:17.974641"
    },
    {
      "arxiv_id": "2404.03732v1",
      "title": "SHROOM-INDElab at SemEval-2024 Task 6: Zero- and Few-Shot LLM-Based Classification for Hallucination Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Bradley P. Allen",
        "Fina Polat",
        "Paul Groth"
      ],
      "abstract": "We describe the University of Amsterdam Intelligent Data Engineering Lab\nteam's entry for the SemEval-2024 Task 6 competition. The SHROOM-INDElab system\nbuilds on previous work on using prompt programming and in-context learning\nwith large language models (LLMs) to build classifiers for hallucination\ndetection, and extends that work through the incorporation of context-specific\ndefinition of task, role, and target concept, and automated generation of\nexamples for use in a few-shot prompting approach. The resulting system\nachieved fourth-best and sixth-best performance in the model-agnostic track and\nmodel-aware tracks for Task 6, respectively, and evaluation using the\nvalidation sets showed that the system's classification decisions were\nconsistent with those of the crowd-sourced human labellers. We further found\nthat a zero-shot approach provided better accuracy than a few-shot approach\nusing automatically generated examples. Code for the system described in this\npaper is available on Github.",
      "tldr_zh": "本研究介绍了阿姆斯特丹大学智能数据工程实验室（SHROOM-INDElab）团队在 SemEval-2024 Task 6 中的参赛系统，该系统利用大型语言模型（LLMs）的提示编程和 in-context learning 构建幻觉检测（hallucination detection）分类器，并通过上下文特定任务定义、角色和目标概念以及自动生成例子来扩展 few-shot prompting 方法。实验结果显示，该系统在模型无关（model-agnostic）轨道和模型感知（model-aware）轨道上分别获得第四和第六名，且其分类决策与人类标注者一致。进一步发现，zero-shot 方法比使用自动生成例子的 few-shot 方法提供更高的准确性，相关代码已在 Github 上开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 6 figures, 4 tables, camera-ready copy, accepted to the 18th\n  International Workshop on Semantic Evaluation (SemEval-2024), for associated\n  code and data see https://github.com/bradleypallen/shroom",
      "pdf_url": "http://arxiv.org/pdf/2404.03732v1",
      "published_date": "2024-04-04 18:01:21 UTC",
      "updated_date": "2024-04-04 18:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:43:30.451851"
    },
    {
      "arxiv_id": "2404.03657v2",
      "title": "OW-VISCapTor: Abstractors for Open-World Video Instance Segmentation and Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Anwesa Choudhuri",
        "Girish Chowdhary",
        "Alexander G. Schwing"
      ],
      "abstract": "We propose the new task 'open-world video instance segmentation and\ncaptioning'. It requires to detect, segment, track and describe with rich\ncaptions never before seen objects. This challenging task can be addressed by\ndeveloping \"abstractors\" which connect a vision model and a language foundation\nmodel. Concretely, we connect a multi-scale visual feature extractor and a\nlarge language model (LLM) by developing an object abstractor and an\nobject-to-text abstractor. The object abstractor, consisting of a prompt\nencoder and transformer blocks, introduces spatially-diverse open-world object\nqueries to discover never before seen objects in videos. An inter-query\ncontrastive loss further encourages the diversity of object queries. The\nobject-to-text abstractor is augmented with masked cross-attention and acts as\na bridge between the object queries and a frozen LLM to generate rich and\ndescriptive object-centric captions for each detected object. Our generalized\napproach surpasses the baseline that jointly addresses the tasks of open-world\nvideo instance segmentation and dense video object captioning by 13% on never\nbefore seen objects, and by 10% on object-centric captions.",
      "tldr_zh": "本研究提出OW-VISCapTor框架及其“abstractors”，旨在解决open-world video instance segmentation and captioning新任务，该任务要求检测、分割、跟踪并用丰富标题描述从未见过的对象。框架通过object abstractor（包括提示编码器、transformer块和spatially-diverse open-world object queries）来发现新对象，并利用inter-query contrastive loss增强查询多样性；同时，object-to-text abstractor通过masked cross-attention桥接object queries和frozen large language model (LLM)，生成详细的对象中心标题。实验结果显示，该方法在从未见过的对象上比基线提升13%，在对象中心标题上提升10%，展示了其在开放世界视频处理中的显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://anwesachoudhuri.github.io/OpenWorldVISCap/",
      "pdf_url": "http://arxiv.org/pdf/2404.03657v2",
      "published_date": "2024-04-04 17:59:58 UTC",
      "updated_date": "2024-12-09 18:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:43:41.224872"
    },
    {
      "arxiv_id": "2404.03653v3",
      "title": "CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Dongzhi Jiang",
        "Guanglu Song",
        "Xiaoshi Wu",
        "Renrui Zhang",
        "Dazhong Shen",
        "Zhuofan Zong",
        "Yu Liu",
        "Hongsheng Li"
      ],
      "abstract": "Diffusion models have demonstrated great success in the field of\ntext-to-image generation. However, alleviating the misalignment between the\ntext prompts and images is still challenging. The root reason behind the\nmisalignment has not been extensively investigated. We observe that the\nmisalignment is caused by inadequate token attention activation. We further\nattribute this phenomenon to the diffusion model's insufficient condition\nutilization, which is caused by its training paradigm. To address the issue, we\npropose CoMat, an end-to-end diffusion model fine-tuning strategy with an\nimage-to-text concept matching mechanism. We leverage an image captioning model\nto measure image-to-text alignment and guide the diffusion model to revisit\nignored tokens. A novel attribute concentration module is also proposed to\naddress the attribute binding problem. Without any image or human preference\ndata, we use only 20K text prompts to fine-tune SDXL to obtain CoMat-SDXL.\nExtensive experiments show that CoMat-SDXL significantly outperforms the\nbaseline model SDXL in two text-to-image alignment benchmarks and achieves\nstart-of-the-art performance.",
      "tldr_zh": "扩散模型在文本到图像生成中常面临文本提示与图像不对齐的问题，该问题源于 token 注意力激活不足和扩散模型的条件利用不充分。论文提出 CoMat，一种端到端的微调策略，通过图像到文本概念匹配机制（如利用图像字幕模型引导模型重新关注忽略的 tokens）和新型属性集中模块来解决属性绑定问题。实验结果显示，仅使用 20K 文本提示微调 SDXL 即可获得 CoMat-SDXL，该模型在两个文本到图像对齐基准上显著优于基线 SDXL，并达到最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.03653v3",
      "published_date": "2024-04-04 17:59:46 UTC",
      "updated_date": "2024-11-27 09:55:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:43:54.667570"
    },
    {
      "arxiv_id": "2404.03647v1",
      "title": "Capabilities of Large Language Models in Control Engineering: A Benchmark Study on GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra",
      "title_zh": "翻译失败",
      "authors": [
        "Darioush Kevian",
        "Usman Syed",
        "Xingang Guo",
        "Aaron Havens",
        "Geir Dullerud",
        "Peter Seiler",
        "Lianhui Qin",
        "Bin Hu"
      ],
      "abstract": "In this paper, we explore the capabilities of state-of-the-art large language\nmodels (LLMs) such as GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra in solving\nundergraduate-level control problems. Controls provides an interesting case\nstudy for LLM reasoning due to its combination of mathematical theory and\nengineering design. We introduce ControlBench, a benchmark dataset tailored to\nreflect the breadth, depth, and complexity of classical control design. We use\nthis dataset to study and evaluate the problem-solving abilities of these LLMs\nin the context of control engineering. We present evaluations conducted by a\npanel of human experts, providing insights into the accuracy, reasoning, and\nexplanatory prowess of LLMs in control engineering. Our analysis reveals the\nstrengths and limitations of each LLM in the context of classical control, and\nour results imply that Claude 3 Opus has become the state-of-the-art LLM for\nsolving undergraduate control problems. Our study serves as an initial step\ntowards the broader goal of employing artificial general intelligence in\ncontrol engineering.",
      "tldr_zh": "本文评估了 GPT-4、Claude 3 Opus 和 Gemini 1.0 Ultra 等大型语言模型（LLMs）在解决本科级控制工程问题上的能力，控制工程结合了数学理论和工程设计。研究引入了 ControlBench 基准数据集，以反映经典控制设计的广度、深度和复杂性，并通过人类专家小组进行评估，考察这些 LLMs 的准确性、推理和解释能力。结果显示，Claude 3 Opus 在本科控制问题上表现出色，成为当前最先进的 LLM，同时揭示了各模型的优势和局限性。该研究为将人工智能一般智能应用于控制工程领域奠定了初步基础。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03647v1",
      "published_date": "2024-04-04 17:58:38 UTC",
      "updated_date": "2024-04-04 17:58:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:44:07.096080"
    },
    {
      "arxiv_id": "2404.03715v1",
      "title": "Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Corby Rosset",
        "Ching-An Cheng",
        "Arindam Mitra",
        "Michael Santacroce",
        "Ahmed Awadallah",
        "Tengyang Xie"
      ],
      "abstract": "This paper studies post-training large language models (LLMs) using\npreference feedback from a powerful oracle to help a model iteratively improve\nover itself. The typical approach for post-training LLMs involves Reinforcement\nLearning from Human Feedback (RLHF), which traditionally separates reward\nlearning and subsequent policy optimization. However, such a reward\nmaximization approach is limited by the nature of \"point-wise\" rewards (such as\nBradley-Terry model), which fails to express complex intransitive or cyclic\npreference relations. While advances on RLHF show reward learning and policy\noptimization can be merged into a single contrastive objective for stability,\nthey yet still remain tethered to the reward maximization framework. Recently,\na new wave of research sidesteps the reward maximization presumptions in favor\nof directly optimizing over \"pair-wise\" or general preferences. In this paper,\nwe introduce Direct Nash Optimization (DNO), a provable and scalable algorithm\nthat marries the simplicity and stability of contrastive learning with\ntheoretical generality from optimizing general preferences. Because DNO is a\nbatched on-policy algorithm using a regression-based objective, its\nimplementation is straightforward and efficient. Moreover, DNO enjoys monotonic\nimprovement across iterations that help it improve even over a strong teacher\n(such as GPT-4). In our experiments, a resulting 7B parameter Orca-2.5 model\naligned by DNO achieves the state-of-the-art win-rate against GPT-4-Turbo of\n33% on AlpacaEval 2.0 (even after controlling for response length), an absolute\ngain of 26% (7% to 33%) over the initializing model. It outperforms models with\nfar more parameters, including Mistral Large, Self-Rewarding LM (70B\nparameters), and older versions of GPT-4.",
      "tldr_zh": "本论文提出Direct Nash Optimization (DNO)，一种可证明且可扩展的算法，用于后训练大型语言模型 (LLMs)，通过直接优化一般偏好（如配对偏好）来实现模型的自我迭代改进，而非依赖传统Reinforcement Learning from Human Feedback (RLHF)的奖励最大化框架，后者受限于点式奖励无法处理复杂的偏好关系。DNO结合对比学习的稳定性和简单性，使用批处理在线策略及基于回归的目标，确保迭代过程中的单调改进，甚至超越强教师模型如GPT-4。实验结果显示，一款7B参数的Orca-2.5模型经DNO优化后，在AlpacaEval 2.0基准上对GPT-4-Turbo的胜率达到33%，较初始模型绝对提升26%，并优于更大参数的模型如Mistral Large和Self-Rewarding LM。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03715v1",
      "published_date": "2024-04-04 17:56:41 UTC",
      "updated_date": "2024-04-04 17:56:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:44:21.186823"
    },
    {
      "arxiv_id": "2404.03635v4",
      "title": "WorDepth: Variational Language Prior for Monocular Depth Estimation",
      "title_zh": "WorDepth：用于单目深度估计的变分语言先验",
      "authors": [
        "Ziyao Zeng",
        "Daniel Wang",
        "Fengyu Yang",
        "Hyoungseob Park",
        "Yangchao Wu",
        "Stefano Soatto",
        "Byung-Woo Hong",
        "Dong Lao",
        "Alex Wong"
      ],
      "abstract": "Three-dimensional (3D) reconstruction from a single image is an ill-posed\nproblem with inherent ambiguities, i.e. scale. Predicting a 3D scene from text\ndescription(s) is similarly ill-posed, i.e. spatial arrangements of objects\ndescribed. We investigate the question of whether two inherently ambiguous\nmodalities can be used in conjunction to produce metric-scaled reconstructions.\nTo test this, we focus on monocular depth estimation, the problem of predicting\na dense depth map from a single image, but with an additional text caption\ndescribing the scene. To this end, we begin by encoding the text caption as a\nmean and standard deviation; using a variational framework, we learn the\ndistribution of the plausible metric reconstructions of 3D scenes corresponding\nto the text captions as a prior. To \"select\" a specific reconstruction or depth\nmap, we encode the given image through a conditional sampler that samples from\nthe latent space of the variational text encoder, which is then decoded to the\noutput depth map. Our approach is trained alternatingly between the text and\nimage branches: in one optimization step, we predict the mean and standard\ndeviation from the text description and sample from a standard Gaussian, and in\nthe other, we sample using a (image) conditional sampler. Once trained, we\ndirectly predict depth from the encoded text using the conditional sampler. We\ndemonstrate our approach on indoor (NYUv2) and outdoor (KITTI) scenarios, where\nwe show that language can consistently improve performance in both.",
      "tldr_zh": "该论文提出WorDepth框架，利用变分语言先验（Variational Language Prior）来提升单目深度估计（Monocular Depth Estimation）的性能，解决从单张图像重建3D场景的模糊性问题，如尺度不确定性。方法通过将文本描述编码为均值和标准差，形成一个表示可信3D场景分布的先验，然后使用条件采样器结合图像信息采样并解码生成深度图。训练过程交替优化文本和图像分支，最终在室内（NYUv2）和室外（KITTI）数据集上实验证明，语言先验能一致改善深度估计的准确性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03635v4",
      "published_date": "2024-04-04 17:54:33 UTC",
      "updated_date": "2024-06-02 04:56:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:44:33.456883"
    },
    {
      "arxiv_id": "2404.03714v1",
      "title": "SpikeExplorer: hardware-oriented Design Space Exploration for Spiking Neural Networks on FPGA",
      "title_zh": "SpikeExplorer：面向硬件",
      "authors": [
        "Dario Padovano",
        "Alessio Carpegna",
        "Alessandro Savino",
        "Stefano Di Carlo"
      ],
      "abstract": "One of today's main concerns is to bring Artificial Intelligence power to\nembedded systems for edge applications. The hardware resources and power\nconsumption required by state-of-the-art models are incompatible with the\nconstrained environments observed in edge systems, such as IoT nodes and\nwearable devices. Spiking Neural Networks (SNNs) can represent a solution in\nthis sense: inspired by neuroscience, they reach unparalleled power and\nresource efficiency when run on dedicated hardware accelerators. However, when\ndesigning such accelerators, the amount of choices that can be taken is huge.\nThis paper presents SpikExplorer, a modular and flexible Python tool for\nhardware-oriented Automatic Design Space Exploration to automate the\nconfiguration of FPGA accelerators for SNNs. Using Bayesian optimizations,\nSpikerExplorer enables hardware-centric multi-objective optimization,\nsupporting factors such as accuracy, area, latency, power, and various\ncombinations during the exploration process. The tool searches the optimal\nnetwork architecture, neuron model, and internal and training parameters,\ntrying to reach the desired constraints imposed by the user. It allows for a\nstraightforward network configuration, providing the full set of explored\npoints for the user to pick the trade-off that best fits the needs. The\npotential of SpikExplorer is showcased using three benchmark datasets. It\nreaches 95.8% accuracy on the MNIST dataset, with a power consumption of\n180mW/image and a latency of 0.12 ms/image, making it a powerful tool for\nautomatically optimizing SNNs.",
      "tldr_zh": "该研究提出 SpikeExplorer，一种模块化和灵活的 Python 工具，用于硬件导向的自动设计空间探索（Design Space Exploration），旨在优化 Spiking Neural Networks (SNNs) 在 FPGA 上的加速器配置。工具采用 Bayesian optimizations 进行硬件中心的多目标优化，包括准确率、面积、延迟、功耗等因素，并自动搜索最佳网络架构、神经元模型和参数，以满足用户设定的约束。实验结果显示，在 MNIST 数据集上，SpikeExplorer 实现了 95.8% 的准确率，同时功耗仅为 180mW/image 和延迟 0.12 ms/image，展示了其在提升 SNNs 边缘应用效率方面的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03714v1",
      "published_date": "2024-04-04 17:53:08 UTC",
      "updated_date": "2024-04-04 17:53:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:44:43.517819"
    },
    {
      "arxiv_id": "2404.03624v1",
      "title": "Standardizing Knowledge Engineering Practices with a Reference Architecture",
      "title_zh": "基于参考架构标准化知识工程实践",
      "authors": [
        "Bradley P. Allen",
        "Filip Ilievski"
      ],
      "abstract": "Knowledge engineering is the process of creating and maintaining\nknowledge-producing systems. Throughout the history of computer science and AI,\nknowledge engineering workflows have been widely used given the importance of\nhigh-quality knowledge for reliable intelligent agents. Meanwhile, the scope of\nknowledge engineering, as apparent from its target tasks and use cases, has\nbeen shifting, together with its paradigms such as expert systems, semantic\nweb, and language modeling. The intended use cases and supported user\nrequirements between these paradigms have not been analyzed globally, as new\nparadigms often satisfy prior pain points while possibly introducing new ones.\nThe recent abstraction of systemic patterns into a boxology provides an opening\nfor aligning the requirements and use cases of knowledge engineering with the\nsystems, components, and software that can satisfy them best. This paper\nproposes a vision of harmonizing the best practices in the field of knowledge\nengineering by leveraging the software engineering methodology of creating\nreference architectures. We describe how a reference architecture can be\niteratively designed and implemented to associate user needs with recurring\nsystemic patterns, building on top of existing knowledge engineering workflows\nand boxologies. We provide a six-step roadmap that can enable the development\nof such an architecture, providing an initial design and outcome of the\ndefinition of architectural scope, selection of information sources, and\nanalysis. We expect that following through on this vision will lead to\nwell-grounded reference architectures for knowledge engineering, will advance\nthe ongoing initiatives of organizing the neurosymbolic knowledge engineering\nspace, and will build new links to the software architectures and data science\ncommunities.",
      "tldr_zh": "这篇论文探讨了知识工程（knowledge engineering）的演变及其在不同范式（如专家系统、语义网和语言建模）中面临的用户需求和痛点问题。作者提出一个愿景，通过创建参考架构（reference architecture）来标准化知识工程的最佳实践，该架构基于现有工作流程和系统模式（boxology），将用户需求与合适系统组件关联。论文提供了一个六步路线图，包括定义架构范围、选择信息来源和进行分析，预期这将促进神经符号知识工程的空间组织，并加强与软件架构和数据科学社区的联系。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 4 figures, 2 tables, camera-ready version, accepted for\n  Transactions on Graph Data and Knowledge (TGDK)",
      "pdf_url": "http://arxiv.org/pdf/2404.03624v1",
      "published_date": "2024-04-04 17:46:32 UTC",
      "updated_date": "2024-04-04 17:46:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:44:56.583877"
    },
    {
      "arxiv_id": "2404.03713v2",
      "title": "Explaining Explainability: Recommendations for Effective Use of Concept Activation Vectors",
      "title_zh": "翻译失败",
      "authors": [
        "Angus Nicolson",
        "Lisa Schut",
        "J. Alison Noble",
        "Yarin Gal"
      ],
      "abstract": "Concept-based explanations translate the internal representations of deep\nlearning models into a language that humans are familiar with: concepts. One\npopular method for finding concepts is Concept Activation Vectors (CAVs), which\nare learnt using a probe dataset of concept exemplars. In this work, we\ninvestigate three properties of CAVs: (1) inconsistency across layers, (2)\nentanglement with other concepts, and (3) spatial dependency. Each property\nprovides both challenges and opportunities in interpreting models. We introduce\ntools designed to detect the presence of these properties, provide insight into\nhow each property can lead to misleading explanations, and provide\nrecommendations to mitigate their impact. To demonstrate practical\napplications, we apply our recommendations to a melanoma classification task,\nshowing how entanglement can lead to uninterpretable results and that the\nchoice of negative probe set can have a substantial impact on the meaning of a\nCAV. Further, we show that understanding these properties can be used to our\nadvantage. For example, we introduce spatially dependent CAVs to test if a\nmodel is translation invariant with respect to a specific concept and class.\nOur experiments are performed on natural images (ImageNet), skin lesions (ISIC\n2019), and a new synthetic dataset, Elements. Elements is designed to capture a\nknown ground truth relationship between concepts and classes. We release this\ndataset to facilitate further research in understanding and evaluating\ninterpretability methods.",
      "tldr_zh": "该论文探讨了 Concept Activation Vectors (CAVs) 在解释深度学习模型时的三个关键属性：层间不一致性、与其他概念的纠缠，以及空间依赖性，这些属性可能导致误导性解释。作者引入了检测工具，并提供了缓解建议，例如在黑素瘤分类任务中，展示了概念纠缠如何影响结果，以及选择负探针集的重要性。进一步，他们引入了空间依赖 CAVs 来测试模型对特定概念和类的平移不变性，并通过实验验证了这些属性的实际应用。论文还发布了一个新合成数据集 Elements，以支持进一步的解释性方法研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Transactions on Machine Learning Research (02/2025)",
      "pdf_url": "http://arxiv.org/pdf/2404.03713v2",
      "published_date": "2024-04-04 17:46:20 UTC",
      "updated_date": "2025-02-13 09:48:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:45:10.753936"
    },
    {
      "arxiv_id": "2404.03623v2",
      "title": "Unveiling LLMs: The Evolution of Latent Representations in a Dynamic Knowledge Graph",
      "title_zh": "揭示 LLMs：动态知识图谱中潜在表示的演变",
      "authors": [
        "Marco Bronzini",
        "Carlo Nicolini",
        "Bruno Lepri",
        "Jacopo Staiano",
        "Andrea Passerini"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate an impressive capacity to recall a\nvast range of factual knowledge. However, understanding their underlying\nreasoning and internal mechanisms in exploiting this knowledge remains a key\nresearch area. This work unveils the factual information an LLM represents\ninternally for sentence-level claim verification. We propose an end-to-end\nframework to decode factual knowledge embedded in token representations from a\nvector space to a set of ground predicates, showing its layer-wise evolution\nusing a dynamic knowledge graph. Our framework employs activation patching, a\nvector-level technique that alters a token representation during inference, to\nextract encoded knowledge. Accordingly, we neither rely on training nor\nexternal models. Using factual and common-sense claims from two claim\nverification datasets, we showcase interpretability analyses at local and\nglobal levels. The local analysis highlights entity centrality in LLM\nreasoning, from claim-related information and multi-hop reasoning to\nrepresentation errors causing erroneous evaluation. On the other hand, the\nglobal reveals trends in the underlying evolution, such as word-based knowledge\nevolving into claim-related facts. By interpreting semantics from LLM latent\nrepresentations and enabling graph-related analyses, this work enhances the\nunderstanding of the factual knowledge resolution process.",
      "tldr_zh": "这篇论文探讨大型语言模型(LLMs)内部事实知识的表示和演化，专注于句子级声明验证。研究提出一个端到端框架，使用 activation patching 技术从向量空间解码 token 表示为基础谓词，并通过动态 knowledge graph 展示层级演化过程，而不依赖训练或外部模型。通过局部分析，论文突出实体在 LLM 推理中的中心性，包括多跳推理和表示错误；全局分析则揭示知识从词级向声明相关事实的演变趋势。该工作增强了对 LLM 事实知识解析机制的理解和可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.03623v2",
      "published_date": "2024-04-04 17:45:59 UTC",
      "updated_date": "2024-08-06 15:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:45:21.162920"
    },
    {
      "arxiv_id": "2404.16045v1",
      "title": "Elicitron: An LLM Agent-Based Simulation Framework for Design Requirements Elicitation",
      "title_zh": "Elicitron：一种基于LLM代理的模拟框架，用于设计需求获取",
      "authors": [
        "Mohammadmehdi Ataei",
        "Hyunmin Cheong",
        "Daniele Grandi",
        "Ye Wang",
        "Nigel Morris",
        "Alexander Tessier"
      ],
      "abstract": "Requirements elicitation, a critical, yet time-consuming and challenging step\nin product development, often fails to capture the full spectrum of user needs.\nThis may lead to products that fall short of expectations. This paper\nintroduces a novel framework that leverages Large Language Models (LLMs) to\nautomate and enhance the requirements elicitation process. LLMs are used to\ngenerate a vast array of simulated users (LLM agents), enabling the exploration\nof a much broader range of user needs and unforeseen use cases. These agents\nengage in product experience scenarios, through explaining their actions,\nobservations, and challenges. Subsequent agent interviews and analysis uncover\nvaluable user needs, including latent ones. We validate our framework with\nthree experiments. First, we explore different methodologies for diverse agent\ngeneration, discussing their advantages and shortcomings. We measure the\ndiversity of identified user needs and demonstrate that context-aware agent\ngeneration leads to greater diversity. Second, we show how our framework\neffectively mimics empathic lead user interviews, identifying a greater number\nof latent needs than conventional human interviews. Third, we showcase that\nLLMs can be used to analyze interviews, capture needs, and classify them as\nlatent or not. Our work highlights the potential of using LLM agents to\naccelerate early-stage product development, reduce costs, and increase\ninnovation.",
      "tldr_zh": "该论文引入 Elicitron 框架，利用 Large Language Models (LLMs) 生成模拟用户代理（LLM agents），以自动化和提升设计需求获取过程。这些代理参与产品体验场景，通过解释行动、观察和挑战，并进行后续访谈和分析，揭示更广泛的用户需求，包括潜在需求。实验结果显示，上下文感知的代理生成方法能提高需求多样性，并比传统访谈识别更多潜在需求，同时 LLMs 可有效分析访谈并分类需求。整体而言，该框架有助于加速早期产品开发、降低成本并增强创新潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16045v1",
      "published_date": "2024-04-04 17:36:29 UTC",
      "updated_date": "2024-04-04 17:36:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:45:33.600206"
    },
    {
      "arxiv_id": "2404.03611v1",
      "title": "InsectMamba: Insect Pest Classification with State Space Model",
      "title_zh": "翻译失败",
      "authors": [
        "Qianning Wang",
        "Chenglin Wang",
        "Zhixin Lai",
        "Yucheng Zhou"
      ],
      "abstract": "The classification of insect pests is a critical task in agricultural\ntechnology, vital for ensuring food security and environmental sustainability.\nHowever, the complexity of pest identification, due to factors like high\ncamouflage and species diversity, poses significant obstacles. Existing methods\nstruggle with the fine-grained feature extraction needed to distinguish between\nclosely related pest species. Although recent advancements have utilized\nmodified network structures and combined deep learning approaches to improve\naccuracy, challenges persist due to the similarity between pests and their\nsurroundings. To address this problem, we introduce InsectMamba, a novel\napproach that integrates State Space Models (SSMs), Convolutional Neural\nNetworks (CNNs), Multi-Head Self-Attention mechanism (MSA), and Multilayer\nPerceptrons (MLPs) within Mix-SSM blocks. This integration facilitates the\nextraction of comprehensive visual features by leveraging the strengths of each\nencoding strategy. A selective module is also proposed to adaptively aggregate\nthese features, enhancing the model's ability to discern pest characteristics.\nInsectMamba was evaluated against strong competitors across five insect pest\nclassification datasets. The results demonstrate its superior performance and\nverify the significance of each model component by an ablation study.",
      "tldr_zh": "这项研究针对昆虫害虫分类的挑战（如高伪装和物种多样性），提出了一种新型模型InsectMamba，以提升细粒度特征提取能力。InsectMamba整合了State Space Models (SSMs)、Convolutional Neural Networks (CNNs)、Multi-Head Self-Attention mechanism (MSA)和Multilayer Perceptrons (MLPs)于Mix-SSM blocks中，并引入一个selective module来自适应聚合特征，从而更好地辨别害虫特性。与现有方法相比，该模型在五个昆虫害虫分类数据集上表现出色，准确率领先竞争对手，并通过消融研究验证了各组件的显著贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.03611v1",
      "published_date": "2024-04-04 17:34:21 UTC",
      "updated_date": "2024-04-04 17:34:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:45:45.561251"
    },
    {
      "arxiv_id": "2404.03608v1",
      "title": "Sailor: Open Language Models for South-East Asia",
      "title_zh": "Sailor：面向东南亚的开源语言模型",
      "authors": [
        "Longxu Dou",
        "Qian Liu",
        "Guangtao Zeng",
        "Jia Guo",
        "Jiahui Zhou",
        "Wei Lu",
        "Min Lin"
      ],
      "abstract": "We present Sailor, a family of open language models ranging from 0.5B to 7B\nparameters, tailored for South-East Asian (SEA) languages. These models are\ncontinually pre-trained from Qwen1.5, a great language model for multilingual\nuse cases. From Qwen1.5, Sailor models accept 200B to 400B tokens, primarily\ncovering the languages of English, Chinese, Vietnamese, Thai, Indonesian,\nMalay, and Lao. The training leverages several techniques, including BPE\ndropout for improving the model robustness, aggressive data cleaning and\ndeduplication, and small proxy models to optimize data mixture. Experimental\nresults on four typical tasks indicate that Sailor models demonstrate strong\nperformance across different benchmarks, including commonsense reasoning,\nquestion answering, reading comprehension and examination. Embracing the\nopen-source spirit, we share our insights through this report to spark a wider\ninterest in developing large language models for multilingual use cases.",
      "tldr_zh": "本研究推出了 Sailor 系列开源语言模型，参数从 0.5B 到 7B，针对东南亚语言（如英语、中文、越南语、泰语、印尼语、马来语和老挝语）进行优化。模型基于 Qwen1.5 进行持续预训练，处理 200B 到 400B tokens，并采用 BPE dropout、数据清洗和去重以及小代理模型等技术来提升鲁棒性和数据混合。实验结果显示，Sailor 模型在常识推理、问答、阅读理解和考试等任务上表现出色，并通过开源报告分享见解，以推动多语言大语言模型的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code is available at https://github.com/sail-sg/sailor-llm",
      "pdf_url": "http://arxiv.org/pdf/2404.03608v1",
      "published_date": "2024-04-04 17:31:32 UTC",
      "updated_date": "2024-04-04 17:31:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:45:56.320766"
    },
    {
      "arxiv_id": "2404.03606v1",
      "title": "Analyzing Musical Characteristics of National Anthems in Relation to Global Indices",
      "title_zh": "分析国家国歌的音乐特征与全球指数的关系",
      "authors": [
        "S M Rakib Hasan",
        "Aakar Dhakal",
        "Ms. Ayesha Siddiqua",
        "Mohammad Mominur Rahman",
        "Md Maidul Islam",
        "Mohammed Arfat Raihan Chowdhury",
        "S M Masfequier Rahman Swapno",
        "SM Nuruzzaman Nobel"
      ],
      "abstract": "Music plays a huge part in shaping peoples' psychology and behavioral\npatterns. This paper investigates the connection between national anthems and\ndifferent global indices with computational music analysis and statistical\ncorrelation analysis. We analyze national anthem musical data to determine\nwhether certain musical characteristics are associated with peace, happiness,\nsuicide rate, crime rate, etc. To achieve this, we collect national anthems\nfrom 169 countries and use computational music analysis techniques to extract\npitch, tempo, beat, and other pertinent audio features. We then compare these\nmusical characteristics with data on different global indices to ascertain\nwhether a significant correlation exists. Our findings indicate that there may\nbe a correlation between the musical characteristics of national anthems and\nthe indices we investigated. The implications of our findings for music\npsychology and policymakers interested in promoting social well-being are\ndiscussed. This paper emphasizes the potential of musical data analysis in\nsocial research and offers a novel perspective on the relationship between\nmusic and social indices. The source code and data are made open-access for\nreproducibility and future research endeavors. It can be accessed at\nhttp://bit.ly/na_code.",
      "tldr_zh": "本文研究了国家国歌的音乐特征与全球指数（如和平、幸福、自杀率和犯罪率等）之间的潜在关联，旨在探讨音乐对心理和行为的影响。研究者收集了169个国家的国歌数据，使用计算音乐分析（computational music analysis）提取音高、节奏、节拍等音频特征，并通过统计相关分析比较这些特征与全球指数的数据。结果显示，国歌的音乐特征可能与社会指数存在显著相关性，为音乐心理学和政策制定者提供新视角。该研究开源了代码和数据，以支持可重复性和未来研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.IR",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03606v1",
      "published_date": "2024-04-04 17:25:31 UTC",
      "updated_date": "2024-04-04 17:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:46:08.054907"
    },
    {
      "arxiv_id": "2404.03596v1",
      "title": "Laser Learning Environment: A new environment for coordination-critical multi-agent tasks",
      "title_zh": "Laser Learning Environment：一个新的环境，用于协调关键的多智能体任务",
      "authors": [
        "Yannick Molinghen",
        "Raphaël Avalos",
        "Mark Van Achter",
        "Ann Nowé",
        "Tom Lenaerts"
      ],
      "abstract": "We introduce the Laser Learning Environment (LLE), a collaborative\nmulti-agent reinforcement learning environment in which coordination is\ncentral. In LLE, agents depend on each other to make progress\n(interdependence), must jointly take specific sequences of actions to succeed\n(perfect coordination), and accomplishing those joint actions does not yield\nany intermediate reward (zero-incentive dynamics). The challenge of such\nproblems lies in the difficulty of escaping state space bottlenecks caused by\ninterdependence steps since escaping those bottlenecks is not rewarded. We test\nmultiple state-of-the-art value-based MARL algorithms against LLE and show that\nthey consistently fail at the collaborative task because of their inability to\nescape state space bottlenecks, even though they successfully achieve perfect\ncoordination. We show that Q-learning extensions such as prioritized experience\nreplay and n-steps return hinder exploration in environments with\nzero-incentive dynamics, and find that intrinsic curiosity with random network\ndistillation is not sufficient to escape those bottlenecks. We demonstrate the\nneed for novel methods to solve this problem and the relevance of LLE as\ncooperative MARL benchmark.",
      "tldr_zh": "这篇论文引入了Laser Learning Environment (LLE)，一个专注于协调的多智能体强化学习(MARL)环境，其中代理相互依赖，必须共同执行特定动作序列才能成功，且这些动作没有中间奖励（zero-incentive dynamics）。实验测试了多种最先进的基于价值的MARL算法，发现它们尽管能实现完美协调，但无法逃脱状态空间瓶颈，导致任务失败。研究还指出，Q-learning的扩展如优先经验回放和n-steps return会阻碍探索，而内在好奇心（如随机网络蒸馏）也不足以解决问题。总之，LLE作为新的合作MARL基准，强调了开发新型方法来应对此类协调挑战的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Pre-print, 21 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.03596v1",
      "published_date": "2024-04-04 17:05:42 UTC",
      "updated_date": "2024-04-04 17:05:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:46:22.829999"
    },
    {
      "arxiv_id": "2404.03592v3",
      "title": "ReFT: Representation Finetuning for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengxuan Wu",
        "Aryaman Arora",
        "Zheng Wang",
        "Atticus Geiger",
        "Dan Jurafsky",
        "Christopher D. Manning",
        "Christopher Potts"
      ],
      "abstract": "Parameter-efficient finetuning (PEFT) methods seek to adapt large neural\nmodels via updates to a small number of weights. However, much prior\ninterpretability work has shown that representations encode rich semantic\ninformation, suggesting that editing representations might be a more powerful\nalternative. We pursue this hypothesis by developing a family of Representation\nFinetuning (ReFT) methods. ReFT methods operate on a frozen base model and\nlearn task-specific interventions on hidden representations. We define a strong\ninstance of the ReFT family, Low-rank Linear Subspace ReFT (LoReFT), and we\nidentify an ablation of this method that trades some performance for increased\nefficiency. Both are drop-in replacements for existing PEFTs and learn\ninterventions that are 15x--65x more parameter-efficient than LoRA. We showcase\nLoReFT on eight commonsense reasoning tasks, four arithmetic reasoning tasks,\ninstruction-tuning, and GLUE. In all these evaluations, our ReFTs deliver the\nbest balance of efficiency and performance, and almost always outperform\nstate-of-the-art PEFTs. We release a generic ReFT training library publicly at\nhttps://github.com/stanfordnlp/pyreft.",
      "tldr_zh": "这篇论文提出了一种名为 Representation Finetuning (ReFT) 的方法，作为 Parameter-efficient finetuning (PEFT) 的替代方案，通过在冻结的语言模型上编辑隐藏表示来实现任务特定干预。核心实现包括 Low-rank Linear Subspace ReFT (LoReFT) 和其高效变体，比现有方法如 LoRA 更参数高效（15x-65x）。实验在八个常识推理任务、四个算术推理任务、指令微调和 GLUE 上显示，ReFT 提供了最佳的效率与性能平衡，并几乎在所有评估中优于状态-of-the-art PEFT 方法。作者还公开了 ReFT 训练库（https://github.com/stanfordnlp/pyreft）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2404.03592v3",
      "published_date": "2024-04-04 17:00:37 UTC",
      "updated_date": "2024-05-22 17:52:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:46:33.615026"
    },
    {
      "arxiv_id": "2404.03590v1",
      "title": "SemGrasp: Semantic Grasp Generation via Language Aligned Discretization",
      "title_zh": "SemGrasp：通过语言对齐离散化的语义抓取生成",
      "authors": [
        "Kailin Li",
        "Jingbo Wang",
        "Lixin Yang",
        "Cewu Lu",
        "Bo Dai"
      ],
      "abstract": "Generating natural human grasps necessitates consideration of not just object\ngeometry but also semantic information. Solely depending on object shape for\ngrasp generation confines the applications of prior methods in downstream\ntasks. This paper presents a novel semantic-based grasp generation method,\ntermed SemGrasp, which generates a static human grasp pose by incorporating\nsemantic information into the grasp representation. We introduce a discrete\nrepresentation that aligns the grasp space with semantic space, enabling the\ngeneration of grasp postures in accordance with language instructions. A\nMultimodal Large Language Model (MLLM) is subsequently fine-tuned, integrating\nobject, grasp, and language within a unified semantic space. To facilitate the\ntraining of SemGrasp, we have compiled a large-scale, grasp-text-aligned\ndataset named CapGrasp, featuring about 260k detailed captions and 50k diverse\ngrasps. Experimental findings demonstrate that SemGrasp efficiently generates\nnatural human grasps in alignment with linguistic intentions. Our code, models,\nand dataset are available publicly at: https://kailinli.github.io/SemGrasp.",
      "tldr_zh": "该论文提出了一种新型语义抓取生成方法SemGrasp，通过语言对齐的离散表示，将抓取空间与语义空间整合，从而生成符合语言指令的自然人类抓取姿势。方法利用Multimodal Large Language Model (MLLM)进行微调，将对象、抓取和语言统一到一个语义空间中，以解决传统基于对象几何方法的局限性。为训练SemGrasp，研究者构建了大规模数据集CapGrasp，包含约26万详细描述和5万多样抓取样本。实验结果显示，SemGrasp能高效生成与语言意图一致的抓取姿势，并已公开代码、模型和数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03590v1",
      "published_date": "2024-04-04 16:58:26 UTC",
      "updated_date": "2024-04-04 16:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:46:45.012143"
    },
    {
      "arxiv_id": "2404.03587v1",
      "title": "Anticipate & Collab: Data-driven Task Anticipation and Knowledge-driven Planning for Human-robot Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Shivam Singh",
        "Karthik Swaminathan",
        "Raghav Arora",
        "Ramandeep Singh",
        "Ahana Datta",
        "Dipanjan Das",
        "Snehasis Banerjee",
        "Mohan Sridharan",
        "Madhava Krishna"
      ],
      "abstract": "An agent assisting humans in daily living activities can collaborate more\neffectively by anticipating upcoming tasks. Data-driven methods represent the\nstate of the art in task anticipation, planning, and related problems, but\nthese methods are resource-hungry and opaque. Our prior work introduced a proof\nof concept framework that used an LLM to anticipate 3 high-level tasks that\nserved as goals for a classical planning system that computed a sequence of\nlow-level actions for the agent to achieve these goals. This paper describes\nDaTAPlan, our framework that significantly extends our prior work toward\nhuman-robot collaboration. Specifically, DaTAPlan planner computes actions for\nan agent and a human to collaboratively and jointly achieve the tasks\nanticipated by the LLM, and the agent automatically adapts to unexpected\nchanges in human action outcomes and preferences. We evaluate DaTAPlan\ncapabilities in a realistic simulation environment, demonstrating accurate task\nanticipation, effective human-robot collaboration, and the ability to adapt to\nunexpected changes. Project website: https://dataplan-hrc.github.io",
      "tldr_zh": "该论文提出DaTAPlan框架，用于提升人类-机器人协作效率，通过LLM进行数据驱动的任务预测，并结合知识驱动的规划系统计算协作行动序列。该框架扩展了先前工作，支持代理和人类共同实现高水平任务，同时能自动适应人类行动结果和偏好的意外变化。在真实模拟环境中，DaTAPlan展示了准确的任务预测、有效协作能力，并证明了其在处理动态场景中的适应性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03587v1",
      "published_date": "2024-04-04 16:52:48 UTC",
      "updated_date": "2024-04-04 16:52:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:46:55.488122"
    },
    {
      "arxiv_id": "2404.03574v1",
      "title": "TinyVQA: Compact Multimodal Deep Neural Network for Visual Question Answering on Resource-Constrained Devices",
      "title_zh": "TinyVQA：紧凑型多模态深度神经网络，用于资源受限设备的视觉问答",
      "authors": [
        "Hasib-Al Rashid",
        "Argho Sarkar",
        "Aryya Gangopadhyay",
        "Maryam Rahnemoonfar",
        "Tinoosh Mohsenin"
      ],
      "abstract": "Traditional machine learning models often require powerful hardware, making\nthem unsuitable for deployment on resource-limited devices. Tiny Machine\nLearning (tinyML) has emerged as a promising approach for running machine\nlearning models on these devices, but integrating multiple data modalities into\ntinyML models still remains a challenge due to increased complexity, latency,\nand power consumption. This paper proposes TinyVQA, a novel multimodal deep\nneural network for visual question answering tasks that can be deployed on\nresource-constrained tinyML hardware. TinyVQA leverages a supervised\nattention-based model to learn how to answer questions about images using both\nvision and language modalities. Distilled knowledge from the supervised\nattention-based VQA model trains the memory aware compact TinyVQA model and low\nbit-width quantization technique is employed to further compress the model for\ndeployment on tinyML devices. The TinyVQA model was evaluated on the FloodNet\ndataset, which is used for post-disaster damage assessment. The compact model\nachieved an accuracy of 79.5%, demonstrating the effectiveness of TinyVQA for\nreal-world applications. Additionally, the model was deployed on a Crazyflie\n2.0 drone, equipped with an AI deck and GAP8 microprocessor. The TinyVQA model\nachieved low latencies of 56 ms and consumes 693 mW power while deployed on the\ntiny drone, showcasing its suitability for resource-constrained embedded\nsystems.",
      "tldr_zh": "这篇论文提出 TinyVQA，一种紧凑的多模态深度神经网络，旨在解决传统机器学习模型在资源受限设备上的部署挑战，特别是整合视觉和语言模态的 tinyML 难题。TinyVQA 采用监督注意力机制和知识蒸馏训练方法，并通过低位宽量化技术进一步压缩模型，使其适合于嵌入式系统。实验结果显示，该模型在 FloodNet 数据集上实现了 79.5% 的准确率，并在 Crazyflie 2.0 无人机上部署时，达到 56 ms 的低延迟和 693 mW 的功耗，证明了其在实际应用中的高效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a full paper by the tinyML Research Symposium 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.03574v1",
      "published_date": "2024-04-04 16:38:49 UTC",
      "updated_date": "2024-04-04 16:38:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:47:11.704951"
    },
    {
      "arxiv_id": "2404.03549v1",
      "title": "Alzheimer's disease detection in PSG signals",
      "title_zh": "翻译失败",
      "authors": [
        "Lorena Gallego-Viñarás",
        "Juan Miguel Mira-Tomás",
        "Anna Michela-Gaeta",
        "Gerard Pinol-Ripoll",
        "Ferrán Barbé",
        "Pablo M. Olmos",
        "Arrate Muñoz-Barrutia"
      ],
      "abstract": "Alzheimer's disease (AD) and sleep disorders exhibit a close association,\nwhere disruptions in sleep patterns often precede the onset of Mild Cognitive\nImpairment (MCI) and early-stage AD. This study delves into the potential of\nutilizing sleep-related electroencephalography (EEG) signals acquired through\npolysomnography (PSG) for the early detection of AD. Our primary focus is on\nexploring semi-supervised Deep Learning techniques for the classification of\nEEG signals due to the clinical scenario characterized by the limited data\navailability. The methodology entails testing and comparing the performance of\nsemi-supervised SMATE and TapNet models, benchmarked against the supervised XCM\nmodel, and unsupervised Hidden Markov Models (HMMs). The study highlights the\nsignificance of spatial and temporal analysis capabilities, conducting\nindependent analyses of each sleep stage. Results demonstrate the effectiveness\nof SMATE in leveraging limited labeled data, achieving stable metrics across\nall sleep stages, and reaching 90% accuracy in its supervised form. Comparative\nanalyses reveal SMATE's superior performance over TapNet and HMM, while XCM\nexcels in supervised scenarios with an accuracy range of 92 - 94%. These\nfindings underscore the potential of semi-supervised models in early AD\ndetection, particularly in overcoming the challenges associated with the\nscarcity of labeled data. Ablation tests affirm the critical role of\nspatio-temporal feature extraction in semi-supervised predictive performance,\nand t-SNE visualizations validate the model's proficiency in distinguishing AD\npatterns. Overall, this research contributes to the advancement of AD detection\nthrough innovative Deep Learning approaches, highlighting the crucial role of\nsemi-supervised learning in addressing data limitations.",
      "tldr_zh": "这篇论文探讨了使用多导睡眠图 (PSG) 信号中的脑电图 (EEG) 来早期检测 Alzheimer's disease (AD)，强调睡眠模式紊乱与 AD 相关的潜在关联，并采用半监督深度学习技术应对标注数据有限的挑战。研究比较了半监督模型 SMATE 和 TapNet 的性能，与监督模型 XCM 和无监督模型 Hidden Markov Models (HMMs) 进行基准测试，结果显示 SMATE 在各睡眠阶段表现出稳定表现，监督形式下准确率达 90%，并优于 TapNet 和 HMM，而 XCM 在监督场景中达到 92-94% 的准确率。总体上，该研究通过时空特征提取和 t-SNE 可视化验证了模型的有效性，突出了半监督学习在 AD 检测中的潜力，有助于解决数据稀缺问题并推进创新性深度学习应用。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "68T07 (Primary), 68T05, 92B20 (Secondary)",
        "I.2.1"
      ],
      "primary_category": "eess.SP",
      "comment": "12 pages, 14 figures. Submitted to IEEE Biomedical and Health\n  Informatics for publication",
      "pdf_url": "http://arxiv.org/pdf/2404.03549v1",
      "published_date": "2024-04-04 15:56:23 UTC",
      "updated_date": "2024-04-04 15:56:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:47:22.744473"
    },
    {
      "arxiv_id": "2404.03543v3",
      "title": "CodeEditorBench: Evaluating Code Editing Capability of Large Language Models",
      "title_zh": "CodeEditorBench：评估大型语言模型的代码编辑能力",
      "authors": [
        "Jiawei Guo",
        "Ziming Li",
        "Xueling Liu",
        "Kaijing Ma",
        "Tianyu Zheng",
        "Zhouliang Yu",
        "Ding Pan",
        "Yizhi LI",
        "Ruibo Liu",
        "Yue Wang",
        "Shuyue Guo",
        "Xingwei Qu",
        "Xiang Yue",
        "Ge Zhang",
        "Wenhu Chen",
        "Jie Fu"
      ],
      "abstract": "Large Language Models (LLMs) for code are rapidly evolving, with code editing\nemerging as a critical capability. We introduce CodeEditorBench, an evaluation\nframework designed to rigorously assess the performance of LLMs in code editing\ntasks, including debugging, translating, polishing, and requirement switching.\nUnlike existing benchmarks focusing solely on code generation, CodeEditorBench\nemphasizes real-world scenarios and practical aspects of software development.\nWe curate diverse coding challenges and scenarios from five sources, covering\nvarious programming languages, complexity levels, and editing tasks. Evaluation\nof 19 LLMs reveals that closed-source models (particularly Gemini-Ultra and\nGPT-4), outperform open-source models in CodeEditorBench, highlighting\ndifferences in model performance based on problem types and prompt\nsensitivities. CodeEditorBench aims to catalyze advancements in LLMs by\nproviding a robust platform for assessing code editing capabilities. We will\nrelease all prompts and datasets to enable the community to expand the dataset\nand benchmark emerging LLMs. By introducing CodeEditorBench, we contribute to\nthe advancement of LLMs in code editing and provide a valuable resource for\nresearchers and practitioners.",
      "tldr_zh": "本研究引入了CodeEditorBench，这是一个评估框架，用于严格测试大型语言模型(LLMs)在代码编辑任务（如调试、翻译、优化和需求切换）上的能力。不同于以往仅关注代码生成的基准，CodeEditorBench 强调真实世界软件开发场景，从五个来源收集了多样化的编码挑战，涵盖多种编程语言、复杂度和任务类型。评估19个LLMs的结果显示，闭源模型（如Gemini-Ultra和GPT-4）在性能上优于开源模型，突出了模型在不同问题类型和提示敏感性方面的差异。该框架旨在推动LLMs在代码编辑领域的进步，并将发布所有提示和数据集供社区扩展。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03543v3",
      "published_date": "2024-04-04 15:49:49 UTC",
      "updated_date": "2025-04-08 09:39:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:47:33.449798"
    },
    {
      "arxiv_id": "2404.03514v2",
      "title": "Embedding-Informed Adaptive Retrieval-Augmented Generation of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chengkai Huang",
        "Yu Xia",
        "Rui Wang",
        "Kaige Xie",
        "Tong Yu",
        "Julian McAuley",
        "Lina Yao"
      ],
      "abstract": "Retrieval-augmented large language models (LLMs) have been remarkably\ncompetent in various NLP tasks. However, it was observed by previous works that\nretrieval is not always helpful, especially when the LLM is already\nknowledgeable on the query to answer. Motivated by this, Adaptive\nRetrieval-Augmented Generation (ARAG) studies retrieving only when the\nknowledge asked by the query is absent in the LLM. Previous works of ARAG\neither require accessing the pre-training corpus or prompting with additional\nmodel inferences. Aiming to avoid such drawbacks, we propose to determine\nwhether the model is knowledgeable on a query via inspecting the\n(contextualized) pre-trained token embeddings of LLMs. We hypothesize that such\nembeddings capture rich information on the model's intrinsic knowledge base,\nwhich enables an efficient way of judging the necessity to retrieve from an\nexternal corpus. Extensive experiments demonstrate our ARAG approach's superior\nperformance across various benchmarks.",
      "tldr_zh": "本文提出了一种基于嵌入信息的 Adaptive Retrieval-Augmented Generation (ARAG) 方法，针对大型语言模型 (LLMs) 的检索增强机制，旨在仅在模型缺少查询知识时进行检索，以避免不必要的操作。方法通过检查 LLM 的预训练 token 嵌入来判断模型的内在知识是否存在，从而规避了访问预训练语料或额外模型推理的缺点。实验结果显示，该方法在各种 NLP 基准上表现出优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03514v2",
      "published_date": "2024-04-04 15:21:22 UTC",
      "updated_date": "2024-12-13 02:45:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:47:44.665990"
    },
    {
      "arxiv_id": "2404.03502v2",
      "title": "AI and the Problem of Knowledge Collapse",
      "title_zh": "AI 与知识崩溃的问题",
      "authors": [
        "Andrew J. Peterson"
      ],
      "abstract": "While artificial intelligence has the potential to process vast amounts of\ndata, generate new insights, and unlock greater productivity, its widespread\nadoption may entail unforeseen consequences. We identify conditions under which\nAI, by reducing the cost of access to certain modes of knowledge, can\nparadoxically harm public understanding. While large language models are\ntrained on vast amounts of diverse data, they naturally generate output towards\nthe 'center' of the distribution. This is generally useful, but widespread\nreliance on recursive AI systems could lead to a process we define as\n\"knowledge collapse\", and argue this could harm innovation and the richness of\nhuman understanding and culture. However, unlike AI models that cannot choose\nwhat data they are trained on, humans may strategically seek out diverse forms\nof knowledge if they perceive them to be worthwhile. To investigate this, we\nprovide a simple model in which a community of learners or innovators choose to\nuse traditional methods or to rely on a discounted AI-assisted process and\nidentify conditions under which knowledge collapse occurs. In our default\nmodel, a 20% discount on AI-generated content generates public beliefs 2.3\ntimes further from the truth than when there is no discount. An empirical\napproach to measuring the distribution of LLM outputs is provided in\ntheoretical terms and illustrated through a specific example comparing the\ndiversity of outputs across different models and prompting styles. Finally,\nbased on the results, we consider further research directions to counteract\nsuch outcomes.",
      "tldr_zh": "本研究探讨了人工智能（AI）在降低知识获取成本的同时，可能导致“knowledge collapse”的悖论问题，即AI生成的输出趋向于分布中心，递归使用可能损害公共理解、创新和文化多样性。作者构建了一个简单模型，模拟学习者选择传统方法或AI辅助过程，发现在默认设置下，AI内容20%的成本折扣会使公共信念偏离真相2.3倍。论文还通过实证方法测量大型语言模型（LLMs）的输出多样性，并建议进一步研究方向来缓解此类风险。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "37 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.03502v2",
      "published_date": "2024-04-04 15:06:23 UTC",
      "updated_date": "2024-04-22 14:18:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:47:56.846202"
    },
    {
      "arxiv_id": "2404.03499v1",
      "title": "Comprehensible Artificial Intelligence on Knowledge Graphs: A survey",
      "title_zh": "基于知识图谱的可理解人工智能：综述",
      "authors": [
        "Simon Schramm",
        "Christoph Wehner",
        "Ute Schmid"
      ],
      "abstract": "Artificial Intelligence applications gradually move outside the safe walls of\nresearch labs and invade our daily lives. This is also true for Machine\nLearning methods on Knowledge Graphs, which has led to a steady increase in\ntheir application since the beginning of the 21st century. However, in many\napplications, users require an explanation of the Artificial Intelligences\ndecision. This led to increased demand for Comprehensible Artificial\nIntelligence. Knowledge Graphs epitomize fertile soil for Comprehensible\nArtificial Intelligence, due to their ability to display connected data, i.e.\nknowledge, in a human- as well as machine-readable way. This survey gives a\nshort history to Comprehensible Artificial Intelligence on Knowledge Graphs.\nFurthermore, we contribute by arguing that the concept Explainable Artificial\nIntelligence is overloaded and overlapping with Interpretable Machine Learning.\nBy introducing the parent concept Comprehensible Artificial Intelligence, we\nprovide a clear-cut distinction of both concepts while accounting for their\nsimilarities. Thus, we provide in this survey a case for Comprehensible\nArtificial Intelligence on Knowledge Graphs consisting of Interpretable Machine\nLearning on Knowledge Graphs and Explainable Artificial Intelligence on\nKnowledge Graphs. This leads to the introduction of a novel taxonomy for\nComprehensible Artificial Intelligence on Knowledge Graphs. In addition, a\ncomprehensive overview of the research on Comprehensible Artificial\nIntelligence on Knowledge Graphs is presented and put into the context of the\ntaxonomy. Finally, research gaps in the field of Comprehensible Artificial\nIntelligence on Knowledge Graphs are identified for future research.",
      "tldr_zh": "这篇调查论文回顾了在知识图谱(Knowledge Graphs)上实现 Comprehensible Artificial Intelligence 的研究历史，并强调了知识图谱作为人类和机器可读平台的优势。论文提出 Comprehensible Artificial Intelligence 作为父概念，以区分并整合 Explainable Artificial Intelligence 和 Interpretable Machine Learning 的重叠领域，同时引入了一个新的分类法来组织相关研究。最终，该论文提供了现有研究的全面概述，并识别了未来研究中的关键空白，如进一步提升 AI 可理解性的方法和应用场景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03499v1",
      "published_date": "2024-04-04 14:57:32 UTC",
      "updated_date": "2024-04-04 14:57:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:48:08.999598"
    },
    {
      "arxiv_id": "2404.03493v3",
      "title": "A Methodology to Study the Impact of Spiking Neural Network Parameters considering Event-Based Automotive Data",
      "title_zh": "翻译失败",
      "authors": [
        "Iqra Bano",
        "Rachmad Vidya Wicaksana Putra",
        "Alberto Marchisio",
        "Muhammad Shafique"
      ],
      "abstract": "Autonomous Driving (AD) systems are considered as the future of human\nmobility and transportation. Solving computer vision tasks such as image\nclassification and object detection/segmentation, with high accuracy and low\npower/energy consumption, is highly needed to realize AD systems in real life.\nThese requirements can potentially be satisfied by Spiking Neural Networks\n(SNNs). However, the state-of-the-art works in SNN-based AD systems still focus\non proposing network models that can achieve high accuracy, and they have not\nsystematically studied the roles of SNN parameters when used for learning\nevent-based automotive data. Therefore, we still lack understanding of how to\neffectively develop SNN models for AD systems. Toward this, we propose a novel\nmethodology to systematically study and analyze the impact of SNN parameters\nconsidering event-based automotive data, then leverage this analysis for\nenhancing SNN developments. To do this, we first explore different settings of\nSNN parameters that directly affect the learning mechanism (i.e., batch size,\nlearning rate, neuron threshold potential, and weight decay), then analyze the\naccuracy results. Afterward, we propose techniques that jointly improve SNN\naccuracy and reduce training time. Experimental results show that our\nmethodology can improve the SNN models for AD systems than the\nstate-of-the-art, as it achieves higher accuracy (i.e., 86%) for the NCARS\ndataset, and it can also achieve iso-accuracy (i.e., ~85% with standard\ndeviation less than 0.5%) while speeding up the training time by 1.9x. In this\nmanner, our research work provides a set of guidelines for SNN parameter\nenhancements, thereby enabling the practical developments of SNN-based AD\nsystems.",
      "tldr_zh": "本文提出了一种新方法，用于系统研究 Spiking Neural Networks (SNNs) 参数对基于事件汽车数据的影响，旨在提升自动驾驶 (AD) 系统中的计算机视觉任务性能，如图像分类和物体检测。方法包括探索 batch size、learning rate、neuron threshold potential 和 weight decay 等参数的设置，并通过分析准确性结果提出联合优化技术，以提高 SNN 准确率并减少训练时间。实验结果显示，该方法在 NCARS 数据集上实现了 86% 的准确率，比现有方法提升显著，并能以 1.9 倍的速度达到等效准确率（约 85%，标准差小于 0.5%），从而为 SNN-based AD 系统的实际开发提供指导原则。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.NE",
      "comment": "To appear at the 18th International Conference on Control,\n  Automation, Robotics and Vision (ICARCV), December 2024, Dubai, UAE",
      "pdf_url": "http://arxiv.org/pdf/2404.03493v3",
      "published_date": "2024-04-04 14:48:26 UTC",
      "updated_date": "2024-09-13 10:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:48:23.833191"
    },
    {
      "arxiv_id": "2404.03491v1",
      "title": "A Cause-Effect Look at Alleviating Hallucination of Knowledge-grounded Dialogue Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jifan Yu",
        "Xiaohan Zhang",
        "Yifan Xu",
        "Xuanyu Lei",
        "Zijun Yao",
        "Jing Zhang",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Empowered by the large-scale pretrained language models, existing dialogue\nsystems have demonstrated impressive performance conducting fluent and\nnatural-sounding conversations. However, they are still plagued by the\nhallucination problem, causing unpredictable factual errors in the generated\nresponses. Recently, knowledge-grounded dialogue generation models, that\nintentionally invoke external knowledge resources to more informative\nresponses, are also proven to be effective in reducing hallucination. Following\nthe idea of getting high-quality knowledge, a few efforts have achieved pretty\ngood performance on this issue. As some inevitable knowledge noises may also\nlead to hallucinations, it is emergent to investigate the reason and future\ndirections for building noise-tolerant methods in KGD tasks. In this paper, we\nanalyze the causal story behind this problem with counterfactual reasoning\nmethods. Based on the causal effect analysis, we propose a possible solution\nfor alleviating the hallucination in KGD by exploiting the dialogue-knowledge\ninteraction. Experimental results of our example implementation show that this\nmethod can reduce hallucination without disrupting other dialogue performance,\nwhile keeping adaptive to different generation models. We hope our efforts can\nsupport and call for more attention to developing lightweight techniques\ntowards robust and trusty dialogue systems.",
      "tldr_zh": "本论文探讨了知识 grounding 对话生成中的 hallucination（幻觉）问题，即生成模型可能因知识噪声而产生事实错误。通过 counterfactual reasoning（反事实推理）方法分析因果关系，作者提出一种利用对话-知识交互的解决方案，以缓解 hallucination。实验结果表明，该方法能在不影响其他对话性能的情况下有效减少错误，并适用于不同生成模型。该研究呼吁开发更多轻量级技术，以构建鲁棒且可信的对话系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.03491v1",
      "published_date": "2024-04-04 14:45:26 UTC",
      "updated_date": "2024-04-04 14:45:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:48:33.841782"
    },
    {
      "arxiv_id": "2404.03474v1",
      "title": "Performance of computer vision algorithms for fine-grained classification using crowdsourced insect images",
      "title_zh": "翻译失败",
      "authors": [
        "Rita Pucci",
        "Vincent J. Kalkman",
        "Dan Stowell"
      ],
      "abstract": "With fine-grained classification, we identify unique characteristics to\ndistinguish among classes of the same super-class. We are focusing on species\nrecognition in Insecta, as they are critical for biodiversity monitoring and at\nthe base of many ecosystems. With citizen science campaigns, billions of images\nare collected in the wild. Once these are labelled, experts can use them to\ncreate distribution maps. However, the labelling process is time-consuming,\nwhich is where computer vision comes in. The field of computer vision offers a\nwide range of algorithms, each with its strengths and weaknesses; how do we\nidentify the algorithm that is in line with our application? To answer this\nquestion, we provide a full and detailed evaluation of nine algorithms among\ndeep convolutional networks (CNN), vision transformers (ViT), and\nlocality-based vision transformers (LBVT) on 4 different aspects:\nclassification performance, embedding quality, computational cost, and gradient\nactivity. We offer insights that we haven't yet had in this domain proving to\nwhich extent these algorithms solve the fine-grained tasks in Insecta. We found\nthat the ViT performs the best on inference speed and computational cost while\nthe LBVT outperforms the others on performance and embedding quality; the CNN\nprovide a trade-off among the metrics.",
      "tldr_zh": "这篇论文评估了多种计算机视觉算法在利用众包昆虫图像进行细粒度分类（fine-grained classification）方面的性能，旨在加速昆虫物种识别以支持生物多样性监测。研究比较了九种算法，包括深度卷积网络（CNN）、视觉变压器（ViT）和基于局部性的视觉变压器（LBVT），从分类性能、嵌入质量（embedding quality）、计算成本和梯度活动四个方面进行全面评估。结果表明，ViT 在推理速度和计算成本上表现最佳，LBVT 在性能和嵌入质量上优于其他算法，而CNN 则在这些指标间提供良好的权衡。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03474v1",
      "published_date": "2024-04-04 14:26:58 UTC",
      "updated_date": "2024-04-04 14:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:48:46.295918"
    },
    {
      "arxiv_id": "2404.03710v2",
      "title": "Self-organized free-flight arrival for urban air mobility",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Waltz",
        "Ostap Okhrin",
        "Michael Schultz"
      ],
      "abstract": "Urban air mobility is an innovative mode of transportation in which electric\nvertical takeoff and landing (eVTOL) vehicles operate between nodes called\nvertiports. We outline a self-organized vertiport arrival system based on deep\nreinforcement learning. The airspace around the vertiport is assumed to be\ncircular, and the vehicles can freely operate inside. Each aircraft is\nconsidered an individual agent and follows a shared policy, resulting in\ndecentralized actions that are based on local information. We investigate the\ndevelopment of the reinforcement learning policy during training and illustrate\nhow the algorithm moves from suboptimal local holding patterns to a safe and\nefficient final policy. The latter is validated in simulation-based scenarios,\nincluding robustness analyses against sensor noise and a changing distribution\nof inbound traffic. Lastly, we deploy the final policy on small-scale unmanned\naerial vehicles to showcase its real-world usability.",
      "tldr_zh": "本文提出了一种基于深度强化学习（deep reinforcement learning）的自组织垂直起降机场（vertiports）到达系统，用于城市空中交通（Urban Air Mobility），以优化 eVTOL 车辆的自由飞行。该系统将每个飞机视为独立代理，采用共享策略进行基于本地信息的去中心化行动，通过训练过程从次优局部保持模式演变为安全高效的最终策略。实验在模拟场景中验证了该策略对传感器噪声和入境交通分布变化的鲁棒性，并通过在小型无人机上部署展示了其实际可用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03710v2",
      "published_date": "2024-04-04 13:43:17 UTC",
      "updated_date": "2024-08-08 09:03:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:48:58.677071"
    },
    {
      "arxiv_id": "2404.03441v2",
      "title": "Benchmarking ChatGPT on Algorithmic Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Sean McLeish",
        "Avi Schwarzschild",
        "Tom Goldstein"
      ],
      "abstract": "We evaluate ChatGPT's ability to solve algorithm problems from the CLRS\nbenchmark suite that is designed for GNNs. The benchmark requires the use of a\nspecified classical algorithm to solve a given problem. We find that ChatGPT\noutperforms specialist GNN models, using Python to successfully solve these\nproblems. This raises new points in the discussion about learning algorithms\nwith neural networks and how we think about what out of distribution testing\nlooks like with web scale training data.",
      "tldr_zh": "本论文评估了 ChatGPT 在算法推理方面的性能，使用 CLRS 基准测试来解决原本为图神经网络(GNNs)设计的算法问题。结果显示，ChatGPT 通过 Python 成功解决了这些问题，并超过了专业的 GNN 模型。研究引发了关于神经网络学习算法的新讨论，特别是如何定义网络规模训练数据的分布外(out of distribution)测试。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03441v2",
      "published_date": "2024-04-04 13:39:06 UTC",
      "updated_date": "2024-04-16 21:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:49:08.944033"
    },
    {
      "arxiv_id": "2404.03425v7",
      "title": "ChangeMamba: Remote Sensing Change Detection With Spatiotemporal State Space Model",
      "title_zh": "翻译失败",
      "authors": [
        "Hongruixuan Chen",
        "Jian Song",
        "Chengxi Han",
        "Junshi Xia",
        "Naoto Yokoya"
      ],
      "abstract": "Convolutional neural networks (CNN) and Transformers have made impressive\nprogress in the field of remote sensing change detection (CD). However, both\narchitectures have inherent shortcomings: CNN are constrained by a limited\nreceptive field that may hinder their ability to capture broader spatial\ncontexts, while Transformers are computationally intensive, making them costly\nto train and deploy on large datasets. Recently, the Mamba architecture, based\non state space models, has shown remarkable performance in a series of natural\nlanguage processing tasks, which can effectively compensate for the\nshortcomings of the above two architectures. In this paper, we explore for the\nfirst time the potential of the Mamba architecture for remote sensing CD tasks.\nWe tailor the corresponding frameworks, called MambaBCD, MambaSCD, and\nMambaBDA, for binary change detection (BCD), semantic change detection (SCD),\nand building damage assessment (BDA), respectively. All three frameworks adopt\nthe cutting-edge Visual Mamba architecture as the encoder, which allows full\nlearning of global spatial contextual information from the input images. For\nthe change decoder, which is available in all three architectures, we propose\nthree spatio-temporal relationship modeling mechanisms, which can be naturally\ncombined with the Mamba architecture and fully utilize its attribute to achieve\nspatio-temporal interaction of multi-temporal features, thereby obtaining\naccurate change information. On five benchmark datasets, our proposed\nframeworks outperform current CNN- and Transformer-based approaches without\nusing any complex training strategies or tricks, fully demonstrating the\npotential of the Mamba architecture in CD tasks. Further experiments show that\nour architecture is quite robust to degraded data. The source code will be\navailable in https://github.com/ChenHongruixuan/MambaCD",
      "tldr_zh": "本论文提出 ChangeMamba 框架，利用基于状态空间模型的 Mamba 架构，首次应用于遥感变化检测（Remote Sensing Change Detection），以克服 CNN 的有限感受野和 Transformers 的高计算成本问题。框架包括 MambaBCD（二元变化检测）、MambaSCD（语义变化检测）和 MambaBDA（建筑物损坏评估），采用 Visual Mamba 作为编码器学习全局空间上下文，并在变化解码器中引入三种时空关系建模机制，实现多时态特征的交互。实验结果显示，该框架在五个基准数据集上优于现有 CNN- 和 Transformer- 基于方法，且对退化数据具有鲁棒性，无需复杂训练策略。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by IEEE TGRS: https://ieeexplore.ieee.org/document/10565926",
      "pdf_url": "http://arxiv.org/pdf/2404.03425v7",
      "published_date": "2024-04-04 13:06:25 UTC",
      "updated_date": "2024-12-30 06:28:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:49:21.848916"
    },
    {
      "arxiv_id": "2404.03419v2",
      "title": "Integrating Hyperparameter Search into Model-Free AutoML with Context-Free Grammars",
      "title_zh": "翻译失败",
      "authors": [
        "Hernán Ceferino Vázquez",
        "Jorge Sanchez",
        "Rafael Carrascosa"
      ],
      "abstract": "Automated Machine Learning (AutoML) has become increasingly popular in recent\nyears due to its ability to reduce the amount of time and expertise required to\ndesign and develop machine learning systems. This is very important for the\npractice of machine learning, as it allows building strong baselines quickly,\nimproving the efficiency of the data scientists, and reducing the time to\nproduction. However, despite the advantages of AutoML, it faces several\nchallenges, such as defining the solutions space and exploring it efficiently.\nRecently, some approaches have been shown to be able to do it using tree-based\nsearch algorithms and context-free grammars. In particular, GramML presents a\nmodel-free reinforcement learning approach that leverages pipeline\nconfiguration grammars and operates using Monte Carlo tree search. However, one\nof the limitations of GramML is that it uses default hyperparameters, limiting\nthe search problem to finding optimal pipeline structures for the available\ndata preprocessors and models. In this work, we propose an extension to GramML\nthat supports larger search spaces including hyperparameter search. We\nevaluated the approach using an OpenML benchmark and found significant\nimprovements compared to other state-of-the-art techniques.",
      "tldr_zh": "这篇论文探讨了 Automated Machine Learning (AutoML) 的挑战，特别是如何高效定义和探索解决方案空间。作者提出了一种扩展 GramML 的方法，将 hyperparameter search 整合到 model-free AutoML 中，使用 context-free grammars 来生成更全面的管道配置和参数优化。实验结果显示，该方法在 OpenML benchmark 上与现有 state-of-the-art 技术相比取得了显著改进，提高了机器学习系统的设计效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03419v2",
      "published_date": "2024-04-04 12:54:13 UTC",
      "updated_date": "2024-04-13 14:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:49:32.889857"
    },
    {
      "arxiv_id": "2404.03418v3",
      "title": "Permissible Knowledge Pooling",
      "title_zh": "翻译失败",
      "authors": [
        "Huimin Dong"
      ],
      "abstract": "Information pooling has been extensively formalised across various logical\nframeworks in distributed systems, characterized by diverse information-sharing\npatterns. These approaches generally adopt an intersection perspective,\naggregating all possible information, regardless of whether it is known or\nunknown to the agents. In contrast, this work adopts a unique stance,\nemphasising that sharing knowledge means distributing what is known, rather\nthan what remains uncertain. This paper introduces new modal logics for\nknowledge pooling and sharing, ranging from a novel language of knowledge\npooling to a dynamic mechanism for knowledge sharing. It also outlines their\naxiomatizations and discusses a potential framework for permissible knowledge\npooling.",
      "tldr_zh": "本文批评了传统信息 pooling 方法在分布式系统中采用 intersection 视角，将已知和未知信息一并聚合；相反，本文强调知识共享应仅限于已知信息，提出新的 modal logics 语言和动态机制来处理 knowledge pooling 和 knowledge sharing。论文提供了这些逻辑的 axiomatizations，并探讨了一个 permissible knowledge pooling 的框架，以更精确地管理分布式知识。实验和理论分析为这种新颖方法奠定了基础，有望改善信息共享的效率和准确性。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03418v3",
      "published_date": "2024-04-04 12:51:28 UTC",
      "updated_date": "2024-05-15 21:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:49:45.974295"
    },
    {
      "arxiv_id": "2404.03414v1",
      "title": "Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought",
      "title_zh": "翻译失败",
      "authors": [
        "Jooyoung Lee",
        "Fan Yang",
        "Thanh Tran",
        "Qian Hu",
        "Emre Barut",
        "Kai-Wei Chang",
        "Chengwei Su"
      ],
      "abstract": "We introduce a novel framework, LM-Guided CoT, that leverages a lightweight\n(i.e., <1B) language model (LM) for guiding a black-box large (i.e., >10B) LM\nin reasoning tasks. Specifically, the lightweight LM first generates a\nrationale for each input instance. The Frozen large LM is then prompted to\npredict a task output based on the rationale generated by the lightweight LM.\nOur approach is resource-efficient in the sense that it only requires training\nthe lightweight LM. We optimize the model through 1) knowledge distillation and\n2) reinforcement learning from rationale-oriented and task-oriented reward\nsignals. We assess our method with multi-hop extractive question answering (QA)\nbenchmarks, HotpotQA, and 2WikiMultiHopQA. Experimental results show that our\napproach outperforms all baselines regarding answer prediction accuracy. We\nalso find that reinforcement learning helps the model to produce higher-quality\nrationales with improved QA performance.",
      "tldr_zh": "该论文提出了一种新框架LM-Guided Chain-of-Thought，利用小型语言模型（<1B参数）来指导大型语言模型（>10B参数）提升推理任务性能。具体方法包括小型LM先生成rationale，然后大型LM基于此预测任务输出，并通过knowledge distillation和reinforcement learning（使用rationale-oriented和task-oriented奖励信号）优化小型LM。实验在HotpotQA和2WikiMultiHopQA等多跳提取式QA基准上显示，该框架在答案预测准确率上超越所有基线模型，且reinforcement learning显著提高了rationale质量和整体QA性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper is accepted to LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.03414v1",
      "published_date": "2024-04-04 12:46:37 UTC",
      "updated_date": "2024-04-04 12:46:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:49:58.493176"
    },
    {
      "arxiv_id": "2404.03709v1",
      "title": "Proceedings 12th International Workshop on Theorem proving components for Educational software",
      "title_zh": "翻译失败",
      "authors": [
        "Julien Narboux",
        "Walther Neuper",
        "Pedro Quaresma"
      ],
      "abstract": "The ThEdu series pursues the smooth transition from an intuitive way of doing\nmathematics at secondary school to a more formal approach to the subject in\nSTEM education, while favouring software support for this transition by\nexploiting the power of theorem-proving technologies. What follows is a brief\ndescription of how the present volume contributes to this enterprise.\n  The 12th International Workshop on Theorem Proving Components for Educational\nSoftware(ThEdu'23), was a satellite event of the 29th international Conference\non Automated Deduction (CADE 2023), July 1-4, 2023, Rome, Italy. ThEdu'23 was\nvery successful, with one invited talk, by Yves Bertot (Inria, France), \"The\nchallenges of using Type Theory to teach Mathematics\", and seven regular\ncontributions. An open call for papers was then issued, to which eight\ncontributions were submitted. Seven submissions have been accepted by our\nreviewers, who jointly produced at least three careful reports on each of the\ncontributions. The resulting revised papers are collected in the present\nvolume.\n  We, the volume editors, hope that this collection of papers will further\npromote the development of theorem-proving based software, and that it will\nallow to improve the mutual understanding between computer scientists,\nmathematicians and stakeholders in education.\n  PC Chairs:Julien Narboux (University of Strasbourg, France); Walther Neuper\n(JKU, Johannes Kepler University, Linz, Austria); Pedro Quaresma (University of\nCoimbra, Portugal)",
      "tldr_zh": "ThEdu 系列研讨会旨在通过定理证明技术（Theorem Proving Components）支持从中学直观数学向 STEM 教育中更正式方法的过渡，以提升软件辅助教育。第 12 届国际研讨会（ThEdu'23）作为 CADE 2023 的卫星事件，于 2023 年 7 月 1-4 日在罗马举行，包含 Yves Bertot 的邀请演讲“使用 Type Theory 教授数学的挑战”以及七个常规贡献和后续七篇接受论文。该论文集汇集这些成果，旨在促进基于定理证明的软件开发，并加强计算机科学家、数学家和教育相关者之间的相互理解。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03709v1",
      "published_date": "2024-04-04 11:51:26 UTC",
      "updated_date": "2024-04-04 11:51:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:50:09.892295"
    },
    {
      "arxiv_id": "2404.03386v1",
      "title": "SENSOR: Imitate Third-Person Expert's Behaviors via Active Sensoring",
      "title_zh": "翻译失败",
      "authors": [
        "Kaichen Huang",
        "Minghao Shao",
        "Shenghua Wan",
        "Hai-Hang Sun",
        "Shuai Feng",
        "Le Gan",
        "De-Chuan Zhan"
      ],
      "abstract": "In many real-world visual Imitation Learning (IL) scenarios, there is a\nmisalignment between the agent's and the expert's perspectives, which might\nlead to the failure of imitation. Previous methods have generally solved this\nproblem by domain alignment, which incurs extra computation and storage costs,\nand these methods fail to handle the \\textit{hard cases} where the viewpoint\ngap is too large. To alleviate the above problems, we introduce active\nsensoring in the visual IL setting and propose a model-based SENSory imitatOR\n(SENSOR) to automatically change the agent's perspective to match the expert's.\nSENSOR jointly learns a world model to capture the dynamics of latent states, a\nsensor policy to control the camera, and a motor policy to control the agent.\nExperiments on visual locomotion tasks show that SENSOR can efficiently\nsimulate the expert's perspective and strategy, and outperforms most baseline\nmethods.",
      "tldr_zh": "该研究针对视觉 Imitation Learning (IL) 中代理与专家视角不匹配的问题，提出 SENSOR 方法，通过主动传感器（active sensoring）自动调整代理视角以模仿第三方专家行为，从而避免了传统领域对齐（domain alignment）的高成本和处理大视角差距的局限。SENSOR 联合学习一个世界模型（world model）来捕捉潜在状态动态、一个传感器策略（sensor policy）来控制相机，以及一个运动策略（motor policy）来控制代理行为。实验结果显示，在视觉运动任务上，SENSOR 能高效模拟专家视角和策略，并优于大多数基线方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03386v1",
      "published_date": "2024-04-04 11:37:55 UTC",
      "updated_date": "2024-04-04 11:37:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:50:22.653012"
    },
    {
      "arxiv_id": "2405.01563v1",
      "title": "Mitigating LLM Hallucinations via Conformal Abstention",
      "title_zh": "翻译失败",
      "authors": [
        "Yasin Abbasi Yadkori",
        "Ilja Kuzborskij",
        "David Stutz",
        "András György",
        "Adam Fisch",
        "Arnaud Doucet",
        "Iuliya Beloshapka",
        "Wei-Hung Weng",
        "Yao-Yuan Yang",
        "Csaba Szepesvári",
        "Ali Taylan Cemgil",
        "Nenad Tomasev"
      ],
      "abstract": "We develop a principled procedure for determining when a large language model\n(LLM) should abstain from responding (e.g., by saying \"I don't know\") in a\ngeneral domain, instead of resorting to possibly \"hallucinating\" a non-sensical\nor incorrect answer. Building on earlier approaches that use self-consistency\nas a more reliable measure of model confidence, we propose using the LLM itself\nto self-evaluate the similarity between each of its sampled responses for a\ngiven query. We then further leverage conformal prediction techniques to\ndevelop an abstention procedure that benefits from rigorous theoretical\nguarantees on the hallucination rate (error rate). Experimentally, our\nresulting conformal abstention method reliably bounds the hallucination rate on\nvarious closed-book, open-domain generative question answering datasets, while\nalso maintaining a significantly less conservative abstention rate on a dataset\nwith long responses (Temporal Sequences) compared to baselines using\nlog-probability scores to quantify uncertainty, while achieveing comparable\nperformance on a dataset with short answers (TriviaQA). To evaluate the\nexperiments automatically, one needs to determine if two responses are\nequivalent given a question. Following standard practice, we use a thresholded\nsimilarity function to determine if two responses match, but also provide a\nmethod for calibrating the threshold based on conformal prediction, with\ntheoretical guarantees on the accuracy of the match prediction, which might be\nof independent interest.",
      "tldr_zh": "本文提出了一种基于 Conformal Abstention 的方法，用于缓解大型语言模型 (LLM) 的 Hallucinations，通过让模型在不确定时选择 abstain（例如，说“我不知道”）。该方法利用 LLM 的 Self-Consistency 来评估多个响应之间的相似性，并结合 Conformal Prediction 技术，提供对 Hallucination Rate（错误率）的严格理论保证。实验结果显示，在各种闭卷开放域问答数据集上，该方法有效控制了错误率，同时在长响应数据集（如 Temporal Sequences）上保持较低的 Abstention Rate，比使用 Log-Probability Scores 的基线方法更具优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01563v1",
      "published_date": "2024-04-04 11:32:03 UTC",
      "updated_date": "2024-04-04 11:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:50:34.836111"
    },
    {
      "arxiv_id": "2404.03382v1",
      "title": "DIDA: Denoised Imitation Learning based on Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Kaichen Huang",
        "Hai-Hang Sun",
        "Shenghua Wan",
        "Minghao Shao",
        "Shuai Feng",
        "Le Gan",
        "De-Chuan Zhan"
      ],
      "abstract": "Imitating skills from low-quality datasets, such as sub-optimal\ndemonstrations and observations with distractors, is common in real-world\napplications. In this work, we focus on the problem of Learning from Noisy\nDemonstrations (LND), where the imitator is required to learn from data with\nnoise that often occurs during the processes of data collection or\ntransmission. Previous IL methods improve the robustness of learned policies by\ninjecting an adversarially learned Gaussian noise into pure expert data or\nutilizing additional ranking information, but they may fail in the LND setting.\nTo alleviate the above problems, we propose Denoised Imitation learning based\non Domain Adaptation (DIDA), which designs two discriminators to distinguish\nthe noise level and expertise level of data, facilitating a feature encoder to\nlearn task-related but domain-agnostic representations. Experiment results on\nMuJoCo demonstrate that DIDA can successfully handle challenging imitation\ntasks from demonstrations with various types of noise, outperforming most\nbaseline methods.",
      "tldr_zh": "这篇论文提出了 DIDA（Denoised Imitation Learning based on Domain Adaptation），一种针对 Learning from Noisy Demonstrations (LND) 的模仿学习方法，用于从包含噪声（如次优演示或干扰观察）的低质量数据中学习技能。DIDA 通过设计两个鉴别器来区分数据的噪声水平和专业水平，帮助特征编码器学习任务相关的、域无关的表示，从而提升政策的鲁棒性。在 MuJoCo 环境中的实验显示，DIDA 成功处理了各种噪声类型的演示任务，并优于大多数基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03382v1",
      "published_date": "2024-04-04 11:29:05 UTC",
      "updated_date": "2024-04-04 11:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:50:47.544863"
    },
    {
      "arxiv_id": "2404.03359v1",
      "title": "REACT: Revealing Evolutionary Action Consequence Trajectories for Interpretable Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Philipp Altmann",
        "Céline Davignon",
        "Maximilian Zorn",
        "Fabian Ritz",
        "Claudia Linnhoff-Popien",
        "Thomas Gabor"
      ],
      "abstract": "To enhance the interpretability of Reinforcement Learning (RL), we propose\nRevealing Evolutionary Action Consequence Trajectories (REACT). In contrast to\nthe prevalent practice of validating RL models based on their optimal behavior\nlearned during training, we posit that considering a range of edge-case\ntrajectories provides a more comprehensive understanding of their inherent\nbehavior. To induce such scenarios, we introduce a disturbance to the initial\nstate, optimizing it through an evolutionary algorithm to generate a diverse\npopulation of demonstrations. To evaluate the fitness of trajectories, REACT\nincorporates a joint fitness function that encourages both local and global\ndiversity in the encountered states and chosen actions. Through assessments\nwith policies trained for varying durations in discrete and continuous\nenvironments, we demonstrate the descriptive power of REACT. Our results\nhighlight its effectiveness in revealing nuanced aspects of RL models' behavior\nbeyond optimal performance, thereby contributing to improved interpretability.",
      "tldr_zh": "该论文提出 REACT 方法，通过揭示进化行动后果轨迹（Evolutionary Action Consequence Trajectories）来提升强化学习（RL）的可解释性。不同于传统方法仅关注最优行为，REACT 通过对初始状态施加干扰并使用进化算法优化，生成多样化的演示轨迹，并引入联合适应度函数以确保状态和动作的局部与全局多样性。实验在离散和连续环境中评估不同训练时长的 RL 策略，结果表明 REACT 能揭示模型行为中的细微方面，从而增强整体可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.03359v1",
      "published_date": "2024-04-04 10:56:30 UTC",
      "updated_date": "2024-04-04 10:56:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:50:58.497867"
    },
    {
      "arxiv_id": "2404.03707v1",
      "title": "Investigating the Robustness of Counterfactual Learning to Rank Models: A Reproducibility Study",
      "title_zh": "翻译失败",
      "authors": [
        "Zechun Niu",
        "Jiaxin Mao",
        "Qingyao Ai",
        "Ji-Rong Wen"
      ],
      "abstract": "Counterfactual learning to rank (CLTR) has attracted extensive attention in\nthe IR community for its ability to leverage massive logged user interaction\ndata to train ranking models. While the CLTR models can be theoretically\nunbiased when the user behavior assumption is correct and the propensity\nestimation is accurate, their effectiveness is usually empirically evaluated\nvia simulation-based experiments due to a lack of widely-available,\nlarge-scale, real click logs. However, the mainstream simulation-based\nexperiments are somewhat limited as they often feature a single, deterministic\nproduction ranker and simplified user simulation models to generate the\nsynthetic click logs. As a result, the robustness of CLTR models in complex and\ndiverse situations is largely unknown and needs further investigation.\n  To address this problem, in this paper, we aim to investigate the robustness\nof existing CLTR models in a reproducibility study with extensive\nsimulation-based experiments that (1) use both deterministic and stochastic\nproduction rankers, each with different ranking performance, and (2) leverage\nmultiple user simulation models with different user behavior assumptions. We\nfind that the DLA models and IPS-DCM show better robustness under various\nsimulation settings than IPS-PBM and PRS with offline propensity estimation.\nBesides, the existing CLTR models often fail to outperform the naive click\nbaselines when the production ranker has relatively high ranking performance or\ncertain randomness, which suggests an urgent need for developing new CLTR\nalgorithms that work for these settings.",
      "tldr_zh": "本研究调查了Counterfactual Learning to Rank (CLTR) 模型的稳健性，通过一个再现性研究进行广泛的模拟实验。实验设计包括使用确定性和随机生产排名器（各具不同排名性能），以及多种用户模拟模型，以反映不同的用户行为假设。结果显示，DLA 模型和 IPS-DCM 在各种模拟设置下比 IPS-PBM 和 PRS 更具稳健性；然而，现有的 CLTR 模型在生产排名器性能较高或存在随机性时，往往无法超越简单的点击基线，这突显了开发新 CLTR 算法的迫切需求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03707v1",
      "published_date": "2024-04-04 10:54:38 UTC",
      "updated_date": "2024-04-04 10:54:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:51:11.778926"
    },
    {
      "arxiv_id": "2404.03354v2",
      "title": "A Comprehensive Survey on Self-Supervised Learning for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Xubin Ren",
        "Wei Wei",
        "Lianghao Xia",
        "Chao Huang"
      ],
      "abstract": "Recommender systems play a crucial role in tackling the challenge of\ninformation overload by delivering personalized recommendations based on\nindividual user preferences. Deep learning techniques, such as RNNs, GNNs, and\nTransformer architectures, have significantly propelled the advancement of\nrecommender systems by enhancing their comprehension of user behaviors and\npreferences. However, supervised learning methods encounter challenges in\nreal-life scenarios due to data sparsity, resulting in limitations in their\nability to learn representations effectively. To address this, self-supervised\nlearning (SSL) techniques have emerged as a solution, leveraging inherent data\nstructures to generate supervision signals without relying solely on labeled\ndata. By leveraging unlabeled data and extracting meaningful representations,\nrecommender systems utilizing SSL can make accurate predictions and\nrecommendations even when confronted with data sparsity. In this paper, we\nprovide a comprehensive review of self-supervised learning frameworks designed\nfor recommender systems, encompassing a thorough analysis of over 170 papers.\nWe conduct an exploration of nine distinct scenarios, enabling a comprehensive\nunderstanding of SSL-enhanced recommenders in different contexts. For each\ndomain, we elaborate on different self-supervised learning paradigms, namely\ncontrastive learning, generative learning, and adversarial learning, so as to\npresent technical details of how SSL enhances recommender systems in various\ncontexts. We consistently maintain the related open-source materials at\nhttps://github.com/HKUDS/Awesome-SSLRec-Papers.",
      "tldr_zh": "这篇论文对自监督学习（Self-Supervised Learning, SSL）在推荐系统中的应用进行了全面综述，分析了超过170篇相关文献，以解决传统监督学习面临的数据稀疏性问题。论文探讨了九个不同场景下的SSL框架，包括对比学习（Contrastive Learning）、生成学习（Generative Learning）和对抗学习（Adversarial Learning），详细说明了这些范式如何利用无标签数据来提升推荐系统的用户行为理解和预测准确性。通过提供开源资源（如https://github.com/HKUDS/Awesome-SSLRec-Papers），论文为研究者提供了宝贵的工具和见解，推动了SSL在推荐领域的进一步发展。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03354v2",
      "published_date": "2024-04-04 10:45:23 UTC",
      "updated_date": "2024-04-07 05:57:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:51:22.656081"
    },
    {
      "arxiv_id": "2404.03348v2",
      "title": "Knowledge Distillation-Based Model Extraction Attack using GAN-based Private Counterfactual Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Fatima Ezzeddine",
        "Omran Ayoub",
        "Silvia Giordano"
      ],
      "abstract": "In recent years, there has been a notable increase in the deployment of\nmachine learning (ML) models as services (MLaaS) across diverse production\nsoftware applications. In parallel, explainable AI (XAI) continues to evolve,\naddressing the necessity for transparency and trustworthiness in ML models. XAI\ntechniques aim to enhance the transparency of ML models by providing insights,\nin terms of model's explanations, into their decision-making process.\nSimultaneously, some MLaaS platforms now offer explanations alongside the ML\nprediction outputs. This setup has elevated concerns regarding vulnerabilities\nin MLaaS, particularly in relation to privacy leakage attacks such as model\nextraction attacks (MEA). This is due to the fact that explanations can unveil\ninsights about the inner workings of the model which could be exploited by\nmalicious users. In this work, we focus on investigating how model\nexplanations, particularly counterfactual explanations (CFs), can be exploited\nfor performing MEA within the MLaaS platform. We also delve into assessing the\neffectiveness of incorporating differential privacy (DP) as a mitigation\nstrategy. To this end, we first propose a novel approach for MEA based on\nKnowledge Distillation (KD) to enhance the efficiency of extracting a\nsubstitute model of a target model exploiting CFs, without any knowledge about\nthe training data distribution by the attacker. Then, we advise an approach for\ntraining CF generators incorporating DP to generate private CFs. We conduct\nthorough experimental evaluations on real-world datasets and demonstrate that\nour proposed KD-based MEA can yield a high-fidelity substitute model with a\nreduced number of queries with respect to baseline approaches. Furthermore, our\nfindings reveal that including a privacy layer can allow mitigating the MEA.\nHowever, on the account of the quality of CFs, impacts the performance of the\nexplanations.",
      "tldr_zh": "本研究探讨了机器学习模型即服务（MLaaS）平台中，使用反事实解释（CFs）进行模型提取攻击（MEA）的隐私风险，特别是在可解释AI（XAI）提供模型解释的情况下。论文提出了一种基于知识蒸馏（KD）的MEA方法，利用GAN-based private CFs生成器，从目标模型提取高保真度的替代模型，而无需攻击者了解训练数据分布，从而提高了攻击效率。实验在真实数据集上表明，该方法比基线方法减少查询次数；此外，通过整合差分隐私（DP）来训练CF生成器，可以缓解MEA，但会降低解释质量和CFs的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.03348v2",
      "published_date": "2024-04-04 10:28:55 UTC",
      "updated_date": "2024-10-22 09:31:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:51:35.096252"
    },
    {
      "arxiv_id": "2404.15320v2",
      "title": "Using Large Language Models to Enrich the Documentation of Datasets for Machine Learning",
      "title_zh": "利用大型语言模型丰富机器学习数据集的文档",
      "authors": [
        "Joan Giner-Miguelez",
        "Abel Gómez",
        "Jordi Cabot"
      ],
      "abstract": "Recent regulatory initiatives like the European AI Act and relevant voices in\nthe Machine Learning (ML) community stress the need to describe datasets along\nseveral key dimensions for trustworthy AI, such as the provenance processes and\nsocial concerns. However, this information is typically presented as\nunstructured text in accompanying documentation, hampering their automated\nanalysis and processing. In this work, we explore using large language models\n(LLM) and a set of prompting strategies to automatically extract these\ndimensions from documents and enrich the dataset description with them. Our\napproach could aid data publishers and practitioners in creating\nmachine-readable documentation to improve the discoverability of their\ndatasets, assess their compliance with current AI regulations, and improve the\noverall quality of ML models trained on them.\n  In this paper, we evaluate the approach on 12 scientific dataset papers\npublished in two scientific journals (Nature's Scientific Data and Elsevier's\nData in Brief) using two different LLMs (GPT3.5 and Flan-UL2). Results show\ngood accuracy with our prompt extraction strategies. Concrete results vary\ndepending on the dimensions, but overall, GPT3.5 shows slightly better accuracy\n(81,21%) than FLAN-UL2 (69,13%) although it is more prone to hallucinations. We\nhave released an open-source tool implementing our approach and a replication\npackage, including the experiments' code and results, in an open-source\nrepository.",
      "tldr_zh": "这篇论文探讨了使用 Large Language Models (LLM) 结合提示策略，从数据集文档中自动提取关键维度（如来源过程和社会问题），以丰富数据集的结构化描述，从而提升其机器可读性。研究在 12 个科学数据集论文上进行评估，使用 GPT3.5 和 Flan-UL2 模型，结果显示 GPT3.5 的整体准确率达到 81.21%，略高于 Flan-UL2 的 69.13%，但 GPT3.5 更容易产生 hallucinations。主要贡献包括发布开源工具，帮助数据发布者和从业者改善数据集发现性、AI 法规合规性和基于这些数据集的 ML 模型质量。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL",
        "H.4.4"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15320v2",
      "published_date": "2024-04-04 10:09:28 UTC",
      "updated_date": "2024-05-24 11:25:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:51:47.755665"
    },
    {
      "arxiv_id": "2404.03325v2",
      "title": "Embodied Neuromorphic Artificial Intelligence for Robotics: Perspectives, Challenges, and Research Development Stack",
      "title_zh": "翻译失败",
      "authors": [
        "Rachmad Vidya Wicaksana Putra",
        "Alberto Marchisio",
        "Fakhreddine Zayer",
        "Jorge Dias",
        "Muhammad Shafique"
      ],
      "abstract": "Robotic technologies have been an indispensable part for improving human\nproductivity since they have been helping humans in completing diverse,\ncomplex, and intensive tasks in a fast yet accurate and efficient way.\nTherefore, robotic technologies have been deployed in a wide range of\napplications, ranging from personal to industrial use-cases. However, current\nrobotic technologies and their computing paradigm still lack embodied\nintelligence to efficiently interact with operational environments, respond\nwith correct/expected actions, and adapt to changes in the environments. Toward\nthis, recent advances in neuromorphic computing with Spiking Neural Networks\n(SNN) have demonstrated the potential to enable the embodied intelligence for\nrobotics through bio-plausible computing paradigm that mimics how the\nbiological brain works, known as \"neuromorphic artificial intelligence (AI)\".\nHowever, the field of neuromorphic AI-based robotics is still at an early\nstage, therefore its development and deployment for solving real-world problems\nexpose new challenges in different design aspects, such as accuracy,\nadaptability, efficiency, reliability, and security. To address these\nchallenges, this paper will discuss how we can enable embodied neuromorphic AI\nfor robotic systems through our perspectives: (P1) Embodied intelligence based\non effective learning rule, training mechanism, and adaptability; (P2)\nCross-layer optimizations for energy-efficient neuromorphic computing; (P3)\nRepresentative and fair benchmarks; (P4) Low-cost reliability and safety\nenhancements; (P5) Security and privacy for neuromorphic computing; and (P6) A\nsynergistic development for energy-efficient and robust neuromorphic-based\nrobotics. Furthermore, this paper identifies research challenges and\nopportunities, as well as elaborates our vision for future research development\ntoward embodied neuromorphic AI for robotics.",
      "tldr_zh": "这篇论文探讨了机器人领域中当前技术的局限性，即缺乏embodied intelligence，无法高效互动、响应环境变化和适应任务。作者提出利用神经形态计算和Spiking Neural Networks (SNN) 构建embodied neuromorphic AI，作为一种模仿生物大脑的计算范式来解决这些挑战。论文从六个视角（P1: 有效学习规则和适应性；P2: 能量高效优化；P3: 公平基准；P4: 低成本可靠性和安全性；P5: 安全隐私；P6: 协同开发）分析了实现embodied neuromorphic AI的关键策略，并识别了研究挑战和机会，为未来能量高效、鲁棒的神经形态机器人系统的发展提供愿景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.RO",
      "comment": "To appear at the 18th International Conference on Control,\n  Automation, Robotics and Vision (ICARCV), December 2024, Dubai, UAE",
      "pdf_url": "http://arxiv.org/pdf/2404.03325v2",
      "published_date": "2024-04-04 09:52:22 UTC",
      "updated_date": "2024-09-12 14:18:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:52:00.103749"
    },
    {
      "arxiv_id": "2404.03323v1",
      "title": "Sparse Concept Bottleneck Models: Gumbel Tricks in Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Semenov",
        "Vladimir Ivanov",
        "Aleksandr Beznosikov",
        "Alexander Gasnikov"
      ],
      "abstract": "We propose a novel architecture and method of explainable classification with\nConcept Bottleneck Models (CBMs). While SOTA approaches to Image Classification\ntask work as a black box, there is a growing demand for models that would\nprovide interpreted results. Such a models often learn to predict the\ndistribution over class labels using additional description of this target\ninstances, called concepts. However, existing Bottleneck methods have a number\nof limitations: their accuracy is lower than that of a standard model and CBMs\nrequire an additional set of concepts to leverage. We provide a framework for\ncreating Concept Bottleneck Model from pre-trained multi-modal encoder and new\nCLIP-like architectures. By introducing a new type of layers known as Concept\nBottleneck Layers, we outline three methods for training them: with\n$\\ell_1$-loss, contrastive loss and loss function based on Gumbel-Softmax\ndistribution (Sparse-CBM), while final FC layer is still trained with\nCross-Entropy. We show a significant increase in accuracy using sparse hidden\nlayers in CLIP-based bottleneck models. Which means that sparse representation\nof concepts activation vector is meaningful in Concept Bottleneck Models.\nMoreover, with our Concept Matrix Search algorithm we can improve CLIP\npredictions on complex datasets without any additional training or fine-tuning.\nThe code is available at: https://github.com/Andron00e/SparseCBM.",
      "tldr_zh": "本研究提出了一种新的可解释分类架构，名为 Sparse Concept Bottleneck Models (Sparse-CBMs)，旨在解决传统 Concept Bottleneck Models (CBMs) 的准确率低下和对额外概念集的依赖问题。作者基于预训练的多模态编码器和 CLIP-like 架构，引入 Concept Bottleneck Layers，并开发三种训练方法：使用 $\\ell_1$-loss、contrastive loss 和基于 Gumbel-Softmax 的损失函数。实验结果显示，采用稀疏隐藏层显著提高了 CLIP-based 瓶颈模型的准确率，同时通过 Concept Matrix Search 算法，无需额外训练即可提升复杂数据集上的预测性能。总的来说，该框架增强了 CBMs 的实用性和解释性，为可解释 AI 分类提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.6, I.2.10, I.4.10, I.5.1, I.5.4, I.5.5",
        "I.2.6; I.2.10; I.4.10; I.5.1; I.5.4; I.5.5"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 1 algorithm, 36 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.03323v1",
      "published_date": "2024-04-04 09:43:43 UTC",
      "updated_date": "2024-04-04 09:43:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:52:12.757069"
    },
    {
      "arxiv_id": "2404.03704v1",
      "title": "Improvement of Performance in Freezing of Gait detection in Parkinsons Disease using Transformer networks and a single waist worn triaxial accelerometer",
      "title_zh": "翻译失败",
      "authors": [
        "Luis Sigcha",
        "Luigi Borzì",
        "Ignacio Pavón",
        "Nélson Costa",
        "Susana Costa",
        "Pedro Arezes",
        "Juan-Manuel López",
        "Guillermo De Arcas"
      ],
      "abstract": "Freezing of gait (FOG) is one of the most incapacitating symptoms in\nParkinsons disease, affecting more than 50 percent of patients in advanced\nstages of the disease. The presence of FOG may lead to falls and a loss of\nindependence with a consequent reduction in the quality of life. Wearable\ntechnology and artificial intelligence have been used for automatic FOG\ndetection to optimize monitoring. However, differences between laboratory and\ndaily-life conditions present challenges for the implementation of reliable\ndetection systems. Consequently, improvement of FOG detection methods remains\nimportant to provide accurate monitoring mechanisms intended for free-living\nand real-time use. This paper presents advances in automatic FOG detection\nusing a single body-worn triaxial accelerometer and a novel classification\nalgorithm based on Transformers and convolutional networks. This study was\nperformed with data from 21 patients who manifested FOG episodes while\nperforming activities of daily living in a home setting. Results indicate that\nthe proposed FOG-Transformer can bring a significant improvement in FOG\ndetection using leave-one-subject-out cross-validation (LOSO CV). These results\nbring opportunities for the implementation of accurate monitoring systems for\nuse in ambulatory or home settings.",
      "tldr_zh": "本研究针对帕金森病患者中常见的步态冻结（Freezing of Gait, FOG）症状，提出了一种改进的自动检测方法，使用单一腰部佩戴的三轴加速度计（triaxial accelerometer）和基于Transformer networks与卷积网络的创新分类算法。研究使用来自21名患者的日常活动数据，在家庭环境中进行实验，并通过leave-one-subject-out cross-validation (LOSO CV)验证，结果显示该FOG-Transformer算法显著提高了检测性能。相比传统方法，此改进有助于开发更可靠的实时监测系统，提升患者在自由生活环境中的安全和生活质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03704v1",
      "published_date": "2024-04-04 09:02:17 UTC",
      "updated_date": "2024-04-04 09:02:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:52:25.921098"
    },
    {
      "arxiv_id": "2404.03304v3",
      "title": "Concept -- An Evaluation Protocol on Conversational Recommender Systems with System-centric and User-centric Factors",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Huang",
        "Peixin Qin",
        "Yang Deng",
        "Wenqiang Lei",
        "Jiancheng Lv",
        "Tat-Seng Chua"
      ],
      "abstract": "The conversational recommendation system (CRS) has been criticized regarding\nits user experience in real-world scenarios, despite recent significant\nprogress achieved in academia. Existing evaluation protocols for CRS may\nprioritize system-centric factors such as effectiveness and fluency in\nconversation while neglecting user-centric aspects. Thus, we propose a new and\ninclusive evaluation protocol, Concept, which integrates both system- and\nuser-centric factors. We conceptualise three key characteristics in\nrepresenting such factors and further divide them into six primary abilities.\nTo implement Concept, we adopt a LLM-based user simulator and evaluator with\nscoring rubrics that are tailored for each primary ability. Our protocol,\nConcept, serves a dual purpose. First, it provides an overview of the pros and\ncons in current CRS models. Second, it pinpoints the problem of low usability\nin the \"omnipotent\" ChatGPT and offers a comprehensive reference guide for\nevaluating CRS, thereby setting the foundation for CRS improvement.",
      "tldr_zh": "本研究提出了一种新的评估协议Concept，用于评估对话推荐系统（Conversational Recommender Systems, CRS），它整合了system-centric（如有效性和流畅性）和user-centric因素，以解决现有协议忽略用户体验的问题。Concept将这些因素概念化为三个关键特性，并细分为六个主要能力，通过基于LLM的用户模拟器和定制评分标准来实施。该协议不仅概述了当前CRS模型的优缺点，还揭示了ChatGPT等“万能”模型的可用性问题，并为CRS的改进提供全面参考指南。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "33 pages, 18 tables, and 10 figures. Our code is available at\n  https://github.com/huangzichun/Concept4CRS",
      "pdf_url": "http://arxiv.org/pdf/2404.03304v3",
      "published_date": "2024-04-04 08:56:48 UTC",
      "updated_date": "2024-05-06 12:44:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:52:38.353901"
    },
    {
      "arxiv_id": "2404.04293v1",
      "title": "Reason from Fallacy: Enhancing Large Language Models' Logical Reasoning through Logical Fallacy Understanding",
      "title_zh": "从谬误中推理：通过逻辑谬误理解增强大型语言模型的逻辑推理",
      "authors": [
        "Yanda Li",
        "Dixuan Wang",
        "Jiaqing Liang",
        "Guochao Jiang",
        "Qianyu He",
        "Yanghua Xiao",
        "Deqing Yang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated good performance in many\nreasoning tasks, but they still struggle with some complicated reasoning tasks\nincluding logical reasoning. One non-negligible reason for LLMs' suboptimal\nperformance on logical reasoning is their overlooking of understanding logical\nfallacies correctly. To evaluate LLMs' capability of logical fallacy\nunderstanding (LFU), we propose five concrete tasks from three cognitive\ndimensions of WHAT, WHY, and HOW in this paper. Towards these LFU tasks, we\nhave successfully constructed a new dataset LFUD based on GPT-4 accompanied by\na little human effort. Our extensive experiments justify that our LFUD can be\nused not only to evaluate LLMs' LFU capability, but also to fine-tune LLMs to\nobtain significantly enhanced performance on logical reasoning.",
      "tldr_zh": "本研究发现，大语言模型 (LLMs) 在逻辑推理任务中表现不佳，主要原因是忽略了逻辑谬误 (logical fallacies) 的正确理解。为评估 LLMs 的逻辑谬误理解能力 (LFU)，论文提出五个具体任务，涵盖 WHAT、WHY 和 HOW 的三个认知维度，并构建了一个新数据集 LFUD，使用 GPT-4 辅助并少量人工参与。实验结果显示，LFUD 不仅能有效评估 LLMs 的 LFU 能力，还可用于微调模型，从而显著提升其逻辑推理性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04293v1",
      "published_date": "2024-04-04 08:38:03 UTC",
      "updated_date": "2024-04-04 08:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:52:49.849874"
    },
    {
      "arxiv_id": "2404.03276v1",
      "title": "A Deep Reinforcement Learning Approach for Security-Aware Service Acquisition in IoT",
      "title_zh": "一种深度强化学习方法，用于物联网中的安全感知服务获取",
      "authors": [
        "Marco Arazzi",
        "Serena Nicolazzo",
        "Antonino Nocera"
      ],
      "abstract": "The novel Internet of Things (IoT) paradigm is composed of a growing number\nof heterogeneous smart objects and services that are transforming architectures\nand applications, increasing systems' complexity, and the need for reliability\nand autonomy. In this context, both smart objects and services are often\nprovided by third parties which do not give full transparency regarding the\nsecurity and privacy of the features offered. Although machine-based Service\nLevel Agreements (SLA) have been recently leveraged to establish and share\npolicies in Cloud-based scenarios, and also in the IoT context, the issue of\nmaking end users aware of the overall system security levels and the\nfulfillment of their privacy requirements through the provision of the\nrequested service remains a challenging task. To tackle this problem, we\npropose a complete framework that defines suitable levels of privacy and\nsecurity requirements in the acquisition of services in IoT, according to the\nuser needs. Through the use of a Reinforcement Learning based solution, a user\nagent, inside the environment, is trained to choose the best smart objects\ngranting access to the target services. Moreover, the solution is designed to\nguarantee deadline requirements and user security and privacy needs. Finally,\nto evaluate the correctness and the performance of the proposed approach we\nillustrate an extensive experimental analysis.",
      "tldr_zh": "本研究提出了一种基于深度强化学习（Deep Reinforcement Learning）的框架，用于IoT环境中安全感知的服务获取。该框架通过训练用户代理选择最佳智能对象，确保满足用户的隐私、安全需求以及截止期限要求，同时处理第三方服务提供者的不透明问题。实验结果显示，该方法有效提升了系统整体安全性和可靠性，为IoT服务获取提供了可靠的自治机制。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03276v1",
      "published_date": "2024-04-04 08:00:12 UTC",
      "updated_date": "2024-04-04 08:00:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:53:00.507977"
    },
    {
      "arxiv_id": "2404.03275v3",
      "title": "DELTA: Decomposed Efficient Long-Term Robot Task Planning using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Liu",
        "Luigi Palmieri",
        "Sebastian Koch",
        "Ilche Georgievski",
        "Marco Aiello"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have sparked a revolution\nacross many research fields. In robotics, the integration of common-sense\nknowledge from LLMs into task and motion planning has drastically advanced the\nfield by unlocking unprecedented levels of context awareness. Despite their\nvast collection of knowledge, large language models may generate infeasible\nplans due to hallucinations or missing domain information. To address these\nchallenges and improve plan feasibility and computational efficiency, we\nintroduce DELTA, a novel LLM-informed task planning approach. By using scene\ngraphs as environment representations within LLMs, DELTA achieves rapid\ngeneration of precise planning problem descriptions. To enhance planning\nperformance, DELTA decomposes long-term task goals with LLMs into an\nautoregressive sequence of sub-goals, enabling automated task planners to\nefficiently solve complex problems. In our extensive evaluation, we show that\nDELTA enables an efficient and fully automatic task planning pipeline,\nachieving higher planning success rates and significantly shorter planning\ntimes compared to the state of the art. Project webpage:\nhttps://delta-llm.github.io/",
      "tldr_zh": "该研究提出DELTA，一种基于Large Language Models (LLMs)的分解式高效长效机器人任务规划方法，以解决LLMs可能产生的幻觉或领域信息缺失问题。DELTA利用scene graphs作为环境表示，帮助LLMs快速生成精确的规划问题描述，并通过LLMs将长期任务目标分解为自动回归的子目标序列，从而提升任务规划器的计算效率。在广泛评估中，DELTA实现了比现有技术更高的规划成功率和显著缩短的规划时间，为机器人任务规划提供了更可靠的自动化管道。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.03275v3",
      "published_date": "2024-04-04 07:59:24 UTC",
      "updated_date": "2025-04-01 14:33:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:53:13.788922"
    },
    {
      "arxiv_id": "2404.03703v3",
      "title": "Mitigating analytical variability in fMRI results with style transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Elodie Germani",
        "Camille Maumet",
        "Elisa Fromont"
      ],
      "abstract": "We propose a novel approach to improve the reproducibility of neuroimaging\nresults by converting statistic maps across different functional MRI pipelines.\nWe make the assumption that pipelines used to compute fMRI statistic maps can\nbe considered as a style component and we propose to use different generative\nmodels, among which, Generative Adversarial Networks (GAN) and Diffusion Models\n(DM) to convert statistic maps across different pipelines. We explore the\nperformance of multiple GAN frameworks, and design a new DM framework for\nunsupervised multi-domain styletransfer. We constrain the generation of 3D fMRI\nstatistic maps using the latent space of an auxiliary classifier that\ndistinguishes statistic maps from different pipelines and extend traditional\nsampling techniques used in DM to improve the transition performance. Our\nexperiments demonstrate that our proposed methods aresuccessful: pipelines can\nindeed be transferred as a style component, providing animportant source of\ndata augmentation for future medical studies.",
      "tldr_zh": "本研究提出了一种新方法，通过风格转移（style transfer）技术缓解功能性 MRI (fMRI) 统计图的分析变异性，以提升神经影像结果的可重复性。方法假设不同 fMRI 管道可视为风格组件，并利用 Generative Adversarial Networks (GAN) 和 Diffusion Models (DM) 等生成模型进行统计图转换，包括探索多种 GAN 框架和设计一个新的 DM 框架，用于无监督的多域风格转移，并通过辅助分类器的潜在空间约束 3D fMRI 图的生成。实验结果表明，该方法成功地将管道作为风格组件，实现有效的转换，并为医疗研究提供重要的数据增强来源。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03703v3",
      "published_date": "2024-04-04 07:49:39 UTC",
      "updated_date": "2025-01-17 09:03:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:53:25.913902"
    },
    {
      "arxiv_id": "2404.03264v1",
      "title": "Foundation Model for Advancing Healthcare: Challenges, Opportunities, and Future Directions",
      "title_zh": "推进医疗保健的基础模型：挑战、机会和未来方向",
      "authors": [
        "Yuting He",
        "Fuxiang Huang",
        "Xinrui Jiang",
        "Yuxiang Nie",
        "Minghao Wang",
        "Jiguang Wang",
        "Hao Chen"
      ],
      "abstract": "Foundation model, which is pre-trained on broad data and is able to adapt to\na wide range of tasks, is advancing healthcare. It promotes the development of\nhealthcare artificial intelligence (AI) models, breaking the contradiction\nbetween limited AI models and diverse healthcare practices. Much more\nwidespread healthcare scenarios will benefit from the development of a\nhealthcare foundation model (HFM), improving their advanced intelligent\nhealthcare services. Despite the impending widespread deployment of HFMs, there\nis currently a lack of clear understanding about how they work in the\nhealthcare field, their current challenges, and where they are headed in the\nfuture. To answer these questions, a comprehensive and deep survey of the\nchallenges, opportunities, and future directions of HFMs is presented in this\nsurvey. It first conducted a comprehensive overview of the HFM including the\nmethods, data, and applications for a quick grasp of the current progress.\nThen, it made an in-depth exploration of the challenges present in data,\nalgorithms, and computing infrastructures for constructing and widespread\napplication of foundation models in healthcare. This survey also identifies\nemerging and promising directions in this field for future development. We\nbelieve that this survey will enhance the community's comprehension of the\ncurrent progress of HFM and serve as a valuable source of guidance for future\ndevelopment in this field. The latest HFM papers and related resources are\nmaintained on our website:\nhttps://github.com/YutingHe-list/Awesome-Foundation-Models-for-Advancing-Healthcare.",
      "tldr_zh": "这篇调查论文探讨了基础模型（Foundation Model）在医疗保健领域的应用及其推动医疗AI发展的潜力，强调它能解决AI模型有限与医疗实践多样性之间的矛盾，从而提升各种医疗场景的智能服务。该论文首先概述了医疗基础模型（HFM）的当前进展，包括方法、数据和应用，然后深入分析了在数据、算法和计算基础设施方面存在的挑战。该研究还识别了未来的关键机会和方向，如新兴技术整合，并提供资源网站以指导进一步发展。总的来说，这为HFM在医疗领域的广泛部署提供了宝贵指导和见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03264v1",
      "published_date": "2024-04-04 07:39:55 UTC",
      "updated_date": "2024-04-04 07:39:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:53:37.459744"
    },
    {
      "arxiv_id": "2404.03263v2",
      "title": "On the Surprising Efficacy of Distillation as an Alternative to Pre-Training Small Models",
      "title_zh": "关于知识蒸馏作为预训练小模型替代",
      "authors": [
        "Sean Farhat",
        "Deming Chen"
      ],
      "abstract": "In this paper, we propose that small models may not need to absorb the cost\nof pre-training to reap its benefits. Instead, they can capitalize on the\nastonishing results achieved by modern, enormous models to a surprising degree.\nWe observe that, when distilled on a task from a pre-trained teacher model, a\nsmall model can achieve or surpass the performance it would achieve if it was\npre-trained then finetuned on that task. To allow this phenomenon to be easily\nleveraged, we establish a connection reducing knowledge distillation to modern\ncontrastive learning, opening two doors: (1) vastly different model\narchitecture pairings can work for the distillation, and (2) most contrastive\nlearning algorithms rooted in the theory of Noise Contrastive Estimation can be\neasily applied and used. We demonstrate this paradigm using pre-trained teacher\nmodels from open-source model hubs, Transformer and convolution based model\ncombinations, and a novel distillation algorithm that massages the\nAlignment/Uniformity perspective of contrastive learning by Wang & Isola (2020)\ninto a distillation objective. We choose this flavor of contrastive learning\ndue to its low computational cost, an overarching theme of this work. We also\nobserve that this phenomenon tends not to occur if the task is data-limited.\nHowever, this can be alleviated by leveraging yet another scale-inspired\ndevelopment: large, pre-trained generative models for dataset augmentation.\nAgain, we use an open-source model, and our rudimentary prompts are sufficient\nto boost the small model`s performance. Thus, we highlight a training method\nfor small models that is up to 94% faster than the standard pre-training\nparadigm without sacrificing performance. For practitioners discouraged from\nfully utilizing modern foundation datasets for their small models due to the\nprohibitive scale, we believe our work keeps that door open.",
      "tldr_zh": "本论文发现，小模型无需进行昂贵的预-training，而是通过knowledge distillation从预训练的教师模型中学习，即可达到或超过预-training后fine-tuning的性能。该方法将knowledge distillation与contrastive learning联系起来，支持不同模型架构配对，并应用基于Noise Contrastive Estimation的算法，包括一个新颖的蒸馏算法，该算法基于Wang & Isola (2020)的Alignment/Uniformity视角，以降低计算成本。实验结果显示，这种范式比标准预-training快94%，且在数据有限的任务中，可通过大型预训练生成模型进行数据集增强来提升性能，从而为资源受限的从业者提供高效的训练替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024. 5th Workshop on Practical ML for Low Resource Settings\n  (PML4LRS). Code can be found at https://github.com/sfarhat/dapt",
      "pdf_url": "http://arxiv.org/pdf/2404.03263v2",
      "published_date": "2024-04-04 07:38:11 UTC",
      "updated_date": "2024-05-03 06:08:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:53:50.532819"
    },
    {
      "arxiv_id": "2404.03259v3",
      "title": "Advancing Aspect-Based Sentiment Analysis through Deep Learning Models",
      "title_zh": "通过深度学习模型推进基于方面的情感分析",
      "authors": [
        "Chen Li",
        "Huidong Tang",
        "Jinli Zhang",
        "Xiujing Guo",
        "Debo Cheng",
        "Yasuhiko Morimoto"
      ],
      "abstract": "Aspect-based sentiment analysis predicts sentiment polarity with fine\ngranularity. While graph convolutional networks (GCNs) are widely utilized for\nsentimental feature extraction, their naive application for syntactic feature\nextraction can compromise information preservation. This study introduces an\ninnovative edge-enhanced GCN, named SentiSys, to navigate the syntactic graph\nwhile preserving intact feature information, leading to enhanced performance.\nSpecifically,we first integrate a bidirectional long short-term memory\n(Bi-LSTM) network and a self-attention-based transformer. This combination\nfacilitates effective text encoding, preventing the loss of information and\npredicting long dependency text. A bidirectional GCN (Bi-GCN) with message\npassing is then employed to encode relationships between entities.\nAdditionally, unnecessary information is filtered out using an aspect-specific\nmasking technique. To validate the effectiveness of our proposed model, we\nconduct extensive evaluation experiments on four benchmark datasets. The\nexperimental results demonstrate enhanced performance in aspect-based sentiment\nanalysis with the use of SentiSys.",
      "tldr_zh": "本研究针对方面-based 情感分析（Aspect-based Sentiment Analysis）中的信息丢失问题，提出了一种创新模型 SentiSys，该模型基于边增强 Graph Convolutional Networks (GCNs) 来优化语法特征提取，同时保留完整特征信息。SentiSys 整合了 Bi-LSTM 和自注意力 Transformer 用于有效文本编码，处理长依赖关系，并采用双向 GCN (Bi-GCN) 编码实体间关系，再通过方面-specific 掩码技术过滤无关信息。实验结果显示，该模型在四个基准数据集上显著提升了情感分析性能，证明了其在细粒度情感极性预测方面的先进性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has already been accepted by the 20th International\n  Conference on Advanced Data Mining and Applications (ADMA2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.03259v3",
      "published_date": "2024-04-04 07:31:56 UTC",
      "updated_date": "2024-09-09 05:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:54:02.446217"
    },
    {
      "arxiv_id": "2404.03253v1",
      "title": "A dataset of primary nasopharyngeal carcinoma MRI with multi-modalities segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yin Li",
        "Qi Chen",
        "Kai Wang",
        "Meige Li",
        "Liping Si",
        "Yingwei Guo",
        "Yu Xiong",
        "Qixing Wang",
        "Yang Qin",
        "Ling Xu",
        "Patrick van der Smagt",
        "Jun Tang",
        "Nutan Chen"
      ],
      "abstract": "Multi-modality magnetic resonance imaging data with various sequences\nfacilitate the early diagnosis, tumor segmentation, and disease staging in the\nmanagement of nasopharyngeal carcinoma (NPC). The lack of publicly available,\ncomprehensive datasets limits advancements in diagnosis, treatment planning,\nand the development of machine learning algorithms for NPC. Addressing this\ncritical need, we introduce the first comprehensive NPC MRI dataset,\nencompassing MR axial imaging of 277 primary NPC patients. This dataset\nincludes T1-weighted, T2-weighted, and contrast-enhanced T1-weighted sequences,\ntotaling 831 scans. In addition to the corresponding clinical data, manually\nannotated and labeled segmentations by experienced radiologists offer\nhigh-quality data resources from untreated primary NPC.",
      "tldr_zh": "本研究发布了一个新的数据集，专注于原发性鼻咽癌(NPC)的多模态MRI图像，用于支持早期诊断、肿瘤分割和疾病分期。该数据集涵盖277名未治疗的NPC患者，共831个MR轴向扫描，包括T1-weighted、T2-weighted和contrast-enhanced T1-weighted序列，并附带临床数据和由经验丰富的放射科医生手动标注的高质量分割。通过提供首个全面的公开资源，该数据集有助于填补研究空白，促进机器学习算法的开发和治疗规划的优化。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03253v1",
      "published_date": "2024-04-04 07:19:31 UTC",
      "updated_date": "2024-04-04 07:19:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:54:14.737878"
    },
    {
      "arxiv_id": "2404.03239v1",
      "title": "Exploring Emotions in Multi-componential Space using Interactive VR Games",
      "title_zh": "使用交互式虚拟现实游戏探索",
      "authors": [
        "Rukshani Somarathna",
        "Gelareh Mohammadi"
      ],
      "abstract": "Emotion understanding is a complex process that involves multiple components.\nThe ability to recognise emotions not only leads to new context awareness\nmethods but also enhances system interaction's effectiveness by perceiving and\nexpressing emotions. Despite the attention to discrete and dimensional models,\nneuroscientific evidence supports those emotions as being complex and\nmulti-faceted. One framework that resonated well with such findings is the\nComponent Process Model (CPM), a theory that considers the complexity of\nemotions with five interconnected components: appraisal, expression,\nmotivation, physiology and feeling. However, the relationship between CPM and\ndiscrete emotions has not yet been fully explored. Therefore, to better\nunderstand emotions underlying processes, we operationalised a data-driven\napproach using interactive Virtual Reality (VR) games and collected multimodal\nmeasures (self-reports, physiological and facial signals) from 39 participants.\nWe used Machine Learning (ML) methods to identify the unique contributions of\neach component to emotion differentiation. Our results showed the role of\ndifferent components in emotion differentiation, with the model including all\ncomponents demonstrating the most significant contribution. Moreover, we found\nthat at least five dimensions are needed to represent the variation of emotions\nin our dataset. These findings also have implications for using VR environments\nin emotion research and highlight the role of physiological signals in emotion\nrecognition within such environments.",
      "tldr_zh": "本研究探讨了情感的多组件空间，使用交互式 Virtual Reality (VR) 游戏来操作化 Component Process Model (CPM)，该模型包括 appraisal、expression、motivation、physiology 和 feeling 等五个组件。研究者从 39 名参与者收集多模态数据（包括 self-reports、physiological and facial signals），并应用 Machine Learning (ML) 方法分析各组件对情感区分的贡献。结果表明，所有组件结合时对情感区分效果最佳，至少需要五个维度来表示情感变化，这为 VR 环境在情感研究中的应用提供了重要启示，并强调了 physiological signals 在情感识别中的关键作用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2404.03239v1",
      "published_date": "2024-04-04 06:54:44 UTC",
      "updated_date": "2024-04-04 06:54:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:54:28.641686"
    },
    {
      "arxiv_id": "2404.04292v5",
      "title": "Conversational Disease Diagnosis via External Planner-Controlled Large Language Models",
      "title_zh": "通过外部规划器控制的大语言模型的对话式疾病诊断",
      "authors": [
        "Zhoujian Sun",
        "Cheng Luo",
        "Ziyi Liu",
        "Zhengxing Huang"
      ],
      "abstract": "The development of large language models (LLMs) has brought unprecedented\npossibilities for artificial intelligence (AI) based medical diagnosis.\nHowever, the application perspective of LLMs in real diagnostic scenarios is\nstill unclear because they are not adept at collecting patient data\nproactively. This study presents a LLM-based diagnostic system that enhances\nplanning capabilities by emulating doctors. Our system involves two external\nplanners to handle planning tasks. The first planner employs a reinforcement\nlearning approach to formulate disease screening questions and conduct initial\ndiagnoses. The second planner uses LLMs to parse medical guidelines and conduct\ndifferential diagnoses. By utilizing real patient electronic medical record\ndata, we constructed simulated dialogues between virtual patients and doctors\nand evaluated the diagnostic abilities of our system. We demonstrated that our\nsystem obtained impressive performance in both disease screening and\ndifferential diagnoses tasks. This research represents a step towards more\nseamlessly integrating AI into clinical settings, potentially enhancing the\naccuracy and accessibility of medical diagnostics.",
      "tldr_zh": "该研究提出了一种基于大型语言模型(LLMs)的对话式疾病诊断系统，通过两个外部规划器模拟医生的规划能力，以解决LLMs在主动收集患者数据方面的不足。第一个规划器采用强化学习(reinforcement learning)方法来制定疾病筛查问题并进行初步诊断；第二个规划器则利用LLMs解析医疗指南(medical guidelines)并执行鉴别诊断(differential diagnoses)。实验基于真实患者电子医疗记录数据构建的模拟对话显示，该系统在疾病筛查和鉴别诊断任务中表现出色，代表了AI向临床设置无缝整合的重要一步，有望提升诊断的准确性和可访问性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2404.04292v5",
      "published_date": "2024-04-04 06:16:35 UTC",
      "updated_date": "2024-05-20 00:45:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:54:39.089447"
    },
    {
      "arxiv_id": "2404.03204v3",
      "title": "RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Detai Xin",
        "Xu Tan",
        "Kai Shen",
        "Zeqian Ju",
        "Dongchao Yang",
        "Yuancheng Wang",
        "Shinnosuke Takamichi",
        "Hiroshi Saruwatari",
        "Shujie Liu",
        "Jinyu Li",
        "Sheng Zhao"
      ],
      "abstract": "We present RALL-E, a robust language modeling method for text-to-speech (TTS)\nsynthesis. While previous work based on large language models (LLMs) shows\nimpressive performance on zero-shot TTS, such methods often suffer from poor\nrobustness, such as unstable prosody (weird pitch and rhythm/duration) and a\nhigh word error rate (WER), due to the autoregressive prediction style of\nlanguage models. The core idea behind RALL-E is chain-of-thought (CoT)\nprompting, which decomposes the task into simpler steps to enhance the\nrobustness of LLM-based TTS. To accomplish this idea, RALL-E first predicts\nprosody features (pitch and duration) of the input text and uses them as\nintermediate conditions to predict speech tokens in a CoT style. Second, RALL-E\nutilizes the predicted duration prompt to guide the computing of self-attention\nweights in Transformer to enforce the model to focus on the corresponding\nphonemes and prosody features when predicting speech tokens. Results of\ncomprehensive objective and subjective evaluations demonstrate that, compared\nto a powerful baseline method VALL-E, RALL-E significantly improves the WER of\nzero-shot TTS from $5.6\\%$ (without reranking) and $1.7\\%$ (with reranking) to\n$2.5\\%$ and $1.0\\%$, respectively. Furthermore, we demonstrate that RALL-E\ncorrectly synthesizes sentences that are hard for VALL-E and reduces the error\nrate from $68\\%$ to $4\\%$.",
      "tldr_zh": "我们提出RALL-E，一种基于Chain-of-Thought (CoT)提示的稳健编解码语言建模方法，用于提升文本到语音(TTS)合成的鲁棒性，以解决现有LLM-based方法的不稳定韵律和高词错误率(WER)问题。RALL-E通过先预测输入文本的韵律特征（如音高和持续时间），然后将这些特征作为中间条件指导Transformer的自注意力权重，从而在CoT风格下更准确地预测语音标记。实验结果显示，与基线VALL-E相比，RALL-E将零样本TTS的WER从5.6%（无reranking）和1.7%（有reranking）分别降低至2.5%和1.0%，并将难合成句子的错误率从68%降至4%。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03204v3",
      "published_date": "2024-04-04 05:15:07 UTC",
      "updated_date": "2024-05-19 21:34:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:54:52.795191"
    },
    {
      "arxiv_id": "2404.03190v2",
      "title": "Adaptive Discrete Disparity Volume for Self-supervised Monocular Depth Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Jianwei Ren"
      ],
      "abstract": "In self-supervised monocular depth estimation tasks, discrete disparity\nprediction has been proven to attain higher quality depth maps than common\ncontinuous methods. However, current discretization strategies often divide\ndepth ranges of scenes into bins in a handcrafted and rigid manner, limiting\nmodel performance. In this paper, we propose a learnable module, Adaptive\nDiscrete Disparity Volume (ADDV), which is capable of dynamically sensing depth\ndistributions in different RGB images and generating adaptive bins for them.\nWithout any extra supervision, this module can be integrated into existing CNN\narchitectures, allowing networks to produce representative values for bins and\na probability volume over them. Furthermore, we introduce novel training\nstrategies - uniformizing and sharpening - through a loss term and temperature\nparameter, respectively, to provide regularizations under self-supervised\nconditions, preventing model degradation or collapse. Empirical results\ndemonstrate that ADDV effectively processes global information, generating\nappropriate bins for various scenes and producing higher quality depth maps\ncompared to handcrafted methods.",
      "tldr_zh": "本研究针对自监督单目深度估计（self-supervised monocular depth estimation）中的离散视差预测问题，提出了一种可学习模块Adaptive Discrete Disparity Volume (ADDV)，它能动态感知不同RGB图像的深度分布，并生成自适应bins，从而超越传统的刚性手工离散化策略。ADDV无需额外监督即可整合到现有CNN架构中，允许网络输出bins的代表值和概率体积，同时引入uniformizing和sharpening训练策略，通过损失项和温度参数进行正则化，以防止模型退化。实验结果表明，ADDV有效处理全局信息，为各种场景生成合适的bins，并显著提升深度图的质量，比手工方法更优。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03190v2",
      "published_date": "2024-04-04 04:22:25 UTC",
      "updated_date": "2024-11-28 00:30:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:55:04.298218"
    },
    {
      "arxiv_id": "2404.03189v2",
      "title": "The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Noah Y. Siegel",
        "Oana-Maria Camburu",
        "Nicolas Heess",
        "Maria Perez-Ortiz"
      ],
      "abstract": "In order to oversee advanced AI systems, it is important to understand their\nunderlying decision-making process. When prompted, large language models (LLMs)\ncan provide natural language explanations or reasoning traces that sound\nplausible and receive high ratings from human annotators. However, it is\nunclear to what extent these explanations are faithful, i.e., truly capture the\nfactors responsible for the model's predictions. In this work, we introduce\nCorrelational Explanatory Faithfulness (CEF), a metric that can be used in\nfaithfulness tests based on input interventions. Previous metrics used in such\ntests take into account only binary changes in the predictions. Our metric\naccounts for the total shift in the model's predicted label distribution, more\naccurately reflecting the explanations' faithfulness. We then introduce the\nCorrelational Counterfactual Test (CCT) by instantiating CEF on the\nCounterfactual Test (CT) from Atanasova et al. (2023). We evaluate the\nfaithfulness of free-text explanations generated by few-shot-prompted LLMs from\nthe Llama2 family on three NLP tasks. We find that our metric measures aspects\nof faithfulness which the CT misses.",
      "tldr_zh": "该论文强调了评估大型语言模型（Large Language Models, LLMs）自由文本解释忠诚度的必要性，因为现有方法仅考虑预测的二元变化，而忽略了概率分布的整体变化。作者引入了Correlational Explanatory Faithfulness (CEF)指标，通过量化输入干预对模型预测标签分布的总移位，来更精确地衡量解释的真实性。随后，他们提出了Correlational Counterfactual Test (CCT)，作为Counterfactual Test (CT)的扩展，并在Llama2家族的LLMs上对三个NLP任务进行实验。结果显示，CEF捕捉到了CT遗漏的忠诚度方面，从而为更可靠的解释评估提供了新工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To be published in ACL 2024. 19 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.03189v2",
      "published_date": "2024-04-04 04:20:04 UTC",
      "updated_date": "2024-06-07 11:54:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:55:16.725961"
    },
    {
      "arxiv_id": "2404.03184v1",
      "title": "The Death of Feature Engineering? BERT with Linguistic Features on SQuAD 2.0",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Li",
        "Yue Zhang"
      ],
      "abstract": "Machine reading comprehension is an essential natural language processing\ntask, which takes into a pair of context and query and predicts the\ncorresponding answer to query. In this project, we developed an end-to-end\nquestion answering model incorporating BERT and additional linguistic features.\nWe conclude that the BERT base model will be improved by incorporating the\nfeatures. The EM score and F1 score are improved 2.17 and 2.14 compared with\nBERT(base). Our best single model reaches EM score 76.55 and F1 score 79.97 in\nthe hidden test set. Our error analysis also shows that the linguistic\narchitecture can help model understand the context better in that it can locate\nanswers that BERT only model predicted \"No Answer\" wrongly.",
      "tldr_zh": "本研究探讨了在SQuAD 2.0数据集上使用BERT结合额外语言学特征的机器阅读理解模型，旨在验证特征工程是否仍具价值。\n结果显示，该模型相对于BERT base提高了EM score 2.17和F1 score 2.14，最佳单模型在隐藏测试集上达到EM score 76.55和F1 score 79.97。\n错误分析表明，添加语言学特征能帮助模型更好地理解上下文，成功修正BERT模型错误预测为\"No Answer\"的问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03184v1",
      "published_date": "2024-04-04 03:50:34 UTC",
      "updated_date": "2024-04-04 03:50:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:55:28.148950"
    },
    {
      "arxiv_id": "2404.04289v1",
      "title": "Designing for Human-Agent Alignment: Understanding what humans want from their agents",
      "title_zh": "翻译失败",
      "authors": [
        "Nitesh Goyal",
        "Minsuk Chang",
        "Michael Terry"
      ],
      "abstract": "Our ability to build autonomous agents that leverage Generative AI continues\nto increase by the day. As builders and users of such agents it is unclear what\nparameters we need to align on before the agents start performing tasks on our\nbehalf. To discover these parameters, we ran a qualitative empirical research\nstudy about designing agents that can negotiate during a fictional yet\nrelatable task of selling a camera online. We found that for an agent to\nperform the task successfully, humans/users and agents need to align over 6\ndimensions: 1) Knowledge Schema Alignment 2) Autonomy and Agency Alignment 3)\nOperational Alignment and Training 4) Reputational Heuristics Alignment 5)\nEthics Alignment and 6) Human Engagement Alignment. These empirical findings\nexpand previous work related to process and specification alignment and the\nneed for values and safety in Human-AI interactions. Subsequently we discuss\nthree design directions for designers who are imagining a world filled with\nHuman-Agent collaborations.",
      "tldr_zh": "这篇论文探讨了在设计自主代理时，确保人类与代理对齐的关键参数，通过一个关于代理谈判卖相机的定性实证研究来识别这些需求。研究发现，人类和代理需要在六个维度上对齐：Knowledge Schema Alignment、Autonomy and Agency Alignment、Operational Alignment and Training、Reputational Heuristics Alignment、Ethics Alignment 和 Human Engagement Alignment。这些发现扩展了之前关于过程和规范对齐以及人类-AI 交互中价值观和安全性的工作，并提出了三个设计方向，以支持未来的人类-代理合作世界。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "Human-AI Alignment, Human-Agent Alignment, Agents, Generative AI,\n  Large Language Models",
      "pdf_url": "http://arxiv.org/pdf/2404.04289v1",
      "published_date": "2024-04-04 03:01:57 UTC",
      "updated_date": "2024-04-04 03:01:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:55:40.434659"
    },
    {
      "arxiv_id": "2404.04287v1",
      "title": "CONFLARE: CONFormal LArge language model REtrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Pouria Rouzrokh",
        "Shahriar Faghani",
        "Cooper U. Gamble",
        "Moein Shariatnia",
        "Bradley J. Erickson"
      ],
      "abstract": "Retrieval-augmented generation (RAG) frameworks enable large language models\n(LLMs) to retrieve relevant information from a knowledge base and incorporate\nit into the context for generating responses. This mitigates hallucinations and\nallows for the updating of knowledge without retraining the LLM. However, RAG\ndoes not guarantee valid responses if retrieval fails to identify the necessary\ninformation as the context for response generation. Also, if there is\ncontradictory content, the RAG response will likely reflect only one of the two\npossible responses. Therefore, quantifying uncertainty in the retrieval process\nis crucial for ensuring RAG trustworthiness. In this report, we introduce a\nfour-step framework for applying conformal prediction to quantify retrieval\nuncertainty in RAG frameworks. First, a calibration set of questions answerable\nfrom the knowledge base is constructed. Each question's embedding is compared\nagainst document embeddings to identify the most relevant document chunks\ncontaining the answer and record their similarity scores. Given a\nuser-specified error rate ({\\alpha}), these similarity scores are then analyzed\nto determine a similarity score cutoff threshold. During inference, all chunks\nwith similarity exceeding this threshold are retrieved to provide context to\nthe LLM, ensuring the true answer is captured in the context with a\n(1-{\\alpha}) confidence level. We provide a Python package that enables users\nto implement the entire workflow proposed in our work, only using LLMs and\nwithout human intervention.",
      "tldr_zh": "该论文提出 CONFLARE 框架，通过 Conformal Prediction 量化检索不确定性，以提升 Retrieval-augmented generation (RAG) 框架的可靠性和可信度。该框架包括四个步骤：构建校准集（calibration set）来比较问题嵌入和文档嵌入、记录相似度分数、根据指定错误率（α）确定相似度阈值，并在推理时检索所有超过阈值的文档，确保以 (1-α) 置信水平捕获正确答案。该方法解决了 RAG 在检索失败或内容矛盾时的潜在问题，并提供了一个 Python 包，支持用户无需人工干预即可实现整个工作流程。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Github code:\n  https://github.com/Mayo-Radiology-Informatics-Lab/conflare",
      "pdf_url": "http://arxiv.org/pdf/2404.04287v1",
      "published_date": "2024-04-04 02:58:21 UTC",
      "updated_date": "2024-04-04 02:58:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:55:51.493781"
    },
    {
      "arxiv_id": "2404.03702v1",
      "title": "Personalized Federated Learning for Spatio-Temporal Forecasting: A Dual Semantic Alignment-Based Contrastive Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Qingxiang Liu",
        "Sheng Sun",
        "Yuxuan Liang",
        "Jingjing Xue",
        "Min Liu"
      ],
      "abstract": "The existing federated learning (FL) methods for spatio-temporal forecasting\nfail to capture the inherent spatio-temporal heterogeneity, which calls for\npersonalized FL (PFL) methods to model the spatio-temporally variant patterns.\nWhile contrastive learning approach is promising in addressing spatio-temporal\nheterogeneity, the existing methods are noneffective in determining negative\npairs and can hardly apply to PFL paradigm. To tackle this limitation, we\npropose a novel PFL method, named Federated dUal sEmantic aLignment-based\ncontraStive learning (FUELS), which can adaptively align positive and negative\npairs based on semantic similarity, thereby injecting precise spatio-temporal\nheterogeneity into the latent representation space by auxiliary contrastive\ntasks. From temporal perspective, a hard negative filtering module is\nintroduced to dynamically align heterogeneous temporal representations for the\nsupplemented intra-client contrastive task. From spatial perspective, we design\nlightweight-but-efficient prototypes as client-level semantic representations,\nbased on which the server evaluates spatial similarity and yields\nclient-customized global prototypes for the supplemented inter-client\ncontrastive task. Extensive experiments demonstrate that FUELS outperforms\nstate-of-the-art methods, with communication cost decreasing by around 94%.",
      "tldr_zh": "本研究针对现有联邦学习（FL）方法无法捕捉时空异质性（spatio-temporal heterogeneity）的局限性，提出了一种新型个性化联邦学习（PFL）方法Federated dUal sEmantic aLignment-based contraStive learning (FUELS)，通过基于语义相似度的自适应对齐来优化对比学习（contrastive learning）。FUELS 从时间视角引入硬负过滤模块（hard negative filtering module）以动态对齐异质时间表示，并从空间视角设计轻量级原型（lightweight-but-efficient prototypes）作为客户端级语义表示，从而生成客户端定制的全局原型。实验结果表明，FUELS 优于现有最先进方法，并将通信成本降低约 94%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03702v1",
      "published_date": "2024-04-04 02:43:56 UTC",
      "updated_date": "2024-04-04 02:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:56:06.102868"
    },
    {
      "arxiv_id": "2404.03164v2",
      "title": "KG4RecEval: Does Knowledge Graph Really Matter for Recommender Systems?",
      "title_zh": "KG4RecEval：知识图谱真的对推荐系统很重要吗？",
      "authors": [
        "Haonan Zhang",
        "Dongxia Wang",
        "Zhu Sun",
        "Yanhui Li",
        "Youcheng Sun",
        "Huizhi Liang",
        "Wenhai Wang"
      ],
      "abstract": "Recommender systems (RSs) are designed to provide personalized\nrecommendations to users. Recently, knowledge graphs (KGs) have been widely\nintroduced in RSs to improve recommendation accuracy. In this study, however,\nwe demonstrate that RSs do not necessarily perform worse even if the KG is\ndowngraded to the user-item interaction graph only (or removed). We propose an\nevaluation framework KG4RecEval to systematically evaluate how much a KG\ncontributes to the recommendation accuracy of a KG-based RS, using our defined\nmetric KGER (KG utilization efficiency in recommendation). We consider the\nscenarios where knowledge in a KG gets completely removed, randomly distorted\nand decreased, and also where recommendations are for cold-start users. Our\nextensive experiments on four commonly used datasets and a number of\nstate-of-the-art KG-based RSs reveal that: to remove, randomly distort or\ndecrease knowledge does not necessarily decrease recommendation accuracy, even\nfor cold-start users. These findings inspire us to rethink how to better\nutilize knowledge from existing KGs, whereby we discuss and provide insights\ninto what characteristics of datasets and KG-based RSs may help improve KG\nutilization efficiency. The code and supplementary material of this paper are\navailable at: https://github.com/HotBento/KG4RecEval.",
      "tldr_zh": "这篇论文质疑知识图谱（KG）在推荐系统（RSs）中的实际价值，提出评估框架 KG4RecEval 和指标 KGER（KG utilization efficiency in recommendation），用于系统评估 KG 对推荐准确率的贡献。研究通过实验模拟移除、随机扭曲或减少 KG，以及针对冷启动用户的场景，检验其对 RSs 性能的影响。结果显示，这些操作并不一定降低推荐准确率，甚至在多个常用数据集和最先进 KG-based RSs 上保持稳定，并提供见解以优化 KG 的利用效率。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03164v2",
      "published_date": "2024-04-04 02:32:58 UTC",
      "updated_date": "2025-01-23 09:40:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:56:15.681119"
    },
    {
      "arxiv_id": "2404.03163v2",
      "title": "Uncertainty in Language Models: Assessment through Rank-Calibration",
      "title_zh": "翻译失败",
      "authors": [
        "Xinmeng Huang",
        "Shuo Li",
        "Mengxin Yu",
        "Matteo Sesia",
        "Hamed Hassani",
        "Insup Lee",
        "Osbert Bastani",
        "Edgar Dobriban"
      ],
      "abstract": "Language Models (LMs) have shown promising performance in natural language\ngeneration. However, as LMs often generate incorrect or hallucinated responses,\nit is crucial to correctly quantify their uncertainty in responding to given\ninputs. In addition to verbalized confidence elicited via prompting, many\nuncertainty measures ($e.g.$, semantic entropy and affinity-graph-based\nmeasures) have been proposed. However, these measures can differ greatly, and\nit is unclear how to compare them, partly because they take values over\ndifferent ranges ($e.g.$, $[0,\\infty)$ or $[0,1]$). In this work, we address\nthis issue by developing a novel and practical framework, termed\n$Rank$-$Calibration$, to assess uncertainty and confidence measures for LMs.\nOur key tenet is that higher uncertainty (or lower confidence) should imply\nlower generation quality, on average. Rank-calibration quantifies deviations\nfrom this ideal relationship in a principled manner, without requiring ad hoc\nbinary thresholding of the correctness score ($e.g.$, ROUGE or METEOR). The\nbroad applicability and the granular interpretability of our methods are\ndemonstrated empirically.",
      "tldr_zh": "该论文探讨了语言模型 (LMs) 在自然语言生成中的不确定性问题，因为现有不确定性措施（如 semantic entropy 和基于亲和图的指标）范围不同（如 [0, ∞) 或 [0,1]），导致比较困难。作者提出了一种名为 Rank-Calibration 的新框架，用于评估 LMs 的不确定性和置信度措施，其核心原则是更高的不确定性应对应较低的生成质量，从而以原则方式量化偏差，而非依赖 ad hoc 的二元阈值（如 ROUGE 或 METEOR）。通过实证实验，该框架展示了广泛的适用性和细粒度可解释性，为更可靠的 LMs 不确定性评估提供了实用工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03163v2",
      "published_date": "2024-04-04 02:31:05 UTC",
      "updated_date": "2024-09-14 02:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:56:28.688176"
    },
    {
      "arxiv_id": "2404.04286v2",
      "title": "Bias Amplification in Language Model Evolution: An Iterated Learning Perspective",
      "title_zh": "语言模型演化中的偏差放大：一个迭代学习视角",
      "authors": [
        "Yi Ren",
        "Shangmin Guo",
        "Linlu Qiu",
        "Bailin Wang",
        "Danica J. Sutherland"
      ],
      "abstract": "With the widespread adoption of Large Language Models (LLMs), the prevalence\nof iterative interactions among these models is anticipated to increase.\nNotably, recent advancements in multi-round self-improving methods allow LLMs\nto generate new examples for training subsequent models. At the same time,\nmulti-agent LLM systems, involving automated interactions among agents, are\nalso increasing in prominence. Thus, in both short and long terms, LLMs may\nactively engage in an evolutionary process. We draw parallels between the\nbehavior of LLMs and the evolution of human culture, as the latter has been\nextensively studied by cognitive scientists for decades. Our approach involves\nleveraging Iterated Learning (IL), a Bayesian framework that elucidates how\nsubtle biases are magnified during human cultural evolution, to explain some\nbehaviors of LLMs. This paper outlines key characteristics of agents' behavior\nin the Bayesian-IL framework, including predictions that are supported by\nexperimental verification with various LLMs. This theoretical framework could\nhelp to more effectively predict and guide the evolution of LLMs in desired\ndirections.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在迭代互动中的偏差放大问题，通过借鉴认知科学中的 Iterated Learning (IL) 框架来分析 LLMs 的演化行为。论文采用贝叶斯-IL 方法，预测并实验验证了代理行为特征，包括偏差在多轮自提升和多智能体系统中如何被放大。结果表明，这一理论框架可有效指导 LLMs 的演化方向，确保其发展更可控和可靠。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04286v2",
      "published_date": "2024-04-04 02:01:25 UTC",
      "updated_date": "2024-10-03 05:27:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:56:40.145464"
    },
    {
      "arxiv_id": "2405.15779v2",
      "title": "LiteNeXt: A Novel Lightweight ConvMixer-based Model with Self-embedding Representation Parallel for Medical Image Segmentation",
      "title_zh": "LiteNeXt：一种新型轻",
      "authors": [
        "Ngoc-Du Tran",
        "Thi-Thao Tran",
        "Quang-Huy Nguyen",
        "Manh-Hung Vu",
        "Van-Truong Pham"
      ],
      "abstract": "The emergence of deep learning techniques has advanced the image segmentation\ntask, especially for medical images. Many neural network models have been\nintroduced in the last decade bringing the automated segmentation accuracy\nclose to manual segmentation. However, cutting-edge models like\nTransformer-based architectures rely on large scale annotated training data,\nand are generally designed with densely consecutive layers in the encoder,\ndecoder, and skip connections resulting in large number of parameters.\nAdditionally, for better performance, they often be pretrained on a larger\ndata, thus requiring large memory size and increasing resource expenses. In\nthis study, we propose a new lightweight but efficient model, namely LiteNeXt,\nbased on convolutions and mixing modules with simplified decoder, for medical\nimage segmentation. The model is trained from scratch with small amount of\nparameters (0.71M) and Giga Floating Point Operations Per Second (0.42). To\nhandle boundary fuzzy as well as occlusion or clutter in objects especially in\nmedical image regions, we propose the Marginal Weight Loss that can help\neffectively determine the marginal boundary between object and background.\nAdditionally, the Self-embedding Representation Parallel technique is proposed\nas an innovative data augmentation strategy that utilizes the network\narchitecture itself for self-learning augmentation, enhancing feature\nextraction robustness without external data. Experiments on public datasets\nincluding Data Science Bowls, GlaS, ISIC2018, PH2, Sunnybrook, and Lung X-ray\ndata show promising results compared to other state-of-the-art CNN-based and\nTransformer-based architectures. Our code is released at:\nhttps://github.com/tranngocduvnvp/LiteNeXt.",
      "tldr_zh": "本文提出了一种新型轻量级模型 LiteNeXt，基于 ConvMixer 和混合模块，用于医疗图像分割。该模型采用简化解码器，仅需 0.71M 参数和 0.42 GFLOPs，从零开始训练，并引入 Marginal Weight Loss 来有效处理图像边界模糊、遮挡等问题，以及 Self-embedding Representation Parallel 作为自学习数据增强策略，提升特征提取鲁棒性。实验结果显示，在 Data Science Bowls、GlaS、ISIC2018、PH2、Sunnybrook 和肺 X 光数据集上，LiteNeXt 优于现有 CNN 和 Transformer 架构的 SOTA 模型，证明了其高效性和潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "This manuscript has been accepted by Biomedical Signal Processing and\n  Control",
      "pdf_url": "http://arxiv.org/pdf/2405.15779v2",
      "published_date": "2024-04-04 01:59:19 UTC",
      "updated_date": "2025-03-09 08:54:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:56:52.709751"
    },
    {
      "arxiv_id": "2404.03150v1",
      "title": "NLP at UC Santa Cruz at SemEval-2024 Task 5: Legal Answer Validation using Few-Shot Multi-Choice QA",
      "title_zh": "翻译失败",
      "authors": [
        "Anish Pahilajani",
        "Samyak Rajesh Jain",
        "Devasha Trivedi"
      ],
      "abstract": "This paper presents our submission to the SemEval 2024 Task 5: The Legal\nArgument Reasoning Task in Civil Procedure. We present two approaches to\nsolving the task of legal answer validation, given an introduction to the case,\na question and an answer candidate. Firstly, we fine-tuned pre-trained\nBERT-based models and found that models trained on domain knowledge perform\nbetter. Secondly, we performed few-shot prompting on GPT models and found that\nreformulating the answer validation task to be a multiple-choice QA task\nremarkably improves the performance of the model. Our best submission is a\nBERT-based model that achieved the 7th place out of 20.",
      "tldr_zh": "这篇论文介绍了 UC Santa Cruz 在 SemEval-2024 Task 5 中的参赛工作，专注于通过 Few-Shot Multi-Choice QA 方法进行法律答案验证任务，包括给定案例介绍、问题和答案候选。研究者采用了两种方法：一是微调基于 BERT 的预训练模型，发现使用领域知识的模型表现更优；二是对 GPT 模型进行 Few-Shot Prompting，将任务转化为多选问答形式，从而显著提升性能。最终，他们的最佳提交是基于 BERT 的模型，在 20 个参赛者中排名第 7。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03150v1",
      "published_date": "2024-04-04 01:50:20 UTC",
      "updated_date": "2024-04-04 01:50:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:57:06.086733"
    },
    {
      "arxiv_id": "2404.03147v5",
      "title": "Eigenpruning: an Interpretability-Inspired PEFT Method",
      "title_zh": "翻译失败",
      "authors": [
        "Tomás Vergara-Browne",
        "Álvaro Soto",
        "Akiko Aizawa"
      ],
      "abstract": "We introduce eigenpruning, a method that removes singular values from weight\nmatrices in an LLM to improve its performance in a particular task. This method\nis inspired by interpretability methods designed to automatically find\nsubnetworks of a model which solve a specific task. In our tests, the pruned\nmodel outperforms the original model by a large margin, while only requiring\nminimal computation to prune the weight matrices. In the case of a small\nsynthetic task in integer multiplication, the Phi-2 model can improve its\naccuracy in the test set from 13.75% to 97.50%. Interestingly, these results\nseem to indicate the existence of a computation path that can solve the task\nvery effectively, but it was not being used by the original model. Finally, we\npublicly release our implementation.",
      "tldr_zh": "本研究提出了一种名为 Eigenpruning 的 PEFT 方法，受可解释性技术启发，通过从 LLM 的权重矩阵中移除奇异值来提升模型在特定任务上的性能。该方法仅需最小计算量即可修剪模型，并在测试中大幅超越原模型，例如在整数乘法合成任务上，Phi-2 模型的测试准确率从 13.75% 提高到 97.50%。这些结果揭示了原模型中可能存在未被利用的有效计算路径，从而为任务优化提供新见解。研究还公开了实现代码，以促进进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Extended abstract accepted to LatinX at NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.03147v5",
      "published_date": "2024-04-04 01:42:28 UTC",
      "updated_date": "2024-06-20 09:32:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:57:17.969300"
    },
    {
      "arxiv_id": "2404.03133v2",
      "title": "A Framework for Guided Motion Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Amnon Attali",
        "Stav Ashur",
        "Isaac Burton Love",
        "Courtney McBeth",
        "James Motes",
        "Marco Morales",
        "Nancy M. Amato"
      ],
      "abstract": "Randomized sampling based algorithms are widely used in robot motion planning\ndue to the problem's intractability, and are experimentally effective on a wide\nrange of problem instances. Most variants bias their sampling using various\nheuristics related to the known underlying structure of the search space. In\nthis work, we formalize the intuitive notion of guided search by defining the\nconcept of a guiding space. This new language encapsulates many seemingly\ndistinct prior methods under the same framework, and allows us to reason about\nguidance, a previously obscured core contribution of different algorithms. We\nsuggest an information theoretic method to evaluate guidance, which\nexperimentally matches intuition when tested on known algorithms in a variety\nof environments. The language and evaluation of guidance suggests improvements\nto existing methods, and allows for simple hybrid algorithms that combine\nguidance from multiple sources.",
      "tldr_zh": "该论文提出一个框架，用于引导机器人运动规划，形式化了“guiding space”的概念，以统一多种基于启发式方法的随机采样算法。作者引入了一种信息理论方法来评估指导的有效性，并在各种环境中实验验证了其与直觉的一致性。该框架不仅揭示了现有算法的核心贡献，还建议了改进策略和简单混合算法，以结合多种指导来源提升规划性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.03133v2",
      "published_date": "2024-04-04 00:58:19 UTC",
      "updated_date": "2024-10-07 03:56:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T21:57:27.615741"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 86,
  "processed_papers_count": 86,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T21:57:54.566193"
}