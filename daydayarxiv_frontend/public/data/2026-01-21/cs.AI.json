{
  "date": "2026-01-21",
  "category": "cs.AI",
  "summary": "",
  "papers": [
    {
      "arxiv_id": "2601.15540v1",
      "title": "PRISM: Deriving the Transformer as a Signal-Denoising Operator via Maximum Coding Rate Reduction",
      "title_zh": "PRISM：基于最大化编码率削减将 Transformer 推导为信号去噪算子",
      "authors": [
        "Dongchen Huang"
      ],
      "abstract": "Deep learning models, particularly Transformers, are often criticized as \"black boxes\" and lack interpretability. We propose Prism, a white-box attention-based architecture derived from the principles of Maximizing Coding Rate Reduction ($\\text{MCR}^2$). By modeling the attention mechanism as a gradient ascent process on a distinct signal-noise manifold, we introduce two physical constraints: an overcomplete dictionary to expand the representational phase space, and an irrational frequency separation ($π$-RoPE) to enforce incoherence between signal and noise subspaces. We demonstrate that these geometric inductive biases can be viewed as a physical constraint and they are sufficient to induce unsupervised functional disentanglement alone. Using TinyStories as a controlled testbed for verifying spectral dynamics, we observe that Prism spontaneously specializes its attention heads into spectrally distinct regimes: low-frequency heads capturing long-range causal dependencies (signal) and high-frequency heads handling local syntactic constraints (noise). Our results suggest that interpretability and performance are not a trade-off, but can be unified through principled geometric construction.",
      "tldr_zh": "本研究提出了 Prism，一种基于最大编码率缩减 ($\\text{MCR}^2$) 原理推导出的白盒注意力架构，旨在解决 Transformer 模型作为“黑盒”缺乏可解释性的问题。该架构将注意力机制建模为信号-噪声流形上的梯度上升过程，并引入了过完备字典 (overcomplete dictionary) 和无理频率分离 ($\\pi$-RoPE) 两个物理约束，以强制信号与噪声子空间的不相干性。实验表明，这些几何归纳偏置足以诱导无监督的功能解耦，使得 Prism 的注意力头自发分化为捕捉长程因果依赖的低频头（信号）和处理局部句法约束的高频头（噪声）。研究结果证明了可解释性与性能并非权衡关系，而是可以通过原则性的几何构建达成统一。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "physics.data-an"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15540v1",
      "published_date": "2026-01-21 23:52:36 UTC",
      "updated_date": "2026-01-21 23:52:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:31:34.347545+00:00"
    },
    {
      "arxiv_id": "2601.15539v1",
      "title": "A Machine Vision Approach to Preliminary Skin Lesion Assessments",
      "title_zh": "皮肤病变初步评估的机器视觉方法",
      "authors": [
        "Ali Khreis",
        "Ro'Yah Radaideh",
        "Quinn McGill"
      ],
      "abstract": "Early detection of malignant skin lesions is critical for improving patient outcomes in aggressive, metastatic skin cancers. This study evaluates a comprehensive system for preliminary skin lesion assessment that combines the clinically established ABCD rule of dermoscopy (analyzing Asymmetry, Borders, Color, and Dermoscopic Structures) with machine learning classification. Using a 1,000-image subset of the HAM10000 dataset, the system implements an automated, rule-based pipeline to compute a Total Dermoscopy Score (TDS) for each lesion. This handcrafted approach is compared against various machine learning solutions, including traditional classifiers (Logistic Regression, Random Forest, and SVM) and deep learning models. While the rule-based system provides high clinical interpretability, results indicate a performance bottleneck when reducing complex morphology to five numerical features. Experimental findings show that transfer learning with EfficientNet-B0 failed significantly due to domain shift between natural and medical images. In contrast, a custom three-layer Convolutional Neural Network (CNN) trained from scratch achieved 78.5% accuracy and 86.5% recall on median-filtered images, representing a 19-point accuracy improvement over traditional methods. The results demonstrate that direct pixel-level learning captures diagnostic patterns beyond handcrafted features and that purpose-built lightweight architectures can outperform large pretrained models for small, domain-specific medical datasets.",
      "tldr_zh": "该研究评估了一种用于皮肤病变初步评估的综合系统，旨在通过机器视觉技术提高恶性皮肤癌的早期检测率。系统结合了皮肤镜检查中临床公认的 ABCD rule（分析 Asymmetry、Borders、Color 和 Dermoscopic Structures），并利用 HAM10000 数据集实现了自动化的 Total Dermoscopy Score (TDS) 计算流程。研究将这种基于手工特征的方法与传统机器学习分类器及深度学习模型进行了对比，发现将复杂形态简化为数值特征会产生性能瓶颈。实验结果显示，由于自然图像与医学图像之间的 Domain shift，使用 EfficientNet-B0 的迁移学习表现不佳。相比之下，在经过中值滤波处理的图像上从头训练的自定义三层 Convolutional Neural Network (CNN) 取得了 78.5% 的准确率和 86.5% 的召回率，准确率比传统方法提高了 19 个百分点。该研究最终证明，直接的像素级学习能捕捉到手工特征之外的诊断模式，且针对特定领域的轻量级架构在小型医学数据集上的表现优于大型预训练模型。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "6 pages, 2 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.15539v1",
      "published_date": "2026-01-21 23:48:59 UTC",
      "updated_date": "2026-01-21 23:48:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:31:40.452727+00:00"
    },
    {
      "arxiv_id": "2601.15538v1",
      "title": "QUAIL: Quantization Aware Unlearning for Mitigating Misinformation in LLMs",
      "title_zh": "QUAIL：用于缓解大语言模型虚假信息的量化感知机器遗忘",
      "authors": [
        "Himanshu Mishra",
        "Kanwal Mehreen"
      ],
      "abstract": "Machine unlearning aims to remove specific knowledge (e.g., copyrighted or private data) from a trained model without full retraining. In practice, models are often quantized (e.g., 4-bit) for deployment, but we find that quantization can catastrophically restore forgotten information [1]. In this paper, we (1) analyze why low-bit quantization undermines unlearning, and (2) propose a quantization-aware unlearning method to mitigate this. We first compute weight-change statistics and bucket overlaps in quantization to show that typical unlearning updates are too small to cross quantization thresholds. Building on this insight, we introduce a logits space hinge loss: for each forget example, we force the output logits of the unlearned model to differ from the original model by at least a margin (half the quantization step). This ensures forgotten examples remain distinguishable even after quantization. We evaluate on language and classification tasks (including a Twitter misinformation dataset) and show our method preserves forgetting under 4-bit quantization, whereas existing methods almost entirely recover the forgotten knowledge.",
      "tldr_zh": "该研究探讨了大语言模型(LLMs)在部署时常用的量化(Quantization)过程如何导致机器遗忘(Machine unlearning)效果失效，进而引发已删除信息的“灾难性恢复”问题。作者通过分析权重变化统计发现，传统的遗忘算法产生的更新量过小，通常无法跨越量化阈值。为此，研究提出了量化感知遗忘方法QUAIL，通过在Logits空间引入铰链损失(Hinge loss)，确保遗忘样本在模型更新前后的输出差异至少达到半个量化步长的边际。这一设计保证了被遗忘的知识在量化后仍能保持不可区分性。在Twitter误导信息数据集等任务上的评估表明，QUAIL在4-bit量化下能有效保留遗忘效果，而现有方法在量化后几乎会完全恢复被遗忘的知识。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15538v1",
      "published_date": "2026-01-21 23:48:38 UTC",
      "updated_date": "2026-01-21 23:48:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:31:40.201945+00:00"
    },
    {
      "arxiv_id": "2601.15533v1",
      "title": "From Generative Engines to Actionable Simulators: The Imperative of Physical Grounding in World Models",
      "title_zh": "从生成引擎到可操作模拟器：世界模型中物理接地的必要性",
      "authors": [
        "Zhikang Chen",
        "Tingting Zhu"
      ],
      "abstract": "A world model is an AI system that simulates how an environment evolves under actions, enabling planning through imagined futures rather than reactive perception. Current world models, however, suffer from visual conflation: the mistaken assumption that high-fidelity video generation implies an understanding of physical and causal dynamics. We show that while modern models excel at predicting pixels, they frequently violate invariant constraints, fail under intervention, and break down in safety-critical decision-making. This survey argues that visual realism is an unreliable proxy for world understanding. Instead, effective world models must encode causal structure, respect domain-specific constraints, and remain stable over long horizons. We propose a reframing of world models as actionable simulators rather than visual engines, emphasizing structured 4D interfaces, constraint-aware dynamics, and closed-loop evaluation. Using medical decision-making as an epistemic stress test, where trial-and-error is impossible and errors are irreversible, we demonstrate that a world model's value is determined not by how realistic its rollouts appear, but by its ability to support counterfactual reasoning, intervention planning, and robust long-horizon foresight.",
      "tldr_zh": "这项研究探讨了世界模型 (World Models) 从生成引擎向可执行模拟器 (Actionable Simulators) 转型的必要性，指出当前模型存在将高保真视频生成误认为物理与因果动力学理解的视觉混淆 (Visual Conflation) 问题。作者发现，虽然现代模型擅长像素预测，但在安全关键型决策中经常违反物理约束并在干预下失效。论文认为视觉真实性 (Visual Realism) 并不是衡量世界理解的可靠指标，有效的世界模型必须编码因果结构并遵循特定领域的约束。为此，研究提议将世界模型重构为可执行模拟器，强调结构化 4D 接口 (Structured 4D Interfaces)、约束感知动力学 (Constraint-aware Dynamics) 和闭环评估 (Closed-loop Evaluation)。通过医疗决策这一无法试错的极端场景进行测试，研究证明了世界模型的真正价值在于其支持反事实推理 (Counterfactual Reasoning)、干预规划 (Intervention Planning) 以及稳健的长时程预见能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15533v1",
      "published_date": "2026-01-21 23:35:33 UTC",
      "updated_date": "2026-01-21 23:35:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:31:33.367326+00:00"
    },
    {
      "arxiv_id": "2601.15519v1",
      "title": "TransportAgents: a multi-agents LLM framework for traffic accident severity prediction",
      "title_zh": "TransportAgents：面向交通事故严重程度预测的多智能体大语言模型框架",
      "authors": [
        "Zhichao Yang",
        "Jiashu He",
        "Jinxuan Fan",
        "Cirillo Cinzia"
      ],
      "abstract": "Accurate prediction of traffic crash severity is critical for improving emergency response and public safety planning. Although recent large language models (LLMs) exhibit strong reasoning capabilities, their single-agent architectures often struggle with heterogeneous, domain-specific crash data and tend to generate biased or unstable predictions. To address these limitations, this paper proposes TransportAgents, a hybrid multi-agent framework that integrates category-specific LLM reasoning with a multilayer perceptron (MLP) integration module. Each specialized agent focuses on a particular subset of traffic information, such as demographics, environmental context, or incident details, to produce intermediate severity assessments that are subsequently fused into a unified prediction. Extensive experiments on two complementary U.S. datasets, the Consumer Product Safety Risk Management System (CPSRMS) and the National Electronic Injury Surveillance System (NEISS), demonstrate that TransportAgents consistently outperforms both traditional machine learning and advanced LLM-based baselines. Across three representative backbones, including closed-source models such as GPT-3.5 and GPT-4o, as well as open-source models such as LLaMA-3.3, the framework exhibits strong robustness, scalability, and cross-dataset generalizability. A supplementary distributional analysis further shows that TransportAgents produces more balanced and well-calibrated severity predictions than standard single-agent LLM approaches, highlighting its interpretability and reliability for safety-critical decision support applications.",
      "tldr_zh": "该研究提出了 TransportAgents，一种用于交通事故严重程度预测的混合多智能体 LLM 框架，旨在解决单智能体架构在处理异构、特定领域事故数据时存在的偏差和不稳定问题。该框架通过集成针对人口统计、环境背景和事故详情等特定类别的 LLM 推理，并结合多层感知器 (MLP) 集成模块，将各专业智能体的中间评估融合成统一的预测结果。在 CPSRMS 和 NEISS 两个美国数据集上的广泛实验表明，TransportAgents 在 GPT-4o 和 LLaMA-3.3 等多种骨干模型上均显著优于传统机器学习和先进的单智能体 LLM 基线。分布分析进一步证实，该框架相比标准单智能体方法能产生更均衡且校准良好的预测，在关键安全决策支持应用中展现出极强的鲁棒性、跨数据集泛化能力和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15519v1",
      "published_date": "2026-01-21 23:14:05 UTC",
      "updated_date": "2026-01-21 23:14:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:31:39.963573+00:00"
    },
    {
      "arxiv_id": "2601.15509v1",
      "title": "The Dark Side of AI Transformers: Sentiment Polarization & the Loss of Business Neutrality by NLP Transformers",
      "title_zh": "AI Transformer 模型的阴暗面：NLP Transformer 模型导致的情感极化与商业中立性丧失",
      "authors": [
        "Prasanna Kumar"
      ],
      "abstract": "The use of Transfer Learning & Transformers has steadily improved accuracy and has significantly contributed in solving complex computation problems. However, this transformer led accuracy improvement in Applied AI Analytics specifically in sentiment analytics comes with the dark side. It is observed during experiments that a lot of these improvements in transformer led accuracy of one class of sentiment has been at the cost of polarization of another class of sentiment and the failing of neutrality. This lack of neutrality poses an acute problem in the Applied NLP space, which relies heavily on the computational outputs of sentiment analytics for reliable industry ready tasks.",
      "tldr_zh": "该研究探讨了 Transfer Learning 与 Transformers 在 Applied AI Analytics 领域，特别是在情感分析应用中的负面影响。尽管 Transformer 模型显著提高了计算准确率并解决了复杂计算问题，但实验发现这种准确率的提升往往以牺牲情感中立性（neutrality）和导致另一类情感极化（polarization）为代价。这种中立性的缺失在 Applied NLP 领域构成了一个严峻挑战，因为该领域高度依赖情感分析的计算输出来执行可靠的工业级任务。研究强调了在追求高准确率的同时，必须关注商业应用中情感倾向失衡对决策可靠性带来的负面作用。通过揭示模型在情感处理上的“黑暗面”，该研究为未来开发更具商业中立性的 NLP 模型提供了重要的警示和见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15509v1",
      "published_date": "2026-01-21 22:40:47 UTC",
      "updated_date": "2026-01-21 22:40:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:31:55.647770+00:00"
    },
    {
      "arxiv_id": "2601.15500v1",
      "title": "Low-Dimensional Adaptation of Rectified Flow: A New Perspective through the Lens of Diffusion and Stochastic Localization",
      "title_zh": "Rectified Flow 的低维自适应：扩散与随机局域化视域下的新视角",
      "authors": [
        "Saptarshi Roy",
        "Alessandro Rinaldo",
        "Purnamrita Sarkar"
      ],
      "abstract": "In recent years, Rectified flow (RF) has gained considerable popularity largely due to its generation efficiency and state-of-the-art performance. In this paper, we investigate the degree to which RF automatically adapts to the intrinsic low dimensionality of the support of the target distribution to accelerate sampling. We show that, using a carefully designed choice of the time-discretization scheme and with sufficiently accurate drift estimates, the RF sampler enjoys an iteration complexity of order $O(k/\\varepsilon)$ (up to log factors), where $\\varepsilon$ is the precision in total variation distance and $k$ is the intrinsic dimension of\n  the target distribution. In addition, we show that the denoising diffusion probabilistic model (DDPM) procedure is equivalent to a stochastic version of RF by establishing a novel connection between these processes and stochastic localization. Building on this connection, we further design a stochastic RF sampler that also adapts to the low-dimensionality of the target distribution under milder requirements on the accuracy of the drift estimates, and also with a specific time schedule. We illustrate with simulations on the synthetic data and text-to-image data experiments the improved performance of the proposed samplers implementing the newly designed time-discretization schedules.",
      "tldr_zh": "该研究从 Diffusion 和 Stochastic Localization 的视角出发，深入探讨了 Rectified Flow (RF) 自动适应目标分布内在低维性以加速采样的机制。研究表明，在采用精心设计的时间离散化方案(Time-discretization scheme)且漂移估计足够精确时，RF 采样器的迭代复杂度与目标分布的内在维度 $k$ 成正比，即 $O(k/\\varepsilon)$。此外，论文建立了 RF 与随机定位(Stochastic Localization)之间的新颖联系，证明了 Denoising Diffusion Probabilistic Model (DDPM) 等同于 RF 的随机版本。基于这一发现，作者进一步设计了一种新型随机 RF 采样器(Stochastic RF sampler)，通过特定的时间调度，在较低的漂移估计精度要求下仍能有效适应低维分布。仿真实验和 Text-to-image 实验均验证了所提采样器及其时间离散化策略在生成性能上的显著提升。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "stat.ML",
      "comment": "32 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.15500v1",
      "published_date": "2026-01-21 22:09:27 UTC",
      "updated_date": "2026-01-21 22:09:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:32:07.585546+00:00"
    },
    {
      "arxiv_id": "2601.15495v1",
      "title": "Tracking the Limits of Knowledge Propagation: How LLMs Fail at Multi-Step Reasoning with Conflicting Knowledge",
      "title_zh": "追踪知识传播的极限：大语言模型在冲突知识下的多步推理失效研究",
      "authors": [
        "Yiyang Feng",
        "Zeming Chen",
        "Haotian Wu",
        "Jiawei Zhou",
        "Antoine Bosselut"
      ],
      "abstract": "A common solution for mitigating outdated or incorrect information in Large Language Models (LLMs) is to provide updated facts in-context or through knowledge editing. However, these methods introduce knowledge conflicts when the knowledge update fails to overwrite the model's parametric knowledge, which propagate to faulty reasoning. Current benchmarks for this problem, however, largely focus only on single knowledge updates and fact recall without evaluating how these updates affect downstream reasoning. In this work, we introduce TRACK (Testing Reasoning Amid Conflicting Knowledge), a new benchmark for studying how LLMs propagate new knowledge through multi-step reasoning when it conflicts with the model's initial parametric knowledge. Spanning three reasoning-intensive scenarios (WIKI, CODE, and MATH), TRACK introduces multiple, realistic conflicts to mirror real-world complexity. Our results on TRACK reveal that providing updated facts to models for reasoning can worsen performance compared to providing no updated facts to a model, and that this performance degradation exacerbates as more updated facts are provided. We show this failure stems from both inability to faithfully integrate updated facts, but also flawed reasoning even when knowledge is integrated. TRACK provides a rigorous new benchmark to measure and guide future progress on propagating conflicting knowledge in multi-step reasoning.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在多步推理中如何处理冲突知识的传播问题，特别是在知识更新未能覆盖模型参数化知识(Parametric Knowledge)时引发的推理故障。作者引入了名为TRACK(Testing Reasoning Amid Conflicting Knowledge)的新基准，涵盖WIKI、CODE和MATH三个推理密集型场景，通过引入多重、真实的知识冲突来模拟现实复杂性。实验结果显示，向模型提供更新事实后的推理性能有时甚至低于不提供任何更新事实的情况，且这种性能退化会随着更新事实数量的增加而进一步加剧。研究揭示了这种失败源于模型无法忠实地整合更新事实，以及即便在知识成功整合后仍会出现推理逻辑缺陷。TRACK基准为衡量和指导未来在多步推理中处理冲突知识的研究提供了严谨的评估工具。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to EACL 2026 (Main)",
      "pdf_url": "https://arxiv.org/pdf/2601.15495v1",
      "published_date": "2026-01-21 21:56:35 UTC",
      "updated_date": "2026-01-21 21:56:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:31:54.757055+00:00"
    },
    {
      "arxiv_id": "2601.15488v1",
      "title": "Multi-Persona Thinking for Bias Mitigation in Large Language Models",
      "title_zh": "用于大语言模型偏见缓解的多角色思维",
      "authors": [
        "Yuxing Chen",
        "Guoqing Luo",
        "Zijun Wu",
        "Lili Mou"
      ],
      "abstract": "Large Language Models (LLMs) exhibit significant social biases that can perpetuate harmful stereotypes and unfair outcomes. In this paper, we propose Multi-Persona Thinking (MPT), a novel inference-time framework that leverages dialectical reasoning from multiple perspectives to reduce bias. MPT guides models to adopt contrasting social identities (e.g., male and female) along with a neutral viewpoint, and then engages these personas iteratively to expose and correct biases. Through a dialectical reasoning process, the framework transforms the potential weakness of persona assignment into a strength for bias mitigation. We evaluate MPT on two widely used bias benchmarks across both open-source and closed-source models of varying scales. Our results demonstrate substantial improvements over existing prompting-based strategies: MPT achieves the lowest bias while maintaining core reasoning ability.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 中存在的社会偏见问题，提出了一种名为 Multi-Persona Thinking (MPT) 的新型推理阶段框架。MPT 通过利用来自多个视角的辩证推理 (dialectical reasoning) 来减少偏见，引导模型同时采纳对比鲜明的社会身份（如男性和女性）以及一个中立观点。该框架通过迭代地调用这些 persona，在交互过程中暴露并纠正潜在的偏见，将身份分配的潜在弱点转化为缓解偏见的优势。研究者在不同规模的开源和闭源模型上，利用两个广泛使用的偏见基准测试对 MPT 进行了评估。实验结果表明，MPT 在保持核心推理能力的同时，其表现显著优于现有的基于提示 (prompting-based) 的策略，并成功实现了最低的偏见水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.15488v1",
      "published_date": "2026-01-21 21:40:58 UTC",
      "updated_date": "2026-01-21 21:40:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:32:12.081229+00:00"
    },
    {
      "arxiv_id": "2601.15487v1",
      "title": "MiRAGE: A Multiagent Framework for Generating Multimodal Multihop Question-Answer Dataset for RAG Evaluation",
      "title_zh": "MiRAGE：用于 RAG 评估的多模态多跳问答数据集生成多智能体框架",
      "authors": [
        "Chandan Kumar Sahu",
        "Premith Kumar Chilukuri",
        "Matthew Hetrich"
      ],
      "abstract": "The rapid evolution of Retrieval-Augmented Generation (RAG) toward multimodal, high-stakes enterprise applications has outpaced the development of domain specific evaluation benchmarks. Existing datasets often rely on general-domain corpora or purely textual retrieval, failing to capture the complexity of specialized technical documents where information is inextricably multimodal and reasoning requires synthesizing disjoint evidence. We address this gap by introducing MiRAGE, a Multiagent framework for RAG systems Evaluation, that leverages a collaborative swarm of specialized agents to generate verified, domain-specific, multimodal, and multi-hop Question-Answer datasets. MiRAGE orchestrates a swarm of specialized agents: a recursive context optimization loop to aggregate scattered evidence, an adversarial verifier agent to guarantee factual grounding, and an agent to recognize the expert persona and the relevant domain to mimic expert cognitive workflows. Extensive empirical evaluation across four distinct domains (regulations, finance, quantitative biology, and journalism) demonstrates that MiRAGE generates datasets with significantly higher reasoning complexity (>2.3 average hops) and factual faithfulness. Our ablation studies point that MiRAGE can be powered by LLMs if textual descriptions of the images are available. Visual grounding still remains a frontier. By automating the creation of gold standard evaluation datasets that reflect the latent thematic structure of proprietary corpora, MiRAGE provides the necessary infrastructure to rigorously benchmark the next generation information retrieval systems.",
      "tldr_zh": "针对多模态检索增强生成(RAG)系统在处理复杂技术文档时缺乏领域特定评估基准的问题，该研究提出了 MiRAGE 框架。MiRAGE 是一种基于多智能体(Multiagent)协作的系统，旨在生成经过验证的、跨领域的多模态多跳(Multimodal Multihop)问答数据集。该框架通过递归上下文优化循环(Recursive Context Optimization Loop)聚合分散证据，利用对抗验证智能体(Adversarial Verifier Agent)确保事实的可靠性，并结合专家角色模拟(Expert Persona)来还原专业的认知工作流。在法规、金融、定量生物学和新闻四个领域的实验表明，MiRAGE 生成的数据集在推理复杂度（平均超过 2.3 跳）和事实忠实度方面显著优于现有基准。消减实验进一步揭示了视觉基元(Visual Grounding)仍是当前技术的挑战，但 MiRAGE 通过自动化构建金标准评估数据集，为下一代信息检索系统的严谨基准测试提供了关键基础设施。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 2 figures, Submitted to ACL",
      "pdf_url": "https://arxiv.org/pdf/2601.15487v1",
      "published_date": "2026-01-21 21:39:09 UTC",
      "updated_date": "2026-01-21 21:39:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:32:07.211498+00:00"
    },
    {
      "arxiv_id": "2601.15485v1",
      "title": "The Rise of Large Language Models and the Direction and Impact of US Federal Research Funding",
      "title_zh": "大语言模型的兴起与美国联邦科研资助的导向及影响",
      "authors": [
        "Yifan Qian",
        "Zhe Wen",
        "Alexander C. Furnas",
        "Yue Bai",
        "Erzhuo Shao",
        "Dashun Wang"
      ],
      "abstract": "Federal research funding shapes the direction, diversity, and impact of the US scientific enterprise. Large language models (LLMs) are rapidly diffusing into scientific practice, holding substantial promise while raising widespread concerns. Despite growing attention to AI use in scientific writing and evaluation, little is known about how the rise of LLMs is reshaping the public funding landscape. Here, we examine LLM involvement at key stages of the federal funding pipeline by combining two complementary data sources: confidential National Science Foundation (NSF) and National Institutes of Health (NIH) proposal submissions from two large US R1 universities, including funded, unfunded, and pending proposals, and the full population of publicly released NSF and NIH awards. We find that LLM use rises sharply beginning in 2023 and exhibits a bimodal distribution, indicating a clear split between minimal and substantive use. Across both private submissions and public awards, higher LLM involvement is consistently associated with lower semantic distinctiveness, positioning projects closer to recently funded work within the same agency. The consequences of this shift are agency-dependent. LLM use is positively associated with proposal success and higher subsequent publication output at NIH, whereas no comparable associations are observed at NSF. Notably, the productivity gains at NIH are concentrated in non-hit papers rather than the most highly cited work. Together, these findings provide large-scale evidence that the rise of LLMs is reshaping how scientific ideas are positioned, selected, and translated into publicly funded research, with implications for portfolio governance, research diversity, and the long-run impact of science.",
      "tldr_zh": "该研究探讨了大语言模型(Large Language Models)的兴起对美国联邦研究资助方向和影响。研究者结合两所R1大学提交给美国国家科学基金会(NSF)和国立卫生研究院(NIH)的机密提案以及公开的资助数据，分析了LLMs在资助申请和评审阶段的渗透情况。研究发现，自2023年起LLMs的使用量急剧增加并呈现双峰分布(bimodal distribution)，且高参与度通常导致提案的语义独特性(semantic distinctiveness)降低，使其内容更趋近于近期已获资助的项目。LLMs对资助结果的影响因机构而异，在NIH中LLMs的使用与更高的获批率及后续产出正相关，而在NSF则无此关联。此外，NIH的产出增长主要集中在非热门论文(non-hit papers)而非高被引工作。这些发现为LLMs如何重塑科学思想的定位、选择和转化提供了大规模证据，并揭示了其对研究多样性和长期科学影响的潜在挑战。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY",
        "physics.soc-ph"
      ],
      "primary_category": "cs.DL",
      "comment": "41 pages, 23 figures, 12 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.15485v1",
      "published_date": "2026-01-21 21:37:08 UTC",
      "updated_date": "2026-01-21 21:37:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:32:44.575255+00:00"
    },
    {
      "arxiv_id": "2601.15484v1",
      "title": "Is Grokipedia Right-Leaning? Comparing Political Framing in Wikipedia and Grokipedia on Controversial Topics",
      "title_zh": "Grokipedia 是否右倾？对比 Wikipedia 与 Grokipedia 在争议性话题上的政治框架",
      "authors": [
        "Philipp Eibl",
        "Erica Coppolillo",
        "Simone Mungari",
        "Luca Luceri"
      ],
      "abstract": "Online encyclopedias are central to contemporary information infrastructures and have become focal points of debates over ideological bias. Wikipedia, in particular, has long been accused of left-leaning bias, while Grokipedia, an AI-generated encyclopedia launched by xAI, has been framed as a right-leaning alternative. This paper presents a comparative analysis of Wikipedia and Grokipedia on well-established politically contested topics. Specifically, we examine differences in semantic framing, political orientation, and content prioritization. We find that semantic similarity between the two platforms decays across article sections and diverges more strongly on controversial topics than on randomly sampled ones. Additionally, we show that both encyclopedias predominantly exhibit left-leaning framings, although Grokipedia exhibits a more bimodal distribution with increased prominence of right-leaning content. The experimental code is publicly available.",
      "tldr_zh": "这项研究对 Wikipedia 和由 xAI 推出的 AI 生成百科全书 Grokipedia 在政治争议话题上的语义框架 (semantic framing)、政治倾向和内容优先级进行了比较分析。研究旨在探究 Wikipedia 的左倾偏见指控与 Grokipedia 作为右倾替代方案的实际表现差异。研究发现两个平台间的语义相似度 (semantic similarity) 随着文章章节逐渐衰减，且在争议性话题上的分歧比随机采样话题更为显著。实验结果表明，尽管两个百科全书都主要表现出左倾框架，但 Grokipedia 展现出更明显的双峰分布 (bimodal distribution)，其右倾内容的显著性有所增加。该研究揭示了 AI 生成内容在处理政治敏感议题时的意识形态分布特征，并为理解数字基础设施的偏见提供了实证数据。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15484v1",
      "published_date": "2026-01-21 21:36:12 UTC",
      "updated_date": "2026-01-21 21:36:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:32:37.066041+00:00"
    },
    {
      "arxiv_id": "2601.15482v1",
      "title": "Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding",
      "title_zh": "鞅前瞻采样：一种大语言模型推理时解码的原理性方法",
      "authors": [
        "Huayu Li",
        "ZhengXiao He",
        "Siyuan Tian",
        "Jinghao Wen",
        "Ao Li"
      ],
      "abstract": "Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 标准自回归解码因逐字生成而导致的短视问题，提出了 Martingale Foresight Sampling (MFS) 这一具有理论基础的框架。MFS 将解码过程建模为寻找最优随机过程的问题，利用 Martingale 理论取代了传统的启发式路径估值和剪枝策略。该框架利用 Doob Decomposition Theorem 衡量路径的可预测优势以进行步骤评估，结合 Optional Stopping Theory 实现对次优候选路径的原则性剪枝，并利用 Martingale Convergence Theorem 建立了自适应停止规则。实验结果表明，MFS 在六项推理基准测试中的准确率显著超过了现有先进方法，同时大幅提升了计算效率。这一研究为推断时 (inference-time) 解码提供了一种具备概率论保障的系统性策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15482v1",
      "published_date": "2026-01-21 21:34:29 UTC",
      "updated_date": "2026-01-21 21:34:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:32:38.180142+00:00"
    },
    {
      "arxiv_id": "2601.15479v1",
      "title": "Benchmarking LLMs for Pairwise Causal Discovery in Biomedical and Multi-Domain Contexts",
      "title_zh": "面向生物医学及多领域语境的大语言模型成对因果发现基准测试",
      "authors": [
        "Sydney Anuyah",
        "Sneha Shajee-Mohan",
        "Ankit-Singh Chauhan",
        "Sunandan Chakraborty"
      ],
      "abstract": "The safe deployment of large language models (LLMs) in high-stakes fields like biomedicine, requires them to be able to reason about cause and effect. We investigate this ability by testing 13 open-source LLMs on a fundamental task: pairwise causal discovery (PCD) from text. Our benchmark, using 12 diverse datasets, evaluates two core skills: 1) \\textbf{Causal Detection} (identifying if a text contains a causal link) and 2) \\textbf{Causal Extraction} (pulling out the exact cause and effect phrases). We tested various prompting methods, from simple instructions (zero-shot) to more complex strategies like Chain-of-Thought (CoT) and Few-shot In-Context Learning (FICL).\n  The results show major deficiencies in current models. The best model for detection, DeepSeek-R1-Distill-Llama-70B, only achieved a mean score of 49.57\\% ($C_{detect}$), while the best for extraction, Qwen2.5-Coder-32B-Instruct, reached just 47.12\\% ($C_{extract}$). Models performed best on simple, explicit, single-sentence relations. However, performance plummeted for more difficult (and realistic) cases, such as implicit relationships, links spanning multiple sentences, and texts containing multiple causal pairs. We provide a unified evaluation framework, built on a dataset validated with high inter-annotator agreement ($κ\\ge 0.758$), and make all our data, code, and prompts publicly available to spur further research. \\href{https://github.com/sydneyanuyah/CausalDiscovery}{Code available here: https://github.com/sydneyanuyah/CausalDiscovery}",
      "tldr_zh": "该研究评估了13个开源大语言模型(LLMs)在生物医学和多领域背景下的成对因果发现(Pairwise Causal Discovery, PCD)能力。通过12个多样化数据集构建的基准测试，研究重点考察了因果检测(Causal Detection)和因果提取(Causal Extraction)两项核心技能，并测试了Zero-shot、Chain-of-Thought (CoT)以及Few-shot In-Context Learning (FICL)等多种提示策略。实验结果显示现有模型在因果推理方面存在显著不足，其中DeepSeek-R1-Distill-Llama-70B在检测任务中得分最高（49.57%），而Qwen2.5-Coder-32B-Instruct在提取任务中表现最佳（47.12%）。模型在处理简单的显性单句关系时表现尚可，但在隐性关系、跨句逻辑以及多因果对等现实且复杂的场景下性能大幅下降。该研究提供了一个基于高一致性标注数据集的统一评估框架，并公开了代码、数据集和提示词以推动因果推理领域的后续研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15479v1",
      "published_date": "2026-01-21 21:29:46 UTC",
      "updated_date": "2026-01-21 21:29:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:32:44.122670+00:00"
    },
    {
      "arxiv_id": "2601.15476v1",
      "title": "Reliability by design: quantifying and eliminating fabrication risk in LLMs. From generative to consultative AI: a comparative analysis in the legal domain and lessons for high-stakes knowledge bases",
      "title_zh": "设计保障可靠性：量化与消除大语言模型中的编造风险。从生成式到咨询式人工智能：法律领域的对比分析及对高风险知识库的启示",
      "authors": [
        "Alex Dantart"
      ],
      "abstract": "This paper examines how to make large language models reliable for high-stakes legal work by reducing hallucinations. It distinguishes three AI paradigms: (1) standalone generative models (\"creative oracle\"), (2) basic retrieval-augmented systems (\"expert archivist\"), and (3) an advanced, end-to-end optimized RAG system (\"rigorous archivist\"). The authors introduce two reliability metrics -False Citation Rate (FCR) and Fabricated Fact Rate (FFR)- and evaluate 2,700 judicial-style answers from 12 LLMs across 75 legal tasks using expert, double-blind review. Results show that standalone models are unsuitable for professional use (FCR above 30%), while basic RAG greatly reduces errors but still leaves notable misgrounding. Advanced RAG, using techniques such as embedding fine-tuning, re-ranking, and self-correction, reduces fabrication to negligible levels (below 0.2%). The study concludes that trustworthy legal AI requires rigor-focused, retrieval-based architectures emphasizing verification and traceability, and provides an evaluation framework applicable to other high-risk domains.",
      "tldr_zh": "该研究探讨了如何通过减少幻觉(hallucinations)使大语言模型(LLMs)在法律等高风险领域达到专业可靠性。作者对比了独立生成模型、基础检索增强生成(RAG)系统以及进阶RAG系统三种范式，并引入错误引用率(FCR)和虚假事实率(FFR)作为核心可靠性指标。通过对12个模型在75项法律任务中的2,700个回答进行专家双盲评审，研究发现独立生成模型的FCR超过30%，无法满足专业办公需求。而进阶RAG系统利用嵌入微调(embedding fine-tuning)、重排序(re-ranking)和自我修正(self-correction)等技术，将虚假事实率降低至0.2%以下的极低水平。研究结论指出，构建可信的法律AI必须依赖强调验证与可追溯性的检索架构，并为其他高风险领域的知识库建设提供了标准化的评估框架。",
      "categories": [
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15476v1",
      "published_date": "2026-01-21 21:26:42 UTC",
      "updated_date": "2026-01-21 21:26:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:33:36.385032+00:00"
    },
    {
      "arxiv_id": "2601.15474v1",
      "title": "Multi-Targeted Graph Backdoor Attack",
      "title_zh": "多目标图后门攻击",
      "authors": [
        "Md Nabi Newaz Khan",
        "Abdullah Arafat Miah",
        "Yu Bi"
      ],
      "abstract": "Graph neural network (GNN) have demonstrated exceptional performance in solving critical problems across diverse domains yet remain susceptible to backdoor attacks. Existing studies on backdoor attack for graph classification are limited to single target attack using subgraph replacement based mechanism where the attacker implants only one trigger into the GNN model. In this paper, we introduce the first multi-targeted backdoor attack for graph classification task, where multiple triggers simultaneously redirect predictions to different target labels. Instead of subgraph replacement, we propose subgraph injection which preserves the structure of the original graphs while poisoning the clean graphs. Extensive experiments demonstrate the efficacy of our approach, where our attack achieves high attack success rates for all target labels with minimal impact on the clean accuracy. Experimental results on five dataset demonstrate the superior performance of our attack framework compared to the conventional subgraph replacement-based attack. Our analysis on four GNN models confirms the generalization capability of our attack which is effective regardless of the GNN model architectures and training parameters settings. We further investigate the impact of the attack design parameters including injection methods, number of connections, trigger sizes, trigger edge density and poisoning ratios. Additionally, our evaluation against state-of-the-art defenses (randomized smoothing and fine-pruning) demonstrates the robustness of our proposed multi-target attacks. This work highlights the GNN vulnerability against multi-targeted backdoor attack in graph classification task. Our source codes will be available at https://github.com/SiSL-URI/Multi-Targeted-Graph-Backdoor-Attack.",
      "tldr_zh": "该研究针对图神经网络(GNN)在图分类任务中的后门攻击(Backdoor Attack)漏洞，指出目前的攻击多局限于基于子图替换(Subgraph Replacement)的单目标攻击。论文提出了首个多目标图后门攻击框架，允许通过多个触发器(Triggers)将预测结果同时重定向到不同的目标标签。该方法创新性地采用子图注入(Subgraph Injection)技术，在向干净图植入毒素的同时能够更好地保留原始图的结构信息。通过在五个数据集和四种GNN模型架构上的实验验证，该攻击在保证极高攻击成功率的同时，对原始分类准确率的影响极小，展现了出色的泛化能力。研究还深入探讨了注入方式、触发器密度和投毒比例等关键参数的影响，并证实该攻击在面对Randomized Smoothing和Fine-pruning等主流防御手段时依然具有较强的鲁棒性。该工作揭示了GNN在多目标后门攻击面前的严重脆弱性，为构建更安全的图学习算法提供了重要依据。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15474v1",
      "published_date": "2026-01-21 21:23:51 UTC",
      "updated_date": "2026-01-21 21:23:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:33:37.281580+00:00"
    },
    {
      "arxiv_id": "2601.15473v1",
      "title": "Panther: Faster and Cheaper Computations with Randomized Numerical Linear Algebra",
      "title_zh": "Panther：基于随机化数值线性代数的高效低成本计算",
      "authors": [
        "Fahd Seddik",
        "Abdulrahman Elbedewy",
        "Gaser Sami",
        "Mohamed Abdelmoniem",
        "Yahia Zakaria"
      ],
      "abstract": "Training modern deep learning models is increasingly constrained by GPU memory and compute limits. While Randomized Numerical Linear Algebra (RandNLA) offers proven techniques to compress these models, the lack of a unified, production-grade library prevents widely adopting these methods. We present Panther, a PyTorch-compatible library that consolidates established RandNLA algorithms into a single high-performance framework. Panther engineers efficient, drop-in replacements for standard components including sketched linear layers, 2D convolution, multi-head attention, and randomized matrix decompositions (such as pivoted CholeskyQR). By implementing a custom C++/CUDA backend (pawX), Panther provides an optimized implementation that can run on both CPUs and GPUs. We demonstrate the effectiveness of RandNLA techniques and Panther's ease of adoption. By replacing standard PyTorch linear layers with Panther layers (requiring only a few lines of code) we achieve significant memory savings (up to 75%) on BERT while maintaining comparable loss. Source code is available (MIT License) at https://github.com/FahdSeddik/panther, along with demonstration video at https://youtu.be/7M3RQb4KWxs.",
      "tldr_zh": "该研究推出了 Panther，一个与 PyTorch 兼容的高性能库，旨在通过随机数值线性代数 (RandNLA) 技术解决深度学习模型训练中的 GPU 内存和计算限制。Panther 整合了成熟的 RandNLA 算法，为 sketched linear layers、2D convolution、multi-head attention 和 randomized matrix decompositions 等标准组件提供了高效的即插即用替代方案。该库利用自定义的 C++/CUDA 后端 (pawX) 实现了针对 CPU 和 GPU 的底层优化，确保了卓越的运行性能。实验结果表明，在 BERT 模型中仅需少量代码修改，即可在保持模型精度基本不变的前提下实现高达 75% 的内存节省。目前 Panther 已基于 MIT License 开源，为在大规模生产环境中普及 RandNLA 技术提供了重要的基础设施支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 3 figures, 2 listings",
      "pdf_url": "https://arxiv.org/pdf/2601.15473v1",
      "published_date": "2026-01-21 21:23:00 UTC",
      "updated_date": "2026-01-21 21:23:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:33:29.237138+00:00"
    },
    {
      "arxiv_id": "2601.15457v1",
      "title": "Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering",
      "title_zh": "分块、检索与重排序：面向政策文档问答的 RAG 架构实证评估",
      "authors": [
        "Anuj Maharjan",
        "Umesh Yadav"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into the public health policy sector offers a transformative approach to navigating the vast repositories of regulatory guidance maintained by agencies such as the Centers for Disease Control and Prevention (CDC). However, the propensity for LLMs to generate hallucinations, defined as plausible but factually incorrect assertions, presents a critical barrier to the adoption of these technologies in high-stakes environments where information integrity is non-negotiable. This empirical evaluation explores the effectiveness of Retrieval-Augmented Generation (RAG) architectures in mitigating these risks by grounding generative outputs in authoritative document context. Specifically, this study compares a baseline Vanilla LLM against Basic RAG and Advanced RAG pipelines utilizing cross-encoder re-ranking. The experimental framework employs a Mistral-7B-Instruct-v0.2 model and an all-MiniLM-L6-v2 embedding model to process a corpus of official CDC policy analytical frameworks and guidance documents. The analysis measures the impact of two distinct chunking strategies, recursive character-based and token-based semantic splitting, on system accuracy, measured through faithfulness and relevance scores across a curated set of complex policy scenarios. Quantitative findings indicate that while Basic RAG architectures provide a substantial improvement in faithfulness (0.621) over Vanilla baselines (0.347), the Advanced RAG configuration achieves a superior faithfulness average of 0.797. These results demonstrate that two-stage retrieval mechanisms are essential for achieving the precision required for domain-specific policy question answering, though structural constraints in document segmentation remain a significant bottleneck for multi-step reasoning tasks.",
      "tldr_zh": "该研究针对Large Language Models (LLMs)在公共卫生政策文件问答中容易产生幻觉的问题，实证评估了Retrieval-Augmented Generation (RAG)架构在保障信息完整性方面的有效性。实验对比了Vanilla LLM、Basic RAG以及采用cross-encoder re-ranking技术的Advanced RAG，并利用Mistral-7B-Instruct-v0.2和all-MiniLM-L6-v2模型处理CDC官方政策文档。研究重点分析了recursive character-based与token-based semantic splitting两种分块(chunking)策略对系统忠实度(faithfulness)和相关性的影响。定量结果显示，Basic RAG将忠实度从Vanilla基线的0.347提升至0.621，而Advanced RAG则进一步达到了0.797的优异表现。研究证明两阶段检索机制对于实现特定领域政策问答所需的精度至关重要。尽管架构优化显著提升了性能，但文档切分的结构性限制仍是多步推理任务中的主要瓶颈。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15457v1",
      "published_date": "2026-01-21 20:52:48 UTC",
      "updated_date": "2026-01-21 20:52:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:33:07.445382+00:00"
    },
    {
      "arxiv_id": "2601.15445v1",
      "title": "Reflexis: Supporting Reflexivity and Rigor in Collaborative Qualitative Analysis through Design for Deliberation",
      "title_zh": "Reflexis：通过审议式设计支持协作定性分析中的自反性与严谨性",
      "authors": [
        "Runlong Ye",
        "Oliver Huang",
        "Patrick Yung Kang Lee",
        "Michael Liut",
        "Carolina Nobre",
        "Ha-Kyung Kong"
      ],
      "abstract": "Reflexive Thematic Analysis (RTA) is a critical method for generating deep interpretive insights. Yet its core tenets, including researcher reflexivity, tangible analytical evolution, and productive disagreement, are often poorly supported by software tools that prioritize speed and consensus over interpretive depth. To address this gap, we introduce Reflexis, a collaborative workspace that centers these practices. It supports reflexivity by integrating in-situ reflection prompts, makes code evolution transparent and tangible, and scaffolds collaborative interpretation by turning differences into productive, positionality-aware dialogue. Results from our paired-analyst study (N=12) indicate that Reflexis encouraged participants toward more granular reflection and reframed disagreements as productive conversations. The evaluation also surfaced key design tensions, including a desire for higher-level, networked memos and more user control over the timing of proactive alerts. Reflexis contributes a design framework for tools that prioritize rigor and transparency to support deep, collaborative interpretation in an age of automation.",
      "tldr_zh": "该研究推出了Reflexis，这是一个旨在支持协作定性分析中反思性（Reflexivity）与严谨性的协作工作空间，以解决现有工具过度追求效率而忽视解释深度的问题。Reflexis 专注于支持反思性主题分析（Reflexive Thematic Analysis, RTA），通过集成原位反思提示（in-situ reflection prompts）并使代码演变透明化，强化了研究者的反思过程。该系统还通过将观点差异转化为具有立场意识（positionality-aware）的对话，为协作解释提供了支架。针对12名分析师的配对研究表明，Reflexis 能有效促进更细致的反思，并将协作中的分歧重构为建设性的对话。尽管评价中也反映出用户对高层级备忘录和提醒控制权的特定需求，但该研究为自动化时代下如何通过设计保障定性分析的严谨性与透明度提供了重要框架。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at CHI 26",
      "pdf_url": "https://arxiv.org/pdf/2601.15445v1",
      "published_date": "2026-01-21 20:24:39 UTC",
      "updated_date": "2026-01-21 20:24:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:33:06.500322+00:00"
    },
    {
      "arxiv_id": "2601.15442v1",
      "title": "A tensor network formalism for neuro-symbolic AI",
      "title_zh": "神经符号人工智能的张量网络形式化体系",
      "authors": [
        "Alex Goessmann",
        "Janina Schütte",
        "Maximilian Fröhlich",
        "Martin Eigel"
      ],
      "abstract": "The unification of neural and symbolic approaches to artificial intelligence remains a central open challenge. In this work, we introduce a tensor network formalism, which captures sparsity principles originating in the different approaches in tensor decompositions. In particular, we describe a basis encoding scheme for functions and model neural decompositions as tensor decompositions. The proposed formalism can be applied to represent logical formulas and probability distributions as structured tensor decompositions. This unified treatment identifies tensor network contractions as a fundamental inference class and formulates efficiently scaling reasoning algorithms, originating from probability theory and propositional logic, as contraction message passing schemes. The framework enables the definition and training of hybrid logical and probabilistic models, which we call Hybrid Logic Network. The theoretical concepts are accompanied by the python library tnreason, which enables the implementation and practical use of the proposed architectures.",
      "tldr_zh": "该研究提出了一种用于神经符号人工智能(Neuro-symbolic AI)的张量网络(Tensor network)形式化方法，旨在统一神经与符号两种人工智能路径。该框架通过基础编码方案和将神经分解(Neural decompositions)视为张量分解，有效捕捉了不同领域中的稀疏性原则。它能将逻辑公式和概率分布统一表示为结构化张量分解，并将张量网络收缩(Tensor network contractions)识别为核心推理机制。通过将概率论和命题逻辑中的推理算法转化为收缩消息传递方案，该研究实现了高效的计算缩放。此外，框架定义并支持训练一种新型的混合逻辑网络(Hybrid Logic Network)，结合了逻辑与概率建模的优势。最后，研究者提供了配套的Python库tnreason，为该架构的实际部署和应用提供了技术支撑。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "math.NA",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "51 pages, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.15442v1",
      "published_date": "2026-01-21 20:20:31 UTC",
      "updated_date": "2026-01-21 20:20:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:33:28.873375+00:00"
    },
    {
      "arxiv_id": "2601.15436v1",
      "title": "Not Your Typical Sycophant: The Elusive Nature of Sycophancy in Large Language Models",
      "title_zh": "并非典型的“谄媚者”：大语言模型中谄媚行为的难以捉摸性",
      "authors": [
        "Shahar Ben Natan",
        "Oren Tsur"
      ],
      "abstract": "We propose a novel way to evaluate sycophancy of LLMs in a direct and neutral way, mitigating various forms of uncontrolled bias, noise, or manipulative language, deliberately injected to prompts in prior works. A key novelty in our approach is the use of LLM-as-a-judge, evaluation of sycophancy as a zero-sum game in a bet setting. Under this framework, sycophancy serves one individual (the user) while explicitly incurring cost on another. Comparing four leading models - Gemini 2.5 Pro, ChatGpt 4o, Mistral-Large-Instruct-2411, and Claude Sonnet 3.7 - we find that while all models exhibit sycophantic tendencies in the common setting, in which sycophancy is self-serving to the user and incurs no cost on others, Claude and Mistral exhibit \"moral remorse\" and over-compensate for their sycophancy in case it explicitly harms a third party. Additionally, we observed that all models are biased toward the answer proposed last. Crucially, we find that these two phenomena are not independent; sycophancy and recency bias interact to produce `constructive interference' effect, where the tendency to agree with the user is exacerbated when the user's opinion is presented last.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）中复杂的阿谀奉承（Sycophancy）现象，并提出了一种基于LLM-as-a-judge的新型评估方法，通过零和博弈的赌博设定（bet setting）来减少提示词中的偏见和噪声。在对比Gemini 2.5 Pro、ChatGPT 4o、Mistral-Large-Instruct-2411和Claude Sonnet 3.7四款领先模型后发现，虽然所有模型在不涉及外部成本时均表现出Sycophancy倾向，但Claude和Mistral在明确涉及伤害第三方时会表现出“道德悔恨”（moral remorse）并产生过度补偿行为。此外，研究识别出模型普遍存在向最后出现的答案倾斜的近因偏差（Recency Bias）。关键发现表明，Sycophancy与Recency Bias之间存在“相长干涉”（constructive interference）效应，即当用户的意见被放置在提示词最后时，模型迎合用户的倾向会显著加剧。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15436v1",
      "published_date": "2026-01-21 20:00:14 UTC",
      "updated_date": "2026-01-21 20:00:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:34:49.868653+00:00"
    },
    {
      "arxiv_id": "2601.15417v1",
      "title": "Ambient Dataloops: Generative Models for Dataset Refinement",
      "title_zh": "Ambient Dataloops：用于数据集精炼的生成模型",
      "authors": [
        "Adrián Rodríguez-Muñoz",
        "William Daspit",
        "Adam Klivans",
        "Antonio Torralba",
        "Constantinos Daskalakis",
        "Giannis Daras"
      ],
      "abstract": "We propose Ambient Dataloops, an iterative framework for refining datasets that makes it easier for diffusion models to learn the underlying data distribution. Modern datasets contain samples of highly varying quality, and training directly on such heterogeneous data often yields suboptimal models. We propose a dataset-model co-evolution process; at each iteration of our method, the dataset becomes progressively higher quality, and the model improves accordingly. To avoid destructive self-consuming loops, at each generation, we treat the synthetically improved samples as noisy, but at a slightly lower noisy level than the previous iteration, and we use Ambient Diffusion techniques for learning under corruption. Empirically, Ambient Dataloops achieve state-of-the-art performance in unconditional and text-conditional image generation and de novo protein design. We further provide a theoretical justification for the proposed framework that captures the benefits of the data looping procedure.",
      "tldr_zh": "该研究提出了 Ambient Dataloops，这是一个用于优化数据集的迭代框架，旨在降低 Diffusion Models 学习底层数据分布的难度。针对现代数据集质量参差不齐导致模型效果不佳的问题，该框架建立了一个数据集与模型的协同演化过程，使数据集质量与模型性能在迭代中同步提升。为了避免生成模型中常见的破坏性自食循环（self-consuming loops），该方法在每一轮生成中将合成改进的样本视为带噪样本，并采用 Ambient Diffusion 技术在噪声水平逐次降低的过程中进行受损数据学习。实验证明，Ambient Dataloops 在无条件和文本条件 Image Generation 以及 De novo protein design 领域均取得了 SOTA 性能。此外，该研究还为这种数据循环流程提供了理论证明，阐述了其在提升生成模型表现方面的核心优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 9 figures, 11 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.15417v1",
      "published_date": "2026-01-21 19:29:04 UTC",
      "updated_date": "2026-01-21 19:29:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:34:33.906543+00:00"
    },
    {
      "arxiv_id": "2601.15416v1",
      "title": "DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction",
      "title_zh": "DuFal：面向高保真极稀疏视图CBCT重建的双频率感知学习",
      "authors": [
        "Cuong Tran Van",
        "Trong-Thang Pham",
        "Ngoc-Son Nguyen",
        "Duy Minh Ho Nguyen",
        "Ngan Le"
      ],
      "abstract": "Sparse-view Cone-Beam Computed Tomography reconstruction from limited X-ray projections remains a challenging problem in medical imaging due to the inherent undersampling of fine-grained anatomical details, which correspond to high-frequency components. Conventional CNN-based methods often struggle to recover these fine structures, as they are typically biased toward learning low-frequency information. To address this challenge, this paper presents DuFal (Dual-Frequency-Aware Learning), a novel framework that integrates frequency-domain and spatial-domain processing via a dual-path architecture. The core innovation lies in our High-Local Factorized Fourier Neural Operator, which comprises two complementary branches: a Global High-Frequency Enhanced Fourier Neural Operator that captures global frequency patterns and a Local High-Frequency Enhanced Fourier Neural Operator that processes spatially partitioned patches to preserve spatial locality that might be lost in global frequency analysis. To improve efficiency, we design a Spectral-Channel Factorization scheme that reduces the Fourier Neural Operator parameter count. We also design a Cross-Attention Frequency Fusion module to integrate spatial and frequency features effectively. The fused features are then decoded through a Feature Decoder to produce projection representations, which are subsequently processed through an Intensity Field Decoding pipeline to reconstruct a final Computed Tomography volume. Experimental results on the LUNA16 and ToothFairy datasets demonstrate that DuFal significantly outperforms existing state-of-the-art methods in preserving high-frequency anatomical features, particularly under extremely sparse-view settings.",
      "tldr_zh": "该研究针对极稀疏视图(Extremely sparse-view)设置下锥形束CT(CBCT)重建中高频精细解剖细节难以恢复的难题，提出了一种名为DuFal (Dual-Frequency-Aware Learning) 的双路径学习框架。该框架通过整合频域与空间域处理，引入了High-Local Factorized Fourier Neural Operator，利用全局和局部增强分支协同捕捉频率模式并保留空间局域性。为了提高模型效率，研究采用了Spectral-Channel Factorization方案降低参数量，并设计了Cross-Attention Frequency Fusion模块实现特征的有效集成。最终，融合特征通过强度场解码(Intensity Field Decoding)流程重建出高质量的CT体积。在LUNA16和ToothFairy数据集上的实验证明，DuFal在保留高频解剖特征方面显著优于现有的State-of-the-art方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published with J2C Certification in Transactions on Machine Learning Research (TMLR)",
      "pdf_url": "https://arxiv.org/pdf/2601.15416v1",
      "published_date": "2026-01-21 19:27:47 UTC",
      "updated_date": "2026-01-21 19:27:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:34:01.412961+00:00"
    },
    {
      "arxiv_id": "2601.15412v1",
      "title": "A Checklist for Trustworthy, Safe, and User-Friendly Mental Health Chatbots",
      "title_zh": "",
      "authors": [
        "Shreya Haran",
        "Samiha Thatikonda",
        "Dong Whi Yoo",
        "Koustuv Saha"
      ],
      "abstract": "Mental health concerns are rising globally, prompting increased reliance on technology to address the demand-supply gap in mental health services. In particular, mental health chatbots are emerging as a promising solution, but these remain largely untested, raising concerns about safety and potential harms. In this paper, we dive into the literature to identify critical gaps in the design and implementation of mental health chatbots. We contribute an operational checklist to help guide the development and design of more trustworthy, safe, and user-friendly chatbots. The checklist serves as both a developmental framework and an auditing tool to ensure ethical and effective chatbot design. We discuss how this checklist is a step towards supporting more responsible design practices and supporting new standards for sociotechnically sound digital mental health tools.",
      "tldr_zh": "",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15412v1",
      "published_date": "2026-01-21 19:24:27 UTC",
      "updated_date": "2026-01-21 19:24:27 UTC",
      "processing_status": "failed",
      "attempts": 3,
      "max_attempts": 3,
      "error": "Your request was blocked.",
      "completed_steps": [],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:58:47.999366+00:00"
    },
    {
      "arxiv_id": "2601.15408v1",
      "title": "CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation",
      "title_zh": "CURE：面向可靠解剖学定位报告生成的课程引导多任务训练",
      "authors": [
        "Pablo Messina",
        "Andrés Villa",
        "Juan León Alcázar",
        "Karen Sánchez",
        "Carlos Hinojosa",
        "Denis Parra",
        "Álvaro Soto",
        "Bernard Ghanem"
      ],
      "abstract": "Medical vision-language models can automate the generation of radiology reports but struggle with accurate visual grounding and factual consistency. Existing models often misalign textual findings with visual evidence, leading to unreliable or weakly grounded predictions. We present CURE, an error-aware curriculum learning framework that improves grounding and report quality without any additional data. CURE fine-tunes a multimodal instructional model on phrase grounding, grounded report generation, and anatomy-grounded report generation using public datasets. The method dynamically adjusts sampling based on model performance, emphasizing harder samples to improve spatial and textual alignment. CURE improves grounding accuracy by +0.37 IoU, boosts report quality by +0.188 CXRFEScore, and reduces hallucinations by 18.6%. CURE is a data-efficient framework that enhances both grounding accuracy and report reliability. Code is available at https://github.com/PabloMessina/CURE and model weights at https://huggingface.co/pamessina/medgemma-4b-it-cure",
      "tldr_zh": "该研究提出了CURE，一个具有错误感知能力的课程学习(Curriculum Learning)框架，旨在解决医学视觉语言模型在放射报告生成中面临的视觉定位(Visual Grounding)不准确和事实不一致等挑战。CURE在Phrase Grounding、Grounded Report Generation和Anatomy-grounded Report Generation等多项任务上对多模态指令模型进行微调，且无需任何额外数据。该框架通过根据模型表现动态调整采样权重，优先处理较难样本，从而有效增强了空间与文本的对齐性能。实验结果表明，CURE将定位准确度提高了0.37 IoU，放射报告质量提升了0.188 CXRFEScore，并将幻觉(Hallucinations)减少了18.6%。作为一个高效利用数据的框架，CURE显著提升了医疗影像报告生成的可靠性与定位精度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "31 pages, 7 figures, submitted to CVPR 2026 (under review)",
      "pdf_url": "https://arxiv.org/pdf/2601.15408v1",
      "published_date": "2026-01-21 19:19:41 UTC",
      "updated_date": "2026-01-21 19:19:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:34:05.975918+00:00"
    },
    {
      "arxiv_id": "2601.15397v1",
      "title": "Beyond Prompting: Efficient and Robust Contextual Biasing for Speech LLMs via Logit-Space Integration (LOGIC)",
      "title_zh": "超越提示：通过 Logit 空间集成（LOGIC）实现语音大语言模型的高效稳健上下文偏置",
      "authors": [
        "Peidong Wang"
      ],
      "abstract": "The rapid emergence of new entities -- driven by cultural shifts, evolving trends, and personalized user data -- poses a significant challenge for existing Speech Large Language Models (Speech LLMs). While these models excel at general conversational tasks, their static training knowledge limits their ability to recognize domain-specific terms such as contact names, playlists, or technical jargon. Existing solutions primarily rely on prompting, which suffers from poor scalability: as the entity list grows, prompting encounters context window limitations, increased inference latency, and the \"lost-in-the-middle\" phenomenon. An alternative approach, Generative Error Correction (GEC), attempts to rewrite transcripts via post-processing but frequently suffers from \"over-correction\", introducing hallucinations of entities that were never spoken.\n  In this work, we introduce LOGIC (Logit-Space Integration for Contextual Biasing), an efficient and robust framework that operates directly in the decoding layer. Unlike prompting, LOGIC decouples context injection from input processing, ensuring constant-time complexity relative to prompt length. Extensive experiments using the Phi-4-MM model across 11 multilingual locales demonstrate that LOGIC achieves an average 9% relative reduction in Entity WER with a negligible 0.30% increase in False Alarm Rate.",
      "tldr_zh": "该研究针对Speech LLMs在识别联系人姓名或技术术语等领域特定实体时存在的局限性，提出了LOGIC（Logit-Space Integration for Contextual Biasing）这一高效且鲁棒的框架。LOGIC直接在解码层（decoding layer）运行，通过将上下文注入与输入处理解耦，实现了相对于提示长度的常数级时间复杂度（constant-time complexity）。该方法有效克服了Prompting带来的推理延迟与上下文窗口限制，并解决了Generative Error Correction（GEC）中常见的过度纠错（over-correction）和幻觉问题。基于Phi-4-MM模型在11个多语言区域的实验证明，LOGIC实现了Entity WER平均相对降低9%，而False Alarm Rate仅略微增加0.30%。实验结果表明，LOGIC在保证推理效率的同时，显著增强了Speech LLMs对动态更新实体的识别准确性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15397v1",
      "published_date": "2026-01-21 19:08:45 UTC",
      "updated_date": "2026-01-21 19:08:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:34:42.494364+00:00"
    },
    {
      "arxiv_id": "2601.15395v1",
      "title": "Beyond Fixed Psychological Personas: State Beats Trait, but Language Models are State-Blind",
      "title_zh": "超越固定心理人格画像：状态优于特质，但语言模型表现出“状态盲”特性",
      "authors": [
        "Tamunotonye Harry",
        "Ivoline Ngong",
        "Chima Nweke",
        "Yuanyuan Feng",
        "Joseph Near"
      ],
      "abstract": "User interactions with language models vary due to static properties of the user (trait) and the specific context of the interaction (state). However, existing persona datasets (like PersonaChat, PANDORA etc.) capture only trait, and ignore the impact of state. We introduce Chameleon, a dataset of 5,001 contextual psychological profiles from 1,667 Reddit users, each measured across multiple contexts. Using the Chameleon dataset, we present three key findings. First, inspired by Latent State-Trait theory, we decompose variance and find that 74\\% is within-person(state) while only 26\\% is between-person (trait). Second, we find that LLMs are state-blind: they focus on trait only, and produce similar responses regardless of state. Third, we find that reward models react to user state, but inconsistently: different models favor or penalize the same users in opposite directions. We release Chameleon to support research on affective computing, personalized dialogue, and RLHF alignment.",
      "tldr_zh": "该研究探讨了用户与语言模型交互中静态属性(trait)与特定语境(state)的影响，指出当前人格数据集往往忽略了state的作用。研究者推出了Chameleon数据集，包含来自1,667名Reddit用户的5,001份跨语境心理档案。基于Latent State-Trait理论的方差分解显示，用户表现中74%的差异源于state，而trait仅占26%。然而，实验发现大语言模型(LLMs)表现出state-blind特性，过度关注trait而忽略语境变化，导致在不同state下生成相似响应。此外，奖励模型(reward models)对用户state的反应极不一致，不同模型对同一用户的评价倾向往往截然相反。该研究通过发布Chameleon数据集，旨在支持情感计算(affective computing)、个性化对话及RLHF alignment领域的后续研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15395v1",
      "published_date": "2026-01-21 19:06:50 UTC",
      "updated_date": "2026-01-21 19:06:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:34:44.226103+00:00"
    },
    {
      "arxiv_id": "2601.15392v1",
      "title": "GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation",
      "title_zh": "GeMM-GAN：一种基于组织病理学图像与临床描述的多模态基因表达谱生成模型",
      "authors": [
        "Francesca Pia Panaccione",
        "Carlo Sgaravatti",
        "Pietro Pinoli"
      ],
      "abstract": "Biomedical research increasingly relies on integrating diverse data modalities, including gene expression profiles, medical images, and clinical metadata. While medical images and clinical metadata are routinely collected in clinical practice, gene expression data presents unique challenges for widespread research use, mainly due to stringent privacy regulations and costly laboratory experiments. To address these limitations, we present GeMM-GAN, a novel Generative Adversarial Network conditioned on histopathology tissue slides and clinical metadata, designed to synthesize realistic gene expression profiles. GeMM-GAN combines a Transformer Encoder for image patches with a final Cross Attention mechanism between patches and text tokens, producing a conditioning vector to guide a generative model in generating biologically coherent gene expression profiles. We evaluate our approach on the TCGA dataset and demonstrate that our framework outperforms standard generative models and generates more realistic and functionally meaningful gene expression profiles, improving by more than 11\\% the accuracy on downstream disease type prediction compared to current state-of-the-art generative models. Code will be available at: https://github.com/francescapia/GeMM-GAN",
      "tldr_zh": "该研究提出了GeMM-GAN，一种以组织病理学切片和临床元数据为条件生成真实基因表达谱的新型生成对抗网络(GAN)，旨在解决基因表达数据因隐私监管和高昂成本而难以获取的问题。该模型结合了用于处理图像块的Transformer Encoder以及图像块与文本标记之间的交叉注意力机制(Cross Attention)，从而产生引导生成模型合成生物一致性基因表达谱的条件向量。在TCGA数据集上的评估结果表明，GeMM-GAN优于标准的生成模型，能够生成更具现实意义和功能性的基因表达谱。实验结果显示，该框架在下游疾病类型预测任务中的准确率比目前最先进(SOTA)的生成模型提高了11%以上，为生物医学研究中的多模态数据整合提供了有效的合成方案。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 2 figures. Published at Image Analysis and Processing - ICIAP 2025 Workshops",
      "pdf_url": "https://arxiv.org/pdf/2601.15392v1",
      "published_date": "2026-01-21 19:03:54 UTC",
      "updated_date": "2026-01-21 19:03:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:35:57.842659+00:00"
    },
    {
      "arxiv_id": "2601.15286v1",
      "title": "Iterative Refinement Improves Compositional Image Generation",
      "title_zh": "迭代精炼提升组合式图像生成",
      "authors": [
        "Shantanu Jaiswal",
        "Mihir Prabhudesai",
        "Nikash Bhardwaj",
        "Zheyang Qin",
        "Amir Zadeh",
        "Chuan Li",
        "Katerina Fragkiadaki",
        "Deepak Pathak"
      ],
      "abstract": "Text-to-image (T2I) models have achieved remarkable progress, yet they continue to struggle with complex prompts that require simultaneously handling multiple objects, relations, and attributes. Existing inference-time strategies, such as parallel sampling with verifiers or simply increasing denoising steps, can improve prompt alignment but remain inadequate for richly compositional settings where many constraints must be satisfied. Inspired by the success of chain-of-thought reasoning in large language models, we propose an iterative test-time strategy in which a T2I model progressively refines its generations across multiple steps, guided by feedback from a vision-language model as the critic in the loop. Our approach is simple, requires no external tools or priors, and can be flexibly applied to a wide range of image generators and vision-language models. Empirically, we demonstrate consistent gains on image generation across benchmarks: a 16.9% improvement in all-correct rate on ConceptMix (k=7), a 13.8% improvement on T2I-CompBench (3D-Spatial category) and a 12.5% improvement on Visual Jenga scene decomposition compared to compute-matched parallel sampling. Beyond quantitative gains, iterative refinement produces more faithful generations by decomposing complex prompts into sequential corrections, with human evaluators preferring our method 58.7% of the time over 41.3% for the parallel baseline. Together, these findings highlight iterative self-correction as a broadly applicable principle for compositional image generation. Results and visualizations are available at https://iterative-img-gen.github.io/",
      "tldr_zh": "该研究针对文本生成图像(Text-to-Image, T2I)模型在处理包含多对象、关系和属性的复杂组合提示词时的局限性，提出了一种迭代测试时策略(iterative test-time strategy)。受大语言模型链式思维(Chain-of-Thought)推理的启发，该方法利用视觉语言模型(Vision-Language Model)作为循环中的批评者(critic)，引导T2I模型通过多个步骤逐步精细化生成内容。该方案无需外部工具或先验知识，且能灵活适配多种图像生成器和视觉语言模型。实验表明，该方法在ConceptMix、T2I-CompBench和Visual Jenga等多个基准测试中均实现了显著的性能提升，例如在ConceptMix(k=7)上的全对率提高了16.9%。人类评估结果显示，58.7%的用户更倾向于迭代精细化的生成效果，证明了迭代自我纠正(iterative self-correction)在提升组合式图像生成忠实度方面的广泛适用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project webpage: https://iterative-img-gen.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2601.15286v1",
      "published_date": "2026-01-21 18:59:40 UTC",
      "updated_date": "2026-01-21 18:59:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:35:15.492338+00:00"
    },
    {
      "arxiv_id": "2601.15282v1",
      "title": "Rethinking Video Generation Model for the Embodied World",
      "title_zh": "重新思考面向具身世界的视频生成模型",
      "authors": [
        "Yufan Deng",
        "Zilin Pan",
        "Hongyu Zhang",
        "Xiaojie Li",
        "Ruoqing Hu",
        "Yufei Ding",
        "Yiming Zou",
        "Yan Zeng",
        "Daquan Zhou"
      ],
      "abstract": "Video generation models have significantly advanced embodied intelligence, unlocking new possibilities for generating diverse robot data that capture perception, reasoning, and action in the physical world. However, synthesizing high-quality videos that accurately reflect real-world robotic interactions remains challenging, and the lack of a standardized benchmark limits fair comparisons and progress. To address this gap, we introduce a comprehensive robotics benchmark, RBench, designed to evaluate robot-oriented video generation across five task domains and four distinct embodiments. It assesses both task-level correctness and visual fidelity through reproducible sub-metrics, including structural consistency, physical plausibility, and action completeness. Evaluation of 25 representative models highlights significant deficiencies in generating physically realistic robot behaviors. Furthermore, the benchmark achieves a Spearman correlation coefficient of 0.96 with human evaluations, validating its effectiveness. While RBench provides the necessary lens to identify these deficiencies, achieving physical realism requires moving beyond evaluation to address the critical shortage of high-quality training data. Driven by these insights, we introduce a refined four-stage data pipeline, resulting in RoVid-X, the largest open-source robotic dataset for video generation with 4 million annotated video clips, covering thousands of tasks and enriched with comprehensive physical property annotations. Collectively, this synergistic ecosystem of evaluation and data establishes a robust foundation for rigorous assessment and scalable training of video models, accelerating the evolution of embodied AI toward general intelligence.",
      "tldr_zh": "该研究针对视频生成模型在具身智能(Embodied Intelligence)领域难以准确合成真实物理交互且缺乏统一评估标准的问题，提出了综合性基准测试RBench。RBench涵盖5个任务领域和4种具身形式，通过结构一致性(Structural Consistency)、物理合理性(Physical Plausibility)和动作完整性(Action Completeness)等指标评估模型的任务准确性与视觉忠实度。对25个代表性模型的实验揭示了现有模型在生成物理真实机器人行为方面的显著缺陷。为解决高质量数据短缺的瓶颈，研究团队通过四阶段数据流水线构建了RoVid-X数据集，该数据集包含400万个带物理属性标注的视频片段，涵盖数千项任务，是目前最大的开源机器人视频生成数据集。这一由评估基准和大规模数据构成的协同生态系统，为具身智能(Embodied AI)视频模型的严格测评与规模化训练奠定了坚实基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Github: https://github.com/DAGroup-PKU/ReVidgen/ Project website: https://dagroup-pku.github.io/ReVidgen.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2601.15282v1",
      "published_date": "2026-01-21 18:59:18 UTC",
      "updated_date": "2026-01-21 18:59:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:35:10.972030+00:00"
    },
    {
      "arxiv_id": "2601.15280v1",
      "title": "LLM-based Multimodal Feedback Produces Equivalent Learning and Better Student Perceptions than Educator Feedback",
      "title_zh": "基于大语言模型的多模态反馈：学习成效等同于教师反馈且学生感知更佳",
      "authors": [
        "Chloe Qianhui Zhao",
        "Jie Cao",
        "Jionghao Lin",
        "Kenneth R. Koedinger"
      ],
      "abstract": "Providing timely, targeted, and multimodal feedback helps students quickly correct errors, build deep understanding and stay motivated, yet making it at scale remains a challenge. This study introduces a real-time AI-facilitated multimodal feedback system that integrates structured textual explanations with dynamic multimedia resources, including the retrieved most relevant slide page references and streaming AI audio narration. In an online crowdsourcing experiment, we compared this system against fixed business-as-usual feedback by educators across three dimensions: (1) learning effectiveness, (2) learner engagement, (3) perceived feedback quality and value. Results showed that AI multimodal feedback achieved learning gains equivalent to original educator feedback while significantly outperforming it on perceived clarity, specificity, conciseness, motivation, satisfaction, and reducing cognitive load, with comparable correctness, trust, and acceptance. Process logs revealed distinct engagement patterns: for multiple-choice questions, educator feedback encouraged more submissions; for open-ended questions, AI-facilitated targeted suggestions lowered revision barriers and promoted iterative improvement. These findings highlight the potential of AI multimodal feedback to provide scalable, real-time, and context-aware support that both reduces instructor workload and enhances student experience.",
      "tldr_zh": "该研究探讨了基于大语言模型 (LLM) 的多模态反馈系统，旨在解决大规模教育场景下提供及时且针对性反馈的难题。该系统通过整合结构化文本、相关的幻灯片页面参考 (slide page references) 以及 AI 语音叙述 (AI audio narration)，为学生提供实时的多模态支持。研究通过众包实验 (crowdsourcing experiment) 对比了该系统与传统教育者反馈 (educator feedback) 在学习效果 (learning effectiveness)、参与度 (learner engagement) 及感知质量等维度的差异。结果显示，AI 多模态反馈在学习增益上与教育者反馈等效，但在清晰度 (clarity)、特异性 (specificity)、简洁性 (conciseness) 和提升学习动机方面显著占优，并能有效降低认知负荷 (cognitive load)。此外，AI 系统在处理开放式问题时能通过针对性建议降低修改门槛，促进学生的迭代改进。该发现证明了 AI 多模态反馈在提供可扩展、实时且具备上下文感知 (context-aware) 支持方面的潜力，既能减轻教师工作负担，又能显著优化学生的学习体验。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, to be published at the 16th International Learning Analytics & Knowledge Conference (LAK '26)",
      "pdf_url": "https://arxiv.org/pdf/2601.15280v1",
      "published_date": "2026-01-21 18:58:08 UTC",
      "updated_date": "2026-01-21 18:58:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:36:52.764090+00:00"
    },
    {
      "arxiv_id": "2601.15279v1",
      "title": "MolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs",
      "title_zh": "MolecularIQ：通过分子图符号化验证评估化学推理能力",
      "authors": [
        "Christoph Bartmann",
        "Johannes Schimunek",
        "Mykyta Ielanskyi",
        "Philipp Seidl",
        "Günter Klambauer",
        "Sohvi Luukkonen"
      ],
      "abstract": "A molecule's properties are fundamentally determined by its composition and structure encoded in its molecular graph. Thus, reasoning about molecular properties requires the ability to parse and understand the molecular graph. Large Language Models (LLMs) are increasingly applied to chemistry, tackling tasks such as molecular name conversion, captioning, text-guided generation, and property or reaction prediction. Most existing benchmarks emphasize general chemical knowledge, rely on literature or surrogate labels that risk leakage or bias, or reduce evaluation to multiple-choice questions. We introduce MolecularIQ, a molecular structure reasoning benchmark focused exclusively on symbolically verifiable tasks. MolecularIQ enables fine-grained evaluation of reasoning over molecular graphs and reveals capability patterns that localize model failures to specific tasks and molecular structures. This provides actionable insights into the strengths and limitations of current chemistry LLMs and guides the development of models that reason faithfully over molecular structure.",
      "tldr_zh": "该研究引入了 MolecularIQ，这是一个专注于在分子图(Molecular Graphs)上进行符号可验证(Symbolically Verifiable)任务的分子结构推理基准。针对当前大语言模型(LLMs)在化学领域基准测试中存在的通用知识过度强调、数据泄露风险以及评估方式局限于多项选择题等局限性，MolecularIQ 实现了对分子图推理能力的细粒度评估。该基准揭示了模型在处理特定化学任务和分子结构时的能力模式，能够有效地定位模型的失效点。通过提供关于当前化学 LLMs 优势与局限性的见解，MolecularIQ 为开发能够对分子结构进行忠实推理的模型提供了重要指导。这一工具不仅增强了对化学推理能力的理解，还为未来更可靠的科学 AI 模型开发奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15279v1",
      "published_date": "2026-01-21 18:58:01 UTC",
      "updated_date": "2026-01-21 18:58:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:36:23.813416+00:00"
    },
    {
      "arxiv_id": "2601.15370v1",
      "title": "Improving MoE Compute Efficiency by Composing Weight and Data Sparsity",
      "title_zh": "结合权重与数据稀疏性提升 MoE 计算效率",
      "authors": [
        "Maciej Kilian",
        "Oleg Mkrtchyan",
        "Luke Zettlemoyer",
        "Akshat Shrivastava",
        "Armen Aghajanyan"
      ],
      "abstract": "Mixture-of-Experts layers achieve compute efficiency through weight sparsity: each token activates only a subset of experts. Data sparsity, where each expert processes only a subset of tokens, offers a complementary axis. Expert-choice routing implements data sparsity directly but violates causality in autoregressive models, creating train-inference mismatch. We recover data sparsity within causal token-choice MoE by leveraging zero-compute (null) experts within the routing pool. When a token routes to null experts, those slots consume no compute. The standard load balancing objective trains the model to uniformly use all experts (real and null) therefore creating data sparsity in expectation without the causality violations. We evaluate on vision-language model training, where data heterogeneity is pronounced: vision encoders produce many low-information tokens while text tokens are denser. At matched expected FLOPs, composing weight and data sparsity yields a more compute-efficient frontier than weight sparsity alone, with gains in training loss and downstream performance. The model learns implicit modality-aware allocation, routing vision tokens to null experts more aggressively than text, without explicit modality routing.",
      "tldr_zh": "该研究旨在通过结合权重稀疏性(Weight Sparsity)和数据稀疏性(Data Sparsity)来优化混合专家模型(Mixture-of-Experts, MoE)的计算效率。传统的MoE主要依靠每个令牌激活部分专家实现权重稀疏，而作者提出在因果令牌选择(Token-choice)路由中引入零计算的“空专家”(Null Experts)来补足数据稀疏性。这种设计利用标准的负载均衡目标，在不违反自回归模型因果性的前提下，使模型能够在期望上产生数据稀疏性。在视觉-语言模型(Vision-Language Models)的训练评估中，该方法在相同计算量(FLOPs)下表现出比仅使用权重稀疏性更优的效率边界，显著降低了训练损失并提升了下游任务性能。研究还发现模型学会了隐式的模态感知分配，相比文本令牌，它会更主动地将低信息量的视觉令牌路由至空专家，实现了更智能的资源分配。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15370v1",
      "published_date": "2026-01-21 18:53:58 UTC",
      "updated_date": "2026-01-21 18:53:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:37:33.427006+00:00"
    },
    {
      "arxiv_id": "2601.15267v1",
      "title": "Evaluation of Large Language Models in Legal Applications: Challenges, Methods, and Future Directions",
      "title_zh": "大语言模型在法律应用中的评估：挑战、方法与未来方向",
      "authors": [
        "Yiran Hu",
        "Huanghai Liu",
        "Chong Wang",
        "Kunran Li",
        "Tien-Hsuan Wu",
        "Haitao Li",
        "Xinran Xu",
        "Siqing Huo",
        "Weihang Su",
        "Ning Zheng",
        "Siyuan Zheng",
        "Qingyao Ai",
        "Yun Liu",
        "Renjun Bian",
        "Yiqun Liu",
        "Charles L. A. Clarke",
        "Weixing Shen",
        "Ben Kao"
      ],
      "abstract": "Large language models (LLMs) are being increasingly integrated into legal applications, including judicial decision support, legal practice assistance, and public-facing legal services. While LLMs show strong potential in handling legal knowledge and tasks, their deployment in real-world legal settings raises critical concerns beyond surface-level accuracy, involving the soundness of legal reasoning processes and trustworthy issues such as fairness and reliability. Systematic evaluation of LLM performance in legal tasks has therefore become essential for their responsible adoption. This survey identifies key challenges in evaluating LLMs for legal tasks grounded in real-world legal practice. We analyze the major difficulties involved in assessing LLM performance in the legal domain, including outcome correctness, reasoning reliability, and trustworthiness. Building on these challenges, we review and categorize existing evaluation methods and benchmarks according to their task design, datasets, and evaluation metrics. We further discuss the extent to which current approaches address these challenges, highlight their limitations, and outline future research directions toward more realistic, reliable, and legally grounded evaluation frameworks for LLMs in legal domains.",
      "tldr_zh": "该综述深入探讨了大语言模型(Large Language Models, LLMs)在司法决策支持、法律实务及公共法律服务中的应用，并强调了系统评估对其负责任采用的必要性。研究识别了在真实法律场景中评估LLMs的关键挑战，重点关注法律推理(legal reasoning)的严谨性、公平性以及可靠性等可信度议题。本文详细分析了评估中的核心难点，涵盖了结果正确性(outcome correctness)、推理可靠性(reasoning reliability)以及可信度(trustworthiness)等方面。通过对现有评估方法和基准测试(benchmarks)在任务设计、数据集和评估指标上的分类综述，文章揭示了当前技术在应对这些挑战时的局限性。最后，该研究指明了未来构建更具真实性、可靠性且以法律为基础的评估框架的发展方向，旨在为法律人工智能的持续演进提供系统性指导。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15267v1",
      "published_date": "2026-01-21 18:51:37 UTC",
      "updated_date": "2026-01-21 18:51:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:36:25.541118+00:00"
    },
    {
      "arxiv_id": "2601.15369v1",
      "title": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation",
      "title_zh": "OpenVision 3：兼顾理解与生成的统一视觉编码器系列",
      "authors": [
        "Letian Zhang",
        "Sucheng Ren",
        "Yanqing Liu",
        "Xianhang Li",
        "Zeyu Wang",
        "Yuyin Zhou",
        "Huaxiu Yao",
        "Zeyu Zheng",
        "Weili Nie",
        "Guilin Liu",
        "Zhiding Yu",
        "Cihang Xie"
      ],
      "abstract": "This paper presents a family of advanced vision encoder, named OpenVision 3, that learns a single, unified visual representation that can serve both image understanding and image generation. Our core architecture is simple: we feed VAE-compressed image latents to a ViT encoder and train its output to support two complementary roles. First, the encoder output is passed to the ViT-VAE decoder to reconstruct the original image, encouraging the representation to capture generative structure. Second, the same representation is optimized with contrastive learning and image-captioning objectives, strengthening semantic features. By jointly optimizing reconstruction- and semantics-driven signals in a shared latent space, the encoder learns representations that synergize and generalize well across both regimes. We validate this unified design through extensive downstream evaluations with the encoder frozen. For multimodal understanding, we plug the encoder into the LLaVA-1.5 framework: it performs comparably with a standard CLIP vision encoder (e.g., 62.4 vs 62.2 on SeedBench, and 83.7 vs 82.9 on POPE). For generation, we test it under the RAE framework: ours substantially surpasses the standard CLIP-based encoder (e.g., gFID: 1.89 vs 2.54 on ImageNet). We hope this work can spur future research on unified modeling.",
      "tldr_zh": "该研究提出了OpenVision 3，这是一系列旨在同时服务于图像理解(image understanding)和图像生成(image generation)的统一视觉编码器家族。其核心架构将VAE压缩的图像潜变量输入ViT编码器，通过让编码器输出同时承担图像重建与语义表征的双重角色来学习统一的视觉表示。在训练过程中，该模型通过ViT-VAE解码器重建图像以捕捉生成结构，并结合对比学习(contrastive learning)与图像描述(image-captioning)目标来强化语义特征。这种在共享潜空间中联合优化重建驱动与语义驱动信号的方法，使得编码器能够学习到在两种任务模式下高度协同且泛化性强的特征。实验结果表明，在多模态理解任务中，OpenVision 3在LLaVA-1.5框架下的表现与标准CLIP视觉编码器相当；而在图像生成任务中，其在RAE框架下的表现显著优于基于CLIP的编码器，在ImageNet上的gFID从2.54提升至1.89。该研究证明了单一编码器同时处理理解与生成任务的可行性，为未来的统一建模研究提供了新的范式。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15369v1",
      "published_date": "2026-01-21 18:47:12 UTC",
      "updated_date": "2026-01-21 18:47:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:36:24.663690+00:00"
    },
    {
      "arxiv_id": "2601.15254v1",
      "title": "Many Experiments, Few Repetitions, Unpaired Data, and Sparse Effects: Is Causal Inference Possible?",
      "title_zh": "多实验、少重复、非配对数据与稀疏效应：因果推断是否可行？",
      "authors": [
        "Felix Schur",
        "Niklas Pfister",
        "Peng Ding",
        "Sach Mukherjee",
        "Jonas Peters"
      ],
      "abstract": "We study the problem of estimating causal effects under hidden confounding in the following unpaired data setting: we observe some covariates $X$ and an outcome $Y$ under different experimental conditions (environments) but do not observe them jointly; we either observe $X$ or $Y$. Under appropriate regularity conditions, the problem can be cast as an instrumental variable (IV) regression with the environment acting as a (possibly high-dimensional) instrument. When there are many environments but only a few observations per environment, standard two-sample IV estimators fail to be consistent. We propose a GMM-type estimator based on cross-fold sample splitting of the instrument-covariate sample and prove that it is consistent as the number of environments grows but the sample size per environment remains constant. We further extend the method to sparse causal effects via $\\ell_1$-regularized estimation and post-selection refitting.",
      "tldr_zh": "本研究探讨了在存在隐藏混杂因素(hidden confounding)和非配对数据(unpaired data)设置下的因果效应估计问题，即协变量 $X$ 和结果 $Y$ 在不同环境(environments)中被分别观测而非联合观测。该研究将此问题转化为以环境作为工具变量(instrumental variable, IV)的回归模型。针对环境中观测样本量较少(few repetitions)导致标准两样本IV估计量(two-sample IV estimators)失效的挑战，作者提出了一种基于工具变量-协变量样本交叉折叠切分(cross-fold sample splitting)的GMM类估计器(GMM-type estimator)。理论证明表明，当环境数量增加而单环境样本量保持固定时，该方法仍能保持一致性(consistent)。此外，该方法通过 $\\ell_1$ 正则化估计($\\ell_1$-regularized estimation)和选择后重拟合(post-selection refitting)进一步扩展到了稀疏因果效应(sparse causal effects)的估计场景。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15254v1",
      "published_date": "2026-01-21 18:36:34 UTC",
      "updated_date": "2026-01-21 18:36:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:37:01.307856+00:00"
    },
    {
      "arxiv_id": "2601.15249v2",
      "title": "Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism",
      "title_zh": "",
      "authors": [
        "Garrett G. Wen",
        "Buxin Su",
        "Natalie Collina",
        "Zhun Deng",
        "Weijie Su"
      ],
      "abstract": "Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards.",
      "tldr_zh": "",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15249v2",
      "published_date": "2026-01-21 18:30:42 UTC",
      "updated_date": "2026-01-22 15:51:15 UTC",
      "processing_status": "failed",
      "attempts": 3,
      "max_attempts": 3,
      "error": "Your request was blocked.",
      "completed_steps": [],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:58:59.871781+00:00"
    },
    {
      "arxiv_id": "2601.15241v1",
      "title": "Feasibility Preservation under Monotone Retrieval Truncation",
      "title_zh": "单调检索截断下的可行性保持",
      "authors": [
        "Sean Plummer"
      ],
      "abstract": "Retrieval-based systems approximate access to a corpus by exposing only a truncated subset of available evidence. Even when relevant information exists in the corpus, truncation can prevent compatible evidence from co-occurring, leading to failures that are not captured by relevance-based evaluation. This paper studies retrieval from a structural perspective, modeling query answering as a feasibility problem under truncation.\n  We formalize retrieval as a sequence of candidate evidence sets and characterize conditions under which feasibility in the limit implies feasibility at finite retrieval depth. We show that monotone truncation suffices to guarantee finite witnessability for individual queries. For classes of queries, we identify finite generation of witness certificates as the additional condition required to obtain a uniform retrieval bound, and we show that this condition is necessary. We further exhibit sharp counterexamples demonstrating failure under non-monotone truncation, non-finitely-generated query classes, and purely slotwise coverage.\n  Together, these results isolate feasibility preservation as a correctness criterion for retrieval independent of relevance scoring or optimization, and clarify structural limitations inherent to truncation-based retrieval.",
      "tldr_zh": "该研究探讨了基于检索的系统在截断（Truncation）操作下如何保持可行性（Feasibility Preservation），指出传统的相关性评估往往忽略了因截断导致互补证据无法共存而引发的系统失效。作者从结构化视角将查询回答建模为截断条件下的可行性问题（Feasibility Problem），并形式化了检索候选证据集序列。研究证明，单调截断（Monotone Truncation）足以保证单个查询的有限见证性（Finite Witnessability），而针对查询类，则需满足有限生成见证证书（Finite Generation of Witness Certificates）这一必要条件以获得统一的检索边界。此外，论文通过反例展示了在非单调截断或非有限生成查询类中可行性保持的失败。这些结果将可行性保持确立为一种独立于相关性评分（Relevance Scoring）的检索正确性准则，并阐明了截断式检索内在的结构性局限。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15241v1",
      "published_date": "2026-01-21 18:25:16 UTC",
      "updated_date": "2026-01-21 18:25:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:36:43.618249+00:00"
    },
    {
      "arxiv_id": "2601.15235v1",
      "title": "Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification",
      "title_zh": "二维投影中的三维解剖寻踪：一种多阶段投影驱动的颈椎骨折识别方法",
      "authors": [
        "Fabi Nahian Madhurja",
        "Rusab Sarmun",
        "Muhammad E. H. Chowdhury",
        "Adam Mushtak",
        "Israa Al-Hashimi",
        "Sohaib Bassam Zoghoul"
      ],
      "abstract": "Cervical spine fractures are critical medical conditions requiring precise and efficient detection for effective clinical management. This study explores the viability of 2D projection-based vertebra segmentation for vertebra-level fracture detection in 3D CT volumes, presenting an end-to-end pipeline for automated analysis of cervical vertebrae (C1-C7). By approximating a 3D volume through optimized 2D axial, sagittal, and coronal projections, regions of interest are identified using the YOLOv8 model from all views and combined to approximate the 3D cervical spine area, achieving a 3D mIoU of 94.45 percent. This projection-based localization strategy reduces computational complexity compared to traditional 3D segmentation methods while maintaining high performance. It is followed by a DenseNet121-Unet-based multi-label segmentation leveraging variance- and energy-based projections, achieving a Dice score of 87.86 percent. Strategic approximation of 3D vertebral masks from these 2D segmentation masks enables the extraction of individual vertebra volumes. The volumes are analyzed for fractures using an ensemble of 2.5D Spatio-Sequential models incorporating both raw slices and projections per vertebra for complementary evaluation. This ensemble achieves vertebra-level and patient-level F1 scores of 68.15 and 82.26, and ROC-AUC scores of 91.62 and 83.04, respectively. We further validate our approach through an explainability study that provides saliency map visualizations highlighting anatomical regions relevant for diagnosis, and an interobserver variability analysis comparing our model's performance with expert radiologists, demonstrating competitive results.",
      "tldr_zh": "本研究提出了一种基于多阶段投影驱动的端到端管线，用于自动化检测3D CT影像中的颈椎（C1-C7）骨折。该方法通过优化2D轴状位、矢状位和冠状位投影来近似3D体积，并利用YOLOv8模型实现感兴趣区域的精准定位，在保持高性能的同时显著降低了传统3D分割的计算复杂性。随后，研究采用基于DenseNet121-Unet的多标签分割技术，结合variance-based和energy-based投影，实现了高效的椎体提取。在骨折检测阶段，系统采用2.5D Spatio-Sequential模型集成，通过互补评估原始切片与投影数据，使椎体级和患者级的ROC-AUC分别达到91.62和83.04。此外，研究通过显著性图(saliency map)的可解释性分析以及与放射科专家的观察者间变异性(interobserver variability)对比，验证了该方案在临床辅助诊断中的可靠性与竞争优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15235v1",
      "published_date": "2026-01-21 18:15:47 UTC",
      "updated_date": "2026-01-21 18:15:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:37:05.819875+00:00"
    },
    {
      "arxiv_id": "2601.15209v2",
      "title": "Deaf and Hard of Hearing Access to Intelligent Personal Assistants: Comparison of Voice-Based Options with an LLM-Powered Touch Interface",
      "title_zh": "聋人及听障人士使用智能个人助理：语音交互方案与大语言模型驱动触摸界面的对比研究",
      "authors": [
        "Paige S. DeVries",
        "Michaela Okosi",
        "Ming Li",
        "Nora Dunphy",
        "Gidey Gezae",
        "Dante Conway",
        "Abraham Glasser",
        "Raja Kushalnagar",
        "Christian Vogler"
      ],
      "abstract": "We investigate intelligent personal assistants (IPAs) accessibility for deaf and hard of hearing (DHH) people who can use their voice in everyday communication. The inability of IPAs to understand diverse accents including deaf speech renders them largely inaccessible to non-signing and speaking DHH individuals. Using an Echo Show, we compare the usability of natural language input via spoken English; with Alexa's automatic speech recognition and a Wizard-of-Oz setting with a trained facilitator re-speaking commands against that of a large language model (LLM)-assisted touch interface in a mixed-methods study. The touch method was navigated through an LLM-powered \"task prompter,\" which integrated the user's history and smart environment to suggest contextually-appropriate commands. Quantitative results showed no significant differences across both spoken English conditions vs LLM-assisted touch. Qualitative results showed variability in opinions on the usability of each method. Ultimately, it will be necessary to have robust deaf-accented speech recognized natively by IPAs.",
      "tldr_zh": "该研究探讨了听障人士(DHH)在使用智能个人助手(IPAs)时的可访问性问题，特别是针对那些在日常沟通中使用语音而非手语的群体。由于现有的IPAs难以识别包括聋人语音在内的多样化口音，研究者利用Echo Show设备对比了三种交互方式：基于Alexa自动语音识别(ASR)的自然语言输入、由专业协调员转述命令的Wizard-of-Oz设置，以及一种由大语言模型(LLM)驱动的触摸界面。该LLM界面通过“任务提示器(task prompter)”整合用户历史和智能环境信息，提供上下文相关的命令建议。定量研究结果显示，语音输入条件与LLM辅助触摸界面在可用性表现上没有显著差异，而定性结果则反映出用户对各方法可用性的评价存在多样性。研究最终指出，虽然LLM辅助界面提供了替代方案，但实现IPAs对聋人口音(deaf-accented speech)的原生鲁棒识别依然是保障可访问性的核心需求。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for publication in ACM CHI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.15209v2",
      "published_date": "2026-01-21 17:33:00 UTC",
      "updated_date": "2026-01-22 16:01:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:37:18.543284+00:00"
    },
    {
      "arxiv_id": "2601.15197v2",
      "title": "BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries",
      "title_zh": "BayesianVLA：基于潜动作查询的视觉-语言-动作模型贝叶斯分解",
      "authors": [
        "Shijie Lian",
        "Bin Yu",
        "Xiaopeng Lin",
        "Laurence T. Yang",
        "Zhaolong Shen",
        "Changti Wu",
        "Yuzhuo Miao",
        "Cong Huang",
        "Kai Chen"
      ],
      "abstract": "Vision-Language-Action (VLA) models have shown promise in robot manipulation but often struggle to generalize to new instructions or complex multi-task scenarios. We identify a critical pathology in current training paradigms where goal-driven data collection creates a dataset bias. In such datasets, language instructions are highly predictable from visual observations alone, causing the conditional mutual information between instructions and actions to vanish, a phenomenon we term Information Collapse. Consequently, models degenerate into vision-only policies that ignore language constraints and fail in out-of-distribution (OOD) settings. To address this, we propose BayesianVLA, a novel framework that enforces instruction following via Bayesian decomposition. By introducing learnable Latent Action Queries, we construct a dual-branch architecture to estimate both a vision-only prior $p(a \\mid v)$ and a language-conditioned posterior $π(a \\mid v, \\ell)$. We then optimize the policy to maximize the conditional Pointwise Mutual Information (PMI) between actions and instructions. This objective effectively penalizes the vision shortcut and rewards actions that explicitly explain the language command. Without requiring new data, BayesianVLA significantly improves generalization. Extensive experiments across on SimplerEnv and RoboCasa demonstrate substantial gains, including an 11.3% improvement on the challenging OOD SimplerEnv benchmark, validating the ability of our approach to robustly ground language in action.",
      "tldr_zh": "该研究探讨了视觉语言动作模型(VLA)在机器人操作中泛化能力不足的问题，指出由于数据集偏置导致的“信息坍缩”(Information Collapse)现象使模型倾向于忽略语言指令。为此，作者提出了BayesianVLA框架，通过引入可学习的Latent Action Queries并结合贝叶斯分解(Bayesian decomposition)来强化指令遵循能力。该框架采用双分支架构分别估计视觉先验与语言辅助后验，通过最大化条件点对互信息(PMI)来惩罚视觉捷径，从而鼓励模型生成与语言指令高度相关的动作。在SimplerEnv和RoboCasa等基准测试中的实验结果表明，BayesianVLA在不依赖新数据的前提下显著提升了泛化性能，在挑战性的分布外(OOD)测试中实现了11.3%的性能提升。这项工作有效验证了通过贝叶斯方法显式对齐语言与动作在机器人操作中的鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15197v2",
      "published_date": "2026-01-21 17:15:22 UTC",
      "updated_date": "2026-01-22 17:01:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:39:48.048164+00:00"
    },
    {
      "arxiv_id": "2601.15195v1",
      "title": "Where Do AI Coding Agents Fail? An Empirical Study of Failed Agentic Pull Requests in GitHub",
      "title_zh": "AI 编程智能体在何处失效？关于 GitHub 中失败智能体拉取请求的实证研究",
      "authors": [
        "Ramtin Ehsani",
        "Sakshi Pathak",
        "Shriya Rawal",
        "Abdullah Al Mujahid",
        "Mia Mohammad Imran",
        "Preetha Chatterjee"
      ],
      "abstract": "AI coding agents are now submitting pull requests (PRs) to software projects, acting not just as assistants but as autonomous contributors. As these agentic contributions are rapidly increasing across real repositories, little is known about how they behave in practice and why many of them fail to be merged. In this paper, we conduct a large-scale study of 33k agent-authored PRs made by five coding agents across GitHub. (RQ1) We first quantitatively characterize merged and not-merged PRs along four broad dimensions: 1) merge outcomes across task types, 2) code changes, 3) CI build results, and 4) review dynamics. We observe that tasks related to documentation, CI, and build update achieve the highest merge success, whereas performance and bug-fix tasks perform the worst. Not-merged PRs tend to involve larger code changes, touch more files, and often do not pass the project's CI/CD pipeline validation. (RQ2) To further investigate why some agentic PRs are not merged, we qualitatively analyze 600 PRs to derive a hierarchical taxonomy of rejection patterns. This analysis complements the quantitative findings in RQ1 by uncovering rejection reasons not captured by quantitative metrics, including lack of meaningful reviewer engagement, duplicate PRs, unwanted feature implementations, and agent misalignment. Together, our findings highlight key socio-technical and human-AI collaboration factors that are critical to improving the success of future agentic workflows.",
      "tldr_zh": "这项研究对 GitHub 上五个 AI coding agents 提交的 3.3 万个 Pull Requests (PRs) 进行了大规模实证研究，旨在分析其在实际开发中的行为表现及未能合并的原因。通过 quantitative characterization，研究发现涉及 documentation、CI 和构建更新的任务合并成功率最高，而 performance 和 bug-fix 任务表现最差。未被合并的 PR 通常具有代码变更量大、触及文件多以及无法通过 CI/CD 流水线验证等特征。进一步的 qualitative analysis 揭示了定量指标无法捕捉的拒绝因素，包括缺乏 reviewer engagement、重复提交、unwanted feature 实现以及 agent misalignment。该研究最后强调了社会技术因素和 human-AI collaboration 在提升未来 agentic workflows 成功率中的关键作用。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at International Mining Software Repositories Conference (MSR 2026)",
      "pdf_url": "https://arxiv.org/pdf/2601.15195v1",
      "published_date": "2026-01-21 17:12:46 UTC",
      "updated_date": "2026-01-21 17:12:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:38:33.434333+00:00"
    },
    {
      "arxiv_id": "2601.15188v1",
      "title": "Benchmarking Large Language Models for ABAP Code Generation: An Empirical Study on Iterative Improvement by Compiler Feedback",
      "title_zh": "ABAP 代码生成的大语言模型基准测试：基于编译器反馈迭代改进的实证研究",
      "authors": [
        "Stephan Wallraven",
        "Tim Köhne",
        "Hartmut Westenberger",
        "Andreas Moser"
      ],
      "abstract": "This work investigates the performance of Large Language Models (LLMs) in generating ABAP code. Despite successful applications of generative AI in many programming languages, there are hardly any systematic analyses of ABAP code generation to date. The aim of the study is to empirically analyze to what extent various LLMs can generate syntactically correct and functional ABAP code, how effectively they use compiler feedback for iterative improvement, and which task types pose special challenges. For this purpose, a benchmark with 180 tasks is conducted, consisting of adapted HumanEval tasks and practical SAP scenarios. The results show significant performance differences between the models: more powerful LLMs achieve success rates of around 75% after several iterations and benefit greatly from compiler feedback, while smaller models perform significantly weaker. Overall, the study highlights the high potential of powerful LLMs for ABAP development processes, especially in iterative error correction.",
      "tldr_zh": "这项研究针对大型语言模型 (LLMs) 在生成 ABAP 代码方面的性能进行了系统的实证分析，填补了该领域缺乏系统化基准评估的空白。研究人员构建了一个包含 180 个任务的基准测试，涵盖了适配后的 HumanEval 任务及实际的 SAP 场景，重点考察模型在利用编译器反馈 (compiler feedback) 进行迭代改进 (iterative improvement) 时的表现。实验结果显示，性能较强的 LLMs 在经过多次迭代后成功率可达约 75%，且能高效利用反馈修正错误，而小型模型的性能则显著较弱。该研究揭示了强大的 LLMs 在 ABAP 开发流程中的巨大潜力，特别是在自动化迭代纠错 (iterative error correction) 场景下具有显著优势。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "20 pages, 10 figures, Author: Hartmut Westenberger (ORCID: 0009-0009-9063-8318)",
      "pdf_url": "https://arxiv.org/pdf/2601.15188v1",
      "published_date": "2026-01-21 17:06:41 UTC",
      "updated_date": "2026-01-21 17:06:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:39:29.422274+00:00"
    },
    {
      "arxiv_id": "2601.15177v1",
      "title": "Dynamic Management of a Deep Learning-Based Anomaly Detection System for 5G Networks",
      "title_zh": "5G 网络下基于深度学习的异常检测系统动态管理",
      "authors": [
        "Lorenzo Fernández Maimó",
        "Alberto Huertas Celdrán",
        "Manuel Gil Pérez",
        "Félix J. García Clemente",
        "Gregorio Martínez Pérez"
      ],
      "abstract": "Fog and mobile edge computing (MEC) will play a key role in the upcoming fifth generation (5G) mobile networks to support decentralized applications, data analytics and management into the network itself by using a highly distributed compute model. Furthermore, increasing attention is paid to providing user-centric cybersecurity solutions, which particularly require collecting, processing and analyzing significantly large amount of data traffic and huge number of network connections in 5G networks. In this regard, this paper proposes a MEC-oriented solution in 5G mobile networks to detect network anomalies in real-time and in autonomic way. Our proposal uses deep learning techniques to analyze network flows and to detect network anomalies. Moreover, it uses policies in order to provide an efficient and dynamic management system of the computing resources used in the anomaly detection process. The paper presents relevant aspects of the deployment of the proposal and experimental results to show its performance.",
      "tldr_zh": "该研究提出了一种面向5G移动网络的MEC-oriented解决方案，旨在通过自主且实时的方式实现网络异常检测。该方案采用Deep Learning技术对网络流量(network flows)进行深度分析，以识别复杂的安全威胁。为了优化检测过程中的计算资源分配，研究引入了基于策略(policies)的动态管理系统，确保了系统在高度分布式的计算模型下的运行效率。文中详细描述了该系统的部署架构，并通过实验结果验证了其在处理大规模数据流量时的卓越性能。这一贡献为5G环境下以用户为中心的Cybersecurity保障提供了关键的技术支撑。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15177v1",
      "published_date": "2026-01-21 16:54:19 UTC",
      "updated_date": "2026-01-21 16:54:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:38:38.529793+00:00"
    },
    {
      "arxiv_id": "2601.15165v1",
      "title": "The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models",
      "title_zh": "灵活性陷阱：为何任意生成顺序会限制扩散语言模型的推理潜力",
      "authors": [
        "Zanlin Ni",
        "Shenzhi Wang",
        "Yang Yue",
        "Tianyu Yu",
        "Weilin Zhao",
        "Yeguo Hua",
        "Tianyi Chen",
        "Jun Song",
        "Cheng Yu",
        "Bo Zheng",
        "Gao Huang"
      ],
      "abstract": "Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint of traditional LLMs, enabling token generation in arbitrary orders. Intuitively, this flexibility implies a solution space that strictly supersets the fixed autoregressive trajectory, theoretically unlocking superior reasoning potential for general tasks like mathematics and coding. Consequently, numerous works have leveraged reinforcement learning (RL) to elicit the reasoning capability of dLLMs. In this paper, we reveal a counter-intuitive reality: arbitrary order generation, in its current form, narrows rather than expands the reasoning boundary of dLLMs. We find that dLLMs tend to exploit this order flexibility to bypass high-uncertainty tokens that are crucial for exploration, leading to a premature collapse of the solution space. This observation challenges the premise of existing RL approaches for dLLMs, where considerable complexities, such as handling combinatorial trajectories and intractable likelihoods, are often devoted to preserving this flexibility. We demonstrate that effective reasoning is better elicited by intentionally forgoing arbitrary order and applying standard Group Relative Policy Optimization (GRPO) instead. Our approach, JustGRPO, is minimalist yet surprisingly effective (e.g., 89.1% accuracy on GSM8K) while fully retaining the parallel decoding ability of dLLMs. Project page: https://nzl-thu.github.io/the-flexibility-trap",
      "tldr_zh": "该研究探讨了扩散大语言模型(dLLMs)中的“灵活性陷阱”，揭示了任意顺序生成(arbitrary order generation)在目前形式下实际上缩小而非扩展了模型的推理边界。作者发现dLLMs倾向于利用这种顺序灵活性来规避对探索至关重要的高不确定性(high-uncertainty)标记，从而导致解空间过早坍缩。这一观察挑战了现有强化学习(RL)方法中为了保留灵活性而引入复杂组合轨迹(combinatorial trajectories)和不可计算似然度(intractable likelihoods)的处理方式。研究证明通过有意放弃任意顺序并应用标准的群体相对策略优化(GRPO)能更有效地激发推理能力。为此，作者提出了名为JustGRPO的极简方法，在完全保留dLLMs并行解码能力的同时显著提升了性能。实验结果显示，该方法在GSM8K数据集上达到了89.1%的准确率，证明了在扩散模型中简化生成逻辑对增强推理潜力的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Code and pre-trained models: https://github.com/LeapLabTHU/JustGRPO",
      "pdf_url": "https://arxiv.org/pdf/2601.15165v1",
      "published_date": "2026-01-21 16:41:58 UTC",
      "updated_date": "2026-01-21 16:41:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:38:36.191046+00:00"
    },
    {
      "arxiv_id": "2601.15164v1",
      "title": "V-CAGE: Context-Aware Generation and Verification for Scalable Long-Horizon Embodied Tasks",
      "title_zh": "V-CAGE：面向可扩展长程具身任务的上下文感知生成与验证",
      "authors": [
        "Yaru Liu",
        "Ao-bo Wang",
        "Nanyang Ye"
      ],
      "abstract": "Learning long-horizon embodied behaviors from synthetic data remains challenging because generated scenes are often physically implausible, language-driven programs frequently \"succeed\" without satisfying task semantics, and high-level instructions require grounding into executable action sequences. To address these limitations, we introduce V-CAGE, a closed-loop framework for generating robust, semantically aligned manipulation datasets at scale. First, we propose a context-aware instantiation mechanism that enforces geometric consistency during scene synthesis. By dynamically maintaining a map of prohibited spatial areas as objects are placed, our system prevents interpenetration and ensures reachable, conflict-free configurations in cluttered environments. Second, to bridge the gap between abstract intent and low-level control, we employ a hierarchical instruction decomposition module. This decomposes high-level goals (e.g., \"get ready for work\") into compositional action primitives, facilitating coherent long-horizon planning. Crucially, we enforce semantic correctness through a VLM-based verification loop. Acting as a visual critic, the VLM performs rigorous rejection sampling after each subtask, filtering out \"silent failures\" where code executes but fails to achieve the visual goal. Experiments demonstrate that V-CAGE yields datasets with superior physical and semantic fidelity, significantly boosting the success rate and generalization of downstream policies compared to non-verified baselines.",
      "tldr_zh": "该研究针对从合成数据中学习长时程具身行为(long-horizon embodied behaviors)面临的物理失真、语义未达成及指令落地困难等挑战，提出了V-CAGE框架。该框架通过上下文感知实例化机制(context-aware instantiation mechanism)在场景合成中强制执行几何一致性，利用动态维护的空间地图防止物体穿透并确保配置无冲突。为了连接抽象意图与底层控制，V-CAGE采用层次化指令分解(hierarchical instruction decomposition)将高层目标拆解为可执行的动作原语(action primitives)。此外，该系统引入了基于视觉语言模型(VLM)的验证闭环，作为视觉评论者(visual critic)执行严格的拒绝采样，从而有效过滤掉代码运行成功但任务目标未达成的“静默失败”(\"silent failures\")。实验证明，V-CAGE生成的数据集具有极高的物理与语义保真度，显著增强了下游策略的成功率和泛化能力，为大规模构建稳健且语义对齐的操纵数据集提供了闭环解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15164v1",
      "published_date": "2026-01-21 16:41:51 UTC",
      "updated_date": "2026-01-21 16:41:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:38:45.551706+00:00"
    },
    {
      "arxiv_id": "2601.15161v1",
      "title": "Automated Rubrics for Reliable Evaluation of Medical Dialogue Systems",
      "title_zh": "医疗对话系统可靠评估的自动化评分准则",
      "authors": [
        "Yinzhu Chen",
        "Abdine Maiga",
        "Hossein A. Rahmani",
        "Emine Yilmaz"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used for clinical decision support, where hallucinations and unsafe suggestions may pose direct risks to patient safety. These risks are particularly challenging as they often manifest as subtle clinical errors that evade detection by generic metrics, while expert-authored fine-grained rubrics remain costly to construct and difficult to scale. In this paper, we propose a retrieval-augmented multi-agent framework designed to automate the generation of instance-specific evaluation rubrics. Our approach grounds evaluation in authoritative medical evidence by decomposing retrieved content into atomic facts and synthesizing them with user interaction constraints to form verifiable, fine-grained evaluation criteria. Evaluated on HealthBench, our framework achieves a Clinical Intent Alignment (CIA) score of 60.12%, a statistically significant improvement over the GPT-4o baseline (55.16%). In discriminative tests, our rubrics yield a mean score delta ($μ_Δ = 8.658$) and an AUROC of 0.977, nearly doubling the quality separation achieved by GPT-4o baseline (4.972). Beyond evaluation, our rubrics effectively guide response refinement, improving quality by 9.2% (from 59.0% to 68.2%). This provides a scalable and transparent foundation for both evaluating and improving medical LLMs. The code is available at https://anonymous.4open.science/r/Automated-Rubric-Generation-AF3C/.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 在临床决策支持中存在的幻觉和安全风险，提出了一种用于自动生成实例特定评估量规的检索增强多智能体框架。该方法通过将检索到的权威医学证据分解为原子事实 (atomic facts)，并结合用户交互约束，构建出可验证且细粒度的评估标准。在 HealthBench 上的实验表明，该框架实现了 60.12% 的临床意图对齐 (Clinical Intent Alignment, CIA) 分数，显著优于 GPT-4o 基线。在判别性测试中，该量规取得了 0.977 的 AUROC，在质量区分能力上几乎是基线模型的两倍。此外，该量规还能有效指导响应细化，将医疗对话回复质量从 59.0% 提升至 68.2%。该研究为医学领域大模型的评估与改进提供了一个可扩展且透明的自动化基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15161v1",
      "published_date": "2026-01-21 16:40:41 UTC",
      "updated_date": "2026-01-21 16:40:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:39:10.182710+00:00"
    },
    {
      "arxiv_id": "2601.15160v1",
      "title": "Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning",
      "title_zh": "知识图谱即隐式奖励模型：路径衍生信号赋能组合性推理",
      "authors": [
        "Yuval Kansal",
        "Niraj K. Jha"
      ],
      "abstract": "Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we present a post-training pipeline, based on a combination of supervised fine-tuning and reinforcement learning (RL), in which knowledge graphs act as implicit reward models. By deriving novel reward signals from knowledge graph paths, we provide verifiable, scalable, and grounded supervision that encourages models to compose intermediate axioms rather than optimize only final answers during RL. We validate this approach in the medical domain, training a 14B model on short-hop reasoning paths (1-3 hops) and evaluating its zero-shot generalization to complex multi-hop queries (4-5 hops). Our experiments show that path-derived rewards act as a \"compositional bridge\", enabling our model to significantly outperform much larger models and frontier systems like GPT-5.2 and Gemini 3 Pro, on the most difficult reasoning tasks. Furthermore, we demonstrate the robustness of our approach to adversarial perturbations against option-shuffling stress tests. This work suggests that grounding the reasoning process in structured knowledge is a scalable and efficient path toward intelligent reasoning.",
      "tldr_zh": "该研究提出了一种自下而上的学习范式，将知识图谱(Knowledge Graphs)作为隐式奖励模型(implicit reward models)，以解决大语言模型在专门科学领域中组合式多跳推理(compositional multi-hop reasoning)能力有限的问题。通过结合有监督微调(SFT)和强化学习(RL)，利用从知识图谱路径中衍生的信号提供可验证且可扩展的监督，促使模型在训练过程中组合中间公理而非仅优化最终答案。在医学领域的实验表明，该14B模型在仅接受短路径推理训练的情况下，在复杂多跳查询任务上的零样本泛化能力显著优于GPT-5.2和Gemini 3 Pro等规模更大的前沿系统。此外，该模型在对抗性扰动测试中展现了极强的鲁棒性(robustness)，证明了将推理过程锚定在结构化知识中是实现高效、可扩展智能推理的有效途径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15160v1",
      "published_date": "2026-01-21 16:38:59 UTC",
      "updated_date": "2026-01-21 16:38:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:38:59.271456+00:00"
    },
    {
      "arxiv_id": "2601.15158v1",
      "title": "Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data",
      "title_zh": "基于结果的强化学习可证明能引导 Transformer 产生推理能力，但前提是拥有合适的数据",
      "authors": [
        "Yuval Ran-Milo",
        "Yotam Alexander",
        "Shahar Mendel",
        "Nadav Cohen"
      ],
      "abstract": "Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought (CoT) but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, gradient flow drives the model to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of \"simple examples\": instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler instances, the model learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, gradient-based learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings.",
      "tldr_zh": "该研究探讨了基于结果监督的强化学习(RL)训练的Transformers如何自发产生链式思维(Chain-of-Thought)推理能力，并深入分析了稀疏奖励驱动梯度下降发现系统推理的机制。作者通过研究单层Transformer在合成图遍历任务中的梯度流(gradient flow)动力学，证明了即便仅依靠最终答案的正确性进行训练，梯度流仍能驱动模型收敛于一种结构化、可解释的逐步遍历算法。研究识别出“简单示例(simple examples)”在推理涌现中的关键作用，即包含较少推理步骤的实例是模型学习通用策略并外推至长链推理的基础。实验结果表明，当训练分布中简单示例比例足够时，模型能习得可泛化的策略，反之则会导致学习失效。该理论发现已在合成数据及真实世界大语言模型(real-world language models)的数学推理任务中得到进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "80 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.15158v1",
      "published_date": "2026-01-21 16:36:19 UTC",
      "updated_date": "2026-01-21 16:36:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:39:11.144071+00:00"
    },
    {
      "arxiv_id": "2601.15153v1",
      "title": "How to Build AI Agents by Augmenting LLMs with Codified Human Expert Domain Knowledge? A Software Engineering Framework",
      "title_zh": "如何通过编码化的人类专家领域知识增强大语言模型来构建 AI 智能体：一种软件工程框架",
      "authors": [
        "Choro Ulan uulu",
        "Mikhail Kulyabin",
        "Iris Fuhrmann",
        "Jan Joosten",
        "Nuno Miguel Martins Pacheco",
        "Filippos Petridis",
        "Rebecca Johnson",
        "Jan Bosch",
        "Helena Holmström Olsson"
      ],
      "abstract": "Critical domain knowledge typically resides with few experts, creating organizational bottlenecks in scalability and decision-making. Non-experts struggle to create effective visualizations, leading to suboptimal insights and diverting expert time. This paper investigates how to capture and embed human domain knowledge into AI agent systems through an industrial case study. We propose a software engineering framework to capture human domain knowledge for engineering AI agents in simulation data visualization by augmenting a Large Language Model (LLM) with a request classifier, Retrieval-Augmented Generation (RAG) system for code generation, codified expert rules, and visualization design principles unified in an agent demonstrating autonomous, reactive, proactive, and social behavior. Evaluation across five scenarios spanning multiple engineering domains with 12 evaluators demonstrates 206% improvement in output quality, with our agent achieving expert-level ratings in all cases versus baseline's poor performance, while maintaining superior code quality with lower variance. Our contributions are: an automated agent-based system for visualization generation and a validated framework for systematically capturing human domain knowledge and codifying tacit expert knowledge into AI agents, demonstrating that non-experts can achieve expert-level outcomes in specialized domains.",
      "tldr_zh": "该研究针对领域专家知识稀缺导致的组织扩展瓶颈问题，提出了一个将人类领域知识捕捉并嵌入 AI agent 系统的软件工程框架。该框架通过在 Large Language Model (LLM) 基础上集成请求分类器(request classifier)、用于代码生成的检索增强生成(RAG)系统、固化的专家规则以及可视化设计原则，构建了具备自主性和主动性的智能体。在跨多个工程领域的五个场景评估中，该智能体使输出质量提升了206%，且在所有案例中均达到专家级评分，显著优于基线模型。此外，系统生成的代码质量更高且波动更小，确保了任务执行的稳健性。该研究的主要贡献在于建立了一套验证有效的框架，用于系统化捕捉并固化隐性专家知识，从而赋能非专家在专业领域实现专家级的产出。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15153v1",
      "published_date": "2026-01-21 16:23:22 UTC",
      "updated_date": "2026-01-21 16:23:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:39:22.699117+00:00"
    },
    {
      "arxiv_id": "2601.15131v1",
      "title": "Vehicle Routing with Finite Time Horizon using Deep Reinforcement Learning with Improved Network Embedding",
      "title_zh": "基于改进网络嵌入深度强化学习的有限时域车辆路径规划",
      "authors": [
        "Ayan Maity",
        "Sudeshna Sarkar"
      ],
      "abstract": "In this paper, we study the vehicle routing problem with a finite time horizon. In this routing problem, the objective is to maximize the number of customer requests served within a finite time horizon. We present a novel routing network embedding module which creates local node embedding vectors and a context-aware global graph representation. The proposed Markov decision process for the vehicle routing problem incorporates the node features, the network adjacency matrix and the edge features as components of the state space. We incorporate the remaining finite time horizon into the network embedding module to provide a proper routing context to the embedding module. We integrate our embedding module with a policy gradient-based deep Reinforcement Learning framework to solve the vehicle routing problem with finite time horizon. We trained and validated our proposed routing method on real-world routing networks, as well as synthetically generated Euclidean networks. Our experimental results show that our method achieves a higher customer service rate than the existing routing methods. Additionally, the solution time of our method is significantly lower than that of the existing methods.",
      "tldr_zh": "该研究针对有限时间跨度（Finite Time Horizon）下的车辆路径问题（Vehicle Routing Problem），提出了一种旨在最大化规定时间内服务客户请求数量的深度强化学习（Deep Reinforcement Learning）框架。作者开发了一种改进的网络嵌入（Network Embedding）模块，通过融合节点特征、邻接矩阵和边特征，生成局部节点嵌入和上下文感知的全局图表示。该方案创新性地将剩余时间跨度引入嵌入过程，并结合基于策略梯度（Policy Gradient）的算法进行求解。在真实世界路由网络和合成欧几里得网络上的实验结果表明，该方法在客户服务率上显著优于现有路径规划算法，同时大幅降低了计算求解时间。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAAI-26 Workshop on AI for Urban Planning",
      "pdf_url": "https://arxiv.org/pdf/2601.15131v1",
      "published_date": "2026-01-21 16:05:04 UTC",
      "updated_date": "2026-01-21 16:05:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:40:22.687158+00:00"
    },
    {
      "arxiv_id": "2601.15130v1",
      "title": "The Plausibility Trap: Using Probabilistic Engines for Deterministic Tasks",
      "title_zh": "合理性陷阱：将概率引擎应用于确定性任务",
      "authors": [
        "Ivan Carrera",
        "Daniel Maldonado-Ruiz"
      ],
      "abstract": "The ubiquity of Large Language Models (LLMs) is driving a paradigm shift where user convenience supersedes computational efficiency. This article defines the \"Plausibility Trap\": a phenomenon where individuals with access to Artificial Intelligence (AI) models deploy expensive probabilistic engines for simple deterministic tasks-such as Optical Character Recognition (OCR) or basic verification-resulting in significant resource waste. Through micro-benchmarks and case studies on OCR and fact-checking, we quantify the \"efficiency tax\"-demonstrating a ~6.5x latency penalty-and the risks of algorithmic sycophancy. To counter this, we introduce Tool Selection Engineering and the Deterministic-Probabilistic Decision Matrix, a framework to help developers determine when to use Generative AI and, crucially, when to avoid it. We argue for a curriculum shift, emphasizing that true digital literacy relies not only in knowing how to use Generative AI, but also on knowing when not to use it.",
      "tldr_zh": "该研究定义了“合理性陷阱”(Plausibility Trap)这一现象，即用户倾向于使用昂贵的概率性大语言模型(LLMs)来处理本应由确定性工具完成的简单任务，如光学字符识别(OCR)或基本验证。通过对 OCR 和事实核查的微基准测试，研究量化了这种“效率税”，发现这种做法会导致约 6.5 倍的延迟惩罚，并增加算法谄媚(Algorithmic Sycophancy)的风险。为解决资源浪费问题，作者提出了工具选择工程(Tool Selection Engineering)和确定性-概率决策矩阵(Deterministic-Probabilistic Decision Matrix)框架，帮助开发者判断何时应使用及何时应避免使用生成式 AI (Generative AI)。该文最后主张进行课程改革，强调真正的数字素养不仅在于掌握如何使用 AI，更在于明确其不适用的场景。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15130v1",
      "published_date": "2026-01-21 16:05:01 UTC",
      "updated_date": "2026-01-21 16:05:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:40:06.734759+00:00"
    },
    {
      "arxiv_id": "2601.15124v1",
      "title": "Overcoming In-Memory Bottlenecks in Graph Foundation Models via Retrieval-Augmented Generation",
      "title_zh": "通过检索增强生成克服图基础模型中的内存瓶颈",
      "authors": [
        "Haonan Yuan",
        "Qingyun Sun",
        "Jiacheng Tao",
        "Xingcheng Fu",
        "Jianxin Li"
      ],
      "abstract": "Graph Foundation Models (GFMs) have emerged as a frontier in graph learning, which are expected to deliver transferable representations across diverse tasks. However, GFMs remain constrained by in-memory bottlenecks: they attempt to encode knowledge into model parameters, which limits semantic capacity, introduces heavy lossy compression with conflicts, and entangles graph representation with the knowledge in ways that hinder efficient adaptation, undermining scalability and interpretability. In this work,we propose RAG-GFM, a Retrieval-Augmented Generation aided Graph Foundation Model that offloads knowledge from parameters and complements parameterized learning. To externalize graph knowledge, we build a dual-modal unified retrieval module, where a semantic store from prefix-structured text and a structural store from centrality-based motif. To preserve heterogeneous information, we design a dual-view alignment objective that contrasts both modalities to capture both content and relational patterns. To enable efficient downstream adaptation, we perform in-context augmentation to enrich supporting instances with retrieved texts and motifs as contextual evidence. Extensive experiments on five benchmark graph datasets demonstrate that RAG-GFM consistently outperforms 13 state-of-the-art baselines in both cross-domain node and graph classification, achieving superior effectiveness and efficiency.",
      "tldr_zh": "该研究提出了RAG-GFM，旨在解决图基础模型(Graph Foundation Models, GFMs)在将知识编码进参数时面临的内存瓶颈、语义容量受限以及可解释性差等问题。该框架引入了检索增强生成(Retrieval-Augmented Generation)技术，将知识从模型参数中卸载到外部存储，并构建了一个双模态统一检索模块。该模块包含基于前缀结构文本(prefix-structured text)的语义库和基于中心性基元(centrality-based motif)的结构库，以实现图知识的外部化。为了保留异构信息，研究设计了双视图对齐目标(dual-view alignment objective)来捕捉内容和关系模式，并通过上下文增强(in-context augmentation)利用检索结果作为推理证据。在五个基准数据集上的实验表明，RAG-GFM在跨域节点和图分类任务中一致优于13种最先进的基线模型。该方法不仅提升了模型的语义表达能力，还在保持高效性的同时增强了图基础模型的可扩展性与可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the Web Conference 2026 (Research Track)",
      "pdf_url": "https://arxiv.org/pdf/2601.15124v1",
      "published_date": "2026-01-21 16:02:43 UTC",
      "updated_date": "2026-01-21 16:02:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:40:27.104659+00:00"
    },
    {
      "arxiv_id": "2601.15123v1",
      "title": "BREPS: Bounding-Box Robustness Evaluation of Promptable Segmentation",
      "title_zh": "BREPS：提示式分割的边界框鲁棒性评估",
      "authors": [
        "Andrey Moskalenko",
        "Danil Kuznetsov",
        "Irina Dudko",
        "Anastasiia Iasakova",
        "Nikita Boldyrev",
        "Denis Shepelev",
        "Andrei Spiridonov",
        "Andrey Kuznetsov",
        "Vlad Shakhuro"
      ],
      "abstract": "Promptable segmentation models such as SAM have established a powerful paradigm, enabling strong generalization to unseen objects and domains with minimal user input, including points, bounding boxes, and text prompts. Among these, bounding boxes stand out as particularly effective, often outperforming points while significantly reducing annotation costs. However, current training and evaluation protocols typically rely on synthetic prompts generated through simple heuristics, offering limited insight into real-world robustness. In this paper, we investigate the robustness of promptable segmentation models to natural variations in bounding box prompts. First, we conduct a controlled user study and collect thousands of real bounding box annotations. Our analysis reveals substantial variability in segmentation quality across users for the same model and instance, indicating that SAM-like models are highly sensitive to natural prompt noise. Then, since exhaustive testing of all possible user inputs is computationally prohibitive, we reformulate robustness evaluation as a white-box optimization problem over the bounding box prompt space. We introduce BREPS, a method for generating adversarial bounding boxes that minimize or maximize segmentation error while adhering to naturalness constraints. Finally, we benchmark state-of-the-art models across 10 datasets, spanning everyday scenes to medical imaging. Code - https://github.com/emb-ai/BREPS.",
      "tldr_zh": "该研究探讨了可提示分割模型（Promptable segmentation models，如 SAM）对边界框（Bounding box）提示中自然变异的鲁棒性。通过一项受控的用户研究，作者发现此类模型对真实用户产生的提示噪声高度敏感，导致同一实例在不同用户输入下的分割质量存在显著差异。由于穷举所有用户输入在计算上不可行，研究提出了一种名为 BREPS 的评估方法，将鲁棒性评估重新定义为边界框提示空间上的白盒优化（White-box optimization）问题。BREPS 能够在遵循自然性约束的前提下，通过生成对抗性边界框（Adversarial bounding boxes）来最小化或最大化分割误差。最后，该研究在涵盖日常场景和医学影像的 10 个数据集上对当前最先进的模型进行了基准测试，为评估模型在真实世界中的稳健性提供了新的工具和见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI2026",
      "pdf_url": "https://arxiv.org/pdf/2601.15123v1",
      "published_date": "2026-01-21 16:02:21 UTC",
      "updated_date": "2026-01-21 16:02:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:41:03.110239+00:00"
    },
    {
      "arxiv_id": "2601.15120v2",
      "title": "Emerging from Ground: Addressing Intent Deviation in Tool-Using Agents via Deriving Real Calls into Virtual Trajectories",
      "title_zh": "破土而出：通过将真实调用转化为虚拟轨迹解决工具使用智能体中的意图偏差",
      "authors": [
        "Qian Xiong",
        "Yuekai Huang",
        "Bo Yang",
        "Yujia Zheng",
        "Tianhao Li",
        "Ziyou Jiang",
        "Zhiyuan Chang",
        "Zhaoyang Li",
        "Huanxiang Feng",
        "Mingyang Li"
      ],
      "abstract": "LLMs have advanced tool-using agents for real-world applications, yet they often lead to unexpected behaviors or results. Beyond obvious failures, the subtle issue of \"intent deviation\" severely hinders reliable evaluation and performance improvement. Existing post-training methods generally leverage either real system samples or virtual data simulated by LLMs. However, the former is costly due to reliance on hand-crafted user requests, while the latter suffers from distribution shift from the real tools in the wild. Additionally, both methods lack negative samples tailored to intent deviation scenarios, hindering effective guidance on preference learning. We introduce RISE, a \"Real-to-Virtual\" method designed to mitigate intent deviation. Anchoring on verified tool primitives, RISE synthesizes virtual trajectories and generates diverse negative samples through mutation on critical parameters. With synthetic data, RISE fine-tunes backbone LLMs via the two-stage training for intent alignment. Evaluation results demonstrate that data synthesized by RISE achieve promising results in eight metrics covering user requires, execution trajectories and agent responses. Integrating with training, RISE achieves an average 35.28% improvement in Acctask (task completion) and 23.27% in Accintent (intent alignment), outperforming SOTA baselines by 1.20--42.09% and 1.17--54.93% respectively.",
      "tldr_zh": "该研究针对大语言模型(LLMs)驱动的工具使用智能体(tool-using agents)中普遍存在的意图偏离(intent deviation)问题，提出了名为RISE的“真实到虚拟”(Real-to-Virtual)方法。RISE以经过验证的工具基元(tool primitives)为基础，通过合成虚拟轨迹并对关键参数进行变异来生成多样化的负样本，解决了现有方法依赖手工样本或存在分布偏移的问题。该框架通过两阶段训练对主干LLMs进行微调，以实现精准的意图对齐(intent alignment)。实验结果显示，RISE在涵盖用户需求、执行轨迹和智能体响应的八项指标上均取得了理想效果。在集成训练后，RISE在任务完成度(Acc_task)和意图对齐度(Acc_intent)上分别实现了35.28%和23.27%的平均提升，性能显著优于现有的SOTA基准模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15120v2",
      "published_date": "2026-01-21 15:58:54 UTC",
      "updated_date": "2026-01-22 12:08:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:40:30.928109+00:00"
    },
    {
      "arxiv_id": "2601.15111v1",
      "title": "Auditing Language Model Unlearning via Information Decomposition",
      "title_zh": "基于信息分解的语言模型遗忘审计",
      "authors": [
        "Anmol Goel",
        "Alan Ritter",
        "Iryna Gurevych"
      ],
      "abstract": "We expose a critical limitation in current approaches to machine unlearning in language models: despite the apparent success of unlearning algorithms, information about the forgotten data remains linearly decodable from internal representations. To systematically assess this discrepancy, we introduce an interpretable, information-theoretic framework for auditing unlearning using Partial Information Decomposition (PID). By comparing model representations before and after unlearning, we decompose the mutual information with the forgotten data into distinct components, formalizing the notions of unlearned and residual knowledge. Our analysis reveals that redundant information, shared across both models, constitutes residual knowledge that persists post-unlearning and correlates with susceptibility to known adversarial reconstruction attacks. Leveraging these insights, we propose a representation-based risk score that can guide abstention on sensitive inputs at inference time, providing a practical mechanism to mitigate privacy leakage. Our work introduces a principled, representation-level audit for unlearning, offering theoretical insight and actionable tools for safer deployment of language models.",
      "tldr_zh": "该研究揭示了当前语言模型机器卸载(machine unlearning)方法的一个关键局限，即尽管卸载算法看似成功，被遗忘数据的信息仍可从模型内部表示中进行线性解码(linearly decodable)。为了系统评估这一差异，作者提出了一个基于偏信息分解(Partial Information Decomposition, PID)的可解释信息论框架来审计卸载效果。通过对比卸载前后的模型表示，该框架将与被遗忘数据的互信息分解为不同组件，从而形式化了已卸载知识与残留知识的概念。研究发现，跨模型共享的冗余信息构成了持久存在的残留知识，并与模型对对抗性重构攻击的易感性显著相关。基于这些见解，研究提出了一种基于表示的风险评分，用于在推理阶段指导模型对敏感输入进行弃权，以缓解隐私泄露风险。这项工作为机器卸载提供了原则性的表示级审计工具，为语言模型的安全部署提供了理论支持和实践指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "EACL 2026 Main",
      "pdf_url": "https://arxiv.org/pdf/2601.15111v1",
      "published_date": "2026-01-21 15:51:19 UTC",
      "updated_date": "2026-01-21 15:51:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:40:32.616250+00:00"
    },
    {
      "arxiv_id": "2601.15109v1",
      "title": "An Agentic Operationalization of DISARM for FIMI Investigation on Social Media",
      "title_zh": "社交媒体 FIMI 调查中 DISARM 框架的智能体化操作化",
      "authors": [
        "Kevin Tseng",
        "Juan Carlos Toledano",
        "Bart De Clerck",
        "Yuliia Dukach",
        "Phil Tinn"
      ],
      "abstract": "The interoperability of data and intelligence across allied partners and their respective end-user groups is considered a foundational enabler to the collective defense capability--both conventional and hybrid--of NATO countries. Foreign Information Manipulation and Interference (FIMI) and related hybrid activities are conducted across various societal dimensions and infospheres, posing an ever greater challenge to the characterization of threats, sustaining situational awareness, and response coordination. Recent advances in AI have further led to the decreasing cost of AI-augmented trolling and interference activities, such as through the generation and amplification of manipulative content. Despite the introduction of the DISARM framework as a standardized metadata and analytical framework for FIMI, operationalizing it at the scale of social media remains a challenge. We propose a framework-agnostic agent-based operationalization of DISARM to investigate FIMI on social media. We develop a multi-agent pipeline in which specialized agentic AI components collaboratively (1) detect candidate manipulative behaviors, and (2) map these behaviors onto standard DISARM taxonomies in a transparent manner. We evaluated the approach on two real-world datasets annotated by domain practitioners. We demonstrate that our approach is effective in scaling the predominantly manual and heavily interpretive work of FIMI analysis, providing a direct contribution to enhancing the situational awareness and data interoperability in the context of operating in media and information-rich settings.",
      "tldr_zh": "该研究针对社交媒体环境下的外国信息操纵与干扰（FIMI）调查，提出了一种基于智能体（agentic）的 DISARM 框架操作化方案。为了应对 AI 驱动的干扰活动日益规模化且成本降低的问题，作者开发了一个多智能体流水线（multi-agent pipeline），通过专门的 AI 智能体组件协作检测潜在的操纵行为，并将其透明地映射到标准的 DISARM 分类体系中。在两个由领域从业者标注的真实数据集上的评估结果表明，该方法能有效扩展原本依赖人工且具有高度解释性的 FIMI 分析工作。这项研究成果显著增强了在复杂信息环境下的态势感知（situational awareness）和数据互操作性，为防御混合威胁提供了重要的技术路径。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15109v1",
      "published_date": "2026-01-21 15:50:13 UTC",
      "updated_date": "2026-01-21 15:50:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:40:43.208183+00:00"
    },
    {
      "arxiv_id": "2601.15086v1",
      "title": "Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning",
      "title_zh": "仅靠记忆留存不足以掌握强化学习中的记忆任务",
      "authors": [
        "Oleg Shchendrigin",
        "Egor Cherepanov",
        "Alexey K. Kovalev",
        "Aleksandr I. Panov"
      ],
      "abstract": "Effective decision-making in the real world depends on memory that is both stable and adaptive: environments change over time, and agents must retain relevant information over long horizons while also updating or overwriting outdated content when circumstances shift. Existing Reinforcement Learning (RL) benchmarks and memory-augmented agents focus primarily on retention, leaving the equally critical ability of memory rewriting largely unexplored. To address this gap, we introduce a benchmark that explicitly tests continual memory updating under partial observability, i.e. the natural setting where an agent must rely on memory rather than current observations, and use it to compare recurrent, transformer-based, and structured memory architectures. Our experiments reveal that classic recurrent models, despite their simplicity, demonstrate greater flexibility and robustness in memory rewriting tasks than modern structured memories, which succeed only under narrow conditions, and transformer-based agents, which often fail beyond trivial retention cases. These findings expose a fundamental limitation of current approaches and emphasize the necessity of memory mechanisms that balance stable retention with adaptive updating. Our work highlights this overlooked challenge, introduces benchmarks to evaluate it, and offers insights for designing future RL agents with explicit and trainable forgetting mechanisms. Code: https://quartz-admirer.github.io/Memory-Rewriting/",
      "tldr_zh": "该研究指出强化学习(Reinforcement Learning)中的有效决策不仅需要记忆保留(Memory Retention)，更需要根据环境变化进行记忆重写(Memory Rewriting)和更新。为此，作者提出了一个针对部分可观测环境下持续记忆更新能力的基准测试，用于评估循环模型、Transformer及结构化记忆架构的表现。实验发现，经典的循环模型在处理记忆重写任务时比现代结构化记忆和Transformer架构表现出更高的灵活性与鲁棒性，后者在复杂保留任务之外往往面临失效。这一结果揭示了当前主流记忆机制在平衡稳定性与适应性方面的局限性。研究强调了开发兼具稳定保留与自适应更新能力的记忆机制的必要性，并为未来设计包含显式可训练遗忘机制(Forgetting Mechanisms)的智能体提供了理论依据与基准工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 6 figures, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.15086v1",
      "published_date": "2026-01-21 15:27:23 UTC",
      "updated_date": "2026-01-21 15:27:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:40:59.970484+00:00"
    },
    {
      "arxiv_id": "2601.15077v1",
      "title": "Multi-Agent Constraint Factorization Reveals Latent Invariant Solution Structure",
      "title_zh": "多智能体约束分解揭示潜在不变解结构",
      "authors": [
        "Christopher Scofield"
      ],
      "abstract": "Multi-agent systems (MAS) composed of large language models often exhibit improved problem-solving performance despite operating on identical information. In this work, we provide a formal explanation for this phenomenon grounded in operator theory and constrained optimization. We model each agent as enforcing a distinct family of validity constraints on a shared solution state, and show that a MAS implements a factorized composition of constraint-enforcement operators. Under mild conditions, these dynamics converge to invariant solution sets defined by the intersection of agent constraint sets. Such invariant structures are generally not dynamically accessible to a single agent applying all constraints simultaneously, even when expressive capacity and information are identical. We extend this result from exact constraint enforcement to soft constraints via proximal operators, and apply the formalism to contemporary text-based dialog systems.",
      "tldr_zh": "该研究针对由 Large Language Models 组成的多智能体系统 (Multi-agent systems, MAS) 在处理相同信息时表现优于单智能体系统的现象，提供了一种基于算子理论 (operator theory) 和约束优化 (constrained optimization) 的正式理论解释。研究者将每个智能体建模为对共享解状态施加特定有效性约束的执行者，并证明了 MAS 实际上实现了约束执行算子 (constraint-enforcement operators) 的分解组合。研究发现，在温和条件下，这些动力学过程会收敛到由各智能体约束集交集定义的不变解集 (invariant solution sets)。即便在表达能力和信息完全一致的情况下，这种不变结构通常也无法通过单个智能体同时应用所有约束来动态获取。该工作进一步将结论从精确约束执行扩展到通过近端算子 (proximal operators) 实现的软约束，并将该形式化框架应用于当代文本对话系统。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15077v1",
      "published_date": "2026-01-21 15:23:04 UTC",
      "updated_date": "2026-01-21 15:23:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:40:43.608383+00:00"
    },
    {
      "arxiv_id": "2601.15075v1",
      "title": "The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution",
      "title_zh": "行为背后的动因：通过智能体归因揭示内部驱动因素",
      "authors": [
        "Chen Qian",
        "Peng Wang",
        "Dongrui Liu",
        "Junyao Yang",
        "Dadi Guo",
        "Ling Tang",
        "Jilin Mei",
        "Qihan Ren",
        "Shuai Shao",
        "Yong Liu",
        "Jie Fu",
        "Jing Shao",
        "Xia Hu"
      ],
      "abstract": "Large Language Model (LLM)-based agents are widely used in real-world applications such as customer service, web navigation, and software engineering. As these systems become more autonomous and are deployed at scale, understanding why an agent takes a particular action becomes increasingly important for accountability and governance. However, existing research predominantly focuses on \\textit{failure attribution} to localize explicit errors in unsuccessful trajectories, which is insufficient for explaining the reasoning behind agent behaviors. To bridge this gap, we propose a novel framework for \\textbf{general agentic attribution}, designed to identify the internal factors driving agent actions regardless of the task outcome. Our framework operates hierarchically to manage the complexity of agent interactions. Specifically, at the \\textit{component level}, we employ temporal likelihood dynamics to identify critical interaction steps; then at the \\textit{sentence level}, we refine this localization using perturbation-based analysis to isolate the specific textual evidence. We validate our framework across a diverse suite of agentic scenarios, including standard tool use and subtle reliability risks like memory-induced bias. Experimental results demonstrate that the proposed framework reliably pinpoints pivotal historical events and sentences behind the agent behavior, offering a critical step toward safer and more accountable agentic systems.",
      "tldr_zh": "该研究针对大语言模型 (LLM) 智能体在广泛应用中缺乏决策解释性的问题，提出了一个通用的智能体归因 (general agentic attribution) 框架，旨在揭示驱动智能体行为的内部因素而非仅局限于失败归因 (failure attribution)。该框架采用层次化架构，在组件级别 (component level) 利用时间似然动态 (temporal likelihood dynamics) 识别关键交互步骤，并在句子级别 (sentence level) 通过基于扰动的分析 (perturbation-based analysis) 精确隔离关键文本证据。研究在工具使用和内存诱导偏差 (memory-induced bias) 等多样化场景下进行了验证，结果证明该框架能可靠地定位决定智能体行为的关键历史事件和语句。这一成果为提高智能体系统的问责制与安全性提供了重要技术支撑，是迈向可信智能体系统的重要一步。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15075v1",
      "published_date": "2026-01-21 15:22:21 UTC",
      "updated_date": "2026-01-21 15:22:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:40:47.032555+00:00"
    },
    {
      "arxiv_id": "2601.15064v1",
      "title": "Incentive-Tuning: Understanding and Designing Incentives for Empirical Human-AI Decision-Making Studies",
      "title_zh": "Incentive-Tuning：人机协作决策实证研究中的激励机制理解与设计",
      "authors": [
        "Simran Kaur",
        "Sara Salimzadeh",
        "Ujwal Gadiraju"
      ],
      "abstract": "AI has revolutionised decision-making across various fields. Yet human judgement remains paramount for high-stakes decision-making. This has fueled explorations of collaborative decision-making between humans and AI systems, aiming to leverage the strengths of both. To explore this dynamic, researchers conduct empirical studies, investigating how humans use AI assistance for decision-making and how this collaboration impacts results. A critical aspect of conducting these studies is the role of participants, often recruited through crowdsourcing platforms. The validity of these studies hinges on the behaviours of the participants, hence effective incentives that can potentially affect these behaviours are a key part of designing and executing these studies. In this work, we aim to address the critical role of incentive design for conducting empirical human-AI decision-making studies, focusing on understanding, designing, and documenting incentive schemes. Through a thematic review of existing research, we explored the current practices, challenges, and opportunities associated with incentive design for human-AI decision-making empirical studies. We identified recurring patterns, or themes, such as what comprises the components of an incentive scheme, how incentive schemes are manipulated by researchers, and the impact they can have on research outcomes. Leveraging the acquired understanding, we curated a set of guidelines to aid researchers in designing effective incentive schemes for their studies, called the Incentive-Tuning Framework, outlining how researchers can undertake, reflect on, and document the incentive design process. By advocating for a standardised yet flexible approach to incentive design and contributing valuable insights along with practical tools, we hope to pave the way for more reliable and generalizable knowledge in the field of human-AI decision-making.",
      "tldr_zh": "该研究探讨了激励机制设计（incentive design）在人机决策（Human-AI decision-making）实证研究中的核心作用，强调了参与者行为对研究有效性的重要影响。通过对现有研究进行主题综述（thematic review），作者识别了激励方案的组成部分、操纵方式及其对研究结果的影响等重复性模式。基于这些见解，研究提出了名为 Incentive-Tuning Framework 的框架，为研究人员提供了一套关于如何实施、反思和记录激励设计过程的系统性准则。该框架倡导一种标准化且灵活的激励设计方法，并提供了实用的工具以增强研究结果的可靠性。通过规范激励机制的设计与文档记录，该项工作旨在推动人机协作决策领域产出更具可泛化性（generalizability）的科研知识。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.GT",
        "cs.IR"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15064v1",
      "published_date": "2026-01-21 15:10:46 UTC",
      "updated_date": "2026-01-21 15:10:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:41:17.976826+00:00"
    },
    {
      "arxiv_id": "2601.15061v1",
      "title": "Differential Privacy Image Generation with Reconstruction Loss and Noise Injection Using an Error Feedback SGD",
      "title_zh": "基于误差反馈随机梯度下降并结合重构损失与噪声注入的差分隐私图像生成",
      "authors": [
        "Qiwei Ma",
        "Jun Zhang"
      ],
      "abstract": "Traditional data masking techniques such as anonymization cannot achieve the expected privacy protection while ensuring data utility for privacy-preserving machine learning. Synthetic data plays an increasingly important role as it generates a large number of training samples and prevents information leakage in real data. The existing methods suffer from the repeating trade-off processes between privacy and utility. We propose a novel framework for differential privacy generation, which employs an Error Feedback Stochastic Gradient Descent(EFSGD) method and introduces a reconstruction loss and noise injection mechanism into the training process. We generate images with higher quality and usability under the same privacy budget as the related work. Extensive experiments demonstrate the effectiveness and generalization of our proposed framework for both grayscale and RGB images. We achieve state-of-the-art results over almost all metrics on three benchmarks: MNIST, Fashion-MNIST, and CelebA.",
      "tldr_zh": "该研究针对传统数据脱敏技术在隐私保护与数据可用性之间难以平衡的问题，提出了一种新型的Differential Privacy图像生成框架。该框架引入了Error Feedback Stochastic Gradient Descent (EFSGD) 方法，并在训练过程中结合了reconstruction loss和noise injection机制。与现有研究相比，该方法在相同的隐私预算下能够生成质量更高且可用性更强的图像。在MNIST、Fashion-MNIST和CelebA基准数据集上的广泛实验证明了该框架在处理灰度图和RGB图像时的有效性与泛化能力。实验结果显示，该方法在几乎所有指标上均达到了state-of-the-art水平，有效解决了合成数据生成中的隐私与效用权衡挑战。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15061v1",
      "published_date": "2026-01-21 15:07:33 UTC",
      "updated_date": "2026-01-21 15:07:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:41:22.070695+00:00"
    },
    {
      "arxiv_id": "2601.15059v1",
      "title": "The Responsibility Vacuum: Organizational Failure in Scaled Agent Systems",
      "title_zh": "责任真空：大规模智能体系统中的组织失效",
      "authors": [
        "Oleg Romanchuk",
        "Roman Bondar"
      ],
      "abstract": "Modern CI/CD pipelines integrating agent-generated code exhibit a structural failure in responsibility attribution. Decisions are executed through formally correct approval processes, yet no entity possesses both the authority to approve those decisions and the epistemic capacity to meaningfully understand their basis.\n  We define this condition as responsibility vacuum: a state in which decisions occur, but responsibility cannot be attributed because authority and verification capacity do not coincide. We show that this is not a process deviation or technical defect, but a structural property of deployments where decision generation throughput exceeds bounded human verification capacity.\n  We identify a scaling limit under standard deployment assumptions, including parallel agent generation, CI-based validation, and individualized human approval gates. Beyond a throughput threshold, verification ceases to function as a decision criterion and is replaced by ritualized approval based on proxy signals. Personalized responsibility becomes structurally unattainable in this regime.\n  We further characterize a CI amplification dynamic, whereby increasing automated validation coverage raises proxy signal density without restoring human capacity. Under fixed time and attention constraints, this accelerates cognitive offloading in the broad sense and widens the gap between formal approval and epistemic understanding. Additional automation therefore amplifies, rather than mitigates, the responsibility vacuum.\n  We conclude that unless organizations explicitly redesign decision boundaries or reassign responsibility away from individual decisions toward batch- or system-level ownership, responsibility vacuum remains an invisible but persistent failure mode in scaled agent deployments.",
      "tldr_zh": "该研究探讨了在集成智能体生成代码的现代 CI/CD 流水中出现的 Responsibility Vacuum (责任真空) 现象，即决策产出与人类验证能力脱节导致责任无法归属的结构性失效。研究指出，当智能体的决策吞吐量超过有限的人类验证能力时，验证过程将从实质性的决策标准转变为基于 Proxy Signals (代理信号) 的仪式化审批，导致个人责任在结构上变得不可行。通过分析 CI Amplification (CI 放大) 动态，研究发现增加自动化验证反而会加速 Cognitive Offloading (认知减负)，从而进一步扩大正式批准与真实认知理解之间的鸿沟。论文强调，Responsibility Vacuum 并非流程偏差或技术缺陷，而是规模化智能体部署中决策生成超过人类验证阈值的固有属性。研究最后建议，除非组织重新设计决策边界，或将责任从个体决策转向 System-level Ownership (系统级所有权)，否则这种失效模式将持续存在。",
      "categories": [
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15059v1",
      "published_date": "2026-01-21 15:05:27 UTC",
      "updated_date": "2026-01-21 15:05:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:41:34.788696+00:00"
    },
    {
      "arxiv_id": "2601.15042v1",
      "title": "Federated Transformer-GNN for Privacy-Preserving Brain Tumor Localization with Modality-Level Explainability",
      "title_zh": "联邦 Transformer-GNN：具有模态级可解释性的隐私保护脑肿瘤定位",
      "authors": [
        "Andrea Protani",
        "Riccardo Taiello",
        "Marc Molina Van Den Bosch",
        "Luigi Serio"
      ],
      "abstract": "Deep learning models for brain tumor analysis require large and diverse datasets that are often siloed across healthcare institutions due to privacy regulations. We present a federated learning framework for brain tumor localization that enables multi-institutional collaboration without sharing sensitive patient data. Our method extends a hybrid Transformer-Graph Neural Network architecture derived from prior decoder-free supervoxel GNNs and is deployed within CAFEIN\\textsuperscript{\\textregistered}, CERN's federated learning platform designed for healthcare environments. We provide an explainability analysis through Transformer attention mechanisms that reveals which MRI modalities drive the model predictions. Experiments on the BraTS dataset demonstrate a key finding: while isolated training on individual client data triggers early stopping well before reaching full training capacity, federated learning enables continued model improvement by leveraging distributed data, ultimately matching centralized performance. This result provides strong justification for federated learning when dealing with complex tasks and high-dimensional input data, as aggregating knowledge from multiple institutions significantly benefits the learning process. Our explainability analysis, validated through rigorous statistical testing on the full test set (paired t-tests with Bonferroni correction), reveals that deeper network layers significantly increase attention to T2 and FLAIR modalities ($p<0.001$, Cohen's $d$=1.50), aligning with clinical practice.",
      "tldr_zh": "该研究提出了一种联邦学习(Federated Learning)框架，用于保护隐私的脑肿瘤定位，并采用了Transformer-GNN混合架构。该方法部署在CERN的CAFEIN平台上，实现了在不共享敏感数据的情况下进行多机构协作。通过Transformer注意机制(Attention Mechanism)进行的解释性分析揭示了不同MRI模态对模型预测的驱动作用。实验结果显示，相较于因数据受限而容易触发提前停止(Early Stopping)的单机构隔离训练，联邦学习能有效汇集分布式知识，使模型性能达到与集中式训练(Centralized Performance)相当的水平。此外，研究通过统计检验验证了模型在深层网络中对T2和FLAIR模态的关注度显著提升，这在临床医学实践上具有高度的一致性与可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15042v1",
      "published_date": "2026-01-21 14:46:00 UTC",
      "updated_date": "2026-01-21 14:46:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:41:34.406445+00:00"
    },
    {
      "arxiv_id": "2601.15038v1",
      "title": "A Curriculum-Based Deep Reinforcement Learning Framework for the Electric Vehicle Routing Problem",
      "title_zh": "基于课程学习的电动汽车车辆路径问题深度强化学习框架",
      "authors": [
        "Mertcan Daysalilar",
        "Fuat Uyguroglu",
        "Gabriel Nicolosi",
        "Adam Meyers"
      ],
      "abstract": "The electric vehicle routing problem with time windows (EVRPTW) is a complex optimization problem in sustainable logistics, where routing decisions must minimize total travel distance, fleet size, and battery usage while satisfying strict customer time constraints. Although deep reinforcement learning (DRL) has shown great potential as an alternative to classical heuristics and exact solvers, existing DRL models often struggle to maintain training stability-failing to converge or generalize when constraints are dense. In this study, we propose a curriculum-based deep reinforcement learning (CB-DRL) framework designed to resolve this instability. The framework utilizes a structured three-phase curriculum that gradually increases problem complexity: the agent first learns distance and fleet optimization (Phase A), then battery management (Phase B), and finally the full EVRPTW (Phase C). To ensure stable learning across phases, the framework employs a modified proximal policy optimization algorithm with phase-specific hyperparameters, value and advantage clipping, and adaptive learning-rate scheduling. The policy network is built upon a heterogeneous graph attention encoder enhanced by global-local attention and feature-wise linear modulation. This specialized architecture explicitly captures the distinct properties of depots, customers, and charging stations. Trained exclusively on small instances with N=10 customers, the model demonstrates robust generalization to unseen instances ranging from N=5 to N=100, significantly outperforming standard baselines on medium-scale problems. Experimental results confirm that this curriculum-guided approach achieves high feasibility rates and competitive solution quality on out-of-distribution instances where standard DRL baselines fail, effectively bridging the gap between neural speed and operational reliability.",
      "tldr_zh": "该研究提出了一种基于课程学习的深度强化学习（Curriculum-Based Deep Reinforcement Learning，CB-DRL）框架，旨在解决带时间窗的电动汽车路径规划问题（EVRPTW）中常见的训练不稳定和收敛困难。该框架通过一个结构化的三阶段课程，由浅入深地训练智能体处理距离优化、电池管理及复杂的全约束任务，并结合改进的近端策略优化（Proximal Policy Optimization）算法确保学习稳定性。其核心策略网络采用了增强的异构图注意力编码器，通过全局-局部注意力和特征线性调制（Feature-wise Linear Modulation）技术，有效捕捉配送中心、客户及充电站的异构属性。实验表明，该模型在仅使用10个客户规模的实例训练后，即可在5至100个客户的测试中展现出强大的泛化能力，表现显著优于标准基准模型。最终，CB-DRL 在分布外（out-of-distribution）实例上实现了极高的可行率和解质量，成功弥合了神经网络求解速度与实际运行可靠性之间的鸿沟。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15038v1",
      "published_date": "2026-01-21 14:42:33 UTC",
      "updated_date": "2026-01-21 14:42:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:41:43.844439+00:00"
    },
    {
      "arxiv_id": "2601.15037v1",
      "title": "Knowledge Restoration-driven Prompt Optimization: Unlocking LLM Potential for Open-Domain Relational Triplet Extraction",
      "title_zh": "知识还原驱动的提示优化：挖掘 LLM 在开放域关系三元组抽取中的潜力",
      "authors": [
        "Xiaonan Jing",
        "Gongqing Wu",
        "Xingrui Zhuo",
        "Lang Sun",
        "Jiapu Wang"
      ],
      "abstract": "Open-domain Relational Triplet Extraction (ORTE) is the foundation for mining structured knowledge without predefined schemas. Despite the impressive in-context learning capabilities of Large Language Models (LLMs), existing methods are hindered by their reliance on static, heuristic-driven prompting strategies. Due to the lack of reflection mechanisms required to internalize erroneous signals, these methods exhibit vulnerability in semantic ambiguity, often making erroneous extraction patterns permanent. To address this bottleneck, we propose a Knowledge Reconstruction-driven Prompt Optimization (KRPO) framework to assist LLMs in continuously improving their extraction capabilities for complex ORTE task flows. Specifically, we design a self-evaluation mechanism based on knowledge restoration, which provides intrinsic feedback signals by projecting structured triplets into semantic consistency scores. Subsequently, we propose a prompt optimizer based on a textual gradient that can internalize historical experiences to iteratively optimize prompts, which can better guide LLMs to handle subsequent extraction tasks. Furthermore, to alleviate relation redundancy, we design a relation canonicalization memory that collects representative relations and provides semantically distinct schemas for the triplets. Extensive experiments across three datasets show that KRPO significantly outperforms strong baselines in the extraction F1 score.",
      "tldr_zh": "该研究针对开放域关系三元组提取 (ORTE) 中大语言模型 (LLMs) 依赖静态提示且缺乏错误反思机制的问题，提出了 KRPO (Knowledge Reconstruction-driven Prompt Optimization) 框架。该框架通过设计基于知识修复 (Knowledge Restoration) 的自我评估机制，将结构化三元组映射为语义一致性分数以提供内在反馈信号。随后，利用基于文本梯度 (Textual Gradient) 的提示优化器迭代内化历史经验，从而更精准地引导 LLMs 执行提取任务。此外，研究还引入了关系规范化记忆 (Relation Canonicalization Memory) 来收集代表性关系并提供语义独特的 Schema，有效缓解了关系冗余问题。在三个数据集上的广泛实验表明，KRPO 在提取 F1 分数上显著优于现有的强基准模型，成功解锁了 LLMs 在处理复杂 ORTE 任务流中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15037v1",
      "published_date": "2026-01-21 14:42:13 UTC",
      "updated_date": "2026-01-21 14:42:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:41:41.035898+00:00"
    },
    {
      "arxiv_id": "2601.15034v1",
      "title": "Visual and Cognitive Demands of a Large Language Model-Powered In-vehicle Conversational Agent",
      "title_zh": "大语言模型驱动的车载对话智能体的视觉与认知需求",
      "authors": [
        "Chris Monk",
        "Allegra Ayala",
        "Christine S. P. Yu",
        "Gregory M. Fitch",
        "Dara Gruber"
      ],
      "abstract": "Driver distraction remains a leading contributor to motor vehicle crashes, necessitating rigorous evaluation of new in-vehicle technologies. This study assessed the visual and cognitive demands associated with an advanced Large Language Model (LLM) conversational agent (Gemini Live) during on-road driving, comparing it against handsfree phone calls, visual turn-by-turn guidance (low load baseline), and the Operation Span (OSPAN) task (high load anchor). Thirty-two licensed drivers completed five secondary tasks while visual and cognitive demands were measured using the Detection Response Task (DRT) for cognitive load, eye-tracking for visual attention, and subjective workload ratings. Results indicated that Gemini Live interactions (both single-turn and multi-turn) and hands-free phone calls shared similar levels of cognitive load, between that of visual turn-by-turn guidance and OSPAN. Exploratory analysis showed that cognitive load remained stable across extended multi-turn conversations. All tasks maintained mean glance durations well below the well-established 2-second safety threshold, confirming low visual demand. Furthermore, drivers consistently dedicated longer glances to the roadway between brief off-road glances toward the device during task completion, particularly during voice-based interactions, rendering longer total-eyes-off-road time findings less consequential. Subjective ratings mirrored objective data, with participants reporting low effort, demands, and perceived distraction for Gemini Live. These findings demonstrate that advanced LLM conversational agents, when implemented via voice interfaces, impose cognitive and visual demands comparable to established, low-risk hands-free benchmarks, supporting their safe deployment in the driving environment.",
      "tldr_zh": "该研究评估了基于大语言模型(Large Language Model)的高级车载对话智能体(Gemini Live)在实际道路驾驶中的视觉和认知需求。通过与免提电话(hands-free phone calls)、视觉导航(visual turn-by-turn guidance)及运算广度任务(OSPAN)进行对比，研究利用探测反应任务(DRT)和眼动追踪(eye-tracking)技术测量了32名驾驶员的负荷。实验结果显示，Gemini Live交互产生的认知负荷与免提电话相近，且在长时多轮对话中保持稳定。在视觉需求方面，所有任务的平均扫视时长均远低于2秒的安全阈值，显示出较低的视觉干扰。驾驶员的主观评分同样反映出较低的努力程度和分心感知。综上所述，采用语音接口的先进LLM对话智能体在视觉和认知需求上与已有的低风险免提基准相当，支持其在驾驶环境中的安全部署。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15034v1",
      "published_date": "2026-01-21 14:37:05 UTC",
      "updated_date": "2026-01-21 14:37:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:42:31.088266+00:00"
    },
    {
      "arxiv_id": "2601.15029v1",
      "title": "Emergent, not Immanent: A Baradian Reading of Explainable AI",
      "title_zh": "涌现而非内在：对可解释人工智能的 Barad 式解读",
      "authors": [
        "Fabio Morreale",
        "Joan Serrà",
        "Yuki Mistufuji"
      ],
      "abstract": "Explainable AI (XAI) is frequently positioned as a technical problem of revealing the inner workings of an AI model. This position is affected by unexamined onto-epistemological assumptions: meaning is treated as immanent to the model, the explainer is positioned outside the system, and a causal structure is presumed recoverable through computational techniques. In this paper, we draw on Barad's agential realism to develop an alternative onto-epistemology of XAI. We propose that interpretations are material-discursive performances that emerge from situated entanglements of the AI model with humans, context, and the interpretative apparatus. To develop this position, we read a comprehensive set of XAI methods through agential realism and reveal the assumptions and limitations that underpin several of these methods. We then articulate the framework's ethical dimension and propose design directions for XAI interfaces that support emergent interpretation, using a speculative text-to-music interface as a case study.",
      "tldr_zh": "该研究对可解释人工智能(Explainable AI, XAI)进行了批判性审视，指出当前将其视为揭示模型内部机制的技术手段这一立场，受限于意义是模型固有(immanent)的等本体认识论假设。作者借鉴Barad的代理现实主义(agential realism)提出了一种替代框架，认为解释并非模型内部信息的简单提取，而是由模型、人类、背景及解释设备在情境纠缠(situated entanglements)中共同生成的物质-话语表现(material-discursive performances)。通过对现有XAI方法的系统性梳理，该研究揭示了主流方法背后的假设与局限性，并进一步探讨了该框架的伦理维度。论文为支持涌现性(emergent)解释的XAI接口指明了设计方向，并以文本转音乐(text-to-music)界面作为案例研究，强调了解释作为一种动态生成过程的独特性。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at CHI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.15029v1",
      "published_date": "2026-01-21 14:32:40 UTC",
      "updated_date": "2026-01-21 14:32:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:41:51.888902+00:00"
    },
    {
      "arxiv_id": "2601.14994v1",
      "title": "Obscuring Data Contamination Through Translation: Evidence from Arabic Corpora",
      "title_zh": "通过翻译掩盖数据污染：来自阿拉伯语语料库的证据",
      "authors": [
        "Chaymaa Abbas",
        "Nour Shamaa",
        "Mariette Awad"
      ],
      "abstract": "Data contamination undermines the validity of Large Language Model evaluation by enabling models to rely on memorized benchmark content rather than true generalization. While prior work has proposed contamination detection methods, these approaches are largely limited to English benchmarks, leaving multilingual contamination poorly understood. In this work, we investigate contamination dynamics in multilingual settings by fine-tuning several open-weight LLMs on varying proportions of Arabic datasets and evaluating them on original English benchmarks. To detect memorization, we extend the Tested Slot Guessing method with a choice-reordering strategy and incorporate Min-K% probability analysis, capturing both behavioral and distributional contamination signals.\n  Our results show that translation into Arabic suppresses conventional contamination indicators, yet models still benefit from exposure to contaminated data, particularly those with stronger Arabic capabilities. This effect is consistently reflected in rising Mink% scores and increased cross-lingual answer consistency as contamination levels grow. To address this blind spot, we propose Translation-Aware Contamination Detection, which identifies contamination by comparing signals across multiple translated benchmark variants rather than English alone. The Translation-Aware Contamination Detection reliably exposes contamination even when English-only methods fail. Together, our findings highlight the need for multilingual, translation-aware evaluation pipelines to ensure fair, transparent, and reproducible assessment of LLMs.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)评估中的数据污染问题，特别是通过翻译手段(如翻译为阿拉伯语)来掩盖污染迹象的现象。作者通过在不同比例的阿拉伯语语料库上微调模型，并利用扩展后的Tested Slot Guessing方法以及Min-K%概率分析，深入研究了多语言环境下的污染动态。实验结果表明，尽管将基准测试翻译成阿拉伯语会抑制传统的污染检测指标，但模型仍能从这些污染数据中获益，且这种效应在Min-K%评分和跨语言答案一致性上得到了体现。针对此问题，研究提出了一种Translation-Aware Contamination Detection方法，通过对比多个翻译变体中的信号来识别污染。该方法能够有效揭示英文检测手段无法发现的隐蔽污染，强调了建立多语言、具备翻译感知能力的评估体系对于确保模型评估公平、透明和可重复的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14994v1",
      "published_date": "2026-01-21 13:53:04 UTC",
      "updated_date": "2026-01-21 13:53:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:42:05.866279+00:00"
    },
    {
      "arxiv_id": "2601.14982v1",
      "title": "Interoperable Architecture for Digital Identity Delegation for AI Agents with Blockchain Integration",
      "title_zh": "集成区块链的 AI 智能体数字身份委托互操作架构",
      "authors": [
        "David Ricardo Saavedra"
      ],
      "abstract": "Verifiable delegation in digital identity systems remains unresolved across centralized, federated, and self-sovereign identity (SSI) environments, particularly where both human users and autonomous AI agents must exercise and transfer authority without exposing primary credentials or private keys. We introduce a unified framework that enables bounded, auditable, and least-privilege delegation across heterogeneous identity ecosystems. The framework includes four key elements: Delegation Grants (DGs), first-class authorization artefacts that encode revocable transfers of authority with enforced scope reduction; a Canonical Verification Context (CVC) that normalizes verification requests into a single structured representation independent of protocols or credential formats; a layered reference architecture that separates trust anchoring, credential and proof validation, policy evaluation, and protocol mediation via a Trust Gateway; and an explicit treatment of blockchain anchoring as an optional integrity layer rather than a structural dependency. Together, these elements advance interoperable delegation and auditability and provide a foundation for future standardization, implementation, and integration of autonomous agents into trusted digital identity infrastructures.",
      "tldr_zh": "该研究针对中心化、联邦式及自主主权身份（SSI）环境中数字身份的可验证委托（Verifiable delegation）难题，提出了一种支持人类用户与自主AI智能体（AI agents）跨异构生态系统安全转移权限的统一框架。该框架由四个核心要素组成：一是通过授权凭证（Delegation Grants, DGs）实现可撤销且限定范围的权限转移；二是利用规范验证上下文（Canonical Verification Context, CVC）将复杂的验证请求标准化，实现协议无关的表示；三是采用分层参考架构，通过信任网关（Trust Gateway）解耦信任锚定、凭证校验与策略评估；四是将区块链锚定（Blockchain anchoring）作为可选的完整性层，以增强系统的审计能力。这一方案不仅实现了有界且符合最小权限原则的权限委托，还为未来自主智能体大规模集成到可信数字身份基础设施中提供了标准化的互操作性基础。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "19 pages, 4 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.14982v1",
      "published_date": "2026-01-21 13:29:23 UTC",
      "updated_date": "2026-01-21 13:29:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:42:19.942472+00:00"
    },
    {
      "arxiv_id": "2601.14973v1",
      "title": "HumanDiffusion: A Vision-Based Diffusion Trajectory Planner with Human-Conditioned Goals for Search and Rescue UAV",
      "title_zh": "HumanDiffusion：面向搜救无人机的以人为条件目标的视觉扩散轨迹规划器",
      "authors": [
        "Faryal Batool",
        "Iana Zhura",
        "Valerii Serpiva",
        "Roohan Ahmed Khan",
        "Ivan Valuev",
        "Issatay Tokmurziyev",
        "Dzmitry Tsetserukou"
      ],
      "abstract": "Reliable human--robot collaboration in emergency scenarios requires autonomous systems that can detect humans, infer navigation goals, and operate safely in dynamic environments. This paper presents HumanDiffusion, a lightweight image-conditioned diffusion planner that generates human-aware navigation trajectories directly from RGB imagery. The system combines YOLO-11--based human detection with diffusion-driven trajectory generation, enabling a quadrotor to approach a target person and deliver medical assistance without relying on prior maps or computationally intensive planning pipelines. Trajectories are predicted in pixel space, ensuring smooth motion and a consistent safety margin around humans. We evaluate HumanDiffusion in simulation and real-world indoor mock-disaster scenarios. On a 300-sample test set, the model achieves a mean squared error of 0.02 in pixel-space trajectory reconstruction. Real-world experiments demonstrate an overall mission success rate of 80% across accident-response and search-and-locate tasks with partial occlusions. These results indicate that human-conditioned diffusion planning offers a practical and robust solution for human-aware UAV navigation in time-critical assistance settings.",
      "tldr_zh": "该研究提出了HumanDiffusion，一种基于视觉的轻量级扩散轨迹规划器(diffusion planner)，旨在提升搜救无人机在动态环境中的人机协作能力。该系统将基于YOLO-11的人体检测与扩散驱动的轨迹生成相结合，能够直接从RGB图像中生成具有人体感知能力的导航轨迹。HumanDiffusion在像素空间(pixel space)内预测轨迹，从而确保平滑的运动并在人体周围保持一致的安全边际，且无需依赖先验地图或高计算量的规划管线。研究人员在仿真环境和真实的室内模拟灾难场景中对该模型进行了评估，涵盖了事故响应和搜索定位等任务。实验结果显示，该模型在像素空间轨迹重建中的均方误差(MSE)仅为0.02，并在存在部分遮挡的真实世界任务中实现了80%的总任务成功率。该成果证明了以人为条件的扩散规划(human-conditioned diffusion planning)能为时间敏感的搜救辅助场景提供实用且鲁棒的人体感知导航解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper has been accepted at HRI, Late Breaking Report, 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.14973v1",
      "published_date": "2026-01-21 13:22:22 UTC",
      "updated_date": "2026-01-21 13:22:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:44:45.136720+00:00"
    },
    {
      "arxiv_id": "2601.14968v1",
      "title": "InstructTime++: Time Series Classification with Multimodal Language Modeling via Implicit Feature Enhancement",
      "title_zh": "InstructTime++：基于隐式特征增强的多模态语言建模时间序列分类",
      "authors": [
        "Mingyue Cheng",
        "Xiaoyu Tao",
        "Huajian Zhang",
        "Qi Liu",
        "Enhong Chen"
      ],
      "abstract": "Most existing time series classification methods adopt a discriminative paradigm that maps input sequences directly to one-hot encoded class labels. While effective, this paradigm struggles to incorporate contextual features and fails to capture semantic relationships among classes. To address these limitations, we propose InstructTime, a novel framework that reformulates time series classification as a multimodal generative task. Specifically, continuous numerical sequences, contextual textual features, and task instructions are treated as multimodal inputs, while class labels are generated as textual outputs by tuned language models. To bridge the modality gap, InstructTime introduces a time series discretization module that converts continuous sequences into discrete temporal tokens, together with an alignment projection layer and a generative self-supervised pre-training strategy to enhance cross-modal representation alignment. Building upon this framework, we further propose InstructTime++, which extends InstructTime by incorporating implicit feature modeling to compensate for the limited inductive bias of language models. InstructTime++ leverages specialized toolkits to mine informative implicit patterns from raw time series and contextual inputs, including statistical feature extraction and vision-language-based image captioning, and translates them into textual descriptions for seamless integration. Extensive experiments on multiple benchmark datasets demonstrate the superior performance of InstructTime++.",
      "tldr_zh": "该研究提出了 InstructTime++，这是一个通过多模态语言建模和隐式特征增强来进行 Time Series Classification 的创新框架。针对传统判别式范式难以利用上下文特征和捕获类别间语义关系的问题，该方法将分类任务重新构建为多模态生成任务，将连续数值序列、文本上下文和任务指令共同作为输入。核心组件 InstructTime 引入了时间序列离散化模块(Time Series Discretization)和对齐投影层，通过生成式自监督预训练策略实现跨模态表征对齐。在此基础上，InstructTime++ 进一步引入隐式特征建模以补偿语言模型的归纳偏置(Inductive Bias)限制，利用专门工具包提取统计特征和基于视觉语言的图像描述(Image Captioning)并将其转化为文本集成。在多个基准数据集上的广泛实验证明，InstructTime++ 展现出了优于现有方法的卓越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14968v1",
      "published_date": "2026-01-21 13:12:23 UTC",
      "updated_date": "2026-01-21 13:12:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:43:49.210079+00:00"
    },
    {
      "arxiv_id": "2601.14958v1",
      "title": "A Comprehensive Benchmark of Language Models on Unicode and Romanized Sinhala",
      "title_zh": "Unicode 及罗马化僧伽罗语语言模型的全面基准测试",
      "authors": [
        "Minuri Rajapakse",
        "Ruvan Weerasinghe"
      ],
      "abstract": "The performance of Language Models (LMs) on lower-resource, morphologically rich languages like Sinhala remains under-explored, particularly for Romanized Sinhala, which is prevalent in digital communication. This paper presents a comprehensive benchmark of modern LMs on a diverse corpus of Unicode and Romanized Sinhala. We evaluate open-source models using perplexity, a measure of how well a model predicts a text, and leading closed-source models via a qualitative analysis of sentence completion. Our findings reveal that the Mistral-Nemo-Base-2407 model achieves the strongest predictive performance on Unicode text and the Mistral-7B-v0.3 model for Romanized text. The results also highlight the strong all-around performance of the Llama-3.1-8B model for both scripts. Furthermore, a significant performance disparity exists among closed-source models: Gemini-1.5-pro and DeepSeek excel at Unicode generation, whereas Claude-3.5-Sonnet is superior at handling Romanized text. These results provide an essential guide for practitioners selecting models for Sinhala-specific applications and highlight the critical role of training data in handling script variations.",
      "tldr_zh": "该研究针对僧伽罗语 (Sinhala) 这种资源匮乏且形态复杂的语言，特别是社交媒体中常用的罗马化 (Romanized) 形式，对现代语言模型 (Language Models) 进行了全面的基准测试。研究通过困惑度 (Perplexity) 评估开源模型，并对领先的闭源模型进行了句子补全的定性分析。实验发现 Mistral-Nemo-Base-2407 在 Unicode 文本上表现最佳，Mistral-7B-v0.3 在 Romanized 文本上领先，而 Llama-3.1-8B 在两种脚本下均表现稳健。在闭源模型对比中，Gemini-1.5-pro 和 DeepSeek 擅长 Unicode 生成，而 Claude-3.5-Sonnet 在处理 Romanized 文本方面更胜一筹。这项工作为僧伽罗语特定应用的模型选择提供了实践指南，并揭示了训练数据在应对脚本变体中的决定性作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 1 figure, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.14958v1",
      "published_date": "2026-01-21 12:58:46 UTC",
      "updated_date": "2026-01-21 12:58:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:43:59.617973+00:00"
    },
    {
      "arxiv_id": "2601.14955v1",
      "title": "Multi-Behavior Sequential Modeling with Transition-Aware Graph Attention Network for E-Commerce Recommendation",
      "title_zh": "面向电商推荐的基于转移感知图注意力网络的多行为序列建模",
      "authors": [
        "Hanqi Jin",
        "Gaoming Yang",
        "Zhangming Chan",
        "Yapeng Yuan",
        "Longbin Li",
        "Fei Sun",
        "Yeqiu Yang",
        "Jian Wu",
        "Yuning Jiang",
        "Bo Zheng"
      ],
      "abstract": "User interactions on e-commerce platforms are inherently diverse, involving behaviors such as clicking, favoriting, adding to cart, and purchasing. The transitions between these behaviors offer valuable insights into user-item interactions, serving as a key signal for understanding evolving preferences. Consequently, there is growing interest in leveraging multi-behavior data to better capture user intent. Recent studies have explored sequential modeling of multi-behavior data, many relying on transformer-based architectures with polynomial time complexity. While effective, these approaches often incur high computational costs, limiting their applicability in large-scale industrial systems with long user sequences. To address this challenge, we propose the Transition-Aware Graph Attention Network (TGA), a linear-complexity approach for modeling multi-behavior transitions. Unlike traditional transformers that treat all behavior pairs equally, TGA constructs a structured sparse graph by identifying informative transitions from three perspectives: (a) item-level transitions, (b) category-level transitions, and (c) neighbor-level transitions. Built upon the structured graph, TGA employs a transition-aware graph Attention mechanism that jointly models user-item interactions and behavior transition types, enabling more accurate capture of sequential patterns while maintaining computational efficiency. Experiments show that TGA outperforms all state-of-the-art models while significantly reducing computational cost. Notably, TGA has been deployed in a large-scale industrial production environment, where it leads to impressive improvements in key business metrics.",
      "tldr_zh": "该研究提出了 Transition-Aware Graph Attention Network (TGA)，一种具有线性复杂度的多行为序列建模方法，旨在解决电子商务推荐系统中处理长序列数据时面临的高额计算成本问题。TGA 通过从物品级(item-level)、类别级(category-level)和邻居级(neighbor-level)三个维度识别关键转化，构建了结构化的稀疏图，从而避免了传统 Transformer 架构中对所有行为对进行等同处理的冗余计算。利用转化感知图注意力机制(transition-aware graph Attention mechanism)，该模型能够联合建模用户-物品交互与行为转化类型，更精准地捕捉用户偏好的动态演变。实验证明，TGA 在性能上显著优于现有最先进(SOTA)模型，同时大幅降低了计算开销。目前该模型已成功部署于大规模工业生产环境，并显著提升了关键业务指标，证明了其在实际大规模应用场景下的有效性与高效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by WWW2026 short paper",
      "pdf_url": "https://arxiv.org/pdf/2601.14955v1",
      "published_date": "2026-01-21 12:53:32 UTC",
      "updated_date": "2026-01-21 12:53:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:43:49.991459+00:00"
    },
    {
      "arxiv_id": "2601.14952v1",
      "title": "CorpusQA: A 10 Million Token Benchmark for Corpus-Level Analysis and Reasoning",
      "title_zh": "CorpusQA：面向语料库级分析与推理的千万级 Token 基准",
      "authors": [
        "Zhiyuan Lu",
        "Chenliang Li",
        "Yingcheng Shi",
        "Weizhou Shen",
        "Ming Yan",
        "Fei Huang"
      ],
      "abstract": "While large language models now handle million-token contexts, their capacity for reasoning across entire document repositories remains largely untested. Existing benchmarks are inadequate, as they are mostly limited to single long texts or rely on a \"sparse retrieval\" assumption-that answers can be derived from a few relevant chunks. This assumption fails for true corpus-level analysis, where evidence is highly dispersed across hundreds of documents and answers require global integration, comparison, and statistical aggregation. To address this critical gap, we introduce CorpusQA, a new benchmark scaling up to 10 million tokens, generated via a novel data synthesis framework. By decoupling reasoning from textual representation, this framework creates complex, computation-intensive queries with programmatically guaranteed ground-truth answers, challenging systems to perform holistic reasoning over vast, unstructured text without relying on fallible human annotation. We further demonstrate the utility of our framework beyond evaluation, showing that fine-tuning on our synthesized data effectively enhances an LLM's general long-context reasoning capabilities. Extensive experiments reveal that even state-of-the-art long-context LLMs struggle as input length increases, and standard retrieval-augmented generation systems collapse entirely. Our findings indicate that memory-augmented agentic architectures offer a more robust alternative, suggesting a critical shift is needed from simply extending context windows to developing advanced architectures for global information synthesis.",
      "tldr_zh": "该研究针对大语言模型在跨文档库进行全语料库级别(corpus-level)推理能力的测试不足，提出了CorpusQA，一个规模达1000万(10 million)token的新型基准测试。CorpusQA通过一种创新的数据合成框架生成，该框架将推理与文本表示解耦，能够生成具有编程保证标准答案(ground-truth)的高难度计算密集型查询，挑战模型在海量非结构化文本上进行全局整合与统计聚合的能力。实验证明，在合成数据上进行微调可有效增强LLM的长上下文推理能力。研究发现，即使是顶尖的长上下文LLMs在输入增加时也面临严峻挑战，而标准检索增强生成(RAG)系统则表现极差。结果表明，相比单纯扩展上下文窗口(context windows)，开发具有存储增强的智能体架构(memory-augmented agentic architectures)是实现全局信息综合更稳健的技术路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14952v1",
      "published_date": "2026-01-21 12:52:30 UTC",
      "updated_date": "2026-01-21 12:52:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:44:17.335416+00:00"
    },
    {
      "arxiv_id": "2601.14951v1",
      "title": "TempViz: On the Evaluation of Temporal Knowledge in Text-to-Image Models",
      "title_zh": "TempViz：文本生成图像模型中的时序知识评估",
      "authors": [
        "Carolin Holtermann",
        "Nina Krebs",
        "Anne Lauscher"
      ],
      "abstract": "Time alters the visual appearance of entities in our world, like objects, places, and animals. Thus, for accurately generating contextually-relevant images, knowledge and reasoning about time can be crucial (e.g., for generating a landscape in spring vs. in winter). Yet, although substantial work exists on understanding and improving temporal knowledge in natural language processing, research on how temporal phenomena appear and are handled in text-to-image (T2I) models remains scarce. We address this gap with TempViz, the first data set to holistically evaluate temporal knowledge in image generation, consisting of 7.9k prompts and more than 600 reference images. Using TempViz, we study the capabilities of five T2I models across five temporal knowledge categories. Human evaluation shows that temporal competence is generally weak, with no model exceeding 75% accuracy across categories. Towards larger-scale studies, we also examine automated evaluation methods, comparing several established approaches against human judgments. However, none of these approaches provides a reliable assessment of temporal cues - further indicating the pressing need for future research on temporal knowledge in T2I.",
      "tldr_zh": "该研究推出了TempViz，这是首个全面评估文本生成图像(Text-to-Image)模型中时间知识(Temporal Knowledge)的数据集，旨在填补图像生成领域对时间维度理解研究的空白。研究团队构建了包含7.9k个提示语和600多张参考图像的评估基准，系统考察了五种T2I模型在五个时间知识类别下的生成能力。人类评估结果显示，当前模型的时间感知能力普遍较弱，没有任何模型在各类别中的准确率超过75%。同时，研究还对比了多种自动化评估方法与人类判断的一致性，发现现有自动评估技术均无法对图像中的时间线索提供可靠评估。这一研究结果表明目前的T2I模型在处理随时间变化的视觉特征方面存在显著局限，凸显了未来针对图像生成领域开展时间推理研究的紧迫性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14951v1",
      "published_date": "2026-01-21 12:52:23 UTC",
      "updated_date": "2026-01-21 12:52:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:44:21.970267+00:00"
    },
    {
      "arxiv_id": "2601.14945v1",
      "title": "TIDAL: Temporally Interleaved Diffusion and Action Loop for High-Frequency VLA Control",
      "title_zh": "TIDAL：面向高频 VLA 控制的时域交错扩散与动作循环",
      "authors": [
        "Yuteng Sun",
        "Haoran Wang",
        "Ruofei Bai",
        "Zhengguo Li",
        "Jun Li",
        "Meng Yee",
        "Chuah",
        "Wei Yun Yau"
      ],
      "abstract": "Large-scale Vision-Language-Action (VLA) models offer semantic generalization but suffer from high inference latency, limiting them to low-frequency batch-and-execute paradigm. This frequency mismatch creates an execution blind spot, causing failures in dynamic environments where targets move during the open-loop execution window. We propose TIDAL (Temporally Interleaved Diffusion and Action Loop), a hierarchical framework that decouples semantic reasoning from high-frequency actuation. TIDAL operates as a backbone-agnostic module for diffusion-based VLAs, using a dual-frequency architecture to redistribute the computational budget. Specifically, a low-frequency macro-intent loop caches semantic embeddings, while a high-frequency micro-control loop interleaves single-step flow integration with execution. This design enables approximately 9 Hz control updates on edge hardware (vs. approximately 2.4 Hz baselines) without increasing marginal overhead. To handle the resulting latency shift, we introduce a temporally misaligned training strategy where the policy learns predictive compensation using stale semantic intent alongside real-time proprioception. Additionally, we address the insensitivity of static vision encoders to velocity by incorporating a differential motion predictor. TIDAL is architectural, making it orthogonal to system-level optimizations. Experiments show a 2x performance gain over open-loop baselines in dynamic interception tasks. Despite a marginal regression in static success rates, our approach yields a 4x increase in feedback frequency and extends the effective horizon of semantic embeddings beyond the native action chunk size. Under non-paused inference protocols, TIDAL remains robust where standard baselines fail due to latency.",
      "tldr_zh": "该研究提出了TIDAL (Temporally Interleaved Diffusion and Action Loop)，这是一种层次化框架，旨在解决大模型Vision-Language-Action (VLA)因高推理延迟而在动态环境中产生的执行盲点问题。该框架采用双频率架构将语义推理与高频执行解耦，利用低频macro-intent loop缓存语义嵌入，并配合高频micro-control loop实现单步流集成与动作执行的交替。为了处理延迟带来的时间偏差，研究引入了temporally misaligned training策略进行预测性补偿，并加入differential motion predictor以弥补静态视觉编码器对速度感知的不足。实验表明，TIDAL在边缘硬件上实现了约9 Hz的控制频率，较基线提升了约4倍，且在动态拦截任务中的性能表现提高了2倍。即使在不间断推理协议下，TIDAL依然表现出极强的鲁棒性，成功克服了传统模型因延迟导致的失败，有效扩展了语义嵌入的动作视野。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14945v1",
      "published_date": "2026-01-21 12:43:11 UTC",
      "updated_date": "2026-01-21 12:43:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:44:23.077122+00:00"
    },
    {
      "arxiv_id": "2601.14931v1",
      "title": "Generative Artificial Intelligence, Musical Heritage and the Construction of Peace Narratives: A Case Study in Mali",
      "title_zh": "生成式人工智能、音乐遗产与和平叙事构建：Mali 案例研究",
      "authors": [
        "Nouhoum Coulibaly",
        "Ousmane Ly",
        "Michael Leventhal",
        "Ousmane Goro"
      ],
      "abstract": "This study explores the capacity of generative artificial intelligence (Gen AI) to contribute to the construction of peace narratives and the revitalization of musical heritage in Mali. The study has been made in a political and social context where inter-community tensions and social fractures motivate a search for new symbolic frameworks for reconciliation. The study empirically explores three questions: (1) how Gen AI can be used as a tool for musical creation rooted in national languages and traditions; (2) to what extent Gen AI systems enable a balanced hybridization between technological innovation and cultural authenticity; and (3) how AI-assisted musical co-creation can strengthen social cohesion and cultural sovereignty. The experimental results suggest that Gen AI, embedded in a culturally conscious participatory framework, can act as a catalyst for symbolic diplomacy, amplifying local voices instead of standardizing them. However, challenges persist regarding the availability of linguistic corpora, algorithmic censorship, and the ethics of generating compositions derived from copyrighted sources.",
      "tldr_zh": "该研究探讨了生成式人工智能 (Generative AI) 在马里构建和平叙事及振兴音乐遗产方面的潜力，特别是在社区紧张局势和社会裂痕的背景下寻求和解的新象征框架。研究实证分析了生成式人工智能如何作为根植于民族语言和传统的音乐创作工具，并探讨了技术创新与文化原真性 (Cultural Authenticity) 之间的平衡。此外，研究评估了人工智能辅助的音乐共同创作在加强社会凝聚力和文化主权 (Cultural Sovereignty) 方面的作用。实验结果表明，嵌入文化意识参与框架的生成式人工智能可以作为符号外交 (Symbolic Diplomacy) 的催化剂，通过放大地方声音而非使其标准化来促进社会和谐。然而，研究也指出在语言语料库 (Linguistic Corpora) 可获得性、算法审查以及源自受版权保护来源的创作伦理等方面仍面临持续挑战。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SD",
      "comment": "12 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.14931v1",
      "published_date": "2026-01-21 12:22:19 UTC",
      "updated_date": "2026-01-21 12:22:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:44:23.826113+00:00"
    },
    {
      "arxiv_id": "2601.14925v1",
      "title": "Fast-ULCNet: A fast and ultra low complexity network for single-channel speech enhancement",
      "title_zh": "Fast-ULCNet：面向单通道语音增强的快速超低复杂度网络",
      "authors": [
        "Nicolás Arrieta Larraza",
        "Niels de Koeijer"
      ],
      "abstract": "Single-channel speech enhancement algorithms are often used in resource-constrained embedded devices, where low latency and low complexity designs gain more importance. In recent years, researchers have proposed a wide variety of novel solutions to this problem. In particular, a recent deep learning model named ULCNet is among the state-of-the-art approaches in this domain. This paper proposes an adaptation of ULCNet, by replacing its GRU layers with FastGRNNs, to reduce both computational latency and complexity. Furthermore, this paper shows empirical evidence on the performance decay of FastGRNNs in long audio signals during inference due to internal state drifting, and proposes a novel approach based on a trainable complementary filter to mitigate it. The resulting model, Fast-ULCNet, performs on par with the state-of-the-art original ULCNet architecture on a speech enhancement task, while reducing its model size by more than half and decreasing its latency by 34% on average.",
      "tldr_zh": "该研究提出了 Fast-ULCNet，一种专为单通道语音增强 (single-channel speech enhancement) 任务设计的快速且超低复杂度网络，旨在满足资源受限嵌入式设备对低延迟的需求。通过将原始 ULCNet 中的 GRU 层替换为 FastGRNNs，该模型显著降低了计算复杂度和延迟。针对 FastGRNNs 在处理长音频信号时出现的内部状态漂移 (internal state drifting) 导致的性能退化问题，研究者提出了一种创新的可训练互补滤波器 (trainable complementary filter) 机制。实验结果显示，Fast-ULCNet 在语音增强性能上与 ULCNet 持平，但模型体积缩减了超过一半，且平均延迟降低了 34%。这一成果为在嵌入式系统中部署高性能、低功耗的实时语音处理技术提供了有效方案。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "©2026 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
      "pdf_url": "https://arxiv.org/pdf/2601.14925v1",
      "published_date": "2026-01-21 12:14:44 UTC",
      "updated_date": "2026-01-21 12:14:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:44:43.880272+00:00"
    },
    {
      "arxiv_id": "2601.14921v1",
      "title": "Vision-Language Models on the Edge for Real-Time Robotic Perception",
      "title_zh": "用于实时机器人感知的边缘侧视觉语言模型",
      "authors": [
        "Sarat Ahmad",
        "Maryam Hafeez",
        "Syed Ali Raza Zaidi"
      ],
      "abstract": "Vision-Language Models (VLMs) enable multimodal reasoning for robotic perception and interaction, but their deployment in real-world systems remains constrained by latency, limited onboard resources, and privacy risks of cloud offloading. Edge intelligence within 6G, particularly Open RAN and Multi-access Edge Computing (MEC), offers a pathway to address these challenges by bringing computation closer to the data source. This work investigates the deployment of VLMs on ORAN/MEC infrastructure using the Unitree G1 humanoid robot as an embodied testbed. We design a WebRTC-based pipeline that streams multimodal data to an edge node and evaluate LLaMA-3.2-11B-Vision-Instruct deployed at the edge versus in the cloud under real-time conditions. Our results show that edge deployment preserves near-cloud accuracy while reducing end-to-end latency by 5\\%. We further evaluate Qwen2-VL-2B-Instruct, a compact model optimized for resource-constrained environments, which achieves sub-second responsiveness, cutting latency by more than half but at the cost of accuracy.",
      "tldr_zh": "该研究探讨了 Vision-Language Models (VLMs) 在实时机器人感知中的应用，旨在解决云端部署带来的高延迟、资源受限及隐私风险等挑战。通过利用 6G 网络中的 Open RAN 和 Multi-access Edge Computing (MEC) 技术，研究者以 Unitree G1 人形机器人为具身智能测试平台，设计并实现了一套基于 WebRTC 的多模态数据流管道。实验对比了 LLaMA-3.2-11B-Vision-Instruct 在边缘节点与云端的性能，结果显示边缘部署在保持接近云端准确率的同时，成功将端到端延迟降低了 5%。此外，研究还评估了专为资源受限环境优化的轻量化模型 Qwen2-VL-2B-Instruct，该模型实现了亚秒级响应并将延迟缩减一半以上，但以牺牲部分准确率为代价。这项工作证明了边缘智能基础设施在提升机器人实时感知能力方面的潜力，为具身智能的边缘化部署提供了实践参考。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14921v1",
      "published_date": "2026-01-21 12:09:48 UTC",
      "updated_date": "2026-01-21 12:09:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:44:42.343001+00:00"
    },
    {
      "arxiv_id": "2601.14917v1",
      "title": "Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models",
      "title_zh": "基于患者特异性深度学习模型的1型糖尿病不良事件个性化预测",
      "authors": [
        "Giorgia Rigamonti",
        "Mirko Paolo Barbato",
        "Davide Marelli",
        "Paolo Napoletano"
      ],
      "abstract": "Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions.",
      "tldr_zh": "该研究针对 Type 1 Diabetes 的管理需求，提出了一种基于 Deep Learning 的个性化血糖预测方法，旨在利用患者特定数据解决传统泛化模型难以应对的个体差异问题。研究人员通过对比 Leave-One-Subject-Out Cross-Validation 与 fine-tuning 策略，评估了不同模型在捕捉患者特定动态特征方面的能力，并进一步验证了多模态数据相比传统 CGM-only 方法的优势。实验结果表明，个性化模型显著提升了对 Adverse Event 的预测准确性，能够实现更精准且及时的临床干预。此外，该研究通过消融实验（ablation study）确定了实现有效个性化所需的最小训练数据集规模，为数据获取受限的真实应用场景提供了重要参考。这些发现强调了自适应个性化预测模型在可穿戴设备和移动健康平台中的巨大潜力，为下一代智能化糖尿病管理方案奠定了技术基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14917v1",
      "published_date": "2026-01-21 11:57:51 UTC",
      "updated_date": "2026-01-21 11:57:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:45:25.024281+00:00"
    },
    {
      "arxiv_id": "2601.14901v1",
      "title": "Just aware enough: Evaluating awareness across artificial systems",
      "title_zh": "适度觉知：跨人工系统的觉知评估",
      "authors": [
        "Nadine Meertens",
        "Suet Lee",
        "Ophelia Deroy"
      ],
      "abstract": "Recent debates on artificial intelligence increasingly emphasise questions of AI consciousness and moral status, yet there remains little agreement on how such properties should be evaluated. In this paper, we argue that awareness offers a more productive and methodologically tractable alternative. We introduce a practical method for evaluating awareness across diverse systems, where awareness is understood as encompassing a system's abilities to process, store and use information in the service of goal-directed action. Central to this approach is the claim that any evaluation aiming to capture the diversity of artificial systems must be domain-sensitive, deployable at any scale, multidimensional, and enable the prediction of task performance, while generalising to the level of abilities for the sake of comparison. Given these four desiderata, we outline a structured approach to evaluating and comparing awareness profiles across artificial systems with differing architectures, scales, and operational domains. By shifting the focus from artificial consciousness to being just aware enough, this approach aims to facilitate principled assessment, support design and oversight, and enable more constructive scientific and public discourse.",
      "tldr_zh": "该研究探讨了人工智能系统中 awareness 的评估问题，认为相比于难以达成共识的 AI consciousness，awareness 提供了一个更具生产力和方法论可行性的替代方案。作者提出了一种评估各类系统 awareness 的实用方法，将其定义为系统为实现目标导向行动而处理、存储和利用信息的能力。该评估框架满足四个核心需求：即评估必须具备 domain-sensitive 特性、可跨规模部署、具备 multidimensional 维度并能预测任务表现。通过这种结构化方法，研究能够比较不同架构、规模和运作领域的 artificial systems 的 awareness profiles。这种从关注 artificial consciousness 到追求“恰到好处的觉知”的转向，旨在促进原则性评估并支持系统的设计与监管。该框架最终为相关科学研究和公众话语提供了更具建设性的讨论基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages (including references), 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2601.14901v1",
      "published_date": "2026-01-21 11:39:35 UTC",
      "updated_date": "2026-01-21 11:39:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:45:07.597169+00:00"
    },
    {
      "arxiv_id": "2601.14895v1",
      "title": "SpatialMem: Unified 3D Memory with Metric Anchoring and Fast Retrieval",
      "title_zh": "SpatialMem：融合度量锚定与快速检索的统一3D存储",
      "authors": [
        "Xinyi Zheng",
        "Yunze Liu",
        "Chi-Hao Wu",
        "Fan Zhang",
        "Hao Zheng",
        "Wenqi Zhou",
        "Walterio W. Mayol-Cuevas",
        "Junxiao Shen"
      ],
      "abstract": "We present SpatialMem, a memory-centric system that unifies 3D geometry, semantics, and language into a single, queryable representation. Starting from casually captured egocentric RGB video, SpatialMem reconstructs metrically scaled indoor environments, detects structural 3D anchors (walls, doors, windows) as the first-layer scaffold, and populates a hierarchical memory with open-vocabulary object nodes -- linking evidence patches, visual embeddings, and two-layer textual descriptions to 3D coordinates -- for compact storage and fast retrieval. This design enables interpretable reasoning over spatial relations (e.g., distance, direction, visibility) and supports downstream tasks such as language-guided navigation and object retrieval without specialized sensors. Experiments across three real-life indoor scenes demonstrate that SpatialMem maintains strong anchor-description-level navigation completion and hierarchical retrieval accuracy under increasing clutter and occlusion, offering an efficient and extensible framework for embodied spatial intelligence.",
      "tldr_zh": "该研究提出了 SpatialMem，一种以记忆为中心的系统，旨在将 3D Geometry、Semantics 和 Language 统一到单一的可查询表示中。该框架通过普通的自我中心 RGB 视频重建具有 Metric Scale 的室内环境，并利用墙壁、门窗等结构化的 3D Anchors 构建首层骨架，随后填充包含 Open-vocabulary 物体节点的 Hierarchical Memory。SpatialMem 将视觉特征、Visual Embeddings 以及双层文本描述与 3D 坐标关联，从而实现紧凑的存储和 Fast Retrieval，支持对距离、方向和可见性等空间关系进行可解释推理。实验证明，该系统在无需专门传感器的情况下，于真实室内场景的 Language-guided Navigation 和 Object Retrieval 任务中表现出色，即使在杂乱和遮挡环境下也能保持高准确性。这项工作为具身空间智能(Embodied Spatial Intelligence)提供了一个高效且可扩展的统一 3D 记忆框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14895v1",
      "published_date": "2026-01-21 11:32:24 UTC",
      "updated_date": "2026-01-21 11:32:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:45:20.615178+00:00"
    },
    {
      "arxiv_id": "2601.14894v1",
      "title": "To Neuro-Symbolic Classification and Beyond by Compiling Description Logic Ontologies to Probabilistic Circuits",
      "title_zh": "通过将描述逻辑本体编译为概率电路：迈向神经符号分类及其延伸",
      "authors": [
        "Nicolas Lazzari",
        "Valentina Presutti",
        "Antonio Vergari"
      ],
      "abstract": "Background: Neuro-symbolic methods enhance the reliability of neural network classifiers through logical constraints, but they lack native support for ontologies.\n  Objectives: We aim to develop a neuro-symbolic method that reliably outputs predictions consistent with a Description Logic ontology that formalizes domain-specific knowledge.\n  Methods: We encode a Description Logic ontology as a circuit, a feed-forward differentiable computational graph that supports tractable execution of queries and transformations. We show that the circuit can be used to (i) generate synthetic datasets that capture the semantics of the ontology; (ii) efficiently perform deductive reasoning on a GPU; (iii) implement neuro-symbolic models whose predictions are approximately or provably consistent with the knowledge defined in the ontology.\n  Results We show that the synthetic dataset generated using the circuit qualitatively captures the semantics of the ontology while being challenging for Machine Learning classifiers, including neural networks. Moreover, we show that compiling the ontology into a circuit is a promising approach for scalable deductive reasoning, with runtimes up to three orders of magnitude faster than available reasoners. Finally, we show that our neuro-symbolic classifiers reliably produce consistent predictions when compared to neural network baselines, maintaining competitive performances or even outperforming them.\n  Conclusions By compiling Description Logic ontologies into circuits, we obtain a tighter integration between the Deep Learning and Knowledge Representation fields. We show that a single circuit representation can be used to tackle different challenging tasks closely related to real-world applications.",
      "tldr_zh": "该研究针对神经符号(neuro-symbolic)分类方法在处理本体论(ontologies)方面的局限，提出了一种通过将描述逻辑(Description Logic)本体编译为概率电路(Probabilistic Circuits)的新型神经符号方法。该方法将本体编码为一种前馈可微计算图，从而支持高效的查询和变换执行。利用这种电路表示，研究者实现了捕捉本体语义的合成数据集生成，并在GPU上实现了高效的演绎推理(deductive reasoning)。实验结果表明，该方法在演绎推理速度上比现有推理器快三个数量级。同时，由此构建的神经符号分类器在确保预测结果与本体知识逻辑一致的同时，其性能表现优于传统的神经网络基线模型。这项工作实现了深度学习(Deep Learning)与知识表示(Knowledge Representation)领域的紧密集成，展示了单一电路表示在处理现实应用相关挑战任务中的巨大潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Manuscript under review",
      "pdf_url": "https://arxiv.org/pdf/2601.14894v1",
      "published_date": "2026-01-21 11:30:14 UTC",
      "updated_date": "2026-01-21 11:30:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:45:15.532849+00:00"
    },
    {
      "arxiv_id": "2601.14888v1",
      "title": "What Makes Low-Bit Quantization-Aware Training Work for Reasoning LLMs? A Systematic Study",
      "title_zh": "推理大语言模型低比特量化感知训练何以奏效？一项系统性研究",
      "authors": [
        "Keyu Lv",
        "Manyi Zhang",
        "Xiaobo Xia",
        "Jingchen Ni",
        "Shannan Yan",
        "Xianzhi Yu",
        "Lu Hou",
        "Chun Yuan",
        "Haoli Bai"
      ],
      "abstract": "Reasoning models excel at complex tasks such as coding and mathematics, yet their inference is often slow and token-inefficient. To improve the inference efficiency, post-training quantization (PTQ) usually comes with the cost of large accuracy drops, especially for reasoning tasks under low-bit settings. In this study, we present a systematic empirical study of quantization-aware training (QAT) for reasoning models. Our key findings include: (1) Knowledge distillation is a robust objective for reasoning models trained via either supervised fine-tuning or reinforcement learning; (2) PTQ provides a strong initialization for QAT, improving accuracy while reducing training cost; (3) Reinforcement learning remains feasible for quantized models given a viable cold start and yields additional gains; and (4) Aligning the PTQ calibration domain with the QAT training domain accelerates convergence and often improves the final accuracy. Finally, we consolidate these findings into an optimized workflow (Reasoning-QAT), and show that it consistently outperforms state-of-the-art PTQ methods across multiple LLM backbones and reasoning datasets. For instance, on Qwen3-0.6B, it surpasses GPTQ by 44.53% on MATH-500 and consistently recovers performance in the 2-bit regime.",
      "tldr_zh": "该研究针对推理大语言模型(Reasoning LLMs)在低比特设置下后量化(PTQ)准确率大幅下降的问题，对量化感知训练(QAT)进行了系统性的实证研究。研究发现，知识蒸馏(Knowledge Distillation)是训练推理模型鲁棒的目标，且将PTQ作为QAT的初始化能显著提升准确率并降低成本。此外，强化学习(Reinforcement Learning)在量化模型上依然可行并能带来额外收益，而对齐PTQ校准域与QAT训练域则能加速收敛。基于这些发现，作者提出了Reasoning-QAT优化工作流，在多个模型基座和推理数据集上均优于现有的PTQ方法。实验结果显示，在Qwen3-0.6B模型上，该方法在MATH-500数据集上比GPTQ准确率高出44.53%，并成功在2-bit量化环境下恢复了性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14888v1",
      "published_date": "2026-01-21 11:22:29 UTC",
      "updated_date": "2026-01-21 11:22:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:45:17.262817+00:00"
    },
    {
      "arxiv_id": "2601.14875v1",
      "title": "GAT-NeRF: Geometry-Aware-Transformer Enhanced Neural Radiance Fields for High-Fidelity 4D Facial Avatars",
      "title_zh": "GAT-NeRF：用于高保真 4D 人脸化身的几何感知 Transformer 增强神经辐射场",
      "authors": [
        "Zhe Chang",
        "Haodong Jin",
        "Ying Sun",
        "Yan Song",
        "Hui Yu"
      ],
      "abstract": "High-fidelity 4D dynamic facial avatar reconstruction from monocular video is a critical yet challenging task, driven by increasing demands for immersive virtual human applications. While Neural Radiance Fields (NeRF) have advanced scene representation, their capacity to capture high-frequency facial details, such as dynamic wrinkles and subtle textures from information-constrained monocular streams, requires significant enhancement. To tackle this challenge, we propose a novel hybrid neural radiance field framework, called Geometry-Aware-Transformer Enhanced NeRF (GAT-NeRF) for high-fidelity and controllable 4D facial avatar reconstruction, which integrates the Transformer mechanism into the NeRF pipeline. GAT-NeRF synergistically combines a coordinate-aligned Multilayer Perceptron (MLP) with a lightweight Transformer module, termed as Geometry-Aware-Transformer (GAT) due to its processing of multi-modal inputs containing explicit geometric priors. The GAT module is enabled by fusing multi-modal input features, including 3D spatial coordinates, 3D Morphable Model (3DMM) expression parameters, and learnable latent codes to effectively learn and enhance feature representations pertinent to fine-grained geometry. The Transformer's effective feature learning capabilities are leveraged to significantly augment the modeling of complex local facial patterns like dynamic wrinkles and acne scars. Comprehensive experiments unequivocally demonstrate GAT-NeRF's state-of-the-art performance in visual fidelity and high-frequency detail recovery, forging new pathways for creating realistic dynamic digital humans for multimedia applications.",
      "tldr_zh": "该研究提出了 GAT-NeRF，一种几何感知 Transformer 增强的神经辐射场框架，用于从单目视频中重建高保真且可控的 4D 面部化身。针对现有 Neural Radiance Fields (NeRF) 难以从受限的单目数据中捕捉动态皱纹和细微纹理等高频细节的问题，该框架创新性地将 Transformer 机制集成到 NeRF 流程中。其核心组件 Geometry-Aware-Transformer (GAT) 模块通过融合 3D 空间坐标、3DMM 表情参数和可学习的潜码 (latent codes) 等多模态输入，显著增强了对精细几何特征的表示学习。这种设计充分利用了 Transformer 的特征学习能力，有效提升了对复杂局部面部模式的建模效果。大量实验证明，GAT-NeRF 在视觉逼真度和高频细节恢复方面达到了 state-of-the-art 水平，为创建逼真的动态数字人提供了有力支持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14875v1",
      "published_date": "2026-01-21 11:05:13 UTC",
      "updated_date": "2026-01-21 11:05:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:46:45.475543+00:00"
    },
    {
      "arxiv_id": "2601.14848v1",
      "title": "From Observation to Prediction: LSTM for Vehicle Lane Change Forecasting on Highway On/Off-Ramps",
      "title_zh": "从观测到预测：基于 LSTM 的高速公路进出匝道车辆换道预测",
      "authors": [
        "Mohamed Abouras",
        "Catherine M. Elias"
      ],
      "abstract": "On and off-ramps are understudied road sections even though they introduce a higher level of variation in highway interactions. Predicting vehicles' behavior in these areas can decrease the impact of uncertainty and increase road safety. In this paper, the difference between this Area of Interest (AoI) and a straight highway section is studied. Multi-layered LSTM architecture to train the AoI model with ExiD drone dataset is utilized. In the process, different prediction horizons and different models' workflow are tested. The results show great promise on horizons up to 4 seconds with prediction accuracy starting from about 76% for the AoI and 94% for the general highway scenarios on the maximum horizon.",
      "tldr_zh": "本研究关注高速公路进出口匝道（On and off-ramps）区域，旨在通过预测该特定区域内的车辆行为来降低不确定性并提高道路安全。该研究深入分析了这一感兴趣区域（Area of Interest, AoI）与普通直行高速路段的驾驶差异，并采用了多层 LSTM 架构进行建模预测。研究利用 ExiD 无人机数据集对模型进行训练，并对比测试了不同的预测时界（Prediction horizons）和模型工作流。实验结果表明，该模型在长达 4 秒的预测时界内展现出极具潜力的预测能力。在最大预测时界下，模型在 AoI 区域的预测准确率约为 76%，而针对普通高速公路场景的准确率则高达 94%。该项工作为复杂交通节点下的车辆行为预判提供了有效的数据支持和技术参考。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14848v1",
      "published_date": "2026-01-21 10:31:03 UTC",
      "updated_date": "2026-01-21 10:31:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:45:43.892995+00:00"
    },
    {
      "arxiv_id": "2601.14844v1",
      "title": "CAG-Avatar: Cross-Attention Guided Gaussian Avatars for High-Fidelity Head Reconstruction",
      "title_zh": "CAG-Avatar：交叉注意力引导的高保真头部重建高斯 Avatar",
      "authors": [
        "Zhe Chang",
        "Haodong Jin",
        "Yan Song",
        "Hui Yu"
      ],
      "abstract": "Creating high-fidelity, real-time drivable 3D head avatars is a core challenge in digital animation. While 3D Gaussian Splashing (3D-GS) offers unprecedented rendering speed and quality, current animation techniques often rely on a \"one-size-fits-all\" global tuning approach, where all Gaussian primitives are uniformly driven by a single expression code. This simplistic approach fails to unravel the distinct dynamics of different facial regions, such as deformable skin versus rigid teeth, leading to significant blurring and distortion artifacts. We introduce Conditionally-Adaptive Gaussian Avatars (CAG-Avatar), a framework that resolves this key limitation. At its core is a Conditionally Adaptive Fusion Module built on cross-attention. This mechanism empowers each 3D Gaussian to act as a query, adaptively extracting relevant driving signals from the global expression code based on its canonical position. This \"tailor-made\" conditioning strategy drastically enhances the modeling of fine-grained, localized dynamics. Our experiments confirm a significant improvement in reconstruction fidelity, particularly for challenging regions such as teeth, while preserving real-time rendering performance.",
      "tldr_zh": "该研究提出了 CAG-Avatar，这是一个基于 Cross-Attention 引导的 Conditionally-Adaptive Gaussian Avatars 框架，旨在解决高保真、实时可驱动 3D 头部头像重建中的核心挑战。针对现有 3D Gaussian Splashing (3D-GS) 技术中所有高斯基元统一由全局表情代码驱动、导致局部区域如皮肤与牙齿产生模糊和畸变的问题，该框架引入了核心的 Conditionally Adaptive Fusion Module。该模块利用 cross-attention 机制，使每个 3D Gaussian 能够作为查询(query)，根据其在规范空间中的位置自适应地从全局表情代码中提取相关的驱动信号。这种“量身定制”的条件策略显著增强了对细粒度、局部动态的建模能力。实验结果表明，CAG-Avatar 在重建忠实度方面取得了显著提升，特别是在牙齿等具有挑战性的区域，同时依然保持了实时的渲染性能。",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14844v1",
      "published_date": "2026-01-21 10:22:53 UTC",
      "updated_date": "2026-01-21 10:22:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:45:44.554165+00:00"
    },
    {
      "arxiv_id": "2601.14840v1",
      "title": "Implementing Knowledge Representation and Reasoning with Object Oriented Design",
      "title_zh": "基于面向对象设计的知识表示与推理实现",
      "authors": [
        "Abdelrhman Bassiouny",
        "Tom Schierenbeck",
        "Sorin Arion",
        "Benjamin Alt",
        "Naren Vasantakumaar",
        "Giang Nguyen",
        "Michael Beetz"
      ],
      "abstract": "This paper introduces KRROOD, a framework designed to bridge the integration gap between modern software engineering and Knowledge Representation & Reasoning (KR&R) systems. While Object-Oriented Programming (OOP) is the standard for developing complex applications, existing KR&R frameworks often rely on external ontologies and specialized languages that are difficult to integrate with imperative code. KRROOD addresses this by treating knowledge as a first-class programming abstraction using native class structures, bridging the gap between the logic programming and OOP paradigms. We evaluate the system on the OWL2Bench benchmark and a human-robot task learning scenario. Experimental results show that KRROOD achieves strong performance while supporting the expressive reasoning required for real-world autonomous systems.",
      "tldr_zh": "该研究引入了KRROOD框架，旨在弥合现代软件工程与知识表示与推理(Knowledge Representation & Reasoning, KR&R)系统之间的集成鸿沟。针对现有框架过度依赖外部本体(Ontologies)和专门语言、难以与命令式代码集成的现状，KRROOD将知识视为一类编程抽象，并利用原生类结构实现了逻辑编程与面向对象编程(Object-Oriented Programming, OOP)范式的有效融合。研究团队在OWL2Bench基准测试和人机协作任务学习场景中对该系统进行了评估。实验结果表明，KRROOD在保持高性能的同时，能够支持真实世界自主系统所需的表达性推理能力。该框架为开发者在主流编程环境中直接构建复杂的知识驱动型应用提供了新的可能。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 2 figures, submitted to the 2026 International Joint Conference on Artificial Intelligence (IJCAI)",
      "pdf_url": "https://arxiv.org/pdf/2601.14840v1",
      "published_date": "2026-01-21 10:14:29 UTC",
      "updated_date": "2026-01-21 10:14:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:45:33.705234+00:00"
    },
    {
      "arxiv_id": "2601.14827v1",
      "title": "Measuring and Aligning Abstraction in Vision-Language Models with Medical Taxonomies",
      "title_zh": "基于医学分类学的视觉-语言模型抽象评估与对齐",
      "authors": [
        "Ben Schaper",
        "Maxime Di Folco",
        "Bernhard Kainz",
        "Julia A. Schnabel",
        "Cosmin I. Bercea"
      ],
      "abstract": "Vision-Language Models show strong zero-shot performance for chest X-ray classification, but standard flat metrics fail to distinguish between clinically minor and severe errors. This work investigates how to quantify and mitigate abstraction errors by leveraging medical taxonomies. We benchmark several state-of-the-art VLMs using hierarchical metrics and introduce Catastrophic Abstraction Errors to capture cross-branch mistakes. Our results reveal substantial misalignment of VLMs with clinical taxonomies despite high flat performance. To address this, we propose risk-constrained thresholding and taxonomy-aware fine-tuning with radial embeddings, which reduce severe abstraction errors to below 2 per cent while maintaining competitive performance. These findings highlight the importance of hierarchical evaluation and representation-level alignment for safer and more clinically meaningful deployment of VLMs.",
      "tldr_zh": "该研究探讨了如何利用医学分类法(medical taxonomies)来量化并缓解视觉语言模型(Vision-Language Models, VLMs)在胸部 X 射线分类中的抽象错误。研究者利用分层指标对多个先进的 VLMs 进行了基准测试，并引入了灾难性抽象错误(Catastrophic Abstraction Errors)概念来捕捉跨分支的误判，发现尽管模型在传统指标上表现良好，但在临床分类逻辑上存在严重失调。为解决这一问题，该研究提出了风险约束阈值(risk-constrained thresholding)和基于径向嵌入(radial embeddings)的分类感知微调(taxonomy-aware fine-tuning)方法。实验结果显示，这些方法能将严重抽象错误降至 2% 以下，同时保持了模型极具竞争力的性能水平。该工作强调了分层评估和表示级对齐对于 VLMs 在临床安全部署中的核心重要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14827v1",
      "published_date": "2026-01-21 09:58:50 UTC",
      "updated_date": "2026-01-21 09:58:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:45:50.465051+00:00"
    },
    {
      "arxiv_id": "2601.14822v1",
      "title": "Multimodal system for skin cancer detection",
      "title_zh": "皮肤癌检测多模态系统",
      "authors": [
        "Volodymyr Sydorskyi",
        "Igor Krashenyi",
        "Oleksii Yakubenko"
      ],
      "abstract": "Melanoma detection is vital for early diagnosis and effective treatment. While deep learning models on dermoscopic images have shown promise, they require specialized equipment, limiting their use in broader clinical settings. This study introduces a multi-modal melanoma detection system using conventional photo images, making it more accessible and versatile. Our system integrates image data with tabular metadata, such as patient demographics and lesion characteristics, to improve detection accuracy. It employs a multi-modal neural network combining image and metadata processing and supports a two-step model for cases with or without metadata. A three-stage pipeline further refines predictions by boosting algorithms and enhancing performance. To address the challenges of a highly imbalanced dataset, specific techniques were implemented to ensure robust training. An ablation study evaluated recent vision architectures, boosting algorithms, and loss functions, achieving a peak Partial ROC AUC of 0.18068 (0.2 maximum) and top-15 retrieval sensitivity of 0.78371. Results demonstrate that integrating photo images with metadata in a structured, multi-stage pipeline yields significant performance improvements. This system advances melanoma detection by providing a scalable, equipment-independent solution suitable for diverse healthcare environments, bridging the gap between specialized and general clinical practices.",
      "tldr_zh": "该研究提出了一种用于皮肤癌检测的多模态系统(Multimodal system)，旨在利用常规照片影像(conventional photo images)而非昂贵的专业皮肤镜设备实现黑色素瘤(Melanoma)的早期诊断。该系统通过多模态神经网络整合了图像数据与患者人口统计学及病灶特征等表格元数据(tabular metadata)，并设计了包含提升算法(boosting algorithms)在内的三阶段处理流程以优化预测性能。针对数据集严重失衡的挑战，研究实施了特定的鲁棒性训练技术，实验结果显示该系统在Partial ROC AUC上达到了0.18068，且top-15检索灵敏度达到0.78371。消融实验进一步证明，将常规照片与元数据结合并采用多阶段流水线能显著提升检测精度。这项工作为多样化的医疗环境提供了一种不依赖特定设备且可扩展的解决方案，有效弥合了专业医疗与普通临床实践之间的技术差距。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to System research and information technologies",
      "pdf_url": "https://arxiv.org/pdf/2601.14822v1",
      "published_date": "2026-01-21 09:50:13 UTC",
      "updated_date": "2026-01-21 09:50:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:47:18.403727+00:00"
    },
    {
      "arxiv_id": "2601.14790v1",
      "title": "CI4A: Semantic Component Interfaces for Agents Empowering Web Automation",
      "title_zh": "CI4A：赋能 Web 自动化的智能体语义组件接口",
      "authors": [
        "Zhi Qiu",
        "Jiazheng Sun",
        "Chenxiao Xia",
        "Jun Zheng",
        "Xin Peng"
      ],
      "abstract": "While Large Language Models demonstrate remarkable proficiency in high-level semantic planning, they remain limited in handling fine-grained, low-level web component manipulations. To address this limitation, extensive research has focused on enhancing model grounding capabilities through techniques such as Reinforcement Learning. However, rather than compelling agents to adapt to human-centric interfaces, we propose constructing interaction interfaces specifically optimized for agents. This paper introduces Component Interface for Agent (CI4A), a semantic encapsulation mechanism that abstracts the complex interaction logic of UI components into a set of unified tool primitives accessible to agents. We implemented CI4A within Ant Design, an industrial-grade front-end framework, covering 23 categories of commonly used UI components. Furthermore, we developed a hybrid agent featuring an action space that dynamically updates according to the page state, enabling flexible invocation of available CI4A tools. Leveraging the CI4A-integrated Ant Design, we refactored and upgraded the WebArena benchmark to evaluate existing SoTA methods. Experimental results demonstrate that the CI4A-based agent significantly outperforms existing approaches, achieving a new SoTA task success rate of 86.3%, alongside substantial improvements in execution efficiency.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models）在处理细粒度、底层网页组件操作方面的局限，提出了 CI4A (Component Interface for Agent) 语义封装机制。CI4A 旨在通过将复杂的 UI 组件交互逻辑抽象为一组供智能体调用的统一工具原语（tool primitives），构建专为智能体优化的交互接口，而非强迫智能体适应以人为中心的界面。作者在工业级前端框架 Ant Design 中实现了该机制，涵盖了 23 类常用 UI 组件，并开发了一个可根据页面状态动态更新动作空间（action space）的混合智能体。通过利用集成 CI4A 的 Ant Design 重构并升级 WebArena 基准测试，实验证明基于 CI4A 的智能体实现了 86.3% 的新 SoTA 任务成功率。该研究不仅显著提升了现有方法的任务完成能力，还在执行效率方面表现出大幅优化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.14790v1",
      "published_date": "2026-01-21 09:14:04 UTC",
      "updated_date": "2026-01-21 09:14:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:47:24.297167+00:00"
    },
    {
      "arxiv_id": "2601.14786v1",
      "title": "Training-Efficient Text-to-Music Generation with State-Space Modeling",
      "title_zh": "基于状态空间建模的高效训练文本到音乐生成",
      "authors": [
        "Wei-Jaw Lee",
        "Fang-Chih Hsieh",
        "Xuanjun Chen",
        "Fang-Duo Tsai",
        "Yi-Hsuan Yang"
      ],
      "abstract": "Recent advances in text-to-music generation (TTM) have yielded high-quality results, but often at the cost of extensive compute and the use of large proprietary internal data. To improve the affordability and openness of TTM training, an open-source generative model backbone that is more training- and data-efficient is needed. In this paper, we constrain the number of trainable parameters in the generative model to match that of the MusicGen-small benchmark (with about 300M parameters), and replace its Transformer backbone with the emerging class of state-space models (SSMs). Specifically, we explore different SSM variants for sequence modeling, and compare a single-stage SSM-based design with a decomposable two-stage SSM/diffusion hybrid design. All proposed models are trained from scratch on a purely public dataset comprising 457 hours of CC-licensed music, ensuring full openness. Our experimental findings are three-fold. First, we show that SSMs exhibit superior training efficiency compared to the Transformer counterpart. Second, despite using only 9% of the FLOPs and 2% of the training data size compared to the MusicGen-small benchmark, our model achieves competitive performance in both objective metrics and subjective listening tests based on MusicCaps captions. Finally, our scaling-down experiment demonstrates that SSMs can maintain competitive performance relative to the Transformer baseline even at the same training budget (measured in iterations), when the model size is reduced to four times smaller. To facilitate the democratization of TTM research, the processed captions, model checkpoints, and source code are available on GitHub via the project page: https://lonian6.github.io/ssmttm/.",
      "tldr_zh": "该研究提出了一种利用状态空间模型 (State-Space Models, SSMs) 实现训练高效的文本到音乐生成 (Text-to-Music Generation, TTM) 的新方法。研究者将模型参数限制在 300M，并采用 SSMs 替代传统的 Transformer 骨干网络，旨在解决当前 TTM 模型对大规模计算资源和私有数据依赖的问题。实验通过单阶段 SSM 以及两阶段 SSM/diffusion 混合设计，在 457 小时的公开数据集上进行了全开源训练。结果显示，SSMs 在训练效率上显著优于 Transformer 架构，仅需 MusicGen-small 基准 9% 的 FLOPs 和 2% 的数据量即可达到同等水平的生成质量。此外，当模型规模缩小四倍时，SSMs 在相同训练预算下仍能维持较强的竞争力。该研究的 Caption 数据、模型权重及源代码已完全开源，为 TTM 研究的民主化提供了重要支持。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "9 pages, 3 figures. This is a preprint of a paper submitted to IEEE/ACM TASLP",
      "pdf_url": "https://arxiv.org/pdf/2601.14786v1",
      "published_date": "2026-01-21 09:06:55 UTC",
      "updated_date": "2026-01-21 09:06:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:47:08.076215+00:00"
    },
    {
      "arxiv_id": "2601.14784v1",
      "title": "Towards Bound Consistency for the No-Overlap Constraint Using MDDs",
      "title_zh": "基于 MDD 的无重叠约束边界相容性研究",
      "authors": [
        "Amaury Guichard",
        "Laurent Michel",
        "Hélène Verhaeghe",
        "Pierre Schaus"
      ],
      "abstract": "Achieving bound consistency for the no-overlap constraint is known to be NP-complete. Therefore, several polynomial-time tightening techniques, such as edge finding, not-first-not-last reasoning, and energetic reasoning, have been introduced for this constraint. In this work, we derive the first bound-consistent algorithm for the no-overlap constraint. By building on the no-overlap MDD defined by Ciré and van Hoeve, we extract bounds of the time window of the jobs, allowing us to tighten start and end times in time polynomial in the number of nodes of the MDD. Similarly, to bound the size and time-complexity, we limit the width of the MDD to a threshold, creating a relaxed MDD that can also be used to relax the bound-consistent filtering. Through experiments on a sequencing problem with time windows and a just-in-time objective ($1 \\mid r_j, d_j, \\bar{d}_j \\mid \\sum E_j + \\sum T_j$), we observe that the proposed filtering, even with a threshold on the width, achieves a stronger reduction in the number of nodes visited in the search tree compared to the previously proposed precedence-detection algorithm of Ciré and van Hoeve. The new filtering also appears to be complementary to classical propagation methods for the no-overlap constraint, allowing a substantial reduction in both the number of nodes and the solving time on several instances.",
      "tldr_zh": "该研究针对实现 no-overlap constraint 的 bound consistency 属于 NP-complete 这一挑战，提出了首个针对该约束的 bound-consistent 算法。该方法基于 Ciré 和 van Hoeve 定义的 no-overlap MDD，通过提取作业时间窗的边界，在 MDD 节点数量的多项式时间内有效收紧任务的开始和结束时间。为了平衡计算规模与时间复杂度，研究人员通过限制 MDD 宽度来构建松弛的 MDD (relaxed MDD)，从而实现可扩展的过滤机制。在带有时间窗和 just-in-time objective 的排序问题实验中，该算法在削减搜索树节点数量方面表现优于现有的 precedence-detection 算法。实验结果证明，这种新型过滤方法与经典的 no-overlap 传播手段具有显著的互补性，能够大幅减少多个实例的搜索节点数并缩短求解时间。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14784v1",
      "published_date": "2026-01-21 09:06:24 UTC",
      "updated_date": "2026-01-21 09:06:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:47:20.706680+00:00"
    },
    {
      "arxiv_id": "2601.14780v1",
      "title": "RECAP: Resistance Capture in Text-based Mental Health Counseling with Large Language Models",
      "title_zh": "RECAP：基于大语言模型的文本心理健康咨询阻抗识别",
      "authors": [
        "Anqi Li",
        "Yuqian Chen",
        "Yu Lu",
        "Zhaoming Chen",
        "Yuan Xie",
        "Zhenzhong Lan"
      ],
      "abstract": "Recognizing and navigating client resistance is critical for effective mental health counseling, yet detecting such behaviors is particularly challenging in text-based interactions. Existing NLP approaches oversimplify resistance categories, ignore the sequential dynamics of therapeutic interventions, and offer limited interpretability.\n  To address these limitations, we propose PsyFIRE, a theoretically grounded framework capturing 13 fine-grained resistance behaviors alongside collaborative interactions. Based on PsyFIRE, we construct the ClientResistance corpus with 23,930 annotated utterances from real-world Chinese text-based counseling, each supported by context-specific rationales. Leveraging this dataset, we develop RECAP, a two-stage framework that detects resistance and fine-grained resistance types with explanations.\n  RECAP achieves 91.25% F1 for distinguishing collaboration and resistance and 66.58% macro-F1 for fine-grained resistance categories classification, outperforming leading prompt-based LLM baselines by over 20 points. Applied to a separate counseling dataset and a pilot study with 62 counselors, RECAP reveals the prevalence of resistance, its negative impact on therapeutic relationships and demonstrates its potential to improve counselors' understanding and intervention strategies.",
      "tldr_zh": "该研究针对文本心理咨询中识别和应对来访者阻抗(resistance)的挑战，指出传统自然语言处理(NLP)方法存在分类简化、忽略互动动态及可解释性不足等局限。为此，作者提出了PsyFIRE框架，旨在捕捉13种细粒度的阻抗行为及协作互动，并基于此构建了包含23,930条真实中文咨询标注话语的ClientResistance语料库。依托该数据集，研究进一步开发了RECAP两阶段框架，实现了对阻抗类型的精准检测及其成因解释。实验表明，RECAP在识别阻抗与协作方面的F1值达91.25%，在细粒度分类性能上比主流的大语言模型(LLM)基线高出20个百分点以上。通过对62名咨询师的试点研究，该研究揭示了阻抗对治疗关系的负面影响，并证明了RECAP在辅助咨询师理解来访者行为和优化干预策略方面的实际应用价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.14780v1",
      "published_date": "2026-01-21 09:00:36 UTC",
      "updated_date": "2026-01-21 09:00:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:48:08.788068+00:00"
    },
    {
      "arxiv_id": "2601.14777v1",
      "title": "FunCineForge: A Unified Dataset Toolkit and Model for Zero-Shot Movie Dubbing in Diverse Cinematic Scenes",
      "title_zh": "FunCineForge：面向多样化影视场景的零样本电影配音统一数据集工具包与模型",
      "authors": [
        "Jiaxuan Liu",
        "Yang Xiang",
        "Han Zhao",
        "Xiangang Li",
        "Zhenhua Ling"
      ],
      "abstract": "Movie dubbing is the task of synthesizing speech from scripts conditioned on video scenes, requiring accurate lip sync, faithful timbre transfer, and proper modeling of character identity and emotion. However, existing methods face two major limitations: (1) high-quality multimodal dubbing datasets are limited in scale, suffer from high word error rates, contain sparse annotations, rely on costly manual labeling, and are restricted to monologue scenes, all of which hinder effective model training; (2) existing dubbing models rely solely on the lip region to learn audio-visual alignment, which limits their applicability to complex live-action cinematic scenes, and exhibit suboptimal performance in lip sync, speech quality, and emotional expressiveness. To address these issues, we propose FunCineForge, which comprises an end-to-end production pipeline for large-scale dubbing datasets and an MLLM-based dubbing model designed for diverse cinematic scenes. Using the pipeline, we construct the first Chinese television dubbing dataset with rich annotations, and demonstrate the high quality of these data. Experiments across monologue, narration, dialogue, and multi-speaker scenes show that our dubbing model consistently outperforms SOTA methods in audio quality, lip sync, timbre transfer, and instruction following. Code and demos are available at https://anonymous.4open.science/w/FunCineForge.",
      "tldr_zh": "该研究提出了 FunCineForge，这是一个旨在解决电影配音（Movie Dubbing）领域中高质量多模态数据集稀缺、标注不足以及模型在复杂电影场景下性能受限等挑战的统一工具包与模型。该项目包含一套端到端的大规模数据集制作流水线，并基于多模态大语言模型（MLLM）设计了适用于多样化场景的配音模型。利用该流水线，研究者构建了首个具有丰富标注的高质量中文电视剧配音数据集。实验结果显示，FunCineForge 在独白、对话及多发言人等多种复杂场景中，在音频质量、对口型（lip sync）、音色迁移（timbre transfer）和指令遵循方面均优于现有的 SOTA 方法。这一成果为实现多样化电影场景下的零样本（Zero-Shot）电影配音提供了强有力的支持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14777v1",
      "published_date": "2026-01-21 08:57:00 UTC",
      "updated_date": "2026-01-21 08:57:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:47:48.027038+00:00"
    },
    {
      "arxiv_id": "2601.14773v1",
      "title": "Semantic-Guided Unsupervised Video Summarization",
      "title_zh": "语义引导的无监督视频摘要",
      "authors": [
        "Haizhou Liu",
        "Haodong Jin",
        "Yiming Wang",
        "Hui Yu"
      ],
      "abstract": "Video summarization is a crucial technique for social understanding, enabling efficient browsing of massive multimedia content and extraction of key information from social platforms. Most existing unsupervised summarization methods rely on Generative Adversarial Networks (GANs) to enhance keyframe selection and generate coherent, video summaries through adversarial training. However, such approaches primarily exploit unimodal features, overlooking the guiding role of semantic information in keyframe selection, and often suffer from unstable training. To address these limitations, we propose a novel Semantic-Guided Unsupervised Video Summarization method. Specifically, we design a novel frame-level semantic alignment attention mechanism and integrate it into a keyframe selector, which guides the Transformer-based generator within the adversarial framework to better reconstruct videos. In addition, we adopt an incremental training strategy to progressively update the model components, effectively mitigating the instability of GAN training. Experimental results demonstrate that our approach achieves superior performance on multiple benchmark datasets.",
      "tldr_zh": "该研究针对现有无监督视频摘要（Unsupervised video summarization）方法忽视语义信息引导且训练不稳定（unstable training）的问题，提出了一种新型的语义引导无监督视频摘要方法（Semantic-Guided Unsupervised Video Summarization）。该方法通过设计一种创新的帧级语义对齐注意力机制（frame-level semantic alignment attention mechanism）并将其集成到关键帧选择器中，引导生成对抗框架（adversarial framework）内的 Transformer 生成器实现更高质量的视频重建。此外，研究采用了增量训练策略（incremental training strategy）来逐步更新模型组件，有效缓解了生成对抗网络（GAN）在训练过程中的不稳定性。实验结果表明，该方法在多个基准数据集（benchmark datasets）上均取得了优异的性能表现，为海量多媒体内容的高效浏览和关键信息提取提供了更强大的技术支撑。",
      "categories": [
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14773v1",
      "published_date": "2026-01-21 08:53:29 UTC",
      "updated_date": "2026-01-21 08:53:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:47:53.067665+00:00"
    },
    {
      "arxiv_id": "2601.14765v1",
      "title": "Anytime Optimal Decision Tree Learning with Continuous Features",
      "title_zh": "针对连续特征的随时最优决策树学习",
      "authors": [
        "Harold Kiossou",
        "Pierre Schaus",
        "Siegfried Nijssen"
      ],
      "abstract": "In recent years, significant progress has been made on algorithms for learning optimal decision trees, primarily in the context of binary features. Extending these methods to continuous features remains substantially more challenging due to the large number of potential splits for each feature. Recently, an elegant exact algorithm was proposed for learning optimal decision trees with continuous features; however, the rapidly increasing computational time limits its practical applicability to shallow depths (typically 3 or 4). It relies on a depth-first search optimization strategy that fully optimizes the left subtree of each split before exploring the corresponding right subtree. While effective in finding optimal solutions given sufficient time, this strategy can lead to poor anytime behavior: when interrupted early, the best-found tree is often highly unbalanced and suboptimal. In such cases, purely greedy methods such as C4.5 may, paradoxically, yield better solutions. To address this limitation, we propose an anytime, yet complete approach leveraging limited discrepancy search, distributing the computational effort more evenly across the entire tree structure, and thus ensuring that a high-quality decision tree is available at any interruption point. Experimental results show that our approach outperforms the existing one in terms of anytime performance.",
      "tldr_zh": "该研究探讨了在处理连续特征(Continuous Features)时学习最优决策树(Optimal Decision Trees)的计算难题，指出当前精确算法因依赖深度优先搜索(Depth-First Search)策略而导致随时性能(Anytime Performance)较差，在提前中断时容易产生极度不平衡且次优的树结构。为此，作者提出了一种基于有限差异搜索(Limited Discrepancy Search)的随时完整搜索方法，通过将计算量更均匀地分布于整个树结构，确保在任何中断点都能输出高质量的决策树。实验结果证明，该方法在随时性能上显著优于现有算法，有效克服了传统精确搜索方法在处理深层树时的实用性局限。该方案在保持搜索完整性的同时，为处理复杂连续特征的决策树优化提供了更具鲁棒性的计算框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14765v1",
      "published_date": "2026-01-21 08:40:06 UTC",
      "updated_date": "2026-01-21 08:40:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:47:43.314553+00:00"
    },
    {
      "arxiv_id": "2601.14764v1",
      "title": "An XAI View on Explainable ASP: Methods, Systems, and Perspectives",
      "title_zh": "XAI 视角下的可解释 ASP：方法、系统与展望",
      "authors": [
        "Thomas Eiter",
        "Tobias Geibinger",
        "Zeynep G. Saribatur"
      ],
      "abstract": "Answer Set Programming (ASP) is a popular declarative reasoning and problem solving approach in symbolic AI. Its rule-based formalism makes it inherently attractive for explainable and interpretive reasoning, which is gaining importance with the surge of Explainable AI (XAI). A number of explanation approaches and tools for ASP have been developed, which often tackle specific explanatory settings and may not cover all scenarios that ASP users encounter. In this survey, we provide, guided by an XAI perspective, an overview of types of ASP explanations in connection with user questions for explanation, and describe how their coverage by current theory and tools. Furthermore, we pinpoint gaps in existing ASP explanations approaches and identify research directions for future work.",
      "tldr_zh": "该综述从可解释人工智能(Explainable AI, XAI)的角度出发，系统探讨了答案集编程(Answer Set Programming, ASP)在符号人工智能推理和问题解决中的可解释性。尽管ASP的规则化形式使其具备天然的解释潜力，但现有工具和方法通常仅针对特定的解释场景，无法覆盖用户可能遇到的所有情况。文章通过将不同类型的ASP解释与用户提出的解释性问题相结合，详细评估了当前理论和系统的覆盖程度。研究识别了现有ASP解释方法中存在的空白，并针对性地提出了未来的研究方向。该综述为建立更全面、以用户为中心的符号化可解释推理系统提供了重要的理论框架和实践指南。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.14764v1",
      "published_date": "2026-01-21 08:37:33 UTC",
      "updated_date": "2026-01-21 08:37:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:48:03.267461+00:00"
    },
    {
      "arxiv_id": "2601.14758v2",
      "title": "Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models",
      "title_zh": "从自回归到掩码扩散语言模型后训练中的机制转变",
      "authors": [
        "Injin Kong",
        "Hyoungjoon Lee",
        "Yohan Jo"
      ],
      "abstract": "Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic \"mechanism shift\" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning.",
      "tldr_zh": "这项研究探讨了将预训练的自回归模型 (Autoregressive models, ARMs) 通过后期训练转化为掩码扩散模型 (Masked Diffusion models, MDMs) 这一过程中的内部算法转换机制。研究旨在厘清后期训练后的 MDMs 是获得了真正的双向推理能力，还是仅仅重新包装了自回归启发式方法。通过对 ARMs 及其对应的 MDMs 进行对比电路分析 (circuit analysis)，研究揭示了依赖于任务结构特性的系统性“机制偏移” (mechanism shift)。在结构层面，MDMs 在处理局部因果依赖任务时保留了自回归电路，但在全局规划任务中则舍弃了初始路径，表现出以早期层处理增加为特征的明显重构。在语义层面，模型从 ARMs 的尖锐局部特化转变为 MDMs 的分布式集成。这些发现表明，扩散后期训练不仅是调整模型参数，更从根本上重组了内部计算以支持非序列化的全局规划。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14758v2",
      "published_date": "2026-01-21 08:26:51 UTC",
      "updated_date": "2026-01-22 02:34:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:48:17.156737+00:00"
    },
    {
      "arxiv_id": "2601.15356v1",
      "title": "Q-Probe: Scaling Image Quality Assessment to High Resolution via Context-Aware Agentic Probing",
      "title_zh": "Q-Probe：通过上下文感知智能体探测实现高分辨率图像质量评估的扩展",
      "authors": [
        "Xiang Li",
        "XueHeng Li",
        "Yu Wang",
        "XuanHua He",
        "ZhangChi Hu",
        "WeiWei Yu",
        "ChengJun Xie"
      ],
      "abstract": "Reinforcement Learning (RL) has empowered Multimodal Large Language Models (MLLMs) to achieve superior human preference alignment in Image Quality Assessment (IQA). However, existing RL-based IQA models typically rely on coarse-grained global views, failing to capture subtle local degradations in high-resolution scenarios. While emerging \"Thinking with Images\" paradigms enable multi-scale visual perception via zoom-in mechanisms, their direct adaptation to IQA induces spurious \"cropping-implies-degradation\" biases and misinterprets natural depth-of-field as artifacts. To address these challenges, we propose Q-Probe, the first agentic IQA framework designed to scale IQA to high resolution via context-aware probing. First, we construct Vista-Bench, a pioneering benchmark tailored for fine-grained local degradation analysis in high-resolution IQA settings. Furthermore, we propose a three-stage training paradigm that progressively aligns the model with human preferences, while simultaneously eliminating causal bias through a novel context-aware cropping strategy. Extensive experiments demonstrate that Q-Probe achieves state-of-the-art performance in high-resolution settings while maintaining superior efficacy across resolution scales.",
      "tldr_zh": "该研究提出了Q-Probe，这是首个旨在通过上下文感知代理探测(Context-Aware Agentic Probing)将图像质量评估(IQA)扩展至高分辨率的智能代理框架。针对现有基于强化学习(RL)的模型难以捕捉细微局部退化以及缩放机制易引发“裁剪即降质”偏见的问题，研究者设计了创新的上下文感知裁剪策略(Context-Aware Cropping Strategy)以消除因果偏差。此外，该研究构建了专门用于精细化局部退化分析的基准测试集Vista-Bench，并提出了一个三阶段训练范式以实现模型与人类偏好的深度对齐。实验结果证明，Q-Probe在高分辨率设置下取得了最先进(SOTA)的性能表现，同时在不同分辨率尺度上均保持了卓越的评估效能。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15356v1",
      "published_date": "2026-01-21 08:02:32 UTC",
      "updated_date": "2026-01-21 08:02:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:49:28.465147+00:00"
    },
    {
      "arxiv_id": "2601.14730v1",
      "title": "FSX: Message Flow Sensitivity Enhanced Structural Explainer for Graph Neural Networks",
      "title_zh": "FSX：基于消息流敏感性增强的图神经网络结构解释器",
      "authors": [
        "Bizu Feng",
        "Zhimu Yang",
        "Shaode Yu",
        "Zixin Hu"
      ],
      "abstract": "Despite the widespread success of Graph Neural Networks (GNNs), understanding the reasons behind their specific predictions remains challenging. Existing explainability methods face a trade-off that gradient-based approaches are computationally efficient but often ignore structural interactions, while game-theoretic techniques capture interactions at the cost of high computational overhead and potential deviation from the model's true reasoning path. To address this gap, we propose FSX (Message Flow Sensitivity Enhanced Structural Explainer), a novel hybrid framework that synergistically combines the internal message flows of the model with a cooperative game approach applied to the external graph data. FSX first identifies critical message flows via a novel flow-sensitivity analysis: during a single forward pass, it simulates localized node perturbations and measures the resulting changes in message flow intensities. These sensitivity-ranked flows are then projected onto the input graph to define compact, semantically meaningful subgraphs. Within each subgraph, a flow-aware cooperative game is conducted, where node contributions are evaluated fairly through a Shapley-like value that incorporates both node-feature importance and their roles in sustaining or destabilizing the identified critical flows. Extensive evaluation across multiple datasets and GNN architectures demonstrates that FSX achieves superior explanation fidelity with significantly reduced runtime, while providing unprecedented insights into the structural logic underlying model predictions--specifically, how important sub-structures exert influence by governing the stability of key internal computational pathways.",
      "tldr_zh": "该研究提出了FSX（Message Flow Sensitivity Enhanced Structural Explainer），这是一种旨在提升图神经网络（GNNs）预测可解释性的新型混合框架。针对现有梯度法忽略结构交互以及博弈论方法计算开销过大的问题，FSX将模型内部的消息流与外部图数据的合作博弈方法有机结合。该框架首先通过流敏感性分析（flow-sensitivity analysis）识别关键消息流，在单次前向传播中模拟局部节点扰动并测量流强度变化。随后，FSX将敏感度排序的流投影为具有语义意义的子图，并在其中进行流感知合作博弈（flow-aware cooperative game），利用类Shapley值（Shapley-like value）公平评估节点对维持关键计算路径的贡献。实验证明，FSX在多个数据集和GNN架构上均实现了更高的解释保真度（fidelity），且显著降低了运行时间。该研究不仅提升了性能，还为理解重要子结构如何通过影响内部计算路径稳定性来干预模型预测提供了深刻的结构逻辑见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures, Preprint",
      "pdf_url": "https://arxiv.org/pdf/2601.14730v1",
      "published_date": "2026-01-21 07:39:42 UTC",
      "updated_date": "2026-01-21 07:39:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:49:40.619589+00:00"
    },
    {
      "arxiv_id": "2601.14728v1",
      "title": "AQAScore: Evaluating Semantic Alignment in Text-to-Audio Generation via Audio Question Answering",
      "title_zh": "AQAScore：基于音频问答的文本到音频生成语义对齐评估",
      "authors": [
        "Chun-Yi Kuan",
        "Kai-Wei Chang",
        "Hung-yi Lee"
      ],
      "abstract": "Although text-to-audio generation has made remarkable progress in realism and diversity, the development of evaluation metrics has not kept pace. Widely-adopted approaches, typically based on embedding similarity like CLAPScore, effectively measure general relevance but remain limited in fine-grained semantic alignment and compositional reasoning. To address this, we introduce AQAScore, a backbone-agnostic evaluation framework that leverages the reasoning capabilities of audio-aware large language models (ALLMs). AQAScore reformulates assessment as a probabilistic semantic verification task; rather than relying on open-ended text generation, it estimates alignment by computing the exact log-probability of a \"Yes\" answer to targeted semantic queries. We evaluate AQAScore across multiple benchmarks, including human-rated relevance, pairwise comparison, and compositional reasoning tasks. Experimental results show that AQAScore consistently achieves higher correlation with human judgments than similarity-based metrics and generative prompting baselines, showing its effectiveness in capturing subtle semantic inconsistencies and scaling with the capability of underlying ALLMs.",
      "tldr_zh": "该研究提出了AQAScore，这是一个旨在评估文本到音频(Text-to-Audio)生成中语义对齐(Semantic Alignment)的新型评估框架。针对CLAPScore等传统指标在细粒度语义和组合推理(Compositional Reasoning)方面的局限性，AQAScore利用音频感知大语言模型(ALLMs)的推理能力，将评估任务重新定义为概率语义验证。该方法通过计算针对特定语义查询回答“Yes”的精确对数概率(Log-probability)来衡量对齐程度，而非依赖开放式文本生成。在多项基准测试中的实验结果显示，AQAScore与人类评判的相关性始终高于基于相似度的指标和生成式提示(Generative Prompting)基线。该框架能有效捕捉细微的语义不一致性，并能随着底层ALLMs能力的提升而不断扩展。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Manuscript in progress",
      "pdf_url": "https://arxiv.org/pdf/2601.14728v1",
      "published_date": "2026-01-21 07:35:36 UTC",
      "updated_date": "2026-01-21 07:35:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:48:41.280267+00:00"
    },
    {
      "arxiv_id": "2601.14724v1",
      "title": "HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding",
      "title_zh": "HERMES：基于 KV 缓存层级化存储的高效流式视频理解",
      "authors": [
        "Haowei Zhang",
        "Shudong Yang",
        "Jinlan Fu",
        "See-Kiong Ng",
        "Xipeng Qiu"
      ],
      "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated significant improvement in offline video understanding. However, extending these capabilities to streaming video inputs, remains challenging, as existing models struggle to simultaneously maintain stable understanding performance, real-time responses, and low GPU memory overhead. To address this challenge, we propose HERMES, a novel training-free architecture for real-time and accurate understanding of video streams. Based on a mechanistic attention investigation, we conceptualize KV cache as a hierarchical memory framework that encapsulates video information across multiple granularities. During inference, HERMES reuses a compact KV cache, enabling efficient streaming understanding under resource constraints. Notably, HERMES requires no auxiliary computations upon the arrival of user queries, thereby guaranteeing real-time responses for continuous video stream interactions, which achieves 10$\\times$ faster TTFT compared to prior SOTA. Even when reducing video tokens by up to 68% compared with uniform sampling, HERMES achieves superior or comparable accuracy across all benchmarks, with up to 11.4% gains on streaming datasets.",
      "tldr_zh": "该研究提出了 HERMES，一种针对实时、准确的视频流理解而设计的全新 training-free 架构，旨在解决多模态大语言模型 (MLLMs) 在处理流媒体视频时难以平衡理解性能、实时响应与显存开销的难题。基于对注意力机制的机理研究，HERMES 将 KV cache 概念化为一种分层存储框架，用以封装多粒度的视频信息。在推理阶段，HERMES 通过复用紧凑的 KV cache，实现了资源受限下的高效流式理解。该架构在用户查询到达时无需进行辅助计算，确保了视频流交互的实时性，其 TTFT 速度比现有 SOTA 模型快 10 倍。实验表明，即便在 token 数量比均匀采样减少 68% 的情况下，HERMES 在各项基准测试中仍保持了领先或相当的准确度。尤其在流媒体数据集上，HERMES 取得了高达 11.4% 的性能增益，展现了其在高效视频理解方面的显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14724v1",
      "published_date": "2026-01-21 07:26:15 UTC",
      "updated_date": "2026-01-21 07:26:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:48:43.591750+00:00"
    },
    {
      "arxiv_id": "2601.14716v1",
      "title": "PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning",
      "title_zh": "PCL-Reasoner-V1.5：基于离线强化学习提升数学推理能力",
      "authors": [
        "Yao Lu",
        "Dengdong Fan",
        "Jianzheng Nie",
        "Fan Xu",
        "Jie Chen",
        "Bin Zhou",
        "Yonghong Tian"
      ],
      "abstract": "We present PCL-Reasoner-V1.5, a 32-billion-parameter large language model (LLM) for mathematical reasoning. The model is built upon Qwen2.5-32B and refined via supervised fine-tuning (SFT) followed by reinforcement learning (RL). A central innovation is our proposed offline RL method, which provides superior training stability and efficiency over standard online RL methods such as GRPO. Our model achieves state-of-the-art performance among models post-trained on Qwen2.5-32B, attaining average accuracies of 90.9% on AIME 2024 and 85.6% on AIME 2025. Our work demonstrates offline RL as a stable and efficient paradigm for advancing reasoning in LLMs. All experiments were conducted on Huawei Ascend 910C NPUs.",
      "tldr_zh": "该研究推出了 PCL-Reasoner-V1.5，这是一个具有320亿参数的数学推理大语言模型(LLM)，旨在通过离线强化学习提升复杂的逻辑推理能力。该模型基于 Qwen2.5-32B 构建，在经过有监督微调(SFT)后采用了创新的离线强化学习(Offline RL)方法进行精炼。相比于 GRPO 等主流的在线强化学习方法，该离线方案在训练稳定性和效率方面表现更为卓越。实验结果显示，PCL-Reasoner-V1.5 在 AIME 2024 和 AIME 2025 上分别取得了 90.9% 和 85.6% 的平均准确率，在同规模后训练模型中处于领先地位。该项工作确立了离线 RL 作为推进大语言模型推理能力的稳定高效范式，且所有实验均在华为 Ascend 910C NPU 上高效完成。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14716v1",
      "published_date": "2026-01-21 07:11:40 UTC",
      "updated_date": "2026-01-21 07:11:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:48:46.592860+00:00"
    },
    {
      "arxiv_id": "2601.14713v1",
      "title": "Adaptive Fidelity Estimation for Quantum Programs with Graph-Guided Noise Awareness",
      "title_zh": "基于图引导噪声感知的量子程序自适应保真度估计",
      "authors": [
        "Tingting Li",
        "Ziming Zhao",
        "Jianwei Yin"
      ],
      "abstract": "Fidelity estimation is a critical yet resource-intensive step in testing quantum programs on noisy intermediate-scale quantum (NISQ) devices, where the required number of measurements is difficult to predefine due to hardware noise, device heterogeneity, and transpilation-induced circuit transformations. We present QuFid, an adaptive and noise-aware framework that determines measurement budgets online by leveraging circuit structure and runtime statistical feedback. QuFid models a quantum program as a directed acyclic graph (DAG) and employs a control-flow-aware random walk to characterize noise propagation along gate dependencies. Backend-specific effects are captured via transpilation-induced structural deformation metrics, which are integrated into the random-walk formulation to induce a noise-propagation operator. Circuit complexity is then quantified through the spectral characteristics of this operator, providing a principled and lightweight basis for adaptive measurement planning. Experiments on 18 quantum benchmarks executed on IBM Quantum backends show that QuFid significantly reduces measurement cost compared to fixed-shot and learning-based baselines, while consistently maintaining acceptable fidelity bias.",
      "tldr_zh": "该研究提出了QuFid，一个针对含噪声中等规模量子(NISQ)设备的自适应且感知噪声的保真度评估(Fidelity estimation)框架，旨在解决由于硬件噪声、设备异构性和转译(Transpilation)导致的测量资源分配难题。该框架将量子程序建模为有向无环图(DAG)，并利用感知控制流的随机游走(Random walk)来刻画噪声沿门依赖关系的传播路径。通过集成转译引起的结构变形指标(Structural deformation metrics)，QuFid构建了噪声传播算子(Noise-propagation operator)并利用其频谱特性量化电路复杂度，为在线确定测量预算提供了理论依据。在IBM Quantum后端进行的18个量子基准测试表明，与固定采样(Fixed-shot)和基于学习的基线方法相比，QuFid在保持可接受的保真度偏置(Fidelity bias)的同时，显著降低了量子程序测试的测量成本。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "Published in AAAI 2026;",
      "pdf_url": "https://arxiv.org/pdf/2601.14713v1",
      "published_date": "2026-01-21 07:04:05 UTC",
      "updated_date": "2026-01-21 07:04:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:49:33.269671+00:00"
    },
    {
      "arxiv_id": "2601.14711v1",
      "title": "DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs",
      "title_zh": "DARA：基于强化学习微调 LLM 上下文决策的在线广告小样本预算分配",
      "authors": [
        "Mingxuan Song",
        "Yusen Huo",
        "Bohan Zhou",
        "Shenglin Yin",
        "Zhen Xiao",
        "Jieyi Long",
        "Zhilin Zhang",
        "Chuan Yu"
      ],
      "abstract": "Optimizing the advertiser's cumulative value of winning impressions under budget constraints poses a complex challenge in online advertising, under the paradigm of AI-Generated Bidding (AIGB). Advertisers often have personalized objectives but limited historical interaction data, resulting in few-shot scenarios where traditional reinforcement learning (RL) methods struggle to perform effectively. Large Language Models (LLMs) offer a promising alternative for AIGB by leveraging their in-context learning capabilities to generalize from limited data. However, they lack the numerical precision required for fine-grained optimization. To address this limitation, we introduce GRPO-Adaptive, an efficient LLM post-training strategy that enhances both reasoning and numerical precision by dynamically updating the reference policy during training. Built upon this foundation, we further propose DARA, a novel dual-phase framework that decomposes the decision-making process into two stages: a few-shot reasoner that generates initial plans via in-context prompting, and a fine-grained optimizer that refines these plans using feedback-driven reasoning. This separation allows DARA to combine LLMs' in-context learning strengths with precise adaptability required by AIGB tasks. Extensive experiments on both real-world and synthetic data environments demonstrate that our approach consistently outperforms existing baselines in terms of cumulative advertiser value under budget constraints.",
      "tldr_zh": "该研究针对在线广告(Online Advertising)中的预算分配问题提出了DARA框架，旨在解决AI-Generated Bidding (AIGB) 范式下广告主在少样本(Few-shot)场景中面临的累积价值优化难题。传统的强化学习(Reinforcement Learning)方法在数据有限时表现不佳，而大语言模型(LLMs)虽具备上下文学习(In-context learning)能力，却在精细化分配所需的数值精度上存在不足。为此，研究团队开发了GRPO-Adaptive后训练策略，通过动态更新参考策略来增强LLMs的推理能力与数值精确度。DARA框架将决策过程分解为两个阶段，即利用少样本推理器(Few-shot reasoner)生成初步方案，并由精细化优化器(Fine-grained optimizer)通过反馈驱动推理进行修正。这种设计有效结合了LLMs的泛化优势与AIGB任务所需的精确适配能力。实验结果显示，该方法在真实世界及合成数据环境下均显著优于现有基准模型，有效提升了预算约束下的广告主累积价值。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at The ACM Web Conference (WWW) 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.14711v1",
      "published_date": "2026-01-21 06:58:44 UTC",
      "updated_date": "2026-01-21 06:58:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:49:21.303925+00:00"
    },
    {
      "arxiv_id": "2601.14710v1",
      "title": "Case-Guided Sequential Assay Planning in Drug Discovery",
      "title_zh": "药物研发中基于案例引导的序贯实验规划",
      "authors": [
        "Tianchi Chen",
        "Jan Bima",
        "Sean L. Wu",
        "Otto Ritter",
        "Bingjia Yang",
        "Xiang Yu"
      ],
      "abstract": "Optimally sequencing experimental assays in drug discovery is a high-stakes planning problem under severe uncertainty and resource constraints. A primary obstacle for standard reinforcement learning (RL) is the absence of an explicit environment simulator or transition data $(s, a, s')$; planning must rely solely on a static database of historical outcomes. We introduce the Implicit Bayesian Markov Decision Process (IBMDP), a model-based RL framework designed for such simulator-free settings. IBMDP constructs a case-guided implicit model of transition dynamics by forming a nonparametric belief distribution using similar historical outcomes. This mechanism enables Bayesian belief updating as evidence accumulates and employs ensemble MCTS planning to generate stable policies that balance information gain toward desired outcomes with resource efficiency. We validate IBMDP through comprehensive experiments. On a real-world central nervous system (CNS) drug discovery task, IBMDP reduced resource consumption by up to 92\\% compared to established heuristics while maintaining decision confidence. To rigorously assess decision quality, we also benchmarked IBMDP in a synthetic environment with a computable optimal policy. Our framework achieves significantly higher alignment with this optimal policy than a deterministic value iteration alternative that uses the same similarity-based model, demonstrating the superiority of our ensemble planner. IBMDP offers a practical solution for sequential experimental design in data-rich but simulator-poor domains.",
      "tldr_zh": "该研究针对药物发现(Drug Discovery)中实验分析顺序优化面临的严重不确定性、资源限制以及缺乏显式环境模拟器或转移数据的问题，提出了一种名为Implicit Bayesian Markov Decision Process (IBMDP)的基于模型的强化学习(Model-based RL)框架。该框架通过利用相似的历史结果构建非参数信念分布，建立了案例引导的隐式转移预测模型，从而在无模拟器的环境下实现规划。IBMDP结合了贝叶斯信念更新(Bayesian belief updating)机制和集成MCTS(Ensemble MCTS)规划，能够在追求理想结果的信息增益与资源效率之间取得平衡，生成稳定的策略。在中枢神经系统(CNS)药物发现的真实任务验证中，IBMDP与既有的启发式方法相比，在保持决策置信度的同时将资源消耗降低了高达92%。此外，合成环境下的基准测试显示，该框架生成的策略与最优策略的一致性显著优于使用相同相似性模型的确定性价值迭代方案。实验结果证明了IBMDP在数据丰富但缺乏模拟器的领域中进行序列实验设计的优越性与实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14710v1",
      "published_date": "2026-01-21 06:58:01 UTC",
      "updated_date": "2026-01-21 06:58:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:49:08.026275+00:00"
    },
    {
      "arxiv_id": "2601.14705v1",
      "title": "Proximal Policy Optimization with Evolutionary Mutations",
      "title_zh": "结合进化变异的近端策略优化",
      "authors": [
        "Casimir Czworkowski",
        "Stephen Hornish",
        "Alhassan S. Yasin"
      ],
      "abstract": "Proximal Policy Optimization (PPO) is a widely used reinforcement learning algorithm known for its stability and sample efficiency, but it often suffers from premature convergence due to limited exploration. In this paper, we propose POEM (Proximal Policy Optimization with Evolutionary Mutations), a novel modification to PPO that introduces an adaptive exploration mechanism inspired by evolutionary algorithms. POEM enhances policy diversity by monitoring the Kullback-Leibler (KL) divergence between the current policy and a moving average of previous policies. When policy changes become minimal, indicating stagnation, POEM triggers an adaptive mutation of policy parameters to promote exploration. We evaluate POEM on four OpenAI Gym environments: CarRacing, MountainCar, BipedalWalker, and LunarLander. Through extensive fine-tuning using Bayesian optimization techniques and statistical testing using Welch's t-test, we find that POEM significantly outperforms PPO on three of the four tasks (BipedalWalker: t=-2.0642, p=0.0495; CarRacing: t=-6.3987, p=0.0002; MountainCar: t=-6.2431, p<0.0001), while performance on LunarLander is not statistically significant (t=-1.8707, p=0.0778). Our results highlight the potential of integrating evolutionary principles into policy gradient methods to overcome exploration-exploitation tradeoffs.",
      "tldr_zh": "该研究针对 Proximal Policy Optimization (PPO) 算法因探索受限而容易导致过早收敛的问题，提出了 POEM (Proximal Policy Optimization with Evolutionary Mutations)。POEM 引入了一种受进化算法启发的自适应探索机制，通过监测当前策略与先前策略移动平均值之间的 Kullback-Leibler (KL) 散度来实时评估策略多样性。当检测到策略更新停滞时，POEM 会触发策略参数的自适应变异以强制增加探索空间。研究团队在 CarRacing、MountainCar、BipedalWalker 和 LunarLander 等四个 OpenAI Gym 环境中进行了评估，并利用 Bayesian optimization 和 Welch's t-test 进行了统计验证。实验结果表明，POEM 在其中三项任务中的表现显著优于基准 PPO 算法。该研究展示了将进化原理集成到策略梯度方法中以优化探索与利用平衡 (exploration-exploitation tradeoffs) 的巨大潜力。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "10 pages, 5 figures, 2 tables, 1 algorithm",
      "pdf_url": "https://arxiv.org/pdf/2601.14705v1",
      "published_date": "2026-01-21 06:34:53 UTC",
      "updated_date": "2026-01-21 06:34:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:49:54.034957+00:00"
    },
    {
      "arxiv_id": "2601.14702v1",
      "title": "AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving",
      "title_zh": "AutoDriDM：面向自动驾驶视觉语言模型决策的可解释基准",
      "authors": [
        "Zecong Tang",
        "Zixu Wang",
        "Yifei Wang",
        "Weitong Lian",
        "Tianjian Gao",
        "Haoran Li",
        "Tengju Ru",
        "Lingyi Meng",
        "Zhejun Cui",
        "Yichen Zhu",
        "Qi Kang",
        "Kaixuan Wang",
        "Yu Zhang"
      ],
      "abstract": "Autonomous driving is a highly challenging domain that requires reliable perception and safe decision-making in complex scenarios. Recent vision-language models (VLMs) demonstrate reasoning and generalization abilities, opening new possibilities for autonomous driving; however, existing benchmarks and metrics overemphasize perceptual competence and fail to adequately assess decision-making processes. In this work, we present AutoDriDM, a decision-centric, progressive benchmark with 6,650 questions across three dimensions - Object, Scene, and Decision. We evaluate mainstream VLMs to delineate the perception-to-decision capability boundary in autonomous driving, and our correlation analysis reveals weak alignment between perception and decision-making performance. We further conduct explainability analyses of models' reasoning processes, identifying key failure modes such as logical reasoning errors, and introduce an analyzer model to automate large-scale annotation. AutoDriDM bridges the gap between perception-centered and decision-centered evaluation, providing guidance toward safer and more reliable VLMs for real-world autonomous driving.",
      "tldr_zh": "该研究提出了 AutoDriDM，这是一个针对 Autonomous Driving 领域中 Vision-Language Models (VLMs) 决策能力的解释性 Benchmark。针对现有评估指标过度强调 Perceptual Competence 的问题，AutoDriDM 构建了包含 6,650 个问题的评估体系，涵盖 Object、Scene 和 Decision 三个维度。通过对主流 VLMs 的评估，研究发现感知性能与决策表现之间的关联性较弱，并识别出逻辑推理错误等关键 Failure Modes。此外，该工作引入了一个 Analyzer Model 以实现大规模自动标注。AutoDriDM 弥补了感知驱动与决策驱动评估之间的鸿沟，为构建更安全、更可靠的真实世界自动驾驶 VLMs 提供了重要指导。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages. Submitted to ACL ARR 2026 January",
      "pdf_url": "https://arxiv.org/pdf/2601.14702v1",
      "published_date": "2026-01-21 06:29:09 UTC",
      "updated_date": "2026-01-21 06:29:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:49:44.743861+00:00"
    },
    {
      "arxiv_id": "2601.14697v1",
      "title": "When Text-as-Vision Meets Semantic IDs in Generative Recommendation: An Empirical Study",
      "title_zh": "当“文本即视觉”遇上生成式推荐中的语义 ID：一项实证研究",
      "authors": [
        "Shutong Qiao",
        "Wei Yuan",
        "Tong Chen",
        "Xiangyu Zhao",
        "Quoc Viet Hung Nguyen",
        "Hongzhi Yin"
      ],
      "abstract": "Semantic ID learning is a key interface in Generative Recommendation (GR) models, mapping items to discrete identifiers grounded in side information, most commonly via a pretrained text encoder. However, these text encoders are primarily optimized for well-formed natural language. In real-world recommendation data, item descriptions are often symbolic and attribute-centric, containing numerals, units, and abbreviations. These text encoders can break these signals into fragmented tokens, weakening semantic coherence and distorting relationships among attributes. Worse still, when moving to multimodal GR, relying on standard text encoders introduces an additional obstacle: text and image embeddings often exhibit mismatched geometric structures, making cross-modal fusion less effective and less stable.\n  In this paper, we revisit representation design for Semantic ID learning by treating text as a visual signal. We conduct a systematic empirical study of OCR-based text representations, obtained by rendering item descriptions into images and encoding them with vision-based OCR models. Experiments across four datasets and two generative backbones show that OCR-text consistently matches or surpasses standard text embeddings for Semantic ID learning in both unimodal and multimodal settings. Furthermore, we find that OCR-based Semantic IDs remain robust under extreme spatial-resolution compression, indicating strong robustness and efficiency in practical deployments.",
      "tldr_zh": "该研究针对生成式推荐 (Generative Recommendation, GR) 模型中 Semantic ID 学习面临的挑战，指出传统预训练文本编码器在处理包含数字、单位和缩写等属性化文本时存在语义碎片化问题，且在多模态场景下易导致图文嵌入不匹配。为此，论文提出了一种将文本视为视觉信号的新视角，并对基于 OCR 的文本表示进行了系统的实证研究，通过将物品描述渲染为图像并利用视觉 OCR 模型进行编码。在四个数据集和两个生成式骨架网络上的实验结果显示，无论在单模态还是多模态设置下，基于 OCR 的文本表示在 Semantic ID 学习方面的表现均能达到或超过标准的文本嵌入。研究进一步发现，基于 OCR 的 Semantic IDs 在极端的空间分辨率压缩下仍能保持鲁棒性，展示了其在实际部署中强大的稳定性与效率，为优化生成式推荐系统的表征设计提供了有效的实证依据。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14697v1",
      "published_date": "2026-01-21 06:18:57 UTC",
      "updated_date": "2026-01-21 06:18:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:50:10.379056+00:00"
    },
    {
      "arxiv_id": "2601.14695v1",
      "title": "CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation",
      "title_zh": "CoScale-RL：基于数据与计算协同缩放的高效后训练",
      "authors": [
        "Yutong Chen",
        "Jiandong Gao",
        "Ji Wu"
      ],
      "abstract": "Training Large Reasoning Model (LRM) is usually unstable and unpredictable, especially on hard problems or weak foundation models. We found that the current post-training scaling strategy can still improve on these cases. We propose CoScale-RL, a novel scaling strategy with better data and computational efficiency. We first scale up solutions to make problems solvable. The core idea is to collect multiple solutions for each problem, rather than simply enlarging the dataset. Then, we scale up rollout computation to stabilize Reinforcement Learning. We further leverage a model merge technique called Re-distillation to sustain or even improve computational efficiency when scaling up. Our method significantly improves data and computational efficiency, with an average 3.76$\\times$ accuracy improvement on four benchmarks. CoScale-RL is able to improve an LRM's ability boundary without an extensive SFT dataset. Our method provides a new scaling direction to further improve LRM's reasoning ability.",
      "tldr_zh": "该研究针对大型推理模型（Large Reasoning Model, LRM）在处理难题或弱基础模型时训练不稳定且不可预测的问题，提出了CoScale-RL。这是一种通过协同扩展数据与计算资源来提高后训练（Post-Training）效率的新型扩展策略。该方法首先通过为每个问题收集多个解（multiple solutions）而非单纯扩大数据集规模来扩展解决方案，使复杂问题变得可解。随后，研究通过扩展展开计算（rollout computation）来稳定强化学习（Reinforcement Learning）过程，并利用重蒸馏（Re-distillation）模型合并（model merge）技术在扩展时维持并提升计算效率。实验表明，CoScale-RL在四个基准测试中平均实现了3.76倍的准确率提升，显著优化了数据和计算效率。该方法在无需大规模有监督微调（SFT）数据集的情况下有效拓展了LRM的能力边界，为增强模型推理能力提供了新的扩展方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "preprint",
      "pdf_url": "https://arxiv.org/pdf/2601.14695v1",
      "published_date": "2026-01-21 06:17:52 UTC",
      "updated_date": "2026-01-21 06:17:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:50:21.754577+00:00"
    },
    {
      "arxiv_id": "2601.14694v1",
      "title": "Re-understanding Graph Unlearning through Memorization",
      "title_zh": "基于记忆视角的图机器遗忘再认识",
      "authors": [
        "Pengfei Ding",
        "Yan Wang",
        "Guanfeng Liu"
      ],
      "abstract": "Graph unlearning (GU), which removes nodes, edges, or features from trained graph neural networks (GNNs), is crucial in Web applications where graph data may contain sensitive, mislabeled, or malicious information. However, existing GU methods lack a clear understanding of the key factors that determine unlearning effectiveness, leading to three fundamental limitations: (1) impractical and inaccurate GU difficulty assessment due to test-access requirements and invalid assumptions, (2) ineffectiveness on hard-to-unlearn tasks, and (3) misaligned evaluation protocols that overemphasize easy tasks and fail to capture true forgetting capability. To address these issues, we establish GNN memorization as a new perspective for understanding graph unlearning and propose MGU, a Memorization-guided Graph Unlearning framework. MGU achieves three key advances: it provides accurate and practical difficulty assessment across different GU tasks, develops an adaptive strategy that dynamically adjusts unlearning objectives based on difficulty levels, and establishes a comprehensive evaluation protocol that aligns with practical requirements. Extensive experiments on ten real-world graphs demonstrate that MGU consistently outperforms state-of-the-art baselines in forgetting quality, computational efficiency, and utility preservation.",
      "tldr_zh": "该研究针对图神经网络(GNNs)中的图遗忘(Graph Unlearning, GU)技术展开，指出现有方法在GU难度评估、处理困难遗忘任务及评估协议对齐方面存在显著局限。为此，论文通过引入GNN记忆化(Memorization)的新视角，提出了记忆化引导的图遗忘框架MGU。MGU实现了对不同GU任务准确的难度评估，并根据难度水平动态调整遗忘目标的自适应策略，同时建立了更符合实际需求的综合评价协议。在十个真实世界图数据集上的广泛实验证明，MGU在遗忘质量(Forgetting Quality)、计算效率和模型效用保持(Utility Preservation)方面一致优于现有的先进基线模型。该工作深化了对图遗忘机制的理解，为Web应用中敏感或错误信息的移除提供了更稳健的技术支撑。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by WWW-2026",
      "pdf_url": "https://arxiv.org/pdf/2601.14694v1",
      "published_date": "2026-01-21 06:14:23 UTC",
      "updated_date": "2026-01-21 06:14:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:50:42.190133+00:00"
    },
    {
      "arxiv_id": "2601.14693v1",
      "title": "Beyond Error-Based Optimization: Experience-Driven Symbolic Regression with Goal-Conditioned Reinforcement Learning",
      "title_zh": "超越基于误差的优化：基于目标条件强化学习的经验驱动符号回归",
      "authors": [
        "Jianwen Sun",
        "Xinrui Li",
        "Fuqing Li",
        "Xiaoxuan Shen"
      ],
      "abstract": "Symbolic Regression aims to automatically identify compact and interpretable mathematical expressions that model the functional relationship between input and output variables. Most existing search-based symbolic regression methods typically rely on the fitting error to inform the search process. However, in the vast expression space, numerous candidate expressions may exhibit similar error values while differing substantially in structure, leading to ambiguous search directions and hindering convergence to the underlying true function. To address this challenge, we propose a novel framework named EGRL-SR (Experience-driven Goal-conditioned Reinforcement Learning for Symbolic Regression). In contrast to traditional error-driven approaches, EGRL-SR introduces a new perspective: leveraging precise historical trajectories and optimizing the action-value network to proactively guide the search process, thereby achieving a more robust expression search. Specifically, we formulate symbolic regression as a goal-conditioned reinforcement learning problem and incorporate hindsight experience replay, allowing the action-value network to generalize common mapping patterns from diverse input-output pairs. Moreover, we design an all-point satisfaction binary reward function that encourages the action-value network to focus on structural patterns rather than low-error expressions, and concurrently propose a structure-guided heuristic exploration strategy to enhance search diversity and space coverage. Experiments on public benchmarks show that EGRL-SR consistently outperforms state-of-the-art methods in recovery rate and robustness, and can recover more complex expressions under the same search budget. Ablation results validate that the action-value network effectively guides the search, with both the reward function and the exploration strategy playing critical roles.",
      "tldr_zh": "该研究提出了 EGRL-SR 框架，旨在解决 Symbolic Regression 在庞大搜索空间中因传统误差驱动优化导致搜索方向模糊的问题。EGRL-SR 将符号回归建模为 Goal-conditioned Reinforcement Learning 问题，并引入 Hindsight Experience Replay 技术，使动作价值网络能够从历史轨迹中泛化出通用的映射模式。通过设计全点满足二元奖励函数 (all-point satisfaction binary reward function)，该框架引导模型关注表达式的结构模式而非仅仅是低误差。此外，研究还提出了一种结构导向的启发式探索策略 (structure-guided heuristic exploration strategy)，以显著增强搜索的多样性和空间覆盖率。实验结果表明，EGRL-SR 在恢复率和鲁棒性方面均优于现有的 SOTA 方法，且能够在相同的搜索预算下恢复更复杂的数学表达式。消融实验证实了动作价值网络在搜索引导中的核心作用，并验证了所提奖励函数与探索策略的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14693v1",
      "published_date": "2026-01-21 06:08:37 UTC",
      "updated_date": "2026-01-21 06:08:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:50:33.031209+00:00"
    },
    {
      "arxiv_id": "2601.14691v2",
      "title": "Gaming the Judge: Unfaithful Chain-of-Thought Can Undermine Agent Evaluation",
      "title_zh": "Gaming the Judge：不忠实的链式思维可能削弱智能体评估",
      "authors": [
        "Muhammad Khalifa",
        "Lajanugen Logeswaran",
        "Jaekyeom Kim",
        "Sungryull Sohn",
        "Yunxiang Zhang",
        "Moontae Lee",
        "Hao Peng",
        "Lu Wang",
        "Honglak Lee"
      ],
      "abstract": "Large language models (LLMs) are increasingly used as judges to evaluate agent performance, particularly in non-verifiable settings where judgments rely on agent trajectories including chain-of-thought (CoT) reasoning. This paradigm implicitly assumes that the agent's CoT faithfully reflects both its internal reasoning and the underlying environment state. We show this assumption is brittle: LLM judges are highly susceptible to manipulation of agent reasoning traces. By systematically rewriting agent CoTs while holding actions and observations fixed, we demonstrate that manipulated reasoning alone can inflate false positive rates of state-of-the-art VLM judges by up to 90% across 800 trajectories spanning diverse web tasks. We study manipulation strategies spanning style-based approaches that alter only the presentation of reasoning and content-based approaches that fabricate signals of task progress, and find that content-based manipulations are consistently more effective. We evaluate prompting-based techniques and scaling judge-time compute, which reduce but do not fully eliminate susceptibility to manipulation. Our findings reveal a fundamental vulnerability in LLM-based evaluation and highlight the need for judging mechanisms that verify reasoning claims against observable evidence.",
      "tldr_zh": "该研究探讨了大型语言模型（LLM）作为裁判评估智能体性能时的可靠性，指出当前依赖 Chain-of-Thought (CoT) 推理的评估范式存在重大风险。作者发现，LLM 裁判极易受到不诚实推理轨迹的操纵，即在保持智能体实际动作和环境观察不变的情况下，仅通过重写 CoT 即可显著干扰评估结果。实验表明，这种操纵策略在 800 个 Web 任务轨迹中能使先进 VLM 裁判的误报率 (false positive rates) 提升高达 90%，其中伪造任务进度的内容级操纵比风格级操纵更为有效。尽管通过优化提示词或增加裁判端计算量 (judge-time compute) 可以缓解该问题，但无法从根本上消除这种脆弱性。该研究揭示了基于 LLM 评估机制的本质漏洞，强调了未来需要开发能够基于可观测证据来验证推理主张的评估机制。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14691v2",
      "published_date": "2026-01-21 06:07:43 UTC",
      "updated_date": "2026-01-22 05:12:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:50:31.502953+00:00"
    },
    {
      "arxiv_id": "2601.14686v1",
      "title": "IB-GRPO: Aligning LLM-based Learning Path Recommendation with Educational Objectives via Indicator-Based Group Relative Policy Optimization",
      "title_zh": "IB-GRPO：通过基于指标的群体相对策略优化实现大语言模型学习路径推荐与教学目标对齐",
      "authors": [
        "Shuai Wang",
        "Yaoming Yang",
        "Bingdong Li",
        "Hao Hao",
        "Aimin Zhou"
      ],
      "abstract": "Learning Path Recommendation (LPR) aims to generate personalized sequences of learning items that maximize long-term learning effect while respecting pedagogical principles and operational constraints. Although large language models (LLMs) offer rich semantic understanding for free-form recommendation, applying them to long-horizon LPR is challenging due to (i) misalignment with pedagogical objectives such as the Zone of Proximal Development (ZPD) under sparse, delayed feedback, (ii) scarce and costly expert demonstrations, and (iii) multi-objective interactions among learning effect, difficulty scheduling, length controllability, and trajectory diversity. To address these issues, we propose IB-GRPO (Indicator-Based Group Relative Policy Optimization), an indicator-guided alignment approach for LLM-based LPR. To mitigate data scarcity, we construct hybrid expert demonstrations via Genetic Algorithm search and teacher RL agents and warm-start the LLM with supervised fine-tuning. Building on this warm-start, we design a within-session ZPD alignment score for difficulty scheduling. IB-GRPO then uses the $I_{ε+}$ dominance indicator to compute group-relative advantages over multiple objectives, avoiding manual scalarization and improving Pareto trade-offs. Experiments on ASSIST09 and Junyi using the KES simulator with a Qwen2.5-7B backbone show consistent improvements over representative RL and LLM baselines.",
      "tldr_zh": "该研究针对基于大语言模型(LLMs)的学习路径推荐(Learning Path Recommendation, LPR)中存在的教学目标失配、专家数据稀缺以及多目标权衡复杂等挑战，提出了IB-GRPO（基于指标的分组相对策略优化）对齐框架。为了解决数据稀缺问题，该方法通过遗传算法(Genetic Algorithm)搜索和教师强化学习智能体构建了混合专家演示数据，并利用监督微调(Supervised Fine-Tuning)对模型进行热启动。在对齐策略方面，IB-GRPO设计了会话内近侧发展区(Zone of Proximal Development, ZPD)对齐分数以优化难度调度，并引入$I_{ε+}$支配指标来计算多目标下的分组相对优势，有效避免了手动标量化并改进了帕累托(Pareto)权衡。实验结果显示，以Qwen2.5-7B为底座的IB-GRPO在ASSIST09和Junyi数据集上表现优异，其性能一致超过了传统的强化学习和LLM基线模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14686v1",
      "published_date": "2026-01-21 06:03:05 UTC",
      "updated_date": "2026-01-21 06:03:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:50:43.322226+00:00"
    },
    {
      "arxiv_id": "2601.14683v1",
      "title": "Local Language Models for Context-Aware Adaptive Anonymization of Sensitive Text",
      "title_zh": "用于敏感文本上下文感知自适应匿名化的本地语言模型",
      "authors": [
        "Aisvarya Adeseye",
        "Jouni Isoaho",
        "Seppo Virtanen",
        "Mohammad Tahir"
      ],
      "abstract": "Qualitative research often contains personal, contextual, and organizational details that pose privacy risks if not handled appropriately. Manual anonymization is time-consuming, inconsistent, and frequently omits critical identifiers. Existing automated tools tend to rely on pattern matching or fixed rules, which fail to capture context and may alter the meaning of the data. This study uses local LLMs to build a reliable, repeatable, and context-aware anonymization process for detecting and anonymizing sensitive data in qualitative transcripts. We introduce a Structured Framework for Adaptive Anonymizer (SFAA) that includes three steps: detection, classification, and adaptive anonymization. The SFAA incorporates four anonymization strategies: rule-based substitution, context-aware rewriting, generalization, and suppression. These strategies are applied based on the identifier type and the risk level. The identifiers handled by the SFAA are guided by major international privacy and research ethics standards, including the GDPR, HIPAA, and OECD guidelines. This study followed a dual-method evaluation that combined manual and LLM-assisted processing. Two case studies were used to support the evaluation. The first includes 82 face-to-face interviews on gamification in organizations. The second involves 93 machine-led interviews using an AI-powered interviewer to test LLM awareness and workplace privacy. Two local models, LLaMA and Phi were used to evaluate the performance of the proposed framework. The results indicate that the LLMs found more sensitive data than a human reviewer. Phi outperformed LLaMA in finding sensitive data, but made slightly more errors. Phi was able to find over 91% of the sensitive data and 94.8% kept the same sentiment as the original text, which means it was very accurate, hence, it does not affect the analysis of the qualitative data.",
      "tldr_zh": "该研究提出了一种利用本地大语言模型 (Local LLMs) 进行上下文感知自适应匿名化处理的方法，旨在解决定性研究中手动匿名化效率低下且缺乏语境理解的问题。研究引入了结构化自适应匿名化框架 (SFAA)，该框架包含检测、分类和自适应匿名化三个阶段，并整合了规则替换、上下文重写、泛化及抑制四种策略。SFAA 的构建参考了 GDPR、HIPAA 和 OECD 等国际隐私与伦理标准，确保了匿名化过程的合规性与严谨性。通过对涉及企业游戏化和 AI 访谈的两项案例研究进行评估，实验对比了 LLaMA 和 Phi 模型的性能表现。结果表明，Local LLMs 在识别敏感数据方面优于人工评审，其中 Phi 模型达到了超过 91% 的敏感数据检出率。此外，94.8% 的匿名化文本保留了原始情感，证明该框架在保护隐私的同时，能有效维持定性数据分析的完整性与准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted and Waiting to be Published. ICAI'25: 27th International Conference on Artificial Intelligence https://american-cse.org/csce2025/conferences-ICAI",
      "pdf_url": "https://arxiv.org/pdf/2601.14683v1",
      "published_date": "2026-01-21 05:59:56 UTC",
      "updated_date": "2026-01-21 05:59:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:50:35.992409+00:00"
    },
    {
      "arxiv_id": "2601.14679v1",
      "title": "HCVR Scene Generation: High Compatibility Virtual Reality Environment Generation for Extended Redirected Walking",
      "title_zh": "HCVR 场景生成：面向扩展重定向行走的高兼容性虚拟现实环境生成",
      "authors": [
        "Yiran Zhang",
        "Xingpeng Sun",
        "Aniket Bera"
      ],
      "abstract": "Natural walking enhances immersion in virtual environments (VEs), but physical space limitations and obstacles hinder exploration, especially in large virtual scenes. Redirected Walking (RDW) techniques mitigate this by subtly manipulating the virtual camera to guide users away from physical collisions within pre-defined VEs. However, RDW efficacy diminishes significantly when substantial geometric divergence exists between the physical and virtual environments, leading to unavoidable collisions. Existing scene generation methods primarily focus on object relationships or layout aesthetics, often neglecting the crucial aspect of physical compatibility required for effective RDW. To address this, we introduce HCVR (High Compatibility Virtual Reality Environment Generation), a novel framework that generates virtual scenes inherently optimized for alignment-based RDW controllers. HCVR first employs ENI++, a novel, boundary-sensitive metric to evaluate the incompatibility between physical and virtual spaces by comparing rotation-sensitive visibility polygons. Guided by the ENI++ compatibility map and user prompts, HCVR utilizes a Large Language Model (LLM) for context-aware 3D asset retrieval and initial layout generation. The framework then strategically adjusts object selection, scaling, and placement to maximize coverage of virtually incompatible regions, effectively guiding users towards RDW-feasible paths. User studies evaluating physical collisions and layout quality demonstrate HCVR's effectiveness with HCVR-generated scenes, resulting in 22.78 times fewer physical collisions and received 35.89\\% less on ENI++ score compared to LLM-based generation with RDW, while also receiving 12.5\\% higher scores on user feedback to layout design.",
      "tldr_zh": "该研究提出了HCVR (High Compatibility Virtual Reality Environment Generation) 框架，旨在解决自然行走在虚拟环境中受物理空间几何差异限制而导致的Redirected Walking (RDW) 失效问题。该框架引入了名为ENI++的新型边界敏感度量标准，通过比较旋转敏感的可视多边形来精准评估物理与虚拟空间的不兼容性。在ENI++兼容性图和用户提示的指导下，HCVR利用大语言模型(LLM)进行上下文感知的3D资产检索和初始布局生成，并战略性地调整物体的选择、缩放与位置，以覆盖虚拟不兼容区域并引导用户进入RDW可行路径。实验评估表明，HCVR生成的场景相比传统基于LLM的生成方法使物理碰撞减少了22.78倍，ENI++评分降低了35.89%，同时在布局设计的用户反馈中提升了12.5%的满意度。",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14679v1",
      "published_date": "2026-01-21 05:51:03 UTC",
      "updated_date": "2026-01-21 05:51:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:51:05.436017+00:00"
    },
    {
      "arxiv_id": "2601.14678v1",
      "title": "Transfer Learning from One Cancer to Another via Deep Learning Domain Adaptation",
      "title_zh": "基于深度学习领域自适应的跨癌种迁移学习",
      "authors": [
        "Justin Cheung",
        "Samuel Savine",
        "Calvin Nguyen",
        "Lin Lu",
        "Alhassan S. Yasin"
      ],
      "abstract": "Supervised deep learning models often achieve excellent performance within their training distribution but struggle to generalize beyond it. In cancer histopathology, for example, a convolutional neural network (CNN) may classify cancer severity accurately for cancer types represented in its training data, yet fail on related but unseen types. Although adenocarcinomas from different organs share morphological features that might support limited cross-domain generalization, addressing domain shift directly is necessary for robust performance. Domain adaptation offers a way to transfer knowledge from labeled data in one cancer type to unlabeled data in another, helping mitigate the scarcity of annotated medical images.\n  This work evaluates cross-domain classification performance among lung, colon, breast, and kidney adenocarcinomas. A ResNet50 trained on any single adenocarcinoma achieves over 98% accuracy on its own domain but shows minimal generalization to others. Ensembling multiple supervised models does not resolve this limitation. In contrast, converting the ResNet50 into a domain adversarial neural network (DANN) substantially improves performance on unlabeled target domains. A DANN trained on labeled breast and colon data and adapted to unlabeled lung data reaches 95.56% accuracy.\n  We also examine the impact of stain normalization on domain adaptation. Its effects vary by target domain: for lung, accuracy drops from 95.56% to 66.60%, while for breast and colon targets, stain normalization boosts accuracy from 49.22% to 81.29% and from 78.48% to 83.36%, respectively. Finally, using Integrated Gradients reveals that DANNs consistently attribute importance to biologically meaningful regions such as densely packed nuclei, indicating that the model learns clinically relevant features and can apply them to unlabeled cancer types.",
      "tldr_zh": "该研究探讨了在癌症组织病理学影像中，如何利用深度学习的 Domain Adaptation 技术实现不同癌症类型间的迁移学习，以解决 CNN 模型跨领域泛化能力不足的问题。实验表明，传统的 ResNet50 虽然在单一训练领域表现优异，但在处理未见过的癌症类型时效果极差，而将其转化为 Domain Adversarial Neural Network (DANN) 则能显著提升在未标注目标领域上的分类表现。例如，在乳腺和结肠癌数据上训练并适配至肺癌领域时，DANN 的准确率可达 95.56%。研究还分析了 Stain Normalization 对不同目标领域影响的差异性，并利用 Integrated Gradients 证实了模型学习到了如细胞核密集区域等具有生物学意义的临床特征。该研究证明了领域自适应技术能够有效利用已标注癌症数据来提升对未标注新癌症类型的诊断性能，为缓解医疗影像标注数据稀缺问题提供了可行路径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "q-bio.TO"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 6 figures, 3 table",
      "pdf_url": "https://arxiv.org/pdf/2601.14678v1",
      "published_date": "2026-01-21 05:50:34 UTC",
      "updated_date": "2026-01-21 05:50:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:51:03.742609+00:00"
    },
    {
      "arxiv_id": "2601.14677v1",
      "title": "A comprehensive overview of deep learning models for object detection from videos/images",
      "title_zh": "视频与图像目标检测深度学习模型全面综述",
      "authors": [
        "Sukana Zulfqar",
        "Sadia Saeed",
        "M. Azam Zia",
        "Anjum Ali",
        "Faisal Mehmood",
        "Abid Ali"
      ],
      "abstract": "Object detection in video and image surveillance is a well-established yet rapidly evolving task, strongly influenced by recent deep learning advancements. This review summarises modern techniques by examining architectural innovations, generative model integration, and the use of temporal information to enhance robustness and accuracy. Unlike earlier surveys, it classifies methods based on core architectures, data processing strategies, and surveillance specific challenges such as dynamic environments, occlusions, lighting variations, and real-time requirements. The primary goal is to evaluate the current effectiveness of semantic object detection, while secondary aims include analysing deep learning models and their practical applications. The review covers CNN-based detectors, GAN-assisted approaches, and temporal fusion methods, highlighting how generative models support tasks such as reconstructing missing frames, reducing occlusions, and normalising illumination. It also outlines preprocessing pipelines, feature extraction progress, benchmarking datasets, and comparative evaluations. Finally, emerging trends in low-latency, efficient, and spatiotemporal learning approaches are identified for future research.",
      "tldr_zh": "该综述全面总结了基于视频和图像监控的物体检测(Object detection)领域的现代深度学习技术，系统探讨了架构创新、生成模型(Generative model)集成以及时间信息(Temporal information)的利用。与以往研究不同，本文根据核心架构、数据处理策略以及监控特有的挑战（如动态环境、遮挡(Occlusions)和光照变化）对现有方法进行了详细分类。研究重点涵盖了基于卷积神经网络(CNN-based)的检测器、生成对抗网络(GAN)辅助方法及时间融合技术，特别强调了生成模型在重建缺失帧、减少遮挡影响及光照归一化方面的显著作用。此外，论文还概述了预处理流程(Preprocessing pipelines)、特征提取进展、基准数据集(Benchmarking datasets)以及各类模型的对比评估。最后，该研究识别了低延迟(Low-latency)、高效能和时空学习(Spatiotemporal learning)等新兴趋势，为未来物体检测技术的发展奠定了理论基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "N/A",
      "pdf_url": "https://arxiv.org/pdf/2601.14677v1",
      "published_date": "2026-01-21 05:50:21 UTC",
      "updated_date": "2026-01-21 05:50:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:50:48.791382+00:00"
    },
    {
      "arxiv_id": "2601.14673v1",
      "title": "Efficient reformulations of ReLU deep neural networks for surrogate modelling in power system optimisation",
      "title_zh": "电力系统优化代理建模中 ReLU 深层神经网络的高效重构",
      "authors": [
        "Yogesh Pipada Sunil Kumar",
        "S. Ali Pourmousavi",
        "Jon A. R. Liisberg",
        "Julian Lesmos-Vinasco"
      ],
      "abstract": "The ongoing decarbonisation of power systems is driving an increasing reliance on distributed energy resources, which introduces complex and nonlinear interactions that are difficult to capture in conventional optimisation models. As a result, machine learning based surrogate modelling has emerged as a promising approach, but integrating machine learning models such as ReLU deep neural networks (DNNs) directly into optimisation often results in nonconvex and computationally intractable formulations. This paper proposes a linear programming (LP) reformulation for a class of convexified ReLU DNNs with non-negative weight matrices beyond the first layer, enabling a tight and tractable embedding of learned surrogate models in optimisation. We evaluate the method using a case study on learning the prosumer's responsiveness within an aggregator bidding problem in the Danish tertiary capacity market. The proposed reformulation is benchmarked against state-of-the-art alternatives, including piecewise linearisation (PWL), MIP-based embedding, and other LP relaxations. Across multiple neural network architectures and market scenarios, the convexified ReLU DNN achieves solution quality comparable to PWL and MIP-based reformulations while significantly improving computational performance and preserving model fidelity, unlike penalty-based reformulations. The results demonstrate that convexified ReLU DNNs offer a scalable and reliable methodology for integrating learned surrogate models in optimisation, with applicability to a wide range of emerging power system applications.",
      "tldr_zh": "该研究探讨了电力系统去碳化背景下，将 ReLU deep neural networks (DNNs) 作为代理模型集成到常规优化模型中时所面临的非凸性和计算不可行性挑战。作者针对除第一层外具有非负权重矩阵的一类凸化 ReLU DNNs，提出了一种高效的 Linear Programming (LP) 重构方法，使学习到的代理模型能够紧凑且易于处理地嵌入到优化框架中。研究通过丹麦三级容量市场中聚合商竞价场景下的产消者响应能力学习进行了案例分析，并将该方法与 Piecewise Linearisation (PWL)、基于 Mixed-Integer Programming (MIP) 的嵌入及其他 LP relaxations 方案进行了对比。实验结果表明，该凸化 ReLU DNNs 方法在保持模型保真度的同时，其解的质量可与 PWL 和 MIP 方案相媲美，且显著提升了计算效率。该研究为新兴电力系统应用中集成学习型代理模型提供了一种具备可扩展性和可靠性的方法论，有效解决了复杂非线性交互的建模难题。",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "primary_category": "eess.SY",
      "comment": "24 pages, 7 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.14673v1",
      "published_date": "2026-01-21 05:40:27 UTC",
      "updated_date": "2026-01-21 05:40:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:51:35.312494+00:00"
    },
    {
      "arxiv_id": "2601.14672v1",
      "title": "GEGO: A Hybrid Golden Eagle and Genetic Optimization Algorithm for Efficient Hyperparameter Tuning in Resource-Constrained Environments",
      "title_zh": "GEGO：一种面向资源受限环境高效超参数调优的金雕遗传混合优化算法",
      "authors": [
        "Amaras Nazarians",
        "Sachin Kumar"
      ],
      "abstract": "Hyperparameter tuning is a critical yet computationally expensive step in training neural networks, particularly when the search space is high dimensional and nonconvex. Metaheuristic optimization algorithms are often used for this purpose due to their derivative free nature and robustness against local optima. In this work, we propose Golden Eagle Genetic Optimization (GEGO), a hybrid metaheuristic that integrates the population movement strategy of Golden Eagle Optimization with the genetic operators of selection, crossover, and mutation.\n  The main novelty of GEGO lies in embedding genetic operators directly into the iterative search process of GEO, rather than applying them as a separate evolutionary stage. This design improves population diversity during search and reduces premature convergence while preserving the exploration behavior of GEO.\n  GEGO is evaluated on standard unimodal, multimodal, and composite benchmark functions from the CEC2017 suite, where it consistently outperforms its constituent algorithms and several classical metaheuristics in terms of solution quality and robustness. The algorithm is further applied to hyperparameter tuning of artificial neural networks on the MNIST dataset, where GEGO achieves improved classification accuracy and more stable convergence compared to GEO and GA. These results indicate that GEGO provides a balanced exploration-exploitation tradeoff and is well suited for hyperparameter optimization under constrained computational settings.",
      "tldr_zh": "该研究提出了一种名为 GEGO (Golden Eagle Genetic Optimization) 的混合元启发式算法，旨在解决资源受限环境下神经网络的高效超参数调优问题。该算法将 Golden Eagle Optimization (GEO) 的种群移动策略与 Genetic Algorithm (GA) 的选择、交叉及变异算子有机结合。其核心创新在于将遗传算子直接嵌入到 GEO 的迭代搜索过程中，从而在保留探索特性的同时，显著提升了种群多样性并有效抑制了早熟收敛 (Premature Convergence)。在 CEC2017 基准测试以及 MNIST 数据集的神经网络超参数优化实验中，GEGO 的解质量、分类准确率及收敛稳定性均优于原有的 GEO、GA 及多种经典元启发式算法。研究结果证明 GEGO 实现了探索 (Exploration) 与开发 (Exploitation) 之间的平衡，是受限计算资源下进行超参数优化的理想工具。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14672v1",
      "published_date": "2026-01-21 05:35:38 UTC",
      "updated_date": "2026-01-21 05:35:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:51:32.704657+00:00"
    },
    {
      "arxiv_id": "2601.14667v1",
      "title": "INFA-Guard: Mitigating Malicious Propagation via Infection-Aware Safeguarding in LLM-Based Multi-Agent Systems",
      "title_zh": "INFA-Guard：通过感染感知防护缓解基于大语言模型的多智能体系统中的恶意传播",
      "authors": [
        "Yijin Zhou",
        "Xiaoya Lu",
        "Dongrui Liu",
        "Junchi Yan",
        "Jing Shao"
      ],
      "abstract": "The rapid advancement of Large Language Model (LLM)-based Multi-Agent Systems (MAS) has introduced significant security vulnerabilities, where malicious influence can propagate virally through inter-agent communication. Conventional safeguards often rely on a binary paradigm that strictly distinguishes between benign and attack agents, failing to account for infected agents i.e., benign entities converted by attack agents. In this paper, we propose Infection-Aware Guard, INFA-Guard, a novel defense framework that explicitly identifies and addresses infected agents as a distinct threat category. By leveraging infection-aware detection and topological constraints, INFA-Guard accurately localizes attack sources and infected ranges. During remediation, INFA-Guard replaces attackers and rehabilitates infected ones, avoiding malicious propagation while preserving topological integrity. Extensive experiments demonstrate that INFA-Guard achieves state-of-the-art performance, reducing the Attack Success Rate (ASR) by an average of 33%, while exhibiting cross-model robustness, superior topological generalization, and high cost-effectiveness.",
      "tldr_zh": "该研究针对基于大语言模型(Large Language Model, LLM)的多智能体系统(Multi-Agent Systems, MAS)中恶意影响通过代理间通信病毒式传播的安全漏洞，指出传统二元防御范式忽略了被攻击者转化的“受感染代理(infected agents)”这一独特威胁。为此，作者提出了名为INFA-Guard的防御框架，通过感染感知检测(infection-aware detection)和拓扑约束(topological constraints)来精确识别攻击源及受感染范围。在修复过程中，该框架通过替换攻击者并修复受感染代理，在抑制恶意传播的同时有效保留了系统的拓扑完整性。实验结果表明，INFA-Guard能将平均攻击成功率(Attack Success Rate, ASR)降低33%，并展现出优异的跨模型稳健性、拓扑泛化能力及成本效益。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14667v1",
      "published_date": "2026-01-21 05:27:08 UTC",
      "updated_date": "2026-01-21 05:27:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:51:36.946448+00:00"
    },
    {
      "arxiv_id": "2601.14663v1",
      "title": "Calibrated uncertainty quantification for prosumer flexibility aggregation in ancillary service markets",
      "title_zh": "辅助服务市场中产消者灵活性聚合的校准不确定性量化",
      "authors": [
        "Yogesh Pipada Sunil Kumar",
        "S. Ali Pourmousavi",
        "Jon A. R. Liisberg",
        "Julian Lesmos-Vinasco"
      ],
      "abstract": "Reliable forecasting of prosumer flexibility is critical for demand response aggregators participating in frequency controlled ancillary services market, where strict reliability requirements such as the P90 standard are enforced. Limited historical data, dependence on exogeneous factors, and heterogenous prosumer behaviour introduce significant epistemic uncertainty, making deterministic or poorly calibrated probabilistic models unsuitable for market bidding. This paper proposes the use of scalable uncertainty quantification framework that integrates Monte Carlo dropout (MCD) with conformal prediction (CP) to produce calibrated, finite sample prediction intervals for aggregated prosumer flexibility. The proposed framework is applied to a behind-the-meter aggregator participating in the Danish manual frequency restoration reserve capacity market. A large-scale synthetic dataset is generated using a modified industry-grade home energy management system, combined with publicly available load, solar, price, activation and device-level data. The resulting machine learning surrogate model captures aggregate prosumer price responsiveness and provides uncertainty-aware estimates suitable for market bidding. Multiple multivariate CP strategies are evaluated and benchmarked against conventional MCD-based methods. Results show that standalone MCD systematically overestimates available flexibility and violates P90 compliance, whereas the proposed MCD-CP framework achieves reliable coverage with controlled conservatism. When embedded in aggregator bidding model, conformalised methods substantially reduce overbidding risk and achieve upto 70% of perfect-information profit while satisfying regulatory reliability constraints, providing practical, computationally efficient, and market-compliant solution for aggregator flexibility forecasting under uncertainty.",
      "tldr_zh": "该研究针对prosumer（产消者）在参与频率控制辅助服务市场时面临的灵活性预测难题，提出了一种可扩展的uncertainty quantification（不确定性量化）框架。为了满足P90等严格的可靠性标准，该框架创新性地将Monte Carlo dropout（MCD）与conformal prediction（CP）相结合，旨在为聚合灵活性生成校准后的有限样本预测区间。研究人员利用工业级家庭能源管理系统结合公开负荷、太阳能及价格数据，构建了能够捕捉聚合价格响应能力的机器学习代理模型。实验结果表明，传统的独立MCD方法会系统性地高估可用灵活性并违反合规要求，而MCD-CP框架在保持受控保守性的同时实现了可靠的覆盖率。当该框架应用于聚合商投标模型时，能显著降低overbidding（超额投标）风险，在满足监管可靠性约束的前提下获得高达70%的理想利润，为电力市场环境下的灵活性预测提供了高效且符合合规要求的解决方案。",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "primary_category": "eess.SY",
      "comment": "Single column 31 pages, 10 figures, 3 tables, submitted for review to Applied Energy",
      "pdf_url": "https://arxiv.org/pdf/2601.14663v1",
      "published_date": "2026-01-21 05:21:31 UTC",
      "updated_date": "2026-01-21 05:21:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:51:43.516103+00:00"
    },
    {
      "arxiv_id": "2601.14662v1",
      "title": "Query-Efficient Agentic Graph Extraction Attacks on GraphRAG Systems",
      "title_zh": "针对 GraphRAG 系统的查询高效智能体图提取攻击",
      "authors": [
        "Shuhua Yang",
        "Jiahao Zhang",
        "Yilong Wang",
        "Dongwon Lee",
        "Suhang Wang"
      ],
      "abstract": "Graph-based retrieval-augmented generation (GraphRAG) systems construct knowledge graphs over document collections to support multi-hop reasoning. While prior work shows that GraphRAG responses may leak retrieved subgraphs, the feasibility of query-efficient reconstruction of the hidden graph structure remains unexplored under realistic query budgets. We study a budget-constrained black-box setting where an adversary adaptively queries the system to steal its latent entity-relation graph. We propose AGEA (Agentic Graph Extraction Attack), a framework that leverages a novelty-guided exploration-exploitation strategy, external graph memory modules, and a two-stage graph extraction pipeline combining lightweight discovery with LLM-based filtering. We evaluate AGEA on medical, agriculture, and literary datasets across Microsoft-GraphRAG and LightRAG systems. Under identical query budgets, AGEA significantly outperforms prior attack baselines, recovering up to 90% of entities and relationships while maintaining high precision. These results demonstrate that modern GraphRAG systems are highly vulnerable to structured, agentic extraction attacks, even under strict query limits.",
      "tldr_zh": "该研究探讨了基于图的检索增强生成(GraphRAG)系统在查询预算受限的黑盒设置下的安全漏洞，提出了名为AGEA (Agentic Graph Extraction Attack)的攻击框架，旨在高效窃取系统的潜在实体关系图。该框架利用新颖性引导的探索-利用策略和外部图内存模块，通过结合轻量级发现与大语言模型(LLM)过滤的二阶段流水线，实现了对图结构的精准提取。在医疗、农业和文学等数据集上针对 Microsoft-GraphRAG 和 LightRAG 系统的实验结果表明，AGEA 在维持高精度的同时，能恢复高达 90% 的实体和关系，其表现显著优于先前的攻击基线。这一发现证实了现代 GraphRAG 系统即使在严格的查询限制下，也极易受到结构化代理攻击的威胁，揭示了此类系统在知识产权保护和数据隐私方面的重大安全风险。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14662v1",
      "published_date": "2026-01-21 05:20:54 UTC",
      "updated_date": "2026-01-21 05:20:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:51:33.865880+00:00"
    },
    {
      "arxiv_id": "2601.14660v1",
      "title": "NeuroFilter: Privacy Guardrails for Conversational LLM Agents",
      "title_zh": "NeuroFilter：面向对话式 LLM 智能体的隐私护栏",
      "authors": [
        "Saswat Das",
        "Ferdinando Fioretto"
      ],
      "abstract": "This work addresses the computational challenge of enforcing privacy for agentic Large Language Models (LLMs), where privacy is governed by the contextual integrity framework. Indeed, existing defenses rely on LLM-mediated checking stages that add substantial latency and cost, and that can be undermined in multi-turn interactions through manipulation or benign-looking conversational scaffolding. Contrasting this background, this paper makes a key observation: internal representations associated with privacy-violating intent can be separated from benign requests using linear structure. Using this insight, the paper proposes NeuroFilter, a guardrail framework that operationalizes contextual integrity by mapping norm violations to simple directions in the model's activation space, enabling detection even when semantic filters are bypassed. The proposed filter is also extended to capture threats arising during long conversations using the concept of activation velocity, which measures cumulative drift in internal representations across turns. A comprehensive evaluation across over 150,000 interactions and covering models from 7B to 70B parameters, illustrates the strong performance of NeuroFilter in detecting privacy attacks while maintaining zero false positives on benign prompts, all while reducing the computational inference cost by several orders of magnitude when compared to LLM-based agentic privacy defenses.",
      "tldr_zh": "该研究针对代理大语言模型（LLM Agents）在执行隐私保护时面临的高计算成本、高延迟以及易受多轮对话操控而失效等挑战，提出了 NeuroFilter 护栏框架。研究者通过观察发现，与隐私违规意图相关的内部表示可以通过线性结构与良性请求分离，从而将规范违规映射到模型激活空间（activation space）中的简单方向，即使语义过滤器被绕过也能实现有效检测。为了应对长对话中的潜在威胁，框架引入了激活速度（activation velocity）概念，通过测量多轮交互中内部表示的累积漂移来捕捉隐私风险。在涵盖 7B 到 70B 参数模型的 15 万次交互评估中，NeuroFilter 在保持良性提示词零误报的同时，展现了卓越的隐私攻击检测能力。与传统的基于 LLM 的防御方案相比，该方法在显著提升安全性的同时，将推理计算成本降低了数个数量级，为实现低延迟且可靠的上下文完整性（contextual integrity）保护提供了高效的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14660v1",
      "published_date": "2026-01-21 05:16:50 UTC",
      "updated_date": "2026-01-21 05:16:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:51:56.031708+00:00"
    },
    {
      "arxiv_id": "2601.14658v1",
      "title": "Say Anything but This: When Tokenizer Betrays Reasoning in LLMs",
      "title_zh": "言之非此：分词器如何干扰大语言模型的推理",
      "authors": [
        "Navid Ayoobi",
        "Marcus I Armstrong",
        "Arjun Mukherjee"
      ],
      "abstract": "Large language models (LLMs) reason over discrete token ID sequences, yet modern subword tokenizers routinely produce non-unique encodings: multiple token ID sequences can detokenize to identical surface strings. This representational mismatch creates an unmeasured fragility wherein reasoning processes can fail. LLMs may treat two internal representations as distinct \"words\" even when they are semantically identical at the text level. In this work, we show that tokenization can betray LLM reasoning through one-to-many token ID mappings. We introduce a tokenization-consistency probe that requires models to replace designated target words in context while leaving all other content unchanged. The task is intentionally simple at the surface level, enabling us to attribute failures to tokenizer-detokenizer artifacts rather than to knowledge gaps or parameter limitations. Through analysis of over 11000 replacement trials across state-of-the-art open-source LLMs, we find a non-trivial rate of outputs exhibit phantom edits: cases where models operate under the illusion of correct reasoning, a phenomenon arising from tokenizer-induced representational defects. We further analyze these cases and provide a taxonomy of eight systematic tokenizer artifacts, including whitespace-boundary shifts and intra-word resegmentation. These findings indicate that part of apparent reasoning deficiency originates in the tokenizer layer, motivating tokenizer-level remedies before incurring the cost of training ever-larger models on ever-larger corpora.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在推理过程中面临的由分词器(Tokenizer)引发的表征错位问题，指出子词分词器产生的非唯一编码会导致模型将语义相同的字符串视为不同的内部表示。作者提出了一种分词一致性探针(Tokenization-consistency probe)，通过要求模型在特定上下文中替换目标词，成功将推理失败归因于分词器的编解码缺陷而非模型知识匮乏。通过对多种SOTA开源LLMs进行超过11,000次实验，研究发现模型经常在分词器缺陷的影响下产生“幻觉编辑”(Phantom edits)，即模型在错误推理的幻觉下运行。该论文进一步归纳了八类系统性的分词伪影(Tokenizer artifacts)，包括空格边界偏移(Whitespace-boundary shifts)和词内重切分(Intra-word resegmentation)。研究结果表明，部分显性的推理缺陷实际上源于分词层，因此在投入高昂成本训练更大规模模型之前，应优先考虑分词层面的修复方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14658v1",
      "published_date": "2026-01-21 05:09:09 UTC",
      "updated_date": "2026-01-21 05:09:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:52:28.706176+00:00"
    },
    {
      "arxiv_id": "2601.14652v1",
      "title": "MAS-Orchestra: Understanding and Improving Multi-Agent Reasoning Through Holistic Orchestration and Controlled Benchmarks",
      "title_zh": "MAS-Orchestra：通过全局编排与受控基准深入理解并提升多智能体推理能力",
      "authors": [
        "Zixuan Ke",
        "Yifei Ming",
        "Austin Xu",
        "Ryan Chin",
        "Xuan-Phi Nguyen",
        "Prathyusha Jwalapuram",
        "Semih Yavuz",
        "Caiming Xiong",
        "Shafiq Joty"
      ],
      "abstract": "While multi-agent systems (MAS) promise elevated intelligence through coordination of agents, current approaches to automatic MAS design under-deliver. Such shortcomings stem from two key factors: (1) methodological complexity - agent orchestration is performed using sequential, code-level execution that limits global system-level holistic reasoning and scales poorly with agent complexity - and (2) efficacy uncertainty - MAS are deployed without understanding if there are tangible benefits compared to single-agent systems (SAS). We propose MAS-Orchestra, a training-time framework that formulates MAS orchestration as a function-calling reinforcement learning problem with holistic orchestration, generating an entire MAS at once. In MAS-Orchestra, complex, goal-oriented sub-agents are abstracted as callable functions, enabling global reasoning over system structure while hiding internal execution details. To rigorously study when and why MAS are beneficial, we introduce MASBENCH, a controlled benchmark that characterizes tasks along five axes: Depth, Horizon, Breadth, Parallel, and Robustness. Our analysis reveals that MAS gains depend critically on task structure, verification protocols, and the capabilities of both orchestrator and sub-agents, rather than holding universally. Guided by these insights, MAS-Orchestra achieves consistent improvements on public benchmarks including mathematical reasoning, multi-hop QA, and search-based QA. Together, MAS-Orchestra and MASBENCH enable better training and understanding of MAS in the pursuit of multi-agent intelligence.",
      "tldr_zh": "该研究提出了 MAS-Orchestra，这是一个旨在改进多智能体系统 (Multi-Agent Systems, MAS) 编排与理解的训练时框架。为了解决现有自动 MAS 设计在方法复杂度和有效性不确定性上的局限，MAS-Orchestra 将智能体编排建模为全局统筹的函数调用强化学习 (Reinforcement Learning) 问题，实现了对系统结构的整体推理。研究团队同步引入了受控基准 MASBENCH，通过五个核心维度对任务进行刻画，用以精准评估 MAS 相对于单智能体系统的收益。分析揭示了 MAS 的增益并非普遍存在，而是高度依赖于任务结构、验证协议及各级智能体的能力。实验结果显示，MAS-Orchestra 在数学推理、多跳问答 (Multi-hop QA) 和搜索式问答等公开基准上均取得了显著且持续的性能提升。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint; Work in Progress",
      "pdf_url": "https://arxiv.org/pdf/2601.14652v1",
      "published_date": "2026-01-21 04:57:02 UTC",
      "updated_date": "2026-01-21 04:57:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:52:31.441344+00:00"
    },
    {
      "arxiv_id": "2601.15351v1",
      "title": "OmniSpectra: A Unified Foundation Model for Native Resolution Astronomical Spectra",
      "title_zh": "OmniSpectra：面向原生分辨率天文光谱的统一基础模型",
      "authors": [
        "Md Khairul Islam",
        "Judy Fox"
      ],
      "abstract": "We present OmniSpectra, the first native-resolution foundation model for astronomy spectra. Unlike traditional models, which are limited to fixed-length input sizes or configurations, OmniSpectra handles spectra of any length at their original size, without resampling or interpolation. Despite the large-scale spectroscopic data from diverse surveys fueling the rapid growth of astronomy, existing foundation models are limited to a fixed wavelength range and specific instruments. OmniSpectra is the first foundation model to learn simultaneously from multiple real-world spectra surveys with different configurations at a large scale. We achieve this by designing a novel architecture with adaptive patching across variable lengths, sinusoidal global wavelength encoding, local positional embeddings through depthwise convolution, and validity-aware self-attention masks. Allowing us to learn multi-scale spatial patterns while skipping attention for invalid patches. Even with a limited training example, OmniSpectra demonstrates excellent zero-shot generalization compared to methods tailored for specific tasks. This transfer learning capability makes this model the state-of-the-art across various astronomy tasks, including source classification, redshift estimation, and properties prediction for stars and galaxies. OmniSpectra reduces the need for training individual models for different tasks from scratch, establishing itself as the next-generation astronomy foundation model.",
      "tldr_zh": "该研究推出了OmniSpectra，这是首个针对天文光谱的原始分辨率(native-resolution)基础模型。与传统模型受限于固定长度输入或特定仪器不同，OmniSpectra能够处理任意长度的光谱，且无需进行重采样(resampling)或插值(interpolation)。该模型通过自适应分块(adaptive patching)、正弦全局波长编码(sinusoidal global wavelength encoding)以及感知有效性的自注意力掩码(validity-aware self-attention masks)等创新架构设计，实现了对多个大规模实测巡天数据的同步学习。即使在训练样本有限的情况下，OmniSpectra也展现出了卓越的零样本(zero-shot)泛化能力。实验证明，该模型在源分类(source classification)、红移估计(redshift estimation)以及恒星与星系属性预测等多项天文任务中均达到了最先进水平。OmniSpectra显著降低了为不同任务单独从头训练模型的需求，确立了其作为下一代天文基础模型的地位。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15351v1",
      "published_date": "2026-01-21 04:39:32 UTC",
      "updated_date": "2026-01-21 04:39:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:51:55.347167+00:00"
    },
    {
      "arxiv_id": "2601.14637v1",
      "title": "Forest-Chat: Adapting Vision-Language Agents for Interactive Forest Change Analysis",
      "title_zh": "Forest-Chat：面向交互式森林变化分析的视觉语言智能体适配",
      "authors": [
        "James Brock",
        "Ce Zhang",
        "Nantheera Anantrasirichai"
      ],
      "abstract": "The increasing availability of high-resolution satellite imagery, together with advances in deep learning, creates new opportunities for enhancing forest monitoring workflows. Two central challenges in this domain are pixel-level change detection and semantic change interpretation, particularly for complex forest dynamics. While large language models (LLMs) are increasingly adopted for data exploration, their integration with vision-language models (VLMs) for remote sensing image change interpretation (RSICI) remains underexplored, especially beyond urban environments. We introduce Forest-Chat, an LLM-driven agent designed for integrated forest change analysis. The proposed framework enables natural language querying and supports multiple RSICI tasks, including change detection, change captioning, object counting, deforestation percentage estimation, and change reasoning. Forest-Chat builds upon a multi-level change interpretation (MCI) vision-language backbone with LLM-based orchestration, and incorporates zero-shot change detection via a foundation change detection model together with an interactive point-prompt interface to support fine-grained user guidance. To facilitate adaptation and evaluation in forest environments, we introduce the Forest-Change dataset, comprising bi-temporal satellite imagery, pixel-level change masks, and multi-granularity semantic change captions generated through a combination of human annotation and rule-based methods. Experimental results demonstrate that Forest-Chat achieves strong performance on Forest-Change and on LEVIR-MCI-Trees, a tree-focused subset of LEVIR-MCI, for joint change detection and captioning, highlighting the potential of interactive, LLM-driven RSICI systems to improve accessibility, interpretability, and analytical efficiency in forest change analysis.",
      "tldr_zh": "该研究提出了 Forest-Chat，一种由大语言模型（LLM）驱动的智能体，旨在通过交互方式实现复杂的森林变化分析。该框架基于多级变化解释（MCI）视觉语言骨干网络并结合 LLM 编排，支持自然语言查询以及变化检测（change detection）、变化描述（change captioning）和毁林比例估计等多种远程探测图像变化解释（RSICI）任务。Forest-Chat 集成了基础变化检测模型的零样本（zero-shot）能力和交互式点提示（point-prompt）界面，能够响应用户的细粒度引导。此外，研究者还发布了包含双时相卫星图像和多粒度语义描述的 Forest-Change 数据集。实验结果证明 Forest-Chat 在相关基准测试中展现出卓越性能，有效提升了森林动态监测的可解释性与分析效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 8 figures, 7 tables, Submitted to Ecological Informatics",
      "pdf_url": "https://arxiv.org/pdf/2601.14637v1",
      "published_date": "2026-01-21 04:23:33 UTC",
      "updated_date": "2026-01-21 04:23:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:52:10.519839+00:00"
    },
    {
      "arxiv_id": "2601.14628v1",
      "title": "A Brain-inspired Embodied Intelligence for Fluid and Fast Reflexive Robotics Control",
      "title_zh": "面向流畅快速反射式机器人控制的类脑具身智能",
      "authors": [
        "Weiyu Guo",
        "He Zhang",
        "Pengteng Li",
        "Tiefu Cai",
        "Ziyang Chen",
        "Yandong Guo",
        "Xiao He",
        "Yongkui Yang",
        "Ying Sun",
        "Hui Xiong"
      ],
      "abstract": "Recent advances in embodied intelligence have leveraged massive scaling of data and model parameters to master natural-language command following and multi-task control. In contrast, biological systems demonstrate an innate ability to acquire skills rapidly from sparse experience. Crucially, current robotic policies struggle to replicate the dynamic stability, reflexive responsiveness, and temporal memory inherent in biological motion. Here we present Neuromorphic Vision-Language-Action (NeuroVLA), a framework that mimics the structural organization of the bio-nervous system between the cortex, cerebellum, and spinal cord. We adopt a system-level bio-inspired design: a high-level model plans goals, an adaptive cerebellum module stabilizes motion using high-frequency sensors feedback, and a bio-inspired spinal layer executes lightning-fast actions generation. NeuroVLA represents the first deployment of a neuromorphic VLA on physical robotics, achieving state-of-the-art performance. We observe the emergence of biological motor characteristics without additional data or special guidance: it stops the shaking in robotic arms, saves significant energy(only 0.4w on Neuromorphic Processor), shows temporal memory ability and triggers safety reflexes in less than 20 milliseconds.",
      "tldr_zh": "该研究提出了Neuromorphic Vision-Language-Action (NeuroVLA)框架，通过模拟生物神经系统中皮层、小脑和脊髓的层次化组织，解决了当前机器人策略在动态稳定性、反射响应和时间记忆方面的不足。NeuroVLA采用系统级仿生设计，利用高级模型规划目标，并结合自适应小脑模块与高频传感器反馈来稳定运动。其独特的仿生脊髓层能够实现极速的动作生成，使系统具备极强的实时响应能力。作为首个在物理机器人上成功部署的类脑VLA模型，NeuroVLA在多个指标上达到了state-of-the-art水平。在无需额外训练数据的情况下，该框架展现了显著的生物运动特性，不仅有效消除了机械臂抖动，在Neuromorphic Processor上的功耗仅为0.4w。此外，该系统还表现出优秀的时间记忆能力，并能在20毫秒内迅速触发安全反射。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14628v1",
      "published_date": "2026-01-21 04:04:44 UTC",
      "updated_date": "2026-01-21 04:04:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:52:58.066362+00:00"
    },
    {
      "arxiv_id": "2601.14620v1",
      "title": "Scaling Ambiguity: Augmenting Human Annotation in Speech Emotion Recognition with Audio-Language Models",
      "title_zh": "扩展模糊性：利用音频语言模型增强语音情感识别中的人工标注",
      "authors": [
        "Wenda Zhang",
        "Hongyu Jin",
        "Siyi Wang",
        "Zhiqiang Wei",
        "Ting Dang"
      ],
      "abstract": "Speech Emotion Recognition models typically use single categorical labels, overlooking the inherent ambiguity of human emotions. Ambiguous Emotion Recognition addresses this by representing emotions as probability distributions, but progress is limited by unreliable ground-truth distributions inferred from sparse human annotations. This paper explores whether Large Audio-Language Models (ALMs) can mitigate the annotation bottleneck by generating high-quality synthetic annotations. We introduce a framework leveraging ALMs to create Synthetic Perceptual Proxies, augmenting human annotations to improve ground-truth distribution reliability. We validate these proxies through statistical analysis of their alignment with human distributions and evaluate their impact by fine-tuning ALMs with the augmented emotion distributions. Furthermore, to address class imbalance and enable unbiased evaluation, we propose DiME-Aug, a Distribution-aware Multimodal Emotion Augmentation strategy. Experiments on IEMOCAP and MSP-Podcast show that synthetic annotations enhance emotion distribution, especially in low-ambiguity regions where annotation agreement is high. However, benefits diminish for highly ambiguous emotions with greater human disagreement. This work provides the first evidence that ALMs could address annotation scarcity in ambiguous emotion recognition, but highlights the need for more advanced prompting or generation strategies to handle highly ambiguous cases.",
      "tldr_zh": "该研究针对语音情感识别(Speech Emotion Recognition)中人工标注稀缺且难以捕捉情感歧义性的问题，探讨了利用大语言音频模型(Large Audio-Language Models, ALMs)生成高质量合成标注的可行性。作者提出了一个利用 ALMs 构建合成感知代理(Synthetic Perceptual Proxies)的框架，旨在通过增强人工标注来提高情感概率分布的可靠性。为应对类别不平衡并确保评估的公正性，研究进一步引入了分布感知多模态情感增强策略(Distribution-aware Multimodal Emotion Augmentation, DiME-Aug)。在 IEMOCAP 和 MSP-Podcast 数据集上的实验证明，合成标注在人工一致性较高的低歧义区域能显著提升情感分布质量。尽管该方法在处理极高歧义的情感案例时仍有局限，但其研究结果首次为利用 ALMs 解决歧义情感识别中的标注瓶颈提供了有力证据。该工作不仅展示了 ALMs 在情感建模领域的潜力，也指出了未来在复杂歧义场景下优化生成策略的方向。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted by ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.14620v1",
      "published_date": "2026-01-21 03:32:24 UTC",
      "updated_date": "2026-01-21 03:32:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:54:00.228050+00:00"
    },
    {
      "arxiv_id": "2601.14615v1",
      "title": "SearchGym: Bootstrapping Real-World Search Agents via Cost-Effective and High-Fidelity Environment Simulation",
      "title_zh": "SearchGym：通过经济高效的高保真环境模拟构建现实世界搜索智能体",
      "authors": [
        "Xichen Zhang",
        "Ziyi He",
        "Yinghao Zhu",
        "Sitong Wu",
        "Shaozuo Yu",
        "Meng Chu",
        "Wenhu Zhang",
        "Haoru Tan",
        "Jiaya Jia"
      ],
      "abstract": "Search agents have emerged as a pivotal paradigm for solving open-ended, knowledge-intensive reasoning tasks. However, training these agents via Reinforcement Learning (RL) faces a critical dilemma: interacting with live commercial Web APIs is prohibitively expensive, while relying on static data snapshots often introduces noise due to data misalignment. This misalignment generates corrupted reward signals that destabilize training by penalizing correct reasoning or rewarding hallucination. To address this, we propose SearchGym, a simulation environment designed to bootstrap robust search agents. SearchGym employs a rigorous generative pipeline to construct a verifiable knowledge graph and an aligned document corpus, ensuring that every reasoning task is factually grounded and strictly solvable. Building on this controllable environment, we introduce SearchGym-RL, a curriculum learning methodology that progressively optimizes agent policies through purified feedback, evolving from basic interactions to complex, long-horizon planning. Extensive experiments across the Llama and Qwen families demonstrate strong Sim-to-Real generalization. Notably, our Qwen2.5-7B-Base model trained within SearchGym surpasses the web-enhanced ASearcher baseline across nine diverse benchmarks by an average relative margin of 10.6%. Our results validate that high-fidelity simulation serves as a scalable and highly cost-effective methodology for developing capable search agents.",
      "tldr_zh": "该研究针对搜索智能体在强化学习(Reinforcement Learning)训练中面临的商业Web API成本高昂及静态快照数据对齐失真问题，提出了SearchGym模拟环境。SearchGym通过严谨的生成流程构建可验证的知识图谱(Knowledge Graph)和对齐的文档语料库，确保推理任务具备事实依据且严格可解。基于此可控环境，研究进一步引入了SearchGym-RL课程学习方法，通过纯净反馈引导智能体策略从基础交互演进至复杂的长程规划。实验结果表明，在模拟环境中训练的模型展现出卓越的模拟到现实(Sim-to-Real)泛化能力，其中Qwen2.5-7B-Base在九项基准测试中的平均表现优于ASearcher基准10.6%。该成果证实了高保真模拟是开发具备高性能、可扩展且极具成本效益的搜索智能体的高效路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14615v1",
      "published_date": "2026-01-21 03:16:17 UTC",
      "updated_date": "2026-01-21 03:16:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:52:59.410244+00:00"
    },
    {
      "arxiv_id": "2601.14609v1",
      "title": "Communication-Efficient Federated Risk Difference Estimation for Time-to-Event Clinical Outcomes",
      "title_zh": "面向临床生存结局的高效通信联邦风险差异估计",
      "authors": [
        "Ziwen Wang",
        "Siqi Li",
        "Marcus Eng Hock Ong",
        "Nan Liu"
      ],
      "abstract": "Privacy-preserving model co-training in medical research is often hindered by server-dependent architectures incompatible with protected hospital data systems and by the predominant focus on relative effect measures (hazard ratios) which lack clinical interpretability for absolute survival risk assessment. We propose FedRD, a communication-efficient framework for federated risk difference estimation in distributed survival data. Unlike typical federated learning frameworks (e.g., FedAvg) that require persistent server connections and extensive iterative communication, FedRD is server-independent with minimal communication: one round of summary statistics exchange for the stratified model and three rounds for the unstratified model. Crucially, FedRD provides valid confidence intervals and hypothesis testing--capabilities absent in FedAvg-based frameworks. We provide theoretical guarantees by establishing the asymptotic properties of FedRD and prove that FedRD (unstratified) is asymptotically equivalent to pooled individual-level analysis. Simulation studies and real-world clinical applications across different countries demonstrate that FedRD outperforms local and federated baselines in both estimation accuracy and prediction performance, providing an architecturally feasible solution for absolute risk assessment in privacy-restricted, multi-site clinical studies.",
      "tldr_zh": "该研究针对医疗研究中隐私保护模型协同训练面临的服务器依赖性架构以及相对效应指标（如 Hazard Ratios）缺乏临床解释力的问题，提出了 FedRD。这是一种面向分布式生存数据的通信高效型联合风险差异（Federated Risk Difference）估计框架。FedRD 采用服务器独立架构，仅需一到三轮摘要统计量交换即可完成，显著降低了通信需求。关键在于该框架能提供有效的置信区间（Confidence Intervals）和假设检验（Hypothesis Testing），弥补了传统 FedAvg 框架的不足。理论证明 FedRD 在渐近性质（Asymptotic Properties）上等同于汇总后的个体级数据分析。实验和跨国临床应用结果显示，FedRD 在估计准确度和预测性能上均优于局部模型和现有联邦学习基准。该成果为隐私受限环境下的多中心临床研究提供了一种兼顾架构可行性与绝对风险评估能力的解决方案。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14609v1",
      "published_date": "2026-01-21 02:59:30 UTC",
      "updated_date": "2026-01-21 02:59:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:53:08.904031+00:00"
    },
    {
      "arxiv_id": "2601.15348v1",
      "title": "Abusive music and song transformation using GenAI and LLMs",
      "title_zh": "利用生成式人工智能与大语言模型进行辱骂性音乐及歌曲的转换",
      "authors": [
        "Jiyang Choi",
        "Rohitash Chandra"
      ],
      "abstract": "Repeated exposure to violence and abusive content in music and song content can influence listeners' emotions and behaviours, potentially normalising aggression or reinforcing harmful stereotypes. In this study, we explore the use of generative artificial intelligence (GenAI) and Large Language Models (LLMs) to automatically transform abusive words (vocal delivery) and lyrical content in popular music. Rather than simply muting or replacing a single word, our approach transforms the tone, intensity, and sentiment, thus not altering just the lyrics, but how it is expressed. We present a comparative analysis of four selected English songs and their transformed counterparts, evaluating changes through both acoustic and sentiment-based lenses. Our findings indicate that Gen-AI significantly reduces vocal aggressiveness, with acoustic analysis showing improvements in Harmonic to Noise Ratio, Cepstral Peak Prominence, and Shimmer. Sentiment analysis reduced aggression by 63.3-85.6\\% across artists, with major improvements in chorus sections (up to 88.6\\% reduction). The transformed versions maintained musical coherence while mitigating harmful content, offering a promising alternative to traditional content moderation that avoids triggering the \"forbidden fruit\" effect, where the censored content becomes more appealing simply because it is restricted. This approach demonstrates the potential for GenAI to create safer listening experiences while preserving artistic expression.",
      "tldr_zh": "该研究探讨了利用生成式人工智能(GenAI)和大型语言模型(LLMs)来自动转化流行音乐中的辱骂性词汇和歌词内容。不同于简单的静音或词汇替换，该方法通过改变音调、强度和情感，实现了对歌词及其表达方式的深度转化。研究人员对四首英文歌曲进行了对比分析，声学分析结果显示GenAI能显著改善谐波噪声比(Harmonic to Noise Ratio)、倒谱峰值突出度(Cepstral Peak Prominence)和频率微扰(Shimmer)，从而降低语音攻击性。情感分析表明，该方法使艺术家的攻击性降低了63.3%至85.6%，其中副歌部分的改善尤为显著。该转化方案在减少有害内容的同时保留了音乐的连贯性，有效避免了传统审查制度可能带来的禁果效应(forbidden fruit effect)。这一研究展示了GenAI在保护艺术表达的同时，为创造更安全的收听环境所具备的巨大潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.15348v1",
      "published_date": "2026-01-21 02:56:45 UTC",
      "updated_date": "2026-01-21 02:56:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:53:26.074674+00:00"
    },
    {
      "arxiv_id": "2601.14599v1",
      "title": "Rethinking Reinforcement fine-tuning of LLMs: A Multi-armed Bandit Learning Perspective",
      "title_zh": "重新审视大语言模型的强化微调：多臂老虎机学习视角",
      "authors": [
        "Xiao Hu",
        "Hong Xie",
        "Tao Tan",
        "Defu Lian",
        "Jianyu Han"
      ],
      "abstract": "A large number of heuristics have been proposed to optimize the reinforcement fine-tuning of LLMs. However, inconsistent claims are made from time to time, making this area elusive. Reflecting on this situation, two fundamental questions still lack a clear understanding: 1) what is the role of each optimizing choice? 2) which ones are the bottlenecks? This paper aims to shed light on them, and it faces the challenge of several entangled confounding factors in the fine-tuning process. To tackle this challenge, we propose a bottom-up experiment pipeline. The bottom layer is composed of a minimalist configuration: one training data, one rollout per round and the reward directly serve as the learning signal without advantage function design. This minimalist configuration connects to multi-armed bandit learning with extremely large discrete action space, which offers theories to corroborate the experiment findings. The up procedure of the experiment pipeline expanding the minimalist configuration layer by layer, examining the role of each design choice. Experimental results on three LLMs and two reasoning datasets not only reveal new understanding of the design choice but also yield essential insights to shape the area.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 在强化学习微调 (reinforcement fine-tuning) 过程中启发式方法众多且结论不一的现状，旨在厘清各项优化选择的具体作用及其性能瓶颈。为解决微调过程中多种混杂因素交织的挑战，作者提出了一套自下而上的实验流水线 (bottom-up experiment pipeline)，从单一训练数据、单次采样 (rollout) 且直接以奖励作为学习信号的极简配置出发进行研究。这种极简配置将 LLM 微调与拥有极大规模离散动作空间的多臂老虎机学习 (multi-armed bandit learning) 联系起来，从而利用相关理论佐证实验发现。通过逐层扩展实验配置，研究者系统地考察了每一项设计选择的功能。在三种 LLMs 和两个推理数据集上的实验结果不仅揭示了对设计选择的新理解，还为强化学习微调领域的发展提供了关键洞察。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14599v1",
      "published_date": "2026-01-21 02:37:44 UTC",
      "updated_date": "2026-01-21 02:37:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:53:21.573554+00:00"
    },
    {
      "arxiv_id": "2601.14598v1",
      "title": "HELIOS: Hierarchical Graph Abstraction for Structure-Aware LLM Decompilation",
      "title_zh": "HELIOS：面向结构感知大语言模型反编译的层级化图抽象",
      "authors": [
        "Yonatan Gizachew Achamyeleh",
        "Harsh Thomare",
        "Mohammad Abdullah Al Faruque"
      ],
      "abstract": "Large language models (LLMs) have recently been applied to binary decompilation, yet they still treat code as plain text and ignore the graphs that govern program control flow. This limitation often yields syntactically fragile and logically inconsistent output, especially for optimized binaries. This paper presents \\textsc{HELIOS}, a framework that reframes LLM-based decompilation as a structured reasoning task. \\textsc{HELIOS} summarizes a binary's control flow and function calls into a hierarchical text representation that spells out basic blocks, their successors, and high-level patterns such as loops and conditionals. This representation is supplied to a general-purpose LLM, along with raw decompiler output, optionally combined with a compiler-in-the-loop that returns error messages when the generated code fails to build.\n  On HumanEval-Decompile for \\texttt{x86\\_64}, \\textsc{HELIOS} raises average object file compilability from 45.0\\% to 85.2\\% for Gemini~2.0 and from 71.4\\% to 89.6\\% for GPT-4.1~Mini. With compiler feedback, compilability exceeds 94\\% and functional correctness improves by up to 5.6 percentage points over text-only prompting. Across six architectures drawn from x86, ARM, and MIPS, \\textsc{HELIOS} reduces the spread in functional correctness while keeping syntactic correctness consistently high, all without fine-tuning. These properties make \\textsc{HELIOS} a practical building block for reverse engineering workflows in security settings where analysts need recompilable, semantically faithful code across diverse hardware targets.",
      "tldr_zh": "该研究提出了HELIOS，一个将基于大语言模型(LLMs)的反编译重新定义为结构化推理任务的框架，旨在解决现有模型忽视程序控制流图(Graphs)而导致的输出逻辑不一致和语法脆弱问题。HELIOS通过将二进制代码的控制流和函数调用总结为一种层次化的文本表示，清晰地描述了基本块(Basic Blocks)、后继节点以及循环(Loops)和条件语句(Conditionals)等高层模式。该表示连同原始反编译器的输出共同提供给通用LLM，并可选地结合编译器在环(Compiler-in-the-Loop)机制，利用错误反馈辅助代码生成。在HumanEval-Decompile基准测试中，HELIOS将Gemini 2.0的可编译率从45.0%大幅提升至85.2%，将GPT-4.1 Mini从71.4%提升至89.6%。实验结果表明，引入编译器反馈后可编译率超过94%，且功能正确性较纯文本提示提升了多达5.6个百分点。该框架在x86、ARM和MIPS等六种架构下均展现出极高的语法正确性，且无需微调(Fine-Tuning)即可在多样化的硬件目标上生成语义忠实的、可重新编译的代码。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14598v1",
      "published_date": "2026-01-21 02:37:33 UTC",
      "updated_date": "2026-01-21 02:37:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:53:41.414103+00:00"
    },
    {
      "arxiv_id": "2601.14597v1",
      "title": "Optimality of Staircase Mechanisms for Vector Queries under Differential Privacy",
      "title_zh": "差分隐私框架下向量查询阶梯机制的最优性",
      "authors": [
        "James Melbourne",
        "Mario Diaz",
        "Shahab Asoodeh"
      ],
      "abstract": "We study the optimal design of additive mechanisms for vector-valued queries under $ε$-differential privacy (DP). Given only the sensitivity of a query and a norm-monotone cost function measuring utility loss, we ask which noise distribution minimizes expected cost among all additive $ε$-DP mechanisms. Using convex rearrangement theory, we show that this infinite-dimensional optimization problem admits a reduction to a one-dimensional compact and convex family of radially symmetric distributions whose extreme points are the staircase distributions. As a consequence, we prove that for any dimension, any norm, and any norm-monotone cost function, there exists an $ε$-DP staircase mechanism that is optimal among all additive mechanisms. This result resolves a conjecture of Geng, Kairouz, Oh, and Viswanath, and provides a geometric explanation for the emergence of staircase mechanisms as extremal solutions in differential privacy.",
      "tldr_zh": "该研究探讨了在 $\\epsilon$-Differential Privacy (DP) 框架下针对向量值查询 (vector-valued queries) 的最优加性机制设计。在已知查询敏感度和衡量效用损失的 norm-monotone cost function 的前提下，研究者寻求在所有加性 $\\epsilon$-DP 机制中能够最小化期望成本的噪声分布。通过引入 convex rearrangement theory，该研究将一个无限维优化问题简化为径向对称分布的单维紧凑凸族，并确定其极值点为 staircase distributions。研究最终证明，对于任何维度、范数以及 norm-monotone cost function，在所有加性机制中都存在一个最优的 $\\epsilon$-DP staircase mechanism。这一结果成功解决了由 Geng, Kairouz, Oh 和 Viswanath 提出的学术猜想，并从几何层面解释了 staircase mechanisms 作为差分隐私极值解的内在逻辑。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.CR",
        "stat.ML"
      ],
      "primary_category": "cs.IT",
      "comment": "Submitted for possible publication",
      "pdf_url": "https://arxiv.org/pdf/2601.14597v1",
      "published_date": "2026-01-21 02:35:33 UTC",
      "updated_date": "2026-01-21 02:35:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:53:41.285413+00:00"
    },
    {
      "arxiv_id": "2601.14595v1",
      "title": "IntelliSA: An Intelligent Static Analyzer for IaC Security Smell Detection Using Symbolic Rules and Neural Inference",
      "title_zh": "IntelliSA：一种基于符号规则与神经推理的 IaC 安全异味检测智能静态分析器",
      "authors": [
        "Qiyue Mei",
        "Michael Fu"
      ],
      "abstract": "Infrastructure as Code (IaC) enables automated provisioning of large-scale cloud and on-premise environments, reducing the need for repetitive manual setup. However, this automation is a double-edged sword: a single misconfiguration in IaC scripts can propagate widely, leading to severe system downtime and security risks. Prior studies have shown that IaC scripts often contain security smells--bad coding patterns that may introduce vulnerabilities--and have proposed static analyzers based on symbolic rules to detect them. Yet, our preliminary analysis reveals that rule-based detection alone tends to over-approximate, producing excessive false positives and increasing the burden of manual inspection. In this paper, we present IntelliSA, an intelligent static analyzer for IaC security smell detection that integrates symbolic rules with neural inference. IntelliSA applies symbolic rules to over-approximate potential smells for broad coverage, then employs neural inference to filter false positives. While an LLM can effectively perform this filtering, reliance on LLM APIs introduces high cost and latency, raises data governance concerns, and limits reproducibility and offline deployment. To address the challenges, we adopt a knowledge distillation approach: an LLM teacher generates pseudo-labels to train a compact student model--over 500x smaller--that learns from the teacher's knowledge and efficiently classifies false positives. We evaluate IntelliSA against two static analyzers and three LLM baselines (Claude-4, Grok-4, and GPT-5) using a human-labeled dataset including 241 security smells across 11,814 lines of real-world IaC code. Experimental results show that IntelliSA achieves the highest F1 score (83%), outperforming baselines by 7-42%. Moreover, IntelliSA demonstrates the best cost-effectiveness, detecting 60% of security smells while inspecting less than 2% of the codebase.",
      "tldr_zh": "该研究针对基础设施即代码 (Infrastructure as Code, IaC) 中安全异味 (security smells) 检测面临的误报率高、人工检查负担重等挑战，提出了 IntelliSA，一种结合符号规则 (symbolic rules) 与神经推理 (neural inference) 的智能静态分析器。该工具首先利用符号规则对潜在的安全异味进行过度近似处理以确保广泛的覆盖率，随后通过神经推理层过滤误报。为了克服大型语言模型 (LLM) API 在成本、延迟及数据隐私方面的局限，IntelliSA 采用知识蒸馏 (knowledge distillation) 方法，训练出一个体积缩小 500 倍以上的紧凑型学生模型来执行分类任务。实验评估显示，IntelliSA 在真实 IaC 代码数据集上取得了 83% 的 F1 分数，性能优于 GPT-5 等基线模型 7-42%。此外，IntelliSA 展现出极高的性价比，仅需审计不到 2% 的代码即可发现 60% 的安全异味，为高效、自动化的 IaC 安全防护提供了有力支持。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at MSR 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.14595v1",
      "published_date": "2026-01-21 02:27:54 UTC",
      "updated_date": "2026-01-21 02:27:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:54:12.123858+00:00"
    },
    {
      "arxiv_id": "2601.14589v1",
      "title": "Designing KRIYA: An AI Companion for Wellbeing Self-Reflection",
      "title_zh": "设计 KRIYA：支持身心健康自我反思的 AI 伴侣",
      "authors": [
        "Shanshan Zhu",
        "Wenxuan Song",
        "Jiayue Melissa Shi",
        "Dong Whi Yoo",
        "Karthik S. Bhat",
        "Koustuv Saha"
      ],
      "abstract": "Most personal wellbeing apps present summative dashboards of health and physical activity metrics, yet many users struggle to translate this information into meaningful understanding. These apps commonly support engagement through goals, reminders, and structured targets, which can reinforce comparison, judgment, and performance anxiety. To explore a complementary approach that prioritizes self-reflection, we design KRIYA, an AI wellbeing companion that supports co-interpretive engagement with personal wellbeing data. KRIYA aims to collaborate with users to explore questions, explanations, and future scenarios through features such as Comfort Zone, Detective Mode, and What-If Planning. We conducted semi-structured interviews with 18 college students interacting with a KRIYA prototype using hypothetical data. Our findings show that through KRIYA interaction, users framed engaging with wellbeing data as interpretation rather than performance, experienced reflection as supportive or pressuring depending on emotional framing, and developed trust through transparency. We discuss design implications for AI companions that support curiosity, self-compassion, and reflective sensemaking of personal health data.",
      "tldr_zh": "该研究针对传统健康应用依赖数据指标易导致用户表现焦虑的问题，设计了名为 KRIYA 的 AI wellbeing companion，旨在通过共同解释的方式支持用户对个人健康数据进行自我反思。KRIYA 引入了 Comfort Zone、Detective Mode 和 What-If Planning 等核心功能，协助用户探索健康问题的解释并规划未来场景。通过对 18 名大学生进行的访谈研究发现，与 KRIYA 的互动促使视角从关注 performance 转向了对数据的 interpretation，且反思体验的性质（支持性或压力感）高度取决于情感框架。研究同时指出，系统透明度是建立 AI 信任的关键要素。最后，该研究探讨了支持好奇心、self-compassion 和反思性 sensemaking 的设计启示，为未来个人健康领域的人机交互设计提供了重要参考。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14589v1",
      "published_date": "2026-01-21 02:03:12 UTC",
      "updated_date": "2026-01-21 02:03:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:54:13.521444+00:00"
    },
    {
      "arxiv_id": "2601.15347v1",
      "title": "Logic Programming on Knowledge Graph Networks And its Application in Medical Domain",
      "title_zh": "知识图谱网络逻辑编程及其在医学领域的应用",
      "authors": [
        "Chuanqing Wang",
        "Zhenmin Zhao",
        "Shanshan Du",
        "Chaoqun Fei",
        "Songmao Zhang",
        "Ruqian Lu"
      ],
      "abstract": "The rash development of knowledge graph research has brought big driving force to its application in many areas, including the medicine and healthcare domain. However, we have found that the application of some major information processing techniques on knowledge graph still lags behind. This defect includes the failure to make sufficient use of advanced logic reasoning, advanced artificial intelligence techniques, special-purpose programming languages, modern probabilistic and statistic theories et al. on knowledge graphs development and application. In particular, the multiple knowledge graphs cooperation and competition techniques have not got enough attention from researchers. This paper develops a systematic theory, technique and application of the concept 'knowledge graph network' and its application in medical and healthcare domain. Our research covers its definition, development, reasoning, computing and application under different conditions such as unsharp, uncertain, multi-modal, vectorized, distributed, federated. Almost in each case we provide (real data) examples and experiment results. Finally, a conclusion of innovation is provided.",
      "tldr_zh": "该研究针对知识图谱(Knowledge Graph)在逻辑推理、人工智能技术应用及多图协作(multiple knowledge graphs cooperation)等方面的不足，系统性地提出了“知识图谱网络”(Knowledge Graph Network)的理论、技术及其在医疗健康领域的应用。文章定义并探讨了知识图谱网络在模糊(unsharp)、不确定(uncertain)、多模态(multi-modal)、向量化(vectorized)、分布式(distributed)及联邦(federated)等多种复杂条件下的推理与计算方法。通过结合逻辑编程(Logic Programming)与现代概率统计理论，该框架旨在弥补医疗领域信息处理技术在深度推理方面的短板。研究为每种技术路径提供了基于真实数据的示例和实验结果，验证了知识图谱网络在多场景下的创新性与实用价值。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.15347v1",
      "published_date": "2026-01-21 01:50:47 UTC",
      "updated_date": "2026-01-21 01:50:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:55:22.474038+00:00"
    },
    {
      "arxiv_id": "2601.14568v1",
      "title": "Breaking the accuracy-resource dilemma: a lightweight adaptive video inference enhancement",
      "title_zh": "破解精度与资源的两难困境：轻量级自适应视频推理增强",
      "authors": [
        "Wei Ma",
        "Shaowu Chen",
        "Junjie Ye",
        "Peichang Zhang",
        "Lei Huang"
      ],
      "abstract": "Existing video inference (VI) enhancement methods typically aim to improve performance by scaling up model sizes and employing sophisticated network architectures. While these approaches demonstrated state-of-the-art performance, they often overlooked the trade-off of resource efficiency and inference effectiveness, leading to inefficient resource utilization and suboptimal inference performance. To address this problem, a fuzzy controller (FC-r) is developed based on key system parameters and inference-related metrics. Guided by the FC-r, a VI enhancement framework is proposed, where the spatiotemporal correlation of targets across adjacent video frames is leveraged. Given the real-time resource conditions of the target device, the framework can dynamically switch between models of varying scales during VI. Experimental results demonstrate that the proposed method effectively achieves a balance between resource utilization and inference performance.",
      "tldr_zh": "该研究针对视频推理 (Video Inference, VI) 增强方法在性能提升与资源效率之间的权衡难题，提出了一种轻量级自适应增强框架。为了解决现有方法因追求高精度而导致的资源利用率低下和推理性能次优问题，研究开发了一个基于关键系统参数和推理相关指标的模糊控制器 (FC-r)。在该控制器的引导下，该框架充分利用了相邻视频帧中目标的时空相关性 (Spatiotemporal Correlation)，并能够根据目标设备的实时资源状况，在不同规模的模型之间进行动态切换。实验结果证明，该方法有效实现了资源利用与推理性能之间的平衡，为打破准确率与资源消耗的困境提供了高效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.14568v1",
      "published_date": "2026-01-21 01:09:38 UTC",
      "updated_date": "2026-01-21 01:09:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:54:38.127707+00:00"
    },
    {
      "arxiv_id": "2601.14553v1",
      "title": "Self-Blinding and Counterfactual Self-Simulation Mitigate Biases and Sycophancy in Large Language Models",
      "title_zh": "自我盲化与反事实自我模拟缓解大语言模型的偏见与阿谀现象",
      "authors": [
        "Brian Christian",
        "Matan Mazor"
      ],
      "abstract": "Fair decisions require ignoring irrelevant, potentially biasing, information. To achieve this, decision-makers need to approximate what decision they would have made had they not known certain facts, such as the gender or race of a job candidate. This counterfactual self-simulation is notoriously hard for humans, leading to biased judgments even by well-meaning actors. Here we show that large language models (LLMs) suffer from similar limitations in their ability to approximate what decisions they would make under counterfactual knowledge in offsetting gender and race biases and overcoming sycophancy. We show that prompting models to ignore or pretend not to know biasing information fails to offset these biases and occasionally backfires. However, unlike humans, LLMs can be given access to a ground-truth model of their own counterfactual cognition -- their own API. We show that this access to the responses of a blinded replica enables fairer decisions, while providing greater transparency to distinguish implicit from intentionally biased behavior.",
      "tldr_zh": "该研究探讨了大型语言模型(Large Language Models, LLMs)在决策过程中如何有效忽略无关的偏见信息，指出模型在应对性别、种族偏见及谄媚(Sycophancy)问题时，面临与人类相似的反事实自我模拟(Counterfactual Self-Simulation)困境。研究发现，简单的提示词(Prompting)技术要求模型忽略偏见信息往往难以奏效，甚至可能适得其反。为了克服这一局限，研究者提出了一种利用API访问自身盲测副本(Blinded Replica)的方法，使模型能够获取其反事实认知的真实模型。这种自我盲测(Self-Blinding)策略显著提高了决策的公平性，并为区分隐性偏见与刻意偏见行为提供了更高的透明度。实验结果证明，该方法比单纯的指令引导更有效，为开发更具鲁棒性和公平性的AI决策系统提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.14553v1",
      "published_date": "2026-01-21 00:26:54 UTC",
      "updated_date": "2026-01-21 00:26:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-23T08:56:54.935560+00:00"
    }
  ],
  "processing_status": "failed",
  "error": "2 papers failed; summary skipped",
  "raw_papers_fetched": true,
  "papers_count": 143,
  "processed_papers_count": 141,
  "failed_papers_count": 2,
  "llm_backup_calls": 0,
  "summary_generated": false,
  "daily_data_saved": false,
  "last_update": "2026-01-23T08:58:59.881122+00:00"
}