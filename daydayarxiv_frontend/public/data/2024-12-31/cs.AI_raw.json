[
  {
    "arxiv_id": "2501.00669v1",
    "title": "Leaf diseases detection using deep learning methods",
    "authors": [
      "El Houcine El Fatimi"
    ],
    "abstract": "This study, our main topic is to devlop a new deep-learning approachs for\nplant leaf disease identification and detection using leaf image datasets. We\nalso discussed the challenges facing current methods of leaf disease detection\nand how deep learning may be used to overcome these challenges and enhance the\naccuracy of disease detection. Therefore, we have proposed a novel method for\nthe detection of various leaf diseases in crops, along with the identification\nand description of an efficient network architecture that encompasses\nhyperparameters and optimization methods. The effectiveness of different\narchitectures was compared and evaluated to see the best architecture\nconfiguration and to create an effective model that can quickly detect leaf\ndisease. In addition to the work done on pre-trained models, we proposed a new\nmodel based on CNN, which provides an efficient method for identifying and\ndetecting plant leaf disease. Furthermore, we evaluated the efficacy of our\nmodel and compared the results to those of some pre-trained state-of-the-art\narchitectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "252 pages , 42 images",
    "pdf_url": "http://arxiv.org/pdf/2501.00669v1",
    "published_date": "2024-12-31 22:56:19 UTC",
    "updated_date": "2024-12-31 22:56:19 UTC"
  },
  {
    "arxiv_id": "2501.00664v3",
    "title": "Grade Inflation in Generative Models",
    "authors": [
      "Phuc Nguyen",
      "Miao Li",
      "Alexandra Morgan",
      "Rima Arnaout",
      "Ramy Arnaout"
    ],
    "abstract": "Generative models hold great potential, but only if one can trust the\nevaluation of the data they generate. We show that many commonly used quality\nscores for comparing two-dimensional distributions of synthetic vs.\nground-truth data give better results than they should, a phenomenon we call\nthe \"grade inflation problem.\" We show that the correlation score, Jaccard\nscore, earth-mover's score, and Kullback-Leibler (relative-entropy) score all\nsuffer grade inflation. We propose that any score that values all datapoints\nequally, as these do, will also exhibit grade inflation; we refer to such\nscores as \"equipoint\" scores. We introduce the concept of \"equidensity\" scores,\nand present the Eden score, to our knowledge the first example of such a score.\nWe found that Eden avoids grade inflation and agrees better with human\nperception of goodness-of-fit than the equipoint scores above. We propose that\nany reasonable equidensity score will avoid grade inflation. We identify a\nconnection between equidensity scores and R\\'enyi entropy of negative order. We\nconclude that equidensity scores are likely to outperform equipoint scores for\ngenerative models, and for comparing low-dimensional distributions more\ngenerally.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 6 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2501.00664v3",
    "published_date": "2024-12-31 22:34:54 UTC",
    "updated_date": "2025-01-22 21:15:18 UTC"
  },
  {
    "arxiv_id": "2501.00663v1",
    "title": "Titans: Learning to Memorize at Test Time",
    "authors": [
      "Ali Behrouz",
      "Peilin Zhong",
      "Vahab Mirrokni"
    ],
    "abstract": "Over more than a decade there has been an extensive research effort on how to\neffectively utilize recurrent models and attention. While recurrent models aim\nto compress the data into a fixed-size memory (called hidden state), attention\nallows attending to the entire context window, capturing the direct\ndependencies of all tokens. This more accurate modeling of dependencies,\nhowever, comes with a quadratic cost, limiting the model to a fixed-length\ncontext. We present a new neural long-term memory module that learns to\nmemorize historical context and helps attention to attend to the current\ncontext while utilizing long past information. We show that this neural memory\nhas the advantage of fast parallelizable training while maintaining a fast\ninference. From a memory perspective, we argue that attention due to its\nlimited context but accurate dependency modeling performs as a short-term\nmemory, while neural memory due to its ability to memorize the data, acts as a\nlong-term, more persistent, memory. Based on these two modules, we introduce a\nnew family of architectures, called Titans, and present three variants to\naddress how one can effectively incorporate memory into this architecture. Our\nexperimental results on language modeling, common-sense reasoning, genomics,\nand time series tasks show that Titans are more effective than Transformers and\nrecent modern linear recurrent models. They further can effectively scale to\nlarger than 2M context window size with higher accuracy in needle-in-haystack\ntasks compared to baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00663v1",
    "published_date": "2024-12-31 22:32:03 UTC",
    "updated_date": "2024-12-31 22:32:03 UTC"
  },
  {
    "arxiv_id": "2501.00644v1",
    "title": "Efficient Standardization of Clinical Notes using Large Language Models",
    "authors": [
      "Daniel B. Hier",
      "Michael D. Carrithers",
      "Thanh Son Do",
      "Tayo Obafemi-Ajayi"
    ],
    "abstract": "Clinician notes are a rich source of patient information but often contain\ninconsistencies due to varied writing styles, colloquialisms, abbreviations,\nmedical jargon, grammatical errors, and non-standard formatting. These\ninconsistencies hinder the extraction of meaningful data from electronic health\nrecords (EHRs), posing challenges for quality improvement, population health,\nprecision medicine, decision support, and research.\n  We present a large language model approach to standardizing a corpus of 1,618\nclinical notes. Standardization corrected an average of $4.9 +/- 1.8$\ngrammatical errors, $3.3 +/- 5.2$ spelling errors, converted $3.1 +/- 3.0$\nnon-standard terms to standard terminology, and expanded $15.8 +/- 9.1$\nabbreviations and acronyms per note. Additionally, notes were re-organized into\ncanonical sections with standardized headings. This process prepared notes for\nkey concept extraction, mapping to medical ontologies, and conversion to\ninteroperable data formats such as FHIR.\n  Expert review of randomly sampled notes found no significant data loss after\nstandardization. This proof-of-concept study demonstrates that standardization\nof clinical notes can improve their readability, consistency, and usability,\nwhile also facilitating their conversion into interoperable data formats.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "92",
      "J.3; I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00644v1",
    "published_date": "2024-12-31 20:52:40 UTC",
    "updated_date": "2024-12-31 20:52:40 UTC"
  },
  {
    "arxiv_id": "2501.00642v1",
    "title": "Enabling New HDLs with Agents",
    "authors": [
      "Mark Zakharov",
      "Farzaneh Rabiei Kashanaki",
      "Jose Renau"
    ],
    "abstract": "Large Language Models (LLMs) based agents are transforming the programming\nlanguage landscape by facilitating learning for beginners, enabling code\ngeneration, and optimizing documentation workflows. Hardware Description\nLanguages (HDLs), with their smaller user community, stand to benefit\nsignificantly from the application of LLMs as tools for learning new HDLs. This\npaper investigates the challenges and solutions of enabling LLMs for HDLs,\nparticularly for HDLs that LLMs have not been previously trained on. This work\nintroduces HDLAgent, an AI agent optimized for LLMs with limited knowledge of\nvarious HDLs. It significantly enhances off-the-shelf LLMs.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00642v1",
    "published_date": "2024-12-31 20:37:20 UTC",
    "updated_date": "2024-12-31 20:37:20 UTC"
  },
  {
    "arxiv_id": "2501.01994v1",
    "title": "Fuzzy Model Identification and Self Learning with Smooth Compositions",
    "authors": [
      "Ebrahim Navid Sadjadi",
      "Jesus Garcia",
      "Jose M. Molina",
      "Akbar Hashemi Borzabadi",
      "Monireh Asadi Abchouyeh"
    ],
    "abstract": "This paper develops a smooth model identification and self-learning strategy\nfor dynamic systems taking into account possible parameter variations and\nuncertainties. We have tried to solve the problem such that the model follows\nthe changes and variations in the system on a continuous and smooth surface.\nRunning the model to adaptively gain the optimum values of the parameters on a\nsmooth surface would facilitate further improvements in the application of\nother derivative based optimization control algorithms such as MPC or robust\ncontrol algorithms to achieve a combined modeling-control scheme. Compared to\nthe earlier works on the smooth fuzzy modeling structures, we could reach a\ndesired trade-off between the model optimality and the computational load. The\nproposed method has been evaluated on a test problem as well as the non-linear\ndynamic of a chemical process.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01994v1",
    "published_date": "2024-12-31 20:19:02 UTC",
    "updated_date": "2024-12-31 20:19:02 UTC"
  },
  {
    "arxiv_id": "2501.05464v2",
    "title": "LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models",
    "authors": [
      "Hang Yang",
      "Hao Chen",
      "Hui Guo",
      "Yineng Chen",
      "Ching-Sheng Lin",
      "Shu Hu",
      "Jinrong Hu",
      "Xi Wu",
      "Xin Wang"
    ],
    "abstract": "Accurate and efficient question-answering systems are essential for\ndelivering high-quality patient care in the medical field. While Large Language\nModels (LLMs) have made remarkable strides across various domains, they\ncontinue to face significant challenges in medical question answering,\nparticularly in understanding domain-specific terminologies and performing\ncomplex reasoning. These limitations undermine their effectiveness in critical\nmedical applications. To address these issues, we propose a novel approach\nincorporating similar case generation within a multi-agent medical\nquestion-answering (MedQA) system. Specifically, we leverage the Llama3.1:70B\nmodel, a state-of-the-art LLM, in a multi-agent architecture to enhance\nperformance on the MedQA dataset using zero-shot learning. Our method\ncapitalizes on the model's inherent medical knowledge and reasoning\ncapabilities, eliminating the need for additional training data. Experimental\nresults show substantial performance gains over existing benchmark models, with\nimprovements of 7% in both accuracy and F1-score across various medical QA\ntasks. Furthermore, we examine the model's interpretability and reliability in\naddressing complex medical queries. This research not only offers a robust\nsolution for medical question answering but also establishes a foundation for\nbroader applications of LLMs in the medical domain.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05464v2",
    "published_date": "2024-12-31 19:55:45 UTC",
    "updated_date": "2025-01-18 05:53:51 UTC"
  },
  {
    "arxiv_id": "2501.00619v1",
    "title": "A Study on Context Length and Efficient Transformers for Biomedical Image Analysis",
    "authors": [
      "Sarah M. Hooper",
      "Hui Xue"
    ],
    "abstract": "Biomedical imaging modalities often produce high-resolution,\nmulti-dimensional images that pose computational challenges for deep neural\nnetworks. These computational challenges are compounded when training\ntransformers due to the self-attention operator, which scales quadratically\nwith context length. Recent developments in long-context models have potential\nto alleviate these difficulties and enable more efficient application of\ntransformers to large biomedical images, although a systematic evaluation on\nthis topic is lacking. In this study, we investigate the impact of context\nlength on biomedical image analysis and we evaluate the performance of recently\nproposed long-context models. We first curate a suite of biomedical imaging\ndatasets, including 2D and 3D data for segmentation, denoising, and\nclassification tasks. We then analyze the impact of context length on network\nperformance using the Vision Transformer and Swin Transformer by varying patch\nsize and attention window size. Our findings reveal a strong relationship\nbetween context length and performance, particularly for pixel-level prediction\ntasks. Finally, we show that recent long-context models demonstrate significant\nimprovements in efficiency while maintaining comparable performance, though we\nhighlight where gaps remain. This work underscores the potential and challenges\nof using long-context models in biomedical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at ML4H 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.00619v1",
    "published_date": "2024-12-31 19:38:38 UTC",
    "updated_date": "2024-12-31 19:38:38 UTC"
  },
  {
    "arxiv_id": "2501.00601v2",
    "title": "DreamDrive: Generative 4D Scene Modeling from Street View Images",
    "authors": [
      "Jiageng Mao",
      "Boyi Li",
      "Boris Ivanovic",
      "Yuxiao Chen",
      "Yan Wang",
      "Yurong You",
      "Chaowei Xiao",
      "Danfei Xu",
      "Marco Pavone",
      "Yue Wang"
    ],
    "abstract": "Synthesizing photo-realistic visual observations from an ego vehicle's\ndriving trajectory is a critical step towards scalable training of self-driving\nmodels. Reconstruction-based methods create 3D scenes from driving logs and\nsynthesize geometry-consistent driving videos through neural rendering, but\ntheir dependence on costly object annotations limits their ability to\ngeneralize to in-the-wild driving scenarios. On the other hand, generative\nmodels can synthesize action-conditioned driving videos in a more generalizable\nway but often struggle with maintaining 3D visual consistency. In this paper,\nwe present DreamDrive, a 4D spatial-temporal scene generation approach that\ncombines the merits of generation and reconstruction, to synthesize\ngeneralizable 4D driving scenes and dynamic driving videos with 3D consistency.\nSpecifically, we leverage the generative power of video diffusion models to\nsynthesize a sequence of visual references and further elevate them to 4D with\na novel hybrid Gaussian representation. Given a driving trajectory, we then\nrender 3D-consistent driving videos via Gaussian splatting. The use of\ngenerative priors allows our method to produce high-quality 4D scenes from\nin-the-wild driving data, while neural rendering ensures 3D-consistent video\ngeneration from the 4D scenes. Extensive experiments on nuScenes and street\nview images demonstrate that DreamDrive can generate controllable and\ngeneralizable 4D driving scenes, synthesize novel views of driving videos with\nhigh fidelity and 3D consistency, decompose static and dynamic elements in a\nself-supervised manner, and enhance perception and planning tasks for\nautonomous driving.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://pointscoder.github.io/DreamDrive/",
    "pdf_url": "http://arxiv.org/pdf/2501.00601v2",
    "published_date": "2024-12-31 18:59:57 UTC",
    "updated_date": "2025-01-03 20:06:37 UTC"
  },
  {
    "arxiv_id": "2501.00599v3",
    "title": "VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM",
    "authors": [
      "Yuqian Yuan",
      "Hang Zhang",
      "Wentong Li",
      "Zesen Cheng",
      "Boqiang Zhang",
      "Long Li",
      "Xin Li",
      "Deli Zhao",
      "Wenqiao Zhang",
      "Yueting Zhuang",
      "Jianke Zhu",
      "Lidong Bing"
    ],
    "abstract": "Video Large Language Models (Video LLMs) have recently exhibited remarkable\ncapabilities in general video understanding. However, they mainly focus on\nholistic comprehension and struggle with capturing fine-grained spatial and\ntemporal details. Besides, the lack of high-quality object-level video\ninstruction data and a comprehensive benchmark further hinders their\nadvancements. To tackle these challenges, we introduce the VideoRefer Suite to\nempower Video LLM for finer-level spatial-temporal video understanding, i.e.,\nenabling perception and reasoning on any objects throughout the video.\nSpecially, we thoroughly develop VideoRefer Suite across three essential\naspects: dataset, model, and benchmark. Firstly, we introduce a multi-agent\ndata engine to meticulously curate a large-scale, high-quality object-level\nvideo instruction dataset, termed VideoRefer-700K. Next, we present the\nVideoRefer model, which equips a versatile spatial-temporal object encoder to\ncapture precise regional and sequential representations. Finally, we\nmeticulously create a VideoRefer-Bench to comprehensively assess the\nspatial-temporal understanding capability of a Video LLM, evaluating it across\nvarious aspects. Extensive experiments and analyses demonstrate that our\nVideoRefer model not only achieves promising performance on video referring\nbenchmarks but also facilitates general video understanding capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 14 figures, technical report",
    "pdf_url": "http://arxiv.org/pdf/2501.00599v3",
    "published_date": "2024-12-31 18:56:46 UTC",
    "updated_date": "2025-03-25 08:10:15 UTC"
  },
  {
    "arxiv_id": "2501.00595v1",
    "title": "Unbiased GNN Learning via Fairness-Aware Subgraph Diffusion",
    "authors": [
      "Abdullah Alchihabi",
      "Yuhong Guo"
    ],
    "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable efficacy in\ntackling a wide array of graph-related tasks across diverse domains. However, a\nsignificant challenge lies in their propensity to generate biased predictions,\nparticularly with respect to sensitive node attributes such as age and gender.\nThese biases, inherent in many machine learning models, are amplified in GNNs\ndue to the message-passing mechanism, which allows nodes to influence each\nother, rendering the task of making fair predictions notably challenging. This\nissue is particularly pertinent in critical domains where model fairness holds\nparamount importance. In this paper, we propose a novel generative\nFairness-Aware Subgraph Diffusion (FASD) method for unbiased GNN learning. The\nmethod initiates by strategically sampling small subgraphs from the original\nlarge input graph, and then proceeds to conduct subgraph debiasing via\ngenerative fairness-aware graph diffusion processes based on stochastic\ndifferential equations (SDEs). To effectively diffuse unfairness in the input\ndata, we introduce additional adversary bias perturbations to the subgraphs\nduring the forward diffusion process, and train score-based models to predict\nthese applied perturbations, enabling them to learn the underlying dynamics of\nthe biases present in the data. Subsequently, the trained score-based models\nare utilized to further debias the original subgraph samples through the\nreverse diffusion process. Finally, FASD induces fair node predictions on the\ninput graph by performing standard GNN learning on the debiased subgraphs.\nExperimental results demonstrate the superior performance of the proposed\nmethod over state-of-the-art Fair GNN baselines across multiple benchmark\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00595v1",
    "published_date": "2024-12-31 18:48:30 UTC",
    "updated_date": "2024-12-31 18:48:30 UTC"
  },
  {
    "arxiv_id": "2501.00581v2",
    "title": "Are the Values of LLMs Structurally Aligned with Humans? A Causal Perspective",
    "authors": [
      "Yipeng Kang",
      "Junqi Wang",
      "Yexin Li",
      "Mengmeng Wang",
      "Wenming Tu",
      "Quansen Wang",
      "Hengli Li",
      "Tingjun Wu",
      "Xue Feng",
      "Fangwei Zhong",
      "Zilong Zheng"
    ],
    "abstract": "As large language models (LLMs) become increasingly integrated into critical\napplications, aligning their behavior with human values presents significant\nchallenges. Current methods, such as Reinforcement Learning from Human Feedback\n(RLHF), typically focus on a limited set of coarse-grained values and are\nresource-intensive. Moreover, the correlations between these values remain\nimplicit, leading to unclear explanations for value-steering outcomes. Our work\nargues that a latent causal value graph underlies the value dimensions of LLMs\nand that, despite alignment training, this structure remains significantly\ndifferent from human value systems. We leverage these causal value graphs to\nguide two lightweight value-steering methods: role-based prompting and sparse\nautoencoder (SAE) steering, effectively mitigating unexpected side effects.\nFurthermore, SAE provides a more fine-grained approach to value steering.\nExperiments on Gemma-2B-IT and Llama3-8B-IT demonstrate the effectiveness and\ncontrollability of our methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00581v2",
    "published_date": "2024-12-31 18:12:05 UTC",
    "updated_date": "2025-02-23 16:33:30 UTC"
  },
  {
    "arxiv_id": "2501.00562v2",
    "title": "An Overview and Discussion on Using Large Language Models for Implementation Generation of Solutions to Open-Ended Problems",
    "authors": [
      "Hashmath Shaik",
      "Alex Doboli"
    ],
    "abstract": "Large Language Models offer new opportunities to devise automated\nimplementation generation methods that can tackle problem solving activities\nbeyond traditional methods, which require algorithmic specifications and can\nuse only static domain knowledge, like performance metrics and libraries of\nbasic building blocks. Large Language Models could support creating new methods\nto support problem solving activities for open-ended problems, like problem\nframing, exploring possible solving approaches, feature elaboration and\ncombination, more advanced implementation assessment, and handling unexpected\nsituations. This report summarized the current work on Large Language Models,\nincluding model prompting, Reinforcement Learning, and Retrieval-Augmented\nGeneration. Future research requirements were also discussed.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00562v2",
    "published_date": "2024-12-31 17:48:33 UTC",
    "updated_date": "2025-01-03 06:28:02 UTC"
  },
  {
    "arxiv_id": "2501.00560v2",
    "title": "Re-evaluating Automatic LLM System Ranking for Alignment with Human Preference",
    "authors": [
      "Mingqi Gao",
      "Yixin Liu",
      "Xinyu Hu",
      "Xiaojun Wan",
      "Jonathan Bragg",
      "Arman Cohan"
    ],
    "abstract": "Evaluating and ranking the capabilities of different LLMs is crucial for\nunderstanding their performance and alignment with human preferences. Due to\nthe high cost and time-consuming nature of human evaluations, an automatic LLM\nbencher (i.e., an automatic evaluation framework that aims to rank LLMs based\non their alignment with human preferences) is indispensable. An automatic LLM\nbencher consists of four components: the input set (e.g., a user instruction),\nthe evaluation model (e.g., an LLM), the evaluation type (e.g., pairwise\ncomparison), and the aggregation method (e.g., the ELO rating system). However,\nprevious work has not thoroughly explored how to select these components or how\ntheir different combinations influence the results. In this work, through\ncontrolled experiments, we provide a series of recommendations on how to choose\neach component to better automate the evaluation of LLMs. Furthermore, we\ndiscovered that when evaluating LLMs with similar performance, the performance\nof the automatic LLM bencher declines sharply, underscoring the limitations of\ncurrent benchers and calling for future work. Lastly, we found that the\nevaluation models' performance at the instance level (e.g., the accuracy of\nselecting the best output) does not always align with their effectiveness when\nused as a component of a bencher, highlighting the importance of dedicated\nsystem-level evaluation of benchers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.00560v2",
    "published_date": "2024-12-31 17:46:51 UTC",
    "updated_date": "2025-02-11 10:02:55 UTC"
  },
  {
    "arxiv_id": "2501.00559v1",
    "title": "AraSTEM: A Native Arabic Multiple Choice Question Benchmark for Evaluating LLMs Knowledge In STEM Subjects",
    "authors": [
      "Ahmad Mustapha",
      "Hadi Al-Khansa",
      "Hadi Al-Mubasher",
      "Aya Mourad",
      "Ranam Hamoud",
      "Hasan El-Husseini",
      "Marwah Al-Sakkaf",
      "Mariette Awad"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities, not only in\ngenerating human-like text, but also in acquiring knowledge. This highlights\nthe need to go beyond the typical Natural Language Processing downstream\nbenchmarks and asses the various aspects of LLMs including knowledge and\nreasoning. Numerous benchmarks have been developed to evaluate LLMs knowledge,\nbut they predominantly focus on the English language. Given that many LLMs are\nmultilingual, relying solely on benchmarking English knowledge is insufficient.\nTo address this issue, we introduce AraSTEM, a new Arabic multiple-choice\nquestion dataset aimed at evaluating LLMs knowledge in STEM subjects. The\ndataset spans a range of topics at different levels which requires models to\ndemonstrate a deep understanding of scientific Arabic in order to achieve high\naccuracy. Our findings show that publicly available models of varying sizes\nstruggle with this dataset, and underscores the need for more localized\nlanguage models. The dataset is freely accessible on Hugging Face.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00559v1",
    "published_date": "2024-12-31 17:45:12 UTC",
    "updated_date": "2024-12-31 17:45:12 UTC"
  },
  {
    "arxiv_id": "2501.00555v1",
    "title": "Monty Hall and Optimized Conformal Prediction to Improve Decision-Making with LLMs",
    "authors": [
      "Harit Vishwakarma",
      "Alan Mishler",
      "Thomas Cook",
      "Niccolò Dalmasso",
      "Natraj Raman",
      "Sumitra Ganesh"
    ],
    "abstract": "Large language models (LLMs) are empowering decision-making in several\napplications, including tool or API usage and answering multiple-choice\nquestions (MCQs). However, they often make overconfident, incorrect\npredictions, which can be risky in high-stakes settings like healthcare and\nfinance. To mitigate these risks, recent works have used conformal prediction\n(CP), a model-agnostic framework for distribution-free uncertainty\nquantification. CP transforms a \\emph{score function} into prediction sets that\ncontain the true answer with high probability. While CP provides this coverage\nguarantee for arbitrary scores, the score quality significantly impacts\nprediction set sizes. Prior works have relied on LLM logits or other heuristic\nscores, lacking quality guarantees. We address this limitation by introducing\nCP-OPT, an optimization framework to learn scores that minimize set sizes while\nmaintaining coverage. Furthermore, inspired by the Monty Hall problem, we\nextend CP's utility beyond uncertainty quantification to improve accuracy. We\npropose \\emph{conformal revision of questions} (CROQ) to revise the problem by\nnarrowing down the available choices to those in the prediction set. The\ncoverage guarantee of CP ensures that the correct choice is in the revised\nquestion prompt with high probability, while the smaller number of choices\nincreases the LLM's chances of answering it correctly. Experiments on MMLU,\nToolAlpaca, and TruthfulQA datasets with Gemma-2, Llama-3 and Phi-3 models show\nthat CP-OPT significantly reduces set sizes while maintaining coverage, and\nCROQ improves accuracy over the standard inference, especially when paired with\nCP-OPT scores. Together, CP-OPT and CROQ offer a robust framework for improving\nboth the safety and accuracy of LLM-driven decision-making.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00555v1",
    "published_date": "2024-12-31 17:33:12 UTC",
    "updated_date": "2024-12-31 17:33:12 UTC"
  },
  {
    "arxiv_id": "2501.05463v1",
    "title": "Proof Recommendation System for the HOL4 Theorem Prover",
    "authors": [
      "Nour Dekhil",
      "Adnan Rashid",
      "Sofiene Tahar"
    ],
    "abstract": "We introduce a proof recommender system for the HOL4 theorem prover. Our tool\nis built upon a transformer-based model [2] designed specifically to provide\nproof assistance in HOL4. The model is trained to discern theorem proving\npatterns from extensive libraries of HOL4 containing proofs of theorems.\nConsequently, it can accurately predict the next tactic(s) (proof step(s))\nbased on the history of previously employed tactics. The tool operates by\nreading a given sequence of tactics already used in a proof process (in our\ncase, it contains at least three tactics), referred to as the current proof\nstate, and provides recommendations for the next optimal proof step(s).",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "Conference on Artificial Intelligence and Theorem Proving (AITP),\n  Aussois, France, 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.05463v1",
    "published_date": "2024-12-31 17:13:59 UTC",
    "updated_date": "2024-12-31 17:13:59 UTC"
  },
  {
    "arxiv_id": "2501.00539v2",
    "title": "MCP-Solver: Integrating Language Models with Constraint Programming Systems",
    "authors": [
      "Stefan Szeider"
    ],
    "abstract": "The MCP Solver bridges Large Language Models (LLMs) with symbolic solvers\nthrough the Model Context Protocol (MCP), an open-source standard for AI system\nintegration. Providing LLMs access to formal solving and reasoning capabilities\naddresses their key deficiency while leveraging their strengths. Our\nimplementation offers interfaces for constraint programming (Minizinc),\npropositional satisfiability (PySAT), and SAT modulo Theories (Python Z3). The\nsystem employs an editing approach with iterated validation to ensure model\nconsistency during modifications and enable structured refinement.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00539v2",
    "published_date": "2024-12-31 16:49:27 UTC",
    "updated_date": "2025-04-06 08:39:04 UTC"
  },
  {
    "arxiv_id": "2501.00537v1",
    "title": "Extending XReason: Formal Explanations for Adversarial Detection",
    "authors": [
      "Amira Jemaa",
      "Adnan Rashid",
      "Sofiene Tahar"
    ],
    "abstract": "Explainable Artificial Intelligence (XAI) plays an important role in\nimproving the transparency and reliability of complex machine learning models,\nespecially in critical domains such as cybersecurity. Despite the prevalence of\nheuristic interpretation methods such as SHAP and LIME, these techniques often\nlack formal guarantees and may produce inconsistent local explanations. To\nfulfill this need, few tools have emerged that use formal methods to provide\nformal explanations. Among these, XReason uses a SAT solver to generate formal\ninstance-level explanation for XGBoost models. In this paper, we extend the\nXReason tool to support LightGBM models as well as class-level explanations.\nAdditionally, we implement a mechanism to generate and detect adversarial\nexamples in XReason. We evaluate the efficiency and accuracy of our approach on\nthe CICIDS-2017 dataset, a widely used benchmark for detecting network attacks.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "International Congress on Information and Communication Technology\n  (ICICT), Lecture Notes in Networks and Systems (LNNS), Springer, 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.00537v1",
    "published_date": "2024-12-31 16:45:03 UTC",
    "updated_date": "2024-12-31 16:45:03 UTC"
  },
  {
    "arxiv_id": "2501.01463v1",
    "title": "Goal Recognition using Actor-Critic Optimization",
    "authors": [
      "Ben Nageris",
      "Felipe Meneguzzi",
      "Reuth Mirsky"
    ],
    "abstract": "Goal Recognition aims to infer an agent's goal from a sequence of\nobservations. Existing approaches often rely on manually engineered domains and\ndiscrete representations. Deep Recognition using Actor-Critic Optimization\n(DRACO) is a novel approach based on deep reinforcement learning that overcomes\nthese limitations by providing two key contributions. First, it is the first\ngoal recognition algorithm that learns a set of policy networks from\nunstructured data and uses them for inference. Second, DRACO introduces new\nmetrics for assessing goal hypotheses through continuous policy\nrepresentations. DRACO achieves state-of-the-art performance for goal\nrecognition in discrete settings while not using the structured inputs used by\nexisting approaches. Moreover, it outperforms these approaches in more\nchallenging, continuous settings at substantially reduced costs in both\ncomputing and memory. Together, these results showcase the robustness of the\nnew algorithm, bridging traditional goal recognition and deep reinforcement\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01463v1",
    "published_date": "2024-12-31 16:44:20 UTC",
    "updated_date": "2024-12-31 16:44:20 UTC"
  },
  {
    "arxiv_id": "2501.00530v2",
    "title": "Superposition in Transformers: A Novel Way of Building Mixture of Experts",
    "authors": [
      "Ayoub Ben Chaliah",
      "Hela Dellagi"
    ],
    "abstract": "Catastrophic forgetting remains a major challenge when adapting large\nlanguage models (LLMs) to new tasks or domains. Conventional fine-tuning often\noverwrites existing knowledge, causing performance degradation on original\ntasks. We introduce Superposition in Transformers, a novel architecture that\nleverages autoencoders to superimpose the hidden representations of a base\nmodel and a fine-tuned model within a shared parameter space. By using\nB-spline-based blending coefficients and autoencoders that adaptively\nreconstruct hidden states based on the input data distribution, our method\neffectively mitigates catastrophic forgetting and enables a new paradigm of\n\"in-model\" superposition. This approach preserves original model capabilities\nwhile allowing compact domain-specific expertise to be added, and it supports\ndynamic switching between model states during inference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00530v2",
    "published_date": "2024-12-31 16:28:23 UTC",
    "updated_date": "2025-01-06 23:02:42 UTC"
  },
  {
    "arxiv_id": "2501.00528v1",
    "title": "PyMilo: A Python Library for ML I/O",
    "authors": [
      "AmirHosein Rostami",
      "Sepand Haghighi",
      "Sadra Sabouri",
      "Alireza Zolanvari"
    ],
    "abstract": "PyMilo is an open-source Python package that addresses the limitations of\nexisting Machine Learning (ML) model storage formats by providing a\ntransparent, reliable, and safe method for exporting and deploying trained\nmodels. Current formats, such as pickle and other binary formats, have\nsignificant problems, such as reliability, safety, and transparency issues. In\ncontrast, PyMilo serializes ML models in a transparent non-executable format,\nenabling straightforward and safe model exchange, while also facilitating the\ndeserialization and deployment of exported models in production environments.\nThis package aims to provide a seamless, end-to-end solution for the\nexportation and importation of pre-trained ML models, which simplifies the\nmodel development and deployment pipeline.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 5 figures, 2 tables, 3 code blocks",
    "pdf_url": "http://arxiv.org/pdf/2501.00528v1",
    "published_date": "2024-12-31 16:27:46 UTC",
    "updated_date": "2024-12-31 16:27:46 UTC"
  },
  {
    "arxiv_id": "2501.00522v1",
    "title": "TinyHelen's First Curriculum: Training and Evaluating Tiny Language Models in a Simpler Language Environment",
    "authors": [
      "Ke Yang",
      "Volodymyr Kindratenko",
      "ChengXiang Zhai"
    ],
    "abstract": "Training language models (LMs) and their application agents is increasingly\ncostly due to large datasets and models, making test failures difficult to\nbear. Simplified language environments serve as primordial training and testing\ngrounds, retaining essential commonsense and communication skills but in a more\ndigestible form, potentially enhancing the learning efficiency of LMs, and thus\nreducing the required model size and data volume for effective training and\nevaluation. In these simplified language environments, workable strategies for\nsmall models, datasets, and agents may be adaptable to larger models, datasets,\nand agents in complex language environments.\n  To create such environments, we focus on two aspects: i) minimizing language\ndataset noise and complexity, and ii) preserving the essential text\ndistribution characteristics. Unlike previous methods, we propose a pipeline to\nrefine text data by eliminating noise, minimizing vocabulary, and maintaining\ngenre-specific patterns (e.g., for books, conversation, code, etc.).\nImplementing this pipeline with large LMs, we have created a leaner suite of LM\ntraining and evaluation datasets: 71M Leaner-Pretrain, 7M Leaner-Instruct,\nLeaner-Glue for assessing linguistic proficiency, and Leaner-Eval for testing\ninstruction-following ability.\n  Our experiments show that leaner pre-training boosts LM learning efficiency.\nTiny LMs trained on these datasets outperform those trained on original\ndatasets in instruction-following across different language granularity levels.\nMoreover, the Leaner-Pretrain dataset's alignment with conventional large LM\ntraining sets enables resource-optimized analysis of how learning objectives,\nmodel architectures, and training techniques impact performance on language\nmodeling and downstream tasks. Our code and datasets are available at\nhttps://github.com/EmpathYang/TinyHelen.git.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00522v1",
    "published_date": "2024-12-31 16:08:15 UTC",
    "updated_date": "2024-12-31 16:08:15 UTC"
  },
  {
    "arxiv_id": "2501.00517v1",
    "title": "A Method for Enhancing the Safety of Large Model Generation Based on Multi-dimensional Attack and Defense",
    "authors": [
      "Keke Zhai"
    ],
    "abstract": "Currently, large models are prone to generating harmful content when faced\nwith complex attack instructions, significantly reducing their defensive\ncapabilities. To address this issue, this paper proposes a method based on\nconstructing data aligned with multi-dimensional attack defense to enhance the\ngenerative security of large models. The core of our method lies in improving\nthe effectiveness of safe alignment learning for large models by innova-tively\nincreasing the diversity of attack instruction dimensions and the accuracy of\ngenerat-ing safe responses. To validate the effectiveness of our method, beyond\nexisting security evaluation benchmarks, we additionally designed new security\nevaluation benchmarks and conducted comparative experiments using Llama3.2 as\nthe baseline model. The final ex-perimental results demonstrate that our method\ncan significantly improve the generative security of large models under complex\ninstructional attacks, while also maintaining and enhancing the models' general\ncapabilities.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00517v1",
    "published_date": "2024-12-31 16:01:25 UTC",
    "updated_date": "2024-12-31 16:01:25 UTC"
  },
  {
    "arxiv_id": "2501.00514v1",
    "title": "H-Net: A Multitask Architecture for Simultaneous 3D Force Estimation and Stereo Semantic Segmentation in Intracardiac Catheters",
    "authors": [
      "Pedram Fekri",
      "Mehrdad Zadeh",
      "Javad Dargahi"
    ],
    "abstract": "The success rate of catheterization procedures is closely linked to the\nsensory data provided to the surgeon. Vision-based deep learning models can\ndeliver both tactile and visual information in a sensor-free manner, while also\nbeing cost-effective to produce. Given the complexity of these models for\ndevices with limited computational resources, research has focused on force\nestimation and catheter segmentation separately. However, there is a lack of a\ncomprehensive architecture capable of simultaneously segmenting the catheter\nfrom two different angles and estimating the applied forces in 3D. To bridge\nthis gap, this work proposes a novel, lightweight, multi-input, multi-output\nencoder-decoder-based architecture. It is designed to segment the catheter from\ntwo points of view and concurrently measure the applied forces in the x, y, and\nz directions. This network processes two simultaneous X-Ray images, intended to\nbe fed by a biplane fluoroscopy system, showing a catheter's deflection from\ndifferent angles. It uses two parallel sub-networks with shared parameters to\noutput two segmentation maps corresponding to the inputs. Additionally, it\nleverages stereo vision to estimate the applied forces at the catheter's tip in\n3D. The architecture features two input channels, two classification heads for\nsegmentation, and a regression head for force estimation through a single\nend-to-end architecture. The output of all heads was assessed and compared with\nthe literature, demonstrating state-of-the-art performance in both segmentation\nand force estimation. To the best of the authors' knowledge, this is the first\ntime such a model has been proposed",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00514v1",
    "published_date": "2024-12-31 15:55:13 UTC",
    "updated_date": "2024-12-31 15:55:13 UTC"
  },
  {
    "arxiv_id": "2501.00502v1",
    "title": "Exploring Physics-Informed Neural Networks for Crop Yield Loss Forecasting",
    "authors": [
      "Miro Miranda",
      "Marcela Charfuelan",
      "Andreas Dengel"
    ],
    "abstract": "In response to climate change, assessing crop productivity under extreme\nweather conditions is essential to enhance food security. Crop simulation\nmodels, which align with physical processes, offer explainability but often\nperform poorly. Conversely, machine learning (ML) models for crop modeling are\npowerful and scalable yet operate as black boxes and lack adherence to crop\ngrowths physical principles. To bridge this gap, we propose a novel method that\ncombines the strengths of both approaches by estimating the water use and the\ncrop sensitivity to water scarcity at the pixel level. This approach enables\nyield loss estimation grounded in physical principles by sequentially solving\nthe equation for crop yield response to water scarcity, using an enhanced loss\nfunction. Leveraging Sentinel-2 satellite imagery, climate data, simulated\nwater use data, and pixel-level yield data, our model demonstrates high\naccuracy, achieving an R2 of up to 0.77, matching or surpassing\nstate-of-the-art models like RNNs and Transformers. Additionally, it provides\ninterpretable and physical consistent outputs, supporting industry,\npolicymakers, and farmers in adapting to extreme weather conditions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 2 figures, NeurIPS 2024 Workshop on Tackling Climate Change\n  with Machine Learning",
    "pdf_url": "http://arxiv.org/pdf/2501.00502v1",
    "published_date": "2024-12-31 15:21:50 UTC",
    "updated_date": "2024-12-31 15:21:50 UTC"
  },
  {
    "arxiv_id": "2501.01462v1",
    "title": "Pan-infection Foundation Framework Enables Multiple Pathogen Prediction",
    "authors": [
      "Lingrui Zhang",
      "Haonan Wu",
      "Nana Jin",
      "Chenqing Zheng",
      "Jize Xie",
      "Qitai Cai",
      "Jun Wang",
      "Qin Cao",
      "Xubin Zheng",
      "Jiankun Wang",
      "Lixin Cheng"
    ],
    "abstract": "Host-response-based diagnostics can improve the accuracy of diagnosing\nbacterial and viral infections, thereby reducing inappropriate antibiotic\nprescriptions. However, the existing cohorts with limited sample size and\ncoarse infections types are unable to support the exploration of an accurate\nand generalizable diagnostic model. Here, we curate the largest infection\nhost-response transcriptome data, including 11,247 samples across 89 blood\ntranscriptome datasets from 13 countries and 21 platforms. We build a\ndiagnostic model for pathogen prediction starting from a pan-infection model as\nfoundation (AUC = 0.97) based on the pan-infection dataset. Then, we utilize\nknowledge distillation to efficiently transfer the insights from this \"teacher\"\nmodel to four lightweight pathogen \"student\" models, i.e., staphylococcal\ninfection (AUC = 0.99), streptococcal infection (AUC = 0.94), HIV infection\n(AUC = 0.93), and RSV infection (AUC = 0.94), as well as a sepsis \"student\"\nmodel (AUC = 0.99). The proposed knowledge distillation framework not only\nfacilitates the diagnosis of pathogens using pan-infection data, but also\nenables an across-disease study from pan-infection to sepsis. Moreover, the\nframework enables high-degree lightweight design of diagnostic models, which is\nexpected to be adaptively deployed in clinical settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.01462v1",
    "published_date": "2024-12-31 14:34:53 UTC",
    "updated_date": "2024-12-31 14:34:53 UTC"
  },
  {
    "arxiv_id": "2501.00461v1",
    "title": "Efficient support ticket resolution using Knowledge Graphs",
    "authors": [
      "Sherwin Varghese",
      "James Tian"
    ],
    "abstract": "A review of over 160,000 customer cases indicates that about 90% of time is\nspent by the product support for solving around 10% of subset of tickets where\na trivial solution may not exist. Many of these challenging cases require the\nsupport of several engineers working together within a \"swarm\", and some also\nneed to go to development support as bugs. These challenging customer issues\nrepresent a major opportunity for machine learning and knowledge graph that\nidentifies the ideal engineer / group of engineers(swarm) that can best address\nthe solution, reducing the wait times for the customer. The concrete ML task we\nconsider here is a learning-to-rank(LTR) task that given an incident and a set\nof engineers currently assigned to the incident (which might be the empty set\nin the non-swarming context), produce a ranked list of engineers best fit to\nhelp resolve that incident. To calculate the rankings, we may consider a wide\nvariety of input features including the incident description provided by the\ncustomer, the affected component(s), engineer ratings of their expertise,\nknowledge base article text written by engineers, response to customer text\nwritten by engineers, and historic swarming data. The central hypothesis test\nis that by including a holistic set of contextual data around which cases an\nengineer has solved, we can significantly improve the LTR algorithm over\nbenchmark models. The article proposes a novel approach of modelling Knowledge\nGraph embeddings from multiple data sources, including the swarm information.\nThe results obtained proves that by incorporating this additional context, we\ncan improve the recommendations significantly over traditional machine learning\nmethods like TF-IDF.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00461v1",
    "published_date": "2024-12-31 14:21:05 UTC",
    "updated_date": "2024-12-31 14:21:05 UTC"
  },
  {
    "arxiv_id": "2501.00457v1",
    "title": "Differentiable Prompt Learning for Vision Language Models",
    "authors": [
      "Zhenhan Huang",
      "Tejaswini Pedapati",
      "Pin-Yu Chen",
      "Jianxi Gao"
    ],
    "abstract": "Prompt learning is an effective way to exploit the potential of large-scale\npre-trained foundational models. Continuous prompts parameterize context tokens\nin prompts by turning them into differentiable vectors. Deep continuous prompts\ninsert prompts not only in the input but also in the intermediate hidden\nrepresentations. Manually designed deep continuous prompts exhibit a remarkable\nimprovement compared to the zero-shot pre-trained model on downstream tasks.\nHow to automate the continuous prompt design is an underexplored area, and a\nfundamental question arises, is manually designed deep prompt strategy optimal?\nTo answer this question, we propose a method dubbed differentiable prompt\nlearning (DPL). The DPL method is formulated as an optimization problem to\nautomatically determine the optimal context length of the prompt to be added to\neach layer, where the objective is to maximize the performance. We test the DPL\nmethod on the pre-trained CLIP. We empirically find that by using only limited\ndata, our DPL method can find deep continuous prompt configuration with high\nconfidence. The performance on the downstream tasks exhibits the superiority of\nthe automatic design: our method boosts the average test accuracy by 2.60% on\n11 datasets compared to baseline methods. Besides, our method focuses only on\nthe prompt configuration (i.e. context length for each layer), which means that\nour method is compatible with the baseline methods that have sophisticated\ndesigns to boost the performance. The DPL method can be deployed to large\nlanguage models or computer vision models at no cost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00457v1",
    "published_date": "2024-12-31 14:13:28 UTC",
    "updated_date": "2024-12-31 14:13:28 UTC"
  },
  {
    "arxiv_id": "2501.00449v1",
    "title": "Do Students with Different Personality Traits Demonstrate Different Physiological Signals in Video-based Learning?",
    "authors": [
      "Chun-Hsiung Tseng",
      "Hao-Chiang Koong Lin",
      "Yung-Hui Chen",
      "Jia-Rou Lin",
      "Andrew Chih-Wei Huang"
    ],
    "abstract": "Past researches show that personality trait is a strong predictor for ones\nacademic performance. Today, mature and verified marker systems for assessing\npersonality traits already exist. However, marker systems-based assessing\nmethods have their own limitations. For example, dishonest responses cannot be\navoided. In this research, the goal is to develop a method that can overcome\nthe limitations. The proposed method will rely on physiological signals for the\nassessment. Thirty participants have participated in this experiment. Based on\nthe statistical results, we found that there are correlations between students\npersonality traits and their physiological signal change when learning via\nvideos. Specifically, we found that participants degree of extraversion,\nagreeableness, conscientiousness, and openness to experiences are correlated\nwith the variance of heart rates, the variance of GSR values, and the skewness\nof voice frequencies, etc.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00449v1",
    "published_date": "2024-12-31 14:00:32 UTC",
    "updated_date": "2024-12-31 14:00:32 UTC"
  },
  {
    "arxiv_id": "2501.14776v1",
    "title": "Green AI: Which Programming Language Consumes the Most?",
    "authors": [
      "Niccolò Marini",
      "Leonardo Pampaloni",
      "Filippo Di Martino",
      "Roberto Verdecchia",
      "Enrico Vicario"
    ],
    "abstract": "AI is demanding an evergrowing portion of environmental resources. Despite\ntheir potential impact on AI environmental sustainability, the role that\nprogramming languages play in AI (in)efficiency is to date still unknown. With\nthis study, we aim to understand the impact that programming languages can have\non AI environmental sustainability. To achieve our goal, we conduct a\ncontrolled empirical experiment by considering five programming languages (C++,\nJava, Python, MATLAB, and R), seven AI algorithms (KNN, SVC, AdaBoost, decision\ntree, logistic regression, naive bayses, and random forest), three popular\ndatasets, and the training and inference phases. The collected results show\nthat programming languages have a considerable impact on AI environmental\nsustainability. Compiled and semi-compiled languages (C++, Java) consistently\nconsume less than interpreted languages (Python, MATLAB, R), which require up\nto 54x more energy. Some languages are cumulatively more efficient in training,\nwhile others in inference. Which programming language consumes the most highly\ndepends on the algorithm considered. Ultimately, algorithm implementation might\nbe the most determining factor in Green AI, regardless of the language used. As\nconclusion, while making AI more environmentally sustainable is paramount, a\ntrade-off between energy efficiency and implementation ease should always be\nconsidered. Green AI can be achieved without the need of completely disrupting\nthe development practices and technologies currently in place.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted at International Workshop on Green and Sustainable Software\n  (GREENS), 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.14776v1",
    "published_date": "2024-12-31 13:53:57 UTC",
    "updated_date": "2024-12-31 13:53:57 UTC"
  },
  {
    "arxiv_id": "2501.00444v1",
    "title": "Knowledge-aware equation discovery with automated background knowledge extraction",
    "authors": [
      "Elizaveta Ivanchik",
      "Alexander Hvatov"
    ],
    "abstract": "In differential equation discovery algorithms, a priori expert knowledge is\nmainly used implicitly to constrain the form of the expected equation, making\nit impossible for the algorithm to truly discover equations. Instead, most\ndifferential equation discovery algorithms try to recover the coefficients for\na known structure. In this paper, we describe an algorithm that allows the\ndiscovery of unknown equations using automatically or manually extracted\nbackground knowledge. Instead of imposing rigid constraints, we modify the\nstructure space so that certain terms are likely to appear within the crossover\nand mutation operators. In this way, we mimic expertly chosen terms while\npreserving the possibility of obtaining any equation form. The paper shows that\nthe extraction and use of knowledge allows it to outperform the SINDy algorithm\nin terms of search stability and robustness. Synthetic examples are given for\nBurgers, wave, and Korteweg--De Vries equations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00444v1",
    "published_date": "2024-12-31 13:51:31 UTC",
    "updated_date": "2024-12-31 13:51:31 UTC"
  },
  {
    "arxiv_id": "2501.01992v1",
    "title": "Disagree and Commit: Degrees of Argumentation-based Agreements",
    "authors": [
      "Timotheus Kampik",
      "Juan Carlos Nieves"
    ],
    "abstract": "In cooperative human decision-making, agreements are often not total; a\npartial degree of agreement is sufficient to commit to a decision and move on,\nas long as one is somewhat confident that the involved parties are likely to\nstand by their commitment in the future, given no drastic unexpected changes.\nIn this paper, we introduce the notion of agreement scenarios that allow\nartificial autonomous agents to reach such agreements, using formal models of\nargumentation, in particular abstract argumentation and value-based\nargumentation. We introduce the notions of degrees of satisfaction and\n(minimum, mean, and median) agreement, as well as a measure of the impact a\nvalue in a value-based argumentation framework has on these notions. We then\nanalyze how degrees of agreement are affected when agreement scenarios are\nexpanded with new information, to shed light on the reliability of partial\nagreements in dynamic scenarios. An implementation of the introduced concepts\nis provided as part of an argumentation-based reasoning software library.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear eventually in the Autonomous Agents and Multi-Agent Systems\n  journal",
    "pdf_url": "http://arxiv.org/pdf/2501.01992v1",
    "published_date": "2024-12-31 12:49:58 UTC",
    "updated_date": "2024-12-31 12:49:58 UTC"
  },
  {
    "arxiv_id": "2501.00418v1",
    "title": "Generalizing Trust: Weak-to-Strong Trustworthiness in Language Models",
    "authors": [
      "Martin Pawelczyk",
      "Lillian Sun",
      "Zhenting Qi",
      "Aounon Kumar",
      "Himabindu Lakkaraju"
    ],
    "abstract": "The rapid proliferation of generative AI, especially large language models,\nhas led to their integration into a variety of applications. A key phenomenon\nknown as weak-to-strong generalization - where a strong model trained on a weak\nmodel's outputs surpasses the weak model in task performance - has gained\nsignificant attention. Yet, whether critical trustworthiness properties such as\nrobustness, fairness, and privacy can generalize similarly remains an open\nquestion. In this work, we study this question by examining if a stronger model\ncan inherit trustworthiness properties when fine-tuned on a weaker model's\noutputs, a process we term weak-to-strong trustworthiness generalization. To\naddress this, we introduce two foundational training strategies: 1) Weak\nTrustworthiness Finetuning (Weak TFT), which leverages trustworthiness\nregularization during the fine-tuning of the weak model, and 2) Weak and\nWeak-to-Strong Trustworthiness Finetuning (Weak+WTS TFT), which extends\nregularization to both weak and strong models. Our experimental evaluation on\nreal-world datasets reveals that while some trustworthiness properties, such as\nfairness, adversarial, and OOD robustness, show significant improvement in\ntransfer when both models were regularized, others like privacy do not exhibit\nsigns of weak-to-strong trustworthiness. As the first study to explore\ntrustworthiness generalization via weak-to-strong generalization, our work\nprovides valuable insights into the potential and limitations of weak-to-strong\ngeneralization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The first two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2501.00418v1",
    "published_date": "2024-12-31 12:40:02 UTC",
    "updated_date": "2024-12-31 12:40:02 UTC"
  },
  {
    "arxiv_id": "2501.00398v2",
    "title": "TSPE: Task-Specific Prompt Ensemble for Improved Zero-Shot Audio Classification",
    "authors": [
      "Nishit Anand",
      "Ashish Seth",
      "Ramani Duraiswami",
      "Dinesh Manocha"
    ],
    "abstract": "Audio-language models (ALMs) excel in zero-shot audio classification, a task\nwhere models classify previously unseen audio clips at test time by leveraging\ndescriptive natural language prompts. We introduce TSPE (Task-Specific Prompt\nEnsemble), a simple, training-free hard prompting method that boosts ALEs'\nzero-shot performance by customizing prompts for diverse audio classification\ntasks. Rather than using generic template-based prompts like \"Sound of a car\"\nwe generate context-rich prompts, such as \"Sound of a car coming from a\ntunnel\". Specifically, we leverage label information to identify suitable sound\nattributes, such as \"loud\" and \"feeble\", and appropriate sound sources, such as\n\"tunnel\" and \"street\" and incorporate this information into the prompts used by\nAudio-Language Models (ALMs) for audio classification. Further, to enhance\naudio-text alignment, we perform prompt ensemble across TSPE-generated\ntask-specific prompts. When evaluated on 12 diverse audio classification\ndatasets, TSPE improves performance across ALMs by showing an absolute\nimprovement of 1.23-16.36% over vanilla zero-shot evaluation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to SALMA Workshop ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.00398v2",
    "published_date": "2024-12-31 11:27:17 UTC",
    "updated_date": "2025-04-03 01:09:23 UTC"
  },
  {
    "arxiv_id": "2501.00397v1",
    "title": "Efficient Relational Context Perception for Knowledge Graph Completion",
    "authors": [
      "Wenkai Tu",
      "Guojia Wan",
      "Zhengchun Shang",
      "Bo Du"
    ],
    "abstract": "Knowledge Graphs (KGs) provide a structured representation of knowledge but\noften suffer from challenges of incompleteness. To address this, link\nprediction or knowledge graph completion (KGC) aims to infer missing new facts\nbased on existing facts in KGs. Previous knowledge graph embedding models are\nlimited in their ability to capture expressive features, especially when\ncompared to deeper, multi-layer models. These approaches also assign a single\nstatic embedding to each entity and relation, disregarding the fact that\nentities and relations can exhibit different behaviors in varying graph\ncontexts. Due to complex context over a fact triple of a KG, existing methods\nhave to leverage complex non-linear context encoder, like transformer, to\nproject entity and relation into low dimensional representations, resulting in\nhigh computation cost. To overcome these limitations, we propose Triple\nReceptance Perception (TRP) architecture to model sequential information,\nenabling the learning of dynamic context of entities and relations. Then we use\ntensor decomposition to calculate triple scores, providing robust relational\ndecoding capabilities. This integration allows for more expressive\nrepresentations. Experiments on benchmark datasets such as YAGO3-10, UMLS,\nFB15k, and FB13 in link prediction and triple classification tasks demonstrate\nthat our method performs better than several state-of-the-art models, proving\nthe effectiveness of the integration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00397v1",
    "published_date": "2024-12-31 11:25:58 UTC",
    "updated_date": "2024-12-31 11:25:58 UTC"
  },
  {
    "arxiv_id": "2501.00383v2",
    "title": "Proactive Conversational Agents with Inner Thoughts",
    "authors": [
      "Xingyu Bruce Liu",
      "Shitao Fang",
      "Weiyan Shi",
      "Chien-Sheng Wu",
      "Takeo Igarashi",
      "Xiang Anthony Chen"
    ],
    "abstract": "One of the long-standing aspirations in conversational AI is to allow them to\nautonomously take initiatives in conversations, i.e., being proactive. This is\nespecially challenging for multi-party conversations. Prior NLP research\nfocused mainly on predicting the next speaker from contexts like preceding\nconversations. In this paper, we demonstrate the limitations of such methods\nand rethink what it means for AI to be proactive in multi-party, human-AI\nconversations. We propose that just like humans, rather than merely reacting to\nturn-taking cues, a proactive AI formulates its own inner thoughts during a\nconversation, and seeks the right moment to contribute. Through a formative\nstudy with 24 participants and inspiration from linguistics and cognitive\npsychology, we introduce the Inner Thoughts framework. Our framework equips AI\nwith a continuous, covert train of thoughts in parallel to the overt\ncommunication process, which enables it to proactively engage by modeling its\nintrinsic motivation to express these thoughts. We instantiated this framework\ninto two real-time systems: an AI playground web app and a chatbot. Through a\ntechnical evaluation and user studies with human participants, our framework\nsignificantly surpasses existing baselines on aspects like anthropomorphism,\ncoherence, intelligence, and turn-taking appropriateness.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00383v2",
    "published_date": "2024-12-31 10:41:56 UTC",
    "updated_date": "2025-02-18 08:53:06 UTC"
  },
  {
    "arxiv_id": "2501.00382v1",
    "title": "Adventures in Demand Analysis Using AI",
    "authors": [
      "Philipp Bach",
      "Victor Chernozhukov",
      "Sven Klaassen",
      "Martin Spindler",
      "Jan Teichert-Kluge",
      "Suhas Vijaykumar"
    ],
    "abstract": "This paper advances empirical demand analysis by integrating multimodal\nproduct representations derived from artificial intelligence (AI). Using a\ndetailed dataset of toy cars on \\textit{Amazon.com}, we combine text\ndescriptions, images, and tabular covariates to represent each product using\ntransformer-based embedding models. These embeddings capture nuanced\nattributes, such as quality, branding, and visual characteristics, that\ntraditional methods often struggle to summarize. Moreover, we fine-tune these\nembeddings for causal inference tasks. We show that the resulting embeddings\nsubstantially improve the predictive accuracy of sales ranks and prices and\nthat they lead to more credible causal estimates of price elasticity. Notably,\nwe uncover strong heterogeneity in price elasticity driven by these\nproduct-specific features. Our findings illustrate that AI-driven\nrepresentations can enrich and modernize empirical demand analysis. The\ninsights generated may also prove valuable for applied causal inference more\nbroadly.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "econ.GN",
    "comment": "42 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.00382v1",
    "published_date": "2024-12-31 10:33:10 UTC",
    "updated_date": "2024-12-31 10:33:10 UTC"
  },
  {
    "arxiv_id": "2501.00368v3",
    "title": "Design Optimizer for Soft Growing Robot Manipulators in Three-Dimensional Environments",
    "authors": [
      "Ahmet Astar",
      "Ozan Nurcan",
      "Erk Demirel",
      "Emir Ozen",
      "Ozan Kutlar",
      "Fabio Stroppa"
    ],
    "abstract": "Soft growing robots are novel devices that mimic plant-like growth for\nnavigation in cluttered or dangerous environments. Their ability to adapt to\nsurroundings, combined with advancements in actuation and manufacturing\ntechnologies, allows them to perform specialized manipulation tasks. This work\npresents an approach for design optimization of soft growing robots;\nspecifically, the three-dimensional extension of the optimizer designed for\nplanar manipulators. This tool is intended to be used by engineers and robot\nenthusiasts before manufacturing their robot: it suggests the optimal size of\nthe robot for solving a specific task. The design process models a\nmulti-objective optimization problem to refine a soft manipulator's kinematic\nchain. Thanks to the novel Rank Partitioning algorithm integrated into\nEvolutionary Computation (EC) algorithms, this method achieves high precision\nin reaching targets and is efficient in resource usage. Results show\nsignificantly high performance in solving three-dimensional tasks, whereas\ncomparative experiments indicate that the optimizer features robust output when\ntested with different EC algorithms, particularly genetic algorithms.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.RO",
    "comment": "17 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.00368v3",
    "published_date": "2024-12-31 09:44:18 UTC",
    "updated_date": "2025-01-23 07:04:34 UTC"
  },
  {
    "arxiv_id": "2501.00365v1",
    "title": "Low-Rank Adaptation for Foundation Models: A Comprehensive Review",
    "authors": [
      "Menglin Yang",
      "Jialin Chen",
      "Yifei Zhang",
      "Jiahong Liu",
      "Jiasheng Zhang",
      "Qiyao Ma",
      "Harshit Verma",
      "Qianru Zhang",
      "Min Zhou",
      "Irwin King",
      "Rex Ying"
    ],
    "abstract": "The rapid advancement of foundation modelslarge-scale neural networks trained\non diverse, extensive datasetshas revolutionized artificial intelligence,\nenabling unprecedented advancements across domains such as natural language\nprocessing, computer vision, and scientific discovery. However, the substantial\nparameter count of these models, often reaching billions or trillions, poses\nsignificant challenges in adapting them to specific downstream tasks. Low-Rank\nAdaptation (LoRA) has emerged as a highly promising approach for mitigating\nthese challenges, offering a parameter-efficient mechanism to fine-tune\nfoundation models with minimal computational overhead. This survey provides the\nfirst comprehensive review of LoRA techniques beyond large Language Models to\ngeneral foundation models, including recent techniques foundations, emerging\nfrontiers and applications of low-rank adaptation across multiple domains.\nFinally, this survey discusses key challenges and future research directions in\ntheoretical understanding, scalability, and robustness. This survey serves as a\nvaluable resource for researchers and practitioners working with efficient\nfoundation model adaptation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00365v1",
    "published_date": "2024-12-31 09:38:55 UTC",
    "updated_date": "2024-12-31 09:38:55 UTC"
  },
  {
    "arxiv_id": "2501.00364v3",
    "title": "FORM: Learning Expressive and Transferable First-Order Logic Reward Machines",
    "authors": [
      "Leo Ardon",
      "Daniel Furelos-Blanco",
      "Roko Parac",
      "Alessandra Russo"
    ],
    "abstract": "Reward machines (RMs) are an effective approach for addressing non-Markovian\nrewards in reinforcement learning (RL) through finite-state machines.\nTraditional RMs, which label edges with propositional logic formulae, inherit\nthe limited expressivity of propositional logic. This limitation hinders the\nlearnability and transferability of RMs since complex tasks will require\nnumerous states and edges. To overcome these challenges, we propose First-Order\nReward Machines ($\\texttt{FORM}$s), which use first-order logic to label edges,\nresulting in more compact and transferable RMs. We introduce a novel method for\n$\\textbf{learning}$ $\\texttt{FORM}$s and a multi-agent formulation for\n$\\textbf{exploiting}$ them and facilitate their transferability, where multiple\nagents collaboratively learn policies for a shared $\\texttt{FORM}$. Our\nexperimental results demonstrate the scalability of $\\texttt{FORM}$s with\nrespect to traditional RMs. Specifically, we show that $\\texttt{FORM}$s can be\neffectively learnt for tasks where traditional RM learning approaches fail. We\nalso show significant improvements in learning speed and task transferability\nthanks to the multi-agent learning framework and the abstraction provided by\nthe first-order language.",
    "categories": [
      "cs.AI",
      "cs.FL",
      "cs.LO",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "AAMAS'25",
    "pdf_url": "http://arxiv.org/pdf/2501.00364v3",
    "published_date": "2024-12-31 09:31:15 UTC",
    "updated_date": "2025-02-28 17:13:11 UTC"
  },
  {
    "arxiv_id": "2501.00363v2",
    "title": "SPDZCoder: Combining Expert Knowledge with LLMs for Generating Privacy-Computing Code",
    "authors": [
      "Xiaoning Dong",
      "Peilin Xin",
      "Jia Li",
      "Wei Xu"
    ],
    "abstract": "Privacy computing receives increasing attention but writing privacy computing\ncode remains challenging for developers due to limited library functions,\nnecessitating function implementation from scratch, and data-oblivious\nrequirement, contradicting intuitive thinking and usual practices of\nprogrammers. Automating the generation of privacy computing code with Large\nLanguage Models can streamline development effort and lower the barrier to\nusing privacy computing frameworks. However, existing LLMs still encounter\nchallenges in code translation for privacy-preserving computation, such as\ntranslating Python to MP-SPDZ, due to the scarcity of MP-SPDZ data required for\neffective pre-training or fine-tuning. Moreover, the lack of a benchmark\nfurther complicates the evaluation of translation quality. To address the\nlimitations, this work proposes SPDZCoder, a rule-based framework that combines\nLLMs with expert knowledge for generating privacy-computing code without\nrequiring additional training data. Specifically, SPDZCoder employ a rigorous\nprocedure for collecting high-quality expert knowledge to represent the\nsemantic-expressing differences between Python and MP-SPDZ, and to derive\ntransformation rules for translating Python to MP-SPDZ based on these\nknowledge. Then, SPDZCoder progressively converts Python code into MP-SPDZ code\nusing transformation rules in a three stage pipeline. To evaluate SPDZCoder, we\nmanually constructed a benchmark dataset, SPDZEval, which comprises six data\nsplits, each representing a distinct class of challenging tasks in MP-SPDZ\nimplementation. Extensive experiments show that SPDZCoder achieves superior\nperformance, significantly surpassing baselines in pass@1 and pass@2.\nSpecifically, SPDZCoder attains an overall correctness of 85.94% and 92.01% in\npass@1 and pass@2, respectively, whereas the best-performing baseline achieves\n63.58% and 76.36%, respectively.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00363v2",
    "published_date": "2024-12-31 09:29:38 UTC",
    "updated_date": "2025-03-21 12:52:57 UTC"
  },
  {
    "arxiv_id": "2501.00353v1",
    "title": "RAG-Instruct: Boosting LLMs with Diverse Retrieval-Augmented Instructions",
    "authors": [
      "Wanlong Liu",
      "Junying Chen",
      "Ke Ji",
      "Li Zhou",
      "Wenyu Chen",
      "Benyou Wang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a key paradigm for\nenhancing large language models (LLMs) by incorporating external knowledge.\nHowever, current RAG methods face two limitations: (1) they only cover limited\nRAG scenarios. (2) They suffer from limited task diversity due to the lack of a\ngeneral RAG dataset. To address these limitations, we propose RAG-Instruct, a\ngeneral method for synthesizing diverse and high-quality RAG instruction data\nbased on any source corpus. Our approach leverages (1) five RAG paradigms,\nwhich encompass diverse query-document relationships, and (2) instruction\nsimulation, which enhances instruction diversity and quality by utilizing the\nstrengths of existing instruction datasets. Using this method, we construct a\n40K instruction dataset from Wikipedia, comprehensively covering diverse RAG\nscenarios and tasks. Experiments demonstrate that RAG-Instruct effectively\nenhances LLMs' RAG capabilities, achieving strong zero-shot performance and\nsignificantly outperforming various RAG baselines across a diverse set of\ntasks. RAG-Instruct is publicly available at\nhttps://github.com/FreedomIntelligence/RAG-Instruct.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00353v1",
    "published_date": "2024-12-31 09:00:51 UTC",
    "updated_date": "2024-12-31 09:00:51 UTC"
  },
  {
    "arxiv_id": "2501.00348v1",
    "title": "Temporal Information Reconstruction and Non-Aligned Residual in Spiking Neural Networks for Speech Classification",
    "authors": [
      "Qi Zhang",
      "Huamin Wang",
      "Hangchi Shen",
      "Shukai Duan",
      "Shiping Wen",
      "Tingwen Huang"
    ],
    "abstract": "Recently, it can be noticed that most models based on spiking neural networks\n(SNNs) only use a same level temporal resolution to deal with speech\nclassification problems, which makes these models cannot learn the information\nof input data at different temporal scales. Additionally, owing to the\ndifferent time lengths of the data before and after the sub-modules of many\nmodels, the effective residual connections cannot be applied to optimize the\ntraining processes of these models.To solve these problems, on the one hand, we\nreconstruct the temporal dimension of the audio spectrum to propose a novel\nmethod named as Temporal Reconstruction (TR) by referring the hierarchical\nprocessing process of the human brain for understanding speech. Then, the\nreconstructed SNN model with TR can learn the information of input data at\ndifferent temporal scales and model more comprehensive semantic information\nfrom audio data because it enables the networks to learn the information of\ninput data at different temporal resolutions. On the other hand, we propose the\nNon-Aligned Residual (NAR) method by analyzing the audio data, which allows the\nresidual connection can be used in two audio data with different time lengths.\nWe have conducted plentiful experiments on the Spiking Speech Commands (SSC),\nthe Spiking Heidelberg Digits (SHD), and the Google Speech Commands v0.02 (GSC)\ndatasets. According to the experiment results, we have achieved the\nstate-of-the-art (SOTA) result 81.02\\% on SSC for the test classification\naccuracy of all SNN models, and we have obtained the SOTA result 96.04\\% on SHD\nfor the classification accuracy of all models.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.00348v1",
    "published_date": "2024-12-31 08:52:40 UTC",
    "updated_date": "2024-12-31 08:52:40 UTC"
  },
  {
    "arxiv_id": "2501.00346v1",
    "title": "CNC: Cross-modal Normality Constraint for Unsupervised Multi-class Anomaly Detection",
    "authors": [
      "Xiaolei Wang",
      "Xiaoyang Wang",
      "Huihui Bai",
      "Eng Gee Lim",
      "Jimin Xiao"
    ],
    "abstract": "Existing unsupervised distillation-based methods rely on the differences\nbetween encoded and decoded features to locate abnormal regions in test images.\nHowever, the decoder trained only on normal samples still reconstructs abnormal\npatch features well, degrading performance. This issue is particularly\npronounced in unsupervised multi-class anomaly detection tasks. We attribute\nthis behavior to over-generalization(OG) of decoder: the significantly\nincreasing diversity of patch patterns in multi-class training enhances the\nmodel generalization on normal patches, but also inadvertently broadens its\ngeneralization to abnormal patches. To mitigate OG, we propose a novel approach\nthat leverages class-agnostic learnable prompts to capture common textual\nnormality across various visual patterns, and then apply them to guide the\ndecoded features towards a normal textual representation, suppressing\nover-generalization of the decoder on abnormal patterns. To further improve\nperformance, we also introduce a gated mixture-of-experts module to specialize\nin handling diverse patch patterns and reduce mutual interference between them\nin multi-class training. Our method achieves competitive performance on the\nMVTec AD and VisA datasets, demonstrating its effectiveness.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.00346v1",
    "published_date": "2024-12-31 08:43:44 UTC",
    "updated_date": "2024-12-31 08:43:44 UTC"
  },
  {
    "arxiv_id": "2501.00343v1",
    "title": "Chunk-Distilled Language Modeling",
    "authors": [
      "Yanhong Li",
      "Karen Livescu",
      "Jiawei Zhou"
    ],
    "abstract": "We introduce Chunk-Distilled Language Modeling (CD-LM), an approach to text\ngeneration that addresses two challenges in current large language models\n(LLMs): the inefficiency of token-level generation, and the difficulty of\nadapting to new data and knowledge. Our method combines deep network-based LLMs\nwith a straightforward retrieval module, which allows the generation of\nmulti-token text chunks at a single decoding step. Our retrieval framework\nenables flexible construction of model- or domain-specific datastores, either\nleveraging the internal knowledge of existing models, or incorporating expert\ninsights from human-annotated corpora. This adaptability allows for enhanced\ncontrol over the language model's distribution without necessitating additional\ntraining. We present the CD-LM formulation along with performance metrics\ndemonstrating its ability to improve language model performance and efficiency\nacross a diverse set of downstream tasks. Code and data will be made publicly\navailable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00343v1",
    "published_date": "2024-12-31 08:32:15 UTC",
    "updated_date": "2024-12-31 08:32:15 UTC"
  },
  {
    "arxiv_id": "2501.00334v1",
    "title": "Loss-Aware Curriculum Learning for Chinese Grammatical Error Correction",
    "authors": [
      "Ding Zhang",
      "Yangning Li",
      "Lichen Bai",
      "Hao Zhang",
      "Yinghui Li",
      "Haiye Lin",
      "Hai-Tao Zheng",
      "Xin Su",
      "Zifei Shan"
    ],
    "abstract": "Chinese grammatical error correction (CGEC) aims to detect and correct errors\nin the input Chinese sentences. Recently, Pre-trained Language Models (PLMS)\nhave been employed to improve the performance. However, current approaches\nignore that correction difficulty varies across different instances and treat\nthese samples equally, enhancing the challenge of model learning. To address\nthis problem, we propose a multi-granularity Curriculum Learning (CL)\nframework. Specifically, we first calculate the correction difficulty of these\nsamples and feed them into the model from easy to hard batch by batch. Then\nInstance-Level CL is employed to help the model optimize in the appropriate\ndirection automatically by regulating the loss function. Extensive experimental\nresults and comprehensive analyses of various datasets prove the effectiveness\nof our method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.00334v1",
    "published_date": "2024-12-31 08:11:49 UTC",
    "updated_date": "2024-12-31 08:11:49 UTC"
  },
  {
    "arxiv_id": "2501.01991v2",
    "title": "A Hybrid Deep Learning and Model-Checking Framework for Accurate Brain Tumor Detection and Validation",
    "authors": [
      "Elhoucine Elfatimi",
      "Lahcen El Fatimi",
      "Hanifa Bouchaneb"
    ],
    "abstract": "Model checking, a formal verification technique, ensures systems meet\npredefined requirements, playing a crucial role in minimizing errors and\nenhancing quality during development. This paper introduces a novel hybrid\nframework integrating model checking with deep learning for brain tumor\ndetection and validation in medical imaging. By combining model-checking\nprinciples with CNN-based feature extraction and K-FCM clustering for\nsegmentation, the proposed approach enhances the reliability of tumor detection\nand segmentation. Experimental results highlight the framework's effectiveness,\nachieving 98\\% accuracy, 96.15\\% precision, and 100\\% recall, demonstrating its\npotential as a robust tool for advanced medical image analysis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.6; I.4.6"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.01991v2",
    "published_date": "2024-12-31 08:09:08 UTC",
    "updated_date": "2025-04-29 21:24:06 UTC"
  },
  {
    "arxiv_id": "2501.00330v1",
    "title": "Exploring the Implicit Semantic Ability of Multimodal Large Language Models: A Pilot Study on Entity Set Expansion",
    "authors": [
      "Hebin Wang",
      "Yangning Li",
      "Yinghui Li",
      "Hai-Tao Zheng",
      "Wenhao Jiang",
      "Hong-Gee Kim"
    ],
    "abstract": "The rapid development of multimodal large language models (MLLMs) has brought\nsignificant improvements to a wide range of tasks in real-world applications.\nHowever, LLMs still exhibit certain limitations in extracting implicit semantic\ninformation. In this paper, we apply MLLMs to the Multi-modal Entity Set\nExpansion (MESE) task, which aims to expand a handful of seed entities with new\nentities belonging to the same semantic class, and multi-modal information is\nprovided with each entity. We explore the capabilities of MLLMs to understand\nimplicit semantic information at the entity-level granularity through the MESE\ntask, introducing a listwise ranking method LUSAR that maps local scores to\nglobal rankings. Our LUSAR demonstrates significant improvements in MLLM's\nperformance on the MESE task, marking the first use of generative MLLM for ESE\ntasks and extending the applicability of listwise ranking.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.00330v1",
    "published_date": "2024-12-31 08:03:48 UTC",
    "updated_date": "2024-12-31 08:03:48 UTC"
  },
  {
    "arxiv_id": "2501.14775v1",
    "title": "Hybrid Firefly-Genetic Algorithm for Single and Multi-dimensional 0-1 Knapsack Problems",
    "authors": [
      "Aswathi Malanthara",
      "Ishaan R Kale"
    ],
    "abstract": "This paper addresses the challenges faced by algorithms, such as the Firefly\nAlgorithm (FA) and the Genetic Algorithm (GA), in constrained optimization\nproblems. While both algorithms perform well for unconstrained problems, their\neffectiveness diminishes when constraints are introduced due to limitations in\nexploration, exploitation, and constraint handling. To overcome these\nchallenges, a hybrid FAGA algorithm is proposed, combining the strengths of\nboth algorithms. The hybrid algorithm is validated by solving unconstrained\nbenchmark functions and constrained optimization problems, including design\nengineering problems and combinatorial problems such as the 0-1 Knapsack\nProblem. The proposed algorithm delivers improved solution accuracy and\ncomputational efficiency compared to conventional optimization algorithm. This\npaper outlines the development and structure of the hybrid algorithm and\ndemonstrates its effectiveness in handling complex optimization problems.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.14775v1",
    "published_date": "2024-12-31 08:03:15 UTC",
    "updated_date": "2024-12-31 08:03:15 UTC"
  },
  {
    "arxiv_id": "2501.01458v1",
    "title": "GAN-TAT: A Novel Framework Using Protein Interaction Networks in Druggable Gene Identification",
    "authors": [
      "George Yuanji Wang",
      "Srisharan Murugesan",
      "Aditya Prince Rohatgi"
    ],
    "abstract": "Identifying druggable genes is essential for developing effective\npharmaceuticals. With the availability of extensive, high-quality data,\ncomputational methods have become a significant asset. Protein Interaction\nNetwork (PIN) is valuable but challenging to implement due to its high\ndimensionality and sparsity. Previous methods relied on indirect integration,\nleading to resolution loss. This study proposes GAN-TAT, a framework utilizing\nan advanced graph embedding technology, ImGAGN, to directly integrate PIN for\ndruggable gene inference work. Tested on three Pharos datasets, GAN-TAT\nachieved the highest AUC-ROC score of 0.951 on Tclin. Further evaluation shows\nthat GAN-TAT's predictions are supported by clinical evidence, highlighting its\npotential practical applications in pharmacogenomics. This research represents\na methodological attempt with the direct utilization of PIN, expanding\npotential new solutions for developing drug targets. The source code of GAN-TAT\nis available at (https://github.com/george-yuanji-wang/GAN-TAT).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "4 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.01458v1",
    "published_date": "2024-12-31 07:37:34 UTC",
    "updated_date": "2024-12-31 07:37:34 UTC"
  },
  {
    "arxiv_id": "2501.00321v1",
    "title": "OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning",
    "authors": [
      "Ling Fu",
      "Biao Yang",
      "Zhebin Kuang",
      "Jiajun Song",
      "Yuzhe Li",
      "Linghao Zhu",
      "Qidi Luo",
      "Xinyu Wang",
      "Hao Lu",
      "Mingxin Huang",
      "Zhang Li",
      "Guozhi Tang",
      "Bin Shan",
      "Chunhui Lin",
      "Qi Liu",
      "Binghong Wu",
      "Hao Feng",
      "Hao Liu",
      "Can Huang",
      "Jingqun Tang",
      "Wei Chen",
      "Lianwen Jin",
      "Yuliang Liu",
      "Xiang Bai"
    ],
    "abstract": "Scoring the Optical Character Recognition (OCR) capabilities of Large\nMultimodal Models (LMMs) has witnessed growing interest recently. Existing\nbenchmarks have highlighted the impressive performance of LMMs in text\nrecognition; however, their abilities on certain challenging tasks, such as\ntext localization, handwritten content extraction, and logical reasoning,\nremain underexplored. To bridge this gap, we introduce OCRBench v2, a\nlarge-scale bilingual text-centric benchmark with currently the most\ncomprehensive set of tasks (4x more tasks than the previous multi-scene\nbenchmark OCRBench), the widest coverage of scenarios (31 diverse scenarios\nincluding street scene, receipt, formula, diagram, and so on), and thorough\nevaluation metrics, with a total of 10,000 human-verified question-answering\npairs and a high proportion of difficult samples. After carefully benchmarking\nstate-of-the-art LMMs on OCRBench v2, we find that 20 out of 22 LMMs score\nbelow 50 (100 in total) and suffer from five-type limitations, including less\nfrequently encountered text recognition, fine-grained perception, layout\nperception, complex element parsing, and logical reasoning. The benchmark and\nevaluation scripts are available at\nhttps://github.com/Yuliang-liu/MultimodalOCR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00321v1",
    "published_date": "2024-12-31 07:32:35 UTC",
    "updated_date": "2024-12-31 07:32:35 UTC"
  },
  {
    "arxiv_id": "2501.00320v2",
    "title": "Autonomous Alignment with Human Value on Altruism through Considerate Self-imagination and Theory of Mind",
    "authors": [
      "Haibo Tong",
      "Enmeng Lu",
      "Yinqian Sun",
      "Zhengqiang Han",
      "Chao Liu",
      "Feifei Zhao",
      "Yi Zeng"
    ],
    "abstract": "With the widespread application of Artificial Intelligence (AI) in human\nsociety, enabling AI to autonomously align with human values has become a\npressing issue to ensure its sustainable development and benefit to humanity.\nOne of the most important aspects of aligning with human values is the\nnecessity for agents to autonomously make altruistic, safe, and ethical\ndecisions, considering and caring for human well-being. Current AI extremely\npursues absolute superiority in certain tasks, remaining indifferent to the\nsurrounding environment and other agents, which has led to numerous safety\nrisks. Altruistic behavior in human society originates from humans' capacity\nfor empathizing others, known as Theory of Mind (ToM), combined with predictive\nimaginative interactions before taking action to produce thoughtful and\naltruistic behaviors. Inspired by this, we are committed to endow agents with\nconsiderate self-imagination and ToM capabilities, driving them through\nimplicit intrinsic motivations to autonomously align with human altruistic\nvalues. By integrating ToM within the imaginative space, agents keep an eye on\nthe well-being of other agents in real time, proactively anticipate potential\nrisks to themselves and others, and make thoughtful altruistic decisions that\nbalance negative effects on the environment. The ancient Chinese story of Sima\nGuang Smashes the Vat illustrates the moral behavior of the young Sima Guang\nsmashed a vat to save a child who had accidentally fallen into it, which is an\nexcellent reference scenario for this paper. We design an experimental scenario\nsimilar to Sima Guang Smashes the Vat and its variants with different\ncomplexities, which reflects the trade-offs and comprehensive considerations\nbetween self-goals, altruistic rescue, and avoiding negative side effects.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00320v2",
    "published_date": "2024-12-31 07:31:46 UTC",
    "updated_date": "2025-01-07 09:25:32 UTC"
  },
  {
    "arxiv_id": "2501.08585v1",
    "title": "A Systematic Review of Machine Learning Methods for Multimodal EEG Data in Clinical Application",
    "authors": [
      "Siqi Zhao",
      "Wangyang Li",
      "Xiru Wang",
      "Stevie Foglia",
      "Hongzhao Tan",
      "Bohan Zhang",
      "Ameer Hamoodi",
      "Aimee Nelson",
      "Zhen Gao"
    ],
    "abstract": "Machine learning (ML) and deep learning (DL) techniques have been widely\napplied to analyze electroencephalography (EEG) signals for disease diagnosis\nand brain-computer interfaces (BCI). The integration of multimodal data has\nbeen shown to enhance the accuracy of ML and DL models. Combining EEG with\nother modalities can improve clinical decision-making by addressing complex\ntasks in clinical populations. This systematic literature review explores the\nuse of multimodal EEG data in ML and DL models for clinical applications. A\ncomprehensive search was conducted across PubMed, Web of Science, and Google\nScholar, yielding 16 relevant studies after three rounds of filtering. These\nstudies demonstrate the application of multimodal EEG data in addressing\nclinical challenges, including neuropsychiatric disorders, neurological\nconditions (e.g., seizure detection), neurodevelopmental disorders (e.g.,\nautism spectrum disorder), and sleep stage classification. Data fusion occurred\nat three levels: signal, feature, and decision levels. The most commonly used\nML models were support vector machines (SVM) and decision trees. Notably, 11\nout of the 16 studies reported improvements in model accuracy with multimodal\nEEG data. This review highlights the potential of multimodal EEG-based ML\nmodels in enhancing clinical diagnostics and problem-solving.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "This paper includes 4 figures, 6 tables, and totals 18 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.08585v1",
    "published_date": "2024-12-31 07:20:56 UTC",
    "updated_date": "2024-12-31 07:20:56 UTC"
  },
  {
    "arxiv_id": "2501.00312v1",
    "title": "M2I2: Learning Efficient Multi-Agent Communication via Masked State Modeling and Intention Inference",
    "authors": [
      "Chuxiong Sun",
      "Peng He",
      "Qirui Ji",
      "Zehua Zang",
      "Jiangmeng Li",
      "Rui Wang",
      "Wei Wang"
    ],
    "abstract": "Communication is essential in coordinating the behaviors of multiple agents.\nHowever, existing methods primarily emphasize content, timing, and partners for\ninformation sharing, often neglecting the critical aspect of integrating shared\ninformation. This gap can significantly impact agents' ability to understand\nand respond to complex, uncertain interactions, thus affecting overall\ncommunication efficiency. To address this issue, we introduce M2I2, a novel\nframework designed to enhance the agents' capabilities to assimilate and\nutilize received information effectively. M2I2 equips agents with advanced\ncapabilities for masked state modeling and joint-action prediction, enriching\ntheir perception of environmental uncertainties and facilitating the\nanticipation of teammates' intentions. This approach ensures that agents are\nfurnished with both comprehensive and relevant information, bolstering more\ninformed and synergistic behaviors. Moreover, we propose a Dimensional Rational\nNetwork, innovatively trained via a meta-learning paradigm, to identify the\nimportance of dimensional pieces of information, evaluating their contributions\nto decision-making and auxiliary tasks. Then, we implement an importance-based\nheuristic for selective information masking and sharing. This strategy\noptimizes the efficiency of masked state modeling and the rationale behind\ninformation sharing. We evaluate M2I2 across diverse multi-agent tasks, the\nresults demonstrate its superior performance, efficiency, and generalization\ncapabilities, over existing state-of-the-art methods in various complex\nscenarios.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00312v1",
    "published_date": "2024-12-31 07:07:28 UTC",
    "updated_date": "2024-12-31 07:07:28 UTC"
  },
  {
    "arxiv_id": "2501.00307v1",
    "title": "Fast and Interpretable Mixed-Integer Linear Program Solving by Learning Model Reduction",
    "authors": [
      "Yixuan Li",
      "Can Chen",
      "Jiajun Li",
      "Jiahui Duan",
      "Xiongwei Han",
      "Tao Zhong",
      "Vincent Chau",
      "Weiwei Wu",
      "Wanyuan Wang"
    ],
    "abstract": "By exploiting the correlation between the structure and the solution of\nMixed-Integer Linear Programming (MILP), Machine Learning (ML) has become a\npromising method for solving large-scale MILP problems. Existing ML-based MILP\nsolvers mainly focus on end-to-end solution learning, which suffers from the\nscalability issue due to the high dimensionality of the solution space. Instead\nof directly learning the optimal solution, this paper aims to learn a reduced\nand equivalent model of the original MILP as an intermediate step. The reduced\nmodel often corresponds to interpretable operations and is much simpler,\nenabling us to solve large-scale MILP problems much faster than existing\ncommercial solvers. However, current approaches rely only on the optimal\nreduced model, overlooking the significant preference information of all\nreduced models. To address this issue, this paper proposes a preference-based\nmodel reduction learning method, which considers the relative performance\n(i.e., objective cost and constraint feasibility) of all reduced models on each\nMILP instance as preferences. We also introduce an attention mechanism to\ncapture and represent preference information, which helps improve the\nperformance of model reduction learning tasks. Moreover, we propose a SetCover\nbased pruning method to control the number of reduced models (i.e., labels),\nthereby simplifying the learning process. Evaluation on real-world MILP\nproblems shows that 1) compared to the state-of-the-art model reduction ML\nmethods, our method obtains nearly 20% improvement on solution accuracy, and 2)\ncompared to the commercial solver Gurobi, two to four orders of magnitude\nspeedups are achieved.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00307v1",
    "published_date": "2024-12-31 06:50:42 UTC",
    "updated_date": "2024-12-31 06:50:42 UTC"
  },
  {
    "arxiv_id": "2501.00298v1",
    "title": "Enhancing Deployment-Time Predictive Model Robustness for Code Analysis and Optimization",
    "authors": [
      "Huanting Wang",
      "Patrick Lenihan",
      "Zheng Wang"
    ],
    "abstract": "Supervised machine learning techniques have shown promising results in code\nanalysis and optimization problems. However, a learning-based solution can be\nbrittle because minor changes in hardware or application workloads -- such as\nfacing a new CPU architecture or code pattern -- may jeopardize decision\naccuracy, ultimately undermining model robustness. We introduce Prom, an\nopen-source library to enhance the robustness and performance of predictive\nmodels against such changes during deployment. Prom achieves this by using\nstatistical assessments to identify test samples prone to mispredictions and\nusing feedback on these samples to improve a deployed model. We showcase Prom\nby applying it to 13 representative machine learning models across 5 code\nanalysis and optimization tasks. Our extensive evaluation demonstrates that\nProm can successfully identify an average of 96% (up to 100%) of\nmispredictions. By relabeling up to 5% of the Prom-identified samples through\nincremental learning, Prom can help a deployed model achieve a performance\ncomparable to that attained during its model training phase.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00298v1",
    "published_date": "2024-12-31 06:17:03 UTC",
    "updated_date": "2024-12-31 06:17:03 UTC"
  },
  {
    "arxiv_id": "2501.00296v1",
    "title": "Predicate Invention from Pixels via Pretrained Vision-Language Models",
    "authors": [
      "Ashay Athalye",
      "Nishanth Kumar",
      "Tom Silver",
      "Yichao Liang",
      "Tomás Lozano-Pérez",
      "Leslie Pack Kaelbling"
    ],
    "abstract": "Our aim is to learn to solve long-horizon decision-making problems in\nhighly-variable, combinatorially-complex robotics domains given raw sensor\ninput in the form of images. Previous work has shown that one way to achieve\nthis aim is to learn a structured abstract transition model in the form of\nsymbolic predicates and operators, and then plan within this model to solve\nnovel tasks at test time. However, these learned models do not ground directly\ninto pixels from just a handful of demonstrations. In this work, we propose to\ninvent predicates that operate directly over input images by leveraging the\ncapabilities of pretrained vision-language models (VLMs). Our key idea is that,\ngiven a set of demonstrations, a VLM can be used to propose a set of predicates\nthat are potentially relevant for decision-making and then to determine the\ntruth values of these predicates in both the given demonstrations and new image\ninputs. We build upon an existing framework for predicate invention, which\ngenerates feature-based predicates operating on object-centric states, to also\ngenerate visual predicates that operate on images. Experimentally, we show that\nour approach -- pix2pred -- is able to invent semantically meaningful\npredicates that enable generalization to novel, complex, and long-horizon tasks\nacross two simulated robotic environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Workshop on Planning in the Era of LLMs (LM4Plan @ AAAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.00296v1",
    "published_date": "2024-12-31 06:14:16 UTC",
    "updated_date": "2024-12-31 06:14:16 UTC"
  },
  {
    "arxiv_id": "2501.00289v2",
    "title": "Dual Diffusion for Unified Image Generation and Understanding",
    "authors": [
      "Zijie Li",
      "Henry Li",
      "Yichun Shi",
      "Amir Barati Farimani",
      "Yuval Kluger",
      "Linjie Yang",
      "Peng Wang"
    ],
    "abstract": "Diffusion models have gained tremendous success in text-to-image generation,\nyet still lag behind with visual understanding tasks, an area dominated by\nautoregressive vision-language models. We propose a large-scale and fully\nend-to-end diffusion model for multi-modal understanding and generation that\nsignificantly improves on existing diffusion-based multimodal models, and is\nthe first of its kind to support the full suite of vision-language modeling\ncapabilities. Inspired by the multimodal diffusion transformer (MM-DiT) and\nrecent advances in discrete diffusion language modeling, we leverage a\ncross-modal maximum likelihood estimation framework that simultaneously trains\nthe conditional likelihoods of both images and text jointly under a single loss\nfunction, which is back-propagated through both branches of the diffusion\ntransformer. The resulting model is highly flexible and capable of a wide range\nof tasks including image generation, captioning, and visual question answering.\nOur model attained competitive performance compared to recent unified image\nunderstanding and generation models, demonstrating the potential of multimodal\ndiffusion modeling as a promising alternative to autoregressive next-token\nprediction models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00289v2",
    "published_date": "2024-12-31 05:49:00 UTC",
    "updated_date": "2025-04-01 19:09:34 UTC"
  },
  {
    "arxiv_id": "2501.00277v1",
    "title": "Efficient Human-in-the-Loop Active Learning: A Novel Framework for Data Labeling in AI Systems",
    "authors": [
      "Yiran Huang",
      "Jian-Feng Yang",
      "Haoda Fu"
    ],
    "abstract": "Modern AI algorithms require labeled data. In real world, majority of data\nare unlabeled. Labeling the data are costly. this is particularly true for some\nareas requiring special skills, such as reading radiology images by physicians.\nTo most efficiently use expert's time for the data labeling, one promising\napproach is human-in-the-loop active learning algorithm. In this work, we\npropose a novel active learning framework with significant potential for\napplication in modern AI systems. Unlike the traditional active learning\nmethods, which only focus on determining which data point should be labeled,\nour framework also introduces an innovative perspective on incorporating\ndifferent query scheme. We propose a model to integrate the information from\ndifferent types of queries. Based on this model, our active learning frame can\nautomatically determine how the next question is queried. We further developed\na data driven exploration and exploitation framework into our active learning\nmethod. This method can be embedded in numerous active learning algorithms.\nThrough simulations on five real-world datasets, including a highly complex\nreal image task, our proposed active learning framework exhibits higher\naccuracy and lower loss compared to other methods.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00277v1",
    "published_date": "2024-12-31 05:12:51 UTC",
    "updated_date": "2024-12-31 05:12:51 UTC"
  },
  {
    "arxiv_id": "2501.01457v1",
    "title": "Reinforcing Thinking through Reasoning-Enhanced Reward Models",
    "authors": [
      "Diji Yang",
      "Linda Zeng",
      "Kezhen Chen",
      "Yi Zhang"
    ],
    "abstract": "Large Language Models (LLMs) exhibit great potential in complex multi-step\nreasoning through inference-time thinking but still struggle with deciding when\nto stop thinking due to limited self-awareness about their knowledge\nboundaries. While human preference alignment has shown extraordinary\nopportunities, expensive labeling challenges adherence to scaling law. Language\nmodel self-critique, as an alternative to using human-labeled reasoning data,\nis questioned with its inherited biases. This work addresses these challenges\nby distilling the LLM's own reasoning processes into synthetic behavioral data,\neliminating the need for manual labeling of intermediate steps. Building on\nthis concept, we propose Distillation-Reinforcement-Reasoning (DRR), a\nthree-step framework that leverages the LLM's inherent behaviors as external\nfeedback by first generating behavioral data using the Reasoner (LLM) to\nreflect its reasoning capabilities, then training a lightweight discriminative\nreward model (DM) on behavioral data, and finally deploying the DM at inference\ntime to assist the Reasoner's decision-making. Experiments on multiple\nbenchmarks show that the DRR framework outperforms self-critique approaches\nwithout relying on additional complex data annotation. Benefiting from\nlightweight design, ease of replication, and adaptability, DRR is applicable to\na wide range of LLM-centric tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01457v1",
    "published_date": "2024-12-31 04:50:15 UTC",
    "updated_date": "2024-12-31 04:50:15 UTC"
  },
  {
    "arxiv_id": "2501.00264v1",
    "title": "Enhancing Wireless Sensor Network Security through Integration with the ServiceNow Cloud Platform",
    "authors": [
      "Syed Atif Ali",
      "Salwa Din"
    ],
    "abstract": "Wireless Sensor Networks (WSNs) continue to experience rapid developments and\nintegration into modern-day applications. Overall, WSNs collect and process\nrelevant data through sensors or nodes and communicate with different networks\nfor superior information management. Nevertheless, a primary concern relative\nto WSNs is security. Considering the high constraints on throughput, battery,\nprocessing power, and memory, typical security procedures present limitations\nfor application in WSNs. This research focuses on the integration of WSNs with\nthe cloud platform, specifically to address these security risks. The cloud\nplatform also adopts a security-driven approach and has attracted many\napplications across various sectors globally. This research specifically\nexplores how cloud computing could be exploited to impede Denial of Service\nattacks from endangering WSNs. WSNs are now deployed in various low-powered\napplications, including disaster management, homeland security, battlefield\nsurveillance, agriculture, and the healthcare industry. WSNs are distinguished\nfrom traditional networks by the numerous wireless connected sensors being\ndeployed to conduct an assigned task. In testing scenarios, the size of WSNs\nranges from a few to several thousand. The overarching requirements of WSNs\ninclude rapid processing of collected data, low-cost installation and\nmaintenance, and low latency in network operations. Given that a substantial\namount of WSN applications are used in high-risk and volatile environments,\nthey must effectively address security concerns. This includes the secure\nmovement, storage, and communication of data through networks, an environment\nin which WSNs are notably vulnerable. The limitations of WSNs have meant that\nthey are predominantly used in unsecured applications despite positive\nadvancements. This study explores methods for integrating the WSN with the\ncloud.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "68M18"
    ],
    "primary_category": "cs.CR",
    "comment": "17 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.00264v1",
    "published_date": "2024-12-31 04:17:17 UTC",
    "updated_date": "2024-12-31 04:17:17 UTC"
  },
  {
    "arxiv_id": "2501.00261v1",
    "title": "Collaborative Approaches to Enhancing Smart Vehicle Cybersecurity by AI-Driven Threat Detection",
    "authors": [
      "Syed Atif Ali",
      "Salwa Din"
    ],
    "abstract": "The introduction sets the stage for exploring collaborative approaches to\nbolstering smart vehicle cybersecurity through AI-driven threat detection. As\nthe automotive industry increasingly adopts connected and automated vehicles\n(CAVs), the need for robust cybersecurity measures becomes paramount. With the\nemergence of new vulnerabilities and security requirements, the integration of\nadvanced technologies such as 5G networks, blockchain, and quantum computing\npresents promising avenues for enhancing CAV cybersecurity . Additionally, the\nroadmap for cybersecurity in autonomous vehicles emphasizes the importance of\nefficient intrusion detection systems and AI-based techniques, along with the\nintegration of secure hardware, software stacks, and advanced threat\nintelligence to address cybersecurity challenges in future autonomous vehicles.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "C.2.1 Network Architecture and Design"
    ],
    "primary_category": "cs.CR",
    "comment": "7 Pages",
    "pdf_url": "http://arxiv.org/pdf/2501.00261v1",
    "published_date": "2024-12-31 04:08:42 UTC",
    "updated_date": "2024-12-31 04:08:42 UTC"
  },
  {
    "arxiv_id": "2501.00254v1",
    "title": "Automatically Planning Optimal Parallel Strategy for Large Language Models",
    "authors": [
      "Zongbiao Li",
      "Xiezhao Li",
      "Yinghao Cui",
      "Yijun Chen",
      "Zhixuan Gu",
      "Yuxuan Liu",
      "Wenbo Zhu",
      "Fei Jia",
      "Ke Liu",
      "Qifeng Li",
      "Junyao Zhan",
      "Jiangtao Zhou",
      "Chenxi Zhang",
      "Qike Liu"
    ],
    "abstract": "The number of parameters in large-scale language models based on transformers\nis gradually increasing, and the scale of computing clusters is also growing.\nThe technology of quickly mobilizing large amounts of computing resources for\nparallel computing is becoming increasingly important. In this paper, we\npropose an automatic parallel algorithm that automatically plans the parallel\nstrategy with maximum throughput based on model and hardware information. By\ndecoupling the training time into computation, communication, and overlap, we\nestablished a training duration simulation model. Based on this simulation\nmodel, we prune the parallel solution space to shorten the search time\nrequired. The multi-node experiment results show that the algorithm can\nestimate the parallel training duration in real time with an average accuracy\nof 96%. In our test, the recommendation strategy provided by the algorithm is\nalways globally optimal.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00254v1",
    "published_date": "2024-12-31 03:51:14 UTC",
    "updated_date": "2024-12-31 03:51:14 UTC"
  },
  {
    "arxiv_id": "2501.00241v1",
    "title": "Exploring Variability in Fine-Tuned Models for Text Classification with DistilBERT",
    "authors": [
      "Giuliano Lorenzoni",
      "Ivens Portugal",
      "Paulo Alencar",
      "Donald Cowan"
    ],
    "abstract": "This study evaluates fine-tuning strategies for text classification using the\nDistilBERT model, specifically the\ndistilbert-base-uncased-finetuned-sst-2-english variant. Through structured\nexperiments, we examine the influence of hyperparameters such as learning rate,\nbatch size, and epochs on accuracy, F1-score, and loss. Polynomial regression\nanalyses capture foundational and incremental impacts of these hyperparameters,\nfocusing on fine-tuning adjustments relative to a baseline model.\n  Results reveal variability in metrics due to hyperparameter configurations,\nshowing trade-offs among performance metrics. For example, a higher learning\nrate reduces loss in relative analysis (p=0.027) but challenges accuracy\nimprovements. Meanwhile, batch size significantly impacts accuracy and F1-score\nin absolute regression (p=0.028 and p=0.005) but has limited influence on loss\noptimization (p=0.170). The interaction between epochs and batch size maximizes\nF1-score (p=0.001), underscoring the importance of hyperparameter interplay.\n  These findings highlight the need for fine-tuning strategies addressing\nnon-linear hyperparameter interactions to balance performance across metrics.\nSuch variability and metric trade-offs are relevant for tasks beyond text\nclassification, including NLP and computer vision. This analysis informs\nfine-tuning strategies for large language models and promotes adaptive designs\nfor broader model applicability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00241v1",
    "published_date": "2024-12-31 03:16:15 UTC",
    "updated_date": "2024-12-31 03:16:15 UTC"
  },
  {
    "arxiv_id": "2501.01989v1",
    "title": "CRRG-CLIP: Automatic Generation of Chest Radiology Reports and Classification of Chest Radiographs",
    "authors": [
      "Jianfei Xu",
      "Thanet Markchom",
      "Huizhi Liang"
    ],
    "abstract": "The complexity of stacked imaging and the massive number of radiographs make\nwriting radiology reports complex and inefficient. Even highly experienced\nradiologists struggle to maintain accuracy and consistency in interpreting\nradiographs under prolonged high-intensity work. To address these issues, this\nwork proposes the CRRG-CLIP Model (Chest Radiology Report Generation and\nRadiograph Classification Model), an end-to-end model for automated report\ngeneration and radiograph classification. The model consists of two modules:\nthe radiology report generation module and the radiograph classification\nmodule. The generation module uses Faster R-CNN to identify anatomical regions\nin radiographs, a binary classifier to select key regions, and GPT-2 to\ngenerate semantically coherent reports. The classification module uses the\nunsupervised Contrastive Language Image Pretraining (CLIP) model, addressing\nthe challenges of high-cost labelled datasets and insufficient features. The\nresults show that the generation module performs comparably to high-performance\nbaseline models on BLEU, METEOR, and ROUGE-L metrics, and outperformed the\nGPT-4o model on BLEU-2, BLEU-3, BLEU-4, and ROUGE-L metrics. The classification\nmodule significantly surpasses the state-of-the-art model in AUC and Accuracy.\nThis demonstrates that the proposed model achieves high accuracy, readability,\nand fluency in report generation, while multimodal contrastive training with\nunlabelled radiograph-report pairs enhances classification performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01989v1",
    "published_date": "2024-12-31 03:07:27 UTC",
    "updated_date": "2024-12-31 03:07:27 UTC"
  },
  {
    "arxiv_id": "2501.00230v2",
    "title": "Federated Deep Subspace Clustering",
    "authors": [
      "Yupei Zhang",
      "Ruojia Feng",
      "Yifei Wang",
      "Xuequn Shang"
    ],
    "abstract": "This paper introduces FDSC, a private-protected subspace clustering (SC)\napproach with federated learning (FC) schema. In each client, there is a deep\nsubspace clustering network accounting for grouping the isolated data, composed\nof a encode network, a self-expressive layer, and a decode network. FDSC is\nachieved by uploading the encode network to communicate with other clients in\nthe server. Besides, FDSC is also enhanced by preserving the local neighborhood\nrelationship in each client. With the effects of federated learning and\nlocality preservation, the learned data features from the encoder are boosted\nso as to enhance the self-expressiveness learning and result in better\nclustering performance. Experiments test FDSC on public datasets and compare\nwith other clustering methods, demonstrating the effectiveness of FDSC.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "68T07",
      "I.5.3"
    ],
    "primary_category": "cs.LG",
    "comment": "8pages,4 figures, 4 Tables",
    "pdf_url": "http://arxiv.org/pdf/2501.00230v2",
    "published_date": "2024-12-31 02:46:29 UTC",
    "updated_date": "2025-01-16 02:28:47 UTC"
  },
  {
    "arxiv_id": "2501.01454v3",
    "title": "A Fourfold Pathogen Reference Ontology Suite",
    "authors": [
      "Shane Babcock",
      "Carter Benson",
      "Giacomo De Colle",
      "Sydney Cohen",
      "Alexander D. Diehl",
      "Ram A. N. R. Challa",
      "Ray Mavrovich",
      "Joshua Billig",
      "Anthony Huffman",
      "Yongqun He",
      "John Beverley"
    ],
    "abstract": "Infectious diseases remain a critical global health challenge, and the\nintegration of standardized ontologies plays a vital role in managing related\ndata. The Infectious Disease Ontology (IDO) and its extensions, such as the\nCoronavirus Infectious Disease Ontology (CIDO), are essential for organizing\nand disseminating information related to infectious diseases. The COVID-19\npandemic highlighted the need for updating IDO and its virus-specific\nextensions. There is an additional need to update IDO extensions specific to\nbacteria, fungus, and parasite infectious diseases. We adopt the \"hub and\nspoke\" methodology to generate pathogen-specific extensions of IDO: Virus\nInfectious Disease Ontology (VIDO), Bacteria Infectious Disease Ontology\n(BIDO), Mycosis Infectious Disease Ontology (MIDO), and Parasite Infectious\nDisease Ontology (PIDO). The creation of pathogen-specific reference ontologies\nadvances modularization and reusability of infectious disease data within the\nIDO ecosystem. Future work will focus on further refining these ontologies,\ncreating new extensions, and developing application ontologies based on them,\nin line with ongoing efforts to standardize biological and biomedical\nterminologies for improved data sharing and analysis.",
    "categories": [
      "q-bio.OT",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "q-bio.OT",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.01454v3",
    "published_date": "2024-12-31 02:34:49 UTC",
    "updated_date": "2025-04-24 20:50:04 UTC"
  },
  {
    "arxiv_id": "2501.00226v1",
    "title": "Generative Emergent Communication: Large Language Model is a Collective World Model",
    "authors": [
      "Tadahiro Taniguchi",
      "Ryo Ueda",
      "Tomoaki Nakamura",
      "Masahiro Suzuki",
      "Akira Taniguchi"
    ],
    "abstract": "This study proposes a unifying theoretical framework called generative\nemergent communication (generative EmCom) that bridges emergent communication,\nworld models, and large language models (LLMs) through the lens of collective\npredictive coding (CPC). The proposed framework formalizes the emergence of\nlanguage and symbol systems through decentralized Bayesian inference across\nmultiple agents, extending beyond conventional discriminative model-based\napproaches to emergent communication. This study makes the following two key\ncontributions: First, we propose generative EmCom as a novel framework for\nunderstanding emergent communication, demonstrating how communication emergence\nin multi-agent reinforcement learning (MARL) can be derived from control as\ninference while clarifying its relationship to conventional discriminative\napproaches. Second, we propose a mathematical formulation showing the\ninterpretation of LLMs as collective world models that integrate multiple\nagents' experiences through CPC. The framework provides a unified theoretical\nfoundation for understanding how shared symbol systems emerge through\ncollective predictive coding processes, bridging individual cognitive\ndevelopment and societal language evolution. Through mathematical formulations\nand discussion on prior works, we demonstrate how this framework explains\nfundamental aspects of language emergence and offers practical insights for\nunderstanding LLMs and developing sophisticated AI systems for improving\nhuman-AI interaction and multi-agent systems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00226v1",
    "published_date": "2024-12-31 02:23:10 UTC",
    "updated_date": "2024-12-31 02:23:10 UTC"
  },
  {
    "arxiv_id": "2501.00224v1",
    "title": "Extracting effective solutions hidden in large language models via generated comprehensive specialists: case studies in developing electronic devices",
    "authors": [
      "Hikari Tomita",
      "Nobuhiro Nakamura",
      "Shoichi Ishida",
      "Toshio Kamiya",
      "Kei Terayama"
    ],
    "abstract": "Recently, many studies have increasingly explored the use of large language\nmodels (LLMs) to generate research ideas and scientific hypotheses. However,\nreal-world research and development often require solving complex,\ninterdisciplinary challenges where solutions may not be readily found through\nexisting knowledge related to the problem. Therefore, it is desirable to\nleverage the vast, comprehensive knowledge of LLMs to generate effective,\nbreakthrough solutions by integrating various perspectives from other\ndisciplines. Here, we propose SELLM (Solution Enumeration via comprehensive\nList and LLM), a framework leveraging LLMs and structured guidance using MECE\n(Mutually Exclusive, Collectively Exhaustive) principles, such as International\nPatent Classification (IPC) and the periodic table of elements. SELLM\nsystematically constructs comprehensive expert agents from the list to generate\ncross-disciplinary and effective solutions. To evaluate SELLM's practicality,\nwe applied it to two challenges: improving light extraction in organic\nlight-emitting diode (OLED) lighting and developing electrodes for\nnext-generation memory materials. The results demonstrate that SELLM\nsignificantly facilitates the generation of effective solutions compared to\ncases without specific customization or effort, showcasing the potential of\nSELLM to enable LLMs to generate effective solutions even for challenging\nproblems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.00224v1",
    "published_date": "2024-12-31 02:20:56 UTC",
    "updated_date": "2024-12-31 02:20:56 UTC"
  },
  {
    "arxiv_id": "2501.00223v1",
    "title": "CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care",
    "authors": [
      "Michael Gubanov",
      "Anna Pyayt",
      "Aleksandra Karolak"
    ],
    "abstract": "Here, we describe one of the first Web-scale hybrid Knowledge Graph\n(KG)-Large Language Model (LLM), populated with the latest peer-reviewed\nmedical knowledge on colorectal Cancer. It is currently being evaluated to\nassist with both medical research and clinical information retrieval tasks at\nMoffitt Cancer Center, which is one of the top Cancer centers in the U.S. and\nin the world. Our hybrid is remarkable as it serves the user needs better than\njust an LLM, KG or a search-engine in isolation. LLMs as is are known to\nexhibit hallucinations and catastrophic forgetting as well as are trained on\noutdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal,\nChEMBL, NCBI, and other require manual curation, hence are quickly getting\nstale. CancerKG is unsupervised and is capable of automatically ingesting and\norganizing the latest medical findings. To alleviate the LLMs shortcomings, the\nverified KG serves as a Retrieval Augmented Generation (RAG) guardrail.\nCancerKG exhibits 5 different advanced user interfaces, each tailored to serve\ndifferent data modalities better and more convenient for the user.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "68T09"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00223v1",
    "published_date": "2024-12-31 02:19:16 UTC",
    "updated_date": "2024-12-31 02:19:16 UTC"
  },
  {
    "arxiv_id": "2501.00217v1",
    "title": "The Potential of LLMs in Automating Software Testing: From Generation to Reporting",
    "authors": [
      "Betim Sherifi",
      "Khaled Slhoub",
      "Fitzroy Nembhard"
    ],
    "abstract": "Having a high quality software is essential in software engineering, which\nrequires robust validation and verification processes during testing\nactivities. Manual testing, while effective, can be time consuming and costly,\nleading to an increased demand for automated methods. Recent advancements in\nLarge Language Models (LLMs) have significantly influenced software\nengineering, particularly in areas like requirements analysis, test automation,\nand debugging. This paper explores an agent-oriented approach to automated\nsoftware testing, using LLMs to reduce human intervention and enhance testing\nefficiency. The proposed framework integrates LLMs to generate unit tests,\nvisualize call graphs, and automate test execution and reporting. Evaluations\nacross multiple applications in Python and Java demonstrate the system's high\ntest coverage and efficient operation. This research underscores the potential\nof LLM-powered agents to streamline software testing workflows while addressing\nchallenges in scalability and accuracy.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "6 pages, 3 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2501.00217v1",
    "published_date": "2024-12-31 02:06:46 UTC",
    "updated_date": "2024-12-31 02:06:46 UTC"
  },
  {
    "arxiv_id": "2501.00210v2",
    "title": "Debunking the CUDA Myth Towards GPU-based AI Systems",
    "authors": [
      "Yunjae Lee",
      "Juntaek Lim",
      "Jehyeon Bang",
      "Eunyeong Cho",
      "Huijong Jeong",
      "Taesu Kim",
      "Hyungjun Kim",
      "Joonhyung Lee",
      "Jinseop Im",
      "Ranggi Hwang",
      "Se Jung Kwon",
      "Dongsoo Lee",
      "Minsoo Rhu"
    ],
    "abstract": "This paper presents a comprehensive evaluation of Intel Gaudi NPUs as an\nalternative to NVIDIA GPUs, which is currently the de facto standard in AI\nsystem design. First, we create a suite of microbenchmarks to compare Intel\nGaudi-2 with NVIDIA A100, showing that Gaudi-2 achieves competitive performance\nnot only in primitive AI compute, memory, and communication operations but also\nin executing several important AI workloads end-to-end. We then assess Gaudi\nNPU's programmability by discussing several software-level optimization\nstrategies to employ for implementing critical FBGEMM operators and vLLM,\nevaluating their efficiency against GPU-optimized counterparts. Results\nindicate that Gaudi-2 achieves energy efficiency comparable to A100, though\nthere are notable areas for improvement in terms of software maturity. Overall,\nwe conclude that, with effective integration into high-level AI frameworks,\nGaudi NPUs could challenge NVIDIA GPU's dominance in the AI server market,\nthough further improvements are necessary to fully compete with NVIDIA's robust\nsoftware ecosystem.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted for publication at the 52nd IEEE/ACM International Symposium\n  on Computer Architecture (ISCA-52), 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.00210v2",
    "published_date": "2024-12-31 01:24:52 UTC",
    "updated_date": "2025-03-22 02:32:17 UTC"
  },
  {
    "arxiv_id": "2501.00208v1",
    "title": "An Empirical Evaluation of Large Language Models on Consumer Health Questions",
    "authors": [
      "Moaiz Abrar",
      "Yusuf Sermet",
      "Ibrahim Demir"
    ],
    "abstract": "This study evaluates the performance of several Large Language Models (LLMs)\non MedRedQA, a dataset of consumer-based medical questions and answers by\nverified experts extracted from the AskDocs subreddit. While LLMs have shown\nproficiency in clinical question answering (QA) benchmarks, their effectiveness\non real-world, consumer-based, medical questions remains less understood.\nMedRedQA presents unique challenges, such as informal language and the need for\nprecise responses suited to non-specialist queries. To assess model\nperformance, responses were generated using five LLMs: GPT-4o mini, Llama 3.1:\n70B, Mistral-123B, Mistral-7B, and Gemini-Flash. A cross-evaluation method was\nused, where each model evaluated its responses as well as those of others to\nminimize bias. The results indicated that GPT-4o mini achieved the highest\nalignment with expert responses according to four out of the five models'\njudges, while Mistral-7B scored lowest according to three out of five models'\njudges. This study highlights the potential and limitations of current LLMs for\nconsumer health medical question answering, indicating avenues for further\ndevelopment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00208v1",
    "published_date": "2024-12-31 01:08:15 UTC",
    "updated_date": "2024-12-31 01:08:15 UTC"
  },
  {
    "arxiv_id": "2501.00199v1",
    "title": "GPT-4 on Clinic Depression Assessment: An LLM-Based Pilot Study",
    "authors": [
      "Giuliano Lorenzoni",
      "Pedro Elkind Velmovitsky",
      "Paulo Alencar",
      "Donald Cowan"
    ],
    "abstract": "Depression has impacted millions of people worldwide and has become one of\nthe most prevalent mental disorders. Early mental disorder detection can lead\nto cost savings for public health agencies and avoid the onset of other major\ncomorbidities. Additionally, the shortage of specialized personnel is a\ncritical issue because clinical depression diagnosis is highly dependent on\nexpert professionals and is time consuming.\n  In this study, we explore the use of GPT-4 for clinical depression assessment\nbased on transcript analysis. We examine the model's ability to classify\npatient interviews into binary categories: depressed and not depressed. A\ncomparative analysis is conducted considering prompt complexity (e.g., using\nboth simple and complex prompts) as well as varied temperature settings to\nassess the impact of prompt complexity and randomness on the model's\nperformance.\n  Results indicate that GPT-4 exhibits considerable variability in accuracy and\nF1-Score across configurations, with optimal performance observed at lower\ntemperature values (0.0-0.2) for complex prompts. However, beyond a certain\nthreshold (temperature >= 0.3), the relationship between randomness and\nperformance becomes unpredictable, diminishing the gains from prompt\ncomplexity.\n  These findings suggest that, while GPT-4 shows promise for clinical\nassessment, the configuration of the prompts and model parameters requires\ncareful calibration to ensure consistent results. This preliminary study\ncontributes to understanding the dynamics between prompt engineering and large\nlanguage models, offering insights for future development of AI-powered tools\nin clinical settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00199v1",
    "published_date": "2024-12-31 00:32:43 UTC",
    "updated_date": "2024-12-31 00:32:43 UTC"
  },
  {
    "arxiv_id": "2501.03254v1",
    "title": "Advanced Displacement Magnitude Prediction in Multi-Material Architected Lattice Structure Beams Using Physics Informed Neural Network Architecture",
    "authors": [
      "Akshansh Mishra"
    ],
    "abstract": "This paper proposes an innovative method for predicting deformation in\narchitected lattice structures that combines Physics-Informed Neural Networks\n(PINNs) with finite element analysis. A thorough study was carried out on\nFCC-based lattice beams utilizing five different materials (Structural Steel,\nAA6061, AA7075, Ti6Al4V, and Inconel 718) under varied edge loads (1000-10000\nN). The PINN model blends data-driven learning with physics-based limitations\nvia a proprietary loss function, resulting in much higher prediction accuracy\nthan linear regression. PINN outperforms linear regression, achieving greater\nR-square (0.7923 vs 0.5686) and lower error metrics (MSE: 0.00017417 vs\n0.00036187). Among the materials examined, AA6061 had the highest displacement\nsensitivity (0.1014 mm at maximum load), while Inconel718 had better structural\nstability.",
    "categories": [
      "cs.AI",
      "cond-mat.mtrl-sci",
      "cs.CE",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "34 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.03254v1",
    "published_date": "2024-12-31 00:15:58 UTC",
    "updated_date": "2024-12-31 00:15:58 UTC"
  },
  {
    "arxiv_id": "2501.00195v1",
    "title": "Towards Unraveling and Improving Generalization in World Models",
    "authors": [
      "Qiaoyi Fang",
      "Weiyu Du",
      "Hang Wang",
      "Junshan Zhang"
    ],
    "abstract": "World models have recently emerged as a promising approach to reinforcement\nlearning (RL), achieving state-of-the-art performance across a wide range of\nvisual control tasks. This work aims to obtain a deep understanding of the\nrobustness and generalization capabilities of world models. Thus motivated, we\ndevelop a stochastic differential equation formulation by treating the world\nmodel learning as a stochastic dynamical system, and characterize the impact of\nlatent representation errors on robustness and generalization, for both cases\nwith zero-drift representation errors and with non-zero-drift representation\nerrors. Our somewhat surprising findings, based on both theoretic and\nexperimental studies, reveal that for the case with zero drift, modest latent\nrepresentation errors can in fact function as implicit regularization and hence\nresult in improved robustness. We further propose a Jacobian regularization\nscheme to mitigate the compounding error propagation effects of non-zero drift,\nthereby enhancing training stability and robustness. Our experimental studies\ncorroborate that this regularization approach not only stabilizes training but\nalso accelerates convergence and improves accuracy of long-horizon prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "An earlier version of this paper was submitted to NeurIPS and\n  received ratings of (7, 6, 6). The reviewers' comments and the original draft\n  are available at OpenReview. This version contains minor modifications based\n  on that submission",
    "pdf_url": "http://arxiv.org/pdf/2501.00195v1",
    "published_date": "2024-12-31 00:15:43 UTC",
    "updated_date": "2024-12-31 00:15:43 UTC"
  },
  {
    "arxiv_id": "2501.00190v2",
    "title": "SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction",
    "authors": [
      "Changchang Yin",
      "Shihan Fu",
      "Bingsheng Yao",
      "Thai-Hoang Pham",
      "Weidan Cao",
      "Dakuo Wang",
      "Jeffrey Caterino",
      "Ping Zhang"
    ],
    "abstract": "Sepsis is an organ dysfunction caused by a deregulated immune response to an\ninfection. Early sepsis prediction and identification allow for timely\nintervention, leading to improved clinical outcomes. Clinical calculators\n(e.g., the six-organ dysfunction assessment of SOFA) play a vital role in\nsepsis identification within clinicians' workflow, providing evidence-based\nrisk assessments essential for sepsis diagnosis. However, artificial\nintelligence (AI) sepsis prediction models typically generate a single sepsis\nrisk score without incorporating clinical calculators for assessing organ\ndysfunctions, making the models less convincing and transparent to clinicians.\nTo bridge the gap, we propose to mimic clinicians' workflow with a novel\nframework SepsisCalc to integrate clinical calculators into the predictive\nmodel, yielding a clinically transparent and precise model for utilization in\nclinical settings. Practically, clinical calculators usually combine\ninformation from multiple component variables in Electronic Health Records\n(EHR), and might not be applicable when the variables are (partially) missing.\nWe mitigate this issue by representing EHRs as temporal graphs and integrating\na learning module to dynamically add the accurately estimated calculator to the\ngraphs. Experimental results on real-world datasets show that the proposed\nmodel outperforms state-of-the-art methods on sepsis prediction tasks.\nMoreover, we developed a system to identify organ dysfunctions and potential\nsepsis risks, providing a human-AI interaction tool for deployment, which can\nhelp clinicians understand the prediction outputs and prepare timely\ninterventions for the corresponding dysfunctions, paving the way for actionable\nclinical decision-making support for early intervention.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00190v2",
    "published_date": "2024-12-31 00:02:07 UTC",
    "updated_date": "2025-01-09 20:00:16 UTC"
  }
]