[
  {
    "arxiv_id": "2509.00284v1",
    "title": "Generative AI for Industrial Contour Detection: A Language-Guided Vision System",
    "authors": [
      "Liang Gong",
      "Tommy",
      "Wang",
      "Sara Chaker",
      "Yanchen Dong",
      "Fouad Bousetouane",
      "Brenden Morton",
      "Mark Mendez"
    ],
    "abstract": "Industrial computer vision systems often struggle with noise, material variability, and uncontrolled imaging conditions, limiting the effectiveness of classical edge detectors and handcrafted pipelines. In this work, we present a language-guided generative vision system for remnant contour detection in manufacturing, designed to achieve CAD-level precision. The system is organized into three stages: data acquisition and preprocessing, contour generation using a conditional GAN, and multimodal contour refinement through vision-language modeling, where standardized prompts are crafted in a human-in-the-loop process and applied through image-text guided synthesis. On proprietary FabTrack datasets, the proposed system improved contour fidelity, enhancing edge continuity and geometric alignment while reducing manual tracing. For the refinement stage, we benchmarked several vision-language models, including Google's Gemini 2.0 Flash, OpenAI's GPT-image-1 integrated within a VLM-guided workflow, and open-source baselines. Under standardized conditions, GPT-image-1 consistently outperformed Gemini 2.0 Flash in both structural accuracy and perceptual quality. These findings demonstrate the promise of VLM-guided generative workflows for advancing industrial computer vision beyond the limitations of classical pipelines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.00284v1",
    "published_date": "2025-08-29 23:58:08 UTC",
    "updated_date": "2025-08-29 23:58:08 UTC"
  },
  {
    "arxiv_id": "2509.08834v1",
    "title": "An Interval Type-2 Version of Bayes Theorem Derived from Interval Probability Range Estimates Provided by Subject Matter Experts",
    "authors": [
      "John T. Rickard",
      "William A. Dembski",
      "James Rickards"
    ],
    "abstract": "Bayesian inference is widely used in many different fields to test hypotheses against observations. In most such applications, an assumption is made of precise input values to produce a precise output value. However, this is unrealistic for real-world applications. Often the best available information from subject matter experts (SMEs) in a given field is interval range estimates of the input probabilities involved in Bayes Theorem. This paper provides two key contributions to extend Bayes Theorem to an interval type-2 (IT2) version. First, we develop an IT2 version of Bayes Theorem that uses a novel and conservative method to avoid potential inconsistencies in the input IT2 MFs that otherwise might produce invalid output results. We then describe a novel and flexible algorithm for encoding SME-provided intervals into IT2 fuzzy membership functions (MFs), which we can use to specify the input probabilities in Bayes Theorem. Our algorithm generalizes and extends previous work on this problem that primarily addressed the encoding of intervals into word MFs for Computing with Words applications.",
    "categories": [
      "cs.AI",
      "physics.comp-ph",
      "physics.data-an",
      "q-fin.CP"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.08834v1",
    "published_date": "2025-08-29 23:47:31 UTC",
    "updated_date": "2025-08-29 23:47:31 UTC"
  },
  {
    "arxiv_id": "2509.00277v1",
    "title": "SABER: A SQL-Compatible Semantic Document Processing System Based on Extended Relational Algebra",
    "authors": [
      "Changjae Lee",
      "Zhuoyue Zhao",
      "Jinjun Xiong"
    ],
    "abstract": "The emergence of large-language models (LLMs) has enabled a new class of semantic data processing systems (SDPSs) to support declarative queries against unstructured documents. Existing SDPSs are, however, lacking a unified algebraic foundation, making their queries difficult to compose, reason, and optimize. We propose a new semantic algebra, SABER (Semantic Algebra Based on Extended Relational algebra), opening the possibility of semantic operations' logical plan construction, optimization, and formal correctness guarantees. We further propose to implement SABER in a SQL-compatible syntax so that it natively supports mixed structured/unstructured data processing. With SABER, we showcase the feasibility of providing a unified interface for existing SDPSs so that it can effectively mix and match any semantically-compatible operator implementation from any SDPS, greatly enhancing SABER's applicability for community contributions.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "6 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.00277v1",
    "published_date": "2025-08-29 23:27:03 UTC",
    "updated_date": "2025-08-29 23:27:03 UTC"
  },
  {
    "arxiv_id": "2509.00272v1",
    "title": "SHERPA: A Model-Driven Framework for Large Language Model Execution",
    "authors": [
      "Boqi Chen",
      "Kua Chen",
      "José Antonio Hernández López",
      "Gunter Mussbacher",
      "Dániel Varró",
      "Amir Feizpour"
    ],
    "abstract": "Recently, large language models (LLMs) have achieved widespread application across various fields. Despite their impressive capabilities, LLMs suffer from a lack of structured reasoning ability, particularly for complex tasks requiring domain-specific best practices, which are often unavailable in the training data. Although multi-step prompting methods incorporating human best practices, such as chain-of-thought and tree-of-thought, have gained popularity, they lack a general mechanism to control LLM behavior. In this paper, we propose SHERPA, a model-driven framework to improve the LLM performance on complex tasks by explicitly incorporating domain-specific best practices into hierarchical state machines. By structuring the LLM execution processes using state machines, SHERPA enables more fine-grained control over their behavior via rules or decisions driven by machine learning-based approaches, including LLMs. We show that SHERPA is applicable to a wide variety of tasks-specifically, code generation, class name generation, and question answering-replicating previously proposed approaches while further improving the performance. We demonstrate the effectiveness of SHERPA for the aforementioned tasks using various LLMs. Our systematic evaluation compares different state machine configurations against baseline approaches without state machines. Results show that integrating well-designed state machines significantly improves the quality of LLM outputs, and is particularly beneficial for complex tasks with well-established human best practices but lacking data used for training LLMs.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "MODELS 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.00272v1",
    "published_date": "2025-08-29 23:14:21 UTC",
    "updated_date": "2025-08-29 23:14:21 UTC"
  },
  {
    "arxiv_id": "2509.00268v4",
    "title": "Remotely sensing stress evolution in elastic media: a passive approach to earthquake monitoring",
    "authors": [
      "Nader Shakibay Senobari"
    ],
    "abstract": "Stress evolution governs material failure across scales, from microscopic fractures to large earthquakes, yet direct observation of its dynamics in natural systems has remained elusive. Laboratory experiments using active ultrasonic measurements have shown that seismic velocity and attenuation are sensitive to stress, but such monitoring has not previously been achievable remotely or passively.\n  Here we introduce a stress-sensitive frequency-domain transform that enables passive monitoring of stress evolution using ambient seismic or acoustic noise. The method quantifies relative energy shifts between adjacent frequency bands, capturing subtle changes in wave-propagation properties linked to evolving shear and normal stress. Applied across scales, from laboratory stick-slip and slow-slip experiments to natural fault systems including the 2018 Kilauea collapse, Cascadia slow-slip episodes, and major earthquakes such as the 2011 Tohoku, 2010 Maule, 2002 Denali, and 2023 Turkey-Syria events, the transform consistently reveals distinctive precursory trajectories and stress-cycle patterns.\n  These results demonstrate that stress evolution in elastic Earth materials can be remotely and passively monitored, bridging laboratory rock physics and large-scale seismology and offering a new foundation for real-time tracking of fault mechanics and earthquake preparation.",
    "categories": [
      "physics.geo-ph",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "25 pages, 9 figures. Github code included",
    "pdf_url": "https://arxiv.org/pdf/2509.00268v4",
    "published_date": "2025-08-29 22:43:13 UTC",
    "updated_date": "2025-12-02 01:20:38 UTC"
  },
  {
    "arxiv_id": "2509.04473v1",
    "title": "SpeechLLM: Unified Speech and Language Model for Enhanced Multi-Task Understanding in Low Resource Settings",
    "authors": [
      "Jaekwon Yoo",
      "Kunal Chandiramani",
      "Divya Tadimeti",
      "Abenezer Girma",
      "Chandra Dhir"
    ],
    "abstract": "While integrating speech encoder with LLM requires substantial data and resources, use cases face limitations due to insufficient availability. To address this, we propose a solution with a parameter-efficient adapter that converts speech embeddings into LLM-compatible tokens, focusing on end-to-end automatic speech recognition (ASR), named entity recognition (NER), and sentiment analysis (SA). To reduce labeling costs, we employ an LLM-based synthetic dataset annotation technique. The proposed adapter, using 7x fewer trainable parameters, achieves significant performance gains: a 26% relative Word Error Rates (WER) improvement on the LibriSpeech ASR task, a 6.3% relative F1 score increase on the NER task, and a 32% relative F1 score boost on the SA task. Moreover, using advanced techniques such as adding a classifier regularizer and optimizing the LLM with Low-Rank Adaptation (LoRA) yields notable performance gains, with Spoken Language Understanding Evaluation (SLUE) score improvement of 6.6% and 9.5%",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.04473v1",
    "published_date": "2025-08-29 22:38:16 UTC",
    "updated_date": "2025-08-29 22:38:16 UTC"
  },
  {
    "arxiv_id": "2509.02605v1",
    "title": "Synthetic Founders: AI-Generated Social Simulations for Startup Validation Research in Computational Social Science",
    "authors": [
      "Jorn K. Teutloff"
    ],
    "abstract": "We present a comparative docking experiment that aligns human-subject interview data with large language model (LLM)-driven synthetic personas to evaluate fidelity, divergence, and blind spots in AI-enabled simulation. Fifteen early-stage startup founders were interviewed about their hopes and concerns regarding AI-powered validation, and the same protocol was replicated with AI-generated founder and investor personas. A structured thematic synthesis revealed four categories of outcomes: (1) Convergent themes - commitment-based demand signals, black-box trust barriers, and efficiency gains were consistently emphasized across both datasets; (2) Partial overlaps - founders worried about outliers being averaged away and the stress of real customer validation, while synthetic personas highlighted irrational blind spots and framed AI as a psychological buffer; (3) Human-only themes - relational and advocacy value from early customer engagement and skepticism toward moonshot markets; and (4) Synthetic-only themes - amplified false positives and trauma blind spots, where AI may overstate adoption potential by missing negative historical experiences.\n  We interpret this comparative framework as evidence that LLM-driven personas constitute a form of hybrid social simulation: more linguistically expressive and adaptable than traditional rule-based agents, yet bounded by the absence of lived history and relational consequence. Rather than replacing empirical studies, we argue they function as a complementary simulation category - capable of extending hypothesis space, accelerating exploratory validation, and clarifying the boundaries of cognitive realism in computational social science.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.MA",
    "comment": "Manuscript submitted to the Journal of Artificial Societies and Social Simulation (JASSS). 21 pages, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2509.02605v1",
    "published_date": "2025-08-29 21:54:53 UTC",
    "updated_date": "2025-08-29 21:54:53 UTC"
  },
  {
    "arxiv_id": "2509.00251v2",
    "title": "Instruction-Level Weight Shaping: A Framework for Self-Improving AI Agents",
    "authors": [
      "Rimom Costa"
    ],
    "abstract": "Large language models (LLMs) are fluent but largely static after pre-training; new or shifting knowledge is typically added with retrieval-augmented generation (RAG) or fine-tuning. RAG raises latency and engineering overhead and often fails to integrate facts; prompt engineering is brittle and can conflict with prior knowledge; fine-tuning is costly and risks catastrophic forgetting. We propose Instruction-Level Weight Shaping (ILWS): curated system instructions act as external, auditable pseudo-parameters updated after each session via reflection and user feedback. A Reflection Engine inspects conversation traces, diagnoses reasoning successes and failures, and proposes typed deltas $ΔK=(ΔS,ΔU,ΔT)$ over instructions, user preferences, and tools. Deltas are version-controlled, evaluated with a sliding window of 1-5 star ratings, auto-repaired on first failure, and rolled back on repeated failure. When an edit budget crosses a threshold, the agent compiles a rating-weighted synthetic set and distills matured instruction-space gains into parameters, converting prompt-space improvements into weight-space without downtime. ILWS makes explicit the low-rank shaping induced by context in transformer blocks, preserves governance, and removes per-call retrieval. In enterprise support it increased throughput 2.4-5.0x and cut audited hallucinations by about 80% versus a frozen baseline. In an Adobe Commerce Cloud proof of concept \"L0 Support\", it achieved 4-5x more tickets per hour and about 80% lower time per ticket, with autonomous instruction updates and optional tool synthesis. Because ILWS operates at the instruction layer until controlled distillation, it generalizes to dynamic domains (legal, medical, engineering) requiring adaptive reasoning, tool creation, and low-latency deployment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 1 figure, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.00251v2",
    "published_date": "2025-08-29 21:34:39 UTC",
    "updated_date": "2025-12-20 18:38:07 UTC"
  },
  {
    "arxiv_id": "2509.00248v1",
    "title": "The Differential Meaning of Models: A Framework for Analyzing the Structural Consequences of Semantic Modeling Decisions",
    "authors": [
      "Zachary K. Stine",
      "James E. Deitrick"
    ],
    "abstract": "The proliferation of methods for modeling of human meaning-making constitutes a powerful class of instruments for the analysis of complex semiotic systems. However, the field lacks a general theoretical framework for describing these modeling practices across various model types in an apples-to-apples way. In this paper, we propose such a framework grounded in the semiotic theory of C. S. Peirce. We argue that such models measure latent symbol geometries, which can be understood as hypotheses about the complex of semiotic agencies underlying a symbolic dataset. Further, we argue that in contexts where a model's value cannot be straightforwardly captured by proxy measures of performance, models can instead be understood relationally, so that the particular interpretive lens of a model becomes visible through its contrast with other models. This forms the basis of a theory of model semantics in which models, and the modeling decisions that constitute them, are themselves treated as signs. In addition to proposing the framework, we illustrate its empirical use with a few brief examples and consider foundational questions and future directions enabled by the framework.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00248v1",
    "published_date": "2025-08-29 21:28:10 UTC",
    "updated_date": "2025-08-29 21:28:10 UTC"
  },
  {
    "arxiv_id": "2509.00244v1",
    "title": "Universal Deep Research: Bring Your Own Model and Strategy",
    "authors": [
      "Peter Belcak",
      "Pavlo Molchanov"
    ],
    "abstract": "Deep research tools are among the most impactful and most commonly encountered agentic systems today. We observe, however, that each deep research agent introduced so far is hard-coded to carry out a particular research strategy using a fixed choice of tools. We introduce Universal Deep Research (UDR), a generalist agentic system that wraps around any language model and enables the user to create, edit, and refine their own entirely custom deep research strategies without any need for additional training or finetuning. To showcase the generality of our system, we equip UDR with example minimal, expansive, and intensive research strategies, and provide a user interface to facilitate experimentation with the system.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00244v1",
    "published_date": "2025-08-29 21:22:19 UTC",
    "updated_date": "2025-08-29 21:22:19 UTC"
  },
  {
    "arxiv_id": "2509.00240v1",
    "title": "Criteria for Credible AI-assisted Carbon Footprinting Systems: The Cases of Mapping and Lifecycle Modeling",
    "authors": [
      "Shaena Ulissi",
      "Andrew Dumit",
      "P. James Joyce",
      "Krishna Rao",
      "Steven Watson",
      "Sangwon Suh"
    ],
    "abstract": "As organizations face increasing pressure to understand their corporate and products' carbon footprints, artificial intelligence (AI)-assisted calculation systems for footprinting are proliferating, but with widely varying levels of rigor and transparency. Standards and guidance have not kept pace with the technology; evaluation datasets are nascent; and statistical approaches to uncertainty analysis are not yet practical to apply to scaled systems. We present a set of criteria to validate AI-assisted systems that calculate greenhouse gas (GHG) emissions for products and materials. We implement a three-step approach: (1) Identification of needs and constraints, (2) Draft criteria development and (3) Refinements through pilots. The process identifies three use cases of AI applications: Case 1 focuses on AI-assisted mapping to existing datasets for corporate GHG accounting and product hotspotting, automating repetitive manual tasks while maintaining mapping quality. Case 2 addresses AI systems that generate complete product models for corporate decision-making, which require comprehensive validation of both component tasks and end-to-end performance. We discuss the outlook for Case 3 applications, systems that generate standards-compliant models. We find that credible AI systems can be built and that they should be validated using system-level evaluations rather than line-item review, with metrics such as benchmark performance, indications of data quality and uncertainty, and transparent documentation. This approach may be used as a foundation for practitioners, auditors, and standards bodies to evaluate AI-assisted environmental assessment tools. By establishing evaluation criteria that balance scalability with credibility requirements, our approach contributes to the field's efforts to develop appropriate standards for AI-assisted carbon footprinting systems.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "16 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2509.00240v1",
    "published_date": "2025-08-29 21:05:19 UTC",
    "updated_date": "2025-08-29 21:05:19 UTC"
  },
  {
    "arxiv_id": "2509.04472v2",
    "title": "RECAP: REwriting Conversations for Intent Understanding in Agentic Planning",
    "authors": [
      "Kushan Mitra",
      "Dan Zhang",
      "Hannah Kim",
      "Estevam Hruschka"
    ],
    "abstract": "Understanding user intent is essential for effective planning in conversational assistants, particularly those powered by large language models (LLMs) coordinating multiple agents. However, real-world dialogues are often ambiguous, underspecified, or dynamic, making intent detection a persistent challenge. Traditional classification-based approaches struggle to generalize in open-ended settings, leading to brittle interpretations and poor downstream planning. We propose RECAP (REwriting Conversations for Agent Planning), a new benchmark designed to evaluate and advance intent rewriting, reframing user-agent dialogues into concise representations of user goals. RECAP captures diverse challenges such as ambiguity, intent drift, vagueness, and mixed-goal conversations. Alongside the dataset, we introduce an LLM-based evaluator that assesses planning utility given the rewritten intent. Using RECAP, we develop a prompt-based rewriting approach that outperforms baselines, in terms of plan preference. We further demonstrate that fine-tuning two DPO-based rewriters yields additional utility gains. Our results highlight intent rewriting as a critical and tractable component for improving agentic planning in open-domain dialogue systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.04472v2",
    "published_date": "2025-08-29 20:45:37 UTC",
    "updated_date": "2025-12-12 08:45:50 UTC"
  },
  {
    "arxiv_id": "2509.00230v2",
    "title": "Evaluating the Effectiveness of Transformer Layers in Wav2Vec 2.0, XLS-R, and Whisper for Speaker Identification Tasks",
    "authors": [
      "Linus Stuhlmann",
      "Michael Alexander Saxer"
    ],
    "abstract": "This study evaluates the performance of three advanced speech encoder models, Wav2Vec 2.0, XLS-R, and Whisper, in speaker identification tasks. By fine-tuning these models and analyzing their layer-wise representations using SVCCA, k-means clustering, and t-SNE visualizations, we found that Wav2Vec 2.0 and XLS-R capture speaker-specific features effectively in their early layers, with fine-tuning improving stability and performance. Whisper showed better performance in deeper layers. Additionally, we determined the optimal number of transformer layers for each model when fine-tuned for speaker identification tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "This was a conducted student project at our univerity, we don't think this fulfills the requirements for a publication on arxiv",
    "pdf_url": "https://arxiv.org/pdf/2509.00230v2",
    "published_date": "2025-08-29 20:39:42 UTC",
    "updated_date": "2025-09-28 19:00:24 UTC"
  },
  {
    "arxiv_id": "2509.00218v1",
    "title": "Embodied AI in Social Spaces: Responsible and Adaptive Robots in Complex Setting -- UKAIRS 2025 (Copy)",
    "authors": [
      "Aleksandra Landowska",
      "Aislinn D Gomez Bergin",
      "Ayodeji O. Abioye",
      "Jayati Deshmukh",
      "Andriana Bouadouki",
      "Maria Wheadon",
      "Athina Georgara",
      "Dominic Price",
      "Tuyen Nguyen",
      "Shuang Ao",
      "Lokesh Singh",
      "Yi Long",
      "Raffaele Miele",
      "Joel E. Fischer",
      "Sarvapali D. Ramchurn"
    ],
    "abstract": "This paper introduces and overviews a multidisciplinary project aimed at developing responsible and adaptive multi-human multi-robot (MHMR) systems for complex, dynamic settings. The project integrates co-design, ethical frameworks, and multimodal sensing to create AI-driven robots that are emotionally responsive, context-aware, and aligned with the needs of diverse users. We outline the project's vision, methodology, and early outcomes, demonstrating how embodied AI can support sustainable, ethical, and human-centred futures.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00218v1",
    "published_date": "2025-08-29 20:01:56 UTC",
    "updated_date": "2025-08-29 20:01:56 UTC"
  },
  {
    "arxiv_id": "2509.00215v2",
    "title": "First Order Model-Based RL through Decoupled Backpropagation",
    "authors": [
      "Joseph Amigo",
      "Rooholla Khorrambakht",
      "Elliot Chane-Sane",
      "Nicolas Mansard",
      "Ludovic Righetti"
    ],
    "abstract": "There is growing interest in reinforcement learning (RL) methods that leverage the simulator's derivatives to improve learning efficiency. While early gradient-based approaches have demonstrated superior performance compared to derivative-free methods, accessing simulator gradients is often impractical due to their implementation cost or unavailability. Model-based RL (MBRL) can approximate these gradients via learned dynamics models, but the solver efficiency suffers from compounding prediction errors during training rollouts, which can degrade policy performance. We propose an approach that decouples trajectory generation from gradient computation: trajectories are unrolled using a simulator, while gradients are computed via backpropagation through a learned differentiable model of the simulator. This hybrid design enables efficient and consistent first-order policy optimization, even when simulator gradients are unavailable, as well as learning a critic from simulation rollouts, which is more accurate. Our method achieves the sample efficiency and speed of specialized optimizers such as SHAC, while maintaining the generality of standard approaches like PPO and avoiding ill behaviors observed in other first-order MBRL methods. We empirically validate our algorithm on benchmark control tasks and demonstrate its effectiveness on a real Go2 quadruped robot, across both quadrupedal and bipedal locomotion tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "CoRL 2025. Project website: https://machines-in-motion.github.io/DMO/",
    "pdf_url": "https://arxiv.org/pdf/2509.00215v2",
    "published_date": "2025-08-29 19:55:25 UTC",
    "updated_date": "2025-09-04 12:46:04 UTC"
  },
  {
    "arxiv_id": "2509.00213v2",
    "title": "Multimodal Deep Learning for Phyllodes Tumor Classification from Ultrasound and Clinical Data",
    "authors": [
      "Farhan Fuad Abir",
      "Abigail Elliott Daly",
      "Kyle Anderman",
      "Tolga Ozmen",
      "Laura J. Brattain"
    ],
    "abstract": "Phyllodes tumors (PTs) are rare fibroepithelial breast lesions that are difficult to classify preoperatively due to their radiological similarity to benign fibroadenomas. This often leads to unnecessary surgical excisions. To address this, we propose a multimodal deep learning framework that integrates breast ultrasound (BUS) images with structured clinical data to improve diagnostic accuracy. We developed a dual-branch neural network that extracts and fuses features from ultrasound images and patient metadata from 81 subjects with confirmed PTs. Class-aware sampling and subject-stratified 5-fold cross-validation were applied to prevent class imbalance and data leakage. The results show that our proposed multimodal method outperforms unimodal baselines in classifying benign versus borderline/malignant PTs. Among six image encoders, ConvNeXt and ResNet18 achieved the best performance in the multimodal setting, with AUC-ROC scores of 0.9427 and 0.9349, and F1-scores of 0.6720 and 0.7294, respectively. This study demonstrates the potential of multimodal AI to serve as a non-invasive diagnostic tool, reducing unnecessary biopsies and improving clinical decision-making in breast tumor management.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE-EMBS International Conference on Body Sensor Networks (IEEE-EMBS BSN 2025)",
    "pdf_url": "https://arxiv.org/pdf/2509.00213v2",
    "published_date": "2025-08-29 19:54:11 UTC",
    "updated_date": "2025-09-25 14:00:16 UTC"
  },
  {
    "arxiv_id": "2509.25196v1",
    "title": "APRIL: API Synthesis with Automatic Prompt Optimization and Reinforcement Learning",
    "authors": [
      "Hua Zhong",
      "Shan Jiang",
      "Sarfraz Khurshid"
    ],
    "abstract": "APIs are central to modern software development, yet composing new APIs from large libraries is difficult due to the exponential search space; traditional component-based synthesis relies on costly exploration and hand-crafted specifications. While large language models (LLMs) can generate implementations from natural language, hallucinations and limited access to up-to-date contextual information often yield incorrect code. In this paper, we present APRIL, an approach that combines LLM-based synthesis with Automatic Prompt Optimization (APO) and Reinforcement Learning from Verifiable Rewards (RLVR): APO iteratively refines prompts for a frozen model, while RLVR fine-tunes the policy toward functional correctness, producing an efficient synthesis pipeline. Evaluated on 81 real-world APIs from widely used scientific Python libraries and benchmarked against instruction-tuned but unfine-tuned LLMs guided by expert prompts, APRIL achieves substantial improvements. These results indicate that integrating APO and RLVR provides a robust, scalable path for component-based API synthesis in large libraries.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.25196v1",
    "published_date": "2025-08-29 19:48:09 UTC",
    "updated_date": "2025-08-29 19:48:09 UTC"
  },
  {
    "arxiv_id": "2509.00210v1",
    "title": "Beyond Pixels: Introducing Geometric-Semantic World Priors for Video-based Embodied Models via Spatio-temporal Alignment",
    "authors": [
      "Jinzhou Tang",
      "Jusheng zhang",
      "Sidi Liu",
      "Waikit Xiu",
      "Qinhan Lv",
      "Xiying Li"
    ],
    "abstract": "Achieving human-like reasoning in deep learning models for complex tasks in unknown environments remains a critical challenge in embodied intelligence. While advanced vision-language models (VLMs) excel in static scene understanding, their limitations in spatio-temporal reasoning and adaptation to dynamic, open-set tasks like task-oriented navigation and embodied question answering (EQA) persist due to inadequate modeling of fine-grained spatio-temporal cues and physical world comprehension. To address this, we propose VEME, a novel cross-modal alignment method that enhances generalization in unseen scenes by learning an ego-centric, experience-centered world model. Our framework integrates three key components: (1) a cross-modal alignment framework bridging objects, spatial representations, and visual semantics with spatio-temporal cues to enhance VLM in-context learning; (2) a dynamic, implicit cognitive map activated by world embedding to enable task-relevant geometric-semantic memory recall; and (3) an instruction-based navigation and reasoning framework leveraging embodied priors for long-term planning and efficient exploration. By embedding geometry-aware spatio-temporal episodic experiences, our method significantly improves reasoning and planning in dynamic environments. Experimental results on VSI-Bench and VLN-CE demonstrate 1%-3% accuracy and exploration efficiency improvement compared to traditional approaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00210v1",
    "published_date": "2025-08-29 19:47:25 UTC",
    "updated_date": "2025-08-29 19:47:25 UTC"
  },
  {
    "arxiv_id": "2509.05317v1",
    "title": "VILOD: A Visual Interactive Labeling Tool for Object Detection",
    "authors": [
      "Isac Holm"
    ],
    "abstract": "The advancement of Object Detection (OD) using Deep Learning (DL) is often hindered by the significant challenge of acquiring large, accurately labeled datasets, a process that is time-consuming and expensive. While techniques like Active Learning (AL) can reduce annotation effort by intelligently querying informative samples, they often lack transparency, limit the strategic insight of human experts, and may overlook informative samples not aligned with an employed query strategy. To mitigate these issues, Human-in-the-Loop (HITL) approaches integrating human intelligence and intuition throughout the machine learning life-cycle have gained traction. Leveraging Visual Analytics (VA), effective interfaces can be created to facilitate this human-AI collaboration. This thesis explores the intersection of these fields by developing and investigating \"VILOD: A Visual Interactive Labeling tool for Object Detection\". VILOD utilizes components such as a t-SNE projection of image features, together with uncertainty heatmaps and model state views. Enabling users to explore data, interpret model states, AL suggestions, and implement diverse sample selection strategies within an iterative HITL workflow for OD. An empirical investigation using comparative use cases demonstrated how VILOD, through its interactive visualizations, facilitates the implementation of distinct labeling strategies by making the model's state and dataset characteristics more interpretable (RQ1). The study showed that different visually-guided labeling strategies employed within VILOD result in competitive OD performance trajectories compared to an automated uncertainty sampling AL baseline (RQ2). This work contributes a novel tool and empirical insight into making the HITL-AL workflow for OD annotation more transparent, manageable, and potentially more effective.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Master's project",
    "pdf_url": "https://arxiv.org/pdf/2509.05317v1",
    "published_date": "2025-08-29 19:27:10 UTC",
    "updated_date": "2025-08-29 19:27:10 UTC"
  },
  {
    "arxiv_id": "2509.05316v1",
    "title": "Standard vs. Modular Sampling: Best Practices for Reliable LLM Unlearning",
    "authors": [
      "Praveen Bushipaka",
      "Lucia Passaro",
      "Tommaso Cucinotta"
    ],
    "abstract": "A conventional LLM Unlearning setting consists of two subsets -\"forget\" and \"retain\", with the objectives of removing the undesired knowledge from the forget set while preserving the remaining knowledge from the retain. In privacy-focused unlearning research, a retain set is often further divided into neighbor sets, containing either directly or indirectly connected to the forget targets; and augmented by a general-knowledge set. A common practice in existing benchmarks is to employ only a single neighbor set, with general knowledge which fails to reflect the real-world data complexities and relationships. LLM Unlearning typically involves 1:1 sampling or cyclic iteration sampling. However, the efficacy and stability of these de facto standards have not been critically examined. In this study, we systematically evaluate these common practices. Our findings reveal that relying on a single neighbor set is suboptimal and that a standard sampling approach can obscure performance trade-offs. Based on this analysis, we propose and validate an initial set of best practices: (1) Incorporation of diverse neighbor sets to balance forget efficacy and model utility, (2) Standard 1:1 sampling methods are inefficient and yield poor results, (3) Our proposed Modular Entity-Level Unlearning (MELU) strategy as an alternative to cyclic sampling. We demonstrate that this modular approach, combined with robust algorithms, provides a clear and stable path towards effective unlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.05316v1",
    "published_date": "2025-08-29 19:25:52 UTC",
    "updated_date": "2025-08-29 19:25:52 UTC"
  },
  {
    "arxiv_id": "2509.00190v1",
    "title": "Explainable Chain-of-Thought Reasoning: An Empirical Analysis on State-Aware Reasoning Dynamics",
    "authors": [
      "Sheldon Yu",
      "Yuxin Xiong",
      "Junda Wu",
      "Xintong Li",
      "Tong Yu",
      "Xiang Chen",
      "Ritwik Sinha",
      "Jingbo Shang",
      "Julian McAuley"
    ],
    "abstract": "Recent advances in chain-of-thought (CoT) prompting have enabled large language models (LLMs) to perform multi-step reasoning. However, the explainability of such reasoning remains limited, with prior work primarily focusing on local token-level attribution, such that the high-level semantic roles of reasoning steps and their transitions remain underexplored. In this paper, we introduce a state-aware transition framework that abstracts CoT trajectories into structured latent dynamics. Specifically, to capture the evolving semantics of CoT reasoning, each reasoning step is represented via spectral analysis of token-level embeddings and clustered into semantically coherent latent states. To characterize the global structure of reasoning, we model their progression as a Markov chain, yielding a structured and interpretable view of the reasoning process. This abstraction supports a range of analyses, including semantic role identification, temporal pattern visualization, and consistency evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.00190v1",
    "published_date": "2025-08-29 18:53:31 UTC",
    "updated_date": "2025-08-29 18:53:31 UTC"
  },
  {
    "arxiv_id": "2509.00189v1",
    "title": "HiVA: Self-organized Hierarchical Variable Agent via Goal-driven Semantic-Topological Evolution",
    "authors": [
      "Jinzhou Tang",
      "Jusheng Zhang",
      "Qinhan Lv",
      "Sidi Liu",
      "Jing Yang",
      "Chengpei Tang",
      "Keze Wang"
    ],
    "abstract": "Autonomous agents play a crucial role in advancing Artificial General Intelligence, enabling problem decomposition and tool orchestration through Large Language Models (LLMs). However, existing paradigms face a critical trade-off. On one hand, reusable fixed workflows require manual reconfiguration upon environmental changes; on the other hand, flexible reactive loops fail to distill reasoning progress into transferable structures. We introduce Hierarchical Variable Agent (HiVA), a novel framework modeling agentic workflows as self-organized graphs with the Semantic-Topological Evolution (STEV) algorithm, which optimizes hybrid semantic-topological spaces using textual gradients as discrete-domain surrogates for backpropagation. The iterative process comprises Multi-Armed Bandit-infused forward routing, diagnostic gradient generation from environmental feedback, and coordinated updates that co-evolve individual semantics and topology for collective optimization in unknown environments. Experiments on dialogue, coding, Long-context Q&A, mathematical, and agentic benchmarks demonstrate improvements of 5-10% in task accuracy and enhanced resource efficiency over existing baselines, establishing HiVA's effectiveness in autonomous task execution.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00189v1",
    "published_date": "2025-08-29 18:51:18 UTC",
    "updated_date": "2025-08-29 18:51:18 UTC"
  },
  {
    "arxiv_id": "2509.00186v1",
    "title": "Generalizable Audio Spoofing Detection using Non-Semantic Representations",
    "authors": [
      "Arnab Das",
      "Yassine El Kheir",
      "Carlos Franzreb",
      "Tim Herzig",
      "Tim Polzehl",
      "Sebastian Möller"
    ],
    "abstract": "Rapid advancements in generative modeling have made synthetic audio generation easy, making speech-based services vulnerable to spoofing attacks. Consequently, there is a dire need for robust countermeasures more than ever. Existing solutions for deepfake detection are often criticized for lacking generalizability and fail drastically when applied to real-world data. This study proposes a novel method for generalizable spoofing detection leveraging non-semantic universal audio representations. Extensive experiments have been performed to find suitable non-semantic features using TRILL and TRILLsson models. The results indicate that the proposed method achieves comparable performance on the in-domain test set while significantly outperforming state-of-the-art approaches on out-of-domain test sets. Notably, it demonstrates superior generalization on public-domain data, surpassing methods based on hand-crafted features, semantic embeddings, and end-to-end architectures.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00186v1",
    "published_date": "2025-08-29 18:37:57 UTC",
    "updated_date": "2025-08-29 18:37:57 UTC"
  },
  {
    "arxiv_id": "2509.00185v1",
    "title": "What Are Research Hypotheses?",
    "authors": [
      "Jian Wu",
      "Sarah Rajtmajer"
    ],
    "abstract": "Over the past decades, alongside advancements in natural language processing, significant attention has been paid to training models to automatically extract, understand, test, and generate hypotheses in open and scientific domains. However, interpretations of the term \\emph{hypothesis} for various natural language understanding (NLU) tasks have migrated from traditional definitions in the natural, social, and formal sciences. Even within NLU, we observe differences defining hypotheses across literature. In this paper, we overview and delineate various definitions of hypothesis. Especially, we discern the nuances of definitions across recently published NLU tasks. We highlight the importance of well-structured and well-defined hypotheses, particularly as we move toward a machine-interpretable scholarly record.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, accepted by Sci-K'25: International Workshop on Scientific Knowledge",
    "pdf_url": "https://arxiv.org/pdf/2509.00185v1",
    "published_date": "2025-08-29 18:37:54 UTC",
    "updated_date": "2025-08-29 18:37:54 UTC"
  },
  {
    "arxiv_id": "2509.00184v1",
    "title": "Virtual Group Knowledge and Group Belief in Topological Evidence Models (Extended Version)",
    "authors": [
      "Alexandru Baltag",
      "Malvin Gattinger",
      "Djanira Gomes"
    ],
    "abstract": "We study notions of (virtual) group knowledge and group belief within multi-agent evidence models, obtained by extending the topological semantics of evidence-based belief and fallible knowledge from individuals to groups. We completely axiomatize and show the decidability of the logic of (\"hard\" and \"soft\") group evidence, and do the same for an especially interesting fragment of it: the logic of group knowledge and group belief. We also extend these languages with dynamic evidence-sharing operators, and completely axiomatize the corresponding logics, showing that they are co-expressive with their static bases.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00184v1",
    "published_date": "2025-08-29 18:33:54 UTC",
    "updated_date": "2025-08-29 18:33:54 UTC"
  },
  {
    "arxiv_id": "2509.00176v1",
    "title": "Waste-Bench: A Comprehensive Benchmark for Evaluating VLLMs in Cluttered Environments",
    "authors": [
      "Muhammad Ali",
      "Salman Khan"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have paved the way for Vision Large Language Models (VLLMs) capable of performing a wide range of visual understanding tasks. While LLMs have demonstrated impressive performance on standard natural images, their capabilities have not been thoroughly explored in cluttered datasets where there is complex environment having deformed shaped objects. In this work, we introduce a novel dataset specifically designed for waste classification in real-world scenarios, characterized by complex environments and deformed shaped objects. Along with this dataset, we present an in-depth evaluation approach to rigorously assess the robustness and accuracy of VLLMs. The introduced dataset and comprehensive analysis provide valuable insights into the performance of VLLMs under challenging conditions. Our findings highlight the critical need for further advancements in VLLM's robustness to perform better in complex environments. The dataset and code for our experiments will be made publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00176v1",
    "published_date": "2025-08-29 18:22:48 UTC",
    "updated_date": "2025-08-29 18:22:48 UTC"
  },
  {
    "arxiv_id": "2509.00174v2",
    "title": "Principled Approximation Methods for Efficient and Scalable Deep Learning",
    "authors": [
      "Pedro Savarese"
    ],
    "abstract": "Recent progress in deep learning has been driven by increasingly larger models. However, their computational and energy demands have grown proportionally, creating significant barriers to their deployment and to a wider adoption of deep learning technologies. This thesis investigates principled approximation methods for improving the efficiency of deep learning systems, with a particular focus on settings that involve discrete constraints and non-differentiability.\n  We study three main approaches toward improved efficiency: architecture design, model compression, and optimization. For model compression, we propose novel approximations for pruning and quantization that frame the underlying discrete problem as continuous and differentiable, enabling gradient-based training of compression schemes alongside the model's parameters. These approximations allow for fine-grained sparsity and precision configurations, leading to highly compact models without significant fine-tuning. In the context of architecture design, we design an algorithm for neural architecture search that leverages parameter sharing across layers to efficiently explore implicitly recurrent architectures. Finally, we study adaptive optimization, revisiting theoretical properties of widely used methods and proposing an adaptive optimizer that allows for quick hyperparameter tuning.\n  Our contributions center on tackling computationally hard problems via scalable and principled approximations. Experimental results on image classification, language modeling, and generative modeling tasks show that the proposed methods provide significant improvements in terms of training and inference efficiency while maintaining, or even improving, the model's performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "PhD thesis",
    "pdf_url": "https://arxiv.org/pdf/2509.00174v2",
    "published_date": "2025-08-29 18:17:48 UTC",
    "updated_date": "2025-09-13 17:01:49 UTC"
  },
  {
    "arxiv_id": "2509.00167v3",
    "title": "Pilot Study on Generative AI and Critical Thinking in Higher Education Classrooms",
    "authors": [
      "W. F. Lamberti",
      "S. R. Lawrence",
      "D. White",
      "S. Kim",
      "S. Abdullah"
    ],
    "abstract": "Generative AI (GAI) tools have seen rapid adoption in educational settings, yet their role in fostering critical thinking remains underexplored. While previous studies have examined GAI as a tutor for specific lessons or as a tool for completing assignments, few have addressed how students critically evaluate the accuracy and appropriateness of GAI-generated responses. This pilot study investigates students' ability to apply structured critical thinking when assessing Generative AI outputs in introductory Computational and Data Science courses. Given that GAI tools often produce contextually flawed or factually incorrect answers, we designed learning activities that require students to analyze, critique, and revise AI-generated solutions. Our findings offer initial insights into students' ability to engage critically with GAI content and lay the groundwork for more comprehensive studies in future semesters.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "stat.AP"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00167v3",
    "published_date": "2025-08-29 18:07:11 UTC",
    "updated_date": "2025-09-08 18:37:35 UTC"
  },
  {
    "arxiv_id": "2508.21816v1",
    "title": "The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning",
    "authors": [
      "Yiming Lin",
      "Yuchen Niu",
      "Shang Wang",
      "Kaizhu Huang",
      "Qiufeng Wang",
      "Xiao-Bo Jin"
    ],
    "abstract": "Context recognition (SR) is a fundamental task in computer vision that aims to extract structured semantic summaries from images by identifying key events and their associated entities. Specifically, given an input image, the model must first classify the main visual events (verb classification), then identify the participating entities and their semantic roles (semantic role labeling), and finally localize these entities in the image (semantic role localization). Existing methods treat verb classification as a single-label problem, but we show through a comprehensive analysis that this formulation fails to address the inherent ambiguity in visual event recognition, as multiple verb categories may reasonably describe the same image. This paper makes three key contributions: First, we reveal through empirical analysis that verb classification is inherently a multi-label problem due to the ubiquitous semantic overlap between verb categories. Second, given the impracticality of fully annotating large-scale datasets with multiple labels, we propose to reformulate verb classification as a single positive multi-label learning (SPMLL) problem - a novel perspective in SR research. Third, we design a comprehensive multi-label evaluation benchmark for SR that is carefully designed to fairly evaluate model performance in a multi-label setting. To address the challenges of SPMLL, we futher develop the Graph Enhanced Verb Multilayer Perceptron (GE-VerbMLP), which combines graph neural networks to capture label correlations and adversarial training to optimize decision boundaries. Extensive experiments on real-world datasets show that our approach achieves more than 3\\% MAP improvement while remaining competitive on traditional top-1 and top-5 accuracy metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICDM 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.21816v1",
    "published_date": "2025-08-29 17:51:55 UTC",
    "updated_date": "2025-08-29 17:51:55 UTC"
  },
  {
    "arxiv_id": "2509.00141v1",
    "title": "Scaling Legal AI: Benchmarking Mamba and Transformers for Statutory Classification and Case Law Retrieval",
    "authors": [
      "Anuraj Maurya"
    ],
    "abstract": "The rapid growth of statutory corpora and judicial decisions requires scalable legal AI systems capable of classification and retrieval over extremely long contexts. Transformer-based architectures (e.g., Longformer, DeBERTa) dominate current legal NLP benchmarks but struggle with quadratic attention costs, limiting efficiency and scalability. In this work, we present the first comprehensive benchmarking of Mamba, a state-space model (SSM) with linear-time selective mechanisms, against leading transformer models for statutory classification and case law retrieval. We evaluate models on open-source legal corpora including LexGLUE, EUR-Lex, and ILDC, covering statutory tagging, judicial outcome prediction, and case retrieval tasks. Metrics include accuracy, recall at k, mean reciprocal rank (MRR), and normalized discounted cumulative gain (nDCG), alongside throughput measured in tokens per second and maximum context length. Results show that Mamba's linear scaling enables processing of legal documents several times longer than transformers, while maintaining or surpassing retrieval and classification performance. This study introduces a new legal NLP benchmark suite for long-context modeling, along with open-source code and datasets to support reproducibility. Our findings highlight trade-offs between state-space models and transformers, providing guidance for deploying scalable legal AI in statutory analysis, judicial decision support, and policy research.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00141v1",
    "published_date": "2025-08-29 17:38:47 UTC",
    "updated_date": "2025-08-29 17:38:47 UTC"
  },
  {
    "arxiv_id": "2508.21803v1",
    "title": "Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture",
    "authors": [
      "Yeawon Lee",
      "Xiaoyang Wang",
      "Christopher C. Yang"
    ],
    "abstract": "Accurate interpretation of clinical narratives is critical for patient care, but the complexity of these notes makes automation challenging. While Large Language Models (LLMs) show promise, single-model approaches can lack the robustness required for high-stakes clinical tasks. We introduce a collaborative multi-agent system (MAS) that models a clinical consultation team to address this gap. The system is tasked with identifying clinical problems by analyzing only the Subjective (S) and Objective (O) sections of SOAP notes, simulating the diagnostic reasoning process of synthesizing raw data into an assessment. A Manager agent orchestrates a dynamically assigned team of specialist agents who engage in a hierarchical, iterative debate to reach a consensus. We evaluated our MAS against a single-agent baseline on a curated dataset of 420 MIMIC-III notes. The dynamic multi-agent configuration demonstrated consistently improved performance in identifying congestive heart failure, acute kidney injury, and sepsis. Qualitative analysis of the agent debates reveals that this structure effectively surfaces and weighs conflicting evidence, though it can occasionally be susceptible to groupthink. By modeling a clinical team's reasoning process, our system offers a promising path toward more accurate, robust, and interpretable clinical decision support tools.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to The 16th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM-BCB 2025)(Poster Paper)",
    "pdf_url": "https://arxiv.org/pdf/2508.21803v1",
    "published_date": "2025-08-29 17:31:24 UTC",
    "updated_date": "2025-08-29 17:31:24 UTC"
  },
  {
    "arxiv_id": "2508.21800v2",
    "title": "Tree-Guided Diffusion Planner",
    "authors": [
      "Hyeonseong Jeon",
      "Cheolhong Min",
      "Jaesik Park"
    ],
    "abstract": "Planning with pretrained diffusion models has emerged as a promising approach for solving test-time guided control problems. Standard gradient guidance typically performs optimally under convex, differentiable reward landscapes. However, it shows substantially reduced effectiveness in real-world scenarios with non-convex objectives, non-differentiable constraints, and multi-reward structures. Furthermore, recent supervised planning approaches require task-specific training or value estimators, which limits test-time flexibility and zero-shot generalization. We propose a Tree-guided Diffusion Planner (TDP), a zero-shot test-time planning framework that balances exploration and exploitation through structured trajectory generation. We frame test-time planning as a tree search problem using a bi-level sampling process: (1) diverse parent trajectories are produced via training-free particle guidance to encourage broad exploration, and (2) sub-trajectories are refined through fast conditional denoising guided by task objectives. TDP addresses the limitations of gradient guidance by exploring diverse trajectory regions and harnessing gradient information across this expanded solution space using only pretrained models and test-time reward signals. We evaluate TDP on three diverse tasks: maze gold-picking, robot arm block manipulation, and AntMaze multi-goal exploration. TDP consistently outperforms state-of-the-art approaches on all tasks. The project page can be found at: https://tree-diffusion-planner.github.io.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.21800v2",
    "published_date": "2025-08-29 17:27:44 UTC",
    "updated_date": "2025-11-09 02:11:42 UTC"
  },
  {
    "arxiv_id": "2508.21797v1",
    "title": "DynaMark: A Reinforcement Learning Framework for Dynamic Watermarking in Industrial Machine Tool Controllers",
    "authors": [
      "Navid Aftabi",
      "Abhishek Hanchate",
      "Satish Bukkapatnam",
      "Dan Li"
    ],
    "abstract": "Industry 4.0's highly networked Machine Tool Controllers (MTCs) are prime targets for replay attacks that use outdated sensor data to manipulate actuators. Dynamic watermarking can reveal such tampering, but current schemes assume linear-Gaussian dynamics and use constant watermark statistics, making them vulnerable to the time-varying, partly proprietary behavior of MTCs. We close this gap with DynaMark, a reinforcement learning framework that models dynamic watermarking as a Markov decision process (MDP). It learns an adaptive policy online that dynamically adapts the covariance of a zero-mean Gaussian watermark using available measurements and detector feedback, without needing system knowledge. DynaMark maximizes a unique reward function balancing control performance, energy consumption, and detection confidence dynamically. We develop a Bayesian belief updating mechanism for real-time detection confidence in linear systems. This approach, independent of specific system assumptions, underpins the MDP for systems with linear dynamics. On a Siemens Sinumerik 828D controller digital twin, DynaMark achieves a reduction in watermark energy by 70% while preserving the nominal trajectory, compared to constant variance baselines. It also maintains an average detection delay equivalent to one sampling interval. A physical stepper-motor testbed validates these findings, rapidly triggering alarms with less control performance decline and exceeding existing benchmarks.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21797v1",
    "published_date": "2025-08-29 17:24:00 UTC",
    "updated_date": "2025-08-29 17:24:00 UTC"
  },
  {
    "arxiv_id": "2508.21795v1",
    "title": "TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection Models with a Text Memory Bank",
    "authors": [
      "Jiawei Liu",
      "Jiahe Hou",
      "Wei Wang",
      "Jinsong Du",
      "Yang Cong",
      "Huijie Fan"
    ],
    "abstract": "Anomaly detection, which aims to identify anomalies deviating from normal patterns, is challenging due to the limited amount of normal data available. Unlike most existing unified methods that rely on carefully designed image feature extractors and memory banks to capture logical relationships between objects, we introduce a text memory bank to enhance the detection of logical anomalies. Specifically, we propose a Three-Memory framework for Unified structural and logical Anomaly Detection (TMUAD). First, we build a class-level text memory bank for logical anomaly detection by the proposed logic-aware text extractor, which can capture rich logical descriptions of objects from input images. Second, we construct an object-level image memory bank that preserves complete object contours by extracting features from segmented objects. Third, we employ visual encoders to extract patch-level image features for constructing a patch-level memory bank for structural anomaly detection. These three complementary memory banks are used to retrieve and compare normal images that are most similar to the query image, compute anomaly scores at multiple levels, and fuse them into a final anomaly score. By unifying structural and logical anomaly detection through collaborative memory banks, TMUAD achieves state-of-the-art performance across seven publicly available datasets involving industrial and medical domains. The model and code are available at https://github.com/SIA-IDE/TMUAD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21795v1",
    "published_date": "2025-08-29 17:22:13 UTC",
    "updated_date": "2025-08-29 17:22:13 UTC"
  },
  {
    "arxiv_id": "2508.21793v1",
    "title": "MoE-Health: A Mixture of Experts Framework for Robust Multimodal Healthcare Prediction",
    "authors": [
      "Xiaoyang Wang",
      "Christopher C. Yang"
    ],
    "abstract": "Healthcare systems generate diverse multimodal data, including Electronic Health Records (EHR), clinical notes, and medical images. Effectively leveraging this data for clinical prediction is challenging, particularly as real-world samples often present with varied or incomplete modalities. Existing approaches typically require complete modality data or rely on manual selection strategies, limiting their applicability in real-world clinical settings where data availability varies across patients and institutions. To address these limitations, we propose MoE-Health, a novel Mixture of Experts framework designed for robust multimodal fusion in healthcare prediction. MoE-Health architecture is specifically developed to handle samples with differing modalities and improve performance on critical clinical tasks. By leveraging specialized expert networks and a dynamic gating mechanism, our approach dynamically selects and combines relevant experts based on available data modalities, enabling flexible adaptation to varying data availability scenarios. We evaluate MoE-Health on the MIMIC-IV dataset across three critical clinical prediction tasks: in-hospital mortality prediction, long length of stay, and hospital readmission prediction. Experimental results demonstrate that MoE-Health achieves superior performance compared to existing multimodal fusion methods while maintaining robustness across different modality availability patterns. The framework effectively integrates multimodal information, offering improved predictive performance and robustness in handling heterogeneous and incomplete healthcare data, making it particularly suitable for deployment in diverse healthcare environments with heterogeneous data availability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to The 16th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM-BCB 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.21793v1",
    "published_date": "2025-08-29 17:17:11 UTC",
    "updated_date": "2025-08-29 17:17:11 UTC"
  },
  {
    "arxiv_id": "2509.00140v2",
    "title": "LLM-based Zero-shot Triple Extraction for Automated Ontology Generation from Software Engineering Standards",
    "authors": [
      "Songhui Yue"
    ],
    "abstract": "Ontologies have supported knowledge representation and white-box reasoning for decades; thus, the automated ontology generation (AOG) plays a crucial role in scaling their use. Software engineering standards (SES) consist of long, unstructured text (with high noise) and paragraphs with domain-specific terms. In this setting, relation triple extraction (RTE), together with term extraction, constitutes the first stage toward AOG. This work proposes an open-source large language model (LLM)-assisted approach to RTE for SES. Instead of solely relying on prompt-engineering-based methods, this study promotes the use of LLMs as an aid in constructing ontologies and explores an effective AOG workflow that includes document segmentation, candidate term mining, LLM-based relation inference, term normalization, and cross-section alignment. Expert-annotated reference sets at three granularities are constructed and used to evaluate the ontology generated from the study. The results show that it is comparable and potentially superior to the OpenIE method of triple extraction.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Semantic Data Integration Workshop, held in conjunction with IEEE International Conference on Semantic Computing (IEEE ICSC 2026), accepted, 2026",
    "pdf_url": "https://arxiv.org/pdf/2509.00140v2",
    "published_date": "2025-08-29 17:14:54 UTC",
    "updated_date": "2026-01-10 00:28:48 UTC"
  },
  {
    "arxiv_id": "2508.21788v1",
    "title": "Going over Fine Web with a Fine-Tooth Comb: Technical Report of Indexing Fine Web for Problematic Content Search and Retrieval",
    "authors": [
      "Inés Altemir Marinas",
      "Anastasiia Kucherenko",
      "Andrei Kucharavy"
    ],
    "abstract": "Large language models (LLMs) rely heavily on web-scale datasets like Common Crawl, which provides over 80\\% of training data for some modern models. However, the indiscriminate nature of web crawling raises challenges in data quality, safety, and ethics. Despite the critical importance of training data quality, prior research on harmful content has been limited to small samples due to computational constraints. This project presents a framework for indexing and analyzing LLM training datasets using an ElasticSearch-based pipeline. We apply it to SwissAI's FineWeb-2 corpus (1.5TB, four languages), achieving fast query performance--most searches in milliseconds, all under 2 seconds. Our work demonstrates real-time dataset analysis, offering practical tools for safer, more accountable AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21788v1",
    "published_date": "2025-08-29 17:04:20 UTC",
    "updated_date": "2025-08-29 17:04:20 UTC"
  },
  {
    "arxiv_id": "2508.21787v1",
    "title": "PiCSAR: Probabilistic Confidence Selection And Ranking for Reasoning Chains",
    "authors": [
      "Joshua Ong Jun Leang",
      "Zheng Zhao",
      "Aryo Pradipta Gema",
      "Sohee Yang",
      "Wai-Chung Kwan",
      "Xuanli He",
      "Wenda Li",
      "Pasquale Minervini",
      "Eleonora Giunchiglia",
      "Shay B. Cohen"
    ],
    "abstract": "Best-of-n sampling improves the accuracy of large language models (LLMs) and large reasoning models (LRMs) by generating multiple candidate solutions and selecting the one with the highest reward. The key challenge for reasoning tasks is designing a scoring function that can identify correct reasoning chains without access to ground-truth answers. We propose Probabilistic Confidence Selection And Ranking (PiCSAR): a simple, training-free method that scores each candidate generation using the joint log-likelihood of the reasoning and final answer. The joint log-likelihood of the reasoning and final answer naturally decomposes into reasoning confidence and answer confidence. PiCSAR achieves substantial gains across diverse benchmarks (+10.18 on MATH500, +9.81 on AIME2025), outperforming baselines with at least 2x fewer samples in 16 out of 20 comparisons. Our analysis reveals that correct reasoning chains exhibit significantly higher reasoning and answer confidence, justifying the effectiveness of PiCSAR.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21787v1",
    "published_date": "2025-08-29 17:03:47 UTC",
    "updated_date": "2025-08-29 17:03:47 UTC"
  },
  {
    "arxiv_id": "2508.21777v1",
    "title": "Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight",
    "authors": [
      "Ugur Dinc",
      "Jibak Sarkar",
      "Philipp Schubert",
      "Sabine Semrau",
      "Thomas Weissmann",
      "Andre Karius",
      "Johann Brand",
      "Bernd-Niklas Axer",
      "Ahmed Gomaa",
      "Pluvio Stephan",
      "Ishita Sheth",
      "Sogand Beirami",
      "Annette Schwarz",
      "Udo Gaipl",
      "Benjamin Frey",
      "Christoph Bert",
      "Stefanie Corradini",
      "Rainer Fietkau",
      "Florian Putz"
    ],
    "abstract": "Introduction: Large language models (LLM) have shown great potential in clinical decision support. GPT-5 is a novel LLM system that has been specifically marketed towards oncology use.\n  Methods: Performance was assessed using two complementary benchmarks: (i) the ACR Radiation Oncology In-Training Examination (TXIT, 2021), comprising 300 multiple-choice items, and (ii) a curated set of 60 authentic radiation oncologic vignettes representing diverse disease sites and treatment indications. For the vignette evaluation, GPT-5 was instructed to generate concise therapeutic plans. Four board-certified radiation oncologists rated correctness, comprehensiveness, and hallucinations. Inter-rater reliability was quantified using Fleiss' \\k{appa}.\n  Results: On the TXIT benchmark, GPT-5 achieved a mean accuracy of 92.8%, outperforming GPT-4 (78.8%) and GPT-3.5 (62.1%). Domain-specific gains were most pronounced in Dose and Diagnosis. In the vignette evaluation, GPT-5's treatment recommendations were rated highly for correctness (mean 3.24/4, 95% CI: 3.11-3.38) and comprehensiveness (3.59/4, 95% CI: 3.49-3.69). Hallucinations were rare with no case reaching majority consensus for their presence. Inter-rater agreement was low (Fleiss' \\k{appa} 0.083 for correctness), reflecting inherent variability in clinical judgment. Errors clustered in complex scenarios requiring precise trial knowledge or detailed clinical adaptation.\n  Discussion: GPT-5 clearly outperformed prior model variants on the radiation oncology multiple-choice benchmark. Although GPT-5 exhibited favorable performance in generating real-world radiation oncology treatment recommendations, correctness ratings indicate room for further improvement. While hallucinations were infrequent, the presence of substantive errors underscores that GPT-5-generated recommendations require rigorous expert oversight before clinical implementation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review in Frontiers in Artificial Intelligence",
    "pdf_url": "https://arxiv.org/pdf/2508.21777v1",
    "published_date": "2025-08-29 16:55:25 UTC",
    "updated_date": "2025-08-29 16:55:25 UTC"
  },
  {
    "arxiv_id": "2508.21773v1",
    "title": "Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering",
    "authors": [
      "Nattapong Kurpukdee",
      "Adrian G. Bors"
    ],
    "abstract": "We propose a realistic scenario for the unsupervised video learning where neither task boundaries nor labels are provided when learning a succession of tasks. We also provide a non-parametric learning solution for the under-explored problem of unsupervised video continual learning. Videos represent a complex and rich spatio-temporal media information, widely used in many applications, but which have not been sufficiently explored in unsupervised continual learning. Prior studies have only focused on supervised continual learning, relying on the knowledge of labels and task boundaries, while having labeled data is costly and not practical. To address this gap, we study the unsupervised video continual learning (uVCL). uVCL raises more challenges due to the additional computational and memory requirements of processing videos when compared to images. We introduce a general benchmark experimental protocol for uVCL by considering the learning of unstructured video data categories during each task. We propose to use the Kernel Density Estimation (KDE) of deep embedded video features extracted by unsupervised video transformer networks as a non-parametric probabilistic representation of the data. We introduce a novelty detection criterion for the incoming new task data, dynamically enabling the expansion of memory clusters, aiming to capture new knowledge when learning a succession of tasks. We leverage the use of transfer learning from the previous tasks as an initial state for the knowledge transfer to the current learning task. We found that the proposed methodology substantially enhances the performance of the model when successively learning many tasks. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, without using any labels or class boundaries.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to The 36th British Machine Vision Conference (BMVC 2025), Sheffield, UK",
    "pdf_url": "https://arxiv.org/pdf/2508.21773v1",
    "published_date": "2025-08-29 16:49:03 UTC",
    "updated_date": "2025-08-29 16:49:03 UTC"
  },
  {
    "arxiv_id": "2508.21762v2",
    "title": "Reasoning-Intensive Regression",
    "authors": [
      "Diane Tchuindjo",
      "Omar Khattab"
    ],
    "abstract": "AI researchers and practitioners increasingly apply large language models (LLMs) to what we call reasoning-intensive regression (RiR), i.e., deducing subtle numerical scores from text. Unlike standard language regression tasks, e.g., for sentiment or similarity, RiR often appears instead in ad-hoc problems such as rubric-based scoring, modeling dense rewards in complex environments, or domain-specific retrieval, where much deeper analysis of context is required while only limited task-specific training data and computation are available. We cast four realistic problems as RiR tasks to establish an initial benchmark, and use that to test our hypothesis that prompting frozen LLMs and finetuning Transformer encoders via gradient descent will both often struggle in RiR. We then propose MENTAT, a simple and lightweight method that combines batch-reflective prompt optimization with neural ensemble learning. MENTAT achieves up to 65% improvement over both baselines, though substantial room remains for future advances in RiR.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21762v2",
    "published_date": "2025-08-29 16:37:42 UTC",
    "updated_date": "2025-11-30 11:18:48 UTC"
  },
  {
    "arxiv_id": "2509.06977v1",
    "title": "Toward Reproducible Cross-Backend Compatibility for Deep Learning: A Configuration-First Framework with Three-Tier Verification",
    "authors": [
      "Zehua Li"
    ],
    "abstract": "This paper presents a configuration-first framework for evaluating cross-backend compatibility in deep learning systems deployed on CPU, GPU, and compiled runtimes. The framework decouples experiments from code using YAML, supports both library and repository models, and employs a three-tier verification protocol covering tensor-level closeness, activation alignment, and task-level metrics. Through 672 checks across multiple models and tolerance settings, we observe that 72.0% of runs pass, with most discrepancies occurring under stricter thresholds. Our results show that detection models and compiled backends are particularly prone to drift, often due to nondeterministic post-processing. We further demonstrate that deterministic adapters and selective fallbacks can substantially improve agreement without significant performance loss. To our knowledge, this is the first unified framework that systematically quantifies and mitigates cross-backend drift in deep learning, providing a reproducible methodology for dependable deployment across heterogeneous runtimes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 7 figures, 3 tables, appendix, code available at https://github.com/william-zehua-li/cross-backend-model-checker",
    "pdf_url": "https://arxiv.org/pdf/2509.06977v1",
    "published_date": "2025-08-29 16:28:28 UTC",
    "updated_date": "2025-08-29 16:28:28 UTC"
  },
  {
    "arxiv_id": "2508.21742v1",
    "title": "Orientability of Causal Relations in Time Series using Summary Causal Graphs and Faithful Distributions",
    "authors": [
      "Timothée Loranchet",
      "Charles K. Assaad"
    ],
    "abstract": "Understanding causal relations between temporal variables is a central challenge in time series analysis, particularly when the full causal structure is unknown. Even when the full causal structure cannot be fully specified, experts often succeed in providing a high-level abstraction of the causal graph, known as a summary causal graph, which captures the main causal relations between different time series while abstracting away micro-level details. In this work, we present conditions that guarantee the orientability of micro-level edges between temporal variables given the background knowledge encoded in a summary causal graph and assuming having access to a faithful and causally sufficient distribution with respect to the true unknown graph. Our results provide theoretical guarantees for edge orientation at the micro-level, even in the presence of cycles or bidirected edges at the macro-level. These findings offer practical guidance for leveraging SCGs to inform causal discovery in complex temporal systems and highlight the value of incorporating expert knowledge to improve causal inference from observational time series data.",
    "categories": [
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21742v1",
    "published_date": "2025-08-29 16:08:35 UTC",
    "updated_date": "2025-08-29 16:08:35 UTC"
  },
  {
    "arxiv_id": "2508.21739v1",
    "title": "Neural Network Acceleration on MPSoC board: Integrating SLAC's SNL, Rogue Software and Auto-SNL",
    "authors": [
      "Hamza Ezzaoui Rahali",
      "Abhilasha Dave",
      "Larry Ruckman",
      "Mohammad Mehdi Rahimifar",
      "Audrey C. Therrien",
      "James J. Russel",
      "Ryan T. Herbst"
    ],
    "abstract": "The LCLS-II Free Electron Laser (FEL) will generate X-ray pulses for beamline experiments at rates of up to 1~MHz, with detectors producing data throughputs exceeding 1 TB/s. Managing such massive data streams presents significant challenges, as transmission and storage infrastructures become prohibitively expensive. Machine learning (ML) offers a promising solution for real-time data reduction, but conventional implementations introduce excessive latency, making them unsuitable for high-speed experimental environments. To address these challenges, SLAC developed the SLAC Neural Network Library (SNL), a specialized framework designed to deploy real-time ML inference models on Field-Programmable Gate Arrays (FPGA). SNL's key feature is the ability to dynamically update model weights without requiring FPGA resynthesis, enhancing flexibility for adaptive learning applications. To further enhance usability and accessibility, we introduce Auto-SNL, a Python extension that streamlines the process of converting Python-based neural network models into SNL-compatible high-level synthesis code. This paper presents a benchmark comparison against hls4ml, the current state-of-the-art tool, across multiple neural network architectures, fixed-point precisions, and synthesis configurations targeting a Xilinx ZCU102 FPGA. The results showed that SNL achieves competitive or superior latency in most tested architectures, while in some cases also offering FPGA resource savings. This adaptation demonstrates SNL's versatility, opening new opportunities for researchers and academics in fields such as high-energy physics, medical imaging, robotics, and many more.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21739v1",
    "published_date": "2025-08-29 16:04:15 UTC",
    "updated_date": "2025-08-29 16:04:15 UTC"
  },
  {
    "arxiv_id": "2508.21733v1",
    "title": "Developer Insights into Designing AI-Based Computer Perception Tools",
    "authors": [
      "Maya Guhan",
      "Meghan E. Hurley",
      "Eric A. Storch",
      "John Herrington",
      "Casey Zampella",
      "Julia Parish-Morris",
      "Gabriel Lázaro-Muñoz",
      "Kristin Kostick-Quenet"
    ],
    "abstract": "Artificial intelligence (AI)-based computer perception (CP) technologies use mobile sensors to collect behavioral and physiological data for clinical decision-making. These tools can reshape how clinical knowledge is generated and interpreted. However, effective integration of these tools into clinical workflows depends on how developers balance clinical utility with user acceptability and trustworthiness. Our study presents findings from 20 in-depth interviews with developers of AI-based CP tools. Interviews were transcribed and inductive, thematic analysis was performed to identify 4 key design priorities: 1) to account for context and ensure explainability for both patients and clinicians; 2) align tools with existing clinical workflows; 3) appropriately customize to relevant stakeholders for usability and acceptability; and 4) push the boundaries of innovation while aligning with established paradigms. Our findings highlight that developers view themselves as not merely technical architects but also ethical stewards, designing tools that are both acceptable by users and epistemically responsible (prioritizing objectivity and pushing clinical knowledge forward). We offer the following suggestions to help achieve this balance: documenting how design choices around customization are made, defining limits for customization choices, transparently conveying information about outputs, and investing in user training. Achieving these goals will require interdisciplinary collaboration between developers, clinicians, and ethicists.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "15 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.21733v1",
    "published_date": "2025-08-29 16:01:02 UTC",
    "updated_date": "2025-08-29 16:01:02 UTC"
  },
  {
    "arxiv_id": "2508.21732v1",
    "title": "CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models",
    "authors": [
      "João Valente",
      "Atabak Dehban",
      "Rodrigo Ventura"
    ],
    "abstract": "Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated impressive capabilities across various multimodal tasks. They continue, however, to struggle with trivial scenarios such as reading values from Digital Measurement Devices (DMDs), particularly in real-world conditions involving clutter, occlusions, extreme viewpoints, and motion blur; common in head-mounted cameras and Augmented Reality (AR) applications. Motivated by these limitations, this work introduces CAD2DMD-SET, a synthetic data generation tool designed to support visual question answering (VQA) tasks involving DMDs. By leveraging 3D CAD models, advanced rendering, and high-fidelity image composition, our tool produces diverse, VQA-labelled synthetic DMD datasets suitable for fine-tuning LVLMs. Additionally, we present DMDBench, a curated validation set of 1,000 annotated real-world images designed to evaluate model performance under practical constraints. Benchmarking three state-of-the-art LVLMs using Average Normalised Levenshtein Similarity (ANLS) and further fine-tuning LoRA's of these models with CAD2DMD-SET's generated dataset yielded substantial improvements, with InternVL showcasing a score increase of 200% without degrading on other tasks. This demonstrates that the CAD2DMD-SET training dataset substantially improves the robustness and performance of LVLMs when operating under the previously stated challenging conditions. The CAD2DMD-SET tool is expected to be released as open-source once the final version of this manuscript is prepared, allowing the community to add different measurement devices and generate their own datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21732v1",
    "published_date": "2025-08-29 15:57:43 UTC",
    "updated_date": "2025-08-29 15:57:43 UTC"
  },
  {
    "arxiv_id": "2508.21730v2",
    "title": "Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem",
    "authors": [
      "Fabrizio Fagiolo",
      "Nicolò Vescera"
    ],
    "abstract": "In this paper we present a variational algorithm for the Traveling Salesman Problem (TSP) that combines (i) a compact encoding of permutations, which reduces the qubit requirement too, (ii) an optimize-freeze-reuse strategy: where the circuit topology (``Ansatz'') is first optimized on a training instance by Simulated Annealing (SA), then ``frozen'' and re-used on novel instances, limited to a rapid re-optimization of only the circuit parameters. This pipeline eliminates costly structural research in testing, making the procedure immediately implementable on NISQ hardware.\n  On a set of $40$ randomly generated symmetric instances that span $4 - 7$ cities, the resulting Ansatz achieves an average optimal trip sampling probability of $100\\%$ for 4 city cases, $90\\%$ for 5 city cases and $80\\%$ for 6 city cases. With 7 cities the success rate drops markedly to an average of $\\sim 20\\%$, revealing the onset of scalability limitations of the proposed method.\n  The results show robust generalization ability for moderate problem sizes and indicate how freezing the Ansatz can dramatically reduce time-to-solution without degrading solution quality. The paper also discusses scalability limitations, the impact of ``warm-start'' initialization of parameters, and prospects for extension to more complex problems, such as Vehicle Routing and Job-Shop Scheduling.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21730v2",
    "published_date": "2025-08-29 15:56:16 UTC",
    "updated_date": "2025-10-28 11:27:51 UTC"
  },
  {
    "arxiv_id": "2509.02598v2",
    "title": "MIDOG 2025: Mitotic Figure Detection with Attention-Guided False Positive Correction",
    "authors": [
      "Andrew Broad",
      "Jason Keighley",
      "Lucy Godson",
      "Alex Wright"
    ],
    "abstract": "We present a novel approach which extends the existing Fully Convolutional One-Stage Object Detector (FCOS) for mitotic figure detection. Our composite model adds a Feedback Attention Ladder CNN (FAL-CNN) model for classification of normal versus abnormal mitotic figures, feeding into a fusion network that is trained to generate adjustments to bounding boxes predicted by FCOS. Our network aims to reduce the false positive rate of the FCOS object detector, to improve the accuracy of object detection and enhance the generalisability of the network. Our model achieved an F1 score of 0.655 for mitosis detection on the preliminary evaluation dataset.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02598v2",
    "published_date": "2025-08-29 15:55:22 UTC",
    "updated_date": "2025-09-18 13:21:39 UTC"
  },
  {
    "arxiv_id": "2509.16212v1",
    "title": "EPIC: Generative AI Platform for Accelerating HPC Operational Data Analytics",
    "authors": [
      "Ahmad Maroof Karimi",
      "Woong Shin",
      "Jesse Hines",
      "Tirthankar Ghosal",
      "Naw Safrin Sattar",
      "Feiyi Wang"
    ],
    "abstract": "We present EPIC, an AI-driven platform designed to augment operational data analytics. EPIC employs a hierarchical multi-agent architecture where a top-level large language model provides query processing, reasoning and synthesis capabilities. These capabilities orchestrate three specialized low-level agents for information retrieval, descriptive analytics, and predictive analytics. This architecture enables EPIC to perform HPC operational analytics on multi-modal data, including text, images, and tabular formats, dynamically and iteratively. EPIC addresses the limitations of existing HPC operational analytics approaches, which rely on static methods that struggle to adapt to evolving analytics tasks and stakeholder demands.\n  Through extensive evaluations on the Frontier HPC system, we demonstrate that EPIC effectively handles complex queries. Using descriptive analytics as a use case, fine-tuned smaller models outperform large state-of-the-art foundation models, achieving up to 26% higher accuracy. Additionally, we achieved 19x savings in LLM operational costs compared to proprietary solutions by employing a hybrid approach that combines large foundational models with fine-tuned local open-weight models.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.16212v1",
    "published_date": "2025-08-29 15:55:07 UTC",
    "updated_date": "2025-08-29 15:55:07 UTC"
  },
  {
    "arxiv_id": "2508.21727v1",
    "title": "OptMark: Robust Multi-bit Diffusion Watermarking via Inference Time Optimization",
    "authors": [
      "Jiazheng Xing",
      "Hai Ci",
      "Hongbin Xu",
      "Hangjie Yuan",
      "Yong Liu",
      "Mike Zheng Shou"
    ],
    "abstract": "Watermarking diffusion-generated images is crucial for copyright protection and user tracking. However, current diffusion watermarking methods face significant limitations: zero-bit watermarking systems lack the capacity for large-scale user tracking, while multi-bit methods are highly sensitive to certain image transformations or generative attacks, resulting in a lack of comprehensive robustness. In this paper, we propose OptMark, an optimization-based approach that embeds a robust multi-bit watermark into the intermediate latents of the diffusion denoising process. OptMark strategically inserts a structural watermark early to resist generative attacks and a detail watermark late to withstand image transformations, with tailored regularization terms to preserve image quality and ensure imperceptibility. To address the challenge of memory consumption growing linearly with the number of denoising steps during optimization, OptMark incorporates adjoint gradient methods, reducing memory usage from O(N) to O(1). Experimental results demonstrate that OptMark achieves invisible multi-bit watermarking while ensuring robust resilience against valuemetric transformations, geometric transformations, editing, and regeneration attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21727v1",
    "published_date": "2025-08-29 15:50:59 UTC",
    "updated_date": "2025-08-29 15:50:59 UTC"
  },
  {
    "arxiv_id": "2508.21720v1",
    "title": "PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation",
    "authors": [
      "Jiho Choi",
      "Seojeong Park",
      "Seongjong Song",
      "Hyunjung Shim"
    ],
    "abstract": "We present a novel training-free framework, \\textit{PosterForest}, for automated scientific poster generation. Unlike prior approaches, which largely neglect the hierarchical structure of scientific documents and the semantic integration of textual and visual elements, our method addresses both challenges directly. We introduce the \\textit{Poster Tree}, a hierarchical intermediate representation that jointly encodes document structure and visual-textual relationships at multiple levels. Our framework employs a multi-agent collaboration strategy, where agents specializing in content summarization and layout planning iteratively coordinate and provide mutual feedback. This approach enables the joint optimization of logical consistency, content fidelity, and visual coherence. Extensive experiments on multiple academic domains show that our method outperforms existing baselines in both qualitative and quantitative evaluations. The resulting posters achieve quality closest to expert-designed ground truth and deliver superior information preservation, structural clarity, and user preference.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21720v1",
    "published_date": "2025-08-29 15:36:06 UTC",
    "updated_date": "2025-08-29 15:36:06 UTC"
  },
  {
    "arxiv_id": "2508.21715v1",
    "title": "Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks",
    "authors": [
      "Amirhossein Nazeri",
      "Wael Hafez"
    ],
    "abstract": "Convolutional Neural Networks (CNNs) have become the foundation of modern computer vision, achieving unprecedented accuracy across diverse image recognition tasks. While these networks excel on in-distribution data, they remain vulnerable to adversarial perturbations imperceptible input modifications that cause misclassification with high confidence. However, existing detection methods either require expensive retraining, modify network architecture, or degrade performance on clean inputs. Here we show that adversarial perturbations create immediate, detectable entropy signatures in CNN activations that can be monitored without any model modification. Using parallel entropy monitoring on VGG-16, we demonstrate that adversarial inputs consistently shift activation entropy by 7% in early convolutional layers, enabling 90% detection accuracy with false positives and false negative rates below 20%. The complete separation between clean and adversarial entropy distributions reveals that CNNs inherently encode distribution shifts in their activation patterns. This work establishes that CNN reliability can be assessed through activation entropy alone, enabling practical deployment of self-diagnostic vision systems that detect adversarial inputs in real-time without compromising original model performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.IT",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 3 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.21715v1",
    "published_date": "2025-08-29 15:33:45 UTC",
    "updated_date": "2025-08-29 15:33:45 UTC"
  },
  {
    "arxiv_id": "2509.00135v1",
    "title": "Optimizing Health Coverage in Ethiopia: A Learning-augmented Approach and Persistent Proportionality Under an Online Budget",
    "authors": [
      "Davin Choo",
      "Yohai Trabelsi",
      "Fentabil Getnet",
      "Samson Warkaye Lamma",
      "Wondesen Nigatu",
      "Kasahun Sime",
      "Lisa Matay",
      "Milind Tambe",
      "Stéphane Verguet"
    ],
    "abstract": "As part of nationwide efforts aligned with the United Nations' Sustainable Development Goal 3 on Universal Health Coverage, Ethiopia's Ministry of Health is strengthening health posts to expand access to essential healthcare services. However, only a fraction of this health system strengthening effort can be implemented each year due to limited budgets and other competing priorities, thus the need for an optimization framework to guide prioritization across the regions of Ethiopia. In this paper, we develop a tool, Health Access Resource Planner (HARP), based on a principled decision-support optimization framework for sequential facility planning that aims to maximize population coverage under budget uncertainty while satisfying region-specific proportionality targets at every time step. We then propose two algorithms: (i) a learning-augmented approach that improves upon expert recommendations at any single-step; and (ii) a greedy algorithm for multi-step planning, both with strong worst-case approximation estimation. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we demonstrated the empirical efficacy of our method on three regions across various planning scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00135v1",
    "published_date": "2025-08-29 15:32:17 UTC",
    "updated_date": "2025-08-29 15:32:17 UTC"
  },
  {
    "arxiv_id": "2508.21693v1",
    "title": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR",
    "authors": [
      "Shashank Vempati",
      "Nishit Anand",
      "Gaurav Talebailkar",
      "Arpan Garai",
      "Chetan Arora"
    ],
    "abstract": "Conventional optical character recognition (OCR) techniques segmented each character and then recognized. This made them prone to error in character segmentation, and devoid of context to exploit language models. Advances in sequence to sequence translation in last decade led to modern techniques first detecting words and then inputting one word at a time to a model to directly output full words as sequence of characters. This allowed better utilization of language models and bypass error-prone character segmentation step. We observe that the above transition in style has moved the bottleneck in accuracy to word segmentation. Hence, in this paper, we propose a natural and logical progression from word level OCR to line-level OCR. The proposal allows to bypass errors in word detection, and provides larger sentence context for better utilization of language models. We show that the proposed technique not only improves the accuracy but also efficiency of OCR. Despite our thorough literature survey, we did not find any public dataset to train and benchmark such shift from word to line-level OCR. Hence, we also contribute a meticulously curated dataset of 251 English page images with line-level annotations. Our experimentation revealed a notable end-to-end accuracy improvement of 5.4%, underscoring the potential benefits of transitioning towards line-level OCR, especially for document images. We also report a 4 times improvement in efficiency compared to word-based pipelines. With continuous improvements in large language models, our methodology also holds potential to exploit such advances. Project Website: https://nishitanand.github.io/line-level-ocr-website",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages. Project Website: https://nishitanand.github.io/line-level-ocr-website",
    "pdf_url": "https://arxiv.org/pdf/2508.21693v1",
    "published_date": "2025-08-29 15:02:11 UTC",
    "updated_date": "2025-08-29 15:02:11 UTC"
  },
  {
    "arxiv_id": "2509.06976v1",
    "title": "A Knowledge-Guided Cross-Modal Feature Fusion Model for Local Traffic Demand Prediction",
    "authors": [
      "Lingyu Zhang",
      "Pengfei Xu",
      "Guobin Wu",
      "Jian Liang",
      "Ruiyang Dong",
      "Yunhai Wang",
      "Xuan Song"
    ],
    "abstract": "Traffic demand prediction plays a critical role in intelligent transportation systems. Existing traffic prediction models primarily rely on temporal traffic data, with limited efforts incorporating human knowledge and experience for urban traffic demand forecasting. However, in real-world scenarios, traffic knowledge and experience derived from human daily life significantly influence precise traffic prediction. Such knowledge and experiences can guide the model in uncovering latent patterns within traffic data, thereby enhancing the accuracy and robustness of predictions. To this end, this paper proposes integrating structured temporal traffic data with textual data representing human knowledge and experience, resulting in a novel knowledge-guided cross-modal feature representation learning (KGCM) model for traffic demand prediction. Based on regional transportation characteristics, we construct a prior knowledge dataset using a large language model combined with manual authoring and revision, covering both regional and global knowledge and experiences. The KGCM model then learns multimodal data features through designed local and global adaptive graph networks, as well as a cross-modal feature fusion mechanism. A proposed reasoning-based dynamic update strategy enables dynamic optimization of the graph model's parameters, achieving optimal performance. Experiments on multiple traffic datasets demonstrate that our model accurately predicts future traffic demand and outperforms existing state-of-the-art (SOTA) models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06976v1",
    "published_date": "2025-08-29 14:52:50 UTC",
    "updated_date": "2025-08-29 14:52:50 UTC"
  },
  {
    "arxiv_id": "2509.04471v2",
    "title": "MOSAIC: A Multilingual, Taxonomy-Agnostic, and Computationally Efficient Approach for Radiological Report Classification",
    "authors": [
      "Alice Schiavone",
      "Marco Fraccaro",
      "Lea Marie Pehrson",
      "Silvia Ingala",
      "Rasmus Bonnevie",
      "Michael Bachmann Nielsen",
      "Vincent Beliveau",
      "Melanie Ganz",
      "Desmond Elliott"
    ],
    "abstract": "Radiology reports contain rich clinical information that can be used to train imaging models without relying on costly manual annotation. However, existing approaches face critical limitations: rule-based methods struggle with linguistic variability, supervised models require large annotated datasets, and recent LLM-based systems depend on closed-source or resource-intensive models that are unsuitable for clinical use. Moreover, current solutions are largely restricted to English and single-modality, single-taxonomy datasets. We introduce MOSAIC, a multilingual, taxonomy-agnostic, and computationally efficient approach for radiological report classification. Built on a compact open-access language model (MedGemma-4B), MOSAIC supports both zero-/few-shot prompting and lightweight fine-tuning, enabling deployment on consumer-grade GPUs. We evaluate MOSAIC across seven datasets in English, Spanish, French, and Danish, spanning multiple imaging modalities and label taxonomies. The model achieves a mean macro F1 score of 88 across five chest X-ray datasets, approaching or exceeding expert-level performance, while requiring only 24 GB of GPU memory. With data augmentation, as few as 80 annotated samples are sufficient to reach a weighted F1 score of 82 on Danish reports, compared to 86 with the full 1600-sample training set. MOSAIC offers a practical alternative to large or proprietary LLMs in clinical settings. Code and models are open-source. We invite the community to evaluate and extend MOSAIC on new languages, taxonomies, and modalities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 14 pages including references and appendix. 9 figures. Preprint",
    "pdf_url": "https://arxiv.org/pdf/2509.04471v2",
    "published_date": "2025-08-29 14:35:00 UTC",
    "updated_date": "2025-10-02 08:59:44 UTC"
  },
  {
    "arxiv_id": "2509.22661v2",
    "title": "Next Point-of-interest (POI) Recommendation Model Based on Multi-modal Spatio-temporal Context Feature Embedding",
    "authors": [
      "Lingyu Zhang",
      "Pengfei Xu",
      "Rui Ban",
      "Zhenchao Zhang",
      "Songtao Liu",
      "Yan Wang",
      "Yunhai Wang"
    ],
    "abstract": "Predicting the next pickup location of individual users is a fundamental problem in intelligent mobility systems, which requires modeling personalized travel behaviors under complex spatiotemporal contexts. Existing methods mainly learn sequential dependencies from raw trajectories, but often fail to capture high-level behavioral semantics and to effectively disentangle long-term habitual preferences from short-term contextual intentions. In this paper, we propose a semantic embedding based dual stream spatiotemporal attention model for next pickup location prediction. Raw trajectories are first transformed into semantically enriched activity sequences to encode users' stay behaviors and movement semantics. A dual stream architecture is then designed to explicitly decouple long-term historical patterns and short-term dynamic intentions, where each stream employs spatiotemporal attention mechanisms to model dependencies at different temporal scales. To integrate heterogeneous contextual information, a context aware dynamic fusion module adaptively balances the contributions of the two streams. Finally, an attention based matching strategy is used to predict the probability distribution over candidate pickup locations. Experiments on real world ride hailing datasets demonstrate that the proposed model consistently outperforms state of the art methods, validating the effectiveness of semantic trajectory abstraction and dual stream spatiotemporal attention for individualized mobility behavior modeling.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.22661v2",
    "published_date": "2025-08-29 14:33:56 UTC",
    "updated_date": "2026-01-21 01:20:59 UTC"
  },
  {
    "arxiv_id": "2508.21666v2",
    "title": "Harnessing IoT and Generative AI for Weather-Adaptive Learning in Climate Resilience Education",
    "authors": [
      "Imran S. A. Khan",
      "Emmanuel G. Blanchard",
      "Sébastien George"
    ],
    "abstract": "This paper introduces the Future Atmospheric Conditions Training System (FACTS), a novel platform that advances climate resilience education through place-based, adaptive learning experiences. FACTS combines real-time atmospheric data collected by IoT sensors with curated resources from a Knowledge Base to dynamically generate localized learning challenges. Learner responses are analyzed by a Generative AI powered server, which delivers personalized feedback and adaptive support. Results from a user evaluation indicate that participants found the system both easy to use and effective for building knowledge related to climate resilience. These findings suggest that integrating IoT and Generative AI into atmospherically adaptive learning technologies holds significant promise for enhancing educational engagement and fostering climate awareness.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "Not enough evidence to prove the effectiveness of the system in the context of learning about climate change",
    "pdf_url": "https://arxiv.org/pdf/2508.21666v2",
    "published_date": "2025-08-29 14:30:06 UTC",
    "updated_date": "2025-11-04 16:22:04 UTC"
  },
  {
    "arxiv_id": "2509.00132v1",
    "title": "CoComposer: LLM Multi-agent Collaborative Music Composition",
    "authors": [
      "Peiwen Xing",
      "Aske Plaat",
      "Niki van Stein"
    ],
    "abstract": "Existing AI Music composition tools are limited in generation duration, musical quality, and controllability. We introduce CoComposer, a multi-agent system that consists of five collaborating agents, each with a task based on the traditional music composition workflow. Using the AudioBox-Aesthetics system, we experimentally evaluate CoComposer on four compositional criteria. We test with three LLMs (GPT-4o, DeepSeek-V3-0324, Gemini-2.5-Flash), and find (1) that CoComposer outperforms existing multi-agent LLM-based systems in music quality, and (2) compared to a single-agent system, in production complexity. Compared to non- LLM MusicLM, CoComposer has better interpretability and editability, although MusicLM still produces better music.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00132v1",
    "published_date": "2025-08-29 14:15:12 UTC",
    "updated_date": "2025-08-29 14:15:12 UTC"
  },
  {
    "arxiv_id": "2508.21648v1",
    "title": "Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI",
    "authors": [
      "Farhad Abtahi",
      "Mehdi Astaraki",
      "Fernando Seoane"
    ],
    "abstract": "Bias in medical artificial intelligence is conventionally viewed as a defect requiring elimination. However, human reasoning inherently incorporates biases shaped by education, culture, and experience, suggesting their presence may be inevitable and potentially valuable. We propose MEDLEY (Medical Ensemble Diagnostic system with Leveraged diversitY), a conceptual framework that orchestrates multiple AI models while preserving their diverse outputs rather than collapsing them into a consensus. Unlike traditional approaches that suppress disagreement, MEDLEY documents model-specific biases as potential strengths and treats hallucinations as provisional hypotheses for clinician verification. A proof-of-concept demonstrator was developed using over 30 large language models, creating a minimum viable product that preserved both consensus and minority views in synthetic cases, making diagnostic uncertainty and latent biases transparent for clinical oversight. While not yet a validated clinical tool, the demonstration illustrates how structured diversity can enhance medical reasoning under clinician supervision. By reframing AI imperfection as a resource, MEDLEY offers a paradigm shift that opens new regulatory, ethical, and innovation pathways for developing trustworthy medical AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21648v1",
    "published_date": "2025-08-29 14:12:03 UTC",
    "updated_date": "2025-08-29 14:12:03 UTC"
  },
  {
    "arxiv_id": "2508.21637v1",
    "title": "A-MHA*: Anytime Multi-Heuristic A*",
    "authors": [
      "Ramkumar Natarajan",
      "Muhammad Suhail Saleem",
      "William Xiao",
      "Sandip Aine",
      "Howie Choset",
      "Maxim Likhachev"
    ],
    "abstract": "Designing good heuristic functions for graph search requires adequate domain knowledge. It is often easy to design heuristics that perform well and correlate with the underlying true cost-to-go values in certain parts of the search space but these may not be admissible throughout the domain thereby affecting the optimality guarantees of the search. Bounded suboptimal search using several such partially good but inadmissible heuristics was developed in Multi-Heuristic A* (MHA*). Although MHA* leverages multiple inadmissible heuristics to potentially generate a faster suboptimal solution, the original version does not improve the solution over time. It is a one shot algorithm that requires careful setting of inflation factors to obtain a desired one time solution. In this work, we tackle this issue by extending MHA* to an anytime version that finds a feasible suboptimal solution quickly and continually improves it until time runs out. Our work is inspired from the Anytime Repairing A* (ARA*) algorithm. We prove that our precise adaptation of ARA* concepts in the MHA* framework preserves the original suboptimal and completeness guarantees and enhances MHA* to perform in an anytime fashion. Furthermore, we report the performance of A-MHA* in 3-D path planning domain and sliding tiles puzzle and compare against MHA* and other anytime algorithms.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21637v1",
    "published_date": "2025-08-29 14:00:45 UTC",
    "updated_date": "2025-08-29 14:00:45 UTC"
  },
  {
    "arxiv_id": "2508.21632v1",
    "title": "QZhou-Embedding Technical Report",
    "authors": [
      "Peng Yu",
      "En Xu",
      "Bin Chen",
      "Haibiao Chen",
      "Yinfei Xu"
    ],
    "abstract": "We present QZhou-Embedding, a general-purpose contextual text embedding model with exceptional text representation capabilities. Built upon the Qwen2.5-7B-Instruct foundation model, we designed a unified multi-task framework comprising specialized data transformation and training strategies. The data transformation scheme enables the incorporation of more diverse textual training datasets, while the task-specific training strategies enhance model learning efficiency. We developed a data synthesis pipeline leveraging LLM API, incorporating techniques such as paraphrasing, augmentation, and hard negative example generation to improve the semantic richness and sample difficulty of the training set. Additionally, we employ a two-stage training strategy, comprising initial retrieval-focused pretraining followed by full-task fine-tuning, enabling the embedding model to extend its capabilities based on robust retrieval performance. Our model achieves state-of-the-art results on the MTEB and CMTEB benchmarks, ranking first on both leaderboards (August 27 2025), and simultaneously achieves state-of-the-art performance on tasks including reranking, clustering, etc. Our findings demonstrate that higher-quality, more diverse data is crucial for advancing retrieval model performance, and that leveraging LLMs generative capabilities can further optimize data quality for embedding model breakthroughs. Our model weights are released on HuggingFace under Apache 2.0 license. For reproducibility, we provide evaluation code and instructions on GitHub.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21632v1",
    "published_date": "2025-08-29 13:47:22 UTC",
    "updated_date": "2025-08-29 13:47:22 UTC"
  },
  {
    "arxiv_id": "2508.21622v1",
    "title": "Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study",
    "authors": [
      "Saravanan Venkatachalam"
    ],
    "abstract": "This paper presents an integrated framework that combines traditional network optimization models with large language models (LLMs) to deliver interactive, explainable, and role-aware decision support for supply chain planning. The proposed system bridges the gap between complex operations research outputs and business stakeholder understanding by generating natural language summaries, contextual visualizations, and tailored key performance indicators (KPIs). The core optimization model addresses tactical inventory redistribution across a network of distribution centers for multi-period and multi-item, using a mixed-integer formulation. The technical architecture incorporates AI agents, RESTful APIs, and a dynamic user interface to support real-time interaction, configuration updates, and simulation-based insights. A case study demonstrates how the system improves planning outcomes by preventing stockouts, reducing costs, and maintaining service levels. Future extensions include integrating private LLMs, transfer learning, reinforcement learning, and Bayesian neural networks to enhance explainability, adaptability, and real-time decision-making.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21622v1",
    "published_date": "2025-08-29 13:34:55 UTC",
    "updated_date": "2025-08-29 13:34:55 UTC"
  },
  {
    "arxiv_id": "2509.07993v1",
    "title": "Revisiting Deepfake Detection: Chronological Continual Learning and the Limits of Generalization",
    "authors": [
      "Federico Fontana",
      "Anxhelo Diko",
      "Romeo Lanzino",
      "Marco Raoul Marini",
      "Bachir Kaddar",
      "Gian Luca Foresti",
      "Luigi Cinque"
    ],
    "abstract": "The rapid evolution of deepfake generation technologies poses critical challenges for detection systems, as non-continual learning methods demand frequent and expensive retraining. We reframe deepfake detection (DFD) as a Continual Learning (CL) problem, proposing an efficient framework that incrementally adapts to emerging visual manipulation techniques while retaining knowledge of past generators. Our framework, unlike prior approaches that rely on unreal simulation sequences, simulates the real-world chronological evolution of deepfake technologies in extended periods across 7 years. Simultaneously, our framework builds upon lightweight visual backbones to allow for the real-time performance of DFD systems. Additionally, we contribute two novel metrics: Continual AUC (C-AUC) for historical performance and Forward Transfer AUC (FWT-AUC) for future generalization. Through extensive experimentation (over 600 simulations), we empirically demonstrate that while efficient adaptation (+155 times faster than full retraining) and robust retention of historical knowledge is possible, the generalization of current approaches to future generators without additional training remains near-random (FWT-AUC $\\approx$ 0.5) due to the unique imprint characterizing each existing generator. Such observations are the foundation of our newly proposed Non-Universal Deepfake Distribution Hypothesis.\n  \\textbf{Code will be released upon acceptance.}",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.07993v1",
    "published_date": "2025-08-29 13:34:21 UTC",
    "updated_date": "2025-08-29 13:34:21 UTC"
  },
  {
    "arxiv_id": "2508.21618v1",
    "title": "Physics-Informed Spectral Modeling for Hyperspectral Imaging",
    "authors": [
      "Zuzanna Gawrysiak",
      "Krzysztof Krawiec"
    ],
    "abstract": "We present PhISM, a physics-informed deep learning architecture that learns without supervision to explicitly disentangle hyperspectral observations and model them with continuous basis functions. \\mname outperforms prior methods on several classification and regression benchmarks, requires limited labeled data, and provides additional insights thanks to interpretable latent representation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21618v1",
    "published_date": "2025-08-29 13:32:07 UTC",
    "updated_date": "2025-08-29 13:32:07 UTC"
  },
  {
    "arxiv_id": "2509.05315v1",
    "title": "Evaluation of Large Language Models for Anomaly Detection in Autonomous Vehicles",
    "authors": [
      "Petros Loukas",
      "David Bassir",
      "Savvas Chatzichristofis",
      "Angelos Amanatiadis"
    ],
    "abstract": "The rapid evolution of large language models (LLMs) has pushed their boundaries to many applications in various domains. Recently, the research community has started to evaluate their potential adoption in autonomous vehicles and especially as complementary modules in the perception and planning software stacks. However, their evaluation is limited in synthetic datasets or manually driving datasets without the ground truth knowledge and more precisely, how the current perception and planning algorithms would perform in the cases under evaluation. For this reason, this work evaluates LLMs on real-world edge cases where current autonomous vehicles have been proven to fail. The proposed architecture consists of an open vocabulary object detector coupled with prompt engineering and large language model contextual reasoning. We evaluate several state-of-the-art models against real edge cases and provide qualitative comparison results along with a discussion on the findings for the potential application of LLMs as anomaly detectors in autonomous vehicles.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.05315v1",
    "published_date": "2025-08-29 13:05:13 UTC",
    "updated_date": "2025-08-29 13:05:13 UTC"
  },
  {
    "arxiv_id": "2508.21595v1",
    "title": "Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics",
    "authors": [
      "Yang You",
      "Alex Schutz",
      "Zhikun Li",
      "Bruno Lacerda",
      "Robert Skilton",
      "Nick Hawes"
    ],
    "abstract": "Many high-level multi-agent planning problems, including multi-robot navigation and path planning, can be effectively modeled using deterministic actions and observations.\n  In this work, we focus on such domains and introduce the class of Deterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of Dec-POMDPs characterized by deterministic transitions and observations conditioned on the state and joint actions.\n  We then propose a practical solver called Iterative Deterministic POMDP Planning (IDPP). This method builds on the classic Joint Equilibrium Search for Policies framework and is specifically optimized to handle large-scale Det-Dec-POMDPs that current Dec-POMDP solvers are unable to address efficiently.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21595v1",
    "published_date": "2025-08-29 12:50:10 UTC",
    "updated_date": "2025-08-29 12:50:10 UTC"
  },
  {
    "arxiv_id": "2508.21589v5",
    "title": "Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning",
    "authors": [
      "Zinan Tang",
      "Xin Gao",
      "Qizhi Pei",
      "Zhuoshi Pan",
      "Mengzhang Cai",
      "Jiang Wu",
      "Conghui He",
      "Lijun Wu"
    ],
    "abstract": "Supervised Fine-Tuning (SFT) Large Language Models (LLM) fundamentally rely on high-quality training data. While data selection and data synthesis are two common strategies to improve data quality, existing approaches often face limitations in static dataset curation that fail to adapt to evolving model capabilities. In this paper, we introduce Middo, a self-evolving Model-informed dynamic data optimization framework that uses model-aware data selection and context-preserving data refinement. Unlike conventional one-off filtering/synthesis methods, our framework establishes a closed-loop optimization system: (1) A self-referential diagnostic module proactively identifies suboptimal samples through tri-axial model signals - loss patterns (complexity), embedding cluster dynamics (diversity), and self-alignment scores (quality); (2) An adaptive optimization engine then transforms suboptimal samples into pedagogically valuable training points while preserving semantic integrity; (3) This optimization process continuously evolves with model capability through dynamic learning principles. Experiments on multiple benchmarks demonstrate that our Middo consistently enhances the quality of seed data and boosts LLM's performance with improving accuracy by 7.15% on average while maintaining the original dataset scale. This work establishes a new paradigm for sustainable LLM training through dynamic human-AI co-evolution of data and models. Our datasets, models, and code are publicly available at https://github.com/Word2VecT/Middo.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2025 (Main)",
    "pdf_url": "https://arxiv.org/pdf/2508.21589v5",
    "published_date": "2025-08-29 12:47:27 UTC",
    "updated_date": "2025-10-22 11:09:23 UTC"
  },
  {
    "arxiv_id": "2508.21587v1",
    "title": "A Survey on Current Trends and Recent Advances in Text Anonymization",
    "authors": [
      "Tobias Deußer",
      "Lorenz Sparrenberg",
      "Armin Berger",
      "Max Hahnbück",
      "Christian Bauckhage",
      "Rafet Sifa"
    ],
    "abstract": "The proliferation of textual data containing sensitive personal information across various domains requires robust anonymization techniques to protect privacy and comply with regulations, while preserving data usability for diverse and crucial downstream tasks. This survey provides a comprehensive overview of current trends and recent advances in text anonymization techniques. We begin by discussing foundational approaches, primarily centered on Named Entity Recognition, before examining the transformative impact of Large Language Models, detailing their dual role as sophisticated anonymizers and potent de-anonymization threats. The survey further explores domain-specific challenges and tailored solutions in critical sectors such as healthcare, law, finance, and education. We investigate advanced methodologies incorporating formal privacy models and risk-aware frameworks, and address the specialized subfield of authorship anonymization. Additionally, we review evaluation frameworks, comprehensive metrics, benchmarks, and practical toolkits for real-world deployment of anonymization solutions. This review consolidates current knowledge, identifies emerging trends and persistent challenges, including the evolving privacy-utility trade-off, the need to address quasi-identifiers, and the implications of LLM capabilities, and aims to guide future research directions for both academics and practitioners in this field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at IEEE DSAA 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.21587v1",
    "published_date": "2025-08-29 12:43:06 UTC",
    "updated_date": "2025-08-29 12:43:06 UTC"
  },
  {
    "arxiv_id": "2508.21566v2",
    "title": "NSPDI-SNN: An efficient lightweight SNN based on nonlinear synaptic pruning and dendritic integration",
    "authors": [
      "Wuque Cai",
      "Hongze Sun",
      "Jiayi He",
      "Qianqian Liao",
      "Yunliang Zang",
      "Duo Chen",
      "Dezhong Yao",
      "Daqing Guo"
    ],
    "abstract": "Spiking neural networks (SNNs) are artificial neural networks based on simulated biological neurons and have attracted much attention in recent artificial intelligence technology studies. The dendrites in biological neurons have efficient information processing ability and computational power; however, the neurons of SNNs rarely match the complex structure of the dendrites. Inspired by the nonlinear structure and highly sparse properties of neuronal dendrites, in this study, we propose an efficient, lightweight SNN method with nonlinear pruning and dendritic integration (NSPDI-SNN). In this method, we introduce nonlinear dendritic integration (NDI) to improve the representation of the spatiotemporal information of neurons. We implement heterogeneous state transition ratios of dendritic spines and construct a new and flexible nonlinear synaptic pruning (NSP) method to achieve the high sparsity of SNN. We conducted systematic experiments on three benchmark datasets (DVS128 Gesture, CIFAR10-DVS, and CIFAR10) and extended the evaluation to two complex tasks (speech recognition and reinforcement learning-based maze navigation task). Across all tasks, NSPDI-SNN consistently achieved high sparsity with minimal performance degradation. In particular, our method achieved the best experimental results on all three event stream datasets. Further analysis showed that NSPDI significantly improved the efficiency of synaptic information transfer as sparsity increased. In conclusion, our results indicate that the complex structure and nonlinear computation of neuronal dendrites provide a promising approach for developing efficient SNN methods.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "q-bio.NC",
    "comment": "16 pages, 9 figures, 7 tables; This manuscript has been submitted for possible pulication",
    "pdf_url": "https://arxiv.org/pdf/2508.21566v2",
    "published_date": "2025-08-29 12:22:00 UTC",
    "updated_date": "2025-10-13 11:27:05 UTC"
  },
  {
    "arxiv_id": "2508.21564v1",
    "title": "Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances",
    "authors": [
      "Issa Hanou",
      "Sebastijan Dumančić",
      "Mathijs de Weerdt"
    ],
    "abstract": "We propose a new framework for discovering landmarks that automatically generalize across a domain. These generalized landmarks are learned from a set of solved instances and describe intermediate goals for planning problems where traditional landmark extraction algorithms fall short. Our generalized landmarks extend beyond the predicates of a domain by using state functions that are independent of the objects of a specific problem and apply to all similar objects, thus capturing repetition. Based on these functions, we construct a directed generalized landmark graph that defines the landmark progression, including loop possibilities for repetitive subplans. We show how to use this graph in a heuristic to solve new problem instances of the same domain. Our results show that the generalized landmark graphs learned from a few small instances are also effective for larger instances in the same domain. If a loop that indicates repetition is identified, we see a significant improvement in heuristic performance over the baseline. Generalized landmarks capture domain information that is interpretable and useful to an automated planner. This information can be discovered from a small set of plans for the same domain.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21564v1",
    "published_date": "2025-08-29 12:21:44 UTC",
    "updated_date": "2025-08-29 12:21:44 UTC"
  },
  {
    "arxiv_id": "2510.08576v2",
    "title": "Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions",
    "authors": [
      "Justus Flerlage",
      "Alexander Acker",
      "Odej Kao"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as transformative tools for natural language understanding and user intent resolution, enabling tasks such as translation, summarization, and, increasingly, the orchestration of complex workflows. This development signifies a paradigm shift from conventional, GUI-driven user interfaces toward intuitive, language-first interaction paradigms. Rather than manually navigating applications, users can articulate their objectives in natural language, enabling LLMs to orchestrate actions across multiple applications in a dynamic and contextual manner. However, extant implementations frequently rely on cloud-based proprietary models, which introduce limitations in terms of privacy, autonomy, and scalability. For language-first interaction to become a truly robust and trusted interface paradigm, local deployment is not merely a convenience; it is an imperative. This limitation underscores the importance of evaluating the feasibility of locally deployable, open-source, and open-access LLMs as foundational components for future intent-based operating systems. In this study, we examine the capabilities of several open-source and open-access models in facilitating user intention resolution through machine assistance. A comparative analysis is conducted against OpenAI's proprietary GPT-4-based systems to assess performance in generating workflows for various user intentions. The present study offers empirical insights into the practical viability, performance trade-offs, and potential of open LLMs as autonomous, locally operable components in next-generation operating systems. The results of this study inform the broader discussion on the decentralization and democratization of AI infrastructure and point toward a future where user-device interaction becomes more seamless, adaptive, and privacy-conscious through locally embedded intelligence.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at First International Workshop on Human-AI Collaborative Systems (HAIC), published in CEUR-WS.org Vol-4072 (2025). URN: urn:nbn:de:0074-4072-x",
    "pdf_url": "https://arxiv.org/pdf/2510.08576v2",
    "published_date": "2025-08-29 12:17:33 UTC",
    "updated_date": "2025-11-11 14:36:59 UTC"
  },
  {
    "arxiv_id": "2508.21559v1",
    "title": "Limitations of Physics-Informed Neural Networks: a Study on Smart Grid Surrogation",
    "authors": [
      "Julen Cestero",
      "Carmine Delle Femine",
      "Kenji S. Muro",
      "Marco Quartulli",
      "Marcello Restelli"
    ],
    "abstract": "Physics-Informed Neural Networks (PINNs) present a transformative approach for smart grid modeling by integrating physical laws directly into learning frameworks, addressing critical challenges of data scarcity and physical consistency in conventional data-driven methods. This paper evaluates PINNs' capabilities as surrogate models for smart grid dynamics, comparing their performance against XGBoost, Random Forest, and Linear Regression across three key experiments: interpolation, cross-validation, and episodic trajectory prediction. By training PINNs exclusively through physics-based loss functions (enforcing power balance, operational constraints, and grid stability) we demonstrate their superior generalization, outperforming data-driven models in error reduction. Notably, PINNs maintain comparatively lower MAE in dynamic grid operations, reliably capturing state transitions in both random and expert-driven control scenarios, while traditional models exhibit erratic performance. Despite slight degradation in extreme operational regimes, PINNs consistently enforce physical feasibility, proving vital for safety-critical applications. Our results contribute to establishing PINNs as a paradigm-shifting tool for smart grid surrogation, bridging data-driven flexibility with first-principles rigor. This work advances real-time grid control and scalable digital twins, emphasizing the necessity of physics-aware architectures in mission-critical energy systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented in PowerTech2025",
    "pdf_url": "https://arxiv.org/pdf/2508.21559v1",
    "published_date": "2025-08-29 12:15:32 UTC",
    "updated_date": "2025-08-29 12:15:32 UTC"
  },
  {
    "arxiv_id": "2508.21550v1",
    "title": "EZ-Sort: Efficient Pairwise Comparison via Zero-Shot CLIP-Based Pre-Ordering and Human-in-the-Loop Sorting",
    "authors": [
      "Yujin Park",
      "Haejun Chung",
      "Ikbeom Jang"
    ],
    "abstract": "Pairwise comparison is often favored over absolute rating or ordinal classification in subjective or difficult annotation tasks due to its improved reliability. However, exhaustive comparisons require a massive number of annotations (O(n^2)). Recent work has greatly reduced the annotation burden (O(n log n)) by actively sampling pairwise comparisons using a sorting algorithm. We further improve annotation efficiency by (1) roughly pre-ordering items using the Contrastive Language-Image Pre-training (CLIP) model hierarchically without training, and (2) replacing easy, obvious human comparisons with automated comparisons. The proposed EZ-Sort first produces a CLIP-based zero-shot pre-ordering, then initializes bucket-aware Elo scores, and finally runs an uncertainty-guided human-in-the-loop MergeSort. Validation was conducted using various datasets: face-age estimation (FGNET), historical image chronology (DHCI), and retinal image quality assessment (EyePACS). It showed that EZ-Sort reduced human annotation cost by 90.5% compared to exhaustive pairwise comparisons and by 19.8% compared to prior work (when n = 100), while improving or maintaining inter-rater reliability. These results demonstrate that combining CLIP-based priors with uncertainty-aware sampling yields an efficient and scalable solution for pairwise ranking.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 2 figures, Accepted at CIKM 2025 (ACM International Conference on Information and Knowledge Management)",
    "pdf_url": "https://arxiv.org/pdf/2508.21550v1",
    "published_date": "2025-08-29 12:06:49 UTC",
    "updated_date": "2025-08-29 12:06:49 UTC"
  },
  {
    "arxiv_id": "2508.21547v1",
    "title": "What Data is Really Necessary? A Feasibility Study of Inference Data Minimization for Recommender Systems",
    "authors": [
      "Jens Leysen",
      "Marco Favier",
      "Bart Goethals"
    ],
    "abstract": "Data minimization is a legal principle requiring personal data processing to be limited to what is necessary for a specified purpose. Operationalizing this principle for recommender systems, which rely on extensive personal data, remains a significant challenge. This paper conducts a feasibility study on minimizing implicit feedback inference data for such systems. We propose a novel problem formulation, analyze various minimization techniques, and investigate key factors influencing their effectiveness. We demonstrate that substantial inference data reduction is technically feasible without significant performance loss. However, its practicality is critically determined by two factors: the technical setting (e.g., performance targets, choice of model) and user characteristics (e.g., history size, preference complexity). Thus, while we establish its technical feasibility, we conclude that data minimization remains practically challenging and its dependence on the technical and user context makes a universal standard for data `necessity' difficult to implement.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication at the 34th ACM International Conference on Information and Knowledge Management (CIKM '25), November 10-14, 2025, Seoul, Republic of Korea",
    "pdf_url": "https://arxiv.org/pdf/2508.21547v1",
    "published_date": "2025-08-29 12:01:17 UTC",
    "updated_date": "2025-08-29 12:01:17 UTC"
  },
  {
    "arxiv_id": "2508.21542v1",
    "title": "Complete Gaussian Splats from a Single Image with Denoising Diffusion Models",
    "authors": [
      "Ziwei Liao",
      "Mohamed Sayed",
      "Steven L. Waslander",
      "Sara Vicente",
      "Daniyar Turmukhambetov",
      "Michael Firman"
    ],
    "abstract": "Gaussian splatting typically requires dense observations of the scene and can fail to reconstruct occluded and unobserved areas. We propose a latent diffusion model to reconstruct a complete 3D scene with Gaussian splats, including the occluded parts, from only a single image during inference. Completing the unobserved surfaces of a scene is challenging due to the ambiguity of the plausible surfaces. Conventional methods use a regression-based formulation to predict a single \"mode\" for occluded and out-of-frustum surfaces, leading to blurriness, implausibility, and failure to capture multiple possible explanations. Thus, they often address this problem partially, focusing either on objects isolated from the background, reconstructing only visible surfaces, or failing to extrapolate far from the input views. In contrast, we propose a generative formulation to learn a distribution of 3D representations of Gaussian splats conditioned on a single input image. To address the lack of ground-truth training data, we propose a Variational AutoReconstructor to learn a latent space only from 2D images in a self-supervised manner, over which a diffusion model is trained. Our method generates faithful reconstructions and diverse samples with the ability to complete the occluded surfaces for high-quality 360-degree renderings.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Main paper: 11 pages; Supplementary materials: 7 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.21542v1",
    "published_date": "2025-08-29 11:55:47 UTC",
    "updated_date": "2025-08-29 11:55:47 UTC"
  },
  {
    "arxiv_id": "2508.21540v2",
    "title": "HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining",
    "authors": [
      "Eduardo Illueca-Fernandez",
      "Kaile Chen",
      "Fernando Seoane",
      "Farhad Abtahi"
    ],
    "abstract": "Process mining has emerged as a powerful analytical technique for understanding complex healthcare workflows. However, its application faces significant barriers, including technical complexity, a lack of standardized approaches, and limited access to practical training resources. We introduce HealthProcessAI, a GenAI framework designed to simplify process mining applications in healthcare and epidemiology by providing a comprehensive wrapper around existing Python (PM4PY) and R (bupaR) libraries. To address unfamiliarity and improve accessibility, the framework integrates multiple Large Language Models (LLMs) for automated process map interpretation and report generation, helping translate technical analyses into outputs that diverse users can readily understand. We validated the framework using sepsis progression data as a proof-of-concept example and compared the outputs of five state-of-the-art LLM models through the OpenRouter platform. To test its functionality, the framework successfully processed sepsis data across four proof-of-concept scenarios, demonstrating robust technical performance and its capability to generate reports through automated LLM analysis. LLM evaluation using five independent LLMs as automated evaluators revealed distinct model strengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency scores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By integrating multiple Large Language Models (LLMs) for automated interpretation and report generation, the framework addresses widespread unfamiliarity with process mining outputs, making them more accessible to clinicians, data scientists, and researchers. This structured analytics and AI-driven interpretation combination represents a novel methodological advance in translating complex process mining results into potentially actionable insights for healthcare applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Figure 1 updated, typos corrected, references added, under review",
    "pdf_url": "https://arxiv.org/pdf/2508.21540v2",
    "published_date": "2025-08-29 11:53:16 UTC",
    "updated_date": "2025-10-15 09:46:12 UTC"
  },
  {
    "arxiv_id": "2509.08698v1",
    "title": "A layered architecture for log analysis in complex IT systems",
    "authors": [
      "Thorsten Wittkopp"
    ],
    "abstract": "In the evolving IT landscape, stability and reliability of systems are essential, yet their growing complexity challenges DevOps teams in implementation and maintenance. Log analysis, a core element of AIOps, provides critical insights into complex behaviors and failures. This dissertation introduces a three-layered architecture to support DevOps in failure resolution. The first layer, Log Investigation, performs autonomous log labeling and anomaly classification. We propose a method that labels log data without manual effort, enabling supervised training and precise evaluation of anomaly detection. Additionally, we define a taxonomy that groups anomalies into three categories, ensuring appropriate method selection. The second layer, Anomaly Detection, detects behaviors deviating from the norm. We propose a flexible Anomaly Detection method adaptable to unsupervised, weakly supervised, and supervised training. Evaluations on public and industry datasets show F1-scores between 0.98 and 1.0, ensuring reliable anomaly detection. The third layer, Root Cause Analysis, identifies minimal log sets describing failures, their origin, and event sequences. By balancing training data and identifying key services, our Root Cause Analysis method consistently detects 90-98% of root cause log lines within the top 10 candidates, providing actionable insights for mitigation. Our research addresses how log analysis methods can be designed and optimized to help DevOps resolve failures efficiently. By integrating these three layers, the architecture equips teams with robust methods to enhance IT system reliability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Dissertation",
    "pdf_url": "https://arxiv.org/pdf/2509.08698v1",
    "published_date": "2025-08-29 11:28:21 UTC",
    "updated_date": "2025-08-29 11:28:21 UTC"
  },
  {
    "arxiv_id": "2508.21521v1",
    "title": "Counterfactual Scenarios for Automated Planning",
    "authors": [
      "Nicola Gigante",
      "Francesco Leofante",
      "Andrea Micheli"
    ],
    "abstract": "Counterfactual Explanations (CEs) are a powerful technique used to explain Machine Learning models by showing how the input to a model should be minimally changed for the model to produce a different output. Similar proposals have been made in the context of Automated Planning, where CEs have been characterised in terms of minimal modifications to an existing plan that would result in the satisfaction of a different goal. While such explanations may help diagnose faults and reason about the characteristics of a plan, they fail to capture higher-level properties of the problem being solved. To address this limitation, we propose a novel explanation paradigm that is based on counterfactual scenarios. In particular, given a planning problem $P$ and an \\ltlf formula $ψ$ defining desired properties of a plan, counterfactual scenarios identify minimal modifications to $P$ such that it admits plans that comply with $ψ$. In this paper, we present two qualitative instantiations of counterfactual scenarios based on an explicit quantification over plans that must satisfy $ψ$. We then characterise the computational complexity of generating such counterfactual scenarios when different types of changes are allowed on $P$. We show that producing counterfactual scenarios is often only as expensive as computing a plan for $P$, thus demonstrating the practical viability of our proposal and ultimately providing a framework to construct practical algorithms in this area.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the 22nd International Conference on Principles of Knowledge Representation and Reasoning (KR 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.21521v1",
    "published_date": "2025-08-29 11:16:17 UTC",
    "updated_date": "2025-08-29 11:16:17 UTC"
  },
  {
    "arxiv_id": "2509.04470v1",
    "title": "COCORELI: Cooperative, Compositional Reconstitution \\& Execution of Language Instructions",
    "authors": [
      "Swarnadeep Bhar",
      "Omar Naim",
      "Eleni Metheniti",
      "Bastien Navarri",
      "Loïc Cabannes",
      "Morteza Ezzabady",
      "Nicholas Asher"
    ],
    "abstract": "We present COCORELI, a hybrid agent framework designed to tackle the limitations of large language models (LLMs) in tasks requiring: following complex instructions, minimizing hallucination, and spatial reasoning. COCORELI integrates medium-sized LLM agents with novel abstraction mechanisms and a discourse module to parse instructions to in-context learn dynamic, high-level representations of the environment. Experiments on natural collaborative construction tasks show that COCORELI outperforms single-LLM CoT and agentic LLM systems, all using larger LLMs. It manages to largely avoid hallucinations, identify missing information, ask for clarifications, and update its learned objects. COCORELI's abstraction abilities extend beyond ENVIRONMENT, as shown in the ToolBench API completion task.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.04470v1",
    "published_date": "2025-08-29 11:15:57 UTC",
    "updated_date": "2025-08-29 11:15:57 UTC"
  },
  {
    "arxiv_id": "2508.21517v1",
    "title": "Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis",
    "authors": [
      "Sweta Kaman",
      "Ankita Sharma",
      "Romi Banerjee"
    ],
    "abstract": "Background: Wisdom is a superordinate construct that embraces perspective taking, reflectiveness, prosocial orientation, reflective empathetic action, and intellectual humility. Unlike conventional models of reasoning that are rigidly bound by binary thinking, wisdom unfolds in shades of ambiguity, requiring both graded evaluation and self-reflective humility. Current measures depend on self-reports and seldom reflect the humility and uncertainty inherent in wise reasoning. A computational framework that takes into account both multidimensionality and confidence has the potential to improve psychological science and allow humane AI. Method: We present a fuzzy inference system with Z numbers, each of the decisions being expressed in terms of a wisdom score (restriction) and confidence score (certainty). As part of this study, participants (N = 100) were exposed to culturally neutral pictorial moral dilemma tasks to which they generated think-aloud linguistic responses, which were mapped into five theoretically based components of wisdom. The scores of each individual component were combined using a base of 21 rules, with membership functions tuned via Gaussian kernel density estimation. Results: In a proof of concept study, the system produced dual attribute wisdom representations that correlated modestly but significantly with established scales while showing negligible relations with unrelated traits, supporting convergent and divergent validity. Contribution: The contribution is to formalize wisdom as a multidimensional, uncertainty-conscious construct, operationalized in the form of Z-numbers. In addition to progressing measurement in psychology, it calculates how fuzzy Z numbers can provide AI systems with interpretable, confidence-sensitive reasoning that affords a safe, middle ground between rigorous computation and human-like judgment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "total 17 pages, main manuscript 12 pages, supplementary 5 pages, 6 tables in main manuscript, 5 figures in main manuscript, 2 tables in supplementary, and 3 figures in supplementary",
    "pdf_url": "https://arxiv.org/pdf/2508.21517v1",
    "published_date": "2025-08-29 11:03:44 UTC",
    "updated_date": "2025-08-29 11:03:44 UTC"
  },
  {
    "arxiv_id": "2508.21513v1",
    "title": "On the Hardness of Learning GNN-based SAT Solvers: The Role of Graph Ricci Curvature",
    "authors": [
      "Geri Skenderi"
    ],
    "abstract": "Graph Neural Networks (GNNs) have recently shown promise as solvers for Boolean Satisfiability Problems (SATs) by operating on graph representations of logical formulas. However, their performance degrades sharply on harder instances, raising the question of whether this reflects fundamental architectural limitations. In this work, we provide a geometric explanation through the lens of graph Ricci Curvature (RC), which quantifies local connectivity bottlenecks. We prove that bipartite graphs derived from random k-SAT formulas are inherently negatively curved, and that this curvature decreases with instance difficulty. Building on this, we show that GNN-based SAT solvers are affected by oversquashing, a phenomenon where long-range dependencies become impossible to compress into fixed-length representations. We validate our claims empirically across different SAT benchmarks and confirm that curvature is both a strong indicator of problem complexity and can be used to predict performance. Finally, we connect our findings to design principles of existing solvers and outline promising directions for future work.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2508.21513v1",
    "published_date": "2025-08-29 10:54:19 UTC",
    "updated_date": "2025-08-29 10:54:19 UTC"
  },
  {
    "arxiv_id": "2509.05314v2",
    "title": "ManipDreamer3D : Synthesizing Plausible Robotic Manipulation Video with Occupancy-aware 3D Trajectory",
    "authors": [
      "Ying Li",
      "Xiaobao Wei",
      "Xiaowei Chi",
      "Yuming Li",
      "Zhongyu Zhao",
      "Hao Wang",
      "Ningning Ma",
      "Ming Lu",
      "Sirui Han",
      "Shanghang Zhang"
    ],
    "abstract": "Data scarcity continues to be a major challenge in the field of robotic manipulation. Although diffusion models provide a promising solution for generating robotic manipulation videos, existing methods largely depend on 2D trajectories, which inherently face issues with 3D spatial ambiguity. In this work, we present a novel framework named ManipDreamer3D for generating plausible 3D-aware robotic manipulation videos from the input image and the text instruction. Our method combines 3D trajectory planning with a reconstructed 3D occupancy map created from a third-person perspective, along with a novel trajectory-to-video diffusion model. Specifically, ManipDreamer3D first reconstructs the 3D occupancy representation from the input image and then computes an optimized 3D end-effector trajectory, minimizing path length while avoiding collisions. Next, we employ a latent editing technique to create video sequences from the initial image latent and the optimized 3D trajectory. This process conditions our specially trained trajectory-to-video diffusion model to produce robotic pick-and-place videos. Our method generates robotic videos with autonomously planned plausible 3D trajectories, significantly reducing human intervention requirements. Experimental results demonstrate superior visual quality compared to existing methods.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "7pages; 7figures; 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.05314v2",
    "published_date": "2025-08-29 10:39:06 UTC",
    "updated_date": "2025-11-13 06:04:25 UTC"
  },
  {
    "arxiv_id": "2508.21496v2",
    "title": "ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding",
    "authors": [
      "Hao Lu",
      "Jiahao Wang",
      "Yaolun Zhang",
      "Ruohui Wang",
      "Xuanyu Zheng",
      "Yepeng Tang",
      "Dahua Lin",
      "Lewei Lu"
    ],
    "abstract": "Video multimodal large language models (Video-MLLMs) have achieved remarkable progress in video understanding. However, they remain vulnerable to hallucination-producing content inconsistent with or unrelated to video inputs. Previous video hallucination benchmarks primarily focus on short-videos. They attribute hallucinations to factors such as strong language priors, missing frames, or vision-language biases introduced by the visual encoder. While these causes indeed account for most hallucinations in short videos, they still oversimplify the cause of hallucinations. Sometimes, models generate incorrect outputs but with correct frame-level semantics. We refer to this type of hallucination as Semantic Aggregation Hallucination (SAH), which arises during the process of aggregating frame-level semantics into event-level semantic groups. Given that SAH becomes particularly critical in long videos due to increased semantic complexity across multiple events, it is essential to separate and thoroughly investigate the causes of this type of hallucination. To address the above issues, we introduce ELV-Halluc, the first benchmark dedicated to long-video hallucination, enabling a systematic investigation of SAH. Our experiments confirm the existence of SAH and show that it increases with semantic complexity. Additionally, we find that models are more prone to SAH on rapidly changing semantics. Moreover, we discuss potential approaches to mitigate SAH. We demonstrate that positional encoding strategy contributes to alleviating SAH, and further adopt DPO strategy to enhance the model's ability to distinguish semantics within and across events. To support this, we curate a dataset of 8K adversarial data pairs and achieve improvements on both ELV-Halluc and Video-MME, including a substantial 27.7% reduction in SAH ratio.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21496v2",
    "published_date": "2025-08-29 10:25:03 UTC",
    "updated_date": "2025-09-02 17:14:38 UTC"
  },
  {
    "arxiv_id": "2509.08697v1",
    "title": "Reshaping the Forward-Forward Algorithm with a Similarity-Based Objective",
    "authors": [
      "James Gong",
      "Raymond Luo",
      "Emma Wang",
      "Leon Ge",
      "Bruce Li",
      "Felix Marattukalam",
      "Waleed Abdulla"
    ],
    "abstract": "Backpropagation is the pivotal algorithm underpinning the success of artificial neural networks, yet it has critical limitations such as biologically implausible backward locking and global error propagation. To circumvent these constraints, the Forward-Forward algorithm was proposed as a more biologically plausible method that replaces the backward pass with an additional forward pass. Despite this advantage, the Forward-Forward algorithm significantly trails backpropagation in accuracy, and its optimal form exhibits low inference efficiency due to multiple forward passes required. In this work, the Forward-Forward algorithm is reshaped through its integration with similarity learning frameworks, eliminating the need for multiple forward passes during inference. This proposed algorithm is named Forward-Forward Algorithm Unified with Similarity-based Tuplet loss (FAUST). Empirical evaluations on MNIST, Fashion-MNIST, and CIFAR-10 datasets indicate that FAUST substantially improves accuracy, narrowing the gap with backpropagation. On CIFAR-10, FAUST achieves 56.22\\% accuracy with a simple multi-layer perceptron architecture, approaching the backpropagation benchmark of 57.63\\% accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.08697v1",
    "published_date": "2025-08-29 10:23:03 UTC",
    "updated_date": "2025-08-29 10:23:03 UTC"
  },
  {
    "arxiv_id": "2508.21488v1",
    "title": "Priors Matter: Addressing Misspecification in Bayesian Deep Q-Learning",
    "authors": [
      "Pascal R. van der Vaart",
      "Neil Yorke-Smith",
      "Matthijs T. J. Spaan"
    ],
    "abstract": "Uncertainty quantification in reinforcement learning can greatly improve exploration and robustness. Approximate Bayesian approaches have recently been popularized to quantify uncertainty in model-free algorithms. However, so far the focus has been on improving the accuracy of the posterior approximation, instead of studying the accuracy of the prior and likelihood assumptions underlying the posterior. In this work, we demonstrate that there is a cold posterior effect in Bayesian deep Q-learning, where contrary to theory, performance increases when reducing the temperature of the posterior. To identify and overcome likely causes, we challenge common assumptions made on the likelihood and priors in Bayesian model-free algorithms. We empirically study prior distributions and show through statistical tests that the common Gaussian likelihood assumption is frequently violated. We argue that developing more suitable likelihoods and priors should be a key focus in future Bayesian reinforcement learning research and we offer simple, implementable solutions for better priors in deep Q-learning that lead to more performant Bayesian algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21488v1",
    "published_date": "2025-08-29 10:12:42 UTC",
    "updated_date": "2025-08-29 10:12:42 UTC"
  },
  {
    "arxiv_id": "2508.21482v1",
    "title": "HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble",
    "authors": [
      "Sara B. Coutinho",
      "Rafael M. O. Cruz",
      "Francimaria R. S. Nascimento",
      "George D. C. Cavalcanti"
    ],
    "abstract": "Psychological biases, such as confirmation bias, make individuals particularly vulnerable to believing and spreading fake news on social media, leading to significant consequences in domains such as public health and politics. Machine learning-based fact-checking systems have been widely studied to mitigate this problem. Among them, ensemble methods are particularly effective in combining multiple classifiers to improve robustness. However, their performance heavily depends on the diversity of the constituent classifiers-selecting genuinely diverse models remains a key challenge, especially when models tend to learn redundant patterns. In this work, we propose a novel automatic classifier selection approach that prioritizes diversity, also extended by performance. The method first computes pairwise diversity between classifiers and applies hierarchical clustering to organize them into groups at different levels of granularity. A HierarchySelect then explores these hierarchical levels to select one pool of classifiers per level, each representing a distinct intra-pool diversity. The most diverse pool is identified and selected for ensemble construction from these. The selection process incorporates an evaluation metric reflecting each classifiers's performance to ensure the ensemble also generalises well. We conduct experiments with 40 heterogeneous classifiers across six datasets from different application domains and with varying numbers of classes. Our method is compared against the Elbow heuristic and state-of-the-art baselines. Results show that our approach achieves the highest accuracy on two of six datasets. The implementation details are available on the project's repository: https://github.com/SaraBCoutinho/HSFN .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IEEE International Conference on Systems, Man, and Cybernetics (SMC) - IEEE SMC 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.21482v1",
    "published_date": "2025-08-29 10:09:20 UTC",
    "updated_date": "2025-08-29 10:09:20 UTC"
  },
  {
    "arxiv_id": "2508.21476v1",
    "title": "Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards",
    "authors": [
      "Xiaolong Wei",
      "Bo Lu",
      "Xingyu Zhang",
      "Zhejun Zhao",
      "Dongdong Shen",
      "Long Xia",
      "Dawei Yin"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable creative writing capabilities, yet their substantial computational demands hinder widespread use. Enhancing Small Language Models (SLMs) offers a promising alternative, but current methods like Supervised Fine-Tuning (SFT) struggle with novelty, and Reinforcement Learning from Human Feedback (RLHF) is costly. This paper explores two distinct AI-driven reward strategies within a Reinforcement Learning from AI Feedback (RLAIF) framework to ignite the creative writing of a 7B-parameter SLM, specifically for generating Chinese greetings. The first strategy employs a RM trained on high-quality preference data curated by a novel multi-agent rejection sampling framework designed for creative tasks. The second, more novel strategy utilizes a principle-guided LLM-as-a-Judge, whose reward function is optimized via an adversarial training scheme with a reflection mechanism, to directly provide reward signals. Comprehensive experiments reveal that while both approaches significantly enhance creative output over baselines, the principle-guided LLM-as-a-Judge demonstrably yields superior generation quality. Furthermore, it offers notable advantages in training efficiency and reduced dependency on human-annotated data, presenting a more scalable and effective path towards creative SLMs. Our automated evaluation methods also exhibit strong alignment with human judgments. Our code and data are publicly available at https://github.com/weixiaolong94-hub/Igniting-Creative-Writing-in-Small-Language-Models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2025 Main",
    "pdf_url": "https://arxiv.org/pdf/2508.21476v1",
    "published_date": "2025-08-29 10:00:55 UTC",
    "updated_date": "2025-08-29 10:00:55 UTC"
  },
  {
    "arxiv_id": "2508.21475v2",
    "title": "MMSearch-Plus: Benchmarking Provenance-Aware Search for Multimodal Browsing Agents",
    "authors": [
      "Xijia Tao",
      "Yihua Teng",
      "Xinxing Su",
      "Xinyu Fu",
      "Jihao Wu",
      "Chaofan Tao",
      "Ziru Liu",
      "Haoli Bai",
      "Rui Liu",
      "Lingpeng Kong"
    ],
    "abstract": "Existing multimodal browsing benchmarks often fail to require genuine multimodal reasoning, as many tasks can be solved with text-only heuristics without vision-in-the-loop verification. We introduce MMSearch-Plus, a 311-task benchmark that enforces multimodal understanding by requiring extraction and propagation of fine-grained visual cues through iterative image-text retrieval and cross-validation under retrieval noise. Our curation procedure seeds questions whose answers require extrapolating from spatial cues and temporal traces to out-of-image facts such as events, dates, and venues. Beyond the dataset, we provide a model-agnostic agent framework with standard browsing tools and a set-of-mark (SoM) module, which lets the agent place marks, crop subregions, and launch targeted image/text searches. SoM enables provenance-aware zoom-and-retrieve and improves robustness in multi-step reasoning. We evaluated closed- and open-source MLLMs in this framework. The strongest system achieves an end-to-end accuracy of 36.0%, and integrating SoM produces consistent gains in multiple settings, with improvements up to +3.9 points. From failure analysis, we observe recurring errors in locating relevant webpages and distinguishing between visually similar events. These results underscore the challenges of real-world multimodal search and establish MMSearch-Plus as a rigorous benchmark for advancing agentic MLLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Project Page: https://mmsearch-plus.github.io",
    "pdf_url": "https://arxiv.org/pdf/2508.21475v2",
    "published_date": "2025-08-29 09:58:27 UTC",
    "updated_date": "2025-09-26 13:36:22 UTC"
  },
  {
    "arxiv_id": "2509.02594v1",
    "title": "OpenAIs HealthBench in Action: Evaluating an LLM-Based Medical Assistant on Realistic Clinical Queries",
    "authors": [
      "Sandhanakrishnan Ravichandran",
      "Shivesh Kumar",
      "Rogerio Corga Da Silva",
      "Miguel Romano",
      "Reinhard Berkels",
      "Michiel van der Heijden",
      "Olivier Fail",
      "Valentine Emmanuel Gnanapragasam"
    ],
    "abstract": "Evaluating large language models (LLMs) on their ability to generate high-quality, accurate, situationally aware answers to clinical questions requires going beyond conventional benchmarks to assess how these systems behave in complex, high-stake clincal scenarios. Traditional evaluations are often limited to multiple-choice questions that fail to capture essential competencies such as contextual reasoning, awareness and uncertainty handling etc. To address these limitations, we evaluate our agentic, RAG-based clinical support assistant, DR.INFO, using HealthBench, a rubric-driven benchmark composed of open-ended, expert-annotated health conversations. On the Hard subset of 1,000 challenging examples, DR.INFO achieves a HealthBench score of 0.51, substantially outperforming leading frontier LLMs (GPT-5, o3, Grok 3, GPT-4, Gemini 2.5, etc.) across all behavioral axes (accuracy, completeness, instruction following, etc.). In a separate 100-sample evaluation against similar agentic RAG assistants (OpenEvidence, Pathway.md), it maintains a performance lead with a health-bench score of 0.54. These results highlight DR.INFOs strengths in communication, instruction following, and accuracy, while also revealing areas for improvement in context awareness and completeness of a response. Overall, the findings underscore the utility of behavior-level, rubric-based evaluation for building a reliable and trustworthy AI-enabled clinical support assistant.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.ET",
      "cs.IR"
    ],
    "primary_category": "q-bio.QM",
    "comment": "13 pages, two graphs",
    "pdf_url": "https://arxiv.org/pdf/2509.02594v1",
    "published_date": "2025-08-29 09:51:41 UTC",
    "updated_date": "2025-08-29 09:51:41 UTC"
  },
  {
    "arxiv_id": "2508.21468v1",
    "title": "Controllable 3D Molecular Generation for Structure-Based Drug Design Through Bayesian Flow Networks and Gradient Integration",
    "authors": [
      "Seungyeon Choi",
      "Hwanhee Kim",
      "Chihyun Park",
      "Dahyeon Lee",
      "Seungyong Lee",
      "Yoonju Kim",
      "Hyoungjoon Park",
      "Sein Kwon",
      "Youngwan Jo",
      "Sanghyun Park"
    ],
    "abstract": "Recent advances in Structure-based Drug Design (SBDD) have leveraged generative models for 3D molecular generation, predominantly evaluating model performance by binding affinity to target proteins. However, practical drug discovery necessitates high binding affinity along with synthetic feasibility and selectivity, critical properties that were largely neglected in previous evaluations. To address this gap, we identify fundamental limitations of conventional diffusion-based generative models in effectively guiding molecule generation toward these diverse pharmacological properties. We propose CByG, a novel framework extending Bayesian Flow Network into a gradient-based conditional generative model that robustly integrates property-specific guidance. Additionally, we introduce a comprehensive evaluation scheme incorporating practical benchmarks for binding affinity, synthetic feasibility, and selectivity, overcoming the limitations of conventional evaluation methods. Extensive experiments demonstrate that our proposed CByG framework significantly outperforms baseline models across multiple essential evaluation criteria, highlighting its effectiveness and practicality for real-world drug discovery applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21468v1",
    "published_date": "2025-08-29 09:49:15 UTC",
    "updated_date": "2025-08-29 09:49:15 UTC"
  },
  {
    "arxiv_id": "2508.21460v1",
    "title": "Diffusion-based Multi-modal Synergy Interest Network for Click-through Rate Prediction",
    "authors": [
      "Xiaoxi Cui",
      "Weihai Lu",
      "Yu Tong",
      "Yiheng Li",
      "Zhejun Zhao"
    ],
    "abstract": "In click-through rate prediction, click-through rate prediction is used to model users' interests. However, most of the existing CTR prediction methods are mainly based on the ID modality. As a result, they are unable to comprehensively model users' multi-modal preferences. Therefore, it is necessary to introduce multi-modal CTR prediction. Although it seems appealing to directly apply the existing multi-modal fusion methods to click-through rate prediction models, these methods (1) fail to effectively disentangle commonalities and specificities across different modalities; (2) fail to consider the synergistic effects between modalities and model the complex interactions between modalities.\n  To address the above issues, this paper proposes the Diffusion-based Multi-modal Synergy Interest Network (Diff-MSIN) framework for click-through prediction. This framework introduces three innovative modules: the Multi-modal Feature Enhancement (MFE) Module Synergistic Relationship Capture (SRC) Module, and the Feature Dynamic Adaptive Fusion (FDAF) Module. The MFE Module and SRC Module extract synergistic, common, and special information among different modalities. They effectively enhances the representation of the modalities, improving the overall quality of the fusion. To encourage distinctiveness among different features, we design a Knowledge Decoupling method. Additionally, the FDAF Module focuses on capturing user preferences and reducing fusion noise. To validate the effectiveness of the Diff-MSIN framework, we conducted extensive experiments using the Rec-Tmall and three Amazon datasets. The results demonstrate that our approach yields a significant improvement of at least 1.67% compared to the baseline, highlighting its potential for enhancing multi-modal recommendation systems. Our code is available at the following link: https://github.com/Cxx-0/Diff-MSIN.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "SIGIR 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.21460v1",
    "published_date": "2025-08-29 09:46:16 UTC",
    "updated_date": "2025-08-29 09:46:16 UTC"
  },
  {
    "arxiv_id": "2508.21449v1",
    "title": "Learning Lifted Action Models From Traces of Incomplete Actions and States",
    "authors": [
      "Niklas Jansen",
      "Jonas Gösgens",
      "Hector Geffner"
    ],
    "abstract": "Consider the problem of learning a lifted STRIPS model of the sliding-tile puzzle from random state-action traces where the states represent the location of the tiles only, and the actions are the labels up, down, left, and right, with no arguments. Two challenges are involved in this problem. First, the states are not full STRIPS states, as some predicates are missing, like the atoms representing the position of the ``blank''. Second, the actions are not full STRIPS either, as they do not reveal all the objects involved in the actions effects and preconditions. Previous approaches have addressed different versions of this model learning problem, but most assume that actions in the traces are full STRIPS actions or that the domain predicates are all observable. The new setting considered in this work is more ``realistic'', as the atoms observed convey the state of the world but not full STRIPS states, and the actions reveal the arguments needed for selecting the action but not the ones needed for modeling it in STRIPS. For formulating and addressing the learning problem, we introduce a variant of STRIPS, which we call STRIPS+, where certain STRIPS action arguments can be left implicit in preconditions which can also involve a limited form of existential quantification. The learning problem becomes the problem of learning STRIPS+ models from STRIPS+ state-action traces. For this, the proposed learning algorithm, called SYNTH, constructs a stratified sequence (conjunction) of precondition expressions or ``queries'' for each action, that denote unique objects in the state and ground the implicit action arguments in STRIPS+. The correctness and completeness of SYNTH is established, and its scalability is tested on state-action traces obtained from STRIPS+ models derived from existing STRIPS domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To be presented at KR 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.21449v1",
    "published_date": "2025-08-29 09:27:53 UTC",
    "updated_date": "2025-08-29 09:27:53 UTC"
  },
  {
    "arxiv_id": "2509.04469v1",
    "title": "Multi-Modal Vision vs. Text-Based Parsing: Benchmarking LLM Strategies for Invoice Processing",
    "authors": [
      "David Berghaus",
      "Armin Berger",
      "Lars Hillebrand",
      "Kostadin Cvejoski",
      "Rafet Sifa"
    ],
    "abstract": "This paper benchmarks eight multi-modal large language models from three families (GPT-5, Gemini 2.5, and open-source Gemma 3) on three diverse openly available invoice document datasets using zero-shot prompting. We compare two processing strategies: direct image processing using multi-modal capabilities and a structured parsing approach converting documents to markdown first. Results show native image processing generally outperforms structured approaches, with performance varying across model types and document characteristics. This benchmark provides insights for selecting appropriate models and processing strategies for automated document systems. Our code is available online.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.04469v1",
    "published_date": "2025-08-29 09:09:20 UTC",
    "updated_date": "2025-08-29 09:09:20 UTC"
  },
  {
    "arxiv_id": "2508.21441v1",
    "title": "A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions",
    "authors": [
      "Christoph Beierle",
      "Alexander Hahn",
      "Diana Howey",
      "Gabriele Kern-Isberner",
      "Kai Sauerwald"
    ],
    "abstract": "Forgetting as a knowledge management operation deliberately ignores parts of the knowledge and beliefs of an agent, for various reasons. Forgetting has many facets, one may want to forget parts of the syntax, a proposition, or a conditional. In the literature, two main operators suitable for performing forgetting have been proposed and investigated in depth: First, variable elimination is a syntactical method that blends out certain atomic variables to focus on the rest of the language. It has been mainly used in the area of logic programming and answer set programming. Second, contraction in AGM belief revision theory effectively removes propositions from belief sets under logical deduction. Both operations rely mainly on classical logics. In this article, we take an epistemic perspective and study forgetting operations in epistemic states with richer semantic structures, but with clear links to propositional logic. This allows us to investigate what forgetting in the epistemic background means, thereby lifting well-known and novel forgetting operations to the epistemic level. We present five general types of epistemic forgetting and instantiate them with seven concrete forgetting operations for Spohn's ranking functions. We take inspiration from postulates of forgetting both from logic programming and AGM theory to propose a rich landscape of axioms for evaluating forgetting operations. Finally, we evaluate all concrete forgetting operations according to all postulates, leading to a novel comprehensive overview highlighting differences and commonalities among the forgetting operators.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21441v1",
    "published_date": "2025-08-29 09:08:54 UTC",
    "updated_date": "2025-08-29 09:08:54 UTC"
  },
  {
    "arxiv_id": "2508.21435v1",
    "title": "MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation",
    "authors": [
      "Francisco Caetano",
      "Christiaan Viviers",
      "Peter H. H. de With",
      "Fons van der Sommen"
    ],
    "abstract": "Synthetic medical data offers a scalable solution for training robust models, but significant domain gaps limit its generalizability to real-world clinical settings. This paper addresses the challenge of cross-domain translation between synthetic and real X-ray images of the head, focusing on bridging discrepancies in attenuation behavior, noise characteristics, and soft tissue representation. We propose MedShift, a unified class-conditional generative model based on Flow Matching and Schrodinger Bridges, which enables high-fidelity, unpaired image translation across multiple domains. Unlike prior approaches that require domain-specific training or rely on paired data, MedShift learns a shared domain-agnostic latent space and supports seamless translation between any pair of domains seen during training. We introduce X-DigiSkull, a new dataset comprising aligned synthetic and real skull X-rays under varying radiation doses, to benchmark domain translation models. Experimental results demonstrate that, despite its smaller model size compared to diffusion-based approaches, MedShift offers strong performance and remains flexible at inference time, as it can be tuned to prioritize either perceptual fidelity or structural consistency, making it a scalable and generalizable solution for domain adaptation in medical imaging. The code and dataset are available at https://caetas.github.io/medshift.html",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the ICCV 2025 AIM Workshop",
    "pdf_url": "https://arxiv.org/pdf/2508.21435v1",
    "published_date": "2025-08-29 09:04:11 UTC",
    "updated_date": "2025-08-29 09:04:11 UTC"
  },
  {
    "arxiv_id": "2508.21433v3",
    "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management",
    "authors": [
      "Tobias Lindenbauer",
      "Igor Slinko",
      "Ludwig Felder",
      "Egor Bogomolov",
      "Yaroslav Zharov"
    ],
    "abstract": "Large Language Model (LLM)-based agents solve complex tasks through iterative reasoning, exploration, and tool-use, a process that can result in long, expensive context histories. While state-of-the-art Software Engineering (SE) agents like OpenHands or Cursor use LLM-based summarization to tackle this issue, it is unclear whether the increased complexity offers tangible performance benefits compared to simply omitting older observations. We present a systematic comparison of these approaches within SWE-agent on SWE-bench Verified across five diverse model configurations. Moreover, we show initial evidence of our findings generalizing to the OpenHands agent scaffold. We find that a simple environment observation masking strategy halves cost relative to the raw agent while matching, and sometimes slightly exceeding, the solve rate of LLM summarization. Additionally, we introduce a novel hybrid approach that further reduces costs by 7% and 11% compared to just observation masking or LLM summarization, respectively. Our findings raise concerns regarding the trend towards pure LLM summarization and provide initial evidence of untapped cost reductions by pushing the efficiency-effectiveness frontier. We release code and data for reproducibility.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "v3: DL4C camera-ready version to be presented at the 4th DL4C workshop co-located with NeurIPS '25; added OpenHands generality probe, added hybrid context management strategy",
    "pdf_url": "https://arxiv.org/pdf/2508.21433v3",
    "published_date": "2025-08-29 09:02:35 UTC",
    "updated_date": "2025-10-27 15:08:54 UTC"
  },
  {
    "arxiv_id": "2508.21430v1",
    "title": "Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models",
    "authors": [
      "Meidan Ding",
      "Jipeng Zhang",
      "Wenxuan Wang",
      "Cheng-Yi Li",
      "Wei-Chieh Fang",
      "Hsin-Yu Wu",
      "Haiqin Zhong",
      "Wenting Chen",
      "Linlin Shen"
    ],
    "abstract": "Multimodal large language models (MLLMs) hold significant potential in medical applications, including disease diagnosis and clinical decision-making. However, these tasks require highly accurate, context-sensitive, and professionally aligned responses, making reliable reward models and judges critical. Despite their importance, medical reward models (MRMs) and judges remain underexplored, with no dedicated benchmarks addressing clinical requirements. Existing benchmarks focus on general MLLM capabilities or evaluate models as solvers, neglecting essential evaluation dimensions like diagnostic accuracy and clinical relevance. To address this, we introduce Med-RewardBench, the first benchmark specifically designed to evaluate MRMs and judges in medical scenarios. Med-RewardBench features a multimodal dataset spanning 13 organ systems and 8 clinical departments, with 1,026 expert-annotated cases. A rigorous three-step process ensures high-quality evaluation data across six clinically critical dimensions. We evaluate 32 state-of-the-art MLLMs, including open-source, proprietary, and medical-specific models, revealing substantial challenges in aligning outputs with expert judgment. Additionally, we develop baseline models that demonstrate substantial performance improvements through fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 5 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.21430v1",
    "published_date": "2025-08-29 08:58:39 UTC",
    "updated_date": "2025-08-29 08:58:39 UTC"
  },
  {
    "arxiv_id": "2509.00125v1",
    "title": "Know When to Explore: Difficulty-Aware Certainty as a Guide for LLM Reinforcement Learning",
    "authors": [
      "Ang Li",
      "Zhihang Yuan",
      "Yang Zhang",
      "Shouda Liu",
      "Yisen Wang"
    ],
    "abstract": "Reinforcement Learning with Verifiable Feedback (RLVF) has become a key technique for enhancing the reasoning abilities of Large Language Models (LLMs). However, its reliance on sparse, outcome based rewards, which only indicate if a final answer is correct or not, fails to provide granular guidance on the reasoning process itself. This limitation hinders efficient learning, as the model cannot distinguish between high quality and inefficient solutions, nor can it learn effectively from different types of failures. To address this, we observe that an LLMs self-certainty often correlates with task difficulty and solution quality. We introduce Difficulty Aware Certainty guided Exploration (DACE), a novel RL algorithm that leverages this insight to dynamically balance the exploration exploitation trade-off. DACE assesses task difficulty online based on the policys success rate. It then uses this signal to modulate an intrinsic reward: for difficult tasks where the model is struggling, DACE encourages exploration by penalizing high certainty; for easier tasks, it encourages learning efficiency by rewarding high certainty. Experiments on challenging mathematical reasoning benchmarks (AIME, MATH) show that DACE significantly outperforms strong baselines. The DACE-trained models not only achieve higher accuracy but also demonstrate more robust performance when scaling test-time compute, validating that our adaptive approach fosters effective exploration without sacrificing precision.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.00125v1",
    "published_date": "2025-08-29 08:57:54 UTC",
    "updated_date": "2025-08-29 08:57:54 UTC"
  },
  {
    "arxiv_id": "2508.21420v1",
    "title": "Benchmarking the State of Networks with a Low-Cost Method Based on Reservoir Computing",
    "authors": [
      "Felix Simon Reimers",
      "Carl-Hendrik Peters",
      "Stefano Nichele"
    ],
    "abstract": "Using data from mobile network utilization in Norway, we showcase the possibility of monitoring the state of communication and mobility networks with a non-invasive, low-cost method. This method transforms the network data into a model within the framework of reservoir computing and then measures the model's performance on proxy tasks. Experimentally, we show how the performance on these proxies relates to the state of the network. A key advantage of this approach is that it uses readily available data sets and leverages the reservoir computing framework for an inexpensive and largely agnostic method. Data from mobile network utilization is available in an anonymous, aggregated form with multiple snapshots per day. This data can be treated like a weighted network. Reservoir computing allows the use of weighted, but untrained networks as a machine learning tool. The network, initialized as a so-called echo state network (ESN), projects incoming signals into a higher dimensional space, on which a single trained layer operates. This consumes less energy than deep neural networks in which every weight of the network is trained. We use neuroscience inspired tasks and trained our ESN model to solve them. We then show how the performance depends on certain network configurations and also how it visibly decreases when perturbing the network. While this work serves as proof of concept, we believe it can be elevated to be used for near-real-time monitoring as well as the identification of possible weak spots of both mobile communication networks as well as transportation networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Net-Zero Future 2025 Conference",
    "pdf_url": "https://arxiv.org/pdf/2508.21420v1",
    "published_date": "2025-08-29 08:42:37 UTC",
    "updated_date": "2025-08-29 08:42:37 UTC"
  },
  {
    "arxiv_id": "2509.02593v4",
    "title": "Robust Pan-Cancer Mitotic Figure Detection with YOLOv12",
    "authors": [
      "Raphaël Bourgade",
      "Guillaume Balezo",
      "Hana Feki",
      "Lily Monier",
      "Matthieu Blons",
      "Alice Blondel",
      "Delphine Loussouarn",
      "Anne Vincent-Salomon",
      "Thomas Walter"
    ],
    "abstract": "Mitotic figures represent a key histoprognostic feature in tumor pathology, providing crucial insights into tumor aggressiveness and proliferation. However, their identification remains challenging, subject to significant inter-observer variability, even among experienced pathologists. To address this issue, the MItosis DOmain Generalization (MIDOG) 2025 challenge marks the third edition of an international competition aiming to develop robust mitosis detection algorithms. In this paper, we present a mitotic figure detection approach based on the state-of-the-art YOLOv12 object detection architecture. Our method achieved an F1-score of 0.801 on the preliminary test set (hotspots only) and ranked second on the final test leaderboard with an F1-score of 0.7216 across complex and heterogeneous whole-slide regions, without relying on external data.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02593v4",
    "published_date": "2025-08-29 08:37:46 UTC",
    "updated_date": "2025-10-19 22:49:24 UTC"
  },
  {
    "arxiv_id": "2508.21411v1",
    "title": "CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN",
    "authors": [
      "Leonard Frank Neis",
      "Andre Antakli",
      "Matthias Klusch"
    ],
    "abstract": "User-friendly modeling and virtual simulation of urban traffic scenarios with different types of interacting agents such as pedestrians, cyclists and autonomous vehicles remains a challenge. We present CARJAN, a novel tool for semi-automated generation and simulation of such scenarios based on the multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN provides a visual user interface for the modeling, storage and maintenance of traffic scenario layouts, and leverages SPARQL Behavior Tree-based decision-making and interactions for agents in dynamic scenario simulations in CARLA. CARJAN provides a first integrated approach for interactive, intelligent agent-based generation and simulation of virtual traffic scenarios in CARLA.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21411v1",
    "published_date": "2025-08-29 08:33:16 UTC",
    "updated_date": "2025-08-29 08:33:16 UTC"
  },
  {
    "arxiv_id": "2508.21407v1",
    "title": "DRASP: A Dual-Resolution Attentive Statistics Pooling Framework for Automatic MOS Prediction",
    "authors": [
      "Cheng-Yeh Yang",
      "Kuan-Tang Huang",
      "Chien-Chun Wang",
      "Hung-Shin Lee",
      "Hsin-Min Wang",
      "Berlin Chen"
    ],
    "abstract": "A pooling mechanism is essential for mean opinion score (MOS) prediction, facilitating the transformation of variable-length audio features into a concise fixed-size representation that effectively encodes speech quality. Existing pooling methods typically operate at a singular granularity, concentrating either on a comprehensive global perspective or a detailed frame-level analysis, which may overlook complementary perceptual insights. To address this limitation, we introduce the Dual-Resolution Attentive Statistics Pooling (DRASP) framework. DRASP integrates both coarse-grained, global statistical summaries and fine-grained, attentive analyses of perceptually significant segments. This dual-view architecture empowers our model to formulate a more thorough and robust representation, capturing both the overarching structural context and salient local details concurrently. Extensive experiments validate the effectiveness and strong generalization ability of the proposed framework. It consistently outperforms various baseline methods across diverse datasets (MusicEval and AES-Natural), MOS prediction backbones (including a CLAP-based model and AudioBox-Aesthetics), and different audio generation systems, achieving a relative improvement of 10.39% in system-level Spearman's rank correlation coefficient (SRCC) over the widely-used average pooling approach.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to APSIPA ASC 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.21407v1",
    "published_date": "2025-08-29 08:27:17 UTC",
    "updated_date": "2025-08-29 08:27:17 UTC"
  },
  {
    "arxiv_id": "2509.00124v1",
    "title": "A Whole New World: Creating a Parallel-Poisoned Web Only AI-Agents Can See",
    "authors": [
      "Shaked Zychlinski"
    ],
    "abstract": "This paper introduces a novel attack vector that leverages website cloaking techniques to compromise autonomous web-browsing agents powered by Large Language Models (LLMs). As these agents become more prevalent, their unique and often homogenous digital fingerprints - comprising browser attributes, automation framework signatures, and network characteristics - create a new, distinguishable class of web traffic. The attack exploits this fingerprintability. A malicious website can identify an incoming request as originating from an AI agent and dynamically serve a different, \"cloaked\" version of its content. While human users see a benign webpage, the agent is presented with a visually identical page embedded with hidden, malicious instructions, such as indirect prompt injections. This mechanism allows adversaries to hijack agent behavior, leading to data exfiltration, malware execution, or misinformation propagation, all while remaining completely invisible to human users and conventional security crawlers. This work formalizes the threat model, details the mechanics of agent fingerprinting and cloaking, and discusses the profound security implications for the future of agentic AI, highlighting the urgent need for robust defenses against this stealthy and scalable attack.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "10 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2509.00124v1",
    "published_date": "2025-08-29 08:14:52 UTC",
    "updated_date": "2025-08-29 08:14:52 UTC"
  },
  {
    "arxiv_id": "2508.21394v3",
    "title": "AI Compute Architecture and Evolution Trends",
    "authors": [
      "Bor-Sung Liang"
    ],
    "abstract": "The focus of AI development has shifted from academic research to practical applications. However, AI development faces numerous challenges at various levels. This article will attempt to analyze the opportunities and challenges of AI from several different perspectives using a structured approach. This article proposes a seven-layer model for AI compute architecture, including Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer, Orchestrator Layer, and Application Layer, from bottom to top.\n  It also explains the three stages in the evolution of large language models (LLMs) using the proposed 7-layer model. For each layer, we describe the development trajectory and key technologies. In Layers 1 and 2 we discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies on computing architecture. In Layer 3 we explore two different development paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs and compares it to traditional processor memory. In Layers 5 to 7 we discuss the trends of AI agents and explore the issues in evolution from a single AI agent to an AI-based ecosystem, and their impact on the AI industry.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "33 pages, 17 figures, 2 Tables",
    "pdf_url": "https://arxiv.org/pdf/2508.21394v3",
    "published_date": "2025-08-29 08:14:45 UTC",
    "updated_date": "2026-01-04 04:13:32 UTC"
  },
  {
    "arxiv_id": "2508.21393v3",
    "title": "VeriLoRA: Fine-Tuning Large Language Models with Verifiable Security via Zero-Knowledge Proofs",
    "authors": [
      "Guofu Liao",
      "Taotao Wang",
      "Shengli Zhang",
      "Jiqun Zhang",
      "Shi Long",
      "Dacheng Tao"
    ],
    "abstract": "Fine-tuning large language models (LLMs) is crucial for adapting them to specific tasks, yet it remains computationally demanding and raises concerns about correctness and privacy, particularly in untrusted environments. Although parameter-efficient methods like Low-Rank Adaptation (LoRA) significantly reduce resource requirements, ensuring the security and verifiability of fine-tuning under zero-knowledge constraints remains an unresolved challenge. To address this, we introduce VeriLoRA, the first framework to integrate LoRA fine-tuning with zero-knowledge proofs (ZKPs), achieving provable security and correctness. VeriLoRA employs advanced cryptographic techniques -- such as lookup arguments, sumcheck protocols, and polynomial commitments -- to verify both arithmetic and non-arithmetic operations in Transformer-based architectures. The framework provides end-to-end verifiability for forward propagation, backward propagation, and parameter updates during LoRA fine-tuning, while safeguarding the privacy of model parameters and training data. Leveraging GPU-based implementations, VeriLoRA demonstrates practicality and efficiency through experimental validation on open-source LLMs like LLaMA, scaling up to 13 billion parameters. By combining parameter-efficient fine-tuning with ZKPs, VeriLoRA bridges a critical gap, enabling secure and trustworthy deployment of LLMs in sensitive or untrusted environments.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "This paper has been accepted for publication at the Network and Distributed System Security Symposium (NDSS) 2026",
    "pdf_url": "https://arxiv.org/pdf/2508.21393v3",
    "published_date": "2025-08-29 08:14:38 UTC",
    "updated_date": "2025-12-02 04:45:18 UTC"
  },
  {
    "arxiv_id": "2508.21389v1",
    "title": "AllSummedUp: un framework open-source pour comparer les metriques d'evaluation de resume",
    "authors": [
      "Tanguy Herserant",
      "Vincent Guigue"
    ],
    "abstract": "This paper investigates reproducibility challenges in automatic text summarization evaluation. Based on experiments conducted across six representative metrics ranging from classical approaches like ROUGE to recent LLM-based methods (G-Eval, SEval-Ex), we highlight significant discrepancies between reported performances in the literature and those observed in our experimental setting. We introduce a unified, open-source framework, applied to the SummEval dataset and designed to support fair and transparent comparison of evaluation metrics. Our results reveal a structural trade-off: metrics with the highest alignment with human judgments tend to be computationally intensive and less stable across runs. Beyond comparative analysis, this study highlights key concerns about relying on LLMs for evaluation, stressing their randomness, technical dependencies, and limited reproducibility. We advocate for more robust evaluation protocols including exhaustive documentation and methodological standardization to ensure greater reliability in automatic summarization assessment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "in French language",
    "pdf_url": "https://arxiv.org/pdf/2508.21389v1",
    "published_date": "2025-08-29 08:05:00 UTC",
    "updated_date": "2025-08-29 08:05:00 UTC"
  },
  {
    "arxiv_id": "2508.21382v2",
    "title": "Normality and the Turing Test",
    "authors": [
      "Alexandre Kabbach"
    ],
    "abstract": "This paper proposes to revisit the Turing test through the concept of normality. Its core argument is that the Turing test is a test of normal intelligence as assessed by a normal judge. First, in the sense that the Turing test targets normal/average rather than exceptional human intelligence, so that successfully passing the test requires machines to \"make mistakes\" and display imperfect behavior just like normal/average humans. Second, in the sense that the Turing test is a statistical test where judgments of intelligence are never carried out by a single \"average\" judge (understood as non-expert) but always by a full jury. As such, the notion of \"average human interrogator\" that Turing talks about in his original paper should be understood primarily as referring to a mathematical abstraction made of the normalized aggregate of individual judgments of multiple judges. Its conclusions are twofold. First, it argues that large language models such as ChatGPT are unlikely to pass the Turing test as those models precisely target exceptional rather than normal/average human intelligence. As such, they constitute models of what it proposes to call artificial smartness rather than artificial intelligence, insofar as they deviate from the original goal of Turing for the modeling of artificial minds. Second, it argues that the objectivization of normal human behavior in the Turing test fails due to the game configuration of the test which ends up objectivizing normative ideals of normal behavior rather than normal behavior per se.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21382v2",
    "published_date": "2025-08-29 07:55:16 UTC",
    "updated_date": "2025-11-08 09:17:07 UTC"
  },
  {
    "arxiv_id": "2508.21380v2",
    "title": "Iterative Inference in a Chess-Playing Neural Network",
    "authors": [
      "Elias Sandmann",
      "Sebastian Lapuschkin",
      "Wojciech Samek"
    ],
    "abstract": "Do neural networks build their representations through smooth, gradual refinement, or via more complex computational processes? We investigate this by extending the logit lens to analyze the policy network of Leela Chess Zero, a superhuman chess engine. Although playing strength and puzzle-solving ability improve consistently across layers, capability progression occurs in distinct computational phases with move preferences undergoing continuous reevaluation--move rankings remain poorly correlated with final outputs until late, and correct puzzle solutions found in middle layers are sometimes overridden. This late-layer reversal is accompanied by concept preference analyses showing final layers prioritize safety over aggression, suggesting a mechanism by which heuristic priors can override tactical solutions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21380v2",
    "published_date": "2025-08-29 07:51:45 UTC",
    "updated_date": "2025-11-25 13:55:48 UTC"
  },
  {
    "arxiv_id": "2508.21378v1",
    "title": "RoboInspector: Unveiling the Unreliability of Policy Code for LLM-enabled Robotic Manipulation",
    "authors": [
      "Chenduo Ying",
      "Linkang Du",
      "Peng Cheng",
      "Yuanchao Shu"
    ],
    "abstract": "Large language models (LLMs) demonstrate remarkable capabilities in reasoning and code generation, enabling robotic manipulation to be initiated with just a single instruction. The LLM carries out various tasks by generating policy code required to control the robot. Despite advances in LLMs, achieving reliable policy code generation remains a significant challenge due to the diverse requirements of real-world tasks and the inherent complexity of user instructions. In practice, different users may provide distinct instructions to drive the robot for the same task, which may cause the unreliability of policy code generation. To bridge this gap, we design RoboInspector, a pipeline to unveil and characterize the unreliability of the policy code for LLM-enabled robotic manipulation from two perspectives: the complexity of the manipulation task and the granularity of the instruction. We perform comprehensive experiments with 168 distinct combinations of tasks, instructions, and LLMs in two prominent frameworks. The RoboInspector identifies four main unreliable behaviors that lead to manipulation failure. We provide a detailed characterization of these behaviors and their underlying causes, giving insight for practical development to reduce unreliability. Furthermore, we introduce a refinement approach guided by failure policy code feedback that improves the reliability of policy code generation by up to 35% in LLM-enabled robotic manipulation, evaluated in both simulation and real-world environments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21378v1",
    "published_date": "2025-08-29 07:47:17 UTC",
    "updated_date": "2025-08-29 07:47:17 UTC"
  },
  {
    "arxiv_id": "2508.21377v1",
    "title": "Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models",
    "authors": [
      "Shubham Sharma",
      "Sneha Tuli",
      "Narendra Badam"
    ],
    "abstract": "Large Language Models (LLMs) are transforming AI across industries, but their development and deployment remain complex. This survey reviews 16 key challenges in building and using LLMs and examines how these challenges are addressed by two state-of-the-art models with unique approaches: OpenAI's closed source GPT-4o (May 2024 update) and DeepSeek-V3-0324 (March 2025), a large open source Mixture-of-Experts model. Through this comparison, we showcase the trade-offs between closed source models (robust safety, fine-tuned reliability) and open source models (efficiency, adaptability). We also explore LLM applications across different domains (from chatbots and coding tools to healthcare and education), highlighting which model attributes are best suited for each use case. This article aims to guide AI researchers, developers, and decision-makers in understanding current LLM capabilities, limitations, and best practices.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.21377v1",
    "published_date": "2025-08-29 07:41:04 UTC",
    "updated_date": "2025-08-29 07:41:04 UTC"
  },
  {
    "arxiv_id": "2508.21376v2",
    "title": "AHELM: A Holistic Evaluation of Audio-Language Models",
    "authors": [
      "Tony Lee",
      "Haoqin Tu",
      "Chi Heem Wong",
      "Zijun Wang",
      "Siwei Yang",
      "Yifan Mai",
      "Yuyin Zhou",
      "Cihang Xie",
      "Percy Liang"
    ],
    "abstract": "Evaluations of audio-language models (ALMs) -- multimodal models that take interleaved audio and text as input and output text -- are hindered by the lack of standardized benchmarks; most benchmarks measure only one or two capabilities and omit evaluative aspects such as fairness or safety. Furthermore, comparison across models is difficult as separate evaluations test a limited number of models and use different prompting methods and inference parameters. To address these shortfalls, we introduce AHELM, a benchmark that aggregates various datasets -- including 2 new synthetic audio-text datasets called PARADE, which evaluates the ALMs on avoiding stereotypes, and CoRe-Bench, which measures reasoning over conversational audio through inferential multi-turn question answering -- to holistically measure the performance of ALMs across 10 aspects we have identified as important to the development and usage of ALMs: audio perception, knowledge, reasoning, emotion detection, bias, fairness, multilinguality, robustness, toxicity, and safety. We also standardize the prompts, inference parameters, and evaluation metrics to ensure equitable comparisons across models. We test 14 open-weight and closed-API ALMs from 3 developers and 3 additional simple baseline systems each consisting of an automatic speech recognizer and a language model. Our results show that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits group unfairness ($p=0.01$) on ASR tasks whereas most of the other models do not. We also find that the baseline systems perform reasonably well on AHELM, with one ranking 6th overall despite having only speech-to-text capabilities. For transparency, all raw prompts, model generations, and outputs are available on our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is intended to be a living benchmark and new datasets and models will be added over time.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21376v2",
    "published_date": "2025-08-29 07:40:39 UTC",
    "updated_date": "2025-09-02 17:58:21 UTC"
  },
  {
    "arxiv_id": "2508.21368v1",
    "title": "EconAgentic in DePIN Markets: A Large Language Model Approach to the Sharing Economy of Decentralized Physical Infrastructure",
    "authors": [
      "Yulin Liu",
      "Mocca Schweitzer"
    ],
    "abstract": "The Decentralized Physical Infrastructure (DePIN) market is revolutionizing the sharing economy through token-based economics and smart contracts that govern decentralized operations. By 2024, DePIN projects have exceeded \\$10 billion in market capitalization, underscoring their rapid growth. However, the unregulated nature of these markets, coupled with the autonomous deployment of AI agents in smart contracts, introduces risks such as inefficiencies and potential misalignment with human values. To address these concerns, we introduce EconAgentic, a Large Language Model (LLM)-powered framework designed to mitigate these challenges. Our research focuses on three key areas: 1) modeling the dynamic evolution of DePIN markets, 2) evaluating stakeholders' actions and their economic impacts, and 3) analyzing macroeconomic indicators to align market outcomes with societal goals. Through EconAgentic, we simulate how AI agents respond to token incentives, invest in infrastructure, and adapt to market conditions, comparing AI-driven decisions with human heuristic benchmarks. Our results show that EconAgentic provides valuable insights into the efficiency, inclusion, and stability of DePIN markets, contributing to both academic understanding and practical improvements in the design and governance of decentralized, tokenized economies.",
    "categories": [
      "econ.GN",
      "cs.AI"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21368v1",
    "published_date": "2025-08-29 07:17:44 UTC",
    "updated_date": "2025-08-29 07:17:44 UTC"
  },
  {
    "arxiv_id": "2508.21365v1",
    "title": "Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models",
    "authors": [
      "Yi Liao",
      "Yu Gu",
      "Yuan Sui",
      "Zining Zhu",
      "Yifan Lu",
      "Guohua Tang",
      "Zhongqian Sun",
      "Wei Yang"
    ],
    "abstract": "Large language models (LLMs) excel at complex reasoning tasks such as mathematics and coding, yet they frequently struggle with simple interactive tasks that young children perform effortlessly. This discrepancy highlights a critical gap between declarative knowledge (knowing about something) and procedural knowledge (knowing how to do something). Although traditional reinforcement learning (RL) agents can acquire procedural knowledge through environmental interaction, they often operate as black boxes and require substantial training data. In contrast, LLMs possess extensive world knowledge and reasoning capabilities, but are unable to effectively convert this static knowledge into dynamic decision-making in interactive settings. To address this challenge, we propose Think in Games (TiG), a novel framework that empowers LLMs to develop procedural understanding through direct interaction with game environments, while retaining their inherent reasoning and explanatory abilities. Specifically, TiG reformulates RL-based decision-making as a language modeling task: LLMs generate language-guided policies, which are refined iteratively through online reinforcement learning based on environmental feedback. Our experimental results show that TiG successfully bridges the gap between declarative and procedural knowledge, achieving competitive performance with dramatically lower data and computational demands compared to conventional RL methods. Moreover, TiG provides step-by-step natural language explanations for its decisions, greatly improving transparency and interpretability in complex interactive tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21365v1",
    "published_date": "2025-08-29 07:13:39 UTC",
    "updated_date": "2025-08-29 07:13:39 UTC"
  },
  {
    "arxiv_id": "2508.21353v1",
    "title": "Adaptive Heavy-Tailed Stochastic Gradient Descent",
    "authors": [
      "Bodu Gong",
      "Gustavo Enrique Batista",
      "Pierre Lafaye de Micheaux"
    ],
    "abstract": "In the era of large-scale neural network models, optimization algorithms often struggle with generalization due to an overreliance on training loss. One key insight widely accepted in the machine learning community is the idea that wide basins (regions around a local minimum where the loss increases gradually) promote better generalization by offering greater stability to small changes in input data or model parameters. In contrast, sharp minima are typically more sensitive and less stable. Motivated by two key empirical observations - the inherent heavy-tailed distribution of gradient noise in stochastic gradient descent and the Edge of Stability phenomenon during neural network training, in which curvature grows before settling at a plateau, we introduce Adaptive Heavy Tailed Stochastic Gradient Descent (AHTSGD). The algorithm injects heavier-tailed noise into the optimizer during the early stages of training to enhance exploration and gradually transitions to lighter-tailed noise as sharpness stabilizes. By dynamically adapting to the sharpness of the loss landscape throughout training, AHTSGD promotes accelerated convergence to wide basins. AHTSGD is the first algorithm to adjust the nature of injected noise into an optimizer based on the Edge of Stability phenomenon. AHTSGD consistently outperforms SGD and other noise-based methods on benchmarks like MNIST and CIFAR-10, with marked gains on noisy datasets such as SVHN. It ultimately accelerates early training from poor initializations and improves generalization across clean and noisy settings, remaining robust to learning rate choices.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21353v1",
    "published_date": "2025-08-29 06:32:26 UTC",
    "updated_date": "2025-08-29 06:32:26 UTC"
  },
  {
    "arxiv_id": "2509.04468v1",
    "title": "Evaluating Large Language Models for Financial Reasoning: A CFA-Based Benchmark Study",
    "authors": [
      "Xuan Yao",
      "Qianteng Wang",
      "Xinbo Liu",
      "Ke-Wei Huang"
    ],
    "abstract": "The rapid advancement of large language models presents significant opportunities for financial applications, yet systematic evaluation in specialized financial contexts remains limited. This study presents the first comprehensive evaluation of state-of-the-art LLMs using 1,560 multiple-choice questions from official mock exams across Levels I-III of CFA, most rigorous professional certifications globally that mirror real-world financial analysis complexity. We compare models distinguished by core design priorities: multi-modal and computationally powerful, reasoning-specialized and highly accurate, and lightweight efficiency-optimized.\n  We assess models under zero-shot prompting and through a novel Retrieval-Augmented Generation pipeline that integrates official CFA curriculum content. The RAG system achieves precise domain-specific knowledge retrieval through hierarchical knowledge organization and structured query generation, significantly enhancing reasoning accuracy in professional financial certification evaluation.\n  Results reveal that reasoning-oriented models consistently outperform others in zero-shot settings, while the RAG pipeline provides substantial improvements particularly for complex scenarios. Comprehensive error analysis identifies knowledge gaps as the primary failure mode, with minimal impact from text readability. These findings provide actionable insights for LLM deployment in finance, offering practitioners evidence-based guidance for model selection and cost-performance optimization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.04468v1",
    "published_date": "2025-08-29 06:13:21 UTC",
    "updated_date": "2025-08-29 06:13:21 UTC"
  },
  {
    "arxiv_id": "2508.21340v1",
    "title": "DLGAN : Time Series Synthesis Based on Dual-Layer Generative Adversarial Networks",
    "authors": [
      "Xuan Hou",
      "Shuhan Liu",
      "Zhaohui Peng",
      "Yaohui Chu",
      "Yue Zhang",
      "Yining Wang"
    ],
    "abstract": "Time series synthesis is an effective approach to ensuring the secure circulation of time series data. Existing time series synthesis methods typically perform temporal modeling based on random sequences to generate target sequences, which often struggle to ensure the temporal dependencies in the generated time series. Additionally, directly modeling temporal features on random sequences makes it challenging to accurately capture the feature information of the original time series. To address the above issues, we propose a simple but effective generative model \\textbf{D}ual-\\textbf{L}ayer \\textbf{G}enerative \\textbf{A}dversarial \\textbf{N}etworks, named \\textbf{DLGAN}. The model decomposes the time series generation process into two stages: sequence feature extraction and sequence reconstruction. First, these two stages form a complete time series autoencoder, enabling supervised learning on the original time series to ensure that the reconstruction process can restore the temporal dependencies of the sequence. Second, a Generative Adversarial Network (GAN) is used to generate synthetic feature vectors that align with the real-time sequence feature vectors, ensuring that the generator can capture the temporal features from real time series. Extensive experiments on four public datasets demonstrate the superiority of this model across various evaluation metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.21340v1",
    "published_date": "2025-08-29 05:58:36 UTC",
    "updated_date": "2025-08-29 05:58:36 UTC"
  },
  {
    "arxiv_id": "2509.02592v1",
    "title": "Beyond Synthetic Augmentation: Group-Aware Threshold Calibration for Robust Balanced Accuracy in Imbalanced Learning",
    "authors": [
      "Hunter Gittlin"
    ],
    "abstract": "Class imbalance remains a fundamental challenge in machine learning, with traditional solutions often creating as many problems as they solve. We demonstrate that group-aware threshold calibration--setting different decision thresholds for different demographic groups--provides superior robustness compared to synthetic data generation methods. Through extensive experiments, we show that group-specific thresholds achieve 1.5-4% higher balanced accuracy than SMOTE and CT-GAN augmented models while improving worst-group balanced accuracy. Unlike single-threshold approaches that apply one cutoff across all groups, our group-aware method optimizes the Pareto frontier between balanced accuracy and worst-group balanced accuracy, enabling fine-grained control over group-level performance. Critically, we find that applying group thresholds to synthetically augmented data yields minimal additional benefit, suggesting these approaches are fundamentally redundant. Our results span seven model families including linear, tree-based, instance-based, and boosting methods, confirming that group-aware threshold calibration offers a simpler, more interpretable, and more effective solution to class imbalance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the AIDEM'25 conference at ECML; to be published in Springer (LNCS)",
    "pdf_url": "https://arxiv.org/pdf/2509.02592v1",
    "published_date": "2025-08-29 05:57:17 UTC",
    "updated_date": "2025-08-29 05:57:17 UTC"
  },
  {
    "arxiv_id": "2510.07320v1",
    "title": "Deep Learning Based Approach to Enhanced Recognition of Emotions and Behavioral Patterns of Autistic Children",
    "authors": [
      "Nelaka K. A. R",
      "Peiris M. K.",
      "Liyanage R. P. B"
    ],
    "abstract": "Autism Spectrum Disorder significantly influences the communication abilities, learning processes, behavior, and social interactions of individuals. Although early intervention and customized educational strategies are critical to improving outcomes, there is a pivotal gap in understanding and addressing nuanced behavioral patterns and emotional identification in autistic children prior to skill development. This extended research delves into the foundational step of recognizing and mapping these patterns as a prerequisite to improving learning and soft skills. Using a longitudinal approach to monitor emotions and behaviors, this study aims to establish a baseline understanding of the unique needs and challenges faced by autistic students, particularly in the Information Technology domain, where opportunities are markedly limited. Through a detailed analysis of behavioral trends over time, we propose a targeted framework for developing applications and technical aids designed to meet these identified needs. Our research underscores the importance of a sequential and evidence-based intervention approach that prioritizes a deep understanding of each child's behavioral and emotional landscape as the basis for effective skill development. By shifting the focus toward early identification of behavioral patterns, we aim to foster a more inclusive and supportive learning environment that can significantly improve the educational and developmental trajectory of children with ASD.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2510.07320v1",
    "published_date": "2025-08-29 05:50:47 UTC",
    "updated_date": "2025-08-29 05:50:47 UTC"
  },
  {
    "arxiv_id": "2508.21334v1",
    "title": "Stairway to Fairness: Connecting Group and Individual Fairness",
    "authors": [
      "Theresia Veronika Rampisela",
      "Maria Maistro",
      "Tuukka Ruotsalo",
      "Falk Scholer",
      "Christina Lioma"
    ],
    "abstract": "Fairness in recommender systems (RSs) is commonly categorised into group fairness and individual fairness. However, there is no established scientific understanding of the relationship between the two fairness types, as prior work on both types has used different evaluation measures or evaluation objectives for each fairness type, thereby not allowing for a proper comparison of the two. As a result, it is currently not known how increasing one type of fairness may affect the other. To fill this gap, we study the relationship of group and individual fairness through a comprehensive comparison of evaluation measures that can be used for both fairness types. Our experiments with 8 runs across 3 datasets show that recommendations that are highly fair for groups can be very unfair for individuals. Our finding is novel and useful for RS practitioners aiming to improve the fairness of their systems. Our code is available at: https://github.com/theresiavr/stairway-to-fairness.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted to RecSys 2025 (short paper)",
    "pdf_url": "https://arxiv.org/pdf/2508.21334v1",
    "published_date": "2025-08-29 05:25:05 UTC",
    "updated_date": "2025-08-29 05:25:05 UTC"
  },
  {
    "arxiv_id": "2508.21330v1",
    "title": "Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models",
    "authors": [
      "Xuan Hou",
      "Shuhan Liu",
      "Zhaohui Peng",
      "Yaohui Chu",
      "Yue Zhang",
      "Yining Wang"
    ],
    "abstract": "Generative models have been successfully used in the field of time series generation. However, when dealing with long-term time series, which span over extended periods and exhibit more complex long-term temporal patterns, the task of generation becomes significantly more challenging. Long-term time series exhibit long-range temporal dependencies, but their data distribution also undergoes gradual changes over time. Finding a balance between these long-term dependencies and the drift in data distribution is a key challenge. On the other hand, long-term time series contain more complex interrelationships between different feature sequences, making the task of effectively capturing both intra-sequence and inter-sequence dependencies another important challenge. To address these issues, we propose Stage-Diff, a staged generative model for long-term time series based on diffusion models. First, through stage-wise sequence generation and inter-stage information transfer, the model preserves long-term sequence dependencies while enabling the modeling of data distribution shifts. Second, within each stage, progressive sequence decomposition is applied to perform channel-independent modeling at different time scales, while inter-stage information transfer utilizes multi-channel fusion modeling. This approach combines the robustness of channel-independent modeling with the information fusion advantages of multi-channel modeling, effectively balancing the intra-sequence and inter-sequence dependencies of long-term time series. Extensive experiments on multiple real-world datasets validate the effectiveness of Stage-Diff in long-term time series generation tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.21330v1",
    "published_date": "2025-08-29 05:10:10 UTC",
    "updated_date": "2025-08-29 05:10:10 UTC"
  },
  {
    "arxiv_id": "2508.21320v1",
    "title": "Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation",
    "authors": [
      "Mohsen Nayebi Kerdabadi",
      "Arya Hadizadeh Moghaddam",
      "Dongjie Wang",
      "Zijun Yao"
    ],
    "abstract": "Medical ontology graphs map external knowledge to medical codes in electronic health records via structured relationships. By leveraging domain-approved connections (e.g., parent-child), predictive models can generate richer medical concept representations by incorporating contextual information from related concepts. However, existing literature primarily focuses on incorporating domain knowledge from a single ontology system, or from multiple ontology systems (e.g., diseases, drugs, and procedures) in isolation, without integrating them into a unified learning structure. Consequently, concept representation learning often remains limited to intra-ontology relationships, overlooking cross-ontology connections. In this paper, we propose LINKO, a large language model (LLM)-augmented integrative ontology learning framework that leverages multiple ontology graphs simultaneously by enabling dual-axis knowledge propagation both within and across heterogeneous ontology systems to enhance medical concept representation learning. Specifically, LINKO first employs LLMs to provide a graph-retrieval-augmented initialization for ontology concept embedding, through an engineered prompt that includes concept descriptions, and is further augmented with ontology context. Second, our method jointly learns the medical concepts in diverse ontology graphs by performing knowledge propagation in two axes: (1) intra-ontology vertical propagation across hierarchical ontology levels and (2) inter-ontology horizontal propagation within every level in parallel. Last, through extensive experiments on two public datasets, we validate the superior performance of LINKO over state-of-the-art baselines. As a plug-in encoder compatible with existing EHR predictive models, LINKO further demonstrates enhanced robustness in scenarios involving limited data availability and rare disease prediction.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "This work has been accepted as a full research paper at CIKM 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.21320v1",
    "published_date": "2025-08-29 04:13:42 UTC",
    "updated_date": "2025-08-29 04:13:42 UTC"
  },
  {
    "arxiv_id": "2509.10482v1",
    "title": "AegisShield: Democratizing Cyber Threat Modeling with Generative AI",
    "authors": [
      "Matthew Grofsky"
    ],
    "abstract": "The increasing sophistication of technology systems makes traditional threat modeling hard to scale, especially for small organizations with limited resources. This paper develops and evaluates AegisShield, a generative AI enhanced threat modeling tool that implements STRIDE and MITRE ATT&CK to automate threat generation and provide systematic assessments. By integrating real time threat intelligence from the National Vulnerability Database and AlienVault Open Threat Exchange, AegisShield produces streamlined and accessible threat descriptions. Our assessment of 243 threats from 15 case studies and over 8000 AI generated threats shows that AegisShield reduces complexity (p less than 0.001), yields outputs semantically aligned with expert developed threats (p less than 0.05), and achieves an 85.4 percent success rate in mapping threats to MITRE ATT&CK techniques (p less than 0.001). Automating and standardizing threat modeling helps under resourced organizations address risk earlier and supports wider adoption of secure by design practices.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Master's thesis",
    "pdf_url": "https://arxiv.org/pdf/2509.10482v1",
    "published_date": "2025-08-29 03:49:15 UTC",
    "updated_date": "2025-08-29 03:49:15 UTC"
  },
  {
    "arxiv_id": "2509.02591v3",
    "title": "Ensemble of Pathology Foundation Models for MIDOG 2025 Track 2: Atypical Mitosis Classification",
    "authors": [
      "Mieko Ochi",
      "Bae Yuan"
    ],
    "abstract": "Mitotic figures are classified into typical and atypical variants, with atypical counts correlating strongly with tumor aggressiveness. Accurate differentiation is therefore essential for patient prognostication and resource allocation, yet remains challenging even for expert pathologists. Here, we leveraged Pathology Foundation Models (PFMs) pre-trained on large histopathology datasets and applied parameter-efficient fine-tuning via low-rank adaptation. In addition, we incorporated ConvNeXt V2, a state-of-the-art convolutional neural network architecture, to complement PFMs. During training, we employed a fisheye transform to emphasize mitoses and Fourier Domain Adaptation using ImageNet target images. Finally, we ensembled multiple PFMs to integrate complementary morphological insights, achieving competitive balanced accuracy on the Preliminary Evaluation Phase dataset.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02591v3",
    "published_date": "2025-08-29 03:24:57 UTC",
    "updated_date": "2025-09-18 10:00:25 UTC"
  },
  {
    "arxiv_id": "2509.04467v4",
    "title": "PDTrim: Targeted Pruning for Prefill-Decode Disaggregation in Inference",
    "authors": [
      "Hao Zhang",
      "Mengsi Lyu",
      "Zhuo Chen",
      "Xingrun Xing",
      "Yulong Ao",
      "Yonghua Lin"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate exceptional capabilities across various tasks, but their deployment is constrained by high computational and memory costs. Model pruning provides an effective means to alleviate these demands. However, existing methods often ignore the characteristics of prefill-decode (PD) disaggregation in practice. In this paper, we propose a pruning method that is highly integrated with PD disaggregation, enabling more precise pruning of blocks. Our approach constructs pruning and distillation sets to perform iterative block removal, obtaining better pruning solutions. Moreover, we analyze the pruning sensitivity of the prefill and decode stages and identify removable blocks specific to each stage, making it well suited for PD disaggregation deployment. Extensive experiments demonstrate our approach consistently achieves strong performance in both PD disaggregation and PD unified (non-PD disaggregation) settings, and can also be extended to other non-block pruning methods. Under the same settings, our method achieves improved performance and faster inference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Minor revisions",
    "pdf_url": "https://arxiv.org/pdf/2509.04467v4",
    "published_date": "2025-08-29 02:29:52 UTC",
    "updated_date": "2025-12-14 14:46:31 UTC"
  },
  {
    "arxiv_id": "2508.21307v1",
    "title": "MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems",
    "authors": [
      "Sri Ram Macharla",
      "Sridhar Murthy J",
      "Anjaneyulu Pasala"
    ],
    "abstract": "MultiFluxAI is an innovative AI platform developed to address the challenges of managing and integrating vast, disparate data sources in product engineering across application domains. It addresses both current and new service related queries that enhance user engagement in the digital ecosystem. This platform leverages advanced AI techniques, such as Generative AI, vectorization, and agentic orchestration to provide dynamic and context-aware responses to complex user queries.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Abstract accepted for presentation at ACM ISEC 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.21307v1",
    "published_date": "2025-08-29 02:08:36 UTC",
    "updated_date": "2025-08-29 02:08:36 UTC"
  },
  {
    "arxiv_id": "2509.12212v1",
    "title": "PowerGrow: Feasible Co-Growth of Structures and Dynamics for Power Grid Synthesis",
    "authors": [
      "Xinyu He",
      "Chenhan Xiao",
      "Haoran Li",
      "Ruizhong Qiu",
      "Zhe Xu",
      "Yang Weng",
      "Jingrui He",
      "Hanghang Tong"
    ],
    "abstract": "Modern power systems are becoming increasingly dynamic, with changing topologies and time-varying loads driven by renewable energy variability, electric vehicle adoption, and active grid reconfiguration. Despite these changes, publicly available test cases remain scarce, due to security concerns and the significant effort required to anonymize real systems. Such limitations call for generative tools that can jointly synthesize grid structure and nodal dynamics. However, modeling the joint distribution of network topology, branch attributes, bus properties, and dynamic load profiles remains a major challenge, while preserving physical feasibility and avoiding prohibitive computational costs. We present PowerGrow, a co-generative framework that significantly reduces computational overhead while maintaining operational validity. The core idea is dependence decomposition: the complex joint distribution is factorized into a chain of conditional distributions over feasible grid topologies, time-series bus loads, and other system attributes, leveraging their mutual dependencies. By constraining the generation process at each stage, we implement a hierarchical graph beta-diffusion process for structural synthesis, paired with a temporal autoencoder that embeds time-series data into a compact latent space, improving both training stability and sample fidelity. Experiments across benchmark settings show that PowerGrow not only outperforms prior diffusion models in fidelity and diversity but also achieves a 98.9\\% power flow convergence rate and improved N-1 contingency resilience. This demonstrates its ability to generate operationally valid and realistic power grid scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.12212v1",
    "published_date": "2025-08-29 01:47:27 UTC",
    "updated_date": "2025-08-29 01:47:27 UTC"
  },
  {
    "arxiv_id": "2508.21302v3",
    "title": "Locus: Agentic Predicate Synthesis for Directed Fuzzing",
    "authors": [
      "Jie Zhu",
      "Chihao Shen",
      "Ziyang Li",
      "Jiahao Yu",
      "Yizheng Chen",
      "Kexin Pei"
    ],
    "abstract": "Directed fuzzing aims to find program inputs that lead to specified target program states. It has broad applications, such as debugging system crashes, confirming reported bugs, and generating exploits for potential vulnerabilities. This task is inherently challenging because target states are often deeply nested in the program, while the search space manifested by numerous possible program inputs is prohibitively large. Existing approaches rely on branch distances or manually-specified constraints to guide the search; however, the branches alone are often insufficient to precisely characterize progress toward reaching the target states, while the manually specified constraints are often tailored for specific bug types and thus difficult to generalize to diverse target states and programs.\n  We present Locus, a novel framework to improve the efficiency of directed fuzzing. Our key insight is to synthesize predicates to capture fuzzing progress as semantically meaningful intermediate states, serving as milestones towards reaching the target states. When used to instrument the program under fuzzing, they can reject executions unlikely to reach the target states, while providing additional coverage guidance. To automate this task and generalize to diverse programs, Locus features an agentic framework with program analysis tools to synthesize and iteratively refine the candidate predicates, while ensuring the predicates strictly relax the target states to prevent false rejections via symbolic execution. Our evaluation shows that Locus substantially improves the efficiency of eight state-of-the-art fuzzers in discovering real-world vulnerabilities, achieving an average speedup of 41.6x. So far, Locus has found nine previously unpatched bugs, with three already acknowledged with draft patches.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.21302v3",
    "published_date": "2025-08-29 01:47:07 UTC",
    "updated_date": "2025-12-09 02:27:24 UTC"
  },
  {
    "arxiv_id": "2508.21296v2",
    "title": "MyGO: Memory Yielding Generative Offline-consolidation for Lifelong Learning Systems",
    "authors": [
      "Shihao Ji",
      "Zihui Song"
    ],
    "abstract": "Continual or Lifelong Learning aims to develop models capable of acquiring new knowledge from a sequence of tasks without catastrophically forgetting what has been learned before. Existing approaches often rely on storing samples from previous tasks (experience replay) or employing complex regularization terms to protect learned weights. However, these methods face challenges related to data privacy, storage limitations, and performance degradation when tasks are dissimilar. To address these challenges, we introduce MyGO (Memory Yielding Generative Offline-consolidation), a novel lifelong learning framework inspired by the biological wake-sleep cycle. During the \"wake\" phase, the system rapidly learns a new task and trains a compact generative model (Generative Memory, G-mem) to capture its data distribution. During the \"sleep\" phase, the system enters an offline state, using all learned G-mem models to generate pseudo-data (\"dreams\") and consolidate new and old knowledge into a core feature extractor via knowledge distillation. This approach obviates the need to store any raw data, retaining only compact generative models, which offers significant advantages in privacy and storage efficiency. We evaluate MyGO on computer vision (Split-MNIST) and natural language processing (Split-AG News) benchmarks, comparing it against a sequential fine-tuning baseline. The results demonstrate that MyGO significantly mitigates catastrophic forgetting and maintains high average accuracy across tasks, proving the framework's effectiveness and domain-generality.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Upon re-evaluating the proposed \"Sleep Phase\" mechanism, the authors identified stability issues in the generative replay component that limit the framework's scalability to high-dimensional data. We are withdrawing the paper to fundamentally revise the generative architecture and correct these limitations before any future submission",
    "pdf_url": "https://arxiv.org/pdf/2508.21296v2",
    "published_date": "2025-08-29 01:29:48 UTC",
    "updated_date": "2026-01-07 02:01:51 UTC"
  },
  {
    "arxiv_id": "2508.21294v1",
    "title": "BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning",
    "authors": [
      "João Guilherme Alves Santos",
      "Giovana Kerche Bonás",
      "Thales Sales Almeida"
    ],
    "abstract": "With the growing capabilities of Large Language Models (LLMs), there is an increasing need for robust evaluation methods, especially in multilingual and non-English contexts. We present an updated version of the BLUEX dataset, now including 2024-2025 exams and automatically generated image captions using state-of-the-art models, enhancing its relevance for data contamination studies in LLM pretraining. Captioning strategies increase accessibility to text-only models by more than 40%, producing 1,422 usable questions, more than doubling the number in the original BLUEX. We evaluated commercial and open-source LLMs and their ability to leverage visual context through captions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 5 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.21294v1",
    "published_date": "2025-08-29 01:23:28 UTC",
    "updated_date": "2025-08-29 01:23:28 UTC"
  },
  {
    "arxiv_id": "2508.21290v1",
    "title": "Efficient Code Embeddings from Code Generation Models",
    "authors": [
      "Daria Kryvosheieva",
      "Saba Sturua",
      "Michael Günther",
      "Scott Martens",
      "Han Xiao"
    ],
    "abstract": "jina-code-embeddings is a novel code embedding model suite designed to retrieve code from natural language queries, perform technical question-answering, and identify semantically similar code snippets across programming languages. It makes innovative use of an autoregressive backbone pre-trained on both text and code, generating embeddings via last-token pooling. We outline the training recipe and demonstrate state-of-the-art performance despite the relatively small size of the models, validating this approach to code embedding model construction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, table and evaluations 5-9",
    "pdf_url": "https://arxiv.org/pdf/2508.21290v1",
    "published_date": "2025-08-29 01:18:15 UTC",
    "updated_date": "2025-08-29 01:18:15 UTC"
  },
  {
    "arxiv_id": "2508.21285v1",
    "title": "A Financial Brain Scan of the LLM",
    "authors": [
      "Hui Chen",
      "Antoine Didisheim",
      "Luciano Somoza",
      "Hanqing Tian"
    ],
    "abstract": "Emerging techniques in computer science make it possible to \"brain scan\" large language models (LLMs), identify the plain-English concepts that guide their reasoning, and steer them while holding other factors constant. We show that this approach can map LLM-generated economic forecasts to concepts such as sentiment, technical analysis, and timing, and compute their relative importance without reducing performance. We also show that models can be steered to be more or less risk-averse, optimistic, or pessimistic, which allows researchers to correct or simulate biases. The method is transparent, lightweight, and replicable for empirical research in the social sciences.",
    "categories": [
      "q-fin.GN",
      "cs.AI",
      "cs.CE",
      "econ.GN"
    ],
    "primary_category": "q-fin.GN",
    "comment": "47 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.21285v1",
    "published_date": "2025-08-29 01:12:57 UTC",
    "updated_date": "2025-08-29 01:12:57 UTC"
  }
]