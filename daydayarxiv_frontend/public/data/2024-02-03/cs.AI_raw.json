[
  {
    "arxiv_id": "2402.02289v1",
    "title": "SemPool: Simple, robust, and interpretable KG pooling for enhancing language models",
    "authors": [
      "Costas Mavromatis",
      "Petros Karypis",
      "George Karypis"
    ],
    "abstract": "Knowledge Graph (KG) powered question answering (QA) performs complex\nreasoning over language semantics as well as knowledge facts. Graph Neural\nNetworks (GNNs) learn to aggregate information from the underlying KG, which is\ncombined with Language Models (LMs) for effective reasoning with the given\nquestion. However, GNN-based methods for QA rely on the graph information of\nthe candidate answer nodes, which limits their effectiveness in more\nchallenging settings where critical answer information is not included in the\nKG. We propose a simple graph pooling approach that learns useful semantics of\nthe KG that can aid the LM's reasoning and that its effectiveness is robust\nunder graph perturbations. Our method, termed SemPool, represents KG facts with\npre-trained LMs, learns to aggregate their semantic information, and fuses it\nat different layers of the LM. Our experimental results show that SemPool\noutperforms state-of-the-art GNN-based methods by 2.27% accuracy points on\naverage when answer information is missing from the KG. In addition, SemPool\noffers interpretability on what type of graph information is fused at different\nLM layers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02289v1",
    "published_date": "2024-02-03 23:03:51 UTC",
    "updated_date": "2024-02-03 23:03:51 UTC"
  },
  {
    "arxiv_id": "2402.02287v4",
    "title": "Future Directions in the Theory of Graph Machine Learning",
    "authors": [
      "Christopher Morris",
      "Fabrizio Frasca",
      "Nadav Dym",
      "Haggai Maron",
      "İsmail İlkan Ceylan",
      "Ron Levie",
      "Derek Lim",
      "Michael Bronstein",
      "Martin Grohe",
      "Stefanie Jegelka"
    ],
    "abstract": "Machine learning on graphs, especially using graph neural networks (GNNs),\nhas seen a surge in interest due to the wide availability of graph data across\na broad spectrum of disciplines, from life to social and engineering sciences.\nDespite their practical success, our theoretical understanding of the\nproperties of GNNs remains highly incomplete. Recent theoretical advancements\nprimarily focus on elucidating the coarse-grained expressive power of GNNs,\npredominantly employing combinatorial techniques. However, these studies do not\nperfectly align with practice, particularly in understanding the generalization\nbehavior of GNNs when trained with stochastic first-order optimization\ntechniques. In this position paper, we argue that the graph machine learning\ncommunity needs to shift its attention to developing a balanced theory of graph\nmachine learning, focusing on a more thorough understanding of the interplay of\nexpressive power, generalization, and optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DM",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02287v4",
    "published_date": "2024-02-03 22:55:31 UTC",
    "updated_date": "2024-06-14 15:54:12 UTC"
  },
  {
    "arxiv_id": "2402.02286v3",
    "title": "Multi-Level Aggregation and Recursive Alignment Architecture for Efficient Parallel Inference Segmentation Network",
    "authors": [
      "Yanhua Zhang",
      "Ke Zhang",
      "Jingyu Wang",
      "Yulin Wu",
      "Wuwei Wang"
    ],
    "abstract": "Real-time semantic segmentation is a crucial research for real-world\napplications. However, many methods lay particular emphasis on reducing the\ncomputational complexity and model size, while largely sacrificing the\naccuracy. To tackle this problem, we propose a parallel inference network\ncustomized for semantic segmentation tasks to achieve a good trade-off between\nspeed and accuracy. We employ a shallow backbone to ensure real-time speed, and\npropose three core components to compensate for the reduced model capacity to\nimprove accuracy. Specifically, we first design a dual-pyramidal path\narchitecture (Multi-level Feature Aggregation Module, MFAM) to aggregate\nmulti-level features from the encoder to each scale, providing hierarchical\nclues for subsequent spatial alignment and corresponding in-network inference.\nThen, we build Recursive Alignment Module (RAM) by combining the flow-based\nalignment module with recursive upsampling architecture for accurate spatial\nalignment between multi-scale feature maps with half the computational\ncomplexity of the straightforward alignment method. Finally, we perform\nindependent parallel inference on the aligned features to obtain multi-scale\nscores, and adaptively fuse them through an attention-based Adaptive Scores\nFusion Module (ASFM) so that the final prediction can favor objects of multiple\nscales. Our framework shows a better balance between speed and accuracy than\nstate-of-the-art real-time methods on Cityscapes and CamVid datasets. We also\nconducted systematic ablation studies to gain insight into our motivation and\narchitectural design. Code is available at:\nhttps://github.com/Yanhua-Zhang/MFARANet.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 9 figures and 12 Tables. Manuscript completed on April 30,\n  2022",
    "pdf_url": "http://arxiv.org/pdf/2402.02286v3",
    "published_date": "2024-02-03 22:51:17 UTC",
    "updated_date": "2024-04-18 13:33:32 UTC"
  },
  {
    "arxiv_id": "2402.02285v1",
    "title": "SynthDST: Synthetic Data is All You Need for Few-Shot Dialog State Tracking",
    "authors": [
      "Atharva Kulkarni",
      "Bo-Hsiang Tseng",
      "Joel Ruben Antony Moniz",
      "Dhivya Piraviperumal",
      "Hong Yu",
      "Shruti Bhargava"
    ],
    "abstract": "In-context learning with Large Language Models (LLMs) has emerged as a\npromising avenue of research in Dialog State Tracking (DST). However, the\nbest-performing in-context learning methods involve retrieving and adding\nsimilar examples to the prompt, requiring access to labeled training data.\nProcuring such training data for a wide range of domains and applications is\ntime-consuming, expensive, and, at times, infeasible. While zero-shot learning\nrequires no training data, it significantly lags behind the few-shot setup.\nThus, `\\textit{Can we efficiently generate synthetic data for any dialogue\nschema to enable few-shot prompting?}' Addressing this question, we propose\n\\method, a data generation framework tailored for DST, utilizing LLMs. Our\napproach only requires the dialogue schema and a few hand-crafted dialogue\ntemplates to synthesize natural, coherent, and free-flowing dialogues with DST\nannotations. Few-shot learning using data from {\\method} results in $4-5%$\nimprovement in Joint Goal Accuracy over the zero-shot baseline on MultiWOZ 2.1\nand 2.4. Remarkably, our few-shot learning approach recovers nearly $98%$ of\nthe performance compared to the few-shot setup using human-annotated training\ndata. Our synthetic data and code can be accessed at\nhttps://github.com/apple/ml-synthdst",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages. 4 figures, EACL 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2402.02285v1",
    "published_date": "2024-02-03 22:49:00 UTC",
    "updated_date": "2024-02-03 22:49:00 UTC"
  },
  {
    "arxiv_id": "2402.05951v3",
    "title": "MinMaxMin $Q$-learning",
    "authors": [
      "Nitsan Soffair",
      "Shie Mannor"
    ],
    "abstract": "MinMaxMin $Q$-learning is a novel optimistic Actor-Critic algorithm that\naddresses the problem of overestimation bias ($Q$-estimations are\noverestimating the real $Q$-values) inherent in conservative RL algorithms. Its\ncore formula relies on the disagreement among $Q$-networks in the form of the\nmin-batch MaxMin $Q$-networks distance which is added to the $Q$-target and\nused as the priority experience replay sampling-rule. We implement MinMaxMin on\ntop of TD3 and TD7, subjecting it to rigorous testing against state-of-the-art\ncontinuous-space algorithms-DDPG, TD3, and TD7-across popular MuJoCo and Bullet\nenvironments. The results show a consistent performance improvement of\nMinMaxMin over DDPG, TD3, and TD7 across all tested tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper do not ready",
    "pdf_url": "http://arxiv.org/pdf/2402.05951v3",
    "published_date": "2024-02-03 21:58:06 UTC",
    "updated_date": "2024-06-02 19:40:34 UTC"
  },
  {
    "arxiv_id": "2402.05950v3",
    "title": "SQT -- std $Q$-target",
    "authors": [
      "Nitsan Soffair",
      "Dotan Di-Castro",
      "Orly Avner",
      "Shie Mannor"
    ],
    "abstract": "Std $Q$-target is a conservative, actor-critic, ensemble, $Q$-learning-based\nalgorithm, which is based on a single key $Q$-formula: $Q$-networks standard\ndeviation, which is an \"uncertainty penalty\", and, serves as a minimalistic\nsolution to the problem of overestimation bias. We implement SQT on top of\nTD3/TD7 code and test it against the state-of-the-art (SOTA) actor-critic\nalgorithms, DDPG, TD3 and TD7 on seven popular MuJoCo and Bullet tasks. Our\nresults demonstrate SQT's $Q$-target formula superiority over TD3's $Q$-target\nformula as a conservative solution to overestimation bias in RL, while SQT\nshows a clear performance advantage on a wide margin over DDPG, TD3, and TD7 on\nall tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05950v3",
    "published_date": "2024-02-03 21:36:22 UTC",
    "updated_date": "2024-06-02 19:39:44 UTC"
  },
  {
    "arxiv_id": "2402.02268v1",
    "title": "Federated Learning with New Knowledge: Fundamentals, Advances, and Futures",
    "authors": [
      "Lixu Wang",
      "Yang Zhao",
      "Jiahua Dong",
      "Ating Yin",
      "Qinbin Li",
      "Xiao Wang",
      "Dusit Niyato",
      "Qi Zhu"
    ],
    "abstract": "Federated Learning (FL) is a privacy-preserving distributed learning approach\nthat is rapidly developing in an era where privacy protection is increasingly\nvalued. It is this rapid development trend, along with the continuous emergence\nof new demands for FL in the real world, that prompts us to focus on a very\nimportant problem: Federated Learning with New Knowledge. The primary challenge\nhere is to effectively incorporate various new knowledge into existing FL\nsystems and evolve these systems to reduce costs, extend their lifespan, and\nfacilitate sustainable development. In this paper, we systematically define the\nmain sources of new knowledge in FL, including new features, tasks, models, and\nalgorithms. For each source, we thoroughly analyze and discuss how to\nincorporate new knowledge into existing FL systems and examine the impact of\nthe form and timing of new knowledge arrival on the incorporation process.\nFurthermore, we comprehensively discuss the potential future directions for FL\nwith new knowledge, considering a variety of factors such as scenario setups,\nefficiency, and security. There is also a continuously updating repository for\nthis topic: https://github.com/conditionWang/FLNK.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.02268v1",
    "published_date": "2024-02-03 21:29:31 UTC",
    "updated_date": "2024-02-03 21:29:31 UTC"
  },
  {
    "arxiv_id": "2402.02263v5",
    "title": "MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly Mixed Classifiers",
    "authors": [
      "Yatong Bai",
      "Mo Zhou",
      "Vishal M. Patel",
      "Somayeh Sojoudi"
    ],
    "abstract": "Adversarial robustness often comes at the cost of degraded accuracy, impeding\nreal-life applications of robust classification models. Training-based\nsolutions for better trade-offs are limited by incompatibilities with\nalready-trained high-performance large models, necessitating the exploration of\ntraining-free ensemble approaches. Observing that robust models are more\nconfident in correct predictions than in incorrect ones on clean and\nadversarial data alike, we speculate amplifying this \"benign confidence\nproperty\" can reconcile accuracy and robustness in an ensemble setting. To\nachieve so, we propose \"MixedNUTS\", a training-free method where the output\nlogits of a robust classifier and a standard non-robust classifier are\nprocessed by nonlinear transformations with only three parameters, which are\noptimized through an efficient algorithm. MixedNUTS then converts the\ntransformed logits into probabilities and mixes them as the overall output. On\nCIFAR-10, CIFAR-100, and ImageNet datasets, experimental results with custom\nstrong adaptive attacks demonstrate MixedNUTS's vastly improved accuracy and\nnear-SOTA robustness -- it boosts CIFAR-100 clean accuracy by 7.86 points,\nsacrificing merely 0.87 points in robust accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "68T07"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02263v5",
    "published_date": "2024-02-03 21:12:36 UTC",
    "updated_date": "2024-10-16 00:15:51 UTC"
  },
  {
    "arxiv_id": "2402.02262v2",
    "title": "Data Quality Matters: Suicide Intention Detection on Social Media Posts Using RoBERTa-CNN",
    "authors": [
      "Emily Lin",
      "Jian Sun",
      "Hsingyu Chen",
      "Mohammad H. Mahoor"
    ],
    "abstract": "Suicide remains a pressing global health concern, necessitating innovative\napproaches for early detection and intervention. This paper focuses on\nidentifying suicidal intentions in posts from the SuicideWatch subreddit by\nproposing a novel deep-learning approach that utilizes the state-of-the-art\nRoBERTa-CNN model. The robustly Optimized BERT Pretraining Approach (RoBERTa)\nexcels at capturing textual nuances and forming semantic relationships within\nthe text. The remaining Convolutional Neural Network (CNN) head enhances\nRoBERTa's capacity to discern critical patterns from extensive datasets. To\nevaluate RoBERTa-CNN, we conducted experiments on the Suicide and Depression\nDetection dataset, yielding promising results. For instance, RoBERTa-CNN\nachieves a mean accuracy of 98% with a standard deviation (STD) of 0.0009.\nAdditionally, we found that data quality significantly impacts the training of\na robust model. To improve data quality, we removed noise from the text data\nwhile preserving its contextual content through either manually cleaning or\nutilizing the OpenAI API.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "4 pages, 1 figure, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.02262v2",
    "published_date": "2024-02-03 20:58:09 UTC",
    "updated_date": "2024-12-20 18:21:16 UTC"
  },
  {
    "arxiv_id": "2402.02258v2",
    "title": "XTSFormer: Cross-Temporal-Scale Transformer for Irregular-Time Event Prediction in Clinical Applications",
    "authors": [
      "Tingsong Xiao",
      "Zelin Xu",
      "Wenchong He",
      "Zhengkun Xiao",
      "Yupu Zhang",
      "Zibo Liu",
      "Shigang Chen",
      "My T. Thai",
      "Jiang Bian",
      "Parisa Rashidi",
      "Zhe Jiang"
    ],
    "abstract": "Adverse clinical events related to unsafe care are among the top ten causes\nof death in the U.S. Accurate modeling and prediction of clinical events from\nelectronic health records (EHRs) play a crucial role in patient safety\nenhancement. An example is modeling de facto care pathways that characterize\ncommon step-by-step plans for treatment or care. However, clinical event data\npose several unique challenges, including the irregularity of time intervals\nbetween consecutive events, the existence of cycles, periodicity, multi-scale\nevent interactions, and the high computational costs associated with long event\nsequences. Existing neural temporal point processes (TPPs) methods do not\neffectively capture the multi-scale nature of event interactions, which is\ncommon in many real-world clinical applications. To address these issues, we\npropose the cross-temporal-scale transformer (XTSFormer), specifically designed\nfor irregularly timed event data. Our model consists of two vital components: a\nnovel Feature-based Cycle-aware Time Positional Encoding (FCPE) that adeptly\ncaptures the cyclical nature of time, and a hierarchical multi-scale temporal\nattention mechanism, where different temporal scales are determined by a\nbottom-up clustering approach. Extensive experiments on several real-world EHR\ndatasets show that our XTSFormer outperforms multiple baseline methods. The\ncode is available at https://github.com/spatialdatasciencegroup/XTSFormer.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2402.02258v2",
    "published_date": "2024-02-03 20:33:39 UTC",
    "updated_date": "2024-12-18 20:31:28 UTC"
  },
  {
    "arxiv_id": "2402.02246v1",
    "title": "ExTTNet: A Deep Learning Algorithm for Extracting Table Texts from Invoice Images",
    "authors": [
      "Adem Akdoğan",
      "Murat Kurt"
    ],
    "abstract": "In this work, product tables in invoices are obtained autonomously via a deep\nlearning model, which is named as ExTTNet. Firstly, text is obtained from\ninvoice images using Optical Character Recognition (OCR) techniques. Tesseract\nOCR engine [37] is used for this process. Afterwards, the number of existing\nfeatures is increased by using feature extraction methods to increase the\naccuracy. Labeling process is done according to whether each text obtained as a\nresult of OCR is a table element or not. In this study, a multilayer artificial\nneural network model is used. The training has been carried out with an Nvidia\nRTX 3090 graphics card and taken $162$ minutes. As a result of the training,\nthe F1 score is $0.92$.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.02246v1",
    "published_date": "2024-02-03 19:24:45 UTC",
    "updated_date": "2024-02-03 19:24:45 UTC"
  },
  {
    "arxiv_id": "2402.02230v1",
    "title": "Federated Learning with Differential Privacy",
    "authors": [
      "Adrien Banse",
      "Jan Kreischer",
      "Xavier Oliva i Jürgens"
    ],
    "abstract": "Federated learning (FL), as a type of distributed machine learning, is\ncapable of significantly preserving client's private data from being shared\namong different parties. Nevertheless, private information can still be\ndivulged by analyzing uploaded parameter weights from clients. In this report,\nwe showcase our empirical benchmark of the effect of the number of clients and\nthe addition of differential privacy (DP) mechanisms on the performance of the\nmodel on different types of data. Our results show that non-i.i.d and small\ndatasets have the highest decrease in performance in a distributed and\ndifferentially private setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "I.2.11"
    ],
    "primary_category": "cs.LG",
    "comment": "Machine Learning (ML) & Federated Learning (FL); 4 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02230v1",
    "published_date": "2024-02-03 18:21:38 UTC",
    "updated_date": "2024-02-03 18:21:38 UTC"
  },
  {
    "arxiv_id": "2402.15515v1",
    "title": "Feasibility of Identifying Factors Related to Alzheimer's Disease and Related Dementia in Real-World Data",
    "authors": [
      "Aokun Chen",
      "Qian Li",
      "Yu Huang",
      "Yongqiu Li",
      "Yu-neng Chuang",
      "Xia Hu",
      "Serena Guo",
      "Yonghui Wu",
      "Yi Guo",
      "Jiang Bian"
    ],
    "abstract": "A comprehensive view of factors associated with AD/ADRD will significantly\naid in studies to develop new treatments for AD/ADRD and identify high-risk\npopulations and patients for prevention efforts. In our study, we summarized\nthe risk factors for AD/ADRD by reviewing existing meta-analyses and review\narticles on risk and preventive factors for AD/ADRD. In total, we extracted 477\nrisk factors in 10 categories from 537 studies. We constructed an interactive\nknowledge map to disseminate our study results. Most of the risk factors are\naccessible from structured Electronic Health Records (EHRs), and clinical\nnarratives show promise as information sources. However, evaluating genomic\nrisk factors using RWD remains a challenge, as genetic testing for AD/ADRD is\nstill not a common practice and is poorly documented in both structured and\nunstructured EHRs. Considering the constantly evolving research on AD/ADRD risk\nfactors, literature mining via NLP methods offers a solution to automatically\nupdate our knowledge map.",
    "categories": [
      "cs.AI",
      "q-bio.QM",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.15515v1",
    "published_date": "2024-02-03 18:17:19 UTC",
    "updated_date": "2024-02-03 18:17:19 UTC"
  },
  {
    "arxiv_id": "2402.02218v1",
    "title": "Machine Intelligence in Africa: a survey",
    "authors": [
      "Allahsera Auguste Tapo",
      "Ali Traore",
      "Sidy Danioko",
      "Hamidou Tembine"
    ],
    "abstract": "In the last 5 years, the availability of large audio datasets in African\ncountries has opened unlimited opportunities to build machine intelligence (MI)\ntechnologies that are closer to the people and speak, learn, understand, and do\nbusinesses in local languages, including for those who cannot read and write.\nUnfortunately, these audio datasets are not fully exploited by current MI\ntools, leaving several Africans out of MI business opportunities. Additionally,\nmany state-of-the-art MI models are not culture-aware, and the ethics of their\nadoption indexes are questionable. The lack thereof is a major drawback in many\napplications in Africa. This paper summarizes recent developments in machine\nintelligence in Africa from a multi-layer multiscale and culture-aware ethics\nperspective, showcasing MI use cases in 54 African countries through 400\narticles on MI research, industry, government actions, as well as uses in art,\nmusic, the informal economy, and small businesses in Africa. The survey also\nopens discussions on the reliability of MI rankings and indexes in the African\ncontinent as well as algorithmic definitions of unclear terms used in MI.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted and to be presented at DSAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02218v1",
    "published_date": "2024-02-03 17:27:14 UTC",
    "updated_date": "2024-02-03 17:27:14 UTC"
  },
  {
    "arxiv_id": "2402.02186v1",
    "title": "Evolution Guided Generative Flow Networks",
    "authors": [
      "Zarif Ikram",
      "Ling Pan",
      "Dianbo Liu"
    ],
    "abstract": "Generative Flow Networks (GFlowNets) are a family of probabilistic generative\nmodels that learn to sample compositional objects proportional to their\nrewards. One big challenge of GFlowNets is training them effectively when\ndealing with long time horizons and sparse rewards. To address this, we propose\nEvolution guided generative flow networks (EGFN), a simple but powerful\naugmentation to the GFlowNets training using Evolutionary algorithms (EA). Our\nmethod can work on top of any GFlowNets training objective, by training a set\nof agent parameters using EA, storing the resulting trajectories in the\nprioritized replay buffer, and training the GFlowNets agent using the stored\ntrajectories. We present a thorough investigation over a wide range of toy and\nreal-world benchmark tasks showing the effectiveness of our method in handling\nlong trajectories and sparse rewards.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 16 figues",
    "pdf_url": "http://arxiv.org/pdf/2402.02186v1",
    "published_date": "2024-02-03 15:28:53 UTC",
    "updated_date": "2024-02-03 15:28:53 UTC"
  },
  {
    "arxiv_id": "2402.02181v1",
    "title": "An Ontology-Based multi-domain model in Social Network Analysis: Experimental validation and case study",
    "authors": [
      "José Alberto Benítez-Andrades",
      "Isaías García-Rodríguez",
      "Carmen Benavides",
      "Héctor Aláiz-Moretón",
      "José Emilio Labra Gayo"
    ],
    "abstract": "The use of social network theory and methods of analysis have been applied to\ndifferent domains in recent years, including public health. The complete\nprocedure for carrying out a social network analysis (SNA) is a time-consuming\ntask that entails a series of steps in which the expert in social network\nanalysis could make mistakes. This research presents a multi-domain knowledge\nmodel capable of automatically gathering data and carrying out different social\nnetwork analyses in different domains, without errors and obtaining the same\nconclusions that an expert in SNA would obtain. The model is represented in an\nontology called OntoSNAQA, which is made up of classes, properties and rules\nrepresenting the domains of People, Questionnaires and Social Network Analysis.\nBesides the ontology itself, different rules are represented by SWRL and SPARQL\nqueries. A Knowledge Based System was created using OntoSNAQA and applied to a\nreal case study in order to show the advantages of the approach. Finally, the\nresults of an SNA analysis obtained through the model were compared to those\nobtained from some of the most widely used SNA applications: UCINET, Pajek,\nCytoscape and Gephi, to test and confirm the validity of the model.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02181v1",
    "published_date": "2024-02-03 15:11:19 UTC",
    "updated_date": "2024-02-03 15:11:19 UTC"
  },
  {
    "arxiv_id": "2402.02168v2",
    "title": "Enhancing Cross-domain Link Prediction via Evolution Process Modeling",
    "authors": [
      "Xuanwen Huang",
      "Wei Chow",
      "Yize Zhu",
      "Yang Wang",
      "Ziwei Chai",
      "Chunping Wang",
      "Lei Chen",
      "Yang Yang"
    ],
    "abstract": "This work proposes DyExpert, a dynamic graph model for cross-domain link\nprediction. It can explicitly model historical evolving processes to learn the\nevolution pattern of a specific downstream graph and subsequently make\npattern-specific link predictions. DyExpert adopts a decode-only transformer\nand is capable of efficiently parallel training and inference by\n\\textit{conditioned link generation} that integrates both evolution modeling\nand link prediction. DyExpert is trained by extensive dynamic graphs across\ndiverse domains, comprising 6M dynamic edges. Extensive experiments on eight\nuntrained graphs demonstrate that DyExpert achieves state-of-the-art\nperformance in cross-domain link prediction. Compared to the advanced baseline\nunder the same setting, DyExpert achieves an average of 11.40% improvement\nAverage Precision across eight graphs. More impressive, it surpasses the fully\nsupervised performance of 8 advanced baselines on 6 untrained graphs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by WWW'25",
    "pdf_url": "http://arxiv.org/pdf/2402.02168v2",
    "published_date": "2024-02-03 14:29:01 UTC",
    "updated_date": "2025-02-05 06:28:11 UTC"
  },
  {
    "arxiv_id": "2402.02167v1",
    "title": "Vi(E)va LLM! A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations",
    "authors": [
      "Luca Podo",
      "Muhammad Ishmal",
      "Marco Angelini"
    ],
    "abstract": "The automatic generation of visualizations is an old task that, through the\nyears, has shown more and more interest from the research and practitioner\ncommunities. Recently, large language models (LLM) have become an interesting\noption for supporting generative tasks related to visualization, demonstrating\ninitial promising results. At the same time, several pitfalls, like the\nmultiple ways of instructing an LLM to generate the desired result, the\ndifferent perspectives leading the generation (code-based, image-based,\ngrammar-based), and the presence of hallucinations even for the visualization\ngeneration task, make their usage less affordable than expected. Following\nsimilar initiatives for benchmarking LLMs, this paper copes with the problem of\nmodeling the evaluation of a generated visualization through an LLM. We propose\na theoretical evaluation stack, EvaLLM, that decomposes the evaluation effort\nin its atomic components, characterizes their nature, and provides an overview\nof how to implement and interpret them. We also designed and implemented an\nevaluation platform that provides a benchmarking resource for the visualization\ngeneration task. The platform supports automatic and manual scoring conducted\nby multiple assessors to support a fine-grained and semantic evaluation based\non the EvaLLM stack. Two case studies on GPT3.5-turbo with Code Interpreter and\nLlama2-70-b models show the benefits of EvaLLM and illustrate interesting\nresults on the current state-of-the-art LLM-generated visualizations.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02167v1",
    "published_date": "2024-02-03 14:28:55 UTC",
    "updated_date": "2024-02-03 14:28:55 UTC"
  },
  {
    "arxiv_id": "2402.02164v4",
    "title": "Hierarchical Structure Enhances the Convergence and Generalizability of Linear Molecular Representation",
    "authors": [
      "Juan-Ni Wu",
      "Tong Wang",
      "Li-Juan Tang",
      "Hai-Long Wu",
      "Ru-Qin Yu"
    ],
    "abstract": "Language models demonstrate fundamental abilities in syntax, semantics, and\nreasoning, though their performance often depends significantly on the inputs\nthey process. This study introduces TSIS (Simplified TSID) and its\nvariants:TSISD (TSIS with Depth-First Search), TSISO (TSIS in Order), and TSISR\n(TSIS in Random), as integral components of the t-SMILES framework. These\nadditions complete the framework's design, providing diverse approaches to\nmolecular representation. Through comprehensive analysis and experiments\nemploying deep generative models, including GPT, diffusion models, and\nreinforcement learning, the findings reveal that the hierarchical structure of\nt-SMILES is more straightforward to parse than initially anticipated.\nFurthermore, t-SMILES consistently outperforms other linear representations\nsuch as SMILES, SELFIES, and SAFE, demonstrating superior convergence speed and\nenhanced generalization capabilities.",
    "categories": [
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.AI",
    "comment": "26pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02164v4",
    "published_date": "2024-02-03 14:24:21 UTC",
    "updated_date": "2024-11-18 16:01:29 UTC"
  },
  {
    "arxiv_id": "2402.02150v1",
    "title": "Data-Driven Prediction of Seismic Intensity Distributions Featuring Hybrid Classification-Regression Models",
    "authors": [
      "Koyu Mizutani",
      "Haruki Mitarai",
      "Kakeru Miyazaki",
      "Soichiro Kumano",
      "Toshihiko Yamasaki"
    ],
    "abstract": "Earthquakes are among the most immediate and deadly natural disasters that\nhumans face. Accurately forecasting the extent of earthquake damage and\nassessing potential risks can be instrumental in saving numerous lives. In this\nstudy, we developed linear regression models capable of predicting seismic\nintensity distributions based on earthquake parameters: location, depth, and\nmagnitude. Because it is completely data-driven, it can predict intensity\ndistributions without geographical information. The dataset comprises seismic\nintensity data from earthquakes that occurred in the vicinity of Japan between\n1997 and 2020, specifically containing 1,857 instances of earthquakes with a\nmagnitude of 5.0 or greater, sourced from the Japan Meteorological Agency. We\ntrained both regression and classification models and combined them to take\nadvantage of both to create a hybrid model. The proposed model outperformed\ncommonly used Ground Motion Prediction Equations (GMPEs) in terms of the\ncorrelation coefficient, F1 score, and MCC. Furthermore, the proposed model can\npredict even abnormal seismic intensity distributions, a task at conventional\nGMPEs often struggle.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02150v1",
    "published_date": "2024-02-03 13:39:22 UTC",
    "updated_date": "2024-02-03 13:39:22 UTC"
  },
  {
    "arxiv_id": "2402.02146v1",
    "title": "Emergency Computing: An Adaptive Collaborative Inference Method Based on Hierarchical Reinforcement Learning",
    "authors": [
      "Weiqi Fu",
      "Lianming Xu",
      "Xin Wu",
      "Li Wang",
      "Aiguo Fei"
    ],
    "abstract": "In achieving effective emergency response, the timely acquisition of\nenvironmental information, seamless command data transmission, and prompt\ndecision-making are crucial. This necessitates the establishment of a resilient\nemergency communication dedicated network, capable of providing communication\nand sensing services even in the absence of basic infrastructure. In this\npaper, we propose an Emergency Network with Sensing, Communication,\nComputation, Caching, and Intelligence (E-SC3I). The framework incorporates\nmechanisms for emergency computing, caching, integrated communication and\nsensing, and intelligence empowerment. E-SC3I ensures rapid access to a large\nuser base, reliable data transmission over unstable links, and dynamic network\ndeployment in a changing environment. However, these advantages come at the\ncost of significant computation overhead. Therefore, we specifically\nconcentrate on emergency computing and propose an adaptive collaborative\ninference method (ACIM) based on hierarchical reinforcement learning.\nExperimental results demonstrate our method's ability to achieve rapid\ninference of AI models with constrained computational and communication\nresources.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02146v1",
    "published_date": "2024-02-03 13:28:35 UTC",
    "updated_date": "2024-02-03 13:28:35 UTC"
  },
  {
    "arxiv_id": "2402.02135v1",
    "title": "Do Moral Judgment and Reasoning Capability of LLMs Change with Language? A Study using the Multilingual Defining Issues Test",
    "authors": [
      "Aditi Khandelwal",
      "Utkarsh Agarwal",
      "Kumar Tanmay",
      "Monojit Choudhury"
    ],
    "abstract": "This paper explores the moral judgment and moral reasoning abilities\nexhibited by Large Language Models (LLMs) across languages through the Defining\nIssues Test. It is a well known fact that moral judgment depends on the\nlanguage in which the question is asked. We extend the work of beyond English,\nto 5 new languages (Chinese, Hindi, Russian, Spanish and Swahili), and probe\nthree LLMs -- ChatGPT, GPT-4 and Llama2Chat-70B -- that shows substantial\nmultilingual text processing and generation abilities. Our study shows that the\nmoral reasoning ability for all models, as indicated by the post-conventional\nscore, is substantially inferior for Hindi and Swahili, compared to Spanish,\nRussian, Chinese and English, while there is no clear trend for the performance\nof the latter four languages. The moral judgments too vary considerably by the\nlanguage.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EACL 2024 (main)",
    "pdf_url": "http://arxiv.org/pdf/2402.02135v1",
    "published_date": "2024-02-03 12:52:36 UTC",
    "updated_date": "2024-02-03 12:52:36 UTC"
  },
  {
    "arxiv_id": "2402.02110v1",
    "title": "Composite Active Learning: Towards Multi-Domain Active Learning with Theoretical Guarantees",
    "authors": [
      "Guang-Yuan Hao",
      "Hengguan Huang",
      "Haotian Wang",
      "Jie Gao",
      "Hao Wang"
    ],
    "abstract": "Active learning (AL) aims to improve model performance within a fixed\nlabeling budget by choosing the most informative data points to label. Existing\nAL focuses on the single-domain setting, where all data come from the same\ndomain (e.g., the same dataset). However, many real-world tasks often involve\nmultiple domains. For example, in visual recognition, it is often desirable to\ntrain an image classifier that works across different environments (e.g.,\ndifferent backgrounds), where images from each environment constitute one\ndomain. Such a multi-domain AL setting is challenging for prior methods because\nthey (1) ignore the similarity among different domains when assigning labeling\nbudget and (2) fail to handle distribution shift of data across different\ndomains. In this paper, we propose the first general method, dubbed composite\nactive learning (CAL), for multi-domain AL. Our approach explicitly considers\nthe domain-level and instance-level information in the problem; CAL first\nassigns domain-level budgets according to domain-level importance, which is\nestimated by optimizing an upper error bound that we develop; with the\ndomain-level budgets, CAL then leverages a certain instance-level query\nstrategy to select samples to label from each domain. Our theoretical analysis\nshows that our method achieves a better error bound compared to current AL\nmethods. Our empirical results demonstrate that our approach significantly\noutperforms the state-of-the-art AL methods on both synthetic and real-world\nmulti-domain datasets. Code is available at\nhttps://github.com/Wang-ML-Lab/multi-domain-active-learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02110v1",
    "published_date": "2024-02-03 10:22:18 UTC",
    "updated_date": "2024-02-03 10:22:18 UTC"
  },
  {
    "arxiv_id": "2402.02101v1",
    "title": "Are Large Language Models Good Prompt Optimizers?",
    "authors": [
      "Ruotian Ma",
      "Xiaolei Wang",
      "Xin Zhou",
      "Jian Li",
      "Nan Du",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "abstract": "LLM-based Automatic Prompt Optimization, which typically utilizes LLMs as\nPrompt Optimizers to self-reflect and refine prompts, has shown promising\nperformance in recent studies. Despite the success, the underlying mechanism of\nthis approach remains unexplored, and the true effectiveness of LLMs as Prompt\nOptimizers requires further validation. In this work, we conducted a\ncomprehensive study to uncover the actual mechanism of LLM-based Prompt\nOptimization. Our findings reveal that the LLM optimizers struggle to identify\nthe true causes of errors during reflection, tending to be biased by their own\nprior knowledge rather than genuinely reflecting on the errors. Furthermore,\neven when the reflection is semantically valid, the LLM optimizers often fail\nto generate appropriate prompts for the target models with a single prompt\nrefinement step, partly due to the unpredictable behaviors of the target\nmodels. Based on the observations, we introduce a new \"Automatic Behavior\nOptimization\" paradigm, which directly optimizes the target model's behavior in\na more controllable manner. We hope our study can inspire new directions for\nautomatic prompt optimization development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02101v1",
    "published_date": "2024-02-03 09:48:54 UTC",
    "updated_date": "2024-02-03 09:48:54 UTC"
  },
  {
    "arxiv_id": "2402.02099v1",
    "title": "Analyzing the Evaluation of Cross-Lingual Knowledge Transfer in Multilingual Language Models",
    "authors": [
      "Sara Rajaee",
      "Christof Monz"
    ],
    "abstract": "Recent advances in training multilingual language models on large datasets\nseem to have shown promising results in knowledge transfer across languages and\nachieve high performance on downstream tasks. However, we question to what\nextent the current evaluation benchmarks and setups accurately measure\nzero-shot cross-lingual knowledge transfer. In this work, we challenge the\nassumption that high zero-shot performance on target tasks reflects high\ncross-lingual ability by introducing more challenging setups involving\ninstances with multiple languages. Through extensive experiments and analysis,\nwe show that the observed high performance of multilingual models can be\nlargely attributed to factors not requiring the transfer of actual linguistic\nknowledge, such as task- and surface-level knowledge. More specifically, we\nobserve what has been transferred across languages is mostly data artifacts and\nbiases, especially for low-resource languages. Our findings highlight the\noverlooked drawbacks of existing cross-lingual test data and evaluation setups,\ncalling for a more nuanced understanding of the cross-lingual capabilities of\nmultilingual models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02099v1",
    "published_date": "2024-02-03 09:41:52 UTC",
    "updated_date": "2024-02-03 09:41:52 UTC"
  },
  {
    "arxiv_id": "2402.02097v2",
    "title": "Settling Decentralized Multi-Agent Coordinated Exploration by Novelty Sharing",
    "authors": [
      "Haobin Jiang",
      "Ziluo Ding",
      "Zongqing Lu"
    ],
    "abstract": "Exploration in decentralized cooperative multi-agent reinforcement learning\nfaces two challenges. One is that the novelty of global states is unavailable,\nwhile the novelty of local observations is biased. The other is how agents can\nexplore in a coordinated way. To address these challenges, we propose MACE, a\nsimple yet effective multi-agent coordinated exploration method. By\ncommunicating only local novelty, agents can take into account other agents'\nlocal novelty to approximate the global novelty. Further, we newly introduce\nweighted mutual information to measure the influence of one agent's action on\nother agents' accumulated novelty. We convert it as an intrinsic reward in\nhindsight to encourage agents to exert more influence on other agents'\nexploration and boost coordinated exploration. Empirically, we show that MACE\nachieves superior performance in three multi-agent environments with sparse\nrewards.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "17 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02097v2",
    "published_date": "2024-02-03 09:35:25 UTC",
    "updated_date": "2024-08-10 06:45:19 UTC"
  },
  {
    "arxiv_id": "2402.02094v1",
    "title": "Deep Semantic-Visual Alignment for Zero-Shot Remote Sensing Image Scene Classification",
    "authors": [
      "Wenjia Xu",
      "Jiuniu Wang",
      "Zhiwei Wei",
      "Mugen Peng",
      "Yirong Wu"
    ],
    "abstract": "Deep neural networks have achieved promising progress in remote sensing (RS)\nimage classification, for which the training process requires abundant samples\nfor each class. However, it is time-consuming and unrealistic to annotate\nlabels for each RS category, given the fact that the RS target database is\nincreasing dynamically. Zero-shot learning (ZSL) allows for identifying novel\nclasses that are not seen during training, which provides a promising solution\nfor the aforementioned problem. However, previous ZSL models mainly depend on\nmanually-labeled attributes or word embeddings extracted from language models\nto transfer knowledge from seen classes to novel classes. Besides, pioneer ZSL\nmodels use convolutional neural networks pre-trained on ImageNet, which focus\non the main objects appearing in each image, neglecting the background context\nthat also matters in RS scene classification. To address the above problems, we\npropose to collect visually detectable attributes automatically. We predict\nattributes for each class by depicting the semantic-visual similarity between\nattributes and images. In this way, the attribute annotation process is\naccomplished by machine instead of human as in other methods. Moreover, we\npropose a Deep Semantic-Visual Alignment (DSVA) that take advantage of the\nself-attention mechanism in the transformer to associate local image regions\ntogether, integrating the background context information for prediction. The\nDSVA model further utilizes the attribute attention maps to focus on the\ninformative image regions that are essential for knowledge transfer in ZSL, and\nmaps the visual images into attribute space to perform ZSL classification. With\nextensive experiments, we show that our model outperforms other\nstate-of-the-art models by a large margin on a challenging large-scale RS scene\nclassification benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published in ISPRS P&RS. The code is available at\n  https://github.com/wenjiaXu/RS_Scene_ZSL",
    "pdf_url": "http://arxiv.org/pdf/2402.02094v1",
    "published_date": "2024-02-03 09:18:49 UTC",
    "updated_date": "2024-02-03 09:18:49 UTC"
  },
  {
    "arxiv_id": "2402.02085v8",
    "title": "Detecting AI-Generated Video via Frame Consistency",
    "authors": [
      "Long Ma",
      "Zhiyuan Yan",
      "Qinglang Guo",
      "Yong Liao",
      "Haiyang Yu",
      "Pengyuan Zhou"
    ],
    "abstract": "The escalating quality of video generated by advanced video generation\nmethods results in new security challenges, while there have been few relevant\nresearch efforts: 1) There is no open-source dataset for generated video\ndetection, 2) No generated video detection method has been proposed so far. To\nthis end, we propose an open-source dataset and a detection method for\ngenerated video for the first time. First, we propose a scalable dataset\nconsisting of 964 prompts, covering various forgery targets, scenes, behaviors,\nand actions, as well as various generation models with different architectures\nand generation methods, including the most popular commercial models like\nOpenAI's Sora and Google's Veo. Second, we found via probing experiments that\nspatial artifact-based detectors lack generalizability. Hence, we propose a\nsimple yet effective \\textbf{de}tection model based on \\textbf{f}rame\n\\textbf{co}nsistency (\\textbf{DeCoF}), which focuses on temporal artifacts by\neliminating the impact of spatial artifacts during feature learning. Extensive\nexperiments demonstrate the efficacy of DeCoF in detecting videos generated by\nunseen video generation models and confirm its powerful generalizability across\nseveral commercially proprietary models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02085v8",
    "published_date": "2024-02-03 08:52:06 UTC",
    "updated_date": "2025-04-20 11:47:02 UTC"
  },
  {
    "arxiv_id": "2402.02079v1",
    "title": "Prototypical Contrastive Learning through Alignment and Uniformity for Recommendation",
    "authors": [
      "Yangxun Ou",
      "Lei Chen",
      "Fenglin Pan",
      "Yupeng Wu"
    ],
    "abstract": "Graph Collaborative Filtering (GCF), one of the most widely adopted\nrecommendation system methods, effectively captures intricate relationships\nbetween user and item interactions. Graph Contrastive Learning (GCL) based GCF\nhas gained significant attention as it leverages self-supervised techniques to\nextract valuable signals from real-world scenarios. However, many methods\nusually learn the instances of discrimination tasks that involve the\nconstruction of contrastive pairs through random sampling. GCL approaches\nsuffer from sampling bias issues, where the negatives might have a semantic\nstructure similar to that of the positives, thus leading to a loss of effective\nfeature representation. To address these problems, we present the\n\\underline{Proto}typical contrastive learning through \\underline{A}lignment and\n\\underline{U}niformity for recommendation, which is called \\textbf{ProtoAU}.\nSpecifically, we first propose prototypes (cluster centroids) as a latent space\nto ensure consistency across different augmentations from the origin graph,\naiming to eliminate the need for random sampling of contrastive pairs.\nFurthermore, the absence of explicit negatives means that directly optimizing\nthe consistency loss between instance and prototype could easily result in\ndimensional collapse issues. Therefore, we propose aligning and maintaining\nuniformity in the prototypes of users and items as optimization objectives to\nprevent falling into trivial solutions. Finally, we conduct extensive\nexperiments on four datasets and evaluate their performance on the task of link\nprediction. Experimental results demonstrate that the proposed ProtoAU\noutperforms other representative methods. The source codes of our proposed\nProtoAU are available at \\url{https://github.com/oceanlvr/ProtoAU}.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02079v1",
    "published_date": "2024-02-03 08:19:26 UTC",
    "updated_date": "2024-02-03 08:19:26 UTC"
  },
  {
    "arxiv_id": "2402.03375v3",
    "title": "BetterV: Controlled Verilog Generation with Discriminative Guidance",
    "authors": [
      "Zehua Pei",
      "Hui-Ling Zhen",
      "Mingxuan Yuan",
      "Yu Huang",
      "Bei Yu"
    ],
    "abstract": "Due to the growing complexity of modern Integrated Circuits (ICs), there is a\nneed for automated circuit design methods. Recent years have seen rising\nresearch in hardware design language generation to facilitate the design\nprocess. In this work, we propose a Verilog generation framework, BetterV,\nwhich fine-tunes the large language models (LLMs) on processed domain-specific\ndatasets and incorporates generative discriminators for guidance on particular\ndesign demands. The Verilog modules are collected, filtered and processed from\ninternet to form a clean and abundant dataset. Instruct-tuning methods are\nspecially designed to fine-tune the LLMs to understand the knowledge about\nVerilog. Furthermore, data are augmented to enrich the training set and also\nused to train a generative discriminator on particular downstream task, which\nleads a guidance for the LLMs to optimize the Verilog implementation. BetterV\nhas the ability to generate syntactically and functionally correct Verilog,\nwhich can outperform GPT-4 on the VerilogEval benchmark. With the help of\ntask-specific generative discriminator, BetterV can achieve remarkable\nimprovement on various electronic design automation (EDA) downstream tasks,\nincluding the netlist node reduction for synthesis and verification runtime\nreduction with Boolean Satisfiability (SAT) solving.",
    "categories": [
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.03375v3",
    "published_date": "2024-02-03 08:00:12 UTC",
    "updated_date": "2024-05-02 09:18:21 UTC"
  },
  {
    "arxiv_id": "2402.02066v1",
    "title": "Trustworthiness of $\\mathbb{X}$ Users: A One-Class Classification Approach",
    "authors": [
      "Tanveer Khan",
      "Fahad Sohrab",
      "Antonis Michalas",
      "Moncef Gabbouj"
    ],
    "abstract": "$\\mathbb{X}$ (formerly Twitter) is a prominent online social media platform\nthat plays an important role in sharing information making the content\ngenerated on this platform a valuable source of information. Ensuring trust on\n$\\mathbb{X}$ is essential to determine the user credibility and prevents issues\nacross various domains. While assigning credibility to $\\mathbb{X}$ users and\nclassifying them as trusted or untrusted is commonly carried out using\ntraditional machine learning models, there is limited exploration about the use\nof One-Class Classification (OCC) models for this purpose. In this study, we\nuse various OCC models for $\\mathbb{X}$ user classification. Additionally, we\npropose using a subspace-learning-based approach that simultaneously optimizes\nboth the subspace and data description for OCC. We also introduce a novel\nregularization term for Subspace Support Vector Data Description (SSVDD),\nexpressing data concentration in a lower-dimensional subspace that captures\ndiverse graph structures. Experimental results show superior performance of the\nintroduced regularization term for SSVDD compared to baseline models and\nstate-of-the-art techniques for $\\mathbb{X}$ user classification.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02066v1",
    "published_date": "2024-02-03 07:14:33 UTC",
    "updated_date": "2024-02-03 07:14:33 UTC"
  },
  {
    "arxiv_id": "2402.02056v1",
    "title": "AnthroScore: A Computational Linguistic Measure of Anthropomorphism",
    "authors": [
      "Myra Cheng",
      "Kristina Gligoric",
      "Tiziano Piccardi",
      "Dan Jurafsky"
    ],
    "abstract": "Anthropomorphism, or the attribution of human-like characteristics to\nnon-human entities, has shaped conversations about the impacts and\npossibilities of technology. We present AnthroScore, an automatic metric of\nimplicit anthropomorphism in language. We use a masked language model to\nquantify how non-human entities are implicitly framed as human by the\nsurrounding context. We show that AnthroScore corresponds with human judgments\nof anthropomorphism and dimensions of anthropomorphism described in social\nscience literature. Motivated by concerns of misleading anthropomorphism in\ncomputer science discourse, we use AnthroScore to analyze 15 years of research\npapers and downstream news articles. In research papers, we find that\nanthropomorphism has steadily increased over time, and that papers related to\nlanguage models have the most anthropomorphism. Within ACL papers, temporal\nincreases in anthropomorphism are correlated with key neural advancements.\nBuilding upon concerns of scientific misinformation in mass media, we identify\nhigher levels of anthropomorphism in news headlines compared to the research\npapers they cite. Since AnthroScore is lexicon-free, it can be directly applied\nto a wide range of text sources.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "EACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2402.02056v1",
    "published_date": "2024-02-03 06:36:11 UTC",
    "updated_date": "2024-02-03 06:36:11 UTC"
  },
  {
    "arxiv_id": "2402.02055v1",
    "title": "Variance Alignment Score: A Simple But Tough-to-Beat Data Selection Method for Multimodal Contrastive Learning",
    "authors": [
      "Yiping Wang",
      "Yifang Chen",
      "Wendan Yan",
      "Kevin Jamieson",
      "Simon Shaolei Du"
    ],
    "abstract": "In recent years, data selection has emerged as a core issue for large-scale\nvisual-language model pretraining, especially on noisy web-curated datasets.\nOne widely adopted strategy assigns quality scores such as CLIP similarity for\neach sample and retains the data pairs with the highest scores. However, these\napproaches are agnostic of data distribution and always fail to select the most\ninformative samples. To solve this problem, we propose a simple yet\ntheoretically principled metric named Variance Alignment Score (VAS), which has\nthe form $\\langle \\Sigma_{\\text{test}}, \\Sigma_i\\rangle$. Here,\n$\\Sigma_{\\text{test}}$ represents the target (cross-)covariance matrix we aim\nto align, potentially based on prior knowledge, while $\\Sigma_i$ denotes the\ntensor product of single or multi-modal representations for the $i$-th sample.\nWe further design a new data selection method that maximizes the total VAS. We\nprovide theoretical analysis in a simplified setting to demonstrate the\ntheoretical advantage of VAS over random or other existing data selection.\nExperimentally, applying VAS and CLIP scores together can outperform baselines\nby a margin of $1.3\\%$ average on 38 evaluation sets for noisy dataset DataComp\nand $2.5\\%$ on VTAB for high-quality dataset CC12M. Additionally, our ablation\nstudy also shows visual features are better than text for calculating VAS, and\nthe related classical experimental design methods may fail under this context.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02055v1",
    "published_date": "2024-02-03 06:29:04 UTC",
    "updated_date": "2024-02-03 06:29:04 UTC"
  },
  {
    "arxiv_id": "2402.05946v2",
    "title": "Unveiling Latent Causal Rules: A Temporal Point Process Approach for Abnormal Event Explanation",
    "authors": [
      "Yiling Kuang",
      "Chao Yang",
      "Yang Yang",
      "Shuang Li"
    ],
    "abstract": "In high-stakes systems such as healthcare, it is critical to understand the\ncausal reasons behind unusual events, such as sudden changes in patient's\nhealth. Unveiling the causal reasons helps with quick diagnoses and precise\ntreatment planning. In this paper, we propose an automated method for\nuncovering \"if-then\" logic rules to explain observational events. We introduce\ntemporal point processes to model the events of interest, and discover the set\nof latent rules to explain the occurrence of events. To achieve this, we employ\nan Expectation-Maximization (EM) algorithm. In the E-step, we calculate the\nlikelihood of each event being explained by each discovered rule. In the\nM-step, we update both the rule set and model parameters to enhance the\nlikelihood function's lower bound. Notably, we optimize the rule set in a\ndifferential manner. Our approach demonstrates accurate performance in both\ndiscovering rules and identifying root causes. We showcase its promising\nresults using synthetic and real healthcare datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AISTATS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05946v2",
    "published_date": "2024-02-03 06:21:33 UTC",
    "updated_date": "2024-03-19 08:43:29 UTC"
  },
  {
    "arxiv_id": "2402.02054v3",
    "title": "Towards Neural Scaling Laws on Graphs",
    "authors": [
      "Jingzhe Liu",
      "Haitao Mao",
      "Zhikai Chen",
      "Tong Zhao",
      "Neil Shah",
      "Jiliang Tang"
    ],
    "abstract": "Deep graph models (e.g., graph neural networks and graph transformers) have\nbecome important techniques for leveraging knowledge across various types of\ngraphs. Yet, the neural scaling laws on graphs, i.e., how the performance of\ndeep graph models changes with model and dataset sizes, have not been\nsystematically investigated, casting doubts on the feasibility of achieving\nlarge graph models. To fill this gap, we benchmark many graph datasets from\ndifferent tasks and make an attempt to establish the neural scaling laws on\ngraphs from both model and data perspectives. The model size we investigated is\nup to 100 million parameters, and the dataset size investigated is up to 50\nmillion samples. We first verify the validity of such laws on graphs,\nestablishing proper formulations to describe the scaling behaviors. For model\nscaling, we identify that despite the parameter numbers, the model depth also\nplays an important role in affecting the model scaling behaviors, which differs\nfrom observations in other domains such as CV and NLP. For data scaling, we\nsuggest that the number of graphs can not effectively measure the graph data\nvolume in scaling law since the sizes of different graphs are highly irregular.\nInstead, we reform the data scaling law with the number of nodes or edges as\nthe metric to address the irregular graph sizes. We further demonstrate that\nthe reformed law offers a unified view of the data scaling behaviors for\nvarious fundamental graph tasks including node classification, link prediction,\nand graph classification. This work provides valuable insights into neural\nscaling laws on graphs, which can serve as an important tool for collecting new\ngraph data and developing large graph models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02054v3",
    "published_date": "2024-02-03 06:17:21 UTC",
    "updated_date": "2024-11-30 01:55:11 UTC"
  },
  {
    "arxiv_id": "2402.02053v2",
    "title": "Affordable Generative Agents",
    "authors": [
      "Yangbin Yu",
      "Qin Zhang",
      "Junyou Li",
      "Qiang Fu",
      "Deheng Ye"
    ],
    "abstract": "The emergence of large language models (LLMs) has significantly advanced the\nsimulation of believable interactive agents. However, the substantial cost on\nmaintaining the prolonged agent interactions poses challenge over the\ndeployment of believable LLM-based agents. Therefore, in this paper, we develop\nAffordable Generative Agents (AGA), a framework for enabling the generation of\nbelievable and low-cost interactions on both agent-environment and inter-agents\nlevels. Specifically, for agent-environment interactions, we substitute\nrepetitive LLM inferences with learned policies; while for inter-agent\ninteractions, we model the social relationships between agents and compress\nauxiliary dialogue information. Extensive experiments on multiple environments\nshow the effectiveness and efficiency of our proposed framework. Also, we delve\ninto the mechanisms of emergent believable behaviors lying in LLM agents,\ndemonstrating that agents can only generate finite behaviors in fixed\nenvironments, based upon which, we understand ways to facilitate emergent\ninteraction behaviors. Our code is publicly available at:\nhttps://github.com/AffordableGenerativeAgents/Affordable-Generative-Agents.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02053v2",
    "published_date": "2024-02-03 06:16:28 UTC",
    "updated_date": "2024-08-28 04:04:45 UTC"
  },
  {
    "arxiv_id": "2402.05120v2",
    "title": "More Agents Is All You Need",
    "authors": [
      "Junyou Li",
      "Qin Zhang",
      "Yangbin Yu",
      "Qiang Fu",
      "Deheng Ye"
    ],
    "abstract": "We find that, simply via a sampling-and-voting method, the performance of\nlarge language models (LLMs) scales with the number of agents instantiated.\nAlso, this method, termed as Agent Forest, is orthogonal to existing\ncomplicated methods to further enhance LLMs, while the degree of enhancement is\ncorrelated to the task difficulty. We conduct comprehensive experiments on a\nwide range of LLM benchmarks to verify the presence of our finding, and to\nstudy the properties that can facilitate its occurrence. Our code is publicly\navailable at: https://github.com/MoreAgentsIsAllYouNeed/AgentForest",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published at Transactions on Machine Learning Research (TMLR)",
    "pdf_url": "http://arxiv.org/pdf/2402.05120v2",
    "published_date": "2024-02-03 05:55:24 UTC",
    "updated_date": "2024-10-11 09:38:40 UTC"
  },
  {
    "arxiv_id": "2402.02043v1",
    "title": "A Plug-in Tiny AI Module for Intelligent and Selective Sensor Data Transmission",
    "authors": [
      "Wenjun Huang",
      "Arghavan Rezvani",
      "Hanning Chen",
      "Yang Ni",
      "Sanggeon Yun",
      "Sungheon Jeong",
      "Mohsen Imani"
    ],
    "abstract": "Applications in the Internet of Things (IoT) utilize machine learning to\nanalyze sensor-generated data. However, a major challenge lies in the lack of\ntargeted intelligence in current sensing systems, leading to vast data\ngeneration and increased computational and communication costs. To address this\nchallenge, we propose a novel sensing module to equip sensing frameworks with\nintelligent data transmission capabilities by integrating a highly efficient\nmachine learning model placed near the sensor. This model provides prompt\nfeedback for the sensing system to transmit only valuable data while discarding\nirrelevant information by regulating the frequency of data transmission. The\nnear-sensor model is quantized and optimized for real-time sensor control. To\nenhance the framework's performance, the training process is customized and a\n\"lazy\" sensor deactivation strategy utilizing temporal information is\nintroduced. The suggested method is orthogonal to other IoT frameworks and can\nbe considered as a plugin for selective data transmission. The framework is\nimplemented, encompassing both software and hardware components. The\nexperiments demonstrate that the framework utilizing the suggested module\nachieves over 85% system efficiency in terms of energy consumption and storage,\nwith negligible impact on performance. This methodology has the potential to\nsignificantly reduce data output from sensors, benefiting a wide range of IoT\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02043v1",
    "published_date": "2024-02-03 05:41:39 UTC",
    "updated_date": "2024-02-03 05:41:39 UTC"
  },
  {
    "arxiv_id": "2402.02042v3",
    "title": "Learning General Parameterized Policies for Infinite Horizon Average Reward Constrained MDPs via Primal-Dual Policy Gradient Algorithm",
    "authors": [
      "Qinbo Bai",
      "Washim Uddin Mondal",
      "Vaneet Aggarwal"
    ],
    "abstract": "This paper explores the realm of infinite horizon average reward Constrained\nMarkov Decision Processes (CMDPs). To the best of our knowledge, this work is\nthe first to delve into the regret and constraint violation analysis of average\nreward CMDPs with a general policy parametrization. To address this challenge,\nwe propose a primal dual-based policy gradient algorithm that adeptly manages\nthe constraints while ensuring a low regret guarantee toward achieving a global\noptimal policy. In particular, our proposed algorithm achieves\n$\\tilde{\\mathcal{O}}({T}^{4/5})$ objective regret and\n$\\tilde{\\mathcal{O}}({T}^{4/5})$ constraint violation bounds.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02042v3",
    "published_date": "2024-02-03 05:35:58 UTC",
    "updated_date": "2024-10-30 05:42:06 UTC"
  },
  {
    "arxiv_id": "2402.02033v1",
    "title": "Benchmark for CEC 2024 Competition on Multiparty Multiobjective Optimization",
    "authors": [
      "Wenjian Luo",
      "Peilan Xu",
      "Shengxiang Yang",
      "Yuhui Shi"
    ],
    "abstract": "The competition focuses on Multiparty Multiobjective Optimization Problems\n(MPMOPs), where multiple decision makers have conflicting objectives, as seen\nin applications like UAV path planning. Despite their importance, MPMOPs remain\nunderstudied in comparison to conventional multiobjective optimization. The\ncompetition aims to address this gap by encouraging researchers to explore\ntailored modeling approaches. The test suite comprises two parts: problems with\ncommon Pareto optimal solutions and Biparty Multiobjective UAV Path Planning\n(BPMO-UAVPP) problems with unknown solutions. Optimization algorithms for the\nfirst part are evaluated using Multiparty Inverted Generational Distance\n(MPIGD), and the second part is evaluated using Multiparty Hypervolume (MPHV)\nmetrics. The average algorithm ranking across all problems serves as a\nperformance benchmark.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 0 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.02033v1",
    "published_date": "2024-02-03 05:14:03 UTC",
    "updated_date": "2024-02-03 05:14:03 UTC"
  },
  {
    "arxiv_id": "2402.02029v1",
    "title": "ScribFormer: Transformer Makes CNN Work Better for Scribble-based Medical Image Segmentation",
    "authors": [
      "Zihan Li",
      "Yuan Zheng",
      "Dandan Shan",
      "Shuzhou Yang",
      "Qingde Li",
      "Beizhan Wang",
      "Yuanting Zhang",
      "Qingqi Hong",
      "Dinggang Shen"
    ],
    "abstract": "Most recent scribble-supervised segmentation methods commonly adopt a CNN\nframework with an encoder-decoder architecture. Despite its multiple benefits,\nthis framework generally can only capture small-range feature dependency for\nthe convolutional layer with the local receptive field, which makes it\ndifficult to learn global shape information from the limited information\nprovided by scribble annotations. To address this issue, this paper proposes a\nnew CNN-Transformer hybrid solution for scribble-supervised medical image\nsegmentation called ScribFormer. The proposed ScribFormer model has a\ntriple-branch structure, i.e., the hybrid of a CNN branch, a Transformer\nbranch, and an attention-guided class activation map (ACAM) branch.\nSpecifically, the CNN branch collaborates with the Transformer branch to fuse\nthe local features learned from CNN with the global representations obtained\nfrom Transformer, which can effectively overcome limitations of existing\nscribble-supervised segmentation methods. Furthermore, the ACAM branch assists\nin unifying the shallow convolution features and the deep convolution features\nto improve model's performance further. Extensive experiments on two public\ndatasets and one private dataset show that our ScribFormer has superior\nperformance over the state-of-the-art scribble-supervised segmentation methods,\nand achieves even better results than the fully-supervised segmentation\nmethods. The code is released at https://github.com/HUANGLIZI/ScribFormer.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IEEE Transactions on Medical Imaging (TMI)",
    "pdf_url": "http://arxiv.org/pdf/2402.02029v1",
    "published_date": "2024-02-03 04:55:22 UTC",
    "updated_date": "2024-02-03 04:55:22 UTC"
  },
  {
    "arxiv_id": "2402.02026v2",
    "title": "Multimodal-Enhanced Objectness Learner for Corner Case Detection in Autonomous Driving",
    "authors": [
      "Lixing Xiao",
      "Ruixiao Shi",
      "Xiaoyang Tang",
      "Yi Zhou"
    ],
    "abstract": "Previous works on object detection have achieved high accuracy in closed-set\nscenarios, but their performance in open-world scenarios is not satisfactory.\nOne of the challenging open-world problems is corner case detection in\nautonomous driving. Existing detectors struggle with these cases, relying\nheavily on visual appearance and exhibiting poor generalization ability. In\nthis paper, we propose a solution by reducing the discrepancy between known and\nunknown classes and introduce a multimodal-enhanced objectness notion learner.\nLeveraging both vision-centric and image-text modalities, our semi-supervised\nlearning framework imparts objectness knowledge to the student model, enabling\nclass-aware detection. Our approach, Multimodal-Enhanced Objectness Learner\n(MENOL) for Corner Case Detection, significantly improves recall for novel\nclasses with lower training costs. By achieving a 76.6% mAR-corner and 79.8%\nmAR-agnostic on the CODA-val dataset with just 5100 labeled training images,\nMENOL outperforms the baseline ORE by 71.3% and 60.6%, respectively. The code\nwill be available at https://github.com/tryhiseyyysum/MENOL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to 2024 IEEE International Conference on Image Processing\n  (ICIP) as oral presentation",
    "pdf_url": "http://arxiv.org/pdf/2402.02026v2",
    "published_date": "2024-02-03 04:47:03 UTC",
    "updated_date": "2024-09-28 08:40:14 UTC"
  },
  {
    "arxiv_id": "2402.05119v5",
    "title": "A Closer Look at the Limitations of Instruction Tuning",
    "authors": [
      "Sreyan Ghosh",
      "Chandra Kiran Reddy Evuru",
      "Sonal Kumar",
      "Ramaneswaran S",
      "Deepali Aneja",
      "Zeyu Jin",
      "Ramani Duraiswami",
      "Dinesh Manocha"
    ],
    "abstract": "Instruction Tuning (IT), the process of training large language models (LLMs)\nusing instruction-response pairs, has emerged as the predominant method for\ntransforming base pre-trained LLMs into open-domain conversational agents.\nWhile IT has achieved notable success and widespread adoption, its limitations\nand shortcomings remain underexplored. In this paper, through rigorous\nexperiments and an in-depth analysis of the changes LLMs undergo through IT, we\nreveal various limitations of IT. In particular, we show that (1) IT fails to\nenhance knowledge or skills in LLMs. LoRA fine-tuning is limited to learning\nresponse initiation and style tokens, and full-parameter fine-tuning leads to\nknowledge degradation. (2) Copying response patterns from IT datasets derived\nfrom knowledgeable sources leads to a decline in response quality. (3)\nFull-parameter fine-tuning increases hallucination by inaccurately borrowing\ntokens from conceptually similar instances in the IT dataset for generating\nresponses. (4) Popular methods to improve IT do not lead to performance\nimprovements over a simple LoRA fine-tuned model. Our findings reveal that\nresponses generated solely from pre-trained knowledge consistently outperform\nresponses by models that learn any form of new knowledge from IT on open-source\ndatasets. We hope the insights and challenges revealed in this paper inspire\nfuture work in related directions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05119v5",
    "published_date": "2024-02-03 04:45:25 UTC",
    "updated_date": "2024-07-14 18:14:57 UTC"
  },
  {
    "arxiv_id": "2402.02025v2",
    "title": "A Survey of Constraint Formulations in Safe Reinforcement Learning",
    "authors": [
      "Akifumi Wachi",
      "Xun Shen",
      "Yanan Sui"
    ],
    "abstract": "Safety is critical when applying reinforcement learning (RL) to real-world\nproblems. As a result, safe RL has emerged as a fundamental and powerful\nparadigm for optimizing an agent's policy while incorporating notions of\nsafety. A prevalent safe RL approach is based on a constrained criterion, which\nseeks to maximize the expected cumulative reward subject to specific safety\nconstraints. Despite recent effort to enhance safety in RL, a systematic\nunderstanding of the field remains difficult. This challenge stems from the\ndiversity of constraint representations and little exploration of their\ninterrelations. To bridge this knowledge gap, we present a comprehensive review\nof representative constraint formulations, along with a curated selection of\nalgorithms designed specifically for each formulation. In addition, we\nelucidate the theoretical underpinnings that reveal the mathematical mutual\nrelations among common problem formulations. We conclude with a discussion of\nthe current state and future directions of safe reinforcement learning\nresearch.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IJCAI-24 survey track",
    "pdf_url": "http://arxiv.org/pdf/2402.02025v2",
    "published_date": "2024-02-03 04:40:31 UTC",
    "updated_date": "2024-05-08 00:59:16 UTC"
  },
  {
    "arxiv_id": "2402.02023v2",
    "title": "Self-Supervised Contrastive Learning for Long-term Forecasting",
    "authors": [
      "Junwoo Park",
      "Daehoon Gwak",
      "Jaegul Choo",
      "Edward Choi"
    ],
    "abstract": "Long-term forecasting presents unique challenges due to the time and memory\ncomplexity of handling long sequences. Existing methods, which rely on sliding\nwindows to process long sequences, struggle to effectively capture long-term\nvariations that are partially caught within the short window (i.e.,\nouter-window variations). In this paper, we introduce a novel approach that\novercomes this limitation by employing contrastive learning and enhanced\ndecomposition architecture, specifically designed to focus on long-term\nvariations. To this end, our contrastive loss incorporates global\nautocorrelation held in the whole time series, which facilitates the\nconstruction of positive and negative pairs in a self-supervised manner. When\ncombined with our decomposition networks, our contrastive learning\nsignificantly improves long-term forecasting performance. Extensive experiments\ndemonstrate that our approach outperforms 14 baseline models in multiple\nexperiments over nine long-term benchmarks, especially in challenging scenarios\nthat require a significantly long output for forecasting. Source code is\navailable at\nhttps://github.com/junwoopark92/Self-Supervised-Contrastive-Forecsating.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at International Conference on Learning Representations\n  (ICLR) 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.02023v2",
    "published_date": "2024-02-03 04:32:34 UTC",
    "updated_date": "2024-03-24 04:01:18 UTC"
  },
  {
    "arxiv_id": "2402.05945v1",
    "title": "Eliminating Information Leakage in Hard Concept Bottleneck Models with Supervised, Hierarchical Concept Learning",
    "authors": [
      "Ao Sun",
      "Yuanyuan Yuan",
      "Pingchuan Ma",
      "Shuai Wang"
    ],
    "abstract": "Concept Bottleneck Models (CBMs) aim to deliver interpretable and\ninterventionable predictions by bridging features and labels with\nhuman-understandable concepts. While recent CBMs show promising potential, they\nsuffer from information leakage, where unintended information beyond the\nconcepts (either when concepts are represented with probabilities or binary\nstates) are leaked to the subsequent label prediction. Consequently, distinct\nclasses are falsely classified via indistinguishable concepts, undermining the\ninterpretation and intervention of CBMs.\n  This paper alleviates the information leakage issue by introducing label\nsupervision in concept predication and constructing a hierarchical concept set.\nAccordingly, we propose a new paradigm of CBMs, namely SupCBM, which achieves\nlabel predication via predicted concepts and a deliberately-designed\nintervention matrix. SupCBM focuses on concepts that are mostly relevant to the\npredicted label and only distinguishes classes when different concepts are\npresented. Our evaluations show that SupCBM outperforms SOTA CBMs over diverse\ndatasets. It also manifests better generality across different backbone models.\nWith proper quantification of information leakage in different CBMs, we\ndemonstrate that SupCBM significantly reduces the information leakage.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05945v1",
    "published_date": "2024-02-03 03:50:58 UTC",
    "updated_date": "2024-02-03 03:50:58 UTC"
  },
  {
    "arxiv_id": "2402.02008v1",
    "title": "How well do LLMs cite relevant medical references? An evaluation framework and analyses",
    "authors": [
      "Kevin Wu",
      "Eric Wu",
      "Ally Cassasola",
      "Angela Zhang",
      "Kevin Wei",
      "Teresa Nguyen",
      "Sith Riantawan",
      "Patricia Shi Riantawan",
      "Daniel E. Ho",
      "James Zou"
    ],
    "abstract": "Large language models (LLMs) are currently being used to answer medical\nquestions across a variety of clinical domains. Recent top-performing\ncommercial LLMs, in particular, are also capable of citing sources to support\ntheir responses. In this paper, we ask: do the sources that LLMs generate\nactually support the claims that they make? To answer this, we propose three\ncontributions. First, as expert medical annotations are an expensive and\ntime-consuming bottleneck for scalable evaluation, we demonstrate that GPT-4 is\nhighly accurate in validating source relevance, agreeing 88% of the time with a\npanel of medical doctors. Second, we develop an end-to-end, automated pipeline\ncalled \\textit{SourceCheckup} and use it to evaluate five top-performing LLMs\non a dataset of 1200 generated questions, totaling over 40K pairs of statements\nand sources. Interestingly, we find that between ~50% to 90% of LLM responses\nare not fully supported by the sources they provide. We also evaluate GPT-4\nwith retrieval augmented generation (RAG) and find that, even still, around\n30\\% of individual statements are unsupported, while nearly half of its\nresponses are not fully supported. Third, we open-source our curated dataset of\nmedical questions and expert annotations for future evaluations. Given the\nrapid pace of LLM development and the potential harms of incorrect or outdated\nmedical information, it is crucial to also understand and quantify their\ncapability to produce relevant, trustworthy medical references.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.02008v1",
    "published_date": "2024-02-03 03:44:57 UTC",
    "updated_date": "2024-02-03 03:44:57 UTC"
  },
  {
    "arxiv_id": "2402.01999v1",
    "title": "A Novel Hyperdimensional Computing Framework for Online Time Series Forecasting on the Edge",
    "authors": [
      "Mohamed Mejri",
      "Chandramouli Amarnath",
      "Abhijit Chatterjee"
    ],
    "abstract": "In recent years, both online and offline deep learning models have been\ndeveloped for time series forecasting. However, offline deep forecasting models\nfail to adapt effectively to changes in time-series data, while online deep\nforecasting models are often expensive and have complex training procedures. In\nthis paper, we reframe the online nonlinear time-series forecasting problem as\none of linear hyperdimensional time-series forecasting. Nonlinear\nlow-dimensional time-series data is mapped to high-dimensional\n(hyperdimensional) spaces for linear hyperdimensional prediction, allowing\nfast, efficient and lightweight online time-series forecasting. Our framework,\nTSF-HD, adapts to time-series distribution shifts using a novel co-training\nframework for its hyperdimensional mapping and its linear hyperdimensional\npredictor. TSF-HD is shown to outperform the state of the art, while having\nreduced inference latency, for both short-term and long-term time series\nforecasting. Our code is publicly available at\nhttp://github.com/tsfhd2024/tsf-hd.git",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01999v1",
    "published_date": "2024-02-03 02:42:53 UTC",
    "updated_date": "2024-02-03 02:42:53 UTC"
  },
  {
    "arxiv_id": "2402.01994v1",
    "title": "Human-Centered Privacy Research in the Age of Large Language Models",
    "authors": [
      "Tianshi Li",
      "Sauvik Das",
      "Hao-Ping Lee",
      "Dakuo Wang",
      "Bingsheng Yao",
      "Zhiping Zhang"
    ],
    "abstract": "The emergence of large language models (LLMs), and their increased use in\nuser-facing systems, has led to substantial privacy concerns. To date, research\non these privacy concerns has been model-centered: exploring how LLMs lead to\nprivacy risks like memorization, or can be used to infer personal\ncharacteristics about people from their content. We argue that there is a need\nfor more research focusing on the human aspect of these privacy issues: e.g.,\nresearch on how design paradigms for LLMs affect users' disclosure behaviors,\nusers' mental models and preferences for privacy controls, and the design of\ntools, systems, and artifacts that empower end-users to reclaim ownership over\ntheir personal data. To build usable, efficient, and privacy-friendly systems\npowered by these models with imperfect privacy properties, our goal is to\ninitiate discussions to outline an agenda for conducting human-centered\nresearch on privacy issues in LLM-powered systems. This Special Interest Group\n(SIG) aims to bring together researchers with backgrounds in usable security\nand privacy, human-AI collaboration, NLP, or any other related domains to share\ntheir perspectives and experiences on this problem, to help our community\nestablish a collective understanding of the challenges, research opportunities,\nresearch methods, and strategies to collaborate with researchers outside of\nHCI.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.HC",
    "comment": "4 pages, CHI EA'24",
    "pdf_url": "http://arxiv.org/pdf/2402.01994v1",
    "published_date": "2024-02-03 02:32:45 UTC",
    "updated_date": "2024-02-03 02:32:45 UTC"
  },
  {
    "arxiv_id": "2403.05541v1",
    "title": "AI in ESG for Financial Institutions: An Industrial Survey",
    "authors": [
      "Jun Xu"
    ],
    "abstract": "The burgeoning integration of Artificial Intelligence (AI) into\nEnvironmental, Social, and Governance (ESG) initiatives within the financial\nsector represents a paradigm shift towards more sus-tainable and equitable\nfinancial practices. This paper surveys the industrial landscape to delineate\nthe necessity and impact of AI in bolstering ESG frameworks. With the advent of\nstringent regulatory requirements and heightened stakeholder awareness,\nfinancial institutions (FIs) are increasingly compelled to adopt ESG criteria.\nAI emerges as a pivotal tool in navigating the complex in-terplay of financial\nactivities and sustainability goals. Our survey categorizes AI applications\nacross three main pillars of ESG, illustrating how AI enhances analytical\ncapabilities, risk assessment, customer engagement, reporting accuracy and\nmore. Further, we delve into the critical con-siderations surrounding the use\nof data and the development of models, underscoring the importance of data\nquality, privacy, and model robustness. The paper also addresses the imperative\nof responsible and sustainable AI, emphasizing the ethical dimensions of AI\ndeployment in ESG-related banking processes. Conclusively, our findings suggest\nthat while AI offers transformative potential for ESG in banking, it also poses\nsignificant challenges that necessitate careful consideration. The final part\nof the paper synthesizes the survey's insights, proposing a forward-looking\nstance on the adoption of AI in ESG practices. We conclude with recommendations\nwith a reference architecture for future research and development, advocating\nfor a balanced approach that leverages AI's strengths while mitigating its\nrisks within the ESG domain.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "q-fin.CP"
    ],
    "primary_category": "cs.CY",
    "comment": "31 pages, 14 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.05541v1",
    "published_date": "2024-02-03 02:14:47 UTC",
    "updated_date": "2024-02-03 02:14:47 UTC"
  },
  {
    "arxiv_id": "2402.01987v2",
    "title": "Online Transfer Learning for RSV Case Detection",
    "authors": [
      "Yiming Sun",
      "Yuhe Gao",
      "Runxue Bao",
      "Gregory F. Cooper",
      "Jessi Espino",
      "Harry Hochheiser",
      "Marian G. Michaels",
      "John M. Aronis",
      "Chenxi Song",
      "Ye Ye"
    ],
    "abstract": "Transfer learning has become a pivotal technique in machine learning and has\nproven to be effective in various real-world applications. However, utilizing\nthis technique for classification tasks with sequential data often faces\nchallenges, primarily attributed to the scarcity of class labels. To address\nthis challenge, we introduce Multi-Source Adaptive Weighting (MSAW), an online\nmulti-source transfer learning method. MSAW integrates a dynamic weighting\nmechanism into an ensemble framework, enabling automatic adjustment of weights\nbased on the relevance and contribution of each source (representing historical\nknowledge) and target model (learning from newly acquired data). We demonstrate\nthe effectiveness of MSAW by applying it to detect Respiratory Syncytial Virus\ncases within Emergency Department visits, utilizing multiple years of\nelectronic health records from the University of Pittsburgh Medical Center. Our\nmethod demonstrates performance improvements over many baselines, including\nrefining pre-trained models with online learning as well as three static\nweighting approaches, showing MSAW's capacity to integrate historical knowledge\nwith progressively accumulated new data. This study indicates the potential of\nonline transfer learning in healthcare, particularly for developing machine\nlearning models that dynamically adapt to evolving situations where new data is\nincrementally accumulated.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01987v2",
    "published_date": "2024-02-03 02:13:08 UTC",
    "updated_date": "2024-04-07 22:10:09 UTC"
  },
  {
    "arxiv_id": "2402.01981v1",
    "title": "Self-Debiasing Large Language Models: Zero-Shot Recognition and Reduction of Stereotypes",
    "authors": [
      "Isabel O. Gallegos",
      "Ryan A. Rossi",
      "Joe Barrow",
      "Md Mehrab Tanjim",
      "Tong Yu",
      "Hanieh Deilamsalehy",
      "Ruiyi Zhang",
      "Sungchul Kim",
      "Franck Dernoncourt"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable advances in language\ngeneration and understanding but are also prone to exhibiting harmful social\nbiases. While recognition of these behaviors has generated an abundance of bias\nmitigation techniques, most require modifications to the training data, model\nparameters, or decoding strategy, which may be infeasible without access to a\ntrainable model. In this work, we leverage the zero-shot capabilities of LLMs\nto reduce stereotyping in a technique we introduce as zero-shot self-debiasing.\nWith two approaches, self-debiasing via explanation and self-debiasing via\nreprompting, we show that self-debiasing can significantly reduce the degree of\nstereotyping across nine different social groups while relying only on the LLM\nitself and a simple prompt, with explanations correctly identifying invalid\nassumptions and reprompting delivering the greatest reductions in bias. We hope\nthis work opens inquiry into other zero-shot techniques for bias mitigation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01981v1",
    "published_date": "2024-02-03 01:40:11 UTC",
    "updated_date": "2024-02-03 01:40:11 UTC"
  },
  {
    "arxiv_id": "2402.07922v1",
    "title": "Towards the Human Digital Twin: Definition and Design -- A survey",
    "authors": [
      "Martin Wolfgang Lauer-Schmaltz",
      "Philip Cash",
      "John Paulin Hansen",
      "Anja Maier"
    ],
    "abstract": "Human Digital Twins (HDTs) are a fast-emerging technology with significant\npotential in fields ranging from healthcare to sports. HDTs extend the\ntraditional understanding of Digital Twins by representing humans as the\nunderlying physical entity. This has introduced several significant challenges,\nincluding ambiguity in the definition of HDTs and a lack of guidance for their\ndesign. This survey brings together the recent advances in the field of HDTs to\nguide future developers by proposing a first cross-domain definition of HDTs\nbased on their characteristics, as well as eleven key design considerations\nthat emerge from the associated challenges.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.HC",
    "comment": "This paper is an extension of the following paper: Lauer-Schmaltz MW,\n  Cash P, Hansen JP, Maier A. Designing Human Digital Twins for\n  Behaviour-Changing Therapy and Rehabilitation: A Systematic Review.\n  Proceedings of the Design Society. 2022;2:1303-1312. doi:10.1017/pds.2022.132",
    "pdf_url": "http://arxiv.org/pdf/2402.07922v1",
    "published_date": "2024-02-03 01:33:05 UTC",
    "updated_date": "2024-02-03 01:33:05 UTC"
  },
  {
    "arxiv_id": "2402.01968v2",
    "title": "A Survey on Context-Aware Multi-Agent Systems: Techniques, Challenges and Future Directions",
    "authors": [
      "Hung Du",
      "Srikanth Thudumu",
      "Rajesh Vasa",
      "Kon Mouzakis"
    ],
    "abstract": "Research interest in autonomous agents is on the rise as an emerging topic.\nThe notable achievements of Large Language Models (LLMs) have demonstrated the\nconsiderable potential to attain human-like intelligence in autonomous agents.\nHowever, the challenge lies in enabling these agents to learn, reason, and\nnavigate uncertainties in dynamic environments. Context awareness emerges as a\npivotal element in fortifying multi-agent systems when dealing with dynamic\nsituations. Despite existing research focusing on both context-aware systems\nand multi-agent systems, there is a lack of comprehensive surveys outlining\ntechniques for integrating context-aware systems with multi-agent systems. To\naddress this gap, this survey provides a comprehensive overview of\nstate-of-the-art context-aware multi-agent systems. First, we outline the\nproperties of both context-aware systems and multi-agent systems that\nfacilitate integration between these systems. Subsequently, we propose a\ngeneral process for context-aware systems, with each phase of the process\nencompassing diverse approaches drawn from various application domains such as\ncollision avoidance in autonomous driving, disaster relief management, utility\nmanagement, supply chain management, human-AI interaction, and others. Finally,\nwe discuss the existing challenges of context-aware multi-agent systems and\nprovide future research directions in this field.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "11 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2402.01968v2",
    "published_date": "2024-02-03 00:27:22 UTC",
    "updated_date": "2025-01-29 05:41:52 UTC"
  }
]