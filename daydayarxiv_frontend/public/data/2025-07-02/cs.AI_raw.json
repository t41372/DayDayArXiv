[
  {
    "arxiv_id": "2507.02200v1",
    "title": "ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning",
    "authors": [
      "Xiao Wang",
      "Jingtao Jiang",
      "Qiang Chen",
      "Lan Chen",
      "Lin Zhu",
      "Yaowei Wang",
      "Yonghong Tian",
      "Jin Tang"
    ],
    "abstract": "Event stream based scene text recognition is a newly arising research topic in recent years which performs better than the widely used RGB cameras in extremely challenging scenarios, especially the low illumination, fast motion. Existing works either adopt end-to-end encoder-decoder framework or large language models for enhanced recognition, however, they are still limited by the challenges of insufficient interpretability and weak contextual logical reasoning. In this work, we propose a novel chain-of-thought reasoning based event stream scene text recognition framework, termed ESTR-CoT. Specifically, we first adopt the vision encoder EVA-CLIP (ViT-G/14) to transform the input event stream into tokens and utilize a Llama tokenizer to encode the given generation prompt. A Q-former is used to align the vision token to the pre-trained large language model Vicuna-7B and output both the answer and chain-of-thought (CoT) reasoning process simultaneously. Our framework can be optimized using supervised fine-tuning in an end-to-end manner. In addition, we also propose a large-scale CoT dataset to train our framework via a three stage processing (i.e., generation, polish, and expert verification). This dataset provides a solid data foundation for the development of subsequent reasoning-based large models. Extensive experiments on three event stream STR benchmark datasets (i.e., EventSTR, WordArt*, IC15*) fully validated the effectiveness and interpretability of our proposed framework. The source code and pre-trained models will be released on https://github.com/Event-AHU/ESTR-CoT.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "A Strong Baseline for Reasoning based Event Stream Scene Text Recognition",
    "pdf_url": "https://arxiv.org/pdf/2507.02200v1",
    "published_date": "2025-07-02 23:41:31 UTC",
    "updated_date": "2025-07-02 23:41:31 UTC"
  },
  {
    "arxiv_id": "2507.02199v2",
    "title": "Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer",
    "authors": [
      "Wenquan Lu",
      "Yuechuan Yang",
      "Kyle Lee",
      "Yanshu Li",
      "Enqi Liu"
    ],
    "abstract": "Chain-of-thought (CoT) reasoning has enabled transformer-based language models to excel at complex mathematics and multi-step planning. However, in standard decoder-only architectures, these reasoning steps are externalized in natural language, improving interpretability at the cost of efficiency. To capture reasoning that is not easily represented in words, many works have explored recurrent architectures that aim to internalize reasoning in latent space, potentially supporting latent CoT. In this paper, we investigate whether such reasoning structures emerge in Huginn-3.5B, a depth-recurrent Transformer that reuses layers at inference time without increasing parameter count. We examine the model's internal behavior on arithmetic tasks using a suite of probing techniques including the Logit Lens and Coda Lens. Our findings reveal limited evidence of interpretable latent CoT by tracking rank trajectories of final and intermediate result tokens. Furthermore, we uncover significant probing inconsistencies across recurrent blocks, where the interpretability of hidden states depends heavily on both the layer index and the decoding method. Finally, we empirically show that increasing recurrence depth yields only marginal gains and falls well short of models that explicitly externalize reasoning steps. The code is available at https://github.com/wenquanlu/huginn-latent-cot.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "First Workshop on the Application of LLM Explainability to Reasoning and Planning at COLM 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.02199v2",
    "published_date": "2025-07-02 23:35:21 UTC",
    "updated_date": "2025-09-28 04:19:15 UTC"
  },
  {
    "arxiv_id": "2507.02197v1",
    "title": "Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust",
    "authors": [
      "Amogh Mannekote",
      "Adam Davies",
      "Guohao Li",
      "Kristy Elizabeth Boyer",
      "ChengXiang Zhai",
      "Bonnie J Dorr",
      "Francesco Pinto"
    ],
    "abstract": "As LLMs are increasingly studied as role-playing agents to generate synthetic data for human behavioral research, ensuring that their outputs remain coherent with their assigned roles has become a critical concern. In this paper, we investigate how consistently LLM-based role-playing agents' stated beliefs about the behavior of the people they are asked to role-play (\"what they say\") correspond to their actual behavior during role-play (\"how they act\"). Specifically, we establish an evaluation framework to rigorously measure how well beliefs obtained by prompting the model can predict simulation outcomes in advance. Using an augmented version of the GenAgents persona bank and the Trust Game (a standard economic game used to quantify players' trust and reciprocity), we introduce a belief-behavior consistency metric to systematically investigate how it is affected by factors such as: (1) the types of beliefs we elicit from LLMs, like expected outcomes of simulations versus task-relevant attributes of individual characters LLMs are asked to simulate; (2) when and how we present LLMs with relevant information about Trust Game; and (3) how far into the future we ask the model to forecast its actions. We also explore how feasible it is to impose a researcher's own theoretical priors in the event that the originally elicited beliefs are misaligned with research objectives. Our results reveal systematic inconsistencies between LLMs' stated (or imposed) beliefs and the outcomes of their role-playing simulation, at both an individual- and population-level. Specifically, we find that, even when models appear to encode plausible beliefs, they may fail to apply them in a consistent way. These findings highlight the need to identify how and when LLMs' stated beliefs align with their simulated behavior, allowing researchers to use LLM-based agents appropriately in behavioral studies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02197v1",
    "published_date": "2025-07-02 23:30:51 UTC",
    "updated_date": "2025-07-02 23:30:51 UTC"
  },
  {
    "arxiv_id": "2507.02173v1",
    "title": "Data Diversification Methods In Alignment Enhance Math Performance In LLMs",
    "authors": [
      "Berkan Dokmeci",
      "Qingyang Wu",
      "Ben Athiwaratkun",
      "Ce Zhang",
      "Shuaiwen Leon Song",
      "James Zou"
    ],
    "abstract": "While recent advances in preference learning have enhanced alignment in human feedback, mathematical reasoning remains a persistent challenge. We investigate how data diversification strategies in preference optimization can improve the mathematical reasoning abilities of large language models (LLMs). We evaluate three common data generation methods: temperature sampling, Chain-of-Thought prompting, and Monte Carlo Tree Search (MCTS), and introduce Diversified-ThinkSolve (DTS), a novel structured approach that systematically decomposes problems into diverse reasoning paths. Our results show that with strategically diversified preference data, models can substantially improve mathematical reasoning performance, with the best approach yielding gains of 7.1% on GSM8K and 4.2% on MATH over the base model. Despite its strong performance, DTS incurs only a marginal computational overhead (1.03x) compared to the baseline, while MCTS is nearly five times more costly with lower returns. These findings demonstrate that structured exploration of diverse problem-solving methods creates more effective preference data for mathematical alignment than traditional approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02173v1",
    "published_date": "2025-07-02 22:12:03 UTC",
    "updated_date": "2025-07-02 22:12:03 UTC"
  },
  {
    "arxiv_id": "2507.02171v2",
    "title": "Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN",
    "authors": [
      "Miroslav Cibula",
      "Kristína Malinovská",
      "Matthias Kerzel"
    ],
    "abstract": "Trajectory planning in robotics is understood as generating a sequence of joint configurations that will lead a robotic agent, or its manipulator, from an initial state to the desired final state, thus completing a manipulation task while considering constraints like robot kinematics and the environment. Typically, this is achieved via sampling-based planners, which are computationally intensive. Recent advances demonstrate that trajectory planning can also be performed by supervised sequence learning of trajectories, often requiring only a single or fixed number of passes through a neural architecture, thus ensuring a bounded computation time. Such fully supervised approaches, however, perform imitation learning; they do not learn based on whether the trajectories can successfully reach a goal, but try to reproduce observed trajectories. In our work, we build on this approach and propose a cognitively inspired self-supervised learning scheme based on a recurrent architecture for building a trajectory model. We evaluate the feasibility of the proposed method on a task of kinematic planning for a robotic arm. The results suggest that the model is able to learn to generate trajectories only using given paired forward and inverse kinematics models, and indicate that this novel method could facilitate planning for more complex manipulation tasks requiring adaptive solutions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "12 pages, 4 figures, 2 tables. To be published in 2025 International Conference on Artificial Neural Networks (ICANN) proceedings. This research was funded by the Horizon Europe project TERAIS, GA no. 101079338, and in part by the Slovak Grant Agency for Science (VEGA), project 1/0373/23. The code can be found at https://doi.org/10.5281/zenodo.17127997",
    "pdf_url": "https://arxiv.org/pdf/2507.02171v2",
    "published_date": "2025-07-02 22:05:58 UTC",
    "updated_date": "2025-09-16 00:36:01 UTC"
  },
  {
    "arxiv_id": "2507.03028v1",
    "title": "Deep Learning-Based Forecasting of Hotel KPIs: A Cross-City Analysis of Global Urban Markets",
    "authors": [
      "C. J. Atapattu",
      "Xia Cui",
      "N. R Abeynayake"
    ],
    "abstract": "This study employs Long Short-Term Memory (LSTM) networks to forecast key performance indicators (KPIs), Occupancy (OCC), Average Daily Rate (ADR), and Revenue per Available Room (RevPAR), across five major cities: Manchester, Amsterdam, Dubai, Bangkok, and Mumbai. The cities were selected for their diverse economic profiles and hospitality dynamics. Monthly data from 2018 to 2025 were used, with 80% for training and 20% for testing. Advanced time series decomposition and machine learning techniques enabled accurate forecasting and trend identification. Results show that Manchester and Mumbai exhibited the highest predictive accuracy, reflecting stable demand patterns, while Dubai and Bangkok demonstrated higher variability due to seasonal and event-driven influences. The findings validate the effectiveness of LSTM models for urban hospitality forecasting and provide a comparative framework for data-driven decision-making. The models generalisability across global cities highlights its potential utility for tourism stakeholders and urban planners.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.03028v1",
    "published_date": "2025-07-02 22:05:51 UTC",
    "updated_date": "2025-07-02 22:05:51 UTC"
  },
  {
    "arxiv_id": "2507.02166v1",
    "title": "Generating Large Semi-Synthetic Graphs of Any Size",
    "authors": [
      "Rodrigo Tuna",
      "Carlos Soares"
    ],
    "abstract": "Graph generation is an important area in network science. Traditional approaches focus on replicating specific properties of real-world graphs, such as small diameters or power-law degree distributions. Recent advancements in deep learning, particularly with Graph Neural Networks, have enabled data-driven methods to learn and generate graphs without relying on predefined structural properties. Despite these advances, current models are limited by their reliance on node IDs, which restricts their ability to generate graphs larger than the input graph and ignores node attributes. To address these challenges, we propose Latent Graph Sampling Generation (LGSG), a novel framework that leverages diffusion models and node embeddings to generate graphs of varying sizes without retraining. The framework eliminates the dependency on node IDs and captures the distribution of node embeddings and subgraph structures, enabling scalable and flexible graph generation. Experimental results show that LGSG performs on par with baseline models for standard metrics while outperforming them in overlooked ones, such as the tendency of nodes to form clusters. Additionally, it maintains consistent structural characteristics across graphs of different sizes, demonstrating robustness and scalability.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02166v1",
    "published_date": "2025-07-02 21:46:28 UTC",
    "updated_date": "2025-07-02 21:46:28 UTC"
  },
  {
    "arxiv_id": "2507.03026v1",
    "title": "Generalized Adaptive Transfer Network: Enhancing Transfer Learning in Reinforcement Learning Across Domains",
    "authors": [
      "Abhishek Verma",
      "Nallarasan V",
      "Balaraman Ravindran"
    ],
    "abstract": "Transfer learning in Reinforcement Learning (RL) enables agents to leverage knowledge from source tasks to accelerate learning in target tasks. While prior work, such as the Attend, Adapt, and Transfer (A2T) framework, addresses negative transfer and selective transfer, other critical challenges remain underexplored. This paper introduces the Generalized Adaptive Transfer Network (GATN), a deep RL architecture designed to tackle task generalization across domains, robustness to environmental changes, and computational efficiency in transfer. GATN employs a domain-agnostic representation module, a robustness-aware policy adapter, and an efficient transfer scheduler to achieve these goals. We evaluate GATN on diverse benchmarks, including Atari 2600, MuJoCo, and a custom chatbot dialogue environment, demonstrating superior performance in cross-domain generalization, resilience to dynamic environments, and reduced computational overhead compared to baselines. Our findings suggest GATN is a versatile framework for real-world RL applications, such as adaptive chatbots and robotic control.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.03026v1",
    "published_date": "2025-07-02 21:33:48 UTC",
    "updated_date": "2025-07-02 21:33:48 UTC"
  },
  {
    "arxiv_id": "2510.15872v1",
    "title": "Multimodal Chip Physical Design Engineer Assistant",
    "authors": [
      "Yun-Da Tsai",
      "Chang-Yu Chao",
      "Liang-Yeh Shen",
      "Tsung-Han Lin",
      "Haoyu Yang",
      "Mark Ho",
      "Yi-Chen Lu",
      "Wen-Hao Liu",
      "Shou-De Lin",
      "Haoxing Ren"
    ],
    "abstract": "Modern chip physical design relies heavily on Electronic Design Automation (EDA) tools, which often struggle to provide interpretable feedback or actionable guidance for improving routing congestion. In this work, we introduce a Multimodal Large Language Model Assistant (MLLMA) that bridges this gap by not only predicting congestion but also delivering human-interpretable design suggestions. Our method combines automated feature generation through MLLM-guided genetic prompting with an interpretable preference learning framework that models congestion-relevant tradeoffs across visual, tabular, and textual inputs. We compile these insights into a \"Design Suggestion Deck\" that surfaces the most influential layout features and proposes targeted optimizations. Experiments on the CircuitNet benchmark demonstrate that our approach outperforms existing models on both accuracy and explainability. Additionally, our design suggestion guidance case study and qualitative analyses confirm that the learned preferences align with real-world design principles and are actionable for engineers. This work highlights the potential of MLLMs as interactive assistants for interpretable and context-aware physical design optimization.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2510.15872v1",
    "published_date": "2025-07-02 21:28:54 UTC",
    "updated_date": "2025-07-02 21:28:54 UTC"
  },
  {
    "arxiv_id": "2507.02152v1",
    "title": "The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies",
    "authors": [
      "Disa Sariola",
      "Patrick Button",
      "Aron Culotta",
      "Nicholas Mattei"
    ],
    "abstract": "Artificial intelligence systems, especially those using machine learning, are being deployed in domains from hiring to loan issuance in order to automate these complex decisions. Judging both the effectiveness and fairness of these AI systems, and their human decision making counterpart, is a complex and important topic studied across both computational and social sciences. Within machine learning, a common way to address bias in downstream classifiers is to resample the training data to offset disparities. For example, if hiring rates vary by some protected class, then one may equalize the rate within the training set to alleviate bias in the resulting classifier. While simple and seemingly effective, these methods have typically only been evaluated using data obtained through convenience samples, introducing selection bias and label bias into metrics. Within the social sciences, psychology, public health, and medicine, audit studies, in which fictitious ``testers'' (e.g., resumes, emails, patient actors) are sent to subjects (e.g., job openings, businesses, doctors) in randomized control trials, provide high quality data that support rigorous estimates of discrimination. In this paper, we investigate how data from audit studies can be used to improve our ability to both train and evaluate automated hiring algorithms. We find that such data reveals cases where the common fairness intervention method of equalizing base rates across classes appears to achieve parity using traditional measures, but in fact has roughly 10% disparity when measured appropriately. We additionally introduce interventions based on individual treatment effect estimation methods that further reduce algorithmic discrimination using this data.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02152v1",
    "published_date": "2025-07-02 21:15:56 UTC",
    "updated_date": "2025-07-02 21:15:56 UTC"
  },
  {
    "arxiv_id": "2507.02145v1",
    "title": "Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization",
    "authors": [
      "Keyan Jin",
      "Yapeng Wang",
      "Leonel Santos",
      "Tao Fang",
      "Xu Yang",
      "Sio Kei Im",
      "Hugo Gonçalo Oliveira"
    ],
    "abstract": "Dialogue summarization is a challenging task with significant practical value in customer service, meeting analysis, and conversational AI. Although large language models (LLMs) have achieved substantial progress in summarization tasks, the performance of step-by-step reasoning architectures-specifically Long Chain-of-Thought (CoT) implementations such as OpenAI-o1 and DeepSeek-R1-remains unexplored for dialogue scenarios requiring concurrent abstraction and conciseness. In this work, we present the first comprehensive and systematic evaluation of state-of-the-art reasoning LLMs and non-reasoning LLMs across three major paradigms-generic, role-oriented, and query-oriented dialogue summarization. Our study spans diverse languages, domains, and summary lengths, leveraging strong benchmarks (SAMSum, DialogSum, CSDS, and QMSum) and advanced evaluation protocols that include both LLM-based automatic metrics and human-inspired criteria. Contrary to trends in other reasoning-intensive tasks, our findings show that explicit stepwise reasoning does not consistently improve dialogue summarization quality. Instead, reasoning LLMs are often prone to verbosity, factual inconsistencies, and less concise summaries compared to their non-reasoning counterparts. Through scenario-specific analyses and detailed case studies, we further identify when and why explicit reasoning may fail to benefit-or even hinder-summarization in complex dialogue contexts. Our work provides new insights into the limitations of current reasoning LLMs and highlights the need for targeted modeling and evaluation strategies for real-world dialogue summarization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02145v1",
    "published_date": "2025-07-02 21:02:41 UTC",
    "updated_date": "2025-07-02 21:02:41 UTC"
  },
  {
    "arxiv_id": "2507.02139v1",
    "title": "When LLMs Disagree: Diagnosing Relevance Filtering Bias and Retrieval Divergence in SDG Search",
    "authors": [
      "William A. Ingram",
      "Bipasha Banerjee",
      "Edward A. Fox"
    ],
    "abstract": "Large language models (LLMs) are increasingly used to assign document relevance labels in information retrieval pipelines, especially in domains lacking human-labeled data. However, different models often disagree on borderline cases, raising concerns about how such disagreement affects downstream retrieval. This study examines labeling disagreement between two open-weight LLMs, LLaMA and Qwen, on a corpus of scholarly abstracts related to Sustainable Development Goals (SDGs) 1, 3, and 7. We isolate disagreement subsets and examine their lexical properties, rank-order behavior, and classification predictability. Our results show that model disagreement is systematic, not random: disagreement cases exhibit consistent lexical patterns, produce divergent top-ranked outputs under shared scoring functions, and are distinguishable with AUCs above 0.74 using simple classifiers. These findings suggest that LLM-based filtering introduces structured variability in document retrieval, even under controlled prompting and shared ranking logic. We propose using classification disagreement as an object of analysis in retrieval evaluation, particularly in policy-relevant or thematic search tasks.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.IR",
    "comment": "Presented at LLM4Eval Workshop, SIGIR 2025 Padova, Italy, July 17, 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.02139v1",
    "published_date": "2025-07-02 20:53:51 UTC",
    "updated_date": "2025-07-02 20:53:51 UTC"
  },
  {
    "arxiv_id": "2507.02125v1",
    "title": "Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities",
    "authors": [
      "Giulio Caldarelli"
    ],
    "abstract": "The blockchain oracle problem, which refers to the challenge of injecting reliable external data into decentralized systems, remains a fundamental limitation to the development of trustless applications. While recent years have seen a proliferation of architectural, cryptographic, and economic strategies to mitigate this issue, no one has yet fully resolved the fundamental question of how a blockchain can gain knowledge about the off-chain world. In this position paper, we critically assess the role artificial intelligence (AI) can play in tackling the oracle problem. Drawing from both academic literature and practitioner implementations, we examine how AI techniques such as anomaly detection, language-based fact extraction, dynamic reputation modeling, and adversarial resistance can enhance oracle systems. We observe that while AI introduces powerful tools for improving data quality, source selection, and system resilience, it cannot eliminate the reliance on unverifiable off-chain inputs. Therefore, this study supports the idea that AI should be understood as a complementary layer of inference and filtering within a broader oracle design, not a substitute for trust assumptions.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02125v1",
    "published_date": "2025-07-02 20:15:21 UTC",
    "updated_date": "2025-07-02 20:15:21 UTC"
  },
  {
    "arxiv_id": "2507.02106v2",
    "title": "Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework",
    "authors": [
      "Semih Kacmaz",
      "E. A. Huerta",
      "Roland Haas"
    ],
    "abstract": "We present a hybrid machine learning framework that combines Physics-Informed Neural Operators (PINOs) with score-based generative diffusion models to simulate the full spatio-temporal evolution of two-dimensional, incompressible, resistive magnetohydrodynamic (MHD) turbulence across a broad range of Reynolds numbers ($\\mathrm{Re}$). The framework leverages the equation-constrained generalization capabilities of PINOs to predict coherent, low-frequency dynamics, while a conditional diffusion model stochastically corrects high-frequency residuals, enabling accurate modeling of fully developed turbulence. Trained on a comprehensive ensemble of high-fidelity simulations with $\\mathrm{Re} \\in \\{100, 250, 500, 750, 1000, 3000, 10000\\}$, the approach achieves state-of-the-art accuracy in regimes previously inaccessible to deterministic surrogates. At $\\mathrm{Re}=1000$ and $3000$, the model faithfully reconstructs the full spectral energy distributions of both velocity and magnetic fields late into the simulation, capturing non-Gaussian statistics, intermittent structures, and cross-field correlations with high fidelity. At extreme turbulence levels ($\\mathrm{Re}=10000$), it remains the first surrogate capable of recovering the high-wavenumber evolution of the magnetic field, preserving large-scale morphology and enabling statistically meaningful predictions.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.LG",
      "gr-qc",
      "physics.comp-ph"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "16 pages, 6 figures, 1 table. Content synced with the published version",
    "pdf_url": "https://arxiv.org/pdf/2507.02106v2",
    "published_date": "2025-07-02 19:33:57 UTC",
    "updated_date": "2025-09-22 01:05:44 UTC"
  },
  {
    "arxiv_id": "2507.02103v1",
    "title": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments",
    "authors": [
      "Daniel Durstewitz",
      "Bruno Averbeck",
      "Georgia Koppe"
    ],
    "abstract": "Modern AI models, such as large language models, are usually trained once on a huge corpus of data, potentially fine-tuned for a specific task, and then deployed with fixed parameters. Their training is costly, slow, and gradual, requiring billions of repetitions. In stark contrast, animals continuously adapt to the ever-changing contingencies in their environments. This is particularly important for social species, where behavioral policies and reward outcomes may frequently change in interaction with peers. The underlying computational processes are often marked by rapid shifts in an animal's behaviour and rather sudden transitions in neuronal population activity. Such computational capacities are of growing importance for AI systems operating in the real world, like those guiding robots or autonomous vehicles, or for agentic AI interacting with humans online. Can AI learn from neuroscience? This Perspective explores this question, integrating the literature on continual and in-context learning in AI with the neuroscience of learning on behavioral tasks with shifting rules, reward probabilities, or outcomes. We will outline an agenda for how specifically insights from neuroscience may inform current developments in AI in this area, and - vice versa - what neuroscience may learn from AI, contributing to the evolving field of NeuroAI.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted as a Perspective article (10 pages, 5 figures)",
    "pdf_url": "https://arxiv.org/pdf/2507.02103v1",
    "published_date": "2025-07-02 19:30:57 UTC",
    "updated_date": "2025-07-02 19:30:57 UTC"
  },
  {
    "arxiv_id": "2507.02092v1",
    "title": "Energy-Based Transformers are Scalable Learners and Thinkers",
    "authors": [
      "Alexi Gladstone",
      "Ganesh Nanduru",
      "Md Mofijul Islam",
      "Peixuan Han",
      "Hyeonjeong Ha",
      "Aman Chadha",
      "Yilun Du",
      "Heng Ji",
      "Jundong Li",
      "Tariq Iqbal"
    ],
    "abstract": "Inference-time computation techniques, analogous to human System 2 Thinking, have recently become popular for improving model performances. However, most existing approaches suffer from several limitations: they are modality-specific (e.g., working only in text), problem-specific (e.g., verifiable domains like math and coding), or require additional supervision/training on top of unsupervised pretraining (e.g., verifiers or verifiable rewards). In this paper, we ask the question \"Is it possible to generalize these System 2 Thinking approaches, and develop models that learn to think solely from unsupervised learning?\" Interestingly, we find the answer is yes, by learning to explicitly verify the compatibility between inputs and candidate-predictions, and then re-framing prediction problems as optimization with respect to this verifier. Specifically, we train Energy-Based Transformers (EBTs) -- a new class of Energy-Based Models (EBMs) -- to assign an energy value to every input and candidate-prediction pair, enabling predictions through gradient descent-based energy minimization until convergence. Across both discrete (text) and continuous (visual) modalities, we find EBTs scale faster than the dominant Transformer++ approach during training, achieving an up to 35% higher scaling rate with respect to data, batch size, parameters, FLOPs, and depth. During inference, EBTs improve performance with System 2 Thinking by 29% more than the Transformer++ on language tasks, and EBTs outperform Diffusion Transformers on image denoising while using fewer forward passes. Further, we find that EBTs achieve better results than existing models on most downstream tasks given the same or worse pretraining performance, suggesting that EBTs generalize better than existing approaches. Consequently, EBTs are a promising new paradigm for scaling both the learning and thinking capabilities of models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02092v1",
    "published_date": "2025-07-02 19:17:29 UTC",
    "updated_date": "2025-07-02 19:17:29 UTC"
  },
  {
    "arxiv_id": "2507.03024v1",
    "title": "Completion of the DrugMatrix Toxicogenomics Database using 3-Dimensional Tensors",
    "authors": [
      "Tan Nguyen",
      "Guojing Cong"
    ],
    "abstract": "We explore applying a tensor completion approach to complete the DrugMatrix toxicogenomics dataset. Our hypothesis is that by preserving the 3-dimensional structure of the data, which comprises tissue, treatment, and transcriptomic measurements, and by leveraging a machine learning formulation, our approach will improve upon prior state-of-the-art results. Our results demonstrate that the new tensor-based method more accurately reflects the original data distribution and effectively captures organ-specific variability. The proposed tensor-based methodology achieved lower mean squared errors and mean absolute errors compared to both conventional Canonical Polyadic decomposition and 2-dimensional matrix factorization methods. In addition, our non-negative tensor completion implementation reveals relationships among tissues. Our findings not only complete the world's largest in-vivo toxicogenomics database with improved accuracy but also offer a promising methodology for future studies of drugs that may cross species barriers, for example, from rats to humans.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 6 figures, BioKDD'25",
    "pdf_url": "https://arxiv.org/pdf/2507.03024v1",
    "published_date": "2025-07-02 19:15:51 UTC",
    "updated_date": "2025-07-02 19:15:51 UTC"
  },
  {
    "arxiv_id": "2507.02085v1",
    "title": "GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters",
    "authors": [
      "Wanjia Zhao",
      "Jiaqi Han",
      "Siyi Gu",
      "Mingjian Jiang",
      "James Zou",
      "Stefano Ermon"
    ],
    "abstract": "Geometric diffusion models have shown remarkable success in molecular dynamics and structure generation. However, efficiently fine-tuning them for downstream tasks with varying geometric controls remains underexplored. In this work, we propose an SE(3)-equivariant adapter framework ( GeoAda) that enables flexible and parameter-efficient fine-tuning for controlled generative tasks without modifying the original model architecture. GeoAda introduces a structured adapter design: control signals are first encoded through coupling operators, then processed by a trainable copy of selected pretrained model layers, and finally projected back via decoupling operators followed by an equivariant zero-initialized convolution. By fine-tuning only these lightweight adapter modules, GeoAda preserves the model's geometric consistency while mitigating overfitting and catastrophic forgetting. We theoretically prove that the proposed adapters maintain SE(3)-equivariance, ensuring that the geometric inductive biases of the pretrained diffusion model remain intact during adaptation. We demonstrate the wide applicability of GeoAda across diverse geometric control types, including frame control, global control, subgraph control, and a broad range of application domains such as particle dynamics, molecular dynamics, human motion prediction, and molecule generation. Empirical results show that GeoAda achieves state-of-the-art fine-tuning performance while preserving original task accuracy, whereas other baselines experience significant performance degradation due to overfitting and catastrophic forgetting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02085v1",
    "published_date": "2025-07-02 18:44:03 UTC",
    "updated_date": "2025-07-02 18:44:03 UTC"
  },
  {
    "arxiv_id": "2507.02083v2",
    "title": "Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab",
    "authors": [
      "Haonan Duan",
      "Stephen Zhewen Lu",
      "Caitlin Fiona Harrigan",
      "Nishkrit Desai",
      "Jiarui Lu",
      "Michał Koziarski",
      "Leonardo Cotta",
      "Chris J. Maddison"
    ],
    "abstract": "Designing experiments and result interpretations are core scientific competencies, particularly in biology, where researchers perturb complex systems to uncover the underlying systems. Recent efforts to evaluate the scientific capabilities of large language models (LLMs) fail to test these competencies because wet-lab experimentation is prohibitively expensive: in expertise, time and equipment. We introduce SciGym, a first-in-class benchmark that assesses LLMs' iterative experiment design and analysis abilities in open-ended scientific discovery tasks. SciGym overcomes the challenge of wet-lab costs by running a dry lab of biological systems. These models, encoded in Systems Biology Markup Language, are efficient for generating simulated data, making them ideal testbeds for experimentation on realistically complex systems. We evaluated six frontier LLMs on 137 small systems, and released a total of 350 systems. Our evaluation shows that while more capable models demonstrated superior performance, all models' performance declined significantly as system complexity increased, suggesting substantial room for improvement in the scientific capabilities of LLM agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02083v2",
    "published_date": "2025-07-02 18:41:44 UTC",
    "updated_date": "2025-07-14 15:17:16 UTC"
  },
  {
    "arxiv_id": "2507.02076v1",
    "title": "Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs",
    "authors": [
      "Mohammad Ali Alomrani",
      "Yingxue Zhang",
      "Derek Li",
      "Qianyi Sun",
      "Soumyasundar Pal",
      "Zhanguang Zhang",
      "Yaochen Hu",
      "Rohan Deepak Ajwani",
      "Antonios Valkanas",
      "Raika Karimi",
      "Peng Cheng",
      "Yunzhou Wang",
      "Pengyi Liao",
      "Hanrui Huang",
      "Bin Wang",
      "Jianye Hao",
      "Mark Coates"
    ],
    "abstract": "Large language models (LLMs) have rapidly progressed into general-purpose agents capable of solving a broad spectrum of tasks. However, current models remain inefficient at reasoning: they apply fixed inference-time compute regardless of task complexity, often overthinking simple problems while underthinking hard ones. This survey presents a comprehensive review of efficient test-time compute (TTC) strategies, which aim to improve the computational efficiency of LLM reasoning. We introduce a two-tiered taxonomy that distinguishes between L1-controllability, methods that operate under fixed compute budgets, and L2-adaptiveness, methods that dynamically scale inference based on input difficulty or model confidence. We benchmark leading proprietary LLMs across diverse datasets, highlighting critical trade-offs between reasoning performance and token usage. Compared to prior surveys on efficient reasoning, our review emphasizes the practical control, adaptability, and scalability of TTC methods. Finally, we discuss emerging trends such as hybrid thinking models and identify key challenges for future work towards making LLMs more computationally efficient, robust, and responsive to user constraints.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02076v1",
    "published_date": "2025-07-02 18:27:42 UTC",
    "updated_date": "2025-07-02 18:27:42 UTC"
  },
  {
    "arxiv_id": "2507.02074v2",
    "title": "Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges",
    "authors": [
      "Sanjeda Akter",
      "Ibne Farabi Shihab",
      "Anuj Sharma"
    ],
    "abstract": "Crash detection from video feeds is a critical problem in intelligent transportation systems. Recent developments in large language models (LLMs) and vision-language models (VLMs) have transformed how we process, reason about, and summarize multimodal information. This paper surveys recent methods leveraging LLMs for crash detection from video data. We present a structured taxonomy of fusion strategies, summarize key datasets, analyze model architectures, compare performance benchmarks, and discuss ongoing challenges and opportunities. Our review provides a foundation for future research in this fast-growing intersection of video understanding and foundation models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02074v2",
    "published_date": "2025-07-02 18:21:01 UTC",
    "updated_date": "2025-09-08 19:23:04 UTC"
  },
  {
    "arxiv_id": "2507.02073v1",
    "title": "HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection",
    "authors": [
      "Nikita Bhedasgaonkar",
      "Rushikesh K. Joshi"
    ],
    "abstract": "In this paper, we propose HCVR (Hybrid approach with Correlation-aware Voting Rules), a lightweight rule-based feature selection method that combines Parameter-to-Parameter (P2P) and Parameter-to-Target (P2T) correlations to eliminate redundant features and retain relevant ones. This method is a hybrid of non-iterative and iterative filtering approaches for dimensionality reduction. It is a greedy method, which works by backward elimination, eliminating possibly multiple features at every step. The rules contribute to voting for features, and a decision to keep or discard is made by majority voting. The rules make use of correlation thresholds between every pair of features, and between features and the target. We provide the results from the application of HCVR to the SPAMBASE dataset. The results showed improvement performance as compared to traditional non-iterative (CFS, mRMR and MI) and iterative (RFE, SFS and Genetic Algorithm) techniques. The effectiveness was assessed based on the performance of different classifiers after applying filtering.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 5 tables, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.02073v1",
    "published_date": "2025-07-02 18:20:56 UTC",
    "updated_date": "2025-07-02 18:20:56 UTC"
  },
  {
    "arxiv_id": "2507.02057v1",
    "title": "MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation",
    "authors": [
      "Lu Yan",
      "Zhuo Zhang",
      "Xiangzhe Xu",
      "Shengwei An",
      "Guangyu Shen",
      "Zhou Xuan",
      "Xuan Chen",
      "Xiangyu Zhang"
    ],
    "abstract": "Large language models (LLMs) have democratized software development, reducing the expertise barrier for programming complex applications. This accessibility extends to malicious software development, raising significant security concerns. While LLM providers have implemented alignment mechanisms to prevent direct generation of overtly malicious code, these safeguards predominantly evaluate individual prompts in isolation, overlooking a critical vulnerability: malicious operations can be systematically decomposed into benign-appearing sub-tasks. In this paper, we introduce the Malware Generation Compiler (MGC), a novel framework that leverages this vulnerability through modular decomposition and alignment-evasive generation. MGC employs a specialized Malware Description Intermediate Representation (MDIR) to bridge high-level malicious intents and benign-appearing code snippets. Extensive evaluation demonstrates that our attack reliably generates functional malware across diverse task specifications and categories, outperforming jailbreaking methods by +365.79% and underground services by +78.07% in correctness on three benchmark datasets. Case studies further show that MGC can reproduce and even enhance 16 real-world malware samples. This work provides critical insights for security researchers by exposing the risks of compositional attacks against aligned AI systems. Demonstrations are available at https://sites.google.com/view/malware-generation-compiler.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02057v1",
    "published_date": "2025-07-02 18:00:49 UTC",
    "updated_date": "2025-07-02 18:00:49 UTC"
  },
  {
    "arxiv_id": "2507.01961v3",
    "title": "AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation",
    "authors": [
      "Sixiang Chen",
      "Jiaming Liu",
      "Siyuan Qian",
      "Han Jiang",
      "Lily Li",
      "Renrui Zhang",
      "Zhuoyang Liu",
      "Chenyang Gu",
      "Chengkai Hou",
      "Pengwei Wang",
      "Zhongyuan Wang",
      "Shanghang Zhang"
    ],
    "abstract": "Recently, mobile manipulation has attracted increasing attention for enabling language-conditioned robotic control in household tasks. However, existing methods still face challenges in coordinating mobile base and manipulator, primarily due to two limitations. On the one hand, they fail to explicitly model the influence of the mobile base on manipulator control, which easily leads to error accumulation under high degrees of freedom. On the other hand, they treat the entire mobile manipulation process with the same visual observation modality (e.g., either all 2D or all 3D), overlooking the distinct multimodal perception requirements at different stages during mobile manipulation. To address this, we propose the Adaptive Coordination Diffusion Transformer (AC-DiT), which enhances mobile base and manipulator coordination for end-to-end mobile manipulation. First, since the motion of the mobile base directly influences the manipulator's actions, we introduce a mobility-to-body conditioning mechanism that guides the model to first extract base motion representations, which are then used as context prior for predicting whole-body actions. This enables whole-body control that accounts for the potential impact of the mobile base's motion. Second, to meet the perception requirements at different stages of mobile manipulation, we design a perception-aware multimodal conditioning strategy that dynamically adjusts the fusion weights between various 2D visual images and 3D point clouds, yielding visual features tailored to the current perceptual needs. This allows the model to, for example, adaptively rely more on 2D inputs when semantic information is crucial for action prediction, while placing greater emphasis on 3D geometric information when precise spatial understanding is required. We validate AC-DiT through extensive experiments on both simulated and real-world mobile manipulation tasks.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: https://ac-dit.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2507.01961v3",
    "published_date": "2025-07-02 17:59:54 UTC",
    "updated_date": "2025-07-05 04:00:38 UTC"
  },
  {
    "arxiv_id": "2507.01957v1",
    "title": "Locality-aware Parallel Decoding for Efficient Autoregressive Image Generation",
    "authors": [
      "Zhuoyang Zhang",
      "Luke J. Huang",
      "Chengyue Wu",
      "Shang Yang",
      "Kelly Peng",
      "Yao Lu",
      "Song Han"
    ],
    "abstract": "We present Locality-aware Parallel Decoding (LPD) to accelerate autoregressive image generation. Traditional autoregressive image generation relies on next-patch prediction, a memory-bound process that leads to high latency. Existing works have tried to parallelize next-patch prediction by shifting to multi-patch prediction to accelerate the process, but only achieved limited parallelization. To achieve high parallelization while maintaining generation quality, we introduce two key techniques: (1) Flexible Parallelized Autoregressive Modeling, a novel architecture that enables arbitrary generation ordering and degrees of parallelization. It uses learnable position query tokens to guide generation at target positions while ensuring mutual visibility among concurrently generated tokens for consistent parallel decoding. (2) Locality-aware Generation Ordering, a novel schedule that forms groups to minimize intra-group dependencies and maximize contextual support, enhancing generation quality. With these designs, we reduce the generation steps from 256 to 20 (256$\\times$256 res.) and 1024 to 48 (512$\\times$512 res.) without compromising quality on the ImageNet class-conditional generation, and achieving at least 3.4$\\times$ lower latency than previous parallelized autoregressive models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The first two authors contributed equally to this work",
    "pdf_url": "https://arxiv.org/pdf/2507.01957v1",
    "published_date": "2025-07-02 17:59:23 UTC",
    "updated_date": "2025-07-02 17:59:23 UTC"
  },
  {
    "arxiv_id": "2507.01955v2",
    "title": "How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks",
    "authors": [
      "Rahul Ramachandran",
      "Ali Garjani",
      "Roman Bachmann",
      "Andrei Atanov",
      "Oğuzhan Fatih Kar",
      "Amir Zamir"
    ],
    "abstract": "Multimodal foundation models, such as GPT-4o, have recently made remarkable progress, but it is not clear where exactly these models stand in terms of understanding vision. In this paper, we benchmark the performance of popular multimodal foundation models (GPT-4o, o4-mini, Gemini 1.5 Pro and Gemini 2.0 Flash, Claude 3.5 Sonnet, Qwen2-VL, Llama 3.2) on standard computer vision tasks (semantic segmentation, object detection, image classification, depth and surface normal prediction) using established datasets (e.g., COCO, ImageNet and its variants, etc).\n  The main challenges to performing this are: 1) most models are trained to output text and cannot natively express versatile domains, such as segments or 3D geometry, and 2) many leading models are proprietary and accessible only at an API level, i.e., there is no weight access to adapt them. We address these challenges by translating standard vision tasks into equivalent text-promptable and API-compatible tasks via prompt chaining to create a standardized benchmarking framework.\n  We observe that 1) the models are not close to the state-of-the-art specialist models at any task. However, 2) they are respectable generalists; this is remarkable as they are presumably trained on primarily image-text-based tasks. 3) They perform semantic tasks notably better than geometric ones. 4) While the prompt-chaining techniques affect performance, better models exhibit less sensitivity to prompt variations. 5) GPT-4o performs the best among non-reasoning models, securing the top position in 4 out of 6 tasks, 6) reasoning models, e.g. o3, show improvements in geometric tasks, and 7) a preliminary analysis of models with native image generation, like the latest GPT-4o, shows they exhibit quirks like hallucinations and spatial misalignments.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page at https://fm-vision-evals.epfl.ch/",
    "pdf_url": "https://arxiv.org/pdf/2507.01955v2",
    "published_date": "2025-07-02 17:59:07 UTC",
    "updated_date": "2025-07-23 10:52:38 UTC"
  },
  {
    "arxiv_id": "2507.01939v4",
    "title": "SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars",
    "authors": [
      "Xiaosheng Zhao",
      "Yang Huang",
      "Guirong Xue",
      "Xiao Kong",
      "Jifeng Liu",
      "Xiaoyu Tang",
      "Timothy C. Beers",
      "Yuan-Sen Ting",
      "A-Li Luo"
    ],
    "abstract": "In recent years, large language models (LLMs) have transformed natural language understanding through vast datasets and large-scale parameterization. Inspired by this success, we present SpecCLIP, a foundation model framework that extends LLM-inspired methodologies to stellar spectral analysis. Stellar spectra, akin to structured language, encode rich physical and chemical information about stars. By training foundation models on large-scale spectral datasets, our goal is to learn robust and informative embeddings that support diverse downstream applications. As a proof of concept, SpecCLIP involves pre-training on two spectral types--LAMOST low-resolution and Gaia XP--followed by contrastive alignment using the CLIP (Contrastive Language-Image Pre-training) framework, adapted to associate spectra from different instruments. This alignment is complemented by auxiliary decoders that preserve spectrum-specific information and enable translation (prediction) between spectral types, with the former achieved by maximizing mutual information between embeddings and input spectra. The result is a cross-spectrum framework enabling intrinsic calibration and flexible applications across instruments. We demonstrate that fine-tuning these models on moderate-sized labeled datasets improves adaptability to tasks such as stellar-parameter estimation and chemical-abundance determination. SpecCLIP also enhances the accuracy and precision of parameter estimates benchmarked against external survey data. Additionally, its similarity search and cross-spectrum prediction capabilities offer potential for anomaly detection. Our results suggest that contrastively trained foundation models enriched with spectrum-aware decoders can advance precision stellar spectroscopy. Our code SpecCLIP is publicly available at https://github.com/Xiaosheng-Zhao/SpecCLIP",
    "categories": [
      "astro-ph.IM",
      "astro-ph.SR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "29 pages, 8 figures, 6 tables. Accepted for publication in ApJ. Comments welcome",
    "pdf_url": "https://arxiv.org/pdf/2507.01939v4",
    "published_date": "2025-07-02 17:49:52 UTC",
    "updated_date": "2025-12-19 18:39:57 UTC"
  },
  {
    "arxiv_id": "2507.01931v1",
    "title": "Adaptability of ASR Models on Low-Resource Language: A Comparative Study of Whisper and Wav2Vec-BERT on Bangla",
    "authors": [
      "Md Sazzadul Islam Ridoy",
      "Sumi Akter",
      "Md. Aminur Rahman"
    ],
    "abstract": "In recent years, neural models trained on large multilingual text and speech datasets have shown great potential for supporting low-resource languages. This study investigates the performances of two state-of-the-art Automatic Speech Recognition (ASR) models, OpenAI's Whisper (Small & Large-V2) and Facebook's Wav2Vec-BERT on Bangla, a low-resource language. We have conducted experiments using two publicly available datasets: Mozilla Common Voice-17 and OpenSLR to evaluate model performances. Through systematic fine-tuning and hyperparameter optimization, including learning rate, epochs, and model checkpoint selection, we have compared the models based on Word Error Rate (WER), Character Error Rate (CER), Training Time, and Computational Efficiency. The Wav2Vec-BERT model outperformed Whisper across all key evaluation metrics, demonstrated superior performance while requiring fewer computational resources, and offered valuable insights to develop robust speech recognition systems in low-resource linguistic settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01931v1",
    "published_date": "2025-07-02 17:44:54 UTC",
    "updated_date": "2025-07-02 17:44:54 UTC"
  },
  {
    "arxiv_id": "2507.01924v1",
    "title": "Exploring a Hybrid Deep Learning Approach for Anomaly Detection in Mental Healthcare Provider Billing: Addressing Label Scarcity through Semi-Supervised Anomaly Detection",
    "authors": [
      "Samirah Bakker",
      "Yao Ma",
      "Seyed Sahand Mohammadi Ziabari"
    ],
    "abstract": "The complexity of mental healthcare billing enables anomalies, including fraud. While machine learning methods have been applied to anomaly detection, they often struggle with class imbalance, label scarcity, and complex sequential patterns. This study explores a hybrid deep learning approach combining Long Short-Term Memory (LSTM) networks and Transformers, with pseudo-labeling via Isolation Forests (iForest) and Autoencoders (AE). Prior work has not evaluated such hybrid models trained on pseudo-labeled data in the context of healthcare billing. The approach is evaluated on two real-world billing datasets related to mental healthcare. The iForest LSTM baseline achieves the highest recall (0.963) on declaration-level data. On the operation-level data, the hybrid iForest-based model achieves the highest recall (0.744), though at the cost of lower precision. These findings highlight the potential of combining pseudo-labeling with hybrid deep learning in complex, imbalanced anomaly detection settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01924v1",
    "published_date": "2025-07-02 17:33:47 UTC",
    "updated_date": "2025-07-02 17:33:47 UTC"
  },
  {
    "arxiv_id": "2507.01918v2",
    "title": "End-to-End Large Portfolio Optimization for Variance Minimization with Neural Networks through Covariance Cleaning",
    "authors": [
      "Christian Bongiorno",
      "Efstratios Manolakis",
      "Rosario Nunzio Mantegna"
    ],
    "abstract": "We develop a rotation-invariant neural network that provides the global minimum-variance portfolio by jointly learning how to lag-transform historical returns and how to regularise both the eigenvalues and the marginal volatilities of large equity covariance matrices. This explicit mathematical mapping offers clear interpretability of each module's role, so the model cannot be regarded as a pure black-box. The architecture mirrors the analytical form of the global minimum-variance solution yet remains agnostic to dimension, so a single model can be calibrated on panels of a few hundred stocks and applied, without retraining, to one thousand US equities-a cross-sectional jump that demonstrates robust out-of-sample generalisation. The loss function is the future realized minimum portfolio variance and is optimized end-to-end on real daily returns. In out-of-sample tests from January 2000 to December 2024 the estimator delivers systematically lower realised volatility, smaller maximum drawdowns, and higher Sharpe ratios than the best analytical competitors, including state-of-the-art non-linear shrinkage. Furthermore, although the model is trained end-to-end to produce an unconstrained (long-short) minimum-variance portfolio, we show that its learned covariance representation can be used in general optimizers under long-only constraints with virtually no loss in its performance advantage over competing estimators. These gains persist when the strategy is executed under a highly realistic implementation framework that models market orders at the auctions, empirical slippage, exchange fees, and financing charges for leverage, and they remain stable during episodes of acute market stress.",
    "categories": [
      "q-fin.PM",
      "cs.AI",
      "math.OC",
      "physics.data-an",
      "stat.ML"
    ],
    "primary_category": "q-fin.PM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01918v2",
    "published_date": "2025-07-02 17:27:29 UTC",
    "updated_date": "2025-07-29 04:20:02 UTC"
  },
  {
    "arxiv_id": "2507.01915v1",
    "title": "Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models",
    "authors": [
      "Chengao Li",
      "Hanyu Zhang",
      "Yunkun Xu",
      "Hongyan Xue",
      "Xiang Ao",
      "Qing He"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful technique for aligning large language models (LLMs) with human preferences. However, effectively aligning LLMs with diverse human preferences remains a significant challenge, particularly when they are conflict. To address this issue, we frame human value alignment as a multi-objective optimization problem, aiming to maximize a set of potentially conflicting objectives. We introduce Gradient-Adaptive Policy Optimization (GAPO), a novel fine-tuning paradigm that employs multiple-gradient descent to align LLMs with diverse preference distributions. GAPO adaptively rescales the gradients for each objective to determine an update direction that optimally balances the trade-offs between objectives. Additionally, we introduce P-GAPO, which incorporates user preferences across different objectives and achieves Pareto solutions that better align with the user's specific needs. Our theoretical analysis demonstrates that GAPO converges towards a Pareto optimal solution for multiple objectives. Empirical results on Mistral-7B show that GAPO outperforms current state-of-the-art methods, achieving superior performance in both helpfulness and harmlessness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 3 figures. Accepted by ACL 2025 (main)",
    "pdf_url": "https://arxiv.org/pdf/2507.01915v1",
    "published_date": "2025-07-02 17:25:26 UTC",
    "updated_date": "2025-07-02 17:25:26 UTC"
  },
  {
    "arxiv_id": "2507.01903v2",
    "title": "AI4Research: A Survey of Artificial Intelligence for Scientific Research",
    "authors": [
      "Qiguang Chen",
      "Mingda Yang",
      "Libo Qin",
      "Jinhao Liu",
      "Zheng Yan",
      "Jiannan Guan",
      "Dengyun Peng",
      "Yiyan Ji",
      "Hanjing Li",
      "Mengkang Hu",
      "Yimeng Zhang",
      "Yihao Liang",
      "Yuhang Zhou",
      "Jiaqi Wang",
      "Zhi Chen",
      "Wanxiang Che"
    ],
    "abstract": "Recent advancements in artificial intelligence (AI), particularly in large language models (LLMs) such as OpenAI-o1 and DeepSeek-R1, have demonstrated remarkable capabilities in complex domains such as logical reasoning and experimental coding. Motivated by these advancements, numerous studies have explored the application of AI in the innovation process, particularly in the context of scientific research. These AI technologies primarily aim to develop systems that can autonomously conduct research processes across a wide range of scientific disciplines. Despite these significant strides, a comprehensive survey on AI for Research (AI4Research) remains absent, which hampers our understanding and impedes further development in this field. To address this gap, we present a comprehensive survey and offer a unified perspective on AI4Research. Specifically, the main contributions of our work are as follows: (1) Systematic taxonomy: We first introduce a systematic taxonomy to classify five mainstream tasks in AI4Research. (2) New frontiers: Then, we identify key research gaps and highlight promising future directions, focusing on the rigor and scalability of automated experiments, as well as the societal impact. (3) Abundant applications and resources: Finally, we compile a wealth of resources, including relevant multidisciplinary applications, data corpora, and tools. We hope our work will provide the research community with quick access to these resources and stimulate innovative breakthroughs in AI4Research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint, Paper list is available at https://github.com/LightChen233/Awesome-AI4Research",
    "pdf_url": "https://arxiv.org/pdf/2507.01903v2",
    "published_date": "2025-07-02 17:19:20 UTC",
    "updated_date": "2025-08-05 16:19:40 UTC"
  },
  {
    "arxiv_id": "2507.01875v1",
    "title": "Towards Foundation Auto-Encoders for Time-Series Anomaly Detection",
    "authors": [
      "Gastón García González",
      "Pedro Casas",
      "Emilio Martínez",
      "Alicia Fernández"
    ],
    "abstract": "We investigate a novel approach to time-series modeling, inspired by the successes of large pretrained foundation models. We introduce FAE (Foundation Auto-Encoders), a foundation generative-AI model for anomaly detection in time-series data, based on Variational Auto-Encoders (VAEs). By foundation, we mean a model pretrained on massive amounts of time-series data which can learn complex temporal patterns useful for accurate modeling, forecasting, and detection of anomalies on previously unseen datasets. FAE leverages VAEs and Dilated Convolutional Neural Networks (DCNNs) to build a generic model for univariate time-series modeling, which could eventually perform properly in out-of-the-box, zero-shot anomaly detection applications. We introduce the main concepts of FAE, and present preliminary results in different multi-dimensional time-series datasets from various domains, including a real dataset from an operational mobile ISP, and the well known KDD 2021 Anomaly Detection dataset.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at ACM KDD 2024, MiLeTS 2024 Workshop, August 25, 2024, Barcelona, Spain",
    "pdf_url": "https://arxiv.org/pdf/2507.01875v1",
    "published_date": "2025-07-02 16:39:36 UTC",
    "updated_date": "2025-07-02 16:39:36 UTC"
  },
  {
    "arxiv_id": "2507.01862v1",
    "title": "Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents",
    "authors": [
      "Sanjay Krishna Anbalagan",
      "Xinrui Nie",
      "Umesh Mohan",
      "Vijay Kumar Kanamarlapudi",
      "Anughna Kommalapati",
      "Xiaodan Zhao"
    ],
    "abstract": "Domain specific chatbot applications often involve multi step interactions, such as refining search filters, selecting multiple items, or performing comparisons. Traditional graphical user interfaces (GUIs) handle these workflows by providing explicit \"Submit\" (commit data) and \"Reset\" (discard data) actions, allowing back-end systems to track user intent unambiguously. In contrast, conversational agents rely on subtle language cues, which can lead to confusion and incomplete context management. This paper proposes modeling these GUI inspired metaphors acknowledgment (submit like) and context switching (reset-like) as explicit tasks within large language model (LLM) prompts. By capturing user acknowledgment, reset actions, and chain of thought (CoT) reasoning as structured session data, we preserve clarity, reduce user confusion, and align domain-specific chatbot interactions with back-end logic. We demonstrate our approach in hotel booking and customer management scenarios, highlighting improvements in multi-turn task coherence, user satisfaction, and efficiency.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "8 pages, 1 figure, pre-print of poster accepted for HCI International 2025 (HCII 2025), CCIS vol 2529",
    "pdf_url": "https://arxiv.org/pdf/2507.01862v1",
    "published_date": "2025-07-02 16:24:50 UTC",
    "updated_date": "2025-07-02 16:24:50 UTC"
  },
  {
    "arxiv_id": "2507.10559v2",
    "title": "NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research",
    "authors": [
      "Shomir Wilson"
    ],
    "abstract": "Recent developments in large language models (LLMs) have been accompanied by rapidly growing public interest in natural language processing (NLP). This attention is reflected by major news venues, which sometimes invite NLP researchers to share their knowledge and views with a wide audience. Recognizing the opportunities of the present, for both the research field and for individual researchers, this paper shares recommendations for communicating with a general audience about the capabilities and limitations of NLP. These recommendations cover three themes: vague terminology as an obstacle to public understanding, unreasonable expectations as obstacles to sustainable growth, and ethical failures as obstacles to continued support. Published NLP research and popular news coverage are cited to illustrate these themes with examples. The recommendations promote effective, transparent communication with the general public about NLP, in order to strengthen public understanding and encourage support for research.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "7 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.10559v2",
    "published_date": "2025-07-02 15:50:09 UTC",
    "updated_date": "2025-07-16 14:25:07 UTC"
  },
  {
    "arxiv_id": "2507.01833v1",
    "title": "Refining Gelfond Rationality Principle Towards More Comprehensive Foundational Principles for Answer Set Semantics",
    "authors": [
      "Yi-Dong Shen",
      "Thomas Eiter"
    ],
    "abstract": "Non-monotonic logic programming is the basis for a declarative problem solving paradigm known as answer set programming (ASP). Departing from the seminal definition by Gelfond and Lifschitz in 1988 for simple normal logic programs, various answer set semantics have been proposed for extensions. We consider two important questions: (1) Should the minimal model property, constraint monotonicity and foundedness as defined in the literature be mandatory conditions for an answer set semantics in general? (2) If not, what other properties could be considered as general principles for answer set semantics? We address the two questions. First, it seems that the three aforementioned conditions may sometimes be too strong, and we illustrate with examples that enforcing them may exclude expected answer sets. Second, we evolve the Gelfond answer set (GAS) principles for answer set construction by refining the Gelfond's rationality principle to well-supportedness, minimality w.r.t. negation by default and minimality w.r.t. epistemic negation. The principle of well-supportedness guarantees that every answer set is constructible from if-then rules obeying a level mapping and is thus free of circular justification, while the two minimality principles ensure that the formalism minimizes knowledge both at the level of answer sets and of world views. Third, to embody the refined GAS principles, we extend the notion of well-supportedness substantially to answer sets and world views, respectively. Fourth, we define new answer set semantics in terms of the refined GAS principles. Fifth, we use the refined GAS principles as an alternative baseline to intuitively assess the existing answer set semantics. Finally, we analyze the computational complexity.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "76 pages. This article is a significantly extended version of a paper presented by the authors at IJCAI-2022",
    "pdf_url": "https://arxiv.org/pdf/2507.01833v1",
    "published_date": "2025-07-02 15:47:54 UTC",
    "updated_date": "2025-07-02 15:47:54 UTC"
  },
  {
    "arxiv_id": "2507.01829v1",
    "title": "mGRADE: Minimal Recurrent Gating Meets Delay Convolutions for Lightweight Sequence Modeling",
    "authors": [
      "Tristan Torchet",
      "Christian Metzner",
      "Laura Kriener",
      "Melika Payvand"
    ],
    "abstract": "Edge devices for temporal processing demand models that capture both short- and long- range dynamics under tight memory constraints. While Transformers excel at sequence modeling, their quadratic memory scaling with sequence length makes them impractical for such settings. Recurrent Neural Networks (RNNs) offer constant memory but train sequentially, and Temporal Convolutional Networks (TCNs), though efficient, scale memory with kernel size. To address this, we propose mGRADE (mininally Gated Recurrent Architecture with Delay Embedding), a hybrid-memory system that integrates a temporal 1D-convolution with learnable spacings followed by a minimal gated recurrent unit (minGRU). This design allows the convolutional layer to realize a flexible delay embedding that captures rapid temporal variations, while the recurrent module efficiently maintains global context with minimal memory overhead. We validate our approach on two synthetic tasks, demonstrating that mGRADE effectively separates and preserves multi-scale temporal features. Furthermore, on challenging pixel-by-pixel image classification benchmarks, mGRADE consistently outperforms both pure convolutional and pure recurrent counterparts using approximately 20% less memory footprint, highlighting its suitability for memory-constrained temporal processing at the edge. This highlights mGRADE's promise as an efficient solution for memory-constrained multi-scale temporal processing at the edge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01829v1",
    "published_date": "2025-07-02 15:44:35 UTC",
    "updated_date": "2025-07-02 15:44:35 UTC"
  },
  {
    "arxiv_id": "2507.01825v1",
    "title": "MILP-SAT-GNN: Yet Another Neural SAT Solver",
    "authors": [
      "Franco Alberto Cardillo",
      "Hamza Khyari",
      "Umberto Straccia"
    ],
    "abstract": "We proposes a novel method that enables Graph Neural Networks (GNNs) to solve SAT problems by leveraging a technique developed for applying GNNs to Mixed Integer Linear Programming (MILP). Specifically, k-CNF formulae are mapped into MILP problems, which are then encoded as weighted bipartite graphs and subsequently fed into a GNN for training and testing. From a theoretical perspective: (i) we establish permutation and equivalence invariance results, demonstrating that the method produces outputs that are stable under reordering of clauses and variables; (ii) we identify a theoretical limitation, showing that for a class of formulae called foldable formulae, standard GNNs cannot always distinguish satisfiable from unsatisfiable instances; (iii) we prove a universal approximation theorem, establishing that with Random Node Initialization (RNI), the method can approximate SAT solving to arbitrary precision on finite datasets, that is, the GNN becomes approximately sound and complete on such datasets. Furthermore, we show that for unfoldable formulae, the same approximation guarantee can be achieved without the need for RNI. Finally, we conduct an experimental evaluation of our approach, which show that, despite the simplicity of the neural architecture, the method achieves promising results.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01825v1",
    "published_date": "2025-07-02 15:39:45 UTC",
    "updated_date": "2025-07-02 15:39:45 UTC"
  },
  {
    "arxiv_id": "2507.21098v1",
    "title": "Artificial intelligence for sustainable wine industry: AI-driven management in viticulture, wine production and enotourism",
    "authors": [
      "Marta Sidorkiewicz",
      "Karolina Królikowska",
      "Berenika Dyczek",
      "Edyta Pijet-Migon",
      "Anna Dubel"
    ],
    "abstract": "This study examines the role of Artificial Intelligence (AI) in enhancing sustainability and efficiency within the wine industry. It focuses on AI-driven intelligent management in viticulture, wine production, and enotourism. As the wine industry faces environmental and economic challenges, AI offers innovative solutions to optimize resource use, reduce environmental impact, and improve customer engagement. Understanding AI's potential in sustainable winemaking is crucial for fostering responsible and efficient industry practices. The research is based on a questionnaire survey conducted among Polish winemakers, combined with a comprehensive analysis of AI methods applicable to viticulture, production, and tourism. Key AI technologies, including predictive analytics, machine learning, and computer vision, are explored. The findings indicate that AI enhances vineyard monitoring, optimizes irrigation, and streamlines production processes, contributing to sustainable resource management. In enotourism, AI-powered chatbots, recommendation systems, and virtual tastings personalize consumer experiences. The study highlights AI's impact on economic, environmental, and social sustainability, supporting local wine enterprises and cultural heritage. Keywords: Artificial Intelligence, Sustainable Development, AI-Driven Management, Viticulture, Wine Production, Enotourism, Wine Enterprises, Local Communities",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 4 figures. Accepted for presentation at the 27th European Conference on Artificial Intelligence (ECAI 2025), October 19-24, 2025, Bologna, Italy",
    "pdf_url": "https://arxiv.org/pdf/2507.21098v1",
    "published_date": "2025-07-02 15:26:13 UTC",
    "updated_date": "2025-07-02 15:26:13 UTC"
  },
  {
    "arxiv_id": "2507.01808v1",
    "title": "Empowering Manufacturers with Privacy-Preserving AI Tools: A Case Study in Privacy-Preserving Machine Learning to Solve Real-World Problems",
    "authors": [
      "Xiaoyu Ji",
      "Jessica Shorland",
      "Joshua Shank",
      "Pascal Delpe-Brice",
      "Latanya Sweeney",
      "Jan Allebach",
      "Ali Shakouri"
    ],
    "abstract": "Small- and medium-sized manufacturers need innovative data tools but, because of competition and privacy concerns, often do not want to share their proprietary data with researchers who might be interested in helping. This paper introduces a privacy-preserving platform by which manufacturers may safely share their data with researchers through secure methods, so that those researchers then create innovative tools to solve the manufacturers' real-world problems, and then provide tools that execute solutions back onto the platform for others to use with privacy and confidentiality guarantees. We illustrate this problem through a particular use case which addresses an important problem in the large-scale manufacturing of food crystals, which is that quality control relies on image analysis tools. Previous to our research, food crystals in the images were manually counted, which required substantial and time-consuming human efforts, but we have developed and deployed a crystal analysis tool which makes this process both more rapid and accurate. The tool enables automatic characterization of the crystal size distribution and numbers from microscope images while the natural imperfections from the sample preparation are automatically removed; a machine learning model to count high resolution translucent crystals and agglomeration of crystals was also developed to aid in these efforts. The resulting algorithm was then packaged for real-world use on the factory floor via a web-based app secured through the originating privacy-preserving platform, allowing manufacturers to use it while keeping their proprietary data secure. After demonstrating this full process, future directions are also explored.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.ET"
    ],
    "primary_category": "cs.CR",
    "comment": "20 pages, 11 figures, 30 references",
    "pdf_url": "https://arxiv.org/pdf/2507.01808v1",
    "published_date": "2025-07-02 15:25:43 UTC",
    "updated_date": "2025-07-02 15:25:43 UTC"
  },
  {
    "arxiv_id": "2507.01806v1",
    "title": "LoRA Fine-Tuning Without GPUs: A CPU-Efficient Meta-Generation Framework for LLMs",
    "authors": [
      "Reza Arabpour",
      "Haitz Sáez de Ocáriz Borde",
      "Anastasis Kratsios"
    ],
    "abstract": "Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large Language Models (LLMs) by enabling parameter-efficient updates. However, their widespread adoption remains limited by the reliance on GPU-based training. In this work, we propose a theoretically grounded approach to LoRA fine-tuning designed specifically for users with limited computational resources, particularly those restricted to standard laptop CPUs. Our method learns a meta-operator that maps any input dataset, represented as a probability distribution, to a set of LoRA weights by leveraging a large bank of pre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead of performing new gradient-based updates, our pipeline constructs adapters via lightweight combinations of existing LoRAs directly on CPU. While the resulting adapters do not match the performance of GPU-trained counterparts, they consistently outperform the base Mistral model on downstream tasks, offering a practical and accessible alternative to traditional GPU-based fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "5-page main paper (excluding references) + 11-page appendix, 3 tables, 1 figure. Accepted to ICML 2025 Workshop on Efficient Systems for Foundation Models",
    "pdf_url": "https://arxiv.org/pdf/2507.01806v1",
    "published_date": "2025-07-02 15:24:47 UTC",
    "updated_date": "2025-07-02 15:24:47 UTC"
  },
  {
    "arxiv_id": "2507.01790v1",
    "title": "How Do Vision-Language Models Process Conflicting Information Across Modalities?",
    "authors": [
      "Tianze Hua",
      "Tian Yun",
      "Ellie Pavlick"
    ],
    "abstract": "AI models are increasingly required to be multimodal, integrating disparate input streams into a coherent state representation on which subsequent behaviors and actions can be based. This paper seeks to understand how such models behave when input streams present conflicting information. Focusing specifically on vision-language models, we provide inconsistent inputs (e.g., an image of a dog paired with the caption \"A photo of a cat\") and ask the model to report the information present in one of the specific modalities (e.g., \"What does the caption say / What is in the image?\"). We find that models often favor one modality over the other, e.g., reporting the image regardless of what the caption says, but that different models differ in which modality they favor. We find evidence that the behaviorally preferred modality is evident in the internal representational structure of the model, and that specific attention heads can restructure the representations to favor one modality over the other. Moreover, we find modality-agnostic \"router heads\" which appear to promote answers about the modality requested in the instruction, and which can be manipulated or transferred in order to improve performance across datasets and modalities. Together, the work provides essential steps towards identifying and controlling if and how models detect and resolve conflicting signals within complex multimodal environments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "All code and resources are available at: https://github.com/ethahtz/vlm_conflicting_info_processing",
    "pdf_url": "https://arxiv.org/pdf/2507.01790v1",
    "published_date": "2025-07-02 15:15:14 UTC",
    "updated_date": "2025-07-02 15:15:14 UTC"
  },
  {
    "arxiv_id": "2507.01788v2",
    "title": "Are Vision Transformer Representations Semantically Meaningful? A Case Study in Medical Imaging",
    "authors": [
      "Montasir Shams",
      "Chashi Mahiul Islam",
      "Shaeke Salman",
      "Phat Tran",
      "Xiuwen Liu"
    ],
    "abstract": "Vision transformers (ViTs) have rapidly gained prominence in medical imaging tasks such as disease classification, segmentation, and detection due to their superior accuracy compared to conventional deep learning models. However, due to their size and complex interactions via the self-attention mechanism, they are not well understood. In particular, it is unclear whether the representations produced by such models are semantically meaningful. In this paper, using a projected gradient-based algorithm, we show that their representations are not semantically meaningful and they are inherently vulnerable to small changes. Images with imperceptible differences can have very different representations; on the other hand, images that should belong to different semantic classes can have nearly identical representations. Such vulnerability can lead to unreliable classification results; for example, unnoticeable changes cause the classification accuracy to be reduced by over 60\\%. %. To the best of our knowledge, this is the first work to systematically demonstrate this fundamental lack of semantic meaningfulness in ViT representations for medical image classification, revealing a critical challenge for their deployment in safety-critical systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.01788v2",
    "published_date": "2025-07-02 15:14:06 UTC",
    "updated_date": "2025-07-10 16:23:29 UTC"
  },
  {
    "arxiv_id": "2507.01786v2",
    "title": "Probing and Steering Evaluation Awareness of Language Models",
    "authors": [
      "Jord Nguyen",
      "Khiem Hoang",
      "Carlo Leonardo Attubato",
      "Felix Hofstätter"
    ],
    "abstract": "Language models can distinguish between testing and deployment phases -- a capability known as evaluation awareness. This has significant safety and policy implications, potentially undermining the reliability of evaluations that are central to AI governance frameworks and voluntary industry commitments. In this paper, we study evaluation awareness in Llama-3.3-70B-Instruct. We show that linear probes can separate real-world evaluation and deployment prompts, suggesting that current models internally represent this distinction. We also find that current safety evaluations are correctly classified by the probes, suggesting that they already appear artificial or inauthentic to models. Our findings underscore the importance of ensuring trustworthy evaluations and understanding deceptive capabilities. More broadly, our work showcases how model internals may be leveraged to support blackbox methods in safety audits, especially for future models more competent at evaluation awareness and deception.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Actionable Interpretability Workshop (Poster) and Workshop on Technical AI Governance (Poster) at ICML 2025, Vancouver, Canada",
    "pdf_url": "https://arxiv.org/pdf/2507.01786v2",
    "published_date": "2025-07-02 15:12:43 UTC",
    "updated_date": "2025-07-09 08:46:58 UTC"
  },
  {
    "arxiv_id": "2507.01785v2",
    "title": "MuRating: A High Quality Data Selecting Approach to Multilingual Large Language Model Pretraining",
    "authors": [
      "Zhixun Chen",
      "Ping Guo",
      "Wenhan Han",
      "Yifan Zhang",
      "Binbin Liu",
      "Haobin Lin",
      "Fengze Liu",
      "Yan Zhao",
      "Bingni Zhang",
      "Taifeng Wang",
      "Yin Zheng",
      "Meng Fang"
    ],
    "abstract": "Data quality is a critical driver of large language model performance, yet existing model-based selection methods focus almost exclusively on English. We introduce MuRating, a scalable framework that transfers high-quality English data-quality signals into a single rater for 17 target languages. MuRating aggregates multiple English \"raters\" via pairwise comparisons to learn unified document-quality scores,then projects these judgments through translation to train a multilingual evaluator on monolingual, cross-lingual, and parallel text pairs. Applied to web data, MuRating selects balanced subsets of English and multilingual content to pretrain a 1.2 B-parameter LLaMA model. Compared to strong baselines, including QuRater, AskLLM, DCLM and so on, our approach boosts average accuracy on both English benchmarks and multilingual evaluations, with especially large gains on knowledge-intensive tasks. We further analyze translation fidelity, selection biases, and underrepresentation of narrative material, outlining directions for future work.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2025 poster",
    "pdf_url": "https://arxiv.org/pdf/2507.01785v2",
    "published_date": "2025-07-02 15:11:12 UTC",
    "updated_date": "2025-12-30 08:00:04 UTC"
  },
  {
    "arxiv_id": "2507.01781v1",
    "title": "BranchNet: A Neuro-Symbolic Learning Framework for Structured Multi-Class Classification",
    "authors": [
      "Dalia Rodríguez-Salas",
      "Christian Riess"
    ],
    "abstract": "We introduce BranchNet, a neuro-symbolic learning framework that transforms decision tree ensembles into sparse, partially connected neural networks. Each branch, defined as a decision path from root to a parent of leaves, is mapped to a hidden neuron, preserving symbolic structure while enabling gradient-based optimization. The resulting models are compact, interpretable, and require no manual architecture tuning. Evaluated on a suite of structured multi-class classification benchmarks, BranchNet consistently outperforms XGBoost in accuracy, with statistically significant gains. We detail the architecture, training procedure, and sparsity dynamics, and discuss the model's strengths in symbolic interpretability as well as its current limitations, particularly on binary tasks where further adaptive calibration may be beneficial.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 3 figures (with two images each)",
    "pdf_url": "https://arxiv.org/pdf/2507.01781v1",
    "published_date": "2025-07-02 15:07:58 UTC",
    "updated_date": "2025-07-02 15:07:58 UTC"
  },
  {
    "arxiv_id": "2507.01770v3",
    "title": "GPU-based complete search for nonlinear minimization subject to bounds",
    "authors": [
      "Guanglu Zhang",
      "Qihang Shan",
      "Jonathan Cagan"
    ],
    "abstract": "This paper introduces a GPU-based complete search method to enclose the global minimum of a nonlinear function subject to simple bounds on the variables. Using interval analysis, coupled with the computational power and architecture of GPU, the method iteratively rules out the regions in the search domain where the global minimum cannot exist and leaves a finite set of regions where the global minimum must exist. For effectiveness, because of the rigor of interval analysis, the method is guaranteed to enclose the global minimum of the nonlinear function even in the presence of rounding errors. For efficiency, the method employs a novel GPU-based single program, single data parallel programming style to circumvent major GPU performance bottlenecks, and a variable cycling technique is also integrated into the method to reduce computational cost when minimizing large-scale nonlinear functions. The method is validated by minimizing 10 multimodal benchmark test functions with scalable dimensions, including the well-known Ackley function, Griewank function, Levy function, and Rastrigin function. These benchmark test functions represent grand challenges of global optimization, and enclosing the guaranteed global minimum of these benchmark test functions with more than 80 dimensions has not been reported in the literature. Our method completely searches the feasible domain and successfully encloses the guaranteed global minimum of these 10 benchmark test functions with up to 10,000 dimensions using only one GPU in a reasonable computation time, far exceeding the reported results in the literature due to the unique method design and implementation based on GPU architecture.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.DC",
      "cs.MS",
      "math.OC"
    ],
    "primary_category": "math.NA",
    "comment": "36 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.01770v3",
    "published_date": "2025-07-02 14:54:52 UTC",
    "updated_date": "2026-01-08 20:50:38 UTC"
  },
  {
    "arxiv_id": "2507.01761v2",
    "title": "Enhanced Generative Model Evaluation with Clipped Density and Coverage",
    "authors": [
      "Nicolas Salvy",
      "Hugues Talbot",
      "Bertrand Thirion"
    ],
    "abstract": "Although generative models have made remarkable progress in recent years, their use in critical applications has been hindered by an inability to reliably evaluate the quality of their generated samples. Quality refers to at least two complementary concepts: fidelity and coverage. Current quality metrics often lack reliable, interpretable values due to an absence of calibration or insufficient robustness to outliers. To address these shortcomings, we introduce two novel metrics: Clipped Density and Clipped Coverage. By clipping individual sample contributions, as well as the radii of nearest neighbor balls for fidelity, our metrics prevent out-of-distribution samples from biasing the aggregated values. Through analytical and empirical calibration, these metrics demonstrate linear score degradation as the proportion of bad samples increases. Thus, they can be straightforwardly interpreted as equivalent proportions of good samples. Extensive experiments on synthetic and real-world datasets demonstrate that Clipped Density and Clipped Coverage outperform existing methods in terms of robustness, sensitivity, and interpretability when evaluating generative models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01761v2",
    "published_date": "2025-07-02 14:40:00 UTC",
    "updated_date": "2025-09-25 09:04:10 UTC"
  },
  {
    "arxiv_id": "2507.01752v3",
    "title": "Tuning without Peeking: Provable Generalization Bounds and Robust LLM Post-Training",
    "authors": [
      "Ismail Labiad",
      "Mathurin Videau",
      "Matthieu Kowalski",
      "Marc Schoenauer",
      "Alessandro Leite",
      "Julia Kempe",
      "Olivier Teytaud"
    ],
    "abstract": "Gradient-based optimization is the workhorse of deep learning, offering efficient and scalable training via backpropagation. However, exposing gradients during training can leak sensitive information about the underlying data, raising privacy and security concerns such as susceptibility to data poisoning attacks. In contrast, black box optimization methods, which treat the model as an opaque function, relying solely on function evaluations to guide optimization, offer a promising alternative in scenarios where data access is restricted, adversarial risks are high, or overfitting is a concern. This paper introduces BBoxER, an evolutionary black-box method for LLM post-training that induces an information bottleneck via implicit compression of the training data. Leveraging the tractability of information flow, we provide non-vacuous generalization bounds and strong theoretical guarantees for privacy, robustness to data poisoning attacks, and extraction attacks. In experiments with LLMs, we demonstrate empirically that black-box optimization methods, despite the scalability and computational challenges inherent to black-box approaches, are able to learn, showing how a few iterations of BBoxER improve performance, generalize well on a benchmark of reasoning datasets, and are robust to membership inference attacks. This positions BBoxER as an attractive add-on on top of gradient-based optimization, offering suitability for deployment in restricted or privacy-sensitive environments while also providing non-vacuous generalization guarantees.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01752v3",
    "published_date": "2025-07-02 14:29:30 UTC",
    "updated_date": "2026-01-05 16:10:09 UTC"
  },
  {
    "arxiv_id": "2507.01749v1",
    "title": "Joint Matching and Pricing for Crowd-shipping with In-store Customers",
    "authors": [
      "Arash Dehghan",
      "Mucahit Cevik",
      "Merve Bodur",
      "Bissan Ghaddar"
    ],
    "abstract": "This paper examines the use of in-store customers as delivery couriers in a centralized crowd-shipping system, targeting the growing need for efficient last-mile delivery in urban areas. We consider a brick-and-mortar retail setting where shoppers are offered compensation to deliver time-sensitive online orders. To manage this process, we propose a Markov Decision Process (MDP) model that captures key uncertainties, including the stochastic arrival of orders and crowd-shippers, and the probabilistic acceptance of delivery offers. Our solution approach integrates Neural Approximate Dynamic Programming (NeurADP) for adaptive order-to-shopper assignment with a Deep Double Q-Network (DDQN) for dynamic pricing. This joint optimization strategy enables multi-drop routing and accounts for offer acceptance uncertainty, aligning more closely with real-world operations. Experimental results demonstrate that the integrated NeurADP + DDQN policy achieves notable improvements in delivery cost efficiency, with up to 6.7\\% savings over NeurADP with fixed pricing and approximately 18\\% over myopic baselines. We also show that allowing flexible delivery delays and enabling multi-destination routing further reduces operational costs by 8\\% and 17\\%, respectively. These findings underscore the advantages of dynamic, forward-looking policies in crowd-shipping systems and offer practical guidance for urban logistics operators.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01749v1",
    "published_date": "2025-07-02 14:27:32 UTC",
    "updated_date": "2025-07-02 14:27:32 UTC"
  },
  {
    "arxiv_id": "2507.01735v1",
    "title": "ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving",
    "authors": [
      "Kai Chen",
      "Ruiyuan Gao",
      "Lanqing Hong",
      "Hang Xu",
      "Xu Jia",
      "Holger Caesar",
      "Dengxin Dai",
      "Bingbing Liu",
      "Dzmitry Tsishkou",
      "Songcen Xu",
      "Chunjing Xu",
      "Qiang Xu",
      "Huchuan Lu",
      "Dit-Yan Yeung"
    ],
    "abstract": "In this paper, we present details of the 1st W-CODA workshop, held in conjunction with the ECCV 2024. W-CODA aims to explore next-generation solutions for autonomous driving corner cases, empowered by state-of-the-art multimodal perception and comprehension techniques. 5 Speakers from both academia and industry are invited to share their latest progress and opinions. We collect research papers and hold a dual-track challenge, including both corner case scene understanding and generation. As the pioneering effort, we will continuously bridge the gap between frontier autonomous driving techniques and fully intelligent, reliable self-driving agents robust towards corner cases.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024. Workshop page: https://coda-dataset.github.io/w-coda2024/",
    "pdf_url": "https://arxiv.org/pdf/2507.01735v1",
    "published_date": "2025-07-02 14:10:25 UTC",
    "updated_date": "2025-07-02 14:10:25 UTC"
  },
  {
    "arxiv_id": "2507.02018v1",
    "title": "NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction",
    "authors": [
      "Yingjie Niu",
      "Mingchuan Zhao",
      "Valerio Poti",
      "Ruihai Dong"
    ],
    "abstract": "Graph representation learning methods have been widely adopted in financial applications to enhance company representations by leveraging inter-firm relationships. However, current approaches face three key challenges: (1) The advantages of relational information are obscured by limitations in downstream task designs; (2) Existing graph models specifically designed for stock prediction often suffer from excessive complexity and poor generalization; (3) Experience-based construction of corporate relationship graphs lacks effective comparison of different graph structures. To address these limitations, we propose a long-term stock prediction task and develop a Node-level Graph Attention Network (NGAT) specifically tailored for corporate relationship graphs. Furthermore, we experimentally demonstrate the limitations of existing graph comparison methods based on model downstream task performance. Experimental results across two datasets consistently demonstrate the effectiveness of our proposed task and model. The project is publicly available on GitHub to encourage reproducibility and future research.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02018v1",
    "published_date": "2025-07-02 13:59:46 UTC",
    "updated_date": "2025-07-02 13:59:46 UTC"
  },
  {
    "arxiv_id": "2507.01719v1",
    "title": "Towards culturally-appropriate conversational AI for health in the majority world: An exploratory study with citizens and professionals in Latin America",
    "authors": [
      "Dorian Peters",
      "Fernanda Espinoza",
      "Marco da Re",
      "Guido Ivetta",
      "Luciana Benotti",
      "Rafael A. Calvo"
    ],
    "abstract": "There is justifiable interest in leveraging conversational AI (CAI) for health across the majority world, but to be effective, CAI must respond appropriately within culturally and linguistically diverse contexts. Therefore, we need ways to address the fact that current LLMs exclude many lived experiences globally. Various advances are underway which focus on top-down approaches and increasing training data. In this paper, we aim to complement these with a bottom-up locally-grounded approach based on qualitative data collected during participatory workshops in Latin America. Our goal is to construct a rich and human-centred understanding of: a) potential areas of cultural misalignment in digital health; b) regional perspectives on chatbots for health and c)strategies for creating culturally-appropriate CAI; with a focus on the understudied Latin American context. Our findings show that academic boundaries on notions of culture lose meaning at the ground level and technologies will need to engage with a broader framework; one that encapsulates the way economics, politics, geography and local logistics are entangled in cultural experience. To this end, we introduce a framework for 'Pluriversal Conversational AI for Health' which allows for the possibility that more relationality and tolerance, rather than just more data, may be called for.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01719v1",
    "published_date": "2025-07-02 13:48:25 UTC",
    "updated_date": "2025-07-02 13:48:25 UTC"
  },
  {
    "arxiv_id": "2507.01717v1",
    "title": "Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI",
    "authors": [
      "Gopichand Kanumolu",
      "Ashok Urlana",
      "Charaka Vinayak Kumar",
      "Bala Mallikarjunarao Garlapati"
    ],
    "abstract": "Patents contain rich technical knowledge that can inspire innovative product ideas, yet accessing and interpreting this information remains a challenge. This work explores the use of Large Language Models (LLMs) and autonomous agents to mine and generate product concepts from a given patent. In this work, we design Agent Ideate, a framework for automatically generating product-based business ideas from patents. We experimented with open-source LLMs and agent-based architectures across three domains: Computer Science, Natural Language Processing, and Material Chemistry. Evaluation results show that the agentic approach consistently outperformed standalone LLMs in terms of idea quality, relevance, and novelty. These findings suggest that combining LLMs with agentic workflows can significantly enhance the innovation pipeline by unlocking the untapped potential of business idea generation from patent data.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "AgentScen Workshop, IJCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.01717v1",
    "published_date": "2025-07-02 13:47:17 UTC",
    "updated_date": "2025-07-02 13:47:17 UTC"
  },
  {
    "arxiv_id": "2507.01702v1",
    "title": "AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness",
    "authors": [
      "Zixin Chen",
      "Hongzhan Lin",
      "Kaixin Li",
      "Ziyang Luo",
      "Zhen Ye",
      "Guang Chen",
      "Zhiyong Huang",
      "Jing Ma"
    ],
    "abstract": "The proliferation of multimodal memes in the social media era demands that multimodal Large Language Models (mLLMs) effectively understand meme harmfulness. Existing benchmarks for assessing mLLMs on harmful meme understanding rely on accuracy-based, model-agnostic evaluations using static datasets. These benchmarks are limited in their ability to provide up-to-date and thorough assessments, as online memes evolve dynamically. To address this, we propose AdamMeme, a flexible, agent-based evaluation framework that adaptively probes the reasoning capabilities of mLLMs in deciphering meme harmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive evaluations by iteratively updating the meme data with challenging samples, thereby exposing specific limitations in how mLLMs interpret harmfulness. Extensive experiments show that our framework systematically reveals the varying performance of different target mLLMs, offering in-depth, fine-grained analyses of model-specific weaknesses. Our code is available at https://github.com/Lbotirx/AdamMeme.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.01702v1",
    "published_date": "2025-07-02 13:32:30 UTC",
    "updated_date": "2025-07-02 13:32:30 UTC"
  },
  {
    "arxiv_id": "2507.01701v1",
    "title": "Exploring Advanced LLM Multi-Agent Systems Based on Blackboard Architecture",
    "authors": [
      "Bochen Han",
      "Songmao Zhang"
    ],
    "abstract": "In this paper, we propose to incorporate the blackboard architecture into LLM multi-agent systems (MASs) so that (1) agents with various roles can share all the information and others' messages during the whole problem-solving process, (2) agents that will take actions are selected based on the current content of the blackboard, and (3) the selection and execution round is repeated until a consensus is reached on the blackboard. We develop the first implementation of this proposal and conduct experiments on commonsense knowledge, reasoning and mathematical datasets. The results show that our system can be competitive with the SOTA static and dynamic MASs by achieving the best average performance, and at the same time manage to spend less tokens. Our proposal has the potential to enable complex and dynamic problem-solving where well-defined structures or workflows are unavailable.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01701v1",
    "published_date": "2025-07-02 13:30:44 UTC",
    "updated_date": "2025-07-02 13:30:44 UTC"
  },
  {
    "arxiv_id": "2507.01700v2",
    "title": "Relational Causal Discovery with Latent Confounders",
    "authors": [
      "Matteo Negro",
      "Andrea Piras",
      "Ragib Ahsan",
      "David Arbour",
      "Elena Zheleva"
    ],
    "abstract": "Estimating causal effects from real-world relational data can be challenging when the underlying causal model and potential confounders are unknown. While several causal discovery algorithms exist for learning causal models with latent confounders from data, they assume that the data is independent and identically distributed (i.i.d.) and are not well-suited for learning from relational data. Similarly, existing relational causal discovery algorithms assume causal sufficiency, which is unrealistic for many real-world datasets. To address this gap, we propose RelFCI, a sound and complete causal discovery algorithm for relational data with latent confounders. Our work builds upon the Fast Causal Inference (FCI) and Relational Causal Discovery (RCD) algorithms and it defines new graphical models, necessary to support causal discovery in relational domains. We also establish soundness and completeness guarantees for relational d-separation with latent confounders. We present experimental results demonstrating the effectiveness of RelFCI in identifying the correct causal structure in relational causal models with latent confounders.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 19 figures. Accepted for publication at the 41st Conference on Uncertainty in Artificial Intelligence (UAI 2025). Andrea Piras and Matteo Negro contributed equally to this work",
    "pdf_url": "https://arxiv.org/pdf/2507.01700v2",
    "published_date": "2025-07-02 13:29:35 UTC",
    "updated_date": "2025-11-03 21:27:56 UTC"
  },
  {
    "arxiv_id": "2507.01693v2",
    "title": "GPT, But Backwards: Exactly Inverting Language Model Outputs",
    "authors": [
      "Adrians Skapars",
      "Edoardo Manino",
      "Youcheng Sun",
      "Lucas C. Cordeiro"
    ],
    "abstract": "The task of reconstructing unknown textual inputs to language models is a fundamental auditing primitive that allows us to assess the model's vulnerability to a range of security issues, including stealing hidden system prompts, detecting backdoors, and leaking private data. Existing inversion works assume access to differing levels of information (e.g. requiring input-output examples, the model parameters, intermediate activations or output logits) but oftentimes fail to fully reconstruct the desired input. In this paper, we present the Sparse One-hot Discrete Adam (SODA) algorithm, a search-based inversion method that can accurately reconstruct the input text, given white-box access to the language model and its output. Our experiments demonstrate for the first time that exact language model inversion is possible on both natural language and random inputs. Indeed, SODA achieves respectively 98% and 79% reconstruction rates on inputs with lengths up to 10 tokens. Furthermore, we show that input length and vocabulary size have a far greater impact on the probability of a successful reconstruction than the size of the language model itself, thus allowing us to scale to models from 33M to 3B parameters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, ICML 2025 Workshop on Reliable and Responsible Foundation Models",
    "pdf_url": "https://arxiv.org/pdf/2507.01693v2",
    "published_date": "2025-07-02 13:20:30 UTC",
    "updated_date": "2025-11-10 15:40:58 UTC"
  },
  {
    "arxiv_id": "2507.01679v2",
    "title": "Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling",
    "authors": [
      "Zeyu Huang",
      "Tianhao Cheng",
      "Zihan Qiu",
      "Zili Wang",
      "Yinghui Xu",
      "Edoardo M. Ponti",
      "Ivan Titov"
    ],
    "abstract": "Existing post-training techniques for large language models are broadly categorized into Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT). Each paradigm presents a distinct trade-off: SFT excels at mimicking demonstration data but can lead to problematic generalization as a form of behavior cloning. Conversely, RFT can significantly enhance a model's performance but is prone to learn unexpected behaviors, and its performance is highly sensitive to the initial policy. In this paper, we propose a unified view of these methods and introduce Prefix-RFT, a hybrid approach that synergizes learning from both demonstration and exploration. Using mathematical reasoning problems as a testbed, we empirically demonstrate that Prefix-RFT is both simple and effective. It not only surpasses the performance of standalone SFT and RFT but also outperforms parallel mixed-policy RFT methods. A key advantage is its seamless integration into existing open-source frameworks, requiring only minimal modifications to the standard RFT pipeline. Our analysis highlights the complementary nature of SFT and RFT, and validates that Prefix-RFT effectively harmonizes these two learning paradigms. Furthermore, ablation studies confirm the method's robustness to variations in the quality and quantity of demonstration data. We hope this work offers a new perspective on LLM post-training, suggesting that a unified paradigm that judiciously integrates demonstration and exploration could be a promising direction for future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Work in progress",
    "pdf_url": "https://arxiv.org/pdf/2507.01679v2",
    "published_date": "2025-07-02 13:04:09 UTC",
    "updated_date": "2025-09-24 21:01:35 UTC"
  },
  {
    "arxiv_id": "2507.01676v1",
    "title": "Deep Recommender Models Inference: Automatic Asymmetric Data Flow Optimization",
    "authors": [
      "Giuseppe Ruggeri",
      "Renzo Andri",
      "Daniele Jahier Pagliari",
      "Lukas Cavigelli"
    ],
    "abstract": "Deep Recommender Models (DLRMs) inference is a fundamental AI workload accounting for more than 79% of the total AI workload in Meta's data centers. DLRMs' performance bottleneck is found in the embedding layers, which perform many random memory accesses to retrieve small embedding vectors from tables of various sizes. We propose the design of tailored data flows to speedup embedding look-ups. Namely, we propose four strategies to look up an embedding table effectively on one core, and a framework to automatically map the tables asymmetrically to the multiple cores of a SoC. We assess the effectiveness of our method using the Huawei Ascend AI accelerators, comparing it with the default Ascend compiler, and we perform high-level comparisons with Nvidia A100. Results show a speed-up varying from 1.5x up to 6.5x for real workload distributions, and more than 20x for extremely unbalanced distributions. Furthermore, the method proves to be much more independent of the query distribution than the baseline.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.AR",
      "cs.IR"
    ],
    "primary_category": "cs.DC",
    "comment": "5 pages, 4 figures, conference: IEEE ICCD24",
    "pdf_url": "https://arxiv.org/pdf/2507.01676v1",
    "published_date": "2025-07-02 13:00:39 UTC",
    "updated_date": "2025-07-02 13:00:39 UTC"
  },
  {
    "arxiv_id": "2507.01668v1",
    "title": "Comparing Optimization Algorithms Through the Lens of Search Behavior Analysis",
    "authors": [
      "Gjorgjina Cenikj",
      "Gašper Petelin",
      "Tome Eftimov"
    ],
    "abstract": "The field of numerical optimization has recently seen a surge in the development of \"novel\" metaheuristic algorithms, inspired by metaphors derived from natural or human-made processes, which have been widely criticized for obscuring meaningful innovations and failing to distinguish themselves from existing approaches. Aiming to address these concerns, we investigate the applicability of statistical tests for comparing algorithms based on their search behavior. We utilize the cross-match statistical test to compare multivariate distributions and assess the solutions produced by 114 algorithms from the MEALPY library. These findings are incorporated into an empirical analysis aiming to identify algorithms with similar search behaviors.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01668v1",
    "published_date": "2025-07-02 12:51:27 UTC",
    "updated_date": "2025-07-02 12:51:27 UTC"
  },
  {
    "arxiv_id": "2507.01663v1",
    "title": "AsyncFlow: An Asynchronous Streaming RL Framework for Efficient LLM Post-Training",
    "authors": [
      "Zhenyu Han",
      "Ansheng You",
      "Haibo Wang",
      "Kui Luo",
      "Guang Yang",
      "Wenqi Shi",
      "Menglong Chen",
      "Sicheng Zhang",
      "Zeshun Lan",
      "Chunshi Deng",
      "Huazhong Ji",
      "Wenjie Liu",
      "Yu Huang",
      "Yixiang Zhang",
      "Chenyi Pan",
      "Jing Wang",
      "Xin Huang",
      "Chunsheng Li",
      "Jianping Wu"
    ],
    "abstract": "Reinforcement learning (RL) has become a pivotal technology in the post-training phase of large language models (LLMs). Traditional task-colocated RL frameworks suffer from significant scalability bottlenecks, while task-separated RL frameworks face challenges in complex dataflows and the corresponding resource idling and workload imbalance. Moreover, most existing frameworks are tightly coupled with LLM training or inference engines, making it difficult to support custom-designed engines. To address these challenges, we propose AsyncFlow, an asynchronous streaming RL framework for efficient post-training. Specifically, we introduce a distributed data storage and transfer module that provides a unified data management and fine-grained scheduling capability in a fully streamed manner. This architecture inherently facilitates automated pipeline overlapping among RL tasks and dynamic load balancing. Moreover, we propose a producer-consumer-based asynchronous workflow engineered to minimize computational idleness by strategically deferring parameter update process within staleness thresholds. Finally, the core capability of AsynFlow is architecturally decoupled from underlying training and inference engines and encapsulated by service-oriented user interfaces, offering a modular and customizable user experience. Extensive experiments demonstrate an average of 1.59 throughput improvement compared with state-of-the-art baseline. The presented architecture in this work provides actionable insights for next-generation RL training system designs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01663v1",
    "published_date": "2025-07-02 12:45:34 UTC",
    "updated_date": "2025-07-02 12:45:34 UTC"
  },
  {
    "arxiv_id": "2507.01652v1",
    "title": "Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective",
    "authors": [
      "Yuxin Mao",
      "Zhen Qin",
      "Jinxing Zhou",
      "Hui Deng",
      "Xuyang Shen",
      "Bin Fan",
      "Jing Zhang",
      "Yiran Zhong",
      "Yuchao Dai"
    ],
    "abstract": "Autoregressive (AR) models have garnered significant attention in image generation for their ability to effectively capture both local and global structures within visual data. However, prevalent AR models predominantly rely on the transformer architectures, which are beset by quadratic computational complexity concerning input sequence length and substantial memory overhead due to the necessity of maintaining key-value caches. Although linear attention mechanisms have successfully reduced this burden in language models, our initial experiments reveal that they significantly degrade image generation quality because of their inability to capture critical long-range dependencies in visual data. We propose Linear Attention with Spatial-Aware Decay (LASAD), a novel attention mechanism that explicitly preserves genuine 2D spatial relationships within the flattened image sequences by computing position-dependent decay factors based on true 2D spatial location rather than 1D sequence positions. Based on this mechanism, we present LASADGen, an autoregressive image generator that enables selective attention to relevant spatial contexts with linear complexity. Experiments on ImageNet show LASADGen achieves state-of-the-art image generation performance and computational efficiency, bridging the gap between linear attention's efficiency and spatial understanding needed for high-quality generation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01652v1",
    "published_date": "2025-07-02 12:27:06 UTC",
    "updated_date": "2025-07-02 12:27:06 UTC"
  },
  {
    "arxiv_id": "2507.01649v2",
    "title": "GradMetaNet: An Equivariant Architecture for Learning on Gradients",
    "authors": [
      "Yoav Gelberg",
      "Yam Eitan",
      "Aviv Navon",
      "Aviv Shamsian",
      "Theo",
      "Putterman",
      "Michael Bronstein",
      "Haggai Maron"
    ],
    "abstract": "Gradients of neural networks encode valuable information for optimization, editing, and analysis of models. Therefore, practitioners often treat gradients as inputs to task-specific algorithms, e.g. for pruning or optimization. Recent works explore learning algorithms that operate directly on gradients but use architectures that are not specifically designed for gradient processing, limiting their applicability. In this paper, we present a principled approach for designing architectures that process gradients. Our approach is guided by three principles: (1) equivariant design that preserves neuron permutation symmetries, (2) processing sets of gradients across multiple data points to capture curvature information, and (3) efficient gradient representation through rank-1 decomposition. Based on these principles, we introduce GradMetaNet, a novel architecture for learning on gradients, constructed from simple equivariant blocks. We prove universality results for GradMetaNet, and show that previous approaches cannot approximate natural gradient-based functions that GradMetaNet can. We then demonstrate GradMetaNet's effectiveness on a diverse set of gradient-based tasks on MLPs and transformers, such as learned optimization, INR editing, and estimating loss landscape curvature.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01649v2",
    "published_date": "2025-07-02 12:22:39 UTC",
    "updated_date": "2025-10-12 19:11:30 UTC"
  },
  {
    "arxiv_id": "2507.01638v1",
    "title": "Customized Exploration of Landscape Features Driving Multi-Objective Combinatorial Optimization Performance",
    "authors": [
      "Ana Nikolikj",
      "Gabriela Ochoa",
      "Tome Eftimov"
    ],
    "abstract": "We present an analysis of landscape features for predicting the performance of multi-objective combinatorial optimization algorithms. We consider features from the recently proposed compressed Pareto Local Optimal Solutions Networks (C-PLOS-net) model of combinatorial landscapes. The benchmark instances are a set of rmnk-landscapes with 2 and 3 objectives and various levels of ruggedness and objective correlation. We consider the performance of three algorithms -- Pareto Local Search (PLS), Global Simple EMO Optimizer (GSEMO), and Non-dominated Sorting Genetic Algorithm (NSGA-II) - using the resolution and hypervolume metrics. Our tailored analysis reveals feature combinations that influence algorithm performance specific to certain landscapes. This study provides deeper insights into feature importance, tailored to specific rmnk-landscapes and algorithms.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01638v1",
    "published_date": "2025-07-02 12:11:41 UTC",
    "updated_date": "2025-07-02 12:11:41 UTC"
  },
  {
    "arxiv_id": "2507.03013v1",
    "title": "Challenges for AI in Multimodal STEM Assessments: a Human-AI Comparison",
    "authors": [
      "Aymeric de Chillaz",
      "Anna Sotnikova",
      "Patrick Jermann",
      "Antoine Bosselut"
    ],
    "abstract": "Generative AI systems have rapidly advanced, with multimodal input capabilities enabling reasoning beyond text-based tasks. In education, these advancements could influence assessment design and question answering, presenting both opportunities and challenges. To investigate these effects, we introduce a high-quality dataset of 201 university-level STEM questions, manually annotated with features such as image type, role, problem complexity, and question format. Our study analyzes how these features affect generative AI performance compared to students. We evaluate four model families with five prompting strategies, comparing results to the average of 546 student responses per question. Although the best model correctly answers on average 58.5 % of the questions using majority vote aggregation, human participants consistently outperform AI on questions involving visual components. Interestingly, human performance remains stable across question features but varies by subject, whereas AI performance is susceptible to both subject matter and question features. Finally, we provide actionable insights for educators, demonstrating how question design can enhance academic integrity by leveraging features that challenge current AI systems without increasing the cognitive burden for students.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.03013v1",
    "published_date": "2025-07-02 12:06:46 UTC",
    "updated_date": "2025-07-02 12:06:46 UTC"
  },
  {
    "arxiv_id": "2507.01634v1",
    "title": "Depth Anything at Any Condition",
    "authors": [
      "Boyuan Sun",
      "Modi Jin",
      "Bowen Yin",
      "Qibin Hou"
    ],
    "abstract": "We present Depth Anything at Any Condition (DepthAnything-AC), a foundation monocular depth estimation (MDE) model capable of handling diverse environmental conditions. Previous foundation MDE models achieve impressive performance across general scenes but not perform well in complex open-world environments that involve challenging conditions, such as illumination variations, adverse weather, and sensor-induced distortions. To overcome the challenges of data scarcity and the inability of generating high-quality pseudo-labels from corrupted images, we propose an unsupervised consistency regularization finetuning paradigm that requires only a relatively small amount of unlabeled data. Furthermore, we propose the Spatial Distance Constraint to explicitly enforce the model to learn patch-level relative relationships, resulting in clearer semantic boundaries and more accurate details. Experimental results demonstrate the zero-shot capabilities of DepthAnything-AC across diverse benchmarks, including real-world adverse weather benchmarks, synthetic corruption benchmarks, and general benchmarks.\n  Project Page: https://ghost233lism.github.io/depthanything-AC-page\n  Code: https://github.com/HVision-NKU/DepthAnythingAC",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01634v1",
    "published_date": "2025-07-02 12:05:57 UTC",
    "updated_date": "2025-07-02 12:05:57 UTC"
  },
  {
    "arxiv_id": "2507.02016v1",
    "title": "Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain",
    "authors": [
      "Cong Wang",
      "Roberto Calandra",
      "Verena Klös"
    ],
    "abstract": "When robots perform complex and context-dependent tasks in our daily lives, deviations from expectations can confuse users. Explanations of the robot's reasoning process can help users to understand the robot intentions. However, when to provide explanations and what they contain are important to avoid user annoyance. We have investigated user preferences for explanation demand and content for a robot that helps with daily cleaning tasks in a kitchen. Our results show that users want explanations in surprising situations and prefer concise explanations that clearly state the intention behind the confusing action and the contextual factors that were relevant to this decision. Based on these findings, we propose two algorithms to identify surprising actions and to construct effective explanations for Belief-Desire-Intention (BDI) robots. Our algorithms can be easily integrated in the BDI reasoning process and pave the way for better human-robot interaction with context- and user-specific explanations.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Paper accepted at IEEE RO-MAN 2025; 6 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.02016v1",
    "published_date": "2025-07-02 12:02:07 UTC",
    "updated_date": "2025-07-02 12:02:07 UTC"
  },
  {
    "arxiv_id": "2507.01631v2",
    "title": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation",
    "authors": [
      "Camille Billouard",
      "Dawa Derksen",
      "Alexandre Constantin",
      "Bruno Vallet"
    ],
    "abstract": "Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D reconstruction from multiview satellite imagery. However, state-of-the-art NeRF methods are typically constrained to small scenes due to the memory footprint during training, which we study in this paper. Previous work on large-scale NeRFs palliate this by dividing the scene into NeRFs. This paper introduces Snake-NeRF, a framework that scales to large scenes. Our out-of-core method eliminates the need to load all images and networks simultaneously, and operates on a single device. We achieve this by dividing the region of interest into NeRFs that 3D tile without overlap. Importantly, we crop the images with overlap to ensure each NeRFs is trained with all the necessary pixels. We introduce a novel $2\\times 2$ 3D tile progression strategy and segmented sampler, which together prevent 3D reconstruction errors along the tile edges. Our experiments conclude that large satellite images can effectively be processed with linear time complexity, on a single GPU, and without compromise in quality.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ICCV 2025 Workshop 3D-VAST (From street to space: 3D Vision Across Altitudes). Our code will be made public after the conference at https://github.com/Ellimac0/Snake-NeRF",
    "pdf_url": "https://arxiv.org/pdf/2507.01631v2",
    "published_date": "2025-07-02 11:59:36 UTC",
    "updated_date": "2025-07-31 13:32:03 UTC"
  },
  {
    "arxiv_id": "2507.01630v2",
    "title": "Prompt Guidance and Human Proximal Perception for HOT Prediction with Regional Joint Loss",
    "authors": [
      "Yuxiao Wang",
      "Yu Lei",
      "Zhenao Wei",
      "Weiying Xue",
      "Xinyu Jiang",
      "Nan Zhuang",
      "Qi Liu"
    ],
    "abstract": "The task of Human-Object conTact (HOT) detection involves identifying the specific areas of the human body that are touching objects. Nevertheless, current models are restricted to just one type of image, often leading to too much segmentation in areas with little interaction, and struggling to maintain category consistency within specific regions. To tackle this issue, a HOT framework, termed \\textbf{P3HOT}, is proposed, which blends \\textbf{P}rompt guidance and human \\textbf{P}roximal \\textbf{P}erception. To begin with, we utilize a semantic-driven prompt mechanism to direct the network's attention towards the relevant regions based on the correlation between image and text. Then a human proximal perception mechanism is employed to dynamically perceive key depth range around the human, using learnable parameters to effectively eliminate regions where interactions are not expected. Calculating depth resolves the uncertainty of the overlap between humans and objects in a 2D perspective, providing a quasi-3D viewpoint. Moreover, a Regional Joint Loss (RJLoss) has been created as a new loss to inhibit abnormal categories in the same area. A new evaluation metric called ``AD-Acc.'' is introduced to address the shortcomings of existing methods in addressing negative samples. Comprehensive experimental results demonstrate that our approach achieves state-of-the-art performance in four metrics across two benchmark datasets. Specifically, our model achieves an improvement of \\textbf{0.7}$\\uparrow$, \\textbf{2.0}$\\uparrow$, \\textbf{1.6}$\\uparrow$, and \\textbf{11.0}$\\uparrow$ in SC-Acc., mIoU, wIoU, and AD-Acc. metrics, respectively, on the HOT-Annotated dataset. The sources code are available at https://github.com/YuxiaoWang-AI/P3HOT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.01630v2",
    "published_date": "2025-07-02 11:59:32 UTC",
    "updated_date": "2025-07-23 09:22:32 UTC"
  },
  {
    "arxiv_id": "2507.01616v1",
    "title": "Enhanced Influence-aware Group Recommendation for Online Media Propagation",
    "authors": [
      "Chengkun He",
      "Xiangmin Zhou",
      "Chen Wang",
      "Longbing Cao",
      "Jie Shao",
      "Xiaodong Li",
      "Guang Xu",
      "Carrie Jinqiu Hu",
      "Zahir Tari"
    ],
    "abstract": "Group recommendation over social media streams has attracted significant attention due to its wide applications in domains such as e-commerce, entertainment, and online news broadcasting. By leveraging social connections and group behaviours, group recommendation (GR) aims to provide more accurate and engaging content to a set of users rather than individuals. Recently, influence-aware GR has emerged as a promising direction, as it considers the impact of social influence on group decision-making. In earlier work, we proposed Influence-aware Group Recommendation (IGR) to solve this task. However, this task remains challenging due to three key factors: the large and ever-growing scale of social graphs, the inherently dynamic nature of influence propagation within user groups, and the high computational overhead of real-time group-item matching.\n  To tackle these issues, we propose an Enhanced Influence-aware Group Recommendation (EIGR) framework. First, we introduce a Graph Extraction-based Sampling (GES) strategy to minimise redundancy across multiple temporal social graphs and effectively capture the evolving dynamics of both groups and items. Second, we design a novel DYnamic Independent Cascade (DYIC) model to predict how influence propagates over time across social items and user groups. Finally, we develop a two-level hash-based User Group Index (UG-Index) to efficiently organise user groups and enable real-time recommendation generation. Extensive experiments on real-world datasets demonstrate that our proposed framework, EIGR, consistently outperforms state-of-the-art baselines in both effectiveness and efficiency.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01616v1",
    "published_date": "2025-07-02 11:34:17 UTC",
    "updated_date": "2025-07-02 11:34:17 UTC"
  },
  {
    "arxiv_id": "2507.01607v5",
    "title": "SoK: On the Survivability of Backdoor Attacks on Unconstrained Face Recognition Systems",
    "authors": [
      "Quentin Le Roux",
      "Yannick Teglia",
      "Teddy Furon",
      "Philippe Loubet-Moundi",
      "Eric Bourbao"
    ],
    "abstract": "The widespread deployment of Deep Learning-based Face Recognition Systems raises many security concerns. While prior research has identified backdoor vulnerabilities on isolated components, Backdoor Attacks on real-world, unconstrained pipelines remain underexplored. This SoK paper presents the first comprehensive system-level analysis and measurement of the impact of Backdoor Attacks on fully-fledged Face Recognition Systems. We combine the existing Supervised Learning backdoor literature targeting face detectors, face antispoofing, and face feature extractors to demonstrate a system-level vulnerability. By analyzing 20 pipeline configurations and 15 attack scenarios in a holistic manner, we reveal that an attacker only needs a single backdoored model to compromise an entire Face Recognition System. Finally, we discuss the impact of such attacks and propose best practices and countermeasures for stakeholders.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). The final version will be available on IEEE Xplore",
    "pdf_url": "https://arxiv.org/pdf/2507.01607v5",
    "published_date": "2025-07-02 11:21:27 UTC",
    "updated_date": "2026-01-20 13:17:36 UTC"
  },
  {
    "arxiv_id": "2507.03011v1",
    "title": "Teacher training in the age of AI: Impact on AI Literacy and Teachers' Attitudes",
    "authors": [
      "Julia Lademann",
      "Jannik Henze",
      "Nadine Honke",
      "Caroline Wollny",
      "Sebastian Becker-Genschow"
    ],
    "abstract": "The rapid integration of artificial intelligence (AI) in education requires teachers to develop AI competencies while preparing students for a society influenced by AI. This study evaluates the impact of an online teacher training program on German in-service teachers' AI literacy, usage behaviors, and attitudes toward AI. A pre-post design study was conducted with teachers (N1 = 291 for AI literacy, N2 = 436 for attitude assessment) participating in the course. The program combined synchronous and asynchronous learning formats, including webinars, self-paced modules, and practical projects. The participants exhibited notable improvements across all domains: AI literacy scores increased significantly, and all attitude items regarding AI usage and integration demonstrated significant positive changes. Teachers reported increased confidence in AI integration. Structured teacher training programs effectively enhance AI literacy and foster positive attitudes toward AI in education.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.03011v1",
    "published_date": "2025-07-02 11:09:47 UTC",
    "updated_date": "2025-07-02 11:09:47 UTC"
  },
  {
    "arxiv_id": "2507.01599v1",
    "title": "Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems",
    "authors": [
      "Zhaoyan Sun",
      "Jiayi Wang",
      "Xinyang Zhao",
      "Jiachi Wang",
      "Guoliang Li"
    ],
    "abstract": "Traditional Data+AI systems utilize data-driven techniques to optimize performance, but they rely heavily on human experts to orchestrate system pipelines, enabling them to adapt to changes in data, queries, tasks, and environments. For instance, while there are numerous data science tools available, developing a pipeline planning system to coordinate these tools remains challenging. This difficulty arises because existing Data+AI systems have limited capabilities in semantic understanding, reasoning, and planning. Fortunately, we have witnessed the success of large language models (LLMs) in enhancing semantic understanding, reasoning, and planning abilities. It is crucial to incorporate LLM techniques to revolutionize data systems for orchestrating Data+AI applications effectively.\n  To achieve this, we propose the concept of a 'Data Agent' - a comprehensive architecture designed to orchestrate Data+AI ecosystems, which focuses on tackling data-related tasks by integrating knowledge comprehension, reasoning, and planning capabilities. We delve into the challenges involved in designing data agents, such as understanding data/queries/environments/tools, orchestrating pipelines/workflows, optimizing and executing pipelines, and fostering pipeline self-reflection. Furthermore, we present examples of data agent systems, including a data science agent, data analytics agents (such as unstructured data analytics agent, semantic structured data analytics agent, data lake analytics agent, and multi-modal data analytics agent), and a database administrator (DBA) agent. We also outline several open challenges associated with designing data agent systems.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01599v1",
    "published_date": "2025-07-02 11:04:49 UTC",
    "updated_date": "2025-07-02 11:04:49 UTC"
  },
  {
    "arxiv_id": "2507.01597v1",
    "title": "T3DM: Test-Time Training-Guided Distribution Shift Modelling for Temporal Knowledge Graph Reasoning",
    "authors": [
      "Yuehang Si",
      "Zefan Zeng",
      "Jincai Huang",
      "Qing Cheng"
    ],
    "abstract": "Temporal Knowledge Graph (TKG) is an efficient method for describing the dynamic development of facts along a timeline. Most research on TKG reasoning (TKGR) focuses on modelling the repetition of global facts and designing patterns of local historical facts. However, they face two significant challenges: inadequate modeling of the event distribution shift between training and test samples, and reliance on random entity substitution for generating negative samples, which often results in low-quality sampling. To this end, we propose a novel distributional feature modeling approach for training TKGR models, Test-Time Training-guided Distribution shift Modelling (T3DM), to adjust the model based on distribution shift and ensure the global consistency of model reasoning. In addition, we design a negative-sampling strategy to generate higher-quality negative quadruples based on adversarial training. Extensive experiments show that T3DM provides better and more robust results than the state-of-the-art baselines in most cases.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01597v1",
    "published_date": "2025-07-02 11:02:37 UTC",
    "updated_date": "2025-07-02 11:02:37 UTC"
  },
  {
    "arxiv_id": "2507.01590v1",
    "title": "Autonomous AI Surveillance: Multimodal Deep Learning for Cognitive and Behavioral Monitoring",
    "authors": [
      "Ameer Hamza",
      "Zuhaib Hussain But",
      "Umar Arif",
      "Samiya",
      "M. Abdullah Asad",
      "Muhammad Naeem"
    ],
    "abstract": "This study presents a novel classroom surveillance system that integrates multiple modalities, including drowsiness, tracking of mobile phone usage, and face recognition,to assess student attentiveness with enhanced precision.The system leverages the YOLOv8 model to detect both mobile phone and sleep usage,(Ghatge et al., 2024) while facial recognition is achieved through LResNet Occ FC body tracking using YOLO and MTCNN.(Durai et al., 2024) These models work in synergy to provide comprehensive, real-time monitoring, offering insights into student engagement and behavior.(S et al., 2023) The framework is trained on specialized datasets, such as the RMFD dataset for face recognition and a Roboflow dataset for mobile phone detection. The extensive evaluation of the system shows promising results. Sleep detection achieves 97. 42% mAP@50, face recognition achieves 86. 45% validation accuracy and mobile phone detection reach 85. 89% mAP@50. The system is implemented within a core PHP web application and utilizes ESP32-CAM hardware for seamless data capture.(Neto et al., 2024) This integrated approach not only enhances classroom monitoring, but also ensures automatic attendance recording via face recognition as students remain seated in the classroom, offering scalability for diverse educational environments.(Banada,2025)",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01590v1",
    "published_date": "2025-07-02 10:59:01 UTC",
    "updated_date": "2025-07-02 10:59:01 UTC"
  },
  {
    "arxiv_id": "2507.01582v1",
    "title": "Exploring Classical Piano Performance Generation with Expressive Music Variational AutoEncoder",
    "authors": [
      "Jing Luo",
      "Xinyu Yang",
      "Jie Wei"
    ],
    "abstract": "The creativity of classical music arises not only from composers who craft the musical sheets but also from performers who interpret the static notations with expressive nuances. This paper addresses the challenge of generating classical piano performances from scratch, aiming to emulate the dual roles of composer and pianist in the creative process. We introduce the Expressive Compound Word (ECP) representation, which effectively captures both the metrical structure and expressive nuances of classical performances. Building on this, we propose the Expressive Music Variational AutoEncoder (XMVAE), a model featuring two branches: a Vector Quantized Variational AutoEncoder (VQ-VAE) branch that generates score-related content, representing the Composer, and a vanilla VAE branch that produces expressive details, fulfilling the role of Pianist. These branches are jointly trained with similar Seq2Seq architectures, leveraging a multiscale encoder to capture beat-level contextual information and an orthogonal Transformer decoder for efficient compound tokens decoding. Both objective and subjective evaluations demonstrate that XMVAE generates classical performances with superior musical quality compared to state-of-the-art models. Furthermore, pretraining the Composer branch on extra musical score datasets contribute to a significant performance gain.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by IEEE SMC 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.01582v1",
    "published_date": "2025-07-02 10:54:23 UTC",
    "updated_date": "2025-07-02 10:54:23 UTC"
  },
  {
    "arxiv_id": "2507.01563v1",
    "title": "Real-Time Emergency Vehicle Siren Detection with Efficient CNNs on Embedded Hardware",
    "authors": [
      "Marco Giordano",
      "Stefano Giacomelli",
      "Claudia Rinaldi",
      "Fabio Graziosi"
    ],
    "abstract": "We present a full-stack emergency vehicle (EV) siren detection system designed for real-time deployment on embedded hardware. The proposed approach is based on E2PANNs, a fine-tuned convolutional neural network derived from EPANNs, and optimized for binary sound event detection under urban acoustic conditions. A key contribution is the creation of curated and semantically structured datasets - AudioSet-EV, AudioSet-EV Augmented, and Unified-EV - developed using a custom AudioSet-Tools framework to overcome the low reliability of standard AudioSet annotations. The system is deployed on a Raspberry Pi 5 equipped with a high-fidelity DAC+microphone board, implementing a multithreaded inference engine with adaptive frame sizing, probability smoothing, and a decision-state machine to control false positive activations. A remote WebSocket interface provides real-time monitoring and facilitates live demonstration capabilities. Performance is evaluated using both framewise and event-based metrics across multiple configurations. Results show the system achieves low-latency detection with improved robustness under realistic audio conditions. This work demonstrates the feasibility of deploying IoS-compatible SED solutions that can form distributed acoustic monitoring networks, enabling collaborative emergency vehicle tracking across smart city infrastructures through WebSocket connectivity on low-cost edge devices.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "10 pages, 10 figures, submitted to https://internetofsounds2025.ieee-is2.org/. arXiv admin note: text overlap with arXiv:2506.23437",
    "pdf_url": "https://arxiv.org/pdf/2507.01563v1",
    "published_date": "2025-07-02 10:27:41 UTC",
    "updated_date": "2025-07-02 10:27:41 UTC"
  },
  {
    "arxiv_id": "2507.01551v2",
    "title": "Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning",
    "authors": [
      "Wu Fei",
      "Hao Kong",
      "Shuxian Liang",
      "Yang Lin",
      "Yibo Yang",
      "Jing Tang",
      "Lei Chen",
      "Xiansheng Hua"
    ],
    "abstract": "Process Reinforcement Learning~(PRL) has demonstrated considerable potential in enhancing the reasoning capabilities of Large Language Models~(LLMs). However, introducing additional process reward models incurs substantial computational overhead, and there is no unified theoretical framework for process-level advantage estimation. To bridge this gap, we propose \\textbf{S}elf-Guided \\textbf{P}rocess \\textbf{R}eward \\textbf{O}ptimization~(\\textbf{SPRO}), a novel framework that enables process-aware RL through two key innovations: (1) we first theoretically demonstrate that process rewards can be derived intrinsically from the policy model itself, and (2) we introduce well-defined cumulative process rewards and \\textbf{M}asked \\textbf{S}tep \\textbf{A}dvantage (\\textbf{MSA}), which facilitates rigorous step-wise action advantage estimation within shared-prompt sampling groups. Our experimental results demonstrate that SPRO outperforms vaniila GRPO with 3.4x higher training efficiency and a 17.5\\% test accuracy improvement. Furthermore, SPRO maintains a stable and elevated policy entropy throughout training while reducing the average response length by approximately $1/3$, evidencing sufficient exploration and prevention of reward hacking. Notably, SPRO incurs no additional computational overhead compared to outcome-supervised RL methods such as GRPO, which benefit industrial implementation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01551v2",
    "published_date": "2025-07-02 10:05:14 UTC",
    "updated_date": "2025-07-03 10:33:08 UTC"
  },
  {
    "arxiv_id": "2507.01548v2",
    "title": "Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants",
    "authors": [
      "Wen Zhan",
      "Ziqun Hua",
      "Peiyue Lin",
      "Yunfei Chen"
    ],
    "abstract": "This paper explores how older adults, particularly aging migrants in urban China, can engage AI-assisted co-creation to express personal narratives that are often fragmented, underrepresented, or difficult to verbalize. Through a pilot workshop combining oral storytelling and the symbolic reconstruction of Hanzi, participants shared memories of migration and recreated new character forms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM), together with physical materials. Supported by human facilitation and a soft AI presence, participants transformed lived experience into visual and tactile expressions without requiring digital literacy. This approach offers new perspectives on human-AI collaboration and aging by repositioning AI not as a content producer but as a supportive mechanism, and by supporting narrative agency within sociotechnical systems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "A version of this manuscript has been submitted to the [IASDR 2025 Conference](https://iasdr2025.org/) and is currently under review",
    "pdf_url": "https://arxiv.org/pdf/2507.01548v2",
    "published_date": "2025-07-02 10:00:12 UTC",
    "updated_date": "2025-07-03 08:45:46 UTC"
  },
  {
    "arxiv_id": "2507.01547v1",
    "title": "AI and Remote Sensing for Resilient and Sustainable Built Environments: A Review of Current Methods, Open Data and Future Directions",
    "authors": [
      "Ubada El Joulani",
      "Tatiana Kalganova",
      "Stergios-Aristoteles Mitoulis",
      "Sotirios Argyroudis"
    ],
    "abstract": "Critical infrastructure, such as transport networks, underpins economic growth by enabling mobility and trade. However, ageing assets, climate change impacts (e.g., extreme weather, rising sea levels), and hybrid threats ranging from natural disasters to cyber attacks and conflicts pose growing risks to their resilience and functionality. This review paper explores how emerging digital technologies, specifically Artificial Intelligence (AI), can enhance damage assessment and monitoring of transport infrastructure. A systematic literature review examines existing AI models and datasets for assessing damage in roads, bridges, and other critical infrastructure impacted by natural disasters. Special focus is given to the unique challenges and opportunities associated with bridge damage detection due to their structural complexity and critical role in connectivity. The integration of SAR (Synthetic Aperture Radar) data with AI models is also discussed, with the review revealing a critical research gap: a scarcity of studies applying AI models to SAR data for comprehensive bridge damage assessment. Therefore, this review aims to identify the research gaps and provide foundations for AI-driven solutions for assessing and monitoring critical transport infrastructures.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01547v1",
    "published_date": "2025-07-02 09:59:23 UTC",
    "updated_date": "2025-07-02 09:59:23 UTC"
  },
  {
    "arxiv_id": "2507.01522v1",
    "title": "Chargax: A JAX Accelerated EV Charging Simulator",
    "authors": [
      "Koen Ponse",
      "Jan Felix Kleuker",
      "Aske Plaat",
      "Thomas Moerland"
    ],
    "abstract": "Deep Reinforcement Learning can play a key role in addressing sustainable energy challenges. For instance, many grid systems are heavily congested, highlighting the urgent need to enhance operational efficiency. However, reinforcement learning approaches have traditionally been slow due to the high sample complexity and expensive simulation requirements. While recent works have effectively used GPUs to accelerate data generation by converting environments to JAX, these works have largely focussed on classical toy problems. This paper introduces Chargax, a JAX-based environment for realistic simulation of electric vehicle charging stations designed for accelerated training of RL agents. We validate our environment in a variety of scenarios based on real data, comparing reinforcement learning agents against baselines. Chargax delivers substantial computational performance improvements of over 100x-1000x over existing environments. Additionally, Chargax' modular architecture enables the representation of diverse real-world charging station configurations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at RLC 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.01522v1",
    "published_date": "2025-07-02 09:27:14 UTC",
    "updated_date": "2025-07-02 09:27:14 UTC"
  },
  {
    "arxiv_id": "2507.01504v3",
    "title": "Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence",
    "authors": [
      "Robert Aufschläger",
      "Youssef Shoeb",
      "Azarm Nowzad",
      "Michael Heigl",
      "Fabian Bally",
      "Martin Schramm"
    ],
    "abstract": "The collection and release of street-level recordings as Open Data play a vital role in advancing autonomous driving systems and AI research. However, these datasets pose significant privacy risks, particularly for pedestrians, due to the presence of Personally Identifiable Information (PII) that extends beyond biometric traits such as faces. In this paper, we present cRID, a novel cross-modal framework combining Large Vision-Language Models, Graph Attention Networks, and representation learning to detect textual describable clues of PII and enhance person re-identification (Re-ID). Our approach focuses on identifying and leveraging interpretable features, enabling the detection of semantically meaningful PII beyond low-level appearance cues. We conduct a systematic evaluation of PII presence in person image datasets. Our experiments show improved performance in practical cross-dataset Re-ID scenarios, notably from Market-1501 to CUHK03-np (detected), highlighting the framework's practical utility. Code is available at https://github.com/RAufschlaeger/cRID.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted for publication at the 2025 IEEE 28th International Conference on Intelligent Transportation Systems (ITSC 2025), taking place during November 18-21, 2025 in Gold Coast, Australia",
    "pdf_url": "https://arxiv.org/pdf/2507.01504v3",
    "published_date": "2025-07-02 09:10:33 UTC",
    "updated_date": "2025-07-15 14:54:52 UTC"
  },
  {
    "arxiv_id": "2507.01502v1",
    "title": "Integrating Traditional and Deep Learning Methods to Detect Tree Crowns in Satellite Images",
    "authors": [
      "Ozan Durgut",
      "Beril Kallfelz-Sirmacek",
      "Cem Unsalan"
    ],
    "abstract": "Global warming, loss of biodiversity, and air pollution are among the most significant problems facing Earth. One of the primary challenges in addressing these issues is the lack of monitoring forests to protect them. To tackle this problem, it is important to leverage remote sensing and computer vision methods to automate monitoring applications. Hence, automatic tree crown detection algorithms emerged based on traditional and deep learning methods. In this study, we first introduce two different tree crown detection methods based on these approaches. Then, we form a novel rule-based approach that integrates these two methods to enhance robustness and accuracy of tree crown detection results. While traditional methods are employed for feature extraction and segmentation of forested areas, deep learning methods are used to detect tree crowns in our method. With the proposed rule-based approach, we post-process these results, aiming to increase the number of detected tree crowns through neighboring trees and localized operations. We compare the obtained results with the proposed method in terms of the number of detected tree crowns and report the advantages, disadvantages, and areas for improvement of the obtained outcomes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 4 figures, journal manuscript",
    "pdf_url": "https://arxiv.org/pdf/2507.01502v1",
    "published_date": "2025-07-02 09:05:28 UTC",
    "updated_date": "2025-07-02 09:05:28 UTC"
  },
  {
    "arxiv_id": "2507.01494v3",
    "title": "Crop Pest Classification Using Deep Learning Techniques: A Review",
    "authors": [
      "Muhammad Hassam Ejaz",
      "Muhammad Bilal",
      "Usman Habib",
      "Muhammad Attique",
      "Tae-Sun Chung"
    ],
    "abstract": "Insect pests continue to bring a serious threat to crop yields around the world, and traditional methods for monitoring them are often slow, manual, and difficult to scale. In recent years, deep learning has emerged as a powerful solution, with techniques like convolutional neural networks (CNNs), vision transformers (ViTs), and hybrid models gaining popularity for automating pest detection. This review looks at 37 carefully selected studies published between 2018 and 2025, all focused on AI-based pest classification. The selected research is organized by crop type, pest species, model architecture, dataset usage, and key technical challenges. The early studies relied heavily on CNNs but latest work is shifting toward hybrid and transformer-based models that deliver higher accuracy and better contextual understanding. Still, challenges like imbalanced datasets, difficulty in detecting small pests, limited generalizability, and deployment on edge devices remain significant hurdles. Overall, this review offers a structured overview of the field, highlights useful datasets, and outlines the key challenges and future directions for AI-based pest monitoring systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This version adds co-authors who were unintentionally left out of the prior submission. Additionally, Table 1 has been reformatted for clarity, and several typographical errors have been corrected",
    "pdf_url": "https://arxiv.org/pdf/2507.01494v3",
    "published_date": "2025-07-02 08:52:35 UTC",
    "updated_date": "2025-08-08 17:34:39 UTC"
  },
  {
    "arxiv_id": "2507.01489v1",
    "title": "Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning",
    "authors": [
      "Yanfei Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as one of the most significant technological advancements in artificial intelligence in recent years. Their ability to understand, generate, and reason with natural language has transformed how we interact with AI systems. With the development of LLM-based agents and reinforcement-learning-based reasoning models, the study of applying reinforcement learning in agent frameworks has become a new research focus. However, all previous studies face the challenge of deciding the tool calling process and the reasoning process simultaneously, and the chain of reasoning was solely relied on the unprocessed raw result with redundant information and symbols unrelated to the task from the tool, which impose a heavy burden on the model's capability to reason. Therefore, in our research, we proposed a hierarchical framework Agent-as-tool that detach the tool calling process and the reasoning process, which enables the model to focus on the verbally reasoning process while the tool calling process is handled by another agent. Our work had achieved comparable results with only a slight reinforcement fine-tuning on 180 samples, and had achieved exceptionally well performance in Bamboogle with 63.2% of exact match and 75.2% in cover exact match, exceeding Search-R1 by 4.8% in exact match and 3.2% in cover exact match.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.01489v1",
    "published_date": "2025-07-02 08:49:43 UTC",
    "updated_date": "2025-07-02 08:49:43 UTC"
  },
  {
    "arxiv_id": "2507.01485v1",
    "title": "BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments",
    "authors": [
      "Yibo Qiu",
      "Zan Huang",
      "Zhiyu Wang",
      "Handi Liu",
      "Yiling Qiao",
      "Yifeng Hu",
      "Shu'ang Sun",
      "Hangke Peng",
      "Ronald X Xu",
      "Mingzhai Sun"
    ],
    "abstract": "Large language models (LLMs) and vision-language models (VLMs) have the potential to transform biological research by enabling autonomous experimentation. Yet, their application remains constrained by rigid protocol design, limited adaptability to dynamic lab conditions, inadequate error handling, and high operational complexity. Here we introduce BioMARS (Biological Multi-Agent Robotic System), an intelligent platform that integrates LLMs, VLMs, and modular robotics to autonomously design, plan, and execute biological experiments. BioMARS uses a hierarchical architecture: the Biologist Agent synthesizes protocols via retrieval-augmented generation; the Technician Agent translates them into executable robotic pseudo-code; and the Inspector Agent ensures procedural integrity through multimodal perception and anomaly detection. The system autonomously conducts cell passaging and culture tasks, matching or exceeding manual performance in viability, consistency, and morphological integrity. It also supports context-aware optimization, outperforming conventional strategies in differentiating retinal pigment epithelial cells. A web interface enables real-time human-AI collaboration, while a modular backend allows scalable integration with laboratory hardware. These results highlight the feasibility of generalizable, AI-driven laboratory automation and the transformative role of language-based reasoning in biological research.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA",
      "q-bio.QM"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01485v1",
    "published_date": "2025-07-02 08:47:02 UTC",
    "updated_date": "2025-07-02 08:47:02 UTC"
  },
  {
    "arxiv_id": "2507.01483v1",
    "title": "Epistemic Scarcity: The Economics of Unresolvable Unknowns",
    "authors": [
      "Craig S Wright"
    ],
    "abstract": "This paper presents a praxeological analysis of artificial intelligence and algorithmic governance, challenging assumptions about the capacity of machine systems to sustain economic and epistemic order. Drawing on Misesian a priori reasoning and Austrian theories of entrepreneurship, we argue that AI systems are incapable of performing the core functions of economic coordination: interpreting ends, discovering means, and communicating subjective value through prices. Where neoclassical and behavioural models treat decisions as optimisation under constraint, we frame them as purposive actions under uncertainty.\n  We critique dominant ethical AI frameworks such as Fairness, Accountability, and Transparency (FAT) as extensions of constructivist rationalism, which conflict with a liberal order grounded in voluntary action and property rights. Attempts to encode moral reasoning in algorithms reflect a misunderstanding of ethics and economics. However complex, AI systems cannot originate norms, interpret institutions, or bear responsibility. They remain opaque, misaligned, and inert.\n  Using the concept of epistemic scarcity, we explore how information abundance degrades truth discernment, enabling both entrepreneurial insight and soft totalitarianism. Our analysis ends with a civilisational claim: the debate over AI concerns the future of human autonomy, institutional evolution, and reasoned choice. The Austrian tradition, focused on action, subjectivity, and spontaneous order, offers the only coherent alternative to rising computational social control.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CY",
      "physics.hist-ph"
    ],
    "primary_category": "econ.GN",
    "comment": "47 pages - submission to QJAE",
    "pdf_url": "https://arxiv.org/pdf/2507.01483v1",
    "published_date": "2025-07-02 08:46:24 UTC",
    "updated_date": "2025-07-02 08:46:24 UTC"
  },
  {
    "arxiv_id": "2507.01479v1",
    "title": "Evaluating the Effectiveness of Direct Preference Optimization for Personalizing German Automatic Text Simplifications for Persons with Intellectual Disabilities",
    "authors": [
      "Yingqiang Gao",
      "Kaede Johnson",
      "David Froehlich",
      "Luisa Carrer",
      "Sarah Ebling"
    ],
    "abstract": "Automatic text simplification (ATS) aims to enhance language accessibility for various target groups, particularly persons with intellectual disabilities. Recent advancements in generative AI, especially large language models (LLMs), have substantially improved the quality of machine-generated text simplifications, thereby mitigating information barriers for the target group. However, existing LLM-based ATS systems do not incorporate preference feedback on text simplifications during training, resulting in a lack of personalization tailored to the specific needs of target group representatives.\n  In this work, we extend the standard supervised fine-tuning (SFT) approach for adapting LLM-based ATS models by leveraging a computationally efficient LLM alignment technique -- direct preference optimization (DPO). Specifically, we post-train LLM-based ATS models using human feedback collected from persons with intellectual disabilities, reflecting their preferences on paired text simplifications generated by mainstream LLMs. Furthermore, we propose a pipeline for developing personalized LLM-based ATS systems, encompassing data collection, model selection, SFT and DPO post-training, and evaluation. Our findings underscore the necessity of active participation of target group persons in designing personalized AI accessibility solutions aligned with human expectations. This work represents a step towards personalizing inclusive AI systems at the target-group level, incorporating insights not only from text simplification experts but also from target group persons themselves.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01479v1",
    "published_date": "2025-07-02 08:43:06 UTC",
    "updated_date": "2025-07-02 08:43:06 UTC"
  },
  {
    "arxiv_id": "2507.02014v1",
    "title": "ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations",
    "authors": [
      "Anoushka Harit",
      "Zhongtian Sun",
      "Suncica Hadzidedic"
    ],
    "abstract": "We introduce ManifoldMind, a probabilistic geometric recommender system for exploratory reasoning over semantic hierarchies in hyperbolic space. Unlike prior methods with fixed curvature and rigid embeddings, ManifoldMind represents users, items, and tags as adaptive-curvature probabilistic spheres, enabling personalised uncertainty modeling and geometry-aware semantic exploration. A curvature-aware semantic kernel supports soft, multi-hop inference, allowing the model to explore diverse conceptual paths instead of overfitting to shallow or direct interactions. Experiments on four public benchmarks show superior NDCG, calibration, and diversity compared to strong baselines. ManifoldMind produces explicit reasoning traces, enabling transparent, trustworthy, and exploration-driven recommendations in sparse or abstract domains.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02014v1",
    "published_date": "2025-07-02 08:42:11 UTC",
    "updated_date": "2025-07-02 08:42:11 UTC"
  },
  {
    "arxiv_id": "2507.01470v1",
    "title": "Zero-Incentive Dynamics: a look at reward sparsity through the lens of unrewarded subgoals",
    "authors": [
      "Yannick Molinghen",
      "Tom Lenaerts"
    ],
    "abstract": "This work re-examines the commonly held assumption that the frequency of rewards is a reliable measure of task difficulty in reinforcement learning. We identify and formalize a structural challenge that undermines the effectiveness of current policy learning methods: when essential subgoals do not directly yield rewards. We characterize such settings as exhibiting zero-incentive dynamics, where transitions critical to success remain unrewarded. We show that state-of-the-art deep subgoal-based algorithms fail to leverage these dynamics and that learning performance is highly sensitive to the temporal proximity between subgoal completion and eventual reward. These findings reveal a fundamental limitation in current approaches and point to the need for mechanisms that can infer latent task structure without relying on immediate incentives.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at \"Finding the Frame 2025\", workshop at RLC",
    "pdf_url": "https://arxiv.org/pdf/2507.01470v1",
    "published_date": "2025-07-02 08:33:03 UTC",
    "updated_date": "2025-07-02 08:33:03 UTC"
  },
  {
    "arxiv_id": "2507.01463v4",
    "title": "NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation",
    "authors": [
      "Max Gandyra",
      "Alessandro Santonicola",
      "Michael Beetz"
    ],
    "abstract": "Instance segmentation of novel objects instances in RGB images, given some example images for each object, is a well known problem in computer vision. Designing a model general enough to be employed for all kinds of novel objects without (re-) training has proven to be a difficult task. To handle this, we present a new training-free framework, called: Novel Object Cyclic Threshold based Instance Segmentation (NOCTIS). NOCTIS integrates two pre-trained models: Grounded-SAM 2 for object proposals with precise bounding boxes and corresponding segmentation masks; and DINOv2 for robust class and patch embeddings, due to its zero-shot capabilities. Internally, the proposal-object matching is realized by determining an object matching score based on the similarity of the class embeddings and the average maximum similarity of the patch embeddings with a new cyclic thresholding (CT) mechanism that mitigates unstable matches caused by repetitive textures or visually similar patterns. Beyond CT, NOCTIS introduces: (i) an appearance score that is unaffected by object selection bias; (ii) the usage of the average confidence of the proposals' bounding box and mask as a scoring component; and (iii) an RGB-only pipeline that performs even better than RGB-D ones. We empirically show that NOCTIS, without further training/fine tuning, outperforms the best RGB and RGB-D methods regarding the mean AP score on the seven core datasets of the BOP 2023 challenge for the \"Model-based 2D segmentation of unseen objects\" task.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 3 figures, 5 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.01463v4",
    "published_date": "2025-07-02 08:23:14 UTC",
    "updated_date": "2025-12-02 12:42:27 UTC"
  },
  {
    "arxiv_id": "2507.01462v1",
    "title": "Quantum-Assisted Automatic Path-Planning for Robotic Quality Inspection in Industry 4.0",
    "authors": [
      "Eneko Osaba",
      "Estibaliz Garrote",
      "Pablo Miranda-Rodriguez",
      "Alessia Ciacco",
      "Itziar Cabanes",
      "Aitziber Mancisidor"
    ],
    "abstract": "This work explores the application of hybrid quantum-classical algorithms to optimize robotic inspection trajectories derived from Computer-Aided Design (CAD) models in industrial settings. By modeling the task as a 3D variant of the Traveling Salesman Problem, incorporating incomplete graphs and open-route constraints, this study evaluates the performance of two D-Wave-based solvers against classical methods such as GUROBI and Google OR-Tools. Results across five real-world cases demonstrate competitive solution quality with significantly reduced computation times, highlighting the potential of quantum approaches in automation under Industry 4.0.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.RO",
    "comment": "2 pages, 1 figure, paper accepted for presentation at the IEEE International Conference on Quantum Computing and Engineering (QCE)",
    "pdf_url": "https://arxiv.org/pdf/2507.01462v1",
    "published_date": "2025-07-02 08:21:52 UTC",
    "updated_date": "2025-07-02 08:21:52 UTC"
  },
  {
    "arxiv_id": "2507.01457v2",
    "title": "Tensor Program Optimization for the RISC-V Vector Extension Using Probabilistic Programs",
    "authors": [
      "Federico Nicolas Peccia",
      "Frederik Haxel",
      "Oliver Bringmann"
    ],
    "abstract": "RISC-V provides a flexible and scalable platform for applications ranging from embedded devices to high-performance computing clusters. Particularly, its RISC-V Vector Extension (RVV) becomes of interest for the acceleration of AI workloads. But writing software that efficiently utilizes the vector units of RISC-V CPUs without expert knowledge requires the programmer to rely on the autovectorization features of compilers or hand-crafted libraries like muRISCV-NN. Smarter approaches, like autotuning frameworks, have been missing the integration with the RISC-V RVV extension, thus heavily limiting the efficient deployment of complex AI workloads. In this paper, we present a workflow based on the TVM compiler to efficiently map AI workloads onto RISC-V vector units. Instead of relying on hand-crafted libraries, we integrated the RVV extension into TVM's MetaSchedule framework, a probabilistic program framework for tensor operation tuning. We implemented different RISC-V SoCs on an FPGA and tuned a wide range of AI workloads on them. We found that our proposal shows a mean improvement of 46% in execution latency when compared against the autovectorization feature of GCC, and 29% against muRISCV-NN. Moreover, the binary resulting from our proposal has a smaller code memory footprint, making it more suitable for embedded devices. Finally, we also evaluated our solution on a commercially available RISC-V SoC implementing the RVV 1.0 Vector Extension and found our solution is able to find mappings that are 35% faster on average than the ones proposed by LLVM. We open-sourced our proposal for the community to expand it to target other RISC-V extensions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 10 figures, 2 algorithms",
    "pdf_url": "https://arxiv.org/pdf/2507.01457v2",
    "published_date": "2025-07-02 08:15:33 UTC",
    "updated_date": "2025-08-19 09:55:09 UTC"
  },
  {
    "arxiv_id": "2507.01446v1",
    "title": "Using multi-agent architecture to mitigate the risk of LLM hallucinations",
    "authors": [
      "Abd Elrahman Amer",
      "Magdi Amer"
    ],
    "abstract": "Improving customer service quality and response time are critical factors for maintaining customer loyalty and increasing a company's market share. While adopting emerging technologies such as Large Language Models (LLMs) is becoming a necessity to achieve these goals, the risk of hallucination remains a major challenge. In this paper, we present a multi-agent system to handle customer requests sent via SMS. This system integrates LLM based agents with fuzzy logic to mitigate hallucination risks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01446v1",
    "published_date": "2025-07-02 08:06:02 UTC",
    "updated_date": "2025-07-02 08:06:02 UTC"
  },
  {
    "arxiv_id": "2507.01438v1",
    "title": "EdgeLoRA: An Efficient Multi-Tenant LLM Serving System on Edge Devices",
    "authors": [
      "Zheyu Shen",
      "Yexiao He",
      "Ziyao Wang",
      "Yuning Zhang",
      "Guoheng Sun",
      "Wanghao Ye",
      "Ang Li"
    ],
    "abstract": "Large Language Models (LLMs) have gained significant attention due to their versatility across a wide array of applications. Fine-tuning LLMs with parameter-efficient adapters, such as Low-Rank Adaptation (LoRA), enables these models to efficiently adapt to downstream tasks without extensive retraining. Deploying fine-tuned LLMs on multi-tenant edge devices offers substantial benefits, such as reduced latency, enhanced privacy, and personalized responses. However, serving LLMs efficiently on resource-constrained edge devices presents critical challenges, including the complexity of adapter selection for different tasks and memory overhead from frequent adapter swapping. Moreover, given the multiple requests in multi-tenant settings, processing requests sequentially results in underutilization of computational resources and increased latency. This paper introduces EdgeLoRA, an efficient system for serving LLMs on edge devices in multi-tenant environments. EdgeLoRA incorporates three key innovations: (1) an adaptive adapter selection mechanism to streamline the adapter configuration process; (2) heterogeneous memory management, leveraging intelligent adapter caching and pooling to mitigate memory operation overhead; and (3) batch LoRA inference, enabling efficient batch processing to significantly reduce computational latency. Comprehensive evaluations using the Llama3.1-8B model demonstrate that EdgeLoRA significantly outperforms the status quo (i.e., llama.cpp) in terms of both latency and throughput. The results demonstrate that EdgeLoRA can achieve up to a 4 times boost in throughput. Even more impressively, it can serve several orders of magnitude more adapters simultaneously. These results highlight EdgeLoRA's potential to transform edge deployment of LLMs in multi-tenant scenarios, offering a scalable and efficient solution for resource-constrained environments.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01438v1",
    "published_date": "2025-07-02 07:47:28 UTC",
    "updated_date": "2025-07-02 07:47:28 UTC"
  },
  {
    "arxiv_id": "2507.01436v3",
    "title": "Challenges & Opportunities with LLM-Assisted Visualization Retargeting",
    "authors": [
      "Luke S. Snyder",
      "Chenglong Wang",
      "Steven M. Drucker"
    ],
    "abstract": "Despite the ubiquity of visualization examples published on the web, retargeting existing custom chart implementations to new datasets remains difficult, time-intensive, and tedious. The adaptation process assumes author familiarity with both the implementation of the example as well as how the new dataset might need to be transformed to fit into the example code. With recent advances in Large Language Models (LLMs), automatic adaptation of code can be achieved from high-level user prompts, reducing the barrier for visualization retargeting. To better understand how LLMs can assist retargeting and its potential limitations, we characterize and evaluate the performance of LLM assistance across multiple datasets and charts of varying complexity, categorizing failures according to type and severity. In our evaluation, we compare two approaches: (1) directly instructing the LLM model to fully generate and adapt code by treating code as text inputs and (2) a more constrained program synthesis pipeline where the LLM guides the code construction process by providing structural information (e.g., visual encodings) based on properties of the example code and data. We find that both approaches struggle when new data has not been appropriately transformed, and discuss important design recommendations for future retargeting systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "5 pages, 3 figures, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2507.01436v3",
    "published_date": "2025-07-02 07:43:43 UTC",
    "updated_date": "2026-01-18 07:48:08 UTC"
  },
  {
    "arxiv_id": "2507.01431v2",
    "title": "Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading",
    "authors": [
      "Yoonseok Yang",
      "Minjune Kim",
      "Marlon Rondinelli",
      "Keren Shao"
    ],
    "abstract": "Grading handwritten, open-ended responses remains a major bottleneck in large university STEM courses. We introduce Pensieve (https://www.pensieve.co), an AI-assisted grading platform that leverages large language models (LLMs) to transcribe and evaluate student work, providing instructors with rubric-aligned scores, transcriptions, and confidence ratings. Unlike prior tools that focus narrowly on specific tasks like transcription or rubric generation, Pensieve supports the entire grading pipeline-from scanned student submissions to final feedback-within a human-in-the-loop interface.\n  Pensieve has been deployed in real-world courses at over 20 institutions and has graded more than 300,000 student responses. We present system details and empirical results across four core STEM disciplines: Computer Science, Mathematics, Physics, and Chemistry. Our findings show that Pensieve reduces grading time by an average of 65%, while maintaining a 95.4% agreement rate with instructor-assigned grades for high-confidence predictions.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 5 figues, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2507.01431v2",
    "published_date": "2025-07-02 07:33:19 UTC",
    "updated_date": "2025-07-07 05:10:47 UTC"
  },
  {
    "arxiv_id": "2507.01429v1",
    "title": "Hardware-software co-exploration with racetrack memory based in-memory computing for CNN inference in embedded systems",
    "authors": [
      "Benjamin Chen Ming Choong",
      "Tao Luo",
      "Cheng Liu",
      "Bingsheng He",
      "Wei Zhang",
      "Joey Tianyi Zhou"
    ],
    "abstract": "Deep neural networks generate and process large volumes of data, posing challenges for low-resource embedded systems. In-memory computing has been demonstrated as an efficient computing infrastructure and shows promise for embedded AI applications. Among newly-researched memory technologies, racetrack memory is a non-volatile technology that allows high data density fabrication, making it a good fit for in-memory computing. However, integrating in-memory arithmetic circuits with memory cells affects both the memory density and power efficiency. It remains challenging to build efficient in-memory arithmetic circuits on racetrack memory within area and energy constraints. To this end, we present an efficient in-memory convolutional neural network (CNN) accelerator optimized for use with racetrack memory. We design a series of fundamental arithmetic circuits as in-memory computing cells suited for multiply-and-accumulate operations. Moreover, we explore the design space of racetrack memory based systems and CNN model architectures, employing co-design to improve the efficiency and performance of performing CNN inference in racetrack memory while maintaining model accuracy. Our designed circuits and model-system co-optimization strategies achieve a small memory bank area with significant improvements in energy and performance for racetrack memory based embedded systems.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.ET",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01429v1",
    "published_date": "2025-07-02 07:29:53 UTC",
    "updated_date": "2025-07-02 07:29:53 UTC"
  },
  {
    "arxiv_id": "2507.01422v1",
    "title": "DocShaDiffusion: Diffusion Model in Latent Space for Document Image Shadow Removal",
    "authors": [
      "Wenjie Liu",
      "Bingshu Wang",
      "Ze Wang",
      "C. L. Philip Chen"
    ],
    "abstract": "Document shadow removal is a crucial task in the field of document image enhancement. However, existing methods tend to remove shadows with constant color background and ignore color shadows. In this paper, we first design a diffusion model in latent space for document image shadow removal, called DocShaDiffusion. It translates shadow images from pixel space to latent space, enabling the model to more easily capture essential features. To address the issue of color shadows, we design a shadow soft-mask generation module (SSGM). It is able to produce accurate shadow mask and add noise into shadow regions specially. Guided by the shadow mask, a shadow mask-aware guided diffusion module (SMGDM) is proposed to remove shadows from document images by supervising the diffusion and denoising process. We also propose a shadow-robust perceptual feature loss to preserve details and structures in document images. Moreover, we develop a large-scale synthetic document color shadow removal dataset (SDCSRD). It simulates the distribution of realistic color shadows and provides powerful supports for the training of models. Experiments on three public datasets validate the proposed method's superiority over state-of-the-art. Our code and dataset will be publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01422v1",
    "published_date": "2025-07-02 07:22:09 UTC",
    "updated_date": "2025-07-02 07:22:09 UTC"
  },
  {
    "arxiv_id": "2507.01418v1",
    "title": "Penalizing Transparency? How AI Disclosure and Author Demographics Shape Human and AI Judgments About Writing",
    "authors": [
      "Inyoung Cheong",
      "Alicia Guo",
      "Mina Lee",
      "Zhehui Liao",
      "Kowe Kadoma",
      "Dongyoung Go",
      "Joseph Chee Chang",
      "Peter Henderson",
      "Mor Naaman",
      "Amy X. Zhang"
    ],
    "abstract": "As AI integrates in various types of human writing, calls for transparency around AI assistance are growing. However, if transparency operates on uneven ground and certain identity groups bear a heavier cost for being honest, then the burden of openness becomes asymmetrical. This study investigates how AI disclosure statement affects perceptions of writing quality, and whether these effects vary by the author's race and gender. Through a large-scale controlled experiment, both human raters (n = 1,970) and LLM raters (n = 2,520) evaluated a single human-written news article while disclosure statements and author demographics were systematically varied. This approach reflects how both human and algorithmic decisions now influence access to opportunities (e.g., hiring, promotion) and social recognition (e.g., content recommendation algorithms). We find that both human and LLM raters consistently penalize disclosed AI use. However, only LLM raters exhibit demographic interaction effects: they favor articles attributed to women or Black authors when no disclosure is present. But these advantages disappear when AI assistance is revealed. These findings illuminate the complex relationships between AI disclosure and author identity, highlighting disparities between machine and human evaluation patterns.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Presented at CHIWORK 2025 Workshop on Generative AI Disclosure, Ownership, and Accountability in Co-Creative Domains",
    "pdf_url": "https://arxiv.org/pdf/2507.01418v1",
    "published_date": "2025-07-02 07:18:09 UTC",
    "updated_date": "2025-07-02 07:18:09 UTC"
  },
  {
    "arxiv_id": "2507.01413v1",
    "title": "Evaluating LLM Agent Collusion in Double Auctions",
    "authors": [
      "Kushal Agrawal",
      "Verona Teo",
      "Juan J. Vazquez",
      "Sudarsh Kunnavakkam",
      "Vishak Srikanth",
      "Andy Liu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities as autonomous agents with rapidly expanding applications in various domains. As these agents increasingly engage in socioeconomic interactions, identifying their potential for undesirable behavior becomes essential. In this work, we examine scenarios where they can choose to collude, defined as secretive cooperation that harms another party. To systematically study this, we investigate the behavior of LLM agents acting as sellers in simulated continuous double auction markets. Through a series of controlled experiments, we analyze how parameters such as the ability to communicate, choice of model, and presence of environmental pressures affect the stability and emergence of seller collusion. We find that direct seller communication increases collusive tendencies, the propensity to collude varies across models, and environmental pressures, such as oversight and urgency from authority figures, influence collusive behavior. Our findings highlight important economic and ethical considerations for the deployment of LLM-based market agents.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01413v1",
    "published_date": "2025-07-02 07:06:49 UTC",
    "updated_date": "2025-07-02 07:06:49 UTC"
  },
  {
    "arxiv_id": "2507.01411v1",
    "title": "Age Sensitive Hippocampal Functional Connectivity: New Insights from 3D CNNs and Saliency Mapping",
    "authors": [
      "Yifei Sun",
      "Marshall A. Dalton",
      "Robert D. Sanders",
      "Yixuan Yuan",
      "Xiang Li",
      "Sharon L. Naismith",
      "Fernando Calamante",
      "Jinglei Lv"
    ],
    "abstract": "Grey matter loss in the hippocampus is a hallmark of neurobiological aging, yet understanding the corresponding changes in its functional connectivity remains limited. Seed-based functional connectivity (FC) analysis enables voxel-wise mapping of the hippocampus's synchronous activity with cortical regions, offering a window into functional reorganization during aging. In this study, we develop an interpretable deep learning framework to predict brain age from hippocampal FC using a three-dimensional convolutional neural network (3D CNN) combined with LayerCAM saliency mapping. This approach maps key hippocampal-cortical connections, particularly with the precuneus, cuneus, posterior cingulate cortex, parahippocampal cortex, left superior parietal lobule, and right superior temporal sulcus, that are highly sensitive to age. Critically, disaggregating anterior and posterior hippocampal FC reveals distinct mapping aligned with their known functional specializations. These findings provide new insights into the functional mechanisms of hippocampal aging and demonstrate the power of explainable deep learning to uncover biologically meaningful patterns in neuroimaging data.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01411v1",
    "published_date": "2025-07-02 07:05:18 UTC",
    "updated_date": "2025-07-02 07:05:18 UTC"
  },
  {
    "arxiv_id": "2507.01410v2",
    "title": "A Fuzzy Approach to the Specification, Verification and Validation of Risk-Based Ethical Decision Making Models",
    "authors": [
      "Abeer Dyoub",
      "Francesca A. Lisi"
    ],
    "abstract": "The ontological and epistemic complexities inherent in the moral domain make it challenging to establish clear standards for evaluating the performance of a moral machine. In this paper, we present a formal method to describe Ethical Decision Making models based on ethical risk assessment. Then, we show how these models that are specified as fuzzy rules can be verified and validated using fuzzy Petri nets. A case study from the medical field is considered to illustrate the proposed approach.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01410v2",
    "published_date": "2025-07-02 07:05:11 UTC",
    "updated_date": "2025-07-13 09:38:44 UTC"
  },
  {
    "arxiv_id": "2507.01401v1",
    "title": "Medical-Knowledge Driven Multiple Instance Learning for Classifying Severe Abdominal Anomalies on Prenatal Ultrasound",
    "authors": [
      "Huanwen Liang",
      "Jingxian Xu",
      "Yuanji Zhang",
      "Yuhao Huang",
      "Yuhan Zhang",
      "Xin Yang",
      "Ran Li",
      "Xuedong Deng",
      "Yanjun Liu",
      "Guowei Tao",
      "Yun Wu",
      "Sheng Zhao",
      "Xinru Gao",
      "Dong Ni"
    ],
    "abstract": "Fetal abdominal malformations are serious congenital anomalies that require accurate diagnosis to guide pregnancy management and reduce mortality. Although AI has demonstrated significant potential in medical diagnosis, its application to prenatal abdominal anomalies remains limited. Most existing studies focus on image-level classification and rely on standard plane localization, placing less emphasis on case-level diagnosis. In this paper, we develop a case-level multiple instance learning (MIL)-based method, free of standard plane localization, for classifying fetal abdominal anomalies in prenatal ultrasound. Our contribution is three-fold. First, we adopt a mixture-of-attention-experts module (MoAE) to weight different attention heads for various planes. Secondly, we propose a medical-knowledge-driven feature selection module (MFS) to align image features with medical knowledge, performing self-supervised image token selection at the case-level. Finally, we propose a prompt-based prototype learning (PPL) to enhance the MFS. Extensively validated on a large prenatal abdominal ultrasound dataset containing 2,419 cases, with a total of 24,748 images and 6 categories, our proposed method outperforms the state-of-the-art competitors. Codes are available at:https://github.com/LL-AC/AAcls.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by MICCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.01401v1",
    "published_date": "2025-07-02 06:31:26 UTC",
    "updated_date": "2025-07-02 06:31:26 UTC"
  },
  {
    "arxiv_id": "2507.01381v3",
    "title": "Distributional Soft Actor-Critic with Diffusion Policy",
    "authors": [
      "Tong Liu",
      "Yinuo Wang",
      "Xujie Song",
      "Wenjun Zou",
      "Liangfa Chen",
      "Likun Wang",
      "Bin Shuai",
      "Jingliang Duan",
      "Shengbo Eben Li"
    ],
    "abstract": "Reinforcement learning has been proven to be highly effective in handling complex control tasks. Traditional methods typically use unimodal distributions, such as Gaussian distributions, to model the output of value distributions. However, unimodal distribution often and easily causes bias in value function estimation, leading to poor algorithm performance. This paper proposes a distributional reinforcement learning algorithm called DSAC-D (Distributed Soft Actor Critic with Diffusion Policy) to address the challenges of estimating bias in value functions and obtaining multimodal policy representations. A multimodal distributional policy iteration framework that can converge to the optimal policy was established by introducing policy entropy and value distribution function. A diffusion value network that can accurately characterize the distribution of multi peaks was constructed by generating a set of reward samples through reverse sampling using a diffusion model. Based on this, a distributional reinforcement learning algorithm with dual diffusion of the value network and the policy network was derived. MuJoCo testing tasks demonstrate that the proposed algorithm not only learns multimodal policy, but also achieves state-of-the-art (SOTA) performance in all 9 control tasks, with significant suppression of estimation bias and total average return improvement of over 10% compared to existing mainstream algorithms. The results of real vehicle testing show that DSAC-D can accurately characterize the multimodal distribution of different driving styles, and the diffusion policy network can characterize multimodal trajectories.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted IEEE ITSC 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.01381v3",
    "published_date": "2025-07-02 05:50:10 UTC",
    "updated_date": "2025-07-11 03:34:59 UTC"
  },
  {
    "arxiv_id": "2507.01378v2",
    "title": "RALLY: Role-Adaptive LLM-Driven Yoked Navigation for Agentic UAV Swarms",
    "authors": [
      "Ziyao Wang",
      "Rongpeng Li",
      "Sizhao Li",
      "Yuming Xiang",
      "Haiping Wang",
      "Zhifeng Zhao",
      "Honggang Zhang"
    ],
    "abstract": "Intelligent control of Unmanned Aerial Vehicles (UAVs) swarms has emerged as a critical research focus, and it typically requires the swarm to navigate effectively while avoiding obstacles and achieving continuous coverage over multiple mission targets. Although traditional Multi-Agent Reinforcement Learning (MARL) approaches offer dynamic adaptability, they are hindered by the semantic gap in numerical communication and the rigidity of homogeneous role structures, resulting in poor generalization and limited task scalability. Recent advances in Large Language Model (LLM)-based control frameworks demonstrate strong semantic reasoning capabilities by leveraging extensive prior knowledge. However, due to the lack of online learning and over-reliance on static priors, these works often struggle with effective exploration, leading to reduced individual potential and overall system performance. To address these limitations, we propose a Role-Adaptive LLM-Driven Yoked navigation algorithm RALLY. Specifically, we first develop an LLM-driven semantic decision framework that uses structured natural language for efficient semantic communication and collaborative reasoning. Afterward, we introduce a dynamic role-heterogeneity mechanism for adaptive role switching and personalized decision-making. Furthermore, we propose a Role-value Mixing Network (RMIX)-based assignment strategy that integrates LLM offline priors with MARL online policies to enable semi-offline training of role selection strategies. Experiments in the Multi-Agent Particle Environment (MPE) environment and a Software-In-The-Loop (SITL) platform demonstrate that RALLY outperforms conventional approaches in terms of task coverage, convergence speed, and generalization, highlighting its strong potential for collaborative navigation in agentic multi-UAV systems.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01378v2",
    "published_date": "2025-07-02 05:44:17 UTC",
    "updated_date": "2025-09-01 13:53:03 UTC"
  },
  {
    "arxiv_id": "2507.01376v1",
    "title": "AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing",
    "authors": [
      "Yinwang Ren",
      "Yangyang Liu",
      "Tang Ji",
      "Xun Xu"
    ],
    "abstract": "AI agents are autonomous systems designed to perceive, reason, and act within dynamic environments. With the rapid advancements in generative AI (GenAI), large language models (LLMs) and multimodal large language models (MLLMs) have significantly improved AI agents' capabilities in semantic comprehension, complex reasoning, and autonomous decision-making. At the same time, the rise of Agentic AI highlights adaptability and goal-directed autonomy in dynamic and complex environments. LLMs-based AI Agents (LLM-Agents), MLLMs-based AI Agents (MLLM-Agents), and Agentic AI contribute to expanding AI's capabilities in information processing, environmental perception, and autonomous decision-making, opening new avenues for smart manufacturing. However, the definitions, capability boundaries, and practical applications of these emerging AI paradigms in smart manufacturing remain unclear. To address this gap, this study systematically reviews the evolution of AI and AI agent technologies, examines the core concepts and technological advancements of LLM-Agents, MLLM-Agents, and Agentic AI, and explores their potential applications in and integration into manufacturing, along with the potential challenges they may face.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to JMS(March 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.01376v1",
    "published_date": "2025-07-02 05:31:17 UTC",
    "updated_date": "2025-07-02 05:31:17 UTC"
  },
  {
    "arxiv_id": "2507.01352v2",
    "title": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy",
    "authors": [
      "Chris Yuhao Liu",
      "Liang Zeng",
      "Yuzhen Xiao",
      "Jujie He",
      "Jiacai Liu",
      "Chaojie Wang",
      "Rui Yan",
      "Wei Shen",
      "Fuxiang Zhang",
      "Jiacheng Xu",
      "Yang Liu",
      "Yahui Zhou"
    ],
    "abstract": "Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches that incorporate advanced training techniques have not yielded meaningful performance improvements. We hypothesize that this brittleness stems primarily from limitations in preference datasets, which are often narrowly scoped, synthetically labeled, or lack rigorous quality control. To address these challenges, we present a large-scale preference dataset comprising 40 million preference pairs, named SynPref-40M. To enable data curation at scale, we design a human-AI synergistic two-stage pipeline that leverages the complementary strengths of human annotation quality and AI scalability. In this pipeline, humans provide verified annotations, while large language models perform automatic curation based on human guidance. Training on this preference mixture, we introduce Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B parameters, trained on a carefully curated subset of 26 million preference pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile across a wide range of capabilities, including alignment with human preferences, objective correctness, safety, resistance to stylistic biases, and best-of-N scaling, achieving state-of-the-art performance across seven major reward model benchmarks. Ablation studies confirm that the effectiveness of our approach stems not only from data scale but also from high-quality curation. The Skywork-Reward-V2 series represents substantial progress in open reward models, highlighting the untapped potential of existing preference datasets and demonstrating how human-AI curation synergy can unlock significantly higher data quality.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01352v2",
    "published_date": "2025-07-02 04:40:29 UTC",
    "updated_date": "2025-07-03 05:58:40 UTC"
  },
  {
    "arxiv_id": "2507.01339v1",
    "title": "User-guided Generative Source Separation",
    "authors": [
      "Yutong Wen",
      "Minje Kim",
      "Paris Smaragdis"
    ],
    "abstract": "Music source separation (MSS) aims to extract individual instrument sources from their mixture. While most existing methods focus on the widely adopted four-stem separation setup (vocals, bass, drums, and other instruments), this approach lacks the flexibility needed for real-world applications. To address this, we propose GuideSep, a diffusion-based MSS model capable of instrument-agnostic separation beyond the four-stem setup. GuideSep is conditioned on multiple inputs: a waveform mimicry condition, which can be easily provided by humming or playing the target melody, and mel-spectrogram domain masks, which offer additional guidance for separation. Unlike prior approaches that relied on fixed class labels or sound queries, our conditioning scheme, coupled with the generative approach, provides greater flexibility and applicability. Additionally, we design a mask-prediction baseline using the same model architecture to systematically compare predictive and generative approaches. Our objective and subjective evaluations demonstrate that GuideSep achieves high-quality separation while enabling more versatile instrument extraction, highlighting the potential of user participation in the diffusion-based generative process for MSS. Our code and demo page are available at https://yutongwen.github.io/GuideSep/",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01339v1",
    "published_date": "2025-07-02 03:58:52 UTC",
    "updated_date": "2025-07-02 03:58:52 UTC"
  },
  {
    "arxiv_id": "2507.01335v2",
    "title": "Reverse Language Model",
    "authors": [
      "Xunjian Yin",
      "Sitao Cheng",
      "Yuxi Xie",
      "Xinyu Hu",
      "Li Lin",
      "Xinyi Wang",
      "Liangming Pan",
      "William Yang Wang",
      "Xiaojun Wan"
    ],
    "abstract": "We introduce LEDOM, the first purely reverse language model, trained autoregressively on 435B tokens with 2B and 7B parameter variants, which processes sequences in reverse temporal order through previous token prediction. For the first time, we present the reverse language model as a potential foundational model across general tasks, accompanied by a set of intriguing examples and insights. Based on LEDOM, we further introduce a novel application: Reverse Reward, where LEDOM-guided reranking of forward language model outputs leads to substantial performance improvements on mathematical reasoning tasks. This approach leverages LEDOM's unique backward reasoning capability to refine generation quality through posterior evaluation. Our findings suggest that LEDOM exhibits unique characteristics with broad application potential. We will release all models, training code, and pre-training data to facilitate future research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress; Models can be found at: https://huggingface.co/Corning/Reverse-Model-7B-348B/tree/main",
    "pdf_url": "https://arxiv.org/pdf/2507.01335v2",
    "published_date": "2025-07-02 03:52:00 UTC",
    "updated_date": "2026-01-07 22:42:53 UTC"
  },
  {
    "arxiv_id": "2507.01327v1",
    "title": "Reasoner for Real-World Event Detection: Scaling Reinforcement Learning via Adaptive Perplexity-Aware Sampling Strategy",
    "authors": [
      "Xiaoyun Zhang",
      "Jingqing Ruan",
      "Xing Ma",
      "Yawen Zhu",
      "Jiansong Chen",
      "Ke Zeng",
      "Xunliang Cai"
    ],
    "abstract": "Detecting abnormal events in real-world customer service dialogues is highly challenging due to the complexity of business data and the dynamic nature of customer interactions. Moreover, models must demonstrate strong out-of-domain (OOD) generalization to enable rapid adaptation across different business scenarios and maximize commercial value. In this work, we propose a novel Adaptive Perplexity-Aware Reinforcement Learning (APARL) framework that leverages the advanced reasoning capabilities of large language models for abnormal event detection. APARL introduces a dual-loop dynamic curriculum learning architecture, enabling the model to progressively focus on more challenging samples as its proficiency increases. This design effectively addresses performance bottlenecks and significantly enhances OOD transferability. Extensive evaluations on food delivery dialogue tasks show that our model achieves significantly enhanced adaptability and robustness, attaining the highest F1 score with an average improvement of 17.19\\%, and an average improvement of 9.59\\% in OOD transfer tests. This method provides a superior solution for industrial deployment of anomaly detection models, contributing to improved operational efficiency and commercial benefits.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 6 figures, submitted to EMNLP",
    "pdf_url": "https://arxiv.org/pdf/2507.01327v1",
    "published_date": "2025-07-02 03:26:02 UTC",
    "updated_date": "2025-07-02 03:26:02 UTC"
  },
  {
    "arxiv_id": "2507.01321v1",
    "title": "ICLShield: Exploring and Mitigating In-Context Learning Backdoor Attacks",
    "authors": [
      "Zhiyao Ren",
      "Siyuan Liang",
      "Aishan Liu",
      "Dacheng Tao"
    ],
    "abstract": "In-context learning (ICL) has demonstrated remarkable success in large language models (LLMs) due to its adaptability and parameter-free nature. However, it also introduces a critical vulnerability to backdoor attacks, where adversaries can manipulate LLM behaviors by simply poisoning a few ICL demonstrations. In this paper, we propose, for the first time, the dual-learning hypothesis, which posits that LLMs simultaneously learn both the task-relevant latent concepts and backdoor latent concepts within poisoned demonstrations, jointly influencing the probability of model outputs. Through theoretical analysis, we derive an upper bound for ICL backdoor effects, revealing that the vulnerability is dominated by the concept preference ratio between the task and the backdoor. Motivated by these findings, we propose ICLShield, a defense mechanism that dynamically adjusts the concept preference ratio. Our method encourages LLMs to select clean demonstrations during the ICL phase by leveraging confidence and similarity scores, effectively mitigating susceptibility to backdoor attacks. Extensive experiments across multiple LLMs and tasks demonstrate that our method achieves state-of-the-art defense effectiveness, significantly outperforming existing approaches (+26.02% on average). Furthermore, our method exhibits exceptional adaptability and defensive performance even for closed-source models (e.g., GPT-4).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.01321v1",
    "published_date": "2025-07-02 03:09:20 UTC",
    "updated_date": "2025-07-02 03:09:20 UTC"
  },
  {
    "arxiv_id": "2507.01313v1",
    "title": "Neural Hamiltonian Operator",
    "authors": [
      "Qian Qi"
    ],
    "abstract": "Stochastic control problems in high dimensions are notoriously difficult to solve due to the curse of dimensionality. An alternative to traditional dynamic programming is Pontryagin's Maximum Principle (PMP), which recasts the problem as a system of Forward-Backward Stochastic Differential Equations (FBSDEs). In this paper, we introduce a formal framework for solving such problems with deep learning by defining a \\textbf{Neural Hamiltonian Operator (NHO)}. This operator parameterizes the coupled FBSDE dynamics via neural networks that represent the feedback control and an ansatz for the value function's spatial gradient. We show how the optimal NHO can be found by training the underlying networks to enforce the consistency conditions dictated by the PMP. By adopting this operator-theoretic view, we situate the deep FBSDE method within the rigorous language of statistical inference, framing it as a problem of learning an unknown operator from simulated data. This perspective allows us to prove the universal approximation capabilities of NHOs under general martingale drivers and provides a clear lens for analyzing the significant optimization challenges inherent to this class of models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DS",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01313v1",
    "published_date": "2025-07-02 02:56:49 UTC",
    "updated_date": "2025-07-02 02:56:49 UTC"
  },
  {
    "arxiv_id": "2507.03002v1",
    "title": "Game-Theoretic Modeling of Vehicle Unprotected Left Turns Considering Drivers' Bounded Rationality",
    "authors": [
      "Yuansheng Lian",
      "Ke Zhang",
      "Meng Li",
      "Shen Li"
    ],
    "abstract": "Modeling the decision-making behavior of vehicles presents unique challenges, particularly during unprotected left turns at intersections, where the uncertainty of human drivers is especially pronounced. In this context, connected autonomous vehicle (CAV) technology emerges as a promising avenue for effectively managing such interactions while ensuring safety and efficiency. Traditional approaches, often grounded in game theory assumptions of perfect rationality, may inadequately capture the complexities of real-world scenarios and drivers' decision-making errors. To fill this gap, we propose a novel decision-making model for vehicle unprotected left-turn scenarios, integrating game theory with considerations for drivers' bounded rationality. Our model, formulated as a two-player normal-form game solved by a quantal response equilibrium (QRE), offers a more nuanced depiction of driver decision-making processes compared to Nash equilibrium (NE) models. Leveraging an Expectation-Maximization (EM) algorithm coupled with a subtle neural network trained on precise microscopic vehicle trajectory data, we optimize model parameters to accurately reflect drivers' interaction-aware bounded rationality and driving styles. Through comprehensive simulation experiments, we demonstrate the efficacy of our proposed model in capturing the interaction-aware bounded rationality and decision tendencies between players. The proposed model proves to be more realistic and efficient than NE models in unprotected left-turn scenarios. Our findings contribute valuable insights into the vehicle decision-making behaviors with bounded rationality, thereby informing the development of more robust and realistic autonomous driving systems.",
    "categories": [
      "eess.SY",
      "cs.AI"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.03002v1",
    "published_date": "2025-07-02 02:22:11 UTC",
    "updated_date": "2025-07-02 02:22:11 UTC"
  },
  {
    "arxiv_id": "2507.01284v1",
    "title": "VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process",
    "authors": [
      "Cristian Gariboldi",
      "Hayato Tokida",
      "Ken Kinjo",
      "Yuki Asada",
      "Alexander Carballo"
    ],
    "abstract": "Recent advancements in open-source Visual Language Models (VLMs) such as LLaVA, Qwen-VL, and Llama have catalyzed extensive research on their integration with diverse systems. The internet-scale general knowledge encapsulated within these models presents significant opportunities for enhancing autonomous driving perception, prediction, and planning capabilities. In this paper we propose VLAD, a vision-language autonomous driving model, which integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end system. We implement a specialized fine-tuning approach using custom question-answer datasets designed specifically to improve the spatial reasoning capabilities of the model. The enhanced VLM generates high-level navigational commands that VAD subsequently processes to guide vehicle operation. Additionally, our system produces interpretable natural language explanations of driving decisions, thereby increasing transparency and trustworthiness of the traditionally black-box end-to-end architecture. Comprehensive evaluation on the real-world nuScenes dataset demonstrates that our integrated system reduces average collision rates by 31.82% compared to baseline methodologies, establishing a new benchmark for VLM-augmented autonomous driving systems.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "2025 IEEE 28th International Conference on Intelligent Transportation Systems (ITSC)",
    "pdf_url": "https://arxiv.org/pdf/2507.01284v1",
    "published_date": "2025-07-02 01:52:40 UTC",
    "updated_date": "2025-07-02 01:52:40 UTC"
  },
  {
    "arxiv_id": "2507.01282v1",
    "title": "Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care",
    "authors": [
      "Matthew JY Kang",
      "Wenli Yang",
      "Monica R Roberts",
      "Byeong Ho Kang",
      "Charles B Malpas"
    ],
    "abstract": "The recent boom of large language models (LLMs) has re-ignited the hope that artificial intelligence (AI) systems could aid medical diagnosis. Yet despite dazzling benchmark scores, LLM assistants have yet to deliver measurable improvements at the bedside. This scoping review aims to highlight the areas where AI is limited to make practical contributions in the clinical setting, specifically in dementia diagnosis and care.\n  Standalone machine-learning models excel at pattern recognition but seldom provide actionable, interpretable guidance, eroding clinician trust. Adjacent use of LLMs by physicians did not result in better diagnostic accuracy or speed. Key limitations trace to the data-driven paradigm: black-box outputs which lack transparency, vulnerability to hallucinations, and weak causal reasoning. Hybrid approaches that combine statistical learning with expert rule-based knowledge, and involve clinicians throughout the process help bring back interpretability. They also fit better with existing clinical workflows, as seen in examples like PEIRS and ATHENA-CDS.\n  Future decision-support should prioritise explanatory coherence by linking predictions to clinically meaningful causes. This can be done through neuro-symbolic or hybrid AI that combines the language ability of LLMs with human causal expertise. AI researchers have addressed this direction, with explainable AI and neuro-symbolic AI being the next logical steps in further advancement in AI. However, they are still based on data-driven knowledge integration instead of human-in-the-loop approaches. Future research should measure success not only by accuracy but by improvements in clinician understanding, workflow fit, and patient outcomes. A better understanding of what helps improve human-computer interactions is greatly needed for AI systems to become part of clinical practice.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01282v1",
    "published_date": "2025-07-02 01:43:06 UTC",
    "updated_date": "2025-07-02 01:43:06 UTC"
  },
  {
    "arxiv_id": "2507.01281v1",
    "title": "Rethinking All Evidence: Enhancing Trustworthy Retrieval-Augmented Generation via Conflict-Driven Summarization",
    "authors": [
      "Juan Chen",
      "Baolong Bi",
      "Wei Zhang",
      "Jingyan Sui",
      "Xiaofei Zhu",
      "Yuanzhuo Wang",
      "Lingrui Mei",
      "Shenghua Liu"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by integrating their parametric knowledge with external retrieved content. However, knowledge conflicts caused by internal inconsistencies or noisy retrieved content can severely undermine the generation reliability of RAG systems.In this work, we argue that LLMs should rethink all evidence, including both retrieved content and internal knowledge, before generating responses.We propose CARE-RAG (Conflict-Aware and Reliable Evidence for RAG), a novel framework that improves trustworthiness through Conflict-Driven Summarization of all available evidence.CARE-RAG first derives parameter-aware evidence by comparing parameter records to identify diverse internal perspectives. It then refines retrieved evidences to produce context-aware evidence, removing irrelevant or misleading content. To detect and summarize conflicts, we distill a 3B LLaMA3.2 model to perform conflict-driven summarization, enabling reliable synthesis across multiple sources.To further ensure evaluation integrity, we introduce a QA Repair step to correct outdated or ambiguous benchmark answers.Experiments on revised QA datasets with retrieval data show that CARE-RAG consistently outperforms strong RAG baselines, especially in scenarios with noisy or conflicting evidence.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01281v1",
    "published_date": "2025-07-02 01:39:49 UTC",
    "updated_date": "2025-07-02 01:39:49 UTC"
  },
  {
    "arxiv_id": "2507.01274v1",
    "title": "AI Meets Maritime Training: Precision Analytics for Enhanced Safety and Performance",
    "authors": [
      "Vishakha Lall",
      "Yisi Liu"
    ],
    "abstract": "Traditional simulator-based training for maritime professionals is critical for ensuring safety at sea but often depends on subjective trainer assessments of technical skills, behavioral focus, communication, and body language, posing challenges such as subjectivity, difficulty in measuring key features, and cognitive limitations. Addressing these issues, this study develops an AI-driven framework to enhance maritime training by objectively assessing trainee performance through visual focus tracking, speech recognition, and stress detection, improving readiness for high-risk scenarios. The system integrates AI techniques, including visual focus determination using eye tracking, pupil dilation analysis, and computer vision; communication analysis through a maritime-specific speech-to-text model and natural language processing; communication correctness using large language models; and mental stress detection via vocal pitch. Models were evaluated on data from simulated maritime scenarios with seafarers exposed to controlled high-stress events. The AI algorithms achieved high accuracy, with ~92% for visual detection, ~91% for maritime speech recognition, and ~90% for stress detection, surpassing existing benchmarks. The system provides insights into visual attention, adherence to communication checklists, and stress levels under demanding conditions. This study demonstrates how AI can transform maritime training by delivering objective performance analytics, enabling personalized feedback, and improving preparedness for real-world operational challenges.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted and Presented at 11th International Maritime Science Conference",
    "pdf_url": "https://arxiv.org/pdf/2507.01274v1",
    "published_date": "2025-07-02 01:19:32 UTC",
    "updated_date": "2025-07-02 01:19:32 UTC"
  },
  {
    "arxiv_id": "2507.01271v4",
    "title": "PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning",
    "authors": [
      "Tatsuki Kawakami",
      "Kazuki Egashira",
      "Atsuyuki Miyai",
      "Go Irie",
      "Kiyoharu Aizawa"
    ],
    "abstract": "In recent years, unlearning techniques, which are methods for inducing a model to \"forget\" previously learned information, have attracted attention as a way to address privacy and copyright concerns in large language models (LLMs) and large multimodal models (LMMs). While several unlearning benchmarks have been established for LLMs, a practical evaluation framework for unlearning in LMMs has been less explored. Specifically, existing unlearning benchmark for LMMs considers only scenarios in which the model is required to unlearn fine-tuned knowledge through a single unlearning operation. In this study, we introduce PULSE protocol for realistic unlearning scenarios for LMMs by introducing two critical perspectives: (i) Pre-trained knowledge Unlearning for analyzing the effect across different knowledge acquisition phases and (ii) Long-term Sustainability Evaluation to address sequential requests. We then evaluate existing unlearning methods along these dimensions. Our results reveal that, although some techniques can successfully unlearn knowledge acquired through fine-tuning, they struggle to eliminate information learned during pre-training. Moreover, methods that effectively unlearn a batch of target data in a single operation exhibit substantial performance degradation when the same data are split and unlearned sequentially.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2025 Workshop: Evaluating the Evolving LLM Lifecycle",
    "pdf_url": "https://arxiv.org/pdf/2507.01271v4",
    "published_date": "2025-07-02 01:13:08 UTC",
    "updated_date": "2025-10-28 08:11:23 UTC"
  },
  {
    "arxiv_id": "2507.03001v1",
    "title": "Evaluating Hierarchical Clinical Document Classification Using Reasoning-Based LLMs",
    "authors": [
      "Akram Mustafa",
      "Usman Naseem",
      "Mostafa Rahimi Azghadi"
    ],
    "abstract": "This study evaluates how well large language models (LLMs) can classify ICD-10 codes from hospital discharge summaries, a critical but error-prone task in healthcare. Using 1,500 summaries from the MIMIC-IV dataset and focusing on the 10 most frequent ICD-10 codes, the study tested 11 LLMs, including models with and without structured reasoning capabilities. Medical terms were extracted using a clinical NLP tool (cTAKES), and models were prompted in a consistent, coder-like format. None of the models achieved an F1 score above 57%, with performance dropping as code specificity increased. Reasoning-based models generally outperformed non-reasoning ones, with Gemini 2.5 Pro performing best overall. Some codes, such as those related to chronic heart disease, were classified more accurately than others. The findings suggest that while LLMs can assist human coders, they are not yet reliable enough for full automation. Future work should explore hybrid methods, domain-specific model training, and the use of structured clinical data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.03001v1",
    "published_date": "2025-07-02 00:53:54 UTC",
    "updated_date": "2025-07-02 00:53:54 UTC"
  },
  {
    "arxiv_id": "2507.01264v1",
    "title": "LLM-based Realistic Safety-Critical Driving Video Generation",
    "authors": [
      "Yongjie Fu",
      "Ruijian Zha",
      "Pei Tian",
      "Xuan Di"
    ],
    "abstract": "Designing diverse and safety-critical driving scenarios is essential for evaluating autonomous driving systems. In this paper, we propose a novel framework that leverages Large Language Models (LLMs) for few-shot code generation to automatically synthesize driving scenarios within the CARLA simulator, which has flexibility in scenario scripting, efficient code-based control of traffic participants, and enforcement of realistic physical dynamics. Given a few example prompts and code samples, the LLM generates safety-critical scenario scripts that specify the behavior and placement of traffic participants, with a particular focus on collision events. To bridge the gap between simulation and real-world appearance, we integrate a video generation pipeline using Cosmos-Transfer1 with ControlNet, which converts rendered scenes into realistic driving videos. Our approach enables controllable scenario generation and facilitates the creation of rare but critical edge cases, such as pedestrian crossings under occlusion or sudden vehicle cut-ins. Experimental results demonstrate the effectiveness of our method in generating a wide range of realistic, diverse, and safety-critical scenarios, offering a promising tool for simulation-based testing of autonomous vehicles.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01264v1",
    "published_date": "2025-07-02 00:45:19 UTC",
    "updated_date": "2025-07-02 00:45:19 UTC"
  },
  {
    "arxiv_id": "2507.01259v1",
    "title": "GAIus: Combining Genai with Legal Clauses Retrieval for Knowledge-based Assistant",
    "authors": [
      "Michał Matak",
      "Jarosław A. Chudziak"
    ],
    "abstract": "In this paper we discuss the capability of large language models to base their answer and provide proper references when dealing with legal matters of non-english and non-chinese speaking country. We discuss the history of legal information retrieval, the difference between case law and statute law, its impact on the legal tasks and analyze the latest research in this field. Basing on that background we introduce gAIus, the architecture of the cognitive LLM-based agent, whose responses are based on the knowledge retrieved from certain legal act, which is Polish Civil Code. We propose a retrieval mechanism which is more explainable, human-friendly and achieves better results than embedding-based approaches. To evaluate our method we create special dataset based on single-choice questions from entrance exams for law apprenticeships conducted in Poland. The proposed architecture critically leveraged the abilities of used large language models, improving the gpt-3.5-turbo-0125 by 419%, allowing it to beat gpt-4o and lifting gpt-4o-mini score from 31% to 86%. At the end of our paper we show the possible future path of research and potential applications of our findings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 2 figures, presented at ICAART 2025, in proceedings of the 17th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART",
    "pdf_url": "https://arxiv.org/pdf/2507.01259v1",
    "published_date": "2025-07-02 00:36:27 UTC",
    "updated_date": "2025-07-02 00:36:27 UTC"
  }
]