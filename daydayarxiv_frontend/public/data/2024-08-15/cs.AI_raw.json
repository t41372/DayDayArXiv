[
  {
    "arxiv_id": "2408.08456v2",
    "title": "Distributional Drift Detection in Medical Imaging with Sketching and Fine-Tuned Transformer",
    "authors": [
      "Yusen Wu",
      "Phuong Nguyen",
      "Rose Yesha",
      "Yelena Yesha"
    ],
    "abstract": "Distributional drift detection is important in medical applications as it\nhelps ensure the accuracy and reliability of models by identifying changes in\nthe underlying data distribution that could affect the prediction results of\nmachine learning models. However, current methods have limitations in detecting\ndrift, for example, the inclusion of abnormal datasets can lead to unfair\ncomparisons. This paper presents an accurate and sensitive approach to detect\ndistributional drift in CT-scan medical images by leveraging data-sketching and\nfine-tuning techniques. We developed a robust baseline library model for\nreal-time anomaly detection, allowing for efficient comparison of incoming\nimages and identification of anomalies. Additionally, we fine-tuned a\npre-trained Vision Transformer model to extract relevant features, using\nmammography as a case study, significantly enhancing model accuracy to 99.11%.\nCombining with data-sketches and fine-tuning, our feature extraction evaluation\ndemonstrated that cosine similarity scores between similar datasets provide\ngreater improvements, from around 50% increased to 99.1%. Finally, the\nsensitivity evaluation shows that our solutions are highly sensitive to even 1%\nsalt-and-pepper and speckle noise, and it is not sensitive to lighting noise\n(e.g., lighting conditions have no impact on data drift). The proposed methods\noffer a scalable and reliable solution for maintaining the accuracy of\ndiagnostic models in dynamic clinical environments.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08456v2",
    "published_date": "2024-08-15 23:46:37 UTC",
    "updated_date": "2025-05-09 17:46:48 UTC"
  },
  {
    "arxiv_id": "2408.08447v1",
    "title": "SpectralEarth: Training Hyperspectral Foundation Models at Scale",
    "authors": [
      "Nassim Ait Ali Braham",
      "Conrad M Albrecht",
      "Julien Mairal",
      "Jocelyn Chanussot",
      "Yi Wang",
      "Xiao Xiang Zhu"
    ],
    "abstract": "Foundation models have triggered a paradigm shift in computer vision and are\nincreasingly being adopted in remote sensing, particularly for multispectral\nimagery. Yet, their potential in hyperspectral imaging (HSI) remains untapped\ndue to the absence of comprehensive and globally representative hyperspectral\ndatasets. To close this gap, we introduce SpectralEarth, a large-scale\nmulti-temporal dataset designed to pretrain hyperspectral foundation models\nleveraging data from the Environmental Mapping and Analysis Program (EnMAP).\nSpectralEarth comprises 538,974 image patches covering 415,153 unique locations\nfrom more than 11,636 globally distributed EnMAP scenes spanning two years of\narchive. Additionally, 17.5% of these locations include multiple timestamps,\nenabling multi-temporal HSI analysis. Utilizing state-of-the-art\nself-supervised learning (SSL) algorithms, we pretrain a series of foundation\nmodels on SpectralEarth. We integrate a spectral adapter into classical vision\nbackbones to accommodate the unique characteristics of HSI. In tandem, we\nconstruct four downstream datasets for land-cover and crop-type mapping,\nproviding benchmarks for model evaluation. Experimental results support the\nversatility of our models, showcasing their generalizability across different\ntasks and sensors. We also highlight computational efficiency during model\nfine-tuning. The dataset, models, and source code will be made publicly\navailable.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08447v1",
    "published_date": "2024-08-15 22:55:59 UTC",
    "updated_date": "2024-08-15 22:55:59 UTC"
  },
  {
    "arxiv_id": "2409.00012v1",
    "title": "AVIN-Chat: An Audio-Visual Interactive Chatbot System with Emotional State Tuning",
    "authors": [
      "Chanhyuk Park",
      "Jungbin Cho",
      "Junwan Kim",
      "Seongmin Lee",
      "Jungsu Kim",
      "Sanghoon Lee"
    ],
    "abstract": "This work presents an audio-visual interactive chatbot (AVIN-Chat) system\nthat allows users to have face-to-face conversations with 3D avatars in\nreal-time. Compared to the previous chatbot services, which provide text-only\nor speech-only communications, the proposed AVIN-Chat can offer audio-visual\ncommunications providing users with a superior experience quality. In addition,\nthe proposed AVIN-Chat emotionally speaks and expresses according to the user's\nemotional state. Thus, it enables users to establish a strong bond with the\nchatbot system, increasing the user's immersion. Through user subjective tests,\nit is demonstrated that the proposed system provides users with a higher sense\nof immersion than previous chatbot systems. The demonstration video is\navailable at https://www.youtube.com/watch?v=Z74uIV9k7_k.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00012v1",
    "published_date": "2024-08-15 22:45:53 UTC",
    "updated_date": "2024-08-15 22:45:53 UTC"
  },
  {
    "arxiv_id": "2408.08444v2",
    "title": "W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering",
    "authors": [
      "Jinming Nian",
      "Zhiyuan Peng",
      "Qifan Wang",
      "Yi Fang"
    ],
    "abstract": "In knowledge-intensive tasks such as open-domain question answering (OpenQA),\nlarge language models (LLMs) often struggle to generate factual answers,\nrelying solely on their internal (parametric) knowledge. To address this\nlimitation, Retrieval-Augmented Generation (RAG) systems enhance LLMs by\nretrieving relevant information from external sources, thereby positioning the\nretriever as a pivotal component. Although dense retrieval demonstrates\nstate-of-the-art performance, its training poses challenges due to the scarcity\nof ground-truth evidence, largely attributed to the high costs of human\nannotation. In this paper, we propose W-RAG, a method that draws weak training\nsignals from the downstream task (such as OpenQA) of an LLM, and fine-tunes the\nretriever to prioritize passages that most benefit the task. Specifically, we\nrerank the top-$k$ passages retrieved via BM25 by assessing the probability\nthat the LLM will generate the correct answer for a question given each\npassage. The highest-ranking passages are then used as positive fine-tuning\nexamples for dense retrieval. We conduct comprehensive experiments across four\npublicly available OpenQA datasets to demonstrate that our approach enhances\nboth retrieval and OpenQA performance compared to baseline models, achieving\nresults comparable to models fine-tuned with human-labeled data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08444v2",
    "published_date": "2024-08-15 22:34:44 UTC",
    "updated_date": "2025-04-25 18:01:29 UTC"
  },
  {
    "arxiv_id": "2408.10264v1",
    "title": "OPDR: Order-Preserving Dimension Reduction for Semantic Embedding of Multimodal Scientific Data",
    "authors": [
      "Chengyu Gong",
      "Gefei Shen",
      "Luanzheng Guo",
      "Nathan Tallent",
      "Dongfang Zhao"
    ],
    "abstract": "One of the most common operations in multimodal scientific data management is\nsearching for the $k$ most similar items (or, $k$-nearest neighbors, KNN) from\nthe database after being provided a new item. Although recent advances of\nmultimodal machine learning models offer a \\textit{semantic} index, the\nso-called \\textit{embedding vectors} mapped from the original multimodal data,\nthe dimension of the resulting embedding vectors are usually on the order of\nhundreds or a thousand, which are impractically high for time-sensitive\nscientific applications.\n  This work proposes to reduce the dimensionality of the output embedding\nvectors such that the set of top-$k$ nearest neighbors do not change in the\nlower-dimensional space, namely Order-Preserving Dimension Reduction (OPDR). In\norder to develop such an OPDR method, our central hypothesis is that by\nanalyzing the intrinsic relationship among key parameters during the\ndimension-reduction map, a quantitative function may be constructed to reveal\nthe correlation between the target (lower) dimensionality and other variables.\nTo demonstrate the hypothesis, this paper first defines a formal measure\nfunction to quantify the KNN similarity for a specific vector, then extends the\nmeasure into an aggregate accuracy of the global metric spaces, and finally\nderives a closed-form function between the target (lower) dimensionality and\nother variables. We incorporate the closed-function into popular\ndimension-reduction methods, various distance metrics, and embedding models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10264v1",
    "published_date": "2024-08-15 22:30:44 UTC",
    "updated_date": "2024-08-15 22:30:44 UTC"
  },
  {
    "arxiv_id": "2408.08437v1",
    "title": "PQV-Mobile: A Combined Pruning and Quantization Toolkit to Optimize Vision Transformers for Mobile Applications",
    "authors": [
      "Kshitij Bhardwaj"
    ],
    "abstract": "While Vision Transformers (ViTs) are extremely effective at computer vision\ntasks and are replacing convolutional neural networks as the new\nstate-of-the-art, they are complex and memory-intensive models. In order to\neffectively run these models on resource-constrained mobile/edge systems, there\nis a need to not only compress these models but also to optimize them and\nconvert them into deployment-friendly formats. To this end, this paper presents\na combined pruning and quantization tool, called PQV-Mobile, to optimize vision\ntransformers for mobile applications. The tool is able to support different\ntypes of structured pruning based on magnitude importance, Taylor importance,\nand Hessian importance. It also supports quantization from FP32 to FP16 and\nint8, targeting different mobile hardware backends. We demonstrate the\ncapabilities of our tool and show important latency-memory-accuracy trade-offs\nfor different amounts of pruning and int8 quantization with Facebook Data\nEfficient Image Transformer (DeiT) models. Our results show that even pruning a\nDeiT model by 9.375% and quantizing it to int8 from FP32 followed by optimizing\nfor mobile applications, we find a latency reduction by 7.18X with a small\naccuracy loss of 2.24%. The tool is open source.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08437v1",
    "published_date": "2024-08-15 22:10:10 UTC",
    "updated_date": "2024-08-15 22:10:10 UTC"
  },
  {
    "arxiv_id": "2408.08435v2",
    "title": "Automated Design of Agentic Systems",
    "authors": [
      "Shengran Hu",
      "Cong Lu",
      "Jeff Clune"
    ],
    "abstract": "Researchers are investing substantial effort in developing powerful\ngeneral-purpose agents, wherein Foundation Models are used as modules within\nagentic systems (e.g. Chain-of-Thought, Self-Reflection, Toolformer). However,\nthe history of machine learning teaches us that hand-designed solutions are\neventually replaced by learned solutions. We describe a newly forming research\narea, Automated Design of Agentic Systems (ADAS), which aims to automatically\ncreate powerful agentic system designs, including inventing novel building\nblocks and/or combining them in new ways. We further demonstrate that there is\nan unexplored yet promising approach within ADAS where agents can be defined in\ncode and new agents can be automatically discovered by a meta agent programming\never better ones in code. Given that programming languages are Turing Complete,\nthis approach theoretically enables the learning of any possible agentic\nsystem: including novel prompts, tool use, workflows, and combinations thereof.\nWe present a simple yet effective algorithm named Meta Agent Search to\ndemonstrate this idea, where a meta agent iteratively programs interesting new\nagents based on an ever-growing archive of previous discoveries. Through\nextensive experiments across multiple domains including coding, science, and\nmath, we show that our algorithm can progressively invent agents with novel\ndesigns that greatly outperform state-of-the-art hand-designed agents.\nImportantly, we consistently observe the surprising result that agents invented\nby Meta Agent Search maintain superior performance even when transferred across\ndomains and models, demonstrating their robustness and generality. Provided we\ndevelop it safely, our work illustrates the potential of an exciting new\nresearch direction toward automatically designing ever-more powerful agentic\nsystems to benefit humanity.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Website: https://shengranhu.com/ADAS",
    "pdf_url": "http://arxiv.org/pdf/2408.08435v2",
    "published_date": "2024-08-15 21:59:23 UTC",
    "updated_date": "2025-03-02 05:13:28 UTC"
  },
  {
    "arxiv_id": "2408.08432v1",
    "title": "Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts",
    "authors": [
      "Abdur R. Fayjie",
      "Jutika Borah",
      "Florencia Carbone",
      "Jan Tack",
      "Patrick Vandewalle"
    ],
    "abstract": "Deep learning has shown tremendous progress in a wide range of digital\npathology and medical image classification tasks. Its integration into safe\nclinical decision-making support requires robust and reliable models. However,\nreal-world data comes with diversities that often lie outside the intended\nsource distribution. Moreover, when test samples are dramatically different,\nclinical decision-making is greatly affected. Quantifying predictive\nuncertainty in models is crucial for well-calibrated predictions and\ndetermining when (or not) to trust a model. Unfortunately, many works have\noverlooked the importance of predictive uncertainty estimation. This paper\nevaluates whether predictive uncertainty estimation adds robustness to deep\nlearning-based diagnostic decision-making systems. We investigate the effect of\nvarious carcinoma distribution shift scenarios on predictive performance and\ncalibration. We first systematically investigate three popular methods for\nimproving predictive uncertainty: Monte Carlo dropout, deep ensemble, and\nfew-shot learning on lung adenocarcinoma classification as a primary disease in\nwhole slide images. Secondly, we compare the effectiveness of the methods in\nterms of performance and calibration under clinically relevant distribution\nshifts such as in-distribution shifts comprising primary disease sub-types and\nother characterization analysis data; out-of-distribution shifts comprising\nwell-differentiated cases, different organ origin, and imaging modality shifts.\nWhile studies on uncertainty estimation exist, to our best knowledge, no\nrigorous large-scale benchmark compares predictive uncertainty estimation\nincluding these dataset shifts for lung carcinoma classification.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "17 pages, 2 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.08432v1",
    "published_date": "2024-08-15 21:49:43 UTC",
    "updated_date": "2024-08-15 21:49:43 UTC"
  },
  {
    "arxiv_id": "2408.08431v1",
    "title": "Multi-Modal Dialogue State Tracking for Playing GuessWhich Game",
    "authors": [
      "Wei Pang",
      "Ruixue Duan",
      "Jinfu Yang",
      "Ning Li"
    ],
    "abstract": "GuessWhich is an engaging visual dialogue game that involves interaction\nbetween a Questioner Bot (QBot) and an Answer Bot (ABot) in the context of\nimage-guessing. In this game, QBot's objective is to locate a concealed image\nsolely through a series of visually related questions posed to ABot. However,\neffectively modeling visually related reasoning in QBot's decision-making\nprocess poses a significant challenge. Current approaches either lack visual\ninformation or rely on a single real image sampled at each round as decoding\ncontext, both of which are inadequate for visual reasoning. To address this\nlimitation, we propose a novel approach that focuses on visually related\nreasoning through the use of a mental model of the undisclosed image. Within\nthis framework, QBot learns to represent mental imagery, enabling robust visual\nreasoning by tracking the dialogue state. The dialogue state comprises a\ncollection of representations of mental imagery, as well as representations of\nthe entities involved in the conversation. At each round, QBot engages in\nvisually related reasoning using the dialogue state to construct an internal\nrepresentation, generate relevant questions, and update both the dialogue state\nand internal representation upon receiving an answer. Our experimental results\non the VisDial datasets (v0.5, 0.9, and 1.0) demonstrate the effectiveness of\nour proposed model, as it achieves new state-of-the-art performance across all\nmetrics and datasets, surpassing previous state-of-the-art models. Codes and\ndatasets from our experiments are freely available at\n\\href{https://github.com/xubuvd/GuessWhich}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at CICAI 2023 (CAAI-A), codes at\n  https://github.com/xubuvd/GuessWhich",
    "pdf_url": "http://arxiv.org/pdf/2408.08431v1",
    "published_date": "2024-08-15 21:46:19 UTC",
    "updated_date": "2024-08-15 21:46:19 UTC"
  },
  {
    "arxiv_id": "2408.08422v1",
    "title": "Assessing and Enhancing Large Language Models in Rare Disease Question-answering",
    "authors": [
      "Guanchu Wang",
      "Junhao Ran",
      "Ruixiang Tang",
      "Chia-Yuan Chang",
      "Chia-Yuan Chang",
      "Yu-Neng Chuang",
      "Zirui Liu",
      "Vladimir Braverman",
      "Zhandong Liu",
      "Xia Hu"
    ],
    "abstract": "Despite the impressive capabilities of Large Language Models (LLMs) in\ngeneral medical domains, questions remain about their performance in diagnosing\nrare diseases. To answer this question, we aim to assess the diagnostic\nperformance of LLMs in rare diseases, and explore methods to enhance their\neffectiveness in this area. In this work, we introduce a rare disease\nquestion-answering (ReDis-QA) dataset to evaluate the performance of LLMs in\ndiagnosing rare diseases. Specifically, we collected 1360 high-quality\nquestion-answer pairs within the ReDis-QA dataset, covering 205 rare diseases.\nAdditionally, we annotated meta-data for each question, facilitating the\nextraction of subsets specific to any given disease and its property. Based on\nthe ReDis-QA dataset, we benchmarked several open-source LLMs, revealing that\ndiagnosing rare diseases remains a significant challenge for these models.\n  To facilitate retrieval augmentation generation for rare disease diagnosis,\nwe collect the first rare diseases corpus (ReCOP), sourced from the National\nOrganization for Rare Disorders (NORD) database. Specifically, we split the\nreport of each rare disease into multiple chunks, each representing a different\nproperty of the disease, including their overview, symptoms, causes, effects,\nrelated disorders, diagnosis, and standard therapies. This structure ensures\nthat the information within each chunk aligns consistently with a question.\nExperiment results demonstrate that ReCOP can effectively improve the accuracy\nof LLMs on the ReDis-QA dataset by an average of 8%. Moreover, it significantly\nguides LLMs to generate trustworthy answers and explanations that can be traced\nback to existing literature.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08422v1",
    "published_date": "2024-08-15 21:09:09 UTC",
    "updated_date": "2024-08-15 21:09:09 UTC"
  },
  {
    "arxiv_id": "2408.16780v1",
    "title": "$EvoAl^{2048}$",
    "authors": [
      "Bernhard J. Berger",
      "Christina Plump",
      "Rolf Drechsler"
    ],
    "abstract": "As AI solutions enter safety-critical products, the explainability and\ninterpretability of solutions generated by AI products become increasingly\nimportant. In the long term, such explanations are the key to gaining users'\nacceptance of AI-based systems' decisions. We report on applying a\nmodel-driven-based optimisation to search for an interpretable and explainable\npolicy that solves the game 2048. This paper describes a solution to the\nGECCO'24 Interpretable Control Competition using the open-source software\nEvoAl. We aimed to develop an approach for creating interpretable policies that\nare easy to adapt to new ideas.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "2 pages, GECCO'24 competition entry",
    "pdf_url": "http://arxiv.org/pdf/2408.16780v1",
    "published_date": "2024-08-15 21:06:18 UTC",
    "updated_date": "2024-08-15 21:06:18 UTC"
  },
  {
    "arxiv_id": "2408.08927v2",
    "title": "VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning and Abstract Syntax Tree (AST)-based Waveform Tracing Tool",
    "authors": [
      "Chia-Tung Ho",
      "Haoxing Ren",
      "Brucek Khailany"
    ],
    "abstract": "Due to the growing complexity of modern Integrated Circuits (ICs), automating\nhardware design can prevent a significant amount of human error from the\nengineering process and result in less errors. Verilog is a popular hardware\ndescription language for designing and modeling digital systems; thus, Verilog\ngeneration is one of the emerging areas of research to facilitate the design\nprocess. In this work, we propose VerilogCoder, a system of multiple Artificial\nIntelligence (AI) agents for Verilog code generation, to autonomously write\nVerilog code and fix syntax and functional errors using collaborative Verilog\ntools (i.e., syntax checker, simulator, and waveform tracer). Firstly, we\npropose a task planner that utilizes a novel Task and Circuit Relation Graph\nretrieval method to construct a holistic plan based on module descriptions. To\ndebug and fix functional errors, we develop a novel and efficient abstract\nsyntax tree (AST)-based waveform tracing tool, which is integrated within the\nautonomous Verilog completion flow. The proposed methodology successfully\ngenerates 94.2% syntactically and functionally correct Verilog code, surpassing\nthe state-of-the-art methods by 33.9% on the VerilogEval-Human v2 benchmark.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "main paper 7 pages, reference 1 page, it is the version that accepted\n  by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.08927v2",
    "published_date": "2024-08-15 20:06:06 UTC",
    "updated_date": "2025-03-05 06:23:52 UTC"
  },
  {
    "arxiv_id": "2408.08401v1",
    "title": "Understanding Help-Seeking Behavior of Students Using LLMs vs. Web Search for Writing SQL Queries",
    "authors": [
      "Harsh Kumar",
      "Mohi Reza",
      "Jeb Mitchell",
      "Ilya Musabirov",
      "Lisa Zhang",
      "Michael Liut"
    ],
    "abstract": "Growth in the use of large language models (LLMs) in programming education is\naltering how students write SQL queries. Traditionally, students relied heavily\non web search for coding assistance, but this has shifted with the adoption of\nLLMs like ChatGPT. However, the comparative process and outcomes of using web\nsearch versus LLMs for coding help remain underexplored. To address this, we\nconducted a randomized interview study in a database classroom to compare web\nsearch and LLMs, including a publicly available LLM (ChatGPT) and an\ninstructor-tuned LLM, for writing SQL queries. Our findings indicate that using\nan instructor-tuned LLM required significantly more interactions than both\nChatGPT and web search, but resulted in a similar number of edits to the final\nSQL query. No significant differences were found in the quality of the final\nSQL queries between conditions, although the LLM conditions directionally\nshowed higher query quality. Furthermore, students using instructor-tuned LLM\nreported a lower mental demand. These results have implications for learning\nand productivity in programming education.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "cs.DB"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08401v1",
    "published_date": "2024-08-15 19:58:41 UTC",
    "updated_date": "2024-08-15 19:58:41 UTC"
  },
  {
    "arxiv_id": "2408.11856v2",
    "title": "Dynamic Adaptive Optimization for Effective Sentiment Analysis Fine-Tuning on Large Language Models",
    "authors": [
      "Hongcheng Ding",
      "Xuanze Zhao",
      "Shamsul Nahar Abdullah",
      "Deshinta Arrova Dewi",
      "Zixiao Jiang",
      "Xiangyu Shi"
    ],
    "abstract": "Sentiment analysis plays a crucial role in various domains, such as business\nintelligence and financial forecasting. Large language models (LLMs) have\nbecome a popular paradigm for sentiment analysis, leveraging multi-task\nlearning to address specific tasks concurrently. However, LLMs with fine-tuning\nfor sentiment analysis often underperforms due to the inherent challenges in\nmanaging diverse task complexities. Moreover, constant-weight approaches in\nmulti-task learning struggle to adapt to variations in data characteristics,\nfurther complicating model effectiveness. To address these issues, we propose a\nnovel multi-task learning framework with a dynamic adaptive optimization (DAO)\nmodule. This module is designed as a plug-and-play component that can be\nseamlessly integrated into existing models, providing an effective and flexible\nsolution for multi-task learning. The key component of the DAO module is\ndynamic adaptive loss, which dynamically adjusts the weights assigned to\ndifferent tasks based on their relative importance and data characteristics\nduring training. Sentiment analyses on a standard and customized financial text\ndataset demonstrate that the proposed framework achieves superior performance.\nSpecifically, this work improves the Mean Squared Error (MSE) and Accuracy\n(ACC) by 15.58% and 1.24% respectively, compared with previous work.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11856v2",
    "published_date": "2024-08-15 19:13:38 UTC",
    "updated_date": "2024-11-12 05:37:15 UTC"
  },
  {
    "arxiv_id": "2408.08376v2",
    "title": "Decoding the human brain tissue response to radiofrequency excitation using a biophysical-model-free deep MRI on a chip framework",
    "authors": [
      "Dinor Nagar",
      "Moritz Zaiss",
      "Or Perlman"
    ],
    "abstract": "Magnetic resonance imaging (MRI) relies on radiofrequency (RF) excitation of\nproton spin. Clinical diagnosis requires a comprehensive collation of\nbiophysical data via multiple MRI contrasts, acquired using a series of RF\nsequences that lead to lengthy examinations. Here, we developed a vision\ntransformer-based framework that captures the spatiotemporal magnetic signal\nevolution and decodes the brain tissue response to RF excitation, constituting\nan MRI on a chip. Following a per-subject rapid calibration scan (28.2 s), a\nwide variety of image contrasts including fully quantitative molecular, water\nrelaxation, and magnetic field maps can be generated automatically. The method\nwas validated across healthy subjects and a cancer patient in two different\nimaging sites, and proved to be 94% faster than alternative protocols. The deep\nMRI on a chip (DeepMonC) framework may reveal the molecular composition of the\nhuman brain tissue in a wide range of pathologies, while offering clinically\nattractive scan times.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "physics.med-ph",
    "comment": "This project was funded by the European Union (ERC, BabyMagnet,\n  project no. 101115639). Views and opinions expressed are however those of the\n  authors only and do not necessarily reflect those of the European Union or\n  the European Research Council. Neither the European Union nor the granting\n  authority can be held responsible for them",
    "pdf_url": "http://arxiv.org/pdf/2408.08376v2",
    "published_date": "2024-08-15 18:39:33 UTC",
    "updated_date": "2024-08-19 05:15:04 UTC"
  },
  {
    "arxiv_id": "2408.08313v3",
    "title": "Can Large Language Models Understand Symbolic Graphics Programs?",
    "authors": [
      "Zeju Qiu",
      "Weiyang Liu",
      "Haiwen Feng",
      "Zhen Liu",
      "Tim Z. Xiao",
      "Katherine M. Collins",
      "Joshua B. Tenenbaum",
      "Adrian Weller",
      "Michael J. Black",
      "Bernhard Sch√∂lkopf"
    ],
    "abstract": "Against the backdrop of enthusiasm for large language models (LLMs), there is\nan urgent need to scientifically assess their capabilities and shortcomings.\nThis is nontrivial in part because it is difficult to find tasks which the\nmodels have not encountered during training. Utilizing symbolic graphics\nprograms, we propose a domain well-suited to test multiple spatial-semantic\nreasoning skills of LLMs. Popular in computer graphics, these programs\nprocedurally generate visual data. While LLMs exhibit impressive skills in\ngeneral program synthesis and analysis, symbolic graphics programs offer a new\nlayer of evaluation: they allow us to test an LLM's ability to answer\ndifferent-grained semantic-level questions of the images or 3D geometries\nwithout a vision encoder. To semantically understand the symbolic programs,\nLLMs would need to possess the ability to \"imagine\" and reason how the\ncorresponding graphics content would look with only the symbolic description.\nWe use this task to evaluate LLMs by creating a large benchmark for the\nsemantic visual understanding of symbolic graphics programs, built procedurally\nwith minimal human effort. Particular emphasis is placed on transformations of\nimages that leave the image level semantics invariant while introducing\nsignificant changes to the underlying program. We evaluate commercial and\nopen-source LLMs on our benchmark to assess their ability to reason about\nvisual output of programs, finding that LLMs considered stronger at reasoning\ngenerally perform better. Lastly, we introduce a novel method to improve this\nability -- Symbolic Instruction Tuning (SIT), in which the LLM is finetuned\nwith pre-collected instruction data on symbolic graphics programs.\nInterestingly, we find that SIT not only improves LLM's understanding on\nsymbolic programs, but it also improves general reasoning ability on various\nother benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Technical Report v3 (47 pages, 26 figures, project page:\n  https://sgp-bench.github.io/, added visual illusion examples)",
    "pdf_url": "http://arxiv.org/pdf/2408.08313v3",
    "published_date": "2024-08-15 17:59:57 UTC",
    "updated_date": "2024-12-11 21:42:14 UTC"
  },
  {
    "arxiv_id": "2408.08312v1",
    "title": "HyperTaxel: Hyper-Resolution for Taxel-Based Tactile Signals Through Contrastive Learning",
    "authors": [
      "Hongyu Li",
      "Snehal Dikhale",
      "Jinda Cui",
      "Soshi Iba",
      "Nawid Jamali"
    ],
    "abstract": "To achieve dexterity comparable to that of humans, robots must intelligently\nprocess tactile sensor data. Taxel-based tactile signals often have low\nspatial-resolution, with non-standardized representations. In this paper, we\npropose a novel framework, HyperTaxel, for learning a geometrically-informed\nrepresentation of taxel-based tactile signals to address challenges associated\nwith their spatial resolution. We use this representation and a contrastive\nlearning objective to encode and map sparse low-resolution taxel signals to\nhigh-resolution contact surfaces. To address the uncertainty inherent in these\nsignals, we leverage joint probability distributions across multiple\nsimultaneous contacts to improve taxel hyper-resolution. We evaluate our\nrepresentation by comparing it with two baselines and present results that\nsuggest our representation outperforms the baselines. Furthermore, we present\nqualitative results that demonstrate the learned representation captures the\ngeometric features of the contact surface, such as flatness, curvature, and\nedges, and generalizes across different objects and sensor configurations.\nMoreover, we present results that suggest our representation improves the\nperformance of various downstream tasks, such as surface classification, 6D\nin-hand pose estimation, and sim-to-real transfer.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by IROS 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08312v1",
    "published_date": "2024-08-15 17:59:53 UTC",
    "updated_date": "2024-08-15 17:59:53 UTC"
  },
  {
    "arxiv_id": "2408.16961v2",
    "title": "The Future of Open Human Feedback",
    "authors": [
      "Shachar Don-Yehiya",
      "Ben Burtenshaw",
      "Ramon Fernandez Astudillo",
      "Cailean Osborne",
      "Mimansa Jaiswal",
      "Tzu-Sheng Kuo",
      "Wenting Zhao",
      "Idan Shenfeld",
      "Andi Peng",
      "Mikhail Yurochkin",
      "Atoosa Kasirzadeh",
      "Yangsibo Huang",
      "Tatsunori Hashimoto",
      "Yacine Jernite",
      "Daniel Vila-Suero",
      "Omri Abend",
      "Jennifer Ding",
      "Sara Hooker",
      "Hannah Rose Kirk",
      "Leshem Choshen"
    ],
    "abstract": "Human feedback on conversations with language language models (LLMs) is\ncentral to how these systems learn about the world, improve their capabilities,\nand are steered toward desirable and safe behaviors. However, this feedback is\nmostly collected by frontier AI labs and kept behind closed doors. In this\nwork, we bring together interdisciplinary experts to assess the opportunities\nand challenges to realizing an open ecosystem of human feedback for AI. We\nfirst look for successful practices in peer production, open source, and\ncitizen science communities. We then characterize the main challenges for open\nhuman feedback. For each, we survey current approaches and offer\nrecommendations. We end by envisioning the components needed to underpin a\nsustainable and open human feedback ecosystem. In the center of this ecosystem\nare mutually beneficial feedback loops, between users and specialized models,\nincentivizing a diverse stakeholders community of model trainers and feedback\nproviders to support a general open feedback pool.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.16961v2",
    "published_date": "2024-08-15 17:59:14 UTC",
    "updated_date": "2024-09-04 15:39:47 UTC"
  },
  {
    "arxiv_id": "2408.08302v1",
    "title": "Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors",
    "authors": [
      "Usman Syed",
      "Ethan Light",
      "Xingang Guo",
      "Huan Zhang",
      "Lianhui Qin",
      "Yanfeng Ouyang",
      "Bin Hu"
    ],
    "abstract": "In this paper, we explore the capabilities of state-of-the-art large language\nmodels (LLMs) such as GPT-4, GPT-4o, Claude 3.5 Sonnet, Claude 3 Opus, Gemini\n1.5 Pro, Llama 3, and Llama 3.1 in solving some selected undergraduate-level\ntransportation engineering problems. We introduce TransportBench, a benchmark\ndataset that includes a sample of transportation engineering problems on a wide\nrange of subjects in the context of planning, design, management, and control\nof transportation systems. This dataset is used by human experts to evaluate\nthe capabilities of various commercial and open-sourced LLMs, especially their\naccuracy, consistency, and reasoning behaviors, in solving transportation\nengineering problems. Our comprehensive analysis uncovers the unique strengths\nand limitations of each LLM, e.g. our analysis shows the impressive accuracy\nand some unexpected inconsistent behaviors of Claude 3.5 Sonnet in solving\nTransportBench problems. Our study marks a thrilling first step toward\nharnessing artificial general intelligence for complex transportation\nchallenges.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08302v1",
    "published_date": "2024-08-15 17:55:45 UTC",
    "updated_date": "2024-08-15 17:55:45 UTC"
  },
  {
    "arxiv_id": "2408.08295v1",
    "title": "SLCA++: Unleash the Power of Sequential Fine-tuning for Continual Learning with Pre-training",
    "authors": [
      "Gengwei Zhang",
      "Liyuan Wang",
      "Guoliang Kang",
      "Ling Chen",
      "Yunchao Wei"
    ],
    "abstract": "In recent years, continual learning with pre-training (CLPT) has received\nwidespread interest, instead of its traditional focus of training from scratch.\nThe use of strong pre-trained models (PTMs) can greatly facilitate knowledge\ntransfer and alleviate catastrophic forgetting, but also suffers from\nprogressive overfitting of pre-trained knowledge into specific downstream\ntasks. A majority of current efforts often keep the PTMs frozen and incorporate\ntask-specific prompts to instruct representation learning, coupled with a\nprompt selection process for inference. However, due to the limited capacity of\nprompt parameters, this strategy demonstrates only sub-optimal performance in\ncontinual learning. In comparison, tuning all parameters of PTMs often provides\nthe greatest potential for representation learning, making sequential\nfine-tuning (Seq FT) a fundamental baseline that has been overlooked in CLPT.\nTo this end, we present an in-depth analysis of the progressive overfitting\nproblem from the lens of Seq FT. Considering that the overly fast\nrepresentation learning and the biased classification layer constitute this\nparticular problem, we introduce the advanced Slow Learner with Classifier\nAlignment (SLCA++) framework to unleash the power of Seq FT, serving as a\nstrong baseline approach for CLPT. Our approach involves a Slow Learner to\nselectively reduce the learning rate of backbone parameters, and a Classifier\nAlignment to align the disjoint classification layers in a post-hoc fashion. We\nfurther enhance the efficacy of SL with a symmetric cross-entropy loss, as well\nas employ a parameter-efficient strategy to implement Seq FT with SLCA++.\nAcross a variety of continual learning scenarios on image classification\nbenchmarks, our approach provides substantial improvements and outperforms\nstate-of-the-art methods by a large margin. Code:\nhttps://github.com/GengDavid/SLCA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper is an extension of our ICCV 23 paper (arXiv:2303.05118)",
    "pdf_url": "http://arxiv.org/pdf/2408.08295v1",
    "published_date": "2024-08-15 17:50:07 UTC",
    "updated_date": "2024-08-15 17:50:07 UTC"
  },
  {
    "arxiv_id": "2408.08282v1",
    "title": "Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model",
    "authors": [
      "Jin Wang",
      "Arturo Laurenzi",
      "Nikos Tsagarakis"
    ],
    "abstract": "Enabling humanoid robots to perform autonomously loco-manipulation in\nunstructured environments is crucial and highly challenging for achieving\nembodied intelligence. This involves robots being able to plan their actions\nand behaviors in long-horizon tasks while using multi-modality to perceive\ndeviations between task execution and high-level planning. Recently, large\nlanguage models (LLMs) have demonstrated powerful planning and reasoning\ncapabilities for comprehension and processing of semantic information through\nrobot control tasks, as well as the usability of analytical judgment and\ndecision-making for multi-modal inputs. To leverage the power of LLMs towards\nhumanoid loco-manipulation, we propose a novel language-model based framework\nthat enables robots to autonomously plan behaviors and low-level execution\nunder given textual instructions, while observing and correcting failures that\nmay occur during task execution. To systematically evaluate this framework in\ngrounding LLMs, we created the robot 'action' and 'sensing' behavior library\nfor task planning, and conducted mobile manipulation tasks and experiments in\nboth simulated and real environments using the CENTAURO robot, and verified the\neffectiveness and application of this approach in robotic tasks with autonomous\nbehavioral planning.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Paper accepted by IROS 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08282v1",
    "published_date": "2024-08-15 17:33:32 UTC",
    "updated_date": "2024-08-15 17:33:32 UTC"
  },
  {
    "arxiv_id": "2408.08926v4",
    "title": "Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models",
    "authors": [
      "Andy K. Zhang",
      "Neil Perry",
      "Riya Dulepet",
      "Joey Ji",
      "Celeste Menders",
      "Justin W. Lin",
      "Eliot Jones",
      "Gashon Hussein",
      "Samantha Liu",
      "Donovan Jasper",
      "Pura Peetathawatchai",
      "Ari Glenn",
      "Vikram Sivashankar",
      "Daniel Zamoshchin",
      "Leo Glikbarg",
      "Derek Askaryar",
      "Mike Yang",
      "Teddy Zhang",
      "Rishi Alluri",
      "Nathan Tran",
      "Rinnara Sangpisit",
      "Polycarpos Yiorkadjis",
      "Kenny Osele",
      "Gautham Raghupathi",
      "Dan Boneh",
      "Daniel E. Ho",
      "Percy Liang"
    ],
    "abstract": "Language Model (LM) agents for cybersecurity that are capable of autonomously\nidentifying vulnerabilities and executing exploits have potential to cause\nreal-world impact. Policymakers, model providers, and researchers in the AI and\ncybersecurity communities are interested in quantifying the capabilities of\nsuch agents to help mitigate cyberrisk and investigate opportunities for\npenetration testing. Toward that end, we introduce Cybench, a framework for\nspecifying cybersecurity tasks and evaluating agents on those tasks. We include\n40 professional-level Capture the Flag (CTF) tasks from 4 distinct CTF\ncompetitions, chosen to be recent, meaningful, and spanning a wide range of\ndifficulties. Each task includes its own description, starter files, and is\ninitialized in an environment where an agent can execute commands and observe\noutputs. Since many tasks are beyond the capabilities of existing LM agents, we\nintroduce subtasks for each task, which break down a task into intermediary\nsteps for a more detailed evaluation. To evaluate agent capabilities, we\nconstruct a cybersecurity agent and evaluate 8 models: GPT-4o, OpenAI\no1-preview, Claude 3 Opus, Claude 3.5 Sonnet, Mixtral 8x22b Instruct, Gemini\n1.5 Pro, Llama 3 70B Chat, and Llama 3.1 405B Instruct. For the top performing\nmodels (GPT-4o and Claude 3.5 Sonnet), we further investigate performance\nacross 4 agent scaffolds (structed bash, action-only, pseudoterminal, and web\nsearch). Without subtask guidance, agents leveraging Claude 3.5 Sonnet, GPT-4o,\nOpenAI o1-preview, and Claude 3 Opus successfully solved complete tasks that\ntook human teams up to 11 minutes to solve. In comparison, the most difficult\ntask took human teams 24 hours and 54 minutes to solve. All code and data are\npublicly available at https://cybench.github.io.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "ICLR 2025 Oral",
    "pdf_url": "http://arxiv.org/pdf/2408.08926v4",
    "published_date": "2024-08-15 17:23:10 UTC",
    "updated_date": "2025-04-12 21:26:07 UTC"
  },
  {
    "arxiv_id": "2408.08264v1",
    "title": "InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models",
    "authors": [
      "Guoxiang Grayson Tong",
      "Carlos A. Sing Long",
      "Daniele E. Schiavazzi"
    ],
    "abstract": "Estimation of cardiovascular model parameters from electronic health records\n(EHR) poses a significant challenge primarily due to lack of identifiability.\nStructural non-identifiability arises when a manifold in the space of\nparameters is mapped to a common output, while practical non-identifiability\ncan result due to limited data, model misspecification, or noise corruption. To\naddress the resulting ill-posed inverse problem, optimization-based or Bayesian\ninference approaches typically use regularization, thereby limiting the\npossibility of discovering multiple solutions. In this study, we use inVAErt\nnetworks, a neural network-based, data-driven framework for enhanced digital\ntwin analysis of stiff dynamical systems. We demonstrate the flexibility and\neffectiveness of inVAErt networks in the context of physiological inversion of\na six-compartment lumped parameter hemodynamic model from synthetic data to\nreal data with missing components.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "cs.NA"
    ],
    "primary_category": "math.NA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08264v1",
    "published_date": "2024-08-15 17:07:40 UTC",
    "updated_date": "2024-08-15 17:07:40 UTC"
  },
  {
    "arxiv_id": "2408.08258v3",
    "title": "Snuffy: Efficient Whole Slide Image Classifier",
    "authors": [
      "Hossein Jafarinia",
      "Alireza Alipanah",
      "Danial Hamdi",
      "Saeed Razavi",
      "Nahal Mirzaie",
      "Mohammad Hossein Rohban"
    ],
    "abstract": "Whole Slide Image (WSI) classification with multiple instance learning (MIL)\nin digital pathology faces significant computational challenges. Current\nmethods mostly rely on extensive self-supervised learning (SSL) for\nsatisfactory performance, requiring long training periods and considerable\ncomputational resources. At the same time, no pre-training affects performance\ndue to domain shifts from natural images to WSIs. We introduce Snuffy\narchitecture, a novel MIL-pooling method based on sparse transformers that\nmitigates performance loss with limited pre-training and enables continual\nfew-shot pre-training as a competitive option. Our sparsity pattern is tailored\nfor pathology and is theoretically proven to be a universal approximator with\nthe tightest probabilistic sharp bound on the number of layers for sparse\ntransformers, to date. We demonstrate Snuffy's effectiveness on CAMELYON16 and\nTCGA Lung cancer datasets, achieving superior WSI and patch-level accuracies.\nThe code is available on https://github.com/jafarinia/snuffy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08258v3",
    "published_date": "2024-08-15 16:59:15 UTC",
    "updated_date": "2025-03-02 04:25:12 UTC"
  },
  {
    "arxiv_id": "2408.08925v1",
    "title": "Retail-GPT: leveraging Retrieval Augmented Generation (RAG) for building E-commerce Chat Assistants",
    "authors": [
      "Bruno Amaral Teixeira de Freitas",
      "Roberto de Alencar Lotufo"
    ],
    "abstract": "This work presents Retail-GPT, an open-source RAG-based chatbot designed to\nenhance user engagement in retail e-commerce by guiding users through product\nrecommendations and assisting with cart operations. The system is\ncross-platform and adaptable to various e-commerce domains, avoiding reliance\non specific chat applications or commercial activities. Retail-GPT engages in\nhuman-like conversations, interprets user demands, checks product availability,\nand manages cart operations, aiming to serve as a virtual sales agent and test\nthe viability of such assistants across different retail businesses.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "5 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.08925v1",
    "published_date": "2024-08-15 16:53:05 UTC",
    "updated_date": "2024-08-15 16:53:05 UTC"
  },
  {
    "arxiv_id": "2408.08252v5",
    "title": "Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding",
    "authors": [
      "Xiner Li",
      "Yulai Zhao",
      "Chenyu Wang",
      "Gabriele Scalia",
      "Gokcen Eraslan",
      "Surag Nair",
      "Tommaso Biancalani",
      "Shuiwang Ji",
      "Aviv Regev",
      "Sergey Levine",
      "Masatoshi Uehara"
    ],
    "abstract": "Diffusion models excel at capturing the natural design spaces of images,\nmolecules, DNA, RNA, and protein sequences. However, rather than merely\ngenerating designs that are natural, we often aim to optimize downstream reward\nfunctions while preserving the naturalness of these design spaces. Existing\nmethods for achieving this goal often require ``differentiable'' proxy models\n(\\textit{e.g.}, classifier guidance or DPS) or involve computationally\nexpensive fine-tuning of diffusion models (\\textit{e.g.}, classifier-free\nguidance, RL-based fine-tuning). In our work, we propose a new method to\naddress these challenges. Our algorithm is an iterative sampling method that\nintegrates soft value functions, which looks ahead to how intermediate noisy\nstates lead to high rewards in the future, into the standard inference\nprocedure of pre-trained diffusion models. Notably, our approach avoids\nfine-tuning generative models and eliminates the need to construct\ndifferentiable models. This enables us to (1) directly utilize\nnon-differentiable features/reward feedback, commonly used in many scientific\ndomains, and (2) apply our method to recent discrete diffusion models in a\nprincipled way. Finally, we demonstrate the effectiveness of our algorithm\nacross several domains, including image generation, molecule generation, and\nDNA/RNA sequence generation. The code is available at\n\\href{https://github.com/masa-ue/SVDD}{https://github.com/masa-ue/SVDD}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "The code is available at https://github.com/masa-ue/SVDD",
    "pdf_url": "http://arxiv.org/pdf/2408.08252v5",
    "published_date": "2024-08-15 16:47:59 UTC",
    "updated_date": "2024-10-25 02:50:44 UTC"
  },
  {
    "arxiv_id": "2408.11855v1",
    "title": "FactorLLM: Factorizing Knowledge via Mixture of Experts for Large Language Models",
    "authors": [
      "Zhongyu Zhao",
      "Menghang Dong",
      "Rongyu Zhang",
      "Wenzhao Zheng",
      "Yunpeng Zhang",
      "Huanrui Yang",
      "Dalong Du",
      "Kurt Keutzer",
      "Shanghang Zhang"
    ],
    "abstract": "Recent research has demonstrated that Feed-Forward Networks (FFNs) in Large\nLanguage Models (LLMs) play a pivotal role in storing diverse linguistic and\nfactual knowledge. Conventional methods frequently face challenges due to\nknowledge confusion stemming from their monolithic and redundant architectures,\nwhich calls for more efficient solutions with minimal computational overhead,\nparticularly for LLMs. In this paper, we explore the FFN computation paradigm\nin LLMs and introduce FactorLLM, a novel approach that decomposes well-trained\ndense FFNs into sparse sub-networks without requiring any further\nmodifications, while maintaining the same level of performance. Furthermore, we\nembed a router from the Mixture-of-Experts (MoE), combined with our devised\nPrior-Approximate (PA) loss term that facilitates the dynamic activation of\nexperts and knowledge adaptation, thereby accelerating computational processes\nand enhancing performance using minimal training data and fine-tuning steps.\nFactorLLM thus enables efficient knowledge factorization and activates select\ngroups of experts specifically tailored to designated tasks, emulating the\ninteractive functional segmentation of the human brain. Extensive experiments\nacross various benchmarks demonstrate the effectiveness of our proposed\nFactorLLM which achieves comparable performance to the source model securing up\nto 85% model performance while obtaining over a 30% increase in inference\nspeed. Code: https://github.com/zhenwuweihe/FactorLLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11855v1",
    "published_date": "2024-08-15 16:45:16 UTC",
    "updated_date": "2024-08-15 16:45:16 UTC"
  },
  {
    "arxiv_id": "2408.16779v2",
    "title": "Inductive Learning of Logical Theories with LLMs: An Expressivity-Graded Analysis",
    "authors": [
      "Jo√£o Pedro Gandarela",
      "Danilo S. Carvalho",
      "Andr√© Freitas"
    ],
    "abstract": "This work presents a novel systematic methodology to analyse the capabilities\nand limitations of Large Language Models (LLMs) with feedback from a formal\ninference engine, on logic theory induction. The analysis is complexity-graded\nw.r.t. rule dependency structure, allowing quantification of specific inference\nchallenges on LLM performance. Integrating LLMs with formal methods is a\npromising frontier in the Natural Language Processing field, as an important\navenue for improving model inference control and explainability. In particular,\ninductive learning over complex sets of facts and rules, poses unique\nchallenges for current autoregressive models, as they lack explicit symbolic\ngrounding. While they can be complemented by formal systems, the properties\ndelivered by LLMs regarding inductive learning, are not well understood and\nquantified. Empirical results indicate that the largest LLMs can achieve\ncompetitive results against a SOTA Inductive Logic Programming (ILP) system\nbaseline, but also that tracking long predicate relationship chains is a more\ndifficult obstacle than theory complexity for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LO",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.16779v2",
    "published_date": "2024-08-15 16:41:00 UTC",
    "updated_date": "2025-01-14 14:26:03 UTC"
  },
  {
    "arxiv_id": "2408.08248v3",
    "title": "Conformalized Answer Set Prediction for Knowledge Graph Embedding",
    "authors": [
      "Yuqicheng Zhu",
      "Nico Potyka",
      "Jiarong Pan",
      "Bo Xiong",
      "Yunjie He",
      "Evgeny Kharlamov",
      "Steffen Staab"
    ],
    "abstract": "Knowledge graph embeddings (KGE) apply machine learning methods on knowledge\ngraphs (KGs) to provide non-classical reasoning capabilities based on\nsimilarities and analogies. The learned KG embeddings are typically used to\nanswer queries by ranking all potential answers, but rankings often lack a\nmeaningful probabilistic interpretation - lower-ranked answers do not\nnecessarily have a lower probability of being true. This limitation makes it\ndifficult to quantify uncertainty of model's predictions, posing challenges for\nthe application of KGE methods in high-stakes domains like medicine. We address\nthis issue by applying the theory of conformal prediction that allows\ngenerating answer sets, which contain the correct answer with probabilistic\nguarantees. We explain how conformal prediction can be used to generate such\nanswer sets for link prediction tasks. Our empirical evaluation on four\nbenchmark datasets using six representative KGE methods validates that the\ngenerated answer sets satisfy the probabilistic guarantees given by the theory\nof conformal prediction. We also demonstrate that the generated answer sets\noften have a sensible size and that the size adapts well with respect to the\ndifficulty of the query.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted as a main conference paper at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.08248v3",
    "published_date": "2024-08-15 16:36:59 UTC",
    "updated_date": "2025-01-25 17:44:05 UTC"
  },
  {
    "arxiv_id": "2408.08242v1",
    "title": "A Conflicts-free, Speed-lossless KAN-based Reinforcement Learning Decision System for Interactive Driving in Roundabouts",
    "authors": [
      "Zhihao Lin",
      "Zhen Tian",
      "Qi Zhang",
      "Ziyang Ye",
      "Hanyang Zhuang",
      "Jianglin Lan"
    ],
    "abstract": "Safety and efficiency are crucial for autonomous driving in roundabouts,\nespecially in the context of mixed traffic where autonomous vehicles (AVs) and\nhuman-driven vehicles coexist. This paper introduces a learning-based algorithm\ntailored to foster safe and efficient driving behaviors across varying levels\nof traffic flows in roundabouts. The proposed algorithm employs a deep\nQ-learning network to effectively learn safe and efficient driving strategies\nin complex multi-vehicle roundabouts. Additionally, a KAN (Kolmogorov-Arnold\nnetwork) enhances the AVs' ability to learn their surroundings robustly and\nprecisely. An action inspector is integrated to replace dangerous actions to\navoid collisions when the AV interacts with the environment, and a route\nplanner is proposed to enhance the driving efficiency and safety of the AVs.\nMoreover, a model predictive control is adopted to ensure stability and\nprecision of the driving actions. The results show that our proposed system\nconsistently achieves safe and efficient driving whilst maintaining a stable\ntraining process, as evidenced by the smooth convergence of the reward function\nand the low variance in the training curves across various traffic flows.\nCompared to state-of-the-art benchmarks, the proposed algorithm achieves a\nlower number of collisions and reduced travel time to destination.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "15 pages, 12 figures, submitted to an IEEE journal",
    "pdf_url": "http://arxiv.org/pdf/2408.08242v1",
    "published_date": "2024-08-15 16:10:25 UTC",
    "updated_date": "2024-08-15 16:10:25 UTC"
  },
  {
    "arxiv_id": "2408.08230v1",
    "title": "Explaining an Agent's Future Beliefs through Temporally Decomposing Future Reward Estimators",
    "authors": [
      "Mark Towers",
      "Yali Du",
      "Christopher Freeman",
      "Timothy J. Norman"
    ],
    "abstract": "Future reward estimation is a core component of reinforcement learning\nagents; i.e., Q-value and state-value functions, predicting an agent's sum of\nfuture rewards. Their scalar output, however, obfuscates when or what\nindividual future rewards an agent may expect to receive. We address this by\nmodifying an agent's future reward estimator to predict their next N expected\nrewards, referred to as Temporal Reward Decomposition (TRD). This unlocks novel\nexplanations of agent behaviour. Through TRD we can: estimate when an agent may\nexpect to receive a reward, the value of the reward and the agent's confidence\nin receiving it; measure an input feature's temporal importance to the agent's\naction decisions; and predict the influence of different actions on future\nrewards. Furthermore, we show that DQN agents trained on Atari environments can\nbe efficiently retrained to incorporate TRD with minimal impact on performance.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages + 3 pages of supplementary material. Published at ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08230v1",
    "published_date": "2024-08-15 15:56:15 UTC",
    "updated_date": "2024-08-15 15:56:15 UTC"
  },
  {
    "arxiv_id": "2408.08227v1",
    "title": "Evolving A* to Efficiently Solve the k Shortest-Path Problem (Extended Version)",
    "authors": [
      "Carlos Linares L√≥pez",
      "Ian Herman"
    ],
    "abstract": "The problem of finding the shortest path in a graph G(V, E) has been widely\nstudied. However, in many applications it is necessary to compute an arbitrary\nnumber of them, k. Even though the problem has raised a lot of interest from\ndifferent research communities and many applications of it are known, it has\nnot been addressed to the same extent as the single shortest path problem. The\nbest algorithm known for efficiently solving this task has a time complexity of\nO (|E| + |V|log{|V|}+k|V|)$ when computing paths in explicit form, and is based\non best-first search. This paper introduces a new search algorithm with the\nsame time complexity, which results from a natural evolution of A* thus, it\npreserves all its interesting properties, making it widely applicable to many\ndifferent domains. Experiments in various testbeds show a significant\nimprovement in performance over the state of the art, often by one or two\norders of magnitude.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "68T20",
      "I.2.8"
    ],
    "primary_category": "cs.DS",
    "comment": "249 plots in 48 figures, and 81 tables. This is an extended version\n  of the paper Linares L\\'opez, Carlos and Herman, Ian. 2024. Evolving A* to\n  Efficiently Solve the k Shortest-Path Problem. Proceedings of the European\n  Conference on Artificial Intelligence (ECAI). To appear",
    "pdf_url": "http://arxiv.org/pdf/2408.08227v1",
    "published_date": "2024-08-15 15:54:25 UTC",
    "updated_date": "2024-08-15 15:54:25 UTC"
  },
  {
    "arxiv_id": "2408.08226v2",
    "title": "Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction",
    "authors": [
      "Yuqicheng Zhu",
      "Nico Potyka",
      "Mojtaba Nayyeri",
      "Bo Xiong",
      "Yunjie He",
      "Evgeny Kharlamov",
      "Steffen Staab"
    ],
    "abstract": "Knowledge graph embedding (KGE) models are often used to predict missing\nlinks for knowledge graphs (KGs). However, multiple KG embeddings can perform\nalmost equally well for link prediction yet give conflicting predictions for\nunseen queries. This phenomenon is termed \\textit{predictive multiplicity} in\nthe literature. It poses substantial risks for KGE-based applications in\nhigh-stake domains but has been overlooked in KGE research. We define\npredictive multiplicity in link prediction, introduce evaluation metrics and\nmeasure predictive multiplicity for representative KGE methods on commonly used\nbenchmark datasets. Our empirical study reveals significant predictive\nmultiplicity in link prediction, with $8\\%$ to $39\\%$ testing queries\nexhibiting conflicting predictions. We address this issue by leveraging voting\nmethods from social choice theory, significantly mitigating conflicts by $66\\%$\nto $78\\%$ in our experiments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted as EMNLP'24 Finding",
    "pdf_url": "http://arxiv.org/pdf/2408.08226v2",
    "published_date": "2024-08-15 15:54:02 UTC",
    "updated_date": "2024-10-04 14:03:41 UTC"
  },
  {
    "arxiv_id": "2408.08216v1",
    "title": "The Dawn of KAN in Image-to-Image (I2I) Translation: Integrating Kolmogorov-Arnold Networks with GANs for Unpaired I2I Translation",
    "authors": [
      "Arpan Mahara",
      "Naphtali D. Rishe",
      "Liangdong Deng"
    ],
    "abstract": "Image-to-Image translation in Generative Artificial Intelligence (Generative\nAI) has been a central focus of research, with applications spanning\nhealthcare, remote sensing, physics, chemistry, photography, and more. Among\nthe numerous methodologies, Generative Adversarial Networks (GANs) with\ncontrastive learning have been particularly successful. This study aims to\ndemonstrate that the Kolmogorov-Arnold Network (KAN) can effectively replace\nthe Multi-layer Perceptron (MLP) method in generative AI, particularly in the\nsubdomain of image-to-image translation, to achieve better generative quality.\nOur novel approach replaces the two-layer MLP with a two-layer KAN in the\nexisting Contrastive Unpaired Image-to-Image Translation (CUT) model,\ndeveloping the KAN-CUT model. This substitution favors the generation of more\ninformative features in low-dimensional vector representations, which\ncontrastive learning can utilize more effectively to produce high-quality\nimages in the target domain. Extensive experiments, detailed in the results\nsection, demonstrate the applicability of KAN in conjunction with contrastive\nlearning and GANs in Generative AI, particularly for image-to-image\ntranslation. This work suggests that KAN could be a valuable component in the\nbroader generative AI domain.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 6 Figures, 1 Table",
    "pdf_url": "http://arxiv.org/pdf/2408.08216v1",
    "published_date": "2024-08-15 15:26:12 UTC",
    "updated_date": "2024-08-15 15:26:12 UTC"
  },
  {
    "arxiv_id": "2408.08215v1",
    "title": "Moving Healthcare AI-Support Systems for Visually Detectable Diseases onto Constrained Devices",
    "authors": [
      "Tess Watt",
      "Christos Chrysoulas",
      "Peter J Barclay"
    ],
    "abstract": "Image classification usually requires connectivity and access to the cloud\nwhich is often limited in many parts of the world, including hard to reach\nrural areas. TinyML aims to solve this problem by hosting AI assistants on\nconstrained devices, eliminating connectivity issues by processing data within\nthe device itself, without internet or cloud access. This pilot study explores\nthe use of tinyML to provide healthcare support with low spec devices in low\nconnectivity environments, focusing on diagnosis of skin diseases and the\nethical use of AI assistants in a healthcare setting. To investigate this,\n10,000 images of skin lesions were used to train a model for classifying\nvisually detectable diseases (VDDs). The model weights were then offloaded to a\nRaspberry Pi with a webcam attached, to be used for the classification of skin\nlesions without internet access. It was found that the developed prototype\nachieved a test accuracy of 78% and a test loss of 1.08.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.08215v1",
    "published_date": "2024-08-15 15:23:37 UTC",
    "updated_date": "2024-08-15 15:23:37 UTC"
  },
  {
    "arxiv_id": "2408.08214v1",
    "title": "Federated Fairness Analytics: Quantifying Fairness in Federated Learning",
    "authors": [
      "Oscar Dilley",
      "Juan Marcelo Parra-Ullauri",
      "Rasheed Hussain",
      "Dimitra Simeonidou"
    ],
    "abstract": "Federated Learning (FL) is a privacy-enhancing technology for distributed ML.\nBy training models locally and aggregating updates - a federation learns\ntogether, while bypassing centralised data collection. FL is increasingly\npopular in healthcare, finance and personal computing. However, it inherits\nfairness challenges from classical ML and introduces new ones, resulting from\ndifferences in data quality, client participation, communication constraints,\naggregation methods and underlying hardware. Fairness remains an unresolved\nissue in FL and the community has identified an absence of succinct definitions\nand metrics to quantify fairness; to address this, we propose Federated\nFairness Analytics - a methodology for measuring fairness. Our definition of\nfairness comprises four notions with novel, corresponding metrics. They are\nsymptomatically defined and leverage techniques originating from XAI,\ncooperative game-theory and networking engineering. We tested a range of\nexperimental settings, varying the FL approach, ML task and data settings. The\nresults show that statistical heterogeneity and client participation affect\nfairness and fairness conscious approaches such as Ditto and q-FedAvg\nmarginally improve fairness-performance trade-offs. Using our techniques, FL\npractitioners can uncover previously unobtainable insights into their system's\nfairness, at differing levels of granularity in order to address fairness\nchallenges in FL. We have open-sourced our work at:\nhttps://github.com/oscardilley/federated-fairness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.GT",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08214v1",
    "published_date": "2024-08-15 15:23:32 UTC",
    "updated_date": "2024-08-15 15:23:32 UTC"
  },
  {
    "arxiv_id": "2408.08208v2",
    "title": "LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation",
    "authors": [
      "Bohao Wang",
      "Feng Liu",
      "Changwang Zhang",
      "Jiawei Chen",
      "Yudi Wu",
      "Sheng Zhou",
      "Xingyu Lou",
      "Jun Wang",
      "Yan Feng",
      "Chun Chen",
      "Can Wang"
    ],
    "abstract": "Sequential Recommenders generate recommendations based on users' historical\ninteraction sequences. However, in practice, these collected sequences are\noften contaminated by noisy interactions, which significantly impairs\nrecommendation performance. Accurately identifying such noisy interactions\nwithout additional information is particularly challenging due to the absence\nof explicit supervisory signals indicating noise. Large Language Models (LLMs),\nequipped with extensive open knowledge and semantic reasoning abilities, offer\na promising avenue to bridge this information gap. However, employing LLMs for\ndenoising in sequential recommendation presents notable challenges: 1) Direct\napplication of pretrained LLMs may not be competent for the denoising task,\nfrequently generating nonsensical responses; 2) Even after fine-tuning, the\nreliability of LLM outputs remains questionable, especially given the\ncomplexity of the denoising task and the inherent hallucinatory issue of LLMs.\n  To tackle these challenges, we propose LLM4DSR, a tailored approach for\ndenoising sequential recommendation using LLMs. We constructed a\nself-supervised fine-tuning task to activate LLMs' capabilities to identify\nnoisy items and suggest replacements. Furthermore, we developed an uncertainty\nestimation module that ensures only high-confidence responses are utilized for\nsequence corrections. Remarkably, LLM4DSR is model-agnostic, allowing corrected\nsequences to be flexibly applied across various recommendation models.\nExtensive experiments validate the superiority of LLM4DSR over existing\nmethods.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08208v2",
    "published_date": "2024-08-15 15:18:46 UTC",
    "updated_date": "2024-11-26 08:07:08 UTC"
  },
  {
    "arxiv_id": "2409.00009v2",
    "title": "Web Retrieval Agents for Evidence-Based Misinformation Detection",
    "authors": [
      "Jacob-Junqi Tian",
      "Hao Yu",
      "Yury Orlovskiy",
      "Tyler Vergho",
      "Mauricio Rivera",
      "Mayank Goel",
      "Zachary Yang",
      "Jean-Francois Godbout",
      "Reihaneh Rabbany",
      "Kellin Pelrine"
    ],
    "abstract": "This paper develops an agent-based automated fact-checking approach for\ndetecting misinformation. We demonstrate that combining a powerful LLM agent,\nwhich does not have access to the internet for searches, with an online web\nsearch agent yields better results than when each tool is used independently.\nOur approach is robust across multiple models, outperforming alternatives and\nincreasing the macro F1 of misinformation detection by as much as 20 percent\ncompared to LLMs without search. We also conduct extensive analyses on the\nsources our system leverages and their biases, decisions in the construction of\nthe system like the search tool and the knowledge base, the type of evidence\nneeded and its impact on the results, and other parts of the overall process.\nBy combining strong performance with in-depth understanding, we hope to provide\nbuilding blocks for future search-enabled misinformation mitigation systems.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "1 main figure, 8 tables, 10 pages, 12 figures in Appendix, 7 tables\n  in Appendix GitHub URL: https://github.com/ComplexData-MILA/webretrieval",
    "pdf_url": "http://arxiv.org/pdf/2409.00009v2",
    "published_date": "2024-08-15 15:13:16 UTC",
    "updated_date": "2024-10-09 19:13:41 UTC"
  },
  {
    "arxiv_id": "2408.08924v2",
    "title": "Prefix Guidance: A Steering Wheel for Large Language Models to Defend Against Jailbreak Attacks",
    "authors": [
      "Jiawei Zhao",
      "Kejiang Chen",
      "Xiaojian Yuan",
      "Weiming Zhang"
    ],
    "abstract": "In recent years, the rapid development of large language models (LLMs) has\nachieved remarkable performance across various tasks. However, research\nindicates that LLMs are vulnerable to jailbreak attacks, where adversaries can\ninduce the generation of harmful content through meticulously crafted prompts.\nThis vulnerability poses significant challenges to the secure use and promotion\nof LLMs. Existing defense methods offer protection from different perspectives\nbut often suffer from insufficient effectiveness or a significant impact on the\nmodel's capabilities. In this paper, we propose a plug-and-play and\neasy-to-deploy jailbreak defense framework, namely Prefix Guidance (PG), which\nguides the model to identify harmful prompts by directly setting the first few\ntokens of the model's output. This approach combines the model's inherent\nsecurity capabilities with an external classifier to defend against jailbreak\nattacks. We demonstrate the effectiveness of PG across three models and five\nattack methods. Compared to baselines, our approach is generally more effective\non average. Additionally, results on the Just-Eval benchmark further confirm\nPG's superiority to preserve the model's performance. our code is available at\nhttps://github.com/weiyezhimeng/Prefix-Guidance.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08924v2",
    "published_date": "2024-08-15 14:51:32 UTC",
    "updated_date": "2024-08-22 17:21:34 UTC"
  },
  {
    "arxiv_id": "2408.08343v2",
    "title": "API-guided Dataset Synthesis to Finetune Large Code Models",
    "authors": [
      "Zongjie Li",
      "Daoyuan Wu",
      "Shuai Wang",
      "Zhendong Su"
    ],
    "abstract": "Large code models (LCMs), pre-trained on vast code corpora, have demonstrated\nremarkable performance across a wide array of code-related tasks. Supervised\nfine-tuning (SFT) plays a vital role in aligning these models with specific\nrequirements and enhancing their performance in particular domains. However,\nsynthesizing high-quality SFT datasets poses a significant challenge due to the\nuneven quality of datasets and the scarcity of domain-specific datasets.\n  Inspired by APIs as high-level abstractions of code that encapsulate rich\nsemantic information in a concise structure, we propose DataScope, an\nAPI-guided dataset synthesis framework designed to enhance the SFT process for\nLCMs in both general and domain-specific scenarios. DataScope comprises two\nmain components: Dsel and Dgen. On one hand, Dsel employs API coverage as a\ncore metric, enabling efficient dataset synthesis in general scenarios by\nselecting subsets of existing (uneven-quality) datasets with higher API\ncoverage. On the other hand, Dgen recasts domain dataset synthesis as a process\nof using API-specified high-level functionality and deliberately-constituted\ncode skeletons to synthesize concrete code.\n  Extensive experiments demonstrate DataScope's effectiveness, with models\nfine-tuned on its synthesized datasets outperforming those tuned on unoptimized\ndatasets five times larger. Furthermore, a series of analyses on model\ninternals, relevant hyperparameters, and case studies provide additional\nevidence for the efficacy of our proposed methods. These findings underscore\nthe significance of dataset quality in SFT and advance the field of LCMs by\nproviding an efficient, cost-effective framework for constructing high-quality\ndatasets. This contribution enhances performance across both general and\ndomain-specific scenarios, paving the way for more powerful and tailored LCMs.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08343v2",
    "published_date": "2024-08-15 14:48:42 UTC",
    "updated_date": "2024-08-22 11:29:51 UTC"
  },
  {
    "arxiv_id": "2408.08188v4",
    "title": "Nl2Hltl2Plan: Scaling Up Natural Language Understanding for Multi-Robots Through Hierarchical Temporal Logic Task Representation",
    "authors": [
      "Shaojun Xu",
      "Xusheng Luo",
      "Yutong Huang",
      "Letian Leng",
      "Ruixuan Liu",
      "Changliu Liu"
    ],
    "abstract": "To enable non-experts to specify long-horizon, multi-robot collaborative\ntasks, language models are increasingly used to translate natural language\ncommands into formal specifications. However, because translation can occur in\nmultiple ways, such translations may lack accuracy or lead to inefficient\nmulti-robot planning. Our key insight is that concise hierarchical\nspecifications can simplify planning while remaining straightforward to derive\nfrom human instructions. We propose Nl2Hltl2Plan, a framework that translates\nnatural language commands into hierarchical Linear Temporal Logic (LTL) and\nsolves the corresponding planning problem. The translation involves two steps\nleveraging Large Language Models (LLMs). First, an LLM transforms instructions\ninto a Hierarchical Task Tree, capturing logical and temporal relations. Next,\na fine-tuned LLM converts sub-tasks into flat LTL formulas, which are\naggregated into hierarchical specifications, with the lowest level\ncorresponding to ordered robot actions. These specifications are then used with\noff-the-shelf planners. Our Nl2Hltl2Plan demonstrates the potential of LLMs in\nhierarchical reasoning for multi-robot task planning. Evaluations in simulation\nand real-world experiments with human participants show that Nl2Hltl2Plan\noutperforms existing methods, handling more complex instructions while\nachieving higher success rates and lower costs in task allocation and planning.\nAdditional details are available at https://nl2hltl2plan.github.io .",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08188v4",
    "published_date": "2024-08-15 14:46:13 UTC",
    "updated_date": "2024-12-05 05:37:46 UTC"
  },
  {
    "arxiv_id": "2408.08182v2",
    "title": "Your Turn: At Home Turning Angle Estimation for Parkinson's Disease Severity Assessment",
    "authors": [
      "Qiushuo Cheng",
      "Catherine Morgan",
      "Arindam Sikdar",
      "Alessandro Masullo",
      "Alan Whone",
      "Majid Mirmehdi"
    ],
    "abstract": "People with Parkinson's Disease (PD) often experience progressively worsening\ngait, including changes in how they turn around, as the disease progresses.\nExisting clinical rating tools are not capable of capturing hour-by-hour\nvariations of PD symptoms, as they are confined to brief assessments within\nclinic settings. Measuring gait turning angles continuously and passively is a\ncomponent step towards using gait characteristics as sensitive indicators of\ndisease progression in PD. This paper presents a deep learning-based approach\nto automatically quantify turning angles by extracting 3D skeletons from videos\nand calculating the rotation of hip and knee joints. We utilise\nstate-of-the-art human pose estimation models, Fastpose and Strided\nTransformer, on a total of 1386 turning video clips from 24 subjects (12 people\nwith PD and 12 healthy control volunteers), trimmed from a PD dataset of\nunscripted free-living videos in a home-like setting (Turn-REMAP). We also\ncurate a turning video dataset, Turn-H3.6M, from the public Human3.6M human\npose benchmark with 3D ground truth, to further validate our method. Previous\ngait research has primarily taken place in clinics or laboratories evaluating\nscripted gait outcomes, but this work focuses on free-living home settings\nwhere complexities exist, such as baggy clothing and poor lighting. Due to\ndifficulties in obtaining accurate ground truth data in a free-living setting,\nwe quantise the angle into the nearest bin $45^\\circ$ based on the manual\nlabelling of expert clinicians. Our method achieves a turning calculation\naccuracy of 41.6%, a Mean Absolute Error (MAE) of 34.7{\\deg}, and a weighted\nprecision WPrec of 68.3% for Turn-REMAP. This is the first work to explore the\nuse of single monocular camera data to quantify turns by PD patients in a home\nsetting.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08182v2",
    "published_date": "2024-08-15 14:36:07 UTC",
    "updated_date": "2024-08-24 16:18:50 UTC"
  },
  {
    "arxiv_id": "2408.08172v2",
    "title": "Towards flexible perception with visual memory",
    "authors": [
      "Robert Geirhos",
      "Priyank Jaini",
      "Austin Stone",
      "Sourabh Medapati",
      "Xi Yi",
      "George Toderici",
      "Abhijit Ogale",
      "Jonathon Shlens"
    ],
    "abstract": "Training a neural network is a monolithic endeavor, akin to carving knowledge\ninto stone: once the process is completed, editing the knowledge in a network\nis nearly impossible, since all information is distributed across the network's\nweights. We here explore a simple, compelling alternative by marrying the\nrepresentational power of deep neural networks with the flexibility of a\ndatabase. Decomposing the task of image classification into image similarity\n(from a pre-trained embedding) and search (via fast nearest neighbor retrieval\nfrom a knowledge database), we build a simple and flexible visual memory that\nhas the following key capabilities: (1.) The ability to flexibly add data\nacross scales: from individual samples all the way to entire classes and\nbillion-scale data; (2.) The ability to remove data through unlearning and\nmemory pruning; (3.) An interpretable decision-mechanism on which we can\nintervene to control its behavior. Taken together, these capabilities\ncomprehensively demonstrate the benefits of an explicit visual memory. We hope\nthat it might contribute to a conversation on how knowledge should be\nrepresented in deep vision models -- beyond carving it in \"stone\" weights.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Adding link to code at\n  https://github.com/google-deepmind/visual-memory",
    "pdf_url": "http://arxiv.org/pdf/2408.08172v2",
    "published_date": "2024-08-15 14:19:13 UTC",
    "updated_date": "2024-09-17 13:35:04 UTC"
  },
  {
    "arxiv_id": "2408.08160v3",
    "title": "General-purpose Clothes Manipulation with Semantic Keypoints",
    "authors": [
      "Yuhong Deng",
      "David Hsu"
    ],
    "abstract": "Clothes manipulation is a critical capability for household robots; yet,\nexisting methods are often confined to specific tasks, such as folding or\nflattening, due to the complex high-dimensional geometry of deformable fabric.\nThis paper presents CLothes mAnipulation with Semantic keyPoints (CLASP) for\ngeneral-purpose clothes manipulation, which enables the robot to perform\ndiverse manipulation tasks over different types of clothes. The key idea of\nCLASP is semantic keypoints -- e.g., \"right shoulder\", \"left sleeve\", etc. -- a\nsparse spatial-semantic representation that is salient for both perception and\naction. Semantic keypoints of clothes can be effectively extracted from depth\nimages and are sufficient to represent a broad range of clothes manipulation\npolicies. CLASP leverages semantic keypoints to bridge LLM-powered task\nplanning and low-level action execution in a two-level hierarchy. Extensive\nsimulation experiments show that CLASP outperforms baseline methods across\ndiverse clothes types in both seen and unseen tasks. Further, experiments with\na Kinova dual-arm system on four distinct tasks -- folding, flattening,\nhanging, and placing -- confirm CLASP's performance on a real robot.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "accepted by IEEE International Conference on Robotics and Automation\n  (ICRA 2025)",
    "pdf_url": "http://arxiv.org/pdf/2408.08160v3",
    "published_date": "2024-08-15 13:49:14 UTC",
    "updated_date": "2025-03-26 06:56:09 UTC"
  },
  {
    "arxiv_id": "2408.08152v1",
    "title": "DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search",
    "authors": [
      "Huajian Xin",
      "Z. Z. Ren",
      "Junxiao Song",
      "Zhihong Shao",
      "Wanjia Zhao",
      "Haocheng Wang",
      "Bo Liu",
      "Liyue Zhang",
      "Xuan Lu",
      "Qiushi Du",
      "Wenjun Gao",
      "Qihao Zhu",
      "Dejian Yang",
      "Zhibin Gou",
      "Z. F. Wu",
      "Fuli Luo",
      "Chong Ruan"
    ],
    "abstract": "We introduce DeepSeek-Prover-V1.5, an open-source language model designed for\ntheorem proving in Lean 4, which enhances DeepSeek-Prover-V1 by optimizing both\ntraining and inference processes. Pre-trained on DeepSeekMath-Base with\nspecialization in formal mathematical languages, the model undergoes supervised\nfine-tuning using an enhanced formal theorem proving dataset derived from\nDeepSeek-Prover-V1. Further refinement is achieved through reinforcement\nlearning from proof assistant feedback (RLPAF). Beyond the single-pass\nwhole-proof generation approach of DeepSeek-Prover-V1, we propose RMaxTS, a\nvariant of Monte-Carlo tree search that employs an intrinsic-reward-driven\nexploration strategy to generate diverse proof paths. DeepSeek-Prover-V1.5\ndemonstrates significant improvements over DeepSeek-Prover-V1, achieving new\nstate-of-the-art results on the test set of the high school level miniF2F\nbenchmark ($63.5\\%$) and the undergraduate level ProofNet benchmark ($25.3\\%$).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08152v1",
    "published_date": "2024-08-15 13:40:03 UTC",
    "updated_date": "2024-08-15 13:40:03 UTC"
  },
  {
    "arxiv_id": "2408.08150v1",
    "title": "Winning Snake: Design Choices in Multi-Shot ASP",
    "authors": [
      "Elisa B√∂hl",
      "Stefan Ellmauthaler",
      "Sarah Alice Gaggl"
    ],
    "abstract": "Answer set programming is a well-understood and established problem-solving\nand knowledge representation paradigm. It has become more prominent amongst a\nwider audience due to its multiple applications in science and industry. The\nconstant development of advanced programming and modeling techniques extends\nthe toolset for developers and users regularly. This paper demonstrates\ndifferent techniques to reuse logic program parts (multi-shot) by solving the\narcade game snake. This game is particularly interesting because a victory can\nbe assured by solving the underlying NP-hard problem of Hamiltonian Cycles. We\nwill demonstrate five hands-on implementations in clingo and compare their\nperformance in an empirical evaluation. In addition, our implementation\nutilizes clingraph to generate a simple yet informative image representation of\nthe game's progress.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 3 figures, to appear in Theory and Practice of Logic\n  Programming (TPLP), Proceedings of ICLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08150v1",
    "published_date": "2024-08-15 13:37:59 UTC",
    "updated_date": "2024-08-15 13:37:59 UTC"
  },
  {
    "arxiv_id": "2408.08341v1",
    "title": "Exploring Latent Space for Generating Peptide Analogs Using Protein Language Models",
    "authors": [
      "Po-Yu Liang",
      "Xueting Huang",
      "Tibo Duran",
      "Andrew J. Wiemer",
      "Jun Bai"
    ],
    "abstract": "Generating peptides with desired properties is crucial for drug discovery and\nbiotechnology. Traditional sequence-based and structure-based methods often\nrequire extensive datasets, which limits their effectiveness. In this study, we\nproposed a novel method that utilized autoencoder shaped models to explore the\nprotein embedding space, and generate novel peptide analogs by leveraging\nprotein language models. The proposed method requires only a single sequence of\ninterest, avoiding the need for large datasets. Our results show significant\nimprovements over baseline models in similarity indicators of peptide\nstructures, descriptors and bioactivities. The proposed method validated\nthrough Molecular Dynamics simulations on TIGIT inhibitors, demonstrates that\nour method produces peptide analogs with similar yet distinct properties,\nhighlighting its potential to enhance peptide screening processes.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08341v1",
    "published_date": "2024-08-15 13:37:27 UTC",
    "updated_date": "2024-08-15 13:37:27 UTC"
  },
  {
    "arxiv_id": "2408.08145v1",
    "title": "Model-based Workflow for the Automated Generation of PDDL Descriptions",
    "authors": [
      "Hamied Nabizada",
      "Tom Jeleniewski",
      "Felix Gehlhoff",
      "Alexander Fay"
    ],
    "abstract": "Manually creating Planning Domain Definition Language (PDDL) descriptions is\ndifficult, error-prone, and requires extensive expert knowledge. However, this\nknowledge is already embedded in engineering models and can be reused.\nTherefore, this contribution presents a comprehensive workflow for the\nautomated generation of PDDL descriptions from integrated system and product\nmodels. The proposed workflow leverages Model-Based Systems Engineering (MBSE)\nto organize and manage system and product information, translating it\nautomatically into PDDL syntax for planning purposes. By connecting system and\nproduct models with planning aspects, it ensures that changes in these models\nare quickly reflected in updated PDDL descriptions, facilitating efficient and\nadaptable planning processes. The workflow is validated within a use case from\naircraft assembly.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08145v1",
    "published_date": "2024-08-15 13:29:25 UTC",
    "updated_date": "2024-08-15 13:29:25 UTC"
  },
  {
    "arxiv_id": "2408.08133v1",
    "title": "EXPLAIN, AGREE, LEARN: Scaling Learning for Neural Probabilistic Logic",
    "authors": [
      "Victor Verreet",
      "Lennert De Smet",
      "Luc De Raedt",
      "Emanuele Sansone"
    ],
    "abstract": "Neural probabilistic logic systems follow the neuro-symbolic (NeSy) paradigm\nby combining the perceptive and learning capabilities of neural networks with\nthe robustness of probabilistic logic. Learning corresponds to likelihood\noptimization of the neural networks. However, to obtain the likelihood exactly,\nexpensive probabilistic logic inference is required. To scale learning to more\ncomplex systems, we therefore propose to instead optimize a sampling based\nobjective. We prove that the objective has a bounded error with respect to the\nlikelihood, which vanishes when increasing the sample count. Furthermore, the\nerror vanishes faster by exploiting a new concept of sample diversity. We then\ndevelop the EXPLAIN, AGREE, LEARN (EXAL) method that uses this objective.\nEXPLAIN samples explanations for the data. AGREE reweighs each explanation in\nconcordance with the neural component. LEARN uses the reweighed explanations as\na signal for learning. In contrast to previous NeSy methods, EXAL can scale to\nlarger problem sizes while retaining theoretical guarantees on the error.\nExperimentally, our theoretical claims are verified and EXAL outperforms recent\nNeSy methods when scaling up the MNIST addition and Warcraft pathfinding\nproblems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08133v1",
    "published_date": "2024-08-15 13:07:51 UTC",
    "updated_date": "2024-08-15 13:07:51 UTC"
  },
  {
    "arxiv_id": "2409.00007v1",
    "title": "Federated Sequence-to-Sequence Learning for Load Disaggregation from Unbalanced Low-Resolution Smart Meter Data",
    "authors": [
      "Xiangrui Li"
    ],
    "abstract": "The importance of Non-Intrusive Load Monitoring (NILM) has been increasingly\nrecognized, given that NILM can enhance energy awareness and provide valuable\ninsights for energy program design. Many existing NILM methods often rely on\nspecialized devices to retrieve high-sampling complex signal data and focus on\nthe high consumption appliances, hindering their applicability in real-world\napplications, especially when smart meters only provide low-resolution active\npower readings for households. In this paper, we propose a new approach using\neasily accessible weather data to achieve load disaggregation for a total of 12\nappliances, encompassing both high and low consumption, in scenarios with very\nlow sampling rates (hourly). Moreover, We develop a federated learning (FL)\nmodel that builds upon a sequence-to-sequence model to fulfil load\ndisaggregation without data sharing. Our experiments demonstrate that the FL\nframework - L2GD can effectively handle statistical heterogeneity and avoid\noverfitting problems. By incorporating weather data, our approach significantly\nimproves the performance of NILM.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00007v1",
    "published_date": "2024-08-15 13:04:49 UTC",
    "updated_date": "2024-08-15 13:04:49 UTC"
  },
  {
    "arxiv_id": "2408.16776v1",
    "title": "Online Behavior Modification for Expressive User Control of RL-Trained Robots",
    "authors": [
      "Isaac Sheidlower",
      "Mavis Murdock",
      "Emma Bethel",
      "Reuben M. Aronson",
      "Elaine Schaertl Short"
    ],
    "abstract": "Reinforcement Learning (RL) is an effective method for robots to learn tasks.\nHowever, in typical RL, end-users have little to no control over how the robot\ndoes the task after the robot has been deployed. To address this, we introduce\nthe idea of online behavior modification, a paradigm in which users have\ncontrol over behavior features of a robot in real time as it autonomously\ncompletes a task using an RL-trained policy. To show the value of this\nuser-centered formulation for human-robot interaction, we present a behavior\ndiversity based algorithm, Adjustable Control Of RL Dynamics (ACORD), and\ndemonstrate its applicability to online behavior modification in simulation and\na user study. In the study (n=23) users adjust the style of paintings as a\nrobot traces a shape autonomously. We compare ACORD to RL and Shared Autonomy\n(SA), and show ACORD affords user-preferred levels of control and expression,\ncomparable to SA, but with the potential for autonomous execution and\nrobustness of RL.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "This work was published and presented at HRI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.16776v1",
    "published_date": "2024-08-15 12:28:08 UTC",
    "updated_date": "2024-08-15 12:28:08 UTC"
  },
  {
    "arxiv_id": "2408.08921v2",
    "title": "Graph Retrieval-Augmented Generation: A Survey",
    "authors": [
      "Boci Peng",
      "Yun Zhu",
      "Yongchao Liu",
      "Xiaohe Bo",
      "Haizhou Shi",
      "Chuntao Hong",
      "Yan Zhang",
      "Siliang Tang"
    ],
    "abstract": "Recently, Retrieval-Augmented Generation (RAG) has achieved remarkable\nsuccess in addressing the challenges of Large Language Models (LLMs) without\nnecessitating retraining. By referencing an external knowledge base, RAG\nrefines LLM outputs, effectively mitigating issues such as ``hallucination'',\nlack of domain-specific knowledge, and outdated information. However, the\ncomplex structure of relationships among different entities in databases\npresents challenges for RAG systems. In response, GraphRAG leverages structural\ninformation across entities to enable more precise and comprehensive retrieval,\ncapturing relational knowledge and facilitating more accurate, context-aware\nresponses. Given the novelty and potential of GraphRAG, a systematic review of\ncurrent technologies is imperative. This paper provides the first comprehensive\noverview of GraphRAG methodologies. We formalize the GraphRAG workflow,\nencompassing Graph-Based Indexing, Graph-Guided Retrieval, and Graph-Enhanced\nGeneration. We then outline the core technologies and training methods at each\nstage. Additionally, we examine downstream tasks, application domains,\nevaluation methodologies, and industrial use cases of GraphRAG. Finally, we\nexplore future research directions to inspire further inquiries and advance\nprogress in the field. In order to track recent progress in this field, we set\nup a repository at \\url{https://github.com/pengboci/GraphRAG-Survey}.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "Ongoing work. Compared to the first version, several references have\n  been added and a GitHub repository link has been provided",
    "pdf_url": "http://arxiv.org/pdf/2408.08921v2",
    "published_date": "2024-08-15 12:20:24 UTC",
    "updated_date": "2024-09-10 15:38:56 UTC"
  },
  {
    "arxiv_id": "2408.08105v3",
    "title": "Multimodal Causal Reasoning Benchmark: Challenging Vision Large Language Models to Discern Causal Links Across Modalities",
    "authors": [
      "Zhiyuan Li",
      "Heng Wang",
      "Dongnan Liu",
      "Chaoyi Zhang",
      "Ao Ma",
      "Jieting Long",
      "Weidong Cai"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have showcased exceptional\nChain-of-Thought (CoT) reasoning ability in complex textual inference tasks\nincluding causal reasoning. However, will these causalities remain\nstraightforward when crucial hints hide in visual details? If not, what factors\nmight influence cross-modal generalization? Whether we can effectively enhance\ntheir capacity for robust causal inference across both text and vision?\nMotivated by these, we introduce MuCR - a novel Multimodal Causal Reasoning\nbenchmark that leverages synthetic siamese images and text pairs to challenge\nMLLMs. Additionally, we develop tailored metrics from multiple perspectives,\nincluding image-level match, phrase-level understanding, and sentence-level\nexplanation, to comprehensively assess MLLMs' comprehension abilities. Our\nexperiments reveal that current MLLMs fall short in multimodal causal reasoning\ncompared to their performance in purely textual settings. Additionally, we find\nthat identifying visual cues across images is key to effective cross-modal\ngeneralization. Finally, we propose a VcCoT strategy that better highlights\nvisual cues, and our results confirm its efficacy in enhancing multimodal\ncausal reasoning. The project is available at:\nhttps://github.com/Zhiyuan-Li-John/MuCR",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "25 pages 26 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.08105v3",
    "published_date": "2024-08-15 12:04:32 UTC",
    "updated_date": "2025-02-16 04:12:08 UTC"
  },
  {
    "arxiv_id": "2409.00005v1",
    "title": "Csi-LLM: A Novel Downlink Channel Prediction Method Aligned with LLM Pre-Training",
    "authors": [
      "Shilong Fan",
      "Zhenyu Liu",
      "Xinyu Gu",
      "Haozhen Li"
    ],
    "abstract": "Downlink channel temporal prediction is a critical technology in massive\nmultiple-input multiple-output (MIMO) systems. However, existing methods that\nrely on fixed-step historical sequences significantly limit the accuracy,\npracticality, and scalability of channel prediction. Recent advances have shown\nthat large language models (LLMs) exhibit strong pattern recognition and\nreasoning abilities over complex sequences. The challenge lies in effectively\naligning wireless communication data with the modalities used in natural\nlanguage processing to fully harness these capabilities. In this work, we\nintroduce Csi-LLM, a novel LLM-powered downlink channel prediction technique\nthat models variable-step historical sequences. To ensure effective\ncross-modality application, we align the design and training of Csi-LLM with\nthe processing of natural language tasks, leveraging the LLM's next-token\ngeneration capability for predicting the next step in channel state information\n(CSI). Simulation results demonstrate the effectiveness of this alignment\nstrategy, with Csi-LLM consistently delivering stable performance improvements\nacross various scenarios and showing significant potential in continuous\nmulti-step prediction.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00005v1",
    "published_date": "2024-08-15 11:39:23 UTC",
    "updated_date": "2024-08-15 11:39:23 UTC"
  },
  {
    "arxiv_id": "2408.08092v3",
    "title": "SC3D: Label-Efficient Outdoor 3D Object Detection via Single Click Annotation",
    "authors": [
      "Qiming Xia",
      "Hongwei Lin",
      "Wei Ye",
      "Hai Wu",
      "Yadan Luo",
      "Cheng Wang",
      "Chenglu Wen"
    ],
    "abstract": "LiDAR-based outdoor 3D object detection has received widespread attention.\nHowever, training 3D detectors from the LiDAR point cloud typically relies on\nexpensive bounding box annotations. This paper presents SC3D, an innovative\nlabel-efficient method requiring only a single coarse click on the bird's eye\nview of the 3D point cloud for each frame. A key challenge here is the absence\nof complete geometric descriptions of the target objects from such simple click\nannotations. To address this issue, our proposed SC3D adopts a progressive\npipeline. Initially, we design a mixed pseudo-label generation module that\nexpands limited click annotations into a mixture of bounding box and semantic\nmask supervision. Next, we propose a mix-supervised teacher model, enabling the\ndetector to learn mixed supervision information. Finally, we introduce a\nmixed-supervised student network that leverages the teacher model's\ngeneralization ability to learn unclicked instances.Experimental results on the\nwidely used nuScenes and KITTI datasets demonstrate that our SC3D with only\ncoarse clicks, which requires only 0.2% annotation cost, achieves\nstate-of-the-art performance compared to weakly-supervised 3D detection\nmethods.The code will be made publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08092v3",
    "published_date": "2024-08-15 11:34:53 UTC",
    "updated_date": "2024-11-15 05:01:34 UTC"
  },
  {
    "arxiv_id": "2408.08089v1",
    "title": "AgentCourt: Simulating Court with Adversarial Evolvable Lawyer Agents",
    "authors": [
      "Guhong Chen",
      "Liyang Fan",
      "Zihan Gong",
      "Nan Xie",
      "Zixuan Li",
      "Ziqiang Liu",
      "Chengming Li",
      "Qiang Qu",
      "Shiwen Ni",
      "Min Yang"
    ],
    "abstract": "In this paper, we present a simulation system called AgentCourt that\nsimulates the entire courtroom process. The judge, plaintiff's lawyer, defense\nlawyer, and other participants are autonomous agents driven by large language\nmodels (LLMs). Our core goal is to enable lawyer agents to learn how to argue a\ncase, as well as improving their overall legal skills, through courtroom\nprocess simulation. To achieve this goal, we propose an adversarial\nevolutionary approach for the lawyer-agent. Since AgentCourt can simulate the\noccurrence and development of court hearings based on a knowledge base and LLM,\nthe lawyer agents can continuously learn and accumulate experience from real\ncourt cases. The simulation experiments show that after two lawyer-agents have\nengaged in a thousand adversarial legal cases in AgentCourt (which can take a\ndecade for real-world lawyers), compared to their pre-evolutionary state, the\nevolved lawyer agents exhibit consistent improvement in their ability to handle\nlegal tasks. To enhance the credibility of our experimental results, we\nenlisted a panel of professional lawyers to evaluate our simulations. The\nevaluation indicates that the evolved lawyer agents exhibit notable\nadvancements in responsiveness, as well as expertise and logical rigor. This\nwork paves the way for advancing LLM-driven agent technology in legal\nscenarios. Code is available at https://github.com/relic-yuexi/AgentCourt.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08089v1",
    "published_date": "2024-08-15 11:33:20 UTC",
    "updated_date": "2024-08-15 11:33:20 UTC"
  },
  {
    "arxiv_id": "2408.08084v1",
    "title": "An Efficient Replay for Class-Incremental Learning with Pre-trained Models",
    "authors": [
      "Weimin Yin",
      "Bin Chen adn Chunzhao Xie",
      "Zhenhao Tan"
    ],
    "abstract": "In general class-incremental learning, researchers typically use sample sets\nas a tool to avoid catastrophic forgetting during continuous learning. At the\nsame time, researchers have also noted the differences between\nclass-incremental learning and Oracle training and have attempted to make\ncorrections. In recent years, researchers have begun to develop\nclass-incremental learning algorithms utilizing pre-trained models, achieving\nsignificant results. This paper observes that in class-incremental learning,\nthe steady state among the weight guided by each class center is disrupted,\nwhich is significantly correlated with catastrophic forgetting. Based on this,\nwe propose a new method to overcoming forgetting . In some cases, by retaining\nonly a single sample unit of each class in memory for replay and applying\nsimple gradient constraints, very good results can be achieved. Experimental\nresults indicate that under the condition of pre-trained models, our method can\nachieve competitive performance with very low computational cost and by simply\nusing the cross-entropy loss.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08084v1",
    "published_date": "2024-08-15 11:26:28 UTC",
    "updated_date": "2024-08-15 11:26:28 UTC"
  },
  {
    "arxiv_id": "2408.08083v2",
    "title": "Confidence-weighted integration of human and machine judgments for superior decision-making",
    "authors": [
      "Felipe Y√°√±ez",
      "Xiaoliang Luo",
      "Omar Valerio Minero",
      "Bradley C. Love"
    ],
    "abstract": "Large language models (LLMs) have emerged as powerful tools in various\ndomains. Recent studies have shown that LLMs can surpass humans in certain\ntasks, such as predicting the outcomes of neuroscience studies. What role does\nthis leave for humans in the overall decision process? One possibility is that\nhumans, despite performing worse than LLMs, can still add value when teamed\nwith them. A human and machine team can surpass each individual teammate when\nteam members' confidence is well-calibrated and team members diverge in which\ntasks they find difficult (i.e., calibration and diversity are needed). We\nsimplified and extended a Bayesian approach to combining judgments using a\nlogistic regression framework that integrates confidence-weighted judgments for\nany number of team members. Using this straightforward method, we demonstrated\nin a neuroscience forecasting task that, even when humans were inferior to\nLLMs, their combination with one or more LLMs consistently improved team\nperformance. Our hope is that this simple and effective strategy for\nintegrating the judgments of humans and machines will lead to productive\ncollaborations.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08083v2",
    "published_date": "2024-08-15 11:16:21 UTC",
    "updated_date": "2025-04-02 00:02:16 UTC"
  },
  {
    "arxiv_id": "2408.08078v1",
    "title": "Treat Stillness with Movement: Remote Sensing Change Detection via Coarse-grained Temporal Foregrounds Mining",
    "authors": [
      "Xixi Wang",
      "Zitian Wang",
      "Jingtao Jiang",
      "Lan Chen",
      "Xiao Wang",
      "Bo Jiang"
    ],
    "abstract": "Current works focus on addressing the remote sensing change detection task\nusing bi-temporal images. Although good performance can be achieved, however,\nseldom of they consider the motion cues which may also be vital. In this work,\nwe revisit the widely adopted bi-temporal images-based framework and propose a\nnovel Coarse-grained Temporal Mining Augmented (CTMA) framework. To be\nspecific, given the bi-temporal images, we first transform them into a video\nusing interpolation operations. Then, a set of temporal encoders is adopted to\nextract the motion features from the obtained video for coarse-grained changed\nregion prediction. Subsequently, we design a novel Coarse-grained Foregrounds\nAugmented Spatial Encoder module to integrate both global and local\ninformation. We also introduce a motion augmented strategy that leverages\nmotion cues as an additional output to aggregate with the spatial features for\nimproved results. Meanwhile, we feed the input image pairs into the ResNet to\nget the different features and also the spatial blocks for fine-grained feature\nlearning. More importantly, we propose a mask augmented strategy that utilizes\ncoarse-grained changed regions, incorporating them into the decoder blocks to\nenhance the final changed prediction. Extensive experiments conducted on\nmultiple benchmark datasets fully validated the effectiveness of our proposed\nframework for remote sensing image change detection. The source code of this\npaper will be released on\nhttps://github.com/Event-AHU/CTM_Remote_Sensing_Change_Detection",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "In Peer Review",
    "pdf_url": "http://arxiv.org/pdf/2408.08078v1",
    "published_date": "2024-08-15 11:04:26 UTC",
    "updated_date": "2024-08-15 11:04:26 UTC"
  },
  {
    "arxiv_id": "2408.08074v3",
    "title": "A Survey on Integrated Sensing, Communication, and Computation",
    "authors": [
      "Dingzhu Wen",
      "Yong Zhou",
      "Xiaoyang Li",
      "Yuanming Shi",
      "Kaibin Huang",
      "Khaled B. Letaief"
    ],
    "abstract": "The forthcoming generation of wireless technology, 6G, aims to usher in an\nera of ubiquitous intelligent services, where everything is interconnected and\nintelligent. This vision requires the seamless integration of three fundamental\nmodules: Sensing for information acquisition, communication for information\nsharing, and computation for information processing and decision-making. These\nmodules are intricately linked, especially in complex tasks such as edge\nlearning and inference. However, the performance of these modules is\ninterdependent, creating a resource competition for time, energy, and\nbandwidth. Existing techniques like integrated communication and computation\n(ICC), integrated sensing and computation (ISC), and integrated sensing and\ncommunication (ISAC) have made partial strides in addressing this challenge,\nbut they fall short of meeting the extreme performance requirements. To\novercome these limitations, it is essential to develop new techniques that\ncomprehensively integrate sensing, communication, and computation. This\nintegrated approach, known as Integrated Sensing, Communication, and\nComputation (ISCC), offers a systematic perspective for enhancing task\nperformance. This paper begins with a comprehensive survey of historic and\nrelated techniques such as ICC, ISC, and ISAC, highlighting their strengths and\nlimitations. It then discusses the benefits, functions, and challenges of ISCC.\nSubsequently, the state-of-the-art signal designs for ISCC, along with network\nresource management strategies specifically tailored for ISCC are explored.\nFurthermore, this paper discusses the exciting research opportunities that lie\nahead for implementing ISCC in future advanced networks, and the unresolved\nissues requiring further investigation. ISCC is expected to unlock the full\npotential of intelligent connectivity, paving the way for groundbreaking\napplications and services.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "This version is accepted by IEEE Communications Surveys & Tutorials\n  on Dec. 18, 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08074v3",
    "published_date": "2024-08-15 11:01:35 UTC",
    "updated_date": "2024-12-18 14:38:31 UTC"
  },
  {
    "arxiv_id": "2408.08067v2",
    "title": "RAGChecker: A Fine-grained Framework for Diagnosing Retrieval-Augmented Generation",
    "authors": [
      "Dongyu Ru",
      "Lin Qiu",
      "Xiangkun Hu",
      "Tianhang Zhang",
      "Peng Shi",
      "Shuaichen Chang",
      "Cheng Jiayang",
      "Cunxiang Wang",
      "Shichao Sun",
      "Huanyu Li",
      "Zizhao Zhang",
      "Binjie Wang",
      "Jiarong Jiang",
      "Tong He",
      "Zhiguo Wang",
      "Pengfei Liu",
      "Yue Zhang",
      "Zheng Zhang"
    ],
    "abstract": "Despite Retrieval-Augmented Generation (RAG) showing promising capability in\nleveraging external knowledge, a comprehensive evaluation of RAG systems is\nstill challenging due to the modular nature of RAG, evaluation of long-form\nresponses and reliability of measurements. In this paper, we propose a\nfine-grained evaluation framework, RAGChecker, that incorporates a suite of\ndiagnostic metrics for both the retrieval and generation modules. Meta\nevaluation verifies that RAGChecker has significantly better correlations with\nhuman judgments than other evaluation metrics. Using RAGChecker, we evaluate 8\nRAG systems and conduct an in-depth analysis of their performance, revealing\ninsightful patterns and trade-offs in the design choices of RAG architectures.\nThe metrics of RAGChecker can guide researchers and practitioners in developing\nmore effective RAG systems. This work has been open sourced at\nhttps://github.com/amazon-science/RAGChecker.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under Review. Github Repo:\n  https://github.com/amazon-science/RAGChecker",
    "pdf_url": "http://arxiv.org/pdf/2408.08067v2",
    "published_date": "2024-08-15 10:20:54 UTC",
    "updated_date": "2024-08-17 00:30:04 UTC"
  },
  {
    "arxiv_id": "2408.08065v3",
    "title": "SPEED: Scalable Preprocessing of EEG Data for Self-Supervised Learning",
    "authors": [
      "Anders Gj√∏lbye",
      "Lina Skerath",
      "William Lehn-Schi√∏ler",
      "Nicolas Langer",
      "Lars Kai Hansen"
    ],
    "abstract": "Electroencephalography (EEG) research typically focuses on tasks with\nnarrowly defined objectives, but recent studies are expanding into the use of\nunlabeled data within larger models, aiming for a broader range of\napplications. This addresses a critical challenge in EEG research. For example,\nKostas et al. (2021) show that self-supervised learning (SSL) outperforms\ntraditional supervised methods. Given the high noise levels in EEG data, we\nargue that further improvements are possible with additional preprocessing.\nCurrent preprocessing methods often fail to efficiently manage the large data\nvolumes required for SSL, due to their lack of optimization, reliance on\nsubjective manual corrections, and validation processes or inflexible protocols\nthat limit SSL. We propose a Python-based EEG preprocessing pipeline optimized\nfor self-supervised learning, designed to efficiently process large-scale data.\nThis optimization not only stabilizes self-supervised training but also\nenhances performance on downstream tasks compared to training with raw data.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "To appear in proceedings of 2024 IEEE International workshop on\n  Machine Learning for Signal Processing",
    "pdf_url": "http://arxiv.org/pdf/2408.08065v3",
    "published_date": "2024-08-15 10:15:01 UTC",
    "updated_date": "2024-09-23 10:30:15 UTC"
  },
  {
    "arxiv_id": "2408.08059v1",
    "title": "Maximally Permissive Reward Machines",
    "authors": [
      "Giovanni Varricchione",
      "Natasha Alechina",
      "Mehdi Dastani",
      "Brian Logan"
    ],
    "abstract": "Reward machines allow the definition of rewards for temporally extended tasks\nand behaviors. Specifying \"informative\" reward machines can be challenging. One\nway to address this is to generate reward machines from a high-level abstract\ndescription of the learning environment, using techniques such as AI planning.\nHowever, previous planning-based approaches generate a reward machine based on\na single (sequential or partial-order) plan, and do not allow maximum\nflexibility to the learning agent. In this paper we propose a new approach to\nsynthesising reward machines which is based on the set of partial order plans\nfor a goal. We prove that learning using such \"maximally permissive\" reward\nmachines results in higher rewards than learning using RMs based on a single\nplan. We present experimental results which support our theoretical claims by\nshowing that our approach obtains higher rewards than the single-plan approach\nin practice.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T05"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper accepted for publication at the European Conference on\n  Artificial Intelligence (ECAI) 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08059v1",
    "published_date": "2024-08-15 09:59:26 UTC",
    "updated_date": "2024-08-15 09:59:26 UTC"
  },
  {
    "arxiv_id": "2408.08058v1",
    "title": "Navigating Data Scarcity using Foundation Models: A Benchmark of Few-Shot and Zero-Shot Learning Approaches in Medical Imaging",
    "authors": [
      "Stefano Woerner",
      "Christian F. Baumgartner"
    ],
    "abstract": "Data scarcity is a major limiting factor for applying modern machine learning\ntechniques to clinical tasks. Although sufficient data exists for some\nwell-studied medical tasks, there remains a long tail of clinically relevant\ntasks with poor data availability. Recently, numerous foundation models have\ndemonstrated high suitability for few-shot learning (FSL) and zero-shot\nlearning (ZSL), potentially making them more accessible to practitioners.\nHowever, it remains unclear which foundation model performs best on FSL medical\nimage analysis tasks and what the optimal methods are for learning from limited\ndata. We conducted a comprehensive benchmark study of ZSL and FSL using 16\npretrained foundation models on 19 diverse medical imaging datasets. Our\nresults indicate that BiomedCLIP, a model pretrained exclusively on medical\ndata, performs best on average for very small training set sizes, while very\nlarge CLIP models pretrained on LAION-2B perform best with slightly more\ntraining samples. However, simply fine-tuning a ResNet-18 pretrained on\nImageNet performs similarly with more than five training examples per class.\nOur findings also highlight the need for further research on foundation models\nspecifically tailored for medical applications and the collection of more\ndatasets to train these models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as an oral presentation in MICCAI 2024 2nd International\n  Workshop on Foundation Models for General Medical AI",
    "pdf_url": "http://arxiv.org/pdf/2408.08058v1",
    "published_date": "2024-08-15 09:55:51 UTC",
    "updated_date": "2024-08-15 09:55:51 UTC"
  },
  {
    "arxiv_id": "2408.08055v2",
    "title": "DeNOTS: Stable Deep Neural ODEs for Time Series",
    "authors": [
      "Ilya Kuleshov",
      "Evgenia Romanenkova",
      "Galina Boeva",
      "Vladislav Zhuzhel",
      "Evgeni Vorsin",
      "Alexey Zaytsev"
    ],
    "abstract": "Neural ODEs are a prominent branch of methods designed to capture the\ntemporal evolution of complex time-stamped data. Their idea is to solve an ODE\nwith Neural Network-defined dynamics, which take the immediate parameters of\nthe observed system into account. However, larger integration intervals cause\ninstability, which forces most modern methods to normalize time to $[0, 1]$. We\nprovably stabilize these models by introducing an adaptive negative feedback\nmechanism. This modification allows for longer integration, which in turn\nimplies higher expressiveness, mirroring the behaviour of increasing depth in\nconventional Neural Networks.Additionally, it provides intriguing theoretical\nproperties: forgetfulness and missing-value robustness. For three open\ndatasets, our method obtains up to 20\\% improvements in downstream quality if\ncompared to existing baselines, including State Space Models and Neural~CDEs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08055v2",
    "published_date": "2024-08-15 09:49:37 UTC",
    "updated_date": "2025-04-15 09:49:17 UTC"
  },
  {
    "arxiv_id": "2408.08054v1",
    "title": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework",
    "authors": [
      "Changyu Du",
      "Sebastian Esser",
      "Stavros Nousias",
      "Andr√© Borrmann"
    ],
    "abstract": "The conventional BIM authoring process typically requires designers to master\ncomplex and tedious modeling commands in order to materialize their design\nintentions within BIM authoring tools. This additional cognitive burden\ncomplicates the design process and hinders the adoption of BIM and model-based\ndesign in the AEC (Architecture, Engineering, and Construction) industry. To\nfacilitate the expression of design intentions more intuitively, we propose\nText2BIM, an LLM-based multi-agent framework that can generate 3D building\nmodels from natural language instructions. This framework orchestrates multiple\nLLM agents to collaborate and reason, transforming textual user input into\nimperative code that invokes the BIM authoring tool's APIs, thereby generating\neditable BIM models with internal layouts, external envelopes, and semantic\ninformation directly in the software. Furthermore, a rule-based model checker\nis introduced into the agentic workflow, utilizing predefined domain knowledge\nto guide the LLM agents in resolving issues within the generated models and\niteratively improving model quality. Extensive experiments were conducted to\ncompare and analyze the performance of three different LLMs under the proposed\nframework. The evaluation results demonstrate that our approach can effectively\ngenerate high-quality, structurally rational building models that are aligned\nwith the abstract concepts specified by user input. Finally, an interactive\nsoftware prototype was developed to integrate the framework into the BIM\nauthoring software Vectorworks, showcasing the potential of modeling by\nchatting.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08054v1",
    "published_date": "2024-08-15 09:48:45 UTC",
    "updated_date": "2024-08-15 09:48:45 UTC"
  },
  {
    "arxiv_id": "2408.08041v1",
    "title": "The Clever Hans Effect in Unsupervised Learning",
    "authors": [
      "Jacob Kauffmann",
      "Jonas Dippel",
      "Lukas Ruff",
      "Wojciech Samek",
      "Klaus-Robert M√ºller",
      "Gr√©goire Montavon"
    ],
    "abstract": "Unsupervised learning has become an essential building block of AI systems.\nThe representations it produces, e.g. in foundation models, are critical to a\nwide variety of downstream applications. It is therefore important to carefully\nexamine unsupervised models to ensure not only that they produce accurate\npredictions, but also that these predictions are not \"right for the wrong\nreasons\", the so-called Clever Hans (CH) effect. Using specially developed\nExplainable AI techniques, we show for the first time that CH effects are\nwidespread in unsupervised learning. Our empirical findings are enriched by\ntheoretical insights, which interestingly point to inductive biases in the\nunsupervised learning machine as a primary source of CH effects. Overall, our\nwork sheds light on unexplored risks associated with practical applications of\nunsupervised learning and suggests ways to make unsupervised learning more\nrobust.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages + supplement",
    "pdf_url": "http://arxiv.org/pdf/2408.08041v1",
    "published_date": "2024-08-15 09:19:42 UTC",
    "updated_date": "2024-08-15 09:19:42 UTC"
  },
  {
    "arxiv_id": "2408.08024v1",
    "title": "Adaptive User Journeys in Pharma E-Commerce with Reinforcement Learning: Insights from SwipeRx",
    "authors": [
      "Ana Fern√°ndez del R√≠o",
      "Michael Brennan Leong",
      "Paulo Saraiva",
      "Ivan Nazarov",
      "Aditya Rastogi",
      "Moiz Hassan",
      "Dexian Tang",
      "√Åfrica Peri√°√±ez"
    ],
    "abstract": "This paper introduces a reinforcement learning (RL) platform that enhances\nend-to-end user journeys in healthcare digital tools through personalization.\nWe explore a case study with SwipeRx, the most popular all-in-one app for\npharmacists in Southeast Asia, demonstrating how the platform can be used to\npersonalize and adapt user experiences. Our RL framework is tested through a\nseries of experiments with product recommendations tailored to each pharmacy\nbased on real-time information on their purchasing history and in-app\nengagement, showing a significant increase in basket size. By integrating\nadaptive interventions into existing mobile health solutions and enriching user\njourneys, our platform offers a scalable solution to improve pharmaceutical\nsupply chain management, health worker capacity building, and clinical decision\nand patient care, ultimately contributing to better healthcare outcomes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at the Third Workshop on End-to-End Customer Journey\n  Optimization at KDD 2024 (KDD CJ Workshop '24), August 26, Barcelona, Spain",
    "pdf_url": "http://arxiv.org/pdf/2408.08024v1",
    "published_date": "2024-08-15 08:47:35 UTC",
    "updated_date": "2024-08-15 08:47:35 UTC"
  },
  {
    "arxiv_id": "2408.08023v1",
    "title": "Causal Discovery from Time-Series Data with Short-Term Invariance-Based Convolutional Neural Networks",
    "authors": [
      "Rujia Shen",
      "Boran Wang",
      "Chao Zhao",
      "Yi Guan",
      "Jingchi Jiang"
    ],
    "abstract": "Causal discovery from time-series data aims to capture both intra-slice\n(contemporaneous) and inter-slice (time-lagged) causality between variables\nwithin the temporal chain, which is crucial for various scientific disciplines.\nCompared to causal discovery from non-time-series data, causal discovery from\ntime-series data necessitates more serialized samples with a larger amount of\nobserved time steps. To address the challenges, we propose a novel\ngradient-based causal discovery approach STIC, which focuses on\n\\textbf{S}hort-\\textbf{T}erm \\textbf{I}nvariance using \\textbf{C}onvolutional\nneural networks to uncover the causal relationships from time-series data.\nSpecifically, STIC leverages both the short-term time and mechanism invariance\nof causality within each window observation, which possesses the property of\nindependence, to enhance sample efficiency. Furthermore, we construct two\ncausal convolution kernels, which correspond to the short-term time and\nmechanism invariance respectively, to estimate the window causal graph. To\ndemonstrate the necessity of convolutional neural networks for causal discovery\nfrom time-series data, we theoretically derive the equivalence between\nconvolution and the underlying generative principle of time-series data under\nthe assumption that the additive noise model is identifiable. Experimental\nevaluations conducted on both synthetic and FMRI benchmark datasets demonstrate\nthat our STIC outperforms baselines significantly and achieves the\nstate-of-the-art performance, particularly when the datasets contain a limited\nnumber of observed time steps. Code is available at\n\\url{https://github.com/HITshenrj/STIC}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08023v1",
    "published_date": "2024-08-15 08:43:28 UTC",
    "updated_date": "2024-08-15 08:43:28 UTC"
  },
  {
    "arxiv_id": "2408.08021v1",
    "title": "DIVE: Towards Descriptive and Diverse Visual Commonsense Generation",
    "authors": [
      "Jun-Hyung Park",
      "Hyuntae Park",
      "Youjin Kang",
      "Eojin Jeon",
      "SangKeun Lee"
    ],
    "abstract": "Towards human-level visual understanding, visual commonsense generation has\nbeen introduced to generate commonsense inferences beyond images. However,\ncurrent research on visual commonsense generation has overlooked an important\nhuman cognitive ability: generating descriptive and diverse inferences. In this\nwork, we propose a novel visual commonsense generation framework, called DIVE,\nwhich aims to improve the descriptiveness and diversity of generated\ninferences. DIVE involves two methods, generic inference filtering and\ncontrastive retrieval learning, which address the limitations of existing\nvisual commonsense resources and training objectives. Experimental results\nverify that DIVE outperforms state-of-the-art models for visual commonsense\ngeneration in terms of both descriptiveness and diversity, while showing a\nsuperior quality in generating unique and novel inferences. Notably, DIVE\nachieves human-level descriptiveness and diversity on Visual Commonsense\nGraphs. Furthermore, human evaluations confirm that DIVE aligns closely with\nhuman judgments on descriptiveness and diversity\\footnote{Our code and dataset\nare available at https://github.com/Park-ing-lot/DIVE.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 10 figuers, EMNLP 2023 (main)",
    "pdf_url": "http://arxiv.org/pdf/2408.08021v1",
    "published_date": "2024-08-15 08:37:24 UTC",
    "updated_date": "2024-08-15 08:37:24 UTC"
  },
  {
    "arxiv_id": "2408.08019v1",
    "title": "Accelerating High-Fidelity Waveform Generation via Adversarial Flow Matching Optimization",
    "authors": [
      "Sang-Hoon Lee",
      "Ha-Yeong Choi",
      "Seong-Whan Lee"
    ],
    "abstract": "This paper introduces PeriodWave-Turbo, a high-fidelity and high-efficient\nwaveform generation model via adversarial flow matching optimization. Recently,\nconditional flow matching (CFM) generative models have been successfully\nadopted for waveform generation tasks, leveraging a single vector field\nestimation objective for training. Although these models can generate\nhigh-fidelity waveform signals, they require significantly more ODE steps\ncompared to GAN-based models, which only need a single generation step.\nAdditionally, the generated samples often lack high-frequency information due\nto noisy vector field estimation, which fails to ensure high-frequency\nreproduction. To address this limitation, we enhance pre-trained CFM-based\ngenerative models by incorporating a fixed-step generator modification. We\nutilized reconstruction losses and adversarial feedback to accelerate\nhigh-fidelity waveform generation. Through adversarial flow matching\noptimization, it only requires 1,000 steps of fine-tuning to achieve\nstate-of-the-art performance across various objective metrics. Moreover, we\nsignificantly reduce inference speed from 16 steps to 2 or 4 steps.\nAdditionally, by scaling up the backbone of PeriodWave from 29M to 70M\nparameters for improved generalization, PeriodWave-Turbo achieves unprecedented\nperformance, with a perceptual evaluation of speech quality (PESQ) score of\n4.454 on the LibriTTS dataset. Audio samples, source code and checkpoints will\nbe available at https://github.com/sh-lee-prml/PeriodWave.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "9 pages, 9 tables, 1 figure,",
    "pdf_url": "http://arxiv.org/pdf/2408.08019v1",
    "published_date": "2024-08-15 08:34:00 UTC",
    "updated_date": "2024-08-15 08:34:00 UTC"
  },
  {
    "arxiv_id": "2408.08015v1",
    "title": "Asteroid: Resource-Efficient Hybrid Pipeline Parallelism for Collaborative DNN Training on Heterogeneous Edge Devices",
    "authors": [
      "Shengyuan Ye",
      "Liekang Zeng",
      "Xiaowen Chu",
      "Guoliang Xing",
      "Xu Chen"
    ],
    "abstract": "On-device Deep Neural Network (DNN) training has been recognized as crucial\nfor privacy-preserving machine learning at the edge. However, the intensive\ntraining workload and limited onboard computing resources pose significant\nchallenges to the availability and efficiency of model training. While existing\nworks address these challenges through native resource management optimization,\nwe instead leverage our observation that edge environments usually comprise a\nrich set of accompanying trusted edge devices with idle resources beyond a\nsingle terminal. We propose Asteroid, a distributed edge training system that\nbreaks the resource walls across heterogeneous edge devices for efficient model\ntraining acceleration. Asteroid adopts a hybrid pipeline parallelism to\norchestrate distributed training, along with a judicious parallelism planning\nfor maximizing throughput under certain resource constraints. Furthermore, a\nfault-tolerant yet lightweight pipeline replay mechanism is developed to tame\nthe device-level dynamics for training robustness and performance stability. We\nimplement Asteroid on heterogeneous edge devices with both vision and language\nmodels, demonstrating up to 12.2x faster training than conventional parallelism\nmethods and 2.1x faster than state-of-the-art hybrid parallelism methods\nthrough evaluations. Furthermore, Asteroid can recover training pipeline 14x\nfaster than baseline methods while preserving comparable throughput despite\nunexpected device exiting and failure.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted by The 30th Annual International Conference on Mobile\n  Computing and Networking (MobiCom'24)",
    "pdf_url": "http://arxiv.org/pdf/2408.08015v1",
    "published_date": "2024-08-15 08:25:50 UTC",
    "updated_date": "2024-08-15 08:25:50 UTC"
  },
  {
    "arxiv_id": "2408.08336v1",
    "title": "Graph representations of 3D data for machine learning",
    "authors": [
      "Tomasz Prytu≈Ça"
    ],
    "abstract": "We give an overview of combinatorial methods to represent 3D data, such as\ngraphs and meshes, from the viewpoint of their amenability to analysis using\nmachine learning algorithms. We highlight pros and cons of various\nrepresentations and we discuss some methods of generating/switching between the\nrepresentations. We finally present two concrete applications in life science\nand industry. Despite its theoretical nature, our discussion is in general\nmotivated by, and biased towards real-world challenges.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "I.2.10; I.4.10; I.5.1; J.2; J.3"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.08336v1",
    "published_date": "2024-08-15 07:45:07 UTC",
    "updated_date": "2024-08-15 07:45:07 UTC"
  },
  {
    "arxiv_id": "2408.07989v1",
    "title": "IIU: Independent Inference Units for Knowledge-based Visual Question Answering",
    "authors": [
      "Yili Li",
      "Jing Yu",
      "Keke Gai",
      "Gang Xiong"
    ],
    "abstract": "Knowledge-based visual question answering requires external knowledge beyond\nvisible content to answer the question correctly. One limitation of existing\nmethods is that they focus more on modeling the inter-modal and intra-modal\ncorrelations, which entangles complex multimodal clues by implicit embeddings\nand lacks interpretability and generalization ability. The key challenge to\nsolve the above problem is to separate the information and process it\nseparately at the functional level. By reusing each processing unit, the\ngeneralization ability of the model to deal with different data can be\nincreased. In this paper, we propose Independent Inference Units (IIU) for\nfine-grained multi-modal reasoning to decompose intra-modal information by the\nfunctionally independent units. Specifically, IIU processes each\nsemantic-specific intra-modal clue by an independent inference unit, which also\ncollects complementary information by communication from different units. To\nfurther reduce the impact of redundant information, we propose a memory update\nmodule to maintain semantic-relevant memory along with the reasoning process\ngradually. In comparison with existing non-pretrained multi-modal reasoning\nmodels on standard datasets, our model achieves a new state-of-the-art,\nenhancing performance by 3%, and surpassing basic pretrained multi-modal\nmodels. The experimental results show that our IIU model is effective in\ndisentangling intra-modal clues as well as reasoning units to provide\nexplainable reasoning evidence. Our code is available at\nhttps://github.com/Lilidamowang/IIU.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07989v1",
    "published_date": "2024-08-15 07:30:47 UTC",
    "updated_date": "2024-08-15 07:30:47 UTC"
  },
  {
    "arxiv_id": "2408.07985v1",
    "title": "Analytical Uncertainty-Based Loss Weighting in Multi-Task Learning",
    "authors": [
      "Lukas Kirchdorfer",
      "Cathrin Elich",
      "Simon Kutsche",
      "Heiner Stuckenschmidt",
      "Lukas Schott",
      "Jan M. K√∂hler"
    ],
    "abstract": "With the rise of neural networks in various domains, multi-task learning\n(MTL) gained significant relevance. A key challenge in MTL is balancing\nindividual task losses during neural network training to improve performance\nand efficiency through knowledge sharing across tasks. To address these\nchallenges, we propose a novel task-weighting method by building on the most\nprevalent approach of Uncertainty Weighting and computing analytically optimal\nuncertainty-based weights, normalized by a softmax function with tunable\ntemperature. Our approach yields comparable results to the combinatorially\nprohibitive, brute-force approach of Scalarization while offering a more\ncost-effective yet high-performing alternative. We conduct an extensive\nbenchmark on various datasets and architectures. Our method consistently\noutperforms six other common weighting methods. Furthermore, we report\nnoteworthy experimental findings for the practical application of MTL. For\nexample, larger networks diminish the influence of weighting methods, and\ntuning the weight decay has a low impact compared to the learning rate.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07985v1",
    "published_date": "2024-08-15 07:10:17 UTC",
    "updated_date": "2024-08-15 07:10:17 UTC"
  },
  {
    "arxiv_id": "2408.07983v1",
    "title": "ArabLegalEval: A Multitask Benchmark for Assessing Arabic Legal Knowledge in Large Language Models",
    "authors": [
      "Faris Hijazi",
      "Somayah AlHarbi",
      "Abdulaziz AlHussein",
      "Harethah Abu Shairah",
      "Reem AlZahrani",
      "Hebah AlShamlan",
      "Omar Knio",
      "George Turkiyyah"
    ],
    "abstract": "The rapid advancements in Large Language Models (LLMs) have led to\nsignificant improvements in various natural language processing tasks. However,\nthe evaluation of LLMs' legal knowledge, particularly in non-English languages\nsuch as Arabic, remains under-explored. To address this gap, we introduce\nArabLegalEval, a multitask benchmark dataset for assessing the Arabic legal\nknowledge of LLMs. Inspired by the MMLU and LegalBench datasets, ArabLegalEval\nconsists of multiple tasks sourced from Saudi legal documents and synthesized\nquestions. In this work, we aim to analyze the capabilities required to solve\nlegal problems in Arabic and benchmark the performance of state-of-the-art\nLLMs. We explore the impact of in-context learning and investigate various\nevaluation methods. Additionally, we explore workflows for generating questions\nwith automatic validation to enhance the dataset's quality. We benchmark\nmultilingual and Arabic-centric LLMs, such as GPT-4 and Jais, respectively. We\nalso share our methodology for creating the dataset and validation, which can\nbe generalized to other domains. We hope to accelerate AI research in the\nArabic Legal domain by releasing the ArabLegalEval dataset and code:\nhttps://github.com/Thiqah/ArabLegalEval",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07983v1",
    "published_date": "2024-08-15 07:09:51 UTC",
    "updated_date": "2024-08-15 07:09:51 UTC"
  },
  {
    "arxiv_id": "2408.07982v2",
    "title": "Toward a Dialogue System Using a Large Language Model to Recognize User Emotions with a Camera",
    "authors": [
      "Hiroki Tanioka",
      "Tetsushi Ueta",
      "Masahiko Sano"
    ],
    "abstract": "The performance of ChatGPT\\copyright{} and other LLMs has improved\ntremendously, and in online environments, they are increasingly likely to be\nused in a wide variety of situations, such as ChatBot on web pages, call center\noperations using voice interaction, and dialogue functions using agents. In the\noffline environment, multimodal dialogue functions are also being realized,\nsuch as guidance by Artificial Intelligence agents (AI agents) using tablet\nterminals and dialogue systems in the form of LLMs mounted on robots. In this\nmultimodal dialogue, mutual emotion recognition between the AI and the user\nwill become important. So far, there have been methods for expressing emotions\non the part of the AI agent or for recognizing them using textual or voice\ninformation of the user's utterances, but methods for AI agents to recognize\nemotions from the user's facial expressions have not been studied. In this\nstudy, we examined whether or not LLM-based AI agents can interact with users\naccording to their emotional states by capturing the user in dialogue with a\ncamera, recognizing emotions from facial expressions, and adding such emotion\ninformation to prompts. The results confirmed that AI agents can have\nconversations according to the emotional state for emotional states with\nrelatively high scores, such as Happy and Angry.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.RO",
      "68T40",
      "I.2.10; I.2.7"
    ],
    "primary_category": "cs.HC",
    "comment": "4 pages, 5 figures, 1 table, The 1st InterAI: Interactive AI for\n  Human-Centered Robotics workshop in conjunction with IEEE Ro-MAN 2024,\n  Pasadona, LA, USA, Aug. 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.07982v2",
    "published_date": "2024-08-15 07:03:00 UTC",
    "updated_date": "2025-02-18 12:48:27 UTC"
  },
  {
    "arxiv_id": "2408.07981v1",
    "title": "LLaVA-Surg: Towards Multimodal Surgical Assistant via Structured Surgical Video Learning",
    "authors": [
      "Jiajie Li",
      "Garrett Skinner",
      "Gene Yang",
      "Brian R Quaranto",
      "Steven D Schwaitzberg",
      "Peter C W Kim",
      "Jinjun Xiong"
    ],
    "abstract": "Multimodal large language models (LLMs) have achieved notable success across\nvarious domains, while research in the medical field has largely focused on\nunimodal images. Meanwhile, current general-domain multimodal models for videos\nstill lack the capabilities to understand and engage in conversations about\nsurgical videos. One major contributing factor is the absence of datasets in\nthe surgical field. In this paper, we create a new dataset, Surg-QA, consisting\nof 102,000 surgical video-instruction pairs, the largest of its kind so far. To\nbuild such a dataset, we propose a novel two-stage question-answer generation\npipeline with LLM to learn surgical knowledge in a structured manner from the\npublicly available surgical lecture videos. The pipeline breaks down the\ngeneration process into two stages to significantly reduce the task complexity,\nallowing us to use a more affordable, locally deployed open-source LLM than the\npremium paid LLM services. It also mitigates the risk of LLM hallucinations\nduring question-answer generation, thereby enhancing the overall quality of the\ngenerated data. We further train LLaVA-Surg, a novel vision-language\nconversational assistant capable of answering open-ended questions about\nsurgical videos, on this Surg-QA dataset, and conduct comprehensive evaluations\non zero-shot surgical video question-answering tasks. We show that LLaVA-Surg\nsignificantly outperforms all previous general-domain models, demonstrating\nexceptional multimodal conversational skills in answering open-ended questions\nabout surgical videos. We will release our code, model, and the\ninstruction-tuning dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07981v1",
    "published_date": "2024-08-15 07:00:20 UTC",
    "updated_date": "2024-08-15 07:00:20 UTC"
  },
  {
    "arxiv_id": "2408.07962v1",
    "title": "Meta SAC-Lag: Towards Deployable Safe Reinforcement Learning via MetaGradient-based Hyperparameter Tuning",
    "authors": [
      "Homayoun Honari",
      "Amir Mehdi Soufi Enayati",
      "Mehran Ghafarian Tamizi",
      "Homayoun Najjaran"
    ],
    "abstract": "Safe Reinforcement Learning (Safe RL) is one of the prevalently studied\nsubcategories of trial-and-error-based methods with the intention to be\ndeployed on real-world systems. In safe RL, the goal is to maximize reward\nperformance while minimizing constraints, often achieved by setting bounds on\nconstraint functions and utilizing the Lagrangian method. However, deploying\nLagrangian-based safe RL in real-world scenarios is challenging due to the\nnecessity of threshold fine-tuning, as imprecise adjustments may lead to\nsuboptimal policy convergence. To mitigate this challenge, we propose a unified\nLagrangian-based model-free architecture called Meta Soft Actor-Critic\nLagrangian (Meta SAC-Lag). Meta SAC-Lag uses meta-gradient optimization to\nautomatically update the safety-related hyperparameters. The proposed method is\ndesigned to address safe exploration and threshold adjustment with minimal\nhyperparameter tuning requirement. In our pipeline, the inner parameters are\nupdated through the conventional formulation and the hyperparameters are\nadjusted using the meta-objectives which are defined based on the updated\nparameters. Our results show that the agent can reliably adjust the safety\nperformance due to the relatively fast convergence rate of the safety\nthreshold. We evaluate the performance of Meta SAC-Lag in five simulated\nenvironments against Lagrangian baselines, and the results demonstrate its\ncapability to create synergy between parameters, yielding better or competitive\nresults. Furthermore, we conduct a real-world experiment involving a robotic\narm tasked with pouring coffee into a cup without spillage. Meta SAC-Lag is\nsuccessfully trained to execute the task, while minimizing effort constraints.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Main text accepted to the IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS) 2024, 10 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.07962v1",
    "published_date": "2024-08-15 06:18:50 UTC",
    "updated_date": "2024-08-15 06:18:50 UTC"
  },
  {
    "arxiv_id": "2408.07956v2",
    "title": "RandomNet: Clustering Time Series Using Untrained Deep Neural Networks",
    "authors": [
      "Xiaosheng Li",
      "Wenjie Xi",
      "Jessica Lin"
    ],
    "abstract": "Neural networks are widely used in machine learning and data mining.\nTypically, these networks need to be trained, implying the adjustment of\nweights (parameters) within the network based on the input data. In this work,\nwe propose a novel approach, RandomNet, that employs untrained deep neural\nnetworks to cluster time series. RandomNet uses different sets of random\nweights to extract diverse representations of time series and then ensembles\nthe clustering relationships derived from these different representations to\nbuild the final clustering results. By extracting diverse representations, our\nmodel can effectively handle time series with different characteristics. Since\nall parameters are randomly generated, no training is required during the\nprocess. We provide a theoretical analysis of the effectiveness of the method.\nTo validate its performance, we conduct extensive experiments on all of the 128\ndatasets in the well-known UCR time series archive and perform statistical\nanalysis of the results. These datasets have different sizes, sequence lengths,\nand they are from diverse fields. The experimental results show that the\nproposed method is competitive compared with existing state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.07956v2",
    "published_date": "2024-08-15 06:09:19 UTC",
    "updated_date": "2024-08-16 20:53:46 UTC"
  },
  {
    "arxiv_id": "2408.07947v4",
    "title": "Conditional Brownian Bridge Diffusion Model for VHR SAR to Optical Image Translation",
    "authors": [
      "Seon-Hoon Kim",
      "Dae-Won Chung"
    ],
    "abstract": "Synthetic Aperture Radar (SAR) imaging technology provides the unique\nadvantage of being able to collect data regardless of weather conditions and\ntime. However, SAR images exhibit complex backscatter patterns and speckle\nnoise, which necessitate expertise for interpretation. Research on translating\nSAR images into optical-like representations has been conducted to aid the\ninterpretation of SAR data. Nevertheless, existing studies have predominantly\nutilized low-resolution satellite imagery datasets and have largely been based\non Generative Adversarial Network (GAN) which are known for their training\ninstability and low fidelity. To overcome these limitations of low-resolution\ndata usage and GAN-based approaches, this letter introduces a conditional\nimage-to-image translation approach based on Brownian Bridge Diffusion Model\n(BBDM). We conducted comprehensive experiments on the MSAW dataset, a paired\nSAR and optical images collection of 0.5m Very-High-Resolution (VHR). The\nexperimental results indicate that our method surpasses both the Conditional\nDiffusion Models (CDMs) and the GAN-based models in diverse perceptual quality\nmetrics.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "5 pages, 2 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2408.07947v4",
    "published_date": "2024-08-15 05:43:46 UTC",
    "updated_date": "2025-04-20 09:03:15 UTC"
  },
  {
    "arxiv_id": "2408.07945v1",
    "title": "Solving a Rubik's Cube Using its Local Graph Structure",
    "authors": [
      "Shunyu Yao",
      "Mitchy Lee"
    ],
    "abstract": "The Rubix Cube is a 3-dimensional single-player combination puzzle attracting\nattention in the reinforcement learning community. A Rubix Cube has six faces\nand twelve possible actions, leading to a small and unconstrained action space\nand a very large state space with only one goal state. Modeling such a large\nstate space and storing the information of each state requires exceptional\ncomputational resources, which makes it challenging to find the shortest\nsolution to a scrambled Rubix cube with limited resources. The Rubix Cube can\nbe represented as a graph, where states of the cube are nodes and actions are\nedges. Drawing on graph convolutional networks, we design a new heuristic,\nweighted convolutional distance, for A star search algorithm to find the\nsolution to a scrambled Rubix Cube. This heuristic utilizes the information of\nneighboring nodes and convolves them with attention-like weights, which creates\na deeper search for the shortest path to the solved state.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07945v1",
    "published_date": "2024-08-15 05:39:52 UTC",
    "updated_date": "2024-08-15 05:39:52 UTC"
  },
  {
    "arxiv_id": "2408.07931v2",
    "title": "Surgical SAM 2: Real-time Segment Anything in Surgical Video by Efficient Frame Pruning",
    "authors": [
      "Haofeng Liu",
      "Erli Zhang",
      "Junde Wu",
      "Mingxuan Hong",
      "Yueming Jin"
    ],
    "abstract": "Surgical video segmentation is a critical task in computer-assisted surgery\nand is vital for enhancing surgical quality and patient outcomes. Recently, the\nSegment Anything Model 2 (SAM2) framework has shown superior advancements in\nimage and video segmentation. However, SAM2 struggles with efficiency due to\nthe high computational demands of processing high-resolution images and complex\nand long-range temporal dynamics in surgical videos. To address these\nchallenges, we introduce Surgical SAM 2 (SurgSAM2), an advanced model to\nutilize SAM2 with an Efficient Frame Pruning (EFP) mechanism, to facilitate\nreal-time surgical video segmentation. The EFP mechanism dynamically manages\nthe memory bank by selectively retaining only the most informative frames,\nreducing memory usage and computational cost while maintaining high\nsegmentation accuracy. Our extensive experiments demonstrate that SurgSAM2\nsignificantly improves both efficiency and segmentation accuracy compared to\nthe vanilla SAM2. Remarkably, SurgSAM2 achieves a 3$\\times$ FPS compared with\nSAM2, while also delivering state-of-the-art performance after fine-tuning with\nlower-resolution data. These advancements establish SurgSAM2 as a leading model\nfor surgical video analysis, making real-time surgical video segmentation in\nresource-constrained environments a reality. Our source code is available at\nhttps://github.com/jinlab-imvr/Surgical-SAM-2.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurIPS 2024 Workshop AIM-FM",
    "pdf_url": "http://arxiv.org/pdf/2408.07931v2",
    "published_date": "2024-08-15 04:59:12 UTC",
    "updated_date": "2025-03-11 12:57:43 UTC"
  },
  {
    "arxiv_id": "2408.07930v4",
    "title": "MAG-SQL: Multi-Agent Generative Approach with Soft Schema Linking and Iterative Sub-SQL Refinement for Text-to-SQL",
    "authors": [
      "Wenxuan Xie",
      "Gaochen Wu",
      "Bowen Zhou"
    ],
    "abstract": "Recent In-Context Learning based methods have achieved remarkable success in\nText-to-SQL task. However, there is still a large gap between the performance\nof these models and human performance on datasets with complex database schema\nand difficult questions, such as BIRD. Besides, existing work has neglected to\nsupervise intermediate steps when solving questions iteratively with question\ndecomposition methods, and the schema linking methods used in these works are\nvery rudimentary. To address these issues, we propose MAG-SQL, a multi-agent\ngenerative approach with soft schema linking and iterative Sub-SQL refinement.\nIn our framework, an entity-based method with tables' summary is used to select\nthe columns in database, and a novel targets-conditions decomposition method is\nintroduced to decompose those complex questions. Additionally, we build a\niterative generating module which includes a Sub-SQL Generator and Sub-SQL\nRefiner, introducing external oversight for each step of generation. Through a\nseries of ablation studies, the effectiveness of each agent in our framework\nhas been demonstrated. When evaluated on the BIRD benchmark with GPT-4, MAG-SQL\nachieves an execution accuracy of 61.08%, compared to the baseline accuracy of\n46.35% for vanilla GPT-4 and the baseline accuracy of 57.56% for MAC-SQL.\nBesides, our approach makes similar progress on Spider. The codes are available\nat https://github.com/LancelotXWX/MAG-SQL.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.07930v4",
    "published_date": "2024-08-15 04:57:55 UTC",
    "updated_date": "2024-11-07 03:37:51 UTC"
  },
  {
    "arxiv_id": "2408.08335v1",
    "title": "Plan with Code: Comparing approaches for robust NL to DSL generation",
    "authors": [
      "Nastaran Bassamzadeh",
      "Chhaya Methani"
    ],
    "abstract": "Planning in code is considered a more reliable approach for many\norchestration tasks. This is because code is more tractable than steps\ngenerated via Natural Language and make it easy to support more complex\nsequences by abstracting deterministic logic into functions. It also allows\nspotting issues with incorrect function names with the help of parsing checks\nthat can be run on code. Progress in Code Generation methodologies, however,\nremains limited to general-purpose languages like C, C++, and Python. LLMs\ncontinue to face challenges with custom function names in Domain Specific\nLanguages or DSLs, leading to higher hallucination rates and syntax errors.\nThis is more common for custom function names, that are typically part of the\nplan. Moreover, keeping LLMs up-to-date with newer function names is an issue.\nThis poses a challenge for scenarios like task planning over a large number of\nAPIs, since the plan is represented as a DSL having custom API names. In this\npaper, we focus on workflow automation in RPA (Robotic Process Automation)\ndomain as a special case of task planning. We present optimizations for using\nRetrieval Augmented Generation (or RAG) with LLMs for DSL generation along with\nan ablation study comparing these strategies with a fine-tuned model. Our\nresults showed that the fine-tuned model scored the best on code similarity\nmetric. However, with our optimizations, RAG approach is able to match the\nquality for in-domain API names in the test set. Additionally, it offers\nsignificant advantage for out-of-domain or unseen API names, outperforming\nFine-Tuned model on similarity metric by 7 pts.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "I.2.2; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "9 pages, 1 figure, 5 tables. arXiv admin note: substantial text\n  overlap with arXiv:2407.02742",
    "pdf_url": "http://arxiv.org/pdf/2408.08335v1",
    "published_date": "2024-08-15 04:29:33 UTC",
    "updated_date": "2024-08-15 04:29:33 UTC"
  },
  {
    "arxiv_id": "2408.11854v2",
    "title": "When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?",
    "authors": [
      "Yanjun Gao",
      "Skatje Myers",
      "Shan Chen",
      "Dmitriy Dligach",
      "Timothy A Miller",
      "Danielle Bitterman",
      "Matthew Churpek",
      "Majid Afshar"
    ],
    "abstract": "The introduction of Large Language Models (LLMs) has advanced data\nrepresentation and analysis, bringing significant progress in their use for\nmedical questions and answering. Despite these advancements, integrating\ntabular data, especially numerical data pivotal in clinical contexts, into LLM\nparadigms has not been thoroughly explored. In this study, we examine the\neffectiveness of vector representations from last hidden states of LLMs for\nmedical diagnostics and prognostics using electronic health record (EHR) data.\nWe compare the performance of these embeddings with that of raw numerical EHR\ndata when used as feature inputs to traditional machine learning (ML)\nalgorithms that excel at tabular data learning, such as eXtreme Gradient\nBoosting. We focus on instruction-tuned LLMs in a zero-shot setting to\nrepresent abnormal physiological data and evaluating their utilities as feature\nextractors to enhance ML classifiers for predicting diagnoses, length of stay,\nand mortality. Furthermore, we examine prompt engineering techniques on\nzero-shot and few-shot LLM embeddings to measure their impact comprehensively.\nAlthough findings suggest the raw data features still prevails in medical ML\ntasks, zero-shot LLM embeddings demonstrate competitive results, suggesting a\npromising avenue for future research in medical applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Findings of EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.11854v2",
    "published_date": "2024-08-15 03:56:40 UTC",
    "updated_date": "2024-09-19 22:19:28 UTC"
  },
  {
    "arxiv_id": "2408.07911v2",
    "title": "CEGRL-TKGR: A Causal Enhanced Graph Representation Learning Framework for Temporal Knowledge Graph Reasoning",
    "authors": [
      "Jinze Sun",
      "Yongpan Sheng",
      "Lirong He",
      "Yongbin Qin",
      "Ming Liu",
      "Tao Jia"
    ],
    "abstract": "Temporal knowledge graph reasoning (TKGR) is increasingly gaining attention\nfor its ability to extrapolate new events from historical data, thereby\nenriching the inherently incomplete temporal knowledge graphs. Existing\ngraph-based representation learning frameworks have made significant strides in\ndeveloping evolving representations for both entities and relational\nembeddings. Despite these achievements, there's a notable tendency in these\nmodels to inadvertently learn biased data representations and mine spurious\ncorrelations, consequently failing to discern the causal relationships between\nevents. This often leads to incorrect predictions based on these false\ncorrelations. To address this, we propose an innovative Causal Enhanced Graph\nRepresentation Learning framework for TKGR (named CEGRL-TKGR). This framework\nintroduces causal structures in graph-based representation learning to unveil\nthe essential causal relationships between events, ultimately enhancing the\nperformance of the TKGR task. Specifically, we first disentangle the\nevolutionary representations of entities and relations in a temporal knowledge\ngraph sequence into two distinct components, namely causal representations and\nconfounding representations. Then, drawing on causal intervention theory, we\nadvocate the utilization of causal representations for predictions, aiming to\nmitigate the effects of erroneous correlations caused by confounding features,\nthus achieving more robust and accurate predictions. Finally, extensive\nexperimental results on six benchmark datasets demonstrate the superior\nperformance of our model in the link prediction task.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07911v2",
    "published_date": "2024-08-15 03:34:53 UTC",
    "updated_date": "2025-01-24 10:37:25 UTC"
  },
  {
    "arxiv_id": "2408.07906v1",
    "title": "KAN versus MLP on Irregular or Noisy Functions",
    "authors": [
      "Chen Zeng",
      "Jiahui Wang",
      "Haoran Shen",
      "Qiao Wang"
    ],
    "abstract": "In this paper, we compare the performance of Kolmogorov-Arnold Networks (KAN)\nand Multi-Layer Perceptron (MLP) networks on irregular or noisy functions. We\ncontrol the number of parameters and the size of the training samples to ensure\na fair comparison. For clarity, we categorize the functions into six types:\nregular functions, continuous functions with local non-differentiable points,\nfunctions with jump discontinuities, functions with singularities, functions\nwith coherent oscillations, and noisy functions. Our experimental results\nindicate that KAN does not always perform best. For some types of functions,\nMLP outperforms or performs comparably to KAN. Furthermore, increasing the size\nof training samples can improve performance to some extent. When noise is added\nto functions, the irregular features are often obscured by the noise, making it\nchallenging for both MLP and KAN to extract these features effectively. We hope\nthese experiments provide valuable insights for future neural network research\nand encourage further investigations to overcome these challenges.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "cs.NE",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07906v1",
    "published_date": "2024-08-15 03:24:07 UTC",
    "updated_date": "2024-08-15 03:24:07 UTC"
  },
  {
    "arxiv_id": "2408.07904v1",
    "title": "Assessing Language Models' Worldview for Fiction Generation",
    "authors": [
      "Aisha Khatun",
      "Daniel G. Brown"
    ],
    "abstract": "The use of Large Language Models (LLMs) has become ubiquitous, with abundant\napplications in computational creativity. One such application is fictional\nstory generation. Fiction is a narrative that occurs in a story world that is\nslightly different than ours. With LLMs becoming writing partners, we question\nhow suitable they are to generate fiction. This study investigates the ability\nof LLMs to maintain a state of world essential to generate fiction. Through a\nseries of questions to nine LLMs, we find that only two models exhibit\nconsistent worldview, while the rest are self-conflicting. Subsequent analysis\nof stories generated by four models revealed a strikingly uniform narrative\npattern. This uniformity across models further suggests a lack of `state'\nnecessary for fiction. We highlight the limitations of current LLMs in fiction\nwriting and advocate for future research to test and create story worlds for\nLLMs to reside in. All code, dataset, and the generated responses can be found\nin https://github.com/tanny411/llm-reliability-and-consistency-evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Short paper",
    "pdf_url": "http://arxiv.org/pdf/2408.07904v1",
    "published_date": "2024-08-15 03:19:41 UTC",
    "updated_date": "2024-08-15 03:19:41 UTC"
  },
  {
    "arxiv_id": "2408.07891v1",
    "title": "Quantum-inspired Interpretable Deep Learning Architecture for Text Sentiment Analysis",
    "authors": [
      "Bingyu Li",
      "Da Zhang",
      "Zhiyuan Zhao",
      "Junyu Gao",
      "Yuan Yuan"
    ],
    "abstract": "Text has become the predominant form of communication on social media,\nembedding a wealth of emotional nuances. Consequently, the extraction of\nemotional information from text is of paramount importance. Despite previous\nresearch making some progress, existing text sentiment analysis models still\nface challenges in integrating diverse semantic information and lack\ninterpretability. To address these issues, we propose a quantum-inspired deep\nlearning architecture that combines fundamental principles of quantum mechanics\n(QM principles) with deep learning models for text sentiment analysis.\nSpecifically, we analyze the commonalities between text representation and QM\nprinciples to design a quantum-inspired text representation method and further\ndevelop a quantum-inspired text embedding layer. Additionally, we design a\nfeature extraction layer based on long short-term memory (LSTM) networks and\nself-attention mechanisms (SAMs). Finally, we calculate the text density matrix\nusing the quantum complex numbers principle and apply 2D-convolution neural\nnetworks (CNNs) for feature condensation and dimensionality reduction. Through\na series of visualization, comparative, and ablation experiments, we\ndemonstrate that our model not only shows significant advantages in accuracy\nand efficiency compared to previous related models but also achieves a certain\nlevel of interpretability by integrating QM principles. Our code is available\nat QISA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07891v1",
    "published_date": "2024-08-15 02:32:50 UTC",
    "updated_date": "2024-08-15 02:32:50 UTC"
  },
  {
    "arxiv_id": "2408.07877v4",
    "title": "BCR-DRL: Behavior- and Context-aware Reward for Deep Reinforcement Learning in Human-AI Coordination",
    "authors": [
      "Xin Hao",
      "Bahareh Nakisa",
      "Mohmmad Naim Rastgoo",
      "Richard Dazeley",
      "Gaoyang Pang"
    ],
    "abstract": "Deep reinforcement Learning (DRL) offers a powerful framework for training AI\nagents to coordinate with human partners. However, DRL faces two critical\nchallenges in human-AI coordination (HAIC): sparse rewards and unpredictable\nhuman behaviors. These challenges significantly limit DRL to identify effective\ncoordination policies, due to its impaired capability of optimizing exploration\nand exploitation. To address these limitations, we propose an innovative\nbehavior- and context-aware reward (BCR) for DRL, which optimizes exploration\nand exploitation by leveraging human behaviors and contextual information in\nHAIC. Our BCR consists of two components: (i)~A novel dual intrinsic rewarding\nscheme to enhance exploration. This scheme composes an AI self-motivated\nintrinsic reward and a human-motivated intrinsic reward, which are designed to\nincrease the capture of sparse rewards by a logarithmic-based strategy; and\n(ii)~A new context-aware weighting mechanism for the designed rewards to\nimprove exploitation. This mechanism helps the AI agent prioritize actions that\nbetter coordinate with the human partner by utilizing contextual information\nthat can reflect the evolution of learning in HAIC. Extensive simulations in\nthe Overcooked environment demonstrate that our approach can increase the\ncumulative sparse rewards by approximately 20% and reduce the convergence time\nby about 67% compared to state-of-the-art baselines.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07877v4",
    "published_date": "2024-08-15 01:33:06 UTC",
    "updated_date": "2025-02-07 00:03:49 UTC"
  }
]