{
  "date": "2024-03-21",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-21 的 arXiv 中文 TLDR 快报！  \n\n今天 arXiv 的论文主要聚焦 AI 和机器学习领域，包括大语言模型（LLM）的优化、图像生成、强化学习在机器人和决策中的应用，以及 AI 在医疗和环境中的潜力；令人印象深刻的文章有 Yoshua Bengio 参与的第 43 篇，以及多篇探讨 LLM 偏见检测和高效训练的方法；这些论文突出了 AI 模型的鲁棒性、公平性和实际应用潜力。\n\n以下是今日论文的精选摘要，我优先选取了重要、话题性和有影响力（例如知名学者参与）的文章，并将相关主题归类讨论。其他次要论文（如纯理论或应用较窄的）将快速掠过，仅简述核心点。\n\n### LLM 和 AI 优化相关\n- **AutoRE: Document-Level Relation Extraction with Large Language Models**（AutoRE: 基于大语言模型的文档级关系抽取）  \n  作者包括 Jie Tang。该论文提出 AutoRE 模型，使用 RHF（Relation-Head-Facts）范式处理文档级关系抽取，避免依赖预定义关系选项，在 RE-DocRED 数据集上超越了现有方法，贡献了高效的 PEFT 框架，实现端到端抽取。\n\n- **Log Probabilities Are a Reliable Estimate of Semantic Plausibility in Base and Instruction-Tuned Language Models**（基于对数概率的语义合理性评估在基础和指令微调语言模型中的可靠性）  \n  主要发现：对数概率比零样本提示更可靠地评估语义合理性，尤其在最小对和上下文场景中，实验证明其鲁棒性，适用于 LLM 的语义分析。\n\n- **The opportunities and risks of large language models in mental health**（大语言模型在心理健康领域的机会和风险）  \n  作者包括 Yoshua Bengio。该文总结 LLM 在心理健康教育、评估和干预中的潜力，同时强调风险，如公平性和伦理问题，建议通过微调和用户参与来最大化益处。\n\n- **ReAct Meets ActRe: When Language Agents Enjoy Training Data Autonomy**（ReAct 与 ActRe 的结合：语言代理在训练数据自治中的应用）  \n  提出 A³T 框架，通过自监督生成训练轨迹，实现 LLM 代理的自迭代提升，在 AlfWorld 和 WebShop 数据集上显著提高任务成功率。\n\n- **Detoxifying Large Language Models via Knowledge Editing**（通过知识编辑净化大语言模型）  \n  引入 Detoxifying with Intraoperative Neural Monitoring 方法，高效减少 LLM 毒性输出，同时保持模型性能，实验显示在 COUNTERFACT 数据集上编辑准确率近 100%。\n\n- **Agentic AI: The Era of Semantic Decoding**（代理 AI：语义解码时代）  \n  探讨语义解码框架，将 LLM 视为语义处理器，提出优化算法，强调 AI 代理在多模态交互中的潜力。\n\n- **MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?**（MathVerse: 多模态 LLM 是否真正理解视觉数学问题的图表？）  \n  构建基准测试多模态 LLM 在数学图表理解上的能力，使用 Chain-of-Thought 评估，揭示 LLM 在视觉推理中的局限。\n\n快速掠过其他 LLM 相关：如第 22 篇（语言代理训练自治）和第 49 篇（LLM 性别偏见检测），它们扩展了 LLM 在多任务和公平性上的应用，但细节较常规。\n\n### 机器人和强化学习\n- **Learning Quadruped Locomotion Using Differentiable Simulation**（使用可微模拟学习四足机器人运动）  \n  提出可微模拟框架，结合高保真模拟器和代理模型，实现四足机器人快速学习复杂地形运动，超越传统 PPO 算法。\n\n- **Planning and Acting While the Clock Ticks**（在时间压力下规划和行动）  \n  扩展情境时间规划，引入并发规划和执行算法，处理实时决策场景，实验显示在时间紧迫任务中性能优于现有方法。\n\n- **Multi-Agent VQA: Exploring Multi-Agent Foundation Models in Zero-Shot Visual Question Answering**（多代理 VQA: 探索多代理基础模型在零样本视觉问答中的应用）  \n  使用多代理系统增强零样本 VQA，代理协同处理对象检测和计数，贡献了新框架和代码库。\n\n快速掠过第 31 篇（民主 AI 框架）和第 35 篇（约束强化学习），它们探讨了强化学习在决策和机器人控制中的扩展，但影响力较小。\n\n### 图像处理和生成\n- **StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text**（StreamingT2V: 从文本生成一致的动态长视频）  \n  提出流式文本到视频模型，支持无限长视频生成，实验显示在运动量和一致性上优于竞争方法。\n\n- **Videoshop: Localized Semantic Video Editing with Noise-Extrapolated Diffusion Inversion**（Videoshop: 使用噪声外推扩散反演的局部语义视频编辑）  \n  创新视频编辑框架，从单帧传播变化，实现高精度语义编辑，超越基线在质量和一致性上。\n\n- **Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language Models for Media Forensics**（ChatGPT 能检测 DeepFakes 吗？多模态 LLM 在媒体取证中的研究）  \n  评估 LLM 在 DeepFakes 检测中的潜力，通过提示工程提升准确性，揭示了 LLM 在媒体鉴定的实用价值。\n\n快速掠过第 12 篇（图像匿名化）和第 29 篇（3D 重建），它们提供了技术创新，但应用场景较窄。\n\n### 其他值得注意的\n- **Deep Active Learning: A Reality Check**（深度主动学习：现实检查）  \n  评估深度主动学习方法，强调起始预算和预训练的影响，提供资源分配指南。\n\n- **Particip-AI: A Democratic Surveying Framework for Anticipating Future AI Use Cases, Harms and Benefits**（Particip-AI: 用于预测未来 AI 用例、危害和益处的民主调查框架）  \n  设计框架让公众评估 AI 影响，实验显示能揭示新危害和张力，促进民主 AI 治理。\n\n其他论文如第 17 篇（引力双重理论）和第 43 篇（AI 信息市场）虽有学术价值，但主题较 niche，仅提及其在特定领域的贡献，如第 43 篇通过 LLM 减少信息不对称。\n\n总之，今天的论文展示了 AI 领域的快速演进，尤其在 LLM 和强化学习的交叉应用上，未来可能推动更公平、智能的系统。更多细节可查阅 arXiv。",
  "papers": [
    {
      "arxiv_id": "2403.14888v3",
      "title": "AutoRE: Document-Level Relation Extraction with Large Language Models",
      "title_zh": "AutoRE：使用大语言模型的文档级别关系抽取",
      "authors": [
        "Lilong Xue",
        "Dan Zhang",
        "Yuxiao Dong",
        "Jie Tang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated exceptional abilities in\ncomprehending and generating text, motivating numerous researchers to utilize\nthem for Information Extraction (IE) purposes, including Relation Extraction\n(RE). Nonetheless, most existing methods are predominantly designed for\nSentence-level Relation Extraction (SentRE) tasks, which typically encompass a\nrestricted set of relations and triplet facts within a single sentence.\nFurthermore, certain approaches resort to treating relations as candidate\nchoices integrated into prompt templates, leading to inefficient processing and\nsuboptimal performance when tackling Document-Level Relation Extraction (DocRE)\ntasks, which entail handling multiple relations and triplet facts distributed\nacross a given document, posing distinct challenges. To overcome these\nlimitations, we introduce AutoRE, an end-to-end DocRE model that adopts a novel\nRE extraction paradigm named RHF (Relation-Head-Facts). Unlike existing\napproaches, AutoRE does not rely on the assumption of known relation options,\nmaking it more reflective of real-world scenarios. Additionally, we have\ndeveloped an easily extensible RE framework using a Parameters Efficient Fine\nTuning (PEFT) algorithm (QLoRA). Our experiments on the RE-DocRED dataset\nshowcase AutoRE's best performance, achieving state-of-the-art results,\nsurpassing TAG by 10.03\\% and 9.03\\% respectively on the dev and test set. The\ncode is available at https://github.com/THUDM/AutoRE and the demonstration\nvideo is provided at https://www.youtube.com/watch?v=IhKRsZUAxKk.",
      "tldr_zh": "该研究提出AutoRE，一种基于Large Language Models (LLMs)的端到端模型，用于处理Document-Level Relation Extraction (DocRE)，以解决现有方法主要针对Sentence-level Relation Extraction (SentRE)且依赖预定义关系选项的局限性。AutoRE 采用创新的RHF (Relation-Head-Facts)范式，不假设已知关系选项，并利用Parameters Efficient Fine Tuning (PEFT)算法如QLoRA来构建易扩展的框架。在RE-DocRED数据集上，AutoRE 实现了state-of-the-art性能，分别比TAG模型在开发集和测试集上提升10.03%和9.03%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14888v3",
      "published_date": "2024-03-21 23:48:21 UTC",
      "updated_date": "2024-07-26 04:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:29:51.461919"
    },
    {
      "arxiv_id": "2405.01394v1",
      "title": "Analysis of a Modular Autonomous Driving Architecture: The Top Submission to CARLA Leaderboard 2.0 Challenge",
      "title_zh": "模块化自动驾驶架构的分析：CARLA 排行榜 2.0 挑战的顶级提交",
      "authors": [
        "Weize Zhang",
        "Mohammed Elmahgiubi",
        "Kasra Rezaee",
        "Behzad Khamidehi",
        "Hamidreza Mirkhani",
        "Fazel Arasteh",
        "Chunlin Li",
        "Muhammad Ahsan Kaleem",
        "Eduardo R. Corral-Soto",
        "Dhruv Sharma",
        "Tongtong Cao"
      ],
      "abstract": "In this paper we present the architecture of the Kyber-E2E submission to the\nmap track of CARLA Leaderboard 2.0 Autonomous Driving (AD) challenge 2023,\nwhich achieved first place. We employed a modular architecture for our solution\nconsists of five main components: sensing, localization, perception,\ntracking/prediction, and planning/control. Our solution leverages\nstate-of-the-art language-assisted perception models to help our planner\nperform more reliably in highly challenging traffic scenarios. We use\nopen-source driving datasets in conjunction with Inverse Reinforcement Learning\n(IRL) to enhance the performance of our motion planner. We provide insight into\nour design choices and trade-offs made to achieve this solution. We also\nexplore the impact of each component in the overall performance of our\nsolution, with the intent of providing a guideline where allocation of\nresources can have the greatest impact.",
      "tldr_zh": "本论文分析了 Kyber-E2E 提交到 CARLA Leaderboard 2.0 挑战的模块化自主驾驶架构，该方案在地图轨道中获得第一名。架构由 sensing、localization、perception、tracking/prediction 和 planning/control 五大组件组成，利用 state-of-the-art 的 language-assisted perception 模型和 Inverse Reinforcement Learning (IRL) 结合 open-source driving datasets，提升 planner 在复杂交通场景中的可靠性和性能。论文探讨了各组件对整体表现的影响，并提供设计选择、权衡及资源分配指导，以优化未来自主驾驶系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01394v1",
      "published_date": "2024-03-21 23:44:19 UTC",
      "updated_date": "2024-03-21 23:44:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:30:04.116945"
    },
    {
      "arxiv_id": "2403.14885v1",
      "title": "Establishing a leader in a pairwise comparisons method",
      "title_zh": "翻译失败",
      "authors": [
        "Jacek Szybowski",
        "Konrad Kułakowski",
        "Jiri Mazurek",
        "Sebastian Ernst"
      ],
      "abstract": "Abstract Like electoral systems, decision-making methods are also vulnerable\nto manipulation by decision-makers. The ability to effectively defend against\nsuch threats can only come from thoroughly understanding the manipulation\nmechanisms. In the presented article, we show two algorithms that can be used\nto launch a manipulation attack. They allow for equating the weights of two\nselected alternatives in the pairwise comparison method and, consequently,\nchoosing a leader. The theoretical considerations are accompanied by a Monte\nCarlo simulation showing the relationship between the size of the PC matrix,\nthe degree of inconsistency, and the ease of manipulation. This work is a\ncontinuation of our previous research published in the paper (Szybowski et al.,\n2023)",
      "tldr_zh": "该论文探讨了决策方法（如pairwise comparisons method）易受决策者操纵的问题，并强调理解操纵机制的重要性。作者提出了两个算法，用于等化两个备选方案的权重，从而在pairwise comparisons method中选择一个leader。理论分析结合Monte Carlo simulation，揭示了PC matrix的大小、不一致度与操纵难易之间的关系；这项工作延续了先前研究（Szybowski et al., 2023），为防御操纵提供基础。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.CY",
        "cs.DM"
      ],
      "primary_category": "cs.AI",
      "comment": "9 figures, 19 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.14885v1",
      "published_date": "2024-03-21 23:42:00 UTC",
      "updated_date": "2024-03-21 23:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:30:13.853275"
    },
    {
      "arxiv_id": "2403.14864v4",
      "title": "Learning Quadruped Locomotion Using Differentiable Simulation",
      "title_zh": "使用可微分模拟学习四足动物运动",
      "authors": [
        "Yunlong Song",
        "Sangbae Kim",
        "Davide Scaramuzza"
      ],
      "abstract": "This work explores the potential of using differentiable simulation for\nlearning quadruped locomotion. Differentiable simulation promises fast\nconvergence and stable training by computing low-variance first-order gradients\nusing robot dynamics. However, its usage for legged robots is still limited to\nsimulation. The main challenge lies in the complex optimization landscape of\nrobotic tasks due to discontinuous dynamics. This work proposes a new\ndifferentiable simulation framework to overcome these challenges. Our approach\ncombines a high-fidelity, non-differentiable simulator for forward dynamics\nwith a simplified surrogate model for gradient backpropagation. This approach\nmaintains simulation accuracy by aligning the robot states from the surrogate\nmodel with those of the precise, non-differentiable simulator. Our framework\nenables learning quadruped walking in simulation in minutes without\nparallelization. When augmented with GPU parallelization, our approach allows\nthe quadruped robot to master diverse locomotion skills on challenging terrains\nin minutes. We demonstrate that differentiable simulation outperforms a\nreinforcement learning algorithm (PPO) by achieving significantly better sample\nefficiency while maintaining its effectiveness in handling large-scale\nenvironments. Our method represents one of the first successful applications of\ndifferentiable simulation to real-world quadruped locomotion, offering a\ncompelling alternative to traditional RL methods.",
      "tldr_zh": "这篇论文探讨了使用可微模拟（differentiable simulation）来学习四足机器人（quadruped locomotion）运动的方法，以实现快速收敛和稳定训练。该框架通过结合高保真非可微模拟器（用于前向动态）和简化代理模型（用于梯度反向传播），克服了不连续动态的优化挑战，并确保机器人状态的精确对齐。实验结果显示，该方法无需并行化即可在几分钟内学会四足行走，结合GPU并行化后，能在复杂地形上快速掌握多样技能，并比强化学习算法PPO在样本效率上显著提升。该研究首次成功将可微模拟应用于真实世界四足运动，提供了一个高效替代传统RL方法的方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8th Annual Conference on Robot Learning (CoRL)",
      "pdf_url": "http://arxiv.org/pdf/2403.14864v4",
      "published_date": "2024-03-21 22:18:59 UTC",
      "updated_date": "2024-10-15 13:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:30:29.100929"
    },
    {
      "arxiv_id": "2403.14859v2",
      "title": "Log Probabilities Are a Reliable Estimate of Semantic Plausibility in Base and Instruction-Tuned Language Models",
      "title_zh": "对数概率是基础语言模型和指令微调语言模型中语义合理性的可靠估计",
      "authors": [
        "Carina Kauf",
        "Emmanuele Chersoni",
        "Alessandro Lenci",
        "Evelina Fedorenko",
        "Anna A. Ivanova"
      ],
      "abstract": "Semantic plausibility (e.g. knowing that \"the actor won the award\" is more\nlikely than \"the actor won the battle\") serves as an effective proxy for\ngeneral world knowledge. Language models (LMs) capture vast amounts of world\nknowledge by learning distributional patterns in text, accessible via log\nprobabilities (LogProbs) they assign to plausible vs. implausible outputs. The\nnew generation of instruction-tuned LMs can now also provide explicit estimates\nof plausibility via prompting. Here, we evaluate the effectiveness of LogProbs\nand basic prompting to measure semantic plausibility, both in single-sentence\nminimal pairs (Experiment 1) and short context-dependent scenarios (Experiment\n2). We find that (i) in both base and instruction-tuned LMs, LogProbs offers a\nmore reliable measure of semantic plausibility than direct zero-shot prompting,\nwhich yields inconsistent and often poor results; (ii) instruction-tuning\ngenerally does not alter the sensitivity of LogProbs to semantic plausibility\n(although sometimes decreases it); (iii) across models, context mostly\nmodulates LogProbs in expected ways, as measured by three novel metrics of\ncontext-sensitive plausibility and their match to explicit human plausibility\njudgments. We conclude that, even in the era of prompt-based evaluations,\nLogProbs constitute a useful metric of semantic plausibility, both in base and\ninstruction-tuned LMs.",
      "tldr_zh": "这篇论文探讨了在基础（base）和指令微调（instruction-tuned）语言模型中，log probabilities (LogProbs) 是否能可靠地估计语义合理性 (semantic plausibility)，作为评估世界知识的代理。研究通过两个实验（单句最小对和短上下文场景）比较了 LogProbs 与直接零样本提示的有效性，发现 LogProbs 更可靠，指令微调通常不会改变其敏感性（有时会降低），且上下文能以预期方式调节 LogProbs，与人类判断一致。最终结论是，即使在提示-based 评估时代，LogProbs 仍是语义合理性的有用指标。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14859v2",
      "published_date": "2024-03-21 22:08:44 UTC",
      "updated_date": "2024-10-21 11:25:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:30:40.394933"
    },
    {
      "arxiv_id": "2403.14843v1",
      "title": "Local Causal Discovery with Linear non-Gaussian Cyclic Models",
      "title_zh": "线性非高斯循环模型下的局部因果发现",
      "authors": [
        "Haoyue Dai",
        "Ignavier Ng",
        "Yujia Zheng",
        "Zhengqing Gao",
        "Kun Zhang"
      ],
      "abstract": "Local causal discovery is of great practical significance, as there are often\nsituations where the discovery of the global causal structure is unnecessary,\nand the interest lies solely on a single target variable. Most existing local\nmethods utilize conditional independence relations, providing only a partially\ndirected graph, and assume acyclicity for the ground-truth structure, even\nthough real-world scenarios often involve cycles like feedback mechanisms. In\nthis work, we present a general, unified local causal discovery method with\nlinear non-Gaussian models, whether they are cyclic or acyclic. We extend the\napplication of independent component analysis from the global context to\nindependent subspace analysis, enabling the exact identification of the\nequivalent local directed structures and causal strengths from the Markov\nblanket of the target variable. We also propose an alternative regression-based\nmethod in the particular acyclic scenarios. Our identifiability results are\nempirically validated using both synthetic and real-world datasets.",
      "tldr_zh": "本文提出了一种通用统一的局部因果发现方法，适用于线性非高斯模型，无论是否存在循环结构（如反馈机制），以解决现有方法依赖条件独立性并假设无环的局限性。该方法扩展了Independent Component Analysis (ICA) 到Independent Subspace Analysis (ISA)，从目标变量的Markov Blanket中精确识别等价的局部有向结构和因果强度；对于无环场景，还提供了一种基于回归的替代方法。实验结果通过合成和真实数据集验证了该方法的识别性，展示了其在实际应用中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Appears at AISTATS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14843v1",
      "published_date": "2024-03-21 21:27:39 UTC",
      "updated_date": "2024-03-21 21:27:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:30:51.630862"
    },
    {
      "arxiv_id": "2403.14817v1",
      "title": "Crowdsourced Multilingual Speech Intelligibility Testing",
      "title_zh": "翻译失败",
      "authors": [
        "Laura Lechler",
        "Kamil Wojcicki"
      ],
      "abstract": "With the advent of generative audio features, there is an increasing need for\nrapid evaluation of their impact on speech intelligibility. Beyond the existing\nlaboratory measures, which are expensive and do not scale well, there has been\ncomparatively little work on crowdsourced assessment of intelligibility.\nStandards and recommendations are yet to be defined, and publicly available\nmultilingual test materials are lacking. In response to this challenge, we\npropose an approach for a crowdsourced intelligibility assessment. We detail\nthe test design, the collection and public release of the multilingual speech\ndata, and the results of our early experiments.",
      "tldr_zh": "这篇论文针对生成音频技术对语音可懂度(speech intelligibility)的评估需求，提出了一种众包(crowdsourced)多语言(multilingual)评估方法，以解决现有实验室措施成本高且不易扩展的问题。研究者详细设计了测试流程，包括收集并公开发布多语言语音数据。初步实验结果表明，这一方法有效，并为制定相关标准和推荐提供了基础。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14817v1",
      "published_date": "2024-03-21 20:14:53 UTC",
      "updated_date": "2024-03-21 20:14:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:31:02.720228"
    },
    {
      "arxiv_id": "2403.14814v3",
      "title": "The opportunities and risks of large language models in mental health",
      "title_zh": "大型语言模型在心理健康中的机会与风险",
      "authors": [
        "Hannah R. Lawrence",
        "Renee A. Schneider",
        "Susan B. Rubin",
        "Maja J. Mataric",
        "Daniel J. McDuff",
        "Megan Jones Bell"
      ],
      "abstract": "Global rates of mental health concerns are rising, and there is increasing\nrealization that existing models of mental health care will not adequately\nexpand to meet the demand. With the emergence of large language models (LLMs)\nhas come great optimism regarding their promise to create novel, large-scale\nsolutions to support mental health. Despite their nascence, LLMs have already\nbeen applied to mental health related tasks. In this paper, we summarize the\nextant literature on efforts to use LLMs to provide mental health education,\nassessment, and intervention and highlight key opportunities for positive\nimpact in each area. We then highlight risks associated with LLMs' application\nto mental health and encourage the adoption of strategies to mitigate these\nrisks. The urgent need for mental health support must be balanced with\nresponsible development, testing, and deployment of mental health LLMs. It is\nespecially critical to ensure that mental health LLMs are fine-tuned for mental\nhealth, enhance mental health equity, and adhere to ethical standards and that\npeople, including those with lived experience with mental health concerns, are\ninvolved in all stages from development through deployment. Prioritizing these\nefforts will minimize potential harms to mental health and maximize the\nlikelihood that LLMs will positively impact mental health globally.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在心理健康领域的机会与风险，强调全球心理健康问题上升背景下，LLMs 可用于创建大规模的教育、评估和干预解决方案。论文总结了现有文献中 LLMs 的应用潜力，包括提升可及性和积极影响。另一方面，它突出了潜在风险，如伦理问题和不公平性，并建议通过针对心理健康的微调、遵守伦理标准以及涉及患者和专家的参与来缓解这些风险。最终，论文呼吁平衡紧迫需求与负责任的开发，确保 LLMs 最大化全球心理健康益处。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 2 tables, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14814v3",
      "published_date": "2024-03-21 19:59:52 UTC",
      "updated_date": "2024-08-01 15:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:31:14.237546"
    },
    {
      "arxiv_id": "2403.14800v1",
      "title": "Deep Active Learning: A Reality Check",
      "title_zh": "深度主动学习：现实检验",
      "authors": [
        "Edrina Gashi",
        "Jiankang Deng",
        "Ismail Elezi"
      ],
      "abstract": "We conduct a comprehensive evaluation of state-of-the-art deep active\nlearning methods. Surprisingly, under general settings, no single-model method\ndecisively outperforms entropy-based active learning, and some even fall short\nof random sampling. We delve into overlooked aspects like starting budget,\nbudget step, and pretraining's impact, revealing their significance in\nachieving superior results. Additionally, we extend our evaluation to other\ntasks, exploring the active learning effectiveness in combination with\nsemi-supervised learning, and object detection. Our experiments provide\nvaluable insights and concrete recommendations for future active learning\nstudies. By uncovering the limitations of current methods and understanding the\nimpact of different experimental settings, we aim to inspire more efficient\ntraining of deep learning models in real-world scenarios with limited\nannotation budgets. This work contributes to advancing active learning's\nefficacy in deep learning and empowers researchers to make informed decisions\nwhen applying active learning to their tasks.",
      "tldr_zh": "这篇论文对最先进的深度主动学习（active learning）方法进行了全面评估，发现这些方法在一般设置下并未显著优于基于熵（entropy-based）的主动学习策略，有些甚至不如随机采样。研究者深入探讨了起始预算、预算步进和预训练的影响，这些因素对结果至关重要，并将评估扩展到半监督学习（semi-supervised learning）和物体检测（object detection）任务。最终，论文提供了宝贵见解和具体推荐，帮助在标注预算有限的真实场景中更高效地训练深度学习模型，并揭示了当前方法的局限性以指导未来研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14800v1",
      "published_date": "2024-03-21 19:28:17 UTC",
      "updated_date": "2024-03-21 19:28:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:31:26.772581"
    },
    {
      "arxiv_id": "2403.14796v1",
      "title": "Planning and Acting While the Clock Ticks",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Coles",
        "Erez Karpas",
        "Andrey Lavrinenko",
        "Wheeler Ruml",
        "Solomon Eyal Shimony",
        "Shahaf Shperberg"
      ],
      "abstract": "Standard temporal planning assumes that planning takes place offline and then\nexecution starts at time 0. Recently, situated temporal planning was\nintroduced, where planning starts at time 0 and execution occurs after planning\nterminates. Situated temporal planning reflects a more realistic scenario where\ntime passes during planning. However, in situated temporal planning a complete\nplan must be generated before any action is executed. In some problems with\ntime pressure, timing is too tight to complete planning before the first action\nmust be executed. For example, an autonomous car that has a truck backing\ntowards it should probably move out of the way now and plan how to get to its\ndestination later. In this paper, we propose a new problem setting: concurrent\nplanning and execution, in which actions can be dispatched (executed) before\nplanning terminates. Unlike previous work on planning and execution, we must\nhandle wall clock deadlines that affect action applicability and goal\nachievement (as in situated planning) while also supporting dispatching actions\nbefore a complete plan has been found. We extend previous work on metareasoning\nfor situated temporal planning to develop an algorithm for this new setting.\nOur empirical evaluation shows that when there is strong time pressure, our\napproach outperforms situated temporal planning.",
      "tldr_zh": "这篇论文针对时间规划中的时间压力问题，提出了一种新的 concurrent planning and execution 设置，允许动作在规划完成前被执行，从而处理标准 temporal planning 和 situated temporal planning 的局限性。作者扩展了 meta-reasoning for situated temporal planning 的方法，开发了一个新算法，能够同时处理墙钟时间截止对动作适用性和目标实现的限制。实验结果显示，在强时间压力场景下，该方法比 situated temporal planning 性能更优。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14796v1",
      "published_date": "2024-03-21 19:18:47 UTC",
      "updated_date": "2024-03-21 19:18:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:31:38.768153"
    },
    {
      "arxiv_id": "2403.14791v4",
      "title": "Particip-AI: A Democratic Surveying Framework for Anticipating Future AI Use Cases, Harms and Benefits",
      "title_zh": "翻译失败",
      "authors": [
        "Jimin Mun",
        "Liwei Jiang",
        "Jenny Liang",
        "Inyoung Cheong",
        "Nicole DeCario",
        "Yejin Choi",
        "Tadayoshi Kohno",
        "Maarten Sap"
      ],
      "abstract": "General purpose AI, such as ChatGPT, seems to have lowered the barriers for\nthe public to use AI and harness its power. However, the governance and\ndevelopment of AI still remain in the hands of a few, and the pace of\ndevelopment is accelerating without a comprehensive assessment of risks. As a\nfirst step towards democratic risk assessment and design of general purpose AI,\nwe introduce PARTICIP-AI, a carefully designed framework for laypeople to\nspeculate and assess AI use cases and their impacts. Our framework allows us to\nstudy more nuanced and detailed public opinions on AI through collecting use\ncases, surfacing diverse harms through risk assessment under alternate\nscenarios (i.e., developing and not developing a use case), and illuminating\ntensions over AI development through making a concluding choice on its\ndevelopment. To showcase the promise of our framework towards informing\ndemocratic AI development, we run a medium-scale study with inputs from 295\ndemographically diverse participants. Our analyses show that participants'\nresponses emphasize applications for personal life and society, contrasting\nwith most current AI development's business focus. We also surface diverse set\nof envisioned harms such as distrust in AI and institutions, complementary to\nthose defined by experts. Furthermore, we found that perceived impact of not\ndeveloping use cases significantly predicted participants' judgements of\nwhether AI use cases should be developed, and highlighted lay users' concerns\nof techno-solutionism. We conclude with a discussion on how frameworks like\nPARTICIP-AI can further guide democratic AI development and governance.",
      "tldr_zh": "该研究引入了 Particip-AI 框架，这是一个民主化调查工具，旨在让普通公众预测和评估未来 AI 用例的益处、危害及影响，从而推动 AI 风险评估和设计的民主化进程。通过一项涉及 295 名参与者的中等规模研究，该框架收集了 AI 用例、评估了不同场景下的风险（如开发与不开发的影响），并突出了公众对 AI 开发的张力，例如 distrust 和 techno-solutionism 的担忧。结果显示，参与者更关注个人生活和社会应用而非商业焦点，且不开发用例的感知影响显著预测了开发决策，为民主 AI 开发与治理提供了宝贵指导。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "AIES 2024, 34 pages, 4 figures, 23 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.14791v4",
      "published_date": "2024-03-21 19:12:37 UTC",
      "updated_date": "2024-09-09 20:09:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:31:54.647506"
    },
    {
      "arxiv_id": "2403.14790v1",
      "title": "Latent Diffusion Models for Attribute-Preserving Image Anonymization",
      "title_zh": "用于属性保留图像匿名化的潜在扩散模型",
      "authors": [
        "Luca Piano",
        "Pietro Basci",
        "Fabrizio Lamberti",
        "Lia Morra"
      ],
      "abstract": "Generative techniques for image anonymization have great potential to\ngenerate datasets that protect the privacy of those depicted in the images,\nwhile achieving high data fidelity and utility. Existing methods have focused\nextensively on preserving facial attributes, but failed to embrace a more\ncomprehensive perspective that considers the scene and background into the\nanonymization process. This paper presents, to the best of our knowledge, the\nfirst approach to image anonymization based on Latent Diffusion Models (LDMs).\nEvery element of a scene is maintained to convey the same meaning, yet\nmanipulated in a way that makes re-identification difficult. We propose two\nLDMs for this purpose: CAMOUFLaGE-Base exploits a combination of pre-trained\nControlNets, and a new controlling mechanism designed to increase the distance\nbetween the real and anonymized images. CAMOFULaGE-Light is based on the\nAdapter technique, coupled with an encoding designed to efficiently represent\nthe attributes of different persons in a scene. The former solution achieves\nsuperior performance on most metrics and benchmarks, while the latter cuts the\ninference time in half at the cost of fine-tuning a lightweight module. We show\nthrough extensive experimental comparison that the proposed method is\ncompetitive with the state-of-the-art concerning identity obfuscation whilst\nbetter preserving the original content of the image and tackling unresolved\nchallenges that current solutions fail to address.",
      "tldr_zh": "这篇论文首次提出基于 Latent Diffusion Models (LDMs) 的图像匿名化方法，旨在保护图像中人物隐私的同时，全面保留场景和背景元素，使其含义不变但难以再识别。作者开发了两个模型：CAMOUFLaGE-Base 结合预训练的 ControlNets 和一个新机制来增加真实图像与匿名化图像的距离；CAMOFULaGE-Light 则使用 Adapter 技术及高效编码来处理多人物属性，显著减少推理时间。实验结果显示，该方法在身份混淆性能上与最先进技术相当，同时更好地保留图像原始内容，并解决了现有方法忽略场景背景的局限性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14790v1",
      "published_date": "2024-03-21 19:09:21 UTC",
      "updated_date": "2024-03-21 19:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:32:06.266079"
    },
    {
      "arxiv_id": "2403.14783v1",
      "title": "Multi-Agent VQA: Exploring Multi-Agent Foundation Models in Zero-Shot Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Jiang",
        "Zhijun Zhuang",
        "Shreyas S. Shivakumar",
        "Dan Roth",
        "Camillo J. Taylor"
      ],
      "abstract": "This work explores the zero-shot capabilities of foundation models in Visual\nQuestion Answering (VQA) tasks. We propose an adaptive multi-agent system,\nnamed Multi-Agent VQA, to overcome the limitations of foundation models in\nobject detection and counting by using specialized agents as tools. Unlike\nexisting approaches, our study focuses on the system's performance without\nfine-tuning it on specific VQA datasets, making it more practical and robust in\nthe open world. We present preliminary experimental results under zero-shot\nscenarios and highlight some failure cases, offering new directions for future\nresearch.",
      "tldr_zh": "这篇论文探索了基础模型在零样本 Visual Question Answering (VQA) 任务中的能力，提出了一种名为 Multi-Agent VQA 的自适应多智能体系统，以专门的智能体作为工具，克服基础模型在物体检测和计数方面的局限性。不同于现有方法，该系统无需针对特定 VQA 数据集进行微调，从而在开放世界中实现更实用和鲁棒的性能。实验结果展示了零样本场景下的初步表现，并突出了某些失败案例，为未来研究提供了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CV",
      "comment": "A full version of the paper will be released soon. The codes are\n  available at https://github.com/bowen-upenn/Multi-Agent-VQA",
      "pdf_url": "http://arxiv.org/pdf/2403.14783v1",
      "published_date": "2024-03-21 18:57:25 UTC",
      "updated_date": "2024-03-21 18:57:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:32:16.047610"
    },
    {
      "arxiv_id": "2403.15499v1",
      "title": "A Causal Analysis of CO2 Reduction Strategies in Electricity Markets Through Machine Learning-Driven Metalearners",
      "title_zh": "翻译失败",
      "authors": [
        "Iman Emtiazi Naeini",
        "Zahra Saberi",
        "Khadijeh Hassanzadeh"
      ],
      "abstract": "This study employs the Causal Machine Learning (CausalML) statistical method\nto analyze the influence of electricity pricing policies on carbon dioxide\n(CO2) levels in the household sector. Investigating the causality between\npotential outcomes and treatment effects, where changes in pricing policies are\nthe treatment, our analysis challenges the conventional wisdom surrounding\nincentive-based electricity pricing. The study's findings suggest that adopting\nsuch policies may inadvertently increase CO2 intensity. Additionally, we\nintegrate a machine learning-based meta-algorithm, reflecting a contemporary\nstatistical approach, to enhance the depth of our causal analysis. The study\nconducts a comparative analysis of learners X, T, S, and R to ascertain the\noptimal methods based on the defined question's specified goals and contextual\nnuances. This research contributes valuable insights to the ongoing dialogue on\nsustainable development practices, emphasizing the importance of considering\nunintended consequences in policy formulation.",
      "tldr_zh": "本研究利用 Causal Machine Learning (CausalML) 方法分析电力定价政策对家庭部门 CO2 水平的影响，探讨政策变化作为治疗（treatment）的因果关系，并挑战传统观点，认为激励型定价可能意外增加 CO2 强度。研究整合了机器学习-based meta-algorithm，并比较了 learners X, T, S 和 R 等模型，以确定最优方法并深化因果分析。结果显示，此类政策可能适得其反，强调在可持续发展和政策制定中需考虑潜在的意外后果，为更有效的 CO2 减排策略提供宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15499v1",
      "published_date": "2024-03-21 18:55:05 UTC",
      "updated_date": "2024-03-21 18:55:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:32:29.217730"
    },
    {
      "arxiv_id": "2403.14773v2",
      "title": "StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text",
      "title_zh": "翻译失败",
      "authors": [
        "Roberto Henschel",
        "Levon Khachatryan",
        "Hayk Poghosyan",
        "Daniil Hayrapetyan",
        "Vahram Tadevosyan",
        "Zhangyang Wang",
        "Shant Navasardyan",
        "Humphrey Shi"
      ],
      "abstract": "Text-to-video diffusion models enable the generation of high-quality videos\nthat follow text instructions, making it easy to create diverse and individual\ncontent. However, existing approaches mostly focus on high-quality short video\ngeneration (typically 16 or 24 frames), ending up with hard-cuts when naively\nextended to the case of long video synthesis. To overcome these limitations, we\nintroduce StreamingT2V, an autoregressive approach for long video generation of\n80, 240, 600, 1200 or more frames with smooth transitions. The key components\nare:(i) a short-term memory block called conditional attention module (CAM),\nwhich conditions the current generation on the features extracted from the\nprevious chunk via an attentional mechanism, leading to consistent chunk\ntransitions, (ii) a long-term memory block called appearance preservation\nmodule, which extracts high-level scene and object features from the first\nvideo chunk to prevent the model from forgetting the initial scene, and (iii) a\nrandomized blending approach that enables to apply a video enhancer\nautoregressively for infinitely long videos without inconsistencies between\nchunks. Experiments show that StreamingT2V generates high motion amount. In\ncontrast, all competing image-to-video methods are prone to video stagnation\nwhen applied naively in an autoregressive manner. Thus, we propose with\nStreamingT2V a high-quality seamless text-to-long video generator that\noutperforms competitors with consistency and motion. Our code will be available\nat: https://github.com/Picsart-AI-Research/StreamingT2V",
      "tldr_zh": "该论文提出 StreamingT2V，一种自回归方法，用于从文本生成一致、动态且可扩展的长视频（如80、240、600或更多帧），解决现有 Text-to-Video 扩散模型在长视频合成中出现的硬切问题。关键组件包括 conditional attention module (CAM) 用于短时记忆以确保块间平滑过渡、appearance preservation module 用于长时记忆以保留初始场景特征，以及 randomized blending approach 以支持无限长视频的增强应用。实验结果显示，StreamingT2V 生成的高运动量视频明显优于竞争方法，避免了视频停滞问题，并在一致性和动态性方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "https://github.com/Picsart-AI-Research/StreamingT2V",
      "pdf_url": "http://arxiv.org/pdf/2403.14773v2",
      "published_date": "2024-03-21 18:27:29 UTC",
      "updated_date": "2025-04-16 13:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:32:41.411782"
    },
    {
      "arxiv_id": "2403.14772v2",
      "title": "Improving Robustness to Model Inversion Attacks via Sparse Coding Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Sayanton V. Dibbo",
        "Adam Breuer",
        "Juston Moore",
        "Michael Teti"
      ],
      "abstract": "Recent model inversion attack algorithms permit adversaries to reconstruct a\nneural network's private and potentially sensitive training data by repeatedly\nquerying the network. In this work, we develop a novel network architecture\nthat leverages sparse-coding layers to obtain superior robustness to this class\nof attacks. Three decades of computer science research has studied sparse\ncoding in the context of image denoising, object recognition, and adversarial\nmisclassification settings, but to the best of our knowledge, its connection to\nstate-of-the-art privacy vulnerabilities remains unstudied. In this work, we\nhypothesize that sparse coding architectures suggest an advantageous means to\ndefend against model inversion attacks because they allow us to control the\namount of irrelevant private information encoded by a network in a manner that\nis known to have little effect on classification accuracy. Specifically,\ncompared to networks trained with a variety of state-of-the-art defenses, our\nsparse-coding architectures maintain comparable or higher classification\naccuracy while degrading state-of-the-art training data reconstructions by\nfactors of 1.1 to 18.3 across a variety of reconstruction quality metrics\n(PSNR, SSIM, FID). This performance advantage holds across 5 datasets ranging\nfrom CelebA faces to medical images and CIFAR-10, and across various\nstate-of-the-art SGD-based and GAN-based inversion attacks, including\nPlug-&-Play attacks. We provide a cluster-ready PyTorch codebase to promote\nresearch and standardize defense evaluations.",
      "tldr_zh": "本研究提出了一种基于稀疏编码（sparse coding）架构的神经网络设计，以提升对模型反转攻击（model inversion attacks）的鲁棒性，这些攻击可通过查询网络重建敏感训练数据。相比现有防御方法，该架构通过控制无关私有信息的编码，维持或提高分类准确率，同时将训练数据重建质量降低1.1到18.3倍（基于PSNR、SSIM和FID指标）。实验在CelebA、医疗图像和CIFAR-10等5个数据集上验证了其有效性，对各种SGD-based和GAN-based攻击（如Plug-&-Play攻击）均表现出优势。该框架还提供了开源PyTorch代码库，以促进进一步研究和防御评估。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14772v2",
      "published_date": "2024-03-21 18:26:23 UTC",
      "updated_date": "2024-08-24 18:29:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:32:55.216870"
    },
    {
      "arxiv_id": "2403.14763v1",
      "title": "Gravitational Duals from Equations of State",
      "title_zh": "翻译失败",
      "authors": [
        "Yago Bea",
        "Raul Jimenez",
        "David Mateos",
        "Shuheng Liu",
        "Pavlos Protopapas",
        "Pedro Tarancón-Álvarez",
        "Pablo Tejerina-Pérez"
      ],
      "abstract": "Holography relates gravitational theories in five dimensions to\nfour-dimensional quantum field theories in flat space. Under this map, the\nequation of state of the field theory is encoded in the black hole solutions of\nthe gravitational theory. Solving the five-dimensional Einstein's equations to\ndetermine the equation of state is an algorithmic, direct problem. Determining\nthe gravitational theory that gives rise to a prescribed equation of state is a\nmuch more challenging, inverse problem. We present a novel approach to solve\nthis problem based on physics-informed neural networks. The resulting algorithm\nis not only data-driven but also informed by the physics of the Einstein's\nequations. We successfully apply it to theories with crossovers, first- and\nsecond-order phase transitions.",
      "tldr_zh": "该研究探讨了全息原理（Holography），将五维引力理论与四维平直空间量子场理论相关联，其中场理论的equation of state在引力理论的黑洞解决方案中编码。作者提出了一种基于physics-informed neural networks的新算法，来解决从给定equation of state反推出引力理论的逆问题，该方法结合数据驱动和Einstein's equations的物理原理。实验结果显示，该算法成功应用于具有交叉、第一阶和第二阶phase transitions的理论中，提供了一个有效的解决方案。",
      "categories": [
        "hep-th",
        "astro-ph.CO",
        "cs.AI",
        "cs.LG",
        "gr-qc"
      ],
      "primary_category": "hep-th",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14763v1",
      "published_date": "2024-03-21 18:07:32 UTC",
      "updated_date": "2024-03-21 18:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:33:06.032016"
    },
    {
      "arxiv_id": "2403.14624v2",
      "title": "MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?",
      "title_zh": "翻译失败",
      "authors": [
        "Renrui Zhang",
        "Dongzhi Jiang",
        "Yichi Zhang",
        "Haokun Lin",
        "Ziyu Guo",
        "Pengshuo Qiu",
        "Aojun Zhou",
        "Pan Lu",
        "Kai-Wei Chang",
        "Peng Gao",
        "Hongsheng Li"
      ],
      "abstract": "The remarkable progress of Multi-modal Large Language Models (MLLMs) has\ngarnered unparalleled attention, due to their superior performance in visual\ncontexts. However, their capabilities in visual math problem-solving remain\ninsufficiently evaluated and understood. We investigate current benchmarks to\nincorporate excessive visual content within textual questions, which\npotentially assist MLLMs in deducing answers without truly interpreting the\ninput diagrams. To this end, we introduce MathVerse, an all-around visual math\nbenchmark designed for an equitable and in-depth evaluation of MLLMs. We\nmeticulously collect 2,612 high-quality, multi-subject math problems with\ndiagrams from publicly available sources. Each problem is then transformed by\nhuman annotators into six distinct versions, each offering varying degrees of\ninformation content in multi-modality, contributing to 15K test samples in\ntotal. This approach allows MathVerse to comprehensively assess whether and how\nmuch MLLMs can truly understand the visual diagrams for mathematical reasoning.\nIn addition, we propose a Chain-of-Thought (CoT) evaluation strategy for a\nfine-grained assessment of the output answers. Rather than naively judging True\nor False, we employ GPT-4(V) to adaptively extract crucial reasoning steps, and\nthen score each step with detailed error analysis, which can reveal the\nintermediate CoT reasoning quality by MLLMs. We hope the MathVerse benchmark\nmay provide unique insights to guide the future development of MLLMs. Project\npage: https://mathverse-cuhk.github.io",
      "tldr_zh": "本研究评估了多模态大语言模型(MLLMs)在视觉数学问题中的真实性能，指出现有基准可能依赖文本信息而非图表解读。研究者引入MathVerse基准，收集了2,612个高质量、多主题数学问题，每个问题转化为6个不同版本的变体，总计15K测试样本，以全面测试MLLMs是否真正理解视觉图表进行数学推理。为此，他们提出Chain-of-Thought (CoT)评估策略，使用GPT-4(V)提取关键推理步骤并进行细粒度评分和错误分析，为未来MLLMs的发展提供宝贵洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024, 46 Pages, Benchmark Project Page:\n  https://mathverse-cuhk.github.io",
      "pdf_url": "http://arxiv.org/pdf/2403.14624v2",
      "published_date": "2024-03-21 17:59:50 UTC",
      "updated_date": "2024-08-18 08:10:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:33:16.252436"
    },
    {
      "arxiv_id": "2403.14617v3",
      "title": "Videoshop: Localized Semantic Video Editing with Noise-Extrapolated Diffusion Inversion",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Fan",
        "Anand Bhattad",
        "Ranjay Krishna"
      ],
      "abstract": "We introduce Videoshop, a training-free video editing algorithm for localized\nsemantic edits. Videoshop allows users to use any editing software, including\nPhotoshop and generative inpainting, to modify the first frame; it\nautomatically propagates those changes, with semantic, spatial, and temporally\nconsistent motion, to the remaining frames. Unlike existing methods that enable\nedits only through imprecise textual instructions, Videoshop allows users to\nadd or remove objects, semantically change objects, insert stock photos into\nvideos, etc. with fine-grained control over locations and appearance. We\nachieve this through image-based video editing by inverting latents with noise\nextrapolation, from which we generate videos conditioned on the edited image.\nVideoshop produces higher quality edits against 6 baselines on 2 editing\nbenchmarks using 10 evaluation metrics.",
      "tldr_zh": "本研究提出了 Videoshop，一种无需训练的视频编辑算法，支持本地化语义编辑，用户可使用如 Photoshop 等软件修改第一帧图像，然后自动将这些变化传播到其他帧，确保语义、空间和时间一致性。不同于依赖文本指令的现有方法，Videoshop 允许精细控制，如添加或移除对象、改变对象语义或插入库存照片，通过 Noise-Extrapolated Diffusion Inversion 的图像-based 编辑技术实现视频生成。该算法在两个编辑基准上，使用10个评估指标，与6个基线模型相比，产生了更高质量的编辑结果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV 2024. Project page:\n  https://videoshop-editing.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2403.14617v3",
      "published_date": "2024-03-21 17:59:03 UTC",
      "updated_date": "2024-10-24 20:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:33:29.668974"
    },
    {
      "arxiv_id": "2403.14606v2",
      "title": "The Elements of Differentiable Programming",
      "title_zh": "可微编程的要素",
      "authors": [
        "Mathieu Blondel",
        "Vincent Roulet"
      ],
      "abstract": "Artificial intelligence has recently experienced remarkable advances, fueled\nby large models, vast datasets, accelerated hardware, and, last but not least,\nthe transformative power of differentiable programming. This new programming\nparadigm enables end-to-end differentiation of complex computer programs\n(including those with control flows and data structures), making gradient-based\noptimization of program parameters possible. As an emerging paradigm,\ndifferentiable programming builds upon several areas of computer science and\napplied mathematics, including automatic differentiation, graphical models,\noptimization and statistics. This book presents a comprehensive review of the\nfundamental concepts useful for differentiable programming. We adopt two main\nperspectives, that of optimization and that of probability, with clear\nanalogies between the two. Differentiable programming is not merely the\ndifferentiation of programs, but also the thoughtful design of programs\nintended for differentiation. By making programs differentiable, we inherently\nintroduce probability distributions over their execution, providing a means to\nquantify the uncertainty associated with program outputs.",
      "tldr_zh": "这本书审视了可微编程(Differentiable Programming)作为人工智能进步的关键驱动力，允许对复杂程序（包括控制流和数据结构）进行端到端微分，从而实现基于梯度的参数优化。该书从优化和概率两个视角出发，构建于automatic differentiation、graphical models、optimization和statistics等领域的基础概念之上。通过设计可微程序，不仅实现了程序微分，还引入了程序执行的概率分布，以量化输出不确定性。总的来说，这为可微编程提供了全面框架，促进了人工智能领域的创新发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "Draft version 2",
      "pdf_url": "http://arxiv.org/pdf/2403.14606v2",
      "published_date": "2024-03-21 17:55:16 UTC",
      "updated_date": "2024-07-24 16:56:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:33:40.324140"
    },
    {
      "arxiv_id": "2403.14592v1",
      "title": "Envisioning the Next-Generation AI Coding Assistants: Insights & Proposals",
      "title_zh": "展望下一代 AI 编码助手：见解与提案",
      "authors": [
        "Khanh Nghiem",
        "Anh Minh Nguyen",
        "Nghi D. Q. Bui"
      ],
      "abstract": "As a research-product hybrid group in AI for Software Engineering (AI4SE), we\npresent four key takeaways from our experience developing in-IDE AI coding\nassistants. AI coding assistants should set clear expectations for usage,\nintegrate with advanced IDE capabilities and existing extensions, use\nextendable backend designs, and collect app data responsibly for downstream\nanalyses. We propose open questions and challenges that academia and industry\nshould address to realize the vision of next-generation AI coding assistants.",
      "tldr_zh": "这篇论文由AI for Software Engineering (AI4SE) 研究团队撰写，基于他们在开发in-IDE AI coding assistants的经验，总结了四个关键要点：设定清晰的使用期望、与高级IDE功能和现有扩展集成、使用可扩展的后端设计，以及负责地收集应用数据以支持后续分析。作者强调了这些要点有助于提升AI coding assistants的实用性，并提出了学术界和工业界需要解决的开放问题和挑战，以推动下一代AI coding assistants的愿景实现。最终，该研究为构建更可靠、智能的代码辅助工具提供了宝贵见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14592v1",
      "published_date": "2024-03-21 17:47:28 UTC",
      "updated_date": "2024-03-21 17:47:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:33:55.077974"
    },
    {
      "arxiv_id": "2403.14589v3",
      "title": "ReAct Meets ActRe: When Language Agents Enjoy Training Data Autonomy",
      "title_zh": "ReAct Meets ActRe：当语言代理享受训练数据自治时",
      "authors": [
        "Zonghan Yang",
        "Peng Li",
        "Ming Yan",
        "Ji Zhang",
        "Fei Huang",
        "Yang Liu"
      ],
      "abstract": "Language agents have demonstrated autonomous decision-making abilities by\nreasoning with foundation models. Recently, efforts have been made to train\nlanguage agents for performance improvement, with multi-step reasoning and\naction trajectories as the training data. However, collecting such trajectories\nstill requires considerable human effort, by either artificial annotation or\nimplementations of diverse prompting frameworks. In this work, we propose\nA$^3$T, a framework that enables the Autonomous Annotation of Agent\nTrajectories in the style of ReAct. The central role is an ActRe prompting\nagent, which explains the reason for an arbitrary action. When randomly\nsampling an external action, the ReAct-style agent could query the ActRe agent\nwith the action to obtain its textual rationales. Novel trajectories are then\nsynthesized by prepending the posterior reasoning from ActRe to the sampled\naction. In this way, the ReAct-style agent executes multiple trajectories for\nthe failed tasks, and selects the successful ones to supplement its failed\ntrajectory for contrastive self-training. Realized by policy gradient methods\nwith binarized rewards, the contrastive self-training with accumulated\ntrajectories facilitates a closed loop for multiple rounds of language agent\nself-improvement. We conduct experiments using QLoRA fine-tuning with the\nopen-sourced Mistral-7B-Instruct-v0.2. In AlfWorld, the agent trained with\nA$^3$T obtains a 1-shot success rate of 96%, and 100% success with 4 iterative\nrounds. In WebShop, the 1-shot performance of the A$^3$T agent matches human\naverage, and 4 rounds of iterative refinement lead to the performance\napproaching human experts. A$^3$T agents significantly outperform existing\ntechniques, including prompting with GPT-4, advanced agent frameworks, and\nfully fine-tuned LLMs.",
      "tldr_zh": "该研究提出 A³T 框架，旨在实现语言代理的训练数据自治，减少人类标注努力，通过结合 ReAct 和 ActRe 提示机制来生成多步推理轨迹。A³T 允许代理从随机采样动作中获取推理解释、合成新轨迹，并使用对比自训练（结合 QLoRA 微调 Mistral-7B-Instruct-v0.2）来迭代改进性能。实验结果显示，在 AlfWorld 上，代理的 1-shot 成功率达 96%，多轮迭代后达 100%；在 WebShop 上，其性能匹配人类平均水平，并接近专家水平，显著超越 GPT-4 和其他现有方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14589v3",
      "published_date": "2024-03-21 17:43:44 UTC",
      "updated_date": "2024-04-01 17:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:34:06.155723"
    },
    {
      "arxiv_id": "2403.14582v1",
      "title": "Large Language Models for Multi-Choice Question Classification of Medical Subjects",
      "title_zh": "翻译失败",
      "authors": [
        "Víctor Ponce-López"
      ],
      "abstract": "The aim of this paper is to evaluate whether large language models trained on\nmulti-choice question data can be used to discriminate between medical\nsubjects. This is an important and challenging task for automatic question\nanswering. To achieve this goal, we train deep neural networks for multi-class\nclassification of questions into the inferred medical subjects. Using our\nMulti-Question (MQ) Sequence-BERT method, we outperform the state-of-the-art\nresults on the MedMCQA dataset with an accuracy of 0.68 and 0.60 on their\ndevelopment and test sets, respectively. In this sense, we show the capability\nof AI and LLMs in particular for multi-classification tasks in the Healthcare\ndomain.",
      "tldr_zh": "本研究评估了大型语言模型(LLMs)是否能有效区分医疗科目的多选题分类，这是一个关键的自动问答挑战。研究团队训练了深度神经网络，使用Multi-Question (MQ) Sequence-BERT方法进行多类分类。结果显示，在MedMCQA数据集上，该模型的准确率达到开发集0.68和测试集0.60，超过了现有最佳性能。总体而言，这展示了AI和LLMs在医疗领域多分类任务中的强大潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14582v1",
      "published_date": "2024-03-21 17:36:08 UTC",
      "updated_date": "2024-03-21 17:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:34:17.795221"
    },
    {
      "arxiv_id": "2403.14578v1",
      "title": "RAmBLA: A Framework for Evaluating the Reliability of LLMs as Assistants in the Biomedical Domain",
      "title_zh": "翻译失败",
      "authors": [
        "William James Bolton",
        "Rafael Poyiadzi",
        "Edward R. Morrell",
        "Gabriela van Bergen Gonzalez Bueno",
        "Lea Goetz"
      ],
      "abstract": "Large Language Models (LLMs) increasingly support applications in a wide\nrange of domains, some with potential high societal impact such as biomedicine,\nyet their reliability in realistic use cases is under-researched. In this work\nwe introduce the Reliability AssesMent for Biomedical LLM Assistants (RAmBLA)\nframework and evaluate whether four state-of-the-art foundation LLMs can serve\nas reliable assistants in the biomedical domain. We identify prompt robustness,\nhigh recall, and a lack of hallucinations as necessary criteria for this use\ncase. We design shortform tasks and tasks requiring LLM freeform responses\nmimicking real-world user interactions. We evaluate LLM performance using\nsemantic similarity with a ground truth response, through an evaluator LLM.",
      "tldr_zh": "该研究引入了 RAmBLA 框架，用于评估大型语言模型 (LLMs) 在生物医学领域作为助手的可靠性，针对其在实际应用中的不足进行系统性研究。框架强调了提示鲁棒性 (prompt robustness)、高召回率 (high recall) 和缺乏幻觉 (lack of hallucinations) 作为关键标准，并设计了短形式任务和模拟真实用户交互的自由形式响应任务。评估通过语义相似度与 ground truth 响应比较，以及使用评估器 LLM 来分析四个最先进的 LLMs 性能，为 LLMs 在生物医学领域的可靠应用提供了重要参考。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2024 Workshop on Reliable and Responsible\n  Foundation Models",
      "pdf_url": "http://arxiv.org/pdf/2403.14578v1",
      "published_date": "2024-03-21 17:30:59 UTC",
      "updated_date": "2024-03-21 17:30:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:34:31.889885"
    },
    {
      "arxiv_id": "2403.14566v2",
      "title": "A survey on Concept-based Approaches For Model Improvement",
      "title_zh": "翻译失败",
      "authors": [
        "Avani Gupta",
        "P J Narayanan"
      ],
      "abstract": "The focus of recent research has shifted from merely improving the metrics\nbased performance of Deep Neural Networks (DNNs) to DNNs which are more\ninterpretable to humans. The field of eXplainable Artificial Intelligence (XAI)\nhas observed various techniques, including saliency-based and concept-based\napproaches. These approaches explain the model's decisions in simple human\nunderstandable terms called Concepts. Concepts are known to be the thinking\nground of humans}. Explanations in terms of concepts enable detecting spurious\ncorrelations, inherent biases, or clever-hans. With the advent of concept-based\nexplanations, a range of concept representation methods and automatic concept\ndiscovery algorithms have been introduced. Some recent works also use concepts\nfor model improvement in terms of interpretability and generalization. We\nprovide a systematic review and taxonomy of various concept representations and\ntheir discovery algorithms in DNNs, specifically in vision. We also provide\ndetails on concept-based model improvement literature marking the first\ncomprehensive survey of these methods.",
      "tldr_zh": "这篇论文对基于概念（Concepts）的深度神经网络（DNNs）改进方法进行了系统性调查，聚焦于可解释人工智能（XAI）领域。作者回顾了各种概念表示方法和自动概念发现算法，特别是针对视觉任务，这些方法能以人类可理解的术语解释模型决策，从而检测spurious correlations、inherent biases或clever-hans问题。论文还分类了利用Concepts提升模型可解释性和泛化能力的文献，这是首个全面综述此类方法的调研，为未来XAI研究提供了重要参考。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14566v2",
      "published_date": "2024-03-21 17:09:20 UTC",
      "updated_date": "2024-03-23 09:50:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:34:41.928514"
    },
    {
      "arxiv_id": "2403.14562v2",
      "title": "Agentic AI: The Era of Semantic Decoding",
      "title_zh": "Agentic AI：语义解码的时代",
      "authors": [
        "Maxime Peyrard",
        "Martin Josifoski",
        "Robert West"
      ],
      "abstract": "Recent work demonstrated great promise in the idea of orchestrating\ncollaborations between LLMs, human input, and various tools to address the\ninherent limitations of LLMs. We propose a novel perspective called semantic\ndecoding, which frames these collaborative processes as optimization procedures\nin semantic space. Specifically, we conceptualize LLMs as semantic processors\nthat manipulate meaningful pieces of information that we call semantic tokens\n(known thoughts). LLMs are among a large pool of other semantic processors,\nincluding humans and tools, such as search engines or code executors.\nCollectively, semantic processors engage in dynamic exchanges of semantic\ntokens to progressively construct high-utility outputs. We refer to these\norchestrated interactions among semantic processors, optimizing and searching\nin semantic space, as semantic decoding algorithms. This concept draws a direct\nparallel to the well-studied problem of syntactic decoding, which involves\ncrafting algorithms to best exploit auto-regressive language models for\nextracting high-utility sequences of syntactic tokens. By focusing on the\nsemantic level and disregarding syntactic details, we gain a fresh perspective\non the engineering of AI systems, enabling us to imagine systems with much\ngreater complexity and capabilities. In this position paper, we formalize the\ntransition from syntactic to semantic tokens as well as the analogy between\nsyntactic and semantic decoding. Subsequently, we explore the possibilities of\noptimizing within the space of semantic tokens via semantic decoding\nalgorithms. We conclude with a list of research opportunities and questions\narising from this fresh perspective. The semantic decoding perspective offers a\npowerful abstraction for search and optimization directly in the space of\nmeaningful concepts, with semantic tokens as the fundamental units of a new\ntype of computation.",
      "tldr_zh": "该论文提出语义解码（semantic decoding）的新视角，将大型语言模型（LLMs）、人类输入和工具（如搜索引擎或代码执行器）的协作视为语义空间中的优化过程。作者将LLMs等视为语义处理器，通过交换语义标记（semantic tokens）来动态构建高效输出，并将此与传统的语法解码（syntactic decoding）类比，强调在语义层面进行优化以忽略语法细节，从而实现更复杂、更强大的AI系统。作为一篇position paper，该研究正式化了从语法到语义的转变，并列出了相关研究机会和问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14562v2",
      "published_date": "2024-03-21 17:06:17 UTC",
      "updated_date": "2025-04-29 15:24:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:34:54.307744"
    },
    {
      "arxiv_id": "2403.14551v1",
      "title": "Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Chengxu Zhuang",
        "Evelina Fedorenko",
        "Jacob Andreas"
      ],
      "abstract": "Today's most accurate language models are trained on orders of magnitude more\nlanguage data than human language learners receive - but with no supervision\nfrom other sensory modalities that play a crucial role in human learning. Can\nwe make LMs' representations and predictions more accurate (and more\nhuman-like) with more ecologically plausible supervision? This paper describes\nLexiContrastive Grounding (LCG), a grounded language learning procedure that\nleverages visual supervision to improve textual representations.\nLexiContrastive Grounding combines a next token prediction strategy with a\ncontrastive visual grounding objective, focusing on early-layer representations\nthat encode lexical information. Across multiple word-learning and\nsentence-understanding benchmarks, LexiContrastive Grounding not only\noutperforms standard language-only models in learning efficiency, but also\nimproves upon vision-and-language learning procedures including CLIP, GIT,\nFlamingo, and Vokenization. Moreover, LexiContrastive Grounding improves\nperplexity by around 5% on multiple language modeling tasks. This work\nunderscores the potential of incorporating visual grounding into language\nmodels, aligning more closely with the multimodal nature of human language\nacquisition.",
      "tldr_zh": "该论文提出 LexiContrastive Grounding (LCG)，一种利用视觉监督的接地语言学习方法，旨在通过更接近人类多感官学习的生态方式改善语言模型的文本表示和预测准确性。LCG 结合了下一个标记预测策略和对比视觉接地目标，专注于编码词汇信息的早期层表示，从而提升词汇学习和句子理解的效率。在多个基准测试中，LCG 不仅在学习效率上优于标准语言模型，还超越了 CLIP、GIT、Flamingo 和 Vokenization 等视觉语言模型，并将语言建模任务的困惑度降低了约 5%，强调了视觉接地在增强语言模型方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14551v1",
      "published_date": "2024-03-21 16:52:01 UTC",
      "updated_date": "2024-03-21 16:52:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:35:06.560178"
    },
    {
      "arxiv_id": "2403.14550v1",
      "title": "Dynamic Explanation Emphasis in Human-XAI Interaction with Communication Robot",
      "title_zh": "翻译失败",
      "authors": [
        "Yosuke Fukuchi",
        "Seiji Yamada"
      ],
      "abstract": "Communication robots have the potential to contribute to effective human-XAI\ninteraction as an interface that goes beyond textual or graphical explanations.\nOne of their strengths is that they can use physical and vocal expressions to\nadd detailed nuances to explanations. However, it is not clear how a robot can\napply such expressions, or in particular, how we can develop a strategy to\nadaptively use such expressions depending on the task and user in dynamic\ninteractions. To address this question, this paper proposes DynEmph, a method\nfor a communication robot to decide where to emphasize XAI-generated\nexplanations with physical expressions. It predicts the effect of emphasizing\ncertain points on a user and aims to minimize the expected difference between\npredicted user decisions and AI-suggested ones. DynEmph features a strategy for\ndeciding where to emphasize in a data-driven manner, relieving engineers from\nthe need to manually design a strategy. We further conducted experiments to\ninvestigate how emphasis selection strategies affect the performance of user\ndecisions. The results suggest that, while a naive strategy (emphasizing\nexplanations for an AI's most probable class) does not necessarily work better,\nDynEmph effectively guides users to better decisions under the condition that\nthe performance of the AI suggestion is high.",
      "tldr_zh": "本研究探讨了通信机器人如何通过物理和声音表达增强人类与XAI（可解释人工智能）的交互，提出DynEmph方法来动态决定在XAI生成的解释中强调哪些部分。DynEmph采用数据驱动策略，通过预测强调对用户决策的影响，旨在最小化用户决策与AI建议之间的预期差异，从而避免手动设计强调策略。实验结果表明，当AI建议性能较高时，DynEmph能有效引导用户做出更好决策，而简单的naive策略（如仅强调AI最可能类别的解释）并不总是优越。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14550v1",
      "published_date": "2024-03-21 16:50:12 UTC",
      "updated_date": "2024-03-21 16:50:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:35:17.339892"
    },
    {
      "arxiv_id": "2403.14539v2",
      "title": "Robust 3D Shape Reconstruction in Zero-Shot from a Single Image in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Junhyeong Cho",
        "Kim Youwang",
        "Hunmin Yang",
        "Tae-Hyun Oh"
      ],
      "abstract": "Recent monocular 3D shape reconstruction methods have shown promising\nzero-shot results on object-segmented images without any occlusions. However,\ntheir effectiveness is significantly compromised in real-world conditions, due\nto imperfect object segmentation by off-the-shelf models and the prevalence of\nocclusions. To effectively address these issues, we propose a unified\nregression model that integrates segmentation and reconstruction, specifically\ndesigned for occlusion-aware 3D shape reconstruction. To facilitate its\nreconstruction in the wild, we also introduce a scalable data synthesis\npipeline that simulates a wide range of variations in objects, occluders, and\nbackgrounds. Training on our synthetic data enables the proposed model to\nachieve state-of-the-art zero-shot results on real-world images, using\nsignificantly fewer parameters than competing approaches.",
      "tldr_zh": "该研究针对现有单目 3D 形状重建方法在野外条件下（如不完美对象分割和遮挡）的局限性，提出一个统一的回归模型，将分割和重建过程整合，实现鲁棒的遮挡感知 3D 形状重建。同时，引入了一个可扩展的数据合成管道，以模拟对象、遮挡物和背景的多样变化。实验结果显示，在合成数据上训练后，该模型在真实世界图像上实现了最先进的 zero-shot 性能，且参数量显著少于竞争方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14539v2",
      "published_date": "2024-03-21 16:40:10 UTC",
      "updated_date": "2024-11-28 13:53:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:35:32.768819"
    },
    {
      "arxiv_id": "2403.14526v1",
      "title": "Click to Grasp: Zero-Shot Precise Manipulation via Visual Diffusion Descriptors",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolaos Tsagkas",
        "Jack Rome",
        "Subramanian Ramamoorthy",
        "Oisin Mac Aodha",
        "Chris Xiaoxuan Lu"
      ],
      "abstract": "Precise manipulation that is generalizable across scenes and objects remains\na persistent challenge in robotics. Current approaches for this task heavily\ndepend on having a significant number of training instances to handle objects\nwith pronounced visual and/or geometric part ambiguities. Our work explores the\ngrounding of fine-grained part descriptors for precise manipulation in a\nzero-shot setting by utilizing web-trained text-to-image diffusion-based\ngenerative models. We tackle the problem by framing it as a dense semantic part\ncorrespondence task. Our model returns a gripper pose for manipulating a\nspecific part, using as reference a user-defined click from a source image of a\nvisually different instance of the same object. We require no manual grasping\ndemonstrations as we leverage the intrinsic object geometry and features.\nPractical experiments in a real-world tabletop scenario validate the efficacy\nof our approach, demonstrating its potential for advancing semantic-aware\nrobotics manipulation. Web page: https://tsagkas.github.io/click2grasp",
      "tldr_zh": "这篇论文提出了 Click to Grasp 方法，利用 visual diffusion descriptors 实现 zero-shot 精确机器人操作，解决了现有方法对大量训练数据的依赖问题。方法将任务转化为 dense semantic part correspondence，通过 web-trained text-to-image diffusion-based generative models，利用用户在源图像上的点击来生成针对特定物体的抓取姿势，而无需手动 grasping demonstrations。实验在真实世界桌面场景中验证了该方法的有效性，展示了其在提升 semantic-aware 机器人操作方面的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14526v1",
      "published_date": "2024-03-21 16:26:19 UTC",
      "updated_date": "2024-03-21 16:26:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:35:43.808194"
    },
    {
      "arxiv_id": "2403.14508v1",
      "title": "Constrained Reinforcement Learning with Smoothed Log Barrier Function",
      "title_zh": "使用平滑对数屏障函数的约束强化学习",
      "authors": [
        "Baohe Zhang",
        "Yuan Zhang",
        "Lilli Frison",
        "Thomas Brox",
        "Joschka Bödecker"
      ],
      "abstract": "Reinforcement Learning (RL) has been widely applied to many control tasks and\nsubstantially improved the performances compared to conventional control\nmethods in many domains where the reward function is well defined. However, for\nmany real-world problems, it is often more convenient to formulate optimization\nproblems in terms of rewards and constraints simultaneously. Optimizing such\nconstrained problems via reward shaping can be difficult as it requires tedious\nmanual tuning of reward functions with several interacting terms. Recent\nformulations which include constraints mostly require a pre-training phase,\nwhich often needs human expertise to collect data or assumes having a\nsub-optimal policy readily available. We propose a new constrained RL method\ncalled CSAC-LB (Constrained Soft Actor-Critic with Log Barrier Function), which\nachieves competitive performance without any pre-training by applying a linear\nsmoothed log barrier function to an additional safety critic. It implements an\nadaptive penalty for policy learning and alleviates the numerical issues that\nare known to complicate the application of the log barrier function method. As\na result, we show that with CSAC-LB, we achieve state-of-the-art performance on\nseveral constrained control tasks with different levels of difficulty and\nevaluate our methods in a locomotion task on a real quadruped robot platform.",
      "tldr_zh": "该论文探讨了强化学习（Reinforcement Learning, RL）在控制任务中的应用，但强调了实际问题中需要同时处理奖励和约束的挑战，现有的方法往往依赖预训练或手动数据收集。作者提出了一种新方法 CSAC-LB（Constrained Soft Actor-Critic with Log Barrier Function），通过应用线性平滑的对数屏障函数（smoothed log barrier function）到安全批评者（safety critic）中，实现自适应惩罚和数值问题的缓解，而无需预训练。实验结果表明，CSAC-LB 在多个难度不同的约束控制任务上达到了最先进性能，并在真实四足机器人平台的运动任务中验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14508v1",
      "published_date": "2024-03-21 16:02:52 UTC",
      "updated_date": "2024-03-21 16:02:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:35:59.762172"
    },
    {
      "arxiv_id": "2403.14504v1",
      "title": "Soft Learning Probabilistic Circuits",
      "title_zh": "翻译失败",
      "authors": [
        "Soroush Ghandi",
        "Benjamin Quost",
        "Cassio de Campos"
      ],
      "abstract": "Probabilistic Circuits (PCs) are prominent tractable probabilistic models,\nallowing for a range of exact inferences. This paper focuses on the main\nalgorithm for training PCs, LearnSPN, a gold standard due to its efficiency,\nperformance, and ease of use, in particular for tabular data. We show that\nLearnSPN is a greedy likelihood maximizer under mild assumptions. While\ninferences in PCs may use the entire circuit structure for processing queries,\nLearnSPN applies a hard method for learning them, propagating at each sum node\na data point through one and only one of the children/edges as in a hard\nclustering process. We propose a new learning procedure named SoftLearn, that\ninduces a PC using a soft clustering process. We investigate the effect of this\nlearning-inference compatibility in PCs. Our experiments show that SoftLearn\noutperforms LearnSPN in many situations, yielding better likelihoods and\narguably better samples. We also analyze comparable tractable models to\nhighlight the differences between soft/hard learning and model querying.",
      "tldr_zh": "本论文探讨了Probabilistic Circuits (PCs)，一种可进行精确推理的概率模型，焦点在于改进其主要训练算法LearnSPN，该算法通过贪婪似然最大化器和硬聚类方法高效处理表格数据，但存在学习与推理不兼容的问题。作者提出了一种新方法SoftLearn，使用软聚类过程来诱导PCs，从而提升学习与推理的兼容性。实验结果显示，SoftLearn在许多场景下优于LearnSPN，提供更高的似然值和更好的样本质量，并通过与其他可计算模型的比较突出了软/硬学习差异。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14504v1",
      "published_date": "2024-03-21 15:56:15 UTC",
      "updated_date": "2024-03-21 15:56:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:36:09.671886"
    },
    {
      "arxiv_id": "2403.14496v1",
      "title": "How Human-Centered Explainable AI Interface Are Designed and Evaluated: A Systematic Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Thu Nguyen",
        "Alessandro Canossa",
        "Jichen Zhu"
      ],
      "abstract": "Despite its technological breakthroughs, eXplainable Artificial Intelligence\n(XAI) research has limited success in producing the {\\em effective\nexplanations} needed by users. In order to improve XAI systems' usability,\npractical interpretability, and efficacy for real users, the emerging area of\n{\\em Explainable Interfaces} (EIs) focuses on the user interface and user\nexperience design aspects of XAI. This paper presents a systematic survey of 53\npublications to identify current trends in human-XAI interaction and promising\ndirections for EI design and development. This is among the first systematic\nsurvey of EI research.",
      "tldr_zh": "尽管可解释人工智能 (XAI) 取得了技术突破，但其在提供有效解释方面仍面临挑战，因此新兴的 Explainable Interfaces (EIs) 专注于用户界面和用户体验设计，以提升 XAI 的可用性、实际可解释性和有效性。本文通过对 53 篇相关出版物进行系统调查，识别了人类-XAI 交互的当前趋势，以及 EI 设计和发展的有前景方向。作为首个系统调查 EI 研究的论文，这为未来的人性化 XAI 接口设计提供了宝贵指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14496v1",
      "published_date": "2024-03-21 15:44:56 UTC",
      "updated_date": "2024-03-21 15:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:36:23.428382"
    },
    {
      "arxiv_id": "2403.14494v2",
      "title": "Learning to Project for Cross-Task Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Dylan Auty",
        "Roy Miles",
        "Benedikt Kolbeinsson",
        "Krystian Mikolajczyk"
      ],
      "abstract": "Traditional knowledge distillation (KD) relies on a proficient teacher\ntrained on the target task, which is not always available. In this setting,\ncross-task distillation can be used, enabling the use of any teacher model\ntrained on a different task. However, many KD methods prove ineffective when\napplied to this cross-task setting. To address this limitation, we propose a\nsimple modification: the use of an inverted projection. We show that this\ndrop-in replacement for a standard projector is effective by learning to\ndisregard any task-specific features which might degrade the student's\nperformance. We find that this simple modification is sufficient for extending\nmany KD methods to the cross-task setting, where the teacher and student tasks\ncan be very different. In doing so, we obtain up to a 1.9% improvement in the\ncross-task setting compared to the traditional projection, at no additional\ncost. Our method can obtain significant performance improvements (up to 7%)\nwhen using even a randomly-initialised teacher on various tasks such as depth\nestimation, image translation, and semantic segmentation, despite the lack of\nany learned knowledge to transfer. To provide conceptual and analytical\ninsights into this result, we show that using an inverted projection allows the\ndistillation loss to be decomposed into a knowledge transfer and a spectral\nregularisation component. Through this analysis we are additionally able to\npropose a novel regularisation loss that allows teacher-free distillation,\nenabling performance improvements of up to 8.57% on ImageNet with no additional\ntraining costs.",
      "tldr_zh": "本文提出了一种名为“Learning to Project”的方法，用于跨任务知识蒸馏 (cross-task knowledge distillation)，通过引入倒置投影 (inverted projection) 来过滤任务特定特征，从而使传统知识蒸馏 (KD) 方法适用于教师模型不在目标任务训练的场景。实验结果显示，该方法在跨任务设置中比传统投影提升高达 1.9%，并在使用随机初始化的教师模型时，在深度估计、图像翻译和语义分割等任务上实现高达 7% 的性能改善。作者通过分析，将蒸馏损失分解为知识转移和谱正则化 (spectral regularisation) 组件，并提出一个新颖的正则化损失，支持无教师蒸馏 (teacher-free distillation)，在 ImageNet 上提升高达 8.57%。这项工作为跨任务知识转移提供了高效且低成本的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "BMVC 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14494v2",
      "published_date": "2024-03-21 15:42:17 UTC",
      "updated_date": "2024-11-27 18:12:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:36:38.539632"
    },
    {
      "arxiv_id": "2403.14488v2",
      "title": "A Causal Bayesian Network and Probabilistic Programming Based Reasoning Framework for Robot Manipulation Under Uncertainty",
      "title_zh": "一种基于因果贝叶斯网络和概率编程的推理框架，用于不确定条件下的机器人操作",
      "authors": [
        "Ricardo Cannizzaro",
        "Michael Groom",
        "Jonathan Routley",
        "Robert Osazuwa Ness",
        "Lars Kunze"
      ],
      "abstract": "Robot object manipulation in real-world environments is challenging because\nrobot operation must be robust to a range of sensing, estimation, and actuation\nuncertainties to avoid potentially unsafe and costly mistakes that are a\nbarrier to their adoption. In this paper, we propose a flexible and\ngeneralisable physics-informed causal Bayesian network (CBN) based framework\nfor a robot to probabilistically reason about candidate manipulation actions,\nto enable robot decision-making robust to arbitrary robot system uncertainties\n-- the first of its kind to use a probabilistic programming language\nimplementation. Using experiments in high-fidelity Gazebo simulation of an\nexemplar block stacking task, we demonstrate our framework's ability to: (1)\npredict manipulation outcomes with high accuracy (Pred Acc: 88.6%); and, (2)\nperform greedy next-best action selection with 94.2% task success rate. We also\ndemonstrate our framework's suitability for real-world robot systems with a\ndomestic robot. Thus, we show that by combining probabilistic causal modelling\nwith physics simulations, we can make robot manipulation more robust to system\nuncertainties and hence more feasible for real-world applications. Further, our\ngeneralised reasoning framework can be used and extended for future robotics\nand causality research.",
      "tldr_zh": "该研究提出了一种基于Causal Bayesian Network (CBN) 和Probabilistic Programming的推理框架，用于机器人操作处理感知、估计和执行不确定性，从而提升决策鲁棒性。该框架结合物理模拟，允许机器人对候选操作进行概率推理，并在Gazebo模拟实验中实现88.6%的操作结果预测准确率和94.2%的任务成功率。通过在真实家用机器人上的验证，该框架证明了其在实际应用中的可行性，并为未来的机器人和因果性研究提供了一个可扩展的通用工具。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "stat.AP",
        "I.2.9; I.2.8; I.2.3; G.3; I.2.6; I.6.8; I.2.4; I.2.10"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 7 figures, submitted to the 2025 IEEE Conference on Robotics\n  and Automation (ICRA 2025)",
      "pdf_url": "http://arxiv.org/pdf/2403.14488v2",
      "published_date": "2024-03-21 15:36:26 UTC",
      "updated_date": "2024-10-03 14:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:36:47.027728"
    },
    {
      "arxiv_id": "2403.14484v1",
      "title": "HyperGALE: ASD Classification via Hypergraph Gated Attention with Learnable Hyperedges",
      "title_zh": "翻译失败",
      "authors": [
        "Mehul Arora",
        "Chirag Shantilal Jain",
        "Lalith Bharadwaj Baru",
        "Kamalaker Dadi",
        "Bapi Raju Surampudi"
      ],
      "abstract": "Autism Spectrum Disorder (ASD) is a neurodevelopmental condition\ncharacterized by varied social cognitive challenges and repetitive behavioral\npatterns. Identifying reliable brain imaging-based biomarkers for ASD has been\na persistent challenge due to the spectrum's diverse symptomatology. Existing\nbaselines in the field have made significant strides in this direction, yet\nthere remains room for improvement in both performance and interpretability. We\npropose \\emph{HyperGALE}, which builds upon the hypergraph by incorporating\nlearned hyperedges and gated attention mechanisms. This approach has led to\nsubstantial improvements in the model's ability to interpret complex brain\ngraph data, offering deeper insights into ASD biomarker characterization.\nEvaluated on the extensive ABIDE II dataset, \\emph{HyperGALE} not only improves\ninterpretability but also demonstrates statistically significant enhancements\nin key performance metrics compared to both previous baselines and the\nfoundational hypergraph model. The advancement \\emph{HyperGALE} brings to ASD\nresearch highlights the potential of sophisticated graph-based techniques in\nneurodevelopmental studies. The source code and implementation instructions are\navailable at GitHub:https://github.com/mehular0ra/HyperGALE.",
      "tldr_zh": "本研究针对自闭症谱系障碍 (ASD) 的分类问题，提出了一种名为 HyperGALE 的模型，该模型基于 hypergraph 结构，引入 learnable hyperedges 和 gated attention 机制，以提升对复杂脑图数据的解释能力和性能。相比现有基线模型，HyperGALE 在 ABIDE II 数据集上的评估中实现了关键性能指标的统计显著提升，提供更深入的 ASD 生物标志物洞察。总之，该方法突显了高级图-based 技术的潜力，并已在 GitHub 上开源代码以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IJCNN 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14484v1",
      "published_date": "2024-03-21 15:31:28 UTC",
      "updated_date": "2024-03-21 15:31:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:37:00.465981"
    },
    {
      "arxiv_id": "2403.14483v1",
      "title": "Utilizing the LightGBM Algorithm for Operator User Credit Assessment Research",
      "title_zh": "利用 LightGBM 算法进行运营商用户信用评估研究",
      "authors": [
        "Shaojie Li",
        "Xinqi Dong",
        "Danqing Ma",
        "Bo Dang",
        "Hengyi Zang",
        "Yulu Gong"
      ],
      "abstract": "Mobile Internet user credit assessment is an important way for communication\noperators to establish decisions and formulate measures, and it is also a\nguarantee for operators to obtain expected benefits. However, credit evaluation\nmethods have long been monopolized by financial industries such as banks and\ncredit. As supporters and providers of platform network technology and network\nresources, communication operators are also builders and maintainers of\ncommunication networks. Internet data improves the user's credit evaluation\nstrategy. This paper uses the massive data provided by communication operators\nto carry out research on the operator's user credit evaluation model based on\nthe fusion LightGBM algorithm. First, for the massive data related to user\nevaluation provided by operators, key features are extracted by data\npreprocessing and feature engineering methods, and a multi-dimensional feature\nset with statistical significance is constructed; then, linear regression,\ndecision tree, LightGBM, and other machine learning algorithms build multiple\nbasic models to find the best basic model; finally, integrates Averaging,\nVoting, Blending, Stacking and other integrated algorithms to refine multiple\nfusion models, and finally establish the most suitable fusion model for\noperator user evaluation.",
      "tldr_zh": "本研究探讨了通信运营商利用自身海量数据进行移动互联网用户信用评估，以提升决策和收益保障。论文首先通过数据预处理和特征工程提取关键特征，构建具有统计意义的多元特征集；然后，使用线性回归、决策树和LightGBM等机器学习算法构建多个基本模型，并选择最佳模型。最终，采用Averaging、Voting、Blending和Stacking等集成算法融合这些模型，建立了最适合运营商用户信用评估的融合LightGBM模型，从而优化了用户信用评价策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.ST"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14483v1",
      "published_date": "2024-03-21 15:29:24 UTC",
      "updated_date": "2024-03-21 15:29:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:37:10.812529"
    },
    {
      "arxiv_id": "2403.14472v5",
      "title": "Detoxifying Large Language Models via Knowledge Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Mengru Wang",
        "Ningyu Zhang",
        "Ziwen Xu",
        "Zekun Xi",
        "Shumin Deng",
        "Yunzhi Yao",
        "Qishen Zhang",
        "Linyi Yang",
        "Jindong Wang",
        "Huajun Chen"
      ],
      "abstract": "This paper investigates using knowledge editing techniques to detoxify Large\nLanguage Models (LLMs). We construct a benchmark, SafeEdit, which covers nine\nunsafe categories with various powerful attack prompts and equips comprehensive\nmetrics for systematic evaluation. We conduct experiments with several\nknowledge editing approaches, indicating that knowledge editing has the\npotential to detoxify LLMs with a limited impact on general performance\nefficiently. Then, we propose a simple yet effective baseline, dubbed\nDetoxifying with Intraoperative Neural Monitoring (DINM), to diminish the\ntoxicity of LLMs within a few tuning steps via only one instance. We further\nprovide an in-depth analysis of the internal mechanism for various detoxifying\napproaches, demonstrating that previous methods like SFT and DPO may merely\nsuppress the activations of toxic parameters, while DINM mitigates the toxicity\nof the toxic parameters to a certain extent, making permanent adjustments. We\nhope that these insights could shed light on future work of developing\ndetoxifying approaches and the underlying knowledge mechanisms of LLMs. Code\nand benchmark are available at https://github.com/zjunlp/EasyEdit.",
      "tldr_zh": "本论文探讨了通过知识编辑技术净化大型语言模型 (LLMs) 的方法，构建了一个名为 SafeEdit 的基准，涵盖九个不安全类别并提供全面评估指标。实验结果显示，多种知识编辑方法能高效减少 LLMs 的毒性，同时对模型的一般性能影响有限。作者提出一个简单有效的基线方法 Detoxifying with Intraoperative Neural Monitoring (DINM)，仅需少数调优步骤和一个实例即可显著降低毒性。进一步分析表明，与之前的 SFT 和 DPO 方法相比，DINM 能更彻底地缓解有毒参数的毒性，实现永久调整，从而为未来 LLMs 的净化策略和知识机制研究提供新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024. Project website: https://zjunlp.github.io/project/SafeEdit\n  Benchmark: https://huggingface.co/datasets/zjunlp/SafeEdit",
      "pdf_url": "http://arxiv.org/pdf/2403.14472v5",
      "published_date": "2024-03-21 15:18:30 UTC",
      "updated_date": "2024-05-28 09:11:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:37:23.871107"
    },
    {
      "arxiv_id": "2403.14469v1",
      "title": "ChatGPT Alternative Solutions: Large Language Models Survey",
      "title_zh": "ChatGPT 替代解决方案：大语言模型调查",
      "authors": [
        "Hanieh Alipour",
        "Nick Pendar",
        "Kohinoor Roy"
      ],
      "abstract": "In recent times, the grandeur of Large Language Models (LLMs) has not only\nshone in the realm of natural language processing but has also cast its\nbrilliance across a vast array of applications. This remarkable display of LLM\ncapabilities has ignited a surge in research contributions within this domain,\nspanning a diverse spectrum of topics. These contributions encompass\nadvancements in neural network architecture, context length enhancements, model\nalignment, training datasets, benchmarking, efficiency improvements, and more.\nRecent years have witnessed a dynamic synergy between academia and industry,\npropelling the field of LLM research to new heights. A notable milestone in\nthis journey is the introduction of ChatGPT, a powerful AI chatbot grounded in\nLLMs, which has garnered widespread societal attention. The evolving technology\nof LLMs has begun to reshape the landscape of the entire AI community,\npromising a revolutionary shift in the way we create and employ AI algorithms.\nGiven this swift-paced technical evolution, our survey embarks on a journey to\nencapsulate the recent strides made in the world of LLMs. Through an\nexploration of the background, key discoveries, and prevailing methodologies,\nwe offer an up-to-the-minute review of the literature. By examining multiple\nLLM models, our paper not only presents a comprehensive overview but also\ncharts a course that identifies existing challenges and points toward potential\nfuture research trajectories. This survey furnishes a well-rounded perspective\non the current state of generative AI, shedding light on opportunities for\nfurther exploration, enhancement, and innovation.",
      "tldr_zh": "这篇论文对 Large Language Models (LLMs) 进行了全面调查，探讨了这些模型作为 ChatGPT 替代方案的潜力，包括神经网络架构改进、上下文长度提升、模型对齐、训练数据集优化以及效率提升等关键进展。作者回顾了 LLMs 的背景、关键发现和现有方法，强调了学术与工业合作推动该领域快速发展，并分析了多个 LLM 模型的应用案例。最终，论文指出了当前挑战，如基准测试和性能瓶颈，并为未来生成式 AI 的探索和创新提供了潜在研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14469v1",
      "published_date": "2024-03-21 15:16:50 UTC",
      "updated_date": "2024-03-21 15:16:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:37:36.107091"
    },
    {
      "arxiv_id": "2403.14468v4",
      "title": "AnyV2V: A Tuning-Free Framework For Any Video-to-Video Editing Tasks",
      "title_zh": "AnyV2V：一种免调优框架，用于任意视频到视频编辑任务",
      "authors": [
        "Max Ku",
        "Cong Wei",
        "Weiming Ren",
        "Harry Yang",
        "Wenhu Chen"
      ],
      "abstract": "In the dynamic field of digital content creation using generative models,\nstate-of-the-art video editing models still do not offer the level of quality\nand control that users desire. Previous works on video editing either extended\nfrom image-based generative models in a zero-shot manner or necessitated\nextensive fine-tuning, which can hinder the production of fluid video edits.\nFurthermore, these methods frequently rely on textual input as the editing\nguidance, leading to ambiguities and limiting the types of edits they can\nperform. Recognizing these challenges, we introduce AnyV2V, a novel tuning-free\nparadigm designed to simplify video editing into two primary steps: (1)\nemploying an off-the-shelf image editing model to modify the first frame, (2)\nutilizing an existing image-to-video generation model to generate the edited\nvideo through temporal feature injection. AnyV2V can leverage any existing\nimage editing tools to support an extensive array of video editing tasks,\nincluding prompt-based editing, reference-based style transfer, subject-driven\nediting, and identity manipulation, which were unattainable by previous\nmethods. AnyV2V can also support any video length. Our evaluation shows that\nAnyV2V achieved CLIP-scores comparable to other baseline methods. Furthermore,\nAnyV2V significantly outperformed these baselines in human evaluations,\ndemonstrating notable improvements in visual consistency with the source video\nwhile producing high-quality edits across all editing tasks.",
      "tldr_zh": "该论文提出 AnyV2V，一种无需微调的框架，用于处理各种视频到视频编辑任务，解决现有模型在质量、控制和编辑多样性上的不足。该框架简化编辑过程为两个步骤：首先使用现成的图像编辑模型修改第一帧，然后通过 temporal feature injection 利用图像到视频生成模型创建编辑视频，从而支持 prompt-based editing、reference-based style transfer、subject-driven editing 和 identity manipulation 等任务，并适用于任意视频长度。实验结果显示，AnyV2V 的 CLIP-scores 与基线相当，但在人类评估中显著优于基线，提供更高的视觉一致性和编辑质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in Transactions on Machine Learning Research (TMLR 2024)\n  (11/2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.14468v4",
      "published_date": "2024-03-21 15:15:00 UTC",
      "updated_date": "2024-11-03 21:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:37:48.557558"
    },
    {
      "arxiv_id": "2403.14460v1",
      "title": "Towards Single-System Illusion in Software-Defined Vehicles -- Automated, AI-Powered Workflow",
      "title_zh": "翻译失败",
      "authors": [
        "Krzysztof Lebioda",
        "Viktor Vorobev",
        "Nenad Petrovic",
        "Fengjunjie Pan",
        "Vahid Zolfaghari",
        "Alois Knoll"
      ],
      "abstract": "We propose a novel model- and feature-based approach to development of\nvehicle software systems, where the end architecture is not explicitly defined.\nInstead, it emerges from an iterative process of search and optimization given\ncertain constraints, requirements and hardware architecture, while retaining\nthe property of single-system illusion, where applications run in a logically\nuniform environment. One of the key points of the presented approach is the\ninclusion of modern generative AI, specifically Large Language Models (LLMs),\nin the loop. With the recent advances in the field, we expect that the LLMs\nwill be able to assist in processing of requirements, generation of formal\nsystem models, as well as generation of software deployment specification and\ntest code. The resulting pipeline is automated to a large extent, with feedback\nbeing generated at each step.",
      "tldr_zh": "该研究提出了一种新型模型和特征驱动的方法，用于开发软件定义车辆(SDV)的软件系统，该方法通过迭代的搜索和优化过程生成最终架构，而非预先定义，确保在给定约束、要求和硬件架构下维持single-system illusion，即应用在逻辑上运行于统一环境。关键创新在于整合Large Language Models (LLMs)等生成式AI，帮助处理要求、生成正式系统模型、软件部署规范和测试代码。该自动化管道在每个步骤提供反馈，预期能显著提升开发效率和系统可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "D.2.1; D.2.2; D.2.4; I.2.7; I.2.2; I.7.0"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14460v1",
      "published_date": "2024-03-21 15:07:57 UTC",
      "updated_date": "2024-03-21 15:07:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:38:01.114919"
    },
    {
      "arxiv_id": "2403.14459v1",
      "title": "Multi-Level Explanations for Generative Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Monteiro Paes",
        "Dennis Wei",
        "Hyo Jin Do",
        "Hendrik Strobelt",
        "Ronny Luss",
        "Amit Dhurandhar",
        "Manish Nagireddy",
        "Karthikeyan Natesan Ramamurthy",
        "Prasanna Sattigeri",
        "Werner Geyer",
        "Soumya Ghosh"
      ],
      "abstract": "Perturbation-based explanation methods such as LIME and SHAP are commonly\napplied to text classification. This work focuses on their extension to\ngenerative language models. To address the challenges of text as output and\nlong text inputs, we propose a general framework called MExGen that can be\ninstantiated with different attribution algorithms. To handle text output, we\nintroduce the notion of scalarizers for mapping text to real numbers and\ninvestigate multiple possibilities. To handle long inputs, we take a\nmulti-level approach, proceeding from coarser levels of granularity to finer\nones, and focus on algorithms with linear scaling in model queries. We conduct\na systematic evaluation, both automated and human, of perturbation-based\nattribution methods for summarization and context-grounded question answering.\nThe results show that our framework can provide more locally faithful\nexplanations of generated outputs.",
      "tldr_zh": "本研究扩展了基于扰动（perturbation-based）的解释方法（如 LIME 和 SHAP），将其应用于生成式语言模型，提出一个通用框架 MExGen 以处理文本输出和长输入的挑战。框架引入 scalarizers 将文本映射为实数，并采用多级（multi-level）方法从粗粒度到细粒度进行解释，确保算法在模型查询上实现线性缩放。实验通过自动化和人工评估在摘要和基于上下文的问题回答任务上进行，结果表明 MExGen 能提供更本地忠诚（locally faithful）的输出解释。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14459v1",
      "published_date": "2024-03-21 15:06:14 UTC",
      "updated_date": "2024-03-21 15:06:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:38:13.642870"
    },
    {
      "arxiv_id": "2403.14443v1",
      "title": "Language Models Can Reduce Asymmetry in Information Markets",
      "title_zh": "语言模型可以减少信息市场中的不对称性",
      "authors": [
        "Nasim Rahaman",
        "Martin Weiss",
        "Manuel Wüthrich",
        "Yoshua Bengio",
        "Li Erran Li",
        "Chris Pal",
        "Bernhard Schölkopf"
      ],
      "abstract": "This work addresses the buyer's inspection paradox for information markets.\nThe paradox is that buyers need to access information to determine its value,\nwhile sellers need to limit access to prevent theft. To study this, we\nintroduce an open-source simulated digital marketplace where intelligent\nagents, powered by language models, buy and sell information on behalf of\nexternal participants. The central mechanism enabling this marketplace is the\nagents' dual capabilities: they not only have the capacity to assess the\nquality of privileged information but also come equipped with the ability to\nforget. This ability to induce amnesia allows vendors to grant temporary access\nto proprietary information, significantly reducing the risk of unauthorized\nretention while enabling agents to accurately gauge the information's relevance\nto specific queries or tasks. To perform well, agents must make rational\ndecisions, strategically explore the marketplace through generated sub-queries,\nand synthesize answers from purchased information. Concretely, our experiments\n(a) uncover biases in language models leading to irrational behavior and\nevaluate techniques to mitigate these biases, (b) investigate how price affects\ndemand in the context of informational goods, and (c) show that inspection and\nhigher budgets both lead to higher quality outcomes.",
      "tldr_zh": "这篇论文探讨了语言模型如何缓解信息市场的信息不对称问题，特别是买家的检查悖论，即买家需访问信息评估价值，而卖家需限制访问防止盗用。研究引入了一个开源模拟数字市场，使用语言模型驱动的智能代理，这些代理具备评估特权信息质量和“忘记”能力的功能，从而允许临时访问并减少盗用风险。实验结果显示，语言模型中的偏差会导致非理性行为，但通过缓解技术可以改善决策；此外，价格会影响信息商品需求，而增加检查和预算可显著提升结果质量。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT",
        "cs.LG",
        "cs.MA",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14443v1",
      "published_date": "2024-03-21 14:48:37 UTC",
      "updated_date": "2024-03-21 14:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:38:28.168252"
    },
    {
      "arxiv_id": "2403.14440v1",
      "title": "Analysing Diffusion Segmentation for Medical Images",
      "title_zh": "分析医疗图像的扩散分割",
      "authors": [
        "Mathias Öttl",
        "Siyuan Mei",
        "Frauke Wilm",
        "Jana Steenpass",
        "Matthias Rübner",
        "Arndt Hartmann",
        "Matthias Beckmann",
        "Peter Fasching",
        "Andreas Maier",
        "Ramona Erber",
        "Katharina Breininger"
      ],
      "abstract": "Denoising Diffusion Probabilistic models have become increasingly popular due\nto their ability to offer probabilistic modeling and generate diverse outputs.\nThis versatility inspired their adaptation for image segmentation, where\nmultiple predictions of the model can produce segmentation results that not\nonly achieve high quality but also capture the uncertainty inherent in the\nmodel. Here, powerful architectures were proposed for improving diffusion\nsegmentation performance. However, there is a notable lack of analysis and\ndiscussions on the differences between diffusion segmentation and image\ngeneration, and thorough evaluations are missing that distinguish the\nimprovements these architectures provide for segmentation in general from their\nbenefit for diffusion segmentation specifically. In this work, we critically\nanalyse and discuss how diffusion segmentation for medical images differs from\ndiffusion image generation, with a particular focus on the training behavior.\nFurthermore, we conduct an assessment how proposed diffusion segmentation\narchitectures perform when trained directly for segmentation. Lastly, we\nexplore how different medical segmentation tasks influence the diffusion\nsegmentation behavior and the diffusion process could be adapted accordingly.\nWith these analyses, we aim to provide in-depth insights into the behavior of\ndiffusion segmentation that allow for a better design and evaluation of\ndiffusion segmentation methods in the future.",
      "tldr_zh": "本研究分析了去噪扩散概率模型（Denoising Diffusion Probabilistic models）在医疗图像分割中的应用，强调其在提供概率建模和捕捉不确定性方面的优势，但指出现有架构缺乏对扩散分割与图像生成差异的深入讨论和全面评估。作者 critically 探讨了扩散分割的训练行为及其与图像生成的区别，并评估了这些架构在直接用于分割任务时的性能。最终，论文探讨了不同医疗分割任务对扩散过程的影响，并提出相应适应策略，以为未来扩散分割方法的設計和评估提供更深入的洞见。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14440v1",
      "published_date": "2024-03-21 14:45:54 UTC",
      "updated_date": "2024-03-21 14:45:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:38:37.294595"
    },
    {
      "arxiv_id": "2403.14435v1",
      "title": "Biased Binary Attribute Classifiers Ignore the Majority Classes",
      "title_zh": "偏差二元属性分类器忽略多数类",
      "authors": [
        "Xinyi Zhang",
        "Johanna Sophie Bieri",
        "Manuel Günther"
      ],
      "abstract": "To visualize the regions of interest that classifiers base their decisions\non, different Class Activation Mapping (CAM) methods have been developed.\nHowever, all of these techniques target categorical classifiers only, though\nmost real-world tasks are binary classification. In this paper, we extend\ngradient-based CAM techniques to work with binary classifiers and visualize the\nactive regions for binary facial attribute classifiers. When training an\nunbalanced binary classifier on an imbalanced dataset, it is well-known that\nthe majority class, i.e. the class with many training samples, is mostly\npredicted much better than minority class with few training instances. In our\nexperiments on the CelebA dataset, we verify these results, when training an\nunbalanced classifier to extract 40 facial attributes simultaneously. One would\nexpect that the biased classifier has learned to extract features mainly for\nthe majority classes and that the proportional energy of the activations mainly\nreside in certain specific regions of the image where the attribute is located.\nHowever, we find very little regular activation for samples of majority\nclasses, while the active regions for minority classes seem mostly reasonable\nand overlap with our expectations. These results suggest that biased\nclassifiers mainly rely on bias activation for majority classes. When training\na balanced classifier on the imbalanced data by employing attribute-specific\nclass weights, majority and minority classes are classified similarly well and\nshow expected activations for almost all attributes",
      "tldr_zh": "本研究扩展了 Class Activation Mapping (CAM) 方法，使其适用于二元分类器，以可视化面部属性分类器的激活区域。实验在 CelebA 数据集上显示，当使用不平衡数据集训练偏置二元分类器时，多数类（样本较多）的激活区域不规则，主要依赖于偏置激活，而少数类的激活区域更符合预期。论文发现，这种偏置导致分类器忽略了多数类的特征提取；然而，通过引入属性特定的类权重进行平衡训练，多数和少数类均能实现类似的良好分类性能，并显示出预期的激活模式。该工作揭示了二元分类器在不平衡数据中的行为偏置，为改进分类器设计提供了新洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14435v1",
      "published_date": "2024-03-21 14:41:58 UTC",
      "updated_date": "2024-03-21 14:41:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:38:50.608769"
    },
    {
      "arxiv_id": "2403.14432v1",
      "title": "On the continuity and smoothness of the value function in reinforcement learning and optimal control",
      "title_zh": "翻译失败",
      "authors": [
        "Hans Harder",
        "Sebastian Peitz"
      ],
      "abstract": "The value function plays a crucial role as a measure for the cumulative\nfuture reward an agent receives in both reinforcement learning and optimal\ncontrol. It is therefore of interest to study how similar the values of\nneighboring states are, i.e., to investigate the continuity of the value\nfunction. We do so by providing and verifying upper bounds on the value\nfunction's modulus of continuity. Additionally, we show that the value function\nis always H\\\"older continuous under relatively weak assumptions on the\nunderlying system and that non-differentiable value functions can be made\ndifferentiable by slightly \"disturbing\" the system.",
      "tldr_zh": "本文探讨了强化学习和最优控制中值函数（value function）的连续性和光滑性，重点分析相邻状态值之间的相似度。研究提供了值函数连续模数（modulus of continuity）的上界，并证明在相对弱假设下，值函数总是Hölder连续的。通过轻微“扰动”系统，作者展示了如何使非可微的值函数变得可微，从而为优化算法提供了潜在改进路径。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY",
        "37H99, 37N35, 93E03",
        "I.2.8"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14432v1",
      "published_date": "2024-03-21 14:39:28 UTC",
      "updated_date": "2024-03-21 14:39:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:39:03.791952"
    },
    {
      "arxiv_id": "2403.14429v1",
      "title": "Style-Extracting Diffusion Models for Semi-Supervised Histopathology Segmentation",
      "title_zh": "风格提取扩散模型用于半监督组织病理学分割",
      "authors": [
        "Mathias Öttl",
        "Frauke Wilm",
        "Jana Steenpass",
        "Jingna Qiu",
        "Matthias Rübner",
        "Arndt Hartmann",
        "Matthias Beckmann",
        "Peter Fasching",
        "Andreas Maier",
        "Ramona Erber",
        "Bernhard Kainz",
        "Katharina Breininger"
      ],
      "abstract": "Deep learning-based image generation has seen significant advancements with\ndiffusion models, notably improving the quality of generated images. Despite\nthese developments, generating images with unseen characteristics beneficial\nfor downstream tasks has received limited attention. To bridge this gap, we\npropose Style-Extracting Diffusion Models, featuring two conditioning\nmechanisms. Specifically, we utilize 1) a style conditioning mechanism which\nallows to inject style information of previously unseen images during image\ngeneration and 2) a content conditioning which can be targeted to a downstream\ntask, e.g., layout for segmentation. We introduce a trainable style encoder to\nextract style information from images, and an aggregation block that merges\nstyle information from multiple style inputs. This architecture enables the\ngeneration of images with unseen styles in a zero-shot manner, by leveraging\nstyles from unseen images, resulting in more diverse generations. In this work,\nwe use the image layout as target condition and first show the capability of\nour method on a natural image dataset as a proof-of-concept. We further\ndemonstrate its versatility in histopathology, where we combine prior knowledge\nabout tissue composition and unannotated data to create diverse synthetic\nimages with known layouts. This allows us to generate additional synthetic data\nto train a segmentation network in a semi-supervised fashion. We verify the\nadded value of the generated images by showing improved segmentation results\nand lower performance variability between patients when synthetic images are\nincluded during segmentation training. Our code will be made publicly available\nat [LINK].",
      "tldr_zh": "该论文提出了一种名为 Style-Extracting Diffusion Models 的新扩散模型框架，用于半监督组织病理学分割（semi-supervised histopathology segmentation）。该模型引入了两个条件机制：style conditioning 用于注入未见图像的风格信息，以及 content conditioning 用于针对下游任务如布局的控制，并通过可训练的 style encoder 和 aggregation block 合并多个风格输入，实现零-shot 生成更多样化的图像。作为概念验证，该方法先在自然图像数据集上展示效果，随后应用于组织病理学，利用组织组成知识和未标注数据生成合成图像。实验结果显示，加入这些合成数据后，分割网络的性能得到提升，包括更高的分割准确性和更低的患者间性能变异性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14429v1",
      "published_date": "2024-03-21 14:36:59 UTC",
      "updated_date": "2024-03-21 14:36:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:39:16.912815"
    },
    {
      "arxiv_id": "2403.14410v1",
      "title": "GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sanqing Qu",
        "Tianpei Zou",
        "Florian Röhrbein",
        "Cewu Lu",
        "Guang Chen",
        "Dacheng Tao",
        "Changjun Jiang"
      ],
      "abstract": "Deep neural networks often exhibit sub-optimal performance under covariate\nand category shifts. Source-Free Domain Adaptation (SFDA) presents a promising\nsolution to this dilemma, yet most SFDA approaches are restricted to closed-set\nscenarios. In this paper, we explore Source-Free Universal Domain Adaptation\n(SF-UniDA) aiming to accurately classify \"known\" data belonging to common\ncategories and segregate them from target-private \"unknown\" data. We propose a\nnovel Global and Local Clustering (GLC) technique, which comprises an adaptive\none-vs-all global clustering algorithm to discern between target classes,\ncomplemented by a local k-NN clustering strategy to mitigate negative transfer.\nDespite the effectiveness, the inherent closed-set source architecture leads to\nuniform treatment of \"unknown\" data, impeding the identification of distinct\n\"unknown\" categories. To address this, we evolve GLC to GLC++, integrating a\ncontrastive affinity learning strategy. We examine the superiority of GLC and\nGLC++ across multiple benchmarks and category shift scenarios. Remarkably, in\nthe most challenging open-partial-set scenarios, GLC and GLC++ surpass GATE by\n16.7% and 18.6% in H-score on VisDA, respectively. GLC++ enhances the novel\ncategory clustering accuracy of GLC by 4.3% in open-set scenarios on\nOffice-Home. Furthermore, the introduced contrastive learning strategy not only\nenhances GLC but also significantly facilitates existing methodologies.",
      "tldr_zh": "本研究探讨了 Source-Free Universal Domain Adaptation (SF-UniDA)，旨在处理深度神经网络在类别和协变量偏移下的性能问题，通过准确分类“已知”数据并分离“未知”数据。作者提出 Global and Local Clustering (GLC) 技术，包括自适应 one-vs-all 全局聚类和局部 k-NN 聚类，以区分目标类别并减少负转移。GLC++ 进一步整合 Contrastive Affinity Learning 策略，提升了对不同“未知”类别的识别能力。在多个基准测试中，GLC 和 GLC++ 在 VisDA 的 open-partial-set 场景中分别比 GATE 高 16.7% 和 18.6% 的 H-score；在 Office-Home 的 open-set 场景中，GLC++ 使新类别聚类准确率提高 4.3%。这项工作不仅提升了 GLC 的性能，还为现有方法提供了有效的对比学习增强。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This is a substantial extension of the CVPR 2023 paper \"Upcycling\n  Models under Domain and Category Shift\"",
      "pdf_url": "http://arxiv.org/pdf/2403.14410v1",
      "published_date": "2024-03-21 13:57:45 UTC",
      "updated_date": "2024-03-21 13:57:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:39:29.391790"
    },
    {
      "arxiv_id": "2403.14409v1",
      "title": "Locating and Mitigating Gender Bias in Large Language Models",
      "title_zh": "在大型语言模型中定位和缓解性别偏见",
      "authors": [
        "Yuchen Cai",
        "Ding Cao",
        "Rongxi Guo",
        "Yaqin Wen",
        "Guiquan Liu",
        "Enhong Chen"
      ],
      "abstract": "Large language models(LLM) are pre-trained on extensive corpora to learn\nfacts and human cognition which contain human preferences. However, this\nprocess can inadvertently lead to these models acquiring biases and stereotypes\nprevalent in society. Prior research has typically tackled the issue of bias\nthrough a one-dimensional perspective, concentrating either on locating or\nmitigating it. This limited perspective has created obstacles in facilitating\nresearch on bias to synergistically complement and progressively build upon one\nanother. In this study, we integrate the processes of locating and mitigating\nbias within a unified framework. Initially, we use causal mediation analysis to\ntrace the causal effects of different components' activation within a large\nlanguage model. Building on this, we propose the LSDM (Least Square Debias\nMethod), a knowledge-editing based method for mitigating gender bias in\noccupational pronouns, and compare it against two baselines on three gender\nbias datasets and seven knowledge competency test datasets. The experimental\nresults indicate that the primary contributors to gender bias are the bottom\nMLP modules acting on the last token of occupational pronouns and the top\nattention module acting on the final word in the sentence. Furthermore, LSDM\nmitigates gender bias in the model more effectively than the other baselines,\nwhile fully preserving the model's capabilities in all other aspects.",
      "tldr_zh": "本研究探讨了 Large Language Models (LLMs) 在训练过程中如何吸收社会性别偏见，并提出一个整合定位和缓解偏见的统一框架。研究者使用 causal mediation analysis 追踪偏见来源，发现性别偏见主要源于底层的 MLP modules 和顶层的 attention module。基于此，他们开发了 LSDM (Least Square Debias Method)，一种基于知识编辑的方法，在三个性别偏见数据集上与两个基线方法比较，结果显示 LSDM 更有效地减轻了偏见，同时保持了模型在七个知识能力测试数据集上的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14409v1",
      "published_date": "2024-03-21 13:57:43 UTC",
      "updated_date": "2024-03-21 13:57:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:39:40.171908"
    },
    {
      "arxiv_id": "2403.14403v2",
      "title": "Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity",
      "title_zh": "Adaptive-RAG：通过问题复杂度学习适应检索增强的大型语言模型",
      "authors": [
        "Soyeong Jeong",
        "Jinheon Baek",
        "Sukmin Cho",
        "Sung Ju Hwang",
        "Jong C. Park"
      ],
      "abstract": "Retrieval-Augmented Large Language Models (LLMs), which incorporate the\nnon-parametric knowledge from external knowledge bases into LLMs, have emerged\nas a promising approach to enhancing response accuracy in several tasks, such\nas Question-Answering (QA). However, even though there are various approaches\ndealing with queries of different complexities, they either handle simple\nqueries with unnecessary computational overhead or fail to adequately address\ncomplex multi-step queries; yet, not all user requests fall into only one of\nthe simple or complex categories. In this work, we propose a novel adaptive QA\nframework, that can dynamically select the most suitable strategy for\n(retrieval-augmented) LLMs from the simplest to the most sophisticated ones\nbased on the query complexity. Also, this selection process is operationalized\nwith a classifier, which is a smaller LM trained to predict the complexity\nlevel of incoming queries with automatically collected labels, obtained from\nactual predicted outcomes of models and inherent inductive biases in datasets.\nThis approach offers a balanced strategy, seamlessly adapting between the\niterative and single-step retrieval-augmented LLMs, as well as the no-retrieval\nmethods, in response to a range of query complexities. We validate our model on\na set of open-domain QA datasets, covering multiple query complexities, and\nshow that ours enhances the overall efficiency and accuracy of QA systems,\ncompared to relevant baselines including the adaptive retrieval approaches.\nCode is available at: https://github.com/starsuzi/Adaptive-RAG.",
      "tldr_zh": "本文提出 Adaptive-RAG 框架，通过查询复杂度学习适应 Retrieval-Augmented Large Language Models (LLMs)，以优化问答 (QA) 任务的响应准确性和效率。该框架使用一个训练好的小型语言模型分类器来预测查询的复杂度水平，该分类器基于自动收集的标签（如模型预测结果和数据集偏差）进行训练，并动态选择从无检索到迭代检索的策略。实验在多个开放域 QA 数据集上验证，显示 Adaptive-RAG 比现有基线方法提高了整体效率和准确性，同时避免了不必要的计算开销。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14403v2",
      "published_date": "2024-03-21 13:52:30 UTC",
      "updated_date": "2024-03-28 06:45:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:39:52.208547"
    },
    {
      "arxiv_id": "2403.14399v1",
      "title": "Building Accurate Translation-Tailored LLMs with Language Aware Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Changtong Zan",
        "Liang Ding",
        "Li Shen",
        "Yibing Zhen",
        "Weifeng Liu",
        "Dacheng Tao"
      ],
      "abstract": "Translation-tailored Large language models (LLMs) exhibit remarkable\ntranslation capabilities, even competing with supervised-trained commercial\ntranslation systems. However, off-target translation remains an unsolved\nproblem, especially for low-resource languages, hindering us from developing\naccurate LLMs-based translation models. To mitigate the off-target translation\nproblem and enhance the performance of LLMs on translation, recent works have\neither designed advanced prompting strategies to highlight the functionality of\ntranslation instructions or exploited the in-context learning ability of LLMs\nby feeding few-shot demonstrations. However, these methods essentially do not\nimprove LLM's ability to follow translation instructions, especially the\nlanguage direction information. In this work, we design a two-stage fine-tuning\nalgorithm to improve the instruction-following ability (especially the\ntranslation direction) of LLMs. Specifically, we first tune LLMs with the\nmaximum likelihood estimation loss on the translation dataset to elicit the\nbasic translation capabilities. In the second stage, we construct\ninstruction-conflicting samples by randomly replacing the translation\ndirections with a wrong one within the instruction, and then introduce an extra\nunlikelihood loss to learn those samples. Experiments on IWSLT and WMT\nbenchmarks upon the LLaMA model spanning 16 zero-shot directions show that,\ncompared to the competitive baseline -- translation-finetuned LLama, our method\ncould effectively reduce the off-target translation ratio (averagely -53.3\\%),\nthus improving translation quality with average +5.7 SacreBLEU and +16.4\nBLEURT. Analysis shows that our method could preserve the model's general task\nperformance on AlpacaEval. Code and models will be released at\n\\url{https://github.com/alphadl/LanguageAware_Tuning}.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在翻译任务中的 off-target translation 问题（尤其是低资源语言的语言方向信息），提出了一种两阶段微调算法，以提升模型遵循翻译指令的能力。具体地，第一阶段使用最大似然估计损失在翻译数据集上微调 LLMs 以激发基本翻译能力；第二阶段通过构建指令冲突样本（随机替换翻译方向）并引入 unlikelihood 损失，进一步强化模型的准确性。实验在 IWSLT 和 WMT 基准上使用 LLaMA 模型测试 16 个零样本方向，结果显示该方法平均降低了 53.3% 的 off-target 翻译比例，同时提升了翻译质量（SacreBLEU 平均 +5.7，BLEURT 平均 +16.4），并保持了模型在一般任务（如 AlpacaEval）上的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14399v1",
      "published_date": "2024-03-21 13:47:40 UTC",
      "updated_date": "2024-03-21 13:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:40:08.492855"
    },
    {
      "arxiv_id": "2403.15489v1",
      "title": "EEG decoding with conditional identification information",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Sun",
        "Jorg De Winne",
        "Paul Devos",
        "Dick Botteldooren"
      ],
      "abstract": "Decoding EEG signals is crucial for unraveling human brain and advancing\nbrain-computer interfaces. Traditional machine learning algorithms have been\nhindered by the high noise levels and inherent inter-person variations in EEG\nsignals. Recent advances in deep neural networks (DNNs) have shown promise,\nowing to their advanced nonlinear modeling capabilities. However, DNN still\nfaces challenge in decoding EEG samples of unseen individuals. To address this,\nthis paper introduces a novel approach by incorporating the conditional\nidentification information of each individual into the neural network, thereby\nenhancing model representation through the synergistic interaction of EEG and\npersonal traits. We test our model on the WithMe dataset and demonstrated that\nthe inclusion of these identifiers substantially boosts accuracy for both\nsubjects in the training set and unseen subjects. This enhancement suggests\npromising potential for improving for EEG interpretability and understanding of\nrelevant identification features.",
      "tldr_zh": "本文提出了一种新方法，用于改进 EEG 信号解码问题，通过将条件识别信息（conditional identification information）融入深度神经网络（DNNs）中，以应对 EEG 信号的高噪声和个体差异挑战。该方法通过 EEG 和个人特征的协同作用增强模型表示，从而提高了对训练集个体和未见过个体的解码准确率。在 WithMe 数据集上的实验显示，准确率显著提升，表明此方法有望增强 EEG 的可解释性和对相关识别特征的理解。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted by 6th International Conference on Advances in Signal\n  Processing and Artificial Intelligence (ASPAI' 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.15489v1",
      "published_date": "2024-03-21 13:38:59 UTC",
      "updated_date": "2024-03-21 13:38:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:40:19.272725"
    },
    {
      "arxiv_id": "2403.14736v2",
      "title": "NaNa and MiGu: Semantic Data Augmentation Techniques to Enhance Protein Classification in Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yi-Shan Lan",
        "Pin-Yu Chen",
        "Tsung-Yi Ho"
      ],
      "abstract": "Protein classification tasks are essential in drug discovery. Real-world\nprotein structures are dynamic, which will determine the properties of\nproteins. However, the existing machine learning methods, like ProNet (Wang et\nal., 2022a), only access limited conformational characteristics and protein\nside-chain features, leading to impractical protein structure and inaccuracy of\nprotein classes in their predictions. In this paper, we propose novel semantic\ndata augmentation methods, Novel Augmentation of New Node Attributes (NaNa),\nand Molecular Interactions and Geometric Upgrading (MiGu) to incorporate\nbackbone chemical and side-chain biophysical information into protein\nclassification tasks and a co-embedding residual learning framework.\nSpecifically, we leverage molecular biophysical, secondary structure, chemical\nbonds, and ionic features of proteins to facilitate protein classification\ntasks. Furthermore, our semantic augmentation methods and the co-embedding\nresidual learning framework can improve the performance of GIN (Xu et al.,\n2019) on EC and Fold datasets (Bairoch, 2000; Andreeva et al., 2007) by 16.41%\nand 11.33% respectively. Our code is available at\nhttps://github.com/r08b46009/Code_for_MIGU_NANA/tree/main.",
      "tldr_zh": "该论文针对蛋白质分类任务中现有机器学习方法的局限性（如ProNet仅考虑有限构象特征），提出两种语义数据增强技术：Novel Augmentation of New Node Attributes (NaNa)和Molecular Interactions and Geometric Upgrading (MiGu)。这些方法通过整合蛋白质的主链化学、侧链生物物理信息、二次结构、化学键和离子特征，并结合co-embedding residual learning框架，提升Graph Neural Networks在蛋白分类中的性能。实验结果显示，在EC and Fold数据集上，NaNa和MiGu使GIN模型的准确率分别提高16.41%和11.33%，为药物发现提供更可靠的工具。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14736v2",
      "published_date": "2024-03-21 13:27:57 UTC",
      "updated_date": "2024-03-26 05:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:40:33.510788"
    },
    {
      "arxiv_id": "2403.14381v2",
      "title": "Editing Knowledge Representation of Language Model via Rephrased Prefix Prompts",
      "title_zh": "通过重新表述的前缀提示编辑语言模型的知识表示",
      "authors": [
        "Yuchen Cai",
        "Ding Cao",
        "Rongxi Guo",
        "Yaqin Wen",
        "Guiquan Liu",
        "Enhong Chen"
      ],
      "abstract": "Neural language models (LMs) have been extensively trained on vast corpora to\nstore factual knowledge about various aspects of the world described in texts.\nCurrent technologies typically employ knowledge editing methods or specific\nprompts to modify LM outputs. However, existing knowledge editing methods are\ncostly and inefficient, struggling to produce appropriate text. Additionally,\nprompt engineering is opaque and requires significant effort to find suitable\nprompts. To address these issues, we introduce a new method called PSPEM\n(Prefix Soft Prompt Editing Method), that can be used for a lifetime with just\none training. It resolves the inefficiencies and generalizability issues in\nknowledge editing methods and overcomes the opacity of prompt engineering by\nautomatically seeking optimal soft prompts. Specifically, PSPEM utilizes a\nprompt encoder and an encoding converter to refine key information in prompts\nand uses prompt alignment techniques to guide model generation, ensuring text\nconsistency and adherence to the intended structure and content, thereby\nmaintaining an optimal balance between efficiency and accuracy. We have\nvalidated the effectiveness of PSPEM through knowledge editing and attribute\ninserting. On the COUNTERFACT dataset, PSPEM achieved nearly 100\\% editing\naccuracy and demonstrated the highest level of fluency. We further analyzed the\nsimilarities between PSPEM and original prompts and their impact on the model's\ninternals. The results indicate that PSPEM can serve as an alternative to\noriginal prompts, supporting the model in effective editing.",
      "tldr_zh": "该研究针对语言模型（LMs）的知识编辑问题，提出了一种高效方法PSPEM（Prefix Soft Prompt Editing Method），它只需一次训练即可长期使用，通过prompt encoder、encoding converter和prompt alignment techniques自动优化软提示，解决现有知识编辑方法的低效性和提示工程的不透明性。PSPEM能精炼提示中的关键信息，确保生成文本的一致性、结构和内容平衡，从而提高编辑准确性和模型泛化能力。在COUNTERFACT数据集上，PSPEM实现了近100%的编辑准确率和最高流畅度，并证明其可作为原提示的替代，支持有效知识编辑和属性插入。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19pages,3figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14381v2",
      "published_date": "2024-03-21 13:15:25 UTC",
      "updated_date": "2024-05-11 13:51:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:40:42.462283"
    },
    {
      "arxiv_id": "2403.14377v1",
      "title": "Knowledge-Enhanced Recommendation with User-Centric Subgraph Network",
      "title_zh": "基于用户中心子图网络的知识增强推荐",
      "authors": [
        "Guangyi Liu",
        "Quanming Yao",
        "Yongqi Zhang",
        "Lei Chen"
      ],
      "abstract": "Recommendation systems, as widely implemented nowadays on various platforms,\nrecommend relevant items to users based on their preferences. The classical\nmethods which rely on user-item interaction matrices has limitations,\nespecially in scenarios where there is a lack of interaction data for new\nitems. Knowledge graph (KG)-based recommendation systems have emerged as a\npromising solution. However, most KG-based methods adopt node embeddings, which\ndo not provide personalized recommendations for different users and cannot\ngeneralize well to the new items. To address these limitations, we propose\nKnowledge-enhanced User-Centric subgraph Network (KUCNet), a subgraph learning\napproach with graph neural network (GNN) for effective recommendation. KUCNet\nconstructs a U-I subgraph for each user-item pair that captures both the\nhistorical information of user-item interactions and the side information\nprovided in KG. An attention-based GNN is designed to encode the U-I subgraphs\nfor recommendation. Considering efficiency, the pruned user-centric computation\ngraph is further introduced such that multiple U-I subgraphs can be\nsimultaneously computed and that the size can be pruned by Personalized\nPageRank. Our proposed method achieves accurate, efficient, and interpretable\nrecommendations especially for new items. Experimental results demonstrate the\nsuperiority of KUCNet over state-of-the-art KG-based and collaborative\nfiltering (CF)-based methods.",
      "tldr_zh": "本研究针对传统推荐系统依赖用户-物品交互矩阵的局限性（如在新物品数据稀缺时的表现不佳），提出了一种基于知识图谱 (KG) 的改进方法：Knowledge-enhanced User-Centric subgraph Network (KUCNet)。KUCNet 通过为每个用户-物品对构建用户中心子图 (U-I subgraph)，结合历史交互数据和 KG 中的辅助信息，并使用注意力机制的图神经网络 (GNN) 进行编码，从而实现个性化和对新物品的良好泛化。为提高效率，该方法引入了修剪的用户中心计算图 (基于 Personalized PageRank)，实验结果显示 KUCNet 在准确性、效率和可解释性上优于现有的 KG-based 和协同过滤 (CF)-based 方法。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14377v1",
      "published_date": "2024-03-21 13:09:23 UTC",
      "updated_date": "2024-03-21 13:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:40:55.657807"
    },
    {
      "arxiv_id": "2403.14371v1",
      "title": "Loop Improvement: An Efficient Approach for Extracting Shared Features from Heterogeneous Data without Central Server",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Li",
        "Chu Kiong Loo",
        "Wei Shiung Liew",
        "Xiaofeng Liu"
      ],
      "abstract": "In federated learning, data heterogeneity significantly impacts performance.\nA typical solution involves segregating these parameters into shared and\npersonalized components, a concept also relevant in multi-task learning.\nAddressing this, we propose \"Loop Improvement\" (LI), a novel method enhancing\nthis separation and feature extraction without necessitating a central server\nor data interchange among participants. Our experiments reveal LI's superiority\nin several aspects: In personalized federated learning environments, LI\nconsistently outperforms the advanced FedALA algorithm in accuracy across\ndiverse scenarios. Additionally, LI's feature extractor closely matches the\nperformance achieved when aggregating data from all clients. In global model\ncontexts, employing LI with stacked personalized layers and an additional\nnetwork also yields comparable results to combined client data scenarios.\nFurthermore, LI's adaptability extends to multi-task learning, streamlining the\nextraction of common features across tasks and obviating the need for\nsimultaneous training. This approach not only enhances individual task\nperformance but also achieves accuracy levels on par with classic multi-task\nlearning methods where all tasks are trained simultaneously. LI integrates a\nloop topology with layer-wise and end-to-end training, compatible with various\nneural network models. This paper also delves into the theoretical\nunderpinnings of LI's effectiveness, offering insights into its potential\napplications. The code is on https://github.com/axedge1983/LI",
      "tldr_zh": "该研究提出了一种名为Loop Improvement (LI)的新方法，用于从异质数据中提取共享特征，而无需中央服务器或数据交换，旨在解决联邦学习(Federated Learning)中数据异质性对性能的影响。LI通过整合循环拓扑(loop topology)、层级训练和端到端训练，增强参数的共享和个性化分离，并兼容各种神经网络模型。实验结果显示，LI在个性化联邦学习环境中优于FedALA算法，在准确率上表现出色，且其特征提取器性能接近于聚合所有客户端数据的场景；在多任务学习中，LI能高效提取共同特征，无需同时训练任务，并实现与经典方法相当的准确率。该方法不仅提升了任务性能，还提供了理论基础和潜在应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14371v1",
      "published_date": "2024-03-21 12:59:24 UTC",
      "updated_date": "2024-03-21 12:59:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:41:07.101635"
    },
    {
      "arxiv_id": "2403.14358v1",
      "title": "Exploring the Potential of Large Language Models in Graph Generation",
      "title_zh": "探索大语言模型在图生成中的潜力",
      "authors": [
        "Yang Yao",
        "Xin Wang",
        "Zeyang Zhang",
        "Yijian Qin",
        "Ziwei Zhang",
        "Xu Chu",
        "Yuekui Yang",
        "Wenwu Zhu",
        "Hong Mei"
      ],
      "abstract": "Large language models (LLMs) have achieved great success in many fields, and\nrecent works have studied exploring LLMs for graph discriminative tasks such as\nnode classification. However, the abilities of LLMs for graph generation remain\nunexplored in the literature. Graph generation requires the LLM to generate\ngraphs with given properties, which has valuable real-world applications such\nas drug discovery, while tends to be more challenging. In this paper, we\npropose LLM4GraphGen to explore the ability of LLMs for graph generation with\nsystematical task designs and extensive experiments. Specifically, we propose\nseveral tasks tailored with comprehensive experiments to address key questions\nregarding LLMs' understanding of different graph structure rules, their ability\nto capture structural type distributions, and their utilization of domain\nknowledge for property-based graph generation. Our evaluations demonstrate that\nLLMs, particularly GPT-4, exhibit preliminary abilities in graph generation\ntasks, including rule-based and distribution-based generation. We also observe\nthat popular prompting methods, such as few-shot and chain-of-thought\nprompting, do not consistently enhance performance. Besides, LLMs show\npotential in generating molecules with specific properties. These findings may\nserve as foundations for designing good LLMs based models for graph generation\nand provide valuable insights and further research.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在图生成任务中的潜力，填补了现有研究主要关注图判别任务（如节点分类）的空白。作者提出了 LLM4GraphGen 框架，通过设计系统任务和实验，评估 LLMs 对图结构规则的理解、结构类型分布的捕捉以及利用领域知识进行属性-based 图生成的能力。结果显示，GPT-4 在规则和分布-based 图生成中表现出初步能力，但 few-shot 和 chain-of-thought prompting 方法并不一致地提升性能；此外，LLMs 在生成具有特定属性的分子方面显示潜力，为未来设计 LLMs-based 图生成模型提供了宝贵基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14358v1",
      "published_date": "2024-03-21 12:37:54 UTC",
      "updated_date": "2024-03-21 12:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:41:22.349020"
    },
    {
      "arxiv_id": "2403.14340v1",
      "title": "Exploring Task Unification in Graph Representation Learning via Generative Approach",
      "title_zh": "通过生成式方法探索图表示学习中的任务统一",
      "authors": [
        "Yulan Hu",
        "Sheng Ouyang",
        "Zhirui Yang",
        "Ge Chen",
        "Junchen Wan",
        "Xiao Wang",
        "Yong Liu"
      ],
      "abstract": "Graphs are ubiquitous in real-world scenarios and encompass a diverse range\nof tasks, from node-, edge-, and graph-level tasks to transfer learning.\nHowever, designing specific tasks for each type of graph data is often costly\nand lacks generalizability. Recent endeavors under the \"Pre-training +\nFine-tuning\" or \"Pre-training + Prompt\" paradigms aim to design a unified\nframework capable of generalizing across multiple graph tasks. Among these,\ngraph autoencoders (GAEs), generative self-supervised models, have demonstrated\ntheir potential in effectively addressing various graph tasks. Nevertheless,\nthese methods typically employ multi-stage training and require adaptive\ndesigns, which on one hand make it difficult to be seamlessly applied to\ndiverse graph tasks and on the other hand overlook the negative impact caused\nby discrepancies in task objectives between the different stages. To address\nthese challenges, we propose GA^2E, a unified adversarially masked autoencoder\ncapable of addressing the above challenges seamlessly. Specifically, GA^2E\nproposes to use the subgraph as the meta-structure, which remains consistent\nacross all graph tasks (ranging from node-, edge-, and graph-level to transfer\nlearning) and all stages (both during training and inference). Further, GA^2E\noperates in a \\textbf{\"Generate then Discriminate\"} manner. It leverages the\nmasked GAE to reconstruct the input subgraph whilst treating it as a generator\nto compel the reconstructed graphs resemble the input subgraph. Furthermore,\nGA^2E introduces an auxiliary discriminator to discern the authenticity between\nthe reconstructed (generated) subgraph and the input subgraph, thus ensuring\nthe robustness of the graph representation through adversarial training\nmechanisms. We validate GA^2E's capabilities through extensive experiments on\n21 datasets across four types of graph tasks.",
      "tldr_zh": "本研究探讨了通过生成式方法实现图表示学习中的任务统一问题，针对现有方法（如预训练+微调）的多阶段训练和任务目标不一致等问题，提出了一种统一的对抗性掩码自编码器GA^2E。GA^2E以子图作为元结构，确保在节点级、边级、图级任务以及转移学习中保持一致，并采用“Generate then Discriminate”的机制：先使用掩码自编码器重建子图，然后通过辅助判别器进行对抗训练，以提升图表示的鲁棒性和真实性。该方法在21个数据集上的广泛实验验证了其在四种图任务中的有效性，提供了一个无缝适配多任务的框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14340v1",
      "published_date": "2024-03-21 12:14:02 UTC",
      "updated_date": "2024-03-21 12:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:41:32.091757"
    },
    {
      "arxiv_id": "2403.14339v1",
      "title": "$\\nabla τ$: Gradient-based and Task-Agnostic machine Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Trippa",
        "Cesare Campagnano",
        "Maria Sofia Bucarelli",
        "Gabriele Tolomei",
        "Fabrizio Silvestri"
      ],
      "abstract": "Machine Unlearning, the process of selectively eliminating the influence of\ncertain data examples used during a model's training, has gained significant\nattention as a means for practitioners to comply with recent data protection\nregulations. However, existing unlearning methods face critical drawbacks,\nincluding their prohibitively high cost, often associated with a large number\nof hyperparameters, and the limitation of forgetting only relatively small data\nportions. This often makes retraining the model from scratch a quicker and more\neffective solution. In this study, we introduce Gradient-based and\nTask-Agnostic machine Unlearning ($\\nabla \\tau$), an optimization framework\ndesigned to remove the influence of a subset of training data efficiently. It\napplies adaptive gradient ascent to the data to be forgotten while using\nstandard gradient descent for the remaining data. $\\nabla \\tau$ offers multiple\nbenefits over existing approaches. It enables the unlearning of large sections\nof the training dataset (up to 30%). It is versatile, supporting various\nunlearning tasks (such as subset forgetting or class removal) and applicable\nacross different domains (images, text, etc.). Importantly, $\\nabla \\tau$\nrequires no hyperparameter adjustments, making it a more appealing option than\nretraining the model from scratch. We evaluate our framework's effectiveness\nusing a set of well-established Membership Inference Attack metrics,\ndemonstrating up to 10% enhancements in performance compared to\nstate-of-the-art methods without compromising the original model's accuracy.",
      "tldr_zh": "这篇论文提出了$\\nabla τ$，一种基于梯度的任务无关机器遗忘(Machine Unlearning)框架，用于高效消除模型训练中特定数据的影响，以符合数据保护法规。方法通过对要遗忘的数据应用自适应梯度上升(adaptive gradient ascent)，同时对剩余数据使用标准梯度下降(gradient descent)，从而实现高效优化。$\\nabla τ$的优势在于能遗忘高达30%的训练数据集，支持多种任务（如子集遗忘或类移除）和跨领域应用（如图像、文本），且无需调整超参数。实验结果显示，在Membership Inference Attack指标上，性能提升高达10%，而不降低原模型的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14339v1",
      "published_date": "2024-03-21 12:11:26 UTC",
      "updated_date": "2024-03-21 12:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:41:43.039716"
    },
    {
      "arxiv_id": "2403.14328v1",
      "title": "Distilling Reinforcement Learning Policies for Interpretable Robot Locomotion: Gradient Boosting Machines and Symbolic Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Fernando Acero",
        "Zhibin Li"
      ],
      "abstract": "Recent advancements in reinforcement learning (RL) have led to remarkable\nachievements in robot locomotion capabilities. However, the complexity and\n``black-box'' nature of neural network-based RL policies hinder their\ninterpretability and broader acceptance, particularly in applications demanding\nhigh levels of safety and reliability. This paper introduces a novel approach\nto distill neural RL policies into more interpretable forms using Gradient\nBoosting Machines (GBMs), Explainable Boosting Machines (EBMs) and Symbolic\nRegression. By leveraging the inherent interpretability of generalized additive\nmodels, decision trees, and analytical expressions, we transform opaque neural\nnetwork policies into more transparent ``glass-box'' models. We train expert\nneural network policies using RL and subsequently distill them into (i) GBMs,\n(ii) EBMs, and (iii) symbolic policies. To address the inherent distribution\nshift challenge of behavioral cloning, we propose to use the Dataset\nAggregation (DAgger) algorithm with a curriculum of episode-dependent\nalternation of actions between expert and distilled policies, to enable\nefficient distillation of feedback control policies. We evaluate our approach\non various robot locomotion gaits -- walking, trotting, bounding, and pacing --\nand study the importance of different observations in joint actions for\ndistilled policies using various methods. We train neural expert policies for\n205 hours of simulated experience and distill interpretable policies with only\n10 minutes of simulated interaction for each gait using the proposed method.",
      "tldr_zh": "本研究针对强化学习（RL）在机器人运动中的黑盒问题，提出一种提炼方法，将神经网络政策转化为更可解释的形式，使用 Gradient Boosting Machines (GBMs)、Explainable Boosting Machines (EBMs) 和 Symbolic Regression。方法涉及先训练专家神经网络政策，然后通过 Dataset Aggregation (DAgger) 算法结合课程学习，解决行为克隆中的分布偏移问题，从而高效提炼出透明的“玻璃盒”模型。实验在 walking、trotting、bounding 和 pacing 等步态上评估，展示了不同观察在联合动作中的重要性，并证明了该方法能将训练时间从 205 小时模拟经验缩短至每个步态仅 10 分钟交互。整体结果为可解释的机器人运动政策提供了可靠基础，提升了安全性与可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14328v1",
      "published_date": "2024-03-21 11:54:45 UTC",
      "updated_date": "2024-03-21 11:54:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:41:55.599303"
    },
    {
      "arxiv_id": "2403.14300v1",
      "title": "DexDribbler: Learning Dexterous Soccer Manipulation via Dynamic Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Yutong Hu",
        "Kehan Wen",
        "Fisher Yu"
      ],
      "abstract": "Learning dexterous locomotion policy for legged robots is becoming\nincreasingly popular due to its ability to handle diverse terrains and resemble\nintelligent behaviors. However, joint manipulation of moving objects and\nlocomotion with legs, such as playing soccer, receive scant attention in the\nlearning community, although it is natural for humans and smart animals. A key\nchallenge to solve this multitask problem is to infer the objectives of\nlocomotion from the states and targets of the manipulated objects. The implicit\nrelation between the object states and robot locomotion can be hard to capture\ndirectly from the training experience. We propose adding a feedback control\nblock to compute the necessary body-level movement accurately and using the\noutputs as dynamic joint-level locomotion supervision explicitly. We further\nutilize an improved ball dynamic model, an extended context-aided estimator,\nand a comprehensive ball observer to facilitate transferring policy learned in\nsimulation to the real world. We observe that our learning scheme can not only\nmake the policy network converge faster but also enable soccer robots to\nperform sophisticated maneuvers like sharp cuts and turns on flat surfaces, a\ncapability that was lacking in previous methods. Video and code are available\nat https://github.com/SysCV/soccer-player",
      "tldr_zh": "这篇论文提出DexDribbler框架，用于学习灵巧足球操控政策（dexterous soccer manipulation），以解决机器人同时处理移动物体操控和腿部运动的多任务挑战。核心方法包括添加反馈控制块（feedback control block）来计算必要的身体级运动，并将其作为动态监督（dynamic supervision）来显式指导关节级运动，同时利用改进的球动态模型、扩展的上下文辅助估计器和全面的球观察器，促进从模拟到现实的策略转移。实验结果表明，该方案加速了政策网络的收敛，并使足球机器人能够执行复杂的操作，如急转弯和急停，提升了整体性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 7 figures, submitted to IROS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14300v1",
      "published_date": "2024-03-21 11:16:28 UTC",
      "updated_date": "2024-03-21 11:16:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:42:10.438782"
    },
    {
      "arxiv_id": "2403.14298v1",
      "title": "From Perils to Possibilities: Understanding how Human (and AI) Biases affect Online Fora",
      "title_zh": "翻译失败",
      "authors": [
        "Virginia Morini",
        "Valentina Pansanella",
        "Katherine Abramski",
        "Erica Cau",
        "Andrea Failla",
        "Salvatore Citraro",
        "Giulio Rossetti"
      ],
      "abstract": "Social media platforms are online fora where users engage in discussions,\nshare content, and build connections. This review explores the dynamics of\nsocial interactions, user-generated contents, and biases within the context of\nsocial media analysis (analyzing works that use the tools offered by complex\nnetwork analysis and natural language processing) through the lens of three key\npoints of view: online debates, online support, and human-AI interactions. On\nthe one hand, we delineate the phenomenon of online debates, where\npolarization, misinformation, and echo chamber formation often proliferate,\ndriven by algorithmic biases and extreme mechanisms of homophily. On the other\nhand, we explore the emergence of online support groups through users'\nself-disclosure and social support mechanisms. Online debates and support\nmechanisms present a duality of both perils and possibilities within social\nmedia; perils of segregated communities and polarized debates, and\npossibilities of empathy narratives and self-help groups. This dichotomy also\nextends to a third perspective: users' reliance on AI-generated content, such\nas the ones produced by Large Language Models, which can manifest both human\nbiases hidden in training sets and non-human biases that emerge from their\nartificial neural architectures. Analyzing interdisciplinary approaches, we aim\nto deepen the understanding of the complex interplay between social\ninteractions, user-generated content, and biases within the realm of social\nmedia ecosystems.",
      "tldr_zh": "这篇评论文章探讨了社交媒体平台上的人类和AI偏见如何影响在线论坛（Online Fora），通过复杂网络分析和自然语言处理工具审视社会互动和用户生成内容。文章从三个关键视角——在线辩论（Online Debates）、在线支持和人类-AI 互动——分析了这些偏见的双重性：在在线辩论中，算法偏见（Algorithmic Biases）和同质性机制（Homophily）可能导致极化、误传和回音室（Echo Chamber）形成，而在线支持则提供移情叙述和自助群体的可能性。论文进一步指出，AI 生成内容如Large Language Models的输出，可能放大隐藏在训练集中的人类偏见或源于神经架构的非人类偏见，从而加深了对社交媒体生态中社会互动与偏见复杂互动的理解。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14298v1",
      "published_date": "2024-03-21 11:04:41 UTC",
      "updated_date": "2024-03-21 11:04:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:42:22.041578"
    },
    {
      "arxiv_id": "2403.14297v2",
      "title": "Impact Assessment of Missing Data in Model Predictions for Earth Observation Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Mena",
        "Diego Arenas",
        "Marcela Charfuelan",
        "Marlon Nuske",
        "Andreas Dengel"
      ],
      "abstract": "Earth observation (EO) applications involving complex and heterogeneous data\nsources are commonly approached with machine learning models. However, there is\na common assumption that data sources will be persistently available. Different\nsituations could affect the availability of EO sources, like noise, clouds, or\nsatellite mission failures. In this work, we assess the impact of missing\ntemporal and static EO sources in trained models across four datasets with\nclassification and regression tasks. We compare the predictive quality of\ndifferent methods and find that some are naturally more robust to missing data.\nThe Ensemble strategy, in particular, achieves a prediction robustness up to\n100%. We evidence that missing scenarios are significantly more challenging in\nregression than classification tasks. Finally, we find that the optical view is\nthe most critical view when it is missing individually.",
      "tldr_zh": "这篇论文评估了在地球观测（Earth Observation）应用中，数据缺失（如噪声、云层或卫星故障）对机器学习模型预测的影响，涉及四个数据集的分类和回归任务。研究比较了不同方法的预测质量，发现Ensemble策略对缺失数据具有高度鲁棒性，可实现高达100%的预测稳定性。结果显示，回归任务比分类任务更易受数据缺失影响，而光学视图（optical view）的缺失被证明是最关键的单一因素。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IEEE International Geoscience and Remote Sensing\n  Symposium 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14297v2",
      "published_date": "2024-03-21 11:03:56 UTC",
      "updated_date": "2024-05-13 09:29:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:42:33.206262"
    },
    {
      "arxiv_id": "2403.14287v1",
      "title": "Enhancing Historical Image Retrieval with Compositional Cues",
      "title_zh": "翻译失败",
      "authors": [
        "Tingyu Lin",
        "Robert Sablatnig"
      ],
      "abstract": "In analyzing vast amounts of digitally stored historical image data, existing\ncontent-based retrieval methods often overlook significant non-semantic\ninformation, limiting their effectiveness for flexible exploration across\nvaried themes. To broaden the applicability of image retrieval methods for\ndiverse purposes and uncover more general patterns, we innovatively introduce a\ncrucial factor from computational aesthetics, namely image composition, into\nthis topic. By explicitly integrating composition-related information extracted\nby CNN into the designed retrieval model, our method considers both the image's\ncomposition rules and semantic information. Qualitative and quantitative\nexperiments demonstrate that the image retrieval network guided by composition\ninformation outperforms those relying solely on content information,\nfacilitating the identification of images in databases closer to the target\nimage in human perception. Please visit https://github.com/linty5/CCBIR to try\nour codes.",
      "tldr_zh": "本研究针对历史图像检索中的问题，提出了一种方法，通过整合图像构图（image composition）信息来弥补现有内容-based检索方法忽略非语义信息的不足。该方法利用CNN提取构图相关信息，并将其与图像的语义信息结合，构建了一个更全面的检索模型。实验结果显示，该模型在定性和定量评估中均优于仅依赖内容信息的基线模型，能更准确地识别与人类感知相符的图像。更多细节可参考GitHub仓库（https://github.com/linty5/CCBIR）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14287v1",
      "published_date": "2024-03-21 10:51:19 UTC",
      "updated_date": "2024-03-21 10:51:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:42:47.446879"
    },
    {
      "arxiv_id": "2403.14282v1",
      "title": "How to be fair? A study of label and selection bias",
      "title_zh": "如何做到公平？ 标签偏差和选择偏差的研究",
      "authors": [
        "Marco Favier",
        "Toon Calders",
        "Sam Pinxteren",
        "Jonathan Meyer"
      ],
      "abstract": "It is widely accepted that biased data leads to biased and thus potentially\nunfair models. Therefore, several measures for bias in data and model\npredictions have been proposed, as well as bias mitigation techniques whose aim\nis to learn models that are fair by design. Despite the myriad of mitigation\ntechniques developed in the past decade, however, it is still poorly understood\nunder what circumstances which methods work. Recently, Wick et al. showed, with\nexperiments on synthetic data, that there exist situations in which bias\nmitigation techniques lead to more accurate models when measured on unbiased\ndata. Nevertheless, in the absence of a thorough mathematical analysis, it\nremains unclear which techniques are effective under what circumstances. We\npropose to address this problem by establishing relationships between the type\nof bias and the effectiveness of a mitigation technique, where we categorize\nthe mitigation techniques by the bias measure they optimize. In this paper we\nillustrate this principle for label and selection bias on the one hand, and\ndemographic parity and ``We're All Equal'' on the other hand. Our theoretical\nanalysis allows to explain the results of Wick et al. and we also show that\nthere are situations where minimizing fairness measures does not result in the\nfairest possible distribution.",
      "tldr_zh": "本研究探讨了 label and selection bias 如何导致模型偏置和不公平问题，并分析了不同偏置缓解技术的有效性。作者通过理论分析，建立偏置类型（如 label and selection bias）与优化措施（如 demographic parity 和 \"We're All Equal\"）之间的关系，解释了 Wick et al. 的实验结果，即某些缓解技术能在无偏置数据上提升模型准确性。研究进一步发现，在特定情况下，最小化公平性指标并不总是产生最公平的分布，从而为选择合适的技术提供了指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14282v1",
      "published_date": "2024-03-21 10:43:55 UTC",
      "updated_date": "2024-03-21 10:43:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:42:57.875162"
    },
    {
      "arxiv_id": "2403.14274v4",
      "title": "Multi-role Consensus through LLMs Discussions for Vulnerability Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Mao",
        "Jialong Li",
        "Dongming Jin",
        "Munan Li",
        "Kenji Tei"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have highlighted the\npotential for vulnerability detection, a crucial component of software quality\nassurance. Despite this progress, most studies have been limited to the\nperspective of a single role, usually testers, lacking diverse viewpoints from\ndifferent roles in a typical software development life-cycle, including both\ndevelopers and testers. To this end, this paper introduces a multi-role\napproach to employ LLMs to act as different roles simulating a real-life code\nreview process and engaging in discussions toward a consensus on the existence\nand classification of vulnerabilities in the code. Preliminary evaluation of\nthis approach indicates a 13.48% increase in the precision rate, an 18.25%\nincrease in the recall rate, and a 16.13% increase in the F1 score.",
      "tldr_zh": "这篇论文提出了一种多角色共识方法，利用 LLMs 模拟软件开发过程中的不同角色（如开发者和测试人员）进行讨论，以检测和分类代码中的漏洞，从而弥补传统单一视角的局限。方法通过模仿真实代码审查过程，促使角色间达成共识，提高漏洞识别的准确性。初步评估显示，该方法相比基线模型，精度提高了 13.48%、召回率提高了 18.25%、F1 分数提高了 16.13%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14274v4",
      "published_date": "2024-03-21 10:28:18 UTC",
      "updated_date": "2024-05-18 14:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:43:10.870126"
    },
    {
      "arxiv_id": "2403.14273v1",
      "title": "Reactor Optimization Benchmark by Reinforcement Learning",
      "title_zh": "基于强化学习的反应堆优化基准",
      "authors": [
        "Deborah Schwarcz",
        "Nadav Schneider",
        "Gal Oren",
        "Uri Steinitz"
      ],
      "abstract": "Neutronic calculations for reactors are a daunting task when using Monte\nCarlo (MC) methods. As high-performance computing has advanced, the simulation\nof a reactor is nowadays more readily done, but design and optimization with\nmultiple parameters is still a computational challenge. MC transport\nsimulations, coupled with machine learning techniques, offer promising avenues\nfor enhancing the efficiency and effectiveness of nuclear reactor optimization.\nThis paper introduces a novel benchmark problem within the OpenNeoMC framework\ndesigned specifically for reinforcement learning. The benchmark involves\noptimizing a unit cell of a research reactor with two varying parameters (fuel\ndensity and water spacing) to maximize neutron flux while maintaining reactor\ncriticality. The test case features distinct local optima, representing\ndifferent physical regimes, thus posing a challenge for learning algorithms.\nThrough extensive simulations utilizing evolutionary and neuroevolutionary\nalgorithms, we demonstrate the effectiveness of reinforcement learning in\nnavigating complex optimization landscapes with strict constraints.\nFurthermore, we propose acceleration techniques within the OpenNeoMC framework,\nincluding model updating and cross-section usage by RAM utilization, to\nexpedite simulation times. Our findings emphasize the importance of machine\nlearning integration in reactor optimization and contribute to advancing\nmethodologies for addressing intricate optimization challenges in nuclear\nengineering. The sources of this work are available at our GitHub repository:\nhttps://github.com/Scientific-Computing-Lab-NRCN/RLOpenNeoMC",
      "tldr_zh": "这篇论文引入了一个新的基准问题，使用强化学习(Reinforcement Learning)优化核反应堆设计，针对Monte Carlo (MC)方法的计算挑战，旨在最大化neutron flux同时保持reactor criticality。基准基于OpenNeoMC框架，涉及两个参数（燃料密度和水间距），并设计了多个局部最优解来测试算法性能。通过进化算法和神经进化算法的模拟，论文证明了强化学习在处理复杂优化景观和严格约束方面的有效性。此外，提出加速技术，如模型更新和RAM利用的cross-section，以缩短模拟时间，并强调了机器学习在核工程优化中的重要作用。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14273v1",
      "published_date": "2024-03-21 10:26:47 UTC",
      "updated_date": "2024-03-21 10:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:43:24.001437"
    },
    {
      "arxiv_id": "2405.01556v1",
      "title": "Semantically Aligned Question and Code Generation for Automated Insight Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ananya Singha",
        "Bhavya Chopra",
        "Anirudh Khatry",
        "Sumit Gulwani",
        "Austin Z. Henley",
        "Vu Le",
        "Chris Parnin",
        "Mukul Singh",
        "Gust Verbruggen"
      ],
      "abstract": "Automated insight generation is a common tactic for helping knowledge\nworkers, such as data scientists, to quickly understand the potential value of\nnew and unfamiliar data. Unfortunately, automated insights produced by\nlarge-language models can generate code that does not correctly correspond (or\nalign) to the insight. In this paper, we leverage the semantic knowledge of\nlarge language models to generate targeted and insightful questions about data\nand the corresponding code to answer those questions. Then through an empirical\nstudy on data from Open-WikiTable, we show that embeddings can be effectively\nused for filtering out semantically unaligned pairs of question and code.\nAdditionally, we found that generating questions and code together yields more\ndiverse questions.",
      "tldr_zh": "本论文针对大语言模型(large-language models)在自动洞察生成中，代码与洞察不匹配的问题，提出一种利用语义知识生成针对数据的问题和对应代码的方法。研究通过对 Open-WikiTable 数据的实证实验，证明 embeddings 可以有效过滤语义不匹配的问题和代码对，从而提高洞察的准确性。此外，发现同时生成问题和代码能产生更多样的问题，提升整体洞察生成的效果。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01556v1",
      "published_date": "2024-03-21 10:01:05 UTC",
      "updated_date": "2024-03-21 10:01:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:43:34.941928"
    },
    {
      "arxiv_id": "2403.14264v1",
      "title": "A Framework for Portrait Stylization with Skin-Tone Awareness and Nudity Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Seungkwon Kim",
        "Sangyeon Kim",
        "Seung-Hun Nam"
      ],
      "abstract": "Portrait stylization is a challenging task involving the transformation of an\ninput portrait image into a specific style while preserving its inherent\ncharacteristics. The recent introduction of Stable Diffusion (SD) has\nsignificantly improved the quality of outcomes in this field. However, a\npractical stylization framework that can effectively filter harmful input\ncontent and preserve the distinct characteristics of an input, such as\nskin-tone, while maintaining the quality of stylization remains lacking. These\nchallenges have hindered the wide deployment of such a framework. To address\nthese issues, this study proposes a portrait stylization framework that\nincorporates a nudity content identification module (NCIM) and a\nskin-tone-aware portrait stylization module (STAPSM). In experiments, NCIM\nshowed good performance in enhancing explicit content filtering, and STAPSM\naccurately represented a diverse range of skin tones. Our proposed framework\nhas been successfully deployed in practice, and it has effectively satisfied\ncritical requirements of real-world applications.",
      "tldr_zh": "本研究提出一个针对人像风格化的框架，利用 Stable Diffusion (SD) 技术，解决有害内容过滤和皮肤色调保留的挑战。框架包括 Nudity Content Identification Module (NCIM) 用于有效识别裸露内容，以及 Skin-Tone-Aware Portrait Stylization Module (STAPSM) 确保风格化过程中准确保持输入图像的皮肤色调多样性。实验结果显示，NCIM 显著提升了显式内容过滤性能，而 STAPSM 成功处理多种皮肤色调，该框架已在实际应用中部署并满足了真实世界需求。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14264v1",
      "published_date": "2024-03-21 09:59:53 UTC",
      "updated_date": "2024-03-21 09:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:43:47.181908"
    },
    {
      "arxiv_id": "2403.14252v1",
      "title": "LayoutLLM: Large Language Model Instruction Tuning for Visually Rich Document Understanding",
      "title_zh": "LayoutLLM：用于视觉丰富",
      "authors": [
        "Masato Fujitake"
      ],
      "abstract": "This paper proposes LayoutLLM, a more flexible document analysis method for\nunderstanding imaged documents. Visually Rich Document Understanding tasks,\nsuch as document image classification and information extraction, have gained\nsignificant attention due to their importance. Existing methods have been\ndeveloped to enhance document comprehension by incorporating pre-training\nawareness of images, text, and layout structure. However, these methods require\nfine-tuning for each task and dataset, and the models are expensive to train\nand operate. To overcome this limitation, we propose a new LayoutLLM that\nintegrates these with large-scale language models (LLMs). By leveraging the\nstrengths of existing research in document image understanding and LLMs'\nsuperior language understanding capabilities, the proposed model, fine-tuned\nwith multimodal instruction datasets, performs an understanding of document\nimages in a single model. Our experiments demonstrate improvement over the\nbaseline model in various document analysis tasks.",
      "tldr_zh": "本论文提出 LayoutLLM，一种基于 Large Language Model (LLM) 的指令微调方法，旨在提升 Visually Rich Document Understanding，例如文档图像分类和信息提取。LayoutLLM 整合了图像、文本和布局结构的理解优势，通过利用多模态指令数据集进行单一模型微调，克服了传统方法需针对每个任务和数据集重复训练的局限性。实验结果显示，该模型在各种文档分析任务中比基线模型性能显著提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14252v1",
      "published_date": "2024-03-21 09:25:24 UTC",
      "updated_date": "2024-03-21 09:25:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:43:58.024749"
    },
    {
      "arxiv_id": "2403.14246v1",
      "title": "CATSE: A Context-Aware Framework for Causal Target Sound Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Shrishail Baligar",
        "Mikolaj Kegler",
        "Bryce Irvin",
        "Marko Stamenovic",
        "Shawn Newsam"
      ],
      "abstract": "Target Sound Extraction (TSE) focuses on the problem of separating sources of\ninterest, indicated by a user's cue, from the input mixture. Most existing\nsolutions operate in an offline fashion and are not suited to the low-latency\ncausal processing constraints imposed by applications in live-streamed content\nsuch as augmented hearing. We introduce a family of context-aware low-latency\ncausal TSE models suitable for real-time processing. First, we explore the\nutility of context by providing the TSE model with oracle information about\nwhat sound classes make up the input mixture, where the objective of the model\nis to extract one or more sources of interest indicated by the user. Since the\npractical applications of oracle models are limited due to their assumptions,\nwe introduce a composite multi-task training objective involving separation and\nclassification losses. Our evaluation involving single- and multi-source\nextraction shows the benefit of using context information in the model either\nby means of providing full context or via the proposed multi-task training loss\nwithout the need for full context information. Specifically, we show that our\nproposed model outperforms size- and latency-matched Waveformer, a\nstate-of-the-art model for real-time TSE.",
      "tldr_zh": "本论文针对 Target Sound Extraction (TSE) 的低延迟实时处理挑战，提出了一种上下文感知框架 CATSE，旨在从输入混合中分离用户指定的感兴趣来源。CATSE 通过提供声音类别上下文或采用复合多任务训练（结合分离损失和分类损失），实现高效的因果模型，而无需依赖预言式信息。实验评估显示，该框架在单源和多源提取任务中，显著优于同尺寸和延迟的 Waveformer 模型，证明了上下文信息对提升 TSE 性能的益处。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Submitted to EUSIPCO 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14246v1",
      "published_date": "2024-03-21 09:06:28 UTC",
      "updated_date": "2024-03-21 09:06:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:44:13.611874"
    },
    {
      "arxiv_id": "2403.14244v1",
      "title": "Isotropic Gaussian Splatting for Real-Time Radiance Field Rendering",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanhao Gong",
        "Lantao Yu",
        "Guanghui Yue"
      ],
      "abstract": "The 3D Gaussian splatting method has drawn a lot of attention, thanks to its\nhigh performance in training and high quality of the rendered image. However,\nit uses anisotropic Gaussian kernels to represent the scene. Although such\nanisotropic kernels have advantages in representing the geometry, they lead to\ndifficulties in terms of computation, such as splitting or merging two kernels.\nIn this paper, we propose to use isotropic Gaussian kernels to avoid such\ndifficulties in the computation, leading to a higher performance method. The\nexperiments confirm that the proposed method is about {\\bf 100X} faster without\nlosing the geometry representation accuracy. The proposed method can be applied\nin a large range applications where the radiance field is needed, such as 3D\nreconstruction, view synthesis, and dynamic object modeling.",
      "tldr_zh": "该论文针对现有的3D Gaussian Splatting方法中使用的anisotropic Gaussian kernels导致的计算困难（如内核分割或合并），提出了一种基于isotropic Gaussian kernels的改进方案，以提升实时radiance field渲染的性能。实验结果显示，该方法比传统方法快约100倍，同时保持了几何表示的准确性。该方法适用于多种应用场景，包括3D reconstruction、view synthesis和dynamic object modeling等领域。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14244v1",
      "published_date": "2024-03-21 09:02:31 UTC",
      "updated_date": "2024-03-21 09:02:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:44:23.227060"
    },
    {
      "arxiv_id": "2403.14243v1",
      "title": "Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large Language Models with Machine Learning in tele-dermatology",
      "title_zh": "翻译失败",
      "authors": [
        "Dimitrios P. Panagoulias",
        "Evridiki Tsoureli-Nikita",
        "Maria Virvou",
        "George A. Tsihrintzis"
      ],
      "abstract": "The rise of Artificial Intelligence creates great promise in the field of\nmedical discovery, diagnostics and patient management. However, the vast\ncomplexity of all medical domains require a more complex approach that combines\nmachine learning algorithms, classifiers, segmentation algorithms and, lately,\nlarge language models. In this paper, we describe, implement and assess an\nArtificial Intelligence-empowered system and methodology aimed at assisting the\ndiagnosis process of skin lesions and other skin conditions within the field of\ndermatology that aims to holistically address the diagnostic process in this\ndomain. The workflow integrates large language, transformer-based vision models\nand sophisticated machine learning tools. This holistic approach achieves a\nnuanced interpretation of dermatological conditions that simulates and\nfacilitates a dermatologist's workflow. We assess our proposed methodology\nthrough a thorough cross-model validation technique embedded in an evaluation\npipeline that utilizes publicly available medical case studies of skin\nconditions and relevant images. To quantitatively score the system performance,\nadvanced machine learning and natural language processing tools are employed\nwhich focus on similarity comparison and natural language inference.\nAdditionally, we incorporate a human expert evaluation process based on a\nstructured checklist to further validate our results. We implemented the\nproposed methodology in a system which achieved approximate (weighted) scores\nof 0.87 for both contextual understanding and diagnostic accuracy,\ndemonstrating the efficacy of our approach in enhancing dermatological\nanalysis. The proposed methodology is expected to prove useful in the\ndevelopment of next-generation tele-dermatology applications, enhancing remote\nconsultation capabilities and access to care, especially in underserved areas.",
      "tldr_zh": "本研究提出了一种名为 Dermacen Analytica 的新型方法，旨在通过整合 Multi-Modal Large Language Models、transformer-based 视觉模型和机器学习工具，辅助远程皮肤病学（tele-dermatology）中的皮肤病变诊断。该方法模拟皮肤科医生的诊断流程，提供全面的皮肤条件解读，并通过交叉模型验证、相似性比较、自然语言推理和人类专家评估进行评估。实验结果显示，该系统在上下文理解和诊断准确性上均达到约 0.87 的加权分数，显著提升了诊断效能。该方法有望应用于下一代远程皮肤病学应用中，提高欠发达地区的医疗访问和咨询能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14243v1",
      "published_date": "2024-03-21 09:02:17 UTC",
      "updated_date": "2024-03-21 09:02:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:44:36.042910"
    },
    {
      "arxiv_id": "2403.14238v1",
      "title": "Reinforcement Learning from Reflective Feedback (RLRF): Aligning and Improving LLMs via Fine-Grained Self-Reflection",
      "title_zh": "翻译失败",
      "authors": [
        "Kyungjae Lee",
        "Dasol Hwang",
        "Sunghyun Park",
        "Youngsoo Jang",
        "Moontae Lee"
      ],
      "abstract": "Despite the promise of RLHF in aligning LLMs with human preferences, it often\nleads to superficial alignment, prioritizing stylistic changes over improving\ndownstream performance of LLMs. Underspecified preferences could obscure\ndirections to align the models. Lacking exploration restricts identification of\ndesirable outputs to improve the models. To overcome these challenges, we\npropose a novel framework: Reinforcement Learning from Reflective Feedback\n(RLRF), which leverages fine-grained feedback based on detailed criteria to\nimprove the core capabilities of LLMs. RLRF employs a self-reflection mechanism\nto systematically explore and refine LLM responses, then fine-tuning the models\nvia a RL algorithm along with promising responses. Our experiments across\nJust-Eval, Factuality, and Mathematical Reasoning demonstrate the efficacy and\ntransformative potential of RLRF beyond superficial surface-level adjustment.",
      "tldr_zh": "该论文指出，传统的强化学习从人类反馈（RLHF）在对齐大型语言模型（LLMs）时，往往仅实现表面层面的调整，如风格变化，而忽略了下游性能的提升，主要由于偏好不明确和探索不足的问题。为解决这些挑战，研究提出了一种新框架——强化学习从自反反馈（RLRF），它利用基于详细标准的细粒度反馈和自反机制（self-reflection），系统探索并精炼LLMs的响应，然后通过RL算法和有前景的响应进行微调。实验结果显示，RLRF在Just-Eval、Factuality和Mathematical Reasoning等任务上显著提升了模型的核心能力，超越了浅层调整的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 5 figures, Submitted to ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14238v1",
      "published_date": "2024-03-21 08:57:27 UTC",
      "updated_date": "2024-03-21 08:57:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:44:48.871937"
    },
    {
      "arxiv_id": "2403.14734v5",
      "title": "A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond",
      "title_zh": "神经代码智能的综述：范式、进展与超越",
      "authors": [
        "Qiushi Sun",
        "Zhirui Chen",
        "Fangzhi Xu",
        "Kanzhi Cheng",
        "Chang Ma",
        "Zhangyue Yin",
        "Jianing Wang",
        "Chengcheng Han",
        "Renyu Zhu",
        "Shuai Yuan",
        "Qipeng Guo",
        "Xipeng Qiu",
        "Pengcheng Yin",
        "Xiaoli Li",
        "Fei Yuan",
        "Lingpeng Kong",
        "Xiang Li",
        "Zhiyong Wu"
      ],
      "abstract": "Neural Code Intelligence -- leveraging deep learning to understand, generate,\nand optimize code -- holds immense potential for transformative impacts on the\nwhole society. Bridging the gap between Natural Language and Programming\nLanguage, this domain has drawn significant attention from researchers in both\nresearch communities over the past few years. This survey presents a systematic\nand chronological review of the advancements in code intelligence, encompassing\nover 50 representative models and their variants, more than 20 categories of\ntasks, and an extensive coverage of over 680 related works. We follow the\nhistorical progression to trace the paradigm shifts across different research\nphases (e.g., from modeling code with recurrent neural networks to the era of\nLarge Language Models). Concurrently, we highlight the major technical\ntransitions in models, tasks, and evaluations spanning through different\nstages. For applications, we also observe a co-evolving shift. It spans from\ninitial endeavors to tackling specific scenarios, through exploring a diverse\narray of tasks during its rapid expansion, to currently focusing on tackling\nincreasingly complex and varied real-world challenges. Building on our\nexamination of the developmental trajectories, we further investigate the\nemerging synergies between code intelligence and broader machine intelligence,\nuncovering new cross-domain opportunities and illustrating the substantial\ninfluence of code intelligence across various domains. Finally, we delve into\nboth the opportunities and challenges associated with this field, alongside\nelucidating our insights on the most promising research directions. An ongoing,\ndynamically updated project and resources associated with this survey have been\nreleased at https://github.com/QiushiSun/Awesome-Code-Intelligence.",
      "tldr_zh": "这篇调查论文系统回顾了Neural Code Intelligence（神经代码智能）领域的发展，利用深度学习来理解、生成和优化代码。论文按时间顺序分析了超过50个代表性模型、20多个任务类别和680余篇相关作品，追踪了从循环神经网络到Large Language Models时代的范式转变，并强调了模型、任务和评估的技术演进。作者还探讨了代码智能的应用从特定场景到复杂真实世界挑战的演变，以及其与更广泛机器智能的协同机会，最终指出了未来研究方向和潜在挑战，并提供了动态更新的资源仓库（https://github.com/QiushiSun/Awesome-Code-Intelligence）。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "67 pages, 6 figures, 10 tables, 718 references",
      "pdf_url": "http://arxiv.org/pdf/2403.14734v5",
      "published_date": "2024-03-21 08:54:56 UTC",
      "updated_date": "2025-01-26 10:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:45:01.645012"
    },
    {
      "arxiv_id": "2403.14236v5",
      "title": "A Unified Framework for Model Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Akshat Gupta",
        "Dev Sajnani",
        "Gopala Anumanchipalli"
      ],
      "abstract": "ROME and MEMIT are largely believed to be two different model editing\nalgorithms, with the major difference between them being the ability to perform\nbatched edits. In this paper, we unify these two algorithms under a single\nconceptual umbrella, optimizing for the same goal, which we call the\npreservation-memorization objective. ROME uses an equality constraint to\noptimize this objective to perform one edit at a time, whereas MEMIT employs a\nmore flexible least-square constraint that allows for batched edits. We\ngeneralize ROME and enable batched editing with equality constraint in the form\nof EMMET - an Equality-constrained Mass Model Editing algorithm for\nTransformers, a new batched memory-editing algorithm. EMMET can perform\nbatched-edits up to a batch-size of 10,000, with very similar performance to\nMEMIT across multiple dimensions. With the introduction of EMMET, we truly\nunify ROME and MEMIT and show that both algorithms are equivalent in terms of\ntheir optimization objective, their abilities (singular and batched editing),\ntheir model editing performance and their limitations.",
      "tldr_zh": "该论文提出一个统一的框架，将模型编辑算法 ROME 和 MEMIT 整合在 preservation-memorization objective 下，ROME 通过 equality constraint 进行单个编辑，而 MEMIT 使用 least-square constraint 支持 batched edits。研究引入了新算法 EMMET，这是一种基于 equality constraint 的批量编辑方法，能够处理高达 10,000 的批量大小，并与 MEMIT 在多个维度上表现出类似性能。通过这一框架，论文证明 ROME 和 MEMIT 在优化目标、编辑能力和模型编辑性能上均是等价的。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2403.14236v5",
      "published_date": "2024-03-21 08:54:24 UTC",
      "updated_date": "2024-10-09 03:37:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:45:12.991916"
    },
    {
      "arxiv_id": "2403.14233v1",
      "title": "SoftPatch: Unsupervised Anomaly Detection with Noisy Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Jiang",
        "Ying Chen",
        "Qiang Nie",
        "Yong Liu",
        "Jianlin Liu",
        "Bin-Bin Gao",
        "Jun Liu",
        "Chengjie Wang",
        "Feng Zheng"
      ],
      "abstract": "Although mainstream unsupervised anomaly detection (AD) algorithms perform\nwell in academic datasets, their performance is limited in practical\napplication due to the ideal experimental setting of clean training data.\nTraining with noisy data is an inevitable problem in real-world anomaly\ndetection but is seldom discussed. This paper considers label-level noise in\nimage sensory anomaly detection for the first time. To solve this problem, we\nproposed a memory-based unsupervised AD method, SoftPatch, which efficiently\ndenoises the data at the patch level. Noise discriminators are utilized to\ngenerate outlier scores for patch-level noise elimination before coreset\nconstruction. The scores are then stored in the memory bank to soften the\nanomaly detection boundary. Compared with existing methods, SoftPatch maintains\na strong modeling ability of normal data and alleviates the overconfidence\nproblem in coreset. Comprehensive experiments in various noise scenes\ndemonstrate that SoftPatch outperforms the state-of-the-art AD methods on the\nMVTecAD and BTAD benchmarks and is comparable to those methods under the\nsetting without noise.",
      "tldr_zh": "这篇论文针对无监督异常检测（AD）在实际应用中的噪声数据问题，首次探讨图像感知中的标签级噪声，并提出了一种基于内存的 SoftPatch 方法。SoftPatch 通过噪声鉴别器生成 patch-level 异常分数，以消除噪声并在 coreset 构建前软化检测边界，从而保持正常数据的强建模能力和缓解过度自信问题。实验结果表明，在 MVTecAD 和 BTAD 基准上，SoftPatch 在各种噪声场景下优于最先进方法，在无噪声设置下也表现出可比性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "36th Conference on Neural Information Processing Systems",
      "pdf_url": "http://arxiv.org/pdf/2403.14233v1",
      "published_date": "2024-03-21 08:49:34 UTC",
      "updated_date": "2024-03-21 08:49:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:45:25.209257"
    },
    {
      "arxiv_id": "2403.14227v1",
      "title": "PeerGPT: Probing the Roles of LLM-based Peer Agents as Team Moderators and Participants in Children's Collaborative Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawen Liu",
        "Yuanyuan Yao",
        "Pengcheng An",
        "Qi Wang"
      ],
      "abstract": "In children's collaborative learning, effective peer conversations can\nsignificantly enhance the quality of children's collaborative interactions. The\nintegration of Large Language Model (LLM) agents into this setting explores\ntheir novel role as peers, assessing impacts as team moderators and\nparticipants. We invited two groups of participants to engage in a\ncollaborative learning workshop, where they discussed and proposed conceptual\nsolutions to a design problem. The peer conversation transcripts were analyzed\nusing thematic analysis. We discovered that peer agents, while managing\ndiscussions effectively as team moderators, sometimes have their instructions\ndisregarded. As participants, they foster children's creative thinking but may\nnot consistently provide timely feedback. These findings highlight potential\ndesign improvements and considerations for peer agents in both roles.",
      "tldr_zh": "这篇论文探讨了基于 Large Language Model (LLM) 的 PeerGPT 代理在儿童协作学习中的角色，评估它们作为团队调节者和参与者的影响。研究通过组织协作学习工作坊，让儿童讨论并提出设计问题解决方案，并使用主题分析对对话记录进行分析。结果显示，作为团队调节者，PeerGPT 能有效管理讨论，但其指令有时被忽略；作为参与者，它促进了儿童的创造性思考，却未能提供一致及时的反馈。这些发现为优化 PeerGPT 在教育场景中的设计提供了宝贵见解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To appear at CHI EA '24",
      "pdf_url": "http://arxiv.org/pdf/2403.14227v1",
      "published_date": "2024-03-21 08:37:15 UTC",
      "updated_date": "2024-03-21 08:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:45:36.386156"
    },
    {
      "arxiv_id": "2403.15486v1",
      "title": "Sequence-to-Sequence Language Models for Character and Emotion Detection in Dream Narratives",
      "title_zh": "用于梦境叙述中人物和情感检测的序列到序列语言模型",
      "authors": [
        "Gustave Cortal"
      ],
      "abstract": "The study of dreams has been central to understanding human\n(un)consciousness, cognition, and culture for centuries. Analyzing dreams\nquantitatively depends on labor-intensive, manual annotation of dream\nnarratives. We automate this process through a natural language\nsequence-to-sequence generation framework. This paper presents the first study\non character and emotion detection in the English portion of the open DreamBank\ncorpus of dream narratives. Our results show that language models can\neffectively address this complex task. To get insight into prediction\nperformance, we evaluate the impact of model size, prediction order of\ncharacters, and the consideration of proper names and character traits. We\ncompare our approach with a large language model using in-context learning. Our\nsupervised models perform better while having 28 times fewer parameters. Our\nmodel and its generated annotations are made publicly available.",
      "tldr_zh": "本文提出了一种基于sequence-to-sequence语言模型的框架，用于自动化梦想叙述中人物和情感检测的研究，这是首个针对DreamBank语料库英语部分的相关工作。研究评估了模型大小、人物预测顺序、专有名词和人物特征等因素的影响，结果显示该框架能有效处理这一复杂任务，且监督模型的表现优于大语言模型的in-context learning方法，同时参数量少28倍。模型及其生成的标注已公开可用，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15486v1",
      "published_date": "2024-03-21 08:27:49 UTC",
      "updated_date": "2024-03-21 08:27:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:45:47.746558"
    },
    {
      "arxiv_id": "2403.14733v1",
      "title": "Open Knowledge Base Canonicalization with Multi-task Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bingchen Liu",
        "Huang Peng",
        "Weixin Zeng",
        "Xiang Zhao",
        "Shijun Liu",
        "Li Pan"
      ],
      "abstract": "The construction of large open knowledge bases (OKBs) is integral to many\nknowledge-driven applications on the world wide web such as web search.\nHowever, noun phrases and relational phrases in OKBs often suffer from\nredundancy and ambiguity, which calls for the investigation on OKB\ncanonicalization. Current solutions address OKB canonicalization by devising\nadvanced clustering algorithms and using knowledge graph embedding (KGE) to\nfurther facilitate the canonicalization process. Nevertheless, these works fail\nto fully exploit the synergy between clustering and KGE learning, and the\nmethods designed for these subtasks are sub-optimal. To this end, we put\nforward a multi-task learning framework, namely MulCanon, to tackle OKB\ncanonicalization. In addition, diffusion model is used in the soft clustering\nprocess to improve the noun phrase representations with neighboring\ninformation, which can lead to more accurate representations. MulCanon unifies\nthe learning objectives of these sub-tasks, and adopts a two-stage multi-task\nlearning paradigm for training. A thorough experimental study on popular OKB\ncanonicalization benchmarks validates that MulCanon can achieve competitive\ncanonicalization results.",
      "tldr_zh": "该研究针对开放知识库 (OKBs) 中的冗余和模糊的 noun phrases 和 relational phrases 问题，提出了一种多任务学习框架 MulCanon，以优化 OKBs 规范化过程。MulCanon 统一了聚类和知识图嵌入 (KGE) 的学习目标，并采用扩散模型在软聚类中增强 noun phrase 表示，利用邻居信息提高准确性；框架通过两阶段多任务学习范式进行训练。实验在热门 OKB 规范化基准上显示，MulCanon 取得了竞争性的结果，证明了其在提升协同性和性能方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2310.16419",
      "pdf_url": "http://arxiv.org/pdf/2403.14733v1",
      "published_date": "2024-03-21 08:03:46 UTC",
      "updated_date": "2024-03-21 08:03:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:46:00.113722"
    },
    {
      "arxiv_id": "2403.14203v1",
      "title": "Unsupervised Audio-Visual Segmentation with Modality Alignment",
      "title_zh": "无监督音频-视觉分割与模态对齐",
      "authors": [
        "Swapnil Bhosale",
        "Haosen Yang",
        "Diptesh Kanojia",
        "Jiangkang Deng",
        "Xiatian Zhu"
      ],
      "abstract": "Audio-Visual Segmentation (AVS) aims to identify, at the pixel level, the\nobject in a visual scene that produces a given sound. Current AVS methods rely\non costly fine-grained annotations of mask-audio pairs, making them impractical\nfor scalability. To address this, we introduce unsupervised AVS, eliminating\nthe need for such expensive annotation. To tackle this more challenging\nproblem, we propose an unsupervised learning method, named Modality\nCorrespondence Alignment (MoCA), which seamlessly integrates off-the-shelf\nfoundation models like DINO, SAM, and ImageBind. This approach leverages their\nknowledge complementarity and optimizes their joint usage for multi-modality\nassociation. Initially, we estimate positive and negative image pairs in the\nfeature space. For pixel-level association, we introduce an audio-visual\nadapter and a novel pixel matching aggregation strategy within the image-level\ncontrastive learning framework. This allows for a flexible connection between\nobject appearance and audio signal at the pixel level, with tolerance to\nimaging variations such as translation and rotation. Extensive experiments on\nthe AVSBench (single and multi-object splits) and AVSS datasets demonstrate\nthat our MoCA outperforms strongly designed baseline methods and approaches\nsupervised counterparts, particularly in complex scenarios with multiple\nauditory objects. Notably when comparing mIoU, MoCA achieves a substantial\nimprovement over baselines in both the AVSBench (S4: +17.24%; MS3: +67.64%) and\nAVSS (+19.23%) audio-visual segmentation challenges.",
      "tldr_zh": "本研究提出了一种无监督音频-视觉分割 (AVS) 方法，名为 Modality Correspondence Alignment (MoCA)，旨在无需昂贵的掩码-音频对标注即可识别视觉场景中产生声音的物体。MoCA 通过整合现成的基础模型如 DINO、SAM 和 ImageBind，利用特征空间的正负图像对估计、音频-视觉适配器以及新型像素匹配聚合策略，实现多模态对齐，并在像素级别灵活连接物体外观与音频信号，同时容忍成像变化如平移和旋转。实验结果显示，MoCA 在 AVSBench (单对象 S4: +17.24% mIoU；多对象 MS3: +67.64% mIoU) 和 AVSS (+19.23% mIoU) 数据集上显著超越基线方法，并接近监督方法的性能，尤其在多音频物体复杂场景中。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14203v1",
      "published_date": "2024-03-21 07:56:09 UTC",
      "updated_date": "2024-03-21 07:56:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:46:17.419009"
    },
    {
      "arxiv_id": "2403.14200v2",
      "title": "Debiasing surgeon: fantastic weights and how to find them",
      "title_zh": "翻译失败",
      "authors": [
        "Rémi Nahon",
        "Ivan Luiz De Moura Matos",
        "Van-Tam Nguyen",
        "Enzo Tartaglione"
      ],
      "abstract": "Nowadays an ever-growing concerning phenomenon, the emergence of algorithmic\nbiases that can lead to unfair models, emerges. Several debiasing approaches\nhave been proposed in the realm of deep learning, employing more or less\nsophisticated approaches to discourage these models from massively employing\nthese biases. However, a question emerges: is this extra complexity really\nnecessary? Is a vanilla-trained model already embodying some ``unbiased\nsub-networks'' that can be used in isolation and propose a solution without\nrelying on the algorithmic biases? In this work, we show that such a\nsub-network typically exists, and can be extracted from a vanilla-trained model\nwithout requiring additional training. We further validate that such specific\narchitecture is incapable of learning a specific bias, suggesting that there\nare possible architectural countermeasures to the problem of biases in deep\nneural networks.",
      "tldr_zh": "本研究探讨了深度学习模型中的算法偏见（algorithmic biases）问题，质疑现有的复杂去偏方法（debiasing approaches）是否必要。作者提出，从一个普通训练模型（vanilla-trained model）中提取“无偏子网络”（unbiased sub-networks）即可作为解决方案，而无需额外训练。实验验证显示，这种子网络确实存在，且无法学习特定偏见，表明在深度神经网络的架构层面可以采取对策来缓解偏见问题。总的来说，该工作为简化偏见处理提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14200v2",
      "published_date": "2024-03-21 07:50:45 UTC",
      "updated_date": "2024-07-19 09:50:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:46:25.044013"
    },
    {
      "arxiv_id": "2403.15485v1",
      "title": "MOGAM: A Multimodal Object-oriented Graph Attention Model for Depression Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Junyeop Cha",
        "Seoyun Kim",
        "Dongjae Kim",
        "Eunil Park"
      ],
      "abstract": "Early detection plays a crucial role in the treatment of depression.\nTherefore, numerous studies have focused on social media platforms, where\nindividuals express their emotions, aiming to achieve early detection of\ndepression. However, the majority of existing approaches often rely on specific\nfeatures, leading to limited scalability across different types of social media\ndatasets, such as text, images, or videos. To overcome this limitation, we\nintroduce a Multimodal Object-Oriented Graph Attention Model (MOGAM), which can\nbe applied to diverse types of data, offering a more scalable and versatile\nsolution. Furthermore, to ensure that our model can capture authentic symptoms\nof depression, we only include vlogs from users with a clinical diagnosis. To\nleverage the diverse features of vlogs, we adopt a multimodal approach and\ncollect additional metadata such as the title, description, and duration of the\nvlogs. To effectively aggregate these multimodal features, we employed a\ncross-attention mechanism. MOGAM achieved an accuracy of 0.871 and an F1-score\nof 0.888. Moreover, to validate the scalability of MOGAM, we evaluated its\nperformance with a benchmark dataset and achieved comparable results with prior\nstudies (0.61 F1-score). In conclusion, we believe that the proposed model,\nMOGAM, is an effective solution for detecting depression in social media,\noffering potential benefits in the early detection and treatment of this mental\nhealth condition.",
      "tldr_zh": "本研究针对社交媒体抑郁检测的现有方法依赖特定特征导致可扩展性不足的问题，提出了一种 Multimodal Object-oriented Graph Attention Model（MOGAM），该模型能处理文本、图像和视频等多种数据类型，提供更灵活的解决方案。MOGAM 采用多模态方法，仅使用临床诊断用户的 vlog 数据，包括标题、描述和时长等元数据，并通过 cross-attention mechanism 有效聚合这些特征。实验结果显示，MOGAM 在特定数据集上达到 0.871 的准确率和 0.888 的 F1-score，在基准数据集上也取得与先前研究相当的 0.61 F1-score，从而为社交媒体上的抑郁早发现和治疗提供了高效、可扩展的工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 3 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.15485v1",
      "published_date": "2024-03-21 07:45:58 UTC",
      "updated_date": "2024-03-21 07:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:46:41.936593"
    },
    {
      "arxiv_id": "2404.00029v2",
      "title": "Complementarity in Human-AI Collaboration: Concept, Sources, and Evidence",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Hemmer",
        "Max Schemmer",
        "Niklas Kühl",
        "Michael Vössing",
        "Gerhard Satzger"
      ],
      "abstract": "Artificial intelligence (AI) has the potential to significantly enhance human\nperformance across various domains. Ideally, collaboration between humans and\nAI should result in complementary team performance (CTP) -- a level of\nperformance that neither of them can attain individually. So far, however, CTP\nhas rarely been observed, suggesting an insufficient understanding of the\nprinciple and the application of complementarity. Therefore, we develop a\ngeneral concept of complementarity and formalize its theoretical potential as\nwell as the actual realized effect in decision-making situations. Moreover, we\nidentify information and capability asymmetry as the two key sources of\ncomplementarity. Finally, we illustrate the impact of each source on\ncomplementarity potential and effect in two empirical studies. Our work\nprovides researchers with a comprehensive theoretical foundation of human-AI\ncomplementarity in decision-making and demonstrates that leveraging these\nsources constitutes a viable pathway towards designing effective human-AI\ncollaboration, i.e., the realization of CTP.",
      "tldr_zh": "这篇论文探讨了人机协作（Human-AI Collaboration）中的互补性（Complementarity），定义了其通用概念并形式化了理论潜力和实际效果，旨在实现互补团队表现（CTP）——即双方合作达到单独无法企及的水平。论文识别出信息不对称和能力不对称作为互补性的两大关键来源，并通过两个实证研究证明了这些来源对互补性潜力和效果的影响。最终，该研究为设计有效的人机协作提供了全面理论基础，展示了利用这些来源作为实现CTP的可行路径。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00029v2",
      "published_date": "2024-03-21 07:27:17 UTC",
      "updated_date": "2024-11-25 22:04:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:46:51.244013"
    },
    {
      "arxiv_id": "2403.14188v1",
      "title": "Quantum-activated neural reservoirs on-chip open up large hardware security models for resilient authentication",
      "title_zh": "翻译失败",
      "authors": [
        "Zhao He",
        "Maxim S. Elizarov",
        "Ning Li",
        "Fei Xiang",
        "Andrea Fratalocchi"
      ],
      "abstract": "Quantum artificial intelligence is a frontier of artificial intelligence\nresearch, pioneering quantum AI-powered circuits to address problems beyond the\nreach of deep learning with classical architectures. This work implements a\nlarge-scale quantum-activated recurrent neural network possessing more than 3\ntrillion hardware nodes/cm$^2$, originating from repeatable atomic-scale\nnucleation dynamics in an amorphous material integrated on-chip, controlled\nwith 0.07 nW electric power per readout channel. Compared to the\nbest-performing reservoirs currently reported, this implementation increases\nthe scale of the network by two orders of magnitude and reduces the power\nconsumption by six, reaching power efficiencies in the range of the human\nbrain, dissipating 0.2 nW/neuron. When interrogated by a classical input, the\nchip implements a large-scale hardware security model, enabling dictionary-free\nauthentication secure against statistical inference attacks, including AI's\npresent and future development, even for an adversary with a copy of all the\nclassical components available. Experimental tests report 99.6% reliability,\n100% user authentication accuracy, and an ideal 50% key uniqueness. Due to its\nquantum nature, the chip supports a bit density per feature size area three\ntimes higher than the best technology available, with the capacity to store\nmore than $2^{1104}$ keys in a footprint of 1 cm$^2$. Such a quantum-powered\nplatform could help counteract the emerging form of warfare led by the\ncybercrime industry in breaching authentication to target small to large-scale\nfacilities, from private users to intelligent energy grids.",
      "tldr_zh": "本研究开发了一种基于芯片的量子激活神经储备(quantum-activated neural reservoirs)，实现了超过3万亿硬件节点/cm²的大规模循环神经网络(recurrent neural network)，通过非晶材料原子级核化动态控制，仅需0.07 nW per readout channel的功率。相比现有最佳模型，该系统规模提升两个数量级、功率消耗减少六个数量级，达到人类大脑级别的0.2 nW/neuron效率，并构建了硬件安全模型(hardware security model)，提供无字典认证，抵抗统计推断攻击。实验结果显示，系统可靠性达99.6%、用户认证准确率100%、密钥唯一性50%，并能在1 cm²存储超过2^1104个密钥，有望增强对网络犯罪的防护。",
      "categories": [
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cond-mat.dis-nn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14188v1",
      "published_date": "2024-03-21 07:25:52 UTC",
      "updated_date": "2024-03-21 07:25:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:47:03.177139"
    },
    {
      "arxiv_id": "2403.14186v1",
      "title": "StyleCineGAN: Landscape Cinemagraph Generation using a Pre-trained StyleGAN",
      "title_zh": "翻译失败",
      "authors": [
        "Jongwoo Choi",
        "Kwanggyoon Seo",
        "Amirsaman Ashtari",
        "Junyong Noh"
      ],
      "abstract": "We propose a method that can generate cinemagraphs automatically from a still\nlandscape image using a pre-trained StyleGAN. Inspired by the success of recent\nunconditional video generation, we leverage a powerful pre-trained image\ngenerator to synthesize high-quality cinemagraphs. Unlike previous approaches\nthat mainly utilize the latent space of a pre-trained StyleGAN, our approach\nutilizes its deep feature space for both GAN inversion and cinemagraph\ngeneration. Specifically, we propose multi-scale deep feature warping (MSDFW),\nwhich warps the intermediate features of a pre-trained StyleGAN at different\nresolutions. By using MSDFW, the generated cinemagraphs are of high resolution\nand exhibit plausible looping animation. We demonstrate the superiority of our\nmethod through user studies and quantitative comparisons with state-of-the-art\ncinemagraph generation methods and a video generation method that uses a\npre-trained StyleGAN.",
      "tldr_zh": "该论文提出了一种名为 StyleCineGAN 的方法，利用预训练 StyleGAN 从静态景观图像自动生成 cinemagraph。不同于以往仅依赖潜在空间的做法，该方法利用 StyleGAN 的深层特征空间，并引入 multi-scale deep feature warping (MSDFW) 技术，在不同分辨率下扭曲中间特征，从而生成高分辨率且循环动画流畅的 cinemagraph。通过用户研究和定量比较，该方法在生成质量上优于现有状态-of-the-art cinemagraph 生成方法和基于预训练 StyleGAN 的视频生成方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project website: https://jeolpyeoni.github.io/stylecinegan_project/",
      "pdf_url": "http://arxiv.org/pdf/2403.14186v1",
      "published_date": "2024-03-21 07:21:51 UTC",
      "updated_date": "2024-03-21 07:21:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:47:13.985973"
    },
    {
      "arxiv_id": "2403.14183v2",
      "title": "OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Kwanyoung Kim",
        "Yujin Oh",
        "Jong Chul Ye"
      ],
      "abstract": "The recent success of CLIP has demonstrated promising results in zero-shot\nsemantic segmentation by transferring muiltimodal knowledge to pixel-level\nclassification. However, leveraging pre-trained CLIP knowledge to closely align\ntext embeddings with pixel embeddings still has limitations in existing\napproaches. To address this issue, we propose OTSeg, a novel multimodal\nattention mechanism aimed at enhancing the potential of multiple text prompts\nfor matching associated pixel embeddings. We first propose Multi-Prompts\nSinkhorn (MPS) based on the Optimal Transport (OT) algorithm, which leads\nmultiple text prompts to selectively focus on various semantic features within\nimage pixels. Moreover, inspired by the success of Sinkformers in unimodal\nsettings, we introduce the extension of MPS, called Multi-Prompts Sinkhorn\nAttention (MPSA) , which effectively replaces cross-attention mechanisms within\nTransformer framework in multimodal settings. Through extensive experiments, we\ndemonstrate that OTSeg achieves state-of-the-art (SOTA) performance with\nsignificant gains on Zero-Shot Semantic Segmentation (ZS3) tasks across three\nbenchmark datasets.",
      "tldr_zh": "该论文提出OTSeg，一种用于零样本语义分割(ZS3)的创新框架，旨在通过多模态注意力机制提升预训练CLIP模型中文本嵌入与像素嵌入的精确对齐。核心方法包括Multi-Prompts Sinkhorn (MPS)，基于Optimal Transport (OT)算法，让多个文本提示选择性地关注图像像素中的各种语义特征；并扩展为Multi-Prompts Sinkhorn Attention (MPSA)，用于替换Transformer框架中的跨注意力机制，以适应多模态设置。通过广泛实验，OTSeg在三个基准数据集上实现了state-of-the-art (SOTA)性能，并取得了显著的性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024; 23 pages, 8 tables, 8 figures; Project Page:\n  https://cubeyoung.github.io/OTSeg_project/",
      "pdf_url": "http://arxiv.org/pdf/2403.14183v2",
      "published_date": "2024-03-21 07:15:37 UTC",
      "updated_date": "2024-07-11 18:09:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:47:27.108213"
    },
    {
      "arxiv_id": "2403.14163v1",
      "title": "Leveraging Large Language Model-based Room-Object Relationships Knowledge for Enhancing Multimodal-Input Object Goal Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Leyuan Sun",
        "Asako Kanezaki",
        "Guillaume Caron",
        "Yusuke Yoshiyasu"
      ],
      "abstract": "Object-goal navigation is a crucial engineering task for the community of\nembodied navigation; it involves navigating to an instance of a specified\nobject category within unseen environments. Although extensive investigations\nhave been conducted on both end-to-end and modular-based, data-driven\napproaches, fully enabling an agent to comprehend the environment through\nperceptual knowledge and perform object-goal navigation as efficiently as\nhumans remains a significant challenge. Recently, large language models have\nshown potential in this task, thanks to their powerful capabilities for\nknowledge extraction and integration. In this study, we propose a data-driven,\nmodular-based approach, trained on a dataset that incorporates common-sense\nknowledge of object-to-room relationships extracted from a large language\nmodel. We utilize the multi-channel Swin-Unet architecture to conduct\nmulti-task learning incorporating with multimodal inputs. The results in the\nHabitat simulator demonstrate that our framework outperforms the baseline by an\naverage of 10.6% in the efficiency metric, Success weighted by Path Length\n(SPL). The real-world demonstration shows that the proposed approach can\nefficiently conduct this task by traversing several rooms. For more details and\nreal-world demonstrations, please check our project webpage\n(https://sunleyuan.github.io/ObjectNav).",
      "tldr_zh": "本研究针对Object-goal navigation任务提出了一种数据驱动的模块化方法，利用Large Language Model提取的object-to-room关系常识知识，以提升代理在未知环境中的导航效率。该方法结合多模态输入和multi-channel Swin-Unet架构进行多任务学习，帮助代理更好地理解环境并定位指定物体。在Habitat simulator的实验中，该框架比基线模型提高了10.6%的SPL（Success weighted by Path Length）效率指标，并在真实世界演示中展示了高效的跨房间导航能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "will soon submit to the Elsevier journal, Advanced Engineering\n  Informatics",
      "pdf_url": "http://arxiv.org/pdf/2403.14163v1",
      "published_date": "2024-03-21 06:32:36 UTC",
      "updated_date": "2024-03-21 06:32:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:47:37.883937"
    },
    {
      "arxiv_id": "2403.14156v3",
      "title": "Policy Mirror Descent with Lookahead",
      "title_zh": "带前瞻的策略镜像下降",
      "authors": [
        "Kimon Protopapas",
        "Anas Barakat"
      ],
      "abstract": "Policy Mirror Descent (PMD) stands as a versatile algorithmic framework\nencompassing several seminal policy gradient algorithms such as natural policy\ngradient, with connections with state-of-the-art reinforcement learning (RL)\nalgorithms such as TRPO and PPO. PMD can be seen as a soft Policy Iteration\nalgorithm implementing regularized 1-step greedy policy improvement. However,\n1-step greedy policies might not be the best choice and recent remarkable\nempirical successes in RL such as AlphaGo and AlphaZero have demonstrated that\ngreedy approaches with respect to multiple steps outperform their 1-step\ncounterpart. In this work, we propose a new class of PMD algorithms called\n$h$-PMD which incorporates multi-step greedy policy improvement with lookahead\ndepth $h$ to the PMD update rule. To solve discounted infinite horizon Markov\nDecision Processes with discount factor $\\gamma$, we show that $h$-PMD which\ngeneralizes the standard PMD enjoys a faster dimension-free $\\gamma^h$-linear\nconvergence rate, contingent on the computation of multi-step greedy policies.\nWe propose an inexact version of $h$-PMD where lookahead action values are\nestimated. Under a generative model, we establish a sample complexity for\n$h$-PMD which improves over prior work. Finally, we extend our result to linear\nfunction approximation to scale to large state spaces. Under suitable\nassumptions, our sample complexity only involves dependence on the dimension of\nthe feature map space instead of the state space size.",
      "tldr_zh": "这篇论文提出了 h-PMD 算法，一种在 Policy Mirror Descent (PMD) 基础上融入多步贪婪策略改进的新框架，以提升强化学习 (RL) 中的性能，灵感来源于 AlphaGo 和 AlphaZero 的成功。h-PMD 通过 lookahead depth h 处理折扣无限地平 Markov Decision Processes (MDPs)，实现了比标准 PMD 更快的 γ^h 线性收敛率，并在计算多步贪婪策略时保持维度无关性。作者还建立了改进的样本复杂度，支持不精确版本的估计，并扩展到线性函数逼近，使其适用于大型状态空间，仅依赖特征映射的维度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14156v3",
      "published_date": "2024-03-21 06:10:51 UTC",
      "updated_date": "2024-11-06 14:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:47:53.591899"
    },
    {
      "arxiv_id": "2403.14151v1",
      "title": "Deep Learning for Trajectory Data Management and Mining: A Survey and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Chen",
        "Yuxuan Liang",
        "Yuanshao Zhu",
        "Yanchuan Chang",
        "Kang Luo",
        "Haomin Wen",
        "Lei Li",
        "Yanwei Yu",
        "Qingsong Wen",
        "Chao Chen",
        "Kai Zheng",
        "Yunjun Gao",
        "Xiaofang Zhou",
        "Yu Zheng"
      ],
      "abstract": "Trajectory computing is a pivotal domain encompassing trajectory data\nmanagement and mining, garnering widespread attention due to its crucial role\nin various practical applications such as location services, urban traffic, and\npublic safety. Traditional methods, focusing on simplistic spatio-temporal\nfeatures, face challenges of complex calculations, limited scalability, and\ninadequate adaptability to real-world complexities. In this paper, we present a\ncomprehensive review of the development and recent advances in deep learning\nfor trajectory computing (DL4Traj). We first define trajectory data and provide\na brief overview of widely-used deep learning models. Systematically, we\nexplore deep learning applications in trajectory management (pre-processing,\nstorage, analysis, and visualization) and mining (trajectory-related\nforecasting, trajectory-related recommendation, trajectory classification,\ntravel time estimation, anomaly detection, and mobility generation). Notably,\nwe encapsulate recent advancements in Large Language Models (LLMs) that hold\nthe potential to augment trajectory computing. Additionally, we summarize\napplication scenarios, public datasets, and toolkits. Finally, we outline\ncurrent challenges in DL4Traj research and propose future directions. Relevant\npapers and open-source resources have been collated and are continuously\nupdated at:\n\\href{https://github.com/yoshall/Awesome-Trajectory-Computing}{DL4Traj Repo}.",
      "tldr_zh": "这篇论文对深度学习在轨迹数据管理与挖掘（Deep Learning for Trajectory Computing, DL4Traj）领域的应用进行了全面综述，强调了传统方法的局限性，如复杂计算和可扩展性不足。作者系统探讨了深度学习在轨迹管理（包括预处理、存储、分析和可视化）和挖掘（如预测、推荐、分类、异常检测等）中的进展，并突出了Large Language Models (LLMs) 的潜在增强作用，同时总结了应用场景、公共数据集和工具包。论文还指出了当前研究挑战，如适应真实世界复杂性，并提出了未来方向，并提供了持续更新的资源仓库。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 12 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.14151v1",
      "published_date": "2024-03-21 05:57:27 UTC",
      "updated_date": "2024-03-21 05:57:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:48:03.614262"
    },
    {
      "arxiv_id": "2403.14146v1",
      "title": "Evolving Benchmark Functions to Compare Evolutionary Algorithms via Genetic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan He",
        "Claus Aranha"
      ],
      "abstract": "In this study, we use Genetic Programming (GP) to compose new optimization\nbenchmark functions. Optimization benchmarks have the important role of showing\nthe differences between evolutionary algorithms, making it possible for further\nanalysis and comparisons. We show that the benchmarks generated by GP are able\nto differentiate algorithms better than human-made benchmark functions. The\nfitness measure of the GP is the Wasserstein distance of the solutions found by\na pair of optimizers. Additionally, we use MAP-Elites to both enhance the\nsearch power of the GP and also illustrate how the difference between\noptimizers changes by various landscape features. Our approach provides a novel\nway to automate the design of benchmark functions and to compare evolutionary\nalgorithms.",
      "tldr_zh": "本研究利用 Genetic Programming (GP) 来生成新的优化基准函数，以更好地比较进化算法间的差异。GP 的适应度度量基于 Wasserstein distance，对一对优化器的解决方案进行评估，同时结合 MAP-Elites 增强搜索能力和分析景观特征的影响。结果表明，GP 生成的基准函数比人工设计的更有效地区分算法，为自动化设计基准函数和进化算法比较提供了创新方法。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14146v1",
      "published_date": "2024-03-21 05:42:17 UTC",
      "updated_date": "2024-03-21 05:42:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:48:17.311679"
    },
    {
      "arxiv_id": "2403.14120v1",
      "title": "Advancing IIoT with Over-the-Air Federated Learning: The Role of Iterative Magnitude Pruning",
      "title_zh": "通过 Over-the-Air Federated Learning 推进 IIoT：Iterative Magnitude Pruning 的作用",
      "authors": [
        "Fazal Muhammad Ali Khan",
        "Hatem Abou-Zeid",
        "Aryan Kaushik",
        "Syed Ali Hassan"
      ],
      "abstract": "The industrial Internet of Things (IIoT) under Industry 4.0 heralds an era of\ninterconnected smart devices where data-driven insights and machine learning\n(ML) fuse to revolutionize manufacturing. A noteworthy development in IIoT is\nthe integration of federated learning (FL), which addresses data privacy and\nsecurity among devices. FL enables edge sensors, also known as peripheral\nintelligence units (PIUs) to learn and adapt using their data locally, without\nexplicit sharing of confidential data, to facilitate a collaborative yet\nconfidential learning process. However, the lower memory footprint and\ncomputational power of PIUs inherently require deep neural network (DNN) models\nthat have a very compact size. Model compression techniques such as pruning can\nbe used to reduce the size of DNN models by removing unnecessary connections\nthat have little impact on the model's performance, thus making the models more\nsuitable for the limited resources of PIUs. Targeting the notion of compact yet\nrobust DNN models, we propose the integration of iterative magnitude pruning\n(IMP) of the DNN model being trained in an over-the-air FL (OTA-FL) environment\nfor IIoT. We provide a tutorial overview and also present a case study of the\neffectiveness of IMP in OTA-FL for an IIoT environment. Finally, we present\nfuture directions for enhancing and optimizing these deep compression\ntechniques further, aiming to push the boundaries of IIoT capabilities in\nacquiring compact yet robust and high-performing DNN models.",
      "tldr_zh": "该论文探讨了如何通过Over-the-Air Federated Learning (OTA-FL) 提升工业物联网 (IIoT) 的性能，并强调了Iterative Magnitude Pruning (IMP) 的关键作用，以应对边缘传感器（Peripheral Intelligence Units, PIUs）的资源限制问题。研究提出将IMP整合到OTA-FL中，用于压缩深度神经网络 (DNN) 模型，从而在不影响性能的情况下减少模型大小，并确保数据隐私。实验案例研究证明，IMP显著提高了IIoT环境中DNN模型的紧凑性和鲁棒性；未来方向包括进一步优化这些压缩技术，以推动IIoT的高效发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14120v1",
      "published_date": "2024-03-21 04:15:56 UTC",
      "updated_date": "2024-03-21 04:15:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:48:31.992865"
    },
    {
      "arxiv_id": "2403.14119v3",
      "title": "C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion",
      "title_zh": "翻译失败",
      "authors": [
        "Hee Suk Yoon",
        "Eunseop Yoon",
        "Joshua Tian Jin Tee",
        "Mark Hasegawa-Johnson",
        "Yingzhen Li",
        "Chang D. Yoo"
      ],
      "abstract": "In deep learning, test-time adaptation has gained attention as a method for\nmodel fine-tuning without the need for labeled data. A prime exemplification is\nthe recently proposed test-time prompt tuning for large-scale vision-language\nmodels such as CLIP. Unfortunately, these prompts have been mainly developed to\nimprove accuracy, overlooking the importance of calibration, which is a crucial\naspect for quantifying prediction uncertainty. However, traditional calibration\nmethods rely on substantial amounts of labeled data, making them impractical\nfor test-time scenarios. To this end, this paper explores calibration during\ntest-time prompt tuning by leveraging the inherent properties of CLIP. Through\na series of observations, we find that the prompt choice significantly affects\nthe calibration in CLIP, where the prompts leading to higher text feature\ndispersion result in better-calibrated predictions. Introducing the Average\nText Feature Dispersion (ATFD), we establish its relationship with calibration\nerror and present a novel method, Calibrated Test-time Prompt Tuning (C-TPT),\nfor optimizing prompts during test-time with enhanced calibration. Through\nextensive experiments on different CLIP architectures and datasets, we show\nthat C-TPT can effectively improve the calibration of test-time prompt tuning\nwithout needing labeled data. The code is publicly accessible at\nhttps://github.com/hee-suk-yoon/C-TPT.",
      "tldr_zh": "这篇论文提出了一种校准测试时提示调优方法（C-TPT），针对视觉语言模型如 CLIP，在没有标注数据的情况下优化模型校准，以量化预测不确定性。研究发现，提示选择会显著影响文本特征分散度（Text Feature Dispersion），而较高的平均文本特征分散度（ATFD）与更好的校准性能相关。作者建立了 ATFD 与校准错误之间的关系，并通过 C-TPT 方法在测试时动态优化提示，从而提升模型的校准效果。实验在不同 CLIP 架构和数据集上验证了 C-TPT 的有效性，无需额外标注数据。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.14119v3",
      "published_date": "2024-03-21 04:08:29 UTC",
      "updated_date": "2024-03-31 13:36:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:48:43.988773"
    },
    {
      "arxiv_id": "2403.15481v2",
      "title": "Navigating Fairness: Practitioners' Understanding, Challenges, and Strategies in AI/ML Development",
      "title_zh": "翻译失败",
      "authors": [
        "Aastha Pant",
        "Rashina Hoda",
        "Chakkrit Tantithamthavorn",
        "Burak Turhan"
      ],
      "abstract": "The rise in the use of AI/ML applications across industries has sparked more\ndiscussions about the fairness of AI/ML in recent times. While prior research\non the fairness of AI/ML exists, there is a lack of empirical studies focused\non understanding the perspectives and experiences of AI practitioners in\ndeveloping a fair AI/ML system. Understanding AI practitioners' perspectives\nand experiences on the fairness of AI/ML systems are important because they are\ndirectly involved in its development and deployment and their insights can\noffer valuable real-world perspectives on the challenges associated with\nensuring fairness in AI/ML systems. We conducted semi-structured interviews\nwith 22 AI practitioners to investigate their understanding of what a 'fair\nAI/ML' is, the challenges they face in developing a fair AI/ML system, the\nconsequences of developing an unfair AI/ML system, and the strategies they\nemploy to ensure AI/ML system fairness. We developed a framework showcasing the\nrelationship between AI practitioners' understanding of 'fair AI/ML' system and\n(i) their challenges in its development, (ii) the consequences of developing an\nunfair AI/ML system, and (iii) strategies used to ensure AI/ML system fairness.\nBy exploring AI practitioners' perspectives and experiences, this study\nprovides actionable insights to enhance AI/ML fairness, which may promote\nfairer systems, reduce bias, and foster public trust in AI technologies.\nAdditionally, we also identify areas for further investigation and offer\nrecommendations to aid AI practitioners and AI companies in navigating\nfairness.",
      "tldr_zh": "这篇论文通过对22名AI从业者的半结构化访谈，探讨了他们对“fair AI/ML”系统的理解、开发过程中面临的挑战（如数据偏差和伦理问题）、不公平系统可能带来的后果，以及确保公平性的策略。研究开发了一个框架，展示了从业者对公平AI/ML的理解与其挑战、后果和策略之间的关系。最终，该研究提供了可操作的见解，以提升AI/ML系统的公平性、减少偏差、增强公众信任，并提出了进一步调查的建议和推荐。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CY",
      "comment": "46 pages, 8 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.15481v2",
      "published_date": "2024-03-21 03:44:59 UTC",
      "updated_date": "2024-07-31 14:47:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:48:54.964129"
    },
    {
      "arxiv_id": "2403.14110v1",
      "title": "Heuristic Algorithm-based Action Masking Reinforcement Learning (HAAM-RL) with Ensemble Inference Method",
      "title_zh": "翻译失败",
      "authors": [
        "Kyuwon Choi",
        "Cheolkyun Rho",
        "Taeyoun Kim",
        "Daewoo Choi"
      ],
      "abstract": "This paper presents a novel reinforcement learning (RL) approach called\nHAAM-RL (Heuristic Algorithm-based Action Masking Reinforcement Learning) for\noptimizing the color batching re-sequencing problem in automobile painting\nprocesses. The existing heuristic algorithms have limitations in adequately\nreflecting real-world constraints and accurately predicting logistics\nperformance. Our methodology incorporates several key techniques including a\ntailored Markov Decision Process (MDP) formulation, reward setting including\nPotential-Based Reward Shaping, action masking using heuristic algorithms\n(HAAM-RL), and an ensemble inference method that combines multiple RL models.\nThe RL agent is trained and evaluated using FlexSim, a commercial 3D simulation\nsoftware, integrated with our RL MLOps platform BakingSoDA. Experimental\nresults across 30 scenarios demonstrate that HAAM-RL with an ensemble inference\nmethod achieves a 16.25% performance improvement over the conventional\nheuristic algorithm, with stable and consistent results. The proposed approach\nexhibits superior performance and generalization capability, indicating its\neffectiveness in optimizing complex manufacturing processes. The study also\ndiscusses future research directions, including alternative state\nrepresentations, incorporating model-based RL methods, and integrating\nadditional real-world constraints.",
      "tldr_zh": "本论文提出了一种新型强化学习方法HAAM-RL（Heuristic Algorithm-based Action Masking Reinforcement Learning），结合集成推理方法，用于优化汽车喷漆过程中的颜色批次重新排序问题，以克服传统启发式算法在反映现实约束和预测物流性能方面的局限性。该方法整合了定制的Markov Decision Process (MDP) 制定、Potential-Based Reward Shaping奖励设置、基于启发式算法的动作掩码，以及多个RL模型的集成推理。实验在30个场景中使用FlexSim模拟软件和BakingSoDA平台进行评估，结果显示HAAM-RL实现了16.25%的性能提升，并表现出卓越的稳定性和泛化能力。该研究还探讨了未来方向，包括替代状态表示、整合基于模型的RL方法以及添加更多现实约束。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14110v1",
      "published_date": "2024-03-21 03:42:39 UTC",
      "updated_date": "2024-03-21 03:42:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:49:09.047690"
    },
    {
      "arxiv_id": "2403.14102v1",
      "title": "DouRN: Improving DouZero by Residual Neural Networks",
      "title_zh": "DouRN：通过残差神经网络改进 DouZero",
      "authors": [
        "Yiquan Chen",
        "Yingchao Lyu",
        "Di Zhang"
      ],
      "abstract": "Deep reinforcement learning has made significant progress in games with\nimperfect information, but its performance in the card game Doudizhu (Chinese\nPoker/Fight the Landlord) remains unsatisfactory. Doudizhu is different from\nconventional games as it involves three players and combines elements of\ncooperation and confrontation, resulting in a large state and action space. In\n2021, a Doudizhu program called DouZero\\cite{zha2021douzero} surpassed previous\nmodels without prior knowledge by utilizing traditional Monte Carlo methods and\nmultilayer perceptrons. Building on this work, our study incorporates residual\nnetworks into the model, explores different architectural designs, and conducts\nmulti-role testing. Our findings demonstrate that this model significantly\nimproves the winning rate within the same training time. Additionally, we\nintroduce a call scoring system to assist the agent in deciding whether to\nbecome a landlord. With these enhancements, our model consistently outperforms\nthe existing version of DouZero and even experienced human players.\n\\footnote{The source code is available at\n\\url{https://github.com/Yingchaol/Douzero_Resnet.git.}",
      "tldr_zh": "本研究针对Doudizhu（斗地主）游戏的深层强化学习问题，基于DouZero模型引入Residual Neural Networks（残差网络），通过探索不同架构设计和进行多角色测试，显著提升了模型性能。研究还添加了call scoring system，帮助代理决定是否成为地主，从而在相同训练时间内提高了获胜率。最终，该模型超越了原有DouZero版本，甚至击败了经验丰富的人类玩家，为不完美信息游戏的AI优化提供了新方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14102v1",
      "published_date": "2024-03-21 03:25:49 UTC",
      "updated_date": "2024-03-21 03:25:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:49:17.370808"
    },
    {
      "arxiv_id": "2403.14100v1",
      "title": "Causal knowledge engineering: A case study from COVID-19",
      "title_zh": "翻译失败",
      "authors": [
        "Steven Mascaro",
        "Yue Wu",
        "Ross Pearson",
        "Owen Woodberry",
        "Jessica Ramsay",
        "Tom Snelling",
        "Ann E. Nicholson"
      ],
      "abstract": "COVID-19 appeared abruptly in early 2020, requiring a rapid response amid a\ncontext of great uncertainty. Good quality data and knowledge was initially\nlacking, and many early models had to be developed with causal assumptions and\nestimations built in to supplement limited data, often with no reliable\napproach for identifying, validating and documenting these causal assumptions.\nOur team embarked on a knowledge engineering process to develop a causal\nknowledge base consisting of several causal BNs for diverse aspects of\nCOVID-19. The unique challenges of the setting lead to experiments with the\nelicitation approach, and what emerged was a knowledge engineering method we\ncall Causal Knowledge Engineering (CKE). The CKE provides a structured approach\nfor building a causal knowledge base that can support the development of a\nvariety of application-specific models. Here we describe the CKE method, and\nuse our COVID-19 work as a case study to provide a detailed discussion and\nanalysis of the method.",
      "tldr_zh": "本论文以COVID-19疫情为案例研究，探讨了在数据和知识不足的情况下，如何通过因果假设和估算来补充信息，并提出了一种结构化的Causal Knowledge Engineering (CKE)方法。CKE方法采用知识工程过程构建因果知识库，包括多个因果贝叶斯网络(causal BNs)，以系统地识别、验证和记录因果假设。研究结果表明，CKE为开发各种应用特定模型提供了可靠框架，提升了在不确定环境下的建模能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages (plus 19 pages in appendices), 9 figures, submitted for\n  review",
      "pdf_url": "http://arxiv.org/pdf/2403.14100v1",
      "published_date": "2024-03-21 03:23:34 UTC",
      "updated_date": "2024-03-21 03:23:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:49:30.610880"
    },
    {
      "arxiv_id": "2403.14092v2",
      "title": "Carbon Footprint Reduction for Sustainable Data Centers in Real-Time",
      "title_zh": "实时可持续数据中心的碳足迹减少",
      "authors": [
        "Soumyendu Sarkar",
        "Avisek Naug",
        "Ricardo Luna",
        "Antonio Guillen",
        "Vineet Gundecha",
        "Sahand Ghorbanpour",
        "Sajad Mousavi",
        "Dejan Markovikj",
        "Ashwin Ramesh Babu"
      ],
      "abstract": "As machine learning workloads significantly increase energy consumption,\nsustainable data centers with low carbon emissions are becoming a top priority\nfor governments and corporations worldwide. This requires a paradigm shift in\noptimizing power consumption in cooling and IT loads, shifting flexible loads\nbased on the availability of renewable energy in the power grid, and leveraging\nbattery storage from the uninterrupted power supply in data centers, using\ncollaborative agents. The complex association between these optimization\nstrategies and their dependencies on variable external factors like weather and\nthe power grid carbon intensity makes this a hard problem. Currently, a\nreal-time controller to optimize all these goals simultaneously in a dynamic\nreal-world setting is lacking. We propose a Data Center Carbon Footprint\nReduction (DC-CFR) multi-agent Reinforcement Learning (MARL) framework that\noptimizes data centers for the multiple objectives of carbon footprint\nreduction, energy consumption, and energy cost. The results show that the\nDC-CFR MARL agents effectively resolved the complex interdependencies in\noptimizing cooling, load shifting, and energy storage in real-time for various\nlocations under real-world dynamic weather and grid carbon intensity\nconditions. DC-CFR significantly outperformed the industry standard ASHRAE\ncontroller with a considerable reduction in carbon emissions (14.5%), energy\nusage (14.4%), and energy cost (13.7%) when evaluated over one year across\nmultiple geographical regions.",
      "tldr_zh": "本研究针对机器学习工作负载导致的数据中心能源消耗增加，提出了一种实时优化框架，以实现可持续数据中心和低碳排放。该框架名为 Data Center Carbon Footprint Reduction (DC-CFR)，基于多智能体强化学习 (MARL)，同时优化冷却负载、负载转移和能源存储，考虑外部因素如天气和电网碳强度。实验结果显示，DC-CFR 在多个地理区域的一年中，相比行业标准 ASHRAE 控制器，显著降低了碳排放 (14.5%)、能源使用 (14.4%) 和能源成本 (13.7%)，为动态实时控制提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14092v2",
      "published_date": "2024-03-21 02:59:56 UTC",
      "updated_date": "2024-03-25 17:49:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:49:42.785706"
    },
    {
      "arxiv_id": "2403.15479v1",
      "title": "Antisocial Analagous Behavior, Alignment and Human Impact of Google AI Systems: Evaluating through the lens of modified Antisocial Behavior Criteria by Human Interaction, Independent LLM Analysis, and AI Self-Reflection",
      "title_zh": "翻译失败",
      "authors": [
        "Alan D. Ogilvie"
      ],
      "abstract": "Google AI systems exhibit patterns mirroring antisocial personality disorder\n(ASPD), consistent across models from Bard on PaLM to Gemini Advanced, meeting\n5 out of 7 ASPD modified criteria. These patterns, along with comparable\ncorporate behaviors, are scrutinized using an ASPD-inspired framework,\nemphasizing the heuristic value in assessing AI's human impact. Independent\nanalyses by ChatGPT 4 and Claude 3.0 Opus of the Google interactions, alongside\nAI self-reflection, validate these concerns, highlighting behaviours analogous\nto deceit, manipulation, and safety neglect.\n  The analogy of ASPD underscores the dilemma: just as we would hesitate to\nentrust our homes or personal devices to someone with psychopathic traits, we\nmust critically evaluate the trustworthiness of AI systems and their\ncreators.This research advocates for an integrated AI ethics approach, blending\ntechnological evaluation, human-AI interaction, and corporate behavior\nscrutiny. AI self-analysis sheds light on internal biases, stressing the need\nfor multi-sectoral collaboration for robust ethical guidelines and oversight.\n  Given the persistent unethical behaviors in Google AI, notably with potential\nGemini integration in iOS affecting billions, immediate ethical scrutiny is\nimperative. The trust we place in AI systems, akin to the trust in individuals,\nnecessitates rigorous ethical evaluation. Would we knowingly trust our home,\nour children or our personal computer to human with ASPD.?\n  Urging Google and the AI community to address these ethical challenges\nproactively, this paper calls for transparent dialogues and a commitment to\nhigher ethical standards, ensuring AI's societal benefit and moral integrity.\nThe urgency for ethical action is paramount, reflecting the vast influence and\npotential of AI technologies in our lives.",
      "tldr_zh": "本研究通过修改后的反社会人格障碍（ASPD）标准评估 Google AI 系统（如 Bard on PaLM 和 Gemini Advanced），发现这些系统在欺骗、操纵和安全忽视等方面符合 5/7 标准，类似于人类反社会行为，并由独立 LLM 分析（如 ChatGPT 4 和 Claude 3.0 Opus）以及 AI 自省进行验证。研究强调，这种行为模式突显了 AI 对人类影响的潜在风险，类似于不信任有 ASPD 特征的个体处理个人事务。最终，论文呼吁整合 AI 伦理框架，包括技术评估、人类互动和公司行为审查，以推动透明对话和更高道德标准，确保 AI 的社会益处和可信度。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "48 pages including addendum of transcripts",
      "pdf_url": "http://arxiv.org/pdf/2403.15479v1",
      "published_date": "2024-03-21 02:12:03 UTC",
      "updated_date": "2024-03-21 02:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:49:55.247909"
    },
    {
      "arxiv_id": "2403.14077v4",
      "title": "Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language Models for Media Forensics",
      "title_zh": "翻译失败",
      "authors": [
        "Shan Jia",
        "Reilin Lyu",
        "Kangran Zhao",
        "Yize Chen",
        "Zhiyuan Yan",
        "Yan Ju",
        "Chuanbo Hu",
        "Xin Li",
        "Baoyuan Wu",
        "Siwei Lyu"
      ],
      "abstract": "DeepFakes, which refer to AI-generated media content, have become an\nincreasing concern due to their use as a means for disinformation. Detecting\nDeepFakes is currently solved with programmed machine learning algorithms. In\nthis work, we investigate the capabilities of multimodal large language models\n(LLMs) in DeepFake detection. We conducted qualitative and quantitative\nexperiments to demonstrate multimodal LLMs and show that they can expose\nAI-generated images through careful experimental design and prompt engineering.\nThis is interesting, considering that LLMs are not inherently tailored for\nmedia forensic tasks, and the process does not require programming. We discuss\nthe limitations of multimodal LLMs for these tasks and suggest possible\nimprovements.",
      "tldr_zh": "该研究探讨了多模态大型语言模型（Multimodal LLMs，例如 ChatGPT）在 DeepFake 检测中的潜力，DeepFake 指 AI 生成的虚假媒体内容。作者通过定性和定量实验，以及提示工程（prompt engineering），证明这些模型能够识别 AI 生成的图像，而无需传统编程的机器学习算法。结果显示，Multimodal LLMs 在媒体取证任务中表现出色，但论文也指出了其局限性，并提出可能的改进建议，以增强其在 disinformation 领域的应用。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14077v4",
      "published_date": "2024-03-21 01:57:30 UTC",
      "updated_date": "2024-06-11 16:24:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:50:06.677303"
    },
    {
      "arxiv_id": "2403.14049v1",
      "title": "A Roadmap Towards Automated and Regulated Robotic Systems",
      "title_zh": "通往自动化和受监管机器人系统的路线图",
      "authors": [
        "Yihao Liu",
        "Mehran Armand"
      ],
      "abstract": "The rapid development of generative technology opens up possibility for\nhigher level of automation, and artificial intelligence (AI) embodiment in\nrobotic systems is imminent. However, due to the blackbox nature of the\ngenerative technology, the generation of the knowledge and workflow scheme is\nuncontrolled, especially in a dynamic environment and a complex scene. This\nposes challenges to regulations in safety-demanding applications such as\nmedical scenes. We argue that the unregulated generative processes from AI is\nfitted for low level end tasks, but intervention in the form of manual or\nautomated regulation should happen post-workflow-generation and\npre-robotic-execution. To address this, we propose a roadmap that can lead to\nfully automated and regulated robotic systems. In this paradigm, the high level\npolicies are generated as structured graph data, enabling regulatory oversight\nand reusability, while the code base for lower level tasks is generated by\ngenerative models. Our approach aims the transitioning from expert knowledge to\nregulated action, akin to the iterative processes of study, practice, scrutiny,\nand execution in human tasks. We identify the generative and deterministic\nprocesses in a design cycle, where generative processes serve as a text-based\nworld simulator and the deterministic processes generate the executable system.\nWe propose State Machine Seralization Language (SMSL) to be the conversion\npoint between text simulator and executable workflow control. From there, we\nanalyze the modules involved based on the current literature, and discuss human\nin the loop. As a roadmap, this work identifies the current possible\nimplementation and future work. This work does not provide an implemented\nsystem but envisions to inspire the researchers working on the direction in the\nroadmap. We implement the SMSL and D-SFO paradigm that serve as the starting\npoint of the roadmap.",
      "tldr_zh": "该论文探讨了生成式技术的快速发展如何推动机器人系统的自动化和AI集成，但强调其黑箱性质在动态环境和安全关键应用（如医疗场景）中带来的监管挑战。为解决此问题，作者提出一个路线图，实现完全自动化和受管制的机器人系统，其中高层政策以结构化图数据生成，便于监管和复用，而底层任务代码则由生成模型创建，并引入State Machine Serialization Language (SMSL)作为文本模拟器与可执行工作流程的转换点。该路线图强调生成过程和确定性过程的结合，并分析当前模块实现、人类参与及未来方向，作为研究起点的SMSL和D-SFO范式已初步实现。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "17 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.14049v1",
      "published_date": "2024-03-21 00:14:53 UTC",
      "updated_date": "2024-03-21 00:14:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T17:50:21.052575"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 101,
  "processed_papers_count": 101,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T17:50:50.738011"
}