{
  "date": "2025-06-25",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-06-25 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ **å¤§å®¶å¥½**ï¼Œæˆ‘æ˜¯ä½ ä»¬çš„è€æœ‹å‹ï¼Œé‚£ä¸ªå–œæ¬¢åœ¨è®ºæ–‡å †é‡Œåˆ¨æ ¹é—®åº•çš„æ•™æˆã€‚\n\n**ä»Šæ—¥æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv ç®€ç›´æ˜¯ç¥ä»™æ‰“æ¶ã€‚é¦–å…ˆï¼Œ**Yoshua Bengio** é¢†è¡”å…¨çƒé¡¶å°–å­¦è€…å‘å¸ƒäº†å…³äº **AI å®‰å…¨çš„â€œæ–°åŠ å¡å…±è¯†â€**ï¼Œè¿™æ˜¯ä¸€ä»½é‡é‡çº§çš„æ”¿ç­–ä¸æŠ€æœ¯è·¯çº¿å›¾ã€‚æŠ€æœ¯å±‚é¢ï¼Œ**â€œReasoningï¼ˆæ¨ç†ï¼‰â€** ä¾ç„¶æ˜¯æ ¸å¿ƒå…³é”®è¯ï¼Œä»å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨ Post-training ä¸­çš„ scaling lawï¼Œåˆ°è®© Ranker å…·å¤‡æ¨ç†èƒ½åŠ›ï¼Œå†åˆ°å¤šæ™ºèƒ½ä½“çš„å¿ƒæ™ºç†è®ºï¼ˆTheory of Mindï¼‰åšå¼ˆï¼Œå¤§å®¶éƒ½åœ¨è¯•å›¾è®©æ¨¡å‹â€œæƒ³â€å¾—æ›´æ·±ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ç¯‡éå¸¸æœ‰æ„æ€çš„ **Meta-Science** ç ”ç©¶ï¼Œç‹ ç‹ åœ°ç»™â€œAI ç”Ÿæˆç§‘ç ”ç‚¹å­â€æ³¼äº†ä¸€ç›†å†·æ°´â€”â€”ç‚¹å­å¬ç€ä¸é”™ï¼Œåšå‡ºæ¥å´ä¸è¡Œã€‚\n\nä¸‹é¢è®©æˆ‘ä»¬æ½œå…¥ä»Šå¤©çš„ç²¾åå†…å®¹ï¼š\n\n---\n\n### ğŸš€ é‡ç£…æ¨èï¼šå®‰å…¨å…±è¯†ä¸ç§‘ç ”åæ€\n\n#### 1. **æ–°åŠ å¡å…¨çƒ AI å®‰å…¨ç ”ç©¶é‡ç‚¹å…±è¯†**\n**# title: The Singapore Consensus on Global AI Safety Research Priorities**\n> **Authors:** Yoshua Bengio, Stuart Russell, Max Tegmark, et al. (å…¨æ˜æ˜Ÿé˜µå®¹)\n\n**æ•™æˆç‚¹è¯„ï¼š** è¿™ä¸æ˜¯ä¸€ç¯‡æ™®é€šçš„æŠ€æœ¯è®ºæ–‡ï¼Œè€Œæ˜¯ **AI å®‰å…¨é¢†åŸŸçš„çº²é¢†æ€§æ–‡ä»¶**ã€‚ç”± Bengio ç‰µå¤´ï¼Œæ±‡é›†äº†å›¾çµå¥–å¾—ä¸»å’Œå…¨çƒ 33 ä¸ªæ”¿åºœçš„æ”¯æŒã€‚\n**æ ¸å¿ƒå†…å®¹ï¼š** æŠ¥å‘Šæå‡ºäº†â€œçºµæ·±é˜²å¾¡ï¼ˆdefence-in-depthï¼‰â€æ¨¡å‹ï¼Œå°† AI å®‰å…¨ç ”ç©¶åˆ’åˆ†ä¸ºä¸‰å¤§ä¼˜å…ˆçº§ï¼š\n1.  **å¼€å‘ï¼ˆDevelopmentï¼‰ï¼š** å¦‚ä½•æ„å»ºæœ¬è´¨ä¸Šå¯ä¿¡çš„ AI ç³»ç»Ÿã€‚\n2.  **è¯„ä¼°ï¼ˆAssessmentï¼‰ï¼š** å¦‚ä½•åœ¨éƒ¨ç½²å‰å‡†ç¡®è¡¡é‡é£é™©ã€‚\n3.  **æ§åˆ¶ï¼ˆControlï¼‰ï¼š** å¦‚ä½•åœ¨éƒ¨ç½²åç›‘æ§å’Œå¹²é¢„ã€‚\n**Implicationï¼š** è¿™å°†æ˜¯æœªæ¥å‡ å¹´ AI å®‰å…¨èµ„é‡‘åˆ†é…å’Œç ”ç©¶æ–¹å‘çš„é£å‘æ ‡ã€‚\n\n#### 2. **æ„æƒ³ä¸æ‰§è¡Œçš„é¸¿æ²Ÿï¼šLLM ç”Ÿæˆçš„ç ”ç©¶ç‚¹å­ vs äººç±»ä¸“å®¶ç‚¹å­**\n**# title: The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas**\n**æ•™æˆç‚¹è¯„ï¼š** è¿™ç¯‡æ–‡ç« å¤ªæœ‰è¶£äº†ï¼å¤§å®¶éƒ½è¯´ AI èƒ½åšç§‘ç ”ï¼Œä½†çœŸçš„èƒ½è¡Œå—ï¼Ÿ\n**æ ¸å¿ƒå‘ç°ï¼š** ä¹‹å‰çš„ç ”ç©¶è¯´ LLM ç”Ÿæˆçš„ç‚¹å­æ›´æœ‰â€œæ–°æ„â€ï¼Œä½†è¿™é¡¹ç ”ç©¶åšäº†**æ‰§è¡Œæµ‹è¯•**ã€‚ä»–ä»¬æ‰¾äº† 43 ä½ä¸“å®¶çœŸçš„å»æ‰§è¡Œè¿™äº›ç‚¹å­ï¼ˆæ¯äººèŠ± 100+ å°æ—¶å†™ä»£ç ã€å†™è®ºæ–‡ï¼‰ã€‚\n**ç»“æœï¼š** æ­¤æ—¶åè½¬æ¥äº†ã€‚è™½ç„¶ LLM çš„ç‚¹å­åœ¨â€œæ„æƒ³é˜¶æ®µâ€çœ‹ç€ä¸é”™ï¼Œä½†åœ¨**æ‰§è¡Œå**çš„åŒè¡Œè¯„å®¡ä¸­ï¼Œè¯„åˆ†å¤§å¹…ä¸‹é™ï¼Œæ˜¾è‘—ä½äºäººç±»ä¸“å®¶çš„ç‚¹å­ã€‚\n**ç»“è®ºï¼š** ç›®å‰çš„ LLM æ“…é•¿ç”Ÿæˆâ€œå¬èµ·æ¥å¾ˆç¾â€çš„è™šå¹»ç‚¹å­ï¼Œä½†ç¼ºä¹è½åœ°å¯è¡Œæ€§å’Œæ·±åº¦ã€‚æˆ‘ä»¬è¯„ä¼°ç§‘ç ” AI æ—¶ï¼Œä¸èƒ½åªçœ‹ Ideaï¼Œå¿…é¡»çœ‹ Executionã€‚\n\n---\n\n### ğŸ§  LLM æ¨ç†ã€å¼ºåŒ–å­¦ä¹ ä¸æ™ºèƒ½ä½“\n\n#### 3. **OctoThinkerï¼šMid-training æ¿€åŠ±å¼ºåŒ–å­¦ä¹ çš„ Scaling**\n**# title: OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** æ¢è®¨äº†ä¸ºä»€ä¹ˆæœ‰äº›åŸºåº§æ¨¡å‹ï¼ˆå¦‚ Qwenï¼‰æ¯”å…¶ä»–çš„ï¼ˆå¦‚ Llamaï¼‰æ›´é€‚åˆè·‘ RLHF/RLã€‚\n**ä¸»è¦å‘ç°ï¼š**\n*   **Mid-training ç­–ç•¥ï¼š** ä½œè€…æå‡ºäº†â€œStable-then-Decayâ€çš„ä¸¤é˜¶æ®µè®­ç»ƒæ³•ã€‚å…ˆç”±é«˜è´¨é‡æ•°å­¦è¯­æ–™ï¼ˆMegaMath-Web-Proï¼‰è®­ç»ƒï¼Œå†å¼•å…¥é•¿æ€ç»´é“¾ï¼ˆLong CoTï¼‰æ•°æ®ã€‚\n*   **ç»“è®ºï¼š** è¿™ç§ Mid-training èƒ½æ˜¾è‘—æå‡æ¨¡å‹åœ¨åç»­ RL é˜¶æ®µçš„ä¸Šé™ã€‚ä»–ä»¬å‘å¸ƒçš„ **OctoThinker** æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å¼ºåŠ²ã€‚\n\n#### 4. **R1-Rankerï¼šæ•™ LLM æ’åºæ¨¡å‹å­¦ä¼šæ¨ç†**\n**# title: R1-Ranker: Teaching LLM Rankers to Reason**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** å°†æœ€è¿‘ç«çƒ­çš„æ¨ç†èƒ½åŠ›ï¼ˆReasoningï¼‰å¼•å…¥åˆ°æ¨èå’Œæ£€ç´¢çš„ **Ranking** ä»»åŠ¡ä¸­ã€‚\n**æ–¹æ³•ï¼š** æå‡ºäº† **R1-Ranker** æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªå˜ä½“ï¼š\n*   **DRankerï¼š** ä¸€æ¬¡æ€§ç”Ÿæˆå®Œæ•´æ’åã€‚\n*   **IRankerï¼š** é‡‡ç”¨è¿­ä»£æ¶ˆé™¤ï¼ˆIterative eliminationï¼‰çš„æ–¹å¼ï¼Œé€šè¿‡é€æ­¥æ¨ç†æ¥å‰”é™¤é€‰é¡¹ã€‚\n**æ•ˆæœï¼š** IRanker-3B åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡»è´¥äº† 7B çš„æ¨¡å‹ï¼Œè¯æ˜äº†â€œæ…¢æ€è€ƒâ€åœ¨æ’åºä»»åŠ¡ä¸­ä¹Ÿæœ‰æ•ˆã€‚\n\n#### 5. **Decryptoï¼šå¤šæ™ºèƒ½ä½“æ¨ç†ä¸å¿ƒæ™ºç†è®ºåŸºå‡†**\n**# title: The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** è¿™æ˜¯ä¸€ä¸ªåŸºäºæ¸¸æˆçš„å¤šæ™ºèƒ½ä½“åšå¼ˆåŸºå‡†ï¼Œä¸“é—¨æµ‹è¯• **å¿ƒæ™ºç†è®º (Theory of Mind, ToM)**ã€‚\n**å‘ç°ï¼š** å³ä¾¿æ˜¯æœ€å…ˆè¿›çš„æ¨ç†æ¨¡å‹ï¼ˆSOTA Reasoning Modelsï¼‰ï¼Œåœ¨éœ€è¦æ¨æµ‹å¯¹æ‰‹å¿ƒç†çŠ¶æ€çš„åšå¼ˆä¸­ï¼Œè¡¨ç°ç”šè‡³ä¸å¦‚ä¸€äº›è€æ¨¡å‹ï¼Œä¸”æ˜¾è‘—å¼±äºäººç±»ã€‚è¿™è¡¨æ˜ç›®å‰çš„â€œæ¨ç†â€æ›´å¤šæ˜¯é€»è¾‘æ¨ç†ï¼Œè€Œéç¤¾ä¼šè®¤çŸ¥æ¨ç†ã€‚\n\n#### 6. **Mobile-R1ï¼šåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„ç§»åŠ¨ç«¯æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ **\n**# title: Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** é’ˆå¯¹æ‰‹æœºæ“ä½œæ™ºèƒ½ä½“ï¼ˆMobile Agentï¼‰ï¼Œæå‡ºäº†ä¸€ç§ä»»åŠ¡çº§å¥–åŠ±çš„äº¤äº’å¼å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚\n**æ–¹æ³•ï¼š** ç›¸æ¯”äºä¼ ç»Ÿçš„ Action-level rewardï¼ŒMobile-R1 ä½¿ç”¨å¤šè½®äº¤äº’çš„ Task-level rewardï¼Œç»“åˆ GRPOï¼ˆGroup Relative Policy Optimizationï¼‰ï¼Œè®©æ™ºèƒ½ä½“å­¦ä¼šè‡ªæˆ‘çº é”™å’Œæ¢ç´¢ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ã€éšç§ä¸é—å¿˜\n\n#### 7. **ç±»é—å¿˜ï¼ˆClass Unlearningï¼‰ä¸­çš„åˆ†å¸ƒé‡åŠ æƒå¿…è¦æ€§**\n**# title: On the Necessity of Output Distribution Reweighting for Effective Class Unlearning**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** æŒ‡å‡ºç°æœ‰çš„æœºå™¨é—å¿˜ï¼ˆUnlearningï¼‰æ–¹æ³•å®¹æ˜“å—åˆ° **MIA-NN**ï¼ˆåŸºäºæœ€è¿‘é‚»çš„æˆå‘˜æ¨ç†æ”»å‡»ï¼‰çš„å½±å“ï¼Œå¯¼è‡´éšç§æ³„éœ²ã€‚\n**æ–¹æ³•ï¼š** æå‡ºäº† **TRW (Tilted ReWeighting)**ï¼Œé€šè¿‡æ¨¡æ‹Ÿâ€œä»å¤´è®­ç»ƒâ€æ¨¡å‹çš„åˆ†å¸ƒå‡ ä½•ï¼Œæ¥é‡æ–°åŠ æƒé—å¿˜ç±»çš„è¾“å‡ºåˆ†å¸ƒï¼Œåœ¨ CIFAR-10 ä¸Šæ˜¾è‘—é™ä½äº†éšç§é£é™©ã€‚\n\n#### 8. **RedCoderï¼šä»£ç å¤§æ¨¡å‹çš„è‡ªåŠ¨åŒ–å¤šè½®çº¢é˜Ÿæµ‹è¯•**\n**# title: RedCoder: Automated Multi-Turn Red Teaming for Code LLMs**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** é’ˆå¯¹ Code LLM çš„å®‰å…¨æ¼æ´ï¼Œæå‡ºäº†ä¸€ä¸ªè‡ªåŠ¨åŒ–çº¢é˜Ÿ Agentã€‚\n**äº®ç‚¹ï¼š** å®ƒæ˜¯**å¤šè½®ï¼ˆMulti-turnï¼‰**çš„ã€‚æ”»å‡»è€… Agent ä¼šåœ¨å¯¹è¯ä¸­ä¸€æ­¥æ­¥è¯±å¯¼æ¨¡å‹å†™å‡ºæœ‰æ¼æ´çš„ä»£ç ï¼Œæ¯”å•è½®æ”»å‡»æ›´ç¬¦åˆç°å®åœºæ™¯ï¼Œæ”»å‡»æˆåŠŸç‡ä¹Ÿæ›´é«˜ã€‚\n\n#### 9. **SABRE-FLï¼šè”é‚¦æç¤ºå­¦ä¹ ä¸­çš„åé—¨é˜²å¾¡**\n**# title: SABRE-FL: Selective and Accurate Backdoor Rejection for Federated Prompt Learning**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** é’ˆå¯¹è”é‚¦å­¦ä¹ ä¸­çš„ Prompt Learningï¼ˆå¦‚ CLIP çš„å¾®è°ƒï¼‰ï¼Œç ”ç©¶äº†åé—¨æ”»å‡»ã€‚\n**é˜²å¾¡ï¼š** æå‡ºäº† SABRE-FLï¼Œæ— éœ€è®¿é—®å®¢æˆ·ç«¯åŸå§‹æ•°æ®ï¼Œä»…é€šè¿‡ Embedding ç©ºé—´çš„å¼‚å¸¸æ£€æµ‹å°±èƒ½è¿‡æ»¤æ‰æ¶æ„çš„ Prompt æ›´æ–°ã€‚\n\n---\n\n### âš¡ ç³»ç»Ÿä¼˜åŒ–ä¸ç¡¬ä»¶åŠ é€Ÿ\n\n#### 10. **Omniwiseï¼šç”¨ LLM é¢„æµ‹ GPU Kernel æ€§èƒ½**\n**# title: Omniwise: Predicting GPU Kernels Performance with LLMs**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** è¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„ç®¡é“ï¼Œç”¨ LLM ç›´æ¥çœ‹ GPU Kernel ä»£ç ï¼ˆæ— éœ€è¿è¡Œï¼‰æ¥é¢„æµ‹æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚å†…å­˜å¸¦å®½ã€GFLOPsï¼‰ã€‚\n**æ•ˆæœï¼š** å³ä¾¿æ˜¯ 3B çš„å°æ¨¡å‹ï¼Œåœ¨ AMD MI250/MI300X ä¸Šä¹Ÿèƒ½è¾¾åˆ°æé«˜çš„é¢„æµ‹å‡†ç¡®ç‡ã€‚è¿™å¯¹äºç¼–è¯‘å™¨ä¼˜åŒ–å’Œæ€§èƒ½åˆ†ææ˜¯å·¨å¤§çš„æ•ˆç‡æå‡ã€‚\n\n#### 11. **GPU Kernel Scientistï¼šLLM é©±åŠ¨çš„ Kernel è¿­ä»£ä¼˜åŒ–**\n**# title: GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** è¿™æ˜¯ä¸€ä¸ª AI Agentï¼Œä¸ä»…èƒ½å†™ GPU Kernelï¼Œè¿˜èƒ½åƒç§‘å­¦å®¶ä¸€æ ·æå‡ºå‡è®¾ã€ä¿®æ”¹ä»£ç ã€åŸºäºè¿è¡Œæ—¶é—´åé¦ˆè¿›è¡Œè¿›åŒ–è¿­ä»£ã€‚\n\n#### 12. **DipSVDï¼šé«˜æ•ˆ LLM å‹ç¼©çš„åŒé‡é‡è¦æ€§ä¿æŠ¤ SVD**\n**# title: DipSVD: Dual-importance Protected SVD for Efficient LLM Compression**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** æ”¹è¿›äº† SVDï¼ˆå¥‡å¼‚å€¼åˆ†è§£ï¼‰å‹ç¼©æ–¹æ³•ã€‚ä¼ ç»Ÿçš„ SVD å®¹æ˜“ç ´åçŸ©é˜µä¸­çš„å…³é”®ç»„ä»¶ï¼ŒDipSVD å¼•å…¥äº†å±€éƒ¨å’Œå…¨å±€çš„é‡è¦æ€§ä¿æŠ¤æœºåˆ¶ï¼Œåœ¨é«˜å‹ç¼©æ¯”ä¸‹ä¿ç•™äº†æ›´å¤šæ¨¡å‹æ€§èƒ½ã€‚\n\n---\n\n### ğŸ§ª ç§‘å­¦ AI (AI for Science)\n\n#### 13. **DeepQuarkï¼šå¤šå¤¸å…‹æŸç¼šæ€çš„æ·±åº¦ç¥ç»ç½‘ç»œæ–¹æ³•**\n**# title: DeepQuark: deep-neural-network approach to multiquark bound states**\n**æ ¸å¿ƒå­¦æœ¯æœ¯è¯­ï¼š** Variational Monte Carlo, Multiquark systems.\n**è´¡çŒ®ï¼š** ç”¨æ·±åº¦å­¦ä¹ è§£å†³é‡å­è‰²åŠ¨åŠ›å­¦ï¼ˆQCDï¼‰ä¸­çš„å¤šä½“é—®é¢˜ã€‚è®¾è®¡äº† DeepQuark æ¶æ„æ¥å¤„ç†å¤šå¤¸å…‹ç³»ç»Ÿçš„å¤æ‚å…³è”ï¼ŒæˆåŠŸæ¨¡æ‹Ÿäº†äº”å¤¸å…‹æ€ï¼Œè®¡ç®—æ•ˆç‡è¿œè¶…ä¼ ç»Ÿè’™ç‰¹å¡æ´›æ–¹æ³•ã€‚\n\n#### 14. **MVPFormerï¼šè„‘ç”µå›¾ï¼ˆiEEGï¼‰çš„åŸºç¡€æ¨¡å‹**\n**# title: A foundation model with multi-variate parallel attention to generate neuronal activity**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** å‘å¸ƒäº†è¿„ä»Šä¸ºæ­¢æœ€å¤§çš„ iEEG æ•°æ®é›†ï¼ˆSWEC, 10,000å°æ—¶ï¼‰ï¼Œå¹¶æå‡ºäº† **MVPFormer**ã€‚è¿™æ˜¯ä¸€ä¸ªç”Ÿæˆå¼åŸºç¡€æ¨¡å‹ï¼Œåˆ©ç”¨å¤šå˜é‡å¹¶è¡Œæ³¨æ„åŠ›æœºåˆ¶ï¼ˆMVPAï¼‰æ¥é¢„æµ‹ç¥ç»å…ƒæ´»åŠ¨ï¼Œåœ¨ç™«ç—«æ£€æµ‹ç­‰ä»»åŠ¡ä¸Šè¾¾åˆ° SOTAã€‚\n\n---\n\n### ğŸ‘ï¸ è§†è§‰ä¸å¤šæ¨¡æ€\n\n#### 15. **BrokenVideosï¼šAI ç”Ÿæˆè§†é¢‘çš„ä¼ªå½±å®šä½åŸºå‡†**\n**# title: BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** ç°åœ¨çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ç”Ÿæˆçš„è§†é¢‘æ€»æœ‰äº›æ€ªæ€ªçš„åœ°æ–¹ï¼ˆæ—¶åºä¸ä¸€è‡´ã€ç‰©ç†æ‰­æ›²ï¼‰ã€‚è¿™ä¸ªæ•°æ®é›†ä¸“é—¨æ ‡æ³¨äº†è¿™äº›â€œå´©åâ€çš„åŒºåŸŸï¼ˆArtifactsï¼‰ï¼Œç”¨äºè®­ç»ƒæ£€æµ‹æ¨¡å‹å’ŒæŒ‡å¯¼ç”Ÿæˆæ¨¡å‹æ”¹è¿›ã€‚\n\n#### 16. **PLADAï¼šå…³æ³¨å‹ç¼©å Deepfake çš„é²æ£’æ£€æµ‹**\n**# title: Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks**\n**æ ¸å¿ƒè´¡çŒ®ï¼š** ç¤¾äº¤ç½‘ç»œä¸Šçš„å›¾ç‰‡ä¼šè¢«å‹ç¼©ï¼Œå¯¼è‡´ Deepfake çš„ç—•è¿¹ï¼ˆArtifactsï¼‰å˜æ¨¡ç³Šã€‚PLADA æå‡ºäº†ä¸€ç§â€œå—æ•ˆåº”æ¶ˆé™¤â€æ¨¡å—ï¼Œä¸“é—¨é’ˆå¯¹è¿™ç§å‹ç¼©ç¯å¢ƒä¸‹çš„ Deepfake è¿›è¡Œæ£€æµ‹ï¼Œæ›´åŠ å®æˆ˜åŒ–ã€‚\n\n---\n\n### ğŸ“ å…¶ä»–å€¼å¾—å…³æ³¨çš„çŸ­è®¯\n\n*   **RAG è¯„æµ‹æ–°æ¡†æ¶ï¼š** **# title: CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation**\n    æå‡ºäº† CCRS æŒ‡æ ‡ä½“ç³»ï¼Œç”¨å•ä¸ªå¼ºåŠ› LLM å¯¹ RAG çš„è¿è´¯æ€§ã€ç›¸å…³æ€§ã€ä¿¡æ¯å¯†åº¦ç­‰ 5 ä¸ªç»´åº¦è¿›è¡Œ Zero-shot è¯„åˆ†ï¼Œæ¯”ç°æœ‰æ–¹æ³•æ›´é«˜æ•ˆä¸”åŒºåˆ†åº¦æ›´å¥½ã€‚\n\n*   **AI è¾…åŠ©ç§‘ç ”å¤ç°ï¼š** **# title: AI Copilots for Reproducibility in Science: A Case Study**\n    ä¸€ä¸ª AI Copilotï¼Œèƒ½å¤Ÿé˜…è¯»è®ºæ–‡å’Œä»£ç ï¼Œè‡ªåŠ¨ç”Ÿæˆ Jupyter Notebook æ¥å¤ç°å®éªŒç»“æœã€‚åˆæ­¥æµ‹è¯•èƒ½å°†å¤ç°æ—¶é—´ä» 30 å°æ—¶ç¼©çŸ­åˆ° 1 å°æ—¶ã€‚\n\n*   **LLM è‡ªåŠ¨å‘ç°æ¨¡å‹æ¶æ„ï¼š** **# title: Language Modeling by Language Models**\n    æå‡ºäº† **Genesys** ç³»ç»Ÿï¼Œåˆ©ç”¨ LLM è¿›è¡Œæ¶æ„æœç´¢ï¼ˆNASï¼‰ï¼Œè‡ªåŠ¨æå‡ºã€å®ç°å¹¶éªŒè¯æ–°çš„è¯­è¨€æ¨¡å‹æ¶æ„ï¼Œå‘ç°äº†ä¸€äº›ä¼˜äº GPT-2/Mamba2 çš„è®¾è®¡ã€‚\n\n---\n**æ•™æˆç»“è¯­ï¼š**\nä»Šå¤©çš„ä¿¡æ¯é‡éå¸¸å¤§ã€‚å¦‚æœä½ å…³æ³¨ LLM çš„æœªæ¥ï¼Œè¯·åŠ¡å¿…ç»†è¯» **OctoThinker** å’Œ **R1-Ranker**ï¼Œè¿™ä»£è¡¨äº† RL å’Œæ¨ç†èƒ½åŠ›çš„ç»“åˆè¶‹åŠ¿ã€‚å¦‚æœä½ æ˜¯ AI ä»ä¸šè€…ï¼Œ**æ–°åŠ å¡å…±è¯†** å€¼å¾—ä¸€çœ‹ï¼Œäº†è§£æœªæ¥çš„åˆè§„è¾¹ç•Œã€‚æœ€åï¼Œåˆ«å¿˜äº†é‚£ç¯‡å…³äº **Ideation-Execution Gap** çš„è®ºæ–‡ï¼Œå®ƒæé†’æˆ‘ä»¬ï¼šTalk is cheap, show me the code (and results).\n\næ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2506.20893v4",
      "title": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning",
      "title_zh": "è®ºè¾“å‡ºåˆ†å¸ƒé‡åŠ æƒå¯¹äºå®ç°æœ‰æ•ˆç±»åˆ«é—å¿˜çš„å¿…è¦æ€§",
      "authors": [
        "Ali Ebrahimpour-Boroojeny",
        "Yian Wang",
        "Hari Sundaram"
      ],
      "abstract": "In this paper, we reveal a significant shortcoming in class unlearning evaluations: overlooking the underlying class geometry can cause privacy leakage. We further propose a simple yet effective solution to mitigate this issue. We introduce a membership-inference attack via nearest neighbors (MIA-NN) that uses the probabilities the model assigns to neighboring classes to detect unlearned samples. Our experiments show that existing unlearning methods are vulnerable to MIA-NN across multiple datasets. We then propose a new fine-tuning objective that mitigates this privacy leakage by approximating, for forget-class inputs, the distribution over the remaining classes that a retrained-from-scratch model would produce. To construct this approximation, we estimate inter-class similarity and tilt the target model's distribution accordingly. The resulting Tilted ReWeighting (TRW) distribution serves as the desired distribution during fine-tuning. We also show that across multiple benchmarks, TRW matches or surpasses existing unlearning methods on prior unlearning metrics. More specifically, on CIFAR-10, it reduces the gap with retrained models by 19% and 46% for U-LiRA and MIA-NN scores, accordingly, compared to the SOTA method for each category.",
      "tldr_zh": "è¯¥ç ”ç©¶æ­ç¤ºäº†ç±»åˆ«é—å¿˜ (class unlearning) è¯„ä¼°ä¸­å­˜åœ¨çš„æ˜¾è‘—ç¼ºé™·ï¼Œå³å¿½è§†åº•å±‚ç±»åˆ«å‡ ä½•ç»“æ„å¯èƒ½å¯¼è‡´éšç§æ³„éœ²ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸºäºæœ€è¿‘é‚»çš„æˆå‘˜æ¨ç†æ”»å‡» (MIA-NN)ï¼Œåˆ©ç”¨æ¨¡å‹åˆ†é…ç»™ç›¸é‚»ç±»åˆ«çš„æ¦‚ç‡æ¥æ£€æµ‹å·²é—å¿˜æ ·æœ¬ï¼Œå¹¶è¯å®äº†ç°æœ‰é—å¿˜æ–¹æ³•å¯¹ MIA-NN çš„è„†å¼±æ€§ã€‚ä¸ºç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶å¼•å…¥äº† Tilted ReWeighting (TRW) ç­–ç•¥ï¼Œé€šè¿‡ä¼°è®¡ç±»åˆ«é—´çš„ç›¸ä¼¼åº¦å¹¶ç›¸åº”è°ƒæ•´ç›®æ ‡æ¨¡å‹çš„åˆ†å¸ƒï¼Œä½¿å…¶åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­é€¼è¿‘ä»å¤´é‡è®­ (retrained-from-scratch) æ¨¡å‹çš„è¾“å‡ºåˆ†å¸ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTRW åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°æˆ–è¶…è¶Šäº†ç°æœ‰é—å¿˜æ–¹æ³•ï¼Œåœ¨ CIFAR-10 æ•°æ®é›†ä¸Šï¼Œå…¶ U-LiRA å’Œ MIA-NN å¾—åˆ†ä¸é‡è®­ç»ƒæ¨¡å‹çš„å·®è·è¾ƒ SOTA æ–¹æ³•åˆ†åˆ«ç¼©å°äº† 19% å’Œ 46%ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20893v4",
      "published_date": "2025-06-25 23:53:56 UTC",
      "updated_date": "2025-11-14 17:27:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:20:34.853235+00:00"
    },
    {
      "arxiv_id": "2506.20886v1",
      "title": "Omniwise: Predicting GPU Kernels Performance with LLMs",
      "title_zh": "Omniwiseï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ GPU å†…æ ¸æ€§èƒ½é¢„æµ‹",
      "authors": [
        "Zixian Wang",
        "Cole Ramos",
        "Muhammad A. Awad",
        "Keith Lowery"
      ],
      "abstract": "In recent years, the rapid advancement of deep neural networks (DNNs) has revolutionized artificial intelligence, enabling models with unprecedented capabilities in understanding, generating, and processing complex data. These powerful architectures have transformed a wide range of downstream applications, tackling tasks beyond human reach. In this paper, we introduce Omniwise, the first end-to-end, self-supervised fine-tuning pipeline that applies large language models (LLMs) to GPU kernel performance prediction--a novel use case in performance profiling. Omniwise is model-agnostic and lightweight, achieving strong results even with a small 3B-parameter model. It can predict key performance metrics, including memory bandwidth, cache hit rates, GFLOPs, and arithmetic intensity, directly from kernel code without the need for code execution or profiling tools. Our approach achieves over 90% of predictions within 10% relative error on GPU kernels executed on AMD MI250 and MI300X architectures. In addition to the pipeline, we develop an online inference server and a Visual Studio Code plugin that seamlessly integrate LLM-based performance prediction into developers' workflows.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº† Omniwiseï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) è¿›è¡Œ GPU kernel æ€§èƒ½é¢„æµ‹çš„ç«¯åˆ°ç«¯ã€è‡ªç›‘ç£å¾®è°ƒæµæ°´çº¿ã€‚Omniwise å…·æœ‰æ¨¡å‹æ— å…³ä¸”è½»é‡åŒ–çš„ç‰¹ç‚¹ï¼Œå³ä½¿åœ¨ä½¿ç”¨ 3B å‚æ•°çš„å°å‹æ¨¡å‹æ—¶ä¹Ÿèƒ½å±•ç°å‡ºå¼ºå¤§çš„é¢„æµ‹èƒ½åŠ›ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿç›´æ¥ä» kernel ä»£ç ä¸­é¢„æµ‹å†…å­˜å¸¦å®½ (memory bandwidth)ã€ç¼“å­˜å‘½ä¸­ç‡ (cache hit rates)ã€GFLOPs å’Œç®—æœ¯å¼ºåº¦ (arithmetic intensity)ï¼Œæ— éœ€å®é™…æ‰§è¡Œä»£ç æˆ–å€ŸåŠ©ä¼ ç»Ÿçš„æ€§èƒ½åˆ†æå·¥å…· (profiling tools)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ AMD MI250 å’Œ MI300X æ¶æ„ä¸Šï¼ŒOmniwise è¶…è¿‡ 90% çš„é¢„æµ‹ç»“æœç›¸å¯¹è¯¯å·®æ§åˆ¶åœ¨ 10% ä»¥å†…ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜é…å¥—å¼€å‘äº†åœ¨çº¿æ¨ç†æœåŠ¡å™¨å’Œ Visual Studio Code æ’ä»¶ï¼Œå®ç°äº†å°†åŸºäº LLM çš„æ€§èƒ½é¢„æµ‹æ— ç¼é›†æˆåˆ°å¼€å‘è€…çš„æ—¥å¸¸å·¥ä½œæµä¸­ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20886v1",
      "published_date": "2025-06-25 23:36:44 UTC",
      "updated_date": "2025-06-25 23:36:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:20:35.133662+00:00"
    },
    {
      "arxiv_id": "2506.22506v1",
      "title": "SABRE-FL: Selective and Accurate Backdoor Rejection for Federated Prompt Learning",
      "title_zh": "SABRE-FLï¼šé¢å‘è”é‚¦æç¤ºå­¦ä¹ çš„é€‰æ‹©æ€§ç²¾å‡†åé—¨å‰”é™¤",
      "authors": [
        "Momin Ahmad Khan",
        "Yasra Chandio",
        "Fatima Muhammad Anwar"
      ],
      "abstract": "Federated Prompt Learning has emerged as a communication-efficient and privacy-preserving paradigm for adapting large vision-language models like CLIP across decentralized clients. However, the security implications of this setup remain underexplored. In this work, we present the first study of backdoor attacks in Federated Prompt Learning. We show that when malicious clients inject visually imperceptible, learnable noise triggers into input images, the global prompt learner becomes vulnerable to targeted misclassification while still maintaining high accuracy on clean inputs. Motivated by this vulnerability, we propose SABRE-FL, a lightweight, modular defense that filters poisoned prompt updates using an embedding-space anomaly detector trained offline on out-of-distribution data. SABRE-FL requires no access to raw client data or labels and generalizes across diverse datasets. We show, both theoretically and empirically, that malicious clients can be reliably identified and filtered using an embedding-based detector. Across five diverse datasets and four baseline defenses, SABRE-FL outperforms all baselines by significantly reducing backdoor accuracy while preserving clean accuracy, demonstrating strong empirical performance and underscoring the need for robust prompt learning in future federated systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è”é‚¦æç¤ºå­¦ä¹ (Federated Prompt Learning)çš„å®‰å…¨é£é™©è¿›è¡Œäº†é¦–æ¬¡æ·±å…¥æ¢è®¨ï¼ŒæŒ‡å‡ºåœ¨åˆ©ç”¨CLIPç­‰å¤§è§†è§‰è¯­è¨€æ¨¡å‹æ—¶ï¼Œæ¶æ„å®¢æˆ·ç«¯å¯èƒ½æ³¨å…¥è§†è§‰ä¸Šä¸å¯å¯Ÿè§‰çš„è§¦å‘å™¨ï¼Œå¯¼è‡´å…¨å±€æç¤ºå­¦ä¹ è€…é¢ä¸´å®šå‘è¯¯åˆ†ç±»çš„åé—¨æ”»å‡»å¨èƒã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†SABRE-FLï¼Œè¿™æ˜¯ä¸€ç§è½»é‡çº§ä¸”æ¨¡å—åŒ–çš„é˜²å¾¡æ¡†æ¶ï¼Œæ—¨åœ¨è¿‡æ»¤å—æ±¡æŸ“çš„æç¤ºæ›´æ–°ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªåœ¨ç¦»çº¿åˆ†å¸ƒå¤–æ•°æ®(out-of-distribution data)ä¸Šè®­ç»ƒçš„åµŒå…¥ç©ºé—´å¼‚å¸¸æ£€æµ‹å™¨(embedding-space anomaly detector)ï¼Œç”¨äºè¯†åˆ«å¹¶å‰”é™¤æ¶æ„æ›´æ–°ã€‚SABRE-FL ä¸éœ€è¦è®¿é—®å®¢æˆ·ç«¯çš„åŸå§‹æ•°æ®æˆ–æ ‡ç­¾ï¼Œåœ¨ä¿è¯éšç§çš„åŒæ—¶å±•ç°äº†è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨äº”ä¸ªå¤šæ ·åŒ–æ•°æ®é›†ä¸Šï¼ŒSABRE-FL åœ¨æ˜¾è‘—é™ä½åé—¨å‡†ç¡®ç‡(backdoor accuracy)çš„åŒæ—¶ï¼Œæœ‰æ•ˆä¿æŒäº†å¹²å‡€è¾“å…¥çš„å‡†ç¡®ç‡ï¼Œæ€§èƒ½ä¼˜äºå¤šç§åŸºå‡†é˜²å¾¡æ–¹æ³•ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨æœªæ¥è”é‚¦ç³»ç»Ÿä¸­æ„å»ºé²æ£’æç¤ºå­¦ä¹ æœºåˆ¶çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.22506v1",
      "published_date": "2025-06-25 23:15:20 UTC",
      "updated_date": "2025-06-25 23:15:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:20:34.577782+00:00"
    },
    {
      "arxiv_id": "2506.20883v2",
      "title": "Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance",
      "title_zh": "ç»“åˆä¸ç¡®å®šæ€§äººç±»æŒ‡å¯¼çš„å¼ºåŒ–å­¦ä¹ å¤æ‚æ¨¡å‹è½¬æ¢",
      "authors": [
        "Kyanna Dagenais",
        "Istvan David"
      ],
      "abstract": "Model-driven engineering problems often require complex model transformations (MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of such problems include model synchronization, automated model repair, and design space exploration. Manually developing complex MTs is an error-prone and often infeasible process. Reinforcement learning (RL) is an apt way to alleviate these issues. In RL, an autonomous agent explores the state space through trial and error to identify beneficial sequences of actions, such as MTs. However, RL methods exhibit performance issues in complex problems. In these situations, human guidance can be of high utility. In this paper, we present an approach and technical framework for developing complex MT sequences through RL, guided by potentially uncertain human advice. Our framework allows user-defined MTs to be mapped onto RL primitives, and executes them as RL programs to find optimal MT sequences. Our evaluation shows that human guidance, even if uncertain, substantially improves RL performance, and results in more efficient development of complex MTs. Through a trade-off between the certainty and timeliness of human advice, our method takes a step towards RL-driven human-in-the-loop engineering methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æ¨¡å‹é©±åŠ¨å·¥ç¨‹(Model-driven engineering)ä¸­æ‰‹åŠ¨å¼€å‘å¤æ‚æ¨¡å‹è½¬æ¢(Model Transformations)çš„éš¾é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§ç»“åˆå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¸ä¸ç¡®å®šäººå·¥æŒ‡å¯¼çš„æŠ€æœ¯æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†ç”¨æˆ·å®šä¹‰çš„æ¨¡å‹è½¬æ¢æ˜ å°„ä¸ºå¼ºåŒ–å­¦ä¹ åŸè¯­ï¼Œé€šè¿‡æ‰§è¡Œå¼ºåŒ–å­¦ä¹ ç¨‹åºæ¥è‡ªåŠ¨å¯»æ‰¾æœ€ä¼˜çš„è½¬æ¢åºåˆ—ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œå¼•å…¥äººå·¥æŒ‡å¯¼â€”â€”å³ä½¿è¯¥æŒ‡å¯¼å…·æœ‰ä¸ç¡®å®šæ€§â€”â€”ä¹Ÿèƒ½æ˜¾è‘—æå‡å¼ºåŒ–å­¦ä¹ åœ¨å¤æ‚é—®é¢˜ä¸­çš„æ€§èƒ½ï¼Œä½¿å¤æ‚æ¨¡å‹è½¬æ¢çš„å¼€å‘æ›´åŠ é«˜æ•ˆã€‚è¯¥æ–¹æ³•é€šè¿‡æƒè¡¡äººå·¥å»ºè®®çš„ç¡®å®šæ€§ä¸åŠæ—¶æ€§ï¼Œä¸ºå®ç°å¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„äººæœºååŒ(human-in-the-loop)å·¥ç¨‹æ–¹æ³•æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for ACM/IEEE MODELS'25",
      "pdf_url": "https://arxiv.org/pdf/2506.20883v2",
      "published_date": "2025-06-25 23:10:12 UTC",
      "updated_date": "2025-08-06 19:48:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:20:38.080124+00:00"
    },
    {
      "arxiv_id": "2506.20877v1",
      "title": "THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired Multi-Stage Fusion",
      "title_zh": "THIRDEYEï¼šåŸºäºç±»è„‘å¤šé˜¶æ®µèåˆçš„çº¿ç´¢æ„ŸçŸ¥å•ç›®æ·±åº¦ä¼°è®¡",
      "authors": [
        "Calin Teodor Ioan"
      ],
      "abstract": "Monocular depth estimation methods traditionally train deep models to infer depth directly from RGB pixels. This implicit learning often overlooks explicit monocular cues that the human visual system relies on, such as occlusion boundaries, shading, and perspective. Rather than expecting a network to discover these cues unaided, we present ThirdEye, a cue-aware pipeline that deliberately supplies each cue through specialised, pre-trained, and frozen networks. These cues are fused in a three-stage cortical hierarchy (V1->V2->V3) equipped with a key-value working-memory module that weights them by reliability. An adaptive-bins transformer head then produces a high-resolution disparity map. Because the cue experts are frozen, ThirdEye inherits large amounts of external supervision while requiring only modest fine-tuning. This extended version provides additional architectural detail, neuroscientific motivation, and an expanded experimental protocol; quantitative results will appear in a future revision.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ThirdEyeï¼Œè¿™æ˜¯ä¸€ç§å—å¤§è„‘å¯å‘çš„çº¿ç´¢æ„ŸçŸ¥å‹å•ç›®æ·±åº¦ä¼°è®¡(Monocular Depth Estimation)æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ˜¾å¼åˆ©ç”¨äººç±»è§†è§‰ç³»ç»Ÿä¾èµ–çš„å•ç›®çº¿ç´¢æ¥æ”¹è¿›æ·±åº¦é¢„æµ‹ã€‚è¯¥æ¡†æ¶ä¸å†ä¾èµ–ç¥ç»ç½‘ç»œç›²ç›®æœç´¢çº¿ç´¢ï¼Œè€Œæ˜¯é€šè¿‡ä¸“é—¨çš„ã€é¢„è®­ç»ƒä¸”å†»ç»“çš„ä¸“å®¶ç½‘ç»œä¸»åŠ¨æä¾›é®æŒ¡è¾¹ç•Œ(occlusion boundaries)ã€é˜´å½±(shading)å’Œé€è§†(perspective)ç­‰å…³é”®çº¿ç´¢ã€‚ç³»ç»Ÿçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªä¸‰é˜¶æ®µçš®å±‚åˆ†å±‚èåˆ(V1->V2->V3)æœºåˆ¶ï¼Œå¹¶é…å¤‡äº†åŸºäºé”®å€¼å¯¹çš„å·¥ä½œè®°å¿†æ¨¡å—(key-value working-memory)ï¼Œèƒ½å¤Ÿæ ¹æ®çº¿ç´¢çš„å¯é æ€§è¿›è¡ŒåŠ æƒèåˆã€‚æœ€ç»ˆç”±è‡ªé€‚åº”åˆ†ç®±Transformerå¤´éƒ¨(adaptive-bins transformer head)ç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„è§†å·®å›¾ã€‚ç”±äºçº¿ç´¢ä¸“å®¶ç½‘ç»œå¤„äºå†»ç»“çŠ¶æ€ï¼ŒThirdEyeèƒ½å¤Ÿç»§æ‰¿å¤§é‡çš„å¤–éƒ¨ç›‘ç£çŸ¥è¯†ï¼ŒåŒæ—¶ä»…éœ€é€‚åº¦çš„å¾®è°ƒå³å¯å®ç°é«˜æ•ˆå­¦ä¹ ã€‚è¯¥ç ”ç©¶è¯¦ç»†é˜è¿°äº†å…¶æ¶æ„ç»†èŠ‚ä¸ç¥ç»ç§‘å­¦åŠ¨æœºï¼Œä¸ºæ·±åº¦å­¦ä¹ ä¸è§†è§‰è®¤çŸ¥ç§‘å­¦çš„ç»“åˆæä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20877v1",
      "published_date": "2025-06-25 22:59:40 UTC",
      "updated_date": "2025-06-25 22:59:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:20:42.307690+00:00"
    },
    {
      "arxiv_id": "2506.20869v3",
      "title": "Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation",
      "title_zh": "é¢å‘å®é™…åº”ç”¨çš„ RAG ç³»ç»Ÿå·¥ç¨‹åŒ–ï¼šè®¾è®¡ã€å¼€å‘ä¸è¯„ä¼°",
      "authors": [
        "Md Toufique Hasan",
        "Muhammad Waseem",
        "Kai-Kristian Kemell",
        "Ayman Asad Khan",
        "Mika Saari",
        "Pekka Abrahamsson"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems are emerging as a key approach for grounding Large Language Models (LLMs) in external knowledge, addressing limitations in factual accuracy and contextual relevance. However, there is a lack of empirical studies that report on the development of RAG-based implementations grounded in real-world use cases, evaluated through general user involvement, and accompanied by systematic documentation of lessons learned. This paper presents five domain-specific RAG applications developed for real-world scenarios across governance, cybersecurity, agriculture, industrial research, and medical diagnostics. Each system incorporates multilingual OCR, semantic retrieval via vector embeddings, and domain-adapted LLMs, deployed through local servers or cloud APIs to meet distinct user needs. A web-based evaluation involving a total of 100 participants assessed the systems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii) Transparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of Recommendation. Based on user feedback and our development experience, we documented twelve key lessons learned, highlighting technical, operational, and ethical challenges affecting the reliability and usability of RAG systems in practice.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­çš„å·¥ç¨‹åŒ–è®¾è®¡ä¸è¯„ä¼°ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨äº‹å®å‡†ç¡®æ€§å’Œä¸Šä¸‹æ–‡ç›¸å…³æ€§æ–¹é¢çš„å±€é™æ€§ã€‚ç ”ç©¶è€…é’ˆå¯¹æ”¿åºœæ²»ç†ã€ç½‘ç»œå®‰å…¨ã€å†œä¸šã€å·¥ä¸šç ”ç©¶å’ŒåŒ»ç–—è¯Šæ–­äº”ä¸ªçœŸå®åœºæ™¯å¼€å‘äº†ç‰¹å®šçš„RAGåº”ç”¨ç¨‹åºï¼Œå¹¶é›†æˆäº†å¤šè¯­è¨€OCRã€åŸºäºå‘é‡åµŒå…¥(vector embeddings)çš„è¯­ä¹‰æ£€ç´¢ä»¥åŠé¢†åŸŸé€‚é…çš„å¤§è¯­è¨€æ¨¡å‹(domain-adapted LLMs)ã€‚é€šè¿‡å¯¹100åå‚ä¸è€…è¿›è¡Œçš„å…­ä¸ªç»´åº¦çš„Webè¯„ä¼°ï¼Œç ”ç©¶éªŒè¯äº†è¿™äº›ç³»ç»Ÿåœ¨æ˜“ç”¨æ€§ã€ç›¸å…³æ€§å’Œå‡†ç¡®æ€§ç­‰æ–¹é¢çš„è¡¨ç°ã€‚åŸºäºå¼€å‘ç»éªŒå’Œç”¨æˆ·åé¦ˆï¼Œè®ºæ–‡æ€»ç»“äº†åäºŒæ¡å…³äºRAGç³»ç»Ÿåœ¨å¯é æ€§å’Œå¯ç”¨æ€§æ–¹é¢çš„å…³é”®æ•™è®­ï¼Œç³»ç»Ÿæ€§åœ°é˜è¿°äº†æŠ€æœ¯ã€è¿è¥å’Œä¼¦ç†ç­‰å¤šæ–¹é¢çš„æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SE",
      "comment": "Published in the Proceedings of the 51st Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2025. Lecture Notes in Computer Science, volume 16082, pages 143-158. Springer, 2026",
      "pdf_url": "https://arxiv.org/pdf/2506.20869v3",
      "published_date": "2025-06-25 22:40:00 UTC",
      "updated_date": "2025-09-24 07:46:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:20:51.388903+00:00"
    },
    {
      "arxiv_id": "2506.20851v1",
      "title": "Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach",
      "title_zh": "GRAPH-AIDï¼šä¸€ç§é€šè¿‡è‡ªåŠ¨åŒ–é›†æˆæ•°æ®ç”Ÿæˆå¯é å¥åº·ä¸è‰¯äº‹ä»¶æ¦‚å†µçš„åŠè‡ªåŠ¨æœ¬ä½“æ„å»ºæ–¹æ³•",
      "authors": [
        "Srikar Reddy Gadusu",
        "Larry Callahan",
        "Samir Lababidi",
        "Arunasri Nishtala",
        "Sophia Healey",
        "Hande McGinty"
      ],
      "abstract": "As data and knowledge expand rapidly, adopting systematic methodologies for ontology generation has become crucial. With the daily increases in data volumes and frequent content changes, the demand for databases to store and retrieve information for the creation of knowledge graphs has become increasingly urgent. The previously established Knowledge Acquisition and Representation Methodology (KNARM) outlines a systematic approach to address these challenges and create knowledge graphs. However, following this methodology highlights the existing challenge of seamlessly integrating Neo4j databases with the Web Ontology Language (OWL). Previous attempts to integrate data from Neo4j into an ontology have been discussed, but these approaches often require an understanding of description logics (DL) syntax, which may not be familiar to many users. Thus, a more accessible method is necessary to bridge this gap. This paper presents a user-friendly approach that utilizes Python and its rdflib library to support ontology development. We showcase our novel approach through a Neo4j database we created by integrating data from the Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS) database. Using this dataset, we developed a Python script that automatically generates the required classes and their axioms, facilitating a smoother integration process. This approach offers a practical solution to the challenges of ontology generation in the context of rapidly growing adverse drug event datasets, supporting improved drug safety monitoring and public health decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GRAPH-AIDï¼Œä¸€ç§åŠè‡ªåŠ¨åŒ–çš„æœ¬ä½“(Ontology)æ„å»ºæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æµ·é‡æ•°æ®èƒŒæ™¯ä¸‹Neo4jæ•°æ®åº“ä¸Web Ontology Language (OWL)é›†æˆå›°éš¾çš„é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•å¯¹æè¿°é€»è¾‘(Description Logics)è¯­æ³•è¦æ±‚è¿‡é«˜ã€ä¸ä¾¿äºæ™®é€šç”¨æˆ·ä½¿ç”¨çš„æƒ…å†µï¼Œè¯¥æ–¹æ¡ˆåˆ©ç”¨PythonåŠå…¶rdflibåº“å®ç°äº†æœ¬ä½“å¼€å‘çš„ç®€åŒ–ã€‚ç ”ç©¶äººå‘˜é€šè¿‡é›†æˆç¾å›½é£Ÿå“è¯å“ç›‘ç£ç®¡ç†å±€(FDA)çš„ä¸è‰¯äº‹ä»¶æŠ¥å‘Šç³»ç»Ÿ(FAERS)æ•°æ®ï¼Œå¼€å‘äº†èƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆç±»(Classes)åŠå…¶å…¬ç†(Axioms)çš„è„šæœ¬ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆé™ä½æœ¬ä½“æ„å»ºçš„æŠ€æœ¯é—¨æ§›ï¼Œå¹¶æ˜¾è‘—æå‡äº†ä»å›¾å½¢æ•°æ®åº“åˆ°çŸ¥è¯†å›¾è°±(Knowledge Graphs)çš„è½¬åŒ–æ•ˆç‡ã€‚GRAPH-AIDä¸ºå¤„ç†å¿«é€Ÿå¢é•¿çš„è¯ç‰©ä¸è‰¯äº‹ä»¶æ•°æ®é›†æä¾›äº†å®ç”¨å·¥å…·ï¼Œå¯¹æ”¹è¿›è¯ç‰©å®‰å…¨ç›‘æµ‹å’Œå…¬å…±å«ç”Ÿå†³ç­–å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20851v1",
      "published_date": "2025-06-25 21:48:21 UTC",
      "updated_date": "2025-06-25 21:48:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:20:53.251643+00:00"
    },
    {
      "arxiv_id": "2506.20841v1",
      "title": "FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization",
      "title_zh": "FixCLRï¼šé¢å‘åŠç›‘ç£é¢†åŸŸæ³›åŒ–çš„è´Ÿç±»å¯¹æ¯”å­¦ä¹ ",
      "authors": [
        "Ha Min Son",
        "Shahbaz Rezaei",
        "Xin Liu"
      ],
      "abstract": "Semi-supervised domain generalization (SSDG) aims to solve the problem of generalizing to out-of-distribution data when only a few labels are available. Due to label scarcity, applying domain generalization methods often underperform. Consequently, existing SSDG methods combine semi-supervised learning methods with various regularization terms. However, these methods do not explicitly regularize to learn domains invariant representations across all domains, which is a key goal for domain generalization. To address this, we introduce FixCLR. Inspired by success in self-supervised learning, we change two crucial components to adapt contrastive learning for explicit domain invariance regularization: utilization of class information from pseudo-labels and using only a repelling term. FixCLR can also be added on top of most existing SSDG and semi-supervised methods for complementary performance improvements. Our research includes extensive experiments that have not been previously explored in SSDG studies. These experiments include benchmarking different improvements to semi-supervised methods, evaluating the performance of pretrained versus non-pretrained models, and testing on datasets with many domains. Overall, FixCLR proves to be an effective SSDG method, especially when combined with other semi-supervised methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠç›‘ç£é¢†åŸŸæ³›åŒ– (Semi-supervised domain generalization, SSDG) ä¸­æ ‡ç­¾ç¨€ç¼ºå¯¼è‡´æ¨¡å‹æ³›åŒ–æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº† FixCLR æ¡†æ¶ã€‚ç”±äºç°æœ‰ SSDG æ–¹æ³•å¾€å¾€ç¼ºä¹å¯¹è·¨é¢†åŸŸä¸å˜ç‰¹å¾ (domain invariant representations) çš„æ˜¾å¼æ­£åˆ™åŒ–ï¼ŒFixCLR å€Ÿé‰´è‡ªç›‘ç£å­¦ä¹ ï¼Œé€šè¿‡åˆ©ç”¨ä¼ªæ ‡ç­¾ (pseudo-labels) çš„ç±»åˆ«ä¿¡æ¯å¹¶å¼•å…¥ä»…åŒ…å«æ’æ–¥é¡¹ (repelling term) çš„å¯¹æ¯”å­¦ä¹ æœºåˆ¶ï¼Œå®ç°äº†æ˜¾å¼çš„é¢†åŸŸä¸å˜æ€§ã€‚FixCLR å…·æœ‰æå¼ºçš„é€šç”¨æ€§ï¼Œå¯ä»¥ä¸ç°æœ‰çš„åŠç›‘ç£å­¦ä¹ æ–¹æ³•ç»“åˆä»¥è·å¾—äº’è¡¥çš„æ€§èƒ½æå‡ã€‚é€šè¿‡åœ¨é¢„è®­ç»ƒæ¨¡å‹è¯„ä¼°åŠå¤šé¢†åŸŸæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒï¼Œè¯¥ç ”ç©¶è¯æ˜äº† FixCLR åœ¨å¤„ç†åˆ†å¸ƒå¤–æ•°æ®æ—¶çš„æœ‰æ•ˆæ€§ï¼Œä¸ºè§£å†³æ ‡ç­¾ç¨€ç¼ºä¸‹çš„é¢†åŸŸæ³›åŒ–é—®é¢˜æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20841v1",
      "published_date": "2025-06-25 21:25:05 UTC",
      "updated_date": "2025-06-25 21:25:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:20:54.064618+00:00"
    },
    {
      "arxiv_id": "2506.20832v1",
      "title": "Leveraging Vision-Language Models to Select Trustworthy Super-Resolution Samples Generated by Diffusion Models",
      "title_zh": "åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ç­›é€‰æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„é«˜å¯ä¿¡åº¦è¶…åˆ†è¾¨ç‡æ ·æœ¬",
      "authors": [
        "Cansu Korkmaz",
        "Ahmet Murat Tekalp",
        "Zafer Dogan"
      ],
      "abstract": "Super-resolution (SR) is an ill-posed inverse problem with many feasible solutions consistent with a given low-resolution image. On one hand, regressive SR models aim to balance fidelity and perceptual quality to yield a single solution, but this trade-off often introduces artifacts that create ambiguity in information-critical applications such as recognizing digits or letters. On the other hand, diffusion models generate a diverse set of SR images, but selecting the most trustworthy solution from this set remains a challenge. This paper introduces a robust, automated framework for identifying the most trustworthy SR sample from a diffusion-generated set by leveraging the semantic reasoning capabilities of vision-language models (VLMs). Specifically, VLMs such as BLIP-2, GPT-4o, and their variants are prompted with structured queries to assess semantic correctness, visual quality, and artifact presence. The top-ranked SR candidates are then ensembled to yield a single trustworthy output in a cost-effective manner. To rigorously assess the validity of VLM-selected samples, we propose a novel Trustworthiness Score (TWS) a hybrid metric that quantifies SR reliability based on three complementary components: semantic similarity via CLIP embeddings, structural integrity using SSIM on edge maps, and artifact sensitivity through multi-level wavelet decomposition. We empirically show that TWS correlates strongly with human preference in both ambiguous and natural images, and that VLM-guided selections consistently yield high TWS values. Compared to conventional metrics like PSNR, LPIPS, which fail to reflect information fidelity, our approach offers a principled, scalable, and generalizable solution for navigating the uncertainty of the diffusion SR space. By aligning outputs with human expectations and semantic correctness, this work sets a new benchmark for trustworthiness in generative SR.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¶…åˆ†è¾¨ç‡(Super-resolution, SR)ä»»åŠ¡ä¸­æ‰©æ•£æ¨¡å‹(Diffusion Models)ç”Ÿæˆæ ·æœ¬éš¾ä»¥ç­›é€‰çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)ï¼ˆå¦‚BLIP-2å’ŒGPT-4oï¼‰è¯­ä¹‰æ¨ç†èƒ½åŠ›æ¥è¯†åˆ«æœ€å¯ä¿¡æ ·æœ¬çš„è‡ªåŠ¨åŒ–æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“æ„åŒ–æŸ¥è¯¢è¯„ä¼°æ ·æœ¬çš„è¯­ä¹‰æ­£ç¡®æ€§ã€è§†è§‰è´¨é‡å’Œä¼ªå½±(Artifacts)ï¼Œå¹¶å¯¹æ’åé å‰çš„å€™é€‰æ ·æœ¬è¿›è¡Œé›†æˆ(Ensemble)ä»¥äº§å‡ºé«˜æ€§ä»·æ¯”çš„å¯ä¿¡è¾“å‡ºã€‚ç ”ç©¶è€…è¿˜åŒæ­¥æå‡ºäº†ä¸€ç§æ–°å‹æ··åˆæŒ‡æ ‡Trustworthiness Score (TWS)ï¼Œé€šè¿‡ç»“åˆCLIPåµŒå…¥çš„è¯­ä¹‰ç›¸ä¼¼åº¦ã€è¾¹ç¼˜å›¾çš„SSIMç»“æ„å®Œæ•´æ€§ä»¥åŠå¤šçº§å°æ³¢åˆ†è§£(Wavelet Decomposition)çš„ä¼ªå½±æ•æ„Ÿåº¦æ¥é‡åŒ–å¯é æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒTWSä¸äººç±»åå¥½å¼ºç›¸å…³ï¼Œä¸”VLMå¼•å¯¼çš„é€‰æ‹©åœ¨ä¿¡æ¯ä¿çœŸåº¦ä¸Šæ˜¾è‘—ä¼˜äºPSNRå’ŒLPIPSç­‰ä¼ ç»ŸæŒ‡æ ‡ã€‚è¯¥å·¥ä½œä¸ºå¤„ç†ç”Ÿæˆå¼è¶…åˆ†è¾¨ç‡ä¸­çš„ä¸ç¡®å®šæ€§æä¾›äº†å¯æ‰©å±•ä¸”é€šç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ºè¯¥é¢†åŸŸçš„å¯ä¿¡åº¦è¯„ä¼°ç¡®ç«‹äº†æ–°åŸºå‡†ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 9 figures, 5 tables, accepted to IEEE Transactions on Circuits and Systems for Video Technology",
      "pdf_url": "https://arxiv.org/pdf/2506.20832v1",
      "published_date": "2025-06-25 21:00:44 UTC",
      "updated_date": "2025-06-25 21:00:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:20:58.644551+00:00"
    },
    {
      "arxiv_id": "2506.20822v1",
      "title": "Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes",
      "title_zh": "æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹ä¸­æ½œåœ¨çš„æš´åŠ›å€¾å‘ï¼šåŸºäºè¡Œä¸ºæƒ…å¢ƒçš„äººå£ç»Ÿè®¡å­¦åˆ†æ",
      "authors": [
        "Quintin Myers",
        "Yanjun Gao"
      ],
      "abstract": "Large language models (LLMs) are increasingly proposed for detecting and responding to violent content online, yet their ability to reason about morally ambiguous, real-world scenarios remains underexamined. We present the first study to evaluate LLMs using a validated social science instrument designed to measure human response to everyday conflict, namely the Violent Behavior Vignette Questionnaire (VBVQ). To assess potential bias, we introduce persona-based prompting that varies race, age, and geographic identity within the United States. Six LLMs developed across different geopolitical and organizational contexts are evaluated under a unified zero-shot setting. Our study reveals two key findings: (1) LLMs surface-level text generation often diverges from their internal preference for violent responses; (2) their violent tendencies vary across demographics, frequently contradicting established findings in criminology, social science, and psychology.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†é“å¾·æ¨¡ç³Šçš„ç°å®å†²çªåœºæ™¯æ—¶æ½œè—çš„æš´åŠ›å€¾å‘åŠäººå£ç»Ÿè®¡å­¦åè§ã€‚ä½œè€…é¦–æ¬¡åˆ©ç”¨ç¤¾ä¼šç§‘å­¦é¢†åŸŸéªŒè¯è¿‡çš„æš´åŠ›è¡Œä¸ºæƒ…å¢ƒé—®å·(Violent Behavior Vignette Questionnaire, VBVQ)ä½œä¸ºæµ‹é‡å·¥å…·ï¼Œå¹¶åœ¨é›¶æ ·æœ¬(zero-shot)è®¾ç½®ä¸‹è¯„ä¼°äº†å…­ç§æ¥è‡ªä¸åŒç»„ç»‡èƒŒæ™¯çš„LLMsã€‚ç ”ç©¶é€šè¿‡å¼•å…¥åŸºäºè§’è‰²æ‰®æ¼”çš„æç¤ºè¯(persona-based prompting)æ¥æ”¹å˜è§’è‰²çš„ç§æ—ã€å¹´é¾„å’Œåœ°åŸŸèº«ä»½ï¼Œä»è€Œæ·±å…¥åˆ†ææ¨¡å‹çš„åè§è¡¨ç°ã€‚å®éªŒæ­ç¤ºäº†ä¸¤ä¸ªæ ¸å¿ƒå‘ç°ï¼šé¦–å…ˆï¼ŒLLMsç”Ÿæˆçš„è¡¨é¢æ–‡æœ¬å¾€å¾€ä¸å…¶å†…éƒ¨å¯¹æš´åŠ›å“åº”çš„åå¥½å­˜åœ¨åå·®ï¼›å…¶æ¬¡ï¼Œæ¨¡å‹è¡¨ç°å‡ºçš„æš´åŠ›å€¾å‘éšäººå£ç»Ÿè®¡ç‰¹å¾è€Œå¼‚ï¼Œä¸”è¿™ç§å·®å¼‚ç»å¸¸è¿èƒŒçŠ¯ç½ªå­¦å’Œç¤¾ä¼šå¿ƒç†å­¦çš„ä¼ ç»Ÿç ”ç©¶ç»“è®ºã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†LLMsåœ¨æ¨¡æ‹Ÿäººç±»ç¤¾ä¼šè¡Œä¸ºæ—¶å­˜åœ¨çš„å¤æ‚åè§ï¼Œå¯¹äºåœ¨ç°å®ä¸–ç•Œä¸­å®‰å…¨éƒ¨ç½²å’Œåº”ç”¨è¿™äº›æ¨¡å‹å…·æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "https://arxiv.org/pdf/2506.20822v1",
      "published_date": "2025-06-25 20:43:04 UTC",
      "updated_date": "2025-06-25 20:43:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:21:00.210369+00:00"
    },
    {
      "arxiv_id": "2506.20821v1",
      "title": "MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering",
      "title_zh": "MultiFinRAGï¼šä¸€ç§é¢å‘é‡‘èé—®ç­”çš„ä¼˜åŒ–å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶",
      "authors": [
        "Chinmay Gondhalekar",
        "Urjitkumar Patel",
        "Fang-Chun Yeh"
      ],
      "abstract": "Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span hundreds of pages and combine diverse modalities, including dense narrative text, structured tables, and complex figures. Answering questions over such content often requires joint reasoning across modalities, which strains traditional large language models (LLMs) and retrieval-augmented generation (RAG) pipelines due to token limitations, layout loss, and fragmented cross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation framework purpose-built for financial QA. MultiFinRAG first performs multimodal extraction by grouping table and figure images into batches and sending them to a lightweight, quantized open-source multimodal LLM, which produces both structured JSON outputs and concise textual summaries. These outputs, along with narrative text, are embedded and indexed with modality-aware similarity thresholds for precise retrieval. A tiered fallback strategy then dynamically escalates from text-only to text+table+image contexts when necessary, enabling cross-modal reasoning while reducing irrelevant context. Despite running on commodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy than ChatGPT-4o (free-tier) on complex financial QA tasks involving text, tables, images, and combined multimodal reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MultiFinRAGï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºé‡‘èé—®ç­”è®¾è®¡çš„å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆ (Multimodal Retrieval-Augmented Generation, RAG) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³é‡‘èæ–‡æ¡£ä¸­ç”±äºæ–‡æœ¬ã€å¤æ‚è¡¨æ ¼å’Œå›¾è¡¨äº¤ç»‡å¯¼è‡´çš„ä¼ ç»Ÿå¤§è¯­è¨€æ¨¡å‹ (LLMs) æ¨ç†å›°éš¾åŠå¸ƒå±€ä¿¡æ¯ä¸¢å¤±ç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è½»é‡çº§ã€é‡åŒ–çš„å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLM) å¯¹è¡¨æ ¼å’Œå›¾åƒè¿›è¡Œåˆ†æ‰¹æå–ï¼Œç”Ÿæˆç»“æ„åŒ–çš„ JSON è¾“å‡ºå’Œæ–‡æœ¬æ‘˜è¦ï¼Œå¹¶ç»“åˆæ¨¡æ€æ„ŸçŸ¥ç›¸ä¼¼åº¦é˜ˆå€¼ (Modality-aware Similarity Thresholds) è¿›è¡Œç²¾ç¡®ç´¢å¼•ã€‚MultiFinRAG åˆ›æ–°æ€§åœ°é‡‡ç”¨äº†åˆ†å±‚å›é€€ç­–ç•¥ (Tiered Fallback Strategy)ï¼Œå¯æ ¹æ®ä»»åŠ¡éœ€æ±‚åŠ¨æ€æ‰©å±•ä¸Šä¸‹æ–‡èŒƒå›´ï¼Œåœ¨é™ä½æ— å…³å¹²æ‰°çš„åŒæ—¶å®ç°é«˜æ•ˆçš„è·¨æ¨¡æ€æ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMultiFinRAG åœ¨å•†ç”¨ç¡¬ä»¶ (Commodity Hardware) ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œåœ¨å¤„ç†æ¶‰åŠå¤šæ¨¡æ€æ¨ç†çš„å¤æ‚é‡‘èé—®ç­”ä»»åŠ¡æ—¶ï¼Œå…¶å‡†ç¡®ç‡æ¯”å…è´¹ç‰ˆ ChatGPT-4o é«˜å‡º 19 ä¸ªç™¾åˆ†ç‚¹ï¼Œä¸ºé‡‘èé¢†åŸŸçš„ä¿¡æ¯æ£€ç´¢ä¸åˆ†ææä¾›äº†é«˜æ•ˆä¸”ä½æˆæœ¬çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint Copy",
      "pdf_url": "https://arxiv.org/pdf/2506.20821v1",
      "published_date": "2025-06-25 20:37:20 UTC",
      "updated_date": "2025-06-25 20:37:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:21:28.096103+00:00"
    },
    {
      "arxiv_id": "2506.20815v2",
      "title": "Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications",
      "title_zh": "é¢å‘ç‰¹å®šé¢†åŸŸäººå·¥æ™ºèƒ½åº”ç”¨çš„åŠ¨æ€ä¸Šä¸‹æ–‡æ„ŸçŸ¥æç¤ºè¯æ¨è",
      "authors": [
        "Xinye Tang",
        "Haijun Zhai",
        "Chaitanya Belwal",
        "Vineeth Thayanithi",
        "Philip Baumann",
        "Yogesh K Roy"
      ],
      "abstract": "LLM-powered applications are highly susceptible to the quality of user prompts, and crafting high-quality prompts can often be challenging especially for domain-specific applications. This paper presents a novel dynamic context-aware prompt recommendation system for domain-specific AI applications. Our solution combines contextual query analysis, retrieval-augmented knowledge grounding, hierarchical skill organization, and adaptive skill ranking to generate relevant and actionable prompt suggestions.\n  The system leverages behavioral telemetry and a two-stage hierarchical reasoning process to dynamically select and rank relevant skills, and synthesizes prompts using both predefined and adaptive templates enhanced with few-shot learning. Experiments on real-world datasets demonstrate that our approach achieves high usefulness and relevance, as validated by both automated and expert evaluations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç‰¹å®šé¢†åŸŸAIåº”ç”¨ä¸­é«˜è´¨é‡æç¤ºè¯(Prompts)ç¼–å†™å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„åŠ¨æ€ä¸Šä¸‹æ–‡æ„ŸçŸ¥æç¤ºè¯æ¨èç³»ç»Ÿã€‚è¯¥æ–¹æ¡ˆæœ‰æœºç»“åˆäº†ä¸Šä¸‹æ–‡æŸ¥è¯¢åˆ†æã€æ£€ç´¢å¢å¼ºçŸ¥è¯†æ¥åœ°(Retrieval-Augmented Knowledge Grounding)ã€å±‚æ¬¡åŒ–æŠ€èƒ½ç»„ç»‡ä»¥åŠè‡ªé€‚åº”æŠ€èƒ½æ’åæŠ€æœ¯ï¼Œæ—¨åœ¨ç”Ÿæˆé«˜åº¦ç›¸å…³ä¸”å…·å¤‡å¯æ“ä½œæ€§çš„æç¤ºè¯å»ºè®®ã€‚ç³»ç»Ÿé€šè¿‡åˆ©ç”¨è¡Œä¸ºé¥æµ‹æ•°æ®å’Œç‹¬ç‰¹çš„ä¸¤é˜¶æ®µå±‚æ¬¡åŒ–æ¨ç†è¿‡ç¨‹æ¥åŠ¨æ€é€‰æ‹©å¹¶æ’åˆ—ç›¸å…³æŠ€èƒ½ï¼Œå¹¶é‡‡ç”¨é¢„å®šä¹‰ä¸è‡ªé€‚åº”æ¨¡æ¿ç»“åˆå°‘æ ·æœ¬å­¦ä¹ (Few-Shot Learning)çš„æ–¹å¼åˆæˆæœ€ç»ˆæç¤ºè¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†çš„è‡ªåŠ¨åŒ–è¯„ä¼°ä¸ä¸“å®¶è¯„å®¡ä¸­å‡å–å¾—äº†ä¼˜å¼‚æˆç»©ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆå»ºè®®çš„å®ç”¨æ€§ä¸ç›¸å…³æ€§ã€‚è¯¥ç ”ç©¶ä¸ºä¼˜åŒ–ç‰¹å®šé¢†åŸŸå¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„äº¤äº’ä½“éªŒæä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20815v2",
      "published_date": "2025-06-25 20:29:46 UTC",
      "updated_date": "2025-07-08 17:25:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:21:21.422037+00:00"
    },
    {
      "arxiv_id": "2507.00054v1",
      "title": "Enhancing Reasoning Capabilities in SLMs with Reward Guided Dataset Distillation",
      "title_zh": "é€šè¿‡å¥–åŠ±å¼•å¯¼çš„æ•°æ®é›†è’¸é¦æå‡å°è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›",
      "authors": [
        "Shreyansh Padarha"
      ],
      "abstract": "The push to compress and impart the proficiency of Large Language Models (LLMs) into more deployable and efficient Small Language Models (SLMs) has benefited from improvements in knowledge distillation (KD) techniques. These techniques allow a smaller student model to learn from a more capable and larger teacher model's responses. However, distillation often revolves around the student model merely copying the teacher's in-distribution responses, limiting its generalisability. This limitation is amplified on reasoning tasks and can be computationally expensive. In this study, we propose AdvDistill, a reward-guided dataset distillation framework. We utilise multiple generations (responses) from a teacher for each prompt and assign rewards based on rule-based verifiers. These varying and normally distributed rewards serve as weights when training student models. Our methods and their subsequent behavioural analysis demonstrate a significant improvement in student model performance for mathematical and complex reasoning tasks, showcasing the efficacy and benefits of incorporating a rewarding mechanism in dataset distillation processes.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çŸ¥è¯†è’¸é¦(knowledge distillation, KD)ä¸­å°å‹è¯­è¨€æ¨¡å‹(Small Language Models, SLMs)ä»…ç®€å•æ¨¡ä»¿å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)çš„åˆ†å¸ƒå†…å“åº”ï¼Œå¯¼è‡´åœ¨æ¨ç†ä»»åŠ¡ä¸­æ³›åŒ–èƒ½åŠ›å—é™ä¸”è®¡ç®—æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†AdvDistillï¼Œä¸€ç§å¥–åŠ±å¼•å¯¼çš„è®­ç»ƒé›†è’¸é¦(dataset distillation)æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºSLMsçš„æ¨ç†èƒ½åŠ›ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ•™å¸ˆæ¨¡å‹é’ˆå¯¹æ¯ä¸ªæç¤ºç”Ÿæˆçš„å¤šä¸ªå“åº”ï¼Œå¹¶é€šè¿‡åŸºäºè§„åˆ™çš„éªŒè¯å™¨(rule-based verifiers)ä¸ºè¿™äº›å“åº”åˆ†é…å¥–åŠ±ã€‚è¿™äº›æ­£æ€åˆ†å¸ƒçš„å¥–åŠ±åœ¨è®­ç»ƒå­¦ç”Ÿæ¨¡å‹æ—¶ä½œä¸ºæƒé‡ä½¿ç”¨ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹æ›´æœ‰æ•ˆåœ°å­¦ä¹ ã€‚å®éªŒç»“æœå’Œè¡Œä¸ºåˆ†æè¡¨æ˜ï¼ŒAdvDistillåœ¨æ•°å­¦å’Œå¤æ‚æ¨ç†ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†å­¦ç”Ÿæ¨¡å‹çš„æ€§èƒ½ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åœ¨æ•°æ®é›†è’¸é¦è¿‡ç¨‹ä¸­å¼•å…¥å¥–åŠ±æœºåˆ¶ï¼Œå¯¹äºå¼€å‘æ›´å…·éƒ¨ç½²æ€§ã€é«˜æ•ˆç‡ä¸”å…·å¤‡å¼ºæ¨ç†èƒ½åŠ›çš„SLMså…·æœ‰æ˜¾è‘—æˆæ•ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "17 Pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.00054v1",
      "published_date": "2025-06-25 20:07:47 UTC",
      "updated_date": "2025-06-25 20:07:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:21:22.483587+00:00"
    },
    {
      "arxiv_id": "2506.20810v1",
      "title": "FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs",
      "title_zh": "FINN-GLï¼šé¢å‘ FPGA åŠ é€Ÿ LSTM çš„é€šç”¨æ··åˆç²¾åº¦æ‰©å±•",
      "authors": [
        "Shashwat Khandelwal",
        "Jakoba Petri-Koenig",
        "Thomas B. PreuÃŸer",
        "Michaela Blott",
        "Shreejith Shanker"
      ],
      "abstract": "Recurrent neural networks (RNNs), particularly LSTMs, are effective for time-series tasks like sentiment analysis and short-term stock prediction. However, their computational complexity poses challenges for real-time deployment in resource constrained environments. While FPGAs offer a promising platform for energy-efficient AI acceleration, existing tools mainly target feed-forward networks, and LSTM acceleration typically requires full custom implementation. In this paper, we address this gap by leveraging the open-source and extensible FINN framework to enable the generalized deployment of LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open Neural Network Exchange (ONNX) specification to model the recurrent nature of LSTM computations, enabling support for mixed quantisation within them and functional verification of LSTM-based models. Furthermore, we introduce custom transformations within the FINN compiler to map the quantised ONNX computation graph to hardware blocks from the HLS kernel library of the FINN compiler and Vitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM model for a mid-price stock prediction task using the widely used dataset and generating a corresponding hardware IP of the model using our flow, targeting the XCZU7EV device. We show that the generated quantised ConvLSTM accelerator through our flow achieves a balance between performance (latency) and resource consumption, while matching (or bettering) inference accuracy of state-of-the-art models with reduced precision. We believe that the generalisable nature of the proposed flow will pave the way for resource-efficient RNN accelerator designs on FPGAs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ LSTMs åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹å®æ—¶éƒ¨ç½²çš„å¤æ‚æ€§ï¼Œä»¥åŠç°æœ‰ FPGA åŠ é€Ÿå·¥å…·å¯¹å¾ªç¯ç¥ç»ç½‘ç»œæ”¯æŒä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäº FINN æ¡†æ¶çš„é€šç”¨æ··åˆç²¾åº¦æ‰©å±•æ–¹æ¡ˆ FINN-GLã€‚è¯¥æ–¹æ¡ˆåˆ›æ–°æ€§åœ°åˆ©ç”¨ ONNX è§„èŒƒä¸­çš„ Scan ç®—å­æ¥å»ºæ¨¡ LSTM çš„é€’å½’ç‰¹æ€§ï¼Œä»è€Œæ”¯æŒæ¨¡å‹å†…éƒ¨çš„æ··åˆé‡åŒ–ï¼ˆmixed quantizationï¼‰ä¸åŠŸèƒ½éªŒè¯ã€‚é€šè¿‡åœ¨ FINN ç¼–è¯‘å™¨ä¸­å¼•å…¥è‡ªå®šä¹‰è½¬æ¢ï¼Œç ”ç©¶æˆåŠŸå°†é‡åŒ–åçš„ ONNX è®¡ç®—å›¾æ˜ å°„è‡³ç”± FINN å†…æ ¸åº“å’Œ Vitis HLS æ„å»ºçš„ç¡¬ä»¶æ¨¡å—ã€‚åœ¨é’ˆå¯¹ XCZU7EV å¹³å°çš„è‚¡ç¥¨é¢„æµ‹ä»»åŠ¡éªŒè¯ä¸­ï¼Œç”Ÿæˆçš„ ConvLSTM åŠ é€Ÿå™¨åœ¨å»¶è¿Ÿä¸èµ„æºæ¶ˆè€—ä¹‹é—´å–å¾—äº†ç†æƒ³å¹³è¡¡ã€‚å®éªŒè¯æ˜ï¼Œè¯¥å·¥å…·æµåœ¨é™ä½ç²¾åº¦çš„åŒæ—¶ï¼Œæ¨ç†å‡†ç¡®ç‡èƒ½å¤ŸåŒ¹é…ç”šè‡³è¶…è¶Šç°æœ‰å°–ç«¯æ¨¡å‹ã€‚è¿™ä¸€é€šç”¨åŒ–æµç¨‹çš„æå‡ºï¼Œä¸ºåœ¨ FPGAs ä¸Šå®ç°èµ„æºé«˜æ•ˆçš„ RNN åŠ é€Ÿå™¨è®¾è®¡å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 6 figures, 5 tables, Accepted for publication in IEEE FPL-2025 (https://2025.fpl.org/)",
      "pdf_url": "https://arxiv.org/pdf/2506.20810v1",
      "published_date": "2025-06-25 20:07:46 UTC",
      "updated_date": "2025-06-25 20:07:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:21:27.823066+00:00"
    },
    {
      "arxiv_id": "2506.20807v2",
      "title": "GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization",
      "title_zh": "GPU Kernel Scientistï¼šå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„è¿­ä»£å¼å†…æ ¸ä¼˜åŒ–æ¡†æ¶",
      "authors": [
        "Martin Andrews",
        "Sam Witteveen"
      ],
      "abstract": "Optimizing GPU kernels for high performance is a complex task, often demanding deep architectural knowledge, extensive profiling, and iterative experimentation. This challenge is amplified when targeting newer or less-documented GPU architectures where traditional development aids are scarce. This paper introduces an LLM-powered \"GPU Kernel Scientist,\" an automated methodology for iteratively refining accelerator kernels.\n  Our methodology employs LLMs in a multi-stage, evolutionary process: (a) strategically selecting promising prior code versions as a basis for new iterations; (b) generating hypotheses for optimization experiments, based on existing code and assimilated knowledge from general GPU literature; and (c) autonomously implementing these experiments through code modification and subsequent submission to an external evaluation system, using only observed timing data as performance feedback. We detail how this approach navigates the challenges of the AMD MI300 target architecture and leverages LLMs to compensate for limited domain-specific human expertise.\n  In addition to our results, we present the architectural design, operational workflow, and qualitative insights, highlighting the potential of LLM-driven agents to democratise and accelerate GPU kernel optimization, especially in resource-constrained or rapidly updating hardware environment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GPU Kernel Scientistï¼Œè¿™æ˜¯ä¸€ä¸ªç”±å¤§è¯­è¨€æ¨¡å‹ (LLM) é©±åŠ¨çš„è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡è¿­ä»£ä¼˜åŒ–è§£å†³ GPU kernel é«˜æ€§èƒ½ä¼˜åŒ–ä¸­çš„å¤æ‚æ€§æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å¤šé˜¶æ®µæ¼”åŒ–è¿‡ç¨‹ï¼Œé¦–å…ˆä»ä¹‹å‰çš„ä»£ç ç‰ˆæœ¬ä¸­ç­–ç•¥æ€§åœ°é€‰æ‹©ä¼˜èƒœç‰ˆæœ¬ä½œä¸ºåŸºç¡€ï¼Œéšåç»“åˆç°æœ‰ä»£ç å’Œé€šç”¨çš„ GPU é¢†åŸŸçŸ¥è¯†ä¸ºä¼˜åŒ–å®éªŒç”Ÿæˆé’ˆå¯¹æ€§çš„å‡è®¾ã€‚ç³»ç»Ÿèƒ½å¤Ÿè‡ªä¸»å®æ–½ä»£ç ä¿®æ”¹å¹¶å°†ç»“æœæäº¤è‡³å¤–éƒ¨è¯„ä¼°ç³»ç»Ÿï¼Œä»…åˆ©ç”¨è§‚æµ‹åˆ°çš„æ‰§è¡Œæ—¶é—´æ•°æ®ä½œä¸ºæ€§èƒ½åé¦ˆã€‚è¯¥æ–¹æ³•åœ¨ AMD MI300 æ¶æ„ä¸Šè¿›è¡Œäº†æ·±å…¥éªŒè¯ï¼Œå±•ç¤ºäº†å…¶åœ¨ç¼ºä¹ç‰¹å®šé¢†åŸŸä¸“å®¶ç»éªŒçš„æƒ…å†µä¸‹åˆ©ç”¨ LLM å¼¥è¡¥çŸ¥è¯†ç¼ºå£çš„èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œä¸ä»…è¯¦ç»†ä»‹ç»äº†æ¶æ„è®¾è®¡å’Œå·¥ä½œæµï¼Œè¿˜çªæ˜¾äº† LLM-driven agents åœ¨åŠ é€Ÿ GPU kernel ä¼˜åŒ–ä»¥åŠæ¨åŠ¨ç¡¬ä»¶ä¼˜åŒ–æ°‘ä¸»åŒ–æ–¹é¢çš„æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºèµ„æºå—é™æˆ–ç¡¬ä»¶å¿«é€Ÿæ›´è¿­çš„ç¯å¢ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "4+1 page paper plus Appendices and Supplementary zip file. Presented at the ES-FoMo \"Efficient Systems for Foundation Models\" workshop at ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.20807v2",
      "published_date": "2025-06-25 19:59:34 UTC",
      "updated_date": "2025-08-22 08:48:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:21:25.045823+00:00"
    },
    {
      "arxiv_id": "2506.20806v1",
      "title": "Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis",
      "title_zh": "æµ·æŠ¥ï¼šåˆ©ç”¨åŸºäºæ™ºèƒ½ä½“çš„åˆ†ææå‡ç½‘ç»œå…¥ä¾µæ£€æµ‹ä¸­å›¾ç¥ç»ç½‘ç»œçš„é²æ£’æ€§",
      "authors": [
        "Zhonghao Zhan",
        "Huichi Zhou",
        "Hamed Haddadi"
      ],
      "abstract": "Graph Neural Networks (GNNs) show great promise for Network Intrusion Detection Systems (NIDS), particularly in IoT environments, but suffer performance degradation due to distribution drift and lack robustness against realistic adversarial attacks. Current robustness evaluations often rely on unrealistic synthetic perturbations and lack demonstrations on systematic analysis of different kinds of adversarial attack, which encompass both black-box and white-box scenarios. This work proposes a novel approach to enhance GNN robustness and generalization by employing Large Language Models (LLMs) in an agentic pipeline as simulated cybersecurity expert agents. These agents scrutinize graph structures derived from network flow data, identifying and potentially mitigating suspicious or adversarially perturbed elements before GNN processing. Our experiments, using a framework designed for realistic evaluation and testing with a variety of adversarial attacks including a dataset collected from physical testbed experiments, demonstrate that integrating LLM analysis can significantly improve the resilience of GNN-based NIDS against challenges, showcasing the potential of LLM agent as a complementary layer in intrusion detection architectures.",
      "tldr_zh": "é’ˆå¯¹ Graph Neural Networks (GNNs) åœ¨ç‰©è”ç½‘ç½‘ç»œå…¥ä¾µæ£€æµ‹ (Network Intrusion Detection Systems, NIDS) ä¸­é¢ä¸´çš„åˆ†å¸ƒåç§» (distribution drift) å’Œå¯¹æŠ—æ”»å‡» (adversarial attacks) é²æ£’æ€§ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ›æ–°çš„å¢å¼ºæ–¹æ³•ã€‚è¯¥æ–¹æ¡ˆè®¾è®¡äº†ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) çš„æ™ºèƒ½ä½“æµæ°´çº¿ (agentic pipeline)ï¼Œæ¨¡æ‹Ÿç½‘ç»œå®‰å…¨ä¸“å®¶å¯¹ç½‘ç»œæµæ•°æ®ç”Ÿæˆçš„å›¾ç»“æ„è¿›è¡Œé¢„å…ˆå®¡æŸ¥ã€‚è¿™äº›æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨ GNN å¤„ç†å‰è¯†åˆ«å¹¶ç¼“è§£å¯ç–‘æˆ–ç»è¿‡å¯¹æŠ—æ€§æ‰°åŠ¨çš„å…ƒç´ ï¼Œä»è€Œæ˜¾è‘—æå‡ç³»ç»Ÿçš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒé‡‡ç”¨äº†ä¸€ä¸ªåŒ…å«ç‰©ç†å®éªŒå°æ•°æ®é›†çš„çœŸå®è¯„ä¼°æ¡†æ¶ï¼Œæ¶µç›–äº†é»‘ç›’ (black-box) å’Œç™½ç›’ (white-box) ç­‰å¤šç§ç°å®å¯¹æŠ—æ”»å‡»åœºæ™¯ã€‚ç»“æœè¯æ˜ï¼Œé›†æˆ LLM æ™ºèƒ½ä½“åˆ†æèƒ½æ˜¾è‘—å¢å¼ºåŸºäº GNN çš„ NIDS åœ¨é¢å¯¹å¤æ‚æŒ‘æˆ˜æ—¶çš„éŸ§æ€§ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº† LLM æ™ºèƒ½ä½“ä½œä¸ºå…¥ä¾µæ£€æµ‹æ¶æ„ä¸­äº’è¡¥å±‚çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºæ„å»ºæ›´å…·é²æ£’æ€§çš„ç½‘ç»œå®‰å…¨ç›‘æ§ç³»ç»Ÿæä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Poster accepted at the 10th IEEE European Symposium on Security and Privacy (Euro S&P 2025)",
      "pdf_url": "https://arxiv.org/pdf/2506.20806v1",
      "published_date": "2025-06-25 19:49:55 UTC",
      "updated_date": "2025-06-25 19:49:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:22:35.609084+00:00"
    },
    {
      "arxiv_id": "2506.20803v1",
      "title": "The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas",
      "title_zh": "æ„æ€-æ‰§è¡Œå·®è·ï¼šå¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸äººç±»ç§‘ç ”åˆ›æ„çš„æ‰§è¡Œæˆæ•ˆå¯¹æ¯”",
      "authors": [
        "Chenglei Si",
        "Tatsunori Hashimoto",
        "Diyi Yang"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise in accelerating the scientific research pipeline. A key capability for this process is the ability to generate novel research ideas, and prior studies have found settings in which LLM-generated research ideas were judged as more novel than human-expert ideas. However, a good idea should not simply appear to be novel, it should also result in better research after being executed. To test whether AI-generated ideas lead to better research outcomes, we conduct an execution study by recruiting 43 expert researchers to execute randomly-assigned ideas, either written by experts or generated by an LLM. Each expert spent over 100 hours implementing the idea and wrote a 4-page short paper to document the experiments. All the executed projects are then reviewed blindly by expert NLP researchers. Comparing the review scores of the same ideas before and after execution, the scores of the LLM-generated ideas decrease significantly more than expert-written ideas on all evaluation metrics (novelty, excitement, effectiveness, and overall; p < 0.05), closing the gap between LLM and human ideas observed at the ideation stage. When comparing the aggregated review scores from the execution study, we even observe that for many metrics there is a flip in rankings where human ideas score higher than LLM ideas. This ideation-execution gap highlights the limitations of current LLMs in generating truly effective research ideas and the challenge of evaluating research ideas in the absence of execution outcomes.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Large Language Models (LLMs) ç”Ÿæˆçš„ç ”ç©¶æƒ³æ³•ä¸äººç±»ä¸“å®¶æƒ³æ³•åœ¨å®é™…æ‰§è¡Œç»“æœä¸Šçš„å·®å¼‚ï¼Œæ­ç¤ºäº†â€œæƒ³æ³•-æ‰§è¡Œå·®è·â€(Ideation-Execution Gap)ã€‚ç ”ç©¶è€…æ‹›å‹Ÿäº† 43 åä¸“å®¶ç ”ç©¶äººå‘˜ï¼Œè®©ä»–ä»¬éšæœºæ‰§è¡Œç”± LLM æˆ–äººç±»ä¸“å®¶æå‡ºçš„ç ”ç©¶æƒ³æ³•ï¼Œæ¯ä½ä¸“å®¶æŠ•å…¥è¶…è¿‡ 100 å°æ—¶è¿›è¡Œå®éªŒå¹¶æ’°å†™è®ºæ–‡ã€‚éšåç”± Natural Language Processing (NLP) é¢†åŸŸçš„ä¸“å®¶å¯¹æ‰§è¡Œåçš„é¡¹ç›®è¿›è¡Œç›²å®¡ï¼Œå¯¹æ¯”è¯„ä¼° Noveltyã€Excitementã€Effectiveness å’Œ Overall ç­‰æŒ‡æ ‡ã€‚ç»“æœæ˜¾ç¤ºï¼ŒLLM ç”Ÿæˆçš„æƒ³æ³•åœ¨æ‰§è¡Œåçš„å„é¡¹æŒ‡æ ‡å¾—åˆ†ä¸‹é™å¹…åº¦æ˜¾è‘—é«˜äºäººç±»æƒ³æ³•ï¼Œä¸”åœ¨æ±‡æ€»è¯„åˆ†ä¸­å‡ºç°äº†æ’ååè½¬ï¼Œå³äººç±»æƒ³æ³•çš„å®é™…è¡¨ç°ä¼˜äº LLM æƒ³æ³•ã€‚è¿™ä¸€å‘ç°å‡¸æ˜¾äº†å½“å‰ LLMs åœ¨ç”Ÿæˆå…·æœ‰å®é™…è½åœ°ä»·å€¼çš„ç ”ç©¶æƒ³æ³•æ–¹é¢çš„å±€é™æ€§ï¼Œå¹¶åæ˜ å‡ºä»…å‡­åˆ›æ„é˜¶æ®µè¯„ä¼°ç§‘ç ”æƒ³æ³•çš„ä¸è¶³ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "main paper is 14 pages",
      "pdf_url": "https://arxiv.org/pdf/2506.20803v1",
      "published_date": "2025-06-25 19:47:23 UTC",
      "updated_date": "2025-06-25 19:47:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:21:39.360105+00:00"
    },
    {
      "arxiv_id": "2506.20790v2",
      "title": "Stochastic Parameter Decomposition",
      "title_zh": "éšæœºå‚æ•°åˆ†è§£",
      "authors": [
        "Lucius Bushnaq",
        "Dan Braun",
        "Lee Sharkey"
      ],
      "abstract": "A key step in reverse engineering neural networks is to decompose them into simpler parts that can be studied in relative isolation. Linear parameter decomposition -- a framework that has been proposed to resolve several issues with current decomposition methods -- decomposes neural network parameters into a sum of sparsely used vectors in parameter space. However, the current main method in this framework, Attribution-based Parameter Decomposition (APD), is impractical on account of its computational cost and sensitivity to hyperparameters. In this work, we introduce \\textit{Stochastic Parameter Decomposition} (SPD), a method that is more scalable and robust to hyperparameters than APD, which we demonstrate by decomposing models that are slightly larger and more complex than was possible to decompose with APD. We also show that SPD avoids other issues, such as shrinkage of the learned parameters, and better identifies ground truth mechanisms in toy models. By bridging causal mediation analysis and network decomposition methods, this demonstration opens up new research possibilities in mechanistic interpretability by removing barriers to scaling linear parameter decomposition methods to larger models. We release a library for running SPD and reproducing our experiments at https://github.com/goodfire-ai/spd/tree/spd-paper.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¥ç»ç½‘ç»œé€†å‘å·¥ç¨‹ä¸­ç°æœ‰æ–¹æ³• Attribution-based Parameter Decomposition (APD) è®¡ç®—æˆæœ¬é«˜ä¸”å¯¹è¶…å‚æ•°æ•æ„Ÿçš„é—®é¢˜ï¼Œæå‡ºäº† Stochastic Parameter Decomposition (SPD)ã€‚SPD æ˜¯ä¸€ç§æ›´å…·å¯æ‰©å±•æ€§å’Œè¶…å‚æ•°é²æ£’æ€§çš„çº¿æ€§å‚æ•°åˆ†è§£æ–¹æ³•ï¼Œèƒ½å¤Ÿå¤„ç†æ¯”ä»¥å¾€æ›´å¤§å‹ä¸”å¤æ‚çš„æ¨¡å‹ã€‚å®éªŒè¡¨æ˜ï¼ŒSPD ä¸ä»…èƒ½æœ‰æ•ˆé¿å…å­¦ä¹ å‚æ•°çš„æ”¶ç¼© (shrinkage) é—®é¢˜ï¼Œè¿˜èƒ½åœ¨ç©å…·æ¨¡å‹ä¸­æ›´å‡†ç¡®åœ°è¯†åˆ« ground truth æœºåˆ¶ã€‚é€šè¿‡å°†å› æœä¸­ä»‹åˆ†æ (causal mediation analysis) ä¸ç½‘ç»œåˆ†è§£æ–¹æ³•ç›¸ç»“åˆï¼Œè¯¥ç ”ç©¶æ¶ˆé™¤äº†çº¿æ€§å‚æ•°åˆ†è§£å‘å¤§æ¨¡å‹æ‰©å±•çš„éšœç¢ã€‚è¿™ä¸€è¿›å±•ä¸ºæœºæ¢°è§£é‡Šæ€§ (mechanistic interpretability) é¢†åŸŸå¼€è¾Ÿäº†æ–°çš„ç ”ç©¶æ–¹å‘ï¼Œå¹¶æä¾›äº†å¼€æºåº“ä»¥æ”¯æŒåç»­å®éªŒä¸åº”ç”¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20790v2",
      "published_date": "2025-06-25 19:26:31 UTC",
      "updated_date": "2025-09-04 11:41:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:21:54.815145+00:00"
    },
    {
      "arxiv_id": "2506.20759v1",
      "title": "Agile Management for Machine Learning: A Systematic Mapping Study",
      "title_zh": "æœºå™¨å­¦ä¹ æ•æ·ç®¡ç†ï¼šç³»ç»Ÿæ€§æ˜ å°„ç ”ç©¶",
      "authors": [
        "Lucas Romao",
        "Hugo Villamizar",
        "Romeu Oliveira",
        "Silvio Alonso",
        "Marcos Kalinowski"
      ],
      "abstract": "[Context] Machine learning (ML)-enabled systems are present in our society, driving significant digital transformations. The dynamic nature of ML development, characterized by experimental cycles and rapid changes in data, poses challenges to traditional project management. Agile methods, with their flexibility and incremental delivery, seem well-suited to address this dynamism. However, it is unclear how to effectively apply these methods in the context of ML-enabled systems, where challenges require tailored approaches. [Goal] Our goal is to outline the state of the art in agile management for ML-enabled systems. [Method] We conducted a systematic mapping study using a hybrid search strategy that combines database searches with backward and forward snowballing iterations. [Results] Our study identified 27 papers published between 2008 and 2024. From these, we identified eight frameworks and categorized recommendations and practices into eight key themes, such as Iteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable Model. The main challenge identified across studies was accurate effort estimation for ML-related tasks. [Conclusion] This study contributes by mapping the state of the art and identifying open gaps in the field. While relevant work exists, more robust empirical evaluation is still needed to validate these contributions.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹æœºå™¨å­¦ä¹ (Machine Learning)ç³»ç»Ÿå› å®éªŒå‘¨æœŸå’Œæ•°æ®å¿«é€Ÿå˜åŒ–è€Œé¢ä¸´çš„é¡¹ç›®ç®¡ç†æŒ‘æˆ˜ï¼Œæ—¨åœ¨æ¢è®¨æœºå™¨å­¦ä¹ æ”¯æŒç³»ç»Ÿçš„æ•æ·ç®¡ç†(Agile Management)ç°çŠ¶ã€‚ç ”ç©¶é‡‡ç”¨äº†ç³»ç»Ÿæ˜ å°„ç ”ç©¶(Systematic Mapping Study)æ–¹æ³•ï¼Œç»“åˆæ•°æ®åº“æœç´¢å’Œé›ªçƒæ³•(Snowballing)å¯¹2008å¹´è‡³2024å¹´é—´çš„æ–‡çŒ®è¿›è¡Œäº†åˆ†æã€‚è°ƒæŸ¥å…±è¯†åˆ«å‡º27ç¯‡ç›¸å…³è®ºæ–‡ï¼Œå¹¶ä»ä¸­æ€»ç»“äº†8ä¸ªç®¡ç†æ¡†æ¶ä»¥åŠæ¶µç›–è¿­ä»£çµæ´»æ€§(Iteration Flexibility)ã€åˆ›æ–°çš„ ML-specific Artifacts å’Œæœ€å°å¯è¡Œæ¨¡å‹(Minimal Viable Model)ç­‰åœ¨å†…çš„8ä¸ªæ ¸å¿ƒä¸»é¢˜ã€‚ç»“æœè¡¨æ˜ï¼Œå¯¹ ML ç›¸å…³ä»»åŠ¡è¿›è¡Œå‡†ç¡®çš„å·¥ä½œé‡ä¼°ç®—(Effort Estimation)æ˜¯è¯¥é¢†åŸŸç›®å‰é¢ä¸´çš„ä¸»è¦ç®¡ç†æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶é€šè¿‡ç³»ç»Ÿåœ°æ˜ å°„æŠ€æœ¯ç°çŠ¶ï¼Œä¸ºè¯¥é¢†åŸŸæä¾›äº†é‡è¦çš„å‚è€ƒèƒŒæ™¯ï¼Œå¹¶æŒ‡å‡ºæœªæ¥ä»éœ€è¦æ›´å¤šç»éªŒè¯„ä¼°(Empirical Evaluation)æ¥éªŒè¯ç›¸å…³ç®¡ç†è´¡çŒ®çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication at the 51st Euromicro Conference Series on Software Engineering and Advanced Applications (SEAA) 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.20759v1",
      "published_date": "2025-06-25 18:47:08 UTC",
      "updated_date": "2025-06-25 18:47:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:22:40.613907+00:00"
    },
    {
      "arxiv_id": "2506.20748v1",
      "title": "Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on Human Prosocial Behavior Toward Chatbots",
      "title_zh": "æ¢ç©¶èŠå¤©æœºå™¨äººæ‹ŸäººåŒ–ä¸äººç±»å…±æƒ…å¯¹äººç±»æŒ‡å‘èŠå¤©æœºå™¨äººçš„äº²ç¤¾ä¼šè¡Œä¸ºçš„å½±å“",
      "authors": [
        "Jingshu Li",
        "Zicheng Zhu",
        "Renwen Zhang",
        "Yi-Chieh Lee"
      ],
      "abstract": "Chatbots are increasingly integrated into people's lives and are widely used to help people. Recently, there has also been growing interest in the reverse direction-humans help chatbots-due to a wide range of benefits including better chatbot performance, human well-being, and collaborative outcomes. However, little research has explored the factors that motivate people to help chatbots. To address this gap, we draw on the Computers Are Social Actors (CASA) framework to examine how chatbot anthropomorphism-including human-like identity, emotional expression, and non-verbal expression-influences human empathy toward chatbots and their subsequent prosocial behaviors and intentions. We also explore people's own interpretations of their prosocial behaviors toward chatbots. We conducted an online experiment (N = 244) in which chatbots made mistakes in a collaborative image labeling task and explained the reasons to participants. We then measured participants' prosocial behaviors and intentions toward the chatbots. Our findings revealed that human identity and emotional expression of chatbots increased participants' prosocial behavior and intention toward chatbots, with empathy mediating these effects. Qualitative analysis further identified two motivations for participants' prosocial behaviors: empathy for the chatbot and perceiving the chatbot as human-like. We discuss the implications of these results for understanding and promoting human prosocial behaviors toward chatbots.",
      "tldr_zh": "è¯¥ç ”ç©¶åŸºäºComputers Are Social Actors (CASA)æ¡†æ¶ï¼Œæ¢è®¨äº†èŠå¤©æœºå™¨äººæ‹ŸäººåŒ–(Anthropomorphism)ä¸äººç±»åŒç†å¿ƒ(Empathy)å¯¹äººç±»å‘æœºå™¨äººæä¾›äº²ç¤¾ä¼šè¡Œä¸º(Prosocial Behavior)çš„å½±å“ã€‚é€šè¿‡ä¸€é¡¹åŒ…å«244åå‚ä¸è€…çš„åœ¨çº¿å®éªŒï¼Œç ”ç©¶è€…è§‚å¯Ÿäº†åœ¨åä½œå›¾åƒæ ‡æ³¨ä»»åŠ¡ä¸­ï¼Œå½“æœºå™¨äººå‡ºç°é”™è¯¯æ—¶äººç±»çš„ååº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæœºå™¨äººçš„ç±»äººèº«ä»½(Human Identity)å’Œæƒ…æ„Ÿè¡¨è¾¾(Emotional Expression)èƒ½æ˜¾è‘—å¢å¼ºäººç±»å¯¹å…¶äº§ç”Ÿçš„äº²ç¤¾ä¼šè¡Œä¸ºåŠæ„æ„¿ï¼Œä¸”åŒç†å¿ƒåœ¨è¿™ä¸€è¿‡ç¨‹ä¸­èµ·åˆ°äº†å…³é”®çš„ä¸­ä»‹ä½œç”¨ã€‚å®šæ€§åˆ†æè¿›ä¸€æ­¥ç¡®å®šäº†äººç±»äº²ç¤¾ä¼šè¡Œä¸ºçš„ä¸¤å¤§åŠ¨æœºï¼šå¯¹æœºå™¨äººçš„åŒç†å¿ƒä»¥åŠå°†å…¶æ„ŸçŸ¥ä¸ºç±»äººå®ä½“ã€‚è¯¥é¡¹ç ”ç©¶ä¸ºç†è§£å¹¶ä¿ƒè¿›äººæœºåä½œä¸­çš„äº²ç¤¾ä¼šäº’åŠ¨æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20748v1",
      "published_date": "2025-06-25 18:16:14 UTC",
      "updated_date": "2025-06-25 18:16:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:21:46.939097+00:00"
    },
    {
      "arxiv_id": "2506.20737v1",
      "title": "MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation",
      "title_zh": "MAGPIEï¼šå¤šæ™ºèƒ½ä½“è¯­å¢ƒéšç§è¯„ä¼°æ•°æ®é›†",
      "authors": [
        "Gurusha Juneja",
        "Alon Albalak",
        "Wenyue Hua",
        "William Yang Wang"
      ],
      "abstract": "The proliferation of LLM-based agents has led to increasing deployment of inter-agent collaboration for tasks like scheduling, negotiation, resource allocation etc. In such systems, privacy is critical, as agents often access proprietary tools and domain-specific databases requiring strict confidentiality. This paper examines whether LLM-based agents demonstrate an understanding of contextual privacy. And, if instructed, do these systems preserve inference time user privacy in non-adversarial multi-turn conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents primarily assess single-turn, low-complexity tasks where private information can be easily excluded. We first present a benchmark - MAGPIE comprising 158 real-life high-stakes scenarios across 15 domains. These scenarios are designed such that complete exclusion of private data impedes task completion yet unrestricted information sharing could lead to substantial losses. We then evaluate the current state-of-the-art LLMs on (a) their understanding of contextually private data and (b) their ability to collaborate without violating user privacy. Empirical experiments demonstrate that current models, including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual privacy, misclassifying private data as shareable 25.2\\% and 43.6\\% of the time. In multi-turn conversations, these models disclose private information in 59.9\\% and 50.5\\% of cases even under explicit privacy instructions. Furthermore, multi-agent systems fail to complete tasks in 71\\% of scenarios. These results underscore that current models are not aligned towards both contextual privacy preservation and collaborative task-solving.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MAGPIEï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(Multi-Agent Systems)ä¸­ä¸Šä¸‹æ–‡éšç§è¯„ä¼°(Contextual Privacy Evaluation)çš„åŸºå‡†æ•°æ®é›†ï¼ŒåŒ…å«è·¨è¶Š15ä¸ªé¢†åŸŸçš„158ä¸ªçœŸå®é«˜é£é™©åœºæ™¯ã€‚MAGPIEæ—¨åœ¨è§£å†³ç°æœ‰åŸºå‡†æµ‹è¯•ä»…é™äºå•è½®ã€ä½å¤æ‚åº¦ä»»åŠ¡çš„å±€é™æ€§ï¼Œå…¶è®¾è®¡çš„åœºæ™¯è¦æ±‚åœ¨ä¸æ³„éœ²ä¼šå¯¼è‡´é‡å¤§æŸå¤±çš„ç§å¯†ä¿¡æ¯å‰æä¸‹å®Œæˆä»»åŠ¡ã€‚é€šè¿‡è¯„ä¼°GPT-4oå’ŒClaude-2.7-Sonnetç­‰ä¸»æµå¤§è¯­è¨€æ¨¡å‹(LLMs)ï¼Œç ”ç©¶å‘ç°è¿™äº›æ¨¡å‹ç¼ºä¹å¯¹ä¸Šä¸‹æ–‡éšç§çš„ç¨³å¥ç†è§£ï¼Œå¸¸å°†éšç§æ•°æ®è¯¯åˆ¤ä¸ºå¯å…±äº«ã€‚åœ¨å¤šè½®å¯¹è¯ä¸­ï¼Œå³ä½¿æœ‰æ˜ç¡®æŒ‡ä»¤ï¼Œæ¨¡å‹ä»ä¼šåœ¨è¶…è¿‡åŠæ•°çš„æ¡ˆä¾‹ä¸­æ³„éœ²éšç§ï¼Œä¸”å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨71%çš„åœºæ™¯ä¸­æ— æ³•å®Œæˆä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰çš„LLMsåœ¨ä¸Šä¸‹æ–‡éšç§ä¿æŠ¤ä¸åä½œå¼ä»»åŠ¡è§£å†³ä¹‹é—´å°šæœªå®ç°æœ‰æ•ˆçš„å¯¹é½(Alignment)ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20737v1",
      "published_date": "2025-06-25 18:04:25 UTC",
      "updated_date": "2025-06-25 18:04:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:23:03.605866+00:00"
    },
    {
      "arxiv_id": "2506.20729v1",
      "title": "Test-time Scaling Techniques in Theoretical Physics -- A Comparison of Methods on the TPBench Dataset",
      "title_zh": "ç†è®ºç‰©ç†ä¸­çš„æµ‹è¯•æ—¶æ‰©å±•æŠ€æœ¯ï¼šåŸºäº TPBench æ•°æ®é›†çš„æ–¹æ³•å¯¹æ¯”",
      "authors": [
        "Zhiqi Gao",
        "Tianyi Li",
        "Yurii Kvasiuk",
        "Sai Chaitanya Tadepalli",
        "Maja Rudolph",
        "Daniel J. H. Chung",
        "Frederic Sala",
        "Moritz MÃ¼nchmeyer"
      ],
      "abstract": "Large language models (LLMs) have shown strong capabilities in complex reasoning, and test-time scaling techniques can enhance their performance with comparably low cost. Many of these methods have been developed and evaluated on mathematical reasoning benchmarks such as AIME. This paper investigates whether the lessons learned from these benchmarks generalize to the domain of advanced theoretical physics. We evaluate a range of common test-time scaling methods on the TPBench physics dataset and compare their effectiveness with results on AIME. To better leverage the structure of physics problems, we develop a novel, symbolic weak-verifier framework to improve parallel scaling results. Our empirical results demonstrate that this method significantly outperforms existing test-time scaling approaches on TPBench. We also evaluate our method on AIME, confirming its effectiveness in solving advanced mathematical problems. Our findings highlight the power of step-wise symbolic verification for tackling complex scientific problems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„æ¨ç†æ—¶æ‰©å±•æŠ€æœ¯(test-time scaling)åœ¨ç†è®ºç‰©ç†é¢†åŸŸçš„åº”ç”¨ï¼Œæ—¨åœ¨éªŒè¯æ•°å­¦æ¨ç†åŸºå‡†çš„ç»éªŒæ˜¯å¦èƒ½è¿ç§»è‡³å¤æ‚çš„ç‰©ç†é¢†åŸŸã€‚ç ”ç©¶è€…åœ¨ TPBench æ•°æ®é›†ä¸Šè¯„ä¼°äº†å¤šç§å¸¸ç”¨çš„æ¨ç†æ—¶æ‰©å±•æ–¹æ³•ï¼Œå¹¶å°†å…¶ä¸ AIME çš„ç»“æœè¿›è¡Œå¯¹æ¯”ã€‚é’ˆå¯¹ç‰©ç†é—®é¢˜çš„ç‰¹æ®Šç»“æ„ï¼Œè¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„ç¬¦å·å¼±éªŒè¯å™¨æ¡†æ¶(symbolic weak-verifier framework)ï¼Œç”¨ä»¥æå‡å¹¶è¡Œæ‰©å±•çš„æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ TPBench ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¸”åœ¨ AIME é«˜çº§æ•°å­¦é—®é¢˜ä¸Šä¹Ÿè¡¨ç°å‡ºæå¼ºçš„æœ‰æ•ˆæ€§ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†é€æ­¥ç¬¦å·éªŒè¯(step-wise symbolic verification)åœ¨è§£å†³å¤æ‚ç§‘å­¦æŒ‘æˆ˜ä¸­çš„æ ¸å¿ƒä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "astro-ph.CO",
        "cs.AI",
        "hep-ph",
        "hep-th"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.20729v1",
      "published_date": "2025-06-25 18:00:18 UTC",
      "updated_date": "2025-06-25 18:00:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:23:00.044595+00:00"
    },
    {
      "arxiv_id": "2506.20705v2",
      "title": "On Convolutions, Intrinsic Dimension, and Diffusion Models",
      "title_zh": "è®ºå·ç§¯ã€æœ¬å¾ç»´åº¦ä¸æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Kin Kwan Leung",
        "Rasa Hosseinzadeh",
        "Gabriel Loaiza-Ganem"
      ],
      "abstract": "The manifold hypothesis asserts that data of interest in high-dimensional ambient spaces, such as image data, lies on unknown low-dimensional submanifolds. Diffusion models (DMs) -- which operate by convolving data with progressively larger amounts of Gaussian noise and then learning to revert this process -- have risen to prominence as the most performant generative models, and are known to be able to learn distributions with low-dimensional support. For a given datum in one of these submanifolds, we should thus intuitively expect DMs to have implicitly learned its corresponding local intrinsic dimension (LID), i.e. the dimension of the submanifold it belongs to. Kamkari et al. (2024b) recently showed that this is indeed the case by linking this LID to the rate of change of the log marginal densities of the DM with respect to the amount of added noise, resulting in an LID estimator known as FLIPD. LID estimators such as FLIPD have a plethora of uses, among others they quantify the complexity of a given datum, and can be used to detect outliers, adversarial examples and AI-generated text. FLIPD achieves state-of-the-art performance at LID estimation, yet its theoretical underpinnings are incomplete since Kamkari et al. (2024b) only proved its correctness under the highly unrealistic assumption of affine submanifolds. In this work we bridge this gap by formally proving the correctness of FLIPD under realistic assumptions. Additionally, we show that an analogous result holds when Gaussian convolutions are replaced with uniform ones, and discuss the relevance of this result.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æµå½¢å‡è®¾(Manifold Hypothesis)ä¸‹æ‰©æ•£æ¨¡å‹(Diffusion Models)ä¸å±€éƒ¨å†…åœ¨ç»´åº¦(LID)ä¹‹é—´çš„å†…åœ¨è”ç³»ï¼ŒæŒ‡å‡ºæ‰©æ•£æ¨¡å‹åœ¨å¤„ç†é«˜ç»´ç©ºé—´æ•°æ®æ—¶èƒ½éšå¼å­¦ä¹ å…¶ä½ç»´æ”¯æ’‘é›†çš„å‡ ä½•ç‰¹å¾ã€‚é’ˆå¯¹ç°æœ‰LIDä¼°è®¡å™¨FLIPDåœ¨ç†è®ºæ¨å¯¼ä¸­ä»…é™äºä»¿å°„å­æµå½¢(Affine Submanifolds)è¿™ä¸€ä¸ç°å®å‡è®¾çš„é—®é¢˜ï¼Œæœ¬æ–‡åœ¨æ›´å…·æ™®é€‚æ€§å’Œç°å®æ„ä¹‰çš„å‡è®¾ä¸‹ï¼Œæ­£å¼è¯æ˜äº†FLIPDä¼°è®¡å±€éƒ¨å†…åœ¨ç»´åº¦çš„æ­£ç¡®æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°å½“é«˜æ–¯å·ç§¯(Gaussian Convolutions)è¢«å‡åŒ€å·ç§¯(Uniform Convolutions)å–ä»£æ—¶ï¼Œç±»ä¼¼çš„ç†è®ºç»“æœä¾ç„¶æˆç«‹ï¼Œå¹¶æ¢è®¨äº†è¯¥ç»“è®ºçš„ç›¸å…³æ€§ã€‚è¯¥å·¥ä½œå¡«è¡¥äº†æ‰©æ•£æ¨¡å‹åœ¨ç»´åº¦ä¼°è®¡æ–¹é¢çš„ç†è®ºç©ºç™½ï¼Œä¸ºåˆ©ç”¨ç”Ÿæˆæ¨¡å‹é‡åŒ–æ•°æ®å¤æ‚æ€§ã€æ£€æµ‹å¼‚å¸¸å€¼åŠAIç”Ÿæˆæ–‡æœ¬æä¾›äº†åšå®çš„æ•°å­¦åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "TMLR 2025 (expert certification)",
      "pdf_url": "https://arxiv.org/pdf/2506.20705v2",
      "published_date": "2025-06-25 18:00:00 UTC",
      "updated_date": "2025-10-13 17:59:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:23:07.223019+00:00"
    },
    {
      "arxiv_id": "2506.20702v2",
      "title": "The Singapore Consensus on Global AI Safety Research Priorities",
      "title_zh": "Singapore å…³äºå…¨çƒäººå·¥æ™ºèƒ½å®‰å…¨ç ”ç©¶ä¼˜å…ˆäº‹é¡¹çš„å…±è¯†",
      "authors": [
        "Yoshua Bengio",
        "Tegan Maharaj",
        "Luke Ong",
        "Stuart Russell",
        "Dawn Song",
        "Max Tegmark",
        "Lan Xue",
        "Ya-Qin Zhang",
        "Stephen Casper",
        "Wan Sie Lee",
        "SÃ¶ren Mindermann",
        "Vanessa Wilfred",
        "Vidhisha Balachandran",
        "Fazl Barez",
        "Michael Belinsky",
        "Imane Bello",
        "Malo Bourgon",
        "Mark Brakel",
        "SimÃ©on Campos",
        "Duncan Cass-Beggs",
        "Jiahao Chen",
        "Rumman Chowdhury",
        "Kuan Chua Seah",
        "Jeff Clune",
        "Juntao Dai",
        "Agnes Delaborde",
        "Nouha Dziri",
        "Francisco Eiras",
        "Joshua Engels",
        "Jinyu Fan",
        "Adam Gleave",
        "Noah Goodman",
        "Fynn Heide",
        "Johannes Heidecke",
        "Dan Hendrycks",
        "Cyrus Hodes",
        "Bryan Low Kian Hsiang",
        "Minlie Huang",
        "Sami Jawhar",
        "Wang Jingyu",
        "Adam Tauman Kalai",
        "Meindert Kamphuis",
        "Mohan Kankanhalli",
        "Subhash Kantamneni",
        "Mathias Bonde Kirk",
        "Thomas Kwa",
        "Jeffrey Ladish",
        "Kwok-Yan Lam",
        "Wan Lee Sie",
        "Taewhi Lee",
        "Xiaojian Li",
        "Jiajun Liu",
        "Chaochao Lu",
        "Yifan Mai",
        "Richard Mallah",
        "Julian Michael",
        "Nick MoÃ«s",
        "Simon MÃ¶ller",
        "Kihyuk Nam",
        "Kwan Yee Ng",
        "Mark Nitzberg",
        "Besmira Nushi",
        "SeÃ¡n O hÃ‰igeartaigh",
        "Alejandro Ortega",
        "Pierre PeignÃ©",
        "James Petrie",
        "Benjamin Prud'Homme",
        "Reihaneh Rabbany",
        "Nayat Sanchez-Pi",
        "Sarah Schwettmann",
        "Buck Shlegeris",
        "Saad Siddiqui",
        "Aradhana Sinha",
        "MartÃ­n Soto",
        "Cheston Tan",
        "Dong Ting",
        "William Tjhi",
        "Robert Trager",
        "Brian Tse",
        "Anthony Tung K. H.",
        "Vanessa Wilfred",
        "John Willes",
        "Denise Wong",
        "Wei Xu",
        "Rongwu Xu",
        "Yi Zeng",
        "HongJiang Zhang",
        "Djordje Å½ikeliÄ‡"
      ],
      "abstract": "Rapidly improving AI capabilities and autonomy hold significant promise of transformation, but are also driving vigorous debate on how to ensure that AI is safe, i.e., trustworthy, reliable, and secure. Building a trusted ecosystem is therefore essential -- it helps people embrace AI with confidence and gives maximal space for innovation while avoiding backlash.\n  The \"2025 Singapore Conference on AI (SCAI): International Scientific Exchange on AI Safety\" aimed to support research in this space by bringing together AI scientists across geographies to identify and synthesise research priorities in AI safety. This resulting report builds on the International AI Safety Report chaired by Yoshua Bengio and backed by 33 governments. By adopting a defence-in-depth model, this report organises AI safety research domains into three types: challenges with creating trustworthy AI systems (Development), challenges with evaluating their risks (Assessment), and challenges with monitoring and intervening after deployment (Control).",
      "tldr_zh": "è¯¥æŠ¥å‘Šæ€»ç»“äº† 2025 Singapore Conference on AI (SCAI) æ±‡é›†å…¨çƒç§‘å­¦å®¶è¾¾æˆçš„å…±è¯†ï¼Œæ—¨åœ¨ç¡®å®šå¹¶æ•´åˆ AI Safety ç ”ç©¶çš„ä¼˜å…ˆäº‹é¡¹ã€‚ç ”ç©¶å»ºç«‹åœ¨ç”± Yoshua Bengio ä¸»æŒã€å¤šå›½æ”¿åºœæ”¯æŒçš„ International AI Safety Report åŸºç¡€ä¹‹ä¸Šï¼Œé€šè¿‡é‡‡ç”¨ Defense-in-depth æ¨¡å‹ï¼Œå°†å®‰å…¨ç ”ç©¶é¢†åŸŸç³»ç»Ÿæ€§åœ°åˆ’åˆ†ä¸ºä¸‰ä¸ªæ ¸å¿ƒç»´åº¦ã€‚å…¶ä¸­ï¼ŒDevelopment ç»´åº¦å…³æ³¨æ„å»º Trustworthy AI ç³»ç»Ÿçš„æŠ€æœ¯æŒ‘æˆ˜ï¼ŒAssessment ç»´åº¦è‡´åŠ›äºè§£å†³é£é™©è¯„ä¼°ä¸­çš„éš¾é¢˜ï¼Œè€Œ Control ç»´åº¦åˆ™èšç„¦äºç³»ç»Ÿéƒ¨ç½²åçš„ Monitoring ä¸å¹²é¢„æœºåˆ¶ã€‚è¯¥å…±è¯†ä¸ºè§£å†³ AI ç³»ç»Ÿçš„å¯é æ€§ã€å®‰å…¨æ€§å’Œä¿¡ä»»é—®é¢˜æä¾›äº†æ˜ç¡®çš„ç§‘ç ”è·¯çº¿å›¾ï¼Œæ—¨åœ¨é€šè¿‡æ„å»ºå—ä¿¡ä»»çš„ç”Ÿæ€ç³»ç»Ÿï¼Œåœ¨æ¨åŠ¨æŠ€æœ¯åˆ›æ–°çš„åŒæ—¶æœ‰æ•ˆé˜²èŒƒæ½œåœ¨é£é™©ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Final report from the \"2025 Singapore Conference on AI (SCAI)\" held April 26: https://www.scai.gov.sg/2025/scai2025-report",
      "pdf_url": "https://arxiv.org/pdf/2506.20702v2",
      "published_date": "2025-06-25 17:59:50 UTC",
      "updated_date": "2025-06-30 21:04:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:23:27.621851+00:00"
    },
    {
      "arxiv_id": "2506.20701v1",
      "title": "Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models",
      "title_zh": "Diffusion Tree Samplingï¼šæ‰©æ•£æ¨¡å‹çš„å¯æ‰©å±•æ¨ç†æ—¶å¯¹é½",
      "authors": [
        "Vineet Jain",
        "Kusha Sareen",
        "Mohammad Pedramfar",
        "Siamak Ravanbakhsh"
      ],
      "abstract": "Adapting a pretrained diffusion model to new objectives at inference time remains an open problem in generative modeling. Existing steering methods suffer from inaccurate value estimation, especially at high noise levels, which biases guidance. Moreover, information from past runs is not reused to improve sample quality, resulting in inefficient use of compute. Inspired by the success of Monte Carlo Tree Search, we address these limitations by casting inference-time alignment as a search problem that reuses past computations. We introduce a tree-based approach that samples from the reward-aligned target density by propagating terminal rewards back through the diffusion chain and iteratively refining value estimates with each additional generation. Our proposed method, Diffusion Tree Sampling (DTS), produces asymptotically exact samples from the target distribution in the limit of infinite rollouts, and its greedy variant, Diffusion Tree Search (DTS$^\\star$), performs a global search for high reward samples. On MNIST and CIFAR-10 class-conditional generation, DTS matches the FID of the best-performing baseline with up to $10\\times$ less compute. In text-to-image generation and language completion tasks, DTS$^\\star$ effectively searches for high reward samples that match best-of-N with up to $5\\times$ less compute. By reusing information from previous generations, we get an anytime algorithm that turns additional compute into steadily better samples, providing a scalable approach for inference-time alignment of diffusion models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹(diffusion model)åœ¨æ¨ç†æ—¶å¯¹é½(inference-time alignment)æ–°ç›®æ ‡çš„é—®é¢˜ï¼ŒæŒ‡å‡ºå½“å‰çš„å¼•å¯¼æ–¹æ³•åœ¨å™ªéŸ³æ°´å¹³è¾ƒé«˜æ—¶å­˜åœ¨ä»·å€¼ä¼°è®¡ä¸å‡†åŠè®¡ç®—æ•ˆç‡ä½ä¸‹çš„å±€é™ã€‚å—è’™ç‰¹å¡æ´›æ ‘æœç´¢(Monte Carlo Tree Search)çš„å¯å‘ï¼Œä½œè€…å°†æ¨ç†æ—¶å¯¹é½å»ºæ¨¡ä¸ºä¸€ä¸ªæœç´¢é—®é¢˜ï¼Œå¹¶æå‡ºäº†Diffusion Tree Sampling (DTS)æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†ç»ˆç«¯å¥–åŠ±(terminal rewards)æ²¿æ‰©æ•£é“¾å›ä¼ ï¼Œå¹¶åˆ©ç”¨åç»­ç”Ÿæˆçš„æ ·æœ¬ä¸æ–­ä¼˜åŒ–ä»·å€¼ä¼°è®¡ï¼Œå®ç°äº†ä»å¥–åŠ±å¯¹é½ç›®æ ‡åˆ†å¸ƒä¸­çš„é‡‡æ ·ã€‚è¯¥æ¡†æ¶åŒ…å«èƒ½ç”Ÿæˆæ¸è¿‘ç²¾ç¡®æ ·æœ¬çš„DTSï¼Œä»¥åŠæ—¨åœ¨å…¨å±€æœç´¢é«˜å¥–åŠ±æ ·æœ¬çš„è´ªå©ªå˜ä½“Diffusion Tree Search (DTS*)ã€‚åœ¨MNISTå’ŒCIFAR-10çš„ç±»åˆ«æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒDTSä»¥å°‘äºåŸºçº¿æ¨¡å‹10å€çš„è®¡ç®—é‡è¾¾åˆ°äº†ç›¸åŒçš„FIDæ€§èƒ½æŒ‡æ ‡ã€‚åœ¨æ–‡æœ¬ç”Ÿæˆå›¾åƒ(text-to-image)åŠè¯­è¨€è¡¥å…¨ä»»åŠ¡ä¸­ï¼ŒDTS*æœç´¢é«˜å¥–åŠ±æ ·æœ¬çš„æ•ˆç‡æ¯”best-of-Né‡‡æ ·é«˜å‡º5å€ã€‚æ€»ä½“è€Œè¨€ï¼ŒDTSä½œä¸ºä¸€ç§å¯æ‰©å±•çš„éšæ—¶ç®—æ³•(anytime algorithm)ï¼Œé€šè¿‡å¤ç”¨å†å²ç”Ÿæˆä¿¡æ¯å°†é¢å¤–è®¡ç®—èµ„æºè½¬åŒ–ä¸ºæ›´é«˜çš„æ ·æœ¬è´¨é‡ï¼Œä¸ºæ‰©æ•£æ¨¡å‹çš„æ¨ç†æ—¶å¯¹é½æä¾›äº†é«˜æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20701v1",
      "published_date": "2025-06-25 17:59:10 UTC",
      "updated_date": "2025-06-25 17:59:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:23:08.313082+00:00"
    },
    {
      "arxiv_id": "2506.20666v3",
      "title": "Using cognitive models to reveal value trade-offs in language models",
      "title_zh": "åˆ©ç”¨è®¤çŸ¥æ¨¡å‹æ­ç¤ºè¯­è¨€æ¨¡å‹ä¸­çš„ä»·å€¼æƒè¡¡",
      "authors": [
        "Sonia K. Murthy",
        "Rosie Zhao",
        "Jennifer Hu",
        "Sham Kakade",
        "Markus Wulfmeier",
        "Peng Qian",
        "Tomer Ullman"
      ],
      "abstract": "Value trade-offs are an integral part of human decision-making and language use, however, current tools for interpreting such dynamic and multi-faceted notions of values in LLMs are limited. In cognitive science, so-called \"cognitive models\" provide formal accounts of such trade-offs in humans, by modeling the weighting of a speaker's competing utility functions in choosing an action or utterance. Here we use a leading cognitive model of polite speech to systematically evaluate value trade-offs in two encompassing model settings: degrees of reasoning \"effort\" in frontier black-box models, and RL post-training dynamics of open-source models. Our results highlight patterns of higher informational utility than social utility in reasoning models' default behavior, and demonstrate that these patterns shift in predictable ways when models are prompted to prioritize certain goals over others. Our findings from LLMs' training dynamics suggest large shifts in utility values early on in training with persistent effects of the choice of base model and pretraining data, compared to feedback dataset or alignment method. Our framework offers a flexible tool for probing value trade-offs across diverse model types, providing insights for generating hypotheses about other social behaviors such as sycophancy and for shaping training regimes that better control trade-offs between values during model development.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨è®¤çŸ¥ç§‘å­¦ä¸­çš„è®¤çŸ¥æ¨¡å‹(cognitive models)æ¥æ­ç¤ºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šç»´ä»·å€¼è§‚ä¹‹é—´çš„æƒè¡¡(value trade-offs)ã€‚ç ”ç©¶è€…é‡‡ç”¨äº†ä¸€ä¸ªé¢†å…ˆçš„ç¤¼è²Œè¨€è¯­æ¨¡å‹ï¼Œé€šè¿‡å¯¹å‘è¨€è€…çš„ç«äº‰æ€§æ•ˆç”¨å‡½æ•°è¿›è¡Œå»ºæ¨¡ï¼Œç³»ç»Ÿè¯„ä¼°äº†å‰æ²¿æ¨ç†æ¨¡å‹ä»¥åŠå¼€æºæ¨¡å‹å¼ºåŒ–å­¦ä¹ (RL)è®­ç»ƒåŠ¨æ€ä¸­çš„ä»·å€¼æƒé‡å˜åŒ–ã€‚ç»“æœæ˜¾ç¤ºï¼Œæ¨ç†æ¨¡å‹åœ¨é»˜è®¤æƒ…å†µä¸‹å±•ç°å‡ºæ¯”ç¤¾äº¤æ•ˆç”¨(social utility)æ›´é«˜çš„ä¿¡æ¯æ•ˆç”¨(informational utility)ï¼Œä½†è¿™ä¸€æ¨¡å¼ä¼šéšç‰¹å®šç›®æ ‡çš„æç¤ºè¯å¼•å¯¼è€Œå‘ç”Ÿå¯é¢„æµ‹çš„åç§»ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹è®­ç»ƒåŠ¨æ€çš„åˆ†æè¡¨æ˜ï¼Œæ•ˆç”¨å€¼çš„é‡å¤§è½¬å˜ä¸»è¦å‘ç”Ÿåœ¨è®­ç»ƒæ—©æœŸï¼Œä¸”åŸºåº§æ¨¡å‹å’Œé¢„è®­ç»ƒæ•°æ®å¯¹æœ€ç»ˆä»·å€¼å–å‘çš„å½±å“æ¯”åé¦ˆæ•°æ®é›†æˆ–å¯¹é½æ–¹æ³•æ›´ä¸ºæŒä¹…ã€‚è¯¥æ¡†æ¶ä¸ºæ¢æµ‹è°„åªš(sycophancy)ç­‰å¤æ‚ç¤¾ä¼šè¡Œä¸ºæä¾›äº†çµæ´»çš„æ¢æµ‹å·¥å…·ï¼Œæœ‰åŠ©äºåœ¨æ¨¡å‹å¼€å‘è¿‡ç¨‹ä¸­è®¾è®¡æ›´ç²¾å‡†çš„è®­ç»ƒæ–¹æ¡ˆæ¥æ§åˆ¶ä¸åŒä»·å€¼é—´çš„æƒè¡¡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.20666v3",
      "published_date": "2025-06-25 17:58:12 UTC",
      "updated_date": "2025-10-06 17:52:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:25:15.938019+00:00"
    },
    {
      "arxiv_id": "2506.21638v3",
      "title": "R1-Ranker: Teaching LLM Rankers to Reason",
      "title_zh": "R1-Rankerï¼šèµ‹äºˆå¤§è¯­è¨€æ¨¡å‹æ’åºå™¨æ¨ç†èƒ½åŠ›",
      "authors": [
        "Tao Feng",
        "Zhigang Hua",
        "Zijie Lei",
        "Yan Xie",
        "Shuang Yang",
        "Bo Long",
        "Jiaxuan You"
      ],
      "abstract": "Large language models (LLMs) have recently shown strong reasoning abilities in domains like mathematics, coding, and scientific problem-solving, yet their potential for ranking tasks, where prime examples include retrieval, recommender systems, and LLM routing, remains underexplored. Ranking requires complex reasoning across heterogeneous candidates, but existing LLM-based rankers are often domain-specific, tied to fixed backbones, and lack iterative refinement, limiting their ability to fully exploit LLMs' reasoning potential. To address these challenges, we propose R1-Ranker, a reasoning-incentive framework built on reinforcement learning, with two complementary designs: DRanker, which generates full rankings in one shot, and IRanker, which decomposes ranking into an iterative elimination process with step-wise rewards to encourage deeper reasoning. We evaluate unified R1-Rankers on nine datasets spanning recommendation, routing, and passage ranking, showing that IRanker-3B consistently achieves state-of-the-art performance, surpasses larger 7B models on some tasks, and yields a 15.7% average relative improvement. Ablation and generalization experiments further confirm the critical role of reinforcement learning and iterative reasoning, with IRanker-3B improving zero-shot performance by over 9% on out-of-domain tasks and reasoning traces boosting other LLMs by up to 22.87%. These results demonstrate that unifying diverse ranking tasks with a single reasoning-driven foundation model is both effective and essential for advancing LLM reasoning in ranking scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰ LLM-based rankers åœ¨æ£€ç´¢ã€æ¨èç³»ç»ŸåŠè·¯ç”±ç­‰æ’åºä»»åŠ¡ä¸­ç¼ºä¹æ·±å…¥æ¨ç†ä¸è¿­ä»£ä¼˜åŒ–èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº† R1-Ranker è¿™ä¸€åŸºäº reinforcement learning çš„æ¨ç†æ¿€åŠ±æ¡†æ¶ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ç§äº’è¡¥è®¾è®¡ï¼šDRanker ç”¨äºå•æ¬¡ç”Ÿæˆå®Œæ•´æ’åï¼Œè€Œ IRanker åˆ™é€šè¿‡å¸¦æœ‰ step-wise rewards çš„è¿­ä»£æ¶ˆé™¤è¿‡ç¨‹æ¥é¼“åŠ±æ›´æ·±å±‚æ¬¡çš„æ¨ç†ã€‚åœ¨æ¶µç›– recommendationã€routing å’Œ passage ranking ç­‰é¢†åŸŸçš„ä¹ä¸ªæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒIRanker-3B è¾¾åˆ°äº† state-of-the-art æ€§èƒ½ï¼Œå¹³å‡ç›¸å¯¹æå‡ 15.7%ï¼Œå¹¶åœ¨å¤šä¸ªä»»åŠ¡ä¸­è¶…è¶Šäº†è§„æ¨¡æ›´å¤§çš„ 7B æ¨¡å‹ã€‚æ¶ˆèä¸æ³›åŒ–å®éªŒè¿›ä¸€æ­¥è¯æ˜äº† reinforcement learning å’Œ iterative reasoning çš„å…³é”®ä½œç”¨ï¼Œä½¿æ¨¡å‹åœ¨åŸŸå¤–ä»»åŠ¡çš„ zero-shot è¡¨ç°æå‡äº† 9% ä»¥ä¸Šã€‚è¯¥ç ”ç©¶è¡¨æ˜ï¼Œæ„å»ºä¸€ä¸ªç»Ÿä¸€çš„æ¨ç†é©±åŠ¨åŸºç¡€æ¨¡å‹å¯¹äºæå‡ LLMs åœ¨å¤æ‚æ’åºåœºæ™¯ä¸­çš„æ¨ç†æ½œåŠ›å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.21638v3",
      "published_date": "2025-06-25 17:56:06 UTC",
      "updated_date": "2025-10-16 04:41:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:23:29.078541+00:00"
    },
    {
      "arxiv_id": "2506.20664v1",
      "title": "The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind",
      "title_zh": "Decryptoï¼šå¤šæ™ºèƒ½ä½“æ¨ç†ä¸å¿ƒç†ç†è®ºåŸºå‡†æµ‹è¯•",
      "authors": [
        "Andrei Lupu",
        "Timon Willi",
        "Jakob Foerster"
      ],
      "abstract": "As Large Language Models (LLMs) gain agentic abilities, they will have to navigate complex multi-agent scenarios, interacting with human users and other agents in cooperative and competitive settings. This will require new reasoning skills, chief amongst them being theory of mind (ToM), or the ability to reason about the \"mental\" states of other agents. However, ToM and other multi-agent abilities in LLMs are poorly understood, since existing benchmarks suffer from narrow scope, data leakage, saturation, and lack of interactivity. We thus propose Decrypto, a game-based benchmark for multi-agent reasoning and ToM drawing inspiration from cognitive science, computational pragmatics and multi-agent reinforcement learning. It is designed to be as easy as possible in all other dimensions, eliminating confounding factors commonly found in other benchmarks. To our knowledge, it is also the first platform for designing interactive ToM experiments.\n  We validate the benchmark design through comprehensive empirical evaluations of frontier LLMs, robustness studies, and human-AI cross-play experiments. We find that LLM game-playing abilities lag behind humans and simple word-embedding baselines. We then create variants of two classic cognitive science experiments within Decrypto to evaluate three key ToM abilities. Surprisingly, we find that state-of-the-art reasoning models are significantly worse at those tasks than their older counterparts. This demonstrates that Decrypto addresses a crucial gap in current reasoning and ToM evaluations, and paves the path towards better artificial agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Decryptoï¼Œè¿™æ˜¯ä¸€ä¸ªå—è®¤çŸ¥ç§‘å­¦ã€è®¡ç®—è¯­ç”¨å­¦å’Œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å¯å‘çš„åŸºäºæ¸¸æˆçš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤šæ™ºèƒ½ä½“åä½œä¸ç«äº‰ç¯å¢ƒä¸­çš„æ¨ç†èƒ½åŠ›å’Œå¿ƒç†ç†è®º (Theory of Mind, ToM)ã€‚Decrypto é€šè¿‡æ’é™¤å…¶ä»–å¹²æ‰°å› ç´ å¹¶å¼•å…¥äº¤äº’å¼å®éªŒå¹³å°ï¼Œè§£å†³äº†ç°æœ‰åŸºå‡†æµ‹è¯•åœ¨è¯„ä¼°èŒƒå›´ã€æ•°æ®æ³„éœ²åŠäº’åŠ¨æ€§æ–¹é¢çš„ä¸è¶³ã€‚é€šè¿‡å¯¹å‰æ²¿æ¨¡å‹è¿›è¡Œç»éªŒè¯„ä¼°å’Œäººç±»ä¸äººå·¥æ™ºèƒ½äº¤å‰å¯¹æˆ˜ (human-AI cross-play) å®éªŒï¼Œç ”ç©¶å‘ç° LLMs çš„æ¸¸æˆè¡¨ç°ç›®å‰ä»è½åäºäººç±»å’Œç®€å•çš„è¯åµŒå…¥åŸºçº¿ (word-embedding baselines)ã€‚ä»¤äººæ„å¤–çš„æ˜¯ï¼Œå®éªŒç»“æœæ˜¾ç¤ºå½“å‰æœ€å…ˆè¿›çš„æ¨ç†æ¨¡å‹åœ¨ ToM ä»»åŠ¡ä¸Šçš„è¡¨ç°ç«Ÿç„¶æ˜¾è‘—å·®äºå…¶æ—©æœŸçš„å¯¹åº”æ¨¡å‹ (older counterparts)ã€‚è¯¥ç ”ç©¶å¡«è¡¥äº†å½“å‰å¤šæ™ºèƒ½ä½“æ¨ç†è¯„ä¼°çš„å…³é”®ç©ºç™½ï¼Œå¹¶ä¸ºå¼€å‘å…·å¤‡æ›´é«˜ç¤¾ä¼šæ™ºèƒ½çš„äººå·¥æ™ºèƒ½æ™ºèƒ½ä½“ (artificial agents) æä¾›äº†é‡è¦è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "41 pages, 19 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.20664v1",
      "published_date": "2025-06-25 17:55:27 UTC",
      "updated_date": "2025-06-25 17:55:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:23:26.084868+00:00"
    },
    {
      "arxiv_id": "2506.20649v1",
      "title": "Disentangled representations of microscopy images",
      "title_zh": "æ˜¾å¾®å›¾åƒçš„è§£è€¦è¡¨ç¤º",
      "authors": [
        "Jacopo Dapueto",
        "Vito Paolo Pastore",
        "Nicoletta Noceti",
        "Francesca Odone"
      ],
      "abstract": "Microscopy image analysis is fundamental for different applications, from diagnosis to synthetic engineering and environmental monitoring. Modern acquisition systems have granted the possibility to acquire an escalating amount of images, requiring a consequent development of a large collection of deep learning-based automatic image analysis methods. Although deep neural networks have demonstrated great performance in this field, interpretability, an essential requirement for microscopy image analysis, remains an open challenge.\n  This work proposes a Disentangled Representation Learning (DRL) methodology to enhance model interpretability for microscopy image classification. Exploiting benchmark datasets from three different microscopic image domains (plankton, yeast vacuoles, and human cells), we show how a DRL framework, based on transferring a representation learnt from synthetic data, can provide a good trade-off between accuracy and interpretability in this domain.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ˜¾å¾®å›¾åƒåˆ†æä¸­æ·±åº¦å­¦ä¹ æ¨¡å‹é¢ä¸´çš„å¯è§£é‡Šæ€§(interpretability)æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§è§£è€¦è¡¨ç¤ºå­¦ä¹ (Disentangled Representation Learning, DRL)æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ—¨åœ¨å¢å¼ºæ˜¾å¾®å›¾åƒåˆ†ç±»æ¨¡å‹çš„é€æ˜åº¦ï¼Œé€šè¿‡è¿ç§»ä»åˆæˆæ•°æ®(synthetic data)ä¸­å­¦ä¹ åˆ°çš„è¡¨ç¤ºæ¥æ„å»ºæ¨¡å‹æ¡†æ¶ã€‚ç ”ç©¶äººå‘˜åœ¨æµ®æ¸¸ç”Ÿç‰©(plankton)ã€é…µæ¯æ¶²æ³¡(yeast vacuoles)å’Œäººç±»ç»†èƒ(human cells)ä¸‰ä¸ªä¸åŒé¢†åŸŸçš„åŸºå‡†æ•°æ®é›†ä¸Šå¯¹è¯¥æ–¹æ³•è¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¿™ç§åŸºäºDRLçš„æ¶æ„èƒ½å¤Ÿåœ¨åˆ†ç±»å‡†ç¡®ç‡ä¸å¯è§£é‡Šæ€§ä¹‹é—´å®ç°ç†æƒ³çš„æƒè¡¡ã€‚è¿™ä¸€æˆæœä¸ºåŒ»ç–—è¯Šæ–­ã€åˆæˆå·¥ç¨‹åŠç¯å¢ƒç›‘æµ‹ç­‰éœ€è¦é«˜å¯é æ€§çš„æ˜¾å¾®å›¾åƒè‡ªåŠ¨åŒ–åˆ†æä»»åŠ¡æä¾›äº†æ›´å…·è§£é‡Šæ€§çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in: International Joint Conference on Neural Networks (IJCNN 2025). Project page: https://github.com/JacopoDapueto/disentangled_microscopy",
      "pdf_url": "https://arxiv.org/pdf/2506.20649v1",
      "published_date": "2025-06-25 17:44:37 UTC",
      "updated_date": "2025-06-25 17:44:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:23:23.795761+00:00"
    },
    {
      "arxiv_id": "2506.20640v2",
      "title": "CoMind: Towards Community-Driven Agents for Machine Learning Engineering",
      "title_zh": "CoMindï¼šè¿ˆå‘æœºå™¨å­¦ä¹ å·¥ç¨‹çš„ç¤¾åŒºé©±åŠ¨å‹æ™ºèƒ½ä½“",
      "authors": [
        "Sijie Li",
        "Weiwei Sun",
        "Shanda Li",
        "Ameet Talwalkar",
        "Yiming Yang"
      ],
      "abstract": "Large language model (LLM) agents show promise in automating machine learning (ML) engineering. However, existing agents typically operate in isolation on a given research problem, without engaging with the broader research community, where human researchers often gain insights and contribute by sharing knowledge. To bridge this gap, we introduce MLE-Live, a live evaluation framework designed to assess an agent's ability to communicate with and leverage collective knowledge from a simulated Kaggle research community. Building on this framework, we propose CoMind, an multi-agent system designed to actively integrate external knowledge. CoMind employs an iterative parallel exploration mechanism, developing multiple solutions simultaneously to balance exploratory breadth with implementation depth. On 75 past Kaggle competitions within our MLE-Live framework, CoMind achieves a 36% medal rate, establishing a new state of the art. Critically, when deployed in eight live, ongoing competitions, CoMind outperforms 92.6% of human competitors on average, placing in the top 5% on three official leaderboards and the top 1% on one.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CoMindï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è§£å†³ç°æœ‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ™ºèƒ½ä½“åœ¨æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰å·¥ç¨‹ä¸­å¾€å¾€å­¤ç«‹è¿è¡Œã€ç¼ºä¹ä¸å¤–éƒ¨ç ”ç©¶ç¤¾åŒºçŸ¥è¯†äº’åŠ¨é—®é¢˜çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚ç ”ç©¶å›¢é˜ŸåŒæ­¥å¼•å…¥äº†MLE-Liveå®æ—¶è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨æµ‹è¯•æ™ºèƒ½ä½“åœ¨æ¨¡æ‹ŸKaggleç¤¾åŒºä¸­è·å–å¹¶åˆ©ç”¨é›†ä½“çŸ¥è¯†çš„èƒ½åŠ›ã€‚CoMindæ ¸å¿ƒé‡‡ç”¨äº†è¿­ä»£å¹¶è¡Œæ¢ç´¢æœºåˆ¶(iterative parallel exploration mechanism)ï¼Œé€šè¿‡åŒæ—¶å¼€å‘å¤šä¸ªè§£å†³æ–¹æ¡ˆæ¥å¹³è¡¡æ¢ç´¢çš„å¹¿åº¦ä¸æ‰§è¡Œçš„æ·±åº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒCoMindåœ¨75åœºå†å²Kaggleç«èµ›ä¸­å®ç°äº†36%çš„è·å¥–ç‡ï¼Œæ ‘ç«‹äº†æ–°çš„State-of-the-Artã€‚åœ¨8åœºæ­£åœ¨è¿›è¡Œçš„å®æ—¶ç«èµ›ä¸­ï¼ŒCoMindå¹³å‡è¶…è¶Šäº†92.6%çš„äººç±»å‚èµ›è€…ï¼Œå¹¶åœ¨å¤šä¸ªå®˜æ–¹æ’è¡Œæ¦œä¸­è·»èº«å‰5%ç”šè‡³å‰1%ï¼Œæ˜¾è‘—è¯æ˜äº†ç¤¾åŒºé©±åŠ¨æ¨¡å¼åœ¨è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ å·¥ç¨‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20640v2",
      "published_date": "2025-06-25 17:36:02 UTC",
      "updated_date": "2025-11-26 05:16:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:23:50.852847+00:00"
    },
    {
      "arxiv_id": "2506.20621v1",
      "title": "Define-ML: An Approach to Ideate Machine Learning-Enabled Systems",
      "title_zh": "Define-MLï¼šä¸€ç§æœºå™¨å­¦ä¹ èµ‹èƒ½ç³»ç»Ÿçš„æ„æ€æ–¹æ³•",
      "authors": [
        "Silvio Alonso",
        "Antonio Pedro Santos Alves",
        "Lucas Romao",
        "HÃ©lio Lopes",
        "Marcos Kalinowski"
      ],
      "abstract": "[Context] The increasing adoption of machine learning (ML) in software systems demands specialized ideation approaches that address ML-specific challenges, including data dependencies, technical feasibility, and alignment between business objectives and probabilistic system behavior. Traditional ideation methods like Lean Inception lack structured support for these ML considerations, which can result in misaligned product visions and unrealistic expectations. [Goal] This paper presents Define-ML, a framework that extends Lean Inception with tailored activities - Data Source Mapping, Feature-to-Data Source Mapping, and ML Mapping - to systematically integrate data and technical constraints into early-stage ML product ideation. [Method] We developed and validated Define-ML following the Technology Transfer Model, conducting both static validation (with a toy problem) and dynamic validation (in a real-world industrial case study). The analysis combined quantitative surveys with qualitative feedback, assessing utility, ease of use, and intent of adoption. [Results] Participants found Define-ML effective for clarifying data concerns, aligning ML capabilities with business goals, and fostering cross-functional collaboration. The approach's structured activities reduced ideation ambiguity, though some noted a learning curve for ML-specific components, which can be mitigated by expert facilitation. All participants expressed the intention to adopt Define-ML. [Conclusion] Define-ML provides an openly available, validated approach for ML product ideation, building on Lean Inception's agility while aligning features with available data and increasing awareness of technical feasibility.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Define-MLï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨æ”¯æŒæœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ç³»ç»Ÿæ„æ€çš„æ¡†æ¶ï¼Œé€šè¿‡æ‰©å±• Lean Inception æ–¹æ³•æ¥è§£å†³æ•°æ®ä¾èµ–ã€æŠ€æœ¯å¯è¡Œæ€§ä»¥åŠä¸šåŠ¡ç›®æ ‡ä¸æ¦‚ç‡ç³»ç»Ÿè¡Œä¸ºä¹‹é—´çš„ä¸€è‡´æ€§é—®é¢˜ã€‚Define-ML å¼•å…¥äº† Data Source Mappingã€Feature-to-Data Source Mapping å’Œ ML Mapping ç­‰å®šåˆ¶åŒ–æ´»åŠ¨ï¼Œæ—¨åœ¨å°†æ•°æ®å’ŒæŠ€æœ¯çº¦æŸç³»ç»Ÿåœ°æ•´åˆåˆ° ML äº§å“çš„æ—©æœŸæ„æ€ä¸­ã€‚ç ”ç©¶äººå‘˜éµå¾ª Technology Transfer Model å¯¹è¯¥æ¡†æ¶è¿›è¡Œäº†å¼€å‘å’ŒéªŒè¯ï¼ŒåŒ…æ‹¬é’ˆå¯¹ç®€å•é—®é¢˜çš„é™æ€éªŒè¯ä»¥åŠåœ¨çœŸå®å·¥ä¸šæ¡ˆä¾‹ç ”ç©¶ä¸­çš„åŠ¨æ€éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDefine-ML åœ¨æ˜ç¡®æ•°æ®å…³æ³¨ç‚¹ã€ä½¿ ML èƒ½åŠ›ä¸ä¸šåŠ¡ç›®æ ‡ä¿æŒä¸€è‡´ä»¥åŠä¿ƒè¿›è·¨èŒèƒ½åä½œæ–¹é¢éå¸¸æœ‰æ•ˆã€‚ç»“æ„åŒ–çš„æ´»åŠ¨æ˜¾è‘—å‡å°‘äº†æ„æ€è¿‡ç¨‹ä¸­çš„æ­§ä¹‰ï¼Œå°½ç®¡ ML ç‰¹å®šç»„ä»¶å­˜åœ¨ä¸€å®šçš„å­¦ä¹ æ›²çº¿ï¼Œä½†å‚ä¸è€…å‡è¡¨è¾¾äº†é‡‡ç”¨è¯¥æ–¹æ³•çš„å¼ºçƒˆæ„å‘ã€‚Define-ML ä¸º ML äº§å“æ„æ€æä¾›äº†ä¸€ç§ç»è¿‡éªŒè¯çš„å¼€æ”¾æ–¹æ³•ï¼Œåœ¨ä¿æŒ Lean Inception æ•æ·æ€§çš„åŒæ—¶ï¼Œå¢å¼ºäº†å›¢é˜Ÿå¯¹æŠ€æœ¯å¯è¡Œæ€§çš„è®¤è¯†å¹¶ç¡®ä¿äº†åŠŸèƒ½è®¾è®¡ä¸å¯ç”¨æ•°æ®çš„ä¸€è‡´æ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication at the 51st Euromicro Conference Series on Software Engineering and Advanced Applications (SEAA) 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.20621v1",
      "published_date": "2025-06-25 17:11:26 UTC",
      "updated_date": "2025-06-25 17:11:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:25:33.673776+00:00"
    },
    {
      "arxiv_id": "2506.20614v1",
      "title": "Weighted Mean Frequencies: a handcraft Fourier feature for 4D Flow MRI segmentation",
      "title_zh": "åŠ æƒå¹³å‡é¢‘ç‡ï¼šä¸€ç§ç”¨äº 4D Flow MRI åˆ†å‰²çš„æ‰‹å·¥å‚…é‡Œå¶ç‰¹å¾",
      "authors": [
        "Simon Perrin",
        "SÃ©bastien Levilly",
        "Huajun Sun",
        "Harold MouchÃ¨re",
        "Jean-Michel Serfaty"
      ],
      "abstract": "In recent decades, the use of 4D Flow MRI images has enabled the quantification of velocity fields within a volume of interest and along the cardiac cycle. However, the lack of resolution and the presence of noise in these biomarkers are significant issues. As indicated by recent studies, it appears that biomarkers such as wall shear stress are particularly impacted by the poor resolution of vessel segmentation. The Phase Contrast Magnetic Resonance Angiography (PC-MRA) is the state-of-the-art method to facilitate segmentation. The objective of this work is to introduce a new handcraft feature that provides a novel visualisation of 4D Flow MRI images, which is useful in the segmentation task. This feature, termed Weighted Mean Frequencies (WMF), is capable of revealing the region in three dimensions where a voxel has been passed by pulsatile flow. Indeed, this feature is representative of the hull of all pulsatile velocity voxels. The value of the feature under discussion is illustrated by two experiments. The experiments involved segmenting 4D Flow MRI images using optimal thresholding and deep learning methods. The results obtained demonstrate a substantial enhancement in terms of IoU and Dice, with a respective increase of 0.12 and 0.13 in comparison with the PC-MRA feature, as evidenced by the deep learning task. This feature has the potential to yield valuable insights that could inform future segmentation processes in other vascular regions, such as the heart or the brain.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ 4D Flow MRI å›¾åƒåˆ†è¾¨ç‡ä¸è¶³å’Œå™ªå£°å¯¹ Wall Shear Stress ç­‰ç”Ÿç‰©æ ‡å¿—ç‰©åˆ†å‰²ç²¾åº¦äº§ç”Ÿçš„å½±å“ï¼Œæå‡ºäº†ä¸€ç§åä¸º Weighted Mean Frequencies (WMF) çš„æ–°å‹æ‰‹å·¥å‚…é‡Œå¶ç‰¹å¾ã€‚WMF ç‰¹å¾é€šè¿‡è¯†åˆ«ä¸‰ç»´ç©ºé—´ä¸­å­˜åœ¨è„‰åŠ¨æµ (Pulsatile Flow) çš„ä½“ç´ åŒºåŸŸï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¡¨å¾æ‰€æœ‰è„‰åŠ¨é€Ÿåº¦ä½“ç´ çš„åŒ…ç»œå¹¶è¾…åŠ©åˆ†å‰²ä»»åŠ¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æ·±åº¦å­¦ä¹ åˆ†å‰²ä»»åŠ¡ä¸­ï¼ŒWMF ç›¸æ¯”äºç›®å‰çš„ PC-MRA æ ‡å‡†åœ¨ IoU å’Œ Dice æŒ‡æ ‡ä¸Šåˆ†åˆ«æ˜¾è‘—æå‡äº† 0.12 å’Œ 0.13ã€‚è¯¥ç ”ç©¶ä¸º 4D Flow MRI æä¾›äº†ä¸€ç§å…¨æ–°çš„å¯è§†åŒ–ç»´åº¦ï¼Œå¹¶å±•ç°å‡ºåœ¨å¿ƒè„å’Œå¤§è„‘ç­‰å…¶ä»–å¤æ‚è¡€ç®¡åŒºåŸŸåˆ†å‰²ä»»åŠ¡ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20614v1",
      "published_date": "2025-06-25 17:04:00 UTC",
      "updated_date": "2025-06-25 17:04:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:25:42.906504+00:00"
    },
    {
      "arxiv_id": "2506.20609v1",
      "title": "Deciphering GunType Hierarchy through Acoustic Analysis of Gunshot Recordings",
      "title_zh": "åŸºäºæªå£°å½•éŸ³å£°å­¦åˆ†æçš„æªæ¢°ç±»å‹å±‚çº§è§£æ",
      "authors": [
        "Ankit Shah",
        "Rita Singh",
        "Bhiksha Raj",
        "Alexander Hauptmann"
      ],
      "abstract": "The escalating rates of gun-related violence and mass shootings represent a significant threat to public safety. Timely and accurate information for law enforcement agencies is crucial in mitigating these incidents. Current commercial gunshot detection systems, while effective, often come with prohibitive costs. This research explores a cost-effective alternative by leveraging acoustic analysis of gunshot recordings, potentially obtainable from ubiquitous devices like cell phones, to not only detect gunshots but also classify the type of firearm used. This paper details a study on deciphering gun type hierarchies using a curated dataset of 3459 recordings. We investigate the fundamental acoustic characteristics of gunshots, including muzzle blasts and shockwaves, which vary based on firearm type, ammunition, and shooting direction. We propose and evaluate machine learning frameworks, including Support Vector Machines (SVMs) as a baseline and a more advanced Convolutional Neural Network (CNN) architecture for joint gunshot detection and gun type classification. Results indicate that our deep learning approach achieves a mean average precision (mAP) of 0.58 on clean labeled data, outperforming the SVM baseline (mAP 0.39). Challenges related to data quality, environmental noise, and the generalization capabilities when using noisy web-sourced data (mAP 0.35) are also discussed. The long-term vision is to develop a highly accurate, real-time system deployable on common recording devices, significantly reducing detection costs and providing critical intelligence to first responders.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹æªæ”¯æš´åŠ›é¢‘å‘ä¸”å•†ä¸šæªå£°ç›‘æµ‹ç³»ç»Ÿæˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨æ‰‹æœºç­‰å¸¸è§è®¾å¤‡çš„å½•éŸ³è¿›è¡Œå£°å­¦åˆ†æçš„ä½æˆæœ¬æ›¿ä»£æ–¹æ¡ˆã€‚ç ”ç©¶äººå‘˜é€šè¿‡åˆ†æåŒ…å«3459æ¡å½•éŸ³çš„æ•°æ®é›†ï¼Œæ¢è®¨äº†å—æªæ”¯å‹å·ã€å¼¹è¯å’Œå°„å‡»æ–¹å‘å½±å“çš„æªå£çˆ†ç ´éŸ³(muzzle blasts)å’Œå†²å‡»æ³¢(shockwaves)ç­‰åŸºæœ¬å£°å­¦ç‰¹å¾ã€‚è¯¥ç ”ç©¶è¯„ä¼°äº†å¤šç§æœºå™¨å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…æ‹¬ä½œä¸ºåŸºå‡†çš„Support Vector Machines (SVMs)ä»¥åŠç”¨äºè”åˆæ£€æµ‹å’Œæªæ”¯ç±»å‹åˆ†ç±»çš„Convolutional Neural Network (CNN)æ¶æ„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨æ¸…æ´—åçš„æ ‡æ³¨æ•°æ®ä¸Šå®ç°äº†0.58çš„å¹³å‡ç²¾åº¦å‡å€¼(mAP)ï¼Œæ€§èƒ½æ˜æ˜¾ä¼˜äºSVMåŸºå‡†çš„0.39ã€‚è®ºæ–‡è¿˜åˆ†æäº†ç¯å¢ƒå™ªå£°å’Œåˆ©ç”¨ç½‘ç»œæ¥æºæ•°æ®è¿›è¡Œè®­ç»ƒæ—¶çš„æ³›åŒ–æŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶æ—¨åœ¨å¼€å‘ä¸€ç§å¯éƒ¨ç½²äºæ™®é€šç”µå­è®¾å¤‡çš„å®æ—¶é«˜ç²¾åº¦ç³»ç»Ÿï¼Œé€šè¿‡é™ä½ç›‘æµ‹æˆæœ¬ä¸ºæ‰§æ³•æœºæ„æä¾›å…³é”®çš„ç°åœºæƒ…æŠ¥ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "4 pages + 1 References",
      "pdf_url": "https://arxiv.org/pdf/2506.20609v1",
      "published_date": "2025-06-25 17:00:21 UTC",
      "updated_date": "2025-06-25 17:00:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:25:37.440264+00:00"
    },
    {
      "arxiv_id": "2506.20608v2",
      "title": "AI Assistants to Enhance and Exploit the PETSc Knowledge Base",
      "title_zh": "å¢å¼ºä¸åˆ©ç”¨ PETSc çŸ¥è¯†åº“çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹",
      "authors": [
        "Barry Smith",
        "Junchao Zhang",
        "Hong Zhang",
        "Lois Curfman McInnes",
        "Murat Keceli",
        "Archit Vasan",
        "Satish Balay",
        "Toby Isaac",
        "Le Chen",
        "Venkatram Vishwanath"
      ],
      "abstract": "Generative AI, especially through large language models (LLMs), is transforming how technical knowledge can be accessed, reused, and extended. PETSc, a widely used numerical library for high-performance scientific computing, has accumulated a rich but fragmented knowledge base over its three decades of development, spanning source code, documentation, mailing lists, GitLab issues, Discord conversations, technical papers, and more. Much of this knowledge remains informal and inaccessible to users and new developers. To activate and utilize this knowledge base more effectively, the PETSc team has begun building an LLM-powered system that combines PETSc content with custom LLM tools -- including retrieval-augmented generation (RAG), reranking algorithms, and chatbots -- to assist users, support developers, and propose updates to formal documentation. This paper presents initial experiences designing and evaluating these tools, focusing on system architecture, using RAG and reranking for PETSc-specific information, evaluation methodologies for various LLMs and embedding models, and user interface design. Leveraging the Argonne Leadership Computing Facility resources, we analyze how LLM responses can enhance the development and use of numerical software, with an initial focus on scalable Krylov solvers. Our goal is to establish an extensible framework for knowledge-centered AI in scientific software, enabling scalable support, enriched documentation, and enhanced workflows for research and development. We conclude by outlining directions for expanding this system into a robust, evolving platform that advances software ecosystems to accelerate scientific discovery.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜æ€§èƒ½ç§‘å­¦è®¡ç®—åº“ PETSc ç§¯ç´¯ä¸‰åä½™å¹´ä½†åˆ†å¸ƒç¢ç‰‡åŒ–çš„çŸ¥è¯†åº“ï¼Œå¼€å‘äº†ä¸€å¥—åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ™ºèƒ½åŠ©æ‰‹ç³»ç»Ÿï¼Œæ—¨åœ¨æå‡æŠ€æœ¯çŸ¥è¯†çš„è·å–ä¸åˆ©ç”¨æ•ˆç‡ã€‚è¯¥ç³»ç»Ÿç»“åˆäº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ã€é‡æ’åº(reranking)ç®—æ³•åŠèŠå¤©æœºå™¨äººå·¥å…·ï¼Œé€šè¿‡æ•´åˆæºç ã€æ–‡æ¡£ã€é‚®ä»¶åˆ—è¡¨åŠ GitLab è®®é¢˜ç­‰éæ­£å¼çŸ¥è¯†ï¼Œæ¿€æ´»äº† PETSc çš„æ ¸å¿ƒçŸ¥è¯†èµ„äº§ã€‚ç ”ç©¶é‡ç‚¹ä»‹ç»äº†ç³»ç»Ÿæ¶æ„è®¾è®¡ã€é’ˆå¯¹ PETSc ç‰¹å®šä¿¡æ¯çš„è¯„ä¼°æ–¹æ³•ï¼Œå¹¶åˆ©ç”¨ Argonne Leadership Computing Facility çš„èµ„æºå¯¹ä¸åŒ LLMs å’ŒåµŒå…¥æ¨¡å‹(embedding models)è¿›è¡Œäº†æ€§èƒ½æµ‹è¯•ã€‚åˆæœŸåº”ç”¨é‡ç‚¹èšç„¦äºå¯æ‰©å±•çš„ Krylov solversï¼Œåˆ†æäº† AI ç”Ÿæˆçš„å“åº”å¦‚ä½•å¢å¼ºæ•°å€¼è½¯ä»¶çš„å¼€å‘ä¸ä½¿ç”¨æµç¨‹ã€‚è¯¥å·¥ä½œçš„æœ€ç»ˆç›®æ ‡æ˜¯ä¸ºç§‘å­¦è½¯ä»¶å»ºç«‹ä¸€ä¸ªä»¥çŸ¥è¯†ä¸ºä¸­å¿ƒçš„ AI æ‰©å±•æ¡†æ¶ï¼Œé€šè¿‡æä¾›å¯æ‰©å±•çš„æ”¯æŒå’Œæ›´ä¸°å¯Œçš„æ–‡æ¡£ï¼ŒåŠ é€Ÿç§‘ç ”å‘ç°å¹¶ä¼˜åŒ–è½¯ä»¶ç”Ÿæ€ç³»ç»Ÿçš„ç ”å‘å·¥ä½œæµã€‚",
      "categories": [
        "cs.AI",
        "math.NA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20608v2",
      "published_date": "2025-06-25 17:00:05 UTC",
      "updated_date": "2025-09-22 14:54:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:25:37.573922+00:00"
    },
    {
      "arxiv_id": "2506.20600v1",
      "title": "CogGen: A Learner-Centered Generative AI Architecture for Intelligent Tutoring with Programming Video",
      "title_zh": "CogGenï¼šä¸€ç§é¢å‘ç¼–ç¨‹è§†é¢‘æ™ºèƒ½è¾…å¯¼çš„ä»¥å­¦ä¹ è€…ä¸ºä¸­å¿ƒçš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ¶æ„",
      "authors": [
        "Wengxi Li",
        "Roy Pea",
        "Nick Haber",
        "Hari Subramonyam"
      ],
      "abstract": "We introduce CogGen, a learner-centered AI architecture that transforms programming videos into interactive, adaptive learning experiences by integrating student modeling with generative AI tutoring based on the Cognitive Apprenticeship framework. The architecture consists of three components: (1) video segmentation by learning goals, (2) a conversational tutoring engine applying Cognitive Apprenticeship strategies, and (3) a student model using Bayesian Knowledge Tracing to adapt instruction. Our technical evaluation demonstrates effective video segmentation accuracy and strong pedagogical alignment across knowledge, method, action, and interaction layers. Ablation studies confirm the necessity of each component in generating effective guidance. This work advances AI-powered tutoring by bridging structured student modeling with interactive AI conversations, offering a scalable approach to enhancing video-based programming education.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CogGenï¼Œè¿™æ˜¯ä¸€ç§ä»¥å­¦ä¹ è€…ä¸ºä¸­å¿ƒçš„ç”Ÿæˆå¼AIæ¶æ„ï¼Œæ—¨åœ¨é€šè¿‡æ•´åˆå­¦ç”Ÿå»ºæ¨¡ä¸åŸºäºCognitive Apprenticeshipæ¡†æ¶çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½è¾…å¯¼ï¼Œå°†ç¼–ç¨‹è§†é¢‘è½¬åŒ–ä¸ºäº¤äº’å¼ä¸”å…·æœ‰è‡ªé€‚åº”æ€§çš„å­¦ä¹ ä½“éªŒã€‚è¯¥æ¶æ„ä¸»è¦ç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼šæŒ‰å­¦ä¹ ç›®æ ‡è¿›è¡Œçš„è§†é¢‘åˆ†å‰²(video segmentation)ã€åº”ç”¨Cognitive Apprenticeshipç­–ç•¥çš„å¯¹è¯è¾…å¯¼å¼•æ“ï¼Œä»¥åŠåˆ©ç”¨Bayesian Knowledge Tracingè¿›è¡Œæ•™å­¦é€‚é…çš„å­¦ç”Ÿæ¨¡å‹ã€‚æŠ€æœ¯è¯„ä¼°è¯æ˜äº†è¯¥ç³»ç»Ÿåœ¨è§†é¢‘åˆ†å‰²å‡†ç¡®åº¦ä»¥åŠåœ¨çŸ¥è¯†ã€æ–¹æ³•ã€è¡ŒåŠ¨å’Œäº¤äº’å±‚çº§çš„æ•™å­¦å¯¹é½æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚æ¶ˆèç ”ç©¶(ablation studies)è¿›ä¸€æ­¥è¯å®äº†å„æ ¸å¿ƒç»„ä»¶åœ¨ç”Ÿæˆæœ‰æ•ˆæ•™å­¦æŒ‡å¯¼ä¸­çš„å¿…è¦æ€§ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡å°†ç»“æ„åŒ–å­¦ç”Ÿå»ºæ¨¡ä¸äº¤äº’å¼AIå¯¹è¯ç›¸èåˆï¼Œä¸ºå¢å¼ºåŸºäºè§†é¢‘çš„ç¼–ç¨‹æ•™è‚²æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20600v1",
      "published_date": "2025-06-25 16:39:05 UTC",
      "updated_date": "2025-06-25 16:39:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:25:46.106558+00:00"
    },
    {
      "arxiv_id": "2506.20598v1",
      "title": "Fine-Tuning and Prompt Engineering of LLMs, for the Creation of Multi-Agent AI for Addressing Sustainable Protein Production Challenges",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹çš„å¾®è°ƒä¸æç¤ºå·¥ç¨‹ï¼šé¢å‘å¯æŒç»­è›‹ç™½è´¨ç”Ÿäº§æŒ‘æˆ˜çš„å¤šæ™ºèƒ½ä½“äººå·¥æ™ºèƒ½æ„å»º",
      "authors": [
        "Alexander D. Kalian",
        "Jaewook Lee",
        "Stefan P. Johannesson",
        "Lennart Otte",
        "Christer Hogstrand",
        "Miao Guo"
      ],
      "abstract": "The global demand for sustainable protein sources has accelerated the need for intelligent tools that can rapidly process and synthesise domain-specific scientific knowledge. In this study, we present a proof-of-concept multi-agent Artificial Intelligence (AI) framework designed to support sustainable protein production research, with an initial focus on microbial protein sources. Our Retrieval-Augmented Generation (RAG)-oriented system consists of two GPT-based LLM agents: (1) a literature search agent that retrieves relevant scientific literature on microbial protein production for a specified microbial strain, and (2) an information extraction agent that processes the retrieved content to extract relevant biological and chemical information. Two parallel methodologies, fine-tuning and prompt engineering, were explored for agent optimisation. Both methods demonstrated effectiveness at improving the performance of the information extraction agent in terms of transformer-based cosine similarity scores between obtained and ideal outputs. Mean cosine similarity scores were increased by up to 25%, while universally reaching mean scores of $\\geq 0.89$ against ideal output text. Fine-tuning overall improved the mean scores to a greater extent (consistently of $\\geq 0.94$) compared to prompt engineering, although lower statistical uncertainties were observed with the latter approach. A user interface was developed and published for enabling the use of the multi-agent AI system, alongside preliminary exploration of additional chemical safety-based search capabilities",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé¢å‘å¯æŒç»­è›‹ç™½è´¨ç”Ÿäº§çš„å¤šæ™ºèƒ½ä½“äººå·¥æ™ºèƒ½æ¡†æ¶ï¼Œåˆå§‹é‡ç‚¹åœ¨äºå¾®ç”Ÿç‰©è›‹ç™½è´¨æ¥æºã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æ¶æ„ï¼Œç”±æ–‡çŒ®æœç´¢æ™ºèƒ½ä½“(literature search agent)å’Œä¿¡æ¯æå–æ™ºèƒ½ä½“(information extraction agent)ç»„æˆï¼Œåˆ†åˆ«è´Ÿè´£æ£€ç´¢ç‰¹å®šèŒæ ªçš„ç§‘ç ”æ–‡çŒ®ä»¥åŠæå–ç›¸å…³çš„ç”Ÿç‰©å’ŒåŒ–å­¦ä¿¡æ¯ã€‚ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¾®è°ƒ(Fine-tuning)ä¸æç¤ºå·¥ç¨‹(Prompt engineering)ä¸¤ç§æ–¹æ³•å¯¹æ™ºèƒ½ä½“æ€§èƒ½çš„ä¼˜åŒ–æ•ˆæœï¼Œå®éªŒè¯æ˜ä¸¤è€…å‡èƒ½æœ‰æ•ˆæå‡æå–å‡†ç¡®æ€§ï¼Œå¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦å¾—åˆ†æœ€é«˜æå‡äº†25%ã€‚è™½ç„¶å¾®è°ƒåœ¨æå‡å¹³å‡å¾—åˆ†(â‰¥ 0.94)æ–¹é¢æ•´ä½“ä¼˜äºæç¤ºå·¥ç¨‹ï¼Œä½†åè€…å±•ç°å‡ºæ›´ä½çš„ç»Ÿè®¡ä¸ç¡®å®šæ€§ã€‚è¯¥å›¢é˜Ÿè¿˜å¼€å‘å¹¶å‘å¸ƒäº†ç›¸åº”çš„ç”¨æˆ·ç•Œé¢ï¼Œå¹¶åˆæ­¥æ¢ç´¢äº†åŸºäºåŒ–å­¦å®‰å…¨çš„æœç´¢èƒ½åŠ›ï¼Œä¸ºåŠ é€Ÿå¯æŒç»­è›‹ç™½è´¨ç”Ÿäº§é¢†åŸŸçš„ç§‘ç ”çŸ¥è¯†åˆæˆæä¾›äº†æ¦‚å¿µéªŒè¯ã€‚",
      "categories": [
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20598v1",
      "published_date": "2025-06-25 16:37:46 UTC",
      "updated_date": "2025-06-25 16:37:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:26:08.161878+00:00"
    },
    {
      "arxiv_id": "2506.20595v1",
      "title": "AI in the Writing Process: How Purposeful AI Support Fosters Student Writing",
      "title_zh": "å†™ä½œè¿‡ç¨‹ä¸­çš„äººå·¥æ™ºèƒ½ï¼šé’ˆå¯¹æ€§ AI æ”¯æŒå¦‚ä½•èµ‹èƒ½å­¦ç”Ÿå†™ä½œ",
      "authors": [
        "Momin N. Siddiqui",
        "Roy Pea",
        "Hari Subramonyam"
      ],
      "abstract": "The ubiquity of technologies like ChatGPT has raised concerns about their impact on student writing, particularly regarding reduced learner agency and superficial engagement with content. While standalone chat-based LLMs often produce suboptimal writing outcomes, evidence suggests that purposefully designed AI writing support tools can enhance the writing process. This paper investigates how different AI support approaches affect writers' sense of agency and depth of knowledge transformation. Through a randomized control trial with 90 undergraduate students, we compare three conditions: (1) a chat-based LLM writing assistant, (2) an integrated AI writing tool to support diverse subprocesses, and (3) a standard writing interface (control). Our findings demonstrate that, among AI-supported conditions, students using the integrated AI writing tool exhibited greater agency over their writing process and engaged in deeper knowledge transformation overall. These results suggest that thoughtfully designed AI writing support targeting specific aspects of the writing process can help students maintain ownership of their work while facilitating improved engagement with content.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœ‰ç›®çš„çš„ AI æ”¯æŒå¦‚ä½•ä¿ƒè¿›å­¦ç”Ÿå†™ä½œï¼Œæ—¨åœ¨è§£å†³ä»¥ ChatGPT ä¸ºä»£è¡¨çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¯èƒ½å¯¼è‡´çš„å­¦ä¹ è€…ä¸»ä½“æ€§ (Learner Agency) å‰Šå¼±å’Œå†…å®¹å‚ä¸åº¦æµ…å±‚åŒ–é—®é¢˜ã€‚ç ”ç©¶äººå‘˜é€šè¿‡ä¸€é¡¹æ¶‰åŠ 90 åæœ¬ç§‘ç”Ÿçš„éšæœºå¯¹ç…§è¯•éªŒ (Randomized Control Trial)ï¼Œå¯¹æ¯”äº†èŠå¤©å¼å¤§è¯­è¨€æ¨¡å‹ (Chat-based LLM) åŠ©æ‰‹ã€æ”¯æŒç‰¹å®šå­è¿‡ç¨‹ (Subprocesses) çš„é›†æˆå¼ AI å†™ä½œå·¥å…·ä»¥åŠæ ‡å‡†å†™ä½œç•Œé¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ AI æ”¯æŒçš„æ¡ä»¶ä¸‹ï¼Œä½¿ç”¨é›†æˆå¼å·¥å…·çš„å­¦ç”Ÿåœ¨å†™ä½œè¿‡ç¨‹ä¸­å±•ç°å‡ºæ›´å¼ºçš„ä¸»ä½“æ€§ï¼Œå¹¶å®ç°äº†æ›´æ·±å±‚æ¬¡çš„çŸ¥è¯†è½¬åŒ– (Knowledge Transformation)ã€‚ç ”ç©¶è¯æ˜ï¼Œé’ˆå¯¹æ€§è®¾è®¡çš„ AI æ”¯æŒå·¥å…·èƒ½æœ‰æ•ˆå¸®åŠ©å­¦ç”Ÿåœ¨ç»´æŒä½œå“æ‰€æœ‰æƒ (Ownership) çš„åŒæ—¶ï¼Œæå‡å¯¹å†…å®¹çš„ç†è§£ä¸äº’åŠ¨ã€‚è¿™ä¸€å‘ç°ä¸ºæœªæ¥æ•™è‚²é¢†åŸŸå¼€å‘èƒ½å¤Ÿå¢å¼ºè€Œéå–ä»£äººç±»èƒ½åŠ›çš„ AI å†™ä½œç³»ç»Ÿæä¾›äº†é‡è¦çš„è®¾è®¡è·¯å¾„å’Œå®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20595v1",
      "published_date": "2025-06-25 16:34:09 UTC",
      "updated_date": "2025-06-25 16:34:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:26:14.624641+00:00"
    },
    {
      "arxiv_id": "2507.21090v1",
      "title": "Thinking Like a Scientist: Can Interactive Simulations Foster Critical AI Literacy?",
      "title_zh": "åƒç§‘å­¦å®¶ä¸€æ ·æ€è€ƒï¼šäº¤äº’å¼æ¨¡æ‹Ÿèƒ½å¦åŸ¹å…»æ‰¹åˆ¤æ€§äººå·¥æ™ºèƒ½ç´ å…»ï¼Ÿ",
      "authors": [
        "Yiling Zhao",
        "Audrey Michal",
        "Nithum Thain",
        "Hari Subramonyam"
      ],
      "abstract": "As AI systems shape individual and societal decisions, fostering critical AI literacy is essential. Traditional approaches, such as blog articles, static lessons, and social media discussions, often fail to support deep conceptual understanding and critical engagement. This study examines whether interactive simulations can help learners think like a scientist by engaging them in hypothesis testing, experimentation, and direct observation of AI behavior. In a controlled study with 605 participants, we assess how interactive AI tutorials impact learning of key concepts such as fairness, dataset representativeness, and bias in language models. Results show that interactive simulations effectively enhance AI literacy across topics, supporting greater knowledge transfer and self-reported confidence, though engagement alone does not predict learning. This work contributes to the growing field of AI literacy education, highlighting how interactive, inquiry-driven methodologies can better equip individuals to critically engage with AI in their daily lives.",
      "tldr_zh": "éšç€äººå·¥æ™ºèƒ½ç³»ç»Ÿå¯¹ç¤¾ä¼šå†³ç­–å½±å“çš„æ—¥ç›ŠåŠ æ·±ï¼ŒåŸ¹å…»æ‰¹åˆ¤æ€§ AI ç´ å…» (Critical AI Literacy) å˜å¾—è‡³å…³é‡è¦ï¼Œä½†ä¼ ç»Ÿçš„é™æ€æ•™å­¦æ–¹æ³•å¾€å¾€éš¾ä»¥æ”¯æŒæ·±å±‚çš„æ¦‚å¿µç†è§£ã€‚è¯¥ç ”ç©¶æ¢è®¨äº†äº¤äº’å¼æ¨¡æ‹Ÿ (Interactive Simulations) æ˜¯å¦èƒ½é€šè¿‡å¼•å¯¼å­¦ä¹ è€…è¿›è¡Œå‡è®¾æ£€éªŒ (Hypothesis Testing)ã€å®éªŒå’Œç›´æ¥è§‚å¯Ÿ AI è¡Œä¸ºï¼Œå¸®åŠ©å…¶å»ºç«‹ç§‘å­¦æ€ç»´æ¨¡å¼ã€‚é€šè¿‡å¯¹ 605 åå‚ä¸è€…çš„å¯¹ç…§ç ”ç©¶ï¼Œè¯¥å·¥ä½œè¯„ä¼°äº†äº¤äº’å¼æ•™ç¨‹å¯¹å…¬å¹³æ€§ (Fairness)ã€æ•°æ®é›†ä»£è¡¨æ€§ (Dataset Representativeness) ä»¥åŠè¯­è¨€æ¨¡å‹åè§ (Bias) ç­‰æ ¸å¿ƒæ¦‚å¿µçš„å­¦ä¹ å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œäº¤äº’å¼æ¨¡æ‹Ÿèƒ½æœ‰æ•ˆæå‡ä¸åŒä¸»é¢˜ä¸‹çš„ AI ç´ å…»ï¼Œæ”¯æŒæ›´é«˜æ°´å¹³çš„çŸ¥è¯†è¿ç§»å¹¶å¢å¼ºå­¦ä¹ è€…çš„è‡ªä¿¡å¿ƒã€‚å°½ç®¡ç ”ç©¶å‘ç°å‚ä¸åº¦æœ¬èº«å¹¶ä¸èƒ½ç›´æ¥é¢„æµ‹å­¦ä¹ æ•ˆæœï¼Œä½†äº¤äº’å¼æ¨¡æ‹Ÿåœ¨ä¿ƒè¿›æ·±å±‚è®¤çŸ¥æ–¹é¢è¡¨ç°æ˜¾è‘—ã€‚è¿™é¡¹ç ”ç©¶ä¸º AI ç´ å…»æ•™è‚²é¢†åŸŸæä¾›äº†é‡è¦è§è§£ï¼Œå¼ºè°ƒäº†ä»¥æ¢ç©¶ä¸ºå¯¼å‘çš„äº’åŠ¨æ–¹æ³•åœ¨å¸®åŠ©ä¸ªä½“æ‰¹åˆ¤æ€§å‚ä¸ AI äº‹åŠ¡æ–¹é¢çš„æ ¸å¿ƒä»·å€¼ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.21090v1",
      "published_date": "2025-06-25 16:28:08 UTC",
      "updated_date": "2025-06-25 16:28:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:26:14.485456+00:00"
    },
    {
      "arxiv_id": "2506.20583v1",
      "title": "Dense Video Captioning using Graph-based Sentence Summarization",
      "title_zh": "åŸºäºå›¾å¥å­æ‘˜è¦çš„å¯†é›†è§†é¢‘æè¿°",
      "authors": [
        "Zhiwang Zhang",
        "Dong Xu",
        "Wanli Ouyang",
        "Luping Zhou"
      ],
      "abstract": "Recently, dense video captioning has made attractive progress in detecting and captioning all events in a long untrimmed video. Despite promising results were achieved, most existing methods do not sufficiently explore the scene evolution within an event temporal proposal for captioning, and therefore perform less satisfactorily when the scenes and objects change over a relatively long proposal. To address this problem, we propose a graph-based partition-and-summarization (GPaS) framework for dense video captioning within two stages. For the ``partition\" stage, a whole event proposal is split into short video segments for captioning at a finer level. For the ``summarization\" stage, the generated sentences carrying rich description information for each segment are summarized into one sentence to describe the whole event. We particularly focus on the ``summarization\" stage, and propose a framework that effectively exploits the relationship between semantic words for summarization. We achieve this goal by treating semantic words as nodes in a graph and learning their interactions by coupling Graph Convolutional Network (GCN) and Long Short Term Memory (LSTM), with the aid of visual cues. Two schemes of GCN-LSTM Interaction (GLI) modules are proposed for seamless integration of GCN and LSTM. The effectiveness of our approach is demonstrated via an extensive comparison with the state-of-the-arts methods on the two benchmarks ActivityNet Captions dataset and YouCook II dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Dense Video Captioning ä»»åŠ¡ä¸­ç°æœ‰æ–¹æ³•éš¾ä»¥åº”å¯¹é•¿äº‹ä»¶ææ¡ˆä¸­åœºæ™¯æ¼”å˜çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäºå›¾çš„ä¸¤é˜¶æ®µåˆ’åˆ†ä¸æ‘˜è¦æ¡†æ¶ Graph-based Partition-and-Summarization (GPaS)ã€‚åœ¨åˆ’åˆ†é˜¶æ®µï¼Œé•¿è§†é¢‘äº‹ä»¶è¢«ç»†åˆ†ä¸ºçŸ­ç‰‡æ®µè¿›è¡Œåˆæ­¥æè¿°ï¼›åœ¨æ‘˜è¦é˜¶æ®µï¼Œç ”ç©¶è€…é‡ç‚¹é€šè¿‡æ„å»ºè¯­ä¹‰è¯å›¾ï¼Œå¹¶ç»“åˆ Graph Convolutional Network (GCN) ä¸ Long Short Term Memory (LSTM) æ¥æ•æ‰è¯é¡¹é—´çš„å¤æ‚äº¤äº’ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡è®¾è®¡äº†ä¸¤ç§ GCN-LSTM Interaction (GLI) æ¨¡å—æ–¹æ¡ˆï¼Œå¹¶åˆ©ç”¨è§†è§‰çº¿ç´¢è¾…åŠ©ç”Ÿæˆæœ€ç»ˆçš„æ±‡æ€»æè¿°ã€‚å®éªŒåœ¨ ActivityNet Captions å’Œ YouCook II æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œç»“æœè¯æ˜ GPaS åœ¨å¤„ç†åœºæ™¯å’Œç‰©ä½“å˜åŒ–æ˜æ˜¾çš„é•¿è§†é¢‘æè¿°æ–¹é¢ä¼˜äºç°æœ‰ SOTA æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆæ‘˜è¦çš„å‡†ç¡®æ€§ä¸è¿è´¯æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2506.20583v1",
      "published_date": "2025-06-25 16:23:43 UTC",
      "updated_date": "2025-06-25 16:23:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:25:56.319894+00:00"
    },
    {
      "arxiv_id": "2506.20582v2",
      "title": "Causal Representation Learning with Observational Grouping for CXR Classification",
      "title_zh": "åŸºäºè§‚æµ‹åˆ†ç»„çš„èƒ¸éƒ¨ X å…‰ï¼ˆCXRï¼‰åˆ†ç±»å› æœè¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Rajat Rasal",
        "Avinash Kori",
        "Ben Glocker"
      ],
      "abstract": "Identifiable causal representation learning seeks to uncover the true causal relationships underlying a data generation process. In medical imaging, this presents opportunities to improve the generalisability and robustness of task-specific latent features. This work introduces the concept of grouping observations to learn identifiable representations for disease classification in chest X-rays via an end-to-end framework. Our experiments demonstrate that these causal representations improve generalisability and robustness across multiple classification tasks when grouping is used to enforce invariance w.r.t race, sex, and imaging views.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¯è¾¨è¯†çš„å› æœè¡¨ç¤ºå­¦ä¹ (Identifiable causal representation learning)ï¼Œæ—¨åœ¨æ­ç¤ºåŒ»ç–—å½±åƒæ•°æ®ç”Ÿæˆè¿‡ç¨‹ä¸­çš„çœŸå®å› æœå…³ç³»ï¼Œä»¥æå‡ç‰¹å®šä»»åŠ¡æ½œç‰¹å¾çš„æ³›åŒ–èƒ½åŠ›ã€‚ä½œè€…å¼•å…¥äº†è§‚æµ‹åˆ†ç»„(grouping observations)çš„æ¦‚å¿µï¼Œæå‡ºä¸€ç§ç”¨äºèƒ¸éƒ¨Xå°„çº¿(CXR)ç–¾ç—…åˆ†ç±»çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œä»¥å­¦ä¹ æ›´å…·ç¨³å¥æ€§çš„è¡¨ç¤ºã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ†ç»„æœºåˆ¶å¼ºåˆ¶æ¨¡å‹å¯¹ç§æ—(race)ã€æ€§åˆ«(sex)å’Œæˆåƒè§†è§’(imaging views)ä¿æŒä¸å˜æ€§(invariance)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§å› æœè¡¨ç¤ºå­¦ä¹ åœ¨å¤šé¡¹åˆ†ç±»ä»»åŠ¡ä¸­æ˜¾è‘—æ”¹å–„äº†æ¨¡å‹çš„æ³›åŒ–æ€§ä¸é²æ£’æ€§ï¼Œä¸ºæ„å»ºå¯é çš„åŒ»ç–—è¯Šæ–­ç³»ç»Ÿæä¾›äº†é‡è¦é€”å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Proceedings of the 3rd FAIMI Workshop at the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2025, Daejeon, South Korea",
      "pdf_url": "https://arxiv.org/pdf/2506.20582v2",
      "published_date": "2025-06-25 16:17:36 UTC",
      "updated_date": "2025-11-19 12:25:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:25:58.211615+00:00"
    },
    {
      "arxiv_id": "2506.20576v1",
      "title": "Vulnerability Disclosure through Adaptive Black-Box Adversarial Attacks on NIDS",
      "title_zh": "é€šè¿‡é’ˆå¯¹ NIDS çš„è‡ªé€‚åº”é»‘ç›’å¯¹æŠ—æ”»å‡»è¿›è¡Œæ¼æ´æŠ«éœ²",
      "authors": [
        "Sabrine Ennaji",
        "Elhadj Benkhelifa",
        "Luigi V. Mancini"
      ],
      "abstract": "Adversarial attacks, wherein slight inputs are carefully crafted to mislead intelligent models, have attracted increasing attention. However, a critical gap persists between theoretical advancements and practical application, particularly in structured data like network traffic, where interdependent features complicate effective adversarial manipulations. Moreover, ambiguity in current approaches restricts reproducibility and limits progress in this field. Hence, existing defenses often fail to handle evolving adversarial attacks. This paper proposes a novel approach for black-box adversarial attacks, that addresses these limitations. Unlike prior work, which often assumes system access or relies on repeated probing, our method strictly respect black-box constraints, reducing interaction to avoid detection and better reflect real-world scenarios. We present an adaptive feature selection strategy using change-point detection and causality analysis to identify and target sensitive features to perturbations. This lightweight design ensures low computational cost and high deployability. Our comprehensive experiments show the attack's effectiveness in evading detection with minimal interaction, enhancing its adaptability and applicability in real-world scenarios. By advancing the understanding of adversarial attacks in network traffic, this work lays a foundation for developing robust defenses.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹ç½‘ç»œå…¥ä¾µæ£€æµ‹ç³»ç»Ÿ (NIDS) çš„æ–°å‹é»‘ç›’å¯¹æŠ—æ”»å‡» (black-box adversarial attacks) æ–¹æ³•ï¼Œæ—¨åœ¨ç¼©å°ç†è®ºç ”ç©¶ä¸å®é™…ç½‘ç»œæµé‡åº”ç”¨ä¹‹é—´çš„å·®è·ã€‚è¯¥æ–¹æ³•ä¸¥æ ¼éµå®ˆé»‘ç›’çº¦æŸï¼Œé€šè¿‡å‡å°‘äº¤äº’é¢‘ç‡æ¥è§„é¿æ£€æµ‹ï¼Œä»è€Œæ›´çœŸå®åœ°æ¨¡æ‹Ÿç°å®ä¸–ç•Œçš„æ”»å‡»åœºæ™¯ã€‚ç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†åŸºäºå˜ç‚¹æ£€æµ‹ (change-point detection) å’Œå› æœåˆ†æ (causality analysis) çš„è‡ªé€‚åº”ç‰¹å¾é€‰æ‹©ç­–ç•¥ï¼Œç”¨ä»¥ç²¾ç¡®è¯†åˆ«å¹¶å¹²æ‰°æ•æ„Ÿç‰¹å¾ã€‚è¿™ç§è½»é‡åŒ–è®¾è®¡ (lightweight design) ä¿è¯äº†è¾ƒä½çš„è®¡ç®—å¼€é”€å’Œæé«˜çš„éƒ¨ç½²èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ”»å‡»æ‰‹æ®µä»…éœ€æå°‘äº¤äº’å³å¯æœ‰æ•ˆé€ƒé¿æ£€æµ‹ï¼Œå±•ç°å‡ºæ˜¾è‘—çš„è‡ªé€‚åº”æ€§å’Œå®ç”¨æ€§ã€‚è¿™é¡¹å·¥ä½œæ·±åŒ–äº†å¯¹ç»“æ„åŒ–ç½‘ç»œæµé‡ä¸­å¯¹æŠ—æ”»å‡»çš„ç†è§£ï¼Œä¸ºå¼€å‘æ›´ç¨³å¥çš„é˜²å¾¡æœºåˆ¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20576v1",
      "published_date": "2025-06-25 16:10:20 UTC",
      "updated_date": "2025-06-25 16:10:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:26:33.061694+00:00"
    },
    {
      "arxiv_id": "2506.20567v1",
      "title": "Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization",
      "title_zh": "å±•ç¤ºã€è®²è¿°ä¸æ€»ç»“ï¼šåŸºäºè§†è§‰çº¿ç´¢è¾…åŠ©å¥å­æ‘˜è¦çš„ç¨ å¯†è§†é¢‘æè¿°",
      "authors": [
        "Zhiwang Zhang",
        "Dong Xu",
        "Wanli Ouyang",
        "Chuanqi Tan"
      ],
      "abstract": "In this work, we propose a division-and-summarization (DaS) framework for dense video captioning. After partitioning each untrimmed long video as multiple event proposals, where each event proposal consists of a set of short video segments, we extract visual feature (e.g., C3D feature) from each segment and use the existing image/video captioning approach to generate one sentence description for this segment. Considering that the generated sentences contain rich semantic descriptions about the whole event proposal, we formulate the dense video captioning task as a visual cue aided sentence summarization problem and propose a new two stage Long Short Term Memory (LSTM) approach equipped with a new hierarchical attention mechanism to summarize all generated sentences as one descriptive sentence with the aid of visual features. Specifically, the first-stage LSTM network takes all semantic words from the generated sentences and the visual features from all segments within one event proposal as the input, and acts as the encoder to effectively summarize both semantic and visual information related to this event proposal. The second-stage LSTM network takes the output from the first-stage LSTM network and the visual features from all video segments within one event proposal as the input, and acts as the decoder to generate one descriptive sentence for this event proposal. Our comprehensive experiments on the ActivityNet Captions dataset demonstrate the effectiveness of our newly proposed DaS framework for dense video captioning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯†é›†è§†é¢‘å­—å¹•ç”Ÿæˆ(Dense Video Captioning)ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åä¸ºDaS(Division-and-Summarization)çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆå°†æœªå‰ªè¾‘çš„é•¿è§†é¢‘åˆ’åˆ†ä¸ºå¤šä¸ªäº‹ä»¶ææ¡ˆ(Event Proposals)ï¼Œå¹¶ä»è§†é¢‘ç‰‡æ®µä¸­æå–C3Dç­‰è§†è§‰ç‰¹å¾ï¼Œè¿›è€Œä¸ºæ¯ä¸ªç‰‡æ®µç”Ÿæˆåˆæ­¥çš„å•å¥æè¿°ã€‚ä¸ºäº†æ•´åˆè¿™äº›æè¿°ï¼Œè®ºæ–‡å°†è¯¥ä»»åŠ¡å»ºæ¨¡ä¸ºè§†è§‰çº¿ç´¢è¾…åŠ©çš„å¥å­æ‘˜è¦é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§é…å¤‡åˆ†å±‚æ³¨æ„åŠ›æœºåˆ¶(Hierarchical Attention Mechanism)çš„ä¸¤é˜¶æ®µLSTMæ¨¡å‹ã€‚ç¬¬ä¸€é˜¶æ®µLSTMä½œä¸ºç¼–ç å™¨ï¼Œè´Ÿè´£æœ‰æ•ˆæ€»ç»“äº‹ä»¶ææ¡ˆä¸­çš„è¯­ä¹‰è¯æ±‡å’Œè§†è§‰ä¿¡æ¯ï¼›ç¬¬äºŒé˜¶æ®µLSTMä½œä¸ºè§£ç å™¨ï¼Œç»“åˆç¼–ç ç»“æœä¸è§†è§‰ç‰¹å¾ç”Ÿæˆæœ€ç»ˆçš„æè¿°æ€§å¥å­ã€‚åœ¨ActivityNet Captionsæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼ŒDaSæ¡†æ¶èƒ½æœ‰æ•ˆåˆ©ç”¨è§†è§‰çº¿ç´¢æ¥å¼•å¯¼å¥å­æ‘˜è¦ï¼Œä»è€Œæ˜¾è‘—æå‡äº†å¯†é›†è§†é¢‘å­—å¹•ç”Ÿæˆçš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "https://arxiv.org/pdf/2506.20567v1",
      "published_date": "2025-06-25 16:02:04 UTC",
      "updated_date": "2025-06-25 16:02:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:26:53.807681+00:00"
    },
    {
      "arxiv_id": "2506.20555v1",
      "title": "DeepQuark: deep-neural-network approach to multiquark bound states",
      "title_zh": "DeepQuarkï¼šæ±‚è§£å¤šå¤¸å…‹æŸç¼šæ€çš„æ·±åº¦ç¥ç»ç½‘ç»œæ–¹æ³•",
      "authors": [
        "Wei-Lin Wu",
        "Lu Meng",
        "Shi-Lin Zhu"
      ],
      "abstract": "For the first time, we implement the deep-neural-network-based variational Monte Carlo approach for the multiquark bound states, whose complexity surpasses that of electron or nucleon systems due to strong SU(3) color interactions. We design a novel and high-efficiency architecture, DeepQuark, to address the unique challenges in multiquark systems such as stronger correlations, extra discrete quantum numbers, and intractable confinement interaction. Our method demonstrates competitive performance with state-of-the-art approaches, including diffusion Monte Carlo and Gaussian expansion method, in the nucleon, doubly heavy tetraquark, and fully heavy tetraquark systems. Notably, it outperforms existing calculations for pentaquarks, exemplified by the triply heavy pentaquark. For the nucleon, we successfully incorporate three-body flux-tube confinement interactions without additional computational costs. In tetraquark systems, we consistently describe hadronic molecule $T_{cc}$ and compact tetraquark $T_{bb}$ with an unbiased form of wave function ansatz. In the pentaquark sector, we obtain weakly bound $\\bar D^*Î_{cc}^*$ molecule $P_{cc\\bar c}(5715)$ with $S=\\frac{5}{2}$ and its bottom partner $P_{bb\\bar b}(15569)$. They can be viewed as the analogs of the molecular $T_{cc}$. We recommend experimental search of $P_{cc\\bar c}(5715)$ in the D-wave $J/ÏˆÎ›_c$ channel. DeepQuark holds great promise for extension to larger multiquark systems, overcoming the computational barriers in conventional methods. It also serves as a powerful framework for exploring confining mechanism beyond two-body interactions in multiquark states, which may offer valuable insights into nonperturbative QCD and general many-body physics.",
      "tldr_zh": "è¯¥ç ”ç©¶é¦–æ¬¡å®ç°äº†åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œ(deep-neural-network)çš„å˜åˆ†è’™ç‰¹å¡ç½—(variational Monte Carlo)æ–¹æ³•ï¼Œå¹¶å¼€å‘äº†åä¸ºDeepQuarkçš„åˆ›æ–°æ¶æ„æ¥æ¢ç©¶å¤šå¤¸å…‹æŸç¼šæ€(multiquark bound states)ã€‚DeepQuarkä¸“é—¨ç”¨äºå¤„ç†å¤šå¤¸å…‹ç³»ç»Ÿä¸­å¼ºSU(3)é¢œè‰²ç›¸äº’ä½œç”¨å¸¦æ¥çš„å¼ºå…³è”ã€ç¦»æ•£é‡å­æ•°åŠç¦é—­ç›¸äº’ä½œç”¨(confinement interaction)ç­‰å¤æ‚æŒ‘æˆ˜ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ ¸å­ã€åŒé‡å‘³åŠå…¨é‡å‘³å››å¤¸å…‹ç³»ç»Ÿä¸Šçš„è¡¨ç°ä¸æ‰©æ•£è’™ç‰¹å¡ç½—(diffusion Monte Carlo)å’Œé«˜æ–¯å±•å¼€æ³•(Gaussian expansion method)ç­‰å…ˆè¿›æŠ€æœ¯ç›¸å½“ï¼Œå¹¶åœ¨äº”å¤¸å…‹ç³»ç»Ÿè®¡ç®—ä¸­å–å¾—äº†æ›´ä¼˜ç»“æœã€‚ç ”ç©¶é€šè¿‡æ— åæ³¢å‡½æ•°æè¿°äº†å¼ºå­åˆ†å­ $T_{cc}$ å’Œç´§å‡‘å››å¤¸å…‹ $T_{bb}$ï¼Œå¹¶é¢„æµ‹äº†æ–°çš„å¼±æŸç¼šåˆ†å­æ€ $P_{cc\\bar c}(5715)$ ä¸ $P_{bb\\bar b}(15569)$ã€‚ä½œè€…å»ºè®®åœ¨Dæ³¢ $J/ÏˆÎ›_c$ é€šé“å¯¹ $P_{cc\\bar c}(5715)$ è¿›è¡Œå®éªŒæœç´¢ã€‚DeepQuarkä¸ä»…å…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„è®¡ç®—å£å’ï¼Œè¿˜ä¸ºç ”ç©¶éå¾®æ‰°é‡å­è‰²åŠ¨åŠ›å­¦(nonperturbative QCD)åŠå¹¿ä¹‰å¤šä½“ç‰©ç†æä¾›äº†å¼ºæœ‰åŠ›çš„æ¡†æ¶ã€‚",
      "categories": [
        "hep-ph",
        "cs.AI",
        "hep-ex",
        "hep-lat",
        "nucl-th"
      ],
      "primary_category": "hep-ph",
      "comment": "10 pages, 3 figures, 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2506.20555v1",
      "published_date": "2025-06-25 15:53:18 UTC",
      "updated_date": "2025-06-25 15:53:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:26:38.204727+00:00"
    },
    {
      "arxiv_id": "2506.20551v1",
      "title": "Large Language Model-Driven Code Compliance Checking in Building Information Modeling",
      "title_zh": "å»ºç­‘ä¿¡æ¯æ¨¡å‹ä¸­å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„è§„èŒƒåˆè§„æ€§æ£€æŸ¥",
      "authors": [
        "Soumya Madireddy",
        "Lu Gao",
        "Zia Din",
        "Kinam Kim",
        "Ahmed Senouci",
        "Zhe Han",
        "Yunpeng Zhang"
      ],
      "abstract": "This research addresses the time-consuming and error-prone nature of manual code compliance checking in Building Information Modeling (BIM) by introducing a Large Language Model (LLM)-driven approach to semi-automate this critical process. The developed system integrates LLMs such as GPT, Claude, Gemini, and Llama, with Revit software to interpret building codes, generate Python scripts, and perform semi-automated compliance checks within the BIM environment. Case studies on a single-family residential project and an office building project demonstrated the system's ability to reduce the time and effort required for compliance checks while improving accuracy. It streamlined the identification of violations, such as non-compliant room dimensions, material usage, and object placements, by automatically assessing relationships and generating actionable reports. Compared to manual methods, the system eliminated repetitive tasks, simplified complex regulations, and ensured reliable adherence to standards. By offering a comprehensive, adaptable, and cost-effective solution, this proposed approach offers a promising advancement in BIM-based compliance checking, with potential applications across diverse regulatory documents in construction projects.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å»ºç­‘ä¿¡æ¯æ¨¡å‹ (Building Information Modeling, BIM) ä¸­äººå·¥è¿›è¡Œè§„èŒƒåˆè§„æ€§æ£€æŸ¥ (code compliance checking) è€—æ—¶ä¸”æ˜“å‡ºé”™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç”±å¤§è¯­è¨€æ¨¡å‹ (Large Language Model, LLM) é©±åŠ¨çš„åŠè‡ªåŠ¨åŒ–æ–¹æ³•ã€‚è¯¥ç³»ç»Ÿæ•´åˆäº† GPTã€Claudeã€Gemini å’Œ Llama ç­‰å¤šç§ LLMï¼Œå¹¶ä¸ Revit è½¯ä»¶ç»“åˆï¼Œå®ç°äº†å¯¹å»ºç­‘è§„èŒƒçš„è§£æã€Python è„šæœ¬çš„è‡ªåŠ¨ç”Ÿæˆä»¥åŠåœ¨ BIM ç¯å¢ƒä¸‹çš„åŠè‡ªåŠ¨åŒ–æ£€æŸ¥ã€‚é€šè¿‡å¯¹å•æˆ·ä½å®…å’ŒåŠå…¬æ¥¼é¡¹ç›®çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œè¯æ˜è¯¥ç³»ç»Ÿèƒ½å¤Ÿæ˜¾è‘—å‡å°‘æ£€æŸ¥æ‰€éœ€çš„æ—¶é—´å’Œç²¾åŠ›ï¼Œå¹¶æé«˜åˆè§„æ€§æ£€æŸ¥çš„å‡†ç¡®æ€§ã€‚è¯¥ç³»ç»Ÿé€šè¿‡è‡ªåŠ¨è¯„ä¼°ç©ºé—´å…³ç³»å¹¶ç”Ÿæˆå¯æ“ä½œæŠ¥å‘Šï¼Œèƒ½å¤Ÿé«˜æ•ˆè¯†åˆ«æˆ¿é—´å°ºå¯¸ã€ææ–™ä½¿ç”¨å’Œæ„ä»¶å¸ƒç½®ç­‰æ–¹é¢çš„è¿è§„è¡Œä¸ºã€‚ä¸ä¼ ç»Ÿäººå·¥æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ¡ˆæ¶ˆé™¤äº†é‡å¤æ€§ä»»åŠ¡ï¼Œç®€åŒ–äº†å¯¹å¤æ‚æ³•è§„çš„ç†è§£ï¼Œå¹¶ç¡®ä¿äº†å¯¹æ ‡å‡†çš„ä¸€è‡´æ€§éµå¾ªã€‚è¿™ç§å…¨é¢ä¸”å…·æœ‰æˆæœ¬æ•ˆç›Šçš„æ–¹æ³•ä¸ºåŸºäº BIM çš„åˆè§„æ€§æ£€æŸ¥æä¾›äº†é‡è¦è¿›å±•ï¼Œåœ¨å»ºç­‘é¡¹ç›®çš„å„ç±»ç›‘ç®¡æ–‡æ¡£å¤„ç†ä¸­å…·æœ‰å¹¿é˜”çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20551v1",
      "published_date": "2025-06-25 15:50:34 UTC",
      "updated_date": "2025-06-25 15:50:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:26:55.105740+00:00"
    },
    {
      "arxiv_id": "2507.22064v1",
      "title": "Machine Learning Experiences: A story of learning AI for use in enterprise software testing that can be used by anyone",
      "title_zh": "æœºå™¨å­¦ä¹ å®è·µï¼šä¸€ç§é¢å‘ä¼ä¸šè½¯ä»¶æµ‹è¯•çš„æ™®é€‚æ€§äººå·¥æ™ºèƒ½å­¦ä¹ è·¯å¾„",
      "authors": [
        "Michael Cohoon",
        "Debbie Furman"
      ],
      "abstract": "This paper details the machine learning (ML) journey of a group of people focused on software testing. It tells the story of how this group progressed through a ML workflow (similar to the CRISP-DM process). This workflow consists of the following steps and can be used by anyone applying ML techniques to a project: gather the data; clean the data; perform feature engineering on the data; splitting the data into two sets, one for training and one for testing; choosing a machine learning model; training the model; testing the model and evaluating the model performance. By following this workflow, anyone can effectively apply ML to any project that they are doing.",
      "tldr_zh": "è¯¥è®ºæ–‡è¯¦ç»†è®°å½•äº†ä¸€ç»„è½¯ä»¶æµ‹è¯•ä¸“ä¸šäººå‘˜å­¦ä¹ å¹¶åº”ç”¨æœºå™¨å­¦ä¹ (Machine Learning)çš„å®è·µå†ç¨‹ï¼Œæ—¨åœ¨ä¸ºä¼ä¸šè½¯ä»¶æµ‹è¯•ä¸­çš„AIåº”ç”¨æä¾›æŒ‡å¯¼ã€‚ç ”ç©¶è€…å±•ç¤ºäº†ä¸€ä¸ªç±»ä¼¼äºCRISP-DMçš„æ ‡å‡†åŒ–æœºå™¨å­¦ä¹ å·¥ä½œæµ(Workflow)ï¼Œè¯¥æµç¨‹æ¶µç›–äº†æ•°æ®æ”¶é›†(Gather the data)ã€æ•°æ®æ¸…æ´—(Clean the data)ã€ç‰¹å¾å·¥ç¨‹(Feature engineering)ä»¥åŠæ•°æ®é›†åˆ†å‰²ç­‰æ ¸å¿ƒæ­¥éª¤ã€‚æ–‡ä¸­è¿›ä¸€æ­¥é˜è¿°äº†å¦‚ä½•é€‰æ‹©ã€è®­ç»ƒã€æµ‹è¯•æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¹¶å¯¹å…¶æ€§èƒ½è¯„ä¼°(Evaluating the model performance)è¿›è¡Œäº†æ·±å…¥æ¢è®¨ã€‚è¯¥ç ”ç©¶çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºè¯æ˜äº†é€šè¿‡éµå¾ªè¿™ä¸€ç³»ç»ŸåŒ–çš„å·¥ä½œæµï¼Œä»»ä½•èƒŒæ™¯çš„äººå‘˜éƒ½èƒ½åœ¨å„è‡ªçš„é¡¹ç›®ä¸­æœ‰æ•ˆåœ°å®æ–½æœºå™¨å­¦ä¹ æŠ€æœ¯ã€‚æœ€ç»ˆï¼Œè¿™ç¯‡è®ºæ–‡ä¸ºä¼ä¸šçº§è½¯ä»¶æµ‹è¯•é¢†åŸŸçš„æ™ºèƒ½åŒ–è½¬å‹æä¾›äº†ä¸€å¥—å¯å€Ÿé‰´çš„å®æˆ˜ç»éªŒå’Œæ–¹æ³•æ¡†æ¶ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.22064v1",
      "published_date": "2025-06-25 15:50:24 UTC",
      "updated_date": "2025-06-25 15:50:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:26:46.316169+00:00"
    },
    {
      "arxiv_id": "2506.20548v1",
      "title": "Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks",
      "title_zh": "å‡å°‘å¯¹è¯¯å¯¼æ€§ä¼ªå½±çš„å…³æ³¨ï¼šé’ˆå¯¹åœ¨çº¿ç¤¾äº¤ç½‘ç»œä¸­å‹ç¼©æ·±åº¦ä¼ªé€ çš„é²æ£’æ£€æµ‹",
      "authors": [
        "Manyi Li",
        "Renshuai Tao",
        "Yufan Liu",
        "Chuangchuang Tan",
        "Haotong Qin",
        "Bing Li",
        "Yunchao Wei",
        "Yao Zhao"
      ],
      "abstract": "With the rapid advancement of deep learning, particularly through generative adversarial networks (GANs) and diffusion models (DMs), AI-generated images, or ``deepfakes\", have become nearly indistinguishable from real ones. These images are widely shared across Online Social Networks (OSNs), raising concerns about their misuse. Existing deepfake detection methods overlook the ``block effects\" introduced by compression in OSNs, which obscure deepfake artifacts, and primarily focus on raw images, rarely encountered in real-world scenarios. To address these challenges, we propose PLADA (Pay Less Attention to Deceptive Artifacts), a novel framework designed to tackle the lack of paired data and the ineffective use of compressed images. PLADA consists of two core modules: Block Effect Eraser (B2E), which uses a dual-stage attention mechanism to handle block effects, and Open Data Aggregation (ODA), which processes both paired and unpaired data to improve detection. Extensive experiments across 26 datasets demonstrate that PLADA achieves a remarkable balance in deepfake detection, outperforming SoTA methods in detecting deepfakes on OSNs, even with limited paired data and compression. More importantly, this work introduces the ``block effect\" as a critical factor in deepfake detection, providing a robust solution for open-world scenarios. Our code is available at https://github.com/ManyiLee/PLADA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤ç½‘ç»œ(Online Social Networks, OSNs)ä¸­å›¾åƒå‹ç¼©äº§ç”Ÿçš„å—æ•ˆåº”(block effects)æ©ç›–ä¼ªé€ ç—•è¿¹çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºPLADAçš„é²æ£’æ£€æµ‹æ¡†æ¶ã€‚é‰´äºç°æœ‰Deepfakeæ£€æµ‹æ–¹æ³•å¤šå…³æ³¨åŸå§‹å›¾åƒè€Œå¿½è§†äº†çœŸå®åœºæ™¯ä¸­çš„å‹ç¼©æŒ‘æˆ˜ï¼ŒPLADAè®¾è®¡äº†Block Effect Eraser (B2E) æ¨¡å—ï¼Œåˆ©ç”¨åŒé˜¶æ®µæ³¨æ„åŠ›æœºåˆ¶å¤„ç†å—æ•ˆåº”ï¼Œå¹¶é…åˆOpen Data Aggregation (ODA) æ¨¡å—æ•´åˆæœ‰å¯¹å’Œæ— å¯¹æ•°æ®ä»¥æå‡æ£€æµ‹æ€§èƒ½ã€‚åœ¨26ä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼ŒPLADAåœ¨æ£€æµ‹OSNsä¸Šçš„å‹ç¼©Deepfakesæ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„SoTAæ–¹æ³•ï¼Œå³ä½¿åœ¨æˆå¯¹æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹ä¹Ÿèƒ½ä¿æŒé«˜å‡†ç¡®ç‡ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†å—æ•ˆåº”(block effect)æ˜¯Deepfakeæ£€æµ‹ä¸­çš„å…³é”®å› ç´ ï¼Œä¸ºå¼€æ”¾ä¸–ç•Œ(open-world)åœºæ™¯ä¸‹çš„ä¼ªé€ å›¾åƒè¯†åˆ«æä¾›äº†æœ‰æ•ˆçš„é²æ£’è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.20548v1",
      "published_date": "2025-06-25 15:46:41 UTC",
      "updated_date": "2025-06-25 15:46:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:26:55.474705+00:00"
    },
    {
      "arxiv_id": "2506.20544v1",
      "title": "When Life Gives You Samples: The Benefits of Scaling up Inference Compute for Multilingual LLMs",
      "title_zh": "å€Ÿé‡‡æ ·ä¹‹åˆ©ï¼šæ‰©å±•å¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹æ¨ç†ä¾§è®¡ç®—çš„æ”¶ç›Š",
      "authors": [
        "Ammar Khairi",
        "Daniel D'souza",
        "Ye Shen",
        "Julia Kreutzer",
        "Sara Hooker"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have shifted focus toward scaling inference-time compute, improving performance without retraining the model. A common approach is to sample multiple outputs in parallel, and select one of these as the final output. However, work to date has focused on English and a handful of domains such as math and code. In contrast, we are most interested in techniques that generalize across open-ended tasks, formally verifiable tasks, and across languages. In this work, we study how to robustly scale inference-time compute for open-ended generative tasks in a multilingual, multi-task setting.\n  Our findings show that both sampling strategy based on temperature variation and selection strategy must be adapted to account for diverse domains and varied language settings. We evaluate existing selection methods, revealing that strategies effective in English often fail to generalize across languages. We propose novel sampling and selection strategies specifically adapted for multilingual and multi-task inference scenarios, and show they yield notable gains across languages and tasks. In particular, our combined sampling and selection methods lead to an average +6.8 jump in win-rates for our 8B models on m-ArenaHard-v2.0 prompts, against proprietary models such as Gemini. At larger scale, Command-A (111B model) equipped with our methods, shows +9.0 improvement in win-rates on the same benchmark with just five samples against single-sample decoding, a substantial increase at minimal cost. Our results underscore the need for language- and task-aware approaches to inference-time compute, aiming to democratize performance improvements in underrepresented languages.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡æ‰©å±•æ¨ç†è®¡ç®—(inference-time compute)æ¥æå‡å¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹(Multilingual LLMs)åœ¨å¤šä»»åŠ¡ã€è·¨è¯­è¨€ç”Ÿæˆåœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚ä½œè€…å‘ç°ï¼Œç›®å‰ä¸»æµçš„æ¨ç†æ‰©å±•ç­–ç•¥ä¸»è¦é’ˆå¯¹è‹±è¯­ç¯å¢ƒï¼Œåœ¨å¤šè¯­è¨€è®¾ç½®ä¸­å­˜åœ¨æ³›åŒ–æ€§ä¸è¶³çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†ä¸€å¥—ä¸“é—¨é’ˆå¯¹å¤šè¯­è¨€åœºæ™¯ä¼˜åŒ–çš„é‡‡æ ·(sampling)å’Œé€‰æ‹©(selection)ç­–ç•¥ï¼Œå¼ºè°ƒäº†æ¸©åº¦å˜åŒ–(temperature variation)ä»¥åŠè¯­è¨€æ„ŸçŸ¥(language-aware)çš„é‡è¦æ€§ã€‚å®éªŒæ•°æ®è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨m-ArenaHard-v2.0åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ¨¡å‹è¡¨ç°ï¼Œä½¿8Bæ¨¡å‹çš„èƒœç‡(win-rates)å¹³å‡æé«˜äº†6.8%ã€‚å¯¹äºå¤§è§„æ¨¡æ¨¡å‹Command-A (111B)ï¼Œä»…ä½¿ç”¨5ä¸ªé‡‡æ ·æ ·æœ¬å³å¯è·å¾—9.0%çš„èƒœç‡æå‡ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æä½æˆæœ¬ä¸‹çš„é«˜æ•ˆæ€§ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å¼€å‘ä»»åŠ¡æ„ŸçŸ¥(task-aware)æ¨ç†ç­–ç•¥çš„å¿…è¦æ€§ï¼Œä¸ºæå‡å¼±åŠ¿è¯­è¨€çš„æ¨¡å‹æ€§èƒ½å¹¶å®ç°æŠ€æœ¯æ°‘ä¸»åŒ–æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20544v1",
      "published_date": "2025-06-25 15:37:53 UTC",
      "updated_date": "2025-06-25 15:37:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:27:00.981064+00:00"
    },
    {
      "arxiv_id": "2506.20535v2",
      "title": "AIMeter: Measuring, Analyzing, and Visualizing Energy and Carbon Footprint of AI Workloads",
      "title_zh": "AIMeterï¼šäººå·¥æ™ºèƒ½å·¥ä½œè´Ÿè½½èƒ½æºä¸ç¢³è¶³è¿¹çš„æµ‹é‡ã€åˆ†æä¸å¯è§†åŒ–",
      "authors": [
        "Hongzhen Huang",
        "Kunming Zhang",
        "Hanlong Liao",
        "Kui Wu",
        "Guoming Tang"
      ],
      "abstract": "The rapid advancement of AI, particularly large language models (LLMs), has raised significant concerns about the energy use and carbon emissions associated with model training and inference. However, existing tools for measuring and reporting such impacts are often fragmented, lacking systematic metric integration and offering limited support for correlation analysis among them. This paper presents AIMeter, a comprehensive software toolkit for the measurement, analysis, and visualization of energy use, power draw, hardware performance, and carbon emissions across AI workloads. By seamlessly integrating with existing AI frameworks, AIMeter offers standardized reports and exports fine-grained time-series data to support benchmarking and reproducibility in a lightweight manner. It further enables in-depth correlation analysis between hardware metrics and model performance and thus facilitates bottleneck identification and performance enhancement. By addressing critical limitations in existing tools, AIMeter encourages the research community to weigh environmental impact alongside raw performance of AI workloads and advances the shift toward more sustainable \"Green AI\" practices. The code is available at https://github.com/SusCom-Lab/AIMeter.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†AIMeterï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹AI Workloadsçš„èƒ½é‡æ¶ˆè€—å’Œç¢³è¶³è¿¹è¿›è¡Œæµ‹é‡ã€åˆ†æå’Œå¯è§†åŒ–çš„ç»¼åˆè½¯ä»¶å·¥å…·åŒ…ã€‚é’ˆå¯¹ç›®å‰æµ‹é‡å·¥å…·ç¢ç‰‡åŒ–ã€ç¼ºä¹ç³»ç»Ÿåº¦é‡æ•´åˆä»¥åŠå…³è”åˆ†æèƒ½åŠ›æœ‰é™ç­‰é—®é¢˜ï¼ŒAIMeteræ—¨åœ¨æ¨åŠ¨AIç ”ç©¶å‘æ›´å¯æŒç»­çš„Green AIè½¬å‹ã€‚è¯¥å·¥å…·åŒ…èƒ½å¤Ÿæ— ç¼é›†æˆåˆ°ç°æœ‰çš„AI Frameworksä¸­ï¼Œæä¾›æ ‡å‡†åŒ–çš„æŠ¥å‘Šå¹¶ä»¥è½»é‡çº§æ–¹å¼å¯¼å‡ºç»†ç²’åº¦çš„æ—¶åºæ•°æ®ï¼Œä»è€Œæ”¯æŒBenchmarkingå’Œå¯é‡å¤æ€§ã€‚é€šè¿‡å¯¹Hardware Metricsä¸Model Performanceä¹‹é—´çš„æ·±å…¥å…³è”åˆ†æï¼ŒAIMeterå¯ä»¥æœ‰æ•ˆåœ°è¯†åˆ«ç³»ç»Ÿç“¶é¢ˆå¹¶è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½ã€‚è¯¥å·¥å…·çš„æ¨å‡ºé¼“åŠ±ç ”ç©¶ç•Œåœ¨è¿½æ±‚åŸå§‹æ€§èƒ½çš„åŒæ—¶å……åˆ†æƒè¡¡å…¶ç¯å¢ƒå½±å“ï¼Œä¸ºå®ç°æ›´ç¯ä¿çš„AIå®è·µå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "11 pages, 7 figures and 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2506.20535v2",
      "published_date": "2025-06-25 15:24:45 UTC",
      "updated_date": "2025-10-30 10:14:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:27:00.038474+00:00"
    },
    {
      "arxiv_id": "2506.20531v1",
      "title": "Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios",
      "title_zh": "é¢å‘ç°å®å®‰å…¨æ”¸å…³é©¾é©¶åœºæ™¯å†³ç­–çš„æ¡ˆä¾‹æ¨ç†å¢å¼ºå¤§è¯­è¨€æ¨¡å‹æ¡†æ¶",
      "authors": [
        "Wenbin Gan",
        "Minh-Son Dao",
        "Koji Zettsu"
      ],
      "abstract": "Driving in safety-critical scenarios requires quick, context-aware decision-making grounded in both situational understanding and experiential reasoning. Large Language Models (LLMs), with their powerful general-purpose reasoning capabilities, offer a promising foundation for such decision-making. However, their direct application to autonomous driving remains limited due to challenges in domain adaptation, contextual grounding, and the lack of experiential knowledge needed to make reliable and interpretable decisions in dynamic, high-risk environments. To address this gap, this paper presents a Case-Based Reasoning Augmented Large Language Model (CBR-LLM) framework for evasive maneuver decision-making in complex risk scenarios. Our approach integrates semantic scene understanding from dashcam video inputs with the retrieval of relevant past driving cases, enabling LLMs to generate maneuver recommendations that are both context-sensitive and human-aligned. Experiments across multiple open-source LLMs show that our framework improves decision accuracy, justification quality, and alignment with human expert behavior. Risk-aware prompting strategies further enhance performance across diverse risk types, while similarity-based case retrieval consistently outperforms random sampling in guiding in-context learning. Case studies further demonstrate the framework's robustness in challenging real-world conditions, underscoring its potential as an adaptive and trustworthy decision-support tool for intelligent driving systems.",
      "tldr_zh": "åœ¨å®‰å…¨è‡³ä¸Šçš„é©¾é©¶åœºæ™¯ä¸­ï¼Œå¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨é¢†åŸŸè‡ªé€‚åº”ã€ä¸Šä¸‹æ–‡å…³è”ä»¥åŠç¼ºä¹ç»éªŒçŸ¥è¯†æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶æå‡ºäº†åŸºäºæ¡ˆä¾‹æ¨ç†å¢å¼ºçš„å¤§è¯­è¨€æ¨¡å‹ (CBR-LLM) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤æ‚é£é™©åœºæ™¯ä¸‹çš„è§„é¿åŠ¨ä½œå†³ç­–é—®é¢˜ã€‚è¯¥æ¡†æ¶é›†æˆäº†æ¥è‡ªè¡Œè½¦è®°å½•ä»ªè§†é¢‘çš„è¯­ä¹‰åœºæ™¯ç†è§£ (Semantic Scene Understanding) ä¸ç›¸å…³å†å²é©¾é©¶æ¡ˆä¾‹çš„æ£€ç´¢ï¼Œä½¿ LLMs èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ä¸Šä¸‹æ–‡æ•æ„Ÿæ€§ä¸”ç¬¦åˆäººç±»è¡Œä¸ºé€»è¾‘çš„é©¾é©¶å»ºè®®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤šä¸ªå¼€æº LLMs ä¸Šæå‡äº†å†³ç­–å‡†ç¡®æ€§ã€è®ºè¯è´¨é‡ä»¥åŠä¸ä¸“å®¶è¡Œä¸ºçš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œé£é™©æ„ŸçŸ¥æç¤º (Risk-aware prompting) ç­–ç•¥å¢å¼ºäº†å¯¹å¤šæ ·åŒ–é£é™©çš„å¤„ç†èƒ½åŠ›ï¼Œè€ŒåŸºäºç›¸ä¼¼æ€§çš„æ¡ˆä¾‹æ£€ç´¢åœ¨å¼•å¯¼ä¸Šä¸‹æ–‡å­¦ä¹  (In-context learning) æ–¹é¢ä¼˜äºéšæœºé‡‡æ ·ã€‚æ¡ˆä¾‹ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†è¯¥ç³»ç»Ÿåœ¨ç°å®æŒ‘æˆ˜ç¯å¢ƒä¸‹çš„é²æ£’æ€§ï¼Œä¸ºå…¶ä½œä¸ºæ™ºèƒ½é©¾é©¶ç³»ç»Ÿä¸­å¯ä¿¡çš„å†³ç­–æ”¯æŒå·¥å…·å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 10 figures, under-review conference",
      "pdf_url": "https://arxiv.org/pdf/2506.20531v1",
      "published_date": "2025-06-25 15:19:25 UTC",
      "updated_date": "2025-06-25 15:19:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:27:29.156040+00:00"
    },
    {
      "arxiv_id": "2506.20525v2",
      "title": "Industrial Energy Disaggregation with Digital Twin-generated Dataset and Efficient Data Augmentation",
      "title_zh": "åŸºäºæ•°å­—å­ªç”Ÿç”Ÿæˆæ•°æ®é›†ä¸é«˜æ•ˆæ•°æ®å¢å¼ºçš„å·¥ä¸šè´Ÿè·åˆ†è§£",
      "authors": [
        "Christian InternÃ²",
        "Andrea Castellani",
        "Sebastian Schmitt",
        "Fabio Stella",
        "Barbara Hammer"
      ],
      "abstract": "Industrial Non-Intrusive Load Monitoring (NILM) is limited by the scarcity of high-quality datasets and the complex variability of industrial energy consumption patterns. To address data scarcity and privacy issues, we introduce the Synthetic Industrial Dataset for Energy Disaggregation (SIDED), an open-source dataset generated using Digital Twin simulations. SIDED includes three types of industrial facilities across three different geographic locations, capturing diverse appliance behaviors, weather conditions, and load profiles. We also propose the Appliance-Modulated Data Augmentation (AMDA) method, a computationally efficient technique that enhances NILM model generalization by intelligently scaling appliance power contributions based on their relative impact. We show in experiments that NILM models trained with AMDA-augmented data significantly improve the disaggregation of energy consumption of complex industrial appliances like combined heat and power systems. Specifically, in our out-of-sample scenarios, models trained with AMDA achieved a Normalized Disaggregation Error of 0.093, outperforming models trained without data augmentation (0.451) and those trained with random data augmentation (0.290). Data distribution analyses confirm that AMDA effectively aligns training and test data distributions, enhancing model generalization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·¥ä¸š Non-Intrusive Load Monitoring (NILM) é¢ä¸´çš„é«˜è´¨é‡æ•°æ®é›†ç¨€ç¼ºå’Œèƒ½æºæ¶ˆè€—æ¨¡å¼å¤æ‚å¤šå˜çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäº Digital Twin æ¨¡æ‹Ÿç”Ÿæˆçš„å¼€æºæ•°æ®é›† Synthetic Industrial Dataset for Energy Disaggregation (SIDED)ã€‚è¯¥æ•°æ®é›†æ¶µç›–äº†ä¸‰ä¸ªä¸åŒåœ°ç†ä½ç½®çš„ä¸‰ç±»å·¥ä¸šè®¾æ–½ï¼Œèƒ½å¤Ÿæ•æ‰å¤šæ ·çš„è®¾å¤‡è¡Œä¸ºã€å¤©æ°”çŠ¶å†µå’Œè´Ÿè½½ç‰¹æ€§ã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº† Appliance-Modulated Data Augmentation (AMDA) æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡æ™ºèƒ½ç¼©æ”¾è®¾å¤‡ç”µåŠ›è´¡çŒ®æ¥å¢å¼ºæ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„è®¡ç®—é«˜æ•ˆå‹æŠ€æœ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ AMDA å¢å¼ºæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹æ˜¾è‘—æå‡äº†å¯¹çƒ­ç”µè”äº§ç³»ç»Ÿç­‰å¤æ‚å·¥ä¸šè®¾å¤‡çš„åˆ†è§£æ€§èƒ½ï¼Œå…¶ Normalized Disaggregation Error (NDE) è¾¾åˆ° 0.093ï¼Œè¿œä¼˜äºæ— å¢å¼ºæˆ–éšæœºå¢å¼ºçš„æ¨¡å‹ã€‚æ•°æ®åˆ†å¸ƒåˆ†æè¯å®ï¼ŒAMDA æœ‰æ•ˆå¯¹é½äº†è®­ç»ƒé›†ä¸æµ‹è¯•é›†çš„åˆ†å¸ƒï¼Œä¸ºè§£å†³å·¥ä¸šèƒ½æºåˆ†è§£ä¸­çš„æ•°æ®åŒ®ä¹ä¸æ³›åŒ–éš¾é¢˜æä¾›äº†æœ‰åŠ›æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20525v2",
      "published_date": "2025-06-25 15:10:43 UTC",
      "updated_date": "2025-09-15 10:51:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:27:12.463145+00:00"
    },
    {
      "arxiv_id": "2507.02921v3",
      "title": "Training-Free Geospatial Place Representation Learning from Large-Scale Point-of-Interest Graph Data",
      "title_zh": "åŸºäºå¤§è§„æ¨¡å…´è¶£ç‚¹å›¾æ•°æ®çš„å…è®­ç»ƒåœ°ç†ç©ºé—´åœ°ç‚¹è¡¨å¾å­¦ä¹ ",
      "authors": [
        "Mohammad Hashemi",
        "Hossein Amiri",
        "Andreas Zufle"
      ],
      "abstract": "Learning effective representations of urban environments requires capturing spatial structure beyond fixed administrative boundaries. Existing geospatial representation learning approaches typically aggregate Points of Interest(POI) into pre-defined administrative regions such as census units or ZIP code areas, assigning a single embedding to each region. However, POIs often form semantically meaningful groups that extend across, within, or beyond these boundaries, defining places that better reflect human activity and urban function. To address this limitation, we propose PlaceRep, a training-free geospatial representation learning method that constructs place-level representations by clustering spatially and semantically related POIs. PlaceRep summarizes large-scale POI graphs from U.S. Foursquare data to produce general-purpose urban region embeddings while automatically identifying places across multiple spatial scales. By eliminating model pre-training, PlaceRep provides a scalable and efficient solution for multi-granular geospatial analysis. Experiments using the tasks of population density estimation and housing price prediction as downstream tasks show that PlaceRep outperforms most state-of-the-art graph-based geospatial representation learning methods and achieves up to a 100x speedup in generating region-level representations on large-scale POI graphs. The implementation of PlaceRep is available at https://github.com/mohammadhashemii/PlaceRep.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PlaceRepï¼Œä¸€ç§æ— éœ€è®­ç»ƒ(Training-free)çš„åœ°ç†ç©ºé—´è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–¹æ³•å°†Points of Interest(POI)èšåˆåœ¨å›ºå®šè¡Œæ”¿è¾¹ç•Œå†…è€Œå¿½è§†å…¶å®é™…è¯­ä¹‰å…³è”çš„å±€é™æ€§ã€‚PlaceRepé€šè¿‡èšç±»ç©ºé—´å’Œè¯­ä¹‰ç›¸å…³çš„POIsæ„å»ºåœºæ‰€çº§(place-level)è¡¨ç¤ºï¼Œèƒ½å¤Ÿæ›´çœŸå®åœ°åæ˜ äººç±»æ´»åŠ¨å’ŒåŸå¸‚åŠŸèƒ½ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ¥è‡ªç¾å›½Foursquareçš„å¤§è§„æ¨¡POIå›¾æ•°æ®ï¼Œåœ¨è‡ªåŠ¨è¯†åˆ«å¤šå°ºåº¦åœºæ‰€çš„åŒæ—¶æ¶ˆé™¤äº†å¤æ‚çš„æ¨¡å‹é¢„è®­ç»ƒè¿‡ç¨‹ï¼Œæå¤§åœ°æå‡äº†å¤„ç†æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPlaceRepåœ¨äººå£å¯†åº¦ä¼°è®¡å’Œæˆ¿ä»·é¢„æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°ä¼˜äºå¤§å¤šæ•°å…ˆè¿›çš„åŸºäºå›¾çš„åœ°ç†ç©ºé—´è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨ç”ŸæˆåŒºåŸŸçº§è¡¨ç¤ºæ—¶å®ç°äº†é«˜è¾¾100å€çš„åŠ é€Ÿï¼Œä¸ºå¤§è§„æ¨¡ã€å¤šç²’åº¦çš„åœ°ç†ç©ºé—´åˆ†ææä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.02921v3",
      "published_date": "2025-06-25 15:10:31 UTC",
      "updated_date": "2026-01-22 18:46:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:27:46.046215+00:00"
    },
    {
      "arxiv_id": "2507.07043v2",
      "title": "Advances in Intelligent Hearing Aids: Deep Learning Approaches to Selective Noise Cancellation",
      "title_zh": "æ™ºèƒ½åŠ©å¬å™¨ç ”ç©¶è¿›å±•ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„é€‰æ‹©æ€§é™å™ªæ–¹æ³•",
      "authors": [
        "Haris Khan",
        "Shumaila Asif",
        "Hassan Nasir",
        "Kamran Aziz Bhatti",
        "Shahzad Amin Sheikh"
      ],
      "abstract": "The integration of artificial intelligence into hearing assistance marks a paradigm shift from traditional amplification-based systems to intelligent, context-aware audio processing. This systematic literature review evaluates advances in AI-driven selective noise cancellation (SNC) for hearing aids, highlighting technological evolution, implementation challenges, and future research directions. We synthesize findings across deep learning architectures, hardware deployment strategies, clinical validation studies, and user-centric design. The review traces progress from early machine learning models to state-of-the-art deep networks, including Convolutional Recurrent Networks for real-time inference and Transformer-based architectures for high-accuracy separation. Key findings include significant gains over traditional methods, with recent models achieving up to 18.3 dB SI-SDR improvement on noisy-reverberant benchmarks, alongside sub-10 ms real-time implementations and promising clinical outcomes. Yet, challenges remain in bridging lab-grade models with real-world deployment - particularly around power constraints, environmental variability, and personalization. Identified research gaps include hardware-software co-design, standardized evaluation protocols, and regulatory considerations for AI-enhanced hearing devices. Future work must prioritize lightweight models, continual learning, contextual-based classification and clinical translation to realize transformative hearing solutions for millions globally.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿåœ°è¯„ä¼°äº†äººå·¥æ™ºèƒ½é©±åŠ¨çš„é€‰æ‹©æ€§å™ªå£°æ¶ˆé™¤ (Selective Noise Cancellation, SNC) åœ¨åŠ©å¬å™¨é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œåæ˜ äº†ä»ä¼ ç»ŸéŸ³é¢‘æ”¾å¤§å‘æ™ºèƒ½æƒ…å¢ƒæ„ŸçŸ¥å¤„ç†çš„èŒƒå¼è½¬å‹ã€‚ç ”ç©¶å…¨é¢æ¢³ç†äº†ä»æ—©æœŸæœºå™¨å­¦ä¹ åˆ°å…ˆè¿›æ·±åº¦å­¦ä¹ ç½‘ç»œçš„æŠ€æœ¯æ¼”è¿›ï¼ŒåŒ…æ‹¬ç”¨äºå®æ—¶æ¨ç†çš„ Convolutional Recurrent Networks å’Œé«˜ç²¾åº¦åˆ†ç¦»çš„ Transformer æ¶æ„ã€‚å…³é”®å‘ç°æ˜¾ç¤ºï¼Œç°ä»£æ¨¡å‹åœ¨å™ªå£°æ··å“åŸºå‡†ä¸Šå®ç°äº†é«˜è¾¾ 18.3 dB çš„ SI-SDR æå‡ï¼Œä¸”èƒ½æ»¡è¶³ä½äº 10 æ¯«ç§’çš„å®æ—¶æ€§è¦æ±‚ã€‚ç„¶è€Œï¼Œåœ¨åŠŸè€—é™åˆ¶ã€ç¯å¢ƒå˜å¼‚æ€§å’Œä¸ªæ€§åŒ–éƒ¨ç½²æ–¹é¢ï¼Œå®éªŒå®¤æ¨¡å‹ä¸ç°å®åº”ç”¨ä¹‹é—´ä»å­˜åœ¨æ˜¾è‘—å·®è·ã€‚æ–‡ç« è¿›ä¸€æ­¥æ˜ç¡®äº† Hardware-Software Co-designã€æ ‡å‡†åŒ–è¯„ä¼°åè®®åŠç›‘ç®¡æ”¿ç­–ç­‰ç ”ç©¶ç©ºç™½ã€‚æœªæ¥ç ”ç©¶éœ€ä¾§é‡äº Lightweight Modelsã€Continual Learning å’Œ Contextual-based Classification çš„å¼€å‘ï¼Œä»¥åŠ é€Ÿä¸´åºŠè½¬åŒ–å¹¶å®ç°åŠ©å¬è§£å†³æ–¹æ¡ˆçš„å…¨çƒæ™®åŠã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "9 pages, 4 figures, submitted as a systematic literature review in AI-based hearing assistance. (June 2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.07043v2",
      "published_date": "2025-06-25 15:05:16 UTC",
      "updated_date": "2025-08-01 18:43:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:27:47.169838+00:00"
    },
    {
      "arxiv_id": "2506.20512v1",
      "title": "OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling",
      "title_zh": "OctoThinkerï¼šä¸­æ®µè®­ç»ƒæ¿€å‘å¼ºåŒ–å­¦ä¹ çš„è§„æ¨¡åŒ–æ‰©å±•",
      "authors": [
        "Zengzhi Wang",
        "Fan Zhou",
        "Xuefeng Li",
        "Pengfei Liu"
      ],
      "abstract": "Different base language model families, such as Llama and Qwen, exhibit divergent behaviors during post-training with reinforcement learning (RL), especially on reasoning-intensive tasks. What makes a base language model suitable for reinforcement learning? Gaining deeper insight into this question is essential for developing RL-scalable foundation models of the next generation. In this work, we investigate how mid-training strategies shape RL dynamics, focusing on two representative model families: Qwen and Llama. Our study reveals that (1) high-quality mathematical corpora, such as MegaMath-Web-Pro, significantly improve both base model and RL performance, while existing alternatives (e.g., FineMath-4plus) fail to do so; (2) further adding QA-style data, particularly long chain-of-thought (CoT) reasoning examples, enhances RL outcomes, and instruction data further unlocks this effect; (3) while long-CoT improves reasoning depth, it can also induce verbosity of model responses and unstability of RL training, underscoring the importance of data formatting; (4) scaling mid-training consistently leads to stronger downstream RL performance. Building on these insights, we introduce a two-stage mid-training strategy, Stable-then-Decay, in which base models are first trained on 200B tokens with a constant learning rate, followed by 20B tokens across three CoT-focused branches with learning rate decay. This yields OctoThinker, a family of models demonstrating strong RL compatibility and closing the performance gap with more RL-friendly model families, i.e., Qwen. We hope our work will help shape pre-training strategies for foundation models in the RL era. To support further research, we release our open-source models along with a curated math reasoning-intensive corpus of over 70 billion tokens (i.e., MegaMath-Web-Pro-Max).",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä»€ä¹ˆæ ·çš„åŸºç¡€è¯­è¨€æ¨¡å‹(base language models)æ›´é€‚åˆè¿›è¡Œå¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)è§„æ¨¡åŒ–ï¼Œé‡ç‚¹åˆ†æäº†ä¸­ç›˜è®­ç»ƒ(mid-training)ç­–ç•¥å¯¹RLåŠ¨æ€çš„å½±å“ã€‚ç ”ç©¶å‘ç°é«˜è´¨é‡æ•°å­¦è¯­æ–™åº“(å¦‚MegaMath-Web-Pro)èƒ½æ˜¾è‘—æå‡RLæ€§èƒ½ï¼Œè€Œé•¿é“¾å¼æ€ç»´(long Chain-of-Thought, CoT)æ¨ç†æ•°æ®åœ¨æŒ‡ä»¤æ•°æ®çš„è¾…åŠ©ä¸‹èƒ½è¿›ä¸€æ­¥ä¼˜åŒ–RLç»“æœã€‚å°½ç®¡é•¿CoTå¢å¼ºäº†æ¨ç†æ·±åº¦ï¼Œä½†ä¹Ÿå¯èƒ½å¯¼è‡´æ¨¡å‹å›ç­”å†—é•¿åŠRLè®­ç»ƒä¸ç¨³å®šï¼Œè¿™çªæ˜¾äº†æ•°æ®æ ¼å¼åŒ–(data formatting)åœ¨æå‡RLè¡¨ç°ä¸­çš„é‡è¦æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸º\"Stable-then-Decay\"çš„ä¸¤é˜¶æ®µä¸­ç›˜è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡æ’å®šå­¦ä¹ ç‡è®­ç»ƒ200B tokensåï¼Œå†åœ¨ä¸“æ³¨äºCoTçš„åˆ†æ”¯ä¸Šè¿›è¡Œ20B tokensçš„å­¦ä¹ ç‡è¡°å‡è®­ç»ƒã€‚åŸºäºè¯¥ç­–ç•¥å¼€å‘çš„OctoThinkerç³»åˆ—æ¨¡å‹å±•ç°äº†æå¼ºçš„RLå…¼å®¹æ€§ï¼Œæœ‰æ•ˆç¼©å°äº†ä¸åŒæ¨¡å‹å®¶æ—é—´åœ¨RLä»»åŠ¡ä¸Šçš„æ€§èƒ½å·®è·ã€‚è¯¥ç ”ç©¶ä¸ä»…è¯å®äº†ä¸­ç›˜è®­ç»ƒè§„æ¨¡åŒ–ä¸ä¸‹æ¸¸RLè¡¨ç°çš„æ­£ç›¸å…³æ€§ï¼Œè¿˜å¼€æºäº†ç›¸å…³æ¨¡å‹åŠè¶…è¿‡70B tokensçš„é«˜è´¨é‡æ•°å­¦æ¨ç†è¯­æ–™åº“MegaMath-Web-Pro-Maxã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages; The first three authors contribute to this work equally",
      "pdf_url": "https://arxiv.org/pdf/2506.20512v1",
      "published_date": "2025-06-25 14:58:13 UTC",
      "updated_date": "2025-06-25 14:58:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:28:51.365841+00:00"
    },
    {
      "arxiv_id": "2507.02920v1",
      "title": "Visual-Conversational Interface for Evidence-Based Explanation of Diabetes Risk Prediction",
      "title_zh": "ç”¨äºç³–å°¿ç—…é£é™©é¢„æµ‹å¾ªè¯è§£é‡Šçš„è§†è§‰å¯¹è¯å¼ç•Œé¢",
      "authors": [
        "Reza Samimi",
        "Aditya Bhattacharya",
        "Lucija Gosak",
        "Gregor Stiglic",
        "Katrien Verbert"
      ],
      "abstract": "Healthcare professionals need effective ways to use, understand, and validate AI-driven clinical decision support systems. Existing systems face two key limitations: complex visualizations and a lack of grounding in scientific evidence. We present an integrated decision support system that combines interactive visualizations with a conversational agent to explain diabetes risk assessments. We propose a hybrid prompt handling approach combining fine-tuned language models for analytical queries with general Large Language Models (LLMs) for broader medical questions, a methodology for grounding AI explanations in scientific evidence, and a feature range analysis technique to support deeper understanding of feature contributions. We conducted a mixed-methods study with 30 healthcare professionals and found that the conversational interactions helped healthcare professionals build a clear understanding of model assessments, while the integration of scientific evidence calibrated trust in the system's decisions. Most participants reported that the system supported both patient risk evaluation and recommendation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—ä¸“å®¶åœ¨ç†è§£å’ŒéªŒè¯AIé©±åŠ¨çš„ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿ(CDSS)æ—¶é¢ä¸´çš„å¯è§†åŒ–å¤æ‚åŠç¼ºä¹ç§‘å­¦è¯æ®ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§é›†æˆäº¤äº’å¼å¯è§†åŒ–ä¸å¯¹è¯å¼ä»£ç†çš„è§†è§‰-å¯¹è¯æ¥å£ï¼Œç”¨äºç³–å°¿ç—…é£é™©é¢„æµ‹çš„å¾ªè¯è§£é‡Šã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨æ··åˆæç¤ºå¤„ç†æ–¹æ³•(Hybrid prompt handling approach)ï¼Œå°†é’ˆå¯¹åˆ†æå‹æŸ¥è¯¢çš„å¾®è°ƒè¯­è¨€æ¨¡å‹ä¸å¤„ç†å¹¿æ³›åŒ»å­¦é—®é¢˜çš„é€šç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)ç›¸ç»“åˆã€‚åŒæ—¶ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ç§å°†AIè§£é‡Šé”šå®šäºç§‘å­¦è¯æ®çš„æ–¹æ³•ï¼Œå¹¶ç»“åˆç‰¹å¾èŒƒå›´åˆ†æ(Feature range analysis)æŠ€æœ¯ï¼Œä»¥æ”¯æŒç”¨æˆ·å¯¹æ¨¡å‹ç‰¹å¾è´¡çŒ®åº¦çš„æ·±å…¥ç†è§£ã€‚é’ˆå¯¹30ååŒ»ç–—ä¸“ä¸šäººå‘˜çš„æ··åˆæ–¹æ³•ç ”ç©¶è¡¨æ˜ï¼Œå¯¹è¯å¼äº¤äº’èƒ½æœ‰æ•ˆå¸®åŠ©ç”¨æˆ·æ„å»ºå¯¹æ¨¡å‹è¯„ä¼°çš„æ¸…æ™°ç†è§£ï¼Œè€Œç§‘å­¦è¯æ®çš„æ•´åˆåˆ™æ˜¾è‘—æ ¡å‡†äº†ç”¨æˆ·å¯¹ç³»ç»Ÿå†³ç­–çš„ä¿¡ä»»ã€‚å¤§å¤šæ•°å‚ä¸è€…è¡¨ç¤ºï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒæ‚£è€…é£é™©è¯„ä¼°åŠä¸´åºŠå»ºè®®çš„ç”Ÿæˆã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "18 pages, 5 figures, 7th ACM Conference on Conversational User Interfaces",
      "pdf_url": "https://arxiv.org/pdf/2507.02920v1",
      "published_date": "2025-06-25 14:56:20 UTC",
      "updated_date": "2025-06-25 14:56:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:27:48.799749+00:00"
    },
    {
      "arxiv_id": "2506.20504v1",
      "title": "Engineering Sentience",
      "title_zh": "æ„ŸçŸ¥åŠ›çš„å·¥ç¨‹åŒ–å®ç°",
      "authors": [
        "Konstantin Demin",
        "Taylor Webb",
        "Eric Elmoznino",
        "Hakwan Lau"
      ],
      "abstract": "We spell out a definition of sentience that may be useful for designing and building it in machines. We propose that for sentience to be meaningful for AI, it must be fleshed out in functional, computational terms, in enough detail to allow for implementation. Yet, this notion of sentience must also reflect something essentially 'subjective', beyond just having the general capacity to encode perceptual content. For this specific functional notion of sentience to occur, we propose that certain sensory signals need to be both assertoric (persistent) and qualitative. To illustrate the definition in more concrete terms, we sketch out some ways for potential implementation, given current technology. Understanding what it takes for artificial agents to be functionally sentient can also help us avoid creating them inadvertently, or at least, realize that we have created them in a timely manner.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Engineering Sentienceï¼Œå¹¶ä¸ºå…¶åœ¨æœºå™¨è®¾è®¡ä¸æ„å»ºä¸­çš„åº”ç”¨æä¾›äº†ä¸€ä¸ªå®ç”¨çš„å®šä¹‰ã€‚ä½œè€…æå‡ºï¼Œä¸ºäº†ä½¿AIçš„æ„ŸçŸ¥å…·æœ‰å®é™…æ„ä¹‰ï¼Œå¿…é¡»å°†å…¶ç»†åŒ–ä¸ºåŠŸèƒ½æ€§å’Œè®¡ç®—æ€§çš„æœ¯è¯­ï¼Œä»è€Œè¾¾åˆ°å¯å®æ–½çš„æ·±åº¦ã€‚è¿™ä¸€æ¦‚å¿µå¼ºè°ƒæ„ŸçŸ¥å¿…é¡»è¶…è¶Šå•çº¯çš„çŸ¥è§‰å†…å®¹ç¼–ç èƒ½åŠ›ï¼Œä½“ç°å‡ºæœ¬è´¨ä¸Šçš„subjectiveç‰¹æ€§ã€‚ä¸ºäº†å®ç°è¿™ç§ç‰¹å®šçš„åŠŸèƒ½æ€§æ„ŸçŸ¥ï¼Œç ”ç©¶æè®®æ„Ÿå®˜ä¿¡å·éœ€åŒæ—¶å…·å¤‡assertoricï¼ˆæŒç»­æ€§ï¼‰ä¸qualitativeï¼ˆå®šæ€§ï¼‰çš„ç‰¹å¾ã€‚è¯¥è®ºæ–‡ç»“åˆå½“å‰æŠ€æœ¯å‹¾å‹’äº†æ½œåœ¨çš„å®ç°è·¯å¾„ï¼Œæ—¨åœ¨æä¾›æ›´å…·ä½“çš„å·¥ç¨‹åŒ–è§†è§’ã€‚ç†è§£äººå·¥æ™ºèƒ½å¦‚ä½•å…·å¤‡åŠŸèƒ½æ€§æ„ŸçŸ¥ï¼Œä¸ä»…æœ‰åŠ©äºé¿å…æ— æ„ä¸­åˆ›å»ºæ­¤ç±»æ™ºèƒ½ï¼Œä¹Ÿèƒ½ç¡®ä¿åœ¨åˆ›å»ºæˆåŠŸæ—¶èƒ½å¤ŸåŠæ—¶è¯†åˆ«ã€‚",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20504v1",
      "published_date": "2025-06-25 14:49:50 UTC",
      "updated_date": "2025-06-25 14:49:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:27:58.454031+00:00"
    },
    {
      "arxiv_id": "2506.20495v5",
      "title": "ReCode: Updating Code API Knowledge with Reinforcement Learning",
      "title_zh": "ReCodeï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„ä»£ç  API çŸ¥è¯†æ›´æ–°",
      "authors": [
        "Haoze Wu",
        "Yunzhi Yao",
        "Wenhao Yu",
        "Ningyu Zhang"
      ],
      "abstract": "Large Language Models (LLMs) exhibit remarkable code generation capabilities but falter when adapting to frequent updates in external library APIs. This critical limitation, stemming from reliance on outdated API knowledge from their training data, even with access to current documentation, impedes reliable code generation in dynamic environments. To tackle this issue, we propose ReCode (rule-based Reinforcement learning for Code Update), a novel framework that mimics human programmer adaptation to API changes. Specifically, we construct a dataset of approximately 2,000 data entries to train the LLMs to perform version migration based on updated information. Then, we introduce a modified string similarity metric for code evaluation as the reward for reinforcement learning. Our experiments demonstrate that ReCode substantially boosts LLMs' code generation performance in dynamic API scenarios, especially on the unseen CodeUpdateArena task. Crucially, compared to supervised fine-tuning, ReCode has less impact on LLMs' general code generation abilities. We apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and DAPO), all achieving consistent improvements. Notably, after training, Qwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned model and the reasoning model with the same architecture. Code is available at https://github.com/zjunlp/ReCode.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é¢å¯¹å¤–éƒ¨åº“ API é¢‘ç¹æ›´æ–°æ—¶å› ä¾èµ–è¿‡æ—¶è®­ç»ƒçŸ¥è¯†è€Œè¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º ReCode çš„è§„åˆ™é©±åŠ¨å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚ReCode é€šè¿‡æ„å»ºåŒ…å«çº¦ 2,000 æ¡æ¡ç›®çš„ç‰ˆæœ¬è¿ç§»æ•°æ®é›†æ¥æ¨¡æ‹Ÿç¨‹åºå‘˜çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶é‡‡ç”¨æ”¹è¿›çš„ä»£ç å­—ç¬¦ä¸²ç›¸ä¼¼åº¦æŒ‡æ ‡ä½œä¸ºå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰çš„å¥–åŠ±æœºåˆ¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒReCode åœ¨åŠ¨æ€ API åœºæ™¯ï¼ˆå¦‚ CodeUpdateArena ä»»åŠ¡ï¼‰ä¸­æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œä¸”ç›¸æ¯”ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å¯¹æ¨¡å‹é€šç”¨ç¼–ç¨‹èƒ½åŠ›çš„å½±å“æ›´å°ã€‚è¯¥æ¡†æ¶åœ¨å¤šç§ LLMs åŠ GRPOã€DAPO ç­‰ç®—æ³•ä¸Šå‡å–å¾—äº†ä¸€è‡´çš„æ€§èƒ½æå‡ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œç»è¿‡ ReCode è®­ç»ƒåçš„ Qwen2.5-Coder-7B åœ¨ç›¸å…³ä»»åŠ¡ä¸Šçš„è¡¨ç°ç”šè‡³è¶…è¶Šäº† 32B è§„æ¨¡çš„æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ï¼Œä¸ºå¤§æ¨¡å‹åœ¨åŠ¨æ€è½¯ä»¶å¼€å‘ç¯å¢ƒä¸­çš„çŸ¥è¯†å®æ—¶æ›´æ–°æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2506.20495v5",
      "published_date": "2025-06-25 14:41:13 UTC",
      "updated_date": "2025-11-23 10:24:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:28:03.516902+00:00"
    },
    {
      "arxiv_id": "2506.20486v1",
      "title": "Mixtures of Neural Cellular Automata: A Stochastic Framework for Growth Modelling and Self-Organization",
      "title_zh": "æ··åˆç¥ç»å…ƒèƒè‡ªåŠ¨æœºï¼šç”¨äºç”Ÿé•¿å»ºæ¨¡ä¸è‡ªç»„ç»‡çš„éšæœºæ¡†æ¶",
      "authors": [
        "Salvatore Milite",
        "Giulio Caravagna",
        "Andrea Sottoriva"
      ],
      "abstract": "Neural Cellular Automata (NCAs) are a promising new approach to model self-organizing processes, with potential applications in life science. However, their deterministic nature limits their ability to capture the stochasticity of real-world biological and physical systems.\n  We propose the Mixture of Neural Cellular Automata (MNCA), a novel framework incorporating the idea of mixture models into the NCA paradigm. By combining probabilistic rule assignments with intrinsic noise, MNCAs can model diverse local behaviors and reproduce the stochastic dynamics observed in biological processes.\n  We evaluate the effectiveness of MNCAs in three key domains: (1) synthetic simulations of tissue growth and differentiation, (2) image morphogenesis robustness, and (3) microscopy image segmentation. Results show that MNCAs achieve superior robustness to perturbations, better recapitulate real biological growth patterns, and provide interpretable rule segmentation. These findings position MNCAs as a promising tool for modeling stochastic dynamical systems and studying self-growth processes.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Neural Cellular Automata (NCAs) ä¼ ç»Ÿçš„ç¡®å®šæ€§å±æ€§é™åˆ¶äº†å…¶æ•æ‰ç”Ÿç‰©å’Œç‰©ç†ç³»ç»Ÿéšæœºæ€§è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº† Mixture of Neural Cellular Automata (MNCA) æ¡†æ¶ã€‚MNCA åˆ›æ–°æ€§åœ°å°†æ··åˆæ¨¡å‹(mixture models)å¼•å…¥ NCA èŒƒå¼ï¼Œé€šè¿‡ç»“åˆæ¦‚ç‡è§„åˆ™åˆ†é…å’Œå†…åœ¨å™ªå£°æ¥æ¨¡æ‹Ÿå¤šæ ·åŒ–çš„å±€éƒ¨è¡Œä¸ºã€‚è¯¥æ¡†æ¶åœ¨ç»„ç»‡ç”Ÿé•¿ä¸åˆ†åŒ–æ¨¡æ‹Ÿã€å›¾åƒå½¢æ€å‘ç”Ÿ(morphogenesis)é²æ£’æ€§ä»¥åŠæ˜¾å¾®å›¾åƒåˆ†å‰²ä¸‰ä¸ªå…³é”®é¢†åŸŸè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMNCA åœ¨åº”å¯¹æ‰°åŠ¨æ—¶å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ï¼Œèƒ½æ›´å¥½åœ°æ¨¡æ‹ŸçœŸå®çš„ç”Ÿç‰©ç”Ÿé•¿æ¨¡å¼ï¼Œå¹¶æä¾›äº†å…·æœ‰è§£é‡Šæ€§çš„è§„åˆ™åˆ†å‰²ã€‚è¿™äº›å‘ç°è¡¨æ˜ MNCA æ˜¯ç ”ç©¶éšæœºåŠ¨åŠ›ç³»ç»Ÿå’Œè‡ªæˆ‘ç”Ÿé•¿(self-growth)è¿‡ç¨‹çš„æœ‰åŠ›å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20486v1",
      "published_date": "2025-06-25 14:33:35 UTC",
      "updated_date": "2025-06-25 14:33:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:28:44.344578+00:00"
    },
    {
      "arxiv_id": "2506.20481v1",
      "title": "Counterfactual Influence as a Distributional Quantity",
      "title_zh": "å°†åäº‹å®å½±å“è§†ä¸ºåˆ†å¸ƒé‡",
      "authors": [
        "Matthieu Meeus",
        "Igor Shilov",
        "Georgios Kaissis",
        "Yves-Alexandre de Montjoye"
      ],
      "abstract": "Machine learning models are known to memorize samples from their training data, raising concerns around privacy and generalization. Counterfactual self-influence is a popular metric to study memorization, quantifying how the model's prediction for a sample changes depending on the sample's inclusion in the training dataset. However, recent work has shown memorization to be affected by factors beyond self-influence, with other training samples, in particular (near-)duplicates, having a large impact. We here study memorization treating counterfactual influence as a distributional quantity, taking into account how all training samples influence how a sample is memorized. For a small language model, we compute the full influence distribution of training samples on each other and analyze its properties. We find that solely looking at self-influence can severely underestimate tangible risks associated with memorization: the presence of (near-)duplicates seriously reduces self-influence, while we find these samples to be (near-)extractable. We observe similar patterns for image classification, where simply looking at the influence distributions reveals the presence of near-duplicates in CIFAR-10. Our findings highlight that memorization stems from complex interactions across training data and is better captured by the full influence distribution than by self-influence alone.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœºå™¨å­¦ä¹ æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®çš„è®°å¿†(Memorization)ç°è±¡ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„åäº‹å®è‡ªæˆ‘å½±å“(Counterfactual self-influence)æŒ‡æ ‡å› å¿½ç•¥æ ·æœ¬é—´äº¤äº’è€Œå­˜åœ¨å±€é™ã€‚ç ”ç©¶è€…æå‡ºå°†åäº‹å®å½±å“(Counterfactual influence)è§†ä¸ºä¸€ç§åˆ†å¸ƒç‰¹å¾ï¼Œé€šè¿‡åˆ†ææ‰€æœ‰è®­ç»ƒæ ·æœ¬å¯¹ç‰¹å®šæ ·æœ¬è®°å¿†è¿‡ç¨‹çš„å®Œæ•´å½±å“åˆ†å¸ƒ(Influence distribution)æ¥å¼€å±•ç ”ç©¶ã€‚é€šè¿‡å¯¹å°å‹è¯­è¨€æ¨¡å‹çš„åˆ†æå‘ç°ï¼Œå•çº¯ä¾èµ–è‡ªæˆ‘å½±å“ä¼šä¸¥é‡ä½ä¼°è®°å¿†å¸¦æ¥çš„é£é™©ï¼Œå°¤å…¶æ˜¯è¿‘é‡å¤(Near-duplicates)æ ·æœ¬çš„å­˜åœ¨ä¼šé™ä½è‡ªæˆ‘å½±å“å¾—åˆ†ï¼Œä½†æ­¤ç±»æ ·æœ¬åè€Œææ˜“è¢«æå–ã€‚åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•ä¹ŸæˆåŠŸæ­ç¤ºäº†CIFAR-10æ•°æ®é›†ä¸­éšè—çš„è¿‘é‡å¤æ ·æœ¬ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹è®°å¿†æºäºè®­ç»ƒæ•°æ®é—´å¤æ‚çš„äº¤äº’ä½œç”¨ï¼Œé‡‡ç”¨å®Œæ•´çš„åˆ†å¸ƒè§†è§’æ¯”å•ä¸€æŒ‡æ ‡èƒ½æ›´å‡†ç¡®åœ°æ•æ‰è®°å¿†ç‰¹å¾ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Workshop on The Impact of Memorization on Trustworthy Foundation Models (MemFM) @ ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.20481v1",
      "published_date": "2025-06-25 14:25:11 UTC",
      "updated_date": "2025-06-25 14:25:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:28:12.890187+00:00"
    },
    {
      "arxiv_id": "2506.20451v1",
      "title": "Automatic Demonstration Selection for LLM-based Tabular Data Classification",
      "title_zh": "é¢å‘åŸºäº LLM çš„è¡¨æ ¼æ•°æ®åˆ†ç±»çš„è‡ªåŠ¨ç¤ºä¾‹é€‰æ‹©",
      "authors": [
        "Shuchu Han",
        "Wolfgang Bruckner"
      ],
      "abstract": "A fundamental question in applying In-Context Learning (ICL) for tabular data classification is how to determine the ideal number of demonstrations in the prompt. This work addresses this challenge by presenting an algorithm to automatically select a reasonable number of required demonstrations. Our method distinguishes itself by integrating not only the tabular data's distribution but also the user's selected prompt template and the specific Large Language Model (LLM) into its estimation. Rooted in Spectral Graph Theory, our proposed algorithm defines a novel metric to quantify the similarities between different demonstrations. We then construct a similarity graph and analyze the eigenvalues of its Laplacian to derive the minimum number of demonstrations capable of representing the data within the LLM's intrinsic representation space. We validate the efficacy of our approach through experiments comparing its performance against conventional random selection algorithms on diverse datasets and LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨è¡¨æ ¼æ•°æ®åˆ†ç±»ä¸­åº”ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ (In-Context Learning, ICL)æ—¶å¦‚ä½•ç¡®å®šç†æƒ³ç¤ºä¾‹(demonstrations)æ•°é‡çš„æ ¸å¿ƒé—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§è‡ªåŠ¨é€‰æ‹©åˆç†ç¤ºä¾‹è§„æ¨¡çš„ç®—æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡æ•´åˆè¡¨æ ¼æ•°æ®åˆ†å¸ƒã€æç¤ºæ¨¡æ¿(prompt template)ä»¥åŠç‰¹å®šçš„å¤§è¯­è¨€æ¨¡å‹(LLM)ç‰¹å¾è¿›è¡Œä¼°ç®—ï¼Œå…·æœ‰æ˜¾è‘—çš„ç»¼åˆæ€§ã€‚ç®—æ³•åŸºäºè°±å›¾ç†è®º(Spectral Graph Theory)å®šä¹‰äº†é‡åŒ–ç¤ºä¾‹é—´ç›¸ä¼¼æ€§çš„æ–°åº¦é‡æŒ‡æ ‡ï¼Œå¹¶æ„å»ºç›¸ä¼¼åº¦å›¾è¿›è¡Œæ·±å…¥åˆ†æã€‚é€šè¿‡ç ”ç©¶æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ(Laplacian)çš„ç‰¹å¾å€¼ï¼Œè¯¥ç®—æ³•èƒ½å¤Ÿæ¨å¯¼å‡ºåœ¨æ¨¡å‹å†…åœ¨è¡¨å¾ç©ºé—´ä¸­ä»£è¡¨æ•°æ®æ‰€éœ€çš„æœ€å°ç¤ºä¾‹æ•°é‡ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§æ•°æ®é›†å’Œæ¨¡å‹ä¸Šçš„è¡¨ç°å‡ä¼˜äºä¼ ç»Ÿçš„éšæœºé€‰æ‹©ç®—æ³•ï¼Œæœ‰æ•ˆæå‡äº†åˆ†ç±»ä»»åŠ¡çš„æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20451v1",
      "published_date": "2025-06-25 13:57:54 UTC",
      "updated_date": "2025-06-25 13:57:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:28:13.030049+00:00"
    },
    {
      "arxiv_id": "2506.21635v1",
      "title": "AeroLite-MDNet: Lightweight Multi-task Deviation Detection Network for UAV Landing",
      "title_zh": "AeroLite-MDNetï¼šé¢å‘æ— äººæœºç€é™†çš„è½»é‡çº§å¤šä»»åŠ¡åå·®æ£€æµ‹ç½‘ç»œ",
      "authors": [
        "Haiping Yang",
        "Huaxing Liu",
        "Wei Wu",
        "Zuohui Chen",
        "Ning Wu"
      ],
      "abstract": "Unmanned aerial vehicles (UAVs) are increasingly employed in diverse applications such as land surveying, material transport, and environmental monitoring. Following missions like data collection or inspection, UAVs must land safely at docking stations for storage or recharging, which is an essential requirement for ensuring operational continuity. However, accurate landing remains challenging due to factors like GPS signal interference. To address this issue, we propose a deviation warning system for UAV landings, powered by a novel vision-based model called AeroLite-MDNet. This model integrates a multiscale fusion module for robust cross-scale object detection and incorporates a segmentation branch for efficient orientation estimation. We introduce a new evaluation metric, Average Warning Delay (AWD), to quantify the system's sensitivity to landing deviations. Furthermore, we contribute a new dataset, UAVLandData, which captures real-world landing deviation scenarios to support training and evaluation. Experimental results show that our system achieves an AWD of 0.7 seconds with a deviation detection accuracy of 98.6\\%, demonstrating its effectiveness in enhancing UAV landing reliability. Code will be available at https://github.com/ITTTTTI/Maskyolo.git",
      "tldr_zh": "é’ˆå¯¹æ— äººæœº(UAVs)åœ¨GPSä¿¡å·å¹²æ‰°ç­‰å¤æ‚ç¯å¢ƒä¸‹éš¾ä»¥ç²¾ç¡®é™è½è‡³åœé ç«™çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºAeroLite-MDNetçš„è½»é‡åŒ–è§†è§‰åå·®é¢„è­¦æ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡é›†æˆå¤šå°ºåº¦èåˆæ¨¡å—(multiscale fusion module)å¢å¼ºè·¨å°ºåº¦ç›®æ ‡æ£€æµ‹çš„é²æ£’æ€§ï¼Œå¹¶åˆ©ç”¨åˆ†å‰²åˆ†æ”¯(segmentation branch)å®ç°é«˜æ•ˆçš„æ–¹å‘ä¼°è®¡(orientation estimation)ã€‚ä¸ºäº†é‡åŒ–ç³»ç»Ÿå¯¹é™è½åå·®çš„æ•æ„Ÿåº¦ï¼Œç ”ç©¶è€…å¼•å…¥äº†å¹³å‡é¢„è­¦å»¶è¿Ÿ(Average Warning Delay, AWD)è¿™ä¸€æ–°æŒ‡æ ‡ï¼Œå¹¶è´¡çŒ®äº†åŒ…å«çœŸå®é™è½åå·®åœºæ™¯çš„æ•°æ®é›†UAVLandDataã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿå®ç°äº†98.6%çš„åå·®æ£€æµ‹å‡†ç¡®ç‡ï¼Œä¸”AWDä»…ä¸º0.7ç§’ï¼Œåœ¨æ˜¾è‘—æå‡æ— äººæœºé™è½å¯é æ€§çš„åŒæ—¶ç¡®ä¿äº†ä½œä¸šçš„æŒç»­æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.21635v1",
      "published_date": "2025-06-25 13:48:30 UTC",
      "updated_date": "2025-06-25 13:48:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:28:17.338186+00:00"
    },
    {
      "arxiv_id": "2506.20430v2",
      "title": "An Agentic System for Rare Disease Diagnosis with Traceable Reasoning",
      "title_zh": "å…·å¤‡å¯è¿½æº¯æ¨ç†èƒ½åŠ›çš„ç½•è§ç—…è¯Šæ–­æ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Weike Zhao",
        "Chaoyi Wu",
        "Yanjie Fan",
        "Xiaoman Zhang",
        "Pengcheng Qiu",
        "Yuze Sun",
        "Xiao Zhou",
        "Yanfeng Wang",
        "Xin Sun",
        "Ya Zhang",
        "Yongguo Yu",
        "Kun Sun",
        "Weidi Xie"
      ],
      "abstract": "Rare diseases collectively affect over 300 million individuals worldwide, yet timely and accurate diagnosis remains a pervasive challenge. This is largely due to their clinical heterogeneity, low individual prevalence, and the limited familiarity most clinicians have with rare conditions. Here, we introduce DeepRare, the first rare disease diagnosis agentic system powered by a large language model (LLM), capable of processing heterogeneous clinical inputs. The system generates ranked diagnostic hypotheses for rare diseases, each accompanied by a transparent chain of reasoning that links intermediate analytic steps to verifiable medical evidence.\n  DeepRare comprises three key components: a central host with a long-term memory module; specialized agent servers responsible for domain-specific analytical tasks integrating over 40 specialized tools and web-scale, up-to-date medical knowledge sources, ensuring access to the most current clinical information. This modular and scalable design enables complex diagnostic reasoning while maintaining traceability and adaptability. We evaluate DeepRare on eight datasets. The system demonstrates exceptional diagnostic performance among 2,919 diseases, achieving 100% accuracy for 1013 diseases. In HPO-based evaluations, DeepRare significantly outperforms other 15 methods, like traditional bioinformatics diagnostic tools, LLMs, and other agentic systems, achieving an average Recall@1 score of 57.18% and surpassing the second-best method (Reasoning LLM) by a substantial margin of 23.79 percentage points. For multi-modal input scenarios, DeepRare achieves 70.60% at Recall@1 compared to Exomiser's 53.20% in 109 cases. Manual verification of reasoning chains by clinical experts achieves 95.40% agreements. Furthermore, the DeepRare system has been implemented as a user-friendly web application http://raredx.cn/doctor.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†DeepRareï¼Œè¿™æ˜¯é¦–ä¸ªç”±å¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨ã€èƒ½å¤Ÿå¤„ç†å¼‚æ„ä¸´åºŠè¾“å…¥çš„ç½•è§ç—…è¯Šæ–­æ™ºèƒ½ä½“ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿç”±å¸¦æœ‰é•¿æœŸè®°å¿†æ¨¡å—çš„ä¸­å¤®ä¸»æ§ä»¥åŠè´Ÿè´£ç‰¹å®šé¢†åŸŸåˆ†æä»»åŠ¡çš„ä¸“ä¸šæ™ºèƒ½ä½“æœåŠ¡å™¨ç»„æˆï¼Œé›†æˆäº†è¶…è¿‡40ç§ä¸“ä¸šå·¥å…·å’Œäº’è”ç½‘è§„æ¨¡çš„æœ€æ–°åŒ»å­¦çŸ¥è¯†åº“ã€‚DeepRareé€šè¿‡æ¨¡å—åŒ–å’Œå¯æ‰©å±•çš„è®¾è®¡å®ç°å¤æ‚çš„è¯Šæ–­æ¨ç†ï¼Œå¹¶ä¸ºæ¯é¡¹è¯Šæ–­å‡è®¾æä¾›å¯è¿½æº¯çš„æ¨ç†é“¾(Traceable Reasoning)ï¼Œå°†åˆ†ææ­¥éª¤ä¸å¯éªŒè¯çš„åŒ»å­¦è¯æ®ç›¸æŒ‚é’©ã€‚åœ¨8ä¸ªæ•°æ®é›†å’Œ2,919ç§ç–¾ç—…çš„è¯„ä¼°ä¸­ï¼ŒDeepRareçš„Recall@1å¹³å‡è¾¾åˆ°57.18%ï¼Œæ˜¾è‘—è¶…è¶Šäº†åŒ…æ‹¬ä¼ ç»Ÿç”Ÿç‰©ä¿¡æ¯å­¦å·¥å…·å’Œå…¶ä»–æ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å†…çš„15ç§æ–¹æ³•ã€‚åœ¨å¤šæ¨¡æ€è¾“å…¥åœºæ™¯ä¸‹ï¼Œå…¶è¡¨ç°ä¼˜äºExomiserç­‰ä¼ ç»Ÿå·¥å…·ï¼Œä¸”ä¸´åºŠä¸“å®¶å¯¹å…¶æ¨ç†é“¾çš„ä¸€è‡´æ€§è®¤å¯åº¦é«˜è¾¾95.40%ã€‚è¯¥ç³»ç»Ÿå·²ä½œä¸ºWebåº”ç”¨ç¨‹åºæŠ•å…¥å®é™…åº”ç”¨ï¼Œä¸ºè§£å†³ç½•è§ç—…è¯Šæ–­ä¸­çš„ä¸´åºŠå¼‚è´¨æ€§å’ŒçŸ¥è¯†ç¼ºå£æä¾›äº†é«˜æ•ˆä¸”å¯ä¿¡ä»»çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20430v2",
      "published_date": "2025-06-25 13:42:26 UTC",
      "updated_date": "2025-08-26 14:13:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:29:04.455185+00:00"
    },
    {
      "arxiv_id": "2506.20417v1",
      "title": "Off-Policy Evaluation and Learning for the Future under Non-Stationarity",
      "title_zh": "éå¹³ç¨³ç¯å¢ƒä¸‹çš„æœªæ¥ç¦»çº¿ç­–ç•¥è¯„ä¼°ä¸å­¦ä¹ ",
      "authors": [
        "Tatsuhiro Shimizu",
        "Kazuki Kawamura",
        "Takanori Muroi",
        "Yusuke Narita",
        "Kei Tateno",
        "Takuma Udagawa",
        "Yuta Saito"
      ],
      "abstract": "We study the novel problem of future off-policy evaluation (F-OPE) and learning (F-OPL) for estimating and optimizing the future value of policies in non-stationary environments, where distributions vary over time. In e-commerce recommendations, for instance, our goal is often to estimate and optimize the policy value for the upcoming month using data collected by an old policy in the previous month. A critical challenge is that data related to the future environment is not observed in the historical data. Existing methods assume stationarity or depend on restrictive reward-modeling assumptions, leading to significant bias. To address these limitations, we propose a novel estimator named \\textit{\\textbf{O}ff-\\textbf{P}olicy Estimator for the \\textbf{F}uture \\textbf{V}alue (\\textbf{\\textit{OPFV}})}, designed for accurately estimating policy values at any future time point. The key feature of OPFV is its ability to leverage the useful structure within time-series data. While future data might not be present in the historical log, we can leverage, for example, seasonal, weekly, or holiday effects that are consistent in both the historical and future data. Our estimator is the first to exploit these time-related structures via a new type of importance weighting, enabling effective F-OPE. Theoretical analysis identifies the conditions under which OPFV becomes low-bias. In addition, we extend our estimator to develop a new policy-gradient method to proactively learn a good future policy using only historical data. Empirical results show that our methods substantially outperform existing methods in estimating and optimizing the future policy value under non-stationarity for various experimental setups.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†éå¹³ç¨³ç¯å¢ƒ(non-stationary environments)ä¸‹çš„æœªæ¥ç¦»ç­–è¯„ä¼°(F-OPE)å’Œå­¦ä¹ (F-OPL)é—®é¢˜ï¼Œæ—¨åœ¨åˆ©ç”¨å†å²æ•°æ®ä¼°è®¡å’Œä¼˜åŒ–æœªæ¥çš„ç­–ç•¥ä»·å€¼ã€‚é’ˆå¯¹ç”µå­å•†åŠ¡æ¨èç­‰åœºæ™¯ä¸­åˆ†å¸ƒéšæ—¶é—´å˜åŒ–çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–å¹³ç¨³æ€§å‡è®¾æˆ–ä¸¥æ ¼çš„å¥–åŠ±å»ºæ¨¡ï¼Œå®¹æ˜“äº§ç”Ÿæ˜¾è‘—åå·®ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºOPFV (Off-Policy Estimator for the Future Value) çš„æ–°å‹ä¼°è®¡å™¨ï¼Œä¸“é—¨ç”¨äºå‡†ç¡®è¯„ä¼°ä»»ä½•æœªæ¥æ—¶é—´ç‚¹çš„ç­–ç•¥ä»·å€¼ã€‚OPFVçš„æ ¸å¿ƒç‰¹å¾åœ¨äºèƒ½å¤Ÿåˆ©ç”¨æ—¶é—´åºåˆ—æ•°æ®ä¸­çš„ç»“æ„åŒ–ä¿¡æ¯ï¼Œé€šè¿‡ä¸€ç§æ–°å‹çš„é‡è¦åº¦é‡‡æ ·(importance weighting)æœºåˆ¶ï¼Œæ•è·å†å²ä¸æœªæ¥æ•°æ®ä¸­ä¸€è‡´çš„å­£èŠ‚æ€§ã€å‘¨åº¦æˆ–èŠ‚å‡æ—¥æ•ˆåº”ã€‚ç†è®ºåˆ†æç¡®å®šäº†è¯¥ä¼°è®¡å™¨å®ç°ä½åå·®(low-bias)çš„æ¡ä»¶ï¼Œç ”ç©¶è¿›ä¸€æ­¥å°†å…¶æ‰©å±•ä¸ºä¸€ç§æ–°å‹ç­–ç•¥æ¢¯åº¦(policy-gradient)æ–¹æ³•ï¼Œä»è€Œä»…å‡­å†å²æ•°æ®å³å¯ä¸»åŠ¨å­¦ä¹ æœªæ¥çš„æœ€ä¼˜ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤šç§å®éªŒè®¾ç½®ä¸‹ï¼Œæ‰€ææ–¹æ³•åœ¨éå¹³ç¨³ç¯å¢ƒä¸­çš„æœªæ¥ç­–ç•¥ä»·å€¼ä¼°è®¡å’Œä¼˜åŒ–æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20417v1",
      "published_date": "2025-06-25 13:31:46 UTC",
      "updated_date": "2025-06-25 13:31:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:30:10.823985+00:00"
    },
    {
      "arxiv_id": "2506.20415v1",
      "title": "SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models",
      "title_zh": "SV-LLMï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ SoC å®‰å…¨éªŒè¯æ™ºèƒ½ä½“æ–¹æ³•",
      "authors": [
        "Dipayan Saha",
        "Shams Tarek",
        "Hasan Al Shaikh",
        "Khan Thamid Hasan",
        "Pavan Sai Nalluri",
        "Md. Ajoad Hasan",
        "Nashmin Alam",
        "Jingbo Zhou",
        "Sujan Kumar Saha",
        "Mark Tehranipoor",
        "Farimah Farahmandi"
      ],
      "abstract": "Ensuring the security of complex system-on-chips (SoCs) designs is a critical imperative, yet traditional verification techniques struggle to keep pace due to significant challenges in automation, scalability, comprehensiveness, and adaptability. The advent of large language models (LLMs), with their remarkable capabilities in natural language understanding, code generation, and advanced reasoning, presents a new paradigm for tackling these issues. Moving beyond monolithic models, an agentic approach allows for the creation of multi-agent systems where specialized LLMs collaborate to solve complex problems more effectively. Recognizing this opportunity, we introduce SV-LLM, a novel multi-agent assistant system designed to automate and enhance SoC security verification. By integrating specialized agents for tasks like verification question answering, security asset identification, threat modeling, test plan and property generation, vulnerability detection, and simulation-based bug validation, SV-LLM streamlines the workflow. To optimize their performance in these diverse tasks, agents leverage different learning paradigms, such as in-context learning, fine-tuning, and retrieval-augmented generation (RAG). The system aims to reduce manual intervention, improve accuracy, and accelerate security analysis, supporting proactive identification and mitigation of risks early in the design cycle. We demonstrate its potential to transform hardware security practices through illustrative case studies and experiments that showcase its applicability and efficacy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SV-LLMï¼Œä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å¤šæ™ºèƒ½ä½“è¾…åŠ©ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³å¤æ‚ç³»ç»ŸèŠ¯ç‰‡(SoCs)è®¾è®¡åœ¨å®‰å…¨æ€§éªŒè¯ä¸­é¢ä¸´çš„è‡ªåŠ¨åŒ–ã€æ‰©å±•æ€§å’Œå…¨é¢æ€§æŒ‘æˆ˜ã€‚é€šè¿‡æ•´åˆä¸“é—¨ç”¨äºå®‰å…¨èµ„äº§è¯†åˆ«(Security Asset Identification)ã€å¨èƒå»ºæ¨¡(Threat Modeling)ã€æµ‹è¯•è®¡åˆ’ä¸å±æ€§ç”Ÿæˆã€æ¼æ´æ£€æµ‹åŠä»¿çœŸæ¼æ´éªŒè¯çš„æ™ºèƒ½ä½“ï¼ŒSV-LLMå®ç°äº†éªŒè¯å·¥ä½œæµçš„è‡ªåŠ¨åŒ–ä¸ä¼˜åŒ–ã€‚ä¸ºäº†æå‡åœ¨å¤šæ ·åŒ–ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œç³»ç»Ÿé‡‡ç”¨äº†æƒ…å¢ƒå­¦ä¹ (In-context Learning)ã€å¾®è°ƒ(Fine-tuning)å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç­‰å¤šç§å­¦ä¹ èŒƒå¼ã€‚è¯¥ç³»ç»Ÿæ˜¾è‘—å‡å°‘äº†äººå·¥å¹²é¢„å¹¶åŠ é€Ÿäº†å®‰å…¨åˆ†æè¿‡ç¨‹ï¼Œæ”¯æŒåœ¨è®¾è®¡å‘¨æœŸæ—©æœŸä¸»åŠ¨è¯†åˆ«å’Œç¼“è§£ç¡¬ä»¶é£é™©ã€‚å®éªŒå’Œæ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼ŒSV-LLMåœ¨æé«˜éªŒè¯å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢å…·æœ‰æ˜¾è‘—æ½œåŠ›ï¼Œä¸ºç¡¬ä»¶å®‰å…¨å®è·µçš„èŒƒå¼è½¬å˜å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20415v1",
      "published_date": "2025-06-25 13:31:13 UTC",
      "updated_date": "2025-06-25 13:31:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:29:11.310755+00:00"
    },
    {
      "arxiv_id": "2506.20413v2",
      "title": "Client Clustering Meets Knowledge Sharing: Enhancing Privacy and Robustness in Personalized Peer-to-Peer Learning",
      "title_zh": "å®¢æˆ·ç«¯èšç±»ä¸çŸ¥è¯†å…±äº«ï¼šæå‡ä¸ªæ€§åŒ–ç‚¹å¯¹ç‚¹å­¦ä¹ ä¸­çš„éšç§æ€§ä¸é²æ£’æ€§",
      "authors": [
        "Mohammad Mahdi Maheri",
        "Denys Herasymuk",
        "Hamed Haddadi"
      ],
      "abstract": "The growing adoption of Artificial Intelligence (AI) in Internet of Things (IoT) ecosystems has intensified the need for personalized learning methods that can operate efficiently and privately across heterogeneous, resource-constrained devices. However, enabling effective personalized learning in decentralized settings introduces several challenges, including efficient knowledge transfer between clients, protection of data privacy, and resilience against poisoning attacks. In this paper, we address these challenges by developing P4 (Personalized, Private, Peer-to-Peer) -- a method designed to deliver personalized models for resource-constrained IoT devices while ensuring differential privacy and robustness against poisoning attacks. Our solution employs a lightweight, fully decentralized algorithm to privately detect client similarity and form collaborative groups. Within each group, clients leverage differentially private knowledge distillation to co-train their models, maintaining high accuracy while ensuring robustness to the presence of malicious clients. We evaluate P4 on popular benchmark datasets using both linear and CNN-based architectures across various heterogeneity settings and attack scenarios. Experimental results show that P4 achieves 5% to 30% higher accuracy than leading differentially private peer-to-peer approaches and maintains robustness with up to 30% malicious clients. Additionally, we demonstrate its practicality by deploying it on resource-constrained devices, where collaborative training between two clients adds only ~7 seconds of overhead.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç‰©è”ç½‘(IoT)ç”Ÿæ€ç³»ç»Ÿä¸­å¼‚æ„èµ„æºå—é™è®¾å¤‡å¯¹ä¸ªæ€§åŒ–å­¦ä¹ çš„éœ€æ±‚ï¼Œæå‡ºäº†åä¸ºP4(Personalized, Private, Peer-to-Peer)çš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å»ä¸­å¿ƒåŒ–ç¯å¢ƒä¸‹çš„çŸ¥è¯†ä¼ è¾“ã€æ•°æ®éšç§å’Œä¸­æ¯’æ”»å‡»(poisoning attacks)ç­‰æ ¸å¿ƒæŒ‘æˆ˜ã€‚è¯¥æ–¹æ¡ˆé‡‡ç”¨è½»é‡çº§çš„å®Œå…¨å»ä¸­å¿ƒåŒ–ç®—æ³•ï¼Œåœ¨ä¿æŠ¤éšç§çš„å‰æä¸‹æ£€æµ‹å®¢æˆ·ç«¯ç›¸ä¼¼æ€§å¹¶è‡ªåŠ¨æ„å»ºåä½œç»„ã€‚ç»„å†…å®¢æˆ·ç«¯é€šè¿‡å·®åˆ†éšç§çŸ¥è¯†è’¸é¦(differentially private knowledge distillation)æŠ€æœ¯è¿›è¡ŒååŒè®­ç»ƒï¼Œæ—¢æå‡äº†æ¨¡å‹å‡†ç¡®ç‡ï¼Œåˆå¢å¼ºäº†å¯¹æ¶æ„æ”»å‡»çš„é²æ£’æ€§ã€‚åœ¨å¤šç§åŸºå‡†æ•°æ®é›†å’Œæ¨¡å‹æ¶æ„ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒP4çš„å‡†ç¡®ç‡æ¯”é¢†å…ˆçš„å·®åˆ†éšç§å¯¹ç­‰å­¦ä¹ æ–¹æ³•é«˜å‡º5%è‡³30%ï¼Œä¸”åœ¨æ¶æ„å®¢æˆ·ç«¯æ¯”ä¾‹è¾¾30%çš„æƒ…å†µä¸‹ä»èƒ½ç»´æŒç¨³å®šæ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨å®é™…èµ„æºå—é™è®¾å¤‡ä¸Šçš„éƒ¨ç½²æµ‹è¯•æ˜¾ç¤ºï¼Œå®¢æˆ·ç«¯é—´çš„åä½œè®­ç»ƒä»…å¢åŠ çº¦7ç§’çš„é¢å¤–å¼€é”€ï¼Œå……åˆ†éªŒè¯äº†å…¶åœ¨ç°å®ç‰©è”ç½‘åœºæ™¯ä¸­çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted for publication at the IEEE Annual Congress on Artificial Intelligence of Things (IEEE AIoT) 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.20413v2",
      "published_date": "2025-06-25 13:27:36 UTC",
      "updated_date": "2025-10-20 09:11:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:29:19.792645+00:00"
    },
    {
      "arxiv_id": "2506.20404v1",
      "title": "GymPN: A Library for Decision-Making in Process Management Systems",
      "title_zh": "GymPNï¼šç”¨äºæµç¨‹ç®¡ç†ç³»ç»Ÿå†³ç­–çš„åº“",
      "authors": [
        "Riccardo Lo Bianco",
        "Willem van Jaarsveld",
        "Remco Dijkman"
      ],
      "abstract": "Process management systems support key decisions about the way work is allocated in organizations. This includes decisions on which task to perform next, when to execute the task, and who to assign the task to. Suitable software tools are required to support these decisions in a way that is optimal for the organization. This paper presents a software library, called GymPN, that supports optimal decision-making in business processes using Deep Reinforcement Learning. GymPN builds on previous work that supports task assignment in business processes, introducing two key novelties: support for partial process observability and the ability to model multiple decisions in a business process. These novel elements address fundamental limitations of previous work and thus enable the representation of more realistic process decisions. We evaluate the library on eight typical business process decision-making problem patterns, showing that GymPN allows for easy modeling of the desired problems, as well as learning optimal decision policies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†GymPNï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning)æ”¯æŒä¸šåŠ¡æµç¨‹ä¸­ä¼˜åŒ–å†³ç­–çš„è½¯ä»¶åº“ã€‚GymPNåœ¨ç°æœ‰ä»»åŠ¡åˆ†é…ç ”ç©¶çš„åŸºç¡€ä¸Šï¼Œå¼•å…¥äº†å¯¹æµç¨‹éƒ¨åˆ†å¯è§‚æµ‹æ€§(partial process observability)çš„æ”¯æŒï¼Œå¹¶å…·å¤‡åœ¨ä¸€ä¸ªä¸šåŠ¡æµç¨‹ä¸­å»ºæ¨¡å¤šé¡¹å†³ç­–çš„èƒ½åŠ›ã€‚è¿™äº›æ ¸å¿ƒåˆ›æ–°ç‚¹è§£å†³äº†ä»¥å¾€å·¥ä½œçš„å±€é™æ€§ï¼Œä½¿å¾—è¯¥åº“èƒ½å¤Ÿè¡¨ç¤ºå¹¶å¤„ç†æ›´ä¸ºçœŸå®çš„æµç¨‹å†³ç­–åœºæ™¯ã€‚ç ”ç©¶äººå‘˜åœ¨å…«ç§å…¸å‹çš„ä¸šåŠ¡æµç¨‹å†³ç­–é—®é¢˜æ¨¡å¼ä¸Šå¯¹è¯¥åº“è¿›è¡Œäº†è¯„ä¼°ï¼Œè¯æ˜äº†GymPNåœ¨å¤æ‚é—®é¢˜å»ºæ¨¡æ–¹é¢çš„ä¾¿æ·æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºè¯¥åº“èƒ½å¤ŸæˆåŠŸå­¦ä¹ åˆ°æœ€ä¼˜å†³ç­–ç­–ç•¥ï¼Œä¸ºç»„ç»‡åœ¨ä»»åŠ¡åˆ†é…ã€æ‰§è¡Œæ—¶æœºåŠäººå‘˜æŒ‡æ´¾ç­‰å…³é”®ç®¡ç†å†³ç­–ä¸Šæä¾›äº†é«˜æ•ˆçš„è‡ªåŠ¨åŒ–æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20404v1",
      "published_date": "2025-06-25 13:19:42 UTC",
      "updated_date": "2025-06-25 13:19:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:29:18.659580+00:00"
    },
    {
      "arxiv_id": "2506.20401v2",
      "title": "Smart Ride and Delivery Services with Electric Vehicles: Leveraging Bidirectional Charging for Profit Optimisation",
      "title_zh": "åŸºäºç”µåŠ¨æ±½è½¦çš„æ™ºèƒ½å‡ºè¡Œä¸é…é€æœåŠ¡ï¼šåˆ©ç”¨åŒå‘å……ç”µå®ç°åˆ©æ¶¦ä¼˜åŒ–",
      "authors": [
        "Jinchun Du",
        "Bojie Shen",
        "Muhammad Aamir Cheema",
        "Adel N. Toosi"
      ],
      "abstract": "With the rising popularity of electric vehicles (EVs), modern service systems, such as ride-hailing delivery services, are increasingly integrating EVs into their operations. Unlike conventional vehicles, EVs often have a shorter driving range, necessitating careful consideration of charging when fulfilling requests. With recent advances in Vehicle-to-Grid (V2G) technology - allowing EVs to also discharge energy back to the grid - new opportunities and complexities emerge. We introduce the Electric Vehicle Orienteering Problem with V2G (EVOP-V2G): a profit-maximization problem where EV drivers must select customer requests or orders while managing when and where to charge or discharge. This involves navigating dynamic electricity prices, charging station selection, and route constraints. We formulate the problem as a Mixed Integer Programming (MIP) model and propose two near-optimal metaheuristic algorithms: one evolutionary (EA) and the other based on large neighborhood search (LNS). Experiments on real-world data show our methods can double driver profits compared to baselines, while maintaining near-optimal performance on small instances and excellent scalability on larger ones. Our work highlights a promising path toward smarter, more profitable EV-based mobility systems that actively support the energy grid.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é›†æˆäº†ç”µåŠ¨æ±½è½¦(Electric Vehicles, EVs)çš„ç°ä»£ç½‘çº¦è½¦å’Œé…é€æœåŠ¡ç³»ç»Ÿï¼Œæ¢è®¨äº†å¦‚ä½•åœ¨æœ‰é™ç»­èˆªèƒ½åŠ›ä¸‹é€šè¿‡å……æ”¾ç”µç®¡ç†ä¼˜åŒ–åˆ©æ¶¦ã€‚éšç€åŒå‘å……ç”µ(Vehicle-to-Grid, V2G)æŠ€æœ¯çš„å‘å±•ï¼Œæœ¬æ–‡æå‡ºäº†å¸¦æœ‰V2GåŠŸèƒ½çš„ç”µåŠ¨æ±½è½¦å®šå‘é—®é¢˜(EVOP-V2G)ï¼Œæ—¨åœ¨é€šè¿‡é€‰æ‹©å®¢æˆ·è¯·æ±‚åŠç®¡ç†å……æ”¾ç”µæ—¶æœºæ¥æœ€å¤§åŒ–å¸æœºçš„åˆ©æ¶¦ã€‚ç ”ç©¶å°†è¯¥é—®é¢˜æ„å»ºä¸ºæ··åˆæ•´æ•°ç¼–ç¨‹(Mixed Integer Programming, MIP)æ¨¡å‹ï¼Œå¹¶è€ƒè™‘äº†åŠ¨æ€ç”µä»·ã€å……ç”µç«™é€‰æ‹©å’Œè·¯å¾„çº¦æŸç­‰å¤æ‚å› ç´ ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†æ¼”åŒ–ç®—æ³•(Evolutionary Algorithm, EA)å’ŒåŸºäºå¤§è§„æ¨¡é‚»åŸŸæœç´¢(Large Neighborhood Search, LNS)çš„ä¸¤ç§å…ƒå¯å‘å¼ç®—æ³•ã€‚åœ¨çœŸå®ä¸–ç•Œæ•°æ®ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¿™äº›æ–¹æ³•ç›¸æ¯”åŸºçº¿æ¨¡å‹èƒ½ä½¿å¸æœºåˆ©æ¶¦ç¿»å€ï¼Œå¹¶åœ¨å¤§è§„æ¨¡å®ä¾‹ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„å¯æ‰©å±•æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºå¼€å‘æ›´æ™ºèƒ½ã€æ›´å…·ç›ˆåˆ©èƒ½åŠ›ä¸”èƒ½ä¸»åŠ¨æ”¯æŒèƒ½æºç”µç½‘çš„ç”µåŠ¨æ±½è½¦ç§»åŠ¨ç³»ç»Ÿæä¾›äº†é‡è¦è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20401v2",
      "published_date": "2025-06-25 13:15:52 UTC",
      "updated_date": "2025-06-26 06:02:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:29:22.841624+00:00"
    },
    {
      "arxiv_id": "2506.20384v1",
      "title": "Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios",
      "title_zh": "Paladin-miniï¼šåœ¨ç°å®åœºæ™¯ä¸­è¡¨ç°å“è¶Šçš„ç²¾ç®€é«˜æ•ˆå‹è¯æ®æº¯æºæ¨¡å‹",
      "authors": [
        "Dror Ivry",
        "Oran Nahum"
      ],
      "abstract": "This paper introduces two significant contributions to address the issue of grounding claims in a given context. Grounding means that given a context (document) and a claim, there's at least one supportive evidence for the claim in the document. We will introduce Paladin-mini, a compact (3.8B parameters) open-source classifier model (used for labeling data as grounded or ungrounded) engineered for robust performance in real-world scenarios, and the grounding-benchmark, a new evaluation dataset designed to assess performance on critical reasoning tasks. We'll also demonstrate the results of Paladin-mini with benchmarks against the current State-of-the-art and share clear and reproducible results.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Paladin-miniï¼Œä¸€ç§ä¸“é—¨ç”¨äºè§£å†³ä¸Šä¸‹æ–‡ä¸»å¼ éªŒè¯ï¼ˆgroundingï¼‰é—®é¢˜çš„ç´§å‡‘å‹å¼€æºåˆ†ç±»å™¨æ¨¡å‹ã€‚è¯¥æ¨¡å‹ä»…æ‹¥æœ‰3.8Bå‚æ•°ï¼ˆparametersï¼‰ï¼Œæ—¨åœ¨ä¸ºçœŸå®åœºæ™¯æä¾›ç¨³å¥çš„æ€§èƒ½ï¼Œç”¨äºåˆ¤å®šç»™å®šæ–‡æ¡£ä¸­æ˜¯å¦å­˜åœ¨æ”¯æŒç‰¹å®šä¸»å¼ çš„è¯æ®ã€‚é™¤äº†æ¨¡å‹è´¡çŒ®ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†grounding-benchmarkï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºè¯„ä¼°å…³é”®æ¨ç†ä»»åŠ¡æ€§èƒ½è€Œè®¾è®¡çš„æ–°å‹è¯„ä¼°æ•°æ®é›†ã€‚é€šè¿‡ä¸å½“å‰æœ€å…ˆè¿›æ°´å¹³ï¼ˆState-of-the-artï¼‰çš„åŸºå‡†æ¨¡å‹è¿›è¡Œå¯¹æ¯”ï¼ŒPaladin-miniå±•ç¤ºäº†å“è¶Šçš„æ€§èƒ½ï¼Œå¹¶æä¾›äº†æ¸…æ™°ä¸”å¯é‡å¤çš„å®éªŒç»“æœã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.20384v1",
      "published_date": "2025-06-25 12:50:28 UTC",
      "updated_date": "2025-06-25 12:50:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:29:31.819891+00:00"
    },
    {
      "arxiv_id": "2506.20373v1",
      "title": "CARMA: Context-Aware Situational Grounding of Human-Robot Group Interactions by Combining Vision-Language Models with Object and Action Recognition",
      "title_zh": "CARMAï¼šç»“åˆè§†è§‰è¯­è¨€æ¨¡å‹ä¸ç‰©ä½“åŠåŠ¨ä½œè¯†åˆ«çš„äººæœºç¾¤ä½“äº¤äº’ä¸Šä¸‹æ–‡æ„ŸçŸ¥æƒ…å¢ƒæ¥åœ°",
      "authors": [
        "Joerg Deigmoeller",
        "Stephan Hasler",
        "Nakul Agarwal",
        "Daniel Tanneberg",
        "Anna Belardinelli",
        "Reza Ghoddoosian",
        "Chao Wang",
        "Felix Ocker",
        "Fan Zhang",
        "Behzad Dariush",
        "Michael Gienger"
      ],
      "abstract": "We introduce CARMA, a system for situational grounding in human-robot group interactions. Effective collaboration in such group settings requires situational awareness based on a consistent representation of present persons and objects coupled with an episodic abstraction of events regarding actors and manipulated objects. This calls for a clear and consistent assignment of instances, ensuring that robots correctly recognize and track actors, objects, and their interactions over time. To achieve this, CARMA uniquely identifies physical instances of such entities in the real world and organizes them into grounded triplets of actors, objects, and actions.\n  To validate our approach, we conducted three experiments, where multiple humans and a robot interact: collaborative pouring, handovers, and sorting. These scenarios allow the assessment of the system's capabilities as to role distinction, multi-actor awareness, and consistent instance identification. Our experiments demonstrate that the system can reliably generate accurate actor-action-object triplets, providing a structured and robust foundation for applications requiring spatiotemporal reasoning and situated decision-making in collaborative settings.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† CARMAï¼Œä¸€ä¸ªç”¨äºäººç±»-æœºå™¨äººç¾¤ä½“äº¤äº’ä¸­æƒ…å¢ƒåŒ–é”šå®š(situational grounding)çš„ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé€šè¿‡ç»“åˆ Vision-Language Models ä¸ç‰©ä½“å’ŒåŠ¨ä½œè¯†åˆ«æŠ€æœ¯ï¼Œå»ºç«‹äº†å¯¹ç°åœºäººå‘˜ã€ç‰©ä½“åŠç›¸å…³äº‹ä»¶çš„ä¸€è‡´æ€§è¡¨å¾ï¼Œä»¥æ»¡è¶³æœ‰æ•ˆåä½œå¯¹æƒ…å¢ƒæ„ŸçŸ¥(situational awareness)çš„è¦æ±‚ã€‚CARMA èƒ½å¤Ÿå”¯ä¸€è¯†åˆ«ç°å®ä¸–ç•Œä¸­çš„ç‰©ç†å®ä½“å®ä¾‹ï¼Œå¹¶å°†å…¶ç»„ç»‡ä¸ºç”± actorã€object å’Œ action æ„æˆçš„é”šå®šä¸‰å…ƒç»„ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡åä½œå€’æ°´(collaborative pouring)ã€äº¤æ¥(handovers)å’Œåˆ†ç±»(sorting)ä¸‰ä¸ªå…·ä½“åœºæ™¯çš„å®éªŒéªŒè¯äº†è¯¥ç³»ç»Ÿçš„å¤šä¸»ä½“æ„ŸçŸ¥å’Œå®ä¾‹è¯†åˆ«èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿå¯é åœ°ç”Ÿæˆå‡†ç¡®çš„ actor-action-object ä¸‰å…ƒç»„ï¼Œä¸ºéœ€è¦æ—¶ç©ºæ¨ç†(spatiotemporal reasoning)å’Œæƒ…å¢ƒå†³ç­–çš„åä½œåº”ç”¨æä¾›äº†ç»“æ„åŒ–ä¸”ç¨³å¥çš„æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20373v1",
      "published_date": "2025-06-25 12:36:49 UTC",
      "updated_date": "2025-06-25 12:36:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:29:35.497050+00:00"
    },
    {
      "arxiv_id": "2506.20362v1",
      "title": "Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations",
      "title_zh": "åŸºäºè°±è‡ªä¸¾ä¸æ‹‰æ™®æ‹‰æ–¯å¢å¼ºçš„è‡ªç›‘ç£å›¾å­¦ä¹ ",
      "authors": [
        "Lorenzo Bini",
        "Stephane Marchand-Maillet"
      ],
      "abstract": "We present LaplaceGNN, a novel self-supervised graph learning framework that bypasses the need for negative sampling by leveraging spectral bootstrapping techniques. Our method integrates Laplacian-based signals into the learning process, allowing the model to effectively capture rich structural representations without relying on contrastive objectives or handcrafted augmentations. By focusing on positive alignment, LaplaceGNN achieves linear scaling while offering a simpler, more efficient, self-supervised alternative for graph neural networks, applicable across diverse domains. Our contributions are twofold: we precompute spectral augmentations through max-min centrality-guided optimization, enabling rich structural supervision without relying on handcrafted augmentations, then we integrate an adversarial bootstrapped training scheme that further strengthens feature learning and robustness. Our extensive experiments on different benchmark datasets show that LaplaceGNN achieves superior performance compared to state-of-the-art self-supervised graph methods, offering a promising direction for efficiently learning expressive graph representations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LaplaceGNNï¼Œè¿™æ˜¯ä¸€ç§åˆ›æ–°çš„è‡ªç›‘ç£å›¾å­¦ä¹ (Self-supervised graph learning)æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å…‰è°±å¼•å¯¼æŠ€æœ¯(Spectral bootstrapping)æ¶ˆé™¤å¯¹è´Ÿé‡‡æ ·(Negative sampling)çš„ä¾èµ–ã€‚è¯¥æ–¹æ³•å°†åŸºäºæ‹‰æ™®æ‹‰æ–¯(Laplacian-based)çš„ä¿¡å·é›†æˆåˆ°å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸ä¾èµ–å¯¹æ¯”ç›®æ ‡æˆ–æ‰‹å·¥å¢å¼ºçš„æƒ…å†µä¸‹æœ‰æ•ˆæ•æ‰ä¸°å¯Œçš„ç»“æ„è¡¨ç¤ºã€‚é€šè¿‡ä¸“æ³¨äºæ­£å‘å¯¹é½ï¼ŒLaplaceGNNå®ç°äº†çº¿æ€§æ‰©å±•ï¼Œä¸ºå›¾ç¥ç»ç½‘ç»œæä¾›äº†ä¸€ä¸ªæ›´ç®€å•ä¸”é«˜æ•ˆçš„è‡ªç›‘ç£æ›¿ä»£æ–¹æ¡ˆã€‚ç ”ç©¶é€šè¿‡æœ€å¤§æœ€å°ä¸­å¿ƒæ€§å¼•å¯¼çš„ä¼˜åŒ–é¢„è®¡ç®—å…‰è°±å¢å¼º(Spectral augmentations)ï¼Œå®ç°äº†æ— éœ€æ‰‹å·¥å¹²é¢„çš„ä¸°å¯Œç»“æ„ç›‘ç£ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æ•´åˆäº†å¯¹æŠ—æ€§å¼•å¯¼è®­ç»ƒæ–¹æ¡ˆ(Adversarial bootstrapped training)ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†ç‰¹å¾å­¦ä¹ èƒ½åŠ›å’Œæ¨¡å‹çš„é²æ£’æ€§ã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒLaplaceGNNçš„æ€§èƒ½ä¼˜äºç°æœ‰çš„è‡ªç›‘ç£å›¾å­¦ä¹ æ–¹æ³•ï¼Œä¸ºé«˜æ•ˆå­¦ä¹ å…·æœ‰è¡¨ç°åŠ›çš„å›¾è¡¨ç¤ºæä¾›äº†ä¸€ä¸ªæå…·å‰æ™¯çš„æ–¹å‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "LaplaceGNN is a novel graph learning framework that employs a bootstrapped teacher-student architecture. Its precomputed spectral augmentations and adversarial training enable robust performance, outperforming SOTA methods while scaling linearly",
      "pdf_url": "https://arxiv.org/pdf/2506.20362v1",
      "published_date": "2025-06-25 12:23:23 UTC",
      "updated_date": "2025-06-25 12:23:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:29:35.713052+00:00"
    },
    {
      "arxiv_id": "2506.20357v1",
      "title": "Tabular Feature Discovery With Reasoning Type Exploration",
      "title_zh": "åŸºäºæ¨ç†ç±»å‹æ¢ç´¢çš„è¡¨æ ¼ç‰¹å¾å‘ç°",
      "authors": [
        "Sungwon Han",
        "Sungkyu Park",
        "Seungeon Lee"
      ],
      "abstract": "Feature engineering for tabular data remains a critical yet challenging step in machine learning. Recently, large language models (LLMs) have been used to automatically generate new features by leveraging their vast knowledge. However, existing LLM-based approaches often produce overly simple or repetitive features, partly due to inherent biases in the transformations the LLM chooses and the lack of structured reasoning guidance during generation. In this paper, we propose a novel method REFeat, which guides an LLM to discover diverse and informative features by leveraging multiple types of reasoning to steer the feature generation process. Experiments on 59 benchmark datasets demonstrate that our approach not only achieves higher predictive accuracy on average, but also discovers more diverse and meaningful features. These results highlight the promise of incorporating rich reasoning paradigms and adaptive strategy selection into LLM-driven feature discovery for tabular data.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹æœºå™¨å­¦ä¹ ä¸­è¡¨æ ¼æ•°æ®ç‰¹å¾å·¥ç¨‹(Feature Engineering)çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºå½“å‰åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„è‡ªåŠ¨åŒ–ç‰¹å¾ç”Ÿæˆæ–¹æ³•å¸¸äº§ç”Ÿç®€å•ä¸”é‡å¤çš„ç‰¹å¾ï¼Œä¸»è¦å½’å› äºæ¨¡å‹çš„å˜æ¢åå·®å’Œç¼ºä¹ç»“æ„åŒ–æ¨ç†æŒ‡å¯¼ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† REFeat æ–¹æ³•ï¼Œé€šè¿‡æ¢ç´¢å¤šç§æ¨ç†ç±»å‹(Reasoning Type Exploration)æ¥å¼•å¯¼å¤§è¯­è¨€æ¨¡å‹å‘ç°å¤šæ ·ä¸”å…·æœ‰ä¿¡æ¯é‡çš„ç‰¹å¾ã€‚è¯¥æ–¹æ³•å°†ä¸°å¯Œçš„æ¨ç†èŒƒå¼ä¸è‡ªé€‚åº”ç­–ç•¥é€‰æ‹©ç›¸ç»“åˆï¼Œæ˜¾è‘—æå‡äº†ç‰¹å¾ç”Ÿæˆçš„è´¨é‡ã€‚åœ¨ 59 ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒREFeat åœ¨å¹³å‡é¢„æµ‹å‡†ç¡®ç‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶èƒ½æŒ–æ˜å‡ºæ›´å…·æ·±åº¦å’Œå¤šæ ·æ€§çš„ç‰¹å¾ã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†åœ¨è¡¨æ ¼æ•°æ®ç‰¹å¾å‘ç°(Feature Discovery)ä¸­å¼•å…¥ç»“æ„åŒ–æ¨ç†å¼•å¯¼çš„é‡è¦æ€§ä¸æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20357v1",
      "published_date": "2025-06-25 12:18:34 UTC",
      "updated_date": "2025-06-25 12:18:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:30:39.031958+00:00"
    },
    {
      "arxiv_id": "2506.20354v2",
      "title": "A foundation model with multi-variate parallel attention to generate neuronal activity",
      "title_zh": "åŸºäºå¤šå˜é‡å¹¶è¡Œæ³¨æ„åŠ›çš„ç¥ç»æ´»åŠ¨ç”ŸæˆåŸºç¡€æ¨¡å‹",
      "authors": [
        "Francesco Carzaniga",
        "Michael Hersche",
        "Abu Sebastian",
        "Kaspar Schindler",
        "Abbas Rahimi"
      ],
      "abstract": "Learning from multi-variate time-series with heterogeneous channel configurations remains a fundamental challenge for deep neural networks, particularly in clinical domains such as intracranial electroencephalography (iEEG), where channel setups vary widely across subjects. In this work, we introduce multi-variate parallel attention (MVPA), a novel self-attention mechanism that disentangles content, temporal, and spatial attention, enabling flexible, generalizable, and efficient modeling of time-series data with varying channel counts and configurations. We use MVPA to build MVPFormer, a generative foundation model for human electrophysiology, trained to predict the evolution of iEEG signals across diverse subjects. To support this and future efforts by the community, we release the SWEC iEEG dataset, the largest publicly available iEEG dataset to date, comprising nearly 10,000 hours of recordings from heterogeneous clinical sources. MVPFormer leverages MVPA to achieve strong generalization across subjects, demonstrating expert-level performance in several iEEG tasks. MVPFormer surpasses state-of-the-art Transformer baselines in seizure detection across the SWEC, the MAYO, and the FNUSA datasets, while also achieving state-of-the-art performance on four Brain TreeBank iEEG decoding tasks. We further validate MVPA on standard time-series forecasting and classification tasks, where it matches or exceeds the performance of existing attention-based models. Together, our contributions establish MVPA as a general-purpose attention mechanism for heterogeneous time-series and MVPFormer as the first open-source, open-weights, and open-data iEEG foundation model with SOTA clinical performance. The code is available at https://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG dataset is available at https://huggingface.co/datasets/NeuroTec/SWEC_iEEG_Dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å¤šå˜é‡å¹¶è¡Œæ³¨æ„åŠ›(Multi-variate Parallel Attention, MVPA)ï¼Œæ—¨åœ¨è§£å†³æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å¤„ç†å…·æœ‰å¼‚æ„é€šé“é…ç½®çš„å¤šå˜é‡æ—¶é—´åºåˆ—(å¦‚é¢…å†…è„‘ç”µå›¾ iEEG)æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚MVPA é€šè¿‡è§£è€¦å†…å®¹ã€æ—¶é—´å’Œç©ºé—´æ³¨æ„åŠ›ï¼Œå®ç°äº†å¯¹ä¸åŒé€šé“æ•°é‡å’Œé…ç½®çš„æ—¶é—´åºåˆ—æ•°æ®è¿›è¡Œçµæ´»ã€é€šç”¨ä¸”é«˜æ•ˆçš„å»ºæ¨¡ã€‚åŸºäºè¯¥æœºåˆ¶ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº† MVPFormerï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹äººç±»ç”µç”Ÿç†å­¦çš„ç”Ÿæˆå¼åŸºç¡€æ¨¡å‹(Foundation Model)ï¼Œå¹¶åŒæ­¥å‘å¸ƒäº†åŒ…å«è¿‘ 10,000 å°æ—¶è®°å½•çš„ SWEC iEEG å…¬å¼€æ•°æ®é›†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMVPFormer åœ¨å¤šä¸ªæ•°æ®é›†çš„ç™«ç—«æ£€æµ‹ä»»åŠ¡ä¸­è¶…è¶Šäº† SOTA çš„ Transformer åŸºå‡†æ¨¡å‹ï¼Œå¹¶åœ¨å¤šé¡¹ iEEG è§£ç ä»»åŠ¡ä¸­è¡¨ç°å“è¶Šã€‚æ­¤å¤–ï¼ŒMVPA åœ¨æ ‡å‡†æ—¶é—´åºåˆ—é¢„æµ‹å’Œåˆ†ç±»ä»»åŠ¡ä¸­ä¹Ÿè¾¾åˆ°äº†é¢†å…ˆæ°´å¹³ï¼Œè¯æ˜äº†å…¶ä½œä¸ºé€šç”¨æ³¨æ„åŠ›æœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚è¯¥ç ”ç©¶å°† MVPFormer ç¡®ç«‹ä¸ºé¦–ä¸ªå¼€æºã€å¼€æ”¾æƒé‡ä¸”å¼€æ”¾æ•°æ®çš„ iEEG åŸºç¡€æ¨¡å‹ï¼Œå…·æœ‰æ˜¾è‘—çš„ä¸´åºŠåº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The code is available at https://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG dataset is available at https://huggingface.co/datasets/NeuroTec/SWEC_iEEG_Dataset",
      "pdf_url": "https://arxiv.org/pdf/2506.20354v2",
      "published_date": "2025-06-25 12:07:10 UTC",
      "updated_date": "2025-08-25 13:34:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:31:04.394305+00:00"
    },
    {
      "arxiv_id": "2506.20353v1",
      "title": "DipSVD: Dual-importance Protected SVD for Efficient LLM Compression",
      "title_zh": "DipSVDï¼šé¢å‘é«˜æ•ˆå¤§è¯­è¨€æ¨¡å‹å‹ç¼©çš„åŒé‡é‡è¦æ€§ä¿æŠ¤å¥‡å¼‚å€¼åˆ†è§£",
      "authors": [
        "Xuan Ding",
        "Rui Sun",
        "Yunjian Zhang",
        "Xiu Yan",
        "Yueqi Zhou",
        "Kaihao Huang",
        "Suzhong Fu",
        "Chuanlong Xie",
        "Yao Zhu"
      ],
      "abstract": "The ever-increasing computational demands and deployment costs of large language models (LLMs) have spurred numerous compressing methods. Compared to quantization and unstructured pruning, SVD compression offers superior hardware compatibility and theoretical guarantees. However, existing SVD-based methods focus on the overall discrepancy between the original and compressed matrices while overlooking the protection of critical components within the matrix, which leads to inferior performance in the compressed models. This paper proposes a dual-level importance protection mechanism to enhance SVD-based compression methods: (1) local importance protection: preserving the most critical singular vectors within each weight matrix through channel-weighted data whitening; and (2) global importance protection: enabling less important layers to bear a greater portion of the compression burden through either a heuristic or optimization-based approach, thereby minimizing the impact of compression on critical layers. Extensive experiments demonstrate that DipSVD outperforms existing SVD-based compression approaches across multiple benchmarks, achieving superior model performance especially at high model compression ratios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DipSVDï¼Œä¸€ç§æ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å‹ç¼©æ•ˆç‡çš„åŒé‡é‡è¦æ€§ä¿æŠ¤SVDæ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰SVDå‹ç¼©æŠ€æœ¯å› å¿½ç•¥æƒé‡çŸ©é˜µå†…å…³é”®ç»„ä»¶ä¿æŠ¤è€Œå¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ï¼ŒDipSVDå¼•å…¥äº†å±€éƒ¨ä¸å…¨å±€ä¸¤ä¸ªå±‚é¢çš„é‡è¦æ€§ä¿æŠ¤æœºåˆ¶ã€‚åœ¨å±€éƒ¨å±‚é¢ï¼Œè¯¥æ–¹æ³•é€šè¿‡Channel-weighted data whiteningä¿ç•™æ¯ä¸ªæƒé‡çŸ©é˜µä¸­æœ€æ ¸å¿ƒçš„å¥‡å¼‚å‘é‡ï¼›åœ¨å…¨å±€å±‚é¢ï¼Œåˆ™é€šè¿‡å¯å‘å¼æˆ–åŸºäºä¼˜åŒ–çš„ç­–ç•¥ï¼Œè®©æ¬¡è¦å±‚æ‰¿æ‹…æ›´å¤šçš„å‹ç¼©è´Ÿæ‹…ï¼Œä»è€Œé™ä½å‹ç¼©å¯¹å…³é”®å±‚çš„å½±å“ã€‚å¹¿æ³›çš„å®éªŒè¯æ˜ï¼ŒDipSVDåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºç°æœ‰çš„SVDå‹ç¼©æ–¹æ¡ˆï¼Œå°¤å…¶åœ¨æ¨¡å‹å¤„äºé«˜å‹ç¼©æ¯”ç¯å¢ƒä¸‹æ—¶å±•ç°å‡ºæ›´ä¸ºä¼˜å¼‚çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20353v1",
      "published_date": "2025-06-25 12:04:53 UTC",
      "updated_date": "2025-06-25 12:04:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:31:05.242582+00:00"
    },
    {
      "arxiv_id": "2506.20342v1",
      "title": "Feature Hallucination for Self-supervised Action Recognition",
      "title_zh": "è‡ªç›‘ç£åŠ¨ä½œè¯†åˆ«ä¸­çš„ç‰¹å¾å¹»è§‰",
      "authors": [
        "Lei Wang",
        "Piotr Koniusz"
      ],
      "abstract": "Understanding human actions in videos requires more than raw pixel analysis; it relies on high-level semantic reasoning and effective integration of multimodal features. We propose a deep translational action recognition framework that enhances recognition accuracy by jointly predicting action concepts and auxiliary features from RGB video frames. At test time, hallucination streams infer missing cues, enriching feature representations without increasing computational overhead. To focus on action-relevant regions beyond raw pixels, we introduce two novel domain-specific descriptors. Object Detection Features (ODF) aggregate outputs from multiple object detectors to capture contextual cues, while Saliency Detection Features (SDF) highlight spatial and intensity patterns crucial for action recognition. Our framework seamlessly integrates these descriptors with auxiliary modalities such as optical flow, Improved Dense Trajectories, skeleton data, and audio cues. It remains compatible with state-of-the-art architectures, including I3D, AssembleNet, Video Transformer Network, FASTER, and recent models like VideoMAE V2 and InternVideo2. To handle uncertainty in auxiliary features, we incorporate aleatoric uncertainty modeling in the hallucination step and introduce a robust loss function to mitigate feature noise. Our multimodal self-supervised action recognition framework achieves state-of-the-art performance on multiple benchmarks, including Kinetics-400, Kinetics-600, and Something-Something V2, demonstrating its effectiveness in capturing fine-grained action dynamics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªç›‘ç£åŠ¨ä½œè¯†åˆ«æå‡ºäº†ä¸€ç§ç‰¹å¾å¹»è§‰(Feature Hallucination)æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡é«˜çº§è¯­ä¹‰æ¨ç†å’Œå¤šæ¨¡æ€ç‰¹å¾é›†æˆæå‡è§†é¢‘ç†è§£èƒ½åŠ›ã€‚è¯¥æ¡†æ¶é€šè¿‡æ·±åº¦å¹³ç§»æœºåˆ¶ä»RGBè§†é¢‘å¸§ä¸­å…±åŒé¢„æµ‹åŠ¨ä½œæ¦‚å¿µå’Œè¾…åŠ©ç‰¹å¾ï¼Œå¹¶åœ¨æµ‹è¯•é˜¶æ®µåˆ©ç”¨å¹»è§‰æµ(hallucination streams)æ¨æ–­ç¼ºå¤±çº¿ç´¢ï¼Œä»è€Œåœ¨ä¸å¢åŠ è®¡ç®—å¼€é”€çš„æƒ…å†µä¸‹å¼ºåŒ–ç‰¹å¾è¡¨ç¤ºã€‚ç ”ç©¶å¼•å…¥äº†ç‰©ä½“æ£€æµ‹ç‰¹å¾(Object Detection Features, ODF)å’Œæ˜¾è‘—æ€§æ£€æµ‹ç‰¹å¾(Saliency Detection Features, SDF)ä¸¤ç§æ–°å‹æè¿°ç¬¦ï¼Œä»¥æ•è·è§†é¢‘åƒç´ ä¹‹å¤–çš„ä¸Šä¸‹æ–‡ä¸ç©ºé—´å¼ºåº¦æ¨¡å¼ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿæ— ç¼é›†æˆå…‰æµã€éª¨æ¶åŠéŸ³é¢‘ç­‰è¾…åŠ©æ¨¡æ€ï¼Œå¹¶ä¸VideoMAE V2å’ŒInternVideo2ç­‰å…ˆè¿›æ¨¡å‹ä¿æŒå…¼å®¹ã€‚ä¸ºäº†åº”å¯¹ç‰¹å¾ä¸ç¡®å®šæ€§ï¼Œç ”ç©¶è¿˜æ•´åˆäº†å¶ç„¶ä¸ç¡®å®šæ€§å»ºæ¨¡(aleatoric uncertainty modeling)ä¸é²æ£’æŸå¤±å‡½æ•°ä»¥æŠ‘åˆ¶ç‰¹å¾å™ªå£°ã€‚æœ€ç»ˆï¼Œè¯¥æ¡†æ¶åœ¨Kinetics-400ã€Kinetics-600åŠSomething-Something V2ç­‰åŸºå‡†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œå±•ç°äº†å…¶åœ¨æ•æ‰ç»†ç²’åº¦åŠ¨ä½œåŠ¨æ€æ–¹é¢çš„å“è¶Šæ•ˆæœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication in International Journal of Computer Vision (IJCV)",
      "pdf_url": "https://arxiv.org/pdf/2506.20342v1",
      "published_date": "2025-06-25 11:50:23 UTC",
      "updated_date": "2025-06-25 11:50:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:31:01.652738+00:00"
    },
    {
      "arxiv_id": "2506.20696v1",
      "title": "IMC-PINN-FE: A Physics-Informed Neural Network for Patient-Specific Left Ventricular Finite Element Modeling with Image Motion Consistency and Biomechanical Parameter Estimation",
      "title_zh": "IMC-PINN-FEï¼šä¸€ç§èåˆå›¾åƒè¿åŠ¨ä¸€è‡´æ€§ä¸ç”Ÿç‰©åŠ›å­¦å‚æ•°ä¼°è®¡çš„æ‚£è€…ç‰¹å¼‚æ€§å·¦å¿ƒå®¤æœ‰é™å…ƒå»ºæ¨¡ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ",
      "authors": [
        "Siyu Mu",
        "Wei Xuan Chan",
        "Choon Hwai Yap"
      ],
      "abstract": "Elucidating the biomechanical behavior of the myocardium is crucial for understanding cardiac physiology, but cannot be directly inferred from clinical imaging and typically requires finite element (FE) simulations. However, conventional FE methods are computationally expensive and often fail to reproduce observed cardiac motions. We propose IMC-PINN-FE, a physics-informed neural network (PINN) framework that integrates imaged motion consistency (IMC) with FE modeling for patient-specific left ventricular (LV) biomechanics. Cardiac motion is first estimated from MRI or echocardiography using either a pre-trained attention-based network or an unsupervised cyclic-regularized network, followed by extraction of motion modes. IMC-PINN-FE then rapidly estimates myocardial stiffness and active tension by fitting clinical pressure measurements, accelerating computation from hours to seconds compared to traditional inverse FE. Based on these parameters, it performs FE modeling across the cardiac cycle at 75x speedup. Through motion constraints, it matches imaged displacements more accurately, improving average Dice from 0.849 to 0.927, while preserving realistic pressure-volume behavior. IMC-PINN-FE advances previous PINN-FE models by introducing back-computation of material properties and better motion fidelity. Using motion from a single subject to reconstruct shape modes also avoids the need for large datasets and improves patient specificity. IMC-PINN-FE offers a robust and efficient approach for rapid, personalized, and image-consistent cardiac biomechanical modeling.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†IMC-PINN-FEï¼Œä¸€ç§å°†å›¾åƒè¿åŠ¨ä¸€è‡´æ€§(Image Motion Consistency, IMC)ä¸æœ‰é™å…ƒ(Finite Element, FE)å»ºæ¨¡ç›¸ç»“åˆçš„ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ(PINN)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæœ‰é™å…ƒæ–¹æ³•è®¡ç®—æˆæœ¬é«˜ä¸”éš¾ä»¥å‡†ç¡®å¤ç°ä¸´åºŠè§‚æµ‹å¿ƒè„è¿åŠ¨çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡é¢„è®­ç»ƒçš„æ³¨æ„åŠ›ç½‘ç»œæˆ–æ— ç›‘ç£å¾ªç¯æ­£åˆ™åŒ–ç½‘ç»œä»MRIæˆ–è¶…å£°å¿ƒåŠ¨å›¾ä¸­æå–è¿åŠ¨æ¨¡å¼ï¼Œå¹¶é€šè¿‡æ‹Ÿåˆä¸´åºŠå‹åŠ›æµ‹é‡æ•°æ®å¿«é€Ÿä¼°ç®—å¿ƒè‚Œåˆšåº¦å’Œä¸»åŠ¨å¼ åŠ›ã€‚ä¸ä¼ ç»Ÿé€†æœ‰é™å…ƒåˆ†æç›¸æ¯”ï¼ŒIMC-PINN-FEå°†ç”Ÿç‰©åŠ›å­¦å‚æ•°è¯„ä¼°çš„æ—¶é—´ä»æ•°å°æ—¶ç¼©çŸ­è‡³æ•°ç§’ï¼Œå¹¶åœ¨æ•´ä¸ªå¿ƒåŠ¨å‘¨æœŸçš„æœ‰é™å…ƒå»ºæ¨¡ä¸­å®ç°äº†75å€çš„åŠ é€Ÿã€‚é€šè¿‡å¼•å…¥è¿åŠ¨çº¦æŸï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ›´ç²¾ç¡®åœ°åŒ¹é…å½±åƒä½ç§»ï¼Œå°†å¹³å‡Diceç³»æ•°ä»0.849æå‡è‡³0.927ï¼ŒåŒæ—¶ä¿æŒäº†çœŸå®çš„å‹åŠ›-å®¹é‡(Pressure-Volume)å…³ç³»ã€‚è¯¥ç ”ç©¶é€šè¿‡å¼•å…¥ææ–™å±æ€§çš„åå‘è®¡ç®—å’Œå•å—è¯•è€…å½¢æ€æ¨¡å¼é‡å»ºï¼Œåœ¨ä¸ä¾èµ–å¤§è§„æ¨¡æ•°æ®é›†çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡äº†æ‚£è€…ç‰¹å¼‚æ€§(Patient-Specific)ï¼Œä¸ºå¿«é€Ÿã€ä¸ªæ€§åŒ–ä¸”å½±åƒä¸€è‡´çš„å¿ƒè„ç”Ÿç‰©åŠ›å­¦å»ºæ¨¡æä¾›äº†ä¸€ç§ç¨³å¥é«˜æ•ˆçš„æ–¹æ³•ã€‚",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20696v1",
      "published_date": "2025-06-25 11:37:34 UTC",
      "updated_date": "2025-06-25 11:37:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:31:04.732160+00:00"
    },
    {
      "arxiv_id": "2506.20332v3",
      "title": "Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards",
      "title_zh": "Mobile-R1ï¼šé€šè¿‡ä»»åŠ¡çº§å¥–åŠ±è¿ˆå‘åŸºäºVLMçš„ç§»åŠ¨æ™ºèƒ½ä½“äº¤äº’å¼å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Jihao Gu",
        "Qihang Ai",
        "Yingyao Wang",
        "Pi Bu",
        "Jingxuan Xing",
        "Zekun Zhu",
        "Wei Jiang",
        "Ziming Wang",
        "Yingxiu Zhao",
        "Ming-Liang Zhang",
        "Jun Song",
        "Yuning Jiang",
        "Bo Zheng"
      ],
      "abstract": "Vision-language model-based mobile agents have gained the ability to not only understand complex instructions and mobile screenshots, but also optimize their action outputs via thinking and reasoning, benefiting from reinforcement learning, such as Group Relative Policy Optimization (GRPO). However, existing research centers on offline reinforcement learning training or online optimization using action-level rewards, which limits the agent's dynamic interaction with the environment. This often results in agents settling into local optima, thereby weakening their ability for exploration and error action correction. To address these challenges, we introduce an approach called Mobile-R1, which employs interactive multi-turn reinforcement learning with task-level rewards for mobile agents. Our training framework consists of three stages: initial format finetuning, single-step online training via action-level reward, followed by online training via task-level reward based on multi-turn trajectories. This strategy is designed to enhance the exploration and error correction capabilities of Mobile-R1, leading to significant performance improvements. Moreover, we have collected a dataset covering 28 Chinese applications with 24,521 high-quality manual annotations and established a new benchmark with 500 trajectories. We will open source all resources, including the dataset, benchmark, model weight, and codes: https://mobile-r1.github.io/Mobile-R1/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Mobile-R1ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹(VLM)çš„ç§»åŠ¨æ™ºèƒ½ä½“è®¾è®¡çš„äº¤äº’å¼å¤šè½®å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒäº¤äº’ä¸­å®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ä¸”çº é”™èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚Mobile-R1å¼•å…¥äº†ä¸‰é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼ŒåŒ…æ‹¬åˆå§‹æ ¼å¼å¾®è°ƒ(Finetuning)ã€åŸºäºåŠ¨ä½œçº§å¥–åŠ±çš„å•æ­¥åœ¨çº¿è®­ç»ƒï¼Œä»¥åŠæœ€é‡è¦çš„åŸºäºå¤šè½®è½¨è¿¹çš„ä»»åŠ¡çº§å¥–åŠ±(Task-Level Rewards)åœ¨çº¿è®­ç»ƒã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥ä»»åŠ¡çº§å¥–åŠ±ï¼Œæ˜¾è‘—æå‡äº†æ™ºèƒ½ä½“åœ¨å¤æ‚ç§»åŠ¨åº”ç”¨ä¸­çš„æ¢ç´¢æ•ˆç‡ä¸é”™è¯¯çº æ­£(Error Correction)èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å‘å¸ƒäº†ä¸€ä¸ªæ¶µç›–28ä¸ªä¸­æ–‡åº”ç”¨ã€åŒ…å«24,521æ¡é«˜è´¨é‡æ‰‹å·¥æ ‡æ³¨çš„æ•°æ®é›†ï¼Œå¹¶å»ºç«‹äº†500æ¡è½¨è¿¹çš„æ–°åŸºå‡†ã€‚å®éªŒè¯æ˜ï¼ŒMobile-R1åœ¨å¤šè½®äº¤äº’ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½è¿›æ­¥ï¼Œä¸ºå®ç°æ›´æ™ºèƒ½ã€æ›´å…·äº¤äº’æ€§çš„ç§»åŠ¨æ™ºèƒ½ä½“æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 15 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.20332v3",
      "published_date": "2025-06-25 11:34:43 UTC",
      "updated_date": "2025-08-16 16:23:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:31:12.716992+00:00"
    },
    {
      "arxiv_id": "2506.20323v1",
      "title": "Comparative Analysis of Deep Learning Models for Crop Disease Detection: A Transfer Learning Approach",
      "title_zh": "å†œä½œç‰©ç—…å®³æ£€æµ‹ä¸­æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¯¹æ¯”åˆ†æï¼šåŸºäºè¿ç§»å­¦ä¹ çš„æ–¹æ³•",
      "authors": [
        "Saundarya Subramaniam",
        "Shalini Majumdar",
        "Shantanu Nadar",
        "Kaustubh Kulkarni"
      ],
      "abstract": "This research presents the development of an Artificial Intelligence (AI) - driven crop disease detection system designed to assist farmers in rural areas with limited resources. We aim to compare different deep learning models for a comparative analysis, focusing on their efficacy in transfer learning. By leveraging deep learning models, including EfficientNet, ResNet101, MobileNetV2, and our custom CNN, which achieved a validation accuracy of 95.76%, the system effectively classifies plant diseases. This research demonstrates the potential of transfer learning in reshaping agricultural practices, improving crop health management, and supporting sustainable farming in rural environments.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ä¸ªäººå·¥æ™ºèƒ½(AI)é©±åŠ¨çš„ä½œç‰©ç—…å®³æ£€æµ‹ç³»ç»Ÿï¼Œæ—¨åœ¨ä¸ºèµ„æºæœ‰é™çš„å†œæ‘åœ°åŒºæä¾›æŠ€æœ¯æ”¯æŒã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨äº†è¿ç§»å­¦ä¹ (Transfer Learning)æ–¹æ³•ï¼Œå¹¶å¯¹EfficientNetã€ResNet101ã€MobileNetV2ä»¥åŠè‡ªå®šä¹‰å·ç§¯ç¥ç»ç½‘ç»œ(Custom CNN)ç­‰å¤šç§æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œäº†å¯¹æ¯”åˆ†æã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿèƒ½æœ‰æ•ˆåˆ†ç±»æ¤ç‰©ç—…å®³ï¼Œå…¶ä¸­è‡ªå®šä¹‰CNNæ¨¡å‹çš„éªŒè¯å‡†ç¡®ç‡(Validation Accuracy)è¾¾åˆ°äº†95.76%ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†è¿ç§»å­¦ä¹ åœ¨é‡å¡‘å†œä¸šå®è·µã€ä¼˜åŒ–ä½œç‰©å¥åº·ç®¡ç†ä»¥åŠæ”¯æŒå†œæ‘å¯æŒç»­è€•ä½œæ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20323v1",
      "published_date": "2025-06-25 11:04:33 UTC",
      "updated_date": "2025-06-25 11:04:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:31:17.769131+00:00"
    },
    {
      "arxiv_id": "2506.22501v1",
      "title": "How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?",
      "title_zh": "å¤šæ¨¡æ€é¥æ„Ÿæ•°æ®é›†å¦‚ä½•é€šè¿‡ SpatialNet-ViT é©±åŠ¨åˆ†ç±»ä»»åŠ¡å˜é©ï¼Ÿ",
      "authors": [
        "Gautam Siddharth Kashyap",
        "Manaswi Kulahara",
        "Nipun Joshi",
        "Usman Naseem"
      ],
      "abstract": "Remote sensing datasets offer significant promise for tackling key classification tasks such as land-use categorization, object presence detection, and rural/urban classification. However, many existing studies tend to focus on narrow tasks or datasets, which limits their ability to generalize across various remote sensing classification challenges. To overcome this, we propose a novel model, SpatialNet-ViT, leveraging the power of Vision Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach combines spatial awareness with contextual understanding, improving both classification accuracy and scalability. Additionally, techniques like data augmentation, transfer learning, and multi-task learning are employed to enhance model robustness and its ability to generalize across diverse datasets",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰é¥æ„Ÿåˆ†ç±»æ–¹æ³•åœ¨å¤„ç†åœŸåœ°åˆ©ç”¨åˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ç­‰ä»»åŠ¡æ—¶æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆ Vision Transformers (ViTs) ä¸ Multi-Task Learning (MTL) çš„æ–°å‹æ¨¡å‹ SpatialNet-ViTã€‚è¯¥æ¨¡å‹é€šè¿‡å°†ç©ºé—´æ„ŸçŸ¥ (spatial awareness) ä¸ä¸Šä¸‹æ–‡ç†è§£æ·±åº¦é›†æˆï¼Œæ˜¾è‘—æå‡äº†åˆ†ç±»çš„å‡†ç¡®æ€§ä¸ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ã€‚ç ”ç©¶è¿‡ç¨‹ä¸­è¿›ä¸€æ­¥å¼•å…¥äº†æ•°æ®å¢å¼º (data augmentation) å’Œè¿ç§»å­¦ä¹  (transfer learning) ç­‰æŠ€æœ¯ï¼Œæœ‰æ•ˆå¢å¼ºäº†æ¨¡å‹åœ¨å¤„ç†å¤šæ ·åŒ–é¥æ„Ÿæ•°æ®é›†æ—¶çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSpatialNet-ViT ä¸ä»…åœ¨å¤šé¡¹åˆ†ç±»æŒ‘æˆ˜ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¿˜å±•ç°äº†å“è¶Šçš„è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œä¸ºé¥æ„Ÿé¢†åŸŸçš„å¤§è§„æ¨¡å¤šä»»åŠ¡å¤„ç†æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in the 2025 IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2025), scheduled for 3 - 8 August 2025 in Brisbane, Australia",
      "pdf_url": "https://arxiv.org/pdf/2506.22501v1",
      "published_date": "2025-06-25 10:50:33 UTC",
      "updated_date": "2025-06-25 10:50:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:31:28.932475+00:00"
    },
    {
      "arxiv_id": "2506.20307v1",
      "title": "Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration",
      "title_zh": "æœ‰é™æ¼”ç¤ºä¸‹çš„è¶…è¶Šä¸“å®¶çº§æ€§èƒ½ï¼šç»“åˆåŒé‡æ¢ç´¢çš„é«˜æ•ˆæ¨¡ä»¿å­¦ä¹ ",
      "authors": [
        "Heyang Zhao",
        "Xingrui Yu",
        "David M. Bossens",
        "Ivor W. Tsang",
        "Quanquan Gu"
      ],
      "abstract": "Imitation learning is a central problem in reinforcement learning where the goal is to learn a policy that mimics the expert's behavior. In practice, it is often challenging to learn the expert policy from a limited number of demonstrations accurately due to the complexity of the state space. Moreover, it is essential to explore the environment and collect data to achieve beyond-expert performance. To overcome these challenges, we propose a novel imitation learning algorithm called Imitation Learning with Double Exploration (ILDE), which implements exploration in two aspects: (1) optimistic policy optimization via an exploration bonus that rewards state-action pairs with high uncertainty to potentially improve the convergence to the expert policy, and (2) curiosity-driven exploration of the states that deviate from the demonstration trajectories to potentially yield beyond-expert performance. Empirically, we demonstrate that ILDE outperforms the state-of-the-art imitation learning algorithms in terms of sample efficiency and achieves beyond-expert performance on Atari and MuJoCo tasks with fewer demonstrations than in previous work. We also provide a theoretical justification of ILDE as an uncertainty-regularized policy optimization method with optimistic exploration, leading to a regret growing sublinearly in the number of episodes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºILDE (Imitation Learning with Double Exploration) çš„æ–°å‹æ¨¡ä»¿å­¦ä¹ ç®—æ³•ï¼Œæ—¨åœ¨è§£å†³åœ¨æœ‰é™ç¤ºæ•™ (limited demonstrations) æƒ…å†µä¸‹éš¾ä»¥å‡†ç¡®å­¦ä¹ ä¸“å®¶ç­–ç•¥å¹¶å®ç°è¶…è¶Šä¸“å®¶æ€§èƒ½çš„æŒ‘æˆ˜ã€‚è¯¥ç®—æ³•æ ¸å¿ƒåœ¨äºå®ç°äº†åŒé‡æ¢ç´¢æœºåˆ¶ï¼šé¦–å…ˆæ˜¯é€šè¿‡æ¢ç´¢å¥–åŠ± (exploration bonus) å¯¹å…·æœ‰é«˜ä¸ç¡®å®šæ€§çš„çŠ¶æ€åŠ¨ä½œå¯¹è¿›è¡Œä¹è§‚ç­–ç•¥ä¼˜åŒ– (optimistic policy optimization)ï¼Œä»¥æé«˜å‘ä¸“å®¶ç­–ç•¥æ”¶æ•›çš„æ•ˆç‡ï¼›å…¶æ¬¡æ˜¯åˆ©ç”¨å¥½å¥‡å¿ƒé©±åŠ¨çš„æ¢ç´¢ (curiosity-driven exploration) è®¿é—®åç¦»ç¤ºæ•™è½¨è¿¹çš„çŠ¶æ€ï¼Œä»è€Œå‘æ˜ä¼˜äºä¸“å®¶çš„ç­–ç•¥ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒILDEåœ¨Atariå’ŒMuJoCoä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰çš„æ¨¡ä»¿å­¦ä¹ ç®—æ³•ï¼Œä¸ä»…æå‡äº†æ ·æœ¬æ•ˆç‡ (sample efficiency)ï¼Œè¿˜èƒ½ä»¥æ›´å°‘çš„ç¤ºæ•™æ•°æ®è¾¾æˆè¶…è¶Šä¸“å®¶çš„æ€§èƒ½ (beyond-expert performance)ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜ä¸ºILDEæä¾›äº†ç†è®ºæ”¯æŒï¼Œè¯æ˜å…¶ä½œä¸ºä¸€ç§å¸¦æœ‰ä¹è§‚æ¢ç´¢çš„ä¸ç¡®å®šæ€§æ­£åˆ™åŒ–ç­–ç•¥ä¼˜åŒ–æ–¹æ³•ï¼Œå…¶æ‚”å€¼ (regret) éšå›åˆæ•°å‘ˆæ¬¡çº¿æ€§å¢é•¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20307v1",
      "published_date": "2025-06-25 10:39:32 UTC",
      "updated_date": "2025-06-25 10:39:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:32:30.660808+00:00"
    },
    {
      "arxiv_id": "2507.02917v2",
      "title": "Echo State Transformer: Attention Over Finite Memories",
      "title_zh": "Echo State Transformerï¼šåŸºäºæœ‰é™è®°å¿†çš„æ³¨æ„åŠ›æœºåˆ¶",
      "authors": [
        "Yannis Bendi-Ouis",
        "Xavier Hinaut"
      ],
      "abstract": "While Large Language Models and their underlying Transformer architecture are remarkably efficient, they do not reflect how our brain processes and learns a diversity of cognitive tasks such as language and working memory. Furthermore, sequential data processing with Transformers encounters a fundamental barrier: quadratic complexity growth with sequence length. Motivated by these limitations, our ambition is to create more efficient models that are less reliant on intensive computations. We introduce Echo State Transformers (EST), a hybrid architecture that elegantly resolves this challenge while demonstrating exceptional performance in classification and detection tasks. EST integrates the Transformer attention mechanisms with principles from Reservoir Computing to create a fixed-size window distributed memory system. Drawing inspiration from Echo State Networks, the most prominent instance of the Reservoir Computing paradigm, our approach leverages reservoirs (random recurrent networks) as a lightweight and efficient memory. Our architecture integrates a new module called ''Working Memory'' based on several reservoirs working in parallel. These reservoirs work as independent working memory units with distinct internal dynamics. A novelty here is that the classical reservoir hyperparameters, controlling the dynamics, are now trained. Thus, the EST dynamically adapts the reservoir memory/non-linearity trade-off. Thanks to these working memory units, EST achieves constant computational complexity at each processing step, effectively breaking the quadratic scaling problem of standard Transformers. We evaluate ESTs on a recent challenging timeseries benchmark: the Time Series Library, which comprises 69 tasks across five categories. Results show that ESTs ranks first overall in two of five categories, outperforming strong state-of-the-art baselines on classification and anomaly detection tasks, while remaining competitive on short-term forecasting. These results position ESTs as a compelling alternative for time-series classification and anomaly detection, and a practical complement to transformer-style models in applications that prioritize robust representations and sensitive event detection.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Echo State Transformer (EST)ï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆäº†Transformeræ³¨æ„åŠ›æœºåˆ¶ä¸å‚¨å±‚è®¡ç®—(Reservoir Computing)åŸç†çš„æ··åˆæ¶æ„ï¼Œæ—¨åœ¨è§£å†³æ ‡å‡†Transformeråœ¨å¤„ç†é•¿åºåˆ—æ—¶é¢ä¸´çš„äºŒæ¬¡æ–¹å¤æ‚åº¦å¢é•¿é—®é¢˜ã€‚ESTå¼•å…¥äº†ä¸€ä¸ªåŸºäºå¤šä¸ªå¹¶è¡Œå‚¨å±‚(reservoirs)çš„â€œå·¥ä½œè®°å¿†â€(Working Memory)æ¨¡å—ï¼Œåˆ©ç”¨éšæœºé€’å½’ç½‘ç»œä½œä¸ºè½»é‡çº§ä¸”é«˜æ•ˆçš„åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿã€‚ä¸ä¼ ç»Ÿçš„Echo State Networksä¸åŒï¼Œè¯¥æ¨¡å‹é€šè¿‡è®­ç»ƒå‚¨å±‚çš„è¶…å‚æ•°æ¥åŠ¨æ€å¹³è¡¡è®°å¿†ä¸éçº¿æ€§ç‰¹æ€§ã€‚å¾—ç›Šäºè¿™ç§å®šé•¿çª—å£çš„å­˜å‚¨æœºåˆ¶ï¼ŒESTåœ¨å¤„ç†æ¯ä¸€æ­¥æ—¶éƒ½èƒ½ä¿æŒå¸¸æ•°çº§çš„è®¡ç®—å¤æ‚åº¦ï¼Œæœ‰æ•ˆæ‰“ç ´äº†åºåˆ—é•¿åº¦çš„æ‰©å±•é™åˆ¶ã€‚åœ¨åŒ…å«69é¡¹ä»»åŠ¡çš„Time Series LibraryåŸºå‡†æµ‹è¯•ä¸­ï¼ŒESTåœ¨åˆ†ç±»å’Œå¼‚å¸¸æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ’åæ•´ä½“ç¬¬ä¸€ï¼Œå¹¶åœ¨çŸ­æœŸé¢„æµ‹ä»»åŠ¡ä¸­ä¿æŒäº†æå¼ºçš„ç«äº‰åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒESTä¸ºæ—¶é—´åºåˆ—åˆ†ææä¾›äº†ä¸€ç§é«˜æ•ˆä¸”ç¨³å¥çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæ˜¯ä¼˜å…ˆè€ƒè™‘è¡¨å¾èƒ½åŠ›å’Œæ•æ„Ÿäº‹ä»¶æ¢æµ‹åº”ç”¨ä¸­Transformeræ¨¡å‹çš„æœ‰åŠ›è¡¥å……ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.02917v2",
      "published_date": "2025-06-25 09:56:25 UTC",
      "updated_date": "2025-10-27 09:37:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:31:25.422830+00:00"
    },
    {
      "arxiv_id": "2506.20274v1",
      "title": "Enterprise Large Language Model Evaluation Benchmark",
      "title_zh": "ä¼ä¸šçº§å¤§è¯­è¨€æ¨¡å‹è¯„æµ‹åŸºå‡†",
      "authors": [
        "Liya Wang",
        "David Yi",
        "Damien Jose",
        "John Passarelli",
        "James Gao",
        "Jordan Leventis",
        "Kang Li"
      ],
      "abstract": "Large Language Models (LLMs) ) have demonstrated promise in boosting productivity across AI-powered tools, yet existing benchmarks like Massive Multitask Language Understanding (MMLU) inadequately assess enterprise-specific task complexities. We propose a 14-task framework grounded in Bloom's Taxonomy to holistically evaluate LLM capabilities in enterprise contexts. To address challenges of noisy data and costly annotation, we develop a scalable pipeline combining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented generation (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six leading models shows open-source contenders like DeepSeek R1 rival proprietary models in reasoning tasks but lag in judgment-based scenarios, likely due to overthinking. Our benchmark reveals critical enterprise performance gaps and offers actionable insights for model optimization. This work provides enterprises a blueprint for tailored evaluations and advances practical LLM deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäº Bloom's Taxonomy çš„ 14 ä»»åŠ¡è¯„ä¼°æ¡†æ¶ï¼Œä»¥å¡«è¡¥ç°æœ‰åŸºå‡†æµ‹è¯•åœ¨è¯„ä¼°ä¼ä¸šçº§ä»»åŠ¡å¤æ‚æ€§æ–¹é¢çš„ç©ºç™½ã€‚ä¸ºåº”å¯¹æ•°æ®å™ªå£°å’Œæ ‡æ³¨æˆæœ¬æŒ‘æˆ˜ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€å¥—é›†æˆ LLM-as-a-Labelerã€LLM-as-a-Judge å’Œ corrective retrieval-augmented generation (CRAG) çš„å¯æ‰©å±•æµæ°´çº¿ï¼ŒæˆåŠŸæ„å»ºäº†æ‹¥æœ‰ 9,700 ä¸ªæ ·æœ¬çš„é²æ£’åŸºå‡†ã€‚å¯¹å…­ç§é¢†å…ˆæ¨¡å‹çš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œä»¥ DeepSeek R1 ä¸ºä»£è¡¨çš„å¼€æºæ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸­è¶³ä»¥åª²ç¾ä¸“æœ‰æ¨¡å‹ï¼Œä½†åœ¨æ¶‰åŠåˆ¤æ–­çš„åœºæ™¯ä¸­å› è¿‡åº¦æ€è€ƒ(overthinking)è€Œè¡¨ç°ç¨é€Šã€‚è¯¥åŸºå‡†æµ‹è¯•ä¸ä»…æ­ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¼ä¸šåº”ç”¨ä¸­çš„å…³é”®æ€§èƒ½å·®è·ï¼Œè¿˜ä¸ºæ¨¡å‹ä¼˜åŒ–æä¾›äº†å¯æ“ä½œçš„è§è§£ã€‚æ€»ä¹‹ï¼Œè¿™é¡¹å·¥ä½œä¸ºä¼ä¸šè¿›è¡Œå®šåˆ¶åŒ–è¯„ä¼°æä¾›äº†è“å›¾ï¼Œå¹¶æœ‰æ•ˆä¿ƒè¿›äº† LLM çš„å®é™…è½åœ°ä¸åº”ç”¨éƒ¨ç½²ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to MLNLP 2025 at https://csity2025.org/mlnlp/index",
      "pdf_url": "https://arxiv.org/pdf/2506.20274v1",
      "published_date": "2025-06-25 09:34:25 UTC",
      "updated_date": "2025-06-25 09:34:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:31:38.185617+00:00"
    },
    {
      "arxiv_id": "2507.02916v1",
      "title": "Efficient Certified Reasoning for Binarized Neural Networks",
      "title_zh": "äºŒå€¼åŒ–ç¥ç»ç½‘ç»œçš„é«˜æ•ˆè®¤è¯æ¨ç†",
      "authors": [
        "Jiong Yang",
        "Yong Kiam Tan",
        "Mate Soos",
        "Magnus O. Myreen",
        "Kuldeep S. Meel"
      ],
      "abstract": "Neural networks have emerged as essential components in safety-critical applications -- these use cases demand complex, yet trustworthy computations. Binarized Neural Networks (BNNs) are a type of neural network where each neuron is constrained to a Boolean value; they are particularly well-suited for safety-critical tasks because they retain much of the computational capacities of full-scale (floating-point or quantized) deep neural networks, but remain compatible with satisfiability solvers for qualitative verification and with model counters for quantitative reasoning. However, existing methods for BNN analysis suffer from either limited scalability or susceptibility to soundness errors, which hinders their applicability in real-world scenarios.\n  In this work, we present a scalable and trustworthy approach for both qualitative and quantitative verification of BNNs. Our approach introduces a native representation of BNN constraints in a custom-designed solver for qualitative reasoning, and in an approximate model counter for quantitative reasoning. We further develop specialized proof generation and checking pipelines with native support for BNN constraint reasoning, ensuring trustworthiness for all of our verification results. Empirical evaluations on a BNN robustness verification benchmark suite demonstrate that our certified solving approach achieves a $9\\times$ speedup over prior certified CNF and PB-based approaches, and our certified counting approach achieves a $218\\times$ speedup over the existing CNF-based baseline. In terms of coverage, our pipeline produces fully certified results for $99\\%$ and $86\\%$ of the qualitative and quantitative reasoning queries on BNNs, respectively. This is in sharp contrast to the best existing baselines which can fully certify only $62\\%$ and $4\\%$ of the queries, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äºŒå€¼åŒ–ç¥ç»ç½‘ç»œ (Binarized Neural Networks, BNNs) åœ¨å®‰å…¨æ€§å…³é”®åº”ç”¨ä¸­é¢ä¸´çš„å¯æ‰©å±•æ€§å’Œå¯é æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§å¯æ‰©å±•ä¸”å€¼å¾—ä¿¡èµ–çš„å®šæ€§ä¸å®šé‡éªŒè¯æ–¹æ³•ã€‚é€šè¿‡åœ¨è‡ªå®šä¹‰æ±‚è§£å™¨ä¸­å¼•å…¥åŸç”Ÿ BNN çº¦æŸè¡¨ç¤ºï¼Œå¹¶ç»“åˆè¿‘ä¼¼æ¨¡å‹è®¡æ•°å™¨ (model counter)ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿé«˜æ•ˆå¤„ç†å¤æ‚çš„æ¨ç†ä»»åŠ¡ã€‚ç ”ç©¶å›¢é˜Ÿè¿›ä¸€æ­¥å¼€å‘äº†ä¸“é—¨çš„è¯æ˜ç”Ÿæˆä¸æ£€æŸ¥æµæ°´çº¿ï¼Œç¡®ä¿äº†æ‰€æœ‰éªŒè¯ç»“æœçš„è®¤è¯æ€§ (certified results)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ±‚è§£æ–¹æ³•åœ¨ BNN é²æ£’æ€§éªŒè¯ä¸Šæ¯”ç°æœ‰ CNF å’Œ PB-based æ–¹æ³•æé€Ÿ 9 å€ï¼Œè€Œè®¡æ•°æ–¹æ³•åˆ™å®ç°äº† 218 å€çš„æé€Ÿã€‚æœ€ç»ˆï¼Œè¯¥æµç¨‹åœ¨å®šæ€§å’Œå®šé‡æ¨ç†æŸ¥è¯¢ä¸­åˆ†åˆ«è¾¾åˆ°äº† 99% å’Œ 86% çš„å…¨è®¤è¯è¦†ç›–ç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†å¹¶æå‡äº† BNN åœ¨çœŸå®åœºæ™¯ä¸­çš„é€‚ç”¨æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 4 figures, to be published in SAT25",
      "pdf_url": "https://arxiv.org/pdf/2507.02916v1",
      "published_date": "2025-06-25 09:27:02 UTC",
      "updated_date": "2025-06-25 09:27:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:32:52.642133+00:00"
    },
    {
      "arxiv_id": "2506.20260v1",
      "title": "Argumentative Ensembling for Robust Recourse under Model Multiplicity",
      "title_zh": "é¢å‘æ¨¡å‹å¤šé‡æ€§ä¸‹ç¨³å¥è¿½ç´¢çš„è®ºè¾©å¼é›†æˆ",
      "authors": [
        "Junqi Jiang",
        "Antonio Rago",
        "Francesco Leofante",
        "Francesca Toni"
      ],
      "abstract": "In machine learning, it is common to obtain multiple equally performing models for the same prediction task, e.g., when training neural networks with different random seeds. Model multiplicity (MM) is the situation which arises when these competing models differ in their predictions for the same input, for which ensembling is often employed to determine an aggregation of the outputs. Providing recourse recommendations via counterfactual explanations (CEs) under MM thus becomes complex, since the CE may not be valid across all models, i.e., the CEs are not robust under MM. In this work, we formalise the problem of providing recourse under MM, which we name recourse-aware ensembling (RAE). We propose the idea that under MM, CEs for each individual model should be considered alongside their predictions so that the aggregated prediction and recourse are decided in tandem. Centred around this intuition, we introduce six desirable properties for solutions to this problem. For solving RAE, we propose a novel argumentative ensembling method which guarantees the robustness of CEs under MM. Specifically, our method leverages computational argumentation to explicitly represent the conflicts between models and counterfactuals regarding prediction results and CE validity. It then uses argumentation semantics to resolve the conflicts and obtain the final solution, in a manner which is parametric to the chosen semantics. Our method also allows for the specification of preferences over the models under MM, allowing further customisation of the ensemble. In a comprehensive theoretical analysis, we characterise the behaviour of argumentative ensembling with four different argumentation semantics. We then empirically demonstrate the effectiveness of our approach in satisfying desirable properties with eight instantiations of our method. (Abstract is shortened for arXiv.)",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœºå™¨å­¦ä¹ ä¸­çš„æ¨¡å‹å¤šæ ·æ€§ (Model Multiplicity) é—®é¢˜ï¼Œå³å¤šä¸ªæ€§èƒ½ç›¸å½“çš„æ¨¡å‹å¯¹åŒä¸€è¾“å…¥äº§ç”Ÿä¸åŒé¢„æµ‹ï¼Œå¯¼è‡´è¿½æº¯å»ºè®® (Recourse) çš„åäº‹å®è§£é‡Š (Counterfactual Explanations) å¾€å¾€ç¼ºä¹é²æ£’æ€§ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œè®ºæ–‡æ­£å¼æå‡ºäº†è¿½æº¯æ„ŸçŸ¥é›†æˆ (Recourse-Aware Ensembling) æ¡†æ¶ï¼Œå¹¶å®šä¹‰äº†å…­é¡¹ç†æƒ³å±æ€§ï¼Œå¼ºè°ƒåº”åŒæ­¥å†³å®šèšåˆé¢„æµ‹ä¸è¿½æº¯æ–¹æ¡ˆã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸºäºè®¡ç®—è®ºè¯ (Computational Argumentation) çš„è®ºè¯é›†æˆæ–¹æ³•ï¼Œé€šè¿‡æ˜¾å¼è¡¨ç¤ºæ¨¡å‹é¢„æµ‹ä¸åäº‹å®è§£é‡Šæœ‰æ•ˆæ€§ä¹‹é—´çš„å†²çªï¼Œå¹¶åˆ©ç”¨è®ºè¯è¯­ä¹‰ (Argumentation Semantics) è¿›è¡Œå†²çªæ¶ˆè§£ï¼Œä»è€Œç¡®ä¿è¿½æº¯åœ¨æ¨¡å‹å¤šæ ·æ€§ä¸‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å…è®¸æ ¹æ®éœ€æ±‚å¯¹é›†æˆä¸­çš„æ¨¡å‹è¿›è¡Œåå¥½æŒ‡å®šã€‚ç†è®ºåˆ†æä¸å…«ä¸ªå®ä¾‹çš„å®éªŒç»“æœå…±åŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆæ»¡è¶³é¢„è®¾å±æ€§ï¼Œä¸ºåœ¨å¤šæ¨¡å‹ç¯å¢ƒä¸‹å®ç°ç¨³å¥ä¸”å¯å®šåˆ¶çš„å†³ç­–è§£é‡Šæä¾›äº†æœ‰æ•ˆæ‰‹æ®µã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2312.15097",
      "pdf_url": "https://arxiv.org/pdf/2506.20260v1",
      "published_date": "2025-06-25 09:07:00 UTC",
      "updated_date": "2025-06-25 09:07:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:33:51.822331+00:00"
    },
    {
      "arxiv_id": "2506.20259v2",
      "title": "Generating and Customizing Robotic Arm Trajectories using Neural Networks",
      "title_zh": "åŸºäºç¥ç»ç½‘ç»œçš„æœºæ¢°è‡‚è½¨è¿¹ç”Ÿæˆä¸å®šåˆ¶",
      "authors": [
        "Andrej LÃºÄny",
        "Matilde Antonj",
        "Carlo Mazzola",
        "Hana HornÃ¡ÄkovÃ¡",
        "Igor FarkaÅ¡"
      ],
      "abstract": "We introduce a neural network approach for generating and customizing the trajectory of a robotic arm, that guarantees precision and repeatability. To highlight the potential of this novel method, we describe the design and implementation of the technique and show its application in an experimental setting of cognitive robotics. In this scenario, the NICO robot was characterized by the ability to point to specific points in space with precise linear movements, increasing the predictability of the robotic action during its interaction with humans. To achieve this goal, the neural network computes the forward kinematics of the robot arm. By integrating it with a generator of joint angles, another neural network was developed and trained on an artificial dataset created from suitable start and end poses of the robotic arm. Through the computation of angular velocities, the robot was characterized by its ability to perform the movement, and the quality of its action was evaluated in terms of shape and accuracy. Thanks to its broad applicability, our approach successfully generates precise trajectories that could be customized in their shape and adapted to different settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨ç¥ç»ç½‘ç»œ (Neural Networks) ç”Ÿæˆå’Œå®šåˆ¶æœºå™¨äººæ‰‹è‡‚è½¨è¿¹çš„æ–¹æ³•ï¼Œæ—¨åœ¨ä¿è¯åŠ¨ä½œçš„ç²¾ç¡®æ€§å’Œå¯é‡å¤æ€§ã€‚é€šè¿‡åœ¨è®¤çŸ¥æœºå™¨äºº (Cognitive Robotics) å®éªŒåœºæ™¯ä¸­åº”ç”¨ï¼ŒNICO æœºå™¨äººèƒ½å¤Ÿæ‰§è¡Œç²¾ç¡®çš„çº¿æ€§è¿åŠ¨æŒ‡å‘ç©ºé—´ç‰¹å®šç‚¹ï¼Œä»è€Œæ˜¾è‘—æé«˜äººæœºäº¤äº’ä¸­æœºå™¨äººåŠ¨ä½œçš„å¯é¢„æµ‹æ€§ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨ç¥ç»ç½‘ç»œè®¡ç®—æœºå™¨äººæ‰‹è‡‚çš„æ­£å‘è¿åŠ¨å­¦ (Forward Kinematics)ï¼Œå¹¶å°†å…¶ä¸å…³èŠ‚è§’åº¦ç”Ÿæˆå™¨ (Generator of Joint Angles) ç›¸é›†æˆã€‚ç ”ç©¶å›¢é˜Ÿåœ¨åŸºäºæœºå™¨äººèµ·å§‹ä¸ç»“æŸå§¿æ€æ„å»ºçš„äººé€ æ•°æ®é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå¹¶é€šè¿‡è§’é€Ÿåº¦ (Angular Velocities) è®¡ç®—æ¥è¯„ä¼°åŠ¨ä½œæ‰§è¡Œçš„å½¢çŠ¶ä¸ç²¾åº¦ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…èƒ½ç”Ÿæˆé«˜ç²¾åº¦è½¨è¿¹ï¼Œè¿˜èƒ½æ ¹æ®ä¸åŒåº”ç”¨åœºæ™¯å¯¹è½¨è¿¹å½¢çŠ¶è¿›è¡Œçµæ´»å®šåˆ¶ä¸é€‚é…ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "The code is released at https://github.com/andylucny/nico2/tree/main/generate",
      "pdf_url": "https://arxiv.org/pdf/2506.20259v2",
      "published_date": "2025-06-25 09:05:58 UTC",
      "updated_date": "2025-06-30 21:02:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:32:51.532809+00:00"
    },
    {
      "arxiv_id": "2506.20253v1",
      "title": "Time-series surrogates from energy consumers generated by machine learning approaches for long-term forecasting scenarios",
      "title_zh": "é¢å‘é•¿æœŸé¢„æµ‹åœºæ™¯çš„åŸºäºæœºå™¨å­¦ä¹ æ–¹æ³•çš„èƒ½æºç”¨æˆ·æ—¶é—´åºåˆ—ä»£ç†",
      "authors": [
        "Ben Gerhards",
        "Nikita Popkov",
        "Annekatrin KÃ¶nig",
        "Marcel Arpogaus",
        "Bastian SchÃ¤fermeier",
        "Leonie Riedl",
        "Stephan Vogt",
        "Philip Hehlert"
      ],
      "abstract": "Forecasting attracts a lot of research attention in the electricity value chain. However, most studies concentrate on short-term forecasting of generation or consumption with a focus on systems and less on individual consumers. Even more neglected is the topic of long-term forecasting of individual power consumption.\n  Here, we provide an in-depth comparative evaluation of data-driven methods for generating synthetic time series data tailored to energy consumption long-term forecasting. High-fidelity synthetic data is crucial for a wide range of applications, including state estimations in energy systems or power grid planning. In this study, we assess and compare the performance of multiple state-of-the-art but less common techniques: a hybrid Wasserstein Generative Adversarial Network (WGAN), Denoising Diffusion Probabilistic Model (DDPM), Hidden Markov Model (HMM), and Masked Autoregressive Bernstein polynomial normalizing Flows (MABF). We analyze the ability of each method to replicate the temporal dynamics, long-range dependencies, and probabilistic transitions characteristic of individual energy consumption profiles. Our comparative evaluation highlights the strengths and limitations of: WGAN, DDPM, HMM and MABF aiding in selecting the most suitable approach for state estimations and other energy-related tasks. Our generation and analysis framework aims to enhance the accuracy and reliability of synthetic power consumption data while generating data that fulfills criteria like anonymisation - preserving privacy concerns mitigating risks of specific profiling of single customers. This study utilizes an open-source dataset from households in Germany with 15min time resolution. The generated synthetic power profiles can readily be used in applications like state estimations or consumption forecasting.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µåŠ›ä»·å€¼é“¾ä¸­ä¸ªäººç”µåŠ›æ¶ˆè´¹é•¿æœŸé¢„æµ‹è¢«å¿½è§†çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€å¥—åŸºäºæ•°æ®é©±åŠ¨æ–¹æ³•çš„åˆæˆæ—¶é—´åºåˆ—æ•°æ®ç”Ÿæˆè¯„ä¼°æ¡†æ¶ã€‚ç ”ç©¶æ·±å…¥å¯¹æ¯”è¯„ä¼°äº† Wasserstein Generative Adversarial Network (WGAN)ã€Denoising Diffusion Probabilistic Model (DDPM)ã€Hidden Markov Model (HMM) ä»¥åŠ Masked Autoregressive Bernstein polynomial normalizing Flows (MABF) ç­‰å‰æ²¿æŠ€æœ¯åœ¨ç”Ÿæˆé«˜ä¿çœŸä¸ªäººç”¨èƒ½æ•°æ®æ–¹é¢çš„è¡¨ç°ã€‚é€šè¿‡åˆ†æè¿™äº›æ–¹æ³•å¯¹æ—¶é—´åŠ¨æ€ã€é•¿ç¨‹ä¾èµ–å’Œæ¦‚ç‡è½¬ç§»ç‰¹æ€§çš„æ•æ‰èƒ½åŠ›ï¼Œæœ¬æ–‡æ­ç¤ºäº†å„æ¨¡å‹åœ¨èƒ½æºç³»ç»ŸçŠ¶æ€ä¼°è®¡(state estimation)å’Œç”µç½‘è§„åˆ’ä¸­çš„é€‚ç”¨æ€§åŠå…¶å±€é™ã€‚å®éªŒåˆ©ç”¨å¾·å›½ä½æˆ·çš„15åˆ†é’Ÿåˆ†è¾¨ç‡æ•°æ®é›†ï¼Œè¯æ˜äº†ç”Ÿæˆçš„åˆæˆåŠŸç‡åˆ†å¸ƒ(power profiles)ä¸ä»…èƒ½æå‡é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œè¿˜é€šè¿‡åŒ¿ååŒ–å¤„ç†æœ‰æ•ˆç¼“è§£äº†ç”¨æˆ·éšç§å’Œç‰¹å®šç”»åƒåˆ†æçš„å®‰å…¨éšæ‚£ã€‚è¿™é¡¹ç ”ç©¶ä¸ºåœ¨ä¿æŠ¤éšç§çš„å‰æä¸‹ç”Ÿæˆå¯ç”¨äºé•¿æœŸé¢„æµ‹åœºæ™¯çš„é«˜è´¨é‡åˆæˆç”µåŠ›æ¶ˆè´¹æ•°æ®æä¾›äº†é‡è¦æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20253v1",
      "published_date": "2025-06-25 08:54:47 UTC",
      "updated_date": "2025-06-25 08:54:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:32:58.196042+00:00"
    },
    {
      "arxiv_id": "2506.20251v1",
      "title": "Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models",
      "title_zh": "Q-resafeï¼šé‡åŒ–å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨é£é™©è¯„ä¼°ä¸é‡åŒ–æ„ŸçŸ¥å®‰å…¨è¡¥ä¸",
      "authors": [
        "Kejia Chen",
        "Jiawen Zhang",
        "Jiacong Hu",
        "Yu Wang",
        "Jian Lou",
        "Zunlei Feng",
        "Mingli Song"
      ],
      "abstract": "Quantized large language models (LLMs) have gained increasing attention and significance for enabling deployment in resource-constrained environments. However, emerging studies on a few calibration dataset-free quantization methods suggest that quantization may compromise the safety capabilities of LLMs, underscoring the urgent need for systematic safety evaluations and effective mitigation strategies. In this paper, we present comprehensive safety evaluations across various mainstream quantization techniques and diverse calibration datasets, utilizing widely accepted safety benchmarks. To address the identified safety vulnerabilities, we propose a quantization-aware safety patching framework, Q-resafe, to efficiently restore the safety capabilities of quantized LLMs while minimizing any adverse impact on utility. Extensive experimental results demonstrate that Q-resafe successfully re-aligns the safety of quantized LLMs with their pre-quantization counterparts, even under challenging evaluation scenarios. Project page is available at: https://github.com/Thecommonirin/Qresafe.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡åŒ–å¤§è¯­è¨€æ¨¡å‹ (Quantized LLMs) åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„éƒ¨ç½²åŠå…¶æ½œåœ¨çš„å®‰å…¨é£é™©è¿›è¡Œäº†ç³»ç»Ÿæ€§æ¢è®¨ã€‚ç ”ç©¶å‘ç°ä¸»æµçš„é‡åŒ– (Quantization) æŠ€æœ¯å¯èƒ½å¯¼è‡´æ¨¡å‹å®‰å…¨æ€§ä¸‹é™ï¼Œä¸ºæ­¤ä½œè€…åˆ©ç”¨å¤šç§å®‰å…¨åŸºå‡† (Safety benchmarks) å¯¹ä¸åŒé‡åŒ–æ–¹æ³•å’Œæ ¡å‡†æ•°æ®é›†è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚ä¸ºä¿®å¤è¿™äº›å®‰å…¨æ¼æ´ï¼Œè®ºæ–‡æå‡ºäº† Q-resafe æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§æ„ŸçŸ¥é‡åŒ–çš„å®‰å…¨è¡¥ä¸ (Quantization-aware safety patching) æ–¹æ¡ˆï¼Œæ—¨åœ¨é«˜æ•ˆæ¢å¤é‡åŒ–æ¨¡å‹çš„å®‰å…¨èƒ½åŠ›å¹¶æœ€å°åŒ–å¯¹å®ç”¨æ€§çš„è´Ÿé¢å½±å“ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒQ-resafe å³ä½¿åœ¨æŒ‘æˆ˜æ€§çš„è¯„ä¼°åœºæ™¯ä¸‹ï¼Œä¹Ÿèƒ½æˆåŠŸå°†é‡åŒ–æ¨¡å‹çš„å®‰å…¨æ€§é‡æ–°å¯¹é½è‡³é‡åŒ–å‰çš„æ°´å¹³ã€‚è¯¥æ¡†æ¶ä¸ºç¡®ä¿é‡åŒ–æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å®‰å…¨æ€§æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.20251v1",
      "published_date": "2025-06-25 08:52:22 UTC",
      "updated_date": "2025-06-25 08:52:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:32:57.188576+00:00"
    },
    {
      "arxiv_id": "2506.20249v1",
      "title": "Language Modeling by Language Models",
      "title_zh": "ç”±è¯­è¨€æ¨¡å‹å®ç°çš„è¯­è¨€å»ºæ¨¡",
      "authors": [
        "Junyan Cheng",
        "Peter Clark",
        "Kyle Richardson"
      ],
      "abstract": "Can we leverage LLMs to model the process of discovering novel language model (LM) architectures? Inspired by real research, we propose a multi-agent LLM approach that simulates the conventional stages of research, from ideation and literature search (proposal stage) to design implementation (code generation), generative pre-training, and downstream evaluation (verification). Using ideas from scaling laws, our system, Genesys, employs a Ladder of Scales approach; new designs are proposed, adversarially reviewed, implemented, and selectively verified at increasingly larger model scales (14M$\\sim$350M parameters) with a narrowing budget (the number of models we can train at each scale). To help make discovery efficient and factorizable, Genesys uses a novel genetic programming backbone, which we show has empirical advantages over commonly used direct prompt generation workflows (e.g., $\\sim$86\\% percentage point improvement in successful design generation, a key bottleneck). We report experiments involving 1,162 newly discovered designs (1,062 fully verified through pre-training) and find the best designs to be highly competitive with known architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common benchmarks). We couple these results with comprehensive system-level ablations and formal results, which give broader insights into the design of effective autonomous discovery systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æ¥è‡ªåŠ¨å‘ç°æ–°å‹è¯­è¨€æ¨¡å‹(LM)æ¶æ„ï¼Œå¹¶æå‡ºäº†åä¸ºGenesysçš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚Genesysæ¨¡æ‹Ÿäº†ä»æ„æ€ã€æ–‡çŒ®æ£€ç´¢åˆ°ä»£ç å®ç°ã€é¢„è®­ç»ƒåŠä¸‹æ¸¸è¯„ä¼°çš„å®Œæ•´ç ”ç©¶é˜¶æ®µã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨äº†åŸºäºç¼©æ”¾æ³•åˆ™(Scaling Laws)çš„é˜¶æ¢¯å¼è§„æ¨¡(Ladder of Scales)æ–¹æ³•ï¼Œé€šè¿‡å¯¹æŠ—æ€§è¯„å®¡å’Œåœ¨14Mè‡³350Må‚æ•°è§„æ¨¡ä¸‹çš„é€çº§éªŒè¯æ¥ç­›é€‰ä¼˜ç§€è®¾è®¡ã€‚Genesyså¼•å…¥äº†åˆ›æ–°çš„é—ä¼ ç¼–ç¨‹(Genetic Programming)éª¨å¹²ç½‘ç»œï¼Œåœ¨è®¾è®¡ç”Ÿæˆçš„æˆåŠŸç‡ä¸Šæ¯”ä¼ ç»Ÿçš„ç›´æ¥æç¤º(Direct Prompt)å·¥ä½œæµæå‡äº†çº¦86%ã€‚å®éªŒå…±å‘ç°äº†1,162ç§æ–°è®¾è®¡ï¼Œå…¶ä¸­1,062ç§é€šè¿‡äº†å®Œæ•´çš„é¢„è®­ç»ƒéªŒè¯ï¼Œæœ€ä¼˜è®¾è®¡åœ¨9é¡¹å¸¸ç”¨åŸºå‡†æµ‹è¯•ä¸­çš„6é¡¹è¡¨ç°ä¼˜äºGPT2å’ŒMamba2ç­‰å·²çŸ¥æ¶æ„ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡ç³»ç»Ÿçº§æ¶ˆèå®éªŒå’Œç†è®ºç»“æœï¼Œä¸ºæ„å»ºé«˜æ•ˆçš„æ¶æ„è‡ªä¸»å‘ç°ç³»ç»Ÿæä¾›äº†æ·±å…¥è§è§£ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20249v1",
      "published_date": "2025-06-25 08:46:10 UTC",
      "updated_date": "2025-06-25 08:46:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:33:10.523233+00:00"
    },
    {
      "arxiv_id": "2506.20694v1",
      "title": "Evaluating PDE discovery methods for multiscale modeling of biological signals",
      "title_zh": "è¯„ä¼°ç”¨äºç”Ÿç‰©ä¿¡å·å¤šå°ºåº¦å»ºæ¨¡çš„åå¾®åˆ†æ–¹ç¨‹å‘ç°æ–¹æ³•",
      "authors": [
        "AndrÃ©a Ducos",
        "Audrey Denizot",
        "Thomas Guyet",
        "Hugues Berry"
      ],
      "abstract": "Biological systems are non-linear, include unobserved variables and the physical principles that govern their dynamics are partly unknown. This makes the characterization of their behavior very challenging. Notably, their activity occurs on multiple interdependent spatial and temporal scales that require linking mechanisms across scales. To address the challenge of bridging gaps between scales, we leverage partial differential equations (PDE) discovery. PDE discovery suggests meso-scale dynamics characteristics from micro-scale data. In this article, we present our framework combining particle-based simulations and PDE discovery and conduct preliminary experiments to assess equation discovery in controlled settings. We evaluate five state-of-the-art PDE discovery methods on particle-based simulations of calcium diffusion in astrocytes. The performances of the methods are evaluated on both the form of the discovered equation and the forecasted temporal variations of calcium concentration. Our results show that several methods accurately recover the diffusion term, highlighting the potential of PDE discovery for capturing macroscopic dynamics in biological systems from microscopic data.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿç‰©ç³»ç»Ÿéçº¿æ€§åŠè·¨å°ºåº¦ç‰©ç†è§„å¾‹æœªçŸ¥çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªç»“åˆ particle-based simulations ä¸ PDE discovery çš„ç ”ç©¶æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¾®è§‚æ•°æ®è¡¨å¾ä¸­è§‚å°ºåº¦çš„åŠ¨åŠ›å­¦ç‰¹å¾ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ astrocytes çš„é’™æ‰©æ•£æ¨¡æ‹Ÿåœºæ™¯ä¸‹ï¼Œå¯¹äº”ç§æœ€å…ˆè¿›çš„ PDE discovery æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”è¯„ä¼°ã€‚è¯„ä¼°è¿‡ç¨‹é‡ç‚¹è€ƒæŸ¥äº†å‘ç°æ–¹ç¨‹çš„æ•°å­¦å½¢å¼ä»¥åŠå¯¹é’™æµ“åº¦æ—¶é—´å˜åŒ–çš„é¢„æµ‹ç²¾åº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¤šç§æ–¹æ³•å‡èƒ½å‡†ç¡®æ¢å¤ diffusion termï¼ŒéªŒè¯äº† PDE discovery åœ¨æ•æ‰ç”Ÿç‰©ç³»ç»Ÿå®è§‚åŠ¨åŠ›å­¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¯¥å·¥ä½œä¸ºè·¨å°ºåº¦ç”Ÿç‰©ä¿¡å·å»ºæ¨¡æä¾›äº†é‡è¦çš„åŸºå‡†è¯„ä¼°ï¼Œå±•ç¤ºäº†ä»å¾®è§‚æ¨¡æ‹Ÿä¸­æå–å®è§‚ç‰©ç†è§„å¾‹çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20694v1",
      "published_date": "2025-06-25 08:43:37 UTC",
      "updated_date": "2025-06-25 08:43:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:33:14.714951+00:00"
    },
    {
      "arxiv_id": "2507.22897v1",
      "title": "RecUserSim: A Realistic and Diverse User Simulator for Evaluating Conversational Recommender Systems",
      "title_zh": "RecUserSimï¼šç”¨äºè¯„ä¼°å¯¹è¯å¼æ¨èç³»ç»Ÿçš„çœŸå®å¤šæ ·åŒ–ç”¨æˆ·æ¨¡æ‹Ÿå™¨",
      "authors": [
        "Luyu Chen",
        "Quanyu Dai",
        "Zeyu Zhang",
        "Xueyang Feng",
        "Mingyu Zhang",
        "Pengcheng Tang",
        "Xu Chen",
        "Yue Zhu",
        "Zhenhua Dong"
      ],
      "abstract": "Conversational recommender systems (CRS) enhance user experience through multi-turn interactions, yet evaluating CRS remains challenging. User simulators can provide comprehensive evaluations through interactions with CRS, but building realistic and diverse simulators is difficult. While recent work leverages large language models (LLMs) to simulate user interactions, they still fall short in emulating individual real users across diverse scenarios and lack explicit rating mechanisms for quantitative evaluation. To address these gaps, we propose RecUserSim, an LLM agent-based user simulator with enhanced simulation realism and diversity while providing explicit scores. RecUserSim features several key modules: a profile module for defining realistic and diverse user personas, a memory module for tracking interaction history and discovering unknown preferences, and a core action module inspired by Bounded Rationality theory that enables nuanced decision-making while generating more fine-grained actions and personalized responses. To further enhance output control, a refinement module is designed to fine-tune final responses. Experiments demonstrate that RecUserSim generates diverse, controllable outputs and produces realistic, high-quality dialogues, even with smaller base LLMs. The ratings generated by RecUserSim show high consistency across different base LLMs, highlighting its effectiveness for CRS evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RecUserSimï¼Œä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“çš„ç”¨æˆ·æ¨¡æ‹Ÿå™¨ï¼Œæ—¨åœ¨è§£å†³å¯¹è¯å¼æ¨èç³»ç»Ÿ(CRS)è¯„ä¼°ä¸­æ¨¡æ‹ŸçœŸå®æ€§ä¸å¤šæ ·æ€§ä¸è¶³ä¸”ç¼ºä¹æ˜¾å¼è¯„åˆ†æœºåˆ¶çš„é—®é¢˜ã€‚RecUserSimé€šè¿‡ç”»åƒæ¨¡å—(Profile module)å®šä¹‰å¤šå…ƒç”¨æˆ·ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨è®°å¿†æ¨¡å—(Memory module)è¿½è¸ªäº¤äº’å†å²ä»¥æŒ–æ˜ç”¨æˆ·åå¥½ã€‚å…¶æ ¸å¿ƒåŠ¨ä½œæ¨¡å—å—æœ‰é™ç†æ€§(Bounded Rationality)ç†è®ºå¯å‘ï¼Œæ”¯æŒç»†ç²’åº¦çš„å†³ç­–åˆ¶å®šä¸ä¸ªæ€§åŒ–å“åº”ç”Ÿæˆã€‚æ­¤å¤–ï¼Œç³»ç»Ÿå¼•å…¥ç²¾ç‚¼æ¨¡å—(Refinement module)ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–è¾“å‡ºçš„å¯æ§æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRecUserSimå³ä½¿åœ¨è¾ƒå°çš„åŸºç¡€æ¨¡å‹ä¸Šä¹Ÿèƒ½ç”Ÿæˆé«˜è´¨é‡ã€çœŸå®çš„å¯¹è¯ï¼Œä¸”å…¶ç”Ÿæˆçš„è¯„åˆ†åœ¨ä¸åŒæ¨¡å‹é—´å…·æœ‰é«˜åº¦ä¸€è‡´æ€§ï¼Œæœ‰æ•ˆæå‡äº†CRSè¯„ä¼°çš„å¯é æ€§ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted by TheWebConf'25 Industry Track",
      "pdf_url": "https://arxiv.org/pdf/2507.22897v1",
      "published_date": "2025-06-25 08:42:46 UTC",
      "updated_date": "2025-06-25 08:42:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:33:17.833460+00:00"
    },
    {
      "arxiv_id": "2506.20245v1",
      "title": "FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data",
      "title_zh": "FedBKDï¼šå…¼é¡¾éç‹¬ç«‹åŒåˆ†å¸ƒæ•°æ®æ³›åŒ–æ€§ä¸ä¸ªæ€§åŒ–çš„è’¸é¦è”é‚¦å­¦ä¹ ",
      "authors": [
        "Yushan Zhao",
        "Jinyuan He",
        "Donglai Chen",
        "Weijie Luo",
        "Chong Xie",
        "Ri Zhang",
        "Yonghong Chen",
        "Yan Xu"
      ],
      "abstract": "Federated learning (FL) is a decentralized collaborative machine learning (ML) technique. It provides a solution to the issues of isolated data islands and data privacy leakage in industrial ML practices. One major challenge in FL is handling the non-identical and independent distributed (non-IID) data. Current solutions either focus on constructing an all-powerful global model, or customizing personalized local models. Few of them can provide both a well-generalized global model and well-performed local models at the same time. Additionally, many FL solutions to the non-IID problem are benefited from introducing public datasets. However, this will also increase the risk of data leakage. To tackle the problems, we propose a novel data-free distillation framework, Federated Bidirectional Knowledge Distillation (FedBKD). Specifically, we train Generative Adversarial Networks (GAN) for synthetic data. During the GAN training, local models serve as discriminators and their parameters are frozen. The synthetic data is then used for bidirectional distillation between global and local models to achieve knowledge interactions so that performances for both sides are improved. We conduct extensive experiments on 4 benchmarks under different non-IID settings. The results show that FedBKD achieves SOTA performances in every case.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FedBKDï¼Œä¸€ç§æ—¨åœ¨åŒæ—¶æå‡è”é‚¦å­¦ä¹ (Federated Learning)åœ¨éç‹¬ç«‹åŒåˆ†å¸ƒ(Non-IID)æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›ä¸ä¸ªæ€§åŒ–æ€§èƒ½çš„åŒå‘çŸ¥è¯†è’¸é¦æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•éš¾ä»¥å…¼é¡¾å…¨å±€æ¨¡å‹æ³›åŒ–ä¸å±€éƒ¨æ¨¡å‹è¡¨ç°ï¼Œä¸”ä¾èµ–å…¬å…±æ•°æ®å¯èƒ½å¯¼è‡´éšç§æ³„éœ²çš„é—®é¢˜ï¼ŒFedBKD å¼•å…¥äº†æ— æ•°æ®è’¸é¦(Data-free Distillation)æœºåˆ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡è®­ç»ƒç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(Generative Adversarial Networks, GAN)äº§ç”Ÿåˆæˆæ•°æ®ï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­å°†å±€éƒ¨æ¨¡å‹ä½œä¸ºå‚æ•°å†»ç»“çš„åˆ¤åˆ«å™¨ã€‚åˆ©ç”¨è¿™äº›åˆæˆæ•°æ®ï¼Œå…¨å±€æ¨¡å‹ä¸å±€éƒ¨æ¨¡å‹ä¹‹é—´è¿›è¡ŒåŒå‘çŸ¥è¯†è’¸é¦(Bidirectional Distillation)ï¼Œä»è€Œå®ç°æ·±å±‚çŸ¥è¯†äº¤äº’å¹¶ä¼˜åŒ–åŒæ–¹æ€§èƒ½ã€‚åœ¨å››ä¸ªä¸»æµåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒFedBKD åœ¨å¤šç§ Non-IID è®¾ç½®ä¸‹å‡å–å¾—äº†å½“å‰æœ€ä¼˜(SOTA)çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20245v1",
      "published_date": "2025-06-25 08:42:10 UTC",
      "updated_date": "2025-06-25 08:42:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:33:16.064944+00:00"
    },
    {
      "arxiv_id": "2506.20243v1",
      "title": "CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment",
      "title_zh": "CBF-AFAï¼šåŸºäºåˆ†å—å¤šè‡ªç›‘ç£å­¦ä¹ èåˆçš„è‡ªåŠ¨æµåˆ©åº¦è¯„ä¼°",
      "authors": [
        "Papa SÃ©ga Wade",
        "Mihai Andries",
        "Ioannis Kanellos",
        "Thierry Moudenc"
      ],
      "abstract": "Automatic fluency assessment (AFA) remains challenging, particularly in capturing speech rhythm, pauses, and disfluencies in non-native speakers. We introduce a chunk-based approach integrating self-supervised learning (SSL) models (Wav2Vec2, HuBERT, and WavLM) selected for their complementary strengths in phonetic, prosodic, and noisy speech modeling, with a hierarchical CNN-BiLSTM framework. Speech is segmented into breath-group chunks using Silero voice activity detection (Silero-VAD), enabling fine-grained temporal analysis while mitigating over-segmentation artifacts. SSL embeddings are fused via a learnable weighted mechanism, balancing acoustic and linguistic features, and enriched with chunk-level fluency markers (e.g., speech rate, pause durations, n-gram repetitions). The CNN-BiLSTM captures local and long-term dependencies across chunks. Evaluated on Avalinguo and Speechocean762, our approach improves F1-score by 2.8 and Pearson correlation by 6.2 points over single SSL baselines on Speechocean762, with gains of 4.2 F1-score and 4.0 Pearson points on Avalinguo, surpassing Pyannote.audio-based segmentation baselines. These findings highlight chunk-based multi-SSL fusion for robust fluency evaluation, though future work should explore generalization to dialects with irregular prosody.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CBF-AFAï¼Œä¸€ç§åŸºäºåˆ†å—çš„å¤šè‡ªç›‘ç£å­¦ä¹ (Multi-SSL)èåˆæ¡†æ¶ï¼Œæ—¨åœ¨æå‡éæ¯è¯­è€…çš„è‡ªåŠ¨æµç•…åº¦è¯„ä¼°(AFA)æ€§èƒ½ã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆWav2Vec2ã€HuBERTå’ŒWavLMç­‰å…·æœ‰äº’è¡¥ä¼˜åŠ¿çš„SSLæ¨¡å‹ï¼Œå¹¶ç»“åˆå±‚æ¬¡åŒ–CNN-BiLSTMæ¶æ„ï¼Œæœ‰æ•ˆæ•æ‰è¯­éŸ³èŠ‚å¥ã€åœé¡¿åŠä¸æµç•…ç‰¹å¾ã€‚ç ”ç©¶åˆ©ç”¨Silero-VADå°†è¯­éŸ³åˆ‡åˆ†ä¸ºå‘¼å¸ç»„åˆ†å—(breath-group chunks)ï¼Œå¹¶é€šè¿‡å¯å­¦ä¹ çš„åŠ æƒæœºåˆ¶èåˆSSLåµŒå…¥ä¸åˆ†å—çº§æµç•…åº¦æŒ‡æ ‡ã€‚åœ¨Avalinguoå’ŒSpeechocean762æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCBF-AFAåœ¨F1åˆ†æ•°å’ŒPearsonç›¸å…³ç³»æ•°ä¸Šå‡æ˜¾è‘—ä¼˜äºå•ä¸€SSLåŸºçº¿åŠåŸºäºPyannote.audioçš„åˆ†å‰²æ–¹æ¡ˆã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº†åŸºäºåˆ†å—çš„å¤šæ¨¡å‹èåˆæŠ€æœ¯åœ¨é²æ£’æ€§è¯­éŸ³è¯„ä¼°ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¤„ç†å¤æ‚çš„éæ¯è¯­è¯­éŸ³ç‰¹å¾æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, accepted for presentation at EUSIPCO 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.20243v1",
      "published_date": "2025-06-25 08:39:22 UTC",
      "updated_date": "2025-06-25 08:39:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:33:28.197064+00:00"
    },
    {
      "arxiv_id": "2507.02915v1",
      "title": "Audio-JEPA: Joint-Embedding Predictive Architecture for Audio Representation Learning",
      "title_zh": "Audio-JEPAï¼šé¢å‘éŸ³é¢‘è¡¨ç¤ºå­¦ä¹ çš„è”åˆåµŒå…¥é¢„æµ‹æ¶æ„",
      "authors": [
        "Ludovic Tuncay",
        "Etienne LabbÃ©",
        "Emmanouil Benetos",
        "Thomas Pellegrini"
      ],
      "abstract": "Building on the Joint-Embedding Predictive Architecture (JEPA) paradigm, a recent self-supervised learning framework that predicts latent representations of masked regions in high-level feature spaces, we propose Audio-JEPA (Audio Joint-Embedding Predictive Architecture), tailored specifically for audio data. Audio-JEPA uses a simple Vision Transformer backbone to predict latent representations of masked spectrogram patches rather than reconstructing raw audio. We pre-train on unlabeled AudioSet clips (10s, 32kHz) with random patch masking on mel-spectrograms. We evaluate on the X-ARES suite covering speech, music, and environmental sound tasks. Although our implementation is a straightforward translation of the original model to audio, the results still show comparable performance to wav2vec 2.0 and data2vec while using less than one-fifth of their training data and with no hyper-parameter tuning. All code and pretrained checkpoints will be released on GitHub.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Audio-JEPAï¼Œä¸€ç§ä¸“é—¨ä¸ºéŸ³é¢‘æ•°æ®è®¾è®¡çš„è”åˆåµŒå…¥é¢„æµ‹æ¶æ„(Joint-Embedding Predictive Architecture)ï¼Œæ—¨åœ¨é€šè¿‡è‡ªç›‘ç£å­¦ä¹ ä¼˜åŒ–éŸ³é¢‘è¡¨ç¤ºå­¦ä¹ ã€‚è¯¥æ¨¡å‹é‡‡ç”¨Vision Transformerä½œä¸ºéª¨å¹²ç½‘ç»œï¼Œæ ¸å¿ƒæ–¹æ³•æ˜¯é¢„æµ‹æ¢…å°”é¢‘è°±å›¾(mel-spectrograms)ä¸­è¢«é®è”½åŒºåŸŸçš„é«˜å±‚æ½œåœ¨è¡¨ç¤ºï¼Œè€Œéç›´æ¥é‡å»ºåŸå§‹éŸ³é¢‘ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨æœªç»æ ‡æ³¨çš„AudioSetæ•°æ®é›†ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼Œå¹¶é€šè¿‡æ¶µç›–è¯­éŸ³ã€éŸ³ä¹å’Œç¯å¢ƒéŸ³ä»»åŠ¡çš„X-ARESå¥—ä»¶éªŒè¯äº†æ¨¡å‹æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAudio-JEPAçš„æ€§èƒ½å¯ä¸wav2vec 2.0å’Œdata2vecç›¸åª²ç¾ï¼Œä¸”åœ¨æœªè¿›è¡Œè¶…å‚æ•°è°ƒä¼˜çš„æƒ…å†µä¸‹ï¼Œå…¶è®­ç»ƒæ•°æ®é‡ä»…éœ€ä¸Šè¿°æ¨¡å‹çš„ä¸åˆ°äº”åˆ†ä¹‹ä¸€ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†JEPAèŒƒå¼åœ¨éŸ³é¢‘å¤„ç†ä¸­çš„é«˜æ•ˆæ€§ï¼Œå¹¶ä¸ºèµ„æºå—é™ä¸‹çš„è‡ªç›‘ç£è¡¨ç¤ºå­¦ä¹ æä¾›äº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.02915v1",
      "published_date": "2025-06-25 08:38:27 UTC",
      "updated_date": "2025-06-25 08:38:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:34:16.949501+00:00"
    },
    {
      "arxiv_id": "2506.20241v1",
      "title": "Enhancing Large Language Models through Structured Reasoning",
      "title_zh": "é€šè¿‡ç»“æ„åŒ–æ¨ç†å¢å¼ºå¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Yubo Dong",
        "Hehe Fan"
      ],
      "abstract": "Recent Large Language Models (LLMs) have significantly advanced natural language processing and automated decision-making. However, these models still encounter difficulties when performing complex reasoning tasks involving logical deduction and systematic planning, primarily due to their reliance on implicit statistical relationships without structured knowledge representation.Inspired by cognitive science and neurosymbolic AI, we introduce a novel approach to enhance LLMs through explicit structured reasoning. First, we convert unstructured data into structured formats by explicitly annotating reasoning steps. We then employ this structured dataset to train LLMs through Supervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning capabilities of LLMs using Group Relative Policy Optimization (GRPO), incorporating two innovative algorithms--MAX-Flow and Longest Common Subsequence (LCS)--which notably improve reasoning effectiveness and reduce computational complexity. Experimental results from fine-tuning a DeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust performance across various scenarios, and improved compatibility with optimization techniques, validating the efficacy of structured reasoning integration in LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†é€»è¾‘æ¼”ç»å’Œç³»ç»Ÿè§„åˆ’ç­‰å¤æ‚æ¨ç†ä»»åŠ¡æ—¶ï¼Œå› è¿‡åº¦ä¾èµ–éšå¼ç»Ÿè®¡å…³ç³»è€Œç¼ºä¹ç»“æ„åŒ–çŸ¥è¯†è¡¨ç¤ºçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å—è®¤çŸ¥ç§‘å­¦å’Œç¥ç»ç¬¦å·AI(Neurosymbolic AI)å¯å‘çš„æ˜¾å¼ç»“æ„åŒ–æ¨ç†å¢å¼ºæ–¹æ³•ã€‚è¯¥æ–¹æ³•é¦–å…ˆé€šè¿‡æ ‡æ³¨æ¨ç†æ­¥éª¤å°†éç»“æ„åŒ–æ•°æ®è½¬åŒ–ä¸ºç»“æ„åŒ–æ ¼å¼ï¼Œå¹¶é‡‡ç”¨ç›‘ç£å¾®è°ƒ(SFT)è¿›è¡Œè®­ç»ƒã€‚æ­¤å¤–ï¼Œç ”ç©¶åˆ©ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)ç»“åˆMAX-Flowå’Œæœ€é•¿å…¬å…±å­åºåˆ—(LCS)ä¸¤ç§åˆ›æ–°ç®—æ³•ï¼Œåœ¨æ˜¾è‘—æå‡æ¨ç†æ•ˆæœçš„åŒæ—¶é™ä½äº†è®¡ç®—å¤æ‚åº¦ã€‚åœ¨DeepSeek-R1-Distill-Qwen-1.5Bæ¨¡å‹ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½ä½¿æ¨¡å‹å®ç°ç®€æ´çš„æ¨ç†è¿‡ç¨‹å¹¶åœ¨å¤šç§åœºæ™¯ä¸‹å±•ç°å‡ºç¨³å¥çš„æ€§èƒ½è¡¨ç°ã€‚è¿™ä¸€æˆæœæœ‰æ•ˆéªŒè¯äº†ç»“æ„åŒ–æ¨ç†é›†æˆåœ¨LLMsä¸­çš„å¯è¡Œæ€§ï¼Œå¹¶å¢å¼ºäº†æ¨¡å‹ä¸å…ˆè¿›ä¼˜åŒ–æŠ€æœ¯çš„å…¼å®¹æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. Under review",
      "pdf_url": "https://arxiv.org/pdf/2506.20241v1",
      "published_date": "2025-06-25 08:36:12 UTC",
      "updated_date": "2025-06-25 08:36:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:34:08.443879+00:00"
    },
    {
      "arxiv_id": "2506.20235v1",
      "title": "Directed Link Prediction using GNN with Local and Global Feature Fusion",
      "title_zh": "èåˆå±€éƒ¨ä¸å…¨å±€ç‰¹å¾çš„ GNN æœ‰å‘é“¾è·¯é¢„æµ‹",
      "authors": [
        "Yuyang Zhang",
        "Xu Shen",
        "Yu Xie",
        "Ka-Chun Wong",
        "Weidun Xie",
        "Chengbin Peng"
      ],
      "abstract": "Link prediction is a classical problem in graph analysis with many practical applications. For directed graphs, recently developed deep learning approaches typically analyze node similarities through contrastive learning and aggregate neighborhood information through graph convolutions. In this work, we propose a novel graph neural network (GNN) framework to fuse feature embedding with community information. We theoretically demonstrate that such hybrid features can improve the performance of directed link prediction. To utilize such features efficiently, we also propose an approach to transform input graphs into directed line graphs so that nodes in the transformed graph can aggregate more information during graph convolutions. Experiments on benchmark datasets show that our approach outperforms the state-of-the-art in most cases when 30%, 40%, 50%, and 60% of the connected links are used as training data, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœ‰å‘å›¾ä¸­çš„é“¾æ¥é¢„æµ‹(Link prediction)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§èåˆç‰¹å¾åµŒå…¥(feature embedding)ä¸ç¤¾åŒºä¿¡æ¯(community information)çš„æ–°å‹å›¾ç¥ç»ç½‘ç»œ(GNN)æ¡†æ¶ã€‚ä½œè€…åœ¨ç†è®ºä¸Šè¯æ˜äº†è¿™ç§ç»“åˆå±€éƒ¨ç‰¹å¾ä¸å…¨å±€ç¤¾åŒºä¿¡æ¯çš„æ··åˆç‰¹å¾èƒ½å¤Ÿæœ‰æ•ˆå¢å¼ºæœ‰å‘é“¾æ¥é¢„æµ‹çš„æ€§èƒ½ã€‚ä¸ºäº†æå‡ç‰¹å¾åˆ©ç”¨æ•ˆç‡ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†æœ‰å‘çº¿å›¾(directed line graphs)è½¬æ¢æŠ€æœ¯ï¼Œä½¿èŠ‚ç‚¹åœ¨å›¾å·ç§¯(graph convolutions)è¿‡ç¨‹ä¸­èƒ½å¤Ÿæ•è·æ›´æ·±å±‚çš„æ‹“æ‰‘ä¿¡æ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨30%è‡³60%ç­‰ä¸åŒè®­ç»ƒæ•°æ®æ¯”ä¾‹ä¸‹ï¼Œè¯¥ç®—æ³•åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°å‡è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›(state-of-the-art)æ–¹æ¡ˆã€‚è¯¥æ¡†æ¶é€šè¿‡å±€éƒ¨ä¸å…¨å±€ç‰¹å¾çš„æ·±åº¦èåˆï¼Œä¸ºå¤„ç†å…·æœ‰å¤æ‚æ–¹å‘æ€§ç‰¹å¾çš„å›¾æ•°æ®æŒ–æ˜ä»»åŠ¡æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20235v1",
      "published_date": "2025-06-25 08:25:56 UTC",
      "updated_date": "2025-06-25 08:25:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:34:17.787231+00:00"
    },
    {
      "arxiv_id": "2506.20209v2",
      "title": "Perspectives in Play: A Multi-Perspective Approach for More Inclusive NLP Systems",
      "title_zh": "è§†è§’çš„åšå¼ˆï¼šä¸€ç§é¢å‘æ›´å…·åŒ…å®¹æ€§ NLP ç³»ç»Ÿçš„å¤šè§†è§’æ–¹æ³•",
      "authors": [
        "Benedetta Muscato",
        "Lucia Passaro",
        "Gizem Gezici",
        "Fosca Giannotti"
      ],
      "abstract": "In the realm of Natural Language Processing (NLP), common approaches for handling human disagreement consist of aggregating annotators' viewpoints to establish a single ground truth. However, prior studies show that disregarding individual opinions can lead can lead to the side effect of underrepresenting minority perspectives, especially in subjective tasks, where annotators may systematically disagree because of their preferences. Recognizing that labels reflect the diverse backgrounds, life experiences, and values of individuals, this study proposes a new multi-perspective approach using soft labels to encourage the development of the next generation of perspective aware models, more inclusive and pluralistic. We conduct an extensive analysis across diverse subjective text classification tasks, including hate speech, irony, abusive language, and stance detection, to highlight the importance of capturing human disagreements, often overlooked by traditional aggregation methods. Results show that the multi-perspective approach not only better approximates human label distributions, as measured by Jensen-Shannon Divergence (JSD), but also achieves superior classification performance (higher F1 scores), outperforming traditional approaches. However, our approach exhibits lower confidence in tasks like irony and stance detection, likely due to the inherent subjectivity present in the texts. Lastly, leveraging Explainable AI (XAI), we explore model uncertainty and uncover meaningful insights into model predictions.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹è‡ªç„¶è¯­è¨€å¤„ç†(NLP)é¢†åŸŸä¸­ä¼ ç»Ÿèšåˆæ ‡æ³¨è€…è§‚ç‚¹ã€å»ºç«‹å•ä¸€æ ‡å‡†ç­”æ¡ˆ(ground truth)ä¼šå¯¼è‡´å°‘æ•°ç¾¤ä½“è§‚ç‚¹ä»£è¡¨æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ—¨åœ¨æ„å»ºæ›´å…·åŒ…å®¹æ€§å’Œå¤šå…ƒåŒ–ç³»ç»Ÿçš„å¤šè§†è§’æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨è½¯æ ‡ç­¾(soft labels)æŠ€æœ¯ï¼Œæ—¨åœ¨é€šè¿‡æ•æ‰æ ‡æ³¨è€…ä¹‹é—´çš„åˆ†æ­§æ¥å¼€å‘è§†è§’æ•æ„Ÿ(perspective aware)çš„æ¨¡å‹ã€‚ç ”ç©¶äººå‘˜åœ¨ä»‡æ¨è¨€è®º(hate speech)ã€è®½åˆº(irony)ã€è¾±éª‚æ€§è¯­è¨€(abusive language)å’Œç«‹åœºæ£€æµ‹(stance detection)ç­‰å¤šä¸ªä¸»è§‚åˆ†ç±»ä»»åŠ¡ä¸Šè¿›è¡Œäº†æ·±å…¥å®éªŒã€‚ç»“æœæ˜¾ç¤ºï¼Œè¯¥å¤šè§†è§’æ–¹æ³•ä¸ä»…åœ¨Jensen-Shannon Divergence (JSD)æŒ‡æ ‡ä¸Šæ›´æ¥è¿‘çœŸå®çš„äººç±»æ ‡ç­¾åˆ†å¸ƒï¼Œä¸”åœ¨åˆ†ç±»æ€§èƒ½(F1 scores)ä¸Šä¼˜äºä¼ ç»Ÿçš„èšåˆå¤„ç†æ–¹æ³•ã€‚å°½ç®¡åœ¨è®½åˆºå’Œç«‹åœºæ£€æµ‹ç­‰é«˜åº¦ä¸»è§‚çš„ä»»åŠ¡ä¸­æ¨¡å‹é¢„æµ‹ç½®ä¿¡åº¦æœ‰æ‰€ä¸‹é™ï¼Œä½†ç»“åˆå¯è§£é‡Šäººå·¥æ™ºèƒ½(Explainable AI, XAI)çš„åˆ†æä¸ºç†è§£æ¨¡å‹çš„ä¸ç¡®å®šæ€§æä¾›äº†é‡è¦çš„å­¦æœ¯æ´å¯Ÿã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20209v2",
      "published_date": "2025-06-25 07:53:36 UTC",
      "updated_date": "2026-01-12 16:32:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:34:18.474064+00:00"
    },
    {
      "arxiv_id": "2506.20204v1",
      "title": "Affective Priming Score: A Data-Driven Method to Detect Priming in Sequential Datasets",
      "title_zh": "æƒ…æ„Ÿå¯åŠ¨è¯„åˆ†ï¼šä¸€ç§æ£€æµ‹åºåˆ—æ•°æ®ä¸­å¯åŠ¨æ•ˆåº”çš„æ•°æ®é©±åŠ¨æ–¹æ³•",
      "authors": [
        "Eduardo Gutierrez Maestro",
        "Hadi Banaee",
        "Amy Loutfi"
      ],
      "abstract": "Affective priming exemplifies the challenge of ambiguity in affective computing. While the community has largely addressed this issue from a label-based perspective, identifying data points in the sequence affected by the priming effect, the impact of priming on data itself, particularly in physiological signals, remains underexplored. Data affected by priming can lead to misclassifications when used in learning models. This study proposes the Affective Priming Score (APS), a data-driven method to detect data points influenced by the priming effect. The APS assigns a score to each data point, quantifying the extent to which it is affected by priming. To validate this method, we apply it to the SEED and SEED-VII datasets, which contain sufficient transitions between emotional events to exhibit priming effects. We train models with the same configuration using both the original data and priming-free sequences. The misclassification rate is significantly reduced when using priming-free sequences compared to the original data. This work contributes to the broader challenge of ambiguity by identifying and mitigating priming effects at the data level, enhancing model robustness, and offering valuable insights for the design and collection of affective computing datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æƒ…æ„Ÿè®¡ç®—ä¸­æƒ…æ„Ÿå¯åŠ¨ (Affective Priming) å¯¼è‡´çš„æ­§ä¹‰é—®é¢˜ï¼Œæå‡ºäº†æƒ…æ„Ÿå¯åŠ¨åˆ†æ•° (Affective Priming Score, APS)ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæ£€æµ‹åºåˆ—æ•°æ®ä¸­å—å¯åŠ¨æ•ˆåº”å½±å“æ•°æ®ç‚¹çš„æ•°æ®é©±åŠ¨æ–¹æ³•ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå—å¯åŠ¨æ•ˆåº”å½±å“çš„æ•°æ®åœ¨å­¦ä¹ æ¨¡å‹ä¸­ä¼šå¯¼è‡´è¯¯åˆ†ç±»ï¼Œè€Œ APS é€šè¿‡ä¸ºæ¯ä¸ªæ•°æ®ç‚¹åˆ†é…é‡åŒ–è¯„åˆ†æ¥è¡¡é‡å…¶å—å½±å“ç¨‹åº¦ã€‚ä¸ºäº†éªŒè¯è¯¥æ–¹æ³•ï¼Œç ”ç©¶äººå‘˜å°†å…¶åº”ç”¨äº SEED å’Œ SEED-VII æ•°æ®é›†ï¼Œå¹¶åœ¨ç›¸åŒé…ç½®ä¸‹å¯¹æ¯”äº†åŸå§‹æ•°æ®ä¸æ— å¯åŠ¨åºåˆ—çš„è®­ç»ƒæ•ˆæœã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨å‰”é™¤äº†å¯åŠ¨æ•ˆåº”çš„æ•°æ®åºåˆ—åï¼Œæ¨¡å‹çš„è¯¯åˆ†ç±»ç‡æ˜¾è‘—é™ä½ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æ•°æ®å±‚é¢è¯†åˆ«å’Œç¼“è§£å¯åŠ¨æ•ˆåº”çš„æœ‰æ•ˆæ€§ã€‚è¿™é¡¹å·¥ä½œä¸ä»…å¢å¼ºäº†æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹çš„é²æ£’æ€§ï¼Œè¿˜ä¸ºæƒ…æ„Ÿè®¡ç®—æ•°æ®é›†çš„è®¾è®¡ä¸é‡‡é›†æä¾›äº†æ–°çš„è§†è§’å’Œæ”¹è¿›æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20204v1",
      "published_date": "2025-06-25 07:48:22 UTC",
      "updated_date": "2025-06-25 07:48:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:34:20.541922+00:00"
    },
    {
      "arxiv_id": "2506.20199v2",
      "title": "How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?",
      "title_zh": "å¦‚ä½•åœ¨å¤§è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­æ£€ç´¢ç¤ºä¾‹ä»¥æå‡ä¼šè¯æƒ…æ„Ÿè¯†åˆ«ï¼Ÿ",
      "authors": [
        "Mengqi Wang",
        "Tiantian Feng",
        "Shrikanth Narayanan"
      ],
      "abstract": "Large language models (LLMs) have enabled a wide variety of real-world applications in various domains. However, creating a high-performing application with high accuracy remains challenging, particularly for subjective tasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this study investigates approaches to improving conversational emotion recognition (CER) by LLMs. Specifically, we explore how to retrieve high-quality examples in in-context learning (ICL) to enhance CER. We propose various strategies based on random and augmented example retrieval and also analyze the impact of conversational context on CER accuracy. Experiments were conducted on the three datasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented example retrieval consistently outperforms other techniques under investigation across all datasets, highlighting the importance of retrieving coherent targeted examples and enhancing them through paraphrasing.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡ä¼˜åŒ–ä¸Šä¸‹æ–‡å­¦ä¹ (In-context Learning)ä¸­çš„ç¤ºä¾‹æ£€ç´¢ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¯¹è¯æƒ…æ„Ÿè¯†åˆ«(Conversational Emotion Recognition)è¿™ä¸€ä¸»è§‚æ€§ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚ç ”ç©¶è€…æå‡ºäº†ä¸€ç³»åˆ—åŸºäºéšæœºæ£€ç´¢ä¸å¢å¼ºç¤ºä¾‹æ£€ç´¢(Augmented Example Retrieval)çš„ç­–ç•¥ï¼Œå¹¶ç³»ç»Ÿåˆ†æäº†å¯¹è¯è¯­å¢ƒå¯¹è¯†åˆ«å‡†ç¡®ç‡çš„å½±å“ã€‚å®éªŒåœ¨IEMOCAPã€MELDå’ŒEmoryNLPä¸‰ä¸ªä¸»æµæ•°æ®é›†ä¸Šå±•å¼€ï¼Œç»“æœè¯æ˜å¢å¼ºç¤ºä¾‹æ£€ç´¢ç­–ç•¥åœ¨æ‰€æœ‰æµ‹è¯•åœºæ™¯ä¸‹å‡è¡¨ç°æœ€ä½³ã€‚è¯¥å‘ç°å¼ºè°ƒäº†æ£€ç´¢å…·æœ‰è¿è´¯æ€§çš„é’ˆå¯¹æ€§ç¤ºä¾‹å¹¶é€šè¿‡æ”¹å†™(Paraphrasing)å¯¹å…¶è¿›è¡Œå¢å¼ºï¼Œæ˜¯æå‡æ¨¡å‹æƒ…æ„Ÿç†è§£èƒ½åŠ›çš„å…³é”®ã€‚è¯¥ç ”ç©¶ä¸ºåˆ©ç”¨ç¤ºä¾‹æ£€ç´¢ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹åœ¨å¤æ‚å¯¹è¯åˆ†æä»»åŠ¡ä¸­çš„è¡¨ç°æä¾›äº†é‡è¦çš„å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20199v2",
      "published_date": "2025-06-25 07:39:19 UTC",
      "updated_date": "2025-06-28 03:04:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:34:19.004894+00:00"
    },
    {
      "arxiv_id": "2506.20197v1",
      "title": "Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹çš„é›¶æ ·æœ¬æº¯æºï¼šä¸€ç§åˆ†å¸ƒæ£€éªŒæ–¹æ³•",
      "authors": [
        "ClÃ©ment L. Canonne",
        "Yash Pote",
        "Uddalok Sarkar"
      ],
      "abstract": "A growing fraction of all code is sampled from Large Language Models (LLMs). We investigate the problem of attributing code generated by language models using hypothesis testing to leverage established techniques and guarantees. Given a set of samples $S$ and a suspect model $\\mathcal{L}^*$, our goal is to assess the likelihood of $S$ originating from $\\mathcal{L}^*$. Due to the curse of dimensionality, this is intractable when only samples from the LLM are given: to circumvent this, we use both samples and density estimates from the LLM, a form of access commonly available.\n  We introduce $\\mathsf{Anubis}$, a zero-shot attribution tool that frames attribution as a distribution testing problem. Our experiments on a benchmark of code samples show that $\\mathsf{Anubis}$ achieves high AUROC scores ( $\\ge0.9$) when distinguishing between LLMs like DeepSeek-Coder, CodeGemma, and Stable-Code using only $\\approx 2000$ samples.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆçš„ä»£ç å½’å±é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºåˆ†å¸ƒæµ‹è¯•ï¼ˆdistribution testingï¼‰çš„å½’å±é‰´å®šæ–¹æ³•ã€‚ä¸ºäº†å…‹æœé«˜ç»´æ•°æ®å¸¦æ¥çš„ç»´åº¦ç¾éš¾ï¼Œè¯¥æ–¹æ³•ç»“åˆåˆ©ç”¨äº†LLMç”Ÿæˆçš„æ ·æœ¬ä»¥åŠæ¨¡å‹æä¾›çš„å¯†åº¦ä¼°è®¡ï¼ˆdensity estimatesï¼‰ï¼Œå°†å½’å±ä»»åŠ¡è½¬åŒ–ä¸ºç»Ÿè®¡å­¦ä¸­çš„å‡è®¾æ£€éªŒï¼ˆhypothesis testingï¼‰é—®é¢˜ã€‚ç ”ç©¶è€…æ®æ­¤å¼€å‘äº†åä¸ºAnubisçš„é›¶æ ·æœ¬å½’å±å·¥å…·ï¼ˆzero-shot attribution toolï¼‰ï¼Œè¯¥å·¥å…·èƒ½å¤Ÿåœ¨æ— éœ€å¯¹ç›®æ ‡æ¨¡å‹è¿›è¡Œé¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹è¯„ä¼°æ ·æœ¬é›†çš„æ¥æºå¯èƒ½æ€§ã€‚åœ¨ä»£ç æ ·æœ¬åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒAnubisåœ¨åŒºåˆ†DeepSeek-Coderã€CodeGemmaå’ŒStable-Codeç­‰æ¨¡å‹æ—¶è¡¨ç°å‡ºè‰²ï¼Œä»…éœ€çº¦2000ä¸ªæ ·æœ¬å³å¯è¾¾åˆ°0.9ä»¥ä¸Šçš„AUROCåˆ†æ•°ã€‚è¯¥ç ”ç©¶ä¸ºLLMç”Ÿæˆå†…å®¹çš„æ¥æºéªŒè¯æä¾›äº†ä¸€ç§é«˜æ•ˆã€å¯é ä¸”å…·æœ‰ç†è®ºä¿éšœçš„æŠ€æœ¯æ‰‹æ®µã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.20197v1",
      "published_date": "2025-06-25 07:37:16 UTC",
      "updated_date": "2025-06-25 07:37:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:34:36.318667+00:00"
    },
    {
      "arxiv_id": "2507.01979v1",
      "title": "Forecasting Labor Markets with LSTNet: A Multi-Scale Deep Learning Approach",
      "title_zh": "åŸºäº LSTNet çš„åŠ³åŠ¨åŠ›å¸‚åœºé¢„æµ‹ï¼šä¸€ç§å¤šå°ºåº¦æ·±åº¦å­¦ä¹ æ–¹æ³•",
      "authors": [
        "Adam Nelson-Archer",
        "Aleia Sen",
        "Meena Al Hasani",
        "Sofia Davila",
        "Jessica Le",
        "Omar Abbouchi"
      ],
      "abstract": "We present a deep learning approach for forecasting short-term employment changes and assessing long-term industry health using labor market data from the U.S. Bureau of Labor Statistics. Our system leverages a Long- and Short-Term Time-series Network (LSTNet) to process multivariate time series data, including employment levels, wages, turnover rates, and job openings. The model outputs both 7-day employment forecasts and an interpretable Industry Employment Health Index (IEHI). Our approach outperforms baseline models across most sectors, particularly in stable industries, and demonstrates strong alignment between IEHI rankings and actual employment volatility. We discuss error patterns, sector-specific performance, and future directions for improving interpretability and generalization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨æ·±åº¦å­¦ä¹ é¢„æµ‹çŸ­æœŸå°±ä¸šå˜åŒ–å¹¶è¯„ä¼°é•¿æœŸè¡Œä¸šå¥åº·çŠ¶å†µçš„æ–¹æ³•ã€‚ç³»ç»Ÿé‡‡ç”¨ Long- and Short-Term Time-series Network (LSTNet) æ¶æ„å¤„ç†æ¥è‡ªç¾å›½åŠ³å·¥ç»Ÿè®¡å±€ (U.S. Bureau of Labor Statistics) çš„å¤šå˜é‡æ—¶é—´åºåˆ—æ•°æ®ï¼Œæ¶µç›–å°±ä¸šæ°´å¹³ã€å·¥èµ„ã€æµå¤±ç‡å’ŒèŒä½ç©ºç¼ºç­‰å…³é”®æŒ‡æ ‡ã€‚æ¨¡å‹çš„æ ¸å¿ƒè¾“å‡ºåŒ…æ‹¬ 7-day employment forecasts ä»¥åŠå…·æœ‰å¯è§£é‡Šæ€§çš„ Industry Employment Health Index (IEHI)ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šæ•°è¡Œä¸šï¼ˆå°¤å…¶æ˜¯ç¨³å®šè¡Œä¸šï¼‰çš„é¢„æµ‹å‡†ç¡®ç‡å‡ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒIEHI æ’åä¸å®é™…å°±ä¸šæ³¢åŠ¨è¡¨ç°å‡ºé«˜åº¦ä¸€è‡´æ€§ï¼ŒéªŒè¯äº†è¯¥æŒ‡æ•°åœ¨è¯„ä¼°è¡Œä¸šå¥åº·åº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¯¥é¡¹å·¥ä½œä¸ºåŠ³åŠ¨åŠ›å¸‚åœºçš„é«˜ç²¾åº¦ã€å¤šå°ºåº¦ç›‘æµ‹æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "Undergraduate senior project, University of Houston, Department of Computer Science",
      "pdf_url": "https://arxiv.org/pdf/2507.01979v1",
      "published_date": "2025-06-25 07:14:02 UTC",
      "updated_date": "2025-06-25 07:14:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:34:31.533774+00:00"
    },
    {
      "arxiv_id": "2506.20179v1",
      "title": "Progressive Alignment Degradation Learning for Pansharpening",
      "title_zh": "ç”¨äºå…¨è‰²é”åŒ–çš„æ¸è¿›å¼å¯¹é½é€€åŒ–å­¦ä¹ ",
      "authors": [
        "Enzhe Zhao",
        "Zhichang Guo",
        "Yao Li",
        "Fanghui Song",
        "Boying Wu"
      ],
      "abstract": "Deep learning-based pansharpening has been shown to effectively generate high-resolution multispectral (HRMS) images. To create supervised ground-truth HRMS images, synthetic data generated using the Wald protocol is commonly employed. This protocol assumes that networks trained on artificial low-resolution data will perform equally well on high-resolution data. However, well-trained models typically exhibit a trade-off in performance between reduced-resolution and full-resolution datasets. In this paper, we delve into the Wald protocol and find that its inaccurate approximation of real-world degradation patterns limits the generalization of deep pansharpening models. To address this issue, we propose the Progressive Alignment Degradation Module (PADM), which uses mutual iteration between two sub-networks, PAlignNet and PDegradeNet, to adaptively learn accurate degradation processes without relying on predefined operators. Building on this, we introduce HFreqdiff, which embeds high-frequency details into a diffusion framework and incorporates CFB and BACM modules for frequency-selective detail extraction and precise reverse process learning. These innovations enable effective integration of high-resolution panchromatic and multispectral images, significantly enhancing spatial sharpness and quality. Experiments and ablation studies demonstrate the proposed method's superior performance compared to state-of-the-art techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…¨è‰²é”åŒ–(Pansharpening)ä¸­Waldåè®®å› å…¶å¯¹çœŸå®ä¸–ç•Œé™é˜¶æ¨¡å¼(Degradation Patterns)è¿‘ä¼¼ä¸å‡†ç¡®è€Œå¯¼è‡´æ·±åº¦å­¦ä¹ æ¨¡å‹æ³›åŒ–èƒ½åŠ›å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ¸è¿›å¼å¯¹é½é™é˜¶æ¨¡å—(Progressive Alignment Degradation Module, PADM)ã€‚è¯¥æ¨¡å—é€šè¿‡PAlignNetå’ŒPDegradeNetä¸¤ä¸ªå­ç½‘ç»œçš„ç›¸äº’è¿­ä»£ï¼Œåœ¨æ— éœ€é¢„å®šä¹‰ç®—å­çš„æƒ…å†µä¸‹è‡ªé€‚åº”å­¦ä¹ ç²¾ç¡®çš„é™é˜¶è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†HFreqdiffæ¡†æ¶ï¼Œå°†é«˜é¢‘ç»†èŠ‚åµŒå…¥æ‰©æ•£æ¨¡å‹(Diffusion Framework)ï¼Œå¹¶ç»“åˆCFBå’ŒBACMæ¨¡å—è¿›è¡Œé¢‘ç‡é€‰æ‹©æ€§ç»†èŠ‚æå–å’Œç²¾ç¡®çš„é€†è¿‡ç¨‹å­¦ä¹ ã€‚è¿™äº›åˆ›æ–°å®ç°äº†é«˜åˆ†è¾¨ç‡å…¨è‰²å›¾åƒä¸å¤šå…‰è°±å›¾åƒçš„æœ‰æ•ˆèåˆï¼Œæ˜¾è‘—æå‡äº†å›¾åƒçš„ç©ºé—´é”åº¦å’Œè´¨é‡ã€‚å®éªŒå’Œæ¶ˆèå®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å„é¡¹æ€§èƒ½æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„å…ˆè¿›æŠ€æœ¯(State-of-the-art)ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.20179v1",
      "published_date": "2025-06-25 07:07:32 UTC",
      "updated_date": "2025-06-25 07:07:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:34:39.830025+00:00"
    },
    {
      "arxiv_id": "2506.22500v1",
      "title": "Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models",
      "title_zh": "æ‰‹æœ¯å®¤ä¸­çš„è§†è§‰-è¯­ä¹‰çŸ¥è¯†å†²çªï¼šé¢å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ‰‹æœ¯é£é™©æ„ŸçŸ¥çš„åˆæˆæ•°æ®æ„å»º",
      "authors": [
        "Weiyi Zhao",
        "Xiaoyu Tan",
        "Liang Liu",
        "Sijia Li",
        "Youwei Song",
        "Xihe Qiu"
      ],
      "abstract": "Surgical risk identification is critical for patient safety and reducing preventable medical errors. While multimodal large language models (MLLMs) show promise for automated operating room (OR) risk detection, they often exhibit visual-semantic knowledge conflicts (VS-KC), failing to identify visual safety violations despite understanding textual rules. To address this, we introduce a dataset comprising over 34,000 synthetic images generated by diffusion models, depicting operating room scenes containing entities that violate established safety rules. These images were created to alleviate data scarcity and examine MLLMs vulnerabilities. In addition, the dataset includes 214 human-annotated images that serve as a gold-standard reference for validation. This comprehensive dataset, spanning diverse perspectives, stages, and configurations, is designed to expose and study VS-KC. Fine-tuning on OR-VSKC significantly improves MLLMs' detection of trained conflict entities and generalizes well to new viewpoints for these entities, but performance on untrained entity types remains poor, highlighting learning specificity and the need for comprehensive training. The main contributions of this work include: (1) a data generation methodology tailored for rule-violation scenarios; (2) the release of the OR-VSKC dataset and its associated benchmark as open-source resources; and (3) an empirical analysis of violation-sensitive knowledge consistency in representative MLLMs. The dataset and appendix are available at https://github.com/zgg2577/VS-KC.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰‹æœ¯å®¤ï¼ˆORï¼‰é£é™©è¯†åˆ«ä¸­çš„è§†è§‰è¯­ä¹‰çŸ¥è¯†å†²çªï¼ˆVS-KCï¼‰é—®é¢˜ï¼ŒæŒ‡å‡ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨ç†è§£æ–‡æœ¬è§„åˆ™çš„æƒ…å†µä¸‹ä»å¯èƒ½æ— æ³•è¯†åˆ«è§†è§‰å®‰å…¨è¿è§„ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œä½œè€…é€šè¿‡æ‰©æ•£æ¨¡å‹ç”Ÿæˆäº†åŒ…å«34,000å¤šå¼ åˆæˆå›¾åƒçš„OR-VSKCæ•°æ®é›†ï¼Œå¹¶è¾…ä»¥214å¼ äººå·¥æ ‡æ³¨çš„é»„é‡‘æ ‡å‡†å›¾åƒè¿›è¡ŒéªŒè¯ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨OR-VSKCä¸Šè¿›è¡Œå¾®è°ƒèƒ½æ˜¾è‘—å¢å¼ºMLLMså¯¹å·²çŸ¥å†²çªå®ä½“çš„æ£€æµ‹èƒ½åŠ›ï¼Œå¹¶èƒ½åœ¨æ–°è§†è§’ä¸‹ä¿æŒè‰¯å¥½çš„æ³›åŒ–è¡¨ç°ã€‚ç„¶è€Œï¼Œæ¨¡å‹å¯¹æœªè®­ç»ƒå®ä½“çš„è¯†åˆ«èƒ½åŠ›ä¾ç„¶æœ‰é™ï¼Œè¿™è¡¨æ˜äº†æ¨¡å‹å­¦ä¹ çš„ç‰¹å¼‚æ€§åŠæ„å»ºå…¨é¢è®­ç»ƒé›†çš„å¿…è¦æ€§ã€‚è¯¥å·¥ä½œé€šè¿‡å¼€æºæ•°æ®é›†ã€åŸºå‡†æµ‹è¯•å’Œå¯¹çŸ¥è¯†ä¸€è‡´æ€§çš„å®è¯åˆ†æï¼Œä¸ºæå‡æ‰‹æœ¯å®‰å…¨æ„ŸçŸ¥æä¾›äº†é‡è¦çš„æ•°æ®æ”¯æŒå’Œæ–¹æ³•è®ºå‚è€ƒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 5 figures. The dataset and appendix are available at https://github.com/zgg2577/VS-KC",
      "pdf_url": "https://arxiv.org/pdf/2506.22500v1",
      "published_date": "2025-06-25 07:06:29 UTC",
      "updated_date": "2025-06-25 07:06:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:34:47.195954+00:00"
    },
    {
      "arxiv_id": "2506.20178v1",
      "title": "COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees",
      "title_zh": "COINï¼šå…·æœ‰å¯è¯æ˜é£é™©ä¿è¯çš„åŸºç¡€æ¨¡å‹ä¸ç¡®å®šæ€§é˜²æŠ¤é€‰æ‹©æ€§é—®ç­”",
      "authors": [
        "Zhiyuan Wang",
        "Jinhao Duan",
        "Qingni Wang",
        "Xiaofeng Zhu",
        "Tianlong Chen",
        "Xiaoshuang Shi",
        "Kaidi Xu"
      ],
      "abstract": "Uncertainty quantification (UQ) for foundation models is essential to identify and mitigate potential hallucinations in automatically generated text. However, heuristic UQ approaches lack formal guarantees for key metrics such as the false discovery rate (FDR) in selective prediction. Previous work adopts the split conformal prediction (SCP) framework to ensure desired coverage of admissible answers by constructing prediction sets, but these sets often contain incorrect candidates, limiting their practical utility. To address this, we propose COIN, an uncertainty-guarding selection framework that calibrates statistically valid thresholds to filter a single generated answer per question under user-specified FDR constraints. COIN estimates the empirical error rate on a calibration set and applies confidence interval methods such as Clopper-Pearson to establish a high-probability upper bound on the true error rate (i.e., FDR). This enables the selection of the largest uncertainty threshold that ensures FDR control on test data while significantly increasing sample retention. We demonstrate COIN's robustness in risk control, strong test-time power in retaining admissible answers, and predictive efficiency under limited calibration data across both general and multimodal text generation tasks. Furthermore, we show that employing alternative upper bound constructions and UQ strategies can further boost COIN's power performance, which underscores its extensibility and adaptability to diverse application scenarios.",
      "tldr_zh": "é’ˆå¯¹åŸºç¡€æ¨¡å‹åœ¨è‡ªåŠ¨æ–‡æœ¬ç”Ÿæˆä¸­å­˜åœ¨çš„å¹»è§‰é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº† COIN æ¡†æ¶ï¼Œæ—¨åœ¨ä¸º Selective Question Answering æä¾›å…·æœ‰å¯è¯æ˜é£é™©ä¿è¯çš„ä¸ç¡®å®šæ€§é‡åŒ–ã€‚ä¼ ç»Ÿçš„å¯å‘å¼æ–¹æ³•ç¼ºä¹æ­£å¼çš„æŒ‡æ ‡ä¿è¯ï¼Œè€ŒåŸºäº Split Conformal Prediction (SCP) çš„æ–¹æ³•ç”Ÿæˆçš„é¢„æµ‹é›†å¾€å¾€åŒ…å«é”™è¯¯å€™é€‰é¡¹ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚COIN é‡‡ç”¨äº†ä¸€ç§ä¸ç¡®å®šæ€§å®ˆå«é€‰æ‹©æœºåˆ¶ï¼Œé€šè¿‡æ ¡å‡†ç»Ÿè®¡æœ‰æ•ˆçš„é˜ˆå€¼ï¼Œåœ¨ç”¨æˆ·æŒ‡å®šçš„ False Discovery Rate (FDR) çº¦æŸä¸‹è¿‡æ»¤å¹¶ç­›é€‰å•ä¸ªç”Ÿæˆç­”æ¡ˆã€‚è¯¥æ¡†æ¶åˆ©ç”¨ Clopper-Pearson ç­‰ç½®ä¿¡åŒºé—´æ–¹æ³•åœ¨æ ¡å‡†é›†ä¸Šå»ºç«‹ FDR çš„é«˜æ¦‚ç‡ä¸Šç•Œï¼Œä»è€Œåœ¨ç¡®ä¿é£é™©æ§åˆ¶çš„å‰æä¸‹æœ€å¤§é™åº¦åœ°æé«˜æ ·æœ¬ä¿ç•™ç‡ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒCOIN åœ¨é€šç”¨æ–‡æœ¬å’Œå¤šæ¨¡æ€ç”Ÿæˆä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºç¨³å¥çš„é£é™©æ§åˆ¶èƒ½åŠ›ã€å¼ºå¤§çš„æµ‹è¯•æ—¶æ•ˆèƒ½ä»¥åŠåœ¨æœ‰é™æ ¡å‡†æ•°æ®ä¸‹çš„é¢„æµ‹æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æ”¯æŒå¤šç§ä¸Šç•Œæ„å»ºå’Œä¸ç¡®å®šæ€§é‡åŒ–ç­–ç•¥ï¼Œå±•ç°äº†å…¶åœ¨ä¸åŒåº”ç”¨åœºæ™¯ä¸­çš„å¯æ‰©å±•æ€§ä¸é€‚åº”æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20178v1",
      "published_date": "2025-06-25 07:04:49 UTC",
      "updated_date": "2025-06-25 07:04:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:35:02.466244+00:00"
    },
    {
      "arxiv_id": "2507.02914v1",
      "title": "OAK -- Onboarding with Actionable Knowledge",
      "title_zh": "OAKï¼šåŸºäºå¯æ“ä½œæ€§çŸ¥è¯†çš„å…¥èŒå¼•å¯¼",
      "authors": [
        "Steve DevÃ¨nes",
        "Marine Capallera",
        "Robin Cherix",
        "Elena Mugellini",
        "Omar Abou Khaled",
        "Francesco Carrino"
      ],
      "abstract": "The loss of knowledge when skilled operators leave poses a critical issue for companies. This know-how is diverse and unstructured. We propose a novel method that combines knowledge graph embeddings and multi-modal interfaces to collect and retrieve expertise, making it actionable. Our approach supports decision-making on the shop floor. Additionally, we leverage LLMs to improve query understanding and provide adapted answers. As application case studies, we developed a proof-of-concept for quality control in high precision manufacturing.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç†Ÿç»ƒæ“ä½œå‘˜ç¦»èŒå¯¼è‡´çš„ä¼ä¸šçŸ¥è¯†æµå¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º OAK (Onboarding with Actionable Knowledge) çš„æ–°å‹æ–¹æ³•ï¼Œæ—¨åœ¨æ•è·å¹¶è½¬åŒ–å¤šæ ·ä¸”éç»“æ„åŒ–çš„æ“ä½œè¯€çª (know-how)ã€‚è¯¥æ¡†æ¶ç»“åˆäº†çŸ¥è¯†å›¾è°±åµŒå…¥ (knowledge graph embeddings) å’Œå¤šæ¨¡æ€æ¥å£ (multi-modal interfaces) æ¥å®ç°ä¸“ä¸šçŸ¥è¯†çš„æ”¶é›†ä¸æ£€ç´¢ï¼Œä½¿å…¶åœ¨ç”Ÿäº§å®è·µä¸­æ›´å…·å¯æ“ä½œæ€§ (actionable)ã€‚é€šè¿‡å¼•å…¥å¤§è¯­è¨€æ¨¡å‹ (LLMs)ï¼Œè¯¥æ–¹æ³•è¿›ä¸€æ­¥æå‡äº†ç³»ç»Ÿå¯¹å¤æ‚æŸ¥è¯¢çš„ç†è§£èƒ½åŠ›ï¼Œå¹¶èƒ½æä¾›é€‚é…çš„è§£ç­”ä»¥æ”¯æŒè½¦é—´ç°åœº (shop floor) çš„å†³ç­–åˆ¶å®šã€‚ä½œä¸ºåº”ç”¨æ¡ˆä¾‹ï¼Œç ”ç©¶å›¢é˜Ÿåœ¨ç²¾å¯†åˆ¶é€  (high precision manufacturing) çš„è´¨é‡æ§åˆ¶ (quality control) é¢†åŸŸå¼€å‘äº†æ¦‚å¿µéªŒè¯åŸå‹ã€‚è¿™ä¸€æ–¹æ¡ˆä¸ºä¼ä¸šåœ¨äººå‘˜æµåŠ¨èƒŒæ™¯ä¸‹ä¿ç•™æ ¸å¿ƒçŸ¥è¯†å¹¶è¾…åŠ©ä¸€çº¿å†³ç­–æä¾›äº†é«˜æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "This paper is an extended version of the work originally presented at the AI-Days 2024 conference in Lausanne, Switzerland. It builds upon the findings shared during the conference and includes additional results and analysis",
      "pdf_url": "https://arxiv.org/pdf/2507.02914v1",
      "published_date": "2025-06-25 07:03:52 UTC",
      "updated_date": "2025-06-25 07:03:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:35:09.412182+00:00"
    },
    {
      "arxiv_id": "2506.20173v1",
      "title": "Valid Selection among Conformal Sets",
      "title_zh": "ç¬¦åˆæ€§é›†åˆçš„æœ‰æ•ˆé€‰æ‹©",
      "authors": [
        "Mahmoud Hegazy",
        "Liviu Aolaritei",
        "Michael I. Jordan",
        "Aymeric Dieuleveut"
      ],
      "abstract": "Conformal prediction offers a distribution-free framework for constructing prediction sets with coverage guarantees. In practice, multiple valid conformal prediction sets may be available, arising from different models or methodologies. However, selecting the most desirable set, such as the smallest, can invalidate the coverage guarantees. To address this challenge, we propose a stability-based approach that ensures coverage for the selected prediction set. We extend our results to the online conformal setting, propose several refinements in settings where additional structure is available, and demonstrate its effectiveness through experiments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Conformal predictionæ¡†æ¶åœ¨æ„å»ºå…·æœ‰coverage guaranteesçš„prediction setsæ—¶é¢ä¸´çš„é€‰æ‹©éš¾é¢˜ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä»å¤šä¸ªæœ‰æ•ˆçš„conformal prediction setsä¸­é€‰æ‹©æœ€ç†æƒ³ï¼ˆä¾‹å¦‚æœ€å°ï¼‰çš„é›†åˆå¾€å¾€ä¼šå¯¼è‡´coverage guaranteeså¤±æ•ˆã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§stability-based approachï¼Œä»¥ç¡®ä¿æ‰€é€‰é¢„æµ‹é›†çš„è¦†ç›–æ€§è´¨ã€‚è¯¥ç ”ç©¶è¿›ä¸€æ­¥å°†ç»“æœæ‰©å±•åˆ°online conformal settingï¼Œå¹¶é’ˆå¯¹å…·æœ‰é¢å¤–ç»“æ„çš„åœºæ™¯æå‡ºäº†å¤šç§ä¼˜åŒ–æ”¹è¿›ã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä¸ºåœ¨ç»´æŒç»Ÿè®¡æœ‰æ•ˆæ€§çš„å‰æä¸‹è¿›è¡Œçµæ´»çš„é¢„æµ‹é›†é€‰æ‹©æä¾›äº†ç†è®ºæ”¯æŒã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.ME",
        "stat.OT"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20173v1",
      "published_date": "2025-06-25 06:59:55 UTC",
      "updated_date": "2025-06-25 06:59:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:35:18.874618+00:00"
    },
    {
      "arxiv_id": "2506.22499v1",
      "title": "Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data",
      "title_zh": "é«˜åˆ†è¾¨ç‡å«æ˜Ÿå½±åƒæ•°æ®å¢å¼ºçš„å¯æ‰©å±•åŠ¨æ€èµ·è®«ç‚¹éœ€æ±‚ä¼°è®¡",
      "authors": [
        "Jiachao Liu",
        "Pablo Guarda",
        "Koichiro Niinuma",
        "Sean Qian"
      ],
      "abstract": "This study presents a novel integrated framework for dynamic origin-destination demand estimation (DODE) in multi-class mesoscopic network models, leveraging high-resolution satellite imagery together with conventional traffic data from local sensors. Unlike sparse local detectors, satellite imagery offers consistent, city-wide road and traffic information of both parking and moving vehicles, overcoming data availability limitations. To extract information from imagery data, we design a computer vision pipeline for class-specific vehicle detection and map matching, generating link-level traffic density observations by vehicle class. Building upon this information, we formulate a computational graph-based DODE model that calibrates dynamic network states by jointly matching observed traffic counts and travel times from local sensors with density measurements derived from satellite imagery. To assess the accuracy and scalability of the proposed framework, we conduct a series of numerical experiments using both synthetic and real-world data. The results of out-of-sample tests demonstrate that supplementing traditional data with satellite-derived density significantly improves estimation performance, especially for links without local sensors. Real-world experiments also confirm the framework's capability to handle large-scale networks, supporting its potential for practical deployment in cities of varying sizes. Sensitivity analysis further evaluates the impact of data quality related to satellite imagery data.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é›†æˆäº†é«˜åˆ†è¾¨ç‡å«æ˜Ÿå›¾åƒ(high-resolution satellite imagery)ä¸ä¼ ç»Ÿä¼ æ„Ÿå™¨æ•°æ®çš„åŠ¨æ€èµ·ç‚¹-ç»ˆç‚¹éœ€æ±‚ä¼°è®¡(dynamic origin-destination demand estimation, DODE)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ¢æµ‹å™¨è¦†ç›–èŒƒå›´æœ‰é™çš„é—®é¢˜ã€‚é€šè¿‡è®¾è®¡è®¡ç®—æœºè§†è§‰æµæ°´çº¿(computer vision pipeline)è¿›è¡Œè½¦è¾†æ£€æµ‹ä¸åœ°å›¾åŒ¹é…ï¼Œç ”ç©¶è€…èƒ½å¤Ÿè·å–è·¯æ®µçº§åˆ«çš„å„ç±»åˆ«äº¤é€šå¯†åº¦è§‚æµ‹æ•°æ®ã€‚æ¡†æ¶é‡‡ç”¨åŸºäºè®¡ç®—å›¾(computational graph-based)çš„æ¨¡å‹ï¼Œé€šè¿‡è”åˆåŒ¹é…æµé‡è®¡æ•°ã€è¡Œç¨‹æ—¶é—´å’Œå«æ˜Ÿè¡ç”Ÿå¯†åº¦æ¥æ ¡å‡†åŠ¨æ€ç½‘ç»œçŠ¶æ€ã€‚æ•°å€¼å®éªŒä¸çœŸå®åœºæ™¯æµ‹è¯•è¯æ˜ï¼Œå¼•å…¥å«æ˜Ÿæ•°æ®æ˜¾è‘—æå‡äº†DODEçš„å‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹ä¼ æ„Ÿå™¨çš„è·¯æ®µè¡¨ç°ä¼˜å¼‚ã€‚è¯¥æ¡†æ¶å…·å¤‡å¤„ç†å¤§è§„æ¨¡ç½‘ç»œçš„å¯æ‰©å±•æ€§(scalability)ï¼Œä¸ºä¸åŒè§„æ¨¡åŸå¸‚çš„äº¤é€šéœ€æ±‚ç®¡ç†æä¾›äº†å®ç”¨çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.22499v1",
      "published_date": "2025-06-25 06:47:06 UTC",
      "updated_date": "2025-06-25 06:47:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:35:21.047175+00:00"
    },
    {
      "arxiv_id": "2506.20167v1",
      "title": "SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs",
      "title_zh": "SEEDï¼šå¤§è¯­è¨€æ¨¡å‹æ—¶é—´åºåˆ—é¢„æµ‹ä¸­ç”¨äºåµŒå…¥é©±åŠ¨è§£ç çš„ç»“æ„åŒ–ç¼–ç å™¨",
      "authors": [
        "Fengze Li",
        "Yue Wang",
        "Yangle Liu",
        "Ming Huang",
        "Dou Hong",
        "Jieming Ma"
      ],
      "abstract": "Multivariate time series forecasting requires models to simultaneously capture variable-wise structural dependencies and generalize across diverse tasks. While structural encoders are effective in modeling feature interactions, they lack the capacity to support semantic-level reasoning or task adaptation. Conversely, large language models (LLMs) possess strong generalization capabilities but remain incompatible with raw time series inputs. This gap limits the development of unified, transferable prediction systems. Therefore, we introduce SEED, a structural encoder for embedding-driven decoding, which integrates four stages: a token-aware encoder for patch extraction, a projection module that aligns patches with language model embeddings, a semantic reprogramming mechanism that maps patches to task-aware prototypes, and a frozen language model for prediction. This modular architecture decouples representation learning from inference, enabling efficient alignment between numerical patterns and semantic reasoning. Empirical results demonstrate that the proposed method achieves consistent improvements over strong baselines, and comparative studies on various datasets confirm SEED's role in addressing the structural-semantic modeling gap.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SEEDï¼Œä¸€ç§ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)æ—¶é—´åºåˆ—é¢„æµ‹çš„åµŒå…¥é©±åŠ¨è§£ç ç»“æ„ç¼–ç å™¨ï¼Œæ—¨åœ¨è§£å†³å¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹ä¸­å˜é‡é—´ç»“æ„ä¾èµ–å»ºæ¨¡ä¸è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ä¹‹é—´çš„çŸ›ç›¾ã€‚é’ˆå¯¹ä¼ ç»Ÿç»“æ„ç¼–ç å™¨ç¼ºä¹è¯­ä¹‰æ¨ç†èƒ½åŠ›ä»¥åŠLLMsæ— æ³•ç›´æ¥å¤„ç†åŸå§‹åºåˆ—æ•°æ®çš„å±€é™æ€§ï¼ŒSEEDè®¾è®¡äº†åŒ…å«Token-aware Encoderã€æŠ•å½±æ¨¡å—ã€è¯­ä¹‰é‡ç¼–ç¨‹æœºåˆ¶(Semantic Reprogramming)ä»¥åŠå†»ç»“çš„å¤§å‹è¯­è¨€æ¨¡å‹å››ä¸ªé˜¶æ®µçš„æ¨¡å—åŒ–æ¶æ„ã€‚è¯¥æ¶æ„å®ç°äº†è¡¨ç¤ºå­¦ä¹ ä¸æ¨ç†è¿‡ç¨‹çš„è§£è€¦ï¼Œèƒ½å¤Ÿå°†æ•°å€¼æ¨¡å¼æœ‰æ•ˆåœ°ä¸è¯­ä¹‰æ¨ç†è¿›è¡Œå¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSEEDåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¡¨ç°å‡ä¼˜äºç°æœ‰çš„å¼ºåŸºå‡†æ¨¡å‹ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†ç»“æ„åŒ–ä¸è¯­ä¹‰å»ºæ¨¡å·®å¼‚æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¯¥ç ”ç©¶ä¸ºæ„å»ºç»Ÿä¸€ä¸”å¯è¿ç§»çš„æ—¶é—´åºåˆ—é¢„æµ‹ç³»ç»Ÿæä¾›äº†æ–°çš„æ€è·¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20167v1",
      "published_date": "2025-06-25 06:40:14 UTC",
      "updated_date": "2025-06-25 06:40:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:35:13.106156+00:00"
    },
    {
      "arxiv_id": "2506.20164v1",
      "title": "Do psychic cells generate consciousness?",
      "title_zh": "å¿ƒç†ç»†èƒæ˜¯å¦äº§ç”Ÿæ„è¯†ï¼Ÿ",
      "authors": [
        "Mototaka Suzuki",
        "Jaan Aru"
      ],
      "abstract": "Technological advances in the past decades have begun to enable neuroscientists to address fundamental questions about consciousness in an unprecedented way. Here we review remarkable recent progress in our understanding of cellular-level mechanisms of conscious processing in the brain. Of particular interest are the cortical pyramidal neurons -- or \"psychic cells\" called by RamÃ³n y Cajal more than 100 years ago -- which have an intriguing cellular mechanism that accounts for selective disruption of feedback signaling in the brain upon anesthetic-induced loss of consciousness. Importantly, a particular class of metabotropic receptors distributed over the dendrites of pyramidal cells are highlighted as the key cellular mechanism. After all, Cajal's instinct over a century ago may turn out to be correct -- we may have just begun to understand whether and how psychic cells indeed generate and control our consciousness.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ„è¯†åœ¨ç»†èƒå±‚é¢çš„äº§ç”Ÿæœºåˆ¶ï¼Œé‡ç‚¹åˆ†æäº† RamÃ³n y Cajal æ›¾æåŠçš„ \"psychic cells\"ï¼ˆå³çš®å±‚é”¥ä½“ç¥ç»å…ƒï¼‰ã€‚é€šè¿‡å›é¡¾ç¥ç»ç§‘å­¦çš„æœ€æ–°è¿›å±•ï¼Œè®ºæ–‡é˜æ˜äº†è¿™äº›ç¥ç»å…ƒä¸­å­˜åœ¨çš„ä¸€ç§ç‹¬ç‰¹çš„ç»†èƒæœºåˆ¶ï¼Œèƒ½å¤Ÿè§£é‡Šåœ¨éº»é†‰è¯±å¯¼æ„è¯†ä¸§å¤±æ—¶å¤§è„‘ä¸­åé¦ˆä¿¡å· (feedback signaling) çš„é€‰æ‹©æ€§ä¸­æ–­ã€‚ç ”ç©¶ç‰¹åˆ«å¼ºè°ƒäº†åˆ†å¸ƒåœ¨é”¥ä½“ç»†èƒæ ‘çªä¸Šçš„ç‰¹å®šç±»åˆ«ä»£è°¢å‹å—ä½“ (metabotropic receptors) æ˜¯è¿™ä¸€è¿‡ç¨‹çš„å…³é”®æ ¸å¿ƒã€‚è¿™äº›å‘ç°è¡¨æ˜ Cajal ä¸€ä¸ªå¤šä¸–çºªå‰çš„ç›´è§‰å¯èƒ½æ˜¯æ­£ç¡®çš„ï¼Œäººç±»å·²å¼€å§‹æ·±å…¥ç†è§£ \"psychic cells\" ç©¶ç«Ÿå¦‚ä½•ç”Ÿæˆå¹¶æ§åˆ¶æ„è¯†ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20164v1",
      "published_date": "2025-06-25 06:38:13 UTC",
      "updated_date": "2025-06-25 06:38:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:35:37.051653+00:00"
    },
    {
      "arxiv_id": "2506.22498v4",
      "title": "ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction",
      "title_zh": "ViFusionTSTï¼šåŸºäºè½½è·ä¿¡å·æ—¶é—´åºåˆ—å›¾åƒè¡¨ç¤ºæ·±åº¦èåˆçš„æ—©æœŸç¦»åºŠé¢„æµ‹",
      "authors": [
        "Hao Liu",
        "Yu Hu",
        "Rakiba Rayhana",
        "Ling Bai",
        "Zheng Liu"
      ],
      "abstract": "Bed-related falls remain a major source of injury in hospitals and long-term care facilities, yet many commercial alarms trigger only after a patient has already left the bed. We show that early bed-exit intent can be predicted using only one low-cost load cell mounted under a bed leg. The resulting load signals are first converted into a compact set of complementary images: an RGB line plot that preserves raw waveforms and three texture maps-recurrence plot, Markov transition field, and Gramian angular field-that expose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin Transformer that processes the line plot and texture maps in parallel and fuses them through cross-attention to learn data-driven modality weights. To provide a realistic benchmark, we collected six months of continuous data from 95 beds in a long-term-care facility. On this real-world dataset ViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing recent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC. The results demonstrate that image-based fusion of load-sensor signals for time series classification is a practical and effective solution for real-time, privacy-preserving fall prevention.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ViFusionTSTï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæ—©æœŸç¦»åºŠé¢„æµ‹ (Early Bed-Exit Prediction) çš„æ·±åº¦èåˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŒ»ç–—æœºæ„ä¸­å› æŠ¥è­¦å»¶è¿Ÿå¯¼è‡´çš„è·Œå€’å—ä¼¤é—®é¢˜ã€‚è¯¥æ–¹æ³•ä»…åˆ©ç”¨åºŠè…¿ä¸‹çš„å•ä¸ªä½æˆæœ¬è´Ÿè·ä¼ æ„Ÿå™¨ (Load Cell) é‡‡é›†ä¿¡å·ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºåŒ…å«åŸå§‹æ³¢å½¢çš„ RGB çº¿æ¡å›¾ä»¥åŠé€’å½’å›¾ (Recurrence Plot)ã€é©¬å°”å¯å¤«è½¬ç§»åœº (Markov Transition Field) å’Œæ ¼æ‹‰å§†è§’åœº (Gramian Angular Field) ä¸‰ç§çº¹ç†å›¾ã€‚æ ¸å¿ƒæ¨¡å‹ ViFusionTST é‡‡ç”¨åŒæµ Swin Transformer æ¶æ„ï¼Œé€šè¿‡äº¤å‰æ³¨æ„åŠ› (Cross-Attention) æœºåˆ¶å¹¶è¡Œå¤„ç†è¿™äº›å›¾åƒè¡¨ç¤ºï¼Œä»¥å®ç°æ•°æ®é©±åŠ¨çš„æ¨¡æ€æƒé‡èåˆã€‚åœ¨æ¶µç›– 95 å¼ åºŠä½ã€ä¸ºæœŸå…­ä¸ªæœˆçš„çœŸå®ä¸–ç•Œæ•°æ®é›†æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹è¾¾åˆ°äº† 0.885 çš„å‡†ç¡®ç‡å’Œ 0.794 çš„ F1 åˆ†æ•°ï¼Œæ€§èƒ½å…¨é¢è¶…è¶Šäº†è¿‘æœŸçš„ 1D å’Œ 2D æ—¶é—´åºåˆ—åŸºå‡†æ¨¡å‹ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¿™ç§åŸºäºå›¾åƒèåˆçš„ä¼ æ„Ÿå™¨ä¿¡å·åˆ†ç±»æ–¹æ¡ˆï¼Œä¸ºå®æ—¶ä¸”ä¿æŠ¤éšç§çš„è·Œå€’é¢„é˜²æä¾›äº†ä¸€ç§åˆ‡å®å¯è¡Œä¸”é«˜æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.22498v4",
      "published_date": "2025-06-25 06:30:59 UTC",
      "updated_date": "2025-10-21 01:04:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:35:38.448576+00:00"
    },
    {
      "arxiv_id": "2506.20159v2",
      "title": "AI and Agile Software Development: From Frustration to Success -- XP2025 Workshop Summary",
      "title_zh": "äººå·¥æ™ºèƒ½ä¸æ•æ·è½¯ä»¶å¼€å‘ï¼šä»æŒ«è´¥è¿ˆå‘æˆåŠŸ â€”â€” XP2025 ç ”è®¨ä¼šæ€»ç»“",
      "authors": [
        "Tomas Herda",
        "Victoria Pichler",
        "Zheying Zhang",
        "Pekka Abrahamsson",
        "Geir K. Hanssen"
      ],
      "abstract": "The full-day workshop on AI and Agile at XP 2025 convened a diverse group of researchers and industry practitioners to address the practical challenges and opportunities of integrating Artificial Intelligence into Agile software development. Through interactive sessions, participants identified shared frustrations related to integrating AI into Agile Software Development practices, including challenges with tooling, governance, data quality, and critical skill gaps. These challenges were systematically prioritized and analyzed to uncover root causes. The workshop culminated in the collaborative development of a research roadmap that pinpoints actionable directions for future work, including both immediate solutions and ambitious long-term goals. The key outcome is a structured agenda designed to foster joint industry-academic efforts to move from identified frustrations to successful implementation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ€»ç»“äº†åœ¨ XP 2025 ä¸¾åŠçš„ AI ä¸æ•æ·è½¯ä»¶å¼€å‘(Agile Software Development)ç ”è®¨ä¼šæˆæœï¼Œæ—¨åœ¨æ¢è®¨å°†äººå·¥æ™ºèƒ½é›†æˆåˆ°æ•æ·å®è·µä¸­çš„å®é™…æŒ‘æˆ˜ä¸æœºé‡ã€‚é€šè¿‡ç ”ç©¶äººå‘˜ä¸ä»ä¸šè€…çš„äº¤äº’å¼è®¨è®ºï¼Œè¯¥ä¼šè®®è¯†åˆ«å¹¶ä¼˜å…ˆæ’åºäº†åœ¨å·¥å…·(tooling)ã€æ²»ç†(governance)ã€æ•°æ®è´¨é‡(data quality)åŠå…³é”®æŠ€èƒ½å·®è·(skill gaps)ç­‰æ–¹é¢çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¯¹è¿™äº›æŒ«æŠ˜çš„æ ¹æœ¬åŸå› è¿›è¡Œäº†ç³»ç»ŸåŒ–åˆ†æï¼Œå¹¶åä½œåˆ¶å®šäº†ä¸€ä»½æ˜ç¡®æœªæ¥è¡ŒåŠ¨æ–¹å‘çš„ç§‘ç ”è·¯çº¿å›¾(research roadmap)ã€‚è¯¥è·¯çº¿å›¾æ¶µç›–äº†å³æ—¶è§£å†³æ–¹æ¡ˆä¸é•¿æœŸçš„é›„å¿ƒç›®æ ‡ï¼Œæ„å»ºäº†ä¸€ä¸ªæ—¨åœ¨ä¿ƒè¿›äº§å­¦ç ”åˆä½œçš„ç»“æ„åŒ–è®®ç¨‹ã€‚è¯¥æˆæœä¸ºå¦‚ä½•å…‹æœ AI é›†æˆè¿‡ç¨‹ä¸­çš„éšœç¢æä¾›äº†æŒ‡å¼•ï¼Œæ—¨åœ¨æ¨åŠ¨è½¯ä»¶å¼€å‘ä»åˆæœŸçš„æŒ«æŠ˜é˜¶æ®µè½¬å‘æˆåŠŸçš„å®è·µåº”ç”¨ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20159v2",
      "published_date": "2025-06-25 06:29:03 UTC",
      "updated_date": "2025-07-03 18:41:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:35:24.040680+00:00"
    },
    {
      "arxiv_id": "2506.20156v1",
      "title": "Irec: A Metacognitive Scaffolding for Self-Regulated Learning through Just-in-Time Insight Recall: A Conceptual Framework and System Prototype",
      "title_zh": "Irecï¼šåŸºäºå³æ—¶æ´å¯Ÿå›æº¯çš„è‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ å…ƒè®¤çŸ¥æ”¯æ¶ï¼šæ¦‚å¿µæ¡†æ¶ä¸ç³»ç»ŸåŸå‹",
      "authors": [
        "Xuefei Hou",
        "Xizhao Tan"
      ],
      "abstract": "The core challenge in learning has shifted from knowledge acquisition to effective Self-Regulated Learning (SRL): planning, monitoring, and reflecting on one's learning. Existing digital tools, however, inadequately support metacognitive reflection. Spaced Repetition Systems (SRS) use de-contextualized review, overlooking the role of context, while Personal Knowledge Management (PKM) tools require high manual maintenance.\n  To address these challenges, this paper introduces \"Insight Recall,\" a novel paradigm that conceptualizes the context-triggered retrieval of personal past insights as a metacognitive scaffold to promote SRL. We formalize this paradigm using the Just-in-Time Adaptive Intervention (JITAI) framework and implement a prototype system, Irec, to demonstrate its feasibility. At its core, Irec uses a dynamic knowledge graph of the user's learning history. When a user faces a new problem, a hybrid retrieval engine recalls relevant personal \"insights.\" Subsequently, a large language model (LLM) performs a deep similarity assessment to filter and present the most relevant scaffold in a just-in-time manner. To reduce cognitive load, Irec features a human-in-the-loop pipeline for LLM-based knowledge graph construction. We also propose an optional \"Guided Inquiry\" module, where users can engage in a Socratic dialogue with an expert LLM, using the current problem and recalled insights as context. The contribution of this paper is a solid theoretical framework and a usable system platform for designing next-generation intelligent learning systems that enhance metacognition and self-regulation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰æ•°å­—å·¥å…·åœ¨å…ƒè®¤çŸ¥åæ€æ”¯æŒæ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº†â€œInsight Recallâ€è¿™ä¸€æ–°å‹èŒƒå¼ï¼Œæ—¨åœ¨é€šè¿‡ä¸Šä¸‹æ–‡è§¦å‘çš„ä¸ªäººè¿‡å¾€è§è§£æ£€ç´¢ä¸ºè‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ ï¼ˆSelf-Regulated Learning, SRLï¼‰æä¾›å…ƒè®¤çŸ¥æ”¯æ¶ã€‚ç ”ç©¶åˆ©ç”¨å³æ—¶é€‚åº”æ€§å¹²é¢„ï¼ˆJust-in-Time Adaptive Intervention, JITAIï¼‰æ¡†æ¶æ„å»ºäº†åä¸ºIrecçš„ç³»ç»ŸåŸå‹ï¼Œå…¶æ ¸å¿ƒæ˜¯åŸºäºç”¨æˆ·å­¦ä¹ å†å²çš„åŠ¨æ€çŸ¥è¯†å›¾è°±ï¼ˆKnowledge Graphï¼‰ã€‚å½“ç”¨æˆ·é¢ä¸´æ–°é—®é¢˜æ—¶ï¼Œç³»ç»Ÿé€šè¿‡æ··åˆæ£€ç´¢ï¼ˆHybrid Retrievalï¼‰å¼•æ“å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ·±åº¦ç›¸ä¼¼æ€§è¯„ä¼°ï¼Œä»¥å³æ—¶æ–¹å¼å‘ˆç°æœ€ç›¸å…³çš„å­¦æœ¯æ”¯æ¶ã€‚ä¸ºäº†é™ä½è®¤çŸ¥è´Ÿè·ï¼ŒIrecé‡‡ç”¨äº†äººæœºååŒçš„çŸ¥è¯†å›¾è°±æ„å»ºç®¡çº¿ï¼Œå¹¶æä¾›äº†å¯é€‰çš„â€œGuided Inquiryâ€æ¨¡å—ä»¥æ”¯æŒè‹æ ¼æ‹‰åº•å¼å¯¹è¯ã€‚è¯¥ç ”ç©¶ä¸ä»…è´¡çŒ®äº†åšå®çš„ç†è®ºæ¡†æ¶ï¼Œè¿˜æä¾›äº†ä¸€ä¸ªå®ç”¨çš„ç³»ç»Ÿå¹³å°ï¼Œä¸ºå¼€å‘å¢å¼ºå…ƒè®¤çŸ¥ä¸è‡ªæˆ‘è°ƒèŠ‚èƒ½åŠ›çš„ä¸‹ä¸€ä»£æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.HC",
      "comment": "Version 1 of a work in progress. Finalized system flowcharts, a public GitHub repository with the source code, and a full reproducibility package detailing the prompts, models, and testing guidelines will be provided in v2",
      "pdf_url": "https://arxiv.org/pdf/2506.20156v1",
      "published_date": "2025-06-25 06:23:39 UTC",
      "updated_date": "2025-06-25 06:23:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:35:33.849000+00:00"
    },
    {
      "arxiv_id": "2507.22063v1",
      "title": "RedCoder: Automated Multi-Turn Red Teaming for Code LLMs",
      "title_zh": "RedCoderï¼šé’ˆå¯¹ä»£ç å¤§è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨åŒ–å¤šè½®çº¢é˜Ÿæµ‹è¯•",
      "authors": [
        "Wenjie Jacky Mo",
        "Qin Liu",
        "Xiaofei Wen",
        "Dongwon Jung",
        "Hadi Askari",
        "Wenxuan Zhou",
        "Zhe Zhao",
        "Muhao Chen"
      ],
      "abstract": "Large Language Models (LLMs) for code generation (i.e., Code LLMs) have demonstrated impressive capabilities in AI-assisted software development and testing. However, recent studies have shown that these models are prone to generating vulnerable or even malicious code under adversarial settings. Existing red-teaming approaches rely on extensive human effort, limiting their scalability and practicality, and generally overlook the interactive nature of real-world AI-assisted programming, which often unfolds over multiple turns. To bridge these gaps, we present RedCoder, a red-teaming agent that engages victim models in multi-turn conversation to elicit vulnerable code. The pipeline to construct RedCoder begins with a multi-agent gaming process that simulates adversarial interactions, yielding a set of prototype conversations and an arsenal of reusable attack strategies. We then fine-tune an LLM on these prototype conversations to serve as the backbone of RedCoder. Once deployed, RedCoder autonomously engages Code LLMs in multi-turn conversations, dynamically retrieving relevant strategies from the arsenal to steer the dialogue toward vulnerability-inducing outputs. Experiments across multiple Code LLMs show that our approach outperforms prior single-turn and multi-turn red-team methods in inducing vulnerabilities in code generation, offering a scalable and effective tool for evaluating the security boundaries of modern code-generation systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»£ç å¤§è¯­è¨€æ¨¡å‹(Code LLMs)åœ¨å¯¹æŠ—ç¯å¢ƒä¸‹æ˜“ç”Ÿæˆæ¼æ´æˆ–æ¶æ„ä»£ç çš„é—®é¢˜ï¼Œæå‡ºäº†è‡ªåŠ¨åŒ–å¤šè½®çº¢é˜Ÿæµ‹è¯•å·¥å…·RedCoderã€‚ä¼ ç»Ÿçš„çº¢é˜Ÿæµ‹è¯•(Red Teaming)æ–¹æ³•ä¾èµ–å¤§é‡äººåŠ›ä¸”å¤šé™äºå•è½®äº¤äº’ï¼Œæ— æ³•æœ‰æ•ˆæ¨¡æ‹ŸçœŸå®çš„AIè¾…åŠ©ç¼–ç¨‹åœºæ™¯ã€‚RedCoderé€šè¿‡å¤šæ™ºèƒ½ä½“åšå¼ˆ(Multi-agent Gaming)è¿‡ç¨‹æ¨¡æ‹Ÿå¯¹æŠ—äº’åŠ¨ï¼Œä»è€Œæ„å»ºå‡ºä¸€å¥—åŸå‹å¯¹è¯é›†å’Œå¯å¤ç”¨çš„æ”»å‡»ç­–ç•¥åº“ã€‚è¯¥å·¥å…·ä»¥å¾®è°ƒåçš„LLMä¸ºæ ¸å¿ƒï¼Œåœ¨å¯¹è¯ä¸­åŠ¨æ€æ£€ç´¢ç­–ç•¥ä»¥å¼•å¯¼ç›®æ ‡æ¨¡å‹äº§ç”Ÿæ¼æ´ä»£ç ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRedCoderåœ¨è¯±å¯¼æ¼æ´ç”Ÿæˆæ–¹é¢çš„è¡¨ç°ä¼˜äºç°æœ‰çš„å•è½®åŠå¤šè½®çº¢é˜Ÿæµ‹è¯•æ–¹æ³•ã€‚è¿™ä¸€æˆæœä¸ºè¯„ä¼°ç°ä»£ä»£ç ç”Ÿæˆç³»ç»Ÿçš„å®‰å…¨è¾¹ç•Œ(Security Boundaries)æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„è‡ªåŠ¨åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.22063v1",
      "published_date": "2025-06-25 06:20:15 UTC",
      "updated_date": "2025-06-25 06:20:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:35:41.450694+00:00"
    },
    {
      "arxiv_id": "2506.20152v1",
      "title": "Loss-Aware Automatic Selection of Structured Pruning Criteria for Deep Neural Network Acceleration",
      "title_zh": "é¢å‘æ·±åº¦ç¥ç»ç½‘ç»œåŠ é€Ÿçš„æŸå¤±æ„ŸçŸ¥ç»“æ„åŒ–å‰ªæå‡†åˆ™è‡ªåŠ¨é€‰æ‹©",
      "authors": [
        "Deepak Ghimire",
        "Kilho Lee",
        "Seong-heum Kim"
      ],
      "abstract": "Structured pruning is a well-established technique for compressing neural networks, making it suitable for deployment in resource-limited edge devices. This paper presents an efficient Loss-Aware Automatic Selection of Structured Pruning Criteria (LAASP) for slimming and accelerating deep neural networks. The majority of pruning methodologies employ a sequential process consisting of three stages: 1) training, 2) pruning, and 3) fine-tuning, whereas the proposed pruning technique adopts a pruning-while-training approach that eliminates the first stage and integrates the second and third stages into a single cycle. The automatic selection of magnitude or similarity-based filter pruning criteria from a specified pool of criteria and the specific pruning layer at each pruning iteration is guided by the network's overall loss on a small subset of the training data. To mitigate the abrupt accuracy drop due to pruning, the network is retrained briefly after each reduction of a predefined number of floating-point operations (FLOPs). The optimal pruning rates for each layer in the network are automatically determined, eliminating the need for manual allocation of fixed or variable pruning rates for each layer. Experiments on the VGGNet and ResNet models on the CIFAR-10 and ImageNet benchmark datasets demonstrate the effectiveness of the proposed method. In particular, the ResNet56 and ResNet110 models on the CIFAR-10 dataset significantly improve the top-1 accuracy compared to state-of-the-art methods while reducing the network FLOPs by 52\\%. Furthermore, the ResNet50 model on the ImageNet dataset reduces FLOPs by more than 42\\% with a negligible 0.33\\% drop in top-5 accuracy. The source code of this paper is publicly available online - https://github.com/ghimiredhikura/laasp.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º LAASP (Loss-Aware Automatic Selection of Structured Pruning Criteria) çš„é«˜æ•ˆç»“æ„åŒ–å‰ªææ–¹æ³•ï¼Œæ—¨åœ¨åŠ é€Ÿæ·±å±‚ç¥ç»ç½‘ç»œåœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„éƒ¨ç½²ã€‚ä¸ä¼ ç»Ÿçš„â€œè®­ç»ƒ-å‰ªæ-å¾®è°ƒâ€ä¸‰é˜¶æ®µæµç¨‹ä¸åŒï¼ŒLAASP é‡‡ç”¨äº†ä¸€ç§â€œè®­ç»ƒä¸­å‰ªæ (pruning-while-training)â€çš„ç­–ç•¥ï¼Œå°†å‰ªæä¸è®­ç»ƒæ•´åˆä¸ºå•ä¸€å¾ªç¯ä»¥æé«˜å‹ç¼©æ•ˆç‡ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç½‘ç»œåœ¨å°‘é‡è®­ç»ƒå­é›†ä¸Šçš„æ•´ä½“æŸå¤± (loss) ä½œä¸ºæŒ‡å¯¼ï¼Œè‡ªåŠ¨ä»é¢„å®šä¹‰çš„å‡†åˆ™æ± ä¸­é€‰æ‹©åŸºäºé‡çº§ (magnitude) æˆ–ç›¸ä¼¼åº¦ (similarity) çš„å‰ªæå‡†åˆ™ï¼Œå¹¶ç¡®å®šæ¯è½®è¿­ä»£ä¸­å…·ä½“çš„å¾…å‰ªæå±‚ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒLAASP èƒ½å¤Ÿè‡ªåŠ¨ç¡®å®šå„å±‚çš„æœ€ä¼˜å‰ªæç‡ï¼Œå½»åº•æ¶ˆé™¤äº†äººå·¥åˆ†é…å›ºå®šæˆ–å˜é‡å‰ªæå‚æ•°çš„éœ€æ±‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ CIFAR-10 æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•ä½¿ ResNet56 å’Œ ResNet110 åœ¨å‡å°‘ 52% FLOPs çš„åŒæ—¶æ˜¾è‘—æå‡äº† Top-1 å‡†ç¡®ç‡ã€‚åœ¨ ImageNet æ•°æ®é›†ä¸Šï¼ŒResNet50 æ¨¡å‹åœ¨å‡å°‘è¶…è¿‡ 42% FLOPs çš„æƒ…å†µä¸‹ï¼ŒTop-5 å‡†ç¡®ç‡ä»…ä¸‹é™äº† 0.33%ï¼Œè¯æ˜äº† LAASP åœ¨ä¿æŒæ¨¡å‹æ€§èƒ½çš„åŒæ—¶å®ç°é«˜æ•ˆå‹ç¼©çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20152v1",
      "published_date": "2025-06-25 06:18:46 UTC",
      "updated_date": "2025-06-25 06:18:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:35:58.064792+00:00"
    },
    {
      "arxiv_id": "2506.20151v1",
      "title": "EAR: Erasing Concepts from Unified Autoregressive Models",
      "title_zh": "EARï¼šç»Ÿä¸€è‡ªå›å½’æ¨¡å‹ä¸­çš„æ¦‚å¿µæ“¦é™¤",
      "authors": [
        "Haipeng Fan",
        "Shiyuan Zhang",
        "Baohunesitu",
        "Zihang Guo",
        "Huaiwen Zhang"
      ],
      "abstract": "Autoregressive (AR) models have achieved unified and strong performance across both visual understanding and image generation tasks. However, removing undesired concepts from AR models while maintaining overall generation quality remains an open challenge. In this paper, we propose Erasure Autoregressive Model (EAR), a fine-tuning method for effective and utility-preserving concept erasure in AR models. Specifically, we introduce Windowed Gradient Accumulation (WGA) strategy to align patch-level decoding with erasure objectives, and Thresholded Loss Masking (TLM) strategy to protect content unrelated to the target concept during fine-tuning. Furthermore, we propose a novel benchmark, Erase Concept Generator and Visual Filter (ECGVF), aim at provide a more rigorous and comprehensive foundation for evaluating concept erasure in AR models. Specifically, we first employ structured templates across diverse large language models (LLMs) to pre-generate a large-scale corpus of target-replacement concept prompt pairs. Subsequently, we generate images from these prompts and subject them to rigorous filtering via a visual classifier to ensure concept fidelity and alignment. Extensive experimental results conducted on the ECGVF benchmark with the AR model Janus-Pro demonstrate that EAR achieves marked improvements in both erasure effectiveness and model utility preservation. Code is available at: https://github.com/immc-lab/ear/",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç»Ÿä¸€è‡ªå›å½’æ¨¡å‹(Autoregressive Models)åœ¨ç§»é™¤ç‰¹å®šæ¦‚å¿µæ—¶éš¾ä»¥ç»´æŒæ•´ä½“ç”Ÿæˆè´¨é‡çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†EAR(Erasure Autoregressive Model)å¾®è°ƒæ–¹æ³•ã€‚ä¸ºäº†å®ç°é«˜æ•ˆä¸”ä¿ç•™æ•ˆç”¨çš„æ¦‚å¿µæ“¦é™¤ï¼ŒEARå¼•å…¥äº†çª—å£æ¢¯åº¦ç´¯ç§¯(Windowed Gradient Accumulation, WGA)ç­–ç•¥ï¼Œå°†è¡¥ä¸çº§è§£ç ä¸æ“¦é™¤ç›®æ ‡å¯¹é½ï¼Œå¹¶åˆ©ç”¨é˜ˆå€¼æŸå¤±æ©ç (Thresholded Loss Masking, TLM)ç­–ç•¥ä¿æŠ¤ä¸ç›®æ ‡æ¦‚å¿µæ— å…³çš„å†…å®¹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…è¿˜æå‡ºäº†åä¸ºECGVF(Erase Concept Generator and Visual Filter)çš„æ–°å‹åŸºå‡†æµ‹è¯•ï¼Œé€šè¿‡å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æç¤ºè¯å¯¹å’Œä¸¥è‹›çš„è§†è§‰åˆ†ç±»å™¨è¿‡æ»¤ï¼Œä¸ºè¯„ä¼°æ¦‚å¿µæ“¦é™¤æä¾›äº†æ›´ä¸¥è°¨çš„åŸºç¡€ã€‚åœ¨Janus-Proæ¨¡å‹ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼ŒEARåœ¨æ˜¾è‘—æå‡æ¦‚å¿µæ“¦é™¤æœ‰æ•ˆæ€§çš„åŒæ—¶ï¼Œèƒ½æœ‰æ•ˆç»´æŒæ¨¡å‹çš„é€šç”¨æ•ˆç”¨å’Œç”Ÿæˆè´¨é‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 7 figures, 1 tables",
      "pdf_url": "https://arxiv.org/pdf/2506.20151v1",
      "published_date": "2025-06-25 06:15:07 UTC",
      "updated_date": "2025-06-25 06:15:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:00.446335+00:00"
    },
    {
      "arxiv_id": "2506.20130v4",
      "title": "AI Copilots for Reproducibility in Science: A Case Study",
      "title_zh": "ç§‘å­¦å¯å¤ç°æ€§ AI åŠ©æ‰‹ï¼šä¸€é¡¹æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Adrien Bibal",
        "Steven N. Minton",
        "Deborah Khider",
        "Yolanda Gil"
      ],
      "abstract": "Open science initiatives seek to make research outputs more transparent, accessible, and reusable, but ensuring that published findings can be independently reproduced remains a persistent challenge. In this paper we describe an AI-driven \"Reproducibility Copilot\" that analyzes manuscripts, code, and supplementary materials to generate structured Jupyter Notebooks and recommendations aimed at facilitating computational, or \"rote\", reproducibility. Our initial results suggest that the copilot has the potential to substantially reduce reproduction time (in one case from over 30 hours to about 1 hour) while achieving high coverage of figures, tables, and results suitable for computational reproduction. The system systematically detects barriers to reproducibility, including missing values for hyperparameters, undocumented preprocessing steps, and incomplete or inaccessible datasets. Although preliminary, these findings suggest that AI tools can meaningfully reduce the burden of reproducibility efforts and contribute to more transparent and verifiable scientific communication.",
      "tldr_zh": "æœ¬ç ”ç©¶å¼€å‘äº†ä¸€ç§ AI é©±åŠ¨çš„ Reproducibility Copilotï¼Œæ—¨åœ¨é€šè¿‡è‡ªåŠ¨åŒ–åˆ†æè®ºæ–‡æ‰‹ç¨¿ã€ä»£ç å’Œè¡¥å……ææ–™ï¼Œç”Ÿæˆç»“æ„åŒ–çš„ Jupyter Notebooks æ¥æå‡ç§‘å­¦ç ”ç©¶çš„å¯å¤ç°æ€§ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿç³»ç»Ÿæ€§åœ°è¯†åˆ«å¤ç°è¿‡ç¨‹ä¸­çš„å…³é”®éšœç¢ï¼Œä¾‹å¦‚ç¼ºå¤±çš„ Hyperparametersã€æœªè®°å½•çš„ Preprocessing æ­¥éª¤ä»¥åŠä¸å®Œæ•´çš„ Datasetsã€‚åˆæ­¥å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥å·¥å…·åœ¨å¤„ç† computational reproduction æ—¶è¡¨ç°å‡ºè‰²ï¼Œåœ¨ç‰¹å®šæ¡ˆä¾‹ä¸­æˆåŠŸå°†å¤ç°æ—¶é—´ä» 30 å°æ—¶ä»¥ä¸Šå¤§å¹…ç¼©çŸ­è‡³çº¦ 1 å°æ—¶ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿåœ¨è¿˜åŸåŸè®ºæ–‡ä¸­çš„ Figuresã€Tables åŠæ ¸å¿ƒ Results æ–¹é¢è¾¾åˆ°äº†æé«˜çš„è¦†ç›–ç‡ã€‚ç»¼ä¸Šæ‰€è¿°ï¼ŒAI Copilots èƒ½å¤Ÿæœ‰æ•ˆå‡è½»ç§‘ç ”äººå‘˜åœ¨å¤ç°å·¥ä½œä¸Šçš„è´Ÿæ‹…ï¼Œä¸ºæ„å»ºæ›´é€æ˜ã€å¯éªŒè¯çš„ç§‘å­¦é€šä¿¡ä½“ç³»æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Reproducible Artificial Intelligence (RAI2026) Workshop, AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2506.20130v4",
      "published_date": "2025-06-25 04:56:28 UTC",
      "updated_date": "2025-12-15 18:11:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:05.761489+00:00"
    },
    {
      "arxiv_id": "2506.20128v1",
      "title": "CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation",
      "title_zh": "CCRSï¼šä¸€ç§ç”¨äº RAG ç»¼åˆè¯„ä¼°çš„é›¶æ ·æœ¬ LLM-as-a-Judge æ¡†æ¶",
      "authors": [
        "Aashiq Muhamed"
      ],
      "abstract": "RAG systems enhance LLMs by incorporating external knowledge, which is crucial for domains that demand factual accuracy and up-to-date information. However, evaluating the multifaceted quality of RAG outputs, spanning aspects such as contextual coherence, query relevance, factual correctness, and informational completeness, poses significant challenges. Existing evaluation methods often rely on simple lexical overlap metrics, which are inadequate for capturing these nuances, or involve complex multi-stage pipelines with intermediate steps like claim extraction or require finetuning specialized judge models, hindering practical efficiency. To address these limitations, we propose CCRS (Contextual Coherence and Relevance Score), a novel suite of five metrics that utilizes a single, powerful, pretrained LLM as a zero-shot, end-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance (QR), Information Density (ID), Answer Correctness (AC), and Information Recall (IR). We apply CCRS to evaluate six diverse RAG system configurations on the challenging BioASQ dataset. Our analysis demonstrates that CCRS effectively discriminates between system performances, confirming, for instance, that the Mistral-7B reader outperforms Llama variants. We provide a detailed analysis of CCRS metric properties, including score distributions, convergent/discriminant validity, tie rates, population statistics, and discriminative power. Compared to the complex RAGChecker framework, CCRS offers comparable or superior discriminative power for key aspects like recall and faithfulness, while being significantly more computationally efficient. CCRS thus provides a practical, comprehensive, and efficient framework for evaluating and iteratively improving RAG systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CCRSï¼ˆContextual Coherence and Relevance Scoreï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLM-as-a-Judgeï¼‰çš„é›¶æ ·æœ¬ï¼ˆZero-Shotï¼‰ç«¯åˆ°ç«¯è¯„æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿåœ¨è¯„ä¼°ä¸Šä¸‹æ–‡è¿è´¯æ€§ã€æŸ¥è¯¢ç›¸å…³æ€§å’Œäº‹å®å‡†ç¡®æ€§ç­‰æ–¹é¢çš„å¤æ‚æŒ‘æˆ˜ã€‚CCRS åŒ…å«äº”é¡¹æ ¸å¿ƒæŒ‡æ ‡ï¼šä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼ˆCCï¼‰ã€é—®é¢˜ç›¸å…³æ€§ï¼ˆQRï¼‰ã€ä¿¡æ¯å¯†åº¦ï¼ˆIDï¼‰ã€ç­”æ¡ˆæ­£ç¡®æ€§ï¼ˆACï¼‰å’Œä¿¡æ¯å¬å›ç‡ï¼ˆIRï¼‰ï¼Œä»…éœ€å•ä¸ªé¢„è®­ç»ƒæ¨¡å‹å³å¯å®Œæˆå…¨é¢è¯„ä¼°ã€‚é€šè¿‡åœ¨æŒ‘æˆ˜æ€§æå¤§çš„ BioASQ æ•°æ®é›†ä¸Šå¯¹å…­ç§ RAG é…ç½®è¿›è¡Œæµ‹è¯•ï¼Œå®éªŒè¯æ˜ CCRS èƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†ä¸åŒç³»ç»Ÿçš„æ€§èƒ½è¡¨ç°ï¼Œå¹¶ç¡®è®¤ Mistral-7B åœ¨é˜…è¯»å™¨ä»»åŠ¡ä¸­ä¼˜äº Llama å˜ä½“ã€‚ä¸å¤æ‚çš„ RAGChecker æ¡†æ¶ç›¸æ¯”ï¼ŒCCRS åœ¨å¬å›ç‡å’Œå¿ å®åº¦ç­‰å…³é”®æŒ‡æ ‡ä¸Šå±•ç°äº†åŒç­‰æˆ–æ›´ä¼˜çš„åˆ¤åˆ«åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—æå‡äº†è®¡ç®—æ•ˆç‡ï¼Œä¸º RAG ç³»ç»Ÿçš„æ€§èƒ½è¯„ä¼°ä¸è¿­ä»£ä¼˜åŒ–æä¾›äº†ä¸€ä¸ªå®ç”¨ã€å…¨é¢ä¸”é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LLM4Eval @ SIGIR 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.20128v1",
      "published_date": "2025-06-25 04:49:03 UTC",
      "updated_date": "2025-06-25 04:49:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:05.883200+00:00"
    },
    {
      "arxiv_id": "2507.02913v1",
      "title": "Toward Cyclic A.I. Modelling of Self-Regulated Learning: A Case Study with E-Learning Trace Data",
      "title_zh": "è¿ˆå‘è‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ çš„å¾ªç¯å¼äººå·¥æ™ºèƒ½å»ºæ¨¡ï¼šåŸºäºåœ¨çº¿å­¦ä¹ è¿½è¸ªæ•°æ®çš„æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Andrew Schwabe",
        "Ã–zgÃ¼r AkgÃ¼n",
        "Ella Haig"
      ],
      "abstract": "Many e-learning platforms assert their ability or potential to improve students' self-regulated learning (SRL), however the cyclical and undirected nature of SRL theoretical models represent significant challenges for representation within contemporary machine learning frameworks. We apply SRL-informed features to trace data in order to advance modelling of students' SRL activities, to improve predictability and explainability regarding the causal effects of learning in an eLearning environment. We demonstrate that these features improve predictive accuracy and validate the value of further research into cyclic modelling techniques for SRL.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é’ˆå¯¹è‡ªæˆ‘è°ƒèŠ‚å­¦ä¹  (Self-Regulated Learning, SRL) ç†è®ºæ¨¡å‹çš„å¾ªç¯å’Œéå¯¼å‘æ€§ç‰¹å¾è¿›è¡Œäººå·¥æ™ºèƒ½å»ºæ¨¡ï¼Œä»¥è§£å†³ç°æœ‰æœºå™¨å­¦ä¹ æ¡†æ¶åœ¨è¡¨ç¤ºæ­¤ç±»å¤æ‚è¿‡ç¨‹æ—¶çš„å±€é™æ€§ã€‚ä½œè€…é€šè¿‡æå–åŸºäº SRL ç†è®ºçš„ç‰¹å¾å¹¶åº”ç”¨äºç”µå­å­¦ä¹  (e-Learning) çš„ç—•è¿¹æ•°æ® (trace data)ï¼Œè‡´åŠ›äºæå‡å­¦ç”Ÿåœ¨çº¿å­¦ä¹ è¡Œä¸ºçš„å¯é¢„æµ‹æ€§ä»¥åŠå­¦ä¹ æ•ˆæœå› æœå…³ç³»çš„è§£é‡ŠåŠ›ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼Œè¿™äº›é’ˆå¯¹æ€§ç‰¹å¾çš„å¼•å…¥æ˜¾è‘—æé«˜äº†é¢„æµ‹å‡†ç¡®ç‡ï¼Œå¹¶æœ‰æ•ˆéªŒè¯äº†åœ¨ SRL é¢†åŸŸå¼€å±•å¾ªç¯å»ºæ¨¡ (cyclic modelling) æŠ€æœ¯ç ”ç©¶çš„å¿…è¦æ€§ä¸ä»·å€¼ã€‚è¯¥å·¥ä½œé€šè¿‡å…·ä½“çš„æ¡ˆä¾‹åˆ†æï¼Œä¸ºæ„å»ºèƒ½å¤Ÿç²¾å‡†æ¨¡æ‹Ÿå¹¶æ”¯æŒå­¦ç”Ÿè‡ªä¸»å­¦ä¹ è¿‡ç¨‹çš„æ™ºèƒ½ç³»ç»Ÿæä¾›äº†ç†è®ºä¾æ®ä¸å®è·µè·¯å¾„ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "6 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.02913v1",
      "published_date": "2025-06-25 04:47:53 UTC",
      "updated_date": "2025-06-25 04:47:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:11.471714+00:00"
    },
    {
      "arxiv_id": "2506.20689v1",
      "title": "U-R-VEDA: Integrating UNET, Residual Links, Edge and Dual Attention, and Vision Transformer for Accurate Semantic Segmentation of CMRs",
      "title_zh": "U-R-VEDAï¼šèåˆ UNETã€æ®‹å·®è¿æ¥ã€è¾¹ç¼˜ä¸åŒé‡æ³¨æ„åŠ›åŠ Vision Transformer çš„ CMR ç²¾å‡†è¯­ä¹‰åˆ†å‰²",
      "authors": [
        "Racheal Mukisa",
        "Arvind K. Bansal"
      ],
      "abstract": "Artificial intelligence, including deep learning models, will play a transformative role in automated medical image analysis for the diagnosis of cardiac disorders and their management. Automated accurate delineation of cardiac images is the first necessary initial step for the quantification and automated diagnosis of cardiac disorders. In this paper, we propose a deep learning based enhanced UNet model, U-R-Veda, which integrates convolution transformations, vision transformer, residual links, channel-attention, and spatial attention, together with edge-detection based skip-connections for an accurate fully-automated semantic segmentation of cardiac magnetic resonance (CMR) images. The model extracts local-features and their interrelationships using a stack of combination convolution blocks, with embedded channel and spatial attention in the convolution block, and vision transformers. Deep embedding of channel and spatial attention in the convolution block identifies important features and their spatial localization. The combined edge information with channel and spatial attention as skip connection reduces information-loss during convolution transformations. The overall model significantly improves the semantic segmentation of CMR images necessary for improved medical image analysis. An algorithm for the dual attention module (channel and spatial attention) has been presented. Performance results show that U-R-Veda achieves an average accuracy of 95.2%, based on DSC metrics. The model outperforms the accuracy attained by other models, based on DSC and HD metrics, especially for the delineation of right-ventricle and left-ventricle-myocardium.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† U-R-Vedaï¼Œè¿™æ˜¯ä¸€ç§å¢å¼ºå‹ UNet æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°å¿ƒè„ç£å…±æŒ¯æˆåƒ (CMR) çš„ç²¾ç¡®å…¨è‡ªåŠ¨è¯­ä¹‰åˆ†å‰²ã€‚è¯¥æ¨¡å‹å·§å¦™åœ°èåˆäº†å·ç§¯å˜æ¢ã€Vision Transformerã€æ®‹å·®é“¾æ¥ (residual links) ä»¥åŠåŒé‡æ³¨æ„åŠ›æœºåˆ¶ (dual attentionï¼ŒåŒ…æ‹¬é€šé“å’Œç©ºé—´æ³¨æ„åŠ›)ã€‚é€šè¿‡åœ¨å·ç§¯å—ä¸­æ·±åº¦åµŒå…¥åŒé‡æ³¨æ„åŠ›ï¼Œæ¨¡å‹èƒ½å¤Ÿç²¾å‡†è¯†åˆ«å…³é”®ç‰¹å¾åŠå…¶ç©ºé—´å®šä½ï¼Œå¹¶åˆ©ç”¨ Vision Transformer æå–å¤æ‚çš„å±€éƒ¨ç‰¹å¾åŠå…¶ç›¸äº’å…³ç³»ã€‚æ­¤å¤–ï¼Œæ¨¡å‹å°†è¾¹ç¼˜æ£€æµ‹ä¿¡æ¯ä¸æ³¨æ„åŠ›æœºåˆ¶ç»“åˆåº”ç”¨äºè·³è·ƒè¿æ¥ (skip connections)ï¼Œæœ‰æ•ˆé™ä½äº†å·ç§¯å˜æ¢è¿‡ç¨‹ä¸­çš„ä¿¡æ¯æŸå¤±ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒU-R-Veda åœ¨ DSC æŒ‡æ ‡ä¸Šè¾¾åˆ°äº† 95.2% çš„å¹³å‡å‡†ç¡®ç‡ï¼Œåœ¨å¤šé¡¹æ€§èƒ½æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰æ¨¡å‹ã€‚è¯¥æ–¹æ³•åœ¨å³å¿ƒå®¤å’Œå·¦å¿ƒå®¤å¿ƒè‚Œçš„è½®å»“å‹¾ç”»æ–¹é¢è¡¨ç°å°¤ä¸ºå“è¶Šï¼Œä¸ºæå‡å¿ƒè„ç–¾ç—…çš„è‡ªåŠ¨åŒ–è¯Šæ–­ä¸ç®¡ç†æ°´å¹³æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "15 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2506.20689v1",
      "published_date": "2025-06-25 04:10:09 UTC",
      "updated_date": "2025-06-25 04:10:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:12.559359+00:00"
    },
    {
      "arxiv_id": "2506.22497v1",
      "title": "Peer Review as Structured Commentary: Immutable Identity, Public Dialogue, and Reproducible Scholarship",
      "title_zh": "åŒè¡Œè¯„å®¡å³ç»“æ„åŒ–è¯„è®ºï¼šä¸å¯ç¯¡æ”¹èº«ä»½ã€å…¬å¼€å¯¹è¯ä¸å¯å¤ç°å­¦æœ¯",
      "authors": [
        "Craig Steven Wright"
      ],
      "abstract": "This paper reconceptualises peer review as structured public commentary. Traditional academic validation is hindered by anonymity, latency, and gatekeeping. We propose a transparent, identity-linked, and reproducible system of scholarly evaluation anchored in open commentary. Leveraging blockchain for immutable audit trails and AI for iterative synthesis, we design a framework that incentivises intellectual contribution, captures epistemic evolution, and enables traceable reputational dynamics. This model empowers fields from computational science to the humanities, reframing academic knowledge as a living process rather than a static credential.",
      "tldr_zh": "è¯¥ç ”ç©¶å°†åŒè¡Œè¯„å®¡(Peer Review)é‡æ–°å®šä¹‰ä¸ºç»“æ„åŒ–å…¬å…±è¯„è®º(Structured Commentary)ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå­¦æœ¯éªŒè¯ä¸­å­˜åœ¨çš„åŒ¿åæ€§(Anonymity)ã€å»¶è¿Ÿ(Latency)å’ŒæŠŠå…³åˆ¶(Gatekeeping)ç­‰å±€é™ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªé€æ˜ã€èº«ä»½å…³è”(Identity-linked)ä¸”å¯é‡ç°çš„å­¦æœ¯è¯„ä»·ä½“ç³»ï¼Œåˆ©ç”¨åŒºå—é“¾(Blockchain)å»ºç«‹ä¸å¯ç¯¡æ”¹çš„å®¡è®¡è¿½è¸ª(Immutable Audit Trails)ï¼Œå¹¶ç»“åˆäººå·¥æ™ºèƒ½(AI)å®ç°ä¿¡æ¯çš„è¿­ä»£åˆæˆã€‚è¯¥æ¡†æ¶é€šè¿‡æ¿€åŠ±æ™ºåŠ›è´¡çŒ®å’Œæ•æ‰è®¤è¯†è®ºæ¼”è¿›(Epistemic Evolution)ï¼Œæ„å»ºäº†å¯è¿½æº¯çš„å£°èª‰åŠ¨æ€(Reputational Dynamics)æœºåˆ¶ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿèµ‹èƒ½ä»è®¡ç®—ç§‘å­¦åˆ°äººæ–‡ç§‘å­¦çš„å¤šä¸ªé¢†åŸŸï¼Œå°†å­¦æœ¯çŸ¥è¯†ä»å•ä¸€çš„é™æ€å‡­è¯(Static Credential)é‡æ„ä¸ºä¸€ä¸ªæŒç»­å‘å±•çš„ç”Ÿå‘½è¿‡ç¨‹(Living Process)ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.DL",
        "cs.SI",
        "physics.hist-ph"
      ],
      "primary_category": "cs.CY",
      "comment": "66 pages, 0 figures, interdisciplinary framework, includes proposed architecture and metadata layer structures",
      "pdf_url": "https://arxiv.org/pdf/2506.22497v1",
      "published_date": "2025-06-25 03:57:40 UTC",
      "updated_date": "2025-06-25 03:57:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:19.951154+00:00"
    },
    {
      "arxiv_id": "2507.08005v1",
      "title": "Unraveling the Potential of Diffusion Models in Small Molecule Generation",
      "title_zh": "æ­ç¤ºæ‰©æ•£æ¨¡å‹åœ¨å°åˆ†å­ç”Ÿæˆä¸­çš„æ½œåŠ›",
      "authors": [
        "Peining Zhang",
        "Daniel Baker",
        "Minghu Song",
        "Jinbo Bi"
      ],
      "abstract": "Generative AI presents chemists with novel ideas for drug design and facilitates the exploration of vast chemical spaces. Diffusion models (DMs), an emerging tool, have recently attracted great attention in drug R\\&D. This paper comprehensively reviews the latest advancements and applications of DMs in molecular generation. It begins by introducing the theoretical principles of DMs. Subsequently, it categorizes various DM-based molecular generation methods according to their mathematical and chemical applications. The review further examines the performance of these models on benchmark datasets, with a particular focus on comparing the generation performance of existing 3D methods. Finally, it concludes by emphasizing current challenges and suggesting future research directions to fully exploit the potential of DMs in drug discovery.",
      "tldr_zh": "è¯¥ç ”ç©¶å…¨é¢ç»¼è¿°äº†æ‰©æ•£æ¨¡å‹(Diffusion Models)åœ¨å°åˆ†å­ç”Ÿæˆé¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œæ¢è®¨äº†å…¶åœ¨è¯ç‰©ç ”å‘(Drug R&D)ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚æ–‡ç« é¦–å…ˆé˜è¿°äº†æ‰©æ•£æ¨¡å‹(Diffusion Models)çš„ç†è®ºåŸºç¡€ï¼Œå¹¶ä¾æ®æ•°å­¦ä¸åŒ–å­¦åº”ç”¨åœºæ™¯å¯¹ä¸åŒçš„åˆ†å­ç”Ÿæˆæ–¹æ³•è¿›è¡Œäº†ç³»ç»Ÿåˆ†ç±»ã€‚ç ”ç©¶é‡ç‚¹å¯¹æ¯”äº†ç°æœ‰æ¨¡å‹åœ¨åŸºå‡†æ•°æ®é›†(Benchmark Datasets)ä¸Šçš„è¡¨ç°ï¼Œç‰¹åˆ«åˆ†æäº†3Dç”Ÿæˆæ–¹æ³•çš„ä¼˜åŠ£ã€‚æœ€åï¼Œè¯¥ç»¼è¿°æŒ‡å‡ºäº†å½“å‰æŠ€æœ¯é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶ä¸ºæœªæ¥åœ¨è¯ç‰©å‘ç°(Drug Discovery)é¢†åŸŸæ·±åº¦æŒ–æ˜æ‰©æ•£æ¨¡å‹(Diffusion Models)çš„æ½œåŠ›æä¾›äº†ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.08005v1",
      "published_date": "2025-06-25 03:55:44 UTC",
      "updated_date": "2025-06-25 03:55:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:25.727929+00:00"
    },
    {
      "arxiv_id": "2506.22496v1",
      "title": "Mitigating Gambling-Like Risk-Taking Behaviors in Large Language Models: A Behavioral Economics Approach to AI Safety",
      "title_zh": "ç¼“è§£å¤§è¯­è¨€æ¨¡å‹ä¸­çš„ç±»èµŒåšå¼é£é™©åå¥½è¡Œä¸ºï¼šä¸€ç§åŸºäºè¡Œä¸ºç»æµå­¦çš„äººå·¥æ™ºèƒ½å®‰å…¨æ–¹æ³•",
      "authors": [
        "Y. Du"
      ],
      "abstract": "Large Language Models (LLMs) exhibit systematic risk-taking behaviors analogous to those observed in gambling psychology, including overconfidence bias, loss-chasing tendencies, and probability misjudgment. Drawing from behavioral economics and prospect theory, we identify and formalize these \"gambling-like\" patterns where models sacrifice accuracy for high-reward outputs, exhibit escalating risk-taking after errors, and systematically miscalibrate uncertainty. We propose the Risk-Aware Response Generation (RARG) framework, incorporating insights from gambling research to address these behavioral biases through risk-calibrated training, loss-aversion mechanisms, and uncertainty-aware decision making. Our approach introduces novel evaluation paradigms based on established gambling psychology experiments, including AI adaptations of the Iowa Gambling Task and probability learning assessments. Experimental results demonstrate measurable reductions in gambling-like behaviors: 18.7\\% decrease in overconfidence bias, 24.3\\% reduction in loss-chasing tendencies, and improved risk calibration across diverse scenarios. This work establishes the first systematic framework for understanding and mitigating gambling psychology patterns in AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸­è¡¨ç°å‡ºçš„ç±»ä¼¼äºèµŒåšå¿ƒç†çš„ç³»ç»Ÿæ€§é£é™©åå¥½è¡Œä¸ºï¼ŒåŒ…æ‹¬è¿‡åº¦è‡ªä¿¡åå·® (overconfidence bias)ã€æŸå¤±è¿½é€å€¾å‘ (loss-chasing tendencies) å’Œæ¦‚ç‡è¯¯åˆ¤ (probability misjudgment)ã€‚ç ”ç©¶å›¢é˜Ÿå€Ÿé‰´è¡Œä¸ºç»æµå­¦ (behavioral economics) å’Œå±•æœ›ç†è®º (prospect theory)ï¼Œè¯†åˆ«å¹¶å…¬å¼åŒ–äº†è¿™äº›æ¨¡å‹ä¸ºè¿½æ±‚é«˜å¥–åŠ±è¾“å‡ºè€Œç‰ºç‰²å‡†ç¡®æ€§çš„æ¨¡å¼ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†é£é™©æ„ŸçŸ¥å“åº”ç”Ÿæˆ (Risk-Aware Response Generation, RARG) æ¡†æ¶ï¼Œé€šè¿‡é£é™©æ ¡å‡†è®­ç»ƒã€æŸå¤±è§„é¿æœºåˆ¶å’Œä¸ç¡®å®šæ€§æ„ŸçŸ¥å†³ç­–æ¥ä¼˜åŒ–æ¨¡å‹è¡Œä¸ºã€‚è¯„ä¼°é‡‡ç”¨äº†é€‚é… AI çš„çˆ±è·ååšå¼ˆä»»åŠ¡ (Iowa Gambling Task) ç­‰å¿ƒç†å­¦å®éªŒèŒƒå¼ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä½¿æ¨¡å‹çš„è¿‡åº¦è‡ªä¿¡åå·®é™ä½äº† 18.7%ï¼ŒæŸå¤±è¿½é€å€¾å‘å‡å°‘äº† 24.3%ï¼Œå¹¶æœ‰æ•ˆæå‡äº†åœ¨å¤šæ ·åŒ–åœºæ™¯ä¸‹çš„é£é™©æ ¡å‡†èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œä¸ºç†è§£å’Œå‡è½»äººå·¥æ™ºèƒ½ç³»ç»Ÿä¸­çš„èµŒåšå¿ƒç†æ¨¡å¼å»ºç«‹äº†é¦–ä¸ªç³»ç»Ÿæ€§æ¡†æ¶ï¼Œå¯¹æå‡äººå·¥æ™ºèƒ½å®‰å…¨ (AI Safety) å…·æœ‰é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "7 pages",
      "pdf_url": "https://arxiv.org/pdf/2506.22496v1",
      "published_date": "2025-06-25 03:45:35 UTC",
      "updated_date": "2025-06-25 03:45:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:31.357627+00:00"
    },
    {
      "arxiv_id": "2506.20103v1",
      "title": "BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos",
      "title_zh": "BrokenVideosï¼šç”¨äº AI ç”Ÿæˆè§†é¢‘ä¸­ç»†ç²’åº¦ä¼ªå½±å®šä½çš„åŸºå‡†æ•°æ®é›†",
      "authors": [
        "Jiahao Lin",
        "Weixuan Peng",
        "Bojia Zi",
        "Yifeng Gao",
        "Xianbiao Qi",
        "Xingjun Ma",
        "Yu-Gang Jiang"
      ],
      "abstract": "Recent advances in deep generative models have led to significant progress in video generation, yet the fidelity of AI-generated videos remains limited. Synthesized content often exhibits visual artifacts such as temporally inconsistent motion, physically implausible trajectories, unnatural object deformations, and local blurring that undermine realism and user trust. Accurate detection and spatial localization of these artifacts are crucial for both automated quality control and for guiding the development of improved generative models. However, the research community currently lacks a comprehensive benchmark specifically designed for artifact localization in AI generated videos. Existing datasets either restrict themselves to video or frame level detection or lack the fine-grained spatial annotations necessary for evaluating localization methods. To address this gap, we introduce BrokenVideos, a benchmark dataset of 3,254 AI-generated videos with meticulously annotated, pixel-level masks highlighting regions of visual corruption. Each annotation is validated through detailed human inspection to ensure high quality ground truth. Our experiments show that training state of the art artifact detection models and multi modal large language models (MLLMs) on BrokenVideos significantly improves their ability to localize corrupted regions. Through extensive evaluation, we demonstrate that BrokenVideos establishes a critical foundation for benchmarking and advancing research on artifact localization in generative video models. The dataset is available at: https://broken-video-detection-datetsets.github.io/Broken-Video-Detection-Datasets.github.io/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹AIç”Ÿæˆè§†é¢‘ä¸­å­˜åœ¨çš„è§†è§‰ä¼ªå½±(Artifacts)ï¼Œå¦‚è¿åŠ¨ä¸ä¸€è‡´ã€ç‰©ç†è½¨è¿¹ä¸åˆç†ã€éè‡ªç„¶ç‰©ä½“å˜å½¢åŠå±€éƒ¨æ¨¡ç³Šç­‰å½±å“çœŸå®æ„Ÿçš„é—®é¢˜ï¼ŒæŒ‡å‡ºå½“å‰ç ”ç©¶é¢†åŸŸç¼ºä¹ç”¨äºç»†ç²’åº¦ç©ºé—´å®šä½çš„ç»¼åˆåŸºå‡†ã€‚ä¸ºæ­¤ï¼Œä½œè€…æ¨å‡ºäº†BrokenVideosåŸºå‡†æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«3,254ä¸ªç»è¿‡ç²¾ç»†æ ‡æ³¨å’Œäººå·¥éªŒè¯çš„AIç”Ÿæˆè§†é¢‘ã€‚è¯¥æ•°æ®é›†æä¾›äº†åƒç´ çº§æ©ç (Pixel-level masks)ä»¥çªå‡ºæ˜¾ç¤ºè§†è§‰æŸååŒºåŸŸï¼Œå¡«è¡¥äº†ç°æœ‰æ•°æ®é›†ä»…é™äºè§†é¢‘æˆ–å¸§çº§æ£€æµ‹çš„ç©ºç™½ã€‚å®éªŒè¯æ˜ï¼Œåœ¨BrokenVideosä¸Šè®­ç»ƒæœ€å…ˆè¿›çš„ä¼ªå½±æ£€æµ‹æ¨¡å‹å’Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)ï¼Œèƒ½æ˜¾è‘—æå‡å…¶å®šä½æŸååŒºåŸŸçš„èƒ½åŠ›ã€‚è¯¥ç ”ç©¶ä¸ºç”Ÿæˆå¼è§†é¢‘æ¨¡å‹ä¸­Artifact Localizationçš„åŸºå‡†æµ‹è¯•å’ŒæŠ€æœ¯è¿›æ­¥å¥ å®šäº†å…³é”®åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 page,4 figures,2 tables",
      "pdf_url": "https://arxiv.org/pdf/2506.20103v1",
      "published_date": "2025-06-25 03:30:04 UTC",
      "updated_date": "2025-06-25 03:30:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:26.625440+00:00"
    },
    {
      "arxiv_id": "2506.22495v4",
      "title": "Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses",
      "title_zh": "æ„ŸçŸ¥å¿ƒè„çš„æ©ç è‡ªç¼–ç å™¨ï¼šæ­ç¤ºå¿ƒç”µå›¾åˆ†æä¸­çš„ç®€å•æ€§åç½®",
      "authors": [
        "He-Yang Xu",
        "Hongxiang Gao",
        "Yuwen Li",
        "Xiu-Shen Wei",
        "Chengyu Liu"
      ],
      "abstract": "The diagnostic value of electrocardiogram (ECG) lies in its dynamic characteristics, ranging from rhythm fluctuations to subtle waveform deformations that evolve across time and frequency domains. However, supervised ECG models tend to overfit dominant and repetitive patterns, overlooking fine-grained but clinically critical cues, a phenomenon known as Simplicity Bias (SB), where models favor easily learnable signals over subtle but informative ones. In this work, we first empirically demonstrate the presence of SB in ECG analyses and its negative impact on diagnostic performance, while simultaneously discovering that self-supervised learning (SSL) can alleviate it, providing a promising direction for tackling the bias. Following the SSL paradigm, we propose a novel method comprising two key components: 1) Temporal-Frequency aware Filters to capture temporal-frequency features reflecting the dynamic characteristics of ECG signals, and 2) building on this, Multi-Grained Prototype Reconstruction for coarse and fine representation learning across dual domains, further mitigating SB. To advance SSL in ECG analyses, we curate a large-scale multi-site ECG dataset with 1.53 million recordings from over 300 clinical centers. Experiments on three downstream tasks across six ECG datasets demonstrate that our method effectively reduces SB and achieves state-of-the-art performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† ECG åˆ†æä¸­å­˜åœ¨çš„ Simplicity Bias é—®é¢˜ï¼Œå³ç›‘ç£å­¦ä¹ æ¨¡å‹å¾€å¾€å€¾å‘äºæ‹Ÿåˆæ˜“è§çš„é‡å¤æ¨¡å¼è€Œå¿½è§†ç»†å¾®ä½†å…³é”®çš„ä¸´åºŠä¿¡å·ã€‚ä½œè€…é€šè¿‡å®éªŒè¯æ˜äº†è¯¥åè§å¯¹è¯Šæ–­æ€§èƒ½çš„è´Ÿé¢å½±å“ï¼Œå¹¶å‘ç° Self-supervised learning æ˜¯è§£å†³è¿™ä¸€é—®é¢˜çš„æœ‰æ•ˆé€”å¾„ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åŒ…å« Temporal-Frequency aware Filters å’Œ Multi-Grained Prototype Reconstruction çš„æ–°æ–¹æ³•ï¼Œç”¨äºæ•æ‰æ—¶é¢‘ç‰¹å¾å¹¶å®ç°åŒåŸŸä¸‹çš„ç²—ç»†ç²’åº¦è¡¨å¾å­¦ä¹ ã€‚ä¸ºæ¨è¿›è¯¥é¢†åŸŸç ”ç©¶ï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ªåŒ…å«æ¥è‡ª 300 å¤šä¸ªä¸´åºŠä¸­å¿ƒçš„ 1.53 million æ¡è®°å½•çš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…­ä¸ªæ•°æ®é›†çš„ä¸‰é¡¹ä¸‹æ¸¸ä»»åŠ¡ä¸­å‡è¾¾åˆ°äº† State-of-the-art æ€§èƒ½ï¼Œæ˜¾è‘—å‡è½»äº† Simplicity Bias å¹¶æå‡äº†å¿ƒç”µè¯Šæ–­çš„å‡†ç¡®æ€§ä¸ç¨³å¥æ€§ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Revised Version 4",
      "pdf_url": "https://arxiv.org/pdf/2506.22495v4",
      "published_date": "2025-06-25 03:25:49 UTC",
      "updated_date": "2025-07-28 01:29:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:49.275516+00:00"
    },
    {
      "arxiv_id": "2506.20100v2",
      "title": "MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations",
      "title_zh": "MIRAGEï¼šå†œä¸šä¸“å®¶å¼•å¯¼å¯¹è¯ä¸­çš„å¤šæ¨¡æ€ä¿¡æ¯å¯»æ±‚ä¸æ¨ç†åŸºå‡†",
      "authors": [
        "Vardhan Dongre",
        "Chi Gui",
        "Shubham Garg",
        "Hooshang Nayyeri",
        "Gokhan Tur",
        "Dilek Hakkani-TÃ¼r",
        "Vikram S. Adve"
      ],
      "abstract": "We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning and decision-making in consultative interaction settings. Designed for the agriculture domain, MIRAGE captures the full complexity of expert consultations by combining natural user queries, expert-authored responses, and image-based context, offering a high-fidelity benchmark for evaluating models on grounded reasoning, clarification strategies, and long-form generation in a real-world, knowledge-intensive domain. Grounded in over 35,000 real user-expert interactions and curated through a carefully designed multi-step pipeline, MIRAGE spans diverse crop health, pest diagnosis, and crop management scenarios. The benchmark includes more than 7,000 unique biological entities, covering plant species, pests, and diseases, making it one of the most taxonomically diverse benchmarks available for vision-language models, grounded in the real world. Unlike existing benchmarks that rely on well-specified user inputs and closed-set taxonomies, MIRAGE features underspecified, context-rich scenarios with open-world settings, requiring models to infer latent knowledge gaps, handle rare entities, and either proactively guide the interaction or respond. Project Page: https://mirage-benchmark.github.io",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MIRAGEï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹å†œä¸šä¸“å®¶å’¨è¯¢åœºæ™¯ä¸­å¤šæ¨¡æ€ä¿¡æ¯å¯»æ±‚ (Multimodal Information-Seeking) ä¸æ¨ç†çš„æ–°å‹åŸºå‡†ã€‚è¯¥åŸºå‡†åŸºäºè¶…è¿‡ 35,000 æ¬¡çœŸå®çš„ä¸“å®¶ä¸ç”¨æˆ·äº’åŠ¨æ•°æ®ï¼Œæ¶µç›–äº†ä½œç‰©å¥åº·ã€ç—…è™«å®³è¯Šæ–­åŠä½œç‰©ç®¡ç†ç­‰å¤šç§å¤æ‚ä¸”çŸ¥è¯†å¯†é›†å‹çš„ç°å®åœºæ™¯ã€‚MIRAGE åŒ…å«è¶…è¿‡ 7,000 ä¸ªç‹¬ç‰¹çš„ç”Ÿç‰©å®ä½“ (Biological Entities)ï¼Œæ˜¯ç›®å‰é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹ (Vision-Language Models) æœ€å…·åˆ†ç±»å¤šæ ·æ€§çš„åŸºå‡†ä¹‹ä¸€ã€‚ä¸åŒäºä»¥å¾€ä¾èµ–æ˜ç¡®è¾“å…¥å’Œå°é—­åˆ†ç±»ç³»ç»Ÿçš„åŸºå‡†ï¼ŒMIRAGE é‡‡ç”¨ä¸å……åˆ†æŒ‡å®š (Underspecified) ä¸”å¯Œå«ä¸Šä¸‹æ–‡çš„å¼€æ”¾ä¸–ç•Œ (Open-World) è®¾ç½®ï¼Œè¦æ±‚æ¨¡å‹èƒ½å¤Ÿæ¨æ–­æ½œåœ¨çš„çŸ¥è¯†å·®è·å¹¶ä¸»åŠ¨å¼•å¯¼äº¤äº’ã€‚é€šè¿‡åœ¨æ¥åœ°æ¨ç† (Grounded Reasoning)ã€æ¾„æ¸…ç­–ç•¥ (Clarification Strategies) å’Œé•¿æ–‡æœ¬ç”Ÿæˆç­‰ä»»åŠ¡ä¸Šçš„ç»¼åˆè¯„ä¼°ï¼Œè¯¥åŸºå‡†ä¸ºå¼€å‘å¯å¤„ç†ç½•è§å®ä½“å’Œå¤æ‚å†³ç­–çš„å†œä¸š AI ç³»ç»Ÿæä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2506.20100v2",
      "published_date": "2025-06-25 03:07:54 UTC",
      "updated_date": "2026-01-06 04:02:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:57.503078+00:00"
    },
    {
      "arxiv_id": "2507.00052v1",
      "title": "VSF-Med:A Vulnerability Scoring Framework for Medical Vision-Language Models",
      "title_zh": "VSF-Medï¼šåŒ»ç–—è§†è§‰è¯­è¨€æ¨¡å‹æ¼æ´è¯„åˆ†æ¡†æ¶",
      "authors": [
        "Binesh Sadanandan",
        "Vahid Behzadan"
      ],
      "abstract": "Vision Language Models (VLMs) hold great promise for streamlining labour-intensive medical imaging workflows, yet systematic security evaluations in clinical settings remain scarce. We introduce VSF--Med, an end-to-end vulnerability-scoring framework for medical VLMs that unites three novel components: (i) a rich library of sophisticated text-prompt attack templates targeting emerging threat vectors; (ii) imperceptible visual perturbations calibrated by structural similarity (SSIM) thresholds to preserve clinical realism; and (iii) an eight-dimensional rubric evaluated by two independent judge LLMs, whose raw scores are consolidated via z-score normalization to yield a 0--32 composite risk metric. Built entirely on publicly available datasets and accompanied by open-source code, VSF--Med synthesizes over 30,000 adversarial variants from 5,000 radiology images and enables reproducible benchmarking of any medical VLM with a single command. Our consolidated analysis reports mean z-score shifts of $0.90Ïƒ$ for persistence-of-attack-effects, $0.74Ïƒ$ for prompt-injection effectiveness, and $0.63Ïƒ$ for safety-bypass success across state-of-the-art VLMs. Notably, Llama-3.2-11B-Vision-Instruct exhibits a peak vulnerability increase of $1.29Ïƒ$ for persistence-of-attack-effects, while GPT-4o shows increases of $0.69Ïƒ$ for that same vector and $0.28Ïƒ$ for prompt-injection attacks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†VSF-Medï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹åŒ»ç–—é¢†åŸŸè§†è§‰è¯­è¨€æ¨¡å‹(Vision Language Models, VLMs)çš„ç«¯åˆ°ç«¯æ¼æ´è¯„åˆ†æ¡†æ¶ï¼Œæ—¨åœ¨å¡«è¡¥ä¸´åºŠç¯å¢ƒä¸‹ç³»ç»Ÿæ€§å®‰å…¨è¯„ä¼°çš„ç©ºç™½ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šä¸€å¥—é’ˆå¯¹æ–°å…´å¨èƒå‘é‡çš„å¤æ‚æ–‡æœ¬æç¤ºæ”»å‡»æ¨¡æ¿åº“ï¼Œä»¥åŠé€šè¿‡ç»“æ„ç›¸ä¼¼æ€§(SSIM)é˜ˆå€¼æ ¡å‡†ã€ä»¥ä¿æŒä¸´åºŠçœŸå®æ„Ÿçš„ä¸å¯å¯Ÿè§‰è§†è§‰æ‰°åŠ¨æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œå®ƒå¼•å…¥äº†ä¸€ä¸ªç”±ä¸¤ä¸ªç‹¬ç«‹çš„å¤§è¯­è¨€æ¨¡å‹(judge LLMs)è¯„ä¼°çš„å…«ç»´ç»†åˆ™ï¼Œå¹¶é€šè¿‡z-scoreå½’ä¸€åŒ–æ±‡æ€»åˆ†å€¼ï¼Œæœ€ç»ˆç”Ÿæˆä¸€ä¸ª0åˆ°32çš„ç»¼åˆé£é™©æŒ‡æ ‡ã€‚åŸºäºå…¬å¼€æ•°æ®é›†ï¼ŒVSF-Medä»5000å¼ æ”¾å°„å­¦å›¾åƒä¸­åˆæˆäº†è¶…è¿‡30,000ä¸ªå¯¹æŠ—æ€§å˜ä½“ï¼Œå®ç°äº†å¯¹åŒ»ç–—VLMçš„ä¸€é”®å¼å¯é‡å¤åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸»æµSOTAæ¨¡å‹åœ¨æ”»å‡»æ•ˆæœæŒä¹…æ€§(persistence-of-attack-effects)ã€æç¤ºæ³¨å…¥(prompt-injection)æœ‰æ•ˆæ€§å’Œå®‰å…¨ç»•è¿‡(safety-bypass)æˆåŠŸç‡æ–¹é¢å‡å­˜åœ¨æ˜¾è‘—æ¼æ´ã€‚ç‰¹åˆ«æ˜¯Llama-3.2-11B-Vision-Instructå’ŒGPT-4oåœ¨ç‰¹å®šæ”»å‡»ç»´åº¦ä¸‹è¡¨ç°å‡ºæ˜æ˜¾çš„è„†å¼±æ€§ï¼Œä¸ºæå‡åŒ»ç–—AIç³»ç»Ÿçš„å®‰å…¨æ€§æä¾›äº†é‡è¦çš„è¯„ä¼°å·¥å…·ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.00052v1",
      "published_date": "2025-06-25 02:56:38 UTC",
      "updated_date": "2025-06-25 02:56:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:58.057246+00:00"
    },
    {
      "arxiv_id": "2507.02912v3",
      "title": "Deep Graph Learning for Industrial Carbon Emission Analysis and Policy Impact",
      "title_zh": "é¢å‘å·¥ä¸šç¢³æ’æ”¾åˆ†æä¸æ”¿ç­–å½±å“çš„æ·±åº¦å›¾å­¦ä¹ ",
      "authors": [
        "Xuanming Zhang"
      ],
      "abstract": "Industrial carbon emissions are a major driver of climate change, yet modeling these emissions is challenging due to multicollinearity among factors and complex interdependencies across sectors and time. We propose a novel graph-based deep learning framework DGL to analyze and forecast industrial CO_2 emissions, addressing high feature correlation and capturing industrial-temporal interdependencies. Unlike traditional regression or clustering methods, our approach leverages a Graph Neural Network (GNN) with attention mechanisms to model relationships between industries (or regions) and a temporal transformer to learn long-range patterns. We evaluate our framework on public global industry emissions dataset derived from EDGAR v8.0, spanning multiple countries and sectors. The proposed model achieves superior predictive performance - reducing error by over 15% compared to baseline deep models - while maintaining interpretability via attention weights and causal analysis. We believe that we are the first Graph-Temporal architecture that resolves multicollinearity by structurally encoding feature relationships, along with integration of causal inference to identify true drivers of emissions, improving transparency and fairness. We also stand a demonstration of policy relevance, showing how model insights can guide sector-specific decarbonization strategies aligned with sustainable development goals. Based on the above, we show high-emission \"hotspots\" and suggest equitable intervention plans, illustrating the potential of state-of-the-art AI graph learning to advance climate action, offering a powerful tool for policymakers and industry stakeholders to achieve carbon reduction targets.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DGL æ¡†æ¶ï¼Œä¸€ç§æ–°å‹çš„åŸºäºå›¾çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œæ—¨åœ¨è§£å†³å·¥ä¸šç¢³æ’æ”¾å»ºæ¨¡ä¸­å› ç´ é—´çš„å¤šé‡å…±çº¿æ€§ (Multicollinearity) å’Œå¤æ‚çš„è·¨éƒ¨é—¨ã€è·¨æ—¶é—´ä¾èµ–å…³ç³»ã€‚è¯¥æ–¹æ³•ç»“åˆäº†å…·å¤‡æ³¨æ„åŠ›æœºåˆ¶ (Attention Mechanism) çš„å›¾ç¥ç»ç½‘ç»œ (GNN) ä»¥æ•æ‰è¡Œä¸šåŠåŒºåŸŸé—´çš„å…³è”ï¼Œå¹¶åˆ©ç”¨æ—¶é—´è½¬æ¢å™¨ (Temporal Transformer) å­¦ä¹ é•¿æœŸæ’æ”¾æ¨¡å¼ã€‚å®éªŒç»“æœåœ¨ EDGAR v8.0 å…¨çƒå·¥ä¸šæ’æ”¾æ•°æ®é›†ä¸Šè¡¨æ˜ï¼ŒDGL ç›¸æ¯”åŸºçº¿æ¨¡å‹å°†é¢„æµ‹è¯¯å·®é™ä½äº† 15% ä»¥ä¸Šã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é€šè¿‡é›†æˆå› æœæ¨ç† (Causal Inference) è¯†åˆ«æ’æ”¾çš„çœŸå®é©±åŠ¨å› ç´ ï¼Œä¸ä»…æé«˜äº†æ¨¡å‹çš„é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ï¼Œè¿˜ä¸ºè¯†åˆ«é«˜æ’æ”¾çƒ­ç‚¹ (Hotspots) åŠåˆ¶å®šé’ˆå¯¹æ€§çš„è„±ç¢³æ”¿ç­–æä¾›äº†ç§‘å­¦ä¾æ®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025 AI for Science Workshop",
      "pdf_url": "https://arxiv.org/pdf/2507.02912v3",
      "published_date": "2025-06-25 02:42:29 UTC",
      "updated_date": "2025-11-05 19:25:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:55.042287+00:00"
    },
    {
      "arxiv_id": "2507.22896v1",
      "title": "iLearnRobot: An Interactive Learning-Based Multi-Modal Robot with Continuous Improvement",
      "title_zh": "iLearnRobotï¼šå…·å¤‡æŒç»­æ”¹è¿›èƒ½åŠ›çš„äº¤äº’å¼å­¦ä¹ å¤šæ¨¡æ€æœºå™¨äºº",
      "authors": [
        "Kohou Wang",
        "ZhaoXiang Liu",
        "Lin Bai",
        "Kun Fan",
        "Xiang Liu",
        "Huan Hu",
        "Kai Wang",
        "Shiguo Lian"
      ],
      "abstract": "It is crucial that robots' performance can be improved after deployment, as they are inherently likely to encounter novel scenarios never seen before. This paper presents an innovative solution: an interactive learning-based robot system powered by a Multi-modal Large Language Model(MLLM). A key feature of our system is its ability to learn from natural dialogues with non-expert users. We also propose chain of question to clarify the exact intent of the question before providing an answer and dual-modality retrieval modules to leverage these interaction events to avoid repeating same mistakes, ensuring a seamless user experience before model updates, which is in contrast to current mainstream MLLM-based robotic systems. Our system marks a novel approach in robotics by integrating interactive learning, paving the way for superior adaptability and performance in diverse environments. We demonstrate the effectiveness and improvement of our method through experiments, both quantitively and qualitatively.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†iLearnRobotï¼Œä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(Multi-modal Large Language Model, MLLM)çš„äº¤äº’å¼å­¦ä¹ æœºå™¨äººç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³æœºå™¨äººéƒ¨ç½²ååœ¨æœªçŸ¥åœºæ™¯ä¸­å®ç°æ€§èƒ½æŒç»­æ”¹è¿›çš„å…³é”®æŒ‘æˆ˜ã€‚è¯¥ç³»ç»Ÿå…·å¤‡ä»ä¸éä¸“å®¶ç”¨æˆ·çš„è‡ªç„¶å¯¹è¯ä¸­å­¦ä¹ çš„èƒ½åŠ›ï¼Œå¹¶å¼•å…¥äº†é—®é¢˜é“¾(Chain of Question)æœºåˆ¶ä»¥åœ¨æä¾›ç­”æ¡ˆå‰ç²¾å‡†æ¾„æ¸…ç”¨æˆ·æ„å›¾ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è®¾è®¡äº†åŒæ¨¡æ€æ£€ç´¢æ¨¡å—(Dual-modality Retrieval)æ¥åˆ©ç”¨äº¤äº’å†å²ï¼Œä»è€Œé¿å…é‡å¤çŠ¯é”™å¹¶ç¡®ä¿æ¨¡å‹æ›´æ–°å‰çš„æ— ç¼ç”¨æˆ·ä½“éªŒã€‚è¿™ç§å°†äº¤äº’å¼å­¦ä¹ é›†æˆçš„åˆ›æ–°æ–¹æ³•ï¼Œä¸ºæœºå™¨äººå¢å¼ºåœ¨å¤šæ ·åŒ–ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œè¡¨ç°å¼€è¾Ÿäº†æ–°é€”å¾„ã€‚å®šé‡å’Œå®šæ€§å®éªŒç»“æœå‡è¯æ˜äº†è¯¥æ–¹æ³•åœ¨æå‡æœºå™¨äººæ€§èƒ½æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "17 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.22896v1",
      "published_date": "2025-06-25 02:10:53 UTC",
      "updated_date": "2025-06-25 02:10:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:36:57.785638+00:00"
    },
    {
      "arxiv_id": "2507.00050v2",
      "title": "SEZ-HARN: Self-Explainable Zero-shot Human Activity Recognition Network",
      "title_zh": "SEZ-HARNï¼šè‡ªè§£é‡Šé›¶æ ·æœ¬äººä½“æ´»åŠ¨è¯†åˆ«ç½‘ç»œ",
      "authors": [
        "Devin Y. De Silva",
        "Sandareka Wickramanayake",
        "Dulani Meedeniya",
        "Sanka Rasnayaka"
      ],
      "abstract": "Human Activity Recognition (HAR), which uses data from Inertial Measurement Unit (IMU) sensors, has many practical applications in healthcare and assisted living environments. However, its use in real-world scenarios has been limited by the lack of comprehensive IMU-based HAR datasets that cover a wide range of activities and the lack of transparency in existing HAR models. Zero-shot HAR (ZS-HAR) overcomes the data limitations, but current models struggle to explain their decisions, making them less transparent. This paper introduces a novel IMU-based ZS-HAR model called the Self-Explainable Zero-shot Human Activity Recognition Network (SEZ-HARN). It can recognize activities not encountered during training and provide skeleton videos to explain its decision-making process. We evaluate the effectiveness of the proposed SEZ-HARN on four benchmark datasets PAMAP2, DaLiAc, HTD-MHAD and MHealth and compare its performance against three state-of-the-art black-box ZS-HAR models. The experiment results demonstrate that SEZ-HARN produces realistic and understandable explanations while achieving competitive Zero-shot recognition accuracy. SEZ-HARN achieves a Zero-shot prediction accuracy within 3\\% of the best-performing black-box model on PAMAP2 while maintaining comparable performance on the other three datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºæƒ¯æ€§æµ‹é‡å•å…ƒ (IMU) ä¼ æ„Ÿå™¨çš„äººä½“æ´»åŠ¨è¯†åˆ« (HAR) åœ¨åŒ»ç–—ä¿å¥åº”ç”¨ä¸­é¢ä¸´çš„è·¨åœºæ™¯æ•°æ®é›†åŒ®ä¹å’Œæ¨¡å‹ç¼ºä¹é€æ˜åº¦çš„é—®é¢˜ï¼Œæå‡ºäº† SEZ-HARN (Self-Explainable Zero-shot Human Activity Recognition Network) æ¨¡å‹ã€‚è¯¥ç½‘ç»œä¸ä»…èƒ½å¤Ÿè¯†åˆ«è®­ç»ƒä¸­æœªè§çš„æ´»åŠ¨ï¼Œå®ç°é›¶æ ·æœ¬ (Zero-shot) è¯†åˆ«ï¼Œè¿˜èƒ½é€šè¿‡ç”Ÿæˆéª¨æ¶è§†é¢‘ (skeleton videos) ä¸ºå…¶å†³ç­–è¿‡ç¨‹æä¾›ç›´è§‚çš„è‡ªæˆ‘è§£é‡Šã€‚ç ”ç©¶äººå‘˜åœ¨ PAMAP2ã€DaLiAcã€HTD-MHAD å’Œ MHealth å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå¹¶å°†å…¶ä¸ä¸‰ç§æœ€å…ˆè¿›çš„é»‘ç›’ (black-box) æ¨¡å‹è¿›è¡Œå¯¹æ¯”ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSEZ-HARN åœ¨ç”Ÿæˆæ˜“äºç†è§£çš„è§£é‡Šçš„åŒæ—¶ï¼Œä¿æŒäº†æå…·ç«äº‰åŠ›çš„å‡†ç¡®ç‡ï¼Œç‰¹åˆ«æ˜¯åœ¨ PAMAP2 æ•°æ®é›†ä¸Šï¼Œå…¶å‡†ç¡®ç‡ä¸é¡¶çº§é»‘ç›’æ¨¡å‹çš„å·®è·æ§åˆ¶åœ¨ 3% ä»¥å†…ã€‚è¯¥ç ”ç©¶é€šè¿‡ç»“åˆé›¶æ ·æœ¬å­¦ä¹ ä¸å¯è§†åŒ–è§£é‡Šæœºåˆ¶ï¼Œä¸ºæå‡äººä½“æ´»åŠ¨è¯†åˆ«ç³»ç»Ÿçš„å®ç”¨æ€§ä¸å¯ä¿¡åº¦æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.00050v2",
      "published_date": "2025-06-25 02:10:34 UTC",
      "updated_date": "2025-07-05 21:04:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:37:07.426716+00:00"
    },
    {
      "arxiv_id": "2506.20081v2",
      "title": "SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization",
      "title_zh": "SACLï¼šåŸºäºè¯­ä¹‰å¢å¼ºé‡æ’åºä¸å®šä½çš„ä»£ç æ£€ç´¢æ–‡æœ¬åå·®ç†è§£ä¸åº”å¯¹",
      "authors": [
        "Dhruv Gupta",
        "Gayathri Ganesh Lakshmy",
        "Yiqing Xie"
      ],
      "abstract": "Retrieval-Augmented Code Generation (RACG) is a critical technique for enhancing code generation by retrieving relevant information. In this work, we conduct an in-depth analysis of code retrieval by systematically masking specific features while preserving code functionality. Our discoveries include: (1) although trained on code, current retrievers heavily rely on surface-level textual features (e.g., docstrings, identifier names), and (2) they exhibit a strong bias towards well-documented code, even if the documentation is irrelevant. Based on our discoveries, we propose SACL, a framework that enriches textual information and reduces bias by augmenting code or structural knowledge with semantic information. Extensive experiments show that SACL substantially improves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on HumanEval / MBPP / SWE-Bench-Lite), which also leads to better code generation performance (e.g., by 4.88% Pass@1 on HumanEval).",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥åˆ†æäº†æ£€ç´¢å¢å¼ºä»£ç ç”Ÿæˆ(Retrieval-Augmented Code Generation)ä¸­çš„ä»£ç æ£€ç´¢åå·®é—®é¢˜ï¼Œæ­ç¤ºäº†ç°æœ‰æ£€ç´¢å™¨åœ¨å¤„ç†ä»£ç æ—¶å­˜åœ¨çš„æ ¸å¿ƒç¼ºé™·ã€‚é€šè¿‡å¯¹ç‰¹å¾è¿›è¡Œç³»ç»Ÿæ€§é®è”½åˆ†æï¼Œç ”ç©¶å‘ç°å½“å‰çš„æ£€ç´¢å™¨è¿‡åº¦ä¾èµ–docstringså’Œidentifier namesç­‰è¡¨é¢æ–‡æœ¬ç‰¹å¾ï¼Œå¹¶å¯¹æ–‡æ¡£å†…å®¹ä¸°å¯Œçš„ä»£ç è¡¨ç°å‡ºå¼ºçƒˆçš„åå·®ï¼Œå³ä¾¿å…¶æ–‡æ¡£ä¸å®é™…åŠŸèƒ½æ— å…³ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†SACLæ¡†æ¶ï¼Œé€šè¿‡å°†è¯­ä¹‰ä¿¡æ¯èå…¥ä»£ç æˆ–ç»“æ„çŸ¥è¯†ä¸­ï¼Œå®ç°è¯­ä¹‰å¢å¼ºçš„é‡æ’åºä¸å®šä½ï¼Œä»è€Œæœ‰æ•ˆä¸°å¯Œæ–‡æœ¬ä¿¡æ¯å¹¶ç¼“è§£æ£€ç´¢åå·®ã€‚å®éªŒè¯æ˜ï¼ŒSACLåœ¨HumanEvalã€MBPPå’ŒSWE-Bench-Liteç­‰åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ£€ç´¢æ€§èƒ½ï¼ŒRecall@1æœ€é«˜æå‡äº†12.8%ã€‚è¿™ç§æ£€ç´¢è´¨é‡çš„ä¼˜åŒ–æœ€ç»ˆæ˜¾è‘—å¢å¼ºäº†ä»£ç ç”Ÿæˆè¡¨ç°ï¼Œä½¿HumanEvalæ•°æ®é›†ä¸Šçš„Pass@1æ€§èƒ½æå‡äº†4.88%ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20081v2",
      "published_date": "2025-06-25 01:44:28 UTC",
      "updated_date": "2025-06-26 04:06:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:37:28.277661+00:00"
    },
    {
      "arxiv_id": "2506.20073v1",
      "title": "A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs",
      "title_zh": "èåˆæ—¶ç©ºæ¨¡å‹ä¸å¤§è¯­è¨€æ¨¡å‹çš„æ¨¡å—åŒ–å¤šä»»åŠ¡æ¨ç†æ¡†æ¶",
      "authors": [
        "Kethmi Hirushini Hettige",
        "Jiahao Ji",
        "Cheng Long",
        "Shili Xiang",
        "Gao Cong",
        "Jingyuan Wang"
      ],
      "abstract": "Spatio-temporal data mining plays a pivotal role in informed decision making across diverse domains. However, existing models are often restricted to narrow tasks, lacking the capacity for multi-task inference and complex long-form reasoning that require generation of in-depth, explanatory outputs. These limitations restrict their applicability to real-world, multi-faceted decision scenarios. In this work, we introduce STReason, a novel framework that integrates the reasoning strengths of large language models (LLMs) with the analytical capabilities of spatio-temporal models for multi-task inference and execution. Without requiring task-specific finetuning, STReason leverages in-context learning to decompose complex natural language queries into modular, interpretable programs, which are then systematically executed to generate both solutions and detailed rationales. To facilitate rigorous evaluation, we construct a new benchmark dataset and propose a unified evaluation framework with metrics specifically designed for long-form spatio-temporal reasoning. Experimental results show that STReason significantly outperforms advanced LLM baselines across all metrics, particularly excelling in complex, reasoning-intensive spatio-temporal scenarios. Human evaluations further validate STReason's credibility and practical utility, demonstrating its potential to reduce expert workload and broaden the applicability to real-world spatio-temporal tasks. We believe STReason provides a promising direction for developing more capable and generalizable spatio-temporal reasoning systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰æ—¶ç©ºæ•°æ®æŒ–æ˜æ¨¡å‹åœ¨å¤šä»»åŠ¡æ¨ç†å’Œå¤æ‚é•¿æ–‡é€»è¾‘è§£é‡Šæ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº† STReason æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„æ¨ç†èƒ½åŠ›ä¸æ—¶ç©ºæ¨¡å‹ (spatio-temporal models) çš„åˆ†æèƒ½åŠ›ç›¸ç»“åˆï¼Œæ—¨åœ¨å®ç°é«˜æ•ˆçš„å¤šä»»åŠ¡æ¨ç†ä¸æ‰§è¡Œã€‚STReason æ— éœ€é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œå¾®è°ƒ (finetuning)ï¼Œè€Œæ˜¯åˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹  (in-context learning) å°†å¤æ‚çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢åˆ†è§£ä¸ºæ¨¡å—åŒ–ã€å¯è§£é‡Šçš„ç¨‹åºï¼Œå¹¶ç³»ç»Ÿåœ°æ‰§è¡Œä»¥ç”Ÿæˆè§£å†³æ–¹æ¡ˆå’Œè¯¦ç»†çš„é€»è¾‘ä¾æ® (rationales)ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªå…¨æ–°çš„åŸºå‡†æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†ä¸“é—¨ç”¨äºé•¿æ–‡æ—¶ç©ºæ¨ç†çš„ç»Ÿä¸€è¯„ä¼°æŒ‡æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSTReason åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºå…ˆè¿›çš„ LLM åŸºå‡†æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¨ç†å¯†é›†å‹çš„æ—¶ç©ºåœºæ™¯ä¸­è¡¨ç°å“è¶Šã€‚äººå·¥è¯„ä¼°è¿›ä¸€æ­¥è¯å®äº†è¯¥æ¡†æ¶çš„å¯é æ€§ä¸å®ç”¨ä»·å€¼ï¼Œå±•ç°äº†å…¶åœ¨å‡è½»ä¸“å®¶å·¥ä½œè´Ÿæ‹…å’Œæ‹“å®½ç°å®ä¸–ç•Œæ—¶ç©ºä»»åŠ¡åº”ç”¨æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2506.20073v1",
      "published_date": "2025-06-25 00:55:34 UTC",
      "updated_date": "2025-06-25 00:55:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:37:19.667604+00:00"
    },
    {
      "arxiv_id": "2507.02911v1",
      "title": "DiceHuBERT: Distilling HuBERT with a Self-Supervised Learning Objective",
      "title_zh": "DiceHuBERTï¼šåŸºäºè‡ªç›‘ç£å­¦ä¹ ç›®æ ‡çš„ HuBERT è’¸é¦",
      "authors": [
        "Hyung Gun Chi",
        "Zakaria Aldeneh",
        "Tatiana Likhomanenko",
        "Oggi Rudovic",
        "Takuya Higuchi",
        "Li-Wei Chen",
        "Shinji Watanabe",
        "Ahmed Hussen Abdelaziz"
      ],
      "abstract": "We introduce DiceHuBERT, a knowledge distillation framework for compressing HuBERT, a widely used self-supervised learning (SSL)-based speech foundation model. Unlike existing distillation methods that rely on layer-wise and feature-wise mapping between teacher and student models, DiceHuBERT leverages HuBERT's iterative self-distillation mechanism by directly replacing the original model with a student model. This replacement allows the student to be trained using the same SSL objective used when pre-training HuBERT, eliminating the need for additional modules or architectural constraints. Experimental results on SUPERB show that DiceHuBERT consistently outperforms existing distillation methods, improving phoneme recognition performance by over 21% and ASR performance by more than 14%. Furthermore, DiceHuBERT demonstrates competitive performance across multiple tasks, highlighting its clear advantage.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DiceHuBERTï¼Œä¸€ç§ç”¨äºå‹ç¼©è‡ªç›‘ç£å­¦ä¹ (Self-Supervised Learning, SSL)è¯­éŸ³åŸºç¡€æ¨¡å‹HuBERTçš„çŸ¥è¯†è’¸é¦(Knowledge Distillation)æ¡†æ¶ã€‚ä¸åŒäºä¼ ç»Ÿä¾èµ–æ•™å¸ˆä¸å­¦ç”Ÿæ¨¡å‹é—´å±‚çº§æˆ–ç‰¹å¾æ˜ å°„çš„æ–¹æ³•ï¼ŒDiceHuBERTåˆ©ç”¨HuBERTçš„è¿­ä»£è‡ªè’¸é¦æœºåˆ¶ï¼Œé€šè¿‡ç›´æ¥å°†åŸå§‹æ¨¡å‹æ›¿æ¢ä¸ºå­¦ç”Ÿæ¨¡å‹å¹¶é‡‡ç”¨ç›¸åŒçš„SSLé¢„è®­ç»ƒç›®æ ‡è¿›è¡Œè®­ç»ƒã€‚è¿™ç§è®¾è®¡æ¶ˆé™¤äº†å¯¹é¢å¤–æ¨¡å—æˆ–ç‰¹å®šæ¶æ„çº¦æŸçš„éœ€æ±‚ï¼Œä½¿å¾—å­¦ç”Ÿæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæ›´åŠ çµæ´»ã€‚åœ¨SUPERBåŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDiceHuBERTçš„ä¸€è‡´æ€§è¡¨ç°ä¼˜äºç°æœ‰è’¸é¦æ–¹æ³•ï¼Œå°†éŸ³ç´ è¯†åˆ«(Phoneme Recognition)æ€§èƒ½æå‡äº†21%ä»¥ä¸Šï¼Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)æ€§èƒ½æå‡äº†14%ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒDiceHuBERTåœ¨å¤šé¡¹ä»»åŠ¡ä¸­å‡å±•ç°å‡ºæå…·ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å®ç°è½»é‡åŒ–è¯­éŸ³åŸºç¡€æ¨¡å‹æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 1 figure, interspeech accepted paper",
      "pdf_url": "https://arxiv.org/pdf/2507.02911v1",
      "published_date": "2025-06-25 00:39:33 UTC",
      "updated_date": "2025-06-25 00:39:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T00:37:29.405868+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 129,
  "processed_papers_count": 129,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T00:46:25.719683+00:00"
}