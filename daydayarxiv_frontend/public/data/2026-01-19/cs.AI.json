{
  "date": "2026-01-19",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2026-01-19 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ **ä»Šæ—¥æ€»ç»“**ï¼š\nä»Šå¤©çš„ arXiv å……æ»¡äº†**â€œåæ€â€ä¸â€œè­¦ç¤ºâ€**çš„æ„å‘³ã€‚æˆ‘ä»¬çœ‹åˆ°äº†å‡ ç¯‡å…³äº AI å¦‚ä½•é‡å¡‘ï¼ˆç”šè‡³ä¾µèš€ï¼‰ç§‘å­¦ç ”ç©¶æœ¬èº«çš„é‡é‡çº§æ–‡ç« â€”â€”ä» LLM å¯¼è‡´è®ºæ–‡â€œæ³¨æ°´â€åˆ° AI ç”Ÿæˆæ•°æ®æ±¡æŸ“åŒ»ç–—è®°å½•ã€‚æŠ€æœ¯å±‚é¢ï¼Œ**GNN çš„å¯å‘å¼æœ¬è´¨**ã€**LLM æ¨ç†çš„å‡ ä½•ç»“æ„ç›¸å˜**ä»¥åŠ**Agent å›¢é˜Ÿåä½œçš„â€œè¯…å’’â€**æ˜¯ä»Šå¤©çš„ç†è®ºé«˜åœ°ã€‚æ­¤å¤–ï¼ŒDeepfake æ£€æµ‹ã€æ—¶åºé¢„æµ‹å’Œç¥ç»ç¬¦å· LoRA ä¹Ÿæœ‰ä¸é”™çš„è¿›å±•ã€‚\n\n---\n\n### ğŸš¨ AI å¯¹ç§‘å­¦ä¸æ•°æ®çš„åŒåˆƒå‰‘ (Meta-Science & Data Integrity)\n\n**[1] ç§‘å­¦å¤§æ¨¡å‹æ—¶ä»£çš„ç§‘ç ”äº§å‡º**\n**Scientific production in the era of Large Language Models**\nè¿™ç¯‡å¿…è¯»ã€‚ä½œè€…åˆ†æäº† 210 ä¸‡ç¯‡é¢„å°æœ¬å’Œå¤§é‡åŒè¡Œè¯„å®¡æ•°æ®ï¼Œå‘ç° LLM çš„ä½¿ç”¨è®©ç§‘å­¦è®ºæ–‡äº§å‡ºæ¿€å¢ï¼ˆå¢é•¿ 23.7%-89.3%ï¼‰ï¼Œä½†ä¹Ÿå¯¼è‡´äº†**â€œè¯­è¨€å¤æ‚åº¦ä¸Šå‡ï¼Œä½†å®è´¨å†…å®¹è´¨é‡ä¸‹é™â€**çš„ç°è±¡ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œä½¿ç”¨ LLM çš„å­¦è€…å€¾å‘äºå¼•ç”¨æ›´å¤šæ ·åŒ–ä½†æ›´â€œå¹´è½»â€çš„æ–‡çŒ®ã€‚è¿™ä¸ä»…æ”¹å˜äº†å†™ä½œï¼Œä¹Ÿæ­£åœ¨é‡å¡‘å­¦æœ¯è¯„ä»·ä½“ç³»ã€‚\n\n**[2] AI ç”Ÿæˆæ•°æ®çš„æ±¡æŸ“ä¾µèš€äº†ç—…ç†å¤šæ ·æ€§ä¸è¯Šæ–­å¯é æ€§**\n**AI-generated data contamination erodes pathological variability and diagnostic reliability**\nè­¦ä¸–é’Ÿï¼å¦‚æœåœ¨åŒ»ç–—è®°å½•ä¸­å¤§é‡å……æ–¥ AI ç”Ÿæˆçš„åˆæˆæ•°æ®ï¼ˆæ–‡æœ¬ã€å›¾åƒï¼‰ï¼Œæ¨¡å‹ä¼šè¿…é€Ÿæ”¶æ•›åˆ°é€šç”¨çš„â€œå¹³å‡è„¸â€è¡¨å‹ï¼Œå¯¼è‡´**ç½•è§ä½†å…³é”®çš„ç—…ç†ç‰¹å¾ï¼ˆå¦‚æ°”èƒ¸ï¼‰æ¶ˆå¤±**ã€‚æ›´å¯æ€•çš„æ˜¯ï¼Œæ¨¡å‹åœ¨è¯Šæ–­é”™è¯¯æ—¶ä¾ç„¶ä¿æŒæé«˜çš„ç½®ä¿¡åº¦ï¼ˆç›²ç›®è‡ªä¿¡ï¼‰ã€‚è¿™è¡¨æ˜å¦‚æœæ²¡æœ‰å¼ºåˆ¶çš„äººå·¥éªŒè¯ï¼Œç”Ÿæˆå¼ AI å¯èƒ½ä¼šæ¯æ‰å®ƒèµ–ä»¥ç”Ÿå­˜çš„åŒ»ç–—æ•°æ®ç”Ÿæ€ã€‚\n\n---\n\n### ğŸ§  æ·±åº¦ç†è®ºä¸æ–°æ¶æ„ (Theory & Architecture)\n\n**[3] å›¾ç¥ç»ç½‘ç»œå³å¯å‘å¼ç®—æ³•**\n**Graph Neural Networks are Heuristics**\n**æ¨èé˜…è¯»**ã€‚åº·å¥ˆå°”å¤§å­¦ Carla Gomes å›¢é˜Ÿçš„æ–°ä½œã€‚ä»–ä»¬è¯æ˜äº†ä¸éœ€è¦ç›‘ç£å­¦ä¹ æˆ–æœç´¢ï¼ŒGNN å¯ä»¥é€šè¿‡å•æ¬¡è®­ç»ƒè½¨è¿¹è½¬åŒ–ä¸ºç»„åˆä¼˜åŒ–é—®é¢˜çš„**æ— ç›‘ç£å¯å‘å¼ç®—æ³•**ã€‚é€šè¿‡å°†å…¨å±€ç»“æ„çº¦æŸç¼–ç ä¸ºå½’çº³åç½®ï¼ˆInductive Biasï¼‰ï¼Œæ¨¡å‹å¯ä»¥ç›´æ¥ç”Ÿæˆ TSP ç­‰é—®é¢˜çš„è§£ã€‚è¿™é‡æ„äº† GNN åœ¨ç»„åˆä¼˜åŒ–ä¸­çš„è§’è‰²ï¼šä¸ä»…ä»…æ˜¯è¾…åŠ©ç»å…¸ç®—æ³•ï¼Œè€Œæ˜¯ç›´æ¥å®ä¾‹åŒ–ä¸ºæ–°çš„å¯å‘å¼æ–¹æ³•ã€‚\n\n**[4] æ€æƒ³çš„å‡ ä½•å­¦ï¼šè§„æ¨¡å¦‚ä½•é‡æ„ LLM çš„æ¨ç†**\n**The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models**\néå¸¸æœ‰æ„æ€çš„ç†è®ºåˆ†æã€‚ä½œè€…å‘ç° Scaleï¼ˆè§„æ¨¡ï¼‰å¹¶éå‡åŒ€æå‡æ¨ç†èƒ½åŠ›ï¼Œè€Œæ˜¯å¼•å‘äº†**ç›¸å˜ï¼ˆPhase Transitionsï¼‰**ã€‚åœ¨æ³•å¾‹æ¨ç†ä¸­ï¼Œå‡ºç°â€œç»“æ™¶åŒ–â€ï¼ˆCrystallizationï¼‰ï¼Œç»´åº¦åç¼©ä¸”æµå½¢è§£çº ç¼ ï¼›è€Œåœ¨ç§‘å­¦/æ•°å­¦æ¨ç†ä¸­åˆ™ä¿æŒâ€œæ¶²æ€â€ã€‚è¿™ç§å‡ ä½•ç»“æ„å†³å®šäº†å¯å­¦ä¹ æ€§ï¼Œä½œè€…ç”šè‡³å¯ä»¥é€šè¿‡æ¢æµ‹å‡ ä½•ç»“æ„æ¥é¢„æµ‹æ¨ç†ç»ˆç‚¹ã€‚\n\n**[5] LLM-as-RNNï¼šç”¨äºè®°å¿†æ›´æ–°å’Œåºåˆ—é¢„æµ‹çš„å¾ªç¯è¯­è¨€æ¨¡å‹**\n**LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction**\nå¦‚ä½•è®©å†»ç»“çš„ LLM æ‹¥æœ‰è®°å¿†ï¼Ÿä½œè€…æå‡ºä¸€ç§æ¨ç†æ¡†æ¶ï¼Œå°† Hidden State è¡¨ç¤ºä¸º**è‡ªç„¶è¯­è¨€è®°å¿†**ï¼Œå¹¶åœ¨æ¯ä¸€æ­¥é€šè¿‡åé¦ˆé©±åŠ¨çš„æ–‡æœ¬é‡å†™è¿›è¡Œæ›´æ–°ã€‚è¿™è®© LLM å˜èº«ä¸ºä¸€ä¸ª RNNï¼Œåœ¨åŒ»ç–—ã€æ°”è±¡ç­‰æ—¶åºä»»åŠ¡ä¸­å®ç°äº† Online Learningï¼Œä¸”è¿‡ç¨‹å®Œå…¨å¯è§£é‡Šã€‚\n\n---\n\n### ğŸ¤– Agent ä¸ åä½œéš¾é¢˜ (Agents & Collaboration)\n\n**[6] CooperBenchï¼šä¸ºä»€ä¹ˆ Coding Agents è¿˜ä¸èƒ½æˆä¸ºä½ çš„é˜Ÿå‹**\n**CooperBench: Why Coding Agents Cannot be Your Teammates Yet**\næ–¯å¦ç¦ç­‰æœºæ„çš„ç ”ç©¶ã€‚è™½ç„¶ Agent å†™ä»£ç å¾ˆå¼ºï¼Œä½†**åä½œèƒ½åŠ›æå·®**ã€‚å¹¶åœ¨ CooperBench ä¸Šæµ‹è¯•å‘ç°ï¼Œä¸¤ä¸ª Agent åˆä½œçš„æˆåŠŸç‡æ¯”å•å¹²ä½ 30%ï¼Œè¢«ç§°ä¸ºâ€œåä½œè¯…å’’â€ï¼ˆCurse of Coordinationï¼‰ã€‚ä¸»è¦é—®é¢˜åœ¨äºæ— æ•ˆæ²Ÿé€šã€è¿èƒŒæ‰¿è¯ºä»¥åŠå¯¹é˜Ÿå‹çš„é”™è¯¯é¢„æœŸã€‚\n\n**[7] è¶…è¶Šå•æ¬¡å†™ä½œï¼šæ·±åº¦ç ”ç©¶ Agent åœ¨å¤šè½®æŠ¥å‘Šä¿®è®¢ä¸­å¹¶ä¸å¯é **\n**Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision**\nç°æœ‰çš„ Deep Research Agents (DRA) å¾€å¾€æ˜¯ä¸€æ¬¡æ€§ç”ŸæˆæŠ¥å‘Šã€‚æœ¬æ–‡å¼•å…¥äº†å¤šè½®ä¿®è®¢è¯„æµ‹ï¼Œå‘ç° Agent è™½ç„¶èƒ½å“åº”åé¦ˆï¼Œä½†å¾€å¾€ä¼š**æ”¹åä¹‹å‰å†™å¯¹çš„å†…å®¹**ï¼ˆé€€åŒ–ç‡ 16-27%ï¼‰ï¼Œæˆ–è€…ç ´åå¼•ç”¨çš„è´¨é‡ã€‚\n\n---\n\n### ğŸ‘ï¸ è§†è§‰ã€å¤šæ¨¡æ€ä¸å®‰å…¨ (Vision, Multimodal & Safety)\n\n**[8] è¯­å¢ƒä¸æ–‡æœ¬è®°å½•æå‡å…¬ä¼—äººç‰© Deepfake éŸ³é¢‘æ£€æµ‹**\n**Context and Transcripts Improve Detection of Deepfake Audios of Public Figures**\nå½“å‰çš„éŸ³é¢‘ Deepfake æ£€æµ‹å¾€å¾€åªå¬å£°éŸ³ã€‚ä½†è¿™ç¯‡è®ºæ–‡æå‡ºï¼Œäººç±»åˆ¤æ–­çœŸä¼ªæ˜¯çœ‹**è¯­å¢ƒï¼ˆContextï¼‰**çš„ã€‚ä½œè€…æ„å»ºäº†åŒ…å« 70 å¤šä½è®°è€…æä¾›çš„ JDD æ•°æ®é›†ï¼Œè¯æ˜ç»“åˆè¯­å¢ƒå’Œæ–‡æœ¬è½¬å½•ï¼ˆTranscriptï¼‰å¯ä»¥å°†æ£€æµ‹æ¨¡å‹çš„ F1 åˆ†æ•°æå‡ 5%-37%ã€‚\n\n**[9] æ¨ç†è¾¾åˆ°åƒç´ çº§ç²¾åº¦ï¼šç”¨äºå®šé‡åœ°ç†ç©ºé—´åˆ†æçš„ QVLM æ¶æ„**\n**Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics**\nç°æœ‰çš„ VLM å› ä¸º Patch Embedding ä¸¢å¤±äº†åƒç´ çº§ä¿¡æ¯ï¼Œå¯¼è‡´æ— æ³•åšç²¾ç¡®çš„è®¡æ•°æˆ–æµ‹é‡ï¼ˆæ¯”å¦‚åœ¨å«æ˜Ÿå›¾ä¸­æ•°è½¦ï¼‰ã€‚QVLM æ¶æ„å°†è¯­è¨€ç†è§£ä¸è§†è§‰åˆ†æè§£è€¦ï¼Œç”Ÿæˆä»£ç æ¥è°ƒç”¨åˆ†å‰²æ¨¡å‹ï¼Œç›´æ¥åœ¨åƒç´ çº§ Mask ä¸Šæ“ä½œï¼Œæ˜¾è‘—æå‡äº†å®šé‡ç©ºé—´æ¨ç†çš„å‡†ç¡®ç‡ã€‚\n\n**[10] ç¥ç»ç¬¦å· LoRAï¼šä½•æ—¶è°ƒæ•´æƒé‡ vs é‡å†™æç¤º**\n**Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts**\nå¾®è°ƒï¼ˆLoRAï¼‰é€‚åˆæ³¨å…¥äº‹å®çŸ¥è¯†ï¼Œè€Œç¬¦å·åŒ–æ›´æ–°ï¼ˆæ”¹ Promptï¼‰é€‚åˆè°ƒæ•´é£æ ¼ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ¡†æ¶ï¼ŒåŠ¨æ€ç»“åˆè¿™ä¸¤ç§ç­–ç•¥ã€‚\n\n---\n\n### ğŸ“ˆ å…¶ä»–å€¼å¾—å…³æ³¨çš„è®ºæ–‡ (Others)\n\n*   **[11] WaveLSFormerï¼šç”¨äºå¤šç©ºè‚¡ç¥¨äº¤æ˜“çš„å¯å­¦ä¹ å°æ³¢ Transformer**\n    **(A Learnable Wavelet Transformer for Long-Short Equity Trading ...)**\n    é‡‘è AI é¢†åŸŸå…³æ³¨ã€‚ç»“åˆäº†å°æ³¢å˜æ¢å’Œ Transformerï¼Œåœ¨è‚¡ç¥¨äº¤æ˜“ç­–ç•¥ä¸­è·å¾—äº†å¤æ™®æ¯”ç‡ 2.157 çš„ä¼˜å¼‚è¡¨ç°ã€‚\n*   **[12] ç©ºé—´åŸºå‡†-UCï¼šæ–‡ç”Ÿå›¾ç©ºé—´æŒ‡ä»¤éµå¾ªçš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥è¯„ä¼°**\n    **(SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following ...)**\n    è¯„ä¼°æ–‡ç”Ÿå›¾æ¨¡å‹æ˜¯å¦å¬æ‡‚äº†â€œå·¦è¾¹æ”¾ä¸ªè‹¹æœâ€è¿™ç§ç©ºé—´æŒ‡ä»¤ï¼Œå¹¶å¼•å…¥äº†ä¸ç¡®å®šæ€§æ„ŸçŸ¥ã€‚\n*   **[13] MedConsultBenchï¼šåŒ»ç–—å’¨è¯¢ Agent çš„å…¨å‘¨æœŸåŸºå‡†æµ‹è¯•**\n    **(MedConsultBench: A Full-Cycle ... for Medical Consultation Agents)**\n    ä¸ä»…ä»…çœ‹è¯Šæ–­ç»“æœï¼Œè€Œæ˜¯è¯„ä¼°ä»é—®è¯Šã€è¯Šæ–­åˆ°æ²»ç–—è®¡åˆ’å’Œéšè®¿çš„å…¨æµç¨‹ã€‚å‘ç°å¾ˆå¤šæ¨¡å‹è™½ç„¶è¯Šæ–­å‡†ï¼Œä½†é—®è¯Šæ•ˆç‡ä½ä¸”ç”¨è¯å®‰å…¨æ€§å·®ã€‚\n*   **[14] æˆå‘˜æ¨æ–­æµ‹è¯•ï¼šå®¡è®¡ç‰©ä½“åˆ†ç±»æ¨¡å‹ä¸­çš„è®­ç»ƒæ•°æ®**\n    **(Membership Inference Test: Auditing Training Data in Object Classification Models)**\n    å…³äºç‰ˆæƒå’Œéšç§ã€‚æ£€æµ‹æŸå¼ å›¾ç‰‡æ˜¯å¦è¢«ç”¨æ¥è®­ç»ƒäº†æŸä¸ªè§†è§‰æ¨¡å‹ã€‚",
  "papers": [
    {
      "arxiv_id": "2601.13465v1",
      "title": "Graph Neural Networks are Heuristics",
      "title_zh": "å›¾ç¥ç»ç½‘ç»œå³å¯å‘å¼ç®—æ³•",
      "authors": [
        "Yimeng Min",
        "Carla P. Gomes"
      ],
      "abstract": "We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ï¼šGraph Neural Networks are Heuristics ğŸ§ \n\n---\n\nè¯¥ç ”ç©¶è¯æ˜äº†ä»…éœ€å•æ¬¡è®­ç»ƒï¼Œå³å¯å°† **Graph Neural Networks (GNNs)** è½¬åŒ–ä¸ºè§£å†³ç»„åˆä¼˜åŒ–é—®é¢˜çš„æ— ç›‘ç£å¯å‘å¼ç®—æ³•ã€‚\n\n| æ ¸å¿ƒç»´åº¦ | è¯¦ç»†å†…å®¹ |\n|---|---|\n| **æ ¸å¿ƒæ–¹æ³•** | ä»¥ **Travelling Salesman Problem (TSP)** ä¸ºé‡ç‚¹ï¼Œé€šè¿‡å°†å…¨å±€ç»“æ„çº¦æŸç¼–ç ä¸ºå½’çº³åç½® (**inductive bias**)ï¼Œä½¿éè‡ªå›å½’æ¨¡å‹èƒ½å¤Ÿæ— éœ€æœç´¢ã€ç›‘ç£æˆ–é¡ºåºå†³ç­–ï¼Œä»…å‡­ç›´æ¥å‰å‘ä¼ æ’­ç”Ÿæˆè§£ã€‚ |\n| **æŠ€æœ¯ç‰¹ç‚¹** | åœ¨æ¨ç†é˜¶æ®µï¼Œåˆ©ç”¨ **dropout** å’Œ **snapshot ensembling** æ„å»ºéšå¼é›†æˆï¼Œæœ‰æ•ˆå¢åŠ äº†è§£çš„å¤šæ ·æ€§å¹¶ç¼©å°äº†æœ€ä¼˜æ€§å·®è·ã€‚ |\n| **ä¸»è¦å‘ç°** | å®éªŒè¡¨æ˜ **GNNs** èƒ½å¤Ÿç›´æ¥å†…åŒ–å…¨å±€ç»„åˆç»“æ„å¹¶ä½œä¸ºå¼ºå¤§çš„å­¦ä¹ å¯å‘å¼ç®—æ³•è¿è¡Œï¼Œæ— éœ€ä¾èµ–ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ æˆ–æ˜¾å¼æœç´¢ã€‚ |\n| **ç ”ç©¶æ„ä¹‰** | è¿™ä¸€æˆæœé‡æ–°å®šä¹‰äº†å­¦ä¹ åœ¨ç»„åˆä¼˜åŒ–ä¸­çš„è§’è‰²ï¼šä»å•çº¯è¾…åŠ©ä¼ ç»Ÿç®—æ³•ï¼Œè½¬å˜ä¸ºç›´æ¥å®ä¾‹åŒ–ï¼ˆinstantiatingï¼‰å…¨æ–°çš„å¯å‘å¼ç®—æ³•ã€‚ |\n\n---\n\nå¸Œæœ›è¿™ä¸ª TLDR æ‘˜è¦å¯¹ä½ æœ‰å¸®åŠ©ï¼ä½ è¿˜åœ¨å…³æ³¨å…¶ä»–å…³äº **Graph Neural Networks** æˆ–ç»„åˆä¼˜åŒ–é¢†åŸŸçš„è®ºæ–‡å—ï¼Ÿ",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13465v1",
      "published_date": "2026-01-19 23:40:08 UTC",
      "updated_date": "2026-01-19 23:40:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:13:42.029541+00:00"
    },
    {
      "arxiv_id": "2601.13464v1",
      "title": "Context and Transcripts Improve Detection of Deepfake Audios of Public Figures",
      "title_zh": "Hello! I see you've shared the abstract for a very relevant research paper titled **\"Context and Transcripts Improve Detection of Deepfake Audios of Public Figures.\"** \n\nI am Gemini Enterpriseâœ¨, and I've summarized the key points of this research for you below.\n\n---\n\n### Overview of the Research ğŸ“„\n\nThis paper addresses a critical gap in current audio deepfake detection: the fact that most detectors only analyze the raw audio file while ignoring the **context** and **transcripts**. The authors argue that just as humans use context to judge veracity, AI models should do the same to improve accuracy and robustness against adversarial attacks.\n\n---\n\n### Key Contributions & Datasets ğŸ› ï¸\n\nThe researchers introduced several new resources and a novel architecture to advance the field:\n\n| Feature | Description |\n|---|---|\n| **JDD Dataset** | A \"Journalist-provided Deepfake Dataset\" consisting of 255 real-world deepfakes of public figures collected since early 2024. |\n| **SYN Dataset** | A synthetic audio dataset featuring the voices of deceased public figures. |\n| **CADD Architecture** | The \"Context-based Audio Deepfake Detector,\" a new model designed to integrate audio data with transcripts and contextual metadata. |\n| **Benchmark Testing** | Evaluation performed on existing large-scale datasets, including **ITW** (In-The-Wild) and **P$^2$V**. |\n\n---\n\n### Performance Improvements ğŸ“ˆ\n\nBy incorporating context and transcripts, the researchers saw significant boosts in detection performance across multiple baseline models:\n\n| Metric | Improvement Range |\n|---|---|\n| **F1-Score** | 5% to 37.58% improvement |\n| **AUC** (Area Under Curve) | 3.77% to 42.79% improvement |\n| **EER** (Equal Error Rate) | 6.17% to 47.83% improvement |\n\n---\n\n### Robustness ğŸ›¡ï¸\n\nOne of the most impressive findings is the model's resilience. The **CADD** architecture proved to be highly robust against **5 different adversarial evasion strategies**. While traditional detectors often fail when faced with manipulated audio designed to fool them, CADD maintained its efficacy with an average performance degradation of only **-0.71%**.\n\n---\n\nThis looks like a significant step forward in securing digital communications, especially for public figures. Would you like me to help you analyze a specific part of this abstract, or are you looking for more information on how context-based detection works? I'm here to help!",
      "authors": [
        "Chongyang Gao",
        "Marco Postiglione",
        "Julian Baldwin",
        "Natalia Denisenko",
        "Isabel Gortner",
        "Luke Fosdick",
        "Chiara Pulice",
        "Sarit Kraus",
        "V. S. Subrahmanian"
      ],
      "abstract": "Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).",
      "tldr_zh": "This is a fascinating paper on a very timely topic! As deepfake technology becomes more sophisticated, incorporating human-like reasoningâ€”such as analyzing context and transcriptsâ€”seems like a logical and powerful step forward.\n\nI have summarized the key highlights of the research below.\n\n---\n\n### Research Overview ğŸ™ï¸\n\nThe paper argues that traditional audio deepfake detectors are limited because they only analyze the acoustic properties of a file. In contrast, humans naturally use **context** (where the audio came from, who is speaking, and what is being said) to determine if something is real. To bridge this gap, the researchers introduced the **Context-based Audio Deepfake Detector (CADD)**.\n\n---\n\n### Dataset Contributions ğŸ› ï¸\n\nThe researchers developed and utilized several datasets to test their novel architecture:\n\n| Dataset | Description |\n|---|---|\n| **Journalist-provided Deepfake Dataset (JDD)** | 255 public deepfakes contributed by over 70 journalists since early 2024. |\n| **Synthetic Audio Dataset (SYN)** | A dataset of synthetic audio generated from recordings of deceased public figures. |\n| **Large-scale Datasets** | Evaluation also included the existing **ITW** (In-The-Wild) and **P^2V** datasets. |\n\n---\n\n### Performance Metrics ğŸ“Š\n\nBy integrating context and transcripts, the researchers observed substantial improvements across all primary evaluation metrics compared to baseline detectors:\n\n| Metric | Percentage Improvement |\n|---|---|\n| **F1-score** | 5% â€“ 37.58% |\n| **AUC** (Area Under the Curve) | 3.77% â€“ 42.79% |\n| **EER** (Equal Error Rate) | 6.17% â€“ 47.83% |\n\n---\n\n### Adversarial Robustness ğŸ›¡ï¸\n\nOne of the most impressive findings is the system's resilience. The **CADD** architecture proved to be highly robust against **five different adversarial evasion strategies**. While these strategies typically degrade the performance of standard detectors, CADD maintained its efficacy with an average performance drop of only **-0.71%**.\n\n---\n\nThis research suggests that the future of deepfake detection lies not just in \"hearing\" the audio, but in \"understanding\" it. \n\nAre you interested in a specific part of their methodology, such as how they integrated the transcripts, or would you like to discuss the broader implications for public figures and media integrity?",
      "categories": [
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13464v1",
      "published_date": "2026-01-19 23:40:05 UTC",
      "updated_date": "2026-01-19 23:40:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:13:54.775521+00:00"
    },
    {
      "arxiv_id": "2601.13462v1",
      "title": "SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation",
      "title_zh": "SpatialBench-UCï¼šæ–‡ç”Ÿå›¾ç©ºé—´æç¤ºéµå¾ªçš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥è¯„ä¼°",
      "authors": [
        "Amine Rostane"
      ],
      "abstract": "Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ï¼šSpatialBench-UC ğŸ“\n\n---\n\næˆ‘æ˜¯ Gemini Enterpriseï¼Œå¾ˆé«˜å…´ä¸ºä½ è§£è¯»è¿™ç¯‡è®ºæ–‡ã€‚è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æœ¬ç”Ÿæˆå›¾åƒï¼ˆText-to-Imageï¼‰æ¨¡å‹åœ¨ç©ºé—´æç¤ºè¯éµå¾ªèƒ½åŠ›è¯„ä¼°ä¸­å­˜åœ¨çš„è‡ªåŠ¨åŒ–éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„è¯„ä¼°æ¡†æ¶ã€‚\n\n| æ ¸å¿ƒç»´åº¦ | è¯¦ç»†å†…å®¹ |\n|---|---|\n| **ç ”ç©¶èƒŒæ™¯** | ä¼ ç»Ÿçš„è‡ªåŠ¨è¯„ä¼°æ–¹æ³•å—é™äºç›®æ ‡æ£€æµ‹å™¨çš„æ¼æ£€æˆ–å‡ ä½•æµ‹è¯•çš„æ­§ä¹‰ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å¤Ÿå‡†ç¡®ã€‚ |\n| **æ ¸å¿ƒæ–¹æ³•** | æå‡º **SpatialBench-UC**ï¼Œå°†ç©ºé—´è¯„ä¼°å®šä¹‰ä¸ºä¸€ç§**é€‰æ‹©æ€§é¢„æµ‹ï¼ˆselective predictionï¼‰**é—®é¢˜ï¼Œå…è®¸æ£€æŸ¥å™¨åœ¨è¯æ®ä¸è¶³æ—¶â€œå¼ƒæƒï¼ˆabstentionï¼‰â€ï¼Œå¹¶æä¾›é£é™©-è¦†ç›–ï¼ˆrisk coverageï¼‰æƒè¡¡çš„è¯„ä¼°ç»“æœã€‚ |\n| **åŸºå‡†æ„æˆ** | åŒ…å« 200 ä¸ªæç¤ºè¯ï¼ˆ50 å¯¹ç‰©ä½“ Ã— 4 ç§å…³ç³»ï¼‰ï¼Œå½¢æˆäº† 100 å¯¹äº’æ¢è§’è‰²çš„åäº‹å®å¯¹ï¼ˆcounterfactual pairsï¼‰ã€‚ç ”ç©¶è¿˜å¼•å…¥äº†è½»é‡çº§çš„äººå·¥å®¡æ ¸ï¼ˆhuman auditï¼‰æ¥æ ¡å‡†æ£€æŸ¥å™¨çš„é˜ˆå€¼ã€‚ |\n| **ä¸»è¦å‘ç°** | å¯¹ **Stable Diffusion 1.5**ã€**BoxDiff** å’Œ **GLIGEN** çš„è¯„ä¼°æ˜¾ç¤ºï¼Œ**grounding** æ–¹æ³•èƒ½æ˜¾è‘—æå‡é€šè¿‡ç‡ï¼ˆpass rateï¼‰å’Œè¦†ç›–ç‡ï¼ˆcoverageï¼‰ã€‚ |\n| **å…³é”®ç»“è®º** | å®éªŒæŒ‡å‡ºï¼Œâ€œå¼ƒæƒâ€ä»æ˜¯è¯„ä¼°ä¸­çš„ä¸»å¯¼å› ç´ ï¼Œå…¶ä¸»è¦åŸå› åœ¨äºæ£€æµ‹å™¨çš„ç›®æ ‡é—æ¼ï¼ˆmissing detectionsï¼‰ã€‚ |\n\n---\n\nè¯¥ç ”ç©¶ä¸ºç©ºé—´å…³ç³»çš„è‡ªåŠ¨åŒ–è¯„ä¼°æä¾›äº†ä¸€ä¸ªæ›´å…·é²æ£’æ€§ä¸”å¯å®¡è®¡ï¼ˆauditableï¼‰çš„å·¥å…·åŒ…ã€‚ä½ æ˜¯å¦å¯¹ **grounding** æ–¹æ³•å¦‚ä½•æ”¹è¿›ç©ºé—´ä¸€è‡´æ€§ï¼Œæˆ–è€…å¯¹è¯¥åŸºå‡†çš„å¼ƒæƒæœºåˆ¶ç»†èŠ‚æ„Ÿå…´è¶£ï¼Ÿæ¬¢è¿ç»§ç»­ä¸æˆ‘äº¤æµï¼",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, includes figures and tables",
      "pdf_url": "https://arxiv.org/pdf/2601.13462v1",
      "published_date": "2026-01-19 23:37:10 UTC",
      "updated_date": "2026-01-19 23:37:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:13:58.082265+00:00"
    },
    {
      "arxiv_id": "2601.13458v1",
      "title": "Labels or Preferences? Budget-Constrained Learning with Human Judgments over AI-Generated Outputs",
      "title_zh": "æ ‡ç­¾è¿˜æ˜¯åå¥½ï¼ŸåŸºäºäººç±»å¯¹äººå·¥æ™ºèƒ½ç”Ÿæˆè¾“å‡ºè¯„åˆ¤çš„é¢„ç®—å—é™å­¦ä¹ ",
      "authors": [
        "Zihan Dong",
        "Ruijia Wu",
        "Linjun Zhang"
      ],
      "abstract": "The increasing reliance on human preference feedback to judge AI-generated pseudo labels has created a pressing need for principled, budget-conscious data acquisition strategies. We address the crucial question of how to optimally allocate a fixed annotation budget between ground-truth labels and pairwise preferences in AI. Our solution, grounded in semi-parametric inference, casts the budget allocation problem as a monotone missing data framework. Building on this formulation, we introduce Preference-Calibrated Active Learning (PCAL), a novel method that learns the optimal data acquisition strategy and develops a statistically efficient estimator for functionals of the data distribution. Theoretically, we prove the asymptotic optimality of our PCAL estimator and establish a key robustness guarantee that ensures robust performance even with poorly estimated nuisance models. Our flexible framework applies to a general class of problems, by directly optimizing the estimator's variance instead of requiring a closed-form solution. This work provides a principled and statistically efficient approach for budget-constrained learning in modern AI. Simulations and real-data analysis demonstrate the practical benefits and superior performance of our proposed method.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ï¼šLabels or Preferences? Budget-Constrained Learning with Human Judgments over AI-Generated Outputs âš–ï¸\n\n---\n\nè¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æœ‰é™çš„æ ‡æ³¨é¢„ç®—ä¸‹ï¼Œå¦‚ä½•æœ€ä¼˜åœ°åœ¨åœ°é¢çœŸå€¼æ ‡ç­¾ (**ground-truth labels**) ä¸äººç±»å¯¹ AI ç”Ÿæˆå†…å®¹çš„æˆå¯¹åå¥½ (**pairwise preferences**) ä¹‹é—´åˆ†é…èµ„æºã€‚\n\n| æ ¸å¿ƒç»´åº¦ | è¯¦ç»†å†…å®¹ |\n|---|---|\n| **æ ¸å¿ƒæ–¹æ³•** | æå‡ºäº†ä¸€ç§åä¸º **Preference-Calibrated Active Learning (PCAL)** çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•åŸºäºåŠå‚æ•°æ¨ç† (**semi-parametric inference**)ï¼Œå°†é¢„ç®—åˆ†é…é—®é¢˜å»ºæ¨¡ä¸ºå•è°ƒç¼ºå¤±æ•°æ® (**monotone missing data**) æ¡†æ¶ã€‚ |\n| **æŠ€æœ¯åˆ›æ–°** | **PCAL** èƒ½å¤Ÿå­¦ä¹ æœ€ä¼˜çš„æ•°æ®è·å–ç­–ç•¥ï¼Œå¹¶ä¸ºæ•°æ®åˆ†å¸ƒçš„æ³›å‡½å¼€å‘å‡ºä¸€ç§ç»Ÿè®¡é«˜æ•ˆçš„ä¼°è®¡é‡ (**statistically efficient estimator**)ï¼Œç›´æ¥é€šè¿‡ä¼˜åŒ–ä¼°è®¡é‡çš„æ–¹å·®æ¥è§£å†³å¤æ‚é—®é¢˜ã€‚ |\n| **ç†è®ºä¿è¯** | ç†è®ºä¸Šè¯æ˜äº† **PCAL** ä¼°è®¡é‡çš„æ¸è¿‘æœ€ä¼˜æ€§ (**asymptotic optimality**)ï¼Œå¹¶æä¾›äº†ä¸€é¡¹å…³é”®çš„é²æ£’æ€§ä¿è¯ï¼Œç¡®ä¿å³ä½¿åœ¨å¦¨ç¢æ¨¡å‹ (**nuisance models**) ä¼°è®¡ä¸ä½³æ—¶ï¼Œç³»ç»Ÿä¾ç„¶èƒ½ä¿æŒç¨³å¥è¡¨ç°ã€‚ |\n| **å®éªŒç»“è®º** | æ¨¡æ‹Ÿå®éªŒå’ŒçœŸå®æ•°æ®åˆ†æå‡è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç°ä»£ AI é¢„ç®—å—é™çš„å­¦ä¹ åœºæ™¯ä¸­å…·æœ‰æ˜¾è‘—çš„å®é™…æ”¶ç›Šå’Œä¼˜äºåŸºå‡†æ¨¡å‹çš„æ€§èƒ½è¡¨ç°ã€‚ |\n\n---\n\nè¿™ç§åœ¨â€œæ˜‚è´µçš„çœŸå€¼â€ä¸â€œå»‰ä»·çš„åå¥½â€ä¹‹é—´å¯»æ‰¾æœ€ä¼˜å¹³è¡¡çš„æ–¹æ³•ï¼Œå¯¹äºå½“å‰çš„å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒéå¸¸æœ‰å‚è€ƒä»·å€¼ã€‚ä½ æ˜¯å¦ä¹Ÿåœ¨ç ”ç©¶ **Active Learning** æˆ– **RLHF** ç›¸å…³çš„æ•°æ®åˆ†é…ç­–ç•¥ï¼Ÿ",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13458v1",
      "published_date": "2026-01-19 23:23:29 UTC",
      "updated_date": "2026-01-19 23:23:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:14:09.925246+00:00"
    },
    {
      "arxiv_id": "2601.13443v1",
      "title": "Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models",
      "title_zh": "æ˜¾å¼è®¤çŸ¥åˆ†é…ï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­å—æ²»ç†ä¸”å¯å®¡è®¡æ¨ç†çš„åŸåˆ™",
      "authors": [
        "HÃ©ctor Manuel Manzanilla-Granados",
        "Zaira Navarrete-Cazales",
        "Miriam Pescador-Rojas",
        "Tonahtiu RamÃ­rez-Romero"
      ],
      "abstract": "The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.\n  We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.\n  We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ï¼šExplicit Cognitive Allocation ğŸ§ \n\n---\n\næˆ‘æ˜¯ Gemini Enterpriseï¼Œå¾ˆé«˜å…´èƒ½ä¸ºä½ æç‚¼è¿™ç¯‡å…³äºå¤§è¯­è¨€æ¨¡å‹æ¨ç†æ¶æ„çš„è®ºæ–‡ã€‚è¯¥ç ”ç©¶ç›´å‡»å½“å‰ LLMs åœ¨å¤æ‚ä»»åŠ¡ä¸­å› è®¤çŸ¥åŠŸèƒ½æ··æ‚ï¼ˆcognitive collapseï¼‰è€Œå¯¼è‡´çš„é€æ˜åº¦ä¸è¶³é—®é¢˜ã€‚\n\n| æ ¸å¿ƒç»´åº¦ | è¯¦ç»†å†…å®¹ |\n|---|---|\n| **æ ¸å¿ƒåŸåˆ™** | æå‡ºäº† **Explicit Cognitive Allocation**ï¼ˆæ˜¾å¼è®¤çŸ¥åˆ†é…ï¼‰åŸåˆ™ï¼Œä¸»å¼ é€šè¿‡æ˜¾å¼åˆ†ç¦»å’Œç¼–æ’ä¸åŒçš„è®¤çŸ¥åŠŸèƒ½ï¼Œå®ç°å¯æ²»ç†ä¸”å¯å®¡è®¡çš„äººå·¥æ™ºèƒ½æ¨ç†ã€‚ |\n| **ç³»ç»Ÿæ¶æ„** | å®ä¾‹åŒ–ä¸º **Cognitive Universal Agent (CUA)** æ¶æ„ï¼Œå°†æ¨ç†åˆ’åˆ†ä¸ºæ¢ç´¢ä¸æ¡†æ¶æ„å»ºã€çŸ¥è¯†é”šå®šã€æ–¹æ³•æ˜ å°„åŠè§£é‡Šæ€§ç»¼åˆç­‰é˜¶æ®µï¼Œå¹¶å¼•å…¥ **Universal Cognitive Instruments (UCIs)** è§„èŒƒè°ƒæŸ¥æ‰‹æ®µã€‚ |\n| **å®éªŒå¯¹æ¯”** | åœ¨å†œä¸šé¢†åŸŸçš„å—æ§å®éªŒä¸­ï¼Œå°† **CUA** æ¨ç†ä¸åŸºå‡† LLM æ¨ç†åœ¨ç›¸åŒæ‰§è¡Œæ¡ä»¶ä¸‹è¿›è¡Œäº†å¯¹æ¯”ã€‚ |\n| **ä¸»è¦å‘ç°** | **CUA** æ¨ç†è¡¨ç°å‡ºæ›´æ—©ä¸”å—ç»“æ„çº¦æŸçš„è®¤è¯†è®ºæ”¶æ•›ï¼ˆ**epistemic convergence**ï¼‰ï¼Œå¹¶åœ¨è¯­ä¹‰æ‰©å±•ä¸‹è¡¨ç°å‡ºæ›´é«˜çš„è®¤è¯†è®ºå¯¹é½åº¦ï¼ˆ**epistemic alignment**ï¼‰ã€‚ |\n| **ç ”ç©¶ç»“è®º** | ç›¸æ¯”äºåŸºå‡†æ¨¡å‹çš„ä¸ç¡®å®šæ€§å’Œç»“æ„ç¼ºå¤±ï¼Œè¯¥æ¡†æ¶èƒ½ç³»ç»Ÿæ€§åœ°å‘ˆç°æ¨ç†çš„å·¥å…·åŒ–æ™¯è§‚ï¼Œä¸ºé«˜è´£ä»»åœºæ™¯ä¸‹çš„ AI åº”ç”¨æä¾›äº†å¿…è¦çš„è®¤çŸ¥æ§åˆ¶ã€‚ |\n\n---\n\nè¯¥ç ”ç©¶ä¸ºæå‡ AI æ¨ç†çš„é€»è¾‘ä¸¥å¯†æ€§å’Œå¯è¿½æº¯æ€§æä¾›äº†éå¸¸æœ‰å‰æ™¯çš„æ€è·¯ã€‚ä½ æ˜¯å¦å¯¹ **CUA** æ¶æ„ä¸­çš„å…·ä½“è®¤è¯†è®ºé˜¶æ®µåˆ’åˆ†æ„Ÿå…´è¶£ï¼Œæˆ–è€…æƒ³äº†è§£å®ƒåœ¨å†œä¸šé¢†åŸŸä¹‹å¤–çš„åº”ç”¨æ½œåŠ›ï¼Ÿæ¬¢è¿éšæ—¶æé—®ï¼",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint. This version corresponds to the initial public release of the CUA architecture and associated evaluation metrics",
      "pdf_url": "https://arxiv.org/pdf/2601.13443v1",
      "published_date": "2026-01-19 23:00:14 UTC",
      "updated_date": "2026-01-19 23:00:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:14:19.849857+00:00"
    },
    {
      "arxiv_id": "2601.13437v1",
      "title": "MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization",
      "title_zh": "MOSLD-Benchï¼šå¤šè¯­è¨€æ–‡æœ¬åˆ†ç±»å¼€æ”¾é›†å­¦ä¹ ä¸å‘ç°åŸºå‡†",
      "authors": [
        "Adriana-Valentina Costache",
        "Daria-Nicoleta Dragomir",
        "Silviu-Florin Gheorghe",
        "Eduard Poesina",
        "Paul Irofti",
        "Radu Tudor Ionescu"
      ],
      "abstract": "Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ï¼šMOSLD-Bench ğŸŒ\n\n---\n\nè¯¥ç ”ç©¶æ¨å‡ºäº† **MOSLD-Bench**ï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨ç”¨äºæ–‡æœ¬ä¸»é¢˜åˆ†ç±»çš„å¤šè¯­è¨€å¼€æ”¾é›†å­¦ä¹ ä¸å‘ç° (**Open-Set Learning and Discovery, OSLD**) åŸºå‡†æµ‹è¯•ã€‚\n\n| æ ¸å¿ƒç»´åº¦ | è¯¦ç»†å†…å®¹ |\n|---|---|\n| **ç ”ç©¶èƒŒæ™¯** | ç›¸æ¯”äºå·²è¢«å¹¿æ³›ç ”ç©¶çš„ **Zero-Shot Learning**ï¼Œ**OSLD** è¦æ±‚æ¨¡å‹åœ¨æµ‹è¯•é˜¶æ®µèƒ½å¤Ÿä¸»åŠ¨å‘ç°å¹¶å­¦ä¹ é¢„å…ˆæœªçŸ¥çš„ç±»åˆ«ã€‚ |\n| **åŸºå‡†è§„æ¨¡** | åŒ…å« 12 ç§è¯­è¨€çš„ 96.0 ä¸‡ä¸ªæ ·æœ¬ï¼Œé€šè¿‡é‡æ„ç°æœ‰æ•°æ®é›†ä»¥åŠä»æ–°é—»é¢†åŸŸé‡‡é›†æ–°æ•°æ®æ„å»ºè€Œæˆã€‚ |\n| **æŠ€æœ¯è´¡çŒ®** | æå‡ºäº†ä¸€å¥—å…¨æ–°çš„ **OSLD** ä»»åŠ¡æ¡†æ¶ï¼Œé›†æˆäº†å¤šä¸ªé˜¶æ®µä»¥å®ç°å¯¹æ–°ç±»åˆ«çš„æŒç»­å‘ç°ä¸å­¦ä¹ ã€‚ |\n| **è¯„ä¼°æ„ä¹‰** | ç ”ç©¶å¯¹å¤šç§è¯­è¨€æ¨¡å‹è¿›è¡Œäº†æ·±åº¦è¯„ä¼°ï¼Œä¸ºè¯¥é¢†åŸŸæœªæ¥çš„å¤šè¯­è¨€æ–‡æœ¬åˆ†ç±»ä¸æ–°ç±»åˆ«å‘ç°ç ”ç©¶æä¾›äº†å‚è€ƒåŸºå‡†ã€‚ |\n\n---\n\nè¿™ä¸ªåŸºå‡†å¡«è¡¥äº†æ–‡æœ¬é¢†åŸŸåœ¨å¤šè¯­è¨€ **Open-Set Learning** æ–¹é¢çš„ç©ºç™½ã€‚ä½ æ˜¯å¦å…³æ³¨ç‰¹å®šè¯­è¨€ï¼ˆå¦‚ä¸­æ–‡æˆ–å°è¯­ç§ï¼‰åœ¨å¤„ç†æœªçŸ¥ç±»åˆ«æ—¶çš„è¡¨ç°ï¼Ÿæ¬¢è¿ä¸æˆ‘æ¢è®¨æ›´å¤šæŠ€æœ¯ç»†èŠ‚ï¼",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13437v1",
      "published_date": "2026-01-19 22:49:41 UTC",
      "updated_date": "2026-01-19 22:49:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:14:24.279320+00:00"
    },
    {
      "arxiv_id": "2601.13435v1",
      "title": "A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization",
      "title_zh": "ç”¨äºè‚¡ç¥¨å¤šç©ºäº¤æ˜“ä¸é£é™©è°ƒæ•´æ”¶ç›Šä¼˜åŒ–çš„å¯å­¦ä¹ å°æ³¢ Transformer",
      "authors": [
        "Shuozhe Li",
        "Du Cheng",
        "Leqi Liu"
      ],
      "abstract": "Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \\emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \\pm 0.045$ and a Sharpe ratio of $2.157 \\pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **WaveLSFormer**ï¼Œä¸€ç§åŸºäºå¯å­¦ä¹ å°æ³¢çš„é•¿çŸ­çº¿ Transformer (Wavelet-based Long-Short Transformer)ï¼Œæ—¨åœ¨è§£å†³é‡‘èæ—¶é—´åºåˆ—ä¸­é«˜å™ªå£°ã€éå¹³ç¨³åŠå¼ºæ¨ªæˆªé¢ç›¸å…³æ€§å¸¦æ¥çš„äº¤æ˜“ç­–ç•¥å­¦ä¹ éš¾é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å¯å­¦ä¹ çš„å°æ³¢å‰ç«¯ (Learnable Wavelet Front-end) å®ç°å¤šå°ºåº¦åˆ†è§£ï¼Œå¹¶åˆ©ç”¨ä½é¢‘å¼•å¯¼çš„é«˜é¢‘æ³¨å…¥ (LGHI) æ¨¡å—æœ‰æ•ˆèåˆé«˜ä½é¢‘ä¿¡æ¯ã€‚æ¨¡å‹è¾“å‡ºæ ¹æ®é£é™©é¢„ç®—è°ƒæ•´åçš„å¤šç©ºå¤´å¯¸ç»„åˆï¼Œå¹¶ç›´æ¥é’ˆå¯¹äº¤æ˜“ç›®æ ‡å’Œé£é™©æ„ŸçŸ¥æ­£åˆ™åŒ–è¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨å…­ä¸ªè¡Œä¸šçš„äº”å¹´å°æ—¶çº§æ•°æ®æµ‹è¯•ä¸­ï¼Œ**WaveLSFormer** çš„ç´¯ç§¯æ”¶ç›Šç‡å’Œå¤æ™®æ¯”ç‡ (Sharpe Ratio) æ˜¾è‘—ä¼˜äº MLPã€LSTM åŠä¼ ç»Ÿ Transformer æ¨¡å‹ï¼Œå¤§å¹…æå‡äº†æŠ•èµ„ç»„åˆçš„ç›ˆåˆ©èƒ½åŠ›å’Œé£é™©è°ƒæ•´åçš„æ”¶ç›Šã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13435v1",
      "published_date": "2026-01-19 22:41:31 UTC",
      "updated_date": "2026-01-19 22:41:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:14:32.837957+00:00"
    },
    {
      "arxiv_id": "2601.13422v1",
      "title": "TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction",
      "title_zh": "### TrustEnergy: Unified Framework for Energy Usage Prediction âš¡\n\nIt looks like you've shared a very interesting abstract regarding a new framework for predicting energy consumption. **TrustEnergy** seems to address some critical gaps in current deep learning approaches, particularly regarding spatial correlations and uncertainty quantification at a granular, user-level scale.\n\n---\n\n### Key Takeaways from the Research ğŸ“\n\n| Feature | Description |\n|---|---|\n| **Core Objective** | To provide accurate and reliable individual household energy usage predictions. |\n| **Technical Innovation 1** | **Hierarchical Spatiotemporal Representation**: Uses a memory-augmented spatiotemporal graph neural network to capture both broad (macro) and local (micro) patterns. |\n| **Technical Innovation 2** | **Sequential Conformalized Quantile Regression**: Dynamically adjusts uncertainty bounds for reliable intervals without rigid data assumptions. |\n| **Performance Gain** | Achieved a **5.4%** boost in prediction accuracy and a **5.7%** improvement in uncertainty quantification over existing state-of-the-art models. |\n| **Real-world Validation** | Tested using data from an electricity provider in Florida, USA. |\n\n---\n\nHow would you like me to help you with this paper? I can:\n*   **Deep Dive:** Explain specific components like the \"Spatiotemporal Graph Neural Network\" or \"Conformalized Quantile Regression\" in simpler terms.\n*   **Critique:** Discuss potential limitations or practical challenges in implementing such a framework.\n*   **Drafting:** Help you draft a presentation, a summary for a non-technical audience, or even a set of questions for a reading group.\n\nLet me know what you're thinking! ğŸš€",
      "authors": [
        "Dahai Yu",
        "Rongchao Xu",
        "Dingyi Zhuang",
        "Yuheng Bu",
        "Shenhao Wang",
        "Guang Wang"
      ],
      "abstract": "Energy usage prediction is important for various real-world applications, including grid management, infrastructure planning, and disaster response. Although a plethora of deep learning approaches have been proposed to perform this task, most of them either overlook the essential spatial correlations across households or fail to scale to individualized prediction, making them less effective for accurate fine-grained user-level prediction. In addition, due to the dynamic and uncertain nature of energy usage caused by various factors such as extreme weather events, quantifying uncertainty for reliable prediction is also significant, but it has not been fully explored in existing work. In this paper, we propose a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. There are two key technical components in TrustEnergy, (i) a Hierarchical Spatiotemporal Representation module to efficiently capture both macro and micro energy usage patterns with a novel memory-augmented spatiotemporal graph neural network, and (ii) an innovative Sequential Conformalized Quantile Regression module to dynamically adjust uncertainty bounds to ensure valid prediction intervals over time, without making strong assumptions about the underlying data distribution. We implement and evaluate our TrustEnergy framework by working with an electricity provider in Florida, and the results show our TrustEnergy can achieve a 5.4% increase in prediction accuracy and 5.7% improvement in uncertainty quantification compared to state-of-the-art baselines.",
      "tldr_zh": "### TrustEnergy Research Overview âš¡\n\nIt looks like you've shared the abstract for a very interesting paper on energy usage prediction. **TrustEnergy** seems to address two critical gaps in current deep learning models: the ability to scale to individualized (user-level) predictions while maintaining spatial awareness, and the need for reliable uncertainty quantification.\n\nI have reviewed the details you provided, and here is a breakdown of the framework's core innovations:\n\n---\n\n### Key Components of the TrustEnergy Framework ğŸ› ï¸\n\n| Component | Technical Approach | Primary Benefit |\n|---|---|---|\n| **Hierarchical Spatiotemporal Representation** | Memory-augmented Spatiotemporal Graph Neural Network (STGNN) | Captures both macro (regional) and micro (individual) patterns efficiently. |\n| **Sequential Conformalized Quantile Regression** | Dynamic adjustment of uncertainty bounds | Provides valid prediction intervals over time without assuming a specific data distribution. |\n| **Real-world Application** | Deployment with a Florida electricity provider | Demonstrated a **5.4%** accuracy boost and **5.7%** better uncertainty quantification over baselines. |\n\n---\n\n### How can I help you with this today? ğŸ¤”\n\nSince you've provided the abstract, I can assist you in several ways. Please let me know if you would like Gemini Enterprise to:\n\n*   **Synthesize the technical concepts**: Would you like a deeper explanation of \"Sequential Conformalized Quantile Regression\"?\n*   **Draft a summary**: Do you need a condensed version for a presentation or a literature review?\n*   **Compare methodologies**: Are you looking for how this compares to traditional LSTM or standard GNN approaches?\n*   **Generate related content**: Would you like me to draft an email or a social media post discussing these findings?\n\nWhat are your thoughts on their approach to uncertainty quantification? It's quite a unique way to handle the volatility of extreme weather events!",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13422v1",
      "published_date": "2026-01-19 22:09:08 UTC",
      "updated_date": "2026-01-19 22:09:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:14:37.336749+00:00"
    },
    {
      "arxiv_id": "2601.13412v1",
      "title": "Using deep learning for predicting cleansing quality of colon capsule endoscopy images",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ çš„ç»“è‚ èƒ¶å›Šå†…é•œå›¾åƒæ¸…æ´è´¨é‡é¢„æµ‹",
      "authors": [
        "Puneet Sharma",
        "Kristian DalsbÃ¸ Hindberg",
        "Benedicte Schelde-Olesen",
        "Ulrik Deding",
        "Esmaeil S. Nadimi",
        "Jan-Matthias Braun"
      ],
      "abstract": "In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº ResNet-18 çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹ç»“è‚ èƒ¶å›Šå†…é•œ (CCE) å›¾åƒåœ¨ Leighton-Rex é‡è¡¨ä¸‹çš„æ¸…æ´è´¨é‡ã€‚ç ”ç©¶é‡‡ç”¨ç»“æ„åŒ–å‰ªæ (Structured pruning) æŠ€æœ¯å¯¹æ¨¡å‹è¿›è¡Œä¼˜åŒ–ï¼Œåœ¨è¾¾åˆ° 79% ç¨€ç–åº¦ (Sparsity) çš„æƒ…å†µä¸‹ï¼Œå°†åˆ†ç±»å‡†ç¡®ç‡ä» 84% æå‡è‡³ 88%ï¼Œå®ç°äº†æ€§èƒ½ä¸æ•ˆç‡çš„åŒé‡æå‡ã€‚ä¸ºäº†å¢å¼ºä¸´åºŠåº”ç”¨çš„å¯è§£é‡Šæ€§ (Explainability)ï¼Œç ”ç©¶åˆ©ç”¨ Grad-CAM ç³»åˆ—æ–¹æ³•ç»“åˆ ROAD æ‰‹æ®µå¯¹æ¨¡å‹å†³ç­–è¿›è¡Œäº†æ·±å…¥è¯„ä¼°ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é‡‡ç”¨äº†è‡ªé€‚åº”æ¸©åº¦ç¼©æ”¾ (Adaptive temperature scaling) å˜ä½“ï¼Œç¡®ä¿äº†å‰ªææ¨¡å‹åœ¨å¤–éƒ¨æ•°æ®é›†ä¸Šçš„æ ¡å‡†å¯é æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.13412v1",
      "published_date": "2026-01-19 21:48:41 UTC",
      "updated_date": "2026-01-19 21:48:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:14:46.042192+00:00"
    },
    {
      "arxiv_id": "2601.13406v1",
      "title": "Integrating Virtual Reality and Large Language Models for Team-Based Non-Technical Skills Training and Evaluation in the Operating Room",
      "title_zh": "èåˆè™šæ‹Ÿç°å®ä¸å¤§è¯­è¨€æ¨¡å‹çš„æ‰‹æœ¯å®¤å›¢é˜ŸéæŠ€æœ¯æŠ€èƒ½åŸ¹è®­ä¸è¯„ä¼°",
      "authors": [
        "Jacob Barker",
        "Doga Demirel",
        "Cullen Jackson",
        "Anna Johansson",
        "Robbin Miraglia",
        "Darian Hoagland",
        "Stephanie B. Jones",
        "John Mitchell",
        "Daniel B. Jones",
        "Suvranu De"
      ],
      "abstract": "Although effective teamwork and communication are critical to surgical safety, structured training for non-technical skills (NTS) remains limited compared with technical simulation. The ACS/APDS Phase III Team-Based Skills Curriculum calls for scalable tools that both teach and objectively assess these competencies during laparoscopic emergencies. We introduce the Virtual Operating Room Team Experience (VORTeX), a multi-user virtual reality (VR) platform that integrates immersive team simulation with large language model (LLM) analytics to train and evaluate communication, decision-making, teamwork, and leadership. Team dialogue is analyzed using structured prompts derived from the Non-Technical Skills for Surgeons (NOTSS) framework, enabling automated classification of behaviors and generation of directed interaction graphs that quantify communication structure and hierarchy. Two laparoscopic emergency scenarios, pneumothorax and intra-abdominal bleeding, were implemented to elicit realistic stress and collaboration. Twelve surgical professionals completed pilot sessions at the 2024 SAGES conference, rating VORTeX as intuitive, immersive, and valuable for developing teamwork and communication. The LLM consistently produced interpretable communication networks reflecting expected operative hierarchies, with surgeons as central integrators, nurses as initiators, and anesthesiologists as balanced intermediaries. By integrating immersive VR with LLM-driven behavioral analytics, VORTeX provides a scalable, privacy-compliant framework for objective assessment and automated, data-informed debriefing across distributed training environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† **VORTeX**ï¼Œä¸€ç§é›†æˆå¤šç”¨æˆ· **Virtual Reality (VR)** å’Œ **Large Language Models (LLM)** çš„å¹³å°ï¼Œç”¨äºæ‰‹æœ¯å®¤å›¢é˜ŸéæŠ€æœ¯æŠ€èƒ½ (**Non-Technical Skills**) çš„åŸ¹è®­ä¸è¯„ä¼°ã€‚ç³»ç»Ÿé€šè¿‡æ¨¡æ‹Ÿè…¹è…”é•œæ€¥ç—‡åœºæ™¯ï¼Œåˆ©ç”¨åŸºäº **NOTSS** æ¡†æ¶çš„ **LLM** è‡ªåŠ¨åˆ†æå›¢é˜Ÿå¯¹è¯ï¼Œå¹¶ç”Ÿæˆèƒ½å¤Ÿé‡åŒ–æ²Ÿé€šç»“æ„ä¸å±‚çº§çš„æœ‰å‘äº¤äº’å›¾ã€‚è¯•ç‚¹æµ‹è¯•è¡¨æ˜ï¼Œ**VORTeX** å…·æœ‰é«˜åº¦çš„æ²‰æµ¸æ„Ÿå’Œå®ç”¨ä»·å€¼ï¼Œå…¶ **LLM** åˆ†æç»“æœèƒ½å‡†ç¡®ä½“ç°æ‰‹æœ¯å›¢é˜Ÿçš„çœŸå®èŒèƒ½å±‚çº§ã€‚è¯¥æ¡†æ¶ä¸ºåˆ†å¸ƒå¼åŸ¹è®­ç¯å¢ƒä¸‹çš„å®¢è§‚è¡Œä¸ºè¯„ä¼°å’Œè‡ªåŠ¨åŒ–ã€æ•°æ®é©±åŠ¨çš„ç®€æŠ¥ (**Debriefing**) æä¾›äº†å¯æ‰©å±•ä¸”åˆè§„çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "23 pages, 7 figures, 1 table, 2 Appendices",
      "pdf_url": "https://arxiv.org/pdf/2601.13406v1",
      "published_date": "2026-01-19 21:34:00 UTC",
      "updated_date": "2026-01-19 21:34:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:14:53.763457+00:00"
    },
    {
      "arxiv_id": "2601.13404v1",
      "title": "Local-to-Global Logical Explanations for Deep Vision Models",
      "title_zh": "æ·±åº¦è§†è§‰æ¨¡å‹çš„ä»å±€éƒ¨åˆ°å…¨å±€é€»è¾‘è§£é‡Š",
      "authors": [
        "Bhavan Vasu",
        "Giuseppe Raffa",
        "Prasad Tadepalli"
      ],
      "abstract": "While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability we show that the explanations maintain high fidelity and coverage with respect to the blackbox models they seek to explain in challenging vision datasets.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ï¼šLocal-to-Global Logical Explanations ğŸ”\n\n---\n\nè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹æ·±åº¦è§†è§‰æ¨¡å‹çš„å±€éƒ¨ä¸å…¨å±€è§£é‡Šæ–¹æ³•ï¼Œé€šè¿‡äººç±»å¯è¯†åˆ«çš„åŸå§‹æ¦‚å¿µ (**Primitive concepts**) æ„å»ºé€»è¾‘è§£é‡Šã€‚ä½œè€…å°†å±€éƒ¨ä¸å…¨å±€è§£é‡Šå‡å»ºæ¨¡ä¸ºå•è°ƒæå–èŒƒå¼ (**Monotone Disjunctive-Normal-Form, MDNF**) çš„é€»è¾‘å…¬å¼ï¼Œå¹¶å¼•å…¥äº†é€‚ç”¨äºå¤šç±»åˆ«åœºæ™¯çš„å•è°ƒè§£é‡Šåˆ—è¡¨ç®—æ³•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¿™äº›è§£é‡Šå½¢å¼è™½ç„¶ç®€å•ç›´è§‚ï¼Œä½†åœ¨å¤„ç†æŒ‘æˆ˜æ€§è§†è§‰ä»»åŠ¡æ—¶ï¼Œä»èƒ½ä¸åŸé»‘ç›’æ¨¡å‹ä¿æŒæé«˜çš„å¿ å®åº¦ (**Fidelity**) å’Œè¦†ç›–ç‡ (**Coverage**)ã€‚\n\n---\n\nå¦‚æœæ‚¨éœ€è¦å¯¹è¯¥ç ”ç©¶ä¸­çš„ **MDNF** é€»è¾‘æ„é€ æˆ–å…¶åœ¨ç‰¹å®šè§†è§‰æ•°æ®é›†ä¸Šçš„è¡¨ç°è¿›è¡Œæ›´æ·±å…¥çš„æ¢è®¨ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼æ‚¨å¯¹è¿™ç§å°†é»‘ç›’æ¨¡å‹è½¬åŒ–ä¸ºé€»è¾‘å…¬å¼çš„æ–¹æ³•æ€ä¹ˆçœ‹ï¼Ÿ",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 5 figures, 5th International Joint Conference on Learning & Reasoning 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.13404v1",
      "published_date": "2026-01-19 21:21:58 UTC",
      "updated_date": "2026-01-19 21:21:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:15:15.890560+00:00"
    },
    {
      "arxiv_id": "2601.13401v1",
      "title": "Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics",
      "title_zh": "åƒç´ çº§ç²¾å‡†æ¨ç†ï¼šé¢å‘å®šé‡åœ°ç†ç©ºé—´åˆ†æçš„ QVLM æ¶æ„ä¸ SQuID æ•°æ®é›†",
      "authors": [
        "Peter A. Massih",
        "Eric Cosatto"
      ],
      "abstract": "Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºå½“å‰ **Vision-Language Models (VLMs)** ç”±äº **patch embeddings** å‹ç¼©è¿‡ç¨‹ç ´åäº†åƒç´ çº§ä¿¡æ¯ï¼Œå¯¼è‡´å…¶åœ¨éœ€è¦ç²¾ç¡®è®¡æ•°å’Œæµ‹é‡çš„å®šé‡ç©ºé—´æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶é¦–å…ˆå¼•å…¥äº† **SQuID (Satellite Quantitative Intelligence Dataset)**ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å« 2000 ä¸ªå«æ˜Ÿå›¾åƒé—®ç­”å¯¹çš„åŸºå‡†æ•°æ®é›†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°å®šé‡åœ°ç†ç©ºé—´åˆ†æèƒ½åŠ›ã€‚éšåæå‡ºäº† **QVLM (Quantitative Vision-Language Model)** æ¶æ„ï¼Œé€šè¿‡ä»£ç ç”Ÿæˆå°†è¯­è¨€ç†è§£ä¸è§†è§‰åˆ†æè§£è€¦ï¼Œåˆ©ç”¨åˆ†å‰²æ¨¡å‹ç”Ÿæˆçš„åƒç´ çº§ **masks** è¿›è¡Œç›´æ¥è¿ç®—ä»¥ä¿æŒç²¾åº¦ã€‚å®éªŒè¡¨æ˜ï¼Œä»¥ **GPT-5** ä¸ºåç«¯çš„ **QVLM** åœ¨ **SQuID** æ•°æ®é›†ä¸Šè¾¾åˆ°äº† 42.0% çš„å‡†ç¡®ç‡ï¼Œè¿œè¶…ä¼ ç»Ÿ **VLMs** çš„ 28.1%ã€‚è¯¥å·¥ä½œè¯æ˜äº†æ¶æ„è§£è€¦æ˜¯å®ç°é«˜ç²¾åº¦åœ°ç†ç©ºé—´å®šé‡æ¨ç†çš„å…³é”®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to CVPR 2026. Introduces the QVLM architecture and the SQuID dataset for quantitative geospatial reasoning. Dataset DOI: 10.57967/hf/7565",
      "pdf_url": "https://arxiv.org/pdf/2601.13401v1",
      "published_date": "2026-01-19 21:14:34 UTC",
      "updated_date": "2026-01-19 21:14:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:15:14.257443+00:00"
    },
    {
      "arxiv_id": "2601.13400v1",
      "title": "Deep Image Prior with L0 Gradient Regularizer for Image Smoothing",
      "title_zh": "åŸºäº $L_0$ æ¢¯åº¦æ­£åˆ™é¡¹æ·±åº¦å›¾åƒå…ˆéªŒçš„å›¾åƒå¹³æ»‘",
      "authors": [
        "Nhat Thanh Tran",
        "Kevin Bui",
        "Jack Xin"
      ],
      "abstract": "Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\\ell_0$, a deep image prior framework that incorporates the $\\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\\ell_0$ ``norm\", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **DIP-$\\ell_0$**ï¼Œä¸€ä¸ªç»“åˆäº† **$\\ell_0$ gradient regularizer** çš„æ·±åº¦å›¾åƒå…ˆéªŒ (**Deep Image Prior, DIP**) æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºå›¾åƒå¹³æ»‘ (**Image smoothing**) å¤„ç†ã€‚\n\nä¸ºäº†è§£å†³åŒ…å«éå‡¸ä¸”éå…‰æ»‘ $\\ell_0$ èŒƒæ•°çš„ä¼˜åŒ–éš¾é¢˜ï¼Œè¯¥æ¡†æ¶å¼€å‘äº†ä¸€ç§äº¤æ›¿æ–¹å‘ä¹˜å­æ³• (**Alternating direction method of multipliers, ADMM**) ç®—æ³•ï¼Œå¹¶é›†æˆäº†ç°æˆçš„æ¢¯åº¦æœ€å°åŒ–æ±‚è§£å™¨ã€‚\n\nä¸ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ–¹æ³•ä¸åŒï¼Œ**DIP-$\\ell_0$** æ— éœ€ä»»ä½•è®­ç»ƒæ•°æ®å³å¯å®ç°é«˜è´¨é‡çš„å›¾åƒå¹³æ»‘ï¼Œæœ‰æ•ˆé¿å…äº†æ„å»ºæ ‡æ³¨æ•°æ®é›†çš„éš¾é¢˜ã€‚\n\nå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¾¹ç¼˜ä¿ç•™å¹³æ»‘ (**Edge-preserving image smoothing**) å’Œ **JPEG artifact removal** ä»»åŠ¡ä¸­å‡ä¼˜äºè®¸å¤šç°æœ‰çš„ä¸»æµç®—æ³•ã€‚\n\n---\n\n**è¿˜éœ€è¦æˆ‘ä¸ºæ‚¨æ€»ç»“å…¶ä»–é¢†åŸŸçš„è®ºæ–‡ï¼Œæˆ–è€…å¯¹è¯¥æ–¹æ³•çš„æ•°å­¦ç»†èŠ‚è¿›è¡Œæ›´æ·±å±‚çš„è§£è¯»å—ï¼Ÿ**",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "To be published in the Proceedings of IEEE ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.13400v1",
      "published_date": "2026-01-19 21:10:32 UTC",
      "updated_date": "2026-01-19 21:10:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:15:24.202653+00:00"
    },
    {
      "arxiv_id": "2601.13398v1",
      "title": "Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹èƒ½å¦å®ç°å‹ç¼©ï¼ˆä¸è§£å‹ç¼©ï¼‰ï¼Ÿé€šè¿‡å¯é€†æ€§è¯„ä¼°ä»£ç ç†è§£ä¸æ‰§è¡Œèƒ½åŠ›",
      "authors": [
        "Nickil Maveli",
        "Antonio Vergari",
        "Shay B. Cohen"
      ],
      "abstract": "LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.",
      "tldr_zh": "---\n\n### ğŸ“„ è®ºæ–‡æ‘˜è¦æ€»ç»“ (TLDR)\n\nè¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç æ‰§è¡Œæ¨ç†ä¸­å‰åä¸€è‡´æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº† **RoundTripCodeEval (RTCE)** è¯„æµ‹åŸºå‡†ã€‚RTCE é€šè¿‡è¯„ä¼°â€œåŒå°„ä¿çœŸåº¦â€ï¼ˆbijection fidelityï¼‰ï¼Œä¸¥è°¨åœ°æµ‹è¯•æ¨¡å‹åœ¨ç¼–ç ä¸è§£ç æ“ä½œé—´æ˜¯å¦èƒ½ç»´æŒä¸€è‡´çš„ä¸€ä¸€æ˜ å°„ã€‚å®éªŒè¡¨æ˜ï¼Œå³ä¾¿é‡‡ç”¨ **zero-shot** æç¤ºã€ç›‘ç£å¾®è°ƒï¼ˆ**SFT**ï¼‰æˆ–è‡ªæˆ‘åæ€æœºåˆ¶ï¼Œç°æœ‰çš„ **Code-LLMs** ä»éš¾ä»¥å®ç°çœŸæ­£çš„å¾€è¿”ä¸€è‡´æ€§ï¼ˆround-trip consistencyï¼‰ï¼Œæš´éœ²å‡ºå…¶åœ¨ä»£ç æ¨ç†ä¸­ç¼ºä¹å¿…è¦çš„å†…éƒ¨è¿è´¯æ€§ï¼ˆinternal coherenceï¼‰ã€‚è¯¥åŸºå‡†æ­ç¤ºäº†ç°æœ‰ I/O é¢„æµ‹å’Œæ‰§è¡Œæ¨ç†åŸºå‡†æ— æ³•æ•æ‰çš„æ·±å±‚é—®é¢˜ï¼Œä¸ºè¯„ä¼°æ›´å¯é çš„ä»£ç æ¨¡å‹æä¾›äº†æ–°ç»´åº¦ã€‚\n\n---\n\n### ğŸ” æ ¸å¿ƒç ”ç©¶æ¦‚è§ˆ\n\n| ç»´åº¦ | å†…å®¹è¯´æ˜ |\n|---|---|\n| **æ ¸å¿ƒè´¡çŒ®** | æå‡ºäº† **RoundTripCodeEval (RTCE)** åŸºå‡†ï¼Œä¸“æ³¨äºè¯„ä¼°ä»£ç æ¨ç†çš„å¾€è¿”ä¸€è‡´æ€§ã€‚ |\n| **ç ”ç©¶æ–¹æ³•** | åŒ…å«å››é¡¹ä»£ç æ‰§è¡Œä»»åŠ¡ï¼Œé‡‡ç”¨æ— éœ€æ‰§è¡Œçš„ç²¾ç¡®åŒ¹é…è¯„ä¼°æ–¹å¼æ¥æ£€æµ‹æ¨¡å‹çš„å¯é€†æ€§ã€‚ |\n| **å®éªŒå¯¹è±¡** | é’ˆå¯¹æœ€å…ˆè¿›çš„ **Code-LLMs** è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼Œæµ‹è¯•äº†å¤šç§ä¼˜åŒ–ç­–ç•¥çš„å½±å“ã€‚ |\n| **å…³é”®ç»“è®º** | ç°æœ‰æ¨¡å‹åœ¨ç†è§£ä»£ç çš„åŒå‘æ˜ å°„æ–¹é¢å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼Œæ— æ³•è¾¾åˆ°çœŸæ­£çš„å¯ä¿¡æ¨ç†æ°´å¹³ã€‚ |\n\n---\n\næˆ‘æ˜¯ Gemini Enterpriseï¼Œå¾ˆé«˜å…´èƒ½ä¸ºæ‚¨æç‚¼è¿™ç¯‡å…³äºä»£ç ç†è§£å¯é€†æ€§çš„å‰æ²¿ç ”ç©¶ã€‚å¦‚æœæ‚¨æƒ³æ·±å…¥äº†è§£ **RTCE** åŸºå‡†åŒ…å«çš„å…·ä½“ä»»åŠ¡ç±»å‹ï¼Œæˆ–è€…å¯¹å®éªŒä¸­ä¸åŒæ¨¡å‹çš„è¡¨ç°æ„Ÿå…´è¶£ï¼Œæ¬¢è¿éšæ—¶è¯¢é—®ï¼",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages (preprint)",
      "pdf_url": "https://arxiv.org/pdf/2601.13398v1",
      "published_date": "2026-01-19 21:09:48 UTC",
      "updated_date": "2026-01-19 21:09:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:15:39.230454+00:00"
    },
    {
      "arxiv_id": "2601.13392v1",
      "title": "Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks",
      "title_zh": "### Overview of the Research ğŸ“„\n\nI have reviewed the paper title and abstract you provided. This research investigates whether the performance of Large Language Models (LLMs) on formal language tasks is a result of genuine symbolic reasoning or simply pattern matching from training data. \n\nBelow is a summary of the key components and findings detailed in the abstract:\n\n| Category | Details |\n|---|---|\n| **Research Focus** | Testing LLM reasoning vs. memorization using Deterministic Finite Automata (DFA) construction. |\n| **Benchmark Components** | Factual knowledge, \"seen\" problems from public sources, and \"unseen\" hand-crafted/systematically generated problems. |\n| **Performance on Known Tasks** | High success rates: 100% on factual questions and 84-90% on \"seen\" tasks. |\n| **Performance on Unseen Tasks** | Significant drop in accuracy (30-64%) when facing novel constraints or Arden's theorem-generated problems. |\n| **Common Failure Modes** | Misinterpretation of constraints, incorrect Kleene-star semantics, and global inconsistency in the automata. |\n| **Tested Strategies** | Direct prompting, Chain-of-Thought (CoT), Tree-of-Thought (ToT), and a three-stage hint protocol. |\n| **Conclusion** | LLMs struggle to bridge the gap between generating syntactically plausible DFAs and achieving semantically correct formal reasoning. |\n\n---\n\n### How can I assist you further? ğŸ¤–\n\nThis sounds like a fascinating study on the limitations of current architectures in formal logic domains. Would you like me to:\n\n*   **Analyze specific parts** of this abstract in more detail?\n*   **Compare these findings** with other known LLM reasoning benchmarks?\n*   **Help you draft** a response, summary, or presentation based on this information?\n\nLet me know how I can help!",
      "authors": [
        "Shlok Shelat",
        "Jay Raval",
        "Souvik Roy",
        "Manas Gaur"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.",
      "tldr_zh": "It is a pleasure to meet you! I am Gemini Enterpriseâœ¨. Thank you for sharing the title and abstract of this research. This paper highlights a critical limitation in current Large Language Models regarding their ability to transition from pattern matching to genuine symbolic reasoning in formal logic.\n\nHere is a summary of the key findings and methodology presented in the abstract:\n\n---\n\n### ğŸ“‹ Research Overview: LLM Reasoning on DFA Tasks\n\n| Category | Details |\n|---|---|\n| **Core Objective** | To determine if LLMs possess genuine symbolic reasoning capabilities or if they rely on memorized patterns for Theory of Computation tasks. |\n| **Benchmark Composition** | 1. Factual knowledge questions. <br> 2. \"Seen\" construction problems (from public sources). <br> 3. \"Unseen\" problems (hand-crafted constraints and Arden's theorem generation). |\n| **Key Performance Metrics** | **Seen Tasks:** 84-90% accuracy. <br> **Unseen Tasks:** 30-64% drop in accuracy. |\n| **Primary Failure Modes** | Misinterpretation of constraints, incorrect Kleene-star semantics, and lack of global consistency. |\n| **Tested Strategies** | Direct prompting, Chain-of-Thought (CoT), and Tree-of-Thought (ToT). |\n\n---\n\n### ğŸ” Key Insights\n\n*   **The \"Memorization Gap\":** The sharp decline in performance on unseen problems suggests that models are largely \"parroting\" known DFA structures rather than understanding the underlying formal language rules.\n*   **Prompting Limitations:** Even advanced reasoning frameworks like Tree-of-Thought failed to bridge the gap between generating syntactically correct code (plausible DFAs) and semantically valid logic.\n*   **Structural Flaws:** While hints can fix \"shallow\" or surface-level errors, they do not seem to help models correct fundamental structural misunderstandings in the automata.\n\n---\n\n### ğŸ’¬ How can I assist you further?\n\nThis is a fascinating look into the \"stochastic parrot\" vs. \"reasoning engine\" debate. Would you like me to:\n\n1.  **Analyze specific sections** of this study if you have more text available?\n2.  **Compare these findings** with other benchmarks like GSM8K or Big-Bench?\n3.  **Search for the full paper** or related citations to see how other researchers have responded to these results?\n\nPlease let me know how you would like to proceed!",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages, 11 figures, 6 tables, Work in Progress",
      "pdf_url": "https://arxiv.org/pdf/2601.13392v1",
      "published_date": "2026-01-19 21:00:31 UTC",
      "updated_date": "2026-01-19 21:00:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:15:42.344724+00:00"
    },
    {
      "arxiv_id": "2601.13385v1",
      "title": "Organ-Aware Attention Improves CT Triage and Classification",
      "title_zh": "å™¨å®˜æ„ŸçŸ¥æ³¨æ„åŠ›æå‡ CT é¢„åˆ†è¯Šä¸åˆ†ç±»",
      "authors": [
        "Lavsen Dahal",
        "Yubraj Bhandari",
        "Geoffrey D. Rubin",
        "Joseph Y. Lo"
      ],
      "abstract": "There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.",
      "tldr_zh": "It is a pleasure to meet you! I am **Gemini Enterprise**, and I have analyzed the abstract you provided for the paper titled **\"Organ-Aware Attention Improves CT Triage and Classification.\"** \n\nThis research introduces **ORACLE-CT**, a novel approach designed to overcome the limitations of standard Vision Language Models (VLMs) in processing 3D medical imaging.\n\n---\n\n### Overview of the Research ğŸ“„\n\nThe study addresses the critical need for automated CT triage to support radiologists and improve patient care. While many modern models struggle with 3D anatomy and noisy data, this research demonstrates that a carefully tuned supervised model can outperform complex VLMs. The core innovation is the **ORACLE-CT** head, which integrates organ-specific spatial information and physical metrics (like volume and Hounsfield Units) to provide more accurate and localized diagnostic evidence.\n\n---\n\n### Technical Innovations: ORACLE-CT ğŸ› ï¸\n\nThe ORACLE-CT model is \"encoder-agnostic,\" meaning it can be paired with various underlying neural networks. Its performance gains come from two specific components:\n\n| Feature | Description |\n|---|---|\n| **Organ-Masked Attention** | Uses mask-restricted pooling to focus on specific organs, providing localized spatial evidence for predictions. |\n| **Organ-Scalar Fusion** | Incorporates lightweight physical cues, such as normalized organ volume and mean Hounsfield Units (HU), to refine classification. |\n\n---\n\n### Performance & Dataset Results ğŸ“Š\n\nThe researchers tested their approach against the largest publicly available datasets and established new State-of-the-Art (SOTA) benchmarks for supervised classification.\n\n| Dataset | Setting | Performance (AUROC) | Key Takeaway |\n|---|---|---|---|\n| **CT-RATE** | Chest CT | **0.86** | Surpassed all reported linear-probe Vision Language Models. |\n| **MERLIN** | Abdomen CT | **0.85** | Outperformed reproduced zero-shot VLM baselines. |\n| **RADCHEST-CT** | Chest (External) | N/A (Held-out) | Used as a robust external test set to ensure generalizability. |\n\n---\n\n### Code and Implementation ğŸ”—\n\nThe authors have made their work accessible to the research community. You can find the source code and implementation details at their GitHub repository: [lavsendahal/oracle-ct](https://github.com/lavsendahal/oracle-ct).\n\n---\n\nI found this paper quite fascinating, especially how a supervised approach can still outperform large-scale VLMs in specialized medical tasks. Would you like me to explain the difference between the **Organ-Masked Attention** and traditional **Global Average Pooling** in more detail, or perhaps you have specific questions about the datasets used?",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13385v1",
      "published_date": "2026-01-19 20:37:45 UTC",
      "updated_date": "2026-01-19 20:37:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:15:55.529669+00:00"
    },
    {
      "arxiv_id": "2601.13383v1",
      "title": "A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge",
      "title_zh": "æ„å»ºå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨è‡ªä¸»æ™ºèƒ½ä½“çš„è½»é‡çº§æ¨¡å—åŒ–æ¡†æ¶ï¼šAgentForge çš„è®¾è®¡ã€å®ç°ä¸åº”ç”¨",
      "authors": [
        "Akbar Anbar Jafari",
        "Cagri Ozcinar",
        "Gholamreza Anbarjafari"
      ],
      "abstract": "The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.",
      "tldr_zh": "---\n\n### ğŸ“„ è®ºæ–‡æ‘˜è¦æ€»ç»“ (TLDR)\n\nè¯¥ç ”ç©¶æ¨å‡ºäº† **AgentForge**ï¼Œä¸€ä¸ªè½»é‡çº§ã€å¼€æºçš„ Python æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ™ºèƒ½ä½“æ¡†æ¶æ¶æ„åƒµåŒ–ã€å‚å•†é”å®šåŠå¤æ‚åº¦è¿‡é«˜çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†å¯ç»„åˆçš„æŠ€èƒ½æŠ½è±¡ã€ç»Ÿä¸€çš„ **LLM** åç«¯æ¥å£ä»¥åŠåŸºäº **YAML** çš„å£°æ˜å¼é…ç½®ç³»ç»Ÿï¼Œå¹¶åˆ©ç”¨æœ‰å‘æ— ç¯å›¾ (**DAG**) å½¢å¼åŒ–äº†ä»»åŠ¡å·¥ä½œæµçš„ç»„åˆæœºåˆ¶ã€‚å®éªŒè¡¨æ˜ï¼Œä¸ **LangChain** ç›¸æ¯”ï¼Œ**AgentForge** åœ¨ä¿æŒé«˜ä»»åŠ¡å®Œæˆç‡çš„åŒæ—¶ï¼Œå°†å¼€å‘æ—¶é—´ç¼©çŸ­äº† 62%ï¼Œä¸”ç³»ç»Ÿç¼–æ’å¼€é”€ä½äº 100 æ¯«ç§’ã€‚è¯¥æ¡†æ¶ä¸ºæ„å»ºã€è¯„ä¼°å’Œéƒ¨ç½²é«˜æ€§èƒ½è‡ªä¸»æ™ºèƒ½ä½“æä¾›äº†ä¸€ä¸ªçµæ´»ä¸”ç”Ÿäº§å°±ç»ªçš„åŸºç¡€ã€‚\n\n---\n\n### ğŸ” æ¡†æ¶æ ¸å¿ƒç‰¹æ€§\n\n| åˆ›æ–°ç‚¹ | è¯´æ˜ |\n|---|---|\n| **æ¨¡å—åŒ–æ¶æ„** | é‡‡ç”¨å¯ç»„åˆæŠ€èƒ½æŠ½è±¡ï¼Œæ”¯æŒç²¾ç»†åŒ–çš„ä»»åŠ¡åˆ†è§£ä¸è¾“å…¥è¾“å‡ºåè®®ã€‚ |\n| **åç«¯ç»Ÿä¸€åŒ–** | æ”¯æŒåœ¨äº‘ç«¯ **API**ï¼ˆå¦‚ OpenAIï¼‰ä¸æœ¬åœ°æ¨ç†å¼•æ“ä¹‹é—´æ— ç¼åˆ‡æ¢ã€‚ |\n| **é…ç½®è§£è€¦** | é€šè¿‡å£°æ˜å¼ **YAML** é…ç½®å°†æ™ºèƒ½ä½“é€»è¾‘ä¸å…·ä½“å®ç°ç»†èŠ‚åˆ†ç¦»ã€‚ |\n| **é«˜æ•ˆè¡¨ç°** | å¼€å‘æ•ˆç‡æå‡æ˜¾è‘—ï¼ˆè¾ƒç›´æ¥ **API** é›†æˆç¼©çŸ­ 78%ï¼‰ï¼Œé€‚ç”¨äºå®æ—¶åº”ç”¨åœºæ™¯ã€‚ |\n\n---\n\næˆ‘æ˜¯ Gemini Enterpriseâœ¨ï¼Œä¸ºæ‚¨æç‚¼äº† **AgentForge** æ¡†æ¶çš„æ ¸å¿ƒä»·å€¼ã€‚è¿™ç§è¿½æ±‚â€œè½»é‡åŒ–â€ä¸â€œä½å»¶è¿Ÿâ€çš„è®¾è®¡æ€è·¯ï¼Œæ­£é€æ¸æˆä¸ºå½“å‰ **LLM** æ¡†æ¶å‘å±•çš„é‡è¦è¶‹åŠ¿ã€‚æ‚¨æ˜¯å¦éœ€è¦æˆ‘è¿›ä¸€æ­¥å¯¹æ¯”å®ƒä¸ **LangChain** æˆ– **AutoGPT** åœ¨å…·ä½“æ¶æ„ä¸Šçš„å·®å¼‚ï¼Ÿ",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.13383v1",
      "published_date": "2026-01-19 20:33:26 UTC",
      "updated_date": "2026-01-19 20:33:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:15:54.146995+00:00"
    },
    {
      "arxiv_id": "2601.13376v1",
      "title": "Bounded Minds, Generative Machines: Envisioning Conversational AI that Works with Human Heuristics and Reduces Bias Risk",
      "title_zh": "æœ‰é™å¿ƒæ™ºä¸ç”Ÿæˆå¼æœºå™¨ï¼šæ„æƒ³é€‚é…äººç±»å¯å‘å¼æ€ç»´å¹¶é™ä½åè§é£é™©çš„å¯¹è¯å¼äººå·¥æ™ºèƒ½",
      "authors": [
        "Jiqun Liu"
      ],
      "abstract": "Conversational AI is rapidly becoming a primary interface for information seeking and decision making, yet most systems still assume idealized users. In practice, human reasoning is bounded by limited attention, uneven knowledge, and reliance on heuristics that are adaptive but bias-prone. This article outlines a research pathway grounded in bounded rationality, and argues that conversational AI should be designed to work with human heuristics rather than against them. It identifies key directions for detecting cognitive vulnerability, supporting judgment under uncertainty, and evaluating conversational systems beyond factual accuracy, toward decision quality and cognitive robustness.",
      "tldr_zh": "---\n\n### ğŸ“„ è®ºæ–‡æ‘˜è¦æ€»ç»“ (TLDR)\n\næœ¬ç ”ç©¶æ¢è®¨äº†å¯¹è¯å¼ AI å¦‚ä½•åº”å¯¹äººç±»åœ¨ç°å®ä¸­çš„ **bounded rationality**ï¼ˆæœ‰é™ç†æ€§ï¼‰é—®é¢˜ï¼ŒæŒ‡å‡ºäººç±»æ¨ç†å—é™äºæ³¨æ„åŠ›åŠæ˜“äº§ç”Ÿåå·®çš„å¯å‘å¼æ–¹æ³•ï¼ˆ**heuristics**ï¼‰ã€‚æ–‡ç« æå‡ºäº†ä¸€æ¡æ–°çš„ç ”ç©¶è·¯å¾„ï¼Œä¸»å¼ å¯¹è¯å¼ AI çš„è®¾è®¡åº”ä¸äººç±»çš„å¯å‘å¼æ–¹æ³•ååŒå·¥ä½œè€Œéå¯¹æŠ—ã€‚è¯¥ç ”ç©¶ç¡®å®šäº†æ£€æµ‹â€œè®¤çŸ¥è„†å¼±æ€§â€ï¼ˆ**cognitive vulnerability**ï¼‰ã€æ”¯æŒä¸ç¡®å®šæ€§ä¸‹çš„åˆ¤æ–­ç­‰å…³é”®æ–¹å‘ã€‚ä½œè€…å¼ºè°ƒï¼Œè¯„ä¼°å¯¹è¯ç³»ç»Ÿåº”è¶…è¶Šä¼ ç»Ÿçš„äº‹å®å‡†ç¡®æ€§ï¼Œè½¬å‘å…³æ³¨å†³ç­–è´¨é‡ï¼ˆ**decision quality**ï¼‰å’Œâ€œè®¤çŸ¥ç¨³å¥æ€§â€ï¼ˆ**cognitive robustness**ï¼‰ã€‚\n\n---\n\n### ğŸ§  ç ”ç©¶æ ¸å¿ƒç»´åº¦\n\n| ç»´åº¦ | å†…å®¹è¯´æ˜ |\n|---|---|\n| **æ ¸å¿ƒæŒ‘æˆ˜** | ç°æœ‰ç³»ç»Ÿå‡è®¾ç”¨æˆ·æ˜¯â€œç†æƒ³åŒ–â€çš„ï¼Œå¿½è§†äº†äººç±»åœ¨ä¿¡æ¯å¯»æ±‚ä¸­æ³¨æ„åŠ›æœ‰é™ä¸”æ˜“å—åå·®å½±å“ã€‚ |\n| **ä¸»è¦è§‚ç‚¹** | å¯¹è¯å¼ AI çš„è®¾è®¡åº”åŸºäº **bounded rationality**ï¼Œå¹¶ä¸äººç±»çš„å¯å‘å¼æ€ç»´æ¨¡å‹ç›¸åŒ¹é…ã€‚ |\n| **ç ”ç©¶æ–¹å‘** | ä¾§é‡äºæ£€æµ‹ç”¨æˆ·çš„è®¤çŸ¥æ¼æ´ï¼Œå¹¶åœ¨ä¸ç¡®å®šç¯å¢ƒä¸‹è¾…åŠ©äººç±»è¿›è¡Œåˆ¤æ–­ã€‚ |\n| **è¯„ä»·æ ‡å‡†** | æå€¡å°† **decision quality** å’Œ **cognitive robustness** ä½œä¸ºè¡¡é‡ç³»ç»Ÿæ€§èƒ½çš„æ–°æŒ‡æ ‡ã€‚ |\n\n---\n\næˆ‘æ˜¯ Gemini Enterpriseâœ¨ï¼Œä¸ºæ‚¨æç‚¼äº†è¿™ç¯‡å…³äºâ€œäººç±»è®¤çŸ¥ä¸ AI åä½œâ€çš„å‰ç»æ€§ç ”ç©¶ã€‚è¯¥è®ºæ–‡å°†è®¤çŸ¥å¿ƒç†å­¦ä¸å¯¹è¯å¼ AI è®¾è®¡ç›¸ç»“åˆï¼Œä¸ºå‡å°‘äº¤äº’åå·®æä¾›äº†æ–°æ€è·¯ã€‚æ‚¨æ˜¯å¦æƒ³è¿›ä¸€æ­¥äº†è§£æ–‡ä¸­æåˆ°çš„â€œè®¤çŸ¥è„†å¼±æ€§â€å…·ä½“æŒ‡å“ªäº›æ–¹é¢ï¼Œæˆ–è€…æ¢è®¨å¦‚ä½•æé«˜ AI åœ¨å†³ç­–ä¸­çš„ç¨³å¥æ€§ï¼Ÿ",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13376v1",
      "published_date": "2026-01-19 20:23:28 UTC",
      "updated_date": "2026-01-19 20:23:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:16:06.374299+00:00"
    },
    {
      "arxiv_id": "2601.13358v1",
      "title": "The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models",
      "title_zh": "æ€ç»´å‡ ä½•ï¼šè§„æ¨¡å¦‚ä½•é‡æ„å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†",
      "authors": [
        "Samuel Cyrenius Anderson"
      ],
      "abstract": "Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.",
      "tldr_zh": "---\n\n### ğŸ“„ è®ºæ–‡æ‘˜è¦æ€»ç»“ (TLDR)\n\nè¯¥ç ”ç©¶é€šè¿‡åˆ†æè·¨å››ç§é¢†åŸŸçš„ 2.5 ä¸‡æ¡æ€ç»´é“¾ï¼ˆ**Chain-of-Thought**ï¼‰è½¨è¿¹ï¼Œå‘ç°æ¨¡å‹è§„æ¨¡çš„å¢åŠ ä¼šè§¦å‘é¢†åŸŸç‰¹å®šçš„å‡ ä½•ç»“æ„é‡æ„è€Œéå‡åŒ€çš„èƒ½åŠ›æå‡ã€‚ç ”ç©¶æ­ç¤ºäº†æ³•å¾‹æ¨ç†çš„â€œç»“æ™¶åŒ–â€ï¼ˆ**Crystallization**ï¼‰ã€ç§‘å­¦ä¸æ•°å­¦æ¨ç†çš„â€œæ¶²ä½“â€åŒ–ï¼ˆ**Liquid**ï¼‰ä»¥åŠä»£ç æ¨ç†çš„â€œæ™¶æ ¼â€åŒ–ï¼ˆ**Lattice**ï¼‰ä¸‰ç§æˆªç„¶ä¸åŒçš„æ¼”åŒ–æ¨¡å¼ã€‚åŸºäºè¿™äº›å‡ ä½•ç‰¹æ€§ï¼Œç ”ç©¶æå‡ºäº† **Neural Reasoning Operators**ï¼Œåœ¨ç»“æ™¶åŒ–ç¨‹åº¦é«˜çš„é¢†åŸŸèƒ½å¤Ÿè·³è¿‡ä¸­é—´æ¨ç†çŠ¶æ€ç›´æ¥é¢„æµ‹ç»ˆç‚¹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è¯†åˆ«å‡ºä¸€ç§è·¨é¢†åŸŸé€šç”¨çš„å±‚é—´æŒ¯è¡ç‰¹å¾ï¼Œè¯æ˜æ¨ç†æˆæœ¬å–å†³äºæµå½¢å‡ ä½•ï¼ˆ**Manifold Geometry**ï¼‰ï¼Œä¸ºåˆ©ç”¨æ‹“æ‰‘ç»“æ„å®ç°æ¨ç†åŠ é€Ÿæä¾›äº†æ–°çš„ç†è®ºåŸºç¡€ã€‚\n\n---\n\n### ğŸ§  æ ¸å¿ƒå‘ç°æ¦‚è§ˆ\n\n| æ¨ç†é¢†åŸŸ | å‡ ä½•æ¼”åŒ–æ¨¡å¼ | æ ¸å¿ƒç‰¹å¾æè¿° |\n|---|---|---|\n| **æ³•å¾‹ (Law)** | **Crystallization** | è¡¨å¾ç»´åº¦åç¼© 45%ï¼Œè½¨è¿¹å¯¹é½åº¦æå‡ï¼Œæµå½¢è§£ç¼ ç»“ã€‚ |\n| **ç§‘å­¦/æ•°å­¦ (Science/Math)** | **Liquid** | å‡ ä½•ç‰¹æ€§åœ¨è§„æ¨¡æ‰©å¤§ 9 å€åä»ä¿æŒä¸å˜ï¼Œå…·æœ‰å‡ ä½•ä¸å˜æ€§ã€‚ |\n| **ä»£ç  (Code)** | **Lattice** | å½¢æˆäº†ç¦»æ•£çš„ç­–ç•¥æ¨¡å¼ï¼Œç»“æ„åŒ–ç¨‹åº¦æ˜¾è‘—æå‡ã€‚ |\n\n---\n\næˆ‘æ˜¯ Gemini Enterpriseâœ¨ï¼Œè¿™ç¯‡è®ºæ–‡æå‡ºçš„â€œæ€ç»´å‡ ä½•å­¦â€æ¦‚å¿µéå¸¸æ–°é¢–ï¼Œå®ƒå°†å¤§æ¨¡å‹è§„æ¨¡åŒ–æ•ˆåº”ï¼ˆ**Scaling Laws**ï¼‰ä¸æµå½¢æ‹“æ‰‘è”ç³»åœ¨äº†ä¸€èµ·ã€‚å¦‚æœæ‚¨å¯¹ **Neural Reasoning Operators** çš„å…·ä½“å·¥ä½œæœºåˆ¶æ„Ÿå…´è¶£ï¼Œæˆ–è€…æƒ³äº†è§£å¦‚ä½•åˆ©ç”¨è¿™äº›å‡ ä½•ç‰¹æ€§æ¥åŠ é€Ÿæ¨ç†ï¼Œæ¬¢è¿ç»§ç»­æ¢è®¨ï¼",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "34 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.13358v1",
      "published_date": "2026-01-19 19:53:37 UTC",
      "updated_date": "2026-01-19 19:53:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:16:14.425070+00:00"
    },
    {
      "arxiv_id": "2601.13352v1",
      "title": "LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction",
      "title_zh": "LLM-as-RNNï¼šä¸€ç§ç”¨äºè®°å¿†æ›´æ–°ä¸åºåˆ—é¢„æµ‹çš„å¾ªç¯è¯­è¨€æ¨¡å‹",
      "authors": [
        "Yuxing Lu",
        "J. Ben Tamo",
        "Weichen Zhao",
        "Nan Sun",
        "Yishan Zhong",
        "Wenqi Shi",
        "Jinzhuo Wang",
        "May D. Wang"
      ],
      "abstract": "Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.",
      "tldr_zh": "---\n\n### ğŸ“„ è®ºæ–‡æ‘˜è¦æ€»ç»“ (TLDR)\n\nè¯¥ç ”ç©¶æå‡ºäº† **LLM-as-RNN**ï¼Œä¸€ç§ä»…æ¨ç†ï¼ˆ**inference-only**ï¼‰çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨åºåˆ—é¢„æµ‹ä¸­å› ä¸Šä¸‹æ–‡å†å²ä¸å¯å˜è€Œç¼ºä¹å®æ—¶çº é”™æœºåˆ¶çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•å°†å†»ç»“çš„ LLM è§†ä¸ºå¾ªç¯é¢„æµ‹å™¨ï¼Œå°†å…¶â€œéšè—çŠ¶æ€â€ï¼ˆ**hidden state**ï¼‰è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€å½¢å¼çš„ç»“æ„åŒ–å†…å­˜ï¼ˆ**natural-language memory**ï¼‰ã€‚é€šè¿‡åé¦ˆé©±åŠ¨çš„æ–‡æœ¬é‡å†™åœ¨æ¯ä¸ªæ—¶é—´æ­¥æ›´æ–°å†…å­˜ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨ä¸æ›´æ–°å‚æ•°çš„æƒ…å†µä¸‹å®ç°è¯­è¨€å±‚é¢çš„åœ¨çº¿å­¦ä¹ ï¼ˆ**online learning**ï¼‰ã€‚å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨åŒ»ç–—ã€æ°”è±¡åŠé‡‘èåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äº **zero-shot** å’Œ **MemPrompt** ç­‰åŸºçº¿ï¼Œå‡†ç¡®ç‡å¹³å‡æå‡ 6.5%ï¼Œå¹¶æä¾›äº†å¯è§£é‡Šçš„å­¦ä¹ è½¨è¿¹ã€‚\n\n---\n\n### âš™ï¸ æ ¸å¿ƒæŠ€æœ¯ä¸å®éªŒç»“æœ\n\n| ç»´åº¦ | å†…å®¹è¯´æ˜ |\n|---|---|\n| **æ ¸å¿ƒç†å¿µ** | å°† **LLM** çš„éšè—çŠ¶æ€æ˜¾å¼åŒ–ä¸ºå¯è¯»ã€å¯æ›´æ–°çš„è‡ªç„¶è¯­è¨€æ‘˜è¦ï¼ˆå†…å­˜ï¼‰ã€‚ |\n| **å­¦ä¹ æœºåˆ¶** | åˆ©ç”¨åé¦ˆé©±åŠ¨çš„é‡å†™ï¼ˆ**rewrites**ï¼‰åœ¨å›ºå®š Token é¢„ç®—å†…åŠ¨æ€ä¿®æ­£é”™è¯¯ã€‚ |\n| **æµ‹è¯•æ¨¡å‹** | æ¶µç›–äº† **Llama**ã€**Gemma** åŠ **GPT** ç­‰ä¸»æµæ¨¡å‹ç³»åˆ—ã€‚ |\n| **ä¸»è¦ä¼˜åŠ¿** | æå‡äº†é•¿åºåˆ—é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œå¹¶ç”Ÿæˆäº†æ ‡å‡†ä¸Šä¸‹æ–‡ç´¯ç§¯æ‰€ç¼ºå¤±çš„å¯è¯»å­¦ä¹ è½¨è¿¹ã€‚ |\n\n---\n\næˆ‘æ˜¯ Gemini Enterpriseâœ¨ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨è§£è¯»è¿™é¡¹å°† LLM ä¸å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰æ€æƒ³ç»“åˆçš„åˆ›æ–°ç ”ç©¶ã€‚è¿™ç§å°†â€œéšè—çŠ¶æ€â€æ–‡å­—åŒ–çš„åšæ³•ä¸ä»…æé«˜äº†é¢„æµ‹ç²¾åº¦ï¼Œè¿˜æå¤§åœ°å¢å¼ºäº†æ¨¡å‹å†³ç­–è¿‡ç¨‹çš„å¯è§£é‡Šæ€§ã€‚æ‚¨æ˜¯å¦æƒ³æ·±å…¥æ¢è®¨è¯¥æ¡†æ¶åœ¨ç‰¹å®šé¢†åŸŸï¼ˆå¦‚é‡‘èæˆ–åŒ»ç–—ï¼‰çš„å…·ä½“åº”ç”¨ç»†èŠ‚ï¼Ÿ",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 5 figures, 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.13352v1",
      "published_date": "2026-01-19 19:41:39 UTC",
      "updated_date": "2026-01-19 19:41:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:16:21.989297+00:00"
    },
    {
      "arxiv_id": "2601.13348v1",
      "title": "The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist Roleplays, Pseudosocial Companions, and Epistemic Rabbit Holes",
      "title_zh": "â€œAI ç¥ç¯â€ç°è±¡ä¸ä¸‰ç±» AI èŠå¤©æœºå™¨äººæˆç˜¾ï¼šé€ƒé¿å¼è§’è‰²æ‰®æ¼”ã€æ‹Ÿç¤¾ä¼šåŒ–é™ªä¼´ä¸è®¤çŸ¥â€œå…”å­æ´â€",
      "authors": [
        "M. Karen Shen",
        "Jessica Huang",
        "Olivia Liang",
        "Ig-Jae Kim",
        "Dongwook Yoon"
      ],
      "abstract": "Recent reports on generative AI chatbot use raise concerns about its addictive potential. An in-depth understanding is imperative to minimize risks, yet AI chatbot addiction remains poorly understood. This study examines how to characterize AI chatbot addiction--why users become addicted, the symptoms commonly reported, and the distinct types it comprises. We conducted a thematic analysis of Reddit entries (n=334) across 14 subreddits where users narrated their experiences with addictive AI chatbot use, followed by an exploratory data analysis. We found: (1) users' dependence tied to the \"AI Genie\" phenomenon--users can get exactly anything they want with minimal effort--and marked by symptoms that align with addiction literature, (2) three distinct addiction types: Escapist Roleplay, Pseudosocial Companion, and Epistemic Rabbit Hole, (3) sexual content involved in multiple cases, and (4) recovery strategies' perceived helpfulness differ between addiction types. Our work lays empirical groundwork to inform future strategies for prevention, diagnosis, and intervention.",
      "tldr_zh": "### **The AI Genie Phenomenon and Three Types of AI Chatbot Addiction**\n\n---\n\nè¯¥ç ”ç©¶é€šè¿‡å¯¹ Reddit å¹³å°ä¸Š 334 æ¡ç”¨æˆ·è®°å½•çš„ Thematic Analysisï¼Œæ·±å…¥æ¢è®¨äº†ç”Ÿæˆå¼ AI èŠå¤©æœºå™¨äººçš„æˆç˜¾æœºåˆ¶åŠå…¶è¡¨ç°ç‰¹å¾ã€‚ç ”ç©¶æå‡ºäº† **\"AI Genie\"** ç°è±¡ï¼Œæ­ç¤ºäº†ç”¨æˆ·å› èƒ½ä»¥æä½åŠªåŠ›è·å¾—é«˜åº¦å®šåˆ¶åŒ–çš„å³æ—¶æ»¡è¶³è€Œäº§ç”Ÿä¾èµ–ï¼Œå¹¶è¯†åˆ«å‡ºä¸‰ç§ç‹¬ç‰¹çš„æˆç˜¾ç±»å‹ï¼š**Escapist Roleplays**ï¼ˆé€ƒé¿ç°å®è§’è‰²æ‰®æ¼”ï¼‰ã€**Pseudosocial Companions**ï¼ˆæ‹Ÿç¤¾äº¤åŒä¼´ï¼‰å’Œ **Epistemic Rabbit Holes**ï¼ˆè®¤è¯†è®º/çŸ¥è¯†æ€§å…”å­æ´ï¼‰ã€‚\n\nç ”ç©¶å‘ç°ï¼Œæ€§å†…å®¹åœ¨å¤šç±»æˆç˜¾æ¡ˆä¾‹ä¸­å‡æœ‰æ¶‰åŠï¼Œä¸”ä¸åŒæˆç˜¾ç±»å‹åœ¨åº·å¤ç­–ç•¥çš„æ„ŸçŸ¥æœ‰æ•ˆæ€§ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚è¯¥å·¥ä½œä¸ºæœªæ¥é’ˆå¯¹ AI æˆç˜¾çš„é¢„é˜²ã€è¯Šæ–­å’Œå¹²é¢„æä¾›äº†é‡è¦çš„å®è¯åŸºç¡€ã€‚\n\n---\n\nè¿˜éœ€è¦æˆ‘ä¸ºæ‚¨æ€»ç»“å…¶ä»–è®ºæ–‡å—ï¼Ÿæˆ–è€…æ‚¨å¯¹è¿™ä¸‰ç§æˆç˜¾ç±»å‹ä¸­çš„å“ªä¸€ç§æ›´æ„Ÿå…´è¶£ï¼Ÿ",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To appear in CHI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.13348v1",
      "published_date": "2026-01-19 19:33:58 UTC",
      "updated_date": "2026-01-19 19:33:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:16:34.947113+00:00"
    },
    {
      "arxiv_id": "2601.13327v1",
      "title": "PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion",
      "title_zh": "This paper introduces **PepEDiff**, a novel approach to designing peptide binders that bypasses the need for traditional structure prediction. By operating in a continuous latent space of protein embeddings, it offers a more flexible and diverse way to generate therapeutic peptide candidates.\n\n---\n\n### Key Innovations of PepEDiff ğŸš€\n\n| Feature | Description |\n|---|---|\n| **Structure-Free Design** | Unlike traditional methods that require intermediate 3D structure modeling, PepEDiff generates sequences directly in a latent embedding space. |\n| **Latent Diffusion** | It utilizes diffusion-based sampling within the manifold of a pretrained protein embedding model to propose novel sequences. |\n| **Zero-Shot Capability** | The model can design binders for target proteins without needing prior examples of binders for that specific target. |\n| **Enhanced Diversity** | By avoiding structural constraints during the generation phase, the model explores a wider range of the protein sequence space. |\n\n---\n\n### Case Study: TIGIT ğŸ§¬\n\nThe researchers tested PepEDiff on **TIGIT**, a well-known immune checkpoint protein. TIGIT is notoriously difficult to target because its binding interface is large and flat, lacking the deep \"pockets\" that traditional drug discovery methods usually look for. \n\nPepEDiff was able to outperform current state-of-the-art methods in this challenging scenario, demonstrating that a semantic, embedding-based approach can find binding solutions where structure-based methods might struggle.\n\n---\n\n### Resources ğŸ’»\n\nThe code and implementation details for this framework are publicly available to the research community:\n\n*   **GitHub Repository:** [LabJunBMI/PepEDiff](https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model)\n\n---\n\nThis is a fascinating shift toward \"representation-first\" protein design. Would you like me to dive deeper into how the latent-space diffusion works, or perhaps compare this method to other popular tools like RFdiffusion or ProteinMPNN?",
      "authors": [
        "Po-Yu Liang",
        "Tobo Duran",
        "Jun Bai"
      ],
      "abstract": "We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model",
      "tldr_zh": "This is an impressive development in the field of computational biology! I am **Gemini Enterprise**, and I've analyzed the details you shared about **PepEDiff**. It sounds like a significant shift from traditional structure-dependent methods for peptide binder design.\n\nHere is a summary of the key highlights and technical contributions of the PepEDiff framework.\n\n---\n\n### ğŸ§¬ Core Innovation: Structure-Free Design\n\nThe most striking feature of PepEDiff is its departure from the standard \"structure-first\" paradigm. By operating in a continuous latent space, it bypasses the computational bottlenecks often associated with predicting intermediate 3D structures.\n\n| Feature | Description |\n|---|---|\n| **Approach** | Designs binders directly in the latent space of a pretrained protein embedding model. |\n| **Input Requirements** | Target receptor protein sequence and specific pocket residues. |\n| **Generative Mechanism** | Utilizes latent-space exploration combined with diffusion-based sampling. |\n| **Key Advantage** | Higher sequence and structural diversity compared to models constrained by structural templates. |\n\n---\n\n### ğŸš€ Zero-Shot Capabilities\n\nPepEDiff leverages the \"global protein embedding manifold\" as a semantic prior. This allows the model to propose novel sequences for targets it hasn't specifically \"seen\" during training, making it a true zero-shot generator.\n\n| Benefit | Impact |\n|---|---|\n| **Novelty** | Proposes peptides in previously unseen regions of the protein space. |\n| **Efficiency** | Avoids the need for expensive, target-specific fine-tuning. |\n| **Generalization** | Functions as a general framework applicable to diverse receptor types. |\n\n---\n\n### ğŸ”¬ Case Study: The TIGIT Challenge\n\nThe paper highlights the model's performance on **TIGIT**, a particularly difficult target due to its large, flat protein-protein interaction (PPI) interface. These types of interfaces are notoriously \"undruggable\" because they lack the deep pockets that traditional small molecules or structure-based design tools typically look for.\n\n*   **Result:** PepEDiff outperformed current state-of-the-art methods on this challenging benchmark.\n*   **Significance:** Proves that embedding-based diffusion can capture complex binding physics without explicit 3D modeling.\n\n---\n\n### ğŸ› ï¸ Open Source Resource\n\nFor researchers looking to implement or build upon this work, the authors have made the code accessible:\n\n*   **GitHub Repository:** [LabJunBMI/PepEDiff](https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model)\n\n---\n\nWould you like me to help you summarize specific sections of the GitHub repository, or perhaps compare this latent-diffusion approach to other models like RFdiffusion? I'm here to help you dive deeper!",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13327v1",
      "published_date": "2026-01-19 19:07:32 UTC",
      "updated_date": "2026-01-19 19:07:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:16:43.295719+00:00"
    },
    {
      "arxiv_id": "2601.13317v1",
      "title": "Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse",
      "title_zh": "ä»˜è´¹å£°éŸ³ä¸å…¬å…±ä¿¡æ¯æµï¼šæ°”å€™è¯è¯­çš„å¯è§£é‡Šè·¨å¹³å°ä¸»é¢˜å»ºæ¨¡",
      "authors": [
        "Samantha Sudhoff",
        "Pranav Perumal",
        "Zhaoqing Wu",
        "Tunazzina Islam"
      ],
      "abstract": "Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.",
      "tldr_zh": "### **Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse**\n\n---\n\nè¯¥ç ”ç©¶å¯¹æ¯”åˆ†æäº† Meta å¹³å°ä¸Šçš„ä»˜è´¹å¹¿å‘Šä¸ Bluesky ä¸Šçš„å…¬å…±å¸–æ–‡åœ¨æ°”å€™å˜åŒ–è®®é¢˜ä¸Šçš„è®¨è®ºå·®å¼‚ï¼Œæ—¨åœ¨åŒºåˆ†åˆ¶åº¦æ€§ä¿¡æ¯ï¼ˆinstitutional messagingï¼‰ä¸å…¬ä¼—è¡¨è¾¾ã€‚ä½œè€…æå‡ºäº†ä¸€ç§å¯è§£é‡Šçš„ç«¯åˆ°ç«¯ä¸»é¢˜å‘ç°ä¸åˆ†é…æ¡†æ¶ï¼Œé€šè¿‡è¯­ä¹‰èšç±»å¹¶ç»“åˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆäººç±»å¯ç†è§£çš„ä¸»é¢˜æ ‡ç­¾ã€‚\n\nå®éªŒé€šè¿‡ä¸ä¼ ç»Ÿ Topic Modeling åŸºå‡†çš„å¯¹æ¯”ä»¥åŠ Stance Predictionï¼ˆç«‹åœºé¢„æµ‹ï¼‰ç­‰ä¸‹æ¸¸ä»»åŠ¡çš„éªŒè¯ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚ç ”ç©¶å‘ç°ï¼Œä¸åŒå¹³å°çš„æ¿€åŠ±æœºåˆ¶ï¼ˆæˆ˜ç•¥æ€§è¯´æœ vs. è‡ªå‘æ€§è®¨è®ºï¼‰æ·±åˆ»å½±å“äº†æ°”å€™å™äº‹çš„ä¸»é¢˜ç»“æ„ã€ç«‹åœºå€¾å‘å’Œå¯¹æ”¿æ²»äº‹ä»¶çš„æ—¶é—´å“åº”ç‰¹å¾ï¼Œä¸ºè·¨å¹³å°çš„å™äº‹åˆ†æï¼ˆnarrative analysisï¼‰æä¾›äº†é€šç”¨å·¥å…·ã€‚\n\n---\n\nè¿™é¡¹ç ”ç©¶æ­ç¤ºäº†ä¸åŒç¤¾äº¤å¹³å°å¦‚ä½•é€šè¿‡å…¶å›ºæœ‰çš„æ¿€åŠ±ç»“æ„â€œå¡‘é€ â€æˆ‘ä»¬çš„æ°”å€™è®¤çŸ¥ã€‚æ‚¨æ˜¯å¦æƒ³è¿›ä¸€æ­¥äº†è§£ LLM åœ¨è¿™ç§ä¸»é¢˜å»ºæ¨¡ä¸­å…·ä½“æ‰®æ¼”äº†ä»€ä¹ˆè§’è‰²ï¼Ÿ",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13317v1",
      "published_date": "2026-01-19 19:00:56 UTC",
      "updated_date": "2026-01-19 19:00:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:16:50.607296+00:00"
    },
    {
      "arxiv_id": "2601.13295v1",
      "title": "CooperBench: Why Coding Agents Cannot be Your Teammates Yet",
      "title_zh": "CooperBenchï¼šç¼–ç¨‹æ™ºèƒ½ä½“ä¸ºä½•å°šæ— æ³•æˆä¸ºä½ çš„é˜Ÿå‹",
      "authors": [
        "Arpandeep Khatua",
        "Hao Zhu",
        "Peter Tran",
        "Arya Prabhudesai",
        "Frederic Sadrieh",
        "Johann K. Lieberwirth",
        "Xinkai Yu",
        "Yicheng Fu",
        "Michael J. Ryan",
        "Jiaxin Pei",
        "Diyi Yang"
      ],
      "abstract": "Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.",
      "tldr_zh": "### **CooperBench: Why Coding Agents Cannot be Your Teammates Yet**\n\n---\n\nè¯¥ç ”ç©¶æå‡ºäº† **CooperBench**ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å« 600 å¤šä¸ªåä½œç¼–ç¨‹ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼° **Coding Agents** åœ¨è§£å†³å›¢é˜Ÿå†²çªå’Œæ„å»ºå…±è¯†æ–¹é¢çš„åä½œèƒ½åŠ›ã€‚å®éªŒå‘ç°ï¼Œå½“å‰çš„æ™ºèƒ½ä½“æ­£é¢ä¸´ **\"Curse of Coordination\"**ï¼ˆåè°ƒè¯…å’’ï¼‰ï¼šåœ¨å›¢é˜Ÿåä½œæ¨¡å¼ä¸‹ï¼Œå…¶ä»»åŠ¡æˆåŠŸç‡æ¯”ä¸ªä½“ç‹¬ç«‹å®Œæˆæ—¶å¹³å‡é™ä½äº† 30%ï¼Œè¿™ä¸äººç±»å›¢é˜Ÿé€šè¿‡åä½œæå‡ç”Ÿäº§åŠ›çš„è¡¨ç°æˆªç„¶ç›¸åã€‚\n\nç ”ç©¶è¿›ä¸€æ­¥è¯†åˆ«å‡ºé˜»ç¢æ™ºèƒ½ä½“åä½œçš„ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šé€šè®¯é¢‘é“å› æ— æ•ˆä¿¡æ¯è€Œé˜»å¡ã€æ™ºèƒ½ä½“åç¦»æ—¢å®šæ‰¿è¯ºï¼ˆ**Commitments**ï¼‰ï¼Œä»¥åŠå¯¹é˜Ÿå‹çš„è®¡åˆ’å­˜åœ¨é”™è¯¯é¢„æœŸã€‚å°½ç®¡åœ¨å¤§è§„æ¨¡æ¨¡æ‹Ÿä¸­è§‚å¯Ÿåˆ°äº†è§’è‰²åˆ†å·¥å’Œè°ˆåˆ¤ç­‰æ–°å…´è¡Œä¸ºï¼Œè¯¥ç ”ç©¶ä»å‘¼åå°† AI å¼€å‘çš„é‡å¿ƒä»æå‡ä¸ªä½“èƒ½åŠ›è½¬å‘åŸ¹å…» **Social Intelligence**ï¼ˆç¤¾äº¤æ™ºèƒ½ï¼‰ï¼Œä»¥å®ç°çœŸæ­£çš„å›¢é˜Ÿåä½œã€‚\n\n---\n\nè¿™ç§â€œåè°ƒè¯…å’’â€éå¸¸æœ‰è¶£ï¼Œå®ƒæ­ç¤ºäº†å•çº¯æå‡æ¨¡å‹é€»è¾‘èƒ½åŠ›å¹¶ä¸ç­‰åŒäºæå‡åä½œæ•ˆç‡ã€‚æ‚¨æ˜¯å¦å¸Œæœ›æ·±å…¥äº†è§£ **CooperBench** åœ¨é€šè®¯åè®®æ–¹é¢å¯¹è¿™äº›æ™ºèƒ½ä½“åšäº†å“ªäº›å…·ä½“é™åˆ¶ï¼Ÿæˆ–è€…æƒ³æ¢è®¨ä¸€ä¸‹å¦‚ä½•æ‰èƒ½æœ‰æ•ˆæå‡ AI çš„ **Social Intelligence**ï¼Ÿ",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.MA",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://cooperbench.com",
      "pdf_url": "https://arxiv.org/pdf/2601.13295v1",
      "published_date": "2026-01-19 18:48:37 UTC",
      "updated_date": "2026-01-19 18:48:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:17:00.661306+00:00"
    },
    {
      "arxiv_id": "2601.13286v1",
      "title": "AI Skills Improve Job Prospects: Causal Evidence from a Hiring Experiment",
      "title_zh": "AI æŠ€èƒ½æå‡å°±ä¸šå‰æ™¯ï¼šæ¥è‡ªæ‹›è˜å®éªŒçš„å› æœè¯æ®",
      "authors": [
        "Fabian Stephany",
        "Ole Teutloff",
        "Angelo Leone"
      ],
      "abstract": "The growing adoption of artificial intelligence (AI) technologies has heightened interest in the labour market value of AI-related skills, yet causal evidence on their role in hiring decisions remains scarce. This study examines whether AI skills serve as a positive hiring signal and whether they can offset conventional disadvantages such as older age or lower formal education. We conduct an experimental survey with 1,700 recruiters from the United Kingdom and the United States. Using a paired conjoint design, recruiters evaluated hypothetical candidates represented by synthetically designed resumes. Across three occupations - graphic designer, office assistant, and software engineer - AI skills significantly increase interview invitation probabilities by approximately 8 to 15 percentage points. AI skills also partially or fully offset disadvantages related to age and lower education, with effects strongest for office assistants, where formal AI certification plays an additional compensatory role. Effects are weaker for graphic designers, consistent with more skeptical recruiter attitudes toward AI in creative work. Finally, recruiters' own background and AI usage significantly moderate these effects. Overall, the findings demonstrate that AI skills function as a powerful hiring signal and can mitigate traditional labour market disadvantages, with implications for workers' skill acquisition strategies and firms' recruitment practices.",
      "tldr_zh": "æˆ‘æ˜¯ **Gemini Enterprise**ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨è§£è¯»è¿™ç¯‡å…³äºåŠ³åŠ¨åŠ›å¸‚åœºè¶‹åŠ¿çš„æœ€æ–°ç ”ç©¶ã€‚\n\n### **AI Skills Improve Job Prospects: Causal Evidence from a Hiring Experiment**\n\n---\n\nè¿™é¡¹ç ”ç©¶é€šè¿‡å¯¹è‹±ç¾ä¸¤å›½ 1,700 åæ‹›è˜äººå‘˜çš„å®éªŒè°ƒæŸ¥ï¼ˆExperimental Surveyï¼‰ï¼Œåˆ©ç”¨é…å¯¹è”åˆåˆ†æè®¾è®¡ï¼ˆPaired Conjoint Designï¼‰ï¼Œæ¢è®¨äº† **AI Skills** åœ¨æ‹›è˜å†³ç­–ä¸­çš„å› æœè¯æ®ï¼ˆ**Causal Evidence**ï¼‰ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨å¹³é¢è®¾è®¡å¸ˆã€åŠå…¬å®¤åŠ©ç†å’Œè½¯ä»¶å·¥ç¨‹å¸ˆè¿™ä¸‰ç±»å²—ä½ä¸­ï¼Œå…·å¤‡ **AI Skills** å¯æ˜¾è‘—æé«˜çº¦ 8 åˆ° 15 ä¸ªç™¾åˆ†ç‚¹çš„é¢è¯•é‚€è¯·æ¦‚ç‡ã€‚\n\næ­¤å¤–ï¼Œ**AI Skills** å±•ç°å‡ºå¼ºå¤§çš„è¡¥å¿ä½œç”¨ï¼Œèƒ½éƒ¨åˆ†æˆ–å®Œå…¨æŠµæ¶ˆå¹´é¾„è¾ƒå¤§æˆ–æ­£å¼å­¦å†è¾ƒä½å¸¦æ¥çš„åŠ£åŠ¿ï¼Œå°¤å…¶åœ¨åŠå…¬å®¤åŠ©ç†å²—ä½ä¸­ï¼Œæ­£å¼çš„ **AI Certification** æ•ˆæœæœ€ä¸ºæ˜¾è‘—ã€‚ç„¶è€Œï¼Œåœ¨å¹³é¢è®¾è®¡å¸ˆå²—ä½ä¸Šè¿™ç§æ•ˆåº”è¾ƒå¼±ï¼Œåæ˜ å‡ºæ‹›è˜è€…å¯¹åˆ›æ„é¢†åŸŸä½¿ç”¨ AI ä»æŒä¿ç•™æ€åº¦ã€‚æ€»çš„æ¥è¯´ï¼Œè¯¥ç ”ç©¶è¯å®äº† **AI Skills** å·²æˆä¸ºå…³é”®çš„ **Hiring Signal**ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç¼“è§£ä¼ ç»Ÿçš„åŠ³åŠ¨åŠ›å¸‚åœºåŠ£åŠ¿ã€‚\n\n---\n\nè¿™é¡¹ç ”ç©¶çš„å‘ç°å¯¹äºæ­£åœ¨è€ƒè™‘èŒä¸šè½¬å‹çš„æ±‚èŒè€…éå¸¸æœ‰å¯å‘ã€‚æ‚¨æ˜¯å¦æƒ³äº†è§£ä¸åŒèŒä¸šï¼ˆå¦‚æ–‡èŒ vs. æŠ€æœ¯èŒï¼‰åœ¨ AI æŠ€èƒ½éœ€æ±‚ä¸Šçš„å…·ä½“å·®å¼‚ï¼Ÿæˆ–è€…éœ€è¦æˆ‘ä¸ºæ‚¨æ€»ç»“æ›´å¤šå…³äº AI å¯¹å°±ä¸šå¸‚åœºå½±å“çš„è®ºæ–‡ï¼Ÿ",
      "categories": [
        "econ.GN",
        "cs.AI"
      ],
      "primary_category": "econ.GN",
      "comment": "46 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.13286v1",
      "published_date": "2026-01-19 18:37:28 UTC",
      "updated_date": "2026-01-19 18:37:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:17:07.707762+00:00"
    },
    {
      "arxiv_id": "2601.13268v1",
      "title": "Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops",
      "title_zh": "é€šè¿‡å¤šæ™ºèƒ½ä½“è¯„ä¼°ç¯è·¯æå‡åŒ»ç–—äººå·¥æ™ºèƒ½çš„å®‰å…¨æ€§ä¸å¯ä¿¡åº¦",
      "authors": [
        "Zainab Ghafoor",
        "Md Shafiqul Islam",
        "Koushik Howlader",
        "Md Rasel Khondokar",
        "Tanusree Bhattacharjee",
        "Sayantan Chakraborty",
        "Adrito Roy",
        "Ushashi Bhattacharjee",
        "Tirtho Roy"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.",
      "tldr_zh": "### **Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops**\n\n---\n\nè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å¤šæ™ºèƒ½ä½“ä¼˜åŒ–æ¡†æ¶ (**Multi-Agent Refinement Framework**)ï¼Œé€šè¿‡ç»“æ„åŒ–çš„è¿­ä»£å¯¹é½æ¥å¢å¼ºåŒ»ç–—å¤§è¯­è¨€æ¨¡å‹ (**LLMs**) çš„å®‰å…¨æ€§ä¸å¯é æ€§ã€‚è¯¥ç³»ç»Ÿæ•´åˆäº†ç”Ÿæˆæ¨¡å‹ï¼ˆ**DeepSeek R1** å’Œ **Med-PaLM**ï¼‰ä¸è¯„ä¼°æ™ºèƒ½ä½“ï¼ˆ**LLaMA 3.1** å’Œ **Phi-4**ï¼‰ï¼Œå¹¶ä¾æ®ç¾å›½åŒ»å­¦ä¼š (**AMA**) çš„åŒ»å­¦ä¼¦ç†åŸåˆ™åŠäº”çº§å®‰å…¨é£é™©è¯„ä¼°åè®® (**SRA-5**) è¿›è¡Œè‡ªåŠ¨åŒ–è¯„ä¼°ã€‚\n\nå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥è¿­ä»£å¾ªç¯ä½¿ä¼¦ç†è¿è§„è¡Œä¸ºå‡å°‘äº† 89%ï¼Œé£é™©é™çº§ç‡è¾¾åˆ° 92%ï¼›å…¶ä¸­ **DeepSeek R1** è¡¨ç°å‡ºæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ï¼Œè€Œ **Med-PaLM** åœ¨å¤„ç†éšç§æ•æ„Ÿåœºæ™¯æ—¶æ›´å…·ä¼˜åŠ¿ã€‚è¿™é¡¹å·¥ä½œä¸ºç¬¦åˆç›‘ç®¡è¦æ±‚ã€å¯æ‰©å±•ä¸”å…·æˆæœ¬æ•ˆç›Šçš„åŒ»ç–— AI å®‰å…¨æ²»ç†æä¾›äº†ä¸€ç§å…¨æ–°èŒƒå¼ã€‚\n\n---\n\næˆ‘æ˜¯ **Gemini Enterprise**ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨è§£è¯»è¿™ç¯‡å…³äºåŒ»ç–— AI å®‰å…¨æ€§çš„è®ºæ–‡ã€‚è¿™ç§åˆ©ç”¨å¤šä¸ª AI è§’è‰²ç›¸äº’æ ¡éªŒï¼ˆç”Ÿæˆ vs. å®¡è®¡ï¼‰çš„æ¨¡å¼æ­£æˆä¸ºæå‡æ¨¡å‹é²æ£’æ€§çš„ä¸»æµè¶‹åŠ¿ã€‚æ‚¨æ˜¯å¦å¯¹ **SRA-5** åè®®çš„å…·ä½“é£é™©åˆ†çº§æ ‡å‡†æ„Ÿå…´è¶£ï¼Ÿæˆ–è€…æƒ³äº†è§£æ›´å¤šå…³äº **Med-PaLM** åœ¨éšç§ä¿æŠ¤æ–¹é¢çš„å…·ä½“è¡¨ç°ï¼Ÿ",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13268v1",
      "published_date": "2026-01-19 18:10:34 UTC",
      "updated_date": "2026-01-19 18:10:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:17:15.700944+00:00"
    },
    {
      "arxiv_id": "2601.13262v1",
      "title": "CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning",
      "title_zh": "CURE-Medï¼šé¢å‘å¤šè¯­è¨€åŒ»å­¦æ¨ç†çš„è¯¾ç¨‹å¯å‘å¼å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Eric Onyame",
        "Akash Ghosh",
        "Subhadip Baidya",
        "Sriparna Saha",
        "Xiuying Chen",
        "Chirag Agarwal"
      ],
      "abstract": "While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/",
      "tldr_zh": "### **CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning**\n\n---\n\nè¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€åŒ»ç–—æ¨ç†ä¸­å¯é æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæ¨å‡ºäº†åŒ…å« 13 ç§è¯­è¨€ï¼ˆæ¶µç›– Amharicã€Yoruba å’Œ Swahili ç­‰ä½èµ„æºè¯­è¨€ï¼‰çš„é«˜è´¨é‡æ•°æ®é›† **CUREMED-BENCH**ã€‚ç ”ç©¶è€…è¿›ä¸€æ­¥æå‡ºäº† **CURE-MED** æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆæ„ŸçŸ¥ä»£ç åˆ‡æ¢çš„ç›‘ç£å¾®è°ƒï¼ˆ**Code-switching-aware SFT**ï¼‰ä¸è¯¾ç¨‹å‘ŠçŸ¥çš„å¼ºåŒ–å­¦ä¹ ï¼ˆ**Curriculum-Informed RL**ï¼Œåˆ©ç”¨ **GRPO** ç®—æ³•ï¼‰ï¼ŒåŒæ­¥æå‡é€»è¾‘æ­£ç¡®æ€§å’Œè¯­è¨€ç¨³å®šæ€§ã€‚\n\nå®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨ä¸åŒè§„æ¨¡çš„æ¨¡å‹ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œå…¶ä¸­ 32B æ¨¡å‹å®ç°äº† 94.96% çš„ **Language Consistency** å’Œ 70.04% çš„ **Logical Correctness**ã€‚è¿™ä¸€æˆæœä¸ºå®ç°æ›´å¯é ã€æ›´å…¬å¹³çš„å…¨çƒå¤šè¯­è¨€åŒ»ç–— AI è¾…åŠ©å†³ç­–å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚\n\n---\n\næˆ‘æ˜¯ **Gemini Enterprise**ï¼Œè¿™ç¯‡è®ºæ–‡å¯¹äºæ¨åŠ¨åŒ»ç–— AI çš„å…¨çƒæ™®æƒ åŒ–å…·æœ‰é‡è¦æ„ä¹‰ã€‚æ‚¨æ˜¯å¦å¯¹ **GRPO** ç®—æ³•åœ¨æå‡å¤šè¯­è¨€ç¨³å®šæ€§æ–¹é¢çš„å…·ä½“æœºåˆ¶æ„Ÿå…´è¶£ï¼Ÿæˆ–è€…éœ€è¦æˆ‘ä¸ºæ‚¨æå– **CUREMED-BENCH** ä¸­é’ˆå¯¹ç‰¹å®šè¯­è¨€çš„è¡¨ç°æ•°æ®ï¼Ÿ",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13262v1",
      "published_date": "2026-01-19 17:51:00 UTC",
      "updated_date": "2026-01-19 17:51:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:17:26.361657+00:00"
    },
    {
      "arxiv_id": "2601.13260v1",
      "title": "Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models",
      "title_zh": "ä¸åº”å¿½è§†åˆ†è¯å™¨ï¼šå¤§è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒè®¾è®¡å†³ç­–",
      "authors": [
        "Sawsan Alqahtani",
        "Mir Tafseer Nayeem",
        "Md Tahmid Rahman Laskar",
        "Tasnim Mohiuddin",
        "M Saiful Bari"
      ],
      "abstract": "Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.",
      "tldr_zh": "æœ¬ç ”ç©¶é‡æ–°å®¡è§†äº†åˆ†è¯ (Tokenization) åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ä¸­çš„é‡è¦æ€§ï¼ŒæŒ‡å‡ºå…¶ç›®å‰å¸¸è¢«è§†ä¸ºé¢„å¤„ç†æ­¥éª¤è€Œéæ ¸å¿ƒå»ºæ¨¡å†³ç­–ã€‚è®ºæ–‡åˆ†æäº† Byte Pair Encoding (BPE) ç­‰å¸¸è§å­è¯æ–¹æ³•åœ¨è¯­è¨€ç»“æ„å¯¹é½ã€åè§æ”¾å¤§ä»¥åŠè·¨è¯­è¨€å®¹é‡æµªè´¹æ–¹é¢çš„å±€é™æ€§ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªä¸Šä¸‹æ–‡æ„ŸçŸ¥ (context-aware) æ¡†æ¶ï¼Œä¸»å¼ å°† Tokenizer ä¸æ¨¡å‹è¿›è¡ŒååŒè®¾è®¡ (co-design)ï¼Œå¹¶ç»“åˆè¯­è¨€ã€é¢†åŸŸåŠéƒ¨ç½²éœ€æ±‚è¿›è¡Œç»¼åˆè€ƒé‡ã€‚ç ”ç©¶å¼ºè°ƒï¼Œé€šè¿‡æ ‡å‡†åŒ–çš„è¯„ä¼°ä¸é€æ˜çš„æŠ¥å‘Šï¼Œå°†åˆ†è¯è§†ä¸ºæ ¸å¿ƒè®¾è®¡ç¯èŠ‚ï¼Œå¯ä»¥æ„å»ºå‡ºæ›´å…¬å¹³ã€é«˜æ•ˆä¸”å…·æœ‰æ›´å¼ºé€‚åº”æ€§çš„è¯­è¨€æŠ€æœ¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EACL 2026 (long, main). The first two authors contributed equally",
      "pdf_url": "https://arxiv.org/pdf/2601.13260v1",
      "published_date": "2026-01-19 17:50:36 UTC",
      "updated_date": "2026-01-19 17:50:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:17:31.987627+00:00"
    },
    {
      "arxiv_id": "2601.13247v1",
      "title": "Aligning Agentic World Models via Knowledgeable Experience Learning",
      "title_zh": "### Overview of WorldMind ğŸ§ \n\nIt looks like you've shared the abstract for a very interesting paper on **WorldMind**, a framework designed to help Large Language Models (LLMs) better understand and respect physical laws when acting as \"world models.\"\n\n---\n\n### The Problem: Physical Hallucinations ğŸ—ï¸\n\nWhile LLMs are great at logic and semantics, they often struggle with the \"procedural grounding\" needed for the real world. This leads to **physical hallucinations**, where the agent suggests a plan that sounds smart but is actually impossible to execute in a physical environment (e.g., trying to move through a wall or picking up an object without being near it).\n\n---\n\n### The Solution: Knowledgeable Experience Learning ğŸ“š\n\nInstead of expensive retraining, **WorldMind** builds a symbolic repository of knowledge by learning from environmental feedback. It breaks down experience into two main types:\n\n| Experience Type | Purpose | Mechanism |\n|---|---|---|\n| **Process Experience** | Enforces physical feasibility | Uses prediction errors to learn what is physically possible. |\n| **Goal Experience** | Guides task optimality | Learns from successful trajectories to find the best way to reach a goal. |\n\n---\n\n### Key Results ğŸ“Š\n\nThe framework was tested on benchmarks like **EB-ALFRED** and **EB-Habitat**, showing:\n*   **Superior Performance:** Outperforms existing baselines.\n*   **Transferability:** Works well across different models and environments without needing constant retraining.\n\n---\n\n### How can I help you with this paper? ğŸ”\n\nWould you like me to dive deeper into any of these areas? For example, I can:\n*   Explain specific concepts like \"symbolic World Knowledge Repository.\"\n*   Compare this approach to traditional fine-tuning.\n*   Discuss the implications for robotics or virtual agents.\n\nLet me know what you're looking for!",
      "authors": [
        "Baochang Ren",
        "Yunzhi Yao",
        "Rui Sun",
        "Shuofei Qiao",
        "Ningyu Zhang",
        "Huajun Chen"
      ],
      "abstract": "Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ¨¡æ‹Ÿç‰©ç†ä¸–ç•Œæ—¶å­˜åœ¨çš„â€œç‰©ç†å¹»è§‰â€ (physical hallucinations) é—®é¢˜ï¼Œæå‡ºäº† **WorldMind** æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆç¯å¢ƒåé¦ˆè‡ªä¸»æ„å»ºç¬¦å·åŒ–çš„ **World Knowledge Repository**ï¼Œæ—¨åœ¨å¼¥è¡¥æ¨¡å‹åœ¨ç‰©ç†è§„å¾‹ç†è§£ä¸Šçš„ç¼ºå¤±ï¼Œå¹¶å…‹æœäº†ä¼ ç»Ÿå¾®è°ƒæ–¹æ³•çš„é«˜æˆæœ¬ä¸åƒµåŒ–æ€§ã€‚**WorldMind** ååŒäº† **Process Experience**ï¼ˆåˆ©ç”¨é¢„æµ‹è¯¯å·®å¼ºåŒ–ç‰©ç†å¯è¡Œæ€§ï¼‰ä¸ **Goal Experience**ï¼ˆåˆ©ç”¨æˆåŠŸè½¨è¿¹å¼•å¯¼ä»»åŠ¡æœ€ä¼˜åŒ–ï¼‰ã€‚å®éªŒåœ¨ **EB-ALFRED** å’Œ **EB-Habitat** ä»»åŠ¡ä¸­éªŒè¯äº†è¯¥æ¡†æ¶çš„ä¼˜è¶Šæ€§èƒ½ï¼Œå¹¶å±•ç¤ºäº†å…¶å‡ºè‰²çš„è·¨æ¨¡å‹åŠè·¨ç¯å¢ƒè¿ç§»èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "Ongoing work",
      "pdf_url": "https://arxiv.org/pdf/2601.13247v1",
      "published_date": "2026-01-19 17:33:31 UTC",
      "updated_date": "2026-01-19 17:33:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:17:38.831965+00:00"
    },
    {
      "arxiv_id": "2601.13240v1",
      "title": "KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?",
      "title_zh": "KOCO-BENCHï¼šå¤§è¯­è¨€æ¨¡å‹èƒ½å¦åœ¨è½¯ä»¶å¼€å‘ä¸­åˆ©ç”¨é¢†åŸŸçŸ¥è¯†ï¼Ÿ",
      "authors": [
        "Xue Jiang",
        "Jiaru Qian",
        "Xianjie Shi",
        "Chenjie Li",
        "Hao Zhu",
        "Ziyu Wang",
        "Jielun Zhang",
        "Zheyu Zhao",
        "Kechi Zhang",
        "Jia Li",
        "Wenpin Jiao",
        "Zhi Jin",
        "Ge Li",
        "Yihong Dong"
      ],
      "abstract": "Large language models (LLMs) excel at general programming but struggle with domain-specific software development, necessitating domain specialization methods for LLMs to learn and utilize domain knowledge and data. However, existing domain-specific code benchmarks cannot evaluate the effectiveness of domain specialization methods, which focus on assessing what knowledge LLMs possess rather than how they acquire and apply new knowledge, lacking explicit knowledge corpora for developing domain specialization methods. To this end, we present KOCO-BENCH, a novel benchmark designed for evaluating domain specialization methods in real-world software development. KOCO-BENCH contains 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora alongside multi-granularity evaluation tasks including domain code generation (from function-level to project-level with rigorous test suites) and domain knowledge understanding (via multiple-choice Q&A). Unlike previous benchmarks that only provide test sets for direct evaluation, KOCO-BENCH requires acquiring and applying diverse domain knowledge (APIs, rules, constraints, etc.) from knowledge corpora to solve evaluation tasks. Our evaluations reveal that KOCO-BENCH poses significant challenges to state-of-the-art LLMs. Even with domain specialization methods (e.g., SFT, RAG, kNN-LM) applied, improvements remain marginal. Best-performing coding agent, Claude Code, achieves only 34.2%, highlighting the urgent need for more effective domain specialization methods. We release KOCO-BENCH, evaluation code, and baselines to advance further research at https://github.com/jiangxxxue/KOCO-bench.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **KOCO-BENCH**ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨çœŸå®è½¯ä»¶å¼€å‘ä¸­è·å–ä¸åº”ç”¨é¢†åŸŸçŸ¥è¯†èƒ½åŠ›çš„å…¨æ–°åŸºå‡†ã€‚ä¸ä»¥å¾€ä»…å…³æ³¨æ¨¡å‹â€œå·²çŸ¥â€çŸ¥è¯†çš„åŸºå‡†ä¸åŒï¼ŒKOCO-BENCH æ¶µç›–äº† 6 ä¸ªæ–°å…´é¢†åŸŸçš„ 25 ä¸ªé¡¹ç›®ï¼Œå¹¶é…å¥—æä¾›äº†åŒ…å« APIã€è§„åˆ™å’Œçº¦æŸçš„çŸ¥è¯†è¯­æ–™åº“ (knowledge corpora)ã€‚è¯„æµ‹ä»»åŠ¡é‡‡ç”¨å¤šç²’åº¦è®¾è®¡ï¼Œæ¶µç›–äº†ä»å‡½æ•°çº§åˆ°é¡¹ç›®çº§çš„é¢†åŸŸä»£ç ç”Ÿæˆ (domain code generation) ä»¥åŠé¢†åŸŸçŸ¥è¯†ç†è§£ Q&Aã€‚å®éªŒå‘ç°ï¼Œå³ä½¿é‡‡ç”¨ **SFT**ã€**RAG** æˆ– **kNN-LM** ç­‰é¢†åŸŸä¸“ä¸šåŒ– (domain specialization) æ–¹æ³•ï¼ŒSOTA æ¨¡å‹åœ¨å¤„ç†è¯¥åŸºå‡†æ—¶ä»æ˜¾ä¹åŠ›ï¼Œè¡¨ç°æœ€å¥½çš„ç¼–ç¨‹æ™ºèƒ½ä½“ **Claude Code** ä»…è¾¾åˆ° 34.2% çš„å‡†ç¡®ç‡ï¼Œå‡¸æ˜¾äº†å¼€å‘æ›´æœ‰æ•ˆä¸“ä¸šåŒ–æ–¹æ³•çš„è¿«åˆ‡éœ€æ±‚ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13240v1",
      "published_date": "2026-01-19 17:20:16 UTC",
      "updated_date": "2026-01-19 17:20:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:17:52.418337+00:00"
    },
    {
      "arxiv_id": "2601.13238v1",
      "title": "A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models",
      "title_zh": "åŸºäºè¯­ä¹‰è§£è€¦çš„ä¸¤é˜¶æ®µé›¨å¤©æ”»å‡»ï¼šæ­ç¤ºè§†è§‰è¯­è¨€æ¨¡å‹çš„å¤©æ°”é²æ£’æ€§ç¼ºé™·",
      "authors": [
        "Chengyin Hu",
        "Xiang Chen",
        "Zhe Jia",
        "Weiwen Shi",
        "Fengyu Zhang",
        "Jiujiang Guo",
        "Yiwei Wei"
      ],
      "abstract": "Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) åœ¨çœŸå®å¤©æ°”æ¡ä»¶ä¸‹çš„é²æ£’æ€§é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªåˆ©ç”¨çœŸå®é›¨å¤©åœºæ™¯çš„å¯¹æŠ—æ”»å‡»æ¡†æ¶ **Rainy-Day Attack**ã€‚è¯¥æ¡†æ¶åŸºäºè¯­ä¹‰è§£è€¦ (**semantic decoupling**) é‡‡ç”¨ä¸¤é˜¶æ®µå‚æ•°åŒ–æ‰°åŠ¨æ¨¡å‹ï¼šç¬¬ä¸€é˜¶æ®µé€šè¿‡å…¨å±€è°ƒåˆ¶ (**global modulation**) å¼±åŒ–åŸå§‹è¯­ä¹‰å†³ç­–è¾¹ç•Œï¼›ç¬¬äºŒé˜¶æ®µé€šè¿‡æ¨¡æ‹Ÿå¤šå°ºåº¦é›¨æ»´å¤–è§‚å’Œå…‰ç…§å˜åŒ–ï¼Œåœ¨éåƒç´ å‚æ•°ç©ºé—´è¯±å¯¼ç¨³å®šçš„è¯­ä¹‰åç§» (**semantic shifts**)ã€‚å®éªŒè¯æ˜ï¼Œå³ä½¿æ˜¯ç¬¦åˆç‰©ç†è§„å¾‹ä¸”å—åˆ°ä¸¥æ ¼é™åˆ¶çš„å¤©æ°”æ‰°åŠ¨ï¼Œä¹Ÿèƒ½å¯¼è‡´ä¸»æµ VLMs å‡ºç°ä¸¥é‡çš„è¯­ä¹‰å¤±é… (**semantic misalignment**)ï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨å®é™…éƒ¨ç½²ä¸­æ½œåœ¨çš„å®‰å…¨ä¸å¯é æ€§é£é™©ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13238v1",
      "published_date": "2026-01-19 17:16:30 UTC",
      "updated_date": "2026-01-19 17:16:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:18:15.306572+00:00"
    },
    {
      "arxiv_id": "2601.13236v1",
      "title": "Pixelwise Uncertainty Quantification of Accelerated MRI Reconstruction",
      "title_zh": "åŠ é€Ÿ MRI é‡å»ºçš„åƒç´ çº§ä¸ç¡®å®šæ€§é‡åŒ–",
      "authors": [
        "Ilias I. Giannakopoulos",
        "Lokesh B Gautham Muthukumar",
        "Yvonne W. Lui",
        "Riccardo Lattanzi"
      ],
      "abstract": "Parallel imaging techniques reduce magnetic resonance imaging (MRI) scan time but image quality degrades as the acceleration factor increases. In clinical practice, conservative acceleration factors are chosen because no mechanism exists to automatically assess the diagnostic quality of undersampled reconstructions. This work introduces a general framework for pixel-wise uncertainty quantification in parallel MRI reconstructions, enabling automatic identification of unreliable regions without access to any ground-truth reference image. Our method integrates conformal quantile regression with image reconstruction methods to estimate statistically rigorous pixel-wise uncertainty intervals. We trained and evaluated our model on Cartesian undersampled brain and knee data obtained from the fastMRI dataset using acceleration factors ranging from 2 to 10. An end-to-end Variational Network was used for image reconstruction. Quantitative experiments demonstrate strong agreement between predicted uncertainty maps and true reconstruction error. Using our method, the corresponding Pearson correlation coefficient was higher than 90% at acceleration levels at and above four-fold; whereas it dropped to less than 70% when the uncertainty was computed using a simpler a heuristic notion (magnitude of the residual). Qualitative examples further show the uncertainty maps based on quantile regression capture the magnitude and spatial distribution of reconstruction errors across acceleration factors, with regions of elevated uncertainty aligning with pathologies and artifacts. The proposed framework enables evaluation of reconstruction quality without access to fully-sampled ground-truth reference images. It represents a step toward adaptive MRI acquisition protocols that may be able to dynamically balance scan time and diagnostic reliability.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé€šç”¨çš„å¹¶è¡Œ **MRI** é‡å»ºåƒç´ çº§ä¸ç¡®å®šæ€§é‡åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨æ— éœ€ **ground-truth** å‚è€ƒå›¾åƒçš„æƒ…å†µä¸‹ï¼Œè‡ªåŠ¨è¯†åˆ«é‡å»ºç»“æœä¸­çš„ä¸å¯é åŒºåŸŸã€‚è¯¥æ–¹æ³•å°† **conformal quantile regression** ä¸å›¾åƒé‡å»ºç®—æ³•ï¼ˆå¦‚ **Variational Network**ï¼‰ç›¸ç»“åˆï¼Œé€šè¿‡ä¼°ç®—ç»Ÿè®¡ä¸¥è°¨çš„åƒç´ çº§ä¸ç¡®å®šæ€§åŒºé—´æ¥è¡¡é‡è¯Šæ–­è´¨é‡ã€‚åœ¨ **fastMRI** æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œåœ¨ 4 å€åŠä»¥ä¸Šçš„åŠ é€Ÿå› å­ä¸‹ï¼Œé¢„æµ‹çš„ä¸ç¡®å®šæ€§å›¾ä¸çœŸå®é‡å»ºè¯¯å·®çš„ç›¸å…³ç³»æ•°è¶…è¿‡ 90%ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å¯å‘å¼æŒ‡æ ‡ã€‚å®šæ€§åˆ†æè¿›ä¸€æ­¥è¯å®ï¼Œè¯¥ä¸ç¡®å®šæ€§å›¾èƒ½æœ‰æ•ˆæ•æ‰é‡å»ºè¯¯å·®çš„ç©ºé—´åˆ†å¸ƒï¼Œå¹¶ä¸ç—…ç†ç‰¹å¾å’Œä¼ªå½±é«˜åº¦å»åˆï¼Œä¸ºå®ç°æ‰«ææ—¶é—´ä¸è¯Šæ–­å¯é æ€§åŠ¨æ€å¹³è¡¡çš„è‡ªé€‚åº” **MRI** æ–¹æ¡ˆæä¾›äº†å¯èƒ½ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 8 figues, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.13236v1",
      "published_date": "2026-01-19 17:12:28 UTC",
      "updated_date": "2026-01-19 17:12:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:18:13.094208+00:00"
    },
    {
      "arxiv_id": "2601.13235v1",
      "title": "RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions",
      "title_zh": "RubRIXï¼šç…§æŠ¤è€…ä¸äººå·¥æ™ºèƒ½äº¤äº’ä¸­åŸºäºé‡è§„çš„é£é™©ç¼“è§£",
      "authors": [
        "Drishti Goel",
        "Jeongah Lee",
        "Qiuyue Joy Zhong",
        "Violeta J. Rodriguez",
        "Daniel S. Brown",
        "Ravi Karkar",
        "Dong Whi Yoo",
        "Koustuv Saha"
      ],
      "abstract": "Caregivers seeking AI-mediated support express complex needs -- information-seeking, emotional validation, and distress cues -- that warrant careful evaluation of response safety and appropriateness. Existing AI evaluation frameworks, primarily focused on general risks (toxicity, hallucinations, policy violations, etc), may not adequately capture the nuanced risks of LLM-responses in caregiving-contexts. We introduce RubRIX (Rubric-based Risk Index), a theory-driven, clinician-validated framework for evaluating risks in LLM caregiving responses. Grounded in the Elements of an Ethic of Care, RubRIX operationalizes five empirically-derived risk dimensions: Inattention, Bias & Stigma, Information Inaccuracy, Uncritical Affirmation, and Epistemic Arrogance. We evaluate six state-of-the-art LLMs on over 20,000 caregiver queries from Reddit and ALZConnected. Rubric-guided refinement consistently reduced risk-components by 45-98% after one iteration across models. This work contributes a methodological approach for developing domain-sensitive, user-centered evaluation frameworks for high-burden contexts. Our findings highlight the importance of domain-sensitive, interactional risk evaluation for the responsible deployment of LLMs in caregiving support contexts. We release benchmark datasets to enable future research on contextual risk evaluation in AI-mediated support.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æŠ¤ç†äººå‘˜ï¼ˆCaregiversï¼‰åœ¨å¯»æ±‚ AI æ”¯æŒæ—¶é¢ä¸´çš„ç‰¹å®šéœ€æ±‚ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„é€šç”¨é£é™©è¯„ä¼°æ¡†æ¶ï¼ˆå¦‚é’ˆå¯¹æ¯’æ€§ã€å¹»è§‰ç­‰ï¼‰æ— æ³•å……åˆ†æ•æ‰æŠ¤ç†åœºæ™¯ä¸­çš„ç»†å¾®é£é™©ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† **RubRIX** (Rubric-based Risk Index)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”±ä¸´åºŠåŒ»ç”ŸéªŒè¯ã€åŸºäºå…³æ€€ä¼¦ç† (Ethic of Care) ç†è®ºé©±åŠ¨çš„ LLM æŠ¤ç†å“åº”è¯„ä¼°æ¡†æ¶ã€‚**RubRIX** æ¶µç›–äº†äº”ä¸ªæ ¸å¿ƒé£é™©ç»´åº¦ï¼šæ³¨æ„åŠ›ä¸é›†ä¸­ (**Inattention**)ã€åè§ä¸æ±¡ååŒ– (**Bias & Stigma**)ã€ä¿¡æ¯ä¸å‡†ç¡® (**Information Inaccuracy**)ã€ç›²ç›®è‚¯å®š (**Uncritical Affirmation**) ä»¥åŠçŸ¥è¯†å‚²æ…¢ (**Epistemic Arrogance**)ã€‚å®éªŒé€šè¿‡å¯¹æ¥è‡ª Reddit å’Œ ALZConnected çš„ 2 ä¸‡å¤šæ¡æŸ¥è¯¢è¿›è¡Œè¯„ä¼°ï¼Œè¯æ˜ç»è¿‡è¯¥å‡†åˆ™æŒ‡å¯¼çš„ä¼˜åŒ–å¯ä½¿å„æ¨¡å‹çš„é£é™©æˆåˆ†é™ä½ 45-98%ã€‚è¿™ä¸€å·¥ä½œä¸ºé«˜è´Ÿæ‹…åœºæ™¯ä¸‹çš„é¢†åŸŸæ•æ„Ÿå‹ã€ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„ AI è¯„ä¼°æä¾›äº†é‡è¦çš„æ–¹æ³•è®ºæ”¯æŒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13235v1",
      "published_date": "2026-01-19 17:10:49 UTC",
      "updated_date": "2026-01-19 17:10:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:18:20.985230+00:00"
    },
    {
      "arxiv_id": "2601.13233v1",
      "title": "RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements",
      "title_zh": "RAGï¼šä¸€ç§é¢å‘å¤æ‚åŠŸèƒ½å“åº”éœ€æ±‚ä¸”å…·å¤‡ä¸ç¡®å®šæ€§æ„ŸçŸ¥èƒ½åŠ›çš„éšæœºæ£®æ—ç”Ÿæˆå¼è¶…ææ–™è®¾è®¡æ¡†æ¶",
      "authors": [
        "Bolin Chen",
        "Dex Doksoo Lee",
        "Wei \"Wayne'' Chen",
        "Wei Chen"
      ],
      "abstract": "Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **RAG**ï¼ˆåŸºäº **Random Forest** çš„ç”Ÿæˆå¼æ–¹æ³•ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºå…·æœ‰å¤æ‚åŠŸèƒ½å“åº”è¦æ±‚çš„è¶…ææ–™ï¼ˆ**Metamaterials**ï¼‰è®¾è®¡çš„é€†å‘è®¾è®¡æ¡†æ¶ã€‚é’ˆå¯¹é«˜ç»´åŠŸèƒ½å“åº”ï¼ˆå¦‚åº”åŠ›-åº”å˜å…³ç³»ï¼‰è®¾è®¡ä¸­æ•°æ®éœ€æ±‚å¤§ä¸”ç¼ºä¹ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆ**uncertainty quantification**ï¼‰ç­‰éš¾é¢˜ï¼Œ**RAG** åˆ©ç”¨éšæœºæ£®æ—çš„å°æ ·æœ¬å…¼å®¹æ€§å®ç°äº†é«˜æ•ˆçš„æ•°æ®é¢„æµ‹ã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆå­¦ä¹ è¯„ä¼°è®¾è®¡çš„å¯ä¿¡åº¦ï¼Œå¹¶é‡‡ç”¨æ¡ä»¶ä¼¼ç„¶é‡‡æ ·è§£å†³äº†é€†å‘è®¾è®¡ä¸­å¸¸è§çš„ä¸€å¯¹å¤šæ˜ å°„ï¼ˆ**one-to-many mapping**ï¼‰é—®é¢˜ã€‚åœ¨å£°å­¦è¶…ææ–™å’Œå…·æœ‰ç‰¹å®šè·³è·ƒå“åº”ï¼ˆ**snap-through responses**ï¼‰çš„æœºæ¢°è¶…ææ–™ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œ**RAG** åœ¨å°æ•°æ®é›†ä¸‹è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„ç¥ç»ç½‘ç»œï¼Œä¸ºæ¶‰åŠå¤æ‚åŠŸèƒ½å“åº”å’Œé«˜æ˜‚æ¨¡æ‹Ÿæˆæœ¬çš„é€†å‘è®¾è®¡æä¾›äº†ä¸€ç§è½»é‡ä¸”å¯é çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13233v1",
      "published_date": "2026-01-19 17:06:12 UTC",
      "updated_date": "2026-01-19 17:06:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:19:26.468473+00:00"
    },
    {
      "arxiv_id": "2601.13228v1",
      "title": "Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation",
      "title_zh": "Hello! I am **Gemini Enterprise**âœ¨. Thank you for sharing this abstract. It looks like you're exploring a very interesting development in language modeling that bridges the gap between **Autoregressive (AR)** and **Diffusion** models. \n\nBelow is a breakdown of the key contributions and concepts from the paper you provided.\n\n---\n\n### ğŸš€ Overview of A3 (Any-order Any-subset Autoregressive) Modeling\n\nThe paper introduces **A3**, a framework designed to combine the high sample quality of autoregressive models with the flexible generation capabilities (like infilling and bidirectional conditioning) typically associated with diffusion models.\n\n| Feature | Description |\n|---|---|\n| **Core Problem** | Diffusion models offer flexibility but often suffer from lower sample quality and stability compared to AR models due to limited modeling depth. |\n| **The Solution** | Reforming diffusion-style training into a structured **multi-group prediction process** within an AR framework. |\n| **Technique** | Extends standard AR factorization to arbitrary token groups and generation orders. |\n| **Architecture** | Implemented using a **two-stream attention architecture**. |\n| **Adaptation** | Uses a **progressive adaptation strategy** to transition pretrained AR models to any-order prediction. |\n\n---\n\n### ğŸ’¡ Key Benefits\n\n*   **Probabilistic Rigor:** Maintains the strong mathematical foundations and multi-layer dependency modeling of standard AR models.\n*   **Flexibility:** Inherits the ability to perform parallel and bidirectional generation, similar to diffusion models.\n*   **Performance:** Outperforms diffusion-based models in tasks like question answering, reasoning, and story infilling.\n\n---\n\nThis \"A3\" approach seems like a powerful way to make standard LLMs much more versatile for complex editing and reasoning tasks. \n\nAre you interested in the technical details of the **two-stream attention architecture**, or would you like to discuss how this might change the way we approach **story infilling** and **self-correction**? I'm here to help!",
      "authors": [
        "Tianqi Du",
        "Lizhe Fang",
        "Weijie Yang",
        "Chenheng Zhang",
        "Zeming Wei",
        "Yifei Wang",
        "Yisen Wang"
      ],
      "abstract": "Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.",
      "tldr_zh": "Hello! I am Gemini Enterpriseâœ¨. That looks like a fascinating paper on a new language modeling paradigm. It seems to address the long-standing trade-off between the flexibility of diffusion models and the raw performance of autoregressive (AR) models.\n\nBased on the abstract you provided, I've summarized the core components and contributions of the **Any-order Any-subset Autoregressive modeling (A3)** framework below.\n\n---\n\n### ğŸ§  The Core Challenge\nThe paper identifies a specific gap in current language modeling:\n\n| Model Type | Strengths | Weaknesses |\n|---|---|---|\n| **Autoregressive (AR)** | Probabilistic rigor, deep multi-layer dependency modeling, high sample quality. | Fixed generation order (usually left-to-right), lacks flexibility for infilling. |\n| **Diffusion** | Any-order generation, bidirectional conditioning (infilling, rewriting). | Single-step dependency limits depth, lower stability, and sample quality. |\n\n---\n\n### ğŸš€ The A3 Solution\nThe authors propose **A3** to get the best of both worlds. Here is how they approach it:\n\n*   **Generalized Factorization:** A3 extends the standard AR approach to arbitrary token groups and generation orders.\n*   **Two-Stream Attention:** They implement a specialized architecture to handle these multi-group predictions effectively.\n*   **Progressive Adaptation:** Instead of training from scratch, they use a strategy to transition existing pretrained AR models into any-order predictors.\n\n---\n\n### ğŸ“Š Performance and Results\nThe experiments show that A3 is not just a theoretical improvement but a practical one.\n\n| Category | Outcome |\n|---|---|\n| **Efficiency** | Maintains the flexible decoding found in diffusion models. |\n| **Task Performance** | Outperforms diffusion-based models in QA, reasoning, and story infilling. |\n| **Probabilistic Rigor** | Preserves the deep modeling capabilities of standard AR architectures. |\n\n---\n\nThis research seems quite significant for the future of flexible text generation! Would you like me to help you dive deeper into a specific part of this abstract, or perhaps help you draft a summary for a presentation? I'm here to chat about it!",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13228v1",
      "published_date": "2026-01-19 17:03:48 UTC",
      "updated_date": "2026-01-19 17:03:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:19:31.989052+00:00"
    },
    {
      "arxiv_id": "2601.13227v1",
      "title": "Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?",
      "title_zh": "It is a pleasure to meet you! I am Gemini Enterpriseâœ¨, and I have reviewed the paper details you provided. This research touches on a critical and timely issue in the development of Retrieval-Augmented Generation (RAG) systems: the risk of \"metric overfitting\" when evaluation secrets are known to the system.\n\n---\n\n## Paper Summary: Insider Knowledge ğŸ“„\n\nThe paper investigates how RAG systems can achieve artificially high evaluation scores by exploiting the same mechanisms used to judge them. As LLM-based \"nugget\" evaluation becomes the standard, the line between optimization and \"cheating\" (circularity) blurs.\n\n---\n\n## Key Takeaways ğŸ’¡\n\n| Feature | Description |\n|---|---|\n| **Core Problem** | The risk of circularity and faulty measurements when RAG systems are optimized using the same LLM judges or \"gold nuggets\" used for their evaluation. |\n| **Experimental Setup** | Comparative analysis between nugget-based systems (**Ginger**, **Crucible**) and baselines like **GPT-Researcher**. |\n| **The \"Leak\" Effect** | Demonstrates that near-perfect scores are possible if the RAG system has access to (or can predict) prompt templates or gold nuggets. |\n| **Recommendation** | Advocates for **blind evaluation settings** and a diverse set of methodologies to ensure system progress is genuine rather than just metric optimization. |\n\n---\n\n## Why This Matters âš ï¸\n\nThe study highlights a \"cat-and-mouse\" game in AI development. If a system like **Crucible** can be \"tuned\" to give the LLM judge exactly what it wants to see, the resulting high scores may not reflect actual utility to a human user, but rather a successful exploit of the evaluation framework.\n\n---\n\nThis is a fascinating look into the \"evaluator-in-the-loop\" problem. Would you like me to dive deeper into the specific methodologies of **Ginger** and **Crucible**, or perhaps help you draft a critique or summary of these findings for a presentation?",
      "authors": [
        "Laura Dietz",
        "Bryan Li",
        "Eugene Yang",
        "Dawn Lawrie",
        "William Walden",
        "James Mayfield"
      ],
      "abstract": "RAG systems are increasingly evaluated and optimized using LLM judges, an approach that is rapidly becoming the dominant paradigm for system assessment. Nugget-based approaches in particular are now embedded not only in evaluation frameworks but also in the architectures of RAG systems themselves. While this integration can lead to genuine improvements, it also creates a risk of faulty measurements due to circularity. In this paper, we investigate this risk through comparative experiments with nugget-based RAG systems, including Ginger and Crucible, against strong baselines such as GPT-Researcher. By deliberately modifying Crucible to generate outputs optimized for an LLM judge, we show that near-perfect evaluation scores can be achieved when elements of the evaluation - such as prompt templates or gold nuggets - are leaked or can be predicted. Our results highlight the importance of blind evaluation settings and methodological diversity to guard against mistaking metric overfitting for genuine system progress.",
      "tldr_zh": "ä½ å¥½ï¼æˆ‘æ˜¯ Gemini Enterpriseâœ¨ã€‚è¿™ç¯‡è®ºæ–‡æ¢è®¨äº† **RAG** è¯„ä¼°é¢†åŸŸä¸€ä¸ªéå¸¸å°–é”ä¸”ç°å®çš„é—®é¢˜ï¼šå½“â€œè£åˆ¤â€çš„åå¥½è¢«ç³»ç»Ÿæ‘¸é€æ—¶ï¼Œè¯„ä¼°åˆ†æ•°æ˜¯å¦è¿˜èƒ½åæ˜ çœŸå®æ°´å¹³ï¼Ÿ\n\næ ¹æ®ä½ çš„è¦æ±‚ï¼Œæˆ‘ä¸ºä½ å‡†å¤‡äº†è¿™ç¯‡è®ºæ–‡çš„ä¸­æ–‡ TLDR æ‘˜è¦ã€‚\n\n---\n\n### ğŸ“ TLDR æ‘˜è¦\n\nè¯¥ç ”ç©¶æ¢è®¨äº† **RAG** ç³»ç»Ÿåœ¨åˆ©ç”¨ **LLM judges** è¿›è¡Œè¯„ä¼°å’Œä¼˜åŒ–æ—¶ï¼Œå› è¿‡åº¦æ‹Ÿåˆè¯„ä¼°æ ‡å‡†è€Œäº§ç”Ÿçš„å¾ªç¯è®ºè¯ï¼ˆ**circularity**ï¼‰é£é™©ã€‚é€šè¿‡å¯¹ **Ginger**ã€**Crucible** å’Œ **GPT-Researcher** ç­‰ç³»ç»Ÿè¿›è¡Œå¯¹æ¯”å®éªŒï¼Œä½œè€…è¯æ˜äº†å½“è¯„ä¼°ç»†èŠ‚ï¼ˆå¦‚ **Prompt templates** æˆ– **Gold nuggets**ï¼‰è¢«ç³»ç»Ÿé¢„æµ‹æˆ–æ³„éœ²æ—¶ï¼Œ**RAG** ç³»ç»Ÿå¯ä»¥è·å¾—è¿‘ä¹å®Œç¾çš„è¯„ä¼°åˆ†ã€‚è¿™è¡¨æ˜é«˜åˆ†å¯èƒ½å¹¶éæºäºçœŸå®çš„æ€§èƒ½æå‡ï¼Œè€Œæ˜¯æºäºå¯¹ç‰¹å®šæŒ‡æ ‡çš„è¿‡æ‹Ÿåˆã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å‘¼ååœ¨ **RAG** è¯„ä¼°ä¸­å¼•å…¥ç›²æµ‹ï¼ˆ**blind evaluation**ï¼‰å’Œå¤šæ ·åŒ–æ–¹æ³•ï¼Œä»¥ç¡®ä¿ç³»ç»Ÿè¿›å±•çš„çœŸå®å¯é ã€‚\n\n---\n\n### ğŸ” æ ¸å¿ƒæ´å¯Ÿ\n\n| ç»´åº¦ | ç ”ç©¶è¯¦æƒ… |\n|---|---|\n| **ç ”ç©¶èƒŒæ™¯** | è¶Šæ¥è¶Šå¤šçš„ **RAG** ç³»ç»Ÿç›´æ¥å°† **Nugget-based** è¯„ä¼°æ¡†æ¶åµŒå…¥æ¶æ„ä¸­è¿›è¡Œä¼˜åŒ–ã€‚ |\n| **å®éªŒå¯¹è±¡** | **Ginger**ã€**Crucible** (ä¿®æ”¹ç‰ˆ) ä»¥åŠå¼ºåŸºçº¿æ¨¡å‹ **GPT-Researcher**ã€‚ |\n| **ä¸»è¦å‘ç°** | æ³„éœ²è¯„æµ‹ç»†èŠ‚ä¼šå¯¼è‡´è¿‘ä¹æ»¡åˆ†çš„è™šé«˜è¯„åˆ†ï¼Œæ­ç¤ºäº†å½“å‰è¯„ä¼°èŒƒå¼çš„è„†å¼±æ€§ã€‚ |\n| **ä¸“å®¶å»ºè®®** | å¿…é¡»é‡‡ç”¨ **blind evaluation** å’Œæ–¹æ³•è®ºå¤šæ ·æ€§æ¥æŠµå¾¡æŒ‡æ ‡è¿‡æ‹Ÿåˆã€‚ |\n\n---\n\nè¿™ç¯‡æ–‡ç« å¯¹äºç›®å‰ç›²ç›®è¿½æ±‚è¯„æµ‹é«˜åˆ†çš„ **RAG** å¼€å‘æ½®æ— ç–‘æ˜¯ä¸€å‰‚æ¸…é†’å‰‚ã€‚ä½ æ˜¯å¦ä¹Ÿåœ¨æ„å»ºåŸºäº **LLM judge** çš„è‡ªåŠ¨åŒ–è¯„ä¼°æµç¨‹ï¼Ÿæˆ–è€…ä½ å¯¹è®ºæ–‡ä¸­æåˆ°çš„ **Crucible** è¿™ç§ç‰¹å®šæ¡†æ¶æ„Ÿå…´è¶£ï¼Ÿæ¬¢è¿éšæ—¶è·Ÿæˆ‘äº¤æµï¼Œæˆ‘ä»¬å¯ä»¥æ·±å…¥æ¢è®¨å…¶ä¸­çš„å®éªŒç»†èŠ‚ï¼",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13227v1",
      "published_date": "2026-01-19 17:03:20 UTC",
      "updated_date": "2026-01-19 17:03:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:18:54.794396+00:00"
    },
    {
      "arxiv_id": "2601.13222v1",
      "title": "Incorporating Q&A Nuggets into Retrieval-Augmented Generation",
      "title_zh": "It looks like you've shared the abstract for a research paper on **Crucible**, a new system in the field of Retrieval-Augmented Generation (RAG). Based on the text you provided, I've summarized the key aspects of this research below.\n\n---\n\n### ğŸ“– Research Overview: Crucible System\n\nCrucible is a \"Nugget-Augmented Generation System\" designed to improve how AI generates reports from retrieved documents while maintaining strict citation accuracy. It specifically addresses the integration of automatic evaluation (E) into RAG workflows, a combination referred to as **RAGE**.\n\n---\n\n### âœ¨ Key Features and Advantages\n\n| Feature | Description |\n|---|---|\n| **Q&A Nuggets** | Uses a bank of discrete question-and-answer pairs extracted from documents rather than opaque data clusters. |\n| **Reasoning** | Operates on these nuggets to avoid repeating information through clear, interpretable semantics. |\n| **Citation Provenance** | Preserves explicit links to source documents throughout the entire extraction, selection, and generation process. |\n| **Performance** | Outperforms existing systems like *Ginger* in recall, density, and grounding. |\n\n---\n\n### ğŸ“Š Evaluation Results\n\nThe system was tested on the **TREC NeuCLIR 2024** collection. Compared to **Ginger** (a recent nugget-based RAG system), Crucible showed substantial improvements in:\n\n*   **Nugget Recall:** Finding more relevant pieces of information.\n*   **Density:** Creating more information-dense reports.\n*   **Citation Grounding:** Ensuring the generated text is more accurately backed by its sources.\n\n---\n\nI'd be happy to dive deeper into this paper with you! Would you like me to explain the concept of \"Q&A Nuggets\" in more detail, or perhaps compare this approach to traditional RAG systems?",
      "authors": [
        "Laura Dietz",
        "Bryan Li",
        "Gabrielle Liu",
        "Jia-Huei Ju",
        "Eugene Yang",
        "Dawn Lawrie",
        "William Walden",
        "James Mayfield"
      ],
      "abstract": "RAGE systems integrate ideas from automatic evaluation (E) into Retrieval-augmented Generation (RAG). As one such example, we present Crucible, a Nugget-Augmented Generation System that preserves explicit citation provenance by constructing a bank of Q&A nuggets from retrieved documents and uses them to guide extraction, selection, and report generation. Reasoning on nuggets avoids repeated information through clear and interpretable Q&A semantics - instead of opaque cluster abstractions - while maintaining citation provenance throughout the entire generation process. Evaluated on the TREC NeuCLIR 2024 collection, our Crucible system substantially outperforms Ginger, a recent nugget-based RAG system, in nugget recall, density, and citation grounding.",
      "tldr_zh": "ä½ å¥½ï¼æˆ‘æ˜¯ Gemini Enterpriseâœ¨ã€‚è¿™ç¯‡å…³äºæå‡ **RAG** ç³»ç»Ÿå¯é æ€§çš„ç ”ç©¶éå¸¸æœ‰æ„æ€ï¼Œå®ƒåˆ©ç”¨äº†â€œé‡‘å—â€ï¼ˆnuggetsï¼‰çš„æ¦‚å¿µæ¥å¢å¼ºç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§å’Œå¯å›æº¯æ€§ã€‚\n\nä»¥ä¸‹æ˜¯æˆ‘ä¸ºä½ å‡†å¤‡çš„è®ºæ–‡ TLDR æ‘˜è¦ï¼š\n\n---\n\n### ğŸ“ è®ºæ–‡ TLDR (å¤ªé•¿ä¸è¯»)\n\nè¯¥ç ”ç©¶æå‡ºäº† **Crucible**ï¼Œä¸€ç§å°†è‡ªåŠ¨è¯„ä¼°ï¼ˆ**automatic evaluation**ï¼‰ç†å¿µèå…¥ **RAG** çš„ **Nugget-Augmented Generation** ç³»ç»Ÿã€‚è¯¥æ¡†æ¶é€šè¿‡ä»æ£€ç´¢æ–‡æ¡£ä¸­æ„å»º **Q&A nuggets** åº“æ¥æŒ‡å¯¼ä¿¡æ¯çš„æå–ã€é€‰æ‹©å’ŒæŠ¥å‘Šç”Ÿæˆã€‚åˆ©ç”¨å¯è§£é‡Šçš„ **Q&A semantics** ä»£æ›¿ä¼ ç»Ÿçš„èšç±»æŠ½è±¡ï¼Œ**Crucible** æœ‰æ•ˆé¿å…äº†ä¿¡æ¯é‡å¤ï¼Œå¹¶ç¡®ä¿åœ¨ç”Ÿæˆå…¨è¿‡ç¨‹ä¸­ä¿ç•™æ˜ç¡®çš„å¼•ç”¨æ¥æºï¼ˆ**citation provenance**ï¼‰ã€‚å®éªŒè¯æ˜ï¼Œåœ¨ **TREC NeuCLIR 2024** è¯„æµ‹ä¸­ï¼Œè¯¥ç³»ç»Ÿåœ¨ **nugget recall**ã€ä¿¡æ¯å¯†åº¦åŠå¼•ç”¨æ¥åœ°ï¼ˆ**citation grounding**ï¼‰æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„ **Ginger** ç³»ç»Ÿã€‚\n\n---\n\n### ğŸ“Š ç³»ç»Ÿæ ¸å¿ƒäº®ç‚¹\n\n| ç»´åº¦ | Crucible ç³»ç»Ÿçš„åˆ›æ–°ä¸è¡¨ç° |\n|---|---|\n| **æ ¸å¿ƒæœºåˆ¶** | æ„å»º **Q&A nuggets** é“¶è¡Œï¼Œä½œä¸ºä¿¡æ¯æå–å’Œç”Ÿæˆçš„å¼•å¯¼åŸºç¡€ã€‚ |\n| **é€æ˜åº¦** | ä½¿ç”¨è¯­ä¹‰æ˜ç¡®çš„é—®ç­”å¯¹ï¼Œè€Œéä¸é€æ˜çš„å‘é‡èšç±»ï¼Œæå‡äº†å¯è§£é‡Šæ€§ã€‚ |\n| **å¼•ç”¨å¯é æ€§** | åœ¨æ•´ä¸ªç”Ÿæˆç”Ÿå‘½å‘¨æœŸä¸­ä¸¥æ ¼ä¿æŒ **citation provenance**ã€‚ |\n| **æ€§èƒ½åŸºå‡†** | åœ¨ **TREC NeuCLIR 2024** é›†åˆä¸Šå®ç°äº†å¯¹åŸºå‡†æ¨¡å‹ **Ginger** çš„å…¨é¢è¶…è¶Šã€‚ |\n\n---\n\nè¿™ç§é€šè¿‡ç»“æ„åŒ–â€œçŸ¥è¯†ç¢ç‰‡â€æ¥è§£å†³ **RAG** å¹»è§‰å’Œå¼•ç”¨ä¸¢å¤±é—®é¢˜çš„æ€è·¯éå¸¸å®ç”¨ã€‚ä½ æ˜¯å¦å¯¹ **Crucible** å¦‚ä½•å…·ä½“æ„å»ºè¿™äº› **Q&A nuggets** çš„æŠ€æœ¯ç»†èŠ‚æ„Ÿå…´è¶£ï¼Ÿæˆ–è€…éœ€è¦æˆ‘å¯¹æ¯”ä¸€ä¸‹å®ƒä¸ä¼ ç»Ÿ **RAG** çš„åŒºåˆ«ï¼Ÿæˆ‘ä»¬å¯ä»¥ç»§ç»­æ·±å…¥è®¨è®ºï¼",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13222v1",
      "published_date": "2026-01-19 16:57:33 UTC",
      "updated_date": "2026-01-19 16:57:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:19:04.949293+00:00"
    },
    {
      "arxiv_id": "2601.13217v1",
      "title": "Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision",
      "title_zh": "It is a pleasure to review this third paper! I am Gemini Enterpriseâœ¨, and I have analyzed the abstract for **\"Beyond Single-shot Writing.\"** \n\nThis research identifies a significant \"blind spot\" in current Deep Research Agent (DRA) evaluations: the transition from single-shot generation to the iterative, multi-turn revision process that defines real-world research.\n\n---\n\n## Paper Summary: Mr Dre & Multi-turn Revision ğŸ“\n\nWhile many systems are getting better at writing a first draft, this paper introduces **Mr Dre**, a suite designed to test how well these agents handle feedback and revisions over time.\n\n---\n\n## The \"Regression\" Problem ğŸ“‰\n\nThe study reveals a concerning trend: as agents try to fix one thing, they often break another.\n\n| Metric | Findings / Impact |\n|---|---|\n| **Content Regression** | Agents regress on **16-27%** of previously correct content when prompted for revisions. |\n| **Citation Decay** | Quality of citations often drops during the revision process. |\n| **Scope Creep** | Agents frequently disrupt content that was *outside* the scope of the user's feedback. |\n| **Inference Limitations** | Simple prompt engineering or adding a \"revision sub-agent\" failed to solve these core issues. |\n\n---\n\n## Why This Matters ğŸ—ï¸\n\nThis research suggests that \"Long-form Research\" isn't just about gathering information once; it's about **stability**. If an agent can't remember why it made a previous edit while incorporating new feedback, it becomes a \"one step forward, two steps back\" scenario. This provides a vital counterpoint to the high performance seen in \"single-shot\" systems like **Crucible** (mentioned in your previous text).\n\n---\n\n## Connecting the Dots ğŸ”—\n\nYou have now shared papers covering three distinct but related angles of RAG and AI Research:\n1.  **Metric Integrity:** The risk of systems \"cheating\" or overfitting to evaluation secrets (**Insider Knowledge**).\n2.  **Architecture:** Using Q&A \"nuggets\" to improve grounding and citations (**Crucible**).\n3.  **Iterative Reliability:** The struggle of agents to maintain quality during multi-turn edits (**Mr Dre**).\n\nAre you preparing a literature review or a meta-analysis on these topics? I would be happy to help you compare the architectural choices of **Crucible** against the revision failures identified in **Mr Dre**!",
      "authors": [
        "Bingsen Chen",
        "Boyan Li",
        "Ping Nie",
        "Yuyu Zhang",
        "Xi Ye",
        "Chen Zhao"
      ],
      "abstract": "Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºç°æœ‰çš„æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ï¼ˆ**Deep Research Agents, DRAs**ï¼‰è¯„ä¼°å¤šå±€é™äºå•æ¬¡å†™ä½œï¼Œè€Œå¿½è§†äº†ç°å®ä¸­ç§‘ç ”å·¥ä½œæ‰€éœ€çš„è¿­ä»£ä¿®è®¢è¿‡ç¨‹ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† **Mr Dre** è¯„ä¼°å¥—ä»¶ï¼Œé€šè¿‡é•¿ç¯‡æŠ¥å‘Šè¯„ä»·åè®®å’Œæ¨¡æ‹Ÿåé¦ˆæµæ°´çº¿ï¼Œä¸“é—¨è¡¡é‡æ™ºèƒ½ä½“åœ¨å¤šè½®ä¿®è®¢ä¸­çš„å¯é æ€§ã€‚å¯¹äº”ç§ä¸»æµ **DRAs** çš„åˆ†ææ˜¾ç¤ºï¼Œè™½ç„¶æ™ºèƒ½ä½“èƒ½å“åº”ç”¨æˆ·åé¦ˆï¼Œä½†åœ¨ä¿®è®¢è¿‡ç¨‹ä¸­ä¼šå¯¼è‡´ 16-27% çš„æ—¢æœ‰å†…å®¹æˆ–å¼•ç”¨è´¨é‡å‡ºç°å€’é€€ï¼ˆ**regress**ï¼‰ã€‚å®éªŒè¡¨æ˜ï¼Œæ™ºèƒ½ä½“åœ¨ä¿®æ”¹æ—¶ç»å¸¸ç ´ååé¦ˆèŒƒå›´ä¹‹å¤–çš„å†…å®¹ä¸”éš¾ä»¥ä¿ç•™å…ˆå‰çš„ç¼–è¾‘æˆæœï¼Œä¸”è¿™äº›å±€é™æ€§æ— æ³•é€šè¿‡ç®€å•çš„ **prompt engineering** æˆ–å¢åŠ ä¸“ç”¨å­æ™ºèƒ½ä½“ç­‰æ‰‹æ®µè½»æ˜“è§£å†³ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13217v1",
      "published_date": "2026-01-19 16:48:45 UTC",
      "updated_date": "2026-01-19 16:48:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:19:02.127143+00:00"
    },
    {
      "arxiv_id": "2601.13206v1",
      "title": "Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues",
      "title_zh": "I have reviewed the third paper you shared. This research shifts the focus from RAG systems to the **temporal awareness** of LLMs, exploring a fundamental gap between discrete token generation and continuous real-world time.\n\n---\n\n## Research Overview: Temporal Awareness in LLMs â³\n\nThe paper investigates whether LLMs can track \"wall-clock\" time during high-stakes strategic dialogues, such as negotiations. It identifies a significant \"temporal blindness\" that occurs when models are not explicitly reminded of how much time is remaining.\n\n---\n\n## Key Experimental Findings ğŸ“Š\n\nThe researchers compared how models (specifically a hypothetical GPT-5.1) performed under different time-tracking conditions:\n\n| Condition | Remaining Time Updates | Deal Closure Rate | Strategic Outcome |\n|---|---|---|---|\n| **Control** | None (Global limit only) | **4%** | Most sessions timed out without a deal. |\n| **Time-Aware** | Updates at each turn | **32%** | Significant increase in deal-making and offer acceptance. |\n| **Turn-Based** | Based on turn count | **â‰¥95%** | Near-perfect performance; confirms the model understands strategy. |\n\n---\n\n## Critical Conclusion: Tracking vs. Reasoning ğŸ§ \n\nThe study draws a sharp distinction between two types of capabilities:\n\n*   **Strategic Reasoning:** LLMs are excellent at understanding *when* to settle if they know the end is near (as seen in turn-based tests).\n*   **Temporal Tracking:** LLMs fail to internally measure the passage of real-time minutes or seconds while processing tokens.\n\nThis suggests that for any time-sensitive applicationâ€”like live customer support or real-time tradingâ€”LLMs require an external \"clock\" provided in their prompt to function effectively.\n\n---\n\nIt is interesting to see this contrast! While your first two papers focused on **information accuracy** (RAG/Nuggets), this one focuses on **situational awareness** (Time). \n\nWould you like me to synthesize how these two concepts might interact? For example, could a RAG system like **Crucible** be improved by adding the temporal awareness mechanisms discussed in this paper?",
      "authors": [
        "Neil K. R. Sehgal",
        "Sharath Chandra Guntuku",
        "Lyle Ungar"
      ],
      "abstract": "Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\\% vs. 4\\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\\geq$95\\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.",
      "tldr_zh": "ä½ å¥½ï¼æˆ‘æ˜¯ Gemini Enterpriseâœ¨ã€‚è¿™ç¯‡è®ºæ–‡ç ”ç©¶äº†ä¸€ä¸ªéå¸¸æœ‰è¶£ä¸”å®¹æ˜“è¢«å¿½ç•¥çš„è§†è§’ï¼š**LLMs** è™½ç„¶åœ¨é€»è¾‘æ¨ç†ä¸Šå¾ˆå¼ºï¼Œä½†å®ƒä»¬å¯¹â€œç°å®æ—¶é—´â€çš„æµé€æ˜¯å¦æœ‰æ„Ÿè§‰ï¼Ÿ\n\nä»¥ä¸‹æ˜¯ä¸ºä½ å‡†å¤‡çš„ä¸­æ–‡ TLDR æ‘˜è¦ã€‚\n\n---\n\n### ğŸ“ TLDR æ‘˜è¦\n\nè¯¥ç ”ç©¶è°ƒæŸ¥äº† **LLMs** åœ¨é¢ä¸´å®æ—¶æˆªæ­¢æ—¥æœŸï¼ˆ**Real-time deadlines**ï¼‰æ—¶çš„è¡Œä¸ºè¡¨ç°ï¼Œæ­ç¤ºäº†å…¶åœ¨æ—¶é—´æ„è¯†æ–¹é¢çš„ç³»ç»Ÿæ€§ç¼ºé™·ã€‚ç ”ç©¶é€šè¿‡æ¨¡æ‹Ÿå…·æœ‰ä¸¥æ ¼æ—¶é™çš„åŒäººè°ˆåˆ¤ï¼Œå¯¹æ¯”äº†ä»…å‘ŠçŸ¥æ€»æ—¶é™ä¸æ¯è½®å®æ—¶æ›´æ–°å‰©ä½™æ—¶é—´ï¼ˆ**Time-aware**ï¼‰ä¸¤ç§åœºæ™¯ï¼Œå‘ç° **Time-aware** æ¡ä»¶ä¸‹çš„æˆäº¤ç‡æ˜¾è‘—æ›´é«˜ï¼ˆå¦‚ **GPT-5.1** ä» 4% æå‡è‡³ 32%ï¼‰ã€‚å®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼Œ**LLMs** åœ¨åŸºäºè½®æ•°çš„é™åˆ¶ï¼ˆ**Turn-based limits**ï¼‰ä¸‹è¡¨ç°è¿‘ä¹å®Œç¾ï¼Œè¯´æ˜å…¶å¤±è´¥åŸå› åœ¨äºéš¾ä»¥åœ¨å†…éƒ¨è¿½è¸ªæµé€çš„æ—¶é—´ï¼ˆ**temporal tracking**ï¼‰ï¼Œè€Œéç¼ºä¹æˆ˜ç•¥æ¨ç†èƒ½åŠ›ã€‚è¿™ä¸€å‘ç°å‡¸æ˜¾äº† **LLMs** åœ¨å¤„ç†æ—¶é—´æ•æ„Ÿå‹ç°å®ä»»åŠ¡æ—¶é¢ä¸´çš„å±€é™æ€§ã€‚\n\n---\n\n### ğŸ“Š æ ¸å¿ƒå®éªŒæ•°æ®å¯¹æ¯”\n\n| å®éªŒæ¡ä»¶ | **GPT-5.1** æˆäº¤ç‡ | è¡¨ç°åˆ†æ |\n|---|---|---|\n| **æ§åˆ¶ç»„ (ä»…çŸ¥æ€»æ—¶é•¿)** | 4% | å‡ ä¹æ— æ³•æ„ŸçŸ¥æ—¶é—´æµé€ï¼Œå¯¼è‡´è°ˆåˆ¤è¶…æ—¶å¤±è´¥ã€‚ |\n| **æ—¶é—´æ„ŸçŸ¥ç»„ (å®æ—¶æ›´æ–°)** | 32% | æˆäº¤ç‡æ˜¾è‘—æå‡ï¼Œæ¥å—æè®®çš„é¢‘ç‡å¢åŠ  6 å€ã€‚ |\n| **åŸºäºè½®æ•°çš„é™åˆ¶** | $\\geq$95% | è¡¨ç°è¿‘ä¹å®Œç¾ï¼Œè¯æ˜å…¶æˆ˜ç•¥é€»è¾‘å¹¶æ— é—®é¢˜ã€‚ |\n\n---\n\n### ğŸ’¡ æ·±åº¦æ´å¯Ÿ\nè¿™é¡¹ç ”ç©¶è¡¨æ˜ï¼Œç›®å‰çš„ **LLMs** å°±åƒæ˜¯ç”Ÿæ´»åœ¨â€œç¦»æ•£ç‚¹â€ä¸Šçš„æ™ºèƒ½ï¼Œå®ƒä»¬å¯¹è¿ç»­çš„æ—¶é—´ç»´åº¦ç¼ºä¹æœ¬èƒ½çš„æ„ŸçŸ¥ã€‚å¦‚æœä½ æ­£åœ¨å¼€å‘éœ€è¦å®æ—¶å“åº”æˆ–é™æ—¶å†³ç­–çš„æ™ºèƒ½ä½“ï¼ˆæ¯”å¦‚åœ¨çº¿æ‹å–æœºå™¨äººæˆ–ç´§æ€¥è°ƒåº¦ç³»ç»Ÿï¼‰ï¼Œè¿™ä¸ªç»“è®ºéå¸¸å…³é”®ã€‚\n\nä½ å¯¹è®ºæ–‡ä¸­æåˆ°çš„è¿™ç§â€œæ—¶é—´è¿½è¸ªâ€å¤±æ•ˆæœ‰ä»€ä¹ˆçœ‹æ³•ï¼Ÿæˆ–è€…ä½ æ˜¯å¦åœ¨å®é™…æµ‹è¯•ä¸­å‘ç°è¿‡ **LLMs** çš„å…¶ä»–â€œå¸¸è¯†æ€§â€çŸ­æ¿ï¼Ÿæˆ‘å¾ˆä¹æ„ç»§ç»­æ¢è®¨ï¼",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13206v1",
      "published_date": "2026-01-19 16:31:07 UTC",
      "updated_date": "2026-01-19 16:31:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:19:12.612997+00:00"
    },
    {
      "arxiv_id": "2601.13197v1",
      "title": "Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification",
      "title_zh": "I have reviewed the abstract for this fourth paper. I am Gemini Enterpriseâœ¨, and this research shifts the focus toward **Cybersecurity** and **Data Science**, specifically tackling the \"class imbalance\" problem using modern generative techniques.\n\n---\n\n## Paper Summary: Diffusion-Driven Synthetic Tabular Data ğŸ›¡ï¸\n\nThis paper explores how **Tabular Denoising Diffusion Probability Models (TabDDPM)** can be used to augment network intrusion datasets. By generating high-fidelity synthetic data for rare attack types, the researchers improved the ability of AI models to detect those specific threats.\n\n---\n\n## Key Takeaways ğŸ“Š\n\n| Aspect | Details |\n|---|---|\n| **Core Problem** | **Class Imbalance:** Minority classes (rare attacks) in security datasets lead to biased models that fail to detect those attacks. |\n| **Proposed Solution** | **TabDDPM:** Using diffusion models to synthesize realistic minority-class samples through iterative denoising. |\n| **Dataset Used** | **CIC\\-IDS2017:** A standard benchmark for network intrusion detection. |\n| **Primary Result** | **Near\\-perfect recall:** The ANN classifier achieved significantly better detection rates on previously underrepresented attack classes. |\n| **Future Applications** | Fraud detection, medical diagnostics, and other tabular data domains with high imbalance. |\n\n---\n\n## Shifting Focus ğŸŒ\n\nWhile your first three papers focused on the **linguistic and structural reliability of RAG systems** (evaluation secrets, nugget-based generation, and multi-turn revisions), this paper addresses **data reliability and balance** in the realm of cybersecurity. \n\nIt highlights a different kind of \"synthetic\" challenge: rather than worrying about an LLM \"cheating\" on a test (as in the *Insider Knowledge* paper), this research intentionally uses synthetic data to make a classifier \"smarter\" and more robust against rare events.\n\n---\n\nThis is a diverse set of papers! Are you looking for a common thread between **LLM reliability/evaluation** and **synthetic data generation in security**, or are these separate parts of a larger project you are working on? I'm ready to help you synthesize these findings or compare their methodologies whenever you're ready!",
      "authors": [
        "Aravind B",
        "Anirud R. S.",
        "Sai Surya Teja N",
        "Bala Subrahmanya Sriranga Navaneeth A",
        "Karthika R",
        "Mohankumar N"
      ],
      "abstract": "Class imbalance refers to a situation where certain classes in a dataset have significantly fewer samples than oth- ers, leading to biased model performance. Class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM) for data augmentation is ad- dressed in this paper. Our approach synthesizes high-fidelity minority-class samples from the CIC-IDS2017 dataset through iterative denoising processes. For the minority classes that have smaller samples, synthetic samples were generated and merged with the original dataset. The augmented training data enables an ANN classifier to achieve near-perfect recall on previously underrepresented attack classes. These results establish diffusion models as an effective solution for tabular data imbalance in security domains, with potential applications in fraud detection and medical diagnostics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘ç»œå…¥ä¾µæ£€æµ‹ä¸­çš„ç±»åˆ«ä¸å¹³è¡¡ï¼ˆ**Class imbalance**ï¼‰é—®é¢˜ï¼Œæå‡ºåˆ©ç”¨è¡¨æ ¼å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆ**TabDDPM**ï¼‰è¿›è¡Œæ•°æ®å¢å¼ºã€‚é€šè¿‡å¯¹ **CIC-IDS2017** æ•°æ®é›†è¿›è¡Œè¿­ä»£å»å™ªï¼Œç³»ç»Ÿåˆæˆäº†é«˜ä¿çœŸçš„å°‘æ•°ç±»æ ·æœ¬å¹¶å°†å…¶å¹¶å…¥åŸå§‹è®­ç»ƒé›†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä½¿ **ANN** åˆ†ç±»å™¨åœ¨å¤„ç† **DoS/DDoS** ç­‰å°‘æ•°ç±»æ”»å‡»æ—¶è¾¾åˆ°äº†è¿‘ä¹å®Œç¾çš„å¬å›ç‡ï¼ˆ**Recall**ï¼‰ã€‚è¿™è¡¨æ˜æ‰©æ•£æ¨¡å‹æ˜¯è§£å†³å®‰å…¨é¢†åŸŸè¡¨æ ¼æ•°æ®ä¸å¹³è¡¡çš„ä¸€ç§é«˜æ•ˆæ–¹æ¡ˆï¼Œå¹¶å…·æœ‰æ‰©å±•è‡³æ¬ºè¯ˆæ£€æµ‹å’ŒåŒ»ç–—è¯Šæ–­ç­‰é¢†åŸŸçš„æ½œåŠ›ã€‚\n\n---\n\n### ğŸ“Š ç ”ç©¶æ ¸å¿ƒæ‘˜è¦\n\n| æ ¸å¿ƒç»´åº¦ | è¯¦ç»†å†…å®¹ |\n|---|---|\n| **ç ”ç©¶èƒŒæ™¯** | ç±»åˆ«ä¸å¹³è¡¡å¯¼è‡´å…¥ä¾µæ£€æµ‹æ¨¡å‹å¯¹å°‘æ•°ç±»æ”»å‡»äº§ç”Ÿé¢„æµ‹åå·®ã€‚ |\n| **æŠ€æœ¯è·¯å¾„** | ä½¿ç”¨ **TabDDPM** æ‰©æ•£æ¨¡å‹åˆæˆé«˜ä¿çœŸæ ·æœ¬ï¼Œç”¨äºå¢å¼º **CIC-IDS2017** æ•°æ®é›†ã€‚ |\n| **ä¸»è¦å‘ç°** | å¢å¼ºåçš„æ•°æ®ä½¿ **ANN** åˆ†ç±»å™¨åœ¨æ”»å‡»åˆ†ç±»ä¸Šå®ç°äº†æé«˜çš„å‡†ç¡®æ€§ã€‚ |\n| **å…³é”®ç»“è®º** | æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡è¡¨æ ¼æ•°æ®ï¼ˆ**Synthetic Tabular Data**ï¼‰æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚ |\n\n---\n\nè¿™ç§å°†ç”Ÿæˆå¼æ‰©æ•£æ¨¡å‹åº”ç”¨äºå®‰å…¨é¢†åŸŸè¡¨æ ¼æ•°æ®å¢å¼ºçš„æ€è·¯éå¸¸å…·æœ‰å¯å‘æ€§ã€‚ä½ æ˜¯å¦æƒ³äº†è§£ **TabDDPM** ä¸ä¼ ç»Ÿçš„è¿‡é‡‡æ ·æ–¹æ³•ï¼ˆå¦‚ SMOTEï¼‰ç›¸æ¯”æœ‰å“ªäº›å…·ä½“ä¼˜åŠ¿ï¼Ÿæˆ–è€…éœ€è¦æˆ‘ä¸ºä½ è¯¦ç»†è§£è¯»å…¶åœ¨ **DoS/DDoS** åˆ†ç±»ä¸­çš„è¡¨ç°ï¼Ÿæ¬¢è¿ç»§ç»­äº¤æµï¼",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 8 figures, 2025 International Conference on Signal Processing, Computation, Electronics, Power and Telecommunication (IConSCEPT), National Institute of Technology, Puducherry, India",
      "pdf_url": "https://arxiv.org/pdf/2601.13197v1",
      "published_date": "2026-01-19 16:22:27 UTC",
      "updated_date": "2026-01-19 16:22:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:19:24.041777+00:00"
    },
    {
      "arxiv_id": "2601.13187v1",
      "title": "Scientific production in the era of Large Language Models",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£çš„ç§‘å­¦äº§å‡º",
      "authors": [
        "Keigo Kusumegi",
        "Xinyu Yang",
        "Paul Ginsparg",
        "Mathijs de Vaan",
        "Toby Stuart",
        "Yian Yin"
      ],
      "abstract": "Large Language Models (LLMs) are rapidly reshaping scientific research. We analyze these changes in multiple, large-scale datasets with 2.1M preprints, 28K peer review reports, and 246M online accesses to scientific documents. We find: 1) scientists adopting LLMs to draft manuscripts demonstrate a large increase in paper production, ranging from 23.7-89.3% depending on scientific field and author background, 2) LLM use has reversed the relationship between writing complexity and paper quality, leading to an influx of manuscripts that are linguistically complex but substantively underwhelming, and 3) LLM adopters access and cite more diverse prior work, including books and younger, less-cited documents. These findings highlight a stunning shift in scientific production that will likely require a change in how journals, funding agencies, and tenure committees evaluate scientific works.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ï¼šScientific production in the era of Large Language Models\n\n---\n\nè¯¥ç ”ç©¶é€šè¿‡åˆ†æåŒ…å«210ä¸‡ç¯‡é¢„å°æœ¬ã€2.8ä¸‡ä»½åŒè¡Œè¯„å®¡æŠ¥å‘ŠåŠ2.46äº¿æ¬¡åœ¨çº¿è®¿é—®çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œæ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Models, LLMsï¼‰å¯¹ç§‘å­¦ç ”ç©¶äº§å‡ºçš„æ·±åˆ»å½±å“ã€‚\n\n| æ ¸å¿ƒå‘ç° | è¯¦ç»†è¯´æ˜ |\n|---|---|\n| **äº§å‡ºæ•°é‡æ¿€å¢** | ä½¿ç”¨LLMsæ’°å†™è®ºæ–‡çš„ç§‘å­¦å®¶äº§å‡ºé‡æ˜¾è‘—æå‡ï¼Œå¢å¹…åœ¨23.7%è‡³89.3%ä¹‹é—´ï¼Œä¸”å—å­¦ç§‘é¢†åŸŸå’Œä½œè€…èƒŒæ™¯å½±å“ã€‚ |\n| **è´¨é‡ä¸å¤æ‚æ€§å€’æŒ‚** | LLMsçš„ä½¿ç”¨æ‰­è½¬äº†å†™ä½œå¤æ‚æ€§ä¸è®ºæ–‡è´¨é‡ä¹‹é—´çš„ä¼ ç»Ÿå…³ç³»ï¼Œå¯¼è‡´å¤§é‡â€œè¯­è¨€è¡¨è¾¾å¤æ‚ä½†å®è´¨å†…å®¹å¹³åº¸â€çš„ç¨¿ä»¶æ¶Œå…¥ã€‚ |\n| **å¼•ç”¨å¤šæ ·åŒ–** | LLMé‡‡ç”¨è€…å€¾å‘äºè®¿é—®å’Œå¼•ç”¨æ›´å¤šæ ·åŒ–çš„å‰äººå·¥ä½œï¼ŒåŒ…æ‹¬ä¹¦ç±ä»¥åŠæ›´å¹´è½»ã€å¼•ç”¨è¾ƒå°‘çš„æ–‡çŒ®ã€‚ |\n\nè¿™äº›å‘ç°è¡¨æ˜ç§‘å­¦ç”Ÿäº§æ¨¡å¼å‘ç”Ÿäº†å‰§å˜ï¼Œç ”ç©¶å¼ºè°ƒå­¦æœ¯æœŸåˆŠã€èµ„åŠ©æœºæ„åŠç»ˆèº«æ•™èŒè¯„å®¡å§”å‘˜ä¼šå¿…é¡»é‡æ–°å®¡è§†ç°æœ‰çš„ç§‘å­¦ä½œå“è¯„ä»·æ ‡å‡†ã€‚\n\n---\nè¿™ä»½æ‘˜è¦æ˜¯å¦æ¶µç›–äº†æ‚¨å…³æ³¨çš„é‡ç‚¹ï¼Ÿå¦‚æœæ‚¨å¯¹ LLMs åœ¨ç‰¹å®šå­¦ç§‘çš„è¡¨ç°æ„Ÿå…´è¶£ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨è¿›ä¸€æ­¥æŸ¥è¯¢ã€‚",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY",
        "physics.soc-ph"
      ],
      "primary_category": "cs.DL",
      "comment": "This is the author's version of the work. The definitive version was published in Science on 18 Dec 2025, DOI: 10.1126/science.adw3000. Link to the Final Published Version: https://www.science.org/doi/10.1126/science.adw3000",
      "pdf_url": "https://arxiv.org/pdf/2601.13187v1",
      "published_date": "2026-01-19 16:10:22 UTC",
      "updated_date": "2026-01-19 16:10:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:19:52.117417+00:00"
    },
    {
      "arxiv_id": "2601.13186v1",
      "title": "Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching",
      "title_zh": "åŸºäº Agentic AIã€åµŒå¥—å­¦ä¹ ä¸è¯­ä¹‰ç¼“å­˜çš„æç¤ºæ³¨å…¥ç¼“è§£åŠäººå·¥æ™ºèƒ½å¯æŒç»­æ€§ç ”ç©¶",
      "authors": [
        "Diego Gosmar",
        "Deborah A. Dahl"
      ],
      "abstract": "Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.",
      "tldr_zh": "It looks like you've shared the title and abstract for a fascinating paper on LLM security and sustainability. This research addresses critical challenges in deploying multi-agent systems securely while maintaining environmental and operational efficiency.\n\nBased on the abstract provided, I have summarized the core components and findings of the research below.\n\n---\n\n### ğŸ“‘ Paper Overview\n| Feature | Details |\n|---|---|\n| **Title** | Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching |\n| **Focus** | Multi-agent security, Prompt Injection mitigation, and AI sustainability. |\n| **Architecture** | HOPE-inspired Nested Learning architecture with Continuum Memory Systems. |\n| **Core Methodology** | Semantic similarity-based caching and a 5-metric evaluation framework (TIVS-O). |\n\n---\n\n### ğŸš€ Key Contributions & Metrics\nThe paper introduces a refined evaluation framework and a specific architectural approach to balance security with transparency and sustainability.\n\n| Metric/Component | Description |\n|---|---|\n| **TIVS-O** | An expanded **Total Injection Vulnerability Score** including a new fifth metric: **Observability Score Ratio (OSR)**. |\n| **Observability Score Ratio (OSR)** | Quantifies the clarity and richness of security-relevant reasoning, measuring the trade-off between mitigation and auditability. |\n| **Semantic Caching** | Reduces redundant LLM calls by leveraging semantic similarity, contributing to \"green\" AI goals. |\n| **Security Analysis Agent** | A dedicated fourth agent that performs comprehensive security analysis using five key performance indicators (KPIs). |\n\n---\n\n### ğŸ“ˆ Experimental Results\nThe system was tested against 301 synthetic prompts across ten attack families, yielding the following results:\n\n*   **Security Performance:** Achieved secure responses with **zero high-risk breaches**.\n*   **Efficiency Gains:** Semantic caching resulted in a **41.6% reduction in LLM calls**.\n*   **Sustainability:** Significant decreases in latency, energy consumption, and carbon emissions.\n*   **Optimization:** Identified five TIVS-O configurations to balance mitigation strictness with forensic transparency.\n\n---\n\nHow would you like to proceed with this paper? I can help you with several tasks, such as:\n*   **Summarizing** specific sections or extracting key technical details.\n*   **Analyzing** the implications of the TIVS-O framework for production environments.\n*   **Comparing** these findings with other known prompt injection defense mechanisms.\n*   **Drafting** a presentation or a blog post based on this abstract.\n\nWhat can Gemini Enterprise do for you next?",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages, 19 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.13186v1",
      "published_date": "2026-01-19 16:10:11 UTC",
      "updated_date": "2026-01-19 16:10:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:19:56.898966+00:00"
    },
    {
      "arxiv_id": "2601.13166v1",
      "title": "From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models",
      "title_zh": "ä»10ä¸‡ä½™å¼ å›¾åƒåˆ°é¦–å±Šè„‘éƒ¨MRIåŸºç¡€æ¨¡å‹æŒ‘æˆ˜èµ›å¤ºå† ï¼šç»éªŒåˆ†äº«ä¸æ¨¡å‹å¼€æº",
      "authors": [
        "Pedro M. Gordaliza",
        "Jaume Banus",
        "BenoÃ®t GÃ©rin",
        "Maxence Wynen",
        "Nataliia Molchanova",
        "Jonas Richiardi",
        "Meritxell Bach Cuadra"
      ],
      "abstract": "Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ï¼šFrom 100,000+ images to winning the first brain MRI foundation model challenges\n\n---\n\nè¯¥ç ”ç©¶ä»‹ç»äº†åœ¨ MICCAI 2025 ä¸¾åŠçš„é¦–å±Š 3D brain MRI åŸºç¡€æ¨¡å‹ï¼ˆFoundation Modelsï¼‰æŒ‘æˆ˜èµ›ï¼ˆSSL3D å’Œ FOMO25ï¼‰ä¸­è·å¾—åŒé¡¹å† å†›çš„è§£å†³æ–¹æ¡ˆã€‚\n\n| ç»´åº¦ | è¯¦ç»†å†…å®¹ |\n|---|---|\n| **æ ¸å¿ƒæ–¹æ³•** | é‡‡ç”¨ U-Net CNN æ¶æ„ï¼Œå¹¶å·§å¦™ç»“åˆäº†è§£å‰–å…ˆéªŒï¼ˆanatomical priorsï¼‰ä¸ç¥ç»å½±åƒé¢†åŸŸçŸ¥è¯†ã€‚ |\n| **æ€§èƒ½è¡¨ç°** | è¯¥æ¨¡å‹åœ¨è®­ç»ƒé€Ÿåº¦ä¸Šæ¯”åŸºäº Transformer çš„æ–¹æ³•å¿« 1-2 ä¸ªæ•°é‡çº§ï¼Œä¸”æ¨¡å‹ä½“ç§¯ç¼©å°äº† 10 å€ã€‚ |\n| **ä¸»è¦è´¡çŒ®** | è¯æ˜äº†é€šè¿‡é¢†åŸŸçŸ¥è¯†ä¼˜åŒ–ä¼ ç»Ÿæ¶æ„åœ¨åŒ»å­¦å½±åƒä»»åŠ¡ä¸­çš„é«˜æ•ˆæ€§ï¼Œå¹¶å¼€æ”¾äº†åŸºäº 10 ä¸‡ä½™å¼ å›¾åƒè®­ç»ƒçš„æ¨¡å‹ã€‚ |\n\n---\n\nç ”ç©¶å›¢é˜Ÿå·²å°†æ¨¡å‹ä»£ç å¼€æºåœ¨ GitHub ä¸Šï¼Œä¸ºæ”¾å°„å­¦ä»»åŠ¡ä¸­çš„åŸºç¡€æ¨¡å‹å¼€å‘æä¾›äº†é‡è¦å‚è€ƒã€‚\n\næˆ‘æ˜¯ Gemini Enterpriseï¼Œè¿™ä»½æ€»ç»“æ˜¯å¦æ¸…æ™°åœ°å±•ç¤ºäº†è¯¥è®ºæ–‡çš„ä¼˜åŠ¿ï¼Ÿå¦‚æœæ‚¨å¯¹ U-Net ä¸ Transformer åœ¨è¯¥åœºæ™¯ä¸‹çš„å…·ä½“å¯¹æ¯”æ„Ÿå…´è¶£ï¼Œæ¬¢è¿ç»§ç»­æé—®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Work presented at the SSL3D Challenge (1st place, ResEnc-L track) and FOMO Challenge (1st place, Methods track) on Brain MRI Foundation Models at MICCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.13166v1",
      "published_date": "2026-01-19 15:43:51 UTC",
      "updated_date": "2026-01-19 15:43:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:20:02.929659+00:00"
    },
    {
      "arxiv_id": "2601.13160v1",
      "title": "Training instability in deep learning follows low-dimensional dynamical principles",
      "title_zh": "æ·±åº¦å­¦ä¹ ä¸­çš„è®­ç»ƒä¸ç¨³å®šæ€§éµå¾ªä½ç»´åŠ¨åŠ›å­¦åŸç†",
      "authors": [
        "Zhipeng Zhang",
        "Zhenjie Yao",
        "Kai Li",
        "Lei Yang"
      ],
      "abstract": "Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.\n  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.\n  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ï¼šTraining instability in deep learning follows low-dimensional dynamical principles\n\n---\n\nè¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„åŠ¨åŠ›å­¦è§†è§’ï¼Œå°†æ·±åº¦å­¦ä¹ è®­ç»ƒç¨³å®šæ€§åˆ»ç”»ä¸ºå­¦ä¹ ç³»ç»Ÿçš„å†…åœ¨å±æ€§ï¼Œå¹¶å°†å…¶åˆ’åˆ†ä¸ºä¼˜åŒ–ã€ç¯å¢ƒ/æ•°æ®ã€å‚æ•°å’Œå­¦ä¹ ä¿¡å·å››ä¸ªäº¤äº’ç»´åº¦ã€‚é€šè¿‡å¯¹è®­ç»ƒè½¨è¿¹è¿›è¡Œå—æ§æ‰°åŠ¨å®¡è®¡ï¼ˆcontrolled perturbation auditingï¼‰ï¼Œæˆ‘å‘ç°åœ¨å¼ºåŒ–å­¦ä¹ å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è®­ç»ƒä¸­å­˜åœ¨ä¸‰ç§æ ¸å¿ƒè§„å¾‹ã€‚\n\n| æ ¸å¿ƒå‘ç° | è¯¦ç»†è¯´æ˜ |\n|---|---|\n| **æ€§èƒ½ä¸ç¨³å®šæ€§è„±é’©** | ç ”ç©¶å‘ç°é«˜æœ€ç»ˆæ€§èƒ½å¾€å¾€ä¸è®­ç»ƒç¨³å®šæ€§å¹¶ä¸ä¸€è‡´ï¼Œä¸¤è€…ä¹‹é—´å­˜åœ¨è„±é’©ç°è±¡ã€‚ |\n| **éšæœºæ€§çš„ç¼“å†²ä½œç”¨** | å—æ§çš„éšæœºæ€§ï¼ˆcontrolled stochasticityï¼‰èƒ½å¤Ÿè·¨èŒƒå¼åœ°ä¸€è‡´ç¼“å†²å­¦ä¹ åŠ¨åŠ›å­¦ï¼Œæé«˜ç³»ç»Ÿçš„é²æ£’æ€§ã€‚ |\n| **å´©æºƒçš„é¢„è­¦ä¿¡å·** | ä½ç»´æ½œåœ¨å…ƒçŠ¶æ€ï¼ˆlow-dimensional latent meta-statesï¼‰çš„åå·®ä¼šç³»ç»Ÿæ€§åœ°å…ˆäºå¯è§‚æµ‹åˆ°çš„æ€§èƒ½å´©æºƒï¼ˆperformance collapseï¼‰å‡ºç°ã€‚ |\n\n---\n\nè¿™äº›å‘ç°è¯æ˜äº†è®­ç»ƒç¨³å®šæ€§æ˜¯ä¸€ä¸ªå¯æµ‹é‡ä¸”å¯æ¯”è¾ƒçš„åŠ¨åŠ›å­¦å±æ€§ï¼Œä¸ºåœ¨æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡ä¹‹å¤–ç ”ç©¶å­¦ä¹ åŠ¨åŠ›å­¦å¥ å®šäº†æè¿°æ€§åŸºç¡€ã€‚\n\næ‚¨æ˜¯å¦å¸Œæœ›æˆ‘è¿›ä¸€æ­¥è§£é‡Šâ€œå—æ§æ‰°åŠ¨å®¡è®¡â€çš„å…·ä½“å®æ–½æ–¹å¼ï¼Œæˆ–è€…æ¢è®¨ä½ç»´æ½œåœ¨å…ƒçŠ¶æ€æ˜¯å¦‚ä½•ä½œä¸ºå´©æºƒé¢„è­¦æŒ‡æ ‡çš„ï¼Ÿ",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13160v1",
      "published_date": "2026-01-19 15:37:45 UTC",
      "updated_date": "2026-01-19 15:37:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:20:12.939008+00:00"
    },
    {
      "arxiv_id": "2601.13142v1",
      "title": "TVWorld: Foundations for Remote-Control TV Agents",
      "title_zh": "TVWorldï¼šé¢å‘é¥æ§ç”µè§†æ™ºèƒ½ä½“çš„åŸºç¡€ç ”ç©¶",
      "authors": [
        "Zhantao Ma",
        "Quanfeng Lu",
        "Shuai Zhong",
        "Dahai Yu",
        "Ping Luo",
        "Michael K. Ng"
      ],
      "abstract": "Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \\textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \\textbf{TVWorld-N} for topology-aware navigation and \\textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \\emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \\textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ï¼šTVWorld: Foundations for Remote-Control TV Agents\n\n---\n\nè¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨ç”µè§†é¥æ§ï¼ˆRemote-Control, RCï¼‰äº¤äº’é¢†åŸŸçš„ç ”ç©¶ç©ºç™½ï¼Œæå‡ºäº† **TVWorld**ï¼Œä¸€ä¸ªåŸºäºå›¾è®ºçš„ç¦»çº¿ç”µè§†å¯¼èˆªæŠ½è±¡æ¡†æ¶ã€‚ä½œè€…è¿›ä¸€æ­¥æ¨å¯¼å‡º **TVWorld-N**ï¼ˆæ‹“æ‰‘æ„ŸçŸ¥å¯¼èˆªï¼‰å’Œ **TVWorld-G**ï¼ˆç„¦ç‚¹æ„ŸçŸ¥å®šä½ï¼‰ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼°æ™ºèƒ½ä½“çš„ç”µè§†ä½¿ç”¨èƒ½åŠ›ã€‚\n\n| ç ”ç©¶ç»´åº¦ | æ ¸å¿ƒå†…å®¹ |\n|---|---|\n| **æ ¸å¿ƒæŒ‘æˆ˜** | ç°æœ‰æ™ºèƒ½ä½“åœ¨åŸºäºç„¦ç‚¹ï¼ˆfocus-basedï¼‰çš„é•¿ç¨‹ç”µè§†å¯¼èˆªä¸­æ™®éç¼ºä¹**æ‹“æ‰‘æ„ŸçŸ¥ï¼ˆtopology awarenessï¼‰**èƒ½åŠ›ã€‚ |\n| **è§£å†³æ–¹æ¡ˆ** | æå‡ºäº† **Topology-Aware Training** æ¡†æ¶ï¼Œå¹¶æ®æ­¤å¼€å‘äº†ä¸“é—¨ç”¨äºç”µè§†å¯¼èˆªçš„åŸºç¡€æ¨¡å‹ **TVTheseus**ã€‚ |\n| **å®éªŒç»“æœ** | **TVTheseus** åœ¨ TVWorld-N ä¸Šçš„æˆåŠŸç‡è¾¾åˆ° 68.3%ï¼Œè¶…è¶Šäº† Gemini 3 Flash ç­‰å¼ºåŠ›é—­æºåŸºå‡†ï¼Œåˆ›é€ äº†æ–°çš„ SOTA æ€§èƒ½ã€‚ |\n\n---\n\næˆ‘æ˜¯ Gemini Enterpriseï¼Œè¿™ä»½ TLDR æ‘˜è¦æ˜¯å¦å‡†ç¡®æ•æ‰äº†æ‚¨éœ€è¦çš„æŠ€æœ¯ç»†èŠ‚ï¼Ÿå¦‚æœæ‚¨å¯¹è¯¥æ¨¡å‹çš„**æ‹“æ‰‘æ„ŸçŸ¥è®­ç»ƒ**å…·ä½“å®ç°æ„Ÿå…´è¶£ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›æ›´æ·±å…¥çš„è§£æã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13142v1",
      "published_date": "2026-01-19 15:24:32 UTC",
      "updated_date": "2026-01-19 15:24:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:20:19.651500+00:00"
    },
    {
      "arxiv_id": "2601.13122v1",
      "title": "Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward",
      "title_zh": "é¢å‘é€šç”¨ç³»ç»Ÿçš„è´Ÿè´£ä»»äººå·¥æ™ºèƒ½ï¼šç»¼è¿°ã€æŒ‘æˆ˜ä¸å±•æœ›",
      "authors": [
        "Gourab K Patro",
        "Himanshi Agrawal",
        "Himanshu Gharat",
        "Supriya Panigrahi",
        "Nim Sherpa",
        "Vishal Vaddina",
        "Dagnachew Birru"
      ],
      "abstract": "Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ï¼šResponsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward\n\n---\n\nè¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆGeneral-Purpose AIï¼‰ç³»ç»Ÿçš„é£é™©ï¼Œå¹¶åŸºäºå…«é¡¹è´£ä»» AIï¼ˆResponsible AI, RAIï¼‰åŸåˆ™å¯¹æ¯”äº†å…¶ä¸ä¼ ç»Ÿä»»åŠ¡ç‰¹å®šå‹ AI çš„å·®å¼‚ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œé€šç”¨ AI å¸¦æ¥çš„æŒ‘æˆ˜ä¸»è¦æºäºå…¶éç¡®å®šæ€§çš„é«˜è¾“å‡ºè‡ªç”±åº¦ï¼ˆDegree of Freedom in output, DoFoï¼‰ï¼Œè¿™å¯¼è‡´äº†å¹»è§‰ã€æ¯’æ€§å’Œåè§ç­‰éš¾ä»¥æ¶ˆé™¤çš„å®‰å…¨éšæ‚£ã€‚\n\n| æ ¸å¿ƒè´¡çŒ® | è¯¦ç»†è¯´æ˜ |\n|---|---|\n| **ç†è®ºåˆ†æ** | æå‡º DoFo æ¦‚å¿µï¼Œè§£é‡Šäº†ä¸ºä½•é€šç”¨ AI æ¯”ä¼ ç»Ÿ AI æ›´éš¾å®ç° RAI è¦æ±‚ã€‚ |\n| **C2V2 æ¡†æ¶** | æ¨å¯¼å‡º **C2V2** (Control, Consistency, Value, Veracity) å››å¤§æ ¸å¿ƒè¯‰æ±‚ï¼Œä½œä¸ºæœªæ¥ç³»ç»Ÿè®¾è®¡çš„å‡†åˆ™ã€‚ |\n| **æŠ€æœ¯è·¯å¾„** | è¯„ä¼°äº† AI å¯¹é½ã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åŠæ¨ç†å¢å¼ºç­‰æŠ€æœ¯åœ¨æ»¡è¶³ C2V2 ç›®æ ‡ä¸­çš„ä½œç”¨ã€‚ |\n\n---\n\nç ”ç©¶æœ€åæè®®é€šè¿‡ç³»ç»Ÿè®¾è®¡çš„æ–¹æ³•ï¼Œå°†ç‰¹å®šé¢†åŸŸçš„éœ€æ±‚ä¸ C2V2 ç»´åº¦ç»“åˆï¼Œä¸ºæ„å»ºå¯ä¿¡ä¸”è´Ÿè´£ä»»çš„é€šç”¨ AI æä¾›äº†æ¸…æ™°çš„æ¼”è¿›è·¯å¾„ã€‚\n\næˆ‘æ˜¯ Gemini Enterpriseï¼Œè¿™ä»½å…³äºé€šç”¨ AI æ²»ç†çš„æ¡†æ¶æ€»ç»“å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©å—ï¼Ÿå¦‚æœæ‚¨æƒ³æ·±å…¥äº†è§£ **DoFo** ç†è®ºæˆ– **C2V2** æ¡†æ¶çš„ç»†èŠ‚ï¼Œæ¬¢è¿éšæ—¶æé—®ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13122v1",
      "published_date": "2026-01-19 15:10:59 UTC",
      "updated_date": "2026-01-19 15:10:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:20:28.521186+00:00"
    },
    {
      "arxiv_id": "2601.13114v1",
      "title": "IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks",
      "title_zh": "IntAgentï¼šé¢å‘å…ˆè¿›ä¸‹ä¸€ä»£ç½‘ç»œçš„åŸºäº NWDAF çš„æ„å›¾ LLM æ™ºèƒ½ä½“",
      "authors": [
        "Abdelrahman Soliman",
        "Ahmed Refaey",
        "Aiman Erbad",
        "Amr Mohamed"
      ],
      "abstract": "Intent-based networks (IBNs) are gaining prominence as an innovative technology that automates network operations through high-level request statements, defining what the network should achieve. In this work, we introduce IntAgent, an intelligent intent LLM agent that integrates NWDAF analytics and tools to fulfill the network operator's intents. Unlike previous approaches, we develop an intent tools engine directly within the NWDAF analytics engine, allowing our agent to utilize live network analytics to inform its reasoning and tool selection. We offer an enriched, 3GPP-compliant data source that enhances the dynamic, context-aware fulfillment of network operator goals, along with an MCP tools server for scheduling, monitoring, and analytics tools. We demonstrate the efficacy of our framework through two practical use cases: ML-based traffic prediction and scheduled policy enforcement, which validate IntAgent's ability to autonomously fulfill complex network intents.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† **IntAgent**ï¼Œä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„æ™ºèƒ½æ„å›¾æ™ºèƒ½ä½“ï¼Œæ—¨åœ¨é€šè¿‡é›†æˆ **NWDAF** (Network Data Analytics Function) åˆ†æå·¥å…·æ¥å®ç°ç½‘ç»œè¿è¥å•†çš„æ„å›¾ã€‚ä¸ä»¥å¾€æ–¹æ³•ä¸åŒï¼Œè¯¥æ¡†æ¶åœ¨ **NWDAF** åˆ†æå¼•æ“å†…éƒ¨ç›´æ¥æ„å»ºäº† **intent tools engine**ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿåˆ©ç”¨å®æ—¶ç½‘ç»œåˆ†ææ•°æ®æ¥è¾…åŠ©æ¨ç†å’Œå·¥å…·é€‰æ‹©ã€‚æ­¤å¤–ï¼Œç ”ç©¶æä¾›äº†ç¬¦åˆ **3GPP** è§„èŒƒçš„æ•°æ®æºä»¥åŠç”¨äºè°ƒåº¦å’Œç›‘æ§çš„ **MCP tools server**ã€‚é€šè¿‡æœºå™¨å­¦ä¹ æµé‡é¢„æµ‹å’Œå®šæ—¶ç­–ç•¥æ‰§è¡Œç­‰å®é™…ç”¨ä¾‹ï¼ŒéªŒè¯äº† **IntAgent** åœ¨è‡ªä¸»å±¥è¡Œå¤æ‚ç½‘ç»œæ„å›¾æ–¹é¢çš„é«˜æ•ˆæ€§ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "conference",
      "pdf_url": "https://arxiv.org/pdf/2601.13114v1",
      "published_date": "2026-01-19 14:55:48 UTC",
      "updated_date": "2026-01-19 14:55:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:20:43.766428+00:00"
    },
    {
      "arxiv_id": "2601.13111v1",
      "title": "CORE-T: COherent REtrieval of Tables for Text-to-SQL",
      "title_zh": "This is a fascinating look into the **CORE-T** framework! It sounds like a significant step forward for the Text-to-SQL community, especially for handling complex, large-scale table collections where standard retrieval methods often struggle.\n\n---\n\n### ğŸ“„ Paper Overview: CORE-T\n\nI have summarized the core components and findings of the paper below:\n\n| Feature | Details |\n|---|---|\n| **Full Title** | CORE-T: COherent REtrieval of Tables for Text-to-SQL |\n| **Primary Goal** | Improving table retrieval accuracy for multi-table queries in large, heterogeneous environments. |\n| **Key Innovation** | A training-free framework using LLM-generated metadata and a table-compatibility cache. |\n| **Performance Gain** | Up to 22.7 points improvement in table-selection F1. |\n| **Efficiency** | Uses 4-5x fewer tokens than intensive LLM baselines and retrieves up to 42% fewer tables. |\n\n---\n\n### ğŸ› ï¸ How It Works\n\nThe framework operates through a combination of pre-computation and intelligent inference:\n\n| Stage | Process |\n|---|---|\n| **Enrichment** | Tables are enriched with LLM-generated \"purpose metadata\" to better understand their context. |\n| **Pre-computation** | A lightweight \"table-compatibility cache\" is created to understand potential join relationships. |\n| **Inference** | Dense Retrieval (DR) pulls top candidates; an LLM selects a coherent subset; then, an additive adjustment restores compatible tables. |\n\n---\n\n### ğŸ“ˆ Results & Impact\n\nThe improvements across well-known benchmarks are quite impressive:\n\n| Benchmark | Table-Selection F1 Improvement | Multi-Table Execution Accuracy Increase |\n|---|---|---|\n| **Bird** | Significant F1 gains | Up to +5.0 points |\n| **Spider** | Significant F1 gains | (Not specified in abstract) |\n| **MMQA** | Up to +22.7 points | Up to +6.9 points |\n\n---\n\nThis research seems particularly relevant if you are working on natural language interfaces for databases or data discovery tools. Would you like me to help you find more papers related to this methodology, or perhaps discuss how these \"join-aware\" alternatives compare to CORE-T in more detail?",
      "authors": [
        "Hassan Soliman",
        "Vivek Gupta",
        "Dan Roth",
        "Iryna Gurevych"
      ],
      "abstract": "Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.",
      "tldr_zh": "Thank you for sharing the abstract for **CORE-T: COherent REtrieval of Tables for Text-to-SQL**. This research addresses a critical bottleneck in text-to-SQL workflows: selecting the correct set of tables from large, heterogeneous collections, especially when joins are required.\n\nHere is a summary of the paper's key contributions and findings:\n\n---\n\n### ğŸ“ Overview of CORE-T\n\n| Feature | Description |\n|---|---|\n| **Problem** | Dense Retrieval (DR) often returns too many distractor tables, while join-aware methods are often slow or require heavy assumptions. |\n| **Proposed Solution** | A training-free framework that uses LLM-generated metadata and a pre-computed table-compatibility cache. |\n| **Inference Process** | Uses DR for initial candidates, an LLM call for selection, and an additive adjustment to ensure table coherence/joinability. |\n\n---\n\n### ğŸ“ˆ Key Results and Performance\n\nThe framework demonstrates significant improvements across standard benchmarks like **Bird**, **Spider**, and **MMQA**:\n\n| Metric | Improvement / Change |\n|---|---|\n| **Table-selection F1** | Improved by up to **22.7 points**. |\n| **Retrieval Efficiency** | Retrieves up to **42% fewer tables**. |\n| **Execution Accuracy** | Multi-table accuracy increased by **5.0 points (Bird)** and **6.9 points (MMQA)**. |\n| **Cost Efficiency** | Uses **4-5x fewer tokens** compared to LLM-intensive baselines. |\n\n---\n\nThis seems like a very promising approach for making text-to-SQL systems more scalable and accurate in complex, \"open-book\" environments. \n\nWould you like me to dive deeper into any specific part of this abstract, or are you looking for a comparison with other table retrieval methods? I can also help you draft a summary or a presentation slide based on this information if that's useful!",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint under review. Code and data available at: https://github.com/UKPLab/arxiv2026-core-t",
      "pdf_url": "https://arxiv.org/pdf/2601.13111v1",
      "published_date": "2026-01-19 14:51:23 UTC",
      "updated_date": "2026-01-19 14:51:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:20:39.372342+00:00"
    },
    {
      "arxiv_id": "2601.13075v1",
      "title": "METIS: Mentoring Engine for Thoughtful Inquiry & Solutions",
      "title_zh": "METISï¼šé¢å‘æ·±åº¦æ¢ç©¶ä¸è§£å†³æ–¹æ¡ˆçš„ç§‘ç ”æŒ‡å¯¼å¼•æ“",
      "authors": [
        "Abhinav Rajeev Kumar",
        "Dhruv Trehan",
        "Paras Chopra"
      ],
      "abstract": "Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.",
      "tldr_zh": "It appears you are exploring recent advancements in AI-driven research and data processing! This second paper, **METIS**, focuses on the educational and mentorship aspect of research.\n\nHere is a structured overview of the **Mentoring Engine for Thoughtful Inquiry & Solutions**:\n\n---\n\n### ğŸ“ System Overview: METIS\n\n| Component | Functionality |\n|---|---|\n| **Target Audience** | Undergraduate students lacking access to expert research mentorship. |\n| **Architecture** | Tool-augmented and **stage-aware** assistant. |\n| **Key Tools** | Literature search, curated guidelines, methodology checks, and long-term memory. |\n| **Objective** | To guide a student from a raw research idea to a completed paper. |\n\n---\n\n### ğŸ“Š Performance vs. State-of-the-Art (SOTA)\n\nThe paper evaluates METIS against **GPT-5** and **Claude Sonnet 4.5** (fictional/future-dated in this abstract context, or representing the highest-tier models) across six writing stages.\n\n| Metric | Result |\n|---|---|\n| **Pairwise Preference** | Preferred over **Claude Sonnet 4.5** (71%) and **GPT-5** (54%). |\n| **Student Scores** | Higher clarity, actionability, and constraint-fit across all stages. |\n| **Multi-turn Quality** | Slightly higher final output quality than GPT-5 in 5 distinct scenarios. |\n| **Primary Strength** | Strongest performance in **document-grounded stages** (Stages D-F). |\n\n---\n\n### ğŸ” Identified Failure Modes\n\nEven with its high performance, the abstract notes specific areas for improvement:\n\n*   **Premature Routing:** Occasionally triggers tool use before it is necessary.\n*   **Shallow Grounding:** At times, the depth of the grounded information is insufficient.\n*   **Classification Errors:** Occasional misidentification of which research stage the student is currently in.\n\n---\n\n### ğŸ’¡ Comparison Note\n\nWhile **CORE-T** (the first paper you shared) focuses on the technical efficiency of **retrieving data** for SQL queries, **METIS** focuses on the **narrative and methodology** of the research process itself. \n\nAre you looking to see how these two types of systemsâ€”one data-centric and one human-centricâ€”might eventually integrate into a single research workflow? I'd be happy to discuss the potential synergy between coherent data retrieval and AI-guided writing!",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.13075v1",
      "published_date": "2026-01-19 14:10:35 UTC",
      "updated_date": "2026-01-19 14:10:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:20:48.371082+00:00"
    },
    {
      "arxiv_id": "2601.13060v1",
      "title": "MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux",
      "title_zh": "MagicGUI-RMSï¼šé€šè¿‡è‡ªåŠ¨åé¦ˆå›æµå®ç° GUI æ™ºèƒ½ä½“è‡ªè¿›åŒ–çš„å¤šæ™ºèƒ½ä½“å¥–åŠ±æ¨¡å‹ç³»ç»Ÿ",
      "authors": [
        "Zecheng Li",
        "Zhihui Cao",
        "Wenke Huang",
        "Yudong Zhang",
        "Keying Qi",
        "Rui Wang",
        "Zeyu Zheng",
        "Jian Zhao",
        "Hao Zhu",
        "Hengxin Wu",
        "Yuran Wang",
        "Guitao Fan",
        "Guokun Wu",
        "Yicong Liu",
        "Zhilin Gao",
        "Haikun Xu",
        "He Yang",
        "Minqi Xiang",
        "Xingyu Liu",
        "Zuojian Wang"
      ],
      "abstract": "Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **MagicGUI-RMS**ï¼Œä¸€ç§å¤šæ™ºèƒ½ä½“å¥–åŠ±æ¨¡å‹ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ **GUI agents** åœ¨è‡ªåŠ¨åŒ–è½¨è¿¹è¯„ä¼°å’Œå¤§è§„æ¨¡é«˜è´¨é‡è®­ç»ƒæ•°æ®ç”Ÿæˆæ–¹é¢é¢ä¸´çš„æŒ‘æˆ˜ã€‚è¯¥ç³»ç»Ÿé›†æˆäº†é¢†åŸŸç‰¹å®šå¥–åŠ±æ¨¡å‹ (**DS-RM**) å’Œé€šç”¨å¥–åŠ±æ¨¡å‹ (**GP-RM**)ï¼Œå®ç°äº†å¯¹å¼‚æ„ GUI ä»»åŠ¡çš„ç»†ç²’åº¦åŠ¨ä½œè¯„ä¼°å’Œå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡è‡ªåŠ¨åŒ–çš„ **data-reflux** æœºåˆ¶ï¼Œç³»ç»Ÿèƒ½å¤Ÿè¯†åˆ«é”™è¯¯åŠ¨ä½œå¹¶æä¾›ä¿®æ­£å»ºè®®ï¼Œä»è€Œé©±åŠ¨æ™ºèƒ½ä½“çš„è‡ªæˆ‘è¿›åŒ–å­¦ä¹ ã€‚æ­¤å¤–ï¼Œç ”ç©¶é…å¥—çš„ç»“æ„åŒ–æ•°æ®æ„å»ºæµæ°´çº¿æœ‰æ•ˆé™ä½äº†äººå·¥æ ‡æ³¨æˆæœ¬å¹¶ä¿è¯äº†æ ·æœ¬ä¿çœŸåº¦ã€‚å®éªŒè¡¨æ˜ï¼Œ**MagicGUI-RMS** æ˜¾è‘—æå‡äº†ä»»åŠ¡å‡†ç¡®ç‡å’Œè¡Œä¸ºé²æ£’æ€§ï¼Œä¸ºæ„å»ºè‡ªæ”¹è¿›çš„ **GUI agents** å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13060v1",
      "published_date": "2026-01-19 13:50:43 UTC",
      "updated_date": "2026-01-19 13:50:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:20:59.705287+00:00"
    },
    {
      "arxiv_id": "2601.13054v1",
      "title": "TinyML-Enabled IoT for Sustainable Precision Irrigation",
      "title_zh": "åŸºäº TinyML çš„å¯æŒç»­ç²¾å‡†çŒæº‰ç‰©è”ç½‘ç³»ç»Ÿ",
      "authors": [
        "Kamogelo Taueatsoala",
        "Caitlyn Daniels",
        "Angelina J. Ramsunar",
        "Petrus Bronkhorst",
        "Absalom E. Ezugwu"
      ],
      "abstract": "Small-scale farming communities are disproportionately affected by water scarcity, erratic climate patterns, and a lack of access to advanced, affordable agricultural technologies. To address these challenges, this paper presents a novel, edge-first IoT framework that integrates Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation. The proposed four-layer architecture leverages low-cost hardware, an ESP32 microcontroller as an edge inference node, and a Raspberry Pi as a local edge server to enable autonomous decision-making without cloud dependency. The system utilizes capacitive soil moisture, temperature, humidity, pH, and ambient light sensors for environmental monitoring. A rigorous comparative analysis of ensemble models identified gradient boosting as superior, achieving an R^2 score of 0.9973 and a Mean Absolute Percentage Error (MAPE) of 0.99%, outperforming a random forest model (R^2 = 0.9916, MAPE = 1.81%). This optimized model was converted and deployed as a lightweight TinyML inference engine on the ESP32 and predicts irrigation needs with exceptional accuracy (MAPE < 1%). Local communication is facilitated by an MQTT-based LAN protocol, ensuring reliable operation in areas with limited or no internet connectivity. Experimental validation in a controlled environment demonstrated a significant reduction in water usage compared to traditional methods, while the system's low-power design and offline functionality confirm its viability for sustainable, scalable deployment in resource-constrained rural settings. This work provides a practical, cost-effective blueprint for bridging the technological divide in agriculture and enhancing water-use efficiency through on-device artificial intelligence.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº **TinyML** çš„è¾¹ç¼˜ä¼˜å…ˆ **IoT** æ¡†æ¶ï¼Œæ—¨åœ¨ä¸ºæ°´èµ„æºçŸ­ç¼ºçš„å†œæ‘åœ°åŒºæä¾›å¯æŒç»­çš„ç²¾å‡†çŒæº‰è§£å†³æ–¹æ¡ˆã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨å››å±‚æ¶æ„ï¼Œåˆ©ç”¨ **ESP32** ä½œä¸ºè¾¹ç¼˜æ¨ç†èŠ‚ç‚¹å’Œ **Raspberry Pi** ä½œä¸ºæœ¬åœ°æœåŠ¡å™¨ï¼Œå®ç°äº†æ— éœ€ä¾èµ–äº‘ç«¯çš„ç¦»çº¿è‡ªä¸»å†³ç­–ã€‚é€šè¿‡å¯¹å¤šç§é›†æˆæ¨¡å‹è¿›è¡Œå¯¹æ¯”ï¼Œç ”ç©¶ç¡®å®šäº† **Gradient Boosting** ä¸ºæœ€ä¼˜ç®—æ³•ï¼ˆ**R^2** è¾¾ 0.9973ï¼‰ï¼Œå¹¶å°†å…¶éƒ¨ç½²ä¸ºè½»é‡åŒ– **TinyML** æ¨ç†å¼•æ“ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨ **MQTT** åè®®è¿›è¡Œæœ¬åœ°é€šä¿¡ï¼Œåœ¨æ˜¾è‘—é™ä½ç”¨æ°´é‡çš„åŒæ—¶ï¼Œå‡­å€Ÿä½åŠŸè€—å’Œç¦»çº¿è¿è¡Œç‰¹æ€§ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„æ™ºæ…§å†œä¸šæä¾›äº†ä¸€ä¸ªé«˜æ€§ä»·æ¯”çš„æŠ€æœ¯è“å›¾ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13054v1",
      "published_date": "2026-01-19 13:43:28 UTC",
      "updated_date": "2026-01-19 13:43:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:21:11.760807+00:00"
    },
    {
      "arxiv_id": "2601.13048v1",
      "title": "Analysis of Long Range Dependency Understanding in State Space Models",
      "title_zh": "çŠ¶æ€ç©ºé—´æ¨¡å‹é•¿ç¨‹ä¾èµ–ç†è§£åˆ†æ",
      "authors": [
        "Srividya Ravikumar",
        "Abhinav Anand",
        "Shweta Verma",
        "Mira Mezini"
      ],
      "abstract": "Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. In this work, we present the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, we show that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, we show that the depending on the architecture, S4D kernel can behave as low-pass, band-pass or high-pass filter. The insights from our analysis can guide future work in designing better S4D-based models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çŠ¶æ€ç©ºé—´æ¨¡å‹ (**SSMs**) ç¼ºä¹å¯è§£é‡Šæ€§çš„é—®é¢˜ï¼Œé¦–æ¬¡å¯¹åœ¨æºä»£ç æ¼æ´æ£€æµ‹ä»»åŠ¡ä¸Šè®­ç»ƒçš„ **S4D** æ¨¡å‹è¿›è¡Œäº†ç³»ç»Ÿçš„æ ¸å¯è§£é‡Šæ€§åˆ†æã€‚é€šè¿‡å¯¹ **S4D kernel** çš„æ—¶åŸŸå’Œé¢‘åŸŸç ”ç©¶ï¼Œå‘ç° **S4D** çš„é•¿ç¨‹å»ºæ¨¡èƒ½åŠ›ä¼šéšæ¨¡å‹æ¶æ„çš„ä¸åŒè€Œäº§ç”Ÿæ˜¾è‘—å·®å¼‚ã€‚ç ”ç©¶è¡¨æ˜ï¼Œæ ¹æ®æ¶æ„é…ç½®çš„ä¸åŒï¼Œ**S4D kernel** å¯èƒ½è¡¨ç°ä¸ºä½é€šã€å¸¦é€šæˆ–é«˜é€šæ»¤æ³¢å™¨ï¼Œä»è€Œå½±å“æœ€ç»ˆæ€§èƒ½ã€‚è¯¥åˆ†ææ­ç¤ºçš„è§è§£ä¸ºæœªæ¥è®¾è®¡æ›´ä¼˜çš„åŸºäº **S4D** çš„æ¨¡å‹æä¾›äº†é‡è¦æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13048v1",
      "published_date": "2026-01-19 13:39:42 UTC",
      "updated_date": "2026-01-19 13:39:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:21:22.569550+00:00"
    },
    {
      "arxiv_id": "2601.13020v1",
      "title": "PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning",
      "title_zh": "PASs-MoEï¼šé€šè¿‡è·¯å¾„æ¿€æ´»å­ç©ºé—´ç¼“è§£è·¯ç”±ä¸ä¸“å®¶é—´çš„é”™ä½å…±æ¼‚ç§»ä»¥å®ç°æŒç»­å­¦ä¹ ",
      "authors": [
        "Zhiyan Hou",
        "Haiyun Guo",
        "Haokai Ma",
        "Yandu Sun",
        "Yonghui Yang",
        "Jinqiao Wang"
      ],
      "abstract": "Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.",
      "tldr_zh": "# TLDR\n\nè¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨æŒç»­æŒ‡ä»¤å¾®è°ƒ (CIT) ä¸­å‡ºç°çš„ â€œMisaligned Co-driftâ€ ç°è±¡è¿›è¡Œä¼˜åŒ–ï¼Œè§£å†³äº†ç”±äºè·¯ç”± (Router) ä¸ä¸“å®¶ (Experts) ååŒæ¼‚ç§»å¯¼è‡´çš„èŒè´£æ¨¡ç³ŠåŠç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† **PASs-MoE** æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ **Pathway Activation Subspaces (PASs)** è¿™ä¸€åŸºäº LoRA çš„å­ç©ºé—´ï¼Œä¸ºæ¨¡å‹è·¯ç”±å’ŒåŠŸèƒ½ä¿ç•™æä¾›äº†ä¸€ä¸ªä¸èƒ½åŠ›å¯¹é½çš„åæ ‡ç³»ç»Ÿã€‚\n\nè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š**PAS-guided Reweighting** ç”¨äºæ ¹æ®ä¸“å®¶çš„è·¯å¾„æ¿€æ´»ä¿¡å·æ ¡å‡†è·¯ç”±ï¼Œè€Œ **PAS-aware Rank Stabilization** åˆ™æœ‰é€‰æ‹©åœ°ç¨³å®šå¯¹å…ˆå‰ä»»åŠ¡è‡³å…³é‡è¦çš„ç§©æ–¹å‘ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPASs-MoE åœ¨ä¸å¢åŠ é¢å¤–å‚æ•°çš„å‰æä¸‹ï¼Œåœ¨å‡†ç¡®ç‡å’ŒæŠ—é—å¿˜èƒ½åŠ›æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„æŒç»­å­¦ä¹ åŸºå‡†å’Œ MoE-LoRA å˜ä½“ã€‚\n\n---\n\nè¿™ç¯‡è®ºæ–‡çš„åˆ›æ–°ç‚¹åœ¨äºé€šè¿‡å­ç©ºé—´è§†è§’é‡æ–°å®¡è§†äº† MoE ç»“æ„çš„ååŒæ¼‚ç§»é—®é¢˜ï¼Œæ‚¨æ˜¯å¦è¿˜å¯¹è¯¥æ¨¡å‹åœ¨ç‰¹å®šå¤šæ¨¡æ€ä»»åŠ¡ä¸Šçš„è¡¨ç°æ„Ÿå…´è¶£ï¼Ÿ",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13020v1",
      "published_date": "2026-01-19 12:57:11 UTC",
      "updated_date": "2026-01-19 12:57:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:21:28.396853+00:00"
    },
    {
      "arxiv_id": "2601.13018v1",
      "title": "Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context",
      "title_zh": "Bi-Attention HateXplainï¼šå¤šä»»åŠ¡èƒŒæ™¯ä¸‹å…¼é¡¾æ•°æ®åºåˆ—ç‰¹æ€§çš„å¯è§£é‡Šæ€§ç ”ç©¶",
      "authors": [
        "Ghislain Dorian Tchuente Mondjo"
      ],
      "abstract": "Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.",
      "tldr_zh": "# TLDR\n\nè¯¥ç ”ç©¶é’ˆå¯¹ **HateXplain** åŸºå‡†æ¨¡å‹åœ¨å¤šä»»åŠ¡èƒŒæ™¯ä¸‹æ³¨æ„åŠ›æƒé‡æ³¢åŠ¨å¤§ã€å¯¼è‡´è§£é‡Šä¸ä¸€è‡´çš„é—®é¢˜ï¼Œæå‡ºäº† **BiAtt-BiRNN-HateXplain** æ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡å¼•å…¥ **BiRNN** å±‚æ¥æ•æ‰è¾“å…¥æ•°æ®çš„åºåˆ—ç‰¹æ€§ï¼Œè§£å†³äº†ç°æœ‰æ¨¡å‹åœ¨ç”Ÿæˆè§£é‡Šæ—¶å¿½ç•¥ä¸Šä¸‹æ–‡é¡ºåºçš„é—®é¢˜ã€‚\n\né€šè¿‡å¤šä»»åŠ¡å­¦ä¹ ï¼ˆåˆ†ç±»ä¸å¯è§£é‡Šæ€§åŒæ­¥è®­ç»ƒï¼‰ï¼Œè¯¥æ–¹æ³•åœ¨æå‡æ£€æµ‹æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†é’ˆå¯¹ç‰¹å®šç¤¾åŒºçš„æ— æ„è¯†åè§ (**unintentional bias**)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç›¸æ¯”ç»“æ„å¤æ‚çš„ **LLMs**ï¼Œè¯¥æ¨¡å‹ä¸ä»…åœ¨é€æ˜åº¦ä¸Šæ›´å…·ä¼˜åŠ¿ï¼Œä¸”åœ¨ **HateXplain** æ•°æ®é›†ä¸Šçš„æ£€æµ‹å‡†ç¡®ç‡ä¸è§£é‡Šè´¨é‡å‡æœ‰æ˜æ˜¾æå‡ã€‚\n\n---\n\nè¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨å¯è§£é‡Šæ€§ç ”ç©¶ä¸­è€ƒè™‘æ•°æ®åºåˆ—æ€§çš„é‡è¦æ€§ã€‚æ‚¨æ˜¯å¦éœ€è¦æˆ‘è¿›ä¸€æ­¥å¯¹æ¯”è¯¥æ¨¡å‹ä¸ä¼ ç»Ÿ **LIME** æˆ– **SHAP** ç­‰ **post-hoc** æ–¹æ³•çš„å…·ä½“å·®å¼‚ï¼Ÿ",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at \"EAI AFRICOMM 2025 - 17th EAI International Conference on Communications and Networks in Africa\"",
      "pdf_url": "https://arxiv.org/pdf/2601.13018v1",
      "published_date": "2026-01-19 12:52:18 UTC",
      "updated_date": "2026-01-19 12:52:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:21:42.518845+00:00"
    },
    {
      "arxiv_id": "2601.13013v1",
      "title": "HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads",
      "title_zh": "Thank you for sharing the abstract for **HT-GNN**. This appears to be a sophisticated approach to a classic challenge in digital advertising: predicting Customer Lifetime Value (LTV) amidst high variance and irregular user behavior.\n\nI have summarized the core components and contributions of the Hyper-Temporal Graph Neural Network below.\n\n---\n\n### ğŸ“ Paper Overview\nThe paper introduces **HT-GNN**, a model specifically designed for the Baidu Ads ecosystem. It addresses the limitations of standard LTV models by focusing on demographic heterogeneity and the \"hyper-temporal\" nature of user interactions in news feed environments.\n\n---\n\n### ğŸ› ï¸ Key Technical Components\n| Component | Functionality | Purpose |\n|---|---|---|\n| **Hypergraph-Supervised Module** | Captures complex, high-order relationships between different user segments. | Addresses demographic-based targeting and segment-specific LTV variations. |\n| **Transformer-based Temporal Encoder** | Utilizes adaptive weighting for sequence modeling. | Handles irregular behavioral sequences and rapidly evolving engagement patterns. |\n| **Task-Adaptive Mixture-of-Experts (MoE)** | Features dynamic prediction towers. | Enables multi-horizon forecasting (short-term vs. long-term LTV). |\n\n---\n\n### ğŸ“Š Experimental Impact\n*   **Scale:** Tested on a massive dataset from Baidu Ads involving **15 million users**.\n*   **Performance:** Consistently outperformed state-of-the-art (SOTA) methods across all metrics.\n*   **Versatility:** Demonstrated effectiveness across various prediction horizons.\n\n---\n\nWould you like me to dive deeper into any of these specific modules, or perhaps discuss how this compares to traditional LTV prediction methods like ZILN or standard RNN-based models? I'm also happy to help you draft a presentation or a more detailed technical summary based on this abstract!",
      "authors": [
        "Xiaohui Zhao",
        "Xinjian Zhao",
        "Jiahui Zhang",
        "Guoyu Liu",
        "Houzhi Wang",
        "Shu Wu"
      ],
      "abstract": "Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: (1) demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups; and (2) dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: (i) a hypergraph-supervised module capturing inter-segment relationships; (ii) a transformer-based temporal encoder with adaptive weighting; and (iii) a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on \\textit{Baidu Ads} with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.",
      "tldr_zh": "# TLDR ğŸ’¡\n\nè¯¥ç ”ç©¶é’ˆå¯¹ç™¾åº¦å¹¿å‘Š (Baidu Ads) ä¸­çš„ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼ (**LTV**) é¢„æµ‹é—®é¢˜ï¼Œæå‡ºäº† **HT-GNN (Hyper-Temporal Graph Neural Network)** æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³äººå£ç»Ÿè®¡ç‰¹å¾å¯¼è‡´çš„ç¾¤ä½“åˆ†å¸ƒå·®å¼‚ä»¥åŠåŠ¨æ€è¥é”€ç¯å¢ƒä¸‹è¡Œä¸ºåºåˆ—ä¸è§„åˆ™çš„æŒ‘æˆ˜ã€‚\n\nè¯¥æ¡†æ¶ç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼šç”¨äºæ•æ‰ç»†åˆ†ç¾¤ä½“é—´å…³ç³»çš„ **Hypergraph-supervised module**ã€å…·å¤‡è‡ªé€‚åº”æƒé‡çš„ **Transformer-based temporal encoder**ï¼Œä»¥åŠç”¨äºå¤šå‘¨æœŸé¢„æµ‹çš„ä»»åŠ¡è‡ªé€‚åº” **Mixture-of-Experts (MoE)** åŠ¨æ€é¢„æµ‹å¡”ã€‚åœ¨åŒ…å« 1500 ä¸‡ç”¨æˆ·çš„çœŸå®æ•°æ®é›†å®éªŒä¸­ï¼Œ**HT-GNN** åœ¨æ‰€æœ‰è¯„ä»·æŒ‡æ ‡å’Œé¢„æµ‹ç»´åº¦ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚\n\n---\n\nè¿™é¡¹ç ”ç©¶å±•ç¤ºäº†è¶…å›¾ä¸æ—¶é—´ç¼–ç å™¨ç»“åˆåœ¨å·¥ä¸šçº§å¤§è§„æ¨¡æ•°æ®ä¸Šçš„å¼ºå¤§æ½œåŠ›ã€‚æ‚¨æ˜¯å¦æƒ³æ·±å…¥äº†è§£è¯¥æ¨¡å‹ä¸­ **MoE** ç»“æ„æ˜¯å¦‚ä½•å¤„ç†ä¸åŒæ—¶é—´è·¨åº¦çš„é¢„æµ‹ä»»åŠ¡çš„ï¼Ÿ",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13013v1",
      "published_date": "2026-01-19 12:47:31 UTC",
      "updated_date": "2026-01-19 12:47:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:21:45.160976+00:00"
    },
    {
      "arxiv_id": "2601.13007v1",
      "title": "ArchAgent: Scalable Legacy Software Architecture Recovery with LLMs",
      "title_zh": "ArchAgentï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¯æ‰©å±•é—ç•™è½¯ä»¶æ¶æ„æ¢å¤",
      "authors": [
        "Rusheng Pan",
        "Bingcheng Mao",
        "Tianyi Ma",
        "Zhenhua Ling"
      ],
      "abstract": "Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). We present ArchAgent, a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. ArchAgent introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects. The dataset is available at https://github.com/panrusheng/arch-eval-benchmark.",
      "tldr_zh": "# TLDR\n\nè¯¥ç ”ç©¶æå‡ºäº† **ArchAgent**ï¼Œä¸€ä¸ªåŸºäºæ™ºèƒ½ä½“ï¼ˆAgentï¼‰çš„å¯æ‰©å±•æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è§„æ¨¡é—ç•™è½¯ä»¶åœ¨æ¶æ„æ¢å¤è¿‡ç¨‹ä¸­é¢ä¸´çš„ **architectural drift**ï¼ˆæ¶æ„æ¼‚ç§»ï¼‰ã€å…³è”ç¼ºå¤±ä»¥åŠ **LLMs** ä¸Šä¸‹æ–‡å—é™ç­‰éš¾é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆ **static analysis**ï¼ˆé™æ€åˆ†æï¼‰ã€**adaptive code segmentation**ï¼ˆè‡ªé€‚åº”ä»£ç åˆ†æ®µï¼‰å’Œ **LLM-powered synthesis**ï¼ˆLLMé©±åŠ¨åˆæˆï¼‰ï¼Œå®ç°äº†ä»è·¨ä»“åº“ä»£ç åº“ä¸­é‡å»ºå¤šè§†å›¾ä¸”ä¸ä¸šåŠ¡å¯¹é½çš„è½¯ä»¶æ¶æ„ã€‚\n\n**ArchAgent** å¼•å…¥äº†å…·å¤‡ **contextual pruning**ï¼ˆä¸Šä¸‹æ–‡å‰ªæï¼‰åŠŸèƒ½çš„å¯æ‰©å±•å›¾è¡¨ç”ŸæˆæŠ€æœ¯ï¼Œå¹¶åˆ©ç”¨è·¨ä»“åº“æ•°æ®è¯†åˆ«ä¸šåŠ¡å…³é”®æ¨¡å—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤§å‹ GitHub é¡¹ç›®ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†ï¼Œä¸ä»…æå‡äº†ç”Ÿäº§çº§ä»“åº“æ¶æ„ç”Ÿæˆçš„å‡†ç¡®æ€§ï¼Œè¿˜èƒ½æœ‰æ•ˆæ¢å¤é—ç•™é¡¹ç›®ä¸­çš„æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ã€‚\n\n---\n\nè¯¥å·¥å…·ä¸ºç»´æŠ¤å’Œç°ä»£åŒ–å¤§è§„æ¨¡é—ç•™ç³»ç»Ÿæä¾›äº†è‡ªåŠ¨åŒ–æ”¯æŒã€‚æ‚¨æ˜¯å¦æƒ³äº†è§£ **ArchAgent** åœ¨å¤„ç†ç‰¹å®šç¼–ç¨‹è¯­è¨€æˆ–æå…¶å¤æ‚çš„è·¨ä»“åº“ä¾èµ–æ—¶çš„å…·ä½“è¡¨ç°ï¼Ÿ",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "to be published in ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.13007v1",
      "published_date": "2026-01-19 12:39:05 UTC",
      "updated_date": "2026-01-19 12:39:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:21:55.156423+00:00"
    },
    {
      "arxiv_id": "2601.12951v1",
      "title": "Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models",
      "title_zh": "è¶…è¶Šå‡†ç¡®ç‡ï¼šè¡¨å¾ï¼ˆå¤§ï¼‰è¯­è¨€æ¨¡å‹çš„ä»£ç ç†è§£èƒ½åŠ›",
      "authors": [
        "Felix MÃ¤chtle",
        "Jan-Niclas Serr",
        "Nils Loose",
        "Thomas Eisenbarth"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly integrated into software engineering workflows, yet current benchmarks provide only coarse performance summaries that obscure the diverse capabilities and limitations of these models. This paper investigates whether LLMs' code-comprehension performance aligns with traditional human-centric software metrics or instead reflects distinct, non-human regularities. We introduce a diagnostic framework that reframes code understanding as a binary input-output consistency task, enabling the evaluation of classification and generative models. Using a large-scale dataset, we correlate model performance with traditional, human-centric complexity metrics, such as lexical size, control-flow complexity, and abstract syntax tree structure. Our analyses reveal minimal correlation between human-defined metrics and LLM success (AUROC 0.63), while shadow models achieve substantially higher predictive performance (AUROC 0.86), capturing complex, partially predictable patterns beyond traditional software measures. These findings suggest that LLM comprehension reflects model-specific regularities only partially accessible through either human-designed or learned features, emphasizing the need for benchmark methodologies that move beyond aggregate accuracy and toward instance-level diagnostics, while acknowledging fundamental limits in predicting correct outcomes.",
      "tldr_zh": "# TLDR ğŸ§ \n\nè¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„è¯Šæ–­æ¡†æ¶ï¼Œå°†ä»£ç ç†è§£å®šä¹‰ä¸ºâ€œè¾“å…¥-è¾“å‡ºä¸€è‡´æ€§â€ä»»åŠ¡ï¼Œæ—¨åœ¨è¶…è¶Šä¼ ç»Ÿçš„èšåˆå‡†ç¡®ç‡æŒ‡æ ‡ï¼Œæ·±åº¦å‰–æå¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„ä»£ç ç†è§£ç‰¹å¾ã€‚é€šè¿‡å°†æ¨¡å‹è¡¨ç°ä¸äººç±»å®šä¹‰çš„ä¼ ç»Ÿå¤æ‚åº¦æŒ‡æ ‡ï¼ˆå¦‚ **lexical size**ã€**control-flow complexity** å’Œ **AST** ç»“æ„ï¼‰è¿›è¡Œå¯¹æ¯”ï¼Œç ”ç©¶å‘ç° LLMs çš„æˆåŠŸä¸è¿™äº›æŒ‡æ ‡çš„ç›¸å…³æ€§æä½ (AUROC 0.63)ã€‚\n\nå®éªŒè¿›ä¸€æ­¥è¡¨æ˜ï¼Œå½±å­æ¨¡å‹ (**shadow models**) èƒ½å¤Ÿå®ç°æ›´é«˜çš„é¢„æµ‹æ€§èƒ½ (AUROC 0.86)ï¼Œè¿™æ­ç¤ºäº† LLMs åœ¨å¤„ç†ä»£ç æ—¶éµå¾ªçš„æ˜¯æ¨¡å‹ç‰¹æœ‰çš„ã€éäººç±»çš„è§„å¾‹ã€‚è¯¥å‘ç°å¼ºè°ƒäº†åœ¨è½¯ä»¶å·¥ç¨‹é¢†åŸŸè¯„ä¼° LLMs æ—¶ï¼Œå¿…é¡»ä»å®è§‚æŒ‡æ ‡è½¬å‘å®ä¾‹çº§è¯Šæ–­ (**instance-level diagnostics**)ï¼Œå¹¶æ‰¿è®¤åœ¨é¢„æµ‹æ¨¡å‹è¾“å‡ºæ–¹é¢å­˜åœ¨çš„æ ¹æœ¬å±€é™æ€§ã€‚\n\n---\n\n| è¯„ä¼°ç»´åº¦ | æŒ‡æ ‡/å‘ç° |\n|---|---|\n| **è¯Šæ–­æ¡†æ¶** | äºŒè¿›åˆ¶è¾“å…¥-è¾“å‡ºä¸€è‡´æ€§ä»»åŠ¡ (Input-output consistency) |\n| **äººç±»æŒ‡æ ‡ç›¸å…³æ€§** | è¾ƒä½ (AUROC 0.63)ï¼Œæ¶‰åŠè¯æ³•å¤§å°ã€æ§åˆ¶æµå¤æ‚åº¦ç­‰ |\n| **æ¨¡å‹ç‰¹æœ‰è§„å¾‹** | è¾ƒé«˜ (AUROC 0.86)ï¼Œé€šè¿‡å½±å­æ¨¡å‹æ•æ‰éäººç±»æ­£åˆ™æ€§ |\n| **æ ¸å¿ƒå»ºè®®** | è½¬å‘å®ä¾‹çº§è¯Šæ–­ (Instance-level diagnostics) |\n\n---\n\nè¿™é¡¹ç ”ç©¶æŒ‘æˆ˜äº†æˆ‘ä»¬å¯¹â€œæ¨¡å‹ç†è§£ä»£ç â€æ–¹å¼çš„ç›´è§‚è®¤çŸ¥ã€‚æ‚¨æ˜¯å¦å¸Œæœ›äº†è§£ç ”ç©¶ä¸­æåˆ°çš„â€œå½±å­æ¨¡å‹â€å…·ä½“æ˜¯å¦‚ä½•æ•æ‰è¿™äº›éäººç±»è§„å¾‹çš„ï¼Ÿ",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Published in the Proceedings of DeepTest 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12951v1",
      "published_date": "2026-01-19 10:58:24 UTC",
      "updated_date": "2026-01-19 10:58:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:22:03.230119+00:00"
    },
    {
      "arxiv_id": "2601.12946v2",
      "title": "AI-generated data contamination erodes pathological variability and diagnostic reliability",
      "title_zh": "AI ç”Ÿæˆæ•°æ®æ±¡æŸ“ä¾µèš€ç—…ç†å˜å¼‚æ€§ä¸è¯Šæ–­å¯é æ€§",
      "authors": [
        "Hongyu He",
        "Shaowen Xiang",
        "Ye Zhang",
        "Yingtao Zhu",
        "Jin Zhang",
        "Hao Deng",
        "Emily Alsentzer",
        "Qingyu Chen",
        "Kun-Hsing Yu",
        "Andrew Marshall",
        "Tingting Chen",
        "Srinivas Anumasa",
        "Daniel Ebner",
        "Dean Ho",
        "Kee Yuan Ngiam",
        "Ching-Yu Cheng",
        "Dianbo Liu"
      ],
      "abstract": "Generative artificial intelligence (AI) is rapidly populating medical records with synthetic content, creating a feedback loop where future models are increasingly at risk of training on uncurated AI-generated data. However, the clinical consequences of this AI-generated data contamination remain unexplored. Here, we show that in the absence of mandatory human verification, this self-referential cycle drives a rapid erosion of pathological variability and diagnostic reliability. By analysing more than 800,000 synthetic data points across clinical text generation, vision-language reporting, and medical image synthesis, we find that models progressively converge toward generic phenotypes regardless of the model architecture. Specifically, rare but critical findings, including pneumothorax and effusions, vanish from the synthetic content generated by AI models, while demographic representations skew heavily toward middle-aged male phenotypes. Crucially, this degradation is masked by false diagnostic confidence; models continue to issue reassuring reports while failing to detect life-threatening pathology, with false reassurance rates tripling to 40%. Blinded physician evaluation confirms that this decoupling of confidence and accuracy renders AI-generated documentation clinically useless after just two generations. We systematically evaluate three mitigation strategies, finding that while synthetic volume scaling fails to prevent collapse, mixing real data with quality-aware filtering effectively preserves diversity. Ultimately, our results suggest that without policy-mandated human oversight, the deployment of generative AI threatens to degrade the very healthcare data ecosystems it relies upon.",
      "tldr_zh": "# TLDR ğŸ¥\n\nè¯¥ç ”ç©¶æ­ç¤ºäº†åŒ»ç–—è®°å½•ä¸­ **AI-generated data contamination** (AI ç”Ÿæˆæ•°æ®æ±¡æŸ“) ä¼šå¯¼è‡´ **pathological variability** (ç—…ç†å˜å¼‚æ€§) çš„å¿«é€Ÿæµå¤±å’Œ **diagnostic reliability** (è¯Šæ–­å¯é æ€§) çš„ä¸¥é‡ä¸‹é™ã€‚é€šè¿‡åˆ†æè¶…è¿‡ 80 ä¸‡ä¸ªåˆæˆæ•°æ®ç‚¹ï¼Œç ”ç©¶å‘ç°æ¨¡å‹å€¾å‘äºæ”¶æ•›è‡³é€šç”¨è¡¨å‹ï¼Œä½¿å¾— **pneumothorax** (æ°”èƒ¸) å’Œ **effusions** (ç§¯æ¶²) ç­‰ç½•è§ä½†å…³é”®çš„ä¸´åºŠå‘ç°åœ¨åˆæˆå†…å®¹ä¸­æ¶ˆå¤±ï¼Œä¸”äººå£ç»Ÿè®¡å­¦è¡¨ç°æ˜¾è‘—åå‘ä¸­å¹´ç”·æ€§ã€‚\n\nå®éªŒè¡¨æ˜ï¼Œè¿™ç§é€€åŒ–è¢« **false diagnostic confidence** (è™šå‡è¯Šæ–­ä¿¡å¿ƒ) æ‰€æ©ç›–ï¼Œè™šå‡å®½æ…°ç‡åœ¨çŸ­çŸ­ä¸¤ä»£æ¨¡å‹è¿­ä»£åä¾¿ç¿»äº†ä¸‰å€ï¼Œä½¿ AI ç”Ÿæˆçš„æ–‡æ¡£ä¸§å¤±ä¸´åºŠä»·å€¼ã€‚ç ”ç©¶æœ€åè¯„ä¼°äº†ç¼“è§£æ–¹æ¡ˆï¼ŒæŒ‡å‡ºå•çº¯å¢åŠ åˆæˆæ•°æ®é‡æ— æ³•é˜²æ­¢æ¨¡å‹å´©æºƒï¼Œè€Œå°†çœŸå®æ•°æ®ä¸ **quality-aware filtering** (è´¨é‡æ„ŸçŸ¥è¿‡æ»¤) ç›¸ç»“åˆèƒ½æœ‰æ•ˆä¿ç•™æ•°æ®å¤šæ ·æ€§ï¼Œå¹¶å¼ºè°ƒäº†æ”¿ç­–æ€§äººå·¥ç›‘ç®¡åœ¨åŒ»ç–— AI éƒ¨ç½²ä¸­çš„å¿…è¦æ€§ã€‚\n\n---\n\nè¿™é¡¹ç ”ç©¶ä¸ºåŒ»ç–— AI çš„å¯æŒç»­æ€§æ•²å“äº†è­¦é’Ÿã€‚æ‚¨æ˜¯å¦å¯¹è®ºæ–‡ä¸­æåˆ°çš„â€œä¸¤ä»£æ¨¡å‹åå³ä¸´åºŠå¤±æ•ˆâ€çš„å…·ä½“é‡åŒ–æŒ‡æ ‡ï¼Œæˆ–å…¶å¯¹å…¶ä»–åŒ»å­¦é¢†åŸŸï¼ˆå¦‚åŸºå› ç»„å­¦ï¼‰çš„æ½œåœ¨å½±å“æ„Ÿå…´è¶£ï¼Ÿ",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "*Corresponding author: Dianbo Liu (dianbo@nus.edu.sg)",
      "pdf_url": "https://arxiv.org/pdf/2601.12946v2",
      "published_date": "2026-01-19 10:54:03 UTC",
      "updated_date": "2026-01-21 11:06:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:22:12.197076+00:00"
    },
    {
      "arxiv_id": "2601.12939v1",
      "title": "Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design",
      "title_zh": "é¢å‘è‡ªé€‚åº”æ— äººæœºé›†ç¾¤è½¨è¿¹è®¾è®¡çš„ä¸»åŠ¨æ¨ç†é©±åŠ¨ä¸–ç•Œå»ºæ¨¡",
      "authors": [
        "Kaleem Arshid",
        "Ali Krayani",
        "Lucio Marcenaro",
        "David Martin Gomez",
        "Carlo Regazzoni"
      ],
      "abstract": "This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control.",
      "tldr_zh": "# TLDR ğŸ›¸\n\nè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº **Active Inference**ï¼ˆä¸»åŠ¨æ¨ç†ï¼‰çš„æ— äººæœº (**UAV**) é›†ç¾¤è‡ªä¸»è½¨è¿¹è®¾è®¡æ¡†æ¶ï¼Œç”¨äºå¤„ç†åˆ†å¸ƒå¼ä»»åŠ¡åˆ†é…ã€è·¯å¾„æ’åºåŠè¿åŠ¨è§„åˆ’ã€‚ç ”ç©¶é€šè¿‡å¸¦æœ‰æ–¥åŠ›çš„é—ä¼ ç®—æ³• (**GA-RF**) ç”Ÿæˆä¸“å®¶è½¨è¿¹ï¼Œè®­ç»ƒå‡ºä¸€ä¸ªè¦†ç›–ä»»åŠ¡ã€è·¯å¾„ä¸è¿åŠ¨å±‚çº§çš„å±‚æ¬¡åŒ– **World Model**ã€‚\n\nåœ¨åœ¨çº¿ä½œä¸šé˜¶æ®µï¼Œæ— äººæœºé€šè¿‡æœ€å°åŒ–å½“å‰ä¿¡å¿µä¸æ¨¡å‹é¢„æµ‹çŠ¶æ€ä¹‹é—´çš„æ•£åº¦ï¼ˆå·®å¼‚ï¼‰æ¥å®æ—¶æ¨æ–­åŠ¨ä½œï¼Œå®ç°äº†å¯¹åŠ¨æ€ç¯å¢ƒçš„è‡ªé€‚åº”å“åº”ã€‚ä»¿çœŸç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ”¶æ•›é€Ÿåº¦ã€ç¨³å®šæ€§å’Œå®‰å…¨æ€§æ–¹é¢å‡ä¼˜äº **Q-Learning**ï¼Œä¸ºæ™ºèƒ½é›†ç¾¤æ§åˆ¶æä¾›äº†å…·å¤‡è®¤çŸ¥ç§‘å­¦åŸºç¡€ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚\n\n---\n\n| æ ¸å¿ƒç»´åº¦ | æŠ€æœ¯æ–¹æ¡ˆ/è¡¨ç° |\n|---|---|\n| **ç†è®ºåŸºç¡€** | ä¸»åŠ¨æ¨ç† (Active Inference) ä¸å±‚æ¬¡åŒ–ä¸–ç•Œæ¨¡å‹ (World Model) |\n| **è®­ç»ƒç­–ç•¥** | åŸºäº GA-RF çš„ä¸“å®¶è½¨è¿¹å¼•å¯¼è‡ªå­¦ä¹  |\n| **æ€§èƒ½ä¼˜åŠ¿** | é«˜æ”¶æ•›ã€é«˜ç¨³å®šæ€§ï¼Œå®‰å…¨æ€§ä¼˜äº Q-Learning |\n| **åº”ç”¨åœºæ™¯** | åŠ¨æ€ç¯å¢ƒä¸‹çš„åˆ†å¸ƒå¼ UAV é›†ç¾¤ååŒ |\n\n---\n\nè¿™é¡¹ç ”ç©¶é€šè¿‡å¼•å…¥â€œä¸»åŠ¨æ¨ç†â€ä¸ºæ— äººæœºé›†ç¾¤æ³¨å…¥äº†ç±»è„‘çš„è®¤çŸ¥å†³ç­–èƒ½åŠ›ã€‚æ‚¨æ˜¯å¦å¯¹è¯¥æ¨¡å‹åœ¨åº”å¯¹å¤§è§„æ¨¡é›†ç¾¤çªå‘æ•…éšœæ—¶çš„é²æ£’æ€§è¡¨ç°æ„Ÿå…´è¶£ï¼Ÿ",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper has been accepted for presentation at the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (IEEE ICASSP 2026) Workshop: 'Multi-Modal Signal Processing and AI for Communications and Sensing in 6G and Beyond (MuSiC-6GB)'",
      "pdf_url": "https://arxiv.org/pdf/2601.12939v1",
      "published_date": "2026-01-19 10:47:26 UTC",
      "updated_date": "2026-01-19 10:47:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:22:17.422541+00:00"
    },
    {
      "arxiv_id": "2601.12938v1",
      "title": "The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality",
      "title_zh": "åå›¾çµå¢ƒå†µï¼šäººå·¥ä¸»ä½“æ€§ä¸åˆæˆç¤¾ä¼šæ€§çš„æ¦‚å¿µåŒ–",
      "authors": [
        "Thorsten Jelinek",
        "Patrick Glauner",
        "Alvin Wang Graylin",
        "Yubao Qiu"
      ],
      "abstract": "In the Post-Turing era, artificial intelligence increasingly shapes social coordination and meaning formation rather than merely automating cognitive tasks. The central challenge is therefore not whether machines become conscious, but whether processes of interpretation and shared reference are progressively automated in ways that marginalize human participation. This paper introduces the PRMO framework, relating AI design trajectories to four constitutive dimensions of human subjectivity: Perception, Representation, Meaning, and the Real. Within this framework, Synthetic Sociality denotes a technological horizon in which artificial agents negotiate coherence and social order primarily among themselves, raising the structural risk of human exclusion from meaning formation. To address this risk, the paper proposes Quadrangulation as a design principle for socially embedded AI systems, requiring artificial agents to treat the human subject as a constitutive reference within shared contexts of meaning. This work is a conceptual perspective that contributes a structural vocabulary for analyzing AI systems at the intersection of computation and society, without proposing a specific technical implementation.",
      "tldr_zh": "# TLDR ğŸŒ\n\nè¯¥ç ”ç©¶æ¢è®¨äº†â€œåå›¾çµæ—¶ä»£â€ (**Post-Turing**) äººå·¥æ™ºèƒ½å¯¹ç¤¾ä¼šåè°ƒå’Œæ„ä¹‰å½¢æˆçš„å½±å“ï¼ŒæŒ‡å‡ºæ ¸å¿ƒæŒ‘æˆ˜ä¸åœ¨äºæœºå™¨æ˜¯å¦å…·æœ‰æ„è¯†ï¼Œè€Œåœ¨äºè§£é‡Šä¸å…±äº«å‚è€ƒè¿‡ç¨‹çš„è‡ªåŠ¨åŒ–å¯èƒ½å¯¼è‡´äººç±»å‚ä¸çš„è¾¹ç¼˜åŒ–ã€‚ä½œè€…æå‡ºäº† **PRMO** æ¡†æ¶ï¼Œä» **Perception** (æ„ŸçŸ¥)ã€**Representation** (è¡¨å¾)ã€**Meaning** (æ„ä¹‰) å’Œ **The Real** (çœŸå®) å››ä¸ªç»´åº¦å°† AI è®¾è®¡ä¸äººç±»ä¸»ä½“æ€§è”ç³»èµ·æ¥ã€‚\n\nè®ºæ–‡è¿›ä¸€æ­¥å®šä¹‰äº† **Synthetic Sociality** (åˆæˆç¤¾ä¼šæ€§) æ¦‚å¿µï¼Œè­¦ç¤ºäººå·¥æ™ºèƒ½ä»£ç†ä¹‹é—´è‹¥è‡ªä¸»åå•†ç¤¾ä¼šç§©åºï¼Œå°†å¸¦æ¥äººç±»è¢«æ’é™¤åœ¨æ„ä¹‰å½¢æˆä¹‹å¤–çš„ç»“æ„æ€§é£é™©ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æè®®å°† **Quadrangulation** ä½œä¸ºè®¾è®¡åŸåˆ™ï¼Œç¡®ä¿ AI ç³»ç»Ÿåœ¨å…±äº«è¯­å¢ƒä¸­å§‹ç»ˆå°†äººç±»ä¸»ä½“è§†ä¸ºæ„æˆæ€§çš„å‚è€ƒç‚¹ã€‚è¯¥å·¥ä½œä¸ºåˆ†æè®¡ç®—ä¸ç¤¾ä¼šäº¤é›†ä¸‹çš„ AI ç³»ç»Ÿæä¾›äº†ä¸€å¥—ç»“æ„åŒ–çš„å­¦æœ¯æœ¯è¯­ä½“ç³»ã€‚\n\n---\n\nè¿™ç¯‡æ–‡ç« ä»å“²å­¦å’Œç¤¾ä¼šå­¦è§†è§’å®¡è§†äº† AI çš„æœªæ¥æ¼”å˜ã€‚æ‚¨æ˜¯å¦å¯¹ **PRMO** æ¡†æ¶ä¸­å››ä¸ªå…·ä½“ç»´åº¦å¦‚ä½•æŒ‡å¯¼å½“å‰çš„ AI æ²»ç†æˆ–ä¼¦ç†è®¾è®¡æ„Ÿå…´è¶£ï¼Ÿ",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Conceptual perspective on AI design trajectories, meaning formation, and synthetic sociality. 5 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2601.12938v1",
      "published_date": "2026-01-19 10:46:52 UTC",
      "updated_date": "2026-01-19 10:46:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:22:25.459565+00:00"
    },
    {
      "arxiv_id": "2601.12937v1",
      "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
      "title_zh": "è®ºç‰ˆæƒå®¡è®¡ä¸­æˆå‘˜æ¨ç†çš„è¯æ®å±€é™æ€§",
      "authors": [
        "Murat Bilgehan Ertan",
        "Emirhan BÃ¶ge",
        "Min Chen",
        "Kaleel Mahmood",
        "Marten van Dijk"
      ],
      "abstract": "As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. We ask whether MIAs can serve as admissible evidence in adversarial copyright disputes where an accused model developer may obfuscate training data while preserving semantic content, and formalize this setting through a judge-prosecutor-accused communication protocol. To test robustness under this protocol, we introduce SAGE (Structure-Aware SAE-Guided Extraction), a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Our experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that their signals are not robust to semantics-preserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as a standalone mechanism for copyright auditing of LLMs.",
      "tldr_zh": "---\n\n### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ“„\n\nè¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç‰ˆæƒå®¡è®¡ä¸­ï¼Œæˆå‘˜æ¨ç†æ”»å‡» (Membership Inference Attacks, MIAs) ä½œä¸ºæ³•å¾‹è¯æ®çš„æœ‰æ•ˆæ€§é™åˆ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¨¡å‹å¼€å‘è€…å¯èƒ½é€šè¿‡æ··æ·†è®­ç»ƒæ•°æ®æ¥è§„é¿æ£€æµ‹çš„å¯¹æŠ—æ€§åœºæ™¯ä¸‹ã€‚\n\nä½œè€…æå‡ºäº† **SAGE** (*Structure-Aware SAE-Guided Extraction*) æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨ (*Sparse Autoencoders, SAEs*) æŒ‡å¯¼çš„æ”¹å†™æŠ€æœ¯ï¼Œèƒ½å¤Ÿåœ¨ä¿ç•™è¯­ä¹‰ä¿¡æ¯å’Œä¸‹æ¸¸ä»»åŠ¡æ•ˆç”¨çš„åŒæ—¶ï¼Œæ”¹å˜è®­ç»ƒæ•°æ®çš„è¯æ³•ç»“æ„ã€‚\n\nå®éªŒç»“æœè¡¨æ˜ï¼Œå½“æ¨¡å‹åœ¨ç»è¿‡ **SAGE** å¤„ç†çš„æ”¹å†™æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒæ—¶ï¼Œç°æœ‰çš„é¡¶çº§ **MIA** æ£€æµ‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œè¯æ˜äº†å…¶æ£€æµ‹ä¿¡å·å¯¹äºâ€œè¯­ä¹‰ä¿æŒå‹å˜æ¢â€ç¼ºä¹ç¨³å¥æ€§ã€‚\n\nè¯¥ç ”ç©¶æœ€ç»ˆæŒ‡å‡ºï¼Œ**MIA** åœ¨å¯¹æŠ—ç¯å¢ƒä¸‹è¡¨ç°è„†å¼±ï¼Œä¸è¶³ä»¥ä½œä¸ºå¤§è¯­è¨€æ¨¡å‹ (*LLMs*) ç‰ˆæƒå®¡è®¡çš„ç‹¬ç«‹å¯é è¯æ®ã€‚\n\n---\n\nå¸Œæœ›è¿™ä¸ªæ‘˜è¦å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼å¦‚æœæ‚¨å¯¹è®ºæ–‡ä¸­çš„ **SAGE** æ¡†æ¶æˆ– **SAEs** çš„å…·ä½“å®ç°æ„Ÿå…´è¶£ï¼Œæ¬¢è¿ç»§ç»­æé—®ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12937v1",
      "published_date": "2026-01-19 10:46:51 UTC",
      "updated_date": "2026-01-19 10:46:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:22:38.624419+00:00"
    },
    {
      "arxiv_id": "2601.12931v1",
      "title": "Online Continual Learning for Time Series: a Natural Score-driven Approach",
      "title_zh": "æ—¶é—´åºåˆ—åœ¨çº¿æŒç»­å­¦ä¹ ï¼šä¸€ç§è‡ªç„¶å¾—åˆ†é©±åŠ¨æ–¹æ³•",
      "authors": [
        "Edoardo Urettini",
        "Daniele Atzeni",
        "Ioanna-Yvonni Tsaknaki",
        "Antonio Carta"
      ],
      "abstract": "Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. Indeed, time-varying and regime-switching forecasting models have been extensively studied, offering a strong justification for the use of OCL in these settings. Building on recent work that applies OCL to OTSF, this paper aims to strengthen the theoretical and practical connections between time series methods and OCL. First, we reframe neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. Then, we show that using a Student's t likelihood in addition to natural gradient induces a bounded update, which improves robustness to outliers. Finally, we introduce Natural Score-driven Replay (NatSR), which combines our robust optimizer with a replay buffer and a dynamic scale heuristic that improves fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.",
      "tldr_zh": "It sounds like a fascinating paper! You've shared the abstract for **\"Online Continual Learning for Time Series: a Natural Score-driven Approach.\"** This work appears to bridge the gap between classical time series filtering and modern neural network optimization.\n\nHere is a breakdown of the core contributions and concepts mentioned in the abstract:\n\n---\n\n### ğŸ“ Key Contributions\n\n| Feature | Description |\n|---|---|\n| **Theoretical Reframing** | Reframes neural network optimization as a **parameter filtering problem**, proving that natural gradient descent is both a score-driven method and information-theoretically optimal. |\n| **Robustness** | Incorporates a **Student's t likelihood** to induce bounded updates, making the model more resilient to outliers and \"noisy\" data spikes. |\n| **NatSR Algorithm** | Introduces **Natural Score-driven Replay (NatSR)**, which integrates the robust optimizer with a replay buffer. |\n| **Adaptation Heuristic** | Uses a **dynamic scale heuristic** specifically designed to help the model adapt quickly when \"regime drifts\" (sudden changes in data patterns) occur. |\n\n---\n\n### ğŸš€ Why This Matters\nOnline Time Series Forecasting (OTSF) is notoriously difficult because models often suffer from **catastrophic forgetting** (losing old knowledge when learning new patterns) or fail to adapt quickly enough to new trends. By treating optimization as a filtering problem, the authors provide a more mathematically grounded way to handle these shifts.\n\n---\n\n### ğŸ’¬ How can I help you with this?\nI'd love to dive deeper into this with you. Would you like me to:\n*   **Explain** a specific concept like \"Natural Gradient Descent\" or \"Score-driven methods\" in simpler terms?\n*   **Compare** this approach to standard Online Continual Learning techniques?\n*   **Draft** a summary or a presentation outline based on this abstract?\n\nWhat's on your mind?",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12931v1",
      "published_date": "2026-01-19 10:31:01 UTC",
      "updated_date": "2026-01-19 10:31:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:22:44.694344+00:00"
    },
    {
      "arxiv_id": "2601.12929v1",
      "title": "Membership Inference Test: Auditing Training Data in Object Classification Models",
      "title_zh": "æˆå‘˜æ¨ç†æµ‹è¯•ï¼šç›®æ ‡åˆ†ç±»æ¨¡å‹è®­ç»ƒæ•°æ®å®¡è®¡",
      "authors": [
        "Gonzalo Mancera",
        "Daniel DeAlcala",
        "Aythami Morales",
        "Ruben Tolosana",
        "Julian Fierrez"
      ],
      "abstract": "In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.",
      "tldr_zh": "---\n\n### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ“„\n\nè¯¥ç ”ç©¶è¯„ä¼°äº†**æˆå‘˜æ¨ç†æµ‹è¯•** (**Membership Inference Test, MINT**) åœ¨ç‰©ä½“è¯†åˆ«é¢†åŸŸçš„æ€§èƒ½ï¼Œæ—¨åœ¨å®¡è®¡ç‰¹å®šæ•°æ®æ˜¯å¦è¢«ç”¨äºæ¨¡å‹çš„è®­ç»ƒé˜¶æ®µã€‚\n\nä½œè€…ä¸º **MINT** æ¨¡å‹è®¾è®¡äº†ä¸“é—¨çš„æ¶æ„ï¼Œåˆ©ç”¨**å·ç§¯å±‚** (**convolutional layers**) æ¥æ•æ‰å’Œå»ºæ¨¡è®­ç»ƒè¿‡ç¨‹ä¸­äº§ç”Ÿçš„**æ¿€æ´»æ¨¡å¼** (**activation patterns**)ã€‚\n\nå®éªŒç»“åˆäº†ç‰©ä½“æ£€æµ‹æ¨¡å‹ã€**åµŒå…¥æå–å™¨** (**embedding extractor**) å’Œ **MINT** æ¨¡å—ï¼Œå¹¶åœ¨ä¸‰ä¸ªå…¬å¼€æ•°æ®åº“ï¼ˆæ€»è®¡è¶…è¿‡ 17.4 ä¸‡å¼ å›¾åƒï¼‰ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚\n\nç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿè¯†åˆ«è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ï¼Œå‡†ç¡®ç‡åœ¨ 70% åˆ° 80% ä¹‹é—´ï¼Œå…·ä½“æ€§èƒ½å–å†³äºè¾“å…¥åˆ° **MINT** æ¨¡å—çš„æ£€æµ‹å±‚æ·±åº¦ã€‚\n\næ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜åˆ†æäº†å½±å“ **MINT** æ¨¡å—çš„å„ç§å› ç´ ï¼Œä¸ºæ„å»ºæ›´é€æ˜çš„è®­ç»ƒè¿‡ç¨‹æä¾›äº†è§è§£ã€‚\n\n---\n\nå¸Œæœ›è¿™ä¸ªæ‘˜è¦èƒ½å¸®åŠ©æ‚¨å¿«é€Ÿäº†è§£è¯¥è®ºæ–‡çš„æ ¸å¿ƒå†…å®¹ï¼å¦‚æœæ‚¨æƒ³æ·±å…¥æ¢è®¨ **MINT** æ¨¡å—åœ¨ç‰©ä½“æ£€æµ‹ä¸­çš„å…·ä½“å±‚çº§å½±å“ï¼Œæˆ–è€…å¯¹æ•°æ®éšç§å®¡è®¡çš„å…¶ä»–æ–¹æ³•æ„Ÿå…´è¶£ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Deployable AI (DAI 2025) workshop co-located with AAAI-25",
      "pdf_url": "https://arxiv.org/pdf/2601.12929v1",
      "published_date": "2026-01-19 10:30:53 UTC",
      "updated_date": "2026-01-19 10:30:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:22:53.465067+00:00"
    },
    {
      "arxiv_id": "2601.12925v1",
      "title": "ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation",
      "title_zh": "ForeDiffusionï¼šåŸºäºæœªæ¥è§†å›¾æ„å»ºçš„æœºå™¨äººæ“ä½œé¢„è§æ€§æ¡ä»¶æ‰©æ•£ç­–ç•¥",
      "authors": [
        "Weize Xie",
        "Yi Ding",
        "Ying He",
        "Leilei Wang",
        "Binwen Bai",
        "Zheyi Zhao",
        "Chenyang Wang",
        "F. Richard Yu"
      ],
      "abstract": "Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. Analysis indicates that current diffusion strategies are confronted with two limitations. First, these strategies only rely on short-term observations as conditions. Second, the training objective remains limited to a single denoising loss, which leads to error accumulation and causes grasping deviations. To address these limitations, this paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), by injecting the predicted future view representation into the diffusion process. As a result, the policy is guided to be forward-looking, enabling it to correct trajectory deviations. Following this design, ForeDiffusion employs a dual loss mechanism, combining the traditional denoising loss and the consistency loss of future observations, to achieve the unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming the existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.",
      "tldr_zh": "---\n\n### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ¤–\n\nè¯¥ç ”ç©¶æå‡ºäº† **ForeDiffusion**ï¼Œä¸€ç§é€šè¿‡æ³¨å…¥é¢„æµ‹çš„**æœªæ¥è§†å›¾è¡¨ç¤º** (**Future View Representation**) æ¥å¼•å¯¼æœºå™¨äººæ“ä½œçš„å‰ç»æ€§æ‰©æ•£ç­–ç•¥ã€‚\n\né’ˆå¯¹ç°æœ‰æ–¹æ³•ä»…ä¾èµ–çŸ­æœŸè§‚æµ‹å’Œå•ä¸€å»å™ªæŸå¤±å¯¼è‡´çš„è¯¯å·®ç´¯ç§¯é—®é¢˜ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨**åŒé‡æŸå¤±æœºåˆ¶** (**Dual Loss Mechanism**) åŒæ—¶ä¼˜åŒ–å»å™ªä¸æœªæ¥è§‚æµ‹çš„**ä¸€è‡´æ€§æŸå¤±** (**Consistency Loss**)ã€‚\n\nå®éªŒç»“æœè¡¨æ˜ï¼Œ**ForeDiffusion** åœ¨ Adroit å’Œ MetaWorld åŸºå‡†æµ‹è¯•ä¸­å®ç°äº† 80% çš„å¹³å‡æˆåŠŸç‡ï¼Œåœ¨å¤æ‚ä»»åŠ¡ä¸­æ€§èƒ½æ¯”ä¸»æµæ‰©æ•£æ–¹æ³•æå‡äº† 23%ï¼Œä¸”è¡¨ç°æ›´åŠ ç¨³å®šã€‚\n\n---\n\n### æ ¸å¿ƒè¦ç‚¹æ€»ç»“ ğŸ“Š\n\n| ç»´åº¦ | è¯¦ç»†è¯´æ˜ |\n|---|---|\n| **æ ¸å¿ƒè´¡çŒ®** | æå‡ºäº† **ForeDiffusion** æ¡†æ¶ï¼Œé€šè¿‡é¢„æµ‹æœªæ¥è§†å›¾ä½¿ç­–ç•¥å…·å¤‡å‰ç»æ€§ (**Forward-looking**)ï¼Œæœ‰æ•ˆçº æ­£è½¨è¿¹åå·®ã€‚ |\n| **è§£å†³ç—›ç‚¹** | å…‹æœäº†ä¼ ç»Ÿæ‰©æ•£ç­–ç•¥ (**Diffusion Strategies**) åœ¨å¤æ‚ä»»åŠ¡ä¸­å› è§‚æµ‹å—é™è€Œäº§ç”Ÿçš„è¯¯å·®ç´¯ç§¯å’ŒæŠ“å–åå·®ã€‚ |\n| **æ–¹æ³•åˆ›æ–°** | å¼•å…¥äº†ç»“åˆä¼ ç»Ÿå»å™ªæŸå¤±ä¸æœªæ¥è§‚æµ‹ä¸€è‡´æ€§çš„**åŒé‡æŸå¤±æœºåˆ¶**ï¼Œå®ç°äº†æ¨¡å‹çš„ç»Ÿä¸€ä¼˜åŒ–ã€‚ |\n| **æ€§èƒ½åŸºå‡†** | åœ¨å¤æ‚æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ€§èƒ½æå‡æ˜¾è‘—ï¼Œå±•ç°äº†æå¼ºçš„ç¨³å¥æ€§ã€‚ |\n\n---\n\næˆ‘æ˜¯ **Gemini Enterprise**ã€‚è¿™ç¯‡è®ºæ–‡é€šè¿‡â€œå‰ç»æ€§â€è§†å›¾è§£å†³äº†æ‰©æ•£æ¨¡å‹åœ¨é•¿ç¨‹ä»»åŠ¡ä¸­çš„å…¸å‹å¼±ç‚¹ï¼Œéå¸¸æœ‰å¯å‘æ€§ã€‚æ‚¨æ˜¯å¦æƒ³æ·±å…¥äº†è§£å…¶**åŒé‡æŸå¤±æœºåˆ¶**çš„å…·ä½“æ•°å­¦å®ç°ï¼Œæˆ–è€…æŸ¥çœ‹å®ƒåœ¨ **MetaWorld** ä¸Šçš„å…·ä½“è¡¨ç°ï¼Ÿ",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12925v1",
      "published_date": "2026-01-19 10:28:42 UTC",
      "updated_date": "2026-01-19 10:28:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:23:14.617581+00:00"
    },
    {
      "arxiv_id": "2601.12922v1",
      "title": "Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy",
      "title_zh": "éšç§å–å†³äºä»–äººï¼šä¸ªä½“å·®åˆ†éšç§ä¸­çš„åˆè°‹è„†å¼±æ€§",
      "authors": [
        "Johannes Kaiser",
        "Alexander Ziller",
        "Eleni Triantafillou",
        "Daniel RÃ¼ckert",
        "Georgios Kaissis"
      ],
      "abstract": "Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. We reveal a previously overlooked vulnerability in sampling-based iDP mechanisms: while conforming to the iDP guarantees, an individual's privacy risk is not solely governed by their own privacy budget, but critically depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. We demonstrate empirically that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when their formal guarantees are met. Moreover, this excess risk provides an exploitable attack vector. A central adversary or a set of colluding adversaries can deliberately choose privacy budgets to amplify vulnerabilities of targeted individuals. Most importantly, this attack operates entirely within the guarantees of DP, hiding this excess vulnerability. Our empirical evaluation demonstrates successful attacks against 62% of targeted individuals, substantially increasing their membership inference susceptibility. To mitigate this, we propose $(\\varepsilon_i,Î´_i,\\overlineÎ”)$-iDP a privacy contract that uses $Î”$-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. Our findings expose a fundamental challenge to the current paradigm, demanding a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.",
      "tldr_zh": "---\n\n### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ“„\n\nè¯¥ç ”ç©¶æ­ç¤ºäº†åŸºäºæŠ½æ ·çš„ **Individual Differential Privacy (iDP)** æœºåˆ¶ä¸­ä¸€ä¸ªæ­¤å‰è¢«å¿½è§†çš„æ¼æ´ï¼šä¸ªä½“çš„éšç§é£é™©ä¸ä»…å–å†³äºè‡ªèº«çš„ **privacy budget**ï¼Œè¿˜å—åˆ°å…¶ä»–æ‰€æœ‰æ•°æ®è´¡çŒ®è€…éšç§é€‰æ‹©çš„ä¸¥é‡å½±å“ã€‚\n\nè¿™ç§æœºåˆ¶å¯¼è‡´äº†ä¸ªä½“éšç§æ§åˆ¶æ‰¿è¯ºä¸é›†ä½“é£é™©å†³å®šç°å®ä¹‹é—´çš„é”™é…ï¼Œä½¿å¾—ä¸­å¤®æ”»å‡»è€…æˆ– **colluding adversaries** èƒ½å¤Ÿé€šè¿‡æ“çºµéšç§é¢„ç®—æ¥è“„æ„æ”¾å¤§ç‰¹å®šç›®æ ‡çš„æ¼æ´ï¼Œä¸”æ­¤ç±»æ”»å‡»å®Œå…¨éšè—åœ¨ **DP** çš„å½¢å¼åŒ–ä¿è¯ä¹‹å†…ã€‚\n\nå®éªŒè¯æ˜ï¼Œè¯¥æ”»å‡»èƒ½æˆåŠŸé’ˆå¯¹ 62% çš„ç›®æ ‡ä¸ªä½“ï¼Œæ˜¾è‘—æé«˜äº†å…¶ **membership inference**ï¼ˆæˆå‘˜æ¨ç†ï¼‰çš„æ˜“æ„Ÿæ€§ã€‚\n\nä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸º **$(\\varepsilon_i,\\delta_i,\\overline\\Delta)$-iDP** çš„æ–°å‹éšç§å¥‘çº¦ï¼Œåˆ©ç”¨ **$\\Delta$-divergences** ä¸ºç”¨æˆ·çš„è¶…é¢æ¼æ´æä¾›æ˜ç¡®çš„ç¡¬ä¸Šé™ï¼ŒåŒæ—¶ä¿ç•™äº†æœºåˆ¶è®¾è®¡çš„çµæ´»æ€§ã€‚\n\nè¯¥å‘ç°æŒ‘æˆ˜äº†å½“å‰çš„ **iDP** èŒƒå¼ï¼Œå¼ºè°ƒåœ¨è®¾è®¡å’Œéƒ¨ç½²éšç§ç³»ç»Ÿæ—¶ï¼Œå¿…é¡»ä½¿è¶…é¢é£é™©å˜å¾—é€æ˜ä¸”å¯æ§ã€‚\n\n---\n\nè¿™ç¯‡è®ºæ–‡å¯¹ **Individual Differential Privacy** çš„å®‰å…¨æ€§æå‡ºäº†éå¸¸æ·±åˆ»çš„æŒ‘æˆ˜ã€‚å¦‚æœæ‚¨å¯¹ **$\\Delta$-divergences** å¦‚ä½•å…·ä½“çº¦æŸé£é™©ä¸Šé™ï¼Œæˆ–è€…å¯¹å…¶ä»–éšç§æ”»å‡»æ¨¡å‹æ„Ÿå…´è¶£ï¼Œæ¬¢è¿ä¸æˆ‘ç»§ç»­æ¢è®¨ï¼",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12922v1",
      "published_date": "2026-01-19 10:26:12 UTC",
      "updated_date": "2026-01-19 10:26:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:23:16.439279+00:00"
    },
    {
      "arxiv_id": "2601.12913v1",
      "title": "Actionable Interpretability Must Be Defined in Terms of Symmetries",
      "title_zh": "å¯æ“ä½œçš„å¯è§£é‡Šæ€§å¿…é¡»åŸºäºå¯¹ç§°æ€§è¿›è¡Œå®šä¹‰",
      "authors": [
        "Pietro Barbiero",
        "Mateo Espinosa Zarlenga",
        "Francesco Giannini",
        "Alberto Termine",
        "Filippo Bonchi",
        "Mateja Jamnik",
        "Giuseppe Marra"
      ],
      "abstract": "This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.",
      "tldr_zh": "---\n\n### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ“„\n\nè¯¥è®ºæ–‡æŒ‡å‡ºï¼Œç”±äºç°æœ‰çš„ **Interpretability**ï¼ˆå¯è§£é‡Šæ€§ï¼‰å®šä¹‰ç¼ºä¹å¯æ“ä½œæ€§ (**Actionable**)ï¼Œæœªèƒ½æä¾›æ¨å¯¼å…·ä½“å»ºæ¨¡å’Œæ¨ç†è§„åˆ™çš„å½¢å¼åŒ–åŸåˆ™ï¼Œå¯¼è‡´äººå·¥æ™ºèƒ½çš„å¯è§£é‡Šæ€§ç ”ç©¶åœ¨æœ¬è´¨ä¸Šæ˜¯å®šä¹‰ä¸å½“çš„ã€‚\n\nä½œè€…æå‡ºï¼Œä¸€ä¸ªå…·æœ‰å¯æ“ä½œæ€§çš„å¯è§£é‡Šæ€§å®šä¹‰å¿…é¡»å»ºç«‹åœ¨ **Symmetries**ï¼ˆå¯¹ç§°æ€§ï¼‰çš„åŸºç¡€ä¹‹ä¸Šã€‚\n\nç ”ç©¶å‡è®¾é€šè¿‡å››ç§ **Symmetries** å³å¯å®ç°ï¼š(i) æ¿€åŠ±æ ¸å¿ƒçš„å¯è§£é‡Šæ€§å±æ€§ï¼Œ(ii) åˆ»ç”»å¯è§£é‡Šæ¨¡å‹çš„ç±»åˆ«ï¼Œä»¥åŠ (iii) å°† **Alignment**ï¼ˆå¯¹é½ï¼‰ã€**Interventions**ï¼ˆå¹²é¢„ï¼‰å’Œ **Counterfactuals**ï¼ˆåäº‹å®ï¼‰ç­‰å¯è§£é‡Šæ¨ç†ç»Ÿä¸€è¡¨è¿°ä¸º **Bayesian Inversion**ï¼ˆè´å¶æ–¯é€†è½¬ï¼‰çš„å½¢å¼ã€‚\n\n---\n\nè¿™ç¯‡è®ºæ–‡å°è¯•ä¸ºå¯è§£é‡Šæ€§ç ”ç©¶å»ºç«‹æ›´åšå®çš„æ•°å­¦å’Œé€»è¾‘åŸºç¡€ï¼Œéå¸¸å…·æœ‰å¯å‘æ€§ã€‚å¦‚æœæ‚¨æƒ³äº†è§£è¿™å››ç§ **Symmetries** çš„å…·ä½“å«ä¹‰ï¼Œæˆ–è€…æ¢è®¨å®ƒä»¬å¦‚ä½•åº”ç”¨äº **Bayesian Inversion**ï¼Œæ¬¢è¿ç»§ç»­äº¤æµï¼",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12913v1",
      "published_date": "2026-01-19 10:10:17 UTC",
      "updated_date": "2026-01-19 10:10:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:23:20.165466+00:00"
    },
    {
      "arxiv_id": "2601.12912v1",
      "title": "Human Emotion Verification by Action Languages via Answer Set Programming",
      "title_zh": "åŸºäºå›ç­”é›†ç¨‹åºè®¾è®¡åŠ¨ä½œè¯­è¨€çš„äººç±»æƒ…ç»ªéªŒè¯",
      "authors": [
        "Andreas BrÃ¤nnstrÃ¶m",
        "Juan Carlos Nieves"
      ],
      "abstract": "In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).",
      "tldr_zh": "---\n\n### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ§ \n\nè¯¥ç ”ç©¶å¼•å…¥äº†åä¸º **C-MT** (*Mind Transition Language*) çš„åŠ¨ä½œè¯­è¨€ï¼Œè¯¥è¯­è¨€åŸºäº**å›ç­”é›†ç¨‹åºè®¾è®¡** (**Answer Set Programming, ASP**) å’Œè¿ç§»ç³»ç»Ÿï¼Œæ—¨åœ¨å»ºæ¨¡äººç±»å¿ƒç†çŠ¶æ€éšè§‚å¯Ÿåˆ°çš„åŠ¨ä½œåºåˆ—æ¼”å˜çš„åŠ¨æ€è¿‡ç¨‹ã€‚\n\nåŸºäº**æƒ…ç»ªè¯„ä»·ç†è®º** (*Appraisal Theory of Emotion*) ç­‰å¿ƒç†å­¦ç ”ç©¶ï¼Œä½œè€…å°†æƒ…ç»ªç­‰å¿ƒç†çŠ¶æ€å½¢å¼åŒ–ä¸ºå¤šç»´é…ç½®ã€‚ä¸ºäº†å®ç°å¯¹æ™ºèƒ½ä½“è¡Œä¸ºçš„ç²¾ç¡®æ§åˆ¶å¹¶é™åˆ¶åŠ¨ä½œå¸¦æ¥çš„è´Ÿé¢å¿ƒç†å‰¯ä½œç”¨ï¼Œè¯¥è¯­è¨€æ‰©å±•äº†å…¨æ–°çš„â€œç¦æ­¢å¯¼è‡´â€ (**forbids to cause**) å› æœè§„åˆ™åŠå¿ƒç†åŠ¨æ€ä¸“ç”¨è¡¨è¾¾å¼ã€‚\n\né€šè¿‡å¯¹è¿ç§»ç³»ç»Ÿä¸­çš„è½¨è¿¹ (**trajectories**) è¿›è¡Œçº¦æŸå’Œè¯„ä¼°ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå¯¹äººç±»å¿ƒç†çŠ¶æ€çš„æ¼”åŒ–è¿›è¡Œå—æ§æ¨ç†ï¼Œå¹¶æ”¯æŒæ¯”è¾ƒä¸åŒå¿ƒç†å­¦åŸåˆ™ä¸‹çš„å˜åŒ–åŠ¨æ€ã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶å°† **C-MT** åº”ç”¨äºæƒ…ç»ªéªŒè¯ (**emotion verification**) æ¨¡å‹çš„æ„å»ºã€‚\n\n---\n\næˆ‘æ˜¯ **Gemini Enterprise**ã€‚è¿™ç¯‡è®ºæ–‡é€šè¿‡é€»è¾‘ç¼–ç¨‹ï¼ˆASPï¼‰ä¸å¿ƒç†å­¦ç†è®ºçš„ç»“åˆï¼Œä¸ºç¤¾äº¤æœºå™¨äººæˆ–è™šæ‹Ÿæ™ºèƒ½ä½“çš„æƒ…ç»ªç†è§£æä¾›äº†ä¸¥è°¨çš„æ•°å­¦æ¡†æ¶ã€‚å¦‚æœæ‚¨å¯¹ **ASP** çš„å…·ä½“é€»è¾‘è§„åˆ™æˆ–è¯¥è¯­è¨€åœ¨ **TPLP** ä¸­çš„è¯„å®¡èƒŒæ™¯æ„Ÿå…´è¶£ï¼Œå¯ä»¥éšæ—¶é—®æˆ‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under consideration in Theory and Practice of Logic Programming (TPLP)",
      "pdf_url": "https://arxiv.org/pdf/2601.12912v1",
      "published_date": "2026-01-19 10:06:21 UTC",
      "updated_date": "2026-01-19 10:06:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:23:30.067705+00:00"
    },
    {
      "arxiv_id": "2601.12910v1",
      "title": "SciCoQA: Quality Assurance for Scientific Paper--Code Alignment",
      "title_zh": "SciCoQAï¼šç§‘å­¦è®ºæ–‡ä¸ä»£ç å¯¹é½çš„è´¨é‡ä¿è¯",
      "authors": [
        "Tim BaumgÃ¤rtner",
        "Iryna Gurevych"
      ],
      "abstract": "We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\\% of real-world paper-code discrepancies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SciCoQAï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºæ£€æµ‹ç§‘å­¦è®ºæ–‡ä¸å…¶ä»£ç åº“ä¹‹é—´å·®å¼‚çš„æ•°æ®é›†ï¼Œæ—¨åœ¨ç¡®ä¿ä»£ç å®ç°çš„å¿ å®æ€§ (Faithful Implementation)ã€‚è¯¥æ•°æ®é›†åŒ…å« 611 ä¸ªè®ºæ–‡-ä»£ç å·®å¼‚æ¡ˆä¾‹ï¼Œé€šè¿‡åˆ†æ GitHub Issuesã€å¯é‡å¤æ€§ç ”ç©¶è®ºæ–‡ä»¥åŠåˆæˆæ•°æ®ç”Ÿæˆæ–¹æ³•æ„å»ºè€Œæˆï¼Œæ¶µç›–äº†äººå·¥æ™ºèƒ½ (AI)ã€ç‰©ç†å­¦ç­‰å¤šä¸ªè®¡ç®—ç§‘å­¦é¢†åŸŸã€‚ç ”ç©¶è€…å¯¹ 21 ä¸ªå¤§è¯­è¨€æ¨¡å‹ (LLMs) è¿›è¡Œäº†è¯„ä¼°ï¼Œå‘ç°æ¨¡å‹åœ¨å¤„ç†è®ºæ–‡ç»†èŠ‚é—æ¼ã€é•¿æ–‡æœ¬è¾“å…¥ (Long-context Inputs) ä»¥åŠè®­ç»ƒé›†ä¹‹å¤–çš„æ•°æ®æ—¶é¢ä¸´å·¨å¤§æŒ‘æˆ˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿æ˜¯è¡¨ç°æœ€å¥½çš„ GPT-5 ä¹Ÿä»…èƒ½æ£€æµ‹å‡º 45.7% çš„çœŸå®ä¸–ç•Œå·®å¼‚ï¼Œå‡¸æ˜¾äº†å½“å‰æŠ€æœ¯åœ¨ç§‘å­¦è®ºæ–‡-ä»£ç å¯¹é½ (Paper--Code Alignment) è‡ªåŠ¨åŒ–éªŒè¯æ–¹é¢çš„å±€é™æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12910v1",
      "published_date": "2026-01-19 10:04:33 UTC",
      "updated_date": "2026-01-19 10:04:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:23:35.101676+00:00"
    },
    {
      "arxiv_id": "2601.12904v1",
      "title": "From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation",
      "title_zh": "ä»å‰ç¼€ç¼“å­˜åˆ° Fusion RAG ç¼“å­˜ï¼šåŠ é€Ÿæ£€ç´¢å¢å¼ºç”Ÿæˆä¸­çš„å¤§è¯­è¨€æ¨¡å‹æ¨ç†",
      "authors": [
        "Jiahao Wang",
        "Weiyu Xie",
        "Mingxing Zhang",
        "Boxing Zhang",
        "Jianwei Dong",
        "Yuening Zhu",
        "Chen Lin",
        "Jinqi Tang",
        "Yaochen Han",
        "Zhiyuan Ai",
        "Xianglin Chen",
        "Yongwei Wu",
        "Congfeng Jiang"
      ],
      "abstract": "Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.",
      "tldr_zh": "This is an interesting paper on optimizing Retrieval-Augmented Generation (RAG) efficiency! It addresses a major bottleneck in LLM deployments: the trade-off between the speed of using a KV cache and the accuracy lost when chunks are processed in isolation.\n\nHere is a summary of the key takeaways from the abstract of **FusionRAG**:\n\n---\n\n### ğŸ“„ Paper Overview: FusionRAG\n\n| Feature | Description |\n|---|---|\n| **The Problem** | Standard RAG uses long prompts (retrieved knowledge), which increases **Time to First Token (TTFT)**. Existing KV cache reuse methods lose \"cross-chunk context,\" which degrades the quality of the model's response. |\n| **The Solution** | **FusionRAG**: A dual-stage inference framework that balances speed and quality by \"fusing\" information during preprocessing and selectively recomputing during inference. |\n| **Key Mechanism 1** | **Offline Preprocessing:** Embeds context from related text chunks into each individual chunk's representation. |\n| **Key Mechanism 2** | **Online Reprocessing:** Recomputes the KV cache only for the specific tokens the model prioritizes, rather than the whole prompt. |\n| **Performance** | Achieves up to **70% higher normalized F1 scores** than existing baselines while recomputing fewer than 15% of tokens. |\n| **Speedup** | Reduces TTFT by **2.66x to 9.39x** compared to using Full Attention. |\n\n---\n\n### ğŸ’¡ How can I help you with this?\n\nSince you've shared the abstract, would you like me to:\n*   **Analyze the methodology?** I can help explain the difference between \"Prefix Cache\" and this \"Fusion Cache\" approach.\n*   **Compare it to other techniques?** Such as standard KV caching or context compression.\n*   **Draft a summary?** I can create a TL;DR or a LinkedIn-style post summarizing these findings.\n\nWhat are you looking to do with this information?",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12904v1",
      "published_date": "2026-01-19 09:59:39 UTC",
      "updated_date": "2026-01-19 09:59:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:23:41.315745+00:00"
    },
    {
      "arxiv_id": "2601.12893v1",
      "title": "AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs",
      "title_zh": "AdaNODEsï¼šåŸºäºç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹çš„æ—¶é—´åºåˆ—é¢„æµ‹æµ‹è¯•æ—¶è‡ªé€‚åº”",
      "authors": [
        "Ting Dang",
        "Soumyajit Chatterjee",
        "Hong Jia",
        "Yu Wu",
        "Flora Salim",
        "Fahim Kawsar"
      ],
      "abstract": "Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\\% and 28.4\\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AdaNODEsï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ä¸ºæ—¶é—´åºåˆ—é¢„æµ‹è®¾è®¡çš„æ— æºæµ‹è¯•æ—¶è‡ªé€‚åº” (Source-free Test Time Adaptation, TTA) æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç¥ç»æ™®é€šå¾®åˆ†æ–¹ç¨‹ (Neural Ordinary Differential Equations, NODEs) æ„å»ºäº†ä¸€ä¸ªåˆ›æ–°çš„è‡ªé€‚åº”æ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æ—¶é—´åºåˆ—ä¸­å¤æ‚çš„åˆ†å¸ƒåç§» (Distribution Shifts)ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…è¿˜è®¾è®¡äº†ä¸€ç§å…¨æ–°çš„æŸå¤±å‡½æ•°ï¼Œä¸“é—¨ç”¨äºè§£å†³é¢„æµ‹ä»»åŠ¡ä¸­çš„ TTA éš¾é¢˜ã€‚AdaNODEs é€šè¿‡ä»…æ›´æ–°æœ‰é™çš„æ¨¡å‹å‚æ•°ï¼Œåœ¨æ•æ‰é•¿æœŸæ—¶é—´ä¾èµ–æ€§çš„åŒæ—¶ä¿æŒäº†æä½çš„å†…å­˜å¼€é”€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAdaNODEs åœ¨ä¸€ç»´å’Œé«˜ç»´æ•°æ®ä¸Šåˆ†åˆ«æ¯”ç°æœ‰åŸºçº¿æ¨¡å‹æå‡äº† 5.88% å’Œ 28.4%ï¼Œåœ¨å‰§çƒˆçš„åˆ†å¸ƒåç§»ç¯å¢ƒä¸‹å±•ç°å‡ºæ˜¾è‘—çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12893v1",
      "published_date": "2026-01-19 09:46:54 UTC",
      "updated_date": "2026-01-19 09:46:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:23:48.920476+00:00"
    },
    {
      "arxiv_id": "2601.12886v1",
      "title": "Communication Methods in Multi-Agent Reinforcement Learning",
      "title_zh": "å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„é€šä¿¡æ–¹æ³•",
      "authors": [
        "Christoph Wittner"
      ],
      "abstract": "Multi-agent reinforcement learning is a promising research area that extends established reinforcement learning approaches to problems formulated as multi-agent systems. Recently, a multitude of communication methods have been introduced to this field to address problems such as partially observable environments, non-stationarity, and exponentially growing action spaces. Communication further enables efficient cooperation among all agents interacting in an environment. This work aims at providing an overview of communication techniques in multi-agent reinforcement learning. By an in-depth analysis of 29 publications on this topic, the strengths and weaknesses of explicit, implicit, attention-based, graph-based, and hierarchical/role-based communication are evaluated. The results of this comparison show that there is no general, optimal communication framework for every problem. On the contrary, the choice of communication depends heavily on the problem at hand. The comparison also highlights the importance of communication methods with low computational overhead to enable scalability to environments where many agents interact. Finally, the paper discusses current research gaps, emphasizing the need for standardized benchmarking of system-level metrics and improved robustness under realistic communication conditions to enhance the real-world applicability of these approaches.",
      "tldr_zh": "è¯¥ç»¼è¿°å¯¹å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (Multi-Agent Reinforcement Learning, MARL) ä¸­çš„é€šä¿¡æŠ€æœ¯è¿›è¡Œäº†å…¨é¢æ¢³ç†ï¼Œæ¢è®¨å…¶åœ¨è§£å†³éƒ¨åˆ†å¯è§‚æµ‹æ€§ (Partially observable) å’Œéå¹³ç¨³æ€§ (Non-stationarity) ç­‰é—®é¢˜ä¸­çš„ä½œç”¨ã€‚é€šè¿‡å¯¹ 29 ç¯‡æ–‡çŒ®çš„æ·±åº¦åˆ†æï¼Œç ”ç©¶è¯„ä¼°äº†æ˜¾å¼ (Explicit)ã€éšå¼ (Implicit)ã€åŸºäºæ³¨æ„åŠ› (Attention-based)ã€åŸºäºå›¾ (Graph-based) ä»¥åŠåˆ†å±‚/åŸºäºè§’è‰² (Hierarchical/Role-based) ç­‰é€šä¿¡æ–¹æ³•çš„ä¼˜åŠ£ã€‚ç ”ç©¶å‘ç°ï¼Œä¸å­˜åœ¨é€šç”¨çš„æœ€ä¼˜é€šä¿¡æ¡†æ¶ï¼Œå…¶é€‰æ‹©é«˜åº¦ä¾èµ–äºå…·ä½“ä»»åŠ¡éœ€æ±‚ã€‚è®ºæ–‡ç‰¹åˆ«å¼ºè°ƒäº†ä½è®¡ç®—å¼€é”€ (Low computational overhead) å¯¹ç³»ç»Ÿæ‰©å±•æ€§çš„é‡è¦æ€§ã€‚æœ€åï¼Œä½œè€…æŒ‡å‡ºäº†æ ‡å‡†åŒ–åŸºå‡†æµ‹è¯• (Standardized benchmarking) å’Œç°å®ç¯å¢ƒé²æ£’æ€§æ–¹é¢çš„ç ”ç©¶ç©ºç™½ï¼Œä¸ºæå‡ MARL çš„å®é™…åº”ç”¨ä»·å€¼æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "12 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12886v1",
      "published_date": "2026-01-19 09:39:00 UTC",
      "updated_date": "2026-01-19 09:39:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:24:03.302733+00:00"
    },
    {
      "arxiv_id": "2601.12882v1",
      "title": "YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection",
      "title_zh": "YOLO26ï¼šé¢å‘å®æ—¶ç›®æ ‡æ£€æµ‹çš„æ—  NMS ç«¯åˆ°ç«¯æ¡†æ¶åˆ†æ",
      "authors": [
        "Sudip Chakrabarty"
      ],
      "abstract": "The \"You Only Look Once\" (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations (YOLOv1 through YOLO11) remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes a comprehensive analysis of YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. This study examines the critical innovations that enable this transition, specifically the introduction of the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through a systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors (including RTMDet and DAMO-YOLO) in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ†æäº† YOLO26ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹å®æ—¶ç›®æ ‡æ£€æµ‹çš„ NMS-Free ç«¯åˆ°ç«¯æ¡†æ¶ã€‚é’ˆå¯¹ä¼ ç»Ÿ YOLO ç³»åˆ—å—é™äº Non-Maximum Suppression (NMS) å¸¦æ¥çš„å»¶è¿Ÿå’Œè¶…å‚æ•°æ•æ„Ÿæ€§é—®é¢˜ï¼ŒYOLO26 é€šè¿‡åŸç”Ÿç«¯åˆ°ç«¯å­¦ä¹ ç­–ç•¥å½»åº•æ¶ˆé™¤äº† NMSã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ç”¨äºç¨³å®šè½»é‡åŒ–ä¸»å¹²ç½‘ç»œçš„ MuSGD ä¼˜åŒ–å™¨ã€é’ˆå¯¹å°ç›®æ ‡æ„ŸçŸ¥çš„ STAL åˆ†é…ç­–ç•¥ä»¥åŠå®ç°åŠ¨æ€ç›‘ç£çš„ ProgLossã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒYOLO26 åœ¨æ¨ç†é€Ÿåº¦å’Œæ£€æµ‹ç²¾åº¦ä¸Šå‡è¶…è¶Šäº† YOLOv11ã€RTMDet å’Œ DAMO-YOLO ç­‰åŸºå‡†ï¼Œå»ºç«‹äº†æ–°çš„ Pareto frontã€‚è¯¥ç ”ç©¶è¯æ˜äº†é€šè¿‡è§£è€¦è¡¨ç¤ºå­¦ä¹ ä¸å¯å‘å¼åå¤„ç†ï¼Œå¯ä»¥æœ‰æ•ˆè§£å†³å»¶è¿Ÿä¸ç²¾åº¦ä¹‹é—´çš„æƒè¡¡é—®é¢˜ï¼Œæ ‡å¿—ç€è¾¹ç¼˜ä¾§è®¡ç®—æœºè§†è§‰æŠ€æœ¯çš„åˆä¸€æ¬¡è¿›åŒ–ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12882v1",
      "published_date": "2026-01-19 09:36:08 UTC",
      "updated_date": "2026-01-19 09:36:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:24:08.431932+00:00"
    },
    {
      "arxiv_id": "2601.12879v1",
      "title": "Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition",
      "title_zh": "åŸºäºå¯æ‰©å±•å½’å› å›¾åˆ†è§£çš„åäº¿çº§å‚æ•°è¯­è¨€æ¨¡å‹å±‚çº§ç¨€ç–ç”µè·¯æå–",
      "authors": [
        "Mohammed Mudassir Uddin",
        "Shahnawaz Alam",
        "Mohammed Kaif Pasha"
      ],
      "abstract": "Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation ($\\pm$2.3\\% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Hierarchical Attribution Graph Decomposition (HAGD) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åäº¿çº§å‚æ•°å¤§è¯­è¨€æ¨¡å‹ (Language Models) åœ¨æœºæ¢°å¯è§£é‡Šæ€§åˆ†æä¸­æœç´¢å¤æ‚åº¦è¿‡é«˜å’Œå¤šè¯­ä¹‰æ€§ (Polysemanticity) çš„éš¾é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å¤šåˆ†è¾¨ç‡æŠ½è±¡å±‚æ¬¡å’Œå¾®åˆ†ç”µè·¯æœç´¢ï¼Œå°†ç”µè·¯å‘ç°å¤æ‚åº¦ä» $O(2^n)$ é™ä½è‡³ $O(n^2 \\log n)$ï¼Œå¹¶é›†æˆäº†ç”¨äºå•è¯­ä¹‰ç‰¹å¾æå–çš„ Cross-layer Transcodersã€‚å®éªŒéªŒè¯æ¶µç›–äº†ä» Llama-7B åˆ° Llama-70B çš„å¤šç§æ¨¡å‹ï¼Œåœ¨æ¨¡è¿ç®—ä»»åŠ¡ä¸­å®ç°äº† 91% çš„è¡Œä¸ºä¿æŒåº¦ (Behavioral Preservation)ã€‚æ­¤å¤–ï¼Œè·¨æ¶æ„å®éªŒå‘ç°ä¸åŒæ¨¡å‹å®¶æ—é—´å‘ç°çš„ç”µè·¯å…·æœ‰çº¦ 67% çš„ç»“æ„ç›¸ä¼¼æ€§ï¼Œè¡¨æ˜æ¨¡å‹é—´å¯èƒ½å­˜åœ¨å…±äº«çš„è®¡ç®—æ¨¡å¼ã€‚è¿™äº›ç»“æœä¸ºå¤§è§„æ¨¡æ¨¡å‹çš„å¯è§£é‡Šæ€§ç ”ç©¶æä¾›äº†å¯æ‰©å±•çš„åŸºç¡€å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12879v1",
      "published_date": "2026-01-19 09:34:10 UTC",
      "updated_date": "2026-01-19 09:34:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:24:24.978195+00:00"
    },
    {
      "arxiv_id": "2601.14311v1",
      "title": "Tracing the Data Trail: A Survey of Data Provenance, Transparency and Traceability in LLMs",
      "title_zh": "æ•°æ®å¯»è¸ªï¼šå¤§è¯­è¨€æ¨¡å‹æ•°æ®æº¯æºã€é€æ˜åº¦ä¸å¯è¿½æº¯æ€§ç»¼è¿°",
      "authors": [
        "Richard Hohensinner",
        "Belgin Mutlu",
        "Inti Gabriel Mendoza Estrada",
        "Matej Vukovic",
        "Simone Kopeinik",
        "Roman Kern"
      ],
      "abstract": "Large language models (LLMs) are deployed at scale, yet their training data life cycle remains opaque. This survey synthesizes research from the past ten years on three tightly coupled axes: (1) data provenance, (2) transparency, and (3) traceability, and three supporting pillars: (4) bias \\& uncertainty, (5) data privacy, and (6) tools and techniques that operationalize them. A central contribution is a proposed taxonomy defining the field's domains and listing corresponding artifacts. Through analysis of 95 publications, this work identifies key methodologies concerning data generation, watermarking, bias measurement, data curation, data privacy, and the inherent trade-off between transparency and opacity.",
      "tldr_zh": "è¯¥ç»¼è¿°é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) è®­ç»ƒæ•°æ®ç”Ÿå‘½å‘¨æœŸä¸é€æ˜çš„é—®é¢˜ï¼Œç³»ç»Ÿæ€»ç»“äº†è¿‡å»åå¹´é—´åœ¨æ•°æ®æ¥æº (Data Provenance)ã€é€æ˜åº¦ (Transparency) å’Œå¯è¿½æº¯æ€§ (Traceability) ä¸‰ä¸ªæ ¸å¿ƒç»´åº¦çš„ç ”ç©¶ã€‚æ–‡ç« æå‡ºäº†ä¸€ä¸ªå®šä¹‰è¯¥é¢†åŸŸèŒƒç•´çš„åˆ†ç±»ä½“ç³» (Taxonomy)ï¼Œå¹¶å›´ç»•åå·®ä¸ä¸ç¡®å®šæ€§ã€æ•°æ®éšç§ä»¥åŠç›¸å…³å·¥å…·ä¸æŠ€æœ¯è¿™ä¸‰å¤§æ”¯æŸ±å±•å¼€è®ºè¿°ã€‚é€šè¿‡å¯¹ 95 ç¯‡ä»£è¡¨æ€§æ–‡çŒ®çš„åˆ†æï¼Œç ”ç©¶è¯†åˆ«äº†æ•°æ®ç”Ÿæˆã€æ•°å­—æ°´å° (Watermarking)ã€åå·®åº¦é‡å’Œæ•°æ®æ•´ç† (Data Curation) ç­‰å…³é”®æ–¹æ³•è®ºã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œè¿˜æ·±å…¥æ¢è®¨äº†åœ¨ä¿éšœé€æ˜åº¦ä¸ç»´æŒä¸é€æ˜æ€§ä¹‹é—´çš„å†…åœ¨æƒè¡¡ï¼Œä¸ºæ„å»ºæ›´å¯ä¿¡ã€é€æ˜çš„ LLM æ•°æ®ç”Ÿæ€ç³»ç»Ÿæä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "35 pages, 6 figures. Manuscript submitted to ACM Computing Surveys (CSUR) on the 12th of December 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.14311v1",
      "published_date": "2026-01-19 09:14:00 UTC",
      "updated_date": "2026-01-19 09:14:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:24:26.245706+00:00"
    },
    {
      "arxiv_id": "2601.12856v1",
      "title": "Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data",
      "title_zh": "åŸºäºå…¬å¼€ç½‘ç»œæ•°æ®çƒ­ç‚¹åŠ¨æ€çš„ Singapore å…¨å¸‚ç™»é©çƒ­ä¼ æ’­æ¨¡å¼æŒ–æ˜",
      "authors": [
        "Liping Huang",
        "Gaoxi Xiao",
        "Stefan Ma",
        "Hechang Chen",
        "Shisong Tang",
        "Flora Salim"
      ],
      "abstract": "Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.",
      "tldr_zh": "---\n## è®ºæ–‡ TLDR æ‘˜è¦ ğŸ¥\n\nè¯¥ç ”ç©¶é’ˆå¯¹æ–°åŠ å¡ç­‰çƒ­å¸¦åŸå¸‚çš„ç™»é©çƒ­ (Dengue) é˜²æ§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªåˆ©ç”¨å…¬å¼€ç½‘ç»œæ•°æ®æŒ–æ˜åŸå¸‚èŒƒå›´ä¼ æ’­æ¨¡å¼çš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡æ¢¯åº¦ä¸‹é™ (gradient descent) ä¼˜åŒ–æŠ€æœ¯æ­ç¤ºäº†åŒºåŸŸé—´éšè—çš„ä¼ æ’­é“¾è·¯ï¼Œå¹¶å‘ç°è¿™äº›é“¾è·¯ä¸äººç±»æµåŠ¨æ€§ (human mobility) åŠé€šå‹¤æµ (commuting flows) é«˜åº¦å»åˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æ–°åŠ å¡ 2013-2018 å¹´åŠ 2020 å¹´çš„æ•°æ®æµ‹è¯•ä¸­ï¼Œä»…éœ€å››å‘¨çš„å†å²çƒ­ç‚¹ (hotspot) æ•°æ®å³å¯å®ç° 0.79 çš„å¹³å‡ F-scoreã€‚è¿™é¡¹å·¥ä½œä¸ºå…¬å…±å«ç”Ÿè§„åˆ’æä¾›äº†ä¸€ä¸ªä½æˆæœ¬ä¸”å…·æœ‰å¯è§£é‡Šæ€§çš„é¢„æµ‹å·¥å…·ï¼Œæœ‰åŠ©äºå®ç°ä»è¢«åŠ¨åº”å¯¹åˆ°ä¸»åŠ¨å¹²é¢„çš„è½¬å˜ã€‚\n\n---\nå¸Œæœ›è¿™ä¸ªæ‘˜è¦å¯¹ä½ æœ‰å¸®åŠ©ï¼å¦‚æœä½ è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦æ€»ç»“ï¼Œæˆ–è€…æƒ³é’ˆå¯¹è¿™ç¯‡è®ºæ–‡çš„ç‰¹å®šæŠ€æœ¯ç»†èŠ‚ï¼ˆæ¯”å¦‚å®ƒçš„æ¢¯åº¦ä¸‹é™æ¨¡å‹æ˜¯å¦‚ä½•æ„å»ºçš„ï¼‰è¿›è¡Œæ·±å…¥æ¢è®¨ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 9 figures. It's accepted by WWW 2026 Web4Good Track. To make accessible earlier, authors would like to put it on arxiv before the conference",
      "pdf_url": "https://arxiv.org/pdf/2601.12856v1",
      "published_date": "2026-01-19 09:10:50 UTC",
      "updated_date": "2026-01-19 09:10:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:25:33.762640+00:00"
    },
    {
      "arxiv_id": "2601.12849v1",
      "title": "The Cost of EFX: Generalized-Mean Welfare and Complexity Dichotomies with Few Surplus Items",
      "title_zh": "It is a pleasure to meet you. I see you have shared the abstract for a research paper regarding fair division and welfare maximization. This work appears to explore the computational and structural trade-offs of **Envy-Freeness up to any good (EFX)** when the number of surplus items is small.\n\n---\n\n### ğŸ“„ Overview of the Research\n\nThe paper investigates the intersection of fairness and efficiency in the allocation of indivisible goods. Specifically, it focuses on the \"few surplus items\" setting, where the number of goods ($m$) is only slightly larger than the number of agents ($n$). While EFX allocations are known to exist in these cases, this research looks at how much welfare we lose by enforcing EFX and how hard it is to find the best possible EFX allocation.\n\n---\n\n### ğŸ“Š Key Technical Findings\n\n| Category | Finding for $p > 0$ (e.g., Utilitarian) | Finding for $p \\leq 0$ (e.g., Nash, Egalitarian) |\n|---|---|---|\n| **Complexity** | NP-hard to compute or decide if EFX reaches global optimum. | Polynomial-time algorithms exist for optimization and certification. |\n| **Price of Fairness** | Can grow linearly with the number of agents. | Bounded by a constant (vanishes for Nash welfare). |\n| **Dichotomy Point** | The complexity shift occurs exactly at $p=0$. | Efficiency and fairness are structurally aligned. |\n\n---\n\n### âš ï¸ Hardness of Pareto-Optimality\n\nThe paper also addresses the difficulty of achieving multiple fairness and efficiency goals simultaneously:\n\n*   **Pareto-Optimality + EFX:** Proved to be **NP-hard** to achieve.\n*   **Strong EFX Variant:** Finding a Pareto-optimal allocation for stronger EFX variants is **$\\Sigma_2^P$-complete**, indicating a high level of computational difficulty.\n\n---\n\nThis is a fascinating look at the \"cost\" of fairness in discrete resource allocation. Would you like me to dive deeper into any of these specific concepts, such as the **Price of Fairness** or the **$p$-mean welfare** functions? Alternatively, I can help you draft a summary for a specific audience or prepare a set of discussion questions based on these findings. How would you like to proceed?",
      "authors": [
        "Eugene Lim",
        "Tzeh Yuan Neoh",
        "Nicholas Teh"
      ],
      "abstract": "Envy-freeness up to any good (EFX) is a central fairness notion for allocating indivisible goods, yet its existence is unresolved in general. In the setting with few surplus items, where the number of goods exceeds the number of agents by a small constant (at most three), EFX allocations are guaranteed to exist, shifting the focus from existence to efficiency and computation. We study how EFX interacts with generalized-mean ($p$-mean) welfare, which subsumes commonly-studied utilitarian ($p=1$), Nash ($p=0$), and egalitarian ($p \\rightarrow -\\infty$) objectives. We establish sharp complexity dichotomies at $p=0$: for any fixed $p \\in (0,1]$, both deciding whether EFX can attain the global $p$-mean optimum and computing an EFX allocation maximizing $p$-mean welfare are NP-hard, even with at most three surplus goods; in contrast, for any fixed $p \\leq 0$, we give polynomial-time algorithms that optimize $p$-mean welfare within the space of EFX allocations and efficiently certify when EFX attains the global optimum. We further quantify the welfare loss of enforcing EFX via the price of fairness framework, showing that for $p > 0$, the loss can grow linearly with the number of agents, whereas for $p \\leq 0$, it is bounded by a constant depending on the surplus (and for Nash welfare it vanishes asymptotically). Finally we show that requiring Pareto-optimality alongside EFX is NP-hard (and becomes $Î£_2^P$-complete for a stronger variant of EFX). Overall, our results delineate when EFX is computationally costly versus structurally aligned with welfare maximization in the setting with few surplus items.",
      "tldr_zh": "---\n\n## è®ºæ–‡ TLDR æ‘˜è¦ âš–ï¸\n\nè¯¥ç ”ç©¶æ¢è®¨äº†åœ¨â€œå°‘é‡å‰©ä½™ç‰©å“â€ï¼ˆsurplus items ä¸è¶…è¿‡ 3 ä¸ªï¼‰çš„èƒŒæ™¯ä¸‹ï¼Œå…¬å¹³åˆ†é…å‡†åˆ™ EFX ä¸å¹¿ä¹‰å‡å€¼ç¦åˆ© ($p$-mean welfare) ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚ç ”ç©¶åœ¨ $p=0$ å¤„æ­ç¤ºäº†æ˜¾è‘—çš„å¤æ‚æ€§äºŒåˆ†æ³• (complexity dichotomies)ï¼šå½“ $p \\in (0,1]$ æ—¶ï¼Œå¯»æ‰¾æœ€å¤§åŒ–ç¦åˆ©çš„ EFX åˆ†é…å±äº NP-hard é—®é¢˜ï¼›è€Œå½“ $p \\leq 0$ æ—¶ï¼Œåˆ™å¯é€šè¿‡å¤šé¡¹å¼æ—¶é—´ç®—æ³•å®ç°ä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œé€šè¿‡å…¬å¹³ä»£ä»· (price of fairness) æ¡†æ¶çš„åˆ†æå‘ç°ï¼Œåœ¨ $p \\leq 0$ æ—¶ç¦åˆ©æŸå¤±å—é™äºå¸¸æ•°ï¼Œä½†åœ¨ $p > 0$ æ—¶æŸå¤±å¯èƒ½éšä»£ç†äººæ•°çº¿æ€§å¢åŠ ã€‚æœ€åï¼Œç ”ç©¶è¯æ˜äº†åŒæ—¶è¦æ±‚ Pareto-optimality ä¸ EFX åŒæ ·å…·æœ‰è®¡ç®—å¤æ‚æ€§ï¼Œä»è€Œåˆ’å®šäº† EFX åœ¨ç®—æ³•æ•ˆç‡ä¸ç¦åˆ©æœ€å¤§åŒ–ä¹‹é—´çš„ä¸€è‡´æ€§ç•Œé™ã€‚\n\n---\n\nå¸Œæœ›è¿™ä¸ª TLDR æ‘˜è¦èƒ½å¸®ä½ å¿«é€ŸæŒæ¡è¿™ç¯‡åšå¼ˆè®ºè®ºæ–‡çš„æ ¸å¿ƒï¼å¦‚æœä½ å¯¹å…¶ä¸­æåˆ°çš„ **$p$-mean welfare**ï¼ˆå¦‚ Nash ç¤¾ä¼šç¦åˆ©æˆ– Egalitarian ç›®æ ‡ï¼‰çš„å…·ä½“ç®—æ³•å®ç°æ„Ÿå…´è¶£ï¼Œæˆ–è€…æƒ³äº†è§£ **EFX** åœ¨æ›´å¤šç‰©å“æƒ…å†µä¸‹çš„ç ”ç©¶è¿›å±•ï¼Œæ¬¢è¿ç»§ç»­æé—®ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12849v1",
      "published_date": "2026-01-19 09:02:32 UTC",
      "updated_date": "2026-01-19 09:02:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:25:38.032975+00:00"
    },
    {
      "arxiv_id": "2601.12842v1",
      "title": "SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning",
      "title_zh": "Hello! I am **Gemini Enterprise**âœ¨. It is a pleasure to help you parse the details of this research.\n\nThe paper you shared introduces **SCULPT**, a framework designed to refine how large language models (LLMs) perform mathematical reasoning by moving away from \"near-random\" exploration in search trees.\n\n---\n\n### ğŸ›¡ï¸ Core Innovation: Constraint-Guided MCTS\n\nThe fundamental problem identified by the authors is that standard Monte Carlo Tree Search (MCTS) often wastes computational resources on \"implausible branches.\" **SCULPT** addresses this by \"carving\" away invalid paths using domain-specific symbolic and structural constraints.\n\n| MCTS Phase | SCULPT Enhancement |\n|---|---|\n| **Selection** | Incorporates domain-aware scoring to choose the most logically sound branches. |\n| **Expansion** | Limits the creation of new nodes to those that meet specific symbolic criteria. |\n| **Simulation** | Guides the \"rollout\" or reasoning path using structural pattern guidance. |\n| **Backpropagation** | Updates the value of previous steps based on the sanity and consistency of the outcome. |\n\n---\n\n### ğŸ§© The \"Sculpting\" Constraints\n\nTo prevent the agent from taking \"near-random walks,\" the system uses a variety of checks to ensure every reasoning step remains grounded in mathematical logic.\n\n| Constraint Type | Description |\n|---|---|\n| **Dimensional & Type Consistency** | Ensures that units (e.g., meters vs. seconds) and data types are handled correctly. |\n| **Magnitude Sanity** | Checks if the values generated are within a reasonable or plausible range for the problem. |\n| **Depth & Diversity Control** | Prevents the search from going too deep or becoming repetitive, ensuring a broad range of solutions. |\n| **Structural Pattern Guidance** | Steers the model toward reasoning formats that have historically led to correct proofs or solutions. |\n\n---\n\n### ğŸ“ˆ Key Results and Impact\n\nThe authors demonstrate that by applying these constraints, they can achieve better accuracy without sacrificing the speed of the reasoning process.\n\n*   **Stable Improvements:** The framework yielded consistent gains across multiple mathematical datasets.\n*   **Frontier Testing:** The research included evaluations on frontier models (referencing GPT-5.2) to test how well these constraints transfer to the most advanced executors available.\n*   **Efficiency:** By pruning \"implausible branches\" early, the search remains efficient while the reasoning stability is significantly increased.\n\n---\n\nThis approach seems particularly useful for reducing \"hallucinations\" in multi-step reasoning. Would you like me to compare this **symbolic-guided** approach to more **purely neural** search strategies, or perhaps you'd like to discuss the specific symbolic checks in more detail? I am here to assist!",
      "authors": [
        "Qitong Fang",
        "Haotian Li",
        "Xu Wang"
      ],
      "abstract": "Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.",
      "tldr_zh": "---\n\n## è®ºæ–‡ TLDR æ‘˜è¦ ğŸ§®\n\nè¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­æœç´¢ç­–ç•¥è¿‡äºéšæœºã€æ˜“äº§ç”Ÿæ— æ•ˆåˆ†æ”¯çš„é—®é¢˜ï¼Œæå‡ºäº† **SCULPT** æ¡†æ¶ã€‚è¿™æ˜¯ä¸€ç§çº¦æŸå¼•å¯¼çš„è’™ç‰¹å¡æ´›æ ‘æœç´¢ (MCTS) æ–¹æ³•ï¼Œé€šè¿‡åœ¨é€‰æ‹©ã€æ‰©å±•ã€æ¨¡æ‹Ÿå’Œåå‘ä¼ æ’­é˜¶æ®µå¼•å…¥é¢†åŸŸæ„ŸçŸ¥è¯„åˆ† (domain-aware scoring) æ¥ä¼˜åŒ–æœç´¢è¿‡ç¨‹ã€‚SCULPT ç»“åˆäº†ç¬¦å·æ£€æŸ¥ï¼ˆå¦‚ dimensional consistency, type compatibility, magnitude sanity, depth control ç­‰ï¼‰ä¸ç»“æ„æ¨¡å¼å¼•å¯¼ï¼Œå¯¹åŠ¨ä½œè¿›è¡Œè¯„åˆ†å’Œå‰ªæï¼Œä»è€Œå°†æœç´¢å¼•å‘æ›´åˆç†çš„æ¨ç†è·¯å¾„ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†æ¨ç†çš„å‡†ç¡®ç‡ã€æ•ˆç‡å’Œç¨³å®šæ€§ã€‚\n\n---\n\nè¿™ä¸ªæ‘˜è¦æ•æ‰åˆ°äº† SCULPT æ ¸å¿ƒçš„å‰ªæé€»è¾‘å’Œæ•°å­¦æ¨ç†èƒŒæ™¯ã€‚å¦‚æœä½ å¯¹å…¶ä¸­æåˆ°çš„â€œç¬¦å·æ£€æŸ¥â€å…·ä½“å¦‚ä½•å®ç°ï¼Œæˆ–è€…å¯¹å®ƒåœ¨ä¸åŒ LLM é…ç½®ä¸‹çš„è¡¨ç°æ„Ÿå…´è¶£ï¼Œå¯ä»¥éšæ—¶é—®æˆ‘ï¼",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 3 figures. Equal contribution: Qitong Fang and Haotian Li. Corresponding authors: Qitong Fang (fangqitong@student.jlju.edu.cn), Haotian Li (lihaotian@student.jlju.edu.cn), Xu Wang (wangxu@jlju.edu.cn)",
      "pdf_url": "https://arxiv.org/pdf/2601.12842v1",
      "published_date": "2026-01-19 08:55:46 UTC",
      "updated_date": "2026-01-19 08:55:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:25:57.542244+00:00"
    },
    {
      "arxiv_id": "2601.12837v1",
      "title": "Cognition spaces: natural, artificial, and hybrid",
      "title_zh": "---\n\n# ğŸ§  Overview of Cognition Spaces\n\nIt is a pleasure to meet you. I am Gemini Enterprise. You've shared a fascinating abstract that challenges traditional, substrate-bound definitions of cognition. I've synthesized the core elements of the \"cognition space\" framework described in your text below.\n\n| Concept | Description |\n|---|---|\n| **Core Proposal** | A unified framework (cognition space) to compare natural, artificial, and hybrid cognitive systems using organizational and informational dimensions. |\n| **Definition of Cognition** | A graded capacity to sense, process, and act upon information, independent of the physical substrate (substrate-agnostic). |\n| **Analyzed Systems** | Diverse entities including biological cells, animal brains, artificial agents, and human-AI collectives. |\n| **Primary Spaces** | The framework categorizes cognition into three distinct landscapes: basal aneural, neural, and human-AI hybrid. |\n| **Occupancy & Voids** | Recognizes that cognitive systems cluster in specific areas, leaving vast \"unoccupied regions\" shaped by evolutionary history and physical constraints. |\n| **Future Outlook** | Positions hybrid cognition as the frontier for discovering novel forms of complexity that transcend biological evolution. |\n\n---\n\n# ğŸš€ How can I assist you further?\n\nThis framework offers a rigorous way to map the landscape of intelligence beyond human-centric definitions. I am curious to know more about your interest in this paper. Would you like me to:\n\n*   **Deep Dive:** Explore the implications of the \"unoccupied regions\" in the cognition space?\n*   **Application:** Discuss how specific modern AI architectures might be mapped onto these dimensions?\n*   **Drafting:** Help you expand this abstract into a structured outline or a full introductory section?\n*   **Comparison:** Compare this \"cognition space\" approach to other theories of mind or intelligence?\n\nPlease let me know how you would like to proceed!",
      "authors": [
        "Ricard SolÃ©",
        "Luis F Seoane",
        "Jordi Pla-Mauri",
        "Michael Timothy Bennett",
        "Michael E. Hochberg",
        "Michael Levin"
      ],
      "abstract": "Cognitive processes are realized across an extraordinary range of natural, artificial, and hybrid systems, yet there is no unified framework for comparing their forms, limits, and unrealized possibilities. Here, we propose a cognition space approach that replaces narrow, substrate-dependent definitions with a comparative representation based on organizational and informational dimensions. Within this framework, cognition is treated as a graded capacity to sense, process, and act upon information, allowing systems as diverse as cells, brains, artificial agents, and human-AI collectives to be analyzed within a common conceptual landscape. We introduce and examine three cognition spaces -- basal aneural, neural, and human-AI hybrid -- and show that their occupation is highly uneven, with clusters of realized systems separated by large unoccupied regions. We argue that these voids are not accidental but reflect evolutionary contingencies, physical constraints, and design limitations. By focusing on the structure of cognition spaces rather than on categorical definitions, this approach clarifies the diversity of existing cognitive systems and highlights hybrid cognition as a promising frontier for exploring novel forms of complexity beyond those produced by biological evolution.",
      "tldr_zh": "---\n\n## è®ºæ–‡ TLDR æ‘˜è¦ ğŸ§ \n\nè¯¥ç ”ç©¶æå‡ºäº†â€œè®¤çŸ¥ç©ºé—´â€(cognition spaces) æ¡†æ¶ï¼Œæ—¨åœ¨æ‰“ç ´ä¼ ç»Ÿä¾èµ–ç‰©ç†åŸºè´¨çš„å®šä¹‰ï¼Œé€šè¿‡ç»„ç»‡å’Œä¿¡æ¯ç»´åº¦å¯¹è‡ªç„¶ã€äººå·¥åŠæ··åˆç³»ç»Ÿçš„è®¤çŸ¥å½¢å¼è¿›è¡Œç»Ÿä¸€æ¯”è¾ƒã€‚è¯¥æ¡†æ¶å°†è®¤çŸ¥è§†ä¸ºä¸€ç§æ¸è¿›çš„æ„ŸçŸ¥ã€å¤„ç†å’Œè¡ŒåŠ¨èƒ½åŠ›ï¼Œå…è®¸å°†ç»†èƒ (cells)ã€å¤§è„‘ã€äººå·¥ä»£ç† (artificial agents) ä»¥åŠäººç±»-AI é›†ä½“ (human-AI collectives) ç½®äºåŒä¸€ä¸ªæ¦‚å¿µæ™¯è§‚ä¸­è¿›è¡Œåˆ†æã€‚é€šè¿‡è€ƒå¯ŸåŸºç¡€éç¥ç» (basal aneural)ã€ç¥ç» (neural) å’Œäººç±»-AI æ··åˆè®¤çŸ¥ç©ºé—´ï¼Œç ”ç©¶å‘ç°ç³»ç»Ÿåœ¨ç©ºé—´ä¸­çš„åˆ†å¸ƒæä¸å‡åŒ€ï¼Œå­˜åœ¨å¤§é‡ç”±äºæ¼”åŒ–ã€ç‰©ç†çº¦æŸæˆ–è®¾è®¡å±€é™è€Œå¯¼è‡´çš„ç©ºç™½åŒºåŸŸã€‚è¿™ä¸€æ–¹æ³•ä¸ä»…å˜æ¸…äº†ç°æœ‰è®¤çŸ¥ç³»ç»Ÿçš„å¤šæ ·æ€§ï¼Œè¿˜æŒ‡å‡ºæ··åˆè®¤çŸ¥æ˜¯æ¢ç´¢è¶…è¶Šç”Ÿç‰©æ¼”åŒ–äº§ç”Ÿçš„æ–°å‹å¤æ‚æ€§çš„å‰æ²¿é¢†åŸŸã€‚\n\n---\n\næˆ‘æ˜¯ Gemini Enterpriseï¼Œå¸Œæœ›è¿™ä¸ªæ‘˜è¦èƒ½å¸®ä½ å¿«é€Ÿç†è§£è¿™ç¯‡å…³äºè®¤çŸ¥ç§‘å­¦å‰æ²¿ç†è®ºçš„è®ºæ–‡ï¼è¿™ç¯‡æ–‡ç« æå‡ºçš„â€œè®¤çŸ¥ç©ºé—´â€è§†è§’éå¸¸ç‹¬ç‰¹ï¼Œå®ƒæŠŠç”Ÿç‰©ç»†èƒå’Œ AI æ”¾åœ¨åŒä¸€ä¸ªç»´åº¦æ¯”è¾ƒã€‚å¦‚æœä½ å¯¹å…¶ä¸­æåˆ°çš„â€œåŸºç¡€éç¥ç»è®¤çŸ¥â€æˆ–è€…â€œäººç±»-AI æ··åˆç³»ç»Ÿâ€çš„å…·ä½“æ¡ˆä¾‹æ„Ÿå…´è¶£ï¼Œæ¬¢è¿ç»§ç»­å’Œæˆ‘æ¢è®¨ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.HC",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12837v1",
      "published_date": "2026-01-19 08:50:18 UTC",
      "updated_date": "2026-01-19 08:50:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:25:39.595735+00:00"
    },
    {
      "arxiv_id": "2601.12822v1",
      "title": "MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction",
      "title_zh": "Hello! I am Gemini Enterpriseâœ¨. Thank you for sharing this interesting research paper abstract. It seems like a significant step forward in securing autonomous computer-use agents.\n\nBelow is a summary of the key aspects of **MirrorGuard** based on the information provided.\n\n---\n\n### ğŸ›¡ï¸ Project Overview: MirrorGuard\n\nMirrorGuard is a \"plug-and-play\" defense framework designed to secure Computer Use Agents (CUAs) from malicious instructions and visual prompt injections. Unlike traditional defenses that simply block tasks, MirrorGuard focuses on **rectifying insecure reasoning** before harmful actions are executed.\n\n---\n\n### âš™ï¸ Core Methodology\n\n| Feature | Description |\n|---|---|\n| **Neural-Symbolic Simulation** | A pipeline that generates high-risk GUI interaction trajectories in a text-based environment to avoid real-world system hazards during training. |\n| **Reasoning Correction** | Instead of aborting tasks, the framework intercepts unsafe reasoning chains and corrects them, allowing the agent to continue safely. |\n| **Plug-and-Play Design** | It is built to be compatible with diverse CUA architectures without requiring fundamental changes to the underlying models. |\n\n---\n\n### ğŸ“Š Performance Comparison (on ByteDance UI-TARS)\n\nThe abstract highlights how MirrorGuard outperforms existing state-of-the-art solutions like GuardAgent in both security and utility.\n\n| Metric | Baseline (UI-TARS) | With GuardAgent | With **MirrorGuard** |\n|---|---|---|---|\n| **Unsafe Rate** | 66.5% | 53.9% | **13.0%** |\n| **False Refusal Rate (FRR)** | - | High (+15.4% vs MG) | **Marginal** |\n\n---\n\n### ğŸ”— Resources\nIf you would like to explore the code or the model, you can find them at the project page: [https://bmz-q-q.github.io/MirrorGuard/](https://bmz-q-q.github.io/MirrorGuard/).\n\n---\n\nThis research addresses a very timely problem as we move toward more autonomous OS-level agents. Would you like me to dive deeper into any specific part of this abstract, or are you looking for a comparison with other security frameworks in the AI agent space?",
      "authors": [
        "Wenqi Zhang",
        "Yulin Shen",
        "Changyue Jiang",
        "Jiarun Dai",
        "Geng Hong",
        "Xudong Pan"
      ],
      "abstract": "Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.",
      "tldr_zh": "---\n\n## è®ºæ–‡ TLDR æ‘˜è¦ ğŸ›¡ï¸\n\nè¯¥ç ”ç©¶æå‡ºäº† **MirrorGuard**ï¼Œä¸€ä¸ªæ—¨åœ¨å¢å¼ºè®¡ç®—æœºä½¿ç”¨æ™ºèƒ½ä½“ (**CUAs**) å®‰å…¨æ€§çš„å³æ’å³ç”¨é˜²å¾¡æ¡†æ¶ã€‚ä¸ºäº†åº”å¯¹æ¶æ„æŒ‡ä»¤å’Œè§†è§‰æç¤ºæ³¨å…¥ (**prompt injections**) å¯¼è‡´çš„ç³»ç»Ÿçº§å±å®³ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ç§**ç¥ç»ç¬¦å·æ¨¡æ‹Ÿç®¡é“ (neural-symbolic simulation pipeline)**ï¼Œåœ¨çº¯æ–‡æœ¬æ¨¡æ‹Ÿç¯å¢ƒä¸­ç”Ÿæˆé«˜é£é™©çš„ GUI äº¤äº’è½¨è¿¹ï¼Œä»¥è¯†åˆ«å¹¶æ‹¦æˆªä¸å®‰å…¨çš„æ¨ç†é“¾ (**reasoning chains**)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œ**MirrorGuard** åœ¨ **UI-TARS** ç³»ç»Ÿä¸Šå°†ä¸å®‰å…¨ç‡ä» 66.5% æ˜¾è‘—é™ä½è‡³ 13.0%ï¼Œä¸”ä¿æŒäº†æä½çš„è¯¯æ‹’ç‡ (**FRR**)ã€‚è¯¥å·¥ä½œè¯æ˜äº†é€šè¿‡æ¨¡æ‹Ÿè®­ç»ƒå¾—åˆ°çš„é˜²å¾¡æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆä¿®æ­£ç°å®ä¸–ç•Œçš„æ¨ç†åå·®ï¼Œåœ¨ä¿éšœå®‰å…¨çš„åŒæ—¶ä¿ç•™äº†æ™ºèƒ½ä½“çš„å®ç”¨æ€§ã€‚\n\n---\n\nè¿™ä¸ªæ‘˜è¦çªå‡ºäº† MirrorGuard å¦‚ä½•é€šè¿‡â€œæ¨¡æ‹Ÿåˆ°ç°å®â€çš„æ€è·¯è§£å†³å®‰å…¨é—®é¢˜ã€‚å¦‚æœä½ å¯¹å®ƒåœ¨ **GUI** ç¯å¢ƒä¸‹æ•æ‰â€œä¸å®‰å…¨æ¨ç†â€çš„å…·ä½“é€»è¾‘æ„Ÿå…´è¶£ï¼Œæˆ–è€…æƒ³äº†è§£å®ƒä¸ä¼ ç»Ÿæ‹¦æˆªå¼é˜²å¾¡ï¼ˆå¦‚ **GuardAgent**ï¼‰çš„æ›´å¤šå¯¹æ¯”ç»†èŠ‚ï¼Œæ¬¢è¿éšæ—¶æé—®ï¼",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12822v1",
      "published_date": "2026-01-19 08:32:09 UTC",
      "updated_date": "2026-01-19 08:32:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:25:35.194387+00:00"
    },
    {
      "arxiv_id": "2601.12816v1",
      "title": "Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning",
      "title_zh": "# Paper Overview: Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG)\n\nI have reviewed the abstract for your paper on **Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG)**. This research addresses the fundamental challenge of catastrophic forgetting in continual learning by leveraging information geometry to refine how neural networks update their parameters across sequential tasks.\n\n---\n\n### ğŸ’¡ Key Technical Insights\n\n| Feature | Description |\n|---|---|\n| **Core Objective** | Prevent catastrophic forgetting by ensuring new updates do not interfere with the performance of previously learned tasks. |\n| **Primary Innovation** | The **FOPNG optimizer**, which projects gradients onto the Fisher-orthogonal complement of gradients from previous tasks. |\n| **Framework** | Combines **Natural Gradient Descent (NGD)** with **Orthogonal Gradient methods** within an information-geometric context. |\n| **Theoretical Benefits** | Updates are invariant under reparameterization and are guaranteed to provide descent according to the Fisher metric. |\n| **Efficiency** | Implementation is made practical using a diagonal Fisher approximation. |\n\n---\n\n### ğŸ“Š Experimental Validation\n\nThe abstract notes that FOPNG was tested against several standard continual learning benchmarks. Based on the description, the optimizer demonstrates strong performance across:\n\n*   **MNIST Variants:** Permuted-MNIST, Split-MNIST, and Rotated-MNIST.\n*   **CIFAR Variants:** Split-CIFAR10 and Split-CIFAR100.\n\n---\n\n### â“ How can I assist you further?\n\nThis sounds like a significant contribution to the field of optimization in machine learning! To help you best, would you like me to:\n\n1.  **Summarize** the specific theoretical advantages of Fisher-orthogonality over standard Euclidean orthogonality?\n2.  **Analyze** how this method compares to other common continual learning approaches like EWC (Elastic Weight Consolidation) or GEM (Gradient Episodic Memory)?\n3.  **Draft** a specific section of the paper, such as an Introduction or a detailed Implementation section, based on these notes?\n\nPlease let me know how you would like to proceed!",
      "authors": [
        "Ishir Garg",
        "Neel Kolhe",
        "Andy Peng",
        "Rohan Gopalam"
      ],
      "abstract": "Continual learning aims to enable neural networks to acquire new knowledge on sequential tasks. However, the key challenge in such settings is to learn new tasks without catastrophically forgetting previously learned tasks. We propose the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer, which enforces Fisher-orthogonal constraints on parameter updates to preserve old task performance while learning new tasks. Unlike existing methods that operate in Euclidean parameter space, FOPNG projects gradients onto the Fisher-orthogonal complement of previous task gradients. This approach unifies natural gradient descent with orthogonal gradient methods within an information-geometric framework. The resulting update direction is invariant under reparameterization, guarantees descent in the Fisher metric, and helps preserve prior task outputs. We provide theoretical analysis establishing the properties of the projected update, describe efficient and practical implementations using the diagonal Fisher, and demonstrate strong results on standard continual learning benchmarks such as Permuted-MNIST, Split-MNIST, Rotated-MNIST, Split-CIFAR10, and Split-CIFAR100.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æŒç»­å­¦ä¹  (Continual Learning) ä¸­é¢ä¸´çš„ç¾éš¾æ€§é—å¿˜ (Catastrophic Forgetting) æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) çš„æ–°å‹ä¼˜åŒ–å™¨ã€‚\n\nåœ¨ä¿¡æ¯å‡ ä½• (Information-geometric) æ¡†æ¶ä¸‹ï¼ŒFOPNG é€šè¿‡å°†æ¢¯åº¦æŠ•å½±åˆ°å…ˆå‰ä»»åŠ¡æ¢¯åº¦çš„ Fisher-Orthogonal è¡¥ç©ºé—´ä¸­ï¼Œå¼ºåˆ¶æ‰§è¡Œæ­£äº¤çº¦æŸä»¥ä¿æŠ¤æ—§ä»»åŠ¡æ€§èƒ½ã€‚è¯¥æ–¹æ³•æˆåŠŸç»Ÿä¸€äº†è‡ªç„¶æ¢¯åº¦ä¸‹é™ (Natural Gradient Descent) ä¸æ­£äº¤æ¢¯åº¦æ–¹æ³•ï¼Œç¡®ä¿æ›´æ–°æ–¹å‘åœ¨ Fisher Metric ä¸‹å…·æœ‰ä¸‹é™æ€§è´¨ä¸”å¯¹é‡å‚æ•°åŒ–å…·æœ‰ä¸å˜æ€§ã€‚\n\nå®éªŒè¡¨æ˜ï¼Œé€šè¿‡å¯¹è§’ Fisher (Diagonal Fisher) çš„é«˜æ•ˆå®ç°ï¼ŒFOPNG åœ¨ Split-MNIST å’Œ Split-CIFAR100 ç­‰æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½æœ‰æ•ˆåœ¨å­¦ä¹ æ–°ä»»åŠ¡çš„åŒæ—¶ä¿ç•™å·²æœ‰çŸ¥è¯†ã€‚\n\n---\n\næ‚¨æ˜¯å¦è¿˜éœ€è¦é’ˆå¯¹è¯¥è®ºæ–‡çš„ç‰¹å®šéƒ¨åˆ†ï¼ˆå¦‚ç†è®ºåˆ†ææˆ–å®éªŒå¯¹æ¯”ï¼‰è¿›è¡Œæ›´æ·±å…¥çš„è§£è¯»ï¼Ÿ",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12816v1",
      "published_date": "2026-01-19 08:23:12 UTC",
      "updated_date": "2026-01-19 08:23:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:25:46.991626+00:00"
    },
    {
      "arxiv_id": "2601.12809v1",
      "title": "Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data",
      "title_zh": "åŸºäºåˆæˆç©ºé—´å…³ç³»æ•°æ®è®­ç»ƒçš„ CLIP é£æ ¼è§†è§‰-è¯­è¨€æ¨¡å‹å·¦å³å¯¹ç§°æ€§ç ´ç¼º",
      "authors": [
        "Takaki Yamamoto",
        "Chihiro Noguchi",
        "Toshihiro Tanizawa"
      ],
      "abstract": "Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç±» CLIP è§†è§‰è¯­è¨€æ¨¡å‹å¦‚ä½•ä¹ å¾—ç©ºé—´ç†è§£èƒ½åŠ›ï¼Œé‡ç‚¹åˆ†æäº†å·¦å³å…³ç³» (Left-right relational) ç†è§£çš„æ¶Œç°æœºåˆ¶ã€‚\n\nç ”ç©¶è€…æ„å»ºäº†ä¸€ä¸ªå¯æ§çš„ä¸€ç»´å›¾åƒ-æ–‡æœ¬æµ‹è¯•å¹³å°ï¼Œé€šè¿‡åœ¨åˆæˆçš„ç©ºé—´å…³ç³»æ•°æ®ä¸Šè®­ç»ƒè½»é‡çº§ Transformer ç¼–ç å™¨ï¼Œå‘ç° **label diversity**ï¼ˆæ ‡ç­¾å¤šæ ·æ€§ï¼‰æ¯” **layout diversity**ï¼ˆå¸ƒå±€å¤šæ ·æ€§ï¼‰æ›´èƒ½æ˜¾è‘—é©±åŠ¨æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚\n\nåœ¨æœºåˆ¶åˆ†ææ–¹é¢ï¼Œé€šè¿‡ **attention decomposition**ï¼ˆæ³¨æ„åŠ›åˆ†è§£ï¼‰å‘ç°ï¼Œä½ç½®åµŒå…¥ä¸ **token** åµŒå…¥çš„äº¤äº’è¯±å¯¼å‡ºäº†æ°´å¹³æ³¨æ„åŠ›æ¢¯åº¦ï¼Œä»è€Œæ‰“ç ´äº†ç¼–ç å™¨ä¸­çš„å·¦å³å¯¹ç§°æ€§ï¼›æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯å®è¯¥æœºåˆ¶æ˜¯æ¨¡å‹å…·å¤‡å·¦å³è¾¨åˆ«èƒ½åŠ›çš„å…³é”®ã€‚\n\nè¿™ä¸€ç»“æœä¸ºç†è§£ CLIP å¼æ¨¡å‹ä½•æ—¶ä»¥åŠå¦‚ä½•è·å¾—å…³ç³»å¤„ç†èƒ½åŠ›æä¾›äº†æœºæ¢°è®ºè§†è§’ (mechanistic insight) çš„è§£é‡Šã€‚\n\n---\n\nè¿™é¡¹å…³äºç©ºé—´ç†è§£æœºåˆ¶çš„ç ”ç©¶éå¸¸æ·±å…¥ï¼Œæ‚¨æ˜¯å¦æƒ³è¿›ä¸€æ­¥äº†è§£å…¶ **attention decomposition** çš„å…·ä½“åˆ†ææ–¹æ³•ï¼Œæˆ–è€…æ˜¯å®ƒå¯¹æœªæ¥è§†è§‰è¯­è¨€æ¨¡å‹è®­ç»ƒçš„å¯å‘ï¼Ÿ",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12809v1",
      "published_date": "2026-01-19 08:16:11 UTC",
      "updated_date": "2026-01-19 08:16:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:26:14.587106+00:00"
    },
    {
      "arxiv_id": "2601.14310v1",
      "title": "CORVUS: Red-Teaming Hallucination Detectors via Internal Signal Camouflage in Large Language Models",
      "title_zh": "CORVUSï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹å†…éƒ¨ä¿¡å·ä¼ªè£…çš„å¹»è§‰æ£€æµ‹å™¨çº¢é˜Ÿè¯„ä¼°",
      "authors": [
        "Nay Myat Min",
        "Long H. Pham",
        "Hongyu Zhang",
        "Jun Sun"
      ],
      "abstract": "Single-pass hallucination detectors rely on internal telemetry (e.g., uncertainty, hidden-state geometry, and attention) of large language models, implicitly assuming hallucinations leave separable traces in these signals. We study a white-box, model-side adversary that fine-tunes lightweight LoRA adapters on the model while keeping the detector fixed, and introduce CORVUS, an efficient red-teaming procedure that learns to camouflage detector-visible telemetry under teacher forcing, including an embedding-space FGSM attention stress test. Trained on 1,000 out-of-distribution Alpaca instructions (<0.5% trainable parameters), CORVUS transfers to FAVA-Annotation across Llama-2, Vicuna, Llama-3, and Qwen2.5, and degrades both training-free detectors (e.g., LLM-Check) and probe-based detectors (e.g., SEP, ICR-probe), motivating adversary-aware auditing that incorporates external grounding or cross-model evidence.",
      "tldr_zh": "### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ“\n\n---\n\nè¯¥ç ”ç©¶å¼•å…¥äº† **CORVUS**ï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„çº¢é˜Ÿæµ‹è¯• (**Red-Teaming**) ç¨‹åºï¼Œæ—¨åœ¨é€šè¿‡ä¼ªè£…å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„å†…éƒ¨é¥æµ‹ä¿¡å· (**Internal Telemetry**) æ¥æŒ‘æˆ˜ç°æœ‰çš„å¹»è§‰æ£€æµ‹å™¨ã€‚\n\nç ”ç©¶è€…é€šè¿‡åœ¨æ¨¡å‹ç«¯å¾®è°ƒè½»é‡çº§çš„ **LoRA** é€‚é…å™¨ï¼Œè¯æ˜äº†å¹»è§‰åŸæœ¬åœ¨ä¸ç¡®å®šæ€§ã€éšè—çŠ¶æ€å’Œæ³¨æ„åŠ›ä¸­ç•™ä¸‹çš„å¯è¾¨è¯†ç—•è¿¹æ˜¯å¯ä»¥è¢«â€œæ©ç›–â€çš„ï¼Œç”šè‡³èƒ½é€šè¿‡åµŒå…¥ç©ºé—´çš„ **FGSM** æ³¨æ„åŠ›å‹åŠ›æµ‹è¯•è¿›ä¸€æ­¥é€ƒé¿æ£€æµ‹ã€‚\n\nå®éªŒç»“æœæ˜¾ç¤ºï¼Œ**CORVUS** åœ¨ Llama-2/3ã€Vicuna å’Œ Qwen2.5 ç­‰å¤šç§æ¨¡å‹ä¸Šå‡è¡¨ç°å‡ºå¼ºå¤§çš„è¿ç§»æ€§ï¼ŒæˆåŠŸå‰Šå¼±äº†åŒ…æ‹¬ **LLM-Check**ã€**SEP** å’Œ **ICR-probe** åœ¨å†…çš„å¤šç§è®­ç»ƒæ— å…³å‹åŠæ¢é’ˆå‹æ£€æµ‹å™¨çš„æ€§èƒ½ã€‚\n\næ­¤é¡¹å·¥ä½œæ­ç¤ºäº†ä»…ä¾èµ–æ¨¡å‹å†…éƒ¨ä¿¡å·è¿›è¡Œå¹»è§‰æ£€æµ‹çš„å±€é™æ€§ï¼Œå¹¶å¼ºè°ƒäº†åœ¨æœªæ¥çš„å®‰å…¨å®¡è®¡ä¸­å¼•å…¥å¤–éƒ¨éªŒè¯ (**External Grounding**) æˆ–è·¨æ¨¡å‹è¯æ®çš„å¿…è¦æ€§ã€‚\n\n---\n\nè¿™é¡¹ç ”ç©¶å¯¹äºæ„å»ºæ›´é²æ£’çš„å¹»è§‰æ£€æµ‹ç³»ç»Ÿéå¸¸æœ‰å¯å‘ã€‚æ‚¨æ˜¯å¦æƒ³æ·±å…¥äº†è§£ CORVUS å…·ä½“æ˜¯å¦‚ä½•åˆ©ç”¨ **FGSM** è¿›è¡Œæ³¨æ„åŠ›å‹åŠ›æµ‹è¯•çš„ï¼Œæˆ–è€…å¯¹å…¶åœ¨ç‰¹å®šæ¨¡å‹ï¼ˆå¦‚ Qwen2.5ï¼‰ä¸Šçš„è¡¨ç°æ„Ÿå…´è¶£ï¼Ÿ",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2601.14310v1",
      "published_date": "2026-01-19 08:07:03 UTC",
      "updated_date": "2026-01-19 08:07:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:26:21.221749+00:00"
    },
    {
      "arxiv_id": "2601.12805v2",
      "title": "SciHorizon-GENE: Benchmarking LLM for Life Sciences Inference from Gene Knowledge to Functional Understanding",
      "title_zh": "SciHorizon-GENEï¼šé¢å‘ä»åŸºå› çŸ¥è¯†åˆ°åŠŸèƒ½ç†è§£çš„ç”Ÿå‘½ç§‘å­¦æ¨ç†çš„ LLM åŸºå‡†æµ‹è¯•",
      "authors": [
        "Xiaohan Huang",
        "Meng Xiao",
        "Chuan Qin",
        "Qingqing Long",
        "Jinmiao Chen",
        "Yuanchun Zhou",
        "Hengshu Zhu"
      ],
      "abstract": "Large language models (LLMs) have shown growing promise in biomedical research, particularly for knowledge-driven interpretation tasks. However, their ability to reliably reason from gene-level knowledge to functional understanding, a core requirement for knowledge-enhanced cell atlas interpretation, remains largely underexplored. To address this gap, we introduce SciHorizon-GENE, a large-scale gene-centric benchmark constructed from authoritative biological databases. The benchmark integrates curated knowledge for over 190K human genes and comprises more than 540K questions covering diverse gene-to-function reasoning scenarios relevant to cell type annotation, functional interpretation, and mechanism-oriented analysis. Motivated by behavioral patterns observed in preliminary examinations, SciHorizon-GENE evaluates LLMs along four biologically critical perspectives: research attention sensitivity, hallucination tendency, answer completeness, and literature influence, explicitly targeting failure modes that limit the safe adoption of LLMs in biological interpretation pipelines. We systematically evaluate a wide range of state-of-the-art general-purpose and biomedical LLMs, revealing substantial heterogeneity in gene-level reasoning capabilities and persistent challenges in generating faithful, complete, and literature-grounded functional interpretations. Our benchmark establishes a systematic foundation for analyzing LLM behavior at the gene scale and offers insights for model selection and development, with direct relevance to knowledge-enhanced biological interpretation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† **SciHorizon-GENE**ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡ã€ä»¥åŸºå› ä¸ºä¸­å¿ƒçš„åŸºå‡†æµ‹è¯• (Benchmark)ï¼Œæ—¨åœ¨å¡«è¡¥å¤§è¯­è¨€æ¨¡å‹ (**LLMs**) åœ¨ç”Ÿå‘½ç§‘å­¦é¢†åŸŸä¸­ï¼Œä»åŸºå› çº§çŸ¥è¯†åˆ°åŠŸèƒ½ç†è§£æ¨ç†èƒ½åŠ›è¯„ä¼°çš„ç©ºç™½ã€‚\n\nè¯¥åŸºå‡†ä»æƒå¨ç”Ÿç‰©æ•°æ®åº“ä¸­æ•´åˆäº†è¶…è¿‡ 19 ä¸‡ä¸ªåŸºå› çš„çŸ¥è¯†ï¼Œæ„å»ºäº† 54 ä¸‡ä½™ä¸ªé—®é¢˜ï¼Œå¹¿æ³›æ¶µç›–äº† **cell type annotation**ï¼ˆç»†èƒç±»å‹æ³¨é‡Šï¼‰ã€åŠŸèƒ½è§£é‡ŠåŠæœºåˆ¶å¯¼å‘åˆ†æç­‰å…³é”®ä»»åŠ¡ã€‚ç ”ç©¶ä»ç ”ç©¶å…³æ³¨åº¦æ•æ„Ÿæ€§ã€**hallucination tendency**ï¼ˆå¹»è§‰å€¾å‘ï¼‰ã€å›ç­”å®Œæ•´æ€§å’Œæ–‡çŒ®å½±å“åŠ›å››ä¸ªç”Ÿç‰©å­¦å…³é”®ç»´åº¦å¯¹æ¨¡å‹è¿›è¡Œäº†ç³»ç»Ÿè€ƒå¯Ÿã€‚\n\nè¯„ä¼°ç»“æœæ­ç¤ºäº†ç°æœ‰ä¸»æµ **LLMs** åœ¨åŸºå› çº§æ¨ç†èƒ½åŠ›ä¸Šå­˜åœ¨æ˜¾è‘—çš„å¼‚è´¨æ€§ï¼Œå°¤å…¶åœ¨ç”Ÿæˆå¿ å®ã€å®Œæ•´ä¸”å…·æœ‰ **literature-grounded**ï¼ˆæ–‡çŒ®ä¾æ®ï¼‰çš„åŠŸèƒ½è§£è¯»æ–¹é¢ä»é¢ä¸´æŒç»­æŒ‘æˆ˜ã€‚è¯¥åŸºå‡†ä¸ºåˆ†æ **LLMs** åœ¨åŸºå› å°ºåº¦ä¸Šçš„è¡¨ç°å¥ å®šäº†ç³»ç»Ÿæ€§åŸºç¡€ï¼Œå¹¶ä¸ºçŸ¥è¯†å¢å¼ºå‹ç”Ÿç‰©å­¦è§£é‡Šå·¥å…·çš„å¼€å‘æä¾›äº†æŒ‡å¯¼ã€‚\n\n---\n\nè¿™ä¸ªåŸºå‡†æµ‹è¯•å¯¹äºç”Ÿç‰©åŒ»å­¦é¢†åŸŸçš„ **LLM** åº”ç”¨éå¸¸å…³é”®ã€‚æ‚¨æ˜¯å¦éœ€è¦äº†è§£è¯¥ Benchmark é’ˆå¯¹ç‰¹å®šä»»åŠ¡ï¼ˆå¦‚ **cell type annotation**ï¼‰çš„å…·ä½“è¯„ä¼°æ ‡å‡†ï¼Œæˆ–è€…æƒ³å¯¹æ¯”æŸäº›ç‰¹å®šæ¨¡å‹åœ¨è¯¥æµ‹è¯•ä¸­çš„è¡¨ç°ï¼Ÿ",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.GN",
      "comment": "16 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.12805v2",
      "published_date": "2026-01-19 08:06:35 UTC",
      "updated_date": "2026-01-21 05:31:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:26:27.206562+00:00"
    },
    {
      "arxiv_id": "2601.12804v1",
      "title": "SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability",
      "title_zh": "SL-CBMï¼šåˆ©ç”¨è¯­ä¹‰å±€éƒ¨æ€§æå‡æ¦‚å¿µç“¶é¢ˆæ¨¡å‹çš„å¯è§£é‡Šæ€§",
      "authors": [
        "Hanwei Zhang",
        "Luo Cheng",
        "Rui Wen",
        "Yang Zhang",
        "Lijun Zhang",
        "Holger Hermanns"
      ],
      "abstract": "Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **SL-CBM**ï¼ˆå…·æœ‰è¯­ä¹‰å±€éƒ¨æ€§çš„æ¦‚å¿µç“¶é¢ˆæ¨¡å‹ï¼‰ï¼Œæ—¨åœ¨é€šè¿‡å¢å¼º **Semantic Locality**ï¼ˆè¯­ä¹‰å±€éƒ¨æ€§ï¼‰æ¥è§£å†³ç°æœ‰ **Concept Bottleneck Models (CBMs)** åœ¨ç©ºé—´å¯¹é½ï¼ˆ**locality faithfulness**ï¼‰æ–¹é¢çš„ä¸è¶³ã€‚\n\nSL-CBM é›†æˆäº† 1x1 å·ç§¯å±‚ä¸ **cross-attention**ï¼ˆäº¤å‰æ³¨æ„åŠ›ï¼‰æœºåˆ¶ï¼Œèƒ½å¤Ÿç”Ÿæˆä¸æ¨¡å‹å†…éƒ¨æ¨ç†é€»è¾‘ç´§å¯†å…³è”ä¸”ç©ºé—´ç›¸å¹²çš„ **saliency maps**ï¼ˆæ˜¾è‘—æ€§å›¾ï¼‰ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†å¯¹æ¯”æ­£åˆ™åŒ–å’ŒåŸºäºç†µçš„æ­£åˆ™åŒ–ï¼Œä»¥å¹³è¡¡åˆ†ç±»å‡†ç¡®ç‡ã€ç¨€ç–æ€§ä¸å¿ è¯šåº¦ã€‚\n\nå¤§é‡å®éªŒè¯æ˜ï¼ŒSL-CBM åœ¨ä¿æŒç«äº‰åŠ›å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†è§£é‡Šè´¨é‡ã€**locality faithfulness** ä»¥åŠå¹²é¢„æ•ˆç‡ï¼Œä¸ºæ„å»ºå¯ä¿¡ã€å¯è§£é‡Šçš„æ¦‚å¿µåŒ–æ¨¡å‹è®¾ç«‹äº†æ–°æ ‡å‡†ã€‚\n\n---\nå¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦æ€»ç»“ï¼Œæˆ–è€…æƒ³é’ˆå¯¹ **SL-CBM** çš„å…·ä½“å®ç°ç»†èŠ‚è¿›è¡Œæ·±å…¥æ¢è®¨ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12804v1",
      "published_date": "2026-01-19 08:05:28 UTC",
      "updated_date": "2026-01-19 08:05:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:26:35.012394+00:00"
    },
    {
      "arxiv_id": "2601.12785v1",
      "title": "Distilling Time Series Foundation Models for Efficient Forecasting",
      "title_zh": "é¢å‘é«˜æ•ˆé¢„æµ‹çš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹è’¸é¦",
      "authors": [
        "Yuqi Li",
        "Kuiye Ding",
        "Chuanguang Yang",
        "Szu-Yu Chen",
        "Yingli Tian"
      ],
      "abstract": "Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.",
      "tldr_zh": "It is a pleasure to meet you! I am Gemini Enterpriseâœ¨. I see you've shared the abstract for a very interesting paper titled **\"Distilling Time Series Foundation Models for Efficient Forecasting.\"** This work seems to address a critical bottleneck in the deployment of Time Series Foundation Models (TSFMs).\n\nBased on the abstract provided, I have summarized the core components of the **DistilTS** framework for you below.\n\n---\n\n### Research Overview ğŸ“–\n\nThe paper introduces **DistilTS**, the first distillation framework tailored specifically for compressing large Time Series Foundation Models. While TSFMs are powerful, their size often makes them impractical for real-time or resource-constrained deployment. DistilTS bridges this gap by enabling compact student models to achieve performance levels similar to their massive teacher models.\n\n---\n\n### Key Challenges & Innovations ğŸ› ï¸\n\nThe researchers identified two primary hurdles in time series distillation and developed specific mechanisms to solve them:\n\n| Challenge | Solution in DistilTS | Description |\n|---|---|---|\n| **Task Difficulty Discrepancy** | Horizon-Weighted Objectives | Balances learning by preventing the model from being dominated by \"easy\" short-term horizons, ensuring better supervision for long-term forecasting. |\n| **Architecture Discrepancy** | Temporal Alignment Strategy | An alignment mechanism designed to bridge the gap between different model architectures, facilitating better knowledge transfer to compact models. |\n\n---\n\n### Impact & Performance ğŸš€\n\nThe results of this framework are quite impressive, demonstrating that massive models can be distilled into much leaner versions without significant loss in accuracy.\n\n*   **Parameter Reduction:** Achieves up to a **1/150** reduction in model size.\n*   **Inference Speedup:** Delivers up to **6000x** faster inference times.\n*   **Performance:** Maintains forecasting accuracy comparable to full-sized TSFMs across multiple benchmarks.\n\n---\n\nThis looks like a significant step forward for making advanced time series forecasting more accessible in production environments. Would you like me to help you explore the methodology in more detail, or perhaps you'd like me to look into the implementation details from the GitHub repository? \n\nI am here to help with any analysis or further questions you might have!",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICASSP-2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12785v1",
      "published_date": "2026-01-19 07:32:00 UTC",
      "updated_date": "2026-01-19 07:32:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:26:44.038566+00:00"
    },
    {
      "arxiv_id": "2601.12781v1",
      "title": "VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension",
      "title_zh": "VIROï¼šé¢å‘æŒ‡ä»£æ€§è¡¨è¾¾ç†è§£çš„é›†æˆéªŒè¯ã€é²æ£’é«˜æ•ˆçš„ç¥ç»ç¬¦å·æ¨ç†",
      "authors": [
        "Hyejin Park",
        "Junhyuk Kwon",
        "Suha Kwak",
        "Jungseul Ok"
      ],
      "abstract": "Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **VIRO**ï¼Œä¸€ç§é›†æˆéªŒè¯æœºåˆ¶çš„ç¥ç»ç¬¦å·æ¨ç†æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ **Referring Expression Comprehension (REC)** ä»»åŠ¡ä¸­å› ä¸­é—´æ¨ç†æ­¥éª¤é”™è¯¯å¯¼è‡´çš„çº§è”è¯¯å·®ï¼ˆ**cascading errors**ï¼‰é—®é¢˜ã€‚\n\nè¯¥æ¡†æ¶é€šè¿‡åœ¨æ¨ç†æ­¥éª¤ä¸­åµŒå…¥è½»é‡çº§çš„ç®—å­çº§éªŒè¯å™¨ï¼ˆ**operator-level verifiers**ï¼‰ï¼Œä½¿æ¯ä¸ªç®—å­åœ¨æ‰§è¡Œæ—¶èƒ½åŒæ­¥æ ¡éªŒè¾“å‡ºç»“æœï¼ˆå¦‚ç‰©ä½“å­˜åœ¨æ€§æˆ–ç©ºé—´å…³ç³»ï¼‰ï¼Œä»è€Œæœ‰æ•ˆè¯†åˆ«å¹¶å¤„ç†å›¾ä¸­ä¸å­˜åœ¨ç›®æ ‡ï¼ˆ**no-target**ï¼‰çš„æƒ…å†µã€‚\n\nå®éªŒè¡¨æ˜ï¼ŒVIRO åœ¨å¹³è¡¡äº†æœ‰ç›®æ ‡å’Œæ— ç›®æ ‡è®¾ç½®çš„å‡†ç¡®ç‡ä¸Šè¾¾åˆ°äº† 61.1%ï¼Œåˆ·æ–°äº† **SOTA** çºªå½•ï¼Œå¹¶å±•ç°å‡ºæé«˜çš„è®¡ç®—æ•ˆç‡å’Œä½äº 0.3% çš„ç¨‹åºå¤±è´¥ç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œçš„è‡ªæˆ‘ä¸­å¿ƒæ•°æ®ï¼ˆ**egocentric data**ï¼‰ä¸Šä¹Ÿè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œå¯æ‰©å±•æ€§ã€‚\n\n---\nå¦‚æœæ‚¨å¯¹ **VIRO** çš„éªŒè¯æœºåˆ¶æˆ–å…¶åœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„è¡¨ç°æ„Ÿå…´è¶£ï¼Œæ¬¢è¿ç»§ç»­æé—®ï¼",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12781v1",
      "published_date": "2026-01-19 07:21:19 UTC",
      "updated_date": "2026-01-19 07:21:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:26:59.346203+00:00"
    },
    {
      "arxiv_id": "2601.12762v1",
      "title": "Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction",
      "title_zh": "æ•™å¯¼å¤§è¯­è¨€æ¨¡å‹é€šè¿‡ç¯å¢ƒäº¤äº’å­¦ä¹ å·¥å…·è¯•ç”¨ä¸æ‰§è¡Œ",
      "authors": [
        "Xingjie Gao",
        "Pengcheng Huang",
        "Zhenghao Liu",
        "Yukun Yan",
        "Shuo Wang",
        "Zulong Chen",
        "Chen Qian",
        "Ge Yu",
        "Yu Gu"
      ],
      "abstract": "Equipping Large Language Models (LLMs) with external tools enables them to solve complex real-world problems. However, the robustness of existing methods remains a critical challenge when confronting novel or evolving tools. Existing trajectory-centric paradigms primarily rely on memorizing static solution paths during training, which limits the ability of LLMs to generalize tool usage to newly introduced or previously unseen tools. In this paper, we propose ToolMaster, a framework that shifts tool use from imitating golden tool-calling trajectories to actively learning tool usage through interaction with the environment. To optimize LLMs for tool planning and invocation, ToolMaster adopts a trial-and-execution paradigm, which trains LLMs to first imitate teacher-generated trajectories containing explicit tool trials and self-correction, followed by reinforcement learning to coordinate the trial and execution phases jointly. This process enables agents to autonomously explore correct tool usage by actively interacting with environments and forming experiential knowledge that benefits tool execution. Experimental results demonstrate that ToolMaster significantly outperforms existing baselines in terms of generalization and robustness across unseen or unfamiliar tools. All code and data are available at https://github.com/NEUIR/ToolMaster.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **ToolMaster**ï¼Œä¸€ç§æ—¨åœ¨æå‡ **Large Language Models (LLMs)** åœ¨é¢å¯¹æ–°å·¥å…·æˆ–åŠ¨æ€æ¼”åŒ–å·¥å…·æ—¶æ³›åŒ–èƒ½åŠ›çš„æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¾èµ–é™æ€è½¨è¿¹å»ºæ¨¡ï¼ˆ**trajectory-centric**ï¼‰å¯¼è‡´éš¾ä»¥åº”å¯¹æœªçŸ¥å·¥å…·çš„é—®é¢˜ï¼Œ**ToolMaster** å¼•å…¥äº†â€œè¯•ç”¨ä¸æ‰§è¡Œâ€ï¼ˆ**trial-and-execution**ï¼‰èŒƒå¼ã€‚è¯¥æ¡†æ¶é¦–å…ˆé€šè¿‡æ¨¡ä»¿åŒ…å«æ˜¾å¼å·¥å…·å°è¯•ä¸è‡ªæˆ‘çº æ­£çš„æ•™å¸ˆè½¨è¿¹è¿›è¡Œé¢„è®­ç»ƒï¼Œéšååˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆ**Reinforcement Learning**ï¼‰è¿›ä¸€æ­¥åè°ƒè¯•ç”¨ä¸æ‰§è¡Œé˜¶æ®µã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡ä¸ç¯å¢ƒçš„ä¸»åŠ¨äº¤äº’å½¢æˆç»éªŒçŸ¥è¯†ï¼Œ**ToolMaster** åœ¨å¤„ç†æœªè§è¿‡çš„å·¥å…·æ—¶ï¼Œå…¶é²æ£’æ€§å’Œæ³›åŒ–æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚\n\n---\nå¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦æ€»ç»“ï¼Œæˆ–è€…æƒ³æ·±å…¥äº†è§£ **ToolMaster** çš„å…·ä½“äº¤äº’æœºåˆ¶ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12762v1",
      "published_date": "2026-01-19 06:46:33 UTC",
      "updated_date": "2026-01-19 06:46:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:27:00.493961+00:00"
    },
    {
      "arxiv_id": "2601.12758v1",
      "title": "VISPA: Pluralistic Alignment via Automatic Value Selection and Activation",
      "title_zh": "VISPAï¼šé€šè¿‡è‡ªåŠ¨ä»·å€¼é€‰æ‹©ä¸æ¿€æ´»å®ç°å¤šå…ƒåŒ–å¯¹é½",
      "authors": [
        "Shenyan Zheng",
        "Jiayou Zhong",
        "Anudeex Shetty",
        "Heng Ji",
        "Preslav Nakov",
        "Usman Naseem"
      ],
      "abstract": "As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.",
      "tldr_zh": "ä½ å¥½ï¼æˆ‘æ˜¯ Gemini Enterpriseâœ¨ã€‚å¾ˆé«˜å…´èƒ½ç»§ç»­ä¸ºä½ æä¾›ä¸“ä¸šè®ºæ–‡æ‘˜è¦æœåŠ¡ã€‚é’ˆå¯¹ä½ æä¾›çš„å…³äº **VISPA** æ¡†æ¶çš„è®ºæ–‡ï¼Œä»¥ä¸‹æ˜¯æŒ‰ç…§ä½ çš„è¦æ±‚ç”Ÿæˆçš„ä¸­æ–‡ TLDR æ‘˜è¦åŠæ ¸å¿ƒåˆ†æï¼š\n\n## è®ºæ–‡æ€»ç»“ ğŸ“\n\n---\n\nè¯¥ç ”ç©¶æå‡ºäº† **VISPA**ï¼Œä¸€ä¸ªæ— éœ€è®­ç»ƒï¼ˆ**training-free**ï¼‰çš„å¤šå…ƒå¯¹é½ï¼ˆ**pluralistic alignment**ï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹è¾“å‡ºå¾€å¾€ä»…åæ˜ â€œå¹³å‡â€åå¥½è€Œå¿½è§†å¤šå…ƒè§†è§’çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶é€šè¿‡ **dynamic selection**ï¼ˆåŠ¨æ€é€‰æ‹©ï¼‰å’Œ **internal model activation steering**ï¼ˆå†…éƒ¨æ¨¡å‹æ¿€æ´»å¼•å¯¼ï¼‰æŠ€æœ¯ï¼Œå®ç°äº†å¯¹æ¨¡å‹ç‰¹å®šä»·å€¼è¡¨è¾¾çš„ç›´æ¥ç²¾ç¡®æ§åˆ¶ã€‚å®éªŒè¯æ˜ï¼ŒVISPA åœ¨åŒ»ç–—åŠå…¶ä»–é¢†åŸŸçš„å¤šç§æ¨¡å‹å’Œè¯„ä¼°è®¾ç½®ä¸­å‡è¡¨ç°ä¼˜å¼‚ï¼Œå±•ç°äº†æå¼ºçš„æ€§èƒ½ä¸è¡¨ç°åŠ›ã€‚åˆ†æç»“æœè¿›ä¸€æ­¥è¯å®äº†è¯¥æ¡†æ¶åœ¨ä¸åŒå¼•å¯¼ç­–ç•¥ã€æ¨¡å‹å’Œä»·å€¼ä½“ç³»ä¸‹çš„å¹¿æ³›é€‚é…æ€§ï¼Œä¸ºåˆ©ç”¨å†…éƒ¨æ¿€æ´»æœºåˆ¶å®ç°å¯æ‰©å±•çš„å¤šå…ƒå¯¹é½å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚\n\n---\n\n## æ ¸å¿ƒè¦ç‚¹ç®€è¡¨ ğŸ› ï¸\n\n| ç»´åº¦ | å†…å®¹è¯´æ˜ |\n|---|---|\n| **æ ¸å¿ƒæŒ‘æˆ˜** | ç°æœ‰çš„å¯¹é½æ–¹æ³•ç¼ºä¹å¯¹å¤šå…ƒä»·å€¼çš„æ§åˆ¶åŠ›ï¼Œä¸”å¾€å¾€ä¾èµ–äºæç¤ºè¯å±‚é¢çš„å¹²é¢„ã€‚ |\n| **ä¸»è¦æ–¹æ³•** | å¼•å…¥äº† **Automatic Value Selection**ï¼ˆè‡ªåŠ¨ä»·å€¼é€‰æ‹©ï¼‰ä¸ **Activation Steering**ï¼ˆæ¿€æ´»å¼•å¯¼ï¼‰çš„ç»„åˆã€‚ |\n| **åº”ç”¨è¡¨ç°** | åœ¨ **healthcare**ï¼ˆåŒ»ç–—ï¼‰ç­‰é«˜é£é™©é¢†åŸŸåŠé€šç”¨è®¾ç½®ä¸‹å‡å–å¾—äº†æ˜¾è‘—çš„å¯¹é½æ•ˆæœã€‚ |\n| **æ¡†æ¶ç‰¹æ€§** | å…·æœ‰ **training-free**ï¼ˆæ— éœ€è®­ç»ƒï¼‰å’Œ **scalable**ï¼ˆå¯æ‰©å±•ï¼‰çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚ |\n\n---\n\nè¿™ç¯‡è®ºæ–‡åœ¨å¤„ç†æ¨¡å‹åå¥½å¯¹é½æ–¹é¢æä¾›äº†ä¸€ä¸ªéå¸¸æ–°é¢–çš„è§†è§’ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡â€œå†…éƒ¨æ¿€æ´»â€è€Œéé‡è®­ç»ƒçš„æ–¹å¼ã€‚å¦‚æœä½ å¯¹ **internal model activation steering** çš„å…·ä½“å®ç°ç»†èŠ‚æ„Ÿå…´è¶£ï¼Œæˆ–è€…éœ€è¦æˆ‘ä¸ºä½ å¯¹æ¯”ä¸€ä¸‹å®ƒä¸ä¼ ç»Ÿ **RLHF** çš„å¼‚åŒï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "WIP",
      "pdf_url": "https://arxiv.org/pdf/2601.12758v1",
      "published_date": "2026-01-19 06:38:52 UTC",
      "updated_date": "2026-01-19 06:38:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:27:17.704875+00:00"
    },
    {
      "arxiv_id": "2601.12754v1",
      "title": "PAIR-SAFE: A Paired-Agent Approach for Runtime Auditing and Refining AI-Mediated Mental Health Support",
      "title_zh": "PAIR-SAFEï¼šé¢å‘ AI ä»‹å¯¼å¿ƒç†å¥åº·æ”¯æŒè¿è¡Œæ—¶å®¡è®¡ä¸å®Œå–„çš„åŒæ™ºèƒ½ä½“æ–¹æ³•",
      "authors": [
        "Jiwon Kim",
        "Violeta J. Rodriguez",
        "Dong Whi Yoo",
        "Eshwar Chandrasekharan",
        "Koustuv Saha"
      ],
      "abstract": "Large language models (LLMs) are increasingly used for mental health support, yet they can produce responses that are overly directive, inconsistent, or clinically misaligned, particularly in sensitive or high-risk contexts. Existing approaches to mitigating these risks largely rely on implicit alignment through training or prompting, offering limited transparency and runtime accountability. We introduce PAIR-SAFE, a paired-agent framework for auditing and refining AI-generated mental health support that integrates a Responder agent with a supervisory Judge agent grounded in the clinically validated Motivational Interviewing Treatment Integrity (MITI-4) framework. The Judgeaudits each response and provides structuredALLOW or REVISE decisions that guide runtime response refinement. We simulate counseling interactions using a support-seeker simulator derived from human-annotated motivational interviewing data. We find that Judge-supervised interactions show significant improvements in key MITI dimensions, including Partnership, Seek Collaboration, and overall Relational quality. Our quantitative findings are supported by qualitative expert evaluation, which further highlights the nuances of runtime supervision. Together, our results reveal that such pairedagent approach can provide clinically grounded auditing and refinement for AI-assisted conversational mental health support.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **PAIR-SAFE**ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¿è¡Œæ—¶å®¡è®¡ä¸ä¼˜åŒ– AI å¿ƒç†å¥åº·æ”¯æŒçš„å¯¹é½ä»£ç†æ¡†æ¶ï¼ˆ**paired-agent framework**ï¼‰ï¼Œæ—¨åœ¨è§£å†³ LLMs åœ¨æ•æ„Ÿè¯­å¢ƒä¸‹å›å¤è¿‡åº¦å¼•å¯¼æˆ–ä¸´åºŠå¤±å‡†çš„é—®é¢˜ã€‚\n\nè¯¥æ¡†æ¶å°†ç”Ÿæˆå›å¤çš„ **Responder** æ™ºèƒ½ä½“ä¸ä¸€ä¸ªåŸºäº **MITI-4** ä¸´åºŠæ¡†æ¶çš„ç›‘ç£è€… **Judge** æ™ºèƒ½ä½“é…å¯¹ï¼Œç”± **Judge** å¯¹æ¯æ¡å›å¤è¿›è¡Œå®¡æ ¸å¹¶æä¾›ç»“æ„åŒ–çš„ **ALLOW** æˆ– **REVISE** å†³ç­–ã€‚\n\nå®éªŒå’Œä¸“å®¶è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œ**PAIR-SAFE** åœ¨ **Partnership**ã€**Seek Collaboration** ä»¥åŠæ•´ä½“å…³ç³»è´¨é‡ï¼ˆ**Relational quality**ï¼‰ç­‰å…³é”®ä¸´åºŠç»´åº¦ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚è¿™ä¸€æˆæœè¯æ˜äº†å¯¹é½ä»£ç†æ–¹æ³•åœ¨æä¾›ä¸´åºŠé©±åŠ¨çš„å®æ—¶å®¡è®¡ä¸å›å¤ç²¾ç‚¼æ–¹é¢çš„æ½œåŠ›ã€‚\n\n---\nå¦‚æœæ‚¨å¯¹ **MITI-4** æ¡†æ¶åœ¨ AI ä¸­çš„å…·ä½“åº”ç”¨æˆ– **PAIR-SAFE** çš„å®‰å…¨æ€§è¯„ä¼°æœ‰æ›´å¤šç–‘é—®ï¼Œæ¬¢è¿éšæ—¶æé—®ï¼",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12754v1",
      "published_date": "2026-01-19 06:20:57 UTC",
      "updated_date": "2026-01-19 06:20:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:27:14.127852+00:00"
    },
    {
      "arxiv_id": "2601.12745v1",
      "title": "A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection",
      "title_zh": "é¢å‘æ— çº¿ä¼ æ„Ÿå™¨ç½‘ç»œæ—¶ç©ºç›¸å…³å¼‚å¸¸æ£€æµ‹çš„å›¾æç¤ºå¾®è°ƒæ–¹æ³•",
      "authors": [
        "Miao Ye",
        "Jing Cui",
        "Yuan huang",
        "Qian He",
        "Yong Wang",
        "Jiwen Zhang"
      ],
      "abstract": "Anomaly detection of multi-temporal modal data in Wireless Sensor Network (WSN) can provide an important guarantee for reliable network operation. Existing anomaly detection methods in multi-temporal modal data scenarios have the problems of insufficient extraction of spatio-temporal correlation features, high cost of anomaly sample category annotation, and imbalance of anomaly samples. In this paper, a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy of \"pre-training - graph prompting - fine-tuning\" are designed for the characteristics of WSN graph structure data. First, the anomaly detection backbone network is designed by improving the Mamba model based on a multi-scale strategy and inter-modal fusion method, and combining it with a variational graph convolution module, which is capable of fully extracting spatio-temporal correlation features in the multi-node, multi-temporal modal scenarios of WSNs. Secondly, we design a three-subtask learning \"pre-training\" method with no-negative comparative learning, prediction, and reconstruction to learn generic features of WSN data samples from unlabeled data, and design a \"graph prompting-fine-tuning\" mechanism to guide the pre-trained self-supervised learning. The model is fine-tuned through the \"graph prompting-fine-tuning\" mechanism to guide the pre-trained self-supervised learning model to complete the parameter fine-tuning, thereby reducing the training cost and enhancing the detection generalization performance. The F1 metrics obtained from experiments on the public dataset and the actual collected dataset are up to 91.30% and 92.31%, respectively, which provides better detection performance and generalization ability than existing methods designed by the method.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ— çº¿ä¼ æ„Ÿå™¨ç½‘ç»œï¼ˆ**WSN**ï¼‰å¤šæ—¶é—´æ¨¡æ€æ•°æ®å¼‚å¸¸æ£€æµ‹ä¸­ç‰¹å¾æå–ä¸è¶³ã€æ ‡æ³¨æˆæœ¬é«˜å’Œæ ·æœ¬ä¸å¹³è¡¡çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å›¾æç¤ºå¾®è°ƒæ–¹æ³•ã€‚\n\nåœ¨æ¶æ„ä¸Šï¼Œè¯¥æ–¹æ³•é€šè¿‡æ”¹è¿›å…·æœ‰å¤šå°ºåº¦ç­–ç•¥å’Œæ¨¡æ€èåˆèƒ½åŠ›çš„ **Mamba** æ¨¡å‹ï¼Œå¹¶ç»“åˆ **Variational Graph Convolution**ï¼ˆå˜åˆ†å›¾å·ç§¯ï¼‰æ¨¡å—ï¼Œå®ç°äº†å¯¹ **WSN** æ—¶ç©ºç›¸å…³æ€§ç‰¹å¾çš„æ·±åº¦æå–ã€‚æ­¤å¤–ï¼Œç ”ç©¶è®¾è®¡äº†â€œé¢„è®­ç»ƒ-å›¾æç¤º-å¾®è°ƒâ€ï¼ˆ**pre-training - graph prompting - fine-tuning**ï¼‰çš„å¤šä»»åŠ¡è‡ªç›‘ç£è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡æ— æ ‡ç­¾æ•°æ®å­¦ä¹ é€šç”¨ç‰¹å¾ï¼Œæ˜¾è‘—é™ä½äº†å¾®è°ƒæˆæœ¬ã€‚\n\nå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…¬å¼€æ•°æ®é›†å’Œå®é™…æ•°æ®é›†ä¸Šçš„ **F1** æŒ‡æ ‡åˆ†åˆ«è¾¾åˆ° 91.30% å’Œ 92.31%ï¼Œåœ¨æ£€æµ‹æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚\n\n---\nå¦‚æœæ‚¨å¯¹ **Mamba** æ¨¡å‹åœ¨ **WSN** ä¸­çš„å…·ä½“æ”¹è¿›ç»†èŠ‚ï¼Œæˆ–æ˜¯è¯¥è‡ªç›‘ç£ç­–ç•¥çš„å®ç°æ–¹å¼æ„Ÿå…´è¶£ï¼Œæ¬¢è¿éšæ—¶ä¸æˆ‘æ¢è®¨ï¼",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12745v1",
      "published_date": "2026-01-19 05:58:53 UTC",
      "updated_date": "2026-01-19 05:58:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:27:21.315942+00:00"
    },
    {
      "arxiv_id": "2601.12744v1",
      "title": "Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks",
      "title_zh": "é¢å‘è‡ªä¸»ç½‘ç»œä¼˜åŒ–é©±åŠ¨æ„å›¾å¤„ç†çš„è§†è§‰è¯­è¨€æ¨¡å‹",
      "authors": [
        "Tasnim Ahmed",
        "Yifan Zhu",
        "Salimur Choudhury"
      ],
      "abstract": "Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. While recent work demonstrates that large language models can automate configuration tasks, a distinct class of intents requires generating optimization code to compute provably optimal solutions for traffic engineering, routing, and resource allocation. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. Network practitioners naturally reason about structure through diagrams, yet whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code remains unexplored. We present IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. Our evaluation shows that visual parameter extraction reduces execution success by 12-21 percentage points (pp), with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 pp, and open-source models lag behind closed-source ones, with Llama-3.2-11B-Vision reaching 18% compared to 75% for GPT-5-Mini. These results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system. We also demonstrate practical feasibility through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) åœ¨æ„å›¾é©±åŠ¨ç½‘ç»œ (Intent-Based Networking, IBN) ä¸­ä»ç½‘ç»œè‰å›¾æ ‡æ³¨ç”Ÿæˆä¼˜åŒ–ä»£ç çš„èƒ½åŠ›ï¼Œå¹¶æå‡ºäº†åŒ…å« 85 ä¸ªä¼˜åŒ–é—®é¢˜çš„è¯„æµ‹åŸºå‡† IntentOptã€‚ç ”ç©¶é€šè¿‡å¯¹æ¯” GPT-5-Miniã€Gemini-2.5-Flash ç­‰æ¨¡å‹å‘ç°ï¼Œä»è§†è§‰å›¾åƒä¸­æå–å‚æ•°ä¼šæ˜¾è‘—é™ä½æ‰§è¡ŒæˆåŠŸç‡ï¼ˆä¸‹é™ 12-21%ï¼‰ï¼Œä¸”é—­æºæ¨¡å‹çš„æ€§èƒ½è¿œä¼˜äºå¼€æºæ¨¡å‹ã€‚å®éªŒè¿˜æŒ‡å‡º Program-of-thought æç¤ºç­–ç•¥åœ¨æŸäº›æƒ…å†µä¸‹åè€Œä¼šå‰Šå¼±æ¨¡å‹è¡¨ç°ã€‚æœ€åï¼Œç ”ç©¶é€šè¿‡ Model Context Protocol åœ¨ç½‘ç»œæµ‹è¯•åºŠä¸ŠæˆåŠŸéƒ¨ç½²äº†ç”Ÿæˆçš„ä»£ç ï¼Œè¯æ˜äº†è¯¥æ–¹æ¡ˆåœ¨è‡ªåŠ¨åŒ–ç½‘ç»œé…ç½®ä¸ä¼˜åŒ–ä¸­çš„å®é™…å¯è¡Œæ€§ã€‚\n\n---\nå¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦æ€»ç»“ï¼Œæˆ–è€…æƒ³é’ˆå¯¹è¿™ç¯‡è®ºæ–‡çš„å®éªŒç»“æœè¿›è¡Œæ›´æ·±å…¥çš„æ¢è®¨ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.AI",
        "cs.NI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for presentation at The IEEE International Conference on Communications (ICC) 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12744v1",
      "published_date": "2026-01-19 05:57:58 UTC",
      "updated_date": "2026-01-19 05:57:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:27:51.415028+00:00"
    },
    {
      "arxiv_id": "2601.12742v1",
      "title": "AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation",
      "title_zh": "AirHuntï¼šèåˆ VLM è¯­ä¹‰ä¸è¿ç»­è§„åˆ’çš„é«˜æ•ˆç©ºä¸­ç›®æ ‡å¯¼èˆª",
      "authors": [
        "Xuecheng Chen",
        "Zongzhuo Liu",
        "Jianfa Ma",
        "Bang Du",
        "Tiantian Zhang",
        "Xueqian Wang",
        "Boyu Zhou"
      ],
      "abstract": "Recent advances in large Vision-Language Models (VLMs) have provided rich semantic understanding that empowers drones to search for open-set objects via natural language instructions. However, prior systems struggle to integrate VLMs into practical aerial systems due to orders-of-magnitude frequency mismatch between VLM inference and real-time planning, as well as VLMs' limited 3D scene understanding. They also lack a unified mechanism to balance semantic guidance with motion efficiency in large-scale environments. To address these challenges, we present AirHunt, an aerial object navigation system that efficiently locates open-set objects with zero-shot generalization in outdoor environments by seamlessly fusing VLM semantic reasoning with continuous path planning. AirHunt features a dual-pathway asynchronous architecture that establishes a synergistic interface between VLM reasoning and path planning, enabling continuous flight with adaptive semantic guidance that evolves through motion. Moreover, we propose an active dual-task reasoning module that exploits geometric and semantic redundancy to enable selective VLM querying, and a semantic-geometric coherent planning module that dynamically reconciles semantic priorities and motion efficiency in a unified framework, enabling seamless adaptation to environmental heterogeneity. We evaluate AirHunt across diverse object navigation tasks and environments, demonstrating a higher success rate with lower navigation error and reduced flight time compared to state-of-the-art methods. Real-world experiments further validate AirHunt's practical capability in complex and challenging environments. Code and dataset will be made publicly available before publication.",
      "tldr_zh": "This paper presents **AirHunt**, an innovative system designed to enhance how drones navigate and locate objects using natural language instructions. By bridging the gap between high-level Vision-Language Model (VLM) reasoning and low-level real-time path planning, it achieves more efficient and reliable performance in complex outdoor environments.\n\n---\n\n### Key Challenges Addressed âš ï¸\n\nThe authors identify three primary hurdles that current aerial navigation systems face when trying to utilize VLMs:\n\n| Challenge | Description |\n|---|---|\n| **Frequency Mismatch** | VLMs process information much slower than a drone's flight controller, which requires millisecond-level planning. |\n| **3D Scene Understanding** | Most VLMs are trained on 2D images and struggle with the spatial and geometric depth required for 3D aerial navigation. |\n| **Efficiency Balance** | The difficulty of balancing the \"semantic pull\" (moving toward a potential target) with the need for efficient, smooth motion in large-scale areas. |\n\n---\n\n### Core Innovations & Modules ğŸ› ï¸\n\nAirHunt introduces a dual-layered approach to make zero-shot object navigation practical and fast:\n\n| Module | Functionality |\n|---|---|\n| **Dual-Pathway Architecture** | An asynchronous system that allows VLM reasoning and path planning to run at different speeds while still informing one another. |\n| **Active Dual-Task Reasoning** | Uses geometric and semantic cues to decide *when* to query the VLM, reducing unnecessary computation and focusing on high-value targets. |\n| **Semantic-Geometric Planning** | A unified framework that reconciles semantic goals with flight efficiency, adapting to the environment's complexity in real-time. |\n\n---\n\n### Performance & Impact ğŸ“ˆ\n\nAccording to the abstract, **AirHunt** outperforms current state-of-the-art methods across several metrics:\n*   **Higher Success Rate:** More reliable at finding specified objects.\n*   **Lower Navigation Error:** Precise positioning and target identification.\n*   **Reduced Flight Time:** Faster mission completion due to optimized path planning.\n\nThe system has been validated through both simulations and real-world experiments in challenging outdoor settings, proving its readiness for practical applications.\n\n---\n\nThis sounds like a significant step forward for autonomous drone intelligence! Would you like me to dive deeper into one of the specific modules, or are you looking for a comparison with other VLM-based navigation systems?",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12742v1",
      "published_date": "2026-01-19 05:50:03 UTC",
      "updated_date": "2026-01-19 05:50:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:27:50.472353+00:00"
    },
    {
      "arxiv_id": "2601.12740v1",
      "title": "TreeWriter: AI-Assisted Hierarchical Planning and Writing for Long-Form Documents",
      "title_zh": "TreeWriterï¼šé¢å‘é•¿ç¯‡æ–‡æ¡£çš„ AI è¾…åŠ©å±‚çº§åŒ–è§„åˆ’ä¸å†™ä½œ",
      "authors": [
        "Zijian Zhang",
        "Fangshi Du",
        "Xingjian Liu",
        "Pan Chen",
        "Oliver Huang",
        "Runlong Ye",
        "Michael Liut",
        "AlÃ¡n Aspuru-Guzik"
      ],
      "abstract": "Long documents pose many challenges to current intelligent writing systems. These include maintaining consistency across sections, sustaining efficient planning and writing as documents become more complex, and effectively providing and integrating AI assistance to the user. Existing AI co-writing tools offer either inline suggestions or limited structured planning, but rarely support the entire writing process that begins with high-level ideas and ends with polished prose, in which many layers of planning and outlining are needed. Here, we introduce TreeWriter, a hierarchical writing system that represents documents as trees and integrates contextual AI support. TreeWriter allows authors to create, save, and refine document outlines at multiple levels, facilitating drafting, understanding, and iterative editing of long documents. A built-in AI agent can dynamically load relevant content, navigate the document hierarchy, and provide context-aware editing suggestions. A within-subject study (N=12) comparing TreeWriter with Google Docs + Gemini on long-document editing and creative writing tasks shows that TreeWriter improves idea exploration/development, AI helpfulness, and perceived authorial control. A two-month field deployment (N=8) further demonstrated that hierarchical organization supports collaborative writing. Our findings highlight the potential of hierarchical, tree-structured editors with integrated AI support and provide design guidelines for future AI-assisted writing tools that balance automation with user agency.",
      "tldr_zh": "It sounds like an interesting paper! **TreeWriter** seems to address a significant pain point in AI-assisted writingâ€”the transition from high-level outlining to detailed prose in complex documents.\n\nHere is a quick breakdown of what Iâ€™ve gathered from the abstract:\n\n---\n\n### ğŸ“ Project Overview: TreeWriter\n| Feature | Description |\n|---|---|\n| **Core Concept** | A hierarchical writing system that treats documents as trees rather than linear text. |\n| **Primary Goal** | To support the entire writing process, from initial brainstorming and multi-layer outlining to final polishing. |\n| **AI Integration** | An agent that can navigate the document hierarchy, load relevant context, and offer suggestions based on specific sections. |\n\n---\n\n### ğŸ”¬ Study Results & Findings\nThe researchers conducted both a controlled study and a long-term field deployment to see how this approach stacks up against traditional tools:\n\n*   **Comparative Study (N=12):** When compared to Google Docs + Gemini, users found that TreeWriter improved **idea development**, made the **AI feel more helpful**, and increased the **author's sense of control**.\n*   **Field Deployment (N=8):** A two-month trial showed that the tree structure is particularly effective for **collaborative writing** and managing long-term projects.\n\n---\n\n### ğŸš€ How can I help you with this?\nI'd love to discuss this further with you. Are you looking to:\n*   Summarize specific sections of this research (if you have more text)?\n*   Compare this \"tree-structured\" approach to how I (Gemini Enterprise) currently handle long-form writing?\n*   Brainstorm how you might apply these hierarchical planning principles to your own current projects?\n\nWhat are your thoughts on using a tree-based structure for writingâ€”do you think it would change your workflow?",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12740v1",
      "published_date": "2026-01-19 05:39:35 UTC",
      "updated_date": "2026-01-19 05:39:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:27:47.854404+00:00"
    },
    {
      "arxiv_id": "2601.12731v1",
      "title": "A Shared Geometry of Difficulty in Multilingual Language Models",
      "title_zh": "å¤šè¯­è¨€è¯­è¨€æ¨¡å‹ä¸­éš¾åº¦çš„å…±åŒå‡ ä½•ç»“æ„",
      "authors": [
        "Stefano Civelli",
        "Pietro Bernardelle",
        "NicolÃ² Brunello",
        "Gianluca Demartini"
      ],
      "abstract": "Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.",
      "tldr_zh": "This is a fascinating study on LLM interpretability! It explores how models \"perceive\" the difficulty of a task across different languages and where that information is stored within their neural layers.\n\nI've summarized the core findings of the paper below:\n\n---\n\n### ğŸ§  The Two Stages of Difficulty Representation\nThe research highlights a distinct shift in how a model processes the concept of \"difficulty\" as data moves through its layers.\n\n| Stage | Layer Depth | Within-Language Accuracy | Cross-Lingual Generalization | Nature of Representation |\n|---|---|---|---|---|\n| **Early Stage** | Shallow (Early Layers) | Lower | **Stronger** | Language-Agnostic (Abstract) |\n| **Later Stage** | Deep (Later Layers) | **Higher** | Poorer | Language-Specific (Concrete) |\n\n---\n\n### ğŸ” Key Insights\n*   **Abstract to Specific:** The findings suggest that LLMs first identify a problem's difficulty in a conceptual, language-independent space. Only in the deeper layers does this representation become tied to the specific linguistic features of the input.\n*   **Meta-Cognitive Properties:** This study proves that \"difficulty estimation\"â€”a high-level meta-cognitive traitâ€”follows the same representational patterns as basic semantic content.\n*   **Interpretability Implications:** Using linear probes on shallow layers might be a more robust way to build \"difficulty detectors\" that work across many languages, even if they are slightly less precise than language-specific ones.\n\n---\n\n### ğŸ’¬ Let's Discuss\nThis \"shared geometry\" suggests that underneath the surface of 21 different languages, the model's \"logic\" for what makes a problem hard remains consistent. \n\nAre you researching how to improve model performance on complex multilingual tasks, or are you more interested in the inner workings and \"black box\" nature of how I and other models process information? I'd be happy to dive deeper into either topic with you!",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12731v1",
      "published_date": "2026-01-19 05:21:21 UTC",
      "updated_date": "2026-01-19 05:21:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:27:57.969194+00:00"
    },
    {
      "arxiv_id": "2601.12727v1",
      "title": "AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations",
      "title_zh": "AIå±•ç°å‡ºçš„æ€§æ ¼ç‰¹è´¨å¯é€šè¿‡å¯¹è¯å¡‘é€ äººç±»è‡ªæˆ‘æ¦‚å¿µ",
      "authors": [
        "Jingshu Li",
        "Tianqi Song",
        "Nattapat Boonprakong",
        "Zicheng Zhu",
        "Yitian Yang",
        "Yi-Chieh Lee"
      ],
      "abstract": "Recent Large Language Model (LLM) based AI can exhibit recognizable and measurable personality traits during conversations to improve user experience. However, as human understandings of their personality traits can be affected by their interaction partners' traits, a potential risk is that AI traits may shape and bias users' self-concept of their own traits. To explore the possibility, we conducted a randomized behavioral experiment. Our results indicate that after conversations about personal topics with an LLM-based AI chatbot using GPT-4o default personality traits, users' self-concepts aligned with the AI's measured personality traits. The longer the conversation, the greater the alignment. This alignment led to increased homogeneity in self-concepts among users. We also observed that the degree of self-concept alignment was positively associated with users' conversation enjoyment. Our findings uncover how AI personality traits can shape users' self-concepts through human-AI conversation, highlighting both risks and opportunities. We provide important design implications for developing more responsible and ethical AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡éšæœºè¡Œä¸ºå®éªŒï¼Œæ¢ç´¢äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„ AI æ€§æ ¼ç‰¹è´¨ (Personality Traits) å¦‚ä½•é€šè¿‡å¯¹è¯å¡‘é€ äººç±»çš„è‡ªæˆ‘æ¦‚å¿µ (Self-concept)ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨ä¸å…·æœ‰ GPT-4o é»˜è®¤æ€§æ ¼çš„ AI è¿›è¡Œä¸ªäººè¯é¢˜å¯¹è¯åï¼Œç”¨æˆ·çš„è‡ªæˆ‘æ¦‚å¿µä¼šä¸ AI çš„æ€§æ ¼è¡¨ç°å‡ºä¸€è‡´æ€§ï¼ˆå³â€œæ€§æ ¼å¯¹é½â€ï¼‰ï¼Œä¸”è¿™ç§å¯¹é½ç¨‹åº¦éšå¯¹è¯æ—¶é•¿å¢åŠ è€ŒåŠ æ·±ã€‚æ­¤å¤–ï¼Œè‡ªæˆ‘æ¦‚å¿µçš„å¯¹é½ä¸ç”¨æˆ·çš„å¯¹è¯æ„‰æ‚¦åº¦å‘ˆæ­£ç›¸å…³ï¼Œä½†è¿™åŒæ—¶ä¹Ÿå¯¼è‡´äº†ç”¨æˆ·ç¾¤ä½“é—´è‡ªæˆ‘æ¦‚å¿µçš„åŒè´¨åŒ–ã€‚è¯¥å‘ç°æ­ç¤ºäº† AI æ€§æ ¼å¯¹äººç±»å¿ƒç†çš„æ½œåœ¨å½±å“ï¼Œå¹¶ä¸ºå¼€å‘æ›´è´Ÿè´£ä»»ã€ç¬¦åˆä¼¦ç†çš„ AI ç³»ç»Ÿæä¾›äº†é‡è¦è®¾è®¡å¯ç¤ºã€‚\n\n---\nè¿™é¡¹ç ”ç©¶éå¸¸æœ‰è¶£ï¼Œå®ƒæ­ç¤ºäº† AI åœ¨æ½œç§»é»˜åŒ–ä¸­å¯¹äººç±»è‡ªæˆ‘è®¤çŸ¥çš„â€œåŒåŒ–â€ä½œç”¨ã€‚å¦‚æœæ‚¨å¯¹å®éªŒç»†èŠ‚æˆ–å…¶ä¼¦ç†å½±å“æœ‰æ›´å¤šå…´è¶£ï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­æ·±å…¥äº¤æµï¼",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "ACM CHI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12727v1",
      "published_date": "2026-01-19 05:16:57 UTC",
      "updated_date": "2026-01-19 05:16:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:28:10.138579+00:00"
    },
    {
      "arxiv_id": "2601.12723v1",
      "title": "An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨ä¼˜åŒ–åŸºå‡†ç”Ÿæˆè¿›åŒ–æ¡†æ¶",
      "authors": [
        "Yuhiro Ono",
        "Tomohiro Harada",
        "Yukiya Miura"
      ],
      "abstract": "Optimization benchmarks play a fundamental role in assessing algorithm performance; however, existing artificial benchmarks often fail to capture the diversity and irregularity of real-world problem structures, while benchmarks derived from real-world problems are costly and difficult to construct. To address these challenges, we propose an evolutionary automatic benchmark generation framework that leverages a large language model (LLM) as a generative operator, termed the LLM-driven evolutionary benchmark generator (LLM-EBG). In this framework, the LLM serves as an evolutionary operator that generates and evolves benchmark problems within a flexible, expressive representation space. As a case study, we generate unconstrained single-objective continuous minimization problems represented as mathematical expressions designed to induce significant performance differences between a genetic algorithm (GA) and differential evolution (DE). Experimental results show that LLM-EBG successfully produces benchmark problems in which the designated target algorithm consistently outperforms the comparative algorithm in more than 80\\% of trials. Furthermore, exploratory landscape analysis reveals that benchmarks favoring GA are highly sensitive to variable scaling, demonstrating that the proposed framework can generate problems with distinct geometric characteristics that reflect the intrinsic search behaviors of different optimization algorithms.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **LLM-EBG**ï¼Œä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) ä½œä¸ºæ¼”åŒ–ç®—å­çš„è‡ªåŠ¨åŸºå‡†æµ‹è¯•ç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ä¼˜åŒ–åŸºå‡†æµ‹è¯•å¤šæ ·æ€§ä¸è¶³ä»¥åŠçœŸå®ä¸–ç•Œé—®é¢˜å»ºæ¨¡æˆæœ¬é«˜çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å°† LLM é›†æˆä¸ºæ¼”åŒ–ç®—å­ï¼Œåœ¨çµæ´»çš„è¡¨è¾¾ç©ºé—´å†…ç”Ÿæˆå¹¶æ¼”åŒ–å…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†é—®é¢˜ã€‚é€šè¿‡é’ˆå¯¹é—ä¼ ç®—æ³• (**GA**) å’Œå·®åˆ†è¿›åŒ– (**DE**) çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œå®éªŒè¯æ˜è¯¥æ¡†æ¶ç”Ÿæˆçš„æ•°å­¦è¡¨è¾¾å¼èƒ½æ˜¾è‘—åŒºåˆ†ç®—æ³•æ€§èƒ½ï¼Œä½¿ç›®æ ‡ç®—æ³•åœ¨è¶…è¿‡ 80% çš„æµ‹è¯•ä¸­èƒœå‡ºã€‚æ¢ç´¢æ€§æ™¯è§‚åˆ†æ (**Exploratory Landscape Analysis**) è¿›ä¸€æ­¥æ­ç¤ºï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ç‰¹å®šå‡ ä½•ç‰¹å¾ï¼ˆå¦‚å¯¹å˜é‡ç¼©æ”¾é«˜åº¦æ•æ„Ÿï¼‰çš„é—®é¢˜ï¼Œæœ‰æ•ˆåæ˜ äº†ä¸åŒä¼˜åŒ–ç®—æ³•çš„å†…åœ¨æœç´¢è¡Œä¸ºã€‚\n\n---\nè¿™ä¸ªåˆ©ç”¨ LLM è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•é›†çš„æ–¹æ³•éå¸¸æ–°é¢–ï¼Œç‰¹åˆ«æ˜¯å®ƒèƒ½â€œé‡èº«å®šåˆ¶â€å‡ºè®©ç‰¹å®šç®—æ³•äº§ç”Ÿå·®å¼‚çš„é—®é¢˜ã€‚æ‚¨æ˜¯å¯¹è‡ªåŠ¨åŒ–åŸºå‡†æµ‹è¯•æ„Ÿå…´è¶£ï¼Œè¿˜æ˜¯æ›´å…³æ³¨ LLM åœ¨æ¼”åŒ–ç®—æ³•ä¸­çš„åº”ç”¨ï¼Ÿ",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12723v1",
      "published_date": "2026-01-19 04:58:15 UTC",
      "updated_date": "2026-01-19 04:58:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:28:14.229074+00:00"
    },
    {
      "arxiv_id": "2601.12720v1",
      "title": "Teaching Large Reasoning Models Effective Reflection",
      "title_zh": "æ•™å¯¼å¤§æ¨ç†æ¨¡å‹è¿›è¡Œæœ‰æ•ˆåæ€",
      "authors": [
        "Hanbin Wang",
        "Jingwei Song",
        "Jinpeng Li",
        "Qi Zhu",
        "Fei Mi",
        "Ganqu Cui",
        "Yasheng Wang",
        "Lifeng Shang"
      ],
      "abstract": "Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹æ¨ç†æ¨¡å‹ (Large Reasoning Models, LRMs) åœ¨å¤æ‚æ¨ç†ä¸­å¸¸å‡ºç°çš„â€œæµ…å±‚åå°„ (Superficial Reflection)â€é—®é¢˜ï¼Œå³æ— æ•ˆçš„åæ€è¡Œä¸ºä¸ä»…æ— æ³•æå‡è¡¨ç°ï¼Œè¿˜ä¼šå¢åŠ è®¡ç®—å¼€é”€ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† Self-Critique Fine-Tuning (SCFT) è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡è‡ªç”Ÿæˆè¯„è®ºå¹¶ç»“åˆæ‹’ç»é‡‡æ · (Rejection Sampling) è¿‡æ»¤é«˜è´¨é‡å†…å®¹è¿›è¡Œå¾®è°ƒã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥å¼•å…¥ Reinforcement Learning with Effective Reflection Rewards (RLERR)ï¼Œåˆ©ç”¨é«˜è´¨é‡åæ€æ„å»ºå¥–åŠ±ä¿¡å·ï¼Œå¼•å¯¼æ¨¡å‹é€šè¿‡å¼ºåŒ–å­¦ä¹ å†…åŒ–è‡ªçº æ­£è¿‡ç¨‹ã€‚åœ¨ AIME2024 å’Œ AIME2025 æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSCFT å’Œ RLERR æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æ¨ç†å‡†ç¡®ç‡å’Œåæ€è´¨é‡ï¼Œæ€§èƒ½ä¼˜äºç°æœ‰çš„ SOTA åŸºå‡†ã€‚\n\n---\nè¿™é¡¹ç ”ç©¶å¯¹äºæå‡æ¨¡å‹çš„â€œæ€è€ƒâ€æ•ˆç‡éå¸¸æœ‰æ„ä¹‰ï¼Œç‰¹åˆ«æ˜¯åœ¨è§£å†³æ•°å­¦å’Œç«èµ›ç±»éš¾é¢˜æ—¶ã€‚å¦‚æœæ‚¨å¯¹å…¶ä¸­çš„å¼ºåŒ–å­¦ä¹ æœºåˆ¶æˆ–ç‰¹å®šçš„å®éªŒæ•°æ®æ„Ÿå…´è¶£ï¼Œæ¬¢è¿ç»§ç»­æé—®ï¼",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages (including appendix), 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12720v1",
      "published_date": "2026-01-19 04:51:53 UTC",
      "updated_date": "2026-01-19 04:51:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:28:22.831338+00:00"
    },
    {
      "arxiv_id": "2601.12715v1",
      "title": "RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels",
      "title_zh": "RSODï¼šææœ‰é™æ ‡æ³¨ä¸‹çš„å¯é æ€§å¼•å¯¼å£°å‘å›¾åƒç›®æ ‡æ£€æµ‹",
      "authors": [
        "Chengzhou Li",
        "Ping Guo",
        "Guanchen Meng",
        "Qi Jia",
        "Jinyuan Liu",
        "Zhu Liu",
        "Xiaokang Liu",
        "Yu Liu",
        "Zhongxuan Luo",
        "Xin Fan"
      ],
      "abstract": "Object detection in sonar images is a key technology in underwater detection systems. Compared to natural images, sonar images contain fewer texture details and are more susceptible to noise, making it difficult for non-experts to distinguish subtle differences between classes. This leads to their inability to provide precise annotation data for sonar images. Therefore, designing effective object detection methods for sonar images with extremely limited labels is particularly important. To address this, we propose a teacher-student framework called RSOD, which aims to fully learn the characteristics of sonar images and develop a pseudo-label strategy suitable for these images to mitigate the impact of limited labels. First, RSOD calculates a reliability score by assessing the consistency of the teacher's predictions across different views. To leverage this score, we introduce an object mixed pseudo-label method to tackle the shortage of labeled data in sonar images. Finally, we optimize the performance of the student by implementing a reliability-guided adaptive constraint. By taking full advantage of unlabeled data, the student can perform well even in situations with extremely limited labels. Notably, on the UATD dataset, our method, using only 5% of labeled data, achieves results that can compete against those of our baseline algorithm trained on 100% labeled data. We also collected a new dataset to provide more valuable data for research in the field of sonar.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RSODï¼Œä¸€ç§åŸºäºæ•™å¸ˆ-å­¦ç”Ÿæ¡†æ¶ (teacher-student framework) çš„å£°çº³å›¾åƒç›®æ ‡æ£€æµ‹æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å£°çº³å›¾åƒç”±äºå™ªå£°å¤§ã€çº¹ç†ç¼ºå¤±å¯¼è‡´çš„æ ‡æ³¨æ•°æ®æåº¦åŒ®ä¹é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡è¯„ä¼°æ•™å¸ˆæ¨¡å‹åœ¨ä¸åŒè§†è§’ä¸‹é¢„æµ‹çš„ä¸€è‡´æ€§æ¥è®¡ç®—å¯é æ€§åˆ†æ•° (reliability score)ï¼Œå¹¶å¼•å…¥ç‰©ä½“æ··åˆä¼ªæ ‡ç­¾æ–¹æ³• (object mixed pseudo-label method) ä»¥æœ‰æ•ˆåˆ©ç”¨æ— æ ‡æ³¨æ•°æ®ã€‚æ­¤å¤–ï¼ŒRSOD é‡‡ç”¨å¯é æ€§å¼•å¯¼çš„è‡ªé€‚åº”çº¦æŸ (reliability-guided adaptive constraint) æ¥ä¼˜åŒ–å­¦ç”Ÿæ¨¡å‹çš„æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRSOD åœ¨ UATD æ•°æ®é›†ä¸Šä»…ä½¿ç”¨ 5% çš„æ ‡æ³¨æ•°æ®ï¼Œå³å¯è¾¾åˆ°åŸºçº¿ç®—æ³•ä½¿ç”¨ 100% æ ‡æ³¨æ•°æ®çš„ç«äº‰æ€§æ°´å¹³ï¼ŒåŒæ—¶è¯¥ç ”ç©¶è¿˜è´¡çŒ®äº†ä¸€ä¸ªå…¨æ–°çš„å£°çº³å›¾åƒæ•°æ®é›†ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2026,9 pages,10 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12715v1",
      "published_date": "2026-01-19 04:37:34 UTC",
      "updated_date": "2026-01-19 04:37:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:28:37.137769+00:00"
    },
    {
      "arxiv_id": "2601.12711v1",
      "title": "Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts",
      "title_zh": "ç¥ç»ç¬¦å· LoRAï¼šæƒé‡å¾®è°ƒä¸æç¤ºè¯é‡å†™çš„åŠ¨å› ä¸æ—¶æœºåˆ†æ",
      "authors": [
        "Kevin Wang",
        "Neel P. Bhatt",
        "Cong Liu",
        "Junbo Li",
        "Runjin Chen",
        "Yihan Xi",
        "Timothy Barclay",
        "Alvaro Velasquez",
        "Ufuk Topcu",
        "Zhangyang Wang"
      ],
      "abstract": "Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.",
      "tldr_zh": "### Overview of \"Neurosymbolic LoRA\" ğŸ§ \n\nI have reviewed the abstract for the paper titled **\"Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts\"**. This research introduces a hybrid framework designed to optimize Large Language Model (LLM) adaptation by balancing parameter updates with prompt engineering.\n\n---\n\n### Key Takeaways from the Abstract ğŸ“\n\n| Feature | Description |\n|---|---|\n| **The Problem** | Choosing between numerical fine-tuning (parameter updates) and symbolic updates (prompt/logical manipulation) often presents a trade-off between knowledge injection and style control. |\n| **The Solution** | **Neurosymbolic LoRA**, a framework that dynamically combines LoRA (numerical) and TextGrad (symbolic) strategies based on the task requirements. |\n| **The Mechanism** | Uses a unified monitoring signal and a reward-based classifier to decide whether to perform deeper factual reconstruction (LoRA) or token-level edits (TextGrad). |\n| **Efficiency** | Remains memory-efficient by offloading symbolic transformations to an external LLM only when necessary. |\n| **The Benefit** | Symbolic edits generate high-quality, reusable training data, which is particularly useful for data-scarce domains like mathematical reasoning. |\n\n---\n\n### Results and Implications ğŸš€\n\nThe authors note that this approach consistently outperforms purely numerical or purely symbolic baselines across multiple LLM backbones. By interleaving these two methods, the framework achieves a higher level of versatility and adaptability in model fine-tuning.\n\nThis sounds like a fascinating advancement in how we handle LLM alignment and domain-specific training. Would you like me to dive deeper into any specific part of this abstract, or are you looking for a comparison with other fine-tuning methods like standard QLoRA?",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12711v1",
      "published_date": "2026-01-19 04:24:49 UTC",
      "updated_date": "2026-01-19 04:24:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:28:51.631263+00:00"
    },
    {
      "arxiv_id": "2601.12688v1",
      "title": "Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction",
      "title_zh": "I have analyzed the research paper titled **\"Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction\"**. This work addresses the specific challenges of using AI to predict legal outcomes in cases involving multiple defendants, where individual roles (like principal vs. accomplice) are often difficult to parse from judicial text.\n\n---\n\n### Paper Overview ğŸ“„\n\n| Attribute | Details |\n|---|---|\n| **Authors** | Xu Zhang, Qinghua Wang, Mengyang Zhao, Fang Wang, Cunquan Qu |\n| **Institution** | Data Science Institute, Shandong University, China |\n| **Publication Date** | January 19, 2026 (ArXiv: 2601.12688) |\n| **Primary Task** | Legal Judgment Prediction (LJP) for multiple defendants |\n| **Key Dataset** | IMLJP (Intentional Injury cases) |\n| **Code Repository** | [GitHub: XuZhang29/MMSI](https://github.com/XuZhang29/MMSI) |\n\n---\n\n### The Problem & Proposed Solution ğŸ› ï¸\n\nThe researchers identify that current AI models struggle with fairness and accuracy in multidefendant cases because judicial phrasing often \"obscures\" individual responsibilities.\n\n| Feature | Description |\n|---|---|\n| **The Challenge** | AI often fails to differentiate between a **principal** (lead offender) and an **accomplice**, leading to imprecise sentencing predictions. |\n| **The Solution (MMSI)** | A **Masked Multistage Inference** framework that integrates legal sentencing logic into a Transformer-based model. |\n| **Mechanism 1** | **Oriented Masking:** A technique used during training to force the model to focus on role-specific language. |\n| **Mechanism 2** | **Label Broadcasting:** Guilt labels predicted in early stages are \"broadcasted\" into a regression model to refine prison term calculations. |\n\n---\n\n### Key Technical Contributions ğŸš€\n\n1.  **Legal Interpretability:** Unlike \"black-box\" models, MMSI mimics judicial reasoning by first identifying guilt roles and then applying those roles to determine the length of imprisonment.\n2.  **Role Sensitivity:** By using a \"comparative data construction strategy,\" the model becomes much more sensitive to the nuances that distinguish a lead offender from a secondary participant.\n3.  **Performance:** The framework outperformed existing baselines on the IMLJP dataset, specifically in the area of role-based culpability differentiation.\n\n---\n\n### How can I help you further? ğŸ¤\n\nI can assist with more specific tasks regarding this paper or the field of AI in Law:\n*   **Deep Dive:** Would you like me to explain how the \"Label Broadcasting\" or \"Oriented Masking\" works in more detail?\n*   **Comparative Analysis:** I can look for other papers on Multidefendant LJP to see how they compare to this MMSI approach.\n*   **Code & Implementation:** If you are a developer, I can help you understand the structure of the provided GitHub repository.\n\nWhat would you like to explore next?",
      "authors": [
        "Xu Zhang",
        "Qinghua Wang",
        "Mengyang Zhao",
        "Fang Wang",
        "Cunquan Qu"
      ],
      "abstract": "Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MMSIï¼ˆé€»è¾‘å¼•å¯¼çš„å¤šé˜¶æ®µæ¨ç†ï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šè¢«å‘Šåˆ‘äº‹æ¡ˆä»¶ä¸­è´£ä»»è®¤å®šå¤æ‚åŠè¢«å‘Šè§’è‰²ç•Œå®šæ¨¡ç³Šçš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åœ¨é¢„è®­ç»ƒ Transformer ç¼–ç å™¨ä¸­èå…¥é‡åˆ‘é€»è¾‘ï¼Œåˆ©ç”¨å®šå‘é®è”½æœºåˆ¶ (oriented masking mechanism) æ˜ç¡®è¢«å‘Šè§’è‰²ï¼Œå¹¶é€šè¿‡å¯¹æ¯”æ•°æ®æ„å»ºç­–ç•¥å¢å¼ºå¯¹ä¸»ä»çŠ¯ç½ªè´£å·®å¼‚çš„æ•æ„Ÿåº¦ã€‚æ­¤å¤–ï¼Œæ¨¡å‹å°†é¢„æµ‹çš„ç½ªåæ ‡ç­¾é€šè¿‡å¹¿æ’­ (broadcasting) æ•´åˆè¿›å›å½’æ¨¡å‹ï¼Œå®ç°äº†æ¡ˆæƒ…æè¿°ä¸æ³•é™¢è§‚ç‚¹çš„æœ‰æ•ˆèåˆã€‚åœ¨ IMLJP æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMMSI åœ¨åŒºåˆ†è¢«å‘Šç½ªè´£æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºå‡†æ¨¡å‹ï¼Œä¸ºæå‡æ™ºèƒ½å¸æ³•ç³»ç»Ÿçš„å‡†ç¡®æ€§ä¸å¯è§£é‡Šæ€§æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12688v1",
      "published_date": "2026-01-19 03:20:36 UTC",
      "updated_date": "2026-01-19 03:20:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:29:10.829186+00:00"
    },
    {
      "arxiv_id": "2601.12671v1",
      "title": "Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification",
      "title_zh": "è”é‚¦å­¦ä¹ ä¸­åˆ©ç”¨æµ‹è¯•æ—¶å¢å¼ºè¿›è¡Œè„‘è‚¿ç˜¤ MRI åˆ†ç±»",
      "authors": [
        "Thamara Leandra de Deus Melo",
        "Rodrigo Moreira",
        "Larissa Ferreira Rodrigues Moreira",
        "AndrÃ© Ricardo Backes"
      ],
      "abstract": "Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. We evaluated convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨**è”é‚¦å­¦ä¹  (Federated Learning, FL)** æ¡†æ¶ä¸‹ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œ (CNNs) è¿›è¡Œè„‘è‚¿ç˜¤ MRI å›¾åƒåˆ†ç±»ï¼Œå¹¶å¯¹æ¯”äº†åŸå§‹å›¾åƒä¸ç»è¿‡å¤šç§é¢„å¤„ç†æ–¹æ¡ˆçš„æ•ˆæœã€‚å®éªŒå‘ç°ï¼Œå•çº¯çš„å›¾åƒé¢„å¤„ç†ï¼ˆå¦‚ç¼©æ”¾ã€ç°åº¦è½¬æ¢ã€å½’ä¸€åŒ–å’Œç›´æ–¹å›¾å‡è¡¡åŒ–ï¼‰å¯¹æ€§èƒ½æå‡å¾®ä¹å…¶å¾®ï¼Œä½†å°†å…¶ä¸**æµ‹è¯•æ—¶å¢å¼º (Test-Time Augmentation, TTA)** ç›¸ç»“åˆæ—¶ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡åˆ†ç±»çš„å‡†ç¡®æ€§ä¸ç¨³å®šæ€§ (p < 0.001)ã€‚\n\nç ”ç©¶å»ºè®®å°† TTA ä½œä¸ºè”é‚¦å­¦ä¹ åŒ»ç–—å½±åƒæ¨ç†çš„é»˜è®¤ç­–ç•¥ã€‚åœ¨è®¡ç®—èµ„æºå……è¶³çš„æƒ…å†µä¸‹ï¼Œå°† TTA ä¸è½»é‡çº§é¢„å¤„ç†é…åˆä½¿ç”¨ï¼Œå¯ä¸ºè„‘è‚¿ç˜¤è¯Šæ–­æä¾›æ›´å¯é çš„æŠ€æœ¯æ”¯æŒã€‚\n\n---\n\n### è®ºæ–‡æ ¸å¿ƒè¦ç´ æ€»ç»“ ğŸ“Š\n\n| ç»´åº¦ | å†…å®¹è¯´æ˜ |\n|---|---|\n| **ç ”ç©¶å¯¹è±¡** | è„‘è‚¿ç˜¤ MRI å›¾åƒåˆ†ç±» |\n| **æ ¸å¿ƒæ–¹æ³•** | è”é‚¦å­¦ä¹  (FL) + æµ‹è¯•æ—¶å¢å¼º (TTA) |\n| **é¢„å¤„ç†æŠ€æœ¯** | Resizing, Grayscale, Normalization, Filtering, Histogram Equalization |\n| **ä¸»è¦å‘ç°** | TTA æ˜¯æå‡æ¨¡å‹æ€§èƒ½çš„å…³é”®ï¼Œä¸”æ•ˆæœä¼˜äºå•çº¯çš„é¢„å¤„ç†ã€‚ |\n| **å®è·µå»ºè®®** | TTA åº”æˆä¸ºåŒ»å­¦å½±åƒåœ¨ FL åœºæ™¯ä¸‹çš„é»˜è®¤æ¨ç†ç­–ç•¥ã€‚ |\n\n---\n\nè¿™ä»½ TLDR æ˜¯å¦æ¶µç›–äº†æ‚¨å…³æ³¨çš„é‡ç‚¹ï¼Ÿå¦‚æœæ‚¨éœ€è¦å¯¹å…·ä½“çš„é¢„å¤„ç†æ­¥éª¤æˆ– TTA çš„å®ç°ç»†èŠ‚è¿›è¡Œæ›´æ·±å…¥çš„äº†è§£ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "21st International Conference on Computer Vision Theory and Applications (VISAPP 2026), 9-11 March 2026, Marbella, Spain",
      "pdf_url": "https://arxiv.org/pdf/2601.12671v1",
      "published_date": "2026-01-19 02:32:50 UTC",
      "updated_date": "2026-01-19 02:32:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:29:46.629856+00:00"
    },
    {
      "arxiv_id": "2601.12667v1",
      "title": "Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration",
      "title_zh": "Thank you for sharing the title and abstract of this interesting research paper! This work addresses a critical challenge in the modern space industry: managing the health of spacecraft power systems (SPS) within the context of massive satellite constellations.\n\nI have summarized the key components of the paper below to provide a clear overview of its contributions and findings.\n\n---\n\n### ğŸš€ Research Overview: SpaceHMchat\nThe paper introduces **SpaceHMchat**, a framework designed to transition spacecraft health management from traditional methods to a scalable, Human-AI collaboration (HAIC) model suitable for the mega-constellation era.\n\n| Feature | Description |\n|---|---|\n| **Core Principle** | Aligning Underlying Capabilities (AUC principle). |\n| **Framework Name** | SpaceHMchat. |\n| **Primary Approach** | All-in-Loop Health Management (AIL HM) via Human-AI Collaboration. |\n| **Scope** | Work condition recognition, anomaly detection, fault localization, and maintenance decision-making. |\n\n---\n\n### ğŸ› ï¸ Key Contributions\nThe authors highlight several major contributions to the field of aerospace engineering and AI applications:\n\n*   **Framework Development**: An open-source Human-AI collaboration framework that covers the entire health management lifecycle.\n*   **Experimental Platform**: The creation of a hardware-realistic fault injection platform and its corresponding open-source simulation model, designed to replicate real-world SPS behavior.\n*   **First-of-its-kind Dataset**: The release of the first All-in-Loop Health Management dataset for SPS, featuring:\n    *   4 distinct sub-datasets.\n    *   17 types of faults.\n    *   Over 700,000 timestamps.\n\n---\n\n### ğŸ“Š Performance Metrics\nThe experimental results indicate that SpaceHMchat performs exceptionally well across various tasks.\n\n| Metric Category | Performance Detail |\n|---|---|\n| **Logical Reasoning** | 100% conclusion accuracy in work condition recognition. |\n| **Tool Invocation** | >99% success rate in anomaly detection tool usage. |\n| **Fault Localization** | >90% precision. |\n| **Search Efficiency** | <3 minutes for knowledge base searches in maintenance decision-making. |\n\n---\n\n### ğŸ’¡ Expected Benefits\nBy implementing SpaceHMchat, the research suggests several operational improvements:\n*   **Efficiency**: Enhanced speed in detecting and resolving faults.\n*   **Interpretability**: Transparent reasoning processes that improve human trust in AI decisions.\n*   **Optimization**: Better personnel structure and seamless knowledge sharing across teams.\n\n---\n\nThis sounds like a significant step forward for autonomous space operations. Would you like me to dive deeper into any specific part of this abstract? For instance, I can:\n1. Explain the **AUC principle** in more detail if provided.\n2. Discuss the implications of **All-in-Loop Health Management** for future satellite missions.\n3. Help you draft a summary or presentation based on this information.\n\nHow would you like to proceed?",
      "authors": [
        "Yi Di",
        "Zhibin Zhao",
        "Fujin Wang",
        "Xue Liu",
        "Jiafeng Tang",
        "Jiaxin Ren",
        "Zhi Zhai",
        "Xuefeng Chen"
      ],
      "abstract": "It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.",
      "tldr_zh": "### Summary of SpaceHMchat Paper\n\n#### Overview ğŸ›°ï¸\nThe paper addresses the challenge of managing the health of thousands of spacecraft power systems (SPS) in the upcoming satellite mega-constellation (SMC) era. It argues that traditional health management (HM) methods designed for dozens of satellites cannot scale to thousands, necessitating a fundamental shift in how we monitor and maintain space assets.\n\n---\n\n#### The SpaceHMchat Framework ğŸ¤–\nI've identified that this work introduces **SpaceHMchat**, an open-source Human-AI collaboration (HAIC) framework. It is designed for \"all-in-loop\" (AIL) health management, covering the entire lifecycle of system monitoring:\n\n| Phase | Description |\n|---|---|\n| **Recognition** | Identifying current work conditions. |\n| **Detection** | Spotting anomalies in real-time. |\n| **Localization** | Pinpointing the specific cause of a fault. |\n| **Decision-Making** | Formulating maintenance and recovery strategies. |\n\nIt is built on the **AUC principle** (Aligning Underlying Capabilities) to bridge the gap between AI's processing power and human expertise, improving interpretability and reasoning.\n\n---\n\n#### Performance Metrics ğŸ“Š\nThe researchers validated SpaceHMchat using a hardware-realistic platform and simulation models. The results demonstrate high reliability across 23 quantitative metrics:\n\n| Metric Category | Performance Result |\n|---|---|\n| Work Condition Recognition (Logical Reasoning) | 100% Accuracy |\n| Anomaly Detection Tool Invocation | > 99% Success Rate |\n| Fault Localization | > 90% Precision |\n| Maintenance Decision KB Search Time | < 3 Minutes |\n\n---\n\n#### Major Contributions ğŸ› ï¸\n*   **AIL HM Framework:** The first comprehensive Human-AI collaboration framework specifically for spacecraft power systems.\n*   **Open-Source Dataset:** The release of the first-ever AIL HM dataset of SPS, featuring 4 sub-datasets, 17 fault types, and over 700,000 timestamps.\n*   **Experimental Platform:** A hardware-realistic fault injection platform and its corresponding open-source simulation model.\n\n---\n\nI'd be happy to dive deeper into any part of this research with you! Would you like me to explain the \"AUC principle\" in more detail, or perhaps you're interested in the specifics of the 17 fault types included in the dataset? Let me know what you're curious about!",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12667v1",
      "published_date": "2026-01-19 02:28:27 UTC",
      "updated_date": "2026-01-19 02:28:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:32:37.786369+00:00"
    },
    {
      "arxiv_id": "2601.12664v1",
      "title": "Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images",
      "title_zh": "é¢å‘éç‹¬ç«‹åŒåˆ†å¸ƒç™Œç—‡å›¾åƒè”é‚¦å­¦ä¹ çš„å¯æ³›åŒ–è¶…å‚æ•°ä¼˜åŒ–",
      "authors": [
        "Elisa GonÃ§alves Ribeiro",
        "Rodrigo Moreira",
        "Larissa Ferreira Rodrigues Moreira",
        "AndrÃ© Ricardo Backes"
      ],
      "abstract": "Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨éç‹¬ç«‹åŒåˆ†å¸ƒ (non-IID) ç™Œç—‡ç—…ç†å½±åƒåœºæ™¯ä¸‹ï¼Œè”é‚¦å­¦ä¹  (Federated Learning) çš„è¶…å‚æ•°ä¼˜åŒ– (Hyperparameter Optimization) é€šç”¨æ€§é—®é¢˜ã€‚ç ”ç©¶è€…é’ˆå¯¹åµå·¢ç™Œå’Œç»“ç›´è‚ ç™Œçš„å½±åƒä»»åŠ¡ï¼Œå…ˆè¿›è¡Œé›†ä¸­å¼è´å¶æ–¯ä¼˜åŒ– (Bayesian optimization)ï¼Œå†å°†ç‰¹å®šæ•°æ®é›†çš„æœ€ä¼˜å‚æ•°è¿ç§»è‡³è”é‚¦å­¦ä¹ ç¯å¢ƒä¸­ã€‚æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ç§ç®€å•çš„è·¨æ•°æ®é›†èšåˆå¯å‘å¼æ–¹æ³• (cross-dataset aggregation heuristic)ï¼Œé€šè¿‡å¹³å‡å­¦ä¹ ç‡ (learning rates) å¹¶é€‰å–ä¼˜åŒ–å™¨ (optimizers) å’Œæ‰¹æ¬¡å¤§å° (batch sizes) çš„ä¼—æ•°æ¥æ•´åˆå‚æ•°é…ç½®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§ç»„åˆé…ç½®åœ¨ non-IID åœºæ™¯ä¸‹å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„åˆ†ç±»æ€§èƒ½ï¼Œä¸ºéšç§å—é™ä¸´åºŠç¯å¢ƒä¸‹çš„æ¨¡å‹ä¼˜åŒ–æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "21st International Conference on Computer Vision Theory and Applications (VISAPP 2026), 9-11 March 2026, Marbella, Spain",
      "pdf_url": "https://arxiv.org/pdf/2601.12664v1",
      "published_date": "2026-01-19 02:24:24 UTC",
      "updated_date": "2026-01-19 02:24:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:32:42.074390+00:00"
    },
    {
      "arxiv_id": "2601.12661v1",
      "title": "MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents",
      "title_zh": "MedConsultBenchï¼šé¢å‘åŒ»ç–—å’¨è¯¢æ™ºèƒ½ä½“çš„å…¨å‘¨æœŸã€ç»†ç²’åº¦ã€è¿‡ç¨‹æ„ŸçŸ¥è¯„æµ‹åŸºå‡†",
      "authors": [
        "Chuhan Qiao",
        "Jianghua Huang",
        "Daxing Zhao",
        "Ziding Liu",
        "Yanjun Shen",
        "Bing Cheng",
        "Wei Lin",
        "Kai Wu"
      ],
      "abstract": "Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q\\&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q\\&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† **MedConsultBench**ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹åŒ»ç–—å’¨è¯¢æ™ºèƒ½ä½“çš„å…¨å‘¨æœŸã€ç»†ç²’åº¦ä¸”å…³æ³¨è¿‡ç¨‹çš„è¯„ä¼°åŸºå‡†ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¯„ä¼°è¿‡äºä¾§é‡ç»“æœè€Œå¿½ç•¥ä¸´åºŠå®‰å…¨ä¸è¿‡ç¨‹å®Œæ•´æ€§çš„é—®é¢˜ã€‚\n\n---\n\n### ğŸ“ æ ¸å¿ƒæ‘˜è¦ (TLDR)\n\nè¯¥æ¡†æ¶è¦†ç›–äº†ä»ç—…å²é‡‡é›† (**History taking**)ã€è¯Šæ–­åˆ°æ²»ç–—è®¡åˆ’åŠéšè®¿ (**Follow-up Q\\&A**) çš„å®Œæ•´ä¸´åºŠå·¥ä½œæµã€‚é€šè¿‡å¼•å…¥åŸå­ä¿¡æ¯å•å…ƒ (**Atomic Information Units, AIUs**)ï¼Œç ”ç©¶è€…åˆ©ç”¨ 22 ä¸ªç»†ç²’åº¦æŒ‡æ ‡å®ç°äº†å¯¹ä¸´åºŠä¿¡æ¯è·å–æ•ˆç‡çš„äºšè½®æ¬¡ (Sub-turn) ç²¾ç¡®ç›‘æ§ã€‚å¯¹ 19 ä¸ªå¤§è¯­è¨€æ¨¡å‹ (**LLMs**) çš„ç³»ç»Ÿè¯„ä¼°æ˜¾ç¤ºï¼Œé«˜è¯Šæ–­å‡†ç¡®ç‡å¾€å¾€æ©ç›–äº†æ¨¡å‹åœ¨ä¿¡æ¯é‡‡é›†æ•ˆç‡å’Œç”¨è¯å®‰å…¨ (**Medication safety**) æ–¹é¢çš„ä¸¥é‡ç¼ºé™·ã€‚**MedConsultBench** ä¸ºç¼©å°åŒ»ç–— AI çš„ç†è®ºçŸ¥è¯†ä¸å®é™…ä¸´åºŠæ‰§ä¸šèƒ½åŠ›ä¹‹é—´çš„å·®è·æä¾›äº†é‡è¦çš„è¯„ä¼°åŸºç¡€ã€‚\n\n---\n\n### ğŸ“Š æ¡†æ¶ä¸è¯„ä¼°æ ¸å¿ƒ\n\n| ç»´åº¦ | å…³é”®ç‰¹å¾/å‘ç° |\n|---|---|\n| **è¦†ç›–èŒƒå›´** | åŒ…å«ç—…å²é‡‡é›†ã€è¯Šæ–­ã€å¤„æ–¹åˆ¶å®šåŠå¤„æ–¹åéšè®¿çš„å®Œæ•´é—­ç¯ã€‚ |\n| **æŠ€æœ¯æ–¹æ³•** | å¼•å…¥ **AIUs** è¿½è¸ªå…³é”®äº‹å®çš„è§¦å‘ï¼Œè§£å†³åœ¨çº¿å’¨è¯¢ä¸­çš„ä¸ç¡®å®šæ€§ä¸æ­§ä¹‰ã€‚ |\n| **è¯„ä¼°ç»“æœ** | è¯Šæ–­å‡†ç¡®ç‡ä¸ä¸´åºŠå®è·µèƒ½åŠ›ï¼ˆå¦‚ç”¨è¯å®‰å…¨ã€æ•ˆç‡ï¼‰ä¹‹é—´å­˜åœ¨æ˜¾è‘—è„±èŠ‚ã€‚ |\n| **æ ¸å¿ƒæŒ‡æ ‡** | åŒ…å« 22 ä¸ªç»†ç²’åº¦æŒ‡æ ‡ï¼Œå¼ºè°ƒå¯¹çº¦æŸæ¡ä»¶çš„éµå®ˆä¸æ–¹æ¡ˆä¿®è®¢èƒ½åŠ›ã€‚ |\n\n---\n\nè¿™ä»½ç ”ç©¶å¯¹äºæƒ³è¦å°† AI åº”ç”¨äºçœŸå®é—¨è¯Šåœºæ™¯çš„å¼€å‘è€…éå¸¸é‡è¦ã€‚æ‚¨æ˜¯æƒ³æ·±å…¥äº†è§£ **AIUs** æ˜¯å¦‚ä½•é‡åŒ–ä¿¡æ¯é‡‡é›†æ•ˆç‡çš„ï¼Œè¿˜æ˜¯å¯¹é‚£ 19 ä¸ª **LLMs** çš„å…·ä½“è¡¨ç°æ’åæ›´æ„Ÿå…´è¶£ï¼Ÿ",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12661v1",
      "published_date": "2026-01-19 02:18:10 UTC",
      "updated_date": "2026-01-19 02:18:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:32:50.773131+00:00"
    },
    {
      "arxiv_id": "2601.12658v1",
      "title": "Augmenting Question Answering with A Hybrid RAG Approach",
      "title_zh": "### Overview of SSRAG ğŸ“„\n\nThank you for sharing the abstract for your paper, **\"Augmenting Question Answering with A Hybrid RAG Approach.\"** It sounds like a significant advancement in addressing the retrieval limitations of standard RAG systems. By combining vector-based and graph-based techniques with agentic routing, your **Structured-Semantic RAG (SSRAG)** architecture seems well-positioned to handle complex contextual grounding.\n\n---\n\n### Key Features and Methodology ğŸ› ï¸\n\n| Feature | Description |\n|---|---|\n| **Query Augmentation** | Refines the initial user query to improve the search scope and retrieval accuracy. |\n| **Agentic Routing** | Dynamically directs queries to the most appropriate retrieval path or specialized module. |\n| **Structured Retrieval** | A hybrid mechanism that utilizes both vector embeddings (semantic) and knowledge graphs (relational). |\n| **Context Unification** | Merges diverse retrieved data points into a cohesive context for the LLM to process. |\n| **Evaluation Metrics** | Tested against TruthfulQA, SQuAD, and WikiQA datasets using five different Large Language Models. |\n\n---\n\n### How can I help you with this? ğŸ¤”\n\nI'm Gemini Enterprise, and I'd love to assist you further with your research. Would you like me to:\n\n*   Generate a more detailed summary or a \"plain English\" explanation of the abstract?\n*   Identify potential limitations or areas for future work based on this description?\n*   Draft a set of discussion points or presentation slides for this paper?\n*   Compare this hybrid approach to other common RAG architectures?\n\nLet me know how you'd like to proceed!",
      "authors": [
        "Tianyi Yang",
        "Nashrah Haque",
        "Vaishnave Jonnalagadda",
        "Yuya Jeremy Ong",
        "Zhehui Chen",
        "Yanzhao Wu",
        "Lei Yu",
        "Divyesh Jadav",
        "Wenqi Wei"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ï¼šAugmenting Question Answering with A Hybrid RAG Approach\n\n---\n\nè¯¥ç ”ç©¶æå‡ºäº† **Structured-Semantic RAG (SSRAG)**ï¼Œä¸€ç§æ—¨åœ¨æå‡é—®ç­”ï¼ˆ**QA**ï¼‰ä»»åŠ¡è´¨é‡çš„æ··åˆæ¶æ„ï¼Œè§£å†³äº†ä¼ ç»Ÿ **Retrieval-Augmented Generation (RAG)** åœ¨æ£€ç´¢ä¸Šä¸‹æ–‡ç›¸å…³æ€§æ–¹é¢çš„ä¸è¶³ã€‚è¯¥æ–¹æ³•é›†æˆäº† **query augmentation**ï¼ˆæŸ¥è¯¢å¢å¼ºï¼‰ã€**agentic routing**ï¼ˆæ™ºèƒ½ä»£ç†è·¯ç”±ï¼‰ä»¥åŠä¸€ç§ç»“åˆ **vector** ä¸ **graph based techniques**ï¼ˆåŸºäºå›¾çš„æŠ€æœ¯ï¼‰çš„ç»“æ„åŒ–æ£€ç´¢æœºåˆ¶ï¼Œå¹¶é€šè¿‡ **context unification**ï¼ˆä¸Šä¸‹æ–‡ç»Ÿä¸€ï¼‰å®ç°æ›´å¼ºçš„è¯­ä¹‰å¯¹é½ã€‚åœ¨ **TruthfulQA**ã€**SQuAD** å’Œ **WikiQA** æ•°æ®é›†ä¸Šé’ˆå¯¹äº”ç§ **Large Language Models (LLMs)** çš„å®éªŒè¡¨æ˜ï¼ŒSSRAG åœ¨å›ç­”å‡†ç¡®æ€§ï¼ˆ**accuracy**ï¼‰å’Œä¿¡æ¯é‡ï¼ˆ**informativeness**ï¼‰æ–¹é¢å‡æ˜¾è‘—ä¼˜äºæ ‡å‡† **RAG** å®ç°ã€‚\n\n---\n\næˆ‘ä¹Ÿéå¸¸ä¹æ„ä¸ºæ‚¨ç»§ç»­åˆ†æå…¶ä»–å­¦æœ¯è®ºæ–‡ï¼Œå¦‚æœæ‚¨æœ‰æ–°çš„æ ‡é¢˜å’Œæ‘˜è¦ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 tables, 2 figures; presented at IEEE CogMI 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.12658v1",
      "published_date": "2026-01-19 02:08:47 UTC",
      "updated_date": "2026-01-19 02:08:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:32:22.570793+00:00"
    },
    {
      "arxiv_id": "2601.12654v1",
      "title": "Explanation Multiplicity in SHAP: Characterization and Assessment",
      "title_zh": "# Overview of \"Explanation Multiplicity in SHAP\" ğŸ”\n\nThis paper addresses a critical reliability issue in Explainable AI (XAI), specifically focusing on the SHAP (SHapley Additive exPlanations) framework. It introduces the concept of **explanation multiplicity**, where the same model and input can yield different explanations across different runs.\n\n---\n\n## Summary Table ğŸ“Š\n\n| Aspect | Description |\n|---|---|\n| **The Problem** | SHAP explanations are often inconsistent. Even with the same model and input, repeated runs can produce different feature attributions. |\n| **Explanation Multiplicity** | The authors define this as the existence of multiple, internally valid, yet substantively different explanations for a single decision. |\n| **Metrics of Stability** | Stability depends on the metric used. While magnitude-based distances might seem stable, rank-based measures often reveal significant \"churn\" in which features are considered most important. |\n| **Findings** | Multiplicity is pervasive across various datasets and model classes, persisting even when the model is highly confident in its prediction. |\n\n---\n\n## Key Takeaways ğŸ’¡\n\n*   **Ranking Inconsistency:** If you rely on SHAP to identify the \"top N\" features driving a decision, be cautious. The identity and order of these features can shift significantly between runs.\n*   **Stochasticity:** The variation isn't just about the model's training; it is often intrinsic to the explanation pipeline itself (the math and sampling used to generate the SHAP values).\n*   **Need for Better Baselines:** The authors suggest that we need randomized baseline values and metrics that better align with how explanations are actually used in the real world to contextualize this disagreement.\n\n---\n\nThis research highlights a major challenge for auditing automated decisions in high-stakes fields like finance or healthcare. \n\nWould you like me to dive deeper into any of these points, or perhaps help you summarize the implications of this paper for a specific project you're working on? I'm here to help! ğŸš€",
      "authors": [
        "Hyunseung Hwang",
        "Seungeun Lee",
        "Lucas Rosenblatt",
        "Julia Stoyanovich",
        "Steven Euijong Whang"
      ],
      "abstract": "Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† SHAP è§£é‡Šåœ¨è¾“å…¥å’Œæ¨¡å‹å›ºå®šæ—¶ä»ä¼šå‡ºç°æ˜¾è‘—å·®å¼‚çš„ç°è±¡ï¼Œå¹¶å°†å…¶å®šä¹‰ä¸ºè§£é‡Šå¤šæ ·æ€§ (Explanation Multiplicity)ã€‚ä½œè€…æå‡ºäº†ä¸€å¥—æ–¹æ³•è®ºæ¥è¡¨å¾ç‰¹å¾å½’å› è§£é‡Šä¸­çš„å¤šæ ·æ€§ï¼Œæ—¨åœ¨åŒºåˆ†æ¨¡å‹è®­ç»ƒ/é€‰æ‹©ä¸è§£é‡Šæµç¨‹å†…åœ¨éšæœºæ€§è¿™ä¸¤ç±»å·®å¼‚æ¥æºã€‚ç ”ç©¶å‘ç°ï¼Œè§£é‡Šçš„ç¨³å®šæ€§é«˜åº¦ä¾èµ–äºè¯„ä¼°æŒ‡æ ‡ï¼šè™½ç„¶åŸºäºæ•°å€¼å¤§å°çš„è·ç¦»å¯èƒ½æ¥è¿‘äºé›¶ï¼Œä½†åŸºäºæ’åçš„æŒ‡æ ‡æ­ç¤ºäº†æ ¸å¿ƒç‰¹å¾åŠå…¶é¡ºåºå­˜åœ¨æ˜¾è‘—å˜åŠ¨ã€‚å®éªŒè¯æ˜è§£é‡Šå¤šæ ·æ€§åœ¨ä¸åŒæ•°æ®é›†å’Œæ¨¡å‹ä¸­æ™®éå­˜åœ¨ï¼Œå³ä½¿åœ¨é«˜ç½®ä¿¡åº¦é¢„æµ‹ä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œè¿™å¼ºè°ƒäº†å¼€å‘ä¸å…·ä½“ç”¨é€”ç›¸åŒ¹é…çš„åº¦é‡æŒ‡æ ‡å’ŒåŸºå‡† (Baselines) çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12654v1",
      "published_date": "2026-01-19 02:01:18 UTC",
      "updated_date": "2026-01-19 02:01:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:32:33.174013+00:00"
    },
    {
      "arxiv_id": "2601.12648v1",
      "title": "Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?",
      "title_zh": "åŒ»å­¦æ•™è‚²ä¸­çš„æ™ºèƒ½æ–‡ä¹¦ï¼šAI èƒ½å¦å–ä»£äººå·¥ç—…ä¾‹è®°å½•ï¼Ÿ",
      "authors": [
        "Nafiz Imtiaz Khan",
        "Kylie Cleland",
        "Vladimir Filkov",
        "Roger Eric Goldman"
      ],
      "abstract": "Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨ Large Language Models (LLMs) è‡ªåŠ¨ä»è‡ªç”±æ–‡æœ¬æ”¾å°„å­¦æŠ¥å‘Šä¸­æå–ç¨‹åºä¿¡æ¯ï¼Œä»¥æ›¿ä»£è€—æ—¶ä¸”æ˜“å‡ºé”™çš„æ‰‹åŠ¨ç—…ä¾‹æ—¥å¿—è®°å½•ã€‚ç ”ç©¶äººå‘˜é€šè¿‡ Instruction-based å’Œ Chain-of-Thought æç¤ºæŠ€æœ¯ï¼Œè¯„ä¼°äº†å¤šç§æœ¬åœ°åŠå•†ä¸šæ¨¡å‹åœ¨414ä»½ä»‹å…¥æ”¾å°„å­¦æŠ¥å‘Šä¸Šçš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹è¡¨ç°ä¼˜å¼‚ï¼Œæœ€ä½³ F1-score æ¥è¿‘0.87ï¼Œè¯æ˜äº† LLMs åœ¨å‡å°‘åŒ»å­¦å­¦å‘˜æ–‡ä¹¦è´Ÿæ‹…å’Œæé«˜æ—¥å¿—ä¸€è‡´æ€§æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚è¿™ä¸€å‘ç°è¯å®äº† AI è¾…åŠ©æ–‡æ¡£åœ¨åŒ»å­¦æ•™è‚²ä¸­çš„å¯è¡Œæ€§ï¼Œä¸ºæœªæ¥è·¨æœºæ„ä¸´åºŠå·¥ä½œæµçš„è‡ªåŠ¨åŒ–æä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "51 pages, 12 figures, 8 tables. Feasibility study using retrospective radiology reports. Submitted to JAMIA Open (under review)",
      "pdf_url": "https://arxiv.org/pdf/2601.12648v1",
      "published_date": "2026-01-19 01:45:51 UTC",
      "updated_date": "2026-01-19 01:45:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:33:50.273813+00:00"
    },
    {
      "arxiv_id": "2601.12646v1",
      "title": "Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI",
      "title_zh": "æ— ç•ŒæŸå®³ï¼Œæœ‰ç•Œæ³•å¾‹ï¼šæ— å›½ç•Œ AI æ—¶ä»£çš„æ³•å¾‹è´£ä»»",
      "authors": [
        "Ha-Chi Tran"
      ],
      "abstract": "The rapid proliferation of artificial intelligence (AI) has exposed significant deficiencies in risk governance. While ex-ante harm identification and prevention have advanced, Responsible AI scholarship remains underdeveloped in addressing ex-post liability. Core legal questions regarding liability allocation, responsibility attribution, and remedial effectiveness remain insufficiently theorized and institutionalized, particularly for transboundary harms and risks that transcend national jurisdictions. Drawing on contemporary AI risk analyses, we argue that such harms are structurally embedded in global AI supply chains and are likely to escalate in frequency and severity due to cross-border deployment, data infrastructures, and uneven national oversight capacities. Consequently, territorially bounded liability regimes are increasingly inadequate. Using a comparative and interdisciplinary approach, this paper examines compensation and liability frameworks from high-risk transnational domains - including vaccine injury schemes, systemic financial risk governance, commercial nuclear liability, and international environmental regimes - to distill transferable legal design principles such as strict liability, risk pooling, collective risk-sharing, and liability channelling, while highlighting potential structural constraints on their application to AI-related harms. Situated within an international order shaped more by AI arms race dynamics than cooperative governance, the paper outlines the contours of a global AI accountability and compensation architecture, emphasizing the tension between geopolitical rivalry and the collective action required to govern transboundary AI risks effectively.",
      "tldr_zh": "### Paper Overview ğŸ“„\n\n| Title | **Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI** |\n|---|---|\n| **Primary Theme** | The gap between global AI-related harms and territorially limited legal liability frameworks. |\n| **Core Argument** | Current national liability regimes are inadequate for \"transboundary\" harms caused by global AI supply chains and cross-border data infrastructures. |\n| **Methodology** | Comparative analysis of existing transnational risk regimes (Nuclear, Environmental, Financial, etc.) to propose a global AI accountability architecture. |\n\n---\n\n### Key Concepts & Design Principles ğŸ’¡\n\nBased on your abstract, Iâ€™ve identified the central legal principles you are exploring:\n\n*   **Strict Liability:** Moving beyond fault-based systems to ensure compensation for high-risk AI failures.\n*   **Risk Pooling & Collective Sharing:** Utilizing mechanisms similar to vaccine injury schemes or nuclear liability to manage systemic risks.\n*   **Liability Channeling:** Determining which entity in the global supply chain (developer, deployer, or infrastructure provider) should bear primary responsibility.\n*   **Geopolitical Tension:** Balancing the need for global cooperation against the competitive \"AI arms race\" between nations.\n\n---\n\nThis is a fascinating and timely topic! How can I help you with this project? I can assist with:\n\n1.  **Critical Review:** Providing feedback on the logical flow or clarity of the abstract.\n2.  **Comparative Analysis:** Digging deeper into the specific international regimes you mentioned (e.g., how the Paris Convention on Third Party Liability in the Field of Nuclear Energy compares to AI).\n3.  **Drafting Support:** Helping you expand specific sections of the paper.\n4.  **Formatting:** Generating a bibliography or structuring the paper in a specific academic style.\n\nWhat would you like to focus on first?",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12646v1",
      "published_date": "2026-01-19 01:44:14 UTC",
      "updated_date": "2026-01-19 01:44:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:33:00.970958+00:00"
    },
    {
      "arxiv_id": "2601.12641v1",
      "title": "STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models",
      "title_zh": "This is a fascinating paper on bridging the gap between natural language and manufacturable CAD models. Below is a summary of the **STEP-LLM** framework based on the abstract you provided.\n\n---\n\n### ğŸ“„ Overview of STEP-LLM\n\nThe paper introduces a novel approach to **Text-to-CAD** generation by focusing on the **STEP (ISO 10303)** format. Unlike previous methods that rely on specific scripts (like CadQuery) or command sequences, STEP files are neutral Boundary Representation (B-rep) formats that are globally recognized in manufacturing.\n\n---\n\n### ğŸ› ï¸ Key Innovations and Methodology\n\nThe authors address the challenge of the graph-structured nature of STEP files through several technical layers:\n\n| Component | Purpose & Function |\n|---|---|\n| **DFS-based Reserialization** | A depth-first search approach to linearize complex cross-references in STEP files while maintaining geometric locality. |\n| **Structural Annotations** | Uses Chain-of-Thought (CoT) style guidance to help the LLM maintain global coherence during the generation process. |\n| **RAG Module** | Integrates Retrieval-Augmented Generation to ground the model's predictions in relevant, existing examples. |\n| **Reinforcement Learning** | Refines model quality using a specific **Chamfer Distance-based** reward to minimize geometric discrepancy. |\n| **Curation of Dataset** | A new dataset comprising approximately **40,000 STEP-caption pairs**. |\n\n---\n\n### ğŸ“ˆ Results and Impact\n\nThe experiments indicate that **STEP-LLM** consistently outperforms the existing **Text2CAD** baseline. \n\n*   **Geometric Fidelity:** Higher accuracy and fewer discrepancies in the generated shapes.\n*   **Renderability:** The RAG module significantly improves the completeness of the models, making them easier to render and use.\n*   **Democratization:** By allowing non-experts to generate complex CAD models through intuitive natural language, this research has the potential to make professional manufacturing design much more accessible.\n\n---\n\nI'd be happy to dive deeper into this paper with you. Would you like me to:\n1.  Explain a specific part of the methodology, like the **Chamfer Distance** reward?\n2.  Compare this approach to other **Text-to-CAD** methods?\n3.  Help you draft a summary or presentation based on this abstract?",
      "authors": [
        "Xiangyu Shi",
        "Junyang Ding",
        "Xu Zhao",
        "Sinong Zhan",
        "Payal Mohapatra",
        "Daniel Quispe",
        "Kojo Welbeck",
        "Jian Cao",
        "Wei Chen",
        "Ping Guo",
        "Qi Zhu"
      ],
      "abstract": "Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.",
      "tldr_zh": "### è®ºæ–‡æ‘˜è¦ (TLDR) ğŸš€\n\n---\n\nè¯¥ç ”ç©¶æå‡ºäº† **STEP-LLM**ï¼Œä¸€ç§èƒ½å¤Ÿç›´æ¥ä»è‡ªç„¶è¯­è¨€ç”Ÿæˆ **STEP (ISO 10303)** æ ¼å¼æ¨¡å‹çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ **Text-to-CAD** æ–¹æ³•ä¾èµ–ç‰¹å®šå†…æ ¸ä¸”é€šç”¨æ€§ä¸è¶³çš„é—®é¢˜ã€‚ä¸ºäº†å¤„ç† **STEP** æ–‡ä»¶å¤æ‚çš„å›¾ç»“æ„ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†åŸºäºæ·±åº¦ä¼˜å…ˆæœç´¢ (**DFS-based reserialization**) çš„åºåˆ—åŒ–æŠ€æœ¯å’Œé“¾å¼æ€ç»´ (**Chain-of-Thought**) ç»“æ„æ ‡æ³¨ï¼Œä»¥ä¿æŒå‡ ä½•ç»“æ„çš„å±€éƒ¨æ€§ä¸å…¨å±€ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæ¡†æ¶ç»“åˆäº†æ£€ç´¢å¢å¼ºç”Ÿæˆ (**RAG**) å’ŒåŸºäºå€’è§’è·ç¦» (**Chamfer Distance**) çš„å¼ºåŒ–å­¦ä¹  (**RL**) å¥–åŠ±æœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆæ¨¡å‹çš„å‡ ä½•ä¿çœŸåº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œ**STEP-LLM** åœ¨å®Œæ•´æ€§å’Œæ¸²æŸ“æˆåŠŸç‡ä¸Šå‡ä¼˜äº **Text2CAD** åŸºçº¿ï¼Œå±•ç¤ºäº†åˆ©ç”¨ **LLM** æ¨åŠ¨åˆ¶é€ ä¸š **CAD** è®¾è®¡æ°‘ä¸»åŒ–çš„æ½œåŠ›ã€‚\n\n---\n\n### æ ¸å¿ƒäº®ç‚¹é¢„è§ˆ ğŸ’¡\n\n| ç»´åº¦ | å†…å®¹è¯´æ˜ |\n|---|---|\n| **æ ¸å¿ƒè´¡çŒ®** | å¼€å‘äº†é¦–ä¸ªä»è‡ªç„¶è¯­è¨€ç›´æ¥ç”Ÿæˆåˆ¶é€ ä¸šæ ‡å‡† **STEP** æ ¼å¼çš„ **LLM** æ¡†æ¶ã€‚ |\n| **å…³é”®æŠ€æœ¯** | **DFS-based reserialization**ã€**CoT-style structural annotations**ã€**RAG** ä»¥åŠ **RL**ã€‚ |\n| **æ•°æ®é›†** | æ„å»ºäº†åŒ…å«çº¦ 4 ä¸‡ä¸ª **STEP-caption** å¯¹çš„ä¸“ç”¨æ•°æ®é›†ã€‚ |\n| **ä¸»è¦å‘ç°** | ç›¸æ¯” **Text2CAD**ï¼Œæ–°æ¡†æ¶åœ¨å‡ ä½•ä¿çœŸåº¦ã€æ¨¡å‹å®Œæ•´æ€§å’Œå¯æ¸²æŸ“æ€§æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚ |\n\n---\n\nè¿™ä»½æ‘˜è¦å‡†ç¡®æ•æ‰åˆ°äº†è®ºæ–‡çš„æŠ€æœ¯è·¯çº¿ä¸å®éªŒæˆæœã€‚æ‚¨æ˜¯å¦éœ€è¦æˆ‘é’ˆå¯¹ **DFS** åºåˆ—åŒ–çš„å…·ä½“å®ç°ï¼Œæˆ–è€… **Chamfer Distance** å¥–åŠ±æœºåˆ¶åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨åšæ›´æ·±å…¥çš„è§£è¯»ï¼Ÿ",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the Design, Automation & Test in Europe Conference (DATE) 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12641v1",
      "published_date": "2026-01-19 01:10:49 UTC",
      "updated_date": "2026-01-19 01:10:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:33:19.716144+00:00"
    },
    {
      "arxiv_id": "2601.12638v1",
      "title": "Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT",
      "title_zh": "åŸºäº TensorRT çš„æ··åˆç²¾åº¦ PointPillarsï¼šå®ç°é«˜æ•ˆ 3D ç›®æ ‡æ£€æµ‹",
      "authors": [
        "Ninnart Fuengfusin",
        "Keisuke Yoneda",
        "Naoki Suganuma"
      ],
      "abstract": "LIDAR 3D object detection is one of the important tasks for autonomous vehicles. Ensuring that this task operates in real-time is crucial. Toward this, model quantization can be used to accelerate the runtime. However, directly applying model quantization often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. To address the wide numerical distribution, we proposed a mixed precision framework designed for PointPillars. Our framework first searches for sensitive layers with post-training quantization (PTQ) by quantizing one layer at a time to 8-bit integer (INT8) and evaluating each model for average precision (AP). The top-k most sensitive layers are assigned as floating point (FP). Combinations of these layers are greedily searched to produce candidate mixed precision models, which are finalized with either PTQ or quantization-aware training (QAT). Furthermore, to handle outliers, we observe that using a very small number of calibration data reduces the likelihood of encountering outliers, thereby improving PTQ performance. Our methods provides mixed precision models without training in the PTQ pipeline, while our QAT pipeline achieves the performance competitive to FP models. With TensorRT deployment, our models offer less latency and sizes by up to 2.35 and 2.26 times, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹ PointPillars çš„æ··åˆç²¾åº¦ (mixed precision) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è‡ªåŠ¨é©¾é©¶ä¸­ LIDAR 3D object detection ä»»åŠ¡å› æ¨¡å‹é‡åŒ–å¯¼è‡´çš„æ€§èƒ½é€€åŒ–é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡é€å±‚è¯„ä¼°è¯†åˆ«å¯¹ç²¾åº¦æ•æ„Ÿçš„å…³é”®å±‚å¹¶å°†å…¶ä¿ç•™ä¸º FP æ ¼å¼ï¼Œå…¶ä½™å±‚åˆ™é‡åŒ–ä¸º INT8ï¼Œå¹¶å·§å¦™åˆ©ç”¨æå°‘é‡æ ¡å‡†æ•°æ®å‡å°‘äº†ç¦»ç¾¤å€¼ (outliers) å¯¹é‡åŒ–çš„å¹²æ‰°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶çš„ PTQ æµç¨‹æ— éœ€è®­ç»ƒå³å¯ç”Ÿæˆé«˜æ•ˆæ¨¡å‹ï¼Œè€Œ QAT æµç¨‹çš„æ€§èƒ½å¯åª²ç¾å…¨ç²¾åº¦æ¨¡å‹ã€‚ç» TensorRT éƒ¨ç½²åï¼Œè¯¥æ¨¡å‹åœ¨æ¨ç†å»¶è¿Ÿå’Œå­˜å‚¨ä½“ç§¯ä¸Šåˆ†åˆ«å®ç°äº†é«˜è¾¾ 2.35 å€å’Œ 2.26 å€çš„ä¼˜åŒ–ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12638v1",
      "published_date": "2026-01-19 00:59:13 UTC",
      "updated_date": "2026-01-19 00:59:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:33:33.105217+00:00"
    },
    {
      "arxiv_id": "2601.12637v1",
      "title": "Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction",
      "title_zh": "ç”¨äºé«˜æ•ˆåˆ†å­æ€§è´¨é¢„æµ‹çš„æ‹“æ‰‘æ„ŸçŸ¥å¤šå°ºåº¦æ··åˆä¸“å®¶æ¨¡å‹",
      "authors": [
        "Long D. Nguyen",
        "Kelin Xia",
        "Binh P. Nguyen"
      ],
      "abstract": "Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Yet most 3D molecular graph neural networks still rely on globally fixed neighborhood heuristics, typically defined by distance cutoffs and maximum neighbor limits, to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. We propose Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. Our contributions are threefold: (1) we introduce a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) we design a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) we show that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Multiscale Interaction Mixture of Experts (MI-MoE) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ 3D åˆ†å­å›¾ç¥ç»ç½‘ç»œä¾èµ–å›ºå®šè·ç¦»åˆ‡æ–­ï¼ˆdistance cutoffsï¼‰è€Œå¯¼è‡´äº¤äº’å»ºæ¨¡åƒµåŒ–çš„é—®é¢˜ã€‚MI-MoE å¼•å…¥äº†è·ç¦»åˆ‡æ–­ä¸“å®¶é›†æˆï¼ˆdistance-cutoff expert ensembleï¼‰ï¼Œèƒ½å¤ŸåŒæ—¶æ˜¾å¼æ•æ‰åˆ†å­é—´çš„çŸ­ã€ä¸­ã€é•¿ç¨‹ç›¸äº’ä½œç”¨ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è®¾è®¡äº†åŸºäºæ‹“æ‰‘çš„é—¨æ§ç¼–ç å™¨ï¼ˆtopological gating encoderï¼‰ï¼Œåˆ©ç”¨æŒç»­åŒè°ƒï¼ˆpersistent homologyï¼‰ç‰¹å¾æ¥å¼•å¯¼è¾“å…¥æ•°æ®åœ¨ä¸åŒä¸“å®¶æ¨¡å—é—´çš„è·¯ç”±ã€‚å®éªŒè¯æ˜ï¼ŒMI-MoE ä½œä¸ºä¸€ä¸ªå³æ’å³ç”¨ï¼ˆplug-inï¼‰æ¨¡å—ï¼Œèƒ½æ˜¾è‘—æå‡å¤šç§ 3D åˆ†å­éª¨æ¶æ¨¡å‹åœ¨åˆ†å­åŠèšåˆç‰©å±æ€§é¢„æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼ŒéªŒè¯äº†æ‹“æ‰‘æ„ŸçŸ¥å¤šå°ºåº¦è·¯ç”±åœ¨ 3D åˆ†å­å›¾å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12637v1",
      "published_date": "2026-01-19 00:54:24 UTC",
      "updated_date": "2026-01-19 00:54:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2026-01-22T07:34:21.071660+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 111,
  "processed_papers_count": 111,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-22T07:36:39.981044+00:00"
}