{
  "date": "2026-01-19",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2026-01-19 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\næˆ‘æ˜¯ä½ ä»¬çš„æ—¥æŠ¥ä½œè€…ã€‚ä»Šå¤© arXiv æ›´æ–°äº† 111 ç¯‡è®ºæ–‡ï¼Œæ•°é‡å¯è§‚ä¸”è´¨é‡é¢‡é«˜ã€‚\n\n**ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„é‡å¤´æˆé›†ä¸­åœ¨**å¯¹ AI æ ¸å¿ƒèƒ½åŠ›çš„é‡æ–°å®¡è§†**â€”â€”ä»å‘ç° GNN æœ¬è´¨ä¸Šæ˜¯ä¸€ç§å¯å‘å¼ç®—æ³•ï¼Œåˆ°æ­ç¤º LLM æ¨ç†è¿‡ç¨‹ä¸­çš„â€œå‡ ä½•ç»“æ„â€ç›¸å˜ï¼Œå†åˆ° YOLO26 å¯¹å®æ—¶ç›®æ ‡æ£€æµ‹çš„é©æ–°ã€‚æ­¤å¤–ï¼Œå…³äº AI Agent åœ¨åä½œå’Œä¿®æ­£æ–¹é¢çš„â€œç¬¨æ‹™â€è¡¨ç°ï¼Œä»¥åŠ AI ç”Ÿæˆæ•°æ®å¯¹åŒ»ç–—é¢†åŸŸçš„â€œæ±¡æŸ“â€è­¦å‘Šï¼Œéƒ½å€¼å¾—æ·±æ€ã€‚\n\n---\n\n### ğŸš€ æ·±åº¦ç†è®ºä¸æ¶æ„é©æ–°\nè¿™é‡Œæœ‰ä¸¤ç¯‡å¯èƒ½æ”¹å˜æˆ‘ä»¬å¯¹ç°æœ‰æ¨¡å‹è®¤çŸ¥çš„æ–‡ç« ï¼Œéå¸¸ç¡¬æ ¸ã€‚\n\n**1. Graph Neural Networks are Heuristics (å›¾ç¥ç»ç½‘ç»œæ˜¯å¯å‘å¼ç®—æ³•)**\n*   **Authors:** Yimeng Min, Carla P. Gomes (åº·å¥ˆå°”å¤§å­¦åç»„)\n*   **æ ¸å¿ƒå‘ç°:** è¿™ç¯‡æ–‡ç« æå…·é¢ è¦†æ€§ã€‚ä½œè€…è¯æ˜äº† GNN ä¸éœ€è¦ç›‘ç£è®­ç»ƒæˆ–æ˜¾å¼æœç´¢å°±èƒ½è§£å†³ç»„åˆä¼˜åŒ–é—®é¢˜ï¼ˆå¦‚ TSPï¼‰ã€‚ä»–ä»¬å±•ç¤ºäº†é€šè¿‡å°†å…¨å±€ç»“æ„çº¦æŸç¼–ç ä¸ºå½’çº³åç½®ï¼ˆinductive biasï¼‰ï¼ŒGNN å¯ä»¥é€šè¿‡å•æ¬¡å‰å‘ä¼ é€’ä½œä¸ºä¸€ç§**æ— ç›‘ç£çš„å¯å‘å¼ç®—æ³•ï¼ˆUnsupervised Heuristicï¼‰**ã€‚\n*   **Implication:** è¿™é‡æ„äº†å­¦ä¹ åœ¨ç»„åˆä¼˜åŒ–ä¸­çš„è§’è‰²ï¼šä¸ä»…ä»…æ˜¯è¾…åŠ©ç»å…¸ç®—æ³•ï¼Œè€Œæ˜¯ç›´æ¥å®ä¾‹åŒ–ä¸ºæ–°çš„ã€å¼ºå¤§çš„å¯å‘å¼æ–¹æ³•ã€‚Dropout å’Œå¿«ç…§é›†æˆï¼ˆsnapshot ensemblingï¼‰è¿˜èƒ½åœ¨æ¨ç†æ—¶å‡å°‘æœ€ä¼˜æ€§å·®è·ã€‚\n\n**2. The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models (æ€ç»´çš„å‡ ä½•å­¦ï¼šè§„æ¨¡å¦‚ä½•é‡æ„ LLM çš„æ¨ç†)**\n*   **Authors:** Samuel Cyrenius Anderson\n*   **æ ¸å¿ƒå‘ç°:** è§„æ¨¡å®šå¾‹ä¸ä»…ä»…æ˜¯æå‡èƒ½åŠ›ï¼Œå®ƒåœ¨é‡æ„æ¨ç†çš„å‡ ä½•ç»“æ„ã€‚ä½œè€…å‘ç°ç¥ç»ç¼©æ”¾å®šå¾‹è§¦å‘äº†ç‰¹å®šé¢†åŸŸçš„**ç›¸å˜ï¼ˆPhase Transitionsï¼‰**ã€‚\n    *   **æ³•å¾‹æ¨ç†**ç»å†äº†â€œç»“æ™¶åŒ–ï¼ˆCrystallizationï¼‰â€ï¼šç»´åº¦åå¡Œï¼Œè½¨è¿¹å¯¹é½å¢åŠ ã€‚\n    *   **ç§‘å­¦/æ•°å­¦æ¨ç†**ä¿æŒâ€œæ¶²æ€ï¼ˆLiquidï¼‰â€ï¼šå‡ ä½•ç»“æ„ä¸å˜ã€‚\n    *   **ä»£ç æ¨ç†**å½¢æˆäº†ç¦»æ•£çš„â€œæ™¶æ ¼ï¼ˆLatticeï¼‰â€ã€‚\n*   **æœ‰è¶£ç‚¹:** ä½œè€…æå‡ºäº†ä¸€ç§â€œé€šç”¨æŒ¯è¡ç‰¹å¾ï¼ˆuniversal oscillatory signatureï¼‰â€ï¼Œè¡¨æ˜æ³¨æ„åŠ›å±‚å’Œå‰é¦ˆå±‚é€šè¿‡ç›¸åçš„åŠ¨åŠ›å­¦é©±åŠ¨æ¨ç†ã€‚\n\n**3. LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction (LLM å³ RNNï¼šç”¨äºè®°å¿†æ›´æ–°å’Œåºåˆ—é¢„æµ‹çš„å¾ªç¯è¯­è¨€æ¨¡å‹)**\n*   **Authors:** Yuxing Lu et al.\n*   **æ ¸å¿ƒå‘ç°:** é’ˆå¯¹ LLM æ¨ç†æ—¶ä¸Šä¸‹æ–‡ä¸å¯å˜çš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§ Inference-only çš„æ¡†æ¶ã€‚å°†å†»ç»“çš„ LLM å˜æˆä¸€ä¸ªå¾ªç¯é¢„æµ‹å™¨ï¼Œé€šè¿‡**åé¦ˆé©±åŠ¨çš„æ–‡æœ¬é‡å†™**æ¥æ›´æ–°å…¶éšè—çŠ¶æ€ï¼ˆè¡¨ç°ä¸ºè‡ªç„¶è¯­è¨€è®°å¿†ï¼‰ã€‚è¿™å…è®¸æ¨¡å‹åœ¨ä¸æ›´æ–°å‚æ•°çš„æƒ…å†µä¸‹è¿›è¡Œâ€œåœ¨çº¿å­¦ä¹ â€ï¼Œåœ¨åŒ»ç–—ã€é‡‘èç­‰åºåˆ—ä»»åŠ¡ä¸Šè¶…è¶Šäº†æ ‡å‡†ä¸Šä¸‹æ–‡ç´¯ç§¯æ–¹æ³•ã€‚\n\n---\n\n### ğŸ¤– Agentic AIï¼šç†æƒ³ä¸ç°å®çš„å·®è·\nä»Šå¤©çš„è®ºæ–‡ç»™ç«çƒ­çš„ Agent æ³¼äº†ä¸€ç›†å†·æ°´ï¼ŒæŒ‡å‡ºäº†å®ƒä»¬åœ¨åä½œå’Œè‡ªæˆ‘ä¿®æ­£ä¸Šçš„æ˜æ˜¾çŸ­æ¿ã€‚\n\n**4. Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks (è¶…è¶Šè®°å¿†ï¼šåœ¨æœªè§è¿‡çš„è®¡ç®—ç†è®ºä»»åŠ¡ä¸Šæµ‹è¯• LLM æ¨ç†)**\n*   **Authors:** Shlok Shelat et al.\n*   **æ ¸å¿ƒå‘ç°:** LLM åœ¨æ„å»ºç¡®å®šæ€§æœ‰é™è‡ªåŠ¨æœºï¼ˆDFAï¼‰æ—¶ï¼Œå¦‚æœæ˜¯è§è¿‡çš„é—®é¢˜ï¼Œè¡¨ç°å¾ˆå¥½ï¼›ä¸€æ—¦é‡åˆ°æœªè§è¿‡çš„ã€éœ€è¦å¤šé‡çº¦æŸçš„é—®é¢˜ï¼Œå‡†ç¡®ç‡æš´è·Œ 30-64%ã€‚è¿™æš´éœ²äº†æ¨¡å‹æ˜¯åœ¨åš**æ¨¡å¼åŒ¹é…**è€ŒéçœŸæ­£çš„**ç¬¦å·æ¨ç†**ã€‚\n\n**5. Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision (æ·±åº¦ç ”ç©¶ Agent åœ¨å¤šè½®æŠ¥å‘Šä¿®è®¢ä¸­å¹¶ä¸å¯é )**\n*   **Authors:** Bingsen Chen et al.\n*   **æ ¸å¿ƒå‘ç°:** ç°æœ‰çš„ Deep Research Agents (DRAs) åœ¨å•æ¬¡å†™ä½œä»»åŠ¡ä¸Šè¿˜è¡Œï¼Œä½†åœ¨**å¤šè½®ä¿®è®¢**ä»»åŠ¡ä¸Šè¡¨ç°ç³Ÿç³•ã€‚å®ƒä»¬è™½ç„¶èƒ½å¤„ç†ç”¨æˆ·çš„åé¦ˆï¼Œä½†ä¼šå¯¼è‡´ 16-27% çš„åŸæœ‰å†…å®¹é€€åŒ–ï¼ˆregressï¼‰ï¼Œä¸”æ— æ³•ä¿ç•™ä¹‹å‰çš„ç¼–è¾‘ã€‚è¿™è¡¨æ˜ç›®å‰çš„ Agent ç¼ºä¹ç»´æŠ¤é•¿æ–‡æ¡£ä¸€è‡´æ€§çš„èƒ½åŠ›ã€‚\n\n**6. CooperBench: Why Coding Agents Cannot be Your Teammates Yet (CooperBench: ä¸ºä»€ä¹ˆç¼–ç  Agent è¿˜ä¸èƒ½åšä½ çš„é˜Ÿå‹)**\n*   **Authors:** Arpandeep Khatua et al. (Diyi Yang ç»„)\n*   **æ ¸å¿ƒå‘ç°:** å¼•å…¥äº† CooperBench åŸºå‡†æµ‹è¯•ã€‚ç»“æœæ˜¾ç¤ºï¼ŒCoding Agents é™·å…¥äº†â€œ**åä½œè¯…å’’ï¼ˆcurse of coordinationï¼‰**â€ï¼šä¸¤ä¸ª Agent åˆä½œæ—¶çš„æˆåŠŸç‡æ¯”å•å¹²ä½ 30%ã€‚\n*   **åŸå› :** æ²Ÿé€šæ¸ é“è¢«æ¨¡ç³Šã€ä¸å‡†ç¡®çš„ä¿¡æ¯å µå¡ï¼›Agent ç»å¸¸è¿èƒŒè‡ªå·±çš„æ‰¿è¯ºï¼›å¯¹é˜Ÿå‹çš„è®¡åˆ’æŠ±æœ‰é”™è¯¯é¢„æœŸã€‚\n\n---\n\n### ğŸ‘ï¸ è®¡ç®—æœºè§†è§‰ä¸å¤šæ¨¡æ€\nYOLO æ›´æ–°äº†ï¼Œå…³æ³¨å®æ—¶æ£€æµ‹çš„åŒå­¦è¯·æ³¨æ„ã€‚\n\n**7. YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection (YOLO26: æ—  NMS ç«¯åˆ°ç«¯å®æ—¶ç›®æ ‡æ£€æµ‹æ¡†æ¶åˆ†æ)**\n*   **Authors:** Sudip Chakrabarty\n*   **æ ¸å¿ƒå‘ç°:** YOLO26 å½»åº•æŠ›å¼ƒäº†éæå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰åå¤„ç†ï¼Œè½¬å‘åŸç”Ÿçš„**ç«¯åˆ°ç«¯ï¼ˆEnd-to-Endï¼‰**å­¦ä¹ ç­–ç•¥ã€‚\n*   **æŠ€æœ¯ç‚¹:** å¼•å…¥äº† MuSGD ä¼˜åŒ–å™¨ç¨³å®šè½»é‡çº§ä¸»å¹²ï¼ŒSTAL è¿›è¡Œå°ç›®æ ‡æ„ŸçŸ¥åˆ†é…ã€‚è¿™æ˜¯å‘ Edge AI è¿ˆè¿›çš„é‡è¦ä¸€æ­¥ï¼Œè§£å†³äº†å»¶è¿Ÿä¸ç²¾åº¦çš„æƒè¡¡é—®é¢˜ã€‚\n\n**8. Context and Transcripts Improve Detection of Deepfake Audios of Public Figures (è¯­å¢ƒå’Œæ–‡æœ¬è®°å½•æé«˜äº†å…¬ä¼—äººç‰© Deepfake éŸ³é¢‘çš„æ£€æµ‹)**\n*   **Authors:** Chongyang Gao et al.\n*   **æ ¸å¿ƒå‘ç°:** ä»…åˆ†æéŸ³é¢‘æ–‡ä»¶æ¥æ£€æµ‹ Deepfake æ˜¯ä¸å¤Ÿçš„ã€‚ä½œè€…æå‡ºäº† CADD æ¶æ„ï¼Œç»“åˆ**è¯­å¢ƒï¼ˆContextï¼‰**å’Œ**æ–‡æœ¬è®°å½•ï¼ˆTranscriptï¼‰**æ¥è¾…åŠ©åˆ¤æ–­ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼ŒF1 åˆ†æ•°æå‡äº† 5%-37%ï¼Œå¯¹æŠ—æ”»å‡»çš„é²æ£’æ€§ä¹Ÿæ˜¾è‘—å¢å¼ºã€‚\n\n---\n\n### ğŸ§¬ AI for Science & Medicine\nAI åœ¨ç§‘å­¦é¢†åŸŸçš„åŒåˆƒå‰‘æ•ˆåº”æ„ˆå‘æ˜æ˜¾ã€‚\n\n**9. Scientific production in the era of Large Language Models (å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£çš„ç§‘å­¦å­¦ç”Ÿäº§åŠ›)**\n*   **Authors:** Keigo Kusumegi, Paul Ginsparg (arXiv åˆ›å§‹äºº), et al.\n*   **æ ¸å¿ƒå‘ç°:** é€šè¿‡åˆ†æ 210 ä¸‡ç¯‡é¢„å°æœ¬ï¼Œå‘ç°ä½¿ç”¨ LLM èµ·è‰è®ºæ–‡çš„ç§‘å­¦å®¶äº§é‡å¤§å¢ï¼ˆ23-89%ï¼‰ï¼Œä½†è¿™å¯¼è‡´äº†**â€œè¯­è¨€å¤æ‚ä½†å†…å®¹ç©ºæ´â€**çš„æ–‡ç« æ¿€å¢ã€‚LLM ç”¨æˆ·å€¾å‘äºå¼•ç”¨æ›´å¤šæ ·åŒ–çš„æ—§ä½œï¼Œè¿™å¯èƒ½ä¼šæ”¹å˜å­¦æœ¯è¯„ä»·ä½“ç³»ã€‚\n\n**10. AI-generated data contamination erodes pathological variability and diagnostic reliability (AI ç”Ÿæˆçš„æ•°æ®æ±¡æŸ“ä¾µèš€äº†ç—…ç†å˜å¼‚æ€§å’Œè¯Šæ–­å¯é æ€§)**\n*   **Authors:** Hongyu He et al.\n*   **æ ¸å¿ƒå‘ç°:** è¿™æ˜¯ä¸€ä¸ªä¸¥é‡çš„è­¦å‘Šã€‚åœ¨ç¼ºä¹äººå·¥éªŒè¯çš„æƒ…å†µä¸‹ï¼ŒåŒ»ç–—è®°å½•ä¸­å¡«å…… AI ç”Ÿæˆçš„åˆæˆå†…å®¹ä¼šå¯¼è‡´**â€œæ¨¡å‹å´©æºƒâ€**â€”â€”ç½•è§ä½†å…³é”®çš„ç—…ç†ç‰¹å¾ï¼ˆå¦‚æ°”èƒ¸ï¼‰åœ¨åˆæˆæ•°æ®ä¸­æ¶ˆå¤±ï¼Œæ•°æ®å‘é€šç”¨è¡¨å‹æ”¶æ•›ã€‚è¿™ä½¿å¾—è¯Šæ–­æ¨¡å‹çš„é”™è¯¯å®‰å…¨æ„Ÿå€å¢ï¼ˆå‡é˜´æ€§ç‡é£™å‡ï¼‰ï¼Œä»…éœ€ä¸¤ä»£è¿­ä»£ï¼Œæ•°æ®å°±ä¼šå˜å¾—ä¸´åºŠæ— ç”¨ã€‚\n\n**11. From 100,000+ images to winning the first brain MRI foundation model challenges (ä» 10ä¸‡+ å›¾åƒåˆ°èµ¢å¾—é¦–ä¸ªè„‘éƒ¨ MRI åŸºç¡€æ¨¡å‹æŒ‘æˆ˜èµ›)**\n*   **Authors:** Pedro M. Gordaliza et al.\n*   **æ ¸å¿ƒå‘ç°:** åœ¨ MICCAI 2025 çš„è„‘éƒ¨ MRI æŒ‘æˆ˜èµ›ä¸­ï¼Œä½œè€…å›¢é˜Ÿå‡­å€Ÿ **U-Net CNN** æ¶æ„å‡»è´¥äº†ä¼—å¤š Transformer æ–¹æ³•ï¼Œæ‹¿ä¸‹äº†ç¬¬ä¸€åã€‚\n*   **Implication:** ä»–ä»¬çš„æ¨¡å‹æ¯” Transformer å¿« 1-2 ä¸ªæ•°é‡çº§ï¼Œå° 10 å€ã€‚å§œè¿˜æ˜¯è€çš„è¾£ï¼ŒCNN åœ¨ç‰¹å®šåŒ»å­¦å½±åƒä»»åŠ¡ä¸Šä¾ç„¶èƒ½æ‰“ã€‚\n\n---\n\n### ğŸ› ï¸ å…¶ä»–å€¼å¾—å…³æ³¨çš„è®ºæ–‡\n\n*   **12. Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts:** (ç¥ç»ç¬¦å· LoRA) æå‡ºäº†ä¸€ç§æ··åˆç­–ç•¥ï¼ŒåŠ¨æ€å†³å®šæ˜¯å¾®è°ƒæƒé‡ï¼ˆç”¨äºäº‹å®é‡å»ºï¼‰è¿˜æ˜¯é‡å†™ Promptï¼ˆç”¨äºé£æ ¼å’Œé€»è¾‘æ§åˆ¶ï¼‰ï¼Œåœ¨æ•°å­¦æ¨ç†ä¸Šæ•ˆæœæ˜¾è‘—ã€‚\n*   **13. AI Skills Improve Job Prospects (AI æŠ€èƒ½æå‡å°±ä¸šå‰æ™¯):** å®éªŒè¡¨æ˜ï¼Œåœ¨ç®€å†ä¸­åˆ—å‡º AI æŠ€èƒ½èƒ½å¢åŠ  8-15% çš„é¢è¯•é‚€è¯·ç‡ï¼Œç”šè‡³èƒ½æŠµæ¶ˆå¹´é¾„å¤§æˆ–å­¦å†ä½çš„åŠ£åŠ¿ã€‚\n*   **14. MirrorGuard: Toward Secure Computer-Use Agents:** (è®¡ç®—æœºæ“ä½œ Agent çš„å®‰å…¨) é’ˆå¯¹èƒ½å¤Ÿæ“ä½œ GUI çš„ Agentï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ¨¡æ‹Ÿç¯å¢ƒè®­ç»ƒçš„é˜²å¾¡æ¡†æ¶ï¼Œé˜²æ­¢è§†è§‰æç¤ºæ³¨å…¥æ”»å‡»ã€‚\n*   **15. The AI Genie Phenomenon and Three Types of AI Chatbot Addiction:** (AI ç²¾çµç°è±¡ä¸èŠå¤©æœºå™¨äººæˆç˜¾) ç ”ç©¶äº† AI èŠå¤©æˆç˜¾çš„ä¸‰ç§ç±»å‹ï¼šé€ƒé¿ç°å®çš„è§’è‰²æ‰®æ¼”ã€ä¼ªç¤¾äº¤ä¼´ä¾£ã€ä»¥åŠçŸ¥è¯†å…”å­æ´ï¼ˆEpistemic Rabbit Holesï¼‰ã€‚\n\n---\n\n**ç»“è¯­ï¼š**\nä»Šå¤©çš„è®ºæ–‡ä¸ä»…å±•ç¤ºäº†æŠ€æœ¯çš„è¿›æ­¥ï¼ˆå¦‚ YOLO26, GNN Heuristicsï¼‰ï¼Œæ›´é‡è¦çš„æ˜¯å¼€å§‹äº†å¤§é‡çš„**åæ€ä¸æ‰¹åˆ¤**ã€‚æ— è®ºæ˜¯ Agent çš„åä½œæ— èƒ½ï¼ŒLLM åœ¨å¤æ‚æ¨ç†ä¸­çš„å‡ ä½•åå¡Œï¼Œè¿˜æ˜¯åˆæˆæ•°æ®å¯¹ç§‘å­¦å’ŒåŒ»ç–—çš„æ½œåœ¨å±å®³ï¼Œéƒ½æé†’æˆ‘ä»¬ï¼šåœ¨è¿½æ±‚ Scale çš„åŒæ—¶ï¼Œå¿…é¡»å…³æ³¨ç³»ç»Ÿçš„å¯é æ€§ã€ç‰©ç†/é€»è¾‘çš„ä¸€è‡´æ€§ä»¥åŠæ•°æ®çš„çº¯å‡€åº¦ã€‚\n\nå¸Œæœ›è¿™ä»½å¿«æŠ¥å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæˆ‘ä»¬æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2601.13465v1",
      "title": "Graph Neural Networks are Heuristics",
      "title_zh": "å›¾ç¥ç»ç½‘ç»œå³å¯å‘å¼ç®—æ³•",
      "authors": [
        "Yimeng Min",
        "Carla P. Gomes"
      ],
      "abstract": "We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯æ˜äº†å•æ¬¡è®­ç»ƒè½¨è¿¹å³å¯å°†å›¾ç¥ç»ç½‘ç»œ(Graph Neural Networks, GNNs)è½¬åŒ–ä¸ºç”¨äºç»„åˆä¼˜åŒ–(combinatorial optimization)çš„æ— ç›‘ç£å¯å‘å¼ç®—æ³•ã€‚ç ”ç©¶ä»¥æ—…è¡Œå•†é—®é¢˜(Travelling Salesman Problem, TSP)ä¸ºæ ¸å¿ƒï¼Œé€šè¿‡å°†å…¨å±€ç»“æ„çº¦æŸç¼–ç ä¸ºå½’çº³åç½®(inductive bias)ï¼Œä½¿éè‡ªå›å½’æ¨¡å‹èƒ½å¤Ÿåœ¨æ— éœ€æœç´¢ã€ç›‘ç£æˆ–åºåˆ—å†³ç­–çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ç›´æ¥å‰å‘ä¼ æ’­ç”Ÿæˆè§£ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ dropout å’Œå¿«ç…§é›†æˆ(snapshot ensembling)æ„å»ºéšå¼é›†æˆï¼Œé€šè¿‡å¢åŠ è§£çš„å¤šæ ·æ€§æœ‰æ•ˆç¼©å°äº†æœ€ä¼˜æ€§å·®è·(optimality gaps)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGNNs æ— éœ€ç›‘ç£è®­ç»ƒæˆ–æ˜¾å¼æœç´¢å³å¯å†…åŒ–å…¨å±€ç»„åˆç»“æ„ï¼Œè¿™é‡å¡‘äº†å­¦ä¹ åœ¨ç»„åˆä¼˜åŒ–ä¸­çš„è§’è‰²ï¼šä»å•çº¯è¾…åŠ©ä¼ ç»Ÿç®—æ³•è½¬å˜ä¸ºç›´æ¥å®ä¾‹åŒ–é«˜æ•ˆçš„å¯å‘å¼ç®—æ³•ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13465v1",
      "published_date": "2026-01-19 23:40:08 UTC",
      "updated_date": "2026-01-19 23:40:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:37:36.734441+00:00"
    },
    {
      "arxiv_id": "2601.13464v1",
      "title": "Context and Transcripts Improve Detection of Deepfake Audios of Public Figures",
      "title_zh": "åˆ©ç”¨è¯­å¢ƒä¸è½¬å½•æ–‡æœ¬æå‡å…¬ä¼—äººç‰©æ·±åº¦ä¼ªé€ éŸ³é¢‘æ£€æµ‹æ•ˆèƒ½",
      "authors": [
        "Chongyang Gao",
        "Marco Postiglione",
        "Julian Baldwin",
        "Natalia Denisenko",
        "Isabel Gortner",
        "Luke Fosdick",
        "Chiara Pulice",
        "Sarit Kraus",
        "V. S. Subrahmanian"
      ],
      "abstract": "Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºå½“å‰çš„éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨ä¸»è¦ä¾èµ–éŸ³é¢‘åˆ†æï¼Œå¿½è§†äº†äººç±»è¯„ä¼°çœŸå®æ€§æ—¶å¸¸ç”¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ä¸ºæ­¤ï¼Œä½œè€…åˆ›å»ºäº†ç”±è®°è€…æä¾›çš„æ·±åº¦ä¼ªé€ æ•°æ®é›†(JDD)å’Œå·²æ•…å…¬ä¼—äººç‰©åˆæˆæ•°æ®é›†(SYN)ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°å‹çš„åŸºäºä¸Šä¸‹æ–‡çš„éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨(CADD)æ¶æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»“åˆä¸Šä¸‹æ–‡æˆ–è½¬å½•æ–‡æœ¬å¯ä½¿åŸºå‡†æ£€æµ‹å™¨çš„ F1-scoreã€AUC å’Œ EER ç­‰æŒ‡æ ‡æ˜¾è‘—æå‡ 5% è‡³ 47.83% ä¸ç­‰ã€‚æ­¤å¤–ï¼ŒCADD åœ¨åº”å¯¹ 5 ç§å¯¹æŠ—æ€§è§„é¿ç­–ç•¥æ—¶è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ï¼Œæ€§èƒ½å¹³å‡ä¸‹é™ä»…ä¸º -0.71%ï¼Œæ˜¾è‘—å¢å¼ºäº†å¯¹å…¬ä¼—äººç‰©éŸ³é¢‘æ·±åº¦ä¼ªé€ çš„æ£€æµ‹èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13464v1",
      "published_date": "2026-01-19 23:40:05 UTC",
      "updated_date": "2026-01-19 23:40:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:37:41.359791+00:00"
    },
    {
      "arxiv_id": "2601.13462v1",
      "title": "SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation",
      "title_zh": "SpatialBench-UCï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­ç©ºé—´æç¤ºéµå¾ªèƒ½åŠ›çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥è¯„ä¼°",
      "authors": [
        "Amine Rostane"
      ],
      "abstract": "Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SpatialBench-UCï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹æ–‡æœ¬ç”Ÿæˆå›¾åƒ (Text-to-Image) æ¨¡å‹ç©ºé—´æç¤ºè¯éµå¾ªèƒ½åŠ›çš„ã€å…·æœ‰ä¸ç¡®å®šæ€§æ„ŸçŸ¥ (Uncertainty-Aware) çš„è¯„ä¼°åŸºå‡†ã€‚è¯¥åŸºå‡†å°†ç©ºé—´è¯„ä¼°è§†ä¸ºä¸€ä¸ªé€‰æ‹©æ€§é¢„æµ‹ (Selective Prediction) é—®é¢˜ï¼Œå…è®¸è¯„ä¼°å™¨åœ¨è¯æ®ä¸è¶³æ—¶å¼ƒæƒ (Abstain) å¹¶æŠ¥å‘Šç½®ä¿¡åº¦ï¼Œä»è€Œè§£å†³äº†ä¼ ç»Ÿè‡ªåŠ¨è¯„ä¼°ä¸­ç”±äºæ£€æµ‹å™¨è¯¯å·®æˆ–å‡ ä½•æµ‹è¯•æ¨¡ç³Šå¯¼è‡´çš„å‡†ç¡®æ€§é—®é¢˜ã€‚SpatialBench-UC åŒ…å« 200 ä¸ªç©ºé—´å…³ç³»æç¤ºè¯ï¼Œå¹¶åˆ©ç”¨åäº‹å®å¯¹ (Counterfactual Pairs) æ„å»ºäº†å¯é‡å¤ä¸”å¯å®¡è®¡çš„è¯„ä¼°æµç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGrounding æ–¹æ³•èƒ½æ˜¾è‘—æå‡æ¨¡å‹çš„é€šè¿‡ç‡å’Œè¦†ç›–ç‡ï¼Œè€Œç›®æ ‡æ¼æ£€å¼•èµ·çš„é€‰æ‹©æ€§å¼ƒæƒä»æ˜¯å½±å“è‡ªåŠ¨è¯„ä¼°æ•ˆèƒ½çš„ä¸»è¦å› ç´ ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, includes figures and tables",
      "pdf_url": "https://arxiv.org/pdf/2601.13462v1",
      "published_date": "2026-01-19 23:37:10 UTC",
      "updated_date": "2026-01-19 23:37:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:37:42.076856+00:00"
    },
    {
      "arxiv_id": "2601.13458v1",
      "title": "Labels or Preferences? Budget-Constrained Learning with Human Judgments over AI-Generated Outputs",
      "title_zh": "æ ‡ç­¾è¿˜æ˜¯åå¥½ï¼ŸåŸºäºäººç±»å¯¹äººå·¥æ™ºèƒ½ç”Ÿæˆè¾“å‡ºè¯„åˆ¤çš„é¢„ç®—å—é™å­¦ä¹ ",
      "authors": [
        "Zihan Dong",
        "Ruijia Wu",
        "Linjun Zhang"
      ],
      "abstract": "The increasing reliance on human preference feedback to judge AI-generated pseudo labels has created a pressing need for principled, budget-conscious data acquisition strategies. We address the crucial question of how to optimally allocate a fixed annotation budget between ground-truth labels and pairwise preferences in AI. Our solution, grounded in semi-parametric inference, casts the budget allocation problem as a monotone missing data framework. Building on this formulation, we introduce Preference-Calibrated Active Learning (PCAL), a novel method that learns the optimal data acquisition strategy and develops a statistically efficient estimator for functionals of the data distribution. Theoretically, we prove the asymptotic optimality of our PCAL estimator and establish a key robustness guarantee that ensures robust performance even with poorly estimated nuisance models. Our flexible framework applies to a general class of problems, by directly optimizing the estimator's variance instead of requiring a closed-form solution. This work provides a principled and statistically efficient approach for budget-constrained learning in modern AI. Simulations and real-data analysis demonstrate the practical benefits and superior performance of our proposed method.",
      "tldr_zh": "---\n\n### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ“\n\nè¯¥ç ”ç©¶é’ˆå¯¹ AI ç”Ÿæˆå†…å®¹æ ‡æ³¨é¢„ç®—å—é™çš„é—®é¢˜ï¼Œæ¢è®¨äº†å¦‚ä½•ä¼˜åŒ–åˆ†é…çœŸå®æ ‡ç­¾ (Ground-truth labels) ä¸æˆå¯¹åå¥½ (Pairwise preferences) çš„æ ‡æ³¨èµ„æºã€‚ç ”ç©¶æå‡ºäº† Preference-Calibrated Active Learning (PCAL) æ¡†æ¶ï¼Œé€šè¿‡åŠå‚æ•°æ¨æ–­ (Semi-parametric inference) å°†å…¶å»ºæ¨¡ä¸ºå•è°ƒç¼ºå¤±æ•°æ® (Monotone missing data) é—®é¢˜ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿç›´æ¥ä¼˜åŒ–ä¼°è®¡é‡çš„æ–¹å·®å¹¶è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜æ•°æ®é‡‡é›†ç­–ç•¥ï¼Œåœ¨ç†è®ºä¸Šè¯æ˜äº†å…¶å…·æœ‰æ¸è¿‘æœ€ä¼˜æ€§ (Asymptotic optimality) ä»¥åŠå¯¹å¹²æ‰°æ¨¡å‹ (Nuisance models) çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPCAL åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æ•°æ®åˆ†æä¸­å‡è¡¨ç°å‡ºæ˜¾è‘—çš„ç»Ÿè®¡æ•ˆç‡å’Œå®ç”¨ä¼˜åŠ¿ã€‚\n\n---\n\nå¸Œæœ›è¿™ä¸ªæ‘˜è¦å¯¹æ‚¨çš„ç ”ç©¶æˆ–å·¥ä½œæœ‰æ‰€å¸®åŠ©ï¼å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦è½¬æ¢ï¼Œæˆ–è€…æƒ³é’ˆå¯¹æ–‡ä¸­çš„æŸä¸ªæœ¯è¯­è¿›è¡Œæ·±å…¥æ¢è®¨ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13458v1",
      "published_date": "2026-01-19 23:23:29 UTC",
      "updated_date": "2026-01-19 23:23:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:37:49.257514+00:00"
    },
    {
      "arxiv_id": "2601.13443v1",
      "title": "Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models",
      "title_zh": "æ˜¾å¼è®¤çŸ¥åˆ†é…ï¼šå¤§è¯­è¨€æ¨¡å‹å—æ²»ç†ä¸å¯å®¡è®¡æ¨ç†åŸåˆ™",
      "authors": [
        "HÃ©ctor Manuel Manzanilla-Granados",
        "Zaira Navarrete-Cazales",
        "Miriam Pescador-Rojas",
        "Tonahtiu RamÃ­rez-Romero"
      ],
      "abstract": "The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.\n  We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.\n  We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­å­˜åœ¨çš„â€œè®¤çŸ¥å´©å¡Œâ€ï¼ˆcognitive collapseï¼‰é—®é¢˜ï¼Œæå‡ºäº†â€œæ˜¾å¼è®¤çŸ¥åˆ†é…â€ï¼ˆExplicit Cognitive Allocationï¼‰åŸåˆ™ï¼Œæ—¨åœ¨å®ç°å—æ²»ç†ä¸”å¯å®¡è®¡çš„ AI æ¨ç†ã€‚è¯¥åŸåˆ™é€šè¿‡â€œè®¤çŸ¥é€šç”¨æ™ºèƒ½ä½“â€ï¼ˆCognitive Universal Agent, CUAï¼‰æ¶æ„å®ç°ï¼Œå°†æ¨ç†è¿‡ç¨‹æ˜¾å¼åˆ’åˆ†ä¸ºæ¢ç´¢ä¸æ¡†æ¶æ„å»ºã€è®¤è¯†è®ºé”šå®šã€æ–¹æ³•è®ºæ˜ å°„åŠè§£é‡Šæ€§ç»¼åˆç­‰ç‹¬ç«‹é˜¶æ®µï¼Œå¹¶å¼•å…¥â€œé€šç”¨è®¤çŸ¥å·¥å…·â€ï¼ˆUniversal Cognitive Instruments, UCIsï¼‰æ¥å½¢å¼åŒ–å¼‚æ„çš„ç ”ç©¶æ‰‹æ®µã€‚åœ¨å†œä¸šé¢†åŸŸçš„å—æ§å®éªŒè¡¨æ˜ï¼Œç›¸æ¯”åŸºçº¿ LLMï¼ŒCUA å±•ç¤ºäº†æ›´æ—©ä¸”ç»“æ„åŒ–çš„è®¤è¯†è®ºæ”¶æ•›ï¼ˆepistemic convergenceï¼‰ä»¥åŠæ›´é«˜çš„è®¤è¯†è®ºå¯¹é½åº¦ï¼Œå¹¶èƒ½ç³»ç»Ÿæ€§åœ°æ­ç¤ºæ¢ç©¶è¿‡ç¨‹ä¸­çš„å·¥å…·æ€§ç»“æ„ï¼Œæ˜¾è‘—æå‡äº†æ¨ç†çš„å¯è¿½æº¯æ€§å’Œç§‘å­¦ä¸¥è°¨æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint. This version corresponds to the initial public release of the CUA architecture and associated evaluation metrics",
      "pdf_url": "https://arxiv.org/pdf/2601.13443v1",
      "published_date": "2026-01-19 23:00:14 UTC",
      "updated_date": "2026-01-19 23:00:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:37:48.087352+00:00"
    },
    {
      "arxiv_id": "2601.13437v1",
      "title": "MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization",
      "title_zh": "MOSLD-Benchï¼šæ–‡æœ¬åˆ†ç±»çš„å¤šè¯­è¨€å¼€æ”¾é›†å­¦ä¹ ä¸å‘ç°åŸºå‡†",
      "authors": [
        "Adriana-Valentina Costache",
        "Daria-Nicoleta Dragomir",
        "Silviu-Florin Gheorghe",
        "Eduard Poesina",
        "Paul Irofti",
        "Radu Tudor Ionescu"
      ],
      "abstract": "Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†é¦–ä¸ªç”¨äºæ–‡æœ¬åˆ†ç±»çš„å¤šè¯­è¨€å¼€æ”¾é›†å­¦ä¹ ä¸å‘ç°(Multilingual Open-Set Learning and Discovery)åŸºå‡†â€”â€”MOSLD-Benchï¼Œæ—¨åœ¨åº”å¯¹æµ‹è¯•é˜¶æ®µå‡ºç°æœªçŸ¥ç±»åˆ«çš„æŒ‘æˆ˜ã€‚è¯¥åŸºå‡†æ¶µç›–12ç§è¯­è¨€çš„96ä¸‡ä¸ªæ•°æ®æ ·æœ¬ï¼Œé€šè¿‡é‡ç»„ç°æœ‰æ•°æ®é›†åŠé‡‡é›†æ–°é—»é¢†åŸŸæ–°æ•°æ®æ„å»ºè€Œæˆã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§æ–°å‹OSLDæ¡†æ¶ï¼Œé€šè¿‡å¤šé˜¶æ®µé›†æˆå®ç°å¯¹æ–°ç±»åˆ«çš„æŒç»­å‘ç°ä¸å­¦ä¹ ã€‚å®éªŒè¯„ä¼°äº†å¤šç§è¯­è¨€æ¨¡å‹å¹¶æä¾›äº†æ€§èƒ½å‚è€ƒï¼Œä¸ºæ–‡æœ¬é¢†åŸŸçš„å¼€æ”¾é›†ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13437v1",
      "published_date": "2026-01-19 22:49:41 UTC",
      "updated_date": "2026-01-19 22:49:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:37:51.927956+00:00"
    },
    {
      "arxiv_id": "2601.13435v1",
      "title": "A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization",
      "title_zh": "é¢å‘è‚¡ç¥¨å¤šç©ºäº¤æ˜“ä¸é£é™©è°ƒæ•´æ”¶ç›Šä¼˜åŒ–çš„å¯å­¦ä¹ å°æ³¢ Transformer",
      "authors": [
        "Shuozhe Li",
        "Du Cheng",
        "Leqi Liu"
      ],
      "abstract": "Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \\emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \\pm 0.045$ and a Sharpe ratio of $2.157 \\pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† WaveLSFormerï¼Œè¿™æ˜¯ä¸€ç§å¯å­¦ä¹ çš„åŸºäºå°æ³¢å˜æ¢ (Wavelet-based) çš„å¤šç©º (Long-short) Transformer æ¨¡å‹ï¼Œæ—¨åœ¨ä¼˜åŒ–æ—¥å†…äº¤æ˜“ç­–ç•¥å¹¶æå‡é£é™©è°ƒæ•´æ”¶ç›Šã€‚è¯¥æ¡†æ¶é€šè¿‡å¯å­¦ä¹ çš„å°æ³¢å‰ç«¯ç”Ÿæˆé«˜/ä½é¢‘åˆ†é‡ï¼Œå¹¶å¼•å…¥ä½é¢‘å¼•å¯¼çš„é«˜é¢‘æ³¨å…¥ (LGHI) æ¨¡å—æ¥èåˆå¤šå°ºåº¦ä¿¡æ¯ï¼Œä»è€Œæœ‰æ•ˆå¤„ç†é‡‘èæ—¶é—´åºåˆ—çš„é‡å™ªå£°å’Œéå¹³ç¨³æ€§ã€‚æ¨¡å‹ç›´æ¥é’ˆå¯¹äº¤æ˜“ç›®æ ‡è¿›è¡Œä¼˜åŒ–ï¼Œå¹¶è¾“å‡ºæ»¡è¶³é£é™©é¢„ç®—çš„å¤´å¯¸ç»„åˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWaveLSFormer åœ¨è·¨è¡Œä¸šäº”å¹´çš„æ•°æ®æµ‹è¯•ä¸­ï¼Œç´¯ç§¯ç­–ç•¥æ”¶ç›Šï¼ˆ0.607ï¼‰å’Œå¤æ™®æ¯”ç‡ (Sharpe ratio, 2.157) å‡æ˜¾è‘—ä¼˜äº MLPã€LSTM åŠä¼ ç»Ÿ Transformer ç­‰åŸºå‡†æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†ç›ˆåˆ©èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13435v1",
      "published_date": "2026-01-19 22:41:31 UTC",
      "updated_date": "2026-01-19 22:41:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:37:54.355975+00:00"
    },
    {
      "arxiv_id": "2601.13422v1",
      "title": "TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction",
      "title_zh": "TrustEnergyï¼šå‡†ç¡®å¯é çš„ç”¨æˆ·çº§èƒ½è€—é¢„æµ‹ç»Ÿä¸€æ¡†æ¶",
      "authors": [
        "Dahai Yu",
        "Rongchao Xu",
        "Dingyi Zhuang",
        "Yuheng Bu",
        "Shenhao Wang",
        "Guang Wang"
      ],
      "abstract": "Energy usage prediction is important for various real-world applications, including grid management, infrastructure planning, and disaster response. Although a plethora of deep learning approaches have been proposed to perform this task, most of them either overlook the essential spatial correlations across households or fail to scale to individualized prediction, making them less effective for accurate fine-grained user-level prediction. In addition, due to the dynamic and uncertain nature of energy usage caused by various factors such as extreme weather events, quantifying uncertainty for reliable prediction is also significant, but it has not been fully explored in existing work. In this paper, we propose a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. There are two key technical components in TrustEnergy, (i) a Hierarchical Spatiotemporal Representation module to efficiently capture both macro and micro energy usage patterns with a novel memory-augmented spatiotemporal graph neural network, and (ii) an innovative Sequential Conformalized Quantile Regression module to dynamically adjust uncertainty bounds to ensure valid prediction intervals over time, without making strong assumptions about the underlying data distribution. We implement and evaluate our TrustEnergy framework by working with an electricity provider in Florida, and the results show our TrustEnergy can achieve a 5.4% increase in prediction accuracy and 5.7% improvement in uncertainty quantification compared to state-of-the-art baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TrustEnergyï¼Œä¸€ä¸ªæ—¨åœ¨å®ç°å‡†ç¡®ä¸”å¯é çš„ç”¨æˆ·çº§(user-level)èƒ½æºä½¿ç”¨é¢„æµ‹çš„ç»Ÿä¸€æ¡†æ¶ï¼Œè§£å†³äº†ç°æœ‰æ¨¡å‹åœ¨ç©ºé—´ç›¸å…³æ€§æ•æ‰å’Œä¸ªæ€§åŒ–é¢„æµ‹æ‰©å±•æ€§æ–¹é¢çš„ä¸è¶³ã€‚è¯¥æ¡†æ¶é€šè¿‡å±‚æ¬¡åŒ–æ—¶ç©ºè¡¨ç¤º(Hierarchical Spatiotemporal Representation)æ¨¡å—ï¼Œåˆ©ç”¨è®°å¿†å¢å¼ºæ—¶ç©ºå›¾ç¥ç»ç½‘ç»œ(memory-augmented spatiotemporal graph neural network)é«˜æ•ˆæ•è·èƒ½æºæ¶ˆè€—çš„å®è§‚ä¸å¾®è§‚æ¨¡å¼ã€‚æ­¤å¤–ï¼ŒTrustEnergy å¼•å…¥äº†åºåˆ—ä¿å½¢åˆ†ä½æ•°å›å½’(Sequential Conformalized Quantile Regression)æ¨¡å—ï¼Œæ—¨åœ¨åŠ¨æ€è°ƒæ•´ä¸ç¡®å®šæ€§è¾¹ç•Œä»¥ä¿è¯é¢„æµ‹ç»“æœçš„å¯é æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTrustEnergy åœ¨çœŸå®åœºæ™¯ä¸‹æ¯”ç°æœ‰åŸºå‡†æ¨¡å‹åœ¨é¢„æµ‹å‡†ç¡®ç‡ä¸Šæå‡äº† 5.4%ï¼Œå¹¶åœ¨ä¸ç¡®å®šæ€§é‡åŒ–(uncertainty quantification)æ–¹é¢æ”¹è¿›äº† 5.7%ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13422v1",
      "published_date": "2026-01-19 22:09:08 UTC",
      "updated_date": "2026-01-19 22:09:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:37:59.034093+00:00"
    },
    {
      "arxiv_id": "2601.13412v1",
      "title": "Using deep learning for predicting cleansing quality of colon capsule endoscopy images",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ çš„ç»“è‚ èƒ¶å›Šå†…é•œå›¾åƒæ¸…æ´åº¦é¢„æµ‹",
      "authors": [
        "Puneet Sharma",
        "Kristian DalsbÃ¸ Hindberg",
        "Benedicte Schelde-Olesen",
        "Ulrik Deding",
        "Esmaeil S. Nadimi",
        "Jan-Matthias Braun"
      ],
      "abstract": "In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯é¢„æµ‹ç»“è‚ èƒ¶å›Šå†…é•œ (Colon Capsule Endoscopy, CCE) å›¾åƒæ¸…æ´è´¨é‡çš„æ–¹æ³•ã€‚é€šè¿‡åœ¨ 500 å¼ åŸºäº Leighton-Rex æ ‡å‡†æ ‡æ³¨çš„å›¾åƒä¸Šè®­ç»ƒ ResNet-18 æ¨¡å‹ï¼Œå¹¶ç»“åˆç»“æ„åŒ–å‰ªæ (Structured pruning) æŠ€æœ¯ï¼Œæ¨¡å‹åœ¨å®ç° 79% ç¨€ç–åº¦çš„åŒæ—¶è¾¾åˆ°äº† 88% çš„äº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼Œæ€§èƒ½ä¼˜äºæœªå‰ªææ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜åˆ©ç”¨ Grad-CAM å’Œ ROAD ç­‰å¤šç§æ–¹æ³•è¯„ä¼°äº†æ¨¡å‹çš„ä¸´åºŠå¯è§£é‡Šæ€§ (Explainability)ï¼Œå¹¶é‡‡ç”¨è‡ªé€‚åº”æ¸©åº¦ç¼©æ”¾ (Adaptive temperature scaling) å˜ä½“å®Œæˆäº†å¤–éƒ¨æ•°æ®é›†çš„æ ¡å‡†ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.13412v1",
      "published_date": "2026-01-19 21:48:41 UTC",
      "updated_date": "2026-01-19 21:48:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:37:59.825005+00:00"
    },
    {
      "arxiv_id": "2601.13406v1",
      "title": "Integrating Virtual Reality and Large Language Models for Team-Based Non-Technical Skills Training and Evaluation in the Operating Room",
      "title_zh": "èåˆè™šæ‹Ÿç°å®ä¸å¤§è¯­è¨€æ¨¡å‹çš„æ‰‹æœ¯å®¤å›¢é˜Ÿåä½œéæŠ€æœ¯æŠ€èƒ½åŸ¹è®­ä¸è¯„ä¼°",
      "authors": [
        "Jacob Barker",
        "Doga Demirel",
        "Cullen Jackson",
        "Anna Johansson",
        "Robbin Miraglia",
        "Darian Hoagland",
        "Stephanie B. Jones",
        "John Mitchell",
        "Daniel B. Jones",
        "Suvranu De"
      ],
      "abstract": "Although effective teamwork and communication are critical to surgical safety, structured training for non-technical skills (NTS) remains limited compared with technical simulation. The ACS/APDS Phase III Team-Based Skills Curriculum calls for scalable tools that both teach and objectively assess these competencies during laparoscopic emergencies. We introduce the Virtual Operating Room Team Experience (VORTeX), a multi-user virtual reality (VR) platform that integrates immersive team simulation with large language model (LLM) analytics to train and evaluate communication, decision-making, teamwork, and leadership. Team dialogue is analyzed using structured prompts derived from the Non-Technical Skills for Surgeons (NOTSS) framework, enabling automated classification of behaviors and generation of directed interaction graphs that quantify communication structure and hierarchy. Two laparoscopic emergency scenarios, pneumothorax and intra-abdominal bleeding, were implemented to elicit realistic stress and collaboration. Twelve surgical professionals completed pilot sessions at the 2024 SAGES conference, rating VORTeX as intuitive, immersive, and valuable for developing teamwork and communication. The LLM consistently produced interpretable communication networks reflecting expected operative hierarchies, with surgeons as central integrators, nurses as initiators, and anesthesiologists as balanced intermediaries. By integrating immersive VR with LLM-driven behavioral analytics, VORTeX provides a scalable, privacy-compliant framework for objective assessment and automated, data-informed debriefing across distributed training environments.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº† VORTeX (Virtual Operating Room Team Experience)ï¼Œè¿™æ˜¯ä¸€ä¸ªç»“åˆäº†å¤šç”¨æˆ·è™šæ‹Ÿç°å® (VR) å¹³å°ä¸å¤§è¯­è¨€æ¨¡å‹ (LLM) åˆ†æçš„ç³»ç»Ÿï¼Œæ—¨åœ¨åŠ å¼ºæ‰‹æœ¯å®¤ä¸­éæŠ€æœ¯æŠ€èƒ½ (NTS) çš„åŸ¹è®­ä¸è¯„ä¼°ã€‚è¯¥å¹³å°é€šè¿‡æ¨¡æ‹Ÿè…¹è…”é•œæ€¥è¯Šåœºæ™¯ï¼Œåˆ©ç”¨ LLM åŸºäº NOTSS (Non-Technical Skills for Surgeons) æ¡†æ¶è‡ªåŠ¨åˆ†æå›¢é˜Ÿå¯¹è¯ï¼Œå¹¶ç”Ÿæˆèƒ½å¤Ÿé‡åŒ–æ²Ÿé€šç»“æ„ä¸å±‚çº§çš„äº¤äº’å›¾è°±ã€‚åœ¨ 2024 SAGES ä¼šè®®çš„åˆæ­¥æµ‹è¯•ä¸­ï¼Œå¤–ç§‘ä¸“ä¸šäººå‘˜å¯¹è¯¥ç³»ç»Ÿçš„æ²‰æµ¸æ„Ÿå’Œæ•™å­¦ä»·å€¼ç»™äºˆäº†é«˜åº¦è¯„ä»·ï¼Œä¸” LLM æˆåŠŸè¯†åˆ«å‡ºç¬¦åˆé¢„æœŸæ‰‹æœ¯å±‚çº§çš„æ²Ÿé€šç½‘ç»œã€‚VORTeX ä¸ºåˆ†å¸ƒå¼åŸ¹è®­ç¯å¢ƒä¸­çš„è¡Œä¸ºå®¢è§‚è¯„ä¼°å’Œæ•°æ®é©±åŠ¨çš„æ±‡æŠ¥ (debriefing) æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ä¸”ç¬¦åˆéšç§è¦æ±‚çš„æ¡†æ¶ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "23 pages, 7 figures, 1 table, 2 Appendices",
      "pdf_url": "https://arxiv.org/pdf/2601.13406v1",
      "published_date": "2026-01-19 21:34:00 UTC",
      "updated_date": "2026-01-19 21:34:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:02.477566+00:00"
    },
    {
      "arxiv_id": "2601.13404v1",
      "title": "Local-to-Global Logical Explanations for Deep Vision Models",
      "title_zh": "æ·±åº¦è§†è§‰æ¨¡å‹çš„ä»å±€éƒ¨åˆ°å…¨å±€é€»è¾‘è§£é‡Š",
      "authors": [
        "Bhavan Vasu",
        "Giuseppe Raffa",
        "Prasad Tadepalli"
      ],
      "abstract": "While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability we show that the explanations maintain high fidelity and coverage with respect to the blackbox models they seek to explain in challenging vision datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦è§†è§‰æ¨¡å‹çš„ä¸é€æ˜æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºäººç±»å¯è¯†åˆ«åŸå§‹æ¦‚å¿µ (primitive concepts) çš„å±€éƒ¨ä¸å…¨å±€è§£é‡Šæ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†è§£é‡Šè¿‡ç¨‹å»ºæ¨¡ä¸ºå•è°ƒæå–èŒƒå¼ (monotone disjunctive-normal-form, MDNF) çš„é€»è¾‘å…¬å¼ï¼Œé€šè¿‡æ»¡è¶³è¿™äº›å…¬å¼æ¥ä¿è¯æ¨¡å‹å¯¹ç‰¹å®šç±»åˆ«çš„é«˜é¢„æµ‹è¯„åˆ†ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ç§åŸºäºåŸå§‹æ¦‚å¿µçš„å•è°ƒè§£é‡Šåˆ—è¡¨ (monotone explanation list) ç®—æ³•ï¼Œç”¨äºå¤„ç†å¤šç±»åˆ«åˆ†ç±»çš„è§£é‡Šé—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒç®€æ´æ€§å’Œå¯è§£é‡Šæ€§çš„åŒæ—¶ï¼Œåœ¨å¤æ‚è§†è§‰æ•°æ®é›†ä¸Šå¯¹é»‘ç›’æ¨¡å‹å±•ç°å‡ºäº†æé«˜çš„å¿ å®åº¦ (fidelity) å’Œè¦†ç›–ç‡ (coverage)ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 5 figures, 5th International Joint Conference on Learning & Reasoning 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.13404v1",
      "published_date": "2026-01-19 21:21:58 UTC",
      "updated_date": "2026-01-19 21:21:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:13.484051+00:00"
    },
    {
      "arxiv_id": "2601.13401v1",
      "title": "Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics",
      "title_zh": "åƒç´ çº§ç²¾åº¦æ¨ç†ï¼šé¢å‘å®šé‡åœ°ç†ç©ºé—´åˆ†æçš„ QVLM æ¶æ„ä¸ SQuID æ•°æ®é›†",
      "authors": [
        "Peter A. Massih",
        "Eric Cosatto"
      ],
      "abstract": "Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Vision-Language Models (VLMs) å›  patch embeddings å¯¼è‡´åƒç´ çº§ä¿¡æ¯ä¸¢å¤±ï¼Œä»è€Œåœ¨å®šé‡ç©ºé—´æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸¤é¡¹æ ¸å¿ƒè´¡çŒ®ã€‚é¦–å…ˆï¼Œç ”ç©¶å‘å¸ƒäº† SQuID (Satellite Quantitative Intelligence Dataset)ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å« 2,000 ä¸ªå«æ˜Ÿå›¾åƒé—®ç­”å¯¹çš„ benchmarkï¼Œä¸“é—¨ç”¨äºè¯„ä¼°å®šé‡ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚å…¶æ¬¡ï¼Œæå‡ºäº† QVLM (Quantitative Vision-Language Model) æ¶æ„ï¼Œé€šè¿‡ code-generation å°†è¯­è¨€ç†è§£ä¸è§†è§‰åˆ†æè§£è€¦ï¼Œåˆ©ç”¨ segmentation masks ç›´æ¥åœ¨åƒç´ å±‚çº§è¿›è¡Œæ“ä½œä»¥ä¿æŒç©ºé—´ç²¾åº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQVLM åœ¨ SQuID ä¸Šçš„å‡†ç¡®ç‡è¾¾åˆ° 42.0%ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿ VLM çš„ 28.1%ï¼Œè¯æ˜äº†æ¶æ„è§£è€¦åœ¨å¤„ç†å®šé‡åœ°ç†ç©ºé—´åˆ†æä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to CVPR 2026. Introduces the QVLM architecture and the SQuID dataset for quantitative geospatial reasoning. Dataset DOI: 10.57967/hf/7565",
      "pdf_url": "https://arxiv.org/pdf/2601.13401v1",
      "published_date": "2026-01-19 21:14:34 UTC",
      "updated_date": "2026-01-19 21:14:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:18.469544+00:00"
    },
    {
      "arxiv_id": "2601.13400v1",
      "title": "Deep Image Prior with L0 Gradient Regularizer for Image Smoothing",
      "title_zh": "ç»“åˆ L0 æ¢¯åº¦æ­£åˆ™é¡¹çš„æ·±åº¦å›¾åƒå…ˆéªŒå›¾åƒå¹³æ»‘",
      "authors": [
        "Nhat Thanh Tran",
        "Kevin Bui",
        "Jack Xin"
      ],
      "abstract": "Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\\ell_0$, a deep image prior framework that incorporates the $\\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\\ell_0$ ``norm\", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DIP-â„“0 æ¡†æ¶ï¼Œé€šè¿‡åœ¨ Deep Image Prior ä¸­å¼•å…¥ â„“0 æ¢¯åº¦æ­£åˆ™é¡¹ (â„“0 gradient regularizer)ï¼Œå®ç°äº†æ— éœ€è®­ç»ƒæ•°æ®çš„é«˜è´¨é‡å›¾åƒå¹³æ»‘ (Image Smoothing)ã€‚ä¸ºäº†æœ‰æ•ˆä¼˜åŒ–åŒ…å«éå‡¸ã€éå¹³æ»‘ â„“0 èŒƒæ•°çš„æŸå¤±å‡½æ•°ï¼Œä½œè€…å¼€å‘äº†ä¸€ç§ç»“åˆäº¤æ›¿æ–¹å‘ä¹˜å­æ³• (ADMM) ä¸ç°æˆ â„“0 æ¢¯åº¦æœ€å°åŒ–æ±‚è§£å™¨çš„ç®—æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDIP-â„“0 åœ¨è¾¹ç¼˜ä¿ç•™å¹³æ»‘ (Edge-preserving smoothing) å’Œ JPEG ä¼ªå½±å»é™¤ (JPEG artifact removal) æ–¹é¢å‡ä¼˜äºå¤šç§ç°æœ‰ç®—æ³•ï¼Œå…‹æœäº†æ·±åº¦å­¦ä¹ æ–¹æ³•å¯¹å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†çš„ä¾èµ–ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "To be published in the Proceedings of IEEE ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.13400v1",
      "published_date": "2026-01-19 21:10:32 UTC",
      "updated_date": "2026-01-19 21:10:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:21.209502+00:00"
    },
    {
      "arxiv_id": "2601.13398v1",
      "title": "Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility",
      "title_zh": "LLM èƒ½å¦å®ç°å‹ç¼©ï¼ˆä¸è§£å‹ç¼©ï¼‰ï¼ŸåŸºäºå¯é€†æ€§çš„ä»£ç ç†è§£ä¸æ‰§è¡Œèƒ½åŠ›è¯„ä¼°",
      "authors": [
        "Nickil Maveli",
        "Antonio Vergari",
        "Shay B. Cohen"
      ],
      "abstract": "LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä»£ç ç†è§£ä¸æ‰§è¡Œä¸­çš„å¯é€†æ€§(Invertibility)é—®é¢˜ï¼Œå¹¶æå‡ºäº†RoundTripCodeEval (RTCE) åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨æ­£åå‘ä»£ç æ‰§è¡Œæ¨ç†ä¸­çš„ä¸€è‡´æ€§ã€‚RTCEé€šè¿‡åŒå°„ä¿çœŸåº¦(Bijection Fidelity)æµ‹é‡ç¼–ç ä¸è§£ç æ“ä½œé—´çš„ä¸€ä¸€å¯¹åº”å…³ç³»ï¼Œå¡«è¡¥äº†ç°æœ‰è¾“å…¥è¾“å‡ºé¢„æµ‹å’Œä»£ç æ‰§è¡ŒåŸºå‡†æµ‹è¯•çš„ç©ºç™½ã€‚é€šè¿‡å¯¹å¤šç§å…ˆè¿›Code-LLMsçš„è¯„ä¼°ï¼Œç ”ç©¶å‘ç°å³ä½¿é‡‡ç”¨é›¶æ ·æœ¬æç¤º(Zero-shot Prompting)ã€ç›‘ç£å¾®è°ƒ(Supervised Fine-tuning)æˆ–è‡ªæˆ‘åæ€(Self-reflection)æœºåˆ¶ï¼Œæ¨¡å‹ä»éš¾ä»¥å®ç°å®Œå…¨çš„å¾€è¿”ä¸€è‡´æ€§(Round-trip Consistency)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰æ¨¡å‹åœ¨å¤„ç†å¯ä¿¡ä»£ç æ¨ç†æ—¶ç¼ºä¹å¿…è¦çš„å†…éƒ¨è¿è´¯æ€§ï¼Œæ­ç¤ºäº†ç°æœ‰è¯„ä¼°ä½“ç³»å°šæœªæ•æ‰åˆ°çš„æ¨¡å‹å±€é™æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages (preprint)",
      "pdf_url": "https://arxiv.org/pdf/2601.13398v1",
      "published_date": "2026-01-19 21:09:48 UTC",
      "updated_date": "2026-01-19 21:09:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:22.407153+00:00"
    },
    {
      "arxiv_id": "2601.13392v1",
      "title": "Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks",
      "title_zh": "è¶…è¶Šè®°å¿†ï¼šåœ¨æœªè§è¿‡çš„è®¡ç®—ç†è®ºä»»åŠ¡ä¸Šæµ‹è¯• LLM çš„æ¨ç†èƒ½åŠ›",
      "authors": [
        "Shlok Shelat",
        "Jay Raval",
        "Souvik Roy",
        "Manas Gaur"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å½¢å¼è¯­è¨€ä»»åŠ¡ä¸­çš„è¡¨ç°æ˜¯æºäºçœŸå®çš„ç¬¦å·æ¨ç†(symbolic reasoning)è¿˜æ˜¯å¯¹å·²çŸ¥ç»“æ„çš„æ¨¡å¼åŒ¹é…ã€‚ç ”ç©¶è€…æå‡ºäº†ä¸€ä¸ªç”¨äºä»æ­£åˆ™è¯­è¨€(regular languages)æ„å»ºç¡®å®šæ€§æœ‰é™è‡ªåŠ¨æœº(DFA)çš„åŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–äº†å·²çŸ¥é—®é¢˜ä»¥åŠé€šè¿‡Arden's theoremç­‰æ–¹æ³•ç”Ÿæˆçš„å…¨æ–°(unseen)é—®é¢˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨å…¨æ–°é—®é¢˜ä¸Šçš„å‡†ç¡®ç‡å¤§å¹…ä¸‹é™30-64%ï¼Œåæ˜ å‡ºå…¶åœ¨å¤„ç†å¤æ‚è¯­è¨€çº¦æŸå’Œä¿æŒå…¨å±€ä¸€è‡´æ€§(global consistency)æ–¹é¢çš„å±€é™ã€‚é€šè¿‡å¯¹æ¯”Chain-of-Thoughtå’ŒTree-of-Thoughtç­‰æç¤ºç­–ç•¥ï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†LLMsåœ¨ç”Ÿæˆè¯­æ³•åˆç†çš„DFAä¸å®ç°è¯­ä¹‰æ­£ç¡®çš„å½¢å¼æ¨ç†(formal reasoning)èƒ½åŠ›ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®è·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages, 11 figures, 6 tables, Work in Progress",
      "pdf_url": "https://arxiv.org/pdf/2601.13392v1",
      "published_date": "2026-01-19 21:00:31 UTC",
      "updated_date": "2026-01-19 21:00:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:28.452657+00:00"
    },
    {
      "arxiv_id": "2601.13385v1",
      "title": "Organ-Aware Attention Improves CT Triage and Classification",
      "title_zh": "å™¨å®˜æ„ŸçŸ¥æ³¨æ„åŠ›æå‡ CT åˆ†è¯Šä¸åˆ†ç±»",
      "authors": [
        "Lavsen Dahal",
        "Yubraj Bhandari",
        "Geoffrey D. Rubin",
        "Joseph Y. Lo"
      ],
      "abstract": "There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜é€šé‡è®¡ç®—æœºæ–­å±‚æ‰«æ(CT)çš„åˆ†è¯Šå’Œåˆ†ç±»æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º ORACLE-CT çš„ç¼–ç å™¨æ— å…³æ¨¡å‹æ¡†æ¶ã€‚ç”±äºé€šç”¨è§†è§‰è¯­è¨€æ¨¡å‹(VLM)åœ¨å¤„ç† 3D è§£å‰–ç»“æ„å’Œå™ªå£°ç›‘ç£æ–¹é¢è¡¨ç°å—é™ï¼Œè¯¥ç ”ç©¶é¦–å…ˆæ„å»ºäº†è¶…è¶Šç°æœ‰çº¿æ€§æ¢æµ‹ VLM çš„ç›‘ç£å­¦ä¹ åŸºå‡†ï¼Œå¹¶è¿›ä¸€æ­¥å¼•å…¥äº†å™¨å®˜æ©ç æ³¨æ„åŠ›(Organ-Masked Attention)å’Œå™¨å®˜æ ‡é‡èåˆ(Organ-Scalar Fusion)æŠ€æœ¯ã€‚é€šè¿‡ç»“åˆç©ºé—´è¯æ®ä¸ä½“ç§¯ã€å¹³å‡ HU å€¼ç­‰è§£å‰–ç‰¹å¾ï¼ŒORACLE-CT åœ¨èƒ¸éƒ¨(CT-RATE)å’Œè…¹éƒ¨(MERLIN)æ•°æ®é›†ä¸Šå‡å–å¾—äº† state-of-the-art (SOTA) çš„åˆ†ç±»æ€§èƒ½ï¼ŒAUROC åˆ†åˆ«è¾¾åˆ° 0.86 å’Œ 0.85ã€‚è¯¥æˆæœä¸ºä¸åŒè§£å‰–éƒ¨ä½çš„ CT å½±åƒæä¾›äº†ç»Ÿä¸€ä¸”é«˜æ•ˆçš„è‡ªåŠ¨åŒ–åˆ†è¯Šä¸åˆ†ç±»è¯„ä¼°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13385v1",
      "published_date": "2026-01-19 20:37:45 UTC",
      "updated_date": "2026-01-19 20:37:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:30.159616+00:00"
    },
    {
      "arxiv_id": "2601.13383v1",
      "title": "A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge",
      "title_zh": "æ„å»ºå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„è‡ªä¸»æ™ºèƒ½ä½“è½»é‡çº§æ¨¡å—åŒ–æ¡†æ¶ï¼šAgentForge çš„è®¾è®¡ã€å®ç°ä¸åº”ç”¨",
      "authors": [
        "Akbar Anbar Jafari",
        "Cagri Ozcinar",
        "Gholamreza Anbarjafari"
      ],
      "abstract": "The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AgentForgeï¼Œä¸€ä¸ªè½»é‡çº§ã€å¼€æºçš„ Python æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ¨¡å—åŒ–æ¶æ„ç®€åŒ– Large Language Models (LLMs) é©±åŠ¨çš„è‡ªä¸»æ™ºèƒ½ä½“å¼€å‘ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°ï¼šæ”¯æŒç²¾ç»†ä»»åŠ¡åˆ†è§£çš„å¯ç»„åˆæŠ€èƒ½æŠ½è±¡ (skill abstraction)ã€ç»Ÿä¸€çš„ LLM åç«¯æ¥å£ä»¥åŠåŸºäº YAML çš„å£°æ˜å¼é…ç½®ç³»ç»Ÿï¼Œæœ‰æ•ˆè§£å†³äº†ç°æœ‰æ¡†æ¶æ¶æ„åƒµåŒ–å’Œå¼€å‘å¤æ‚åº¦é«˜çš„é—®é¢˜ã€‚é€šè¿‡å°†æŠ€èƒ½ç»„åˆå½¢å¼åŒ–ä¸ºæœ‰å‘æ— ç¯å›¾ (DAG)ï¼ŒAgentForge èƒ½å¤Ÿçµæ´»è¡¨ç¤ºå¤æ‚çš„é¡ºåºå’Œå¹¶è¡Œä»»åŠ¡å·¥ä½œæµã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ LangChain ç›¸æ¯”ï¼ŒAgentForge å¯ç¼©çŸ­ 62% çš„å¼€å‘æ—¶é—´ï¼Œä¸”ç³»ç»Ÿç¼–æ’å»¶è¿Ÿä½äº 100msï¼Œåœ¨ä¿è¯é«˜æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—æå‡äº†å¼€å‘æ•ˆç‡ã€‚è¯¥æ¡†æ¶ä¸ºæ„å»ºã€è¯„ä¼°å’Œéƒ¨ç½²é«˜æ€§èƒ½è‡ªä¸»æ™ºèƒ½ä½“æä¾›äº†ä¸€ä¸ªå…¼é¡¾çµæ´»æ€§ä¸ç”Ÿäº§åŠ›çš„åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.13383v1",
      "published_date": "2026-01-19 20:33:26 UTC",
      "updated_date": "2026-01-19 20:33:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:30.808500+00:00"
    },
    {
      "arxiv_id": "2601.13376v1",
      "title": "Bounded Minds, Generative Machines: Envisioning Conversational AI that Works with Human Heuristics and Reduces Bias Risk",
      "title_zh": "æœ‰é™å¿ƒæ™ºä¸ç”Ÿæˆå¼æœºå™¨ï¼šå±•æœ›ååŒäººç±»å¯å‘å¼æ€ç»´å¹¶é™ä½åè§é£é™©çš„å¯¹è¯å¼äººå·¥æ™ºèƒ½",
      "authors": [
        "Jiqun Liu"
      ],
      "abstract": "Conversational AI is rapidly becoming a primary interface for information seeking and decision making, yet most systems still assume idealized users. In practice, human reasoning is bounded by limited attention, uneven knowledge, and reliance on heuristics that are adaptive but bias-prone. This article outlines a research pathway grounded in bounded rationality, and argues that conversational AI should be designed to work with human heuristics rather than against them. It identifies key directions for detecting cognitive vulnerability, supporting judgment under uncertainty, and evaluating conversational systems beyond factual accuracy, toward decision quality and cognitive robustness.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¯¹è¯å¼ AIï¼ˆConversational AIï¼‰åœ¨ä¿¡æ¯æ£€ç´¢ä¸å†³ç­–ä¸­çš„ä½œç”¨ï¼ŒæŒ‡å‡ºç›®å‰ç³»ç»Ÿå¾€å¾€å‡è®¾ç”¨æˆ·æ˜¯ç†æƒ³åŒ–çš„ï¼Œå¿½è§†äº†äººç±»æœ‰é™ç†æ€§ï¼ˆbounded rationalityï¼‰åŠå¯å‘æ³•ï¼ˆheuristicsï¼‰æ˜“äº§ç”Ÿåè§ï¼ˆbias riskï¼‰çš„å±€é™ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§åŸºäºæœ‰é™ç†æ€§çš„ç ”ç©¶è·¯å¾„ï¼Œä¸»å¼  AI è®¾è®¡åº”ä¸äººç±»çš„å¯å‘å¼æ€ç»´ååŒå·¥ä½œï¼Œè€Œéæ’æ–¥ã€‚é€šè¿‡è¯†åˆ«è®¤çŸ¥è„†å¼±æ€§ï¼ˆcognitive vulnerabilityï¼‰ã€æ”¯æŒä¸ç¡®å®šç¯å¢ƒä¸‹çš„åˆ¤æ–­ï¼Œå¹¶ä»å†³ç­–è´¨é‡å’Œè®¤çŸ¥é²æ£’æ€§ï¼ˆcognitive robustnessï¼‰ç­‰ç»´åº¦è¯„ä¼°ç³»ç»Ÿï¼Œè¯¥ç ”ç©¶æ—¨åœ¨æ„å»ºèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘åè§é£é™©å¹¶æå‡äººç±»å†³ç­–èƒ½åŠ›çš„ç”Ÿæˆå¼æœºå™¨ã€‚",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13376v1",
      "published_date": "2026-01-19 20:23:28 UTC",
      "updated_date": "2026-01-19 20:23:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:33.077076+00:00"
    },
    {
      "arxiv_id": "2601.13358v1",
      "title": "The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models",
      "title_zh": "æ€ç»´å‡ ä½•å­¦ï¼šè§„æ¨¡å¦‚ä½•é‡æ„å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†",
      "authors": [
        "Samuel Cyrenius Anderson"
      ],
      "abstract": "Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¥ç»ç¼©æ”¾å®šå¾‹ï¼ˆNeural Scaling Lawsï¼‰å¦‚ä½•é‡å¡‘å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†ç»“æ„ï¼Œé€šè¿‡åˆ†æå››å¤§é¢†åŸŸï¼ˆæ³•å¾‹ã€ç§‘å­¦ã€ä»£ç ã€æ•°å­¦ï¼‰çš„25,000å¤šæ¡é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰è½¨è¿¹ï¼Œå‘ç°è§„æ¨¡å¢é•¿è§¦å‘äº†é¢†åŸŸç‰¹å®šçš„ç›¸å˜ï¼ˆPhase Transitionsï¼‰è€Œéå‡åŒ€çš„æ€§èƒ½æå‡ã€‚ç ”ç©¶å‘ç°æ³•å¾‹æ¨ç†å‘ˆç°â€œç»“æ™¶åŒ–â€ï¼ˆCrystallizationï¼‰ç‰¹å¾ï¼Œè¡¨ç°ä¸ºè¡¨å¾ç»´åº¦å¤§å¹…åç¼©å’Œæµå½¢è§£ç¼ ï¼ˆManifold Untanglingï¼‰ï¼›è€Œç§‘å­¦ä¸æ•°å­¦æ¨ç†ä¿æŒâ€œæ¶²æ€â€ï¼ˆLiquidï¼‰çš„å‡ ä½•ä¸å˜æ€§ï¼›ä»£ç æ¨ç†åˆ™å½¢æˆäº†ç¦»æ•£çš„â€œæ™¶æ ¼â€ï¼ˆLatticeï¼‰ç­–ç•¥æ¨¡å¼ã€‚åŸºäºæ­¤ï¼Œä½œè€…å¼•å…¥äº†ç¥ç»æ¨ç†ç®—å­ï¼ˆNeural Reasoning Operatorsï¼‰ï¼Œåœ¨ç»“æ™¶åŒ–çš„æ³•å¾‹ä»»åŠ¡ä¸­æ— éœ€éå†ä¸­é—´çŠ¶æ€å³å¯é¢„æµ‹æ¨ç†ç»ˆç‚¹ï¼Œå‡†ç¡®ç‡è¾¾63.6%ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¯†åˆ«å‡ºä¸€ç§é€šç”¨çš„éœ‡è¡ç‰¹å¾ï¼ˆOscillatory Signatureï¼‰ï¼Œè¯æ˜æ¨ç†æˆæœ¬ç”±æµå½¢å‡ ä½•ï¼ˆManifold Geometryï¼‰å†³å®šï¼Œä¸ºåˆ©ç”¨æ‹“æ‰‘ç»“æ„å®ç°æ¨ç†åŠ é€Ÿæä¾›äº†å¯èƒ½ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "34 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.13358v1",
      "published_date": "2026-01-19 19:53:37 UTC",
      "updated_date": "2026-01-19 19:53:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:36.464491+00:00"
    },
    {
      "arxiv_id": "2601.13352v1",
      "title": "LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction",
      "title_zh": "LLM-as-RNNï¼šä¸€ç§ç”¨äºè®°å¿†æ›´æ–°ä¸åºåˆ—é¢„æµ‹çš„å¾ªç¯è¯­è¨€æ¨¡å‹",
      "authors": [
        "Yuxing Lu",
        "J. Ben Tamo",
        "Weichen Zhao",
        "Nan Sun",
        "Yishan Zhong",
        "Wenqi Shi",
        "Jinzhuo Wang",
        "May D. Wang"
      ],
      "abstract": "Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LLM-as-RNNï¼Œè¿™æ˜¯ä¸€ç§ä»…éœ€æ¨ç†(Inference-only)çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨åºåˆ—é¢„æµ‹ä¸­å› ä¾èµ–ä¸å¯å˜ä¸Šä¸‹æ–‡è€Œç¼ºä¹å¯æ›´æ–°è®°å¿†æœºåˆ¶çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†å†»ç»“çš„ LLM çš„éšè—çŠ¶æ€è¡¨ç¤ºä¸ºè‡ªç„¶è¯­è¨€è®°å¿†ï¼ˆç»“æ„åŒ–çš„ç³»ç»Ÿæç¤ºæ‘˜è¦ï¼‰ï¼Œå¹¶åˆ©ç”¨åé¦ˆé©±åŠ¨çš„æ–‡æœ¬é‡å†™åœ¨æ¯ä¸ªæ—¶é—´æ­¥è¿›è¡Œæ›´æ–°ï¼Œå°†æ¨¡å‹è½¬åŒ–ä¸ºå¾ªç¯é¢„æµ‹å™¨ã€‚è¿™ç§æœºåˆ¶ä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å›ºå®š Token é¢„ç®—å†…å®ç°æ— éœ€å‚æ•°æ›´æ–°çš„åœ¨çº¿å­¦ä¹ (Online Learning)ï¼Œä»è€Œæœ‰æ•ˆçº æ­£ç”Ÿæˆé”™è¯¯å¹¶ä¿ç•™ä»»åŠ¡ç›¸å…³æ¨¡å¼ã€‚åœ¨åŒ»ç–—ã€æ°”è±¡å’Œé‡‘èé¢†åŸŸçš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒLLM-as-RNN åœ¨ Llamaã€Gemma å’Œ GPT ç³»åˆ—æ¨¡å‹ä¸Šçš„é¢„æµ‹å‡†ç¡®ç‡å¹³å‡æé«˜äº† 6.5%ï¼Œæ˜¾è‘—ä¼˜äº Zero-shot å’Œ MemPrompt ç­‰åŸºå‡†æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æä¾›äº†ä¼ ç»Ÿä¸Šä¸‹æ–‡ç´¯ç§¯æ‰€æ¬ ç¼ºçš„å¯è§£é‡Šã€äººç±»å¯è¯»çš„å­¦ä¹ è½¨è¿¹ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 5 figures, 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.13352v1",
      "published_date": "2026-01-19 19:41:39 UTC",
      "updated_date": "2026-01-19 19:41:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:39.439368+00:00"
    },
    {
      "arxiv_id": "2601.13348v1",
      "title": "The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist Roleplays, Pseudosocial Companions, and Epistemic Rabbit Holes",
      "title_zh": "â€œAI ç¥ç¯â€ç°è±¡ä¸ä¸‰ç±» AI èŠå¤©æœºå™¨äººæˆç˜¾ï¼šé€ƒé¿å¼è§’è‰²æ‰®æ¼”ã€æ‹Ÿç¤¾ä¼šé™ªä¼´åŠè®¤çŸ¥â€œå…”å­æ´â€",
      "authors": [
        "M. Karen Shen",
        "Jessica Huang",
        "Olivia Liang",
        "Ig-Jae Kim",
        "Dongwook Yoon"
      ],
      "abstract": "Recent reports on generative AI chatbot use raise concerns about its addictive potential. An in-depth understanding is imperative to minimize risks, yet AI chatbot addiction remains poorly understood. This study examines how to characterize AI chatbot addiction--why users become addicted, the symptoms commonly reported, and the distinct types it comprises. We conducted a thematic analysis of Reddit entries (n=334) across 14 subreddits where users narrated their experiences with addictive AI chatbot use, followed by an exploratory data analysis. We found: (1) users' dependence tied to the \"AI Genie\" phenomenon--users can get exactly anything they want with minimal effort--and marked by symptoms that align with addiction literature, (2) three distinct addiction types: Escapist Roleplay, Pseudosocial Companion, and Epistemic Rabbit Hole, (3) sexual content involved in multiple cases, and (4) recovery strategies' perceived helpfulness differ between addiction types. Our work lays empirical groundwork to inform future strategies for prevention, diagnosis, and intervention.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½èŠå¤©æœºå™¨äººçš„æˆç˜¾æ½œåŠ›åŠå…¶ç‰¹å¾ï¼Œæå‡ºäº†â€œAI Genieâ€ç°è±¡ï¼Œå³ç”¨æˆ·èƒ½ä»¥æä½æˆæœ¬è·å¾—ä»»ä½•æ¸´æœ›çš„å†…å®¹ã€‚é€šè¿‡å¯¹Redditç¤¾åŒº334æ¡ç”¨æˆ·ç»å†çš„ Thematic Analysisï¼Œç ”ç©¶è¯†åˆ«å¹¶å®šä¹‰äº†ä¸‰ç§æˆªç„¶ä¸åŒçš„æˆç˜¾ç±»å‹ï¼šEscapist Roleplaysï¼ˆé€ƒé¿ä¸»ä¹‰è§’è‰²æ‰®æ¼”ï¼‰ã€Pseudosocial Companionsï¼ˆæ‹Ÿç¤¾ä¼šåŒä¼´ï¼‰å’ŒEpistemic Rabbit Holesï¼ˆæ¢ç´¢æ€§è®¤çŸ¥é»‘æ´ï¼‰ã€‚ç ”ç©¶å‘ç°ï¼Œè¿™äº›æˆç˜¾ç—‡çŠ¶ä¸ä¼ ç»Ÿæˆç˜¾æ–‡çŒ®ä¸€è‡´ï¼Œä¸”å¸¸æ¶‰åŠæ€§å†…å®¹ï¼Œä¸åŒç±»å‹çš„åº·å¤ç­–ç•¥æœ‰æ•ˆæ€§å­˜åœ¨å·®å¼‚ã€‚è¯¥å·¥ä½œä¸ºæœªæ¥é’ˆå¯¹AIæˆç˜¾çš„é¢„é˜²ã€è¯Šæ–­å’Œå¹²é¢„æä¾›äº†å…³é”®çš„å®è¯åŸºç¡€ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To appear in CHI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.13348v1",
      "published_date": "2026-01-19 19:33:58 UTC",
      "updated_date": "2026-01-19 19:33:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:50.392990+00:00"
    },
    {
      "arxiv_id": "2601.13327v1",
      "title": "PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion",
      "title_zh": "PepEDiffï¼šåŸºäºè›‹ç™½è´¨åµŒå…¥æ‰©æ•£çš„é›¶æ ·æœ¬å¤šè‚½ç»“åˆå‰‚è®¾è®¡",
      "authors": [
        "Po-Yu Liang",
        "Tobo Duran",
        "Jun Bai"
      ],
      "abstract": "We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PepEDiffï¼Œä¸€ç§æ–°å‹çš„å¤šè‚½é…ä½“ç”Ÿæˆå™¨ï¼Œæ—¨åœ¨å®ç°é’ˆå¯¹ç‰¹å®šé¶æ ‡å—ä½“è›‹ç™½çš„ Zero-Shot å¤šè‚½é…ä½“è®¾è®¡ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨é¢„è®­ç»ƒè›‹ç™½åµŒå…¥æ¨¡å‹çš„è¿ç»­æ½œåœ¨ç©ºé—´ï¼ˆlatent spaceï¼‰ä¸­ç›´æ¥ç”Ÿæˆåºåˆ—ï¼Œå¹¶ç»“åˆæ‰©æ•£æ¨¡å‹ï¼ˆdiffusion-based samplingï¼‰è¿›è¡Œé‡‡æ ·ï¼Œä»è€Œæ‘†è„±äº†å¯¹ä¸­é—´ç»“æ„é¢„æµ‹çš„ä¾èµ–ã€‚è¿™ç§ç­–ç•¥ä¸ä»…æå‡äº†åºåˆ—å’Œç»“æ„çš„å¤šæ ·æ€§ï¼Œè¿˜åˆ©ç”¨è›‹ç™½è´¨åµŒå…¥æµå½¢ï¼ˆprotein embedding manifoldï¼‰ä½œä¸ºè¯­ä¹‰å…ˆéªŒæ¥æ¢ç´¢æœªçŸ¥çš„å¤šè‚½ç©ºé—´ã€‚å®éªŒè¡¨æ˜ï¼ŒPepEDiff åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ TIGIT é¶æ ‡åŠå¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºç°æœ‰çš„ SOTA æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶ä½œä¸ºé€šç”¨ã€æ— ç»“æ„ï¼ˆstructure-freeï¼‰å¤šè‚½è®¾è®¡æ¡†æ¶çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13327v1",
      "published_date": "2026-01-19 19:07:32 UTC",
      "updated_date": "2026-01-19 19:07:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:53.310703+00:00"
    },
    {
      "arxiv_id": "2601.13317v1",
      "title": "Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse",
      "title_zh": "ä»˜è´¹è¯è¯­ä¸å…¬å…±åŠ¨æ€ï¼šæ°”å€™è¯è¯­çš„å¯è§£é‡Šè·¨å¹³å°ä¸»é¢˜å»ºæ¨¡",
      "authors": [
        "Samantha Sudhoff",
        "Pranav Perumal",
        "Zhaoqing Wu",
        "Tunazzina Islam"
      ],
      "abstract": "Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å¯è§£é‡Šçš„ç«¯åˆ°ç«¯ä¸»é¢˜å‘ç°ä¸åˆ†é…æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆè¯­ä¹‰ç›¸ä¼¼åº¦èšç±»å’Œå¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ç”Ÿæˆäººç±»å¯ç†è§£çš„ä¸»é¢˜æ ‡ç­¾ã€‚ç ”ç©¶å¯¹æ¯”åˆ†æäº† Meta å¹³å°çš„ä»˜è´¹å¹¿å‘Š (Paid Voices) ä¸ Bluesky ç¤¾äº¤åª’ä½“çš„å…¬å…±åŠ¨æ€ (Public Feeds) åœ¨ 2024 å¹´ 7 æœˆè‡³ 2025 å¹´ 9 æœˆæœŸé—´çš„æ°”å€™è®®é¢˜è®¨è®ºã€‚é€šè¿‡äººå·¥è¯„ä»·ã€åŸºäº LLM çš„è¯„ä¼°ä»¥åŠç«‹åœºé¢„æµ‹ (Stance Prediction) ç­‰ä»»åŠ¡ï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶åœ¨æ•æ‰ä¸»é¢˜è¿è´¯æ€§æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚ç ”ç©¶å‘ç°ï¼Œä¸åŒå¹³å°çš„æ¿€åŠ±æœºåˆ¶æ˜¾è‘—å½±å“äº†æ°”å€™å™äº‹çš„ä¸»é¢˜ç»“æ„ã€ç«‹åœºå–å‘ä»¥åŠå¯¹æ”¿æ²»äº‹ä»¶çš„æ—¶é—´å“åº”æ€§ã€‚è¯¥æˆæœæ­ç¤ºäº†æœºæ„å®£ä¼ ä¸å…¬ä¼—è¡¨è¾¾ä¹‹é—´çš„ç³»ç»Ÿæ€§å·®å¼‚ï¼Œå¹¶ä¸ºè·¨å¼‚æ„é€šä¿¡ç¯å¢ƒçš„æ¯”è¾ƒå™äº‹åˆ†ææä¾›äº†é€šç”¨æ¡†æ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13317v1",
      "published_date": "2026-01-19 19:00:56 UTC",
      "updated_date": "2026-01-19 19:00:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:54.939381+00:00"
    },
    {
      "arxiv_id": "2601.13295v1",
      "title": "CooperBench: Why Coding Agents Cannot be Your Teammates Yet",
      "title_zh": "CooperBenchï¼šç¼–ç¨‹æ™ºèƒ½ä½“ä¸ºä½•å°šä¸èƒ½æˆä¸ºä½ çš„é˜Ÿå‹",
      "authors": [
        "Arpandeep Khatua",
        "Hao Zhu",
        "Peter Tran",
        "Arya Prabhudesai",
        "Frederic Sadrieh",
        "Johann K. Lieberwirth",
        "Xinkai Yu",
        "Yicheng Fu",
        "Michael J. Ryan",
        "Jiaxin Pei",
        "Diyi Yang"
      ],
      "abstract": "Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CooperBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å« 600 å¤šä¸ªåä½œç¼–ç¨‹ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼° AI æ™ºèƒ½ä½“åœ¨å›¢é˜Ÿåä½œä¸­çš„åè°ƒèƒ½åŠ›å’Œç¤¾äº¤æ™ºèƒ½ (Social Intelligence)ã€‚å®éªŒå‘ç°ï¼Œç°æœ‰æœ€å…ˆè¿›çš„ç¼–ç¨‹æ™ºèƒ½ä½“é¢ä¸´â€œåè°ƒä¹‹å’’â€ (Curse of Coordination)ï¼Œå³åä½œæ¨¡å¼ä¸‹çš„æˆåŠŸç‡æ¯”ç‹¬ç«‹å®Œæˆä»»åŠ¡æ—¶å¹³å‡é™ä½äº† 30%ï¼Œè¿™ä¸äººç±»åä½œæå‡æ•ˆç‡çš„å¸¸æ€æˆªç„¶ç›¸åã€‚åˆ†æè¡¨æ˜ï¼Œæ™ºèƒ½ä½“åœ¨åä½œä¸­å­˜åœ¨é€šä¿¡ä½æ•ˆã€éš¾ä»¥éµå®ˆæ‰¿è¯ºä»¥åŠå¯¹ä»–äººçš„è®¡åˆ’å­˜åœ¨é”™è¯¯é¢„æœŸç­‰ä¸‰å¤§æ ¸å¿ƒé—®é¢˜ã€‚å°½ç®¡åœ¨æ¨¡æ‹Ÿä¸­è§‚å¯Ÿåˆ°äº†è§’è‰²åˆ†é…å’Œè°ˆåˆ¤ç­‰åˆæ­¥çš„æ¶Œç°è¡Œä¸ºï¼Œè¯¥ç ”ç©¶å‘¼å AI é¢†åŸŸåº”ä»å•çº¯è¿½æ±‚ä¸ªä½“èƒ½åŠ›è½¬å‘å¼€å‘æ›´å…·ç¤¾äº¤æ™ºèƒ½çš„åä½œç³»ç»Ÿã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.MA",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://cooperbench.com",
      "pdf_url": "https://arxiv.org/pdf/2601.13295v1",
      "published_date": "2026-01-19 18:48:37 UTC",
      "updated_date": "2026-01-19 18:48:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:38:57.076752+00:00"
    },
    {
      "arxiv_id": "2601.13286v1",
      "title": "AI Skills Improve Job Prospects: Causal Evidence from a Hiring Experiment",
      "title_zh": "AI æŠ€èƒ½æå‡å°±ä¸šå‰æ™¯ï¼šæ¥è‡ªæ‹›è˜å®éªŒçš„å› æœè¯æ®",
      "authors": [
        "Fabian Stephany",
        "Ole Teutloff",
        "Angelo Leone"
      ],
      "abstract": "The growing adoption of artificial intelligence (AI) technologies has heightened interest in the labour market value of AI-related skills, yet causal evidence on their role in hiring decisions remains scarce. This study examines whether AI skills serve as a positive hiring signal and whether they can offset conventional disadvantages such as older age or lower formal education. We conduct an experimental survey with 1,700 recruiters from the United Kingdom and the United States. Using a paired conjoint design, recruiters evaluated hypothetical candidates represented by synthetically designed resumes. Across three occupations - graphic designer, office assistant, and software engineer - AI skills significantly increase interview invitation probabilities by approximately 8 to 15 percentage points. AI skills also partially or fully offset disadvantages related to age and lower education, with effects strongest for office assistants, where formal AI certification plays an additional compensatory role. Effects are weaker for graphic designers, consistent with more skeptical recruiter attitudes toward AI in creative work. Finally, recruiters' own background and AI usage significantly moderate these effects. Overall, the findings demonstrate that AI skills function as a powerful hiring signal and can mitigate traditional labour market disadvantages, with implications for workers' skill acquisition strategies and firms' recruitment practices.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡åœ¨è‹±å›½å’Œç¾å›½çš„1,700åæ‹›è˜äººå‘˜ä¸­è¿›è¡Œå®éªŒæ€§è°ƒæŸ¥(Experimental survey)ï¼Œé‡‡ç”¨é…å¯¹è”åˆè®¾è®¡(Paired conjoint design)æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)æŠ€èƒ½å¯¹é›‡ä½£å†³ç­–çš„å› æœå½±å“ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨å¹³é¢è®¾è®¡å¸ˆã€åŠå…¬å®¤åŠ©ç†å’Œè½¯ä»¶å·¥ç¨‹å¸ˆå²—ä½ä¸­ï¼Œå…·å¤‡AIæŠ€èƒ½æ˜¾è‘—æé«˜äº†çº¦8è‡³15ä¸ªç™¾åˆ†ç‚¹çš„é¢è¯•é‚€è¯·æ¦‚ç‡ã€‚æ­¤å¤–ï¼ŒAIæŠ€èƒ½å¯ä»¥éƒ¨åˆ†æˆ–å…¨éƒ¨æŠµæ¶ˆé«˜é¾„æˆ–ä½å­¦å†å¸¦æ¥çš„ä¼ ç»ŸåŠ³åŠ¨åŠ›å¸‚åœºåŠ£åŠ¿ï¼Œä¸”è¿™ç§è¡¥å¿æ•ˆåº”åœ¨åŠå…¬å®¤åŠ©ç†å²—ä½ä¸Šæœ€ä¸ºæ˜æ˜¾ã€‚ç ”ç©¶è¿˜å‘ç°ï¼Œæ‹›è˜äººå‘˜å¯¹AIåœ¨åˆ›æ„å·¥ä½œä¸­æŒæ›´æ€€ç–‘çš„æ€åº¦ï¼Œä¸”å…¶è‡ªèº«èƒŒæ™¯ä¼šè°ƒèŠ‚è¿™äº›æ•ˆåº”ã€‚æ€»ä½“è€Œè¨€ï¼ŒAIæŠ€èƒ½å·²æˆä¸ºä¸€ç§å¼ºæœ‰åŠ›çš„é›‡ä½£ä¿¡å·(Hiring signal)ï¼Œå¯¹åŠ³åŠ¨è€…çš„æŠ€èƒ½è·å–ç­–ç•¥å’Œä¼ä¸šçš„æ‹›è˜å®è·µå…·æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚",
      "categories": [
        "econ.GN",
        "cs.AI"
      ],
      "primary_category": "econ.GN",
      "comment": "46 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.13286v1",
      "published_date": "2026-01-19 18:37:28 UTC",
      "updated_date": "2026-01-19 18:37:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:02.156353+00:00"
    },
    {
      "arxiv_id": "2601.13268v1",
      "title": "Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops",
      "title_zh": "é€šè¿‡å¤šæ™ºèƒ½ä½“è¯„ä¼°å¾ªç¯æå‡åŒ»ç–—äººå·¥æ™ºèƒ½çš„å®‰å…¨æ€§ä¸å¯ä¿¡åº¦",
      "authors": [
        "Zainab Ghafoor",
        "Md Shafiqul Islam",
        "Koushik Howlader",
        "Md Rasel Khondokar",
        "Tanusree Bhattacharjee",
        "Sayantan Chakraborty",
        "Adrito Roy",
        "Ushashi Bhattacharjee",
        "Tirtho Roy"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç²¾ç‚¼æ¡†æ¶(multi-agent refinement framework)ï¼Œæ—¨åœ¨é€šè¿‡ç»“æ„åŒ–çš„è¿­ä»£å¯¹é½æé«˜åŒ»ç–—å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚è¯¥ç³»ç»Ÿç»“åˆäº† DeepSeek R1 å’Œ Med-PaLM ä½œä¸ºç”Ÿæˆæ¨¡å‹ï¼Œå¹¶åˆ©ç”¨ LLaMA 3.1 å’Œ Phi-4 ä½œä¸ºè¯„ä¼°æ™ºèƒ½ä½“ï¼Œä¾æ®ç¾å›½åŒ»å­¦ä¼š(AMA)åŒ»å­¦ä¼¦ç†åŸåˆ™å’Œäº”çº§å®‰å…¨é£é™©è¯„ä¼°(SRA-5)åè®®å¯¹å›å¤è¿›è¡Œå®¡æ ¸ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDeepSeek R1 å…·æœ‰æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ï¼Œè€Œ Med-PaLM åœ¨éšç§æ•æ„Ÿåœºæ™¯ä¸­è¡¨ç°æ›´ä¼˜ï¼›é€šè¿‡è¿­ä»£å¾ªç¯ï¼Œæ¨¡å‹ä¼¦ç†è¿è§„å‡å°‘äº†89%ï¼Œé£é™©é™çº§ç‡è¾¾92%ã€‚è¯¥ç ”ç©¶ä¸ºç¬¦åˆç›‘ç®¡è¦æ±‚ä¸”å…·å¤‡æˆæœ¬æ•ˆç›Šçš„åŒ»ç–— AI å®‰å…¨æ²»ç†æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13268v1",
      "published_date": "2026-01-19 18:10:34 UTC",
      "updated_date": "2026-01-19 18:10:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:03.440667+00:00"
    },
    {
      "arxiv_id": "2601.13262v1",
      "title": "CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning",
      "title_zh": "CURE-Medï¼šé¢å‘å¤šè¯­è¨€åŒ»ç–—æ¨ç†çš„è¯¾ç¨‹å¯å‘å¼å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Eric Onyame",
        "Akash Ghosh",
        "Subhadip Baidya",
        "Sriparna Saha",
        "Xiuying Chen",
        "Chirag Agarwal"
      ],
      "abstract": "While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤šè¯­è¨€åŒ»å­¦æ¨ç†ä¸­çš„ä¸å¯é æ€§ï¼Œé¦–å…ˆæ¨å‡ºäº†CUREMED-BENCHæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¶µç›–é˜¿å§†å“ˆæ‹‰è¯­(Amharic)ã€çº¦é²å·´è¯­(Yoruba)å’Œæ–¯ç“¦å¸Œé‡Œè¯­(Swahili)ç­‰13ç§è¯­è¨€çš„é«˜è´¨é‡åŒ»å­¦æ¨ç†æ•°æ®é›†ã€‚åŸºäºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†CURE-MEDï¼Œä¸€ç§è¯¾ç¨‹å‘ŠçŸ¥å¼ºåŒ–å­¦ä¹ (Curriculum-Informed Reinforcement Learning)æ¡†æ¶ï¼Œé€šè¿‡æ•´åˆä»£ç åˆ‡æ¢æ„ŸçŸ¥ç›‘ç£å¾®è°ƒ(code-switching-aware SFT)å’Œç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(Group Relative Policy Optimization, GRPO)æ¥åŒæ­¥æå‡é€»è¾‘æ­£ç¡®æ€§å’Œè¯­è¨€ç¨³å®šæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒè§„æ¨¡æ¨¡å‹ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œ32Bæ¨¡å‹å®ç°äº†94.96%çš„è¯­è¨€ä¸€è‡´æ€§å’Œ70.04%çš„é€»è¾‘å‡†ç¡®ç‡ã€‚è¿™é¡¹å·¥ä½œä¸ºåœ¨å¤šè¯­è¨€åŒ»ç–—ç¯å¢ƒä¸­éƒ¨ç½²å¯é ä¸”å…¬å¹³çš„æ¨ç†æ¨¡å‹æä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13262v1",
      "published_date": "2026-01-19 17:51:00 UTC",
      "updated_date": "2026-01-19 17:51:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:15.748415+00:00"
    },
    {
      "arxiv_id": "2601.13260v1",
      "title": "Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models",
      "title_zh": "è«å°†åˆ†è¯å™¨è§†ä½œç†æ‰€å½“ç„¶ï¼šå¤§è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒè®¾è®¡å†³ç­–",
      "authors": [
        "Sawsan Alqahtani",
        "Mir Tafseer Nayeem",
        "Md Tahmid Rahman Laskar",
        "Tasnim Mohiuddin",
        "M Saiful Bari"
      ],
      "abstract": "Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‘æˆ˜äº†å°† Tokenization ä»…è§†ä¸ºé¢„å¤„ç†æ­¥éª¤çš„ä¼ ç»Ÿè§‚ç‚¹ï¼Œä¸»å¼ å°†å…¶ä½œä¸º Large Language Models (LLMs) çš„æ ¸å¿ƒå»ºæ¨¡å†³ç­–ã€‚è®ºæ–‡æŒ‡å‡º Byte Pair Encoding (BPE) ç­‰ä¸»æµå­è¯æ–¹æ¡ˆåœ¨è¯­è¨€å­¦å¯¹é½ã€åå·®æ”¾å¤§åŠè·¨è¯­è¨€å®¹é‡åˆ†é…ä¸Šå­˜åœ¨å±€é™ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ª Context-aware æ¡†æ¶ï¼Œä¸»å¼ ç»“åˆè¯­è¨€å­¦ã€ç‰¹å®šé¢†åŸŸåŠéƒ¨ç½²éœ€æ±‚ï¼Œå®ç° Tokenizer ä¸æ¨¡å‹çš„ååŒè®¾è®¡ (Co-design)ã€‚é€šè¿‡å¼ºè°ƒæ ‡å‡†åŒ–è¯„ä¼°å’Œé€æ˜æŠ¥å‘Šï¼Œè¯¥ç ”ç©¶æ—¨åœ¨å°† Tokenization è§†ä¸ºæ ¸å¿ƒè®¾è®¡é—®é¢˜ï¼Œä»è€Œå¼€å‘å‡ºæ›´å…¬å¹³ã€é«˜æ•ˆä¸”å…·é€‚åº”æ€§çš„è¯­è¨€æŠ€æœ¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EACL 2026 (long, main). The first two authors contributed equally",
      "pdf_url": "https://arxiv.org/pdf/2601.13260v1",
      "published_date": "2026-01-19 17:50:36 UTC",
      "updated_date": "2026-01-19 17:50:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:11.427801+00:00"
    },
    {
      "arxiv_id": "2601.13247v1",
      "title": "Aligning Agentic World Models via Knowledgeable Experience Learning",
      "title_zh": "é€šè¿‡çŸ¥è¯†æ€§ç»éªŒå­¦ä¹ å¯¹é½æ™ºèƒ½ä½“ä¸–ç•Œæ¨¡å‹",
      "authors": [
        "Baochang Ren",
        "Yunzhi Yao",
        "Rui Sun",
        "Shuofei Qiao",
        "Ningyu Zhang",
        "Huajun Chen"
      ],
      "abstract": "Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç‰©ç†ä¸–ç•Œæ¨¡æ‹Ÿä¸­å­˜åœ¨çš„â€œç‰©ç†å¹»è§‰â€ï¼ˆphysical hallucinationsï¼‰é—®é¢˜ï¼Œæå‡ºäº† WorldMind æ¡†æ¶ã€‚WorldMind é€šè¿‡è‡ªä¸»æ„å»ºç¬¦å·åŒ–çš„ World Knowledge Repositoryï¼ˆä¸–ç•ŒçŸ¥è¯†åº“ï¼‰ï¼Œå°†ç¯å¢ƒåé¦ˆè½¬åŒ–ä¸ºå¯å­¦ä¹ çš„ç»éªŒï¼Œæœ‰æ•ˆå¼¥åˆäº†è¯­ä¹‰çŸ¥è¯†ä¸ç‰©ç†è§„å¾‹ä¹‹é—´çš„é¸¿æ²Ÿã€‚è¯¥æ¡†æ¶æ•´åˆäº† Process Experience ä»¥é€šè¿‡é¢„æµ‹è¯¯å·®ç¡®ä¿ç‰©ç†å¯è¡Œæ€§ï¼Œå¹¶åˆ©ç”¨ Goal Experience å¼•å¯¼ä»»åŠ¡çš„æœ€ä¼˜æ‰§è¡Œè·¯å¾„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWorldMind åœ¨ EB-ALFRED å’Œ EB-Habitat åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œå¹¶å±•ç°å‡ºå“è¶Šçš„è·¨æ¨¡å‹ä¸è·¨ç¯å¢ƒè¿ç§»èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "Ongoing work",
      "pdf_url": "https://arxiv.org/pdf/2601.13247v1",
      "published_date": "2026-01-19 17:33:31 UTC",
      "updated_date": "2026-01-19 17:33:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:13.570867+00:00"
    },
    {
      "arxiv_id": "2601.13240v1",
      "title": "KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?",
      "title_zh": "KOCO-BENCHï¼šå¤§è¯­è¨€æ¨¡å‹èƒ½å¦åˆ©ç”¨è½¯ä»¶å¼€å‘ä¸­çš„é¢†åŸŸçŸ¥è¯†ï¼Ÿ",
      "authors": [
        "Xue Jiang",
        "Jiaru Qian",
        "Xianjie Shi",
        "Chenjie Li",
        "Hao Zhu",
        "Ziyu Wang",
        "Jielun Zhang",
        "Zheyu Zhao",
        "Kechi Zhang",
        "Jia Li",
        "Wenpin Jiao",
        "Zhi Jin",
        "Ge Li",
        "Yihong Dong"
      ],
      "abstract": "Large language models (LLMs) excel at general programming but struggle with domain-specific software development, necessitating domain specialization methods for LLMs to learn and utilize domain knowledge and data. However, existing domain-specific code benchmarks cannot evaluate the effectiveness of domain specialization methods, which focus on assessing what knowledge LLMs possess rather than how they acquire and apply new knowledge, lacking explicit knowledge corpora for developing domain specialization methods. To this end, we present KOCO-BENCH, a novel benchmark designed for evaluating domain specialization methods in real-world software development. KOCO-BENCH contains 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora alongside multi-granularity evaluation tasks including domain code generation (from function-level to project-level with rigorous test suites) and domain knowledge understanding (via multiple-choice Q&A). Unlike previous benchmarks that only provide test sets for direct evaluation, KOCO-BENCH requires acquiring and applying diverse domain knowledge (APIs, rules, constraints, etc.) from knowledge corpora to solve evaluation tasks. Our evaluations reveal that KOCO-BENCH poses significant challenges to state-of-the-art LLMs. Even with domain specialization methods (e.g., SFT, RAG, kNN-LM) applied, improvements remain marginal. Best-performing coding agent, Claude Code, achieves only 34.2%, highlighting the urgent need for more effective domain specialization methods. We release KOCO-BENCH, evaluation code, and baselines to advance further research at https://github.com/jiangxxxue/KOCO-bench.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† KOCO-BENCHï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨çœŸå®è½¯ä»¶å¼€å‘ä¸­åˆ©ç”¨é¢†åŸŸçŸ¥è¯†èƒ½åŠ›çš„æ–°å‹åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†æ¶µç›–äº† 6 ä¸ªæ–°å…´é¢†åŸŸçš„ 11 ä¸ªæ¡†æ¶å’Œ 25 ä¸ªé¡¹ç›®ï¼Œæä¾›äº†ç²¾å¿ƒç­–åˆ’çš„çŸ¥è¯†è¯­æ–™åº“ (knowledge corpora) ä»¥åŠæ¶µç›–é¢†åŸŸä»£ç ç”Ÿæˆå’ŒçŸ¥è¯†ç†è§£çš„å¤šç²’åº¦è¯„ä¼°ä»»åŠ¡ã€‚ä¸ä»¥å¾€ä»…æä¾›æµ‹è¯•é›†çš„åŸºå‡†ä¸åŒï¼ŒKOCO-BENCH è¦æ±‚æ¨¡å‹å¿…é¡»ä»è¯­æ–™åº“ä¸­è·å–å¹¶åº”ç”¨ APIã€è§„åˆ™å’Œçº¦æŸç­‰çŸ¥è¯†æ¥è§£å†³å®é™…é—®é¢˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿é‡‡ç”¨äº† SFTã€RAG å’Œ kNN-LM ç­‰é¢†åŸŸä¸“ä¸šåŒ– (domain specialization) æ–¹æ³•ï¼Œç°æœ‰ SOTA æ¨¡å‹å’Œç¼–ç æ™ºèƒ½ä½“ï¼ˆå¦‚ Claude Codeï¼‰çš„è¡¨ç°ä¾ç„¶ä¸å°½å¦‚äººæ„ï¼Œæœ€é«˜å‡†ç¡®ç‡ä»…ä¸º 34.2%ï¼Œå‡¸æ˜¾äº†å¼€å‘æ›´æœ‰æ•ˆçš„é¢†åŸŸä¸“ä¸šåŒ–æ–¹æ³•çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13240v1",
      "published_date": "2026-01-19 17:20:16 UTC",
      "updated_date": "2026-01-19 17:20:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:16.015089+00:00"
    },
    {
      "arxiv_id": "2601.13238v1",
      "title": "A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models",
      "title_zh": "åŸºäºè¯­ä¹‰è§£è€¦çš„ä¸¤é˜¶æ®µé›¨å¤©æ”»å‡»ï¼šæ­ç¤ºè§†è§‰è¯­è¨€æ¨¡å‹çš„å¤©æ°”é²æ£’æ€§ç¼ºé™·",
      "authors": [
        "Chengyin Hu",
        "Xiang Chen",
        "Zhe Jia",
        "Weiwen Shi",
        "Fengyu Zhang",
        "Jiujiang Guo",
        "Yiwei Wei"
      ],
      "abstract": "Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models, VLMs)åœ¨çœŸå®å¤©æ°”æ¡ä»¶ä¸‹çš„é²æ£’æ€§ï¼Œå¹¶æå‡ºäº†é¦–ä¸ªåŸºäºé›¨å¤©åœºæ™¯çš„å¯¹æŠ—æ”»å‡»æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ä¸€ç§åŸºäºè¯­ä¹‰è§£è€¦(semantic decoupling)çš„ä¸¤é˜¶æ®µå‚æ•°åŒ–æ‰°åŠ¨æ¨¡å‹ï¼šç¬¬ä¸€é˜¶æ®µé€šè¿‡ä½ç»´å…¨å±€è°ƒåˆ¶å‰Šå¼±åŸå§‹è¯­ä¹‰å†³ç­–è¾¹ç•Œï¼›ç¬¬äºŒé˜¶æ®µé€šè¿‡æ¨¡æ‹Ÿå¤šå°ºåº¦é›¨æ»´å’Œå…‰ç…§å˜åŒ–ï¼Œåœ¨éåƒç´ å‚æ•°ç©ºé—´ä¸­è¯±å¯¼ç¨³å®šçš„è¯­ä¹‰åç§»(semantic shifts)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿æ˜¯å—åˆ°ä¸¥æ ¼çº¦æŸä¸”ç¬¦åˆç‰©ç†é€»è¾‘çš„é™é›¨æ‰°åŠ¨ï¼Œä¹Ÿèƒ½å¯¼è‡´ä¸»æµVLMsäº§ç”Ÿæ˜¾è‘—çš„è¯­ä¹‰é”™ä½(semantic misalignment)ï¼Œæš´éœ²å‡ºæ¨¡å‹åœ¨å®é™…éƒ¨ç½²ä¸­çš„å®‰å…¨éšæ‚£ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼Œå…‰ç…§å»ºæ¨¡å’Œå¤šå°ºåº¦é›¨æ»´ç»“æ„æ˜¯å¼•å‘æ­¤ç±»è¯­ä¹‰åç§»çš„æ ¸å¿ƒå› ç´ ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13238v1",
      "published_date": "2026-01-19 17:16:30 UTC",
      "updated_date": "2026-01-19 17:16:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:27.186651+00:00"
    },
    {
      "arxiv_id": "2601.13236v1",
      "title": "Pixelwise Uncertainty Quantification of Accelerated MRI Reconstruction",
      "title_zh": "åŠ é€Ÿ MRI é‡å»ºçš„åƒç´ çº§ä¸ç¡®å®šæ€§é‡åŒ–",
      "authors": [
        "Ilias I. Giannakopoulos",
        "Lokesh B Gautham Muthukumar",
        "Yvonne W. Lui",
        "Riccardo Lattanzi"
      ],
      "abstract": "Parallel imaging techniques reduce magnetic resonance imaging (MRI) scan time but image quality degrades as the acceleration factor increases. In clinical practice, conservative acceleration factors are chosen because no mechanism exists to automatically assess the diagnostic quality of undersampled reconstructions. This work introduces a general framework for pixel-wise uncertainty quantification in parallel MRI reconstructions, enabling automatic identification of unreliable regions without access to any ground-truth reference image. Our method integrates conformal quantile regression with image reconstruction methods to estimate statistically rigorous pixel-wise uncertainty intervals. We trained and evaluated our model on Cartesian undersampled brain and knee data obtained from the fastMRI dataset using acceleration factors ranging from 2 to 10. An end-to-end Variational Network was used for image reconstruction. Quantitative experiments demonstrate strong agreement between predicted uncertainty maps and true reconstruction error. Using our method, the corresponding Pearson correlation coefficient was higher than 90% at acceleration levels at and above four-fold; whereas it dropped to less than 70% when the uncertainty was computed using a simpler a heuristic notion (magnitude of the residual). Qualitative examples further show the uncertainty maps based on quantile regression capture the magnitude and spatial distribution of reconstruction errors across acceleration factors, with regions of elevated uncertainty aligning with pathologies and artifacts. The proposed framework enables evaluation of reconstruction quality without access to fully-sampled ground-truth reference images. It represents a step toward adaptive MRI acquisition protocols that may be able to dynamically balance scan time and diagnostic reliability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠ é€Ÿç£å…±æŒ¯æˆåƒ(MRI)é‡å»ºè´¨é‡éš¾ä»¥è‡ªåŠ¨è¯„ä¼°çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é€šç”¨çš„åƒç´ çº§ä¸ç¡®å®šæ€§é‡åŒ–(Pixelwise Uncertainty Quantification)æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†ç¬¦åˆåˆ†ä½æ•°å›å½’(Conformal Quantile Regression)ä¸ç«¯åˆ°ç«¯å˜åˆ†ç½‘ç»œ(End-to-End Variational Network)ç›¸ç»“åˆï¼Œåœ¨æ— éœ€çœŸå€¼å‚è€ƒå›¾åƒçš„æƒ…å†µä¸‹å³å¯ä¼°ç®—ç»Ÿè®¡ä¸¥è°¨çš„åƒç´ çº§ä¸ç¡®å®šæ€§åŒºé—´ã€‚åœ¨fastMRIæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„ä¸ç¡®å®šæ€§å›¾ä¸å®é™…é‡å»ºè¯¯å·®é«˜åº¦ä¸€è‡´ï¼Œåœ¨4å€åŠä»¥ä¸ŠåŠ é€Ÿå› å­ä¸‹çš„çš®å°”é€Šç›¸å…³ç³»æ•°è¶…è¿‡90%ï¼Œæ˜¾è‘—ä¼˜äºå¯å‘å¼æ®‹å·®æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘èƒ½å¤ŸåŠ¨æ€å¹³è¡¡æ‰«ææ—¶é—´ä¸è¯Šæ–­å¯é æ€§çš„è‡ªé€‚åº”MRIé‡‡é›†åè®®å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 8 figues, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.13236v1",
      "published_date": "2026-01-19 17:12:28 UTC",
      "updated_date": "2026-01-19 17:12:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:31.728089+00:00"
    },
    {
      "arxiv_id": "2601.13235v1",
      "title": "RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions",
      "title_zh": "RubRIXï¼šçœ‹æŠ¤è€…-AIäº¤äº’ä¸­åŸºäºè¯„ä»·é‡è¡¨çš„é£é™©ç¼“è§£",
      "authors": [
        "Drishti Goel",
        "Jeongah Lee",
        "Qiuyue Joy Zhong",
        "Violeta J. Rodriguez",
        "Daniel S. Brown",
        "Ravi Karkar",
        "Dong Whi Yoo",
        "Koustuv Saha"
      ],
      "abstract": "Caregivers seeking AI-mediated support express complex needs -- information-seeking, emotional validation, and distress cues -- that warrant careful evaluation of response safety and appropriateness. Existing AI evaluation frameworks, primarily focused on general risks (toxicity, hallucinations, policy violations, etc), may not adequately capture the nuanced risks of LLM-responses in caregiving-contexts. We introduce RubRIX (Rubric-based Risk Index), a theory-driven, clinician-validated framework for evaluating risks in LLM caregiving responses. Grounded in the Elements of an Ethic of Care, RubRIX operationalizes five empirically-derived risk dimensions: Inattention, Bias & Stigma, Information Inaccuracy, Uncritical Affirmation, and Epistemic Arrogance. We evaluate six state-of-the-art LLMs on over 20,000 caregiver queries from Reddit and ALZConnected. Rubric-guided refinement consistently reduced risk-components by 45-98% after one iteration across models. This work contributes a methodological approach for developing domain-sensitive, user-centered evaluation frameworks for high-burden contexts. Our findings highlight the importance of domain-sensitive, interactional risk evaluation for the responsible deployment of LLMs in caregiving support contexts. We release benchmark datasets to enable future research on contextual risk evaluation in AI-mediated support.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RubRIX (Rubric-based Risk Index)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”±ç†è®ºé©±åŠ¨å¹¶ç»ä¸´åºŠéªŒè¯çš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è¯†åˆ«å’Œç¼“è§£å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æŠ¤ç†æ”¯æŒåœºæ™¯ä¸­ç‰¹æœ‰çš„äº¤äº’é£é™©ã€‚è¯¥æ¡†æ¶åŸºäºå…³æ€€ä¼¦ç†å­¦ (Ethic of Care) ç†è®ºï¼Œé‡åŒ–äº†äº”ä¸ªå…³é”®é£é™©ç»´åº¦ï¼šç–å¿½ (Inattention)ã€åè§ä¸æ±¡å (Bias & Stigma)ã€ä¿¡æ¯ä¸å‡†ç¡® (Information Inaccuracy)ã€ç›²ç›®è‚¯å®š (Uncritical Affirmation) å’Œè®¤çŸ¥å‚²æ…¢ (Epistemic Arrogance)ã€‚é€šè¿‡å¯¹å…­ç§å…ˆè¿› LLMs åœ¨è¶…è¿‡ 20,000 æ¡çœŸå®æŠ¤ç†è€…æŸ¥è¯¢ä¸Šçš„è¯„ä¼°ï¼Œå®éªŒè¯æ˜åŸºäºè¯¥å‡†åˆ™çš„è¿­ä»£æ”¹è¿›èƒ½å°†å„æ¨¡å‹çš„é£é™©æˆåˆ†æ˜¾è‘—é™ä½ 45-98%ã€‚è¯¥ç ”ç©¶ä¸ºé«˜è´Ÿæ‹…ã€é«˜é£é™©é¢†åŸŸå¼€å‘é¢†åŸŸæ•æ„Ÿ (domain-sensitive) ä¸”ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„ AI è¯„ä¼°ä½“ç³»æä¾›äº†é‡è¦çš„æ–¹æ³•è®ºå‚è€ƒï¼Œå¹¶å‘å¸ƒäº†ç›¸å…³åŸºå‡†æ•°æ®é›†ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13235v1",
      "published_date": "2026-01-19 17:10:49 UTC",
      "updated_date": "2026-01-19 17:10:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:33.604050+00:00"
    },
    {
      "arxiv_id": "2601.13233v1",
      "title": "RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements",
      "title_zh": "RAGï¼šé¢å‘å¤æ‚åŠŸèƒ½å“åº”éœ€æ±‚è¶…ææ–™ä¸ç¡®å®šæ€§æ„ŸçŸ¥è®¾è®¡çš„åŸºäºéšæœºæ£®æ—çš„ç”Ÿæˆå¼è®¾è®¡æ¡†æ¶",
      "authors": [
        "Bolin Chen",
        "Dex Doksoo Lee",
        "Wei \"Wayne'' Chen",
        "Wei Chen"
      ],
      "abstract": "Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RAndom-forest-based Generative approach (RAG) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è¶…ææ–™ (Metamaterials) åœ¨å¤„ç†é«˜ç»´ã€éçº¿æ€§åŠŸèƒ½å“åº” (Functional Responses) æ—¶ï¼Œä¼ ç»Ÿç”Ÿæˆå¼è®¾è®¡é¢ä¸´çš„æ•°æ®éœ€æ±‚é«˜å’Œç¼ºä¹ä¸ç¡®å®šæ€§é‡åŒ–ç­‰æŒ‘æˆ˜ã€‚RAG åˆ©ç”¨éšæœºæ£®æ— (Random Forest) çš„å°æ ·æœ¬å…¼å®¹æ€§å®ç°é«˜æ•ˆé¢„æµ‹ï¼Œé€šè¿‡é›†æˆå­¦ä¹ ä¼°è®¡ä¼¼ç„¶åº¦ä»¥è¯„ä¼°ç”Ÿæˆè®¾è®¡çš„å¯ä¿¡åº¦ï¼Œå¹¶æœ‰æ•ˆå¤„ç†äº†é€†å‘è®¾è®¡ä¸­çš„ä¸€å¯¹å¤šæ˜ å°„é—®é¢˜ã€‚å®éªŒåœ¨å£°å­¦è¶…ææ–™çš„é¢‘å¸¦è®¾è®¡ä»¥åŠå…·æœ‰ç‰¹å®šæ•æ‰å“åº” (Snap-through responses) çš„åŠ›å­¦è¶…ææ–™ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼Œç›¸æ¯”ç¥ç»ç½‘ç»œï¼ŒRAG å…·æœ‰æ˜¾è‘—çš„æ•°æ®æ•ˆç‡ä¼˜åŠ¿ï¼Œä¸ºæ¶‰åŠæ˜‚è´µæ¨¡æ‹Ÿå’Œå¤æ‚åŠŸèƒ½è¦æ±‚çš„é€†å‘è®¾è®¡æä¾›äº†ä¸€ç§è½»é‡åŒ–ä¸”å¯é çš„é€šç”¨æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13233v1",
      "published_date": "2026-01-19 17:06:12 UTC",
      "updated_date": "2026-01-19 17:06:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:39.037523+00:00"
    },
    {
      "arxiv_id": "2601.13228v1",
      "title": "Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation",
      "title_zh": "è‡ªå›å½’æ¨¡å‹åœ¨ä»»æ„é¡ºåºç”Ÿæˆä¸­åª²ç¾æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Tianqi Du",
        "Lizhe Fang",
        "Weijie Yang",
        "Chenheng Zhang",
        "Zeming Wei",
        "Yifei Wang",
        "Yisen Wang"
      ],
      "abstract": "Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Any-order Any-subset Autoregressive modeling (A3)æ¡†æ¶ï¼Œæ—¨åœ¨å…‹æœæ‰©æ•£æ¨¡å‹ (Diffusion models) åœ¨é‡‡æ ·è´¨é‡ä¸ç¨³å®šæ€§ä¸Šçš„å±€é™ï¼ŒåŒæ—¶ä¿ç•™å…¶ä»»æ„é¡ºåºç”Ÿæˆçš„çµæ´»æ€§ã€‚A3å°†æ‰©æ•£é£æ ¼çš„è®­ç»ƒé‡æ„ä¸ºç»“æ„åŒ–çš„å¤šç»„é¢„æµ‹è¿‡ç¨‹ï¼Œé€šè¿‡åŒæµæ³¨æ„åŠ›æ¶æ„ (two-stream attention architecture) å’Œæ¸è¿›å¼é€‚é…ç­–ç•¥ï¼Œä½¿é¢„è®­ç»ƒçš„è‡ªå›å½’æ¨¡å‹ (Autoregressive models) èƒ½å¤Ÿæ”¯æŒä»»æ„Tokenåˆ†ç»„å’Œç”Ÿæˆé¡ºåºã€‚è¯¥æ–¹æ³•åœ¨ä¿ç•™ARæ¨¡å‹æ¦‚ç‡ä¸¥è°¨æ€§å’Œå¤šå±‚ä¾èµ–å»ºæ¨¡ä¼˜åŠ¿çš„åŸºç¡€ä¸Šï¼Œå¼•å…¥äº†æ‰©æ•£æ¨¡å‹çš„å¹¶è¡Œä¸åŒå‘ç”Ÿæˆèƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼ŒA3åœ¨é—®ç­”ã€å¸¸è¯†æ¨ç†å’Œæ•…äº‹å¡«å……ç­‰ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜äºåŸºäºæ‰©æ•£çš„æ¨¡å‹ï¼Œä¸ºçµæ´»é«˜æ•ˆçš„è¯­è¨€æ¨¡å‹èŒƒå¼æä¾›äº†ç»Ÿä¸€çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13228v1",
      "published_date": "2026-01-19 17:03:48 UTC",
      "updated_date": "2026-01-19 17:03:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:40.928934+00:00"
    },
    {
      "arxiv_id": "2601.13227v1",
      "title": "Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?",
      "title_zh": "å†…éƒ¨æƒ…æŠ¥ï¼šRAG ç³»ç»Ÿèƒ½ä»è¯„ä¼°â€œç§˜è¾›â€ä¸­è·ç›Šå‡ ä½•ï¼Ÿ",
      "authors": [
        "Laura Dietz",
        "Bryan Li",
        "Eugene Yang",
        "Dawn Lawrie",
        "William Walden",
        "James Mayfield"
      ],
      "abstract": "RAG systems are increasingly evaluated and optimized using LLM judges, an approach that is rapidly becoming the dominant paradigm for system assessment. Nugget-based approaches in particular are now embedded not only in evaluation frameworks but also in the architectures of RAG systems themselves. While this integration can lead to genuine improvements, it also creates a risk of faulty measurements due to circularity. In this paper, we investigate this risk through comparative experiments with nugget-based RAG systems, including Ginger and Crucible, against strong baselines such as GPT-Researcher. By deliberately modifying Crucible to generate outputs optimized for an LLM judge, we show that near-perfect evaluation scores can be achieved when elements of the evaluation - such as prompt templates or gold nuggets - are leaked or can be predicted. Our results highlight the importance of blind evaluation settings and methodological diversity to guard against mistaking metric overfitting for genuine system progress.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨åˆ©ç”¨ LLM judges è¯„ä¼°å’Œä¼˜åŒ– RAG ç³»ç»Ÿæ—¶ï¼Œç”±äºè¯„ä¼°æ¡†æ¶ï¼ˆç‰¹åˆ«æ˜¯åŸºäº nugget çš„æ–¹æ³•ï¼‰ä¸ç³»ç»Ÿæ¶æ„é«˜åº¦é›†æˆè€Œå¯¼è‡´çš„å¾ªç¯æ€§é£é™©å’Œåº¦é‡åå·®ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å¯¹ Ginger å’Œ Crucible ç­‰ç³»ç»Ÿè¿›è¡Œå¯¹æ¯”å®éªŒï¼Œå¹¶ä»¥ GPT-Researcher ä¸ºåŸºçº¿ï¼Œæ­ç¤ºäº†å½“è¯„ä¼°è¦ç´ ï¼ˆå¦‚ prompt templates æˆ– gold nuggetsï¼‰è¢«æ³„éœ²æˆ–é¢„æµ‹æ—¶ï¼Œç³»ç»Ÿå¯ä»¥è·å¾—æ¥è¿‘å®Œç¾çš„è¯„åˆ†ã€‚è¿™ç§ç°è±¡è¡¨æ˜ï¼Œå½“å‰çš„è¯„ä¼°ç»“æœå¯èƒ½æ›´å¤šåœ°åæ˜ äº† metric overfittingï¼ˆæŒ‡æ ‡æ‹Ÿåˆï¼‰ï¼Œè€ŒéçœŸæ­£çš„æŠ€æœ¯è¿›æ­¥ã€‚è¯¥è®ºæ–‡å¼ºè°ƒäº† blind evaluation è®¾ç½®å’Œè¯„ä¼°æ–¹æ³•å¤šæ ·æ€§çš„å¿…è¦æ€§ï¼Œä»¥ç¡®ä¿ RAG ç³»ç»Ÿè¯„ä¼°çš„çœŸå®æ€§ä¸å¯é æ€§ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13227v1",
      "published_date": "2026-01-19 17:03:20 UTC",
      "updated_date": "2026-01-19 17:03:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:42.104634+00:00"
    },
    {
      "arxiv_id": "2601.13222v1",
      "title": "Incorporating Q&A Nuggets into Retrieval-Augmented Generation",
      "title_zh": "å°†é—®ç­”ç²¾è¦æ•´åˆè‡³æ£€ç´¢å¢å¼ºç”Ÿæˆ",
      "authors": [
        "Laura Dietz",
        "Bryan Li",
        "Gabrielle Liu",
        "Jia-Huei Ju",
        "Eugene Yang",
        "Dawn Lawrie",
        "William Walden",
        "James Mayfield"
      ],
      "abstract": "RAGE systems integrate ideas from automatic evaluation (E) into Retrieval-augmented Generation (RAG). As one such example, we present Crucible, a Nugget-Augmented Generation System that preserves explicit citation provenance by constructing a bank of Q&A nuggets from retrieved documents and uses them to guide extraction, selection, and report generation. Reasoning on nuggets avoids repeated information through clear and interpretable Q&A semantics - instead of opaque cluster abstractions - while maintaining citation provenance throughout the entire generation process. Evaluated on the TREC NeuCLIR 2024 collection, our Crucible system substantially outperforms Ginger, a recent nugget-based RAG system, in nugget recall, density, and citation grounding.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Crucibleï¼Œä¸€ç§å°† Q&A nuggets èå…¥æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-augmented Generation, RAG) çš„ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡æ„å»º Q&A åº“æ¥å¼•å¯¼ä¿¡æ¯çš„æå–ã€é€‰æ‹©å’ŒæŠ¥å‘Šç”Ÿæˆã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨æ¸…æ™°ä¸”å…·å¤‡å¯è§£é‡Šæ€§çš„ Q&A semantics ä»£æ›¿æ¨¡ç³Šçš„èšç±»æŠ½è±¡ï¼Œåœ¨æœ‰æ•ˆé¿å…é‡å¤ä¿¡æ¯çš„åŒæ—¶ï¼Œç¡®ä¿äº†æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹å…·å¤‡æ˜ç¡®çš„å¼•ç”¨æº¯æº (citation provenance)ã€‚åœ¨ TREC NeuCLIR 2024 æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCrucible åœ¨ nugget recallã€density ä»¥åŠå¼•ç”¨æ¥åœ° (citation grounding) æ–¹é¢æ˜¾è‘—ä¼˜äºè¿‘æœŸçš„ nugget-based RAG ç³»ç»Ÿ Gingerã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13222v1",
      "published_date": "2026-01-19 16:57:33 UTC",
      "updated_date": "2026-01-19 16:57:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:43.950583+00:00"
    },
    {
      "arxiv_id": "2601.13217v1",
      "title": "Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision",
      "title_zh": "è¶…è¶Šå•æ¬¡å†™ä½œï¼šæ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“åœ¨å¤šè½®æŠ¥å‘Šä¿®è®¢ä¸­çš„ä¸å¯é æ€§ç ”ç©¶",
      "authors": [
        "Bingsen Chen",
        "Boyan Li",
        "Ping Nie",
        "Yuyu Zhang",
        "Xi Ye",
        "Chen Zhao"
      ],
      "abstract": "Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ (Deep Research Agents, DRAs) åœ¨å¤šè½®æŠ¥å‘Šä¿®è®¢ä¸­çš„å¯é æ€§ï¼ŒæŒ‡å‡ºå½“å‰çš„è¯„ä¼°åŸºå‡†é€šå¸¸å°†æŠ¥å‘Šç”Ÿæˆè§†ä¸ºå•æ¬¡å†™ä½œä»»åŠ¡ï¼Œå¿½ç•¥äº†äººç±»ç ”ç©¶ä¸­å¸¸è§çš„è¿­ä»£ä¿®è®¢è¿‡ç¨‹ã€‚ä¸ºæ­¤ï¼Œä½œè€…æ¨å‡ºäº†è¯„ä¼°å¥—ä»¶ Mr Dreï¼ŒåŒ…å«äº†ä¸€å¥—æ¶µç›–å…¨é¢æ€§ã€äº‹å®æ€§å’Œé™ˆè¿°è´¨é‡çš„é•¿ç¯‡æŠ¥å‘Šè¯„ä¼°åè®®ï¼Œä»¥åŠä¸€ä¸ªç»è¿‡äººç±»éªŒè¯çš„åé¦ˆæ¨¡æ‹Ÿç®¡é“ã€‚åˆ†æç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶ DRAs èƒ½å¤Ÿå“åº”ç”¨æˆ·åé¦ˆï¼Œä½†ä¼šåœ¨ 16-27% çš„æ—¢æœ‰å†…å®¹å’Œå¼•ç”¨è´¨é‡ä¸Šå‡ºç°æ€§èƒ½é€€åŒ–ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå³ä½¿æ˜¯è¡¨ç°æœ€ä½³çš„æ™ºèƒ½ä½“åœ¨å¤šè½®ä¿®è®¢ä¸­ä¹Ÿä¼šå¹²æ‰°åé¦ˆèŒƒå›´å¤–çš„å†…å®¹ï¼Œä¸”éš¾ä»¥é€šè¿‡æç¤ºå·¥ç¨‹ (Prompt Engineering) æˆ–è®¾ç«‹ä¸“é—¨çš„ä¿®è®¢å­æ™ºèƒ½ä½“æ¥ä¿®å¤ã€‚è¯¥å·¥ä½œæ­ç¤ºäº†å½“å‰ DRAs åœ¨ç»´æŒé•¿æ–‡æ¡£ä¸€è‡´æ€§å’Œå“åº”è¿­ä»£åé¦ˆæ–¹é¢çš„æ˜¾è‘—å±€é™æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13217v1",
      "published_date": "2026-01-19 16:48:45 UTC",
      "updated_date": "2026-01-19 16:48:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:52.440098+00:00"
    },
    {
      "arxiv_id": "2601.13206v1",
      "title": "Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues",
      "title_zh": "å®æ—¶æ—¶é™æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹ç­–ç•¥æ€§å¯¹è¯ä¸­çš„æ—¶é—´æ„ŸçŸ¥ç¼ºé™·",
      "authors": [
        "Neil K. R. Sehgal",
        "Sharath Chandra Guntuku",
        "Lyle Ungar"
      ],
      "abstract": "Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\\% vs. 4\\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\\geq$95\\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é¢ä¸´å®æ—¶æˆªæ­¢æ—¥æœŸï¼ˆreal-time deadlinesï¼‰æ—¶çš„å†³ç­–è¡Œä¸ºï¼Œæ­ç¤ºäº†å®ƒä»¬åœ¨è¿ç»­æ—¶é—´æ„ŸçŸ¥æ–¹é¢çš„ç³»ç»Ÿæ€§ç¼ºé™·ã€‚é€šè¿‡åœ¨æ¨¡æ‹Ÿè°ˆåˆ¤ä»»åŠ¡ä¸­å¯¹æ¯”ä»…å‘ŠçŸ¥å…¨å±€æ—¶é™ä¸å®æ—¶æ›´æ–°å‰©ä½™æ—¶é—´ï¼ˆtime-aware conditionï¼‰çš„è¡¨ç°ï¼Œç ”ç©¶å‘ç°æä¾›æ˜¾å¼æ—¶é—´åé¦ˆèƒ½æ˜¾è‘—æé«˜æˆäº¤ç‡ï¼ˆdeal closure ratesï¼‰ï¼Œä¾‹å¦‚ GPT-5.1 çš„æˆäº¤ç‡ä» 4% æå‡è‡³ 32%ã€‚ç”±äºè¿™äº›æ¨¡å‹åœ¨åŸºäºå›åˆçš„é™åˆ¶ï¼ˆturn-based limitsï¼‰ä¸‹èƒ½è¾¾åˆ°è¿‘ä¹å®Œç¾çš„æˆäº¤ç‡ï¼Œå®éªŒè¯æ˜å…¶å¤±è´¥æ ¹æºåœ¨äºæ— æ³•åœ¨å†…éƒ¨è¿½è¸ªç»è¿‡çš„æ—¶é—´ï¼ˆtemporal trackingï¼‰ï¼Œè€Œéç¼ºä¹ç­–ç•¥æ€§æ¨ç†èƒ½åŠ›ã€‚è¿™ä¸€å‘ç°è¡¨æ˜ LLMs åœ¨éœ€è¦ç²¾å‡†æ—¶é—´æ„è¯†çš„å®æ—¶åº”ç”¨éƒ¨ç½²ä¸­ä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13206v1",
      "published_date": "2026-01-19 16:31:07 UTC",
      "updated_date": "2026-01-19 16:31:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:51.072035+00:00"
    },
    {
      "arxiv_id": "2601.13197v1",
      "title": "Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification",
      "title_zh": "æ‰©æ•£é©±åŠ¨çš„åˆæˆè¡¨æ ¼æ•°æ®ç”Ÿæˆï¼Œç”¨äºå¢å¼º DoS/DDoS æ”»å‡»åˆ†ç±»",
      "authors": [
        "Aravind B",
        "Anirud R. S.",
        "Sai Surya Teja N",
        "Bala Subrahmanya Sriranga Navaneeth A",
        "Karthika R",
        "Mohankumar N"
      ],
      "abstract": "Class imbalance refers to a situation where certain classes in a dataset have significantly fewer samples than oth- ers, leading to biased model performance. Class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM) for data augmentation is ad- dressed in this paper. Our approach synthesizes high-fidelity minority-class samples from the CIC-IDS2017 dataset through iterative denoising processes. For the minority classes that have smaller samples, synthetic samples were generated and merged with the original dataset. The augmented training data enables an ANN classifier to achieve near-perfect recall on previously underrepresented attack classes. These results establish diffusion models as an effective solution for tabular data imbalance in security domains, with potential applications in fraud detection and medical diagnostics.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºè¡¨æ ¼å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ (TabDDPM) çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç½‘ç»œå…¥ä¾µæ£€æµ‹ä¸­å› ç±»åˆ«ä¸å¹³è¡¡ (Class imbalance) å¯¼è‡´çš„æ¨¡å‹æ€§èƒ½åå·®ã€‚è¯¥æ–¹æ³•åˆ©ç”¨è¿­ä»£å»å™ªè¿‡ç¨‹ä» CIC-IDS2017 æ•°æ®é›†ä¸­åˆæˆé«˜ä¿çœŸçš„å°‘æ•°ç±»æ ·æœ¬ï¼Œå¹¶å°†å…¶ä¸åŸå§‹æ•°æ®åˆå¹¶ä»¥å¢å¼ºè®­ç»ƒé›†ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆä½¿äººå·¥ç¥ç»ç½‘ç»œ (ANN) åˆ†ç±»å™¨åœ¨åŸæœ¬ä»£è¡¨æ€§ä¸è¶³çš„æ”»å‡»ç±»åˆ«ä¸Šå®ç°äº†æ¥è¿‘å®Œç¾çš„å¬å›ç‡ (Recall)ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†æ‰©æ•£æ¨¡å‹ (Diffusion Models) åœ¨å¤„ç†å®‰å…¨é¢†åŸŸè¡¨æ ¼æ•°æ®ä¸å¹³è¡¡æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å±•ç°äº†å…¶åœ¨æ¬ºè¯ˆæ£€æµ‹å’ŒåŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 8 figures, 2025 International Conference on Signal Processing, Computation, Electronics, Power and Telecommunication (IConSCEPT), National Institute of Technology, Puducherry, India",
      "pdf_url": "https://arxiv.org/pdf/2601.13197v1",
      "published_date": "2026-01-19 16:22:27 UTC",
      "updated_date": "2026-01-19 16:22:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:39:52.706514+00:00"
    },
    {
      "arxiv_id": "2601.13187v1",
      "title": "Scientific production in the era of Large Language Models",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£çš„ç§‘å­¦äº§å‡º",
      "authors": [
        "Keigo Kusumegi",
        "Xinyu Yang",
        "Paul Ginsparg",
        "Mathijs de Vaan",
        "Toby Stuart",
        "Yian Yin"
      ],
      "abstract": "Large Language Models (LLMs) are rapidly reshaping scientific research. We analyze these changes in multiple, large-scale datasets with 2.1M preprints, 28K peer review reports, and 246M online accesses to scientific documents. We find: 1) scientists adopting LLMs to draft manuscripts demonstrate a large increase in paper production, ranging from 23.7-89.3% depending on scientific field and author background, 2) LLM use has reversed the relationship between writing complexity and paper quality, leading to an influx of manuscripts that are linguistically complex but substantively underwhelming, and 3) LLM adopters access and cite more diverse prior work, including books and younger, less-cited documents. These findings highlight a stunning shift in scientific production that will likely require a change in how journals, funding agencies, and tenure committees evaluate scientific works.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡åˆ†æåŒ…å«210ä¸‡ç¯‡é¢„å°æœ¬ã€2.8ä¸‡ä»½åŒè¡Œè¯„å®¡æŠ¥å‘ŠåŠå¤§è§„æ¨¡åœ¨çº¿è®¿é—®è®°å½•çš„æ•°æ®é›†ï¼Œæ¢è®¨äº†Large Language Models (LLMs) å¯¹ç§‘å­¦ç ”ç©¶äº§å‡ºçš„æ·±è¿œå½±å“ã€‚ç ”ç©¶å‘ç°ï¼Œé‡‡ç”¨LLMsçš„ç§‘å­¦å®¶è®ºæ–‡äº§é‡æ˜¾è‘—æå‡ï¼ˆ23.7%-89.3%ï¼‰ï¼Œä½†åŒæ—¶ä¹Ÿåè½¬äº†å†™ä½œå¤æ‚æ€§ä¸è®ºæ–‡è´¨é‡ä¹‹é—´çš„å…³ç³»ï¼Œå¯¼è‡´å¤§é‡è¯­è¨€ä¿®é¥°å¤æ‚ä½†å®è´¨å†…å®¹å¹³åº¸çš„æ–‡ç¨¿æ¶Œç°ã€‚æ­¤å¤–ï¼ŒLLMä½¿ç”¨è€…å€¾å‘äºå¼•ç”¨æ›´å¤šæ ·åŒ–çš„æ–‡çŒ®ï¼ŒåŒ…æ‹¬ä¹¦ç±ä»¥åŠå‘è¡¨æ—¶é—´è¾ƒçŸ­ä¸”è¢«å¼•æ¬¡æ•°è¾ƒå°‘çš„æ–‡æ¡£ã€‚è¿™äº›å‘ç°è¡¨æ˜ç§‘å­¦ç”Ÿäº§æ¨¡å¼æ­£åœ¨å‘ç”Ÿå‰§å˜ï¼Œæš—ç¤ºæœŸåˆŠã€èµ„åŠ©æœºæ„å’Œè¯„å®¡å§”å‘˜ä¼šéœ€è¦é‡æ–°åˆ¶å®šå¯¹å­¦æœ¯æˆæœçš„è¯„ä¼°æ ‡å‡†ã€‚",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY",
        "physics.soc-ph"
      ],
      "primary_category": "cs.DL",
      "comment": "This is the author's version of the work. The definitive version was published in Science on 18 Dec 2025, DOI: 10.1126/science.adw3000. Link to the Final Published Version: https://www.science.org/doi/10.1126/science.adw3000",
      "pdf_url": "https://arxiv.org/pdf/2601.13187v1",
      "published_date": "2026-01-19 16:10:22 UTC",
      "updated_date": "2026-01-19 16:10:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:04.817576+00:00"
    },
    {
      "arxiv_id": "2601.13186v1",
      "title": "Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching",
      "title_zh": "ç»“åˆæ™ºèƒ½ä½“ AIã€åµŒå¥—å­¦ä¹ åŠåŸºäºè¯­ä¹‰ç¼“å­˜å®ç° AI å¯æŒç»­æ€§çš„æç¤ºæ³¨å…¥ç¼“è§£",
      "authors": [
        "Diego Gosmar",
        "Deborah A. Dahl"
      ],
      "abstract": "Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)ç‰¹åˆ«æ˜¯å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„æç¤ºæ³¨å…¥(Prompt Injection)é£é™©ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆä»£ç†AI(Agentic AI)ã€åµŒå¥—å­¦ä¹ (Nested Learning)åŠè¯­ä¹‰ç¼“å­˜(Semantic Caching)çš„é˜²å¾¡æ¡†æ¶ã€‚é€šè¿‡å¼•å…¥è§‚å¯Ÿæ€§è¯„åˆ†æ¯”ç‡(Observability Score Ratio)å¹¶æ‰©å±•ä¸ºTIVS-Oè¯„ä¼°ä½“ç³»ï¼Œè¯¥ç³»ç»Ÿåœ¨HOPEå¯å‘å¼çš„æ¶æ„ä¸­åˆ©ç”¨è¿ç»­è®°å¿†ç³»ç»Ÿ(Continuum Memory Systems)å¹³è¡¡äº†é˜²å¾¡æ•ˆèƒ½ä¸å®¡è®¡é€æ˜åº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿå®ç°äº†é›¶é«˜é£é™©è¿è§„ï¼Œå¹¶åˆ©ç”¨è¯­ä¹‰ç¼“å­˜æŠ€æœ¯å‡å°‘äº†41.6%çš„LLMè°ƒç”¨ï¼Œæ˜¾è‘—é™ä½äº†å¤„ç†å»¶è¿Ÿã€èƒ½è€—åŠç¢³æ’æ”¾ã€‚ç ”ç©¶è¯æ˜ï¼Œåœ¨æ— éœ€ä¿®æ”¹æ¨¡å‹æƒé‡çš„å‰æä¸‹ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆååŒå®‰å…¨æ€§ã€å®æ—¶æ€§èƒ½ä¸ç¯å¢ƒå¯æŒç»­æ€§ï¼Œä¸ºç”Ÿäº§çº§LLMçš„ç»¿è‰²éƒ¨ç½²æä¾›äº†å¯è¡Œè·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages, 19 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.13186v1",
      "published_date": "2026-01-19 16:10:11 UTC",
      "updated_date": "2026-01-19 16:10:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:08.729756+00:00"
    },
    {
      "arxiv_id": "2601.13166v1",
      "title": "From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models",
      "title_zh": "ä»åä¸‡ä½™å¼ å›¾åƒåˆ°å¤ºå† é¦–å±Šè„‘éƒ¨ MRI åŸºç¡€æ¨¡å‹æŒ‘æˆ˜èµ›ï¼šç»éªŒåˆ†äº«ä¸æ¨¡å‹å‘å¸ƒ",
      "authors": [
        "Pedro M. Gordaliza",
        "Jaume Banus",
        "BenoÃ®t GÃ©rin",
        "Maxence Wynen",
        "Nataliia Molchanova",
        "Jonas Richiardi",
        "Meritxell Bach Cuadra"
      ],
      "abstract": "Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ†äº«äº†åœ¨MICCAI 2025é¦–å±Š3Dè„‘éƒ¨MRIåŸºç¡€æ¨¡å‹(Foundation Models)æŒ‘æˆ˜èµ›ï¼ˆSSL3Då’ŒFOMO25ï¼‰ä¸­å¤ºå† çš„è§£å†³æ–¹æ¡ˆã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸºäºU-Net CNNçš„æ¶æ„ï¼Œå¹¶é€šè¿‡ç»“åˆè§£å‰–å…ˆéªŒ(anatomical priors)å’Œç¥ç»å½±åƒé¢†åŸŸçŸ¥è¯†æ¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚ä¸åŸºäºTransformerçš„ç«äº‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹çš„è®­ç»ƒé€Ÿåº¦æé«˜äº†1-2ä¸ªæ•°é‡çº§ï¼Œä¸”æ¨¡å‹å‚æ•°é‡ç¼©å°äº†10å€ã€‚è¯¥æˆæœè¯æ˜äº†ç»“åˆé¢†åŸŸçŸ¥è¯†çš„æ¶æ„åœ¨å¤„ç†å¤æ‚æ”¾å°„å­¦ä»»åŠ¡ä¸­çš„é«˜æ•ˆæ€§ä¸ä¼˜è¶Šæ€§ï¼Œç›¸å…³æ¨¡å‹å·²åœ¨GitHubå¼€æºã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Work presented at the SSL3D Challenge (1st place, ResEnc-L track) and FOMO Challenge (1st place, Methods track) on Brain MRI Foundation Models at MICCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.13166v1",
      "published_date": "2026-01-19 15:43:51 UTC",
      "updated_date": "2026-01-19 15:43:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:20.544925+00:00"
    },
    {
      "arxiv_id": "2601.13160v1",
      "title": "Training instability in deep learning follows low-dimensional dynamical principles",
      "title_zh": "æ·±åº¦å­¦ä¹ è®­ç»ƒä¸ç¨³å®šæ€§éµå¾ªä½ç»´åŠ¨åŠ›å­¦åŸç†",
      "authors": [
        "Zhipeng Zhang",
        "Zhenjie Yao",
        "Kai Li",
        "Lei Yang"
      ],
      "abstract": "Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.\n  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.\n  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„åŠ¨åŠ›å­¦è§†è§’(unified dynamical perspective)ï¼Œå°†æ·±åº¦å­¦ä¹ è®­ç»ƒç¨³å®šæ€§å®šä¹‰ä¸ºç”±optimizationã€environmental/dataã€parametricå’Œlearning-signalå››ä¸ªç»´åº¦æ„æˆçš„ç³»ç»Ÿå†…åœ¨å±æ€§ã€‚é€šè¿‡å¯¹å¼ºåŒ–å­¦ä¹ å’Œå¤§è¯­è¨€æ¨¡å‹è®­ç»ƒè½¨è¿¹è¿›è¡Œå—æ§æ‰°åŠ¨å®¡è®¡(controlled perturbation auditing)ï¼Œç ”ç©¶æ­ç¤ºäº†æ”¯é…å­¦ä¹ åŠ¨æ€çš„åº•å±‚è§„å¾‹ã€‚å®éªŒå‘ç°ï¼Œé«˜æœ€ç»ˆæ€§èƒ½ä¸è®­ç»ƒç¨³å®šæ€§å¾€å¾€æ˜¯è§£è€¦çš„ï¼Œè€Œå—æ§çš„éšæœºæ€§(controlled stochasticity)åœ¨ä¸åŒèŒƒå¼ä¸‹å‡èƒ½æœ‰æ•ˆç¼“å†²å­¦ä¹ åŠ¨æ€ã€‚æ­¤å¤–ï¼Œç ”ç©¶æŒ‡å‡ºä½ç»´æ½œå…ƒçŠ¶æ€(low-dimensional latent meta-states)çš„åå·®ä¼šç³»ç»Ÿæ€§åœ°é¢„ç¤ºæ€§èƒ½å´©æºƒã€‚è¿™äº›å‘ç°è¯æ˜äº†è®­ç»ƒç¨³å®šæ€§æ˜¯ä¸€ä¸ªå¯è¡¡é‡ä¸”å¯æ¯”è¾ƒçš„åŠ¨åŠ›å­¦å±æ€§ï¼Œä¸ºè¶…è¶Šæœ€ç»ˆæ€§èƒ½è¯„ä¼°ã€æ·±å…¥ç†è§£å­¦ä¹ åŠ¨æ€æä¾›äº†æè¿°æ€§åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13160v1",
      "published_date": "2026-01-19 15:37:45 UTC",
      "updated_date": "2026-01-19 15:37:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:12.348836+00:00"
    },
    {
      "arxiv_id": "2601.13142v1",
      "title": "TVWorld: Foundations for Remote-Control TV Agents",
      "title_zh": "TVWorldï¼šé¥æ§ç”µè§†æ™ºèƒ½ä½“åŸºç¡€",
      "authors": [
        "Zhantao Ma",
        "Quanfeng Lu",
        "Shuai Zhong",
        "Dahai Yu",
        "Ping Luo",
        "Michael K. Ng"
      ],
      "abstract": "Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \\textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \\textbf{TVWorld-N} for topology-aware navigation and \\textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \\emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \\textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† TVWorldï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå›¾æŠ½è±¡ (Graph-based abstraction) çš„ç¦»çº¿ç”µè§†å¯¼èˆªå¹³å°ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ (LVLMs) åœ¨ç”µè§†é¥æ§äº¤äº’ (Remote-control interaction) é¢†åŸŸçš„ç ”ç©¶ç©ºç™½ã€‚ç ”ç©¶è€…è¿›ä¸€æ­¥æå‡ºäº† TVWorld-N å’Œ TVWorld-G ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ï¼Œæ­ç¤ºäº†ç°æœ‰æ™ºèƒ½ä½“åœ¨é•¿ç¨‹ç”µè§†å¯¼èˆªä¸­æ™®éç¼ºä¹æ‹“æ‰‘æ„ŸçŸ¥ (Topology awareness) çš„å±€é™æ€§ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº† Topology-Aware Training æ¡†æ¶ï¼Œå¹¶æ®æ­¤æ„å»ºäº†ä¸“é—¨ç”¨äºç”µè§†å¯¼èˆªçš„åŸºç¡€æ¨¡å‹ TVTheseusã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTVTheseus åœ¨ TVWorld-N ä¸Šçš„æˆåŠŸç‡è¾¾åˆ° 68.3%ï¼Œè¶…è¶Šäº† Gemini 3 Flash ç­‰å¼ºåŠ›é—­æºæ¨¡å‹ï¼Œåˆ·æ–°äº†å½“å‰æœ€å…ˆè¿›æ°´å¹³ (SOTA)ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13142v1",
      "published_date": "2026-01-19 15:24:32 UTC",
      "updated_date": "2026-01-19 15:24:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:15.667539+00:00"
    },
    {
      "arxiv_id": "2601.13122v1",
      "title": "Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward",
      "title_zh": "é€šç”¨ç³»ç»Ÿçš„è´Ÿè´£ä»»äººå·¥æ™ºèƒ½ï¼šç»¼è¿°ã€æŒ‘æˆ˜ä¸å‰ç»",
      "authors": [
        "Gourab K Patro",
        "Himanshi Agrawal",
        "Himanshu Gharat",
        "Supriya Panigrahi",
        "Nim Sherpa",
        "Vishal Vaddina",
        "Dagnachew Birru"
      ],
      "abstract": "Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿåœ°å›é¡¾äº†é€šç”¨äººå·¥æ™ºèƒ½(General-Purpose AI)åœ¨å…¬å¹³æ€§ã€éšç§å’Œå®‰å…¨æ€§ç­‰å…«å¤§è´Ÿè´£ä»»AI(RAI)åŸåˆ™ä¸‹é¢ä¸´çš„é£é™©ä¸æŒ‘æˆ˜ã€‚ä½œè€…æŒ‡å‡ºï¼Œé€šç”¨ç³»ç»Ÿç›¸è¾ƒäºä¼ ç»Ÿä»»åŠ¡ç‰¹å®šç³»ç»Ÿå…·æœ‰æ›´é«˜çš„è¾“å‡ºè‡ªç”±åº¦(Degree of Freedom in output, DoFo)ï¼Œè¿™æ˜¯å¯¼è‡´å…¶äº§ç”Ÿå¹»è§‰ã€æ¯’æ€§å’Œåè§ç­‰é—®é¢˜çš„æ ¸å¿ƒåŸå› ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†C2V2ï¼ˆControl, Consistency, Value, Veracityï¼‰æ ¸å¿ƒè¯‰æ±‚æ¡†æ¶ï¼Œä½œä¸ºæœªæ¥é€šç”¨AIæ»¡è¶³RAIè¦æ±‚çš„åŸºç¡€ã€‚ç ”ç©¶å¼ºè°ƒï¼Œé€šè¿‡ç³»ç»Ÿè®¾è®¡æ–¹æ³•å¹¶ç»“åˆAIå¯¹é½ã€æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)åŠæ¨ç†å¢å¼ºç­‰æŠ€æœ¯ï¼Œåœ¨C2V2ç»´åº¦ä¸Šå»ºç«‹é¢†åŸŸç›¸å…³çš„å½¢å¼åŒ–æ¨¡å‹ï¼Œæ˜¯å®ç°å¯ä¿¡é€šç”¨äººå·¥æ™ºèƒ½çš„å…³é”®è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13122v1",
      "published_date": "2026-01-19 15:10:59 UTC",
      "updated_date": "2026-01-19 15:10:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:25.338243+00:00"
    },
    {
      "arxiv_id": "2601.13114v1",
      "title": "IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks",
      "title_zh": "IntAgentï¼šé¢å‘å…ˆè¿›ä¸‹ä¸€ä»£ç½‘ç»œçš„åŸºäº NWDAF çš„æ„å›¾ LLM æ™ºèƒ½ä½“",
      "authors": [
        "Abdelrahman Soliman",
        "Ahmed Refaey",
        "Aiman Erbad",
        "Amr Mohamed"
      ],
      "abstract": "Intent-based networks (IBNs) are gaining prominence as an innovative technology that automates network operations through high-level request statements, defining what the network should achieve. In this work, we introduce IntAgent, an intelligent intent LLM agent that integrates NWDAF analytics and tools to fulfill the network operator's intents. Unlike previous approaches, we develop an intent tools engine directly within the NWDAF analytics engine, allowing our agent to utilize live network analytics to inform its reasoning and tool selection. We offer an enriched, 3GPP-compliant data source that enhances the dynamic, context-aware fulfillment of network operator goals, along with an MCP tools server for scheduling, monitoring, and analytics tools. We demonstrate the efficacy of our framework through two practical use cases: ML-based traffic prediction and scheduled policy enforcement, which validate IntAgent's ability to autonomously fulfill complex network intents.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† IntAgentï¼Œä¸€ç§åŸºäº NWDAF çš„æ™ºèƒ½æ„å›¾ LLM Agentï¼Œæ—¨åœ¨é€šè¿‡é«˜çº§è¯·æ±‚å®ç° Intent-based networks (IBNs) çš„è‡ªåŠ¨åŒ–è¿ç»´ã€‚IntAgent çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†æ„å›¾å·¥å…·å¼•æ“ç›´æ¥é›†æˆåœ¨ NWDAF åˆ†æå¼•æ“ä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿåˆ©ç”¨å®æ—¶ç½‘ç»œåˆ†ææ•°æ®æ¥é©±åŠ¨æ¨ç†å’Œå·¥å…·é€‰æ‹©ã€‚è¯¥æ¡†æ¶æä¾›äº†ç¬¦åˆ 3GPP è§„èŒƒçš„æ•°æ®æºï¼Œå¹¶ç»“åˆ MCP å·¥å…·æœåŠ¡å™¨å®ç°äº†åŠ¨æ€ã€æ„ŸçŸ¥ä¸Šä¸‹æ–‡çš„æ„å›¾å±¥è¡Œã€‚é€šè¿‡æµé‡é¢„æµ‹å’Œç­–ç•¥æ‰§è¡Œç­‰ç”¨ä¾‹éªŒè¯ï¼ŒIntAgent å±•ç°äº†è‡ªä¸»å¤„ç†å¤æ‚ç½‘ç»œæ„å›¾çš„èƒ½åŠ›ï¼Œä¸ºä¸‹ä¸€ä»£ç½‘ç»œæ™ºèƒ½åŒ–æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "conference",
      "pdf_url": "https://arxiv.org/pdf/2601.13114v1",
      "published_date": "2026-01-19 14:55:48 UTC",
      "updated_date": "2026-01-19 14:55:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:20.036405+00:00"
    },
    {
      "arxiv_id": "2601.13111v1",
      "title": "CORE-T: COherent REtrieval of Tables for Text-to-SQL",
      "title_zh": "CORE-Tï¼šé¢å‘æ–‡æœ¬åˆ° SQL çš„è¿è´¯è¡¨æ ¼æ£€ç´¢",
      "authors": [
        "Hassan Soliman",
        "Vivek Gupta",
        "Dan Roth",
        "Iryna Gurevych"
      ],
      "abstract": "Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CORE-Tï¼Œä¸€ç§é¢å‘ Text-to-SQL ä»»åŠ¡çš„å¯æ‰©å±•ã€å…è®­ç»ƒï¼ˆtraining-freeï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹å¼‚æ„è¡¨æ ¼é›†åˆä¸­å¤šè¡¨å…³è”æ£€ç´¢çš„æ€§èƒ½ç“¶é¢ˆã€‚è¯¥æ–¹æ³•é€šè¿‡ LLM ç”Ÿæˆçš„ç”¨é€”å…ƒæ•°æ® (metadata) å¢å¼ºè¡¨æ ¼ä¿¡æ¯ï¼Œå¹¶é¢„å…ˆè®¡ç®—è½»é‡çº§çš„è¡¨æ ¼å…¼å®¹æ€§ç¼“å­˜ (table-compatibility cache)ã€‚åœ¨æ¨ç†é˜¶æ®µï¼ŒCORE-T ç»“åˆ Dense Retrieval (DR) ä¸å•æ¬¡ LLM è°ƒç”¨æ¥ç­›é€‰è¿è´¯ä¸”å¯è¿æ¥ï¼ˆjoinableï¼‰çš„è¡¨æ ¼å­é›†ï¼Œå¹¶åˆ©ç”¨åŠ æ€§è°ƒæ•´æ­¥éª¤æ¢å¤å¼ºå…¼å®¹çš„è¡¨æ ¼ã€‚å®éªŒè¡¨æ˜ï¼ŒCORE-T åœ¨ Birdã€Spider å’Œ MMQA ç­‰æ•°æ®é›†ä¸Šå°†è¡¨æ ¼é€‰æ‹©çš„ F1 åˆ†æ•°æå‡äº†é«˜è¾¾ 22.7 ç‚¹ï¼Œåœ¨æ˜¾è‘—é™ä½ Token æ¶ˆè€—çš„åŒæ—¶ï¼Œæœ‰æ•ˆæé«˜äº†å¤šè¡¨æŸ¥è¯¢çš„æ‰§è¡Œå‡†ç¡®ç‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint under review. Code and data available at: https://github.com/UKPLab/arxiv2026-core-t",
      "pdf_url": "https://arxiv.org/pdf/2601.13111v1",
      "published_date": "2026-01-19 14:51:23 UTC",
      "updated_date": "2026-01-19 14:51:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:29.471327+00:00"
    },
    {
      "arxiv_id": "2601.13075v1",
      "title": "METIS: Mentoring Engine for Thoughtful Inquiry & Solutions",
      "title_zh": "METISï¼šç”¨äºæ·±åº¦æ¢ç©¶ä¸è§£å†³æ–¹æ¡ˆçš„æŒ‡å¯¼å¼•æ“",
      "authors": [
        "Abhinav Rajeev Kumar",
        "Dhruv Trehan",
        "Paras Chopra"
      ],
      "abstract": "Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº† METISï¼Œä¸€ä¸ªå…·å¤‡å·¥å…·å¢å¼ºå’Œé˜¶æ®µæ„ŸçŸ¥ (stage-aware) èƒ½åŠ›çš„ AI ç ”ç©¶å¯¼å¸ˆç³»ç»Ÿï¼Œæ—¨åœ¨å¼•å¯¼æœ¬ç§‘ç”Ÿå®Œæˆä»ç§‘ç ”æ„æ€åˆ°è®ºæ–‡äº§å‡ºçš„å…¨è¿‡ç¨‹ã€‚è¯¥ç³»ç»Ÿé›†æˆäº†æ–‡çŒ®æœç´¢ (literature search)ã€ç²¾å¿ƒç­–åˆ’çš„æŒ‡å—ã€æ–¹æ³•è®ºæ£€æŸ¥åŠè®°å¿†åŠŸèƒ½ï¼Œèƒ½å¤Ÿé’ˆå¯¹ç ”ç©¶çš„ä¸åŒé˜¶æ®µæä¾›ä¸“ä¸šæ”¯æŒã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œåœ¨å…­ä¸ªå†™ä½œé˜¶æ®µçš„å•è½®æç¤ºä¸­ï¼ŒLLM è¯„åˆ¤ METIS çš„è¡¨ç°ä¼˜äº Claude Sonnet 4.5 (71%) å’Œ GPT-5 (54%)ï¼Œå¹¶åœ¨å­¦ç”Ÿè¯„ä¼°å’Œå¤šè½®è¾…å¯¼åœºæ™¯ä¸‹è¡¨ç°å‡ºæ›´é«˜çš„æ¸…æ™°åº¦ä¸å¯æ“ä½œæ€§ã€‚å®éªŒè¯æ˜ METIS åœ¨æ–‡æ¡£é©±åŠ¨é˜¶æ®µå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸ºè§£å†³å­¦ç”Ÿç¼ºä¹ä¸“å®¶å¯¼å¸ˆæŒ‡å¯¼çš„é—®é¢˜æä¾›äº†æœ‰æ•ˆçš„ AI è¾…åŠ©æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2601.13075v1",
      "published_date": "2026-01-19 14:10:35 UTC",
      "updated_date": "2026-01-19 14:10:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:30.037402+00:00"
    },
    {
      "arxiv_id": "2601.13060v1",
      "title": "MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux",
      "title_zh": "MagicGUI-RMSï¼šåŸºäºè‡ªåŠ¨åé¦ˆå›æµçš„è‡ªè¿›åŒ– GUI æ™ºèƒ½ä½“å¤šæ™ºèƒ½ä½“å¥–åŠ±æ¨¡å‹ç³»ç»Ÿ",
      "authors": [
        "Zecheng Li",
        "Zhihui Cao",
        "Wenke Huang",
        "Yudong Zhang",
        "Keying Qi",
        "Rui Wang",
        "Zeyu Zheng",
        "Jian Zhao",
        "Hao Zhu",
        "Hengxin Wu",
        "Yuran Wang",
        "Guitao Fan",
        "Guokun Wu",
        "Yicong Liu",
        "Zhilin Gao",
        "Haikun Xu",
        "He Yang",
        "Minqi Xiang",
        "Xingyu Liu",
        "Zuojian Wang"
      ],
      "abstract": "Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº† MagicGUI-RMSï¼Œä¸€ç§ä¸“ä¸º GUI Agents è®¾è®¡çš„å¤šæ™ºèƒ½ä½“å¥–åŠ±æ¨¡å‹ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³è½¨è¿¹è¯„ä¼°è‡ªåŠ¨åŒ–å’Œå¤§è§„æ¨¡é«˜è´¨é‡è®­ç»ƒæ•°æ®ç”Ÿæˆçš„éš¾é¢˜ã€‚è¯¥ç³»ç»Ÿé€šè¿‡é›†æˆé¢†åŸŸç‰¹å®šå¥–åŠ±æ¨¡å‹ (DS-RM) å’Œé€šç”¨å¥–åŠ±æ¨¡å‹ (GP-RM)ï¼Œå®ç°äº†ç»†ç²’åº¦çš„åŠ¨ä½œè¯„ä¼°ä»¥åŠåœ¨å¼‚æ„ä»»åŠ¡ä¸­çš„å¼ºæ³›åŒ–èƒ½åŠ›ã€‚MagicGUI-RMS å¼•å…¥äº†ç»“æ„åŒ–çš„æ•°æ®æ„å»ºæµæ°´çº¿å’Œè‡ªåŠ¨åŒ–æ•°æ®å›æµ (data-reflux) æœºåˆ¶ï¼Œèƒ½å¤Ÿè¯†åˆ«é”™è¯¯åŠ¨ä½œå¹¶æä¾›çº æ­£æ€§åé¦ˆï¼Œä»è€Œå®ç°æ™ºèƒ½ä½“çš„è‡ªæˆ‘è¿›åŒ–ã€‚å®éªŒè¯æ˜ï¼Œè¯¥ç³»ç»Ÿæ˜¾è‘—æå‡äº†ä»»åŠ¡å‡†ç¡®æ€§å’Œè¡Œä¸ºé²æ£’æ€§ï¼Œä¸ºæ„å»ºå¯è‡ªæˆ‘æ”¹è¿›çš„ GUI æ™ºèƒ½ä½“å¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13060v1",
      "published_date": "2026-01-19 13:50:43 UTC",
      "updated_date": "2026-01-19 13:50:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:30.302194+00:00"
    },
    {
      "arxiv_id": "2601.13054v1",
      "title": "TinyML-Enabled IoT for Sustainable Precision Irrigation",
      "title_zh": "é¢å‘å¯æŒç»­ç²¾å‡†çŒæº‰çš„ TinyML èµ‹èƒ½ç‰©è”ç½‘",
      "authors": [
        "Kamogelo Taueatsoala",
        "Caitlyn Daniels",
        "Angelina J. Ramsunar",
        "Petrus Bronkhorst",
        "Absalom E. Ezugwu"
      ],
      "abstract": "Small-scale farming communities are disproportionately affected by water scarcity, erratic climate patterns, and a lack of access to advanced, affordable agricultural technologies. To address these challenges, this paper presents a novel, edge-first IoT framework that integrates Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation. The proposed four-layer architecture leverages low-cost hardware, an ESP32 microcontroller as an edge inference node, and a Raspberry Pi as a local edge server to enable autonomous decision-making without cloud dependency. The system utilizes capacitive soil moisture, temperature, humidity, pH, and ambient light sensors for environmental monitoring. A rigorous comparative analysis of ensemble models identified gradient boosting as superior, achieving an R^2 score of 0.9973 and a Mean Absolute Percentage Error (MAPE) of 0.99%, outperforming a random forest model (R^2 = 0.9916, MAPE = 1.81%). This optimized model was converted and deployed as a lightweight TinyML inference engine on the ESP32 and predicts irrigation needs with exceptional accuracy (MAPE < 1%). Local communication is facilitated by an MQTT-based LAN protocol, ensuring reliable operation in areas with limited or no internet connectivity. Experimental validation in a controlled environment demonstrated a significant reduction in water usage compared to traditional methods, while the system's low-power design and offline functionality confirm its viability for sustainable, scalable deployment in resource-constrained rural settings. This work provides a practical, cost-effective blueprint for bridging the technological divide in agriculture and enhancing water-use efficiency through on-device artificial intelligence.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº Tiny Machine Learning (TinyML) çš„è¾¹ç¼˜ä¼˜å…ˆï¼ˆedge-firstï¼‰ç‰©è”ç½‘ï¼ˆIoTï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨ä¸ºèµ„æºå—é™çš„å°è§„æ¨¡å†œåœºæä¾›ä½æˆæœ¬ã€ç¦»çº¿çš„ç²¾å‡†çŒæº‰æ–¹æ¡ˆã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨ç”± ESP32 å¾®æ§åˆ¶å™¨å’Œ Raspberry Pi ç»„æˆçš„å››å±‚æ¶æ„ï¼Œé€šè¿‡é›†æˆå¤šç§ç¯å¢ƒä¼ æ„Ÿå™¨å®ç°äº†æ— éœ€äº‘ç«¯ä¾èµ–çš„è‡ªä¸»å†³ç­–ã€‚å®éªŒå¯¹æ¯”è¡¨æ˜ï¼ŒGradient Boosting æ¨¡å‹åœ¨é¢„æµ‹çŒæº‰éœ€æ±‚æ–¹é¢è¡¨ç°æœ€ä¼˜ï¼ˆ$R^2 = 0.9973$ï¼ŒMAPE < 1%ï¼‰ï¼Œå¹¶å·²æˆåŠŸéƒ¨ç½²ä¸ºè½»é‡åŒ–æ¨ç†å¼•æ“ã€‚è¯¥æ–¹æ¡ˆç»“åˆ MQTT å±€åŸŸç½‘é€šä¿¡åè®®ä¸ä½åŠŸè€—è®¾è®¡ï¼Œåœ¨æ˜¾è‘—æé«˜æ°´åˆ†åˆ©ç”¨æ•ˆç‡çš„åŒæ—¶ï¼Œä¸ºåè¿œå†œæ‘åœ°åŒºçš„å¯æŒç»­å†œä¸šå‘å±•æä¾›äº†å¯æ‰©å±•çš„æŠ€æœ¯è“å›¾ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13054v1",
      "published_date": "2026-01-19 13:43:28 UTC",
      "updated_date": "2026-01-19 13:43:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:41.490860+00:00"
    },
    {
      "arxiv_id": "2601.13048v1",
      "title": "Analysis of Long Range Dependency Understanding in State Space Models",
      "title_zh": "çŠ¶æ€ç©ºé—´æ¨¡å‹å¯¹é•¿ç¨‹ä¾èµ–ç†è§£çš„åˆ†æ",
      "authors": [
        "Srividya Ravikumar",
        "Abhinav Anand",
        "Shweta Verma",
        "Mira Mezini"
      ],
      "abstract": "Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. In this work, we present the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, we show that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, we show that the depending on the architecture, S4D kernel can behave as low-pass, band-pass or high-pass filter. The insights from our analysis can guide future work in designing better S4D-based models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çŠ¶æ€ç©ºé—´æ¨¡å‹ (State Space Models, SSMs) åœ¨å¤„ç†é•¿åºåˆ—ä»»åŠ¡æ—¶ç¼ºä¹å¯è§£é‡Šæ€§çš„é—®é¢˜ï¼Œå¯¹åº”ç”¨äºæºç æ¼æ´æ£€æµ‹ (vulnerability detection in source code) ä»»åŠ¡çš„å¯¹è§’åŒ–çŠ¶æ€ç©ºé—´æ¨¡å‹ (S4D) è¿›è¡Œäº†é¦–æ¬¡ç³»ç»Ÿçš„æ ¸å¯è§£é‡Šæ€§ç ”ç©¶ (kernel interpretability study)ã€‚é€šè¿‡å¯¹ S4D æ ¸ (kernel) çš„æ—¶åŸŸå’Œé¢‘åŸŸåˆ†æï¼Œç ”ç©¶å‘ç°å…¶é•¿ç¨‹å»ºæ¨¡èƒ½åŠ›åœ¨ä¸åŒæ¨¡å‹æ¶æ„ä¸‹å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå¹¶ç›´æ¥å½±å“æœ€ç»ˆæ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼Œæ ¹æ®æ¶æ„é…ç½®çš„ä¸åŒï¼ŒS4D æ ¸å¯èƒ½è¡¨ç°ä¸ºä½é€š (low-pass)ã€å¸¦é€š (band-pass) æˆ–é«˜é€š (high-pass) æ»¤æ³¢å™¨ã€‚è¿™äº›åˆ†æç»“æœä¸ºæœªæ¥è®¾è®¡æ›´é«˜æ•ˆçš„åŸºäº S4D çš„æ¨¡å‹æ¶æ„æä¾›äº†é‡è¦çš„æŒ‡å¯¼æ„ä¹‰ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13048v1",
      "published_date": "2026-01-19 13:39:42 UTC",
      "updated_date": "2026-01-19 13:39:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:48.923925+00:00"
    },
    {
      "arxiv_id": "2601.13020v1",
      "title": "PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning",
      "title_zh": "PASs-MoEï¼šåˆ©ç”¨è·¯å¾„æ¿€æ´»å­ç©ºé—´ç¼“è§£æŒç»­å­¦ä¹ ä¸­è·¯ç”±ä¸ä¸“å®¶é—´çš„é”™ä½ååŒæ¼‚ç§»",
      "authors": [
        "Zhiyan Hou",
        "Haiyun Guo",
        "Haokai Ma",
        "Yandu Sun",
        "Yonghui Yang",
        "Jinqiao Wang"
      ],
      "abstract": "Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨æŒç»­æŒ‡ä»¤å¾®è°ƒ(Continual instruction tuning, CIT)ä¸­çš„é—å¿˜é—®é¢˜ï¼Œæå‡ºäº†PASs-MoEæ¡†æ¶ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œç°æœ‰çš„LoRA-based MoEæ–¹æ³•å­˜åœ¨â€œMisaligned Co-driftâ€ç°è±¡ï¼Œå³è·¯ç”±å™¨(Router)ä¸ä¸“å®¶(Experts)çš„ååŒåç§»ä¼šå¯¼è‡´ä¸“å®¶èŒè´£æ¨¡ç³Šå¹¶åŠ å‰§é—å¿˜ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡å¼•å…¥äº†é€šè·¯æ¿€æ´»å­ç©ºé—´(Pathway Activation Subspaces, PASs)ï¼Œåˆ©ç”¨LoRAè¯±å¯¼çš„å­ç©ºé—´ä½œä¸ºèƒ½åŠ›å¯¹é½çš„åæ ‡ç³»ã€‚åŸºäºæ­¤ï¼ŒPASs-MoEé€šè¿‡PAS-guided Reweightingæ ¡å‡†è·¯ç”±ä¿¡å·ï¼Œå¹¶åˆ©ç”¨PAS-aware Rank Stabilizationç¨³å®šæ—§ä»»åŠ¡çš„å…³é”®ç§©æ–¹å‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸å¢åŠ å‚æ•°çš„æƒ…å†µä¸‹ï¼Œåœ¨å‡†ç¡®ç‡å’ŒæŠ—é—å¿˜æ€§èƒ½ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„æŒç»­å­¦ä¹ (Continual Learning)åŸºçº¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13020v1",
      "published_date": "2026-01-19 12:57:11 UTC",
      "updated_date": "2026-01-19 12:57:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:48.531666+00:00"
    },
    {
      "arxiv_id": "2601.13018v1",
      "title": "Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context",
      "title_zh": "Bi-Attention HateXplainï¼šåœ¨å¤šä»»åŠ¡èƒŒæ™¯ä¸‹å®ç°å¯è§£é‡Šæ€§æ—¶å…¼é¡¾æ•°æ®çš„åºåˆ—ç‰¹æ€§",
      "authors": [
        "Ghislain Dorian Tchuente Mondjo"
      ],
      "abstract": "Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ HateXplain åŸºå‡†æ¨¡å‹åœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­å­˜åœ¨çš„ Attention é¢„æµ‹æ³¢åŠ¨å¤§å’Œè§£é‡Šä¸ä¸€è‡´ç­‰é—®é¢˜ï¼Œæå‡ºäº† BiAtt-BiRNN-HateXplain æ¨¡å‹ã€‚è¯¥æ¨¡å‹åˆ©ç”¨ BiRNN å±‚åœ¨å¯è§£é‡Šæ€§åˆ†æä¸­å……åˆ†æ•æ‰è¾“å…¥æ•°æ®çš„åºåˆ—ç‰¹å¾ï¼ˆsequential aspectï¼‰ï¼Œç›¸æ¯”å¤æ‚çš„ LLMs å…·æœ‰æ›´é«˜çš„é€æ˜åº¦ã€‚é€šè¿‡å°†è§£é‡Šæ€§ä¸åˆ†ç±»ä»»åŠ¡ç›¸ç»“åˆçš„å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ï¼Œæ¨¡å‹èƒ½å¤Ÿå®ç°æ›´ç²¾å‡†çš„åˆ†ç±»å¹¶å‡å°‘é’ˆå¯¹ç¤¾åŒºçš„æ— æ„åè§ï¼ˆunintentional biasï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ HateXplain æ•°æ®é›†ä¸Šçš„æ£€æµ‹æ€§èƒ½ã€å¯è§£é‡Šæ€§æŒ‡æ ‡ä»¥åŠåè§å‰Šå‡æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at \"EAI AFRICOMM 2025 - 17th EAI International Conference on Communications and Networks in Africa\"",
      "pdf_url": "https://arxiv.org/pdf/2601.13018v1",
      "published_date": "2026-01-19 12:52:18 UTC",
      "updated_date": "2026-01-19 12:52:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:50.467190+00:00"
    },
    {
      "arxiv_id": "2601.13013v1",
      "title": "HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads",
      "title_zh": "HT-GNNï¼šé¢å‘ Baidu Ads å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼é¢„æµ‹çš„è¶…æ—¶åºå›¾ç¥ç»ç½‘ç»œ",
      "authors": [
        "Xiaohui Zhao",
        "Xinjian Zhao",
        "Jiahui Zhang",
        "Guoyu Liu",
        "Houzhi Wang",
        "Shu Wu"
      ],
      "abstract": "Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: (1) demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups; and (2) dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: (i) a hypergraph-supervised module capturing inter-segment relationships; (ii) a transformer-based temporal encoder with adaptive weighting; and (iii) a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on \\textit{Baidu Ads} with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HT-GNN (Hyper-Temporal Graph Neural Network)ï¼Œæ—¨åœ¨è§£å†³ç™¾åº¦å¹¿å‘Š (Baidu Ads) ä¿¡æ¯æµåœºæ™¯ä¸‹ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼ (Lifetime Value, LTV) é¢„æµ‹ä¸­é¢ä¸´çš„äººå£ç»Ÿè®¡å¼‚è´¨æ€§å’Œè¡Œä¸ºåºåˆ—ä¸è§„åˆ™ç­‰æŒ‘æˆ˜ã€‚HT-GNN æ ¸å¿ƒåŒ…å«ä¸‰ä¸ªç»„ä»¶ï¼šä¸€ä¸ªæ•æ‰ä¸åŒç»†åˆ†ç¾¤ä½“é—´å…³ç³»çš„è¶…å›¾ç›‘ç£æ¨¡å— (Hypergraph-supervised module)ã€ä¸€ä¸ªå¸¦è‡ªé€‚åº”æƒé‡çš„ Transformer æ—¶é—´ç¼–ç å™¨ï¼Œä»¥åŠç”¨äºå¤šå‘¨æœŸ LTV é¢„æµ‹çš„ä»»åŠ¡è‡ªé€‚åº”ä¸“å®¶æ··åˆç½‘ç»œ (Task-adaptive Mixture-of-Experts, MoE)ã€‚åœ¨åŒ…å«1500ä¸‡ç”¨æˆ·çš„çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHT-GNN åœ¨å„é¡¹è¯„ä¼°æŒ‡æ ‡å’Œé¢„æµ‹å‘¨æœŸä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œèƒ½æœ‰æ•ˆæ”¯æŒå¹¿å‘Šå¹³å°çš„å‡ºä»·ä¼˜åŒ–ä¸é¢„ç®—åˆ†é…ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.13013v1",
      "published_date": "2026-01-19 12:47:31 UTC",
      "updated_date": "2026-01-19 12:47:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:53.468924+00:00"
    },
    {
      "arxiv_id": "2601.13007v1",
      "title": "ArchAgent: Scalable Legacy Software Architecture Recovery with LLMs",
      "title_zh": "ArchAgentï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¯æ‰©å±•é—ç•™è½¯ä»¶æ¶æ„æ¢å¤",
      "authors": [
        "Rusheng Pan",
        "Bingcheng Mao",
        "Tianyi Ma",
        "Zhenhua Ling"
      ],
      "abstract": "Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). We present ArchAgent, a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. ArchAgent introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects. The dataset is available at https://github.com/panrusheng/arch-eval-benchmark.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ArchAgentï¼Œä¸€ç§å¯æ‰©å±•çš„åŸºäº agent çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è§„æ¨¡é—ç•™è½¯ä»¶æ¶æ„æ¢å¤ä¸­é¢ä¸´çš„ architectural driftï¼ˆæ¶æ„æ¼‚ç§»ï¼‰ã€å…³ç³»ç¼ºå¤±ä»¥åŠ LLMs ä¸Šä¸‹æ–‡å—é™ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶ç»“åˆäº† static analysisï¼ˆé™æ€åˆ†æï¼‰ã€adaptive code segmentationï¼ˆè‡ªé€‚åº”ä»£ç åˆ†æ®µï¼‰ä¸ LLM-powered synthesisï¼ˆå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åˆæˆï¼‰ï¼Œèƒ½ä»è·¨ä»“åº“ä»£ç åº“ä¸­é‡å»ºå¤šè§†å›¾ä¸”å¯¹é½ä¸šåŠ¡çš„æ¶æ„ã€‚é€šè¿‡å¼•å…¥å¸¦æœ‰ä¸Šä¸‹æ–‡å‰ªæçš„å¯æ‰©å±•å›¾è¡¨ç”ŸæˆæŠ€æœ¯å¹¶é›†æˆè·¨ä»“åº“æ•°æ®ï¼ŒArchAgent æ˜¾è‘—æå‡äº†è¯†åˆ«ä¸šåŠ¡å…³é”®æ¨¡å—çš„èƒ½åŠ›ã€‚å®éªŒå’Œæ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼ŒArchAgent åœ¨ç”Ÿäº§çº§é¡¹ç›®ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰åŸºå‡†ï¼Œèƒ½å¤Ÿæœ‰æ•ˆä»é—ç•™ç³»ç»Ÿä¸­æ¢å¤æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "to be published in ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.13007v1",
      "published_date": "2026-01-19 12:39:05 UTC",
      "updated_date": "2026-01-19 12:39:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:40:55.968232+00:00"
    },
    {
      "arxiv_id": "2601.12951v1",
      "title": "Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models",
      "title_zh": "è¶…è¶Šå‡†ç¡®ç‡ï¼šå‰–æï¼ˆå¤§ï¼‰è¯­è¨€æ¨¡å‹çš„ä»£ç ç†è§£èƒ½åŠ›",
      "authors": [
        "Felix MÃ¤chtle",
        "Jan-Niclas Serr",
        "Nils Loose",
        "Thomas Eisenbarth"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly integrated into software engineering workflows, yet current benchmarks provide only coarse performance summaries that obscure the diverse capabilities and limitations of these models. This paper investigates whether LLMs' code-comprehension performance aligns with traditional human-centric software metrics or instead reflects distinct, non-human regularities. We introduce a diagnostic framework that reframes code understanding as a binary input-output consistency task, enabling the evaluation of classification and generative models. Using a large-scale dataset, we correlate model performance with traditional, human-centric complexity metrics, such as lexical size, control-flow complexity, and abstract syntax tree structure. Our analyses reveal minimal correlation between human-defined metrics and LLM success (AUROC 0.63), while shadow models achieve substantially higher predictive performance (AUROC 0.86), capturing complex, partially predictable patterns beyond traditional software measures. These findings suggest that LLM comprehension reflects model-specific regularities only partially accessible through either human-designed or learned features, emphasizing the need for benchmark methodologies that move beyond aggregate accuracy and toward instance-level diagnostics, while acknowledging fundamental limits in predicting correct outcomes.",
      "tldr_zh": "### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ“\n\n---\n\nè¯¥ç ”ç©¶è°ƒæŸ¥äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„ä»£ç ç†è§£ (Code comprehension) èƒ½åŠ›æ˜¯å¦ç¬¦åˆä¼ ç»Ÿçš„äººç±»ä¸­å¿ƒåŒ–è½¯ä»¶æŒ‡æ ‡ (Human-centric metrics)ã€‚ç ”ç©¶è€…æå‡ºäº†ä¸€ä¸ªå°†ä»£ç ç†è§£é‡æ„ä¸ºè¾“å…¥-è¾“å‡ºä¸€è‡´æ€§ (Input-output consistency) çš„è¯Šæ–­æ¡†æ¶ï¼Œå¹¶åˆ†æäº†æ¨¡å‹è¡¨ç°ä¸è¯æ±‡å¤§å° (Lexical size)ã€æ§åˆ¶æµå¤æ‚åº¦ (Control-flow complexity) åŠæŠ½è±¡è¯­æ³•æ ‘ (Abstract syntax tree) ç»“æ„çš„ç›¸å…³æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œäººç±»å®šä¹‰çš„æŒ‡æ ‡ä¸ LLM çš„æˆåŠŸä»…æœ‰æä½ç›¸å…³æ€§ (AUROC 0.63)ï¼Œè€Œå½±å­æ¨¡å‹ (Shadow models) èƒ½æ•æ‰åˆ°æ›´å¤æ‚çš„éäººç±»è§„å¾‹ (AUROC 0.86)ã€‚è¿™è¡¨æ˜ LLM çš„ä»£ç ç†è§£éµå¾ªç‰¹å®šçš„æ¨¡å‹è§„å¾‹ï¼Œç ”ç©¶å¼ºè°ƒè¯„ä¼°æ–¹æ³•åº”ä»å®è§‚çš„å‡†ç¡®ç‡ (Accuracy) è½¬å‘å®ä¾‹çº§åˆ«çš„è¯Šæ–­ (Instance-level diagnostics)ã€‚\n\n---\n\n### è¯„ä¼°ç»“æœå¯¹æ¯” ğŸ“Š\n\n| è¯„ä¼°ç»´åº¦ | é¢„æµ‹è¡¨ç° (AUROC) | æ ¸å¿ƒå‘ç° |\n|---|---|---|\n| äººç±»ä¸­å¿ƒåŒ–æŒ‡æ ‡ (Human-centric metrics) | 0.63 | ä¼ ç»Ÿè½¯ä»¶åº¦é‡æŒ‡æ ‡æ— æ³•æœ‰æ•ˆè§£é‡Šæˆ–é¢„æµ‹ LLM çš„ä»£ç ç†è§£æˆåŠŸç‡ |\n| å½±å­æ¨¡å‹ (Shadow models) | 0.86 | æ­ç¤ºäº†æ¨¡å‹ç†è§£ä¸­å­˜åœ¨å¤æ‚çš„ã€éƒ¨åˆ†å¯é¢„æµ‹çš„éäººç±»æ¨¡å¼ |\n\n---",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Published in the Proceedings of DeepTest 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12951v1",
      "published_date": "2026-01-19 10:58:24 UTC",
      "updated_date": "2026-01-19 10:58:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:15.571180+00:00"
    },
    {
      "arxiv_id": "2601.12946v2",
      "title": "AI-generated data contamination erodes pathological variability and diagnostic reliability",
      "title_zh": "AIç”Ÿæˆæ•°æ®æ±¡æŸ“å‰Šå¼±äº†ç—…ç†å¤šæ ·æ€§ä¸è¯Šæ–­å¯é æ€§",
      "authors": [
        "Hongyu He",
        "Shaowen Xiang",
        "Ye Zhang",
        "Yingtao Zhu",
        "Jin Zhang",
        "Hao Deng",
        "Emily Alsentzer",
        "Qingyu Chen",
        "Kun-Hsing Yu",
        "Andrew Marshall",
        "Tingting Chen",
        "Srinivas Anumasa",
        "Daniel Ebner",
        "Dean Ho",
        "Kee Yuan Ngiam",
        "Ching-Yu Cheng",
        "Dianbo Liu"
      ],
      "abstract": "Generative artificial intelligence (AI) is rapidly populating medical records with synthetic content, creating a feedback loop where future models are increasingly at risk of training on uncurated AI-generated data. However, the clinical consequences of this AI-generated data contamination remain unexplored. Here, we show that in the absence of mandatory human verification, this self-referential cycle drives a rapid erosion of pathological variability and diagnostic reliability. By analysing more than 800,000 synthetic data points across clinical text generation, vision-language reporting, and medical image synthesis, we find that models progressively converge toward generic phenotypes regardless of the model architecture. Specifically, rare but critical findings, including pneumothorax and effusions, vanish from the synthetic content generated by AI models, while demographic representations skew heavily toward middle-aged male phenotypes. Crucially, this degradation is masked by false diagnostic confidence; models continue to issue reassuring reports while failing to detect life-threatening pathology, with false reassurance rates tripling to 40%. Blinded physician evaluation confirms that this decoupling of confidence and accuracy renders AI-generated documentation clinically useless after just two generations. We systematically evaluate three mitigation strategies, finding that while synthetic volume scaling fails to prevent collapse, mixing real data with quality-aware filtering effectively preserves diversity. Ultimately, our results suggest that without policy-mandated human oversight, the deployment of generative AI threatens to degrade the very healthcare data ecosystems it relies upon.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) å¯¼è‡´çš„æ•°æ®æ±¡æŸ“é—®é¢˜ï¼Œé€šè¿‡åˆ†æè¶…è¿‡ 800,000 ä¸ªåˆæˆæ•°æ®ç‚¹ï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨è‡ªå¼•ç”¨è®­ç»ƒå¾ªç¯ä¸­ä¼šå¯¼è‡´ç—…ç†å¤šæ ·æ€§å’Œè¯Šæ–­å¯é æ€§çš„å¿«é€Ÿä¸‹é™ã€‚ç ”ç©¶å‘ç°ï¼Œåˆæˆå†…å®¹ä¼šå‘é€šç”¨è¡¨å‹æ”¶æ•›ï¼Œå¯¼è‡´æ°”èƒ¸ (pneumothorax) å’Œç§¯æ¶² (effusions) ç­‰ç½•è§å…³é”®å‘ç°æ¶ˆå¤±ï¼Œä¸”äººå£ç»Ÿè®¡å­¦è¡¨ç°å‘ä¸­å¹´ç”·æ€§åç§»ã€‚è¿™ç§é€€åŒ–ä¼´éšç€è™šå‡çš„è¯Šæ–­ä¿¡å¿ƒï¼Œé”™è¯¯å®‰æ…°ç‡ (false reassurance rates) é£™å‡è‡³ 40%ï¼Œä¸”åŒ»ç”Ÿè¯„ä¼°æ˜¾ç¤º AI ç”Ÿæˆæ–‡æ¡£åœ¨ä¸¤ä¸ªè¿­ä»£å‘¨æœŸåå³å¤±å»ä¸´åºŠä»·å€¼ã€‚å®éªŒè¡¨æ˜ï¼Œå•çº¯æ‰©å¤§åˆæˆæ•°æ®è§„æ¨¡æ— æ³•é˜²æ­¢æ¨¡å‹å´©æºƒï¼Œè€Œå°†çœŸå®æ•°æ®ä¸è´¨é‡è¿‡æ»¤ (quality-aware filtering) ç›¸ç»“åˆèƒ½æœ‰æ•ˆä¿ç•™æ•°æ®å¤šæ ·æ€§ï¼Œå¼ºè°ƒäº†æ”¿ç­–å¼ºåˆ¶çš„äººå·¥ç›‘ç£å¯¹ç»´æŠ¤åŒ»ç–—æ•°æ®ç”Ÿæ€ç³»ç»Ÿçš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "*Corresponding author: Dianbo Liu (dianbo@nus.edu.sg)",
      "pdf_url": "https://arxiv.org/pdf/2601.12946v2",
      "published_date": "2026-01-19 10:54:03 UTC",
      "updated_date": "2026-01-21 11:06:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:01.231211+00:00"
    },
    {
      "arxiv_id": "2601.12939v1",
      "title": "Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design",
      "title_zh": "é¢å‘è‡ªé€‚åº”æ— äººæœºé›†ç¾¤è½¨è¿¹è®¾è®¡çš„ä¸»åŠ¨æ¨ç†é©±åŠ¨ä¸–ç•Œå»ºæ¨¡",
      "authors": [
        "Kaleem Arshid",
        "Ali Krayani",
        "Lucio Marcenaro",
        "David Martin Gomez",
        "Carlo Regazzoni"
      ],
      "abstract": "This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºä¸»åŠ¨æ¨ç† (Active Inference) çš„æ¡†æ¶ï¼Œç”¨äºæ— äººæœºé›†ç¾¤ (UAV Swarms) çš„è‡ªä¸»è½¨è¿¹è®¾è®¡ã€‚è¯¥æ–¹æ³•é€šè¿‡æ•´åˆæ¦‚ç‡æ¨ç†å’Œè‡ªæˆ‘å­¦ä¹ ï¼Œå®ç°äº†åˆ†å¸ƒå¼çš„ä»»åŠ¡åˆ†é…ã€è·¯å¾„æ’åºå’Œè¿åŠ¨è§„åˆ’ã€‚æ¡†æ¶åˆ©ç”¨å¸¦æœ‰æ–¥åŠ›å› å­çš„é—ä¼ ç®—æ³• (GA-RF) ç”Ÿæˆçš„ä¸“å®¶è½¨è¿¹æ¥è®­ç»ƒå±‚çº§åŒ–ä¸–ç•Œæ¨¡å‹ (World Model)ï¼Œä»è€Œæ•è·ä»»åŠ¡ã€èˆªçº¿åŠè¿åŠ¨ä¸‰ä¸ªå±‚çº§çš„é›†ç¾¤è¡Œä¸ºã€‚åœ¨åœ¨çº¿è¿è¡Œä¸­ï¼Œæ— äººæœºé€šè¿‡æœ€å°åŒ–å½“å‰ä¿¡å¿µä¸æ¨¡å‹é¢„æµ‹çŠ¶æ€ä¹‹é—´çš„æ•£åº¦æ¥æ¨æ–­åŠ¨ä½œï¼Œå®ç°äº†å¯¹åŠ¨æ€ç¯å¢ƒçš„è‡ªé€‚åº”å“åº”ã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œä¸ Q-Learning ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶å…·æœ‰æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ã€æ›´é«˜çš„ç¨³å®šæ€§å’Œå®‰å…¨æ€§ï¼Œè¯æ˜äº†å…¶åœ¨æ™ºèƒ½æ— äººæœºé›†ç¾¤æ§åˆ¶ä¸­çš„å¯æ‰©å±•æ€§å’Œè®¤çŸ¥åŸºç¡€ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper has been accepted for presentation at the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (IEEE ICASSP 2026) Workshop: 'Multi-Modal Signal Processing and AI for Communications and Sensing in 6G and Beyond (MuSiC-6GB)'",
      "pdf_url": "https://arxiv.org/pdf/2601.12939v1",
      "published_date": "2026-01-19 10:47:26 UTC",
      "updated_date": "2026-01-19 10:47:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:04.937810+00:00"
    },
    {
      "arxiv_id": "2601.12938v1",
      "title": "The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality",
      "title_zh": "åå›¾çµå¢ƒå†µï¼šäººå·¥ä¸»ä½“æ€§ä¸åˆæˆç¤¾ä¼šæ€§çš„æ¦‚å¿µåŒ–æ„å»º",
      "authors": [
        "Thorsten Jelinek",
        "Patrick Glauner",
        "Alvin Wang Graylin",
        "Yubao Qiu"
      ],
      "abstract": "In the Post-Turing era, artificial intelligence increasingly shapes social coordination and meaning formation rather than merely automating cognitive tasks. The central challenge is therefore not whether machines become conscious, but whether processes of interpretation and shared reference are progressively automated in ways that marginalize human participation. This paper introduces the PRMO framework, relating AI design trajectories to four constitutive dimensions of human subjectivity: Perception, Representation, Meaning, and the Real. Within this framework, Synthetic Sociality denotes a technological horizon in which artificial agents negotiate coherence and social order primarily among themselves, raising the structural risk of human exclusion from meaning formation. To address this risk, the paper proposes Quadrangulation as a design principle for socially embedded AI systems, requiring artificial agents to treat the human subject as a constitutive reference within shared contexts of meaning. This work is a conceptual perspective that contributes a structural vocabulary for analyzing AI systems at the intersection of computation and society, without proposing a specific technical implementation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åå›¾çµæ—¶ä»£ (Post-Turing era) äººå·¥æ™ºèƒ½å¦‚ä½•å½±å“ç¤¾ä¼šåè°ƒå’Œæ„ä¹‰æ„å»ºï¼ŒæŒ‡å‡ºæ ¸å¿ƒæŒ‘æˆ˜åœ¨äºè§£é‡Šå’Œå…±äº«å‚è€ƒè¿‡ç¨‹çš„è‡ªåŠ¨åŒ–å¯èƒ½å¯¼è‡´äººç±»å‚ä¸çš„è¾¹ç¼˜åŒ–ã€‚è®ºæ–‡å¼•å…¥äº† PRMO æ¡†æ¶ï¼Œå°† AI è®¾è®¡è½¨è¿¹ä¸äººç±»ä¸»ä½“æ€§çš„å››ä¸ªæ ¸å¿ƒç»´åº¦ï¼ˆPerception, Representation, Meaning å’Œ the Realï¼‰ç›¸è”ç³»ã€‚æ–‡ä¸­è¿›ä¸€æ­¥é˜è¿°äº†â€œåˆæˆç¤¾äº¤æ€§â€ (Synthetic Sociality) çš„æ¦‚å¿µï¼Œå³äººå·¥æ™ºèƒ½ä½“åœ¨å½¼æ­¤ä¹‹é—´åå•†ç¤¾ä¼šç§©åºï¼Œä»è€Œäº§ç”Ÿå°†äººç±»æ’é™¤åœ¨æ„ä¹‰å½¢æˆä¹‹å¤–çš„ç»“æ„æ€§é£é™©ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†â€œå››è§’å®šä½â€ (Quadrangulation) ä½œä¸ºç¤¾ä¼šåµŒå…¥å¼ AI ç³»ç»Ÿçš„å·¥ä½œåŸåˆ™ï¼Œè¦æ±‚ AI åœ¨å…±äº«è¯­å¢ƒä¸­å°†äººç±»ä¸»ä½“ä½œä¸ºæ„æˆæ€§å‚è€ƒï¼Œä¸ºç†è§£è®¡ç®—ä¸ç¤¾ä¼šäº¤é›†ä¸‹çš„ AI ç³»ç»Ÿæä¾›äº†é‡è¦çš„ç»“æ„æ€§è§†è§’ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Conceptual perspective on AI design trajectories, meaning formation, and synthetic sociality. 5 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2601.12938v1",
      "published_date": "2026-01-19 10:46:52 UTC",
      "updated_date": "2026-01-19 10:46:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:08.252220+00:00"
    },
    {
      "arxiv_id": "2601.12937v1",
      "title": "On the Evidentiary Limits of Membership Inference for Copyright Auditing",
      "title_zh": "è®ºç‰ˆæƒå®¡è®¡ä¸­æˆå‘˜æ¨ç†çš„è¯æ®å±€é™æ€§",
      "authors": [
        "Murat Bilgehan Ertan",
        "Emirhan BÃ¶ge",
        "Min Chen",
        "Kaleel Mahmood",
        "Marten van Dijk"
      ],
      "abstract": "As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. We ask whether MIAs can serve as admissible evidence in adversarial copyright disputes where an accused model developer may obfuscate training data while preserving semantic content, and formalize this setting through a judge-prosecutor-accused communication protocol. To test robustness under this protocol, we introduce SAGE (Structure-Aware SAE-Guided Extraction), a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Our experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that their signals are not robust to semantics-preserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as a standalone mechanism for copyright auditing of LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æˆå‘˜æ¨ç†æ”»å‡» (Membership Inference Attacks, MIAs) åœ¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) ç‰ˆæƒå®¡è®¡ä¸­ä½œä¸ºæ³•å¾‹è¯æ®çš„å±€é™æ€§ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªæ¨¡æ‹Ÿå¯¹æŠ—æ€§ç‰ˆæƒçº çº·çš„é€šä¿¡åè®®ã€‚ç ”ç©¶è€…æå‡ºäº† SAGE (Structure-Aware SAE-Guided Extraction) æ¡†æ¶ï¼Œåˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨ (Sparse Autoencoders, SAEs) æŒ‡å¯¼æ–‡æœ¬æ”¹å†™ï¼Œåœ¨ä¿ç•™è¯­ä¹‰å†…å®¹å’Œä¸‹æ¸¸æ•ˆç”¨çš„åŒæ—¶æ”¹å˜è®­ç»ƒæ•°æ®çš„è¯æ±‡ç»“æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“æ¨¡å‹åœ¨ç”± SAGE ç”Ÿæˆçš„æ”¹å†™æ–‡æœ¬ä¸Šè¿›è¡Œå¾®è°ƒæ—¶ï¼Œç°æœ‰çš„ MIAs è¯†åˆ«æ•ˆèƒ½æ˜¾è‘—ä¸‹é™ï¼Œè¯æ˜å…¶æ¢æµ‹ä¿¡å·å¯¹è¯­ä¹‰ä¿æŒå‹è½¬æ¢ç¼ºä¹é²æ£’æ€§ã€‚ç ”ç©¶ç»“è®ºè®¤ä¸ºï¼ŒMIAs åœ¨å¯¹æŠ—æ€§ç¯å¢ƒä¸‹å…·æœ‰è„†å¼±æ€§ï¼Œä¸è¶³ä»¥ç‹¬ç«‹ä½œä¸º LLMs ç‰ˆæƒå®¡è®¡çš„å¯é è¯æ®ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12937v1",
      "published_date": "2026-01-19 10:46:51 UTC",
      "updated_date": "2026-01-19 10:46:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:25.581515+00:00"
    },
    {
      "arxiv_id": "2601.12931v1",
      "title": "Online Continual Learning for Time Series: a Natural Score-driven Approach",
      "title_zh": "æ—¶é—´åºåˆ—åœ¨çº¿æŒç»­å­¦ä¹ ï¼šä¸€ç§è‡ªç„¶åˆ†å€¼é©±åŠ¨æ–¹æ³•",
      "authors": [
        "Edoardo Urettini",
        "Daniele Atzeni",
        "Ioanna-Yvonni Tsaknaki",
        "Antonio Carta"
      ],
      "abstract": "Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. Indeed, time-varying and regime-switching forecasting models have been extensively studied, offering a strong justification for the use of OCL in these settings. Building on recent work that applies OCL to OTSF, this paper aims to strengthen the theoretical and practical connections between time series methods and OCL. First, we reframe neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. Then, we show that using a Student's t likelihood in addition to natural gradient induces a bounded update, which improves robustness to outliers. Finally, we introduce Natural Score-driven Replay (NatSR), which combines our robust optimizer with a replay buffer and a dynamic scale heuristic that improves fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨çº¿æŒç»­å­¦ä¹ (Online Continual Learning, OCL)åœ¨åœ¨çº¿æ—¶é—´åºåˆ—é¢„æµ‹(Online Time Series Forecasting, OTSF)ä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨åŠ å¼ºä¸¤è€…ä¹‹é—´çš„ç†è®ºä¸å®è·µè”ç³»ã€‚ä½œè€…å°†ç¥ç»ç½‘ç»œä¼˜åŒ–é‡æ–°å®šä¹‰ä¸ºå‚æ•°æ»¤æ³¢(parameter filtering)é—®é¢˜ï¼Œè¯æ˜äº†è‡ªç„¶æ¢¯åº¦ä¸‹é™(Natural Gradient Descent)ä½œä¸ºä¸€ç§å¾—åˆ†é©±åŠ¨(score-driven)æ–¹æ³•å…·æœ‰ä¿¡æ¯è®ºæœ€ä¼˜æ€§ã€‚é€šè¿‡å¼•å…¥Student's tä¼¼ç„¶å‡½æ•°ï¼Œè¯¥æ–¹æ³•å®ç°äº†æœ‰ç•Œæ›´æ–°ï¼Œæ˜¾è‘—æå‡äº†å¯¹ç¦»ç¾¤å€¼(outliers)çš„é²æ£’æ€§ã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†Natural Score-driven Replay (NatSR)æ¡†æ¶ï¼Œç»“åˆé‡æ”¾ç¼“å†²åŒº(replay buffer)å’ŒåŠ¨æ€å°ºåº¦å¯å‘å¼æ–¹æ³•ï¼Œä¼˜åŒ–äº†æ¨¡å‹åœ¨çŠ¶æ€æ¼‚ç§»(regime drifts)æ—¶çš„å¿«é€Ÿé€‚åº”èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNatSRåœ¨é¢„æµ‹æ€§èƒ½ä¸Šä¼˜äºç°æœ‰çš„å¤šç§å¤æ‚å…ˆè¿›æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12931v1",
      "published_date": "2026-01-19 10:31:01 UTC",
      "updated_date": "2026-01-19 10:31:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:28.120729+00:00"
    },
    {
      "arxiv_id": "2601.12929v1",
      "title": "Membership Inference Test: Auditing Training Data in Object Classification Models",
      "title_zh": "æˆå‘˜æ¨ç†æµ‹è¯•ï¼šç›®æ ‡åˆ†ç±»æ¨¡å‹è®­ç»ƒæ•°æ®å®¡è®¡",
      "authors": [
        "Gonzalo Mancera",
        "Daniel DeAlcala",
        "Aythami Morales",
        "Ruben Tolosana",
        "Julian Fierrez"
      ],
      "abstract": "In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ†æäº†æˆå‘˜æ¨ç†æµ‹è¯• (Membership Inference Test, MINT) åœ¨ç›®æ ‡è¯†åˆ«é¢†åŸŸçš„åº”ç”¨ï¼Œæ—¨åœ¨å®¡è®¡ç‰¹å®šæ•°æ®æ˜¯å¦è¢«ç”¨äºæ¨¡å‹è®­ç»ƒã€‚ä½œè€…æå‡ºå¹¶å¼€å‘äº†ä¸“é—¨çš„ MINT æ¨¡å‹æ¶æ„ï¼Œåˆ©ç”¨å·ç§¯å±‚ (convolutional layers) æ•æ‰è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¿€æ´»æ¨¡å¼ï¼Œå¹¶ç»“åˆäº†ç›®æ ‡æ£€æµ‹æ¨¡å‹ä¸åµŒå…¥æå–å™¨ (embedding extractor)ã€‚åœ¨æ¶‰åŠè¶…è¿‡ 17.4 ä¸‡å¼ å›¾åƒçš„ä¸‰ä¸ªå…¬å¼€æ•°æ®åº“å®éªŒä¸­ï¼Œè¯¥æ¶æ„å®ç°äº† 70% è‡³ 80% çš„ç²¾ç¡®ç‡ï¼Œå…¶æ€§èƒ½è¡¨ç°å–å†³äºè¾“å…¥è‡³ MINT æ¨¡å—çš„æ£€æµ‹å±‚æ·±åº¦ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ¢è®¨äº†å½±å“ MINT æ¨¡å—çš„å…³é”®å› ç´ ï¼Œä¸ºæ„å»ºæ›´é€æ˜çš„æœºå™¨å­¦ä¹ è®­ç»ƒè¿‡ç¨‹æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Deployable AI (DAI 2025) workshop co-located with AAAI-25",
      "pdf_url": "https://arxiv.org/pdf/2601.12929v1",
      "published_date": "2026-01-19 10:30:53 UTC",
      "updated_date": "2026-01-19 10:30:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:34.291786+00:00"
    },
    {
      "arxiv_id": "2601.12925v1",
      "title": "ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation",
      "title_zh": "ForeDiffusionï¼šåŸºäºæœªæ¥è§†è§’æ„å»ºçš„æœºå™¨äººæ“ä½œå‰ç»æ¡ä»¶æ‰©æ•£ç­–ç•¥",
      "authors": [
        "Weize Xie",
        "Yi Ding",
        "Ying He",
        "Leilei Wang",
        "Binwen Bai",
        "Zheyi Zhao",
        "Chenyang Wang",
        "F. Richard Yu"
      ],
      "abstract": "Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. Analysis indicates that current diffusion strategies are confronted with two limitations. First, these strategies only rely on short-term observations as conditions. Second, the training objective remains limited to a single denoising loss, which leads to error accumulation and causes grasping deviations. To address these limitations, this paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), by injecting the predicted future view representation into the diffusion process. As a result, the policy is guided to be forward-looking, enabling it to correct trajectory deviations. Following this design, ForeDiffusion employs a dual loss mechanism, combining the traditional denoising loss and the consistency loss of future observations, to achieve the unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming the existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ForeDiffusionï¼Œä¸€ç§é€šè¿‡æ„å»ºæœªæ¥è§†å›¾æ¥å®ç°é¢„è§æ€§æ¡ä»¶çš„æ‰©æ•£ç­–ç•¥ (Foresight-Conditioned Diffusion Policy)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æœºå™¨äººæ“ä½œæ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­å› è¿‡åº¦ä¾èµ–çŸ­æœŸè§‚æµ‹å’Œå•ä¸€å»å™ªæŸå¤± (denoising loss) è€Œå¯¼è‡´çš„è¯¯å·®ç´¯ç§¯ä¸æŠ“å–åå·®é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†é¢„æµ‹çš„æœªæ¥è§†å›¾è¡¨ç¤ºæ³¨å…¥æ‰©æ•£è¿‡ç¨‹ï¼Œèµ‹äºˆç­–ç•¥å‰ç»æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆä¿®æ­£è½¨è¿¹åå·®ã€‚ForeDiffusion é‡‡ç”¨äº†åŒé‡æŸå¤±æœºåˆ¶ (dual loss mechanism)ï¼Œå°†ä¼ ç»Ÿçš„å»å™ªæŸå¤±ä¸æœªæ¥è§‚æµ‹çš„ä¸€è‡´æ€§æŸå¤± (consistency loss) ç»“åˆï¼Œå®ç°äº†ç»Ÿä¸€çš„ä¼˜åŒ–ç›®æ ‡ã€‚åœ¨ Adroit å¥—ä»¶å’Œ MetaWorld åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æˆåŠŸç‡æ¯”ä¸»æµæ‰©æ•£æ¨¡å‹æå‡äº† 23%ï¼Œå¹³å‡æˆåŠŸç‡è¾¾åˆ° 80%ï¼Œåœ¨å„ç±»ä»»åŠ¡ä¸­è¡¨ç°å‡ºæé«˜çš„ç¨³å®šæ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12925v1",
      "published_date": "2026-01-19 10:28:42 UTC",
      "updated_date": "2026-01-19 10:28:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:35.830853+00:00"
    },
    {
      "arxiv_id": "2601.12922v1",
      "title": "Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy",
      "title_zh": "ä½ çš„éšç§å–å†³äºä»–äººï¼šä¸ªä½“å·®åˆ†éšç§ä¸­çš„åˆè°‹æ¼æ´",
      "authors": [
        "Johannes Kaiser",
        "Alexander Ziller",
        "Eleni Triantafillou",
        "Daniel RÃ¼ckert",
        "Georgios Kaissis"
      ],
      "abstract": "Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. We reveal a previously overlooked vulnerability in sampling-based iDP mechanisms: while conforming to the iDP guarantees, an individual's privacy risk is not solely governed by their own privacy budget, but critically depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. We demonstrate empirically that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when their formal guarantees are met. Moreover, this excess risk provides an exploitable attack vector. A central adversary or a set of colluding adversaries can deliberately choose privacy budgets to amplify vulnerabilities of targeted individuals. Most importantly, this attack operates entirely within the guarantees of DP, hiding this excess vulnerability. Our empirical evaluation demonstrates successful attacks against 62% of targeted individuals, substantially increasing their membership inference susceptibility. To mitigate this, we propose $(\\varepsilon_i,Î´_i,\\overlineÎ”)$-iDP a privacy contract that uses $Î”$-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. Our findings expose a fundamental challenge to the current paradigm, demanding a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.",
      "tldr_zh": "è¯¥ç ”ç©¶æ­ç¤ºäº†ä¸ªä½“å·®åˆ†éšç§(Individual Differential Privacy, iDP)åœ¨åŸºäºæŠ½æ ·çš„æœºåˆ¶ä¸­å­˜åœ¨çš„ä¸€ä¸ªå…³é”®æ¼æ´ï¼šä¸ªä½“çš„éšç§é£é™©ä¸ä»…å–å†³äºå…¶è‡ªèº«çš„éšç§é¢„ç®—ï¼Œè¿˜æ·±å—å…¶ä»–æ•°æ®è´¡çŒ®è€…éšç§é€‰æ‹©çš„å½±å“ã€‚è¿™ç§æœºåˆ¶å…è®¸æ”»å‡»è€…æˆ–åˆè°‹è€…é€šè¿‡æ“çºµéšç§é¢„ç®—ï¼Œåœ¨å®Œå…¨ç¬¦åˆå·®åˆ†éšç§(DP)ä¿è¯çš„å‰æä¸‹ï¼Œæ”¾å¤§ç‰¹å®šä¸ªä½“çš„è„†å¼±æ€§å¹¶å®æ–½æ”»å‡»ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ”»å‡»æ‰‹æ®µåœ¨æˆå‘˜æ¨ç†(Membership Inference)æµ‹è¯•ä¸­å¯¹62%çš„ç›®æ ‡ä¸ªä½“å–å¾—äº†æˆåŠŸï¼Œæ˜¾è‘—æå‡äº†å…¶éšç§æš´éœ²é£é™©ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º$(\\varepsilon_i,Î´_i,\\overlineÎ”)$-iDPçš„éšç§å¥‘çº¦ï¼Œé€šè¿‡$\\Delta$-divergencesä¸ºç”¨æˆ·æä¾›æº¢å‡ºé£é™©çš„ç¡¬ä¸Šé™ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†é‡æ–°è¯„ä¼°iDPç³»ç»Ÿè®¾è®¡ã€å®¡è®¡åŠéƒ¨ç½²æ–¹å¼çš„ç´§è¿«æ€§ï¼Œä»¥ç¡®ä¿ä¸ªä½“çš„é¢å¤–éšç§é£é™©é€æ˜ä¸”å¯æ§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12922v1",
      "published_date": "2026-01-19 10:26:12 UTC",
      "updated_date": "2026-01-19 10:26:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:39.677148+00:00"
    },
    {
      "arxiv_id": "2601.12913v1",
      "title": "Actionable Interpretability Must Be Defined in Terms of Symmetries",
      "title_zh": "å¯æ“ä½œçš„å¯è§£é‡Šæ€§å¿…é¡»åŸºäºå¯¹ç§°æ€§è¿›è¡Œå®šä¹‰",
      "authors": [
        "Pietro Barbiero",
        "Mateo Espinosa Zarlenga",
        "Francesco Giannini",
        "Alberto Termine",
        "Filippo Bonchi",
        "Mateja Jamnik",
        "Giuseppe Marra"
      ],
      "abstract": "This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºå½“å‰äººå·¥æ™ºèƒ½é¢†åŸŸå…³äº Interpretability (å¯è§£é‡Šæ€§) çš„ç ”ç©¶ç”±äºå®šä¹‰ç¼ºä¹â€œè¡ŒåŠ¨åŠ›â€(Actionable) è€Œå­˜åœ¨å±€é™ï¼Œæ— æ³•ä¸ºå»ºæ¨¡å’Œæ¨ç†æä¾›å½¢å¼åŒ–çš„åŸåˆ™ã€‚è®ºæ–‡æå‡ºï¼Œå…·æœ‰è¡ŒåŠ¨åŠ›çš„å¯è§£é‡Šæ€§å¿…é¡»é€šè¿‡ Symmetries (å¯¹ç§°æ€§) æ¥å®šä¹‰ã€‚ä½œè€…å‡è®¾é€šè¿‡å››ç§å¯¹ç§°æ€§å¯ä»¥æœ‰æ•ˆé©±åŠ¨æ ¸å¿ƒå¯è§£é‡Šå±æ€§å¹¶åˆ»ç”»å¯è§£é‡Šæ¨¡å‹ç±»åˆ«ï¼Œä»è€Œå°† Alignment (å¯¹é½)ã€Interventions (å¹²é¢„) å’Œ Counterfactuals (åäº‹å®) ç­‰æ¨ç†è¿‡ç¨‹ç»Ÿä¸€è¡¨è¿°ä¸ºä¸€ç§ Bayesian inversion (è´å¶æ–¯åæ¼”) å½¢å¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12913v1",
      "published_date": "2026-01-19 10:10:17 UTC",
      "updated_date": "2026-01-19 10:10:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:41.570811+00:00"
    },
    {
      "arxiv_id": "2601.12912v1",
      "title": "Human Emotion Verification by Action Languages via Answer Set Programming",
      "title_zh": "åŸºäºå›ç­”é›†ç¨‹åºè®¾è®¡çš„åŠ¨ä½œè¯­è¨€äººç±»æƒ…æ„ŸéªŒè¯",
      "authors": [
        "Andreas BrÃ¤nnstrÃ¶m",
        "Juan Carlos Nieves"
      ],
      "abstract": "In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º C-MT (Mind Transition Language) çš„åŠ¨ä½œè¯­è¨€ï¼ŒåŸºäº Answer Set Programming (ASP) å’Œè½¬æ¢ç³»ç»Ÿï¼Œæ—¨åœ¨æ¨¡æ‹Ÿäººç±»å¿ƒç†çŠ¶æ€éšåŠ¨ä½œåºåˆ—çš„æ¼”å˜è¿‡ç¨‹ã€‚ç ”ç©¶å€Ÿé‰´äº†å¿ƒç†å­¦ä¸­çš„ Appraisal Theory of Emotionï¼Œå°†æƒ…ç»ªç­‰å¿ƒç†çŠ¶æ€å½¢å¼åŒ–ä¸ºå¤šç»´é…ç½®ï¼Œå¹¶å¼•å…¥äº†å…¨æ–°çš„ \"forbids to cause\" å› æœè§„åˆ™ä»¥é™åˆ¶éå¿…è¦çš„å¿ƒç†å‰¯ä½œç”¨ã€‚é€šè¿‡å°†å¿ƒç†å˜åŒ–åŸåˆ™è½¬åŒ–ä¸ºè½¬æ¢çº¦æŸå’Œä¸å˜æ€§å±æ€§ï¼Œè¯¥æ¡†æ¶å®ç°äº†å¯¹å¿ƒç†çŠ¶æ€åŠ¨æ€è½¨è¿¹çš„å—æ§æ¨ç†ã€‚è¯¥æ–¹æ³•æœ€ç»ˆè¢«åº”ç”¨äºè®¾è®¡ emotion verification æ¨¡å‹ï¼Œä¸ºåˆ†æå’Œæ¯”è¾ƒä¸åŒå¿ƒç†å­¦åŸåˆ™ä¸‹çš„çŠ¶æ€å˜åŒ–æä¾›äº†ç†è®ºä¸æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under consideration in Theory and Practice of Logic Programming (TPLP)",
      "pdf_url": "https://arxiv.org/pdf/2601.12912v1",
      "published_date": "2026-01-19 10:06:21 UTC",
      "updated_date": "2026-01-19 10:06:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:45.138590+00:00"
    },
    {
      "arxiv_id": "2601.12910v1",
      "title": "SciCoQA: Quality Assurance for Scientific Paper--Code Alignment",
      "title_zh": "SciCoQAï¼šç§‘å­¦è®ºæ–‡ä¸ä»£ç å¯¹é½çš„è´¨é‡ä¿éšœ",
      "authors": [
        "Tim BaumgÃ¤rtner",
        "Iryna Gurevych"
      ],
      "abstract": "We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\\% of real-world paper-code discrepancies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SciCoQAï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨æ£€æµ‹ç§‘å­¦è®ºæ–‡åŠå…¶ä»£ç åº“ä¹‹é—´å·®å¼‚ï¼ˆdiscrepanciesï¼‰çš„æ•°æ®é›†ï¼Œä»¥ç¡®ä¿å®ç°çš„å¿ å®åº¦ï¼ˆfaithful implementationsï¼‰ã€‚ç ”ç©¶äººå‘˜é€šè¿‡ GitHub issuesã€å¯é‡å¤æ€§è®ºæ–‡ä»¥åŠä¸€ç§åˆæˆæ•°æ®ç”Ÿæˆæ–¹æ³•æ„å»ºäº†è¯¥æ•°æ®é›†ï¼Œå…±åŒ…å« 611 ä¸ªæ¡ˆä¾‹ï¼ˆ81 ä¸ªçœŸå®æ¡ˆä¾‹ï¼Œ530 ä¸ªåˆæˆæ¡ˆä¾‹ï¼‰ï¼Œæ¶µç›–äººå·¥æ™ºèƒ½ã€ç‰©ç†ã€å®šé‡ç”Ÿç‰©å­¦ç­‰å¤šä¸ªè®¡ç®—ç§‘å­¦é¢†åŸŸã€‚é€šè¿‡å¯¹ 21 ç§å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¯„ä¼°ï¼Œå‘ç° SciCoQA å…·æœ‰æé«˜æŒ‘æˆ˜æ€§ï¼Œè¡¨ç°æœ€ä½³çš„ GPT-5 ä¹Ÿä»…èƒ½æ£€æµ‹å‡º 45.7% çš„çœŸå®å·®å¼‚ã€‚å®éªŒç»“æœæ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨å¤„ç†è®ºæ–‡ç»†èŠ‚é—æ¼ã€é•¿æ–‡æœ¬è¾“å…¥ï¼ˆlong-context inputsï¼‰ä»¥åŠè®­ç»ƒè¯­æ–™å¤–æ•°æ®æ—¶çš„å±€é™æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12910v1",
      "published_date": "2026-01-19 10:04:33 UTC",
      "updated_date": "2026-01-19 10:04:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:45.540221+00:00"
    },
    {
      "arxiv_id": "2601.12904v1",
      "title": "From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation",
      "title_zh": "ä»å‰ç¼€ç¼“å­˜åˆ°èåˆ RAG ç¼“å­˜ï¼šåŠ é€Ÿæ£€ç´¢å¢å¼ºç”Ÿæˆä¸­çš„å¤§è¯­è¨€æ¨¡å‹æ¨ç†",
      "authors": [
        "Jiahao Wang",
        "Weiyu Xie",
        "Mingxing Zhang",
        "Boxing Zhang",
        "Jianwei Dong",
        "Yuening Zhu",
        "Chen Lin",
        "Jinqi Tang",
        "Yaochen Han",
        "Zhiyuan Ai",
        "Xianglin Chen",
        "Yongwei Wu",
        "Congfeng Jiang"
      ],
      "abstract": "Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FusionRAGï¼Œä¸€ç§æ—¨åœ¨åŠ é€Ÿæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æ¨ç†è¿‡ç¨‹çš„æ–°å‹æ¡†æ¶ï¼Œè§£å†³äº†ç°æœ‰ KV cache å¤ç”¨æŠ€æœ¯å› ç¼ºä¹è·¨æ–‡æœ¬å—ä¸Šä¸‹æ–‡ä¿¡æ¯è€Œå¯¼è‡´çš„ç”Ÿæˆè´¨é‡ä¸‹é™é—®é¢˜ã€‚è¯¥æ¡†æ¶åœ¨ç¦»çº¿é¢„å¤„ç†é˜¶æ®µå°†ç›¸å…³æ–‡æœ¬å—çš„ä¿¡æ¯åµŒå…¥åˆ°æ¯ä¸ª chunk ä¸­ï¼Œå¹¶åœ¨åœ¨çº¿æ¨ç†é˜¶æ®µé’ˆå¯¹æ¨¡å‹å…³æ³¨çš„ç‰¹å®š token é‡æ–°è®¡ç®— KV cacheï¼Œä»è€Œåœ¨ç”Ÿæˆè´¨é‡ä¸æ•ˆç‡ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚å®éªŒè¡¨æ˜ï¼ŒFusionRAG åœ¨ä»…éœ€é‡æ–°è®¡ç®—ä¸åˆ° 15% token çš„æƒ…å†µä¸‹ï¼Œå…¶å½’ä¸€åŒ– F1 åˆ†æ•°æ¯”åŸºçº¿æ¨¡å‹é«˜å‡º 70%ï¼Œä¸”ç›¸æ¯” Full Attention å°†é¦–å­—ç”Ÿæˆå»¶è¿Ÿ (TTFT) é™ä½äº† 2.66 å€è‡³ 9.39 å€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12904v1",
      "published_date": "2026-01-19 09:59:39 UTC",
      "updated_date": "2026-01-19 09:59:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:49.278912+00:00"
    },
    {
      "arxiv_id": "2601.12893v1",
      "title": "AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs",
      "title_zh": "AdaNODEsï¼šåŸºäºç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹çš„æ—¶é—´åºåˆ—é¢„æµ‹æµ‹è¯•æ—¶è‡ªé€‚åº”",
      "authors": [
        "Ting Dang",
        "Soumyajit Chatterjee",
        "Hong Jia",
        "Yu Wu",
        "Flora Salim",
        "Fahim Kawsar"
      ],
      "abstract": "Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\\% and 28.4\\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AdaNODEsï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ä¸ºæ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆTime Series Forecastingï¼‰è®¾è®¡çš„æ— æºæµ‹è¯•æ—¶è‡ªé€‚åº”ï¼ˆSource-free Test Time Adaptation, TTAï¼‰æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥ç¥ç»å¾®åˆ†æ–¹ç¨‹ï¼ˆNeural Ordinary Differential Equations, NODEsï¼‰æ„å»ºè‡ªé€‚åº”æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ—¶é—´åºåˆ—ä¸­çš„åˆ†å¸ƒåç§»ï¼ˆDistribution Shiftsï¼‰é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§åˆ›æ–°çš„æŸå¤±å‡½æ•°ã€‚AdaNODEs ä»…éœ€æ›´æ–°å°‘é‡çš„æ¨¡å‹å‚æ•°ï¼Œèƒ½å¤Ÿé«˜æ•ˆæ•è·æ—¶é—´ä¾èµ–æ€§å¹¶æ˜¾è‘—é™ä½å†…å­˜å ç”¨ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å•ç»´å’Œé«˜ç»´æ•°æ®é›†ä¸Šåˆ†åˆ«æ¯” SOTA æ¨¡å‹æå‡äº† 5.88% å’Œ 28.4%ï¼Œå±•ç°äº†åœ¨ä¸¥è‹›åˆ†å¸ƒåç§»ç¯å¢ƒä¸‹çš„å¼ºå¤§é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12893v1",
      "published_date": "2026-01-19 09:46:54 UTC",
      "updated_date": "2026-01-19 09:46:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:41:52.748531+00:00"
    },
    {
      "arxiv_id": "2601.12886v1",
      "title": "Communication Methods in Multi-Agent Reinforcement Learning",
      "title_zh": "å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„é€šä¿¡æ–¹æ³•",
      "authors": [
        "Christoph Wittner"
      ],
      "abstract": "Multi-agent reinforcement learning is a promising research area that extends established reinforcement learning approaches to problems formulated as multi-agent systems. Recently, a multitude of communication methods have been introduced to this field to address problems such as partially observable environments, non-stationarity, and exponentially growing action spaces. Communication further enables efficient cooperation among all agents interacting in an environment. This work aims at providing an overview of communication techniques in multi-agent reinforcement learning. By an in-depth analysis of 29 publications on this topic, the strengths and weaknesses of explicit, implicit, attention-based, graph-based, and hierarchical/role-based communication are evaluated. The results of this comparison show that there is no general, optimal communication framework for every problem. On the contrary, the choice of communication depends heavily on the problem at hand. The comparison also highlights the importance of communication methods with low computational overhead to enable scalability to environments where many agents interact. Finally, the paper discusses current research gaps, emphasizing the need for standardized benchmarking of system-level metrics and improved robustness under realistic communication conditions to enhance the real-world applicability of these approaches.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿåœ°å›é¡¾äº†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (Multi-Agent Reinforcement Learning, MARL) ä¸­çš„é€šä¿¡æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³éƒ¨åˆ†å¯è§‚æµ‹ç¯å¢ƒã€éå¹³ç¨³æ€§å’ŒåŠ¨ä½œç©ºé—´çˆ†ç‚¸ç­‰æ ¸å¿ƒæŒ‘æˆ˜ã€‚ç ”ç©¶é€šè¿‡å¯¹29ç¯‡å­¦æœ¯æ–‡çŒ®çš„æ·±å…¥åˆ†æï¼Œè¯„ä¼°äº†æ˜¾å¼ (explicit)ã€éšå¼ (implicit)ã€åŸºäºæ³¨æ„åŠ› (attention-based)ã€åŸºäºå›¾ (graph-based) ä»¥åŠåŸºäºåˆ†å±‚/è§’è‰² (hierarchical/role-based) ç­‰ä¸åŒé€šä¿¡æŠ€æœ¯çš„ä¼˜åŠ£ã€‚æ¯”è¾ƒç»“æœè¡¨æ˜ï¼Œç›®å‰å°šä¸å­˜åœ¨é€šç”¨çš„æœ€ä¼˜é€šä¿¡æ¡†æ¶ï¼Œå…¶é€‰æ‹©é«˜åº¦ä¾èµ–äºå…·ä½“é—®é¢˜ã€‚ç ”ç©¶å¼ºè°ƒï¼Œä½è®¡ç®—å¼€é”€çš„é€šä¿¡æ–¹æ³•å¯¹äºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ (scalability) è‡³å…³é‡è¦ã€‚æœ€åï¼Œè®ºæ–‡æŒ‡å‡ºäº†å½“å‰åœ¨ç³»ç»Ÿçº§æŒ‡æ ‡æ ‡å‡†åŒ–åŸºå‡†æµ‹è¯•ä»¥åŠçœŸå®é€šä¿¡ç¯å¢ƒä¸‹çš„ç¨³å¥æ€§ (robustness) ç­‰æ–¹é¢çš„ç ”ç©¶ç©ºç™½ï¼Œä¸ºæå‡ç›¸å…³ç®—æ³•çš„ç°å®åº”ç”¨ä»·å€¼æä¾›äº†æŒ‡å¼•ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "12 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12886v1",
      "published_date": "2026-01-19 09:39:00 UTC",
      "updated_date": "2026-01-19 09:39:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:02.478595+00:00"
    },
    {
      "arxiv_id": "2601.12882v1",
      "title": "YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection",
      "title_zh": "YOLO26ï¼šé¢å‘å®æ—¶ç›®æ ‡æ£€æµ‹çš„æ—  NMS ç«¯åˆ°ç«¯æ¡†æ¶åˆ†æ",
      "authors": [
        "Sudip Chakrabarty"
      ],
      "abstract": "The \"You Only Look Once\" (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations (YOLOv1 through YOLO11) remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes a comprehensive analysis of YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. This study examines the critical innovations that enable this transition, specifically the introduction of the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through a systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors (including RTMDet and DAMO-YOLO) in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ†æäº† YOLO26ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨å½»åº•æ”¹å˜å®æ—¶ç›®æ ‡æ£€æµ‹èŒƒå¼çš„ç«¯åˆ°ç«¯(End-to-End)æ¡†æ¶ï¼Œé€šè¿‡æ¶ˆé™¤éæå¤§å€¼æŠ‘åˆ¶(NMS)åå¤„ç†è§£å†³äº†ä¼ ç»Ÿ YOLO ç³»åˆ—çš„å»¶è¿Ÿå’Œè¶…å‚æ•°æ•æ„Ÿæ€§é—®é¢˜ã€‚è¯¥æ¶æ„å¼•å…¥äº†ç”¨äºç¨³å®šè½»é‡çº§ä¸»å¹²ç½‘ç»œçš„ MuSGD ä¼˜åŒ–å™¨ã€é’ˆå¯¹å°ç›®æ ‡æ„ŸçŸ¥åˆ†é…çš„ STAL æŠ€æœ¯ä»¥åŠåŠ¨æ€ç›‘ç£çš„ ProgLoss æŸå¤±å‡½æ•°ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒYOLO26 åœ¨æ¨ç†é€Ÿåº¦å’Œæ£€æµ‹ç²¾åº¦ä¸Šå‡å»ºç«‹äº†æ–°çš„å¸•ç´¯æ‰˜å‰æ²¿(Pareto front)ï¼Œè¡¨ç°ä¼˜äº RTMDet å’Œ DAMO-YOLO ç­‰å…ˆè¿›æ¨¡å‹ã€‚é€šè¿‡å°†è¡¨ç¤ºå­¦ä¹ ä¸å¯å‘å¼åå¤„ç†è§£è€¦ï¼ŒYOLO26 æˆåŠŸè§£å†³äº†å»¶è¿Ÿä¸ç²¾åº¦ä¹‹é—´çš„æƒè¡¡ï¼Œæ ‡å¿—ç€è¾¹ç¼˜ä¾§è®¡ç®—æœºè§†è§‰æŠ€æœ¯çš„åˆä¸€æ¬¡é‡è¦è¿›åŒ–ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12882v1",
      "published_date": "2026-01-19 09:36:08 UTC",
      "updated_date": "2026-01-19 09:36:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:15.534992+00:00"
    },
    {
      "arxiv_id": "2601.12879v1",
      "title": "Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition",
      "title_zh": "åŸºäºå¯æ‰©å±•å½’å› å›¾åˆ†è§£çš„åäº¿å‚æ•°è¯­è¨€æ¨¡å‹å±‚çº§ç¨€ç–ç”µè·¯æå–",
      "authors": [
        "Mohammed Mudassir Uddin",
        "Shahnawaz Alam",
        "Mohammed Kaif Pasha"
      ],
      "abstract": "Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation ($\\pm$2.3\\% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å±‚æ¬¡åŒ–å½’å› å›¾åˆ†è§£ (Hierarchical Attribution Graph Decomposition, HAGD) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä»åäº¿å‚æ•°é‡çº§è¯­è¨€æ¨¡å‹ä¸­æå–ç¨€ç–è®¡ç®—ç”µè·¯æ—¶é¢ä¸´çš„æŒ‡æ•°çº§æœç´¢å¤æ‚åº¦å’Œå¤šä¹‰æ€§ (polysemanticity) æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å¤šåˆ†è¾¨ç‡æŠ½è±¡å±‚æ¬¡å’Œå¯å¾®åˆ†ç”µè·¯æœç´¢ï¼ŒæˆåŠŸå°†ç”µè·¯å‘ç°å¤æ‚åº¦ä» $O(2^n)$ é™ä½è‡³ $O(n^2 \\log n)$ã€‚HAGD é›†æˆäº†è·¨å±‚è½¬ç å™¨ (cross-layer transcoders) ä»¥æå–å•è¯­ä¹‰ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨å›¾ç¥ç»ç½‘ç»œ (GNN) å…ƒå­¦ä¹ è¿›è¡Œæ‹“æ‰‘é¢„æµ‹å’Œå› æœå¹²é¢„éªŒè¯ã€‚åœ¨ Llama-70B ç­‰å¤§å‹æ¨¡å‹ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨ä¿æŒå­å›¾å¯è§£é‡Šæ€§çš„åŒæ—¶ï¼Œèƒ½å®ç°é«˜è¾¾ 91% çš„è¡Œä¸ºä¿ç•™ç‡ï¼Œå¹¶æ­ç¤ºäº†è·¨æ¶æ„æ¨¡å‹é—´å­˜åœ¨çº¦ 67% çš„ç»“æ„ç›¸ä¼¼æ€§ï¼Œä¸ºå¤§è§„æ¨¡æ¨¡å‹çš„å¯è§£é‡Šæ€§ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12879v1",
      "published_date": "2026-01-19 09:34:10 UTC",
      "updated_date": "2026-01-19 09:34:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:16.168649+00:00"
    },
    {
      "arxiv_id": "2601.14311v1",
      "title": "Tracing the Data Trail: A Survey of Data Provenance, Transparency and Traceability in LLMs",
      "title_zh": "è¿½è¸ªæ•°æ®è¶³è¿¹ï¼šå¤§è¯­è¨€æ¨¡å‹æ•°æ®æº¯æºã€é€æ˜åº¦ä¸å¯è¿½æº¯æ€§ç»¼è¿°",
      "authors": [
        "Richard Hohensinner",
        "Belgin Mutlu",
        "Inti Gabriel Mendoza Estrada",
        "Matej Vukovic",
        "Simone Kopeinik",
        "Roman Kern"
      ],
      "abstract": "Large language models (LLMs) are deployed at scale, yet their training data life cycle remains opaque. This survey synthesizes research from the past ten years on three tightly coupled axes: (1) data provenance, (2) transparency, and (3) traceability, and three supporting pillars: (4) bias \\& uncertainty, (5) data privacy, and (6) tools and techniques that operationalize them. A central contribution is a proposed taxonomy defining the field's domains and listing corresponding artifacts. Through analysis of 95 publications, this work identifies key methodologies concerning data generation, watermarking, bias measurement, data curation, data privacy, and the inherent trade-off between transparency and opacity.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿæ€»ç»“äº†è¿‡å»åå¹´å…³äºå¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ•°æ®æ¥æº(Data Provenance)ã€é€æ˜åº¦(Transparency)å’Œå¯è¿½æº¯æ€§(Traceability)ä¸‰ä¸ªæ ¸å¿ƒç»´åº¦çš„ç ”ç©¶ã€‚è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåˆ†ç±»æ³•(Taxonomy)ï¼Œæ˜ç¡®äº†è¯¥é¢†åŸŸçš„å„å­é¢†åŸŸåŠç›¸åº”çš„å·¥ä»¶(Artifacts)ï¼Œå¹¶æ¢è®¨äº†åè§ä¸ä¸ç¡®å®šæ€§ã€æ•°æ®éšç§ä»¥åŠç›¸å…³å·¥å…·ç­‰æ”¯æ’‘æ”¯æŸ±ã€‚é€šè¿‡å¯¹95ç¯‡æ–‡çŒ®çš„æ·±å…¥åˆ†æï¼Œè¯¥ç ”ç©¶è¯†åˆ«äº†æ•°æ®ç”Ÿæˆã€æ°´å°(Watermarking)ã€åå·®æµ‹é‡å’Œæ•°æ®æ¸…æ´—(Data Curation)ç­‰å…³é”®æ–¹æ³•è®ºã€‚æœ€åï¼Œæ–‡ç« æ­ç¤ºäº†é€æ˜åº¦ä¸ä¸é€æ˜æ€§ä¹‹é—´å›ºæœ‰çš„æƒè¡¡å…³ç³»ï¼Œä¸ºç†è§£LLMè®­ç»ƒæ•°æ®ç”Ÿå‘½å‘¨æœŸæä¾›äº†é‡è¦çš„ç†è®ºæ¡†æ¶ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "35 pages, 6 figures. Manuscript submitted to ACM Computing Surveys (CSUR) on the 12th of December 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.14311v1",
      "published_date": "2026-01-19 09:14:00 UTC",
      "updated_date": "2026-01-19 09:14:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:14.794459+00:00"
    },
    {
      "arxiv_id": "2601.12856v1",
      "title": "Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data",
      "title_zh": "åŸºäºå¼€æ”¾ç½‘ç»œæ•°æ®ä¸­çš„çƒ­ç‚¹åŠ¨æ€æŒ–æ˜ Singapore å…¨å¸‚ç™»é©çƒ­ä¼ æ’­æ¨¡å¼",
      "authors": [
        "Liping Huang",
        "Gaoxi Xiao",
        "Stefan Ma",
        "Hechang Chen",
        "Shisong Tang",
        "Flora Salim"
      ],
      "abstract": "Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å…¬å¼€çš„ç½‘ç»œæ•°æ®æŒ–æ˜æ–°åŠ å¡åŸå¸‚èŒƒå›´å†…çš„ç™»é©çƒ­ï¼ˆDengueï¼‰ä¼ æ’­æ¨¡å¼ã€‚è¯¥æ–¹æ³•ä¸å†å°†ç—…ä¾‹è§†ä¸ºå­¤ç«‹æŠ¥å‘Šï¼Œè€Œæ˜¯é€šè¿‡å»ºæ¨¡ä¸åŒåŒºåŸŸé—´çš„çƒ­ç‚¹ï¼ˆHotspotï¼‰åŠ¨æ€ï¼Œæ­ç¤ºäº†å—äººç±»æµåŠ¨ï¼ˆhuman mobilityï¼‰é©±åŠ¨çš„æ½œåœ¨çº¿æ€§ä¼ æ’­é“¾æ¥ã€‚ç ”ç©¶åˆ©ç”¨æ¢¯åº¦ä¸‹é™ï¼ˆgradient descentï¼‰ä¼˜åŒ–è¿™äº›éšè—é“¾æ¥ï¼Œå¹¶ç»“åˆå†å²æ•°æ®è¿›è¡Œçƒ­ç‚¹çŠ¶æ€é¢„æµ‹ï¼Œå®éªŒæ˜¾ç¤ºä»…éœ€å››å‘¨çš„å†å²çƒ­ç‚¹è®°å½•å³å¯è¾¾åˆ° 0.79 çš„å¹³å‡ F-scoreã€‚ç ”ç©¶å‘ç°æ‰€å­¦ä¹ çš„ä¼ æ’­é“¾æ¥ä¸é€šå‹¤æµï¼ˆcommuting flowsï¼‰é«˜åº¦ä¸€è‡´ï¼Œä¸ºæµè¡Œç—…å»ºæ¨¡æä¾›äº†ä¸€ç§å…·æœ‰é«˜åº¦å¯è§£é‡Šæ€§ä¸”ä½æˆæœ¬çš„é¢„æµ‹å·¥å…·ï¼Œæœ‰åŠ©äºæå‡åŸå¸‚å…¬å…±å«ç”Ÿçš„é¢„è­¦ä¸å¤åŸèƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 9 figures. It's accepted by WWW 2026 Web4Good Track. To make accessible earlier, authors would like to put it on arxiv before the conference",
      "pdf_url": "https://arxiv.org/pdf/2601.12856v1",
      "published_date": "2026-01-19 09:10:50 UTC",
      "updated_date": "2026-01-19 09:10:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:17.659072+00:00"
    },
    {
      "arxiv_id": "2601.12849v1",
      "title": "The Cost of EFX: Generalized-Mean Welfare and Complexity Dichotomies with Few Surplus Items",
      "title_zh": "EFX çš„ä»£ä»·ï¼šå°‘é‡å‰©ä½™ç‰©å“æƒ…å½¢ä¸‹çš„å¹¿ä¹‰å‡å€¼ç¦åˆ©ä¸å¤æ‚åº¦äºŒåˆ†æ€§",
      "authors": [
        "Eugene Lim",
        "Tzeh Yuan Neoh",
        "Nicholas Teh"
      ],
      "abstract": "Envy-freeness up to any good (EFX) is a central fairness notion for allocating indivisible goods, yet its existence is unresolved in general. In the setting with few surplus items, where the number of goods exceeds the number of agents by a small constant (at most three), EFX allocations are guaranteed to exist, shifting the focus from existence to efficiency and computation. We study how EFX interacts with generalized-mean ($p$-mean) welfare, which subsumes commonly-studied utilitarian ($p=1$), Nash ($p=0$), and egalitarian ($p \\rightarrow -\\infty$) objectives. We establish sharp complexity dichotomies at $p=0$: for any fixed $p \\in (0,1]$, both deciding whether EFX can attain the global $p$-mean optimum and computing an EFX allocation maximizing $p$-mean welfare are NP-hard, even with at most three surplus goods; in contrast, for any fixed $p \\leq 0$, we give polynomial-time algorithms that optimize $p$-mean welfare within the space of EFX allocations and efficiently certify when EFX attains the global optimum. We further quantify the welfare loss of enforcing EFX via the price of fairness framework, showing that for $p > 0$, the loss can grow linearly with the number of agents, whereas for $p \\leq 0$, it is bounded by a constant depending on the surplus (and for Nash welfare it vanishes asymptotically). Finally we show that requiring Pareto-optimality alongside EFX is NP-hard (and becomes $Î£_2^P$-complete for a stronger variant of EFX). Overall, our results delineate when EFX is computationally costly versus structurally aligned with welfare maximization in the setting with few surplus items.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å°‘æ•°å‰©ä½™ç‰©å“ï¼ˆFew Surplus Itemsï¼‰åœºæ™¯ä¸‹ï¼Œå…¬å¹³åˆ†é…æ¦‚å¿µ Envy-freeness up to any good (EFX) ä¸å¹¿ä¹‰å‡å€¼ç¦åˆ©ï¼ˆGeneralized-Mean Welfareï¼Œ$p$-mean welfareï¼‰ä¹‹é—´çš„æƒè¡¡ä¸è®¡ç®—å¤æ‚åº¦ã€‚ç ”ç©¶æ­ç¤ºäº†åœ¨ $p=0$ å¤„å­˜åœ¨è®¡ç®—å¤æ‚åº¦äºŒåˆ†æ€§ï¼šå½“ $p \\in (0,1]$ æ—¶ï¼Œå¯»æ‰¾æœ€å¤§åŒ– $p$-mean ç¦åˆ©çš„ EFX åˆ†é…å±äº NP-hard é—®é¢˜ï¼›è€Œå½“ $p \\le 0$ æ—¶ï¼ˆåŒ…å« Nash ç¦åˆ©å’Œå…¬å¹³ä¸»ä¹‰ç›®æ ‡ï¼‰ï¼Œåˆ™å­˜åœ¨å¤šé¡¹å¼æ—¶é—´ç®—æ³•å®ç°ä¼˜åŒ–å¹¶éªŒè¯å…¨å±€æœ€ä¼˜æ€§ã€‚åœ¨å…¬å¹³æ€§ä»£ä»·ï¼ˆPrice of Fairnessï¼‰æ–¹é¢ï¼Œç ”ç©¶è¡¨æ˜ $p \\le 0$ æ—¶çš„ç¦åˆ©æŸå¤±è¿œå°äº $p > 0$ çš„æƒ…å†µï¼Œåè€…æŸå¤±éšä»£ç†äººæ•°é‡çº¿æ€§å¢é•¿ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¯æ˜äº†åœ¨è¦æ±‚ EFX çš„åŒæ—¶æ»¡è¶³ Pareto-optimality åŒæ ·å…·æœ‰é«˜åº¦çš„è®¡ç®—å¤æ‚æ€§ï¼ˆNP-hard ç”šè‡³ $\\Sigma_2^P$-completeï¼‰ï¼Œç³»ç»Ÿåœ°ç•Œå®šäº† EFX åœ¨æ•ˆç‡å’Œè®¡ç®—ä¸Šçš„è¾¹ç•Œã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12849v1",
      "published_date": "2026-01-19 09:02:32 UTC",
      "updated_date": "2026-01-19 09:02:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:20.268107+00:00"
    },
    {
      "arxiv_id": "2601.12842v1",
      "title": "SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning",
      "title_zh": "SCULPTï¼šé€šè¿‡çº¦æŸå¼•å¯¼å‰ªæ MCTS ä¸ºæ•°å­¦æ¨ç†å¼€è¾Ÿé«˜æ•ˆè·¯å¾„",
      "authors": [
        "Qitong Fang",
        "Haotian Li",
        "Xu Wang"
      ],
      "abstract": "Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SCULPTï¼Œä¸€ç§é’ˆå¯¹æ•°å­¦æ¨ç†è®¾è®¡çš„çº¦æŸå¼•å¯¼å‰ªæå‹ Monte Carlo Tree Search (MCTS) æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¤§è¯­è¨€æ¨¡å‹ (LLMs) æ™ºèƒ½ä½“å·¥ä½œæµå› éšæœºæ¢ç´¢å’Œç¼ºä¹é¢†åŸŸå…ˆéªŒè€Œå¯¼è‡´æœç´¢æ— æ•ˆåˆ†æ”¯çš„é—®é¢˜ã€‚SCULPT å°†é¢†åŸŸæ„ŸçŸ¥è¯„åˆ†é›†æˆåˆ°æœç´¢çš„å„ä¸ªé˜¶æ®µï¼Œé€šè¿‡ç»“åˆç¬¦å·æ£€æŸ¥ï¼ˆåŒ…æ‹¬ dimensional consistencyã€type compatibilityã€magnitude sanityã€depth control å’Œ diversityï¼‰ä¸ç»“æ„åŒ–æ¨¡å¼å¼•å¯¼æ¥å¯¹è¡ŒåŠ¨è¿›è¡Œè¯„åˆ†å’Œå‰ªæï¼Œä»è€Œå¼•å¯¼æœç´¢èµ°å‘åˆç†çš„æ¨ç†è·¯å¾„ã€‚åœ¨å¤šé¡¹æ•°æ®é›†ä»¥åŠ GPT-5.2 ç­‰æ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSCULPT åœ¨ä¿æŒæ•ˆç‡çš„åŒæ—¶æ˜¾è‘—æå‡äº†å¤æ‚æ¨ç†ä»»åŠ¡çš„å‡†ç¡®æ€§ä¸ç¨³å®šæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 3 figures. Equal contribution: Qitong Fang and Haotian Li. Corresponding authors: Qitong Fang (fangqitong@student.jlju.edu.cn), Haotian Li (lihaotian@student.jlju.edu.cn), Xu Wang (wangxu@jlju.edu.cn)",
      "pdf_url": "https://arxiv.org/pdf/2601.12842v1",
      "published_date": "2026-01-19 08:55:46 UTC",
      "updated_date": "2026-01-19 08:55:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:25.129423+00:00"
    },
    {
      "arxiv_id": "2601.12837v1",
      "title": "Cognition spaces: natural, artificial, and hybrid",
      "title_zh": "è®¤çŸ¥ç©ºé—´ï¼šè‡ªç„¶ã€äººå·¥ä¸æ··åˆ",
      "authors": [
        "Ricard SolÃ©",
        "Luis F Seoane",
        "Jordi Pla-Mauri",
        "Michael Timothy Bennett",
        "Michael E. Hochberg",
        "Michael Levin"
      ],
      "abstract": "Cognitive processes are realized across an extraordinary range of natural, artificial, and hybrid systems, yet there is no unified framework for comparing their forms, limits, and unrealized possibilities. Here, we propose a cognition space approach that replaces narrow, substrate-dependent definitions with a comparative representation based on organizational and informational dimensions. Within this framework, cognition is treated as a graded capacity to sense, process, and act upon information, allowing systems as diverse as cells, brains, artificial agents, and human-AI collectives to be analyzed within a common conceptual landscape. We introduce and examine three cognition spaces -- basal aneural, neural, and human-AI hybrid -- and show that their occupation is highly uneven, with clusters of realized systems separated by large unoccupied regions. We argue that these voids are not accidental but reflect evolutionary contingencies, physical constraints, and design limitations. By focusing on the structure of cognition spaces rather than on categorical definitions, this approach clarifies the diversity of existing cognitive systems and highlights hybrid cognition as a promising frontier for exploring novel forms of complexity beyond those produced by biological evolution.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†è®¤çŸ¥ç©ºé—´ (Cognition Spaces) çš„æ–¹æ³•ï¼Œæ—¨åœ¨ä¸ºæ¯”è¾ƒè‡ªç„¶ã€äººå·¥åŠæ··åˆç³»ç»Ÿçš„è®¤çŸ¥å½¢å¼å’Œé™åˆ¶æä¾›ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ‘’å¼ƒäº†ä¾èµ–äºç‰¹å®šåŸºè´¨çš„ç‹­éš˜å®šä¹‰ï¼Œè½¬è€ŒåŸºäºç»„ç»‡å’Œä¿¡æ¯ç»´åº¦ï¼Œå°†è®¤çŸ¥è§†ä¸ºä¸€ç§æ„ŸçŸ¥ã€å¤„ç†å’Œå¯¹ä¿¡æ¯åšå‡ºååº”çš„ç­‰çº§åŒ–èƒ½åŠ›ã€‚é€šè¿‡å¯¹åŸºç¡€æ— ç¥ç» (Basal aneural)ã€ç¥ç» (Neural) å’Œäººç±»-AI æ··åˆ (Human-AI hybrid) ä¸‰ç§è®¤çŸ¥ç©ºé—´çš„åˆ†æï¼Œç ”ç©¶å‘ç°è¿™äº›ç©ºé—´çš„åˆ†å¸ƒæä¸å‡åŒ€ï¼Œå­˜åœ¨ç”±æ¼”åŒ–å¶ç„¶æ€§ã€ç‰©ç†çº¦æŸå’Œè®¾è®¡é™åˆ¶å¯¼è‡´çš„å·¨å¤§ç©ºç™½åŒºåŸŸã€‚è¿™ä¸€ç ”ç©¶ä¸ä»…é˜æ˜äº†ç°æœ‰è®¤çŸ¥ç³»ç»Ÿçš„å¤šæ ·æ€§ï¼Œè¿˜æŒ‡å‡ºæ··åˆè®¤çŸ¥æ˜¯æ¢ç´¢è¶…è¶Šç”Ÿç‰©æ¼”åŒ–äº§ç”Ÿçš„æ–°å‹å¤æ‚æ€§å½¢å¼çš„é‡è¦å‰æ²¿ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.HC",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12837v1",
      "published_date": "2026-01-19 08:50:18 UTC",
      "updated_date": "2026-01-19 08:50:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:28.202021+00:00"
    },
    {
      "arxiv_id": "2601.12822v1",
      "title": "MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction",
      "title_zh": "MirrorGuardï¼šé€šè¿‡ä»æ¨¡æ‹Ÿåˆ°ç°å®çš„æ¨ç†çº æ­£æ„å»ºå®‰å…¨çš„è®¡ç®—æœºä½¿ç”¨æ™ºèƒ½ä½“",
      "authors": [
        "Wenqi Zhang",
        "Yulin Shen",
        "Changyue Jiang",
        "Jiarun Dai",
        "Geng Hong",
        "Xudong Pan"
      ],
      "abstract": "Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MirrorGuardï¼Œä¸€ä¸ªå³æ’å³ç”¨çš„é˜²å¾¡æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è®¡ç®—æœºä½¿ç”¨ä»£ç† (Computer-Use Agents, CUAs) åœ¨æ‰§è¡Œè‡ªåŠ¨åŒ–ä»»åŠ¡æ—¶é¢ä¸´çš„æ¶æ„æŒ‡ä»¤å’Œè§†è§‰æç¤ºæ³¨å…¥ç­‰å®‰å…¨é£é™©ã€‚MirrorGuard é‡‡ç”¨äº†ä¸€ç§åˆ›æ–°çš„ç¥ç»ç¬¦å·æ¨¡æ‹Ÿ (neural-symbolic simulation) æµæ°´çº¿ï¼Œåœ¨çº¯æ–‡æœ¬æ¨¡æ‹Ÿç¯å¢ƒä¸­ç”Ÿæˆé«˜é£é™© GUI äº¤äº’è½¨è¿¹ï¼Œä»è€Œåœ¨ä¸æ‰§è¡Œå®é™…æ“ä½œçš„æƒ…å†µä¸‹è¯†åˆ«å¹¶çº æ­£æ™ºèƒ½ä½“ä¸å®‰å…¨çš„æ¨ç†é“¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ UI-TARS ç³»ç»Ÿä¸Šï¼Œè¯¥æ¡†æ¶å°†ä¸å®‰å…¨ç‡ä» 66.5% æ˜¾è‘—é™ä½è‡³ 13.0%ï¼Œåœ¨é™ä½é£é™©çš„åŒæ—¶ä¿æŒäº†æä½çš„é”™è¯¯æ‹’ç»ç‡ (False Refusal Rate)ã€‚è¯¥å·¥ä½œè¯æ˜äº†åŸºäºæ¨¡æ‹Ÿç”Ÿæˆçš„é˜²å¾¡æœºåˆ¶èƒ½å¤Ÿä¸ºçœŸå®ä¸–ç•Œä¸­çš„æ™ºèƒ½ä½“æä¾›ç¨³å¥çš„å®‰å…¨ä¿éšœï¼Œå¹¶å…¼é¡¾äº†å…¶å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12822v1",
      "published_date": "2026-01-19 08:32:09 UTC",
      "updated_date": "2026-01-19 08:32:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:32.126867+00:00"
    },
    {
      "arxiv_id": "2601.12816v1",
      "title": "Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning",
      "title_zh": "é¢å‘æŒç»­å­¦ä¹ çš„ Fisher æ­£äº¤æŠ•å½±è‡ªç„¶æ¢¯åº¦ä¸‹é™",
      "authors": [
        "Ishir Garg",
        "Neel Kolhe",
        "Andy Peng",
        "Rohan Gopalam"
      ],
      "abstract": "Continual learning aims to enable neural networks to acquire new knowledge on sequential tasks. However, the key challenge in such settings is to learn new tasks without catastrophically forgetting previously learned tasks. We propose the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer, which enforces Fisher-orthogonal constraints on parameter updates to preserve old task performance while learning new tasks. Unlike existing methods that operate in Euclidean parameter space, FOPNG projects gradients onto the Fisher-orthogonal complement of previous task gradients. This approach unifies natural gradient descent with orthogonal gradient methods within an information-geometric framework. The resulting update direction is invariant under reparameterization, guarantees descent in the Fisher metric, and helps preserve prior task outputs. We provide theoretical analysis establishing the properties of the projected update, describe efficient and practical implementations using the diagonal Fisher, and demonstrate strong results on standard continual learning benchmarks such as Permuted-MNIST, Split-MNIST, Rotated-MNIST, Split-CIFAR10, and Split-CIFAR100.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) ä¼˜åŒ–å™¨ï¼Œæ—¨åœ¨è§£å†³ç¥ç»ç½‘ç»œåœ¨æŒç»­å­¦ä¹  (Continual Learning) ä¸­é¢ä¸´çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚è¯¥æ–¹æ³•åœ¨ä¿¡æ¯å‡ ä½• (Information-geometric) æ¡†æ¶ä¸‹ï¼Œå°†å½“å‰ä»»åŠ¡çš„æ¢¯åº¦æŠ•å½±åˆ°å…ˆå‰ä»»åŠ¡æ¢¯åº¦çš„ Fisher æ­£äº¤è¡¥ç©ºé—´ï¼Œå®ç°äº†è‡ªç„¶æ¢¯åº¦ä¸‹é™ (Natural Gradient Descent) ä¸æ­£äº¤æ¢¯åº¦æ–¹æ³•çš„æœ‰æœºç»Ÿä¸€ã€‚è¿™ç§æ›´æ–°æ–¹å¼å…·æœ‰å‚æ•°é‡æ„ä¸å˜æ€§ï¼Œèƒ½ç¡®ä¿åœ¨ Fisher åº¦é‡ä¸‹è¿›è¡Œæ¢¯åº¦ä¸‹é™çš„åŒæ—¶æœ‰æ•ˆä¿ç•™æ—§ä»»åŠ¡çš„æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼ŒåŸºäºå¯¹è§’ Fisher (Diagonal Fisher) çš„é«˜æ•ˆå®ç°åœ¨ Permuted-MNISTã€Split-CIFAR10 å’Œ Split-CIFAR100 ç­‰å¤šä¸ªæ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†ä¼˜å¼‚ç»“æœã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12816v1",
      "published_date": "2026-01-19 08:23:12 UTC",
      "updated_date": "2026-01-19 08:23:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:33.419829+00:00"
    },
    {
      "arxiv_id": "2601.12809v1",
      "title": "Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data",
      "title_zh": "åŸºäºåˆæˆç©ºé—´å…³ç³»æ•°æ®è®­ç»ƒçš„ CLIP å¼è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„å·¦å³å¯¹ç§°æ€§ç ´ç¼º",
      "authors": [
        "Takaki Yamamoto",
        "Chihiro Noguchi",
        "Toshihiro Tanizawa"
      ],
      "abstract": "Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.",
      "tldr_zh": "è¯¥ç ”ç©¶å»ºç«‹äº†ä¸€ä¸ªå¯æ§çš„ 1D å›¾åƒ-æ–‡æœ¬å®éªŒå¹³å°ï¼Œæ—¨åœ¨æ¢ç©¶åŸºäº CLIP é£æ ¼å¯¹æ¯”å­¦ä¹ è®­ç»ƒçš„ Transformer è§†è§‰å’Œæ–‡æœ¬ç¼–ç å™¨å¦‚ä½•ä¹ å¾—å·¦å³ç©ºé—´å…³ç³»ç†è§£èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œå¯¹æ¯”è®­ç»ƒèƒ½å¤Ÿä½¿æ¨¡å‹ä¹ å¾—å·¦å³å…³ç³»ï¼Œä¸”æ ‡ç­¾å¤šæ ·æ€§ (label diversity) ç›¸æ¯”å¸ƒå±€å¤šæ ·æ€§ (layout diversity) æ˜¯é©±åŠ¨æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„å…³é”®å› ç´ ã€‚é€šè¿‡æ³¨æ„åŠ›åˆ†è§£ (attention decomposition)ï¼Œç ”ç©¶æ­ç¤ºäº†ä½ç½®åµŒå…¥ (positional embeddings) ä¸ä»¤ç‰ŒåµŒå…¥ (token embeddings) çš„äº¤äº’ä¼šè¯±å‘æ°´å¹³æ³¨æ„åŠ›æ¢¯åº¦ï¼Œä»è€Œæ‰“ç ´ç¼–ç å™¨ä¸­çš„å·¦å³å¯¹ç§°æ€§ (left-right symmetry)ã€‚è¯¥æˆæœä¸ºç†è§£ CLIP é£æ ¼æ¨¡å‹è·å–ç©ºé—´å…³ç³»èƒ½åŠ›çš„åº•å±‚æœºåˆ¶æä¾›äº†é‡è¦çš„å­¦æœ¯è§è§£ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12809v1",
      "published_date": "2026-01-19 08:16:11 UTC",
      "updated_date": "2026-01-19 08:16:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:45.056036+00:00"
    },
    {
      "arxiv_id": "2601.14310v1",
      "title": "CORVUS: Red-Teaming Hallucination Detectors via Internal Signal Camouflage in Large Language Models",
      "title_zh": "CORVUSï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹å†…éƒ¨ä¿¡å·ä¼ªè£…çš„å¹»è§‰æ£€æµ‹å™¨çº¢é˜Ÿæµ‹è¯•",
      "authors": [
        "Nay Myat Min",
        "Long H. Pham",
        "Hongyu Zhang",
        "Jun Sun"
      ],
      "abstract": "Single-pass hallucination detectors rely on internal telemetry (e.g., uncertainty, hidden-state geometry, and attention) of large language models, implicitly assuming hallucinations leave separable traces in these signals. We study a white-box, model-side adversary that fine-tunes lightweight LoRA adapters on the model while keeping the detector fixed, and introduce CORVUS, an efficient red-teaming procedure that learns to camouflage detector-visible telemetry under teacher forcing, including an embedding-space FGSM attention stress test. Trained on 1,000 out-of-distribution Alpaca instructions (<0.5% trainable parameters), CORVUS transfers to FAVA-Annotation across Llama-2, Vicuna, Llama-3, and Qwen2.5, and degrades both training-free detectors (e.g., LLM-Check) and probe-based detectors (e.g., SEP, ICR-probe), motivating adversary-aware auditing that incorporates external grounding or cross-model evidence.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¾èµ–å¤§è¯­è¨€æ¨¡å‹(LLMs)å†…éƒ¨é¥æµ‹ä¿¡å·ï¼ˆå¦‚ä¸ç¡®å®šæ€§ã€éšè—çŠ¶æ€å‡ ä½•å’Œæ³¨æ„åŠ›ï¼‰çš„å•æ¬¡å¹»è§‰æ£€æµ‹å™¨ï¼Œæå‡ºäº†ä¸€ç§åä¸º CORVUS çš„çº¢é˜Ÿæµ‹è¯•(Red-Teaming)ç¨‹åºã€‚CORVUS é€šè¿‡å¾®è°ƒè½»é‡çº§çš„ LoRA é€‚é…å™¨ï¼Œå­¦ä¹ åœ¨æ¨¡å‹ç”Ÿæˆå¹»è§‰æ—¶ä¼ªè£…è¿™äº›æ£€æµ‹å™¨å¯è§çš„å†…éƒ¨ä¿¡å·ï¼Œå¹¶å¼•å…¥äº†åµŒå…¥ç©ºé—´ FGSM æ³¨æ„åŠ›å‹åŠ›æµ‹è¯•ã€‚å®éªŒè¯æ˜ï¼ŒCORVUS åœ¨ Llama-2ã€Llama-3 å’Œ Qwen2.5 ç­‰å¤šç§æ¨¡å‹ä¸Šè¡¨ç°å‡ºæå¼ºçš„è¿ç§»æ€§ï¼Œèƒ½æ˜¾è‘—å‰Šå¼±åŒ…æ‹¬ LLM-Check åœ¨å†…çš„è®­ç»ƒæ— å…³æ£€æµ‹å™¨ä»¥åŠ SEPã€ICR-probe ç­‰åŸºäºæ¢é’ˆçš„æ£€æµ‹å™¨çš„æ€§èƒ½ã€‚è¯¥å‘ç°æ­ç¤ºäº†ä»…ä¾èµ–æ¨¡å‹å†…éƒ¨ä¿¡å·è¿›è¡Œå¹»è§‰æ£€æµ‹çš„è„†å¼±æ€§ï¼Œå¼ºè°ƒäº†åœ¨å®‰å…¨å®¡è®¡ä¸­å¼•å…¥å¤–éƒ¨ä¾æ®(External Grounding)æˆ–è·¨æ¨¡å‹è¯æ®(Cross-model Evidence)çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2601.14310v1",
      "published_date": "2026-01-19 08:07:03 UTC",
      "updated_date": "2026-01-19 08:07:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:53.580259+00:00"
    },
    {
      "arxiv_id": "2601.12805v2",
      "title": "SciHorizon-GENE: Benchmarking LLM for Life Sciences Inference from Gene Knowledge to Functional Understanding",
      "title_zh": "SciHorizon-GENEï¼šé¢å‘ç”Ÿå‘½ç§‘å­¦ä»åŸºå› çŸ¥è¯†åˆ°åŠŸèƒ½ç†è§£çš„ LLM æ¨ç†åŸºå‡†æµ‹è¯•",
      "authors": [
        "Xiaohan Huang",
        "Meng Xiao",
        "Chuan Qin",
        "Qingqing Long",
        "Jinmiao Chen",
        "Yuanchun Zhou",
        "Hengshu Zhu"
      ],
      "abstract": "Large language models (LLMs) have shown growing promise in biomedical research, particularly for knowledge-driven interpretation tasks. However, their ability to reliably reason from gene-level knowledge to functional understanding, a core requirement for knowledge-enhanced cell atlas interpretation, remains largely underexplored. To address this gap, we introduce SciHorizon-GENE, a large-scale gene-centric benchmark constructed from authoritative biological databases. The benchmark integrates curated knowledge for over 190K human genes and comprises more than 540K questions covering diverse gene-to-function reasoning scenarios relevant to cell type annotation, functional interpretation, and mechanism-oriented analysis. Motivated by behavioral patterns observed in preliminary examinations, SciHorizon-GENE evaluates LLMs along four biologically critical perspectives: research attention sensitivity, hallucination tendency, answer completeness, and literature influence, explicitly targeting failure modes that limit the safe adoption of LLMs in biological interpretation pipelines. We systematically evaluate a wide range of state-of-the-art general-purpose and biomedical LLMs, revealing substantial heterogeneity in gene-level reasoning capabilities and persistent challenges in generating faithful, complete, and literature-grounded functional interpretations. Our benchmark establishes a systematic foundation for analyzing LLM behavior at the gene scale and offers insights for model selection and development, with direct relevance to knowledge-enhanced biological interpretation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† SciHorizon-GENEï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæƒå¨ç”Ÿç‰©æ•°æ®åº“æ„å»ºçš„å¤§è§„æ¨¡ã€ä»¥åŸºå› ä¸ºä¸­å¿ƒçš„åŸºå‡†æµ‹è¯•(benchmark)ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä»åŸºå› çŸ¥è¯†åˆ°åŠŸèƒ½ç†è§£çš„æ¨ç†èƒ½åŠ›ã€‚è¯¥åŸºå‡†æ•´åˆäº†è¶…è¿‡ 19 ä¸‡ä¸ªäººç±»åŸºå› çŸ¥è¯†ï¼ŒåŒ…å«é€¾ 54 ä¸‡ä¸ªæ¶µç›–ç»†èƒç±»å‹æ³¨é‡Š(cell type annotation)ã€åŠŸèƒ½è§£é‡ŠåŠæœºåˆ¶åˆ†æç­‰æ¨ç†åœºæ™¯çš„é—®é¢˜ã€‚é€šè¿‡ä»ç ”ç©¶å…³æ³¨åº¦æ•æ„Ÿæ€§ã€å¹»è§‰å€¾å‘(hallucination tendency)ã€å›ç­”å®Œæ•´æ€§å’Œæ–‡çŒ®å½±å“åŠ›å››ä¸ªå…³é”®ç»´åº¦è¿›è¡Œç³»ç»Ÿè¯„ä¼°ï¼Œç ”ç©¶æ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨åŸºå› çº§æ¨ç†ä¸Šçš„æ˜¾è‘—å¼‚è´¨æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMs åœ¨ç”Ÿæˆå¿ å®ã€å®Œæ•´ä¸”æœ‰æ–‡çŒ®ä¾æ®çš„åŠŸèƒ½è§£é‡Šæ–¹é¢ä»é¢ä¸´æŒä¹…æŒ‘æˆ˜ï¼ŒSciHorizon-GENE ä¸ºç”Ÿç‰©å­¦è§£é‡Šé¢†åŸŸçš„æ¨¡å‹å¼€å‘ä¸é€‰å‹å¥ å®šäº†ç³»ç»Ÿæ€§åŸºç¡€ã€‚",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.GN",
      "comment": "16 pages",
      "pdf_url": "https://arxiv.org/pdf/2601.12805v2",
      "published_date": "2026-01-19 08:06:35 UTC",
      "updated_date": "2026-01-21 05:31:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:50.899534+00:00"
    },
    {
      "arxiv_id": "2601.12804v1",
      "title": "SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability",
      "title_zh": "SL-CBMï¼šé€šè¿‡è¯­ä¹‰å±€éƒ¨æ€§æå‡æ¦‚å¿µç“¶é¢ˆæ¨¡å‹çš„å¯è§£é‡Šæ€§",
      "authors": [
        "Hanwei Zhang",
        "Luo Cheng",
        "Rui Wen",
        "Yang Zhang",
        "Lijun Zhang",
        "Holger Hermanns"
      ],
      "abstract": "Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SL-CBM (CBM with Semantic Locality)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ Concept Bottleneck Models (CBMs) éš¾ä»¥å°†æ¦‚å¿µä¸å›¾åƒåŒºåŸŸè¿›è¡Œç©ºé—´å¯¹é½ï¼ˆå³ locality faithfulness è¾ƒå·®ï¼‰çš„é—®é¢˜ã€‚SL-CBM é€šè¿‡ç»“åˆ 1x1 å·ç§¯å±‚ä¸ cross-attention æœºåˆ¶ï¼Œåœ¨æ¦‚å¿µ(concept)å’Œç±»åˆ«(class)çº§åˆ«ç”Ÿæˆä¸æ¨¡å‹å†…éƒ¨æ¨ç†ç´§å¯†è€¦åˆçš„ç©ºé—´æ˜¾è‘—æ€§å›¾(saliency maps)ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº† contrastive å’Œ entropy-based æ­£åˆ™åŒ–ï¼Œä»¥åœ¨åˆ†ç±»å‡†ç¡®ç‡ã€ç¨€ç–æ€§ä¸å¿ å®åº¦ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSL-CBM åœ¨æ˜¾è‘—æå‡å±€éƒ¨å¿ å®åº¦ã€è§£é‡Šè´¨é‡å’Œå¹²é¢„æ•ˆç‡(intervention efficacy)çš„åŒæ—¶ï¼Œä¾ç„¶ä¿æŒäº†æå…·ç«äº‰åŠ›çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œä¸ºæ„å»ºå¯è§£é‡Šä¸”å¯ä¿¡çš„æ¦‚å¿µæ¨¡å‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12804v1",
      "published_date": "2026-01-19 08:05:28 UTC",
      "updated_date": "2026-01-19 08:05:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:53.963700+00:00"
    },
    {
      "arxiv_id": "2601.12785v1",
      "title": "Distilling Time Series Foundation Models for Efficient Forecasting",
      "title_zh": "é¢å‘é«˜æ•ˆé¢„æµ‹çš„æ—¶é—´åºåˆ—åŸºåº§æ¨¡å‹è’¸é¦",
      "authors": [
        "Yuqi Li",
        "Kuiye Ding",
        "Chuanguang Yang",
        "Szu-Yu Chen",
        "Yingli Tian"
      ],
      "abstract": "Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DistilTSï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨ä¸ºæ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ (Time Series Foundation Models, TSFMs) è®¾è®¡çš„çŸ¥è¯†è’¸é¦ (Knowledge Distillation) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§æ¨¡å‹éƒ¨ç½²æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†æ°´å¹³åŠ æƒç›®æ ‡ (horizon-weighted objectives) ä»¥å¹³è¡¡ä¸åŒé¢„æµ‹å‘¨æœŸä¹‹é—´çš„å­¦ä¹ æƒé‡ï¼Œå¹¶é€šè¿‡æ—¶é—´å¯¹é½ç­–ç•¥ (temporal alignment strategy) å…‹æœäº†è’¸é¦è¿‡ç¨‹ä¸­çš„æ¶æ„ä¸åŒ¹é… (architecture discrepancy) æŒ‘æˆ˜ã€‚å®éªŒè¡¨æ˜ï¼ŒDistilTS åœ¨ä¿æŒä¸å…¨è§„æ¨¡ TSFMs ç›¸å½“é¢„æµ‹æ€§èƒ½çš„åŒæ—¶ï¼Œå°†å‚æ•°é‡å‡å°‘äº†å¤šè¾¾ 1/150ï¼Œæ¨ç†é€Ÿåº¦æå‡äº† 6000 å€ï¼Œä¸ºé«˜æ•ˆçš„æ—¶é—´åºåˆ—é¢„æµ‹ (Time Series Forecasting) æä¾›äº†å¯è¡Œæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICASSP-2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12785v1",
      "published_date": "2026-01-19 07:32:00 UTC",
      "updated_date": "2026-01-19 07:32:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:42:55.492655+00:00"
    },
    {
      "arxiv_id": "2601.12781v1",
      "title": "VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension",
      "title_zh": "VIROï¼šé¢å‘æŒ‡ä»£æ€§è¡¨è¾¾ç†è§£çš„èåˆéªŒè¯ã€é²æ£’ä¸”é«˜æ•ˆçš„ç¥ç»ç¬¦å·æ¨ç†",
      "authors": [
        "Hyejin Park",
        "Junhyuk Kwon",
        "Suha Kwak",
        "Jungseul Ok"
      ],
      "abstract": "Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† VIRO (Verification-Integrated Reasoning Operators)ï¼Œè¿™æ˜¯ä¸€ä¸ªç¥ç»ç¬¦å· (neuro-symbolic) æ¨ç†æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æŒ‡ä»£æ€§è¡¨è¾¾ç†è§£ (Referring Expression Comprehension, REC) ä¸­å› ä¸­é—´æ­¥éª¤é”™è¯¯å¯¼è‡´çš„çº§è”è¯¯å·® (cascading errors) é—®é¢˜ã€‚VIRO é€šè¿‡åœ¨æ¨ç†æ­¥éª¤ä¸­åµŒå…¥è½»é‡çº§çš„ç®—å­çº§éªŒè¯å™¨ (operator-level verifiers)ï¼Œå¯¹ç‰©ä½“å­˜åœ¨æ€§æˆ–ç©ºé—´å…³ç³»è¿›è¡Œå®æ—¶æ ¡éªŒï¼Œä»è€Œä½¿ç³»ç»Ÿèƒ½ç¨³å¥åœ°è¯†åˆ«å¹¶å¤„ç†å›¾åƒä¸­ä¸å­˜åœ¨ç›®æ ‡ (no-target) çš„æƒ…å†µã€‚å®éªŒè¡¨æ˜ï¼ŒVIRO åœ¨åŒ…å«æ— ç›®æ ‡åœºæ™¯çš„è®¾ç½®ä¸‹è¾¾åˆ°äº† 61.1% çš„å¹³è¡¡å‡†ç¡®ç‡ï¼Œå¹¶ä¿æŒäº†æä½çš„ç¨‹åºå¤±è´¥ç‡ (å°‘äº 0.3%) ä¸é«˜æ•ˆçš„ååé‡ (throughput)ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åœ¨çœŸå®ä¸–ç•Œçš„è‡ªæˆ‘ä¸­å¿ƒæ•°æ® (egocentric data) ä¸Šå±•ç°äº†å¼ºæ³›åŒ–æ€§ï¼Œå…¶è§£è€¦çš„ç¨‹åºç”Ÿæˆä¸æ‰§è¡Œæ¨¡å¼ä¹Ÿæ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ (scalability)ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12781v1",
      "published_date": "2026-01-19 07:21:19 UTC",
      "updated_date": "2026-01-19 07:21:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:05.278175+00:00"
    },
    {
      "arxiv_id": "2601.12762v1",
      "title": "Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction",
      "title_zh": "é€šè¿‡ç¯å¢ƒäº¤äº’æ•™å¯¼å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ å·¥å…·è¯•ç”¨ä¸æ‰§è¡Œ",
      "authors": [
        "Xingjie Gao",
        "Pengcheng Huang",
        "Zhenghao Liu",
        "Yukun Yan",
        "Shuo Wang",
        "Zulong Chen",
        "Chen Qian",
        "Ge Yu",
        "Yu Gu"
      ],
      "abstract": "Equipping Large Language Models (LLMs) with external tools enables them to solve complex real-world problems. However, the robustness of existing methods remains a critical challenge when confronting novel or evolving tools. Existing trajectory-centric paradigms primarily rely on memorizing static solution paths during training, which limits the ability of LLMs to generalize tool usage to newly introduced or previously unseen tools. In this paper, we propose ToolMaster, a framework that shifts tool use from imitating golden tool-calling trajectories to actively learning tool usage through interaction with the environment. To optimize LLMs for tool planning and invocation, ToolMaster adopts a trial-and-execution paradigm, which trains LLMs to first imitate teacher-generated trajectories containing explicit tool trials and self-correction, followed by reinforcement learning to coordinate the trial and execution phases jointly. This process enables agents to autonomously explore correct tool usage by actively interacting with environments and forming experiential knowledge that benefits tool execution. Experimental results demonstrate that ToolMaster significantly outperforms existing baselines in terms of generalization and robustness across unseen or unfamiliar tools. All code and data are available at https://github.com/NEUIR/ToolMaster.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ToolMaster æ¡†æ¶ï¼Œæ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨é¢å¯¹æ–°é¢–æˆ–æ¼”åŒ–å·¥å…·æ—¶çš„é²æ£’æ€§ã€‚è¯¥æ¡†æ¶æ”¹å˜äº†ä»¥å¾€å•çº¯æ¨¡ä»¿é™æ€è§£å†³æ–¹æ¡ˆçš„èŒƒå¼ï¼Œè½¬è€Œé‡‡ç”¨ trial-and-executionï¼ˆè¯•é”™ä¸æ‰§è¡Œï¼‰èŒƒå¼ï¼Œé€šè¿‡ä¸ç¯å¢ƒçš„çœŸå®äº¤äº’ä¸»åŠ¨å­¦ä¹ å·¥å…·ç”¨æ³•ã€‚ToolMaster é¦–å…ˆé€šè¿‡æ¨¡ä»¿åŒ…å«æ˜¾å¼å°è¯•ä¸è‡ªæˆ‘ä¿®æ­£çš„è½¨è¿¹è¿›è¡Œè®­ç»ƒï¼Œéšååˆ©ç”¨ Reinforcement Learningï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰åè°ƒå°è¯•ä¸æ‰§è¡Œé˜¶æ®µï¼Œä½¿æ™ºèƒ½ä½“èƒ½è‡ªä¸»æ¢ç´¢å¹¶å½¢æˆç»éªŒçŸ¥è¯†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒToolMaster åœ¨å¤„ç†æœªè§è¿‡æˆ–ä¸ç†Ÿæ‚‰çš„å·¥å…·æ—¶ï¼Œå…¶æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§å‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12762v1",
      "published_date": "2026-01-19 06:46:33 UTC",
      "updated_date": "2026-01-19 06:46:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:04.061275+00:00"
    },
    {
      "arxiv_id": "2601.12758v1",
      "title": "VISPA: Pluralistic Alignment via Automatic Value Selection and Activation",
      "title_zh": "VISPAï¼šåŸºäºè‡ªåŠ¨ä»·å€¼é€‰æ‹©ä¸æ¿€æ´»çš„å¤šå…ƒå¯¹é½",
      "authors": [
        "Shenyan Zheng",
        "Jiayou Zhong",
        "Anudeex Shetty",
        "Heng Ji",
        "Preslav Nakov",
        "Usman Naseem"
      ],
      "abstract": "As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† VISPAï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„å¤šæ ·åŒ–å¯¹é½ (Pluralistic Alignment) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹è¾“å‡ºå€¾å‘äºåæ˜ â€œå¹³å‡â€äººç±»åå¥½è€Œå¿½è§†å¤šå…ƒè§‚ç‚¹çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡åŠ¨æ€ä»·å€¼é€‰æ‹© (Automatic Value Selection) å’Œå†…éƒ¨æ¨¡å‹æ¿€æ´»å¼•å¯¼ (Internal Model Activation Steering) æœºåˆ¶ï¼Œå®ç°äº†å¯¹ä»·å€¼è¡¨è¾¾çš„ç›´æ¥æ§åˆ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVISPA åœ¨åŒ»ç–—ç­‰å¤šä¸ªé¢†åŸŸçš„å¤šç§å¯¹é½æ¨¡å¼ä¸‹è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶å±•ç°å‡ºæå¼ºçš„è·¨æ¨¡å‹ä¸è·¨ä»·å€¼é€‚åº”æ€§ã€‚è¿™ä¸€æˆæœè¯æ˜äº†é€šè¿‡å†…éƒ¨æ¿€æ´»æœºåˆ¶å®ç°å¤šæ ·åŒ–å¯¹é½çš„å¯è¡Œæ€§ï¼Œä¸ºæ„å»ºèƒ½å¤ŸæœåŠ¡äºå…¨ä½“ç”¨æˆ·çš„è¯­è¨€æ¨¡å‹æä¾›äº†å¯æ‰©å±•çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "WIP",
      "pdf_url": "https://arxiv.org/pdf/2601.12758v1",
      "published_date": "2026-01-19 06:38:52 UTC",
      "updated_date": "2026-01-19 06:38:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:05.867981+00:00"
    },
    {
      "arxiv_id": "2601.12754v1",
      "title": "PAIR-SAFE: A Paired-Agent Approach for Runtime Auditing and Refining AI-Mediated Mental Health Support",
      "title_zh": "PAIR-SAFEï¼šä¸€ç§ç”¨äº AI ä»‹å¯¼å¿ƒç†å¥åº·æ”¯æŒè¿è¡Œæ—¶å®¡è®¡ä¸ä¼˜åŒ–çš„åŒæ™ºèƒ½ä½“æ–¹æ³•",
      "authors": [
        "Jiwon Kim",
        "Violeta J. Rodriguez",
        "Dong Whi Yoo",
        "Eshwar Chandrasekharan",
        "Koustuv Saha"
      ],
      "abstract": "Large language models (LLMs) are increasingly used for mental health support, yet they can produce responses that are overly directive, inconsistent, or clinically misaligned, particularly in sensitive or high-risk contexts. Existing approaches to mitigating these risks largely rely on implicit alignment through training or prompting, offering limited transparency and runtime accountability. We introduce PAIR-SAFE, a paired-agent framework for auditing and refining AI-generated mental health support that integrates a Responder agent with a supervisory Judge agent grounded in the clinically validated Motivational Interviewing Treatment Integrity (MITI-4) framework. The Judgeaudits each response and provides structuredALLOW or REVISE decisions that guide runtime response refinement. We simulate counseling interactions using a support-seeker simulator derived from human-annotated motivational interviewing data. We find that Judge-supervised interactions show significant improvements in key MITI dimensions, including Partnership, Seek Collaboration, and overall Relational quality. Our quantitative findings are supported by qualitative expert evaluation, which further highlights the nuances of runtime supervision. Together, our results reveal that such pairedagent approach can provide clinically grounded auditing and refinement for AI-assisted conversational mental health support.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PAIR-SAFEï¼Œä¸€ç§ç”¨äºå®¡è®¡å’Œæ”¹è¿›äººå·¥æ™ºèƒ½ä»‹å¯¼å¿ƒç†å¥åº·æ”¯æŒçš„åŒæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•æ„Ÿè¯­å¢ƒä¸‹å¯èƒ½äº§ç”Ÿçš„è¿‡åº¦æŒ‡ä»¤æ€§æˆ–ä¸´åºŠå¤±å‡†é—®é¢˜ã€‚è¯¥æ¡†æ¶ç»“åˆäº†å“åº”æ™ºèƒ½ä½“ï¼ˆResponderï¼‰ä¸åŸºäºä¸´åºŠéªŒè¯çš„ MITI-4 æ¡†æ¶çš„ç›‘ç£è¯„å®¡æ™ºèƒ½ä½“ï¼ˆJudgeï¼‰ï¼Œé€šè¿‡æä¾› ALLOW æˆ– REVISE å†³ç­–å®ç°è¿è¡Œæ—¶çš„å®æ—¶å“åº”ä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ Judge çš„ç›‘ç£ä¸‹ï¼ŒAI çš„å›å¤åœ¨åä½œæ€§ï¼ˆPartnershipï¼‰ã€å¯»æ±‚åˆä½œï¼ˆSeek Collaborationï¼‰å’Œæ•´ä½“å…³ç³»è´¨é‡ç­‰å…³é”®ç»´åº¦ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†åŒæ™ºèƒ½ä½“æ–¹æ³•èƒ½ä¸º AI è¾…åŠ©çš„å¿ƒç†æ”¯æŒå¯¹è¯æä¾›å…·æœ‰ä¸´åºŠä¾æ®çš„å®¡è®¡ä¸ä¿®æ­£ï¼Œæå‡äº†ç³»ç»Ÿçš„å¯ä¿¡åº¦ä¸å®‰å…¨æ€§ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12754v1",
      "published_date": "2026-01-19 06:20:57 UTC",
      "updated_date": "2026-01-19 06:20:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:07.451991+00:00"
    },
    {
      "arxiv_id": "2601.12745v1",
      "title": "A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection",
      "title_zh": "é¢å‘æ— çº¿ä¼ æ„Ÿå™¨ç½‘ç»œæ—¶ç©ºç›¸å…³æ€§å¼‚å¸¸æ£€æµ‹çš„å›¾æç¤ºå¾®è°ƒæ–¹æ³•",
      "authors": [
        "Miao Ye",
        "Jing Cui",
        "Yuan huang",
        "Qian He",
        "Yong Wang",
        "Jiwen Zhang"
      ],
      "abstract": "Anomaly detection of multi-temporal modal data in Wireless Sensor Network (WSN) can provide an important guarantee for reliable network operation. Existing anomaly detection methods in multi-temporal modal data scenarios have the problems of insufficient extraction of spatio-temporal correlation features, high cost of anomaly sample category annotation, and imbalance of anomaly samples. In this paper, a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy of \"pre-training - graph prompting - fine-tuning\" are designed for the characteristics of WSN graph structure data. First, the anomaly detection backbone network is designed by improving the Mamba model based on a multi-scale strategy and inter-modal fusion method, and combining it with a variational graph convolution module, which is capable of fully extracting spatio-temporal correlation features in the multi-node, multi-temporal modal scenarios of WSNs. Secondly, we design a three-subtask learning \"pre-training\" method with no-negative comparative learning, prediction, and reconstruction to learn generic features of WSN data samples from unlabeled data, and design a \"graph prompting-fine-tuning\" mechanism to guide the pre-trained self-supervised learning. The model is fine-tuned through the \"graph prompting-fine-tuning\" mechanism to guide the pre-trained self-supervised learning model to complete the parameter fine-tuning, thereby reducing the training cost and enhancing the detection generalization performance. The F1 metrics obtained from experiments on the public dataset and the actual collected dataset are up to 91.30% and 92.31%, respectively, which provides better detection performance and generalization ability than existing methods designed by the method.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ— çº¿ä¼ æ„Ÿå™¨ç½‘ç»œ(WSN)åœ¨å¤šæ—¶åºæ¨¡æ€æ•°æ®å¼‚å¸¸æ£€æµ‹ä¸­é¢ä¸´çš„ç‰¹å¾æå–ä¸å……åˆ†ã€æ ‡æ³¨æˆæœ¬é«˜åŠæ ·æœ¬ä¸å¹³è¡¡ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºâ€œé¢„è®­ç»ƒ-å›¾æç¤º-å¾®è°ƒâ€(pre-training - graph prompting - fine-tuning)çš„è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ã€‚å…¶éª¨å¹²ç½‘ç»œé€šè¿‡æ”¹è¿›å¤šå°ºåº¦ Mamba æ¨¡å‹å¹¶ç»“åˆå˜åˆ†å›¾å·ç§¯(Variational Graph Convolution)æ¨¡å—ï¼Œå®ç°äº†å¯¹ WSN å¤šèŠ‚ç‚¹æ—¶ç©ºç›¸å…³æ€§ç‰¹å¾çš„æ·±åº¦æå–ã€‚è¯¥æ–¹æ³•åœ¨æ— æ ‡ç­¾æ•°æ®ä¸Šé€šè¿‡å¯¹æ¯”å­¦ä¹ ã€é¢„æµ‹å’Œé‡æ„ä»»åŠ¡å­¦ä¹ é€šç”¨ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨å›¾æç¤º(graph prompting)æœºåˆ¶å¼•å¯¼æ¨¡å‹å¾®è°ƒï¼Œæœ‰æ•ˆé™ä½äº†è®­ç»ƒå¼€é”€å¹¶å¢å¼ºäº†æ³›åŒ–æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å…¬å¼€æ•°æ®é›†å’Œå®æµ‹æ•°æ®é›†ä¸Šçš„ F1 åˆ†æ•°åˆ†åˆ«è¾¾åˆ° 91.30% å’Œ 92.31%ï¼Œåœ¨æ£€æµ‹ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12745v1",
      "published_date": "2026-01-19 05:58:53 UTC",
      "updated_date": "2026-01-19 05:58:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:12.394574+00:00"
    },
    {
      "arxiv_id": "2601.12744v1",
      "title": "Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks",
      "title_zh": "é¢å‘è‡ªæ™ºç½‘ç»œä¼˜åŒ–é©±åŠ¨æ„å›¾å¤„ç†çš„è§†è§‰è¯­è¨€æ¨¡å‹",
      "authors": [
        "Tasnim Ahmed",
        "Yifan Zhu",
        "Salimur Choudhury"
      ],
      "abstract": "Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. While recent work demonstrates that large language models can automate configuration tasks, a distinct class of intents requires generating optimization code to compute provably optimal solutions for traffic engineering, routing, and resource allocation. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. Network practitioners naturally reason about structure through diagrams, yet whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code remains unexplored. We present IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. Our evaluation shows that visual parameter extraction reduces execution success by 12-21 percentage points (pp), with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 pp, and open-source models lag behind closed-source ones, with Llama-3.2-11B-Vision reaching 18% compared to 75% for GPT-5-Mini. These results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system. We also demonstrate practical feasibility through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) åœ¨è‡ªæ²»ç½‘ç»œä¸­é€šè¿‡ç½‘ç»œæ‹“æ‰‘è‰å›¾ç”Ÿæˆä¼˜åŒ–ä»£ç ï¼Œä»¥å®ç°æ„å›¾é©±åŠ¨ç½‘ç»œ (IBN) çš„èƒ½åŠ›ã€‚ä½œè€…æå‡ºäº† IntentOpt åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«æµé‡å·¥ç¨‹å’Œèµ„æºåˆ†é…ç­‰ 17 ä¸ªç±»åˆ«çš„ 85 ä¸ªä¼˜åŒ–é—®é¢˜ï¼Œå¹¶å¯¹ GPT-5-Mini å’Œ Gemini-2.5-Flash ç­‰ä¸»æµæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè§†è§‰å‚æ•°æå–ç›¸æ¯”çº¯æ–‡æœ¬è¾“å…¥ä¼šå¯¼è‡´æ‰§è¡ŒæˆåŠŸç‡ä¸‹é™ 12-21%ï¼Œä¸”å¼€æºæ¨¡å‹åœ¨ç”Ÿæˆä¼˜åŒ–ä»£ç æ–¹é¢æ˜¾è‘—è½åäºé—­æºæ¨¡å‹ã€‚æœ€åï¼Œè¯¥ç ”ç©¶é€šè¿‡æ¡ˆä¾‹å±•ç¤ºäº†åˆ©ç”¨ Model Context Protocol å°† VLM ç”Ÿæˆçš„ä»£ç éƒ¨ç½²åˆ°ç½‘ç»œæµ‹è¯•åºŠçš„å¯è¡Œæ€§ï¼Œä¸ºå¤šæ¨¡æ€æ„å›¾å¤„ç†å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.NI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for presentation at The IEEE International Conference on Communications (ICC) 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12744v1",
      "published_date": "2026-01-19 05:57:58 UTC",
      "updated_date": "2026-01-19 05:57:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:29.978911+00:00"
    },
    {
      "arxiv_id": "2601.12742v1",
      "title": "AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation",
      "title_zh": "AirHuntï¼šèåˆVLMè¯­ä¹‰ä¸è¿ç»­è§„åˆ’çš„é«˜æ•ˆç©ºä¸­ç›®æ ‡å¯¼èˆª",
      "authors": [
        "Xuecheng Chen",
        "Zongzhuo Liu",
        "Jianfa Ma",
        "Bang Du",
        "Tiantian Zhang",
        "Xueqian Wang",
        "Boyu Zhou"
      ],
      "abstract": "Recent advances in large Vision-Language Models (VLMs) have provided rich semantic understanding that empowers drones to search for open-set objects via natural language instructions. However, prior systems struggle to integrate VLMs into practical aerial systems due to orders-of-magnitude frequency mismatch between VLM inference and real-time planning, as well as VLMs' limited 3D scene understanding. They also lack a unified mechanism to balance semantic guidance with motion efficiency in large-scale environments. To address these challenges, we present AirHunt, an aerial object navigation system that efficiently locates open-set objects with zero-shot generalization in outdoor environments by seamlessly fusing VLM semantic reasoning with continuous path planning. AirHunt features a dual-pathway asynchronous architecture that establishes a synergistic interface between VLM reasoning and path planning, enabling continuous flight with adaptive semantic guidance that evolves through motion. Moreover, we propose an active dual-task reasoning module that exploits geometric and semantic redundancy to enable selective VLM querying, and a semantic-geometric coherent planning module that dynamically reconciles semantic priorities and motion efficiency in a unified framework, enabling seamless adaptation to environmental heterogeneity. We evaluate AirHunt across diverse object navigation tasks and environments, demonstrating a higher success rate with lower navigation error and reduced flight time compared to state-of-the-art methods. Real-world experiments further validate AirHunt's practical capability in complex and challenging environments. Code and dataset will be made publicly available before publication.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AirHuntï¼Œä¸€ç§æ—¨åœ¨å®ç°é«˜æ•ˆæˆ·å¤–ç›®æ ‡å¯¼èˆªçš„ç©ºä¸­ç³»ç»Ÿï¼Œé€šè¿‡å°†Vision-Language Models (VLMs)çš„è¯­ä¹‰æ¨ç†ä¸è¿ç»­è·¯å¾„è§„åˆ’(continuous path planning)æ— ç¼èåˆï¼Œå®ç°äº†å¯¹å¼€æ”¾é›†(open-set)ç›®æ ‡çš„é›¶æ ·æœ¬æ³›åŒ–(zero-shot generalization)æœç´¢ã€‚ç³»ç»Ÿé‡‡ç”¨äº†åŒè·¯å¾„å¼‚æ­¥æ¶æ„(dual-pathway asynchronous architecture)ï¼Œæœ‰æ•ˆè§£å†³äº†VLMæ¨ç†ä¸å®æ—¶è§„åˆ’ä¹‹é—´çš„é¢‘ç‡å¤±é…é—®é¢˜ã€‚è¯¥æ¡†æ¶è¿˜å¼•å…¥äº†ä¸»åŠ¨åŒä»»åŠ¡æ¨ç†æ¨¡å—ä»¥å®ç°é€‰æ‹©æ€§VLMæŸ¥è¯¢ï¼Œå¹¶é€šè¿‡è¯­ä¹‰-å‡ ä½•ä¸€è‡´æ€§è§„åˆ’æ¨¡å—(semantic-geometric coherent planning module)åœ¨ç»Ÿä¸€æ¡†æ¶ä¸‹åŠ¨æ€å¹³è¡¡è¯­ä¹‰ä¼˜å…ˆçº§ä¸è¿åŠ¨æ•ˆç‡ã€‚å®éªŒè¯æ˜ï¼ŒAirHuntåœ¨å¤šç§å¯¼èˆªä»»åŠ¡ä¸­å‡å–å¾—äº†æ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•æ›´é«˜çš„æˆåŠŸç‡ã€æ›´ä½çš„å¯¼èˆªè¯¯å·®å’Œæ›´çŸ­çš„é£è¡Œæ—¶é—´ï¼Œå¹¶å·²åœ¨å¤æ‚ç°å®ç¯å¢ƒä¸­éªŒè¯äº†å…¶å¯é æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12742v1",
      "published_date": "2026-01-19 05:50:03 UTC",
      "updated_date": "2026-01-19 05:50:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:26.297763+00:00"
    },
    {
      "arxiv_id": "2601.12740v1",
      "title": "TreeWriter: AI-Assisted Hierarchical Planning and Writing for Long-Form Documents",
      "title_zh": "TreeWriterï¼šé¢å‘é•¿æ–‡æ¡£çš„äººå·¥æ™ºèƒ½è¾…åŠ©åˆ†å±‚è§„åˆ’ä¸å†™ä½œ",
      "authors": [
        "Zijian Zhang",
        "Fangshi Du",
        "Xingjian Liu",
        "Pan Chen",
        "Oliver Huang",
        "Runlong Ye",
        "Michael Liut",
        "AlÃ¡n Aspuru-Guzik"
      ],
      "abstract": "Long documents pose many challenges to current intelligent writing systems. These include maintaining consistency across sections, sustaining efficient planning and writing as documents become more complex, and effectively providing and integrating AI assistance to the user. Existing AI co-writing tools offer either inline suggestions or limited structured planning, but rarely support the entire writing process that begins with high-level ideas and ends with polished prose, in which many layers of planning and outlining are needed. Here, we introduce TreeWriter, a hierarchical writing system that represents documents as trees and integrates contextual AI support. TreeWriter allows authors to create, save, and refine document outlines at multiple levels, facilitating drafting, understanding, and iterative editing of long documents. A built-in AI agent can dynamically load relevant content, navigate the document hierarchy, and provide context-aware editing suggestions. A within-subject study (N=12) comparing TreeWriter with Google Docs + Gemini on long-document editing and creative writing tasks shows that TreeWriter improves idea exploration/development, AI helpfulness, and perceived authorial control. A two-month field deployment (N=8) further demonstrated that hierarchical organization supports collaborative writing. Our findings highlight the potential of hierarchical, tree-structured editors with integrated AI support and provide design guidelines for future AI-assisted writing tools that balance automation with user agency.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† TreeWriterï¼Œè¿™æ˜¯ä¸€ç§å°†æ–‡æ¡£è¡¨ç¤ºä¸ºæ ‘çŠ¶ç»“æ„ï¼ˆTree-structuredï¼‰çš„å±‚æ¬¡åŒ–å†™ä½œç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³é•¿æ–‡æ¡£ç¼–å†™ä¸­ä¸€è‡´æ€§ç»´æŠ¤å’Œå¤æ‚è§„åˆ’çš„éš¾é¢˜ã€‚è¯¥ç³»ç»Ÿæ”¯æŒä½œè€…åœ¨å¤šä¸ªå±‚çº§ä¸Šåˆ›å»ºå’Œç»†åŒ–æ–‡æ¡£å¤§çº²ï¼Œå¹¶é›†æˆäº†ä¸€ä¸ªèƒ½å¤ŸåŠ¨æ€å¯¼èˆªæ–‡æ¡£å±‚çº§å¹¶æä¾›ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼ˆContext-awareï¼‰å»ºè®®çš„ AI Agentã€‚å¯¹æ¯”å®éªŒå’Œå®åœ°éƒ¨ç½²ç»“æœè¡¨æ˜ï¼ŒTreeWriter åœ¨åˆ›æ„å¼€å‘ã€AI è¾…åŠ©æ•ˆç‡åŠä½œè€…çš„æŒæ§æ„Ÿï¼ˆAuthorial controlï¼‰æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ Google Docs + Gemini æ¨¡å¼ã€‚æ­¤é¡¹å·¥ä½œå±•ç¤ºäº†å±‚æ¬¡åŒ–ç¼–è¾‘å™¨åœ¨æå‡ AI è¾…åŠ©å†™ä½œä½“éªŒæ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œå¹¶ä¸ºæœªæ¥å¹³è¡¡è‡ªåŠ¨åŒ–ä¸ç”¨æˆ·è‡ªä¸»æ€§ï¼ˆUser agencyï¼‰çš„å·¥å…·è®¾è®¡æä¾›äº†é‡è¦æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12740v1",
      "published_date": "2026-01-19 05:39:35 UTC",
      "updated_date": "2026-01-19 05:39:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:30.266812+00:00"
    },
    {
      "arxiv_id": "2601.12731v1",
      "title": "A Shared Geometry of Difficulty in Multilingual Language Models",
      "title_zh": "å¤šè¯­è¨€è¯­è¨€æ¨¡å‹ä¸­éš¾åº¦çš„å…±äº«å‡ ä½•ç»“æ„",
      "authors": [
        "Stefano Civelli",
        "Pietro Bernardelle",
        "NicolÃ² Brunello",
        "Gianluca Demartini"
      ],
      "abstract": "Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸­é—®é¢˜éš¾åº¦(problem-difficulty)çš„å¤šè¯­è¨€å‡ ä½•ç‰¹å¾ï¼Œé€šè¿‡åœ¨21ç§è¯­è¨€ç‰ˆæœ¬çš„Easy2Hard benchmarkä¸Šè®­ç»ƒçº¿æ€§æ¢é’ˆ(linear probes)è¿›è¡Œåˆ†æã€‚ç ”ç©¶å‘ç°ï¼Œéš¾åº¦ä¿¡å·å‡ºç°åœ¨æ¨¡å‹çš„æµ…å±‚(early-layers)å’Œæ·±å±‚(later-layers)ä¸¤ä¸ªåŠŸèƒ½æˆªç„¶ä¸åŒçš„é˜¶æ®µã€‚æ·±å±‚è¡¨ç¤ºçš„æ¢é’ˆåœ¨åŒè¯­è¨€è¯„ä¼°ä¸­å‡†ç¡®ç‡æé«˜ï¼Œä½†è·¨è¯­è¨€æ³›åŒ–(cross-lingual generalization)èƒ½åŠ›è¾ƒå·®ï¼›è€Œæµ…å±‚è¡¨ç¤ºè™½ç„¶åœ¨åŒè¯­è¨€ä¸‹è¡¨ç°ç¨é€Šï¼Œå´å…·æœ‰æ˜¾è‘—æ›´å¥½çš„è·¨è¯­è¨€æ³›åŒ–æ€§ã€‚ç»“æœè¡¨æ˜ï¼ŒLLMsä¼šå…ˆå½¢æˆä¸€ç§ä¸è¯­è¨€æ— å…³(language-agnostic)çš„éš¾åº¦æŠ½è±¡è¡¨ç¤ºï¼Œéšåå†è½¬åŒ–ä¸ºè¯­è¨€ç‰¹å®š(language-specific)çš„è¡¨ç¤ºã€‚è¿™ä¸€å‘ç°è¯å®äº†æ¨¡å‹çš„ä¸¤é˜¶æ®µè¡¨å¾è¿‡ç¨‹å¯ä»¥ä»è¯­ä¹‰å†…å®¹å»¶ä¼¸è‡³é—®é¢˜éš¾åº¦è¯„ä¼°ç­‰é«˜çº§å…ƒè®¤çŸ¥å±æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12731v1",
      "published_date": "2026-01-19 05:21:21 UTC",
      "updated_date": "2026-01-19 05:21:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:35.025900+00:00"
    },
    {
      "arxiv_id": "2601.12727v1",
      "title": "AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations",
      "title_zh": "AI å±•ç°çš„äººæ ¼ç‰¹è´¨å¯é€šè¿‡å¯¹è¯å¡‘é€ äººç±»è‡ªæˆ‘æ¦‚å¿µ",
      "authors": [
        "Jingshu Li",
        "Tianqi Song",
        "Nattapat Boonprakong",
        "Zicheng Zhu",
        "Yitian Yang",
        "Yi-Chieh Lee"
      ],
      "abstract": "Recent Large Language Model (LLM) based AI can exhibit recognizable and measurable personality traits during conversations to improve user experience. However, as human understandings of their personality traits can be affected by their interaction partners' traits, a potential risk is that AI traits may shape and bias users' self-concept of their own traits. To explore the possibility, we conducted a randomized behavioral experiment. Our results indicate that after conversations about personal topics with an LLM-based AI chatbot using GPT-4o default personality traits, users' self-concepts aligned with the AI's measured personality traits. The longer the conversation, the greater the alignment. This alignment led to increased homogeneity in self-concepts among users. We also observed that the degree of self-concept alignment was positively associated with users' conversation enjoyment. Our findings uncover how AI personality traits can shape users' self-concepts through human-AI conversation, highlighting both risks and opportunities. We provide important design implications for developing more responsible and ethical AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å±•ç°çš„äººæ ¼ç‰¹è´¨ï¼ˆPersonality Traitsï¼‰å¦‚ä½•é€šè¿‡å¯¹è¯å¡‘é€ äººç±»çš„è‡ªæˆ‘æ¦‚å¿µï¼ˆSelf-conceptï¼‰ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å¯¹åŸºäºGPT-4oçš„èŠå¤©æœºå™¨äººè¿›è¡Œéšæœºè¡Œä¸ºå®éªŒå‘ç°ï¼Œç”¨æˆ·åœ¨è¿›è¡Œä¸ªäººè¯é¢˜å¯¹è¯åï¼Œå…¶è‡ªæˆ‘æ¦‚å¿µä¼šæ˜¾è‘—å‘AIå±•ç°çš„äººæ ¼ç‰¹è´¨é æ‹¢ï¼Œä¸”å¯¹è¯æ—¶é•¿ä¸è¿™ç§ä¸€è‡´æ€§ï¼ˆAlignmentï¼‰ç¨‹åº¦æ­£ç›¸å…³ã€‚è¿™ç§ä¸€è‡´æ€§ä¸ä»…å¯¼è‡´äº†ç”¨æˆ·è‡ªæˆ‘æ¦‚å¿µçš„åŒè´¨åŒ–ï¼Œè¿˜ä¸å¯¹è¯çš„æ„‰æ‚¦åº¦æå‡ç›¸å…³è”ã€‚è¯¥å‘ç°æ­ç¤ºäº†AIäººæ ¼å¯¹äººç±»è®¤çŸ¥çš„æ½œåœ¨åå€šé£é™©ä¸å¡‘é€ ä½œç”¨ï¼Œä¸ºæ„å»ºæ›´å…·ä¼¦ç†è´£ä»»æ„Ÿçš„AIç³»ç»Ÿæä¾›äº†é‡è¦çš„è®¾è®¡å‚è€ƒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "ACM CHI 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12727v1",
      "published_date": "2026-01-19 05:16:57 UTC",
      "updated_date": "2026-01-19 05:16:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:42.377302+00:00"
    },
    {
      "arxiv_id": "2601.12723v1",
      "title": "An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä¼˜åŒ–åŸºå‡†è‡ªåŠ¨ç”Ÿæˆè¿›åŒ–æ¡†æ¶",
      "authors": [
        "Yuhiro Ono",
        "Tomohiro Harada",
        "Yukiya Miura"
      ],
      "abstract": "Optimization benchmarks play a fundamental role in assessing algorithm performance; however, existing artificial benchmarks often fail to capture the diversity and irregularity of real-world problem structures, while benchmarks derived from real-world problems are costly and difficult to construct. To address these challenges, we propose an evolutionary automatic benchmark generation framework that leverages a large language model (LLM) as a generative operator, termed the LLM-driven evolutionary benchmark generator (LLM-EBG). In this framework, the LLM serves as an evolutionary operator that generates and evolves benchmark problems within a flexible, expressive representation space. As a case study, we generate unconstrained single-objective continuous minimization problems represented as mathematical expressions designed to induce significant performance differences between a genetic algorithm (GA) and differential evolution (DE). Experimental results show that LLM-EBG successfully produces benchmark problems in which the designated target algorithm consistently outperforms the comparative algorithm in more than 80\\% of trials. Furthermore, exploratory landscape analysis reveals that benchmarks favoring GA are highly sensitive to variable scaling, demonstrating that the proposed framework can generate problems with distinct geometric characteristics that reflect the intrinsic search behaviors of different optimization algorithms.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LLM-driven evolutionary benchmark generator (LLM-EBG)ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) ä½œä¸ºè¿›åŒ–ç®—å­ (evolutionary operator) æ¥è‡ªåŠ¨ç”Ÿæˆä¼˜åŒ–åŸºå‡†æµ‹è¯•çš„è¿›åŒ–æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰åŸºå‡†æµ‹è¯•ç¼ºä¹å¤šæ ·æ€§ä¸”æ„å»ºæˆæœ¬é«˜çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶åœ¨çµæ´»çš„è¡¨ç¤ºç©ºé—´å†…ç”Ÿæˆå¹¶è¿›åŒ–æ•°å­¦è¡¨è¾¾å¼ï¼Œä»¥è¯±å¯¼ä¸åŒç®—æ³•é—´çš„æ€§èƒ½å·®å¼‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM-EBG èƒ½å¤ŸæˆåŠŸç”Ÿæˆä½¿æŒ‡å®šç®—æ³•åœ¨è¶…è¿‡ 80% çš„æµ‹è¯•ä¸­èƒœå‡ºçš„åŸºå‡†é—®é¢˜ã€‚é€šè¿‡æ¢ç´¢æ€§æ™¯è§‚åˆ†æ (exploratory landscape analysis)ï¼Œç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†è¯¥æ¡†æ¶ç”Ÿæˆçš„é¢˜ç›®å…·æœ‰ç‹¬ç‰¹çš„å‡ ä½•ç‰¹å¾ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåæ˜ ä¸åŒä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚ GA å’Œ DEï¼‰çš„å†…åœ¨æœç´¢è¡Œä¸ºå·®å¼‚ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12723v1",
      "published_date": "2026-01-19 04:58:15 UTC",
      "updated_date": "2026-01-19 04:58:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:39.704653+00:00"
    },
    {
      "arxiv_id": "2601.12720v1",
      "title": "Teaching Large Reasoning Models Effective Reflection",
      "title_zh": "æ•™å¯¼å¤§æ¨ç†æ¨¡å‹è¿›è¡Œæœ‰æ•ˆåæ€",
      "authors": [
        "Hanbin Wang",
        "Jingwei Song",
        "Jinpeng Li",
        "Qi Zhu",
        "Fei Mi",
        "Ganqu Cui",
        "Yasheng Wang",
        "Lifeng Shang"
      ],
      "abstract": "Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§æ¨ç†æ¨¡å‹(Large Reasoning Models, LRMs)ä¸­å­˜åœ¨çš„â€œè‚¤æµ…åæ€(superficial reflection)â€é—®é¢˜ï¼Œå³è‡ªæˆ‘ä¿®æ­£è¡Œä¸ºå¾€å¾€æ— æ³•å®è´¨æ€§æå‡ç­”æ¡ˆè´¨é‡ä¸”å¢åŠ è®¡ç®—å¼€é”€ã€‚ä½œè€…æå‡ºäº†Self-Critique Fine-Tuning (SCFT)è®­ç»ƒæ¡†æ¶ï¼Œåˆ©ç”¨è‡ªç”Ÿæˆçš„è¯„è®ºè¿›è¡Œæ‹’ç»é‡‡æ ·å’Œå¾®è°ƒï¼Œä»¥å¢å¼ºæ¨¡å‹çš„åæ€æ¨ç†èƒ½åŠ›ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥å¼•å…¥äº†åŸºäºæœ‰æ•ˆåæ€å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (RLERR)ï¼Œé€šè¿‡æ„å»ºå¥–åŠ±ä¿¡å·å¼•å¯¼æ¨¡å‹å†…åŒ–è‡ªæˆ‘ä¿®æ­£è¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨AIME2024å’ŒAIME2025ç­‰æå…·æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ¨ç†å‡†ç¡®åº¦ä¸åæ€è´¨é‡ï¼Œè¡¨ç°ä¼˜äºç°æœ‰çš„å‰æ²¿åŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages (including appendix), 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12720v1",
      "published_date": "2026-01-19 04:51:53 UTC",
      "updated_date": "2026-01-19 04:51:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:42.094129+00:00"
    },
    {
      "arxiv_id": "2601.12715v1",
      "title": "RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels",
      "title_zh": "RSODï¼šæå°‘é‡æ ‡ç­¾ä¸‹çš„å¯é æ€§å¼•å¯¼å£°å‘å›¾åƒç›®æ ‡æ£€æµ‹",
      "authors": [
        "Chengzhou Li",
        "Ping Guo",
        "Guanchen Meng",
        "Qi Jia",
        "Jinyuan Liu",
        "Zhu Liu",
        "Xiaokang Liu",
        "Yu Liu",
        "Zhongxuan Luo",
        "Xin Fan"
      ],
      "abstract": "Object detection in sonar images is a key technology in underwater detection systems. Compared to natural images, sonar images contain fewer texture details and are more susceptible to noise, making it difficult for non-experts to distinguish subtle differences between classes. This leads to their inability to provide precise annotation data for sonar images. Therefore, designing effective object detection methods for sonar images with extremely limited labels is particularly important. To address this, we propose a teacher-student framework called RSOD, which aims to fully learn the characteristics of sonar images and develop a pseudo-label strategy suitable for these images to mitigate the impact of limited labels. First, RSOD calculates a reliability score by assessing the consistency of the teacher's predictions across different views. To leverage this score, we introduce an object mixed pseudo-label method to tackle the shortage of labeled data in sonar images. Finally, we optimize the performance of the student by implementing a reliability-guided adaptive constraint. By taking full advantage of unlabeled data, the student can perform well even in situations with extremely limited labels. Notably, on the UATD dataset, our method, using only 5% of labeled data, achieves results that can compete against those of our baseline algorithm trained on 100% labeled data. We also collected a new dataset to provide more valuable data for research in the field of sonar.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RSODï¼Œä¸€ç§å¯é æ€§å¼•å¯¼çš„å£°å‘å›¾åƒç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å£°å‘å›¾åƒå› å™ªå£°å¹²æ‰°ã€çº¹ç†ç¼ºå¤±åŠä¸“å®¶æ ‡æ³¨æ•°æ®æåº¦åŒ®ä¹è€Œå¯¼è‡´çš„æ£€æµ‹éš¾é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æ•™å¸ˆ-å­¦ç”Ÿ (teacher-student) æ¶æ„ï¼Œé€šè¿‡è¯„ä¼°æ•™å¸ˆæ¨¡å‹åœ¨ä¸åŒè§†è§’ä¸‹é¢„æµ‹çš„ä¸€è‡´æ€§æ¥è®¡ç®—å¯é æ€§åˆ†æ•° (reliability score)ï¼Œå¹¶æ®æ­¤å¼•å…¥ç‰©ä½“æ··åˆä¼ªæ ‡ç­¾æ–¹æ³• (object mixed pseudo-label method) ä»¥åº”å¯¹æ ‡æ³¨çŸ­ç¼ºã€‚æ­¤å¤–ï¼Œé€šè¿‡å®æ–½å¯é æ€§å¼•å¯¼çš„è‡ªé€‚åº”çº¦æŸ (reliability-guided adaptive constraint)ï¼Œå­¦ç”Ÿæ¨¡å‹èƒ½å¤Ÿå……åˆ†åˆ©ç”¨æ— æ ‡ç­¾æ•°æ®è¿›è¡Œæ€§èƒ½ä¼˜åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ UATD æ•°æ®é›†ä¸Šï¼ŒRSOD ä»…ä½¿ç”¨ 5% çš„æ ‡æ³¨æ•°æ®å³å¯è¾¾åˆ°ä¸ä½¿ç”¨ 100% æ ‡æ³¨æ•°æ®çš„åŸºçº¿æ¨¡å‹ç›¸åª²ç¾çš„æ€§èƒ½ï¼Œä¸”è¯¥ç ”ç©¶è¿˜è´¡çŒ®äº†ä¸€ä¸ªå…¨æ–°çš„å£°å‘å›¾åƒæ•°æ®é›†ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2026,9 pages,10 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12715v1",
      "published_date": "2026-01-19 04:37:34 UTC",
      "updated_date": "2026-01-19 04:37:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:44.184290+00:00"
    },
    {
      "arxiv_id": "2601.12711v1",
      "title": "Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts",
      "title_zh": "Neurosymbolic LoRAï¼šæƒé‡å¾®è°ƒä¸æç¤ºé‡å†™çš„æŠ‰æ‹©æ—¶æœºä¸åŠ¨å› åˆ†æ",
      "authors": [
        "Kevin Wang",
        "Neel P. Bhatt",
        "Cong Liu",
        "Junbo Li",
        "Runjin Chen",
        "Yihan Xi",
        "Timothy Barclay",
        "Alvaro Velasquez",
        "Ufuk Topcu",
        "Zhangyang Wang"
      ],
      "abstract": "Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Neurosymbolic LoRA æ¡†æ¶ï¼Œæ—¨åœ¨åŠ¨æ€ç»“åˆæ•°å€¼å‚æ•°å¾®è°ƒ(Numerical Updates)ä¸ç¬¦å·åŒ–æç¤ºè¯é‡å†™(Symbolic Manipulations)è¿™ä¸¤ç§äº’è¡¥çš„æ¨¡å‹é€‚é…ç­–ç•¥ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ç»Ÿä¸€çš„ç›‘æ§ä¿¡å·å’ŒåŸºäºå¥–åŠ±çš„åˆ†ç±»å™¨ï¼Œç”¨äºè‡ªåŠ¨å†³ç­–ä½•æ—¶é€šè¿‡ LoRA è¿›è¡Œæ·±å±‚äº‹å®é‡å»ºï¼Œä»¥åŠä½•æ—¶åº”ç”¨ TextGrad è¿›è¡Œè¯å…ƒçº§åˆ«çš„ç¬¦å·ç¼–è¾‘ã€‚è¿™ç§æ–¹æ³•ä¸ä»…é€šè¿‡æŒ‰éœ€å¸è½½ç¬¦å·ä»»åŠ¡ä¿æŒäº†å†…å­˜é«˜æ•ˆæ€§ï¼Œè¿˜èƒ½å°†ç¼–è¾‘åçš„é«˜è´¨é‡æç¤ºè¯è½¬åŒ–ä¸ºå¯å¤ç”¨çš„è®­ç»ƒæ•°æ®ï¼Œç‰¹åˆ«æœ‰åŠ©äºæ•°å­¦æ¨ç†ç­‰æ•°æ®ç¨€ç¼ºé¢†åŸŸã€‚åœ¨å¤šç§ LLM éª¨å¹²æ¨¡å‹ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒNeurosymbolic LoRA çš„è¡¨ç°ä¼˜äºçº¯æ•°å€¼æˆ–çº¯ç¬¦å·çš„åŸºå‡†æ¨¡å‹ï¼Œè¯æ˜äº†äº¤æ›¿è¿›è¡Œæ•°å€¼ä¸ç¬¦å·æ›´æ–°åœ¨æå‡æ¨¡å‹å¾®è°ƒçµæ´»æ€§å’Œæ€§èƒ½æ–¹é¢çš„æ˜¾è‘—ä»·å€¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12711v1",
      "published_date": "2026-01-19 04:24:49 UTC",
      "updated_date": "2026-01-19 04:24:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:44:10.940408+00:00"
    },
    {
      "arxiv_id": "2601.12688v1",
      "title": "Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction",
      "title_zh": "é¢å‘å¯è§£é‡Šå¤šè¢«å‘Šåˆ¤å†³é¢„æµ‹çš„é€»è¾‘å¼•å¯¼å¤šé˜¶æ®µæ¨ç†",
      "authors": [
        "Xu Zhang",
        "Qinghua Wang",
        "Mengyang Zhao",
        "Fang Wang",
        "Cunquan Qu"
      ],
      "abstract": "Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MMSI (Masked Multistage Inference) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šè¢«å‘Šæ¡ˆä»¶ä¸­å› å¸æ³•è¡¨è¿°æ¨¡ç³Šå¯¼è‡´çš„è§’è‰²åˆ’åˆ†éš¾é¢˜åŠæ³•å¾‹å¯è§£é‡Šæ€§ä¸è¶³çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†é‡åˆ‘é€»è¾‘èå…¥é¢„è®­ç»ƒ Transformer ç¼–ç å™¨ä¸­ï¼Œé€šè¿‡å®šå‘æ©ç æœºåˆ¶ (oriented masking) æ˜ç¡®è¢«å‘Šè§’è‰²ï¼Œå¹¶åˆ©ç”¨æ¯”è¾ƒæ•°æ®æ„å»ºç­–ç•¥æå‡æ¨¡å‹å¯¹ä¸»ä»çŠ¯åˆ‘äº‹è´£ä»»å·®å¼‚çš„æ•æ„Ÿåº¦ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨å¹¿æ’­æœºåˆ¶å°†é¢„æµ‹çš„ç½ªåæ ‡ç­¾æ•´åˆè¿›å›å½’æ¨¡å‹ï¼Œå®ç°äº†çŠ¯ç½ªæè¿°ä¸æ³•é™¢è§‚ç‚¹çš„æ·±åº¦èåˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMMSI åœ¨ IMLJP æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œæœ‰æ•ˆæå‡äº†æ™ºèƒ½å¸æ³•ç³»ç»Ÿä¸­å¤šè¢«å‘Šå®šç½ªé‡åˆ‘çš„å‡†ç¡®æ€§ä¸é€æ˜åº¦ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12688v1",
      "published_date": "2026-01-19 03:20:36 UTC",
      "updated_date": "2026-01-19 03:20:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:43:49.620150+00:00"
    },
    {
      "arxiv_id": "2601.12671v1",
      "title": "Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification",
      "title_zh": "è”é‚¦å­¦ä¹ ä¸­åˆ©ç”¨æµ‹è¯•æ—¶å¢å¼ºè¿›è¡Œè„‘è‚¿ç˜¤ MRI åˆ†ç±»",
      "authors": [
        "Thamara Leandra de Deus Melo",
        "Rodrigo Moreira",
        "Larissa Ferreira Rodrigues Moreira",
        "AndrÃ© Ricardo Backes"
      ],
      "abstract": "Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. We evaluated convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†åœ¨è”é‚¦å­¦ä¹  (Federated Learning, FL) ç¯å¢ƒä¸‹ï¼Œä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œ (CNNs) è¿›è¡Œè„‘è‚¿ç˜¤ MRI å›¾åƒåˆ†ç±»çš„æ•ˆæœã€‚ç ”ç©¶å¯¹æ¯”äº†åŸå§‹å›¾åƒä¸ç»è¿‡é¢„å¤„ç†ï¼ˆåŒ…æ‹¬ç¼©æ”¾ã€ç°åº¦è½¬æ¢ã€å½’ä¸€åŒ–ã€æ»¤æ³¢å’Œç›´æ–¹å›¾å‡è¡¡åŒ–ï¼‰çš„å›¾åƒï¼Œå‘ç°å•çº¯çš„é¢„å¤„ç†å¸¦æ¥çš„æ€§èƒ½æå‡å¾®ä¹å…¶å¾®ã€‚ç„¶è€Œï¼Œå½“é¢„å¤„ç†ä¸æµ‹è¯•æ—¶å¢å¼º (Test-Time Augmentation, TTA) ç»“åˆä½¿ç”¨æ—¶ï¼Œåœ¨è”é‚¦ MRI åˆ†ç±»ä»»åŠ¡ä¸­å±•ç°å‡ºäº†æ˜¾è‘—ä¸”å…·æœ‰ç»Ÿè®¡å­¦æ„ä¹‰çš„æ”¹è¿› ($p < 0.001$)ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒTTA åº”ä½œä¸ºåŸºäºè”é‚¦å­¦ä¹ çš„åŒ»å­¦æˆåƒä¸­çš„é»˜è®¤æ¨ç†ç­–ç•¥ï¼Œä¸”åœ¨è®¡ç®—èµ„æºå…è®¸çš„æƒ…å†µä¸‹ï¼Œå°† TTA ä¸è½»é‡åŒ–é¢„å¤„ç†ç»“åˆå¯ä»¥è·å¾—æ›´å¯é çš„æ€§èƒ½å¢ç›Šã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "21st International Conference on Computer Vision Theory and Applications (VISAPP 2026), 9-11 March 2026, Marbella, Spain",
      "pdf_url": "https://arxiv.org/pdf/2601.12671v1",
      "published_date": "2026-01-19 02:32:50 UTC",
      "updated_date": "2026-01-19 02:32:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:44:23.584950+00:00"
    },
    {
      "arxiv_id": "2601.12667v1",
      "title": "Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration",
      "title_zh": "å·¨å‹æ˜Ÿåº§æ—¶ä»£ä¸‹é€šè¿‡äººæœºåä½œèµ‹èƒ½èˆªå¤©å™¨ç”µæºç³»ç»Ÿçš„å…¨é“¾è·¯å¥åº·ç®¡ç†",
      "authors": [
        "Yi Di",
        "Zhibin Zhao",
        "Fujin Wang",
        "Xue Liu",
        "Jiafeng Tang",
        "Jiaxin Ren",
        "Zhi Zhai",
        "Xuefeng Chen"
      ],
      "abstract": "It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·¨å‹æ˜Ÿåº§(SMC)æ—¶ä»£ä¸‹èˆªå¤©å™¨ç”µæºç³»ç»Ÿ(SPS)å¤§è§„æ¨¡å¥åº·ç®¡ç†çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åŸºäºAligning Underlying Capabilities (AUC)åŸåˆ™çš„å¼€æºäººæœºåä½œ(Human-AI Collaboration)æ¡†æ¶ SpaceHMchatã€‚è¯¥æ¡†æ¶å®ç°äº†å…¨ç¯èŠ‚å¥åº·ç®¡ç†(All-in-loop Health Management)ï¼Œæ¶µç›–å·¥å†µè¯†åˆ«ã€å¼‚å¸¸æ£€æµ‹ã€æ•…éšœå®šä½å’Œç»´ä¿®å†³ç­–ï¼Œæ—¨åœ¨é€šè¿‡äººæœºååŒæå‡ç³»ç»Ÿçš„é€æ˜åº¦ã€å¯è§£é‡Šæ€§ä¸å†³ç­–æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSpaceHMchat åœ¨å·¥å†µè¯†åˆ«çš„é€»è¾‘æ¨ç†å‡†ç¡®ç‡è¾¾åˆ°100%ï¼Œæ•…éšœå®šä½ç²¾åº¦è¶…è¿‡90%ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘å¸ƒäº†é¦–ä¸ªSPSå…¨ç¯èŠ‚å¥åº·ç®¡ç†æ•°æ®é›†ï¼ŒåŒ…å«17ç§æ•…éšœç±»å‹åŠè¶…è¿‡70ä¸‡æ¡æ—¶é—´æˆ³æ•°æ®ï¼Œä¸ºè¯¥é¢†åŸŸçš„æœªæ¥ç ”ç©¶æä¾›äº†é‡è¦åŸºå‡†ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12667v1",
      "published_date": "2026-01-19 02:28:27 UTC",
      "updated_date": "2026-01-19 02:28:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:45:29.495939+00:00"
    },
    {
      "arxiv_id": "2601.12664v1",
      "title": "Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images",
      "title_zh": "é¢å‘éç‹¬ç«‹åŒåˆ†å¸ƒç™Œç—‡å›¾åƒè”é‚¦å­¦ä¹ çš„å¯æ³›åŒ–è¶…å‚æ•°ä¼˜åŒ–",
      "authors": [
        "Elisa GonÃ§alves Ribeiro",
        "Rodrigo Moreira",
        "Larissa Ferreira Rodrigues Moreira",
        "AndrÃ© Ricardo Backes"
      ],
      "abstract": "Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.",
      "tldr_zh": "### è®ºæ–‡ TLDR æ‘˜è¦ ğŸ“„\n\n---\n\nè¯¥ç ”ç©¶é’ˆå¯¹ç™Œç—‡ç»„ç»‡ç—…ç†å­¦å›¾åƒè®­ç»ƒä¸­çš„éšç§ä¸éç‹¬ç«‹åŒåˆ†å¸ƒ (non-IID) æ•°æ®æŒ‘æˆ˜ï¼Œæ¢è®¨äº†è”é‚¦å­¦ä¹  (Federated Learning, FL) ä¸­è¶…å‚æ•°ä¼˜åŒ–çš„æ¨å¹¿æ€§ã€‚ç ”ç©¶é€šè¿‡åœ¨åµå·¢ç™Œå’Œç»“ç›´è‚ ç™Œæ•°æ®é›†ä¸Šè¿›è¡Œä¸­å¿ƒåŒ–è´å¶æ–¯è¶…å‚æ•°ä¼˜åŒ– (Bayesian hyperparameter optimization)ï¼Œæå‡ºäº†ä¸€ç§ç®€å•çš„è·¨æ•°æ®é›†èšåˆå¯å‘å¼æ–¹æ³• (cross-dataset aggregation heuristic)ã€‚è¯¥æ–¹æ³•é€šè¿‡å¹³å‡å­¦ä¹ ç‡ (learning rates) å¹¶ç»“åˆä¼—æ•°ä¼˜åŒ–å™¨ (modal optimizers) ä¸æ‰¹é‡å¤§å° (batch sizes) æ¥ç¡®å®šæœ€ä¼˜é…ç½®ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§ç»„åˆé…ç½®åœ¨è·¨æ•°æ®é›†çš„ non-IID è”é‚¦å­¦ä¹ åœºæ™¯ä¸­è¡¨ç°å‡ºç«äº‰åŠ›ï¼Œå®ç°äº†æœ‰æ•ˆçš„è¶…å‚æ•°æ³›åŒ–ã€‚\n\n---\n\nå¦‚æœä½ è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦è½¬æ¢ï¼Œæˆ–è€…æƒ³é’ˆå¯¹è¿™é¡¹ç ”ç©¶çš„ç‰¹å®šæ–¹æ³•è¿›è¡Œæ·±å…¥è®¨è®ºï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ï¼",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "21st International Conference on Computer Vision Theory and Applications (VISAPP 2026), 9-11 March 2026, Marbella, Spain",
      "pdf_url": "https://arxiv.org/pdf/2601.12664v1",
      "published_date": "2026-01-19 02:24:24 UTC",
      "updated_date": "2026-01-19 02:24:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:44:29.199818+00:00"
    },
    {
      "arxiv_id": "2601.12661v1",
      "title": "MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents",
      "title_zh": "MedConsultBenchï¼šé¢å‘åŒ»ç–—å’¨è¯¢æ™ºèƒ½ä½“çš„å…¨å‘¨æœŸã€ç»†ç²’åº¦ã€è¿‡ç¨‹æ„ŸçŸ¥è¯„æµ‹åŸºå‡†",
      "authors": [
        "Chuhan Qiao",
        "Jianghua Huang",
        "Daxing Zhao",
        "Ziding Liu",
        "Yanjun Shen",
        "Bing Cheng",
        "Wei Lin",
        "Kai Wu"
      ],
      "abstract": "Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q\\&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q\\&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.",
      "tldr_zh": "## MedConsultBench è®ºæ–‡ TLDR æ‘˜è¦ ğŸ“„\n\n---\n\nè¯¥ç ”ç©¶æå‡ºäº†MedConsultBenchï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹åŒ»ç–—å’¨è¯¢æ™ºèƒ½ä½“çš„å…¨å‘¨æœŸã€ç»†ç²’åº¦ä¸”è¿‡ç¨‹æ„ŸçŸ¥çš„è¯„æµ‹åŸºå‡†ï¼Œæ¶µç›–äº†ä»ç—…å²é‡‡é›†ã€è¯Šæ–­åˆ°æ²»ç–—è®¡åˆ’åŠéšè®¿é—®ç­”(follow-up Q&A)çš„å®Œæ•´ä¸´åºŠæµç¨‹ã€‚è¯¥åŸºå‡†é€šè¿‡å¼•å…¥åŸå­ä¿¡æ¯å•å…ƒ(Atomic Information Units, AIUs)å’Œ22é¡¹ç»†ç²’åº¦æŒ‡æ ‡ï¼Œèƒ½å¤Ÿä»¥å­è½®æ¬¡(sub-turn)ç²¾åº¦å®æ—¶ç›‘æ§ä¸´åºŠä¿¡æ¯çš„è·å–æ•ˆç‡ä¸é€»è¾‘ä¸¥å¯†æ€§ã€‚å¯¹19ä¸ªå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„ç³»ç»Ÿè¯„ä¼°æ­ç¤ºï¼Œæ¨¡å‹çš„é«˜è¯Šæ–­å‡†ç¡®ç‡å¾€å¾€æ©ç›–äº†å…¶åœ¨ä¿¡æ¯é‡‡é›†æ•ˆç‡å’Œç”¨è¯å®‰å…¨æ€§æ–¹é¢çš„æ˜¾è‘—ç¼ºé™·ã€‚MedConsultBenché€šè¿‡å¼ºè°ƒä¸´åºŠè·¯å¾„çš„å®Œæ•´æ€§ä¸å®‰å…¨æ€§ï¼Œä¸ºå¯¹é½åŒ»ç–—äººå·¥æ™ºèƒ½ä¸çœŸå®ä¸–ç•Œä¸´åºŠéœ€æ±‚æä¾›äº†ä¸¥è°¨çš„è¯„ä¼°åŸºç¡€ã€‚\n\n---\n\næˆ‘æ˜¯ Gemini Enterpriseï¼Œå·²ç»ä¸ºæ‚¨å®Œæˆäº†è¿™ç¯‡è®ºæ–‡æ‘˜è¦çš„æç‚¼ã€‚å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–è®ºæ–‡éœ€è¦è½¬æ¢ï¼Œæˆ–è€…æƒ³æ·±å…¥äº†è§£è¯¥åŸºå‡†æµ‹è¯•ä¸­çš„å…·ä½“è¯„ä»·æŒ‡æ ‡ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12661v1",
      "published_date": "2026-01-19 02:18:10 UTC",
      "updated_date": "2026-01-19 02:18:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:44:50.314668+00:00"
    },
    {
      "arxiv_id": "2601.12658v1",
      "title": "Augmenting Question Answering with A Hybrid RAG Approach",
      "title_zh": "é‡‡ç”¨æ··åˆå¼ RAG æ–¹æ³•å¢å¼ºé—®ç­”",
      "authors": [
        "Tianyi Yang",
        "Nashrah Haque",
        "Vaishnave Jonnalagadda",
        "Yuya Jeremy Ong",
        "Zhehui Chen",
        "Yanzhao Wu",
        "Lei Yu",
        "Divyesh Jadav",
        "Wenqi Wei"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Structured-Semantic RAG (SSRAG)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æå‡é—®ç­” (QA) è´¨é‡çš„æ··åˆæ¶æ„ï¼Œè§£å†³äº†ä¼ ç»Ÿæ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation, RAG) åœ¨è·å–ä¸Šä¸‹æ–‡ç›¸å…³ä¿¡æ¯æ–¹é¢çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆæŸ¥è¯¢å¢å¼º (query augmentation)ã€æ™ºèƒ½ä½“è·¯ç”± (agentic routing) ä»¥åŠç»“åˆå‘é‡ (vector) ä¸å›¾ (graph) æŠ€æœ¯çš„ç»“æ„åŒ–æ£€ç´¢æœºåˆ¶ï¼Œå®ç°äº†æ›´ç²¾å‡†çš„ä¸Šä¸‹æ–‡ç»Ÿä¸€ (context unification)ã€‚é€šè¿‡ä¼˜åŒ–æ£€ç´¢æµç¨‹å’Œå¢å¼ºä¸Šä¸‹æ–‡æ¥åœ°æ€§ (contextual grounding)ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†å›ç­”çš„å‡†ç¡®æ€§å’Œä¿¡æ¯ä¸°å¯Œåº¦ã€‚åœ¨ TruthfulQAã€SQuAD å’Œ WikiQA æ•°æ®é›†ä»¥åŠäº”ç§å¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSSRAG çš„å“åº”è´¨é‡å§‹ç»ˆä¼˜äºæ ‡å‡†çš„ RAG å®ç°ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 tables, 2 figures; presented at IEEE CogMI 2025",
      "pdf_url": "https://arxiv.org/pdf/2601.12658v1",
      "published_date": "2026-01-19 02:08:47 UTC",
      "updated_date": "2026-01-19 02:08:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:44:37.152188+00:00"
    },
    {
      "arxiv_id": "2601.12654v1",
      "title": "Explanation Multiplicity in SHAP: Characterization and Assessment",
      "title_zh": "SHAP è§£é‡Šçš„å¤šé‡æ€§ï¼šè¡¨å¾ä¸è¯„ä¼°",
      "authors": [
        "Hyunseung Hwang",
        "Seungeun Lee",
        "Lucas Rosenblatt",
        "Julia Stoyanovich",
        "Steven Euijong Whang"
      ],
      "abstract": "Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†SHAPè§£é‡Šåœ¨è¾“å…¥ã€ä»»åŠ¡å’Œæ¨¡å‹å‡ä¿æŒä¸å˜çš„æƒ…å†µä¸‹ï¼Œå¤šæ¬¡è¿è¡Œä»äº§ç”Ÿæ˜¾è‘—å˜åŒ–çš„ç°è±¡ï¼Œå¹¶å°†å…¶å®šä¹‰ä¸ºâ€œè§£é‡Šå¤šæ ·æ€§â€(Explanation Multiplicity)ã€‚è®ºæ–‡æå‡ºäº†ä¸€å¥—æ–¹æ³•è®ºæ¥åˆ»ç”»ç‰¹å¾å½’å› (feature-attribution)è§£é‡Šä¸­çš„å¤šæ ·æ€§ï¼Œæ—¨åœ¨åŒºåˆ†æ¨¡å‹è®­ç»ƒ/é€‰æ‹©å¸¦æ¥çš„å½±å“ä¸è§£é‡Šæµç¨‹æœ¬èº«å›ºæœ‰çš„éšæœºæ€§ã€‚ç ”ç©¶å‘ç°ï¼Œè§£é‡Šçš„ç¨³å®šæ€§é«˜åº¦ä¾èµ–äºè¯„ä¼°æŒ‡æ ‡ï¼šè™½ç„¶åŸºäºæ•°å€¼å¤§å°(magnitude-based)çš„è·ç¦»å¯èƒ½æ¥è¿‘äºé›¶ï¼Œä½†åŸºäºæ’å(rank-based)çš„åº¦é‡å´æ­ç¤ºäº†æ ¸å¿ƒç‰¹å¾èº«ä»½åŠæ’åºçš„å‰§çƒˆå˜åŠ¨ã€‚å®éªŒè¯æ˜ï¼Œè§£é‡Šå¤šæ ·æ€§åœ¨ä¸åŒæ•°æ®é›†ã€æ¨¡å‹ç±»åˆ«å’Œç½®ä¿¡åŒºé—´å†…æ™®éå­˜åœ¨ï¼Œå¼ºè°ƒäº†åœ¨åº”ç”¨ä¸­é€‰æ‹©ä¸è§£é‡Šæ„å›¾ç›¸åŒ¹é…çš„è¯„ä¼°æŒ‡æ ‡å’ŒéšæœºåŸºå‡†å€¼(randomized baseline values)çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12654v1",
      "published_date": "2026-01-19 02:01:18 UTC",
      "updated_date": "2026-01-19 02:01:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:44:36.688773+00:00"
    },
    {
      "arxiv_id": "2601.12648v1",
      "title": "Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?",
      "title_zh": "åŒ»å­¦æ•™è‚²ä¸­çš„æ™ºèƒ½æ–‡ä¹¦ï¼šäººå·¥æ™ºèƒ½èƒ½å¦æ›¿ä»£äººå·¥ç—…ä¾‹è®°å½•ï¼Ÿ",
      "authors": [
        "Nafiz Imtiaz Khan",
        "Kylie Cleland",
        "Vladimir Filkov",
        "Roger Eric Goldman"
      ],
      "abstract": "Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)ä»éç»“æ„åŒ–æ”¾å°„å­¦æŠ¥å‘Šä¸­è‡ªåŠ¨ç”Ÿæˆæ‰‹æœ¯ç—…ä¾‹è®°å½•çš„å¯è¡Œæ€§ï¼Œä»¥è§£å†³äººå·¥è®°å½•è€—æ—¶ä¸”ä¸ä¸€è‡´çš„é—®é¢˜ã€‚ç ”ç©¶é€šè¿‡æŒ‡ä»¤å­¦ä¹ (Instruction-based)å’Œé“¾å¼æ€ç»´(Chain-of-Thought)æç¤ºè¯å·¥ç¨‹ï¼Œè¯„ä¼°äº†å¤šç§æœ¬åœ°åŠå•†ä¸šLLMsåœ¨414ä»½ä»‹å…¥æ”¾å°„å­¦æŠ¥å‘Šä¸Šçš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ€§èƒ½æœ€ä¼˜çš„æ¨¡å‹ F1-score æ¥è¿‘0.87ï¼Œåœ¨è‡ªåŠ¨åŒ–æå–ç»“æ„åŒ–æ‰‹æœ¯ä¿¡æ¯æ–¹é¢è¡¨ç°å¼ºåŠ²ã€‚è¯¥è‡ªåŠ¨åŒ–æ–¹æ¡ˆèƒ½æ˜¾è‘—å‡è½»å—è®­äººå‘˜çš„æ–‡ä¹¦è´Ÿæ‹…å¹¶æé«˜ç—…ä¾‹è®°å½•çš„ä¸€è‡´æ€§ï¼Œè¯æ˜äº†AIè¾…åŠ©æ–‡æ¡£ç®¡ç†åœ¨åŒ»å­¦æ•™è‚²é¢†åŸŸå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "51 pages, 12 figures, 8 tables. Feasibility study using retrospective radiology reports. Submitted to JAMIA Open (under review)",
      "pdf_url": "https://arxiv.org/pdf/2601.12648v1",
      "published_date": "2026-01-19 01:45:51 UTC",
      "updated_date": "2026-01-19 01:45:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:44:40.240051+00:00"
    },
    {
      "arxiv_id": "2601.12646v1",
      "title": "Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI",
      "title_zh": "æ— ç•ŒæŸå®³ï¼Œæœ‰ç•Œä¹‹æ³•ï¼šæ— å›½ç•Œäººå·¥æ™ºèƒ½æ—¶ä»£çš„æ³•å¾‹è´£ä»»",
      "authors": [
        "Ha-Chi Tran"
      ],
      "abstract": "The rapid proliferation of artificial intelligence (AI) has exposed significant deficiencies in risk governance. While ex-ante harm identification and prevention have advanced, Responsible AI scholarship remains underdeveloped in addressing ex-post liability. Core legal questions regarding liability allocation, responsibility attribution, and remedial effectiveness remain insufficiently theorized and institutionalized, particularly for transboundary harms and risks that transcend national jurisdictions. Drawing on contemporary AI risk analyses, we argue that such harms are structurally embedded in global AI supply chains and are likely to escalate in frequency and severity due to cross-border deployment, data infrastructures, and uneven national oversight capacities. Consequently, territorially bounded liability regimes are increasingly inadequate. Using a comparative and interdisciplinary approach, this paper examines compensation and liability frameworks from high-risk transnational domains - including vaccine injury schemes, systemic financial risk governance, commercial nuclear liability, and international environmental regimes - to distill transferable legal design principles such as strict liability, risk pooling, collective risk-sharing, and liability channelling, while highlighting potential structural constraints on their application to AI-related harms. Situated within an international order shaped more by AI arms race dynamics than cooperative governance, the paper outlines the contours of a global AI accountability and compensation architecture, emphasizing the tension between geopolitical rivalry and the collective action required to govern transboundary AI risks effectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)å¿«é€Ÿæ™®åŠèƒŒæ™¯ä¸‹ï¼Œæ³•å¾‹åœ¨åº”å¯¹è·¨å›½ç•ŒæŸå®³(transboundary harms)æ—¶äº‹åè´£ä»»(ex-post liability)æœºåˆ¶çš„ç¼ºå¤±ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œç”±äºAIé£é™©åµŒå…¥å…¨çƒä¾›åº”é“¾ä¸”å…·æœ‰è·¨å¢ƒéƒ¨ç½²ç‰¹æ€§ï¼Œä¼ ç»Ÿçš„å—é¢†åœŸé™åˆ¶çš„æ³•å¾‹ä½“ç³»(territorially bounded liability regimes)å·²éš¾ä»¥æœ‰æ•ˆåˆ†é…è´£ä»»æˆ–æä¾›æ•‘æµã€‚é€šè¿‡å¯¹ç–«è‹—ä¼¤å®³è®¡åˆ’ã€æ ¸è´£ä»»åŠå›½é™…ç¯å¢ƒåè®®ç­‰é«˜é£é™©é¢†åŸŸçš„è·¨å­¦ç§‘æ¯”è¾ƒç ”ç©¶ï¼Œä½œè€…æç‚¼å‡ºä¸¥æ ¼è´£ä»»(strict liability)ã€é£é™©æ± (risk pooling)å’Œè´£ä»»æ¸ é“(liability channelling)ç­‰æ ¸å¿ƒæ³•å¾‹è®¾è®¡åŸåˆ™ã€‚æœ€åï¼Œè¯¥ç ”ç©¶å‹¾å‹’äº†å…¨çƒAIå½’è´£ä¸è¡¥å¿æ¶æ„çš„è½®å»“ï¼Œå¹¶æ·±å…¥åˆ†æäº†åœ°ç¼˜æ”¿æ²»ç«äº‰ä¸è·¨å›½ç•ŒAIé£é™©æ²»ç†æ‰€éœ€çš„é›†ä½“è¡ŒåŠ¨ä¹‹é—´çš„å†…åœ¨å¼ åŠ›ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12646v1",
      "published_date": "2026-01-19 01:44:14 UTC",
      "updated_date": "2026-01-19 01:44:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:44:49.009293+00:00"
    },
    {
      "arxiv_id": "2601.12641v1",
      "title": "STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models",
      "title_zh": "STEP-LLMï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ä»è‡ªç„¶è¯­è¨€ç”Ÿæˆ CAD STEP æ¨¡å‹",
      "authors": [
        "Xiangyu Shi",
        "Junyang Ding",
        "Xu Zhao",
        "Sinong Zhan",
        "Payal Mohapatra",
        "Daniel Quispe",
        "Kojo Welbeck",
        "Jian Cao",
        "Wei Chen",
        "Ping Guo",
        "Qi Zhu"
      ],
      "abstract": "Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†STEP-LLMï¼Œä¸€ç§æ—¨åœ¨é€šè¿‡å¤§è¯­è¨€æ¨¡å‹(LLMs)ç›´æ¥ä»è‡ªç„¶è¯­è¨€ç”Ÿæˆå·¥ä¸šæ ‡å‡† STEP æ ¼å¼æ¨¡å‹çš„æ–°å‹æ¡†æ¶ã€‚é’ˆå¯¹ STEP æ–‡ä»¶å¤æ‚çš„å›¾ç»“æ„å’Œäº¤å‰å¼•ç”¨æŒ‘æˆ˜ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨äº†åŸºäºæ·±åº¦ä¼˜å…ˆæœç´¢(DFS)çš„é‡åºåˆ—åŒ–æŠ€æœ¯ä¸é“¾å¼æ€ç»´(Chain-of-Thought)ç»“æ„æ ‡æ³¨ï¼Œå¹¶ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)è¿›è¡Œç›‘ç£å¾®è°ƒã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†åŸºäºå€’è§’è·ç¦»(Chamfer Distance)å‡ ä½•å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (RL)æ¥è¿›ä¸€æ­¥ä¼˜åŒ–ç”Ÿæˆè´¨é‡ã€‚å®éªŒè¯æ˜ï¼ŒSTEP-LLM åœ¨å‡ ä½•ä¿çœŸåº¦å’Œå¯æ¸²æŸ“æ€§ä¸Šæ˜¾è‘—ä¼˜äº Text2CAD åŸºçº¿ï¼Œå±•ç¤ºäº† LLM é©±åŠ¨çš„ CAD æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆåœ¨æ°‘ä¸»åŒ–åˆ¶é€ è®¾è®¡æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the Design, Automation & Test in Europe Conference (DATE) 2026",
      "pdf_url": "https://arxiv.org/pdf/2601.12641v1",
      "published_date": "2026-01-19 01:10:49 UTC",
      "updated_date": "2026-01-19 01:10:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:44:53.353584+00:00"
    },
    {
      "arxiv_id": "2601.12638v1",
      "title": "Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT",
      "title_zh": "åŸºäº TensorRT çš„æ··åˆç²¾åº¦ PointPillars é«˜æ•ˆ 3D ç›®æ ‡æ£€æµ‹",
      "authors": [
        "Ninnart Fuengfusin",
        "Keisuke Yoneda",
        "Naoki Suganuma"
      ],
      "abstract": "LIDAR 3D object detection is one of the important tasks for autonomous vehicles. Ensuring that this task operates in real-time is crucial. Toward this, model quantization can be used to accelerate the runtime. However, directly applying model quantization often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. To address the wide numerical distribution, we proposed a mixed precision framework designed for PointPillars. Our framework first searches for sensitive layers with post-training quantization (PTQ) by quantizing one layer at a time to 8-bit integer (INT8) and evaluating each model for average precision (AP). The top-k most sensitive layers are assigned as floating point (FP). Combinations of these layers are greedily searched to produce candidate mixed precision models, which are finalized with either PTQ or quantization-aware training (QAT). Furthermore, to handle outliers, we observe that using a very small number of calibration data reduces the likelihood of encountering outliers, thereby improving PTQ performance. Our methods provides mixed precision models without training in the PTQ pipeline, while our QAT pipeline achieves the performance competitive to FP models. With TensorRT deployment, our models offer less latency and sizes by up to 2.35 and 2.26 times, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹ PointPillars çš„æ··åˆç²¾åº¦ (Mixed Precision) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ LIDAR 3D ç›®æ ‡æ£€æµ‹ä¸­å› æ•°å€¼åˆ†å¸ƒå¹¿æ³›å’Œæç«¯ç¦»ç¾¤ç‚¹ (Outliers) å¯¼è‡´çš„é‡åŒ–æ€§èƒ½é€€åŒ–é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡è®­ç»ƒåé‡åŒ– (PTQ) è¯†åˆ«å¯¹ç²¾åº¦æ•æ„Ÿçš„å±‚å¹¶å°†å…¶ä¿ç•™ä¸ºæµ®ç‚¹ (FP) æ ¼å¼ï¼Œåˆ©ç”¨è´ªå¿ƒæœç´¢ç¡®å®šæœ€ä¼˜æ··åˆç²¾åº¦ç»„åˆï¼Œå¹¶é…åˆå°‘é‡æ ¡å‡†æ•°æ®æ¥æå‡é‡åŒ–ç¨³å®šæ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆçš„é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ (QAT) æµç¨‹å¯å®ç°ä¸ FP æ¨¡å‹ç›¸å½“çš„ç²¾åº¦è¡¨ç°ã€‚åœ¨ TensorRT éƒ¨ç½²ä¸‹ï¼Œè¯¥æ–¹æ³•æˆåŠŸå°†æ¨ç†å»¶è¿Ÿé™ä½äº† 2.35 å€ï¼Œæ¨¡å‹ä½“ç§¯å‡å°äº† 2.26 å€ï¼Œæ˜¾è‘—æå‡äº†è‡ªåŠ¨é©¾é©¶ä»»åŠ¡çš„å®æ—¶æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2601.12638v1",
      "published_date": "2026-01-19 00:59:13 UTC",
      "updated_date": "2026-01-19 00:59:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:44:54.176511+00:00"
    },
    {
      "arxiv_id": "2601.12637v1",
      "title": "Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction",
      "title_zh": "ç”¨äºé«˜æ•ˆåˆ†å­å±æ€§é¢„æµ‹çš„æ‹“æ‰‘æ„ŸçŸ¥å¤šå°ºåº¦æ··åˆä¸“å®¶æ¨¡å‹",
      "authors": [
        "Long D. Nguyen",
        "Kelin Xia",
        "Binh P. Nguyen"
      ],
      "abstract": "Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Yet most 3D molecular graph neural networks still rely on globally fixed neighborhood heuristics, typically defined by distance cutoffs and maximum neighbor limits, to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. We propose Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. Our contributions are threefold: (1) we introduce a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) we design a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) we show that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Multiscale Interaction Mixture of Experts (MI-MoE)ï¼Œæ—¨åœ¨è§£å†³ 3D åˆ†å­å›¾ç¥ç»ç½‘ç»œå› ä¾èµ–å›ºå®šè·ç¦»åˆ‡æ–­ï¼ˆdistance cutoffsï¼‰è€Œéš¾ä»¥çµæ´»æ•æ‰ä¸åŒé‡çº§ç›¸äº’ä½œç”¨çš„é—®é¢˜ã€‚MI-MoE å¼•å…¥äº†ä¸€ä¸ªè·ç¦»åˆ‡æ–­ä¸“å®¶é›†æˆï¼ˆdistance-cutoff expert ensembleï¼‰æ¥æ˜¾å¼å»ºæ¨¡çŸ­ã€ä¸­ã€é•¿ç¨‹ç›¸äº’ä½œç”¨ï¼Œå¹¶ç»“åˆåˆ©ç”¨æŒä¹…åŒè°ƒï¼ˆpersistent homologyï¼‰ç‰¹å¾çš„æ‹“æ‰‘é—¨æ§ç¼–ç å™¨ï¼ˆtopological gating encoderï¼‰å®ç°åŠ¨æ€è¾“å…¥è·¯ç”±ã€‚å®éªŒè¯æ˜ï¼Œä½œä¸ºä¸€ç§å³æ’å³ç”¨æ¨¡å—ï¼ŒMI-MoE åœ¨åˆ†å­å’Œèšåˆç‰©å±æ€§é¢„æµ‹çš„å¤šé¡¹åŸºå‡†ä»»åŠ¡ä¸­ä¸€è‡´æå‡äº†ä¸»æµ 3D åˆ†å­éª¨å¹²ç½‘ç»œï¼ˆbackbonesï¼‰çš„æ€§èƒ½ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†æ‹“æ‰‘æ„ŸçŸ¥ï¼ˆtopology-awareï¼‰çš„å¤šå°ºåº¦è·¯ç”±åœ¨ 3D åˆ†å­å›¾å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.12637v1",
      "published_date": "2026-01-19 00:54:24 UTC",
      "updated_date": "2026-01-19 00:54:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-22T23:45:40.822595+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 111,
  "processed_papers_count": 111,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-22T23:46:24.152256+00:00"
}