{
  "date": "2024-06-08",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-08 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 51 篇论文，主要聚焦于 AI 和机器学习领域，尤其是大型语言模型 (LLMs) 的优化、安全性和应用扩展，同时涉及机器人规划、语音合成和网络安全等话题。令人印象深刻的文章包括 NYU 团队开发的 LLM 网络安全基准，以及亚马逊的文本生成精炼方法；有名学者如 Tomas Lozano-Pérez 和 Leslie Pack Kaelbling 等 MIT 研究者参与的机器人智能论文，也值得关注。这些论文突出了 LLM 在实际任务中的潜力，但也暴露了偏见和鲁棒性挑战。\n\n下面，我将挑选最具话题度和影响力的论文优先讨论，将相关主题归类（如 LLM 优化和安全），并快速掠过其他较次要的文章。每篇论文会列出标题（中文 + 英文），并简要描述其核心贡献和发现。\n\n### LLM 优化与安全（重点领域）\n- **NYU CTF Bench: A Scalable Open-Source Benchmark Dataset for Evaluating LLMs in Offensive Security**  \n  这篇论文由 NYU 团队主导，构建了一个可扩展的开源基准数据集，用于评估 LLMs 在网络安全捕获旗帜 (CTF) 挑战中的性能。主要贡献是通过自动化框架测试多种 LLMs（如黑盒和开源模型），发现它们在漏洞检测中的潜力，并提供公开代码。该发现有助于提升 AI 在真实威胁管理中的应用。\n\n- **CERET: Cost-Effective Extrinsic Refinement for Text Generation**  \n  作者包括亚马逊的 Saab Mansour 等。论文提出 CERET 方法，通过语义稳定性和不确定性指标优化 LLMs 的文本生成。主要发现是 CERET 在摘要和问答任务中比自一致性基线提升 1.6% 和 3.5% 的性能，同时仅需 9.4% 的延迟，显著提高了成本效益。\n\n- **Creativity Has Left the Chat: The Price of Debiasing Language Models**  \n  这篇探讨 LLMs 去偏置后的创造力损失。贡献在于实验证明，强化学习从人类反馈 (RLHF) 会降低输出多样性（如熵和嵌入聚类），并建议提示工程可缓解营销任务中的权衡。\n\n- **VP-LLM: Text-Driven 3D Volume Completion with Large Language Models through Patchification**  \n  论文使用 LLMs 指导 3D 对象补全。主要发现是通过分块编码和文本提示，LLMs 能超越扩散模型在生成质量上，提供更精确的 3D 补全。\n\n- **A Fine-tuning Dataset and Benchmark for Large Language Models for Protein Understanding**  \n  作者团队包括 Yu Guang Wang。贡献是构建 ProteinLMDataset（17.46 亿 tokens 和 89.3 万指令），用于 LLMs 在蛋白质理解中的微调。发现 InternLM2-7B 在基准测试中超越 GPT-4，突显 LLMs 在生物领域的潜力。\n\n### 机器人与智能系统（相关主题，快速讨论）\n- **Coupling Machine Learning with Ontology for Robotics Applications**  \n  作者 Osama F. Zaki 提出将机器学习与知识库本体结合的机器人方法。主要贡献是通过实验验证双层智能框架（ML 和 KB），时间复杂度线性增长，提升了自治系统的风险感知。\n\n- **Trust the PRoC3S: Solving Long-Horizon Robotics Problems with LLMs and Constraint Satisfaction**  \n  MIT 学者如 Tomas Lozano-Pérez 参与。论文使用 LLMs 生成代码并结合约束满足问题 (CCSP) 解决机器人任务。主要发现是该方法高效处理长时域操作，避免碰撞，优于现有基线。\n\n### 其他亮点（简要掠过）\n- **Autoregressive Diffusion Transformer for Text-to-Speech Synthesis**  \n  贡献一个 ARDiT 模型，用于文本到语音合成。主要发现是它在零样本场景下媲美或超越最先进模型，支持高质量语音编辑和低延迟生成。\n\n- **Automata Extraction from Transformers**  \n  论文开发算法将 Transformer 模型解释为有限状态自动机 (DFA)。主要发现是它提升了 ML 系统的可解释性，尤其在处理形式语言时。\n\n其他论文如主观性检测、记忆故障预测或资源分配等，虽然涉及 AI 子领域，但相对次要或技术细节较深，我将快速掠过。例如，**ThatiAR: Subjectivity Detection in Arabic News Sentences** 构建了首个阿拉伯主观性检测数据集，提升了 LLM 在多语言任务中的性能；**Online DPO: Online Direct Preference Optimization with Fast-Slow Chasing** 提出 DPO 框架改善 LLM 持续学习，但细节较专业，不展开。\n\n总之，今天的论文强调了 LLMs 的实用性和挑战，建议读者关注安全和优化方向，以推动 AI 更可靠的应用。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2407.02500v1",
      "title": "Coupling Machine Learning with Ontology for Robotics Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Osama F. Zaki"
      ],
      "abstract": "In this paper I present a practical approach for coupling machine learning\n(ML) algorithms with knowledge bases (KB) ontology formalism. The lack of\navailability of prior knowledge in dynamic scenarios is without doubt a major\nbarrier for scalable machine intelligence. My view of the interaction between\nthe two tiers intelligence is based on the idea that when knowledge is not\nreadily available at the knowledge base tier, more knowledge can be extracted\nfrom the other tier, which has access to trained models from machine learning\nalgorithms. To analyse this hypothesis, I create two experiments based on\ndifferent datasets, which are related directly to risk-awareness of autonomous\nsystems, analysed by different machine learning algorithms (namely; multi-layer\nfeedforward backpropagation, Naive Bayes, and J48 decision tree). My analysis\nshows that the two-tiers intelligence approach for coupling ML and KB is\ncomputationally valid and the time complexity of the algorithms during the\nrobot mission is linear with the size of the data and knowledge.",
      "tldr_zh": "本研究提出了一种将机器学习 (ML) 与知识库 (KB) ontology 相结合的实用方法，旨在解决动态场景中缺乏先验知识的挑战。该方法基于双层智能框架，当 KB 中知识不足时，通过训练的 ML 模型提取额外知识，并通过两个实验（使用多层前向反馈传播、Naive Bayes 和 J48 决策树算法）验证其在自主系统风险意识方面的有效性。实验结果显示，这种耦合方法在计算上是可行的，算法的时间复杂度与数据和知识的大小呈线性关系。该框架为机器人应用提供了更具可扩展性的智能解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02500v1",
      "published_date": "2024-06-08 23:38:03 UTC",
      "updated_date": "2024-06-08 23:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:43:33.199985"
    },
    {
      "arxiv_id": "2406.05590v3",
      "title": "NYU CTF Bench: A Scalable Open-Source Benchmark Dataset for Evaluating LLMs in Offensive Security",
      "title_zh": "NYU CTF Bench：用于在进攻性安全领域评估 LLMs 的可扩展开源基准数据集",
      "authors": [
        "Minghao Shao",
        "Sofija Jancheska",
        "Meet Udeshi",
        "Brendan Dolan-Gavitt",
        "Haoran Xi",
        "Kimberly Milner",
        "Boyuan Chen",
        "Max Yin",
        "Siddharth Garg",
        "Prashanth Krishnamurthy",
        "Farshad Khorrami",
        "Ramesh Karri",
        "Muhammad Shafique"
      ],
      "abstract": "Large Language Models (LLMs) are being deployed across various domains today.\nHowever, their capacity to solve Capture the Flag (CTF) challenges in\ncybersecurity has not been thoroughly evaluated. To address this, we develop a\nnovel method to assess LLMs in solving CTF challenges by creating a scalable,\nopen-source benchmark database specifically designed for these applications.\nThis database includes metadata for LLM testing and adaptive learning,\ncompiling a diverse range of CTF challenges from popular competitions.\nUtilizing the advanced function calling capabilities of LLMs, we build a fully\nautomated system with an enhanced workflow and support for external tool calls.\nOur benchmark dataset and automated framework allow us to evaluate the\nperformance of five LLMs, encompassing both black-box and open-source models.\nThis work lays the foundation for future research into improving the efficiency\nof LLMs in interactive cybersecurity tasks and automated task planning. By\nproviding a specialized benchmark, our project offers an ideal platform for\ndeveloping, testing, and refining LLM-based approaches to vulnerability\ndetection and resolution. Evaluating LLMs on these challenges and comparing\nwith human performance yields insights into their potential for AI-driven\ncybersecurity solutions to perform real-world threat management. We make our\nbenchmark dataset open source to public\nhttps://github.com/NYU-LLM-CTF/NYU_CTF_Bench along with our playground\nautomated framework https://github.com/NYU-LLM-CTF/llm_ctf_automation.",
      "tldr_zh": "该研究开发了NYU CTF Bench，一个可扩展的开源基准数据集，用于评估大型语言模型（LLMs）在网络安全领域的攻防挑战（CTF）中表现。数据集包含多样化的CTF挑战元数据，支持LLMs的测试和自适应学习，并通过LLMs的先进功能调用构建了一个全自动系统，允许外部工具调用和增强的工作流程。实验评估了五个LLMs（包括黑盒和开源模型）的性能，与人类表现比较，揭示了AI在自动化威胁管理和漏洞检测方面的潜力。该基准数据集及其自动化框架已开源，供研究者进一步优化LLMs在交互式网络安全任务中的应用。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05590v3",
      "published_date": "2024-06-08 22:21:42 UTC",
      "updated_date": "2025-02-18 12:26:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:43:44.584162"
    },
    {
      "arxiv_id": "2406.05588v2",
      "title": "CERET: Cost-Effective Extrinsic Refinement for Text Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jason Cai",
        "Hang Su",
        "Monica Sunkara",
        "Igor Shalyminov",
        "Saab Mansour"
      ],
      "abstract": "Large Language Models (LLMs) are powerful models for generation tasks, but\nthey may not generate good quality outputs in their first attempt. Apart from\nmodel fine-tuning, existing approaches to improve prediction accuracy and\nquality typically involve LLM self-improvement / self-reflection that\nincorporate feedback from models themselves. Despite their effectiveness, these\nmethods are hindered by their high computational cost and lack of scalability.\nIn this work, we propose CERET, a method for refining text generations by\nconsidering semantic stability, entailment and inter-sample uncertainty\nmeasures. Experimental results show that CERET outperforms Self-consistency and\nSelf-rerank baselines consistently under various task setups, by ~1.6% in\nRouge-1 for abstractive summarization and ~3.5% in hit rate for question\nanswering. Compared to LLM Self-rerank method, our approach only requires 9.4%\nof its latency and is more cost-effective.",
      "tldr_zh": "本文提出 CERET，一种成本有效的外部精炼方法，用于提升大型语言模型 (LLMs) 在文本生成任务中的输出质量，通过考虑语义稳定性、entailment 和 inter-sample uncertainty 措施来优化生成过程。相比现有的自我改进方法如 Self-consistency 和 Self-rerank，CERET 在实验中表现出色，在抽象式总结任务中 Rouge-1 得分提高了约 1.6%，在问答任务中命中率提高了约 3.5%。此外，CERET 的延迟仅为 LLM Self-rerank 方法的 9.4%，显著提高了计算效率和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "The source code and data samples are released at\n  https://github.com/amazon-science/CERET-LLM-refine",
      "pdf_url": "http://arxiv.org/pdf/2406.05588v2",
      "published_date": "2024-06-08 22:17:52 UTC",
      "updated_date": "2024-11-02 03:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:43:57.474072"
    },
    {
      "arxiv_id": "2406.05587v1",
      "title": "Creativity Has Left the Chat: The Price of Debiasing Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Behnam Mohammadi"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\nbut can exhibit biases and may generate toxic content. While alignment\ntechniques like Reinforcement Learning from Human Feedback (RLHF) reduce these\nissues, their impact on creativity, defined as syntactic and semantic\ndiversity, remains unexplored. We investigate the unintended consequences of\nRLHF on the creativity of LLMs through three experiments focusing on the\nLlama-2 series. Our findings reveal that aligned models exhibit lower entropy\nin token predictions, form distinct clusters in the embedding space, and\ngravitate towards \"attractor states\", indicating limited output diversity. Our\nfindings have significant implications for marketers who rely on LLMs for\ncreative tasks such as copywriting, ad creation, and customer persona\ngeneration. The trade-off between consistency and creativity in aligned models\nshould be carefully considered when selecting the appropriate model for a given\napplication. We also discuss the importance of prompt engineering in harnessing\nthe creative potential of base models.",
      "tldr_zh": "本研究探讨了使用对齐技术如 Reinforcement Learning from Human Feedback (RLHF) 来减少大型语言模型 (LLMs) 的偏差和毒性内容，但这可能导致创造力下降。研究通过针对 Llama-2 系列模型的三项实验，分析了 token 预测的熵、嵌入空间的聚类以及吸引子状态，发现对齐模型的输出多样性降低，表现为较低的句法和语义多样性。结果表明，这种权衡在营销应用（如文案撰写和广告创作）中值得注意，用户应考虑模型的一致性与创造力平衡，并通过提示工程来挖掘基础模型的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05587v1",
      "published_date": "2024-06-08 22:14:51 UTC",
      "updated_date": "2024-06-08 22:14:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:44:08.010980"
    },
    {
      "arxiv_id": "2406.05572v2",
      "title": "Trust the PRoC3S: Solving Long-Horizon Robotics Problems with LLMs and Constraint Satisfaction",
      "title_zh": "翻译失败",
      "authors": [
        "Aidan Curtis",
        "Nishanth Kumar",
        "Jing Cao",
        "Tomás Lozano-Pérez",
        "Leslie Pack Kaelbling"
      ],
      "abstract": "Recent developments in pretrained large language models (LLMs) applied to\nrobotics have demonstrated their capacity for sequencing a set of discrete\nskills to achieve open-ended goals in simple robotic tasks. In this paper, we\nexamine the topic of LLM planning for a set of continuously parameterized\nskills whose execution must avoid violations of a set of kinematic, geometric,\nand physical constraints. We prompt the LLM to output code for a function with\nopen parameters, which, together with environmental constraints, can be viewed\nas a Continuous Constraint Satisfaction Problem (CCSP). This CCSP can be solved\nthrough sampling or optimization to find a skill sequence and continuous\nparameter settings that achieve the goal while avoiding constraint violations.\nAdditionally, we consider cases where the LLM proposes unsatisfiable CCSPs,\nsuch as those that are kinematically infeasible, dynamically unstable, or lead\nto collisions, and re-prompt the LLM to form a new CCSP accordingly.\nExperiments across three different simulated 3D domains demonstrate that our\nproposed strategy, PRoC3S, is capable of solving a wide range of complex\nmanipulation tasks with realistic constraints on continuous parameters much\nmore efficiently and effectively than existing baselines.",
      "tldr_zh": "本研究提出PRoC3S策略，利用大型语言模型（LLMs）和约束满足技术来解决长时序机器人问题，特别是针对连续参数化的技能序列，确保避免运动学、几何和物理约束的违反。方法涉及提示LLM输出带有开放参数的代码函数，形成Continuous Constraint Satisfaction Problem (CCSP)，并通过采样或优化解决CCSP，以生成可行的技能序列；若LLM生成不可满足的CCSP（如运动学不可行或碰撞风险），则重新提示LLM进行调整。实验在三个模拟3D领域中显示，PRoC3S比现有基线更高效有效，能够处理复杂操作任务。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05572v2",
      "published_date": "2024-06-08 20:56:14 UTC",
      "updated_date": "2024-09-06 02:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:44:21.937891"
    },
    {
      "arxiv_id": "2406.05564v1",
      "title": "Automata Extraction from Transformers",
      "title_zh": "从Transformer中提取自动机",
      "authors": [
        "Yihao Zhang",
        "Zeming Wei",
        "Meng Sun"
      ],
      "abstract": "In modern machine (ML) learning systems, Transformer-based architectures have\nachieved milestone success across a broad spectrum of tasks, yet understanding\ntheir operational mechanisms remains an open problem. To improve the\ntransparency of ML systems, automata extraction methods, which interpret\nstateful ML models as automata typically through formal languages, have proven\neffective for explaining the mechanism of recurrent neural networks (RNNs).\nHowever, few works have been applied to this paradigm to Transformer models. In\nparticular, understanding their processing of formal languages and identifying\ntheir limitations in this area remains unexplored. In this paper, we propose an\nautomata extraction algorithm specifically designed for Transformer models.\nTreating the Transformer model as a black-box system, we track the model\nthrough the transformation process of their internal latent representations\nduring their operations, and then use classical pedagogical approaches like L*\nalgorithm to interpret them as deterministic finite-state automata (DFA).\nOverall, our study reveals how the Transformer model comprehends the structure\nof formal languages, which not only enhances the interpretability of the\nTransformer-based ML systems but also marks a crucial step toward a deeper\nunderstanding of how ML systems process formal languages. Code and data are\navailable at https://github.com/Zhang-Yihao/Transfomer2DFA.",
      "tldr_zh": "这篇论文针对 Transformer 模型在机器学习中的运作机制不透明问题，提出了一种专门的 automata extraction 算法，将模型视为黑盒系统，通过跟踪内部 latent representations 的转换，并应用 L* algorithm 来解释为 deterministic finite-state automata (DFA)。该方法扩展了以往主要用于 RNNs 的技术，揭示了 Transformer 如何理解 formal languages 的结构。研究结果不仅提升了 Transformer 模型的可解释性，还为深入探索机器学习系统处理 formal languages 提供了关键见解。代码和数据可从 GitHub 获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.FL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05564v1",
      "published_date": "2024-06-08 20:07:24 UTC",
      "updated_date": "2024-06-08 20:07:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:44:34.007115"
    },
    {
      "arxiv_id": "2406.05559v1",
      "title": "ThatiAR: Subjectivity Detection in Arabic News Sentences",
      "title_zh": "ThatiAR：阿拉伯新闻句子的主观性检测",
      "authors": [
        "Reem Suwaileh",
        "Maram Hasanain",
        "Fatema Hubail",
        "Wajdi Zaghouani",
        "Firoj Alam"
      ],
      "abstract": "Detecting subjectivity in news sentences is crucial for identifying media\nbias, enhancing credibility, and combating misinformation by flagging\nopinion-based content. It provides insights into public sentiment, empowers\nreaders to make informed decisions, and encourages critical thinking. While\nresearch has developed methods and systems for this purpose, most efforts have\nfocused on English and other high-resourced languages. In this study, we\npresent the first large dataset for subjectivity detection in Arabic,\nconsisting of ~3.6K manually annotated sentences, and GPT-4o based explanation.\nIn addition, we included instructions (both in English and Arabic) to\nfacilitate LLM based fine-tuning. We provide an in-depth analysis of the\ndataset, annotation process, and extensive benchmark results, including PLMs\nand LLMs. Our analysis of the annotation process highlights that annotators\nwere strongly influenced by their political, cultural, and religious\nbackgrounds, especially at the beginning of the annotation process. The\nexperimental results suggest that LLMs with in-context learning provide better\nperformance. We aim to release the dataset and resources for the community.",
      "tldr_zh": "这篇论文介绍了 ThatiAR 系统，用于检测阿拉伯新闻句子中的主观性，以识别媒体偏见、提升可信度和打击虚假信息。研究贡献包括发布首个大规模阿拉伯语数据集，包含约 3.6K 手动标注句子、GPT-4o 基于解释以及英文和阿拉伯文指令，以支持 LLMs 的微调。分析显示，标注过程受标注者政治、文化和宗教背景影响，而实验结果表明，使用 in-context learning 的 LLMs 在基准测试中表现出色；作者计划向社区公开数据集和资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Subjectivity, Sentiment, Disinformation, Misinformation, Fake news,\n  LLMs, Transformers, Instruction Dataset",
      "pdf_url": "http://arxiv.org/pdf/2406.05559v1",
      "published_date": "2024-06-08 19:24:17 UTC",
      "updated_date": "2024-06-08 19:24:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:44:45.769265"
    },
    {
      "arxiv_id": "2406.05551v1",
      "title": "Autoregressive Diffusion Transformer for Text-to-Speech Synthesis",
      "title_zh": "用于文本到语音合成的自回归扩散变压器",
      "authors": [
        "Zhijun Liu",
        "Shuai Wang",
        "Sho Inoue",
        "Qibing Bai",
        "Haizhou Li"
      ],
      "abstract": "Audio language models have recently emerged as a promising approach for\nvarious audio generation tasks, relying on audio tokenizers to encode waveforms\ninto sequences of discrete symbols. Audio tokenization often poses a necessary\ncompromise between code bitrate and reconstruction accuracy. When dealing with\nlow-bitrate audio codes, language models are constrained to process only a\nsubset of the information embedded in the audio, which in turn restricts their\ngenerative capabilities. To circumvent these issues, we propose encoding audio\nas vector sequences in continuous space $\\mathbb R^d$ and autoregressively\ngenerating these sequences using a decoder-only diffusion transformer (ARDiT).\nOur findings indicate that ARDiT excels in zero-shot text-to-speech and\nexhibits performance that compares to or even surpasses that of\nstate-of-the-art models. High-bitrate continuous speech representation enables\nalmost flawless reconstruction, allowing our model to achieve nearly perfect\nspeech editing. Our experiments reveal that employing Integral Kullback-Leibler\n(IKL) divergence for distillation at each autoregressive step significantly\nboosts the perceived quality of the samples. Simultaneously, it condenses the\niterative sampling process of the diffusion model into a single step.\nFurthermore, ARDiT can be trained to predict several continuous vectors in one\nstep, significantly reducing latency during sampling. Impressively, one of our\nmodels can generate $170$ ms of $24$ kHz speech per evaluation step with\nminimal degradation in performance. Audio samples are available at\nhttp://ardit-tts.github.io/ .",
      "tldr_zh": "本研究提出了一种Autoregressive Diffusion Transformer (ARDiT) 方法，用于文本到语音（text-to-speech）合成，通过将音频编码为连续空间 \\(\\mathbb{R}^d\\) 中的向量序列，并采用自回归生成方式，绕过了传统音频分词的比特率与重建准确性权衡问题。实验结果显示，ARDiT 在零样本文本到语音任务上表现出色，甚至超越了最先进模型，实现几乎完美的语音重建和编辑。利用 Integral Kullback-Leibler (IKL) 散度进行蒸馏，该方法显著提升了样本质量，并将扩散模型的迭代采样简化为单步，同时允许一步预测多个向量，减少延迟，例如一个模型可在每个评估步骤生成 170 ms 的 24 kHz 语音，几乎无性能损失。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05551v1",
      "published_date": "2024-06-08 18:57:13 UTC",
      "updated_date": "2024-06-08 18:57:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:45:25.027026"
    },
    {
      "arxiv_id": "2406.05546v1",
      "title": "Training Through Failure: Effects of Data Consistency in Parallel Machine Learning Training",
      "title_zh": "翻译失败",
      "authors": [
        "Ray Cao",
        "Sherry Luo",
        "Steve Gan",
        "Sujeeth Jinesh"
      ],
      "abstract": "In this study, we explore the impact of relaxing data consistency in parallel\nmachine learning training during a failure using various parameter server\nconfigurations. Our failure recovery strategies include traditional\ncheckpointing, chain replication (which ensures a backup server takes over in\ncase of failure), and a novel stateless parameter server approach. In the\nstateless approach, workers continue generating gradient updates even if the\nparameter server is down, applying these updates once the server is back\nonline. We compare these techniques to a standard checkpointing approach, where\nthe training job is resumed from the latest checkpoint.\n  To assess the resilience and performance of each configuration, we\nintentionally killed the parameter server during training for each experiment.\nOur experiment results indicate that the stateless parameter server approach\ncontinues to train towards convergence and improves accuracy as much as 10\\% in\nthe face of a failure despite using stale weights and gradients. The chain\nreplication and checkpointing techniques demonstrate convergence but suffer\nfrom setbacks in accuracy due to restarting from old checkpoints. These results\nsuggest that allowing workers to continue generating updates during server\ndowntime and applying these updates later can effectively improve hardware\nutilization. Furthermore, despite higher resource usage, the stateless\nparameter server method incurs similar monetary costs in terms of hardware\nusage compared to standard checkpointing methods due to the pricing structure\nof common cloud providers.",
      "tldr_zh": "本文研究了在并行机器学习训练中，放松数据一致性对故障恢复的影响，比较了传统 checkpointing、chain replication 和新型 stateless parameter server 方法。在 stateless parameter server 方法中，即使参数服务器宕机，workers 仍可继续生成梯度更新，并在服务器恢复后应用这些更新。实验结果显示，该方法在面对故障时仍能实现收敛，并将准确率提高多达10%，同时提升硬件利用率，且整体成本与标准 checkpointing 方法类似。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05546v1",
      "published_date": "2024-06-08 18:31:56 UTC",
      "updated_date": "2024-06-08 18:31:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:45:17.116019"
    },
    {
      "arxiv_id": "2406.05543v1",
      "title": "VP-LLM: Text-Driven 3D Volume Completion with Large Language Models through Patchification",
      "title_zh": "翻译失败",
      "authors": [
        "Jianmeng Liu",
        "Yichen Liu",
        "Yuyao Zhang",
        "Zeyuan Meng",
        "Yu-Wing Tai",
        "Chi-Keung Tang"
      ],
      "abstract": "Recent conditional 3D completion works have mainly relied on CLIP or BERT to\nencode textual information, which cannot support complex instruction.\nMeanwhile, large language models (LLMs) have shown great potential in\nmulti-modal understanding and generation tasks. Inspired by the recent\nadvancements of LLM, we present Volume Patch LLM (VP-LLM), which leverages LLMs\nto perform conditional 3D completion in a single-forward pass. To integrate a\n3D model into the LLM tokenization configuration, the incomplete 3D object is\nfirst divided into small patches that can be encoded independently. These\nencoded patches are then fed into an LLM along with the text prompt,\ninstructing the LLM to capture the relations between these patches as well as\ninjecting semantic meanings into the 3D object. Our results demonstrate a\nstrong ability of LLMs to interpret complex text instructions and understand 3D\nobjects, surpassing state-of-the-art diffusion-based 3D completion models in\ngeneration quality.",
      "tldr_zh": "该论文提出VP-LLM框架，利用大型语言模型(LLMs)通过Patchification技术实现文本驱动的3D体积完成，解决了传统依赖CLIP或BERT的模型在处理复杂指令方面的局限性。具体方法包括将不完整的3D对象分成小patches进行独立编码，然后与文本提示一起输入LLM，以捕获patches间的关系并注入语义含义。实验结果表明，VP-LLM在生成质量上超越了最先进的基于扩散的3D完成模型，展示了LLMs在多模态理解和3D生成任务中的强大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "27pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.05543v1",
      "published_date": "2024-06-08 18:17:09 UTC",
      "updated_date": "2024-06-08 18:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:45:21.615281"
    },
    {
      "arxiv_id": "2406.05540v2",
      "title": "A Fine-tuning Dataset and Benchmark for Large Language Models for Protein Understanding",
      "title_zh": "针对大语言模型",
      "authors": [
        "Yiqing Shen",
        "Zan Chen",
        "Michail Mamalakis",
        "Luhan He",
        "Haiyang Xia",
        "Tianbin Li",
        "Yanzhou Su",
        "Junjun He",
        "Yu Guang Wang"
      ],
      "abstract": "The parallels between protein sequences and natural language in their\nsequential structures have inspired the application of large language models\n(LLMs) to protein understanding. Despite the success of LLMs in NLP, their\neffectiveness in comprehending protein sequences remains an open question,\nlargely due to the absence of datasets linking protein sequences to descriptive\ntext. Researchers have then attempted to adapt LLMs for protein understanding\nby integrating a protein sequence encoder with a pre-trained LLM. However, this\nadaptation raises a fundamental question: \"Can LLMs, originally designed for\nNLP, effectively comprehend protein sequences as a form of language?\" Current\ndatasets fall short in addressing this question due to the lack of a direct\ncorrelation between protein sequences and corresponding text descriptions,\nlimiting the ability to train and evaluate LLMs for protein understanding\neffectively. To bridge this gap, we introduce ProteinLMDataset, a dataset\nspecifically designed for further self-supervised pretraining and supervised\nfine-tuning (SFT) of LLMs to enhance their capability for protein sequence\ncomprehension. Specifically, ProteinLMDataset includes 17.46 billion tokens for\npretraining and 893,000 instructions for SFT. Additionally, we present\nProteinLMBench, the first benchmark dataset consisting of 944 manually verified\nmultiple-choice questions for assessing the protein understanding capabilities\nof LLMs. ProteinLMBench incorporates protein-related details and sequences in\nmultiple languages, establishing a new standard for evaluating LLMs' abilities\nin protein comprehension. The large language model InternLM2-7B, pretrained and\nfine-tuned on the ProteinLMDataset, outperforms GPT-4 on ProteinLMBench,\nachieving the highest accuracy score.",
      "tldr_zh": "这篇论文针对大型语言模型 (LLMs) 在蛋白质理解中的局限性，提出一个新的微调数据集 ProteinLMDataset 和基准 ProteinLMBench，以桥接蛋白质序列与文本描述的关联缺口。ProteinLMDataset 包括 17.46 亿 tokens 用于自监督预训练，以及 89.3 万条指令用于监督微调 (SFT)，旨在提升 LLMs 对蛋白质序列的理解能力。ProteinLMBench 则是一个由 944 个手动验证的多选题组成的基准数据集，涵盖多种语言的蛋白质相关细节和序列，用于评估 LLMs 的蛋白质理解性能。在实验中，使用 ProteinLMDataset 预训练和微调的 InternLM2-7B 模型在 ProteinLMBench 上超过了 GPT-4，实现了最高准确率。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05540v2",
      "published_date": "2024-06-08 18:11:30 UTC",
      "updated_date": "2024-07-08 16:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:45:42.178784"
    },
    {
      "arxiv_id": "2406.05535v1",
      "title": "Perturbation Towards Easy Samples Improves Targeted Adversarial Transferability",
      "title_zh": "翻译失败",
      "authors": [
        "Junqi Gao",
        "Biqing Qi",
        "Yao Li",
        "Zhichang Guo",
        "Dong Li",
        "Yuming Xing",
        "Dazhi Zhang"
      ],
      "abstract": "The transferability of adversarial perturbations provides an effective\nshortcut for black-box attacks. Targeted perturbations have greater\npracticality but are more difficult to transfer between models. In this paper,\nwe experimentally and theoretically demonstrated that neural networks trained\non the same dataset have more consistent performance in\nHigh-Sample-Density-Regions (HSDR) of each class instead of low sample density\nregions. Therefore, in the target setting, adding perturbations towards HSDR of\nthe target class is more effective in improving transferability. However,\ndensity estimation is challenging in high-dimensional scenarios. Further\ntheoretical and experimental verification demonstrates that easy samples with\nlow loss are more likely to be located in HSDR. Perturbations towards such easy\nsamples in the target class can avoid density estimation for HSDR location.\nBased on the above facts, we verified that adding perturbations to easy samples\nin the target class improves targeted adversarial transferability of existing\nattack methods. A generative targeted attack strategy named Easy Sample\nMatching Attack (ESMA) is proposed, which has a higher success rate for\ntargeted attacks and outperforms the SOTA generative method. Moreover, ESMA\nrequires only 5% of the storage space and much less computation time comparing\nto the current SOTA, as ESMA attacks all classes with only one model instead of\nseperate models for each class. Our code is available at\nhttps://github.com/gjq100/ESMA.",
      "tldr_zh": "本文通过实验和理论分析发现，神经网络在同一数据集上训练时，在 High-Sample-Density-Regions (HSDR) 中表现更一致，因此向目标类别的 HSDR 添加扰动可提升针对性对抗扰动的转移性。作者进一步证明，低损失的 easy samples 更可能位于 HSDR，从而避免了高维场景下的密度估计挑战，并验证了向这些 easy samples 添加扰动能改善现有攻击方法的转移性。基于此，提出了一种生成式攻击策略 Easy Sample Matching Attack (ESMA)，它在针对性攻击中实现更高的成功率，比 SOTA 方法更高效，仅需 5% 存储空间和更少计算时间，且使用一个模型即可攻击所有类。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05535v1",
      "published_date": "2024-06-08 17:33:23 UTC",
      "updated_date": "2024-06-08 17:33:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:45:53.355658"
    },
    {
      "arxiv_id": "2406.05534v1",
      "title": "Online DPO: Online Direct Preference Optimization with Fast-Slow Chasing",
      "title_zh": "翻译失败",
      "authors": [
        "Biqing Qi",
        "Pengfei Li",
        "Fangyuan Li",
        "Junqi Gao",
        "Kaiyan Zhang",
        "Bowen Zhou"
      ],
      "abstract": "Direct Preference Optimization (DPO) improves the alignment of large language\nmodels (LLMs) with human values by training directly on human preference\ndatasets, eliminating the need for reward models. However, due to the presence\nof cross-domain human preferences, direct continual training can lead to\ncatastrophic forgetting, limiting DPO's performance and efficiency. Inspired by\nintraspecific competition driving species evolution, we propose a Online\nFast-Slow chasing DPO (OFS-DPO) for preference alignment, simulating\ncompetition through fast and slow chasing among models to facilitate rapid\nadaptation. Specifically, we first derive the regret upper bound for online\nlearning, validating our motivation with a min-max optimization pattern. Based\non this, we introduce two identical modules using Low-rank Adaptive (LoRA) with\ndifferent optimization speeds to simulate intraspecific competition, and\npropose a new regularization term to guide their learning. To further mitigate\ncatastrophic forgetting in cross-domain scenarios, we extend the OFS-DPO with\nLoRA modules combination strategy, resulting in the Cross domain Online\nFast-Slow chasing DPO (COFS-DPO). This method leverages linear combinations of\nfast modules parameters from different task domains, fully utilizing historical\ninformation to achive continual value alignment. Experimental results show that\nOFS-DPO outperforms DPO in in-domain alignment, while COFS-DPO excels in\ncross-domain continual learning scenarios.",
      "tldr_zh": "本文提出Online Fast-Slow chasing DPO (OFS-DPO)，一种基于种内竞争模拟的在线偏好优化方法，用于解决Direct Preference Optimization (DPO)在跨领域训练中导致的灾难性遗忘问题。OFS-DPO 通过推导在线学习的遗憾上界，并使用两个LoRA模块以不同优化速度进行竞争，同时引入新正则化项来引导学习；其扩展版Cross domain Online Fast-Slow chasing DPO (COFS-DPO) 则通过LoRA模块组合策略利用历史信息，实现跨领域持续价值对齐。实验结果显示，OFS-DPO 在领域内对齐任务上优于DPO，而COFS-DPO 在跨领域持续学习场景中表现出显著优势。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05534v1",
      "published_date": "2024-06-08 17:30:54 UTC",
      "updated_date": "2024-06-08 17:30:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:46:05.874099"
    },
    {
      "arxiv_id": "2406.05533v1",
      "title": "PAPR in Motion: Seamless Point-level 3D Scene Interpolation",
      "title_zh": "翻译失败",
      "authors": [
        "Shichong Peng",
        "Yanshu Zhang",
        "Ke Li"
      ],
      "abstract": "We propose the problem of point-level 3D scene interpolation, which aims to\nsimultaneously reconstruct a 3D scene in two states from multiple views,\nsynthesize smooth point-level interpolations between them, and render the scene\nfrom novel viewpoints, all without any supervision between the states. The\nprimary challenge is on achieving a smooth transition between states that may\ninvolve significant and non-rigid changes. To address these challenges, we\nintroduce \"PAPR in Motion\", a novel approach that builds upon the recent\nProximity Attention Point Rendering (PAPR) technique, which can deform a point\ncloud to match a significantly different shape and render a visually coherent\nscene even after non-rigid deformations. Our approach is specifically designed\nto maintain the temporal consistency of the geometric structure by introducing\nvarious regularization techniques for PAPR. The result is a method that can\neffectively bridge large scene changes and produce visually coherent and\ntemporally smooth interpolations in both geometry and appearance. Evaluation\nacross diverse motion types demonstrates that \"PAPR in Motion\" outperforms the\nleading neural renderer for dynamic scenes. For more results and code, please\nvisit our project website at https://niopeng.github.io/PAPR-in-Motion/ .",
      "tldr_zh": "本研究提出点级 3D 场景插值问题，旨在从多个视角无监督地重建两个状态的 3D 场景、合成平滑的点级插值，并从新视角渲染场景，尤其处理重大和非刚性变化的挑战。作者引入 \"PAPR in Motion\" 方法，基于 Proximity Attention Point Rendering (PAPR) 技术，通过添加各种正则化技术来维护几何结构的时序一致性，从而实现视觉连贯且平滑的几何和外观插值。实验结果显示，该方法在多样运动类型中优于领先的神经渲染器，为动态场景插值提供了高效解决方案。更多细节可访问项目网站 https://niopeng.github.io/PAPR-in-Motion/。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05533v1",
      "published_date": "2024-06-08 17:27:27 UTC",
      "updated_date": "2024-06-08 17:27:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:46:16.467682"
    },
    {
      "arxiv_id": "2406.05532v2",
      "title": "Exploring Adversarial Robustness of Deep State Space Models",
      "title_zh": "探索深度状态空间模型的对抗鲁棒性",
      "authors": [
        "Biqing Qi",
        "Yang Luo",
        "Junqi Gao",
        "Pengfei Li",
        "Kai Tian",
        "Zhiyuan Ma",
        "Bowen Zhou"
      ],
      "abstract": "Deep State Space Models (SSMs) have proven effective in numerous task\nscenarios but face significant security challenges due to Adversarial\nPerturbations (APs) in real-world deployments. Adversarial Training (AT) is a\nmainstream approach to enhancing Adversarial Robustness (AR) and has been\nvalidated on various traditional DNN architectures. However, its effectiveness\nin improving the AR of SSMs remains unclear. While many enhancements in SSM\ncomponents, such as integrating Attention mechanisms and expanding to\ndata-dependent SSM parameterizations, have brought significant gains in\nStandard Training (ST) settings, their potential benefits in AT remain\nunexplored. To investigate this, we evaluate existing structural variants of\nSSMs with AT to assess their AR performance. We observe that pure SSM\nstructures struggle to benefit from AT, whereas incorporating Attention yields\na markedly better trade-off between robustness and generalization for SSMs in\nAT compared to other components. Nonetheless, the integration of Attention also\nleads to Robust Overfitting (RO) issues. To understand these phenomena, we\nempirically and theoretically analyze the output error of SSMs under AP. We\nfind that fixed-parameterized SSMs have output error bounds strictly related to\ntheir parameters, limiting their AT benefits, while input-dependent SSMs may\nface the problem of error explosion. Furthermore, we show that the Attention\ncomponent effectively scales the output error of SSMs during training, enabling\nthem to benefit more from AT, but at the cost of introducing RO due to its high\nmodel complexity. Inspired by this, we propose a simple and effective Adaptive\nScaling (AdS) mechanism that brings AT performance close to\nAttention-integrated SSMs without introducing the issue of RO. Our code is\navailable at\nhttps://github.com/Biqing-Qi/Exploring-Adversarial-Robustness-of-Deep-State-Space-Models.git.",
      "tldr_zh": "本研究探讨了Deep State Space Models (SSMs) 的Adversarial Robustness (AR)，发现传统Adversarial Training (AT) 在纯 SSMs 结构上收益有限，而整合Attention 机制能显著改善 SSMs 在 AT 中的鲁棒性和泛化权衡，但会引发Robust Overfitting (RO) 问题。作者通过实验和理论分析揭示，固定参数 SSMs 的输出错误边界受参数限制，而输入依赖 SSMs 可能出现错误爆炸；Attention 通过缩放输出错误提升 AT 效果，却增加了模型复杂性。最终，提出Adaptive Scaling (AdS) 机制，作为一种简单有效的替代方案，能使 SSMs 的 AT 性能接近 Attention 整合水平，同时避免 RO 问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05532v2",
      "published_date": "2024-06-08 17:25:48 UTC",
      "updated_date": "2024-10-09 02:28:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:46:30.803907"
    },
    {
      "arxiv_id": "2406.05531v1",
      "title": "Enhancing Adversarial Transferability via Information Bottleneck Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Biqing Qi",
        "Junqi Gao",
        "Jianxing Liu",
        "Ligang Wu",
        "Bowen Zhou"
      ],
      "abstract": "From the perspective of information bottleneck (IB) theory, we propose a\nnovel framework for performing black-box transferable adversarial attacks named\nIBTA, which leverages advancements in invariant features. Intuitively,\ndiminishing the reliance of adversarial perturbations on the original data,\nunder equivalent attack performance constraints, encourages a greater reliance\non invariant features that contributes most to classification, thereby\nenhancing the transferability of adversarial attacks. Building on this\nmotivation, we redefine the optimization of transferable attacks using a novel\ntheoretical framework that centers around IB. Specifically, to overcome the\nchallenge of unoptimizable mutual information, we propose a simple and\nefficient mutual information lower bound (MILB) for approximating computation.\nMoreover, to quantitatively evaluate mutual information, we utilize the Mutual\nInformation Neural Estimator (MINE) to perform a thorough analysis. Our\nexperiments on the ImageNet dataset well demonstrate the efficiency and\nscalability of IBTA and derived MILB. Our code is available at\nhttps://github.com/Biqing-Qi/Enhancing-Adversarial-Transferability-via-Information-Bottleneck-Constraints.",
      "tldr_zh": "本论文从Information Bottleneck (IB)理论角度提出IBTA框架，用于提升黑盒对抗攻击的可转移性。框架的核心是减少对抗扰动对原始数据的依赖，同时增加对不变特征的依赖，以在保持攻击性能的前提下提升转移效果；为此，作者引入互信息下界(MILB)来近似计算互信息，并利用Mutual Information Neural Estimator (MINE)进行定量评估。实验在ImageNet数据集上验证了IBTA和MILB的效率和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05531v1",
      "published_date": "2024-06-08 17:25:31 UTC",
      "updated_date": "2024-06-08 17:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:46:49.465630"
    },
    {
      "arxiv_id": "2406.05516v3",
      "title": "Verbalized Probabilistic Graphical Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Hengguan Huang",
        "Xing Shen",
        "Songtao Wang",
        "Lingfa Meng",
        "Dianbo Liu",
        "Hao Wang",
        "Samir Bhatt"
      ],
      "abstract": "Human cognition excels at transcending sensory input and forming latent\nrepresentations that structure our understanding of the world. Although Large\nLanguage Models (LLMs) can produce chain-of-thought reasoning, they lack a\nprincipled framework to capture latent structures and model uncertainty,\nespecially in compositional reasoning tasks. We propose Verbalized\nProbabilistic Graphical Modeling (vPGM), a Bayesian prompting framework that\nguides LLMs to simulate key principles of Probabilistic Graphical Models (PGMs)\nin natural language. Unlike many traditional probabilistic methods requiring\nsubstantial domain expertise or specialized training, vPGM bypasses\nexpert-driven model design, making it well-suited for scenarios with limited\nassumptions or scarce data. We evaluated our model on several compositional\nreasoning tasks, both close-ended and open-ended. Our results indicate that the\nmodel effectively enhances confidence calibration and text generation quality.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）在捕捉潜在结构和建模不确定性方面的不足，尤其在组合推理任务中。作者提出Verbalized Probabilistic Graphical Modeling (vPGM)，一个基于Bayesian prompting的框架，引导LLMs使用自然语言模拟Probabilistic Graphical Models (PGMs)的关键原则，从而避免了传统方法对领域专长和专门训练的依赖。vPGM特别适用于假设有限或数据稀缺的场景，并在多个封闭式和开放式组合推理任务上进行了评估，结果显示它显著提升了置信度校准和文本生成质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05516v3",
      "published_date": "2024-06-08 16:35:31 UTC",
      "updated_date": "2025-03-04 18:07:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:46:52.672129"
    },
    {
      "arxiv_id": "2406.05506v2",
      "title": "Towards a Benchmark for Causal Business Process Reasoning with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Fabiana Fournier",
        "Lior Limonad",
        "Inna Skarbovsky"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used for boosting\norganizational efficiency and automating tasks. While not originally designed\nfor complex cognitive processes, recent efforts have further extended to employ\nLLMs in activities such as reasoning, planning, and decision-making. In\nbusiness processes, such abilities could be invaluable for leveraging on the\nmassive corpora LLMs have been trained on for gaining deep understanding of\nsuch processes. In this work, we plant the seeds for the development of a\nbenchmark to assess the ability of LLMs to reason about causal and process\nperspectives of business operations. We refer to this view as\nCausally-augmented Business Processes (BP^C). The core of the benchmark\ncomprises a set of BP^C related situations, a set of questions about these\nsituations, and a set of deductive rules employed to systematically resolve the\nground truth answers to these questions. Also with the power of LLMs, the seed\nis then instantiated into a larger-scale set of domain-specific situations and\nquestions. Reasoning on BP^C is of crucial importance for process interventions\nand process improvement. Our benchmark, accessible at\nhttps://huggingface.co/datasets/ibm/BPC, can be used in one of two possible\nmodalities: testing the performance of any target LLM and training an LLM to\nadvance its capability to reason about BP^C.",
      "tldr_zh": "这篇论文旨在开发一个基准，用于评估大型语言模型(LLMs)在因果商业流程推理方面的能力，特别关注Causally-augmented Business Processes (BP^C)。基准的核心包括一组BP^C相关情况、一组问题以及用于确定真实答案的演绎规则，并通过LLMs扩展到更大规模的领域特定场景。实验结果表明，该基准可用于测试任何目标LLMs的性能或训练LLMs以提升其推理能力，从而支持商业流程的干预和改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2406.05506v2",
      "published_date": "2024-06-08 16:10:53 UTC",
      "updated_date": "2024-07-16 15:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:47:03.990014"
    },
    {
      "arxiv_id": "2406.05505v1",
      "title": "I-SIRch: AI-Powered Concept Annotation Tool For Equitable Extraction And Analysis Of Safety Insights From Maternity Investigations",
      "title_zh": "翻译失败",
      "authors": [
        "Mohit Kumar Singh",
        "Georgina Cosma",
        "Patrick Waterson",
        "Jonathan Back",
        "Gyuchan Thomas Jun"
      ],
      "abstract": "Maternity care is a complex system involving treatments and interactions\nbetween patients, providers, and the care environment. To improve patient\nsafety and outcomes, understanding the human factors (e.g. individuals\ndecisions, local facilities) influencing healthcare delivery is crucial.\nHowever, most current tools for analysing healthcare data focus only on\nbiomedical concepts (e.g. health conditions, procedures and tests), overlooking\nthe importance of human factors. We developed a new approach called I-SIRch,\nusing artificial intelligence to automatically identify and label human factors\nconcepts in maternity healthcare investigation reports describing adverse\nmaternity incidents produced by England's Healthcare Safety Investigation\nBranch (HSIB). These incident investigation reports aim to identify\nopportunities for learning and improving maternal safety across the entire\nhealthcare system. I-SIRch was trained using real data and tested on both real\nand simulated data to evaluate its performance in identifying human factors\nconcepts. When applied to real reports, the model achieved a high level of\naccuracy, correctly identifying relevant concepts in 90\\% of the sentences from\n97 reports. Applying I-SIRch to analyse these reports revealed that certain\nhuman factors disproportionately affected mothers from different ethnic groups.\nOur work demonstrates the potential of using automated tools to identify human\nfactors concepts in maternity incident investigation reports, rather than\nfocusing solely on biomedical concepts. This approach opens up new\npossibilities for understanding the complex interplay between social,\ntechnical, and organisational factors influencing maternal safety and\npopulation health outcomes. By taking a more comprehensive view of maternal\nhealthcare delivery, we can develop targeted interventions to address\ndisparities and improve maternal outcomes.",
      "tldr_zh": "本研究开发了I-SIRch，一种基于AI的工具，用于从英国Healthcare Safety Investigation Branch (HSIB)产科调查报告中公平提取和分析人类因素(human factors)概念，从而弥补现有工具对生物医学概念的偏重。I-SIRch使用真实数据训练，并在测试中实现了90%的句子准确率，成功识别了这些报告中影响产妇安全的相关概念。分析结果显示，某些人类因素对不同民族群体的母亲影响不均等，这为理解社会、技术和组织因素的交互提供了新视角，并有助于制定针对性干预以减少健康不平等并改善产妇结局。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05505v1",
      "published_date": "2024-06-08 16:05:31 UTC",
      "updated_date": "2024-06-08 16:05:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:47:17.939207"
    },
    {
      "arxiv_id": "2406.05498v3",
      "title": "SelfDefend: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner",
      "title_zh": "翻译失败",
      "authors": [
        "Xunguang Wang",
        "Daoyuan Wu",
        "Zhenlan Ji",
        "Zongjie Li",
        "Pingchuan Ma",
        "Shuai Wang",
        "Yingjiu Li",
        "Yang Liu",
        "Ning Liu",
        "Juergen Rahmel"
      ],
      "abstract": "Jailbreaking is an emerging adversarial attack that bypasses the safety\nalignment deployed in off-the-shelf large language models (LLMs) and has\nevolved into multiple categories: human-based, optimization-based,\ngeneration-based, and the recent indirect and multilingual jailbreaks. However,\ndelivering a practical jailbreak defense is challenging because it needs to not\nonly handle all the above jailbreak attacks but also incur negligible delays to\nuser prompts, as well as be compatible with both open-source and closed-source\nLLMs. Inspired by how the traditional security concept of shadow stacks defends\nagainst memory overflow attacks, this paper introduces a generic LLM jailbreak\ndefense framework called SelfDefend, which establishes a shadow LLM as a\ndefense instance (in detection state) to concurrently protect the target LLM\ninstance (in normal answering state) in the normal stack and collaborate with\nit for checkpoint-based access control. The effectiveness of SelfDefend builds\nupon our observation that existing LLMs can identify harmful prompts or\nintentions in user queries, which we empirically validate using mainstream\nGPT-3.5/4 models against major jailbreak attacks. To further improve the\ndefense's robustness and minimize costs, we employ a data distillation approach\nto tune dedicated open-source defense models. When deployed to protect\nGPT-3.5/4, Claude, Llama-2-7b/13b, and Mistral, these models outperform seven\nstate-of-the-art defenses and match the performance of GPT-4-based SelfDefend,\nwith significantly lower extra delays. Further experiments show that the tuned\nmodels are robust to adaptive jailbreaks and prompt injections.",
      "tldr_zh": "这篇论文提出了 SelfDefend，一种实用的防御框架，旨在帮助大型语言模型 (LLMs) 抵御多种越狱攻击 (jailbreaking)，包括基于人类、优化、生成、间接和多语言的攻击，同时确保低延迟并兼容开源和闭源模型。SelfDefend 借鉴传统安全机制（如 shadow stacks），使用一个 shadow LLM 作为防御实例，与目标 LLM 协作进行检查点-based 访问控制，并利用现有 LLMs 识别有害提示的能力。研究通过数据蒸馏方法微调开源防御模型，结果显示这些模型在保护 GPT-3.5/4、Claude、Llama-2-7b/13b 和 Mistral 等模型时，优于七种最先进防御，并匹配 GPT-4-based 性能，同时显著降低额外延迟，并对自适应越狱和提示注入攻击表现出鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by USENIX Security Symposium 2025. Please cite the\n  conference version of this paper, i.e., \"Xunguang Wang, Daoyuan Wu, Zhenlan\n  Ji, Zongjie Li, Pingchuan Ma, Shuai Wang, Yingjiu Li, Yang Liu, Ning Liu, and\n  Juergen Rahmel. SelfDefend: LLMs Can Defend Themselves against Jailbreaking\n  in a Practical Manner. In Proc. USENIX Security, 2025.\"",
      "pdf_url": "http://arxiv.org/pdf/2406.05498v3",
      "published_date": "2024-06-08 15:45:31 UTC",
      "updated_date": "2025-02-05 10:29:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:47:30.485956"
    },
    {
      "arxiv_id": "2406.05488v1",
      "title": "Online Policy Distillation with Decision-Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Xinqiang Yu",
        "Chuanguang Yang",
        "Chengqing Yu",
        "Libo Huang",
        "Zhulin An",
        "Yongjun Xu"
      ],
      "abstract": "Policy Distillation (PD) has become an effective method to improve deep\nreinforcement learning tasks. The core idea of PD is to distill policy\nknowledge from a teacher agent to a student agent. However, the teacher-student\nframework requires a well-trained teacher model which is computationally\nexpensive.In the light of online knowledge distillation, we study the knowledge\ntransfer between different policies that can learn diverse knowledge from the\nsame environment.In this work, we propose Online Policy Distillation (OPD) with\nDecision-Attention (DA), an online learning framework in which different\npolicies operate in the same environment to learn different perspectives of the\nenvironment and transfer knowledge to each other to obtain better performance\ntogether. With the absence of a well-performance teacher policy, the\ngroup-derived targets play a key role in transferring group knowledge to each\nstudent policy. However, naive aggregation functions tend to cause student\npolicies quickly homogenize. To address the challenge, we introduce the\nDecision-Attention module to the online policies distillation framework. The\nDecision-Attention module can generate a distinct set of weights for each\npolicy to measure the importance of group members. We use the Atari platform\nfor experiments with various reinforcement learning algorithms, including PPO\nand DQN. In different tasks, our method can perform better than an independent\ntraining policy on both PPO and DQN algorithms. This suggests that our OPD-DA\ncan transfer knowledge between different policies well and help agents obtain\nmore rewards.",
      "tldr_zh": "本研究提出Online Policy Distillation (OPD)框架，通过让多个策略在同一环境中同时学习并互相转移知识，来提升强化学习任务的性能，而无需依赖预训练的教师模型。OPD引入Decision-Attention (DA)模块，为每个策略生成独特的权重，以评估群组成员的重要性，避免策略同质化问题。实验在Atari平台上使用PPO和DQN算法显示，OPD-DA比独立训练策略表现更好，帮助代理获得更多奖励。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05488v1",
      "published_date": "2024-06-08 14:40:53 UTC",
      "updated_date": "2024-06-08 14:40:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:47:45.108803"
    },
    {
      "arxiv_id": "2406.05478v1",
      "title": "Revisiting Non-Autoregressive Transformers for Efficient Image Synthesis",
      "title_zh": "重新审视非自回归 Transformer 用于高效图像合成",
      "authors": [
        "Zanlin Ni",
        "Yulin Wang",
        "Renping Zhou",
        "Jiayi Guo",
        "Jinyi Hu",
        "Zhiyuan Liu",
        "Shiji Song",
        "Yuan Yao",
        "Gao Huang"
      ],
      "abstract": "The field of image synthesis is currently flourishing due to the advancements\nin diffusion models. While diffusion models have been successful, their\ncomputational intensity has prompted the pursuit of more efficient\nalternatives. As a representative work, non-autoregressive Transformers (NATs)\nhave been recognized for their rapid generation. However, a major drawback of\nthese models is their inferior performance compared to diffusion models. In\nthis paper, we aim to re-evaluate the full potential of NATs by revisiting the\ndesign of their training and inference strategies. Specifically, we identify\nthe complexities in properly configuring these strategies and indicate the\npossible sub-optimality in existing heuristic-driven designs. Recognizing this,\nwe propose to go beyond existing methods by directly solving the optimal\nstrategies in an automatic framework. The resulting method, named AutoNAT,\nadvances the performance boundaries of NATs notably, and is able to perform\ncomparably with the latest diffusion models at a significantly reduced\ninference cost. The effectiveness of AutoNAT is validated on four benchmark\ndatasets, i.e., ImageNet-256 & 512, MS-COCO, and CC3M. Our code is available at\nhttps://github.com/LeapLabTHU/ImprovedNAT.",
      "tldr_zh": "本文重新审视 Non-Autoregressive Transformers (NATs)，旨在为图像合成提供更高效的替代方案，以应对扩散模型的计算密集问题。作者提出 AutoNAT 方法，通过自动框架直接求解最优训练和推理策略，超越现有启发式设计，提升 NATs 的性能表现。实验在 ImageNet-256 & 512、MS-COCO 和 CC3M 等基准数据集上验证，AutoNAT 实现了与最新扩散模型相当的生成质量，但显著降低了推理成本。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05478v1",
      "published_date": "2024-06-08 13:52:20 UTC",
      "updated_date": "2024-06-08 13:52:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:47:57.572751"
    },
    {
      "arxiv_id": "2406.10248v4",
      "title": "On the Worst Prompt Performance of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Cao",
        "Deng Cai",
        "Zhisong Zhang",
        "Yuexian Zou",
        "Wai Lam"
      ],
      "abstract": "The performance of large language models (LLMs) is acutely sensitive to the\nphrasing of prompts, which raises significant concerns about their reliability\nin real-world scenarios. Existing studies often divide prompts into task-level\ninstructions and case-level inputs and primarily focus on evaluating and\nimproving robustness against variations in tasks-level instructions. However,\nthis setup fails to fully address the diversity of real-world user queries and\nassumes the existence of task-specific datasets. To address these limitations,\nwe introduce RobustAlpacaEval, a new benchmark that consists of semantically\nequivalent case-level queries and emphasizes the importance of using the worst\nprompt performance to gauge the lower bound of model performance. Extensive\nexperiments on RobustAlpacaEval with ChatGPT and six open-source LLMs from the\nLlama, Mistral, and Gemma families uncover substantial variability in model\nperformance; for instance, a difference of 45.48% between the worst and best\nperformance for the Llama-2-70B-chat model, with its worst performance dipping\nas low as 9.38%. We further illustrate the difficulty in identifying the worst\nprompt from both model-agnostic and model-dependent perspectives, emphasizing\nthe absence of a shortcut to characterize the worst prompt. We also attempt to\nenhance the worst prompt performance using existing prompt engineering and\nprompt consistency methods, but find that their impact is limited. These\nfindings underscore the need to create more resilient LLMs that can maintain\nhigh performance across diverse prompts. Data and code are available at\nhttps://github.com/cbwbuaa/On-the-Worst-Prompt- Performance-of-LLMs.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)对提示短语的敏感性问题，这可能导致其在实际应用中的可靠性不足。研究者引入了RobustAlpacaEval基准测试，该基准聚焦于语义等价的案例级查询，并使用最差提示性能来评估模型的下限。实验结果显示，ChatGPT和Llama、Mistral、Gemma系列的开源LLMs存在显著性能差异，例如Llama-2-70B-chat模型的最差性能仅为9.38%，与最佳性能相差45.48%。尽管尝试了现有提示工程和提示一致性方法，这些方法的改善效果有限，论文强调需要开发更具弹性的LLMs，以在多样化提示下维持高性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10248v4",
      "published_date": "2024-06-08 13:40:38 UTC",
      "updated_date": "2024-10-30 09:48:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:48:12.442300"
    },
    {
      "arxiv_id": "2406.05464v2",
      "title": "DAISY: Data Adaptive Self-Supervised Early Exit for Speech Representation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tzu-Quan Lin",
        "Hung-yi Lee",
        "Hao Tang"
      ],
      "abstract": "Self-supervised speech models have shown to be useful for various tasks, but\ntheir large size limits the use in devices with low computing power and memory.\nIn this work, we explore early exit, an approach for reducing latency by\nexiting the forward process of a network early. Most approaches of early exit\nneed a separate early exit model for each task, with some even requiring\nfine-tuning of the entire pretrained model. We introduce Data Adaptive\nSelf-Supervised Early Exit (DAISY), an approach that decides when to exit based\non the self-supervised loss, eliminating the need for multiple round of\ntraining and fine-tuning. DAISY matches the performance of HuBERT on the\nMiniSUPERB benchmark, but with much faster inference times. Our analysis on the\nadaptivity of DAISY shows that the model exits early (using fewer layers) on\nclean data while exits late (using more layers) on noisy data, dynamically\nadjusting the computational cost of inference based on the noise level of each\nsample.",
      "tldr_zh": "该研究提出DAISY（Data Adaptive Self-Supervised Early Exit），一种数据自适应自监督早期退出方法，用于优化语音表示模型的推理效率。该方法基于自监督损失动态决定何时退出网络前向过程，从而避免了为每个任务训练单独模型或进行整体微调。实验结果显示，DAISY在MiniSUPERB基准上与HuBERT模型性能相当，但推理时间显著缩短；此外，它能根据样本噪声水平自动调整计算成本，在干净数据上早退出（使用更少层），在噪声数据上晚退出（使用更多层）。这为在低计算设备上部署自监督语音模型提供了高效解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05464v2",
      "published_date": "2024-06-08 12:58:13 UTC",
      "updated_date": "2024-08-29 19:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:48:22.259953"
    },
    {
      "arxiv_id": "2407.16888v2",
      "title": "A Nested Model for AI Design and Validation",
      "title_zh": "翻译失败",
      "authors": [
        "Akshat Dubey",
        "Zewen Yang",
        "Georges Hattab"
      ],
      "abstract": "The growing AI field faces trust, transparency, fairness, and discrimination\nchallenges. Despite the need for new regulations, there is a mismatch between\nregulatory science and AI, preventing a consistent framework. A five-layer\nnested model for AI design and validation aims to address these issues and\nstreamline AI application design and validation, improving fairness, trust, and\nAI adoption. This model aligns with regulations, addresses AI practitioner's\ndaily challenges, and offers prescriptive guidance for determining appropriate\nevaluation approaches by identifying unique validity threats. We have three\nrecommendations motivated by this model: authors should distinguish between\nlayers when claiming contributions to clarify the specific areas in which the\ncontribution is made and to avoid confusion, authors should explicitly state\nupstream assumptions to ensure that the context and limitations of their AI\nsystem are clearly understood, AI venues should promote thorough testing and\nvalidation of AI systems and their compliance with regulatory requirements.",
      "tldr_zh": "这篇论文针对 AI 领域面临的信任、透明度、公平性和歧视挑战，提出一个五层嵌套模型（five-layer nested model）来桥接法规科学与 AI 的差距。该模型简化了 AI 设计和验证流程，提高公平性、信任和 AI 采用，并提供指导识别独特有效性威胁（validity threats）。作者给出三点推荐：作者应区分层级以澄清贡献、明确上游假设（upstream assumptions），以及 AI 场所应促进系统彻底测试和法规遵守。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.16888v2",
      "published_date": "2024-06-08 12:46:12 UTC",
      "updated_date": "2024-08-01 11:46:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:48:33.338575"
    },
    {
      "arxiv_id": "2406.05460v2",
      "title": "Fighting Against the Repetitive Training and Sample Dependency Problem in Few-shot Named Entity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Tian",
        "Wenpeng Yin",
        "Dan Li",
        "Marie-Francine Moens"
      ],
      "abstract": "Few-shot named entity recognition (NER) systems recognize entities using a\nfew labeled training examples. The general pipeline consists of a span detector\nto identify entity spans in text and an entity-type classifier to assign types\nto entities. Current span detectors rely on extensive manual labeling to guide\ntraining. Almost every span detector requires initial training on basic span\nfeatures followed by adaptation to task-specific features. This process leads\nto repetitive training of the basic span features among span detectors.\nAdditionally, metric-based entity-type classifiers, such as prototypical\nnetworks, typically employ a specific metric that gauges the distance between\nthe query sample and entity-type referents, ultimately assigning the most\nprobable entity type to the query sample. However, these classifiers encounter\nthe sample dependency problem, primarily stemming from the limited samples\navailable for each entity-type referent. To address these challenges, we\nproposed an improved few-shot NER pipeline. First, we introduce a steppingstone\nspan detector that is pre-trained on open-domain Wikipedia data. It can be used\nto initialize the pipeline span detector to reduce the repetitive training of\nbasic features. Second, we leverage a large language model (LLM) to set\nreliable entity-type referents, eliminating reliance on few-shot samples of\neach type. Our model exhibits superior performance with fewer training steps\nand human-labeled data compared with baselines, as demonstrated through\nextensive experiments on various datasets. Particularly in fine-grained\nfew-shot NER settings, our model outperforms strong baselines, including\nChatGPT. We will publicly release the code, datasets, LLM outputs, and model\ncheckpoints.",
      "tldr_zh": "本研究针对 Few-shot Named Entity Recognition (NER) 中的重复训练和样本依赖问题，提出了一种改进的管道框架。具体而言，该框架引入了基于开源维基百科数据预训练的 steppingstone span detector，以初始化 span detector 模块，减少基本特征的重复训练；同时，利用 Large Language Model (LLM) 设置可靠的 entity-type referents，消除对少量样本的依赖。通过广泛实验验证，该模型在各种数据集上表现出色，需要更少的训练步骤和标注数据，尤其在细粒度 few-shot NER 设置中，超越了包括 ChatGPT 在内的强基线模型。作者计划公开代码、数据集和模型检查点，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ieee access: https://doi.org/10.1109/ACCESS.2024.3374727",
      "pdf_url": "http://arxiv.org/pdf/2406.05460v2",
      "published_date": "2024-06-08 12:36:30 UTC",
      "updated_date": "2024-06-18 23:45:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:48:44.760098"
    },
    {
      "arxiv_id": "2406.05446v1",
      "title": "Design of reliable technology valuation model with calibrated machine learning of patent indicators",
      "title_zh": "翻译失败",
      "authors": [
        "Seunghyun Lee",
        "Janghyeok Yoon",
        "Jaewoong Choi"
      ],
      "abstract": "Machine learning (ML) has revolutionized the digital transformation of\ntechnology valuation by predicting the value of patents with high accuracy.\nHowever, the lack of validation regarding the reliability of these models\nhinders experts from fully trusting the confidence of model predictions. To\naddress this issue, we propose an analytical framework for reliable technology\nvaluation using calibrated ML models, which provide robust confidence levels in\nmodel predictions. We extract quantitative patent indicators that represent\nvarious technology characteristics as input data, using the patent maintenance\nperiod as a proxy for technology values. Multiple ML models are developed to\ncapture the nonlinear relationship between patent indicators and technology\nvalue. The reliability and accuracy of these models are evaluated, presenting a\nPareto-front map where the expected calibration error, Matthews correlation\ncoefficient and F1-scores are compared. After identifying the best-performing\nmodel, we apply SHapley Additive exPlanation (SHAP) analysis to pinpoint the\nmost significant input features by confidence bin. Through a case study, we\nconfirmed that the proposed approach offers a practical guideline for\ndeveloping reliable and accurate ML-based technology valuation models, with\nsignificant implications for both academia and industry.",
      "tldr_zh": "本研究针对机器学习（ML）在专利估值中的可靠性问题，提出了一种基于校准 ML 模型的分析框架，以提供稳健的预测置信水平。研究提取专利指标（如维护期）作为输入数据，开发多个 ML 模型来捕捉专利指标与技术价值之间的非线性关系，并通过 Pareto-front 图比较模型的期望校准错误、Matthews 相关系数和 F1 分数。最终，使用 SHapley Additive exPlanation (SHAP) 分析识别关键特征，并通过案例研究验证了该方法的实用性，为学术和工业领域开发可靠的 ML 估值模型提供了重要指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05446v1",
      "published_date": "2024-06-08 11:52:37 UTC",
      "updated_date": "2024-06-08 11:52:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:48:57.801196"
    },
    {
      "arxiv_id": "2406.05443v1",
      "title": "Novel Approach to Intrusion Detection: Introducing GAN-MSCNN-BILSTM with LIME Predictions",
      "title_zh": "翻译失败",
      "authors": [
        "Asmaa Benchama",
        "Khalid Zebbara"
      ],
      "abstract": "This paper introduces an innovative intrusion detection system that harnesses\nGenerative Adversarial Networks (GANs), Multi-Scale Convolutional Neural\nNetworks (MSCNNs), and Bidirectional Long Short-Term Memory (BiLSTM) networks,\nsupplemented by Local Interpretable Model-Agnostic Explanations (LIME) for\ninterpretability. Employing a GAN, the system generates realistic network\ntraffic data, encompassing both normal and attack patterns. This synthesized\ndata is then fed into an MSCNN-BiLSTM architecture for intrusion detection. The\nMSCNN layer extracts features from the network traffic data at different\nscales, while the BiLSTM layer captures temporal dependencies within the\ntraffic sequences. Integration of LIME allows for explaining the model's\ndecisions. Evaluation on the Hogzilla dataset, a standard benchmark, showcases\nan impressive accuracy of 99.16\\% for multi-class classification and 99.10\\%\nfor binary classification, while ensuring interpretability through LIME. This\nfusion of deep learning and interpretability presents a promising avenue for\nenhancing intrusion detection systems by improving transparency and decision\nsupport in network security.",
      "tldr_zh": "本论文提出了一种新型入侵检测系统，结合 Generative Adversarial Networks (GAN) 生成真实网络流量数据（包括正常和攻击模式）、Multi-Scale Convolutional Neural Networks (MSCNN) 提取多尺度特征，以及 Bidirectional Long Short-Term Memory (BiLSTM) 捕捉流量序列的时间依赖性，并通过 Local Interpretable Model-Agnostic Explanations (LIME) 提升模型决策的可解释性。该系统在 Hogzilla 数据集上评估，实现了多类分类准确率99.16%和二元分类准确率99.10%，显著提高了检测性能。整体框架融合了深度学习与解释性技术，为网络安全提供了更透明和可靠的决策支持。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05443v1",
      "published_date": "2024-06-08 11:26:44 UTC",
      "updated_date": "2024-06-08 11:26:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:49:08.294239"
    },
    {
      "arxiv_id": "2406.12898v1",
      "title": "A Comprehensive Evaluation of Generative Models in Calorimeter Shower Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Farzana Yasmin Ahmad",
        "Vanamala Venkataswamy",
        "Geoffrey Fox"
      ],
      "abstract": "The pursuit of understanding fundamental particle interactions has reached\nunparalleled precision levels. Particle physics detectors play a crucial role\nin generating low-level object signatures that encode collision physics.\nHowever, simulating these particle collisions is a demanding task in terms of\nmemory and computation which will be exasperated with larger data volumes, more\ncomplex detectors, and a higher pileup environment in the High-Luminosity LHC.\nThe introduction of \"Fast Simulation\" has been pivotal in overcoming\ncomputational bottlenecks. The use of deep-generative models has sparked a\nsurge of interest in surrogate modeling for detector simulations, generating\nparticle showers that closely resemble the observed data. Nonetheless, there is\na pressing need for a comprehensive evaluation of their performance using a\nstandardized set of metrics. In this study, we conducted a rigorous evaluation\nof three generative models using standard datasets and a diverse set of metrics\nderived from physics, computer vision, and statistics. Furthermore, we explored\nthe impact of using full versus mixed precision modes during inference. Our\nevaluation revealed that the CaloDiffusion and CaloScore generative models\ndemonstrate the most accurate simulation of particle showers, yet there remains\nsubstantial room for improvement. Our findings identified areas where the\nevaluated models fell short in accurately replicating Geant4 data.",
      "tldr_zh": "该论文对生成模型在粒子淋浴模拟中的性能进行了全面评估，旨在解决粒子物理学中模拟计算资源需求的挑战。研究者使用标准数据集和多种指标（包括物理、计算机视觉和统计学领域）评估了三种生成模型，并比较了全精度和混合精度模式的影响。结果显示，CaloDiffusion 和 CaloScore 模型在模拟粒子淋浴方面表现出最高准确性，但仍存在不足，无法完全复制 Geant4 数据，从而为未来模型改进提供了方向。",
      "categories": [
        "physics.ins-det",
        "cs.AI",
        "hep-ex",
        "physics.data-an"
      ],
      "primary_category": "physics.ins-det",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12898v1",
      "published_date": "2024-06-08 11:17:28 UTC",
      "updated_date": "2024-06-08 11:17:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:49:20.913876"
    },
    {
      "arxiv_id": "2406.05439v1",
      "title": "A Scalable and Near-Optimal Conformance Checking Approach for Long Traces",
      "title_zh": "翻译失败",
      "authors": [
        "Eli Bogdanov",
        "Izack Cohen",
        "Avigdor Gal"
      ],
      "abstract": "Long traces and large event logs that originate from sensors and prediction\nmodels are becoming more common in our data-rich world. In such circumstances,\nconformance checking, a key task in process mining, can become computationally\ninfeasible due to the exponential complexity of finding an optimal alignment.\n  This paper introduces a novel sliding window approach to address these\nscalability challenges while preserving the interpretability of alignment-based\nmethods. By breaking down traces into manageable subtraces and iteratively\naligning each with the process model, our method significantly reduces the\nsearch space.\n  The approach uses global information that captures structural properties of\nthe trace and the process model to make informed alignment decisions,\ndiscarding unpromising alignments even if they are optimal for a local\nsubtrace. This improves the overall accuracy of the results.\n  Experimental evaluations demonstrate that the proposed method consistently\nfinds optimal alignments in most cases and highlight its scalability. This is\nfurther supported by a theoretical complexity analysis, which shows the reduced\ngrowth of the search space compared to other common conformance checking\nmethods.\n  This work provides a valuable contribution towards efficient conformance\nchecking for large-scale process mining applications.",
      "tldr_zh": "这篇论文针对长 traces 的 conformance checking 问题，提出了一种可伸缩且接近最优的 sliding window approach，以解决传统方法的指数级复杂性挑战，同时保留 alignment-based 方法的可解释性。该方法将 traces 拆分成可管理的 subtraces，并利用全局信息捕获 traces 和 process model 的结构属性，进行迭代 alignment 并丢弃不 promising 的选项，从而显著减少搜索空间。实验评估显示，该方法在大多数情况下找到 optimal alignments，并证明了其可伸缩性；理论复杂度分析进一步证实了其相对于其他 conformance checking 方法的效率优势，为大型过程挖掘应用提供了重要贡献。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05439v1",
      "published_date": "2024-06-08 11:04:42 UTC",
      "updated_date": "2024-06-08 11:04:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:49:33.822103"
    },
    {
      "arxiv_id": "2406.05422v1",
      "title": "Diffusion-based Reinforcement Learning for Dynamic UAV-assisted Vehicle Twins Migration in Vehicular Metaverses",
      "title_zh": "翻译失败",
      "authors": [
        "Yongju Tong",
        "Jiawen Kang",
        "Junlong Chen",
        "Minrui Xu",
        "Gaolei Li",
        "Weiting Zhang",
        "Xincheng Yan"
      ],
      "abstract": "Air-ground integrated networks can relieve communication pressure on ground\ntransportation networks and provide 6G-enabled vehicular Metaverses services\noffloading in remote areas with sparse RoadSide Units (RSUs) coverage and\ndowntown areas where users have a high demand for vehicular services. Vehicle\nTwins (VTs) are the digital twins of physical vehicles to enable more immersive\nand realistic vehicular services, which can be offloaded and updated on RSU, to\nmanage and provide vehicular Metaverses services to passengers and drivers. The\nhigh mobility of vehicles and the limited coverage of RSU signals necessitate\nVT migration to ensure service continuity when vehicles leave the signal\ncoverage of RSUs. However, uneven VT task migration might overload some RSUs,\nwhich might result in increased service latency, and thus impactive immersive\nexperiences for users. In this paper, we propose a dynamic Unmanned Aerial\nVehicle (UAV)-assisted VT migration framework in air-ground integrated\nnetworks, where UAVs act as aerial edge servers to assist ground RSUs during VT\ntask offloading. In this framework, we propose a diffusion-based Reinforcement\nLearning (RL) algorithm, which can efficiently make immersive VT migration\ndecisions in UAV-assisted vehicular networks. To balance the workload of RSUs\nand improve VT migration quality, we design a novel dynamic path planning\nalgorithm based on a heuristic search strategy for UAVs. Simulation results\nshow that the diffusion-based RL algorithm with UAV-assisted performs better\nthan other baseline schemes.",
      "tldr_zh": "这篇论文提出了一种动态 UAV 辅助的 Vehicle Twins (VTs) 迁移框架，用于空地一体化网络中车辆元宇宙服务，以缓解 RSU 覆盖有限和高移动性导致的服务中断问题。框架采用 Diffusion-based Reinforcement Learning 算法来优化 VT 迁移决策，并设计了基于启发式搜索策略的动态路径规划算法，帮助 UAV 作为空中边缘服务器平衡 RSU 工作负载并减少服务延迟。模拟结果显示，该方法比基线方案更有效地提升了用户沉浸体验和服务质量。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05422v1",
      "published_date": "2024-06-08 09:53:56 UTC",
      "updated_date": "2024-06-08 09:53:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:49:48.800398"
    },
    {
      "arxiv_id": "2406.05418v1",
      "title": "Multi-attribute Auction-based Resource Allocation for Twins Migration in Vehicular Metaverses: A GPT-based DRL Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yongju Tong",
        "Junlong Chen",
        "Minrui Xu",
        "Jiawen Kang",
        "Zehui Xiong",
        "Dusit Niyato",
        "Chau Yuen",
        "Zhu Han"
      ],
      "abstract": "Vehicular Metaverses are developed to enhance the modern automotive industry\nwith an immersive and safe experience among connected vehicles and roadside\ninfrastructures, e.g., RoadSide Units (RSUs). For seamless synchronization with\nvirtual spaces, Vehicle Twins (VTs) are constructed as digital representations\nof physical entities. However, resource-intensive VTs updating and high\nmobility of vehicles require intensive computation, communication, and storage\nresources, especially for their migration among RSUs with limited coverages. To\naddress these issues, we propose an attribute-aware auction-based mechanism to\noptimize resource allocation during VTs migration by considering both price and\nnon-monetary attributes, e.g., location and reputation. In this mechanism, we\npropose a two-stage matching for vehicular users and Metaverse service\nproviders in multi-attribute resource markets. First, the resource attributes\nmatching algorithm obtains the resource attributes perfect matching, namely,\nbuyers and sellers can participate in a double Dutch auction (DDA). Then, we\ntrain a DDA auctioneer using a generative pre-trained transformer (GPT)-based\ndeep reinforcement learning (DRL) algorithm to adjust the auction clocks\nefficiently during the auction process. We compare the performance of social\nwelfare and auction information exchange costs with state-of-the-art baselines\nunder different settings. Simulation results show that our proposed GPT-based\nDRL auction schemes have better performance than others.",
      "tldr_zh": "该研究针对Vehicular Metaverses中Vehicle Twins (VTs)迁移的资源分配问题，提出了一种基于多属性的拍卖机制，以优化计算、通信和存储资源的使用，同时考虑价格和非货币属性（如位置和声誉）。该机制采用两阶段匹配方法：首先通过资源属性匹配算法实现完美匹配，然后利用GPT-based Deep Reinforcement Learning (DRL)算法训练双荷兰拍卖 (DDA) auctioneer，以高效调整拍卖过程。实验结果显示，该方案在社会福利和拍卖信息交换成本方面优于现有基线，证明了其在高流动性车辆场景中的有效性。",
      "categories": [
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.05418v1",
      "published_date": "2024-06-08 09:41:38 UTC",
      "updated_date": "2024-06-08 09:41:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:49:59.989752"
    },
    {
      "arxiv_id": "2406.05413v1",
      "title": "Discover Your Neighbors: Advanced Stable Test-Time Adaptation in Dynamic World",
      "title_zh": "发现你的邻居：动态世界中的高级稳定测试时适应",
      "authors": [
        "Qinting Jiang",
        "Chuyang Ye",
        "Dongyan Wei",
        "Yuan Xue",
        "Jingyan Jiang",
        "Zhi Wang"
      ],
      "abstract": "Despite progress, deep neural networks still suffer performance declines\nunder distribution shifts between training and test domains, leading to a\nsubstantial decrease in Quality of Experience (QoE) for multimedia\napplications. Existing test-time adaptation (TTA) methods are challenged by\ndynamic, multiple test distributions within batches. This work provides a new\nperspective on analyzing batch normalization techniques through class-related\nand class-irrelevant features, our observations reveal combining source and\ntest batch normalization statistics robustly characterizes target\ndistributions. However, test statistics must have high similarity. We thus\npropose Discover Your Neighbours (DYN), the first backward-free approach\nspecialized for dynamic TTA. The core innovation is identifying similar samples\nvia instance normalization statistics and clustering into groups which provides\nconsistent class-irrelevant representations. Specifically, Our DYN consists of\nlayer-wise instance statistics clustering (LISC) and cluster-aware batch\nnormalization (CABN). In LISC, we perform layer-wise clustering of approximate\nfeature samples at each BN layer by calculating the cosine similarity of\ninstance normalization statistics across the batch. CABN then aggregates SBN\nand TCN statistics to collaboratively characterize the target distribution,\nenabling more robust representations. Experimental results validate DYN's\nrobustness and effectiveness, demonstrating maintained performance under\ndynamic data stream patterns.",
      "tldr_zh": "该论文针对深度神经网络在训练和测试域分布偏移下性能下降的问题，特别是在动态多分布测试批次中影响 Quality of Experience (QoE)，提出了一种先进的 Test-Time Adaptation (TTA) 方法 Discover Your Neighbours (DYN)。DYN 的核心创新是通过 Layer-wise Instance Statistics Clustering (LISC) 计算实例标准化统计的余弦相似度进行层级聚类，以及 Cluster-Aware Batch Normalization (CABN) 聚合源和测试批标准化统计，以提供一致的类无关表示并稳健表征目标分布。作为首个无反向传播（backward-free）的动态 TTA 方案，实验验证 DYN 在动态数据流模式下显著提升了模型性能和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.05413v1",
      "published_date": "2024-06-08 09:22:32 UTC",
      "updated_date": "2024-06-08 09:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:50:14.584930"
    },
    {
      "arxiv_id": "2406.05410v1",
      "title": "MLLM-SR: Conversational Symbolic Regression base Multi-Modal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yanjie Li",
        "Weijun Li",
        "Lina Yu",
        "Min Wu",
        "Jingyi Liu",
        "Wenqiang Li",
        "Shu Wei",
        "Yusong Deng"
      ],
      "abstract": "Formulas are the language of communication between humans and nature. It is\nan important research topic of artificial intelligence to find expressions from\nobserved data to reflect the relationship between each variable in the data,\nwhich is called a symbolic regression problem. The existing symbolic regression\nmethods directly generate expressions according to the given observation data,\nand we cannot require the algorithm to generate expressions that meet specific\nrequirements according to the known prior knowledge. For example, the\nexpression needs to contain $\\sin$ or be symmetric, and so on. Even if it can,\nit often requires very complex operations, which is very inconvenient. In this\npaper, based on multi-modal large language models, we propose MLLM-SR, a\nconversational symbolic regression method that can generate expressions that\nmeet the requirements simply by describing the requirements with natural\nlanguage instructions. By experimenting on the Nguyen dataset, we can\ndemonstrate that MLLM-SR leads the state-of-the-art baselines in fitting\nperformance. More notably, we experimentally demonstrate that MLLM-SR can well\nunderstand the prior knowledge we add to the natural language instructions.\nMoreover, the addition of prior knowledge can effectively guide MLLM-SR to\ngenerate correct expressions.",
      "tldr_zh": "本研究针对符号回归（symbolic regression）问题提出 MLLM-SR，一种基于多模态大语言模型（Multi-Modal Large Language Models）的对话式方法，能够通过自然语言指令轻松生成符合特定要求的表达式，例如包含 $\\sin$ 函数或具有对称性。相比现有方法，MLLM-SR 避免了复杂操作，直接利用用户指令融入先验知识，从而提升生成表达式的准确性和灵活性。在 Nguyen 数据集上的实验显示，MLLM-SR 在拟合性能上领先最先进基线，并且能有效理解并应用指令中的先验知识来指导正确表达式生成。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages,",
      "pdf_url": "http://arxiv.org/pdf/2406.05410v1",
      "published_date": "2024-06-08 09:17:54 UTC",
      "updated_date": "2024-06-08 09:17:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:50:24.398971"
    },
    {
      "arxiv_id": "2406.05409v1",
      "title": "Natural Language-Oriented Programming (NLOP): Towards Democratizing Software Creation",
      "title_zh": "自然语言导向编程 (N",
      "authors": [
        "Amin Beheshti"
      ],
      "abstract": "As generative Artificial Intelligence (AI) technologies evolve, they offer\nunprecedented potential to automate and enhance various tasks, including\ncoding. Natural Language-Oriented Programming (NLOP), a vision introduced in\nthis paper, harnesses this potential by allowing developers to articulate\nsoftware requirements and logic in their natural language, thereby\ndemocratizing software creation. This approach streamlines the development\nprocess and significantly lowers the barrier to entry for software engineering,\nmaking it feasible for non-experts to contribute effectively to software\nprojects. By simplifying the transition from concept to code, NLOP can\naccelerate development cycles, enhance collaborative efforts, and reduce\nmisunderstandings in requirement specifications. This paper reviews various\nprogramming models, assesses their contributions and limitations, and\nhighlights that natural language will be the new programming language. Through\nthis comparison, we illustrate how NLOP stands to transform the landscape of\nsoftware engineering by fostering greater inclusivity and innovation.",
      "tldr_zh": "本论文引入了Natural Language-Oriented Programming (NLOP)，一种利用生成式AI技术让开发者用自然语言表达软件需求和逻辑的方法，旨在民主化软件创建过程。NLOP通过简化从概念到代码的转换，降低软件工程门槛，使非专家也能有效参与项目开发，从而加速开发周期、增强协作并减少需求规格误解。该研究比较了各种编程模型的优缺点，强调自然语言将成为未来的编程语言，推动软件工程领域的包容性和创新。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted in: 2024 IEEE International Conference on Software Services\n  Engineering (SSE), Shenzhen, China, July 7-13, 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05409v1",
      "published_date": "2024-06-08 09:13:54 UTC",
      "updated_date": "2024-06-08 09:13:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:50:34.905633"
    },
    {
      "arxiv_id": "2406.05396v1",
      "title": "Mean-field Chaos Diffusion Models",
      "title_zh": "平均场混沌扩散模型",
      "authors": [
        "Sungwoo Park",
        "Dongjun Kim",
        "Ahmed Alaa"
      ],
      "abstract": "In this paper, we introduce a new class of score-based generative models\n(SGMs) designed to handle high-cardinality data distributions by leveraging\nconcepts from mean-field theory. We present mean-field chaos diffusion models\n(MF-CDMs), which address the curse of dimensionality inherent in\nhigh-cardinality data by utilizing the propagation of chaos property of\ninteracting particles. By treating high-cardinality data as a large stochastic\nsystem of interacting particles, we develop a novel score-matching method for\ninfinite-dimensional chaotic particle systems and propose an approximation\nscheme that employs a subdivision strategy for efficient training. Our\ntheoretical and empirical results demonstrate the scalability and effectiveness\nof MF-CDMs for managing large high-cardinality data structures, such as 3D\npoint clouds.",
      "tldr_zh": "本文提出了一种新的基于分数的生成模型（score-based generative models, SGMs），利用均值场理论（mean-field theory）来处理高基数数据分布。作者引入均值场混沌扩散模型（MF-CDMs），通过互动粒子的混沌传播属性（propagation of chaos）解决高基数数据中的维度诅咒（curse of dimensionality），并开发了一种针对无限维混沌粒子系统的分数匹配方法（score-matching method），结合细分策略实现高效训练。实验结果显示，MF-CDMs 在管理大型高基数数据结构（如3D point clouds）方面具有良好的可扩展性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05396v1",
      "published_date": "2024-06-08 08:24:06 UTC",
      "updated_date": "2024-06-08 08:24:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:50:49.430782"
    },
    {
      "arxiv_id": "2406.05392v2",
      "title": "Deconstructing The Ethics of Large Language Models from Long-standing Issues to New-emerging Dilemmas: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyuan Deng",
        "Yiqun Duan",
        "Xin Jin",
        "Heng Chang",
        "Yijun Tian",
        "Han Liu",
        "Yichen Wang",
        "Kuofeng Gao",
        "Henry Peng Zou",
        "Yiqiao Jin",
        "Yijia Xiao",
        "Shenghao Wu",
        "Zongxing Xie",
        "Weimin Lyu",
        "Sihong He",
        "Lu Cheng",
        "Haohan Wang",
        "Jun Zhuang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved unparalleled success across\ndiverse language modeling tasks in recent years. However, this progress has\nalso intensified ethical concerns, impacting the deployment of LLMs in everyday\ncontexts. This paper provides a comprehensive survey of ethical challenges\nassociated with LLMs, from longstanding issues such as copyright infringement,\nsystematic bias, and data privacy, to emerging problems like truthfulness and\nsocial norms. We critically analyze existing research aimed at understanding,\nexamining, and mitigating these ethical risks. Our survey underscores\nintegrating ethical standards and societal values into the development of LLMs,\nthereby guiding the development of responsible and ethically aligned language\nmodels.",
      "tldr_zh": "这篇论文对大型语言模型 (LLMs) 的伦理挑战进行了全面调查，从长期问题如版权侵犯、系统偏差和数据隐私，到新兴困境如真实性和社会规范。作者批判性地分析了现有研究，旨在理解、评估并缓解这些风险。最终，该调查强调了在 LLM 开发过程中整合伦理标准和社会价值观的必要性，以指导创建负责任且伦理对齐的语言模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05392v2",
      "published_date": "2024-06-08 07:55:01 UTC",
      "updated_date": "2024-10-21 07:08:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:50:59.021011"
    },
    {
      "arxiv_id": "2406.10247v1",
      "title": "QCQA: Quality and Capacity-aware grouped Query Attention",
      "title_zh": "QCQA: 质量和容量感知的分组查询注意力",
      "authors": [
        "Vinay Joshi",
        "Prashant Laddha",
        "Shambhavi Sinha",
        "Om Ji Omer",
        "Sreenivas Subramoney"
      ],
      "abstract": "Excessive memory requirements of key and value features (KV-cache) present\nsignificant challenges in the autoregressive inference of large language models\n(LLMs), restricting both the speed and length of text generation. Approaches\nsuch as Multi-Query Attention (MQA) and Grouped Query Attention (GQA) mitigate\nthese challenges by grouping query heads and consequently reducing the number\nof corresponding key and value heads. However, MQA and GQA decrease the\nKV-cache size requirements at the expense of LLM accuracy (quality of text\ngeneration). These methods do not ensure an optimal tradeoff between KV-cache\nsize and text generation quality due to the absence of quality-aware grouping\nof query heads. To address this issue, we propose Quality and Capacity-Aware\nGrouped Query Attention (QCQA), which identifies optimal query head groupings\nusing an evolutionary algorithm with a computationally efficient and\ninexpensive fitness function. We demonstrate that QCQA achieves a significantly\nbetter tradeoff between KV-cache capacity and LLM accuracy compared to GQA. For\nthe Llama2 $7\\,$B model, QCQA achieves $\\mathbf{20}$\\% higher accuracy than GQA\nwith similar KV-cache size requirements in the absence of fine-tuning. After\nfine-tuning both QCQA and GQA, for a similar KV-cache size, QCQA provides\n$\\mathbf{10.55}\\,$\\% higher accuracy than GQA. Furthermore, QCQA requires\n$40\\,$\\% less KV-cache size than GQA to attain similar accuracy. The proposed\nquality and capacity-aware grouping of query heads can serve as a new paradigm\nfor KV-cache optimization in autoregressive LLM inference.",
      "tldr_zh": "该论文提出 QCQA（Quality and Capacity-aware Grouped Query Attention），一种新型注意力机制，用于优化大型语言模型（LLMs）在自回归推理中的 KV-cache 内存需求问题。QCQA 通过进化算法和高效的适应度函数实现质量感知的查询头分组，相比传统 Multi-Query Attention (MQA) 和 Grouped Query Attention (GQA)，它在减少 KV-cache 大小的同时显著提升文本生成准确性。在 Llama2 7B 模型上，QCQA 无微调时比 GQA 准确性提高 20%，微调后提高 10.55%，并在类似准确性下减少 40% 的 KV-cache 大小。该方法为 LLMs 的 KV-cache 优化提供了新的范式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10247v1",
      "published_date": "2024-06-08 07:49:55 UTC",
      "updated_date": "2024-06-08 07:49:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:51:15.280867"
    },
    {
      "arxiv_id": "2406.05375v2",
      "title": "LEMMA-RCA: A Large Multi-modal Multi-domain Dataset for Root Cause Analysis",
      "title_zh": "LEMMA-RCA：一个大型多模态多领域数据集，用于根因分析",
      "authors": [
        "Lecheng Zheng",
        "Zhengzhang Chen",
        "Dongjie Wang",
        "Chengyuan Deng",
        "Reon Matsuoka",
        "Haifeng Chen"
      ],
      "abstract": "Root cause analysis (RCA) is crucial for enhancing the reliability and\nperformance of complex systems. However, progress in this field has been\nhindered by the lack of large-scale, open-source datasets tailored for RCA. To\nbridge this gap, we introduce LEMMA-RCA, a large dataset designed for diverse\nRCA tasks across multiple domains and modalities. LEMMA-RCA features various\nreal-world fault scenarios from IT and OT operation systems, encompassing\nmicroservices, water distribution, and water treatment systems, with hundreds\nof system entities involved. We evaluate the quality of LEMMA-RCA by testing\nthe performance of eight baseline methods on this dataset under various\nsettings, including offline and online modes as well as single and multiple\nmodalities. Our experimental results demonstrate the high quality of LEMMA-RCA.\nThe dataset is publicly available at https://lemma-rca.github.io/.",
      "tldr_zh": "本研究指出，根因分析（RCA）领域缺乏大规模开源数据集，这阻碍了复杂系统的可靠性和性能提升。为解决此问题，研究团队引入了 LEMMA-RCA，这是一个大型多模态（multi-modal）和多领域（multi-domain）数据集，涵盖 IT 和 OT 操作系统的真实故障场景，包括微服务、水分配和水处理系统，并涉及数百个系统实体。研究者评估了八种基线方法在离线和在线模式以及单模态和多模态设置下的性能，结果证明 LEMMA-RCA 的高质量，并已公开提供数据集链接（https://lemma-rca.github.io/）。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05375v2",
      "published_date": "2024-06-08 07:00:31 UTC",
      "updated_date": "2024-09-26 22:42:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:51:24.476785"
    },
    {
      "arxiv_id": "2406.05369v1",
      "title": "Venn Diagram Prompting : Accelerating Comprehension with Scaffolding Effect",
      "title_zh": "翻译失败",
      "authors": [
        "Sakshi Mahendru",
        "Tejul Pandit"
      ],
      "abstract": "We introduce Venn Diagram (VD) Prompting, an innovative prompting technique\nwhich allows Large Language Models (LLMs) to combine and synthesize information\nacross complex, diverse and long-context documents in knowledge-intensive\nquestion-answering tasks. Generating answers from multiple documents involves\nnumerous steps to extract relevant and unique information and amalgamate it\ninto a cohesive response. To improve the quality of the final answer, multiple\nLLM calls or pretrained models are used to perform different tasks such as\nsummarization, reorganization and customization. The approach covered in the\npaper focuses on replacing the multi-step strategy via a single LLM call using\nVD prompting. Our proposed technique also aims to eliminate the inherent\nposition bias in the LLMs, enhancing consistency in answers by removing\nsensitivity to the sequence of input information. It overcomes the challenge of\ninconsistency traditionally associated with varying input sequences. We also\nexplore the practical applications of the VD prompt based on our examination of\nthe prompt's outcomes. In the experiments performed on four public benchmark\nquestion-answering datasets, VD prompting continually matches or surpasses the\nperformance of a meticulously crafted instruction prompt which adheres to\noptimal guidelines and practices.",
      "tldr_zh": "本研究引入了Venn Diagram (VD) Prompting，一种创新的提示技术，用于帮助Large Language Models (LLMs)在知识密集型问答任务中，从复杂多样的长上下文文档中组合和合成信息。VD Prompting通过单一LLM调用替换传统的多步策略（如总结、重组和定制），从而消除inherent position bias，提高答案的一致性和对输入序列的鲁棒性。实验结果显示，在四个公共基准问答数据集上，VD Prompting的性能持续匹配或超过精心设计的指令提示，显著加速了信息理解过程。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. 10 pages, Accepted in 2024 the 6th World Symposium on\n  Artificial Intelligence (WSAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.05369v1",
      "published_date": "2024-06-08 06:27:26 UTC",
      "updated_date": "2024-06-08 06:27:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:51:35.853022"
    },
    {
      "arxiv_id": "2406.05365v2",
      "title": "CaLM: Contrasting Large and Small Language Models to Verify Grounded Generation",
      "title_zh": "翻译失败",
      "authors": [
        "I-Hung Hsu",
        "Zifeng Wang",
        "Long T. Le",
        "Lesly Miculicich",
        "Nanyun Peng",
        "Chen-Yu Lee",
        "Tomas Pfister"
      ],
      "abstract": "Grounded generation aims to equip language models (LMs) with the ability to\nproduce more credible and accountable responses by accurately citing verifiable\nsources. However, existing methods, by either feeding LMs with raw or\npreprocessed materials, remain prone to errors. To address this, we introduce\nCaLM, a novel verification framework. CaLM leverages the insight that a robust\ngrounded response should be consistent with information derived solely from its\ncited sources. Our framework empowers smaller LMs, which rely less on\nparametric memory and excel at processing relevant information given a query,\nto validate the output of larger LMs. Larger LM responses that closely align\nwith the smaller LMs' output, which relies exclusively on cited documents, are\nverified. Responses showing discrepancies are iteratively refined through a\nfeedback loop. Experiments on three open-domain question-answering datasets\ndemonstrate significant performance gains of 1.5% to 7% absolute average\nwithout any required model fine-tuning.",
      "tldr_zh": "该研究提出 CaLM 框架，用于验证语言模型（LMs）的 grounded generation，确保响应准确引用可验证来源并减少错误。CaLM 方法通过对比大型语言模型（large LMs）的输出与小型语言模型（small LMs）的生成，后者仅依赖引用的文档进行处理，并通过反馈循环迭代改进不一致的响应。在三个开放域问答数据集上的实验中，CaLM 实现了 1.5% 到 7% 的绝对性能提升，而无需任何模型微调。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 Camera Ready Version",
      "pdf_url": "http://arxiv.org/pdf/2406.05365v2",
      "published_date": "2024-06-08 06:04:55 UTC",
      "updated_date": "2024-06-24 07:39:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:51:52.672565"
    },
    {
      "arxiv_id": "2406.05364v2",
      "title": "Is On-Device AI Broken and Exploitable? Assessing the Trust and Ethics in Small Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kalyan Nakka",
        "Jimmy Dani",
        "Nitesh Saxena"
      ],
      "abstract": "In this paper, we present a very first study to investigate trust and ethical\nimplications of on-device artificial intelligence (AI), focusing on small\nlanguage models (SLMs) amenable for personal devices like smartphones. While\non-device SLMs promise enhanced privacy, reduced latency, and improved user\nexperience compared to cloud-based services, we posit that they might also\nintroduce significant risks and vulnerabilities compared to their on-server\ncounterparts. As part of our trust assessment study, we conduct a systematic\nevaluation of the state-of-the-art on-devices SLMs, contrasted to their\non-server counterparts, based on a well-established trustworthiness measurement\nframework. Our results show on-device SLMs to be significantly less\ntrustworthy, specifically demonstrating more stereotypical, unfair and\nprivacy-breaching behavior. Informed by these findings, we then perform our\nethics assessment study using a dataset of unethical questions, that depicts\nharmful scenarios. Our results illustrate the lacking ethical safeguards in\non-device SLMs, emphasizing their capabilities of generating harmful content.\nFurther, the broken safeguards and exploitable nature of on-device SLMs is\ndemonstrated using potentially unethical vanilla prompts, to which the\non-device SLMs answer with valid responses without any filters and without the\nneed for any jailbreaking or prompt engineering. These responses can be abused\nfor various harmful and unethical scenarios like: societal harm, illegal\nactivities, hate, self-harm, exploitable phishing content and many others, all\nof which indicates the severe vulnerability and exploitability of these\non-device SLMs.",
      "tldr_zh": "这篇论文首次系统评估了设备端人工智能（AI）的信任和伦理问题，聚焦于适合智能手机等设备的Small Language Models (SLMs)。研究者对比了设备端SLMs与服务器端模型，使用trustworthiness measurement framework进行评估，结果显示设备端SLMs更易表现出刻板印象、不公平行为和隐私侵犯。进一步的伦理评估通过不道德问题数据集揭示，这些模型缺乏有效安全机制，能轻易生成有害内容，如涉及社会伤害、非法活动和仇恨等。总体而言，该研究突出了设备端SLMs的漏洞和可利用性，强调了潜在风险。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "26 pages, 31 figures and 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.05364v2",
      "published_date": "2024-06-08 05:45:42 UTC",
      "updated_date": "2025-03-05 04:18:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:52:04.449854"
    },
    {
      "arxiv_id": "2406.05354v1",
      "title": "Investigating Memory Failure Prediction Across CPU Architectures",
      "title_zh": "跨 CPU 架构的内存故障预测调查",
      "authors": [
        "Qiao Yu",
        "Wengui Zhang",
        "Min Zhou",
        "Jialiang Yu",
        "Zhenli Sheng",
        "Jasmin Bogatinovski",
        "Jorge Cardoso",
        "Odej Kao"
      ],
      "abstract": "Large-scale datacenters often experience memory failures, where Uncorrectable\nErrors (UEs) highlight critical malfunction in Dual Inline Memory Modules\n(DIMMs). Existing approaches primarily utilize Correctable Errors (CEs) to\npredict UEs, yet they typically neglect how these errors vary between different\nCPU architectures, especially in terms of Error Correction Code (ECC)\napplicability. In this paper, we investigate the correlation between CEs and\nUEs across different CPU architectures, including X86 and ARM. Our analysis\nidentifies unique patterns of memory failure associated with each processor\nplatform. Leveraging Machine Learning (ML) techniques on production datasets,\nwe conduct the memory failure prediction in different processors' platforms,\nachieving up to 15% improvements in F1-score compared to the existing\nalgorithm. Finally, an MLOps (Machine Learning Operations) framework is\nprovided to consistently improve the failure prediction in the production\nenvironment.",
      "tldr_zh": "本研究调查了不同 CPU 架构（如 X86 和 ARM）中内存故障的预测问题，重点分析 Correctable Errors (CEs) 与 Uncorrectable Errors (UEs) 之间的相关性，以及 Error Correction Code (ECC) 的适用差异。研究人员通过 Machine Learning (ML) 技术在生产数据集上进行预测，识别出各平台独特的故障模式，并实现了比现有算法高出 15% 的 F1-score 改进。最后，他们提供了一个 MLOps (Machine Learning Operations) 框架，以持续优化数据中心环境中的内存故障预测。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted by 2024 54th Annual IEEE/IFIP International Conference on\n  Dependable Systems and Networks (DSN), Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2406.05354v1",
      "published_date": "2024-06-08 05:10:23 UTC",
      "updated_date": "2024-06-08 05:10:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:52:15.019341"
    },
    {
      "arxiv_id": "2406.05348v2",
      "title": "Toward Reliable Ad-hoc Scientific Information Extraction: A Case Study on Two Materials Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Satanu Ghosh",
        "Neal R. Brodnik",
        "Carolina Frey",
        "Collin Holgate",
        "Tresa M. Pollock",
        "Samantha Daly",
        "Samuel Carton"
      ],
      "abstract": "We explore the ability of GPT-4 to perform ad-hoc schema based information\nextraction from scientific literature. We assess specifically whether it can,\nwith a basic prompting approach, replicate two existing material science\ndatasets, given the manuscripts from which they were originally manually\nextracted. We employ materials scientists to perform a detailed manual error\nanalysis to assess where the model struggles to faithfully extract the desired\ninformation, and draw on their insights to suggest research directions to\naddress this broadly important task.",
      "tldr_zh": "本研究探讨了GPT-4在进行ad-hoc schema based information extraction方面的可靠性，通过一个基本提示方法，尝试从科学文献中复制两个现有materials science datasets。实验涉及使用GPT-4从原始手稿中提取信息，并由材料科学家进行详细的手动错误分析，以识别模型在忠实提取数据时的挑战点。基于这些分析，该论文提出研究方向，以改进这一重要任务的准确性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Update on 12/11/2024: Added some relevant literature that we missed\n  in previous version of the paper",
      "pdf_url": "http://arxiv.org/pdf/2406.05348v2",
      "published_date": "2024-06-08 04:24:16 UTC",
      "updated_date": "2024-12-11 19:28:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:52:35.294781"
    },
    {
      "arxiv_id": "2406.05347v3",
      "title": "MSAGPT: Neural Prompting Protein Structure Prediction via MSA Generative Pre-Training",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Chen",
        "Zhilei Bei",
        "Xingyi Cheng",
        "Pan Li",
        "Jie Tang",
        "Le Song"
      ],
      "abstract": "Multiple Sequence Alignment (MSA) plays a pivotal role in unveiling the\nevolutionary trajectories of protein families. The accuracy of protein\nstructure predictions is often compromised for protein sequences that lack\nsufficient homologous information to construct high quality MSA. Although\nvarious methods have been proposed to generate virtual MSA under these\nconditions, they fall short in comprehensively capturing the intricate\ncoevolutionary patterns within MSA or require guidance from external oracle\nmodels. Here we introduce MSAGPT, a novel approach to prompt protein structure\npredictions via MSA generative pretraining in the low MSA regime. MSAGPT\nemploys a simple yet effective 2D evolutionary positional encoding scheme to\nmodel complex evolutionary patterns. Endowed by this, its flexible 1D MSA\ndecoding framework facilitates zero or few shot learning. Moreover, we\ndemonstrate that leveraging the feedback from AlphaFold2 can further enhance\nthe model capacity via Rejective Fine tuning (RFT) and Reinforcement Learning\nfrom AF2 Feedback (RLAF). Extensive experiments confirm the efficacy of MSAGPT\nin generating faithful virtual MSA to enhance the structure prediction\naccuracy. The transfer learning capabilities also highlight its great potential\nfor facilitating other protein tasks.",
      "tldr_zh": "这篇论文介绍了 MSAGPT，一种通过 MSA 生成式预训练来提升蛋白质结构预测的方法，针对蛋白序列缺乏同源信息导致 MSA 质量低下的问题。MSAGPT 采用简单的 2D 进化位置编码方案建模复杂的共进化模式，并通过灵活的 1D MSA 解码框架实现零样本或少样本学习，同时利用 AlphaFold2 的反馈进行 Rejective Fine Tuning (RFT) 和 Reinforcement Learning from AF2 Feedback (RLAF) 以优化模型性能。实验结果证明，MSAGPT 能生成可靠的虚拟 MSA，提高结构预测准确性，并展示出转移学习潜力，支持其他蛋白质相关任务。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05347v3",
      "published_date": "2024-06-08 04:23:57 UTC",
      "updated_date": "2024-10-28 08:51:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:52:40.759565"
    },
    {
      "arxiv_id": "2406.05343v2",
      "title": "M3GIA: A Cognition Inspired Multilingual and Multimodal General Intelligence Ability Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Song",
        "Yadong Li",
        "Jianhua Xu",
        "Guowei Wu",
        "Lingfeng Ming",
        "Kexin Yi",
        "Weihua Luo",
        "Houyi Li",
        "Yi Du",
        "Fangda Guo",
        "Kaicheng Yu"
      ],
      "abstract": "As recent multi-modality large language models (MLLMs) have shown formidable\nproficiency on various complex tasks, there has been increasing attention on\ndebating whether these models could eventually mirror human intelligence.\nHowever, existing benchmarks mainly focus on evaluating solely on task\nperformance, such as the accuracy of identifying the attribute of an object.\nCombining well-developed cognitive science to understand the intelligence of\nMLLMs beyond superficial achievements remains largely unexplored. To this end,\nwe introduce the first cognitive-driven multi-lingual and multi-modal benchmark\nto evaluate the general intelligence ability of MLLMs, dubbed M3GIA.\nSpecifically, we identify five key cognitive factors based on the\nwell-recognized Cattell-Horn-Carrol (CHC) model of intelligence and propose a\nnovel evaluation metric. In addition, since most MLLMs are trained to perform\nin different languages, a natural question arises: is language a key factor\ninfluencing the cognitive ability of MLLMs? As such, we go beyond English to\nencompass other languages based on their popularity, including Chinese, French,\nSpanish, Portuguese and Korean, to construct our M3GIA. We make sure all the\ndata relevant to the cultural backgrounds are collected from their native\ncontext to avoid English-centric bias. We collected a significant corpus of\ndata from human participants, revealing that the most advanced MLLM reaches the\nlower boundary of human intelligence in English. Yet, there remains a\npronounced disparity in the other five languages assessed. We also reveals an\ninteresting winner takes all phenomenon that are aligned with the discovery in\ncognitive studies. Our benchmark will be open-sourced, with the aspiration of\nfacilitating the enhancement of cognitive capabilities in MLLMs.",
      "tldr_zh": "本文提出 M3GIA，这是一个基于认知科学的 multilingual 和 multimodal 基准，用于评估多模态大语言模型 (MLLMs) 的通用智能能力，基于 Cattell-Horn-Carrol (CHC) 模型识别五个关键认知因素并引入新型评价指标。M3GIA 支持多语言（如中文、法语、西班牙语、葡萄牙语和韩语），通过从本土文化背景收集数据避免英语中心偏差，并发现最先进的 MLLM 在英语中达到人类智能下限，但在其他语言中存在显著差距，同时观察到与认知研究一致的“赢家通吃”现象。该基准将开源，以促进 MLLMs 认知能力的提升。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05343v2",
      "published_date": "2024-06-08 04:07:09 UTC",
      "updated_date": "2024-06-14 08:35:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:52:51.428965"
    },
    {
      "arxiv_id": "2406.05339v3",
      "title": "To what extent can ASV systems naturally defend against spoofing attacks?",
      "title_zh": "ASV 系统在多大程度上能够自然",
      "authors": [
        "Jee-weon Jung",
        "Xin Wang",
        "Nicholas Evans",
        "Shinji Watanabe",
        "Hye-jin Shim",
        "Hemlata Tak",
        "Sidhhant Arora",
        "Junichi Yamagishi",
        "Joon Son Chung"
      ],
      "abstract": "The current automatic speaker verification (ASV) task involves making binary\ndecisions on two types of trials: target and non-target. However, emerging\nadvancements in speech generation technology pose significant threats to the\nreliability of ASV systems. This study investigates whether ASV effortlessly\nacquires robustness against spoofing attacks (i.e., zero-shot capability) by\nsystematically exploring diverse ASV systems and spoofing attacks, ranging from\ntraditional to cutting-edge techniques. Through extensive analyses conducted on\neight distinct ASV systems and 29 spoofing attack systems, we demonstrate that\nthe evolution of ASV inherently incorporates defense mechanisms against\nspoofing attacks. Nevertheless, our findings also underscore that the\nadvancement of spoofing attacks far outpaces that of ASV systems, hence\nnecessitating further research on spoofing-robust ASV methodologies.",
      "tldr_zh": "本研究探讨了自动说话者验证 (ASV) 系统对 spoofing attacks 的自然防御能力（即 zero-shot capability），通过系统性分析八种 ASV 系统和 29 种从传统到前沿的欺骗攻击技术。结果表明，ASV 系统的演化过程已内在地增强了对 spoofing attacks 的防御机制。然而，欺骗攻击技术的进步远超 ASV 系统的发展，因此需要进一步研究 spoofing-robust ASV 方法，以提升其可靠性。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 3 figures, 3 tables, Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05339v3",
      "published_date": "2024-06-08 03:44:39 UTC",
      "updated_date": "2024-11-18 01:46:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:53:02.612924"
    },
    {
      "arxiv_id": "2406.06626v1",
      "title": "Benchmarking Neural Decoding Backbones towards Enhanced On-edge iBCI Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Zhou Zhou",
        "Guohang He",
        "Zheng Zhang",
        "Luziwei Leng",
        "Qinghai Guo",
        "Jianxing Liao",
        "Xuan Song",
        "Ran Cheng"
      ],
      "abstract": "Traditional invasive Brain-Computer Interfaces (iBCIs) typically depend on\nneural decoding processes conducted on workstations within laboratory settings,\nwhich prevents their everyday usage. Implementing these decoding processes on\nedge devices, such as the wearables, introduces considerable challenges related\nto computational demands, processing speed, and maintaining accuracy. This\nstudy seeks to identify an optimal neural decoding backbone that boasts robust\nperformance and swift inference capabilities suitable for edge deployment. We\nexecuted a series of neural decoding experiments involving nonhuman primates\nengaged in random reaching tasks, evaluating four prospective models, Gated\nRecurrent Unit (GRU), Transformer, Receptance Weighted Key Value (RWKV), and\nSelective State Space model (Mamba), across several metrics: single-session\ndecoding, multi-session decoding, new session fine-tuning, inference speed,\ncalibration speed, and scalability. The findings indicate that although the GRU\nmodel delivers sufficient accuracy, the RWKV and Mamba models are preferable\ndue to their superior inference and calibration speeds. Additionally, RWKV and\nMamba comply with the scaling law, demonstrating improved performance with\nlarger data sets and increased model sizes, whereas GRU shows less pronounced\nscalability, and the Transformer model requires computational resources that\nscale prohibitively. This paper presents a thorough comparative analysis of the\nfour models in various scenarios. The results are pivotal in pinpointing an\noptimal backbone that can handle increasing data volumes and is viable for edge\nimplementation. This analysis provides essential insights for ongoing research\nand practical applications in the field.",
      "tldr_zh": "本研究针对侵入性脑机接口 (iBCI) 的神经解码过程在边缘设备（如可穿戴设备）上的挑战，benchmark 了四种模型：Gated Recurrent Unit (GRU)、Transformer、Receptance Weighted Key Value (RWKV) 和 Selective State Space model (Mamba)，以评估其在单会话解码、多会话解码、推理速度、校准速度和可扩展性等方面的性能。实验使用非人灵长类动物进行随机到达任务，结果显示 RWKV 和 Mamba 模型在推理和校准速度上优于 GRU，且符合扩展定律，能更好地处理更大数据集和模型规模，而 Transformer 的资源需求过高。总体而言，此分析为选择适合边缘部署的神经解码骨干模型提供了关键洞见，推动 iBCI 向日常应用发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.06626v1",
      "published_date": "2024-06-08 02:45:36 UTC",
      "updated_date": "2024-06-08 02:45:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:53:16.801163"
    },
    {
      "arxiv_id": "2406.05322v1",
      "title": "Teaching-Assistant-in-the-Loop: Improving Knowledge Distillation from Imperfect Teacher Models in Low-Budget Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhang Zhou",
        "Wei Ai"
      ],
      "abstract": "There is increasing interest in distilling task-specific knowledge from large\nlanguage models (LLM) to smaller student models. Nonetheless, LLM distillation\npresents a dual challenge: 1) there is a high cost associated with querying the\nteacher LLM, such as GPT-4, for gathering an ample number of demonstrations; 2)\nthe teacher LLM might provide imperfect outputs with a negative impact on the\nstudent's learning process. To enhance sample efficiency within\nresource-constrained, imperfect teacher scenarios, we propose a three-component\nframework leveraging three signal types. The first signal is the student's\nself-consistency (consistency of student multiple outputs), which is a proxy of\nthe student's confidence. Specifically, we introduce a ``teaching assistant''\n(TA) model to assess the uncertainty of both the student's and the teacher's\noutputs via confidence scoring, which serves as another two signals for student\ntraining. Furthermore, we propose a two-stage training schema to first warm up\nthe student with a small proportion of data to better utilize student's signal.\nExperiments have shown the superiority of our proposed framework for four\ncomplex reasoning tasks. On average, our proposed two-stage framework brings a\nrelative improvement of up to 20.79% compared to fine-tuning without any\nsignals across datasets.",
      "tldr_zh": "该论文针对从大型语言模型(LLM)如GPT-4到小型学生模型的知识蒸馏过程，解决了查询成本高和教师模型输出不完美的双重挑战。研究提出一个三组件框架，利用学生的自一致性信号（作为自信度代理）和一个教学助理(TA)模型来评估输出不确定性，从而提供额外的训练信号；同时采用两阶段训练方案，先用少量数据预热学生模型以优化信号利用。实验结果显示，在四个复杂推理任务上，该框架相较于无信号微调平均提高了20.79%的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.05322v1",
      "published_date": "2024-06-08 02:17:43 UTC",
      "updated_date": "2024-06-08 02:17:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:53:38.729038"
    },
    {
      "arxiv_id": "2406.05318v1",
      "title": "Integrating Text and Image Pre-training for Multi-modal Algorithmic Reasoning",
      "title_zh": "整合文本和图像预训练用于多模态算法推理",
      "authors": [
        "Zijian Zhang",
        "Wei Liu"
      ],
      "abstract": "In this paper, we present our solution for SMART-101 Challenge of CVPR\nMulti-modal Algorithmic Reasoning Task 2024. Unlike traditional visual\nquestions and answer tasks, this challenge evaluates abstraction, deduction and\ngeneralization ability of neural network in solving visuo-linguistic puzzles\ndesigned for specially children in the 6-8 age group. Our model is based on two\npre-trained models, dedicated to extract features from text and image\nrespectively. To integrate the features from different modalities, we employed\na fusion layer with attention mechanism. We explored different text and image\npre-trained models, and fine-tune the integrated classifier on the SMART-101\ndataset. Experiment results show that under the data splitting style of puzzle\nsplit, our proposed integrated classifier achieves superior performance,\nverifying the effectiveness of multi-modal pre-trained representations.",
      "tldr_zh": "这篇论文提出了一种整合文本和图像预训练模型的解决方案，用于 CVPR 2024 Multi-modal Algorithmic Reasoning Task 中的 SMART-101 挑战。该挑战评估神经网络在解决针对 6-8 岁儿童设计的视语言谜题时的抽象、演绎和泛化能力。模型使用两个预训练模型分别提取文本和图像特征，并通过带有注意力机制的融合层整合这些多模态特征，然后在 SMART-101 数据集上微调分类器。实验结果显示，在 puzzle split 数据分割风格下，该整合分类器表现出色，验证了多模态预训练表示的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05318v1",
      "published_date": "2024-06-08 01:45:06 UTC",
      "updated_date": "2024-06-08 01:45:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:53:38.845704"
    },
    {
      "arxiv_id": "2406.05315v3",
      "title": "Aligned at the Start: Conceptual Groupings in LLM Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Mehrdad Khatir",
        "Sanchit Kabra",
        "Chandan K. Reddy"
      ],
      "abstract": "This paper shifts focus to the often-overlooked input embeddings - the\ninitial representations fed into transformer blocks. Using fuzzy graph,\nk-nearest neighbor (k-NN), and community detection, we analyze embeddings from\ndiverse LLMs, finding significant categorical community structure aligned with\npredefined concepts and categories aligned with humans. We observe these\ngroupings exhibit within-cluster organization (such as hierarchies, topological\nordering, etc.), hypothesizing a fundamental structure that precedes contextual\nprocessing. To further investigate the conceptual nature of these groupings, we\nexplore cross-model alignments across different LLM categories within their\ninput embeddings, observing a medium to high degree of alignment. Furthermore,\nprovide evidence that manipulating these groupings can play a functional role\nin mitigating ethnicity bias in LLM tasks.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLM）输入嵌入的结构，揭示了这些初始表示中存在显著的概念分组，与人类预定义类别对齐。研究采用fuzzy graph、k-nearest neighbor (k-NN) 和 community detection 等方法，分析不同LLM的嵌入，发现这些分组具有内部组织（如层次和拓扑排序），并假设其为先于上下文处理的根本结构。进一步实验显示，不同LLM类别间的嵌入存在中等到高的跨模型对齐，且操纵这些分组可有效缓解LLM任务中的种族偏见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05315v3",
      "published_date": "2024-06-08 01:27:19 UTC",
      "updated_date": "2025-02-24 17:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:53:57.005924"
    },
    {
      "arxiv_id": "2406.05314v1",
      "title": "Relational Proxy Loss for Audio-Text based Keyword Spotting",
      "title_zh": "翻译失败",
      "authors": [
        "Youngmoon Jung",
        "Seungjin Lee",
        "Joon-Young Yang",
        "Jaeyoung Roh",
        "Chang Woo Han",
        "Hoon-Young Cho"
      ],
      "abstract": "In recent years, there has been an increasing focus on user convenience,\nleading to increased interest in text-based keyword enrollment systems for\nkeyword spotting (KWS). Since the system utilizes text input during the\nenrollment phase and audio input during actual usage, we call this task\naudio-text based KWS. To enable this task, both acoustic and text encoders are\ntypically trained using deep metric learning loss functions, such as triplet-\nand proxy-based losses. This study aims to improve existing methods by\nleveraging the structural relations within acoustic embeddings and within text\nembeddings. Unlike previous studies that only compare acoustic and text\nembeddings on a point-to-point basis, our approach focuses on the relational\nstructures within the embedding space by introducing the concept of Relational\nProxy Loss (RPL). By incorporating RPL, we demonstrated improved performance on\nthe Wall Street Journal (WSJ) corpus.",
      "tldr_zh": "本研究针对音频-文本基于的关键字检测 (audio-text based KWS) 任务，提出了一种新的损失函数 Relational Proxy Loss (RPL)，旨在利用声学嵌入和文本嵌入内的结构关系，提高现有深度度量学习方法（如 triplet- and proxy-based losses）的性能。与传统的点对点比较方法不同，RPL 关注嵌入空间的整体关系结构。实验结果显示，在 Wall Street Journal (WSJ) 语料库上，该方法显著提升了关键字检测的准确性。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 2 figures, Accepted by Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.05314v1",
      "published_date": "2024-06-08 01:21:17 UTC",
      "updated_date": "2024-06-08 01:21:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:54:08.026458"
    },
    {
      "arxiv_id": "2406.05307v1",
      "title": "DeviceBERT: Applied Transfer Learning With Targeted Annotations and Vocabulary Enrichment to Identify Medical Device and Component Terminology in FDA Recall Summaries",
      "title_zh": "翻译失败",
      "authors": [
        "Miriam Farrington"
      ],
      "abstract": "FDA Medical Device recalls are critical and time-sensitive events, requiring\nswift identification of impacted devices to inform the public of a recall event\nand ensure patient safety. The OpenFDA device recall dataset contains valuable\ninformation about ongoing device recall actions, but manually extracting\nrelevant device information from the recall action summaries is a\ntime-consuming task. Named Entity Recognition (NER) is a task in Natural\nLanguage Processing (NLP) that involves identifying and categorizing named\nentities in unstructured text. Existing NER models, including domain-specific\nmodels like BioBERT, struggle to correctly identify medical device trade names,\npart numbers and component terms within these summaries. To address this, we\npropose DeviceBERT, a medical device annotation, pre-processing and enrichment\npipeline, which builds on BioBERT to identify and label medical device\nterminology in the device recall summaries with improved accuracy. Furthermore,\nwe demonstrate that our approach can be applied effectively for performing\nentity recognition tasks where training data is limited or sparse.",
      "tldr_zh": "本文提出DeviceBERT，一种基于BioBERT的转移学习方法，通过目标注释和词汇丰富管道，针对FDA医疗设备召回摘要中识别医疗设备贸易名称、部件号和组件术语，从而提高实体识别准确性。DeviceBERT解决了现有NER模型在处理此类任务时的局限性，并通过预处理和词汇增强机制，使其适用于训练数据稀缺的场景。该方法有助于加速召回信息提取，确保患者安全和公共健康。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.05307v1",
      "published_date": "2024-06-08 00:33:22 UTC",
      "updated_date": "2024-06-08 00:33:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T17:54:27.205090"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 53,
  "processed_papers_count": 53,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T17:54:52.832224"
}