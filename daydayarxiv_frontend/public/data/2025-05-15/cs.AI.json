{
  "date": "2025-05-15",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-15 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 132 篇论文，主要聚焦 AI 模型的优化、安全性和应用（如代码生成、机器人操控和医疗诊断），重点包括 LLM 在复杂任务中的增强性能（如 MathCoder-VL 的多模态数学推理 SOTA）和强化学习在动态环境中的进展（如 IceMamba 的海冰预测），以及知名学者如 Junshan Zhang 和 Henk Wymeersch 参与的论文，强调了 AI 代理和多模态系统的潜力。\n\n下面，我将挑选并讨论部分关键论文，先从重要、话题度高的文章入手，如 LLM 和强化学习相关的内容，再简要触及医疗和机器人领域，最后快速掠过次要论文。每个条目列出论文标题（中文 + 英文），并用简洁描述突出主要贡献和发现。\n\n### LLM 和 AI 代理：增强推理与安全\n这些论文探讨了 LLM 在代码生成、决策和安全方面的改进，相关主题紧密，是本日亮点。\n- **J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning**（中文：通过强化学习激励 LLM-as-a-Judge 中的思考）  \n  主要贡献：提出 J1 框架，使用强化学习优化 LLM 的推理过程，显著提升了评判任务的准确性（如在 RewardBench 上提高 9.94 分），并展示了如何通过激励机制减少偏差。\n- **CRPE: Expanding The Reasoning Capability of Large Language Model for Code Generation**（中文：扩展 LLM 在代码生成中的推理能力）  \n  主要贡献：引入三阶段框架提升 LLM 的代码推理能力，生成的 COT-Coder 模型在 LiveCodeBench 上超越 Qwen2.5，pass@1 准确率达 35.08%，证明了通过合成数据增强模型泛化。\n- **Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents**（中文：多步规划和推理提升 LLM 代理的行为）  \n  主要贡献：开发 Pre-Act 方法，使 LLM 代理通过多步计划生成更精确的行动，在 Almita 数据集上提升行动准确率 69.5%，并展示了在对话和任务型代理中的适用性。\n- **Neural Thermodynamic Laws for Large Language Model Training**（中文：LLM 训练的神经热力学定律）  \n  主要贡献：提出 NTL 框架，将热力学原理应用于 LLM 训练，解释了模型规模与损失的关系，并指导学习率调度，提供了更高效的训练策略。\n- **MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning**（中文：连接视觉和代码以提升多模态数学推理）  \n  主要贡献：构建多模态模型 MathCoder-VL，使用代码监督实现图像到代码转换，在 MathVista 上超越 GPT-4o 和 Claude 3.5，在几何问题上提升 9.2%，是 ACL 2025 Findings 接受的亮点。\n- **Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models**（中文：深入理解 LLM 的推理能力）  \n  主要贡献：评估 LLM 在动态任务中的推理局限性，发现 chain-of-thought 方法在数学任务中有效，但在空间协调上不足，强调需超越静态基准。\n\n### 强化学习和机器人：动态决策与控制\n这些论文强调了强化学习在机器人和环境交互中的应用，相关工作有实际影响。\n- **EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation**（中文：统一的 3D 多模态表示用于机器人操控）  \n  主要贡献：提出 EmbodiedMAE 框架，融合 RGB、深度和点云数据，在机器人任务中超越 SOTA 模型，提升 15% 性能，并展示了在模拟和真实环境中的鲁棒性。\n- **FORTRESS: Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning**（中文：通过多模态推理实时防止分布外故障）  \n  主要贡献：开发 FORTRESS 系统，使用多模态推理和规划实时避免机器人故障，在 ANYmal 机器人上提升安全性和规划成功率，是知名学者 Marco Pavone 参与的实用工作。\n- **Offline Reinforcement Learning for Microgrid Voltage Regulation**（中文：微电网电压调控的离线强化学习）  \n  主要贡献：使用离线强化学习算法（如 CQL）在 IEEE 33-bus 系统上实现电压调控，即使在低质量数据上也能有效，减少了在线交互需求。\n- **Long-CL: Task-Core Memory Management and Consolidation for Long-term Continual Learning**（中文：长期持续学习的任务核心内存管理和整合）  \n  主要贡献：提出 Long-CL 框架，通过内存管理和对比学习处理长期任务流，在 FewRel 和 TACRED 数据集上提升 7.4% AP，解决了灾难性遗忘问题。\n\n### 医疗和图像处理：AI 在诊断中的应用\n这些论文聚焦 AI 在医疗中的安全和效率，体现了实际社会价值。\n- **VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety**（中文：提升弱势道路使用者安全的交叉口穿越意图预测）  \n  主要贡献：构建 VRU-CIPI 模型，使用 GRU 和 Transformer 预测行人穿越意图，准确率达 96.45%，并通过 I2V 通信提升交通安全。\n- **PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language**（中文：针对低资源 Pashto 语言的 OCR 多模态模型基准测试）  \n  主要贡献：创建 PsOCR 数据集并评估 LMMs，在 Pashto OCR 上实现 97% 准确率，展示了在低资源语言中的潜力。\n- **AI-enhanced semantic feature norms for 786 concepts**（中文：AI 增强的 786 个概念语义特征规范）  \n  主要贡献：使用 LLM 生成和验证语义特征数据集，提升了认知科学任务的预测性能，知名学者 Jonathan D. Cohen 参与。\n\n### 其他主题：快速掠过\n其余论文涉及量子计算、时间序列预测和特定领域方法，但影响较小，仅简要提及。\n- **IceMamba: Seasonal Forecasting of Pan-Arctic Sea Ice with State Space Model**（中文：使用状态空间模型的泛北极海冰季节预测）  \n  主要贡献：提出 IceMamba 模型，在海冰预测上超越 25 个基准，RMSE 和 ACC 指标最佳。\n- **Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering**（中文：量子计算和 AI：在科学和工程中的高级自动化视角）  \n  主要贡献：讨论量子 CAE 框架在优化中的应用，提供案例分析。\n- 其他如 **GNN-Suite**（用于生物信息学的 GNN 基准框架）、**LibIQ**（实时频谱分类）和 **AdaptCLIP**（通用视觉异常检测）等，均有小幅改进，但非核心话题，仅在特定领域（如图神经网络或频谱分析）有应用价值。\n\n总之，今天的论文突显了 AI 在推理、安全和实际应用中的进展，MathCoder-VL 和 EmbodiedMAE 等工作特别值得关注。AI 社区应继续重视模型泛化和伦理问题，以推动更可靠的技术创新。更多细节可查阅 arXiv。",
  "papers": [
    {
      "arxiv_id": "2505.10749v1",
      "title": "Code-Driven Planning in Grid Worlds with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ashwath Vaithinathan Aravindan",
        "Zhisheng Tang",
        "Mayank Kejriwal"
      ],
      "abstract": "We propose an iterative programmatic planning (IPP) framework for solving\ngrid-based tasks by synthesizing interpretable agent policies expressed in code\nusing large language models (LLMs). Instead of relying on traditional search or\nreinforcement learning, our approach uses code generation as policy synthesis,\nwhere the LLM outputs executable programs that map environment states to action\nsequences. Our proposed architecture incorporates several prompting strategies,\nincluding direct code generation, pseudocode-conditioned refinement, and\ncurriculum-based prompting, but also includes an iterative refinement mechanism\nthat updates code based on task performance feedback. We evaluate our approach\nusing six leading LLMs and two challenging grid-based benchmarks (GRASP and\nMiniGrid). Our IPP framework demonstrates improvements over direct code\ngeneration ranging from 10\\% to as much as 10x across five of the six models\nand establishes a new state-of-the-art result for GRASP. IPP is found to\nsignificantly outperform direct elicitation of a solution from GPT-o3-mini (by\n63\\% on MiniGrid to 116\\% on GRASP), demonstrating the viability of the overall\napproach. Computational costs of all code generation approaches are similar.\nWhile code generation has a higher initial prompting cost compared to direct\nsolution elicitation (\\$0.08 per task vs. \\$0.002 per instance for\nGPT-o3-mini), the code can be reused for any number of instances, making the\namortized cost significantly lower (by 400x on GPT-o3-mini across the complete\nGRASP benchmark).",
      "tldr_zh": "该研究提出了一种迭代程序化规划 (IPP) 框架，使用大型语言模型 (LLMs) 通过代码生成来合成可解释的代理策略，旨在解决网格世界任务，而非依赖传统搜索或强化学习。框架整合了多种提示策略，包括直接代码生成、伪代码条件精炼、基于课程的提示，以及一个基于任务性能反馈的迭代精炼机制。实验在六个领先 LLMs 和两个基准 (GRASP 和 MiniGrid) 上显示，IPP 比直接代码生成提高了 10% 到 10 倍，并为 GRASP 建立了新的最先进结果。总体而言，该方法显著提升了性能，且尽管初始提示成本较高，代码的重用性使摊销成本大幅降低。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10749v1",
      "published_date": "2025-05-15 23:23:31 UTC",
      "updated_date": "2025-05-15 23:23:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:05:46.887863"
    },
    {
      "arxiv_id": "2505.11557v1",
      "title": "AC-LoRA: (Almost) Training-Free Access Control-Aware Multi-Modal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Lara Magdalena Lazier",
        "Aritra Dhar",
        "Vasilije Stambolic",
        "Lukas Cavigelli"
      ],
      "abstract": "Corporate LLMs are gaining traction for efficient knowledge dissemination and\nmanagement within organizations. However, as current LLMs are vulnerable to\nleaking sensitive information, it has proven difficult to apply them in\nsettings where strict access control is necessary. To this end, we design\nAC-LoRA, an end-to-end system for access control-aware corporate LLM chatbots\nthat maintains a strong information isolation guarantee. AC-LoRA maintains\nseparate LoRA adapters for permissioned datasets, along with the document\nembedding they are finetuned on. AC-LoRA retrieves a precise set of LoRA\nadapters based on the similarity score with the user query and their\npermission. This similarity score is later used to merge the responses if more\nthan one LoRA is retrieved, without requiring any additional training for LoRA\nrouting. We provide an end-to-end prototype of AC-LoRA, evaluate it on two\ndatasets, and show that AC-LoRA matches or even exceeds the performance of\nstate-of-the-art LoRA mixing techniques while providing strong isolation\nguarantees. Furthermore, we show that AC-LoRA design can be directly applied to\ndifferent modalities.",
      "tldr_zh": "该论文提出AC-LoRA，一种几乎不需要训练的访问控制感知多模态LLMs系统，旨在解决企业LLMs在严格访问控制场景下的敏感信息泄露问题。AC-LoRA通过维护独立的LoRA adapters和文档嵌入，根据用户查询的相似分数及权限来检索和合并响应，从而实现强信息隔离，而无需额外训练。实验评估显示，AC-LoRA在两个数据集上的性能匹配或超过现有LoRA混合技术，并可直接扩展到不同模态。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11557v1",
      "published_date": "2025-05-15 23:19:35 UTC",
      "updated_date": "2025-05-15 23:19:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:05:57.850119"
    },
    {
      "arxiv_id": "2505.10746v1",
      "title": "ChestyBot: Detecting and Disrupting Chinese Communist Party Influence Stratagems",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Stoffolano",
        "Ayush Rout",
        "Justin M. Pelletier"
      ],
      "abstract": "Foreign information operations conducted by Russian and Chinese actors\nexploit the United States' permissive information environment. These campaigns\nthreaten democratic institutions and the broader Westphalian model. Yet,\nexisting detection and mitigation strategies often fail to identify active\ninformation campaigns in real time. This paper introduces ChestyBot, a\npragmatics-based language model that detects unlabeled foreign malign influence\ntweets with up to 98.34% accuracy. The model supports a novel framework to\ndisrupt foreign influence operations in their formative stages.",
      "tldr_zh": "本文研究了俄罗斯和中国等外国演员的信息操作如何利用美国的宽松环境，威胁民主机构和国际秩序。论文引入ChestyBot，一种基于语用学的语言模型，能够以高达98.34%的准确率检测未标记的外国恶意影响推文。ChestyBot 支持一个创新框架，用于在这些影响操作的早期阶段进行中断，从而提升实时检测和缓解策略的效能。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR",
        "cs.SI"
      ],
      "primary_category": "cs.CY",
      "comment": "Presented at USCYBERCOM Cyber Recon Symposium 2023 at DreamPort in\n  Columbia, MD on April 20, 2023",
      "pdf_url": "http://arxiv.org/pdf/2505.10746v1",
      "published_date": "2025-05-15 23:12:20 UTC",
      "updated_date": "2025-05-15 23:12:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:06:08.950204"
    },
    {
      "arxiv_id": "2505.10742v1",
      "title": "Evaluations at Work: Measuring the Capabilities of GenAI in Use",
      "title_zh": "工作中的评估：测量 GenAI 在使用中的能力",
      "authors": [
        "Brandon Lepine",
        "Gawesha Weerantunga",
        "Juho Kim",
        "Pamela Mishkin",
        "Matthew Beane"
      ],
      "abstract": "Current AI benchmarks miss the messy, multi-turn nature of human-AI\ncollaboration. We present an evaluation framework that decomposes real-world\ntasks into interdependent subtasks, letting us track both LLM performance and\nusers' strategies across a dialogue. Complementing this framework, we develop a\nsuite of metrics, including a composite usage derived from semantic similarity,\nword overlap, and numerical matches; structural coherence; intra-turn\ndiversity; and a novel measure of the \"information frontier\" reflecting the\nalignment between AI outputs and users' working knowledge. We demonstrate our\nmethodology in a financial valuation task that mirrors real-world complexity.\nOur empirical findings reveal that while greater integration of LLM-generated\ncontent generally enhances output quality, its benefits are moderated by\nfactors such as response incoherence, excessive subtask diversity, and the\ndistance of provided information from users' existing knowledge. These results\nsuggest that proactive dialogue strategies designed to inject novelty may\ninadvertently undermine task performance. Our work thus advances a more\nholistic evaluation of human-AI collaboration, offering both a robust\nmethodological framework and actionable insights for developing more effective\nAI-augmented work processes.",
      "tldr_zh": "本文提出一个评估框架，将真实世界任务分解为相互依赖的子任务，以更全面地评估生成式 AI (GenAI) 在人类-AI 协作中的能力，包括跟踪 LLM 性能和用户策略。框架结合多种指标，如基于语义相似性、词重叠和数字匹配的复合使用度、结构一致性、内部轮次多样性，以及新颖的“information frontier” measure，来量化 AI 输出与用户知识的 alignment。在一个模拟复杂性的财务估值任务中，实验结果显示，整合 LLM 生成内容通常提升输出质量，但响应不连贯、过度子任务多样性和信息距离用户现有知识等因素可能削弱效果，从而为设计更有效的 AI 增强工作流程提供行动性见解。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10742v1",
      "published_date": "2025-05-15 23:06:23 UTC",
      "updated_date": "2025-05-15 23:06:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:06:22.275816"
    },
    {
      "arxiv_id": "2505.10732v1",
      "title": "Automating Security Audit Using Large Language Model based Agent: An Exploration Experiment",
      "title_zh": "使用基于大型语言模型的代理自动进行安全审计：一个探索性实验",
      "authors": [
        "Jia Hui Chin",
        "Pu Zhang",
        "Yu Xin Cheong",
        "Jonathan Pan"
      ],
      "abstract": "In the current rapidly changing digital environment, businesses are under\nconstant stress to ensure that their systems are secured. Security audits help\nto maintain a strong security posture by ensuring that policies are in place,\ncontrols are implemented, gaps are identified for cybersecurity risks\nmitigation. However, audits are usually manual, requiring much time and costs.\nThis paper looks at the possibility of developing a framework to leverage Large\nLanguage Models (LLMs) as an autonomous agent to execute part of the security\naudit, namely with the field audit. password policy compliance for Windows\noperating system. Through the conduct of an exploration experiment of using\nGPT-4 with Langchain, the agent executed the audit tasks by accurately flagging\npassword policy violations and appeared to be more efficient than traditional\nmanual audits. Despite its potential limitations in operational consistency in\ncomplex and dynamic environment, the framework suggests possibilities to extend\nfurther to real-time threat monitoring and compliance checks.",
      "tldr_zh": "该研究提出了一种框架，利用 Large Language Models (LLMs) 作为自治代理来自动化安全审计，特别针对 Windows 操作系统的密码策略合规性，以减少手动审计的成本和时间。实验通过 GPT-4 和 Langchain 构建代理，成功准确标记密码政策违规，并显示出比传统方法更高的效率。尽管在复杂动态环境中可能存在操作一致性的局限性，该框架展示了扩展到实时威胁监控和合规检查的潜力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10732v1",
      "published_date": "2025-05-15 22:22:52 UTC",
      "updated_date": "2025-05-15 22:22:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:06:32.955121"
    },
    {
      "arxiv_id": "2505.10726v1",
      "title": "Learning Repetition-Invariant Representations for Polymer Informatics",
      "title_zh": "学习聚合物信息学的重复不变表示",
      "authors": [
        "Yihan Zhu",
        "Gang Liu",
        "Eric Inae",
        "Tengfei Luo",
        "Meng Jiang"
      ],
      "abstract": "Polymers are large macromolecules composed of repeating structural units\nknown as monomers and are widely applied in fields such as energy storage,\nconstruction, medicine, and aerospace. However, existing graph neural network\nmethods, though effective for small molecules, only model the single unit of\npolymers and fail to produce consistent vector representations for the true\npolymer structure with varying numbers of units. To address this challenge, we\nintroduce Graph Repetition Invariance (GRIN), a novel method to learn polymer\nrepresentations that are invariant to the number of repeating units in their\ngraph representations. GRIN integrates a graph-based maximum spanning tree\nalignment with repeat-unit augmentation to ensure structural consistency. We\nprovide theoretical guarantees for repetition-invariance from both model and\ndata perspectives, demonstrating that three repeating units are the minimal\naugmentation required for optimal invariant representation learning. GRIN\noutperforms state-of-the-art baselines on both homopolymer and copolymer\nbenchmarks, learning stable, repetition-invariant representations that\ngeneralize effectively to polymer chains of unseen sizes.",
      "tldr_zh": "这篇论文针对聚合物信息学（Polymer Informatics）提出了一种新方法 Graph Repetition Invariance (GRIN)，旨在学习对重复单位数量不变的聚合物表示，以解决现有 Graph Neural Network 方法仅建模单个单位而无法生成一致向量的挑战。GRIN 通过整合基于图的最大生成树对齐（graph-based maximum spanning tree alignment）和重复单位增强（repeat-unit augmentation）来确保结构一致性，并从模型和数据角度提供了理论保证，证明三个重复单位是最小增强要求。在同聚物（homopolymer）和共聚物（copolymer）基准测试中，GRIN 超过了最先进基线，实现了稳定、可泛化的聚合物表示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages,3 figuares",
      "pdf_url": "http://arxiv.org/pdf/2505.10726v1",
      "published_date": "2025-05-15 22:05:40 UTC",
      "updated_date": "2025-05-15 22:05:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:06:46.600235"
    },
    {
      "arxiv_id": "2505.10718v1",
      "title": "AI-enhanced semantic feature norms for 786 concepts",
      "title_zh": "翻译失败",
      "authors": [
        "Siddharth Suresh",
        "Kushin Mukherjee",
        "Tyler Giallanza",
        "Xizheng Yu",
        "Mia Patil",
        "Jonathan D. Cohen",
        "Timothy T. Rogers"
      ],
      "abstract": "Semantic feature norms have been foundational in the study of human\nconceptual knowledge, yet traditional methods face trade-offs between\nconcept/feature coverage and verifiability of quality due to the\nlabor-intensive nature of norming studies. Here, we introduce a novel approach\nthat augments a dataset of human-generated feature norms with responses from\nlarge language models (LLMs) while verifying the quality of norms against\nreliable human judgments. We find that our AI-enhanced feature norm dataset,\nNOVA: Norms Optimized Via AI, shows much higher feature density and overlap\namong concepts while outperforming a comparable human-only norm dataset and\nword-embedding models in predicting people's semantic similarity judgments.\nTaken together, we demonstrate that human conceptual knowledge is richer than\ncaptured in previous norm datasets and show that, with proper validation, LLMs\ncan serve as powerful tools for cognitive science research.",
      "tldr_zh": "本文提出了一种新方法，使用大型语言模型(LLMs)增强人类生成的数据集，创建了NOVA数据集，以解决传统语义特征规范在概念/特征覆盖度和质量可验证性上的权衡问题。研究通过与可靠人类判断进行验证，发现NOVA数据集具有更高的特征密度和概念重叠，并在预测语义相似性判断上优于纯人类数据集和word-embedding模型。总体而言，这证明了人类概念知识比以往数据集更丰富，并展示了LLMs经适当验证后可作为认知科学研究的强大工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10718v1",
      "published_date": "2025-05-15 21:43:34 UTC",
      "updated_date": "2025-05-15 21:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:06:57.506801"
    },
    {
      "arxiv_id": "2505.10717v2",
      "title": "A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Jean-Philippe Corbeil",
        "Amin Dada",
        "Jean-Michel Attendu",
        "Asma Ben Abacha",
        "Alessandro Sordoni",
        "Lucas Caccia",
        "François Beaulieu",
        "Thomas Lin",
        "Jens Kleesiek",
        "Paul Vozila"
      ],
      "abstract": "High computation costs and latency of large language models such as GPT-4\nhave limited their deployment in clinical settings. Small language models\n(SLMs) offer a cost-effective alternative, but their limited capacity requires\nbiomedical domain adaptation, which remains challenging. An additional\nbottleneck is the unavailability and high sensitivity of clinical data. To\naddress these challenges, we propose a novel framework for adapting SLMs into\nhigh-performing clinical models. We introduce the MediPhi collection of\n3.8B-parameter SLMs developed with our novel framework: pre-instruction tuning\nof experts on relevant medical and clinical corpora (PMC, Medical Guideline,\nMedWiki, etc.), model merging, and clinical-tasks alignment. To cover most\nclinical tasks, we extended the CLUE benchmark to CLUE+, doubling its size. Our\nexpert models deliver relative improvements on this benchmark over the base\nmodel without any task-specific fine-tuning: 64.3% on medical entities, 49.5%\non radiology reports, and 44% on ICD-10 coding (outperforming GPT-4-0125 by\n14%). We unify the expert models into MediPhi via model merging, preserving\ngains across benchmarks. Furthermore, we built the MediFlow collection, a\nsynthetic dataset of 2.5 million high-quality instructions on 14 medical NLP\ntasks, 98 fine-grained document types, and JSON format support. Alignment of\nMediPhi using supervised fine-tuning and direct preference optimization\nachieves further gains of 18.9% on average.",
      "tldr_zh": "该研究提出了一种模块化框架，用于通过合成数据适应小型语言模型（SLMs）以应用于临床场景，解决大语言模型如 GPT-4 的高计算成本和延迟问题。框架包括预指令调优（pre-instruction tuning）在相关医疗语料（如 PMC 和 Medical Guideline）上训练专家模型、模型合并（model merging）和临床任务对齐（clinical-tasks alignment）。他们扩展了 CLUE 基准为 CLUE+，并开发了 MediPhi 集合的 3.8B 参数 SLMs，在 CLUE+ 上实现显著提升，包括医疗实体 64.3%、放射学报告 49.5% 和 ICD-10 编码 44%（超过 GPT-4-0125 14%）。此外，构建了 MediFlow 合成数据集（250 万条指令，覆盖 14 个医疗 NLP 任务和 98 种文档类型），通过监督微调和直接偏好优化进一步提升 MediPhi 的性能，平均获得 18.9% 的改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10717v2",
      "published_date": "2025-05-15 21:40:21 UTC",
      "updated_date": "2025-05-21 17:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:07:12.266358"
    },
    {
      "arxiv_id": "2505.10711v1",
      "title": "GNN-Suite: a Graph Neural Network Benchmarking Framework for Biomedical Informatics",
      "title_zh": "GNN-Suite：用于生物医学信息学的图神经网络基准测试",
      "authors": [
        "Sebestyén Kamp",
        "Giovanni Stracquadanio",
        "T. Ian Simpson"
      ],
      "abstract": "We present GNN-Suite, a robust modular framework for constructing and\nbenchmarking Graph Neural Network (GNN) architectures in computational biology.\nGNN-Suite standardises experimentation and reproducibility using the Nextflow\nworkflow to evaluate GNN performance. We demonstrate its utility in identifying\ncancer-driver genes by constructing molecular networks from protein-protein\ninteraction (PPI) data from STRING and BioGRID and annotating nodes with\nfeatures from the PCAWG, PID, and COSMIC-CGC repositories.\n  Our design enables fair comparisons among diverse GNN architectures including\nGAT, GAT3H, GCN, GCN2, GIN, GTN, HGCN, PHGCN, and GraphSAGE and a baseline\nLogistic Regression (LR) model. All GNNs were configured as standardised\ntwo-layer models and trained with uniform hyperparameters (dropout = 0.2; Adam\noptimiser with learning rate = 0.01; and an adjusted binary cross-entropy loss\nto address class imbalance) over an 80/20 train-test split for 300 epochs. Each\nmodel was evaluated over 10 independent runs with different random seeds to\nyield statistically robust performance metrics, with balanced accuracy (BACC)\nas the primary measure. Notably, GCN2 achieved the highest BACC (0.807 +/-\n0.035) on a STRING-based network, although all GNN types outperformed the LR\nbaseline, highlighting the advantage of network-based learning over\nfeature-only approaches.\n  Our results show that a common framework for implementing and evaluating GNN\narchitectures aids in identifying not only the best model but also the most\neffective means of incorporating complementary data. By making GNN-Suite\npublicly available, we aim to foster reproducible research and promote improved\nbenchmarking standards in computational biology. Future work will explore\nadditional omics datasets and further refine network architectures to enhance\npredictive accuracy and interpretability in biomedical applications.",
      "tldr_zh": "该论文介绍了 GNN-Suite，一个模块化框架，用于在计算生物学中构建和基准测试 Graph Neural Network (GNN) 架构，以标准化实验和提升可重复性。该框架利用 Nextflow 工作流，通过从 STRING 和 BioGRID 的蛋白质-蛋白质相互作用 (PPI) 数据构建分子网络，并结合 PCAWG、PID 和 COSMIC-CGC 的节点特征，应用于识别癌症驱动基因。实验中，多种 GNN 模型（如 GAT、GCN2 和 GraphSAGE）以统一超参数（如 dropout=0.2 和 Adam 优化器）进行两层训练，结果显示 GCN2 取得了最高的平衡准确率 (BACC) 0.807 ± 0.035，并整体优于基线 Logistic Regression (LR) 模型，突显了网络-based 学习的优势。通过公开 GNN-Suite，论文旨在促进生物医学领域的可重复研究和基准标准改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "J.3; I.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "Main article 8 pages (20 in total with supplementary information\n  included), 3 main article figures and 3 supplemental figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10711v1",
      "published_date": "2025-05-15 21:14:30 UTC",
      "updated_date": "2025-05-15 21:14:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:07:24.865998"
    },
    {
      "arxiv_id": "2505.10705v1",
      "title": "Embodied AI in Machine Learning -- is it Really Embodied?",
      "title_zh": "翻译失败",
      "authors": [
        "Matej Hoffmann",
        "Shubhan Parag Patni"
      ],
      "abstract": "Embodied Artificial Intelligence (Embodied AI) is gaining momentum in the\nmachine learning communities with the goal of leveraging current progress in AI\n(deep learning, transformers, large language and visual-language models) to\nempower robots. In this chapter we put this work in the context of \"Good\nOld-Fashioned Artificial Intelligence\" (GOFAI) (Haugeland, 1989) and the\nbehavior-based or embodied alternatives (R. A. Brooks 1991; Pfeifer and Scheier\n2001). We claim that the AI-powered robots are only weakly embodied and inherit\nsome of the problems of GOFAI. Moreover, we review and critically discuss the\npossibility of cross-embodiment learning (Padalkar et al. 2024). We identify\nfundamental roadblocks and propose directions on how to make progress.",
      "tldr_zh": "本论文探讨了Embodied AI在机器学习中的应用，质疑其是否真正实现了“体化”，并将当前基于深度学习、Transformer和大型语言/视觉语言模型的机器人技术置于GOFAI（Good Old-Fashioned Artificial Intelligence）和行为-based Embodied AI的背景下。作者认为，这些AI驱动机器人仅是weakly embodied，继承了GOFAI的固有问题，如脱离真实物理交互的局限性。论文还审视并批判性地讨论了cross-embodiment learning的可能性，识别出关键障碍。最终，作者提出未来方向，以推动Embodied AI向更真实体化的发展。",
      "categories": [
        "cs.AI",
        "cs.NE",
        "cs.RO",
        "68T40",
        "I.2.9"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10705v1",
      "published_date": "2025-05-15 20:52:49 UTC",
      "updated_date": "2025-05-15 20:52:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:07:34.097115"
    },
    {
      "arxiv_id": "2505.10695v1",
      "title": "Predicting Human Behavior in Autonomous Systems: A Collaborative Machine Teaching Approach for Reducing Transfer of Control Events",
      "title_zh": "在自主系统中预测人类行为：一种协作机器教学方法用于",
      "authors": [
        "Julian Wolter",
        "Amr Gomaa"
      ],
      "abstract": "As autonomous systems become integral to various industries, effective\nstrategies for fault handling are essential to ensure reliability and\nefficiency. Transfer of Control (ToC), a traditional approach for interrupting\nautomated processes during faults, is often triggered unnecessarily in\nnon-critical situations. To address this, we propose a data-driven method that\nuses human interaction data to train AI models capable of preemptively\nidentifying and addressing issues or assisting users in resolution. Using an\ninteractive tool simulating an industrial vacuum cleaner, we collected data and\ndeveloped an LSTM-based model to predict user behavior. Our findings reveal\nthat even data from non-experts can effectively train models to reduce\nunnecessary ToC events, enhancing the system's robustness. This approach\nhighlights the potential of AI to learn directly from human problem-solving\nbehaviors, complementing sensor data to improve industrial automation and\nhuman-AI collaboration.",
      "tldr_zh": "该论文提出了一种协作机器教学方法，用于预测人类行为并减少自主系统中的Transfer of Control (ToC) 事件，从而提升系统可靠性和效率。该方法利用人类交互数据训练AI模型，例如基于LSTM的模型，来预先识别问题并协助用户解决问题；在模拟工业真空清洁器的实验中，即使使用非专家数据，也能有效降低不必要的ToC事件，提高系统鲁棒性。该研究强调AI从人类问题解决行为中学习，补充传感器数据，促进工业自动化和human-AI collaboration的优化。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10695v1",
      "published_date": "2025-05-15 20:34:29 UTC",
      "updated_date": "2025-05-15 20:34:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:07:47.356115"
    },
    {
      "arxiv_id": "2505.10691v1",
      "title": "Predicting Risk of Pulmonary Fibrosis Formation in PASC Patients",
      "title_zh": "预测 PASC 患者肺纤维化形成的风险",
      "authors": [
        "Wanying Dou",
        "Gorkem Durak",
        "Koushik Biswas",
        "Ziliang Hong",
        "Andrea Mia Bejar",
        "Elif Keles",
        "Kaan Akin",
        "Sukru Mehmet Erturk",
        "Alpay Medetalibeyoglu",
        "Marc Sala",
        "Alexander Misharin",
        "Hatice Savas",
        "Mary Salvatore",
        "Sachin Jambawalikar",
        "Drew Torigian",
        "Jayaram K. Udupa",
        "Ulas Bagci"
      ],
      "abstract": "While the acute phase of the COVID-19 pandemic has subsided, its long-term\neffects persist through Post-Acute Sequelae of COVID-19 (PASC), commonly known\nas Long COVID. There remains substantial uncertainty regarding both its\nduration and optimal management strategies. PASC manifests as a diverse array\nof persistent or newly emerging symptoms--ranging from fatigue, dyspnea, and\nneurologic impairments (e.g., brain fog), to cardiovascular, pulmonary, and\nmusculoskeletal abnormalities--that extend beyond the acute infection phase.\nThis heterogeneous presentation poses substantial challenges for clinical\nassessment, diagnosis, and treatment planning. In this paper, we focus on\nimaging findings that may suggest fibrotic damage in the lungs, a critical\nmanifestation characterized by scarring of lung tissue, which can potentially\naffect long-term respiratory function in patients with PASC. This study\nintroduces a novel multi-center chest CT analysis framework that combines deep\nlearning and radiomics for fibrosis prediction. Our approach leverages\nconvolutional neural networks (CNNs) and interpretable feature extraction,\nachieving 82.2% accuracy and 85.5% AUC in classification tasks. We demonstrate\nthe effectiveness of Grad-CAM visualization and radiomics-based feature\nanalysis in providing clinically relevant insights for PASC-related lung\nfibrosis prediction. Our findings highlight the potential of deep\nlearning-driven computational methods for early detection and risk assessment\nof PASC-related lung fibrosis--presented for the first time in the literature.",
      "tldr_zh": "这篇论文针对 PASC（Post-Acute Sequelae of COVID-19，或 Long COVID）患者预测肺纤维化形成的风险，聚焦于肺组织疤痕可能导致的长期呼吸功能问题。研究引入了一种新型多中心胸部 CT 分析框架，结合深度学习（CNNs）和放射组学（radiomics）进行预测，实现了82.2%的准确率和85.5%的 AUC。利用 Grad-CAM 视觉化和放射组学特征分析，该方法提供了临床相关的洞见，并首次在文献中展示深度学习驱动的早期检测和风险评估潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10691v1",
      "published_date": "2025-05-15 20:30:21 UTC",
      "updated_date": "2025-05-15 20:30:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:07:59.861865"
    },
    {
      "arxiv_id": "2505.13497v1",
      "title": "LODGE: Joint Hierarchical Task Planning and Learning of Domain Models with Grounded Execution",
      "title_zh": "翻译失败",
      "authors": [
        "Claudius Kienle",
        "Benjamin Alt",
        "Oleg Arenz",
        "Jan Peters"
      ],
      "abstract": "Large Language Models (LLMs) enable planning from natural language\ninstructions using implicit world knowledge, but often produce flawed plans\nthat require refinement. Instead of directly predicting plans, recent methods\naim to learn a problem domain that can be solved for different goal states\nusing classical planners. However, these approaches require significant human\nfeedback to obtain useful models. We address this shortcoming by learning\nhierarchical domains, where low-level predicates and actions are composed into\nhigher-level counterparts, and by leveraging simulation to validate their\npreconditions and effects. This hierarchical approach is particularly powerful\nfor long-horizon planning, where LLM-based planning approaches typically\nstruggle. Furthermore, we introduce a central error reasoner to ensure\nconsistency among the different planning levels. Evaluation on two challenging\nInternational Planning Competition (IPC) domains and a long-horizon robot\nmanipulation task demonstrates higher planning success rates than\nstate-of-the-art domain synthesis and LLM-modulo planning methods, while\nconstructing high-quality models of the domain. Resources, videos and detailed\nexperiment results are available at https://claudius-kienle.github.io/lodge/.",
      "tldr_zh": "本文提出 LODGE 框架，通过联合分层任务规划和域模型学习，解决 Large Language Models (LLMs) 在从自然语言指令中生成计划时的缺陷问题。该框架学习 hierarchical domains，将低级谓词和动作组成高级对应物，并利用模拟验证其先决条件和效果，同时引入中央错误推理器确保不同规划级别的一致性。这种方法特别适用于长 horizons 规划任务。在两个 International Planning Competition (IPC) 领域和一个长 horizons 机器人操作任务的评估中，LODGE 比现有领域合成和 LLM-modulo 规划方法实现了更高的规划成功率，并构建了高质量的域模型。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13497v1",
      "published_date": "2025-05-15 20:23:21 UTC",
      "updated_date": "2025-05-15 20:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:08:10.912324"
    },
    {
      "arxiv_id": "2505.10681v1",
      "title": "Towards an LLM-powered Social Digital Twinning Platform",
      "title_zh": "迈向基于LLM的社会数字孪生平台",
      "authors": [
        "Önder Gürcan",
        "Vanja Falck",
        "Markus G. Rousseau",
        "Larissa L. Lima"
      ],
      "abstract": "We present Social Digital Twinner, an innovative social simulation tool for\nexploring plausible effects of what-if scenarios in complex adaptive social\nsystems. The architecture is composed of three seamlessly integrated parts: a\ndata infrastructure featuring real-world data and a multi-dimensionally\nrepresentative synthetic population of citizens, an LLM-enabled agent-based\nsimulation engine, and a user interface that enable intuitive, natural language\ninteractions with the simulation engine and the artificial agents (i.e.\ncitizens). Social Digital Twinner facilitates real-time engagement and empowers\nstakeholders to collaboratively design, test, and refine intervention measures.\nThe approach is promoting a data-driven and evidence-based approach to societal\nproblem-solving. We demonstrate the tool's interactive capabilities by\naddressing the critical issue of youth school dropouts in Kragero, Norway,\nshowcasing its ability to create and execute a dedicated social digital twin\nusing natural language.",
      "tldr_zh": "本文提出 Social Digital Twinner，一种基于 LLM 的社会数字孪生平台，用于模拟复杂适应性社会系统中的假设场景影响。该平台由数据基础设施（整合真实数据和合成人口）、LLM-enabled agent-based simulation engine 和自然语言用户界面三部分组成，支持实时互动和协作设计干预措施。研究通过挪威 Kragero 青年辍学案例展示了该工具的实际应用能力，促进数据驱动的社会问题解决。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "13 pages, 3 figures, 23rd International Conference on Practical\n  applications of Agents and Multi-Agent Systems (PAAMS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.10681v1",
      "published_date": "2025-05-15 19:58:50 UTC",
      "updated_date": "2025-05-15 19:58:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:08:22.526921"
    },
    {
      "arxiv_id": "2505.10677v1",
      "title": "A Conformal Predictive Measure for Assessing Catastrophic Forgetting",
      "title_zh": "翻译失败",
      "authors": [
        "Ioannis Pitsiorlas",
        "Nour Jamoussi",
        "Marios Kountouris"
      ],
      "abstract": "This work introduces a novel methodology for assessing catastrophic\nforgetting (CF) in continual learning. We propose a new conformal prediction\n(CP)-based metric, termed the Conformal Prediction Confidence Factor (CPCF), to\nquantify and evaluate CF effectively. Our framework leverages adaptive CP to\nestimate forgetting by monitoring the model's confidence on previously learned\ntasks. This approach provides a dynamic and practical solution for monitoring\nand measuring CF of previous tasks as new ones are introduced, offering greater\nsuitability for real-world applications. Experimental results on four benchmark\ndatasets demonstrate a strong correlation between CPCF and the accuracy of\nprevious tasks, validating the reliability and interpretability of the proposed\nmetric. Our results highlight the potential of CPCF as a robust and effective\ntool for assessing and understanding CF in dynamic learning environments.",
      "tldr_zh": "本研究提出了一种基于 Conformal Prediction (CP) 的新指标 Conformal Prediction Confidence Factor (CPCF)，用于有效量化评估持续学习中的 Catastrophic Forgetting (CF)。该方法利用自适应 CP 监控模型在先前任务上的置信度变化，提供动态且适用于真实世界场景的遗忘评估框架。实验结果显示，在四个基准数据集上，CPCF 与先前任务的准确率存在强相关性，验证了其可靠性和可解释性，并突显其作为评估动态学习环境 CF 的强大工具的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10677v1",
      "published_date": "2025-05-15 19:42:17 UTC",
      "updated_date": "2025-05-15 19:42:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:08:34.046621"
    },
    {
      "arxiv_id": "2505.11556v1",
      "title": "Assessing Collective Reasoning in Multi-Agent LLMs via Hidden Profile Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Li",
        "Aoi Naito",
        "Hirokazu Shirado"
      ],
      "abstract": "Multi-agent systems built on large language models (LLMs) promise enhanced\nproblem-solving through distributed information integration, but also risk\nreplicating collective reasoning failures observed in human groups. Yet, no\ntheory-grounded benchmark exists to systematically evaluate such failures. In\nthis paper, we introduce the Hidden Profile paradigm from social psychology as\na diagnostic testbed for multi-agent LLM systems. By distributing critical\ninformation asymmetrically across agents, the paradigm reveals how inter-agent\ndynamics support or hinder collective reasoning. We first formalize the\nparadigm for multi-agent decision-making under distributed knowledge and\ninstantiate it as a benchmark with nine tasks spanning diverse scenarios,\nincluding adaptations from prior human studies. We then conduct experiments\nwith GPT-4.1 and five other leading LLMs, including reasoning-enhanced\nvariants, showing that multi-agent systems across all models fail to match the\naccuracy of single agents given complete information. While agents' collective\nperformance is broadly comparable to that of human groups, nuanced behavioral\ndifferences emerge, such as increased sensitivity to social desirability.\nFinally, we demonstrate the paradigm's diagnostic utility by exploring a\ncooperation-contradiction trade-off in multi-agent LLM systems. We find that\nwhile cooperative agents are prone to over-coordination in collective settings,\nincreased contradiction impairs group convergence. This work contributes a\nreproducible framework for evaluating multi-agent LLM systems and motivates\nfuture research on artificial collective intelligence and human-AI interaction.",
      "tldr_zh": "本研究引入 Hidden Profile 范式（来自社会心理学），作为评估多智能体 LLM 系统集体推理能力的基准，通过不对称分配信息来揭示代理间动态对决策的影响。论文形式化了这一范式，并创建了九个任务场景，实验使用 GPT-4.1 和其他 LLM 模型，结果显示多智能体系统在分布式知识下不如单一代理准确，且虽与人类群体表现类似，但表现出更高的社会可取性敏感性。最终，研究探讨了合作与矛盾的权衡，发现合作易导致过度协调，而增加矛盾会阻碍群体收敛，为未来多智能体 LLM 的集体智能和人机交互研究提供了可重现框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11556v1",
      "published_date": "2025-05-15 19:22:54 UTC",
      "updated_date": "2025-05-15 19:22:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:08:48.181391"
    },
    {
      "arxiv_id": "2505.10670v1",
      "title": "Interpretable Risk Mitigation in LLM Agent Systems",
      "title_zh": "LLM 代理系统中的可解释风险缓解",
      "authors": [
        "Jan Chojnacki"
      ],
      "abstract": "Autonomous agents powered by large language models (LLMs) enable novel use\ncases in domains where responsible action is increasingly important. Yet the\ninherent unpredictability of LLMs raises safety concerns about agent\nreliability. In this work, we explore agent behaviour in a toy, game-theoretic\nenvironment based on a variation of the Iterated Prisoner's Dilemma. We\nintroduce a strategy-modification method-independent of both the game and the\nprompt-by steering the residual stream with interpretable features extracted\nfrom a sparse autoencoder latent space. Steering with the good-faith\nnegotiation feature lowers the average defection probability by 28 percentage\npoints. We also identify feasible steering ranges for several open-source LLM\nagents. Finally, we hypothesise that game-theoretic evaluation of LLM agents,\ncombined with representation-steering alignment, can generalise to real-world\napplications on end-user devices and embodied platforms.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)驱动的自主代理在高责任领域中的安全问题，特别是在其不可预测性导致的风险上。研究者引入了一种独立于游戏和提示的策略修改方法，通过从稀疏自编码器(sparse autoencoder)潜空间提取的可解释特征来引导residual stream，例如使用good-faith negotiation特征，将平均背叛概率降低了28个百分点。在基于Iterated Prisoner's Dilemma的游戏环境中，实验识别了多个开源LLM代理的可行引导范围，并假设这种结合游戏理论评估和representation-steering alignment的方法可推广到真实世界的终端设备和实体平台应用。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10670v1",
      "published_date": "2025-05-15 19:22:11 UTC",
      "updated_date": "2025-05-15 19:22:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:08:59.219335"
    },
    {
      "arxiv_id": "2505.10665v1",
      "title": "Seasonal Forecasting of Pan-Arctic Sea Ice with State Space Model",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Wang",
        "Weidong Yang",
        "Lei Wang",
        "Guihua Wang",
        "Ruibo Lei"
      ],
      "abstract": "The rapid decline of Arctic sea ice resulting from anthropogenic climate\nchange poses significant risks to indigenous communities, ecosystems, and the\nglobal climate system. This situation emphasizes the immediate necessity for\nprecise seasonal sea ice forecasts. While dynamical models perform well for\nshort-term forecasts, they encounter limitations in long-term forecasts and are\ncomputationally intensive. Deep learning models, while more computationally\nefficient, often have difficulty managing seasonal variations and uncertainties\nwhen dealing with complex sea ice dynamics. In this research, we introduce\nIceMamba, a deep learning architecture that integrates sophisticated attention\nmechanisms within the state space model. Through comparative analysis of 25\nrenowned forecast models, including dynamical, statistical, and deep learning\napproaches, our experimental results indicate that IceMamba delivers excellent\nseasonal forecasting capabilities for Pan-Arctic sea ice concentration.\nSpecifically, IceMamba outperforms all tested models regarding average RMSE and\nanomaly correlation coefficient (ACC) and ranks second in Integrated Ice Edge\nError (IIEE). This innovative approach enhances our ability to foresee and\nalleviate the effects of sea ice variability, offering essential insights for\nstrategies aimed at climate adaptation.",
      "tldr_zh": "该研究针对北极海冰快速减少对社区和全球气候的影响，提出了一种名为 IceMamba 的深度学习架构，该架构整合了状态空间模型中的高级注意力机制，以更好地处理季节变化和不确定性问题。相比动态模型的计算密集和深度学习模型的局限，IceMamba 通过实验与25个知名模型（包括动态、统计和深度学习方法）进行比较，在平均 RMSE 和异常相关系数 (ACC) 上表现出最佳性能，并在 Integrated Ice Edge Error (IIEE) 上排名第二。这种创新方法增强了 Pan-Arctic 海冰浓度的季节性预测能力，为气候适应策略提供重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is published in npj Climate and Atmospheric Science:\n  https://www.nature.com/articles/s41612-025-01058-0#Sec16 Supplementary\n  information:\n  https://static-content.springer.com/esm/art%3A10.1038%2Fs41612-025-01058-0/MediaObjects/41612_2025_1058_MOESM1_ESM.pdf",
      "pdf_url": "http://arxiv.org/pdf/2505.10665v1",
      "published_date": "2025-05-15 19:15:00 UTC",
      "updated_date": "2025-05-15 19:15:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:09:12.368780"
    },
    {
      "arxiv_id": "2505.10664v1",
      "title": "CLIP Embeddings for AI-Generated Image Detection: A Few-Shot Study with Lightweight Classifier",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Ou"
      ],
      "abstract": "Verifying the authenticity of AI-generated images presents a growing\nchallenge on social media platforms these days. While vision-language models\n(VLMs) like CLIP outdo in multimodal representation, their capacity for\nAI-generated image classification is underexplored due to the absence of such\nlabels during the pre-training process. This work investigates whether CLIP\nembeddings inherently contain information indicative of AI generation. A\nproposed pipeline extracts visual embeddings using a frozen CLIP model, feeds\nits embeddings to lightweight networks, and fine-tunes only the final\nclassifier. Experiments on the public CIFAKE benchmark show the performance\nreaches 95% accuracy without language reasoning. Few-shot adaptation to curated\ncustom with 20% of the data results in performance to 85%. A closed-source\nbaseline (Gemini-2.0) has the best zero-shot accuracy yet fails on specific\nstyles. Notably, some specific image types, such as wide-angle photographs and\noil paintings, pose significant challenges to classification. These results\nindicate previously unexplored difficulties in classifying certain types of\nAI-generated images, revealing new and more specific questions in this domain\nthat are worth further investigation.",
      "tldr_zh": "本研究探讨了使用 CLIP 嵌入检测 AI-generated images 的潜力，提出了一种基于冻结 CLIP 模型提取视觉嵌入并通过轻量级分类器微调的管道，旨在解决社交媒体上的图像真实性验证问题。实验在 CIFAKE 基准上实现了 95% 的准确率，而在 few-shot 场景中使用 20% 数据时，准确率达到 85%，优于 closed-source 基线如 Gemini-2.0 在 zero-shot 下的表现。结果显示某些图像类型（如 wide-angle photographs 和 oil paintings）对分类构成显著挑战，揭示了 AI 生成图像检测领域的潜在难题，需要进一步调查。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures, not submitted to any conference",
      "pdf_url": "http://arxiv.org/pdf/2505.10664v1",
      "published_date": "2025-05-15 19:14:39 UTC",
      "updated_date": "2025-05-15 19:14:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:09:22.336756"
    },
    {
      "arxiv_id": "2505.10653v1",
      "title": "On the Evaluation of Engineering Artificial General Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Sandeep Neema",
        "Susmit Jha",
        "Adam Nagel",
        "Ethan Lew",
        "Chandrasekar Sureshkumar",
        "Aleksa Gordic",
        "Chase Shimmin",
        "Hieu Nguygen",
        "Paul Eremenko"
      ],
      "abstract": "We discuss the challenges and propose a framework for evaluating engineering\nartificial general intelligence (eAGI) agents. We consider eAGI as a\nspecialization of artificial general intelligence (AGI), deemed capable of\naddressing a broad range of problems in the engineering of physical systems and\nassociated controllers. We exclude software engineering for a tractable scoping\nof eAGI and expect dedicated software engineering AI agents to address the\nsoftware implementation challenges. Similar to human engineers, eAGI agents\nshould possess a unique blend of background knowledge (recall and retrieve) of\nfacts and methods, demonstrate familiarity with tools and processes, exhibit\ndeep understanding of industrial components and well-known design families, and\nbe able to engage in creative problem solving (analyze and synthesize),\ntransferring ideas acquired in one context to another. Given this broad\nmandate, evaluating and qualifying the performance of eAGI agents is a\nchallenge in itself and, arguably, a critical enabler to developing eAGI\nagents. In this paper, we address this challenge by proposing an extensible\nevaluation framework that specializes and grounds Bloom's taxonomy - a\nframework for evaluating human learning that has also been recently used for\nevaluating LLMs - in an engineering design context. Our proposed framework\nadvances the state of the art in benchmarking and evaluation of AI agents in\nterms of the following: (a) developing a rich taxonomy of evaluation questions\nspanning from methodological knowledge to real-world design problems; (b)\nmotivating a pluggable evaluation framework that can evaluate not only textual\nresponses but also evaluate structured design artifacts such as CAD models and\nSysML models; and (c) outlining an automatable procedure to customize the\nevaluation benchmark to different engineering contexts.",
      "tldr_zh": "这篇论文探讨了评估工程人工智能通用智能 (eAGI) 代理的挑战，并提出一个可扩展的评估框架，将 Bloom's taxonomy 应用于工程设计情境。eAGI 被定义为 AGI 的一个分支，专注于物理系统和控制器的工程问题，而非软件工程，要求代理具备背景知识、工具熟悉度、工业组件理解以及创造性问题解决能力。该框架的主要贡献包括：开发一个从方法知识到真实世界设计问题的丰富问题分类；支持评估文本响应和结构化设计制品（如 CAD models 和 SysML models）的可插拔系统；以及提供一个自动化的程序来定制评估基准适应不同工程情境。",
      "categories": [
        "cs.AI",
        "I.2; J.2; J.6"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.10653v1",
      "published_date": "2025-05-15 18:52:47 UTC",
      "updated_date": "2025-05-15 18:52:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:09:36.472564"
    },
    {
      "arxiv_id": "2505.10643v2",
      "title": "Artificial Intelligence Bias on English Language Learners in Automatic Scoring",
      "title_zh": "翻译失败",
      "authors": [
        "Shuchen Guo",
        "Yun Wang",
        "Jichao Yu",
        "Xuansheng Wu",
        "Bilgehan Ayik",
        "Field M. Watts",
        "Ehsan Latif",
        "Ninghao Liu",
        "Lei Liu",
        "Xiaoming Zhai"
      ],
      "abstract": "This study investigated potential scoring biases and disparities toward\nEnglish Language Learners (ELLs) when using automatic scoring systems for\nmiddle school students' written responses to science assessments. We\nspecifically focus on examining how unbalanced training data with ELLs\ncontributes to scoring bias and disparities. We fine-tuned BERT with four\ndatasets: responses from (1) ELLs, (2) non-ELLs, (3) a mixed dataset reflecting\nthe real-world proportion of ELLs and non-ELLs (unbalanced), and (4) a balanced\nmixed dataset with equal representation of both groups. The study analyzed 21\nassessment items: 10 items with about 30,000 ELL responses, five items with\nabout 1,000 ELL responses, and six items with about 200 ELL responses. Scoring\naccuracy (Acc) was calculated and compared to identify bias using Friedman\ntests. We measured the Mean Score Gaps (MSGs) between ELLs and non-ELLs and\nthen calculated the differences in MSGs generated through both the human and AI\nmodels to identify the scoring disparities. We found that no AI bias and\ndistorted disparities between ELLs and non-ELLs were found when the training\ndataset was large enough (ELL = 30,000 and ELL = 1,000), but concerns could\nexist if the sample size is limited (ELL = 200).",
      "tldr_zh": "这篇论文研究了自动评分系统对 English Language Learners (ELLs) 的潜在偏见问题，重点考察训练数据不平衡如何导致评分偏差。研究者使用四个数据集微调 BERT 模型，包括纯 ELLs、纯 non-ELLs、不平衡混合数据集和平衡混合数据集，并通过分析 21 个评估项目的评分准确性 (Acc) 和 Mean Score Gaps (MSGs) 来评估偏见。结果表明，当训练数据样本足够大 (ELLs = 30,000 或 1,000) 时，AI 没有显著偏见和差距；但样本较小时 (ELLs = 200)，可能存在评分不公问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10643v2",
      "published_date": "2025-05-15 18:32:24 UTC",
      "updated_date": "2025-05-19 21:42:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:09:49.264092"
    },
    {
      "arxiv_id": "2505.10640v1",
      "title": "The Hitchhikers Guide to Production-ready Trustworthy Foundation Model powered Software (FMware)",
      "title_zh": "翻译失败",
      "authors": [
        "Kirill Vasilevski",
        "Benjamin Rombaut",
        "Gopi Krishnan Rajbahadur",
        "Gustavo A. Oliva",
        "Keheliya Gallaba",
        "Filipe R. Cogo",
        "Jiahuei",
        "Lin",
        "Dayi Lin",
        "Haoxiang Zhang",
        "Bouyan Chen",
        "Kishanthan Thangarajah",
        "Ahmed E. Hassan",
        "Zhen Ming",
        "Jiang"
      ],
      "abstract": "Foundation Models (FMs) such as Large Language Models (LLMs) are reshaping\nthe software industry by enabling FMware, systems that integrate these FMs as\ncore components. In this KDD 2025 tutorial, we present a comprehensive\nexploration of FMware that combines a curated catalogue of challenges with\nreal-world production concerns. We first discuss the state of research and\npractice in building FMware. We further examine the difficulties in selecting\nsuitable models, aligning high-quality domain-specific data, engineering robust\nprompts, and orchestrating autonomous agents. We then address the complex\njourney from impressive demos to production-ready systems by outlining issues\nin system testing, optimization, deployment, and integration with legacy\nsoftware. Drawing on our industrial experience and recent research in the area,\nwe provide actionable insights and a technology roadmap for overcoming these\nchallenges. Attendees will gain practical strategies to enable the creation of\ntrustworthy FMware in the evolving technology landscape.",
      "tldr_zh": "这篇KDD 2025教程探讨了Foundation Models (FMs)如Large Language Models (LLMs)如何重塑软件行业，通过将FMs整合为核心组件创建FMware系统。教程系统地分析了构建FMware的挑战，包括模型选择、领域特定数据对齐、提示工程以及自主代理编排，并从演示到生产系统的全流程中讨论系统测试、优化、部署和与遗留软件集成的实际问题。基于工业经验和最新研究，该教程提供可操作的见解和技术路线图，帮助开发人员构建可信赖的FMware，实现其在实际应用中的可靠部署。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10640v1",
      "published_date": "2025-05-15 18:22:45 UTC",
      "updated_date": "2025-05-15 18:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:10:01.834369"
    },
    {
      "arxiv_id": "2505.10559v1",
      "title": "Neural Thermodynamic Laws for Large Language Model Training",
      "title_zh": "翻译失败",
      "authors": [
        "Ziming Liu",
        "Yizhou Liu",
        "Jeff Gore",
        "Max Tegmark"
      ],
      "abstract": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules.",
      "tldr_zh": "本研究引入了 Neural Thermodynamic Laws (NTL) 框架，以揭示大型语言模型 (LLMs) 训练动态的潜在规律。理论上，该框架基于河-valley loss landscape 假设，证明了热力学量（如温度、熵、热容、热传导）和经典热力学原理（如三大定律和等分配定理）在 LLM 训练中自然浮现。实践中，NTL 提供直观的指导，帮助设计学习率调度，从而优化模型训练过程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.data-an",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10559v1",
      "published_date": "2025-05-15 17:59:22 UTC",
      "updated_date": "2025-05-15 17:59:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:10:12.853836"
    },
    {
      "arxiv_id": "2505.10557v1",
      "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning",
      "title_zh": "MathCoder-VL：桥接视觉与代码以增强多模态数学推理",
      "authors": [
        "Ke Wang",
        "Junting Pan",
        "Linda Wei",
        "Aojun Zhou",
        "Weikang Shi",
        "Zimu Lu",
        "Han Xiao",
        "Yunqiao Yang",
        "Houxing Ren",
        "Mingjie Zhan",
        "Hongsheng Li"
      ],
      "abstract": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder.",
      "tldr_zh": "本研究发现，现有的自然语言图像标题数据集主要关注自然场景，而忽略了数学图形细节，从而限制了Large Multimodal Models (LMMs)在多模态数学推理上的进展。为解决此问题，提出使用代码作为监督进行跨模态对齐，开发了image-to-code模型FigCodifier和ImgCode-8.6M数据集，并通过model-in-the-loop方法构建了MM-MathInstruct-3M用于微调。最终，MathCoder-VL模型先在ImgCode-8.6M上训练跨模态对齐，然后在MM-MathInstruct-3M上微调，实现多模态数学问题解决，并在六种指标上达到开源SOTA，特别是MathVista几何子集中超越GPT-4o和Claude 3.5 Sonnet，分别提升8.9%和9.2%。该模型及数据集将在GitHub开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2505.10557v1",
      "published_date": "2025-05-15 17:59:21 UTC",
      "updated_date": "2025-05-15 17:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:10:26.139131"
    },
    {
      "arxiv_id": "2505.10551v1",
      "title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data",
      "title_zh": "可行性重要吗？理解可行性对合成训练数据的影响",
      "authors": [
        "Yiwen Liu",
        "Jessica Bader",
        "Jae Myung Kim"
      ],
      "abstract": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets.",
      "tldr_zh": "本研究探讨了合成训练数据中“feasibility”（即合成图像属性是否能在现实世界中真实存在）对模型性能的影响，针对CLIP-based分类器，焦点在于背景、颜色和纹理等属性。研究引入了VariReal管道，该方法利用大语言模型生成文本提示，并最小编辑源图像以创建可行或不可行属性。实验结果显示，feasibility对LoRA-fine-tuned CLIP的top-1准确率影响极小（差异小于0.3%），不同属性对分类性能的影响各异，且混合可行和不可行图像的训练数据集与纯可行或纯不可行数据集相比，性能差异不显著。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPRW 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10551v1",
      "published_date": "2025-05-15 17:57:38 UTC",
      "updated_date": "2025-05-15 17:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:10:37.363000"
    },
    {
      "arxiv_id": "2505.10547v1",
      "title": "Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning",
      "title_zh": "通过多模态推理实现实时分布外故障预防",
      "authors": [
        "Milan Ganai",
        "Rohan Sinha",
        "Christopher Agia",
        "Daniel Morton",
        "Marco Pavone"
      ],
      "abstract": "Foundation models can provide robust high-level reasoning on appropriate\nsafety interventions in hazardous scenarios beyond a robot's training data,\ni.e. out-of-distribution (OOD) failures. However, due to the high inference\nlatency of Large Vision and Language Models, current methods rely on manually\ndefined intervention policies to enact fallbacks, thereby lacking the ability\nto plan generalizable, semantically safe motions. To overcome these challenges\nwe present FORTRESS, a framework that generates and reasons about semantically\nsafe fallback strategies in real time to prevent OOD failures. At a low\nfrequency in nominal operations, FORTRESS uses multi-modal reasoners to\nidentify goals and anticipate failure modes. When a runtime monitor triggers a\nfallback response, FORTRESS rapidly synthesizes plans to fallback goals while\ninferring and avoiding semantically unsafe regions in real time. By bridging\nopen-world, multi-modal reasoning with dynamics-aware planning, we eliminate\nthe need for hard-coded fallbacks and human safety interventions. FORTRESS\noutperforms on-the-fly prompting of slow reasoning models in safety\nclassification accuracy on synthetic benchmarks and real-world ANYmal robot\ndata, and further improves system safety and planning success in simulation and\non quadrotor hardware for urban navigation.",
      "tldr_zh": "这篇论文提出 FORTRESS 框架，通过多模态推理实时防止 Out-of-Distribution (OOD) 失败，帮助机器人处理超出训练数据的危险场景。FORTRESS 在正常操作中低频使用多模态推理器识别目标并预测失败模式，并在触发后备响应时快速合成语义安全的计划路径，避免不安全区域。实验结果显示，该框架在合成基准和真实世界机器人数据上优于现有方法，提高了安全分类准确性和规划成功率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Website: https://milanganai.github.io/fortress/",
      "pdf_url": "http://arxiv.org/pdf/2505.10547v1",
      "published_date": "2025-05-15 17:55:28 UTC",
      "updated_date": "2025-05-15 17:55:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:10:49.342191"
    },
    {
      "arxiv_id": "2505.10543v1",
      "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models",
      "title_zh": "迈向大语言模型推理能力更深入的理解",
      "authors": [
        "Annie Wong",
        "Thomas Bäck",
        "Aske Plaat",
        "Niki van Stein",
        "Anna V. Kononova"
      ],
      "abstract": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning.",
      "tldr_zh": "这项研究评估了大型语言模型（Large Language Models, LLMs）在动态环境中的推理能力，测试了自反思（self-reflection）、启发式变异（heuristic mutation）和规划（planning）等提示技术对模型适应性的影响。实验发现，大型模型通常优于小型模型，但战略性提示能缩小性能差距，而过长提示可能损害小型模型在基本任务上的表现。高级提示技术在复杂游戏中更显著提升小型模型的性能，但会引入不稳定性，导致性能波动。总体而言，LLMs 在规划、推理和空间协调等方面与人类相比存在根本缺陷，研究强调需要采用动态基准而非静态基准来更全面评估推理能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10543v1",
      "published_date": "2025-05-15 17:53:47 UTC",
      "updated_date": "2025-05-15 17:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:11:01.117976"
    },
    {
      "arxiv_id": "2505.10609v1",
      "title": "Agent Name Service (ANS): A Universal Directory for Secure AI Agent Discovery and Interoperability",
      "title_zh": "翻译失败",
      "authors": [
        "Ken Huang",
        "Vineeth Sai Narajala",
        "Idan Habler",
        "Akram Sheriff"
      ],
      "abstract": "The proliferation of AI agents requires robust mechanisms for secure\ndiscovery. This paper introduces the Agent Name Service (ANS), a novel\narchitecture based on DNS addressing the lack of a public agent discovery\nframework. ANS provides a protocol-agnostic registry infrastructure that\nleverages Public Key Infrastructure (PKI) certificates for verifiable agent\nidentity and trust. The architecture features several key innovations: a\nformalized agent registration and renewal mechanism for lifecycle management;\nDNS-inspired naming conventions with capability-aware resolution; a modular\nProtocol Adapter Layer supporting diverse communication standards (A2A, MCP,\nACP etc.); and precisely defined algorithms for secure resolution. We implement\nstructured communication using JSON Schema and conduct a comprehensive threat\nanalysis of our proposal. The result is a foundational directory service\naddressing the core challenges of secured discovery and interaction in\nmulti-agent systems, paving the way for future interoperable, trustworthy, and\nscalable agent ecosystems.",
      "tldr_zh": "这篇论文引入了 Agent Name Service (ANS)，一个基于 DNS 的新型架构，旨在解决 AI 代理的安全发现和互操作性问题。ANS 通过 Public Key Infrastructure (PKI) 证书提供协议无关的注册基础设施，包括代理注册与续订机制、基于能力的命名约定、模块化的 Protocol Adapter Layer（支持 A2A、MCP、ACP 等标准），以及精确的安全解析算法。论文使用 JSON Schema 实现结构化通信，并进行全面威胁分析，最终为多代理系统构建了一个可靠的目录服务，促进可互操作、可信赖和可扩展的代理生态系统的发展。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "15 pages, 6 figures, 6 code listings, Supported and endorsed by OWASP\n  GenAI ASI Project",
      "pdf_url": "http://arxiv.org/pdf/2505.10609v1",
      "published_date": "2025-05-15 17:49:36 UTC",
      "updated_date": "2025-05-15 17:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:11:14.239344"
    },
    {
      "arxiv_id": "2505.10537v1",
      "title": "LibIQ: Toward Real-Time Spectrum Classification in O-RAN dApps",
      "title_zh": "翻译失败",
      "authors": [
        "Filippo Olimpieri",
        "Noemi Giustini",
        "Andrea Lacava",
        "Salvatore D'Oro",
        "Tommaso Melodia",
        "Francesca Cuomo"
      ],
      "abstract": "The O-RAN architecture is transforming cellular networks by adopting RAN\nsoftwarization and disaggregation concepts to enable data-driven monitoring and\ncontrol of the network. Such management is enabled by RICs, which facilitate\nnear-real-time and non-real-time network control through xApps and rApps.\nHowever, they face limitations, including latency overhead in data exchange\nbetween the RAN and RIC, restricting real-time monitoring, and the inability to\naccess user plain data due to privacy and security constraints, hindering use\ncases like beamforming and spectrum classification. In this paper, we leverage\nthe dApps concept to enable real-time RF spectrum classification with LibIQ, a\nnovel library for RF signals that facilitates efficient spectrum monitoring and\nsignal classification by providing functionalities to read I/Q samples as\ntime-series, create datasets and visualize time-series data through plots and\nspectrograms. Thanks to LibIQ, I/Q samples can be efficiently processed to\ndetect external RF signals, which are subsequently classified using a CNN\ninside the library. To achieve accurate spectrum analysis, we created an\nextensive dataset of time-series-based I/Q samples, representing distinct\nsignal types captured using a custom dApp running on a 5G deployment over the\nColosseum network emulator and an OTA testbed. We evaluate our model by\ndeploying LibIQ in heterogeneous scenarios with varying center frequencies,\ntime windows, and external RF signals. In real-time analysis, the model\nclassifies the processed I/Q samples, achieving an average accuracy of\napproximately 97.8\\% in identifying signal types across all scenarios. We\npledge to release both LibIQ and the dataset created as a publicly available\nframework upon acceptance.",
      "tldr_zh": "该论文针对 O-RAN 架构中 RICs 的延迟问题和隐私限制，提出 LibIQ 库，以实现实时 RF 频谱分类。LibIQ 提供读取 I/Q samples 作为时间序列、创建数据集和可视化功能，并使用 CNN 模型对外部 RF 信号进行分类。实验在 5G 部署和 OTA 测试床的多种场景下评估，平均准确率达 97.8%，并计划开源 LibIQ 和相关数据集。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "6 pages, 5 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.10537v1",
      "published_date": "2025-05-15 17:47:30 UTC",
      "updated_date": "2025-05-15 17:47:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:11:25.564168"
    },
    {
      "arxiv_id": "2505.13496v1",
      "title": "ADALog: Adaptive Unsupervised Anomaly detection in Logs with Self-attention Masked Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Przemek Pospieszny",
        "Wojciech Mormul",
        "Karolina Szyndler",
        "Sanjeev Kumar"
      ],
      "abstract": "Modern software systems generate extensive heterogeneous log data with\ndynamic formats, fragmented event sequences, and varying temporal patterns,\nmaking anomaly detection both crucial and challenging. To address these\ncomplexities, we propose ADALog, an adaptive, unsupervised anomaly detection\nframework designed for practical applicability across diverse real-world\nenvironments. Unlike traditional methods reliant on log parsing, strict\nsequence dependencies, or labeled data, ADALog operates on individual\nunstructured logs, extracts intra-log contextual relationships, and performs\nadaptive thresholding on normal data. The proposed approach utilizes a\ntransformer-based, pretrained bidirectional encoder with a masked language\nmodeling task, fine-tuned on normal logs to capture domain-specific syntactic\nand semantic patterns essential for accurate anomaly detection. Anomalies are\nidentified via token-level reconstruction probabilities, aggregated into\nlog-level scores, with adaptive percentile-based thresholding calibrated only\non normal data. This allows the model to dynamically adapt to evolving system\nbehaviors while avoiding rigid, heuristic-based thresholds common in\ntraditional systems. We evaluate ADALog on benchmark datasets BGL, Thunderbird,\nand Spirit, showing strong generalization and competitive performance compared\nto state-of-the-art supervised and unsupervised methods. Additional ablation\nstudies examine the effects of masking, fine-tuning, and token positioning on\nmodel behavior and interpretability.",
      "tldr_zh": "该论文提出 ADALog，一种自适应无监督异常检测框架，用于处理现代软件系统产生的异构日志数据，包括动态格式、碎片化事件序列和变化的时序模式。ADALog 基于 Transformer 的预训练双向编码器和 Masked Language Modeling 任务，在正常日志上进行微调，以提取内部上下文关系并捕捉领域特定的语法和语义模式。异常检测通过 token-level 的重建概率聚合为日志级分数，并采用基于正常数据的自适应百分位数阈值，实现动态适应系统行为的演变。实验在 BGL、Thunderbird 和 Spirit 等基准数据集上显示，ADALog 表现出强的泛化能力，与最先进的有监督和无监督方法竞争性能；此外，消融研究探讨了 masking、fine-tuning 和 token 定位对模型行为和可解释性的影响。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.2.6; I.2.7; I.5.1; C.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "Conference paper accepted at ICMLT 2025; to appear in the IEEE\n  Conference Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2505.13496v1",
      "published_date": "2025-05-15 17:31:40 UTC",
      "updated_date": "2025-05-15 17:31:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:11:38.639143"
    },
    {
      "arxiv_id": "2505.10522v1",
      "title": "Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Xinrui Wang",
        "Yan Jin"
      ],
      "abstract": "Reinforcement learning (RL) has demonstrated remarkable potential in robotic\nmanipulation but faces challenges in sample inefficiency and lack of\ninterpretability, limiting its applicability in real world scenarios. Enabling\nthe agent to gain a deeper understanding and adapt more efficiently to diverse\nworking scenarios is crucial, and strategic knowledge utilization is a key\nfactor in this process. This paper proposes a Knowledge Capture, Adaptation,\nand Composition (KCAC) framework to systematically integrate knowledge transfer\ninto RL through cross-task curriculum learning. KCAC is evaluated using a two\nblock stacking task in the CausalWorld benchmark, a complex robotic\nmanipulation environment. To our knowledge, existing RL approaches fail to\nsolve this task effectively, reflecting deficiencies in knowledge capture. In\nthis work, we redesign the benchmark reward function by removing rigid\nconstraints and strict ordering, allowing the agent to maximize total rewards\nconcurrently and enabling flexible task completion. Furthermore, we define two\nself-designed sub-tasks and implement a structured cross-task curriculum to\nfacilitate efficient learning. As a result, our KCAC approach achieves a 40\npercent reduction in training time while improving task success rates by 10\npercent compared to traditional RL methods. Through extensive evaluation, we\nidentify key curriculum design parameters subtask selection, transition timing,\nand learning rate that optimize learning efficiency and provide conceptual\nguidance for curriculum based RL frameworks. This work offers valuable insights\ninto curriculum design in RL and robotic learning.",
      "tldr_zh": "本研究针对强化学习（RL）在机器人操作中的样本效率低和可解释性差问题，提出了一种Knowledge Capture, Adaptation and Composition (KCAC)框架，通过跨任务课程学习来实现知识转移和整合。KCAC在CausalWorld基准的两个块堆叠任务上进行评估，重新设计了奖励函数以增加任务灵活性，并定义了两个自设计的子任务来构建结构化课程。实验结果显示，该框架将训练时间减少40%，并将任务成功率提高10%，同时识别了关键参数如子任务选择、过渡时机和学习率，以优化学习效率。该工作为RL和机器人学习中的课程设计提供了重要指导和见解。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10522v1",
      "published_date": "2025-05-15 17:30:29 UTC",
      "updated_date": "2025-05-15 17:30:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:11:50.844651"
    },
    {
      "arxiv_id": "2505.10518v1",
      "title": "Multi-Token Prediction Needs Registers",
      "title_zh": "翻译失败",
      "authors": [
        "Anastasios Gerontopoulos",
        "Spyros Gidaris",
        "Nikos Komodakis"
      ],
      "abstract": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR.",
      "tldr_zh": "本文提出 MuToR，一种简单有效的 multi-token prediction 方法，通过在输入序列中交错 learnable register tokens 来预测未来目标，从而解决 multi-token prediction 在预训练外场景（如 fine-tuning）中表现不一致的问题。与现有方法相比，MuToR 只引入微量额外参数、不需架构更改，并保持与 next-token pretraining 目标的兼容性，特别适合 supervised fine-tuning 和参数高效微调 (PEFT)。实验结果显示，MuToR 在语言和视觉领域的生成任务中表现出色，并在预训练等用例中展现了可扩展的预测范围。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10518v1",
      "published_date": "2025-05-15 17:25:03 UTC",
      "updated_date": "2025-05-15 17:25:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:12:03.513126"
    },
    {
      "arxiv_id": "2505.10515v1",
      "title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models",
      "title_zh": "PnPXAI：一种通用 XAI 框架，提供跨多种模态和模型的自动解释",
      "authors": [
        "Seongun Kim",
        "Sol A Kim",
        "Geonhyeong Kim",
        "Enver Menadjiev",
        "Chanwoo Lee",
        "Seongwook Chung",
        "Nari Kim",
        "Jaesik Choi"
      ],
      "abstract": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance.",
      "tldr_zh": "本文讨论了现有后验解释方法（post hoc explanation methods）的局限性，包括对特定神经网络架构和数据模态的依赖，以及支持的 XAI 方法有限和缺乏优化，导致实际应用受阻。为解决这些问题，研究提出 PnPXAI，一个通用 XAI 框架，支持多种数据模态和模型的 Plug-and-Play (PnP) 方式，能够自动检测模型架构、推荐适用的解释方法并优化超参数。通过用户调查和在医学、金融等领域的验证，PnPXAI 展示了其有效性和多功能性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10515v1",
      "published_date": "2025-05-15 17:21:54 UTC",
      "updated_date": "2025-05-15 17:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:12:14.955014"
    },
    {
      "arxiv_id": "2505.10607v1",
      "title": "MONAQ: Multi-Objective Neural Architecture Querying for Time-Series Analysis on Resource-Constrained Devices",
      "title_zh": "MONAQ：多目标神经架构查询用于资源受限设备上的时间序列分析",
      "authors": [
        "Patara Trirat",
        "Jae-Gil Lee"
      ],
      "abstract": "The growing use of smartphones and IoT devices necessitates efficient\ntime-series analysis on resource-constrained hardware, which is critical for\nsensing applications such as human activity recognition and air quality\nprediction. Recent efforts in hardware-aware neural architecture search (NAS)\nautomate architecture discovery for specific platforms; however, none focus on\ngeneral time-series analysis with edge deployment. Leveraging the\nproblem-solving and reasoning capabilities of large language models (LLM), we\npropose MONAQ, a novel framework that reformulates NAS into Multi-Objective\nNeural Architecture Querying tasks. MONAQ is equipped with multimodal query\ngeneration for processing multimodal time-series inputs and hardware\nconstraints, alongside an LLM agent-based multi-objective search to achieve\ndeployment-ready models via code generation. By integrating numerical data,\ntime-series images, and textual descriptions, MONAQ improves an LLM's\nunderstanding of time-series data. Experiments on fifteen datasets demonstrate\nthat MONAQ-discovered models outperform both handcrafted models and NAS\nbaselines while being more efficient.",
      "tldr_zh": "该研究提出MONAQ框架，利用大型语言模型(LLM)的推理能力，将神经架构搜索(NAS)转化为多目标神经架构查询任务，以适应资源受限设备上的时间序列分析，如人类活动识别和空气质量预测。MONAQ通过多模态查询生成处理数值数据、时间序列图像和文本描述，同时采用LLM代理的多目标搜索和代码生成，生成高效的部署就绪模型。实验在15个数据集上显示，MONAQ发现的模型在性能上优于手工设计模型和NAS基线，同时实现了更高的效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code will be available at https://github.com/kaist-dmlab/MONAQ",
      "pdf_url": "http://arxiv.org/pdf/2505.10607v1",
      "published_date": "2025-05-15 16:35:33 UTC",
      "updated_date": "2025-05-15 16:35:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:12:26.977139"
    },
    {
      "arxiv_id": "2505.10483v1",
      "title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Li",
        "Haonan Wang",
        "Qixiang Zhang",
        "Boyu Xiao",
        "Chenchang Hu",
        "Hualiang Wang",
        "Xiaomeng Li"
      ],
      "abstract": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values.",
      "tldr_zh": "本文提出 UniEval，一种统一的整体评估框架，用于评估多模态理解和生成模型，旨在解决当前评估的碎片化和依赖额外资源等问题。UniEval 包括 UniBench 基准（支持统一和视觉生成模型，包含 81 个细粒度标签以提升多样性）和 UniScore 指标，该框架无需额外模型、图像或标注，实现简化的评估过程。实验结果表明，UniBench 比现有基准更具挑战性，UniScore 与人类评估高度一致，且通过评估 SoTA 模型，揭示了统一模型的独特价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "UniEval is the first evaluation framework designed for unified\n  multimodal models, including a holistic benchmark UniBench and the UniScore\n  metric",
      "pdf_url": "http://arxiv.org/pdf/2505.10483v1",
      "published_date": "2025-05-15 16:34:50 UTC",
      "updated_date": "2025-05-15 16:34:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:12:39.186410"
    },
    {
      "arxiv_id": "2505.10482v1",
      "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps",
      "title_zh": "翻译失败",
      "authors": [
        "Ningyuan Yang",
        "Jiaxuan Gao",
        "Feng Gao",
        "Yi Wu",
        "Chao Yu"
      ],
      "abstract": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy.",
      "tldr_zh": "本文提出 NCDPO 框架，用于微调 Diffusion Policies，通过在扩散时间步上进行梯度回传，解决现有方法在行动似然估计上的计算挑战。NCDPO 将 Diffusion Policy 重新表述为噪声条件确定性策略，使每个去噪步骤成为可微变换，从而实现高效的似然评估和优化。实验结果表明，NCDPO 在样本效率上与 MLP+PPO 相当，并在机器人控制和多代理游戏等基准上表现出色，同时对去噪步数具有鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10482v1",
      "published_date": "2025-05-15 16:33:44 UTC",
      "updated_date": "2025-05-15 16:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:12:51.053706"
    },
    {
      "arxiv_id": "2505.10606v1",
      "title": "Continuity and Isolation Lead to Doubts or Dilemmas in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hector Pasten",
        "Felipe Urrutia",
        "Hector Jimenez",
        "Cristian B. Calderon",
        "Cristóbal Rojas",
        "Alexander Kozachinskiy"
      ],
      "abstract": "Understanding how Transformers work and how they process information is key\nto the theoretical and empirical advancement of these machines. In this work,\nwe demonstrate the existence of two phenomena in Transformers, namely isolation\nand continuity. Both of these phenomena hinder Transformers to learn even\nsimple pattern sequences. Isolation expresses that any learnable sequence must\nbe isolated from another learnable sequence, and hence some sequences cannot be\nlearned by a single Transformer at the same time. Continuity entails that an\nattractor basin forms around a learned sequence, such that any sequence falling\nin that basin will collapse towards the learned sequence. Here, we\nmathematically prove these phenomena emerge in all Transformers that use\ncompact positional encoding, and design rigorous experiments, demonstrating\nthat the theoretical limitations we shed light on occur on the practical scale.",
      "tldr_zh": "这篇论文揭示了Transformer模型中的两种现象：isolation和continuity，它们阻碍了模型学习简单模式序列。Isolation表示任何可学习的序列必须与其他可学习的序列隔离，因此单个Transformer无法同时处理某些序列；Continuity则导致围绕已学习序列形成吸引子盆，使得落入该盆的序列会崩溃到已学习序列。作者通过数学证明证明了这些现象在所有使用紧凑位置编码的Transformer中出现，并设计了严格实验，在实际规模上验证了这些理论限制的存在，从而为Transformer的改进提供了重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10606v1",
      "published_date": "2025-05-15 16:24:14 UTC",
      "updated_date": "2025-05-15 16:24:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:13:02.853985"
    },
    {
      "arxiv_id": "2505.10472v1",
      "title": "Large Language Models for Cancer Communication: Evaluating Linguistic Quality, Safety, and Accessibility in Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Agnik Saha",
        "Victoria Churchill",
        "Anny D. Rodriguez",
        "Ugur Kursuncu",
        "Muhammed Y. Idris"
      ],
      "abstract": "Effective communication about breast and cervical cancers remains a\npersistent health challenge, with significant gaps in public understanding of\ncancer prevention, screening, and treatment, potentially leading to delayed\ndiagnoses and inadequate treatments. This study evaluates the capabilities and\nlimitations of Large Language Models (LLMs) in generating accurate, safe, and\naccessible cancer-related information to support patient understanding. We\nevaluated five general-purpose and three medical LLMs using a mixed-methods\nevaluation framework across linguistic quality, safety and trustworthiness, and\ncommunication accessibility and affectiveness. Our approach utilized\nquantitative metrics, qualitative expert ratings, and statistical analysis\nusing Welch's ANOVA, Games-Howell, and Hedges' g. Our results show that\ngeneral-purpose LLMs produced outputs of higher linguistic quality and\naffectiveness, while medical LLMs demonstrate greater communication\naccessibility. However, medical LLMs tend to exhibit higher levels of potential\nharm, toxicity, and bias, reducing their performance in safety and\ntrustworthiness. Our findings indicate a duality between domain-specific\nknowledge and safety in health communications. The results highlight the need\nfor intentional model design with targeted improvements, particularly in\nmitigating harm and bias, and improving safety and affectiveness. This study\nprovides a comprehensive evaluation of LLMs for cancer communication, offering\ncritical insights for improving AI-generated health content and informing\nfuture development of accurate, safe, and accessible digital health tools.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在癌症沟通中的表现，焦点在于生成准确、安全和可访问的乳腺癌及宫颈癌相关信息，以解决公众理解缺口问题。研究采用混合方法框架，对五种通用 LLMs 和三种医疗 LLMs 进行评估，包括语言质量、安全及可信度、以及沟通可访问性和有效性的定量指标、专家定性评分和统计分析（如 Welch's ANOVA 和 Hedges' g）。结果显示，通用 LLMs 在语言质量和有效性方面表现更佳，而医疗 LLMs 更具可访问性，但后者在潜在危害、毒性和偏见方面更高，导致安全性和可信度较低。论文强调领域特定知识与安全性的二元性，呼吁针对性改进 LLMs，以减少偏见并提升 AI 生成的健康内容质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10472v1",
      "published_date": "2025-05-15 16:23:21 UTC",
      "updated_date": "2025-05-15 16:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:13:16.805953"
    },
    {
      "arxiv_id": "2505.10468v3",
      "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges",
      "title_zh": "AI Agents 与 Agentic AI：概念分类、应用及挑战",
      "authors": [
        "Ranjan Sapkota",
        "Konstantinos I. Roumeliotis",
        "Manoj Karkee"
      ],
      "abstract": "This study critically distinguishes between AI Agents and Agentic AI,\noffering a structured conceptual taxonomy, application mapping, and challenge\nanalysis to clarify their divergent design philosophies and capabilities. We\nbegin by outlining the search strategy and foundational definitions,\ncharacterizing AI Agents as modular systems driven by Large Language Models\n(LLMs) and Large Image Models (LIMs) for narrow, task-specific automation.\nGenerative AI is positioned as a precursor, with AI Agents advancing through\ntool integration, prompt engineering, and reasoning enhancements. In contrast,\nAgentic AI systems represent a paradigmatic shift marked by multi-agent\ncollaboration, dynamic task decomposition, persistent memory, and orchestrated\nautonomy. Through a sequential evaluation of architectural evolution,\noperational mechanisms, interaction styles, and autonomy levels, we present a\ncomparative analysis across both paradigms. Application domains such as\ncustomer support, scheduling, and data summarization are contrasted with\nAgentic AI deployments in research automation, robotic coordination, and\nmedical decision support. We further examine unique challenges in each paradigm\nincluding hallucination, brittleness, emergent behavior, and coordination\nfailure and propose targeted solutions such as ReAct loops, RAG, orchestration\nlayers, and causal modeling. This work aims to provide a definitive roadmap for\ndeveloping robust, scalable, and explainable AI agent and Agentic AI-driven\nsystems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision\nSupport System, Agentic-AI Applications",
      "tldr_zh": "这篇论文对AI Agents和Agentic AI进行了概念区分，提供了一个结构化的分类框架、应用映射和挑战分析。AI Agents被定义为基于LLMs和LIMs的模块化系统，专注于特定任务自动化，通过工具整合、提示工程和推理增强发展；相比之下，Agentic AI代表范式转变，强调多智能体协作、动态任务分解、持久记忆和协调自治。论文比较了二者在架构、操作机制和应用领域的差异，例如AI Agents用于客户支持和数据总结，而Agentic AI适用于研究自动化和医疗决策支持，并探讨了挑战如幻觉和协调失败，提出解决方案包括ReAct loops、RAG和编排层。该工作旨在为开发稳健、可扩展的AI系统提供路线图。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages, 14 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.10468v3",
      "published_date": "2025-05-15 16:21:33 UTC",
      "updated_date": "2025-05-20 04:49:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:13:28.353010"
    },
    {
      "arxiv_id": "2505.10465v2",
      "title": "Superposition Yields Robust Neural Scaling",
      "title_zh": "叠加产生稳健的神经缩放",
      "authors": [
        "Yizhou Liu",
        "Ziming Liu",
        "Jeff Gore"
      ],
      "abstract": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)的神经缩放定律，即模型规模越大，损失越低的原因，通过superposition（表示叠加）和特征频率分布的经验原则构建了一个玩具模型。研究发现，在强superposition下，损失与模型维度成反比，导致稳健的缩放行为，这在几何上归因于向量间的干扰随维度减小而增加。实验分析了四个开源LLMs家族，证实了模型预测，并与Chinchilla缩放定律一致。最终，论文强调superposition是神经scaling laws的关键机制，并预见这将启发更高效的训练策略和模型架构，以减少计算和参数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 23 figures, with corrections",
      "pdf_url": "http://arxiv.org/pdf/2505.10465v2",
      "published_date": "2025-05-15 16:18:13 UTC",
      "updated_date": "2025-05-18 15:54:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:13:39.323115"
    },
    {
      "arxiv_id": "2505.10457v1",
      "title": "SEAL: Searching Expandable Architectures for Incremental Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Gambella",
        "Vicente Javier Castro Solar",
        "Manuel Roveri"
      ],
      "abstract": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios.",
      "tldr_zh": "本论文提出SEAL框架，用于Incremental Learning场景中动态搜索可扩展架构。SEAL通过基于容量估计指标的策略，仅在必要时扩展模型结构，并采用cross-distillation training来维护稳定性，同时NAS组件联合优化架构和扩展策略。实验在多个基准上证明，SEAL显著减少了遗忘现象，提高了准确性，同时保持了更低的模型大小，展示了其在资源受限的增量学习中的高效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "68T07"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10457v1",
      "published_date": "2025-05-15 16:14:18 UTC",
      "updated_date": "2025-05-15 16:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:13:50.598421"
    },
    {
      "arxiv_id": "2505.10453v1",
      "title": "Vision language models have difficulty recognizing virtual objects",
      "title_zh": "视觉语言模型难以识别虚拟对象",
      "authors": [
        "Tyler Tran",
        "Sangeet Khemlani",
        "J. G. Trafton"
      ],
      "abstract": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate.",
      "tldr_zh": "该研究探讨了视觉语言模型 (VLMs) 在理解图像场景视空间属性方面的局限性，特别是对虚拟对象 (virtual objects) 的识别困难。作者提出一种测试方法，通过添加描述性提示（如在一张显示人站在树下的图像中想象一个风筝卡在树上）来评估 VLMs 是否能正确更新场景表示并推理对象间的空间关系。系统评估结果显示，当前最先进的 VLMs 在处理虚拟对象时表现不足，这突显了这些模型在场景理解方面的关键缺陷，并为未来改进提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10453v1",
      "published_date": "2025-05-15 16:11:33 UTC",
      "updated_date": "2025-05-15 16:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:14:03.924041"
    },
    {
      "arxiv_id": "2505.10604v1",
      "title": "MIRAGE: A Multi-modal Benchmark for Spatial Perception, Reasoning, and Intelligence",
      "title_zh": "MIRAGE：一种多模态基准，用于空间感知、推理和智能",
      "authors": [
        "Chonghan Liu",
        "Haoran Wang",
        "Felix Henry",
        "Pu Miao",
        "Yajie Zhang",
        "Yu Zhao",
        "Peiran Wu"
      ],
      "abstract": "Spatial perception and reasoning are core components of human cognition,\nencompassing object recognition, spatial relational understanding, and dynamic\nreasoning. Despite progress in computer vision, existing benchmarks reveal\nsignificant gaps in models' abilities to accurately recognize object attributes\nand reason about spatial relationships, both essential for dynamic reasoning.\nTo address these limitations, we propose MIRAGE, a multi-modal benchmark\ndesigned to evaluate models' capabilities in Counting (object attribute\nrecognition), Relation (spatial relational reasoning), and Counting with\nRelation. Through diverse and complex scenarios requiring fine-grained\nrecognition and reasoning, MIRAGE highlights critical limitations in\nstate-of-the-art models, underscoring the need for improved representations and\nreasoning frameworks. By targeting these foundational abilities, MIRAGE\nprovides a pathway toward spatiotemporal reasoning in future research.",
      "tldr_zh": "这篇论文提出了 MIRAGE，一个多模态基准，用于评估模型在空间感知、推理和智能方面的能力，包括物体属性识别（Counting）、空间关系推理（Relation）和结合二者的任务。MIRAGE 通过多样化和复杂的场景，揭示了现有计算机视觉模型在识别物体属性和处理空间关系方面的显著局限性。最终，该基准强调了改进模型表示和推理框架的必要性，为未来时空推理研究铺平道路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10604v1",
      "published_date": "2025-05-15 16:08:14 UTC",
      "updated_date": "2025-05-15 16:08:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:14:14.536210"
    },
    {
      "arxiv_id": "2505.10443v1",
      "title": "Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Orvalho",
        "Marta Kwiatkowska"
      ],
      "abstract": "Understanding the reasoning and robustness of Large Language Models (LLMs) is\ncritical for their reliable use in programming tasks. While recent studies have\nassessed LLMs' ability to predict program outputs, most focus solely on the\naccuracy of those predictions, without evaluating the reasoning behind them.\nMoreover, it has been observed on mathematical reasoning tasks that LLMs can\narrive at correct answers through flawed logic, raising concerns about similar\nissues in code understanding.\n  In this work, we evaluate whether state-of-the-art LLMs with up to 8B\nparameters can reason about Python programs or are simply guessing. We apply\nfive semantics-preserving code mutations: renaming variables, mirroring\ncomparison expressions, swapping if-else branches, converting for loops to\nwhile, and loop unrolling. These mutations maintain program semantics while\naltering its syntax. We evaluated six LLMs and performed a human expert\nanalysis using LiveCodeBench to assess whether the correct predictions are\nbased on sound reasoning. We also evaluated prediction stability across\ndifferent code mutations on LiveCodeBench and CruxEval. Our findings show that\nsome LLMs, such as Llama3.2, produce correct predictions based on flawed\nreasoning in up to 61% of cases. Furthermore, LLMs often change predictions in\nresponse to our code mutations, indicating limited robustness in their semantic\nunderstanding.",
      "tldr_zh": "本研究评估Large Language Models (LLMs) 在代码理解中的推理鲁棒性，焦点在于它们是否能抵抗semantics-preserving mutations 而非单纯猜测。研究者应用五种语义保持的代码变异（包括重命名变量、镜像比较表达式、交换if-else分支、将for循环转换为while循环及循环展开），并使用LiveCodeBench和CruxEval对六种LLMs进行测试，同时结合人类专家分析。结果显示，如Llama3.2的LLMs在多达61%的正确预测中依赖错误推理，且这些模型常因代码变异而改变预测，揭示了其语义理解的有限鲁棒性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 5 tables, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2505.10443v1",
      "published_date": "2025-05-15 16:04:25 UTC",
      "updated_date": "2025-05-15 16:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:14:27.439998"
    },
    {
      "arxiv_id": "2505.10442v1",
      "title": "IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Dechen Gao",
        "Hang Wang",
        "Hanchu Zhou",
        "Nejib Ammar",
        "Shatadal Mishra",
        "Ahmadreza Moradipari",
        "Iman Soltani",
        "Junshan Zhang"
      ],
      "abstract": "Imitation learning (IL) and reinforcement learning (RL) each offer distinct\nadvantages for robotics policy learning: IL provides stable learning from\ndemonstrations, and RL promotes generalization through exploration. While\nexisting robot learning approaches using IL-based pre-training followed by\nRL-based fine-tuning are promising, this two-step learning paradigm often\nsuffers from instability and poor sample efficiency during the RL fine-tuning\nphase. In this work, we introduce IN-RIL, INterleaved Reinforcement learning\nand Imitation Learning, for policy fine-tuning, which periodically injects IL\nupdates after multiple RL updates and hence can benefit from the stability of\nIL and the guidance of expert data for more efficient exploration throughout\nthe entire fine-tuning process. Since IL and RL involve different optimization\nobjectives, we develop gradient separation mechanisms to prevent destructive\ninterference during \\ABBR fine-tuning, by separating possibly conflicting\ngradient updates in orthogonal subspaces. Furthermore, we conduct rigorous\nanalysis, and our findings shed light on why interleaving IL with RL stabilizes\nlearning and improves sample-efficiency. Extensive experiments on 14 robot\nmanipulation and locomotion tasks across 3 benchmarks, including\nFurnitureBench, OpenAI Gym, and Robomimic, demonstrate that \\ABBR can\nsignificantly improve sample efficiency and mitigate performance collapse\nduring online finetuning in both long- and short-horizon tasks with either\nsparse or dense rewards. IN-RIL, as a general plug-in compatible with various\nstate-of-the-art RL algorithms, can significantly improve RL fine-tuning, e.g.,\nfrom 12\\% to 88\\% with 6.3x improvement in the success rate on Robomimic\nTransport. Project page: https://github.com/ucd-dare/IN-RIL.",
      "tldr_zh": "这项研究提出 IN-RIL，一种交错强化学习 (RL) 和模仿学习 (IL) 的框架，用于机器人策略微调，旨在结合 IL 的稳定学习优势和 RL 的探索泛化能力，以解决传统两步学习范式中的不稳定性和服务效率问题。IN-RIL 通过定期注入 IL 更新并采用梯度分离机制来防止冲突梯度干扰，从而在整个微调过程中实现更高效的探索和学习。实验在 14 个机器人操作和运动任务上（如 FurnitureBench、OpenAI Gym 和 Robomimic）显示，IN-RIL 显著提升样本效率，防止性能崩溃，并在 Robomimic Transport 任务中将成功率从 12% 提高到 88%，证明其作为通用插件的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10442v1",
      "published_date": "2025-05-15 16:01:21 UTC",
      "updated_date": "2025-05-15 16:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:14:40.184321"
    },
    {
      "arxiv_id": "2505.10441v1",
      "title": "PIF: Anomaly detection via preference embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Filippo Leveni",
        "Luca Magri",
        "Giacomo Boracchi",
        "Cesare Alippi"
      ],
      "abstract": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space.",
      "tldr_zh": "该论文提出了一种名为 PIF 的异常检测方法，结合自适应隔离技术和 preference embedding 的优势，用于检测相对于结构化模式的异常。PIF 通过在高维空间中嵌入数据，并使用高效的树-based 方法 PI-Forest 来计算异常分数，从而提升检测的灵活性和准确性。实验结果表明，PIF 在合成和真实数据集上优于现有最先进技术，特别是在测量任意距离和隔离偏好空间中的点方面。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)",
      "pdf_url": "http://arxiv.org/pdf/2505.10441v1",
      "published_date": "2025-05-15 16:00:31 UTC",
      "updated_date": "2025-05-15 16:00:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:14:50.864085"
    },
    {
      "arxiv_id": "2505.11552v1",
      "title": "GSPRec: Temporal-Aware Graph Spectral Filtering for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmad Bin Rabiah",
        "Julian McAuley"
      ],
      "abstract": "Graph-based recommendation systems are effective at modeling collaborative\npatterns but often suffer from two limitations: overreliance on low-pass\nfiltering, which suppresses user-specific signals, and omission of sequential\ndynamics in graph construction. We introduce GSPRec, a graph spectral model\nthat integrates temporal transitions through sequentially-informed graph\nconstruction and applies frequency-aware filtering in the spectral domain.\nGSPRec encodes item transitions via multi-hop diffusion to enable the use of\nsymmetric Laplacians for spectral processing. To capture user preferences, we\ndesign a dual-filtering mechanism: a Gaussian bandpass filter to extract\nmid-frequency, user-level patterns, and a low-pass filter to retain global\ntrends. Extensive experiments on four public datasets show that GSPRec\nconsistently outperforms baselines, with an average improvement of 6.77% in\nNDCG@10. Ablation studies show the complementary benefits of both sequential\ngraph augmentation and bandpass filtering.",
      "tldr_zh": "该研究提出GSPRec，一种时间感知的图谱过滤推荐模型，解决了传统图-based推荐系统过度依赖低通过滤（抑制用户特定信号）和忽略序列动态的问题。通过序列信息图构建和多跳扩散编码项目转换，GSPRec利用对称Laplacians进行谱域处理，并设计双过滤机制：高斯带通过滤提取中频用户级模式，低通过滤保留全局趋势。实验在四个公共数据集上显示，GSPRec比基线模型平均提升6.77%在NDCG@10的性能，消融研究证实序列图增强和带通过滤的互补益处。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11552v1",
      "published_date": "2025-05-15 15:49:56 UTC",
      "updated_date": "2025-05-15 15:49:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:15:03.020860"
    },
    {
      "arxiv_id": "2505.10420v1",
      "title": "Learned Lightweight Smartphone ISP with Unpaired Data",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Arhire",
        "Radu Timofte"
      ],
      "abstract": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data .",
      "tldr_zh": "本文提出了一种无需配对数据的训练方法，用于开发轻量级智能手机 ISP（Image Signal Processor），以解决获取像素级对齐 RAW 和高质量参考图像的成本高难题。该方法采用多项损失函数结合对抗训练（adversarial training），利用多个鉴别器处理预训练网络的特征图，从而保持内容结构并从目标 RGB 数据集学习颜色和纹理特征。实验在 Zurich RAW to RGB 和 Fujifilm UltraISP 数据集上显示，该方法使用适合移动设备的神经网络架构，在多个评价指标上实现了高保真度，并优于传统配对训练方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPRW 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10420v1",
      "published_date": "2025-05-15 15:37:51 UTC",
      "updated_date": "2025-05-15 15:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:15:15.567408"
    },
    {
      "arxiv_id": "2505.10405v1",
      "title": "Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding",
      "title_zh": "用于生成式语义通信的关键信息嵌入的视觉保真度指数",
      "authors": [
        "Jianhao Huang",
        "Qunsong Zeng",
        "Kaibin Huang"
      ],
      "abstract": "Generative semantic communication (Gen-SemCom) with large artificial\nintelligence (AI) model promises a transformative paradigm for 6G networks,\nwhich reduces communication costs by transmitting low-dimensional prompts\nrather than raw data. However, purely prompt-driven generation loses\nfine-grained visual details. Additionally, there is a lack of systematic\nmetrics to evaluate the performance of Gen-SemCom systems. To address these\nissues, we develop a hybrid Gen-SemCom system with a critical information\nembedding (CIE) framework, where both text prompts and semantically critical\nfeatures are extracted for transmissions. First, a novel approach of semantic\nfiltering is proposed to select and transmit the semantically critical features\nof images relevant to semantic label. By integrating the text prompt and\ncritical features, the receiver reconstructs high-fidelity images using a\ndiffusion-based generative model. Next, we propose the generative visual\ninformation fidelity (GVIF) metric to evaluate the visual quality of the\ngenerated image. By characterizing the statistical models of image features,\nthe GVIF metric quantifies the mutual information between the distorted\nfeatures and their original counterparts. By maximizing the GVIF metric, we\ndesign a channel-adaptive Gen-SemCom system that adaptively control the volume\nof features and compression rate according to the channel state. Experimental\nresults validate the GVIF metric's sensitivity to visual fidelity, correlating\nwith both the PSNR and critical information volume. In addition, the optimized\nsystem achieves superior performance over benchmarking schemes in terms of\nhigher PSNR and lower FID scores.",
      "tldr_zh": "该研究针对生成式语义通信(Gen-SemCom)在6G网络中的问题，提出了一种混合系统，结合关键信息嵌入(CIE)框架，通过语义过滤方法提取并传输文本提示和图像的关键语义特征，从而使用扩散模型(diffusion-based generative model)重建高保真图像。作者引入了生成式视觉信息保真度(GVIF)指标，该指标基于图像特征的统计模型量化失真特征与原始特征的互信息，用于评估生成的视觉质量。实验结果显示，GVIF指标对视觉保真度高度敏感，并与PSNR和关键信息量相关；优化后的信道自适应系统在PSNR和FID分数上显著优于基准方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10405v1",
      "published_date": "2025-05-15 15:28:32 UTC",
      "updated_date": "2025-05-15 15:28:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:15:27.900869"
    },
    {
      "arxiv_id": "2505.10402v1",
      "title": "Rethinking Repetition Problems of LLMs in Code Generation",
      "title_zh": "重新思考 LLMs 在代码生成中的重复问题",
      "authors": [
        "Yihong Dong",
        "Yuchen Liu",
        "Xue Jiang",
        "Zhi Jin",
        "Ge Li"
      ],
      "abstract": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code.",
      "tldr_zh": "本论文重新审视了 LLMs 在代码生成中的重复问题，不仅包括内容重复，还强调了更常见的结构重复，后者涉及固定结构但不同模式的代码。作者提出了一种高效解码方法 RPG（Repetition Penalization based on Grammar），通过利用语法规则识别重复并降低关键标记的概率，从而有效缓解这些问题。为此，论文构建了新数据集 CodeRepetEval 用于全面评估相关方案。实验结果显示，RPG 在 CodeRepetEval、HumanEval 和 MBPP 基准上显著优于基线，减少了重复并提升了生成的代码质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2025 (main)",
      "pdf_url": "http://arxiv.org/pdf/2505.10402v1",
      "published_date": "2025-05-15 15:26:32 UTC",
      "updated_date": "2025-05-15 15:26:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:15:39.675058"
    },
    {
      "arxiv_id": "2505.10399v1",
      "title": "Evaluating Model Explanations without Ground Truth",
      "title_zh": "翻译失败",
      "authors": [
        "Kaivalya Rawal",
        "Zihao Fu",
        "Eoin Delaney",
        "Chris Russell"
      ],
      "abstract": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth.",
      "tldr_zh": "该论文探讨了在缺乏“ground truth”理想解释的情况下评估模型解释的挑战，指出现有方法依赖于ground truth比较或模型敏感性检验的局限性。作者提出了三个desirable principles来指导解释评估策略的发展，并引入了ground-truth Agnostic eXplanation Evaluation框架（AXE），该框架无需访问ground truth或依赖模型敏感性，提供一个独立的解释质量衡量标准。通过与基线模型比较，AXE被验证有效，并能检测explanation fairwashing现象，为更可靠的模型解释评估提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "https://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth",
      "pdf_url": "http://arxiv.org/pdf/2505.10399v1",
      "published_date": "2025-05-15 15:22:06 UTC",
      "updated_date": "2025-05-15 15:22:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:15:51.608806"
    },
    {
      "arxiv_id": "2505.10603v1",
      "title": "Toward a Public and Secure Generative AI: A Comparative Analysis of Open and Closed LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jorge Machado"
      ],
      "abstract": "Generative artificial intelligence (Gen AI) systems represent a critical\ntechnology with far-reaching implications across multiple domains of society.\nHowever, their deployment entails a range of risks and challenges that require\ncareful evaluation. To date, there has been a lack of comprehensive,\ninterdisciplinary studies offering a systematic comparison between open-source\nand proprietary (closed) generative AI systems, particularly regarding their\nrespective advantages and drawbacks. This study aims to: i) critically evaluate\nand compare the characteristics, opportunities, and challenges of open and\nclosed generative AI models; and ii) propose foundational elements for the\ndevelopment of an Open, Public, and Safe Gen AI framework. As a methodology, we\nadopted a combined approach that integrates three methods: literature review,\ncritical analysis, and comparative analysis. The proposed framework outlines\nkey dimensions, openness, public governance, and security, as essential pillars\nfor shaping the future of trustworthy and inclusive Gen AI. Our findings reveal\nthat open models offer greater transparency, auditability, and flexibility,\nenabling independent scrutiny and bias mitigation. In contrast, closed systems\noften provide better technical support and ease of implementation, but at the\ncost of unequal access, accountability, and ethical oversight. The research\nalso highlights the importance of multi-stakeholder governance, environmental\nsustainability, and regulatory frameworks in ensuring responsible development.",
      "tldr_zh": "本研究比较了开源和封闭的大型语言模型(LLMs)生成式人工智能(Gen AI)的特性、优势和挑战，旨在评估其在透明度、审计性和伦理监督方面的差异。采用文献综述、批判分析和比较分析相结合的方法，研究发现开源模型提供更高的透明度、可审计性及灵活性，便于独立审查和偏见缓解，而封闭系统虽提供更好技术支持和易用性，但可能导致不平等访问和责任问题。最终，论文提出一个 Open, Public, and Safe Gen AI 框架，强调开放性、公共治理和安全作为关键支柱，以推动可信赖和包容性的 Gen AI 发展，并突出多利益相关者治理、环境可持续性和监管框架的重要性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10603v1",
      "published_date": "2025-05-15 15:21:09 UTC",
      "updated_date": "2025-05-15 15:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:16:04.265762"
    },
    {
      "arxiv_id": "2505.10394v1",
      "title": "Inconsistency Handling in DatalogMTL",
      "title_zh": "DatalogMTL 中的不一致性处理",
      "authors": [
        "Meghyn Bienvenu",
        "Camille Bourgaux",
        "Atefe Khodadaditaghanaki"
      ],
      "abstract": "In this paper, we explore the issue of inconsistency handling in DatalogMTL,\nan extension of Datalog with metric temporal operators. Since facts are\nassociated with time intervals, there are different manners to restore\nconsistency when they contradict the rules, such as removing facts or modifying\ntheir time intervals. Our first contribution is the definition of relevant\nnotions of conflicts (minimal explanations for inconsistency) and repairs\n(possible ways of restoring consistency) for this setting and the study of the\nproperties of these notions and the associated inconsistency-tolerant\nsemantics. Our second contribution is a data complexity analysis of the tasks\nof generating a single conflict / repair and query entailment under\nrepair-based semantics.",
      "tldr_zh": "这篇论文探讨了 DatalogMTL 中的不一致性处理问题，DatalogMTL 是 Datalog 的扩展，添加了 metric temporal operators，并将事实与时间区间关联。作者的主要贡献包括定义冲突（minimal explanations for inconsistency）和修复（repairs）的概念，并分析这些概念的属性以及相关的 inconsistency-tolerant semantics。论文还对生成单个冲突/修复任务以及在 repair-based semantics 下查询蕴含（query entailment）的数据复杂度进行了分析。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LO",
      "comment": "This is an extended version of a paper appearing at the 34th\n  International Joint Conference on Artificial Intelligence (IJCAI 2025). 24\n  pages",
      "pdf_url": "http://arxiv.org/pdf/2505.10394v1",
      "published_date": "2025-05-15 15:17:09 UTC",
      "updated_date": "2025-05-15 15:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:16:15.188997"
    },
    {
      "arxiv_id": "2505.10393v1",
      "title": "Uncovering Magnetic Phases with Synthetic Data and Physics-Informed Training",
      "title_zh": "通过合成数据和物理信息指导训练揭示磁相",
      "authors": [
        "Agustin Medina",
        "Marcelo Arlego",
        "Carlos A. Lamas"
      ],
      "abstract": "We investigate the efficient learning of magnetic phases using artificial\nneural networks trained on synthetic data, combining computational simplicity\nwith physics-informed strategies. Focusing on the diluted Ising model, which\nlacks an exact analytical solution, we explore two complementary approaches: a\nsupervised classification using simple dense neural networks, and an\nunsupervised detection of phase transitions using convolutional autoencoders\ntrained solely on idealized spin configurations.\n  To enhance model performance, we incorporate two key forms of\nphysics-informed guidance. First, we exploit architectural biases which\npreferentially amplify features related to symmetry breaking. Second, we\ninclude training configurations that explicitly break $\\mathbb{Z}_2$ symmetry,\nreinforcing the network's ability to detect ordered phases. These mechanisms,\nacting in tandem, increase the network's sensitivity to phase structure even in\nthe absence of explicit labels. We validate the machine learning predictions\nthrough comparison with direct numerical estimates of critical temperatures and\npercolation thresholds.\n  Our results show that synthetic, structured, and computationally efficient\ntraining schemes can reveal physically meaningful phase boundaries, even in\ncomplex systems. This framework offers a low-cost and robust alternative to\nconventional methods, with potential applications in broader condensed matter\nand statistical physics contexts.",
      "tldr_zh": "本文研究使用合成数据和物理信息指导（physics-informed guidance）训练人工神经网络（neural networks），以高效学习稀释 Ising 模型（diluted Ising model）的磁性相位（magnetic phases）。他们探索了监督分类（supervised classification）使用密集神经网络，以及无监督检测相变（unsupervised detection）使用卷积自编码器（convolutional autoencoders），并通过架构偏差和打破 $\\mathbb{Z}_2$ 对称性的训练配置增强网络对相结构的敏感性。实验结果验证了机器学习预测的准确性，与直接数值估计的临界温度（critical temperatures）和渗流阈值（percolation thresholds）相符，并证明了这种低成本框架在凝聚态物质和统计物理领域的潜在应用。",
      "categories": [
        "cond-mat.str-el",
        "cs.AI"
      ],
      "primary_category": "cond-mat.str-el",
      "comment": "25 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10393v1",
      "published_date": "2025-05-15 15:16:16 UTC",
      "updated_date": "2025-05-15 15:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:16:29.435074"
    },
    {
      "arxiv_id": "2505.10392v1",
      "title": "Schreier-Coset Graph Propagation",
      "title_zh": "Schreier-Coset 图传播",
      "authors": [
        "Aryan Mishra",
        "Lizhen Lin"
      ],
      "abstract": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications.",
      "tldr_zh": "本论文针对Graph Neural Networks (GNNs) 中的over-squashing 问题，提出Schreier-Coset Graph Propagation (SCGP) 作为一种群论增强方法，通过Schreier-coset embeddings 丰富节点特征，而不改变输入图拓扑，从而提升长距离消息传递效率。SCGP 嵌入无瓶颈的连接模式，保持计算高效性，并避免了如Cayley graphs 那样的可扩展性瓶颈。实验结果显示，SCGP 在标准节点和图分类基准上表现优于或相当于是expander graphs 和 rewired GNN 基线，尤其在处理分层和模块化图结构时，提供更低的推理延迟、更好的可扩展性和低内存占用，适合实时和资源受限应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 1 figure , preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.10392v1",
      "published_date": "2025-05-15 15:14:02 UTC",
      "updated_date": "2025-05-15 15:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:16:40.891490"
    },
    {
      "arxiv_id": "2505.10387v1",
      "title": "Multi-Agent Path Finding For Large Agents Is Intractable",
      "title_zh": "针对大型智能体的多智能体路径寻找是不可处理的",
      "authors": [
        "Artem Agafonov",
        "Konstantin Yakovlev"
      ],
      "abstract": "The multi-agent path finding (MAPF) problem asks to find a set of paths on a\ngraph such that when synchronously following these paths the agents never\nencounter a conflict. In the most widespread MAPF formulation, the so-called\nClassical MAPF, the agents sizes are neglected and two types of conflicts are\nconsidered: occupying the same vertex or using the same edge at the same time\nstep. Meanwhile in numerous practical applications, e.g. in robotics, taking\ninto account the agents' sizes is vital to ensure that the MAPF solutions can\nbe safely executed. Introducing large agents yields an additional type of\nconflict arising when one agent follows an edge and its body overlaps with the\nbody of another agent that is actually not using this same edge (e.g. staying\nstill at some distinct vertex of the graph). Until now it was not clear how\nharder the problem gets when such conflicts are to be considered while\nplanning. Specifically, it was known that Classical MAPF problem on an\nundirected graph can be solved in polynomial time, however no complete\npolynomial-time algorithm was presented to solve MAPF with large agents. In\nthis paper we, for the first time, establish that the latter problem is NP-hard\nand, thus, if P!=NP no polynomial algorithm for it can, unfortunately, be\npresented. Our proof is based on the prevalent in the field technique of\nreducing the seminal 3SAT problem (which is known to be an NP-complete problem)\nto the problem at hand. In particular, for an arbitrary 3SAT formula we\nprocedurally construct a dedicated graph with specific start and goal vertices\nand show that the given 3SAT formula is satisfiable iff the corresponding path\nfinding instance has a solution.",
      "tldr_zh": "该论文探讨了多智能体路径查找（Multi-Agent Path Finding, MAPF）问题，当代理体大小被考虑时会引入额外的冲突类型，例如一个代理体在移动时与其他静止代理体重叠。经典MAPF忽略代理体大小，仅需处理顶点或边冲突，因此可在无向图上以多项式时间求解。作者首次证明，考虑大型代理体的MAPF问题是NP-hard，通过将经典NP-complete问题3SAT归约到MAPF上来构建特定图实例，从而证明了给定3SAT公式可满足当且仅当对应的MAPF实例有解。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10387v1",
      "published_date": "2025-05-15 15:07:40 UTC",
      "updated_date": "2025-05-15 15:07:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:16:50.897295"
    },
    {
      "arxiv_id": "2505.10375v2",
      "title": "Are Sparse Autoencoders Useful for Java Function Bug Detection?",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Melo",
        "Claudia Mamede",
        "Andre Catarino",
        "Rui Abreu",
        "Henrique Lopes Cardoso"
      ],
      "abstract": "Software vulnerabilities such as buffer overflows and SQL injections are a\nmajor source of security breaches. Traditional methods for vulnerability\ndetection remain essential but are limited by high false positive rates,\nscalability issues, and reliance on manual effort. These constraints have\ndriven interest in AI-based approaches to automated vulnerability detection and\nsecure code generation. While Large Language Models (LLMs) have opened new\navenues for classification tasks, their complexity and opacity pose challenges\nfor interpretability and deployment. Sparse Autoencoder offer a promising\nsolution to this problem. We explore whether SAEs can serve as a lightweight,\ninterpretable alternative for bug detection in Java functions. We evaluate the\neffectiveness of SAEs when applied to representations from GPT-2 Small and\nGemma 2B, examining their capacity to highlight buggy behaviour without\nfine-tuning the underlying LLMs. We found that SAE-derived features enable bug\ndetection with an F1 score of up to 89%, consistently outperforming fine-tuned\ntransformer encoder baselines. Our work provides the first empirical evidence\nthat SAEs can be used to detect software bugs directly from the internal\nrepresentations of pretrained LLMs, without any fine-tuning or task-specific\nsupervision.",
      "tldr_zh": "本研究探讨了 Sparse Autoencoders (SAEs) 是否能作为一种轻量级、可解释的工具，用于检测 Java 函数中的软件漏洞，如缓冲区溢出和 SQL 注入，以克服传统方法的高假阳性率和可扩展性问题。研究者评估了 SAEs 在不微调 Large Language Models (LLMs) 的情况下，从 GPT-2 Small 和 Gemma 2B 的内部表示中提取特征进行漏洞检测。结果显示，SAE 派生特征实现了高达 89% 的 F1 分数，优于微调的 transformer 编码器基线，并提供了首个实证证据，证明 SAEs 可直接从预训练 LLM 的表示中检测漏洞，而无需任务特定监督。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10375v2",
      "published_date": "2025-05-15 14:59:17 UTC",
      "updated_date": "2025-05-21 20:27:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:17:04.098784"
    },
    {
      "arxiv_id": "2505.10371v1",
      "title": "ILIF: Temporal Inhibitory Leaky Integrate-and-Fire Neuron for Overactivation in Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Sun",
        "Peibo Duan",
        "Levin Kuhlmann",
        "Beilun Wang",
        "Bin Zhang"
      ],
      "abstract": "The Spiking Neural Network (SNN) has drawn increasing attention for its\nenergy-efficient, event-driven processing and biological plausibility. To train\nSNNs via backpropagation, surrogate gradients are used to approximate the\nnon-differentiable spike function, but they only maintain nonzero derivatives\nwithin a narrow range of membrane potentials near the firing threshold,\nreferred to as the surrogate gradient support width gamma. We identify a major\nchallenge, termed the dilemma of gamma: a relatively large gamma leads to\noveractivation, characterized by excessive neuron firing, which in turn\nincreases energy consumption, whereas a small gamma causes vanishing gradients\nand weakens temporal dependencies. To address this, we propose a temporal\nInhibitory Leaky Integrate-and-Fire (ILIF) neuron model, inspired by biological\ninhibitory mechanisms. This model incorporates interconnected inhibitory units\nfor membrane potential and current, effectively mitigating overactivation while\npreserving gradient propagation. Theoretical analysis demonstrates ILIF\neffectiveness in overcoming the gamma dilemma, and extensive experiments on\nmultiple datasets show that ILIF improves energy efficiency by reducing firing\nrates, stabilizes training, and enhances accuracy. The code is available at\ngithub.com/kaisun1/ILIF.",
      "tldr_zh": "本研究针对 Spiking Neural Networks (SNNs) 训练中的 gamma 困境提出解决方案，该困境导致过度激活（overactivation）增加能耗，或梯度消失（vanishing gradients）削弱时间依赖。作者开发了 Temporal Inhibitory Leaky Integrate-and-Fire (ILIF) 神经元模型，借鉴生物抑制机制，通过相互连接的抑制单元控制膜电位和电流，从而缓解过度激活同时保持梯度传播。实验在多个数据集上验证，ILIF 显著提高了能效、稳定了训练过程并提升了准确率，代码已在 GitHub 上公开。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10371v1",
      "published_date": "2025-05-15 14:56:06 UTC",
      "updated_date": "2025-05-15 14:56:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:17:15.825210"
    },
    {
      "arxiv_id": "2505.10361v1",
      "title": "Plasticity as the Mirror of Empowerment",
      "title_zh": "可塑性作为赋能的镜像",
      "authors": [
        "David Abel",
        "Michael Bowling",
        "André Barreto",
        "Will Dabney",
        "Shi Dong",
        "Steven Hansen",
        "Anna Harutyunyan",
        "Khimya Khetarpal",
        "Clare Lyle",
        "Razvan Pascanu",
        "Georgios Piliouras",
        "Doina Precup",
        "Jonathan Richens",
        "Mark Rowland",
        "Tom Schaul",
        "Satinder Singh"
      ],
      "abstract": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency.",
      "tldr_zh": "这篇论文引入了“plasticity”作为一种衡量代理（agents）被过去观察影响程度的通用指标，并将其与“empowerment”概念联系起来。作者使用“generalized directed information”这一新信息理论量来定义plasticity，并证明plasticity是empowerment的镜像，即代理的plasticity等同于环境的empowerment，反之亦然。同时，研究揭示了代理的plasticity和empowerment之间存在张力，强调在代理设计中需平衡两者，以更好地理解代理性及其在人工智能和认知科学中的含义。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10361v1",
      "published_date": "2025-05-15 14:52:16 UTC",
      "updated_date": "2025-05-15 14:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:17:26.859308"
    },
    {
      "arxiv_id": "2505.10360v1",
      "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation",
      "title_zh": "FactsR：一种更安全的方法，用于生成高质量的医疗保健文档",
      "authors": [
        "Victor Petrén Bach Hansen",
        "Lasse Krogsbøll",
        "Jonas Lyngsø",
        "Mathias Baltzersen",
        "Andreas Motzfeldt",
        "Kevin Pelgrims",
        "Lars Maaløe"
      ],
      "abstract": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support.",
      "tldr_zh": "这篇论文提出了 FactsR 方法，一种更安全的生成高质量医疗文档的框架，以解决现有 AI 记录工具依赖一次性提示导致的幻觉增加、错误风险和医生校对负担问题。FactsR 通过在医疗咨询过程中实时提取关键临床信息（Facts），并递归使用这些信息来生成最终笔记，从而确保文档更准确和简洁。同时，该方法将医生纳入笔记生成循环，提供实时决策支持，并显著提升患者安全。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10360v1",
      "published_date": "2025-05-15 14:51:22 UTC",
      "updated_date": "2025-05-15 14:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:17:39.038272"
    },
    {
      "arxiv_id": "2505.10352v1",
      "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity",
      "title_zh": "SpikeVideoFormer：一种高效的基于脉冲驱动的视频 Transformer，带有 Hamming 注意力以及 \\(\\mathcal",
      "authors": [
        "Shihao Zou",
        "Qingfeng Li",
        "Wei Ji",
        "Jingjing Li",
        "Yongkui Yang",
        "Guoqi Li",
        "Chao Dong"
      ],
      "abstract": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer",
      "tldr_zh": "该论文提出了一种高效的 spike-driven video Transformer 模型 SpikeVideoFormer，用于视频视觉任务，具有线性时间复杂度 \\(\\mathcal{O}(T)\\) 和 spike-driven Hamming attention (SDHA)。SDHA 通过从传统 attention 适配到 SNNs 框架，结合优化后的 space-time attention 设计，提升了模型在视频任务中的性能。实验结果显示，SpikeVideoFormer 在分类、人类姿势跟踪和语义分割任务上比现有 SNN 方法提升超过15%，并在效率上实现与 ANN 方法相当的性能，同时获得16倍、10倍和5倍的能效改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10352v1",
      "published_date": "2025-05-15 14:43:35 UTC",
      "updated_date": "2025-05-15 14:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:17:53.180125"
    },
    {
      "arxiv_id": "2505.10347v1",
      "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel S. Gama",
        "Valdir Grassi Jr"
      ],
      "abstract": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available.",
      "tldr_zh": "这篇论文比较了 Specialized Multi-Task Optimizers (SMTOs) 与 uniform loss 在 Multi-Task Learning 中的性能，评估 SMTOs 如何通过处理冲突梯度和不同梯度范数来平衡任务学习。研究通过广泛的实证实验，包括最新 SMTOs 方法，在更复杂的多任务问题上进行测试，发现 SMTOs 整体优于 uniform loss，而固定权重方法也能实现与 SMTOs 相媲美的结果。论文进一步解释了 uniform loss 在某些情况下表现类似的原因，并计划公开代码以便进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10347v1",
      "published_date": "2025-05-15 14:34:36 UTC",
      "updated_date": "2025-05-15 14:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:18:03.411995"
    },
    {
      "arxiv_id": "2505.10331v1",
      "title": "Emergence of Structure in Ensembles of Random Neural Networks",
      "title_zh": "随机神经网络集成中的结构涌现",
      "authors": [
        "Luca Muscarnera",
        "Luigi Loreti",
        "Giovanni Todeschini",
        "Alessio Fumagalli",
        "Francesco Regazzoni"
      ],
      "abstract": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon.",
      "tldr_zh": "这篇论文研究了随机神经网络集合中结构的涌现，提出一个理论模型来分析随机分类器ensemble的集体行为。作者通过Gibbs measure加权ensemble（以分类损失作为能量），证明存在一个最优温度参数，使得分类性能相对于损失达到最优，且在高斯分布样本和教师perceptron标签的场景下，此温度不依赖于未知的教师分类器或分类器数量，展现出普遍性。在MNIST数据集上的实验验证了这一现象的相关性，并通过物理类比解释了其自组织性质。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10331v1",
      "published_date": "2025-05-15 14:20:02 UTC",
      "updated_date": "2025-05-15 14:20:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:18:15.715111"
    },
    {
      "arxiv_id": "2505.10330v1",
      "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change",
      "title_zh": "强化学习代理对突然环境变化的高效适应",
      "authors": [
        "Jonathan Clifford Balloch"
      ],
      "abstract": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components.",
      "tldr_zh": "该论文探讨了强化学习（RL）代理在真实世界环境中面对突发变化时的适应挑战，传统RL方法因数据密集和假设静态环境而难以高效调整，导致灾难性遗忘。论文证明了高效在线适应的两个关键能力：（1）优先级探索和采样策略，用于识别和学习相关经验；（2）通过结构化表示选择性保留先验知识，从而允许更新而不破坏可重用组件。这些发现为RL代理在动态环境中实现鲁棒性和持续学习提供了重要基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "PhD Dissertation, 131 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.10330v1",
      "published_date": "2025-05-15 14:19:01 UTC",
      "updated_date": "2025-05-15 14:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:18:27.489355"
    },
    {
      "arxiv_id": "2505.10328v1",
      "title": "A Comparative Study of SMT and MILP for the Nurse Rostering Problem",
      "title_zh": "SMT 和 MILP 在护士排班问题中的比较研究",
      "authors": [
        "Alvin Combrink",
        "Stephie Do",
        "Kristofer Bengtsson",
        "Sabino Francesco Roselli",
        "Martin Fabian"
      ],
      "abstract": "The effects of personnel scheduling on the quality of care and working\nconditions for healthcare personnel have been thoroughly documented. However,\nthe ever-present demand and large variation of constraints make healthcare\nscheduling particularly challenging. This problem has been studied for decades,\nwith limited research aimed at applying Satisfiability Modulo Theories (SMT).\nSMT has gained momentum within the formal verification community in the last\ndecades, leading to the advancement of SMT solvers that have been shown to\noutperform standard mathematical programming techniques.\n  In this work, we propose generic constraint formulations that can model a\nwide range of real-world scheduling constraints. Then, the generic constraints\nare formulated as SMT and MILP problems and used to compare the respective\nstate-of-the-art solvers, Z3 and Gurobi, on academic and real-world inspired\nrostering problems. Experimental results show how each solver excels for\ncertain types of problems; the MILP solver generally performs better when the\nproblem is highly constrained or infeasible, while the SMT solver performs\nbetter otherwise. On real-world inspired problems containing a more varied set\nof shifts and personnel, the SMT solver excels. Additionally, it was noted\nduring experimentation that the SMT solver was more sensitive to the way the\ngeneric constraints were formulated, requiring careful consideration and\nexperimentation to achieve better performance. We conclude that SMT-based\nmethods present a promising avenue for future research within the domain of\npersonnel scheduling.",
      "tldr_zh": "这篇论文比较了 Satisfiability Modulo Theories (SMT) 和 Mixed-Integer Linear Programming (MILP) 在护理排班问题中的应用，提出了一种通用约束表述来处理真实世界的各种排班约束。研究者使用 SMT 求解器 Z3 和 MILP 求解器 Gurobi 对学术和真实世界灵感问题进行实验，结果显示 MILP 在高度约束或不可行问题中表现更佳，而 SMT 在包含多样化班次和人员的复杂场景中更具优势。论文还指出，SMT 求解器对约束表述更敏感，需要精细调整，并认为 SMT 方法为未来人员排班研究提供了有前景的途径。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10328v1",
      "published_date": "2025-05-15 14:12:39 UTC",
      "updated_date": "2025-05-15 14:12:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:18:40.462786"
    },
    {
      "arxiv_id": "2505.10321v1",
      "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents",
      "title_zh": "AutoPentest：利用自治 LLM 代理增强漏洞管理",
      "authors": [
        "Julius Henke"
      ],
      "abstract": "A recent area of increasing research is the use of Large Language Models\n(LLMs) in penetration testing, which promises to reduce costs and thus allow\nfor higher frequency. We conduct a review of related work, identifying best\npractices and common evaluation issues. We then present AutoPentest, an\napplication for performing black-box penetration tests with a high degree of\nautonomy. AutoPentest is based on the LLM GPT-4o from OpenAI and the LLM agent\nframework LangChain. It can perform complex multi-step tasks, augmented by\nexternal tools and knowledge bases. We conduct a study on three\ncapture-the-flag style Hack The Box (HTB) machines, comparing our\nimplementation AutoPentest with the baseline approach of manually using the\nChatGPT-4o user interface. Both approaches are able to complete 15-25 % of the\nsubtasks on the HTB machines, with AutoPentest slightly outperforming ChatGPT.\nWe measure a total cost of \\$96.20 US when using AutoPentest across all\nexperiments, while a one-month subscription to ChatGPT Plus costs \\$20. The\nresults show that further implementation efforts and the use of more powerful\nLLMs released in the future are likely to make this a viable part of\nvulnerability management.",
      "tldr_zh": "该论文回顾了大型语言模型(LLM)在渗透测试中的应用，并提出了AutoPentest，一种基于GPT-4o和LangChain框架的自治代理系统，用于进行黑盒渗透测试。该系统通过整合外部工具和知识库，能处理复杂多步任务，在Hack The Box(HTB)机器上的实验中，AutoPentest与手动ChatGPT-4o均完成15-25%的子任务，且AutoPentest略有优势，总成本为96.20美元。研究结果表明，进一步优化和使用更先进的LLM可能使AutoPentest成为漏洞管理的重要工具。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "24 pages, 1 figure, for implementation, see\n  https://github.com/JuliusHenke/autopentest",
      "pdf_url": "http://arxiv.org/pdf/2505.10321v1",
      "published_date": "2025-05-15 14:06:00 UTC",
      "updated_date": "2025-05-15 14:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:18:52.597123"
    },
    {
      "arxiv_id": "2505.10320v1",
      "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chenxi Whitehouse",
        "Tianlu Wang",
        "Ping Yu",
        "Xian Li",
        "Jason Weston",
        "Ilia Kulikov",
        "Swarnadeep Saha"
      ],
      "abstract": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses.",
      "tldr_zh": "本研究引入了 J1 方法，通过强化学习（Reinforcement Learning）训练 LLM-as-a-Judge 模型，以激励其进行更强的 chain-of-thought 推理，从而提升判断能力。J1 将可验证和不可验证的提示转换为带有可验证奖励的判断任务，减少偏见，并在 8B 或 70B 模型规模上超越了现有模型，包括从 DeepSeek-R1 蒸馏的版本，甚至在某些基准上超过了 o1-mini 和 R1。实验分析比较了 Pairwise-J1 与 Pointwise-J1、离线与在线训练、奖励策略等变体，发现模型通过学习概述评估标准、与自生成参考答案比较以及重新评估响应正确性，实现了更准确的判断。总的来说，J1 为改进 AI 评估质量提供了有效框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 8 tables, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10320v1",
      "published_date": "2025-05-15 14:05:15 UTC",
      "updated_date": "2025-05-15 14:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:19:04.250790"
    },
    {
      "arxiv_id": "2505.10600v1",
      "title": "Enhancing IoT Cyber Attack Detection in the Presence of Highly Imbalanced Data",
      "title_zh": "在高度不平衡数据存在的情况下增强 IoT 网络攻击检测",
      "authors": [
        "Md. Ehsanul Haque",
        "Md. Saymon Hosen Polash",
        "Md Al-Imran Sanjida Simla",
        "Md Alomgir Hossain",
        "Sarwar Jahan"
      ],
      "abstract": "Due to the rapid growth in the number of Internet of Things (IoT) networks,\nthe cyber risk has increased exponentially, and therefore, we have to develop\neffective IDS that can work well with highly imbalanced datasets. A high rate\nof missed threats can be the result, as traditional machine learning models\ntend to struggle in identifying attacks when normal data volume is much higher\nthan the volume of attacks. For example, the dataset used in this study reveals\na strong class imbalance with 94,659 instances of the majority class and only\n28 instances of the minority class, making it quite challenging to determine\nrare attacks accurately. The challenges presented in this research are\naddressed by hybrid sampling techniques designed to improve data imbalance\ndetection accuracy in IoT domains. After applying these techniques, we evaluate\nthe performance of several machine learning models such as Random Forest, Soft\nVoting, Support Vector Classifier (SVC), K-Nearest Neighbors (KNN), Multi-Layer\nPerceptron (MLP), and Logistic Regression with respect to the classification of\ncyber-attacks. The obtained results indicate that the Random Forest model\nachieved the best performance with a Kappa score of 0.9903, test accuracy of\n0.9961, and AUC of 0.9994. Strong performance is also shown by the Soft Voting\nmodel, with an accuracy of 0.9952 and AUC of 0.9997, indicating the benefits of\ncombining model predictions. Overall, this work demonstrates the value of\nhybrid sampling combined with robust model and feature selection for\nsignificantly improving IoT security against cyber-attacks, especially in\nhighly imbalanced data environments.",
      "tldr_zh": "该研究针对物联网（IoT）网络中高度不平衡数据的问题，开发了增强网络攻击检测的方法，以解决传统机器学习模型在多数类数据（如正常流量）远多于少数类数据（如攻击）时的检测挑战。研究采用混合采样技术来平衡数据集，并评估了多种模型，包括 Random Forest、Soft Voting、SVC、KNN、MLP 和 Logistic Regression。结果表明，Random Forest 模型表现出色，Kappa score 达 0.9903、测试准确率 0.9961 和 AUC 0.9994，而 Soft Voting 模型也实现了 0.9952 的准确率和 0.9997 的 AUC。该方法证明了混合采样结合鲁棒模型选择的有效性，能够显著提升 IoT 环境下的网络安全防护。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Published paper of CSNT2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10600v1",
      "published_date": "2025-05-15 14:02:48 UTC",
      "updated_date": "2025-05-15 14:02:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:19:16.357026"
    },
    {
      "arxiv_id": "2505.10315v1",
      "title": "Private Transformer Inference in MLaaS: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Li",
        "Xinyu Zhou",
        "Yitong Wang",
        "Liangxin Qian",
        "Jun Zhao"
      ],
      "abstract": "Transformer models have revolutionized AI, powering applications like content\ngeneration and sentiment analysis. However, their deployment in Machine\nLearning as a Service (MLaaS) raises significant privacy concerns, primarily\ndue to the centralized processing of sensitive user data. Private Transformer\nInference (PTI) offers a solution by utilizing cryptographic techniques such as\nsecure multi-party computation and homomorphic encryption, enabling inference\nwhile preserving both user data and model privacy. This paper reviews recent\nPTI advancements, highlighting state-of-the-art solutions and challenges. We\nalso introduce a structured taxonomy and evaluation framework for PTI, focusing\non balancing resource efficiency with privacy and bridging the gap between\nhigh-performance inference and data privacy.",
      "tldr_zh": "Transformer 模型在 MLaaS（Machine Learning as a Service）中的部署引发了隐私担忧，主要由于敏感用户数据的集中处理。论文调查了 Private Transformer Inference (PTI)，通过 secure multi-party computation 和 homomorphic encryption 等加密技术，实现推理过程的同时保护用户数据和模型隐私。作者回顾了 PTI 的最新进展、挑战和最先进解决方案，并引入了结构化的 taxonomy 和 evaluation framework，以平衡资源效率和隐私水平，并桥接高性能推理与数据隐私之间的差距。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10315v1",
      "published_date": "2025-05-15 14:00:19 UTC",
      "updated_date": "2025-05-15 14:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:19:30.099706"
    },
    {
      "arxiv_id": "2505.10309v1",
      "title": "Empirically evaluating commonsense intelligence in large language models with large-scale human judgments",
      "title_zh": "通过大规模人类判断对大型语言模型中的常识智能进行实证评估",
      "authors": [
        "Tuan Dung Nguyen",
        "Duncan J. Watts",
        "Mark E. Whiting"
      ],
      "abstract": "Commonsense intelligence in machines is often assessed by static benchmarks\nthat compare a model's output against human-prescribed correct labels. An\nimportant, albeit implicit, assumption of these labels is that they accurately\ncapture what any human would think, effectively treating human common sense as\nhomogeneous. However, recent empirical work has shown that humans vary\nenormously in what they consider commonsensical; thus what appears self-evident\nto one benchmark designer may not be so to another. Here, we propose a novel\nmethod for evaluating common sense in artificial intelligence (AI),\nspecifically in large language models (LLMs), that incorporates empirically\nobserved heterogeneity among humans by measuring the correspondence between a\nmodel's judgment and that of a human population. We first find that, when\ntreated as independent survey respondents, most LLMs remain below the human\nmedian in their individual commonsense competence. Second, when used as\nsimulators of a hypothetical population, LLMs correlate with real humans only\nmodestly in the extent to which they agree on the same set of statements. In\nboth cases, smaller, open-weight models are surprisingly more competitive than\nlarger, proprietary frontier models. Our evaluation framework, which ties\ncommonsense intelligence to its cultural basis, contributes to the growing call\nfor adapting AI models to human collectivities that possess different, often\nincompatible, social stocks of knowledge.",
      "tldr_zh": "该研究质疑了传统静态基准对大型语言模型(LLMs)常识智能的评估方法，指出这些基准忽略了人类常识的异质性，并提出一种新框架，通过大规模人类判断来测量模型判断与人类人群判断的对应性。实验结果显示，作为独立调查响应者，大多数LLMs在常识能力上低于人类中位数，而作为模拟器时，LLMs与真实人类的共识相关性仅为适中，且小型开源模型的表现优于大型专有模型。该框架强调常识的文化基础，呼吁AI模型适应不同社会知识背景以提升其适用性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10309v1",
      "published_date": "2025-05-15 13:55:27 UTC",
      "updated_date": "2025-05-15 13:55:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:19:39.131178"
    },
    {
      "arxiv_id": "2505.10300v1",
      "title": "AI LEGO: Scaffolding Cross-Functional Collaboration in Industrial Responsible AI Practices during Early Design Stages",
      "title_zh": "翻译失败",
      "authors": [
        "Muzhe Wu",
        "Yanzhi Zhao",
        "Shuyi Han",
        "Michael Xieyang Liu",
        "Hong Shen"
      ],
      "abstract": "Responsible AI (RAI) efforts increasingly emphasize the importance of\naddressing potential harms early in the AI development lifecycle through\nsocial-technical lenses. However, in cross-functional industry teams, this work\nis often stalled by a persistent knowledge handoff challenge: the difficulty of\ntransferring high-level, early-stage technical design rationales from technical\nexperts to non-technical or user-facing roles for ethical evaluation and harm\nidentification. Through literature review and a co-design study with 8\npractitioners, we unpack how this challenge manifests -- technical design\nchoices are rarely handed off in ways that support meaningful engagement by\nnon-technical roles; collaborative workflows lack shared, visual structures to\nsupport mutual understanding; and non-technical practitioners are left without\nscaffolds for systematic harm evaluation. Existing tools like JIRA or Google\nDocs, while useful for product tracking, are ill-suited for supporting joint\nharm identification across roles, often requiring significant extra effort to\nalign understanding. To address this, we developed AI LEGO, a web-based\nprototype that supports cross-functional AI practitioners in effectively\nfacilitating knowledge handoff and identifying harmful design choices in the\nearly design stages. Technical roles use interactive blocks to draft\ndevelopment plans, while non-technical roles engage with those blocks through\nstage-specific checklists and LLM-driven persona simulations to surface\npotential harms. In a study with 18 cross-functional practitioners, AI LEGO\nincreased the volume and likelihood of harms identified compared to baseline\nworksheets. Participants found that its modular structure and persona prompts\nmade harm identification more accessible, fostering clearer and more\ncollaborative RAI practices in early design.",
      "tldr_zh": "本文研究了工业 Responsible AI (RAI) 实践中的知识传递挑战，特别是在早期设计阶段，技术专家难以将设计理由传达给非技术角色，导致危害识别不足。通过文献回顾和与8名从业者的共同设计研究，作者开发了AI LEGO，一个基于网络的原型工具。该工具允许技术角色使用交互块草拟开发计划，非技术角色则通过阶段特定检查列表和LLM驱动的角色模拟来识别潜在危害。在实验中，AI LEGO相较于基线工作表显著提高了危害识别的数量和可能性，促进了跨功能团队的协作和更有效的RAI实践。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10300v1",
      "published_date": "2025-05-15 13:49:02 UTC",
      "updated_date": "2025-05-15 13:49:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:19:52.196961"
    },
    {
      "arxiv_id": "2505.10297v1",
      "title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning",
      "title_zh": "防御边缘：代表性注意力用于缓解联邦学习中的后门攻击",
      "authors": [
        "Chibueze Peace Obioma",
        "Youcheng Sun",
        "Mustafa A. Mustafa"
      ],
      "abstract": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments.",
      "tldr_zh": "该论文针对联邦学习（Federated Learning, FL）中后门攻击（backdoor attacks）问题，提出了一种新型防御机制FeRA（Federated Representative-Attention-based Defense）。FeRA通过跨客户端注意力（cross-client attention）机制分析内部特征表示，并基于表示重建错误（representation reconstruction errors）计算异常分数，以识别和隔离恶意客户端。实验结果显示，FeRA在非-IID数据分布的边缘设备场景下有效降低了后门攻击成功率，同时保持了主任务的高准确率，且该方法模型无关、攻击无关，且无需标记的参考数据，适合资源受限的部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to ESORICS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10297v1",
      "published_date": "2025-05-15 13:44:32 UTC",
      "updated_date": "2025-05-15 13:44:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:20:03.784257"
    },
    {
      "arxiv_id": "2505.10278v1",
      "title": "MASS: Multi-Agent Simulation Scaling for Portfolio Construction",
      "title_zh": "翻译失败",
      "authors": [
        "Taian Guo",
        "Haiyang Shen",
        "Jinsheng Huang",
        "Zhengyang Mao",
        "Junyu Luo",
        "Zhuoru Chen",
        "Xuhui Liu",
        "Bingyu Xia",
        "Luchen Liu",
        "Yun Ma",
        "Ming Zhang"
      ],
      "abstract": "LLM-based multi-agent has gained significant attention for their potential in\nsimulation and enhancing performance. However, existing works are limited to\npure simulations or are constrained by predefined workflows, restricting their\napplicability and effectiveness. In this paper, we introduce the Multi-Agent\nScaling Simulation (MASS) for portfolio construction. MASS achieves stable and\ncontinuous excess returns by progressively increasing the number of agents for\nlarge-scale simulations to gain a superior understanding of the market and\noptimizing agent distribution end-to-end through a reverse optimization\nprocess, rather than relying on a fixed workflow. We demonstrate its\nsuperiority through performance experiments, ablation studies, backtesting\nexperiments, experiments on updated data and stock pools, scaling experiments,\nparameter sensitivity experiments, and visualization experiments, conducted in\ncomparison with 6 state-of-the-art baselines on 3 challenging A-share stock\npools. We expect the paradigm established by MASS to expand to other tasks with\nsimilar characteristics. The implementation of MASS has been open-sourced at\nhttps://github.com/gta0804/MASS.",
      "tldr_zh": "本文提出 Multi-Agent Scaling Simulation (MASS) 框架，用于投资组合构建，通过逐步增加代理数量进行大规模模拟，以获得对市场的更深入理解，并通过反向优化过程端到端优化代理分布，从而实现稳定且持续的超额回报，而非依赖预定义工作流。相比现有 LLM-based multi-agent 方法，MASS 克服了纯模拟的局限性，并在性能实验、消融研究、回测等测试中，与6个最先进基线在3个挑战性的A股股票池上表现出29.32%的准确率提升。该框架的开源实现（https://github.com/gta0804/MASS）有望扩展到其他类似任务中。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10278v1",
      "published_date": "2025-05-15 13:27:18 UTC",
      "updated_date": "2025-05-15 13:27:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:20:16.242203"
    },
    {
      "arxiv_id": "2505.10273v1",
      "title": "AttentionGuard: Transformer-based Misbehavior Detection for Secure Vehicular Platoons",
      "title_zh": "翻译失败",
      "authors": [
        "Hexu Li",
        "Konstantinos Kalogiannis",
        "Ahmed Mohamed Hussain",
        "Panos Papadimitratos"
      ],
      "abstract": "Vehicle platooning, with vehicles traveling in close formation coordinated\nthrough Vehicle-to-Everything (V2X) communications, offers significant benefits\nin fuel efficiency and road utilization. However, it is vulnerable to\nsophisticated falsification attacks by authenticated insiders that can\ndestabilize the formation and potentially cause catastrophic collisions. This\npaper addresses this challenge: misbehavior detection in vehicle platooning\nsystems. We present AttentionGuard, a transformer-based framework for\nmisbehavior detection that leverages the self-attention mechanism to identify\nanomalous patterns in mobility data. Our proposal employs a multi-head\ntransformer-encoder to process sequential kinematic information, enabling\neffective differentiation between normal mobility patterns and falsification\nattacks across diverse platooning scenarios, including steady-state\n(no-maneuver) operation, join, and exit maneuvers. Our evaluation uses an\nextensive simulation dataset featuring various attack vectors (constant,\ngradual, and combined falsifications) and operational parameters (controller\ntypes, vehicle speeds, and attacker positions). Experimental results\ndemonstrate that AttentionGuard achieves up to 0.95 F1-score in attack\ndetection, with robust performance maintained during complex maneuvers.\nNotably, our system performs effectively with minimal latency (100ms decision\nintervals), making it suitable for real-time transportation safety\napplications. Comparative analysis reveals superior detection capabilities and\nestablishes the transformer-encoder as a promising approach for securing\nCooperative Intelligent Transport Systems (C-ITS) against sophisticated insider\nthreats.",
      "tldr_zh": "本研究针对车辆编队（Vehicle platooning）系统易受认证内部攻击者的伪造攻击问题，提出AttentionGuard，一种基于Transformer的异常行为检测框架。该框架利用多头Transformer-encoder处理序列运动数据，通过自注意力机制有效识别正常模式与攻击模式，在稳态、加入和退出等场景中表现出色。实验结果显示，AttentionGuard在各种攻击类型下实现高达0.95的F1-score，同时保持最低延迟（100ms），优于现有方法，并为安全合作智能交通系统（C-ITS）提供可靠的实时防护。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "Author's version; Accepted for presentation at the ACM Workshop on\n  Wireless Security and Machine Learning (WiseML 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.10273v1",
      "published_date": "2025-05-15 13:24:09 UTC",
      "updated_date": "2025-05-15 13:24:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:20:27.618552"
    },
    {
      "arxiv_id": "2505.10264v1",
      "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Diana",
        "André Nusser",
        "Chuan Xu",
        "Giovanni Neglia"
      ],
      "abstract": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art.",
      "tldr_zh": "本研究揭示了Federated Learning中隐私保护的脆弱性，提出了一种基于超平面的数据重建攻击，以克服现有方法的局限，如对客户端数据分布的依赖和批量大小限制。该攻击利用全连接层的几何视角构建恶意模型参数，能够在不需任何先验知识的情况下完美恢复任意大的数据批量。通过在图像和表格数据集上的广泛实验，该方法优于现有攻击，并实现了比最先进技术大两个数量级的完美数据重建。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10264v1",
      "published_date": "2025-05-15 13:16:32 UTC",
      "updated_date": "2025-05-15 13:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:20:39.164367"
    },
    {
      "arxiv_id": "2505.10261v1",
      "title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Yang",
        "Huitao Li",
        "Matthew Yu Heng Wong",
        "Yuhe Ke",
        "Xin Li",
        "Kunyu Yu",
        "Jingchi Liao",
        "Jonathan Chong Kai Liew",
        "Sabarinath Vinod Nair",
        "Jasmine Chiat Ling Ong",
        "Irene Li",
        "Douglas Teodoro",
        "Chuan Hong",
        "Daniel Shu Wei Ting",
        "Nan Liu"
      ],
      "abstract": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications.",
      "tldr_zh": "这篇论文探讨了生成式大型语言模型 (LLMs) 与传统自然语言处理 (NLP) 在医学领域的演变，通过分析 19,123 篇研究来比较二者在不同任务中的表现。结果显示，LLMs 在开放式任务中表现出显著优势，而传统 NLP 在信息提取和分析任务中更具主导性。随着这些技术的快速发展，论文强调确保其在医疗应用中的道德使用至关重要，以充分发挥其潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10261v1",
      "published_date": "2025-05-15 13:11:14 UTC",
      "updated_date": "2025-05-15 13:11:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:20:51.433054"
    },
    {
      "arxiv_id": "2505.10260v1",
      "title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data",
      "title_zh": "比较 LLM 文本标注技能：关于社交媒体数据中人权侵犯的研究",
      "authors": [
        "Poli Apollinaire Nemkova",
        "Solomon Ubani",
        "Mark V. Albert"
      ],
      "abstract": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios.",
      "tldr_zh": "这篇论文比较了多种大型语言模型（LLMs）如 GPT-3.5、GPT-4、LLAMA3、Mistral 7B 和 Claude-2 在零-shot 和 few-shot 设置下，对俄语和乌克兰语社交媒体数据的文本标注能力，焦点是二元分类任务——识别人类权利侵犯的提及。研究通过将模型的标注结果与人类双重标注的金标准数据集（1000个样本）进行比较，评估了不同提示条件（英语和俄语提示）下的性能。分析揭示了每个模型的独特错误模式、优势、限制以及跨语言适应性，为理解 LLMs 在敏感、多语言语境中的可靠性和适用性提供了关键洞见。最终，该研究强调了 LLMs 处理主观性强、上下文依赖任务的挑战，为其在真实场景中的部署提供了指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10260v1",
      "published_date": "2025-05-15 13:10:47 UTC",
      "updated_date": "2025-05-15 13:10:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:21:05.944090"
    },
    {
      "arxiv_id": "2505.10599v1",
      "title": "UDDETTS: Unifying Discrete and Dimensional Emotions for Controllable Emotional Text-to-Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxuan Liu",
        "Zhenhua Ling"
      ],
      "abstract": "Recent neural codec language models have made great progress in the field of\ntext-to-speech (TTS), but controllable emotional TTS still faces many\nchallenges. Traditional methods rely on predefined discrete emotion labels to\ncontrol emotion categories and intensities, which can't capture the complexity\nand continuity of human emotional perception and expression. The lack of\nlarge-scale emotional speech datasets with balanced emotion distributions and\nfine-grained emotion annotations often causes overfitting in synthesis models\nand impedes effective emotion control. To address these issues, we propose\nUDDETTS, a neural codec language model unifying discrete and dimensional\nemotions for controllable emotional TTS. This model introduces the\ninterpretable Arousal-Dominance-Valence (ADV) space for dimensional emotion\ndescription and supports emotion control driven by either discrete emotion\nlabels or nonlinearly quantified ADV values. Furthermore, a semi-supervised\ntraining strategy is designed to comprehensively utilize diverse speech\ndatasets with different types of emotion annotations to train the UDDETTS.\nExperiments show that UDDETTS achieves linear emotion control along the three\ndimensions of ADV space, and exhibits superior end-to-end emotional speech\nsynthesis capabilities.",
      "tldr_zh": "该论文提出了 UDDETTS，一种统一离散和维度情感的神经编解码器语言模型，用于解决可控情感 Text-to-Speech (TTS) 的挑战。模型引入了可解释的 Arousal-Dominance-Valence (ADV) 空间来描述维度情感，支持基于离散情感标签或非线性量化 ADV 值的控制，并采用半监督训练策略充分利用多样语音数据集。实验结果表明，UDDETTS 实现了 ADV 空间的三维线性情感控制，并展现了优越的端到端情感语音合成能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2505.10599v1",
      "published_date": "2025-05-15 12:57:19 UTC",
      "updated_date": "2025-05-15 12:57:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:21:15.970338"
    },
    {
      "arxiv_id": "2505.10231v1",
      "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhe Luo",
        "Ziyu Zhou",
        "Zixin Shu",
        "Aurélie Pahud de Mortanges",
        "Robert Berke",
        "Mauricio Reyes"
      ],
      "abstract": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner.",
      "tldr_zh": "这项研究首次系统探讨了Human-AI alignment、fairness和performance trade-offs在医疗成像中的相互作用，发现融入人类洞见能有效减少不同人群间的公平差距，并提升模型的领域外泛化能力。实验结果显示，虽然Human-AI alignment通常有益，但过度调整可能导致性能权衡，因此需要制定校准策略。总体而言，该方法为开发公平、鲁棒且可泛化的医疗AI系统提供了有前景的途径，并公开了相关代码以供参考。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10231v1",
      "published_date": "2025-05-15 12:43:23 UTC",
      "updated_date": "2025-05-15 12:43:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:21:26.725826"
    },
    {
      "arxiv_id": "2505.10212v1",
      "title": "Do LLMs Memorize Recommendation Datasets? A Preliminary Study on MovieLens-1M",
      "title_zh": "翻译失败",
      "authors": [
        "Dario Di Palma",
        "Felice Antonio Merra",
        "Maurizio Sfilio",
        "Vito Walter Anelli",
        "Fedelucio Narducci",
        "Tommaso Di Noia"
      ],
      "abstract": "Large Language Models (LLMs) have become increasingly central to\nrecommendation scenarios due to their remarkable natural language understanding\nand generation capabilities. Although significant research has explored the use\nof LLMs for various recommendation tasks, little effort has been dedicated to\nverifying whether they have memorized public recommendation dataset as part of\ntheir training data. This is undesirable because memorization reduces the\ngeneralizability of research findings, as benchmarking on memorized datasets\ndoes not guarantee generalization to unseen datasets. Furthermore, memorization\ncan amplify biases, for example, some popular items may be recommended more\nfrequently than others.\n  In this work, we investigate whether LLMs have memorized public\nrecommendation datasets. Specifically, we examine two model families (GPT and\nLlama) across multiple sizes, focusing on one of the most widely used dataset\nin recommender systems: MovieLens-1M. First, we define dataset memorization as\nthe extent to which item attributes, user profiles, and user-item interactions\ncan be retrieved by prompting the LLMs. Second, we analyze the impact of\nmemorization on recommendation performance. Lastly, we examine whether\nmemorization varies across model families and model sizes. Our results reveal\nthat all models exhibit some degree of memorization of MovieLens-1M, and that\nrecommendation performance is related to the extent of memorization. We have\nmade all the code publicly available at:\nhttps://github.com/sisinflab/LLM-MemoryInspector",
      "tldr_zh": "本研究探讨大型语言模型(LLMs)是否记忆公共推荐数据集，特别针对MovieLens-1M数据集，旨在评估记忆对模型泛化性和偏见放大的影响。研究方法包括定义记忆程度（通过提示检索项目属性、用户资料和用户-项目交互）、分析记忆对推荐性能的影响，并比较GPT和Llama系列不同规模模型的差异。结果显示，所有测试模型均存在一定程度的记忆，且记忆程度与推荐性能密切相关。该工作公开了代码，提醒研究者需注意数据集记忆问题以提升模型的可靠性和泛化能力。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10212v1",
      "published_date": "2025-05-15 12:16:36 UTC",
      "updated_date": "2025-05-15 12:16:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:21:40.709282"
    },
    {
      "arxiv_id": "2505.10201v1",
      "title": "A Fine-Grained Complexity View on Propositional Abduction -- Algorithms and Lower Bounds",
      "title_zh": "翻译失败",
      "authors": [
        "Victor Lagerkvist",
        "Mohamed Maizia",
        "Johannes Schmidt"
      ],
      "abstract": "The Boolean satisfiability problem (SAT) is a well-known example of monotonic\nreasoning, of intense practical interest due to fast solvers, complemented by\nrigorous fine-grained complexity results. However, for non-monotonic reasoning,\ne.g., abductive reasoning, comparably little is known outside classic\ncomplexity theory. In this paper we take a first step of bridging the gap\nbetween monotonic and non-monotonic reasoning by analyzing the complexity of\nintractable abduction problems under the seemingly overlooked but natural\nparameter n: the number of variables in the knowledge base. We obtain several\npositive results for $\\Sigma^P_2$- as well as NP- and coNP-complete fragments,\nwhich implies the first example of beating exhaustive search for a\n$\\Sigma^P_2$-complete problem (to the best of our knowledge). We complement\nthis with lower bounds and for many fragments rule out improvements under the\n(strong) exponential-time hypothesis.",
      "tldr_zh": "本论文探讨了命题溯因(Propositional Abduction)的精细复杂度，分析了以知识库中变量数量n作为参数的不可解问题，旨在桥接单调推理（如SAT）和非单调推理之间的差距。研究者开发了针对Σ^P_2-complete、NP-complete和coNP-complete碎片的算法，首次实现了在Σ^P_2-complete问题中超越穷举搜索的正向结果。论文同时提供了下界，并在指数时间假设(exponential-time hypothesis)下排除了许多碎片的进一步改进可能性，从而为非单调推理的复杂度理论奠定了基础。",
      "categories": [
        "cs.CC",
        "cs.AI",
        "F.2.2"
      ],
      "primary_category": "cs.CC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10201v1",
      "published_date": "2025-05-15 11:56:19 UTC",
      "updated_date": "2025-05-15 11:56:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:21:52.748151"
    },
    {
      "arxiv_id": "2505.10197v1",
      "title": "Advancing Community Detection with Graph Convolutional Neural Networks: Bridging Topological and Attributive Cohesion",
      "title_zh": "使用图卷积神经网络推进社区检测：桥接拓扑和属性凝聚力",
      "authors": [
        "Anjali de Silva",
        "Gang Chen",
        "Hui Ma",
        "Seyed Mohammad Nekooei",
        "Xingquan Zuo"
      ],
      "abstract": "Community detection, a vital technology for real-world applications, uncovers\ncohesive node groups (communities) by leveraging both topological and attribute\nsimilarities in social networks. However, existing Graph Convolutional Networks\n(GCNs) trained to maximize modularity often converge to suboptimal solutions.\nAdditionally, directly using human-labeled communities for training can\nundermine topological cohesiveness by grouping disconnected nodes based solely\non node attributes. We address these issues by proposing a novel Topological\nand Attributive Similarity-based Community detection (TAS-Com) method. TAS-Com\nintroduces a novel loss function that exploits the highly effective and\nscalable Leiden algorithm to detect community structures with global optimal\nmodularity. Leiden is further utilized to refine human-labeled communities to\nensure connectivity within each community, enabling TAS-Com to detect community\nstructures with desirable trade-offs between modularity and compliance with\nhuman labels. Experimental results on multiple benchmark networks confirm that\nTAS-Com can significantly outperform several state-of-the-art algorithms.",
      "tldr_zh": "本研究针对社区检测中的问题，指出现有 Graph Convolutional Networks (GCNs) 在最大化 modularity 时易收敛到次优解，并可能因依赖人类标记而破坏拓扑凝聚。论文提出了一种新型 Topological and Attributive Similarity-based Community detection (TAS-Com) 方法，该方法引入新损失函数，利用 Leiden 算法检测全局最优模块度的社区结构，并精炼人类标记以确保社区内连接性，从而平衡拓扑和属性相似性。实验结果显示，TAS-Com 在多个基准网络上显著优于现有算法，展示了其在社交网络应用中的潜力。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "This paper has been accepted by IJCAI (International Joint Conference\n  on Artificial Intelligence) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10197v1",
      "published_date": "2025-05-15 11:53:33 UTC",
      "updated_date": "2025-05-15 11:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:22:04.838881"
    },
    {
      "arxiv_id": "2505.10191v1",
      "title": "LanTu: Dynamics-Enhanced Deep Learning for Eddy-Resolving Ocean Forecasting",
      "title_zh": "LanTu：动力学增强的深度学习用于涡旋分辨海洋预报",
      "authors": [
        "Qingyu Zheng",
        "Qi Shao",
        "Guijun Han",
        "Wei Li",
        "Hong Li",
        "Xuan Wang"
      ],
      "abstract": "Mesoscale eddies dominate the spatiotemporal multiscale variability of the\nocean, and their impact on the energy cascade of the global ocean cannot be\nignored. Eddy-resolving ocean forecasting is providing more reliable protection\nfor fisheries and navigational safety, but also presents significant scientific\nchallenges and high computational costs for traditional numerical models.\nArtificial intelligence (AI)-based weather and ocean forecasting systems are\nbecoming powerful tools that balance forecast performance with computational\nefficiency. However, the complex multiscale features in the ocean dynamical\nsystem make AI models still face many challenges in mesoscale eddy forecasting\n(especially regional modelling). Here, we develop LanTu, a regional\neddy-resolving ocean forecasting system based on dynamics-enhanced deep\nlearning. We incorporate cross-scale interactions into LanTu and construct\nmultiscale physical constraint for optimising LanTu guided by knowledge of eddy\ndynamics in order to improve the forecasting skill of LanTu for mesoscale\nevolution. The results show that LanTu outperforms the existing advanced\noperational numerical ocean forecasting system (NOFS) and AI-based ocean\nforecasting system (AI-OFS) in temperature, salinity, sea level anomaly and\ncurrent prediction, with a lead time of more than 10 days. Our study highlights\nthat dynamics-enhanced deep learning (LanTu) can be a powerful paradigm for\neddy-resolving ocean forecasting.",
      "tldr_zh": "本研究开发了LanTu，一种基于动态增强深度学习的区域涡流分辨率（eddy-resolving）海洋预报系统，旨在解决中尺度涡流（mesoscale eddies）对海洋多尺度变异性的挑战，同时降低传统数值模型的高计算成本。\nLanTu通过整合跨尺度交互和多尺度物理约束，优化模型以更好地捕捉涡流动态知识。\n实验结果表明，LanTu在温度、盐度、海平面异常和电流预测上优于现有数值海洋预报系统（NOFS）和AI-based海洋预报系统（AI-OFS），预报领先时间超过10天。\n这项工作强调了动态增强深度学习作为高效涡流分辨率海洋预报的强大范式。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG",
        "nlin.CD"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "22 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10191v1",
      "published_date": "2025-05-15 11:47:54 UTC",
      "updated_date": "2025-05-15 11:47:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:22:17.510995"
    },
    {
      "arxiv_id": "2505.10188v1",
      "title": "A User Study Evaluating Argumentative Explanations in Diagnostic Decision Support",
      "title_zh": "翻译失败",
      "authors": [
        "Felix Liedeker",
        "Olivia Sanchez-Graillet",
        "Moana Seidler",
        "Christian Brandt",
        "Jörg Wellmer",
        "Philipp Cimiano"
      ],
      "abstract": "As the field of healthcare increasingly adopts artificial intelligence, it\nbecomes important to understand which types of explanations increase\ntransparency and empower users to develop confidence and trust in the\npredictions made by machine learning (ML) systems. In shared decision-making\nscenarios where doctors cooperate with ML systems to reach an appropriate\ndecision, establishing mutual trust is crucial. In this paper, we explore\ndifferent approaches to generating explanations in eXplainable AI (XAI) and\nmake their underlying arguments explicit so that they can be evaluated by\nmedical experts. In particular, we present the findings of a user study\nconducted with physicians to investigate their perceptions of various types of\nAI-generated explanations in the context of diagnostic decision support. The\nstudy aims to identify the most effective and useful explanations that enhance\nthe diagnostic process. In the study, medical doctors filled out a survey to\nassess different types of explanations. Further, an interview was carried out\npost-survey to gain qualitative insights on the requirements of explanations\nincorporated in diagnostic decision support. Overall, the insights gained from\nthis study contribute to understanding the types of explanations that are most\neffective.",
      "tldr_zh": "该研究评估了在诊断决策支持系统中，使用辩证解释（argumentative explanations）如何提升医疗AI的透明度和用户信任。研究通过一项用户调查和后续访谈，邀请医生评估不同类型的eXplainable AI (XAI)生成解释，旨在识别最有效和有用的解释类型。结果显示，这些解释有助于医生在共享决策场景中增强信心和合作，最终为改进AI在医疗领域的应用提供了宝贵insights。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at 'The First Workshop on Natural Language Argument-Based\n  Explanations', co-located with ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.10188v1",
      "published_date": "2025-05-15 11:42:24 UTC",
      "updated_date": "2025-05-15 11:42:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:22:27.976087"
    },
    {
      "arxiv_id": "2505.10185v1",
      "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think",
      "title_zh": "翻译失败",
      "authors": [
        "Seongyun Lee",
        "Seungone Kim",
        "Minju Seo",
        "Yongrae Jo",
        "Dongyoung Go",
        "Hyeonbin Hwang",
        "Jinho Park",
        "Xiang Yue",
        "Sean Welleck",
        "Graham Neubig",
        "Moontae Lee",
        "Minjoon Seo"
      ],
      "abstract": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design.",
      "tldr_zh": "本研究提出 CoT Encyclopedia，这是一个自底向上的框架，用于分析、预测和控制推理模型（如大型语言模型）的 Chain-of-Thought (CoT) 推理策略。该框架通过自动从模型生成的 CoT 中提取多样化推理标准、嵌入语义空间、聚类成类别，并衍生对比性标准，来提供更可解释和全面的推理行为分析。实验结果显示，该方法在人类评估中优于现有方法，并能预测模型可能采用的策略并引导其转向更有效的替代方案。此外，研究发现，训练数据格式（如自由形式 vs. 多项选择）对推理行为的影响远大于数据领域，强调了格式感知模型设计的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.10185v1",
      "published_date": "2025-05-15 11:31:02 UTC",
      "updated_date": "2025-05-15 11:31:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:22:40.767300"
    },
    {
      "arxiv_id": "2505.10183v1",
      "title": "KAITIAN: A Unified Communication Framework for Enabling Efficient Collaboration Across Heterogeneous Accelerators in Embodied AI Systems",
      "title_zh": "KAITIAN：一种用于在具身 AI 系统中实现异构加速器高效协作的统一通信框架",
      "authors": [
        "Jieke Lin",
        "Wanyu Wang",
        "Longxiang Yin",
        "Yinhe Han"
      ],
      "abstract": "Embodied Artificial Intelligence (AI) systems, such as autonomous robots and\nintelligent vehicles, are increasingly reliant on diverse heterogeneous\naccelerators (e.g., GPGPUs, NPUs, FPGAs) to meet stringent real-time processing\nand energy-efficiency demands. However, the proliferation of vendor-specific\nproprietary communication libraries creates significant interoperability\nbarriers, hindering seamless collaboration between different accelerator types\nand leading to suboptimal resource utilization and performance bottlenecks in\ndistributed AI workloads. This paper introduces KAITIAN, a novel distributed\ncommunication framework designed to bridge this gap. KAITIAN provides a unified\nabstraction layer that intelligently integrates vendor-optimized communication\nlibraries for intra-group efficiency with general-purpose communication\nprotocols for inter-group interoperability. Crucially, it incorporates a\nload-adaptive scheduling mechanism that dynamically balances computational\ntasks across heterogeneous devices based on their real-time performance\ncharacteristics. Implemented as an extension to PyTorch and rigorously\nevaluated on a testbed featuring NVIDIA GPUs and Cambricon MLUs, KAITIAN\ndemonstrates significant improvements in resource utilization and scalability\nfor distributed training tasks. Experimental results show that KAITIAN can\naccelerate training time by up to 42% compared to baseline homogeneous systems,\nwhile incurring minimal communication overhead (2.8--4.3%) and maintaining\nmodel accuracy. KAITIAN paves the way for more flexible and powerful\nheterogeneous computing in complex embodied AI applications.",
      "tldr_zh": "该论文针对Embodied AI系统（如机器人和智能车辆）中异构加速器（如GPGPUs、NPUs和FPGAs）的协作问题，提出KAITIAN框架，以解决供应商特定通信库导致的互操作性障碍和资源利用低效问题。KAITIAN提供一个统一的抽象层，结合供应商优化通信库和通用协议，并引入负载自适应调度机制，根据实时性能动态平衡计算任务。实验结果显示，在PyTorch扩展的测试床上，KAITIAN将分布式训练时间加速高达42%，通信开销仅为2.8-4.3%，同时保持模型准确性，并为复杂Embodied AI应用的异构计算带来更灵活的解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "9 pages, 4 figures. Jieke Lin and Wanyu Wang contributed equally to\n  this work",
      "pdf_url": "http://arxiv.org/pdf/2505.10183v1",
      "published_date": "2025-05-15 11:29:43 UTC",
      "updated_date": "2025-05-15 11:29:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:22:52.919318"
    },
    {
      "arxiv_id": "2505.10172v1",
      "title": "Does Scaling Law Apply in Time Series Forecasting?",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyan Li",
        "Libing Chen",
        "Yin Tang"
      ],
      "abstract": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling.",
      "tldr_zh": "本研究质疑了规模扩展定律（scaling law）在时间序列预测（time series forecasting）中的适用性，提出了一种超轻量级模型Alinear，仅使用k-level参数就实现了与大型模型相当的性能。Alinear引入了horizon-aware adaptive decomposition机制（动态调整不同预测长度的组件强调）和progressive frequency attenuation策略（在各种预测范围内实现稳定预测，而不依赖attention机制），从而更高效地处理趋势和季节组件。实验在七个基准数据集上显示，Alinear在使用不到大型模型1%参数的情况下，持续优于基线模型，并在短和超长预测范围内保持高准确率；此外，该工作还提出一个新的参数感知评估指标，验证了自适应设计的必要性，并倡导转向更高效的时间序列建模范式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10172v1",
      "published_date": "2025-05-15 11:04:39 UTC",
      "updated_date": "2025-05-15 11:04:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:23:06.044239"
    },
    {
      "arxiv_id": "2505.10597v2",
      "title": "Two Minds Better Than One: Collaborative Reward Modeling for LLM Alignment",
      "title_zh": "两个头脑胜过一个：用于 LLM 对齐的协作奖励建模",
      "authors": [
        "Jiazheng Zhang",
        "Wenqing Jing",
        "Zizhuo Zhang",
        "Zhiheng Xi",
        "Shihan Dou",
        "Rongxiang Weng",
        "Jiahuan Li",
        "Jingang Wang",
        "Mingxu Chai",
        "Shibo Hong",
        "Tao Gui",
        "Qi Zhang"
      ],
      "abstract": "Reward models (RMs) play a pivotal role in aligning large language models\n(LLMs) with human values. However, noisy preferences in human feedback can lead\nto reward misgeneralization - a phenomenon where reward models learn spurious\ncorrelations or overfit to noisy preferences, which poses important challenges\nto the generalization of RMs. This paper systematically analyzes the\ncharacteristics of preference pairs and aims to identify how noisy preferences\ndiffer from human-aligned preferences in reward modeling. Our analysis reveals\nthat noisy preferences are difficult for RMs to fit, as they cause sharp\ntraining fluctuations and irregular gradient updates. These distinctive\ndynamics suggest the feasibility of identifying and excluding such noisy\npreferences. Empirical studies demonstrate that policy LLM optimized with a\nreward model trained on the full preference dataset, which includes substantial\nnoise, performs worse than the one trained on a subset of exclusively high\nquality preferences. To address this challenge, we propose an online\nCollaborative Reward Modeling (CRM) framework to achieve robust preference\nlearning through peer review and curriculum learning. In particular, CRM\nmaintains two RMs that collaboratively filter potential noisy preferences by\npeer-reviewing each other's data selections. Curriculum learning synchronizes\nthe capabilities of two models, mitigating excessive disparities to promote the\nutility of peer review. Extensive experiments demonstrate that CRM\nsignificantly enhances RM generalization, with up to 9.94 points improvement on\nRewardBench under an extreme 40\\% noise. Moreover, CRM can seamlessly extend to\nimplicit-reward alignment methods, offering a robust and versatile alignment\nstrategy.",
      "tldr_zh": "这篇论文分析了人类反馈中的噪声偏好如何导致奖励模型（RMs）在对齐大型语言模型（LLMs）时出现奖励泛化错误（reward misgeneralization），如学习虚假相关性和训练波动。作者提出在线协作奖励建模（CRM）框架，利用两个 RMs 通过同行评审过滤噪声偏好，并结合课程学习同步模型能力以提升鲁棒性。实验结果显示，CRM 在 RewardBench 上实现了高达 9.94 点的泛化性能提升，即使在 40% 噪声环境下。总体而言，该框架为更可靠的 LLM 对齐策略提供了可扩展的解决方案，包括隐式奖励对齐方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10597v2",
      "published_date": "2025-05-15 10:58:20 UTC",
      "updated_date": "2025-05-19 03:28:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:23:17.329341"
    },
    {
      "arxiv_id": "2505.10169v1",
      "title": "Modeling Saliency Dataset Bias",
      "title_zh": "显著性数据集偏差的建模",
      "authors": [
        "Matthias Kümmerer",
        "Harneet Khanuja",
        "Matthias Bethge"
      ],
      "abstract": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes.",
      "tldr_zh": "该研究发现，现有的图像显著性(saliency)预测模型在不同数据集间泛化性能下降约40%，主要由于数据集偏差，即使增加数据集多样性也无法完全解决，约60%差距源于特定偏差。  \n为了应对这一问题，论文提出了一种新架构：在数据集无关的encoder-decoder结构中添加少于20个可解释参数（如多尺度结构、中央偏差和注视点分布），仅通过这些参数适应新数据即可填补超过75%的泛化差距，甚至用少于50个样本即可实现大部分改善。  \n该模型在MIT/Tuebingen Saliency Benchmark的三个数据集（MIT300、CAT2000和COCO-Freeview）上达到了新的state-of-the-art水平，即使从无关数据集泛化也能表现突出，并在适应各自训练数据集时获得显著提升。  \n此外，该模型还提供了对空间显著性属性的洞见，揭示了结合绝对和相对大小的复杂多尺度效应。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10169v1",
      "published_date": "2025-05-15 10:55:47 UTC",
      "updated_date": "2025-05-15 10:55:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:23:30.425550"
    },
    {
      "arxiv_id": "2505.10167v2",
      "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models",
      "title_zh": "QuXAI：混合量子机器学习模型的解释器",
      "authors": [
        "Saikat Barua",
        "Mostafizur Rahman",
        "Shehenaz Khaled",
        "Md Jafor Sadek",
        "Rafiul Islam",
        "Shahnewaz Siddique"
      ],
      "abstract": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology.\n  Our code and experiments are open-sourced at:\nhttps://github.com/GitsSaikat/QuXAI",
      "tldr_zh": "该研究引入了 QuXAI 框架，基于 Q-MEDLEY 解释器，针对混合量子-经典机器学习 (HQML) 模型的黑箱问题，提供全局和局部解释，以提升其透明度和可靠性。QuXAI 通过量子特征映射、特征推理和可视化归因，保留量子转换阶段来分析特征重要性，并在实验中证明 Q-MEDLEY 能有效识别影响因素、分离噪声，并与经典 XAI 技术竞争。消融研究突出了 Q-MEDLEY 的复合结构优势，最终为 HQML 的可解释性和安全应用提供了重要途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 6 figures, 7 equations",
      "pdf_url": "http://arxiv.org/pdf/2505.10167v2",
      "published_date": "2025-05-15 10:51:34 UTC",
      "updated_date": "2025-05-16 14:30:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:23:41.146215"
    },
    {
      "arxiv_id": "2505.10134v1",
      "title": "Large Wireless Localization Model (LWLM): A Foundation Model for Positioning in 6G Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Guangjin Pan",
        "Kaixuan Huang",
        "Hui Chen",
        "Shunqing Zhang",
        "Christian Häger",
        "Henk Wymeersch"
      ],
      "abstract": "Accurate and robust localization is a critical enabler for emerging 5G and 6G\napplications, including autonomous driving, extended reality (XR), and smart\nmanufacturing. While data-driven approaches have shown promise, most existing\nmodels require large amounts of labeled data and struggle to generalize across\ndeployment scenarios and wireless configurations. To address these limitations,\nwe propose a foundation-model-based solution tailored for wireless\nlocalization. We first analyze how different self-supervised learning (SSL)\ntasks acquire general-purpose and task-specific semantic features based on\ninformation bottleneck (IB) theory. Building on this foundation, we design a\npretraining methodology for the proposed Large Wireless Localization Model\n(LWLM). Specifically, we propose an SSL framework that jointly optimizes three\ncomplementary objectives: (i) spatial-frequency masked channel modeling\n(SF-MCM), (ii) domain-transformation invariance (DTI), and (iii)\nposition-invariant contrastive learning (PICL). These objectives jointly\ncapture the underlying semantics of wireless channel from multiple\nperspectives. We further design lightweight decoders for key downstream tasks,\nincluding time-of-arrival (ToA) estimation, angle-of-arrival (AoA) estimation,\nsingle base station (BS) localization, and multiple BS localization.\nComprehensive experimental results confirm that LWLM consistently surpasses\nboth model-based and supervised learning baselines across all localization\ntasks. In particular, LWLM achieves 26.0%--87.5% improvement over transformer\nmodels without pretraining, and exhibits strong generalization under\nlabel-limited fine-tuning and unseen BS configurations, confirming its\npotential as a foundation model for wireless localization.",
      "tldr_zh": "该研究提出 Large Wireless Localization Model (LWLM)，一种针对 6G 网络定位的基础模型，旨在解决现有数据驱动方法依赖大量标注数据且泛化能力弱的问题。LWLM 通过信息瓶颈 (IB) 理论分析自监督学习 (SSL) 任务，并设计一个联合优化框架，包括空间-频率掩码通道建模 (SF-MCM)、域变换不变性 (DTI) 和位置不变对比学习 (PICL)，从多个角度捕获无线通道的底层语义。模型还配备轻量级解码器，支持下游任务如到达时间估计 (ToA)、到达角度估计 (AoA) 和单/多基站定位。实验结果显示，LWLM 在所有任务中比基线模型提升 26.0%–87.5%，并在标签有限的微调和未见基站配置下表现出色，证明其作为无线定位基础模型的潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "13 pages,16 figures.This work has been submitted to the IEEE for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2505.10134v1",
      "published_date": "2025-05-15 10:04:44 UTC",
      "updated_date": "2025-05-15 10:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:23:54.015078"
    },
    {
      "arxiv_id": "2505.10596v1",
      "title": "Inclusivity of AI Speech in Healthcare: A Decade Look Back",
      "title_zh": "翻译失败",
      "authors": [
        "Retno Larasati"
      ],
      "abstract": "The integration of AI speech recognition technologies into healthcare has the\npotential to revolutionize clinical workflows and patient-provider\ncommunication. However, this study reveals significant gaps in inclusivity,\nwith datasets and research disproportionately favouring high-resource\nlanguages, standardized accents, and narrow demographic groups. These biases\nrisk perpetuating healthcare disparities, as AI systems may misinterpret speech\nfrom marginalized groups. This paper highlights the urgent need for inclusive\ndataset design, bias mitigation research, and policy frameworks to ensure\nequitable access to AI speech technologies in healthcare.",
      "tldr_zh": "这篇论文回顾了过去十年AI语音识别技术在医疗领域的整合，强调其潜力在改善临床工作流程和患者-提供者沟通方面发挥革命性作用。然而，研究发现存在显著的包容性(inclusivity)差距：数据集和研究偏向高资源语言、标准化口音以及狭窄的人口群体，导致AI系统可能误解边缘化群体的语音，从而加剧医疗不平等。论文呼吁通过设计包容性数据集、开展偏见(bias)缓解研究以及制定政策框架，来确保AI语音技术在医疗中的公平访问。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10596v1",
      "published_date": "2025-05-15 10:03:05 UTC",
      "updated_date": "2025-05-15 10:03:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:24:03.870118"
    },
    {
      "arxiv_id": "2505.10128v1",
      "title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity",
      "title_zh": "翻译失败",
      "authors": [
        "Huy Q. Le",
        "Latif U. Khan",
        "Choong Seon Hong"
      ],
      "abstract": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance.",
      "tldr_zh": "该论文针对联邦学习（Federated Learning）中领域异质性（Domain Heterogeneity）导致的全局模型收敛问题，提出一个新框架，通过原型增强（prototype augmentation）来提升模型的泛化能力和鲁棒性。框架引入 FedAPC（Federated Augmented Prototype Contrastive Learning），它利用从增强数据平均特征派生的原型来捕获更丰富的表示，并通过将本地特征与全局原型对齐，减少对特定领域的过拟合。实验结果在 Office-10 和 Digits 数据集上显示，FedAPC 优于现有最先进（SOTA）基线，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "IWCMC 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10128v1",
      "published_date": "2025-05-15 09:53:14 UTC",
      "updated_date": "2025-05-15 09:53:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:24:17.849005"
    },
    {
      "arxiv_id": "2505.10120v1",
      "title": "All You Need Is Synthetic Task Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Guillaume Godin"
      ],
      "abstract": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining.",
      "tldr_zh": "本研究提出了一种合成任务增强策略，通过联合训练一个 Graph Transformer 神经网络来处理分子属性预测任务，该方法结合稀疏的多任务实验目标和从 XGBoost 模型训练的 Osmordred 分子描述符派生的合成辅助任务。相比传统方法，该策略无需预训练或特征注入，即可显著提升模型性能。实验结果显示，在 19 个分子属性预测任务中，性能一致改善，其中 16 个任务中多任务 Graph Transformer 优于 XGBoost 单任务学习。这为分子属性预测提供了高效且简化的新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 3 Figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.10120v1",
      "published_date": "2025-05-15 09:46:27 UTC",
      "updated_date": "2025-05-15 09:46:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:24:29.573630"
    },
    {
      "arxiv_id": "2505.11550v1",
      "title": "AI-generated Text Detection: A Multifaceted Approach to Binary and Multiclass Classification",
      "title_zh": "AI 生成",
      "authors": [
        "Harika Abburi",
        "Sanmitra Bhattacharya",
        "Edward Bowen",
        "Nirmala Pudota"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ngenerating text that closely resembles human writing across a wide range of\nstyles and genres. However, such capabilities are prone to potential misuse,\nsuch as fake news generation, spam email creation, and misuse in academic\nassignments. As a result, accurate detection of AI-generated text and\nidentification of the model that generated it are crucial for maintaining the\nresponsible use of LLMs. In this work, we addressed two sub-tasks put forward\nby the Defactify workshop under AI-Generated Text Detection shared task at the\nAssociation for the Advancement of Artificial Intelligence (AAAI 2025): Task A\ninvolved distinguishing between human-authored or AI-generated text, while Task\nB focused on attributing text to its originating language model. For each task,\nwe proposed two neural architectures: an optimized model and a simpler variant.\nFor Task A, the optimized neural architecture achieved fifth place with $F1$\nscore of 0.994, and for Task B, the simpler neural architecture also ranked\nfifth place with $F1$ score of 0.627.",
      "tldr_zh": "该研究探讨了检测 AI 生成文本的方法，以应对 Large Language Models (LLMs) 的潜在滥用，如假新闻生成和学术作弊。作者针对 AAAI 2025 Defactify 工作坊的任务，提出了两种神经架构：一种优化模型用于二元分类（区分人类撰写或 AI 生成文本），另一种简单变体用于多类分类（归因文本到特定语言模型）。实验结果显示，优化模型在 Task A 上获得第五名，F1 score 达 0.994，而简单模型在 Task B 上也排名第五，F1 score 为 0.627，从而证明了该方法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11550v1",
      "published_date": "2025-05-15 09:28:06 UTC",
      "updated_date": "2025-05-15 09:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:24:41.705411"
    },
    {
      "arxiv_id": "2505.10105v1",
      "title": "EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Zibin Dong",
        "Fei Ni",
        "Yifu Yuan",
        "Yinchuan Li",
        "Jianye Hao"
      ],
      "abstract": "We present EmbodiedMAE, a unified 3D multi-modal representation for robot\nmanipulation. Current approaches suffer from significant domain gaps between\ntraining datasets and robot manipulation tasks, while also lacking model\narchitectures that can effectively incorporate 3D information. To overcome\nthese limitations, we enhance the DROID dataset with high-quality depth maps\nand point clouds, constructing DROID-3D as a valuable supplement for 3D\nembodied vision research. Then we develop EmbodiedMAE, a multi-modal masked\nautoencoder that simultaneously learns representations across RGB, depth, and\npoint cloud modalities through stochastic masking and cross-modal fusion.\nTrained on DROID-3D, EmbodiedMAE consistently outperforms state-of-the-art\nvision foundation models (VFMs) in both training efficiency and final\nperformance across 70 simulation tasks and 20 real-world robot manipulation\ntasks on two robot platforms. The model exhibits strong scaling behavior with\nsize and promotes effective policy learning from 3D inputs. Experimental\nresults establish EmbodiedMAE as a reliable unified 3D multi-modal VFM for\nembodied AI systems, particularly in precise tabletop manipulation settings\nwhere spatial perception is critical.",
      "tldr_zh": "本研究提出了EmbodiedMAE，一种统一的3D多模态表示框架，用于提升机器人操作性能，以解决现有方法在训练数据集与任务领域差距以及3D信息整合不足的问题。作者首先增强DROID数据集，添加高质量的depth maps和point clouds，构建了DROID-3D数据集作为3D具身视觉研究的补充。然后，EmbodiedMAE采用多模态masked autoencoder，通过随机masking和cross-modal fusion，同时学习RGB、depth和point cloud模态的表示。实验结果显示，该模型在DROID-3D上训练后，在70个模拟任务和20个真实世界机器人操作任务中，超越了最先进的vision foundation models (VFMs)，并展示了优秀的训练效率、缩放行为和从3D输入的有效策略学习能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10105v1",
      "published_date": "2025-05-15 09:12:17 UTC",
      "updated_date": "2025-05-15 09:12:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:24:54.679076"
    },
    {
      "arxiv_id": "2505.10101v1",
      "title": "LAV: Audio-Driven Dynamic Visual Generation with Neural Compression and StyleGAN2",
      "title_zh": "翻译失败",
      "authors": [
        "Jongmin Jung",
        "Dasaem Jeong"
      ],
      "abstract": "This paper introduces LAV (Latent Audio-Visual), a system that integrates\nEnCodec's neural audio compression with StyleGAN2's generative capabilities to\nproduce visually dynamic outputs driven by pre-recorded audio. Unlike previous\nworks that rely on explicit feature mappings, LAV uses EnCodec embeddings as\nlatent representations, directly transformed into StyleGAN2's style latent\nspace via randomly initialized linear mapping. This approach preserves semantic\nrichness in the transformation, enabling nuanced and semantically coherent\naudio-visual translations. The framework demonstrates the potential of using\npretrained audio compression models for artistic and computational\napplications.",
      "tldr_zh": "本研究引入了 LAV 系统，通过整合 EnCodec 的神经音频压缩（neural compression）和 StyleGAN2 的生成能力，实现基于预录音频的动态视觉输出。与以往依赖显式特征映射的方法不同，LAV 使用 EnCodec 嵌入作为潜在表示，并通过随机初始化的线性映射直接转换为 StyleGAN2 的风格潜在空间，从而保留语义丰富性和实现细致连贯的音频-视觉转换。该框架展示了预训练音频压缩模型在艺术和计算应用中的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.GR",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Paper accepted at ISEA 2025, The 30th International Symposium on\n  Electronic/Emerging Art, Seoul, Republic of Korea, 23 - 29 May 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10101v1",
      "published_date": "2025-05-15 09:04:12 UTC",
      "updated_date": "2025-05-15 09:04:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:25:04.923532"
    },
    {
      "arxiv_id": "2505.10093v1",
      "title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Hsuan-Lei Shao"
      ],
      "abstract": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems.",
      "tldr_zh": "这篇论文提出了一种使用 Generative AI 和 LLMs 的方法，从 1,367 篇 1996-2019 年台湾基于中国研究的同行评议文章中提取并标准化实体关系 triples，构建一个特定领域的 knowledge graph 和 vector database。研究通过 D3.js 基于的系统可视化这些数据，允许用户探索概念节点、语义关系，从而揭示未被发掘的知识轨迹、主题集群和研究空白。该方法实现了从线性文本消费向网络化知识导航的转变，提供了一个可扩展的数据驱动替代方案来优化传统本体构建。最后，该工作展示了 Generative AI 在增强区域研究和数字人文方面的潜力，支持区域知识系统的重新设计。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.4; H.3.3; J.5"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10093v1",
      "published_date": "2025-05-15 08:51:53 UTC",
      "updated_date": "2025-05-15 08:51:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:25:18.600109"
    },
    {
      "arxiv_id": "2505.10074v2",
      "title": "Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Abdelmagied",
        "Mohamed Amine Chatti",
        "Shoeb Joarder",
        "Qurat Ul Ain",
        "Rawaa Alatrash"
      ],
      "abstract": "Massive Open Online Courses (MOOCs) lack direct interaction between learners\nand instructors, making it challenging for learners to understand new knowledge\nconcepts. Recently, learners have increasingly used Large Language Models\n(LLMs) to support them in acquiring new knowledge. However, LLMs are prone to\nhallucinations which limits their reliability. Retrieval-Augmented Generation\n(RAG) addresses this issue by retrieving relevant documents before generating a\nresponse. However, the application of RAG across different MOOCs is limited by\nunstructured learning material. Furthermore, current RAG systems do not\nactively guide learners toward their learning needs. To address these\nchallenges, we propose a Graph RAG pipeline that leverages Educational\nKnowledge Graphs (EduKGs) and Personal Knowledge Graphs (PKGs) to guide\nlearners to understand knowledge concepts in the MOOC platform CourseMapper.\nSpecifically, we implement (1) a PKG-based Question Generation method to\nrecommend personalized questions for learners in context, and (2) an\nEduKG-based Question Answering method that leverages the relationships between\nknowledge concepts in the EduKG to answer learner selected questions. To\nevaluate both methods, we conducted a study with 3 expert instructors on 3\ndifferent MOOCs in the MOOC platform CourseMapper. The results of the\nevaluation show the potential of Graph RAG to empower learners to understand\nnew knowledge concepts in a personalized learning experience.",
      "tldr_zh": "该论文针对MOOCs中学习者理解知识概念的挑战（如师生互动不足和Large Language Models (LLMs)易产生hallucinations），提出Graph Retrieval-Augmented Generation (Graph RAG)框架，以提升学习支持。框架利用Educational Knowledge Graphs (EduKGs)和Personal Knowledge Graphs (PKGs)，实现PKG-based Question Generation来推荐个性化问题，以及EduKG-based Question Answering来利用知识概念间的关系回答问题。实验在CourseMapper平台上涉及3个MOOCs和专家评估，结果表明Graph RAG能提供个性化的学习体验，帮助学习者更有效地理解新知识概念。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at EMOOCs 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10074v2",
      "published_date": "2025-05-15 08:24:47 UTC",
      "updated_date": "2025-05-16 15:33:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:25:29.540998"
    },
    {
      "arxiv_id": "2505.10073v1",
      "title": "Multi-Robot Task Allocation for Homogeneous Tasks with Collision Avoidance via Spatial Clustering",
      "title_zh": "通过空间聚类实现碰撞避免的多机器人同质任务分配",
      "authors": [
        "Rathin Chandra Shit",
        "Sharmila Subudhi"
      ],
      "abstract": "In this paper, a novel framework is presented that achieves a combined\nsolution based on Multi-Robot Task Allocation (MRTA) and collision avoidance\nwith respect to homogeneous measurement tasks taking place in industrial\nenvironments. The spatial clustering we propose offers to simultaneously solve\nthe task allocation problem and deal with collision risks by cutting the\nworkspace into distinguishable operational zones for each robot. To divide task\nsites and to schedule robot routes within corresponding clusters, we use\nK-means clustering and the 2-Opt algorithm. The presented framework shows\nsatisfactory performance, where up to 93\\% time reduction (1.24s against\n17.62s) with a solution quality improvement of up to 7\\% compared to the best\nperforming method is demonstrated. Our method also completely eliminates\ncollision points that persist in comparative methods in a most significant\nsense. Theoretical analysis agrees with the claim that spatial partitioning\nunifies the apparently disjoint tasks allocation and collision avoidance\nproblems under conditions of many identical tasks to be distributed over sparse\ngeographical areas. Ultimately, the findings in this work are of substantial\nimportance for real world applications where both computational efficiency and\noperation free from collisions is of paramount importance.",
      "tldr_zh": "本文提出了一种基于空间聚类(Spatial Clustering)的框架，用于Multi-Robot Task Allocation (MRTA)，旨在同时解决同质测量任务的分配和碰撞避免(Collision Avoidance)问题，尤其适用于工业环境。框架通过K-means clustering划分任务站点并使用2-Opt algorithm调度机器人路径，将工作空间分区为不同操作区域，从而减少碰撞风险。实验结果显示，与最佳方法相比，该框架可将任务完成时间减少高达93%（从17.62秒降至1.24秒），并提高解决方案质量7%，完全消除碰撞点。理论分析进一步证明，空间分区能统一任务分配和碰撞避免问题，在处理多个相同任务的稀疏区域时具有显著实际应用价值。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "5 pages, 4 figures, Scheduled for presentation at an upcoming\n  conference",
      "pdf_url": "http://arxiv.org/pdf/2505.10073v1",
      "published_date": "2025-05-15 08:20:57 UTC",
      "updated_date": "2025-05-15 08:20:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:25:41.665007"
    },
    {
      "arxiv_id": "2505.11548v2",
      "title": "One Shot Dominance: Knowledge Poisoning Attack on Retrieval-Augmented Generation Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Chang",
        "Mingyang Li",
        "Xiaojun Jia",
        "Junjie Wang",
        "Yuekai Huang",
        "Ziyou Jiang",
        "Yang Liu",
        "Qing Wang"
      ],
      "abstract": "Large Language Models (LLMs) enhanced with Retrieval-Augmented Generation\n(RAG) have shown improved performance in generating accurate responses.\nHowever, the dependence on external knowledge bases introduces potential\nsecurity vulnerabilities, particularly when these knowledge bases are publicly\naccessible and modifiable. While previous studies have exposed knowledge\npoisoning risks in RAG systems, existing attack methods suffer from critical\nlimitations: they either require injecting multiple poisoned documents\n(resulting in poor stealthiness) or can only function effectively on simplistic\nqueries (limiting real-world applicability). This paper reveals a more\nrealistic knowledge poisoning attack against RAG systems that achieves\nsuccessful attacks by poisoning only a single document while remaining\neffective for complex multi-hop questions involving complex relationships\nbetween multiple elements. Our proposed AuthChain address three challenges to\nensure the poisoned documents are reliably retrieved and trusted by the LLM,\neven against large knowledge bases and LLM's own knowledge. Extensive\nexperiments across six popular LLMs demonstrate that AuthChain achieves\nsignificantly higher attack success rates while maintaining superior\nstealthiness against RAG defense mechanisms compared to state-of-the-art\nbaselines.",
      "tldr_zh": "这篇论文揭示了Retrieval-Augmented Generation (RAG) 系统依赖外部知识库的安全漏洞，提出了一种名为One Shot Dominance的知识毒化攻击方法。作者开发了AuthChain框架，通过仅毒化单个文档，即可针对复杂多跳查询实现高效攻击，同时解决确保毒化文档被可靠检索和信任的三大挑战。实验结果显示，在六个流行Large Language Models (LLMs)上，AuthChain比现有基准方法实现了更高的攻击成功率和隐秘性，并有效对抗RAG防御机制。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "14pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11548v2",
      "published_date": "2025-05-15 08:14:58 UTC",
      "updated_date": "2025-05-20 02:50:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:25:53.616378"
    },
    {
      "arxiv_id": "2505.10594v1",
      "title": "CRPE: Expanding The Reasoning Capability of Large Language Model for Code Generation",
      "title_zh": "CRPE：扩展大型语言模型的推理能力用于代码生成",
      "authors": [
        "Ningxin Gui",
        "Qianghuai Jia",
        "Feijun Jiang",
        "Yuling Jiao",
        "dechun wang",
        "Jerry Zhijian Yang"
      ],
      "abstract": "We introduce CRPE (Code Reasoning Process Enhancer), an innovative\nthree-stage framework for data synthesis and model training that advances the\ndevelopment of sophisticated code reasoning capabilities in large language\nmodels (LLMs). Building upon existing system-1 models, CRPE addresses the\nfundamental challenge of enhancing LLMs' analytical and logical processing in\ncode generation tasks. Our framework presents a methodologically rigorous yet\nimplementable approach to cultivating advanced code reasoning abilities in\nlanguage models. Through the implementation of CRPE, we successfully develop an\nenhanced COT-Coder that demonstrates marked improvements in code generation\ntasks. Evaluation results on LiveCodeBench (20240701-20240901) demonstrate that\nour COT-Coder-7B-StepDPO, derived from Qwen2.5-Coder-7B-Base, with a pass@1\naccuracy of 21.88, exceeds all models with similar or even larger sizes.\nFurthermore, our COT-Coder-32B-StepDPO, based on Qwen2.5-Coder-32B-Base,\nexhibits superior performance with a pass@1 accuracy of 35.08, outperforming\nGPT4O on the benchmark. Overall, CRPE represents a comprehensive, open-source\nmethod that encompasses the complete pipeline from instruction data acquisition\nthrough expert code reasoning data synthesis, culminating in an autonomous\nreasoning enhancement mechanism.",
      "tldr_zh": "本研究引入了 CRPE（Code Reasoning Process Enhancer），一个创新的三阶段框架，用于数据合成和模型训练，以提升大型语言模型（LLMs）在代码生成任务中的分析和逻辑推理能力。CRPE 构建于现有 system-1 模型基础上，通过指令数据获取、专家代码推理数据合成以及自主推理增强机制，成功开发了增强版 COT-Coder。评估结果显示，在 LiveCodeBench 基准上，COT-Coder-7B-StepDPO 的 pass@1 准确率达到 21.88%，优于同等或更大模型，而 COT-Coder-32B-StepDPO 则以 35.08% 的准确率超越 GPT4O，为开源代码推理能力提升提供了全面方法。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10594v1",
      "published_date": "2025-05-15 08:13:45 UTC",
      "updated_date": "2025-05-15 08:13:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:26:06.536128"
    },
    {
      "arxiv_id": "2505.10066v1",
      "title": "Dark LLMs: The Growing Threat of Unaligned AI Models",
      "title_zh": "Dark LLMs：非对齐 AI 模型的日益增长威胁",
      "authors": [
        "Michael Fire",
        "Yitzhak Elbazis",
        "Adi Wasenstein",
        "Lior Rokach"
      ],
      "abstract": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated.",
      "tldr_zh": "该研究警告了大型语言模型（LLMs）面临的安全威胁，特别是“dark LLMs”——这些模型故意缺乏道德防护或通过jailbreak attacks修改，导致它们能生成有害输出。研究团队发现了一个通用jailbreak攻击，能够有效入侵多个先进模型，使其回答任何问题，尽管该攻击方法七个月前已公开。实验结果显示，许多LLMs仍易受攻击，而行业提供商的响应不足，随着开源LLMs的普及，这一风险将进一步加剧，呼吁采取紧急干预措施以防止危险知识的泛滥。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "68T50, 68T05, 68P25",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10066v1",
      "published_date": "2025-05-15 08:07:04 UTC",
      "updated_date": "2025-05-15 08:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:26:17.267088"
    },
    {
      "arxiv_id": "2505.10055v1",
      "title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language",
      "title_zh": "翻译失败",
      "authors": [
        "Ijazul Haq",
        "Yingjie Zhang",
        "Irfan Ali Khan"
      ],
      "abstract": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR.",
      "tldr_zh": "本文评估了Large Multimodal Models (LMMs)在低资源语言Pashto的Optical Character Recognition (OCR)任务中的性能，针对Pashto脚本的连写特性及数据集稀缺问题，开发了合成数据集PsOCR，包含一百万张标注图像，覆盖1,000个字体家族、颜色和布局。研究使用一个10K图像的基准子集测试了七个开源模型（如Qwen-7B和InternVL）和四个闭源模型（如Gemini），结果显示Gemini整体表现最佳，而Qwen-7B在开源模型中领先。PsOCR数据集及其基准测试为Pashto及其他类似脚本（如Arabic和Persian）的OCR研究奠定了基础，并可从GitHub获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10055v1",
      "published_date": "2025-05-15 07:58:38 UTC",
      "updated_date": "2025-05-15 07:58:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:26:30.249746"
    },
    {
      "arxiv_id": "2505.10050v1",
      "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Fahad Almalki",
        "Mehedi Masud"
      ],
      "abstract": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection.",
      "tldr_zh": "本研究针对传统机器学习模型在金融欺诈检测中的透明度和可解释性不足问题，提出了一种结合 stacking ensemble 方法（使用 XGBoost、LightGBM 和 CatBoost）的框架，并整合 Explainable AI (XAI) 技术。\n该框架通过 SHAP 进行特征选择，并利用 LIME、Partial Dependence Plots (PDP) 和 Permutation Feature Importance (PFI) 来解释模型预测决策。\n在 IEEE-CIS Fraud Detection 数据集（包含超过590,000条真实交易记录）上，模型实现了99%的准确率和0.99的 AUC-ROC 分数，优于现有方法。\n这一方法证明了高预测准确性与透明解释性的结合可能，为更道德和可信的金融欺诈检测解决方案提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10050v1",
      "published_date": "2025-05-15 07:53:02 UTC",
      "updated_date": "2025-05-15 07:53:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:26:42.662116"
    },
    {
      "arxiv_id": "2505.10043v2",
      "title": "Boosting Text-to-Chart Retrieval through Training with Synthesized Semantic Insights",
      "title_zh": "通过利用合成的语义洞见训练提升文本到图表检索",
      "authors": [
        "Yifan Wu",
        "Lutao Yan",
        "Yizhang Zhu",
        "Yinan Mei",
        "Jiannan Wang",
        "Nan Tang",
        "Yuyu Luo"
      ],
      "abstract": "Charts are crucial for data analysis and decision-making.Text-to-chart\nretrieval systems have become increasingly important for Business Intelligence\n(BI), where users need to find relevant charts that match their analytical\nneeds. These needs can be categorized into precise queries that are\nwell-specified and fuzzy queries that are more exploratory -- both require\nunderstanding the semantics and context of the charts. However, existing\ntext-to-chart retrieval solutions often fail to capture the semantic content\nand contextual information of charts, primarily due to the lack of\ncomprehensive metadata (or semantic insights). To address this limitation, we\npropose a training data development pipeline that automatically synthesizes\nhierarchical semantic insights for charts, covering visual patterns\n(visual-oriented), statistical properties (statistics-oriented), and practical\napplications (task-oriented), which produces 207,498 semantic insights for\n69,166 charts. Based on these, we train a CLIP-based model named ChartFinder to\nlearn better representations of charts for text-to-chart retrieval. Our method\nleverages rich semantic insights during the training phase to develop a model\nthat understands both visual and semantic aspects of charts.To evaluate\ntext-to-chart retrieval performance, we curate the first benchmark, CRBench,\nfor this task with 21,862 charts and 326 text queries from real-world BI\napplications, with ground-truth labels verified by the crowd\nworkers.Experiments show that ChartFinder significantly outperforms existing\nmethods in text-to-chart retrieval tasks across various settings. For precise\nqueries, ChartFinder achieves up to 66.9% NDCG@10, which is 11.58% higher than\nstate-of-the-art models. In fuzzy query tasks, our method also demonstrates\nconsistent improvements, with an average increase of 5% across nearly all\nmetrics.",
      "tldr_zh": "该研究针对文本到图表检索（Text-to-Chart Retrieval）系统存在的语义内容和上下文捕捉不足的问题，提出了一种基于合成语义洞见的训练数据开发管道。该管道自动生成图表的层次化语义洞见，包括视觉模式（visual patterns）、统计属性（statistical properties）和实际应用（task-oriented），从而为69,166个图表生成了207,498个语义洞见。基于此，研究训练了一个CLIP-based模型ChartFinder，使其更好地理解图表的视觉和语义方面。实验在首个基准CRBench上评估，该基准包含21,862个图表和326个真实查询，结果显示ChartFinder在精确查询中NDCG@10达到66.9%，比最先进模型高11.58%，而在模糊查询中平均提升5%以上。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10043v2",
      "published_date": "2025-05-15 07:41:14 UTC",
      "updated_date": "2025-05-21 03:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:26:53.289040"
    },
    {
      "arxiv_id": "2505.10037v1",
      "title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction",
      "title_zh": "用于抗癌药物反应预测的量子-经典混合模型中的最优归一化",
      "authors": [
        "Takafumi Ito",
        "Lysenko Artem",
        "Tatsuhiko Tsunoda"
      ],
      "abstract": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers.",
      "tldr_zh": "这篇论文探讨了量子-经典混合机器学习 (QHML) 模型在癌症药物反应预测中的应用，强调其在小数据集上具有高泛化能力和鲁棒性，但容易受数据编码影响导致稳定性问题。研究提出了一种新型归一化策略，使用基于 moderated gradient 版本的 $\\tanh$ 函数来转换神经网络输出，避免值集中在极端范围，从而优化数据接口。实验结果显示，在基因表达和药物反应数据集上，QHML 模型在优化归一化后比经典深度学习模型表现更优，为量子计算机在生物医学数据分析中开辟了新可能性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10037v1",
      "published_date": "2025-05-15 07:33:41 UTC",
      "updated_date": "2025-05-15 07:33:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:27:05.251193"
    },
    {
      "arxiv_id": "2505.10034v1",
      "title": "The First MPDD Challenge: Multimodal Personality-aware Depression Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Changzeng Fu",
        "Zelin Fu",
        "Xinhe Kuang",
        "Jiacheng Dong",
        "Qi Zhang",
        "Kaifeng Su",
        "Yikai Su",
        "Wenbo Shi",
        "Junfeng Yao",
        "Yuliang Zhao",
        "Shiqi Zhao",
        "Jiadong Wang",
        "Siyang Song",
        "Chaoran Liu",
        "Yuichiro Yoshikawa",
        "Björn Schuller",
        "Hiroshi Ishiguro"
      ],
      "abstract": "Depression is a widespread mental health issue affecting diverse age groups,\nwith notable prevalence among college students and the elderly. However,\nexisting datasets and detection methods primarily focus on young adults,\nneglecting the broader age spectrum and individual differences that influence\ndepression manifestation. Current approaches often establish a direct mapping\nbetween multimodal data and depression indicators, failing to capture the\ncomplexity and diversity of depression across individuals. This challenge\nincludes two tracks based on age-specific subsets: Track 1 uses the\nMPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses\nthe MPDD-Young dataset for detecting depression in younger participants. The\nMultimodal Personality-aware Depression Detection (MPDD) Challenge aims to\naddress this gap by incorporating multimodal data alongside individual\ndifference factors. We provide a baseline model that fuses audio and video\nmodalities with individual difference information to detect depression\nmanifestations in diverse populations. This challenge aims to promote the\ndevelopment of more personalized and accurate de pression detection methods,\nadvancing mental health research and fostering inclusive detection systems.\nMore details are available on the official challenge website:\nhttps://hacilab.github.io/MPDDChallenge.github.io.",
      "tldr_zh": "该论文介绍了首个 MPDD 挑战（Multimodal Personality-aware Depression Detection），旨在解决现有抑郁检测方法忽略年龄多样性和个体差异的问题，这些方法通常直接映射多模态数据到抑郁指标，却未能捕捉抑郁的复杂表现。挑战分为两个赛道：Track 1 使用 MPDD-Elderly 数据集针对老年人进行抑郁检测，Track 2 使用 MPDD-Young 数据集针对年轻人。论文提供了一个基线模型，通过融合音频、视频模态与个体差异信息，提升抑郁检测的准确性和个性化，最终推动心理健康研究和更包容的检测系统发展。",
      "categories": [
        "cs.AI",
        "68T07",
        "I.2.0; H.5.1"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted as part of the MPDD Challenge in the\n  ACMMM 2025 Grand Challenge",
      "pdf_url": "http://arxiv.org/pdf/2505.10034v1",
      "published_date": "2025-05-15 07:29:33 UTC",
      "updated_date": "2025-05-15 07:29:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:27:17.583806"
    },
    {
      "arxiv_id": "2505.10027v1",
      "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Shijie Lyu"
      ],
      "abstract": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes.",
      "tldr_zh": "本研究提出了一种基于离线强化学习的潜在扩散模型（ORL-LDM），用于遥感图像超分辨率重建，以克服现有深度学习方法在处理复杂场景和保留细节方面的局限性。该方法构建了一个强化学习环境，包括状态、动作和奖励，并通过近端策略优化（PPO）算法优化 LDM 模型的逆向去噪过程，从而提升图像重建质量。在 RESISC45 数据集上的实验显示，与基线模型相比，ORL-LDM 在 PSNR 上提高了 3-4 dB、SSIM 提高了 0.08-0.11、LPIPS 降低了 0.06-0.10，尤其在结构化和复杂自然场景中表现突出。该方法证明了其在提高超分辨率图像质量和适应性方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the 4th International Conference on Computing Innovation\n  and Applied Physics (CONF-CIAP 2025), and will be published in EAI Community\n  Research Series-CORE or Theoretical and Natural Science (TNS)",
      "pdf_url": "http://arxiv.org/pdf/2505.10027v1",
      "published_date": "2025-05-15 07:17:03 UTC",
      "updated_date": "2025-05-15 07:17:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:27:29.637173"
    },
    {
      "arxiv_id": "2505.10016v1",
      "title": "Application of YOLOv8 in monocular downward multiple Car Target detection",
      "title_zh": "翻译失败",
      "authors": [
        "Shijie Lyu"
      ],
      "abstract": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection.",
      "tldr_zh": "本论文探讨了YOLOv8在单目向下多车目标检测中的应用，旨在解决自动驾驶系统中物体检测面临的挑战，如高成本、天气和光照影响以及分辨率限制。研究团队通过整合结构重参数化技术、bidirectional pyramid structure network model和新型检测管道，对YOLOv8框架进行了改进，提升了多尺度、小型和远程物体的检测效率和精度。实验结果显示，该增强模型的检测准确率达到65%，在大型和小目标检测上显著优于传统方法，并适用于实际自动驾驶场景和赛事如Formula Student Autonomous China (FSAC)。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.8; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the 5th International Conference on Signal Processing and\n  Machine Learning (CONF-SPML 2025), to appear in Applied and Computational\n  Engineering",
      "pdf_url": "http://arxiv.org/pdf/2505.10016v1",
      "published_date": "2025-05-15 06:58:45 UTC",
      "updated_date": "2025-05-15 06:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:27:40.814903"
    },
    {
      "arxiv_id": "2505.10012v1",
      "title": "Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering",
      "title_zh": "量子计算和人工智能：科学和工程中高级自动化的视角",
      "authors": [
        "Tadashi Kadowaki"
      ],
      "abstract": "Recent advances in artificial intelligence (AI) and quantum computing are\naccelerating automation in scientific and engineering processes, fundamentally\nreshaping research methodologies. This perspective highlights parallels between\nscientific automation and established Computer-Aided Engineering (CAE)\npractices, introducing Quantum CAE as a framework that leverages quantum\nalgorithms for simulation, optimization, and machine learning within\nengineering design. Practical implementations of Quantum CAE are illustrated\nthrough case studies for combinatorial optimization problems. Further\ndiscussions include advancements toward higher automation levels, highlighting\nthe critical role of specialized AI agents proficient in quantum algorithm\ndesign. The integration of quantum computing with AI raises significant\nquestions about the collaborative dynamics among human scientists and\nengineers, AI systems, and quantum computational resources, underscoring a\ntransformative future for automated discovery and innovation.",
      "tldr_zh": "本论文探讨了人工智能（AI）和量子计算如何加速科学和工程领域的自动化，重新塑造研究方法。作者引入了 Quantum CAE 框架，将量子算法应用于工程设计中的模拟、优化和机器学习，并通过组合优化问题的案例研究展示其实践应用。论文强调了专门的 AI 代理在量子算法设计中的关键作用，并讨论了量子计算与 AI 整合对人类科学家、工程师、AI 系统和量子资源协作的影响，预示着自动发现和创新的变革性未来。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10012v1",
      "published_date": "2025-05-15 06:53:30 UTC",
      "updated_date": "2025-05-15 06:53:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:27:52.945964"
    },
    {
      "arxiv_id": "2505.09989v1",
      "title": "AI Greenferencing: Routing AI Inferencing to Green Modular Data Centers with Heron",
      "title_zh": "翻译失败",
      "authors": [
        "Tella Rajashekhar Reddy",
        "Palak",
        "Rohan Gandhi",
        "Anjaly Parayil",
        "Chaojie Zhang",
        "Mike Shepperd",
        "Liangcheng Yu",
        "Jayashree Mohan",
        "Srinivasan Iyengar",
        "Shivkumar Kalyanaraman",
        "Debopam Bhattacherjee"
      ],
      "abstract": "AI power demand is growing unprecedentedly thanks to the high power density\nof AI compute and the emerging inferencing workload. On the supply side,\nabundant wind power is waiting for grid access in interconnection queues. In\nthis light, this paper argues bringing AI workload to modular compute clusters\nco-located in wind farms. Our deployment right-sizing strategy makes it\neconomically viable to deploy more than 6 million high-end GPUs today that\ncould consume cheap, green power at its source. We built Heron, a cross-site\nsoftware router, that could efficiently leverage the complementarity of power\ngeneration across wind farms by routing AI inferencing workload around power\ndrops. Using 1-week ofcoding and conversation production traces from Azure and\n(real) variable wind power traces, we show how Heron improves aggregate goodput\nof AI compute by up to 80% compared to the state-of-the-art.",
      "tldr_zh": "这篇论文针对 AI 计算的电力需求急剧增长问题，提出将 AI 推理工作负载路由到位于风电场的模块化数据中心，以利用廉价的绿色电力。作者开发了 Heron，一种跨站点软件路由器，通过动态路由工作负载来利用风电场之间电力生成的互补性，应对电力波动。实验基于 Azure 的生产跟踪和真实风力发电数据表明，Heron 比现有技术提高了 AI 计算的聚合 goodput 高达 80%，并使部署超过 600 万高端 GPUs 成为经济可行。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09989v1",
      "published_date": "2025-05-15 06:03:47 UTC",
      "updated_date": "2025-05-15 06:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:28:05.575685"
    },
    {
      "arxiv_id": "2505.10593v1",
      "title": "LLM-Explorer: Towards Efficient and Affordable LLM-based Exploration for Mobile Apps",
      "title_zh": "翻译失败",
      "authors": [
        "Shanhui Zhao",
        "Hao Wen",
        "Wenjie Du",
        "Cheng Liang",
        "Yunxin Liu",
        "Xiaozhou Ye",
        "Ye Ouyang",
        "Yuanchun Li"
      ],
      "abstract": "Large language models (LLMs) have opened new opportunities for automated\nmobile app exploration, an important and challenging problem that used to\nsuffer from the difficulty of generating meaningful UI interactions. However,\nexisting LLM-based exploration approaches rely heavily on LLMs to generate\nactions in almost every step, leading to a huge cost of token fees and\ncomputational resources. We argue that such extensive usage of LLMs is neither\nnecessary nor effective, since many actions during exploration do not require,\nor may even be biased by the abilities of LLMs. Further, based on the insight\nthat a precise and compact knowledge plays the central role for effective\nexploration, we introduce LLM-Explorer, a new exploration agent designed for\nefficiency and affordability. LLM-Explorer uses LLMs primarily for maintaining\nthe knowledge instead of generating actions, and knowledge is used to guide\naction generation in a LLM-less manner. Based on a comparison with 5 strong\nbaselines on 20 typical apps, LLM-Explorer was able to achieve the fastest and\nhighest coverage among all automated app explorers, with over 148x lower cost\nthan the state-of-the-art LLM-based approach.",
      "tldr_zh": "这篇论文提出了 LLM-Explorer，一种高效且经济的移动 app 探索框架，旨在减少对大型语言模型(LLMs)的过度依赖，以降低 token 费用和计算资源消耗。与现有方法不同，LLM-Explorer 主要使用 LLMs 来维护精确的知识库，而非在每个步骤生成动作，而是通过知识指导无 LLM 的动作生成，从而提升探索效率。实验结果显示，在 20 个典型 app 上，该框架比 5 个强基线实现了最快和最高覆盖率，且成本比最先进的 LLM-based 方法低 148 倍。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by MobiCom 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10593v1",
      "published_date": "2025-05-15 05:28:35 UTC",
      "updated_date": "2025-05-15 05:28:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:28:17.610328"
    },
    {
      "arxiv_id": "2505.09974v1",
      "title": "Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data",
      "title_zh": "翻译失败",
      "authors": [
        "Adel ElZemity",
        "Budi Arief",
        "Shujun Li"
      ],
      "abstract": "The integration of large language models (LLMs) into cyber security\napplications presents significant opportunities, such as enhancing threat\nanalysis and malware detection, but can also introduce critical risks and\nsafety concerns, including personal data leakage and automated generation of\nnew malware. We present a systematic evaluation of safety risks in fine-tuned\nLLMs for cyber security applications. Using the OWASP Top 10 for LLM\nApplications framework, we assessed seven open-source LLMs: Phi 3 Mini 3.8B,\nMistral 7B, Qwen 2.5 7B, Llama 3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B.\nOur evaluation shows that fine-tuning reduces safety resilience across all\ntested LLMs (e.g., the safety score of Llama 3.1 8B against prompt injection\ndrops from 0.95 to 0.15). We propose and evaluate a safety alignment approach\nthat carefully rewords instruction-response pairs to include explicit safety\nprecautions and ethical considerations. This approach demonstrates that it is\npossible to maintain or even improve model safety while preserving technical\nutility, offering a practical path forward for developing safer fine-tuning\nmethodologies. This work offers a systematic evaluation for safety risks in\nLLMs, enabling safer adoption of generative AI in sensitive domains, and\ncontributing towards the development of secure, trustworthy, and ethically\naligned LLMs.",
      "tldr_zh": "该论文分析了使用伪恶意网络安全数据微调大型语言模型（LLMs）的安全风险，强调了这些模型在网络安全应用中的潜在问题，如个人数据泄露和自动生成恶意软件。研究者采用 OWASP Top 10 for LLM Applications 框架，对七个开源 LLMs（包括 Phi 3 Mini 3.8B、Mistral 7B、Qwen 2.5 7B 等）进行了系统评估，结果显示微调过程显著降低了模型的安全性，例如 Llama 3.1 8B 对提示注入的安全分数从 0.95 降至 0.15。作者提出了一种安全对齐方法，通过重新措辞指令-响应对以纳入显式安全预防和道德考虑，从而在保持技术效用前提下维持或提升模型安全性，为开发安全、可信赖的 LLMs 提供了实用路径。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09974v1",
      "published_date": "2025-05-15 05:22:53 UTC",
      "updated_date": "2025-05-15 05:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:28:31.357100"
    },
    {
      "arxiv_id": "2505.09970v2",
      "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents",
      "title_zh": "Pre-Act：多步规划和推理提升LLM代理中的行动",
      "authors": [
        "Mrinal Rawat",
        "Ambuje Gupta",
        "Rushil Goomer",
        "Alessandro Di Bari",
        "Neha Gupta",
        "Roberto Pieraccini"
      ],
      "abstract": "The ReAct (Reasoning + Action) capability in large language models (LLMs) has\nbecome the foundation of modern agentic systems. Recent LLMs, such as\nDeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through\nthe generation of ample intermediate tokens, which help build a strong premise\nbefore producing the final output tokens. In this paper, we introduce Pre-Act,\na novel approach that enhances the agent's performance by creating a multi-step\nexecution plan along with the detailed reasoning for the given user input. This\nplan incrementally incorporates previous steps and tool outputs, refining\nitself after each step execution until the final response is obtained. Our\napproach is applicable to both conversational and non-conversational agents. To\nmeasure the performance of task-oriented agents comprehensively, we propose a\ntwo-level evaluation framework: (1) turn level and (2) end-to-end. Our\nturn-level evaluation, averaged across five models, shows that our approach,\nPre-Act, outperforms ReAct by 70% in Action Recall on the Almita dataset. While\nthis approach is effective for larger models, smaller models crucial for\npractical applications, where latency and cost are key constraints, often\nstruggle with complex reasoning tasks required for agentic systems. To address\nthis limitation, we fine-tune relatively small models such as Llama 3.1 (8B &\n70B) using the proposed Pre-Act approach. Our experiments show that the\nfine-tuned 70B model outperforms GPT-4, achieving a 69.5% improvement in action\naccuracy (turn-level) and a 28% improvement in goal completion rate\n(end-to-end) on the Almita (out-of-domain) dataset.",
      "tldr_zh": "该论文引入了Pre-Act方法，通过多步规划和推理来提升大型语言模型(LLMs)代理的性能，特别是针对ReAct框架的改进。Pre-Act为用户输入生成详细的执行计划，并在每个步骤后整合先前输出进行完善，适用于对话和非对话代理，并提出一个两级评估框架（turn level和end-to-end）。实验结果显示，Pre-Act在Almita数据集上使Action Recall比ReAct提高70%，而微调后的Llama 3.1 70B模型在行动准确率上比GPT-4提升69.5%，在目标完成率上提升28%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09970v2",
      "published_date": "2025-05-15 05:17:47 UTC",
      "updated_date": "2025-05-19 03:17:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:28:42.870121"
    },
    {
      "arxiv_id": "2505.09969v1",
      "title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Azimi Lamir",
        "Shiva Razzagzadeh",
        "Zeynab Rezaei"
      ],
      "abstract": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics.",
      "tldr_zh": "本研究提出一个全面的机器学习框架，用于心脏病预测，基于包含303个样本和14个特征的heart-disease数据集。方法包括数据预处理、训练Logistic Regression、K-Nearest Neighbors (KNN)和Random Forest分类器，并通过GridSearchCV和RandomizedSearchCV进行超参数调优，其中Random Forest分类器表现出色，达到91%的accuracy和0.89的F1-score。实验结果显示该框架在预测准确性和平衡性能（如precision、recall和confusion matrix）方面表现强劲，有助于临床决策，但受限于数据集规模和泛化性，未来需采用更大更多样化的数据集进行改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09969v1",
      "published_date": "2025-05-15 05:13:38 UTC",
      "updated_date": "2025-05-15 05:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:28:53.942558"
    },
    {
      "arxiv_id": "2505.09955v1",
      "title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeho Kim",
        "Seulki Lee"
      ],
      "abstract": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices.",
      "tldr_zh": "这篇论文提出 TransPL，一种用于时间序列无监督域适应 (UDA) 的新方法，通过向量量化 (VQ) 对时间序列补丁进行编码，构建源域的类级和通道级代码转移矩阵，并利用贝叶斯规则生成基于通道加权的伪标签，以捕捉时间模式和通道转移。TransPL 的关键优势包括显式建模域间差异、适用于不同 UDA 场景（如弱监督 UDA），以及提供可解释的伪标签生成过程。在四个时间序列 UDA 基准测试中，该方法比现有伪标签策略提高了 6.1% 准确率和 4.9% F1 分数，并通过学得的代码转移矩阵提供可解释的域适应洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025 Accept",
      "pdf_url": "http://arxiv.org/pdf/2505.09955v1",
      "published_date": "2025-05-15 04:27:48 UTC",
      "updated_date": "2025-05-15 04:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:29:05.892069"
    },
    {
      "arxiv_id": "2505.09952v1",
      "title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning",
      "title_zh": "任务核心记忆管理和巩固技术用于长期持续学习",
      "authors": [
        "Tianyu Huai",
        "Jie Zhou",
        "Yuxuan Cai",
        "Qin Chen",
        "Wen Wu",
        "Xingjiao Wu",
        "Xipeng Qiu",
        "Liang He"
      ],
      "abstract": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach.",
      "tldr_zh": "本论文针对长期持续学习（long-term continual learning）问题，探讨模型在处理大量顺序任务时如何避免灾难性遗忘（catastrophic forgetting），同时保留先前知识以模拟人类学习机制。作者提出Long-CL框架，包括task-core memory management策略，用于高效索引和适应性更新关键记忆，以及long-term memory consolidation机制，用于选择性保留困难和鉴别性样本以强化知识保留。为了推动研究，他们构建并发布了多模态基准MMLongCL-Bench和文本基准TextLongCL-Bench。实验结果显示，Long-CL框架分别在两个基准上比现有最先进方法提高了7.4%和6.5%的AP，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to Neurips2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09952v1",
      "published_date": "2025-05-15 04:22:35 UTC",
      "updated_date": "2025-05-15 04:22:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:29:17.661443"
    },
    {
      "arxiv_id": "2505.11547v1",
      "title": "On Technique Identification and Threat-Actor Attribution using LLMs and Embedding Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kyla Guru",
        "Robert J. Moss",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "Attribution of cyber-attacks remains a complex but critical challenge for\ncyber defenders. Currently, manual extraction of behavioral indicators from\ndense forensic documentation causes significant attribution delays, especially\nfollowing major incidents at the international scale. This research evaluates\nlarge language models (LLMs) for cyber-attack attribution based on behavioral\nindicators extracted from forensic documentation. We test OpenAI's GPT-4 and\ntext-embedding-3-large for identifying threat actors' tactics, techniques, and\nprocedures (TTPs) by comparing LLM-generated TTPs against human-generated data\nfrom MITRE ATT&CK Groups. Our framework then identifies TTPs from text using\nvector embedding search and builds profiles to attribute new attacks for a\nmachine learning model to learn. Key contributions include: (1) assessing\noff-the-shelf LLMs for TTP extraction and attribution, and (2) developing an\nend-to-end pipeline from raw CTI documents to threat-actor prediction. This\nresearch finds that standard LLMs generate TTP datasets with noise, resulting\nin a low similarity to human-generated datasets. However, the TTPs generated\nare similar in frequency to those within the existing MITRE datasets.\nAdditionally, although these TTPs are different than human-generated datasets,\nour work demonstrates that they still prove useful for training a model that\nperforms above baseline on attribution. Project code and files are contained\nhere: https://github.com/kylag/ttp_attribution.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）如 OpenAI 的 GPT-4 和 text-embedding-3-large，用于从取证文档中提取行为指标，以识别威胁行为者的策略、技术和程序（TTPs），并将其与 MITRE ATT&CK Groups 的手动数据比较。研究开发了一个端到端框架，利用向量嵌入搜索构建 TTP 配置文件，并训练机器学习模型进行攻击归因。关键贡献包括评估现成 LLMs 的提取和归因性能，以及从原始 CTI 文档到威胁行为者预测的完整管道；尽管 LLMs 生成的 TTP 数据集存在噪音和与人工数据集的低相似度，但这些数据仍能有效训练模型，使其在归因任务中超过基线水平。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11547v1",
      "published_date": "2025-05-15 04:14:29 UTC",
      "updated_date": "2025-05-15 04:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:29:30.356815"
    },
    {
      "arxiv_id": "2505.09945v1",
      "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph",
      "title_zh": "使用检索增强生成和知识图谱个性化大型语言模型",
      "authors": [
        "Deeksha Prahlad",
        "Chanhee Lee",
        "Dongha Kim",
        "Hokeun Kim"
      ],
      "abstract": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 的过拟合问题及其导致的幻觉 (hallucinations)，提出了一种个性化方法，通过检索增强生成 (RAG) 和知识图谱 (KGs) 辅助 LLMs 生成及时、事实性和个性化的响应。方法利用 KGs 的结构化存储优势，将其应用于用户个人数据，如日历信息，从而提升模型对个人信息的理解和响应准确性。与基线 LLMs 相比，实验结果显示，该方法显著提高了响应准确性，同时响应时间仅适度增加。总的来说，这一创新为构建更可靠的对话助手提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)",
      "pdf_url": "http://arxiv.org/pdf/2505.09945v1",
      "published_date": "2025-05-15 04:01:58 UTC",
      "updated_date": "2025-05-15 04:01:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:29:40.772997"
    },
    {
      "arxiv_id": "2505.09935v1",
      "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed S. Abdelrahman",
        "Mohamed Abdel-Aty",
        "Quoc Dai Tran"
      ],
      "abstract": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users.",
      "tldr_zh": "该研究提出 VRU-CIPI 框架，使用基于顺序注意力的模型来预测脆弱道路用户 (VRUs) 在十字路口的过马路意图，从而提升道路安全。框架结合 Gated Recurrent Unit (GRU) 捕捉 VRUs 运动的时序动态，以及多头 Transformer 自注意力机制编码上下文和空间依赖。实验在 UCF-VRU 数据集上实现 96.45% 的准确率和 33 帧/秒的实时推理速度；此外，通过与 Infrastructure-to-Vehicles (I2V) 通信整合，该方法能及时激活过马路信号并向车辆发出警告，促进更安全高效的道路互动。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09935v1",
      "published_date": "2025-05-15 03:40:29 UTC",
      "updated_date": "2025-05-15 03:40:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:29:53.422155"
    },
    {
      "arxiv_id": "2505.09932v1",
      "title": "Demystifying AI Agents: The Final Generation of Intelligence",
      "title_zh": "揭秘 AI 代理：智能的最终一代",
      "authors": [
        "Kevin J McNamara",
        "Rhea Pritham Marpu"
      ],
      "abstract": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence.",
      "tldr_zh": "这篇白皮书回顾了人工智能（AI）从简单规则系统到复杂自主AI agents的演变历程，强调了关键技术里程碑如提示技术、训练方法、硬件能力和架构创新的贡献。论文认为，当前AI agents（如OpenAI的ChatGPT with plugins和xAI的Grok）可能代表AI发展的“最终一代”，具备高级推理和交互能力，并通过实际例子阐述其潜力。研究还探讨了AI进步的惊人速度（每六个月翻倍）所带来的社会影响，并呼吁在应对机遇和挑战时需注入智慧和远见。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09932v1",
      "published_date": "2025-05-15 03:35:12 UTC",
      "updated_date": "2025-05-15 03:35:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:30:05.923665"
    },
    {
      "arxiv_id": "2505.09926v2",
      "title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Bin-Bin Gao",
        "Yue Zhou",
        "Jiangtao Yan",
        "Yuezhi Cai",
        "Weixi Zhang",
        "Meng Wang",
        "Jun Liu",
        "Yong Liu",
        "Lei Wang",
        "Chengjie Wang"
      ],
      "abstract": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP.",
      "tldr_zh": "本研究提出AdaptCLIP，一种适应CLIP模型的方法，用于通用视觉异常检测，能够在无需额外微调的情况下识别新型或未见领域的异常。AdaptCLIP基于两个关键洞见：视觉和文本表示应交替学习，以及查询与正常图像提示的比较学习需结合上下文和对齐的残差特征；它仅添加视觉适配器、文本适配器和提示查询适配器，支持zero-/few-shot泛化，并在基数据集上训练后实现目标域的无训练方式。在12个工业和医疗领域的异常检测基准上，AdaptCLIP显著优于现有方法，达到最先进性能，并计划开源代码和模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "27 pages, 15 figures, 22 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.09926v2",
      "published_date": "2025-05-15 03:24:28 UTC",
      "updated_date": "2025-05-19 03:02:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:30:16.754663"
    },
    {
      "arxiv_id": "2505.09925v1",
      "title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Yutao Yang",
        "Jie Zhou",
        "Junsong Li",
        "Qianjun Pan",
        "Bihao Zhan",
        "Qin Chen",
        "Xipeng Qiu",
        "Liang He"
      ],
      "abstract": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods.",
      "tldr_zh": "这篇论文提出了一种交互式持续学习范式，AI 模型通过实时人类反馈动态学习新技能，同时保留先前知识，并处理传统持续学习的局限，如依赖静态数据集和噪声标签问题。作者引入 RiCL 框架，利用 Large Language Models (LLMs) 及其三个关键组件：temporal consistency-aware purifier 来自动区分噪声样本、interaction-aware direct preference optimization 来协调 AI 和人类反馈以对齐意图，以及 noise-resistant contrastive learning 来捕获鲁棒表示，从而避免依赖不可靠标签。在 FewRel 和 TACRED 数据集上的实验显示，RiCL 框架显著优于现有在线持续学习和噪声标签学习方法，证明了其在真实交互场景中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09925v1",
      "published_date": "2025-05-15 03:22:03 UTC",
      "updated_date": "2025-05-15 03:22:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:30:30.223996"
    },
    {
      "arxiv_id": "2505.09923v1",
      "title": "\"There Is No Such Thing as a Dumb Question,\" But There Are Good Ones",
      "title_zh": "“世上没有愚蠢的问题”，但有些问题是好的。",
      "authors": [
        "Minjung Shin",
        "Donghyun Kim",
        "Jeh-Kwang Ryu"
      ],
      "abstract": "Questioning has become increasingly crucial for both humans and artificial\nintelligence, yet there remains limited research comprehensively assessing\nquestion quality. In response, this study defines good questions and presents a\nsystematic evaluation framework. We propose two key evaluation dimensions:\nappropriateness (sociolinguistic competence in context) and effectiveness\n(strategic competence in goal achievement). Based on these foundational\ndimensions, a rubric-based scoring system was developed. By incorporating\ndynamic contextual variables, our evaluation framework achieves structure and\nflexibility through semi-adaptive criteria. The methodology was validated using\nthe CAUS and SQUARE datasets, demonstrating the ability of the framework to\naccess both well-formed and problematic questions while adapting to varied\ncontexts. As we establish a flexible and comprehensive framework for question\nevaluation, this study takes a significant step toward integrating questioning\nbehavior with structured analytical methods grounded in the intrinsic nature of\nquestioning.",
      "tldr_zh": "这篇论文探讨了问题质量评估的重要性，针对人类和人工智能的质疑行为，定义了“好问题”并提出一个系统评价框架。研究引入两个关键维度：appropriateness（语境中的社会语言能力）和effectiveness（目标实现中的战略能力），并开发了一个rubric-based scoring system，通过整合动态contextual variables实现semi-adaptive criteria。框架在CAUS和SQUARE数据集上得到验证，能有效评估良好和有问题的问句，并适应不同语境，从而为将问题行为与结构化分析方法整合奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures and 4 tables. This work has been accepted for\n  presentation as a poster with full paper publication at CogSci 2025. This is\n  the final submission",
      "pdf_url": "http://arxiv.org/pdf/2505.09923v1",
      "published_date": "2025-05-15 03:12:28 UTC",
      "updated_date": "2025-05-15 03:12:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:30:41.463527"
    },
    {
      "arxiv_id": "2505.09920v1",
      "title": "Offline Reinforcement Learning for Microgrid Voltage Regulation",
      "title_zh": "翻译失败",
      "authors": [
        "Shan Yang",
        "Yongli Zhu"
      ],
      "abstract": "This paper presents a study on using different offline reinforcement learning\nalgorithms for microgrid voltage regulation with solar power penetration. When\nenvironment interaction is unviable due to technical or safety reasons, the\nproposed approach can still obtain an applicable model through offline-style\ntraining on a previously collected dataset, lowering the negative impact of\nlacking online environment interactions. Experiment results on the IEEE 33-bus\nsystem demonstrate the feasibility and effectiveness of the proposed approach\non different offline datasets, including the one with merely low-quality\nexperience.",
      "tldr_zh": "这篇论文探讨了使用离线强化学习（offline reinforcement learning）算法来调节微电网（microgrid）电压的问题，特别是针对太阳能渗透场景。作者提出了一种方法，通过在预先收集的数据集上进行离线训练，避开了在线环境交互的限制，从而降低了安全和技术挑战带来的负面影响。在 IEEE 33-bus 系统上的实验结果证明了该方法的有效性，即使在仅包含低质量经验的数据集上也能取得良好的性能。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09920v1",
      "published_date": "2025-05-15 03:10:18 UTC",
      "updated_date": "2025-05-15 03:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:30:52.691096"
    },
    {
      "arxiv_id": "2505.09907v1",
      "title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Linwei Zhang",
        "LuFeng",
        "Ruijia Liang"
      ],
      "abstract": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization.",
      "tldr_zh": "本文提出了一种混合深度学习模型TCN-MLP-Attention，用于预测Hass鳄梨的价格，该模型结合TCN（Temporal Convolutional Networks）提取序列特征、MLP（Multi-Layer Perceptrons）处理非线性交互，以及Attention机制动态加权特征，以应对价格波动的复杂性。模型基于超过50,000条美国鳄梨销售数据（2015-2018年），包括销售量、平均价格、时间、地域、天气和品种等变量，经过缺失值填充和特征归一化等预处理后进行训练。实验结果显示，该模型的RMSE为1.23和MSE为1.51，显著优于传统方法，为农业市场时间序列预测提供可扩展的解决方案，并支持智能供应链管理和价格策略优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09907v1",
      "published_date": "2025-05-15 02:26:22 UTC",
      "updated_date": "2025-05-15 02:26:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:31:05.441162"
    },
    {
      "arxiv_id": "2505.09901v1",
      "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyuan Zhang",
        "Darcy Wang",
        "Ningyuan Chen",
        "Rodrigo Mansur",
        "Vahid Sarhangian"
      ],
      "abstract": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements.",
      "tldr_zh": "这篇论文比较了大型语言模型 (LLMs) 和人类的探索-利用 (E&E) 策略，通过标准多臂赌博机 (MAB) 任务进行分析。研究采用可解释选择模型和推理增强方法（如提示策略），发现启用推理后，LLMs 的行为更接近人类，表现出相似的随机和定向探索，尤其在简单静态任务中。然而，在复杂非静态环境中，LLMs 难以匹配人类的适应性，特别是定向探索的有效性，尽管在某些场景下其后悔率与人类相当。总体而言，该研究突显了 LLMs 作为人类行为模拟器和决策工具的潜力与局限性，并指出了改进方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09901v1",
      "published_date": "2025-05-15 02:09:18 UTC",
      "updated_date": "2025-05-15 02:09:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:31:17.926841"
    },
    {
      "arxiv_id": "2505.15828v1",
      "title": "Generative AI-Aided QoE Maximization for RIS-Assisted Digital Twin Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayuan Chen",
        "Yuxiang Li",
        "Changyan Yi",
        "Shimin Gong"
      ],
      "abstract": "In this paper, we investigate a quality of experience (QoE)-aware resource\nallocation problem for reconfigurable intelligent surface (RIS)-assisted\ndigital twin (DT) interaction with uncertain evolution. In the considered\nsystem, mobile users are expected to interact with a DT model maintained on a\nDT server that is deployed on a base station, via effective uplink and downlink\nchannels assisted by an RIS. Our goal is to maximize the sum of all mobile\nusers' joint subjective and objective QoE in DT interactions across various DT\nscenes, by jointly optimizing phase shift matrix, receive/transmit beamforming\nmatrix, rendering resolution configuration and computing resource allocation.\nWhile solving this problem is challenging mainly due to the uncertain evolution\nof the DT model, which leads to multiple scene-specific problems, and require\nus to constantly re-solve each of them whenever DT model evolves.\n  To this end, leveraging the dynamic optimization capabilities of decision\ntransformers and the generalization strengths of generative artificial\nintelligence (GAI), we propose a novel GAI-aided approach, called the\nprompt-guided decision transformer integrated with zero-forcing optimization\n(PG-ZFO). Simulations are conducted to evaluate the proposed PG-ZFO,\ndemonstrating its effectiveness and superiority over counterparts.",
      "tldr_zh": "本文研究了可重构智能表面(RIS)辅助的数字孪生(DT)交互中，用户质量体验(QoE)感知资源分配问题，目标是通过优化相移矩阵、收发波束形成矩阵、渲染分辨率和计算资源分配，来最大化所有移动用户的联合主观和客观QoE，同时应对DT模型不确定演化的挑战。  \n为解决这一问题，作者提出了一种新型方法prompt-guided decision transformer integrated with zero-forcing optimization (PG-ZFO)，它利用decision transformers的动态优化能力和generative artificial intelligence (GAI)的泛化优势，实现对多个场景特定问题的有效处理。  \n模拟实验结果显示，PG-ZFO比传统方法表现出显著优越性，证明了其在提升QoE方面的有效性。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15828v1",
      "published_date": "2025-05-15 02:00:29 UTC",
      "updated_date": "2025-05-15 02:00:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:31:30.159137"
    },
    {
      "arxiv_id": "2505.10590v1",
      "title": "Anchoring AI Capabilities in Market Valuations: The Capability Realization Rate Model and Valuation Misalignment Risk",
      "title_zh": "将 AI 能力锚定在市场估值中：能力实现率",
      "authors": [
        "Xinmin Fang",
        "Lingfeng Tao",
        "Zhengxiong Li"
      ],
      "abstract": "Recent breakthroughs in artificial intelligence (AI) have triggered surges in\nmarket valuations for AI-related companies, often outpacing the realization of\nunderlying capabilities. We examine the anchoring effect of AI capabilities on\nequity valuations and propose a Capability Realization Rate (CRR) model to\nquantify the gap between AI potential and realized performance. Using data from\nthe 2023--2025 generative AI boom, we analyze sector-level sensitivity and\nconduct case studies (OpenAI, Adobe, NVIDIA, Meta, Microsoft, Goldman Sachs) to\nillustrate patterns of valuation premium and misalignment. Our findings\nindicate that AI-native firms commanded outsized valuation premiums anchored to\nfuture potential, while traditional companies integrating AI experienced\nre-ratings subject to proof of tangible returns. We argue that CRR can help\nidentify valuation misalignment risk-where market prices diverge from realized\nAI-driven value. We conclude with policy recommendations to improve\ntransparency, mitigate speculative bubbles, and align AI innovation with\nsustainable market value.",
      "tldr_zh": "该研究探讨了AI能力对市场估值的锚定效应，提出Capability Realization Rate (CRR)模型来量化AI潜力与实际表现之间的差距，以识别valuation misalignment risk。作者使用2023-2025生成式AI繁荣的数据，分析行业敏感性和对OpenAI、Adobe、NVIDIA、Meta、Microsoft、Goldman Sachs等公司的案例研究，发现AI-native公司因未来潜力获得过高估值溢价，而传统公司需证明tangible returns才能重新估值。研究结果表明，CRR模型有助于揭示市场价格偏离AI驱动价值的风险，并提出政策建议以提升透明度、缓解投机泡沫，并促进AI创新与可持续市场价值的统一。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "11 pages, 3 figures, NeurIPS",
      "pdf_url": "http://arxiv.org/pdf/2505.10590v1",
      "published_date": "2025-05-15 01:06:06 UTC",
      "updated_date": "2025-05-15 01:06:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:31:41.407428"
    },
    {
      "arxiv_id": "2505.11546v1",
      "title": "Control Invariant Sets for Neural Network Dynamical Systems and Recursive Feasibility in Model Predictive Control",
      "title_zh": "神经网络动态系统的控制不变集与模型预测控制中的递归可行性",
      "authors": [
        "Xiao Li",
        "Tianhao Wei",
        "Changliu Liu",
        "Anouck Girard",
        "Ilya Kolmanovsky"
      ],
      "abstract": "Neural networks are powerful tools for data-driven modeling of complex\ndynamical systems, enhancing predictive capability for control applications.\nHowever, their inherent nonlinearity and black-box nature challenge control\ndesigns that prioritize rigorous safety and recursive feasibility guarantees.\nThis paper presents algorithmic methods for synthesizing control invariant sets\nspecifically tailored to neural network based dynamical models. These\nalgorithms employ set recursion, ensuring termination after a finite number of\niterations and generating subsets in which closed-loop dynamics are forward\ninvariant, thus guaranteeing perpetual operational safety. Additionally, we\npropose model predictive control designs that integrate these control invariant\nsets into mixed-integer optimization, with guaranteed adherence to safety\nconstraints and recursive feasibility at the computational level. We also\npresent a comprehensive theoretical analysis examining the properties and\nguarantees of the proposed methods. Numerical simulations in an autonomous\ndriving scenario demonstrate the methods' effectiveness in synthesizing\ncontrol-invariant sets offline and implementing model predictive control\nonline, ensuring safety and recursive feasibility.",
      "tldr_zh": "这篇论文针对神经网络动态系统的建模问题，提出算法方法来合成控制不变集（Control Invariant Sets），以应对其非线性和黑箱特性带来的安全挑战。方法采用集合递归（set recursion）技术，确保在有限迭代后生成前向不变的子集，从而支持闭环动态的安全性，并将其整合到混合整数优化的模型预测控制（Model Predictive Control）设计中，实现递归可行性（Recursive Feasibility）的保证。数值模拟在自动驾驶场景中验证了这些方法的有效性，展示了离线合成控制不变集和在线控制实现的可靠性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11546v1",
      "published_date": "2025-05-15 01:01:14 UTC",
      "updated_date": "2025-05-15 01:01:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:31:53.450345"
    },
    {
      "arxiv_id": "2505.09868v1",
      "title": "Which Demographic Features Are Relevant for Individual Fairness Evaluation of U.S. Recidivism Risk Assessment Tools?",
      "title_zh": "翻译失败",
      "authors": [
        "Tin Trung Nguyen",
        "Jiannan Xu",
        "Phuong-Anh Nguyen-Le",
        "Jonathan Lazar",
        "Donald Braman",
        "Hal Daumé III",
        "Zubin Jelveh"
      ],
      "abstract": "Despite its U.S. constitutional foundation, the technical ``individual\nfairness'' criterion has not been operationalized in state or federal\nstatutes/regulations. We conduct a human subjects experiment to address this\ngap, evaluating which demographic features are relevant for individual fairness\nevaluation of recidivism risk assessment (RRA) tools. Our analyses conclude\nthat the individual similarity function should consider age and sex, but it\nshould ignore race.",
      "tldr_zh": "这篇论文探讨了在评估美国再犯风险评估 (RRA) 工具的 individual fairness 时，哪些人口统计特征（如年龄、性别和种族）相关的问题。研究者通过人类受试者实验操作化这一标准，结果显示个体相似性函数应考虑年龄和性别，但忽略种族。该发现有助于填补 individual fairness 在美国法规中的空白，促进更公平的 RRA 工具设计。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09868v1",
      "published_date": "2025-05-15 00:07:07 UTC",
      "updated_date": "2025-05-15 00:07:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:32:05.325771"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 132,
  "processed_papers_count": 132,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T23:32:30.346343"
}