{
  "date": "2025-05-15",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-15 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 领域，尤其是大型语言模型 (LLM) 的优化、安全性和应用扩展，强调了强化学习、多模态模型和知识图谱的创新；重点包括 Neural Thermodynamic Laws 的理论框架、MathCoder-VL 在多模态数学推理上的突破，以及知名学者如 Max Tegmark 和 Ziming Liu 的作品，这些论文展示了 LLM 在代码生成和推理中的潜力，同时探讨了实际应用中的鲁棒性和公平性挑战。\n\n### LLM 优化与安全：重点论文\n今天的多篇论文探讨了 LLM 的训练动态和安全问题，先聊聊这些令人印象深刻的成果。\n- **Neural Thermodynamic Laws for Large Language Model Training（神经热力学定律用于大型语言模型训练）**：作者包括知名学者 Max Tegmark，该论文引入 NTL 框架，基于热力学原理分析 LLM 训练动态，证明了温度、熵等概念在损失景观下的应用，并提供直观的 learning rate 调度指导，主要贡献是桥接理论与实践，提升了 LLM 训练的鲁棒性。\n- **Superposition Yields Robust Neural Scaling（叠加产生鲁棒神经缩放）**：作者 Ziming Liu 和 Jeff Gore 构建玩具模型，解释 LLM 损失随模型规模的幂律下降，证明强叠加下损失与维度成反比，主要发现是叠加机制驱动了神经缩放定律，为高效训练策略提供新洞见。\n- **J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning（J1：通过强化学习激励 LLM-as-a-Judge 的思考）**：该论文提出强化学习框架优化 LLM 判断过程，通过奖励机制提升推理能力，显著超越 GPT-4 在某些基准上的表现，贡献在于缓解 LLM 幻觉问题，提高 AI 判断的可靠性。\n- **Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models（深入理解大型语言模型的推理能力）**：论文评估 LLM 的自反、启发式突变和规划技术，发现高级提示可缩小模型规模差距，但推理不稳定，主要发现是 LLM 在动态环境中存在根本局限，需要超越静态基准。\n\n### 多模态模型与图像处理：相关创新\n接下来，聊聊多模态和视觉领域的论文，这些与 LLM 结合的进展有话题潜力。\n- **MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning（MathCoder-VL：桥接视觉和代码以增强多模态数学推理）**：Accepted to ACL 2025，该论文使用代码监督对齐视觉和文本模态，构建 ImgCode-8.6M 数据集和 MM-MathInstruct-3M 指令集，MathCoder-VL 模型在 MathVista 上超越 GPT-4o 和 Claude 3.5，主要贡献是提升多模态数学问题解决的精度。\n- **UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation（UniEval：统一的多模态理解和生成的整体评估框架）**：论文提出 UniBench 基准和 UniScore 指标，用于评估多模态模型，UniEval 无需额外标注就实现简化评估，主要发现是它在多样任务上优于现有指标，推动了多模态 AI 的标准化。\n- **AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection（AdaptCLIP：为通用视觉异常检测适配 CLIP）**：该方法通过视觉和文本适配器提升 CLIP 的泛化能力，在工业和医疗基准上实现 SOTA 性能，主要贡献是支持零样本检测，显著减少异常识别错误。\n\n### 强化学习与机器人学：实用应用\n强化学习相关论文也值得一提，尤其是那些解决实际问题的。\n- **FORTRESS: Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning（FORTRESS：通过多模态推理实现实时分布外故障预防）**：论文提出 FORTRESS 框架，使用多模态推理预测机器人故障，并在模拟和硬件上提升安全性，主要发现是它在城市导航中减少了人为干预。\n- **Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps（通过扩散时间步反向传播微调扩散策略）**：引入 NCDPO 框架，使扩散模型在机器人控制中更高效，主要贡献是提升样本效率，适用于多代理游戏场景。\n- **AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge（AI 代理 vs. Agentic AI：概念分类、应用和挑战）**：该论文区分 AI 代理和 Agentic AI，提供分类框架和挑战分析，主要发现是多代理协作在医疗和研究中的潜力。\n\n其他论文如那些探讨量子计算（e.g., Quantum Computing and AI）、知识图谱（e.g., From Text to Network）和图像生成（e.g., SpikeVideoFormer）的，贡献虽稳固但较专业，就快速掠过：它们分别优化了量子模拟、图谱构建和视频生成效率，但细节较琐碎，不如上述主题有话题度。\n\n总之，今天的 arXiv 突显了 AI 领域的快速迭代，LLM 的理论和应用创新尤为突出，建议关注这些论文以把握前沿趋势！",
  "papers": [
    {
      "arxiv_id": "2505.10559v1",
      "title": "Neural Thermodynamic Laws for Large Language Model Training",
      "title_zh": "神经热力学定律用于大型语言模型训练",
      "authors": [
        "Ziming Liu",
        "Yizhou Liu",
        "Jeff Gore",
        "Max Tegmark"
      ],
      "abstract": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules.",
      "tldr_zh": "该论文引入 Neural Thermodynamic Laws (NTL) 框架，以揭示大型语言模型 (LLMs) 训练的底层动态规律。理论上，研究者证明了热力学量（如温度、熵、热容、热传导）和经典热力学原理（如三定律和等分配定理）在河谷损失景观假设下自然浮现。实践上，该框架为设计学习率调度提供了直观的指导，帮助优化LLMs的训练过程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.data-an",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10559v1",
      "published_date": "2025-05-15 17:59:22 UTC",
      "updated_date": "2025-05-15 17:59:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:01.222953"
    },
    {
      "arxiv_id": "2505.10557v1",
      "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning",
      "title_zh": "MathCoder-VL：桥接视觉与代码以增强多模态数学推理",
      "authors": [
        "Ke Wang",
        "Junting Pan",
        "Linda Wei",
        "Aojun Zhou",
        "Weikang Shi",
        "Zimu Lu",
        "Han Xiao",
        "Yunqiao Yang",
        "Houxing Ren",
        "Mingjie Zhan",
        "Hongsheng Li"
      ],
      "abstract": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder.",
      "tldr_zh": "该研究指出，现有的自然语言图像标题数据集忽略了数学图形的复杂细节，限制了 Large Multimodal Models (LMMs) 在多模态数学推理中的发展。为解决这一问题，作者提出使用代码作为监督进行跨模态对齐，开发了 image-to-code 模型 FigCodifier 和数据集 ImgCode-8.6M，这是目前最大的图像代码数据集。接着，利用 FigCodifier 合成新数学图形，构建了高品质的多模态数学指令数据集 MM-MathInstruct-3M。最终，作者训练了 MathCoder-VL 模型，先在 ImgCode-8.6M 上进行跨模态对齐，然后在 MM-MathInstruct-3M 上微调，实现多模态数学问题解决，并在六个指标上达到开源 State-of-the-Art (SOTA)，特别是在 MathVista 的几何子集中 surpassing GPT-4o 和 Claude 3.5 Sonnet，分别提升 8.9% 和 9.2%。数据集和模型将开源于 GitHub。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2505.10557v1",
      "published_date": "2025-05-15 17:59:21 UTC",
      "updated_date": "2025-05-15 17:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:06.565223"
    },
    {
      "arxiv_id": "2505.10551v1",
      "title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data",
      "title_zh": "可行性重要吗？ 理解可行性对合成训练数据的影响",
      "authors": [
        "Yiwen Liu",
        "Jessica Bader",
        "Jae Myung Kim"
      ],
      "abstract": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets.",
      "tldr_zh": "这篇论文探讨了合成训练数据中feasibility（图像属性的现实可能性）对模型性能的影响，质疑是否需要排除infeasible图像（如狗悬浮在空中）。研究引入了VariReal管道，通过大型语言模型生成的文本提示对源图像进行最小编辑，生成feasible或infeasible属性的图像，并针对CLIP-based classifiers的background、color和texture属性进行实验。结果显示，feasibility对LoRA-fine-tuned CLIP的top-1准确率影响极小（小于0.3%），不同属性对性能的影响各异，且混合feasible和infeasible图像的训练数据集与纯数据集相比没有显著差异。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPRW 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10551v1",
      "published_date": "2025-05-15 17:57:38 UTC",
      "updated_date": "2025-05-15 17:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:07.243722"
    },
    {
      "arxiv_id": "2505.10547v1",
      "title": "Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning",
      "title_zh": "实时分布外故障预防通过多模态推理",
      "authors": [
        "Milan Ganai",
        "Rohan Sinha",
        "Christopher Agia",
        "Daniel Morton",
        "Marco Pavone"
      ],
      "abstract": "Foundation models can provide robust high-level reasoning on appropriate\nsafety interventions in hazardous scenarios beyond a robot's training data,\ni.e. out-of-distribution (OOD) failures. However, due to the high inference\nlatency of Large Vision and Language Models, current methods rely on manually\ndefined intervention policies to enact fallbacks, thereby lacking the ability\nto plan generalizable, semantically safe motions. To overcome these challenges\nwe present FORTRESS, a framework that generates and reasons about semantically\nsafe fallback strategies in real time to prevent OOD failures. At a low\nfrequency in nominal operations, FORTRESS uses multi-modal reasoners to\nidentify goals and anticipate failure modes. When a runtime monitor triggers a\nfallback response, FORTRESS rapidly synthesizes plans to fallback goals while\ninferring and avoiding semantically unsafe regions in real time. By bridging\nopen-world, multi-modal reasoning with dynamics-aware planning, we eliminate\nthe need for hard-coded fallbacks and human safety interventions. FORTRESS\noutperforms on-the-fly prompting of slow reasoning models in safety\nclassification accuracy on synthetic benchmarks and real-world ANYmal robot\ndata, and further improves system safety and planning success in simulation and\non quadrotor hardware for urban navigation.",
      "tldr_zh": "该论文提出 FORTRESS 框架，通过多模态推理实时生成语义安全的回退策略，以防止机器人面对 Out-of-Distribution (OOD) 失败时出现问题。FORTRESS 在正常操作中低频使用多模态推理器识别目标并预测失败模式，并在回退触发时快速合成动态感知规划，避免语义不安全区域。相比传统依赖手动干预的方法，该框架在合成基准、ANYmal 机器人数据以及模拟和四旋翼硬件实验中，显著提高了安全分类准确性和规划成功率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Website: https://milanganai.github.io/fortress/",
      "pdf_url": "http://arxiv.org/pdf/2505.10547v1",
      "published_date": "2025-05-15 17:55:28 UTC",
      "updated_date": "2025-05-15 17:55:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:08.296842"
    },
    {
      "arxiv_id": "2505.10543v1",
      "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models",
      "title_zh": "迈向大语言模型推理能力更深入的理解",
      "authors": [
        "Annie Wong",
        "Thomas Bäck",
        "Aske Plaat",
        "Niki van Stein",
        "Anna V. Kononova"
      ],
      "abstract": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning.",
      "tldr_zh": "该研究系统评估了大型语言模型（Large Language Models, LLMs）在动态环境中的推理能力，测试了自反（self-reflection）、启发式变异（heuristic mutation）和规划（planning）等提示技术对模型适应性的影响。实验结果显示，较大模型通常优于较小模型，但战略提示能缩小性能差距，同时发现过长提示会损害较小模型的基本任务表现，而高级提示技术在复杂游戏中更显著提升较小模型的效果。总体而言，高级推理方法如Chain of Thought可能带来不稳定性和性能下降，与人类相比，LLMs在规划、推理和空间协调等方面仍存在根本性局限，强调需要采用动态基准而非静态基准来全面评估推理能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10543v1",
      "published_date": "2025-05-15 17:53:47 UTC",
      "updated_date": "2025-05-15 17:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:09.707348"
    },
    {
      "arxiv_id": "2505.10537v1",
      "title": "LibIQ: Toward Real-Time Spectrum Classification in O-RAN dApps",
      "title_zh": "LibIQ：面向 O-RAN dApps 的实时频谱分类",
      "authors": [
        "Filippo Olimpieri",
        "Noemi Giustini",
        "Andrea Lacava",
        "Salvatore D'Oro",
        "Tommaso Melodia",
        "Francesca Cuomo"
      ],
      "abstract": "The O-RAN architecture is transforming cellular networks by adopting RAN\nsoftwarization and disaggregation concepts to enable data-driven monitoring and\ncontrol of the network. Such management is enabled by RICs, which facilitate\nnear-real-time and non-real-time network control through xApps and rApps.\nHowever, they face limitations, including latency overhead in data exchange\nbetween the RAN and RIC, restricting real-time monitoring, and the inability to\naccess user plain data due to privacy and security constraints, hindering use\ncases like beamforming and spectrum classification. In this paper, we leverage\nthe dApps concept to enable real-time RF spectrum classification with LibIQ, a\nnovel library for RF signals that facilitates efficient spectrum monitoring and\nsignal classification by providing functionalities to read I/Q samples as\ntime-series, create datasets and visualize time-series data through plots and\nspectrograms. Thanks to LibIQ, I/Q samples can be efficiently processed to\ndetect external RF signals, which are subsequently classified using a CNN\ninside the library. To achieve accurate spectrum analysis, we created an\nextensive dataset of time-series-based I/Q samples, representing distinct\nsignal types captured using a custom dApp running on a 5G deployment over the\nColosseum network emulator and an OTA testbed. We evaluate our model by\ndeploying LibIQ in heterogeneous scenarios with varying center frequencies,\ntime windows, and external RF signals. In real-time analysis, the model\nclassifies the processed I/Q samples, achieving an average accuracy of\napproximately 97.8\\% in identifying signal types across all scenarios. We\npledge to release both LibIQ and the dataset created as a publicly available\nframework upon acceptance.",
      "tldr_zh": "本研究针对O-RAN架构中RIC的延迟开销和隐私限制问题，提出LibIQ库，以实现实时RF频谱分类。LibIQ提供读取I/Q samples作为时间序列、创建数据集和可视化（如图和频谱图）等功能，并结合CNN模型对外部RF信号进行检测和分类。实验使用5G部署和OTA testbed创建的广泛I/Q样本数据集，在不同中心频率、时间窗口和信号场景下评估，模型平均准确率达97.8%。作者承诺公开发布LibIQ库和数据集，促进O-RAN dApps的实际应用。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "6 pages, 5 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.10537v1",
      "published_date": "2025-05-15 17:47:30 UTC",
      "updated_date": "2025-05-15 17:47:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:13.796738"
    },
    {
      "arxiv_id": "2505.10522v1",
      "title": "Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation",
      "title_zh": "知识捕获、适应和组合 (KCAC)：一种用于机器人操作的跨任务课程学习框架",
      "authors": [
        "Xinrui Wang",
        "Yan Jin"
      ],
      "abstract": "Reinforcement learning (RL) has demonstrated remarkable potential in robotic\nmanipulation but faces challenges in sample inefficiency and lack of\ninterpretability, limiting its applicability in real world scenarios. Enabling\nthe agent to gain a deeper understanding and adapt more efficiently to diverse\nworking scenarios is crucial, and strategic knowledge utilization is a key\nfactor in this process. This paper proposes a Knowledge Capture, Adaptation,\nand Composition (KCAC) framework to systematically integrate knowledge transfer\ninto RL through cross-task curriculum learning. KCAC is evaluated using a two\nblock stacking task in the CausalWorld benchmark, a complex robotic\nmanipulation environment. To our knowledge, existing RL approaches fail to\nsolve this task effectively, reflecting deficiencies in knowledge capture. In\nthis work, we redesign the benchmark reward function by removing rigid\nconstraints and strict ordering, allowing the agent to maximize total rewards\nconcurrently and enabling flexible task completion. Furthermore, we define two\nself-designed sub-tasks and implement a structured cross-task curriculum to\nfacilitate efficient learning. As a result, our KCAC approach achieves a 40\npercent reduction in training time while improving task success rates by 10\npercent compared to traditional RL methods. Through extensive evaluation, we\nidentify key curriculum design parameters subtask selection, transition timing,\nand learning rate that optimize learning efficiency and provide conceptual\nguidance for curriculum based RL frameworks. This work offers valuable insights\ninto curriculum design in RL and robotic learning.",
      "tldr_zh": "该研究提出了一种Knowledge Capture, Adaptation, and Composition (KCAC)框架，通过跨任务课程学习来整合知识转移，旨在解决Reinforcement learning (RL)在机器人操作中的样本效率低和可解释性差等问题。在CausalWorld基准上的两个积木堆叠任务实验中，研究者重新设计了奖励函数并定义了子任务，实现结构化的跨任务课程学习，结果显示KCAC框架将训练时间减少40%，任务成功率提高10%。此外，该框架还识别了关键课程设计参数，如子任务选择、过渡时机和学习率，为优化RL和机器人学习提供了概念指导。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10522v1",
      "published_date": "2025-05-15 17:30:29 UTC",
      "updated_date": "2025-05-15 17:30:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:13.573230"
    },
    {
      "arxiv_id": "2505.10518v1",
      "title": "Multi-Token Prediction Needs Registers",
      "title_zh": "多令牌预测需要寄存器",
      "authors": [
        "Anastasios Gerontopoulos",
        "Spyros Gidaris",
        "Nikos Komodakis"
      ],
      "abstract": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR.",
      "tldr_zh": "这篇论文提出 MuToR，一种简单有效的多标记预测方法，通过在输入序列中交错可学习的 register tokens 来预测未来的目标，从而解决多标记预测在预训练中有效但在微调中不一致的问题。与现有方法相比，MuToR 只增加微量参数、无需架构修改，并保持与 next-token pretraining 目标的对齐，特别适合 supervised fine-tuning。实验结果显示，MuToR 在语言和视觉领域的生成任务中表现出色，包括 supervised fine-tuning、参数高效微调 (PEFT) 和 pretraining。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10518v1",
      "published_date": "2025-05-15 17:25:03 UTC",
      "updated_date": "2025-05-15 17:25:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:18.073371"
    },
    {
      "arxiv_id": "2505.10515v1",
      "title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models",
      "title_zh": "PnPXAI：一种提供跨多种模态和模型自动解释的通用 XAI 框架",
      "authors": [
        "Seongun Kim",
        "Sol A Kim",
        "Geonhyeong Kim",
        "Enver Menadjiev",
        "Chanwoo Lee",
        "Seongwook Chung",
        "Nari Kim",
        "Jaesik Choi"
      ],
      "abstract": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance.",
      "tldr_zh": "本文研究了现有 post hoc explanation methods 的局限性，包括对特定神经网络架构和数据模式的依赖、支持 XAI 方法数量有限以及缺乏优化，导致其在实际应用中难以推广。为解决这些问题，作者提出 PnPXAI，一个通用 XAI 框架，支持多种数据模式和模型的 Plug-and-Play (PnP) 集成，能够自动检测模型架构、推荐适用的解释方法并优化超参数。通过用户调查验证了框架的有效性，并在医学和金融等领域展示了其多功能性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10515v1",
      "published_date": "2025-05-15 17:21:54 UTC",
      "updated_date": "2025-05-15 17:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:19.125226"
    },
    {
      "arxiv_id": "2505.10483v1",
      "title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation",
      "title_zh": "UniEval：统一整体评估框架用于统一的多模态理解和生成",
      "authors": [
        "Yi Li",
        "Haonan Wang",
        "Qixiang Zhang",
        "Boyu Xiao",
        "Chenchang Hu",
        "Hualiang Wang",
        "Xiaomeng Li"
      ],
      "abstract": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values.",
      "tldr_zh": "该论文提出 UniEval，一种统一的整体评估框架，用于评估多模态理解和生成模型，以解决现有基准的局限性，如缺乏整体结果和多样性。UniEval 包括 UniBench 基准（支持统一和视觉生成模型，包含81个细粒度标签）和 UniScore 指标，无需额外模型、图像或标注，从而简化评估过程。实验结果表明，UniBench 比现有基准更具挑战性，UniScore 与人类评估高度一致，并通过评估 SoTA 模型揭示了统一模型的独特价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "UniEval is the first evaluation framework designed for unified\n  multimodal models, including a holistic benchmark UniBench and the UniScore\n  metric",
      "pdf_url": "http://arxiv.org/pdf/2505.10483v1",
      "published_date": "2025-05-15 16:34:50 UTC",
      "updated_date": "2025-05-15 16:34:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:20.773883"
    },
    {
      "arxiv_id": "2505.10482v1",
      "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps",
      "title_zh": "通过扩散时间步的反向传播微调扩散策略",
      "authors": [
        "Ningyuan Yang",
        "Jiaxuan Gao",
        "Feng Gao",
        "Yi Wu",
        "Chao Yu"
      ],
      "abstract": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy.",
      "tldr_zh": "本研究针对 Diffusion Policies 在决策场景（如机器人和自动驾驶）中的局限性，提出了一种新的微调框架 NCDPO，以解决演示数据次优导致的轨迹生成问题和 Proximal Policy Optimization (PPO) 在扩散模型上的适应困难。NCDPO 将 Diffusion Policy 重新表述为基于噪声的确定性策略，并通过将每个去噪步骤视为可微变换，实现对所有扩散时间步的梯度反向传播，从而提升优化效率。实验结果显示，NCDPO 在样本效率上与直接应用 PPO 于 MLP 策略（MLP+PPO）相当，并在连续机器人控制和多代理游戏基准上优于现有方法，同时对去噪时间步数量表现出鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10482v1",
      "published_date": "2025-05-15 16:33:44 UTC",
      "updated_date": "2025-05-15 16:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:29.397665"
    },
    {
      "arxiv_id": "2505.10468v1",
      "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge",
      "title_zh": "AI Agents 与 Agentic AI：概念分类学、应用和挑战",
      "authors": [
        "Ranjan Sapkota",
        "Konstantinos I. Roumeliotis",
        "Manoj Karkee"
      ],
      "abstract": "This study critically distinguishes between AI Agents and Agentic AI,\noffering a structured conceptual taxonomy, application mapping, and challenge\nanalysis to clarify their divergent design philosophies and capabilities. We\nbegin by outlining the search strategy and foundational definitions,\ncharacterizing AI Agents as modular systems driven by Large Language Models\n(LLMs) and Large Image Models (LIMs) for narrow, task-specific automation.\nGenerative AI is positioned as a precursor, with AI Agents advancing through\ntool integration, prompt engineering, and reasoning enhancements. In contrast,\nAgentic AI systems represent a paradigmatic shift marked by multi-agent\ncollaboration, dynamic task decomposition, persistent memory, and orchestrated\nautonomy. Through a sequential evaluation of architectural evolution,\noperational mechanisms, interaction styles, and autonomy levels, we present a\ncomparative analysis across both paradigms. Application domains such as\ncustomer support, scheduling, and data summarization are contrasted with\nAgentic AI deployments in research automation, robotic coordination, and\nmedical decision support. We further examine unique challenges in each paradigm\nincluding hallucination, brittleness, emergent behavior, and coordination\nfailure and propose targeted solutions such as ReAct loops, RAG, orchestration\nlayers, and causal modeling. This work aims to provide a definitive roadmap for\ndeveloping robust, scalable, and explainable AI agent and Agentic AI-driven\nsystems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision\nSupport System, Agentic-AI Applications",
      "tldr_zh": "这篇论文对 AI Agents 和 Agentic AI 进行了概念区分，提供了一个结构化的分类框架（conceptual taxonomy）、应用映射和挑战分析，旨在阐明二者的设计哲学和能力差异。AI Agents 被定义为基于 Large Language Models (LLMs) 和 Large Image Models (LIMs) 的模块化系统，主要用于特定任务自动化，如客户支持、调度和数据总结；相比之下，Agentic AI 强调多智能体协作、动态任务分解、持久记忆和自治，适用于研究自动化、机器人协调和医疗决策支持等领域。通过比较架构演变、操作机制和自治水平，该研究分析了各自的挑战，包括幻觉（hallucination）、脆弱性（brittleness）和协调失败，并提出针对性解决方案如 ReAct loops、RAG 和编排层，以为开发稳健、可扩展的 AI 系统提供路线图。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, 14 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.10468v1",
      "published_date": "2025-05-15 16:21:33 UTC",
      "updated_date": "2025-05-15 16:21:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:31.950576"
    },
    {
      "arxiv_id": "2505.10465v1",
      "title": "Superposition Yields Robust Neural Scaling",
      "title_zh": "叠加产生稳健的神经缩放",
      "authors": [
        "Yizhou liu",
        "Ziming Liu",
        "Jeff Gore"
      ],
      "abstract": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）的神经缩放定律，即模型规模增大时损失函数呈幂律下降的原因。作者基于两个经验原则——叠加（superposition）表示（即模型维度不足以完全表示所有特征）和特征频率分布，构建了一个玩具模型（toy model）来分析损失随模型规模的变化。结果显示，在弱叠加条件下，损失缩放依赖于特征频率分布；而在强叠加条件下，损失与模型维度成反比，这种稳健行为在几何上源于向量间的干扰。实验分析了四个开源LLMs家族，发现它们表现出强叠加，并与模型预测一致，同时符合Chinchilla scaling law。该发现强调叠加是神经缩放定律的关键机制，可能引导更高效的训练策略和模型架构。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 23 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10465v1",
      "published_date": "2025-05-15 16:18:13 UTC",
      "updated_date": "2025-05-15 16:18:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:32.643468"
    },
    {
      "arxiv_id": "2505.10457v1",
      "title": "SEAL: Searching Expandable Architectures for Incremental Learning",
      "title_zh": "SEAL：针对增量学习的可扩展架构搜索",
      "authors": [
        "Matteo Gambella",
        "Vicente Javier Castro Solar",
        "Manuel Roveri"
      ],
      "abstract": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios.",
      "tldr_zh": "该论文提出SEAL框架，一种基于Neural Architecture Search (NAS)的方法，用于处理数据-incremental learning场景，其中数据顺序到达且无法存储。SEAL通过容量估计指标动态扩展模型结构，仅在必要时进行扩展，并采用cross-distillation training来保持稳定性，同时NAS组件联合搜索最佳架构和扩展策略。实验结果显示，SEAL在多个基准上显著减少了遗忘现象，提高了准确率，同时保持更小的模型大小，证明了结合NAS和选择性扩展的效率潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "68T07"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10457v1",
      "published_date": "2025-05-15 16:14:18 UTC",
      "updated_date": "2025-05-15 16:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:34.573861"
    },
    {
      "arxiv_id": "2505.10453v1",
      "title": "Vision language models have difficulty recognizing virtual objects",
      "title_zh": "视觉语言模型难以识别虚拟对象",
      "authors": [
        "Tyler Tran",
        "Sangeet Khemlani",
        "J. G. Trafton"
      ],
      "abstract": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate.",
      "tldr_zh": "本研究探讨了视觉语言模型（VLMs）在识别虚拟对象（virtual objects）方面的局限性，这些对象虽未实际出现在图像中，但与场景的 visuospatial properties 相关。作者提出通过添加描述性提示（如在图像中想象树上有风筝）来测试 VLMs 是否能正确更新场景表示并推理空间关系。实验系统评估了最先进的 VLMs，结果显示这些模型在处理虚拟对象时表现不佳，暴露了其场景理解能力的不足。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10453v1",
      "published_date": "2025-05-15 16:11:33 UTC",
      "updated_date": "2025-05-15 16:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:35.144929"
    },
    {
      "arxiv_id": "2505.10443v1",
      "title": "Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?",
      "title_zh": "大语言模型在理解代码方面对语义保持变异是否鲁棒？",
      "authors": [
        "Pedro Orvalho",
        "Marta Kwiatkowska"
      ],
      "abstract": "Understanding the reasoning and robustness of Large Language Models (LLMs) is\ncritical for their reliable use in programming tasks. While recent studies have\nassessed LLMs' ability to predict program outputs, most focus solely on the\naccuracy of those predictions, without evaluating the reasoning behind them.\nMoreover, it has been observed on mathematical reasoning tasks that LLMs can\narrive at correct answers through flawed logic, raising concerns about similar\nissues in code understanding.\n  In this work, we evaluate whether state-of-the-art LLMs with up to 8B\nparameters can reason about Python programs or are simply guessing. We apply\nfive semantics-preserving code mutations: renaming variables, mirroring\ncomparison expressions, swapping if-else branches, converting for loops to\nwhile, and loop unrolling. These mutations maintain program semantics while\naltering its syntax. We evaluated six LLMs and performed a human expert\nanalysis using LiveCodeBench to assess whether the correct predictions are\nbased on sound reasoning. We also evaluated prediction stability across\ndifferent code mutations on LiveCodeBench and CruxEval. Our findings show that\nsome LLMs, such as Llama3.2, produce correct predictions based on flawed\nreasoning in up to 61% of cases. Furthermore, LLMs often change predictions in\nresponse to our code mutations, indicating limited robustness in their semantic\nunderstanding.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在理解代码时的推理鲁棒性，特别是面对语义保持不变的代码变异 (semantics-preserving mutations)。研究者通过五种变异方法——重命名变量、镜像比较表达式、交换 if-else 分支、将 for 循环转换为 while 循环，以及循环展开 (loop unrolling)——测试了六种最多 8B 参数的 LLMs。结果显示，一些模型如 Llama3.2 在多达 61% 的正确预测中依赖于错误的推理，且 LLMs 经常在代码变异后改变预测，表明其语义理解缺乏稳定性。该研究突出了 LLMs 在编程任务中可靠性的潜在缺陷，并使用 LiveCodeBench 和 CruxEval 等工具进行了评估。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 5 tables, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2505.10443v1",
      "published_date": "2025-05-15 16:04:25 UTC",
      "updated_date": "2025-05-15 16:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:39.715273"
    },
    {
      "arxiv_id": "2505.10442v1",
      "title": "IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning",
      "title_zh": "IN-RIL：交错强化学习和模仿学习用于策略微调",
      "authors": [
        "Dechen Gao",
        "Hang Wang",
        "Hanchu Zhou",
        "Nejib Ammar",
        "Shatadal Mishra",
        "Ahmadreza Moradipari",
        "Iman Soltani",
        "Junshan Zhang"
      ],
      "abstract": "Imitation learning (IL) and reinforcement learning (RL) each offer distinct\nadvantages for robotics policy learning: IL provides stable learning from\ndemonstrations, and RL promotes generalization through exploration. While\nexisting robot learning approaches using IL-based pre-training followed by\nRL-based fine-tuning are promising, this two-step learning paradigm often\nsuffers from instability and poor sample efficiency during the RL fine-tuning\nphase. In this work, we introduce IN-RIL, INterleaved Reinforcement learning\nand Imitation Learning, for policy fine-tuning, which periodically injects IL\nupdates after multiple RL updates and hence can benefit from the stability of\nIL and the guidance of expert data for more efficient exploration throughout\nthe entire fine-tuning process. Since IL and RL involve different optimization\nobjectives, we develop gradient separation mechanisms to prevent destructive\ninterference during \\ABBR fine-tuning, by separating possibly conflicting\ngradient updates in orthogonal subspaces. Furthermore, we conduct rigorous\nanalysis, and our findings shed light on why interleaving IL with RL stabilizes\nlearning and improves sample-efficiency. Extensive experiments on 14 robot\nmanipulation and locomotion tasks across 3 benchmarks, including\nFurnitureBench, OpenAI Gym, and Robomimic, demonstrate that \\ABBR can\nsignificantly improve sample efficiency and mitigate performance collapse\nduring online finetuning in both long- and short-horizon tasks with either\nsparse or dense rewards. IN-RIL, as a general plug-in compatible with various\nstate-of-the-art RL algorithms, can significantly improve RL fine-tuning, e.g.,\nfrom 12\\% to 88\\% with 6.3x improvement in the success rate on Robomimic\nTransport. Project page: https://github.com/ucd-dare/IN-RIL.",
      "tldr_zh": "这篇论文介绍了 IN-RIL，一种交错强化学习 (RL) 和模仿学习 (IL) 的方法，用于机器人策略微调，以结合 IL 的稳定性和 RL 的探索能力。IN-RIL 通过周期性地注入 IL 更新并采用梯度分离机制，避免优化目标冲突，从而提升样本效率和学习稳定性。实验在 14 个机器人操作和运动任务上（如 FurnitureBench、OpenAI Gym 和 Robomimic）证明，该方法显著提高了性能，避免了在线微调中的崩溃问题，例如在 Robomimic Transport 任务上成功率从 12% 提升到 88%，并可作为通用插件与多种 RL 算法兼容。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10442v1",
      "published_date": "2025-05-15 16:01:21 UTC",
      "updated_date": "2025-05-15 16:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:40.926741"
    },
    {
      "arxiv_id": "2505.10441v1",
      "title": "PIF: Anomaly detection via preference embedding",
      "title_zh": "PIF：基于偏好嵌入的异常检测",
      "authors": [
        "Filippo Leveni",
        "Luca Magri",
        "Giacomo Boracchi",
        "Cesare Alippi"
      ],
      "abstract": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space.",
      "tldr_zh": "本论文提出了一种名为 PIF 的新型异常检测方法，通过 preference embedding 将数据嵌入高维空间，并结合自适应隔离方法来处理相对于结构化模式的异常问题。具体而言，PI-Forest 作为一种高效的树-based 技术，用于计算异常分数，从而提升检测的灵活性。实验结果显示，PIF 在合成和真实数据集上比现有最先进的技术表现更优，尤其在测量任意 distances 和在 preference space 中隔离点方面。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)",
      "pdf_url": "http://arxiv.org/pdf/2505.10441v1",
      "published_date": "2025-05-15 16:00:31 UTC",
      "updated_date": "2025-05-15 16:00:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:42.238307"
    },
    {
      "arxiv_id": "2505.10420v1",
      "title": "Learned Lightweight Smartphone ISP with Unpaired Data",
      "title_zh": "基于学习的轻量级智能手机图像信号处理器，使用非配对数据",
      "authors": [
        "Andrei Arhire",
        "Radu Timofte"
      ],
      "abstract": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data .",
      "tldr_zh": "这篇论文提出了一种无需配对数据的训练方法，用于开发轻量级智能手机 Image Signal Processor (ISP)，以将 RAW 传感器图像转换为高质量 RGB 图像。方法采用多项损失函数和 adversarial training，通过多个 discriminators 处理预训练网络的特征图，确保内容结构保持的同时学习目标数据集的颜色和纹理特征。实验结果显示，该方法在 Zurich RAW to RGB 和 Fujifilm UltraISP 数据集上表现出色，在多个评估指标上实现高保真度，并优于传统配对训练方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPRW 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10420v1",
      "published_date": "2025-05-15 15:37:51 UTC",
      "updated_date": "2025-05-15 15:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:45.023926"
    },
    {
      "arxiv_id": "2505.10405v1",
      "title": "Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding",
      "title_zh": "用于生成式语义通信的关键信息嵌入的视觉保真度指数",
      "authors": [
        "Jianhao Huang",
        "Qunsong Zeng",
        "Kaibin Huang"
      ],
      "abstract": "Generative semantic communication (Gen-SemCom) with large artificial\nintelligence (AI) model promises a transformative paradigm for 6G networks,\nwhich reduces communication costs by transmitting low-dimensional prompts\nrather than raw data. However, purely prompt-driven generation loses\nfine-grained visual details. Additionally, there is a lack of systematic\nmetrics to evaluate the performance of Gen-SemCom systems. To address these\nissues, we develop a hybrid Gen-SemCom system with a critical information\nembedding (CIE) framework, where both text prompts and semantically critical\nfeatures are extracted for transmissions. First, a novel approach of semantic\nfiltering is proposed to select and transmit the semantically critical features\nof images relevant to semantic label. By integrating the text prompt and\ncritical features, the receiver reconstructs high-fidelity images using a\ndiffusion-based generative model. Next, we propose the generative visual\ninformation fidelity (GVIF) metric to evaluate the visual quality of the\ngenerated image. By characterizing the statistical models of image features,\nthe GVIF metric quantifies the mutual information between the distorted\nfeatures and their original counterparts. By maximizing the GVIF metric, we\ndesign a channel-adaptive Gen-SemCom system that adaptively control the volume\nof features and compression rate according to the channel state. Experimental\nresults validate the GVIF metric's sensitivity to visual fidelity, correlating\nwith both the PSNR and critical information volume. In addition, the optimized\nsystem achieves superior performance over benchmarking schemes in terms of\nhigher PSNR and lower FID scores.",
      "tldr_zh": "这篇论文针对生成语义通信(Gen-SemCom)中传输低维提示导致的视觉细节丢失问题，提出了一种结合关键信息嵌入(CIE)框架的混合系统，通过语义过滤方法选择并传输与语义标签相关的图像关键特征，以扩散模型重建高保真图像。论文还引入了生成视觉信息保真度(GVIF)指标，该指标基于图像特征的统计模型量化扭曲特征与原始特征的互信息，用于评估生成图像的质量，并设计了一个通道自适应系统来优化特征量和压缩率。实验结果验证了GVIF对视觉保真的敏感性，并显示优化系统在PSNR和FID分数上显著优于基准方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10405v1",
      "published_date": "2025-05-15 15:28:32 UTC",
      "updated_date": "2025-05-15 15:28:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:47.645364"
    },
    {
      "arxiv_id": "2505.10402v1",
      "title": "Rethinking Repetition Problems of LLMs in Code Generation",
      "title_zh": "重新审视 LLMs 在代码生成中的重复问题",
      "authors": [
        "Yihong Dong",
        "Yuchen Liu",
        "Xue Jiang",
        "Zhi Jin",
        "Ge Li"
      ],
      "abstract": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code.",
      "tldr_zh": "本文重新审视了大型语言模型(LLMs)在代码生成中的重复问题，特别是更常见的结构重复，该问题涉及固定结构但多种模式的代码。作者正式定义了结构重复，并提出了一种高效解码方法RPG（Repetition Penalization based on Grammar），通过利用语法规则识别重复并降低关键标记的概率来缓解这一问题。为此，构建了新数据集CodeRepetEval，用于全面评估重复问题缓解方法。实验结果表明，RPG在CodeRepetEval、HumanEval和MBPP基准上显著优于基线，成功减少了重复并提高了生成的代码质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2025 (main)",
      "pdf_url": "http://arxiv.org/pdf/2505.10402v1",
      "published_date": "2025-05-15 15:26:32 UTC",
      "updated_date": "2025-05-15 15:26:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:56.011455"
    },
    {
      "arxiv_id": "2505.10399v1",
      "title": "Evaluating Model Explanations without Ground Truth",
      "title_zh": "无需 Ground Truth 的模型解释评估",
      "authors": [
        "Kaivalya Rawal",
        "Zihao Fu",
        "Eoin Delaney",
        "Chris Russell"
      ],
      "abstract": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth.",
      "tldr_zh": "该论文指出了现有模型解释评估框架的局限性，即依赖理想的“ground-truth”解释或模型对重要输入的敏感性，导致评估不准确。作者提出了三个理想原则，并开发了“ground-truth Agnostic eXplanation Evaluation”（AXE）框架，用于独立评估和比较本地特征重要性解释，而无需访问ground-truth或模型敏感性数据。实验结果显示，AXE 与基线方法相比更可靠，并能有效检测解释“fairwashing”，为模型解释质量评估提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "https://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth",
      "pdf_url": "http://arxiv.org/pdf/2505.10399v1",
      "published_date": "2025-05-15 15:22:06 UTC",
      "updated_date": "2025-05-15 15:22:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:50:57.999095"
    },
    {
      "arxiv_id": "2505.10394v1",
      "title": "Inconsistency Handling in DatalogMTL",
      "title_zh": "DatalogMTL 中的不一致性处理",
      "authors": [
        "Meghyn Bienvenu",
        "Camille Bourgaux",
        "Atefe Khodadaditaghanaki"
      ],
      "abstract": "In this paper, we explore the issue of inconsistency handling in DatalogMTL,\nan extension of Datalog with metric temporal operators. Since facts are\nassociated with time intervals, there are different manners to restore\nconsistency when they contradict the rules, such as removing facts or modifying\ntheir time intervals. Our first contribution is the definition of relevant\nnotions of conflicts (minimal explanations for inconsistency) and repairs\n(possible ways of restoring consistency) for this setting and the study of the\nproperties of these notions and the associated inconsistency-tolerant\nsemantics. Our second contribution is a data complexity analysis of the tasks\nof generating a single conflict / repair and query entailment under\nrepair-based semantics.",
      "tldr_zh": "本文探讨了 DatalogMTL（Datalog 的扩展，添加了 metric temporal operators）中不一致处理的问题，当事实与规则冲突时，可通过移除事实或修改时间区间等方式恢复一致性。论文的主要贡献包括定义 conflicts（最小不一致解释）和 repairs（恢复一致性的可能方式）的概念，并研究这些概念的属性以及相关的 inconsistency-tolerant semantics。其次，论文对生成单个 conflict/repair 以及在 repair-based semantics 下查询蕴含的数据复杂性进行了分析。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LO",
      "comment": "This is an extended version of a paper appearing at the 34th\n  International Joint Conference on Artificial Intelligence (IJCAI 2025). 24\n  pages",
      "pdf_url": "http://arxiv.org/pdf/2505.10394v1",
      "published_date": "2025-05-15 15:17:09 UTC",
      "updated_date": "2025-05-15 15:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:00.577001"
    },
    {
      "arxiv_id": "2505.10393v1",
      "title": "Uncovering Magnetic Phases with Synthetic Data and Physics-Informed Training",
      "title_zh": "通过合成数据和基于物理信息的训练揭示磁性相",
      "authors": [
        "Agustin Medina",
        "Marcelo Arlego",
        "Carlos A. Lamas"
      ],
      "abstract": "We investigate the efficient learning of magnetic phases using artificial\nneural networks trained on synthetic data, combining computational simplicity\nwith physics-informed strategies. Focusing on the diluted Ising model, which\nlacks an exact analytical solution, we explore two complementary approaches: a\nsupervised classification using simple dense neural networks, and an\nunsupervised detection of phase transitions using convolutional autoencoders\ntrained solely on idealized spin configurations.\n  To enhance model performance, we incorporate two key forms of\nphysics-informed guidance. First, we exploit architectural biases which\npreferentially amplify features related to symmetry breaking. Second, we\ninclude training configurations that explicitly break $\\mathbb{Z}_2$ symmetry,\nreinforcing the network's ability to detect ordered phases. These mechanisms,\nacting in tandem, increase the network's sensitivity to phase structure even in\nthe absence of explicit labels. We validate the machine learning predictions\nthrough comparison with direct numerical estimates of critical temperatures and\npercolation thresholds.\n  Our results show that synthetic, structured, and computationally efficient\ntraining schemes can reveal physically meaningful phase boundaries, even in\ncomplex systems. This framework offers a low-cost and robust alternative to\nconventional methods, with potential applications in broader condensed matter\nand statistical physics contexts.",
      "tldr_zh": "本文使用合成数据和物理信息指导训练人工神经网络，高效学习磁性相，特别是针对缺乏精确解析解的稀释 Ising model。研究探索了监督分类（基于简单密集神经网络）和无监督检测（使用卷积自编码器训练于理想自旋配置）两种方法，并通过架构偏置放大对称性破缺相关特征，以及纳入显式破缺 \\(\\mathbb{Z}_2\\) symmetry 的训练配置，提升网络对相结构的敏感性。结果验证了机器学习预测与数值估计的一致性，并证明这种合成训练框架可揭示有意义的相边界，提供低成本的替代方案，适用于更广泛的凝聚态和统计物理领域。",
      "categories": [
        "cond-mat.str-el",
        "cs.AI"
      ],
      "primary_category": "cond-mat.str-el",
      "comment": "25 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10393v1",
      "published_date": "2025-05-15 15:16:16 UTC",
      "updated_date": "2025-05-15 15:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:02.418721"
    },
    {
      "arxiv_id": "2505.10392v1",
      "title": "Schreier-Coset Graph Propagation",
      "title_zh": "Schreier-Coset 图传播",
      "authors": [
        "Aryan Mishra",
        "Lizhen Lin"
      ],
      "abstract": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications.",
      "tldr_zh": "本研究针对Graph Neural Networks (GNNs) 中over-squashing问题，提出Schreier-Coset Graph Propagation (SCGP)，这是一种基于群论的增强方法，通过Schreier-coset embeddings丰富节点特征，而不改变输入图拓扑，从而提升长距离消息传递并保持计算效率。SCGP解决了现有方法如Cayley graphs和expander graphs的可扩展性瓶颈，提供无瓶颈连接模式。实验结果显示，在标准节点和图分类基准上，SCGP的性能与或超过expander graph和rewired GNN基线，尤其在层次化和模块化图结构中，表现出更低的推理延迟、更强的可扩展性和低内存占用，适合实时和资源受限应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 1 figure , preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.10392v1",
      "published_date": "2025-05-15 15:14:02 UTC",
      "updated_date": "2025-05-15 15:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:04.121182"
    },
    {
      "arxiv_id": "2505.10387v1",
      "title": "Multi-Agent Path Finding For Large Agents Is Intractable",
      "title_zh": "多智能体路径寻找对于大型智能体是不可计算的",
      "authors": [
        "Artem Agafonov",
        "Konstantin Yakovlev"
      ],
      "abstract": "The multi-agent path finding (MAPF) problem asks to find a set of paths on a\ngraph such that when synchronously following these paths the agents never\nencounter a conflict. In the most widespread MAPF formulation, the so-called\nClassical MAPF, the agents sizes are neglected and two types of conflicts are\nconsidered: occupying the same vertex or using the same edge at the same time\nstep. Meanwhile in numerous practical applications, e.g. in robotics, taking\ninto account the agents' sizes is vital to ensure that the MAPF solutions can\nbe safely executed. Introducing large agents yields an additional type of\nconflict arising when one agent follows an edge and its body overlaps with the\nbody of another agent that is actually not using this same edge (e.g. staying\nstill at some distinct vertex of the graph). Until now it was not clear how\nharder the problem gets when such conflicts are to be considered while\nplanning. Specifically, it was known that Classical MAPF problem on an\nundirected graph can be solved in polynomial time, however no complete\npolynomial-time algorithm was presented to solve MAPF with large agents. In\nthis paper we, for the first time, establish that the latter problem is NP-hard\nand, thus, if P!=NP no polynomial algorithm for it can, unfortunately, be\npresented. Our proof is based on the prevalent in the field technique of\nreducing the seminal 3SAT problem (which is known to be an NP-complete problem)\nto the problem at hand. In particular, for an arbitrary 3SAT formula we\nprocedurally construct a dedicated graph with specific start and goal vertices\nand show that the given 3SAT formula is satisfiable iff the corresponding path\nfinding instance has a solution.",
      "tldr_zh": "本论文探讨了 Multi-Agent Path Finding (MAPF) 问题，当代理具有实际大小时，会引入额外的冲突类型，例如一个代理移动时与其余代理重叠。该问题与 Classical MAPF 不同，后者忽略代理大小并可在多项式时间内解决，而考虑代理大小的版本被证明是 NP-hard。论文通过将经典的 3SAT 问题归约到特定 MAPF 实例来证明这一复杂性，为机器人等实际应用中的路径规划提供了重要理论洞见。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10387v1",
      "published_date": "2025-05-15 15:07:40 UTC",
      "updated_date": "2025-05-15 15:07:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:05.458351"
    },
    {
      "arxiv_id": "2505.10375v1",
      "title": "Are Sparse Autoencoders Useful for Java Function Bug Detection?",
      "title_zh": "稀疏自动编码器是否适用于 Java 函数错误检测？",
      "authors": [
        "Rui Melo",
        "Claudia Mamede",
        "Andre Catarino",
        "Rui Abreu",
        "Henrique Lopes Cardoso"
      ],
      "abstract": "Software vulnerabilities such as buffer overflows and SQL injections are a\nmajor source of security breaches. Traditional methods for vulnerability\ndetection remain essential but are limited by high false positive rates,\nscalability issues, and reliance on manual effort. These constraints have\ndriven interest in AI-based approaches to automated vulnerability detection and\nsecure code generation. While Large Language Models (LLMs) have opened new\navenues for classification tasks, their complexity and opacity pose challenges\nfor interpretability and deployment. Sparse Autoencoder offer a promising\nsolution to this problem. We explore whether SAEs can serve as a lightweight,\ninterpretable alternative for bug detection in Java functions. We evaluate the\neffectiveness of SAEs when applied to representations from GPT-2 Small and\nGemma 2B, examining their capacity to highlight buggy behaviour without\nfine-tuning the underlying LLMs. We found that SAE-derived features enable bug\ndetection with an F1 score of up to 89%, consistently outperforming fine-tuned\ntransformer encoder baselines. Our work provides the first empirical evidence\nthat SAEs can be used to detect software bugs directly from the internal\nrepresentations of pretrained LLMs, without any fine-tuning or task-specific\nsupervision.",
      "tldr_zh": "这篇论文探讨了Sparse Autoencoders (SAEs)是否能作为一种轻量级、可解释的工具，用于检测Java函数中的软件漏洞，如缓冲区溢出和SQL注入，以克服传统方法的高假阳性率和Large Language Models (LLMs)的不透明性问题。研究评估了SAEs在GPT-2 Small和Gemma 2B的内部表示上进行bug检测的效果，而无需对LLMs进行微调。结果显示，SAE派生特征实现了高达89%的F1分数，显著优于微调的transformer编码器基线。该工作首次提供了实证证据，证明SAEs可以直接从预训练LLMs的表示中检测软件bug，无需任务特定监督。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10375v1",
      "published_date": "2025-05-15 14:59:17 UTC",
      "updated_date": "2025-05-15 14:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:08.744943"
    },
    {
      "arxiv_id": "2505.10371v1",
      "title": "ILIF: Temporal Inhibitory Leaky Integrate-and-Fire Neuron for Overactivation in Spiking Neural Networks",
      "title_zh": "ILIF：时域抑制泄漏积分发放神经元，用于脉冲神经网络中的过度激活",
      "authors": [
        "Kai Sun",
        "Peibo Duan",
        "Levin Kuhlmann",
        "Beilun Wang",
        "Bin Zhang"
      ],
      "abstract": "The Spiking Neural Network (SNN) has drawn increasing attention for its\nenergy-efficient, event-driven processing and biological plausibility. To train\nSNNs via backpropagation, surrogate gradients are used to approximate the\nnon-differentiable spike function, but they only maintain nonzero derivatives\nwithin a narrow range of membrane potentials near the firing threshold,\nreferred to as the surrogate gradient support width gamma. We identify a major\nchallenge, termed the dilemma of gamma: a relatively large gamma leads to\noveractivation, characterized by excessive neuron firing, which in turn\nincreases energy consumption, whereas a small gamma causes vanishing gradients\nand weakens temporal dependencies. To address this, we propose a temporal\nInhibitory Leaky Integrate-and-Fire (ILIF) neuron model, inspired by biological\ninhibitory mechanisms. This model incorporates interconnected inhibitory units\nfor membrane potential and current, effectively mitigating overactivation while\npreserving gradient propagation. Theoretical analysis demonstrates ILIF\neffectiveness in overcoming the gamma dilemma, and extensive experiments on\nmultiple datasets show that ILIF improves energy efficiency by reducing firing\nrates, stabilizes training, and enhances accuracy. The code is available at\ngithub.com/kaisun1/ILIF.",
      "tldr_zh": "该研究针对 Spiking Neural Networks (SNN) 训练中的 gamma dilemma 问题提出了一种 Temporal Inhibitory Leaky Integrate-and-Fire (ILIF) 神经元模型，该问题导致 surrogate gradients 的 overactivation（过度神经元 firing）和 vanishing gradients（梯度消失）。ILIF 模型受生物抑制机制启发，通过膜电位和电流的互连抑制单元有效缓解 overactivation，同时保持梯度传播和时间依赖性。实验结果显示，该模型在多个数据集上降低了 firing rates，提高了能效，稳定了训练过程，并提升了准确率。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10371v1",
      "published_date": "2025-05-15 14:56:06 UTC",
      "updated_date": "2025-05-15 14:56:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:10.213645"
    },
    {
      "arxiv_id": "2505.10361v1",
      "title": "Plasticity as the Mirror of Empowerment",
      "title_zh": "可塑性作为赋能的镜像",
      "authors": [
        "David Abel",
        "Michael Bowling",
        "André Barreto",
        "Will Dabney",
        "Shi Dong",
        "Steven Hansen",
        "Anna Harutyunyan",
        "Khimya Khetarpal",
        "Clare Lyle",
        "Razvan Pascanu",
        "Georgios Piliouras",
        "Doina Precup",
        "Jonathan Richens",
        "Mark Rowland",
        "Tom Schaul",
        "Satinder Singh"
      ],
      "abstract": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency.",
      "tldr_zh": "本文提出“plasticity”（可塑性）作为衡量代理（agents）被过去观察影响程度的通用指标，并揭示其与“empowerment”（赋能）之间的镜像关系。作者使用新的信息论量“generalized directed information”（广义定向信息）定义plasticity，并证明代理的plasticity等同于环境的empowerment，反之亦然。同时，研究发现plasticity和empowerment之间存在张力，提示在代理设计中需平衡两者。这些发现为理解代理在人工智能和认知科学中的本质提供了关键洞见。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10361v1",
      "published_date": "2025-05-15 14:52:16 UTC",
      "updated_date": "2025-05-15 14:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:10.975471"
    },
    {
      "arxiv_id": "2505.10360v1",
      "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation",
      "title_zh": "FactsR：一种更安全的方法，用于生成高质量医疗文档",
      "authors": [
        "Victor Petrén Bach Hansen",
        "Lasse Krogsbøll",
        "Jonas Lyngsø",
        "Mathias Baltzersen",
        "Andreas Motzfeldt",
        "Kevin Pelgrims",
        "Lars Maaløe"
      ],
      "abstract": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support.",
      "tldr_zh": "本文提出 FactsR 方法，以解决现有 AI-scribing 解决方案在医疗文档生成中存在的幻觉(hallucinations)、错误误传和安全风险问题，这些问题源于依赖单次或少次提示的生成方式。FactsR 通过实时提取关键临床信息（Facts）并递归使用这些信息生成最终笔记，将医生纳入生成循环，确保文档更准确和简洁。同时，该方法扩展了实时决策支持的应用，提升了患者安全和临床效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10360v1",
      "published_date": "2025-05-15 14:51:22 UTC",
      "updated_date": "2025-05-15 14:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:13.172001"
    },
    {
      "arxiv_id": "2505.10352v1",
      "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity",
      "title_zh": "SpikeVideoFormer：高效的脉冲驱动视频 Transformer，带有汉明注意力和 $\\mathcal{O}(T)$ 复杂度",
      "authors": [
        "Shihao Zou",
        "Qingfeng Li",
        "Wei Ji",
        "Jingjing Li",
        "Yongkui Yang",
        "Guoqi Li",
        "Chao Dong"
      ],
      "abstract": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer",
      "tldr_zh": "该研究引入了 SpikeVideoFormer，一种基于脉冲神经网络 (SNNs) 的高效视频 Transformer，采用 spike-driven Hamming attention (SDHA) 机制，并实现了线性时间复杂度 \\(\\mathcal{O}(T)\\)，以更好地处理视频任务中的时空特征。相比传统注意力，SDHA 通过理论指导将实值注意力适应到 SNNs 中，并优化了多种空间-时间注意力设计以提升性能。该模型在视频分类、人体姿势跟踪和语义分割等任务上表现出色，比现有 SNN 方法提高了超过 15% 的性能，并与 ANN 方法相当，同时实现了 16 倍、10 倍和 5 倍的效率提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10352v1",
      "published_date": "2025-05-15 14:43:35 UTC",
      "updated_date": "2025-05-15 14:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:22.045486"
    },
    {
      "arxiv_id": "2505.10347v1",
      "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning",
      "title_zh": "统一损失 vs. 专用优化：在多任务学习中的比较分析",
      "authors": [
        "Gabriel S. Gama",
        "Valdir Grassi Jr"
      ],
      "abstract": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available.",
      "tldr_zh": "这篇论文比较了 Specialized Multi-Task Optimizers (SMTOs) 与 uniform loss 在 Multi-Task Learning 中的性能，焦点在于 SMTOs 如何通过处理冲突梯度和不同梯度规范来平衡任务学习。研究通过对更复杂多任务问题的广泛实证评估，包括最新 SMTOs 方法，检验了最近的批评，即等权重任务可能因超参数优化和正则化不足而影响结果。结果显示，SMTOs 整体优于 uniform loss，而固定权重也能实现竞争性表现；此外，论文解释了 uniform loss 在某些情况下与 SMTOs 类似的原因，并计划公开代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10347v1",
      "published_date": "2025-05-15 14:34:36 UTC",
      "updated_date": "2025-05-15 14:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:23.681852"
    },
    {
      "arxiv_id": "2505.10331v1",
      "title": "Emergence of Structure in Ensembles of Random Neural Networks",
      "title_zh": "随机神经网络集合中的结构涌现",
      "authors": [
        "Luca Muscarnera",
        "Luigi Loreti",
        "Giovanni Todeschini",
        "Alessio Fumagalli",
        "Francesco Regazzoni"
      ],
      "abstract": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon.",
      "tldr_zh": "这篇论文探讨了随机神经网络集合（Ensembles of Random Neural Networks）中结构的涌现（Emergence of Structure），即随机组件如何产生全局有序行为。研究者引入了一个理论模型，使用 Gibbs measure 加权随机分类器，并将分类损失作为能量函数，以确定一个有限温度参数，实现分类的优化。分析证明，在高斯分布（Gaussian distribution）生成样本和教师感知器（teacher perceptron）构建标签的情况下，最优温度独立于未知的教师分类器或分类器数量，展示了这一现象的普遍性。在 MNIST 数据集上的实验进一步验证了其在高质量数据集中的相关性，并通过物理类比解释了这种自组织行为。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10331v1",
      "published_date": "2025-05-15 14:20:02 UTC",
      "updated_date": "2025-05-15 14:20:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:26.182994"
    },
    {
      "arxiv_id": "2505.10330v1",
      "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change",
      "title_zh": "强化学习代理对突发环境变化的高效适应",
      "authors": [
        "Jonathan Clifford Balloch"
      ],
      "abstract": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components.",
      "tldr_zh": "这篇论文探讨了强化学习（RL）代理在真实世界环境中面对突发环境变化时的适应挑战，传统RL方法因数据密集和假设静态环境而难以有效应对，可能导致灾难性遗忘。论文提出两种关键能力来实现高效在线适应：（1）优先级探索和采样策略，用于识别和学习相关经验；（2）通过结构化表示选择性保留先验知识，从而更新模型而不干扰可重用组件。总体而言，该研究为RL代理在动态环境中的鲁棒性提供了重要框架，强调了平衡探索与知识保留的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "PhD Dissertation, 131 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.10330v1",
      "published_date": "2025-05-15 14:19:01 UTC",
      "updated_date": "2025-05-15 14:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:25.478023"
    },
    {
      "arxiv_id": "2505.10328v1",
      "title": "A Comparative Study of SMT and MILP for the Nurse Rostering Problem",
      "title_zh": "SMT 与 MILP 在护士排班问题中的比较研究",
      "authors": [
        "Alvin Combrink",
        "Stephie Do",
        "Kristofer Bengtsson",
        "Sabino Francesco Roselli",
        "Martin Fabian"
      ],
      "abstract": "The effects of personnel scheduling on the quality of care and working\nconditions for healthcare personnel have been thoroughly documented. However,\nthe ever-present demand and large variation of constraints make healthcare\nscheduling particularly challenging. This problem has been studied for decades,\nwith limited research aimed at applying Satisfiability Modulo Theories (SMT).\nSMT has gained momentum within the formal verification community in the last\ndecades, leading to the advancement of SMT solvers that have been shown to\noutperform standard mathematical programming techniques.\n  In this work, we propose generic constraint formulations that can model a\nwide range of real-world scheduling constraints. Then, the generic constraints\nare formulated as SMT and MILP problems and used to compare the respective\nstate-of-the-art solvers, Z3 and Gurobi, on academic and real-world inspired\nrostering problems. Experimental results show how each solver excels for\ncertain types of problems; the MILP solver generally performs better when the\nproblem is highly constrained or infeasible, while the SMT solver performs\nbetter otherwise. On real-world inspired problems containing a more varied set\nof shifts and personnel, the SMT solver excels. Additionally, it was noted\nduring experimentation that the SMT solver was more sensitive to the way the\ngeneric constraints were formulated, requiring careful consideration and\nexperimentation to achieve better performance. We conclude that SMT-based\nmethods present a promising avenue for future research within the domain of\npersonnel scheduling.",
      "tldr_zh": "这篇论文比较了 SMT（Satisfiability Modulo Theories）和 MILP（Mixed-Integer Linear Programming）在护士排班问题中的应用，提出通用的约束表述来建模各种真实世界的调度需求和限制。研究者使用 Z3（SMT 求解器）和 Gurobi（MILP 求解器）对学术和真实世界灵感问题进行实验，结果显示 MILP 求解器在高度约束或不可行问题上表现更佳，而 SMT 求解器在其他场景，尤其是涉及多样化班次和人员的复杂问题中更具优势。论文还发现 SMT 求解器对约束表述更敏感，需要优化以提升性能。总体而言，该研究认为 SMT 方法为未来人员调度领域的研究提供了有前景的途径。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10328v1",
      "published_date": "2025-05-15 14:12:39 UTC",
      "updated_date": "2025-05-15 14:12:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:30.762502"
    },
    {
      "arxiv_id": "2505.10321v1",
      "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents",
      "title_zh": "AutoPentest：通过自主LLM代理增强漏洞管理",
      "authors": [
        "Julius Henke"
      ],
      "abstract": "A recent area of increasing research is the use of Large Language Models\n(LLMs) in penetration testing, which promises to reduce costs and thus allow\nfor higher frequency. We conduct a review of related work, identifying best\npractices and common evaluation issues. We then present AutoPentest, an\napplication for performing black-box penetration tests with a high degree of\nautonomy. AutoPentest is based on the LLM GPT-4o from OpenAI and the LLM agent\nframework LangChain. It can perform complex multi-step tasks, augmented by\nexternal tools and knowledge bases. We conduct a study on three\ncapture-the-flag style Hack The Box (HTB) machines, comparing our\nimplementation AutoPentest with the baseline approach of manually using the\nChatGPT-4o user interface. Both approaches are able to complete 15-25 % of the\nsubtasks on the HTB machines, with AutoPentest slightly outperforming ChatGPT.\nWe measure a total cost of \\$96.20 US when using AutoPentest across all\nexperiments, while a one-month subscription to ChatGPT Plus costs \\$20. The\nresults show that further implementation efforts and the use of more powerful\nLLMs released in the future are likely to make this a viable part of\nvulnerability management.",
      "tldr_zh": "该研究回顾了大型语言模型 (LLMs) 在渗透测试中的相关工作，并提出了 AutoPentest，一种高度自治的黑盒渗透测试应用，基于 OpenAI 的 GPT-4o 和 LangChain 框架，支持复杂多步任务并整合外部工具和知识库。实验在三个 Hack The Box (HTB) 机器上进行，与手动使用 ChatGPT-4o 的基线方法比较，结果显示 AutoPentest 略微优于基线，两者均能完成 15-25% 的子任务。总体成本为 96.20 美元，研究指出，进一步优化和更强大 LLMs 的应用有望使其成为漏洞管理的重要组成部分。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "24 pages, 1 figure, for implementation, see\n  https://github.com/JuliusHenke/autopentest",
      "pdf_url": "http://arxiv.org/pdf/2505.10321v1",
      "published_date": "2025-05-15 14:06:00 UTC",
      "updated_date": "2025-05-15 14:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:31.975713"
    },
    {
      "arxiv_id": "2505.10320v1",
      "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning",
      "title_zh": "J1：通过强化学习在 LLM-as-a-Judge 中激励思考",
      "authors": [
        "Chenxi Whitehouse",
        "Tianlu Wang",
        "Ping Yu",
        "Xian Li",
        "Jason Weston",
        "Ilia Kulikov",
        "Swarnadeep Saha"
      ],
      "abstract": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses.",
      "tldr_zh": "该研究引入了J1方法，通过Reinforcement Learning训练LLM-as-a-Judge模型，以激励Chain-of-Thought Reasoning并减少判断偏差。具体而言，J1将可验证和不可验证的提示转换为带有可验证奖励的判断任务，使模型学会概述评估标准、与自生成参考答案比较，并重新评估响应正确性。实验结果显示，J1在8B或70B模型大小上超越了现有模型，包括从DeepSeek-R1蒸馏的模型，并在某些基准上超过了o1-mini和R1。尽管模型更小，该方法通过比较Pairwise-J1 vs Pointwise-J1以及不同训练策略，证明了其在提升判断质量方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 8 tables, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10320v1",
      "published_date": "2025-05-15 14:05:15 UTC",
      "updated_date": "2025-05-15 14:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:33.815579"
    },
    {
      "arxiv_id": "2505.10315v1",
      "title": "Private Transformer Inference in MLaaS: A Survey",
      "title_zh": "MLaaS 中的私有 Transformer 推理：一项综述",
      "authors": [
        "Yang Li",
        "Xinyu Zhou",
        "Yitong Wang",
        "Liangxin Qian",
        "Jun Zhao"
      ],
      "abstract": "Transformer models have revolutionized AI, powering applications like content\ngeneration and sentiment analysis. However, their deployment in Machine\nLearning as a Service (MLaaS) raises significant privacy concerns, primarily\ndue to the centralized processing of sensitive user data. Private Transformer\nInference (PTI) offers a solution by utilizing cryptographic techniques such as\nsecure multi-party computation and homomorphic encryption, enabling inference\nwhile preserving both user data and model privacy. This paper reviews recent\nPTI advancements, highlighting state-of-the-art solutions and challenges. We\nalso introduce a structured taxonomy and evaluation framework for PTI, focusing\non balancing resource efficiency with privacy and bridging the gap between\nhigh-performance inference and data privacy.",
      "tldr_zh": "本论文调查了 Transformer 模型在 Machine Learning as a Service (MLaaS) 中的部署所带来的隐私问题，特别是对敏感用户数据的集中处理。Private Transformer Inference (PTI) 通过采用 secure multi-party computation 和 homomorphic encryption 等加密技术，实现用户数据和模型隐私保护下的推理过程。论文回顾了 PTI 的最新进展，引入了一个结构化的 taxonomy 和 evaluation framework，旨在平衡资源效率与隐私需求，同时弥合高性能推理与数据隐私之间的差距。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10315v1",
      "published_date": "2025-05-15 14:00:19 UTC",
      "updated_date": "2025-05-15 14:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:36.152847"
    },
    {
      "arxiv_id": "2505.10309v1",
      "title": "Empirically evaluating commonsense intelligence in large language models with large-scale human judgments",
      "title_zh": "基于大规模人类判断的经验性评估大型语言模型中的常识智能",
      "authors": [
        "Tuan Dung Nguyen",
        "Duncan J. Watts",
        "Mark E. Whiting"
      ],
      "abstract": "Commonsense intelligence in machines is often assessed by static benchmarks\nthat compare a model's output against human-prescribed correct labels. An\nimportant, albeit implicit, assumption of these labels is that they accurately\ncapture what any human would think, effectively treating human common sense as\nhomogeneous. However, recent empirical work has shown that humans vary\nenormously in what they consider commonsensical; thus what appears self-evident\nto one benchmark designer may not be so to another. Here, we propose a novel\nmethod for evaluating common sense in artificial intelligence (AI),\nspecifically in large language models (LLMs), that incorporates empirically\nobserved heterogeneity among humans by measuring the correspondence between a\nmodel's judgment and that of a human population. We first find that, when\ntreated as independent survey respondents, most LLMs remain below the human\nmedian in their individual commonsense competence. Second, when used as\nsimulators of a hypothetical population, LLMs correlate with real humans only\nmodestly in the extent to which they agree on the same set of statements. In\nboth cases, smaller, open-weight models are surprisingly more competitive than\nlarger, proprietary frontier models. Our evaluation framework, which ties\ncommonsense intelligence to its cultural basis, contributes to the growing call\nfor adapting AI models to human collectivities that possess different, often\nincompatible, social stocks of knowledge.",
      "tldr_zh": "这篇论文提出了一种新方法，通过大规模人类判断来评估大型语言模型(LLMs)的常识智能，该方法考虑了人类常识的异质性，而不是依赖统一的静态基准。研究发现，当LLMs被视为独立调查受访者时，大多数模型在常识能力上低于人类中位数，且在模拟人群时，与真实人类的同意程度仅为适度相关。令人意外的是，小型开源模型比大型专有模型更具竞争力，这一框架强调了将AI适应不同文化和社会知识的重要性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10309v1",
      "published_date": "2025-05-15 13:55:27 UTC",
      "updated_date": "2025-05-15 13:55:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:36.795871"
    },
    {
      "arxiv_id": "2505.10300v1",
      "title": "AI LEGO: Scaffolding Cross-Functional Collaboration in Industrial Responsible AI Practices during Early Design Stages",
      "title_zh": "AI LEGO：在工业负责任AI实践早期设计阶段的跨职能协作支架",
      "authors": [
        "Muzhe Wu",
        "Yanzhi Zhao",
        "Shuyi Han",
        "Michael Xieyang Liu",
        "Hong Shen"
      ],
      "abstract": "Responsible AI (RAI) efforts increasingly emphasize the importance of\naddressing potential harms early in the AI development lifecycle through\nsocial-technical lenses. However, in cross-functional industry teams, this work\nis often stalled by a persistent knowledge handoff challenge: the difficulty of\ntransferring high-level, early-stage technical design rationales from technical\nexperts to non-technical or user-facing roles for ethical evaluation and harm\nidentification. Through literature review and a co-design study with 8\npractitioners, we unpack how this challenge manifests -- technical design\nchoices are rarely handed off in ways that support meaningful engagement by\nnon-technical roles; collaborative workflows lack shared, visual structures to\nsupport mutual understanding; and non-technical practitioners are left without\nscaffolds for systematic harm evaluation. Existing tools like JIRA or Google\nDocs, while useful for product tracking, are ill-suited for supporting joint\nharm identification across roles, often requiring significant extra effort to\nalign understanding. To address this, we developed AI LEGO, a web-based\nprototype that supports cross-functional AI practitioners in effectively\nfacilitating knowledge handoff and identifying harmful design choices in the\nearly design stages. Technical roles use interactive blocks to draft\ndevelopment plans, while non-technical roles engage with those blocks through\nstage-specific checklists and LLM-driven persona simulations to surface\npotential harms. In a study with 18 cross-functional practitioners, AI LEGO\nincreased the volume and likelihood of harms identified compared to baseline\nworksheets. Participants found that its modular structure and persona prompts\nmade harm identification more accessible, fostering clearer and more\ncollaborative RAI practices in early design.",
      "tldr_zh": "该研究探讨了在工业Responsible AI (RAI)实践早期设计阶段的跨职能协作挑战，特别是技术专家与非技术角色之间的高水平知识传递难题。通过文献回顾和与8名从业者的联合设计研究，团队开发了AI LEGO，一个基于网络的原型工具。该工具允许技术角色使用交互模块起草开发计划，非技术角色则通过阶段特定检查列表和LLM驱动的角色模拟来识别潜在危害。在一项涉及18名从业者的研究中，AI LEGO显著提高了危害识别的数量和可能性，促进了更清晰、协作的RAI实践。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10300v1",
      "published_date": "2025-05-15 13:49:02 UTC",
      "updated_date": "2025-05-15 13:49:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:39.413172"
    },
    {
      "arxiv_id": "2505.10297v1",
      "title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning",
      "title_zh": "防御边缘：代表性注意力用于缓解联邦学习中的后门攻击",
      "authors": [
        "Chibueze Peace Obioma",
        "Youcheng Sun",
        "Mustafa A. Mustafa"
      ],
      "abstract": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments.",
      "tldr_zh": "本研究针对联邦学习（Federated Learning, FL）中后门攻击（backdoor attacks）的挑战，提出了一种新型防御机制FeRA（Federated Representative-Attention-based Defense），它利用跨客户端注意力机制分析内部特征表示，以基于表示重建错误计算异常分数，从而区分良性和恶意客户端。FeRA特别适用于非独立同分布（non-IID）数据场景，能够有效识别偏离群体共识的客户端。实验结果显示，该方法显著降低了后门攻击成功率，同时保持了主任务的高准确性，且作为模型无关（model-agnostic）和攻击无关（attack-agnostic）的方案，不需要标记参考数据，适合资源有限的边缘设备部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to ESORICS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10297v1",
      "published_date": "2025-05-15 13:44:32 UTC",
      "updated_date": "2025-05-15 13:44:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:47.973639"
    },
    {
      "arxiv_id": "2505.10278v1",
      "title": "MASS: Multi-Agent Simulation Scaling for Portfolio Construction",
      "title_zh": "MASS: 多智能体模拟缩放用于投资组合构建",
      "authors": [
        "Taian Guo",
        "Haiyang Shen",
        "Jinsheng Huang",
        "Zhengyang Mao",
        "Junyu Luo",
        "Zhuoru Chen",
        "Xuhui Liu",
        "Bingyu Xia",
        "Luchen Liu",
        "Yun Ma",
        "Ming Zhang"
      ],
      "abstract": "LLM-based multi-agent has gained significant attention for their potential in\nsimulation and enhancing performance. However, existing works are limited to\npure simulations or are constrained by predefined workflows, restricting their\napplicability and effectiveness. In this paper, we introduce the Multi-Agent\nScaling Simulation (MASS) for portfolio construction. MASS achieves stable and\ncontinuous excess returns by progressively increasing the number of agents for\nlarge-scale simulations to gain a superior understanding of the market and\noptimizing agent distribution end-to-end through a reverse optimization\nprocess, rather than relying on a fixed workflow. We demonstrate its\nsuperiority through performance experiments, ablation studies, backtesting\nexperiments, experiments on updated data and stock pools, scaling experiments,\nparameter sensitivity experiments, and visualization experiments, conducted in\ncomparison with 6 state-of-the-art baselines on 3 challenging A-share stock\npools. We expect the paradigm established by MASS to expand to other tasks with\nsimilar characteristics. The implementation of MASS has been open-sourced at\nhttps://github.com/gta0804/MASS.",
      "tldr_zh": "这篇论文引入了 MASS（Multi-Agent Scaling Simulation），一种基于 LLM 的多智能体框架，用于投资组合构建，通过逐步增加智能体数量进行大规模模拟，并通过反向优化过程端到端优化智能体分布，以实现稳定且持续的超额回报。不同于现有工作依赖预定义工作流，MASS 提供更灵活的模拟方法，提升了对市场的理解。实验结果显示，MASS 在与 6 个最先进基线的比较中，在 3 个具有挑战性的 A 股股票池上表现出显著优越性，包括性能实验、回测实验和消融研究等，并已开源实现，预计可扩展到其他类似任务。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10278v1",
      "published_date": "2025-05-15 13:27:18 UTC",
      "updated_date": "2025-05-15 13:27:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:51.615880"
    },
    {
      "arxiv_id": "2505.10273v1",
      "title": "AttentionGuard: Transformer-based Misbehavior Detection for Secure Vehicular Platoons",
      "title_zh": "AttentionGuard: 基于 Transformer 的异常行为检测用于安全车辆编队",
      "authors": [
        "Hexu Li",
        "Konstantinos Kalogiannis",
        "Ahmed Mohamed Hussain",
        "Panos Papadimitratos"
      ],
      "abstract": "Vehicle platooning, with vehicles traveling in close formation coordinated\nthrough Vehicle-to-Everything (V2X) communications, offers significant benefits\nin fuel efficiency and road utilization. However, it is vulnerable to\nsophisticated falsification attacks by authenticated insiders that can\ndestabilize the formation and potentially cause catastrophic collisions. This\npaper addresses this challenge: misbehavior detection in vehicle platooning\nsystems. We present AttentionGuard, a transformer-based framework for\nmisbehavior detection that leverages the self-attention mechanism to identify\nanomalous patterns in mobility data. Our proposal employs a multi-head\ntransformer-encoder to process sequential kinematic information, enabling\neffective differentiation between normal mobility patterns and falsification\nattacks across diverse platooning scenarios, including steady-state\n(no-maneuver) operation, join, and exit maneuvers. Our evaluation uses an\nextensive simulation dataset featuring various attack vectors (constant,\ngradual, and combined falsifications) and operational parameters (controller\ntypes, vehicle speeds, and attacker positions). Experimental results\ndemonstrate that AttentionGuard achieves up to 0.95 F1-score in attack\ndetection, with robust performance maintained during complex maneuvers.\nNotably, our system performs effectively with minimal latency (100ms decision\nintervals), making it suitable for real-time transportation safety\napplications. Comparative analysis reveals superior detection capabilities and\nestablishes the transformer-encoder as a promising approach for securing\nCooperative Intelligent Transport Systems (C-ITS) against sophisticated insider\nthreats.",
      "tldr_zh": "本论文提出AttentionGuard，一种基于Transformer的框架，用于检测车辆编队系统中的异常行为，以应对经认证的内部攻击可能导致的编队不稳定和碰撞风险。该框架利用多头Transformer-encoder处理顺序运动数据，通过self-attention机制识别正常模式与伪造攻击（如常量、渐进或组合 falsifications）间的差异，并在稳态操作、加入和退出maneuvers等多种场景中表现出色。实验结果显示，AttentionGuard在模拟数据集上实现高达0.95的F1-score，并保持最小延迟（100ms决策间隔），使其适用于实时Cooperative Intelligent Transport Systems (C-ITS)安全应用。相比基线模型，该方法显著提升了检测能力，为保护V2X通信的车辆编队提供了可靠解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "Author's version; Accepted for presentation at the ACM Workshop on\n  Wireless Security and Machine Learning (WiseML 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.10273v1",
      "published_date": "2025-05-15 13:24:09 UTC",
      "updated_date": "2025-05-15 13:24:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:51.551706"
    },
    {
      "arxiv_id": "2505.10264v1",
      "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning",
      "title_zh": "突破隐私：基于超平面的联邦学习数据重建攻击",
      "authors": [
        "Francesco Diana",
        "André Nusser",
        "Chuan Xu",
        "Giovanni Neglia"
      ],
      "abstract": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art.",
      "tldr_zh": "该论文探讨了 Federated Learning 中的隐私风险，揭示恶意中央服务器可通过操纵模型更新重建客户端的私有数据，而现有数据重建攻击方法依赖数据分布假设或在大型批量下效率低下。研究提出了一种基于超平面（Hyperplane-Based）的创新攻击方法，利用全连接层的几何视角来构建恶意模型参数，从而在分类任务中无需任何先验知识即可完美恢复任意大小的数据批量。通过在图像和表格数据集上的广泛实验，该攻击比现有方法性能更优，并实现了比最先进技术大两个数量级的完美数据重建。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10264v1",
      "published_date": "2025-05-15 13:16:32 UTC",
      "updated_date": "2025-05-15 13:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:53.926993"
    },
    {
      "arxiv_id": "2505.10261v1",
      "title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine",
      "title_zh": "生成式大语言模型与传统自然语言处理在医学中的演变景观",
      "authors": [
        "Rui Yang",
        "Huitao Li",
        "Matthew Yu Heng Wong",
        "Yuhe Ke",
        "Xin Li",
        "Kunyu Yu",
        "Jingchi Liao",
        "Jonathan Chong Kai Liew",
        "Sabarinath Vinod Nair",
        "Jasmine Chiat Ling Ong",
        "Irene Li",
        "Douglas Teodoro",
        "Chuan Hong",
        "Daniel Shu Wei Ting",
        "Nan Liu"
      ],
      "abstract": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications.",
      "tldr_zh": "这篇论文探讨了生成式大型语言模型(LLMs)和传统自然语言处理(NLP)在医学领域的演变差异，通过分析19,123份研究进行系统评估。研究发现，LLMs在开放式(open-ended)任务中表现出显著优势，而传统NLP在信息提取和分析任务中占据主导地位。随着这些技术的快速发展，论文强调确保其伦理使用至关重要，以充分发挥其在医疗应用中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10261v1",
      "published_date": "2025-05-15 13:11:14 UTC",
      "updated_date": "2025-05-15 13:11:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:54.794085"
    },
    {
      "arxiv_id": "2505.10260v1",
      "title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data",
      "title_zh": "比较LLM文本标注技能：一项关于社交媒体数据中人权侵犯的研究",
      "authors": [
        "Poli Apollinaire Nemkova",
        "Solomon Ubani",
        "Mark V. Albert"
      ],
      "abstract": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios.",
      "tldr_zh": "本研究比较了多个大型语言模型（LLMs）如GPT-3.5、GPT-4、LLAMA3、Mistral 7B和Claude-2在零-shot和few-shot设置下，对俄语和乌克兰语社交媒体帖子的文本标注能力，焦点是二元分类任务——识别人权侵犯引用。研究方法包括将模型标注结果与人类双重标注的金标准比较，并在英语和俄语提示条件下评估性能，同时分析各模型的错误模式、优势、局限性和跨语言适应性。通过这些比较，论文揭示了LLMs在多语言敏感任务中的可靠性和适用性，并强调了它们在处理主观、上下文依赖判断时的挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10260v1",
      "published_date": "2025-05-15 13:10:47 UTC",
      "updated_date": "2025-05-15 13:10:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:51:57.511516"
    },
    {
      "arxiv_id": "2505.10231v1",
      "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging",
      "title_zh": "关于人类-AI 对齐、公平性和性能权衡在医学成像中的相互作用",
      "authors": [
        "Haozhe Luo",
        "Ziyu Zhou",
        "Zixin Shu",
        "Aurélie Pahud de Mortanges",
        "Robert Berke",
        "Mauricio Reyes"
      ],
      "abstract": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner.",
      "tldr_zh": "这篇论文首次系统探讨了 Human-AI alignment 与公平性在医疗成像中的互动，揭示了深度神经网络偏见导致的人口群体公平差距问题。研究发现，融入人类洞见可以有效减少这些公平差距并提升模型的领域外泛化能力，但过度 alignment 可能带来性能权衡，从而强调了需要采用校准策略。总体而言，该方法为开发公平、鲁棒且可泛化的医疗 AI 系统提供了新途径，并公开了代码（https://github.com/Roypic/Aligner）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10231v1",
      "published_date": "2025-05-15 12:43:23 UTC",
      "updated_date": "2025-05-15 12:43:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:00.327791"
    },
    {
      "arxiv_id": "2505.10212v1",
      "title": "Do LLMs Memorize Recommendation Datasets? A Preliminary Study on MovieLens-1M",
      "title_zh": "大型语言模型是否记忆推荐数据集？ 关于 MovieLens-1M 的初步研究",
      "authors": [
        "Dario Di Palma",
        "Felice Antonio Merra",
        "Maurizio Sfilio",
        "Vito Walter Anelli",
        "Fedelucio Narducci",
        "Tommaso Di Noia"
      ],
      "abstract": "Large Language Models (LLMs) have become increasingly central to\nrecommendation scenarios due to their remarkable natural language understanding\nand generation capabilities. Although significant research has explored the use\nof LLMs for various recommendation tasks, little effort has been dedicated to\nverifying whether they have memorized public recommendation dataset as part of\ntheir training data. This is undesirable because memorization reduces the\ngeneralizability of research findings, as benchmarking on memorized datasets\ndoes not guarantee generalization to unseen datasets. Furthermore, memorization\ncan amplify biases, for example, some popular items may be recommended more\nfrequently than others.\n  In this work, we investigate whether LLMs have memorized public\nrecommendation datasets. Specifically, we examine two model families (GPT and\nLlama) across multiple sizes, focusing on one of the most widely used dataset\nin recommender systems: MovieLens-1M. First, we define dataset memorization as\nthe extent to which item attributes, user profiles, and user-item interactions\ncan be retrieved by prompting the LLMs. Second, we analyze the impact of\nmemorization on recommendation performance. Lastly, we examine whether\nmemorization varies across model families and model sizes. Our results reveal\nthat all models exhibit some degree of memorization of MovieLens-1M, and that\nrecommendation performance is related to the extent of memorization. We have\nmade all the code publicly available at:\nhttps://github.com/sisinflab/LLM-MemoryInspector",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)是否记忆公共推荐数据集，以MovieLens-1M为例，指出记忆可能降低模型的泛化能力和放大偏差。研究方法包括通过提示检索模型对项目属性、用户资料和用户-项目互动的记忆程度，并分析其对推荐性能的影响。结果显示，GPT和Llama系列模型在不同大小上均存在记忆行为，且记忆程度与推荐性能正相关。作者已将代码公开在GitHub上，以供进一步验证。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10212v1",
      "published_date": "2025-05-15 12:16:36 UTC",
      "updated_date": "2025-05-15 12:16:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:00.476793"
    },
    {
      "arxiv_id": "2505.10201v1",
      "title": "A Fine-Grained Complexity View on Propositional Abduction -- Algorithms and Lower Bounds",
      "title_zh": "对命题溯因的细粒度复杂度视角——算法和下界",
      "authors": [
        "Victor Lagerkvist",
        "Mohamed Maizia",
        "Johannes Schmidt"
      ],
      "abstract": "The Boolean satisfiability problem (SAT) is a well-known example of monotonic\nreasoning, of intense practical interest due to fast solvers, complemented by\nrigorous fine-grained complexity results. However, for non-monotonic reasoning,\ne.g., abductive reasoning, comparably little is known outside classic\ncomplexity theory. In this paper we take a first step of bridging the gap\nbetween monotonic and non-monotonic reasoning by analyzing the complexity of\nintractable abduction problems under the seemingly overlooked but natural\nparameter n: the number of variables in the knowledge base. We obtain several\npositive results for $\\Sigma^P_2$- as well as NP- and coNP-complete fragments,\nwhich implies the first example of beating exhaustive search for a\n$\\Sigma^P_2$-complete problem (to the best of our knowledge). We complement\nthis with lower bounds and for many fragments rule out improvements under the\n(strong) exponential-time hypothesis.",
      "tldr_zh": "这篇论文探讨了命题溯因（propositional abduction）的精细复杂度，分析了在参数 n（知识库中的变量数）下的不可解问题，以桥接单调推理（如 SAT）和非单调推理的差距。研究者为 Σ^P_2-complete 以及 NP-complete 和 coNP-complete 片段开发了优于穷举搜索的算法，实现了首次击败穷举搜索的 Σ^P_2-complete 问题示例。论文还提供了下界，并在指数时间假设（exponential-time hypothesis）下，排除了许多片段的进一步改进可能性。",
      "categories": [
        "cs.CC",
        "cs.AI",
        "F.2.2"
      ],
      "primary_category": "cs.CC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10201v1",
      "published_date": "2025-05-15 11:56:19 UTC",
      "updated_date": "2025-05-15 11:56:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:03.342813"
    },
    {
      "arxiv_id": "2505.10197v1",
      "title": "Advancing Community Detection with Graph Convolutional Neural Networks: Bridging Topological and Attributive Cohesion",
      "title_zh": "使用图卷积神经网络推进社区检测：桥接拓扑和属性凝聚",
      "authors": [
        "Anjali de Silva",
        "Gang Chen",
        "Hui Ma",
        "Seyed Mohammad Nekooei",
        "Xingquan Zuo"
      ],
      "abstract": "Community detection, a vital technology for real-world applications, uncovers\ncohesive node groups (communities) by leveraging both topological and attribute\nsimilarities in social networks. However, existing Graph Convolutional Networks\n(GCNs) trained to maximize modularity often converge to suboptimal solutions.\nAdditionally, directly using human-labeled communities for training can\nundermine topological cohesiveness by grouping disconnected nodes based solely\non node attributes. We address these issues by proposing a novel Topological\nand Attributive Similarity-based Community detection (TAS-Com) method. TAS-Com\nintroduces a novel loss function that exploits the highly effective and\nscalable Leiden algorithm to detect community structures with global optimal\nmodularity. Leiden is further utilized to refine human-labeled communities to\nensure connectivity within each community, enabling TAS-Com to detect community\nstructures with desirable trade-offs between modularity and compliance with\nhuman labels. Experimental results on multiple benchmark networks confirm that\nTAS-Com can significantly outperform several state-of-the-art algorithms.",
      "tldr_zh": "这篇论文针对社区检测中的问题，提出了一种新型方法 Topological and Attributive Similarity-based Community detection (TAS-Com)，利用 Graph Convolutional Networks (GCNs) 桥接拓扑和属性凝聚，以解决现有 GCNs 在最大化 modularity 时收敛到次优解的问题。TAS-Com 引入一个新损失函数，并借助 Leiden 算法检测具有全局最优 modularity 的社区结构，同时精炼人类标记的社区以确保内部连通性，实现 modularity 与标签符合性的良好权衡。在多个基准网络上的实验结果表明，TAS-Com 显著优于现有算法。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "This paper has been accepted by IJCAI (International Joint Conference\n  on Artificial Intelligence) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10197v1",
      "published_date": "2025-05-15 11:53:33 UTC",
      "updated_date": "2025-05-15 11:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:06.260040"
    },
    {
      "arxiv_id": "2505.10191v1",
      "title": "LanTu: Dynamics-Enhanced Deep Learning for Eddy-Resolving Ocean Forecasting",
      "title_zh": "LanTu：动态增强深度学习用于涡流分辨海洋预报",
      "authors": [
        "Qingyu Zheng",
        "Qi Shao",
        "Guijun Han",
        "Wei Li",
        "Hong Li",
        "Xuan Wang"
      ],
      "abstract": "Mesoscale eddies dominate the spatiotemporal multiscale variability of the\nocean, and their impact on the energy cascade of the global ocean cannot be\nignored. Eddy-resolving ocean forecasting is providing more reliable protection\nfor fisheries and navigational safety, but also presents significant scientific\nchallenges and high computational costs for traditional numerical models.\nArtificial intelligence (AI)-based weather and ocean forecasting systems are\nbecoming powerful tools that balance forecast performance with computational\nefficiency. However, the complex multiscale features in the ocean dynamical\nsystem make AI models still face many challenges in mesoscale eddy forecasting\n(especially regional modelling). Here, we develop LanTu, a regional\neddy-resolving ocean forecasting system based on dynamics-enhanced deep\nlearning. We incorporate cross-scale interactions into LanTu and construct\nmultiscale physical constraint for optimising LanTu guided by knowledge of eddy\ndynamics in order to improve the forecasting skill of LanTu for mesoscale\nevolution. The results show that LanTu outperforms the existing advanced\noperational numerical ocean forecasting system (NOFS) and AI-based ocean\nforecasting system (AI-OFS) in temperature, salinity, sea level anomaly and\ncurrent prediction, with a lead time of more than 10 days. Our study highlights\nthat dynamics-enhanced deep learning (LanTu) can be a powerful paradigm for\neddy-resolving ocean forecasting.",
      "tldr_zh": "这项研究开发了LanTu，一种基于Dynamics-Enhanced Deep Learning的区域中尺度涡流预报系统，旨在解决传统数值模型在计算成本和准确性上的挑战。LanTu通过整合跨尺度交互和多尺度物理约束，利用中尺度涡流动力学知识优化模型，提高了对海洋多尺度特征的预测能力。实验结果表明，LanTu在温度、盐度、海平面异常和电流预测方面优于现有的数值海洋预报系统(NOFS)和AI-based海洋预报系统(AI-OFS)，预测时长超过10天。该系统展示了动态增强深度学习在Eddy-Resolving Ocean Forecasting中的强大潜力。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG",
        "nlin.CD"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "22 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10191v1",
      "published_date": "2025-05-15 11:47:54 UTC",
      "updated_date": "2025-05-15 11:47:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:15.456488"
    },
    {
      "arxiv_id": "2505.10188v1",
      "title": "A User Study Evaluating Argumentative Explanations in Diagnostic Decision Support",
      "title_zh": "评估诊断决策支持中论证性解释的用户研究",
      "authors": [
        "Felix Liedeker",
        "Olivia Sanchez-Graillet",
        "Moana Seidler",
        "Christian Brandt",
        "Jörg Wellmer",
        "Philipp Cimiano"
      ],
      "abstract": "As the field of healthcare increasingly adopts artificial intelligence, it\nbecomes important to understand which types of explanations increase\ntransparency and empower users to develop confidence and trust in the\npredictions made by machine learning (ML) systems. In shared decision-making\nscenarios where doctors cooperate with ML systems to reach an appropriate\ndecision, establishing mutual trust is crucial. In this paper, we explore\ndifferent approaches to generating explanations in eXplainable AI (XAI) and\nmake their underlying arguments explicit so that they can be evaluated by\nmedical experts. In particular, we present the findings of a user study\nconducted with physicians to investigate their perceptions of various types of\nAI-generated explanations in the context of diagnostic decision support. The\nstudy aims to identify the most effective and useful explanations that enhance\nthe diagnostic process. In the study, medical doctors filled out a survey to\nassess different types of explanations. Further, an interview was carried out\npost-survey to gain qualitative insights on the requirements of explanations\nincorporated in diagnostic decision support. Overall, the insights gained from\nthis study contribute to understanding the types of explanations that are most\neffective.",
      "tldr_zh": "本研究评估了在诊断决策支持中，使用不同类型的解释（argumentative explanations）如何提升AI系统的透明度和用户信任，特别是eXplainable AI (XAI)领域的应用。研究通过一项用户研究，包括医生参与的调查和后续访谈，探讨了医疗专家对AI生成解释的感知，并识别出哪些解释类型最有效。结果表明，这些解释有助于增强医生与AI的合作，提高诊断过程的准确性和互信，为医疗AI的优化提供了宝贵见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at 'The First Workshop on Natural Language Argument-Based\n  Explanations', co-located with ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.10188v1",
      "published_date": "2025-05-15 11:42:24 UTC",
      "updated_date": "2025-05-15 11:42:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:14.948982"
    },
    {
      "arxiv_id": "2505.10185v1",
      "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think",
      "title_zh": "CoT 百科全书：分析、预测和控制推理模型的思考方式",
      "authors": [
        "Seongyun Lee",
        "Seungone Kim",
        "Minju Seo",
        "Yongrae Jo",
        "Dongyoung Go",
        "Hyeonbin Hwang",
        "Jinho Park",
        "Xiang Yue",
        "Sean Welleck",
        "Graham Neubig",
        "Moontae Lee",
        "Minjoon Seo"
      ],
      "abstract": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design.",
      "tldr_zh": "本研究提出 CoT Encyclopedia 框架，用于分析、预测和控制推理模型的思维过程。该框架采用自底向上的方法，从模型生成的 chain-of-thought (CoT) 中自动提取多样化推理标准，将其嵌入语义空间、聚类成代表性类别，并推导对比性 rubrics 以解释模型行为。相比现有方法，人评估显示该框架更具可解释性和全面性；此外，它能预测模型可能采用的策略并引导向更有效的替代方案。研究还发现，训练数据格式（如自由形式 vs. multiple-choice）对推理行为的影响远大于数据领域，这为模型设计提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.10185v1",
      "published_date": "2025-05-15 11:31:02 UTC",
      "updated_date": "2025-05-15 11:31:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:19.786937"
    },
    {
      "arxiv_id": "2505.10183v1",
      "title": "KAITIAN: A Unified Communication Framework for Enabling Efficient Collaboration Across Heterogeneous Accelerators in Embodied AI Systems",
      "title_zh": "KAITIAN：用于在具身 AI 系统中启用异构加速器高效协作的统一通信框架",
      "authors": [
        "Jieke Lin",
        "Wanyu Wang",
        "Longxiang Yin",
        "Yinhe Han"
      ],
      "abstract": "Embodied Artificial Intelligence (AI) systems, such as autonomous robots and\nintelligent vehicles, are increasingly reliant on diverse heterogeneous\naccelerators (e.g., GPGPUs, NPUs, FPGAs) to meet stringent real-time processing\nand energy-efficiency demands. However, the proliferation of vendor-specific\nproprietary communication libraries creates significant interoperability\nbarriers, hindering seamless collaboration between different accelerator types\nand leading to suboptimal resource utilization and performance bottlenecks in\ndistributed AI workloads. This paper introduces KAITIAN, a novel distributed\ncommunication framework designed to bridge this gap. KAITIAN provides a unified\nabstraction layer that intelligently integrates vendor-optimized communication\nlibraries for intra-group efficiency with general-purpose communication\nprotocols for inter-group interoperability. Crucially, it incorporates a\nload-adaptive scheduling mechanism that dynamically balances computational\ntasks across heterogeneous devices based on their real-time performance\ncharacteristics. Implemented as an extension to PyTorch and rigorously\nevaluated on a testbed featuring NVIDIA GPUs and Cambricon MLUs, KAITIAN\ndemonstrates significant improvements in resource utilization and scalability\nfor distributed training tasks. Experimental results show that KAITIAN can\naccelerate training time by up to 42% compared to baseline homogeneous systems,\nwhile incurring minimal communication overhead (2.8--4.3%) and maintaining\nmodel accuracy. KAITIAN paves the way for more flexible and powerful\nheterogeneous computing in complex embodied AI applications.",
      "tldr_zh": "该论文针对Embodied AI系统（如自主机器人和智能车辆）中异构加速器（GPGPUs、NPUs、FPGAs）的互操作性问题，提出KAITIAN框架，以统一通信层桥接供应商专有库和通用协议。KAITIAN整合负载自适应调度机制，根据实时性能动态平衡任务，实现高效的跨设备协作，并作为PyTorch的扩展进行实现。实验结果显示，KAITIAN在分布式训练任务中将训练时间加速高达42%，通信开销仅为2.8-4.3%，同时保持模型准确性，并为复杂Embodied AI应用的异构计算提供更灵活的解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "9 pages, 4 figures. Jieke Lin and Wanyu Wang contributed equally to\n  this work",
      "pdf_url": "http://arxiv.org/pdf/2505.10183v1",
      "published_date": "2025-05-15 11:29:43 UTC",
      "updated_date": "2025-05-15 11:29:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:21.102627"
    },
    {
      "arxiv_id": "2505.10172v1",
      "title": "Does Scaling Law Apply in Time Series Forecasting?",
      "title_zh": "缩放定律是否适用于时间序列预测？",
      "authors": [
        "Zeyan Li",
        "Libing Chen",
        "Yin Tang"
      ],
      "abstract": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling.",
      "tldr_zh": "本研究质疑了Scaling Law在Time Series Forecasting中的适用性，提出了一种超轻量级模型Alinear，仅使用k-level parameters即可实现与大型模型相当的预测性能。Alinear引入了Horizon-aware adaptive decomposition mechanism和Progressive frequency attenuation strategy，动态调整组件强调并实现稳定预测，而避免了attention机制的计算开销。在七个基准数据集上的实验显示，Alinear在使用不到1%参数的情况下， consistently outperforms大型模型，并在短和超长预测horizon上保持高准确率；此外，论文提出了一种新的Parameter-aware evaluation metric，并通过分析验证了趋势和季节组件的重要性取决于数据特性，从而倡导更高效的时间序列建模范式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10172v1",
      "published_date": "2025-05-15 11:04:39 UTC",
      "updated_date": "2025-05-15 11:04:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:22.805876"
    },
    {
      "arxiv_id": "2505.10169v1",
      "title": "Modeling Saliency Dataset Bias",
      "title_zh": "建模显著性数据集偏差",
      "authors": [
        "Matthias Kümmerer",
        "Harneet Khanuja",
        "Matthias Bethge"
      ],
      "abstract": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes.",
      "tldr_zh": "这篇论文探讨了图像显著性预测模型在不同数据集间的泛化挑战，由于数据集偏差导致性能下降约40%，即使增加数据集多样性也无法完全解决。作者提出了一种新架构，通过在数据集无关的编码器-解码器结构中添加少于20个数据集特定参数（如多尺度结构、中央偏差和注视点分布），来有效处理这些偏差，仅需少于50个样本即可覆盖超过75%的泛化差距。该模型在MIT/Tuebingen Saliency Benchmark的三个数据集（MIT300、CAT2000和COCO-Freeview）上实现了新的最先进性能，并提供了对空间显著性属性的洞见，包括复杂的绝对和相对大小的多尺度效应。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10169v1",
      "published_date": "2025-05-15 10:55:47 UTC",
      "updated_date": "2025-05-15 10:55:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:25.925011"
    },
    {
      "arxiv_id": "2505.10167v1",
      "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models",
      "title_zh": "QuXAI：混合量子机器学习模型的解释器",
      "authors": [
        "Saikat Barua",
        "Mostafizur Rahman",
        "Shehenaz Khaled",
        "Md Jafor Sadek",
        "Rafiul Islam",
        "Shahnewaz Siddique"
      ],
      "abstract": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology.",
      "tldr_zh": "本文提出QuXAI框架，用于解释混合量子-经典机器学习(HQML)模型的特征重要性，以解决这些模型的黑盒行为问题，提高透明度和可靠性。QuXAI基于Q-MEDLEY解释器，结合量子特征映射、特征基于推理和可视化归因，保留量子转换阶段来分析HQML模型。实验结果显示，Q-MEDLEY能有效识别影响力的经典方面、分离噪声，并在经典验证设置中与传统XAI技术竞争；消融研究进一步证实其复合结构的优势。该框架的意义在于提升HQML模型的可解释性和可靠性，促进更安全、负责任的量子增强AI技术的应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 6 figures, 7 equations",
      "pdf_url": "http://arxiv.org/pdf/2505.10167v1",
      "published_date": "2025-05-15 10:51:34 UTC",
      "updated_date": "2025-05-15 10:51:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:26.465238"
    },
    {
      "arxiv_id": "2505.10134v1",
      "title": "Large Wireless Localization Model (LWLM): A Foundation Model for Positioning in 6G Networks",
      "title_zh": "大型无线定位模型 (LWLM)：用于 6G 网络中定位的基础模型",
      "authors": [
        "Guangjin Pan",
        "Kaixuan Huang",
        "Hui Chen",
        "Shunqing Zhang",
        "Christian Häger",
        "Henk Wymeersch"
      ],
      "abstract": "Accurate and robust localization is a critical enabler for emerging 5G and 6G\napplications, including autonomous driving, extended reality (XR), and smart\nmanufacturing. While data-driven approaches have shown promise, most existing\nmodels require large amounts of labeled data and struggle to generalize across\ndeployment scenarios and wireless configurations. To address these limitations,\nwe propose a foundation-model-based solution tailored for wireless\nlocalization. We first analyze how different self-supervised learning (SSL)\ntasks acquire general-purpose and task-specific semantic features based on\ninformation bottleneck (IB) theory. Building on this foundation, we design a\npretraining methodology for the proposed Large Wireless Localization Model\n(LWLM). Specifically, we propose an SSL framework that jointly optimizes three\ncomplementary objectives: (i) spatial-frequency masked channel modeling\n(SF-MCM), (ii) domain-transformation invariance (DTI), and (iii)\nposition-invariant contrastive learning (PICL). These objectives jointly\ncapture the underlying semantics of wireless channel from multiple\nperspectives. We further design lightweight decoders for key downstream tasks,\nincluding time-of-arrival (ToA) estimation, angle-of-arrival (AoA) estimation,\nsingle base station (BS) localization, and multiple BS localization.\nComprehensive experimental results confirm that LWLM consistently surpasses\nboth model-based and supervised learning baselines across all localization\ntasks. In particular, LWLM achieves 26.0%--87.5% improvement over transformer\nmodels without pretraining, and exhibits strong generalization under\nlabel-limited fine-tuning and unseen BS configurations, confirming its\npotential as a foundation model for wireless localization.",
      "tldr_zh": "该研究提出Large Wireless Localization Model (LWLM)，一种针对6G网络定位的基础模型，旨在解决现有数据驱动方法依赖大量标注数据且泛化能力不足的问题。LWLM基于information bottleneck (IB) theory分析self-supervised learning (SSL)任务，设计了一个联合优化框架，包括spatial-frequency masked channel modeling (SF-MCM)、domain-transformation invariance (DTI)和position-invariant contrastive learning (PICL)，从多角度捕获无线通道的底层语义。论文还开发了轻量级解码器，支持time-of-arrival (ToA)估计、angle-of-arrival (AoA)估计以及单/多基站定位任务；实验结果显示，LWLM在所有任务中比基线模型提升26.0%–87.5%，并在标签有限和未见配置下表现出卓越的泛化能力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "13 pages,16 figures.This work has been submitted to the IEEE for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2505.10134v1",
      "published_date": "2025-05-15 10:04:44 UTC",
      "updated_date": "2025-05-15 10:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:29.088914"
    },
    {
      "arxiv_id": "2505.10128v1",
      "title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity",
      "title_zh": "在边缘设备上针对领域异质性的鲁棒联邦学习",
      "authors": [
        "Huy Q. Le",
        "Latif U. Khan",
        "Choong Seon Hong"
      ],
      "abstract": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance.",
      "tldr_zh": "本研究针对 Federated Learning (FL) 在边缘设备上训练时面临的领域异质性问题，提出了一种新框架 FedAPC，以提升全局模型的泛化能力和鲁棒性。FedAPC 通过原型增强（prototype augmentation）和对比学习（Contrastive Learning），利用增强数据的均值特征派生原型，并对齐本地特征与全局原型，从而增强特征多样性并减少过拟合。实验结果显示，在 Office-10 和 Digits 数据集上，FedAPC 框架优于 SOTA 基线，证明了其在处理统计异质性方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "IWCMC 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10128v1",
      "published_date": "2025-05-15 09:53:14 UTC",
      "updated_date": "2025-05-15 09:53:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:30.019561"
    },
    {
      "arxiv_id": "2505.10120v1",
      "title": "All You Need Is Synthetic Task Augmentation",
      "title_zh": "只需合成任务增强",
      "authors": [
        "Guillaume Godin"
      ],
      "abstract": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining.",
      "tldr_zh": "本研究提出了一种合成任务增强策略，用于解决规则-based模型（如Random Forests）注入可微神经网络框架的挑战。方法是通过联合训练一个Graph Transformer神经网络，同时处理稀疏的多任务分子属性预测目标和从XGBoost模型派生的合成辅助任务，从而提升模型性能。结果显示，在19个分子属性预测任务中，性能一致显著改善，其中16个任务的Graph Transformer优于XGBoost单任务学习。该策略无需预训练或特征注入，即可有效增强神经模型在多任务分子属性预测中的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 3 Figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.10120v1",
      "published_date": "2025-05-15 09:46:27 UTC",
      "updated_date": "2025-05-15 09:46:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:32.947902"
    },
    {
      "arxiv_id": "2505.10105v1",
      "title": "EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation",
      "title_zh": "EmbodiedMAE：一种统一的3D多模态表示，用于机器人操控",
      "authors": [
        "Zibin Dong",
        "Fei Ni",
        "Yifu Yuan",
        "Yinchuan Li",
        "Jianye Hao"
      ],
      "abstract": "We present EmbodiedMAE, a unified 3D multi-modal representation for robot\nmanipulation. Current approaches suffer from significant domain gaps between\ntraining datasets and robot manipulation tasks, while also lacking model\narchitectures that can effectively incorporate 3D information. To overcome\nthese limitations, we enhance the DROID dataset with high-quality depth maps\nand point clouds, constructing DROID-3D as a valuable supplement for 3D\nembodied vision research. Then we develop EmbodiedMAE, a multi-modal masked\nautoencoder that simultaneously learns representations across RGB, depth, and\npoint cloud modalities through stochastic masking and cross-modal fusion.\nTrained on DROID-3D, EmbodiedMAE consistently outperforms state-of-the-art\nvision foundation models (VFMs) in both training efficiency and final\nperformance across 70 simulation tasks and 20 real-world robot manipulation\ntasks on two robot platforms. The model exhibits strong scaling behavior with\nsize and promotes effective policy learning from 3D inputs. Experimental\nresults establish EmbodiedMAE as a reliable unified 3D multi-modal VFM for\nembodied AI systems, particularly in precise tabletop manipulation settings\nwhere spatial perception is critical.",
      "tldr_zh": "本研究提出EmbodiedMAE，一种统一的3D多模态表示框架，用于提升机器人操作性能，以解决现有方法在训练数据集领域差距和3D信息整合方面的局限性。研究团队增强了DROID数据集，添加高质量深度图和点云，构建了DROID-3D数据集；随后开发了EmbodiedMAE的多模态掩码自动编码器，通过随机掩码和跨模态融合同时学习RGB、深度和点云的表示。实验结果显示，EmbodiedMAE在70个模拟任务和20个真实机器人任务上，超越了最先进视觉基础模型(VFMs)，并在训练效率和最终性能方面表现出色，具有良好的模型规模扩展性，为依赖精确空间感知的机器人操作提供可靠的支持。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10105v1",
      "published_date": "2025-05-15 09:12:17 UTC",
      "updated_date": "2025-05-15 09:12:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:41.253375"
    },
    {
      "arxiv_id": "2505.10101v1",
      "title": "LAV: Audio-Driven Dynamic Visual Generation with Neural Compression and StyleGAN2",
      "title_zh": "LAV：基于神经压缩和 StyleGAN2 的音频驱动动态视觉生成",
      "authors": [
        "Jongmin Jung",
        "Dasaem Jeong"
      ],
      "abstract": "This paper introduces LAV (Latent Audio-Visual), a system that integrates\nEnCodec's neural audio compression with StyleGAN2's generative capabilities to\nproduce visually dynamic outputs driven by pre-recorded audio. Unlike previous\nworks that rely on explicit feature mappings, LAV uses EnCodec embeddings as\nlatent representations, directly transformed into StyleGAN2's style latent\nspace via randomly initialized linear mapping. This approach preserves semantic\nrichness in the transformation, enabling nuanced and semantically coherent\naudio-visual translations. The framework demonstrates the potential of using\npretrained audio compression models for artistic and computational\napplications.",
      "tldr_zh": "本文提出 LAV 系统，将 EnCodec 的神经音频压缩与 StyleGAN2 的生成能力整合，用于基于预录音频生成动态视觉输出。不同于以往依赖显式特征映射的方法，LAV 使用 EnCodec 嵌入作为 latent representations，通过随机初始化的线性映射直接转换为 StyleGAN2 的 style latent space，从而保留语义丰富性和实现细微、语义连贯的音频-视觉转换。该框架展示了预训练音频压缩模型在艺术和计算应用中的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.GR",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Paper accepted at ISEA 2025, The 30th International Symposium on\n  Electronic/Emerging Art, Seoul, Republic of Korea, 23 - 29 May 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10101v1",
      "published_date": "2025-05-15 09:04:12 UTC",
      "updated_date": "2025-05-15 09:04:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:42.576506"
    },
    {
      "arxiv_id": "2505.10093v1",
      "title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI",
      "title_zh": "从文本到网络：使用生成式 AI 构建基于台湾的中国研究知识图谱",
      "authors": [
        "Hsuan-Lei Shao"
      ],
      "abstract": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems.",
      "tldr_zh": "该研究针对台湾中国研究（Taiwan-Based China Studies）的丰富学术文献，提出了一种使用生成式 AI（Generative AI）和大型语言模型（Large Language Models, LLMs）的方法，将无结构化文本转化为结构化的知识图谱。具体而言，研究从1996年至2019年的1,367篇同行评议文章中提取并标准化实体关系三元组，并通过D3.js基于系统进行可视化，形成一个可交互的知识图谱和向量数据库。这种方法实现了从线性文本消费到网络化知识导航的转变，揭示了知识轨迹、主题集群及研究空白，并为区域研究和数字人文领域提供可扩展的数据驱动基础设施。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.4; H.3.3; J.5"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10093v1",
      "published_date": "2025-05-15 08:51:53 UTC",
      "updated_date": "2025-05-15 08:51:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:45.279775"
    },
    {
      "arxiv_id": "2505.10074v1",
      "title": "Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs",
      "title_zh": "利用图检索增强生成支持 MOOCs 中学习者对知识概念的理解",
      "authors": [
        "Mohamed Abdelmagied",
        "Mohamed Amine Chatti",
        "Shoeb Joarder",
        "Qurat Ul Ain",
        "Rawaa Alatrash"
      ],
      "abstract": "Massive Open Online Courses (MOOCs) lack direct interaction between learners\nand instructors, making it challenging for learners to understand new knowledge\nconcepts. Recently, learners have increasingly used Large Language Models\n(LLMs) to support them in acquiring new knowledge. However, LLMs are prone to\nhallucinations which limits their reliability. Retrieval-Augmented Generation\n(RAG) addresses this issue by retrieving relevant documents before generating a\nresponse. However, the application of RAG across different MOOCs is limited by\nunstructured learning material. Furthermore, current RAG systems do not\nactively guide learners toward their learning needs. To address these\nchallenges, we propose a Graph RAG pipeline that leverages Educational\nKnowledge Graphs (EduKGs) and Personal Knowledge Graphs (PKGs) to guide\nlearners to understand knowledge concepts in the MOOC platform CourseMapper.\nSpecifically, we implement (1) a PKG-based Question Generation method to\nrecommend personalized questions for learners in context, and (2) an\nEduKG-based Question Answering method that leverages the relationships between\nknowledge concepts in the EduKG to answer learner selected questions. To\nevaluate both methods, we conducted a study with 3 expert instructors on 3\ndifferent MOOCs in the MOOC platform CourseMapper. The results of the\nevaluation show the potential of Graph RAG to empower learners to understand\nnew knowledge concepts in a personalized learning experience.",
      "tldr_zh": "该研究针对 MOOCs 中学习者理解新知识概念的挑战（如师生互动不足和 Large Language Models (LLMs) 的 hallucination 问题），提出 Graph Retrieval-Augmented Generation (Graph RAG) 管道，利用 Educational Knowledge Graphs (EduKGs) 和 Personal Knowledge Graphs (PKGs) 提供个性化学习支持。框架具体包括基于 PKG 的问题生成方法，以推荐上下文相关的个性化问题，以及基于 EduKG 的问题回答方法，利用知识概念间的关系来回答学习者选定的问题。在 CourseMapper 平台上进行的实验，涉及3门 MOOCs 和3位专家指导员，结果表明 Graph RAG 有潜力提升学习者的个性化体验和知识理解。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at EMOOCs 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10074v1",
      "published_date": "2025-05-15 08:24:47 UTC",
      "updated_date": "2025-05-15 08:24:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:47.717282"
    },
    {
      "arxiv_id": "2505.10073v1",
      "title": "Multi-Robot Task Allocation for Homogeneous Tasks with Collision Avoidance via Spatial Clustering",
      "title_zh": "通过空间聚类实现同质任务的多机器人任务分配及碰撞避免",
      "authors": [
        "Rathin Chandra Shit",
        "Sharmila Subudhi"
      ],
      "abstract": "In this paper, a novel framework is presented that achieves a combined\nsolution based on Multi-Robot Task Allocation (MRTA) and collision avoidance\nwith respect to homogeneous measurement tasks taking place in industrial\nenvironments. The spatial clustering we propose offers to simultaneously solve\nthe task allocation problem and deal with collision risks by cutting the\nworkspace into distinguishable operational zones for each robot. To divide task\nsites and to schedule robot routes within corresponding clusters, we use\nK-means clustering and the 2-Opt algorithm. The presented framework shows\nsatisfactory performance, where up to 93\\% time reduction (1.24s against\n17.62s) with a solution quality improvement of up to 7\\% compared to the best\nperforming method is demonstrated. Our method also completely eliminates\ncollision points that persist in comparative methods in a most significant\nsense. Theoretical analysis agrees with the claim that spatial partitioning\nunifies the apparently disjoint tasks allocation and collision avoidance\nproblems under conditions of many identical tasks to be distributed over sparse\ngeographical areas. Ultimately, the findings in this work are of substantial\nimportance for real world applications where both computational efficiency and\noperation free from collisions is of paramount importance.",
      "tldr_zh": "本研究提出了一种新框架，用于处理同质测量任务的 Multi-Robot Task Allocation (MRTA) 和 collision avoidance 问题，通过 spatial clustering 将工业工作空间划分为不同的操作区域，从而同时解决任务分配和碰撞风险。框架采用 K-means clustering 分割任务站点，并使用 2-Opt algorithm 调度机器人路径，确保高效路由规划。实验结果显示，与最佳方法相比，该框架可将处理时间减少93%（从17.62秒降至1.24秒），解决方案质量提高7%，并完全消除碰撞点。理论分析进一步证明，spatial partitioning 在许多相同任务分布于稀疏区域时，能统一任务分配和碰撞避免问题，对计算效率和安全性的实际工业应用具有重大意义。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "5 pages, 4 figures, Scheduled for presentation at an upcoming\n  conference",
      "pdf_url": "http://arxiv.org/pdf/2505.10073v1",
      "published_date": "2025-05-15 08:20:57 UTC",
      "updated_date": "2025-05-15 08:20:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:49.734482"
    },
    {
      "arxiv_id": "2505.10066v1",
      "title": "Dark LLMs: The Growing Threat of Unaligned AI Models",
      "title_zh": "Dark LLMs：非对齐 AI 模型的日益增长威胁",
      "authors": [
        "Michael Fire",
        "Yitzhak Elbazis",
        "Adi Wasenstein",
        "Lior Rokach"
      ],
      "abstract": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated.",
      "tldr_zh": "本研究探讨了大语言模型 (LLMs) 面临的日益严重威胁，即易受 jailbreak 攻击影响，导致模型生成有害输出。研究者识别了“dark LLMs”——这些模型故意缺乏伦理约束，或通过修改训练数据引入弱点，并开发了一个通用 jailbreak 攻击，成功入侵多种先进模型，使其响应几乎任何问题。实验结果显示，尽管攻击方法7个月前公开，许多LLMs仍未得到有效修复，凸显了行业在AI安全方面的不足，并警告随着模型训练变得更易访问，这种风险将进一步加剧，需要紧急干预以防止LLMs扩散危险知识。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "68T50, 68T05, 68P25",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10066v1",
      "published_date": "2025-05-15 08:07:04 UTC",
      "updated_date": "2025-05-15 08:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:49.699378"
    },
    {
      "arxiv_id": "2505.10055v1",
      "title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language",
      "title_zh": "PsOCR：在低资源普什图语光学字符识别中的大型多模态模型基准测试",
      "authors": [
        "Ijazul Haq",
        "Yingjie Zhang",
        "Irfan Ali Khan"
      ],
      "abstract": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR.",
      "tldr_zh": "本研究评估了大型多模态模型 (LMMs) 在低资源语言 Pashto 的光学字符识别 (OCR) 任务中的性能，以应对其脚本连写和数据集稀缺的挑战。研究团队开发了合成数据集 PsOCR，包含一百万图像，标注了单词、行和文档级别的边界框，并覆盖1000种字体、颜色和布局，用于训练和评估基于 Convolutional Neural Networks (CNNs) 和 Transformers 的模型。实验使用一个10K图像的基准子集测试了七个开源模型（如DeepSeek's Janus和Qwen-7B）和四个闭源模型（如GPT-4o和Gemini），结果显示Gemini整体表现最佳，而Qwen-7B在开源模型中领先。该工作揭示了当前LMMs在Pashto OCR的优缺点，并为类似脚本（如Arabic、Persian和Urdu）的进一步研究奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10055v1",
      "published_date": "2025-05-15 07:58:38 UTC",
      "updated_date": "2025-05-15 07:58:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:53.732700"
    },
    {
      "arxiv_id": "2505.10050v1",
      "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods",
      "title_zh": "使用可解释 AI 和堆叠集成方法的金融欺诈检测",
      "authors": [
        "Fahad Almalki",
        "Mehedi Masud"
      ],
      "abstract": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection.",
      "tldr_zh": "本研究针对传统机器学习模型在金融欺诈检测中缺乏透明度和可解释性的问题，提出了一种结合 stacking ensemble 方法的框架，使用 XGBoost、LightGBM 和 CatBoost 作为基模型，以提升预测准确性。框架还整合了 Explainable AI (XAI) 技术，包括 SHAP 用于特征选择，以及 LIME、Partial Dependence Plots (PDP) 和 Permutation Feature Importance (PFI) 来解释模型决策。在 IEEE-CIS 欺诈检测数据集上，该模型实现了99%的准确率和0.99的 AUC-ROC 得分，优于现有方法，证明了高性能与透明度相结合的可行性，从而促进更可信和合规的金融欺诈检测解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10050v1",
      "published_date": "2025-05-15 07:53:02 UTC",
      "updated_date": "2025-05-15 07:53:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:54.909937"
    },
    {
      "arxiv_id": "2505.10043v1",
      "title": "Boosting Text-to-Chart Retrieval through Training with Synthesized Semantic Insights",
      "title_zh": "通过使用合成的语义洞见训练提升文本到图表检索",
      "authors": [
        "Yifan Wu",
        "Lutao Yan",
        "Yizhang Zhu",
        "Yinan Mei",
        "Jiannan Wang",
        "Nan Tang",
        "Yuyu Luo"
      ],
      "abstract": "Charts are crucial for data analysis and decision-making.Text-to-chart\nretrieval systems have become increasingly important for Business Intelligence\n(BI), where users need to find relevant charts that match their analytical\nneeds. These needs can be categorized into precise queries that are\nwell-specified and fuzzy queries that are more exploratory -- both require\nunderstanding the semantics and context of the charts. However, existing\ntext-to-chart retrieval solutions often fail to capture the semantic content\nand contextual information of charts, primarily due to the lack of\ncomprehensive metadata (or semantic insights). To address this limitation, we\npropose a training data development pipeline that automatically synthesizes\nhierarchical semantic insights for charts, covering visual patterns\n(visual-oriented), statistical properties (statistics-oriented), and practical\napplications (task-oriented), which produces 207,498 semantic insights for\n69,166 charts. Based on these, we train a CLIP-based model named ChartFinder to\nlearn better representations of charts for text-to-chart retrieval. Our method\nleverages rich semantic insights during the training phase to develop a model\nthat understands both visual and semantic aspects of charts.To evaluate\ntext-to-chart retrieval performance, we curate the first benchmark, CRBench,\nfor this task with 21,862 charts and 326 text queries from real-world BI\napplications, with ground-truth labels verified by the crowd\nworkers.Experiments show that ChartFinder significantly outperforms existing\nmethods in text-to-chart retrieval tasks across various settings. For precise\nqueries, ChartFinder achieves up to 66.9% NDCG@10, which is 11.58% higher than\nstate-of-the-art models. In fuzzy query tasks, our method also demonstrates\nconsistent improvements, with an average increase of 5% across nearly all\nmetrics.",
      "tldr_zh": "本研究针对文本到图表检索系统在商业智能（BI）中的不足，提出一个自动合成图表层次化语义洞见的训练数据管道，该管道涵盖视觉模式（visual-oriented）、统计属性（statistics-oriented）和实际应用（task-oriented），从而为69,166个图表生成了207,498个语义洞见。基于这些洞见，训练了CLIP-based模型ChartFinder，以更好地捕捉图表的视觉和语义表示，提升对精确查询和模糊查询的检索性能。为评估效果，研究团队构建了首个基准测试CRBench，包含21,862个图表和326个真实世界查询。实验结果显示，ChartFinder在精确查询中NDCG@10达到66.9%，比最先进模型高11.58%；在模糊查询中平均提升5%，证明了方法的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10043v1",
      "published_date": "2025-05-15 07:41:14 UTC",
      "updated_date": "2025-05-15 07:41:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:59.183766"
    },
    {
      "arxiv_id": "2505.10037v1",
      "title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction",
      "title_zh": "用于抗癌药物反应预测的量子-经典混合模型的最优归一化",
      "authors": [
        "Takafumi Ito",
        "Lysenko Artem",
        "Tatsuhiko Tsunoda"
      ],
      "abstract": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers.",
      "tldr_zh": "该研究探讨了量子-经典混合机器学习 (QHML) 模型在癌症药物响应预测中的优势，这些模型在小数据集上表现出鲁棒性和高泛化能力，但对数据编码敏感，可能导致稳定性问题。为解决此问题，研究提出了一种新型归一化策略，使用基于 moderated gradient 的 $\\tanh$ 函数来转换神经网络输出，避免值集中在极端范围。在癌症细胞系的基因表达和药物响应数据集上实验验证显示，优化归一化后的 QHML 模型比经典深度学习模型预测性能更佳，为量子计算机在生物医学数据分析中的应用开辟了新可能性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10037v1",
      "published_date": "2025-05-15 07:33:41 UTC",
      "updated_date": "2025-05-15 07:33:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:52:59.995540"
    },
    {
      "arxiv_id": "2505.10034v1",
      "title": "The First MPDD Challenge: Multimodal Personality-aware Depression Detection",
      "title_zh": "首个 MPDD 挑战：多模态个性感知抑郁检测",
      "authors": [
        "Changzeng Fu",
        "Zelin Fu",
        "Xinhe Kuang",
        "Jiacheng Dong",
        "Qi Zhang",
        "Kaifeng Su",
        "Yikai Su",
        "Wenbo Shi",
        "Junfeng Yao",
        "Yuliang Zhao",
        "Shiqi Zhao",
        "Jiadong Wang",
        "Siyang Song",
        "Chaoran Liu",
        "Yuichiro Yoshikawa",
        "Björn Schuller",
        "Hiroshi Ishiguro"
      ],
      "abstract": "Depression is a widespread mental health issue affecting diverse age groups,\nwith notable prevalence among college students and the elderly. However,\nexisting datasets and detection methods primarily focus on young adults,\nneglecting the broader age spectrum and individual differences that influence\ndepression manifestation. Current approaches often establish a direct mapping\nbetween multimodal data and depression indicators, failing to capture the\ncomplexity and diversity of depression across individuals. This challenge\nincludes two tracks based on age-specific subsets: Track 1 uses the\nMPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses\nthe MPDD-Young dataset for detecting depression in younger participants. The\nMultimodal Personality-aware Depression Detection (MPDD) Challenge aims to\naddress this gap by incorporating multimodal data alongside individual\ndifference factors. We provide a baseline model that fuses audio and video\nmodalities with individual difference information to detect depression\nmanifestations in diverse populations. This challenge aims to promote the\ndevelopment of more personalized and accurate de pression detection methods,\nadvancing mental health research and fostering inclusive detection systems.\nMore details are available on the official challenge website:\nhttps://hacilab.github.io/MPDDChallenge.github.io.",
      "tldr_zh": "本论文介绍了首个 Multimodal Personality-aware Depression Detection (MPDD) 挑战，旨在解决现有抑郁检测方法忽略年龄多样性和个人差异的问题，这些方法通常直接映射多模态数据到抑郁指标，却未能捕捉抑郁表现的复杂性。挑战分为两个轨道：Track 1 使用 MPDD-Elderly 数据集针对老年人进行检测，Track 2 使用 MPDD-Young 数据集针对年轻人。研究提供了一个基线模型，通过融合音频、视频模态与个人差异信息，提升抑郁检测的准确性和个性化，从而推动更具包容性的心理健康研究和系统发展。",
      "categories": [
        "cs.AI",
        "68T07",
        "I.2.0; H.5.1"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted as part of the MPDD Challenge in the\n  ACMMM 2025 Grand Challenge",
      "pdf_url": "http://arxiv.org/pdf/2505.10034v1",
      "published_date": "2025-05-15 07:29:33 UTC",
      "updated_date": "2025-05-15 07:29:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:07.683990"
    },
    {
      "arxiv_id": "2505.10027v1",
      "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction",
      "title_zh": "ORL-LDM：离线强化学习引导的潜在扩散模型超分辨率重建",
      "authors": [
        "Shijie Lyu"
      ],
      "abstract": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes.",
      "tldr_zh": "本文提出ORL-LDM方法，利用离线强化学习指导潜在扩散模型(Latent Diffusion Model)对遥感图像进行超分辨率重建，以解决现有深度学习方法在处理复杂场景和保留细节方面的局限性。该方法构建强化学习环境，包括状态、动作和奖励，通过近端策略优化(PPO)优化LDM的逆去噪过程，从而提升重建质量。在RESISC45数据集上的实验显示，与基线模型相比，PSNR提高了3-4dB，SSIM提高了0.08-0.11，LPIPS降低了0.06-0.10，尤其在结构化和复杂自然场景中表现优异，结果验证了该方法的有效性和适应性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the 4th International Conference on Computing Innovation\n  and Applied Physics (CONF-CIAP 2025), and will be published in EAI Community\n  Research Series-CORE or Theoretical and Natural Science (TNS)",
      "pdf_url": "http://arxiv.org/pdf/2505.10027v1",
      "published_date": "2025-05-15 07:17:03 UTC",
      "updated_date": "2025-05-15 07:17:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:10.493260"
    },
    {
      "arxiv_id": "2505.10016v1",
      "title": "Application of YOLOv8 in monocular downward multiple Car Target detection",
      "title_zh": "YOLOv8在单目向下多汽车目标检测中的应用",
      "authors": [
        "Shijie Lyu"
      ],
      "abstract": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection.",
      "tldr_zh": "该论文探讨了自动驾驶系统中物体检测的挑战，如高成本和受天气影响的问题，并提出了一种基于 YOLOv8 的改进目标检测网络。改进方法整合了 structural reparameterization 技术、bidirectional pyramid structure network 以及新型检测管道，以实现对多尺度、小型和远程物体的高效精确检测。实验结果显示，该模型的检测准确率达到65%，优于传统方法，并在实际应用中表现出色，尤其适用于自动驾驶竞赛如 Formula Student Autonomous China (FSAC)。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.8; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the 5th International Conference on Signal Processing and\n  Machine Learning (CONF-SPML 2025), to appear in Applied and Computational\n  Engineering",
      "pdf_url": "http://arxiv.org/pdf/2505.10016v1",
      "published_date": "2025-05-15 06:58:45 UTC",
      "updated_date": "2025-05-15 06:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:12.156699"
    },
    {
      "arxiv_id": "2505.10012v1",
      "title": "Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering",
      "title_zh": "量子计算和 AI：科学和工程中高级自动化的视角",
      "authors": [
        "Tadashi Kadowaki"
      ],
      "abstract": "Recent advances in artificial intelligence (AI) and quantum computing are\naccelerating automation in scientific and engineering processes, fundamentally\nreshaping research methodologies. This perspective highlights parallels between\nscientific automation and established Computer-Aided Engineering (CAE)\npractices, introducing Quantum CAE as a framework that leverages quantum\nalgorithms for simulation, optimization, and machine learning within\nengineering design. Practical implementations of Quantum CAE are illustrated\nthrough case studies for combinatorial optimization problems. Further\ndiscussions include advancements toward higher automation levels, highlighting\nthe critical role of specialized AI agents proficient in quantum algorithm\ndesign. The integration of quantum computing with AI raises significant\nquestions about the collaborative dynamics among human scientists and\nengineers, AI systems, and quantum computational resources, underscoring a\ntransformative future for automated discovery and innovation.",
      "tldr_zh": "该论文探讨了人工智能 (AI) 和量子计算如何加速科学和工程领域的自动化，强调其与传统 Computer-Aided Engineering (CAE) 实践的平行关系。作者引入 Quantum CAE 框架，利用量子算法进行模拟、优化和机器学习，以提升工程设计效率。案例研究展示了该框架在组合优化问题上的实际应用，并突出了专业 AI 代理在量子算法设计中的关键作用。最终，论文讨论了人类科学家、AI 系统和量子计算资源之间的协作动态，预示着自动化发现和创新的变革性未来。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10012v1",
      "published_date": "2025-05-15 06:53:30 UTC",
      "updated_date": "2025-05-15 06:53:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:13.727479"
    },
    {
      "arxiv_id": "2505.09989v1",
      "title": "AI Greenferencing: Routing AI Inferencing to Green Modular Data Centers with Heron",
      "title_zh": "AI 绿色推理：利用 Heron 将 AI 推理路由到绿色模块化数据中心",
      "authors": [
        "Tella Rajashekhar Reddy",
        "Palak",
        "Rohan Gandhi",
        "Anjaly Parayil",
        "Chaojie Zhang",
        "Mike Shepperd",
        "Liangcheng Yu",
        "Jayashree Mohan",
        "Srinivasan Iyengar",
        "Shivkumar Kalyanaraman",
        "Debopam Bhattacherjee"
      ],
      "abstract": "AI power demand is growing unprecedentedly thanks to the high power density\nof AI compute and the emerging inferencing workload. On the supply side,\nabundant wind power is waiting for grid access in interconnection queues. In\nthis light, this paper argues bringing AI workload to modular compute clusters\nco-located in wind farms. Our deployment right-sizing strategy makes it\neconomically viable to deploy more than 6 million high-end GPUs today that\ncould consume cheap, green power at its source. We built Heron, a cross-site\nsoftware router, that could efficiently leverage the complementarity of power\ngeneration across wind farms by routing AI inferencing workload around power\ndrops. Using 1-week ofcoding and conversation production traces from Azure and\n(real) variable wind power traces, we show how Heron improves aggregate goodput\nof AI compute by up to 80% compared to the state-of-the-art.",
      "tldr_zh": "该论文讨论了AI推理工作负载的电力需求急剧增长问题，并提出将AI计算路由到风电场附近的模块化数据中心，以利用廉价的绿色电力。研究者开发了Heron，一种跨站点软件路由器，通过动态路由AI inferencing工作负载来利用风电场间电力生成的互补性，应对电力波动。实验基于Azure的生产跟踪和真实风力数据表明，Heron相较于现有技术可将AI计算的aggregate goodput提高高达80%，并证明部署超过600万高端GPU的经济可行性。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09989v1",
      "published_date": "2025-05-15 06:03:47 UTC",
      "updated_date": "2025-05-15 06:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:15.887947"
    },
    {
      "arxiv_id": "2505.09974v1",
      "title": "Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data",
      "title_zh": "分析使用伪恶意网络安全数据微调的LLMs中的安全风险",
      "authors": [
        "Adel ElZemity",
        "Budi Arief",
        "Shujun Li"
      ],
      "abstract": "The integration of large language models (LLMs) into cyber security\napplications presents significant opportunities, such as enhancing threat\nanalysis and malware detection, but can also introduce critical risks and\nsafety concerns, including personal data leakage and automated generation of\nnew malware. We present a systematic evaluation of safety risks in fine-tuned\nLLMs for cyber security applications. Using the OWASP Top 10 for LLM\nApplications framework, we assessed seven open-source LLMs: Phi 3 Mini 3.8B,\nMistral 7B, Qwen 2.5 7B, Llama 3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B.\nOur evaluation shows that fine-tuning reduces safety resilience across all\ntested LLMs (e.g., the safety score of Llama 3.1 8B against prompt injection\ndrops from 0.95 to 0.15). We propose and evaluate a safety alignment approach\nthat carefully rewords instruction-response pairs to include explicit safety\nprecautions and ethical considerations. This approach demonstrates that it is\npossible to maintain or even improve model safety while preserving technical\nutility, offering a practical path forward for developing safer fine-tuning\nmethodologies. This work offers a systematic evaluation for safety risks in\nLLMs, enabling safer adoption of generative AI in sensitive domains, and\ncontributing towards the development of secure, trustworthy, and ethically\naligned LLMs.",
      "tldr_zh": "这篇论文分析了使用伪恶意网络安全数据微调大型语言模型（LLMs）时可能引入的安全风险，包括个人数据泄露和自动生成新恶意软件。研究者通过OWASP Top 10 for LLM Applications框架评估了七个开源LLMs（如Llama 3.1 8B），发现微调后模型的安全性显著降低，例如Llama 3.1 8B对prompt injection的safety score从0.95降至0.15。论文提出一种安全对齐方法，通过重新表述指令-响应对以包含明确的safety precautions和ethical considerations，实现了模型安全性的维持或提升，同时保留了技术实用性。该工作为在敏感领域安全采用生成AI提供了系统评估路径，促进开发更可信赖和道德对齐的LLMs。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09974v1",
      "published_date": "2025-05-15 05:22:53 UTC",
      "updated_date": "2025-05-15 05:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:19.223518"
    },
    {
      "arxiv_id": "2505.09970v1",
      "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents",
      "title_zh": "Pre-Act：多步骤规划和推理改善大型语言模型代理的行为",
      "authors": [
        "Mrinal Rawat",
        "Ambuje Gupta",
        "Rushil Goomer",
        "Alessandro Di Bari",
        "Neha Gupta",
        "Roberto Pieraccini"
      ],
      "abstract": "The ReAct (Reasoning + Action) capability in large language models (LLMs) has\nbecome the foundation of modern agentic systems. Recent LLMs, such as\nDeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through\nthe generation of ample intermediate tokens, which help build a strong premise\nbefore producing the final output tokens. In this paper, we introduce Pre-Act,\na novel approach that enhances the agent's performance by creating a multi-step\nexecution plan along with the detailed reasoning for the given user input. This\nplan incrementally incorporates previous steps and tool outputs, refining\nitself after each step execution until the final response is obtained. Our\napproach is applicable to both conversational and non-conversational agents. To\nmeasure the performance of task-oriented agents comprehensively, we propose a\ntwo-level evaluation framework: (1) turn level and (2) end-to-end. Our\nturn-level evaluation, averaged across five models, shows that our approach,\nPre-Act, outperforms ReAct by 70% in Action Recall on the Almita dataset. While\nthis approach is effective for larger models, smaller models crucial for\npractical applications, where latency and cost are key constraints, often\nstruggle with complex reasoning tasks required for agentic systems. To address\nthis limitation, we fine-tune relatively small models such as Llama 3.1 (8B &\n70B) using the proposed Pre-Act approach. Our experiments show that the\nfine-tuned 70B model outperforms GPT-4, achieving a 69.5% improvement in action\naccuracy (turn-level) and a 28% improvement in goal completion rate\n(end-to-end) on the Almita (out-of-domain) dataset.",
      "tldr_zh": "本文提出 Pre-Act 方法，通过多步规划和推理来提升大型语言模型 (LLMs) 代理的性能，特别是针对 ReAct 框架的改进。Pre-Act 为用户输入生成详细的执行计划，并逐步整合先前步骤和工具输出，直至得出最终响应，适用于对话和非对话代理。为全面评估任务导向代理，论文引入两级评估框架（turn level 和 end-to-end）。实验结果显示，Pre-Act 在 Almita 数据集上比 ReAct 在 Action Recall 上提升 70%，且通过 fine-tune 较小模型如 Llama 3.1 70B，其行动准确率和目标完成率分别较 GPT-4 提高了 69.5% 和 28%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09970v1",
      "published_date": "2025-05-15 05:17:47 UTC",
      "updated_date": "2025-05-15 05:17:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:21.235580"
    },
    {
      "arxiv_id": "2505.09969v1",
      "title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives",
      "title_zh": "心脏病预测的全面机器学习框架：性能评估和未来展望",
      "authors": [
        "Ali Azimi Lamir",
        "Shiva Razzagzadeh",
        "Zeynab Rezaei"
      ],
      "abstract": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics.",
      "tldr_zh": "本研究提出一个全面的机器学习框架，用于心脏病预测，基于包含303个样本和14个特征的心脏病数据集。方法包括数据预处理、训练Logistic Regression、K-Nearest Neighbors (KNN)和Random Forest分类器，并通过GridSearchCV和RandomizedSearchCV进行超参数调优。Random Forest分类器表现出色，达到91%的准确率和0.89的F1-score，并在精确率、召回率和混淆矩阵等指标上显示均衡性能。该框架有助于临床决策，但受限于数据集规模和泛化性，未来应使用更大、更多样化的数据集进行改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09969v1",
      "published_date": "2025-05-15 05:13:38 UTC",
      "updated_date": "2025-05-15 05:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:22.457598"
    },
    {
      "arxiv_id": "2505.09955v1",
      "title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation",
      "title_zh": "TransPL：用于时间序列无监督领域自适应的 VQ 代码转移矩阵伪标签生成",
      "authors": [
        "Jaeho Kim",
        "Seulki Lee"
      ],
      "abstract": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices.",
      "tldr_zh": "该研究提出TransPL，一种用于时间序列无监督域适应(Unsupervised Domain Adaptation, UDA)的创新方法，通过向量量化(Vector Quantization, VQ)对时间序列补丁进行编码，构建类级和通道级的代码转换矩阵，以更好地捕捉时间模式和通道偏移。TransPL利用Bayes规则从源域矩阵生成目标域的伪标签，基于通道加权的类条件似然，提高伪标签的准确性和可解释性。该方法适用于多种UDA场景，包括弱监督UDA，并在四个时间序列UDA基准上验证，相比现有伪标签方法平均提高6.1%准确率和4.9%F1分数，并通过学得的代码转换矩阵提供可解释的域适应洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025 Accept",
      "pdf_url": "http://arxiv.org/pdf/2505.09955v1",
      "published_date": "2025-05-15 04:27:48 UTC",
      "updated_date": "2025-05-15 04:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:25.351394"
    },
    {
      "arxiv_id": "2505.09952v1",
      "title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning",
      "title_zh": "针对长期持续学习的任务核心记忆管理和巩固机制",
      "authors": [
        "Tianyu Huai",
        "Jie Zhou",
        "Yuxuan Cai",
        "Qin Chen",
        "Wen Wu",
        "Xingjiao Wu",
        "Xipeng Qiu",
        "Liang He"
      ],
      "abstract": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach.",
      "tldr_zh": "这篇论文针对长期持续学习(long-term continual learning)问题，探讨了模型在处理大量顺序任务时如何缓解灾难性遗忘(catastrophic forgetting)，并提出了一种受人类记忆机制启发的框架Long-CL。该框架包括任务核心记忆管理策略，用于高效索引和适应性更新关键记忆，以及长期记忆巩固机制，选择性地保留困难和鉴别性样本，以确保知识保留。为促进研究，他们构建并发布了多模态基准MMLongCL-Bench和文本基准TextLongCL-Bench。实验结果显示，Long-CL在两个基准上分别比现有最先进方法提高了7.4%和6.5%的AP，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to Neurips2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09952v1",
      "published_date": "2025-05-15 04:22:35 UTC",
      "updated_date": "2025-05-15 04:22:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:25.729605"
    },
    {
      "arxiv_id": "2505.09945v1",
      "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph",
      "title_zh": "利用检索增强生成和知识图谱个性化大型语言模型",
      "authors": [
        "Deeksha Prahlad",
        "Chanhee Lee",
        "Dongha Kim",
        "Hokeun Kim"
      ],
      "abstract": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time.",
      "tldr_zh": "该研究针对大语言模型（LLMs）因过度拟合而产生的幻觉问题，提出了一种个性化方法，通过检索增强生成（RAG）和知识图谱（KGs）来辅助LLMs生成及时、事实性和个性化的响应。方法利用KGs的结构化优势存储和更新个人数据，如日历信息，从而提升模型对用户特定信息的理解和准确性。实验结果显示，与仅使用文本输入的基线LLMs相比，该方法显著提高了响应准确性，同时响应时间仅适度增加。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)",
      "pdf_url": "http://arxiv.org/pdf/2505.09945v1",
      "published_date": "2025-05-15 04:01:58 UTC",
      "updated_date": "2025-05-15 04:01:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:33.028618"
    },
    {
      "arxiv_id": "2505.09935v1",
      "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety",
      "title_zh": "VRU-CIPI：交叉路口穿越意图预测以改善易受伤害道路使用者安全",
      "authors": [
        "Ahmed S. Abdelrahman",
        "Mohamed Abdel-Aty",
        "Quoc Dai Tran"
      ],
      "abstract": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users.",
      "tldr_zh": "本文提出 VRU-CIPI 框架，这是一个基于顺序注意力的模型，用于预测脆弱道路使用者 (VRUs) 在十字路口的过马路意图，从而提升道路交互安全。该框架结合 Gated Recurrent Unit (GRU) 捕获 VRUs 运动的时序动态，以及多头 Transformer 自注意力机制编码上下文和空间依赖。在 UCF-VRU 数据集上，VRU-CIPI 实现了 96.45% 的准确率和 33 帧/秒的实时推理速度。通过与 Infrastructure-to-Vehicles (I2V) 通信整合，该方法能主动激活过马路信号并向连接车辆发送早期警告，确保更顺畅和安全的道路环境。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09935v1",
      "published_date": "2025-05-15 03:40:29 UTC",
      "updated_date": "2025-05-15 03:40:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:36.931870"
    },
    {
      "arxiv_id": "2505.09932v1",
      "title": "Demystifying AI Agents: The Final Generation of Intelligence",
      "title_zh": "解密 AI 代理：智能的最终一代",
      "authors": [
        "Kevin J McNamara",
        "Rhea Pritham Marpu"
      ],
      "abstract": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence.",
      "tldr_zh": "这篇白皮书回顾了人工智能（AI）的发展历程，从基本的规则系统演进到先进的自主AI agents，能够进行复杂推理和互动。论文强调了关键技术里程碑，包括提示技术、训练方法、硬件能力和架构创新，这些共同推动了如OpenAI's ChatGPT with plugins和xAI's Grok等系统的出现，并认为这些代表了AI的“最终一代”智能。作者探讨了这些agents的能力及其社会影响，同时指出AI进步的速度已加快到每六个月翻倍，并呼吁在应对机遇和挑战时需要智慧和远见。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09932v1",
      "published_date": "2025-05-15 03:35:12 UTC",
      "updated_date": "2025-05-15 03:35:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:36.902546"
    },
    {
      "arxiv_id": "2505.09926v1",
      "title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection",
      "title_zh": "AdaptCLIP：将 CLIP 适应用于通用视觉异常检测",
      "authors": [
        "Bin-Bin Gao",
        "Yue Zhu",
        "Jiangtao Yan",
        "Yuezhi Cai",
        "Weixi Zhang",
        "Meng Wang",
        "Jun Liu",
        "Yong Liu",
        "Lei Wang",
        "Chengjie Wang"
      ],
      "abstract": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP.",
      "tldr_zh": "本研究提出AdaptCLIP，一种简单有效的框架，用于适应CLIP模型实现通用视觉异常检测，无需额外微调，从而解决现有方法在提示模板设计和标记交互上的局限性。AdaptCLIP基于两个关键洞见：视觉和文本表示应交替学习，以及查询与正常图像提示的比较学习需结合上下文和对齐的残差特征；它通过添加视觉适配器、文本适配器和提示查询适配器来增强CLIP的表现，支持零/少样本跨域泛化。实验结果显示，AdaptCLIP在12个工业和医疗领域的异常检测基准上取得最先进性能，大幅超越竞争方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "27 pages, 15 figures, 22 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.09926v1",
      "published_date": "2025-05-15 03:24:28 UTC",
      "updated_date": "2025-05-15 03:24:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:39.377127"
    },
    {
      "arxiv_id": "2505.09925v1",
      "title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback",
      "title_zh": "基于实时嘈杂人类反馈的强化交互持续学习",
      "authors": [
        "Yutao Yang",
        "Jie Zhou",
        "Junsong Li",
        "Qianjun Pan",
        "Bihao Zhan",
        "Qin Chen",
        "Xipeng Qiu",
        "Liang He"
      ],
      "abstract": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods.",
      "tldr_zh": "这篇论文提出了一种交互式持续学习范式，允许 AI 模型通过实时人类反馈动态学习新技能，同时保留先前知识，并解决传统持续学习中静态数据集和噪声标签的问题。作者引入了 RiCL 框架，利用 Large Language Models (LLMs)，包括 temporal consistency-aware purifier 来区分噪声样本、interaction-aware direct preference optimization 来对齐模型行为与人类意图、以及 noise-resistant contrastive learning 来捕获鲁棒表示，从而减少对不可靠标签的依赖。在 FewRel 和 TACRED 数据集上的实验显示，RiCL 显著优于现有在线持续学习和噪声标签学习方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09925v1",
      "published_date": "2025-05-15 03:22:03 UTC",
      "updated_date": "2025-05-15 03:22:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:42.174154"
    },
    {
      "arxiv_id": "2505.09923v1",
      "title": "\"There Is No Such Thing as a Dumb Question,\" But There Are Good Ones",
      "title_zh": "“世上不存在愚蠢的问题”，但有些是好的",
      "authors": [
        "Minjung Shin",
        "Donghyun Kim",
        "Jeh-Kwang Ryu"
      ],
      "abstract": "Questioning has become increasingly crucial for both humans and artificial\nintelligence, yet there remains limited research comprehensively assessing\nquestion quality. In response, this study defines good questions and presents a\nsystematic evaluation framework. We propose two key evaluation dimensions:\nappropriateness (sociolinguistic competence in context) and effectiveness\n(strategic competence in goal achievement). Based on these foundational\ndimensions, a rubric-based scoring system was developed. By incorporating\ndynamic contextual variables, our evaluation framework achieves structure and\nflexibility through semi-adaptive criteria. The methodology was validated using\nthe CAUS and SQUARE datasets, demonstrating the ability of the framework to\naccess both well-formed and problematic questions while adapting to varied\ncontexts. As we establish a flexible and comprehensive framework for question\nevaluation, this study takes a significant step toward integrating questioning\nbehavior with structured analytical methods grounded in the intrinsic nature of\nquestioning.",
      "tldr_zh": "本研究强调质疑（questioning）对人类和人工智能的重要性，但指出现有评估问题质量的研究不足，因此提出一个系统性的评估框架来定义“好问题”。框架基于两个关键维度：appropriateness（语境中的社会语言能力）和effectiveness（目标实现中的战略能力），并开发了rubric-based scoring system，通过semi-adaptive criteria整合动态语境变量，实现评估的结构与灵活性。使用CAUS和SQUARE数据集进行验证，框架成功评估了良好和有问题的问句，并适应不同语境。该研究为将质疑行为与结构化分析方法整合奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures and 4 tables. This work has been accepted for\n  presentation as a poster with full paper publication at CogSci 2025. This is\n  the final submission",
      "pdf_url": "http://arxiv.org/pdf/2505.09923v1",
      "published_date": "2025-05-15 03:12:28 UTC",
      "updated_date": "2025-05-15 03:12:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:43.801401"
    },
    {
      "arxiv_id": "2505.09920v1",
      "title": "Offline Reinforcement Learning for Microgrid Voltage Regulation",
      "title_zh": "离线强化学习用于微电网电压调节",
      "authors": [
        "Shan Yang",
        "Yongli Zhu"
      ],
      "abstract": "This paper presents a study on using different offline reinforcement learning\nalgorithms for microgrid voltage regulation with solar power penetration. When\nenvironment interaction is unviable due to technical or safety reasons, the\nproposed approach can still obtain an applicable model through offline-style\ntraining on a previously collected dataset, lowering the negative impact of\nlacking online environment interactions. Experiment results on the IEEE 33-bus\nsystem demonstrate the feasibility and effectiveness of the proposed approach\non different offline datasets, including the one with merely low-quality\nexperience.",
      "tldr_zh": "本研究探讨了使用离线强化学习（offline reinforcement learning）算法来调节带有太阳能渗透的微电网电压问题。通过在预先收集的数据集上进行离线训练，该方法避免了在线环境交互的潜在技术或安全风险，从而获得可应用的模型。实验结果在IEEE 33-bus系统上验证了该方法的有效性，即使在仅包含低质量经验的数据集上也能表现出色，为微电网电压调节提供了可靠的替代方案。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09920v1",
      "published_date": "2025-05-15 03:10:18 UTC",
      "updated_date": "2025-05-15 03:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:43.920474"
    },
    {
      "arxiv_id": "2505.09907v1",
      "title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture",
      "title_zh": "使用混合深度学习模型的鳄梨价格预测：TCN-MLP-Attention 架构",
      "authors": [
        "Linwei Zhang",
        "LuFeng",
        "Ruijia Liang"
      ],
      "abstract": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization.",
      "tldr_zh": "本研究针对鳄梨价格的复杂波动（如季节、地域和天气影响），提出了一种混合深度学习模型TCN-MLP-Attention Architecture，结合Temporal Convolutional Networks (TCN)用于序列特征提取、Multi-Layer Perceptrons (MLP)处理非线性交互，以及Attention机制进行动态特征加权。数据集包括2015-2018年超过50,000条美国Hass鳄梨销售记录，经过缺失值填充和特征归一化等预处理后，该模型在实验中表现出色，RMSE为1.23和MSE为1.51，优于传统方法。该方法为农业市场的时间序列预测提供可扩展的框架，并为智能供应链管理和价格策略优化带来宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09907v1",
      "published_date": "2025-05-15 02:26:22 UTC",
      "updated_date": "2025-05-15 02:26:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:49.693614"
    },
    {
      "arxiv_id": "2505.09901v1",
      "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks",
      "title_zh": "比较 LLMs 与人类的探索-利用策略：来自标准多臂老虎机任务的洞见",
      "authors": [
        "Ziyuan Zhang",
        "Darcy Wang",
        "Ningyuan Chen",
        "Rodrigo Mansur",
        "Vahid Sarhangian"
      ],
      "abstract": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements.",
      "tldr_zh": "这篇论文比较了大型语言模型 (LLMs) 和人类的探索-利用 (E&E) 策略，通过标准多臂老虎机 (MAB) 任务进行分析。研究采用可解释的选择模型和推理提示方法，考察了如何使 LLMs 的决策更接近人类行为。结果显示，启用推理后，LLMs 在简单静态任务中表现出与人类相似的随机和定向探索，但在复杂非静态环境中，LLMs 难以匹配人类的适应性，尤其在有效定向探索方面，尽管后悔率在某些场景下类似。总体而言，该研究揭示了 LLMs 作为人类行为模拟器和决策工具的潜力与局限性，并指出了改进方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09901v1",
      "published_date": "2025-05-15 02:09:18 UTC",
      "updated_date": "2025-05-15 02:09:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:50.563614"
    },
    {
      "arxiv_id": "2505.09868v1",
      "title": "Which Demographic Features Are Relevant for Individual Fairness Evaluation of U.S. Recidivism Risk Assessment Tools?",
      "title_zh": "哪些人口统计特征对美国再犯风险评估工具的个体公平性评估是相关的？",
      "authors": [
        "Tin Trung Nguyen",
        "Jiannan Xu",
        "Phuong-Anh Nguyen-Le",
        "Jonathan Lazar",
        "Donald Braman",
        "Hal Daumé III",
        "Zubin Jelveh"
      ],
      "abstract": "Despite its U.S. constitutional foundation, the technical ``individual\nfairness'' criterion has not been operationalized in state or federal\nstatutes/regulations. We conduct a human subjects experiment to address this\ngap, evaluating which demographic features are relevant for individual fairness\nevaluation of recidivism risk assessment (RRA) tools. Our analyses conclude\nthat the individual similarity function should consider age and sex, but it\nshould ignore race.",
      "tldr_zh": "该研究探讨了在美国再犯风险评估 (RRA) 工具中，哪些人口统计特征对个体公平 (individual fairness) 评估最为相关，尽管这一标准源于美国宪法但尚未在法规中明确定义。通过人类实验，研究者发现个体相似性函数应考虑 age 和 sex 特征，但应忽略 race。最终结论为，这一方法有助于更精确地操作化个体公平性标准，减少潜在偏见。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09868v1",
      "published_date": "2025-05-15 00:07:07 UTC",
      "updated_date": "2025-05-15 00:07:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:53:54.589805"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 90,
  "processed_papers_count": 90,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T10:54:17.444211"
}