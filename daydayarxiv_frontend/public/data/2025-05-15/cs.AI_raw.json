[
  {
    "arxiv_id": "2505.10559v1",
    "title": "Neural Thermodynamic Laws for Large Language Model Training",
    "authors": [
      "Ziming Liu",
      "Yizhou Liu",
      "Jeff Gore",
      "Max Tegmark"
    ],
    "abstract": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.data-an",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.10559v1",
    "published_date": "2025-05-15 17:59:22 UTC",
    "updated_date": "2025-05-15 17:59:22 UTC"
  },
  {
    "arxiv_id": "2505.10557v1",
    "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning",
    "authors": [
      "Ke Wang",
      "Junting Pan",
      "Linda Wei",
      "Aojun Zhou",
      "Weikang Shi",
      "Zimu Lu",
      "Han Xiao",
      "Yunqiao Yang",
      "Houxing Ren",
      "Mingjie Zhan",
      "Hongsheng Li"
    ],
    "abstract": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2505.10557v1",
    "published_date": "2025-05-15 17:59:21 UTC",
    "updated_date": "2025-05-15 17:59:21 UTC"
  },
  {
    "arxiv_id": "2505.10551v1",
    "title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data",
    "authors": [
      "Yiwen Liu",
      "Jessica Bader",
      "Jae Myung Kim"
    ],
    "abstract": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPRW 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.10551v1",
    "published_date": "2025-05-15 17:57:38 UTC",
    "updated_date": "2025-05-15 17:57:38 UTC"
  },
  {
    "arxiv_id": "2505.10547v1",
    "title": "Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning",
    "authors": [
      "Milan Ganai",
      "Rohan Sinha",
      "Christopher Agia",
      "Daniel Morton",
      "Marco Pavone"
    ],
    "abstract": "Foundation models can provide robust high-level reasoning on appropriate\nsafety interventions in hazardous scenarios beyond a robot's training data,\ni.e. out-of-distribution (OOD) failures. However, due to the high inference\nlatency of Large Vision and Language Models, current methods rely on manually\ndefined intervention policies to enact fallbacks, thereby lacking the ability\nto plan generalizable, semantically safe motions. To overcome these challenges\nwe present FORTRESS, a framework that generates and reasons about semantically\nsafe fallback strategies in real time to prevent OOD failures. At a low\nfrequency in nominal operations, FORTRESS uses multi-modal reasoners to\nidentify goals and anticipate failure modes. When a runtime monitor triggers a\nfallback response, FORTRESS rapidly synthesizes plans to fallback goals while\ninferring and avoiding semantically unsafe regions in real time. By bridging\nopen-world, multi-modal reasoning with dynamics-aware planning, we eliminate\nthe need for hard-coded fallbacks and human safety interventions. FORTRESS\noutperforms on-the-fly prompting of slow reasoning models in safety\nclassification accuracy on synthetic benchmarks and real-world ANYmal robot\ndata, and further improves system safety and planning success in simulation and\non quadrotor hardware for urban navigation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Website: https://milanganai.github.io/fortress/",
    "pdf_url": "http://arxiv.org/pdf/2505.10547v1",
    "published_date": "2025-05-15 17:55:28 UTC",
    "updated_date": "2025-05-15 17:55:28 UTC"
  },
  {
    "arxiv_id": "2505.10543v1",
    "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models",
    "authors": [
      "Annie Wong",
      "Thomas BÃ¤ck",
      "Aske Plaat",
      "Niki van Stein",
      "Anna V. Kononova"
    ],
    "abstract": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10543v1",
    "published_date": "2025-05-15 17:53:47 UTC",
    "updated_date": "2025-05-15 17:53:47 UTC"
  },
  {
    "arxiv_id": "2505.10537v1",
    "title": "LibIQ: Toward Real-Time Spectrum Classification in O-RAN dApps",
    "authors": [
      "Filippo Olimpieri",
      "Noemi Giustini",
      "Andrea Lacava",
      "Salvatore D'Oro",
      "Tommaso Melodia",
      "Francesca Cuomo"
    ],
    "abstract": "The O-RAN architecture is transforming cellular networks by adopting RAN\nsoftwarization and disaggregation concepts to enable data-driven monitoring and\ncontrol of the network. Such management is enabled by RICs, which facilitate\nnear-real-time and non-real-time network control through xApps and rApps.\nHowever, they face limitations, including latency overhead in data exchange\nbetween the RAN and RIC, restricting real-time monitoring, and the inability to\naccess user plain data due to privacy and security constraints, hindering use\ncases like beamforming and spectrum classification. In this paper, we leverage\nthe dApps concept to enable real-time RF spectrum classification with LibIQ, a\nnovel library for RF signals that facilitates efficient spectrum monitoring and\nsignal classification by providing functionalities to read I/Q samples as\ntime-series, create datasets and visualize time-series data through plots and\nspectrograms. Thanks to LibIQ, I/Q samples can be efficiently processed to\ndetect external RF signals, which are subsequently classified using a CNN\ninside the library. To achieve accurate spectrum analysis, we created an\nextensive dataset of time-series-based I/Q samples, representing distinct\nsignal types captured using a custom dApp running on a 5G deployment over the\nColosseum network emulator and an OTA testbed. We evaluate our model by\ndeploying LibIQ in heterogeneous scenarios with varying center frequencies,\ntime windows, and external RF signals. In real-time analysis, the model\nclassifies the processed I/Q samples, achieving an average accuracy of\napproximately 97.8\\% in identifying signal types across all scenarios. We\npledge to release both LibIQ and the dataset created as a publicly available\nframework upon acceptance.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "6 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.10537v1",
    "published_date": "2025-05-15 17:47:30 UTC",
    "updated_date": "2025-05-15 17:47:30 UTC"
  },
  {
    "arxiv_id": "2505.10522v1",
    "title": "Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation",
    "authors": [
      "Xinrui Wang",
      "Yan Jin"
    ],
    "abstract": "Reinforcement learning (RL) has demonstrated remarkable potential in robotic\nmanipulation but faces challenges in sample inefficiency and lack of\ninterpretability, limiting its applicability in real world scenarios. Enabling\nthe agent to gain a deeper understanding and adapt more efficiently to diverse\nworking scenarios is crucial, and strategic knowledge utilization is a key\nfactor in this process. This paper proposes a Knowledge Capture, Adaptation,\nand Composition (KCAC) framework to systematically integrate knowledge transfer\ninto RL through cross-task curriculum learning. KCAC is evaluated using a two\nblock stacking task in the CausalWorld benchmark, a complex robotic\nmanipulation environment. To our knowledge, existing RL approaches fail to\nsolve this task effectively, reflecting deficiencies in knowledge capture. In\nthis work, we redesign the benchmark reward function by removing rigid\nconstraints and strict ordering, allowing the agent to maximize total rewards\nconcurrently and enabling flexible task completion. Furthermore, we define two\nself-designed sub-tasks and implement a structured cross-task curriculum to\nfacilitate efficient learning. As a result, our KCAC approach achieves a 40\npercent reduction in training time while improving task success rates by 10\npercent compared to traditional RL methods. Through extensive evaluation, we\nidentify key curriculum design parameters subtask selection, transition timing,\nand learning rate that optimize learning efficiency and provide conceptual\nguidance for curriculum based RL frameworks. This work offers valuable insights\ninto curriculum design in RL and robotic learning.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10522v1",
    "published_date": "2025-05-15 17:30:29 UTC",
    "updated_date": "2025-05-15 17:30:29 UTC"
  },
  {
    "arxiv_id": "2505.10518v1",
    "title": "Multi-Token Prediction Needs Registers",
    "authors": [
      "Anastasios Gerontopoulos",
      "Spyros Gidaris",
      "Nikos Komodakis"
    ],
    "abstract": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10518v1",
    "published_date": "2025-05-15 17:25:03 UTC",
    "updated_date": "2025-05-15 17:25:03 UTC"
  },
  {
    "arxiv_id": "2505.10515v1",
    "title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models",
    "authors": [
      "Seongun Kim",
      "Sol A Kim",
      "Geonhyeong Kim",
      "Enver Menadjiev",
      "Chanwoo Lee",
      "Seongwook Chung",
      "Nari Kim",
      "Jaesik Choi"
    ],
    "abstract": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10515v1",
    "published_date": "2025-05-15 17:21:54 UTC",
    "updated_date": "2025-05-15 17:21:54 UTC"
  },
  {
    "arxiv_id": "2505.10483v1",
    "title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation",
    "authors": [
      "Yi Li",
      "Haonan Wang",
      "Qixiang Zhang",
      "Boyu Xiao",
      "Chenchang Hu",
      "Hualiang Wang",
      "Xiaomeng Li"
    ],
    "abstract": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "UniEval is the first evaluation framework designed for unified\n  multimodal models, including a holistic benchmark UniBench and the UniScore\n  metric",
    "pdf_url": "http://arxiv.org/pdf/2505.10483v1",
    "published_date": "2025-05-15 16:34:50 UTC",
    "updated_date": "2025-05-15 16:34:50 UTC"
  },
  {
    "arxiv_id": "2505.10482v1",
    "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps",
    "authors": [
      "Ningyuan Yang",
      "Jiaxuan Gao",
      "Feng Gao",
      "Yi Wu",
      "Chao Yu"
    ],
    "abstract": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2505.10482v1",
    "published_date": "2025-05-15 16:33:44 UTC",
    "updated_date": "2025-05-15 16:33:44 UTC"
  },
  {
    "arxiv_id": "2505.10468v1",
    "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge",
    "authors": [
      "Ranjan Sapkota",
      "Konstantinos I. Roumeliotis",
      "Manoj Karkee"
    ],
    "abstract": "This study critically distinguishes between AI Agents and Agentic AI,\noffering a structured conceptual taxonomy, application mapping, and challenge\nanalysis to clarify their divergent design philosophies and capabilities. We\nbegin by outlining the search strategy and foundational definitions,\ncharacterizing AI Agents as modular systems driven by Large Language Models\n(LLMs) and Large Image Models (LIMs) for narrow, task-specific automation.\nGenerative AI is positioned as a precursor, with AI Agents advancing through\ntool integration, prompt engineering, and reasoning enhancements. In contrast,\nAgentic AI systems represent a paradigmatic shift marked by multi-agent\ncollaboration, dynamic task decomposition, persistent memory, and orchestrated\nautonomy. Through a sequential evaluation of architectural evolution,\noperational mechanisms, interaction styles, and autonomy levels, we present a\ncomparative analysis across both paradigms. Application domains such as\ncustomer support, scheduling, and data summarization are contrasted with\nAgentic AI deployments in research automation, robotic coordination, and\nmedical decision support. We further examine unique challenges in each paradigm\nincluding hallucination, brittleness, emergent behavior, and coordination\nfailure and propose targeted solutions such as ReAct loops, RAG, orchestration\nlayers, and causal modeling. This work aims to provide a definitive roadmap for\ndeveloping robust, scalable, and explainable AI agent and Agentic AI-driven\nsystems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision\nSupport System, Agentic-AI Applications",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "32 pages, 14 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.10468v1",
    "published_date": "2025-05-15 16:21:33 UTC",
    "updated_date": "2025-05-15 16:21:33 UTC"
  },
  {
    "arxiv_id": "2505.10465v1",
    "title": "Superposition Yields Robust Neural Scaling",
    "authors": [
      "Yizhou liu",
      "Ziming Liu",
      "Jeff Gore"
    ],
    "abstract": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 23 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.10465v1",
    "published_date": "2025-05-15 16:18:13 UTC",
    "updated_date": "2025-05-15 16:18:13 UTC"
  },
  {
    "arxiv_id": "2505.10457v1",
    "title": "SEAL: Searching Expandable Architectures for Incremental Learning",
    "authors": [
      "Matteo Gambella",
      "Vicente Javier Castro Solar",
      "Manuel Roveri"
    ],
    "abstract": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "68T07"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.10457v1",
    "published_date": "2025-05-15 16:14:18 UTC",
    "updated_date": "2025-05-15 16:14:18 UTC"
  },
  {
    "arxiv_id": "2505.10453v1",
    "title": "Vision language models have difficulty recognizing virtual objects",
    "authors": [
      "Tyler Tran",
      "Sangeet Khemlani",
      "J. G. Trafton"
    ],
    "abstract": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10453v1",
    "published_date": "2025-05-15 16:11:33 UTC",
    "updated_date": "2025-05-15 16:11:33 UTC"
  },
  {
    "arxiv_id": "2505.10443v1",
    "title": "Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?",
    "authors": [
      "Pedro Orvalho",
      "Marta Kwiatkowska"
    ],
    "abstract": "Understanding the reasoning and robustness of Large Language Models (LLMs) is\ncritical for their reliable use in programming tasks. While recent studies have\nassessed LLMs' ability to predict program outputs, most focus solely on the\naccuracy of those predictions, without evaluating the reasoning behind them.\nMoreover, it has been observed on mathematical reasoning tasks that LLMs can\narrive at correct answers through flawed logic, raising concerns about similar\nissues in code understanding.\n  In this work, we evaluate whether state-of-the-art LLMs with up to 8B\nparameters can reason about Python programs or are simply guessing. We apply\nfive semantics-preserving code mutations: renaming variables, mirroring\ncomparison expressions, swapping if-else branches, converting for loops to\nwhile, and loop unrolling. These mutations maintain program semantics while\naltering its syntax. We evaluated six LLMs and performed a human expert\nanalysis using LiveCodeBench to assess whether the correct predictions are\nbased on sound reasoning. We also evaluated prediction stability across\ndifferent code mutations on LiveCodeBench and CruxEval. Our findings show that\nsome LLMs, such as Llama3.2, produce correct predictions based on flawed\nreasoning in up to 61% of cases. Furthermore, LLMs often change predictions in\nresponse to our code mutations, indicating limited robustness in their semantic\nunderstanding.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "10 pages, 5 tables, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2505.10443v1",
    "published_date": "2025-05-15 16:04:25 UTC",
    "updated_date": "2025-05-15 16:04:25 UTC"
  },
  {
    "arxiv_id": "2505.10442v1",
    "title": "IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning",
    "authors": [
      "Dechen Gao",
      "Hang Wang",
      "Hanchu Zhou",
      "Nejib Ammar",
      "Shatadal Mishra",
      "Ahmadreza Moradipari",
      "Iman Soltani",
      "Junshan Zhang"
    ],
    "abstract": "Imitation learning (IL) and reinforcement learning (RL) each offer distinct\nadvantages for robotics policy learning: IL provides stable learning from\ndemonstrations, and RL promotes generalization through exploration. While\nexisting robot learning approaches using IL-based pre-training followed by\nRL-based fine-tuning are promising, this two-step learning paradigm often\nsuffers from instability and poor sample efficiency during the RL fine-tuning\nphase. In this work, we introduce IN-RIL, INterleaved Reinforcement learning\nand Imitation Learning, for policy fine-tuning, which periodically injects IL\nupdates after multiple RL updates and hence can benefit from the stability of\nIL and the guidance of expert data for more efficient exploration throughout\nthe entire fine-tuning process. Since IL and RL involve different optimization\nobjectives, we develop gradient separation mechanisms to prevent destructive\ninterference during \\ABBR fine-tuning, by separating possibly conflicting\ngradient updates in orthogonal subspaces. Furthermore, we conduct rigorous\nanalysis, and our findings shed light on why interleaving IL with RL stabilizes\nlearning and improves sample-efficiency. Extensive experiments on 14 robot\nmanipulation and locomotion tasks across 3 benchmarks, including\nFurnitureBench, OpenAI Gym, and Robomimic, demonstrate that \\ABBR can\nsignificantly improve sample efficiency and mitigate performance collapse\nduring online finetuning in both long- and short-horizon tasks with either\nsparse or dense rewards. IN-RIL, as a general plug-in compatible with various\nstate-of-the-art RL algorithms, can significantly improve RL fine-tuning, e.g.,\nfrom 12\\% to 88\\% with 6.3x improvement in the success rate on Robomimic\nTransport. Project page: https://github.com/ucd-dare/IN-RIL.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10442v1",
    "published_date": "2025-05-15 16:01:21 UTC",
    "updated_date": "2025-05-15 16:01:21 UTC"
  },
  {
    "arxiv_id": "2505.10441v1",
    "title": "PIF: Anomaly detection via preference embedding",
    "authors": [
      "Filippo Leveni",
      "Luca Magri",
      "Giacomo Boracchi",
      "Cesare Alippi"
    ],
    "abstract": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)",
    "pdf_url": "http://arxiv.org/pdf/2505.10441v1",
    "published_date": "2025-05-15 16:00:31 UTC",
    "updated_date": "2025-05-15 16:00:31 UTC"
  },
  {
    "arxiv_id": "2505.10420v1",
    "title": "Learned Lightweight Smartphone ISP with Unpaired Data",
    "authors": [
      "Andrei Arhire",
      "Radu Timofte"
    ],
    "abstract": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPRW 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.10420v1",
    "published_date": "2025-05-15 15:37:51 UTC",
    "updated_date": "2025-05-15 15:37:51 UTC"
  },
  {
    "arxiv_id": "2505.10405v1",
    "title": "Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding",
    "authors": [
      "Jianhao Huang",
      "Qunsong Zeng",
      "Kaibin Huang"
    ],
    "abstract": "Generative semantic communication (Gen-SemCom) with large artificial\nintelligence (AI) model promises a transformative paradigm for 6G networks,\nwhich reduces communication costs by transmitting low-dimensional prompts\nrather than raw data. However, purely prompt-driven generation loses\nfine-grained visual details. Additionally, there is a lack of systematic\nmetrics to evaluate the performance of Gen-SemCom systems. To address these\nissues, we develop a hybrid Gen-SemCom system with a critical information\nembedding (CIE) framework, where both text prompts and semantically critical\nfeatures are extracted for transmissions. First, a novel approach of semantic\nfiltering is proposed to select and transmit the semantically critical features\nof images relevant to semantic label. By integrating the text prompt and\ncritical features, the receiver reconstructs high-fidelity images using a\ndiffusion-based generative model. Next, we propose the generative visual\ninformation fidelity (GVIF) metric to evaluate the visual quality of the\ngenerated image. By characterizing the statistical models of image features,\nthe GVIF metric quantifies the mutual information between the distorted\nfeatures and their original counterparts. By maximizing the GVIF metric, we\ndesign a channel-adaptive Gen-SemCom system that adaptively control the volume\nof features and compression rate according to the channel state. Experimental\nresults validate the GVIF metric's sensitivity to visual fidelity, correlating\nwith both the PSNR and critical information volume. In addition, the optimized\nsystem achieves superior performance over benchmarking schemes in terms of\nhigher PSNR and lower FID scores.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10405v1",
    "published_date": "2025-05-15 15:28:32 UTC",
    "updated_date": "2025-05-15 15:28:32 UTC"
  },
  {
    "arxiv_id": "2505.10402v1",
    "title": "Rethinking Repetition Problems of LLMs in Code Generation",
    "authors": [
      "Yihong Dong",
      "Yuchen Liu",
      "Xue Jiang",
      "Zhi Jin",
      "Ge Li"
    ],
    "abstract": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2025 (main)",
    "pdf_url": "http://arxiv.org/pdf/2505.10402v1",
    "published_date": "2025-05-15 15:26:32 UTC",
    "updated_date": "2025-05-15 15:26:32 UTC"
  },
  {
    "arxiv_id": "2505.10399v1",
    "title": "Evaluating Model Explanations without Ground Truth",
    "authors": [
      "Kaivalya Rawal",
      "Zihao Fu",
      "Eoin Delaney",
      "Chris Russell"
    ],
    "abstract": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "https://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth",
    "pdf_url": "http://arxiv.org/pdf/2505.10399v1",
    "published_date": "2025-05-15 15:22:06 UTC",
    "updated_date": "2025-05-15 15:22:06 UTC"
  },
  {
    "arxiv_id": "2505.10394v1",
    "title": "Inconsistency Handling in DatalogMTL",
    "authors": [
      "Meghyn Bienvenu",
      "Camille Bourgaux",
      "Atefe Khodadaditaghanaki"
    ],
    "abstract": "In this paper, we explore the issue of inconsistency handling in DatalogMTL,\nan extension of Datalog with metric temporal operators. Since facts are\nassociated with time intervals, there are different manners to restore\nconsistency when they contradict the rules, such as removing facts or modifying\ntheir time intervals. Our first contribution is the definition of relevant\nnotions of conflicts (minimal explanations for inconsistency) and repairs\n(possible ways of restoring consistency) for this setting and the study of the\nproperties of these notions and the associated inconsistency-tolerant\nsemantics. Our second contribution is a data complexity analysis of the tasks\nof generating a single conflict / repair and query entailment under\nrepair-based semantics.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LO",
    "comment": "This is an extended version of a paper appearing at the 34th\n  International Joint Conference on Artificial Intelligence (IJCAI 2025). 24\n  pages",
    "pdf_url": "http://arxiv.org/pdf/2505.10394v1",
    "published_date": "2025-05-15 15:17:09 UTC",
    "updated_date": "2025-05-15 15:17:09 UTC"
  },
  {
    "arxiv_id": "2505.10393v1",
    "title": "Uncovering Magnetic Phases with Synthetic Data and Physics-Informed Training",
    "authors": [
      "Agustin Medina",
      "Marcelo Arlego",
      "Carlos A. Lamas"
    ],
    "abstract": "We investigate the efficient learning of magnetic phases using artificial\nneural networks trained on synthetic data, combining computational simplicity\nwith physics-informed strategies. Focusing on the diluted Ising model, which\nlacks an exact analytical solution, we explore two complementary approaches: a\nsupervised classification using simple dense neural networks, and an\nunsupervised detection of phase transitions using convolutional autoencoders\ntrained solely on idealized spin configurations.\n  To enhance model performance, we incorporate two key forms of\nphysics-informed guidance. First, we exploit architectural biases which\npreferentially amplify features related to symmetry breaking. Second, we\ninclude training configurations that explicitly break $\\mathbb{Z}_2$ symmetry,\nreinforcing the network's ability to detect ordered phases. These mechanisms,\nacting in tandem, increase the network's sensitivity to phase structure even in\nthe absence of explicit labels. We validate the machine learning predictions\nthrough comparison with direct numerical estimates of critical temperatures and\npercolation thresholds.\n  Our results show that synthetic, structured, and computationally efficient\ntraining schemes can reveal physically meaningful phase boundaries, even in\ncomplex systems. This framework offers a low-cost and robust alternative to\nconventional methods, with potential applications in broader condensed matter\nand statistical physics contexts.",
    "categories": [
      "cond-mat.str-el",
      "cs.AI"
    ],
    "primary_category": "cond-mat.str-el",
    "comment": "25 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.10393v1",
    "published_date": "2025-05-15 15:16:16 UTC",
    "updated_date": "2025-05-15 15:16:16 UTC"
  },
  {
    "arxiv_id": "2505.10392v1",
    "title": "Schreier-Coset Graph Propagation",
    "authors": [
      "Aryan Mishra",
      "Lizhen Lin"
    ],
    "abstract": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 1 figure , preprint",
    "pdf_url": "http://arxiv.org/pdf/2505.10392v1",
    "published_date": "2025-05-15 15:14:02 UTC",
    "updated_date": "2025-05-15 15:14:02 UTC"
  },
  {
    "arxiv_id": "2505.10387v1",
    "title": "Multi-Agent Path Finding For Large Agents Is Intractable",
    "authors": [
      "Artem Agafonov",
      "Konstantin Yakovlev"
    ],
    "abstract": "The multi-agent path finding (MAPF) problem asks to find a set of paths on a\ngraph such that when synchronously following these paths the agents never\nencounter a conflict. In the most widespread MAPF formulation, the so-called\nClassical MAPF, the agents sizes are neglected and two types of conflicts are\nconsidered: occupying the same vertex or using the same edge at the same time\nstep. Meanwhile in numerous practical applications, e.g. in robotics, taking\ninto account the agents' sizes is vital to ensure that the MAPF solutions can\nbe safely executed. Introducing large agents yields an additional type of\nconflict arising when one agent follows an edge and its body overlaps with the\nbody of another agent that is actually not using this same edge (e.g. staying\nstill at some distinct vertex of the graph). Until now it was not clear how\nharder the problem gets when such conflicts are to be considered while\nplanning. Specifically, it was known that Classical MAPF problem on an\nundirected graph can be solved in polynomial time, however no complete\npolynomial-time algorithm was presented to solve MAPF with large agents. In\nthis paper we, for the first time, establish that the latter problem is NP-hard\nand, thus, if P!=NP no polynomial algorithm for it can, unfortunately, be\npresented. Our proof is based on the prevalent in the field technique of\nreducing the seminal 3SAT problem (which is known to be an NP-complete problem)\nto the problem at hand. In particular, for an arbitrary 3SAT formula we\nprocedurally construct a dedicated graph with specific start and goal vertices\nand show that the given 3SAT formula is satisfiable iff the corresponding path\nfinding instance has a solution.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10387v1",
    "published_date": "2025-05-15 15:07:40 UTC",
    "updated_date": "2025-05-15 15:07:40 UTC"
  },
  {
    "arxiv_id": "2505.10375v1",
    "title": "Are Sparse Autoencoders Useful for Java Function Bug Detection?",
    "authors": [
      "Rui Melo",
      "Claudia Mamede",
      "Andre Catarino",
      "Rui Abreu",
      "Henrique Lopes Cardoso"
    ],
    "abstract": "Software vulnerabilities such as buffer overflows and SQL injections are a\nmajor source of security breaches. Traditional methods for vulnerability\ndetection remain essential but are limited by high false positive rates,\nscalability issues, and reliance on manual effort. These constraints have\ndriven interest in AI-based approaches to automated vulnerability detection and\nsecure code generation. While Large Language Models (LLMs) have opened new\navenues for classification tasks, their complexity and opacity pose challenges\nfor interpretability and deployment. Sparse Autoencoder offer a promising\nsolution to this problem. We explore whether SAEs can serve as a lightweight,\ninterpretable alternative for bug detection in Java functions. We evaluate the\neffectiveness of SAEs when applied to representations from GPT-2 Small and\nGemma 2B, examining their capacity to highlight buggy behaviour without\nfine-tuning the underlying LLMs. We found that SAE-derived features enable bug\ndetection with an F1 score of up to 89%, consistently outperforming fine-tuned\ntransformer encoder baselines. Our work provides the first empirical evidence\nthat SAEs can be used to detect software bugs directly from the internal\nrepresentations of pretrained LLMs, without any fine-tuning or task-specific\nsupervision.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "10 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.10375v1",
    "published_date": "2025-05-15 14:59:17 UTC",
    "updated_date": "2025-05-15 14:59:17 UTC"
  },
  {
    "arxiv_id": "2505.10371v1",
    "title": "ILIF: Temporal Inhibitory Leaky Integrate-and-Fire Neuron for Overactivation in Spiking Neural Networks",
    "authors": [
      "Kai Sun",
      "Peibo Duan",
      "Levin Kuhlmann",
      "Beilun Wang",
      "Bin Zhang"
    ],
    "abstract": "The Spiking Neural Network (SNN) has drawn increasing attention for its\nenergy-efficient, event-driven processing and biological plausibility. To train\nSNNs via backpropagation, surrogate gradients are used to approximate the\nnon-differentiable spike function, but they only maintain nonzero derivatives\nwithin a narrow range of membrane potentials near the firing threshold,\nreferred to as the surrogate gradient support width gamma. We identify a major\nchallenge, termed the dilemma of gamma: a relatively large gamma leads to\noveractivation, characterized by excessive neuron firing, which in turn\nincreases energy consumption, whereas a small gamma causes vanishing gradients\nand weakens temporal dependencies. To address this, we propose a temporal\nInhibitory Leaky Integrate-and-Fire (ILIF) neuron model, inspired by biological\ninhibitory mechanisms. This model incorporates interconnected inhibitory units\nfor membrane potential and current, effectively mitigating overactivation while\npreserving gradient propagation. Theoretical analysis demonstrates ILIF\neffectiveness in overcoming the gamma dilemma, and extensive experiments on\nmultiple datasets show that ILIF improves energy efficiency by reducing firing\nrates, stabilizes training, and enhances accuracy. The code is available at\ngithub.com/kaisun1/ILIF.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10371v1",
    "published_date": "2025-05-15 14:56:06 UTC",
    "updated_date": "2025-05-15 14:56:06 UTC"
  },
  {
    "arxiv_id": "2505.10361v1",
    "title": "Plasticity as the Mirror of Empowerment",
    "authors": [
      "David Abel",
      "Michael Bowling",
      "AndrÃ© Barreto",
      "Will Dabney",
      "Shi Dong",
      "Steven Hansen",
      "Anna Harutyunyan",
      "Khimya Khetarpal",
      "Clare Lyle",
      "Razvan Pascanu",
      "Georgios Piliouras",
      "Doina Precup",
      "Jonathan Richens",
      "Mark Rowland",
      "Tom Schaul",
      "Satinder Singh"
    ],
    "abstract": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10361v1",
    "published_date": "2025-05-15 14:52:16 UTC",
    "updated_date": "2025-05-15 14:52:16 UTC"
  },
  {
    "arxiv_id": "2505.10360v1",
    "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation",
    "authors": [
      "Victor PetrÃ©n Bach Hansen",
      "Lasse KrogsbÃ¸ll",
      "Jonas LyngsÃ¸",
      "Mathias Baltzersen",
      "Andreas Motzfeldt",
      "Kevin Pelgrims",
      "Lars MaalÃ¸e"
    ],
    "abstract": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10360v1",
    "published_date": "2025-05-15 14:51:22 UTC",
    "updated_date": "2025-05-15 14:51:22 UTC"
  },
  {
    "arxiv_id": "2505.10352v1",
    "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity",
    "authors": [
      "Shihao Zou",
      "Qingfeng Li",
      "Wei Ji",
      "Jingjing Li",
      "Yongkui Yang",
      "Guoqi Li",
      "Chao Dong"
    ],
    "abstract": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.10352v1",
    "published_date": "2025-05-15 14:43:35 UTC",
    "updated_date": "2025-05-15 14:43:35 UTC"
  },
  {
    "arxiv_id": "2505.10347v1",
    "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning",
    "authors": [
      "Gabriel S. Gama",
      "Valdir Grassi Jr"
    ],
    "abstract": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10347v1",
    "published_date": "2025-05-15 14:34:36 UTC",
    "updated_date": "2025-05-15 14:34:36 UTC"
  },
  {
    "arxiv_id": "2505.10331v1",
    "title": "Emergence of Structure in Ensembles of Random Neural Networks",
    "authors": [
      "Luca Muscarnera",
      "Luigi Loreti",
      "Giovanni Todeschini",
      "Alessio Fumagalli",
      "Francesco Regazzoni"
    ],
    "abstract": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10331v1",
    "published_date": "2025-05-15 14:20:02 UTC",
    "updated_date": "2025-05-15 14:20:02 UTC"
  },
  {
    "arxiv_id": "2505.10330v1",
    "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change",
    "authors": [
      "Jonathan Clifford Balloch"
    ],
    "abstract": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "PhD Dissertation, 131 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.10330v1",
    "published_date": "2025-05-15 14:19:01 UTC",
    "updated_date": "2025-05-15 14:19:01 UTC"
  },
  {
    "arxiv_id": "2505.10328v1",
    "title": "A Comparative Study of SMT and MILP for the Nurse Rostering Problem",
    "authors": [
      "Alvin Combrink",
      "Stephie Do",
      "Kristofer Bengtsson",
      "Sabino Francesco Roselli",
      "Martin Fabian"
    ],
    "abstract": "The effects of personnel scheduling on the quality of care and working\nconditions for healthcare personnel have been thoroughly documented. However,\nthe ever-present demand and large variation of constraints make healthcare\nscheduling particularly challenging. This problem has been studied for decades,\nwith limited research aimed at applying Satisfiability Modulo Theories (SMT).\nSMT has gained momentum within the formal verification community in the last\ndecades, leading to the advancement of SMT solvers that have been shown to\noutperform standard mathematical programming techniques.\n  In this work, we propose generic constraint formulations that can model a\nwide range of real-world scheduling constraints. Then, the generic constraints\nare formulated as SMT and MILP problems and used to compare the respective\nstate-of-the-art solvers, Z3 and Gurobi, on academic and real-world inspired\nrostering problems. Experimental results show how each solver excels for\ncertain types of problems; the MILP solver generally performs better when the\nproblem is highly constrained or infeasible, while the SMT solver performs\nbetter otherwise. On real-world inspired problems containing a more varied set\nof shifts and personnel, the SMT solver excels. Additionally, it was noted\nduring experimentation that the SMT solver was more sensitive to the way the\ngeneric constraints were formulated, requiring careful consideration and\nexperimentation to achieve better performance. We conclude that SMT-based\nmethods present a promising avenue for future research within the domain of\npersonnel scheduling.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.10328v1",
    "published_date": "2025-05-15 14:12:39 UTC",
    "updated_date": "2025-05-15 14:12:39 UTC"
  },
  {
    "arxiv_id": "2505.10321v1",
    "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents",
    "authors": [
      "Julius Henke"
    ],
    "abstract": "A recent area of increasing research is the use of Large Language Models\n(LLMs) in penetration testing, which promises to reduce costs and thus allow\nfor higher frequency. We conduct a review of related work, identifying best\npractices and common evaluation issues. We then present AutoPentest, an\napplication for performing black-box penetration tests with a high degree of\nautonomy. AutoPentest is based on the LLM GPT-4o from OpenAI and the LLM agent\nframework LangChain. It can perform complex multi-step tasks, augmented by\nexternal tools and knowledge bases. We conduct a study on three\ncapture-the-flag style Hack The Box (HTB) machines, comparing our\nimplementation AutoPentest with the baseline approach of manually using the\nChatGPT-4o user interface. Both approaches are able to complete 15-25 % of the\nsubtasks on the HTB machines, with AutoPentest slightly outperforming ChatGPT.\nWe measure a total cost of \\$96.20 US when using AutoPentest across all\nexperiments, while a one-month subscription to ChatGPT Plus costs \\$20. The\nresults show that further implementation efforts and the use of more powerful\nLLMs released in the future are likely to make this a viable part of\nvulnerability management.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "24 pages, 1 figure, for implementation, see\n  https://github.com/JuliusHenke/autopentest",
    "pdf_url": "http://arxiv.org/pdf/2505.10321v1",
    "published_date": "2025-05-15 14:06:00 UTC",
    "updated_date": "2025-05-15 14:06:00 UTC"
  },
  {
    "arxiv_id": "2505.10320v1",
    "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning",
    "authors": [
      "Chenxi Whitehouse",
      "Tianlu Wang",
      "Ping Yu",
      "Xian Li",
      "Jason Weston",
      "Ilia Kulikov",
      "Swarnadeep Saha"
    ],
    "abstract": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 8 tables, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.10320v1",
    "published_date": "2025-05-15 14:05:15 UTC",
    "updated_date": "2025-05-15 14:05:15 UTC"
  },
  {
    "arxiv_id": "2505.10315v1",
    "title": "Private Transformer Inference in MLaaS: A Survey",
    "authors": [
      "Yang Li",
      "Xinyu Zhou",
      "Yitong Wang",
      "Liangxin Qian",
      "Jun Zhao"
    ],
    "abstract": "Transformer models have revolutionized AI, powering applications like content\ngeneration and sentiment analysis. However, their deployment in Machine\nLearning as a Service (MLaaS) raises significant privacy concerns, primarily\ndue to the centralized processing of sensitive user data. Private Transformer\nInference (PTI) offers a solution by utilizing cryptographic techniques such as\nsecure multi-party computation and homomorphic encryption, enabling inference\nwhile preserving both user data and model privacy. This paper reviews recent\nPTI advancements, highlighting state-of-the-art solutions and challenges. We\nalso introduce a structured taxonomy and evaluation framework for PTI, focusing\non balancing resource efficiency with privacy and bridging the gap between\nhigh-performance inference and data privacy.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10315v1",
    "published_date": "2025-05-15 14:00:19 UTC",
    "updated_date": "2025-05-15 14:00:19 UTC"
  },
  {
    "arxiv_id": "2505.10309v1",
    "title": "Empirically evaluating commonsense intelligence in large language models with large-scale human judgments",
    "authors": [
      "Tuan Dung Nguyen",
      "Duncan J. Watts",
      "Mark E. Whiting"
    ],
    "abstract": "Commonsense intelligence in machines is often assessed by static benchmarks\nthat compare a model's output against human-prescribed correct labels. An\nimportant, albeit implicit, assumption of these labels is that they accurately\ncapture what any human would think, effectively treating human common sense as\nhomogeneous. However, recent empirical work has shown that humans vary\nenormously in what they consider commonsensical; thus what appears self-evident\nto one benchmark designer may not be so to another. Here, we propose a novel\nmethod for evaluating common sense in artificial intelligence (AI),\nspecifically in large language models (LLMs), that incorporates empirically\nobserved heterogeneity among humans by measuring the correspondence between a\nmodel's judgment and that of a human population. We first find that, when\ntreated as independent survey respondents, most LLMs remain below the human\nmedian in their individual commonsense competence. Second, when used as\nsimulators of a hypothetical population, LLMs correlate with real humans only\nmodestly in the extent to which they agree on the same set of statements. In\nboth cases, smaller, open-weight models are surprisingly more competitive than\nlarger, proprietary frontier models. Our evaluation framework, which ties\ncommonsense intelligence to its cultural basis, contributes to the growing call\nfor adapting AI models to human collectivities that possess different, often\nincompatible, social stocks of knowledge.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10309v1",
    "published_date": "2025-05-15 13:55:27 UTC",
    "updated_date": "2025-05-15 13:55:27 UTC"
  },
  {
    "arxiv_id": "2505.10300v1",
    "title": "AI LEGO: Scaffolding Cross-Functional Collaboration in Industrial Responsible AI Practices during Early Design Stages",
    "authors": [
      "Muzhe Wu",
      "Yanzhi Zhao",
      "Shuyi Han",
      "Michael Xieyang Liu",
      "Hong Shen"
    ],
    "abstract": "Responsible AI (RAI) efforts increasingly emphasize the importance of\naddressing potential harms early in the AI development lifecycle through\nsocial-technical lenses. However, in cross-functional industry teams, this work\nis often stalled by a persistent knowledge handoff challenge: the difficulty of\ntransferring high-level, early-stage technical design rationales from technical\nexperts to non-technical or user-facing roles for ethical evaluation and harm\nidentification. Through literature review and a co-design study with 8\npractitioners, we unpack how this challenge manifests -- technical design\nchoices are rarely handed off in ways that support meaningful engagement by\nnon-technical roles; collaborative workflows lack shared, visual structures to\nsupport mutual understanding; and non-technical practitioners are left without\nscaffolds for systematic harm evaluation. Existing tools like JIRA or Google\nDocs, while useful for product tracking, are ill-suited for supporting joint\nharm identification across roles, often requiring significant extra effort to\nalign understanding. To address this, we developed AI LEGO, a web-based\nprototype that supports cross-functional AI practitioners in effectively\nfacilitating knowledge handoff and identifying harmful design choices in the\nearly design stages. Technical roles use interactive blocks to draft\ndevelopment plans, while non-technical roles engage with those blocks through\nstage-specific checklists and LLM-driven persona simulations to surface\npotential harms. In a study with 18 cross-functional practitioners, AI LEGO\nincreased the volume and likelihood of harms identified compared to baseline\nworksheets. Participants found that its modular structure and persona prompts\nmade harm identification more accessible, fostering clearer and more\ncollaborative RAI practices in early design.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10300v1",
    "published_date": "2025-05-15 13:49:02 UTC",
    "updated_date": "2025-05-15 13:49:02 UTC"
  },
  {
    "arxiv_id": "2505.10297v1",
    "title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning",
    "authors": [
      "Chibueze Peace Obioma",
      "Youcheng Sun",
      "Mustafa A. Mustafa"
    ],
    "abstract": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to ESORICS 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.10297v1",
    "published_date": "2025-05-15 13:44:32 UTC",
    "updated_date": "2025-05-15 13:44:32 UTC"
  },
  {
    "arxiv_id": "2505.10278v1",
    "title": "MASS: Multi-Agent Simulation Scaling for Portfolio Construction",
    "authors": [
      "Taian Guo",
      "Haiyang Shen",
      "Jinsheng Huang",
      "Zhengyang Mao",
      "Junyu Luo",
      "Zhuoru Chen",
      "Xuhui Liu",
      "Bingyu Xia",
      "Luchen Liu",
      "Yun Ma",
      "Ming Zhang"
    ],
    "abstract": "LLM-based multi-agent has gained significant attention for their potential in\nsimulation and enhancing performance. However, existing works are limited to\npure simulations or are constrained by predefined workflows, restricting their\napplicability and effectiveness. In this paper, we introduce the Multi-Agent\nScaling Simulation (MASS) for portfolio construction. MASS achieves stable and\ncontinuous excess returns by progressively increasing the number of agents for\nlarge-scale simulations to gain a superior understanding of the market and\noptimizing agent distribution end-to-end through a reverse optimization\nprocess, rather than relying on a fixed workflow. We demonstrate its\nsuperiority through performance experiments, ablation studies, backtesting\nexperiments, experiments on updated data and stock pools, scaling experiments,\nparameter sensitivity experiments, and visualization experiments, conducted in\ncomparison with 6 state-of-the-art baselines on 3 challenging A-share stock\npools. We expect the paradigm established by MASS to expand to other tasks with\nsimilar characteristics. The implementation of MASS has been open-sourced at\nhttps://github.com/gta0804/MASS.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10278v1",
    "published_date": "2025-05-15 13:27:18 UTC",
    "updated_date": "2025-05-15 13:27:18 UTC"
  },
  {
    "arxiv_id": "2505.10273v1",
    "title": "AttentionGuard: Transformer-based Misbehavior Detection for Secure Vehicular Platoons",
    "authors": [
      "Hexu Li",
      "Konstantinos Kalogiannis",
      "Ahmed Mohamed Hussain",
      "Panos Papadimitratos"
    ],
    "abstract": "Vehicle platooning, with vehicles traveling in close formation coordinated\nthrough Vehicle-to-Everything (V2X) communications, offers significant benefits\nin fuel efficiency and road utilization. However, it is vulnerable to\nsophisticated falsification attacks by authenticated insiders that can\ndestabilize the formation and potentially cause catastrophic collisions. This\npaper addresses this challenge: misbehavior detection in vehicle platooning\nsystems. We present AttentionGuard, a transformer-based framework for\nmisbehavior detection that leverages the self-attention mechanism to identify\nanomalous patterns in mobility data. Our proposal employs a multi-head\ntransformer-encoder to process sequential kinematic information, enabling\neffective differentiation between normal mobility patterns and falsification\nattacks across diverse platooning scenarios, including steady-state\n(no-maneuver) operation, join, and exit maneuvers. Our evaluation uses an\nextensive simulation dataset featuring various attack vectors (constant,\ngradual, and combined falsifications) and operational parameters (controller\ntypes, vehicle speeds, and attacker positions). Experimental results\ndemonstrate that AttentionGuard achieves up to 0.95 F1-score in attack\ndetection, with robust performance maintained during complex maneuvers.\nNotably, our system performs effectively with minimal latency (100ms decision\nintervals), making it suitable for real-time transportation safety\napplications. Comparative analysis reveals superior detection capabilities and\nestablishes the transformer-encoder as a promising approach for securing\nCooperative Intelligent Transport Systems (C-ITS) against sophisticated insider\nthreats.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "Author's version; Accepted for presentation at the ACM Workshop on\n  Wireless Security and Machine Learning (WiseML 2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.10273v1",
    "published_date": "2025-05-15 13:24:09 UTC",
    "updated_date": "2025-05-15 13:24:09 UTC"
  },
  {
    "arxiv_id": "2505.10264v1",
    "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning",
    "authors": [
      "Francesco Diana",
      "AndrÃ© Nusser",
      "Chuan Xu",
      "Giovanni Neglia"
    ],
    "abstract": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10264v1",
    "published_date": "2025-05-15 13:16:32 UTC",
    "updated_date": "2025-05-15 13:16:32 UTC"
  },
  {
    "arxiv_id": "2505.10261v1",
    "title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine",
    "authors": [
      "Rui Yang",
      "Huitao Li",
      "Matthew Yu Heng Wong",
      "Yuhe Ke",
      "Xin Li",
      "Kunyu Yu",
      "Jingchi Liao",
      "Jonathan Chong Kai Liew",
      "Sabarinath Vinod Nair",
      "Jasmine Chiat Ling Ong",
      "Irene Li",
      "Douglas Teodoro",
      "Chuan Hong",
      "Daniel Shu Wei Ting",
      "Nan Liu"
    ],
    "abstract": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10261v1",
    "published_date": "2025-05-15 13:11:14 UTC",
    "updated_date": "2025-05-15 13:11:14 UTC"
  },
  {
    "arxiv_id": "2505.10260v1",
    "title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data",
    "authors": [
      "Poli Apollinaire Nemkova",
      "Solomon Ubani",
      "Mark V. Albert"
    ],
    "abstract": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10260v1",
    "published_date": "2025-05-15 13:10:47 UTC",
    "updated_date": "2025-05-15 13:10:47 UTC"
  },
  {
    "arxiv_id": "2505.10231v1",
    "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging",
    "authors": [
      "Haozhe Luo",
      "Ziyu Zhou",
      "Zixin Shu",
      "AurÃ©lie Pahud de Mortanges",
      "Robert Berke",
      "Mauricio Reyes"
    ],
    "abstract": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10231v1",
    "published_date": "2025-05-15 12:43:23 UTC",
    "updated_date": "2025-05-15 12:43:23 UTC"
  },
  {
    "arxiv_id": "2505.10212v1",
    "title": "Do LLMs Memorize Recommendation Datasets? A Preliminary Study on MovieLens-1M",
    "authors": [
      "Dario Di Palma",
      "Felice Antonio Merra",
      "Maurizio Sfilio",
      "Vito Walter Anelli",
      "Fedelucio Narducci",
      "Tommaso Di Noia"
    ],
    "abstract": "Large Language Models (LLMs) have become increasingly central to\nrecommendation scenarios due to their remarkable natural language understanding\nand generation capabilities. Although significant research has explored the use\nof LLMs for various recommendation tasks, little effort has been dedicated to\nverifying whether they have memorized public recommendation dataset as part of\ntheir training data. This is undesirable because memorization reduces the\ngeneralizability of research findings, as benchmarking on memorized datasets\ndoes not guarantee generalization to unseen datasets. Furthermore, memorization\ncan amplify biases, for example, some popular items may be recommended more\nfrequently than others.\n  In this work, we investigate whether LLMs have memorized public\nrecommendation datasets. Specifically, we examine two model families (GPT and\nLlama) across multiple sizes, focusing on one of the most widely used dataset\nin recommender systems: MovieLens-1M. First, we define dataset memorization as\nthe extent to which item attributes, user profiles, and user-item interactions\ncan be retrieved by prompting the LLMs. Second, we analyze the impact of\nmemorization on recommendation performance. Lastly, we examine whether\nmemorization varies across model families and model sizes. Our results reveal\nthat all models exhibit some degree of memorization of MovieLens-1M, and that\nrecommendation performance is related to the extent of memorization. We have\nmade all the code publicly available at:\nhttps://github.com/sisinflab/LLM-MemoryInspector",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10212v1",
    "published_date": "2025-05-15 12:16:36 UTC",
    "updated_date": "2025-05-15 12:16:36 UTC"
  },
  {
    "arxiv_id": "2505.10201v1",
    "title": "A Fine-Grained Complexity View on Propositional Abduction -- Algorithms and Lower Bounds",
    "authors": [
      "Victor Lagerkvist",
      "Mohamed Maizia",
      "Johannes Schmidt"
    ],
    "abstract": "The Boolean satisfiability problem (SAT) is a well-known example of monotonic\nreasoning, of intense practical interest due to fast solvers, complemented by\nrigorous fine-grained complexity results. However, for non-monotonic reasoning,\ne.g., abductive reasoning, comparably little is known outside classic\ncomplexity theory. In this paper we take a first step of bridging the gap\nbetween monotonic and non-monotonic reasoning by analyzing the complexity of\nintractable abduction problems under the seemingly overlooked but natural\nparameter n: the number of variables in the knowledge base. We obtain several\npositive results for $\\Sigma^P_2$- as well as NP- and coNP-complete fragments,\nwhich implies the first example of beating exhaustive search for a\n$\\Sigma^P_2$-complete problem (to the best of our knowledge). We complement\nthis with lower bounds and for many fragments rule out improvements under the\n(strong) exponential-time hypothesis.",
    "categories": [
      "cs.CC",
      "cs.AI",
      "F.2.2"
    ],
    "primary_category": "cs.CC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10201v1",
    "published_date": "2025-05-15 11:56:19 UTC",
    "updated_date": "2025-05-15 11:56:19 UTC"
  },
  {
    "arxiv_id": "2505.10197v1",
    "title": "Advancing Community Detection with Graph Convolutional Neural Networks: Bridging Topological and Attributive Cohesion",
    "authors": [
      "Anjali de Silva",
      "Gang Chen",
      "Hui Ma",
      "Seyed Mohammad Nekooei",
      "Xingquan Zuo"
    ],
    "abstract": "Community detection, a vital technology for real-world applications, uncovers\ncohesive node groups (communities) by leveraging both topological and attribute\nsimilarities in social networks. However, existing Graph Convolutional Networks\n(GCNs) trained to maximize modularity often converge to suboptimal solutions.\nAdditionally, directly using human-labeled communities for training can\nundermine topological cohesiveness by grouping disconnected nodes based solely\non node attributes. We address these issues by proposing a novel Topological\nand Attributive Similarity-based Community detection (TAS-Com) method. TAS-Com\nintroduces a novel loss function that exploits the highly effective and\nscalable Leiden algorithm to detect community structures with global optimal\nmodularity. Leiden is further utilized to refine human-labeled communities to\nensure connectivity within each community, enabling TAS-Com to detect community\nstructures with desirable trade-offs between modularity and compliance with\nhuman labels. Experimental results on multiple benchmark networks confirm that\nTAS-Com can significantly outperform several state-of-the-art algorithms.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "This paper has been accepted by IJCAI (International Joint Conference\n  on Artificial Intelligence) 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.10197v1",
    "published_date": "2025-05-15 11:53:33 UTC",
    "updated_date": "2025-05-15 11:53:33 UTC"
  },
  {
    "arxiv_id": "2505.10191v1",
    "title": "LanTu: Dynamics-Enhanced Deep Learning for Eddy-Resolving Ocean Forecasting",
    "authors": [
      "Qingyu Zheng",
      "Qi Shao",
      "Guijun Han",
      "Wei Li",
      "Hong Li",
      "Xuan Wang"
    ],
    "abstract": "Mesoscale eddies dominate the spatiotemporal multiscale variability of the\nocean, and their impact on the energy cascade of the global ocean cannot be\nignored. Eddy-resolving ocean forecasting is providing more reliable protection\nfor fisheries and navigational safety, but also presents significant scientific\nchallenges and high computational costs for traditional numerical models.\nArtificial intelligence (AI)-based weather and ocean forecasting systems are\nbecoming powerful tools that balance forecast performance with computational\nefficiency. However, the complex multiscale features in the ocean dynamical\nsystem make AI models still face many challenges in mesoscale eddy forecasting\n(especially regional modelling). Here, we develop LanTu, a regional\neddy-resolving ocean forecasting system based on dynamics-enhanced deep\nlearning. We incorporate cross-scale interactions into LanTu and construct\nmultiscale physical constraint for optimising LanTu guided by knowledge of eddy\ndynamics in order to improve the forecasting skill of LanTu for mesoscale\nevolution. The results show that LanTu outperforms the existing advanced\noperational numerical ocean forecasting system (NOFS) and AI-based ocean\nforecasting system (AI-OFS) in temperature, salinity, sea level anomaly and\ncurrent prediction, with a lead time of more than 10 days. Our study highlights\nthat dynamics-enhanced deep learning (LanTu) can be a powerful paradigm for\neddy-resolving ocean forecasting.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.LG",
      "nlin.CD"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "22 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.10191v1",
    "published_date": "2025-05-15 11:47:54 UTC",
    "updated_date": "2025-05-15 11:47:54 UTC"
  },
  {
    "arxiv_id": "2505.10188v1",
    "title": "A User Study Evaluating Argumentative Explanations in Diagnostic Decision Support",
    "authors": [
      "Felix Liedeker",
      "Olivia Sanchez-Graillet",
      "Moana Seidler",
      "Christian Brandt",
      "JÃ¶rg Wellmer",
      "Philipp Cimiano"
    ],
    "abstract": "As the field of healthcare increasingly adopts artificial intelligence, it\nbecomes important to understand which types of explanations increase\ntransparency and empower users to develop confidence and trust in the\npredictions made by machine learning (ML) systems. In shared decision-making\nscenarios where doctors cooperate with ML systems to reach an appropriate\ndecision, establishing mutual trust is crucial. In this paper, we explore\ndifferent approaches to generating explanations in eXplainable AI (XAI) and\nmake their underlying arguments explicit so that they can be evaluated by\nmedical experts. In particular, we present the findings of a user study\nconducted with physicians to investigate their perceptions of various types of\nAI-generated explanations in the context of diagnostic decision support. The\nstudy aims to identify the most effective and useful explanations that enhance\nthe diagnostic process. In the study, medical doctors filled out a survey to\nassess different types of explanations. Further, an interview was carried out\npost-survey to gain qualitative insights on the requirements of explanations\nincorporated in diagnostic decision support. Overall, the insights gained from\nthis study contribute to understanding the types of explanations that are most\neffective.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at 'The First Workshop on Natural Language Argument-Based\n  Explanations', co-located with ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2505.10188v1",
    "published_date": "2025-05-15 11:42:24 UTC",
    "updated_date": "2025-05-15 11:42:24 UTC"
  },
  {
    "arxiv_id": "2505.10185v1",
    "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think",
    "authors": [
      "Seongyun Lee",
      "Seungone Kim",
      "Minju Seo",
      "Yongrae Jo",
      "Dongyoung Go",
      "Hyeonbin Hwang",
      "Jinho Park",
      "Xiang Yue",
      "Sean Welleck",
      "Graham Neubig",
      "Moontae Lee",
      "Minjoon Seo"
    ],
    "abstract": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2505.10185v1",
    "published_date": "2025-05-15 11:31:02 UTC",
    "updated_date": "2025-05-15 11:31:02 UTC"
  },
  {
    "arxiv_id": "2505.10183v1",
    "title": "KAITIAN: A Unified Communication Framework for Enabling Efficient Collaboration Across Heterogeneous Accelerators in Embodied AI Systems",
    "authors": [
      "Jieke Lin",
      "Wanyu Wang",
      "Longxiang Yin",
      "Yinhe Han"
    ],
    "abstract": "Embodied Artificial Intelligence (AI) systems, such as autonomous robots and\nintelligent vehicles, are increasingly reliant on diverse heterogeneous\naccelerators (e.g., GPGPUs, NPUs, FPGAs) to meet stringent real-time processing\nand energy-efficiency demands. However, the proliferation of vendor-specific\nproprietary communication libraries creates significant interoperability\nbarriers, hindering seamless collaboration between different accelerator types\nand leading to suboptimal resource utilization and performance bottlenecks in\ndistributed AI workloads. This paper introduces KAITIAN, a novel distributed\ncommunication framework designed to bridge this gap. KAITIAN provides a unified\nabstraction layer that intelligently integrates vendor-optimized communication\nlibraries for intra-group efficiency with general-purpose communication\nprotocols for inter-group interoperability. Crucially, it incorporates a\nload-adaptive scheduling mechanism that dynamically balances computational\ntasks across heterogeneous devices based on their real-time performance\ncharacteristics. Implemented as an extension to PyTorch and rigorously\nevaluated on a testbed featuring NVIDIA GPUs and Cambricon MLUs, KAITIAN\ndemonstrates significant improvements in resource utilization and scalability\nfor distributed training tasks. Experimental results show that KAITIAN can\naccelerate training time by up to 42% compared to baseline homogeneous systems,\nwhile incurring minimal communication overhead (2.8--4.3%) and maintaining\nmodel accuracy. KAITIAN paves the way for more flexible and powerful\nheterogeneous computing in complex embodied AI applications.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "9 pages, 4 figures. Jieke Lin and Wanyu Wang contributed equally to\n  this work",
    "pdf_url": "http://arxiv.org/pdf/2505.10183v1",
    "published_date": "2025-05-15 11:29:43 UTC",
    "updated_date": "2025-05-15 11:29:43 UTC"
  },
  {
    "arxiv_id": "2505.10172v1",
    "title": "Does Scaling Law Apply in Time Series Forecasting?",
    "authors": [
      "Zeyan Li",
      "Libing Chen",
      "Yin Tang"
    ],
    "abstract": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10172v1",
    "published_date": "2025-05-15 11:04:39 UTC",
    "updated_date": "2025-05-15 11:04:39 UTC"
  },
  {
    "arxiv_id": "2505.10169v1",
    "title": "Modeling Saliency Dataset Bias",
    "authors": [
      "Matthias KÃ¼mmerer",
      "Harneet Khanuja",
      "Matthias Bethge"
    ],
    "abstract": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10169v1",
    "published_date": "2025-05-15 10:55:47 UTC",
    "updated_date": "2025-05-15 10:55:47 UTC"
  },
  {
    "arxiv_id": "2505.10167v1",
    "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models",
    "authors": [
      "Saikat Barua",
      "Mostafizur Rahman",
      "Shehenaz Khaled",
      "Md Jafor Sadek",
      "Rafiul Islam",
      "Shahnewaz Siddique"
    ],
    "abstract": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 6 figures, 7 equations",
    "pdf_url": "http://arxiv.org/pdf/2505.10167v1",
    "published_date": "2025-05-15 10:51:34 UTC",
    "updated_date": "2025-05-15 10:51:34 UTC"
  },
  {
    "arxiv_id": "2505.10134v1",
    "title": "Large Wireless Localization Model (LWLM): A Foundation Model for Positioning in 6G Networks",
    "authors": [
      "Guangjin Pan",
      "Kaixuan Huang",
      "Hui Chen",
      "Shunqing Zhang",
      "Christian HÃ¤ger",
      "Henk Wymeersch"
    ],
    "abstract": "Accurate and robust localization is a critical enabler for emerging 5G and 6G\napplications, including autonomous driving, extended reality (XR), and smart\nmanufacturing. While data-driven approaches have shown promise, most existing\nmodels require large amounts of labeled data and struggle to generalize across\ndeployment scenarios and wireless configurations. To address these limitations,\nwe propose a foundation-model-based solution tailored for wireless\nlocalization. We first analyze how different self-supervised learning (SSL)\ntasks acquire general-purpose and task-specific semantic features based on\ninformation bottleneck (IB) theory. Building on this foundation, we design a\npretraining methodology for the proposed Large Wireless Localization Model\n(LWLM). Specifically, we propose an SSL framework that jointly optimizes three\ncomplementary objectives: (i) spatial-frequency masked channel modeling\n(SF-MCM), (ii) domain-transformation invariance (DTI), and (iii)\nposition-invariant contrastive learning (PICL). These objectives jointly\ncapture the underlying semantics of wireless channel from multiple\nperspectives. We further design lightweight decoders for key downstream tasks,\nincluding time-of-arrival (ToA) estimation, angle-of-arrival (AoA) estimation,\nsingle base station (BS) localization, and multiple BS localization.\nComprehensive experimental results confirm that LWLM consistently surpasses\nboth model-based and supervised learning baselines across all localization\ntasks. In particular, LWLM achieves 26.0%--87.5% improvement over transformer\nmodels without pretraining, and exhibits strong generalization under\nlabel-limited fine-tuning and unseen BS configurations, confirming its\npotential as a foundation model for wireless localization.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "13 pages,16 figures.This work has been submitted to the IEEE for\n  possible publication",
    "pdf_url": "http://arxiv.org/pdf/2505.10134v1",
    "published_date": "2025-05-15 10:04:44 UTC",
    "updated_date": "2025-05-15 10:04:44 UTC"
  },
  {
    "arxiv_id": "2505.10128v1",
    "title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity",
    "authors": [
      "Huy Q. Le",
      "Latif U. Khan",
      "Choong Seon Hong"
    ],
    "abstract": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IWCMC 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.10128v1",
    "published_date": "2025-05-15 09:53:14 UTC",
    "updated_date": "2025-05-15 09:53:14 UTC"
  },
  {
    "arxiv_id": "2505.10120v1",
    "title": "All You Need Is Synthetic Task Augmentation",
    "authors": [
      "Guillaume Godin"
    ],
    "abstract": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 3 Figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.10120v1",
    "published_date": "2025-05-15 09:46:27 UTC",
    "updated_date": "2025-05-15 09:46:27 UTC"
  },
  {
    "arxiv_id": "2505.10105v1",
    "title": "EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation",
    "authors": [
      "Zibin Dong",
      "Fei Ni",
      "Yifu Yuan",
      "Yinchuan Li",
      "Jianye Hao"
    ],
    "abstract": "We present EmbodiedMAE, a unified 3D multi-modal representation for robot\nmanipulation. Current approaches suffer from significant domain gaps between\ntraining datasets and robot manipulation tasks, while also lacking model\narchitectures that can effectively incorporate 3D information. To overcome\nthese limitations, we enhance the DROID dataset with high-quality depth maps\nand point clouds, constructing DROID-3D as a valuable supplement for 3D\nembodied vision research. Then we develop EmbodiedMAE, a multi-modal masked\nautoencoder that simultaneously learns representations across RGB, depth, and\npoint cloud modalities through stochastic masking and cross-modal fusion.\nTrained on DROID-3D, EmbodiedMAE consistently outperforms state-of-the-art\nvision foundation models (VFMs) in both training efficiency and final\nperformance across 70 simulation tasks and 20 real-world robot manipulation\ntasks on two robot platforms. The model exhibits strong scaling behavior with\nsize and promotes effective policy learning from 3D inputs. Experimental\nresults establish EmbodiedMAE as a reliable unified 3D multi-modal VFM for\nembodied AI systems, particularly in precise tabletop manipulation settings\nwhere spatial perception is critical.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10105v1",
    "published_date": "2025-05-15 09:12:17 UTC",
    "updated_date": "2025-05-15 09:12:17 UTC"
  },
  {
    "arxiv_id": "2505.10101v1",
    "title": "LAV: Audio-Driven Dynamic Visual Generation with Neural Compression and StyleGAN2",
    "authors": [
      "Jongmin Jung",
      "Dasaem Jeong"
    ],
    "abstract": "This paper introduces LAV (Latent Audio-Visual), a system that integrates\nEnCodec's neural audio compression with StyleGAN2's generative capabilities to\nproduce visually dynamic outputs driven by pre-recorded audio. Unlike previous\nworks that rely on explicit feature mappings, LAV uses EnCodec embeddings as\nlatent representations, directly transformed into StyleGAN2's style latent\nspace via randomly initialized linear mapping. This approach preserves semantic\nrichness in the transformation, enabling nuanced and semantically coherent\naudio-visual translations. The framework demonstrates the potential of using\npretrained audio compression models for artistic and computational\napplications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.GR",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Paper accepted at ISEA 2025, The 30th International Symposium on\n  Electronic/Emerging Art, Seoul, Republic of Korea, 23 - 29 May 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.10101v1",
    "published_date": "2025-05-15 09:04:12 UTC",
    "updated_date": "2025-05-15 09:04:12 UTC"
  },
  {
    "arxiv_id": "2505.10093v1",
    "title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI",
    "authors": [
      "Hsuan-Lei Shao"
    ],
    "abstract": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.4; H.3.3; J.5"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.10093v1",
    "published_date": "2025-05-15 08:51:53 UTC",
    "updated_date": "2025-05-15 08:51:53 UTC"
  },
  {
    "arxiv_id": "2505.10074v1",
    "title": "Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs",
    "authors": [
      "Mohamed Abdelmagied",
      "Mohamed Amine Chatti",
      "Shoeb Joarder",
      "Qurat Ul Ain",
      "Rawaa Alatrash"
    ],
    "abstract": "Massive Open Online Courses (MOOCs) lack direct interaction between learners\nand instructors, making it challenging for learners to understand new knowledge\nconcepts. Recently, learners have increasingly used Large Language Models\n(LLMs) to support them in acquiring new knowledge. However, LLMs are prone to\nhallucinations which limits their reliability. Retrieval-Augmented Generation\n(RAG) addresses this issue by retrieving relevant documents before generating a\nresponse. However, the application of RAG across different MOOCs is limited by\nunstructured learning material. Furthermore, current RAG systems do not\nactively guide learners toward their learning needs. To address these\nchallenges, we propose a Graph RAG pipeline that leverages Educational\nKnowledge Graphs (EduKGs) and Personal Knowledge Graphs (PKGs) to guide\nlearners to understand knowledge concepts in the MOOC platform CourseMapper.\nSpecifically, we implement (1) a PKG-based Question Generation method to\nrecommend personalized questions for learners in context, and (2) an\nEduKG-based Question Answering method that leverages the relationships between\nknowledge concepts in the EduKG to answer learner selected questions. To\nevaluate both methods, we conducted a study with 3 expert instructors on 3\ndifferent MOOCs in the MOOC platform CourseMapper. The results of the\nevaluation show the potential of Graph RAG to empower learners to understand\nnew knowledge concepts in a personalized learning experience.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at EMOOCs 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.10074v1",
    "published_date": "2025-05-15 08:24:47 UTC",
    "updated_date": "2025-05-15 08:24:47 UTC"
  },
  {
    "arxiv_id": "2505.10073v1",
    "title": "Multi-Robot Task Allocation for Homogeneous Tasks with Collision Avoidance via Spatial Clustering",
    "authors": [
      "Rathin Chandra Shit",
      "Sharmila Subudhi"
    ],
    "abstract": "In this paper, a novel framework is presented that achieves a combined\nsolution based on Multi-Robot Task Allocation (MRTA) and collision avoidance\nwith respect to homogeneous measurement tasks taking place in industrial\nenvironments. The spatial clustering we propose offers to simultaneously solve\nthe task allocation problem and deal with collision risks by cutting the\nworkspace into distinguishable operational zones for each robot. To divide task\nsites and to schedule robot routes within corresponding clusters, we use\nK-means clustering and the 2-Opt algorithm. The presented framework shows\nsatisfactory performance, where up to 93\\% time reduction (1.24s against\n17.62s) with a solution quality improvement of up to 7\\% compared to the best\nperforming method is demonstrated. Our method also completely eliminates\ncollision points that persist in comparative methods in a most significant\nsense. Theoretical analysis agrees with the claim that spatial partitioning\nunifies the apparently disjoint tasks allocation and collision avoidance\nproblems under conditions of many identical tasks to be distributed over sparse\ngeographical areas. Ultimately, the findings in this work are of substantial\nimportance for real world applications where both computational efficiency and\noperation free from collisions is of paramount importance.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "5 pages, 4 figures, Scheduled for presentation at an upcoming\n  conference",
    "pdf_url": "http://arxiv.org/pdf/2505.10073v1",
    "published_date": "2025-05-15 08:20:57 UTC",
    "updated_date": "2025-05-15 08:20:57 UTC"
  },
  {
    "arxiv_id": "2505.10066v1",
    "title": "Dark LLMs: The Growing Threat of Unaligned AI Models",
    "authors": [
      "Michael Fire",
      "Yitzhak Elbazis",
      "Adi Wasenstein",
      "Lior Rokach"
    ],
    "abstract": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "68T50, 68T05, 68P25",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10066v1",
    "published_date": "2025-05-15 08:07:04 UTC",
    "updated_date": "2025-05-15 08:07:04 UTC"
  },
  {
    "arxiv_id": "2505.10055v1",
    "title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language",
    "authors": [
      "Ijazul Haq",
      "Yingjie Zhang",
      "Irfan Ali Khan"
    ],
    "abstract": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10055v1",
    "published_date": "2025-05-15 07:58:38 UTC",
    "updated_date": "2025-05-15 07:58:38 UTC"
  },
  {
    "arxiv_id": "2505.10050v1",
    "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods",
    "authors": [
      "Fahad Almalki",
      "Mehedi Masud"
    ],
    "abstract": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10050v1",
    "published_date": "2025-05-15 07:53:02 UTC",
    "updated_date": "2025-05-15 07:53:02 UTC"
  },
  {
    "arxiv_id": "2505.10043v1",
    "title": "Boosting Text-to-Chart Retrieval through Training with Synthesized Semantic Insights",
    "authors": [
      "Yifan Wu",
      "Lutao Yan",
      "Yizhang Zhu",
      "Yinan Mei",
      "Jiannan Wang",
      "Nan Tang",
      "Yuyu Luo"
    ],
    "abstract": "Charts are crucial for data analysis and decision-making.Text-to-chart\nretrieval systems have become increasingly important for Business Intelligence\n(BI), where users need to find relevant charts that match their analytical\nneeds. These needs can be categorized into precise queries that are\nwell-specified and fuzzy queries that are more exploratory -- both require\nunderstanding the semantics and context of the charts. However, existing\ntext-to-chart retrieval solutions often fail to capture the semantic content\nand contextual information of charts, primarily due to the lack of\ncomprehensive metadata (or semantic insights). To address this limitation, we\npropose a training data development pipeline that automatically synthesizes\nhierarchical semantic insights for charts, covering visual patterns\n(visual-oriented), statistical properties (statistics-oriented), and practical\napplications (task-oriented), which produces 207,498 semantic insights for\n69,166 charts. Based on these, we train a CLIP-based model named ChartFinder to\nlearn better representations of charts for text-to-chart retrieval. Our method\nleverages rich semantic insights during the training phase to develop a model\nthat understands both visual and semantic aspects of charts.To evaluate\ntext-to-chart retrieval performance, we curate the first benchmark, CRBench,\nfor this task with 21,862 charts and 326 text queries from real-world BI\napplications, with ground-truth labels verified by the crowd\nworkers.Experiments show that ChartFinder significantly outperforms existing\nmethods in text-to-chart retrieval tasks across various settings. For precise\nqueries, ChartFinder achieves up to 66.9% NDCG@10, which is 11.58% higher than\nstate-of-the-art models. In fuzzy query tasks, our method also demonstrates\nconsistent improvements, with an average increase of 5% across nearly all\nmetrics.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.10043v1",
    "published_date": "2025-05-15 07:41:14 UTC",
    "updated_date": "2025-05-15 07:41:14 UTC"
  },
  {
    "arxiv_id": "2505.10037v1",
    "title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction",
    "authors": [
      "Takafumi Ito",
      "Lysenko Artem",
      "Tatsuhiko Tsunoda"
    ],
    "abstract": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.10037v1",
    "published_date": "2025-05-15 07:33:41 UTC",
    "updated_date": "2025-05-15 07:33:41 UTC"
  },
  {
    "arxiv_id": "2505.10034v1",
    "title": "The First MPDD Challenge: Multimodal Personality-aware Depression Detection",
    "authors": [
      "Changzeng Fu",
      "Zelin Fu",
      "Xinhe Kuang",
      "Jiacheng Dong",
      "Qi Zhang",
      "Kaifeng Su",
      "Yikai Su",
      "Wenbo Shi",
      "Junfeng Yao",
      "Yuliang Zhao",
      "Shiqi Zhao",
      "Jiadong Wang",
      "Siyang Song",
      "Chaoran Liu",
      "Yuichiro Yoshikawa",
      "BjÃ¶rn Schuller",
      "Hiroshi Ishiguro"
    ],
    "abstract": "Depression is a widespread mental health issue affecting diverse age groups,\nwith notable prevalence among college students and the elderly. However,\nexisting datasets and detection methods primarily focus on young adults,\nneglecting the broader age spectrum and individual differences that influence\ndepression manifestation. Current approaches often establish a direct mapping\nbetween multimodal data and depression indicators, failing to capture the\ncomplexity and diversity of depression across individuals. This challenge\nincludes two tracks based on age-specific subsets: Track 1 uses the\nMPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses\nthe MPDD-Young dataset for detecting depression in younger participants. The\nMultimodal Personality-aware Depression Detection (MPDD) Challenge aims to\naddress this gap by incorporating multimodal data alongside individual\ndifference factors. We provide a baseline model that fuses audio and video\nmodalities with individual difference information to detect depression\nmanifestations in diverse populations. This challenge aims to promote the\ndevelopment of more personalized and accurate de pression detection methods,\nadvancing mental health research and fostering inclusive detection systems.\nMore details are available on the official challenge website:\nhttps://hacilab.github.io/MPDDChallenge.github.io.",
    "categories": [
      "cs.AI",
      "68T07",
      "I.2.0; H.5.1"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted as part of the MPDD Challenge in the\n  ACMMM 2025 Grand Challenge",
    "pdf_url": "http://arxiv.org/pdf/2505.10034v1",
    "published_date": "2025-05-15 07:29:33 UTC",
    "updated_date": "2025-05-15 07:29:33 UTC"
  },
  {
    "arxiv_id": "2505.10027v1",
    "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction",
    "authors": [
      "Shijie Lyu"
    ],
    "abstract": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by the 4th International Conference on Computing Innovation\n  and Applied Physics (CONF-CIAP 2025), and will be published in EAI Community\n  Research Series-CORE or Theoretical and Natural Science (TNS)",
    "pdf_url": "http://arxiv.org/pdf/2505.10027v1",
    "published_date": "2025-05-15 07:17:03 UTC",
    "updated_date": "2025-05-15 07:17:03 UTC"
  },
  {
    "arxiv_id": "2505.10016v1",
    "title": "Application of YOLOv8 in monocular downward multiple Car Target detection",
    "authors": [
      "Shijie Lyu"
    ],
    "abstract": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.8; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by the 5th International Conference on Signal Processing and\n  Machine Learning (CONF-SPML 2025), to appear in Applied and Computational\n  Engineering",
    "pdf_url": "http://arxiv.org/pdf/2505.10016v1",
    "published_date": "2025-05-15 06:58:45 UTC",
    "updated_date": "2025-05-15 06:58:45 UTC"
  },
  {
    "arxiv_id": "2505.10012v1",
    "title": "Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering",
    "authors": [
      "Tadashi Kadowaki"
    ],
    "abstract": "Recent advances in artificial intelligence (AI) and quantum computing are\naccelerating automation in scientific and engineering processes, fundamentally\nreshaping research methodologies. This perspective highlights parallels between\nscientific automation and established Computer-Aided Engineering (CAE)\npractices, introducing Quantum CAE as a framework that leverages quantum\nalgorithms for simulation, optimization, and machine learning within\nengineering design. Practical implementations of Quantum CAE are illustrated\nthrough case studies for combinatorial optimization problems. Further\ndiscussions include advancements toward higher automation levels, highlighting\nthe critical role of specialized AI agents proficient in quantum algorithm\ndesign. The integration of quantum computing with AI raises significant\nquestions about the collaborative dynamics among human scientists and\nengineers, AI systems, and quantum computational resources, underscoring a\ntransformative future for automated discovery and innovation.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.10012v1",
    "published_date": "2025-05-15 06:53:30 UTC",
    "updated_date": "2025-05-15 06:53:30 UTC"
  },
  {
    "arxiv_id": "2505.09989v1",
    "title": "AI Greenferencing: Routing AI Inferencing to Green Modular Data Centers with Heron",
    "authors": [
      "Tella Rajashekhar Reddy",
      "Palak",
      "Rohan Gandhi",
      "Anjaly Parayil",
      "Chaojie Zhang",
      "Mike Shepperd",
      "Liangcheng Yu",
      "Jayashree Mohan",
      "Srinivasan Iyengar",
      "Shivkumar Kalyanaraman",
      "Debopam Bhattacherjee"
    ],
    "abstract": "AI power demand is growing unprecedentedly thanks to the high power density\nof AI compute and the emerging inferencing workload. On the supply side,\nabundant wind power is waiting for grid access in interconnection queues. In\nthis light, this paper argues bringing AI workload to modular compute clusters\nco-located in wind farms. Our deployment right-sizing strategy makes it\neconomically viable to deploy more than 6 million high-end GPUs today that\ncould consume cheap, green power at its source. We built Heron, a cross-site\nsoftware router, that could efficiently leverage the complementarity of power\ngeneration across wind farms by routing AI inferencing workload around power\ndrops. Using 1-week ofcoding and conversation production traces from Azure and\n(real) variable wind power traces, we show how Heron improves aggregate goodput\nof AI compute by up to 80% compared to the state-of-the-art.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09989v1",
    "published_date": "2025-05-15 06:03:47 UTC",
    "updated_date": "2025-05-15 06:03:47 UTC"
  },
  {
    "arxiv_id": "2505.09974v1",
    "title": "Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data",
    "authors": [
      "Adel ElZemity",
      "Budi Arief",
      "Shujun Li"
    ],
    "abstract": "The integration of large language models (LLMs) into cyber security\napplications presents significant opportunities, such as enhancing threat\nanalysis and malware detection, but can also introduce critical risks and\nsafety concerns, including personal data leakage and automated generation of\nnew malware. We present a systematic evaluation of safety risks in fine-tuned\nLLMs for cyber security applications. Using the OWASP Top 10 for LLM\nApplications framework, we assessed seven open-source LLMs: Phi 3 Mini 3.8B,\nMistral 7B, Qwen 2.5 7B, Llama 3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B.\nOur evaluation shows that fine-tuning reduces safety resilience across all\ntested LLMs (e.g., the safety score of Llama 3.1 8B against prompt injection\ndrops from 0.95 to 0.15). We propose and evaluate a safety alignment approach\nthat carefully rewords instruction-response pairs to include explicit safety\nprecautions and ethical considerations. This approach demonstrates that it is\npossible to maintain or even improve model safety while preserving technical\nutility, offering a practical path forward for developing safer fine-tuning\nmethodologies. This work offers a systematic evaluation for safety risks in\nLLMs, enabling safer adoption of generative AI in sensitive domains, and\ncontributing towards the development of secure, trustworthy, and ethically\naligned LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09974v1",
    "published_date": "2025-05-15 05:22:53 UTC",
    "updated_date": "2025-05-15 05:22:53 UTC"
  },
  {
    "arxiv_id": "2505.09970v1",
    "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents",
    "authors": [
      "Mrinal Rawat",
      "Ambuje Gupta",
      "Rushil Goomer",
      "Alessandro Di Bari",
      "Neha Gupta",
      "Roberto Pieraccini"
    ],
    "abstract": "The ReAct (Reasoning + Action) capability in large language models (LLMs) has\nbecome the foundation of modern agentic systems. Recent LLMs, such as\nDeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through\nthe generation of ample intermediate tokens, which help build a strong premise\nbefore producing the final output tokens. In this paper, we introduce Pre-Act,\na novel approach that enhances the agent's performance by creating a multi-step\nexecution plan along with the detailed reasoning for the given user input. This\nplan incrementally incorporates previous steps and tool outputs, refining\nitself after each step execution until the final response is obtained. Our\napproach is applicable to both conversational and non-conversational agents. To\nmeasure the performance of task-oriented agents comprehensively, we propose a\ntwo-level evaluation framework: (1) turn level and (2) end-to-end. Our\nturn-level evaluation, averaged across five models, shows that our approach,\nPre-Act, outperforms ReAct by 70% in Action Recall on the Almita dataset. While\nthis approach is effective for larger models, smaller models crucial for\npractical applications, where latency and cost are key constraints, often\nstruggle with complex reasoning tasks required for agentic systems. To address\nthis limitation, we fine-tune relatively small models such as Llama 3.1 (8B &\n70B) using the proposed Pre-Act approach. Our experiments show that the\nfine-tuned 70B model outperforms GPT-4, achieving a 69.5% improvement in action\naccuracy (turn-level) and a 28% improvement in goal completion rate\n(end-to-end) on the Almita (out-of-domain) dataset.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09970v1",
    "published_date": "2025-05-15 05:17:47 UTC",
    "updated_date": "2025-05-15 05:17:47 UTC"
  },
  {
    "arxiv_id": "2505.09969v1",
    "title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives",
    "authors": [
      "Ali Azimi Lamir",
      "Shiva Razzagzadeh",
      "Zeynab Rezaei"
    ],
    "abstract": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09969v1",
    "published_date": "2025-05-15 05:13:38 UTC",
    "updated_date": "2025-05-15 05:13:38 UTC"
  },
  {
    "arxiv_id": "2505.09955v1",
    "title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation",
    "authors": [
      "Jaeho Kim",
      "Seulki Lee"
    ],
    "abstract": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2025 Accept",
    "pdf_url": "http://arxiv.org/pdf/2505.09955v1",
    "published_date": "2025-05-15 04:27:48 UTC",
    "updated_date": "2025-05-15 04:27:48 UTC"
  },
  {
    "arxiv_id": "2505.09952v1",
    "title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning",
    "authors": [
      "Tianyu Huai",
      "Jie Zhou",
      "Yuxuan Cai",
      "Qin Chen",
      "Wen Wu",
      "Xingjiao Wu",
      "Xipeng Qiu",
      "Liang He"
    ],
    "abstract": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to Neurips2025",
    "pdf_url": "http://arxiv.org/pdf/2505.09952v1",
    "published_date": "2025-05-15 04:22:35 UTC",
    "updated_date": "2025-05-15 04:22:35 UTC"
  },
  {
    "arxiv_id": "2505.09945v1",
    "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph",
    "authors": [
      "Deeksha Prahlad",
      "Chanhee Lee",
      "Dongha Kim",
      "Hokeun Kim"
    ],
    "abstract": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)",
    "pdf_url": "http://arxiv.org/pdf/2505.09945v1",
    "published_date": "2025-05-15 04:01:58 UTC",
    "updated_date": "2025-05-15 04:01:58 UTC"
  },
  {
    "arxiv_id": "2505.09935v1",
    "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety",
    "authors": [
      "Ahmed S. Abdelrahman",
      "Mohamed Abdel-Aty",
      "Quoc Dai Tran"
    ],
    "abstract": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09935v1",
    "published_date": "2025-05-15 03:40:29 UTC",
    "updated_date": "2025-05-15 03:40:29 UTC"
  },
  {
    "arxiv_id": "2505.09932v1",
    "title": "Demystifying AI Agents: The Final Generation of Intelligence",
    "authors": [
      "Kevin J McNamara",
      "Rhea Pritham Marpu"
    ],
    "abstract": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09932v1",
    "published_date": "2025-05-15 03:35:12 UTC",
    "updated_date": "2025-05-15 03:35:12 UTC"
  },
  {
    "arxiv_id": "2505.09926v1",
    "title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection",
    "authors": [
      "Bin-Bin Gao",
      "Yue Zhu",
      "Jiangtao Yan",
      "Yuezhi Cai",
      "Weixi Zhang",
      "Meng Wang",
      "Jun Liu",
      "Yong Liu",
      "Lei Wang",
      "Chengjie Wang"
    ],
    "abstract": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "27 pages, 15 figures, 22 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.09926v1",
    "published_date": "2025-05-15 03:24:28 UTC",
    "updated_date": "2025-05-15 03:24:28 UTC"
  },
  {
    "arxiv_id": "2505.09925v1",
    "title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback",
    "authors": [
      "Yutao Yang",
      "Jie Zhou",
      "Junsong Li",
      "Qianjun Pan",
      "Bihao Zhan",
      "Qin Chen",
      "Xipeng Qiu",
      "Liang He"
    ],
    "abstract": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09925v1",
    "published_date": "2025-05-15 03:22:03 UTC",
    "updated_date": "2025-05-15 03:22:03 UTC"
  },
  {
    "arxiv_id": "2505.09923v1",
    "title": "\"There Is No Such Thing as a Dumb Question,\" But There Are Good Ones",
    "authors": [
      "Minjung Shin",
      "Donghyun Kim",
      "Jeh-Kwang Ryu"
    ],
    "abstract": "Questioning has become increasingly crucial for both humans and artificial\nintelligence, yet there remains limited research comprehensively assessing\nquestion quality. In response, this study defines good questions and presents a\nsystematic evaluation framework. We propose two key evaluation dimensions:\nappropriateness (sociolinguistic competence in context) and effectiveness\n(strategic competence in goal achievement). Based on these foundational\ndimensions, a rubric-based scoring system was developed. By incorporating\ndynamic contextual variables, our evaluation framework achieves structure and\nflexibility through semi-adaptive criteria. The methodology was validated using\nthe CAUS and SQUARE datasets, demonstrating the ability of the framework to\naccess both well-formed and problematic questions while adapting to varied\ncontexts. As we establish a flexible and comprehensive framework for question\nevaluation, this study takes a significant step toward integrating questioning\nbehavior with structured analytical methods grounded in the intrinsic nature of\nquestioning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 4 figures and 4 tables. This work has been accepted for\n  presentation as a poster with full paper publication at CogSci 2025. This is\n  the final submission",
    "pdf_url": "http://arxiv.org/pdf/2505.09923v1",
    "published_date": "2025-05-15 03:12:28 UTC",
    "updated_date": "2025-05-15 03:12:28 UTC"
  },
  {
    "arxiv_id": "2505.09920v1",
    "title": "Offline Reinforcement Learning for Microgrid Voltage Regulation",
    "authors": [
      "Shan Yang",
      "Yongli Zhu"
    ],
    "abstract": "This paper presents a study on using different offline reinforcement learning\nalgorithms for microgrid voltage regulation with solar power penetration. When\nenvironment interaction is unviable due to technical or safety reasons, the\nproposed approach can still obtain an applicable model through offline-style\ntraining on a previously collected dataset, lowering the negative impact of\nlacking online environment interactions. Experiment results on the IEEE 33-bus\nsystem demonstrate the feasibility and effectiveness of the proposed approach\non different offline datasets, including the one with merely low-quality\nexperience.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.09920v1",
    "published_date": "2025-05-15 03:10:18 UTC",
    "updated_date": "2025-05-15 03:10:18 UTC"
  },
  {
    "arxiv_id": "2505.09907v1",
    "title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture",
    "authors": [
      "Linwei Zhang",
      "LuFeng",
      "Ruijia Liang"
    ],
    "abstract": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09907v1",
    "published_date": "2025-05-15 02:26:22 UTC",
    "updated_date": "2025-05-15 02:26:22 UTC"
  },
  {
    "arxiv_id": "2505.09901v1",
    "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks",
    "authors": [
      "Ziyuan Zhang",
      "Darcy Wang",
      "Ningyuan Chen",
      "Rodrigo Mansur",
      "Vahid Sarhangian"
    ],
    "abstract": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09901v1",
    "published_date": "2025-05-15 02:09:18 UTC",
    "updated_date": "2025-05-15 02:09:18 UTC"
  },
  {
    "arxiv_id": "2505.09868v1",
    "title": "Which Demographic Features Are Relevant for Individual Fairness Evaluation of U.S. Recidivism Risk Assessment Tools?",
    "authors": [
      "Tin Trung Nguyen",
      "Jiannan Xu",
      "Phuong-Anh Nguyen-Le",
      "Jonathan Lazar",
      "Donald Braman",
      "Hal DaumÃ© III",
      "Zubin Jelveh"
    ],
    "abstract": "Despite its U.S. constitutional foundation, the technical ``individual\nfairness'' criterion has not been operationalized in state or federal\nstatutes/regulations. We conduct a human subjects experiment to address this\ngap, evaluating which demographic features are relevant for individual fairness\nevaluation of recidivism risk assessment (RRA) tools. Our analyses conclude\nthat the individual similarity function should consider age and sex, but it\nshould ignore race.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09868v1",
    "published_date": "2025-05-15 00:07:07 UTC",
    "updated_date": "2025-05-15 00:07:07 UTC"
  }
]